<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-21  Taming Generative Synthetic Data for X-ray Prohibited Item Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ca0a2e91f3788acd39262d173122e00f')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    38 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-21-æ›´æ–°"><a href="#2025-11-21-æ›´æ–°" class="headerlink" title="2025-11-21 æ›´æ–°"></a>2025-11-21 æ›´æ–°</h1><h2 id="Taming-Generative-Synthetic-Data-for-X-ray-Prohibited-Item-Detection"><a href="#Taming-Generative-Synthetic-Data-for-X-ray-Prohibited-Item-Detection" class="headerlink" title="Taming Generative Synthetic Data for X-ray Prohibited Item Detection"></a>Taming Generative Synthetic Data for X-ray Prohibited Item Detection</h2><p><strong>Authors:Jialong Sun, Hongguang Zhu, Weizhe Liu, Yunda Sun, Renshuai Tao, Yunchao Wei</strong></p>
<p>Training prohibited item detection models requires a large amount of X-ray security images, but collecting and annotating these images is time-consuming and laborious. To address data insufficiency, X-ray security image synthesis methods composite images to scale up datasets. However, previous methods primarily follow a two-stage pipeline, where they implement labor-intensive foreground extraction in the first stage and then composite images in the second stage. Such a pipeline introduces inevitable extra labor cost and is not efficient. In this paper, we propose a one-stage X-ray security image synthesis pipeline (Xsyn) based on text-to-image generation, which incorporates two effective strategies to improve the usability of synthetic images. The Cross-Attention Refinement (CAR) strategy leverages the cross-attention map from the diffusion model to refine the bounding box annotation. The Background Occlusion Modeling (BOM) strategy explicitly models background occlusion in the latent space to enhance imaging complexity. To the best of our knowledge, compared with previous methods, Xsyn is the first to achieve high-quality X-ray security image synthesis without extra labor cost. Experiments demonstrate that our method outperforms all previous methods with 1.2% mAP improvement, and the synthetic images generated by our method are beneficial to improve prohibited item detection performance across various X-ray security datasets and detectors. Code is available at <a target="_blank" rel="noopener" href="https://github.com/pILLOW-1/Xsyn/">https://github.com/pILLOW-1/Xsyn/</a>.</p>
<blockquote>
<p>è®­ç»ƒç¦æ­¢ç‰©å“æ£€æµ‹æ¨¡å‹éœ€è¦å¤§é‡çš„Xå…‰å®‰æ£€å›¾åƒï¼Œä½†æ”¶é›†å’Œæ ‡æ³¨è¿™äº›å›¾åƒæ—¢è€—æ—¶åˆè´¹åŠ›ã€‚ä¸ºäº†è§£å†³æ•°æ®ä¸è¶³çš„é—®é¢˜ï¼ŒXå…‰å®‰æ£€å›¾åƒåˆæˆæ–¹æ³•é€šè¿‡åˆæˆå›¾åƒæ¥æ‰©å¤§æ•°æ®é›†ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„æ–¹æ³•ä¸»è¦é‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“ï¼Œåœ¨ç¬¬ä¸€é˜¶æ®µè¿›è¡ŒåŠ³åŠ¨å¯†é›†å‹çš„å‰æ™¯æå–ï¼Œç„¶ååœ¨ç¬¬äºŒé˜¶æ®µè¿›è¡Œå›¾åƒåˆæˆã€‚è¿™ç§ç®¡é“å¸¦æ¥äº†ä¸å¯é¿å…çš„é¢å¤–åŠ³åŠ¨åŠ›æˆæœ¬ï¼Œå¹¶ä¸”æ•ˆç‡ä¸é«˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ä¸€é˜¶æ®µXå…‰å®‰æ£€å›¾åƒåˆæˆç®¡é“ï¼ˆXsynï¼‰ï¼Œè¯¥ç®¡é“é‡‡ç”¨ä¸¤ç§æœ‰æ•ˆç­–ç•¥æ¥æé«˜åˆæˆå›¾åƒçš„ä½¿ç”¨æ€§ã€‚Cross-Attention Refinementï¼ˆCARï¼‰ç­–ç•¥åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„äº¤å‰æ³¨æ„åŠ›å›¾æ¥ä¼˜åŒ–è¾¹ç•Œæ¡†æ ‡æ³¨ã€‚Background Occlusion Modelingï¼ˆBOMï¼‰ç­–ç•¥åœ¨æ½œåœ¨ç©ºé—´ä¸­æ˜¾å¼å»ºæ¨¡èƒŒæ™¯é®æŒ¡ï¼Œä»¥æé«˜æˆåƒå¤æ‚æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒXsyné¦–æ¬¡å®ç°äº†æ— éœ€é¢å¤–åŠ³åŠ¨åŠ›æˆæœ¬çš„é«˜è´¨é‡Xå…‰å®‰æ£€å›¾åƒåˆæˆã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ‰€æœ‰ä¹‹å‰çš„æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼ŒmAPæé«˜äº†1.2%ï¼Œå¹¶ä¸”æˆ‘ä»¬æ–¹æ³•ç”Ÿæˆçš„åˆæˆå›¾åƒå¯¹æé«˜å„ç§Xå…‰å®‰æ£€æ•°æ®é›†å’Œæ£€æµ‹å™¨çš„ç¦æ­¢ç‰©å“æ£€æµ‹æ€§èƒ½æœ‰ç›Šã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/pILLOW-1/Xsyn/%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/pILLOW-1/Xsyn/è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.15299v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ä¸€ç«™å¼Xå…‰å®‰æ£€å›¾åƒåˆæˆæ–¹æ³•ï¼ˆXsynï¼‰ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤ç§ç­–ç•¥æé«˜åˆæˆå›¾åƒçš„ä½¿ç”¨æ€§ï¼ŒåŒ…æ‹¬åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„è·¨æ³¨æ„åŠ›æ˜ å°„ç»†åŒ–è¾¹ç•Œæ¡†æ ‡æ³¨çš„èƒŒæ™¯é®æŒ¡å»ºæ¨¡ç­–ç•¥ï¼ˆBOMï¼‰ã€‚ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼ŒXsynæ— éœ€é¢å¤–äººå·¥æˆæœ¬å³å¯å®ç°é«˜è´¨é‡Xå…‰å®‰æ£€å›¾åƒåˆæˆï¼Œä¸”åœ¨å¤šä¸ªæ•°æ®é›†å’Œæ£€æµ‹å™¨ä¸Šæé«˜äº†ç¦è¿ç‰©å“çš„æ£€æµ‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®­ç»ƒç¦è¿ç‰©å“æ£€æµ‹æ¨¡å‹éœ€è¦å¤§é‡Xå…‰å®‰æ£€å›¾åƒï¼Œä½†æ”¶é›†å’Œæ ‡æ³¨è¿™äº›å›¾åƒè€—æ—¶è´¹åŠ›ã€‚</li>
<li>X-rayå®‰æ£€å›¾åƒåˆæˆæ–¹æ³•é€šè¿‡åˆæˆå›¾åƒæ¥è§£å†³æ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦éµå¾ªä¸¤é˜¶æ®µæµç¨‹ï¼Œç¬¬ä¸€é˜¶æ®µè¿›è¡ŒåŠ³åŠ¨å¯†é›†å‹çš„å‰æ™¯æå–ï¼Œç¬¬äºŒé˜¶æ®µè¿›è¡Œå›¾åƒåˆæˆï¼Œè¿™ç§æ–¹æ³•æˆæœ¬é«˜ä¸”æ•ˆç‡ä½ä¸‹ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ä¸€ç«™å¼Xå…‰å®‰æ£€å›¾åƒåˆæˆæ–¹æ³•ï¼ˆXsynï¼‰ã€‚</li>
<li>Xsyné‡‡ç”¨ä¸¤ç§ç­–ç•¥æé«˜åˆæˆå›¾åƒè´¨é‡ï¼šè·¨æ³¨æ„åŠ›ç»†åŒ–ï¼ˆCARï¼‰å’ŒèƒŒæ™¯é®æŒ¡å»ºæ¨¡ï¼ˆBOMï¼‰ã€‚</li>
<li>Xsynæ— éœ€é¢å¤–äººå·¥æˆæœ¬å³å¯å®ç°é«˜è´¨é‡Xå…‰å®‰æ£€å›¾åƒåˆæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.15299">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7b6f1d37728266ef6b9f429e8996856d" align="middle">
<img src="https://picx.zhimg.com/v2-58668a08881ba7cf636abd59c3538ba6" align="middle">
<img src="https://picx.zhimg.com/v2-1b648bc86e5e172231dd7131b5448367" align="middle">
<img src="https://picx.zhimg.com/v2-bb30402b3b3ca6699deb293ce3107b96" align="middle">
<img src="https://picx.zhimg.com/v2-ca0a2e91f3788acd39262d173122e00f" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Jointly-Conditioned-Diffusion-Model-for-Multi-View-Pose-Guided-Person-Image-Synthesis"><a href="#Jointly-Conditioned-Diffusion-Model-for-Multi-View-Pose-Guided-Person-Image-Synthesis" class="headerlink" title="Jointly Conditioned Diffusion Model for Multi-View Pose-Guided Person Image Synthesis"></a>Jointly Conditioned Diffusion Model for Multi-View Pose-Guided Person Image Synthesis</h2><p><strong>Authors:Chengyu Xie, Zhi Gong, Junchi Ren, Linkun Yu, Si Shen, Fei Shen, Xiaoyu Du</strong></p>
<p>Pose-guided human image generation is limited by incomplete textures from single reference views and the absence of explicit cross-view interaction. We present jointly conditioned diffusion model (JCDM), a jointly conditioned diffusion framework that exploits multi-view priors. The appearance prior module (APM) infers a holistic identity preserving prior from incomplete references, and the joint conditional injection (JCI) mechanism fuses multi-view cues and injects shared conditioning into the denoising backbone to align identity, color, and texture across poses. JCDM supports a variable number of reference views and integrates with standard diffusion backbones with minimal and targeted architectural modifications. Experiments demonstrate state of the art fidelity and cross-view consistency.</p>
<blockquote>
<p>å§¿æ€å¼•å¯¼çš„äººä½“å›¾åƒç”Ÿæˆå—é™äºå•ä¸€å‚è€ƒè§†è§’çš„ä¸å®Œæ•´çº¹ç†ä»¥åŠç¼ºä¹æ˜ç¡®çš„è·¨è§†è§’äº¤äº’ã€‚æˆ‘ä»¬æå‡ºäº†è”åˆæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆJCDMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤šè§†è§’å…ˆéªŒçš„è”åˆæ¡ä»¶æ‰©æ•£æ¡†æ¶ã€‚å¤–è§‚å…ˆéªŒæ¨¡å—ï¼ˆAPMï¼‰ä»ä¸å®Œå…¨çš„å‚è€ƒä¸­æ¨æ–­å‡ºæ•´ä½“çš„èº«ä»½ä¿ç•™å…ˆéªŒï¼Œè”åˆæ¡ä»¶æ³¨å…¥ï¼ˆJCIï¼‰æœºåˆ¶èåˆäº†å¤šè§†è§’çº¿ç´¢ï¼Œå¹¶å°†å…±äº«æ¡ä»¶æ³¨å…¥å»å™ªä¸»å¹²ä¸­ï¼Œä»¥åœ¨å§¿æ€ä¹‹é—´å¯¹é½èº«ä»½ã€é¢œè‰²å’Œçº¹ç†ã€‚JCDMæ”¯æŒå¯å˜æ•°é‡çš„å‚è€ƒè§†è§’ï¼Œå¹¶èƒ½ä¸æ ‡å‡†æ‰©æ•£ä¸»å¹²è¿›è¡Œé›†æˆï¼Œåªéœ€è¿›è¡Œæœ€å°åŒ–å’Œæœ‰é’ˆå¯¹æ€§çš„æ¶æ„ä¿®æ”¹ã€‚å®éªŒè¯æ˜äº†å…¶å“è¶Šçš„ä¿çœŸåº¦å’Œè·¨è§†è§’ä¸€è‡´æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.15092v1">PDF</a> </p>
<p><strong>Summary</strong>:<br>å¤šè§†è§’å…ˆéªŒæ‰©æ•£æ¨¡å‹ï¼ˆJCDMï¼‰æ˜¯ä¸€ç§åŸºäºå¤šè§†è§’å…ˆéªŒçš„è”åˆæ¡ä»¶æ‰©æ•£æ¡†æ¶ï¼Œè§£å†³äº†å§¿æ€å¼•å¯¼çš„äººä½“å›¾åƒç”Ÿæˆä¸­çš„çº¹ç†ä¸å®Œæ•´å’Œç¼ºä¹è·¨è§†è§’äº¤äº’çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹åŒ…æ‹¬å¤–è§‚å…ˆéªŒæ¨¡å—ï¼ˆAPMï¼‰å’Œè”åˆæ¡ä»¶æ³¨å…¥ï¼ˆJCIï¼‰æœºåˆ¶ï¼Œèƒ½å¤Ÿä»å‰è§†è§’çš„ä¸å®Œå…¨å‚è€ƒä¸­æ¨æ–­æ•´ä½“èº«ä»½ä¿æŒå…ˆéªŒä¿¡æ¯ï¼Œèåˆå¤šè§†è§’çº¿ç´¢å¹¶å°†å…±äº«æ¡ä»¶æ³¨å…¥å»å™ªä¸»å¹²ä¸­ï¼Œä»¥å®ç°è·¨å§¿æ€çš„èº«ä»½ã€é¢œè‰²å’Œçº¹ç†å¯¹é½ã€‚JCDMæ”¯æŒå¯å˜æ•°é‡çš„å‚è€ƒè§†è§’ï¼Œå¹¶èƒ½ä¸æ ‡å‡†æ‰©æ•£ä¸»å¹²è¿›è¡Œé›†æˆï¼Œåªéœ€è¿›è¡Œæœ€å°çš„æœ‰é’ˆå¯¹æ€§çš„æ¶æ„ä¿®æ”¹ã€‚å®éªŒè¯æ˜å…¶è¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆçš„ä¿çœŸåº¦å’Œè·¨è§†è§’ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>JCDMè§£å†³äº†å§¿æ€å¼•å¯¼çš„äººä½“å›¾åƒç”Ÿæˆä¸­çš„çº¹ç†ä¸å®Œæ•´é—®é¢˜ã€‚</li>
<li>JCDMåˆ©ç”¨å¤šè§†è§’å…ˆéªŒä¿¡æ¯æ¥æé«˜å›¾åƒç”Ÿæˆçš„è·¨è§†è§’ä¸€è‡´æ€§ã€‚</li>
<li>å¤–è§‚å…ˆéªŒæ¨¡å—ï¼ˆAPMï¼‰å¯ä»¥ä»ä¸å®Œå…¨çš„å‚è€ƒä¸­æ¨æ–­å‡ºèº«ä»½ä¿æŒçš„å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>è”åˆæ¡ä»¶æ³¨å…¥ï¼ˆJCIï¼‰æœºåˆ¶å®ç°äº†è·¨å§¿æ€çš„èº«ä»½ã€é¢œè‰²å’Œçº¹ç†å¯¹é½ã€‚</li>
<li>JCDMæ”¯æŒä½¿ç”¨å¯å˜æ•°é‡çš„å‚è€ƒè§†è§’ã€‚</li>
<li>JCDMå¯ä»¥ä¸ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ä¸»å¹²é›†æˆï¼Œåªéœ€è¿›è¡Œå°‘é‡çš„æ¶æ„ä¿®æ”¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.15092">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-98ffb048bba7a3ad75ecd5447271cfcc" align="middle">
<img src="https://picx.zhimg.com/v2-b5b3edfdfff0c67c61c1a77da0742b34" align="middle">
<img src="https://picx.zhimg.com/v2-87da02a2fe0fcc838799665cdc860e0e" align="middle">
<img src="https://picx.zhimg.com/v2-712bb297ccf57f4dc299a69ff0bfd631" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GeoMVD-Geometry-Enhanced-Multi-View-Generation-Model-Based-on-Geometric-Information-Extraction"><a href="#GeoMVD-Geometry-Enhanced-Multi-View-Generation-Model-Based-on-Geometric-Information-Extraction" class="headerlink" title="GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction"></a>GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction</h2><p><strong>Authors:Jiaqi Wu, Yaosen Chen, Shuyuan Zhu</strong></p>
<p>Multi-view image generation holds significant application value in computer vision, particularly in domains like 3D reconstruction, virtual reality, and augmented reality. Most existing methods, which rely on extending single images, face notable computational challenges in maintaining cross-view consistency and generating high-resolution outputs. To address these issues, we propose the Geometry-guided Multi-View Diffusion Model, which incorporates mechanisms for extracting multi-view geometric information and adjusting the intensity of geometric features to generate images that are both consistent across views and rich in detail. Specifically, we design a multi-view geometry information extraction module that leverages depth maps, normal maps, and foreground segmentation masks to construct a shared geometric structure, ensuring shape and structural consistency across different views. To enhance consistency and detail restoration during generation, we develop a decoupled geometry-enhanced attention mechanism that strengthens feature focus on key geometric details, thereby improving overall image quality and detail preservation. Furthermore, we apply an adaptive learning strategy that fine-tunes the model to better capture spatial relationships and visual coherence between the generated views, ensuring realistic results. Our model also incorporates an iterative refinement process that progressively improves the output quality through multiple stages of image generation. Finally, a dynamic geometry information intensity adjustment mechanism is proposed to adaptively regulate the influence of geometric data, optimizing overall quality while ensuring the naturalness of generated images. More details can be found on the project page: <a target="_blank" rel="noopener" href="https://sobeymil.github.io/GeoMVD.com">https://sobeymil.github.io/GeoMVD.com</a>.</p>
<blockquote>
<p>å¤šè§†è§’å›¾åƒç”Ÿæˆåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ï¼Œç‰¹åˆ«æ˜¯åœ¨3Dé‡å»ºã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºå•å¼ å›¾åƒçš„æ‰©å±•ï¼Œä½†åœ¨ä¿æŒè·¨è§†å›¾ä¸€è‡´æ€§å’Œç”Ÿæˆé«˜åˆ†è¾¨ç‡è¾“å‡ºæ–¹é¢é¢ä¸´é‡å¤§çš„è®¡ç®—æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å‡ ä½•å¼•å¯¼çš„å¤šè§†å›¾æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†æå–å¤šè§†å›¾å‡ ä½•ä¿¡æ¯å’Œè°ƒæ•´å‡ ä½•ç‰¹å¾å¼ºåº¦çš„æœºåˆ¶ï¼Œä»¥ç”Ÿæˆæ—¢è·¨è§†å›¾ä¸€è‡´åˆç»†èŠ‚ä¸°å¯Œçš„å›¾åƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¤šè§†å›¾å‡ ä½•ä¿¡æ¯æå–æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨æ·±åº¦å›¾ã€æ³•çº¿å›¾å’Œå‰æ™¯åˆ†å‰²æ©è†œæ¥æ„å»ºå…±äº«å‡ ä½•ç»“æ„ï¼Œç¡®ä¿ä¸åŒè§†å›¾ä¹‹é—´çš„å½¢çŠ¶å’Œç»“æ„ä¸€è‡´æ€§ã€‚ä¸ºäº†å¢å¼ºç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸€è‡´æ€§å’Œç»†èŠ‚æ¢å¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è§£è€¦çš„å‡ ä½•å¢å¼ºæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶åŠ å¼ºäº†å¯¹å…³é”®å‡ ä½•ç»†èŠ‚çš„ç‰¹å¾å…³æ³¨ï¼Œä»è€Œæé«˜äº†æ•´ä½“å›¾åƒè´¨é‡å’Œç»†èŠ‚ä¿ç•™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç­–ç•¥ï¼Œå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æ›´å¥½åœ°æ•æ‰ç”Ÿæˆè§†å›¾ä¹‹é—´çš„ç©ºé—´å…³ç³»å’Œè§†è§‰è¿è´¯æ€§ï¼Œç¡®ä¿ç»“æœçš„çœŸå®æ€§ã€‚æˆ‘ä»¬çš„æ¨¡å‹è¿˜ç»“åˆäº†ä¸€ç§è¿­ä»£ç»†åŒ–è¿‡ç¨‹ï¼Œé€šè¿‡å¤šä¸ªé˜¶æ®µçš„å›¾åƒç”Ÿæˆé€æ­¥æ”¹è¿›è¾“å‡ºè´¨é‡ã€‚æœ€åï¼Œæå‡ºäº†ä¸€ç§åŠ¨æ€å‡ ä½•ä¿¡æ¯å¼ºåº¦è°ƒæ•´æœºåˆ¶ï¼Œè‡ªé€‚åº”åœ°è°ƒèŠ‚å‡ ä½•æ•°æ®çš„å½±å“ï¼Œä¼˜åŒ–æ•´ä½“è´¨é‡ï¼ŒåŒæ—¶ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è‡ªç„¶æ€§ã€‚æ›´å¤šç»†èŠ‚å¯è®¿é—®é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://sobeymil.github.io/GeoMVD.com%E3%80%82">https://sobeymil.github.io/GeoMVD.comã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.12204v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå‡ ä½•å¼•å¯¼çš„å¤šè§†è§’æ‰©æ•£æ¨¡å‹ï¼ˆGeometry-guided Multi-View Diffusion Modelï¼‰ï¼Œç”¨äºå¤šè§†è§’å›¾åƒç”Ÿæˆã€‚è¯¥æ¨¡å‹é€šè¿‡æå–å’Œåˆ©ç”¨å¤šè§†è§’å‡ ä½•ä¿¡æ¯ï¼Œè°ƒæ•´å‡ ä½•ç‰¹å¾å¼ºåº¦ï¼Œç”Ÿæˆè§†è§’é—´ä¸€è‡´ä¸”ç»†èŠ‚ä¸°å¯Œçš„å›¾åƒã€‚æ¨¡å‹åŒ…æ‹¬å¤šè§†è§’å‡ ä½•ä¿¡æ¯æå–æ¨¡å—ã€å¢å¼ºå‡ ä½•ç‰¹å¾çš„æ³¨æ„åŠ›æœºåˆ¶å’Œè‡ªé€‚åº”å­¦ä¹ ç­–ç•¥ç­‰ï¼Œå¯åº”ç”¨äº3Dé‡å»ºã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚è¯¦æƒ…è®¿é—®é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://sobeymil.github.io/GeoMVD.com%E3%80%82">https://sobeymil.github.io/GeoMVD.comã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºä¸€ç§åŸºäºå‡ ä½•å¼•å¯¼çš„å¤šè§†è§’æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¤šè§†è§’å›¾åƒç”Ÿæˆã€‚</li>
<li>è®¾è®¡å¤šè§†è§’å‡ ä½•ä¿¡æ¯æå–æ¨¡å—ï¼Œåˆ©ç”¨æ·±åº¦å›¾ã€æ³•çº¿å›¾ã€å‰æ™¯åˆ†å‰²æ©è†œæ„å»ºå…±äº«å‡ ä½•ç»“æ„ï¼Œç¡®ä¿ä¸åŒè§†è§’çš„å½¢çŠ¶å’Œç»“æ„ä¸€è‡´æ€§ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§è§£è€¦çš„å‡ ä½•å¢å¼ºæ³¨æ„åŠ›æœºåˆ¶ï¼Œæé«˜äº†å¯¹å…³é”®å‡ ä½•ç»†èŠ‚çš„å…³æ³¨åº¦ï¼Œæ”¹å–„å›¾åƒè´¨é‡å’Œç»†èŠ‚ä¿ç•™ã€‚</li>
<li>åº”ç”¨è‡ªé€‚åº”å­¦ä¹ ç­–ç•¥ï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°æ•æ‰ç©ºé—´å…³ç³»å’Œè§†è§‰è¿è´¯æ€§ï¼Œç¡®ä¿ç”Ÿæˆç»“æœçš„çœŸå®æ€§ã€‚</li>
<li>æ¨¡å‹åŒ…å«è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ï¼Œé€šè¿‡å¤šä¸ªé˜¶æ®µçš„å›¾åƒç”Ÿæˆé€æ­¥æé«˜è¾“å‡ºè´¨é‡ã€‚</li>
<li>æå‡ºåŠ¨æ€å‡ ä½•ä¿¡æ¯å¼ºåº¦è°ƒæ•´æœºåˆ¶ï¼Œè‡ªé€‚åº”è°ƒèŠ‚å‡ ä½•æ•°æ®çš„å½±å“ï¼Œä¼˜åŒ–æ•´ä½“è´¨é‡ï¼Œç¡®ä¿ç”Ÿæˆå›¾åƒçš„è‡ªç„¶æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.12204">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-44e9596b83cb24b51fccbf6d6581539f" align="middle">
<img src="https://picx.zhimg.com/v2-ef809415046b3e1cc53a65b60b8df75b" align="middle">
<img src="https://picx.zhimg.com/v2-f8a60713b97c90f1d6b5648b30631e98" align="middle">
<img src="https://picx.zhimg.com/v2-c0bec6e15a1eee1dc91dcb78e24bb8b3" align="middle">
<img src="https://picx.zhimg.com/v2-f974e32f6b357030d10663b8ea08aa6d" align="middle">
<img src="https://picx.zhimg.com/v2-61ca6097f1d8a6db94ca4f0632c4d022" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Wonder3D-Cross-domain-Diffusion-for-High-fidelity-3D-Generation-from-a-Single-Image"><a href="#Wonder3D-Cross-domain-Diffusion-for-High-fidelity-3D-Generation-from-a-Single-Image" class="headerlink" title="Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image"></a>Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image</h2><p><strong>Authors:Yuxiao Yang, Xiao-Xiao Long, Zhiyang Dou, Cheng Lin, Yuan Liu, Qingsong Yan, Yuexin Ma, Haoqian Wang, Zhiqiang Wu, Wei Yin</strong></p>
<p>In this work, we introduce \textbf{Wonder3D++}, a novel method for efficiently generating high-fidelity textured meshes from single-view images. Recent methods based on Score Distillation Sampling (SDS) have shown the potential to recover 3D geometry from 2D diffusion priors, but they typically suffer from time-consuming per-shape optimization and inconsistent geometry. In contrast, certain works directly produce 3D information via fast network inferences, but their results are often of low quality and lack geometric details. To holistically improve the quality, consistency, and efficiency of single-view reconstruction tasks, we propose a cross-domain diffusion model that generates multi-view normal maps and the corresponding color images. To ensure the consistency of generation, we employ a multi-view cross-domain attention mechanism that facilitates information exchange across views and modalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that drives high-quality surfaces from the multi-view 2D representations in only about $3$ minute in a coarse-to-fine manner. Our extensive evaluations demonstrate that our method achieves high-quality reconstruction results, robust generalization, and good efficiency compared to prior works. Code available at <a target="_blank" rel="noopener" href="https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus">https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus</a>.</p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†\textbf{Wonder3D++}ï¼Œè¿™æ˜¯ä¸€ç§ä»å•è§†å›¾å›¾åƒé«˜æ•ˆç”Ÿæˆé«˜ä¿çœŸçº¹ç†ç½‘æ ¼çš„æ–°æ–¹æ³•ã€‚æœ€è¿‘åŸºäºScore Distillation Samplingï¼ˆSDSï¼‰çš„æ–¹æ³•å·²æ˜¾ç¤ºå‡ºä»äºŒç»´æ‰©æ•£å…ˆéªŒæ¢å¤ä¸‰ç»´å‡ ä½•çš„æ½œåŠ›ï¼Œä½†å®ƒä»¬é€šå¸¸å—åˆ°è€—æ—¶çš„é’ˆå¯¹å½¢çŠ¶ä¼˜åŒ–å’Œä¸ä¸€è‡´çš„å‡ ä½•å½¢çŠ¶çš„å›°æ‰°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒæŸäº›å·¥ä½œé€šè¿‡å¿«é€Ÿç½‘ç»œæ¨ç†ç›´æ¥äº§ç”Ÿä¸‰ç»´ä¿¡æ¯ï¼Œä½†å…¶ç»“æœå¾€å¾€è´¨é‡è¾ƒä½ï¼Œç¼ºä¹å‡ ä½•ç»†èŠ‚ã€‚ä¸ºäº†å…¨é¢æé«˜å•è§†å›¾é‡å»ºä»»åŠ¡çš„è´¨é‡ã€ä¸€è‡´æ€§å’Œæ•ˆç‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è·¨åŸŸæ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆå¤šè§†å›¾æ³•çº¿è´´å›¾å’Œç›¸åº”çš„å½©è‰²å›¾åƒã€‚ä¸ºç¡®ä¿ç”Ÿæˆçš„è¿è´¯æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§å¤šè§†å›¾è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶ï¼Œä¿ƒè¿›äº†è·¨è§†å›¾å’Œè·¨æ¨¡æ€çš„ä¿¡æ¯äº¤æ¢ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§çº§è”çš„3Dç½‘æ ¼æå–ç®—æ³•ï¼Œè¯¥ç®—æ³•ä»¥ä»ç²—åˆ°ç»†çš„æ–¹å¼ä»…çº¦3åˆ†é’Ÿä»å¤šè§†å›¾äºŒç»´è¡¨ç¤ºä¸­é©±åŠ¨é«˜è´¨é‡è¡¨é¢ã€‚æˆ‘ä»¬çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»¥å‰çš„å·¥ä½œç›¸æ¯”ï¼Œå®ç°äº†é«˜è´¨é‡çš„é‡å»ºç»“æœã€ç¨³å¥çš„æ³›åŒ–èƒ½åŠ›å’Œè‰¯å¥½çš„æ•ˆç‡ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/xxlong">https://github.com/xxlong</a> è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®ä¸»é¡µæŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.01767v2">PDF</a> 21 pages, 19 figures, accepted by TPAMI</p>
<p><strong>Summary</strong><br>     æœ¬å·¥ä½œæ¨å‡ºWonder3D++æ–¹æ³•ï¼Œå¯ä»å•è§†å›¾å›¾åƒé«˜æ•ˆç”Ÿæˆé«˜ä¿çœŸçº¹ç†ç½‘æ ¼ã€‚è¯¥æ–¹æ³•ç»“åˆScore Distillation Samplingï¼ˆSDSï¼‰çš„ä¼˜åŠ¿ï¼Œé€šè¿‡è·¨åŸŸæ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šè§†è§’æ³•çº¿å›¾åŠå¯¹åº”å½©è‰²å›¾åƒï¼Œå¹¶é‡‡ç”¨å¤šè§†è§’è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿ç”Ÿæˆçš„è¿è´¯æ€§ã€‚æœ€åï¼Œé‡‡ç”¨çº§è”çš„3Dç½‘æ ¼æå–ç®—æ³•ï¼Œä»¥ç²—ç»†ç»“åˆçš„æ–¹å¼ä»å¤šè§†è§’2Dè¡¨ç¤ºä¸­å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡è¡¨é¢ï¼Œå®ç°é«˜æ•ˆã€é«˜è´¨é‡çš„é‡å»ºç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Wonder3D++æ˜¯ä¸€ç§ä»å•è§†å›¾å›¾åƒé«˜æ•ˆç”Ÿæˆé«˜ä¿çœŸçº¹ç†ç½‘æ ¼çš„æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆScore Distillation Samplingï¼ˆSDSï¼‰çš„ä¼˜åŠ¿ï¼Œæé«˜äº†3Då‡ ä½•æ¢å¤çš„æ½œåŠ›ã€‚</li>
<li>è·¨åŸŸæ‰©æ•£æ¨¡å‹ç”¨äºç”Ÿæˆå¤šè§†è§’æ³•çº¿å›¾å’Œå½©è‰²å›¾åƒï¼Œç¡®ä¿ç”Ÿæˆçš„è¿è´¯æ€§ã€‚</li>
<li>å¤šè§†è§’è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶çš„åº”ç”¨ä¿ƒè¿›äº†ä¸åŒè§†è§’å’Œæ¨¡æ€ä¹‹é—´çš„ä¿¡æ¯äº¤æµã€‚</li>
<li>é‡‡ç”¨çº§è”çš„3Dç½‘æ ¼æå–ç®—æ³•ï¼Œä»¥ç²—ç»†ç»“åˆçš„æ–¹å¼å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡è¡¨é¢ã€‚</li>
<li>è¯¥æ–¹æ³•çš„é‡å»ºç»“æœå…·æœ‰é«˜è´¨é‡å’Œè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.01767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cb416a1942cfc7bb6010afecdc149ad6" align="middle">
<img src="https://picx.zhimg.com/v2-04bf346657622b3852a6a0932eb652fb" align="middle">
<img src="https://picx.zhimg.com/v2-48721280b800a0aa472098f66a757873" align="middle">
<img src="https://picx.zhimg.com/v2-e491e567d0d1a8f1b40516b6370d818c" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Denoising-weak-lensing-mass-maps-with-diffusion-model-systematic-comparison-with-generative-adversarial-network"><a href="#Denoising-weak-lensing-mass-maps-with-diffusion-model-systematic-comparison-with-generative-adversarial-network" class="headerlink" title="Denoising weak lensing mass maps with diffusion model: systematic comparison with generative adversarial network"></a>Denoising weak lensing mass maps with diffusion model: systematic comparison with generative adversarial network</h2><p><strong>Authors:Shohei D. Aoyama, Ken Osato, Masato Shirasaki</strong></p>
<p>Removing the shape noise from the observed weak lensing field, i.e., denoising, enhances the potential of WL by accessing information at small scales where the shape noise dominates without denoising. We utilise two machine learning (ML) models for denosing: generative adversarial network (GAN) and diffusion model (DM). We evaluate the performance of denosing with GAN and DM utilising the large suite of mock WL observations, which serve as the training and test data sets. We apply denoising to 1,000 noisy mass maps with GAN and DM models trained with 39,000 mock observations. Both models can fairly well reproduce the true convergence map on large scales. Then, we measure cosmological statistics: power spectrum, bispectrum, one-point probability distribution function, peak and minima counts, and scattering transform coefficients. We find that DM outperforms GAN in almost all considered statistics and recovers the correct statistics down to small scales. For example, the angular power spectrum can be recovered with DM up to multipoles $\ell \lesssim 6000$ while the noise power spectrum dominates from $\ell \simeq 2000$. We also conduct stress tests on the trained model; denoising the maps with different characteristics, e.g., different source redshifts, from the training data. The performance degrades at small scales, but the statistics can still be recovered at large scales. Though the training of DM is more computationally demanding compared with GAN, there are several advantages: numerically stable training, higher performance in the reconstruction of cosmological statistics, and sampling multiple realisations once the model is trained. It has been known that DM can generate higher-quality images in real-world problems than GAN, the superiority has been confirmed as well in the WL denoising problem.</p>
<blockquote>
<p>ä»è§‚æµ‹åˆ°çš„å¼±å¼•åŠ›é€é•œåœºå»é™¤å½¢çŠ¶å™ªå£°ï¼Œå³é™å™ªï¼Œå¢å¼ºäº†å¼±å¼•åŠ›é€é•œçš„æ½œåŠ›ã€‚é€šè¿‡è®¿é—®æœªé™å™ªæ—¶å½¢çŠ¶å™ªå£°å ä¸»å¯¼åœ°ä½çš„å°å°ºåº¦ä¿¡æ¯æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬åˆ©ç”¨ä¸¤ç§æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¨¡å‹è¿›è¡Œé™å™ªï¼šç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ã€‚æˆ‘ä»¬åˆ©ç”¨å¤§é‡çš„æ¨¡æ‹Ÿå¼±å¼•åŠ›é€é•œè§‚æµ‹ç»“æœæ¥è¯„ä¼°ä½¿ç”¨GANå’ŒDMè¿›è¡Œé™å™ªçš„æ€§èƒ½ï¼Œè¿™äº›è§‚æµ‹ç»“æœæ—¢ä½œä¸ºè®­ç»ƒæ•°æ®ä¹Ÿä½œä¸ºæµ‹è¯•æ•°æ®ã€‚æˆ‘ä»¬å¯¹1000ä¸ªå¸¦æœ‰å™ªå£°çš„è´¨é‡å›¾åº”ç”¨äº†é™å™ªå¤„ç†ï¼Œè¿™äº›è´¨é‡å›¾ä½¿ç”¨GANå’ŒDMæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒæ•°æ®ä¸º39000ä¸ªæ¨¡æ‹Ÿè§‚æµ‹ç»“æœã€‚è¿™ä¸¤ç§æ¨¡å‹åœ¨å¤§å°ºåº¦ä¸Šéƒ½èƒ½è¾ƒå¥½åœ°å†ç°çœŸå®çš„æ”¶æ•›å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬æµ‹é‡å®‡å®™å­¦ç»Ÿè®¡é‡ï¼šåŠŸç‡è°±ã€åŒè°±ã€ä¸€ç‚¹æ¦‚ç‡åˆ†å¸ƒå‡½æ•°ã€å³°å’Œè°·å€¼è®¡æ•°ä»¥åŠæ•£å°„å˜æ¢ç³»æ•°ã€‚æˆ‘ä»¬å‘ç°DMåœ¨å‡ ä¹æ‰€æœ‰çš„ç»Ÿè®¡é‡ä¸Šéƒ½ä¼˜äºGANï¼Œå¹¶èƒ½æ¢å¤åˆ°å°å°ºåº¦çš„æ­£ç¡®ç»Ÿè®¡é‡ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨DMå¯ä»¥æ¢å¤åˆ°å¤šé‡è§’Î»â‰ˆ6000çš„è§’åŠŸç‡è°±ï¼Œè€Œå™ªå£°åŠŸç‡è°±åˆ™ä»Î»â‰ˆ2000å¼€å§‹å ä¸»å¯¼åœ°ä½ã€‚æˆ‘ä»¬è¿˜å¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œäº†å‹åŠ›æµ‹è¯•ï¼Œå³å¯¹å…·æœ‰ä¸åŒç‰¹æ€§çš„åœ°å›¾è¿›è¡Œé™å™ªï¼Œä¾‹å¦‚ä¸è®­ç»ƒæ•°æ®ä¸åŒçš„æºçº¢ç§»ã€‚è™½ç„¶åœ¨å°å°ºåº¦ä¸Šçš„æ€§èƒ½æœ‰æ‰€ä¸‹é™ï¼Œä½†åœ¨å¤§å°ºåº¦ä¸Šä»ç„¶å¯ä»¥æ¢å¤ç»Ÿè®¡é‡ã€‚å°½ç®¡ä¸GANç›¸æ¯”ï¼ŒDMçš„è®­ç»ƒè®¡ç®—éœ€æ±‚æ›´å¤§ï¼Œä½†DMæœ‰å‡ ä¸ªä¼˜åŠ¿ï¼šæ•°å€¼ç¨³å®šçš„è®­ç»ƒã€åœ¨é‡å»ºå®‡å®™å­¦ç»Ÿè®¡é‡æ–¹é¢æ€§èƒ½æ›´é«˜ã€ä¸€æ—¦æ¨¡å‹è®­ç»ƒå®Œæˆå°±å¯ä»¥è¿›è¡Œå¤šæ¬¡é‡‡æ ·å®ç°ã€‚å·²çŸ¥DMåœ¨ç°å®ä¸–ç•Œçš„é—®é¢˜ä¸­å¯ä»¥ç”Ÿæˆæ¯”GANæ›´é«˜è´¨é‡çš„å›¾åƒï¼Œå…¶åœ¨å¼±å¼•åŠ›é€é•œé™å™ªé—®é¢˜ä¸Šçš„ä¼˜è¶Šæ€§ä¹Ÿå¾—åˆ°äº†è¯å®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00345v2">PDF</a> Submitted to PASJ, 18 pages, 19 figures, 5 tables</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰è¿›è¡Œå¼±å¼•åŠ›é€é•œè§‚æµ‹æ•°æ®é™å™ªï¼Œå¯ä»¥æé«˜WLçš„æ½œåŠ›ã€‚åœ¨æ¨¡æ‹Ÿå¼±å¼•åŠ›é€é•œè§‚æµ‹æ•°æ®çš„å¤§è§„æ¨¡æµ‹è¯•ä¸­ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å‡ ä¹æ‰€æœ‰è€ƒè™‘çš„ç»Ÿè®¡ç‰¹å¾ä¸Šéƒ½ä¼˜äºGANï¼Œå¹¶ä¸”åœ¨è¾ƒå°çš„å°ºåº¦ä¸Šæ¢å¤äº†æ­£ç¡®çš„ç»Ÿè®¡ç‰¹å¾ã€‚å°½ç®¡DMè®­ç»ƒç›¸å¯¹æ›´è€—æ—¶ï¼Œä½†å®ƒåœ¨æ•°å€¼ç¨³å®šæ€§æ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œå¹¶å±•ç°å‡ºæ›´é«˜æ€§èƒ½çš„å®‡å®™å­¦ç»Ÿè®¡é‡å»ºèƒ½åŠ›ï¼Œè€Œä¸”ä¸€æ—¦æ¨¡å‹è®­ç»ƒå®Œæˆå³å¯é‡‡æ ·å¤šä¸ªå®ç°ã€‚å·²çŸ¥DMåœ¨ç°å®é—®é¢˜çš„å›¾åƒç”Ÿæˆä¸­è´¨é‡é«˜äºGANï¼Œå…¶åœ¨å¼±å¼•åŠ›é€é•œæ¶ˆå™ªé—®é¢˜ä¸­çš„ä¼˜è¶Šæ€§ä¹Ÿå¾—åˆ°äº†è¯å®ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>é€šè¿‡å»é™¤å¼±å¼•åŠ›é€é•œè§‚æµ‹æ•°æ®ä¸­çš„å½¢çŠ¶å™ªå£°ï¼ˆå³é™å™ªï¼‰ï¼Œå¯ä»¥è®¿é—®å°å°ºåº¦ä¸Šçš„ä¿¡æ¯ï¼Œä»è€Œæé«˜å¼±å¼•åŠ›é€é•œçš„æ½œåŠ›ã€‚</li>
<li>ä½¿ç”¨äº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ä¸¤ç§æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œé™å™ªã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿå¼±å¼•åŠ›é€é•œè§‚æµ‹æ•°æ®çš„æµ‹è¯•ä¸­ï¼Œè¯„ä¼°äº†GANå’ŒDMçš„é™å™ªæ€§èƒ½ã€‚</li>
<li>åœ¨å¤„ç†å¸¦æœ‰å„ç§ç‰¹æ€§çš„åœ°å›¾æ—¶ï¼ˆä¾‹å¦‚ä¸åŒçš„æºçº¢ç§»ï¼‰ï¼Œè™½ç„¶æ€§èƒ½æœ‰æ‰€ä¸‹é™ï¼Œä½†DMä»ç„¶èƒ½å¤Ÿåœ¨å¤§å°ºåº¦ä¸Šæ¢å¤ç»Ÿè®¡æ•°æ®ã€‚è¿™æ„å‘³ç€DMåœ¨å¤„ç†ä¸åŒç±»å‹çš„å™ªå£°æ–¹é¢è¡¨ç°å‡ºä¸€å®šçš„ç¨³å¥æ€§ã€‚ç„¶è€Œæ€§èƒ½æœ‰æ‰€é€€åŒ–ä»éœ€è¦åœ¨åç»­ç ”ç©¶ä¸­è¿›è¡Œä¼˜åŒ–æ”¹è¿›ã€‚è¿™è¡¨æ˜è¿™ä¸¤ç§æ–¹æ³•éƒ½æœ‰æ½œåœ¨çš„æ”¹è¿›ç©ºé—´ã€‚å› æ­¤åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©æœ€é€‚åˆçš„æ–¹æ³•ã€‚åœ¨é™å™ªè¿‡ç¨‹ä¸­å¯èƒ½éœ€è¦æ ¹æ®åœ°å›¾çš„ç‰¹æ€§è¿›è¡Œé’ˆå¯¹æ€§çš„è°ƒæ•´å’Œä¼˜åŒ–ä»¥æé«˜æ€§èƒ½ã€‚å› æ­¤å®é™…åº”ç”¨ä¸­éœ€è¦è€ƒè™‘åˆ°è¿™ä¸€ç‚¹å¹¶è¿›è¡Œç›¸åº”çš„ä¼˜åŒ–å·¥ä½œã€‚å°½ç®¡å¦‚æ­¤DMåœ¨æ•°å€¼ç¨³å®šæ€§æ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿å¹¶ä¸”åœ¨é‡å»ºå®‡å®™å­¦ç»Ÿè®¡ç‰¹å¾æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½èƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒåœ¨å¼±å¼•åŠ›é€é•œæ¶ˆå™ªé—®é¢˜ä¸­æ˜¾ç¤ºå‡ºä¼˜è¶Šæ€§ä¹Ÿéœ€è¦åœ¨åç»­ç ”ç©¶ä¸­æŒç»­ä¼˜åŒ–å’Œæ”¹è¿›æ¨¡å‹çš„æ€§èƒ½ä»¥ä¾¿æ›´å¥½åœ°æ»¡è¶³å®é™…éœ€æ±‚è§£å†³ç°å®é—®é¢˜ä»¥å®ç°æ›´å‡†ç¡®å’Œå¯é çš„å¼±å¼•åŠ›é€é•œè§‚æµ‹æ•°æ®åˆ†æã€‚æ€»ä½“æ¥è¯´è™½ç„¶DMç›¸è¾ƒäºGANæœ‰ä¸€å®šçš„ä¼˜åŠ¿ä½†ä»éœ€è¦æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œä¼˜åŒ–å’Œæ”¹è¿›ä»¥å®ç°æœ€ä½³çš„é™å™ªæ•ˆæœå’Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»¥ä¾¿æ›´å¥½åœ°åº”ç”¨äºå®é™…é—®é¢˜ä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00345">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ca689a4a337893db4d293875dec55d66" align="middle">
<img src="https://picx.zhimg.com/v2-4c617e74d30c69a116b534560fdbca74" align="middle">
<img src="https://picx.zhimg.com/v2-8393079b2b3ceb73e53841bf66309fa1" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Adaptive-Diffusion-Models-for-Sparse-View-Motion-Corrected-Head-Cone-beam-CT"><a href="#Adaptive-Diffusion-Models-for-Sparse-View-Motion-Corrected-Head-Cone-beam-CT" class="headerlink" title="Adaptive Diffusion Models for Sparse-View Motion-Corrected Head Cone-beam CT"></a>Adaptive Diffusion Models for Sparse-View Motion-Corrected Head Cone-beam CT</h2><p><strong>Authors:Antoine De Paepe, Alexandre Bousse, ClÃ©mentine Phung-Ngoc, Youness Mellak, Dimitris Visvikis</strong></p>
<p>Cone-beam computed tomography (CBCT) is an imaging modality widely used in head and neck diagnostics due to its accessibility and lower radiation dose. However, its relatively long acquisition times make it susceptible to patient motion, especially under sparse-view settings used to reduce dose, which can result in severe image artifacts. In this work, we propose a novel framework, joint reconstruction and motion estimation (JRM) with adaptive diffusion model (ADM), that simultaneously addresses motion compensation and sparse-view reconstruction in head CBCT. Leveraging recent advances in diffusion-based generative models, our method integrates a wavelet-domain diffusion prior into an iterative reconstruction pipeline to guide the solution toward anatomically plausible volumes while estimating rigid motion parameters in a blind fashion. We evaluate our method on simulated motion-affected CBCT data derived from real clinical computed tomography (CT) volumes. Experimental results demonstrate that JRM- ADM achieves consistent quantitative improvements over both traditional and learning-based baselines. In highly undersampled cases, JRM-ADM improves peak signal-to-noise ratio (PSNR) by more than 4 dB and structural similarity index measure (SSIM) by 0.10 compared to baseline the motion-corrected (MC) reconstruction method. These results highlight the potential of our approach to enable motion-robust and low-dose CBCT imaging, paving the way for improved clinical viability. The project page is available at <a target="_blank" rel="noopener" href="https://antoinedepaepe.github.io/jrm-adm-io/">https://antoinedepaepe.github.io/jrm-adm-io/</a>.</p>
<blockquote>
<p>é”¥æŸè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCBCTï¼‰æ˜¯ä¸€ç§åœ¨å¤´éƒ¨å’Œé¢ˆéƒ¨è¯Šæ–­ä¸­å¹¿æ³›ä½¿ç”¨çš„æˆåƒæ–¹å¼ï¼Œå› å…¶å¯åŠæ€§å’Œè¾ƒä½çš„è¾å°„å‰‚é‡è€Œå—åˆ°æ¬¢è¿ã€‚ç„¶è€Œï¼Œå…¶ç›¸å¯¹è¾ƒé•¿çš„é‡‡é›†æ—¶é—´ä½¿å…¶å®¹æ˜“å—åˆ°æ‚£è€…è¿åŠ¨çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”¨äºå‡å°‘å‰‚é‡çš„ç¨€ç–è§†å›¾è®¾ç½®ä¸‹ï¼Œå¯èƒ½å¯¼è‡´ä¸¥é‡çš„å›¾åƒä¼ªå½±ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œå³è”åˆé‡å»ºå’ŒåŠ¨æ€ä¼°è®¡ï¼ˆJRMï¼‰ä¸è‡ªé€‚åº”æ‰©æ•£æ¨¡å‹ï¼ˆADMï¼‰ï¼Œè¯¥æ¡†æ¶å¯ä»¥åŒæ—¶è§£å†³å¤´éƒ¨CBCTä¸­çš„è¿åŠ¨è¡¥å¿å’Œç¨€ç–è§†å›¾é‡å»ºé—®é¢˜ã€‚åˆ©ç”¨åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†å°æ³¢åŸŸæ‰©æ•£å…ˆéªŒçŸ¥è¯†é›†æˆåˆ°è¿­ä»£é‡å»ºæµç¨‹ä¸­ï¼Œä»¥å‘è§£å‰–ä¸Šåˆç†çš„ä½“ç§¯å¼•å¯¼è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶ä»¥ç›²æ€ä¼°è®¡åˆšä½“è¿åŠ¨å‚æ•°ã€‚æˆ‘ä»¬åœ¨ä»çœŸå®çš„ä¸´åºŠè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä½“ç§¯æ´¾ç”Ÿçš„æ¨¡æ‹Ÿè¿åŠ¨å½±å“CBCTæ•°æ®ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºäºä¼ ç»Ÿå’Œå­¦ä¹ çš„åŸºçº¿ç›¸æ¯”ï¼ŒJRM-ADMæŒç»­å®ç°äº†å®šé‡æ”¹è¿›ã€‚åœ¨é«˜åº¦æ¬ é‡‡æ ·çš„æƒ…å†µä¸‹ï¼Œä¸åŸºäºè¿åŠ¨çš„æ ¡æ­£ï¼ˆMCï¼‰é‡å»ºæ–¹æ³•ç›¸æ¯”ï¼ŒJRM-ADMçš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æé«˜äº†è¶…è¿‡4åˆ†è´ï¼Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼‰æé«˜äº†0.10ã€‚è¿™äº›ç»“æœçªå‡ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®ç°ç¨³å¥è¿åŠ¨å’Œä½å‰‚é‡CBCTæˆåƒæ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºæ”¹å–„ä¸´åºŠå¯è¡Œæ€§é“ºå¹³äº†é“è·¯ã€‚é¡¹ç›®é¡µé¢å¯åœ¨[<a target="_blank" rel="noopener" href="https://antoinedepaepe.github.io/jrm-adm-io/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://antoinedepaepe.github.io/jrm-adm-io/]ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14033v6">PDF</a> 12 pages, 10 figures, 2 table4</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè”åˆé‡å»ºå’Œè¿åŠ¨ä¼°è®¡ï¼ˆJRMï¼‰ä¸è‡ªé€‚åº”æ‰©æ•£æ¨¡å‹ï¼ˆADMï¼‰çš„æ–°æ¡†æ¶ï¼Œç”¨äºè§£å†³å¤´éƒ¨é”¥å½¢æŸè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCBCTï¼‰ä¸­çš„è¿åŠ¨è¡¥å¿å’Œç¨€ç–è§†å›¾é‡å»ºé—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼Œå°†å°æ³¢åŸŸæ‰©æ•£å…ˆéªŒé›†æˆåˆ°è¿­ä»£é‡å»ºç®¡é“ä¸­ï¼Œä»¥å¼•å¯¼è§£å†³æ–¹æ¡ˆæœå‘è§£å‰–ä¸Šåˆç†çš„ä½“ç§¯ï¼ŒåŒæ—¶ä»¥ç›²çš„æ–¹å¼ä¼°è®¡åˆšä½“è¿åŠ¨å‚æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒJRM-ADMç›¸è¾ƒäºä¼ ç»Ÿå’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨æ¨¡æ‹Ÿè¿åŠ¨å½±å“çš„CBCTæ•°æ®ä¸Šå®ç°äº†æŒç»­çš„å®šé‡æ”¹è¿›ã€‚åœ¨é«˜åº¦æ¬ é‡‡æ ·çš„æƒ…å†µä¸‹ï¼Œä¸åŸºäºè¿åŠ¨çš„æ ¡æ­£ï¼ˆMCï¼‰é‡å»ºæ–¹æ³•ç›¸æ¯”ï¼ŒJRM-ADMçš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æé«˜äº†è¶…è¿‡4åˆ†è´ï¼Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼‰æé«˜äº†0.1ã€‚è¿™ä¸ºè¿åŠ¨é²æ£’å’Œä½å‰‚é‡CBCTæˆåƒçš„å®ç°æä¾›äº†æ½œåŠ›ï¼Œä¸ºæé«˜ä¸´åºŠå¯è¡Œæ€§é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CBCTåœ¨å¤´é¢ˆè¯Šæ–­ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å…¶è¾ƒé•¿çš„é‡‡é›†æ—¶é—´æ˜“å—åˆ°æ‚£è€…è¿åŠ¨çš„å½±å“ï¼Œå¯¼è‡´å›¾åƒå‡ºç°ä¸¥é‡ä¼ªå½±ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªåä¸ºJRM-ADMçš„æ–°æ¡†æ¶ï¼ŒåŒæ—¶è§£å†³è¿åŠ¨è¡¥å¿å’Œç¨€ç–è§†å›¾é‡å»ºé—®é¢˜ã€‚</li>
<li>åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå°æ³¢åŸŸæ‰©æ•£å…ˆéªŒï¼Œå°†å…¶é›†æˆåˆ°è¿­ä»£é‡å»ºç®¡é“ä¸­ã€‚</li>
<li>JRM-ADMæ–¹æ³•èƒ½å¼•å¯¼è§£å†³æ–¹æ¡ˆå‘è§£å‰–ä¸Šåˆç†çš„ä½“ç§¯å‘å±•ï¼Œå¹¶ç›²ä¼°åˆšä½“è¿åŠ¨å‚æ•°ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒJRM-ADMåœ¨æ¨¡æ‹Ÿè¿åŠ¨å½±å“çš„CBCTæ•°æ®ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿå’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•ã€‚</li>
<li>åœ¨é«˜åº¦æ¬ é‡‡æ ·æƒ…å†µä¸‹ï¼ŒJRM-ADMçš„PSNRå’ŒSSIMæŒ‡æ ‡ç›¸è¾ƒäºè¿åŠ¨æ ¡æ­£æ–¹æ³•æœ‰æ˜æ˜¾æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14033">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0114ad3189aeb117fb7760dfd04cbe7" align="middle">
<img src="https://picx.zhimg.com/v2-b0fdbbf07617e161809721827e29877d" align="middle">
<img src="https://picx.zhimg.com/v2-69db05d8cc633d03802c363f73feee6e" align="middle">
<img src="https://picx.zhimg.com/v2-1269658bd0ae7604a8bd4e93159602b2" align="middle">
<img src="https://picx.zhimg.com/v2-1c8f93baa4d581ef74ab753a8cb0589c" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Other-Vehicle-Trajectories-Are-Also-Needed-A-Driving-World-Model-Unifies-Ego-Other-Vehicle-Trajectories-in-Video-Latent-Space"><a href="#Other-Vehicle-Trajectories-Are-Also-Needed-A-Driving-World-Model-Unifies-Ego-Other-Vehicle-Trajectories-in-Video-Latent-Space" class="headerlink" title="Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space"></a>Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space</h2><p><strong>Authors:Jian Zhu, Zhengyu Jia, Tian Gao, Jiaxin Deng, Shidi Li, Lang Zhang, Fu Liu, Peng Jia, Xianpeng Lang</strong></p>
<p>Advanced end-to-end autonomous driving systems predict other vehiclesâ€™ motions and plan ego vehicleâ€™s trajectory. The world model that can foresee the outcome of the trajectory has been used to evaluate the autonomous driving system. However, existing world models predominantly emphasize the trajectory of the ego vehicle and leave other vehicles uncontrollable. This limitation hinders their ability to realistically simulate the interaction between the ego vehicle and the driving scenario. In this paper, we propose a driving World Model named EOT-WM, unifying Ego-Other vehicle Trajectories in videos for driving simulation. Specifically, it remains a challenge to match multiple trajectories in the BEV space with each vehicle in the video to control the video generation. We first project ego-other vehicle trajectories in the BEV space into the image coordinate for vehicle-trajectory match via pixel positions. Then, trajectory videos are encoded by the Spatial-Temporal Variational Auto Encoder to align with driving video latents spatially and temporally in the unified visual space. A trajectory-injected diffusion Transformer is further designed to denoise the noisy video latents for video generation with the guidance of ego-other vehicle trajectories. In addition, we propose a metric based on control latent similarity to evaluate the controllability of trajectories. Extensive experiments are conducted on the nuScenes dataset, and the proposed model outperforms the state-of-the-art method by 30% in FID and 55% in FVD. The model can also predict unseen driving scenes with self-produced trajectories.</p>
<blockquote>
<p>é«˜çº§ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿèƒ½å¤Ÿé¢„æµ‹å…¶ä»–è½¦è¾†çš„è¡Œé©¶è½¨è¿¹å¹¶è§„åˆ’è‡ªèº«è½¦è¾†çš„è¡Œé©¶è½¨è¿¹ã€‚èƒ½å¤Ÿé¢„æµ‹è½¨è¿¹ç»“æœçš„å…¨çƒæ¨¡å‹å·²ç»è¢«ç”¨æ¥è¯„ä¼°è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¸–ç•Œæ¨¡å‹ä¸»è¦å…³æ³¨è‡ªèº«è½¦è¾†çš„è½¨è¿¹ï¼Œè€Œå¿½ç•¥å¯¹å…¶ä»–è½¦è¾†çš„æ“æ§ã€‚è¿™ä¸€å±€é™é˜»ç¢äº†å®ƒä»¬çœŸå®æ¨¡æ‹Ÿè‡ªèº«è½¦è¾†ä¸é©¾é©¶åœºæ™¯ä¹‹é—´äº’åŠ¨çš„èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºEOT-WMçš„é©¾é©¶ä¸–ç•Œæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»Ÿä¸€äº†è§†é¢‘ä¸­è‡ªèº«è½¦è¾†ä¸å…¶ä»–è½¦è¾†çš„è½¨è¿¹ï¼Œç”¨äºé©¾é©¶æ¨¡æ‹Ÿã€‚å…·ä½“æ¥è¯´ï¼Œå°†é¸Ÿç°ç©ºé—´ä¸­çš„å¤šæ¡è½¨è¿¹ä¸è§†é¢‘ä¸­çš„æ¯è¾†è½¦ç›¸åŒ¹é…ä»¥æ§åˆ¶è§†é¢‘ç”Ÿæˆä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬é¦–å…ˆå°†åœ¨é¸Ÿç°ç©ºé—´ä¸­çš„è‡ªèº«è½¦è¾†å’Œå…¶ä»–è½¦è¾†è½¨è¿¹æŠ•å½±åˆ°å›¾åƒåæ ‡ä¸­ï¼Œé€šè¿‡åƒç´ ä½ç½®è¿›è¡Œè½¦è¾†è½¨è¿¹åŒ¹é…ã€‚ç„¶åï¼Œä½¿ç”¨æ—¶ç©ºå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨å¯¹è½¨è¿¹è§†é¢‘è¿›è¡Œç¼–ç ï¼Œä½¿å…¶åœ¨ç»Ÿä¸€è§†è§‰ç©ºé—´ä¸­ä¸é©¾é©¶è§†é¢‘æ½œåœ¨å˜é‡åœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šå¯¹é½ã€‚è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ä¸ªè½¨è¿¹æ³¨å…¥æ‰©æ•£Transformerï¼Œå¯¹å¸¦æœ‰å™ªå£°çš„è§†é¢‘æ½œåœ¨å˜é‡è¿›è¡Œå»å™ªï¼Œä»¥åœ¨è‡ªèº«è½¦è¾†å’Œå…¶ä»–è½¦è¾†è½¨è¿¹çš„æŒ‡å¯¼ä¸‹ç”Ÿæˆè§†é¢‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ§åˆ¶æ½œåœ¨å˜é‡ç›¸ä¼¼æ€§çš„æŒ‡æ ‡æ¥è¯„ä¼°è½¨è¿¹çš„å¯æ§æ€§ã€‚åœ¨nuScenesæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œæ‰€æå‡ºæ¨¡å‹çš„FIDå¾—åˆ†æ¯”æœ€æ–°æŠ€æœ¯é«˜å‡º30%ï¼ŒFVDå¾—åˆ†é«˜å‡º55%ã€‚è¯¥æ¨¡å‹è¿˜å¯ä»¥é¢„æµ‹æœªè§è¿‡çš„é©¾é©¶åœºæ™¯å¹¶ç”Ÿæˆè‡ªèº«è½¦è¾†çš„è½¨è¿¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09215v4">PDF</a> 8 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºEOT-WMçš„é©¾é©¶ä¸–ç•Œæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»Ÿä¸€äº†è‡ªæˆ‘è½¦è¾†å’Œå…¶ä»–è½¦è¾†çš„è½¨è¿¹ï¼Œç”¨äºé©¾é©¶æ¨¡æ‹Ÿã€‚é€šè¿‡æŠ•å½±è½¦è¾†åœ¨é¸Ÿç°ç©ºé—´ä¸­çš„è½¨è¿¹åˆ°å›¾åƒåæ ‡è¿›è¡ŒåŒ¹é…ï¼Œå¹¶ä½¿ç”¨æ—¶ç©ºå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨å¯¹è½¨è¿¹è§†é¢‘è¿›è¡Œç¼–ç ã€‚è®¾è®¡äº†ä¸€ä¸ªè½¨è¿¹æ³¨å…¥æ‰©æ•£Transformerï¼Œç”¨äºå»å™ªè§†é¢‘æ½œåœ¨è¡¨ç¤ºï¼Œä»¥ç”Ÿæˆå—è‡ªæˆ‘è½¦è¾†å’Œå…¶ä»–è½¦è¾†è½¨è¿¹æŒ‡å¯¼çš„è§†é¢‘ã€‚åŒæ—¶ï¼Œæå‡ºäº†åŸºäºæ§åˆ¶æ½œåœ¨ç›¸ä¼¼æ€§åº¦é‡çš„è¯„ä»·æŒ‡æ ‡ã€‚åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨FIDå’ŒFVDæŒ‡æ ‡ä¸Šåˆ†åˆ«ä¼˜äºç°æœ‰æŠ€æœ¯30%å’Œ55%ã€‚è¯¥æ¨¡å‹å¯é¢„æµ‹å…·æœ‰è‡ªæˆ‘ç”Ÿæˆè½¨è¿¹çš„æœªè§é©¾é©¶åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EOT-WMæ¨¡å‹ç»Ÿä¸€äº†è‡ªæˆ‘è½¦è¾†å’Œå…¶ä»–è½¦è¾†çš„è½¨è¿¹ï¼Œå¢å¼ºäº†é©¾é©¶æ¨¡æ‹Ÿçš„çœŸå®æ€§ã€‚</li>
<li>é€šè¿‡æŠ•å½±è½¦è¾†åœ¨é¸Ÿç°ç©ºé—´ä¸­çš„è½¨è¿¹åˆ°å›¾åƒåæ ‡è¿›è¡ŒåŒ¹é…ã€‚</li>
<li>ä½¿ç”¨æ—¶ç©ºå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨å¯¹è½¨è¿¹è§†é¢‘è¿›è¡Œç¼–ç ï¼Œä¸é©¾é©¶è§†é¢‘æ½œåœ¨è¡¨ç¤ºè¿›è¡Œå¯¹é½ã€‚</li>
<li>è®¾è®¡äº†è½¨è¿¹æ³¨å…¥æ‰©æ•£Transformerï¼Œç”¨äºå»å™ªè§†é¢‘æ½œåœ¨è¡¨ç¤ºï¼Œç”Ÿæˆå—è½¨è¿¹æŒ‡å¯¼çš„è§†é¢‘ã€‚</li>
<li>æå‡ºäº†åŸºäºæ§åˆ¶æ½œåœ¨ç›¸ä¼¼æ€§åº¦é‡çš„è¯„ä»·æŒ‡æ ‡æ¥è¯„ä¼°è½¨è¿¹çš„å¯æ§æ€§ã€‚</li>
<li>åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨FIDå’ŒFVDæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09215">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c85ec8f4ae751b2b42e7db5526b9a80" align="middle">
<img src="https://picx.zhimg.com/v2-d506f18870590a27c46bc74fc114f75a" align="middle">
<img src="https://picx.zhimg.com/v2-bb666d7b4be2452791160fe9338e9321" align="middle">
<img src="https://picx.zhimg.com/v2-02b33f92d6dca1359686027ecef9e8e2" align="middle">
<img src="https://picx.zhimg.com/v2-3f15a26721daa93c0f6a548723ef8950" align="middle">
<img src="https://picx.zhimg.com/v2-20eead1c57effb34b00feaadf6f05e61" align="middle">
<img src="https://picx.zhimg.com/v2-97a20e3a3c764094ff69b3aa7d8d1122" align="middle">
<img src="https://picx.zhimg.com/v2-c1328607098d89ec00b51d4f6f5f3204" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="RN-SDEs-Limited-Angle-CT-Reconstruction-with-Residual-Null-Space-Diffusion-Stochastic-Differential-Equations"><a href="#RN-SDEs-Limited-Angle-CT-Reconstruction-with-Residual-Null-Space-Diffusion-Stochastic-Differential-Equations" class="headerlink" title="RN-SDEs: Limited-Angle CT Reconstruction with Residual Null-Space Diffusion Stochastic Differential Equations"></a>RN-SDEs: Limited-Angle CT Reconstruction with Residual Null-Space Diffusion Stochastic Differential Equations</h2><p><strong>Authors:Jiaqi Guo, Santiago Lopez-Tapia, Wing Shun Li, Yunnan Wu, Marcelo Carignano, Martin KrÃ¶ger, Vinayak P. Dravid, Igal Szleifer, Vadim Backman, Aggelos K. Katsaggelos</strong></p>
<p>Computed tomography is a widely used imaging modality with applications ranging from medical imaging to material analysis. One major challenge arises from the lack of scanning information at certain angles, leading to distorted CT images with artifacts. This results in an ill-posed problem known as the Limited Angle Computed Tomography (LACT) reconstruction problem. To address this problem, we propose Residual Null-Space Diffusion Stochastic Differential Equations (RN-SDEs), which are a variant of diffusion models that characterize the diffusion process with mean-reverting (MR) stochastic differential equations. To demonstrate the generalizability of RN-SDEs, our experiments are conducted on two different LACT datasets, i.e., ChromSTEM and C4KC-KiTS. Through extensive experiments, we show that by leveraging learned Mean-Reverting SDEs as a prior and emphasizing data consistency using Range-Null Space Decomposition (RNSD) based rectification, RN-SDEs can restore high-quality images from severe degradation and achieve state-of-the-art performance in most LACT tasks. Additionally, we present a quantitative comparison of computational complexity and runtime efficiency, highlighting the superior effectiveness of our proposed approach.</p>
<blockquote>
<p>è®¡ç®—æœºæ–­å±‚æ‰«ææ˜¯ä¸€ç§å¹¿æ³›åº”ç”¨äºæˆåƒçš„æŠ€æœ¯ï¼Œå…¶åº”ç”¨èŒƒå›´ä»åŒ»å­¦å½±åƒåˆ°ææ–™åˆ†æéƒ½æœ‰æ¶‰åŠã€‚ç„¶è€Œï¼Œä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ¥è‡ªäºæŸäº›è§’åº¦æ‰«æä¿¡æ¯çš„ç¼ºå¤±ï¼Œå¯¼è‡´è®¡ç®—æœºæ–­å±‚æ‰«æå›¾åƒå¤±çœŸå¹¶å‡ºç°ä¼ªå½±ã€‚è¿™å¯¼è‡´äº†ä¸€ä¸ªè¢«ç§°ä¸ºæœ‰é™è§’åº¦è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆLACTï¼‰é‡å»ºé—®é¢˜çš„ä¸é€‚å®šé—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ®‹å·®é›¶ç©ºé—´æ‰©æ•£éšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆRN-SDEsï¼‰ï¼Œå®ƒæ˜¯æ‰©æ•£æ¨¡å‹çš„ä¸€ç§å˜ä½“ï¼Œç”¨å‡å€¼å›å¤ï¼ˆMRï¼‰éšæœºå¾®åˆ†æ–¹ç¨‹æ¥è¡¨å¾æ‰©æ•£è¿‡ç¨‹ã€‚ä¸ºäº†å±•ç¤ºRN-SDEsçš„é€šç”¨æ€§ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªä¸åŒçš„LACTæ•°æ®é›†ï¼ˆå³ChromSTEMå’ŒC4KC-KiTSï¼‰ä¸Šè¿›è¡Œäº†å®éªŒã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†åˆ©ç”¨å­¦ä¹ å¾—åˆ°çš„å‡å€¼å›å¤SDEsä½œä¸ºå…ˆéªŒï¼Œå¹¶é€šè¿‡åŸºäºèŒƒå›´é›¶ç©ºé—´åˆ†è§£ï¼ˆRNSDï¼‰çš„ä¿®æ­£æ¥å¼ºè°ƒæ•°æ®ä¸€è‡´æ€§ï¼ŒRN-SDEså¯ä»¥ä»ä¸¥é‡é€€åŒ–çš„å›¾åƒä¸­æ¢å¤é«˜è´¨é‡å›¾åƒï¼Œå¹¶åœ¨å¤§å¤šæ•°LACTä»»åŠ¡ä¸­å®ç°æœ€ä½³æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯¹è®¡ç®—å¤æ‚åº¦å’Œè¿è¡Œæ•ˆç‡è¿›è¡Œäº†å®šé‡æ¯”è¾ƒï¼Œçªå‡ºäº†æˆ‘ä»¬æå‡ºæ–¹æ³•çš„å“è¶Šæœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.13930v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºè®¡ç®—å±‚ææˆåƒï¼ˆCTï¼‰åœ¨åŒ»ç–—æˆåƒå’Œææ–™åˆ†æç­‰é¢†åŸŸå¹¿æ³›åº”ç”¨çš„åŒæ—¶ï¼Œå…¶æœ‰é™è§’åº¦è®¡ç®—å±‚ææˆåƒï¼ˆLACTï¼‰é‡å»ºé—®é¢˜ä¸­çš„å›¾åƒå¤±çœŸå’Œä¼ªå½±é—®é¢˜æ—¥ç›Šå‡¸æ˜¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºæ®‹å·®é›¶ç©ºé—´æ‰©æ•£éšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆRN-SDEsï¼‰çš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å­¦ä¹ å’Œåˆ©ç”¨å‡å€¼å›å½’ï¼ˆMRï¼‰éšæœºå¾®åˆ†æ–¹ç¨‹æ¥æè¿°æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶ç»“åˆèŒƒå›´é›¶ç©ºé—´åˆ†è§£ï¼ˆRNSDï¼‰ä¿®æ­£æŠ€æœ¯ï¼ŒRN-SDEså¯åœ¨ä¸¥é‡é™è´¨çš„æƒ…å†µä¸‹æ¢å¤é«˜è´¨é‡å›¾åƒï¼Œå¹¶åœ¨å¤§å¤šæ•°LACTä»»åŠ¡ä¸­å®ç°æœ€ä½³æ€§èƒ½ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜å¯¹æ¯”äº†è®¡ç®—å¤æ‚åº¦å’Œè¿è¡Œæ•ˆç‡ï¼Œçªæ˜¾äº†æ‰€ææ–¹æ³•çš„é«˜æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¡ç®—å±‚ææˆåƒï¼ˆCTï¼‰å­˜åœ¨æœ‰é™è§’åº¦é—®é¢˜ï¼Œå¯¼è‡´å›¾åƒå¤±çœŸå’Œä¼ªå½±ã€‚</li>
<li>æå‡ºåŸºäºæ®‹å·®é›¶ç©ºé—´æ‰©æ•£éšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆRN-SDEsï¼‰çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>RN-SDEsåˆ©ç”¨å‡å€¼å›å½’ï¼ˆMRï¼‰éšæœºå¾®åˆ†æ–¹ç¨‹æè¿°æ‰©æ•£è¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡èŒƒå›´é›¶ç©ºé—´åˆ†è§£ï¼ˆRNSDï¼‰ä¿®æ­£æŠ€æœ¯ï¼ŒRN-SDEsèƒ½åœ¨ä¸¥é‡é™è´¨æƒ…å†µä¸‹æ¢å¤é«˜è´¨é‡å›¾åƒã€‚</li>
<li>RN-SDEsåœ¨å¤§å¤šæ•°æœ‰é™è§’åº¦è®¡ç®—å±‚ææˆåƒï¼ˆLACTï¼‰ä»»åŠ¡ä¸­å®ç°æœ€ä½³æ€§èƒ½ã€‚</li>
<li>ç›¸æ¯”å…¶ä»–æ–¹æ³•ï¼ŒRN-SDEså…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡å’Œè¿è¡Œæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.13930">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3b8ed099dcc3f742c9304e17415e7649" align="middle">
<img src="https://picx.zhimg.com/v2-372294e3ac6981e06fe75752438c72a5" align="middle">
<img src="https://picx.zhimg.com/v2-ac7e7f2fdff15ad2b9fbb512a01036fb" align="middle">
<img src="https://picx.zhimg.com/v2-d635f30f84991f104263974057f35815" align="middle">
<img src="https://picx.zhimg.com/v2-62c42e7a768a222be2a80191029fe48e" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Detecting-Out-of-Distribution-Objects-through-Class-Conditioned-Inpainting"><a href="#Detecting-Out-of-Distribution-Objects-through-Class-Conditioned-Inpainting" class="headerlink" title="Detecting Out-of-Distribution Objects through Class-Conditioned Inpainting"></a>Detecting Out-of-Distribution Objects through Class-Conditioned Inpainting</h2><p><strong>Authors:Quang-Huy Nguyen, Jin Peng Zhou, Zhenzhen Liu, Khanh-Huyen Bui, Kilian Q. Weinberger, Wei-Lun Chao, Dung D. Le</strong></p>
<p>Recent object detectors have achieved impressive accuracy in identifying objects seen during training. However, real-world deployment often introduces novel and unexpected objects, referred to as out-of-distribution (OOD) objects, posing significant challenges to model trustworthiness. Modern object detectors are typically overconfident, making it unreliable to use their predictions alone for OOD detection. To address this, we propose leveraging an auxiliary model as a complementary solution. Specifically, we utilize an off-the-shelf text-to-image generative model, such as Stable Diffusion, which is trained with objective functions distinct from those of discriminative object detectors. We hypothesize that this fundamental difference enables the detection of OOD objects by measuring inconsistencies between the models. Concretely, for a given detected object bounding box and its predicted in-distribution class label, we perform class-conditioned inpainting on the image with the object removed. If the object is OOD, the inpainted image is likely to deviate significantly from the original, making the reconstruction error a robust indicator of OOD status. Extensive experiments demonstrate that our approach consistently surpasses existing zero-shot and non-zero-shot OOD detection methods, establishing a robust framework for enhancing object detection systems in dynamic environments.</p>
<blockquote>
<p>æœ€è¿‘çš„ç‰©ä½“æ£€æµ‹å™¨åœ¨è¯†åˆ«è®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°çš„ç‰©ä½“æ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œåœ¨ç°å®ä¸–ç•Œéƒ¨ç½²ä¸­ç»å¸¸ä¼šé‡åˆ°æ–°çš„å’Œæ„æ–™ä¹‹å¤–çš„ç‰©ä½“ï¼Œè¿™äº›è¢«ç§°ä¸ºè¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„ç‰©ä½“ï¼ˆOODç‰©ä½“ï¼‰ï¼Œå¯¹æ¨¡å‹çš„å¯ä¿¡æ€§æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚ç°ä»£ç‰©ä½“æ£€æµ‹å™¨é€šå¸¸è¿‡äºè‡ªä¿¡ï¼Œä»…ä½¿ç”¨å…¶é¢„æµ‹ç»“æœè¿›è¡ŒOODæ£€æµ‹æ˜¯ä¸å¯é çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨è¾…åŠ©æ¨¡å‹ä½œä¸ºè¡¥å……è§£å†³æ–¹æ¡ˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ©ç”¨ç°æˆçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¦‚Stable Diffusionç­‰ï¼Œå…¶é‡‡ç”¨çš„å®¢è§‚å‡½æ•°ä¸åˆ¤åˆ«å¼ç‰©ä½“æ£€æµ‹å™¨çš„å®¢è§‚å‡½æ•°æœ‰æ‰€ä¸åŒã€‚æˆ‘ä»¬å‡è®¾è¿™ç§åŸºæœ¬å·®å¼‚èƒ½å¤Ÿé€šè¿‡æµ‹é‡æ¨¡å‹ä¹‹é—´çš„ä¸€è‡´æ€§æ¥æ£€æµ‹OODç‰©ä½“ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºç»™å®šçš„æ£€æµ‹åˆ°çš„ç‰©ä½“è¾¹ç•Œæ¡†åŠå…¶é¢„æµ‹çš„åˆ†å¸ƒå†…ç±»åˆ«æ ‡ç­¾ï¼Œæˆ‘ä»¬å¯¹ç§»é™¤äº†ç‰©ä½“çš„å›¾åƒè¿›è¡Œç±»åˆ«æ¡ä»¶å¡«å……ã€‚å¦‚æœç‰©ä½“æ˜¯OODï¼Œå¡«å……åçš„å›¾åƒå¾ˆå¯èƒ½ä¸åŸå§‹å›¾åƒæœ‰å¾ˆå¤§çš„åå·®ï¼Œä½¿å¾—é‡å»ºè¯¯å·®æˆä¸ºOODçŠ¶æ€çš„ç¨³å¥æŒ‡æ ‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆè¶…è¶Šç°æœ‰çš„é›¶æ ·æœ¬å’Œéé›¶æ ·æœ¬OODæ£€æµ‹æ–¹æ³•ï¼Œä¸ºåŠ¨æ€ç¯å¢ƒä¸­å¢å¼ºç‰©ä½“æ£€æµ‹ç³»ç»Ÿå»ºç«‹äº†ä¸€ä¸ªç¨³å¥çš„æ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.03292v4">PDF</a> Accepted in WACV 2026 (Algorithms track)</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ‘˜è¦æå‡ºäº†ä¸€ç§åˆ©ç”¨è¾…åŠ©æ¨¡å‹æ¥å¢å¼ºå¯¹è±¡æ£€æµ‹ç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­å¯¹æ–°å‹å¯¹è±¡è¯†åˆ«çš„å¯é æ€§æ–¹æ³•ã€‚é€šè¿‡ç»“åˆä¸€ä¸ªä¸“é—¨çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚Stable Diffusionï¼‰ï¼Œå¹¶åˆ©ç”¨ç±»æ¡ä»¶ä¿®å¤æŠ€æœ¯æ¥æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡æ˜¯å¦ä¸ºè®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–çš„ç±»å‹ï¼Œè¿›è€Œæå‡æ¨¡å‹åœ¨é¢ä¸´æœªçŸ¥å¯¹è±¡æ—¶çš„æ£€æµ‹èƒ½åŠ›ã€‚è¯¥æ–¹æ³•æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„é›¶æ ·æœ¬å’Œéé›¶æ ·æœ¬æœªçŸ¥å¯¹è±¡æ£€æµ‹æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°ä»£å¯¹è±¡æ£€æµ‹å™¨åœ¨é¢ä¸´è®­ç»ƒæ—¶æœªè§çš„æ–°å‹å¯¹è±¡æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>è¾…åŠ©æ¨¡å‹ï¼Œå¦‚æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚Stable Diffusionï¼‰ï¼Œå¯ç”¨äºå¢å¼ºå¯¹è±¡æ£€æµ‹ç³»ç»Ÿçš„å¯é æ€§ã€‚</li>
<li>é€šè¿‡æµ‹é‡ç”Ÿæˆæ¨¡å‹ä¸æ£€æµ‹æ¨¡å‹ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ï¼Œå¯ä»¥æ£€æµ‹å›¾åƒä¸­çš„æœªçŸ¥å¯¹è±¡ã€‚</li>
<li>åˆ©ç”¨ç±»æ¡ä»¶ä¿®å¤æŠ€æœ¯å¯¹å›¾åƒä¸­çš„å¯¹è±¡è¿›è¡Œä¿®å¤ï¼Œåˆ¤æ–­å…¶æ˜¯å¦ä¸ºè®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–çš„ç±»å‹ã€‚</li>
<li>å½“æ£€æµ‹åˆ°æ–°å‹å¯¹è±¡æ—¶ï¼Œä¿®å¤åçš„å›¾åƒå¯èƒ½ä¸åŸå§‹å›¾åƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä½¿å¾—é‡å»ºè¯¯å·®æˆä¸ºåˆ¤æ–­æœªçŸ¥å¯¹è±¡çš„æœ‰æ•ˆæŒ‡æ ‡ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å„ç§å®éªŒä¸­è¡¨ç°ä¼˜è¶Šï¼Œè¶…è¶Šç°æœ‰çš„é›¶æ ·æœ¬å’Œéé›¶æ ·æœ¬æœªçŸ¥å¯¹è±¡æ£€æµ‹æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.03292">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57205401a2577b2470ff408fb93c9f3b" align="middle">
<img src="https://picx.zhimg.com/v2-eac961f19d28efae10ab782733ffa097" align="middle">
<img src="https://picx.zhimg.com/v2-4544d7a56dd405f59e3350c4b60b351b" align="middle">
<img src="https://picx.zhimg.com/v2-86409418ce2df76447274bc8a8338a3c" align="middle">
<img src="https://picx.zhimg.com/v2-0d8bfa83d8f27209b3ca8d6e6a3b32c2" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-21/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-21/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-21/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a6284d0e4f6e2ce7a2a445f0345fb29d" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-21  When CNNs Outperform Transformers and Mambas Revisiting Deep Architectures for Dental Caries Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-21/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0521b43922cb23507d794ced592afe96" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-21  Gaussian Blending Rethinking Alpha Blending in 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33446.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
