<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  Beat on Gaze Learning Stylized Generation of Gaze and Head Dynamics">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-2728ea1bfc3efad0d6c082b65169f3e3')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    22 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-24-æ›´æ–°"><a href="#2025-09-24-æ›´æ–°" class="headerlink" title="2025-09-24 æ›´æ–°"></a>2025-09-24 æ›´æ–°</h1><h2 id="Beat-on-Gaze-Learning-Stylized-Generation-of-Gaze-and-Head-Dynamics"><a href="#Beat-on-Gaze-Learning-Stylized-Generation-of-Gaze-and-Head-Dynamics" class="headerlink" title="Beat on Gaze: Learning Stylized Generation of Gaze and Head Dynamics"></a>Beat on Gaze: Learning Stylized Generation of Gaze and Head Dynamics</h2><p><strong>Authors:Chengwei Shi, Chong Cao, Xin Tong, Xukun Shen</strong></p>
<p>Head and gaze dynamics are crucial in expressive 3D facial animation for conveying emotion and intention. However, existing methods frequently address facial components in isolation, overlooking the intricate coordination between gaze, head motion, and speech. The scarcity of high-quality gaze-annotated datasets hinders the development of data-driven models capable of capturing realistic, personalized gaze control. To address these challenges, we propose StyGazeTalk, an audio-driven method that generates synchronized gaze and head motion styles. We extract speaker-specific motion traits from gaze-head sequences with a multi-layer LSTM structure incorporating a style encoder, enabling the generation of diverse animation styles. We also introduce a high-precision multimodal dataset comprising eye-tracked gaze, audio, head pose, and 3D facial parameters, providing a valuable resource for training and evaluating head and gaze control models. Experimental results demonstrate that our method generates realistic, temporally coherent, and style-aware head-gaze motions, significantly advancing the state-of-the-art in audio-driven facial animation. </p>
<blockquote>
<p>å¤´éƒ¨å’Œç›®å…‰åŠ¨æ€åœ¨ä¼ è¾¾æƒ…æ„Ÿä¸æ„å›¾çš„è¡¨ç°åŠ›åè¶³çš„3Dé¢éƒ¨åŠ¨ç”»ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•å¾€å¾€å­¤ç«‹åœ°å¤„ç†é¢éƒ¨ç»„ä»¶ï¼Œå¿½ç•¥äº†ç›®å…‰ã€å¤´éƒ¨è¿åŠ¨å’Œè¯­éŸ³ä¹‹é—´çš„å¤æ‚åè°ƒã€‚é«˜è´¨é‡ç›®å…‰æ³¨é‡Šæ•°æ®é›†çš„ç¨€ç¼ºé˜»ç¢äº†æ•°æ®é©±åŠ¨æ¨¡å‹çš„å‘å±•ï¼Œè€Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿæ•æ‰çœŸå®ã€ä¸ªæ€§åŒ–çš„ç›®å…‰æ§åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†StyGazeTalkï¼Œè¿™æ˜¯ä¸€ç§éŸ³é¢‘é©±åŠ¨çš„æ–¹æ³•ï¼Œå¯ä»¥ç”ŸæˆåŒæ­¥çš„ç›®å…‰å’Œå¤´éƒ¨è¿åŠ¨é£æ ¼ã€‚æˆ‘ä»¬ä»ç›®å…‰-å¤´éƒ¨åºåˆ—ä¸­æå–å‡ºä¸è¯´è¯è€…ç›¸å…³çš„è¿åŠ¨ç‰¹å¾ï¼Œé‡‡ç”¨å¤šå±‚LSTMç»“æ„å¹¶èå…¥é£æ ¼ç¼–ç å™¨ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨ç”»é£æ ¼ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªé«˜ç²¾åº¦å¤šæ¨¡å¼æ•°æ®é›†ï¼ŒåŒ…æ‹¬çœ¼åŠ¨è¿½è¸ªç›®å…‰ã€éŸ³é¢‘ã€å¤´éƒ¨å§¿æ€å’Œ3Dé¢éƒ¨å‚æ•°ï¼Œä¸ºè®­ç»ƒå’Œè¯„ä¼°å¤´éƒ¨å’Œç›®å…‰æ§åˆ¶æ¨¡å‹æä¾›äº†å®è´µçš„èµ„æºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç”ŸæˆçœŸå®ã€æ—¶é—´è¿è´¯ä¸”é£æ ¼æ˜æ˜¾çš„å¤´éƒ¨-ç›®å…‰è¿åŠ¨ï¼Œåœ¨éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»æ–¹é¢æ˜¾è‘—æå‡äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17168v1">PDF</a> arXiv submission</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§éŸ³é¢‘é©±åŠ¨çš„æ–¹æ³•ï¼Œç”¨äºç”ŸæˆåŒæ­¥çš„å‡è§†å’Œå¤´éƒ¨è¿åŠ¨é£æ ¼ã€‚æ–‡ç« å¼ºè°ƒäº†å¤´éƒ¨å’Œå‡è§†åŠ¨åŠ›å­¦åœ¨è¡¨è¾¾3Dé¢éƒ¨åŠ¨ç”»ä¸­çš„é‡è¦æ€§ï¼Œå¹¶é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼ˆå­¤ç«‹å¤„ç†é¢éƒ¨ç»„ä»¶ï¼Œå¿½è§†å‡è§†ã€å¤´éƒ¨è¿åŠ¨å’Œè¯­éŸ³ä¹‹é—´çš„å¤æ‚åè°ƒï¼‰æå‡ºäº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†æ•æ‰çœŸå®çš„ä¸ªæ€§åŒ–å‡è§†æ§åˆ¶ï¼Œå¼•å…¥äº†é«˜è´¨é‡å‡è§†æ³¨é‡Šæ•°æ®é›†ã€‚æ–‡ç« é‡‡ç”¨å¤šå±‚LSTMç»“æ„ç»“åˆé£æ ¼ç¼–ç å™¨ï¼Œä»å‡è§†å¤´éƒ¨åºåˆ—ä¸­æå–è¯´è¯äººç‰¹å®šçš„è¿åŠ¨ç‰¹å¾ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨ç”»é£æ ¼ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªé«˜ç²¾åº¦å¤šæ¨¡å¼æ•°æ®é›†ï¼ŒåŒ…å«çœ¼åŠ¨è¿½è¸ªå‡è§†ã€éŸ³é¢‘ã€å¤´éƒ¨å§¿åŠ¿å’Œ3Dé¢éƒ¨å‚æ•°ï¼Œä¸ºè®­ç»ƒå’Œè¯„ä¼°å¤´éƒ¨å’Œå‡è§†æ§åˆ¶æ¨¡å‹æä¾›äº†å®è´µèµ„æºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„å¤´éƒ¨å‡è§†åŠ¨ä½œçœŸå®ã€æ—¶é—´è¿è´¯ã€é£æ ¼é²œæ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºè°ƒäº†å¤´éƒ¨å’Œå‡è§†åŠ¨åŠ›å­¦åœ¨è¡¨è¾¾3Dé¢éƒ¨åŠ¨ç”»ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¸¸å¸¸å­¤ç«‹åœ°å¤„ç†é¢éƒ¨ç»„ä»¶ï¼Œå¿½ç•¥äº†å‡è§†ã€å¤´éƒ¨è¿åŠ¨å’Œè¯­éŸ³ä¹‹é—´çš„å¤æ‚åè°ƒã€‚</li>
<li>é«˜è´¨é‡å‡è§†æ³¨é‡Šæ•°æ®é›†çš„ç¼ºä¹é˜»ç¢äº†æ•°æ®é©±åŠ¨æ¨¡å‹çš„å‘å±•ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿæ•æ‰çœŸå®çš„ä¸ªæ€§åŒ–å‡è§†æ§åˆ¶ã€‚</li>
<li>æå‡ºäº† StyGazeTalk æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§éŸ³é¢‘é©±åŠ¨çš„æ–¹æ³•ï¼Œç”¨äºç”ŸæˆåŒæ­¥çš„å‡è§†å’Œå¤´éƒ¨è¿åŠ¨é£æ ¼ã€‚</li>
<li>é‡‡ç”¨å¤šå±‚LSTMç»“æ„å’Œé£æ ¼ç¼–ç å™¨ï¼Œä»å‡è§†å¤´éƒ¨åºåˆ—ä¸­æå–è¯´è¯äººç‰¹å®šçš„è¿åŠ¨ç‰¹å¾ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªåŒ…å«çœ¼åŠ¨è¿½è¸ªå‡è§†ã€éŸ³é¢‘ã€å¤´éƒ¨å§¿åŠ¿å’Œ3Dé¢éƒ¨å‚æ•°çš„é«˜ç²¾åº¦å¤šæ¨¡å¼æ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17168">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0d5b98f5984b41426083a6817253aa2a" align="middle">
<img src="https://picx.zhimg.com/v2-715e86ae7a05bf144f44d9923671a549" align="middle">
<img src="https://picx.zhimg.com/v2-0aed3a14ef9dbed77d55574d8ebd1180" align="middle">
<img src="https://picx.zhimg.com/v2-c2f46be3dc63404e62d16d218295fa7b" align="middle">
<img src="https://picx.zhimg.com/v2-367674a20c8fa40f79a4469036809de4" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PGSTalker-Real-Time-Audio-Driven-Talking-Head-Generation-via-3D-Gaussian-Splatting-with-Pixel-Aware-Density-Control"><a href="#PGSTalker-Real-Time-Audio-Driven-Talking-Head-Generation-via-3D-Gaussian-Splatting-with-Pixel-Aware-Density-Control" class="headerlink" title="PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D   Gaussian Splatting with Pixel-Aware Density Control"></a>PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D   Gaussian Splatting with Pixel-Aware Density Control</h2><p><strong>Authors:Tianheng Zhu, Yinfeng Yu, Liejun Wang, Fuchun Sun, Wendong Zheng</strong></p>
<p>Audio-driven talking head generation is crucial for applications in virtual reality, digital avatars, and film production. While NeRF-based methods enable high-fidelity reconstruction, they suffer from low rendering efficiency and suboptimal audio-visual synchronization. This work presents PGSTalker, a real-time audio-driven talking head synthesis framework based on 3D Gaussian Splatting (3DGS). To improve rendering performance, we propose a pixel-aware density control strategy that adaptively allocates point density, enhancing detail in dynamic facial regions while reducing redundancy elsewhere. Additionally, we introduce a lightweight Multimodal Gated Fusion Module to effectively fuse audio and spatial features, thereby improving the accuracy of Gaussian deformation prediction. Extensive experiments on public datasets demonstrate that PGSTalker outperforms existing NeRF- and 3DGS-based approaches in rendering quality, lip-sync precision, and inference speed. Our method exhibits strong generalization capabilities and practical potential for real-world deployment. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆå¯¹äºè™šæ‹Ÿç°å®ã€æ•°å­—åŒ–èº«å’Œç”µå½±åˆ¶ä½œä¸­çš„åº”ç”¨è‡³å…³é‡è¦ã€‚è™½ç„¶åŸºäºNeRFçš„æ–¹æ³•èƒ½å¤Ÿå®ç°é«˜ä¿çœŸé‡å»ºï¼Œä½†å®ƒä»¬å­˜åœ¨æ¸²æŸ“æ•ˆç‡ä½ä¸‹å’ŒéŸ³è§†é¢‘åŒæ­¥ä¸ä½³çš„é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†PGSTalkerï¼Œä¸€ä¸ªåŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„å®æ—¶éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨åˆæˆæ¡†æ¶ã€‚ä¸ºäº†æé«˜æ¸²æŸ“æ€§èƒ½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åƒç´ æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿè‡ªé€‚åº”åœ°åˆ†é…ç‚¹å¯†åº¦ï¼Œä»è€Œåœ¨åŠ¨æ€é¢éƒ¨åŒºåŸŸå¢å¼ºç»†èŠ‚ï¼ŒåŒæ—¶å‡å°‘å…¶ä»–åœ°æ–¹çš„å†—ä½™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„å¤šæ¨¡å¼é—¨æ§èåˆæ¨¡å—ï¼Œä»¥æœ‰æ•ˆåœ°èåˆéŸ³é¢‘å’Œç©ºé—´ç‰¹å¾ï¼Œä»è€Œæé«˜é«˜æ–¯å˜å½¢é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPGSTalkeråœ¨æ¸²æŸ“è´¨é‡ã€å”‡åŒæ­¥ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦æ–¹é¢ä¼˜äºç°æœ‰çš„NeRFå’Œ3DGSæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œåœ¨å®é™…éƒ¨ç½²ä¸­çš„å®ç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16922v1">PDF</a> Main paper (15 pages). Accepted for publication by ICONIP(   International Conference on Neural Information Processing) 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯åœ¨è™šæ‹Ÿç°å®ã€æ•°å­—åˆ†èº«å’Œç”µå½±åˆ¶ä½œä¸­å…·æœ‰å¹¿æ³›åº”ç”¨ã€‚æœ¬ç ”ç©¶æå‡ºPGSTalkerï¼Œä¸€ä¸ªåŸºäº3Dé«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰çš„å®æ—¶éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨åˆæˆæ¡†æ¶ã€‚ä¸ºæå‡æ¸²æŸ“æ€§èƒ½ï¼Œç ”ç©¶é‡‡ç”¨åƒç´ æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ç­–ç•¥ï¼Œè‡ªé€‚åº”åˆ†é…ç‚¹å¯†åº¦ï¼Œåœ¨åŠ¨æ€é¢éƒ¨åŒºåŸŸå¢å¼ºç»†èŠ‚çš„åŒæ—¶å‡å°‘å†—ä½™ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥è½»é‡çº§å¤šæ¨¡æ€é—¨æ§èåˆæ¨¡å—ï¼Œæœ‰æ•ˆèåˆéŸ³é¢‘å’Œç©ºé—´ç‰¹å¾ï¼Œä»è€Œæé«˜é«˜æ–¯å˜å½¢é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒPGSTalkeråœ¨æ¸²æŸ“è´¨é‡ã€å”‡åŒæ­¥ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦ä¸Šä¼˜äºç°æœ‰çš„NeRFå’Œ3DGSæ–¹æ³•ã€‚è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œå®é™…åº”ç”¨æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯åœ¨å¤šä¸ªé¢†åŸŸæœ‰é‡è¦åº”ç”¨ã€‚</li>
<li>PGSTalkeræ˜¯ä¸€ä¸ªåŸºäº3Dé«˜æ–¯å¹³é“ºçš„å®æ—¶éŸ³é¢‘é©±åŠ¨è¯´è¯å¤´åˆæˆæ¡†æ¶ã€‚</li>
<li>åƒç´ æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ç­–ç•¥æå‡äº†æ¸²æŸ“æ€§èƒ½ï¼Œé€šè¿‡è‡ªé€‚åº”åˆ†é…ç‚¹å¯†åº¦ä¼˜åŒ–ç»†èŠ‚å’Œå†—ä½™ã€‚</li>
<li>å¼•å…¥çš„å¤šæ¨¡æ€é—¨æ§èåˆæ¨¡å—æœ‰æ•ˆèåˆäº†éŸ³é¢‘å’Œç©ºé—´ç‰¹å¾ã€‚</li>
<li>PGSTalkeråœ¨æ¸²æŸ“è´¨é‡ã€å”‡åŒæ­¥ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯åº”ç”¨äºå¤šç§åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4bee1be9c769726296148800b2e1d994" align="middle">
<img src="https://picx.zhimg.com/v2-2728ea1bfc3efad0d6c082b65169f3e3" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Deep-Dubbing-End-to-End-Auto-Audiobook-System-with-Text-to-Timbre-and-Context-Aware-Instruct-TTS"><a href="#Deep-Dubbing-End-to-End-Auto-Audiobook-System-with-Text-to-Timbre-and-Context-Aware-Instruct-TTS" class="headerlink" title="Deep Dubbing: End-to-End Auto-Audiobook System with Text-to-Timbre and   Context-Aware Instruct-TTS"></a>Deep Dubbing: End-to-End Auto-Audiobook System with Text-to-Timbre and   Context-Aware Instruct-TTS</h2><p><strong>Authors:Ziqi Dai, Yiting Chen, Jiacheng Xu, Liufei Xie, Yuchen Wang, Zhenchuan Yang, Bingsong Bai, Yangsheng Gao, Wenjiang Zhou, Weifeng Zhao, Ruohua Zhou</strong></p>
<p>The pipeline for multi-participant audiobook production primarily consists of three stages: script analysis, character voice timbre selection, and speech synthesis. Among these, script analysis can be automated with high accuracy using NLP models, whereas character voice timbre selection still relies on manual effort. Speech synthesis uses either manual dubbing or text-to-speech (TTS). While TTS boosts efficiency, it struggles with emotional expression, intonation control, and contextual scene adaptation. To address these challenges, we propose DeepDubbing, an end-to-end automated system for multi-participant audiobook production. The system comprises two main components: a Text-to-Timbre (TTT) model and a Context-Aware Instruct-TTS (CA-Instruct-TTS) model. The TTT model generates role-specific timbre embeddings conditioned on text descriptions. The CA-Instruct-TTS model synthesizes expressive speech by analyzing contextual dialogue and incorporating fine-grained emotional instructions. This system enables the automated generation of multi-participant audiobooks with both timbre-matched character voices and emotionally expressive narration, offering a novel solution for audiobook production. </p>
<blockquote>
<p>é’ˆå¯¹å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§æµç¨‹ä¸»è¦æ¶µç›–ä¸‰ä¸ªé˜¶æ®µï¼šå‰§æœ¬åˆ†æã€è§’è‰²å—“éŸ³éŸ³è´¨çš„é€‰å–ä»¥åŠè¯­éŸ³åˆæˆã€‚å…¶ä¸­ï¼Œå‰§æœ¬åˆ†æå¯å€ŸåŠ©NLPæ¨¡å‹å®ç°é«˜åº¦è‡ªåŠ¨åŒ–ï¼Œè€Œè§’è‰²å—“éŸ³éŸ³è´¨çš„é€‰å–ä»éœ€è¦äººå·¥æ“ä½œã€‚è¯­éŸ³åˆæˆåˆ™é‡‡ç”¨äººå·¥é…éŸ³æˆ–æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ã€‚è™½ç„¶TTSæŠ€æœ¯èƒ½æé«˜æ•ˆç‡ï¼Œä½†åœ¨æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è°ƒæ§åˆ¶å’Œä¸Šä¸‹æ–‡åœºæ™¯é€‚åº”æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†DeepDubbingè¿™ä¸€ç«¯åˆ°ç«¯çš„å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§è‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªç»„ä»¶ï¼šæ–‡æœ¬åˆ°éŸ³è´¨ï¼ˆTTTï¼‰æ¨¡å‹å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æŒ‡ä»¤è¯­éŸ³åˆæˆï¼ˆCA-Instruct-TTSï¼‰æ¨¡å‹ã€‚TTTæ¨¡å‹æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆç‰¹å®šè§’è‰²çš„éŸ³è´¨åµŒå…¥ã€‚CA-Instruct-TTSæ¨¡å‹é€šè¿‡åˆ†æä¸Šä¸‹æ–‡å¯¹è¯å¹¶èå…¥ç²¾ç»†çš„æƒ…æ„ŸæŒ‡ä»¤ï¼Œåˆæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è¯­éŸ³ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå®ç°å¤šå‚ä¸è€…æœ‰å£°ä¹¦çš„è‡ªåŠ¨åŒ–ç”Ÿæˆï¼Œæ—¢åŒ¹é…è§’è‰²å—“éŸ³éŸ³è´¨ï¼Œåˆå…·å¤‡æƒ…æ„Ÿä¸°å¯Œçš„æ—ç™½ï¼Œä¸ºæœ‰å£°ä¹¦ç”Ÿäº§æä¾›å…¨æ–°è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15845v1">PDF</a> Submitted to ICASSP 2026.Copyright 2026 IEEE. Personal use of this   material is permitted. Permission from IEEE must be obtained for all other   uses, including reprinting&#x2F;republishing, creating new collective works, for   resale or redistribution to servers or lists, or reuse of any copyrighted   component of this work. DOI will be added upon IEEE Xplore publication</p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä»‹ç»äº†å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§çš„æµç¨‹ï¼ŒåŒ…æ‹¬è„šæœ¬åˆ†æã€è§’è‰²å£°éŸ³éŸ³è‰²é€‰æ‹©å’Œè¯­éŸ³åˆæˆä¸‰ä¸ªé˜¶æ®µã€‚å…¶ä¸­ï¼Œè„šæœ¬åˆ†æå¯ä»¥ä½¿ç”¨NLPæ¨¡å‹å®ç°è‡ªåŠ¨åŒ–ä¸”é«˜å‡†ç¡®ç‡ï¼›éŸ³è‰²é€‰æ‹©ä»éœ€è¦äººå·¥æ“ä½œã€‚è¯­éŸ³åˆæˆé‡‡ç”¨äººå·¥é…éŸ³æˆ–TTSæŠ€æœ¯ï¼Œä½†TTSæŠ€æœ¯åœ¨æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è°ƒæ§åˆ¶å’Œåœºæ™¯é€‚åº”æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºDeepDubbingç³»ç»Ÿï¼ŒåŒ…æ‹¬Text-to-Timbreæ¨¡å‹å’ŒContext-Aware Instruct-TTSæ¨¡å‹ï¼Œå®ç°å¤šå‚ä¸è€…æœ‰å£°ä¹¦çš„è‡ªåŠ¨åŒ–ç”Ÿæˆï¼Œå…·æœ‰éŸ³è‰²åŒ¹é…çš„è§’è‰²å£°éŸ³å’Œæƒ…æ„Ÿä¸°å¯Œçš„å™è¿°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§æµç¨‹åŒ…æ‹¬è„šæœ¬åˆ†æã€è§’è‰²å£°éŸ³éŸ³è‰²é€‰æ‹©å’Œè¯­éŸ³åˆæˆä¸‰ä¸ªé˜¶æ®µã€‚</li>
<li>è„šæœ¬åˆ†æå¯ä»¥ä½¿ç”¨NLPæ¨¡å‹å®ç°è‡ªåŠ¨åŒ–ä¸”é«˜å‡†ç¡®ç‡ã€‚</li>
<li>éŸ³è‰²é€‰æ‹©ç›®å‰ä»éœ€è¦äººå·¥æ“ä½œã€‚</li>
<li>è¯­éŸ³åˆæˆé‡‡ç”¨äººå·¥é…éŸ³æˆ–TTSæŠ€æœ¯ï¼Œä½†TTSåœ¨æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è°ƒæ§åˆ¶å’Œåœºæ™¯é€‚åº”æ–¹é¢æœ‰æŒ‘æˆ˜ã€‚</li>
<li>DeepDubbingç³»ç»ŸåŒ…æ‹¬Text-to-Timbreæ¨¡å‹å’ŒContext-Aware Instruct-TTSæ¨¡å‹ï¼Œå¯å®ç°å¤šå‚ä¸è€…æœ‰å£°ä¹¦çš„è‡ªåŠ¨åŒ–ç”Ÿæˆã€‚</li>
<li>Text-to-Timbreæ¨¡å‹æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆè§’è‰²ç‰¹å®šçš„éŸ³è‰²åµŒå…¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15845">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bc8dafef98971565ae9adc22e95dab18" align="middle">
<img src="https://picx.zhimg.com/v2-9e921cf4dc3ef153927978d6dcaca319" align="middle">
<img src="https://picx.zhimg.com/v2-702380b2f46364b0769482b714ff400a" align="middle">
<img src="https://picx.zhimg.com/v2-82d6a5148fa18eeebc5840c8018e8128" align="middle">
<img src="https://picx.zhimg.com/v2-d2fc2d216d00d09c4c42c42190ac8516" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Tiny-is-not-small-enough-High-quality-low-resource-facial-animation-models-through-hybrid-knowledge-distillation"><a href="#Tiny-is-not-small-enough-High-quality-low-resource-facial-animation-models-through-hybrid-knowledge-distillation" class="headerlink" title="Tiny is not small enough: High-quality, low-resource facial animation   models through hybrid knowledge distillation"></a>Tiny is not small enough: High-quality, low-resource facial animation   models through hybrid knowledge distillation</h2><p><strong>Authors:Zhen Han, Mattias Teye, Derek Yadgaroff, Judith BÃ¼tepage</strong></p>
<p>The training of high-quality, robust machine learning models for speech-driven 3D facial animation requires a large, diverse dataset of high-quality audio-animation pairs. To overcome the lack of such a dataset, recent work has introduced large pre-trained speech encoders that are robust to variations in the input audio and, therefore, enable the facial animation model to generalize across speakers, audio quality, and languages. However, the resulting facial animation models are prohibitively large and lend themselves only to offline inference on a dedicated machine. In this work, we explore on-device, real-time facial animation models in the context of game development. We overcome the lack of large datasets by using hybrid knowledge distillation with pseudo-labeling. Given a large audio dataset, we employ a high-performing teacher model to train very small student models. In contrast to the pre-trained speech encoders, our student models only consist of convolutional and fully-connected layers, removing the need for attention context or recurrent updates. In our experiments, we demonstrate that we can reduce the memory footprint to up to 3.4 MB and required future audio context to up to 81 ms while maintaining high-quality animations. This paves the way for on-device inference, an important step towards realistic, model-driven digital characters. </p>
<blockquote>
<p>å¯¹äºé«˜è´¨é‡ã€ç¨³å¥çš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œè¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»è®­ç»ƒï¼Œéœ€è¦é«˜è´¨é‡éŸ³é¢‘åŠ¨ç”»å¯¹çš„å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†ã€‚ä¸ºäº†å…‹æœç¼ºä¹è¿™æ ·çš„æ•°æ®é›†ï¼Œè¿‘æœŸçš„å·¥ä½œå¼•å…¥äº†å¤§å‹é¢„è®­ç»ƒè¯­éŸ³ç¼–ç å™¨ï¼Œå®ƒå¯¹è¾“å…¥éŸ³é¢‘çš„å˜åŒ–å…·æœ‰é²æ£’æ€§ï¼Œå› æ­¤ï¼Œä½¿å¾—é¢éƒ¨åŠ¨ç”»æ¨¡å‹èƒ½å¤Ÿåœ¨å‘è¨€äººã€éŸ³é¢‘è´¨é‡å’Œè¯­è¨€æ–¹é¢å®ç°æ³›åŒ–ã€‚ç„¶è€Œï¼Œç”±æ­¤äº§ç”Ÿçš„é¢éƒ¨åŠ¨ç”»æ¨¡å‹è¿‡äºåºå¤§ï¼Œåªèƒ½åœ¨ä¸“ç”¨æœºå™¨ä¸Šè¿›è¡Œç¦»çº¿æ¨ç†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨æ¸¸æˆå¼€å‘çš„èƒŒæ™¯ä¸‹æ¢ç´¢äº†è®¾å¤‡ä¸Šçš„å®æ—¶é¢éƒ¨åŠ¨ç”»æ¨¡å‹ã€‚é€šè¿‡ä½¿ç”¨æ··åˆçŸ¥è¯†è’¸é¦å’Œä¼ªæ ‡ç­¾æŠ€æœ¯ï¼Œæˆ‘ä»¬å…‹æœäº†ç¼ºä¹å¤§è§„æ¨¡æ•°æ®é›†çš„éš¾é¢˜ã€‚ç»™å®šä¸€ä¸ªå¤§å‹éŸ³é¢‘æ•°æ®é›†ï¼Œæˆ‘ä»¬åˆ©ç”¨é«˜æ€§èƒ½çš„æ•™å¸ˆæ¨¡å‹æ¥è®­ç»ƒéå¸¸å°çš„çš„å­¦ç”Ÿæ¨¡å‹ã€‚ä¸é¢„è®­ç»ƒçš„è¯­éŸ³ç¼–ç å™¨ä¸åŒï¼Œæˆ‘ä»¬çš„å­¦ç”Ÿæ¨¡å‹åªåŒ…å«å·ç§¯å±‚å’Œå…¨è¿æ¥å±‚ï¼Œæ— éœ€æ³¨æ„åŠ›ä¸Šä¸‹æ–‡æˆ–é€’å½’æ›´æ–°ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¯æ˜å¯ä»¥å°†å†…å­˜å ç”¨å‡å°‘åˆ°æœ€å¤š3.4MBï¼Œå¹¶å°†æœªæ¥éŸ³é¢‘ä¸Šä¸‹æ–‡çš„éœ€æ±‚å‡å°‘åˆ°æœ€å¤š81æ¯«ç§’ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„åŠ¨ç”»æ•ˆæœã€‚è¿™ä¸ºè®¾å¤‡ç«¯æ¨ç†é“ºå¹³äº†é“è·¯ï¼Œæ˜¯æœç€é€¼çœŸã€æ¨¡å‹é©±åŠ¨çš„æ•°å­—è§’è‰²è¿ˆè¿›çš„é‡è¦ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.18352v2">PDF</a> Accepted to ACM TOG 2025 (SIGGRAPH journal track); Project page:   <a target="_blank" rel="noopener" href="https://electronicarts.github.io/tiny-voice2face/">https://electronicarts.github.io/tiny-voice2face/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†é¢å‘æ¸¸æˆå¼€å‘çš„å®æ—¶é¢éƒ¨åŠ¨ç”»æ¨¡å‹ã€‚ä¸ºè§£å†³é«˜è´¨é‡éŸ³é¢‘åŠ¨ç”»å¯¹å¤§å‹æ•°æ®é›†çš„éœ€æ±‚ï¼Œé‡‡ç”¨æ··åˆçŸ¥è¯†è’¸é¦ä¸ä¼ªæ ‡ç­¾æŠ€æœ¯ï¼Œåˆ©ç”¨é«˜æ€§èƒ½æ•™å¸ˆæ¨¡å‹è®­ç»ƒå°å‹å­¦ç”Ÿæ¨¡å‹ã€‚å­¦ç”Ÿæ¨¡å‹ä»…åŒ…å«å·ç§¯å±‚å’Œå…¨è¿æ¥å±‚ï¼Œæ— éœ€æ³¨æ„åŠ›ä¸Šä¸‹æ–‡æˆ–é€’å½’æ›´æ–°ï¼Œé™ä½äº†å†…å­˜å ç”¨å¹¶ç»´æŒäº†é«˜è´¨é‡åŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜è´¨é‡ã€ç¨³å¥çš„æœºå™¨å­¦ä¹ ä»»åŠ¡é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»éœ€è¦å¤§å‹ã€å¤šæ ·åŒ–çš„é«˜è´¨é‡éŸ³é¢‘åŠ¨ç”»æ•°æ®é›†ã€‚</li>
<li>è¿‘æœŸå·¥ä½œå¼•å…¥å¤§å‹é¢„è®­ç»ƒè¯­éŸ³ç¼–ç å™¨ï¼Œå¯¹è¾“å…¥éŸ³é¢‘çš„å˜å¼‚å…·æœ‰é²æ£’æ€§ï¼Œä½¿é¢éƒ¨åŠ¨ç”»æ¨¡å‹èƒ½å¤Ÿè·¨è¯´è¯äººã€éŸ³é¢‘è´¨é‡å’Œè¯­è¨€è¿›è¡Œæ¨å¹¿ã€‚</li>
<li>ç°æœ‰é¢éƒ¨åŠ¨ç”»æ¨¡å‹é€šå¸¸è¿‡äºåºå¤§ï¼Œä»…é™äºç¦»çº¿æ¨ç†ï¼Œä¸é€‚ç”¨äºæ¸¸æˆå¼€å‘ç­‰åœºæ™¯ã€‚</li>
<li>æå‡ºä½¿ç”¨æ··åˆçŸ¥è¯†è’¸é¦ä¸ä¼ªæ ‡ç­¾æŠ€æœ¯ï¼Œè§£å†³ç¼ºä¹å¤§å‹æ•°æ®é›†çš„é—®é¢˜ã€‚</li>
<li>åˆ©ç”¨é«˜æ€§èƒ½æ•™å¸ˆæ¨¡å‹è®­ç»ƒå°å‹å­¦ç”Ÿæ¨¡å‹ï¼Œå­¦ç”Ÿæ¨¡å‹ä»…åŒ…å«å·ç§¯å’Œå®Œå…¨è¿æ¥å±‚ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œåœ¨ç»´æŒé«˜è´¨é‡åŠ¨ç”»çš„åŒæ—¶ï¼Œèƒ½å‡å°‘å†…å­˜å ç”¨é«˜è¾¾3.4MBï¼Œå¹¶å°†æœªæ¥éŸ³é¢‘ä¸Šä¸‹æ–‡éœ€æ±‚å‡å°‘åˆ°81msã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.18352">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a488ddfa0737851e3b84abd16a1488ee" align="middle">
<img src="https://picx.zhimg.com/v2-3773e9beda8873cf0d8c68a5f4e2f250" align="middle">
<img src="https://picx.zhimg.com/v2-ed3fe0ca6e849b2b78f9bd8b305180d3" align="middle">
<img src="https://picx.zhimg.com/v2-1be340f59a9634cc7cb9e84496bb6c44" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Revisiting-Speech-Lip-Alignment-A-Phoneme-Aware-Speech-Encoder-for-Robust-Talking-Head-Synthesis"><a href="#Revisiting-Speech-Lip-Alignment-A-Phoneme-Aware-Speech-Encoder-for-Robust-Talking-Head-Synthesis" class="headerlink" title="Revisiting Speech-Lip Alignment: A Phoneme-Aware Speech Encoder for   Robust Talking Head Synthesis"></a>Revisiting Speech-Lip Alignment: A Phoneme-Aware Speech Encoder for   Robust Talking Head Synthesis</h2><p><strong>Authors:Yihuan Huang, Jiajun Liu, Yanzhen Ren, Wuyang Liu, Zongkun Sun</strong></p>
<p>Speech-driven talking head synthesis tasks commonly use general acoustic features as guided speech features. However, we discovered that these features suffer from phoneme-viseme alignment ambiguity, which refers to the uncertainty and imprecision in matching phonemes with visemes. To overcome this limitation, we propose a phoneme-aware speech encoder (PASE) that explicitly enforces accurate phoneme-viseme correspondence. PASE first captures fine-grained speech and visual features, then introduces a prediction-reconstruction task to improve robustness under noise and modality absence. Furthermore, a phoneme-level alignment module guided by phoneme embeddings and contrastive learning ensures discriminative audio and visual alignment. Experimental results show that PASE achieves state-of-the-art performance in both NeRF and 3DGS rendering models. Its lip sync accuracy improves by 13.7% and 14.2% compared to the acoustic feature, producing results close to the ground truth videos. </p>
<blockquote>
<p>è¯­éŸ³é©±åŠ¨è¯´è¯äººå¤´éƒ¨åˆæˆä»»åŠ¡é€šå¸¸ä½¿ç”¨é€šç”¨å£°å­¦ç‰¹å¾ä½œä¸ºå¼•å¯¼è¯­éŸ³ç‰¹å¾ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°è¿™äº›ç‰¹å¾å­˜åœ¨éŸ³ç´ -é¢éƒ¨åŠ¨ç”»å‚æ•°å¯¹é½æ¨¡ç³Šçš„é—®é¢˜ï¼Œå³éŸ³ç´ ä¸é¢éƒ¨åŠ¨ç”»å‚æ•°åŒ¹é…æ—¶å­˜åœ¨ä¸ç¡®å®šæ€§å’Œä¸ç²¾ç¡®æ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§éŸ³ç´ æ„ŸçŸ¥è¯­éŸ³ç¼–ç å™¨ï¼ˆPASEï¼‰ï¼Œå®ƒæ˜¾å¼åœ°å¼ºåˆ¶æ‰§è¡Œå‡†ç¡®çš„éŸ³ç´ -é¢éƒ¨åŠ¨ç”»å‚æ•°å¯¹åº”å…³ç³»ã€‚PASEé¦–å…ˆæ•è·ç²¾ç»†çš„è¯­éŸ³å’Œè§†è§‰ç‰¹å¾ï¼Œç„¶åå¼•å…¥é¢„æµ‹é‡å»ºä»»åŠ¡ï¼Œä»¥æé«˜å™ªå£°å’Œæ¨¡æ€ç¼ºå¤±æƒ…å†µä¸‹çš„ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œä¸€ä¸ªç”±éŸ³ç´ åµŒå…¥å’Œå¯¹æ¯”å­¦ä¹ å¼•å¯¼çš„éŸ³ç´ çº§å¯¹é½æ¨¡å—ç¡®ä¿äº†åŒºåˆ†æ€§çš„éŸ³é¢‘å’Œè§†è§‰å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPASEåœ¨NeRFå’Œ3DGSæ¸²æŸ“æ¨¡å‹ä¸­éƒ½è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½ã€‚ä¸å£°å­¦ç‰¹å¾ç›¸æ¯”ï¼Œå…¶å”‡åŒæ­¥ç²¾åº¦æé«˜äº†13.7%å’Œ14.2%ï¼Œç”Ÿæˆçš„ç»“æœæ¥è¿‘çœŸå®è§†é¢‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05803v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†è¯­éŸ³é©±åŠ¨çš„å¤´éƒ¨åˆæˆä»»åŠ¡ä¸­å¸¸è§çš„ä»¥é€šç”¨å£°å­¦ç‰¹å¾ä½œä¸ºå¼•å¯¼è¯­éŸ³ç‰¹å¾çš„é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œç”±äºè¯­éŸ³ä¸è§†è§‰ä¹‹é—´çš„éŸ³ç´ -å§¿æ€å¯¹åº”æ¨¡ç³Šï¼Œå³éŸ³ç´ ä¸å§¿æ€åŒ¹é…çš„ä¸ç¡®å®šæ€§å’Œä¸ç²¾ç¡®æ€§ï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§éŸ³ç´ æ„ŸçŸ¥è¯­éŸ³ç¼–ç å™¨ï¼ˆPASEï¼‰ï¼Œå®ƒèƒ½å‡†ç¡®åœ°å¯¹åº”éŸ³ç´ å’Œå§¿æ€ã€‚PASEé¦–å…ˆæ•æ‰ç²¾ç»†çš„è¯­éŸ³å’Œè§†è§‰ç‰¹å¾ï¼Œç„¶åå¼•å…¥é¢„æµ‹é‡å»ºä»»åŠ¡ï¼Œä»¥æé«˜å™ªå£°å’Œæ¨¡æ€ç¼ºå¤±ä¸‹çš„ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡éŸ³ç´ åµŒå…¥å’Œå¯¹æ¯”å­¦ä¹ å¼•å¯¼çš„éŸ³ç´ çº§å¯¹é½æ¨¡å—ç¡®ä¿äº†éŸ³é¢‘å’Œè§†è§‰å¯¹é½çš„é‰´åˆ«æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPASEåœ¨NeRFå’Œ3DGSæ¸²æŸ“æ¨¡å‹ä¸Šå‡è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå”‡åŒæ­¥ç²¾åº¦åˆ†åˆ«æé«˜äº†13.7%å’Œ14.2%ï¼Œä¸å£°å­¦ç‰¹å¾ç›¸æ¯”ï¼Œç”Ÿæˆçš„ç»“æœæ›´æ¥è¿‘çœŸå®è§†é¢‘ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰è¯­éŸ³é©±åŠ¨å¤´éƒ¨åˆæˆä»»åŠ¡ä¾èµ–äºé€šç”¨å£°å­¦ç‰¹å¾ä½œä¸ºå¼•å¯¼è¯­éŸ³ç‰¹å¾ã€‚</li>
<li>å­˜åœ¨éŸ³ç´ ä¸å§¿æ€åŒ¹é…çš„ä¸ç¡®å®šæ€§å’Œä¸ç²¾ç¡®æ€§é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§éŸ³ç´ æ„ŸçŸ¥è¯­éŸ³ç¼–ç å™¨ï¼ˆPASEï¼‰æ¥å‡†ç¡®å¯¹åº”éŸ³ç´ å’Œå§¿æ€ã€‚</li>
<li>PASEèƒ½æ•æ‰ç²¾ç»†çš„è¯­éŸ³å’Œè§†è§‰ç‰¹å¾ã€‚</li>
<li>é¢„æµ‹é‡å»ºä»»åŠ¡æé«˜äº†å™ªå£°å’Œæ¨¡æ€ç¼ºå¤±ä¸‹çš„ç¨³å¥æ€§ã€‚</li>
<li>éŸ³ç´ çº§å¯¹é½æ¨¡å—é€šè¿‡éŸ³ç´ åµŒå…¥å’Œå¯¹æ¯”å­¦ä¹ å¢å¼ºäº†éŸ³é¢‘å’Œè§†è§‰å¯¹é½çš„é‰´åˆ«æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05803">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fd77ef9769c5e4c199cb986c416bc8c4" align="middle">
<img src="https://picx.zhimg.com/v2-ef509e3cf7f109302bdea3a1caa09141" align="middle">
<img src="https://picx.zhimg.com/v2-d9c9459803817f097638172f2585854d" align="middle">
<img src="https://picx.zhimg.com/v2-9bf48199e1f393ea598bd58bc29caed3" align="middle">
<img src="https://picx.zhimg.com/v2-1d0f52e712ded4568efbc615bf817ced" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="FLOAT-Generative-Motion-Latent-Flow-Matching-for-Audio-driven-Talking-Portrait"><a href="#FLOAT-Generative-Motion-Latent-Flow-Matching-for-Audio-driven-Talking-Portrait" class="headerlink" title="FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking   Portrait"></a>FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking   Portrait</h2><p><strong>Authors:Taekyung Ki, Dongchan Min, Gyeongsu Chae</strong></p>
<p>With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency. </p>
<blockquote>
<p>éšç€åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè‚–åƒå›¾åƒåŠ¨ç”»å·²ç»å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œç”±äºå…¶è¿­ä»£é‡‡æ ·çš„æ€§è´¨ï¼Œå®ƒåœ¨æ—¶åºä¸€è‡´çš„è§†é¢‘ç”Ÿæˆå’Œå¿«é€Ÿé‡‡æ ·æ–¹é¢ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†FLOATï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæµåŒ¹é…ç”Ÿæˆæ¨¡å‹çš„éŸ³é¢‘é©±åŠ¨å¼è¯´è¯è‚–åƒè§†é¢‘ç”Ÿæˆæ–¹æ³•ã€‚æˆ‘ä»¬åˆ©ç”¨å­¦ä¹ åˆ°çš„æ­£äº¤è¿åŠ¨æ½œåœ¨ç©ºé—´ï¼Œè€Œä¸æ˜¯åŸºäºåƒç´ çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†é«˜æ•ˆä¸”æ—¶åºä¸€è‡´çš„è¿åŠ¨ç”Ÿæˆå’Œç¼–è¾‘ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºå˜å‹å™¨çš„çŸ¢é‡åœºé¢„æµ‹å™¨ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªæœ‰æ•ˆçš„å¸§æ¡ä»¶æœºåˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒè¯­éŸ³é©±åŠ¨çš„æƒ…æ„Ÿå¢å¼ºï¼Œèƒ½å¤Ÿå®ç°è¡¨è¾¾æ€§è¿åŠ¨çš„è‡ªç„¶èåˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€è¿åŠ¨ä¿çœŸåº¦å’Œæ•ˆç‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„éŸ³é¢‘é©±åŠ¨å¼è¯´è¯è‚–åƒæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01064v5">PDF</a> ICCV 2025. Project page:   <a target="_blank" rel="noopener" href="https://deepbrainai-research.github.io/float/">https://deepbrainai-research.github.io/float/</a></p>
<p><strong>Summary</strong></p>
<p>éšç€æ‰©æ•£ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè‚–åƒå›¾åƒåŠ¨ç”»å·²ç»å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œå®ƒä»é¢ä¸´å› è¿­ä»£é‡‡æ ·äº§ç”Ÿçš„è§†é¢‘ç”Ÿæˆæ—¶é—´ä¸€è‡´æ€§å’Œå¿«é€Ÿé‡‡æ ·æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†åŸºäºæµåŒ¹é…ç”Ÿæˆæ¨¡å‹çš„éŸ³é¢‘é©±åŠ¨è‚–åƒè§†é¢‘ç”Ÿæˆæ–¹æ³•FLOATã€‚æˆ‘ä»¬åˆ©ç”¨å­¦ä¹ åˆ°çš„æ­£äº¤è¿åŠ¨æ½œåœ¨ç©ºé—´ï¼Œè€ŒéåŸºäºåƒç´ çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†é«˜æ•ˆçš„æ—¶é—´ä¸€è‡´è¿åŠ¨ç”Ÿæˆå’Œç¼–è¾‘ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥åŸºäºå˜æ¢å™¨çš„å‘é‡åœºé¢„æµ‹å™¨ï¼Œå¹¶é…å¤‡äº†æœ‰æ•ˆçš„å¸§æ¡ä»¶æœºåˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒè¯­éŸ³é©±åŠ¨çš„æƒ…æ„Ÿå¢å¼ºï¼Œèƒ½å¤Ÿè‡ªç„¶åœ°èå…¥è¡¨è¾¾æ€§åŠ¨ä½œã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€è¿åŠ¨ä¿çœŸåº¦å’Œæ•ˆç‡æ–¹é¢è¶…è¶Šäº†ç°æœ‰éŸ³é¢‘é©±åŠ¨çš„è‚–åƒåŠ¨ç”»æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FLOATæ˜¯ä¸€ç§åŸºäºæµåŒ¹é…ç”Ÿæˆæ¨¡å‹çš„éŸ³é¢‘é©±åŠ¨è‚–åƒè§†é¢‘ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨æ­£äº¤è¿åŠ¨æ½œåœ¨ç©ºé—´ï¼Œå®ç°é«˜æ•ˆçš„æ—¶é—´ä¸€è‡´è¿åŠ¨ç”Ÿæˆå’Œç¼–è¾‘ã€‚</li>
<li>å¼•å…¥åŸºäºå˜æ¢å™¨çš„å‘é‡åœºé¢„æµ‹å™¨ï¼Œé…å¤‡æœ‰æ•ˆçš„å¸§æ¡ä»¶æœºåˆ¶ã€‚</li>
<li>æ”¯æŒè¯­éŸ³é©±åŠ¨çš„æƒ…æ„Ÿå¢å¼ºï¼Œèå…¥è¡¨è¾¾æ€§åŠ¨ä½œã€‚</li>
<li>æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€è¿åŠ¨ä¿çœŸåº¦å’Œæ•ˆç‡æ–¹é¢è¶…è¶Šç°æœ‰éŸ³é¢‘é©±åŠ¨çš„è‚–åƒåŠ¨ç”»æ–¹æ³•ã€‚</li>
<li>é¢å¯¹æŒ‘æˆ˜ï¼šè¿­ä»£é‡‡æ ·å¸¦æ¥çš„æ—¶é—´ä¸€è‡´è§†é¢‘ç”Ÿæˆå’Œå¿«é€Ÿé‡‡æ ·é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01064">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31e85e1d61a000eda461b783ae612dd7" align="middle">
<img src="https://picx.zhimg.com/v2-16292bb7e83296bca7145627a7591bdc" align="middle">
<img src="https://picx.zhimg.com/v2-e1bf23e979ccafd415927201321dc284" align="middle">
<img src="https://picx.zhimg.com/v2-e664574875172447d0fa281156a519d0" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-585eeb01e1b5036bc615aaedb3aea715" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  UniPixel Unified Object Referring and Segmentation for Pixel-Level   Visual Reasoning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-21/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5eb7fc7256b42dcd3bfff81dba874c60" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-21  DICE Diffusion Consensus Equilibrium for Sparse-view CT Reconstruction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32562k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
