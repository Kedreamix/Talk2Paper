<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  TMD-TTS A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for   Ãœ-Tsang, Amdo and Kham Speech Dataset Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    45 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-24-æ›´æ–°"><a href="#2025-09-24-æ›´æ–°" class="headerlink" title="2025-09-24 æ›´æ–°"></a>2025-09-24 æ›´æ–°</h1><h2 id="TMD-TTS-A-Unified-Tibetan-Multi-Dialect-Text-to-Speech-Synthesis-for-U-Tsang-Amdo-and-Kham-Speech-Dataset-Generation"><a href="#TMD-TTS-A-Unified-Tibetan-Multi-Dialect-Text-to-Speech-Synthesis-for-U-Tsang-Amdo-and-Kham-Speech-Dataset-Generation" class="headerlink" title="TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for   Ãœ-Tsang, Amdo and Kham Speech Dataset Generation"></a>TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for   Ãœ-Tsang, Amdo and Kham Speech Dataset Generation</h2><p><strong>Authors:Yutong Liu, Ziyue Zhang, Ban Ma-bao, Renzeng Duojie, Yuqing Cai, Yongbin Yu, Xiangxiang Wang, Fan Gao, Cheng Huang, Nyima Tashi</strong></p>
<p>Tibetan is a low-resource language with limited parallel speech corpora spanning its three major dialects (&quot;U-Tsang, Amdo, and Kham), limiting progress in speech modeling. To address this issue, we propose TMD-TTS, a unified Tibetan multi-dialect text-to-speech (TTS) framework that synthesizes parallel dialectal speech from explicit dialect labels. Our method features a dialect fusion module and a Dialect-Specialized Dynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and linguistic variations across dialects. Extensive objective and subjective evaluations demonstrate that TMD-TTS significantly outperforms baselines in dialectal expressiveness. We further validate the quality and utility of the synthesized speech through a challenging Speech-to-Speech Dialect Conversion (S2SDC) task. </p>
<blockquote>
<p>è—è¯­æ˜¯ä¸€ç§èµ„æºæœ‰é™çš„è¯­ç§ï¼Œå…¶ä¸‰å¤§æ–¹è¨€ï¼ˆä¹Œæ–¯è—ã€å®‰å¤šå’Œåº·å·´ï¼‰çš„å¹³è¡Œè¯­éŸ³è¯­æ–™åº“æœ‰é™ï¼Œé™åˆ¶äº†è¯­éŸ³å»ºæ¨¡çš„è¿›å±•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†TMD-TTSï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è—è¯­å¤šæ–¹è¨€æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¡†æ¶ï¼Œå®ƒå¯ä»¥æ ¹æ®æ˜ç¡®çš„æ–¹è¨€æ ‡ç­¾åˆæˆå¹³è¡Œæ–¹è¨€è¯­éŸ³ã€‚æˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰æ–¹è¨€èåˆæ¨¡å—å’Œæ–¹è¨€ä¸“ç”¨åŠ¨æ€è·¯ç”±ç½‘ç»œï¼ˆDSDR-Netï¼‰ï¼Œå¯ä»¥æ•æ‰ä¸åŒæ–¹è¨€ä¹‹é—´çš„ç»†å¾®å£°éŸ³å’Œè¯­è¨€å˜åŒ–ã€‚å¤§é‡çš„å®¢è§‚å’Œä¸»è§‚è¯„ä¼°è¡¨æ˜ï¼Œåœ¨æ–¹è¨€è¡¨ç°åŠ›æ–¹é¢ï¼ŒTMD-TTSæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯­éŸ³åˆ°è¯­éŸ³æ–¹è¨€è½¬æ¢ï¼ˆS2SDCï¼‰ä»»åŠ¡éªŒè¯äº†åˆæˆè¯­éŸ³çš„è´¨é‡å’Œå®ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18060v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹è—è¯­çš„ç»Ÿä¸€å¤šæ–¹è¨€æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¡†æ¶TMD-TTSï¼Œè§£å†³äº†è—è¯­èµ„æºåŒ®ä¹çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶èƒ½å¤ŸåˆæˆåŒ…å«æ˜ç¡®æ–¹è¨€æ ‡ç­¾çš„å¹¶è¡Œæ–¹è¨€è¯­éŸ³ã€‚é€šè¿‡é‡‡ç”¨æ–¹è¨€èåˆæ¨¡å—å’Œæ–¹è¨€ä¸“ç”¨åŠ¨æ€è·¯ç”±ç½‘ç»œï¼ˆDSDR-Netï¼‰ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ•æ‰ä¸åŒæ–¹è¨€ä¹‹é—´çš„ç»†å¾®å£°éŸ³å’Œè¯­è¨€å­¦å·®å¼‚ã€‚å®¢è§‚å’Œä¸»è§‚è¯„ä¼°å‡è¡¨æ˜ï¼ŒTMD-TTSåœ¨æ–¹è¨€è¡¨ç°åŠ›æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡æŒ‘æˆ˜æ€§çš„è¯­éŸ³åˆ°è¯­éŸ³æ–¹è¨€è½¬æ¢ï¼ˆS2SDCï¼‰ä»»åŠ¡éªŒè¯äº†åˆæˆè¯­éŸ³çš„è´¨é‡å’Œå®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è—è¯­æ˜¯ä¸€ç§èµ„æºåŒ®ä¹çš„è¯­è¨€ï¼Œå…¶ä¸‰å¤§æ–¹è¨€ï¼ˆU-Tsangã€Amdoå’ŒKhamï¼‰çš„å¹³è¡Œè¯­éŸ³è¯­æ–™åº“æœ‰é™ï¼Œé™åˆ¶äº†è¯­éŸ³å»ºæ¨¡çš„è¿›å±•ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è—è¯­å¤šæ–¹è¨€æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¡†æ¶TMD-TTSï¼Œèƒ½å¤ŸåˆæˆåŒ…å«æ˜ç¡®æ–¹è¨€æ ‡ç­¾çš„å¹¶è¡Œæ–¹è¨€è¯­éŸ³ã€‚</li>
<li>TMD-TTSæ¡†æ¶åŒ…å«æ–¹è¨€èåˆæ¨¡å—å’Œæ–¹è¨€ä¸“ç”¨åŠ¨æ€è·¯ç”±ç½‘ç»œï¼ˆDSDR-Netï¼‰ï¼Œç”¨äºæ•æ‰ä¸åŒæ–¹è¨€ä¹‹é—´çš„ç»†å¾®å£°éŸ³å’Œè¯­è¨€å­¦å·®å¼‚ã€‚</li>
<li>å®¢è§‚å’Œä¸»è§‚è¯„ä¼°è¡¨æ˜ï¼ŒTMD-TTSåœ¨æ–¹è¨€è¡¨ç°åŠ›æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚</li>
<li>åˆæˆè¯­éŸ³çš„è´¨é‡å’Œå®ç”¨æ€§é€šè¿‡æŒ‘æˆ˜æ€§çš„è¯­éŸ³åˆ°è¯­éŸ³æ–¹è¨€è½¬æ¢ï¼ˆS2SDCï¼‰ä»»åŠ¡å¾—åˆ°éªŒè¯ã€‚</li>
<li>TMD-TTSæ¡†æ¶æœ‰åŠ©äºæ¨åŠ¨è—è¯­æ–¹è¨€çš„è¯­éŸ³ç ”ç©¶å’Œåº”ç”¨å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18060">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18060v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18060v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18060v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18060v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18060v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18060v1/page_3_1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WenetSpeech-Chuan-A-Large-Scale-Sichuanese-Corpus-with-Rich-Annotation-for-Dialectal-Speech-Processing"><a href="#WenetSpeech-Chuan-A-Large-Scale-Sichuanese-Corpus-with-Rich-Annotation-for-Dialectal-Speech-Processing" class="headerlink" title="WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation   for Dialectal Speech Processing"></a>WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation   for Dialectal Speech Processing</h2><p><strong>Authors:Yuhang Dai, Ziyu Zhang, Shuai Wang, Longhao Li, Zhao Guo, Tianlun Zuo, Shuiyuan Wang, Hongfei Xue, Chengyou Wang, Qing Wang, Xin Xu, Hui Bu, Jie Li, Jian Kang, Binbin Zhang, Lei Xie</strong></p>
<p>The scarcity of large-scale, open-source data for dialects severely hinders progress in speech technology, a challenge particularly acute for the widely spoken Sichuanese dialects of Chinese. To address this critical gap, we introduce WenetSpeech-Chuan, a 10,000-hour, richly annotated corpus constructed using our novel Chuan-Pipeline, a complete data processing framework for dialectal speech. To facilitate rigorous evaluation and demonstrate the corpusâ€™s effectiveness, we also release high-quality ASR and TTS benchmarks, WenetSpeech-Chuan-Eval, with manually verified transcriptions. Experiments show that models trained on WenetSpeech-Chuan achieve state-of-the-art performance among open-source systems and demonstrate results comparable to commercial services. As the largest open-source corpus for Sichuanese dialects, WenetSpeech-Chuan not only lowers the barrier to research in dialectal speech processing but also plays a crucial role in promoting AI equity and mitigating bias in speech technologies. The corpus, benchmarks, models, and receipts are publicly available on our project page. </p>
<blockquote>
<p>æ–¹è¨€å¤§è§„æ¨¡å¼€æºæ•°æ®çš„ç¨€ç¼ºä¸¥é‡é˜»ç¢äº†è¯­éŸ³æŠ€æœ¯çš„è¿›æ­¥ï¼Œå¯¹äºå¹¿æ³›ä½¿ç”¨çš„å››å·æ–¹è¨€æ¥è¯´ï¼Œè¿™ä¸€æŒ‘æˆ˜å°¤ä¸ºä¸¥å³»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å…³é”®ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†WenetSpeech-Chuanï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æˆ‘ä»¬æ–°å‹Chuan-Pipelineæ„å»ºè€Œæˆçš„10000å°æ—¶ä¸°å¯Œæ³¨é‡Šè¯­æ–™åº“ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ–¹è¨€è¯­éŸ³æ•°æ®å¤„ç†æ¡†æ¶ã€‚ä¸ºäº†ä¿ƒè¿›ä¸¥æ ¼è¯„ä¼°å¹¶è¯æ˜è¯­æ–™åº“çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº†é«˜è´¨é‡çš„ASRå’ŒTTSåŸºå‡†æµ‹è¯•WenetSpeech-Chuan-Evalï¼Œå…¶ä¸­åŒ…å«æ‰‹åŠ¨éªŒè¯çš„è½¬å½•ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨WenetSpeech-Chuanä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨å¼€æºç³»ç»Ÿä¸­å¤„äºæœ€æ–°æŠ€æœ¯æ€§èƒ½æ°´å¹³ï¼Œå¹¶ä¸”æ˜¾ç¤ºçš„ç»“æœä¸å•†ä¸šæœåŠ¡ç›¸å½“ã€‚ä½œä¸ºå››å·æ–¹è¨€æœ€å¤§çš„å¼€æºè¯­æ–™åº“ï¼ŒWenetSpeech-Chuanä¸ä»…é™ä½äº†æ–¹è¨€è¯­éŸ³å¤„ç†çš„ç ”ç©¶å£å’ï¼Œè€Œä¸”åœ¨ä¿ƒè¿›äººå·¥æ™ºèƒ½å…¬å¹³å’Œç¼“è§£è¯­éŸ³æŠ€æœ¯ä¸­çš„åè§æ–¹é¢ä¹Ÿå‘æŒ¥äº†å…³é”®ä½œç”¨ã€‚è¯­æ–™åº“ã€åŸºå‡†æµ‹è¯•ã€æ¨¡å‹å’Œæ”¶æ®å‡å¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ä¸Šå…¬å¼€è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18004v1">PDF</a> 4 pages, 5 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>è¿™æ˜¯ä¸€ç¯‡å…³äºWenetSpeech-Chuançš„ä»‹ç»ï¼Œå®ƒæ˜¯ä¸€ä¸ªé’ˆå¯¹å››å·è¯çš„å¤§å‹ã€å¼€æºè¯­éŸ³æ•°æ®è¯­æ–™åº“ã€‚è¯¥è¯­æ–™åº“é‡‡ç”¨åˆ›æ–°çš„Chuan-Pipelineæ•°æ®å¤„ç†æ¡†æ¶æ„å»ºè€Œæˆï¼ŒåŒ…æ‹¬ä¸°å¯Œçš„æ³¨é‡Šã€‚æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†é«˜è´¨é‡çš„è‡ªè¯„ä¼°æŠ¥å‘Šå’Œè¯­éŸ³åˆæˆæŠ¥å‘Šæ¥è¯„ä¼°è¯­æ–™åº“çš„æœ‰æ•ˆæ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºWenetSpeech-Chuanè®­ç»ƒçš„æ¨¡å‹åœ¨å¼€æ”¾ç³»ç»Ÿä¸­è¡¨ç°å“è¶Šï¼Œä¸å•†ä¸šæœåŠ¡ç›¸æ¯”ä¹Ÿæœ‰ç«äº‰åŠ›ã€‚è¯¥è¯­æ–™åº“ä¸ä»…é™ä½äº†æ–¹è¨€è¯­éŸ³å¤„ç†çš„é—¨æ§›ï¼Œè¿˜ä¿ƒè¿›äº†äººå·¥æ™ºèƒ½çš„å…¬å¹³æ€§å¹¶å‡è½»äº†è¯­éŸ³æŠ€æœ¯ä¸­çš„åè§é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WenetSpeech-Chuanæ˜¯ä¸€ä¸ªå¤§å‹ã€å¼€æºçš„å››å·è¯è¯­éŸ³æ•°æ®è¯­æ–™åº“ï¼Œç”¨äºè§£å†³æ–¹è¨€è¯­éŸ³æ•°æ®çš„ç¨€ç¼ºé—®é¢˜ã€‚</li>
<li>Chuan-Pipelineæ˜¯ä¸€ç§å®Œæ•´çš„æ–¹è¨€è¯­éŸ³æ•°æ®å¤„ç†æ¡†æ¶ï¼Œç”¨äºæ„å»ºWenetSpeech-Chuanè¯­æ–™åº“ã€‚</li>
<li>WenetSpeech-Chuan-Evalæ˜¯å‘å¸ƒçš„é«˜è´¨é‡è‡ªè¯„ä¼°æŠ¥å‘Šå’Œè¯­éŸ³åˆæˆæŠ¥å‘Šï¼Œç”¨äºè¯„ä¼°è¯­æ–™åº“çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åŸºäºWenetSpeech-Chuanè®­ç»ƒçš„æ¨¡å‹åœ¨å¼€æ”¾ç³»ç»Ÿä¸­è¡¨ç°å“è¶Šï¼Œä¸å•†ä¸šæœåŠ¡ç›¸æ¯”ä¹Ÿæœ‰ç«äº‰åŠ›ã€‚</li>
<li>WenetSpeech-Chuanè¯­æ–™åº“ä¿ƒè¿›äº†æ–¹è¨€è¯­éŸ³å¤„ç†çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</li>
<li>è¯¥è¯­æ–™åº“çš„å…¬å¼€ä½¿ç”¨æœ‰åŠ©äºä¿ƒè¿›äººå·¥æ™ºèƒ½çš„å…¬å¹³æ€§ï¼Œå¹¶æœ‰åŠ©äºå‡è½»è¯­éŸ³æŠ€æœ¯ä¸­çš„åè§é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18004">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_1_2.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_2_2.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_2_3.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Audiobook-CC-Controllable-Long-context-Speech-Generation-for-Multicast-Audiobook"><a href="#Audiobook-CC-Controllable-Long-context-Speech-Generation-for-Multicast-Audiobook" class="headerlink" title="Audiobook-CC: Controllable Long-context Speech Generation for Multicast   Audiobook"></a>Audiobook-CC: Controllable Long-context Speech Generation for Multicast   Audiobook</h2><p><strong>Authors:Min Liu, JingJing Yin, Xiang Zhang, Siyu Hao, Yanni Hu, Bin Lin, Yuan Feng, Hongbin Zhou, Jianhao Ye</strong></p>
<p>Existing text-to-speech systems predominantly focus on single-sentence synthesis and lack adequate contextual modeling as well as fine-grained performance control capabilities for generating coherent multicast audiobooks. To address these limitations, we propose a context-aware and emotion controllable speech synthesis framework specifically engineered for multicast audiobooks with three key innovations: a context mechanism for contextual consistency, a disentanglement paradigm to decouple style control from speech prompts for semantic consistency, and self-distillation to boost emotional expressiveness and instruction controllability. Experimental results show superior performance across the generation of narration, dialogue, and the whole chapter, significantly outperforming existing baselines. Ablation studies are conducted to validate the effectiveness of our proposed methods. Demo samples can be found in <a target="_blank" rel="noopener" href="https://everest-ai.github.io/">https://everest-ai.github.io/</a>. </p>
<blockquote>
<p>ç°æœ‰çš„æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿä¸»è¦é›†ä¸­åœ¨å•å¥åˆæˆä¸Šï¼Œç¼ºä¹è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡å»ºæ¨¡å’Œç”Ÿæˆè¿è´¯çš„å¤šæ’­æœ‰å£°ä¹¦æ‰€éœ€çš„ç²¾ç»†æ€§èƒ½æ§åˆ¶åŠŸèƒ½ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸“é—¨é’ˆå¯¹å¤šæ’­æœ‰å£°ä¹¦çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œæƒ…æ„Ÿå¯æ§çš„è¯­éŸ³åˆæˆæ¡†æ¶ï¼ŒåŒ…å«ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼šä¸€ç§ç”¨äºä¸Šä¸‹æ–‡ä¸€è‡´æ€§çš„ä¸Šä¸‹æ–‡æœºåˆ¶ï¼Œä¸€ç§å°†é£æ ¼æ§åˆ¶ä¸è¯­éŸ³æç¤ºè§£è€¦ä»¥å®ç°è¯­ä¹‰ä¸€è‡´æ€§çš„åˆ†ç¦»èŒƒå¼ï¼Œä»¥åŠè‡ªæˆ‘è’¸é¦æŠ€æœ¯æ¥æå‡æƒ…æ„Ÿè¡¨ç°åŠ›å’ŒæŒ‡ä»¤å¯æ§æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨å™è¿°ã€å¯¹è¯è¿˜æ˜¯æ•´ç« çš„ç”Ÿæˆæ–¹é¢ï¼Œè¯¥æ¡†æ¶çš„æ€§èƒ½éƒ½ä¼˜äºç°æœ‰åŸºçº¿ã€‚æ¶ˆèç ”ç©¶å·²éªŒè¯äº†æˆ‘ä»¬æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ¼”ç¤ºæ ·æœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://everest-ai.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://everest-ai.github.io/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17516v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬é’ˆå¯¹ç°æœ‰æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿåœ¨å¤šå¥å­åˆæˆæ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§é¢å‘å¤šåª’ä½“éŸ³é¢‘ä¹¦çš„è¯­å¢ƒæ„ŸçŸ¥å’Œæƒ…æ„Ÿå¯æ§çš„è¯­éŸ³åˆæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶å…·æœ‰ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼šè¯­å¢ƒæœºåˆ¶ç¡®ä¿è¯­å¢ƒä¸€è‡´æ€§ï¼Œè§£è€¦é£æ ¼æ§åˆ¶ä¸è¯­éŸ³æç¤ºä»¥ç»´æŒè¯­ä¹‰ä¸€è‡´æ€§ï¼Œä»¥åŠé€šè¿‡è‡ªæˆ‘æç‚¼æå‡æƒ…æ„Ÿè¡¨ç°åŠ›å’ŒæŒ‡ä»¤æ§åˆ¶æ€§ã€‚å®éªŒç»“æœè¯æ˜è¯¥æ¡†æ¶åœ¨å™äº‹ã€å¯¹è¯å’Œæ•´ç« ç”Ÿæˆæ–¹é¢è¡¨ç°å“è¶Šï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿåœ¨å¤„ç†å¤šå¥å­åˆæˆæ—¶å­˜åœ¨å±€é™æ€§ï¼Œç¼ºä¹è¶³å¤Ÿçš„è¯­å¢ƒå»ºæ¨¡å’Œç²¾ç»†çš„æ€§èƒ½æ§åˆ¶ã€‚</li>
<li>æå‡ºçš„è¯­éŸ³åˆæˆæ¡†æ¶å…·æœ‰ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼ŒåŒ…æ‹¬è¯­å¢ƒæœºåˆ¶ã€è§£è€¦é£æ ¼æ§åˆ¶å’Œè‡ªæˆ‘æç‚¼æŠ€æœ¯ã€‚</li>
<li>è¯­å¢ƒæœºåˆ¶ç¡®ä¿ç”Ÿæˆçš„è¯­éŸ³åœ¨è¯­å¢ƒä¸Šä¿æŒä¸€è‡´æ€§ã€‚</li>
<li>è§£è€¦é£æ ¼æ§åˆ¶ä½¿è¯­éŸ³æç¤ºä¸é£æ ¼æ§åˆ¶åˆ†ç¦»ï¼Œç»´æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>è‡ªæˆ‘æç‚¼æŠ€æœ¯æå‡äº†è¯­éŸ³çš„æƒ…æ„Ÿè¡¨ç°åŠ›å’ŒæŒ‡ä»¤æ§åˆ¶æ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å™äº‹ã€å¯¹è¯å’Œæ•´ç« ç”Ÿæˆæ–¹é¢è¡¨ç°å“è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17516">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.17516v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.17516v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.17516v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.17516v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.17516v1/page_3_2.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="VoXtream-Full-Stream-Text-to-Speech-with-Extremely-Low-Latency"><a href="#VoXtream-Full-Stream-Text-to-Speech-with-Extremely-Low-Latency" class="headerlink" title="VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency"></a>VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency</h2><p><strong>Authors:Nikita Torgashov, Gustav Eje Henter, Gabriel Skantze</strong></p>
<p>We present VoXtream, a fully autoregressive, zero-shot streaming text-to-speech (TTS) system for real-time use that begins speaking from the first word. VoXtream directly maps incoming phonemes to audio tokens using a monotonic alignment scheme and a dynamic look-ahead that does not delay onset. Built around an incremental phoneme transformer, a temporal transformer predicting semantic and duration tokens, and a depth transformer producing acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay among publicly available streaming TTS: 102 ms on GPU. Despite being trained on a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several metrics, while delivering competitive quality in both output- and full-streaming settings. Demo and code are available at <a target="_blank" rel="noopener" href="https://herimor.github.io/voxtream">https://herimor.github.io/voxtream</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†VoXtreamï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨è‡ªå›å½’çš„é›¶æ ·æœ¬æµå¼æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿï¼Œé€‚ç”¨äºå®æ—¶ä½¿ç”¨ï¼Œä»ç¬¬ä¸€ä¸ªå­—å¼€å§‹è¯´è¯ã€‚VoXtreamç›´æ¥ä½¿ç”¨å•è°ƒå¯¹é½æ–¹æ¡ˆå’Œä¸ä¼šå»¶è¿Ÿå‘éŸ³çš„åŠ¨æ€å‰ç»ï¼Œå°†ä¼ å…¥çš„éŸ³ç´ ç›´æ¥æ˜ å°„åˆ°éŸ³é¢‘ä»¤ç‰Œã€‚VoXtreamå»ºç«‹åœ¨å¢é‡éŸ³ç´ å˜æ¢å™¨å‘¨å›´ï¼Œä¸€ä¸ªé¢„æµ‹è¯­ä¹‰å’ŒæŒç»­æ—¶é—´ä»¤ç‰Œçš„æ—¶é—´å˜æ¢å™¨ï¼Œä»¥åŠä¸€ä¸ªäº§ç”Ÿå£°éŸ³ä»¤ç‰Œçš„æ·±åº¦å˜æ¢å™¨ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒVoXtreamçš„åˆå§‹å»¶è¿Ÿæ˜¯å…¬ä¼—å¯ç”¨çš„æµå¼TTSä¸­æœ€çŸ­çš„ï¼šGPUä¸Šä¸º102æ¯«ç§’ã€‚å°½ç®¡å®ƒä»…åœ¨ä¸­ç­‰è§„æ¨¡çš„9kå°æ—¶è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†å®ƒèƒ½åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡æ›´å¤§çš„åŸºçº¿æ°´å¹³ï¼ŒåŒæ—¶åœ¨è¾“å‡ºå’Œå…¨æµå¼è®¾ç½®ä¸­éƒ½æä¾›äº†å…·æœ‰ç«äº‰åŠ›çš„è´¨é‡ã€‚Demoå’Œä»£ç å¯ä»¥åœ¨ <a target="_blank" rel="noopener" href="https://herimor.github.io/voxtream">https://herimor.github.io/voxtream</a> ä¸Šæ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15969v1">PDF</a> 5 pages, 1 figure, submitted to IEEE ICASSP 2026</p>
<p><strong>æ‘˜è¦</strong></p>
<p>VoXtreamæ˜¯ä¸€æ¬¾å…¨è‡ªå›å½’ã€é›¶å°„å‡»æµæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿï¼Œé€‚ç”¨äºå®æ—¶ä½¿ç”¨ï¼Œå¯ä»ç¬¬ä¸€ä¸ªå­—å¼€å§‹å‘å£°ã€‚VoXtreamç›´æ¥ä½¿ç”¨å•è°ƒå¯¹é½æ–¹æ¡ˆå’Œæ— éœ€å»¶è¿Ÿçš„åŠ¨æ€å‰ç»ï¼Œå°†ä¼ å…¥çš„éŸ³ç´ ç›´æ¥æ˜ å°„åˆ°éŸ³é¢‘ä»¤ç‰Œã€‚é€šè¿‡æ„å»ºå¢é‡éŸ³ç´ è½¬æ¢å™¨ã€é¢„æµ‹è¯­ä¹‰å’ŒæŒç»­æ—¶é—´æ ‡è®°çš„æ—¶é—´è½¬æ¢å™¨ä»¥åŠäº§ç”Ÿå£°éŸ³æ ‡è®°çš„æ·±åº¦è½¬æ¢å™¨ï¼ŒVoXtreamè¾¾åˆ°äº†æˆ‘ä»¬å·²çŸ¥çš„å…¬å¼€å¯ç”¨æµåª’ä½“TTSä¸­æœ€ä½çš„é¦–ä¸ªå»¶è¿Ÿï¼šGPUä¸Šä¸º102æ¯«ç§’ã€‚å°½ç®¡å®ƒæ˜¯åœ¨ä¸­ç­‰è§„æ¨¡çš„9kå°æ—¶è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œä½†åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šï¼Œå®ƒè¾¾åˆ°æˆ–è¶…è¿‡äº†æ›´å¤§çš„åŸºçº¿ç³»ç»Ÿçš„è¡¨ç°ï¼ŒåŒæ—¶åœ¨è¾“å‡ºå’Œæµå¼ä¼ è¾“ç¯å¢ƒä¸­éƒ½æä¾›äº†ç«äº‰åŠ›çš„è´¨é‡ã€‚ç›¸å…³æ¼”ç¤ºå’Œä»£ç å¯è®¿é—®herimor.github.io&#x2F;voxtreamã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>VoXtreamæ˜¯ä¸€ä¸ªç”¨äºå®æ—¶ä½¿ç”¨çš„å…¨è‡ªå›å½’ã€é›¶å°„å‡»æµæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿã€‚</li>
<li>ç³»ç»Ÿå¯å°†ä¼ å…¥çš„éŸ³ç´ ç›´æ¥æ˜ å°„åˆ°éŸ³é¢‘ä»¤ç‰Œï¼Œå…·æœ‰åŠ¨æ€å‰ç»å’Œå•è°ƒå¯¹é½æ–¹æ¡ˆã€‚</li>
<li>VoXtreamé€šè¿‡å¢é‡éŸ³ç´ è½¬æ¢å™¨ã€é¢„æµ‹è¯­ä¹‰å’ŒæŒç»­æ—¶é—´çš„æ—¶é—´è½¬æ¢å™¨ä»¥åŠäº§ç”Ÿå£°éŸ³æ ‡è®°çš„æ·±åº¦è½¬æ¢å™¨å®ç°é«˜æ•ˆæ€§èƒ½ã€‚</li>
<li>VoXtreamåœ¨GPUä¸Šçš„é¦–ä¸ªå»¶è¿Ÿè¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„ä½æ°´å¹³ï¼Œä¸º102æ¯«ç§’ã€‚</li>
<li>è¯¥ç³»ç»Ÿåœ¨ä¸­ç­‰è§„æ¨¡çš„è¯­æ–™åº“ä¸Šè®­ç»ƒï¼Œä½†åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡äº†æ›´å¤§çš„åŸºçº¿ç³»ç»Ÿçš„è¡¨ç°ã€‚</li>
<li>VoXtreamåœ¨è¾“å‡ºå’Œæµå¼ä¼ è¾“ç¯å¢ƒä¸­éƒ½æä¾›äº†é«˜è´¨é‡çš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15969">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15969v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15969v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15969v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15969v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15969v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15969v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Deep-Dubbing-End-to-End-Auto-Audiobook-System-with-Text-to-Timbre-and-Context-Aware-Instruct-TTS"><a href="#Deep-Dubbing-End-to-End-Auto-Audiobook-System-with-Text-to-Timbre-and-Context-Aware-Instruct-TTS" class="headerlink" title="Deep Dubbing: End-to-End Auto-Audiobook System with Text-to-Timbre and   Context-Aware Instruct-TTS"></a>Deep Dubbing: End-to-End Auto-Audiobook System with Text-to-Timbre and   Context-Aware Instruct-TTS</h2><p><strong>Authors:Ziqi Dai, Yiting Chen, Jiacheng Xu, Liufei Xie, Yuchen Wang, Zhenchuan Yang, Bingsong Bai, Yangsheng Gao, Wenjiang Zhou, Weifeng Zhao, Ruohua Zhou</strong></p>
<p>The pipeline for multi-participant audiobook production primarily consists of three stages: script analysis, character voice timbre selection, and speech synthesis. Among these, script analysis can be automated with high accuracy using NLP models, whereas character voice timbre selection still relies on manual effort. Speech synthesis uses either manual dubbing or text-to-speech (TTS). While TTS boosts efficiency, it struggles with emotional expression, intonation control, and contextual scene adaptation. To address these challenges, we propose DeepDubbing, an end-to-end automated system for multi-participant audiobook production. The system comprises two main components: a Text-to-Timbre (TTT) model and a Context-Aware Instruct-TTS (CA-Instruct-TTS) model. The TTT model generates role-specific timbre embeddings conditioned on text descriptions. The CA-Instruct-TTS model synthesizes expressive speech by analyzing contextual dialogue and incorporating fine-grained emotional instructions. This system enables the automated generation of multi-participant audiobooks with both timbre-matched character voices and emotionally expressive narration, offering a novel solution for audiobook production. </p>
<blockquote>
<p>å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§æµç¨‹ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼šå‰§æœ¬åˆ†æã€è§’è‰²å—“éŸ³éŸ³è´¨é€‰æ‹©å’Œè¯­éŸ³åˆæˆã€‚å…¶ä¸­ï¼Œå‰§æœ¬åˆ†æå¯ä»¥ä½¿ç”¨NLPæ¨¡å‹å®ç°é«˜åº¦è‡ªåŠ¨åŒ–ï¼Œè€Œè§’è‰²å—“éŸ³éŸ³è´¨é€‰æ‹©ä»ç„¶éœ€è¦äººå·¥æ“ä½œã€‚è¯­éŸ³åˆæˆé‡‡ç”¨äººå·¥é…éŸ³æˆ–æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ã€‚è™½ç„¶TTSæŠ€æœ¯æé«˜äº†æ•ˆç‡ï¼Œä½†åœ¨æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è°ƒæ§åˆ¶å’Œä¸Šä¸‹æ–‡åœºæ™¯é€‚åº”æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†DeepDubbingï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªç»„ä»¶ï¼šæ–‡æœ¬åˆ°éŸ³è´¨ï¼ˆTTTï¼‰æ¨¡å‹å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æŒ‡ä»¤TTSï¼ˆCA-Instruct-TTSï¼‰æ¨¡å‹ã€‚TTTæ¨¡å‹æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆç‰¹å®šè§’è‰²çš„éŸ³è´¨åµŒå…¥ã€‚CA-Instruct-TTSæ¨¡å‹é€šè¿‡åˆ†æä¸Šä¸‹æ–‡å¯¹è¯å¹¶èå…¥ç²¾ç»†çš„æƒ…æ„ŸæŒ‡ä»¤ï¼Œåˆæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è¯­éŸ³ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå®ç°å¤šå‚ä¸è€…æœ‰å£°ä¹¦çš„è‡ªåŠ¨ç”Ÿæˆï¼Œæ—¢æœ‰åŒ¹é…çš„éŸ³è´¨è§’è‰²å£°éŸ³ï¼Œåˆæœ‰æƒ…æ„Ÿä¸°å¯Œçš„æ—ç™½ï¼Œä¸ºæœ‰å£°ä¹¦ç”Ÿäº§æä¾›äº†æ–°é¢–çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15845v1">PDF</a> Submitted to ICASSP 2026.Copyright 2026 IEEE. Personal use of this   material is permitted. Permission from IEEE must be obtained for all other   uses, including reprinting&#x2F;republishing, creating new collective works, for   resale or redistribution to servers or lists, or reuse of any copyrighted   component of this work. DOI will be added upon IEEE Xplore publication</p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä¸»è¦ä»‹ç»äº†å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§çš„æµç¨‹ï¼ŒåŒ…æ‹¬è„šæœ¬åˆ†æã€è§’è‰²å£°éŸ³éŸ³è‰²çš„é€‰æ‹©ä»¥åŠè¯­éŸ³åˆæˆä¸‰ä¸ªé˜¶æ®µã€‚å…¶ä¸­ï¼Œè„šæœ¬åˆ†æå¯ä»¥é€šè¿‡NLPæ¨¡å‹å®ç°è‡ªåŠ¨åŒ–ä¸”å‡†ç¡®ç‡é«˜ï¼›è§’è‰²å£°éŸ³éŸ³è‰²çš„é€‰æ‹©ä»ç„¶éœ€è¦äººå·¥æ“ä½œã€‚ä¸ºæé«˜æ•ˆç‡ï¼Œæå‡ºDeepDubbingç³»ç»Ÿï¼ŒåŒ…æ‹¬Text-to-Timbreæ¨¡å‹å’ŒContext-Aware Instruct-TTSæ¨¡å‹ï¼Œå®ç°å¤šå‚ä¸è€…æœ‰å£°ä¹¦çš„è‡ªåŠ¨åŒ–ç”Ÿæˆï¼Œå…·æœ‰éŸ³è‰²åŒ¹é…å’Œå¯Œæœ‰æƒ…æ„Ÿè¡¨è¾¾çš„æ—ç™½åŠŸèƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šå‚ä¸è€…æœ‰å£°ä¹¦ç”Ÿäº§æµç¨‹åŒ…æ‹¬è„šæœ¬åˆ†æã€è§’è‰²å£°éŸ³éŸ³è‰²é€‰æ‹©å’Œè¯­éŸ³åˆæˆä¸‰ä¸ªé˜¶æ®µã€‚</li>
<li>è„šæœ¬åˆ†æå¯ä»¥é€šè¿‡NLPæ¨¡å‹å®ç°è‡ªåŠ¨åŒ–ä¸”å‡†ç¡®ç‡é«˜ã€‚</li>
<li>è§’è‰²å£°éŸ³éŸ³è‰²çš„é€‰æ‹©ä»ç„¶éœ€è¦äººå·¥æ“ä½œã€‚</li>
<li>DeepDubbingç³»ç»Ÿæ˜¯å®ç°å¤šå‚ä¸è€…æœ‰å£°ä¹¦è‡ªåŠ¨åŒ–ç”Ÿæˆçš„å…³é”®ã€‚</li>
<li>DeepDubbingç³»ç»ŸåŒ…æ‹¬Text-to-Timbreæ¨¡å‹å’ŒContext-Aware Instruct-TTSæ¨¡å‹ä¸¤ä¸ªä¸»è¦ç»„ä»¶ã€‚</li>
<li>Text-to-Timbreæ¨¡å‹æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆè§’è‰²ç‰¹å®šçš„éŸ³è‰²åµŒå…¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15845">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15845v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15845v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15845v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15845v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15845v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Beyond-Video-to-SFX-Video-to-Audio-Synthesis-with-Environmentally-Aware-Speech"><a href="#Beyond-Video-to-SFX-Video-to-Audio-Synthesis-with-Environmentally-Aware-Speech" class="headerlink" title="Beyond Video-to-SFX: Video to Audio Synthesis with Environmentally Aware   Speech"></a>Beyond Video-to-SFX: Video to Audio Synthesis with Environmentally Aware   Speech</h2><p><strong>Authors:Xinlei Niu, Jianbo Ma, Dylan Harper-Harris, Xiangyu Zhang, Charles Patrick Martin, Jing Zhang</strong></p>
<p>The generation of realistic, context-aware audio is important in real-world applications such as video game development. While existing video-to-audio (V2A) methods mainly focus on Foley sound generation, they struggle to produce intelligible speech. Meanwhile, current environmental speech synthesis approaches remain text-driven and fail to temporally align with dynamic video content. In this paper, we propose Beyond Video-to-SFX (BVS), a method to generate synchronized audio with environmentally aware intelligible speech for given videos. We introduce a two-stage modeling method: (1) stage one is a video-guided audio semantic (V2AS) model to predict unified audio semantic tokens conditioned on phonetic cues; (2) stage two is a video-conditioned semantic-to-acoustic (VS2A) model that refines semantic tokens into detailed acoustic tokens. Experiments demonstrate the effectiveness of BVS in scenarios such as video-to-context-aware speech synthesis and immersive audio background conversion, with ablation studies further validating our design. Our demonstration is available at~\href{<a target="_blank" rel="noopener" href="https://xinleiniu.github.io/BVS-demo/%7D%7BBVS-Demo%7D">https://xinleiniu.github.io/BVS-demo/}{BVS-Demo}</a>. </p>
<blockquote>
<p>åœ¨ç°å®ä¸–ç•Œçš„åº”ç”¨ï¼ˆå¦‚æ¸¸æˆå¼€å‘ï¼‰ä¸­ï¼Œç”ŸæˆçœŸå®ã€å…·æœ‰è¯­å¢ƒæ„è¯†çš„éŸ³é¢‘è‡³å…³é‡è¦ã€‚ç°æœ‰çš„è§†é¢‘åˆ°éŸ³é¢‘ï¼ˆV2Aï¼‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨éŸ³æ•ˆå£°éŸ³ç”Ÿæˆä¸Šï¼Œä½†åœ¨ç”Ÿæˆå¯ç†è§£çš„è¯­éŸ³æ–¹é¢é‡åˆ°äº†å›°éš¾ã€‚ä¸æ­¤åŒæ—¶ï¼Œå½“å‰çš„ç¯å¢ƒè¯­éŸ³åˆæˆæ–¹æ³•ä»ç„¶æ˜¯æ–‡æœ¬é©±åŠ¨çš„ï¼Œå¹¶ä¸”ä¸èƒ½ä¸åŠ¨æ€è§†é¢‘å†…å®¹åœ¨æ—¶é—´ä¸Šè¿›è¡Œå¯¹é½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†è¶…è¶Šè§†é¢‘åˆ°éŸ³æ•ˆï¼ˆBVSï¼‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¸ºç»™å®šçš„è§†é¢‘ç”Ÿæˆå…·æœ‰ç¯å¢ƒæ„è¯†çš„åŒæ­¥å¯ç†è§£è¯­éŸ³çš„éŸ³é¢‘ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µçš„å»ºæ¨¡æ–¹æ³•ï¼šï¼ˆ1ï¼‰ç¬¬ä¸€é˜¶æ®µæ˜¯è§†é¢‘å¼•å¯¼éŸ³é¢‘è¯­ä¹‰ï¼ˆV2ASï¼‰æ¨¡å‹ï¼Œæ ¹æ®è¯­éŸ³çº¿ç´¢é¢„æµ‹ç»Ÿä¸€çš„éŸ³é¢‘è¯­ä¹‰æ ‡è®°ï¼›ï¼ˆ2ï¼‰ç¬¬äºŒé˜¶æ®µæ˜¯è§†é¢‘æ¡ä»¶è¯­ä¹‰åˆ°å£°éŸ³ï¼ˆVS2Aï¼‰æ¨¡å‹ï¼Œå®ƒå°†è¯­ä¹‰æ ‡è®°ç»†åŒ–ä¸ºè¯¦ç»†çš„å£°å­¦æ ‡è®°ã€‚å®éªŒè¡¨æ˜ï¼ŒBVSåœ¨è§†é¢‘åˆ°ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯­éŸ³åˆæˆå’Œæ²‰æµ¸å¼éŸ³é¢‘èƒŒæ™¯è½¬æ¢ç­‰åœºæ™¯ä¸­éå¸¸æœ‰æ•ˆï¼Œæ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„è®¾è®¡ã€‚æˆ‘ä»¬çš„æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://xinleiniu.github.io/BVS-demo/">BVS-Demo</a>æŸ¥çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15492v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬æå‡ºä¸€ç§åä¸ºBeyond Video-to-SFXï¼ˆBVSï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨ç”Ÿæˆä¸è§†é¢‘åŒæ­¥çš„å…·æœ‰ç¯å¢ƒæ„è¯†çš„å¯è¯†åˆ«è¯­éŸ³çš„éŸ³é¢‘ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µå»ºæ¨¡æ–¹æ³•ï¼Œé¦–å…ˆé€šè¿‡è§†é¢‘å¼•å¯¼éŸ³é¢‘è¯­ä¹‰ï¼ˆV2ASï¼‰æ¨¡å‹é¢„æµ‹åŸºäºè¯­éŸ³ç‰¹å¾çš„ç»Ÿä¸€éŸ³é¢‘è¯­ä¹‰ä»¤ç‰Œï¼Œç„¶åé€šè¿‡è§†é¢‘æ¡ä»¶è¯­ä¹‰åˆ°å£°éŸ³ï¼ˆVS2Aï¼‰æ¨¡å‹ç»†åŒ–è¯­ä¹‰ä»¤ç‰Œä¸ºè¯¦ç»†çš„å£°å­¦ä»¤ç‰Œã€‚æ­¤æ–¹æ³•èƒ½æœ‰æ•ˆåº”ç”¨äºè§†é¢‘åˆ°è¯­å¢ƒæ„ŸçŸ¥è¯­éŸ³åˆæˆå’Œæ²‰æµ¸å¼éŸ³é¢‘èƒŒæ™¯è½¬æ¢ç­‰åœºæ™¯ã€‚å…·ä½“æ¼”ç¤ºè¯·å‚è€ƒæä¾›çš„é“¾æ¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ–‡æœ¬ä»‹ç»äº†ä¸€ç§æ–°çš„è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆæ–¹æ³•Beyond Video-to-SFXï¼ˆBVSï¼‰ã€‚</li>
<li>è¯¥æ–¹æ³•æ—¨åœ¨ç”Ÿæˆå…·æœ‰ç¯å¢ƒæ„è¯†çš„å¯è¯†åˆ«è¯­éŸ³çš„éŸ³é¢‘ï¼Œé€‚ç”¨äºè§†é¢‘æ¸¸æˆå¼€å‘ç­‰ç°å®åº”ç”¨ã€‚</li>
<li>BVSé‡‡ç”¨ä¸¤é˜¶æ®µå»ºæ¨¡ï¼ŒåŒ…æ‹¬è§†é¢‘å¼•å¯¼éŸ³é¢‘è¯­ä¹‰ï¼ˆV2ASï¼‰æ¨¡å‹å’Œè§†é¢‘æ¡ä»¶è¯­ä¹‰åˆ°å£°éŸ³ï¼ˆVS2Aï¼‰æ¨¡å‹ã€‚</li>
<li>V2ASæ¨¡å‹åŸºäºè¯­éŸ³ç‰¹å¾é¢„æµ‹ç»Ÿä¸€éŸ³é¢‘è¯­ä¹‰ä»¤ç‰Œã€‚</li>
<li>VS2Aæ¨¡å‹å°†è¯­ä¹‰ä»¤ç‰Œç»†åŒ–ä¸ºè¯¦ç»†çš„å£°å­¦ä»¤ç‰Œï¼Œå®ç°éŸ³é¢‘çš„ç²¾ç»†åˆæˆã€‚</li>
<li>BVSæ–¹æ³•åœ¨è§†é¢‘åˆ°è¯­å¢ƒæ„ŸçŸ¥è¯­éŸ³åˆæˆå’Œæ²‰æµ¸å¼éŸ³é¢‘èƒŒæ™¯è½¬æ¢ç­‰åœºæ™¯å…·æœ‰åº”ç”¨ä»·å€¼ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15492">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15492v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15492v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15492v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15492v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Frustratingly-Easy-Data-Augmentation-for-Low-Resource-ASR"><a href="#Frustratingly-Easy-Data-Augmentation-for-Low-Resource-ASR" class="headerlink" title="Frustratingly Easy Data Augmentation for Low-Resource ASR"></a>Frustratingly Easy Data Augmentation for Low-Resource ASR</h2><p><strong>Authors:Katsumi Ibaraki, David Chiang</strong></p>
<p>This paper introduces three self-contained data augmentation methods for low-resource Automatic Speech Recognition (ASR). Our techniques first generate novel textâ€“using gloss-based replacement, random replacement, or an LLM-based approachâ€“and then apply Text-to-Speech (TTS) to produce synthetic audio. We apply these methods, which leverage only the original annotated data, to four languages with extremely limited resources (Vatlongos, Nashta, Shinekhen Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a combination of the original audio and generated synthetic data yields significant performance gains, including a 14.3% absolute WER reduction for Nashta. The methods prove effective across all four low-resource languages and also show utility for high-resource languages like English, demonstrating their broad applicability. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸‰ç§ç”¨äºä½èµ„æºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„è‡ªä¸»æ•°æ®å¢å¼ºæ–¹æ³•ã€‚æˆ‘ä»¬çš„æŠ€æœ¯é¦–å…ˆä½¿ç”¨åŸºäºæœ¯è¯­æ›¿æ¢ã€éšæœºæ›¿æ¢æˆ–åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹æ³•ç”Ÿæˆæ–°çš„æ–‡æœ¬ï¼Œç„¶ååº”ç”¨æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ç”ŸæˆåˆæˆéŸ³é¢‘ã€‚æˆ‘ä»¬åªåœ¨æœ‰é™èµ„æºçš„å››ç§è¯­è¨€ï¼ˆç“¦ç‰¹éš†æˆˆæ–¯è¯­ã€çº³æ–¯å¡”è¯­ã€è°¢å†…è‚¯å¸ƒé‡Œäºšç‰¹è¯­å’Œå¡å¡è´è¯­ï¼‰ä¸­åº”ç”¨è¿™äº›æ–¹æ³•ä½¿ç”¨åŸå§‹æ ‡æ³¨æ•°æ®ã€‚é€šè¿‡å¯¹é¢„è®­ç»ƒçš„Wav2Vec2-XLSR-53æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç»“åˆåŸå§‹éŸ³é¢‘å’Œç”Ÿæˆçš„åˆæˆæ•°æ®ï¼Œå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…¶ä¸­çº³æ–¯å¡”è¯­çš„ç»å¯¹å­—è¯é”™è¯¯ç‡ï¼ˆWERï¼‰é™ä½äº†14.3%ã€‚è¿™äº›æ–¹æ³•åœ¨å››ç§ä½èµ„æºè¯­è¨€ä¸­éƒ½è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”åœ¨é«˜èµ„æºè¯­è¨€å¦‚è‹±è¯­ä¸­ä¹Ÿæ˜¾ç¤ºå‡ºå®ç”¨æ€§ï¼Œè¯æ˜äº†å…¶å¹¿æ³›çš„åº”ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15373v1">PDF</a> 5 pages, 2 figures, 2 tables, submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸‰ç§ä¸ºä½èµ„æºè¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰è‡ªæˆ‘å®Œå–„çš„æ•°æ®å¢å¼ºæ–¹æ³•ã€‚è¿™äº›æ–¹æ³•é¦–å…ˆåˆ©ç”¨åŸºäºè¯ä¹‰çš„æ›¿ä»£ã€éšæœºæ›¿ä»£æˆ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹æ³•ç”Ÿæˆæ–°æ–‡æœ¬ï¼Œç„¶ååº”ç”¨æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯ç”ŸæˆåˆæˆéŸ³é¢‘ã€‚è¿™äº›æ–¹æ³•ä»…åˆ©ç”¨åŸå§‹æ ‡æ³¨æ•°æ®ï¼Œåº”ç”¨äºå››ç§èµ„æºæåº¦åŒ®ä¹çš„è¯­è¨€ï¼ˆVatlongosã€Nashtaã€Shinekhen Buryatå’ŒKakabeï¼‰ã€‚é€šè¿‡é¢„è®­ç»ƒçš„Wav2Vec2-XLSR-53æ¨¡å‹å¯¹åŸå§‹éŸ³é¢‘å’Œç”Ÿæˆåˆæˆæ•°æ®çš„ç»„åˆè¿›è¡Œå¾®è°ƒï¼Œå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…¶ä¸­Nashtaè¯­è¨€çš„ç»å¯¹è¯é”™è¯¯ç‡ï¼ˆWERï¼‰é™ä½äº†14.3%ã€‚è¿™äº›æ–¹æ³•åœ¨å››ç§ä½èµ„æºè¯­è¨€ä¸­éƒ½è¡¨ç°å‡ºæœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨é«˜èµ„æºè¯­è¨€å¦‚è‹±è¯­ä¸­ä¹Ÿæ˜¾ç¤ºäº†å…¶åº”ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»ä¸‰ç§è‡ªæˆ‘å®Œå–„çš„æ•°æ®å¢å¼ºæ–¹æ³•ç”¨äºä½èµ„æºè¯­éŸ³è¯†åˆ«ã€‚</li>
<li>æ–¹æ³•åŒ…æ‹¬åŸºäºè¯ä¹‰çš„æ›¿ä»£ã€éšæœºæ›¿ä»£æˆ–å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–°æ–‡æœ¬ã€‚</li>
<li>ä½¿ç”¨æ–‡æœ¬è½¬è¯­éŸ³æŠ€æœ¯å°†æ–°æ–‡æœ¬è½¬åŒ–ä¸ºåˆæˆéŸ³é¢‘ã€‚</li>
<li>è¿™äº›æ–¹æ³•ä»…åˆ©ç”¨åŸå§‹æ ‡æ³¨æ•°æ®ï¼Œé€‚ç”¨äºå¤šç§è¯­è¨€ã€‚</li>
<li>åœ¨å››ç§èµ„æºæåº¦åŒ®ä¹çš„è¯­è¨€ä¸­æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>é€šè¿‡å¯¹é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒï¼Œå®ç°äº†è¯é”™è¯¯ç‡çš„æ˜¾è‘—é™ä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15373">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15373v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15373v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15373v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15373v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.15373v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Do-You-Hear-What-I-Mean-Quantifying-the-Instruction-Perception-Gap-in-Instruction-Guided-Expressive-Text-To-Speech-Systems"><a href="#Do-You-Hear-What-I-Mean-Quantifying-the-Instruction-Perception-Gap-in-Instruction-Guided-Expressive-Text-To-Speech-Systems" class="headerlink" title="Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in   Instruction-Guided Expressive Text-To-Speech Systems"></a>Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in   Instruction-Guided Expressive Text-To-Speech Systems</h2><p><strong>Authors:Yi-Cheng Lin, Huang-Cheng Chou, Tzu-Chieh Wei, Kuan-Yu Chen, Hung-yi Lee</strong></p>
<p>Instruction-guided text-to-speech (ITTS) enables users to control speech generation through natural language prompts, offering a more intuitive interface than traditional TTS. However, the alignment between user style instructions and listener perception remains largely unexplored. This work first presents a perceptual analysis of ITTS controllability across two expressive dimensions (adverbs of degree and graded emotion intensity) and collects human ratings on speaker age and word-level emphasis attributes. To comprehensively reveal the instruction-perception gap, we provide a data collection with large-scale human evaluations, named Expressive VOice Control (E-VOC) corpus. Furthermore, we reveal that (1) gpt-4o-mini-tts is the most reliable ITTS model with great alignment between instruction and generated utterances across acoustic dimensions. (2) The 5 analyzed ITTS systems tend to generate Adult voices even when the instructions ask to use child or Elderly voices. (3) Fine-grained control remains a major challenge, indicating that most ITTS systems have substantial room for improvement in interpreting slightly different attribute instructions. </p>
<blockquote>
<p>æŒ‡ä»¤å¼•å¯¼å‹æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆITTSï¼‰å…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºæ¥æ§åˆ¶è¯­éŸ³ç”Ÿæˆï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªæ¯”ä¼ ç»ŸTTSæ›´ç›´è§‚çš„ç•Œé¢ã€‚ç„¶è€Œï¼Œç”¨æˆ·é£æ ¼æŒ‡ä»¤å’Œå¬ä¼—æ„ŸçŸ¥ä¹‹é—´çš„å¯¹é½ä»ç„¶å¾ˆå¤§ç¨‹åº¦ä¸Šæœªè¢«æ¢ç´¢ã€‚è¿™é¡¹å·¥ä½œé¦–å…ˆé’ˆå¯¹ITTSåœ¨ä¸¤ä¸ªè¡¨è¾¾ç»´åº¦ï¼ˆç¨‹åº¦å‰¯è¯å’Œåˆ†çº§æƒ…ç»ªå¼ºåº¦ï¼‰ä¸Šçš„å¯æ§æ€§è¿›è¡Œäº†æ„ŸçŸ¥åˆ†æï¼Œå¹¶å¯¹è¯´è¯äººçš„å¹´é¾„å’Œå•è¯çº§åˆ«çš„å¼ºè°ƒå±æ€§è¿›è¡Œäº†äººç±»è¯„åˆ†ã€‚ä¸ºäº†å…¨é¢æ­ç¤ºæŒ‡ä»¤æ„ŸçŸ¥å·®è·ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¤§è§„æ¨¡äººç±»è¯„ä¼°çš„æ•°æ®æ”¶é›†ï¼Œåä¸ºè¡¨ç°åŠ›è¯­éŸ³æ§åˆ¶ï¼ˆE-VOCï¼‰è¯­æ–™åº“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ­ç¤ºï¼šï¼ˆ1ï¼‰gpt-4o-mini-ttsæ˜¯æœ€å¯é çš„ITTSæ¨¡å‹ï¼Œåœ¨å£°å­¦ç»´åº¦ä¸Šï¼ŒæŒ‡ä»¤å’Œç”Ÿæˆè¯è¯­ä¹‹é—´çš„å¯¹é½æ•ˆæœå¾ˆå¥½ã€‚ï¼ˆ2ï¼‰è¿™äº”ä¸ªåˆ†æçš„ITTSç³»ç»Ÿå€¾å‘äºç”Ÿæˆæˆå¹´äººå£°éŸ³ï¼Œå³ä½¿æŒ‡ä»¤è¦æ±‚ä½¿ç”¨å„¿ç«¥æˆ–è€å¹´äººå£°éŸ³ã€‚ï¼ˆ3ï¼‰ç²¾ç»†æ§åˆ¶ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ï¼Œè¿™è¡¨æ˜å¤§å¤šæ•°ITTSç³»ç»Ÿåœ¨è§£é‡Šç•¥æœ‰ä¸åŒçš„å±æ€§æŒ‡ä»¤æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13989v3">PDF</a> Submission to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>æŒ‡ä»¤å¼•å¯¼å¼æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆITTSï¼‰å…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºæ§åˆ¶è¯­éŸ³ç”Ÿæˆï¼Œç›¸è¾ƒäºä¼ ç»ŸTTSæä¾›äº†æ›´ç›´è§‚çš„æ“ä½œç•Œé¢ã€‚ç„¶è€Œï¼Œç”¨æˆ·æŒ‡ä»¤é£æ ¼ä¸å¬ä¼—æ„ŸçŸ¥ä¹‹é—´çš„å¯¹é½ç¨‹åº¦å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æœ¬ç ”ç©¶é¦–å…ˆé’ˆå¯¹ITTSçš„å¯æ§æ€§è¿›è¡Œæ„ŸçŸ¥åˆ†æï¼Œæ¶µç›–ç¨‹åº¦å‰¯è¯å’Œåˆ†çº§æƒ…æ„Ÿå¼ºåº¦ä¸¤ä¸ªè¡¨è¾¾ç»´åº¦ï¼Œå¹¶æ”¶é›†äººç±»è¯„ä»·è€…å…³äºè¯´è¯äººå¹´é¾„å’Œå•è¯çº§åˆ«å¼ºè°ƒå±æ€§çš„è¯„åˆ†ã€‚ä¸ºäº†å…¨é¢æ­ç¤ºæŒ‡ä»¤ä¸æ„ŸçŸ¥ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬æä¾›äº†å¤§è§„æ¨¡äººç±»è¯„ä¼°çš„æ•°æ®æ”¶é›†ï¼Œåä¸ºè¡¨è¾¾æ€§è¯­éŸ³æ§åˆ¶ï¼ˆE-VOCï¼‰è¯­æ–™åº“ã€‚ç ”ç©¶å‘ç°ï¼ŒGPT-4o-mini-ttsæ˜¯å¯é åº¦æœ€é«˜çš„ITTSæ¨¡å‹ï¼ŒæŒ‡ä»¤ä¸ç”Ÿæˆçš„è¯­éŸ³ç‰‡æ®µåœ¨å£°å­¦ç»´åº¦ä¸Šçš„å¯¹é½åº¦è‰¯å¥½ã€‚ä½†å­˜åœ¨ç³»ç»Ÿç”Ÿæˆçš„å£°éŸ³ä¸å®é™…æŒ‡ä»¤è¦æ±‚çš„å„¿ç«¥æˆ–è€å¹´å£°éŸ³å·®å¼‚è¾ƒå¤§ï¼Œç²¾ç»†æ§åˆ¶ä»æ˜¯ä¸»è¦æŒ‘æˆ˜ï¼Œæ„å‘³ç€å¤§å¤šæ•°ITTSç³»ç»Ÿåœ¨è§£è¯»ç»†å¾®å±æ€§æŒ‡ä»¤æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ITTSå…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºæ§åˆ¶è¯­éŸ³ç”Ÿæˆï¼Œå…¶ç•Œé¢ç›¸è¾ƒäºä¼ ç»ŸTTSæ›´ä¸ºç›´è§‚ã€‚</li>
<li>æŒ‡ä»¤å¼•å¯¼å¼æ–‡æœ¬è½¬è¯­éŸ³åœ¨æ„ŸçŸ¥åˆ†ææ–¹é¢ä»æœ‰è®¸å¤šæœªçŸ¥é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å…³äºç”¨æˆ·æŒ‡ä»¤é£æ ¼ä¸å¬ä¼—æ„ŸçŸ¥çš„å¯¹é½ã€‚</li>
<li>E-VOCè¯­æ–™åº“ç”¨äºå…¨é¢æ­ç¤ºæŒ‡ä»¤ä¸æ„ŸçŸ¥ä¹‹é—´çš„å·®è·ï¼Œé€šè¿‡å¤§è§„æ¨¡äººç±»è¯„ä¼°çš„æ•°æ®æ”¶é›†æ¥å®ç°ã€‚</li>
<li>GPT-4o-mini-ttsæ˜¯å¯é åº¦æœ€é«˜çš„ITTSæ¨¡å‹ï¼Œå…¶åœ¨å£°å­¦ç»´åº¦ä¸Šçš„æŒ‡ä»¤ä¸ç”Ÿæˆè¯­éŸ³çš„å¯¹é½åº¦è¡¨ç°æœ€ä½³ã€‚</li>
<li>ITTSç³»ç»Ÿåœ¨ç”Ÿæˆç‰¹å®šå£°éŸ³ï¼ˆå¦‚å„¿ç«¥æˆ–è€å¹´å£°éŸ³ï¼‰æ—¶å­˜åœ¨åå·®ï¼Œå®é™…ç”Ÿæˆçš„å¾€å¾€åå‘äºæˆå¹´å£°éŸ³ã€‚</li>
<li>ITTSåœ¨ç²¾ç»†æ§åˆ¶æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå³è§£è¯»ç»†å¾®å±æ€§æŒ‡ä»¤çš„èƒ½åŠ›æœ‰å¾…æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13989">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.13989v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.13989v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.13989v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.13989v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.13989v3/page_3_1.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="LTA-thinker-Latent-Thought-Augmented-Training-Framework-for-Large-Language-Models-on-Complex-Reasoning"><a href="#LTA-thinker-Latent-Thought-Augmented-Training-Framework-for-Large-Language-Models-on-Complex-Reasoning" class="headerlink" title="LTA-thinker: Latent Thought-Augmented Training Framework for Large   Language Models on Complex Reasoning"></a>LTA-thinker: Latent Thought-Augmented Training Framework for Large   Language Models on Complex Reasoning</h2><p><strong>Authors:Jiaqi Wang, Binquan Ji, Haibo Luo, Yiyang Qi, Ruiting Li, Huiyan Wang, Yuantao Han, Cangyi Yang, jiaxu Zhang, Feiliang Ren</strong></p>
<p>Complex Reasoning in Large Language Models can be dynamically optimized using Test-Time Scaling (TTS) to mitigate Overthinking. Methods such as Coconut, SoftCoT and its variant are effective in continuous latent space inference, the core bottleneck still lies in the efficient generation and utilization of high-quality Latent Thought. Drawing from the theory of SoftCoT++ that a larger variance in the generated Latent Thought distribution more closely approximates the golden truth distribution, we propose a Latent Thought-Augmented Training Frameworkâ€“LTA-Thinker, which improves distributional variance and enhances reasoning performance from two perspectives. First, LTA-Thinker constructs a Latent Thought generation architecture based on a learnable prior. This architecture aims to increase the variance distribution of generated Latent Thought Vectors in order to simplify the overall structure and raise the performance ceiling. Second, LTA-Thinker introduces a distribution-based directional optimization paradigm that jointly constrains both distribution locality and distribution scale. This mechanism improves information efficiency and computational cost through a multi-objective co-training strategy, which combines standard Supervised Fine-Tuning (SFT) loss with two novel losses: Semantic Alignment Loss, which utilizes KL divergence to ensure that the Latent Thought is highly relevant to the semantics of the question; Reasoning Focus Loss, which utilizes a contrastive learning mechanism to guide the model to focus on the most critical reasoning steps. Experiments show that LTA-thinker achieves state-of-the-art (SOTA) performance among various baselines and demonstrates a higher performance ceiling and better scaling effects. </p>
<blockquote>
<p>åœ¨å¤§è¯­è¨€æ¨¡å‹çš„å¤æ‚æ¨ç†ä¸­ï¼Œå¯ä»¥é€šè¿‡æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰è¿›è¡ŒåŠ¨æ€ä¼˜åŒ–ï¼Œä»¥å‡è½»è¿‡åº¦æ€è€ƒã€‚æ¤°å­æ•°ã€SoftCoTåŠå…¶å˜ç§ç­‰æ–¹æ³•åœ¨è¿ç»­æ½œåœ¨ç©ºé—´æ¨ç†ä¸­æ•ˆæœæ˜¾è‘—ï¼Œä½†æ ¸å¿ƒç“¶é¢ˆä»åœ¨äºé«˜æ•ˆç”Ÿæˆå’Œåˆ©ç”¨é«˜è´¨é‡çš„æ½œåœ¨æ€ç»´ã€‚æ ¹æ®SoftCoT++çš„ç†è®ºï¼Œç”Ÿæˆçš„æ½œåœ¨æ€ç»´åˆ†å¸ƒåœ¨æ›´å¤§çš„æ–¹å·®ä¸‹æ›´æ¥è¿‘çœŸå®åˆ†å¸ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæ½œåœ¨æ€ç»´çš„è®­ç»ƒæ¡†æ¶â€”â€”LTA-Thinkerï¼Œä»ä¸¤ä¸ªæ–¹é¢æé«˜åˆ†å¸ƒæ–¹å·®å¹¶å¢å¼ºæ¨ç†æ€§èƒ½ã€‚é¦–å…ˆï¼ŒLTA-Thinkeræ„å»ºäº†ä¸€ä¸ªåŸºäºå¯å­¦ä¹ å…ˆéªŒçš„æ½œåœ¨æ€ç»´ç”Ÿæˆæ¶æ„ã€‚è¯¥æ¶æ„æ—¨åœ¨å¢åŠ ç”Ÿæˆçš„æ½œåœ¨æ€ç»´å‘é‡çš„æ–¹å·®åˆ†å¸ƒï¼Œä»¥ç®€åŒ–æ•´ä½“ç»“æ„å¹¶æé«˜æ€§èƒ½ä¸Šé™ã€‚å…¶æ¬¡ï¼ŒLTA-Thinkerå¼•å…¥äº†ä¸€ç§åŸºäºåˆ†å¸ƒçš„æ–¹å‘ä¼˜åŒ–èŒƒå¼ï¼ŒåŒæ—¶çº¦æŸåˆ†å¸ƒå±€éƒ¨æ€§å’Œåˆ†å¸ƒè§„æ¨¡ã€‚è¯¥æœºåˆ¶é€šè¿‡å¤šç›®æ ‡è”åˆè®­ç»ƒç­–ç•¥æé«˜äº†ä¿¡æ¯æ•ˆç‡å’Œè®¡ç®—æˆæœ¬ï¼Œç»“åˆæ ‡å‡†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æŸå¤±ä¸ä¸¤ç§æ–°å‹æŸå¤±ï¼šè¯­ä¹‰å¯¹é½æŸå¤±ï¼Œåˆ©ç”¨KLæ•£åº¦ç¡®ä¿æ½œåœ¨æ€ç»´ä¸é—®é¢˜çš„è¯­ä¹‰é«˜åº¦ç›¸å…³ï¼›æ¨ç†ç„¦ç‚¹æŸå¤±ï¼Œåˆ©ç”¨å¯¹æ¯”å­¦ä¹ æœºåˆ¶å¼•å¯¼æ¨¡å‹å…³æ³¨æœ€å…³é”®çš„æ¨ç†æ­¥éª¤ã€‚å®éªŒè¡¨æ˜ï¼ŒLTA-thinkeråœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼ˆSOTAï¼‰çš„æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†æ›´é«˜çš„æ€§èƒ½ä¸Šé™å’Œæ›´å¥½çš„æ‰©å±•æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12875v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­åˆ©ç”¨æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰è¿›è¡ŒåŠ¨æ€ä¼˜åŒ–ä»¥å‡å°‘è¿‡åº¦æ€è€ƒçš„æ–¹æ³•ã€‚æ–‡ç« ä»‹ç»äº†Coconutã€SoftCoTåŠå…¶å˜ä½“ç­‰æ–¹æ³•åœ¨è¿ç»­æ½œåœ¨ç©ºé—´æ¨ç†ä¸­çš„åº”ç”¨ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ½œåœ¨æ€ç»´å¢å¼ºè®­ç»ƒæ¡†æ¶LTA-Thinkerï¼Œæ—¨åœ¨æé«˜åˆ†å¸ƒæ–¹å·®å¹¶å¢å¼ºæ¨ç†æ€§èƒ½ã€‚LTA-Thinkerä»ä¸¤ä¸ªæ–¹é¢è¿›è¡Œæ”¹è¿›ï¼šæ„å»ºåŸºäºå¯å­¦ä¹ å…ˆéªŒçš„æ½œåœ¨æ€ç»´ç”Ÿæˆæ¶æ„ï¼Œå¢åŠ ç”Ÿæˆæ½œåœ¨æ€ç»´å‘é‡çš„æ–¹å·®åˆ†å¸ƒï¼›å¼•å…¥åŸºäºåˆ†å¸ƒçš„æ–¹å‘ä¼˜åŒ–èŒƒå¼ï¼Œè”åˆçº¦æŸåˆ†å¸ƒå±€éƒ¨æ€§å’Œåˆ†å¸ƒè§„æ¨¡ã€‚å®éªŒè¡¨æ˜ï¼ŒLTA-Thinkeråœ¨å¤šç§åŸºçº¿æ–¹æ³•ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œå…·æœ‰æ›´é«˜çš„æ€§èƒ½ä¸Šé™å’Œæ›´å¥½çš„æ‰©å±•æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¤æ‚æ¨ç†å¯ä»¥é€šè¿‡æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰è¿›è¡ŒåŠ¨æ€ä¼˜åŒ–ï¼Œä»¥å‡è½»è¿‡åº¦æ€è€ƒçš„é—®é¢˜ã€‚</li>
<li>SoftCoT++ç†è®ºè¡¨æ˜ï¼Œæ›´å¤§çš„æ½œåœ¨æ€ç»´åˆ†å¸ƒæ–¹å·®æ›´æ¥è¿‘çœŸå®åˆ†å¸ƒã€‚</li>
<li>LTA-Thinkeræå‡ºäº†ä¸€ç§æ½œåœ¨æ€ç»´å¢å¼ºè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨æé«˜åˆ†å¸ƒæ–¹å·®å¹¶å¢å¼ºæ¨ç†æ€§èƒ½ã€‚</li>
<li>LTA-Thinkeræ„å»ºäº†ä¸€ä¸ªåŸºäºå¯å­¦ä¹ å…ˆéªŒçš„æ½œåœ¨æ€ç»´ç”Ÿæˆæ¶æ„ã€‚</li>
<li>LTA-Thinkerå¼•å…¥äº†åŸºäºåˆ†å¸ƒçš„æ–¹å‘ä¼˜åŒ–èŒƒå¼ï¼Œè”åˆçº¦æŸåˆ†å¸ƒå±€éƒ¨æ€§å’Œåˆ†å¸ƒè§„æ¨¡ã€‚</li>
<li>LTA-Thinkeré‡‡ç”¨å¤šç›®æ ‡è”åˆè®­ç»ƒç­–ç•¥ï¼Œç»“åˆæ ‡å‡†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æŸå¤±ä¸ä¸¤ç§æ–°æŸå¤±ï¼šè¯­ä¹‰å¯¹é½æŸå¤±å’Œæ¨ç†ç„¦ç‚¹æŸå¤±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12875">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.12875v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.12875v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.12875v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Building-Coding-Agents-via-Entropy-Enhanced-Multi-Turn-Preference-Optimization"><a href="#Building-Coding-Agents-via-Entropy-Enhanced-Multi-Turn-Preference-Optimization" class="headerlink" title="Building Coding Agents via Entropy-Enhanced Multi-Turn Preference   Optimization"></a>Building Coding Agents via Entropy-Enhanced Multi-Turn Preference   Optimization</h2><p><strong>Authors:Jiahao Yu, Zelei Cheng, Xian Wu, Xinyu Xing</strong></p>
<p>Software engineering presents complex, multi-step challenges for Large Language Models (LLMs), requiring reasoning over large codebases and coordinated tool use. The difficulty of these tasks is exemplified by benchmarks like SWE-bench, where current LLMs still struggle to resolve real-world issues.   A promising approach to enhance performance is test-time scaling (TTS), but its gains are heavily dependent on the diversity of model outputs.   While standard alignment methods such as Direct Preference Optimization (DPO) and Kahneman-Tversky Optimization (KTO) are effective at aligning model outputs with human preferences, this process can come at the cost of reduced diversity, limiting the effectiveness of TTS.   Additionally, existing preference optimization algorithms are typically designed for single-turn tasks and do not fully address the complexities of multi-turn reasoning and tool integration required for interactive coding agents.   To bridge this gap, we introduce EntroPO, an entropy-enhanced framework that adapts existing preference optimization algorithms to the multi-turn, tool-assisted setting.   EntroPO augments the preference objective to explicitly preserve policy entropy and generalizes learning to optimize over multi-turn interactions rather than single-turn responses.   We validate EntroPO by fine-tuning a diverse suite of models from different families and sizes (up to 106B parameters).   To maximize performance gains from TTS, we further propose a hybrid best-trajectory selection scheme combining a learned verifier model with model free approaches.   On the \swebench leaderboard, our approach establishes new state-of-the-art results among open-weight models. A 30B parameter model trained with EntroPO ranks 1st on \lite and 4th on \verified on the open-weight leaderboard, surpassed only by models with over 10x more parameters(\eg$&gt;$350B). </p>
<blockquote>
<p>è½¯ä»¶å·¥ç¨‹ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¸¦æ¥äº†å¤æ‚ã€å¤šæ­¥éª¤çš„æŒ‘æˆ˜ï¼Œéœ€è¦å¤„ç†å¤§å‹ä»£ç åº“å¹¶è¿›è¡Œå·¥å…·åè°ƒã€‚è¿™äº›ä»»åŠ¡çš„éš¾åº¦ä½“ç°åœ¨å¦‚SWE-benchç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œå½“å‰LLMåœ¨è§£å†³ç°å®ä¸–ç•Œé—®é¢˜æ—¶ä»é¢ä¸´å›°éš¾ã€‚ä¸€ç§æé«˜æ€§èƒ½çš„æœ‰å‰é€”çš„æ–¹æ³•æ˜¯æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰ï¼Œä½†å…¶æ”¶ç›Šåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ¨¡å‹è¾“å‡ºçš„å¤šæ ·æ€§ã€‚è™½ç„¶ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å’Œå¡å†…æ›¼-ç‰¹æ²ƒæ–¯åŸºä¼˜åŒ–ï¼ˆKTOï¼‰ç­‰æ ‡å‡†å¯¹é½æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å°†æ¨¡å‹è¾“å‡ºä¸äººç±»çš„åå¥½å¯¹é½ï¼Œä½†è¿™ä¸ªè¿‡ç¨‹å¯èƒ½ä¼šå¯¼è‡´å¤šæ ·æ€§é™ä½ï¼Œä»è€Œé™åˆ¶äº†TTSçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„åå¥½ä¼˜åŒ–ç®—æ³•é€šå¸¸æ˜¯ä¸ºå•è½®ä»»åŠ¡è®¾è®¡çš„ï¼Œå¹¶ä¸èƒ½å®Œå…¨è§£å†³å¤šè½®æ¨ç†å’Œå·¥å…·é›†æˆæ‰€éœ€çš„äº¤äº’ç¼–ç ä»£ç†çš„å¤æ‚æ€§ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†EntroPOï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç†µå¢å¼ºçš„æ¡†æ¶ï¼Œå®ƒé€‚åº”äº†ç°æœ‰çš„åå¥½ä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºå¤šè½®ã€å·¥å…·è¾…åŠ©çš„ç¯å¢ƒã€‚EntroPOé€šè¿‡å¢å¼ºåå¥½ç›®æ ‡æ¥æ˜¾å¼åœ°ä¿ç•™ç­–ç•¥ç†µï¼Œå¹¶å°†å­¦ä¹ æ¨å¹¿åˆ°ä¼˜åŒ–å¤šè½®äº¤äº’è€Œä¸æ˜¯å•è½®å“åº”ã€‚æˆ‘ä»¬é€šè¿‡å¾®è°ƒæ¥è‡ªä¸åŒå®¶æ—å’Œè§„æ¨¡çš„å¤šæ ·åŒ–æ¨¡å‹ï¼ˆå‚æ•°é«˜è¾¾106Bï¼‰æ¥éªŒè¯EntroPOçš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†æœ€å¤§é™åº¦åœ°æé«˜TTSçš„æ€§èƒ½æ”¶ç›Šï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§æ··åˆçš„æœ€ä½³è½¨è¿¹é€‰æ‹©æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆç»“åˆäº†å­¦ä¹ éªŒè¯æ¨¡å‹å’Œæ— æ¨¡å‹æ–¹æ³•ã€‚åœ¨Swebenchæ’è¡Œæ¦œä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ ‘ç«‹äº†å¼€æ”¾æƒé‡æ¨¡å‹ä¸­çš„æœ€æ–°æŠ€æœ¯æ ‡æ†ã€‚ä½¿ç”¨EntroPOè®­ç»ƒçš„å‚æ•°ä¸º30Bçš„æ¨¡å‹åœ¨å¼€æ”¾æƒé‡æ’è¡Œæ¦œä¸Šçš„\liteæ’åç¬¬ä¸€ï¼Œåœ¨\verifiedæ’åç¬¬å››ï¼Œä»…è¢«å‚æ•°è¶…è¿‡æˆ‘ä»¬åå€ä»¥ä¸Šçš„æ¨¡å‹ï¼ˆä¾‹å¦‚å¤§äº350Bå‚æ•°çš„æ¨¡å‹ï¼‰è¶…è¶Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12434v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä»‹ç»äº†è½¯ä»¶å·¥ç¨‹å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬åœ¨å¤§è§„æ¨¡ä»£ç åº“ä¸Šè¿›è¡Œæ¨ç†å’Œåè°ƒå·¥å…·çš„ä½¿ç”¨ã€‚ä¸ºæå‡æ€§èƒ½ï¼Œä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•æ˜¯æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰ï¼Œä½†å…¶æ”¶ç›Šé«˜åº¦ä¾èµ–äºæ¨¡å‹è¾“å‡ºçš„å¤šæ ·æ€§ã€‚è™½ç„¶ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å’Œå¡å†…æ›¼-ç‰¹ç»´å°”æ–¯åŸºä¼˜åŒ–ï¼ˆKTOï¼‰ç­‰æ ‡å‡†å¯¹é½æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ï¼Œè¿™ä¸€è¿‡ç¨‹å¯èƒ½ä¼šé™ä½å¤šæ ·æ€§ï¼Œé™åˆ¶äº†TTSçš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¼•å…¥EntroPOæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€‚åº”äºå¤šå›åˆå·¥å…·è¾…åŠ©è®¾ç½®ï¼Œé€šè¿‡ä¼˜åŒ–åå¥½ç›®æ ‡æ¥æ˜ç¡®ä¿ç•™ç­–ç•¥ç†µï¼Œå¹¶ä¼˜åŒ–å¤šå›åˆäº¤äº’è€Œéå•å›åˆå“åº”ã€‚å®éªŒéªŒè¯äº†EntroPOçš„æœ‰æ•ˆæ€§ï¼Œåœ¨è½¯ä»¶å·¥ç¨‹æŠ€æœ¯ç«èµ›ä¸­è·å¾—é¢†å…ˆæ°´å¹³ã€‚ä½¿ç”¨EntroPOè®­ç»ƒçš„å‚æ•°ä¸ºä¸‰åäº¿çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¬å¼€æƒé‡æ’è¡Œæ¦œä¸Šå–å¾—äº†ä¼˜å¼‚æˆç»©ã€‚æ€»çš„æ¥è¯´ï¼Œè¯¥æ–‡å…³æ³¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§£å†³è½¯ä»¶å·¥ç¨‹æŒ‘æˆ˜æ–¹é¢çš„è¿›å±•ä»¥åŠé€šè¿‡æ”¹è¿›çš„æµ‹è¯•æ—¶é—´ç¼©æ”¾ç­–ç•¥æé«˜å…¶æ€§èƒ½çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯ä¸ƒä¸ªå…³é”®è¦ç‚¹ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§£å†³è½¯ä»¶å·¥ç¨‹æŒ‘æˆ˜æ—¶é¢ä¸´æ¨ç†å’Œåè°ƒå·¥å…·ä½¿ç”¨çš„å¤æ‚é—®é¢˜ã€‚</li>
<li>æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰æ˜¯æé«˜æ¨¡å‹æ€§èƒ½çš„ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ï¼Œä½†å…¶æˆåŠŸå–å†³äºæ¨¡å‹è¾“å‡ºçš„å¤šæ ·æ€§ã€‚</li>
<li>æ ‡å‡†å¯¹é½æ–¹æ³•å¦‚ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å’Œå¡å†…æ›¼-ç‰¹ç»´å°”æ–¯åŸºä¼˜åŒ–ï¼ˆKTOï¼‰å¯èƒ½é™ä½æ¨¡å‹è¾“å‡ºçš„å¤šæ ·æ€§ã€‚</li>
<li>EntroPOæ¡†æ¶é€šè¿‡é€‚åº”å¤šå›åˆå·¥å…·è¾…åŠ©è®¾ç½®æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæ—¨åœ¨ä¿ç•™ç­–ç•¥ç†µå¹¶ä¼˜åŒ–å¤šå›åˆäº¤äº’ã€‚</li>
<li>EntroPOæ¡†æ¶åœ¨è½¯ä»¶å·¥ç¨‹æŠ€æœ¯ç«èµ›ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>ä½¿ç”¨EntroPOè®­ç»ƒçš„å‚æ•°ä¸ºä¸‰åäº¿çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¬å¼€æƒé‡æ’è¡Œæ¦œä¸Šååˆ—å‰èŒ…ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12434">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.12434v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.12434v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="P2VA-Converting-Persona-Descriptions-into-Voice-Attributes-for-Fair-and-Controllable-Text-to-Speech"><a href="#P2VA-Converting-Persona-Descriptions-into-Voice-Attributes-for-Fair-and-Controllable-Text-to-Speech" class="headerlink" title="P2VA: Converting Persona Descriptions into Voice Attributes for Fair and   Controllable Text-to-Speech"></a>P2VA: Converting Persona Descriptions into Voice Attributes for Fair and   Controllable Text-to-Speech</h2><p><strong>Authors:Yejin Lee, Jaehoon Kang, Kyuhong Shim</strong></p>
<p>While persona-driven large language models (LLMs) and prompt-based text-to-speech (TTS) systems have advanced significantly, a usability gap arises when users attempt to generate voices matching their desired personas from implicit descriptions. Most users lack specialized knowledge to specify detailed voice attributes, which often leads TTS systems to misinterpret their expectations. To address these gaps, we introduce Persona-to-Voice-Attribute (P2VA), the first framework enabling voice generation automatically from persona descriptions. Our approach employs two strategies: P2VA-C for structured voice attributes, and P2VA-O for richer style descriptions. Evaluation shows our P2VA-C reduces WER by 5% and improves MOS by 0.33 points. To the best of our knowledge, P2VA is the first framework to establish a connection between persona and voice synthesis. In addition, we discover that current LLMs embed societal biases in voice attributes during the conversion process. Our experiments and findings further provide insights into the challenges of building persona-voice systems. </p>
<blockquote>
<p>è™½ç„¶ä¸ªæ€§é©±åŠ¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒåŸºäºæç¤ºçš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿå·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†åœ¨ç”¨æˆ·å°è¯•ä»éšå¼æè¿°ç”ŸæˆåŒ¹é…å…¶æ‰€éœ€ä¸ªæ€§çš„å£°éŸ³æ—¶ï¼Œå°±ä¼šå‡ºç°å¯ç”¨æ€§å·®è·ã€‚å¤§å¤šæ•°ç”¨æˆ·ç¼ºä¹æŒ‡å®šè¯¦ç»†è¯­éŸ³å±æ€§çš„ä¸“ä¸šçŸ¥è¯†ï¼Œè¿™å¾€å¾€å¯¼è‡´TTSç³»ç»Ÿè¯¯è§£ä»–ä»¬çš„æœŸæœ›ã€‚ä¸ºäº†è§£å†³è¿™äº›å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†Person-to-Voiceå±æ€§ï¼ˆP2VAï¼‰ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿä»ä¸ªæ€§æè¿°ä¸­è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³çš„æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤ç§ç­–ç•¥ï¼šP2VA-Cç”¨äºç»“æ„åŒ–çš„è¯­éŸ³å±æ€§ï¼ŒP2VA æ­ç¤ºäº†ä¸ªäººç‰¹è´¨çš„é‡è¦æ€§å¹¶å°†å…¶åµŒå…¥è¯­éŸ³è¡¨è¾¾ä¹‹ä¸­ã€‚è¯„ä»·è¡¨æ˜æˆ‘ä»¬çš„P2VA-Cé™ä½äº†å­—é”™è¯¯ç‡ï¼ˆWERï¼‰5%ï¼Œå¹¶æé«˜äº†å¹³å‡æ„è§å¾—åˆ†ï¼ˆMOSï¼‰0.33åˆ†ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒP2VAæ˜¯ç¬¬ä¸€ä¸ªå»ºç«‹ä¸ªæ€§ä¸è¯­éŸ³åˆæˆä¹‹é—´è”ç³»çš„æ¡†æ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è½¬æ¢è¿‡ç¨‹ä¸­åµŒå…¥è¯­éŸ³å±æ€§çš„ç¤¾ä¼šåè§ã€‚æˆ‘ä»¬çš„å®éªŒå’Œå‘ç°ä¸ºè¿›ä¸€æ­¥æ„å»ºä¸ªæ€§åŒ–è¯­éŸ³ç³»ç»Ÿæä¾›äº†æ·±å…¥è§è§£å’Œå¯ç¤ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.17093v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>åŸºäºæ–‡æœ¬çš„æè¿°ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºP2VAçš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»äººç‰©æè¿°ä¸­è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†ä¸¤ç§ç­–ç•¥ï¼šP2VA-Cç”¨äºç»“æ„åŒ–è¯­éŸ³å±æ€§ï¼ŒP2VA-Oç”¨äºæ›´ä¸°å¯Œé£æ ¼æè¿°ã€‚è¯„ä»·æ˜¾ç¤ºï¼ŒP2VA-Cé™ä½äº†å­—é”™è¯¯ç‡ï¼ˆWERï¼‰5%ï¼Œå¹¶æé«˜äº†å¹³å‡æ„è§åˆ†æ•°ï¼ˆMOSï¼‰0.33åˆ†ã€‚è¿™æ˜¯é¦–ä¸ªå»ºç«‹äººç‰©ä¸è¯­éŸ³åˆæˆä¹‹é—´è”ç³»çš„æ¡†æ¶ã€‚æ­¤å¤–ï¼Œè¿˜å‘ç°å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è½¬æ¢è¿‡ç¨‹ä¸­ä¼šåµŒå…¥è¯­éŸ³å±æ€§ä¸­çš„ç¤¾ä¼šåè§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>P2VAæ¡†æ¶å®ç°ä»äººç‰©æè¿°è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³ã€‚</li>
<li>æ¡†æ¶åŒ…å«ä¸¤ç§ç­–ç•¥ï¼šP2VA-Cç”¨äºç»“æ„åŒ–è¯­éŸ³å±æ€§ï¼ŒP2VA-Oç”¨äºæ›´ä¸°å¯Œé£æ ¼æè¿°ã€‚</li>
<li>P2VA-Cå¯é™ä½å­—é”™è¯¯ç‡ï¼ˆWERï¼‰5%ï¼Œæé«˜å¹³å‡æ„è§åˆ†æ•°ï¼ˆMOSï¼‰0.33åˆ†ã€‚</li>
<li>è¯¥æ¡†æ¶æ˜¯é¦–ä¸ªå»ºç«‹äººç‰©ä¸è¯­éŸ³åˆæˆè”ç³»çš„æ¡†æ¶ã€‚</li>
<li>å½“å‰LLMsåœ¨è¯­éŸ³å±æ€§è½¬æ¢è¿‡ç¨‹ä¸­ä¼šåµŒå…¥ç¤¾ä¼šåè§ã€‚</li>
<li>ç”¨æˆ·ç¼ºä¹è¯¦ç»†è¯­éŸ³å±æ€§çŸ¥è¯†ï¼Œå¯¼è‡´TTSç³»ç»Ÿè¯¯è§£ç”¨æˆ·æœŸæœ›ã€‚</li>
<li>P2VAæ¡†æ¶æœ‰åŠ©äºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæé«˜TTSç³»ç»Ÿçš„ç”¨æˆ·ä½“éªŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.17093">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.17093v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.17093v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.17093v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.17093v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.17093v2/page_3_1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="TT-DF-A-Large-Scale-Diffusion-Based-Dataset-and-Benchmark-for-Human-Body-Forgery-Detection"><a href="#TT-DF-A-Large-Scale-Diffusion-Based-Dataset-and-Benchmark-for-Human-Body-Forgery-Detection" class="headerlink" title="TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human   Body Forgery Detection"></a>TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human   Body Forgery Detection</h2><p><strong>Authors:Wenkui Yang, Zhida Zhang, Xiaoqiang Zhou, Junxian Duan, Jie Cao</strong></p>
<p>The emergence and popularity of facial deepfake methods spur the vigorous development of deepfake datasets and facial forgery detection, which to some extent alleviates the security concerns about facial-related artificial intelligence technologies. However, when it comes to human body forgery, there has been a persistent lack of datasets and detection methods, due to the later inception and complexity of human body generation methods. To mitigate this issue, we introduce TikTok-DeepFake (TT-DF), a novel large-scale diffusion-based dataset containing 6,120 forged videos with 1,378,857 synthetic frames, specifically tailored for body forgery detection. TT-DF offers a wide variety of forgery methods, involving multiple advanced human image animation models utilized for manipulation, two generative configurations based on the disentanglement of identity and pose information, as well as different compressed versions. The aim is to simulate any potential unseen forged data in the wild as comprehensively as possible, and we also furnish a benchmark on TT-DF. Additionally, we propose an adapted body forgery detection model, Temporal Optical Flow Network (TOF-Net), which exploits the spatiotemporal inconsistencies and optical flow distribution differences between natural data and forged data. Our experiments demonstrate that TOF-Net achieves favorable performance on TT-DF, outperforming current state-of-the-art extendable facial forgery detection models. For our TT-DF dataset, please refer to <a target="_blank" rel="noopener" href="https://github.com/HashTAG00002/TT-DF">https://github.com/HashTAG00002/TT-DF</a>. </p>
<blockquote>
<p>é¢éƒ¨æ·±åº¦ä¼ªé€ æ–¹æ³•çš„å‡ºç°å’Œæµè¡Œåˆºæ¿€äº†æ·±åº¦ä¼ªé€ æ•°æ®é›†å’Œé¢éƒ¨ä¼ªé€ æ£€æµ‹æŠ€æœ¯çš„è“¬å‹ƒå‘å±•ï¼Œè¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡è½»äº†ä¸é¢éƒ¨ç›¸å…³çš„äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å®‰å…¨æ‹…å¿§ã€‚ç„¶è€Œï¼Œå½“æ¶‰åŠåˆ°äººä½“ä¼ªé€ æ—¶ï¼Œç”±äºäººä½“ç”Ÿæˆæ–¹æ³•çš„èµ·æ­¥è¾ƒè¿Ÿå’Œå¤æ‚æ€§ï¼Œæ•°æ®é›†å’Œæ£€æµ‹æ–¹æ³•çš„ç¼ºä¹ä¸€ç›´å­˜åœ¨ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†TikTok-DeepFakeï¼ˆTT-DFï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹çš„å¤§è§„æ¨¡æ‰©æ•£åŸºç¡€æ•°æ®é›†ï¼ŒåŒ…å«6,120ä¸ªä¼ªé€ è§†é¢‘å’Œ1,378,857ä¸ªåˆæˆå¸§ï¼Œä¸“é—¨ç”¨äºäººä½“ä¼ªé€ æ£€æµ‹ã€‚TT-DFæä¾›äº†å¤šç§ä¼ªé€ æ–¹æ³•ï¼Œæ¶‰åŠå¤šç§å…ˆè¿›çš„äººä½“å›¾åƒåŠ¨ç”»æ¨¡å‹ç”¨äºæ“ä½œï¼Œä¸¤ç§åŸºäºèº«ä»½å’Œå§¿åŠ¿ä¿¡æ¯è§£è€¦çš„ç”Ÿæˆé…ç½®ï¼Œä»¥åŠä¸åŒçš„å‹ç¼©ç‰ˆæœ¬ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°½å¯èƒ½å…¨é¢åœ°æ¨¡æ‹Ÿé‡å¤–ä»»ä½•æ½œåœ¨æœªè§è¿‡çš„ä¼ªé€ æ•°æ®ï¼Œæˆ‘ä»¬è¿˜ä¸ºTT-DFæä¾›äº†ä¸€ä¸ªåŸºå‡†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€‚åº”æ€§çš„äººä½“ä¼ªé€ æ£€æµ‹æ¨¡å‹â€”â€”Temporal Optical Flow Networkï¼ˆTOF-Netï¼‰ï¼Œå®ƒåˆ©ç”¨è‡ªç„¶æ•°æ®å’Œä¼ªé€ æ•°æ®ä¹‹é—´çš„æ—¶ç©ºä¸ä¸€è‡´æ€§å’Œå…‰æµåˆ†å¸ƒå·®å¼‚ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒTOF-Netåœ¨TT-DFä¸Šè¡¨ç°è‰¯å¥½ï¼Œä¼˜äºå½“å‰å…ˆè¿›çš„å¯æ‰©å±•é¢éƒ¨ä¼ªé€ æ£€æµ‹æ¨¡å‹ã€‚æœ‰å…³æˆ‘ä»¬çš„TT-DFæ•°æ®é›†ï¼Œè¯·å‚é˜…<a target="_blank" rel="noopener" href="https://github.com/HashTAG00002/TT-DF%E3%80%82">https://github.com/HashTAG00002/TT-DFã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08437v2">PDF</a> Accepted by PRCV 2024</p>
<p><strong>Summary</strong><br>     æ¨å‡ºTikTok-DeepFakeæ•°æ®é›†ï¼ŒåŒ…å«6,120ä¸ªä¼ªé€ è§†é¢‘å’Œ1,378,857ä¸ªåˆæˆå¸§ï¼Œæ—¨åœ¨è§£å†³äººä½“ä¼ªé€ æ£€æµ‹ç¼ºä¹æ•°æ®é›†å’Œæ–¹æ³•çš„é—®é¢˜ã€‚åŒæ—¶æå‡ºTemporal Optical Flow Network (TOF-Net)æ¨¡å‹ï¼Œèƒ½åˆ©ç”¨æ—¶ç©ºä¸ä¸€è‡´æ€§å’Œå…‰å­¦æµåˆ†å¸ƒå·®å¼‚è¿›è¡Œèº«ä½“ä¼ªé€ æ£€æµ‹ï¼Œè¡¨ç°ä¼˜äºå½“å‰å…ˆè¿›çš„é¢éƒ¨ä¼ªé€ æ£€æµ‹æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TikTok-DeepFakeï¼ˆTT-DFï¼‰æ•°æ®é›†æ˜¯ä¸ºäº†è§£å†³äººä½“ä¼ªé€ æ£€æµ‹ç¼ºä¹æ•°æ®é›†çš„é—®é¢˜è€Œæ¨å‡ºçš„ï¼ŒåŒ…å«å¤§é‡ä¼ªé€ è§†é¢‘å’Œåˆæˆå¸§ã€‚</li>
<li>TT-DFæ•°æ®é›†æä¾›äº†å¤šç§ä¼ªé€ æ–¹æ³•ï¼ŒåŒ…æ‹¬å¤šç§å…ˆè¿›çš„äººä½“å›¾åƒåŠ¨ç”»æ¨¡å‹ã€åŸºäºèº«ä»½å’Œå§¿åŠ¿ä¿¡æ¯è§£è€¦çš„ä¸¤ç§ç”Ÿæˆé…ç½®ä»¥åŠä¸åŒçš„å‹ç¼©ç‰ˆæœ¬ã€‚</li>
<li>TOF-Netæ¨¡å‹è¢«æå‡ºæ¥æ£€æµ‹èº«ä½“ä¼ªé€ ï¼Œå®ƒèƒ½åˆ©ç”¨æ—¶ç©ºä¸ä¸€è‡´æ€§å’Œå…‰å­¦æµåˆ†å¸ƒå·®å¼‚è¿›è¡Œè¯†åˆ«ã€‚</li>
<li>TOF-Netæ¨¡å‹åœ¨TT-DFæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå½“å‰å…ˆè¿›çš„é¢éƒ¨ä¼ªé€ æ£€æµ‹æ¨¡å‹ã€‚</li>
<li>TT-DFæ•°æ®é›†çš„ç›®æ ‡æ˜¯æ¨¡æ‹Ÿé‡å¤–ä»»ä½•æ½œåœ¨æœªè§çš„ä¼ªé€ æ•°æ®ï¼Œå¹¶æä¾›äº†ç›¸åº”çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>æ•°æ®é›†å’Œæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HashTAG00002/TT-DF%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/HashTAG00002/TT-DFæ‰¾åˆ°ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08437">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.08437v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.08437v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2505.08437v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/Interactive/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_Interactive/2509.17711v1/page_3_2.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  DA-Mamba Dialogue-aware selective state-space model for multimodal   engagement estimation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_4_0.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  Towards Seeing Bones at Radio Frequency
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30055.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
