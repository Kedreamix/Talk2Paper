<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
    <meta name="description" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  TS-P$^2$CL Plug-and-Play Dual Contrastive Learning for Vision-Guided   Medical Time Series Classification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-a93e3776597773699674e91737962a70')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-24-æ›´æ–°"><a href="#2025-09-24-æ›´æ–°" class="headerlink" title="2025-09-24 æ›´æ–°"></a>2025-09-24 æ›´æ–°</h1><h2 id="TS-P-2-CL-Plug-and-Play-Dual-Contrastive-Learning-for-Vision-Guided-Medical-Time-Series-Classification"><a href="#TS-P-2-CL-Plug-and-Play-Dual-Contrastive-Learning-for-Vision-Guided-Medical-Time-Series-Classification" class="headerlink" title="TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided   Medical Time Series Classification"></a>TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided   Medical Time Series Classification</h2><p><strong>Authors:Qiâ€™ao Xu, Pengfei Wang, Bo Zhong, Tianwen Qian, Xiaoling Wang, Ye Wang, Hong Yu</strong></p>
<p>Medical time series (MedTS) classification is pivotal for intelligent healthcare, yet its efficacy is severely limited by poor cross-subject generation due to the profound cross-individual heterogeneity. Despite advances in architectural innovations and transfer learning techniques, current methods remain constrained by modality-specific inductive biases that limit their ability to learn universally invariant representations. To overcome this, we propose TS-P$^2$CL, a novel plug-and-play framework that leverages the universal pattern recognition capabilities of pre-trained vision models. We introduce a vision-guided paradigm that transforms 1D physiological signals into 2D pseudo-images, establishing a bridge to the visual domain. This transformation enables implicit access to rich semantic priors learned from natural images. Within this unified space, we employ a dual-contrastive learning strategy: intra-modal consistency enforces temporal coherence, while cross-modal alignment aligns time-series dynamics with visual semantics, thereby mitigating individual-specific biases and learning robust, domain-invariant features. Extensive experiments on six MedTS datasets demonstrate that TS-P$^2$CL consistently outperforms fourteen methods in both subject-dependent and subject-independent settings. </p>
<blockquote>
<p>åŒ»ç–—æ—¶é—´åºåˆ—ï¼ˆMedTSï¼‰åˆ†ç±»å¯¹äºæ™ºèƒ½åŒ»ç–—è‡³å…³é‡è¦ï¼Œä½†å…¶æ•ˆç‡å—åˆ°ä¸ªä½“é—´å·¨å¤§å¼‚è´¨æ€§å¯¼è‡´çš„è·¨ä¸»é¢˜ç”Ÿæˆä¸è‰¯çš„é™åˆ¶ã€‚å°½ç®¡åœ¨å»ºç­‘åˆ›æ–°å’Œè¿ç§»å­¦ä¹ æŠ€æœ¯æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œå½“å‰çš„æ–¹æ³•ä»ç„¶å—åˆ°ç‰¹å®šäºæ¨¡æ€çš„å½’çº³åç½®çš„çº¦æŸï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å­¦ä¹ æ™®éä¸å˜è¡¨ç¤ºçš„èƒ½åŠ›ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†TS-P$^2$CLï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹å³æ’å³ç”¨æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒè§†è§‰æ¨¡å‹çš„é€šç”¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è§†è§‰å¼•å¯¼èŒƒå¼ï¼Œå°†1Dç”Ÿç†ä¿¡å·è½¬æ¢ä¸º2Dä¼ªå›¾åƒï¼Œå»ºç«‹äº†ä¸è§†è§‰é¢†åŸŸçš„æ¡¥æ¢ã€‚è¿™ç§è½¬æ¢èƒ½å¤Ÿéšå¼åœ°è®¿é—®ä»è‡ªç„¶å›¾åƒä¸­å­¦ä¹ åˆ°çš„ä¸°å¯Œçš„è¯­ä¹‰å…ˆéªŒã€‚åœ¨è¿™ä¸ªç»Ÿä¸€çš„ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åŒé‡å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼šæ¨¡æ€å†…ä¸€è‡´æ€§åŠ å¼ºæ—¶é—´è¿è´¯æ€§ï¼Œè€Œæ¨¡æ€é—´å¯¹é½å°†æ—¶é—´åºåˆ—åŠ¨æ€ä¸è§†è§‰è¯­ä¹‰å¯¹é½ï¼Œä»è€Œå‡è½»ä¸ªä½“ç‰¹å®šåè§å¹¶å­¦ä¹ ç¨³å¥çš„ã€é¢†åŸŸä¸å˜çš„ç‰¹å¾ã€‚åœ¨å…­ä¸ªMedTSæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTS-P$^2$CLåœ¨ä¸»ä½“ä¾èµ–å’Œä¸»ä½“ç‹¬ç«‹çš„ç¯å¢ƒä¸­å§‹ç»ˆä¼˜äºåå››ç§æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17802v1">PDF</a> 12 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºTS-P$^2$CLçš„æ–°å‹å³æ’å³ç”¨æ¡†æ¶ï¼Œç”¨äºè§£å†³åŒ»ç–—æ—¶é—´åºåˆ—åˆ†ç±»ä¸­çš„è·¨ä¸»é¢˜ç”Ÿæˆé—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒè§†è§‰æ¨¡å‹çš„é€šç”¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›ï¼Œé€šè¿‡è½¬æ¢ä¸€ç»´ç”Ÿç†ä¿¡å·ä¸ºäºŒç»´ä¼ªå›¾åƒï¼Œå»ºç«‹ä¸è§†è§‰é¢†åŸŸçš„æ¡¥æ¢ï¼Œä»è€Œè®¿é—®ä»è‡ªç„¶å›¾åƒä¸­å­¦ä¹ åˆ°çš„ä¸°å¯Œè¯­ä¹‰å…ˆéªŒã€‚åœ¨ç»Ÿä¸€çš„ç©ºé—´å†…ï¼Œé‡‡ç”¨åŒå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œå³æ¨¡æ€å†…ä¸€è‡´æ€§ä¿è¯æ—¶é—´è¿è´¯æ€§ï¼Œæ¨¡æ€é—´å¯¹é½å°†æ—¶é—´åºåˆ—åŠ¨æ€ä¸è§†è§‰è¯­ä¹‰å¯¹é½ï¼Œä»è€Œå‡è½»ä¸ªä½“ç‰¹å¼‚æ€§åè§å¹¶å­¦ä¹ ç¨³å¥çš„ã€é¢†åŸŸä¸å˜çš„ç‰¹å¾ã€‚åœ¨å…­ä¸ªåŒ»ç–—æ—¶é—´åºåˆ—æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTS-P$^2$CLåœ¨ä¸»ä½“ä¾èµ–å’Œä¸»ä½“ç‹¬ç«‹è®¾ç½®ä¸­å‡ä¼˜äºåå››ç§æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»ç–—æ—¶é—´åºåˆ—åˆ†ç±»åœ¨æ™ºèƒ½åŒ»ç–—ä¸­è‡³å…³é‡è¦ï¼Œä½†å—åˆ°è·¨ä¸»é¢˜ç”Ÿæˆä¸ä½³çš„é™åˆ¶ï¼Œä¸»è¦åŸå› æ˜¯è·¨ä¸ªä½“ä¹‹é—´å­˜åœ¨å·¨å¤§å·®å¼‚ã€‚</li>
<li>å½“å‰æ–¹æ³•å—åˆ°æ¨¡æ€ç‰¹å®šå½’çº³åè§çš„å½±å“ï¼Œæ— æ³•å­¦ä¹ æ™®éçš„ä¸å˜è¡¨ç¤ºã€‚</li>
<li>TS-P$^2$CLæ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹çš„é€šç”¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>é€šè¿‡å°†ä¸€ç»´ç”Ÿç†ä¿¡å·è½¬æ¢ä¸ºäºŒç»´ä¼ªå›¾åƒï¼Œå»ºç«‹ä¸è§†è§‰é¢†åŸŸçš„æ¡¥æ¢ï¼Œè®¿é—®ä¸°å¯Œçš„è¯­ä¹‰å…ˆéªŒã€‚</li>
<li>é‡‡ç”¨åŒå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§å’Œæ¨¡æ€é—´å¯¹é½ï¼Œä»è€Œå‡è½»ä¸ªä½“ç‰¹å¼‚æ€§åè§ã€‚</li>
<li>åœ¨å¤šä¸ªåŒ»ç–—æ—¶é—´åºåˆ—æ•°æ®é›†ä¸Šï¼ŒTS-P$^2$CLè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>TS-P$^2$CLæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯æ¨å¹¿åˆ°å…¶ä»–éœ€è¦è·¨æ¨¡æ€å­¦ä¹ çš„é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17802">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1919a3547a8616cd924a4122c9d5319f" align="middle">
<img src="https://picx.zhimg.com/v2-c3d92c003607a4c1acfa054dd1eeb03e" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="VCE-Safe-Autoregressive-Image-Generation-via-Visual-Contrast-Exploitation"><a href="#VCE-Safe-Autoregressive-Image-Generation-via-Visual-Contrast-Exploitation" class="headerlink" title="VCE: Safe Autoregressive Image Generation via Visual Contrast   Exploitation"></a>VCE: Safe Autoregressive Image Generation via Visual Contrast   Exploitation</h2><p><strong>Authors:Feng Han, Chao Gong, Zhipeng Wei, Jingjing Chen, Yu-Gang Jiang</strong></p>
<p>Recently, autoregressive image generation models have wowed audiences with their remarkable capability in creating surprisingly realistic images. Models such as GPT-4o and LlamaGen can not only produce images that faithfully mimic renowned artistic styles like Ghibli, Van Gogh, or Picasso, but also potentially generate Not-Safe-For-Work (NSFW) content, raising significant concerns regarding copyright infringement and ethical use. Despite these concerns, methods to safeguard autoregressive text-to-image models remain underexplored. Previous concept erasure methods, primarily designed for diffusion models that operate in denoising latent space, are not directly applicable to autoregressive models that generate images token by token. To address this critical gap, we propose Visual Contrast Exploitation (VCE), a novel framework comprising: (1) an innovative contrastive image pair construction paradigm that precisely decouples unsafe concepts from their associated content semantics, and (2) a sophisticated DPO-based training approach that enhances the modelâ€™s ability to identify and leverage visual contrastive features from image pairs, enabling precise concept erasure. Our comprehensive experiments across three challenging tasks-artist style erasure, explicit content erasure, and object removal-demonstrate that our method effectively secures the model, achieving state-of-the-art results while erasing unsafe concepts and maintaining the integrity of unrelated safe concepts. The code and models are available at <a target="_blank" rel="noopener" href="https://github.com/Maplebb/VCE">https://github.com/Maplebb/VCE</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œè‡ªå›å½’å›¾åƒç”Ÿæˆæ¨¡å‹å‡­å€Ÿå…¶åˆ›é€ æƒŠäººé€¼çœŸå›¾åƒçš„èƒ½åŠ›å¸å¼•äº†è§‚ä¼—çš„ç›®å…‰ã€‚è¯¸å¦‚GPT-4oå’ŒLlamaGenç­‰æ¨¡å‹ä¸ä»…èƒ½å¤Ÿäº§ç”Ÿå¿ å®æ¨¡ä»¿å‰åœåŠ›ã€æ¢µé«˜æˆ–æ¯•åŠ ç´¢ç­‰è‘—åè‰ºæœ¯é£æ ¼çš„å›¾åƒï¼Œè€Œä¸”è¿˜å¯èƒ½ç”Ÿæˆä¸é€‚åˆå·¥ä½œåœºåˆï¼ˆNSFWï¼‰çš„å†…å®¹ï¼Œè¿™å¼•å‘äº†å…³äºç‰ˆæƒä¾µçŠ¯å’Œé“å¾·ä½¿ç”¨æ–¹é¢çš„æ‹…å¿§ã€‚å°½ç®¡å­˜åœ¨è¿™äº›æ‹…å¿§ï¼Œä½†ä¿æŠ¤è‡ªå›å½’æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„æ–¹æ³•ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚ä»¥å‰çš„æ¦‚å¿µæ¶ˆé™¤æ–¹æ³•ä¸»è¦è®¾è®¡ç”¨äºåœ¨é™å™ªæ½œåœ¨ç©ºé—´æ“ä½œçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä¸ç›´æ¥é€‚ç”¨äºé€ä»¤ç‰Œç”Ÿæˆå›¾åƒçš„è‡ªå›å½’æ¨¡å‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å…³é”®ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†è§†è§‰å¯¹æ¯”åˆ©ç”¨ï¼ˆVCEï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼šï¼ˆ1ï¼‰ä¸€ç§åˆ›æ–°çš„å¯¹æ¯”å›¾åƒå¯¹æ„å»ºèŒƒå¼ï¼Œè¯¥èŒƒå¼ç²¾ç¡®åœ°å°†ä»ä¸å®‰å…¨æ¦‚å¿µä¸å…¶å…³è”çš„å†…å®¹è¯­ä¹‰ä¸­åˆ†ç¦»å‡ºæ¥ï¼›ï¼ˆ2ï¼‰ä¸€ç§åŸºäºDPOçš„å…ˆè¿›è®­ç»ƒæ–¹æ³•ï¼Œæé«˜æ¨¡å‹ä»å›¾åƒå¯¹ä¸­è¯†åˆ«å’Œåˆ©ç”¨è§†è§‰å¯¹æ¯”ç‰¹å¾çš„èƒ½åŠ›ï¼Œä»è€Œå®ç°ç²¾ç¡®çš„æ¦‚å¿µæ¶ˆé™¤ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼ˆè‰ºæœ¯å®¶é£æ ¼æ¶ˆé™¤ã€æ˜ç¡®å†…å®¹æ¶ˆé™¤å’Œå¯¹è±¡ç§»é™¤ï¼‰ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°ä¿æŠ¤äº†æ¨¡å‹ï¼Œåœ¨æ¶ˆé™¤ä¸å®‰å…¨æ¦‚å¿µçš„åŒæ—¶ä¿æŒæ— å…³å®‰å…¨æ¦‚å¿µçš„å®Œæ•´æ€§ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç›¸å…³ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Maplebb/VCE%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Maplebb/VCEä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16986v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¿‘æœŸå‡ºç°çš„åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒçš„è‡ªå›å½’æ¨¡å‹ï¼ˆå¦‚GPT-4oå’ŒLlamaGenï¼‰ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ç”Ÿæˆé€¼çœŸçš„å›¾åƒå¹¶æ¨¡ä»¿ä¸åŒçš„è‰ºæœ¯é£æ ¼ï¼Œä½†åŒæ—¶ä¹Ÿå­˜åœ¨ç”Ÿæˆä¸é€‚åˆå·¥ä½œåœºåˆï¼ˆNSFWï¼‰å†…å®¹çš„éšæ‚£ï¼Œå¼•å‘ç‰ˆæƒå’Œä¼¦ç†é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºè§†è§‰å¯¹æ¯”åˆ©ç”¨ï¼ˆVCEï¼‰çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…æ‹¬æ„å»ºå¯¹æ¯”å›¾åƒå¯¹å’ŒåŸºäºDPOçš„è®­ç»ƒæ–¹æ³•ï¼Œå¯ç²¾ç¡®åœ°å°†ä¸å®‰å…¨æ¦‚å¿µä¸å…¶ç›¸å…³å†…å®¹è¯­ä¹‰åˆ†ç¦»ï¼Œå®ç°ç²¾ç¡®çš„æ¦‚å¿µæ¶ˆé™¤ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¶ˆé™¤ä¸å®‰å…¨æ¦‚å¿µçš„åŒæ—¶ä¿æŒäº†å®‰å…¨æ¦‚å¿µçš„å®Œæ•´æ€§ï¼Œå–å¾—äº†ä¸šç•Œæœ€ä½³æ•ˆæœã€‚ä»£ç å’Œæ¨¡å‹å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªå›å½’å›¾åƒç”Ÿæˆæ¨¡å‹å…·æœ‰æ¨¡ä»¿å¤šç§è‰ºæœ¯é£æ ¼çš„èƒ½åŠ›ï¼Œå¹¶èƒ½ç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚</li>
<li>è¿™äº›æ¨¡å‹å¯èƒ½ç”Ÿæˆä¸é€‚åˆå·¥ä½œåœºåˆï¼ˆNSFWï¼‰çš„å†…å®¹ï¼Œå¼•å‘ç‰ˆæƒå’Œä¼¦ç†é—®é¢˜ã€‚</li>
<li>å½“å‰ç¼ºä¹é’ˆå¯¹è‡ªå›å½’æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„ä¿æŠ¤æªæ–½ã€‚</li>
<li>æå‡ºçš„è§†è§‰å¯¹æ¯”åˆ©ç”¨ï¼ˆVCEï¼‰æ¡†æ¶åŒ…æ‹¬æ„å»ºå¯¹æ¯”å›¾åƒå¯¹å’ŒåŸºäºDPOçš„è®­ç»ƒæ–¹æ³•ã€‚</li>
<li>VCEæ¡†æ¶å¯ä»¥ç²¾ç¡®åœ°å°†ä¸å®‰å…¨æ¦‚å¿µä¸å…¶ç›¸å…³å†…å®¹è¯­ä¹‰åˆ†ç¦»ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒVCEæ¡†æ¶åœ¨æ¶ˆé™¤ä¸å®‰å…¨æ¦‚å¿µçš„åŒæ—¶ä¿æŒäº†å®‰å…¨æ¦‚å¿µçš„å®Œæ•´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16986">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3e18db0f1bd3bef3190459f429f43845" align="middle">
<img src="https://picx.zhimg.com/v2-fdd002b1f358f9ec11a677b8fa5daa60" align="middle">
<img src="https://picx.zhimg.com/v2-9841d872da1088a6c00776cf97bdc2e2" align="middle">
<img src="https://picx.zhimg.com/v2-42c251441d071fd505cb1deca1c75ef7" align="middle">
<img src="https://picx.zhimg.com/v2-d8a4808d19a283dc94b24f45c0416e0c" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RegionMed-CLIP-A-Region-Aware-Multimodal-Contrastive-Learning-Pre-trained-Model-for-Medical-Image-Understanding"><a href="#RegionMed-CLIP-A-Region-Aware-Multimodal-Contrastive-Learning-Pre-trained-Model-for-Medical-Image-Understanding" class="headerlink" title="RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning   Pre-trained Model for Medical Image Understanding"></a>RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning   Pre-trained Model for Medical Image Understanding</h2><p><strong>Authors:Tianchen Fang, Guiru Liu</strong></p>
<p>Medical image understanding plays a crucial role in enabling automated diagnosis and data-driven clinical decision support. However, its progress is impeded by two primary challenges: the limited availability of high-quality annotated medical data and an overreliance on global image features, which often miss subtle but clinically significant pathological regions. To address these issues, we introduce RegionMed-CLIP, a region-aware multimodal contrastive learning framework that explicitly incorporates localized pathological signals along with holistic semantic representations. The core of our method is an innovative region-of-interest (ROI) processor that adaptively integrates fine-grained regional features with the global context, supported by a progressive training strategy that enhances hierarchical multimodal alignment. To enable large-scale region-level representation learning, we construct MedRegion-500k, a comprehensive medical image-text corpus that features extensive regional annotations and multilevel clinical descriptions. Extensive experiments on image-text retrieval, zero-shot classification, and visual question answering tasks demonstrate that RegionMed-CLIP consistently exceeds state-of-the-art vision language models by a wide margin. Our results highlight the critical importance of region-aware contrastive pre-training and position RegionMed-CLIP as a robust foundation for advancing multimodal medical image understanding. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒç†è§£åœ¨ä¿ƒè¿›è‡ªåŠ¨åŒ–è¯Šæ–­å’Œæ²»ç–—å†³ç­–æ”¯æŒä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œå…¶è¿›å±•å—åˆ°ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜çš„é™åˆ¶ï¼šé«˜è´¨é‡æ ‡æ³¨åŒ»å­¦æ•°æ®çš„æœ‰é™å¯ç”¨æ€§ï¼Œä»¥åŠå¯¹å…¨å±€å›¾åƒç‰¹å¾çš„è¿‡åº¦ä¾èµ–ï¼Œè¿™å¾€å¾€ä¼šå¯¼è‡´å¾®å¦™çš„ä½†ä¸´åºŠä¸Šé‡è¦çš„ç—…ç†åŒºåŸŸè¢«é—æ¼ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†RegionMed-CLIPï¼Œè¿™æ˜¯ä¸€ä¸ªåŒºåŸŸæ„ŸçŸ¥çš„å¤šæ¨¡å¼å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå®ƒæ˜¾å¼åœ°ç»“åˆäº†å±€éƒ¨ç—…ç†ä¿¡å·å’Œæ•´ä½“è¯­ä¹‰è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªåˆ›æ–°çš„å…´è¶£åŒºåŸŸï¼ˆROIï¼‰å¤„ç†å™¨ï¼Œå®ƒè‡ªé€‚åº”åœ°é›†æˆäº†ç²¾ç»†çš„å±€éƒ¨ç‰¹å¾ä¸å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¹¶å¾—åˆ°äº†ä¸€ç§å¢å¼ºå±‚æ¬¡å¤šæ¨¡å¼å¯¹é½çš„æ¸è¿›è®­ç»ƒç­–ç•¥çš„æ”¯æŒã€‚ä¸ºäº†è¿›è¡Œå¤§è§„æ¨¡çš„åŒºåŸŸçº§åˆ«è¡¨ç¤ºå­¦ä¹ ï¼Œæˆ‘ä»¬æ„å»ºäº†MedRegion-500kï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥åŒºåŸŸæ³¨é‡Šå’Œå¤šå±‚æ¬¡ä¸´åºŠæè¿°ä¸ºç‰¹è‰²çš„åŒ»å­¦å›¾åƒ-æ–‡æœ¬è¯­æ–™åº“ã€‚åœ¨å›¾åƒ-æ–‡æœ¬æ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»å’Œè§†è§‰é—®ç­”ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRegionMed-CLIPå§‹ç»ˆå¤§å¹…è¶…è¶Šäº†æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†åŒºåŸŸæ„ŸçŸ¥å¯¹æ¯”é¢„è®­ç»ƒçš„å…³é”®é‡è¦æ€§ï¼Œå¹¶å°†RegionMed-CLIPå®šä½ä¸ºæ¨åŠ¨å¤šæ¨¡å¼åŒ»å­¦å›¾åƒç†è§£å‘å±•çš„ç¨³å¥åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05244v2">PDF</a> Upon further review, we identified that our dataset requires   optimization to ensure research reliability and accuracy. Additionally,   considering the target journalâ€™s latest submission policies, we believe   comprehensive manuscript revisions are necessary</p>
<p><strong>Summary</strong></p>
<p>RegionMed-CLIPæ˜¯ä¸€ç§é’ˆå¯¹åŒ»ç–—å›¾åƒç†è§£çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆå±€éƒ¨ç—…ç†ä¿¡å·å’Œæ•´ä½“è¯­ä¹‰è¡¨ç¤ºï¼Œè§£å†³é«˜è´¨é‡æ ‡æ³¨åŒ»ç–—æ•°æ®æœ‰é™å’Œè¿‡åº¦ä¾èµ–å…¨å±€å›¾åƒç‰¹å¾çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡è‡ªé€‚åº”é›†æˆç»†ç²’åº¦åŒºåŸŸç‰¹å¾ä¸å…¨å±€ä¸Šä¸‹æ–‡çš„æ ¸å¿ƒåŒºåŸŸå¤„ç†å™¨ï¼Œä»¥åŠå¢å¼ºå±‚æ¬¡åŒ–å¤šæ¨¡æ€å¯¹é½çš„æ¸è¿›è®­ç»ƒç­–ç•¥ï¼Œå®ç°äº†æœ‰æ•ˆçš„å­¦ä¹ ã€‚ä¸ºæ”¯æŒå¤§è§„æ¨¡åŒºåŸŸçº§åˆ«è¡¨ç¤ºå­¦ä¹ ï¼Œæ„å»ºäº†MedRegion-500kåŒ»ç–—å›¾åƒæ–‡æœ¬è¯­æ–™åº“ï¼ŒåŒ…å«ä¸°å¯Œçš„åŒºåŸŸæ ‡æ³¨å’Œå¤šå±‚ä¸´åºŠæè¿°ã€‚å®éªŒè¡¨æ˜ï¼ŒRegionMed-CLIPåœ¨å›¾åƒæ–‡æœ¬æ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»å’Œè§†è§‰é—®ç­”ä»»åŠ¡ä¸Šå‡å¤§å¹…è¶…è¶Šå½“å‰å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå‡¸æ˜¾äº†åŒºåŸŸæ„ŸçŸ¥å¯¹æ¯”é¢„è®­ç»ƒçš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RegionMed-CLIPè§£å†³äº†åŒ»ç–—å›¾åƒç†è§£ä¸­çš„ä¸¤å¤§æŒ‘æˆ˜ï¼šé«˜è´¨é‡æ ‡æ³¨åŒ»ç–—æ•°æ®æœ‰é™å’Œè¿‡åº¦ä¾èµ–å…¨å±€å›¾åƒç‰¹å¾ã€‚</li>
<li>RegionMed-CLIPé€šè¿‡ç»“åˆå±€éƒ¨ç—…ç†ä¿¡å·å’Œæ•´ä½“è¯­ä¹‰è¡¨ç¤ºï¼Œæé«˜äº†åŒ»ç–—å›¾åƒç†è§£çš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡è‡ªé€‚åº”é›†æˆç»†ç²’åº¦åŒºåŸŸç‰¹å¾ä¸å…¨å±€ä¸Šä¸‹æ–‡çš„åŒºåŸŸå¤„ç†å™¨å®ç°æœ‰æ•ˆå­¦ä¹ ã€‚</li>
<li>æ¸è¿›è®­ç»ƒç­–ç•¥å¢å¼ºäº†å±‚æ¬¡åŒ–å¤šæ¨¡æ€å¯¹é½ï¼Œæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>ä¸ºæ”¯æŒå¤§è§„æ¨¡åŒºåŸŸçº§åˆ«è¡¨ç¤ºå­¦ä¹ ï¼Œæ„å»ºäº†MedRegion-500kåŒ»ç–—å›¾åƒæ–‡æœ¬è¯­æ–™åº“ã€‚</li>
<li>RegionMed-CLIPåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05244">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4409389a475b3efc3467f6322ecaf107" align="middle">
<img src="https://picx.zhimg.com/v2-e0038387d1731557539231913673eb74" align="middle">
<img src="https://picx.zhimg.com/v2-5b048fbad3f03f4ac0c39114b067eb10" align="middle">
<img src="https://picx.zhimg.com/v2-e98bdf7cef64cadde7f2ee8c5e2dc8cc" align="middle">
<img src="https://picx.zhimg.com/v2-a93e3776597773699674e91737962a70" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CLIPTTA-Robust-Contrastive-Vision-Language-Test-Time-Adaptation"><a href="#CLIPTTA-Robust-Contrastive-Vision-Language-Test-Time-Adaptation" class="headerlink" title="CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation"></a>CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation</h2><p><strong>Authors:Marc Lafon, Gustavo Adolfo Vargas Hakim, ClÃ©ment Rambour, Christian Desrosier, Nicolas Thome</strong></p>
<p>Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities but often fail to generalize under distribution shifts. Test-time adaptation (TTA) allows models to update at inference time without labeled data, typically via entropy minimization. However, this objective is fundamentally misaligned with the contrastive image-text training of VLMs, limiting adaptation performance and introducing failure modes such as pseudo-label drift and class collapse. We propose CLIPTTA, a new gradient-based TTA method for vision-language models that leverages a soft contrastive loss aligned with CLIPâ€™s pre-training objective. We provide a theoretical analysis of CLIPTTAâ€™s gradients, showing how its batch-aware design mitigates the risk of collapse. We further extend CLIPTTA to the open-set setting, where both in-distribution (ID) and out-of-distribution (OOD) samples are encountered, using an Outlier Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75 datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms entropy-based objectives and is highly competitive with state-of-the-art TTA methods, outperforming them on a large number of datasets and exhibiting more stable performance across diverse shifts. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰å±•ç°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬èƒ½åŠ›ï¼Œä½†åœ¨åˆ†å¸ƒå˜åŒ–ä¸‹é€šå¸¸éš¾ä»¥æ¨å¹¿ã€‚æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰å…è®¸æ¨¡å‹åœ¨æ¨ç†æ—¶é—´è¿›è¡Œæ— éœ€æ ‡è®°æ•°æ®çš„æ›´æ–°ï¼Œé€šå¸¸é€šè¿‡ç†µæœ€å°åŒ–å®ç°ã€‚ç„¶è€Œï¼Œè¿™ä¸€ç›®æ ‡æ ¹æœ¬ä¸Šä¸CLIPç­‰è§†è§‰è¯­è¨€æ¨¡å‹çš„å¯¹æ¯”å›¾åƒæ–‡æœ¬è®­ç»ƒç›¸æ‚–ï¼Œé™åˆ¶äº†é€‚åº”æ€§èƒ½å¹¶å¼•å…¥äº†ä¼ªæ ‡ç­¾æ¼‚ç§»å’Œç±»åˆ«å´©æºƒç­‰å¤±è´¥æ¨¡å¼ã€‚æˆ‘ä»¬æå‡ºäº†CLIPTTAï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ¢¯åº¦çš„æ–°TTAæ–¹æ³•ï¼Œé€‚ç”¨äºè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå®ƒåˆ©ç”¨ä¸CLIPé¢„è®­ç»ƒç›®æ ‡å¯¹é½çš„è½¯å¯¹æ¯”æŸå¤±ã€‚æˆ‘ä»¬å¯¹CLIPTTAçš„æ¢¯åº¦è¿›è¡Œäº†ç†è®ºåˆ†æï¼Œå±•ç¤ºäº†å…¶æ‰¹é‡æ„ŸçŸ¥è®¾è®¡å¦‚ä½•ç¼“è§£å´©æºƒé£é™©ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†CLIPTTAæ‰©å±•åˆ°å¼€æ”¾é›†è®¾ç½®ï¼Œåœ¨æ­¤è®¾ç½®ä¸­é‡åˆ°çš„æ˜¯åˆ†å¸ƒå†…ï¼ˆIDï¼‰å’Œåˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ ·æœ¬ï¼Œä½¿ç”¨å¼‚å¸¸å€¼å¯¹æ¯”æ›å…‰ï¼ˆOCEï¼‰æŸå¤±æ¥æ”¹å–„OODæ£€æµ‹ã€‚åœ¨æ¶µç›–å¤šç§åˆ†å¸ƒå˜åŒ–çš„7.æ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒCLIPTTAå§‹ç»ˆä¼˜äºåŸºäºç†µçš„ç›®æ ‡ï¼Œå¹¶åœ¨æœ€æ–°TTAæ–¹æ³•ä¸­è¡¨ç°å‡ºé«˜åº¦ç«äº‰åŠ›ï¼Œåœ¨å¤§é‡æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºå®ƒä»¬å¹¶åœ¨å„ç§å˜åŒ–ä¸­å±•ç°å‡ºæ›´ç¨³å®šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.14312v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ¢¯åº¦çš„æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•CLIPTTAï¼Œç”¨äºæé«˜è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰åœ¨ä¸åŒåˆ†å¸ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚CLIPTTAåˆ©ç”¨ä¸CLIPé¢„è®­ç»ƒç›®æ ‡ä¸€è‡´çš„è½¯å¯¹æ¯”æŸå¤±ï¼Œè§£å†³äº†ä¼ ç»Ÿç†µæœ€å°åŒ–ç›®æ ‡å­˜åœ¨çš„ä¼ªæ ‡ç­¾æ¼‚ç§»å’Œç±»åˆ«å´©æºƒé—®é¢˜ã€‚é€šè¿‡ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯ï¼ŒCLIPTTAåœ¨å¤šç§æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºåŸºäºç†µçš„ç›®æ ‡ï¼Œå¹¶ä¸å½“å‰å…ˆè¿›çš„æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ç«äº‰ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ‰©å±•åˆ°å¼€æ”¾é›†è®¾ç½®ï¼Œä½¿ç”¨å¼‚å¸¸å€¼å¯¹æ¯”æ›å…‰ï¼ˆOCEï¼‰æŸå¤±æé«˜å¼‚å¸¸å€¼æ£€æµ‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>CLIPTTAæ˜¯ä¸€ç§é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹çš„æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹åœ¨ä¸åŒåˆ†å¸ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>CLIPTTAåˆ©ç”¨è½¯å¯¹æ¯”æŸå¤±è§£å†³ä¼ªæ ‡ç­¾æ¼‚ç§»å’Œç±»åˆ«å´©æºƒé—®é¢˜ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç†µæœ€å°åŒ–ç›®æ ‡ä¸åŒã€‚</li>
<li>CLIPTTAçš„ç†è®ºåˆ†ææ˜¾ç¤ºå…¶æ‰¹æ¬¡æ„ŸçŸ¥è®¾è®¡èƒ½å¤Ÿé™ä½ç±»åˆ«å´©æºƒçš„é£é™©ã€‚</li>
<li>CLIPTTAæ‰©å±•åˆ°å¼€æ”¾é›†è®¾ç½®ï¼Œé€šè¿‡å¼•å…¥Outlier Contrastive Exposureï¼ˆOCEï¼‰æŸå¤±æ¥æé«˜å¼‚å¸¸å€¼æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCLIPTTAä¼˜äºåŸºäºç†µçš„ç›®æ ‡å¹¶ä¸å…¶ä»–å…ˆè¿›çš„æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ç«äº‰ã€‚</li>
<li>CLIPTTAåœ¨å¤šç§åˆ†å¸ƒå˜åŒ–ä¸‹çš„è¡¨ç°ç¨³å®šä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.14312">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8286638fd717818e79f901f10efd80b3" align="middle">
<img src="https://picx.zhimg.com/v2-89c86ca2211e847902091c6792246ad9" align="middle">
<img src="https://picx.zhimg.com/v2-27d6212facaa51880c719d69069881d3" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Test-Time-Multimodal-Backdoor-Detection-by-Contrastive-Prompting"><a href="#Test-Time-Multimodal-Backdoor-Detection-by-Contrastive-Prompting" class="headerlink" title="Test-Time Multimodal Backdoor Detection by Contrastive Prompting"></a>Test-Time Multimodal Backdoor Detection by Contrastive Prompting</h2><p><strong>Authors:Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng</strong></p>
<p>While multimodal contrastive learning methods (e.g., CLIP) can achieve impressive zero-shot classification performance, recent research has revealed that these methods are vulnerable to backdoor attacks. To defend against backdoor attacks on CLIP, existing defense methods focus on either the pre-training stage or the fine-tuning stage, which would unfortunately cause high computational costs due to numerous parameter updates and are not applicable in black-box settings. In this paper, we provide the first attempt at a computationally efficient backdoor detection method to defend against backdoored CLIP in the \emph{inference} stage. We empirically find that the visual representations of backdoored images are \emph{insensitive} to \emph{benign} and \emph{malignant} changes in class description texts. Motivated by this observation, we propose BDetCLIP, a novel test-time backdoor detection method based on contrastive prompting. Specifically, we first prompt a language model (e.g., GPT-4) to produce class-related description texts (benign) and class-perturbed random texts (malignant) by specially designed instructions. Then, the distribution difference in cosine similarity between images and the two types of class description texts can be used as the criterion to detect backdoor samples. Extensive experiments validate that our proposed BDetCLIP is superior to state-of-the-art backdoor detection methods, in terms of both effectiveness and efficiency. Our codes are publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Purshow/BDetCLIP">https://github.com/Purshow/BDetCLIP</a>. </p>
<blockquote>
<p>å°½ç®¡å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼ˆä¾‹å¦‚CLIPï¼‰å¯ä»¥å®ç°ä»¤äººå°è±¡æ·±åˆ»çš„é›¶æ ·æœ¬åˆ†ç±»æ€§èƒ½ï¼Œä½†æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜è¿™äº›æ–¹æ³•å®¹æ˜“å—åˆ°åé—¨æ”»å‡»çš„å½±å“ã€‚ä¸ºäº†é˜²å¾¡CLIPçš„åé—¨æ”»å‡»ï¼Œç°æœ‰çš„é˜²å¾¡æ–¹æ³•ä¸»è¦å…³æ³¨é¢„è®­ç»ƒé˜¶æ®µæˆ–å¾®è°ƒé˜¶æ®µï¼Œè¿™ä¼šå¯¼è‡´ç”±äºå¤§é‡å‚æ•°æ›´æ–°è€Œäº§ç”Ÿçš„é«˜è®¡ç®—æˆæœ¬ï¼Œå¹¶ä¸”ä¸é€‚ç”¨äºé»‘ç›’è®¾ç½®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡å°è¯•äº†ä¸€ç§è®¡ç®—é«˜æ•ˆçš„åé—¨æ£€æµ‹æ–¹æ³•ï¼Œåœ¨æ¨ç†é˜¶æ®µé˜²å¾¡è¢«åé—¨æ§åˆ¶çš„CLIPã€‚æˆ‘ä»¬å®è¯å‘ç°ï¼Œè¢«åé—¨æ§åˆ¶çš„å›¾åƒè§†è§‰è¡¨ç¤ºå¯¹è‰¯æ€§ï¼ˆbenignï¼‰å’Œæ¶æ€§ï¼ˆmalignantï¼‰å˜åŒ–çš„ç±»åˆ«æè¿°æ–‡æœ¬å¹¶ä¸æ•æ„Ÿã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†BDetCLIPï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æµ‹è¯•æ—¶é—´åé—¨æ£€æµ‹æ–¹æ³•ï¼ŒåŸºäºå¯¹æ¯”æç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡ç‰¹å®šè®¾è®¡çš„æŒ‡ä»¤æç¤ºè¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚GPT-4ï¼‰ç”Ÿæˆä¸ç±»åˆ«ç›¸å…³çš„æè¿°æ–‡æœ¬ï¼ˆè‰¯æ€§ï¼‰å’Œç±»åˆ«æ‰°åŠ¨éšæœºæ–‡æœ¬ï¼ˆæ¶æ€§ï¼‰ã€‚ç„¶åï¼Œå›¾åƒä¸è¿™ä¸¤ç§ç±»åˆ«æè¿°æ–‡æœ¬ä¹‹é—´ä½™å¼¦ç›¸ä¼¼æ€§çš„åˆ†å¸ƒå·®å¼‚å¯ä»¥ç”¨ä½œæ£€æµ‹åé—¨æ ·æœ¬çš„å‡†åˆ™ã€‚å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„BDetCLIPåœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢ä¼˜äºå½“å‰å…ˆè¿›çš„åé—¨æ£€æµ‹æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/Purshow/BDetCLIP%E3%80%82">https://github.com/Purshow/BDetCLIPã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15269v3">PDF</a> Accepted to ICML2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹CLIPæ¨¡å‹åœ¨æ¨ç†é˜¶æ®µçš„æŠ—åé—¨æ”»å‡»æ–¹æ³•BDetCLIPã€‚ç ”ç©¶å‘ç°ï¼Œè¢«åé—¨æ”»å‡»çš„å›¾åƒåœ¨è§†è§‰è¡¨ç¤ºä¸Šå¯¹è‰¯æ€§åŠæ¶æ€§æ–‡æœ¬æè¿°å˜åŒ–ä¸æ•æ„Ÿã€‚åŸºäºæ­¤è§‚å¯Ÿï¼ŒBDetCLIPåˆ©ç”¨å¯¹æ¯”æç¤ºåœ¨æµ‹è¯•æ—¶è¿›è¡Œåé—¨æ ·æœ¬æ£€æµ‹ã€‚è¯¥æ–¹æ³•é€šè¿‡è¯­è¨€æ¨¡å‹äº§ç”Ÿä¸ç±»åˆ«ç›¸å…³çš„è‰¯æ€§æè¿°å’Œç±»åˆ«éšæœºæ‰°åŠ¨ä¸‹çš„æ¶æ€§æè¿°æ–‡æœ¬ï¼Œè®¡ç®—å›¾åƒä¸è¿™ä¸¤ç±»æè¿°æ–‡æœ¬é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦åˆ†å¸ƒå·®å¼‚ä½œä¸ºæ£€æµ‹æ ‡å‡†ã€‚å®éªŒè¯å®ï¼Œç›¸è¾ƒäºç°æœ‰æŠ€æœ¯ï¼ŒBDetCLIPåœ¨æ£€æµ‹æ•ˆæœå’Œæ•ˆç‡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚ç›¸å…³ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ–¹æ³•çš„æ½œåœ¨å¨èƒï¼šè¿‘æœŸç ”ç©¶æ­ç¤ºï¼ŒCLIPç­‰å¤šåª’ä½“å¯¹æ¯”å­¦ä¹ æ–¹æ³•è™½å…·å¤‡å‡ºè‰²çš„é›¶æ ·æœ¬åˆ†ç±»æ€§èƒ½ï¼Œä½†ä»å­˜åœ¨åé—¨æ”»å‡»é£é™©ã€‚</li>
<li>ç°æœ‰é˜²å¾¡ç­–ç•¥çš„æŒ‘æˆ˜ï¼šå½“å‰é˜²å¾¡ç­–ç•¥é›†ä¸­åœ¨é¢„è®­ç»ƒæˆ–å¾®è°ƒé˜¶æ®µï¼Œæ¶‰åŠå¤§é‡å‚æ•°æ›´æ–°å’Œé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ï¼Œä¸”åœ¨é»‘ç›’ç¯å¢ƒä¸­ä¸é€‚ç”¨ã€‚</li>
<li>æ–°é¢–çš„åå‘æ£€æµ‹ç­–ç•¥ï¼šé¦–æ¬¡æå‡ºåœ¨è®¡ç®—æ•ˆç‡é«˜çš„æ¨ç†é˜¶æ®µè¿›è¡Œåé—¨æ£€æµ‹çš„æ–¹æ³•ã€‚</li>
<li>å›¾åƒä¸æ–‡æœ¬æè¿°é—´çš„æ•æ„Ÿæ€§è§‚å¯Ÿï¼šç ”ç©¶å‘ç°è¢«åé—¨æ”»å‡»çš„å›¾åƒå¯¹è‰¯æ€§åŠæ¶æ€§æ–‡æœ¬æè¿°å˜åŒ–è§†è§‰ä¸Šä¸æ•æ„Ÿã€‚</li>
<li>BDetCLIPæ–¹æ³•ä»‹ç»ï¼šåŸºäºå¯¹æ¯”æç¤ºå’Œä½™å¼¦ç›¸ä¼¼åº¦åˆ†å¸ƒå·®å¼‚è¿›è¡Œåé—¨æ ·æœ¬æ£€æµ‹ã€‚</li>
<li>å®éªŒéªŒè¯ï¼šå¯¹æ¯”å®éªŒè¯æ˜BDetCLIPåœ¨æ£€æµ‹æ•ˆæœä¸æ•ˆç‡ä¸Šè¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.15269">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cb530a8ce239652586c06dda746fa169" align="middle">
<img src="https://picx.zhimg.com/v2-26c906f77a1e6f02f728add97f93266c" align="middle">
<img src="https://picx.zhimg.com/v2-1d027a0a0ddfc4a4f16482053e4f5f9a" align="middle">
<img src="https://picx.zhimg.com/v2-668c1b026800d7079c2cec03d224f8cf" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Superpixel-Graph-Contrastive-Clustering-with-Semantic-Invariant-Augmentations-for-Hyperspectral-Images"><a href="#Superpixel-Graph-Contrastive-Clustering-with-Semantic-Invariant-Augmentations-for-Hyperspectral-Images" class="headerlink" title="Superpixel Graph Contrastive Clustering with Semantic-Invariant   Augmentations for Hyperspectral Images"></a>Superpixel Graph Contrastive Clustering with Semantic-Invariant   Augmentations for Hyperspectral Images</h2><p><strong>Authors:Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou</strong></p>
<p>Hyperspectral images (HSI) clustering is an important but challenging task. The state-of-the-art (SOTA) methods usually rely on superpixels, however, they do not fully utilize the spatial and spectral information in HSI 3-D structure, and their optimization targets are not clustering-oriented. In this work, we first use 3-D and 2-D hybrid convolutional neural networks to extract the high-order spatial and spectral features of HSI through pre-training, and then design a superpixel graph contrastive clustering (SPGCC) model to learn discriminative superpixel representations. Reasonable augmented views are crucial for contrastive clustering, and conventional contrastive learning may hurt the cluster structure since different samples are pushed away in the embedding space even if they belong to the same class. In SPGCC, we design two semantic-invariant data augmentations for HSI superpixels: pixel sampling augmentation and model weight augmentation. Then sample-level alignment and clustering-center-level contrast are performed for better intra-class similarity and inter-class dissimilarity of superpixel embeddings. We perform clustering and network optimization alternatively. Experimental results on several HSI datasets verify the advantages of the proposed SPGCC compared to SOTA methods. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/jhqi/spgcc">https://github.com/jhqi/spgcc</a>. </p>
<blockquote>
<p>é«˜å…‰è°±å›¾åƒï¼ˆHSIï¼‰èšç±»æ˜¯ä¸€é¡¹é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ç›®å‰å…ˆè¿›çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºè¶…åƒç´ ï¼Œä½†å®ƒä»¬æ²¡æœ‰å……åˆ†åˆ©ç”¨HSIä¸‰ç»´ç»“æ„ä¸­çš„ç©ºé—´å’Œå…‰è°±ä¿¡æ¯ï¼Œä¸”å…¶ä¼˜åŒ–ç›®æ ‡å¹¶éé’ˆå¯¹èšç±»ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ä¸‰ç»´å’ŒäºŒç»´æ··åˆå·ç§¯ç¥ç»ç½‘ç»œé€šè¿‡é¢„è®­ç»ƒæå–HSIçš„é«˜é˜¶ç©ºé—´å’Œå…‰è°±ç‰¹å¾ï¼Œç„¶åè®¾è®¡è¶…åƒç´ å›¾å¯¹æ¯”èšç±»ï¼ˆSPGCCï¼‰æ¨¡å‹æ¥å­¦ä¹ åˆ¤åˆ«è¶…åƒç´ è¡¨ç¤ºã€‚åˆç†çš„å¢å¼ºè§†å›¾å¯¹äºå¯¹æ¯”èšç±»è‡³å…³é‡è¦ï¼Œè€Œä¼ ç»Ÿçš„å¯¹æ¯”å­¦ä¹ å¯èƒ½ä¼šæŸå®³èšç±»ç»“æ„ï¼Œå› ä¸ºä¸åŒæ ·æœ¬å³ä½¿åœ¨å±äºåŒä¸€ç±»åˆ«çš„æƒ…å†µä¸‹ä¹Ÿä¼šåœ¨åµŒå…¥ç©ºé—´ä¸­ç›¸äº’æ¨å¼€ã€‚åœ¨SPGCCä¸­ï¼Œæˆ‘ä»¬ä¸ºHSIè¶…åƒç´ è®¾è®¡äº†ä¸¤ç§è¯­ä¹‰ä¸å˜çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼šåƒç´ é‡‡æ ·å¢å¼ºå’Œæ¨¡å‹æƒé‡å¢å¼ºã€‚ç„¶åå¯¹è¶…åƒç´ åµŒå…¥è¿›è¡Œæ ·æœ¬çº§å¯¹é½å’Œèšç±»ä¸­å¿ƒçº§å¯¹æ¯”ï¼Œä»¥æ›´å¥½åœ°å®ç°ç±»å†…ç›¸ä¼¼æ€§å’Œç±»é—´å·®å¼‚æ€§ã€‚æˆ‘ä»¬äº¤æ›¿æ‰§è¡Œèšç±»å’Œç½‘ç»œä¼˜åŒ–ã€‚åœ¨å¤šä¸ªHSIæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†ä¸å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºSPGCCçš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/jhqi/spgcc%E3%80%82">https://github.com/jhqi/spgccã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.01799v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åŸºäºä¸‰ç»´å’ŒäºŒç»´æ··åˆå·ç§¯ç¥ç»ç½‘ç»œçš„é«˜å…‰è°±å›¾åƒèšç±»æ–¹æ³•ã€‚é€šè¿‡é¢„è®­ç»ƒæå–é«˜å…‰è°±å›¾åƒçš„é«˜é˜¶ç©ºé—´å’Œå…‰è°±ç‰¹å¾ï¼Œç„¶åè®¾è®¡è¶…åƒç´ å›¾å¯¹æ¯”èšç±»æ¨¡å‹ï¼ˆSPGCCï¼‰ï¼Œå­¦ä¹ å…·æœ‰åŒºåˆ†æ€§çš„è¶…åƒç´ è¡¨ç¤ºã€‚åˆç†çš„æ•°æ®å¢å¼ºå¯¹æ¯”èšç±»è‡³å…³é‡è¦ï¼Œä¼ ç»Ÿçš„å¯¹æ¯”å­¦ä¹ å¯èƒ½æŸå®³èšç±»ç»“æ„ï¼Œå› ä¸ºåŒä¸€ç±»çš„ä¸åŒæ ·æœ¬åœ¨åµŒå…¥ç©ºé—´ä¸­ä¼šè¢«æ¨å¼€ã€‚åœ¨SPGCCä¸­ï¼Œä¸ºHSIè¶…åƒç´ è®¾è®¡äº†ä¸¤ç§è¯­ä¹‰ä¸å˜çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼šåƒç´ é‡‡æ ·å¢å¼ºå’Œæ¨¡å‹æƒé‡å¢å¼ºã€‚ç„¶åè¿›è¡Œæ ·æœ¬çº§å¯¹é½å’Œèšç±»ä¸­å¿ƒçº§å¯¹æ¯”ï¼Œä»¥æ”¹å–„è¶…åƒç´ åµŒå…¥çš„ç±»å†…ç›¸ä¼¼æ€§å’Œç±»é—´å·®å¼‚æ€§ã€‚é€šè¿‡äº¤æ›¿è¿›è¡Œèšç±»å’Œç½‘ç»œä¼˜åŒ–ï¼Œåœ¨å‡ ä¸ªé«˜å…‰è°±å›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†æ‰€æå‡ºçš„SPGCCç›¸è¾ƒäºæœ€æ–°æ–¹æ³•å…·æœ‰ä¼˜åŠ¿ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åŸºäºä¸‰ç»´å’ŒäºŒç»´æ··åˆå·ç§¯ç¥ç»ç½‘ç»œçš„é«˜å…‰è°±å›¾åƒèšç±»æ–¹æ³•ã€‚</li>
<li>é€šè¿‡é¢„è®­ç»ƒæå–é«˜å…‰è°±å›¾åƒçš„é«˜é˜¶ç©ºé—´å’Œå…‰è°±ç‰¹å¾ã€‚</li>
<li>è®¾è®¡äº†è¶…åƒç´ å›¾å¯¹æ¯”èšç±»æ¨¡å‹ï¼ˆSPGCCï¼‰æ¥å­¦ä¹ åŒºåˆ†æ€§çš„è¶…åƒç´ è¡¨ç¤ºã€‚</li>
<li>å¼•å…¥åˆç†çš„æ•°æ®å¢å¼ºå¯¹æ¯”èšç±»ï¼Œè§£å†³äº†ä¼ ç»Ÿå¯¹æ¯”å­¦ä¹ å¯èƒ½æŸå®³èšç±»ç»“æ„çš„é—®é¢˜ã€‚</li>
<li>é’ˆå¯¹HSIè¶…åƒç´ è®¾è®¡ä¸¤ç§è¯­ä¹‰ä¸å˜çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼šåƒç´ é‡‡æ ·å¢å¼ºå’Œæ¨¡å‹æƒé‡å¢å¼ºã€‚</li>
<li>å®ç°æ ·æœ¬çº§å¯¹é½å’Œèšç±»ä¸­å¿ƒçº§å¯¹æ¯”ï¼Œæé«˜è¶…åƒç´ åµŒå…¥çš„ç±»å†…ç›¸ä¼¼æ€§å’Œç±»é—´å·®å¼‚æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.01799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4526a930b353088910cbe17310213a8a" align="middle">
<img src="https://picx.zhimg.com/v2-791816d2439234f0096810ca3b2f8b8a" align="middle">
<img src="https://picx.zhimg.com/v2-8cf97f1f97719d6c90e635a68c648826" align="middle">
<img src="https://picx.zhimg.com/v2-4885cb50e7327dfefd795a7a8a377d3d" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-af3d3c2296e160340e135672856ebb89" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  Accurate Thyroid Cancer Classification using a Novel Binary Pattern   Driven Local Discrete Cosine Transform Descriptor
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f4d6ca190ffea9ea27fa48f23675a116" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  FROQ Observing Face Recognition Models for Efficient Quality Assessment
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33125.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
