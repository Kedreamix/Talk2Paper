<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  Towards Seeing Bones at Radio Frequency">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_4_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-04
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    82 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-24-æ›´æ–°"><a href="#2025-09-24-æ›´æ–°" class="headerlink" title="2025-09-24 æ›´æ–°"></a>2025-09-24 æ›´æ–°</h1><h2 id="Towards-Seeing-Bones-at-Radio-Frequency"><a href="#Towards-Seeing-Bones-at-Radio-Frequency" class="headerlink" title="Towards Seeing Bones at Radio Frequency"></a>Towards Seeing Bones at Radio Frequency</h2><p><strong>Authors:Yiwen Song, Hongyang Li, Kuang Yuan, Ran Bi, Swarun Kumar</strong></p>
<p>Wireless sensing literature has long aspired to achieve X-ray-like vision at radio frequencies. Yet, state-of-the-art wireless sensing literature has yet to generate the archetypal X-ray image: one of the bones beneath flesh. In this paper, we explore MCT, a penetration-based RF-imaging system for imaging bones at mm-resolution, one that significantly exceeds prior penetration-based RF imaging literature. Indeed the long wavelength, significant attenuation and complex diffraction that occur as RF propagates through flesh, have long limited imaging resolution (to several centimeters at best). We address these concerns through a novel penetration-based synthetic aperture algorithm, coupled with a learning-based pipeline to correct for diffraction-induced artifacts. A detailed evaluation of meat models demonstrates a resolution improvement from sub-decimeter to sub-centimeter over prior art in RF penetrative imaging. </p>
<blockquote>
<p>æ— çº¿ä¼ æ„Ÿæ–‡çŒ®é•¿æœŸä»¥æ¥ä¸€ç›´æ¸´æœ›å®ç°åœ¨å°„é¢‘ä¸‹çš„ç±»ä¼¼Xå°„çº¿çš„è§†è§‰ã€‚ç„¶è€Œï¼Œæœ€å…ˆè¿›çš„æ— çº¿ä¼ æ„Ÿæ–‡çŒ®å°šæœªç”Ÿæˆå…¸å‹çš„Xå°„çº¿å›¾åƒï¼šå³è‚‰ä¸‹çš„éª¨éª¼å›¾åƒã€‚æœ¬æ–‡æ¢è®¨äº†MCTè¿™ä¸€åŸºäºç©¿é€çš„å°„é¢‘æˆåƒç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿä»¥æ¯«ç±³çº§åˆ†è¾¨ç‡å¯¹éª¨éª¼è¿›è¡Œæˆåƒï¼Œæ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰çš„ç©¿é€å¼å°„é¢‘æˆåƒæ–‡çŒ®ã€‚å®é™…ä¸Šï¼Œå°„é¢‘åœ¨ä¼ æ’­è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿè¾ƒé•¿çš„æ³¢é•¿ã€è¾ƒå¤§çš„è¡°å‡å’Œå¤æ‚çš„è¡å°„ç°è±¡ï¼Œé•¿æœŸä»¥æ¥ä¸€ç›´é™åˆ¶äº†æˆåƒåˆ†è¾¨ç‡ï¼ˆæœ€å¤šè¾¾åˆ°å‡ å˜ç±³ï¼‰ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ç§æ–°å‹çš„åŸºäºç©¿é€çš„åˆæˆå­”å¾„ç®—æ³•ï¼Œä»¥åŠåŸºäºå­¦ä¹ çš„ç®¡é“æ¥æ ¡æ­£è¡å°„å¼•èµ·çš„ä¼ªå½±æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚å¯¹è‚‰ç±»æ¨¡å‹çš„è¯¦ç»†è¯„ä¼°è¡¨æ˜ï¼Œä¸å…ˆå‰çš„å°„é¢‘ç©¿é€æˆåƒæŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æˆåƒæŠ€æœ¯åˆ†è¾¨ç‡ä»åˆ†ç±³çº§æé«˜åˆ°äº†å˜ç±³çº§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17979v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢ç´¢äº†ä¸€ç§åŸºäºç©¿é€çš„RFæˆåƒç³»ç»ŸMCTï¼Œèƒ½å¤Ÿä»¥æ¯«ç±³çº§åˆ†è¾¨ç‡æˆåƒéª¨éª¼ï¼Œæ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰çš„ç©¿é€å¼RFæˆåƒæ–‡çŒ®ã€‚é’ˆå¯¹RFä¿¡å·åœ¨ä¼ æ’­è¿‡ç¨‹ä¸­å—åˆ°çš„é•¿æ³¢é•¿ã€å¤§å¹…è¡°å‡å’Œå¤æ‚è¡å°„é—®é¢˜ï¼Œè¯¥æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ç©¿é€å¼åˆæˆå­”å¾„ç®—æ³•ï¼Œå¹¶ç»“åˆå­¦ä¹ ç®¡é“æ ¡æ­£è¡å°„å¼•èµ·çš„ä¼ªå½±ã€‚å¯¹è‚‰ç±»æ¨¡å‹çš„è¯¦ç»†è¯„ä¼°æ˜¾ç¤ºï¼Œåœ¨å°„é¢‘ç©¿é€æˆåƒæ–¹é¢ï¼Œå…¶åˆ†è¾¨ç‡è¾ƒä¹‹å‰çš„æŠ€æœ¯æœ‰æ‰€æå‡ï¼Œä»åˆ†ç±³çº§æé«˜åˆ°äº†å˜ç±³çº§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡æ—¨åœ¨å®ç°æ— çº¿ä¼ æ„Ÿçš„Xå°„çº¿è§†è§‰ï¼Œæ¢ç´¢äº†ä¸€ç§æ–°çš„RFæˆåƒç³»ç»ŸMCTã€‚</li>
<li>MCTç³»ç»Ÿèƒ½å¤Ÿæ˜¾è‘—è¶…è¶Šç°æœ‰ç©¿é€å¼RFæˆåƒæŠ€æœ¯çš„åˆ†è¾¨ç‡ï¼Œå®ç°æ¯«ç±³çº§éª¨éª¼æˆåƒã€‚</li>
<li>RFä¿¡å·åœ¨ä¼ æ’­è¿‡ç¨‹ä¸­é¢ä¸´é•¿æ³¢é•¿ã€å¤§å¹…è¡°å‡å’Œå¤æ‚è¡å°„çš„é—®é¢˜ã€‚</li>
<li>é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ç©¿é€å¼åˆæˆå­”å¾„ç®—æ³•ã€‚</li>
<li>è¯¥ç®—æ³•ç»“åˆå­¦ä¹ ç®¡é“ï¼Œèƒ½å¤Ÿæ ¡æ­£å› è¡å°„å¯¼è‡´çš„å›¾åƒä¼ªå½±ã€‚</li>
<li>åœ¨è‚‰ç±»æ¨¡å‹ä¸Šçš„è¯¦ç»†è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æŠ€æœ¯åœ¨RFç©¿é€æˆåƒçš„åˆ†è¾¨ç‡ä¸Šæœ‰æ‰€æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17979">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17979v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17979v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17979v1/page_3_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SmaRT-Style-Modulated-Robust-Test-Time-Adaptation-for-Cross-Domain-Brain-Tumor-Segmentation-in-MRI"><a href="#SmaRT-Style-Modulated-Robust-Test-Time-Adaptation-for-Cross-Domain-Brain-Tumor-Segmentation-in-MRI" class="headerlink" title="SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain   Brain Tumor Segmentation in MRI"></a>SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain   Brain Tumor Segmentation in MRI</h2><p><strong>Authors:Yuanhan Wang, Yifei Chen, Shuo Jiang, Wenjing Yu, Mingxuan Liu, Beining Wu, Jinying Zong, Feiwei Qin, Changmiao Wang, Qiyuan Tian</strong></p>
<p>Reliable brain tumor segmentation in MRI is indispensable for treatment planning and outcome monitoring, yet models trained on curated benchmarks often fail under domain shifts arising from scanner and protocol variability as well as population heterogeneity. Such gaps are especially severe in low-resource and pediatric cohorts, where conventional test-time or source-free adaptation strategies often suffer from instability and structural inconsistency. We propose SmaRT, a style-modulated robust test-time adaptation framework that enables source-free cross-domain generalization. SmaRT integrates style-aware augmentation to mitigate appearance discrepancies, a dual-branch momentum strategy for stable pseudo-label refinement, and structural priors enforcing consistency, integrity, and connectivity. This synergy ensures both adaptation stability and anatomical fidelity under extreme domain shifts. Extensive evaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRT consistently outperforms state-of-the-art methods, with notable gains in Dice accuracy and boundary precision. Overall, SmaRT bridges the gap between algorithmic advances and equitable clinical applicability, supporting robust deployment of MRI-based neuro-oncology tools in diverse clinical environments. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/baiyou1234/SmaRT">https://github.com/baiyou1234/SmaRT</a>. </p>
<blockquote>
<p>å¯é çš„è„‘è‚¿ç˜¤MRIåˆ†å‰²å¯¹æ²»ç–—è®¡åˆ’å’Œç–—æ•ˆç›‘æµ‹è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨æ‰«æä»ªå’Œåè®®å˜åŒ–ä»¥åŠäººç¾¤å¼‚è´¨æ€§å¼•èµ·çš„é¢†åŸŸè½¬ç§»ä¸­ï¼Œç»è¿‡ç²¾å¿ƒè®­ç»ƒçš„æ¨¡å‹å¾€å¾€ä¼šå‡ºç°å¤±æ•ˆã€‚è¿™ç§å·®è·åœ¨ä½èµ„æºå’Œå„¿ç§‘ç¾¤ä½“ä¸­å°¤ä¸ºä¸¥é‡ï¼Œä¼ ç»Ÿæµ‹è¯•æ—¶é—´æˆ–æ— éœ€æºé€‚åº”çš„ç­–ç•¥å¾€å¾€é¢ä¸´ä¸ç¨³å®šå’Œç»“æ„ä¸ä¸€è‡´çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†SmaRTï¼Œè¿™æ˜¯ä¸€ç§é£æ ¼è°ƒåˆ¶é²æ£’çš„æµ‹è¯•æ—¶é—´è‡ªé€‚åº”æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°æ— æºçš„è·¨åŸŸæ³›åŒ–ã€‚SmaRTé›†æˆäº†é£æ ¼æ„ŸçŸ¥å¢å¼ºæ¥å‡å°‘å¤–è§‚å·®å¼‚ï¼ŒåŒåˆ†æ”¯åŠ¨é‡ç­–ç•¥ç”¨äºç¨³å®šçš„ä¼ªæ ‡ç­¾ç»†åŒ–ï¼Œä»¥åŠç»“æ„å…ˆéªŒå¼ºåˆ¶ä¸€è‡´æ€§ã€å®Œæ•´æ€§å’Œè¿é€šæ€§ã€‚è¿™ç§ååŒä½œç”¨ç¡®ä¿äº†æç«¯é¢†åŸŸè½¬ç§»ä¸‹çš„é€‚åº”ç¨³å®šæ€§å’Œè§£å‰–ä¿çœŸåº¦ã€‚åœ¨æ’’å“ˆæ‹‰ä»¥å—éæ´²å’Œå„¿ç§‘èƒ¶è´¨ç˜¤æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSmaRTå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨Diceç²¾åº¦å’Œè¾¹ç•Œç²¾åº¦æ–¹é¢æœ‰æ˜¾è‘—çš„æå‡ã€‚æ€»ä½“è€Œè¨€ï¼ŒSmaRTå¼¥è¡¥äº†ç®—æ³•è¿›æ­¥å’Œå…¬å¹³ä¸´åºŠåº”ç”¨ä¹‹é—´çš„é¸¿æ²Ÿï¼Œæ”¯æŒåœ¨å¤šæ ·åŒ–çš„ä¸´åºŠç¯å¢ƒä¸­ç¨³å¥éƒ¨ç½²åŸºäºMRIçš„ç¥ç»è‚¿ç˜¤å­¦å·¥å…·ã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/baiyou1234/SmaRT%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/baiyou1234/SmaRTä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17925v1">PDF</a> 11 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSmaRTçš„é£æ ¼è°ƒåˆ¶ç¨³å¥æµ‹è¯•æ—¶é—´è‡ªé€‚åº”æ¡†æ¶ï¼Œå®ç°äº†æ— æºçš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡é›†æˆé£æ ¼æ„ŸçŸ¥å¢å¼ºã€åŒåˆ†æ”¯åŠ¨é‡ç­–ç•¥å’Œç»“æ„æ€§å…ˆéªŒçŸ¥è¯†ï¼Œç¡®ä¿åœ¨æç«¯åŸŸè½¬ç§»ä¸‹çš„é€‚åº”æ€§å’Œè§£å‰–å­¦ä¿çœŸåº¦ã€‚åœ¨æ’’å“ˆæ‹‰ä»¥å—éæ´²å’Œå„¿ç§‘èƒ¶è´¨ç˜¤æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSmaRTåœ¨ç‹„æ°ç²¾åº¦å’Œè¾¹ç•Œç²¾åº¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼ŒæˆåŠŸç¼©å°äº†ç®—æ³•è¿›æ­¥ä¸å…¬å¹³ä¸´åºŠåº”ç”¨ä¹‹é—´çš„å·®è·ï¼Œæ”¯æŒMRIç¥ç»è‚¿ç˜¤å­¦å·¥å…·åœ¨ä¸åŒä¸´åºŠç¯å¢ƒä¸­çš„ç¨³å¥éƒ¨ç½²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯é çš„è„‘è‚¿ç˜¤MRIåˆ†å‰²å¯¹äºæ²»ç–—è§„åˆ’å’Œç»“æœç›‘æµ‹è‡³å…³é‡è¦ã€‚ä½†å®é™…åº”ç”¨ä¸­é¢ä¸´æ¥è‡ªæ‰«æä»ªã€åè®®å˜åŒ–å’Œäººç¾¤å·®å¼‚çš„é¢†åŸŸè¿ç§»é—®é¢˜ã€‚</li>
<li>åœ¨ä½èµ„æºå’Œå„¿ç§‘ç¾¤ä½“ä¸­ï¼Œä¼ ç»Ÿçš„æµ‹è¯•æ—¶é—´æˆ–æ— éœ€æºé€‚åº”ç­–ç•¥å­˜åœ¨ä¸ç¨³å®šæ€§å’Œç»“æ„ä¸ä¸€è‡´æ€§ã€‚</li>
<li>SmaRTæ¡†æ¶é€šè¿‡é£æ ¼æ„ŸçŸ¥å¢å¼ºæ¥å‡è½»å¤–è§‚å·®å¼‚ï¼Œå®ç°è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>SmaRTé‡‡ç”¨åŒåˆ†æ”¯åŠ¨é‡ç­–ç•¥è¿›è¡Œç¨³å®šçš„ä¼ªæ ‡ç­¾ä¼˜åŒ–ï¼Œç¡®ä¿é€‚åº”æ€§ç¨³å®šæ€§ã€‚</li>
<li>é€šè¿‡ç»“æ„æ€§å…ˆéªŒçŸ¥è¯†å¼ºåŒ–ä¸€è‡´æ€§ã€å®Œæ•´æ€§å’Œè¿é€šæ€§ï¼Œç¡®ä¿è§£å‰–å­¦ä¿çœŸåº¦ã€‚</li>
<li>åœ¨æ’’å“ˆæ‹‰ä»¥å—éæ´²å’Œå„¿ç§‘èƒ¶è´¨ç˜¤æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒSmaRTåœ¨ç‹„æ°ç²¾åº¦å’Œè¾¹ç•Œç²¾åº¦æ–¹é¢è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17925">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17925v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17925v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17925v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Monte-Carlo-parameter-study-for-Seyfert-AGN-starburst-composite-galaxies-NGC1068-and-NGC7469"><a href="#Monte-Carlo-parameter-study-for-Seyfert-AGN-starburst-composite-galaxies-NGC1068-and-NGC7469" class="headerlink" title="Monte Carlo parameter study for Seyfert AGN-starburst composite galaxies   NGC1068 and NGC7469"></a>Monte Carlo parameter study for Seyfert AGN-starburst composite galaxies   NGC1068 and NGC7469</h2><p><strong>Authors:Silvia Salvatore, BjÃ¶rn Eichmann, Giacomo Sommani, Santiago del Palacio, Patrik M. Veres, Julia Becker Tjus</strong></p>
<p>Seyfert-starburst composite galaxies host two promising phenomena of non-thermal high-energy radiation. In this regard the IceCube observation of high-energy neutrinos from the direction of the Seyfert-starburst composite galaxy NGC 1068 is not surprising. More recently, another Seyfert-starburst composite galaxy, NGC 7469, has shown hints for neutrino emission at even higher energies. Theoretical investigations could clarify that their so-called AGN corona is the most-likely origin of these neutrinos due to the need of being partially $\gamma$-ray opaque. In this work, we present an updated version of our Seyfert-starburst composite model from 2022, that accounts for a proper treatment of the stochastic acceleration processes in the AGN corona and the secondary electrons and positrons from leptonic radiation processes. Moreover, we use a Markov Chain Monte Carlo (MCMC) approach to study the parameter space of these two potential high-energy neutrino sources under consideration of the given prior knowledge. In the case of NGC 1068, we can successfully explain its non-thermal observational features, where both its AGN corona and starburst ring are needed to account for the observations at high- energies. In the case of NGC 7469, the high-energy signatures can only be explained assuming a small coronal radius and the including external $\gamma\gamma$-pair attenuation. In general, both sources exhibit a strong influence of the $\gamma$-ray opaqueness on the results, highlighting the need for an accurate treatment of the intrinsic coronal X-ray field and the spatial extent of the $\gamma$-ray production site. </p>
<blockquote>
<p>å¡å¼—ç‰¹æ˜Ÿçˆ†å‘å¤åˆæ˜Ÿç³»æœ‰ä¸¤ç§å…·æœ‰å‰æ™¯çš„éçƒ­é«˜èƒ½è¾å°„ç°è±¡ã€‚å› æ­¤ï¼Œä»å¡å¼—ç‰¹æ˜Ÿçˆ†å‘å¤åˆæ˜Ÿç³»NGC 1068æ–¹å‘è§‚æµ‹åˆ°IceCubeçš„é«˜èƒ½ä¸­å¾®å­å¹¶ä¸æ„å¤–ã€‚æœ€è¿‘ï¼Œå¦ä¸€ä¸ªå¡å¼—ç‰¹æ˜Ÿçˆ†å‘å¤åˆæ˜Ÿç³»NGC 7469æ˜¾ç¤ºå‡ºæ›´é«˜èƒ½é‡ä¸‹çš„ä¸­å¾®å­å‘å°„è¿¹è±¡ã€‚ç†è®ºç ”ç©¶è¡¨æ˜ï¼Œç”±äºéœ€è¦éƒ¨åˆ†Î³å°„çº¿ä¸é€æ€§ï¼Œæ‰€è°“çš„æ´»åŠ¨æ˜Ÿç³»æ ¸å†•å¯èƒ½æ˜¯è¿™äº›ä¸­å¾®å­çš„æœ€å¯èƒ½æ¥æºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æ›´æ–°åçš„å¡å¼—ç‰¹æ˜Ÿçˆ†å‘å¤åˆæ¨¡å‹ï¼ˆ2022ç‰ˆï¼‰ï¼Œè¯¥æ¨¡å‹è€ƒè™‘äº†æ´»åŠ¨æ˜Ÿç³»æ ¸å†•ä¸­éšæœºåŠ é€Ÿè¿‡ç¨‹çš„é€‚å½“å¤„ç†ä»¥åŠæ¥è‡ªè½»å­è¾å°„è¿‡ç¨‹çš„æ¬¡çº§ç”µå­å’Œæ­£ç”µå­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡ç½—ï¼ˆMCMCï¼‰æ–¹æ³•ï¼Œæ ¹æ®å·²æœ‰çš„å…ˆéªŒçŸ¥è¯†æ¥ç ”ç©¶è¿™ä¸¤ä¸ªæ½œåœ¨çš„é«˜èƒ½ä¸­å¾®å­æºçš„å‚æ•°ç©ºé—´ã€‚å¯¹äºNGC 1068ï¼Œæˆ‘ä»¬å¯ä»¥æˆåŠŸè§£é‡Šå…¶éçƒ­è§‚æµ‹ç‰¹å¾ï¼Œå…¶ä¸­æ—¢éœ€è¦å…¶æ´»åŠ¨æ˜Ÿç³»æ ¸å†•ä¹Ÿéœ€è¦å…¶æ˜Ÿçˆ†ç¯æ¥è§£é‡Šé«˜èƒ½è§‚æµ‹ç»“æœã€‚å¯¹äºNGC 7469ï¼Œé«˜èƒ½ç‰¹å¾åªèƒ½å‡è®¾è¾ƒå°çš„å†•åŠå¾„å¹¶åŒ…æ‹¬å¤–éƒ¨Î³Î³å¯¹è¡°å‡æ‰èƒ½å¾—åˆ°è§£é‡Šã€‚æ€»çš„æ¥è¯´ï¼Œä¸¤ä¸ªæºçš„ç»“æœéƒ½å¼ºçƒˆå—åˆ°Î³å°„çº¿ä¸é€æ€§çš„å½±å“ï¼Œè¿™å¼ºè°ƒäº†éœ€è¦å‡†ç¡®å¤„ç†å†…åœ¨çš„å† çŠ¶Xå°„çº¿åœºå’ŒÎ³å°„çº¿äº§ç”Ÿéƒ¨ä½çš„ç©ºé—´èŒƒå›´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17751v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¡å¼—ç‰¹-æ˜Ÿæš´å¤åˆæ˜Ÿç³»è¡¨ç°å‡ºéçƒ­é«˜èƒ½è¾å°„çš„ä¸¤ä¸ªæœ‰å‰æ™¯çš„ç°è±¡ã€‚IceCubeå¯¹å¡å¼—ç‰¹-æ˜Ÿæš´å¤åˆæ˜Ÿç³»NGC 1068çš„é«˜èƒ½ä¸­å¾®å­è§‚æµ‹å¹¶ä¸æ„å¤–ã€‚æœ€è¿‘ï¼Œå¦ä¸€ä¸ªå¡å¼—ç‰¹-æ˜Ÿæš´å¤åˆæ˜Ÿç³»NGC 7469æ˜¾ç¤ºå‡ºæ›´é«˜èƒ½çº§çš„ä¸­å¾®å­å‘å°„è¿¹è±¡ã€‚ç†è®ºç ”ç©¶è¡¨æ˜ï¼Œç”±äºéœ€è¦éƒ¨åˆ†Î³å°„çº¿é®è”½ï¼Œæ‰€è°“çš„æ´»åŠ¨æ˜Ÿç³»æ ¸å†•å¯èƒ½æ˜¯è¿™äº›ä¸­å¾®å­çš„èµ·æºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æ›´æ–°åçš„å¡å¼—ç‰¹-æ˜Ÿæš´å¤åˆæ¨¡å‹ï¼ˆ2022ç‰ˆï¼‰ï¼Œè¯¥æ¨¡å‹å¯¹æ´»åŠ¨æ˜Ÿç³»æ ¸å†•ä¸­çš„éšæœºåŠ é€Ÿè¿‡ç¨‹ä»¥åŠæ¥è‡ªè½»å­è¾å°„è¿‡ç¨‹çš„æ¬¡çº§ç”µå­å’Œæ­£ç”µå­è¿›è¡Œäº†é€‚å½“å¤„ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ï¼ˆMCMCï¼‰æ–¹æ³•ï¼Œæ ¹æ®ç°æœ‰å…ˆéªŒçŸ¥è¯†ç ”ç©¶è¿™ä¸¤ä¸ªæ½œåœ¨é«˜èƒ½ä¸­å¾®å­æºå‚æ•°ç©ºé—´ã€‚åœ¨NGC 1068çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬èƒ½å¤ŸæˆåŠŸè§£é‡Šå…¶éçƒ­è§‚æµ‹ç‰¹å¾ï¼Œå…¶ä¸­æ—¢éœ€è¦å…¶æ´»åŠ¨æ˜Ÿç³»æ ¸å†•ä¹Ÿéœ€è¦æ˜Ÿæš´ç¯æ¥è§£é‡Šé«˜èƒ½è§‚æµ‹ç»“æœã€‚åœ¨NGC 7469çš„æƒ…å†µä¸‹ï¼Œé«˜èƒ½ç‰¹å¾åªèƒ½å‡è®¾è¾ƒå°çš„å†•åŠå¾„å¹¶åŒ…æ‹¬å¤–éƒ¨Î³Î³å¯¹è¡°å‡æ¥è§£é‡Šã€‚æ€»çš„æ¥è¯´ï¼Œä¸¤ä¸ªæºéƒ½è¡¨ç°å‡ºÎ³å°„çº¿é®è”½å¯¹ç»“æœçš„å½±å“ï¼Œå¼ºè°ƒäº†å¯¹å›ºæœ‰å† çŠ¶Xå°„çº¿åœºå’ŒÎ³å°„çº¿äº§ç”Ÿä½ç‚¹ç©ºé—´èŒƒå›´çš„å‡†ç¡®å¤„ç†çš„å¿…è¦æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¡å¼—ç‰¹-æ˜Ÿæš´å¤åˆæ˜Ÿç³»è¡¨ç°å‡ºéçƒ­é«˜èƒ½è¾å°„ç°è±¡ã€‚</li>
<li>NGC 1068å’ŒNGC 7469æ˜¯ä¸¤ä¸ªå…·æœ‰é«˜èƒ½ä¸­å¾®å­å‘å°„è¿¹è±¡çš„æ˜Ÿç³»ã€‚</li>
<li>ç†è®ºç ”ç©¶è¡¨æ˜ï¼Œæ´»åŠ¨æ˜Ÿç³»æ ¸å†•å¯èƒ½æ˜¯è¿™äº›ä¸­å¾®å­çš„èµ·æºï¼Œéœ€è¦éƒ¨åˆ†Î³å°„çº¿é®è”½ã€‚</li>
<li>æ›´æ–°çš„å¡å¼—ç‰¹-æ˜Ÿæš´å¤åˆæ¨¡å‹è€ƒè™‘äº†æ´»åŠ¨æ˜Ÿç³»æ ¸å†•ä¸­çš„éšæœºåŠ é€Ÿè¿‡ç¨‹å’Œè½»å­è¾å°„çš„æ¬¡çº§ç”µå­å’Œæ­£ç”µå­ã€‚</li>
<li>é‡‡ç”¨MCMCæ–¹æ³•ç ”ç©¶äº†è¿™ä¸¤ä¸ªæ˜Ÿç³»çš„ä¸­å¾®å­æºå‚æ•°ç©ºé—´ã€‚</li>
<li>åœ¨NGC 1068çš„æƒ…å†µä¸‹ï¼Œéœ€è¦åŒæ—¶è€ƒè™‘å…¶æ ¸å†•å’Œæ˜Ÿæš´ç¯æ¥è§£é‡Šé«˜èƒ½è§‚æµ‹ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17751">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17751v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17751v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17751v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Automated-Labeling-of-Intracranial-Arteries-with-Uncertainty-Quantification-Using-Deep-Learning"><a href="#Automated-Labeling-of-Intracranial-Arteries-with-Uncertainty-Quantification-Using-Deep-Learning" class="headerlink" title="Automated Labeling of Intracranial Arteries with Uncertainty   Quantification Using Deep Learning"></a>Automated Labeling of Intracranial Arteries with Uncertainty   Quantification Using Deep Learning</h2><p><strong>Authors:Javier Bisbal, Patrick Winter, Sebastian Jofre, Aaron Ponce, Sameer A. Ansari, Ramez Abdalla, Michael Markl, Oliver Welin Odeback, Sergio Uribe, Cristian Tejos, Julio Sotelo, Susanne Schnell, David Marlevi</strong></p>
<p>Accurate anatomical labeling of intracranial arteries is essential for cerebrovascular diagnosis and hemodynamic analysis but remains time-consuming and subject to interoperator variability. We present a deep learning-based framework for automated artery labeling from 3D Time-of-Flight Magnetic Resonance Angiography (3D ToF-MRA) segmentations (n&#x3D;35), incorporating uncertainty quantification to enhance interpretability and reliability. We evaluated three convolutional neural network architectures: (1) a UNet with residual encoder blocks, reflecting commonly used baselines in vascular labeling; (2) CS-Net, an attention-augmented UNet incorporating channel and spatial attention mechanisms for enhanced curvilinear structure recognition; and (3) nnUNet, a self-configuring framework that automates preprocessing, training, and architectural adaptation based on dataset characteristics. Among these, nnUNet achieved the highest labeling performance (average Dice score: 0.922; average surface distance: 0.387 mm), with improved robustness in anatomically complex vessels. To assess predictive confidence, we implemented test-time augmentation (TTA) and introduced a novel coordinate-guided strategy to reduce interpolation errors during augmented inference. The resulting uncertainty maps reliably indicated regions of anatomical ambiguity, pathological variation, or manual labeling inconsistency. We further validated clinical utility by comparing flow velocities derived from automated and manual labels in co-registered 4D Flow MRI datasets, observing close agreement with no statistically significant differences. Our framework offers a scalable, accurate, and uncertainty-aware solution for automated cerebrovascular labeling, supporting downstream hemodynamic analysis and facilitating clinical integration. </p>
<blockquote>
<p>ç²¾ç¡®è§£å‰–æ ‡è®°é¢…å†…åŠ¨è„‰å¯¹è„‘è¡€ç®¡ç–¾ç—…çš„è¯Šæ–­å’Œè¡€æµåŠ¨åŠ›å­¦åˆ†æè‡³å…³é‡è¦ï¼Œä½†è¿™ä»æ˜¯ä¸€é¡¹è€—æ—¶çš„ä»»åŠ¡ï¼Œå¹¶ä¸”å­˜åœ¨æ“ä½œè€…ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åŒ–åŠ¨è„‰æ ‡è®°æ¡†æ¶ï¼Œå¯ä»ä¸‰ç»´é£è¡Œæ—¶é—´ç£å…±æŒ¯è¡€ç®¡é€ å½±ï¼ˆ3D ToF-MRAï¼‰åˆ†å‰²æ•°æ®ä¸­å¾—å‡ºï¼ˆn&#x3D;35ï¼‰ï¼Œå¹¶ç»“åˆä¸ç¡®å®šæ€§é‡åŒ–æ¥æé«˜å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸‰ç§å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼šï¼ˆ1ï¼‰å¸¦æœ‰æ®‹å·®ç¼–ç å™¨å—çš„UNetï¼Œè¿™æ˜¯è¡€ç®¡æ ‡è®°ä¸­å¸¸ç”¨çš„åŸºå‡†çº¿ï¼›ï¼ˆ2ï¼‰CS-Netï¼Œä¸€ç§å¢å¼ºå‹UNetï¼Œç»“åˆäº†é€šé“å’Œç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æé«˜æ›²çº¿ç»“æ„çš„è¯†åˆ«èƒ½åŠ›ï¼›ï¼ˆ3ï¼‰nnUNetï¼Œä¸€ä¸ªè‡ªé…ç½®æ¡†æ¶ï¼Œå¯åŸºäºæ•°æ®é›†ç‰¹æ€§è‡ªåŠ¨åŒ–é¢„å¤„ç†ã€è®­ç»ƒå’Œæ¶æ„è°ƒæ•´ã€‚å…¶ä¸­ï¼ŒnnUNetçš„æ ‡è®°æ€§èƒ½æœ€é«˜ï¼ˆå¹³å‡Diceå¾—åˆ†ä¸º0.922ï¼Œå¹³å‡è¡¨é¢è·ç¦»ä¸º0.387æ¯«ç±³ï¼‰ï¼Œåœ¨è§£å‰–ç»“æ„å¤æ‚çš„è¡€ç®¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„ç¨³å¥æ€§ã€‚ä¸ºäº†è¯„ä¼°é¢„æµ‹ç½®ä¿¡åº¦ï¼Œæˆ‘ä»¬å®æ–½äº†æµ‹è¯•æ—¶é—´å¢å¼ºï¼ˆTTAï¼‰å¹¶å¼•å…¥äº†ä¸€ç§æ–°å‹åæ ‡å¼•å¯¼ç­–ç•¥ï¼Œä»¥å‡å°‘å¢å¼ºæ¨ç†è¿‡ç¨‹ä¸­çš„æ’å€¼è¯¯å·®ã€‚æ‰€å¾—çš„ä¸ç¡®å®šæ€§å›¾å¯é åœ°æŒ‡ç¤ºäº†è§£å‰–æ¨¡ç³Šã€ç—…ç†å˜åŒ–æˆ–æ‰‹åŠ¨æ ‡è®°ä¸ä¸€è‡´çš„åŒºåŸŸã€‚æˆ‘ä»¬é€šè¿‡æ¯”è¾ƒè‡ªåŠ¨å’Œæ‰‹åŠ¨æ ‡è®°åœ¨æ³¨å†Œçš„4Dè¡€æµMRIæ•°æ®é›†ä¸­çš„æµé€Ÿæ¥è¿›ä¸€æ­¥éªŒè¯ä¸´åºŠå®ç”¨æ€§ï¼Œè§‚å¯Ÿåˆ°ä¸¤è€…é—´æ— ç»Ÿè®¡å­¦ä¸Šçš„æ˜¾è‘—å·®å¼‚ï¼Œä¸€è‡´æ€§è¾ƒå¥½ã€‚æˆ‘ä»¬çš„æ¡†æ¶æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ã€å‡†ç¡®ã€å…·æœ‰ä¸ç¡®å®šæ€§çš„è‡ªåŠ¨åŒ–è„‘è¡€ç®¡æ ‡è®°è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒä¸‹æ¸¸è¡€æµåŠ¨åŠ›å­¦åˆ†æï¼Œä¿ƒè¿›ä¸´åºŠæ•´åˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17726v1">PDF</a> 16 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åŒ–é¢…å†…åŠ¨è„‰æ ‡æ³¨æ¡†æ¶ï¼Œåº”ç”¨äº3Dæ—¶é—´é£è¡Œç£å…±æŒ¯è¡€ç®¡é€ å½±ï¼ˆ3D ToF-MRAï¼‰åˆ†å‰²ã€‚è¯¥æ¡†æ¶ç»“åˆä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæé«˜äº†è§£é‡Šæ€§å’Œå¯é æ€§ã€‚è¯„ä¼°äº†ä¸‰ç§å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼Œæœ€ç»ˆå‘ç°nnUNetåœ¨è§£å‰–å¤æ‚è¡€ç®¡ä¸­è¡¨ç°å‡ºæœ€é«˜çš„æ ‡æ³¨æ€§èƒ½ã€‚é€šè¿‡æµ‹è¯•æ—¶é—´å¢å¼ºå’Œä¸€ç§æ–°çš„åæ ‡å¼•å¯¼ç­–ç•¥ï¼Œè¯¥æ¡†æ¶çš„ä¸ç¡®å®šæ€§åœ°å›¾èƒ½å¯é åœ°æŒ‡ç¤ºè§£å‰–æ¨¡ç³Šã€ç—…ç†å˜åŒ–æˆ–æ‰‹åŠ¨æ ‡æ³¨ä¸ä¸€è‡´çš„åŒºåŸŸã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¸æ‰‹åŠ¨æ ‡ç­¾åœ¨æ³¨å†Œçš„4Dè¡€æµMRIæ•°æ®é›†ä¸Šçš„æµé€Ÿå¯¹æ¯”ï¼ŒéªŒè¯äº†å…¶ä¸´åºŠå®ç”¨æ€§ã€‚è¯¥æ¡†æ¶ä¸ºä¸‹æ¸¸è¡€æµåŠ¨åŠ›å­¦åˆ†æå’Œä¸´åºŠæ•´åˆæä¾›äº†å¯æ‰©å±•ã€å‡†ç¡®å’Œè€ƒè™‘ä¸ç¡®å®šæ€§çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨åŒ–é¢…å†…åŠ¨è„‰æ ‡æ³¨å¯¹è„‘è¡€ç®¡è¯Šæ–­å’Œè¡€æµåŠ¨åŠ›å­¦åˆ†æè‡³å…³é‡è¦ã€‚</li>
<li>ä»‹ç»äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åŒ–åŠ¨è„‰æ ‡æ³¨æ¡†æ¶ï¼Œåº”ç”¨äº3D ToF-MRAåˆ†å‰²ã€‚</li>
<li>ç»“åˆä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæé«˜æ¨¡å‹çš„è§£é‡Šæ€§å’Œå¯é æ€§ã€‚</li>
<li>è¯„ä¼°äº†ä¸‰ç§å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå…¶ä¸­nnUNetåœ¨å¤æ‚è¡€ç®¡ç»“æ„ä¸­è¡¨ç°æœ€ä½³ã€‚</li>
<li>é€šè¿‡æµ‹è¯•æ—¶é—´å¢å¼ºå’Œåæ ‡å¼•å¯¼ç­–ç•¥ï¼Œç”Ÿæˆä¸ç¡®å®šæ€§åœ°å›¾ä»¥æŒ‡ç¤ºæ¨¡ç³Šæˆ–ä¸ä¸€è‡´åŒºåŸŸã€‚</li>
<li>æ¡†æ¶çš„ä¸´åºŠå®ç”¨æ€§é€šè¿‡å¯¹æ¯”è‡ªåŠ¨åŒ–å’Œæ‰‹åŠ¨æ ‡ç­¾çš„æµé€Ÿå¾—åˆ°éªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17726">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17726v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MRN-Harnessing-2D-Vision-Foundation-Models-for-Diagnosing-Parkinsonâ€™s-Disease-with-Limited-3D-MR-Data"><a href="#MRN-Harnessing-2D-Vision-Foundation-Models-for-Diagnosing-Parkinsonâ€™s-Disease-with-Limited-3D-MR-Data" class="headerlink" title="MRN: Harnessing 2D Vision Foundation Models for Diagnosing Parkinsonâ€™s   Disease with Limited 3D MR Data"></a>MRN: Harnessing 2D Vision Foundation Models for Diagnosing Parkinsonâ€™s   Disease with Limited 3D MR Data</h2><p><strong>Authors:Ding Shaodong, Liu Ziyang, Zhou Yijun, Liu Tao</strong></p>
<p>The automatic diagnosis of Parkinsonâ€™s disease is in high clinical demand due to its prevalence and the importance of targeted treatment. Current clinical practice often relies on diagnostic biomarkers in QSM and NM-MRI images. However, the lack of large, high-quality datasets makes training diagnostic models from scratch prone to overfitting. Adapting pre-trained 3D medical models is also challenging, as the diversity of medical imaging leads to mismatches in voxel spacing and modality between pre-training and fine-tuning data. In this paper, we address these challenges by leveraging 2D vision foundation models (VFMs). Specifically, we crop multiple key ROIs from NM and QSM images, process each ROI through separate branches to compress the ROI into a token, and then combine these tokens into a unified patient representation for classification. Within each branch, we use 2D VFMs to encode axial slices of the 3D ROI volume and fuse them into the ROI token, guided by an auxiliary segmentation head that steers the feature extraction toward specific brain nuclei. Additionally, we introduce multi-ROI supervised contrastive learning, which improves diagnostic performance by pulling together representations of patients from the same class while pushing away those from different classes. Our approach achieved first place in the MICCAI 2025 PDCADxFoundation challenge, with an accuracy of 86.0% trained on a dataset of only 300 labeled QSM and NM-MRI scans, outperforming the second-place method by 5.5%.These results highlight the potential of 2D VFMs for clinical analysis of 3D MR images. </p>
<blockquote>
<p>å¸•é‡‘æ£®ç—…åœ¨ä¸´åºŠä¸Šçš„è‡ªåŠ¨è¯Šæ–­éœ€æ±‚å¾ˆé«˜ï¼Œå› ä¸ºå…¶æµè¡Œæ€§å’Œé’ˆå¯¹æ€§æ²»ç–—çš„é‡è¦æ€§ã€‚å½“å‰çš„ä¸´åºŠå®è·µé€šå¸¸ä¾èµ–äºQSMå’ŒNM-MRIå›¾åƒä¸­çš„è¯Šæ–­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¤§è§„æ¨¡çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œä»é›¶å¼€å§‹è®­ç»ƒè¯Šæ–­æ¨¡å‹å®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œé€‚åº”é¢„è®­ç»ƒçš„3DåŒ»ç–—æ¨¡å‹ä¹Ÿé¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºåŒ»å­¦æˆåƒçš„å¤šæ ·æ€§å¯¼è‡´é¢„è®­ç»ƒå’Œå¾®è°ƒæ•°æ®ä¹‹é—´çš„ä½“ç´ é—´è·å’Œæ¨¡æ€ä¸åŒ¹é…ã€‚</p>
</blockquote>
<p>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨äºŒç»´è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä»NMå’ŒQSMå›¾åƒä¸­è£å‰ªå¤šä¸ªå…³é”®ROIï¼Œé€šè¿‡å•ç‹¬çš„åˆ†æ”¯å¤„ç†æ¯ä¸ªROIï¼Œå°†å…¶å‹ç¼©ä¸ºä»¤ç‰Œï¼Œç„¶åå°†è¿™äº›ä»¤ç‰Œç»„åˆæˆç»Ÿä¸€çš„æ‚£è€…è¡¨ç¤ºè¿›è¡Œåˆ†ç±»ã€‚åœ¨æ¯ä¸ªåˆ†æ”¯ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äºŒç»´VFMså¯¹ä¸‰ç»´ROIä½“ç§¯çš„è½´å‘åˆ‡ç‰‡è¿›è¡Œç¼–ç ï¼Œå¹¶å°†å…¶èåˆåˆ°ROIä»¤ç‰Œä¸­ï¼Œç”±è¾…åŠ©åˆ†å‰²å¤´å¼•å¯¼ï¼Œè¯¥åˆ†å‰²å¤´å°†ç‰¹å¾æå–å¼•å¯¼è‡³ç‰¹å®šçš„è„‘æ ¸ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šROIç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡æ‹‰è¿‘åŒä¸€ç±»åˆ«æ‚£è€…çš„è¡¨ç¤ºå¹¶æ¨å¼€ä¸åŒç±»åˆ«æ‚£è€…çš„è¡¨ç¤ºï¼Œæé«˜äº†è¯Šæ–­æ€§èƒ½ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17566v1">PDF</a> First-place solution of the classification track for MICCAIâ€™2025   PDCADxFoundation Challenge</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡åˆ©ç”¨äºŒç»´è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰è§£å†³å¸•é‡‘æ£®ç—…è‡ªåŠ¨è¯Šæ–­ä¸­çš„æŒ‘æˆ˜ã€‚é€šè¿‡è£å‰ªå…³é”®ROIå¹¶è¿›è¡Œå¤„ç†ï¼Œå°†æ‚£è€…å›¾åƒè½¬åŒ–ä¸ºç»Ÿä¸€è¡¨ç¤ºè¿›è¡Œåˆ†ç±»ã€‚å¼•å…¥å¤šROIç›‘ç£å¯¹æ¯”å­¦ä¹ æé«˜è¯Šæ–­æ€§èƒ½ã€‚åœ¨MICCAI 2025 PDCADxFoundationæŒ‘æˆ˜ä¸­ï¼Œä½¿ç”¨ä»…300ä¸ªæ ‡è®°çš„QSMå’ŒNM-MRIæ‰«ææ•°æ®é›†è®­ç»ƒï¼Œå‡†ç¡®ç‡è¾¾86.0%ï¼Œä¼˜äºç¬¬äºŒåæ–¹æ³•5.5%ã€‚çªæ˜¾äº†äºŒç»´VFMsåœ¨ä¸‰ç»´åŒ»å­¦å›¾åƒä¸´åºŠåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¸•é‡‘æ£®ç—…è‡ªåŠ¨è¯Šæ–­çš„ä¸´åºŠéœ€æ±‚è¿«åˆ‡ï¼Œå½“å‰å®è·µä¾èµ–QSMå’ŒNM-MRIå›¾åƒçš„è¯Šæ–­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚</li>
<li>ç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†å¯¼è‡´ä»å¤´è®­ç»ƒè¯Šæ–­æ¨¡å‹æ˜“å‡ºç°è¿‡æ‹Ÿåˆã€‚</li>
<li>åˆ©ç”¨äºŒç»´è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰è§£å†³é€‚åº”é¢„è®­ç»ƒçš„ä¸‰ç»´åŒ»å­¦æ¨¡å‹çš„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡è£å‰ªå¹¶å¤„ç†å…³é”®ROIï¼ˆæ„Ÿå…´è¶£åŒºåŸŸï¼‰ï¼Œå°†æ‚£è€…å›¾åƒè½¬åŒ–ä¸ºç»Ÿä¸€è¡¨ç¤ºè¿›è¡Œåˆ†ç±»ã€‚</li>
<li>å¼•å…¥å¤šROIç›‘ç£å¯¹æ¯”å­¦ä¹ æé«˜è¯Šæ–­æ€§èƒ½ï¼Œé€šè¿‡æ‹‰è¿‘åŒä¸€ç±»åˆ«æ‚£è€…è¡¨ç¤ºï¼Œæ¨è¿œä¸åŒç±»åˆ«æ‚£è€…è¡¨ç¤ºã€‚</li>
<li>åœ¨MICCAIæŒ‘æˆ˜ä¸­å–å¾—ç¬¬ä¸€åï¼Œä½¿ç”¨æœ‰é™æ•°æ®é›†å‡†ç¡®ç‡è¾¾86.0%ï¼Œè¡¨ç°å‡ºäºŒç»´VFMsåœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17566">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17566v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17566v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17566v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multimodal-Medical-Image-Classification-via-Synergistic-Learning-Pre-training"><a href="#Multimodal-Medical-Image-Classification-via-Synergistic-Learning-Pre-training" class="headerlink" title="Multimodal Medical Image Classification via Synergistic Learning   Pre-training"></a>Multimodal Medical Image Classification via Synergistic Learning   Pre-training</h2><p><strong>Authors:Qinghua Lin, Guang-Hai Liu, Zuoyong Li, Yang Li, Yuting Jiang, Xiang Wu</strong></p>
<p>Multimodal pathological images are usually in clinical diagnosis, but computer vision-based multimodal image-assisted diagnosis faces challenges with modality fusion, especially in the absence of expert-annotated data. To achieve the modality fusion in multimodal images with label scarcity, we propose a novel &#96;&#96;pretraining + fine-tuningâ€ framework for multimodal semi-supervised medical image classification. Specifically, we propose a synergistic learning pretraining framework of consistency, reconstructive, and aligned learning. By treating one modality as an augmented sample of another modality, we implement a self-supervised learning pre-train, enhancing the baseline modelâ€™s feature representation capability. Then, we design a fine-tuning method for multimodal fusion. During the fine-tuning stage, we set different encoders to extract features from the original modalities and provide a multimodal fusion encoder for fusion modality. In addition, we propose a distribution shift method for multimodal fusion features, which alleviates the prediction uncertainty and overfitting risks caused by the lack of labeled samples. We conduct extensive experiments on the publicly available gastroscopy image datasets Kvasir and Kvasirv2. Quantitative and qualitative results demonstrate that the proposed method outperforms the current state-of-the-art classification methods. The code will be released at: <a target="_blank" rel="noopener" href="https://github.com/LQH89757/MICS">https://github.com/LQH89757/MICS</a>. </p>
<blockquote>
<p>å¤šæ¨¡æ€ç—…ç†å›¾åƒåœ¨ä¸´åºŠè¯Šæ–­ä¸­é€šå¸¸å¾ˆé‡è¦ï¼Œä½†åŸºäºè®¡ç®—æœºè§†è§‰çš„å¤šæ¨¡æ€å›¾åƒè¾…åŠ©è¯Šæ–­åœ¨æ¨¡æ€èåˆæ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¼ºä¹ä¸“å®¶æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ã€‚ä¸ºäº†å®ç°æ ‡ç­¾ç¨€ç¼ºæƒ…å†µä¸‹çš„å¤šæ¨¡æ€å›¾åƒæ¨¡æ€èåˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„â€œé¢„è®­ç»ƒ+å¾®è°ƒâ€æ¡†æ¶ç”¨äºå¤šæ¨¡æ€åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªååŒå­¦ä¹ é¢„è®­ç»ƒæ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸€è‡´æ€§ã€é‡å»ºå’Œå¯¹é½å­¦ä¹ ã€‚é€šè¿‡å°†ä¸€ç§æ¨¡æ€è§†ä¸ºå¦ä¸€ç§æ¨¡æ€çš„å¢å¼ºæ ·æœ¬ï¼Œæˆ‘ä»¬å®ç°äº†è‡ªç›‘ç£å­¦ä¹ é¢„è®­ç»ƒï¼Œæé«˜äº†åŸºçº¿æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç”¨äºæ¨¡æ€èåˆçš„å¾®è°ƒæ–¹æ³•ã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼Œæˆ‘ä»¬è®¾ç½®ä¸åŒçš„ç¼–ç å™¨ä»åŸå§‹æ¨¡æ€ä¸­æå–ç‰¹å¾ï¼Œå¹¶æä¾›ä¸€ä¸ªå¤šæ¨¡æ€èåˆç¼–ç å™¨è¿›è¡Œèåˆæ¨¡æ€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€èåˆç‰¹å¾åˆ†å¸ƒè½¬ç§»æ–¹æ³•ï¼Œè¿™å‡è½»äº†ç”±äºç¼ºå°‘æ ‡è®°æ ·æœ¬å¯¼è‡´çš„ä¸ç¡®å®šæ€§é¢„æµ‹å’Œè¿‡æ‹Ÿåˆé£é™©ã€‚æˆ‘ä»¬åœ¨å…¬å¼€å¯ç”¨çš„èƒƒé•œå›¾åƒæ•°æ®é›†Kvasirå’ŒKvasirv2ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒã€‚å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„åˆ†ç±»æ–¹æ³•ã€‚ä»£ç å°†åœ¨ä»¥ä¸‹ç½‘å€å‘å¸ƒï¼š<a target="_blank" rel="noopener" href="https://github.com/LQH89757/MICS">https://github.com/LQH89757/MICS</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17492v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨ä¸´åºŠåŒ»å­¦è¯Šæ–­ä¸­ï¼Œå¤šæ¨¡æ€åŒ»å­¦å›¾åƒçš„ä½¿ç”¨å˜å¾—è¶Šæ¥è¶Šæ™®éã€‚ç„¶è€Œï¼Œåœ¨ç¼ºä¹ä¸“å®¶æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¤šæ¨¡æ€å›¾åƒèåˆé¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„â€œé¢„è®­ç»ƒ+å¾®è°ƒâ€æ¡†æ¶ï¼Œç”¨äºè¿›è¡ŒåŠç›‘ç£å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚é€šè¿‡ä¸€è‡´æ€§ã€é‡å»ºå’Œå¯¹é½å­¦ä¹ çš„ååŒå­¦ä¹ é¢„è®­ç»ƒæ¡†æ¶ï¼Œæé«˜åŸºçº¿æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚éšåè®¾è®¡äº†ä¸€ç§å¾®è°ƒæ–¹æ³•è¿›è¡Œå¤šæ¨¡æ€èåˆã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¬å¼€å¯ç”¨çš„èƒƒé•œå›¾åƒæ•°æ®é›†Kvasirå’ŒKvasirv2ä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåœ¨ä¸´åºŠè¯Šæ–­ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†ç¼ºä¹ä¸“å®¶æ ‡æ³¨æ•°æ®çš„æ¨¡æ€èåˆé¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§â€œé¢„è®­ç»ƒ+å¾®è°ƒâ€æ¡†æ¶è¿›è¡ŒåŠç›‘ç£å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚</li>
<li>ååŒå­¦ä¹ é¢„è®­ç»ƒæ¡†æ¶åŒ…æ‹¬ä¸€è‡´æ€§ã€é‡å»ºå’Œå¯¹æ¥å­¦ä¹ ï¼Œæé«˜æ¨¡å‹ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚</li>
<li>å¾®è°ƒæ–¹æ³•è®¾è®¡ç”¨äºå¤šæ¨¡æ€èåˆï¼ŒåŒ…æ‹¬ä¸åŒç¼–ç å™¨æå–ç‰¹å¾å’Œä¸€ä¸ªå¤šæ¨¡æ€èåˆç¼–ç å™¨ã€‚</li>
<li>å¼•å…¥åˆ†å¸ƒåç§»æ–¹æ³•å¤„ç†å¤šæ¨¡æ€èåˆç‰¹å¾ï¼Œé™ä½é¢„æµ‹ä¸ç¡®å®šæ€§å’Œè¿‡æ‹Ÿåˆé£é™©ã€‚</li>
<li>åœ¨å…¬å¼€æ•°æ®é›†Kvasirå’ŒKvasirv2ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œè¯æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åˆ†ç±»æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17492">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17492v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17492v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17492v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17492v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17492v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Medical-AI-Consensus-A-Multi-Agent-Framework-for-Radiology-Report-Generation-and-Evaluation"><a href="#Medical-AI-Consensus-A-Multi-Agent-Framework-for-Radiology-Report-Generation-and-Evaluation" class="headerlink" title="Medical AI Consensus: A Multi-Agent Framework for Radiology Report   Generation and Evaluation"></a>Medical AI Consensus: A Multi-Agent Framework for Radiology Report   Generation and Evaluation</h2><p><strong>Authors:Ahmed T. Elboardy, Ghada Khoriba, Essam A. Rashed</strong></p>
<p>Automating radiology report generation poses a dual challenge: building clinically reliable systems and designing rigorous evaluation protocols. We introduce a multi-agent reinforcement learning framework that serves as both a benchmark and evaluation environment for multimodal clinical reasoning in the radiology ecosystem. The proposed framework integrates large language models (LLMs) and large vision models (LVMs) within a modular architecture composed of ten specialized agents responsible for image analysis, feature extraction, report generation, review, and evaluation. This design enables fine-grained assessment at both the agent level (e.g., detection and segmentation accuracy) and the consensus level (e.g., report quality and clinical relevance). We demonstrate an implementation using chatGPT-4o on public radiology datasets, where LLMs act as evaluators alongside medical radiologist feedback. By aligning evaluation protocols with the LLM development lifecycle, including pretraining, finetuning, alignment, and deployment, the proposed benchmark establishes a path toward trustworthy deviance-based radiology report generation. </p>
<blockquote>
<p>è‡ªåŠ¨åŒ–ç”Ÿæˆæ”¾å°„å­¦æŠ¥å‘Šé¢ä¸´åŒé‡æŒ‘æˆ˜ï¼šå»ºç«‹ä¸´åºŠå¯é çš„ç³»ç»Ÿå’Œè®¾è®¡ä¸¥æ ¼çš„è¯„ä»·åè®®ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¢å¯ä½œä¸ºæ”¾å°„å­¦ç”Ÿæ€ç³»ç»Ÿä¸­å¤šæ¨¡å¼ä¸´åºŠæ¨ç†çš„åŸºå‡†æµ‹è¯•ç¯å¢ƒï¼Œä¹Ÿå¯ç”¨äºå¯¹å…¶è¿›è¡Œè¯„ä»·ã€‚æ‰€æå‡ºçš„æ¡†æ¶åœ¨æ¨¡å—åŒ–æ¶æ„ä¸­é›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤§å‹è§†è§‰æ¨¡å‹ï¼ˆLVMï¼‰ï¼Œç”±10ä¸ªä¸“èŒæ™ºèƒ½ä½“ç»„æˆï¼Œè´Ÿè´£å›¾åƒåˆ†æã€ç‰¹å¾æå–ã€æŠ¥å‘Šç”Ÿæˆã€å®¡æŸ¥å’Œè¯„ä¼°ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿåœ¨æ™ºèƒ½ä½“å±‚é¢ï¼ˆä¾‹å¦‚æ£€æµ‹å’Œåˆ†å‰²å‡†ç¡®æ€§ï¼‰å’Œå…±è¯†å±‚é¢ï¼ˆä¾‹å¦‚æŠ¥å‘Šè´¨é‡å’Œä¸´åºŠç›¸å…³æ€§ï¼‰è¿›è¡Œç²¾ç»†è¯„ä¼°ã€‚æˆ‘ä»¬ä½¿ç”¨ChatGPT-4oåœ¨å…¬å…±æ”¾å°„å­¦æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®ç°å±•ç¤ºï¼Œå…¶ä¸­LLMä½œä¸ºè¯„ä¼°å™¨ä¸åŒ»å­¦æ”¾å°„ç§‘åŒ»å¸ˆåé¦ˆç›¸ç»“åˆã€‚é€šè¿‡ä½¿è¯„ä»·åè®®ä¸LLMå¼€å‘å‘¨æœŸï¼ˆåŒ…æ‹¬é¢„è®­ç»ƒã€å¾®è°ƒã€å¯¹é½å’Œéƒ¨ç½²ï¼‰ä¿æŒä¸€è‡´ï¼Œæ‰€æå‡ºçš„æ ‡å‡†å»ºç«‹äº†ä¸€æ¡åŸºäºå¯ä¿¡åå·®çš„æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆè·¯å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17353v1">PDF</a> NeurIPS2025 Workshop: Evaluating the Evolving LLM Lifecycle:   Benchmarks, Emergent Abilities, and Scaling</p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒè‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆé¢ä¸´ä¸´åºŠå¯é ç³»ç»Ÿå’Œä¸¥æ ¼è¯„ä¼°åè®®çš„åŒæŒ‘æˆ˜ã€‚å¼•å…¥å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä½œä¸ºæ”¾å°„å­¦ç”Ÿæ€ç³»ç»Ÿä¸­å¤šæ¨¡å¼ä¸´åºŠæ¨ç†çš„åŸºå‡†å’Œè¯„ä»·ç¯å¢ƒã€‚è¯¥æ¡†æ¶æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤§å‹è§†è§‰æ¨¡å‹ï¼Œé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼ŒåŒ…å«è´Ÿè´£å›¾åƒåˆ†æã€ç‰¹å¾æå–ã€æŠ¥å‘Šç”Ÿæˆã€å®¡æŸ¥å’Œè¯„ä¼°çš„åä¸ªä¸“ç”¨æ™ºèƒ½ä½“ã€‚è¿™ä¸€è®¾è®¡å¯åœ¨æ™ºèƒ½ä½“å±‚é¢å’Œå…±è¯†å±‚é¢è¿›è¡Œç²¾ç»†è¯„ä¼°ï¼Œå¦‚æ£€æµ‹ä¸åˆ†å‰²ç²¾åº¦ã€æŠ¥å‘Šè´¨é‡å’Œä¸´åºŠç›¸å…³æ€§ç­‰ã€‚ä½¿ç”¨ChatGPT-4oåœ¨å…¬å…±æ”¾å°„å­¦æ•°æ®é›†ä¸Šå®ç°ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹æ‰®æ¼”è¯„ä¼°è€…è§’è‰²ï¼ŒåŒæ—¶ç»“åˆåŒ»å­¦æ”¾å°„ç§‘åŒ»ç”Ÿåé¦ˆã€‚é€šè¿‡è®©è¯„ä¼°åè®®ä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„å‘å±•å‘¨æœŸä¿æŒä¸€è‡´ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒã€å¾®è°ƒã€å¯¹é½å’Œéƒ¨ç½²ï¼Œè¯¥åŸºå‡†æµ‹è¯•ä¸ºåŸºäºå¯ä¿¡åå·®çš„åŒ»å­¦å›¾åƒæŠ¥å‘Šç”Ÿæˆé“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨åŒ–ç”ŸæˆåŒ»å­¦å›¾åƒæŠ¥å‘Šéœ€è¦ä¸´åºŠå¯é æ€§å’Œä¸¥æ ¼çš„è¯„ä¼°åè®®ã€‚</li>
<li>å¼•å…¥å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä½œä¸ºæ”¾å°„å­¦ä¸­çš„åŸºå‡†å’Œè¯„ä»·ç¯å¢ƒã€‚</li>
<li>æ¡†æ¶æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤§å‹è§†è§‰æ¨¡å‹ï¼Œé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ã€‚</li>
<li>æ¡†æ¶åŒ…å«è´Ÿè´£ä¸åŒä»»åŠ¡çš„åä¸ªä¸“ç”¨æ™ºèƒ½ä½“ã€‚</li>
<li>å¯ä»¥åœ¨æ™ºèƒ½ä½“å±‚é¢å’Œå…±è¯†å±‚é¢è¿›è¡Œç²¾ç»†è¯„ä¼°ã€‚</li>
<li>ä½¿ç”¨ChatGPT-4oåœ¨å…¬å…±æ”¾å°„å­¦æ•°æ®é›†ä¸Šå®ç°è¯¥æ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17353">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17353v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17353v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17353v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Viscoelastic-properties-of-tumor-spheroids-revealed-by-a-microfluidic-compression-device-and-a-modified-power-law-model"><a href="#Viscoelastic-properties-of-tumor-spheroids-revealed-by-a-microfluidic-compression-device-and-a-modified-power-law-model" class="headerlink" title="Viscoelastic properties of tumor spheroids revealed by a microfluidic   compression device and a modified power law model"></a>Viscoelastic properties of tumor spheroids revealed by a microfluidic   compression device and a modified power law model</h2><p><strong>Authors:Mrinal Pandey, Bangguo Zhu, Kaitlyn Roach, Young Joon Suh, Jeffrey E Segall, Chung-Yuen Hui, Mingming Wu</strong></p>
<p>Clinically, palpation is one of the important diagnostic methods to assess tumor malignancy. In laboratory research, it is well accepted that the bulk stiffness of the tumor and the surrounding tissue is closely correlated with the malignant state of the tumor. Here, we postulate that, in addition to tumor stiffness, tumor viscoelasticity - the fact that tumor tissue takes time to bounce back after compression, can also be used to evaluate the tumor malignancy state. In this work, we characterized the viscoelastic properties of breast tumor spheroids using a recently developed microfluidic compression device and a theoretical power law model. Breast tumor cells at varying malignant levels; a non-tumorigenic epithelial (MCF10A), moderately malignant tumor (MCF7) and triple negative metastatic tumor (MDA-MB-231) cells were used. Spheroids embedded within a 3D extracellular matrix were periodically compressed, and their strain responses were recorded using microscopic imaging. Our results revealed that the measured strain relaxation curves can be successfully described by a modified power law model, demonstrated that non-tumorigenic tumor spheroids were more elastic, exhibited shorter relaxation time and less plasticity than those of tumorigenic spheroids. Together, these results highlight that viscoelastic properties in addition to bulk stiffness of the tumor spheroids can serve as a complementary mechanical biomarker of tumor malignancy and demonstrate the validity of a modified power law model for the mechanical characterization of a living tissue. </p>
<blockquote>
<p>åœ¨ä¸´åºŠä¸­ï¼Œè§¦è¯Šæ˜¯è¯„ä¼°è‚¿ç˜¤æ¶æ€§ç¨‹åº¦çš„é‡è¦è¯Šæ–­æ–¹æ³•ä¹‹ä¸€ã€‚åœ¨å®éªŒå®¤ç ”ç©¶ä¸­ï¼Œäººä»¬æ™®éè®¤ä¸ºè‚¿ç˜¤çš„ä½“ç§¯åˆšåº¦å’Œå‘¨å›´ç»„ç»‡çš„ä½“ç§¯åˆšåº¦ä¸è‚¿ç˜¤çš„æ¶æ€§çŠ¶æ€å¯†åˆ‡ç›¸å…³ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬å‡è®¾é™¤äº†è‚¿ç˜¤åˆšåº¦å¤–ï¼Œè‚¿ç˜¤çš„ç²˜å¼¹æ€§ï¼ˆå³è‚¿ç˜¤ç»„ç»‡åœ¨å‹ç¼©åéœ€è¦ä¸€æ®µæ—¶é—´æ‰èƒ½æ¢å¤çš„ç‰¹æ€§ï¼‰ä¹Ÿå¯ç”¨äºè¯„ä¼°è‚¿ç˜¤çš„æ¶æ€§çŠ¶æ€ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€è¿‘å¼€å‘çš„å¾®æµä½“å‹ç¼©è£…ç½®å’Œç†è®ºå¹‚å¾‹æ¨¡å‹è¡¨å¾äº†ä¹³è…ºç™Œçƒä½“çš„ç²˜å¼¹æ€§ç‰¹æ€§ã€‚ä½¿ç”¨äº†ä¸åŒæ¶æ€§ç¨‹åº¦çš„ä¹³è…ºç™Œç»†èƒï¼ŒåŒ…æ‹¬éè‚¿ç˜¤æ€§ä¸Šçš®ï¼ˆMCF10Aï¼‰ã€ä¸­åº¦æ¶æ€§è‚¿ç˜¤ï¼ˆMCF7ï¼‰å’Œä¸‰é˜´æ€§è½¬ç§»æ€§è‚¿ç˜¤ï¼ˆMDA-MB-231ï¼‰ç»†èƒã€‚åµŒå…¥ä¸‰ç»´ç»†èƒå¤–åŸºè´¨çš„çƒä½“è¢«å®šæœŸå‹ç¼©ï¼Œå…¶åº”å˜å“åº”é€šè¿‡æ˜¾å¾®é•œæˆåƒè¿›è¡Œè®°å½•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæµ‹å¾—çš„åº”å˜æ¾å¼›æ›²çº¿å¯ä»¥æˆåŠŸåœ°ç”¨ä¿®æ­£åçš„å¹‚å¾‹æ¨¡å‹æ¥æè¿°ï¼Œè¿™è¡¨æ˜éè‚¿ç˜¤æ€§è‚¿ç˜¤çƒä½“æ›´å¯Œæœ‰å¼¹æ€§ï¼Œå…¶æ¾å¼›æ—¶é—´è¾ƒçŸ­ã€å¯å¡‘æ€§è¾ƒå°ï¼Œä¸å…·æœ‰è‚¿ç˜¤æ€§çš„çƒä½“ç›¸æ¯”ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™äº›ç»“æœå¼ºè°ƒï¼Œé™¤äº†è‚¿ç˜¤çƒä½“çš„ä½“ç§¯åˆšåº¦å¤–ï¼Œå…¶ç²˜å¼¹æ€§ç‰¹æ€§å¯ä»¥ä½œä¸ºè¡¥å……çš„æœºæ¢°ç”Ÿç‰©æ ‡å¿—ç‰©æ¥æŒ‡ç¤ºè‚¿ç˜¤çš„æ¶æ€§ç¨‹åº¦ï¼Œå¹¶éªŒè¯äº†ä¿®æ­£åçš„å¹‚å¾‹æ¨¡å‹åœ¨æ´»ç»„ç»‡æœºæ¢°ç‰¹æ€§è¡¨å¾ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17294v1">PDF</a> This manuscript contains 14 pages, 4 figures, along with a   Supplementary Information</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶æ¢è®¨äº†è‚¿ç˜¤çƒä½“çš„ç²˜å¼¹æ€§ç‰¹æ€§ä¸è‚¿ç˜¤æ¶æ€§ç¨‹åº¦çš„å…³ç³»ã€‚åˆ©ç”¨å¾®æµä½“å‹ç¼©è£…ç½®å’Œç†è®ºå¹‚å¾‹æ¨¡å‹ï¼Œå¯¹ä¸‰ç§ä¸åŒæ¶æ€§ç¨‹åº¦çš„ä¹³è…ºè‚¿ç˜¤ç»†èƒè¿›è¡Œä¸‰ç»´åŸºè´¨å†…çƒä½“å‹ç¼©å®éªŒï¼Œå¹¶è®°å½•åº”å˜å“åº”ã€‚ç ”ç©¶å‘ç°éè‚¿ç˜¤æ€§çƒä½“è¾ƒæœ‰å¼¹æ€§ï¼Œæ¾é©°æ—¶é—´è¾ƒçŸ­ä¸”å¯å¡‘æ€§è¾ƒä½ï¼›æ¶æ€§è‚¿ç˜¤çƒä½“åˆ™å±•ç°å‡ºæ›´ç²˜å¼¹æ€§è´¨åœ°ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè‚¿ç˜¤çƒä½“çš„ç²˜å¼¹æ€§ç‰¹æ€§å¯ä½œä¸ºè‚¿ç˜¤æ¶æ€§ç¨‹åº¦çš„è¾…åŠ©æœºæ¢°ç”Ÿç‰©æ ‡å¿—ç‰©ï¼ŒåŒæ—¶éªŒè¯äº†æ”¹è¿›åçš„å¹‚å¾‹æ¨¡å‹åœ¨æ´»ç»„ç»‡æœºæ¢°ç‰¹æ€§è¡¨å¾ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‚¿ç˜¤æ¶æ€§å’Œç²˜å¼¹æ€§ç‰¹æ€§æœ‰å…³ã€‚é™¤äº†è‚¿ç˜¤çš„ä½“ç§¯åˆšåº¦å¤–ï¼Œè‚¿ç˜¤çš„ç²˜å¼¹æ€§å³å‹ç¼©åæ¢å¤çš„æ—¶é—´é•¿åº¦ä¹Ÿèƒ½åæ˜ è‚¿ç˜¤çš„æ¶æ€§ç¨‹åº¦ã€‚</li>
<li>åˆ©ç”¨å¾®æµä½“å‹ç¼©è£…ç½®å’Œç†è®ºå¹‚å¾‹æ¨¡å‹å¯¹ä¹³è…ºè‚¿ç˜¤ç»†èƒçš„ç²˜å¼¹æ€§ç‰¹æ€§è¿›è¡Œäº†ç ”ç©¶ã€‚</li>
<li>ä¸‰ç§ä¸åŒæ¶æ€§ç¨‹åº¦çš„ä¹³è…ºè‚¿ç˜¤ç»†èƒè¢«ç ”ç©¶ï¼šéè‚¿ç˜¤æ€§ä¸Šçš®ã€ä¸­åº¦æ¶æ€§è‚¿ç˜¤å’Œè½¬ç§»æ€§ä¸‰é˜´æ€§è‚¿ç˜¤ç»†èƒã€‚</li>
<li>é€šè¿‡å‘¨æœŸæ€§å‹ç¼©åµŒå…¥åœ¨ä¸‰ç»´åŸºè´¨ä¸­çš„è‚¿ç˜¤çƒä½“ï¼Œå¹¶è®°å½•å…¶åº”å˜å“åº”æ¥äº†è§£å…¶ç‰¹æ€§ã€‚</li>
<li>ç ”ç©¶å‘ç°éè‚¿ç˜¤æ€§çƒä½“çš„å¼¹æ€§è¾ƒé«˜ï¼Œå…·æœ‰è¾ƒçŸ­çš„æ¾å¼›æ—¶é—´å’Œè¾ƒä½çš„å¯å¡‘æ€§ï¼Œè€Œè‚¿ç˜¤çƒä½“çš„ç²˜å¼¹æ€§æ›´ä¸ºæ˜æ˜¾ã€‚</li>
<li>è‚¿ç˜¤çƒä½“çš„ç²˜å¼¹æ€§ç‰¹æ€§å¯ä»¥ä½œä¸ºè‚¿ç˜¤æ¶æ€§ç¨‹åº¦çš„è¾…åŠ©æœºæ¢°ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17294">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17294v1/page_0_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="eROSITA-selection-of-new-period-bounce-Cataclysmic-Variables-First-follow-up-confirmation-using-TESS-and-SDSS"><a href="#eROSITA-selection-of-new-period-bounce-Cataclysmic-Variables-First-follow-up-confirmation-using-TESS-and-SDSS" class="headerlink" title="eROSITA-selection of new period-bounce Cataclysmic Variables: First   follow-up confirmation using TESS and SDSS"></a>eROSITA-selection of new period-bounce Cataclysmic Variables: First   follow-up confirmation using TESS and SDSS</h2><p><strong>Authors:Daniela MuÃ±oz-Giraldo, Beate Stelzer, Axel Schwope, Santiago HernÃ¡ndez-DÃ­az, Scott F. Anderson, Sebastian Demasi</strong></p>
<p>Between 40$%$ and 80$%$ of cataclysmic variables (CVs) are expected to have evolved past the period-minimum and contain a degenerate donor. However, observational surveys for CVs have only been able to detect a few of these highly evolved â€œperiod-bouncersâ€, most likely due to the intrinsic faintness associated with their predicted low mass accretion rates. We have produced an initial selection of 137 high-likelihood period-bounce candidates from WD catalog based on our multiwavelength period-bouncer scorecard and selection cuts including X-ray data from the extended ROentgen Survey with an Imaging Telescope Array (eROSITA) on board the Spektrum-Roentgen-Gamma spacecraft (SRG). We have laid out three main requirements (classification as a CV, determination of an orbital period and detection of a very late-type donor) that should result in the confirmation of several of these candidates. Our path for confirming these candidates has already produced its first successful result with the confirmation of GALEX J125751.4-283015 as a new period-bouncer. Several other candidates have already fulfilled at least one of our three requirements making their future confirmation likely. Our search for period-bouncers using the X-ray eROSITA emission of objects in optical WD catalogs has led to the confirmation of six new period-bouncers identified from the Gaia DR3 WD catalog (five previously known CVs and one WD candidate), a 18$%$ increase that brings the present population to 39 systems. Both the selection method for period-bounce candidates and the confirmation path that we outlined will aid in future searches for new period-bounce candidates, contributing to the goal of resolving the discrepancy between the predicted high number of period-bouncers and the low number of these systems successfully observed to date. </p>
<blockquote>
<p>é¢„è®¡çº¦æœ‰40%è‡³80%çš„å¤§ç¾å˜å˜é‡ï¼ˆCVsï¼‰å·²ç»æ¼”è¿›åˆ°å‘¨æœŸæœ€å°é˜¶æ®µä¹‹åï¼Œå¹¶åŒ…å«é€€åŒ–ä¾›ä½“ã€‚ç„¶è€Œï¼Œå¯¹äºCVçš„è§‚å¯Ÿè°ƒæŸ¥åªèƒ½æ£€æµ‹åˆ°è¿™äº›é«˜åº¦æ¼”åŒ–çš„â€œå‘¨æœŸåå¼¹è€…â€ä¸­çš„å°‘æ•°å‡ ä¸ªï¼Œè¿™å¾ˆå¯èƒ½ä¸å®ƒä»¬é¢„æµ‹çš„è¾ƒä½è´¨é‡å¢é•¿ç‡çš„å›ºæœ‰æš—æ·¡æ€§æœ‰å…³ã€‚æˆ‘ä»¬åŸºäºå¤šæ³¢é•¿å‘¨æœŸåå¼¹è¯„åˆ†å¡å’ŒåŒ…æ‹¬Xå°„çº¿æ•°æ®åœ¨å†…çš„é€‰æ‹©æ ‡å‡†ï¼ˆè¿™äº›æ•°æ®æ¥è‡ªæ­è½½åœ¨å…‰è°±ç½—æ©å¡”ä¼½å¤ªç©ºé£è¡Œå™¨ä¸Šçš„æ‰©å±•ç½—æ©å¡”ä¼½æˆåƒæœ›è¿œé•œé˜µåˆ—çš„eROSITAè°ƒæŸ¥ï¼‰ï¼Œä»WDç›®å½•ä¸­åˆæ­¥ç­›é€‰å‡ºäº†137ä¸ªé«˜æ¦‚ç‡å‘¨æœŸåå¼¹å€™é€‰è€…ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰ä¸ªä¸»è¦è¦æ±‚ï¼ˆåˆ†ç±»ä¸ºCVã€ç¡®å®šè½¨é“å‘¨æœŸå’Œæ£€æµ‹åˆ°éå¸¸æ™šå‹çš„ä¾›ä½“ï¼‰ï¼Œè¿™å°†å¯¼è‡´å¯¹è¿™äº›å€™é€‰è€…çš„ç¡®è®¤ã€‚æˆ‘ä»¬ç¡®è®¤è¿™äº›å€™é€‰è€…çš„è·¯å¾„å·²ç»äº§ç”Ÿäº†ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœï¼Œå³ç¡®è®¤GALEX J125751.4-283015ä¸ºæ–°å‘¨æœŸåå¼¹è€…ã€‚å…¶ä»–å‡ ä½å€™é€‰è€…å·²ç»æ»¡è¶³äº†æˆ‘ä»¬çš„è‡³å°‘ä¸€é¡¹è¦æ±‚ï¼Œå› æ­¤ä»–ä»¬çš„æœªæ¥ç¡®è®¤å¯èƒ½æ€§å¾ˆå¤§ã€‚æˆ‘ä»¬åˆ©ç”¨å…‰å­¦WDç›®å½•ä¸­çš„Xå°„çº¿eROSITAå‘å°„ç‰©å¯¹å‘¨æœŸåå¼¹è€…çš„æœç´¢å·²ç»ç¡®è®¤äº†åœ¨Gaia DR3 WDç›®å½•ä¸­æ–°å¢çš„å…­ä¸ªå‘¨æœŸåå¼¹è€…ï¼ˆäº”ä¸ªå·²çŸ¥çš„CVå’Œä¸€ä¸ªWDå€™é€‰è€…ï¼‰ï¼Œè¿™ä¸€å¢é•¿ç‡ä¸ºç›®å‰çš„å‘¨æœŸåå¼¹è€…æ•°é‡å¢åŠ äº†çº¦å¢åŠ åˆ°äº†åŸå…ˆçš„ç™¾åˆ†ä¹‹ä¸€åå…«ï¼ˆç°åœ¨æ€»è®¡ä¸º ä¸‰åä¹ä¸ªç³»ç»Ÿï¼‰ã€‚æ— è®ºæ˜¯å‘¨æœŸåå¼¹å€™é€‰è€…çš„é€‰æ‹©æ–¹æ³•è¿˜æ˜¯æˆ‘ä»¬æ¦‚è¿°çš„ç¡®è®¤è·¯å¾„ï¼Œéƒ½å°†æœ‰åŠ©äºæœªæ¥å¯»æ‰¾æ–°çš„å‘¨æœŸåå¼¹å€™é€‰è€…ï¼Œä¸ºå®ç°è§£å†³é¢„æµ‹ä¸­å­˜åœ¨å¤§é‡å‘¨æœŸåå¼¹è€…ä¸è¿„ä»Šä¸ºæ­¢è§‚å¯Ÿåˆ°çš„è¿™äº›ç³»ç»Ÿæ•°é‡ä¹‹é—´å·®è·çš„ç›®æ ‡åšå‡ºè´¡çŒ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17216v1">PDF</a> 15 pages, 12 figures. Submitted to A&amp;A</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¯¹ç¾å˜å˜é‡ï¼ˆCVsï¼‰ä¸­çš„å‘¨æœŸåå¼¹å€™é€‰è€…çš„ç ”ç©¶ã€‚æ®ä¼°è®¡ï¼Œ40%~80%çš„CVså·²ç»æ¼”åŒ–åˆ°å‘¨æœŸæœ€å°å€¼ä¹‹åå¹¶æ‹¥æœ‰é€€åŒ–ä¾›ä½“æ˜Ÿï¼Œä½†è§‚æµ‹è°ƒæŸ¥ä»…èƒ½æ£€æµ‹åˆ°å°‘æ•°è¿™äº›é«˜åº¦æ¼”åŒ–çš„â€œå‘¨æœŸåå¼¹è€…â€ï¼Œè¿™å¯èƒ½ä¸å®ƒä»¬é¢„æµ‹çš„è¾ƒä½è´¨é‡å¸ç§¯ç‡å¯¼è‡´çš„å†…åœ¨æš—æ·¡æœ‰å…³ã€‚ç ”ç©¶è€…åŸºäºå¤šæ³¢é•¿å‘¨æœŸåå¼¹å¾—åˆ†å¡å’Œé€‰æ‹©æ ‡å‡†ï¼Œä»WDç›®å½•ä¸­ç­›é€‰å‡º137ä¸ªé«˜æ¦‚ç‡å‘¨æœŸåå¼¹å€™é€‰è€…ã€‚ä½¿ç”¨SRGå«æ˜Ÿä¸Šçš„eROSITAæœ›è¿œé•œçš„Xå°„çº¿æ•°æ®ï¼Œç ”ç©¶è€…ç¡®è®¤äº†è‡³å°‘å…­ä¸ªæ–°çš„å‘¨æœŸåå¼¹ç³»ç»Ÿï¼Œå…¶ä¸­äº”ä¸ªæ˜¯å·²çŸ¥çš„CVså’Œä¸€ä¸ªWDå€™é€‰è€…ã€‚ç ”ç©¶è€…çš„é€‰æ‹©æ–¹æ³•å’Œç¡®è®¤è·¯å¾„å°†æœ‰åŠ©äºæœªæ¥å¯»æ‰¾æ–°çš„å‘¨æœŸåå¼¹å€™é€‰è€…ï¼Œä¸ºè§£å†³é¢„æµ‹çš„å‘¨æœŸåå¼¹è€…æ•°é‡ä¸æˆåŠŸè§‚å¯Ÿåˆ°çš„æ•°é‡ä¹‹é—´çš„ä¸ä¸€è‡´åšå‡ºè´¡çŒ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¾å˜å˜é‡ï¼ˆCVsï¼‰ä¸­æœ‰é«˜è¾¾80%å¯èƒ½å·²æ¼”åŒ–è‡³å‘¨æœŸæœ€å°å€¼ä¹‹åï¼ŒåŒ…å«é€€åŒ–ä¾›ä½“æ˜Ÿã€‚</li>
<li>ç›®å‰è§‚æµ‹ä»…èƒ½æ£€æµ‹åˆ°å°‘æ•°â€œå‘¨æœŸåå¼¹è€…â€ï¼ŒåŸå› åœ¨äºå…¶é¢„æµ‹çš„ä½è´¨é‡å¸ç§¯ç‡å¯¼è‡´çš„å†…åœ¨æš—æ·¡ã€‚</li>
<li>åŸºäºå¤šæ³¢é•¿å‘¨æœŸåå¼¹å¾—åˆ†å¡å’Œé€‰æ‹©æ ‡å‡†ï¼Œä»WDç›®å½•ç­›é€‰å‡ºé«˜æ¦‚ç‡å‘¨æœŸåå¼¹å€™é€‰è€…ã€‚</li>
<li>åˆ©ç”¨SRGå«æ˜Ÿä¸Šçš„eROSITAæœ›è¿œé•œçš„Xå°„çº¿æ•°æ®ï¼Œç¡®è®¤äº†è‡³å°‘å…­ä¸ªæ–°çš„å‘¨æœŸåå¼¹ç³»ç»Ÿã€‚</li>
<li>ç ”ç©¶è€…çš„é€‰æ‹©æ–¹æ³•å’Œç¡®è®¤è·¯å¾„æœ‰åŠ©äºæé«˜æœªæ¥å¯»æ‰¾æ–°çš„å‘¨æœŸåå¼¹å€™é€‰è€…çš„æ•ˆç‡ã€‚</li>
<li>æ­¤ç ”ç©¶ä¸ºè§£å†³é¢„æµ‹çš„å‘¨æœŸåå¼¹è€…æ•°é‡ä¸æˆåŠŸè§‚å¯Ÿåˆ°çš„æ•°é‡ä¹‹é—´çš„ä¸ä¸€è‡´åšå‡ºè´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17216">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17216v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17216v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17216v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17216v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17216v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Echo-Path-Pathology-Conditioned-Echo-Video-Generation"><a href="#Echo-Path-Pathology-Conditioned-Echo-Video-Generation" class="headerlink" title="Echo-Path: Pathology-Conditioned Echo Video Generation"></a>Echo-Path: Pathology-Conditioned Echo Video Generation</h2><p><strong>Authors:Kabir Hamzah Muhammad, Marawan Elbatel, Yi Qin, Xiaomeng Li</strong></p>
<p>Cardiovascular diseases (CVDs) remain the leading cause of mortality globally, and echocardiography is critical for diagnosis of both common and congenital cardiac conditions. However, echocardiographic data for certain pathologies are scarce, hindering the development of robust automated diagnosis models. In this work, we propose Echo-Path, a novel generative framework to produce echocardiogram videos conditioned on specific cardiac pathologies. Echo-Path can synthesize realistic ultrasound video sequences that exhibit targeted abnormalities, focusing here on atrial septal defect (ASD) and pulmonary arterial hypertension (PAH). Our approach introduces a pathology-conditioning mechanism into a state-of-the-art echo video generator, allowing the model to learn and control disease-specific structural and motion patterns in the heart. Quantitative evaluation demonstrates that the synthetic videos achieve low distribution distances, indicating high visual fidelity. Clinically, the generated echoes exhibit plausible pathology markers. Furthermore, classifiers trained on our synthetic data generalize well to real data and, when used to augment real training sets, it improves downstream diagnosis of ASD and PAH by 7% and 8% respectively. Code, weights and dataset are available here <a target="_blank" rel="noopener" href="https://github.com/Marshall-mk/EchoPathv1">https://github.com/Marshall-mk/EchoPathv1</a> </p>
<blockquote>
<p>å¿ƒè¡€ç®¡ç–¾ç—…ï¼ˆCVDï¼‰ä»ç„¶æ˜¯å…¨çƒä¸»è¦çš„æ­»äº¡åŸå› ï¼Œè¶…å£°å¿ƒåŠ¨å›¾å¯¹äºå¸¸è§å’Œå…ˆå¤©æ€§å¿ƒè„ç—…çš„è¯Šæ–­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼ŒæŸäº›ç—…ç†çš„è¶…å£°å¿ƒåŠ¨å›¾æ•°æ®ç¨€ç¼ºï¼Œé˜»ç¢äº†ç¨³å¥çš„è‡ªåŠ¨åŒ–è¯Šæ–­æ¨¡å‹çš„å‘å±•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Echo-Pathï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹ç”Ÿæˆæ¡†æ¶ï¼Œå¯ä»¥æ ¹æ®ç‰¹å®šçš„å¿ƒè„ç—…ç†ç”Ÿæˆè¶…å£°å¿ƒåŠ¨å›¾è§†é¢‘ã€‚Echo-Pathå¯ä»¥åˆæˆé€¼çœŸçš„è¶…å£°è§†é¢‘åºåˆ—ï¼Œè¿™äº›è§†é¢‘åºåˆ—æ˜¾ç¤ºå‡ºäº†æœ‰é’ˆå¯¹æ€§çš„å¼‚å¸¸ï¼Œè¿™é‡Œä¸»è¦å…³æ³¨æˆ¿é—´éš”ç¼ºæŸï¼ˆASDï¼‰å’Œè‚ºåŠ¨è„‰é«˜å‹ï¼ˆPAHï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ç—…ç†è°ƒèŠ‚æœºåˆ¶å¼•å…¥å…ˆè¿›çš„å›å£°è§†é¢‘ç”Ÿæˆå™¨ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ å’Œæ§åˆ¶å¿ƒè„ä¸­çš„ç‰¹å®šç–¾ç—…çš„ç»“æ„å’Œè¿åŠ¨æ¨¡å¼ã€‚å®šé‡è¯„ä¼°è¡¨æ˜ï¼Œåˆæˆè§†é¢‘çš„åˆ†å¸ƒè·ç¦»è¾ƒä½ï¼Œè¯´æ˜è§†è§‰ä¿çœŸåº¦è¾ƒé«˜ã€‚åœ¨ä¸´åºŠæ–¹é¢ï¼Œç”Ÿæˆçš„å›å£°è¡¨ç°å‡ºåˆç†çš„ç—…ç†æ ‡è®°ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æˆ‘ä»¬çš„åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒçš„åˆ†ç±»å™¨èƒ½å¤Ÿå¾ˆå¥½åœ°æ¨å¹¿åˆ°çœŸå®æ•°æ®ï¼Œå½“ç”¨äºå¢å¼ºçœŸå®è®­ç»ƒé›†æ—¶ï¼Œå¯¹æé«˜ASDå’ŒPAHçš„ä¸‹æ¸¸è¯Šæ–­å‡†ç¡®ç‡åˆ†åˆ«æé«˜äº†7%å’Œ8%ã€‚ä»£ç ã€æƒé‡å’Œæ•°æ®é›†å¯åœ¨æ­¤å¤„æ‰¾åˆ°ï¼š[<a target="_blank" rel="noopener" href="https://github.com/Marshall-mk/EchoPathv1]%EF%BC%88%E9%93%BE%E6%8E%A5%E6%97%A0%E6%B3%95%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE%EF%BC%8C%E8%AF%B7%E8%87%AA%E8%A1%8C%E5%A4%8D%E5%88%B6%E8%87%B3%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AE%BF%E9%97%AE%EF%BC%89%E3%80%82">https://github.com/Marshall-mk/EchoPathv1]ï¼ˆé“¾æ¥æ— æ³•ç›´æ¥è®¿é—®ï¼Œè¯·è‡ªè¡Œå¤åˆ¶è‡³æµè§ˆå™¨è®¿é—®ï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17190v1">PDF</a> 10 pages, 3 figures, MICCAI-AMAI2025 Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºEcho-Pathçš„æ–°å‹ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºæ ¹æ®ç‰¹å®šå¿ƒè„ç—…ç†ç”Ÿæˆè¶…å£°å¿ƒåŠ¨å›¾è§†é¢‘åºåˆ—ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåˆæˆå…·æœ‰çœŸå®æ„Ÿçš„è¶…å£°å¿ƒåŠ¨è§†é¢‘ï¼Œå±•ç¤ºç‰¹å®šçš„å¿ƒè„å¼‚å¸¸ï¼Œå¦‚æˆ¿é—´éš”ç¼ºæŸå’Œè‚ºåŠ¨è„‰é«˜å‹ã€‚è¯¥ç ”ç©¶å°†ç—…ç†æ¡ä»¶æœºåˆ¶å¼•å…¥å…ˆè¿›çš„å›å£°è§†é¢‘ç”Ÿæˆå™¨ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ å’Œæ§åˆ¶ç–¾ç—…ç‰¹å®šçš„å¿ƒè„ç»“æ„å’Œè¿åŠ¨æ¨¡å¼ã€‚åˆæˆçš„è§†é¢‘åœ¨è§†è§‰ä¸Šæœ‰é«˜åº¦çš„çœŸå®æ„Ÿï¼Œå¹¶ä¸”å¯ä»¥ä½œä¸ºä¸´åºŠç—…ç†æ ‡è®°ã€‚æ­¤å¤–ï¼Œä½¿ç”¨åˆæˆæ•°æ®è®­ç»ƒçš„åˆ†ç±»å™¨èƒ½å¤Ÿå¾ˆå¥½åœ°æ¨å¹¿åˆ°çœŸå®æ•°æ®ï¼Œå¹¶ä¸”å½“ç”¨äºå¢å¼ºç°å®è®­ç»ƒé›†æ—¶ï¼Œå¯ä»¥æé«˜å¯¹æˆ¿é—´éš”ç¼ºæŸå’Œè‚ºåŠ¨è„‰é«˜å‹çš„è¯Šæ–­å‡†ç¡®ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Echo-Pathæ˜¯ä¸€ç§ç”¨äºç”Ÿæˆç‰¹å®šå¿ƒè„ç—…ç†çš„è¶…å£°å¿ƒåŠ¨å›¾è§†é¢‘çš„ç”Ÿæˆæ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿåˆæˆå…·æœ‰çœŸå®æ„Ÿçš„è¶…å£°å¿ƒåŠ¨è§†é¢‘åºåˆ—ï¼Œå±•ç¤ºç‰¹å®šçš„å¿ƒè„å¼‚å¸¸å¦‚æˆ¿é—´éš”ç¼ºæŸå’Œè‚ºåŠ¨è„‰é«˜å‹ã€‚</li>
<li>Echo-Pathå°†ç—…ç†æ¡ä»¶æœºåˆ¶å¼•å…¥å…ˆè¿›çš„å›å£°è§†é¢‘ç”Ÿæˆå™¨ã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ å’Œæ§åˆ¶ç–¾ç—…ç‰¹å®šçš„å¿ƒè„ç»“æ„å’Œè¿åŠ¨æ¨¡å¼ã€‚</li>
<li>åˆæˆçš„è§†é¢‘åœ¨è§†è§‰ä¸Šé«˜åº¦çœŸå®ï¼Œå¯ä½œä¸ºä¸´åºŠç—…ç†æ ‡è®°ã€‚</li>
<li>ä½¿ç”¨åˆæˆæ•°æ®è®­ç»ƒçš„åˆ†ç±»å™¨å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17190">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17190v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17190v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17190v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Ambiguous-Medical-Image-Segmentation-Using-Diffusion-Schrodinger-Bridge"><a href="#Ambiguous-Medical-Image-Segmentation-Using-Diffusion-Schrodinger-Bridge" class="headerlink" title="Ambiguous Medical Image Segmentation Using Diffusion SchrÃ¶dinger   Bridge"></a>Ambiguous Medical Image Segmentation Using Diffusion SchrÃ¶dinger   Bridge</h2><p><strong>Authors:Lalith Bharadwaj Baru, Kamalaker Dadi, Tapabrata Chakraborti, Raju S. Bapi</strong></p>
<p>Accurate segmentation of medical images is challenging due to unclear lesion boundaries and mask variability. We introduce \emph{Segmentation Sch&quot;{o}dinger Bridge (SSB)}, the first application of Sch&quot;{o}dinger Bridge for ambiguous medical image segmentation, modelling joint image-mask dynamics to enhance performance. SSB preserves structural integrity, delineates unclear boundaries without additional guidance, and maintains diversity using a novel loss function. We further propose the \emph{Diversity Divergence Index} ($D_{DDI}$) to quantify inter-rater variability, capturing both diversity and consensus. SSB achieves state-of-the-art performance on LIDC-IDRI, COCA, and RACER (in-house) datasets. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒå‡†ç¡®åˆ†å‰²æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºç—…å˜è¾¹ç•Œä¸æ¸…æ™°å’Œæ©è†œå­˜åœ¨å˜åŒ–ã€‚æˆ‘ä»¬å¼•å…¥äº†SchÃ¶dinger Bridgeåˆ†å‰²ï¼ˆSSBï¼‰ï¼Œè¿™æ˜¯SchÃ¶dinger Bridgeé¦–æ¬¡è¢«åº”ç”¨äºæ¨¡ç³ŠåŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œé€šè¿‡å»ºæ¨¡å›¾åƒå’Œæ©è†œè”åˆåŠ¨æ€æ¥æé«˜æ€§èƒ½ã€‚SSBä¿ç•™äº†ç»“æ„å®Œæ•´æ€§ï¼Œåœ¨æ²¡æœ‰é¢å¤–æŒ‡å¯¼çš„æƒ…å†µä¸‹æç»˜äº†ä¸æ¸…æ™°è¾¹ç•Œï¼Œå¹¶ä½¿ç”¨æ–°å‹æŸå¤±å‡½æ•°ç»´æŒå¤šæ ·æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†å¤šæ ·æ€§å‘æ•£æŒ‡æ•°ï¼ˆD_{DDI}ï¼‰æ¥é‡åŒ–è¯„ä»·è€…é—´å·®å¼‚æ€§ï¼ŒåŒæ—¶æ•æ‰å¤šæ ·æ€§å’Œå…±è¯†ã€‚SSBåœ¨LIDC-IDRIã€COCAå’ŒRACERï¼ˆå†…éƒ¨ï¼‰æ•°æ®é›†ä¸Šå®ç°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³çš„æ€§èƒ½è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17187v1">PDF</a> MICCAI 2025 (11 pages, 2 figures, 1 table, and 26 references)</p>
<p><strong>Summary</strong></p>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´å› ç—…ç¶è¾¹ç•Œä¸æ¸…å’Œé®ç½©å˜åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¼•å…¥â€œSegmentation Sch&quot;{o}dinger Bridge (SSB)â€æŠ€æœ¯ï¼Œé¦–æ¬¡å°†Sch&quot;{o}dinger Bridgeåº”ç”¨äºæ¨¡ç³ŠåŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œå»ºç«‹å›¾åƒä¸é®ç½©çš„åŠ¨æ€è”åˆæ¨¡å‹ä»¥æé«˜æ€§èƒ½ã€‚SSBä¿ç•™ç»“æ„å®Œæ•´æ€§ï¼Œåœ¨æ— éœ€é¢å¤–æŒ‡å¯¼çš„æƒ…å†µä¸‹æç»˜ä¸æ¸…çš„è¾¹ç•Œï¼Œå¹¶ä½¿ç”¨æ–°å‹æŸå¤±å‡½æ•°ç»´æŒå¤šæ ·æ€§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†â€œå¤šæ ·æ€§å‘æ•£æŒ‡æ•°â€ï¼ˆDiversity Divergence Indexï¼Œ$D_{DDI}$ï¼‰æ¥è¡¡é‡è¯„ä¼°è€…ä¹‹é—´çš„å·®å¼‚ï¼ŒåŒæ—¶æ•æ‰å¤šæ ·æ€§å’Œå…±è¯†ã€‚SSBåœ¨LIDC-IDRIã€COCAå’ŒRACERæ•°æ®é›†ä¸Šè¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´ç—…ç¶è¾¹ç•Œä¸æ¸…å’Œé®ç½©å˜åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥SSBæŠ€æœ¯ï¼Œé¦–æ¬¡å°†Sch&quot;{o}dinger Bridgeåº”ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ã€‚</li>
<li>SSBå»ºç«‹å›¾åƒä¸é®ç½©çš„åŠ¨æ€è”åˆæ¨¡å‹ï¼Œæé«˜åˆ†å‰²æ€§èƒ½ã€‚</li>
<li>SSBåœ¨æ— éœ€é¢å¤–æŒ‡å¯¼çš„æƒ…å†µä¸‹èƒ½å¤Ÿæç»˜ä¸æ¸…çš„è¾¹ç•Œã€‚</li>
<li>SSBä½¿ç”¨æ–°å‹æŸå¤±å‡½æ•°æ¥ä¿æŒå¤šæ ·æ€§ã€‚</li>
<li>æå‡ºâ€œå¤šæ ·æ€§å‘æ•£æŒ‡æ•°â€ï¼ˆDiversity Divergence Indexï¼Œ$D_{DDI}$ï¼‰æ¥è¡¡é‡è¯„ä¼°è€…ä¹‹é—´çš„å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17187">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17187v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17187v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.17187v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Accurate-Thyroid-Cancer-Classification-using-a-Novel-Binary-Pattern-Driven-Local-Discrete-Cosine-Transform-Descriptor"><a href="#Accurate-Thyroid-Cancer-Classification-using-a-Novel-Binary-Pattern-Driven-Local-Discrete-Cosine-Transform-Descriptor" class="headerlink" title="Accurate Thyroid Cancer Classification using a Novel Binary Pattern   Driven Local Discrete Cosine Transform Descriptor"></a>Accurate Thyroid Cancer Classification using a Novel Binary Pattern   Driven Local Discrete Cosine Transform Descriptor</h2><p><strong>Authors:Saurabh Saini, Kapil Ahuja, Marc C. Steinbach, Thomas Wick</strong></p>
<p>In this study, we develop a new CAD system for accurate thyroid cancer classification with emphasis on feature extraction. Prior studies have shown that thyroid texture is important for segregating the thyroid ultrasound images into different classes. Based upon our experience with breast cancer classification, we first conjuncture that the Discrete Cosine Transform (DCT) is the best descriptor for capturing textural features. Thyroid ultrasound images are particularly challenging as the gland is surrounded by multiple complex anatomical structures leading to variations in tissue density. Hence, we second conjuncture the importance of localization and propose that the Local DCT (LDCT) descriptor captures the textural features best in this context. Another disadvantage of complex anatomy around the thyroid gland is scattering of ultrasound waves resulting in noisy and unclear textures. Hence, we third conjuncture that one image descriptor is not enough to fully capture the textural features and propose the integration of another popular texture capturing descriptor (Improved Local Binary Pattern, ILBP) with LDCT. ILBP is known to be noise resilient as well. We term our novel descriptor as Binary Pattern Driven Local Discrete Cosine Transform (BPD-LDCT). Final classification is carried out using a non-linear SVM. The proposed CAD system is evaluated on the only two publicly available thyroid cancer datasets, namely TDID and AUITD. The evaluation is conducted in two stages. In Stage I, thyroid nodules are categorized as benign or malignant. In Stage II, the malignant cases are further sub-classified into TI-RADS (4) and TI-RADS (5). For Stage I classification, our proposed model demonstrates exceptional performance of nearly 100% on TDID and 97% on AUITD. In Stage II classification, the proposed model again attains excellent classification of close to 100% on TDID and 99% on AUITD. </p>
<blockquote>
<p>åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°çš„è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ï¼ˆCADï¼‰ç³»ç»Ÿï¼Œç”¨äºå¯¹ç”²çŠ¶è…ºç™Œè¿›è¡Œç²¾ç¡®åˆ†ç±»ï¼Œå¹¶é‡ç‚¹ç ”ç©¶ç‰¹å¾æå–ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œç”²çŠ¶è…ºçº¹ç†å¯¹äºå°†ç”²çŠ¶è…ºè¶…å£°å›¾åƒåˆ†ç±»ä¸ºä¸åŒçš„ç±»åˆ«éå¸¸é‡è¦ã€‚åŸºäºæˆ‘ä»¬å¯¹ä¹³è…ºç™Œåˆ†ç±»çš„ç»éªŒï¼Œæˆ‘ä»¬é¦–å…ˆæ¨æµ‹ç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆDCTï¼‰æ˜¯æ•è·çº¹ç†ç‰¹å¾çš„æœ€ä½³æè¿°ç¬¦ã€‚ç”²çŠ¶è…ºè¶…å£°å›¾åƒå°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè¯¥è…ºä½“è¢«å¤šä¸ªå¤æ‚çš„è§£å‰–ç»“æ„æ‰€åŒ…å›´ï¼Œå¯¼è‡´ç»„ç»‡å¯†åº¦å˜åŒ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å…¶æ¬¡ä¹Ÿæ¨æµ‹å®šä½çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºå±€éƒ¨ç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆLDCTï¼‰æè¿°ç¬¦åœ¨è¿™ç§æƒ…å†µä¸‹èƒ½æœ€å¥½åœ°æ•è·çº¹ç†ç‰¹å¾ã€‚ç”²çŠ¶è…ºå‘¨å›´å¤æ‚è§£å‰–ç»“æ„å¦ä¸€ä¸ªä¸åˆ©ä¹‹å¤„æ˜¯è¶…å£°æ³¢çš„æ•£å°„å¯¼è‡´çº¹ç†å˜ˆæ‚ä¸”ä¸æ¸…æ™°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å†æ¬¡æ¨æµ‹å•ä¸€çš„å›¾åƒæè¿°ç¬¦ä¸è¶³ä»¥å®Œå…¨æ•è·çº¹ç†ç‰¹å¾ï¼Œå¹¶æå‡ºå°†å¦ä¸€ç§æµè¡Œçš„çº¹ç†æ•è·æè¿°ç¬¦ï¼ˆæ”¹è¿›åçš„å±€éƒ¨äºŒå€¼æ¨¡å¼ï¼ŒILBPï¼‰ä¸LDCTç›¸ç»“åˆã€‚å·²çŸ¥ILBPå…·æœ‰æŠ—å™ªå£°æ€§ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–°å‹æè¿°ç¬¦ç§°ä¸ºäºŒè¿›åˆ¶æ¨¡å¼é©±åŠ¨çš„å±€éƒ¨ç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆBPD-LDCTï¼‰ã€‚æœ€ç»ˆçš„åˆ†ç±»æ˜¯é€šè¿‡éçº¿æ€§æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰è¿›è¡Œçš„ã€‚è¯¥CADç³»ç»Ÿæ˜¯åœ¨ä¸¤ä¸ªå…¬å¼€çš„ç”²çŠ¶è…ºç™Œæ•°æ®é›†TDIDå’ŒAUITDä¸Šè¿›è¡Œè¯„ä¼°çš„ã€‚è¯„ä¼°åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µè¿›è¡Œã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œç”²çŠ¶è…ºç»“èŠ‚è¢«åˆ†ç±»ä¸ºè‰¯æ€§æˆ–æ¶æ€§ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¶æ€§ç—…ä¾‹è¿›ä¸€æ­¥ç»†åˆ†ä¸ºTI-RADSï¼ˆ4ï¼‰å’ŒTI-RADSï¼ˆ5ï¼‰ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µåˆ†ç±»ä¸­ï¼Œæˆ‘ä»¬æå‡ºçš„æ¨¡å‹åœ¨TDIDä¸Šè¡¨ç°å‡ºè¿‘100ï¼…çš„å‡ºè‰²æ€§èƒ½ï¼Œåœ¨AUITDä¸Šä¸º97ï¼…ã€‚åœ¨ç¬¬äºŒé˜¶æ®µåˆ†ç±»ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨TDIDä¸Šå†æ¬¡å®ç°äº†æ¥è¿‘100ï¼…çš„ä¼˜ç§€åˆ†ç±»ï¼Œåœ¨AUITDä¸Šä¸º99ï¼…ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16382v1">PDF</a> 15 Pages, 7 Figures, 5 Tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§æ–°çš„CADç³»ç»Ÿï¼Œç”¨äºç”²çŠ¶è…ºç™Œç—‡çš„å‡†ç¡®åˆ†ç±»ï¼Œé‡ç‚¹åœ¨äºç‰¹å¾æå–ã€‚ç ”ç©¶ä¸­ï¼Œç»“åˆç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆDCTï¼‰ä¸å±€éƒ¨ç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆLDCTï¼‰ä»¥åŠæ”¹è¿›å±€éƒ¨äºŒå€¼æ¨¡å¼ï¼ˆILBPï¼‰æ„å»ºäº†ä¸€ç§æ–°å‹æè¿°å™¨BPD-LDCTï¼Œä»¥æ•æ‰ç”²çŠ¶è…ºè¶…å£°å›¾åƒä¸­çš„çº¹ç†ç‰¹å¾ã€‚æœ€ç»ˆé‡‡ç”¨éçº¿æ€§æ”¯æŒå‘é‡æœºè¿›è¡Œåˆ†ç±»ã€‚åœ¨å…¬å¼€æ•°æ®é›†TDIDå’ŒAUITDä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥CADç³»ç»Ÿåœ¨ä¸¤ä¸ªé˜¶æ®µå‡è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶å¼€å‘äº†ä¸€ç§æ–°çš„CADç³»ç»Ÿç”¨äºç”²çŠ¶è…ºç™Œç—‡åˆ†ç±»ã€‚</li>
<li>é‡ç‚¹åœ¨äºç‰¹å¾æå–ï¼Œç»“åˆç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆDCTï¼‰ä¸å±€éƒ¨ç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆLDCTï¼‰è¿›è¡Œçº¹ç†ç‰¹å¾æ•æ‰ã€‚</li>
<li>é’ˆå¯¹ç”²çŠ¶è…ºè¶…å£°å›¾åƒå¤æ‚è§£å‰–ç»“æ„å¼•èµ·çš„çº¹ç†å˜åŒ–é—®é¢˜ï¼Œæå‡ºé‡‡ç”¨æ”¹è¿›å±€éƒ¨äºŒå€¼æ¨¡å¼ï¼ˆILBPï¼‰ç»“åˆLDCTè¿›è¡Œæè¿°ã€‚</li>
<li>ä½¿ç”¨éçº¿æ€§æ”¯æŒå‘é‡æœºè¿›è¡Œåˆ†ç±»ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16382">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16382v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16382v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16382v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16382v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16382v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="TF-DWGNet-A-Directed-Weighted-Graph-Neural-Network-with-Tensor-Fusion-for-Multi-Omics-Cancer-Subtype-Classification"><a href="#TF-DWGNet-A-Directed-Weighted-Graph-Neural-Network-with-Tensor-Fusion-for-Multi-Omics-Cancer-Subtype-Classification" class="headerlink" title="TF-DWGNet: A Directed Weighted Graph Neural Network with Tensor Fusion   for Multi-Omics Cancer Subtype Classification"></a>TF-DWGNet: A Directed Weighted Graph Neural Network with Tensor Fusion   for Multi-Omics Cancer Subtype Classification</h2><p><strong>Authors:Tiantian Yang, Zhiqian Chen</strong></p>
<p>Integration and analysis of multi-omics data provide valuable insights for cancer subtype classification. However, such data are inherently heterogeneous, high-dimensional, and exhibit complex intra- and inter-modality dependencies. Recent advances in graph neural networks (GNNs) offer powerful tools for modeling such structure. Yet, most existing methods rely on prior knowledge or predefined similarity networks to construct graphs, which are often undirected or unweighted, failing to capture the directionality and strength of biological interactions. Interpretability at both the modality and feature levels also remains limited. To address these challenges, we propose TF-DWGNet, a novel Graph Neural Network framework that combines tree-based Directed Weighted graph construction with Tensor Fusion for multiclass cancer subtype classification. TF-DWGNet introduces two key innovations: a supervised tree-based approach for constructing directed, weighted graphs tailored to each omics modality, and a tensor fusion mechanism that captures unimodal, bimodal, and trimodal interactions using low-rank decomposition for efficiency. TF-DWGNet enables modality-specific representation learning, joint embedding fusion, and interpretable subtype prediction. Experiments on real-world cancer datasets show that TF-DWGNet consistently outperforms state-of-the-art baselines across multiple metrics and statistical tests. Moreover, it provides biologically meaningful insights by ranking influential features and modalities. These results highlight TF-DWGNetâ€™s potential for effective and interpretable multi-omics integration in cancer research. </p>
<blockquote>
<p>å¤šç»„å­¦æ•°æ®çš„æ•´åˆä¸åˆ†æä¸ºç™Œç—‡äºšå‹åˆ†ç±»æä¾›äº†å®è´µçš„è§è§£ã€‚ç„¶è€Œï¼Œæ­¤ç±»æ•°æ®æœ¬è´¨ä¸Šæ˜¯å¼‚è´¨æ€§çš„ã€é«˜ç»´çš„ï¼Œå¹¶è¡¨ç°å‡ºå¤æ‚çš„å†…éƒ¨å’Œå¤–éƒ¨æ¨¡æ€ä¾èµ–æ€§ã€‚å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰çš„æœ€æ–°è¿›å±•ä¸ºå»ºæ¨¡æ­¤ç±»ç»“æ„æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºå…ˆéªŒçŸ¥è¯†æˆ–é¢„å®šä¹‰çš„ç›¸ä¼¼æ€§ç½‘ç»œæ¥æ„å»ºå›¾ï¼Œè¿™äº›å›¾é€šå¸¸æ˜¯æ— æ–¹å‘æˆ–æ— æƒé‡çš„ï¼Œæ— æ³•æ•æ‰ç”Ÿç‰©ç›¸äº’ä½œç”¨çš„æ–¹å‘æ€§å’Œå¼ºåº¦ã€‚åŒæ—¶åœ¨æ¨¡æ€å’Œç‰¹å¾å±‚é¢çš„å¯è§£é‡Šæ€§ä»ç„¶æœ‰é™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16301v1">PDF</a> 9 pages, 4 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†TF-DWGNetï¼Œä¸€ç§ç»“åˆæ ‘ç»“æ„å¯¼å‘åŠ æƒå›¾ä¸å¼ é‡èåˆçš„æ–°å‹å›¾ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºå¤šç±»ç™Œç—‡äºšå‹åˆ†ç±»ã€‚TF-DWGNetè§£å†³å¤šç»„å­¦æ•°æ®é›†æˆä¸­çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ„å»ºé’ˆå¯¹æ¯ç§ç»„å­¦æ¨¡æ€çš„æœ‰ç›‘ç£çš„åŸºäºæ ‘çš„å®šå‘åŠ æƒå›¾ï¼Œä»¥åŠæ•æ‰å•æ¨¡æ€ã€åŒæ¨¡æ€å’Œä¸‰æ¨¡æ€äº¤äº’çš„å¼ é‡èåˆæœºåˆ¶ã€‚å®éªŒè¡¨æ˜ï¼ŒTF-DWGNetåœ¨çœŸå®ä¸–ç•Œç™Œç—‡æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶æä¾›äº†å…·æœ‰ç”Ÿç‰©å­¦æ„ä¹‰çš„ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TF-DWGNetæ˜¯ä¸€ä¸ªæ–°å‹çš„å›¾ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºå¤šç±»ç™Œç—‡äºšå‹åˆ†ç±»ã€‚</li>
<li>å®ƒç»“åˆäº†æ ‘ç»“æ„å¯¼å‘åŠ æƒå›¾ä¸å¼ é‡èåˆæœºåˆ¶ï¼Œå¤„ç†å¤šç»„å­¦æ•°æ®çš„å¼‚è´¨æ€§ã€é«˜ç»´æ€§ä»¥åŠå¤æ‚çš„å†…å¤–æ¨¡æ€ä¾èµ–é—®é¢˜ã€‚</li>
<li>TF-DWGNeté€šè¿‡æ„å»ºé’ˆå¯¹æ¯ä¸ªç»„å­¦æ¨¡æ€çš„å®šå‘åŠ æƒå›¾ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•ä¾èµ–å…ˆéªŒçŸ¥è¯†æˆ–é¢„è®¾ç›¸ä¼¼æ€§ç½‘ç»œçš„é—®é¢˜ã€‚</li>
<li>å®ƒå¼•å…¥äº†å¼ é‡èåˆæœºåˆ¶ï¼Œèƒ½å¤Ÿæ•æ‰å•æ¨¡æ€ã€åŒæ¨¡æ€å’Œä¸‰æ¨¡æ€çš„äº¤äº’ä½œç”¨ï¼Œå¹¶é€šè¿‡ä½ç§©åˆ†è§£æé«˜æ•ˆç‡ã€‚</li>
<li>TF-DWGNetå®ç°äº†æ¨¡æ€ç‰¹å®šçš„è¡¨ç¤ºå­¦ä¹ ã€è”åˆåµŒå…¥èåˆå’Œå¯è§£é‡Šçš„äºšå‹é¢„æµ‹ã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œç™Œç—‡æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTF-DWGNetçš„è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16301">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16301v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16301v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16301v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16301v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16301v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="R-Net-A-Reliable-and-Resource-Efficient-CNN-for-Colorectal-Cancer-Detection-with-XAI-Integration"><a href="#R-Net-A-Reliable-and-Resource-Efficient-CNN-for-Colorectal-Cancer-Detection-with-XAI-Integration" class="headerlink" title="R-Net: A Reliable and Resource-Efficient CNN for Colorectal Cancer   Detection with XAI Integration"></a>R-Net: A Reliable and Resource-Efficient CNN for Colorectal Cancer   Detection with XAI Integration</h2><p><strong>Authors:Rokonozzaman Ayon, Md Taimur Ahad, Bo Song, Yan Li</strong></p>
<p>State-of-the-art (SOTA) Convolutional Neural Networks (CNNs) are criticized for their extensive computational power, long training times, and large datasets. To overcome this limitation, we propose a reasonable network (R-Net), a lightweight CNN only to detect and classify colorectal cancer (CRC) using the Enteroscope Biopsy Histopathological Hematoxylin and Eosin Image Dataset (EBHI). Furthermore, six SOTA CNNs, including Multipath-based CNNs (DenseNet121, ResNet50), Depth-based CNNs (InceptionV3), width-based multi-connection CNNs (Xception), depth-wise separable convolutions (MobileNetV2), spatial exploitation-based CNNs (VGG16), Transfer learning, and two ensemble models are also tested on the same dataset. The ensemble models are a multipath-depth-width combination (DenseNet121-InceptionV3-Xception) and a multipath-depth-spatial combination (ResNet18-InceptionV3-VGG16). However, the proposed R-Net lightweight achieved 99.37% accuracy, outperforming MobileNet (95.83%) and ResNet50 (96.94%). Most importantly, to understand the decision-making of R-Net, Explainable AI such as SHAP, LIME, and Grad-CAM are integrated to visualize which parts of the EBHI image contribute to the detection and classification process of R-Net. The main novelty of this research lies in building a reliable, lightweight CNN R-Net that requires fewer computing resources yet maintains strong prediction results. SOTA CNNs, transfer learning, and ensemble models also extend our knowledge on CRC classification and detection. XAI functionality and the impact of pixel intensity on correct and incorrect classification images are also some novelties in CRC detection and classification. </p>
<blockquote>
<p>æœ€å…ˆè¿›çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰å› å…¶å·¨å¤§çš„è®¡ç®—åŠ›ã€æ¼«é•¿çš„è®­ç»ƒæ—¶é—´å’Œåºå¤§çš„æ•°æ®é›†è€Œå—åˆ°æ‰¹è¯„ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆç†çš„ç½‘ç»œï¼ˆR-Netï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„CNNï¼Œä»…ç”¨äºä½¿ç”¨èƒƒè‚ é•œæ´»æ£€ç»„ç»‡ç—…ç†å­¦è‹æœ¨ç²¾å’Œä¼Šçº¢å›¾åƒæ•°æ®é›†ï¼ˆEBHIï¼‰æ£€æµ‹å’Œåˆ†ç±»ç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰ã€‚æ­¤å¤–ï¼Œè¿˜åœ¨åŒä¸€æ•°æ®é›†ä¸Šæµ‹è¯•äº†å…­ç§æœ€å…ˆè¿›çš„CNNï¼ŒåŒ…æ‹¬åŸºäºå¤šè·¯å¾„çš„CNNï¼ˆDenseNet121ã€ResNet50ï¼‰ã€åŸºäºæ·±åº¦çš„CNNï¼ˆInceptionV3ï¼‰ã€åŸºäºå®½åº¦çš„å¤šè¿æ¥CNNï¼ˆXceptionï¼‰ã€æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆMobileNetV2ï¼‰ã€åŸºäºç©ºé—´åˆ©ç”¨çš„CNNï¼ˆVGG16ï¼‰ã€è¿ç§»å­¦ä¹ ä»¥åŠä¸¤ç§é›†æˆæ¨¡å‹ã€‚é›†æˆæ¨¡å‹æ˜¯ä¸€ç§å¤šè·¯å¾„æ·±åº¦å®½åº¦ç»„åˆï¼ˆDenseNet121-InceptionV3-Xceptionï¼‰å’Œä¸€ç§å¤šè·¯å¾„æ·±åº¦ç©ºé—´ç»„åˆï¼ˆResNet18-InceptionV3-VGG16ï¼‰ã€‚ç„¶è€Œï¼Œæ‰€æå‡ºçš„R-Netè½»å‹ç½‘ç»œè¾¾åˆ°äº†99.37%çš„å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†MobileNetï¼ˆ95.83%ï¼‰å’ŒResNet50ï¼ˆ96.94%ï¼‰ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œä¸ºäº†ç†è§£R-Netçš„å†³ç­–è¿‡ç¨‹ï¼Œæˆ‘ä»¬é›†æˆäº†å¯è§£é‡Šçš„AIï¼Œå¦‚SHAPã€LIMEå’ŒGrad-CAMï¼Œä»¥å¯è§†åŒ–EBHIå›¾åƒçš„å“ªäº›éƒ¨åˆ†å¯¹R-Netçš„æ£€æµ‹å’Œåˆ†ç±»è¿‡ç¨‹æœ‰æ‰€è´¡çŒ®ã€‚è¿™é¡¹ç ”ç©¶çš„ä¸»è¦æ–°é¢–ä¹‹å¤„åœ¨äºå»ºç«‹äº†ä¸€ä¸ªå¯é ä¸”è½»é‡çº§çš„CNN R-Netï¼Œå®ƒéœ€è¦çš„è®¡ç®—èµ„æºè¾ƒå°‘ï¼Œä½†é¢„æµ‹ç»“æœä»ç„¶å¼ºå¤§ã€‚æœ€å…ˆè¿›çš„CNNã€è¿ç§»å­¦ä¹ å’Œé›†æˆæ¨¡å‹ä¹Ÿæ‰©å±•äº†æˆ‘ä»¬å¯¹CRCåˆ†ç±»å’Œæ£€æµ‹çš„è®¤è¯†ã€‚å¯è§£é‡Šçš„AIåŠŸèƒ½å’Œåƒç´ å¼ºåº¦å¯¹æ­£ç¡®å’Œé”™è¯¯åˆ†ç±»å›¾åƒçš„å½±å“ä¹Ÿæ˜¯CRCæ£€æµ‹å’Œåˆ†ç±»ä¸­çš„ä¸€äº›æ–°é¢–ä¹‹å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16251v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨å¤„ç†ç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰æ£€æµ‹ä¸åˆ†ç±»æ—¶å­˜åœ¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§çš„CNNç½‘ç»œï¼ˆR-Netï¼‰ã€‚ç›¸æ¯”äºå…¶ä»–å¤æ‚æ¨¡å‹å¦‚DenseNetã€ResNetç­‰ï¼ŒR-Netåœ¨ç›¸åŒæ•°æ®é›†ä¸Šå–å¾—äº†æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œè¾¾åˆ°99.37%ã€‚ç ”ç©¶è¿˜èåˆäº†å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆExplainable AIï¼‰æŠ€æœ¯æ¥åˆ†æR-Netçš„å†³ç­–è¿‡ç¨‹ã€‚æ­¤ç ”ç©¶çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºæ„å»ºäº†ä¸€ä¸ªå¯é çš„è½»é‡çº§CNNç½‘ç»œï¼Œæ—¢å‡å°‘äº†è®¡ç®—èµ„æºéœ€æ±‚ï¼Œåˆä¿æŒäº†å‡ºè‰²çš„é¢„æµ‹æ€§èƒ½ã€‚åŒæ—¶ï¼Œç ”ç©¶ä¹Ÿæ‹“å±•äº†æˆ‘ä»¬å¯¹CRCæ£€æµ‹å’Œåˆ†ç±»çš„è®¤è¯†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶é’ˆå¯¹ç°æœ‰CNNåœ¨å¤„ç†ç»“ç›´è‚ ç™Œæ£€æµ‹ä¸åˆ†ç±»æ—¶çš„è®¡ç®—é‡å¤§ã€è®­ç»ƒæ—¶é—´é•¿å’Œæ•°æ®é›†éœ€æ±‚å¤§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§CNNç½‘ç»œï¼ˆR-Netï¼‰ã€‚</li>
<li>R-Netåœ¨Enteroscope Biopsy Histopathological Hematoxylinå’ŒEosin Imageæ•°æ®é›†ï¼ˆEBHIï¼‰ä¸Šå–å¾—äº†é«˜è¾¾99.37%çš„å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†å…¶ä»–å¤æ‚æ¨¡å‹å¦‚MobileNetå’ŒResNetç­‰ã€‚</li>
<li>ç ”ç©¶ç»“åˆäº†å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆExplainable AIï¼‰æŠ€æœ¯æ¥åˆ†æR-Netçš„å†³ç­–è¿‡ç¨‹ï¼Œæ­ç¤ºäº†æ¨¡å‹å¯¹å›¾åƒå“ªäº›éƒ¨åˆ†çš„ä¾èµ–ã€‚</li>
<li>è¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºæ„å»ºäº†ä¸€ä¸ªæ—¢å¯é åˆè½»é‡çº§çš„CNNç½‘ç»œï¼Œé™ä½äº†è®¡ç®—èµ„æºéœ€æ±‚ä½†ä¿æŒäº†é«˜é¢„æµ‹æ€§èƒ½ã€‚</li>
<li>ç ”ç©¶å±•ç¤ºäº†å¤šç§å…ˆè¿›CNNã€è¿ç§»å­¦ä¹ å’Œé›†æˆæ¨¡å‹åœ¨CRCæ£€æµ‹ä¸åˆ†ç±»çš„åº”ç”¨ï¼Œæ‹“å±•äº†ç›¸å…³çŸ¥è¯†é¢†åŸŸã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16251">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16251v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16251v1/page_2_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="A-study-on-Deep-Convolutional-Neural-Networks-transfer-learning-and-Mnet-model-for-Cervical-Cancer-Detection"><a href="#A-study-on-Deep-Convolutional-Neural-Networks-transfer-learning-and-Mnet-model-for-Cervical-Cancer-Detection" class="headerlink" title="A study on Deep Convolutional Neural Networks, transfer learning, and   Mnet model for Cervical Cancer Detection"></a>A study on Deep Convolutional Neural Networks, transfer learning, and   Mnet model for Cervical Cancer Detection</h2><p><strong>Authors:Saifuddin Sagor, Md Taimur Ahad, Faruk Ahmed, Rokonozzaman Ayon, Sanzida Parvin</strong></p>
<p>Early and accurate detection through Pap smear analysis is critical to improving patient outcomes and reducing mortality of Cervical cancer. State-of-the-art (SOTA) Convolutional Neural Networks (CNNs) require substantial computational resources, extended training time, and large datasets. In this study, a lightweight CNN model, S-Net (Simple Net), is developed specifically for cervical cancer detection and classification using Pap smear images to address these limitations. Alongside S-Net, six SOTA CNNs were evaluated using transfer learning, including multi-path (DenseNet201, ResNet152), depth-based (Serasnet152), width-based multi-connection (Xception), depth-wise separable convolutions (MobileNetV2), and spatial exploitation-based (VGG19). All models, including S-Net, achieved comparable accuracy, with S-Net reaching 99.99%. However, S-Net significantly outperforms the SOTA CNNs in terms of computational efficiency and inference time, making it a more practical choice for real-time and resource-constrained applications. A major limitation in CNN-based medical diagnosis remains the lack of transparency in the decision-making process. To address this, Explainable AI (XAI) techniques, such as SHAP, LIME, and Grad-CAM, were employed to visualize and interpret the key image regions influencing model predictions. The novelty of this study lies in the development of a highly accurate yet computationally lightweight model (S-Net) caPable of rapid inference while maintaining interpretability through XAI integration. Furthermore, this work analyzes the behavior of SOTA CNNs, investigates the effects of negative transfer learning on Pap smear images, and examines pixel intensity patterns in correctly and incorrectly classified samples. </p>
<blockquote>
<p>é€šè¿‡æ¶‚ç‰‡åˆ†æè¿›è¡Œæ—©æœŸå’Œå‡†ç¡®çš„æ£€æµ‹å¯¹äºæ”¹å–„å®«é¢ˆç™Œæ‚£è€…é¢„åå’Œé™ä½æ­»äº¡ç‡è‡³å…³é‡è¦ã€‚ç°æœ‰çš„å…ˆè¿›æŠ€æœ¯ï¼ˆSOTAï¼‰å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€è¾ƒé•¿çš„è®­ç»ƒæ—¶é—´å’Œå¤§è§„æ¨¡æ•°æ®é›†ã€‚æœ¬ç ”ç©¶é’ˆå¯¹è¿™äº›é™åˆ¶ï¼Œå¼€å‘äº†ä¸€ç§ç”¨äºå®«é¢ˆç™Œæ£€æµ‹å’Œåˆ†ç±»çš„è½»é‡çº§CNNæ¨¡å‹S-Netï¼ˆSimple Netï¼‰ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ¶‚ç‰‡å›¾åƒè¿›è¡Œæ£€æµ‹ã€‚é™¤S-Netå¤–ï¼Œè¿˜åˆ©ç”¨è¿ç§»å­¦ä¹ è¯„ä¼°äº†å…­ç§SOTA CNNï¼ŒåŒ…æ‹¬å¤šè·¯ï¼ˆDenseNet201ã€ResNet152ï¼‰ã€åŸºäºæ·±åº¦ï¼ˆSerasnet152ï¼‰ã€åŸºäºå®½åº¦çš„å¤šè¿æ¥ï¼ˆXceptionï¼‰ã€æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆMobileNetV2ï¼‰å’ŒåŸºäºç©ºé—´åˆ©ç”¨ï¼ˆVGG19ï¼‰ã€‚æ‰€æœ‰æ¨¡å‹ï¼ŒåŒ…æ‹¬S-Netåœ¨å†…ï¼Œå‡è¾¾åˆ°ç›¸è¿‘çš„å‡†ç¡®æ€§ï¼Œå…¶ä¸­S-Netè¾¾åˆ°99.99%ã€‚ç„¶è€Œï¼Œåœ¨è¿ç®—æ•ˆç‡å’Œæ¨ç†æ—¶é—´ä¸Šï¼ŒS-Netæ˜¾è‘—ä¼˜äºSOTA CNNï¼Œä½¿å…¶æˆä¸ºå®æ—¶å’Œèµ„æºå—é™åº”ç”¨æ›´å®ç”¨çš„é€‰æ‹©ã€‚CNNåœ¨åŒ»å­¦è¯Šæ–­ä¸­çš„ä¸€ä¸ªä¸»è¦å±€é™æ€§åœ¨äºå†³ç­–è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œé‡‡ç”¨äº†å¯è§£é‡Šçš„AIï¼ˆXAIï¼‰æŠ€æœ¯ï¼Œå¦‚SHAPã€LIMEå’ŒGrad-CAMï¼Œä»¥å¯è§†åŒ–å’Œè§£é‡Šå½±å“æ¨¡å‹é¢„æµ‹çš„å…³é”®å›¾åƒåŒºåŸŸã€‚æœ¬ç ”ç©¶çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå¼€å‘äº†ä¸€ç§é«˜åº¦å‡†ç¡®ä½†è®¡ç®—é‡å°çš„æ¨¡å‹ï¼ˆS-Netï¼‰ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒXAIé›†æˆè§£é‡Šæ€§çš„åŒæ—¶è¿›è¡Œå¿«é€Ÿæ¨ç†ã€‚æ­¤å¤–ï¼Œæœ¬å·¥ä½œè¿˜åˆ†æäº†SOTA CNNçš„è¡Œä¸ºï¼Œç ”ç©¶äº†è´Ÿè¿ç§»å­¦ä¹ å¯¹æ¶‚ç‰‡å›¾åƒçš„å½±å“ï¼Œå¹¶æ¢è®¨äº†æ­£ç¡®å’Œé”™è¯¯åˆ†ç±»æ ·æœ¬ä¸­çš„åƒç´ å¼ºåº¦æ¨¡å¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16250v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§è½»é‡çº§çš„CNNæ¨¡å‹ï¼ˆS-Netï¼‰ç”¨äºå®«é¢ˆç™Œçš„æ£€æµ‹å’Œåˆ†ç±»ã€‚ç›¸è¾ƒäºå…¶ä»–å…ˆè¿›CNNæ¨¡å‹ï¼ŒS-Netåœ¨å·´æ°æ¶‚ç‰‡å›¾åƒåˆ†æä¸­å…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡å’Œæ›´å¿«çš„æ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚ç ”ç©¶è¿˜åˆ©ç”¨å¯è§£é‡Šæ€§AIæŠ€æœ¯è§£æäº†æ¨¡å‹å†³ç­–è¿‡ç¨‹çš„å…³é”®å›¾åƒåŒºåŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å¼ºè°ƒäº†æ—©æœŸå‡†ç¡®æ£€æµ‹å®«é¢ˆç™Œçš„é‡è¦æ€§ï¼Œä»¥åŠé€šè¿‡å·´æ°æ¶‚ç‰‡åˆ†æåœ¨æ”¹å–„æ‚£è€…é¢„åå’Œé™ä½æ­»äº¡ç‡æ–¹é¢çš„ä½œç”¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è½»é‡çº§çš„CNNæ¨¡å‹ï¼ˆS-Netï¼‰ï¼Œä¸“é—¨ç”¨äºå®«é¢ˆç™Œçš„æ£€æµ‹å’Œåˆ†ç±»ï¼Œè§£å†³äº†ç°æœ‰CNNæ¨¡å‹è®¡ç®—èµ„æºéœ€æ±‚å¤§ã€è®­ç»ƒæ—¶é—´é•¿å’Œæ•°æ®é›†éœ€æ±‚å¤§çš„é—®é¢˜ã€‚</li>
<li>S-Netåœ¨å·´æ°æ¶‚ç‰‡å›¾åƒåˆ†æä¸­çš„å‡†ç¡®ç‡è¾¾åˆ°äº†99.99%ï¼Œå¹¶ä¸”ç›¸è¾ƒäºå…¶ä»–å…ˆè¿›CNNæ¨¡å‹å…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡å’Œæ›´å¿«çš„æ¨ç†æ—¶é—´ã€‚</li>
<li>å¯è§£é‡Šæ€§AIæŠ€æœ¯è¢«ç”¨äºè§£ææ¨¡å‹å†³ç­–è¿‡ç¨‹çš„å…³é”®å›¾åƒåŒºåŸŸï¼Œå¢å¼ºäº†æ¨¡å‹çš„é€æ˜åº¦ã€‚</li>
<li>æœ¬ç ”ç©¶åˆ†æäº†å¤šç§å…ˆè¿›CNNæ¨¡å‹åœ¨å·´æ°æ¶‚ç‰‡å›¾åƒåˆ†æä¸­çš„è¡¨ç°ï¼Œæ¢è®¨äº†è´Ÿè¿ç§»å­¦ä¹ çš„å½±å“ï¼Œå¹¶ç ”ç©¶äº†æ­£ç¡®å’Œé”™è¯¯åˆ†ç±»æ ·æœ¬çš„åƒç´ å¼ºåº¦æ¨¡å¼ã€‚</li>
<li>S-Netæ¨¡å‹ç»“åˆäº†é«˜å‡†ç¡®æ€§ã€è®¡ç®—è½»é‡æ€§å’Œæ¨ç†é€Ÿåº¦å¿«çš„ä¼˜åŠ¿ï¼Œé€‚åˆç”¨äºå®æ—¶å’Œèµ„æºå—é™çš„åº”ç”¨åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16250">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16250v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.16250v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="ENSAM-an-efficient-foundation-model-for-interactive-segmentation-of-3D-medical-images"><a href="#ENSAM-an-efficient-foundation-model-for-interactive-segmentation-of-3D-medical-images" class="headerlink" title="ENSAM: an efficient foundation model for interactive segmentation of 3D   medical images"></a>ENSAM: an efficient foundation model for interactive segmentation of 3D   medical images</h2><p><strong>Authors:Elias Stenhede, Agnar Martin BjÃ¸rnstad, Arian Ranjbar</strong></p>
<p>We present ENSAM (Equivariant, Normalized, Segment Anything Model), a lightweight and promptable model for universal 3D medical image segmentation. ENSAM combines a SegResNet-based encoder with a prompt encoder and mask decoder in a U-Net-style architecture, using latent cross-attention, relative positional encoding, normalized attention, and the Muon optimizer for training. ENSAM is designed to achieve good performance under limited data and computational budgets, and is trained from scratch on under 5,000 volumes from multiple modalities (CT, MRI, PET, ultrasound, microscopy) on a single 32 GB GPU in 6 hours. As part of the CVPR 2025 Foundation Models for Interactive 3D Biomedical Image Segmentation Challenge, ENSAM was evaluated on hidden test set with multimodal 3D medical images, obtaining a DSC AUC of 2.404, NSD AUC of 2.266, final DSC of 0.627, and final NSD of 0.597, outperforming two previously published baseline models (VISTA3D, SAM-Med3D) and matching the third (SegVol), surpassing its performance in final DSC but trailing behind in the other three metrics. In the coreset track of the challenge, ENSAM ranks 5th of 10 overall and best among the approaches not utilizing pretrained weights. Ablation studies confirm that our use of relative positional encodings and the Muon optimizer each substantially speed up convergence and improve segmentation quality. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ENSAMï¼ˆç­‰ä»·ã€å½’ä¸€åŒ–ã€åˆ†å‰²ä»»ä½•æ¨¡å‹ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé€šç”¨3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„è½»ä¾¿ä¸”å¯æç¤ºçš„æ¨¡å‹ã€‚ENSAMç»“åˆäº†åŸºäºSegResNetçš„ç¼–ç å™¨ã€æç¤ºç¼–ç å™¨å’Œæ©è†œè§£ç å™¨ï¼Œé‡‡ç”¨U-Neté£æ ¼çš„æ¶æ„ï¼Œä½¿ç”¨æ½œåœ¨äº¤å‰æ³¨æ„åŠ›ã€ç›¸å¯¹ä½ç½®ç¼–ç ã€å½’ä¸€åŒ–æ³¨æ„åŠ›å’ŒMuonä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒã€‚ENSAMæ—¨åœ¨æœ‰é™çš„æ•°æ®å’Œè®¡ç®—é¢„ç®—ä¸‹å®ç°è‰¯å¥½çš„æ€§èƒ½ï¼Œåœ¨å•ä¸ª32GB GPUä¸Šï¼Œä½¿ç”¨ä¸åˆ°5000ä¸ªæ¥è‡ªå¤šç§æ¨¡æ€ï¼ˆCTã€MRIã€PETã€è¶…å£°ã€æ˜¾å¾®é•œï¼‰çš„ä½“ç§¯æ•°æ®è¿›è¡Œä»å¤´è®­ç»ƒï¼Œä»…éœ€6å°æ—¶ã€‚ä½œä¸ºCVPR 2025äº¤äº’å¼3Dç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²æŒ‘æˆ˜èµ›çš„åŸºç¡€æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼ŒENSAMåœ¨å…·æœ‰å¤šæ¨¡æ€3DåŒ»å­¦å›¾åƒçš„éšè—æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè·å¾—äº†DSC AUC 2.404ã€NSD AUC 2.266ã€æœ€ç»ˆDSC 0.627å’Œæœ€ç»ˆNSD 0.597çš„æˆç»©ï¼Œä¼˜äºä¹‹å‰å‘è¡¨çš„ä¸¤ä¸ªåŸºçº¿æ¨¡å‹ï¼ˆVISTA3Dã€SAM-Med3Dï¼‰å¹¶åŒ¹é…äº†ç¬¬ä¸‰åï¼ˆSegVolï¼‰åœ¨æœ€ç»ˆDSCä¸Šçš„è¡¨ç°ï¼Œä½†åœ¨å…¶ä»–ä¸‰ä¸ªæŒ‡æ ‡ä¸Šç¨é€Šä¸€ç­¹ã€‚åœ¨æŒ‘æˆ˜çš„æ ¸å¿ƒé›†èµ›é“ä¸­ï¼ŒENSAMåœ¨10ä¸ªæ¨¡å‹ä¸­æ’åç¬¬5ï¼Œä¸”åœ¨æœªä½¿ç”¨é¢„è®­ç»ƒæƒé‡çš„æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ã€‚æ¶ˆèç ”ç©¶è¯å®ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„ç›¸å¯¹ä½ç½®ç¼–ç å’ŒMuonä¼˜åŒ–å™¨å„è‡ªæ˜¾è‘—åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦å¹¶æé«˜äº†åˆ†å‰²è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15874v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ENSAMæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºé€šç”¨3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„è½»ä¾¿ã€å¿«é€Ÿå“åº”çš„æ¨¡å‹ã€‚ENSAMç»“åˆSegResNetç¼–ç å™¨ã€æç¤ºç¼–ç å™¨å’Œæ©è†œè§£ç å™¨ï¼Œé‡‡ç”¨U-Neté£æ ¼çš„æ¶æ„ï¼Œå¹¶åˆ©ç”¨æ½œåœ¨äº¤å‰æ³¨æ„åŠ›ã€ç›¸å¯¹ä½ç½®ç¼–ç ã€å½’ä¸€åŒ–æ³¨æ„åŠ›å’ŒMuonä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒã€‚ENSAMæ—¨åœ¨å®ç°åœ¨æœ‰é™æ•°æ®å’Œè®¡ç®—é¢„ç®—ä¸‹å®ç°è‰¯å¥½æ€§èƒ½ï¼Œåœ¨å•ä¸ª32GB GPUä¸Šï¼Œä½¿ç”¨å¤šç§æ¨¡æ€ï¼ˆCTã€MRIã€PETã€è¶…å£°ã€æ˜¾å¾®é•œï¼‰åœ¨ä¸åˆ°5,000ä¸ªä½“ç§¯çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒåªéœ€6å°æ—¶ã€‚åœ¨CVPR 2025äº¤äº’å¼3Dç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²æŒ‘æˆ˜çš„åŸºç¡€æ¨¡å‹è¯„ä¼°ä¸­ï¼ŒENSAMåœ¨éšè—æµ‹è¯•é›†ä¸Šè¿›è¡Œå¤šæ¨¡æ€3DåŒ»å­¦å›¾åƒè¯„ä¼°ï¼Œè·å¾—äº†DSC AUCä¸º2.404ç­‰è¯„ä»·æŒ‡æ ‡ï¼Œç›¸è¾ƒäºå…ˆå‰å‘è¡¨çš„ä¸¤ä¸ªåŸºçº¿æ¨¡å‹ï¼ˆVISTA3Dã€SAM-Med3Dï¼‰è¡¨ç°æ›´ä½³ï¼Œå¹¶åŒ¹é…äº†ç¬¬ä¸‰åSegVolçš„æ€§èƒ½ï¼Œåœ¨æœ€ç»ˆDSCä¸Šè¡¨ç°è¶…è¶ŠSegVolä½†åœ¨å…¶ä»–ä¸‰ä¸ªæŒ‡æ ‡ä¸Šç¨é€Šä¸€ç­¹ã€‚åœ¨æŒ‘æˆ˜çš„æ ¸å¿ƒé›†èµ›é“ä¸­ï¼ŒENSAMä½åˆ—ç¬¬äº”åã€‚æ¶ˆèç ”ç©¶è¯å®ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„ç›¸å¯¹ä½ç½®ç¼–ç å’ŒMuonä¼˜åŒ–å™¨åˆ†åˆ«æ˜¾è‘—åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦å¹¶æé«˜äº†åˆ†å‰²è´¨é‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ENSAMæ˜¯ä¸€ä¸ªç”¨äºé€šç”¨3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„è½»ä¾¿ã€å¿«é€Ÿå“åº”çš„æ¨¡å‹ã€‚</li>
<li>ENSAMç»“åˆå¤šç§æŠ€æœ¯ï¼ŒåŒ…æ‹¬SegResNetç¼–ç å™¨ã€æç¤ºç¼–ç å™¨ã€æ©è†œè§£ç å™¨ã€æ½œåœ¨äº¤å‰æ³¨æ„åŠ›ã€ç›¸å¯¹ä½ç½®ç¼–ç å’Œå½’ä¸€åŒ–æ³¨æ„åŠ›ã€‚</li>
<li>ENSAMåœ¨æœ‰é™æ•°æ®å’Œè®¡ç®—é¢„ç®—ä¸‹è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨CVPR 2025æŒ‘æˆ˜ä¸­ï¼ŒENSAMåœ¨éšè—æµ‹è¯•é›†ä¸Šè·å¾—äº†è‰¯å¥½çš„è¯„ä»·æŒ‡æ ‡ç»“æœï¼Œç›¸è¾ƒäºå…¶ä»–æ¨¡å‹æœ‰ä¼˜åŠ¿ä¹Ÿæœ‰åŠ£åŠ¿ã€‚</li>
<li>ENSAMåœ¨æŒ‘æˆ˜çš„æ ¸å¿ƒé›†èµ›é“ä¸­æ’åç¬¬äº”ã€‚</li>
<li>æ¶ˆèç ”ç©¶è¯å®ç›¸å¯¹ä½ç½®ç¼–ç å’ŒMuonä¼˜åŒ–å™¨å¯¹æ¨¡å‹æ€§èƒ½æœ‰ç§¯æå½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15874">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15874v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15874v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15874v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Uncertainty-Gated-Deformable-Network-for-Breast-Tumor-Segmentation-in-MR-Images"><a href="#Uncertainty-Gated-Deformable-Network-for-Breast-Tumor-Segmentation-in-MR-Images" class="headerlink" title="Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR   Images"></a>Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR   Images</h2><p><strong>Authors:Yue Zhang, Jiahua Dong, Chengtao Peng, Qiuli Wang, Dan Song, Guiduo Duan</strong></p>
<p>Accurate segmentation of breast tumors in magnetic resonance images (MRI) is essential for breast cancer diagnosis, yet existing methods face challenges in capturing irregular tumor shapes and effectively integrating local and global features. To address these limitations, we propose an uncertainty-gated deformable network to leverage the complementary information from CNN and Transformers. Specifically, we incorporates deformable feature modeling into both convolution and attention modules, enabling adaptive receptive fields for irregular tumor contours. We also design an Uncertainty-Gated Enhancing Module (U-GEM) to selectively exchange complementary features between CNN and Transformer based on pixel-wise uncertainty, enhancing both local and global representations. Additionally, a Boundary-sensitive Deep Supervision Loss is introduced to further improve tumor boundary delineation. Comprehensive experiments on two clinical breast MRI datasets demonstrate that our method achieves superior segmentation performance compared with state-of-the-art methods, highlighting its clinical potential for accurate breast tumor delineation. </p>
<blockquote>
<p>åœ¨ç£å…±æŒ¯å›¾åƒï¼ˆMRIï¼‰ä¸­å¯¹ä¹³è…ºç™Œè‚¿ç˜¤è¿›è¡Œç²¾ç¡®åˆ†å‰²å¯¹äºä¹³è…ºç™Œè¯Šæ–­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨æ•æ‰ä¸è§„åˆ™è‚¿ç˜¤å½¢çŠ¶ä»¥åŠæœ‰æ•ˆåœ°æ•´åˆå±€éƒ¨å’Œå…¨å±€ç‰¹å¾æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸ç¡®å®šæ€§é—¨æ§å¯å˜å½¢ç½‘ç»œï¼Œä»¥åˆ©ç”¨CNNå’ŒTransformerçš„äº’è¡¥ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å¯å˜å½¢ç‰¹å¾å»ºæ¨¡èå…¥å·ç§¯å’Œæ³¨æ„åŠ›æ¨¡å—ï¼Œä¸ºä¸è§„åˆ™è‚¿ç˜¤è½®å»“æä¾›è‡ªé€‚åº”æ„Ÿå—é‡ã€‚æˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ä¸ªä¸ç¡®å®šæ€§é—¨æ§å¢å¼ºæ¨¡å—ï¼ˆU-GEMï¼‰ï¼Œè¯¥æ¨¡å—æ ¹æ®åƒç´ çº§ä¸ç¡®å®šæ€§æœ‰é€‰æ‹©åœ°äº¤æ¢CNNå’ŒTransformerä¹‹é—´çš„äº’è¡¥ç‰¹å¾ï¼Œå¢å¼ºäº†å±€éƒ¨å’Œå…¨å±€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§è¾¹ç•Œæ•æ„Ÿæ·±åº¦ç›‘ç£æŸå¤±ï¼Œä»¥è¿›ä¸€æ­¥æ”¹å–„è‚¿ç˜¤è¾¹ç•Œçš„å‹¾å‹’ã€‚åœ¨ä¸¤ä¸ªä¸´åºŠä¹³è…ºç™ŒMRIæ•°æ®é›†ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€æ–°æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨åˆ†å‰²æ€§èƒ½ä¸Šå–å¾—äº†ä¼˜åŠ¿ï¼Œçªæ˜¾äº†å…¶åœ¨å‡†ç¡®æç»˜ä¹³è…ºç™Œè‚¿ç˜¤æ–¹é¢çš„ä¸´åºŠæ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15758v1">PDF</a> 5 pages, 2 figures</p>
<p><strong>Summary</strong><br>åŒ»å­¦ç£å…±æŒ¯æˆåƒä¸­ä¹³è…ºç™Œè‚¿ç˜¤çš„ç²¾ç¡®åˆ†å‰²å¯¹è¯Šæ–­è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´æ•æ‰è‚¿ç˜¤ä¸è§„åˆ™å½¢çŠ¶å’Œæœ‰æ•ˆæ•´åˆå±€éƒ¨ä¸å…¨å±€ç‰¹å¾çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§ä¸ç¡®å®šæ€§é—¨æ§å¯å˜å½¢ç½‘ç»œï¼Œç»“åˆå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒTransformerçš„äº’è¡¥ä¿¡æ¯ã€‚é€šè¿‡å¼•å…¥å¯å˜å½¢ç‰¹å¾å»ºæ¨¡å’Œä¸ç¡®å®šæ€§é—¨æ§å¢å¼ºæ¨¡å—ï¼ˆU-GEMï¼‰ï¼Œè¯¥ç½‘ç»œå¯è‡ªé€‚åº”åœ°å¤„ç†ä¸è§„åˆ™è‚¿ç˜¤è¾¹ç•Œï¼ŒåŒæ—¶å¢å¼ºå±€éƒ¨å’Œå…¨å±€ç‰¹å¾è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†è¾¹ç•Œæ•æ„Ÿæ·±åº¦ç›‘ç£æŸå¤±ï¼Œä»¥è¿›ä¸€æ­¥æé«˜è‚¿ç˜¤è¾¹ç•Œçš„æç»˜æ•ˆæœã€‚åœ¨å¤šä¸ªä¸´åºŠä¹³è…ºMRIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºå…¶ä»–å‰æ²¿æŠ€æœ¯ï¼Œå…·æœ‰æ›´å‡ºè‰²çš„åˆ†å‰²æ€§èƒ½ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å‡†ç¡®æç»˜ä¹³è…ºç™Œè‚¿ç˜¤æ–¹é¢çš„ä¸´åºŠæ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¹³è…ºç™Œè¯Šæ–­ä¸­ï¼ŒMRIå›¾åƒä¸­è‚¿ç˜¤çš„ç²¾ç¡®åˆ†å‰²éå¸¸é‡è¦ã€‚</li>
<li>ç°æœ‰åˆ†å‰²æ–¹æ³•åœ¨å¤„ç†ä¸è§„åˆ™è‚¿ç˜¤å½¢çŠ¶å’Œæ•´åˆå±€éƒ¨ä¸å…¨å±€ç‰¹å¾æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä¸ç¡®å®šæ€§é—¨æ§å¯å˜å½¢ç½‘ç»œï¼Œç»“åˆCNNå’ŒTransformerçš„ä¼˜åŠ¿ã€‚</li>
<li>é€šè¿‡å¯å˜å½¢ç‰¹å¾å»ºæ¨¡ï¼Œç½‘ç»œèƒ½è‡ªé€‚åº”å¤„ç†ä¸è§„åˆ™è‚¿ç˜¤è¾¹ç•Œã€‚</li>
<li>U-GEMæ¨¡å—å¯é€‰æ‹©æ€§äº¤æ¢CNNå’ŒTransformerä¹‹é—´çš„äº’è¡¥ç‰¹å¾ï¼ŒåŸºäºåƒç´ çº§ä¸ç¡®å®šæ€§ã€‚</li>
<li>å¼•å…¥è¾¹ç•Œæ•æ„Ÿæ·±åº¦ç›‘ç£æŸå¤±ï¼Œæ”¹å–„è‚¿ç˜¤è¾¹ç•Œæç»˜æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15758">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15758v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15758v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15758v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15758v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15758v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="pFedSAM-Personalized-Federated-Learning-of-Segment-Anything-Model-for-Medical-Image-Segmentation"><a href="#pFedSAM-Personalized-Federated-Learning-of-Segment-Anything-Model-for-Medical-Image-Segmentation" class="headerlink" title="pFedSAM: Personalized Federated Learning of Segment Anything Model for   Medical Image Segmentation"></a>pFedSAM: Personalized Federated Learning of Segment Anything Model for   Medical Image Segmentation</h2><p><strong>Authors:Tong Wang, Xingyue Zhao, Linghao Zhuang, Haoyu Zhao, Jiayi Yin, Yuyang He, Gang Yu, Bo Lin</strong></p>
<p>Medical image segmentation is crucial for computer-aided diagnosis, yet privacy constraints hinder data sharing across institutions. Federated learning addresses this limitation, but existing approaches often rely on lightweight architectures that struggle with complex, heterogeneous data. Recently, the Segment Anything Model (SAM) has shown outstanding segmentation capabilities; however, its massive encoder poses significant challenges in federated settings. In this work, we present the first personalized federated SAM framework tailored for heterogeneous data scenarios in medical image segmentation. Our framework integrates two key innovations: (1) a personalized strategy that aggregates only the global parameters to capture cross-client commonalities while retaining the designed L-MoE (Localized Mixture-of-Experts) component to preserve domain-specific features; and (2) a decoupled global-local fine-tuning mechanism that leverages a teacher-student paradigm via knowledge distillation to bridge the gap between the global shared model and the personalized local models, thereby mitigating overgeneralization. Extensive experiments on two public datasets validate that our approach significantly improves segmentation performance, achieves robust cross-domain adaptation, and reduces communication overhead. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹è®¡ç®—æœºè¾…åŠ©è¯Šæ–­è‡³å…³é‡è¦ï¼Œä½†éšç§çº¦æŸé˜»ç¢äº†æœºæ„é—´çš„æ•°æ®å…±äº«ã€‚è”åˆå­¦ä¹ è§£å†³äº†è¿™ä¸€é™åˆ¶ï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤„ç†å¤æ‚ã€å¼‚æ„æ•°æ®èƒ½åŠ›ä¸è¶³çš„è½»å‹æ¶æ„ã€‚æœ€è¿‘ï¼ŒSegment Anything Modelï¼ˆSAMï¼‰è¡¨ç°å‡ºäº†å‡ºè‰²çš„åˆ†å‰²èƒ½åŠ›ï¼›ç„¶è€Œï¼Œå…¶åºå¤§çš„ç¼–ç å™¨åœ¨è”åˆè®¾ç½®ä¸­æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡æ¨å‡ºäº†é’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å¼‚æ„æ•°æ®åœºæ™¯çš„ä¸ªæ€§åŒ–è”é‚¦SAMæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ¡†æ¶é›†æˆäº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ä¸ªæ€§åŒ–ç­–ç•¥ï¼Œåªèšåˆå…¨å±€å‚æ•°ä»¥æ•è·è·¨å®¢æˆ·ç«¯çš„å…±æ€§ï¼ŒåŒæ—¶ä¿ç•™è®¾è®¡çš„L-MoEï¼ˆå±€éƒ¨æ··åˆä¸“å®¶ï¼‰ç»„ä»¶ä»¥ä¿æŒé¢†åŸŸç‰¹å®šç‰¹å¾ï¼›ï¼ˆ2ï¼‰è§£è€¦çš„å…¨å±€-å±€éƒ¨å¾®è°ƒæœºåˆ¶ï¼Œåˆ©ç”¨æ•™å¸ˆ-å­¦ç”ŸèŒƒå¼é€šè¿‡çŸ¥è¯†è’¸é¦æ¥ç¼©å°å…¨å±€å…±äº«æ¨¡å‹å’Œä¸ªæ€§åŒ–æœ¬åœ°æ¨¡å‹ä¹‹é—´çš„å·®è·ï¼Œä»è€Œç¼“è§£è¿‡åº¦æ³›åŒ–ã€‚åœ¨ä¸¤ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†åˆ†å‰²æ€§èƒ½ï¼Œå®ç°äº†ç¨³å¥çš„è·¨åŸŸé€‚åº”ï¼Œå¹¶é™ä½äº†é€šä¿¡å¼€é”€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15638v1">PDF</a> 5 pages</p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹äºè®¡ç®—æœºè¾…åŠ©è¯Šæ–­è‡³å…³é‡è¦ï¼Œä½†éšç§çº¦æŸé™åˆ¶äº†è·¨æœºæ„çš„æ•°æ®å…±äº«ã€‚è”é‚¦å­¦ä¹ è§£å†³äº†è¿™ä¸€å±€é™æ€§ï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤„ç†å¤æ‚ã€å¼‚æ„æ•°æ®æ–¹é¢çš„è½»å‹æ¶æ„ã€‚æœ€è¿‘ï¼ŒSegment Anything Modelï¼ˆSAMï¼‰å±•ç°å‡ºå‡ºè‰²çš„åˆ†å‰²èƒ½åŠ›ï¼Œä½†å…¶åºå¤§çš„ç¼–ç å™¨åœ¨è”é‚¦è®¾ç½®ä¸­æ„æˆæŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶é¦–æ¬¡æå‡ºé’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å¼‚æ„æ•°æ®åœºæ™¯çš„ä¸ªæ€§åŒ–è”é‚¦SAMæ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆä¸¤é¡¹å…³é”®åˆ›æ–°ï¼šä¸€æ˜¯ä»…èšåˆå…¨å±€å‚æ•°çš„ä¸ªæ€§åŒ–ç­–ç•¥ï¼Œä»¥æ•æ‰è·¨å®¢æˆ·ç«¯çš„å…±æ€§å¹¶ä¿ç•™è®¾è®¡çš„L-MoEï¼ˆå±€éƒ¨æ··åˆä¸“å®¶ï¼‰ç»„ä»¶ä»¥ä¿ç•™é¢†åŸŸç‰¹å®šç‰¹å¾ï¼›äºŒæ˜¯é‡‡ç”¨è§£è€¦çš„å…¨å±€-å±€éƒ¨å¾®è°ƒæœºåˆ¶ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦çš„æ•™å¸ˆ-å­¦ç”ŸèŒƒå¼ç¼©å°å…¨å±€å…±äº«æ¨¡å‹å’Œä¸ªæ€§åŒ–æœ¬åœ°æ¨¡å‹ä¹‹é—´çš„å·®è·ï¼Œä»è€Œç¼“è§£è¿‡åº¦æ³›åŒ–é—®é¢˜ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜åˆ†å‰²æ€§èƒ½ï¼Œå®ç°ç¨³å¥çš„è·¨åŸŸé€‚åº”ï¼Œå¹¶å‡å°‘é€šä¿¡å¼€é”€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²åœ¨è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ä¸­çš„é‡è¦æ€§ä»¥åŠéšç§çº¦æŸå¯¹æ•°æ®å…±äº«çš„å½±å“ã€‚</li>
<li>è”é‚¦å­¦ä¹ ä¸ºè§£å†³è·¨æœºæ„æ•°æ®å…±äº«é—®é¢˜æä¾›äº†ä¸€ç§è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ã€å¼‚æ„æ•°æ®æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>Segment Anything Modelï¼ˆSAMï¼‰åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„å‡ºè‰²è¡¨ç°åŠå…¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>ä¸ªæ€§åŒ–è”é‚¦SAMæ¡†æ¶çš„æå‡ºï¼Œé’ˆå¯¹å¼‚æ„æ•°æ®åœºæ™¯è¿›è¡Œå®šåˆ¶ã€‚</li>
<li>æ¡†æ¶ä¸­ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šä¸ªæ€§åŒ–ç­–ç•¥ä¸è§£è€¦çš„å…¨å±€-å±€éƒ¨å¾®è°ƒæœºåˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15638">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15638v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15638v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15638v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15638v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.15638v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="VocSegMRI-Multimodal-Learning-for-Precise-Vocal-Tract-Segmentation-in-Real-time-MRI"><a href="#VocSegMRI-Multimodal-Learning-for-Precise-Vocal-Tract-Segmentation-in-Real-time-MRI" class="headerlink" title="VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in   Real-time MRI"></a>VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in   Real-time MRI</h2><p><strong>Authors:Daiqi Liu, TomÃ¡s Arias-Vergara, Johannes Enk, Fangxu Xing, Maureen Stone, Jerry L. Prince, Jana Hutter, Andreas Maier, Jonghye Woo, Paula Andrea PÃ©rez-Toro</strong></p>
<p>Accurately segmenting articulatory structures in real-time magnetic resonance imaging (rtMRI) remains challenging, as most existing methods rely almost entirely on visual cues. Yet synchronized acoustic and phonological signals provide complementary context that can enrich visual information and improve precision. In this paper, we introduce VocSegMRI, a multimodal framework that integrates video, audio, and phonological inputs through cross-attention fusion for dynamic feature alignment. To further enhance cross-modal representation, we incorporate a contrastive learning objective that improves segmentation performance even when the audio modality is unavailable at inference. Evaluated on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance (HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines. Ablation studies confirm the contributions of cross-attention and contrastive learning to segmentation precision and robustness. These results highlight the value of integrative multimodal modeling for accurate vocal tract analysis. </p>
<blockquote>
<p>å®æ—¶ç£å…±æŒ¯æˆåƒï¼ˆrtMRIï¼‰ä¸­ç²¾ç¡®åˆ†å‰²å‘éŸ³ç»“æ„ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºå¤§å¤šæ•°ç°æœ‰æ–¹æ³•å‡ ä¹å®Œå…¨ä¾èµ–äºè§†è§‰çº¿ç´¢ã€‚ç„¶è€Œï¼ŒåŒæ­¥çš„å£°å­¦å’Œè¯­éŸ³ä¿¡å·æä¾›äº†ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯ä»¥ä¸°å¯Œè§†è§‰ä¿¡æ¯å¹¶æé«˜ç²¾åº¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†VocSegMRIï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ¨¡å¼æ¡†æ¶ï¼Œé€šè¿‡è·¨æ³¨æ„èåˆæ•´åˆè§†é¢‘ã€éŸ³é¢‘å’Œè¯­éŸ³è¾“å…¥ï¼Œä»¥å®ç°åŠ¨æ€ç‰¹å¾å¯¹é½ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºè·¨æ¨¡å¼è¡¨ç¤ºï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¯¹æ¯”å­¦ä¹ ç›®æ ‡ï¼Œå³ä½¿åœ¨æ¨ç†é˜¶æ®µéŸ³é¢‘æ¨¡å¼ä¸å¯ç”¨çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æé«˜åˆ†å‰²æ€§èƒ½ã€‚åœ¨USC-75 rtMRIæ•°æ®é›†çš„ä¸€ä¸ªå­é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒDiceå¾—åˆ†ä¸º0.95ï¼Œ95%ç™¾åˆ†ä½Hausdorffè·ç¦»ï¼ˆHD_95ï¼‰ä¸º4.20æ¯«ç±³ï¼Œè¶…è¿‡äº†å•æ¨¡æ€å’Œå¤šæ¨¡æ€åŸºçº¿ã€‚æ¶ˆèç ”ç©¶è¯å®äº†è·¨æ³¨æ„åŠ›å’Œå¯¹æ¯”å­¦ä¹ å¯¹åˆ†å‰²ç²¾åº¦å’Œç¨³å¥æ€§çš„è´¡çŒ®ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æ•´åˆå¤šæ¨¡å¼å»ºæ¨¡åœ¨å‡†ç¡®åˆ†æå£°å¸¦ç»“æ„ä¸­çš„é‡è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13767v2">PDF</a> Preprint submitted to ICASSP</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€æ¡†æ¶VocSegMRIï¼Œå®ƒç»“åˆäº†è§†é¢‘ã€éŸ³é¢‘å’Œè¯­éŸ³å­¦è¾“å…¥ï¼Œé€šè¿‡è·¨æ³¨æ„åŠ›èåˆå®ç°åŠ¨æ€ç‰¹å¾å¯¹é½ï¼Œä»¥æé«˜å®æ—¶ç£å…±æŒ¯æˆåƒï¼ˆrtMRIï¼‰ä¸­å¯¹å‘éŸ³ç»“æ„çš„å‡†ç¡®åˆ†å‰²ã€‚è¯¥æ¡†æ¶ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ¥æé«˜åˆ†å‰²æ€§èƒ½ï¼Œç”šè‡³åœ¨éŸ³é¢‘æ¨¡å¼ä¸å¯ç”¨çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°ä¼˜è¶Šè¡¨ç°ã€‚åœ¨USC-75 rtMRIæ•°æ®é›†çš„ä¸€ä¸ªå­é›†ä¸Šè¯„ä¼°ï¼Œè¯¥æ–¹æ³•å®ç°äº†æœ€é«˜æ°´å¹³çš„æ€§èƒ½ï¼ŒDiceå¾—åˆ†ä¸º0.95ï¼ŒHausdorff Distanceï¼ˆHD_95ï¼‰çš„95thç™¾åˆ†ä½æ•°ä¸º4.20æ¯«ç±³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VocSegMRIæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¡†æ¶ï¼Œç»“åˆäº†è§†é¢‘ã€éŸ³é¢‘å’Œè¯­éŸ³å­¦è¾“å…¥ã€‚</li>
<li>é€šè¿‡è·¨æ³¨æ„åŠ›èåˆå®ç°åŠ¨æ€ç‰¹å¾å¯¹é½ï¼Œä»¥æé«˜rtMRIä¸­å‘éŸ³ç»“æ„çš„åˆ†å‰²å‡†ç¡®æ€§ã€‚</li>
<li>ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ¥æé«˜åˆ†å‰²æ€§èƒ½ï¼Œå³ä½¿åœ¨éŸ³é¢‘æ¨¡å¼ä¸å¯ç”¨çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ä¿æŒä¼˜è¶Šè¡¨ç°ã€‚</li>
<li>åœ¨USC-75 rtMRIæ•°æ®é›†çš„ä¸€ä¸ªå­é›†ä¸Šè¯„ä¼°ï¼Œè¯¥æ–¹æ³•å®ç°äº†æœ€é«˜æ°´å¹³çš„æ€§èƒ½ã€‚</li>
<li>Diceå¾—åˆ†ä¸º0.95ï¼Œæ˜¾ç¤ºå‡ºé«˜ç²¾ç¡®åº¦ã€‚</li>
<li>Hausdorff Distanceï¼ˆHD_95ï¼‰çš„95thç™¾åˆ†ä½æ•°ä¸º4.20æ¯«ç±³ï¼Œè¡¨æ˜åˆ†å‰²ç»“æœçš„è¾¹ç•Œå®šä½å‡†ç¡®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.13767v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.13767v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.13767v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.13767v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="PPORLD-EDNetLDCT-A-Proximal-Policy-Optimization-Based-Reinforcement-Learning-Framework-for-Adaptive-Low-Dose-CT-Denoising"><a href="#PPORLD-EDNetLDCT-A-Proximal-Policy-Optimization-Based-Reinforcement-Learning-Framework-for-Adaptive-Low-Dose-CT-Denoising" class="headerlink" title="PPORLD-EDNetLDCT: A Proximal Policy Optimization-Based Reinforcement   Learning Framework for Adaptive Low-Dose CT Denoising"></a>PPORLD-EDNetLDCT: A Proximal Policy Optimization-Based Reinforcement   Learning Framework for Adaptive Low-Dose CT Denoising</h2><p><strong>Authors:Debopom Sutradhar, Ripon Kumar Debnath, Mohaimenul Azam Khan Raiaan, Yan Zhang, Reem E. Mohamed, Sami Azam</strong></p>
<p>Low-dose computed tomography (LDCT) is critical for minimizing radiation exposure, but it often leads to increased noise and reduced image quality. Traditional denoising methods, such as iterative optimization or supervised learning, often fail to preserve image quality. To address these challenges, we introduce PPORLD-EDNetLDCT, a reinforcement learning-based (RL) approach with Encoder-Decoder for LDCT. Our method utilizes a dynamic RL-based approach in which an advanced posterior policy optimization (PPO) algorithm is used to optimize denoising policies in real time, based on image quality feedback, trained via a custom gym environment. The experimental results on the low dose CT image and projection dataset demonstrate that the proposed PPORLD-EDNetLDCT model outperforms traditional denoising techniques and other DL-based methods, achieving a peak signal-to-noise ratio of 41.87, a structural similarity index measure of 0.9814 and a root mean squared error of 0.00236. Moreover, in NIH-AAPM-Mayo Clinic Low Dose CT Challenge dataset our method achieved a PSNR of 41.52, SSIM of 0.9723 and RMSE of 0.0051. Furthermore, we validated the quality of denoising using a classification task in the COVID-19 LDCT dataset, where the images processed by our method improved the classification accuracy to 94%, achieving 4% higher accuracy compared to denoising without RL-based denoising. </p>
<blockquote>
<p>ä½å‰‚é‡è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆLDCTï¼‰å¯¹äºæœ€å°åŒ–è¾å°„æš´éœ²è‡³å…³é‡è¦ï¼Œä½†é€šå¸¸ä¼šå¯¼è‡´å™ªå£°å¢åŠ å’Œå›¾åƒè´¨é‡ä¸‹é™ã€‚ä¼ ç»Ÿçš„é™å™ªæ–¹æ³•ï¼Œå¦‚è¿­ä»£ä¼˜åŒ–æˆ–ç›‘ç£å­¦ä¹ ï¼Œå¾€å¾€æ— æ³•ä¿æŒå›¾åƒè´¨é‡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†PPWORLD-EDNetLDCTï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„LDCTç¼–ç å™¨-è§£ç å™¨æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨åŠ¨æ€RLæ–¹æ³•ï¼Œä½¿ç”¨å…ˆè¿›çš„åéªŒç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ç®—æ³•ï¼Œæ ¹æ®å›¾åƒè´¨é‡åé¦ˆå®æ—¶ä¼˜åŒ–é™å™ªç­–ç•¥ï¼Œå¹¶é€šè¿‡è‡ªå®šä¹‰çš„gymç¯å¢ƒè¿›è¡Œè®­ç»ƒã€‚åœ¨ä½å‰‚é‡CTå›¾åƒå’ŒæŠ•å½±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„PPWORLD-EDNetLDCTæ¨¡å‹ä¼˜äºä¼ ç»Ÿé™å™ªæŠ€æœ¯å’Œå…¶ä»–æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œè¾¾åˆ°å³°å€¼ä¿¡å™ªæ¯”41.87ï¼Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°æµ‹é‡å€¼ä¸º0.9814ï¼Œå‡æ–¹æ ¹è¯¯å·®ä¸º0.00236ã€‚æ­¤å¤–ï¼Œåœ¨NIH-AAPM-Mayo Clinicä½å‰‚é‡CTæŒ‘æˆ˜èµ›æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†PSNR 41.52ã€SSIM 0.9723å’ŒRMSE 0.0051ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨COVID-19 LDCTæ•°æ®é›†ä¸­é€šè¿‡åˆ†ç±»ä»»åŠ¡éªŒè¯äº†é™å™ªè´¨é‡ï¼Œä½¿ç”¨æˆ‘ä»¬æ–¹æ³•å¤„ç†çš„å›¾åƒæé«˜äº†åˆ†ç±»ç²¾åº¦è‡³94%ï¼Œä¸æœªä½¿ç”¨RLçš„é™å™ªç›¸æ¯”ï¼Œæé«˜äº†4%çš„å‡†ç¡®ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03185v2">PDF</a> 20 pages, 5 figures, 5 tables</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬ç ”ç©¶é‡‡ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•æ¥è§£å†³ä½å‰‚é‡è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆLDCTï¼‰ä¸­çš„å™ªå£°é—®é¢˜ï¼Œæå‡ºäº†PPWORLD-EDNetLDCTæ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨åŠ¨æ€RLç­–ç•¥ä¼˜åŒ–å»å™ªç­–ç•¥ï¼Œæ ¹æ®å›¾åƒè´¨é‡åé¦ˆå®æ—¶è°ƒæ•´ï¼Œå¹¶é€šè¿‡è‡ªå®šä¹‰çš„gymç¯å¢ƒè¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸è¾ƒäºä¼ ç»Ÿå»å™ªæŠ€æœ¯å’Œå…¶ä»–æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ–¹æ³•ï¼ŒPPWORLD-EDNetLDCTæ¨¡å‹åœ¨å™ªå£°æ¶ˆé™¤æ–¹é¢è¡¨ç°æ›´ä¼˜ç§€ï¼Œä¿¡å·å³°å€¼æ¯”è¾¾åˆ°41.87ï¼Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°æµ‹é‡å€¼ä¸º0.9814ï¼Œå‡æ–¹æ ¹è¯¯å·®ä¸º0.00236ã€‚åœ¨NIH-AAPM-Mayo Clinicä½å‰‚é‡CTæŒ‘æˆ˜æ•°æ®é›†ä¸Šï¼Œå…¶è¡¨ç°åŒæ ·å‡ºè‰²ã€‚æ­¤å¤–ï¼Œåœ¨COVID-19 LDCTæ•°æ®é›†ä¸Šè¿›è¡Œåˆ†ç±»ä»»åŠ¡éªŒè¯æ—¶ï¼Œä½¿ç”¨è¯¥æ–¹æ³•å¤„ç†çš„å›¾åƒåˆ†ç±»å‡†ç¡®ç‡æå‡è‡³94%ï¼Œç›¸è¾ƒäºéRLå»å™ªæ–¹æ³•æé«˜äº†4%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>PPWORLD-EDNetLDCTæ¨¡å‹é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è§£å†³LDCTä¸­çš„å™ªå£°é—®é¢˜ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨åŠ¨æ€RLç­–ç•¥ä¼˜åŒ–å»å™ªç­–ç•¥ï¼Œæ ¹æ®å›¾åƒè´¨é‡åé¦ˆå®æ—¶è°ƒæ•´ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹ç›¸è¾ƒäºä¼ ç»Ÿå»å™ªæŠ€æœ¯å’Œå…¶ä»–æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ–¹æ³•æœ‰æ›´å¥½çš„å»å™ªæ•ˆæœã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ¨¡å‹æé«˜äº†COVID-19 LDCTæ•°æ®é›†çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚</li>
<li>ä½¿ç”¨RLæ–¹æ³•åœ¨å»å™ªè¿‡ç¨‹ä¸­æœ‰åŠ©äºæé«˜å›¾åƒè´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03185">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.03185v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.03185v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_åŒ»å­¦å›¾åƒ/2509.03185v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/TTS/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_TTS/2509.18004v1/page_0_0.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  TMD-TTS A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for   Ãœ-Tsang, Amdo and Kham Speech Dataset Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-24\./crop_Diffusion Models/2509.16986v1/page_1_0.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  Seg4Diff Unveiling Open-Vocabulary Segmentation in Text-to-Image   Diffusion Transformers
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29739.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
