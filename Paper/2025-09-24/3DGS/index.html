<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  GeoSVR Taming Sparse Voxels for Geometrically Accurate Surface   Reconstruction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-e114d1803777fd50f2690e4b4ddcfdc2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426566&auth_key=1760426566-0-0-815ec6501a5f2baa65bf7830787b6480&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    77 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-24-æ›´æ–°"><a href="#2025-09-24-æ›´æ–°" class="headerlink" title="2025-09-24 æ›´æ–°"></a>2025-09-24 æ›´æ–°</h1><h2 id="GeoSVR-Taming-Sparse-Voxels-for-Geometrically-Accurate-Surface-Reconstruction"><a href="#GeoSVR-Taming-Sparse-Voxels-for-Geometrically-Accurate-Surface-Reconstruction" class="headerlink" title="GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface   Reconstruction"></a>GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface   Reconstruction</h2><p><strong>Authors:Jiahe Li, Jiawei Zhang, Youmin Zhang, Xiao Bai, Jin Zheng, Xiaohan Yu, Lin Gu</strong></p>
<p>Reconstructing accurate surfaces with radiance fields has achieved remarkable progress in recent years. However, prevailing approaches, primarily based on Gaussian Splatting, are increasingly constrained by representational bottlenecks. In this paper, we introduce GeoSVR, an explicit voxel-based framework that explores and extends the under-investigated potential of sparse voxels for achieving accurate, detailed, and complete surface reconstruction. As strengths, sparse voxels support preserving the coverage completeness and geometric clarity, while corresponding challenges also arise from absent scene constraints and locality in surface refinement. To ensure correct scene convergence, we first propose a Voxel-Uncertainty Depth Constraint that maximizes the effect of monocular depth cues while presenting a voxel-oriented uncertainty to avoid quality degradation, enabling effective and robust scene constraints yet preserving highly accurate geometries. Subsequently, Sparse Voxel Surface Regularization is designed to enhance geometric consistency for tiny voxels and facilitate the voxel-based formation of sharp and accurate surfaces. Extensive experiments demonstrate our superior performance compared to existing methods across diverse challenging scenarios, excelling in geometric accuracy, detail preservation, and reconstruction completeness while maintaining high efficiency. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Fictionarry/GeoSVR">https://github.com/Fictionarry/GeoSVR</a>. </p>
<blockquote>
<p>é€šè¿‡è¾å°„åœºé‡å»ºç²¾ç¡®è¡¨é¢è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç›®å‰æµè¡Œçš„æ–¹æ³•ä¸»è¦åŸºäºé«˜æ–¯æ‹¼è´´ï¼Œè¶Šæ¥è¶Šå—åˆ°è¡¨ç¤ºç“¶é¢ˆçš„é™åˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†GeoSVRï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ˜¾å¼çš„ä½“ç´ æ¡†æ¶ï¼Œæ¢ç´¢å’Œæ‰©å±•äº†ç¨€ç–ä½“ç´ å°šæœªç ”ç©¶çš„æ½œåŠ›ï¼Œä»¥å®ç°å‡†ç¡®ã€è¯¦ç»†å’Œå®Œæ•´çš„è¡¨é¢é‡å»ºã€‚ç¨€ç–ä½“ç´ çš„ä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿä¿æŒè¦†ç›–çš„å®Œæ•´æ€§å’Œå‡ ä½•æ¸…æ™°åº¦ï¼Œè€Œç›¸åº”çš„æŒ‘æˆ˜ä¹Ÿæ¥è‡ªäºåœºæ™¯çº¦æŸçš„ç¼ºå¤±å’Œè¡¨é¢ç»†åŒ–ä¸­çš„å±€éƒ¨æ€§ã€‚ä¸ºäº†ç¡®ä¿æ­£ç¡®çš„åœºæ™¯æ”¶æ•›ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§ä½“ç´ ä¸ç¡®å®šæ€§æ·±åº¦çº¦æŸï¼Œæœ€å¤§é™åº¦åœ°åˆ©ç”¨å•çœ¼æ·±åº¦çº¿ç´¢ï¼ŒåŒæ—¶å‘ˆç°ä½“ç´ å®šå‘çš„ä¸ç¡®å®šæ€§ï¼Œä»¥é¿å…è´¨é‡ä¸‹é™ï¼Œä»è€Œå®ç°æœ‰æ•ˆå’Œç¨³å¥çš„åœºæ™¯çº¦æŸï¼ŒåŒæ—¶ä¿æŒé«˜åº¦å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶ã€‚éšåï¼Œè®¾è®¡äº†ç¨€ç–ä½“ç´ è¡¨é¢æ­£åˆ™åŒ–ï¼Œä»¥æé«˜å¾®å°ä½“ç´ çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œä¿ƒè¿›åŸºäºä½“ç´ çš„å°–é”å’Œç²¾ç¡®è¡¨é¢çš„å½¢æˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­å…·æœ‰å“è¶Šçš„æ€§èƒ½ï¼Œåœ¨å‡ ä½•ç²¾åº¦ã€ç»†èŠ‚ä¿ç•™å’Œé‡å»ºå®Œæ•´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ•ˆç‡ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Fictionarry/GeoSVR%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Fictionarry/GeoSVRæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18090v1">PDF</a> Accepted at NeurIPS 2025 (Spotlight). Project page:   <a target="_blank" rel="noopener" href="https://fictionarry.github.io/GeoSVR-project/">https://fictionarry.github.io/GeoSVR-project/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå°„çº¿åœºçš„è¡¨é¢é‡å»ºå·²ç»å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å½“å‰æ–¹æ³•ä¸»è¦åŸºäºé«˜æ–¯æ¶‚æ–‘æŠ€æœ¯ï¼Œå­˜åœ¨è¡¨è¾¾ç“¶é¢ˆã€‚æœ¬æ–‡å¼•å…¥GeoSVRï¼Œä¸€ä¸ªæ˜ç¡®çš„ä½“ç´ åŸºæ¡†æ¶ï¼Œæ¢ç´¢å¹¶æ‰©å±•äº†ç¨€ç–ä½“ç´ åœ¨å®ç°ç²¾ç¡®ã€ç»†è‡´å’Œå®Œæ•´çš„è¡¨é¢é‡å»ºæ–¹é¢çš„æ½œåŠ›ã€‚ç¨€ç–ä½“ç´ èƒ½å¤Ÿä¿æŒè¦†ç›–å®Œæ•´æ€§å’Œå‡ ä½•æ¸…æ™°åº¦ï¼ŒåŒæ—¶é¢ä¸´åœºæ™¯çº¦æŸç¼ºå¤±å’Œè¡¨é¢ç»†åŒ–å±€éƒ¨æ€§ç­‰æŒ‘æˆ˜ã€‚ä¸ºç¡®ä¿æ­£ç¡®çš„åœºæ™¯æ”¶æ•›ï¼Œæœ¬æ–‡é¦–å…ˆæå‡ºä½“ç´ ä¸ç¡®å®šæ€§æ·±åº¦çº¦æŸï¼Œæœ€å¤§åŒ–å•ç›®æ·±åº¦çº¿ç´¢çš„å½±å“ï¼ŒåŒæ—¶æå‡ºé¢å‘ä½“ç´ çš„ä¸ç¡®å®šæ€§ä»¥é¿å…è´¨é‡ä¸‹é™ï¼Œå®ç°æœ‰æ•ˆä¸”ç¨³å¥çš„åœºæ™¯çº¦æŸï¼ŒåŒæ—¶ä¿æŒé«˜åº¦ç²¾ç¡®çš„å‡ ä½•ã€‚éšåè®¾è®¡ç¨€ç–ä½“ç´ è¡¨é¢æ­£åˆ™åŒ–ï¼Œä»¥æé«˜å¾®å°ä½“ç´ å‡ ä½•ä¸€è‡´æ€§ï¼Œä¿ƒè¿›åŸºäºä½“ç´ çš„å°–é”å’Œç²¾ç¡®è¡¨é¢å½¢æˆã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æŒ‘æˆ˜åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œåœ¨å‡ ä½•ç²¾åº¦ã€ç»†èŠ‚ä¿ç•™å’Œé‡å»ºå®Œæ•´æ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GeoSVRæ˜¯ä¸€ä¸ªåŸºäºä½“ç´ çš„æ–¹æ³•ï¼Œç”¨äºè¡¨é¢é‡å»ºï¼Œæ—¨åœ¨è§£å†³å½“å‰æ–¹æ³•çš„è¡¨è¾¾ç“¶é¢ˆé—®é¢˜ã€‚</li>
<li>ç¨€ç–ä½“ç´ åœ¨è¡¨é¢é‡å»ºä¸­å…·æœ‰ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿä¿æŒè¦†ç›–å®Œæ•´æ€§å’Œå‡ ä½•æ¸…æ™°åº¦ã€‚</li>
<li>ä½“ç´ ä¸ç¡®å®šæ€§æ·±åº¦çº¦æŸæ–¹æ³•ç”¨äºç¡®ä¿åœºæ™¯çš„æ­£ç¡®æ”¶æ•›ï¼ŒåŒæ—¶ä¿æŒå‡ ä½•çš„é«˜ç²¾åº¦ã€‚</li>
<li>æå‡ºçš„ç¨€ç–ä½“ç´ è¡¨é¢æ­£åˆ™åŒ–æŠ€æœ¯å¯æé«˜å¾®å°ä½“ç´ çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œå½¢æˆå°–é”å’Œç²¾ç¡®çš„è¡¨é¢ã€‚</li>
<li>å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒGeoSVRåœ¨å‡ ä½•ç²¾åº¦ã€ç»†èŠ‚ä¿ç•™å’Œé‡å»ºå®Œæ•´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>GeoSVRæ–¹æ³•å…·æœ‰é«˜æ•ˆç‡ï¼Œé€‚ç”¨äºå¤šç§æŒ‘æˆ˜åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18090">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e9874405109723a224d1d317a3c3eeb4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426573&auth_key=1760426573-0-0-a05b7461a2b17038a9668930a8f47b6d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1f34f0013aef80ad15ea603ef67df016~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426580&auth_key=1760426580-0-0-ea71758b1ce7a43bf411dd4a2783fdf6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d044a5dec7de361a932da83a4cbb7737~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426587&auth_key=1760426587-0-0-9ac1a3e6adcc3566f469c1b3862066d3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GaussianPSL-A-novel-framework-based-on-Gaussian-Splatting-for-exploring-the-Pareto-frontier-in-multi-criteria-optimization"><a href="#GaussianPSL-A-novel-framework-based-on-Gaussian-Splatting-for-exploring-the-Pareto-frontier-in-multi-criteria-optimization" class="headerlink" title="GaussianPSL: A novel framework based on Gaussian Splatting for exploring   the Pareto frontier in multi-criteria optimization"></a>GaussianPSL: A novel framework based on Gaussian Splatting for exploring   the Pareto frontier in multi-criteria optimization</h2><p><strong>Authors:Phuong Mai Dinh, Van-Nam Huynh</strong></p>
<p>Multi-objective optimization (MOO) is essential for solving complex real-world problems involving multiple conflicting objectives. However, many practical applications - including engineering design, autonomous systems, and machine learning - often yield non-convex, degenerate, or discontinuous Pareto frontiers, which involve traditional scalarization and Pareto Set Learning (PSL) methods that struggle to approximate accurately. Existing PSL approaches perform well on convex fronts but tend to fail in capturing the diversity and structure of irregular Pareto sets commonly observed in real-world scenarios. In this paper, we propose Gaussian-PSL, a novel framework that integrates Gaussian Splatting into PSL to address the challenges posed by non-convex Pareto frontiers. Our method dynamically partitions the preference vector space, enabling simple MLP networks to learn localized features within each region, which are then integrated by an additional MLP aggregator. This partition-aware strategy enhances both exploration and convergence, reduces sensi- tivity to initialization, and improves robustness against local optima. We first provide the mathematical formulation for controllable Pareto set learning using Gaussian Splat- ting. Then, we introduce the Gaussian-PSL architecture and evaluate its performance on synthetic and real-world multi-objective benchmarks. Experimental results demonstrate that our approach outperforms standard PSL models in learning irregular Pareto fronts while maintaining computational efficiency and model simplicity. This work offers a new direction for effective and scalable MOO under challenging frontier geometries. </p>
<blockquote>
<p>å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMOOï¼‰å¯¹äºè§£å†³æ¶‰åŠå¤šä¸ªç›¸äº’å†²çªç›®æ ‡çš„å¤æ‚ç°å®ä¸–ç•Œé—®é¢˜è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè®¸å¤šå®é™…åº”ç”¨ï¼ˆåŒ…æ‹¬å·¥ç¨‹è®¾è®¡ã€è‡ªä¸»ç³»ç»Ÿå’Œæœºå™¨å­¦ä¹ ï¼‰é€šå¸¸ä¼šäº§ç”Ÿéå‡¸ã€é€€åŒ–æˆ–é—´æ–­çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼Œè¿™äº›å‰æ²¿æ¶‰åŠåˆ°ä¼ ç»Ÿçš„æ ‡é‡åŒ–å’Œå¸•ç´¯æ‰˜é›†å­¦ä¹ ï¼ˆPSLï¼‰æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•åœ¨è¿‘ä¼¼æ—¶é‡åˆ°å›°éš¾ã€‚ç°æœ‰çš„PSLæ–¹æ³•åœ¨å‡¸å‰æ²¿ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ•æ‰ç°å®ä¸–ç•Œåœºæ™¯ä¸­å¸¸è§çš„ä¸è§„åˆ™å¸•ç´¯æ‰˜é›†çš„å¤šæ ·æ€§å’Œç»“æ„æ—¶å¾€å¾€å¤±è´¥ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†é«˜æ–¯-PSLï¼Œè¿™æ˜¯ä¸€ä¸ªå°†é«˜æ–¯æ¶‚æ•·é›†æˆåˆ°PSLä¸­çš„æ–°å‹æ¡†æ¶ï¼Œä»¥è§£å†³éå‡¸å¸•ç´¯æ‰˜å‰æ²¿æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŠ¨æ€åœ°åˆ’åˆ†åå¥½å‘é‡ç©ºé—´ï¼Œä½¿ç®€å•çš„MLPç½‘ç»œèƒ½å¤Ÿåœ¨æ¯ä¸ªåŒºåŸŸå†…å­¦ä¹ å±€éƒ¨ç‰¹å¾ï¼Œç„¶åç”±ä¸€ä¸ªé¢å¤–çš„MLPèšåˆå™¨è¿›è¡Œé›†æˆã€‚è¿™ç§åˆ†åŒºæ„ŸçŸ¥ç­–ç•¥æé«˜äº†æ¢ç´¢å’Œæ”¶æ•›èƒ½åŠ›ï¼Œå‡å°‘äº†å¯¹åˆå§‹åŒ–çš„æ•æ„Ÿæ€§ï¼Œå¹¶æé«˜äº†å¯¹æŠ—å±€éƒ¨æœ€ä¼˜çš„ç¨³å¥æ€§ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨é«˜æ–¯æ¶‚æ•·æä¾›å¯æ§å¸•ç´¯æ‰˜é›†å­¦ä¹ çš„æ•°å­¦å…¬å¼ã€‚ç„¶åï¼Œæˆ‘ä»¬ä»‹ç»é«˜æ–¯-PSLæ¶æ„ï¼Œå¹¶åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„å¤šç›®æ ‡åŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°å…¶æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å­¦ä¹ ä¸è§„åˆ™å¸•ç´¯æ‰˜å‰æ²¿æ–¹é¢ä¼˜äºæ ‡å‡†PSLæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡å’Œæ¨¡å‹ç®€å•æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºæœ‰æ•ˆå’Œå¯æ‰©å±•çš„MOOåœ¨å…·æœ‰æŒ‘æˆ˜çš„å‰æ²¿å‡ ä½•ç»“æ„ä¸­æä¾›äº†æ–°çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17889v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºGaussian-PSLçš„æ–°å‹æ¡†æ¶ï¼Œé›†æˆé«˜æ–¯åˆ†è£‚æŠ€æœ¯äºParetoé›†å­¦ä¹ æ–¹æ³•ä¸­ï¼Œä»¥è§£å†³éå‡¸Paretoå‰æ²¿æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ¨æ€åˆ’åˆ†åå¥½å‘é‡ç©ºé—´ï¼Œä½¿MLPç½‘ç»œèƒ½å¤Ÿåœ¨æ¯ä¸ªåŒºåŸŸå†…å­¦ä¹ å±€éƒ¨ç‰¹å¾ï¼Œå¹¶é€šè¿‡é¢å¤–çš„MLPèšåˆå™¨è¿›è¡Œé›†æˆã€‚æ­¤æ–¹æ³•æé«˜äº†æ¢ç´¢ä¸æ”¶æ•›èƒ½åŠ›ï¼Œå‡å°‘å¯¹åˆå§‹åŒ–çš„æ•æ„Ÿæ€§ï¼Œå¹¶å¢å¼ºäº†å¯¹å±€éƒ¨æœ€ä¼˜è§£çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGaussian-PSLåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œå¤šç›®æ ‡åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œæœ‰æ•ˆå­¦ä¹ ä¸è§„åˆ™Paretoå‰æ²¿ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡å’Œæ¨¡å‹ç®€å•æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMOOï¼‰æ˜¯è§£å†³æ¶‰åŠå¤šä¸ªå†²çªç›®æ ‡å¤æ‚ç°å®ä¸–ç•Œé—®é¢˜çš„å…³é”®ã€‚</li>
<li>å®è·µä¸­å¸¸è§çš„éå‡¸ã€é€€åŒ–æˆ–æ–­ç»­çš„Paretoå‰æ²¿ç»™å‡†ç¡®è¿‘ä¼¼å¸¦æ¥æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰Paretoé›†å­¦ä¹ æ–¹æ³•ï¼ˆPSLï¼‰åœ¨å‡¸å‰æ²¿ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ•æ‰ç°å®ä¸–ç•Œä¸­å¸¸è§çš„ä¸è§„åˆ™Paretoé›†çš„å¤šæ ·æ€§å’Œç»“æ„æ—¶å¾€å¾€å¤±æ•ˆã€‚</li>
<li>Gaussian-PSLæ¡†æ¶é›†æˆäº†é«˜æ–¯åˆ†è£‚æŠ€æœ¯ï¼Œè§£å†³äº†éå‡¸Paretoå‰æ²¿çš„æŒ‘æˆ˜ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åŠ¨æ€åˆ’åˆ†åå¥½å‘é‡ç©ºé—´ï¼Œæé«˜äº†æ¢ç´¢ä¸æ”¶æ•›èƒ½åŠ›ã€‚</li>
<li>Gaussian-PSLåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œå¤šç›®æ ‡åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°å­¦ä¹ ä¸è§„åˆ™Paretoå‰æ²¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17889">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-fd3373637e32ef008f8bfa391440a8d3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426595&auth_key=1760426595-0-0-ec8ff57e3278f14e3f0d83811dfc015d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9914b3be2edd271f876c5459c8bea285~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426602&auth_key=1760426602-0-0-a86d248a895763ceec254462966f2dae&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c81ec2b1b72b763763f1777d06469462~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426609&auth_key=1760426609-0-0-0c2d291c58f1b858f69a067d1d424a41&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c7bb6c4c6c356f566b1ceec003e6262c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426615&auth_key=1760426615-0-0-641ccd02887880b2b98f0af4f0dd0476&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8201279aa39b12635beefe1f8936ee7f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426622&auth_key=1760426622-0-0-fc65fde44577ed7d4d7cef3f5544c344&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-baf10173ab9c087766b0b1451db59765~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426630&auth_key=1760426630-0-0-6197853e3da626ad7ecbefe24c948354&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ProDyG-Progressive-Dynamic-Scene-Reconstruction-via-Gaussian-Splatting-from-Monocular-Videos"><a href="#ProDyG-Progressive-Dynamic-Scene-Reconstruction-via-Gaussian-Splatting-from-Monocular-Videos" class="headerlink" title="ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting   from Monocular Videos"></a>ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting   from Monocular Videos</h2><p><strong>Authors:Shi Chen, Erik SandstrÃ¶m, Sandro Lombardi, Siyuan Li, Martin R. Oswald</strong></p>
<p>Achieving truly practical dynamic 3D reconstruction requires online operation, global pose and map consistency, detailed appearance modeling, and the flexibility to handle both RGB and RGB-D inputs. However, existing SLAM methods typically merely remove the dynamic parts or require RGB-D input, while offline methods are not scalable to long video sequences, and current transformer-based feedforward methods lack global consistency and appearance details. To this end, we achieve online dynamic scene reconstruction by disentangling the static and dynamic parts within a SLAM system. The poses are tracked robustly with a novel motion masking strategy, and dynamic parts are reconstructed leveraging a progressive adaptation of a Motion Scaffolds graph. Our method yields novel view renderings competitive to offline methods and achieves on-par tracking with state-of-the-art dynamic SLAM methods. </p>
<blockquote>
<p>å®ç°çœŸæ­£å®ç”¨çš„åŠ¨æ€3Dé‡å»ºéœ€è¦åœ¨çº¿æ“ä½œã€å…¨å±€å§¿æ€å’Œåœ°å›¾ä¸€è‡´æ€§ã€è¯¦ç»†çš„å¤–è§‚å»ºæ¨¡ï¼Œä»¥åŠå¤„ç†RGBå’ŒRGB-Dè¾“å…¥çš„çµæ´»æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„SLAMæ–¹æ³•é€šå¸¸åªæ˜¯å»é™¤äº†åŠ¨æ€éƒ¨åˆ†æˆ–è€…éœ€è¦RGB-Dè¾“å…¥ï¼Œè€Œç¦»çº¿æ–¹æ³•å¹¶ä¸é€‚ç”¨äºé•¿è§†é¢‘åºåˆ—ï¼Œç›®å‰åŸºäºtransformerçš„å‰é¦ˆæ–¹æ³•ç¼ºä¹å…¨å±€ä¸€è‡´æ€§å’Œå¤–è§‚ç»†èŠ‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨ä¸€ä¸ªSLAMç³»ç»Ÿå†…åˆ†ç¦»é™æ€å’ŒåŠ¨æ€éƒ¨åˆ†æ¥å®ç°åœ¨çº¿åŠ¨æ€åœºæ™¯é‡å»ºã€‚æˆ‘ä»¬é€šè¿‡ä¸€ç§æ–°é¢–çš„åŠ¨æ€æ©è†œç­–ç•¥æ¥ç¨³å¥åœ°è·Ÿè¸ªå§¿æ€ï¼Œå¹¶åˆ©ç”¨Motion Scaffoldså›¾çš„é€æ­¥é€‚åº”æ¥é‡å»ºåŠ¨æ€éƒ¨åˆ†ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„æ–°è§†è§’æ¸²æŸ“ä¸ç¦»çº¿æ–¹æ³•ç›¸å½“ï¼Œå¹¶ä¸”ä¸æœ€å…ˆè¿›çš„åŠ¨æ€SLAMæ–¹æ³•çš„è·Ÿè¸ªæ€§èƒ½ç›¸å½“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17864v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å®ç°çœŸæ­£å®ç”¨çš„åŠ¨æ€ä¸‰ç»´é‡å»ºæ‰€éœ€çš„æŠ€æœ¯è¦æ±‚ï¼ŒåŒ…æ‹¬åœ¨çº¿æ“ä½œã€å…¨å±€å§¿æ€å’Œåœ°å›¾ä¸€è‡´æ€§ã€è¯¦ç»†çš„å¤–è§‚å»ºæ¨¡ä»¥åŠå¤„ç†RGBå’ŒRGB-Dè¾“å…¥çš„çµæ´»æ€§ã€‚é’ˆå¯¹ç°æœ‰SLAMæ–¹æ³•çš„ä¸è¶³ï¼Œå¦‚ä»…å»é™¤åŠ¨æ€éƒ¨åˆ†æˆ–éœ€è¦RGB-Dè¾“å…¥ï¼Œä»¥åŠç¦»çº¿æ–¹æ³•ä¸é€‚ç”¨äºé•¿è§†é¢‘åºåˆ—å’Œå½“å‰åŸºäºå˜å‹å™¨çš„å‰é¦ˆæ–¹æ³•ç¼ºä¹å…¨å±€ä¸€è‡´æ€§å’Œå¤–è§‚ç»†èŠ‚çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨çº¿åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡SLAMç³»ç»Ÿå†…çš„é™æ€å’ŒåŠ¨æ€éƒ¨åˆ†åˆ†ç¦»æ¥å®ç°ï¼Œé‡‡ç”¨æ–°é¢–çš„è¿åŠ¨æ©æ¨¡ç­–ç•¥è¿›è¡Œå§¿æ€è·Ÿè¸ªï¼Œå¹¶åˆ©ç”¨Motion Scaffoldså›¾çš„é€æ­¥é€‚åº”è¿›è¡ŒåŠ¨æ€éƒ¨åˆ†çš„é‡å»ºã€‚è¯¥æ–¹æ³•ç”Ÿæˆçš„æ–°è§†è§’æ¸²æŸ“æ•ˆæœä¸ç¦»çº¿æ–¹æ³•ç›¸å½“ï¼Œå¹¶ä¸”ä¸æœ€æ–°çš„åŠ¨æ€SLAMæ–¹æ³•åœ¨è·Ÿè¸ªæ–¹é¢è¡¨ç°ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®ç°åŠ¨æ€ä¸‰ç»´é‡å»ºéœ€æ»¡è¶³åœ¨çº¿æ“ä½œã€å…¨å±€ä¸€è‡´æ€§ç­‰è¦æ±‚ã€‚</li>
<li>ç°æœ‰SLAMæ–¹æ³•å­˜åœ¨å±€é™ï¼Œå¦‚å¤„ç†åŠ¨æ€éƒ¨åˆ†çš„æ–¹å¼ä¸è¶³æˆ–ä¾èµ–RGB-Dè¾“å…¥ã€‚</li>
<li>ç¦»çº¿æ–¹æ³•ä¸é€‚åˆé•¿è§†é¢‘åºåˆ—ã€‚</li>
<li>åŸºäºå˜å‹å™¨çš„å‰é¦ˆæ–¹æ³•ç¼ºä¹å…¨å±€ä¸€è‡´æ€§å’Œå¤–è§‚ç»†èŠ‚ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§åœ¨çº¿åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œé€šè¿‡SLAMç³»ç»Ÿå†…é™æ€å’ŒåŠ¨æ€éƒ¨åˆ†çš„åˆ†ç¦»æ¥å®ç°ã€‚</li>
<li>é‡‡ç”¨æ–°é¢–çš„è¿åŠ¨æ©æ¨¡ç­–ç•¥è¿›è¡Œå§¿æ€è·Ÿè¸ªã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17864">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2160a027611e319a8e8ea84ee257cdb0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426638&auth_key=1760426638-0-0-4efb9ad64ba3fe09d3ff20f6b2edf17b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0a11ba26b4f4353768649dc59898fca0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426645&auth_key=1760426645-0-0-7ce360c61f1d6156a59c7c5e9ed8b4ef&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-53c917db3e87c850ee533c1391b761a4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426652&auth_key=1760426652-0-0-3bf22e4264b507003ff58a5eb4122b70&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-54e265dae114457cf7c6cd924b31d20f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426659&auth_key=1760426659-0-0-008f7ffedc5ae4bc621918ef07200505&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="From-Restoration-to-Reconstruction-Rethinking-3D-Gaussian-Splatting-for-Underwater-Scenes"><a href="#From-Restoration-to-Reconstruction-Rethinking-3D-Gaussian-Splatting-for-Underwater-Scenes" class="headerlink" title="From Restoration to Reconstruction: Rethinking 3D Gaussian Splatting for   Underwater Scenes"></a>From Restoration to Reconstruction: Rethinking 3D Gaussian Splatting for   Underwater Scenes</h2><p><strong>Authors:Guoxi Huang, Haoran Wang, Zipeng Qi, Wenjun Lu, David Bull, Nantheera Anantrasirichai</strong></p>
<p>Underwater image degradation poses significant challenges for 3D reconstruction, where simplified physical models often fail in complex scenes. We propose \textbf{R-Splatting}, a unified framework that bridges underwater image restoration (UIR) with 3D Gaussian Splatting (3DGS) to improve both rendering quality and geometric fidelity. Our method integrates multiple enhanced views produced by diverse UIR models into a single reconstruction pipeline. During inference, a lightweight illumination generator samples latent codes to support diverse yet coherent renderings, while a contrastive loss ensures disentangled and stable illumination representations. Furthermore, we propose \textit{Uncertainty-Aware Opacity Optimization (UAOO)}, which models opacity as a stochastic function to regularize training. This suppresses abrupt gradient responses triggered by illumination variation and mitigates overfitting to noisy or view-specific artifacts. Experiments on Seathru-NeRF and our new BlueCoral3D dataset demonstrate that R-Splatting outperforms strong baselines in both rendering quality and geometric accuracy. </p>
<blockquote>
<p>æ°´ä¸‹å›¾åƒé€€åŒ–ç»™ä¸‰ç»´é‡å»ºå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸­ï¼Œç®€åŒ–çš„ç‰©ç†æ¨¡å‹å¾€å¾€ä¼šå¤±æ•ˆã€‚æˆ‘ä»¬æå‡ºäº†<strong>R-Splatting</strong>æ¡†æ¶ï¼Œå®ƒå°†æ°´ä¸‹å›¾åƒæ¢å¤ï¼ˆUIRï¼‰ä¸ä¸‰ç»´é«˜æ–¯æ‹¼æ¥ï¼ˆ3DGSï¼‰ç›¸ç»“åˆï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å¤šç§ç”±ä¸åŒUIRæ¨¡å‹ç”Ÿæˆçš„æ•ˆæœå›¾é›†æˆåˆ°ä¸€ä¸ªå•ä¸€çš„ä¸‰ç»´é‡å»ºæµç¨‹ä¸­ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä¸€ä¸ªè½»é‡çº§çš„ç…§æ˜ç”Ÿæˆå™¨é‡‡æ ·æ½œåœ¨ä»£ç æ¥æ”¯æŒå¤šæ ·ä¸”è¿è´¯çš„æ¸²æŸ“ï¼ŒåŒæ—¶å¯¹æ¯”æŸå¤±ç¡®ä¿äº†ç…§æ˜è¡¨ç¤ºçš„åˆ†ç¦»å’Œç¨³å®šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ä¸é€æ˜åº¦ä¼˜åŒ–ï¼ˆUAOOï¼‰ï¼Œå°†ä¸é€æ˜åº¦å»ºæ¨¡ä¸ºéšæœºå‡½æ•°æ¥è¿›è¡Œè®­ç»ƒè§„èŒƒåŒ–ã€‚è¿™æŠ‘åˆ¶äº†ç”±å…‰ç…§å˜åŒ–è§¦å‘çš„çªç„¶æ¢¯åº¦å“åº”ï¼Œå¹¶å‡è½»äº†å¯¹å™ªå£°æˆ–ç‰¹å®šè§†è§’ä¼ªå½±çš„è¿‡æ‹Ÿåˆã€‚åœ¨Seathru-NeRFå’Œæˆ‘ä»¬æ–°çš„BlueCoral3Dæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒR-Splattingåœ¨æ¸²æŸ“è´¨é‡å’Œå‡ ä½•å‡†ç¡®æ€§æ–¹é¢éƒ½ä¼˜äºå¼ºå¤§çš„åŸºçº¿æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17789v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ°´ä¸‹å›¾åƒé€€åŒ–ç»™ä¸‰ç»´é‡å»ºå¸¦æ¥å¾ˆå¤§æŒ‘æˆ˜ï¼Œå¤æ‚çš„åœºæ™¯ä½¿å¾—ç®€åŒ–çš„ç‰©ç†æ¨¡å‹å¸¸å¸¸å¤±æ•ˆã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºR-Splattingçš„ç»Ÿä¸€æ¡†æ¶ï¼Œå®ƒå°†æ°´ä¸‹å›¾åƒæ¢å¤ï¼ˆUIRï¼‰ä¸ä¸‰ç»´é«˜æ–¯æ‹¼æ¥ï¼ˆ3DGSï¼‰ç›¸ç»“åˆï¼Œä»¥æé«˜æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ä¿çœŸåº¦ã€‚è¯¥æ–¹æ³•å°†å¤šç§å¢å¼ºè§†å›¾é›†æˆåˆ°å•ä¸ªé‡å»ºç®¡é“ä¸­ï¼Œé€šè¿‡è½»é‡çº§ç…§æ˜ç”Ÿæˆå™¨é‡‡æ ·æ½œåœ¨ä»£ç æ¥æ”¯æŒå¤šæ ·ä¸”è¿è´¯çš„æ¸²æŸ“ï¼Œå¯¹æ¯”æŸå¤±ç¡®ä¿ç…§æ˜è¡¨ç¤ºçš„å»è€¦åˆå’Œç¨³å®šã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¸é€æ˜åº¦ä¼˜åŒ–ï¼ˆUAOOï¼‰ï¼Œå°†ä¸é€æ˜åº¦å»ºæ¨¡ä¸ºéšæœºå‡½æ•°ä»¥è§„èŒƒè®­ç»ƒï¼Œè¿™æŠ‘åˆ¶äº†ç”±ç…§æ˜å˜åŒ–è§¦å‘çš„çªç„¶æ¢¯åº¦å“åº”ï¼Œå¹¶å‡è½»äº†å¯¹å™ªå£°æˆ–ç‰¹å®šè§†å›¾çš„è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒR-Splattingåœ¨æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ç²¾åº¦ä¸Šå‡ä¼˜äºå¼ºåŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°´ä¸‹å›¾åƒé€€åŒ–å¯¹ä¸‰ç»´é‡å»ºæ„æˆæŒ‘æˆ˜ï¼Œå¤æ‚åœºæ™¯ä½¿ç®€åŒ–ç‰©ç†æ¨¡å‹å¤±æ•ˆã€‚</li>
<li>æå‡ºR-Splattingæ¡†æ¶ï¼Œç»“åˆæ°´ä¸‹å›¾åƒæ¢å¤ï¼ˆUIRï¼‰ä¸ä¸‰ç»´é«˜æ–¯æ‹¼æ¥ï¼ˆ3DGSï¼‰ã€‚</li>
<li>é›†æˆå¤šä¸ªå¢å¼ºè§†å›¾åˆ°å•ä¸€é‡å»ºç®¡é“ä¸­ã€‚</li>
<li>ä½¿ç”¨è½»é‡çº§ç…§æ˜ç”Ÿæˆå™¨æ”¯æŒå¤šæ ·ä¸”è¿è´¯çš„æ¸²æŸ“ã€‚</li>
<li>å¯¹æ¯”æŸå¤±ç¡®ä¿ç…§æ˜è¡¨ç¤ºçš„å»è€¦åˆå’Œç¨³å®šæ€§ã€‚</li>
<li>å¼•å…¥ä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¸é€æ˜åº¦ä¼˜åŒ–ï¼ˆUAOOï¼‰ï¼Œä»¥æŠ‘åˆ¶ç”±ç…§æ˜å˜åŒ–å¼•å‘çš„çªç„¶æ¢¯åº¦å“åº”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17789">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-34dcba2c079581813048a436b72de836~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426688&auth_key=1760426688-0-0-3869e97a4ecf299b1764c8f73220cc7a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-691871dd5c713a4ac13e08a96b8c4766~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426717&auth_key=1760426717-0-0-39511c52ca36a5cdba089f6beb800d68&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-82a8a1092a2323863f90b6dd51976b92~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426745&auth_key=1760426745-0-0-e5fffb17ed19b1a51aca203ed859c4f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4a4c3c90d2d155638581dab0688caa63~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426752&auth_key=1760426752-0-0-c5a6395aaef952da94dbe86fa3bb42eb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c95bd1e4bebf5c7e04a36720590286b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426760&auth_key=1760426760-0-0-6e1c9d425f2616e4f80a0373e9b35312&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="EmbodiedSplat-Personalized-Real-to-Sim-to-Real-Navigation-with-Gaussian-Splats-from-a-Mobile-Device"><a href="#EmbodiedSplat-Personalized-Real-to-Sim-to-Real-Navigation-with-Gaussian-Splats-from-a-Mobile-Device" class="headerlink" title="EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian   Splats from a Mobile Device"></a>EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian   Splats from a Mobile Device</h2><p><strong>Authors:Gunjan Chhablani, Xiaomeng Ye, Muhammad Zubair Irshad, Zsolt Kira</strong></p>
<p>The field of Embodied AI predominantly relies on simulation for training and evaluation, often using either fully synthetic environments that lack photorealism or high-fidelity real-world reconstructions captured with expensive hardware. As a result, sim-to-real transfer remains a major challenge. In this paper, we introduce EmbodiedSplat, a novel approach that personalizes policy training by efficiently capturing the deployment environment and fine-tuning policies within the reconstructed scenes. Our method leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to bridge the gap between realistic scene capture and effective training environments. Using iPhone-captured deployment scenes, we reconstruct meshes via GS, enabling training in settings that closely approximate real-world conditions. We conduct a comprehensive analysis of training strategies, pre-training datasets, and mesh reconstruction techniques, evaluating their impact on sim-to-real predictivity in real-world scenarios. Experimental results demonstrate that agents fine-tuned with EmbodiedSplat outperform both zero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and synthetically generated datasets (HSSD), achieving absolute success rate improvements of 20% and 40% on real-world Image Navigation task. Moreover, our approach yields a high sim-vs-real correlation (0.87â€“0.97) for the reconstructed meshes, underscoring its effectiveness in adapting policies to diverse environments with minimal effort. Project page: <a target="_blank" rel="noopener" href="https://gchhablani.github.io/embodied-splat">https://gchhablani.github.io/embodied-splat</a> </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½å®ä½“åŒ–é¢†åŸŸä¸»è¦ä¾èµ–äºæ¨¡æ‹Ÿè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œé€šå¸¸ä½¿ç”¨ç¼ºä¹çœŸå®æ„Ÿçš„å…¨åˆæˆç¯å¢ƒæˆ–ä½¿ç”¨æ˜‚è´µçš„ç¡¬ä»¶æ•è·çš„é«˜ä¿çœŸç°å®ä¸–ç•Œé‡å»ºã€‚å› æ­¤ï¼Œæ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†EmbodiedSplatï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é«˜æ•ˆæ•è·éƒ¨ç½²ç¯å¢ƒå¹¶åœ¨é‡å»ºåœºæ™¯ä¸­å¯¹ç­–ç•¥è¿›è¡Œå¾®è°ƒæ¥ä¸ªæ€§åŒ–ç­–ç•¥è®­ç»ƒçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨ä¸‰ç»´é«˜æ–¯æº…ç—•ï¼ˆGSï¼‰å’Œæ –æ¯åœ°æ¨¡æ‹Ÿå™¨ï¼ˆHabitat-Simï¼‰æ¥å¼¥ç°å®åœºæ™¯æ•æ‰å’Œæœ‰æ•ˆè®­ç»ƒç¯å¢ƒä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬ä½¿ç”¨iPhoneæ•è·çš„éƒ¨ç½²åœºæ™¯ï¼Œé€šè¿‡GSé‡å»ºç½‘æ ¼ï¼Œä½¿å¾—åœ¨æ¥è¿‘çœŸå®ä¸–ç•Œæ¡ä»¶çš„è®¾ç½®ä¸­è¿›è¡ŒåŸ¹è®­æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å¯¹è®­ç»ƒç­–ç•¥ã€é¢„è®­ç»ƒæ•°æ®é›†å’Œç½‘æ ¼é‡å»ºæŠ€æœ¯è¿›è¡Œäº†ç»¼åˆåˆ†æï¼Œè¯„ä¼°äº†å®ƒä»¬åœ¨ç°å®åœºæ™¯ä¸­å¯¹æ¨¡æ‹Ÿåˆ°ç°å®çš„é¢„æµ‹èƒ½åŠ›çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨EmbodiedSplatè¿›è¡Œå¾®è°ƒçš„ä»£ç†åœ¨ç°å®ä¸–ç•Œå›¾åƒå¯¼èˆªä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºä»¥é›¶æ ·æœ¬æ–¹å¼é¢„è®­ç»ƒçš„åŸºå‡†æ¨¡å‹ï¼Œæ— è®ºæ˜¯å¤§è§„æ¨¡ç°å®ä¸–ç•Œæ•°æ®é›†ï¼ˆHM3Dï¼‰è¿˜æ˜¯åˆæˆæ•°æ®é›†ï¼ˆHSSDï¼‰ï¼Œç»å¯¹æˆåŠŸç‡åˆ†åˆ«æé«˜äº†20%å’Œ40%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹é‡å»ºç½‘æ ¼çš„æ¨¡æ‹Ÿä¸ç°å®çš„å…³è”åº¦è¾ƒé«˜ï¼ˆ0.87-0.97ï¼‰ï¼Œçªæ˜¾äº†å…¶åœ¨é€‚åº”å¤šç§ç¯å¢ƒå¹¶æœ€å°åŒ–åŠªåŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://gchhablani.github.io/embodied-splat">https://gchhablani.github.io/embodied-splat</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17430v1">PDF</a> 16 pages, 18 figures, paper accepted at ICCV, 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†EmbodiedSplatè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒä¸»è¦é€šè¿‡æ•æ‰éƒ¨ç½²ç¯å¢ƒå¹¶ç²¾ç»†åŒ–è°ƒæ•´ç­–ç•¥æ¥è§£å†³ä»¿çœŸåˆ°ç°å®è¿ç§»çš„æŒ‘æˆ˜ã€‚æ–¹æ³•ç»“åˆäº†ä¸‰ç»´é«˜æ–¯å¡«å……æŠ€æœ¯å’Œæ¨¡æ‹Ÿè½¯ä»¶Habitaæ¨¡æ‹Ÿå™¨æ¥ç¼©å‡çœŸå®åœºæ™¯æ•æ‰ä¸è®­ç»ƒç¯å¢ƒä¹‹é—´çš„é¸¿æ²Ÿã€‚ä½¿ç”¨iPhoneæ•æ‰çš„éƒ¨ç½²åœºæ™¯è¿›è¡Œç½‘æ ¼é‡å»ºï¼Œä½¿è®­ç»ƒç¯å¢ƒæ›´æ¥è¿‘çœŸå®ä¸–ç•Œæ¡ä»¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨EmbodiedSplatè¿›è¡Œå¾®è°ƒåçš„æ™ºèƒ½ä½“è¡¨ç°ä¼˜äºé¢„è®­ç»ƒçš„å¤§è§„æ¨¡ç°å®æ•°æ®é›†å’Œåˆæˆæ•°æ®é›†ä¸Šçš„é›¶èµ·ç‚¹åŸºå‡†æµ‹è¯•ï¼Œåœ¨çœŸå®ä¸–ç•Œå›¾åƒå¯¼èˆªä»»åŠ¡ä¸Šå–å¾—äº†é«˜è¾¾20%å’Œ40%çš„ç»å¯¹æˆåŠŸç‡æå‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ–¹æ³•çš„é‡å»ºç½‘æ ¼ä¸çœŸå®ä¸–ç•Œçš„ç›¸ä¼¼æ€§é«˜ï¼Œæ¨¡æ‹Ÿä¸ç°å®çš„ç›¸å…³æ€§è¾¾åˆ°0.87è‡³0.97ï¼Œè¯´æ˜å…¶åœ¨é€‚åº”ä¸åŒç¯å¢ƒæ–¹é¢å…·æœ‰é«˜æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EmbodiedSplatæ–¹æ³•é€šè¿‡æ•æ‰éƒ¨ç½²ç¯å¢ƒå¹¶ç²¾ç»†åŒ–è°ƒæ•´ç­–ç•¥æ¥è§£å†³ä»¿çœŸåˆ°ç°å®çš„è¿ç§»æŒ‘æˆ˜ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆä¸‰ç»´é«˜æ–¯å¡«å……æŠ€æœ¯å’Œæ¨¡æ‹Ÿè½¯ä»¶Habitaæ¨¡æ‹Ÿå™¨ï¼Œå®ç°çœŸå®åœºæ™¯æ•æ‰ä¸è®­ç»ƒç¯å¢ƒçš„æœ‰æ•ˆå¯¹æ¥ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨iPhoneæ•æ‰çš„éƒ¨ç½²åœºæ™¯è¿›è¡Œç½‘æ ¼é‡å»ºï¼Œæé«˜äº†è®­ç»ƒç¯å¢ƒçš„çœŸå®æ€§å’Œæœ‰æ•ˆæ€§ã€‚</li>
<li>å¯¹æ¯”å®éªŒæ˜¾ç¤ºï¼ŒEmbodiedSplatå¾®è°ƒåçš„æ™ºèƒ½ä½“è¡¨ç°ä¼˜äºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹ï¼Œåœ¨çœŸå®ä¸–ç•Œå›¾åƒå¯¼èˆªä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—æˆåŠŸã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰é«˜æ•ˆçš„ç­–ç•¥é€‚åº”æ€§ï¼Œèƒ½é€‚åº”å¤šç§ç¯å¢ƒå¹¶å¿«é€Ÿè°ƒæ•´ã€‚</li>
<li>é‡å»ºç½‘æ ¼ä¸çœŸå®ä¸–ç•Œçš„ç›¸ä¼¼æ€§é«˜ï¼Œæ¨¡æ‹Ÿä¸ç°å®çš„ç›¸å…³æ€§è¾¾åˆ°è¾ƒé«˜æ•°å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17430">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-35234055b4b0e6d76da1a8bb0e9ca3f1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426767&auth_key=1760426767-0-0-63a1a06f0707bb8d67a192ff4b5db560&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b884f6399ce1b4d179e260a58c79e304~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426775&auth_key=1760426775-0-0-a8f62b9b17d6068b8c40e6ea474d7bfe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-11f758a15307d54bd9e799151836f869~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426782&auth_key=1760426782-0-0-7f09a4bd985764a25b498a7a090bce73&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f18b57bac1e1ef3d71e774964df448f2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426789&auth_key=1760426789-0-0-adc605e4a60a79bc6660a40e5dd2f7d6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b8a6c602d7ec0706dbcf6f29b2c07aa1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426795&auth_key=1760426795-0-0-c73a101f46dcb3c72aaf92d630837848&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-62cfcbefc4801fb0a4af2f1a4f9ddfb6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426802&auth_key=1760426802-0-0-4882f4613f6c02064e615e4d7c0e61f0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="FGGS-LiDAR-Ultra-Fast-GPU-Accelerated-Simulation-from-General-3DGS-Models-to-LiDAR"><a href="#FGGS-LiDAR-Ultra-Fast-GPU-Accelerated-Simulation-from-General-3DGS-Models-to-LiDAR" class="headerlink" title="FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS   Models to LiDAR"></a>FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS   Models to LiDAR</h2><p><strong>Authors:Junzhe Wu, Yufei Jia, Yiyi Yan, Zhixing Chen, Tiao Tan, Zifan Wang, Guangyu Wang</strong></p>
<p>While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic rendering, its vast ecosystem of assets remains incompatible with high-performance LiDAR simulation, a critical tool for robotics and autonomous driving. We present \textbf{FGGS-LiDAR}, a framework that bridges this gap with a truly plug-and-play approach. Our method converts \textit{any} pretrained 3DGS model into a high-fidelity, watertight mesh without requiring LiDAR-specific supervision or architectural alterations. This conversion is achieved through a general pipeline of volumetric discretization and Truncated Signed Distance Field (TSDF) extraction. We pair this with a highly optimized, GPU-accelerated ray-casting module that simulates LiDAR returns at over 500 FPS. We validate our approach on indoor and outdoor scenes, demonstrating exceptional geometric fidelity; By enabling the direct reuse of 3DGS assets for geometrically accurate depth sensing, our framework extends their utility beyond visualization and unlocks new capabilities for scalable, multimodal simulation. Our open-source implementation is available at <a target="_blank" rel="noopener" href="https://github.com/TATP-233/FGGS-LiDAR">https://github.com/TATP-233/FGGS-LiDAR</a>. </p>
<blockquote>
<p>è™½ç„¶3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼ˆ3DGSï¼‰å·²ç»å½»åº•æ”¹å˜äº†ç…§ç‰‡çº§æ¸²æŸ“ï¼Œä½†å…¶åºå¤§çš„èµ„äº§ç”Ÿæ€ç³»ç»Ÿä»ç„¶ä¸é«˜æ€§èƒ½æ¿€å…‰é›·è¾¾æ¨¡æ‹Ÿä¸å…¼å®¹ï¼Œè¿™æ˜¯æœºå™¨äººæŠ€æœ¯å’Œè‡ªåŠ¨é©¾é©¶çš„é‡è¦å·¥å…·ã€‚æˆ‘ä»¬æ¨å‡ºäº†FGGS-LiDARæ¡†æ¶ï¼ŒçœŸæ­£å®ç°äº†å³æ’å³ç”¨ï¼Œå¼¥è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ä»»ä½•é¢„è®­ç»ƒçš„3DGSæ¨¡å‹è½¬æ¢ä¸ºé«˜ä¿çœŸã€æ— ç¼éš™ç½‘æ ¼ï¼Œæ— éœ€æ¿€å…‰é›·è¾¾ç‰¹å®šçš„ç›‘ç£æˆ–æ¶æ„æ”¹åŠ¨ã€‚è¿™ç§è½¬æ¢æ˜¯é€šè¿‡ä½“ç§¯ç¦»æ•£åŒ–å’Œæˆªæ–­æœ‰ç¬¦å·è·ç¦»åœºï¼ˆTSDFï¼‰æå–çš„ä¸€èˆ¬ç®¡é“æ¥å®ç°çš„ã€‚æˆ‘ä»¬å°†å…¶ä¸é«˜åº¦ä¼˜åŒ–ã€GPUåŠ é€Ÿçš„å…‰çº¿æŠ•å°„æ¨¡å—ç›¸ç»“åˆï¼Œæ¨¡æ‹Ÿæ¿€å…‰é›·è¾¾ä»¥è¶…è¿‡500å¸§æ¯ç§’çš„é€Ÿåº¦è¿”å›æ•°æ®ã€‚æˆ‘ä»¬åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å‡ºè‰²çš„å‡ ä½•ä¿çœŸåº¦ï¼›é€šè¿‡ä½¿3DGSèµ„äº§èƒ½å¤Ÿç›´æ¥ç”¨äºå‡ ä½•ç²¾ç¡®çš„æ·±åº¦æ„ŸçŸ¥ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å°†å…¶ç”¨é€”æ‰©å±•åˆ°äº†å¯è§†åŒ–ä¹‹å¤–ï¼Œå¹¶è§£é”äº†å¯æ‰©å±•ã€å¤šæ¨¡å¼æ¨¡æ‹Ÿçš„æ–°èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å¼€æºå®ç°å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/TATP-233/FGGS-LiDAR%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/TATP-233/FGGS-LiDARæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17390v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>3DGSæŠ€æœ¯åœ¨å®ç°é€¼çœŸçš„æ¸²æŸ“æ–¹é¢å–å¾—äº†é©å‘½æ€§çš„è¿›å±•ï¼Œä½†å…¶åºå¤§çš„èµ„äº§ç”Ÿæ€ç³»ç»Ÿä¸ç”¨äºæœºå™¨äººå’Œè‡ªåŠ¨é©¾é©¶çš„å…³é”®å·¥å…·â€”â€”é«˜æ€§èƒ½æ¿€å…‰é›·è¾¾ä»¿çœŸä¸å…¼å®¹ã€‚æœ¬æ–‡æå‡ºçš„FGGS-LiDARæ¡†æ¶é€šè¿‡çœŸæ­£çš„å³æ’å³ç”¨æ–¹æ³•è§£å†³äº†è¿™ä¸€å·®è·ã€‚è¯¥æ–¹æ³•å°†ä»»ä½•é¢„è®­ç»ƒçš„3DGSæ¨¡å‹è½¬æ¢ä¸ºé«˜ä¿çœŸã€æ— ç¼éš™ç½‘æ ¼ï¼Œæ— éœ€æ¿€å…‰é›·è¾¾ç‰¹å®šçš„ç›‘ç£æˆ–æ¶æ„æ”¹åŠ¨ã€‚è¯¥è½¬æ¢é€šè¿‡ä½“ç§¯ç¦»æ•£åŒ–å’Œæˆªæ–­æœ‰ç¬¦å·è·ç¦»åœºï¼ˆTSDFï¼‰æå–çš„ä¸€èˆ¬ç®¡é“å®ç°ã€‚é…åˆé«˜åº¦ä¼˜åŒ–ã€GPUåŠ é€Ÿçš„å…‰çº¿æŠ•å°„æ¨¡å—ï¼Œå¯åœ¨è¶…è¿‡500FPSçš„æƒ…å†µä¸‹æ¨¡æ‹Ÿæ¿€å…‰é›·è¾¾è¿”å›ã€‚åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯çš„éªŒè¯ä¸­ï¼Œæ˜¾ç¤ºå‡ºå“è¶Šçš„å‡ ä½•ä¿çœŸåº¦ï¼›é€šè¿‡ä½¿3DGSèµ„äº§èƒ½å¤Ÿç›´æ¥ç”¨äºå‡ ä½•ç²¾ç¡®çš„æ·±åº¦æ„ŸçŸ¥ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ‰©å±•äº†å®ƒä»¬çš„ç”¨é€”ï¼Œä¸ä»…é™äºå¯è§†åŒ–ï¼Œå¹¶å¼€å¯äº†å¯æ‰©å±•ã€å¤šæ¨¡å¼ä»¿çœŸçš„æ–°èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSæŠ€æœ¯åœ¨æ¸²æŸ“æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä½†åœ¨ä¸é«˜æ€§èƒ½æ¿€å…‰é›·è¾¾ä»¿çœŸé›†æˆæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>FGGS-LiDARæ¡†æ¶è§£å†³äº†è¿™ä¸€éš¾é¢˜ï¼Œå®ç°äº†é¢„è®­ç»ƒçš„3DGSæ¨¡å‹ä¸æ¿€å…‰é›·è¾¾ä»¿çœŸçš„æ— ç¼é›†æˆã€‚</li>
<li>FGGS-LiDARæ¡†æ¶é‡‡ç”¨é€šç”¨æ–¹æ³•è½¬æ¢æ¨¡å‹ï¼Œæ— éœ€ç‰¹å®šäºæ¿€å…‰é›·è¾¾çš„ç›‘ç£æˆ–ä¿®æ”¹æ¨¡å‹æ¶æ„ã€‚</li>
<li>é€šè¿‡ä½“ç§¯ç¦»æ•£åŒ–å’ŒTSDFæå–æŠ€æœ¯å®ç°æ¨¡å‹è½¬æ¢ã€‚</li>
<li>é«˜åº¦ä¼˜åŒ–çš„GPUåŠ é€Ÿå…‰çº¿æŠ•å°„æ¨¡å—ä¿è¯äº†å¿«é€Ÿçš„æ¿€å…‰é›·è¾¾æ¨¡æ‹Ÿæ€§èƒ½ã€‚</li>
<li>å®¤å†…å¤–éªŒè¯å±•ç¤ºäº†å…¶å‡ ä½•ä¿çœŸåº¦çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17390">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4cc7bc040494aa8e6f85d95cf05d63e5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426810&auth_key=1760426810-0-0-2830c5d635460529030266e89d6e1ba3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-519e90a95163c01da6c1c69c74e0b792~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426818&auth_key=1760426818-0-0-cc363ea87f372b2f8982cb010ae1b5df&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9a1e575d2fe3f89b00785fe6e50632bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426825&auth_key=1760426825-0-0-9cf64f8cb98425168fc8244ed42ff797&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-71d274e4d728e87053c15763e8925aab~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426833&auth_key=1760426833-0-0-8487c619c1fe48bfc338c60581a67d51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-042968646119727831b7c10bdde45e1e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426840&auth_key=1760426840-0-0-ba4b0f302e20298c43f984c38f0a7bf6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4e9a64e65a667e43f2366b21935576fc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426847&auth_key=1760426847-0-0-89b476791666fb5aa6f4efe25deb7eba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SPFSplatV2-Efficient-Self-Supervised-Pose-Free-3D-Gaussian-Splatting-from-Sparse-Views"><a href="#SPFSplatV2-Efficient-Self-Supervised-Pose-Free-3D-Gaussian-Splatting-from-Sparse-Views" class="headerlink" title="SPFSplatV2: Efficient Self-Supervised Pose-Free 3D Gaussian Splatting   from Sparse Views"></a>SPFSplatV2: Efficient Self-Supervised Pose-Free 3D Gaussian Splatting   from Sparse Views</h2><p><strong>Authors:Ranran Huang, Krystian Mikolajczyk</strong></p>
<p>We introduce SPFSplatV2, an efficient feed-forward framework for 3D Gaussian splatting from sparse multi-view images, requiring no ground-truth poses during training and inference. It employs a shared feature extraction backbone, enabling simultaneous prediction of 3D Gaussian primitives and camera poses in a canonical space from unposed inputs. A masked attention mechanism is introduced to efficiently estimate target poses during training, while a reprojection loss enforces pixel-aligned Gaussian primitives, providing stronger geometric constraints. We further demonstrate the compatibility of our training framework with different reconstruction architectures, resulting in two model variants. Remarkably, despite the absence of pose supervision, our method achieves state-of-the-art performance in both in-domain and out-of-domain novel view synthesis, even under extreme viewpoint changes and limited image overlap, and surpasses recent methods that rely on geometric supervision for relative pose estimation. By eliminating dependence on ground-truth poses, our method offers the scalability to leverage larger and more diverse datasets. Code and pretrained models will be available on our project page: <a target="_blank" rel="noopener" href="https://ranrhuang.github.io/spfsplatv2/">https://ranrhuang.github.io/spfsplatv2/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†SPFSplatV2ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å‰é¦ˆæ¡†æ¶ï¼Œç”¨äºä»ç¨€ç–çš„å¤šè§†è§’å›¾åƒè¿›è¡Œ3Dé«˜æ–¯å–·ç»˜ï¼Œå…¶åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦çœŸå®å§¿æ€ã€‚å®ƒé‡‡ç”¨å…±äº«ç‰¹å¾æå–ä¸»å¹²ï¼Œèƒ½å¤Ÿä»æ— å§¿æ€è¾“å…¥çš„å›¾åƒä¸­åŒæ—¶é¢„æµ‹3Dé«˜æ–¯åŸºæœ¬ä½“å’Œç›¸æœºåœ¨è§„èŒƒç©ºé—´ä¸­çš„å§¿æ€ã€‚å¼•å…¥äº†ä¸€ç§æ©æ¨¡æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆåœ°ä¼°è®¡ç›®æ ‡å§¿æ€ï¼Œè€Œé‡æŠ•å½±æŸå¤±åˆ™å¼ºåˆ¶å®æ–½åƒç´ å¯¹é½çš„é«˜æ–¯åŸºæœ¬ä½“ï¼Œæä¾›æ›´å¼ºçš„å‡ ä½•çº¦æŸã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯æ˜äº†æˆ‘ä»¬çš„è®­ç»ƒæ¡†æ¶ä¸ä¸åŒé‡å»ºæ¶æ„çš„å…¼å®¹æ€§ï¼Œä»è€Œäº§ç”Ÿäº†ä¸¤ç§æ¨¡å‹å˜ä½“ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æ²¡æœ‰å§¿æ€ç›‘ç£ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸŸå†…å’ŒåŸŸå¤–çš„æ–°è§†è§’åˆæˆæ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå³ä½¿åœ¨æç«¯è§†è§’å˜åŒ–å’Œå›¾åƒé‡å æœ‰é™çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œè€Œä¸”è¶…è¶Šäº†æœ€è¿‘ä¾èµ–å‡ ä½•ç›‘ç£è¿›è¡Œç›¸å¯¹å§¿æ€ä¼°è®¡çš„æ–¹æ³•ã€‚é€šè¿‡æ¶ˆé™¤å¯¹çœŸå®å§¿æ€çš„ä¾èµ–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åˆ©ç”¨æ›´å¤§å’Œæ›´å¤šæ ·çš„æ•°æ®é›†è¿›è¡Œæ‰©å±•ã€‚ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å°†å¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢è·å¾—ï¼š<a target="_blank" rel="noopener" href="https://ranrhuang.github.io/spfsplatv2/">https://ranrhuang.github.io/spfsplatv2/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17246v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>SPFSplatV2æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å‰é¦ˆæ¡†æ¶ï¼Œç”¨äºä»ç¨€ç–çš„å¤šè§†è§’å›¾åƒè¿›è¡Œ3Dé«˜æ–¯å–·æº…ã€‚å®ƒæ— éœ€åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä¾èµ–çœŸå®å§¿æ€ï¼Œå¹¶é‡‡ç”¨äº†å…±äº«ç‰¹å¾æå–ä¸»å¹²ï¼Œå¯ä»æ— å§¿æ€è¾“å…¥çš„å›¾åƒä¸­åŒæ—¶é¢„æµ‹3Dé«˜æ–¯åŸºæœ¬å½¢ä½“å’Œç›¸æœºåœ¨è§„èŒƒç©ºé—´ä¸­çš„å§¿æ€ã€‚å¼•å…¥çš„æ©è†œæ³¨æ„åŠ›æœºåˆ¶å¯æœ‰æ•ˆåœ°ä¼°è®¡ç›®æ ‡å§¿æ€çš„è®­ç»ƒè¿‡ç¨‹ï¼Œè€Œé‡æŠ•å½±æŸå¤±åˆ™ç¡®ä¿äº†åƒç´ å¯¹é½çš„é«˜æ–¯åŸºæœ¬å½¢ä½“ï¼Œæä¾›äº†æ›´å¼ºçš„å‡ ä½•çº¦æŸã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„è®­ç»ƒæ¡†æ¶ä¸ä¸åŒçš„é‡å»ºæ¶æ„çš„å…¼å®¹æ€§ï¼Œå¹¶æ¨å‡ºäº†ä¸¤æ¬¾æ¨¡å‹å˜ç§ã€‚å°½ç®¡æ²¡æœ‰å§¿æ€ç›‘ç£ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»èƒ½åœ¨åŸŸå†…å’ŒåŸŸå¤–çš„å…¨æ–°è§†è§’åˆæˆä¸­è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç”šè‡³åœ¨æç«¯è§†è§’å˜åŒ–å’Œå›¾åƒé‡å æœ‰é™çš„æƒ…å†µä¸‹ä¹Ÿè¶…è¶Šäº†è¿‘æœŸä¾èµ–å‡ ä½•ç›‘ç£è¿›è¡Œç›¸å¯¹å§¿æ€ä¼°è®¡çš„æ–¹æ³•ã€‚æ¶ˆé™¤å¯¹çœŸå®å§¿æ€çš„ä¾èµ–ï¼Œä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨æ›´å¤§å’Œæ›´å¤šæ ·çš„æ•°æ®é›†è¿›è¡Œæ‰©å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SPFSPlatV2æ˜¯ä¸€ä¸ªæ— éœ€çœŸå®å§¿æ€ç›‘ç£å’Œè®­ç»ƒçš„é«˜æ•ˆå‰é¦ˆæ¡†æ¶ï¼Œç”¨äºä»ç¨€ç–çš„å¤šè§†è§’å›¾åƒè¿›è¡Œ3Dé«˜æ–¯å–·æº…ã€‚</li>
<li>ä½¿ç”¨äº†å…±äº«ç‰¹å¾æå–ä¸»å¹²æŠ€æœ¯ï¼Œå…è®¸ä»éå®šä½è¾“å…¥ä¸­åŒæ—¶é¢„æµ‹3Dé«˜æ–¯åŸºæœ¬å½¢ä½“å’Œç›¸æœºå§¿æ€ã€‚</li>
<li>å¼•å…¥æ©è†œæ³¨æ„åŠ›æœºåˆ¶ä»¥é«˜æ•ˆä¼°è®¡ç›®æ ‡å§¿æ€è®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>é‡æŠ•å½±æŸå¤±ç¡®ä¿åƒç´ å¯¹é½çš„é«˜æ–¯åŸºæœ¬å½¢ä½“ï¼Œæä¾›æ›´å¼ºçš„å‡ ä½•çº¦æŸã€‚</li>
<li>è®­ç»ƒæ¡†æ¶å…¼å®¹ä¸åŒçš„é‡å»ºæ¶æ„ï¼Œæ¨å‡ºä¸¤æ¬¾æ¨¡å‹å˜ç§ã€‚</li>
<li>åœ¨æç«¯è§†è§’å˜åŒ–å’Œæœ‰é™å›¾åƒé‡å æ¡ä»¶ä¸‹ï¼Œè¯¥æ–¹æ³•åœ¨å…¨æ–°è§†è§’åˆæˆä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å¯¹å‡ ä½•ç›‘ç£ä¾èµ–çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17246">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c2c1fb487aac71f966bdb08836d28072~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426854&auth_key=1760426854-0-0-550d8c4ebeffa9f866bad49e80c02112&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8a69221296024e4854f71d361e9ddf4c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426864&auth_key=1760426864-0-0-032b03ca2816262594874d08cdcf9fc5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5c8eece601ff72c1107e81b13e75cfa3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426871&auth_key=1760426871-0-0-79f0fea0631abac85221f335bf030f11&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d323a82856c0e47c3128937f1eeb1cb2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426878&auth_key=1760426878-0-0-275387d2c79b854b245de5b15ad2376a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HyRF-Hybrid-Radiance-Fields-for-Memory-efficient-and-High-quality-Novel-View-Synthesis"><a href="#HyRF-Hybrid-Radiance-Fields-for-Memory-efficient-and-High-quality-Novel-View-Synthesis" class="headerlink" title="HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel   View Synthesis"></a>HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel   View Synthesis</h2><p><strong>Authors:Zipeng Wang, Dan Xu</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative to NeRF-based approaches, enabling real-time, high-quality novel view synthesis through explicit, optimizable 3D Gaussians. However, 3DGS suffers from significant memory overhead due to its reliance on per-Gaussian parameters to model view-dependent effects and anisotropic shapes. While recent works propose compressing 3DGS with neural fields, these methods struggle to capture high-frequency spatial variations in Gaussian properties, leading to degraded reconstruction of fine details. We present Hybrid Radiance Fields (HyRF), a novel scene representation that combines the strengths of explicit Gaussians and neural fields. HyRF decomposes the scene into (1) a compact set of explicit Gaussians storing only critical high-frequency parameters and (2) grid-based neural fields that predict remaining properties. To enhance representational capacity, we introduce a decoupled neural field architecture, separately modeling geometry (scale, opacity, rotation) and view-dependent color. Additionally, we propose a hybrid rendering scheme that composites Gaussian splatting with a neural field-predicted background, addressing limitations in distant scene representation. Experiments demonstrate that HyRF achieves state-of-the-art rendering quality while reducing model size by over 20 times compared to 3DGS and maintaining real-time performance. Our project page is available at <a target="_blank" rel="noopener" href="https://wzpscott.github.io/hyrf/">https://wzpscott.github.io/hyrf/</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œ3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰ä½œä¸ºä¸€ç§å¼ºå¤§çš„æ›¿ä»£NeRFçš„æ–¹æ³•è€Œå‡ºç°ï¼Œå®ƒé€šè¿‡æ˜ç¡®çš„ã€å¯ä¼˜åŒ–çš„3Dé«˜æ–¯å®ç°å®æ—¶é«˜è´¨é‡çš„æ–°è§†è§’åˆæˆã€‚ç„¶è€Œï¼Œç”±äº3DGSä¾èµ–äºé«˜æ–¯å‚æ•°æ¥æ¨¡æ‹Ÿè§†è§’ç›¸å…³çš„æ•ˆæœå’Œå„å‘å¼‚æ€§å½¢çŠ¶ï¼Œå› æ­¤å®ƒå­˜åœ¨è¾ƒå¤§çš„å†…å­˜å¼€é”€ã€‚è™½ç„¶æœ€è¿‘çš„å·¥ä½œæå‡ºä½¿ç”¨ç¥ç»ç½‘ç»œåœºå‹ç¼©3DGSï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ•è·é«˜æ–¯å±æ€§çš„é«˜é¢‘ç©ºé—´å˜åŒ–æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´ç²¾ç»†ç»†èŠ‚çš„é‡å»ºé€€åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†æ··åˆè¾å°„åœºï¼ˆHyRFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆæ˜¾å¼é«˜æ–¯å’Œç¥ç»ç½‘ç»œåœºä¼˜ç‚¹çš„æ–°å‹åœºæ™¯è¡¨ç¤ºæ–¹æ³•ã€‚HyRFå°†åœºæ™¯åˆ†è§£ä¸ºï¼ˆ1ï¼‰ä¸€ç»„ç´§å‡‘çš„æ˜¾å¼é«˜æ–¯ï¼Œåªå­˜å‚¨å…³é”®çš„é«˜é¢‘å‚æ•°ï¼Œï¼ˆ2ï¼‰åŸºäºç½‘æ ¼çš„ç¥ç»ç½‘ç»œåœºï¼Œç”¨äºé¢„æµ‹å…¶ä½™å±æ€§ã€‚ä¸ºäº†æé«˜è¡¨ç¤ºèƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†è§£è€¦ç¥ç»ç½‘ç»œåœºæ¶æ„ï¼Œè¯¥æ¶æ„åˆ†åˆ«æ¨¡æ‹Ÿå‡ ä½•ï¼ˆå°ºåº¦ã€ä¸é€æ˜åº¦ã€æ—‹è½¬ï¼‰å’Œè§†è§’ç›¸å…³çš„é¢œè‰²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ¸²æŸ“æ–¹æ¡ˆï¼Œå°†é«˜æ–¯å±•å¼€ä¸ç¥ç»ç½‘ç»œåœºé¢„æµ‹çš„èƒŒæ™¯è¿›è¡Œç»„åˆï¼Œè§£å†³äº†è¿œè·ç¦»åœºæ™¯è¡¨ç¤ºçš„å±€é™æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒHyRFè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œä¸3DGSç›¸æ¯”ï¼Œæ¨¡å‹å¤§å°å‡å°‘äº†20å€ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ€§èƒ½ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://wzpscott.github.io/hyrf/%E8%AE%BF%E9%97%AE%E3%80%82">https://wzpscott.github.io/hyrf/è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17083v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Hybrid Radiance Fieldsï¼ˆHyRFï¼‰æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯ç»“åˆäº†æ˜¾å¼é«˜æ–¯å’Œç¥ç»åœºçš„ä¼˜ç‚¹ï¼Œç”¨äºå®æ—¶é«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆã€‚é’ˆå¯¹ç°æœ‰æŠ€æœ¯çš„å†…å­˜å¼€é”€å¤§å’Œå¯¹é«˜é¢‘ç©ºé—´å˜åŒ–æ•æ‰èƒ½åŠ›æœ‰é™çš„é—®é¢˜ï¼ŒHyRFé€šè¿‡åˆ†è§£åœºæ™¯ã€é‡‡ç”¨ç´§å‡‘çš„é«˜æ–¯é›†å­˜å‚¨å…³é”®é«˜é¢‘å‚æ•°ä»¥åŠåŸºäºç½‘æ ¼çš„ç¥ç»ç½‘ç»œé¢„æµ‹å‰©ä½™å±æ€§ç­‰æ–¹æ³•è¿›è¡Œæ”¹è¿›ã€‚åŒæ—¶ï¼Œå¼•å…¥äº†å»è€¦åˆçš„ç¥ç»ç½‘ç»œæ¶æ„å’Œæ··åˆæ¸²æŸ“æ–¹æ¡ˆï¼Œæé«˜äº†è¡¨ç¤ºèƒ½åŠ›å’Œæ¸²æŸ“è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼ŒHyRFè¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆçš„æ¸²æŸ“è´¨é‡ï¼Œæ¨¡å‹å¤§å°è¾ƒ3DGSå‡å°‘äº†20å€ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæˆä¸ºä¸€ç§æ›¿ä»£NeRFçš„æ–¹æ³•ï¼Œå®ç°å®æ—¶é«˜è´¨é‡æ–°å‹è§†å›¾åˆæˆã€‚</li>
<li>3DGSå­˜åœ¨å†…å­˜å¼€é”€å¤§ï¼Œä¾èµ–é«˜æ–¯å‚æ•°å»ºæ¨¡è§†å›¾ç›¸å…³æ•ˆåº”å’Œå½¢çŠ¶é—®é¢˜ã€‚</li>
<li>æœ€è¿‘çš„å·¥ä½œå°è¯•ç”¨ç¥ç»ç½‘ç»œå‹ç¼©3DGSï¼Œä½†éš¾ä»¥æ•æ‰é«˜æ–¯å±æ€§çš„é«˜é¢‘ç©ºé—´å˜åŒ–ã€‚</li>
<li>æå‡ºHyRFæŠ€æœ¯ï¼Œç»“åˆæ˜¾å¼é«˜æ–¯å’Œç¥ç»åœºçš„ä¼˜ç‚¹ï¼Œè§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>HyRFå°†åœºæ™¯åˆ†è§£ä¸ºç´§å‡‘çš„é«˜æ–¯é›†å’ŒåŸºäºç½‘æ ¼çš„ç¥ç»ç½‘ç»œé¢„æµ‹å‰©ä½™å±æ€§ã€‚</li>
<li>å¼•å…¥å»è€¦åˆç¥ç»ç½‘ç»œæ¶æ„å’Œæ··åˆæ¸²æŸ“æ–¹æ¡ˆï¼Œæé«˜è¡¨ç¤ºèƒ½åŠ›å’Œæ¸²æŸ“è´¨é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17083">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5155924741ad3270c83af5debd89ddae~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426885&auth_key=1760426885-0-0-690f0cd13e845c09033ed291b3227970&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d02592ac4473bc388a274f9989394a3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426892&auth_key=1760426892-0-0-dab6caf63fac97a62da9b9e8c2e3dd5f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4a83be3a634fed56dd535ea757c0b253~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426899&auth_key=1760426899-0-0-55573d1778471d8e05ca30e4b8b49b06&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7a871bfd24a47a759cf52edeebb5c8d6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426906&auth_key=1760426906-0-0-6536a9207371846d906650dae99e4d5c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Efficient-3D-Scene-Reconstruction-and-Simulation-from-Sparse-Endoscopic-Views"><a href="#Efficient-3D-Scene-Reconstruction-and-Simulation-from-Sparse-Endoscopic-Views" class="headerlink" title="Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic   Views"></a>Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic   Views</h2><p><strong>Authors:Zhenya Yang</strong></p>
<p>Surgical simulation is essential for medical training, enabling practitioners to develop crucial skills in a risk-free environment while improving patient safety and surgical outcomes. However, conventional methods for building simulation environments are cumbersome, time-consuming, and difficult to scale, often resulting in poor details and unrealistic simulations. In this paper, we propose a Gaussian Splatting-based framework to directly reconstruct interactive surgical scenes from endoscopic data while ensuring efficiency, rendering quality, and realism. A key challenge in this data-driven simulation paradigm is the restricted movement of endoscopic cameras, which limits viewpoint diversity. As a result, the Gaussian Splatting representation overfits specific perspectives, leading to reduced geometric accuracy. To address this issue, we introduce a novel virtual camera-based regularization method that adaptively samples virtual viewpoints around the scene and incorporates them into the optimization process to mitigate overfitting. An effective depth-based regularization is applied to both real and virtual views to further refine the scene geometry. To enable fast deformation simulation, we propose a sparse control node-based Material Point Method, which integrates physical properties into the reconstructed scene while significantly reducing computational costs. Experimental results on representative surgical data demonstrate that our method can efficiently reconstruct and simulate surgical scenes from sparse endoscopic views. Notably, our method takes only a few minutes to reconstruct the surgical scene and is able to produce physically plausible deformations in real-time with user-defined interactions. </p>
<blockquote>
<p>æ‰‹æœ¯æ¨¡æ‹Ÿåœ¨åŒ»å­¦è®­ç»ƒä¸­è‡³å…³é‡è¦ï¼Œè®©å®è·µè€…åœ¨æ— é£é™©ç¯å¢ƒä¸­åŸ¹å…»å…³é”®æŠ€èƒ½ï¼ŒåŒæ—¶æé«˜æ‚£è€…å®‰å…¨æ€§å’Œæ‰‹æœ¯æ•ˆæœã€‚ç„¶è€Œï¼Œä¼ ç»Ÿå»ºç«‹æ¨¡æ‹Ÿç¯å¢ƒçš„æ–¹æ³•å¾ˆç¬¨æ‹™ï¼Œè€—æ—¶è€—åŠ›ï¼Œéš¾ä»¥æ‰©å±•ï¼Œå¾€å¾€å¯¼è‡´ç»†èŠ‚ä¸è¶³å’Œæ¨¡æ‹Ÿä¸çœŸå®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ¶‚æŠ¹ï¼ˆGaussian Splattingï¼‰çš„æ¡†æ¶ï¼Œç›´æ¥ä»å†…çª¥é•œæ•°æ®é‡å»ºäº¤äº’å¼æ‰‹æœ¯åœºæ™¯ï¼ŒåŒæ—¶ç¡®ä¿æ•ˆç‡ã€æ¸²æŸ“è´¨é‡å’ŒçœŸå®æ€§ã€‚åœ¨è¿™ç§æ•°æ®é©±åŠ¨æ¨¡æ‹ŸèŒƒå¼ä¸­çš„å…³é”®æŒ‘æˆ˜æ˜¯å†…çª¥é•œç›¸æœºè¿åŠ¨å—é™ï¼Œè¿™é™åˆ¶äº†è§†è§’å¤šæ ·æ€§ã€‚å› æ­¤ï¼Œé«˜æ–¯æ¶‚æŠ¹è¡¨ç¤ºæ³•è¿‡åº¦æ‹Ÿåˆç‰¹å®šè§†è§’ï¼Œå¯¼è‡´å‡ ä½•ç²¾åº¦é™ä½ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„åŸºäºè™šæ‹Ÿç›¸æœºçš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è‡ªé€‚åº”åœ°é‡‡æ ·åœºæ™¯å‘¨å›´çš„è™šæ‹Ÿè§‚ç‚¹ï¼Œå¹¶å°†å…¶çº³å…¥ä¼˜åŒ–è¿‡ç¨‹ä»¥å‡è½»è¿‡åº¦æ‹Ÿåˆã€‚å¯¹çœŸå®å’Œè™šæ‹Ÿè§†å›¾éƒ½åº”ç”¨äº†æœ‰æ•ˆçš„åŸºäºæ·±åº¦çš„æ­£åˆ™åŒ–ï¼Œä»¥è¿›ä¸€æ­¥ç»†åŒ–åœºæ™¯å‡ ä½•ã€‚ä¸ºäº†å®ç°å¿«é€Ÿå˜å½¢æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç¨€ç–æ§åˆ¶èŠ‚ç‚¹çš„ç‰©è´¨ç‚¹æ³•ï¼ˆMaterial Point Methodï¼‰ï¼Œå®ƒå°†ç‰©ç†å±æ€§èå…¥é‡å»ºçš„åœºæ™¯ä¸­ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬ã€‚åœ¨å…·æœ‰ä»£è¡¨æ€§çš„æ‰‹æœ¯æ•°æ®ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ä»ç¨€ç–çš„å†…çª¥é•œè§†è§’é‡å»ºå’Œæ¨¡æ‹Ÿæ‰‹æœ¯åœºæ™¯ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åªéœ€å‡ åˆ†é’Ÿå°±èƒ½é‡å»ºæ‰‹æœ¯åœºæ™¯ï¼Œå¹¶èƒ½å¤Ÿåœ¨å®æ—¶ä¸­äº§ç”Ÿç‰©ç†ä¸Šåˆç†çš„å˜å½¢ä»¥åŠç”¨æˆ·å®šä¹‰çš„äº¤äº’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.17027v1">PDF</a> Workshop Paper of AECAI@MICCAI 2025</p>
<p><strong>Summary</strong><br>     æ‰‹æœ¯æ¨¡æ‹Ÿåœ¨åŒ»å­¦è®­ç»ƒä¸­å…·æœ‰é‡è¦ä½œç”¨ï¼Œèƒ½æé«˜æ‰‹æœ¯æŠ€èƒ½å’Œæ‚£è€…å®‰å…¨æ€§ã€‚ä¼ ç»Ÿæ¨¡æ‹Ÿæ–¹æ³•ç¹çè€—æ—¶ä¸”éš¾ä»¥æ‰©å±•ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºé«˜æ–¯æ¶‚æ±¡çš„æ¡†æ¶ï¼Œä»å†…çª¥é•œæ•°æ®ä¸­å¿«é€Ÿé‡å»ºæ‰‹æœ¯åœºæ™¯ï¼Œå¹¶å¼•å…¥è™šæ‹Ÿç›¸æœºæ­£åˆ™åŒ–æ–¹æ³•å’Œç‰©è´¨ç‚¹æ³•ï¼Œæé«˜å‡ ä½•å‡†ç¡®æ€§å’Œå®æ—¶æ¨¡æ‹Ÿæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰‹æœ¯æ¨¡æ‹Ÿåœ¨åŒ»å­¦è®­ç»ƒä¸­çš„é‡è¦æ€§ï¼šæé«˜æ‰‹æœ¯æŠ€èƒ½ã€æ‚£è€…å®‰å…¨æ€§å’Œæ‰‹æœ¯æ•ˆæœã€‚</li>
<li>ä¼ ç»Ÿæ¨¡æ‹Ÿæ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼šç¹çã€è€—æ—¶ã€éš¾ä»¥æ‰©å±•ï¼Œä»¥åŠç»†èŠ‚ä¸è¶³å’Œæ¨¡æ‹Ÿä¸çœŸå®ã€‚</li>
<li>åŸºäºé«˜æ–¯æ¶‚æ±¡çš„æ¡†æ¶ï¼šç›´æ¥ä»å†…çª¥é•œæ•°æ®é‡å»ºæ‰‹æœ¯åœºæ™¯ï¼Œæé«˜æ•ˆç‡ã€æ¸²æŸ“è´¨é‡å’ŒçœŸå®æ€§ã€‚</li>
<li>è™šæ‹Ÿç›¸æœºæ­£åˆ™åŒ–æ–¹æ³•ï¼šè§£å†³å†…çª¥é•œè§†è§’é™åˆ¶é—®é¢˜ï¼Œæé«˜å‡ ä½•å‡†ç¡®æ€§ã€‚</li>
<li>æ·±åº¦åŸºç¡€ä¸Šçš„æ­£åˆ™åŒ–ï¼šè¿›ä¸€æ­¥ç»†åŒ–åœºæ™¯å‡ ä½•ã€‚</li>
<li>ç¨€ç–æ§åˆ¶èŠ‚ç‚¹ç‰©è´¨ç‚¹æ³•ï¼šå®ç°å¿«é€Ÿå˜å½¢æ¨¡æ‹Ÿï¼Œé›†æˆç‰©ç†å±æ€§å¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.17027">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bf2df3dd026c14d74e5e848ff84898e0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426913&auth_key=1760426913-0-0-a6a6d4063f1a5ec3cf9554269f323f71&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a3d1a70de4123202ace85f6f0e161eb5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426921&auth_key=1760426921-0-0-4b081c0eebabb63ec2c1ef0b3f32f329&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-27b08631679040f9e705742f66f6b012~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426928&auth_key=1760426928-0-0-72bc871d2d63966a93eb02f7f8a68c0b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="PGSTalker-Real-Time-Audio-Driven-Talking-Head-Generation-via-3D-Gaussian-Splatting-with-Pixel-Aware-Density-Control"><a href="#PGSTalker-Real-Time-Audio-Driven-Talking-Head-Generation-via-3D-Gaussian-Splatting-with-Pixel-Aware-Density-Control" class="headerlink" title="PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D   Gaussian Splatting with Pixel-Aware Density Control"></a>PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D   Gaussian Splatting with Pixel-Aware Density Control</h2><p><strong>Authors:Tianheng Zhu, Yinfeng Yu, Liejun Wang, Fuchun Sun, Wendong Zheng</strong></p>
<p>Audio-driven talking head generation is crucial for applications in virtual reality, digital avatars, and film production. While NeRF-based methods enable high-fidelity reconstruction, they suffer from low rendering efficiency and suboptimal audio-visual synchronization. This work presents PGSTalker, a real-time audio-driven talking head synthesis framework based on 3D Gaussian Splatting (3DGS). To improve rendering performance, we propose a pixel-aware density control strategy that adaptively allocates point density, enhancing detail in dynamic facial regions while reducing redundancy elsewhere. Additionally, we introduce a lightweight Multimodal Gated Fusion Module to effectively fuse audio and spatial features, thereby improving the accuracy of Gaussian deformation prediction. Extensive experiments on public datasets demonstrate that PGSTalker outperforms existing NeRF- and 3DGS-based approaches in rendering quality, lip-sync precision, and inference speed. Our method exhibits strong generalization capabilities and practical potential for real-world deployment. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆå¯¹äºè™šæ‹Ÿç°å®ã€æ•°å­—åŒ–èº«å’Œç”µå½±åˆ¶ä½œç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚è™½ç„¶åŸºäºNeRFçš„æ–¹æ³•èƒ½å¤Ÿå®ç°é«˜ä¿çœŸé‡å»ºï¼Œä½†å®ƒä»¬å­˜åœ¨æ¸²æŸ“æ•ˆç‡ä½ä¸‹å’Œè§†å¬åŒæ­¥ä¸ä½³çš„é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰çš„å®æ—¶éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨åˆæˆæ¡†æ¶PGSTalkerã€‚ä¸ºæé«˜æ¸²æŸ“æ€§èƒ½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åƒç´ æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯è‡ªé€‚åº”åˆ†é…ç‚¹å¯†åº¦ï¼Œåœ¨åŠ¨æ€é¢éƒ¨åŒºåŸŸå¢å¼ºç»†èŠ‚çš„åŒæ—¶å‡å°‘å…¶ä»–åŒºåŸŸçš„å†—ä½™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„å¤šæ¨¡æ€é—¨æ§èåˆæ¨¡å—ï¼Œä»¥æœ‰æ•ˆåœ°èåˆéŸ³é¢‘å’Œç©ºé—´ç‰¹å¾ï¼Œä»è€Œæé«˜é«˜æ–¯å˜å½¢é¢„æµ‹çš„ç²¾åº¦ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPGSTalkeråœ¨æ¸²æŸ“è´¨é‡ã€å”‡åŒæ­¥ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦æ–¹é¢ä¼˜äºç°æœ‰çš„NeRFå’Œ3DGSæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…éƒ¨ç½²çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16922v1">PDF</a> Main paper (15 pages). Accepted for publication by ICONIP(   International Conference on Neural Information Processing) 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºéŸ³é¢‘é©±åŠ¨çš„å¤´éƒ¨ç”ŸæˆæŠ€æœ¯å¯¹äºè™šæ‹Ÿç°å®ã€æ•°å­—è§’è‰²å’Œç”µå½±åˆ¶ä½œç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºPGSTalkerï¼Œä¸€ä¸ªåŸºäºå®æ—¶éŸ³é¢‘é©±åŠ¨ä¸3Dé«˜æ–¯å–·å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„å¤´éƒ¨åˆæˆæ¡†æ¶ã€‚ä¸ºæé«˜æ¸²æŸ“æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºåƒç´ æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ç­–ç•¥ï¼Œè‡ªé€‚åº”åˆ†é…ç‚¹å¯†åº¦ï¼Œåœ¨åŠ¨æ€é¢éƒ¨åŒºåŸŸå¢å¼ºç»†èŠ‚çš„åŒæ—¶å‡å°‘å†—ä½™ã€‚åŒæ—¶å¼•å…¥è½»é‡çº§çš„å¤šæ¨¡æ€é—¨èåˆæ¨¡å—ï¼Œæœ‰æ•ˆèåˆéŸ³é¢‘å’Œç©ºé—´ç‰¹å¾ï¼Œæé«˜é«˜æ–¯å˜å½¢é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPGSTalkeråœ¨æ¸²æŸ“è´¨é‡ã€å”‡åŒæ­¥ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦æ–¹é¢ä¼˜äºç°æœ‰çš„NeRFå’Œ3DGSæ–¹æ³•ã€‚æ­¤æ–¹æ³•å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>éŸ³é¢‘é©±åŠ¨çš„å¤´éƒ¨ç”ŸæˆæŠ€æœ¯åœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰é‡è¦æ€§ã€‚</li>
<li>PGSTalkeræ˜¯ä¸€ä¸ªåŸºäºå®æ—¶éŸ³é¢‘ä¸3DGSæŠ€æœ¯çš„å¤´éƒ¨åˆæˆæ¡†æ¶ã€‚</li>
<li>åƒç´ æ„ŸçŸ¥å¯†åº¦æ§åˆ¶ç­–ç•¥æé«˜äº†æ¸²æŸ“æ€§èƒ½ã€‚</li>
<li>å¤šæ¨¡æ€é—¨èåˆæ¨¡å—æœ‰æ•ˆèåˆéŸ³é¢‘å’Œç©ºé—´ç‰¹å¾ã€‚</li>
<li>PGSTalkeråœ¨æ¸²æŸ“è´¨é‡ã€å”‡åŒæ­¥ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>æ­¤æ–¹æ³•å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨æ½œåŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4bee1be9c769726296148800b2e1d994~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426936&auth_key=1760426936-0-0-44040cb0eedb3c34e6065b08f1369594&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2728ea1bfc3efad0d6c082b65169f3e3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426943&auth_key=1760426943-0-0-9b3fe2f6bbd0c281a674776795ed86bc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="ConfidentSplat-Confidence-Weighted-Depth-Fusion-for-Accurate-3D-Gaussian-Splatting-SLAM"><a href="#ConfidentSplat-Confidence-Weighted-Depth-Fusion-for-Accurate-3D-Gaussian-Splatting-SLAM" class="headerlink" title="ConfidentSplat: Confidence-Weighted Depth Fusion for Accurate 3D   Gaussian Splatting SLAM"></a>ConfidentSplat: Confidence-Weighted Depth Fusion for Accurate 3D   Gaussian Splatting SLAM</h2><p><strong>Authors:Amanuel T. Dufera, Yuan-Li Cai</strong></p>
<p>We introduce ConfidentSplat, a novel 3D Gaussian Splatting (3DGS)-based SLAM system for robust, highfidelity RGB-only reconstruction. Addressing geometric inaccuracies in existing RGB-only 3DGS SLAM methods that stem from unreliable depth estimation, ConfidentSplat incorporates a core innovation: a confidence-weighted fusion mechanism. This mechanism adaptively integrates depth cues from multiview geometry with learned monocular priors (Omnidata ViT), dynamically weighting their contributions based on explicit reliability estimates-derived predominantly from multi-view geometric consistency-to generate high-fidelity proxy depth for map supervision. The resulting proxy depth guides the optimization of a deformable 3DGS map, which efficiently adapts online to maintain global consistency following pose updates from a DROID-SLAM-inspired frontend and backend optimizations (loop closure, global bundle adjustment). Extensive validation on standard benchmarks (TUM-RGBD, ScanNet) and diverse custom mobile datasets demonstrates significant improvements in reconstruction accuracy (L1 depth error) and novel view synthesis fidelity (PSNR, SSIM, LPIPS) over baselines, particularly in challenging conditions. ConfidentSplat underscores the efficacy of principled, confidence-aware sensor fusion for advancing state-of-the-art dense visual SLAM. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ConfidentSplatï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ–°å‹ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰çš„SLAMç³»ç»Ÿï¼Œç”¨äºç¨³å¥çš„é«˜ä¿çœŸä»…RGBé‡å»ºã€‚é’ˆå¯¹ç°æœ‰ä»…RGBçš„3DGS SLAMæ–¹æ³•ä¸­ç”±äºæ·±åº¦ä¼°è®¡ä¸å¯é è€Œäº§ç”Ÿçš„å‡ ä½•è¯¯å·®é—®é¢˜ï¼ŒConfidentSplatèå…¥äº†ä¸€é¡¹æ ¸å¿ƒåˆ›æ–°ï¼šç½®ä¿¡åŠ æƒèåˆæœºåˆ¶ã€‚è¯¥æœºåˆ¶è‡ªé€‚åº”åœ°æ•´åˆäº†å¤šè§†è§’å‡ ä½•çš„æ·±åº¦çº¿ç´¢å’Œå­¦ä¹ çš„å•çœ¼å…ˆéªŒçŸ¥è¯†ï¼ˆOmnidata ViTï¼‰ï¼Œå¹¶æ ¹æ®æ˜ç¡®çš„å¯é æ€§ä¼°è®¡ï¼ˆä¸»è¦æ¥æºäºå¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§ï¼‰åŠ¨æ€æƒè¡¡å…¶è´¡çŒ®ï¼Œä»¥ç”Ÿæˆç”¨äºåœ°å›¾ç›‘ç£çš„é«˜ä¿çœŸä»£ç†æ·±åº¦ã€‚ç»“æœäº§ç”Ÿçš„ä»£ç†æ·±åº¦å¼•å¯¼å¯å˜å½¢3DGSåœ°å›¾çš„ä¼˜åŒ–ï¼Œè¯¥åœ°å›¾åœ¨å—åˆ°DROID-SLAMå¯å‘çš„å‰ç«¯å’Œåç«¯ä¼˜åŒ–ï¼ˆé—­ç¯ã€å…¨å±€æ†ç»‘è°ƒæ•´ï¼‰çš„å§¿æ€æ›´æ–°åï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°è¿›è¡Œåœ¨çº¿è°ƒæ•´ä»¥ä¿æŒå…¨å±€ä¸€è‡´æ€§ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ï¼ˆTUM-RGBDã€ScanNetï¼‰å’Œå„ç§è‡ªå®šä¹‰ç§»åŠ¨æ•°æ®é›†ä¸Šçš„å¹¿æ³›éªŒè¯è¡¨æ˜ï¼Œä¸åŸºå‡†çº¿ç›¸æ¯”ï¼Œé‡å»ºç²¾åº¦ï¼ˆL1æ·±åº¦è¯¯å·®ï¼‰å’Œæ–°è§†å›¾åˆæˆä¿çœŸåº¦ï¼ˆPSNRã€SSIMã€LPIPSï¼‰å‡æœ‰æ˜¾è‘—æé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ã€‚ConfidentSplatå¼ºè°ƒäº†æœ‰åŸåˆ™çš„ã€åŸºäºç½®ä¿¡åº¦çš„ä¼ æ„Ÿå™¨èåˆåœ¨æé«˜æœ€å…ˆè¿›çš„å¯†é›†è§†è§‰SLAMä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16863v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ConfidentSplatæ˜¯ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰çš„æ–°å‹åŒæ­¥å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰ç³»ç»Ÿï¼Œç”¨äºç¨³å¥çš„é«˜ä¿çœŸä»…RGBé‡å»ºã€‚å®ƒé€šè¿‡å¼•å…¥ä¿¡å¿ƒåŠ æƒèåˆæœºåˆ¶ï¼Œè§£å†³äº†ç°æœ‰RGBä»…ä¸‰ç»´é«˜æ–¯æ‰©å±•SLAMæ–¹æ³•ä¸­ç”±äºæ·±åº¦ä¼°è®¡ä¸å¯é å¯¼è‡´çš„å‡ ä½•è¯¯å·®é—®é¢˜ã€‚è¯¥æœºåˆ¶è‡ªé€‚åº”åœ°é›†æˆäº†å¤šè§†è§’å‡ ä½•çš„æ·±åº¦çº¿ç´¢å’Œå­¦ä¹ çš„å•çœ¼å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶æ ¹æ®æ˜ç¡®çš„å¯é æ€§ä¼°è®¡åŠ¨æ€è°ƒæ•´å…¶è´¡çŒ®ï¼Œç”Ÿæˆç”¨äºåœ°å›¾ç›‘ç£çš„é«˜ä¿çœŸä»£ç†æ·±åº¦ã€‚ä»£ç†æ·±åº¦å¼•å¯¼å¯å˜å½¢ä¸‰ç»´é«˜æ–¯æ‰©å±•åœ°å›¾çš„ä¼˜åŒ–ï¼Œè¯¥åœ°å›¾èƒ½å¤Ÿåœ¨çº¿æœ‰æ•ˆåœ°é€‚åº”å…¨å±€ä¸€è‡´æ€§ï¼Œå¹¶æ ¹æ®å‰ç«¯å’Œåç«¯ä¼˜åŒ–ï¼ˆä¾‹å¦‚å›è·¯å…³é—­å’Œå…¨å±€æ†ç»‘è°ƒæ•´ï¼‰è¿›è¡Œå§¿æ€æ›´æ–°ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•å’Œå¤šç§è‡ªå®šä¹‰ç§»åŠ¨æ•°æ®é›†ä¸Šçš„å¹¿æ³›éªŒè¯è¡¨æ˜ï¼Œåœ¨é‡å»ºç²¾åº¦ï¼ˆL1æ·±åº¦è¯¯å·®ï¼‰å’Œæ–°è§†è§’åˆæˆä¿çœŸåº¦ï¼ˆPSNRã€SSIMã€LPIPSï¼‰æ–¹é¢ï¼Œä¸åŸºå‡†æµ‹è¯•ç›¸æ¯”æœ‰æ˜¾è‘—æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ã€‚ConfidentSplatå¼ºè°ƒäº†åŸåˆ™æ€§ã€ä¿¡å¿ƒæ„ŸçŸ¥ä¼ æ„Ÿå™¨èåˆåœ¨æé«˜æœ€æ–°å¯†é›†è§†è§‰SLAMä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ConfidentSplatæ˜¯ä¸€ä¸ªåŸºäº3DGSçš„SLAMç³»ç»Ÿï¼Œç”¨äºRGBä»…é‡å»ºï¼Œå®ç°ç¨³å¥çš„é«˜ä¿çœŸæ•ˆæœã€‚</li>
<li>è¯¥ç³»ç»Ÿé€šè¿‡ä¿¡å¿ƒåŠ æƒèåˆæœºåˆ¶è§£å†³æ·±åº¦ä¼°è®¡ä¸å¯é å¯¼è‡´çš„å‡ ä½•è¯¯å·®é—®é¢˜ã€‚</li>
<li>èåˆæœºåˆ¶ç»“åˆäº†å¤šè§†è§’å‡ ä½•çš„æ·±åº¦çº¿ç´¢å’Œå­¦ä¹ çš„å•çœ¼å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>åŸºäºæ˜ç¡®çš„å¯é æ€§ä¼°è®¡åŠ¨æ€è°ƒæ•´æ·±åº¦çº¿ç´¢å’Œå…ˆéªŒçŸ¥è¯†çš„è´¡çŒ®ã€‚</li>
<li>ç³»ç»Ÿç”Ÿæˆé«˜ä¿çœŸä»£ç†æ·±åº¦ï¼Œç”¨äºåœ°å›¾ç›‘ç£åŠå¯å˜å½¢ä¸‰ç»´é«˜æ–¯æ‰©å±•åœ°å›¾çš„ä¼˜åŒ–ã€‚</li>
<li>è¯¥ç³»ç»Ÿåœ¨å¤šç§æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›éªŒè¯ï¼Œåœ¨é‡å»ºç²¾åº¦å’Œæ–°è§†è§’åˆæˆä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16863">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-945ce8022b7b05b921548f38cd69a085~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426951&auth_key=1760426951-0-0-7bc45d6f654c3a024b23b1b6557f8d13&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3f9e17770e267c67762a42073b4bfe24~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426959&auth_key=1760426959-0-0-a29b9cd08242c215b4b3d4d9906865cc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-49d38ade88a3616c5b7e4a7d57ce68bd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426965&auth_key=1760426965-0-0-2846a9a7466e5bf13a780b4c62a5b79c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-21ca5f206a71470515e8c792ee939378~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426972&auth_key=1760426972-0-0-9bb94fcce74e80add5e0a4c6447949c0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2875acb1aeb7cc1b371abe06c30303eb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426979&auth_key=1760426979-0-0-b38c258b84713a65e43f7771dc8c5aac&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-40c37cc9547ae3a45946213abe8baf4c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426986&auth_key=1760426986-0-0-66e8f8cd903ce2cbe8b7141c16ab136d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7d148e0411a6f0e88b45555c8c4e27b9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426993&auth_key=1760426993-0-0-d5c35c65b2e554dbf56e7de55986e570&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-203a155fa0a8f1ad802c0b21318775c4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426999&auth_key=1760426999-0-0-7819b53b1af22907f65b22d78e7da5e2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="SQS-Enhancing-Sparse-Perception-Models-via-Query-based-Splatting-in-Autonomous-Driving"><a href="#SQS-Enhancing-Sparse-Perception-Models-via-Query-based-Splatting-in-Autonomous-Driving" class="headerlink" title="SQS: Enhancing Sparse Perception Models via Query-based Splatting in   Autonomous Driving"></a>SQS: Enhancing Sparse Perception Models via Query-based Splatting in   Autonomous Driving</h2><p><strong>Authors:Haiming Zhang, Yiyao Zhu, Wending Zhou, Xu Yan, Yingjie Cai, Bingbing Liu, Shuguang Cui, Zhen Li</strong></p>
<p>Sparse Perception Models (SPMs) adopt a query-driven paradigm that forgoes explicit dense BEV or volumetric construction, enabling highly efficient computation and accelerated inference. In this paper, we introduce SQS, a novel query-based splatting pre-training specifically designed to advance SPMs in autonomous driving. SQS introduces a plug-in module that predicts 3D Gaussian representations from sparse queries during pre-training, leveraging self-supervised splatting to learn fine-grained contextual features through the reconstruction of multi-view images and depth maps. During fine-tuning, the pre-trained Gaussian queries are seamlessly integrated into downstream networks via query interaction mechanisms that explicitly connect pre-trained queries with task-specific queries, effectively accommodating the diverse requirements of occupancy prediction and 3D object detection. Extensive experiments on autonomous driving benchmarks demonstrate that SQS delivers considerable performance gains across multiple query-based 3D perception tasks, notably in occupancy prediction and 3D object detection, outperforming prior state-of-the-art pre-training approaches by a significant margin (i.e., +1.3 mIoU on occupancy prediction and +1.0 NDS on 3D detection). </p>
<blockquote>
<p>ç¨€ç–æ„ŸçŸ¥æ¨¡å‹ï¼ˆSPMsï¼‰é‡‡ç”¨æŸ¥è¯¢é©±åŠ¨èŒƒå¼ï¼Œæ‘’å¼ƒäº†æ˜¾å¼çš„å¯†é›†BEVæˆ–ä½“ç§¯æ„å»ºï¼Œå®ç°äº†é«˜æ•ˆè®¡ç®—å’ŒåŠ é€Ÿæ¨ç†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SQSï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæŸ¥è¯¢çš„åŠˆè£‚é¢„è®­ç»ƒæ–¹æ³•ï¼Œä¸“ä¸ºè‡ªä¸»é©¾é©¶ä¸­çš„SPMsè®¾è®¡ã€‚SQSå¼•å…¥äº†ä¸€ä¸ªæ’ä»¶æ¨¡å—ï¼Œåœ¨é¢„è®­ç»ƒæœŸé—´ä»ç¨€ç–æŸ¥è¯¢ä¸­é¢„æµ‹3Dé«˜æ–¯è¡¨ç¤ºï¼Œåˆ©ç”¨è‡ªç›‘ç£åŠˆè£‚æ³•é€šè¿‡å¤šè§†è§’å›¾åƒå’Œæ·±åº¦å›¾çš„é‡å»ºæ¥å­¦ä¹ ç²¾ç»†çš„ä¸Šä¸‹æ–‡ç‰¹å¾ã€‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡æŸ¥è¯¢äº¤äº’æœºåˆ¶æ— ç¼é›†æˆé¢„è®­ç»ƒçš„é«˜æ–¯æŸ¥è¯¢åˆ°ä¸‹æ¸¸ç½‘ç»œä¸­ï¼Œæ˜¾å¼è¿æ¥é¢„è®­ç»ƒæŸ¥è¯¢å’Œä»»åŠ¡ç‰¹å®šæŸ¥è¯¢ï¼Œæœ‰æ•ˆæ»¡è¶³å ç”¨é¢„æµ‹å’Œ3Då¯¹è±¡æ£€æµ‹çš„å¤šæ ·åŒ–è¦æ±‚ã€‚åœ¨è‡ªåŠ¨é©¾é©¶åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSQSåœ¨å¤šä¸ªåŸºäºæŸ¥è¯¢çš„3Dæ„ŸçŸ¥ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨å ç”¨é¢„æµ‹å’Œ3Då¯¹è±¡æ£€æµ‹æ–¹é¢ï¼Œæ˜¾è‘—ä¼˜äºæœ€æ–°çš„é¢„è®­ç»ƒæ–¹æ³•ï¼ˆå³åœ¨å ç”¨é¢„æµ‹ä¸Šæé«˜äº†1.3 mIoUï¼Œåœ¨3Dæ£€æµ‹ä¸Šæé«˜äº†1.0 NDSï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16588v1">PDF</a> NeurIPS 2025 (Spotlight)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­çš„ç¨€ç–æ„ŸçŸ¥æ¨¡å‹ï¼ˆSPMsï¼‰çš„é¢„è®­ç»ƒæ–¹æ³•SQSã€‚SQSé‡‡ç”¨åŸºäºæŸ¥è¯¢çš„å–·æ¶‚é¢„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡è‡ªæˆ‘ç›‘ç£çš„å–·æ¶‚å­¦ä¹ ç²¾ç»†çš„ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œå¹¶é€šè¿‡é‡å»ºå¤šè§†è§’å›¾åƒå’Œæ·±åº¦å›¾é¢„æµ‹ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼Œé¢„è®­ç»ƒçš„é«˜æ–¯æŸ¥è¯¢é€šè¿‡æŸ¥è¯¢äº¤äº’æœºåˆ¶æ— ç¼é›†æˆåˆ°ä¸‹æ¸¸ç½‘ç»œä¸­ï¼Œæœ‰æ•ˆæ»¡è¶³å ç”¨é¢„æµ‹å’Œä¸‰ç»´ç›®æ ‡æ£€æµ‹çš„å„ç§éœ€æ±‚ã€‚SQSåœ¨è‡ªåŠ¨é©¾é©¶åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨å ç”¨é¢„æµ‹å’Œä¸‰ç»´ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæ˜¾è‘—ä¼˜äºå…ˆå‰çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SQSåˆ©ç”¨åŸºäºæŸ¥è¯¢çš„å–·æ¶‚é¢„è®­ç»ƒç­–ç•¥æ¨è¿›ç¨€ç–æ„ŸçŸ¥æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„åº”ç”¨ã€‚</li>
<li>SQSå¼•å…¥äº†ä¸€ä¸ªæ’ä»¶æ¨¡å—ï¼Œè¯¥æ¨¡å—åœ¨é¢„è®­ç»ƒé˜¶æ®µä»ç¨€ç–æŸ¥è¯¢ä¸­é¢„æµ‹ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>é€šè¿‡è‡ªæˆ‘ç›‘ç£çš„å–·æ¶‚å­¦ä¹ ï¼ŒSQSèƒ½å¤Ÿå­¦ä¹ ç²¾ç»†çš„ä¸Šä¸‹æ–‡ç‰¹å¾ã€‚</li>
<li>SQSé€šè¿‡é‡å»ºå¤šè§†è§’å›¾åƒå’Œæ·±åº¦å›¾è¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>åœ¨å¾®è°ƒé˜¶æ®µï¼ŒSQSå°†é¢„è®­ç»ƒçš„é«˜æ–¯æŸ¥è¯¢æ— ç¼é›†æˆåˆ°ä¸‹æ¸¸ç½‘ç»œä¸­ã€‚</li>
<li>SQSæ˜¾è‘—æé«˜äº†å ç”¨é¢„æµ‹å’Œä¸‰ç»´ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16588">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-42e9c2e7dddbcd9cdd17cf7533dcf0e1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427006&auth_key=1760427006-0-0-94bc5a5617d834eca51ba682e94ed5f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cf01e1a65ba340f06abcc45375a945a6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427014&auth_key=1760427014-0-0-40d3e6fba95a6d1d90f2e152c0ed65d4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-311bfbe0b79a44c80d1d3f9f15a1ed2d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427021&auth_key=1760427021-0-0-8964e378420f114d6866d49e52c4e917&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="ST-GS-Vision-Based-3D-Semantic-Occupancy-Prediction-with-Spatial-Temporal-Gaussian-Splatting"><a href="#ST-GS-Vision-Based-3D-Semantic-Occupancy-Prediction-with-Spatial-Temporal-Gaussian-Splatting" class="headerlink" title="ST-GS: Vision-Based 3D Semantic Occupancy Prediction with   Spatial-Temporal Gaussian Splatting"></a>ST-GS: Vision-Based 3D Semantic Occupancy Prediction with   Spatial-Temporal Gaussian Splatting</h2><p><strong>Authors:Xiaoyang Yan, Muleilan Pei, Shaojie Shen</strong></p>
<p>3D occupancy prediction is critical for comprehensive scene understanding in vision-centric autonomous driving. Recent advances have explored utilizing 3D semantic Gaussians to model occupancy while reducing computational overhead, but they remain constrained by insufficient multi-view spatial interaction and limited multi-frame temporal consistency. To overcome these issues, in this paper, we propose a novel Spatial-Temporal Gaussian Splatting (ST-GS) framework to enhance both spatial and temporal modeling in existing Gaussian-based pipelines. Specifically, we develop a guidance-informed spatial aggregation strategy within a dual-mode attention mechanism to strengthen spatial interaction in Gaussian representations. Furthermore, we introduce a geometry-aware temporal fusion scheme that effectively leverages historical context to improve temporal continuity in scene completion. Extensive experiments on the large-scale nuScenes occupancy prediction benchmark showcase that our proposed approach not only achieves state-of-the-art performance but also delivers markedly better temporal consistency compared to existing Gaussian-based methods. </p>
<blockquote>
<p>åœ¨è§†è§‰ä¸ºä¸­å¿ƒçš„è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œä¸‰ç»´å ç”¨é¢„æµ‹å¯¹äºå…¨é¢çš„åœºæ™¯ç†è§£è‡³å…³é‡è¦ã€‚æœ€è¿‘çš„è¿›å±•å·²ç»æ¢ç´¢äº†åˆ©ç”¨ä¸‰ç»´è¯­ä¹‰é«˜æ–¯å¯¹å ç”¨è¿›è¡Œå»ºæ¨¡ï¼ŒåŒæ—¶å‡å°‘è®¡ç®—å¼€é”€ï¼Œä½†å®ƒä»¬ä»ç„¶å—åˆ°è§†å›¾é—´çš„ç©ºé—´äº¤äº’ä¸è¶³å’Œå¤šå¸§æ—¶é—´ä¸€è‡´æ€§çš„é™åˆ¶ã€‚ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ—¶ç©ºé«˜æ–¯æ¶‚æŠ¹ï¼ˆST-GSï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºç°æœ‰åŸºäºé«˜æ–¯ç®¡é“çš„ç©ºé—´å’Œæ—¶é—´å»ºæ¨¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨åŒæ¨¡å¼æ³¨æ„åŠ›æœºåˆ¶å†…éƒ¨å¼€å‘äº†ä¸€ç§å—æŒ‡å¯¼çš„ç©ºé—´èšåˆç­–ç•¥ï¼Œä»¥åŠ å¼ºé«˜æ–¯è¡¨ç¤ºä¸­çš„ç©ºé—´äº¤äº’ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å‡ ä½•æ„ŸçŸ¥çš„æ—¶é—´èåˆæ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å†å²ä¸Šä¸‹æ–‡ï¼Œæé«˜åœºæ™¯å®Œæˆä¸­çš„æ—¶é—´è¿ç»­æ€§ã€‚åœ¨å¤§å‹nuSceneså ç”¨é¢„æµ‹åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¸ä»…è¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½æ°´å¹³ï¼Œè€Œä¸”åœ¨æ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä¸ç°æœ‰çš„åŸºäºé«˜æ–¯çš„æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜æ˜¾æ›´ä¼˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16552v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„åŸºäºæ—¶ç©ºé«˜æ–¯æ•£æ–‘ï¼ˆST-GSï¼‰çš„æ¡†æ¶ï¼Œç”¨äºå¢å¼ºç°æœ‰é«˜æ–¯å‹ç®¡é“ä¸­çš„ç©ºé—´å’Œæ—¶é—´å»ºæ¨¡ã€‚é€šè¿‡å‘å±•ä¸€ç§åŸºäºå¯¼å‘çš„ç©ºé—´èšåˆç­–ç•¥å’ŒåŒæ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¼ºåŒ–é«˜æ–¯è¡¨ç¤ºä¸­çš„ç©ºé—´äº¤äº’ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºå‡ ä½•çš„æ—¶ç©ºèåˆæ–¹æ¡ˆï¼Œåˆ©ç”¨å†å²èƒŒæ™¯æé«˜åœºæ™¯å®Œæˆçš„æ—¶åºè¿ç»­æ€§ã€‚åœ¨å¤§å‹åœºæ™¯æ•°æ®é›†nuScenesä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…è¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½æ°´å¹³ï¼Œè€Œä¸”åœ¨æ—¶é—´è¿ç»­æ€§æ–¹é¢ä¸ç°æœ‰çš„é«˜æ–¯æ–¹æ³•ç›¸æ¯”è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D occupancy predictionå¯¹äºè‡ªä¸»é©¾é©¶ä¸­çš„åœºæ™¯ç†è§£è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åˆ©ç”¨3Dè¯­ä¹‰é«˜æ–¯æ¨¡å‹è¿›è¡Œå»ºæ¨¡ä»¥é™ä½è®¡ç®—å¼€é”€ï¼Œä½†å­˜åœ¨ç©ºé—´äº¤äº’ä¸è¶³å’Œæ—¶åºä¸€è‡´æ€§å—é™çš„é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„ST-GSæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºé«˜æ–¯å‹ç®¡é“ä¸­çš„ç©ºé—´å’Œæ—¶é—´å»ºæ¨¡ã€‚</li>
<li>é€šè¿‡å‘å±•ä¸€ç§åŸºäºå¯¼å‘çš„ç©ºé—´èšåˆç­–ç•¥å’ŒåŒæ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶æ¥å¼ºåŒ–é«˜æ–¯è¡¨ç¤ºä¸­çš„ç©ºé—´äº¤äº’ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºå‡ ä½•çš„æ—¶ç©ºèåˆæ–¹æ¡ˆï¼Œä»¥åˆ©ç”¨å†å²èƒŒæ™¯æé«˜åœºæ™¯é¢„æµ‹çš„è¿ç»­æ€§ã€‚</li>
<li>åœ¨å¤§å‹æ•°æ®é›†nuScenesä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…æ€§èƒ½å…ˆè¿›ï¼Œè€Œä¸”åœ¨æ—¶é—´è¿ç»­æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16552">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0f40a475032b63d8c5fa63c4b387b5de~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427028&auth_key=1760427028-0-0-6b664b2f00cf653cd1f2c52a343b6b95&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-030e769848627f36fec17bdad710e69d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427036&auth_key=1760427036-0-0-748b1d44d1d2d71f7be9db06f6bdb7bd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9b03e280daa47761d50a6c2d5659b629~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427043&auth_key=1760427043-0-0-9c7772f383a33912149f479d4d5afbf2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-62938f150fcf752587c149276b875e01~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427049&auth_key=1760427049-0-0-e890859bc456b0ea6ad56663c10e81d3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c7a801fbc3d686a3eccb3ef683d30dab~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427056&auth_key=1760427056-0-0-307a2a8ec0297b275e9f5ecc30dceb20&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-78552dd195a20edc6c58ab46281e251a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427062&auth_key=1760427062-0-0-f82a5bfa29f1ed53bac5fa359742de86&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Flats-Hybrid-2D-3D-Photometric-Scene-Reconstruction"><a href="#3D-Gaussian-Flats-Hybrid-2D-3D-Photometric-Scene-Reconstruction" class="headerlink" title="3D Gaussian Flats: Hybrid 2D&#x2F;3D Photometric Scene Reconstruction"></a>3D Gaussian Flats: Hybrid 2D&#x2F;3D Photometric Scene Reconstruction</h2><p><strong>Authors:Maria Taktasheva, Lily Goli, Alessandro Fiorini,  Zhen,  Li, Daniel Rebain, Andrea Tagliasacchi</strong></p>
<p>Recent advances in radiance fields and novel view synthesis enable creation of realistic digital twins from photographs. However, current methods struggle with flat, texture-less surfaces, creating uneven and semi-transparent reconstructions, due to an ill-conditioned photometric reconstruction objective. Surface reconstruction methods solve this issue but sacrifice visual quality. We propose a novel hybrid 2D&#x2F;3D representation that jointly optimizes constrained planar (2D) Gaussians for modeling flat surfaces and freeform (3D) Gaussians for the rest of the scene. Our end-to-end approach dynamically detects and refines planar regions, improving both visual fidelity and geometric accuracy. It achieves state-of-the-art depth estimation on ScanNet++ and ScanNetv2, and excels at mesh extraction without overfitting to a specific camera model, showing its effectiveness in producing high-quality reconstruction of indoor scenes. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œåœ¨è¾å°„åœºå’Œæ–°å‹è§†è§’åˆæˆæ–¹é¢çš„è¿›å±•ä½¿å¾—å¯ä»¥ä»ç…§ç‰‡åˆ›å»ºçœŸå®çš„æ•°å­—åŒèƒèƒã€‚ç„¶è€Œï¼Œç”±äºç—…æ€çš„å…‰åº¦é‡å»ºç›®æ ‡ï¼Œå½“å‰çš„æ–¹æ³•åœ¨å¤„ç†å¹³å¦ã€æ— çº¹ç†çš„è¡¨é¢æ—¶é¢ä¸´å›°éš¾ï¼Œä¼šäº§ç”Ÿä¸å‡åŒ€å’ŒåŠé€æ˜é‡å»ºã€‚è¡¨é¢é‡å»ºæ–¹æ³•å¯ä»¥è§£å†³æ­¤é—®é¢˜ï¼Œä½†ç‰ºç‰²äº†è§†è§‰è´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ··åˆçš„äºŒç»´&#x2F;ä¸‰ç»´è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒåŒæ—¶ä¼˜åŒ–ç”¨äºå»ºæ¨¡å¹³é¢ï¼ˆäºŒç»´ï¼‰çš„é«˜æ–¯å’Œç”¨äºåœºæ™¯å…¶ä½™éƒ¨åˆ†çš„è‡ªç”±å½¢å¼ï¼ˆä¸‰ç»´ï¼‰é«˜æ–¯ã€‚æˆ‘ä»¬çš„ç«¯åˆ°ç«¯æ–¹æ³•åŠ¨æ€æ£€æµ‹å’Œå¹³æ•´å¹³é¢åŒºåŸŸï¼Œæé«˜äº†è§†è§‰ä¿çœŸåº¦å’Œå‡ ä½•ç²¾åº¦ã€‚å®ƒåœ¨ScanNet++å’ŒScanNetv2ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ·±åº¦ä¼°è®¡ï¼Œå¹¶ä¸”åœ¨ä¸è¿‡åº¦æ‹Ÿåˆç‰¹å®šç›¸æœºæ¨¡å‹çš„æƒ…å†µä¸‹æ“…é•¿ç½‘æ ¼æå–ï¼Œå±•ç¤ºäº†å…¶åœ¨å®¤å†…åœºæ™¯é«˜è´¨é‡é‡å»ºä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16423v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä½¿ç”¨æœ€æ–°è¾å°„åœºå’Œæ–°é¢–è§†å›¾åˆæˆæŠ€æœ¯åˆ›å»ºçœŸå®æ•°å­—åŒèƒèƒçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•åœ¨å¤„ç†å¹³å¦ã€æ— çº¹ç†çš„è¡¨é¢æ—¶é‡åˆ°å›°éš¾ï¼Œä¼šäº§ç”Ÿä¸å‡åŒ€å’ŒåŠé€æ˜é‡å»ºã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ··åˆ2D&#x2F;3Dè¡¨ç¤ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¼˜åŒ–çº¦æŸå¹³é¢ï¼ˆ2Dï¼‰é«˜æ–¯æ¨¡å‹å’Œè‡ªç”±å½¢å¼ï¼ˆ3Dï¼‰é«˜æ–¯æ¨¡å‹æ¥å®ç°ã€‚æ­¤æ–¹æ³•åŠ¨æ€æ£€æµ‹å’Œä¼˜åŒ–å¹³é¢åŒºåŸŸï¼Œåœ¨æé«˜è§†è§‰ä¿çœŸåº¦å’Œå‡ ä½•ç²¾åº¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨ScanNet++å’ŒScanNetv2ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ·±åº¦ä¼°è®¡ï¼Œå±•ç¤ºäº†åœ¨å®¤å†…åœºæ™¯é«˜è´¨é‡å»ºä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¾å°„åœºå’Œæ–°é¢–è§†å›¾åˆæˆæŠ€æœ¯ç”¨äºåˆ›å»ºçœŸå®æ•°å­—åŒèƒèƒã€‚</li>
<li>å½“å‰æ–¹æ³•åœ¨å¤„ç†å¹³å¦ã€æ— çº¹ç†è¡¨é¢æ—¶å­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´ä¸å‡åŒ€å’ŒåŠé€æ˜é‡å»ºã€‚</li>
<li>æ–°å‹æ··åˆ2D&#x2F;3Dè¡¨ç¤ºæ–¹æ³•æ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>æ–¹æ³•é€šè¿‡ä¼˜åŒ–çº¦æŸå¹³é¢ï¼ˆ2Dï¼‰é«˜æ–¯æ¨¡å‹å’Œè‡ªç”±å½¢å¼ï¼ˆ3Dï¼‰é«˜æ–¯æ¨¡å‹å®ç°ã€‚</li>
<li>è¯¥æ–¹æ³•åŠ¨æ€æ£€æµ‹å’Œä¼˜åŒ–å¹³é¢åŒºåŸŸã€‚</li>
<li>æ–¹æ³•åœ¨æé«˜è§†è§‰ä¿çœŸåº¦å’Œå‡ ä½•ç²¾åº¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16423">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a7a1f305e957137d650faf6eb99bfaf1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427070&auth_key=1760427070-0-0-db4e7a989e7fc92d981fee525613e5c2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4881156590ac8d0dd8eb3550a1a6de22~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427077&auth_key=1760427077-0-0-716fcb4ad5bb41382572b4470c146411&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c4ab91c4732a716dcac4ebb5a3a14582~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427083&auth_key=1760427083-0-0-84d947702be047ab90a4b886c132e944&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-786fefda5fb93f2cddbc0a6493578f5a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427090&auth_key=1760427090-0-0-65fe555650292301a54eb7d38b2cd8ce&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="RadarGaussianDet3D-An-Efficient-and-Effective-Gaussian-based-3D-Detector-with-4D-Automotive-Radars"><a href="#RadarGaussianDet3D-An-Efficient-and-Effective-Gaussian-based-3D-Detector-with-4D-Automotive-Radars" class="headerlink" title="RadarGaussianDet3D: An Efficient and Effective Gaussian-based 3D   Detector with 4D Automotive Radars"></a>RadarGaussianDet3D: An Efficient and Effective Gaussian-based 3D   Detector with 4D Automotive Radars</h2><p><strong>Authors:Weiyi Xiong, Bing Zhu, Tao Huang, Zewei Zheng</strong></p>
<p>4D automotive radars have gained increasing attention for autonomous driving due to their low cost, robustness, and inherent velocity measurement capability. However, existing 4D radar-based 3D detectors rely heavily on pillar encoders for BEV feature extraction, where each point contributes to only a single BEV grid, resulting in sparse feature maps and degraded representation quality. In addition, they also optimize bounding box attributes independently, leading to sub-optimal detection accuracy. Moreover, their inference speed, while sufficient for high-end GPUs, may fail to meet the real-time requirement on vehicle-mounted embedded devices. To overcome these limitations, an efficient and effective Gaussian-based 3D detector, namely RadarGaussianDet3D is introduced, leveraging Gaussian primitives and distributions as intermediate representations for radar points and bounding boxes. In RadarGaussianDet3D, a novel Point Gaussian Encoder (PGE) is designed to transform each point into a Gaussian primitive after feature aggregation and employs the 3D Gaussian Splatting (3DGS) technique for BEV rasterization, yielding denser feature maps. PGE exhibits exceptionally low latency, owing to the optimized algorithm for point feature aggregation and fast rendering of 3DGS. In addition, a new Box Gaussian Loss (BGL) is proposed, which converts bounding boxes into 3D Gaussian distributions and measures their distance to enable more comprehensive and consistent optimization. Extensive experiments on TJ4DRadSet and View-of-Delft demonstrate that RadarGaussianDet3D achieves state-of-the-art detection accuracy while delivering substantially faster inference, highlighting its potential for real-time deployment in autonomous driving. </p>
<blockquote>
<p>éšç€å››ç»´æ±½è½¦é›·è¾¾åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œå…¶ä½æˆæœ¬ã€é²æ£’æ€§å’Œå›ºæœ‰çš„é€Ÿåº¦æµ‹é‡èƒ½åŠ›å¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºå››ç»´é›·è¾¾çš„ä¸‰ç»´æ£€æµ‹å™¨åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæŸ±çŠ¶ç¼–ç å™¨è¿›è¡Œé¸Ÿç°è§†å›¾ç‰¹å¾æå–ï¼Œæ¯ä¸ªç‚¹ä»…å¯¹é¸Ÿç°å›¾ä¸­çš„ä¸€ä¸ªç½‘æ ¼ä½œå‡ºè´¡çŒ®ï¼Œä»è€Œå¯¼è‡´ç‰¹å¾æ˜ å°„ç¨€ç–å¹¶ä¸”è¡¨ç¤ºè´¨é‡ä¸‹é™ã€‚æ­¤å¤–ï¼Œå®ƒä»¬è¿˜ç‹¬ç«‹ä¼˜åŒ–è¾¹ç•Œæ¡†å±æ€§ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸é«˜ã€‚è™½ç„¶å®ƒä»¬çš„æ¨ç†é€Ÿåº¦è¶³ä»¥æ»¡è¶³é«˜ç«¯GPUçš„éœ€æ±‚ï¼Œä½†å¯èƒ½æ— æ³•æ»¡è¶³è½¦è½½åµŒå…¥å¼è®¾å¤‡çš„å®æ—¶è¦æ±‚ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œå¼•å…¥äº†ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„åŸºäºé«˜æ–¯çš„ä¸‰ç»´æ£€æµ‹å™¨RadarGaussianDet3Dï¼Œåˆ©ç”¨é«˜æ–¯åŸè¯­å’Œåˆ†å¸ƒä½œä¸ºé›·è¾¾ç‚¹å’Œè¾¹ç•Œæ¡†çš„ä¸­é—´è¡¨ç¤ºå½¢å¼ã€‚RadarGaussianDet3Dè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ç‚¹é«˜æ–¯ç¼–ç å™¨ï¼ˆPGEï¼‰ï¼Œåœ¨ç‰¹å¾èšåˆåå°†æ¯ä¸ªç‚¹è½¬æ¢ä¸ºé«˜æ–¯åŸè¯­ï¼Œå¹¶é‡‡ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯è¿›è¡Œé¸Ÿç°å›¾æ¸²æŸ“ï¼Œç”Ÿæˆæ›´å¯†é›†çš„ç‰¹å¾æ˜ å°„ã€‚ç”±äºç‚¹ç‰¹å¾èšåˆçš„ä¼˜åŒ–ç®—æ³•å’Œä¸‰ç»´GSçš„å¿«é€Ÿæ¸²æŸ“ï¼ŒPGEå…·æœ‰æä½çš„å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„Box Gaussian Lossï¼ˆBGLï¼‰ï¼Œå®ƒå°†è¾¹ç•Œæ¡†è½¬æ¢ä¸ºä¸‰ç»´é«˜æ–¯åˆ†å¸ƒå¹¶æµ‹é‡å…¶è·ç¦»ï¼Œä»è€Œå®ç°æ›´å…¨é¢å’Œä¸€è‡´æ€§çš„ä¼˜åŒ–ã€‚åœ¨TJ4DRadSetå’ŒView-of-Delftä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRadarGaussianDet3Dè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ£€æµ‹ç²¾åº¦å¹¶å®ç°äº†æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œå‡¸æ˜¾äº†å…¶åœ¨è‡ªåŠ¨é©¾é©¶å®æ—¶éƒ¨ç½²ä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16119v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹è‡ªä¸»é©¾é©¶çš„4Dæ±½è½¦é›·è¾¾æ£€æµ‹æŠ€æœ¯ã€‚ä¼ ç»Ÿçš„é›·è¾¾æ¢æµ‹å™¨ä¾èµ–äºæŸ±ç¼–ç å™¨è¿›è¡Œç‰¹å¾æå–ï¼Œå­˜åœ¨ç‰¹å¾ç¨€ç–å’Œè¡¨ç¤ºè´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œå¼•å…¥äº†é«˜æ•ˆçš„RadarGaussianDet3Dæ£€æµ‹å™¨ï¼Œé‡‡ç”¨é«˜æ–¯åŸå§‹å’Œåˆ†å¸ƒä½œä¸ºé›·è¾¾ç‚¹å’Œè¾¹ç•Œæ¡†çš„ä¸­é—´è¡¨ç¤ºå½¢å¼ã€‚è¯¥æ£€æµ‹å™¨è®¾è®¡äº†ç‚¹é«˜æ–¯ç¼–ç å™¨ï¼ˆPGEï¼‰ï¼Œé€šè¿‡ç‰¹å¾èšåˆå°†æ¯ä¸ªç‚¹è½¬åŒ–ä¸ºé«˜æ–¯åŸå§‹ï¼Œå¹¶é‡‡ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼æ¥æŠ€æœ¯è¿›è¡Œé¸Ÿç°å›¾æ¸²æŸ“ï¼Œç”Ÿæˆæ›´å¯†é›†çš„ç‰¹å¾å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†Box Gaussian Lossï¼ˆBGLï¼‰ï¼Œå®ç°å¯¹è¾¹ç•Œæ¡†çš„å…¨é¢ä¼˜åŒ–ã€‚å®éªŒè¯æ˜RadarGaussianDet3Dæ£€æµ‹å‡†ç¡®åº¦é«˜ã€æ¨ç†é€Ÿåº¦å¿«ï¼Œé€‚åˆå®æ—¶éƒ¨ç½²äºè‡ªä¸»é©¾é©¶åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>4Dæ±½è½¦é›·è¾¾å› å…¶ä½æˆæœ¬ã€ç¨³å¥æ€§å’Œé€Ÿåº¦æµ‹é‡èƒ½åŠ›è€Œå—åˆ°è‡ªä¸»é©¾é©¶çš„å…³æ³¨ã€‚</li>
<li>ä¼ ç»Ÿé›·è¾¾æ£€æµ‹å™¨ä¾èµ–æŸ±ç¼–ç å™¨è¿›è¡Œç‰¹å¾æå–ï¼Œå­˜åœ¨ç‰¹å¾ç¨€ç–å’Œè¡¨ç¤ºè´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚</li>
<li>RadarGaussianDet3Dæ£€æµ‹å™¨åˆ©ç”¨é«˜æ–¯åŸå§‹å’Œåˆ†å¸ƒæ¥æ”¹è¿›æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>ç‚¹é«˜æ–¯ç¼–ç å™¨ï¼ˆPGEï¼‰å°†æ¯ä¸ªç‚¹è½¬åŒ–ä¸ºé«˜æ–¯åŸå§‹ï¼Œé€šè¿‡ä¸‰ç»´é«˜æ–¯æ‹¼æ¥æŠ€æœ¯ç”Ÿæˆæ›´å¯†é›†çš„ç‰¹å¾å›¾ã€‚</li>
<li>RadarGaussianDet3Dæ£€æµ‹å™¨å…·æœ‰é«˜æ•ˆæ€§ï¼Œé€‚åˆè½¦è½½åµŒå…¥å¼è®¾å¤‡çš„å®æ—¶è¦æ±‚ã€‚</li>
<li>Box Gaussian Lossï¼ˆBGLï¼‰çš„æå‡ºå®ç°äº†å¯¹è¾¹ç•Œæ¡†çš„å…¨é¢ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16119">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-033f864d45e7446d366b460d48402e9a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427098&auth_key=1760427098-0-0-68c13226ec00c102737b879c962a0dab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6795ef03ee8edd408c97372cac917300~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427106&auth_key=1760427106-0-0-2c621c644aebf0b0dcd0503bcaaaec64&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ab1b1cb08086b3058c9289a45caa3a0d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427113&auth_key=1760427113-0-0-dbadf81b8aaf9136c875372bb5acb748&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cfadcedd2d48f596419e1decb9050a14~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427120&auth_key=1760427120-0-0-354da46f5945a21a0285f635f91d0a4e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d0a1930c129125969b57a5a6bf533165~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427126&auth_key=1760427126-0-0-b0585f3bdfc380e6c545c9d6de10a395&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ba274e87368750f9612b0d8dec9c7356~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427133&auth_key=1760427133-0-0-26a71e89cebba0cde64e64533bf712fa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Zero-Shot-Visual-Grounding-in-3D-Gaussians-via-View-Retrieval"><a href="#Zero-Shot-Visual-Grounding-in-3D-Gaussians-via-View-Retrieval" class="headerlink" title="Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval"></a>Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval</h2><p><strong>Authors:Liwei Liao, Xufeng Li, Xiaoyun Zheng, Boning Liu, Feng Gao, Ronggang Wang</strong></p>
<p>3D Visual Grounding (3DVG) aims to locate objects in 3D scenes based on text prompts, which is essential for applications such as robotics. However, existing 3DVG methods encounter two main challenges: first, they struggle to handle the implicit representation of spatial textures in 3D Gaussian Splatting (3DGS), making per-scene training indispensable; second, they typically require larges amounts of labeled data for effective training. To this end, we propose \underline{G}rounding via \underline{V}iew \underline{R}etrieval (GVR), a novel zero-shot visual grounding framework for 3DGS to transform 3DVG as a 2D retrieval task that leverages object-level view retrieval to collect grounding clues from multiple views, which not only avoids the costly process of 3D annotation, but also eliminates the need for per-scene training. Extensive experiments demonstrate that our method achieves state-of-the-art visual grounding performance while avoiding per-scene training, providing a solid foundation for zero-shot 3DVG research. Video demos can be found in <a target="_blank" rel="noopener" href="https://github.com/leviome/GVR_demos">https://github.com/leviome/GVR_demos</a>. </p>
<blockquote>
<p>3Dè§†è§‰å®šä½ï¼ˆ3DVGï¼‰æ—¨åœ¨æ ¹æ®æ–‡æœ¬æç¤ºå®šä½3Dåœºæ™¯ä¸­çš„ç‰©ä½“ï¼Œè¿™å¯¹äºæœºå™¨äººç­‰é¢†åŸŸçš„åº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„3DVGæ–¹æ³•é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šé¦–å…ˆï¼Œä»–ä»¬éš¾ä»¥å¤„ç†3Dé«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰ä¸­ç©ºé—´çº¹ç†çš„éšå¼è¡¨ç¤ºï¼Œä½¿å¾—æ¯åœºæ™¯è®­ç»ƒå˜å¾—å¿…ä¸å¯å°‘ï¼›å…¶æ¬¡ï¼Œä»–ä»¬é€šå¸¸éœ€è¦å¤§é‡çš„æ ‡è®°æ•°æ®è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†é€šè¿‡è§†å›¾æ£€ç´¢ï¼ˆGVRï¼‰è¿›è¡Œå®šä½çš„æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„é›¶æ ·æœ¬è§†è§‰å®šä½æ¡†æ¶ï¼Œç”¨äºå°†3DVGè½¬åŒ–ä¸ºä¸€ä¸ªåˆ©ç”¨å¯¹è±¡çº§è§†å›¾æ£€ç´¢çš„äºŒç»´æ£€ç´¢ä»»åŠ¡ï¼Œä»ä¸åŒè§†è§’æ”¶é›†å®šä½çº¿ç´¢ã€‚è¿™ä¸ä»…é¿å…äº†æ˜‚è´µçš„ä¸‰ç»´æ ‡æ³¨è¿‡ç¨‹ï¼Œè€Œä¸”æ¶ˆé™¤äº†å¯¹æ¯åœºæ™¯è®­ç»ƒçš„éœ€æ±‚ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„è§†è§‰å®šä½æ€§èƒ½ï¼Œé¿å…äº†æ¯åœºæ™¯è®­ç»ƒï¼Œä¸ºé›¶æ ·æœ¬çš„3DVGç ”ç©¶æä¾›äº†åšå®çš„åŸºç¡€ã€‚è§†é¢‘æ¼”ç¤ºå¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/leviome/GVR_demos">https://github.com/leviome/GVR_demos</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15871v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ–‡æœ¬çš„3Dç‰©ä½“å®šä½ï¼ˆ3DVGï¼‰æŠ€æœ¯åœ¨æœºå™¨äººç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´å¤„ç†3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰ä¸­çš„ç©ºé—´çº¹ç†éšå¼è¡¨ç¤ºçš„æŒ‘æˆ˜ï¼Œå¹¶éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†GVRï¼ˆåŸºäºè§†å›¾æ£€ç´¢çš„æ¥åœ°ï¼‰ï¼Œä¸€ç§æ–°é¢–çš„é›¶æ ·æœ¬è§†è§‰æ¥åœ°æ¡†æ¶ï¼Œå°†3DVGè½¬åŒ–ä¸º2Dæ£€ç´¢ä»»åŠ¡ï¼Œä»å¤šä¸ªè§†å›¾æ”¶é›†æ¥åœ°çº¿ç´¢ï¼Œé¿å…äº†æ˜‚è´µçš„3Dæ ‡æ³¨è¿‡ç¨‹ï¼Œå¹¶æ— éœ€åœºæ™¯è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†å…ˆè¿›çš„è§†è§‰å®šä½æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D Visual Grounding (3DVG) æŠ€æœ¯æ—¨åœ¨æ ¹æ®æ–‡æœ¬æç¤ºåœ¨3Dåœºæ™¯ä¸­è¿›è¡Œç‰©ä½“å®šä½ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤„ç†3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰ä¸­çš„ç©ºé—´çº¹ç†è¡¨ç¤ºæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºçš„GVRæ¡†æ¶å°†3DVGè½¬åŒ–ä¸º2Dæ£€ç´¢ä»»åŠ¡ï¼Œé€šè¿‡å¯¹è±¡çº§åˆ«çš„è§†å›¾æ£€ç´¢æ”¶é›†æ¥åœ°çº¿ç´¢ã€‚</li>
<li>GVRé¿å…äº†æ˜‚è´µçš„3Dæ ‡æ³¨è¿‡ç¨‹ï¼Œå¹¶æ— éœ€æ¯ä¸ªåœºæ™¯è¿›è¡Œå•ç‹¬è®­ç»ƒã€‚</li>
<li>GVRå®ç°äº†å…ˆè¿›çš„è§†è§‰å®šä½æ€§èƒ½ã€‚</li>
<li>GVRä¸ºæœªæ¥çš„é›¶æ ·æœ¬3DVGç ”ç©¶å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15871">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-918e25a5277ec5f173928c00bfb94fc1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427140&auth_key=1760427140-0-0-22229f414beba4ea50738465dbd80e19&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f759c5337e9f342e8db1fa60d70723f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427148&auth_key=1760427148-0-0-dc2364a8c1920278dd8c1b700020ac7c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9f85adfacde81834864aad82b327501b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427155&auth_key=1760427155-0-0-b69ba1f89b678756bdac7fd0da004291&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-923ab6d741910e694a2398e943fe50c1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427162&auth_key=1760427162-0-0-d23c90f6dc0ecf00c8b5fc5354ae4585&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="MS-GS-Multi-Appearance-Sparse-View-3D-Gaussian-Splatting-in-the-Wild"><a href="#MS-GS-Multi-Appearance-Sparse-View-3D-Gaussian-Splatting-in-the-Wild" class="headerlink" title="MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild"></a>MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild</h2><p><strong>Authors:Deming Li, Kaiwen Jiang, Yutao Tang, Ravi Ramamoorthi, Rama Chellappa, Cheng Peng</strong></p>
<p>In-the-wild photo collections often contain limited volumes of imagery and exhibit multiple appearances, e.g., taken at different times of day or seasons, posing significant challenges to scene reconstruction and novel view synthesis. Although recent adaptations of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3DGS) have improved in these areas, they tend to oversmooth and are prone to overfitting. In this paper, we present MS-GS, a novel framework designed with Multi-appearance capabilities in Sparse-view scenarios using 3DGS. To address the lack of support due to sparse initializations, our approach is built on the geometric priors elicited from monocular depth estimations. The key lies in extracting and utilizing local semantic regions with a Structure-from-Motion (SfM) points anchored algorithm for reliable alignment and geometry cues. Then, to introduce multi-view constraints, we propose a series of geometry-guided supervision at virtual views in a fine-grained and coarse scheme to encourage 3D consistency and reduce overfitting. We also introduce a dataset and an in-the-wild experiment setting to set up more realistic benchmarks. We demonstrate that MS-GS achieves photorealistic renderings under various challenging sparse-view and multi-appearance conditions and outperforms existing approaches significantly across different datasets. </p>
<blockquote>
<p>åœ¨é‡å¤–çš„ç…§ç‰‡é›†é€šå¸¸åŒ…å«æœ‰é™çš„å›¾åƒé‡ï¼Œå¹¶ä¸”å‘ˆç°å‡ºå¤šç§å¤–è§‚ï¼Œä¾‹å¦‚åœ¨ä¸€å¤©çš„ä¸åŒæ—¶é—´æˆ–å­£èŠ‚æ‹æ‘„çš„ç…§ç‰‡ï¼Œç»™åœºæ™¯é‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡æœ€è¿‘å¯¹ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œ3Dé«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰çš„æ”¹ç¼–åœ¨è¿™äº›é¢†åŸŸæœ‰æ‰€æ”¹è¿›ï¼Œä½†å®ƒä»¬å¾€å¾€è¿‡äºå¹³æ»‘ä¸”å®¹æ˜“è¿‡åº¦æ‹Ÿåˆã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MS-GSï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨3DGSåœ¨ç¨€ç–è§†å›¾åœºæ™¯ä¸­çš„å¤šå¤–è§‚åŠŸèƒ½ã€‚ä¸ºäº†è§£å†³ç”±äºç¨€ç–åˆå§‹åŒ–è€Œå¯¼è‡´çš„æ”¯æŒä¸è¶³çš„é—®é¢˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨ä»å•ç›®æ·±åº¦ä¼°è®¡ä¸­å¼•å‘çš„å‡ ä½•å…ˆéªŒä¹‹ä¸Šã€‚å…³é”®åœ¨äºæå–å’Œåˆ©ç”¨å…·æœ‰ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰ç‚¹é”šå®šç®—æ³•çš„æœ¬åœ°ä¸Šä¸‹æ–‡åŒºåŸŸæ¥å®ç°å¯é çš„å¯¹é½å’Œå‡ ä½•çº¿ç´¢ã€‚ç„¶åï¼Œä¸ºäº†å¼•å…¥å¤šè§†å›¾çº¦æŸï¼Œæˆ‘ä»¬åœ¨ç²¾ç»†å’Œç²—ç•¥çš„æ–¹æ¡ˆä¸­æå‡ºäº†ä¸€ç³»åˆ—å‡ ä½•æŒ‡å¯¼çš„ç›‘ç£åœ¨è™šæ‹Ÿè§†å›¾ä¸Šï¼Œä»¥é¼“åŠ±3Dä¸€è‡´æ€§å¹¶å‡å°‘è¿‡åº¦æ‹Ÿåˆã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ä¸ªæ•°æ®é›†å’Œä¸€ä¸ªé‡å¤–å®éªŒè®¾ç½®ï¼Œä»¥å»ºç«‹æ›´ç°å®çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒMS-GSåœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¨€ç–è§†å›¾å’Œå¤šå¤–è§‚æ¡ä»¶ä¸‹å®ç°äº†é€¼çœŸçš„æ¸²æŸ“ï¼Œå¹¶ä¸”åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15548v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMS-GSçš„æ–°æ¡†æ¶ï¼Œç”¨äºå¤„ç†å…·æœ‰ä¸åŒæ—¶é—´å’Œå­£èŠ‚å˜åŒ–çš„å¤šè§†è§’åœºæ™¯ã€‚å®ƒç»“åˆäº†Neural Radiance Fieldå’Œ3D Gaussian SplattingæŠ€æœ¯ï¼Œé€šè¿‡å¼•å…¥å‡ ä½•å…ˆéªŒä¿¡æ¯å’Œç»“æ„ä»è¿åŠ¨ç®—æ³•ï¼Œè§£å†³äº†ç¨€ç–åˆå§‹åŒ–çš„é—®é¢˜ï¼Œæé«˜äº†åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆçš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸€ç³»åˆ—å‡ ä½•å¼•å¯¼çš„ç²¾ç»†ä¸ç²—ç³™çš„ç›‘ç£æ–¹å¼å¼•å…¥å¤šè§†è§’çº¦æŸï¼Œä»¥é¼“åŠ±ä¸‰ç»´ä¸€è‡´æ€§å¹¶å‡å°‘è¿‡æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªæ•°æ®é›†å’Œå®éªŒè®¾ç½®ï¼Œä»¥å»ºç«‹æ›´ç°å®çš„åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMS-GSåœ¨å¤„ç†å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¨€ç–è§†è§’å’Œå¤šè§†è§’æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿå®ç°é€¼çœŸçš„æ¸²æŸ“æ•ˆæœï¼Œå¹¶åœ¨ä¸åŒæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MS-GSæ¡†æ¶ç»“åˆäº†Neural Radiance Fieldå’Œ3D Gaussian SplattingæŠ€æœ¯ï¼Œæ—¨åœ¨å¤„ç†å…·æœ‰å¤šç§å¤–è§‚ï¼ˆå¦‚ä¸åŒæ—¶é—´å’Œå­£èŠ‚ï¼‰çš„é‡å¤–ç…§ç‰‡é›†ã€‚</li>
<li>è¯¥æ¡†æ¶è§£å†³äº†ç¨€ç–åˆå§‹åŒ–çš„é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥å‡ ä½•å…ˆéªŒä¿¡æ¯å’Œç»“æ„ä»è¿åŠ¨ç®—æ³•æé«˜åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆçš„æ€§èƒ½ã€‚</li>
<li>é€šè¿‡å‡ ä½•å¼•å¯¼çš„ç²¾ç»†ä¸ç²—ç³™çš„ç›‘ç£æ–¹å¼å¼•å…¥å¤šè§†è§’çº¦æŸï¼Œä»¥å¢å¼ºä¸‰ç»´ä¸€è‡´æ€§å¹¶å‡å°‘è¿‡æ‹Ÿåˆç°è±¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®é›†å’Œå®éªŒè®¾ç½®ï¼Œæ—¨åœ¨å»ºç«‹æ›´ç°å®çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ–¹æ³•åœ¨é‡å¤–ç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒMS-GSåœ¨å¤„ç†å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¨€ç–è§†è§’å’Œå¤šè§†è§’æ¡ä»¶ä¸‹è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>MS-GSå®ç°äº†é€¼çœŸçš„æ¸²æŸ“æ•ˆæœï¼Œå¹¶åœ¨ä¸åŒæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15548">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cebc2722a2395e437d121c92ee7fee03~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427169&auth_key=1760427169-0-0-2f9120f2ab11f895cd8f690911cd34db&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a7ed8b0f79bac996f315aacdbcf60c80~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427176&auth_key=1760427176-0-0-5eef28b12b6badd5e2fa350ecbebd71b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ac5d4f8c1734668ecc01b9dacc868914~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427183&auth_key=1760427183-0-0-819ce307e8244e81c492d0a0cf4509a6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b2574253e10f006f39a995e932511356~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427190&auth_key=1760427190-0-0-0199226f3da8595e42370fb363413e98&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="AD-GS-Alternating-Densification-for-Sparse-Input-3D-Gaussian-Splatting"><a href="#AD-GS-Alternating-Densification-for-Sparse-Input-3D-Gaussian-Splatting" class="headerlink" title="AD-GS: Alternating Densification for Sparse-Input 3D Gaussian Splatting"></a>AD-GS: Alternating Densification for Sparse-Input 3D Gaussian Splatting</h2><p><strong>Authors:Gurutva Patle, Nilay Girgaonkar, Nagabhushan Somraj, Rajiv Soundararajan</strong></p>
<p>3D Gaussian Splatting (3DGS) has shown impressive results in real-time novel view synthesis. However, it often struggles under sparse-view settings, producing undesirable artifacts such as floaters, inaccurate geometry, and overfitting due to limited observations. We find that a key contributing factor is uncontrolled densification, where adding Gaussian primitives rapidly without guidance can harm geometry and cause artifacts. We propose AD-GS, a novel alternating densification framework that interleaves high and low densification phases. During high densification, the model densifies aggressively, followed by photometric loss based training to capture fine-grained scene details. Low densification then primarily involves aggressive opacity pruning of Gaussians followed by regularizing their geometry through pseudo-view consistency and edge-aware depth smoothness. This alternating approach helps reduce overfitting by carefully controlling model capacity growth while progressively refining the scene representation. Extensive experiments on challenging datasets demonstrate that AD-GS significantly improves rendering quality and geometric consistency compared to existing methods. The source code for our model can be found on our project page: <a target="_blank" rel="noopener" href="https://gurutvapatle.github.io/publications/2025/ADGS.html">https://gurutvapatle.github.io/publications/2025/ADGS.html</a> . </p>
<blockquote>
<p>3Dé«˜æ–¯æ··åˆæŠ€æœ¯ï¼ˆ3DGSï¼‰åœ¨å®æ—¶åˆæˆæ–°è§†è§’å›¾åƒæ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœã€‚ç„¶è€Œï¼Œå®ƒåœ¨ç¨€ç–è§†è§’ç¯å¢ƒä¸‹é€šå¸¸å­˜åœ¨æŒ‘æˆ˜ï¼Œäº§ç”Ÿäº†æµ®å­ã€å‡ ä½•ä¸ç²¾ç¡®ä»¥åŠè¿‡æ‹Ÿåˆç­‰ä¸å¸Œæœ›å‡ºç°çš„ä¼ªå½±ï¼Œè¿™æ˜¯ç”±äºè§‚æµ‹æ•°æ®æœ‰é™å¯¼è‡´çš„ã€‚æˆ‘ä»¬å‘ç°ï¼Œå…³é”®å½±å“å› ç´ åœ¨äºæœªæ§åˆ¶çš„å¯†é›†åŒ–ï¼Œå³åœ¨æ²¡æœ‰æŒ‡å¯¼çš„æƒ…å†µä¸‹å¿«é€Ÿæ·»åŠ é«˜æ–¯åŸºæœ¬ä½“å¯èƒ½ä¼šæŸå®³å‡ ä½•ç»“æ„å¹¶å¯¼è‡´ä¼ªå½±ã€‚æˆ‘ä»¬æå‡ºäº†AD-GSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„äº¤æ›¿å¯†é›†åŒ–æ¡†æ¶ï¼Œå®ƒäº¤æ›¿è¿›è¡Œé«˜å¯†é›†åŒ–é˜¶æ®µå’Œä½å¯†é›†åŒ–é˜¶æ®µã€‚åœ¨é«˜å¯†é›†åŒ–é˜¶æ®µï¼Œæ¨¡å‹ä¼šå¯†é›†åœ°æ‰©å±•ï¼Œéšåé€šè¿‡åŸºäºå…‰åº¦æŸå¤±çš„åŸ¹è®­æ¥æ•æ‰åœºæ™¯çš„ç²¾ç»†ç»†èŠ‚ã€‚ä½å¯†é›†åŒ–åˆ™ä¸»è¦æ¶‰åŠé«˜æ–¯çš„ä¸é€æ˜åº¦ä¿®å‰ªï¼Œç„¶åé€šè¿‡ä¼ªè§†ä¸€è‡´æ€§è¾¹ç¼˜æ„ŸçŸ¥æ·±åº¦å¹³æ»‘å¯¹å…¶è¿›è¡Œå‡ ä½•æ­£åˆ™åŒ–ã€‚è¿™ç§äº¤æ›¿çš„æ–¹æ³•é€šè¿‡è°¨æ…æ§åˆ¶æ¨¡å‹å®¹é‡çš„å¢é•¿ï¼ŒåŒæ—¶é€æ­¥ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºï¼Œæœ‰åŠ©äºå‡å°‘è¿‡æ‹Ÿåˆç°è±¡ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAD-GSæ˜¾è‘—æé«˜äº†æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„æ¨¡å‹æºä»£ç å¯ä»¥åœ¨é¡¹ç›®é¡µé¢æ‰¾åˆ°ï¼š[<a target="_blank" rel="noopener" href="https://gurutvapatle.github.io/publications/2025/ADGS.html]%E3%80%82">https://gurutvapatle.github.io/publications/2025/ADGS.html]ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11003v2">PDF</a> SIGGRAPH Asia 2025</p>
<p><strong>Summary</strong></p>
<p>å®æ—¶åœºæ™¯ä¸‹çš„æ–°å‹è§†è§’åˆæˆæŠ€æœ¯ä¸­ï¼ŒAD-GSæ–¹æ¡ˆè¡¨ç°ä¼˜ç§€ï¼Œå®ƒåœ¨é«˜æ–¯ç‚¹å¢é•¿ä¸Šæœ‰æ–°é¢–çš„å‘¨æœŸæ€§å˜æ¢æ–¹æ¡ˆï¼ˆäº¤æ›¿ç¨ åŒ–ï¼‰ã€‚è¿™å¤§å¤§æ”¹å–„äº†åŸæœ‰æ–¹æ¡ˆçš„æµ®ç‚¹å’Œè¿‡åº¦æ‹Ÿåˆç­‰é—®é¢˜ã€‚åœ¨ä¸åŒéš¾åº¦åœºæ™¯ä¸‹è¿›è¡Œäº†å®éªŒï¼ŒAD-GSéƒ½èƒ½æ˜¾è‘—ä¼˜åŒ–æ¸²æŸ“è´¨é‡å¹¶ä¿æŒå‡ ä½•ä¸€è‡´æ€§ã€‚è¯¦ç»†ä¿¡æ¯è¯·æŸ¥é˜…é¡¹ç›®ç½‘é¡µé“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://gurutvapatle.github.io/publications/2025/ADGS.html">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AD-GSé’ˆå¯¹ç¨€ç–è§†è§’åœºæ™¯ä¸‹çš„3DGSæŠ€æœ¯è¿›è¡Œä¼˜åŒ–ï¼Œè§£å†³äº†æµ®ç‚¹å’Œå‡ ä½•å¤±çœŸç­‰é—®é¢˜ã€‚</li>
<li>æå‡ºäº¤æ›¿ç¨ åŒ–ç­–ç•¥ï¼Œåœ¨é«˜å¯†åº¦é˜¶æ®µé€šè¿‡è®­ç»ƒæ•æ‰ç»†èŠ‚ï¼Œä½å¯†åº¦é˜¶æ®µåˆ™ä¼˜åŒ–å‡ ä½•ç»“æ„ã€‚</li>
<li>é«˜å¯†åº¦é˜¶æ®µä¸»è¦å¯†é›†å¢é•¿æ¨¡å‹ï¼Œè€Œä½å¯†åº¦é˜¶æ®µæ³¨é‡å‰”é™¤å†—ä½™é«˜æ–¯ç‚¹å¹¶ä¼˜åŒ–å‡ ä½•ç»“æ„ã€‚</li>
<li>é€šè¿‡ä¼ªè§†è§’ä¸€è‡´æ€§åŠè¾¹ç¼˜æ„ŸçŸ¥æ·±åº¦å¹³æ»‘æ¥å¢å¼ºå‡ ä½•ç»“æ„æ­£åˆ™åŒ–ã€‚</li>
<li>AD-GSæ¨¡å‹åœ¨å¤šç§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜å…¶æ˜¾è‘—æé«˜äº†æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ä¸€è‡´æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11003">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2394ef54a8077dee5f43a98b99968aa5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427197&auth_key=1760427197-0-0-a09adf0489e9698c073aca458ab56f4b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0752d730f8348c9b88c6e24851b7dc2d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427205&auth_key=1760427205-0-0-d306fcb9d4e5d8374bd1f4e43464d31b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4770f8eb6fac75560fa7be4834b6d1f1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427212&auth_key=1760427212-0-0-4aa34c3e0a822aed1c430d9d643d967a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c6c6fa4f2733957627a0d2bc1d51e014~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427219&auth_key=1760427219-0-0-03c69f35aa9028e27de8a63f26b2172c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4d75872e396825952912ae349322fe3f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427226&auth_key=1760427226-0-0-2a22d71ed0de354f5d0409d04e75ab28&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e114d1803777fd50f2690e4b4ddcfdc2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427233&auth_key=1760427233-0-0-f03689f870d7e290dea1700422cbfcba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="GeoSplat-A-Deep-Dive-into-Geometry-Constrained-Gaussian-Splatting"><a href="#GeoSplat-A-Deep-Dive-into-Geometry-Constrained-Gaussian-Splatting" class="headerlink" title="GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting"></a>GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting</h2><p><strong>Authors:Yangming Li, Chaoyu Liu, Lihao Liu, Simon Masnou, Carola-Bibiane SchÃ¶nlieb</strong></p>
<p>A few recent works explored incorporating geometric priors to regularize the optimization of Gaussian splatting, further improving its performance. However, those early studies mainly focused on the use of low-order geometric priors (e.g., normal vector), and they are also unreliably estimated by noise-sensitive methods, like local principal component analysis. To address their limitations, we first present GeoSplat, a general geometry-constrained optimization framework that exploits both first-order and second-order geometric quantities to improve the entire training pipeline of Gaussian splatting, including Gaussian initialization, gradient update, and densification. As an example, we initialize the scales of 3D Gaussian primitives in terms of principal curvatures, leading to a better coverage of the object surface than random initialization. Secondly, based on certain geometric structures (e.g., local manifold), we introduce efficient and noise-robust estimation methods that provide dynamic geometric priors for our framework. We conduct extensive experiments on multiple datasets for novel view synthesis, showing that our framework: GeoSplat, significantly improves the performance of Gaussian splatting and outperforms previous baselines. </p>
<blockquote>
<p>è¿‘æœŸæœ‰å‡ é¡¹ç ”ç©¶å°è¯•å°†å‡ ä½•å…ˆéªŒçŸ¥è¯†èå…¥é«˜æ–¯æ¶‚æ–‘ï¼ˆGaussian Splattingï¼‰çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œä»¥è¿›ä¸€æ­¥æå‡å…¶æ€§èƒ½ã€‚ç„¶è€Œï¼Œæ—©æœŸçš„ç ”ç©¶ä¸»è¦å…³æ³¨ä½é˜¶å‡ ä½•å…ˆéªŒçŸ¥è¯†çš„ä½¿ç”¨ï¼ˆä¾‹å¦‚æ³•å‘é‡ï¼‰ï¼Œå¹¶ä¸”å®ƒä»¬ä¸»è¦é€šè¿‡å¯¹å™ªå£°æ•æ„Ÿçš„æ–¹æ³•ï¼ˆå¦‚å±€éƒ¨ä¸»æˆåˆ†åˆ†æï¼‰è¿›è¡Œä¼°ç®—ï¼Œè¿™ä¼šå¯¼è‡´ä¼°ç®—ç»“æœä¸å¯é ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†GeoSplatï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„å‡ ä½•çº¦æŸä¼˜åŒ–æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸€é˜¶å’ŒäºŒé˜¶å‡ ä½•é‡æ¥æ”¹å–„é«˜æ–¯æ¶‚æ–‘çš„æ•´ä¸ªè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬é«˜æ–¯åˆå§‹åŒ–ã€æ¢¯åº¦æ›´æ–°å’Œå¯†é›†åŒ–ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ ¹æ®ä¸»æ›²ç‡æ¥åˆå§‹åŒ–3Dé«˜æ–¯åŸºå…ƒçš„å°ºåº¦ï¼Œç›¸è¾ƒäºéšæœºåˆå§‹åŒ–ï¼Œè¿™èƒ½æ›´å¥½åœ°è¦†ç›–ç‰©ä½“è¡¨é¢ã€‚å…¶æ¬¡ï¼ŒåŸºäºæŸäº›å‡ ä½•ç»“æ„ï¼ˆå¦‚å±€éƒ¨æµå½¢ï¼‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†é«˜æ•ˆä¸”å¯¹å™ªå£°é²æ£’çš„ä¼°è®¡æ–¹æ³•ï¼Œä¸ºæˆ‘ä»¬çš„æ¡†æ¶æä¾›åŠ¨æ€å‡ ä½•å…ˆéªŒçŸ¥è¯†ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å…³äºæ–°å‹è§†å›¾åˆæˆçš„å®éªŒï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ¡†æ¶GeoSplatèƒ½æ˜¾è‘—æ”¹å–„é«˜æ–¯æ¶‚æ–‘çš„æ€§èƒ½å¹¶è¶…è¶Šä¹‹å‰çš„åŸºçº¿æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05075v2">PDF</a> </p>
<p><strong>Summary</strong><br>     è¿‘æœŸç ”ç©¶å°è¯•å°†å‡ ä½•å…ˆéªŒçŸ¥è¯†å¼•å…¥é«˜æ–¯æ’å€¼çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œä»¥æå‡å…¶æ€§èƒ½ã€‚æ—©æœŸç ”ç©¶ä¸»è¦å…³æ³¨ä½é˜¶å‡ ä½•å…ˆéªŒçŸ¥è¯†çš„åº”ç”¨ï¼Œå¦‚æ³•å‘é‡ç­‰ï¼Œå¹¶å—é™äºå™ªå£°æ•æ„Ÿçš„æ–¹æ³•ï¼ˆå¦‚å±€éƒ¨ä¸»æˆåˆ†åˆ†æï¼‰å¯¼è‡´ä¼°è®¡ä¸å‡†ç¡®çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºGeoSplatæ¡†æ¶ï¼Œåˆ©ç”¨ä¸€é˜¶å’ŒäºŒé˜¶å‡ ä½•é‡æ”¹å–„é«˜æ–¯æ’å€¼çš„æ•´ä¸ªè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬é«˜æ–¯åˆå§‹åŒ–ã€æ¢¯åº¦æ›´æ–°å’Œå¯†é›†åŒ–ã€‚é€šè¿‡åŸºäºä¸»æ›²ç‡çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œå®ç°æ¯”éšæœºåˆå§‹åŒ–æ›´å¥½çš„ç‰©ä½“è¡¨é¢è¦†ç›–æ•ˆæœã€‚æ­¤å¤–ï¼ŒåŸºäºæŸäº›å‡ ä½•ç»“æ„ï¼ˆå¦‚å±€éƒ¨æµå½¢ï¼‰ï¼Œæœ¬æ–‡å¼•å…¥é«˜æ•ˆä¸”æŠ—å™ªå£°çš„ä¼°è®¡æ–¹æ³•ï¼Œä¸ºæ¡†æ¶æä¾›åŠ¨æ€å‡ ä½•å…ˆéªŒã€‚å®éªŒè¯æ˜ï¼ŒGeoSplatæ¡†æ¶èƒ½æ˜¾è‘—æå‡é«˜æ–¯æ’å€¼æ€§èƒ½å¹¶è¶…è¶Šå…ˆå‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿‘æœŸç ”ç©¶å°†å‡ ä½•å…ˆéªŒçŸ¥è¯†å¼•å…¥é«˜æ–¯æ’å€¼çš„ä¼˜åŒ–ä¸­ï¼Œæ—¨åœ¨æé«˜å…¶æ€§èƒ½ã€‚</li>
<li>æ—©æœŸç ”ç©¶ä¸»è¦å…³æ³¨ä½é˜¶å‡ ä½•å…ˆéªŒçš„åº”ç”¨ï¼Œä½†å­˜åœ¨å™ªå£°æ•æ„Ÿé—®é¢˜ã€‚</li>
<li>GeoSplatæ¡†æ¶åˆ©ç”¨ä¸€é˜¶å’ŒäºŒé˜¶å‡ ä½•é‡æ”¹å–„é«˜æ–¯æ’å€¼çš„æ•´ä¸ªè®­ç»ƒæµç¨‹ã€‚</li>
<li>é€šè¿‡åŸºäºä¸»æ›²ç‡çš„åˆå§‹åŒ–æ–¹æ³•ï¼ŒGeoSplatå®ç°æ›´å¥½çš„ç‰©ä½“è¡¨é¢è¦†ç›–æ•ˆæœã€‚</li>
<li>GeoSplatå¼•å…¥é«˜æ•ˆä¸”æŠ—å™ªå£°çš„ä¼°è®¡æ–¹æ³•ï¼Œä¸ºæ¡†æ¶æä¾›åŠ¨æ€å‡ ä½•å…ˆéªŒã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒGeoSplatæ¡†æ¶èƒ½æ˜¾è‘—æå‡é«˜æ–¯æ’å€¼çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05075">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-435a2ff1ed47fd326e011cd3339fd9bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427240&auth_key=1760427240-0-0-da2ee4203323a77ce6d00a6a3ac0f9a5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="DriveSplat-Decoupled-Driving-Scene-Reconstruction-with-Geometry-enhanced-Partitioned-Neural-Gaussians"><a href="#DriveSplat-Decoupled-Driving-Scene-Reconstruction-with-Geometry-enhanced-Partitioned-Neural-Gaussians" class="headerlink" title="DriveSplat: Decoupled Driving Scene Reconstruction with   Geometry-enhanced Partitioned Neural Gaussians"></a>DriveSplat: Decoupled Driving Scene Reconstruction with   Geometry-enhanced Partitioned Neural Gaussians</h2><p><strong>Authors:Cong Wang, Xianda Guo, Wenbo Xu, Wei Tian, Ruiqi Song, Chenming Zhang, Lingxi Li, Long Chen</strong></p>
<p>In the realm of driving scenarios, the presence of rapidly moving vehicles, pedestrians in motion, and large-scale static backgrounds poses significant challenges for 3D scene reconstruction. Recent methods based on 3D Gaussian Splatting address the motion blur problem by decoupling dynamic and static components within the scene. However, these decoupling strategies overlook background optimization with adequate geometry relationships and rely solely on fitting each training view by adding Gaussians. Therefore, these models exhibit limited robustness in rendering novel views and lack an accurate geometric representation. To address the above issues, we introduce DriveSplat, a high-quality reconstruction method for driving scenarios based on neural Gaussian representations with dynamic-static decoupling. To better accommodate the predominantly linear motion patterns of driving viewpoints, a region-wise voxel initialization scheme is employed, which partitions the scene into near, middle, and far regions to enhance close-range detail representation. Deformable neural Gaussians are introduced to model non-rigid dynamic actors, whose parameters are temporally adjusted by a learnable deformation network. The entire framework is further supervised by depth and normal priors from pre-trained models, improving the accuracy of geometric structures. Our method has been rigorously evaluated on the Waymo and KITTI datasets, demonstrating state-of-the-art performance in novel-view synthesis for driving scenarios. </p>
<blockquote>
<p>åœ¨é©¾é©¶åœºæ™¯é¢†åŸŸï¼Œå¿«é€Ÿç§»åŠ¨è½¦è¾†ã€è¿åŠ¨ä¸­çš„è¡Œäººå’Œå¤§è§„æ¨¡é™æ€èƒŒæ™¯çš„å­˜åœ¨å¯¹3Dåœºæ™¯é‡å»ºæ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æœ€è¿‘åŸºäº3Dé«˜æ–¯æ‹¼è´´çš„æ–¹æ³•é€šè¿‡è§£è€¦åœºæ™¯å†…çš„åŠ¨æ€å’Œé™æ€æˆåˆ†æ¥è§£å†³è¿åŠ¨æ¨¡ç³Šé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›è§£è€¦ç­–ç•¥å¿½ç•¥äº†èƒŒæ™¯ä¼˜åŒ–çš„å……è¶³å‡ ä½•å…³ç³»ï¼Œä»…ä¾èµ–äºé€šè¿‡æ·»åŠ é«˜æ–¯æ¥æ‹Ÿåˆæ¯ä¸ªè®­ç»ƒè§†å›¾ã€‚å› æ­¤ï¼Œè¿™äº›æ¨¡å‹åœ¨å‘ˆç°æ–°è§†å›¾æ–¹é¢è¡¨ç°å‡ºæœ‰é™çš„ç¨³å¥æ€§ï¼Œå¹¶ä¸”ç¼ºä¹ç²¾ç¡®å‡ ä½•è¡¨ç¤ºã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†DriveSplatï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç¥ç»é«˜æ–¯è¡¨ç¤ºå’ŒåŠ¨é™è§£è€¦çš„é©¾é©¶åœºæ™¯é«˜è´¨é‡é‡å»ºæ–¹æ³•ã€‚ä¸ºäº†æ›´å¥½åœ°é€‚åº”é©¾é©¶è§‚ç‚¹çš„ä¸»è¦çº¿æ€§è¿åŠ¨æ¨¡å¼ï¼Œé‡‡ç”¨åŒºåŸŸåŒ–ä½“ç´ åˆå§‹åŒ–æ–¹æ¡ˆï¼Œå°†åœºæ™¯åˆ’åˆ†ä¸ºè¿‘ã€ä¸­ã€è¿œåŒºåŸŸï¼Œä»¥å¢å¼ºè¿‘è·ç¦»ç»†èŠ‚çš„è¡¨ç¤ºã€‚æˆ‘ä»¬å¼•å…¥äº†å¯å˜å½¢ç¥ç»é«˜æ–¯æ¥æ¨¡æ‹Ÿéåˆšæ€§åŠ¨æ€å‚ä¸è€…ï¼Œå…¶å‚æ•°ç”±å¯å­¦ä¹ å˜å½¢ç½‘ç»œè¿›è¡Œæ—¶é—´è°ƒæ•´ã€‚æ•´ä¸ªæ¡†æ¶è¿˜å—åˆ°é¢„è®­ç»ƒæ¨¡å‹çš„æ·±åº¦å’Œæ³•çº¿å…ˆéªŒçš„ç›‘ç£ï¼Œæé«˜äº†å‡ ä½•ç»“æ„çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨Waymoå’ŒKITTIæ•°æ®é›†ä¸Šè¿›è¡Œäº†ä¸¥æ ¼è¯„ä¼°ï¼Œåœ¨é©¾é©¶åœºæ™¯çš„æ–°è§†å›¾åˆæˆæ–¹é¢è¡¨ç°å‡ºæœ€æ–°æŠ€æœ¯æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.15376v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†ä¸€ç§åŸºäºç¥ç»é«˜æ–¯è¡¨ç¤ºçš„é«˜è´¨é‡çš„é©¾é©¶åœºæ™¯é‡å»ºæ–¹æ³•DriveSplatï¼Œé‡‡ç”¨åŠ¨æ€é™æ€è§£è€¦æŠ€æœ¯ï¼Œä»¥è§£å†³é©¾é©¶åœºæ™¯ä¸­å¿«é€Ÿç§»åŠ¨çš„è½¦è¾†ã€è¡Œäººä»¥åŠå¤§è§„æ¨¡é™æ€èƒŒæ™¯å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åŒºåŸŸæ€§çš„ä½“ç´ åˆå§‹åŒ–æ–¹æ¡ˆå¢å¼ºè¿‘è·ç¦»çš„ç»†èŠ‚è¡¨ç¤ºï¼Œå¹¶å¼•å…¥å¯å˜å½¢ç¥ç»é«˜æ–¯æ¥æ¨¡æ‹Ÿéåˆšæ€§çš„åŠ¨æ€ç‰©ä½“ã€‚æ•´ä¸ªæ¡†æ¶å—åˆ°æ¥è‡ªé¢„è®­ç»ƒæ¨¡å‹çš„æ·±åº¦å’Œæ³•çº¿å…ˆéªŒçš„ç›‘ç£ï¼Œæé«˜äº†å‡ ä½•ç»“æ„çš„å‡†ç¡®æ€§ã€‚åœ¨Waymoå’ŒKITTIæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é©¾é©¶åœºæ™¯çš„æ–°è§†è§’åˆæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DriveSplatæ˜¯ä¸€ç§é’ˆå¯¹é©¾é©¶åœºæ™¯çš„é‡å»ºæ–¹æ³•ï¼Œé‡‡ç”¨ç¥ç»é«˜æ–¯è¡¨ç¤ºå’ŒåŠ¨æ€é™æ€è§£è€¦æŠ€æœ¯ã€‚</li>
<li>æ–¹æ³•é€šè¿‡åŒºåŸŸæ€§çš„ä½“ç´ åˆå§‹åŒ–æ–¹æ¡ˆï¼Œå°†åœºæ™¯åˆ†ä¸ºè¿‘ã€ä¸­ã€è¿œåŒºåŸŸï¼Œä»¥å¢å¼ºè¿‘è·ç¦»çš„ç»†èŠ‚è¡¨ç¤ºã€‚</li>
<li>å¼•å…¥å¯å˜å½¢ç¥ç»é«˜æ–¯æ¥æ¨¡æ‹Ÿéåˆšæ€§çš„åŠ¨æ€ç‰©ä½“ï¼Œå¦‚è½¦è¾†å’Œè¡Œäººã€‚</li>
<li>æ•´ä¸ªæ¡†æ¶å—åˆ°æ·±åº¦å’Œæ³•çº¿å…ˆéªŒçš„ç›‘ç£ï¼Œä»¥æé«˜å‡ ä½•ç»“æ„çš„å‡†ç¡®æ€§ã€‚</li>
<li>æ–¹æ³•åœ¨Waymoå’ŒKITTIæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ˜¾ç¤ºå‡ºåœ¨æ–°è§†è§’åˆæˆé©¾é©¶åœºæ™¯æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†ç°æœ‰è§£è€¦ç­–ç•¥å¿½ç•¥èƒŒæ™¯ä¼˜åŒ–çš„é—®é¢˜ï¼Œå…·æœ‰æ›´å‡†ç¡®çš„å‡ ä½•è¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.15376">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5dd2df39baac9384448e78ed798681b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427248&auth_key=1760427248-0-0-55d40279b93a2d7239d5bf4c5f0fd1ec&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cee96cdfdda6412da705919f4435bccc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427256&auth_key=1760427256-0-0-5d1e5e28d1ded3dd06422bf96d23da30&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-92955fbfb3200d798ff63a1a4294d7cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427263&auth_key=1760427263-0-0-42f710dfe543b0567db7fccb697e26a7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a93732e7858d629516915612d510effd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427269&auth_key=1760427269-0-0-a460e504bb44ff5f1a8fb61c04a98313&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-624982d7dc322f0bed8a4b11e782b47b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427299&auth_key=1760427299-0-0-67a5b2b731227e9247a7e6c3e139da5d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-864502a0eb2dba327a9a1ba906da8248~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427306&auth_key=1760427306-0-0-cc2f5eabcb6c286168a99f07cf3423a2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-24/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-556ccf301cf768e79a373e3753415719~resize:0:q75.jpg?source=1f5c5e47&expiration=1760427313&auth_key=1760427313-0-0-48bab5532e19441adfa3e6dec5f7f2a3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  From Restoration to Reconstruction Rethinking 3D Gaussian Splatting for   Underwater Scenes
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-24/GAN/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-63a31023f0c4d33f3bb052ad5f1852fa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760426389&auth_key=1760426389-0-0-2a08f983d6efb5b2343c6e7ad656a124&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-24  HyPlaneHead Rethinking Tri-plane-like Representations in Full-Head   Image Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
