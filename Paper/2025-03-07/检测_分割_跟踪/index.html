<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-07  MIAdapt Source-free Few-shot Domain Adaptive Object Detection for   Microscopic Images">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-0f2b6bad5cba4fcaa7969fcd5e097b66.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    24 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-07-æ›´æ–°"><a href="#2025-03-07-æ›´æ–°" class="headerlink" title="2025-03-07 æ›´æ–°"></a>2025-03-07 æ›´æ–°</h1><h2 id="MIAdapt-Source-free-Few-shot-Domain-Adaptive-Object-Detection-for-Microscopic-Images"><a href="#MIAdapt-Source-free-Few-shot-Domain-Adaptive-Object-Detection-for-Microscopic-Images" class="headerlink" title="MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for   Microscopic Images"></a>MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for   Microscopic Images</h2><p><strong>Authors:Nimra Dilawar, Sara Nadeem, Javed Iqbal, Waqas Sultani, Mohsen Ali</strong></p>
<p>Existing generic unsupervised domain adaptation approaches require access to both a large labeled source dataset and a sufficient unlabeled target dataset during adaptation. However, collecting a large dataset, even if unlabeled, is a challenging and expensive endeavor, especially in medical imaging. In addition, constraints such as privacy issues can result in cases where source data is unavailable. Taking in consideration these challenges, we propose MIAdapt, an adaptive approach for Microscopic Imagery Adaptation as a solution for Source-free Few-shot Domain Adaptive Object detection (SF-FSDA). We also define two competitive baselines (1) Faster-FreeShot and (2) MT-FreeShot. Extensive experiments on the challenging M5-Malaria and Raabin-WBC datasets validate the effectiveness of MIAdapt. Without using any image from the source domain MIAdapt surpasses state-of-the-art source-free UDA (SF-UDA) methods by +21.3% mAP and few-shot domain adaptation (FSDA) approaches by +4.7% mAP on Raabin-WBC. Our code and models will be publicly available. </p>
<blockquote>
<p>ç°æœ‰çš„é€šç”¨æ— ç›‘ç£åŸŸè‡ªé€‚åº”æ–¹æ³•è¦æ±‚åœ¨é€‚åº”è¿‡ç¨‹ä¸­è®¿é—®å¤§é‡æ ‡è®°æºæ•°æ®é›†å’Œè¶³å¤Ÿçš„æ— æ ‡è®°ç›®æ ‡æ•°æ®é›†ã€‚ç„¶è€Œï¼Œæ”¶é›†å¤§æ•°æ®é›†ï¼Œå³ä½¿æ˜¯æ— æ ‡ç­¾çš„ï¼Œä¹Ÿæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§å’Œæ˜‚è´µçš„å·¥ä½œï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»å­¦å½±åƒé¢†åŸŸã€‚æ­¤å¤–ï¼Œéšç§é—®é¢˜ç­‰çº¦æŸå¯èƒ½å¯¼è‡´æºæ•°æ®ä¸å¯ç”¨ã€‚è€ƒè™‘åˆ°è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MIAdaptï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ˜¾å¾®é•œå›¾åƒè‡ªé€‚åº”çš„é€‚åº”æ€§æ–¹æ³•ï¼Œä½œä¸ºæ— æºåŸŸæ•°æ®ä½æ ·æœ¬åŸŸè‡ªé€‚åº”å¯¹è±¡æ£€æµ‹ï¼ˆSF-FSDAï¼‰çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬è¿˜å®šä¹‰äº†ä¸¤ä¸ªæœ‰ç«äº‰åŠ›çš„åŸºçº¿æ¨¡å‹ï¼šï¼ˆ1ï¼‰Faster-FreeShotå’Œï¼ˆ2ï¼‰MT-FreeShotã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„M5-Malariaå’ŒRaabin-WBCæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†MIAdaptçš„æœ‰æ•ˆæ€§ã€‚MIAdaptåœ¨ä¸ä½¿ç”¨ä»»ä½•æºåŸŸå›¾åƒçš„æƒ…å†µä¸‹ï¼Œåœ¨Raabin-WBCæ•°æ®é›†ä¸Šè¶…è¿‡äº†æœ€æ–°çš„æ— æºåŸŸè‡ªé€‚åº”ï¼ˆSF-UDAï¼‰æ–¹æ³•ï¼Œæé«˜äº†+21.3%çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆmAPï¼‰ï¼Œå¹¶ä¸”è¶…è¿‡äº†ä½æ ·æœ¬åŸŸè‡ªé€‚åº”ï¼ˆFSDAï¼‰æ–¹æ³•æé«˜äº†+4.7%çš„mAPã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å°†å…¬å¼€å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.03370v1">PDF</a> Under Review</p>
<p><strong>Summary</strong><br>æ•°æ®æºå—é™çš„æƒ…å†µä¸‹è¿›è¡ŒåŸŸè‡ªé€‚åº”ç‰©ä½“æ£€æµ‹æ˜¯æ–°çš„æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºMIAdaptæ–¹æ³•ç”¨äºæ˜¾å¾®é•œå›¾åƒåŸŸè‡ªé€‚åº”ï¼Œè§£å†³æ— æºå°‘æ ·æœ¬åŸŸè‡ªé€‚åº”ç‰©ä½“æ£€æµ‹ï¼ˆSF-FSDAï¼‰é—®é¢˜ã€‚é€šè¿‡M5ç–Ÿç–¾å’ŒRaabin-WBCæ•°æ®é›†çš„å®éªŒéªŒè¯ï¼ŒMIAdaptè¾ƒç°æœ‰çš„æºè‡ªç”±UDAï¼ˆSF-UDAï¼‰æ–¹æ³•å’Œå°‘æ ·æœ¬åŸŸè‡ªé€‚åº”ï¼ˆFSDAï¼‰æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œæé«˜äº†å¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰é€šç”¨æ— ç›‘ç£åŸŸè‡ªé€‚åº”æ–¹æ³•éœ€è¦å¤§é‡æ ‡æ³¨æºæ•°æ®é›†å’Œè¶³å¤Ÿçš„æœªæ ‡æ³¨ç›®æ ‡æ•°æ®é›†è¿›è¡Œé€‚åº”ï¼Œä½†åœ¨åŒ»ç–—å½±åƒç­‰é¢†åŸŸæ•°æ®æ”¶é›†å›°éš¾ä¸”æ˜‚è´µã€‚</li>
<li>ç ”ç©¶æå‡ºäº†MIAdaptæ–¹æ³•ç”¨äºæ˜¾å¾®é•œå›¾åƒåŸŸè‡ªé€‚åº”ï¼Œè§£å†³æ— æºå°‘æ ·æœ¬åŸŸè‡ªé€‚åº”ç‰©ä½“æ£€æµ‹çš„æŒ‘æˆ˜ã€‚</li>
<li>å®šä¹‰äº†ä¸¤ä¸ªç«äº‰åŸºå‡†çº¿æ–¹æ³•ï¼šFaster-FreeShotå’ŒMT-FreeShotã€‚</li>
<li>åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„M5ç–Ÿç–¾å’ŒRaabin-WBCæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒéªŒè¯äº†MIAdaptçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>MIAdaptè¾ƒç°æœ‰æºè‡ªç”±UDAæ–¹æ³•å’Œå°‘æ ·æœ¬åŸŸè‡ªé€‚åº”æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œæé«˜äº†å¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰ã€‚</li>
<li>MIAdaptåœ¨ä¸å¯¹æºåŸŸå›¾åƒè¿›è¡Œä½¿ç”¨çš„æƒ…å†µä¸‹å®ç°æ€§èƒ½æå‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.03370">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5a350a73e924dfb5455dff3634a43c45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-15bae6af356674b32e943cf399db7933.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-36c11912e3ba825a78e7f84a4e48e2c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-58276572fd7ef9418bb2a247dae84426.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-28e881fce8314b446a3cb04432c63a0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b477433883d23a14325a3ee3fd471e9b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8f5f5852f7e12fab744a57b670e0630d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Label-Efficient-LiDAR-Semantic-Segmentation-with-2D-3D-Vision-Transformer-Adapters"><a href="#Label-Efficient-LiDAR-Semantic-Segmentation-with-2D-3D-Vision-Transformer-Adapters" class="headerlink" title="Label-Efficient LiDAR Semantic Segmentation with 2D-3D Vision   Transformer Adapters"></a>Label-Efficient LiDAR Semantic Segmentation with 2D-3D Vision   Transformer Adapters</h2><p><strong>Authors:Julia Hindel, Rohit Mohan, Jelena Bratulic, Daniele Cattaneo, Thomas Brox, Abhinav Valada</strong></p>
<p>LiDAR semantic segmentation models are typically trained from random initialization as universal pre-training is hindered by the lack of large, diverse datasets. Moreover, most point cloud segmentation architectures incorporate custom network layers, limiting the transferability of advances from vision-based architectures. Inspired by recent advances in universal foundation models, we propose BALViT, a novel approach that leverages frozen vision models as amodal feature encoders for learning strong LiDAR encoders. Specifically, BALViT incorporates both range-view and birdâ€™s-eye-view LiDAR encoding mechanisms, which we combine through a novel 2D-3D adapter. While the range-view features are processed through a frozen image backbone, our birdâ€™s-eye-view branch enhances them through multiple cross-attention interactions. Thereby, we continuously improve the vision network with domain-dependent knowledge, resulting in a strong label-efficient LiDAR encoding mechanism. Extensive evaluations of BALViT on the SemanticKITTI and nuScenes benchmarks demonstrate that it outperforms state-of-the-art methods on small data regimes. We make the code and models publicly available at: <a target="_blank" rel="noopener" href="http://balvit.cs.uni-freiburg.de/">http://balvit.cs.uni-freiburg.de</a>. </p>
<blockquote>
<p>æ¿€å…‰é›·è¾¾è¯­ä¹‰åˆ†å‰²æ¨¡å‹é€šå¸¸ä»éšæœºåˆå§‹åŒ–å¼€å§‹è®­ç»ƒï¼Œå› ä¸ºç¼ºä¹å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œé€šç”¨é¢„è®­ç»ƒå—åˆ°é˜»ç¢ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°ç‚¹äº‘åˆ†å‰²æ¶æ„éƒ½èå…¥äº†è‡ªå®šä¹‰ç½‘ç»œå±‚ï¼Œé™åˆ¶äº†åŸºäºè§†è§‰æ¶æ„çš„è¿›å±•çš„è¿ç§»æ€§ã€‚å—é€šç”¨åŸºç¡€æ¨¡å‹çš„æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†BALViTï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨å†»ç»“çš„è§†è§‰æ¨¡å‹ä½œä¸ºæ¨¡æ€ç‰¹å¾ç¼–ç å™¨ï¼Œç”¨äºå­¦ä¹ å¼ºå¤§çš„æ¿€å…‰é›·è¾¾ç¼–ç å™¨ã€‚å…·ä½“æ¥è¯´ï¼ŒBALViTç»“åˆäº†èŒƒå›´è§†å›¾å’Œé¸Ÿç°è§†å›¾æ¿€å…‰é›·è¾¾ç¼–ç æœºåˆ¶ï¼Œæˆ‘ä»¬é€šè¿‡æ–°å‹2D-3Dé€‚é…å™¨å°†å®ƒä»¬ç»“åˆèµ·æ¥ã€‚èŒƒå›´è§†å›¾ç‰¹å¾é€šè¿‡å†»ç»“çš„å›¾åƒä¸»å¹²è¿›è¡Œå¤„ç†ï¼Œè€Œæˆ‘ä»¬çš„é¸Ÿç°è§†å›¾åˆ†æ”¯åˆ™é€šè¿‡å¤šæ¬¡äº¤å‰æ³¨æ„åŠ›äº¤äº’æ¥å¢å¼ºå®ƒä»¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ©ç”¨é¢†åŸŸç›¸å…³çŸ¥è¯†ä¸æ–­æ”¹å–„è§†è§‰ç½‘ç»œï¼Œä»è€Œå½¢æˆäº†å¼ºå¤§çš„æ ‡ç­¾æœ‰æ•ˆæ¿€å…‰é›·è¾¾ç¼–ç æœºåˆ¶ã€‚BALViTåœ¨SemanticKITTIå’ŒnuScenesåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå®ƒåœ¨å°æ•°æ®ç¯å¢ƒä¸‹ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="http://balvit.cs.uni-freiburg.de/">http://balvit.cs.uni-freiburg.de</a>å…¬å¼€äº†ä»£ç å’Œæ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.03299v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LiDARè¯­ä¹‰åˆ†å‰²æ¨¡å‹é€šå¸¸ä»éšæœºåˆå§‹åŒ–å¼€å§‹è®­ç»ƒï¼Œå› ä¸ºé€šç”¨é¢„è®­ç»ƒå—é™äºç¼ºä¹å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†ã€‚æœ¬æ–‡æå‡ºBALViTæ–¹æ³•ï¼Œåˆ©ç”¨å†»ç»“çš„è§†è§‰æ¨¡å‹ä½œä¸ºæ¨¡æ€ç‰¹å¾ç¼–ç å™¨ï¼Œç”¨äºå­¦ä¹ å¼ºå¤§çš„LiDARç¼–ç å™¨ã€‚BALViTç»“åˆäº†èŒƒå›´è§†å›¾å’Œé¸Ÿç°è§†å›¾ä¸¤ç§LiDARç¼–ç æœºåˆ¶ï¼Œå¹¶é€šè¿‡æ–°å‹2D-3Dé€‚é…å™¨è¿›è¡Œèåˆã€‚èŒƒå›´è§†å›¾ç‰¹å¾é€šè¿‡å†»ç»“çš„å›¾åƒä¸»å¹²è¿›è¡Œå¤„ç†ï¼Œè€Œé¸Ÿç°è§†å›¾åˆ†æ”¯åˆ™é€šè¿‡å¤šæ¬¡äº¤å‰æ³¨æ„åŠ›äº¤äº’å¢å¼ºç‰¹å¾ã€‚å› æ­¤ï¼ŒBALViTä¸æ–­ä»¥é¢†åŸŸç›¸å…³çŸ¥è¯†ä¼˜åŒ–è§†è§‰ç½‘ç»œï¼Œå½¢æˆå¼ºå¤§çš„æ ‡ç­¾æ•ˆç‡LiDARç¼–ç æœºåˆ¶ã€‚åœ¨SemanticKITTIå’ŒnuScenesåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå®ƒåœ¨å°æ•°æ®æƒ…å†µä¸‹è¡¨ç°ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚ä»£ç å’Œæ¨¡å‹å¯åœ¨å…¬å¼€ç½‘ç«™ä¸‹è½½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LiDARè¯­ä¹‰åˆ†å‰²æ¨¡å‹é€šå¸¸ä»éšæœºåˆå§‹åŒ–è®­ç»ƒï¼Œå› ä¸ºé¢„è®­ç»ƒå—é™äºæ•°æ®é›†è§„æ¨¡å’Œå¤šæ ·æ€§ã€‚</li>
<li>BALViTæ–¹æ³•åˆ©ç”¨å†»ç»“çš„è§†è§‰æ¨¡å‹ä½œä¸ºæ¨¡æ€ç‰¹å¾ç¼–ç å™¨è¿›è¡ŒLiDARå­¦ä¹ ã€‚</li>
<li>BALViTç»“åˆèŒƒå›´è§†å›¾å’Œé¸Ÿç°è§†å›¾ä¸¤ç§LiDARç¼–ç æœºåˆ¶ã€‚</li>
<li>èŒƒå›´è§†å›¾ç‰¹å¾é€šè¿‡å›¾åƒä¸»å¹²å¤„ç†ï¼Œé¸Ÿç°è§†å›¾åˆ†æ”¯é€šè¿‡å¤šæ¬¡äº¤å‰æ³¨æ„åŠ›äº¤äº’å¢å¼ºã€‚</li>
<li>BALViTæé«˜äº†é¢†åŸŸç›¸å…³çŸ¥è¯†çš„ä½¿ç”¨æ•ˆç‡ï¼Œä¼˜åŒ–äº†æ ‡ç­¾æ•ˆç‡LiDARç¼–ç æœºåˆ¶ã€‚</li>
<li>åœ¨SemanticKITTIå’ŒnuScenesåŸºå‡†æµ‹è¯•ä¸­ï¼ŒBALViTåœ¨å°æ•°æ®æƒ…å†µä¸‹è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.03299">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c77c91645371e9c8f50ae5679908364c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3993b5261b025f47cc169db92a25f8e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcdd3086c48e25771b8b372e018f3d15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1dc3706284e6bb30204417595c6684b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fab075ac3b263fd6f221ee9853e7503b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d5a14a92fbee965dcfbd2694924874a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0f2b6bad5cba4fcaa7969fcd5e097b66.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SLTNet-Efficient-Event-based-Semantic-Segmentation-with-Spike-driven-Lightweight-Transformer-based-Networks"><a href="#SLTNet-Efficient-Event-based-Semantic-Segmentation-with-Spike-driven-Lightweight-Transformer-based-Networks" class="headerlink" title="SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven   Lightweight Transformer-based Networks"></a>SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven   Lightweight Transformer-based Networks</h2><p><strong>Authors:Xiaxin Zhu, Fangming Guo, Xianlei Long, Qingyi Gu, Chao Chen, Fuqiang Gu</strong></p>
<p>Event-based semantic segmentation has great potential in autonomous driving and robotics due to the advantages of event cameras, such as high dynamic range, low latency, and low power cost. Unfortunately, current artificial neural network (ANN)-based segmentation methods suffer from high computational demands, the requirements for image frames, and massive energy consumption, limiting their efficiency and application on resource-constrained edge&#x2F;mobile platforms. To address these problems, we introduce SLTNet, a spike-driven lightweight transformer-based network designed for event-based semantic segmentation. Specifically, SLTNet is built on efficient spike-driven convolution blocks (SCBs) to extract rich semantic features while reducing the modelâ€™s parameters. Then, to enhance the long-range contextural feature interaction, we propose novel spike-driven transformer blocks (STBs) with binary mask operations. Based on these basic blocks, SLTNet employs a high-efficiency single-branch architecture while maintaining the low energy consumption of the Spiking Neural Network (SNN). Finally, extensive experiments on DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms state-of-the-art (SOTA) SNN-based methods by at most 9.06% and 9.39% mIoU, respectively, with extremely 4.58x lower energy consumption and 114 FPS inference speed. Our code is open-sourced and available at <a target="_blank" rel="noopener" href="https://github.com/longxianlei/SLTNet-v1.0">https://github.com/longxianlei/SLTNet-v1.0</a>. </p>
<blockquote>
<p>åŸºäºäº‹ä»¶çš„è¯­ä¹‰åˆ†å‰²åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæŠ€æœ¯æ–¹é¢æœ‰ç€å·¨å¤§çš„æ½œåŠ›ï¼Œè¿™æ˜¯å› ä¸ºäº‹ä»¶ç›¸æœºå…·æœ‰è¯¸å¦‚é«˜åŠ¨æ€èŒƒå›´ã€ä½å»¶è¿Ÿå’Œä½åŠŸè€—ç­‰ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œå½“å‰åŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰çš„åˆ†å‰²æ–¹æ³•å­˜åœ¨è®¡ç®—é‡å¤§ã€å¯¹å›¾åƒå¸§çš„è¦æ±‚é«˜ä»¥åŠèƒ½è€—å·¨å¤§çš„é—®é¢˜ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨èµ„æºå—é™çš„è¾¹ç¼˜&#x2F;ç§»åŠ¨å¹³å°ä¸Šçš„æ•ˆç‡å’Œåº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SLTNetï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºåŸºäºäº‹ä»¶çš„è¯­ä¹‰åˆ†å‰²çš„è„‰å†²é©±åŠ¨è½»é‡åŒ–å˜å‹å™¨ç½‘ç»œã€‚å…·ä½“è€Œè¨€ï¼ŒSLTNetå»ºç«‹åœ¨é«˜æ•ˆçš„è„‰å†²é©±åŠ¨å·ç§¯å—ï¼ˆSCBï¼‰ä¸Šï¼Œä»¥æå–ä¸°å¯Œçš„è¯­ä¹‰ç‰¹å¾ï¼ŒåŒæ—¶å‡å°‘æ¨¡å‹çš„å‚æ•°ã€‚ç„¶åï¼Œä¸ºäº†å¢å¼ºé•¿è·ç¦»ä¸Šä¸‹æ–‡ç‰¹å¾çš„äº¤äº’ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°å‹çš„è„‰å†²é©±åŠ¨å˜å‹å™¨å—ï¼ˆSTBï¼‰ä¸äºŒè¿›åˆ¶æ©ç æ“ä½œã€‚åŸºäºè¿™äº›åŸºæœ¬å—ï¼ŒSLTNeté‡‡ç”¨é«˜æ•ˆçš„å•åˆ†æ”¯æ¶æ„ï¼ŒåŒæ—¶ä¿æŒè„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰çš„ä½èƒ½è€—ã€‚æœ€åï¼Œåœ¨DDD17å’ŒDSEC-Semanticæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSLTNetç›¸è¾ƒäºæœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„åŸºäºSNNçš„æ–¹æ³•æœ€å¤šé«˜å‡º9.06%å’Œ9.39%çš„mIoUï¼ŒåŒæ—¶èƒ½è€—é™ä½äº†4.58å€ï¼Œæ¨ç†é€Ÿåº¦è¾¾åˆ°æ¯ç§’114å¸§ã€‚æˆ‘ä»¬çš„ä»£ç å·²å¼€æºï¼Œå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/longxianlei/SLTNet-v1.0%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/longxianlei/SLTNet-v1.0è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12843v2">PDF</a> Submitted to 2025 IEEE&#x2F;RSJ International Conference on Intelligent   Robots and Systems (IROS 2025)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>äº‹ä»¶é©±åŠ¨çš„è¯­ä¹‰åˆ†å‰²åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººé¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¾—ç›Šäºäº‹ä»¶ç›¸æœºçš„é«˜åŠ¨æ€èŒƒå›´ã€ä½å»¶è¿Ÿå’Œä½åŠŸè€—ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œå½“å‰åŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰çš„åˆ†å‰²æ–¹æ³•å­˜åœ¨è®¡ç®—é‡å¤§ã€å¯¹å›¾åƒå¸§çš„è¦æ±‚é«˜ã€èƒ½è€—å·¨å¤§ç­‰é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™çš„è¾¹ç¼˜&#x2F;ç§»åŠ¨å¹³å°ä¸Šçš„æ•ˆç‡å’Œåº”ç”¨ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SLTNetï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºäº‹ä»¶é©±åŠ¨çš„è¯­ä¹‰åˆ†å‰²çš„è„‰å†²é©±åŠ¨è½»é‡çº§Transformerç½‘ç»œã€‚SLTNeté‡‡ç”¨é«˜æ•ˆçš„è„‰å†²é©±åŠ¨å·ç§¯å—ï¼ˆSCBï¼‰æå–ä¸°å¯Œçš„è¯­ä¹‰ç‰¹å¾ï¼ŒåŒæ—¶å‡å°‘æ¨¡å‹å‚æ•°ã€‚ä¸ºå¢å¼ºé•¿è·ç¦»ä¸Šä¸‹æ–‡ç‰¹å¾çš„äº¤äº’ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°å‹çš„è„‰å†²é©±åŠ¨Transformerå—ï¼ˆSTBï¼‰ä¸äºŒè¿›åˆ¶æ©ç æ“ä½œã€‚åŸºäºè¿™äº›åŸºæœ¬å—ï¼ŒSLTNeté‡‡ç”¨é«˜æ•ˆçš„å•åˆ†æ”¯æ¶æ„ï¼ŒåŒæ—¶ä¿æŒè„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰çš„ä½èƒ½è€—ã€‚åœ¨DDD17å’ŒDSEC-Semanticæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSLTNetè¾ƒå…ˆè¿›çš„SNNæ–¹æ³•æœ€å¤šå¯æé«˜9.06%å’Œ9.39%çš„mIoUï¼ŒåŒæ—¶èƒ½è€—é™ä½4.58å€ï¼Œæ¨ç†é€Ÿåº¦è¾¾åˆ°æ¯ç§’114å¸§ã€‚æˆ‘ä»¬çš„ä»£ç å·²å¼€æºï¼Œå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/longxianlei/SLTNet-v1.0">https://github.com/longxianlei/SLTNet-v1.0</a>è®¿é—®ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>äº‹ä»¶é©±åŠ¨çš„è¯­ä¹‰åˆ†å‰²åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººé¢†åŸŸå…·æœ‰æ½œåŠ›ï¼Œå› äº‹ä»¶ç›¸æœºçš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚</li>
<li>å½“å‰åŸºäºANNçš„æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ã€èµ„æºéœ€æ±‚å’Œèƒ½è€—æ–¹é¢å­˜åœ¨å±€é™ã€‚</li>
<li>SLTNeté‡‡ç”¨è„‰å†²é©±åŠ¨æŠ€æœ¯ï¼Œç»“åˆå·ç§¯å’ŒTransformerå—ï¼Œä»¥æé«˜è¯­ä¹‰åˆ†å‰²æ•ˆç‡ã€‚</li>
<li>SLTNetè®¾è®¡æ—¨åœ¨æå–ä¸°å¯Œè¯­ä¹‰ç‰¹å¾ï¼ŒåŒæ—¶å‡å°‘æ¨¡å‹å‚æ•°å’Œèƒ½è€—ã€‚</li>
<li>é€šè¿‡æ–°é¢–çš„è„‰å†²é©±åŠ¨Transformerå—ï¼Œå®ç°é•¿è·ç¦»ä¸Šä¸‹æ–‡ç‰¹å¾äº¤äº’ã€‚</li>
<li>SLTNeté‡‡ç”¨å•åˆ†æ”¯é«˜æ•ˆæ¶æ„ï¼Œç»“åˆSNNçš„ä½èƒ½è€—ç‰¹ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12843">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8a9fd43542ae86163bfcb73b76d795b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-400c5ccd3ff680b94b98e730c8e47c63.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-014cb0afee5bec82a110ed5906f51da2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e683da018eef63853ab60a52317cf9b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4210acd429a80fdb06c438ed259e8d9e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-648101753df553fbcb2cdd65fc139ced.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f38dc730018c054cf9c59879ceb00aeb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Fractal-Calibration-for-long-tailed-object-detection"><a href="#Fractal-Calibration-for-long-tailed-object-detection" class="headerlink" title="Fractal Calibration for long-tailed object detection"></a>Fractal Calibration for long-tailed object detection</h2><p><strong>Authors:Konstantinos Panagiotis Alexandridis, Ismail Elezi, Jiankang Deng, Anh Nguyen, Shan Luo</strong></p>
<p>Real-world datasets follow an imbalanced distribution, which poses significant challenges in rare-category object detection. Recent studies tackle this problem by developing re-weighting and re-sampling methods, that utilise the class frequencies of the dataset. However, these techniques focus solely on the frequency statistics and ignore the distribution of the classes in image space, missing important information. In contrast to them, we propose FRActal CALibration (FRACAL): a novel post-calibration method for long-tailed object detection. FRACAL devises a logit adjustment method that utilises the fractal dimension to estimate how uniformly classes are distributed in image space. During inference, it uses the fractal dimension to inversely downweight the probabilities of uniformly spaced class predictions achieving balance in two axes: between frequent and rare categories, and between uniformly spaced and sparsely spaced classes. FRACAL is a post-processing method and it does not require any training, also it can be combined with many off-the-shelf models such as one-stage sigmoid detectors and two-stage instance segmentation models. FRACAL boosts the rare class performance by up to 8.6% and surpasses all previous methods on LVIS dataset, while showing good generalisation to other datasets such as COCO, V3Det and OpenImages. We provide the code at <a target="_blank" rel="noopener" href="https://github.com/kostas1515/FRACAL">https://github.com/kostas1515/FRACAL</a>. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œçš„æ•°æ®é›†å‘ˆç°å‡ºä¸å‡è¡¡çš„åˆ†å¸ƒï¼Œè¿™ç»™ç½•è§ç±»åˆ«å¯¹è±¡æ£€æµ‹å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡å¼€å‘é‡æ–°åŠ æƒå’Œé‡æ–°é‡‡æ ·æ–¹æ³•æ¥è§£å†³æ­¤é—®é¢˜ï¼Œè¿™äº›æ–¹æ³•åˆ©ç”¨æ•°æ®é›†çš„ç±»åˆ«é¢‘ç‡ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯åªå…³æ³¨é¢‘ç‡ç»Ÿè®¡ï¼Œè€Œå¿½ç•¥äº†ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒï¼Œä»è€Œä¸¢å¤±äº†é‡è¦ä¿¡æ¯ã€‚ä¸ä¹‹ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†FRACtal CALibrationï¼ˆFRACALï¼‰ï¼šä¸€ç§ç”¨äºé•¿å°¾å¯¹è±¡æ£€æµ‹çš„æ–°å‹åæ ¡å‡†æ–¹æ³•ã€‚FRACALè®¾è®¡äº†ä¸€ç§é€»è¾‘è°ƒæ•´æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å½¢ç»´åº¦æ¥ä¼°è®¡ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒæœ‰å¤šå‡åŒ€ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå®ƒä½¿ç”¨åˆ†å½¢ç»´åº¦æ¥é€†å‘ä¸‹è°ƒæ•´å‡åŒ€é—´éš”çš„ç±»åˆ«é¢„æµ‹æ¦‚ç‡ï¼Œä»è€Œåœ¨ä¸¤ä¸ªè½´ä¹‹é—´å®ç°å¹³è¡¡ï¼šå¸¸è§ç±»åˆ«ä¸ç½•è§ç±»åˆ«ä¹‹é—´ï¼Œä»¥åŠå‡åŒ€é—´éš”çš„ç±»åˆ«ä¸ç¨€ç–é—´éš”çš„ç±»åˆ«ä¹‹é—´ã€‚FRACALæ˜¯ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼Œå®ƒå¯ä»¥ä¸è®¸å¤šç°æˆçš„æ¨¡å‹ï¼ˆå¦‚å•é˜¶æ®µSigmoidæ£€æµ‹å™¨å’Œä¸¤é˜¶æ®µå®ä¾‹åˆ†å‰²æ¨¡å‹ï¼‰ç›¸ç»“åˆã€‚FRACALæé«˜äº†ç½•è§ç±»åˆ«çš„æ€§èƒ½ï¼Œæé«˜äº†é«˜è¾¾8.6%ï¼Œå¹¶åœ¨LVISæ•°æ®é›†ä¸Šè¶…è¶Šäº†æ‰€æœ‰ä¹‹å‰çš„æ–¹æ³•ï¼ŒåŒæ—¶åœ¨å…¶ä»–æ•°æ®é›†å¦‚COCOã€V3Detå’ŒOpenImagesä¸Šä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/kostas1515/FRACAL%E3%80%82">https://github.com/kostas1515/FRACALã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.11774v2">PDF</a> CVPR2025</p>
<p><strong>Summary</strong><br>åŸºäºç°å®ä¸–ç•Œçš„å¤æ‚æ•°æ®é›†ä¸å¹³è¡¡åˆ†å¸ƒçš„é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºFRACALçš„æ–°å‹åæ ¡å‡†æ–¹æ³•ï¼Œç”¨äºé•¿å°¾ç›®æ ‡æ£€æµ‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åˆ†å½¢ç»´åº¦æ¥ä¼°è®¡ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒå‡åŒ€æ€§ï¼Œå¹¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­é€šè¿‡åå‘ä¸‹è°ƒæ¦‚ç‡å®ç°å¹³è¡¡ã€‚æ­¤æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œå¯ä»¥ä¸å…¶ä»–ç°æˆæ¨¡å‹ç›¸ç»“åˆï¼Œæ˜¾è‘—æå‡ç¨€æœ‰ç±»åˆ«çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°å®ä¸–ç•Œçš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†å­˜åœ¨ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œå¯¹ç¨€æœ‰ç±»åˆ«æ£€æµ‹æ„æˆæŒ‘æˆ˜ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦é€šè¿‡é‡åŠ æƒå’Œé‡é‡‡æ ·æ–¹æ³•è§£å†³æ­¤é—®é¢˜ï¼Œä½†ä»…å…³æ³¨é¢‘ç‡ç»Ÿè®¡è€Œå¿½ç•¥äº†ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒã€‚</li>
<li>FRACALæ˜¯ä¸€ç§æ–°å‹åæ ¡å‡†æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å½¢ç»´åº¦æ¥ä¼°è®¡ç±»åˆ«åˆ†å¸ƒçš„å‡åŒ€æ€§ã€‚</li>
<li>FRACALåœ¨æ¨ç†è¿‡ç¨‹ä¸­é€šè¿‡åå‘ä¸‹è°ƒæ¦‚ç‡å®ç°å¹³è¡¡ï¼Œå…¼é¡¾å¸¸è§å’Œç¨€æœ‰ç±»åˆ«ï¼Œä»¥åŠå‡åŒ€å’Œç¨€ç–åˆ†å¸ƒçš„ç±»åˆ«ã€‚</li>
<li>FRACALæ˜¯ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œæ— éœ€é¢å¤–è®­ç»ƒï¼Œå¯ä¸å…¶ä»–ç°æˆæ¨¡å‹ï¼ˆå¦‚å•é˜¶æ®µSigmoidæ£€æµ‹å™¨å’Œä¸¤é˜¶æ®µå®ä¾‹åˆ†å‰²æ¨¡å‹ï¼‰ç»“åˆä½¿ç”¨ã€‚</li>
<li>FRACALåœ¨LVISæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¶…è¶Šäº†æ‰€æœ‰ä¹‹å‰çš„æ–¹æ³•ï¼Œå¹¶æé«˜äº†ç¨€æœ‰ç±»åˆ«çš„æ€§èƒ½é«˜è¾¾8.6%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.11774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-252e5455c267348acfa93dba9720fb3a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3e509b4c0c7665d0d3cd95f0a3e90f6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ce19e79997329618fd498c1981297cb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f959787b2132de32e9c10ebece77f1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f20ab4e75de3c994d67d2f6effa4f36.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Scale-Invariant-Object-Detection-by-Adaptive-Convolution-with-Unified-Global-Local-Context"><a href="#Scale-Invariant-Object-Detection-by-Adaptive-Convolution-with-Unified-Global-Local-Context" class="headerlink" title="Scale-Invariant Object Detection by Adaptive Convolution with Unified   Global-Local Context"></a>Scale-Invariant Object Detection by Adaptive Convolution with Unified   Global-Local Context</h2><p><strong>Authors:Amrita Singh, Snehasis Mukherjee</strong></p>
<p>Dense features are important for detecting minute objects in images. Unfortunately, despite the remarkable efficacy of the CNN models in multi-scale object detection, CNN models often fail to detect smaller objects in images due to the loss of dense features during the pooling process. Atrous convolution addresses this issue by applying sparse kernels. However, sparse kernels often can lose the multi-scale detection efficacy of the CNN model. In this paper, we propose an object detection model using a Switchable (adaptive) Atrous Convolutional Network (SAC-Net) based on the efficientDet model. A fixed atrous rate limits the performance of the CNN models in the convolutional layers. To overcome this limitation, we introduce a switchable mechanism that allows for dynamically adjusting the atrous rate during the forward pass. The proposed SAC-Net encapsulates the benefits of both low-level and high-level features to achieve improved performance on multi-scale object detection tasks, without losing the dense features. Further, we apply a depth-wise switchable atrous rate to the proposed network, to improve the scale-invariant features. Finally, we apply global context on the proposed model. Our extensive experiments on benchmark datasets demonstrate that the proposed SAC-Net outperforms the state-of-the-art models by a significant margin in terms of accuracy. </p>
<blockquote>
<p>å¯†é›†ç‰¹å¾å¯¹äºæ£€æµ‹å›¾åƒä¸­çš„å¾®å°ç‰©ä½“éå¸¸é‡è¦ã€‚ç„¶è€Œï¼Œå°½ç®¡CNNæ¨¡å‹åœ¨å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ä¸­æ•ˆæœæ˜¾è‘—ï¼Œä½†ç”±äºæ± åŒ–è¿‡ç¨‹ä¸­å¯†é›†ç‰¹å¾çš„æŸå¤±ï¼ŒCNNæ¨¡å‹å¾€å¾€æ— æ³•æ£€æµ‹å›¾åƒä¸­çš„è¾ƒå°ç‰©ä½“ã€‚ç©ºæ´å·ç§¯é€šè¿‡åº”ç”¨ç¨€ç–æ ¸æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œç¨€ç–æ ¸å¾€å¾€ä¼šæŸå¤±CNNæ¨¡å‹çš„å¤šå°ºåº¦æ£€æµ‹æ•ˆæœã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºefficientDetæ¨¡å‹çš„å¯åˆ‡æ¢ï¼ˆè‡ªé€‚åº”ï¼‰ç©ºæ´å·ç§¯ç½‘ç»œï¼ˆSAC-Netï¼‰çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚å›ºå®šçš„ç©ºæ´ç‡é™åˆ¶äº†CNNæ¨¡å‹åœ¨å·ç§¯å±‚ä¸­çš„æ€§èƒ½ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¯åˆ‡æ¢æœºåˆ¶ï¼Œå…è®¸åœ¨å‰å‘ä¼ é€’è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´ç©ºæ´ç‡ã€‚æ‰€æå‡ºçš„SAC-Netç»“åˆäº†ä½å±‚æ¬¡å’Œé«˜å±‚æ¬¡ç‰¹å¾çš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿåœ¨å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šå®ç°æ”¹è¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¸æŸå¤±å¯†é›†ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ‰€æå‡ºçš„ç½‘ç»œåº”ç”¨äº†æ·±åº¦å¯åˆ‡æ¢ç©ºæ´ç‡ï¼Œä»¥æ”¹è¿›å°ºåº¦ä¸å˜ç‰¹å¾ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨æ‰€ææ¨¡å‹ä¸Šåº”ç”¨äº†å…¨å±€ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬åœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„SAC-Netåœ¨å‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºæœ€æ–°æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.05274v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºEfficientDetæ¨¡å‹çš„Switchableï¼ˆè‡ªé€‚åº”ï¼‰è†¨èƒ€å·ç§¯ç½‘ç»œï¼ˆSAC-Netï¼‰èƒ½æœ‰æ•ˆè§£å†³CNNæ¨¡å‹åœ¨å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ä¸­å› æ± åŒ–è¿‡ç¨‹æŸå¤±å¯†é›†ç‰¹å¾è€Œå¯¼è‡´æ— æ³•æ£€æµ‹è¾ƒå°ç›®æ ‡çš„é—®é¢˜ã€‚SAC-Neté€šè¿‡å¼•å…¥å¯åˆ‡æ¢æœºåˆ¶ï¼ŒåŠ¨æ€è°ƒæ•´è†¨èƒ€ç‡ï¼Œç»“åˆé«˜ä½å±‚æ¬¡ç‰¹å¾çš„ä¼˜ç‚¹ï¼Œå®ç°äº†å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶ä¿ç•™äº†å¯†é›†ç‰¹å¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>CNNæ¨¡å‹åœ¨æ£€æµ‹è¾ƒå°å›¾åƒç›®æ ‡æ—¶å¯èƒ½å› æ± åŒ–è¿‡ç¨‹ä¸­æŸå¤±å¯†é›†ç‰¹å¾è€Œå¤±æ•ˆã€‚</li>
<li>è†¨èƒ€å·ç§¯æœ‰åŠ©äºè§£å†³æ­¤é—®é¢˜ï¼Œä½†å›ºå®šè†¨èƒ€ç‡é™åˆ¶äº†CNNæ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>SAC-Netå¼•å…¥å¯åˆ‡æ¢æœºåˆ¶ï¼Œå…è®¸åœ¨å‘å‰ä¼ é€’è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´è†¨èƒ€ç‡ã€‚</li>
<li>SAC-Netç»“åˆé«˜ä½å±‚æ¬¡ç‰¹å¾çš„ä¼˜ç‚¹ï¼Œå®ç°å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹æ€§èƒ½çš„æå‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ·±åº¦å¯åˆ‡æ¢çš„è†¨èƒ€ç‡ï¼Œä»¥æ”¹å–„å°ºåº¦ä¸å˜ç‰¹å¾ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.05274">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-75080b1042938f5f6d301966e64dd09e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Adapting-Pre-Trained-Vision-Models-for-Novel-Instance-Detection-and-Segmentation"><a href="#Adapting-Pre-Trained-Vision-Models-for-Novel-Instance-Detection-and-Segmentation" class="headerlink" title="Adapting Pre-Trained Vision Models for Novel Instance Detection and   Segmentation"></a>Adapting Pre-Trained Vision Models for Novel Instance Detection and   Segmentation</h2><p><strong>Authors:Yangxiao Lu, Jishnu Jaykumar P, Yunhui Guo, Nicholas Ruozzi, Yu Xiang</strong></p>
<p>Novel Instance Detection and Segmentation (NIDS) aims at detecting and segmenting novel object instances given a few examples of each instance. We propose a unified, simple, yet effective framework (NIDS-Net) comprising object proposal generation, embedding creation for both instance templates and proposal regions, and embedding matching for instance label assignment. Leveraging recent advancements in large vision methods, we utilize Grounding DINO and Segment Anything Model (SAM) to obtain object proposals with accurate bounding boxes and masks. Central to our approach is the generation of high-quality instance embeddings. We utilized foreground feature averages of patch embeddings from the DINOv2 ViT backbone, followed by refinement through a weight adapter mechanism that we introduce.   We show experimentally that our weight adapter can adjust the embeddings locally within their feature space and effectively limit overfitting in the few-shot setting. Furthermore, the weight adapter optimizes weights to enhance the distinctiveness of instance embeddings during similarity computation. This methodology enables a straightforward matching strategy that results in significant performance gains. Our framework surpasses current state-of-the-art methods, demonstrating notable improvements in four detection datasets. In the segmentation tasks on seven core datasets of the BOP challenge, our method outperforms the leading published RGB methods and remains competitive with the best RGB-D method. We have also verified our method using real-world images from a Fetch robot and a RealSense camera. Project Page: <a target="_blank" rel="noopener" href="https://irvlutd.github.io/NIDSNet/">https://irvlutd.github.io/NIDSNet/</a> </p>
<blockquote>
<p>æ–°å‹å®ä¾‹æ£€æµ‹ä¸åˆ†å‰²ï¼ˆNIDSï¼‰æ—¨åœ¨é€šè¿‡æ¯ä¸ªå®ä¾‹çš„å‡ ä¸ªç¤ºä¾‹æ¥æ£€æµ‹å’Œåˆ†å‰²æ–°å‹å¯¹è±¡å®ä¾‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€ã€ç®€å•ã€æœ‰æ•ˆçš„æ¡†æ¶ï¼ˆNIDS-Netï¼‰ï¼Œå®ƒåŒ…æ‹¬ç”Ÿæˆå¯¹è±¡ææ¡ˆã€ä¸ºå®ä¾‹æ¨¡æ¿å’Œææ¡ˆåŒºåŸŸåˆ›å»ºåµŒå…¥ï¼Œä»¥åŠç”¨äºå®ä¾‹æ ‡ç­¾åˆ†é…çš„åµŒå…¥åŒ¹é…ã€‚æˆ‘ä»¬åˆ©ç”¨å¤§å‹è§†è§‰æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼Œä½¿ç”¨æ¥åœ°DINOå’Œåˆ†æ®µä»»ä½•æ¨¡å‹ï¼ˆSAMï¼‰è·å¾—å¸¦æœ‰ç²¾ç¡®è¾¹ç•Œæ¡†å’Œè’™ç‰ˆçš„å¯¹è±¡ææ¡ˆã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ç”Ÿæˆé«˜è´¨é‡å®ä¾‹åµŒå…¥ã€‚æˆ‘ä»¬ä½¿ç”¨DINOv2 ViTéª¨å¹²ç½‘ä¸­è¡¥ä¸åµŒå…¥çš„å‰æ™¯ç‰¹å¾å¹³å‡å€¼ï¼Œç„¶åé€šè¿‡æˆ‘ä»¬å¼•å…¥çš„æƒé‡é€‚é…å™¨æœºåˆ¶è¿›è¡Œå¾®è°ƒã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æƒé‡é€‚é…å™¨å¯ä»¥åœ¨å…¶ç‰¹å¾ç©ºé—´å†…å±€éƒ¨è°ƒæ•´åµŒå…¥ï¼Œå¹¶åœ¨å°æ ·æœ¬è®¾ç½®ä¸­æœ‰æ•ˆé™åˆ¶è¿‡æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œæƒé‡é€‚é…å™¨ä¼˜åŒ–æƒé‡ï¼Œåœ¨ç›¸ä¼¼åº¦è®¡ç®—è¿‡ç¨‹ä¸­å¢å¼ºå®ä¾‹åµŒå…¥çš„åŒºåˆ†åº¦ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—ç®€å•çš„åŒ¹é…ç­–ç•¥èƒ½å¤Ÿå¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„æ¡†æ¶è¶…è¶Šäº†å½“å‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œåœ¨å››ä¸ªæ£€æµ‹æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚åœ¨BOPæŒ‘æˆ˜ä¸­çš„ä¸ƒä¸ªæ ¸å¿ƒæ•°æ®é›†ä¸Šçš„åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºé¢†å…ˆçš„å·²å‘å¸ƒRGBæ–¹æ³•ï¼Œå¹¶ä¸”ä¸æœ€ä½³çš„RGB-Dæ–¹æ³•ä¿æŒç«äº‰åŠ›ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨Fetchæœºå™¨äººå’ŒRealSenseç›¸æœºæ‹æ‘„çš„çœŸå®ä¸–ç•Œå›¾åƒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://irvlutd.github.io/NIDSnet/">https://irvlutd.github.io/NIDSnet/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17859v3">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://irvlutd.github.io/NIDSNet/">https://irvlutd.github.io/NIDSNet/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹æ–°å‹å®ä¾‹æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡çš„æ–°æ–¹æ³•ï¼ˆNIDS-Netï¼‰ã€‚å®ƒæ•´åˆäº†å®ä¾‹ææ¡ˆç”Ÿæˆã€å®ä¾‹æ¨¡æ¿ä¸ææ¡ˆåŒºåŸŸçš„åµŒå…¥åˆ›å»ºï¼Œä»¥åŠåµŒå…¥åŒ¹é…æ¥åˆ†é…å®ä¾‹æ ‡ç­¾ã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†æœ€æ–°çš„å¤§è§„æ¨¡è§†è§‰æ–¹æ³•ï¼Œå¹¶ç»“åˆäº†Grounding DINOå’ŒSAMæ¨¡å‹æ¥è·å–å‡†ç¡®è¾¹ç•Œæ¡†å’Œæ©æ¨¡çš„å®ä¾‹ææ¡ˆã€‚æ ¸å¿ƒåœ¨äºç”Ÿæˆé«˜è´¨é‡çš„å®ä¾‹åµŒå…¥ï¼Œåˆ©ç”¨å‰æ™¯ç‰¹å¾å¹³å‡æ–¹æ³•è·å¾—è¡¥ä¸åµŒå…¥ï¼Œå†é€šè¿‡æ–°å¼•å…¥çš„æƒé‡é€‚é…å™¨æœºåˆ¶è¿›è¡Œç²¾ç‚¼ã€‚å®éªŒè¡¨æ˜ï¼Œæƒé‡é€‚é…å™¨èƒ½å¤Ÿåœ¨ç‰¹å¾ç©ºé—´å†…å±€éƒ¨è°ƒæ•´åµŒå…¥ï¼Œæœ‰æ•ˆé™åˆ¶å°æ ·æœ¬è¿‡æ‹Ÿåˆé—®é¢˜ï¼ŒåŒæ—¶ä¼˜åŒ–æƒé‡æé«˜å®ä¾‹åµŒå…¥çš„åŒºåˆ†åº¦ã€‚æ­¤æ–¹æ³•åœ¨å››ä¸ªæ£€æµ‹æ•°æ®é›†å’Œä¸ƒä¸ªåˆ†å‰²æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºå½“å‰æœ€ä½³æ–¹æ³•ã€‚åŒæ—¶ï¼Œé€šè¿‡å®é™…åº”ç”¨éªŒè¯äº†æ–¹æ³•çš„å¯è¡Œæ€§ã€‚æ›´å¤šè¯¦æƒ…å‚è§é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://irvlutd.github.io/NIDSnet/">https://irvlutd.github.io/NIDSnet/</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NIDS-Netæ˜¯ä¸€ç§ç”¨äºæ–°å‹å®ä¾‹æ£€æµ‹å’Œåˆ†å‰²çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ¶µç›–äº†å¯¹è±¡ææ¡ˆç”Ÿæˆã€åµŒå…¥åˆ›å»ºå’ŒåµŒå…¥åŒ¹é…ç­‰å…³é”®ç¯èŠ‚ã€‚</li>
<li>åˆ©ç”¨å…ˆè¿›çš„è§†è§‰æ–¹æ³•å¦‚Grounding DINOå’ŒSAMè·å–ç²¾ç¡®è¾¹ç•Œæ¡†å’Œæ©æ¨¡çš„å®ä¾‹ææ¡ˆã€‚</li>
<li>æå‡ºäº†åˆ©ç”¨å‰æ™¯ç‰¹å¾å¹³å‡å’Œæƒé‡é€‚é…å™¨æœºåˆ¶æ¥ç”Ÿæˆé«˜è´¨é‡å®ä¾‹åµŒå…¥çš„æ–¹æ³•ã€‚æƒé‡é€‚é…å™¨èƒ½å¤Ÿåœ¨ç‰¹å¾ç©ºé—´å†…å±€éƒ¨è°ƒæ•´åµŒå…¥ï¼Œä¼˜åŒ–æƒé‡ä»¥æé«˜å®ä¾‹åµŒå…¥çš„åŒºåˆ†åº¦ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17859">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8f640f79ca7c673c7fbd01b83864b37.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-11ab40ff290ddfdb7613566cc75cb705.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-64542b83a405e3bbc9c0b198e8620c37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60b77b2894ec5ce9a3f3dcfbc631075e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a9f655b657ccede111bbcf8a16f04e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1c24e6f8780c8d5aea8c30b63671db2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa1e7c36fd641d3e9a3ef41dade59b6d.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-07/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-07/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-07/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-caf74e0cad5935f83c6077237c86f9da.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-07  OCL Ordinal Contrastive Learning for Imputating Features with   Progressive Labels
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-07/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-68ea508991b0fd7d1ea06dc120a606a5.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-07  A Generative Approach to High Fidelity 3D Reconstruction from Text Data
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23542.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
