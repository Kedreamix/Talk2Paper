<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  Synthetic Speech Classification IEEE Signal Processing Cup 2022   challenge">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-bf6e7db4f0253c8902f2ba241b051a88.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    38 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-19-æ›´æ–°"><a href="#2024-12-19-æ›´æ–°" class="headerlink" title="2024-12-19 æ›´æ–°"></a>2024-12-19 æ›´æ–°</h1><h2 id="Synthetic-Speech-Classification-IEEE-Signal-Processing-Cup-2022-challenge"><a href="#Synthetic-Speech-Classification-IEEE-Signal-Processing-Cup-2022-challenge" class="headerlink" title="Synthetic Speech Classification: IEEE Signal Processing Cup 2022   challenge"></a>Synthetic Speech Classification: IEEE Signal Processing Cup 2022   challenge</h2><p><strong>Authors:Mahieyin Rahmun, Rafat Hasan Khan, Tanjim Taharat Aurpa, Sadia Khan, Zulker Nayeen Nahiyan, Mir Sayad Bin Almas, Rakibul Hasan Rajib, Syeda Sakira Hassan</strong></p>
<p>The aim of this project is to implement and design arobust synthetic speech classifier for the IEEE Signal ProcessingCup 2022 challenge. Here, we learn a synthetic speech attributionmodel using the speech generated from various text-to-speech(TTS) algorithms as well as unknown TTS algorithms. Weexperiment with both the classical machine learning methodssuch as support vector machine, Gaussian mixture model, anddeep learning based methods such as ResNet, VGG16, and twoshallow end-to-end networks. We observe that deep learningbased methods with raw data demonstrate the best performance. </p>
<blockquote>
<p>æ­¤é¡¹ç›®çš„ç›®æ ‡æ˜¯é’ˆå¯¹IEEEä¿¡å·å¤„ç†æ¯2022æŒ‘æˆ˜èµ›ï¼Œè®¾è®¡å’Œå®ç°ä¸€ä¸ªç¨³å¥çš„åˆæˆè¯­éŸ³åˆ†ç±»å™¨ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨å„ç§æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç®—æ³•ä»¥åŠæœªçŸ¥TTSç®—æ³•ç”Ÿæˆçš„è¯­éŸ³æ¥å­¦ä¹ åˆæˆè¯­éŸ³å½’å±æ¨¡å‹ã€‚æˆ‘ä»¬å°è¯•ä½¿ç”¨ç»å…¸çš„æœºå™¨å­¦ä¹ æ–¹æ³•å’Œæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œæ¯”å¦‚æ”¯æŒå‘é‡æœºã€é«˜æ–¯æ··åˆæ¨¡å‹ä»¥åŠResNetã€VGG16å’Œä¸¤ä¸ªæµ…å±‚ç«¯åˆ°ç«¯ç½‘ç»œã€‚æˆ‘ä»¬å‘ç°åŸºäºæ·±åº¦å­¦ä¹ å’ŒåŸå§‹æ•°æ®çš„æ–¹æ¡ˆè¡¨ç°å‡ºæœ€ä½³æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13279v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥é¡¹ç›®æ—¨åœ¨é’ˆå¯¹IEEEä¿¡å·å¤„ç†æ¯2022æŒ‘æˆ˜èµ›è®¾è®¡å’Œå®ç°ä¸€ä¸ªç¨³å¥çš„åˆæˆè¯­éŸ³åˆ†ç±»å™¨ã€‚è¯¥é¡¹ç›®ä½¿ç”¨å„ç§æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç®—æ³•ç”Ÿæˆçš„è¯­éŸ³ä»¥åŠæœªçŸ¥TTSç®—æ³•æ¥å­¦ä¹ åˆæˆè¯­éŸ³å±æ€§æ¨¡å‹ã€‚å®éªŒåŒ…æ‹¬ä½¿ç”¨ç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•çš„å¯¹æ¯”å®éªŒï¼Œç»“æœæ˜¾ç¤ºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ€§èƒ½æœ€ä½³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¡¹ç›®ç›®æ ‡æ˜¯è®¾è®¡å’Œå®ç°ä¸€ä¸ªé’ˆå¯¹IEEEä¿¡å·å¤„ç†æ¯2022æŒ‘æˆ˜èµ›çš„ç¨³å¥åˆæˆè¯­éŸ³åˆ†ç±»å™¨ã€‚</li>
<li>é¡¹ç›®ä½¿ç”¨å¤šç§TTSç®—æ³•ç”Ÿæˆçš„è¯­éŸ³ä½œä¸ºæ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>é¡¹ç›®å¯¹æ¯”äº†ç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚æ”¯æŒå‘é‡æœºå’Œé«˜æ–¯æ··åˆæ¨¡å‹ï¼‰å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚ResNetå’ŒVGG16ï¼‰ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜æ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ€§èƒ½æœ€ä½³ã€‚</li>
<li>ç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®èƒ½å¤Ÿæé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>è¯¥é¡¹ç›®ä¸ºåˆæˆè¯­éŸ³çš„è¯†åˆ«æä¾›äº†æœ‰æ•ˆæ–¹æ³•å’Œæ€è·¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13279">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6c0c7d843c4c129cdf4b03bee0002fb5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6a41dbd469da9862d4c7ea53308940d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0dc98995ec3a9be72f9dfc8c6c357e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70d1d10cb250cc12ef84954c13a5e358.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Phoneme-Level-Feature-Discrepancies-A-Key-to-Detecting-Sophisticated-Speech-Deepfakes"><a href="#Phoneme-Level-Feature-Discrepancies-A-Key-to-Detecting-Sophisticated-Speech-Deepfakes" class="headerlink" title="Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated   Speech Deepfakes"></a>Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated   Speech Deepfakes</h2><p><strong>Authors:Kuiyuan Zhang, Zhongyun Hua, Rushi Lan, Yushu Zhang, Yifang Guo</strong></p>
<p>Recent advancements in text-to-speech and speech conversion technologies have enabled the creation of highly convincing synthetic speech. While these innovations offer numerous practical benefits, they also cause significant security challenges when maliciously misused. Therefore, there is an urgent need to detect these synthetic speech signals. Phoneme features provide a powerful speech representation for deepfake detection. However, previous phoneme-based detection approaches typically focused on specific phonemes, overlooking temporal inconsistencies across the entire phoneme sequence. In this paper, we develop a new mechanism for detecting speech deepfakes by identifying the inconsistencies of phoneme-level speech features. We design an adaptive phoneme pooling technique that extracts sample-specific phoneme-level features from frame-level speech data. By applying this technique to features extracted by pre-trained audio models on previously unseen deepfake datasets, we demonstrate that deepfake samples often exhibit phoneme-level inconsistencies when compared to genuine speech. To further enhance detection accuracy, we propose a deepfake detector that uses a graph attention network to model the temporal dependencies of phoneme-level features. Additionally, we introduce a random phoneme substitution augmentation technique to increase feature diversity during training. Extensive experiments on four benchmark datasets demonstrate the superior performance of our method over existing state-of-the-art detection methods. </p>
<blockquote>
<p>è¿‘æœŸæ–‡æœ¬åˆ°è¯­éŸ³å’Œè¯­éŸ³è½¬æ¢æŠ€æœ¯çš„è¿›å±•ä½¿å¾—åˆ›å»ºé«˜åº¦é€¼çœŸçš„åˆæˆè¯­éŸ³æˆä¸ºå¯èƒ½ã€‚è™½ç„¶è¿™äº›åˆ›æ–°æä¾›äº†è®¸å¤šå®é™…å¥½å¤„ï¼Œä½†å®ƒä»¬åœ¨æ¶æ„æ»¥ç”¨æ—¶ä¹Ÿå¸¦æ¥äº†é‡å¤§çš„å®‰å…¨æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæ€¥éœ€æ£€æµ‹è¿™äº›åˆæˆè¯­éŸ³ä¿¡å·ã€‚éŸ³ç´ ç‰¹å¾ä¸ºæ·±åº¦ä¼ªé€ æ£€æµ‹æä¾›äº†å¼ºå¤§çš„è¯­éŸ³è¡¨å¾ã€‚ç„¶è€Œï¼Œä»¥å‰çš„åŸºäºéŸ³ç´ çš„æ£€æµ‹æ–¹æ³•é€šå¸¸ä¸“æ³¨äºç‰¹å®šéŸ³ç´ ï¼Œå¿½ç•¥äº†æ•´ä¸ªéŸ³ç´ åºåˆ—ä¸­çš„æ—¶é—´ä¸ä¸€è‡´æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§é€šè¿‡è¯†åˆ«éŸ³ç´ çº§è¯­éŸ³ç‰¹å¾çš„ä¸ä¸€è‡´æ€§æ¥æ£€æµ‹è¯­éŸ³æ·±åº¦ä¼ªé€ çš„æ–°æœºåˆ¶ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”çš„éŸ³ç´ æ± åŒ–æŠ€æœ¯ï¼Œä»å¸§çº§è¯­éŸ³æ•°æ®ä¸­æå–æ ·æœ¬ç‰¹å®šçš„éŸ³ç´ çº§ç‰¹å¾ã€‚é€šè¿‡å°†è¿™é¡¹æŠ€æœ¯åº”ç”¨åœ¨ä»å…ˆå‰æœªè§è¿‡çš„æ·±åº¦ä¼ªé€ æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„éŸ³é¢‘æ¨¡å‹æ‰€æå–çš„ç‰¹å¾ä¸Šï¼Œæˆ‘ä»¬è¯æ˜ä¸çœŸå®è¯­éŸ³ç›¸æ¯”ï¼Œæ·±åº¦ä¼ªé€ æ ·æœ¬åœ¨éŸ³ç´ çº§ä¸Šé€šå¸¸è¡¨ç°å‡ºä¸ä¸€è‡´æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ£€æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œå¯¹éŸ³ç´ çº§ç‰¹å¾çš„æ—¶é—´ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§éšæœºéŸ³ç´ æ›¿æ¢å¢å¼ºæŠ€æœ¯ï¼Œä»¥å¢åŠ è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç‰¹å¾å¤šæ ·æ€§ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ£€æµ‹æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12619v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸæ–‡æœ¬è½¬è¯­éŸ³å’Œè¯­éŸ³è½¬æ¢æŠ€æœ¯çš„è¿›å±•ä½¿å¾—åˆ›å»ºé«˜åº¦é€¼çœŸçš„åˆæˆè¯­éŸ³æˆä¸ºå¯èƒ½ã€‚è™½ç„¶è¿™äº›åˆ›æ–°æä¾›äº†è®¸å¤šå®é™…åˆ©ç›Šï¼Œä½†å½“å®ƒä»¬è¢«æ¶æ„è¯¯ç”¨æ—¶ï¼Œä¹Ÿä¼šå¸¦æ¥é‡å¤§å®‰å…¨æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œè¿«åˆ‡éœ€è¦æ£€æµ‹è¿™äº›åˆæˆè¯­éŸ³ä¿¡å·ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡è¯†åˆ«éŸ³ç´ çº§è¯­éŸ³ç‰¹å¾çš„ä¸ä¸€è‡´æ€§æ¥æ£€æµ‹è¯­éŸ³æ·±åº¦ä¼ªé€ çš„æ–°æœºåˆ¶ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”çš„éŸ³ç´ æ± åŒ–æŠ€æœ¯ï¼Œä»å¸§çº§è¯­éŸ³æ•°æ®ä¸­æå–æ ·æœ¬ç‰¹å®šçš„éŸ³ç´ çº§ç‰¹å¾ã€‚é€šè¿‡å°†æ­¤æŠ€æœ¯åº”ç”¨äºé¢„è®­ç»ƒéŸ³é¢‘æ¨¡å‹æå–çš„ç‰¹å¾ä¹‹å‰æœªè§è¿‡çš„æ·±åº¦ä¼ªé€ æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬è¯æ˜æ·±åº¦ä¼ªé€ æ ·æœ¬ä¸çœŸå®è¯­éŸ³ç›¸æ¯”ï¼Œå¾€å¾€è¡¨ç°å‡ºéŸ³ç´ çº§çš„ä¸ä¸€è‡´æ€§ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜æ£€æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œå¯¹éŸ³ç´ çº§ç‰¹å¾çš„æ—¶é—´ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§éšæœºéŸ³ç´ æ›¿æ¢å¢å¼ºæŠ€æœ¯ï¼Œä»¥å¢åŠ è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç‰¹å¾å¤šæ ·æ€§ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ£€æµ‹æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆæˆè¯­éŸ³æŠ€æœ¯çš„è¿›å±•å¸¦æ¥äº†å®ç”¨æ€§å’Œå®‰å…¨æ€§æŒ‘æˆ˜ã€‚</li>
<li>æ£€æµ‹åˆæˆè¯­éŸ³ä¿¡å·çš„éœ€æ±‚è¿«åˆ‡ã€‚</li>
<li>éŸ³ç´ çº§ç‰¹å¾åœ¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­èµ·åˆ°é‡è¦ä½œç”¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è‡ªé€‚åº”çš„éŸ³ç´ æ± åŒ–æŠ€æœ¯ï¼Œç”¨äºæå–æ ·æœ¬ç‰¹å®šçš„éŸ³ç´ çº§ç‰¹å¾ã€‚</li>
<li>é€šè¿‡å›¾æ³¨æ„åŠ›ç½‘ç»œå¯¹éŸ³ç´ çº§ç‰¹å¾çš„æ—¶é—´ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡ï¼Œæé«˜æ£€æµ‹ç²¾åº¦ã€‚</li>
<li>å¼•å…¥éšæœºéŸ³ç´ æ›¿æ¢å¢å¼ºæŠ€æœ¯ï¼Œå¢åŠ è®­ç»ƒç‰¹å¾å¤šæ ·æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-979d83bdb21767ba36ea6710276f10b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00bb35e2a988cc91bda518f9a6481d49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f707af58709fdcc35a6a4e36063be29.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b05844da076cda2e754ca3c6da10b9bc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fe5a85918dd32d3ac733c344793edb4c.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ProsodyFM-Unsupervised-Phrasing-and-Intonation-Control-for-Intelligible-Speech-Synthesis"><a href="#ProsodyFM-Unsupervised-Phrasing-and-Intonation-Control-for-Intelligible-Speech-Synthesis" class="headerlink" title="ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible   Speech Synthesis"></a>ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible   Speech Synthesis</h2><p><strong>Authors:Xiangheng He, Junjie Chen, Zixing Zhang, BjÃ¶rn W. Schuller</strong></p>
<p>Prosody contains rich information beyond the literal meaning of words, which is crucial for the intelligibility of speech. Current models still fall short in phrasing and intonation; they not only miss or misplace breaks when synthesizing long sentences with complex structures but also produce unnatural intonation. We propose ProsodyFM, a prosody-aware text-to-speech synthesis (TTS) model with a flow-matching (FM) backbone that aims to enhance the phrasing and intonation aspects of prosody. ProsodyFM introduces two key components: a Phrase Break Encoder to capture initial phrase break locations, followed by a Duration Predictor for the flexible adjustment of break durations; and a Terminal Intonation Encoder which integrates a set of intonation shape tokens combined with a novel Pitch Processor for more robust modeling of human-perceived intonation change. ProsodyFM is trained with no explicit prosodic labels and yet can uncover a broad spectrum of break durations and intonation patterns. Experimental results demonstrate that ProsodyFM can effectively improve the phrasing and intonation aspects of prosody, thereby enhancing the overall intelligibility compared to four state-of-the-art (SOTA) models. Out-of-distribution experiments show that this prosody improvement can further bring ProsodyFM superior generalizability for unseen complex sentences and speakers. Our case study intuitively illustrates the powerful and fine-grained controllability of ProsodyFM over phrasing and intonation. </p>
<blockquote>
<p>éŸµå¾‹åŒ…å«è¶…è¶Šè¯æ±‡å­—é¢æ„ä¹‰çš„ä¸°å¯Œä¿¡æ¯ï¼Œè¿™å¯¹äºè¯­éŸ³çš„æ¸…æ™°åº¦è‡³å…³é‡è¦ã€‚å½“å‰æ¨¡å‹åœ¨çŸ­è¯­å’Œè¯­è°ƒæ–¹é¢ä»æœ‰ä¸è¶³ï¼›å®ƒä»¬åœ¨åˆæˆå…·æœ‰å¤æ‚ç»“æ„çš„é•¿å¥å­æ—¶ï¼Œä¸ä»…ä¼šé—æ¼æˆ–é”™ä½æ–­ç‚¹ï¼Œè¿˜ä¼šäº§ç”Ÿä¸è‡ªç„¶çš„è¯­è°ƒã€‚æˆ‘ä»¬æå‡ºäº†ProsodyFMï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰éŸµå¾‹æ„ŸçŸ¥çš„æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆTTSï¼‰æ¨¡å‹ï¼Œå®ƒé‡‡ç”¨æµåŒ¹é…ï¼ˆFMï¼‰ä½œä¸ºä¸»å¹²ï¼Œæ—¨åœ¨å¢å¼ºéŸµå¾‹çš„çŸ­è¯­å’Œè¯­è°ƒæ–¹é¢ã€‚ProsodyFMå¼•å…¥äº†ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šPhrase Break Encoderç”¨äºæ•æ‰åˆå§‹çŸ­è¯­æ–­ç‚¹ä½ç½®ï¼Œç„¶åæ˜¯Duration Predictorç”¨äºçµæ´»è°ƒæ•´æ–­å¥æŒç»­æ—¶é—´ï¼›Terminal Intonation Encoderåˆ™æ•´åˆäº†ä¸€ç»„è¯­è°ƒå½¢çŠ¶æ ‡è®°ï¼Œå¹¶ç»“åˆæ–°å‹Pitch Processorï¼Œä»¥æ›´ç¨³å¥åœ°æ¨¡æ‹Ÿäººç±»æ„ŸçŸ¥çš„è¯­è°ƒå˜åŒ–ã€‚ProsodyFMæ— éœ€æ˜ç¡®çš„éŸµå¾‹æ ‡ç­¾å³å¯è¿›è¡Œè®­ç»ƒï¼Œä½†èƒ½å¤Ÿæ­ç¤ºå¹¿æ³›çš„æ–­å¥æŒç»­æ—¶é—´å’Œè¯­è°ƒæ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒProsodyFMå¯ä»¥æœ‰æ•ˆæ”¹å–„éŸµå¾‹çš„çŸ­è¯­å’Œè¯­è°ƒæ–¹é¢ï¼Œä»è€Œä¸å››ç§æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”æé«˜æ•´ä½“æ¸…æ™°åº¦ã€‚åˆ†å¸ƒå¤–å®éªŒè¡¨æ˜ï¼Œè¿™ç§éŸµå¾‹æ”¹è¿›å¯ä»¥è¿›ä¸€æ­¥æé«˜ProsodyFMå¯¹æœªè§è¿‡çš„å¤æ‚å¥å­å’Œè¯´è¯äººçš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¡ˆä¾‹ç ”ç©¶ç›´è§‚åœ°è¯´æ˜äº†ProsodyFMåœ¨çŸ­è¯­å’Œè¯­è°ƒä¸Šçš„å¼ºå¤§å’Œç²¾ç»†å¯æ§æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11795v1">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä¸­çš„ä¿¡æ¯æŒ‡å‡ºï¼Œè¯­éŸ³ä¸­çš„éŸµå¾‹ï¼ˆProsodyï¼‰åŒ…å«è¶…è¶Šå•è¯å­—é¢æ„ä¹‰çš„ä¸°å¯Œä¿¡æ¯ï¼Œè¿™å¯¹è¯­éŸ³çš„å¯æ‡‚åº¦è‡³å…³é‡è¦ã€‚å½“å‰çš„è¯­éŸ³åˆæˆæ¨¡å‹åœ¨è¡¨è¾¾å’Œè¯­è°ƒæ–¹é¢ä»å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æ­£ç¡®æˆ–è‡ªç„¶åœ°å¤„ç†é•¿å¥å¤æ‚ç»“æ„ä¸­çš„åœé¡¿å’Œè¯­è°ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¸¦æœ‰æµåŒ¹é…ï¼ˆFMï¼‰èƒŒéª¨çš„éŸµå¾‹æ„ŸçŸ¥æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆTTSï¼‰æ¨¡å‹â€”â€”ProsodyFMï¼Œæ—¨åœ¨å¢å¼ºéŸµå¾‹çš„è¯­è°ƒå’Œè¡¨è¾¾æ–¹é¢ã€‚ProsodyFMå¼•å…¥äº†ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šä¸€ä¸ªçŸ­è¯­æ–­å¥ç¼–ç å™¨ï¼Œç”¨äºæ•æ‰åˆå§‹æ–­å¥ä½ç½®ï¼Œéšåæ˜¯ä¸€ä¸ªæ—¶é•¿é¢„æµ‹å™¨ï¼Œç”¨äºçµæ´»åœ°è°ƒæ•´æ–­å¥æ—¶é•¿ï¼›è¿˜æœ‰ä¸€ä¸ªç»ˆç«¯è¯­è°ƒç¼–ç å™¨ï¼Œå®ƒç»“åˆäº†è¯­è°ƒå½¢çŠ¶æ ‡è®°å’Œä¸€ç§æ–°çš„éŸ³è°ƒå¤„ç†å™¨ï¼Œä»¥æ›´ç¨³å¥åœ°æ¨¡æ‹Ÿäººç±»æ„ŸçŸ¥çš„è¯­è°ƒå˜åŒ–ã€‚ProsodyFMæ— éœ€æ˜ç¡®çš„éŸµå¾‹æ ‡ç­¾å³å¯è¿›è¡Œè®­ç»ƒï¼Œä½†å¯ä»¥æ­ç¤ºå¹¿æ³›çš„æ–­å¥æ—¶é•¿å’Œè¯­è°ƒæ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å››ç§æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼ŒProsodyFMå¯ä»¥æœ‰æ•ˆåœ°æ”¹å–„éŸµå¾‹çš„è¡¨è¾¾å’Œè¯­è°ƒæ–¹é¢ï¼Œä»è€Œæé«˜æ•´ä½“çš„å¯æ‡‚åº¦ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹æœªè§è¿‡çš„å¤æ‚å¥å­å’Œè¯´è¯è€…çš„å®éªŒè¡¨æ˜ï¼ŒProsodyFMåœ¨æ³›åŒ–èƒ½åŠ›ä¸Šå…·æœ‰ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„æ¡ˆä¾‹ç ”ç©¶ç›´è§‚åœ°å±•ç¤ºäº†ProsodyFMåœ¨è¡¨è¾¾å’Œè¯­è°ƒæ–¹é¢çš„å¼ºå¤§å’Œç²¾ç»†å¯æ§æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬ä¸­çš„éŸµå¾‹ä¿¡æ¯å¯¹è¯­éŸ³çš„å¯æ‡‚åº¦è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰è¯­éŸ³åˆæˆæ¨¡å‹åœ¨è¡¨è¾¾å’Œè¯­è°ƒæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„éŸµå¾‹æ„ŸçŸ¥æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆæ¨¡å‹â€”â€”ProsodyFMã€‚</li>
<li>ProsodyFMåŒ…å«çŸ­è¯­æ–­å¥ç¼–ç å™¨ã€æ—¶é•¿é¢„æµ‹å™¨å’Œç»ˆç«¯è¯­è°ƒç¼–ç å™¨ä¸‰ä¸ªå…³é”®ç»„ä»¶ã€‚</li>
<li>ProsodyFMæ— éœ€æ˜ç¡®çš„éŸµå¾‹æ ‡ç­¾å³å¯è¿›è¡Œè®­ç»ƒï¼Œå¹¶èƒ½æ­ç¤ºå¹¿æ³›çš„æ–­å¥æ—¶é•¿å’Œè¯­è°ƒæ¨¡å¼ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒProsodyFMåœ¨è¡¨è¾¾å’Œè¯­è°ƒæ–¹é¢ä¼˜äºå…¶ä»–å…ˆè¿›æ¨¡å‹ï¼Œæé«˜äº†è¯­éŸ³çš„æ•´ä½“å¯æ‡‚åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11795">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bc2700e586faf6c530d1991b60e0070b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-512fd61d7c098a56063450b371b8474d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a87b34706eca829194ec8aa82370d56c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b46770780f9c00a34107b6ee55fc5722.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2c32f83692e4bdf11e40a8cccac8d520.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Region-Based-Optimization-in-Continual-Learning-for-Audio-Deepfake-Detection"><a href="#Region-Based-Optimization-in-Continual-Learning-for-Audio-Deepfake-Detection" class="headerlink" title="Region-Based Optimization in Continual Learning for Audio Deepfake   Detection"></a>Region-Based Optimization in Continual Learning for Audio Deepfake   Detection</h2><p><strong>Authors:Yujie Chen, Jiangyan Yi, Cunhang Fan, Jianhua Tao, Yong Ren, Siding Zeng, Chu Yuan Zhang, Xinrui Yan, Hao Gu, Jun Xue, Chenglong Wang, Zhao Lv, Xiaohui Zhang</strong></p>
<p>Rapid advancements in speech synthesis and voice conversion bring convenience but also new security risks, creating an urgent need for effective audio deepfake detection. Although current models perform well, their effectiveness diminishes when confronted with the diverse and evolving nature of real-world deepfakes. To address this issue, we propose a continual learning method named Region-Based Optimization (RegO) for audio deepfake detection. Specifically, we use the Fisher information matrix to measure important neuron regions for real and fake audio detection, dividing them into four regions. First, we directly fine-tune the less important regions to quickly adapt to new tasks. Next, we apply gradient optimization in parallel for regions important only to real audio detection, and in orthogonal directions for regions important only to fake audio detection. For regions that are important to both, we use sample proportion-based adaptive gradient optimization. This region-adaptive optimization ensures an appropriate trade-off between memory stability and learning plasticity. Additionally, to address the increase of redundant neurons from old tasks, we further introduce the Ebbinghaus forgetting mechanism to release them, thereby promoting the capability of the model to learn more generalized discriminative features. Experimental results show our method achieves a 21.3% improvement in EER over the state-of-the-art continual learning approach RWM for audio deepfake detection. Moreover, the effectiveness of RegO extends beyond the audio deepfake detection domain, showing potential significance in other tasks, such as image recognition. The code is available at <a target="_blank" rel="noopener" href="https://github.com/cyjie429/RegO">https://github.com/cyjie429/RegO</a> </p>
<blockquote>
<p>éšç€è¯­éŸ³åˆæˆå’Œè¯­éŸ³è½¬æ¢çš„å¿«é€Ÿå‘å±•ï¼Œè™½ç„¶ç°æœ‰çš„æ¨¡å‹åœ¨éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†å½“é¢å¯¹ç°å®ä¸–ç•Œä¸­å¤šæ ·ä¸”ä¸æ–­æ¼”å˜çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ—¶ï¼Œå…¶æœ‰æ•ˆæ€§ä¼šé™ä½ï¼Œè¿™æ—¢å¸¦æ¥äº†ä¾¿åˆ©ä¹Ÿå¸¦æ¥äº†æ–°çš„å®‰å…¨é£é™©ï¼Œä»è€Œè¿«åˆ‡éœ€è¦æœ‰æ•ˆçš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æŠ€æœ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºéŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹çš„æŒç»­å­¦ä¹ æ–¹æ³•ï¼Œç§°ä¸ºåŸºäºåŒºåŸŸçš„ä¼˜åŒ–ï¼ˆRegOï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨Fisherä¿¡æ¯çŸ©é˜µæ¥è¡¡é‡çœŸå®å’Œä¼ªé€ éŸ³é¢‘æ£€æµ‹ä¸­é‡è¦çš„ç¥ç»å…ƒåŒºåŸŸï¼Œå¹¶å°†å…¶åˆ†ä¸ºå››ä¸ªåŒºåŸŸã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ç›´æ¥å¾®è°ƒä¸å¤ªé‡è¦çš„åŒºåŸŸä»¥å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯¹ä»…å¯¹çœŸå®éŸ³é¢‘æ£€æµ‹é‡è¦çš„åŒºåŸŸè¿›è¡Œå¹¶è¡Œæ¢¯åº¦ä¼˜åŒ–ï¼Œè€Œå¯¹ä»…å¯¹ä¼ªé€ éŸ³é¢‘æ£€æµ‹é‡è¦çš„åŒºåŸŸè¿›è¡Œæ­£äº¤æ–¹å‘ä¸Šçš„æ¢¯åº¦ä¼˜åŒ–ã€‚å¯¹äºä¸¤è€…éƒ½é‡è¦çš„åŒºåŸŸï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºæ ·æœ¬æ¯”ä¾‹çš„é€‚åº”æ€§æ¢¯åº¦ä¼˜åŒ–ã€‚è¿™ç§åŒºåŸŸè‡ªé€‚åº”ä¼˜åŒ–ç¡®ä¿äº†å†…å­˜ç¨³å®šæ€§å’Œå­¦ä¹ å¯å¡‘æ€§ä¹‹é—´çš„é€‚å½“æƒè¡¡ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³æ—§ä»»åŠ¡ä¸­å†—ä½™ç¥ç»å…ƒçš„å¢åŠ é—®é¢˜ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†è‰¾å®¾æµ©æ–¯é—å¿˜æœºåˆ¶æ¥é‡Šæ”¾å®ƒä»¬ï¼Œä»è€Œä¿ƒè¿›æ¨¡å‹å­¦ä¹ æ›´é€šç”¨çš„åˆ¤åˆ«ç‰¹å¾çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹çš„EERä¸Šæ¯”æœ€æ–°æŒç»­å­¦ä¹ æ–¹æ³•RWMæé«˜äº†21.3%ã€‚è€Œä¸”ï¼ŒRegOçš„æœ‰æ•ˆæ€§ä¸ä»…å±€é™äºéŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹é¢†åŸŸï¼Œåœ¨å›¾åƒè¯†åˆ«ç­‰å…¶ä»–ä»»åŠ¡ä¸­ä¹Ÿæ˜¾ç¤ºå‡ºæ½œåœ¨çš„é‡è¦æ€§ã€‚ç›¸å…³ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/cyjie429/RegO%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/cyjie429/RegOè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11551v1">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹çš„æ–°æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹åœ¨åº”å¯¹çœŸå®ä¸–ç•Œæ·±åº¦ä¼ªé€ æ—¶æ•ˆæœä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåŒºåŸŸä¼˜åŒ–çš„æŒç»­å­¦ä¹ æ–¹æ³•ï¼ˆRegOï¼‰ã€‚è¯¥æ–¹æ³•ä½¿ç”¨Fisherä¿¡æ¯çŸ©é˜µå¯¹éŸ³é¢‘çœŸå®ä¸ä¼ªé€ æ£€æµ‹ä¸­çš„é‡è¦ç¥ç»å…ƒåŒºåŸŸè¿›è¡Œåˆ’åˆ†ï¼Œé‡‡ç”¨ä¸åŒä¼˜åŒ–ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸Šçš„æ€§èƒ½è¾ƒæœ€æ–°æŒç»­å­¦ä¹ æ–¹æ³•RWMæé«˜äº†21.3%ã€‚åŒæ—¶ï¼ŒRegOæ–¹æ³•åœ¨å…¶ä»–ä»»åŠ¡å¦‚å›¾åƒè¯†åˆ«ä¸­ä¹Ÿæ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³åˆæˆå’Œè¯­éŸ³è½¬æ¢çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†ä¾¿åˆ©ï¼ŒåŒæ—¶ä¹Ÿå¸¦æ¥äº†æ–°çš„å®‰å…¨é£é™©ï¼Œå¯¹éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æå‡ºäº†è¿«åˆ‡éœ€æ±‚ã€‚</li>
<li>å½“å‰æ¨¡å‹åœ¨åº”å¯¹çœŸå®ä¸–ç•Œæ·±åº¦ä¼ªé€ æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>æå‡ºçš„RegOæ–¹æ³•ä½¿ç”¨Fisherä¿¡æ¯çŸ©é˜µåˆ’åˆ†é‡è¦ç¥ç»å…ƒåŒºåŸŸï¼Œå¹¶é‡‡ç”¨ä¸åŒä¼˜åŒ–ç­–ç•¥æ¥æé«˜éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹çš„æ€§èƒ½ã€‚</li>
<li>RegOæ–¹æ³•é€šè¿‡ç›´æ¥å¾®è°ƒæ¬¡è¦åŒºåŸŸã€å¯¹çœŸå®éŸ³é¢‘æ£€æµ‹é‡è¦åŒºåŸŸåº”ç”¨æ¢¯åº¦ä¼˜åŒ–ã€é‡Šæ”¾å†—ä½™ç¥ç»å…ƒç­‰æœºåˆ¶ï¼Œå®ç°äº†è®°å¿†ç¨³å®šæ€§ä¸å­¦ä¹ å¯å¡‘æ€§ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>Ebbinghauså¿˜è®°æœºåˆ¶è¢«å¼•å…¥ä»¥é‡Šæ”¾å†—ä½™ç¥ç»å…ƒï¼Œæé«˜æ¨¡å‹å­¦ä¹ æ›´é€šç”¨åˆ¤åˆ«ç‰¹å¾çš„èƒ½åŠ›ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRegOæ–¹æ³•åœ¨éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸Šçš„æ€§èƒ½è¾ƒRWMæœ‰æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11551">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5ec3916cda4db7fb3ba8a07bec82bb82.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce4233cfb3e86f813abe9b7524e07414.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53d98381ea03abefb8a4eb8305f085b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d11926a2480a9f1568c949c3bfc92879.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e460503f63d6a801c5ea8127a342ce19.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Multi-modal-and-Multi-scale-Spatial-Environment-Understanding-for-Immersive-Visual-Text-to-Speech"><a href="#Multi-modal-and-Multi-scale-Spatial-Environment-Understanding-for-Immersive-Visual-Text-to-Speech" class="headerlink" title="Multi-modal and Multi-scale Spatial Environment Understanding for   Immersive Visual Text-to-Speech"></a>Multi-modal and Multi-scale Spatial Environment Understanding for   Immersive Visual Text-to-Speech</h2><p><strong>Authors:Rui Liu, Shuwei He, Yifan Hu, Haizhou Li</strong></p>
<p>Visual Text-to-Speech (VTTS) aims to take the environmental image as the prompt to synthesize the reverberant speech for the spoken content. The challenge of this task lies in understanding the spatial environment from the image. Many attempts have been made to extract global spatial visual information from the RGB space of an spatial image. However, local and depth image information are crucial for understanding the spatial environment, which previous works have ignored. To address the issues, we propose a novel multi-modal and multi-scale spatial environment understanding scheme to achieve immersive VTTS, termed M2SE-VTTS. The multi-modal aims to take both the RGB and Depth spaces of the spatial image to learn more comprehensive spatial information, and the multi-scale seeks to model the local and global spatial knowledge simultaneously. Specifically, we first split the RGB and Depth images into patches and adopt the Gemini-generated environment captions to guide the local spatial understanding. After that, the multi-modal and multi-scale features are integrated by the local-aware global spatial understanding. In this way, M2SE-VTTS effectively models the interactions between local and global spatial contexts in the multi-modal spatial environment. Objective and subjective evaluations suggest that our model outperforms the advanced baselines in environmental speech generation. The code and audio samples are available at: <a target="_blank" rel="noopener" href="https://github.com/AI-S2-Lab/M2SE-VTTS">https://github.com/AI-S2-Lab/M2SE-VTTS</a>. </p>
<blockquote>
<p>è§†è§‰æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆVTTSï¼‰æ—¨åœ¨ä»¥ç¯å¢ƒå›¾åƒä¸ºæç¤ºï¼Œåˆæˆä¸è¯­éŸ³å†…å®¹ç›¸ç¬¦çš„å›å“è¯­éŸ³ã€‚è¯¥ä»»åŠ¡é¢ä¸´çš„æŒ‘æˆ˜åœ¨äºä»å›¾åƒä¸­ç†è§£ç©ºé—´ç¯å¢ƒã€‚è®¸å¤šå°è¯•éƒ½è¯•å›¾ä»ç©ºé—´å›¾åƒçš„RGBç©ºé—´ä¸­æå–å…¨å±€ç©ºé—´è§†è§‰ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå±€éƒ¨å’Œæ·±åº¦å›¾åƒä¿¡æ¯å¯¹äºç†è§£ç©ºé—´ç¯å¢ƒè‡³å…³é‡è¦ï¼Œè€Œä»¥å‰çš„å·¥ä½œå´å¿½ç•¥äº†è¿™ä¸€ç‚¹ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡å¼ã€å¤šå°ºåº¦çš„ç©ºé—´ç¯å¢ƒç†è§£æ–¹æ¡ˆï¼Œä»¥å®ç°æ²‰æµ¸å¼VTTSï¼Œç§°ä¸ºM2SE-VTTSã€‚å¤šæ¨¡å¼æ—¨åœ¨åˆ©ç”¨ç©ºé—´å›¾åƒçš„RGBå’Œæ·±åº¦ç©ºé—´æ¥å­¦ä¹ æ›´å…¨é¢çš„ç©ºé—´ä¿¡æ¯ï¼Œè€Œå¤šå°ºåº¦åˆ™æ—¨åœ¨åŒæ—¶å»ºæ¨¡å±€éƒ¨å’Œå…¨å±€ç©ºé—´çŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå°†RGBå’Œæ·±åº¦å›¾åƒåˆ†å‰²æˆæ–‘å—ï¼Œå¹¶é‡‡ç”¨Geminiç”Ÿæˆçš„ç¯å¢ƒå­—å¹•æ¥æŒ‡å¯¼å±€éƒ¨ç©ºé—´ç†è§£ã€‚ä¹‹åï¼Œé€šè¿‡å±€éƒ¨æ„ŸçŸ¥å…¨å±€ç©ºé—´ç†è§£ï¼Œå°†å¤šæ¨¡å¼å’Œå¤šå°ºåº¦ç‰¹å¾ç›¸ç»“åˆã€‚è¿™æ ·ï¼ŒM2SE-VTTSæœ‰æ•ˆåœ°å»ºæ¨¡äº†å¤šæ¨¡å¼ç©ºé—´ç¯å¢ƒä¸­å±€éƒ¨å’Œå…¨å±€ç©ºé—´ä¸Šä¸‹æ–‡ä¹‹é—´çš„äº¤äº’ã€‚å®¢è§‚å’Œä¸»è§‚è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ç¯å¢ƒè¯­éŸ³ç”Ÿæˆæ–¹é¢ä¼˜äºå…ˆè¿›çš„åŸºçº¿æ¨¡å‹ã€‚ä»£ç å’ŒéŸ³é¢‘æ ·æœ¬å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/AI-S2-Lab/M2SE-VTTS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/AI-S2-Lab/M2SE-VTTSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11409v2">PDF</a> 9 pages,2 figures, Accepted by AAAIâ€™2025</p>
<p><strong>Summary</strong><br>     è§†è§‰æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆVTTSï¼‰ä»¥ç¯å¢ƒå›¾åƒä¸ºæç¤ºåˆæˆè¯­éŸ³å†…å®¹ã€‚å…¶æŒ‘æˆ˜åœ¨äºä»å›¾åƒç†è§£ç©ºé—´ç¯å¢ƒã€‚ä¸ºæ›´å¥½åœ°äº†è§£ç©ºé—´ç¯å¢ƒï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ–°é¢–çš„å¤šæ¨¡å¼å¤šå°ºåº¦ç©ºé—´ç¯å¢ƒç†è§£æ–¹æ¡ˆï¼Œå®ç°æ²‰æµ¸å¼VTTSï¼Œç§°ä¸ºM2SE-VTTSã€‚è¯¥æ–¹æ¡ˆæ—¨åœ¨åŒæ—¶åˆ©ç”¨å›¾åƒçš„RGBå’Œæ·±åº¦ç©ºé—´å­¦ä¹ æ›´å…¨é¢çš„ç©ºé—´ä¿¡æ¯ï¼Œå¹¶åŒæ—¶å»ºæ¨¡å±€éƒ¨å’Œå…¨å±€ç©ºé—´çŸ¥è¯†ã€‚é€šè¿‡åˆ†å‰²RGBå’Œæ·±åº¦å›¾åƒæˆè¡¥ä¸å¹¶é‡‡ç”¨Geminiç”Ÿæˆçš„ç¯å¢ƒå­—å¹•æ¥æŒ‡å¯¼å±€éƒ¨ç©ºé—´ç†è§£ï¼Œç„¶åæ•´åˆå¤šæ¨¡å¼å¤šå°ºåº¦ç‰¹å¾ã€‚è¿™ç§æ–¹å¼æœ‰æ•ˆåœ°å»ºæ¨¡äº†å¤šæ¨¡å¼ç©ºé—´ç¯å¢ƒä¸­å±€éƒ¨å’Œå…¨å±€ç©ºé—´ä¸Šä¸‹æ–‡ä¹‹é—´çš„äº¤äº’ã€‚å®¢è§‚å’Œä¸»è§‚è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ç¯å¢ƒè¯­éŸ³ç”Ÿæˆæ–¹é¢ä¼˜äºå…ˆè¿›åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VTTSä»¥ç¯å¢ƒå›¾åƒä¸ºæç¤ºåˆæˆè¯­éŸ³å†…å®¹ã€‚</li>
<li>ç†è§£ç©ºé—´ç¯å¢ƒæ˜¯VTTSçš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä¸€ç§æ–°é¢–çš„å¤šæ¨¡å¼å¤šå°ºåº¦ç©ºé—´ç¯å¢ƒç†è§£æ–¹æ¡ˆM2SE-VTTSã€‚</li>
<li>M2SE-VTTSåŒæ—¶åˆ©ç”¨å›¾åƒçš„RGBå’Œæ·±åº¦ç©ºé—´ã€‚</li>
<li>M2SE-VTTSé€šè¿‡åˆ†å‰²å›¾åƒå¹¶æ•´åˆå¤šæ¨¡å¼å¤šå°ºåº¦ç‰¹å¾æ¥å®ç°å±€éƒ¨å’Œå…¨å±€ç©ºé—´çŸ¥è¯†çš„å»ºæ¨¡ã€‚</li>
<li>M2SE-VTTSæœ‰æ•ˆåœ°å»ºæ¨¡äº†å¤šæ¨¡å¼ç©ºé—´ç¯å¢ƒä¸­å±€éƒ¨å’Œå…¨å±€ç©ºé—´ä¸Šä¸‹æ–‡çš„äº¤äº’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11409">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9d4b59d9d40f7b4691cbebe8b175e12d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-536e36346343d82f79dfd72745661d1b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5bfa305460b888bdd5f8b636969786e4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bfe3d84b30cce3c4a16f7859ca4117c0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Efficient-Generative-Modeling-with-Residual-Vector-Quantization-Based-Tokens"><a href="#Efficient-Generative-Modeling-with-Residual-Vector-Quantization-Based-Tokens" class="headerlink" title="Efficient Generative Modeling with Residual Vector Quantization-Based   Tokens"></a>Efficient Generative Modeling with Residual Vector Quantization-Based   Tokens</h2><p><strong>Authors:Jaehyeon Kim, Taehong Moon, Keon Lee, Jaewoong Cho</strong></p>
<p>We explore the use of Residual Vector Quantization (RVQ) for high-fidelity generation in vector-quantized generative models. This quantization technique maintains higher data fidelity by employing more in-depth tokens. However, increasing the token number in generative models leads to slower inference speeds. To this end, we introduce ResGen, an efficient RVQ-based discrete diffusion model that generates high-fidelity samples without compromising sampling speed. Our key idea is a direct prediction of vector embedding of collective tokens rather than individual ones. Moreover, we demonstrate that our proposed token masking and multi-token prediction method can be formulated within a principled probabilistic framework using a discrete diffusion process and variational inference. We validate the efficacy and generalizability of the proposed method on two challenging tasks across different modalities: conditional image generation} on ImageNet 256x256 and zero-shot text-to-speech synthesis. Experimental results demonstrate that ResGen outperforms autoregressive counterparts in both tasks, delivering superior performance without compromising sampling speed. Furthermore, as we scale the depth of RVQ, our generative models exhibit enhanced generation fidelity or faster sampling speeds compared to similarly sized baseline models. The project page can be found at <a target="_blank" rel="noopener" href="https://resgen-genai.github.io/">https://resgen-genai.github.io</a> </p>
<blockquote>
<p>æˆ‘ä»¬æ¢è®¨äº†æ®‹å·®å‘é‡é‡åŒ–ï¼ˆRVQï¼‰åœ¨é«˜ä¿çœŸç”Ÿæˆå‘é‡é‡åŒ–ç”Ÿæˆæ¨¡å‹ä¸­çš„åº”ç”¨ã€‚è¿™ç§é‡åŒ–æŠ€æœ¯é€šè¿‡é‡‡ç”¨æ›´æ·±å…¥çš„æ ‡è®°æ¥ä¿æŒæ›´é«˜çš„æ•°æ®ä¿çœŸåº¦ã€‚ç„¶è€Œï¼Œåœ¨ç”Ÿæˆæ¨¡å‹ä¸­å¢åŠ æ ‡è®°æ•°é‡ä¼šå¯¼è‡´æ¨ç†é€Ÿåº¦å˜æ…¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ResGenï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºRVQçš„é«˜æ•ˆç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²é‡‡æ ·é€Ÿåº¦çš„æƒ…å†µä¸‹ç”Ÿæˆé«˜ä¿çœŸæ ·æœ¬ã€‚æˆ‘ä»¬çš„å…³é”®æƒ³æ³•æ˜¯é¢„æµ‹é›†ä½“æ ‡è®°çš„å‘é‡åµŒå…¥è€Œä¸æ˜¯å•ä¸ªæ ‡è®°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ ‡è®°æ©ç å’Œå¤šæ ‡è®°é¢„æµ‹æ–¹æ³•å¯ä»¥ä½¿ç”¨ç¦»æ•£æ‰©æ•£è¿‡ç¨‹å’Œå˜åˆ†æ¨æ–­åœ¨åŸåˆ™æ€§æ¦‚ç‡æ¡†æ¶å†…åˆ¶å®šã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªä¸åŒæ¨¡æ€çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸ŠéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ï¼šImageNet 256x256ä¸Šçš„æ¡ä»¶å›¾åƒç”Ÿæˆå’Œé›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒResGenåœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸­éƒ½ä¼˜äºè‡ªå›å½’æ–¹æ³•ï¼Œåœ¨ä¸ç‰ºç‰²é‡‡æ ·é€Ÿåº¦çš„æƒ…å†µä¸‹å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œéšç€æˆ‘ä»¬æ‰©å¤§RVQçš„æ·±åº¦ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆæ¨¡å‹ä¸ç±»ä¼¼è§„æ¨¡çš„åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„ç”Ÿæˆä¿çœŸåº¦æˆ–æ›´å¿«çš„é‡‡æ ·é€Ÿåº¦ã€‚é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://resgen-genai.github.ioæ‰¾åˆ°./">https://resgen-genai.github.ioæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10208v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ‘˜è¦ä»‹ç»äº†Residual Vector Quantizationï¼ˆRVQï¼‰åœ¨å‘é‡é‡åŒ–ç”Ÿæˆæ¨¡å‹ä¸­çš„åº”ç”¨ï¼Œå¹¶æ¢è®¨å¦‚ä½•é€šè¿‡ä¿æŒæ›´é«˜æ•°æ®ä¿çœŸåº¦çš„åŒæ—¶æé«˜æ•ˆç‡æ¥è§£å†³ç”Ÿæˆæ¨¡å‹çš„æ¨æ–­é€Ÿåº¦é—®é¢˜ã€‚ç ”ç©¶äººå‘˜å¼•å…¥äº†ResGenæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºRVQçš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²é‡‡æ ·é€Ÿåº¦çš„æƒ…å†µä¸‹ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å¯¹é›†ä½“å‘é‡åµŒå…¥çš„ç›´æ¥é¢„æµ‹ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§æœ‰åŸåˆ™çš„éšæœºè¿‡ç¨‹å’Œå˜åˆ†æ¨æ–­æ¥è¡¨è¿°æ‰€æå‡ºçš„æ–¹æ³•ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒResGenåœ¨æ¡ä»¶å›¾åƒç”Ÿæˆå’Œé›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆç­‰ä»»åŠ¡ä¸Šä¼˜äºè‡ªå›å½’æ¨¡å‹ï¼Œä¸”éšç€RVQæ·±åº¦çš„å¢åŠ ï¼Œå…¶ç”Ÿæˆè´¨é‡å’Œé‡‡æ ·é€Ÿåº¦éƒ½æœ‰æ‰€æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯è¯¥æ–‡æœ¬çš„å…³é”®è§è§£ï¼š</p>
<ol>
<li>Residual Vector Quantizationï¼ˆRVQï¼‰ç”¨äºæé«˜å‘é‡é‡åŒ–ç”Ÿæˆæ¨¡å‹çš„æ•°æ®ä¿çœŸåº¦ã€‚</li>
<li>ç”Ÿæˆæ¨¡å‹ä¸­å¢åŠ tokenæ•°é‡ä¼šå¯¼è‡´æ¨æ–­é€Ÿåº¦ä¸‹é™ã€‚</li>
<li>ResGenæ˜¯ä¸€ä¸ªé«˜æ•ˆçš„åŸºäºRVQçš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼Œèƒ½åŒæ—¶å®ç°é«˜ä¿çœŸåº¦æ ·æœ¬ç”Ÿæˆå’Œå¿«é€Ÿé‡‡æ ·ã€‚</li>
<li>æ ¸å¿ƒæ€æƒ³æ˜¯å¯¹é›†ä½“tokenå‘é‡åµŒå…¥çš„ç›´æ¥é¢„æµ‹è€Œéå•ä¸ªtokençš„é¢„æµ‹ã€‚</li>
<li>æå‡ºçš„æ–¹æ³•åœ¨æ¡ä»¶å›¾åƒç”Ÿæˆå’Œé›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>ä¸è‡ªå›å½’æ¨¡å‹ç›¸æ¯”ï¼ŒResGenå±•ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10208">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31cd55db7de65f71324b8e938087bd00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15d33db3d4919e0e7ddfb506a4b75f12.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="CosyVoice-2-Scalable-Streaming-Speech-Synthesis-with-Large-Language-Models"><a href="#CosyVoice-2-Scalable-Streaming-Speech-Synthesis-with-Large-Language-Models" class="headerlink" title="CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language   Models"></a>CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language   Models</h2><p><strong>Authors:Zhihao Du, Yuxuan Wang, Qian Chen, Xian Shi, Xiang Lv, Tianyu Zhao, Zhifu Gao, Yexin Yang, Changfeng Gao, Hui Wang, Fan Yu, Huadai Liu, Zhengyan Sheng, Yue Gu, Chong Deng, Wen Wang, Shiliang Zhang, Zhijie Yan, Jingren Zhou</strong></p>
<p>In our previous work, we introduced CosyVoice, a multilingual speech synthesis model based on supervised discrete speech tokens. By employing progressive semantic decoding with two popular generative models, language models (LMs) and Flow Matching, CosyVoice demonstrated high prosody naturalness, content consistency, and speaker similarity in speech in-context learning. Recently, significant progress has been made in multi-modal large language models (LLMs), where the response latency and real-time factor of speech synthesis play a crucial role in the interactive experience. Therefore, in this report, we present an improved streaming speech synthesis model, CosyVoice 2, which incorporates comprehensive and systematic optimizations. Specifically, we introduce finite-scalar quantization to improve the codebook utilization of speech tokens. For the text-speech LM, we streamline the model architecture to allow direct use of a pre-trained LLM as the backbone. In addition, we develop a chunk-aware causal flow matching model to support various synthesis scenarios, enabling both streaming and non-streaming synthesis within a single model. By training on a large-scale multilingual dataset, CosyVoice 2 achieves human-parity naturalness, minimal response latency, and virtually lossless synthesis quality in the streaming mode. We invite readers to listen to the demos at <a target="_blank" rel="noopener" href="https://funaudiollm.github.io/cosyvoice2">https://funaudiollm.github.io/cosyvoice2</a>. </p>
<blockquote>
<p>åœ¨ä¹‹å‰çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†CosyVoiceï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºç›‘ç£ç¦»æ•£è¯­éŸ³æ ‡è®°çš„å¤šè¯­ç§è¯­éŸ³åˆæˆæ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨ä¸¤ç§æµè¡Œçš„ç”Ÿæˆæ¨¡å‹â€”â€”è¯­è¨€æ¨¡å‹å’ŒæµåŒ¹é…ï¼Œè¿›è¡Œæ¸è¿›å¼è¯­ä¹‰è§£ç ï¼ŒCosyVoiceåœ¨è¯­å¢ƒä¸­å­¦ä¹ è¯­éŸ³æ—¶ï¼Œè¡¨ç°å‡ºé«˜åº¦çš„è¯­è°ƒè‡ªç„¶æ€§ã€å†…å®¹ä¸€è‡´æ€§å’Œè¯´è¯äººç›¸ä¼¼æ€§ã€‚æœ€è¿‘ï¼Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—äº†é‡å¤§è¿›å±•ï¼Œå…¶ä¸­è¯­éŸ³åˆæˆçš„å“åº”å»¶è¿Ÿå’Œå®æ—¶å› ç´ åœ¨äº¤äº’ä½“éªŒä¸­å‘æŒ¥äº†å…³é”®ä½œç”¨ã€‚å› æ­¤ï¼Œåœ¨è¿™ä»½æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ”¹è¿›çš„æµå¼è¯­éŸ³åˆæˆæ¨¡å‹CosyVoice 2ï¼Œå®ƒåŒ…å«äº†å…¨é¢å’Œç³»ç»Ÿçš„ä¼˜åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥æœ‰é™æ ‡é‡é‡åŒ–æ¥æé«˜è¯­éŸ³æ ‡è®°çš„ç æœ¬åˆ©ç”¨ç‡ã€‚å¯¹äºæ–‡æœ¬-è¯­éŸ³LMï¼Œæˆ‘ä»¬ç®€åŒ–äº†æ¨¡å‹æ¶æ„ï¼Œå…è®¸ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºéª¨å¹²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å—æ„ŸçŸ¥å› æœæµåŒ¹é…æ¨¡å‹ï¼Œä»¥æ”¯æŒå„ç§åˆæˆåœºæ™¯ï¼Œèƒ½åœ¨å•ä¸ªæ¨¡å‹ä¸­å®ç°æµå¼å’Œéæµå¼åˆæˆã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡å¤šè¯­ç§æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒCosyVoice 2è¾¾åˆ°äº†ä¸äººç±»ç›¸å½“çš„è‡ªç„¶åº¦ã€æçŸ­çš„å“åº”å»¶è¿Ÿï¼Œä»¥åŠåœ¨æµå¼æ¨¡å¼ä¸‹çš„å‡ ä¹æ— æŸçš„åˆæˆè´¨é‡ã€‚æˆ‘ä»¬é‚€è¯·è¯»è€…åœ¨<a target="_blank" rel="noopener" href="https://funaudiollm.github.io/cosyvoice">https://funaudiollm.github.io/cosyvoice</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10117v2">PDF</a> Tech report, work in progress</p>
<p><strong>æ‘˜è¦</strong><br>åŸºäºå…ˆå‰çš„å·¥ä½œï¼Œæˆ‘ä»¬æ¨å‡ºäº†CosyVoice 2ï¼Œä¸€ä¸ªä¼˜åŒ–çš„æµå¼è¯­éŸ³åˆæˆæ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æœ‰é™æ ‡é‡é‡åŒ–æ”¹è¿›è¯­éŸ³ä»¤ç‰Œçš„ç æœ¬åˆ©ç”¨ç‡ï¼Œç®€åŒ–æ–‡æœ¬-è¯­éŸ³LMæ¨¡å‹æ¶æ„ä»¥ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒLLMä½œä¸ºéª¨å¹²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†å—æ„ŸçŸ¥å› æœæµåŒ¹é…æ¨¡å‹ï¼Œæ”¯æŒå„ç§åˆæˆåœºæ™¯ï¼Œåœ¨å•ä¸ªæ¨¡å‹å†…å®ç°æµå’Œéæµåˆæˆã€‚é€šè¿‡å¤§è§„æ¨¡å¤šè¯­ç§æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼ŒCosyVoice 2è¾¾åˆ°äº†äººç±»è‡ªç„¶æ°´å¹³çš„è‡ªç„¶åº¦ã€æä½çš„å“åº”å»¶è¿Ÿå’Œå‡ ä¹æ— æŸçš„åˆæˆè´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>CosyVoice 2æ˜¯æ”¹è¿›çš„æµå¼è¯­éŸ³åˆæˆæ¨¡å‹ï¼ŒåŸºäºä¹‹å‰çš„å·¥ä½œCosyVoiceã€‚</li>
<li>å¼•å…¥æœ‰é™æ ‡é‡é‡åŒ–æ”¹è¿›è¯­éŸ³ä»¤ç‰Œçš„ç æœ¬åˆ©ç”¨ç‡ï¼Œæé«˜åˆæˆè´¨é‡ã€‚</li>
<li>ç®€åŒ–æ–‡æœ¬-è¯­éŸ³LMæ¨¡å‹æ¶æ„ï¼Œå…è®¸ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒLLMä½œä¸ºéª¨å¹²ï¼Œå¢å¼ºæ¨¡å‹çš„é€šç”¨æ€§å’Œçµæ´»æ€§ã€‚</li>
<li>å¼€å‘å—æ„ŸçŸ¥å› æœæµåŒ¹é…æ¨¡å‹ï¼Œæ”¯æŒå¤šç§åˆæˆåœºæ™¯ï¼Œå®ç°æµå’Œéæµåˆæˆã€‚</li>
<li>æ¨¡å‹åœ¨å¤§è§„æ¨¡å¤šè¯­ç§æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>CosyVoice 2è¾¾åˆ°äº†äººç±»è‡ªç„¶æ°´å¹³çš„è‡ªç„¶åº¦ï¼Œåˆæˆè´¨é‡é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10117">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c2a0a513ed5fc12ec7e9232a3a6f2db1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-013cedb83ae1d2a08609293706433d33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb8685059f388de8b82e0bc6c456ffc6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf6e7db4f0253c8902f2ba241b051a88.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="CoVoMix-Advancing-Zero-Shot-Speech-Generation-for-Human-like-Multi-talker-Conversations"><a href="#CoVoMix-Advancing-Zero-Shot-Speech-Generation-for-Human-like-Multi-talker-Conversations" class="headerlink" title="CoVoMix: Advancing Zero-Shot Speech Generation for Human-like   Multi-talker Conversations"></a>CoVoMix: Advancing Zero-Shot Speech Generation for Human-like   Multi-talker Conversations</h2><p><strong>Authors:Leying Zhang, Yao Qian, Long Zhou, Shujie Liu, Dongmei Wang, Xiaofei Wang, Midia Yousefi, Yanmin Qian, Jinyu Li, Lei He, Sheng Zhao, Michael Zeng</strong></p>
<p>Recent advancements in zero-shot text-to-speech (TTS) modeling have led to significant strides in generating high-fidelity and diverse speech. However, dialogue generation, along with achieving human-like naturalness in speech, continues to be a challenge. In this paper, we introduce CoVoMix: Conversational Voice Mixture Generation, a novel model for zero-shot, human-like, multi-speaker, multi-round dialogue speech generation. CoVoMix first converts dialogue text into multiple streams of discrete tokens, with each token stream representing semantic information for individual talkers. These token streams are then fed into a flow-matching based acoustic model to generate mixed mel-spectrograms. Finally, the speech waveforms are produced using a HiFi-GAN model. Furthermore, we devise a comprehensive set of metrics for measuring the effectiveness of dialogue modeling and generation. Our experimental results show that CoVoMix can generate dialogues that are not only human-like in their naturalness and coherence but also involve multiple talkers engaging in multiple rounds of conversation. This is exemplified by instances generated in a single channel where one speakerâ€™s utterance is seamlessly mixed with anotherâ€™s interjections or laughter, indicating the latterâ€™s role as an attentive listener. Audio samples are available at <a target="_blank" rel="noopener" href="https://aka.ms/covomix">https://aka.ms/covomix</a>. </p>
<blockquote>
<p>è¿‘æœŸé›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å»ºæ¨¡çš„è¿›å±•ä¸ºç”Ÿæˆé«˜ä¿çœŸå’Œå¤šæ ·åŒ–çš„è¯­éŸ³è¿ˆå‡ºäº†é‡è¦çš„ä¸€æ­¥ã€‚ç„¶è€Œï¼Œå¯¹è¯ç”Ÿæˆä»¥åŠå®ç°è¯­éŸ³çš„äººç±»è‡ªç„¶æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†CoVoMixï¼šä¼šè¯è¯­éŸ³æ··åˆç”Ÿæˆï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºé›¶æ ·æœ¬ã€äººç±»ã€å¤šå‘è¨€äººã€å¤šè½®å¯¹è¯è¯­éŸ³ç”Ÿæˆçš„æ–°å‹æ¨¡å‹ã€‚CoVoMixé¦–å…ˆå°†å¯¹å¯¹è¯æ–‡æœ¬è½¬æ¢ä¸ºå¤šä¸ªç¦»æ•£ä»¤ç‰Œæµï¼Œæ¯ä¸ªä»¤ç‰Œæµä»£è¡¨ä¸ªåˆ«å‘è¨€è€…çš„è¯­ä¹‰ä¿¡æ¯ã€‚è¿™äº›ä»¤ç‰Œæµç„¶åè¢«è¾“å…¥åŸºäºæµåŒ¹é…çš„å£°å­¦æ¨¡å‹ï¼Œä»¥ç”Ÿæˆæ··åˆçš„æ¢…å°”é¢‘è°±å›¾ã€‚æœ€åï¼Œä½¿ç”¨HiFi-GANæ¨¡å‹ç”Ÿæˆè¯­éŸ³æ³¢å½¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€å¥—ç»¼åˆæŒ‡æ ‡æ¥è¯„ä¼°å¯¹è¯å»ºæ¨¡å’Œç”Ÿæˆçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCoVoMixå¯ä»¥ç”Ÿæˆä¸ä»…è‡ªç„¶è¿è´¯ä¸”äººæ€§åŒ–ï¼Œè€Œä¸”æ¶‰åŠå¤šä¸ªå‘è¨€è€…è¿›è¡Œå¤šè½®å¯¹è¯çš„è¯­éŸ³ã€‚è¿™ä½“ç°åœ¨å•é€šé“ç”Ÿæˆçš„å®ä¾‹ä¸­ï¼Œä¸€ä¸ªå‘è¨€äººçš„è¯è¯­å¯ä»¥æ— ç¼åœ°ä¸å…¶ä»–å‘è¨€äººçš„æ’è¯æˆ–ç¬‘å£°æ··åˆï¼Œè¿™è¡¨æ˜åè€…ä½œä¸ºå€¾å¬è€…çš„è§’è‰²ã€‚éŸ³é¢‘æ ·æœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://aka.ms/covomix%E6%89%BE%E5%88%B0%E3%80%82">https://aka.ms/covomixæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.06690v3">PDF</a> Neural Information Processing Systems 2024, poster</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†CoVoMixæ¨¡å‹ï¼Œä¸€ç§ç”¨äºé›¶æ ·æœ¬ã€äººç±»èˆ¬çš„ã€å¤šè¯´è¯è€…ã€å¤šè½®å¯¹è¯è¯­éŸ³ç”Ÿæˆçš„æ–°æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†å¯¹è¯æ–‡æœ¬è½¬æ¢ä¸ºå¤šä¸ªç¦»æ•£ä»¤ç‰Œæµï¼Œå†åˆ©ç”¨åŸºäºæµåŒ¹é…çš„å£°å­¦æ¨¡å‹ç”Ÿæˆæ··åˆæ¢…å°”é¢‘è°±å›¾ï¼Œæœ€åä½¿ç”¨HiFi-GANæ¨¡å‹ç”Ÿæˆè¯­éŸ³æ³¢å½¢ï¼Œå®ç°å¯¹è¯ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€å¥—å…¨é¢çš„åº¦é‡æ ‡å‡†æ¥è¡¡é‡å¯¹è¯å»ºæ¨¡å’Œç”Ÿæˆçš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoVoMixä¸ä»…å¯ä»¥ç”Ÿæˆäººç±»èˆ¬è‡ªç„¶å’Œè¿è´¯çš„å¯¹è¯ï¼Œè€Œä¸”å¯ä»¥æ¶‰åŠå¤šä¸ªè¯´è¯è€…åœ¨å•ä¸€é€šé“ä¸­è¿›è¡Œå¤šè½®å¯¹è¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CoVoMixæ˜¯ä¸€ç§ç”¨äºé›¶æ ·æœ¬ã€äººç±»èˆ¬çš„ã€å¤šè¯´è¯è€…ã€å¤šè½®å¯¹è¯è¯­éŸ³ç”Ÿæˆçš„æ–°æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹é€šè¿‡å°†å¯¹è¯æ–‡æœ¬è½¬æ¢ä¸ºå¤šä¸ªç¦»æ•£ä»¤ç‰Œæµæ¥å¤„ç†å¤šè¯´è¯è€…å¯¹è¯ã€‚</li>
<li>CoVoMixåˆ©ç”¨åŸºäºæµåŒ¹é…çš„å£°å­¦æ¨¡å‹ç”Ÿæˆæ··åˆæ¢…å°”é¢‘è°±å›¾ã€‚</li>
<li>HiFi-GANæ¨¡å‹ç”¨äºç”Ÿæˆè¯­éŸ³æ³¢å½¢ã€‚</li>
<li>æå‡ºäº†ä¸€å¥—å…¨é¢çš„åº¦é‡æ ‡å‡†æ¥è¡¡é‡å¯¹è¯å»ºæ¨¡å’Œç”Ÿæˆçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒCoVoMixå¯ä»¥ç”Ÿæˆè‡ªç„¶ã€è¿è´¯çš„å¤šè½®å¯¹è¯ï¼Œæ¶‰åŠå¤šä¸ªè¯´è¯è€…ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.06690">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9716230f7737dc589b1388c413df57da.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e438de1a52e9a82a0b7c2746575c06dc.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="maria-A-novel-simulator-for-forecasting-sub-mm-observations"><a href="#maria-A-novel-simulator-for-forecasting-sub-mm-observations" class="headerlink" title="maria: A novel simulator for forecasting (sub-)mm observations"></a>maria: A novel simulator for forecasting (sub-)mm observations</h2><p><strong>Authors:J. van Marrewijk, T. W. Morris, T. Mroczkowski, C. Cicone, S. Dicker, L. Di Mascolo, S. K. Haridas, J. Orlowski-Scherer, E. Rasia, C. Romero, J. WÃ¼rzinger</strong></p>
<p>Millimeter-wave single-dish telescopes offer two key advantages compared to interferometers: they can efficiently map larger portions of the sky, and they can recover larger spatial scales. Nonetheless, fluctuations in the atmosphere limit the accurate retrieval of signals from astronomical sources. To efficiently reduce atmospheric noise and filtering effects in current and future facilities, we introduce {\tt maria}, a versatile and user-friendly multi-purpose telescope simulator that optimizes scanning strategies and instrument designs, produces synthetic time-ordered data, time streams, and maps from hydrodynamical simulations, thereby enabling a fair comparison between theory and observations. Each mock observatory scans through the atmosphere in a configurable pattern over the celestial object. We generate evolving and location-and-time-specific weather for each of the fiducial sites using a combination of satellite and ground-based measurements. While {\tt maria} is a generic virtual telescope, this study specifically focuses on mimicking broadband bolometers observing at 100 GHz. We compare the mock time streams with real MUSTANG-2 observations and find that they are quantitatively similar by conducting a k-sample Anderson-Darling test resulting in a p-value of p&lt;0.001. Subsequently, we image the TODs to create noise maps and realistic mock observations of clusters of galaxies for both MUSTANG-2 and an instrument concept for the 50m Atacama Large Aperture Submillimeter Telescope (AtLAST). Furthermore, using {\tt maria}, we find that a 50m dish provides the highest levels of correlation of atmospheric signals across adjacent detectors compared to smaller apertures (e.g., 42-cm and 6-m), facilitating removal of atmospheric signal on large scales. </p>
<blockquote>
<p>æ¯«ç±³æ³¢å•ç›˜æœ›è¿œé•œä¸å¹²æ¶‰ä»ªç›¸æ¯”å…·æœ‰ä¸¤å¤§ä¼˜åŠ¿ï¼šå®ƒä»¬å¯ä»¥æœ‰æ•ˆåœ°æ˜ å°„å¤©ç©ºçš„æ›´å¤§éƒ¨åˆ†ï¼Œå¹¶ä¸”å¯ä»¥æ¢å¤æ›´å¤§çš„ç©ºé—´å°ºåº¦ã€‚ç„¶è€Œï¼Œå¤§æ°”æ³¢åŠ¨é™åˆ¶äº†ä»å¤©æ–‡æºå‡†ç¡®æ£€ç´¢ä¿¡å·ã€‚ä¸ºäº†åœ¨å½“å‰å’Œæœªæ¥çš„è®¾æ–½ä¸­æœ‰æ•ˆåœ°å‡å°‘å¤§æ°”å™ªå£°å’Œæ»¤æ³¢æ•ˆåº”ï¼Œæˆ‘ä»¬å¼•å…¥äº†{\tt maria}ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨ä¸”ç”¨æˆ·å‹å¥½çš„å¤šåŠŸèƒ½æœ›è¿œé•œæ¨¡æ‹Ÿå™¨ï¼Œå®ƒä¼˜åŒ–æ‰«æç­–ç•¥å’Œä»ªå™¨è®¾è®¡ï¼Œä»æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿä¸­äº§ç”Ÿåˆæˆæ—¶é—´é¡ºåºæ•°æ®ã€æ—¶é—´æµå’Œåœ°å›¾ï¼Œä»è€Œå®ç°ç†è®ºä¸è§‚å¯Ÿä¹‹é—´çš„å…¬å¹³æ¯”è¾ƒã€‚æ¯ä¸ªæ¨¡æ‹Ÿå¤©æ–‡å°éƒ½ä»¥å¯é…ç½®çš„æ¨¡å¼é€šè¿‡å¤§æ°”æ‰«æå¤©ä½“å¯¹è±¡ã€‚æˆ‘ä»¬ç»“åˆå«æ˜Ÿå’Œåœ°é¢æµ‹é‡ï¼Œä¸ºæ¯ä¸ªåŸºå‡†ç‚¹ç”Ÿæˆä¸æ–­å‘å±•å’Œç‰¹å®šåœ°ç‚¹å’Œæ—¶é—´çš„å¤©æ°”ã€‚è™½ç„¶{\tt maria}æ˜¯ä¸€ä¸ªé€šç”¨çš„è™šæ‹Ÿæœ›è¿œé•œï¼Œä½†è¿™é¡¹ç ”ç©¶ç‰¹åˆ«ä¾§é‡äºæ¨¡æ‹Ÿåœ¨100 GHzè§‚æµ‹çš„å®½å¸¦æµ‹è¾å°„ä»ªã€‚æˆ‘ä»¬å°†æ¨¡æ‹Ÿçš„æ—¶é—´æµä¸ç°å®ä¸­çš„MUSTANG-2è§‚æµ‹ç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶é€šè¿‡è¿›è¡Œkæ ·æœ¬å®‰å¾·æ£®-è¾¾æ—æµ‹è¯•å¾—å‡ºpå€¼ä¸ºp&lt;0.001ï¼Œå‘ç°å®ƒä»¬åœ¨æ•°é‡ä¸Šæ˜¯ç›¸ä¼¼çš„ã€‚éšåï¼Œæˆ‘ä»¬å°†æ—¶é—´åºåˆ—å›¾åƒåŒ–ä¸ºå™ªå£°å›¾ï¼Œå¹¶ä¸ºMUSTANG-2å’Œ50ç±³é˜¿å¡”å¡é©¬å¤§å£å¾„äºšæ¯«ç±³æ³¢æœ›è¿œé•œï¼ˆAtLASTï¼‰çš„æ¦‚å¿µä»ªå™¨åˆ¶ä½œé€¼çœŸçš„æ¨¡æ‹Ÿè§‚æµ‹æ˜Ÿç³»å›¢å›¾åƒã€‚æ­¤å¤–ï¼Œé€šè¿‡{\tt maria}ï¼Œæˆ‘ä»¬å‘ç°ä¸è¾ƒå°çš„å­”å¾„ï¼ˆä¾‹å¦‚42å˜ç±³å’Œ6ç±³ï¼‰ç›¸æ¯”ï¼Œ50ç±³çš„ç›˜å­åœ¨å¤§èŒƒå›´ä¸Šæä¾›æœ€é«˜æ°´å¹³çš„å¤§æ°”ä¿¡å·ç›¸å…³æ€§ï¼Œæœ‰åŠ©äºæ¶ˆé™¤å¤§æ°”ä¿¡å·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.10731v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ¯«ç±³æ³¢å•ç›˜æœ›è¿œé•œä¸å¹²æ¶‰ä»ªç›¸æ¯”å…·æœ‰ä¸¤å¤§ä¼˜åŠ¿ï¼šèƒ½å¤Ÿé«˜æ•ˆåœ°æ˜ å°„å¤©ç©ºæ›´å¤§åŒºåŸŸï¼Œå¹¶èƒ½æ¢å¤æ›´å¤§çš„ç©ºé—´å°ºåº¦ã€‚ç„¶è€Œï¼Œå¤§æ°”æ³¢åŠ¨é™åˆ¶äº†ä»å¤©æ–‡æºå‡†ç¡®æ£€ç´¢ä¿¡å·ã€‚ä¸ºäº†åœ¨å½“å‰å’Œæœªæ¥çš„è®¾æ–½ä¸­æœ‰æ•ˆåœ°å‡å°‘å¤§æ°”å™ªå£°å’Œè¿‡æ»¤æ•ˆåº”ï¼Œæˆ‘ä»¬å¼•å…¥äº†{\tt maria}ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨ä¸”ç”¨æˆ·å‹å¥½çš„å¤šåŠŸèƒ½æœ›è¿œé•œæ¨¡æ‹Ÿå™¨ï¼Œå¯ä»¥ä¼˜åŒ–æ‰«æç­–ç•¥å’Œä»ªå™¨è®¾è®¡ï¼Œä»æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿä¸­äº§ç”Ÿåˆæˆæ—¶åºæ•°æ®ã€æ—¶é—´æµå’Œåœ°å›¾ï¼Œä»è€Œå®ç°ç†è®ºä¸è§‚æµ‹ä¹‹é—´çš„å…¬å¹³æ¯”è¾ƒã€‚æ¯ä¸ªæ¨¡æ‹Ÿè§‚æµ‹ç«™éƒ½ä»¥å¯é…ç½®çš„æ¨¡å¼ç©¿è¿‡å¤§æ°”å±‚å¯¹å¤©ä½“è¿›è¡Œæ‰«æã€‚æˆ‘ä»¬ç»“åˆå«æ˜Ÿå’Œåœ°é¢æµ‹é‡ï¼Œä¸ºæ¯ä¸€ä¸ªåŸºå‡†ç‚¹ç”Ÿæˆä¸æ–­å‘å±•å’Œç‰¹å®šäºåœ°ç‚¹å’Œæ—¶é—´çš„å¤©æ°”ã€‚è™½ç„¶{\tt maria}æ˜¯ä¸€ä¸ªé€šç”¨çš„è™šæ‹Ÿæœ›è¿œé•œï¼Œä½†è¿™é¡¹ç ”ç©¶ç‰¹åˆ«å…³æ³¨æ¨¡ä»¿åœ¨100 GHzè§‚æµ‹çš„å®½å¸¦ boloä»ªã€‚æˆ‘ä»¬å°†æ¨¡æ‹Ÿçš„æ—¶é—´æµä¸å®é™…çš„MUSTANG-2è§‚æµ‹ç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œå‘ç°å®ƒä»¬åœ¨æ•°é‡ä¸Šæ˜¯ç›¸ä¼¼çš„ï¼Œé€šè¿‡è¿›è¡Œkæ ·æœ¬å®‰å¾·æ£®-è¾¾æ—æµ‹è¯•å¾—å‡ºpå€¼å°äº0.001ã€‚éšåï¼Œæˆ‘ä»¬å¯¹TODè¿›è¡Œæˆåƒä»¥åˆ›å»ºå™ªå£°å›¾å’Œç°å®çš„æ¨¡æ‹Ÿæ˜Ÿç³»å›¢è§‚æµ‹ç»“æœï¼Œè¿™äº›ç»“æœé€‚ç”¨äºMUSTANG-2å’Œ50ç±³é˜¿å¡”å¡é©¬å¤§å‹å­”å¾„äºšæ¯«ç±³æœ›è¿œé•œï¼ˆAtLASTï¼‰çš„ä»ªå™¨æ¦‚å¿µã€‚æ­¤å¤–ï¼Œé€šè¿‡{\tt maria}ï¼Œæˆ‘ä»¬å‘ç°ä¸è¾ƒå°çš„å­”å¾„ï¼ˆä¾‹å¦‚42å˜ç±³å’Œ6ç±³ï¼‰ç›¸æ¯”ï¼Œ50ç±³çš„ç›˜å­æä¾›çš„å¤§æ°”ä¿¡å·ç›¸é‚»æ¢æµ‹å™¨ä¹‹é—´çš„æœ€é«˜æ°´å¹³ç›¸å…³æ€§ï¼Œæœ‰åŠ©äºåœ¨å¤§å°ºåº¦ä¸Šæ¶ˆé™¤å¤§æ°”ä¿¡å·ã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>æ¯«ç±³æ³¢å•ç›˜æœ›è¿œé•œç›¸æ¯”å¹²æ¶‰ä»ªå…·æœ‰æ˜ å°„å¤©ç©ºåŒºåŸŸæ›´å¹¿ã€æ¢å¤ç©ºé—´å°ºåº¦æ›´å¤§çš„ä¸¤å¤§ä¼˜åŠ¿ã€‚</li>
<li>å¤§æ°”æ³¢åŠ¨å¯¹ä»å¤©æ–‡å­¦æºæ¥æ”¶ä¿¡å·äº§ç”Ÿå½±å“ï¼Œéœ€è¦å‡å°‘å¤§æ°”å™ªå£°å’Œè¿‡æ»¤æ•ˆåº”ã€‚</li>
<li>{\tt maria}æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½æœ›è¿œé•œæ¨¡æ‹Ÿå™¨ï¼Œèƒ½å¤Ÿä¼˜åŒ–æ‰«æç­–ç•¥å’Œä»ªå™¨è®¾è®¡ï¼Œå¹¶ç”Ÿæˆåˆæˆæ•°æ®ã€æ—¶é—´æµå’Œåœ°å›¾ã€‚</li>
<li>{\tt maria}æ¨¡æ‹Ÿè§‚æµ‹ç«™ä»¥ç‰¹å®šæ¨¡å¼æ‰«æå¤©ä½“ï¼ŒåŒæ—¶è€ƒè™‘å¤§æ°”å±‚çš„å½±å“ã€‚</li>
<li>é€šè¿‡ç»“åˆå«æ˜Ÿå’Œåœ°é¢æµ‹é‡ï¼Œç”Ÿæˆç‰¹å®šåœ°ç‚¹å’Œæ—¶é—´çš„å¤©æ°”æ•°æ®ã€‚</li>
<li>{\tt maria}æ¨¡æ‹Ÿç»“æœä¸MUSTANG-2å®é™…è§‚æµ‹åœ¨æ•°é‡ä¸Šç›¸ä¼¼ï¼Œç»è¿‡ä¸¥æ ¼ç»Ÿè®¡æµ‹è¯•éªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.10731">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d6f712e3be1dc50c19cd2602aa1db777.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02391d88da01c64060c2244749077344.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2f95d1af1ba15363fec4e026523a28a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f2669435526a5fa0415d06577c888492.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4558f7de649e3b44b48473b8da50fa5d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-62d437298890314e4abde63a25f2e4ad.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  Dialogue with the Machine and Dialogue with the Art World Evaluating   Generative AI for Culturally-Situated Creativity
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-62816a2ba15fa317d81e7a9f8172f741.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  Parameter-efficient Fine-tuning for improved Convolutional Baseline for   Brain Tumor Segmentation in Sub-Saharan Africa Adult Glioma Dataset
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23901.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
