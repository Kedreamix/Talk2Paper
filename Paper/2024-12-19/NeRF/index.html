<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  GraphAvatar Compact Head Avatars with GNN-Generated 3D Gaussians">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-f48b889f694388b756223771c0d053df.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    44 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-19-æ›´æ–°"><a href="#2024-12-19-æ›´æ–°" class="headerlink" title="2024-12-19 æ›´æ–°"></a>2024-12-19 æ›´æ–°</h1><h2 id="GraphAvatar-Compact-Head-Avatars-with-GNN-Generated-3D-Gaussians"><a href="#GraphAvatar-Compact-Head-Avatars-with-GNN-Generated-3D-Gaussians" class="headerlink" title="GraphAvatar: Compact Head Avatars with GNN-Generated 3D Gaussians"></a>GraphAvatar: Compact Head Avatars with GNN-Generated 3D Gaussians</h2><p><strong>Authors:Xiaobao Wei, Peng Chen, Ming Lu, Hui Chen, Feng Tian</strong></p>
<p>Rendering photorealistic head avatars from arbitrary viewpoints is crucial for various applications like virtual reality. Although previous methods based on Neural Radiance Fields (NeRF) can achieve impressive results, they lack fidelity and efficiency. Recent methods using 3D Gaussian Splatting (3DGS) have improved rendering quality and real-time performance but still require significant storage overhead. In this paper, we introduce a method called GraphAvatar that utilizes Graph Neural Networks (GNN) to generate 3D Gaussians for the head avatar. Specifically, GraphAvatar trains a geometric GNN and an appearance GNN to generate the attributes of the 3D Gaussians from the tracked mesh. Therefore, our method can store the GNN models instead of the 3D Gaussians, significantly reducing the storage overhead to just 10MB. To reduce the impact of face-tracking errors, we also present a novel graph-guided optimization module to refine face-tracking parameters during training. Finally, we introduce a 3D-aware enhancer for post-processing to enhance the rendering quality. We conduct comprehensive experiments to demonstrate the advantages of GraphAvatar, surpassing existing methods in visual fidelity and storage consumption. The ablation study sheds light on the trade-offs between rendering quality and model size. The code will be released at: <a target="_blank" rel="noopener" href="https://github.com/ucwxb/GraphAvatar">https://github.com/ucwxb/GraphAvatar</a> </p>
<blockquote>
<p>ä»ä»»æ„è§†è§’æ¸²æŸ“é€¼çœŸçš„å¤´åƒå¯¹äºè™šæ‹Ÿç°å®ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚å°½ç®¡åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å…ˆå‰æ–¹æ³•å¯ä»¥å®ç°ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä½†å®ƒä»¬ç¼ºä¹çœŸå®æ„Ÿå’Œæ•ˆç‡ã€‚ä½¿ç”¨ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰çš„æœ€è¿‘æ–¹æ³•æé«˜äº†æ¸²æŸ“è´¨é‡å’Œå®æ—¶æ€§èƒ½ï¼Œä½†ä»ç„¶éœ€è¦å¾ˆå¤§çš„å­˜å‚¨å¼€é”€ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åä¸ºGraphAvatarçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ç”Ÿæˆå¤´åƒçš„3Dé«˜æ–¯åˆ†å¸ƒã€‚å…·ä½“æ¥è¯´ï¼ŒGraphAvatarè®­ç»ƒäº†ä¸€ä¸ªå‡ ä½•GNNå’Œä¸€ä¸ªå¤–è§‚GNNï¼Œä»è·Ÿè¸ªçš„ç½‘æ ¼ä¸­äº§ç”Ÿ3Dé«˜æ–¯åˆ†å¸ƒçš„å±æ€§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å­˜å‚¨GNNæ¨¡å‹è€Œä¸æ˜¯3Dé«˜æ–¯åˆ†å¸ƒï¼Œå°†å­˜å‚¨å¼€é”€å¤§å¹…é™ä½åˆ°ä»…10MBã€‚ä¸ºäº†å‡å°‘é¢éƒ¨è·Ÿè¸ªè¯¯å·®çš„å½±å“ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªæ–°å‹çš„å›¾å¼•å¯¼ä¼˜åŒ–æ¨¡å—ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜åŒ–é¢éƒ¨è·Ÿè¸ªå‚æ•°ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç”¨äºåå¤„ç†çš„3Dæ„ŸçŸ¥å¢å¼ºå™¨ï¼Œä»¥æé«˜æ¸²æŸ“è´¨é‡ã€‚æˆ‘ä»¬è¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œå±•ç¤ºäº†GraphAvatarçš„ä¼˜åŠ¿ï¼Œåœ¨è§†è§‰çœŸå®æ„Ÿå’Œå­˜å‚¨æ¶ˆè€—æ–¹é¢è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚æ¶ˆèç ”ç©¶æ­ç¤ºäº†æ¸²æŸ“è´¨é‡å’Œæ¨¡å‹å¤§å°ä¹‹é—´çš„æƒè¡¡ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/ucwxb/GraphAvatar">https://github.com/ucwxb/GraphAvatar</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13983v1">PDF</a> accepted by AAAI2025</p>
<p><strong>æ‘˜è¦</strong><br>é‡‡ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ç”Ÿæˆå¤´æ˜¾äººç‰©æ¨¡å‹ï¼Œå®ç°é«˜ä¿çœŸåº¦æ¸²æŸ“ã€‚é€šè¿‡å‡ ä½•GNNå’Œå¤–è§‚GNNç”Ÿæˆä¸‰ç»´é«˜æ–¯åˆ†å¸ƒå±æ€§ï¼Œé™ä½å­˜å‚¨éœ€æ±‚è‡³ä»…10MBã€‚å¼•å…¥å›¾å¼•å¯¼ä¼˜åŒ–æ¨¡å—ï¼Œå‡å°‘é¢éƒ¨è·Ÿè¸ªè¯¯å·®å¯¹æ¸²æŸ“è´¨é‡çš„å½±å“ï¼Œå¹¶æå‡ºä¸‰ç»´æ„ŸçŸ¥å¢å¼ºå™¨ç”¨äºåæœŸå¤„ç†ä»¥æå‡æ¸²æŸ“è´¨é‡ã€‚å®éªŒè¯æ˜GraphAvataråœ¨è§†è§‰ä¿çœŸåº¦å’Œå­˜å‚¨æ¶ˆè€—æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ç”Ÿæˆä¸‰ç»´é«˜æ–¯åˆ†å¸ƒï¼Œå®ç°é«˜è´¨é‡çš„å¤´æ˜¾äººç‰©æ¸²æŸ“ã€‚</li>
<li>é€šè¿‡å‡ ä½•å’Œå¤–è§‚GNNæ¨¡å‹ç”Ÿæˆå±æ€§ï¼Œå¤§å¹…é™ä½å­˜å‚¨éœ€æ±‚è‡³ä»…10MBã€‚</li>
<li>å›¾å¼•å¯¼ä¼˜åŒ–æ¨¡å—å‡å°‘äº†é¢éƒ¨è·Ÿè¸ªè¯¯å·®å¯¹æ¸²æŸ“æ•ˆæœçš„å½±å“ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹çš„ä¸‰ç»´æ„ŸçŸ¥å¢å¼ºå™¨è¿›è¡Œåå¤„ç†ä»¥æå‡æ¸²æŸ“è´¨é‡ã€‚</li>
<li>å®éªŒè¯æ˜GraphAvataråœ¨è§†è§‰ä¿çœŸåº¦å’Œå­˜å‚¨æ¶ˆè€—æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ¶ˆèç ”ç©¶æ­ç¤ºäº†æ¸²æŸ“è´¨é‡å’Œæ¨¡å‹å¤§å°ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13983">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-499727917bec8913fec8dee0d29c0265.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-334573154ce596e4d0d70d1cf06d6c47.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cf870dad7b6fa78ed96a65941a326f27.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-75eda6d48b2a3d0fedaa25367e8d5cb2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-555c65c663223607d9c0758ab83bc605.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="RelationField-Relate-Anything-in-Radiance-Fields"><a href="#RelationField-Relate-Anything-in-Radiance-Fields" class="headerlink" title="RelationField: Relate Anything in Radiance Fields"></a>RelationField: Relate Anything in Radiance Fields</h2><p><strong>Authors:Sebastian Koch, Johanna Wald, Mirco Colosi, Narunas Vaskevicius, Pedro Hermosilla, Federico Tombari, Timo Ropinski</strong></p>
<p>Neural radiance fields are an emerging 3D scene representation and recently even been extended to learn features for scene understanding by distilling open-vocabulary features from vision-language models. However, current method primarily focus on object-centric representations, supporting object segmentation or detection, while understanding semantic relationships between objects remains largely unexplored. To address this gap, we propose RelationField, the first method to extract inter-object relationships directly from neural radiance fields. RelationField represents relationships between objects as pairs of rays within a neural radiance field, effectively extending its formulation to include implicit relationship queries. To teach RelationField complex, open-vocabulary relationships, relationship knowledge is distilled from multi-modal LLMs. To evaluate RelationField, we solve open-vocabulary 3D scene graph generation tasks and relationship-guided instance segmentation, achieving state-of-the-art performance in both tasks. See the project website at <a target="_blank" rel="noopener" href="https://relationfield.github.io/">https://relationfield.github.io</a>. </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºæ˜¯ä¸€ç§æ–°å…´çš„3Dåœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œæœ€è¿‘ç”šè‡³è¢«æ‰©å±•ä¸ºé€šè¿‡å­¦ä¹ ç‰¹å¾æ¥ç”¨äºåœºæ™¯ç†è§£ï¼Œé€šè¿‡ä»è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æç‚¼å¼€æ”¾è¯æ±‡ç‰¹å¾ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é¢å‘å¯¹è±¡çš„è¡¨ç¤ºä¸Šï¼Œæ”¯æŒå¯¹è±¡åˆ†å‰²æˆ–æ£€æµ‹ï¼Œè€Œç†è§£å¯¹è±¡ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ä»ç„¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæœªè¢«æ¢ç´¢ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†RelationFieldï¼Œè¿™æ˜¯ç¬¬ä¸€ç§ç›´æ¥ä»ç¥ç»è¾å°„åœºä¸­æå–å¯¹è±¡é—´å…³ç³»çš„æ–¹æ³•ã€‚RelationFieldå°†å¯¹è±¡ä¹‹é—´çš„å…³ç³»è¡¨ç¤ºä¸ºç¥ç»è¾å°„åœºå†…çš„å°„çº¿å¯¹ï¼Œæœ‰æ•ˆåœ°å°†å…¶å…¬å¼æ‰©å±•ä¸ºåŒ…æ‹¬éšå¼å…³ç³»æŸ¥è¯¢ã€‚ä¸ºäº†æ•™å¯¼RelationFieldå¤æ‚ä¸”å¼€æ”¾çš„è¯æ±‡å…³ç³»ï¼Œå…³ç³»çŸ¥è¯†æ˜¯ä»å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æç‚¼å‡ºæ¥çš„ã€‚ä¸ºäº†è¯„ä¼°RelationFieldçš„æ€§èƒ½ï¼Œæˆ‘ä»¬è§£å†³äº†å¼€æ”¾å¼è¯æ±‡çš„3Dåœºæ™¯å›¾ç”Ÿæˆä»»åŠ¡å’Œå…³ç³»å¯¼å‘çš„å®ä¾‹åˆ†å‰²ä»»åŠ¡ï¼Œåœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸­éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ›´å¤šè¯¦æƒ…å¯è§é¡¹ç›®ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://relationfield.github.io./">https://relationfield.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13652v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://relationfield.github.io/">https://relationfield.github.io</a></p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰æ˜¯ä¸€ç§æ–°å…´çš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œæœ€è¿‘è¢«æ‰©å±•ç”¨äºå­¦ä¹ åœºæ™¯ç†è§£çš„ç‰¹å¾ã€‚å½“å‰çš„æ–¹æ³•ä¸»è¦å…³æ³¨å¯¹è±¡ä¸­å¿ƒçš„è¡¨ç¤ºï¼Œæ”¯æŒå¯¹è±¡åˆ†å‰²æˆ–æ£€æµ‹ï¼Œä½†åœ¨ç†è§£å¯¹è±¡ä¹‹é—´çš„è¯­ä¹‰å…³ç³»æ–¹é¢ä»å­˜åœ¨å¾ˆå¤§å·®è·ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºRelationFieldï¼Œè¿™æ˜¯ç¬¬ä¸€ç§ç›´æ¥ä»ç¥ç»ç½‘ç»œè¾å°„åœºä¸­æå–å¯¹è±¡é—´å…³ç³»çš„æ–¹æ³•ã€‚RelationFieldå°†å¯¹è±¡é—´çš„å…³ç³»è¡¨ç¤ºä¸ºç¥ç»è¾å°„åœºå†…çš„æˆå¯¹å°„çº¿ï¼Œæœ‰æ•ˆåœ°å°†å…¶å…¬å¼æ‰©å±•ä¸ºåŒ…å«éšå¼å…³ç³»æŸ¥è¯¢ã€‚ä¸ºäº†æ•™æˆRelationFieldå¤æ‚ã€å¼€æ”¾è¯æ±‡çš„å…³ç³»ï¼Œæˆ‘ä»¬ä»å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­æç‚¼å…³ç³»çŸ¥è¯†ã€‚åœ¨å¼€æ”¾è¯æ±‡3Dåœºæ™¯å›¾ç”Ÿæˆä»»åŠ¡å’Œå…³ç³»å¼•å¯¼å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒRelationFieldå–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·è®¿é—®é¡¹ç›®ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://relationfield.github.io./">https://relationfield.github.ioã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰NeRFä¸»è¦ç”¨äºå¯¹è±¡ä¸­å¿ƒçš„è¡¨ç¤ºï¼Œæ”¯æŒå¯¹è±¡åˆ†å‰²å’Œæ£€æµ‹ã€‚</li>
<li>å¯¹è±¡é—´çš„è¯­ä¹‰å…³ç³»åœ¨NeRFä¸­çš„ç†è§£ä»ç„¶æ˜¯ä¸€ä¸ªæœªè¢«å……åˆ†æ¢ç´¢çš„é¢†åŸŸã€‚</li>
<li>RelationFieldæ˜¯ç¬¬ä¸€ä¸ªç›´æ¥ä»NeRFæå–å¯¹è±¡é—´å…³ç³»çš„æ–¹æ³•ã€‚</li>
<li>RelationFieldé€šè¿‡å°†å¯¹è±¡é—´çš„å…³ç³»è¡¨ç¤ºä¸ºNeRFå†…çš„æˆå¯¹å°„çº¿æ¥æœ‰æ•ˆåœ°å¤„ç†éšå¼å…³ç³»æŸ¥è¯¢ã€‚</li>
<li>RelationFieldä»å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æç‚¼å¤æ‚ã€å¼€æ”¾è¯æ±‡çš„å…³ç³»çŸ¥è¯†ã€‚</li>
<li>åœ¨å¼€æ”¾è¯æ±‡3Dåœºæ™¯å›¾ç”Ÿæˆä»»åŠ¡å’Œå…³ç³»å¼•å¯¼å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒRelationFieldè¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13652">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9c15efc8de0f571320f5595c9e1a3338.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ece9247f79c352994ea0555386769b05.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64613d7b3775581e6b56e0d93a08c7e6.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EOGS-Gaussian-Splatting-for-Earth-Observation"><a href="#EOGS-Gaussian-Splatting-for-Earth-Observation" class="headerlink" title="EOGS: Gaussian Splatting for Earth Observation"></a>EOGS: Gaussian Splatting for Earth Observation</h2><p><strong>Authors:Luca Savant Aira, Gabriele Facciolo, Thibaud Ehret</strong></p>
<p>Recently, Gaussian splatting has emerged as a strong alternative to NeRF, demonstrating impressive 3D modeling capabilities while requiring only a fraction of the training and rendering time. In this paper, we show how the standard Gaussian splatting framework can be adapted for remote sensing, retaining its high efficiency. This enables us to achieve state-of-the-art performance in just a few minutes, compared to the day-long optimization required by the best-performing NeRF-based Earth observation methods. The proposed framework incorporates remote-sensing improvements from EO-NeRF, such as radiometric correction and shadow modeling, while introducing novel components, including sparsity, view consistency, and opacity regularizations. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œé«˜æ–¯æ¶‚æŠ¹ï¼ˆGaussian splattingï¼‰ä½œä¸ºä¸€ç§å¼ºå¤§çš„NeRFæ›¿ä»£æ–¹æ³•å´­éœ²å¤´è§’ï¼Œå±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„3Då»ºæ¨¡èƒ½åŠ›ï¼ŒåŒæ—¶ä»…éœ€ä¸€å°éƒ¨åˆ†è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•é€‚åº”æ ‡å‡†é«˜æ–¯æ¶‚æŠ¹æ¡†æ¶è¿›è¡Œé¥æ„Ÿï¼ŒåŒæ—¶ä¿æŒå…¶é«˜æ•ˆç‡ã€‚è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿåœ¨å‡ åˆ†é’Ÿå†…è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œè€Œæ— éœ€ä½¿ç”¨åŸºäºNeRFçš„åœ°çƒè§‚æµ‹æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³çš„é•¿æ—¶é—´ä¼˜åŒ–æ–¹æ³•ã€‚æ‰€æå‡ºçš„æ¡†æ¶èå…¥äº†é¥æ„Ÿæ”¹è¿›çš„å†…å®¹ï¼Œä¾‹å¦‚EO-NeRFçš„è¾å°„æ ¡æ­£å’Œé˜´å½±å»ºæ¨¡ï¼ŒåŒæ—¶å¼•å…¥äº†æ–°é¢–ç»„ä»¶ï¼ŒåŒ…æ‹¬ç¨€ç–æ€§ã€è§†å›¾ä¸€è‡´æ€§å’Œä¸é€æ˜åº¦æ­£åˆ™åŒ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13047v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‘æœŸï¼Œé«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯æˆä¸ºNeRFçš„æœ‰åŠ›æ›¿ä»£æ–¹æ¡ˆï¼Œå±•ç°äº†å¼ºå¤§çš„3Då»ºæ¨¡èƒ½åŠ›ï¼Œä¸”åªéœ€ä¸€å°éƒ¨åˆ†è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´ã€‚æœ¬æ–‡å±•ç¤ºäº†å¦‚ä½•å°†æ ‡å‡†é«˜æ–¯æ¶‚æŠ¹æ¡†æ¶é€‚åº”äºé¥æ„Ÿé¢†åŸŸï¼ŒåŒæ—¶ä¿æŒå…¶é«˜æ•ˆç‡ã€‚è¿™ä½¿æˆ‘ä»¬åœ¨çŸ­çŸ­å‡ åˆ†é’Ÿå†…å³å¯å®ç°å“è¶Šæ€§èƒ½ï¼Œè€Œæœ€ä½³æ€§èƒ½çš„NeRFåœ°çƒè§‚æµ‹æ–¹æ³•åˆ™éœ€è¦ä¸€æ•´å¤©çš„ä¼˜åŒ–ã€‚æ‰€ææ¡†æ¶èå…¥äº†EO-NeRFçš„é¥æ„Ÿæ”¹è¿›ï¼Œå¦‚è¾å°„æ ¡æ­£å’Œé˜´å½±å»ºæ¨¡ï¼ŒåŒæ—¶å¼•å…¥äº†æ–°é¢–ç»„ä»¶ï¼ŒåŒ…æ‹¬ç¨€ç–æ€§ã€è§†å›¾ä¸€è‡´æ€§å’Œä¸é€æ˜åº¦æ­£åˆ™åŒ–ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯ä½œä¸ºNeRFçš„æ›¿ä»£æ–¹æ¡ˆï¼Œå±•ç°å‡ºå¼ºå¤§çš„3Då»ºæ¨¡èƒ½åŠ›ï¼Œä¸”æ•ˆç‡æ›´é«˜ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶é€‚åº”äºé¥æ„Ÿé¢†åŸŸï¼Œå®ç°äº†é«˜æ•ˆæ€§èƒ½ã€‚</li>
<li>ä¸æœ€ä½³æ€§èƒ½çš„NeRFåœ°çƒè§‚æµ‹æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨å‡ åˆ†é’Ÿå†…å³å¯å®ç°å“è¶Šæ€§èƒ½ï¼Œæ— éœ€é•¿æ—¶é—´çš„ä¼˜åŒ–ã€‚</li>
<li>èåˆäº†EO-NeRFçš„é¥æ„Ÿæ”¹è¿›ï¼Œå¦‚è¾å°„æ ¡æ­£å’Œé˜´å½±å»ºæ¨¡ã€‚</li>
<li>å¼•å…¥äº†æ–°é¢–ç»„ä»¶ï¼ŒåŒ…æ‹¬ç¨€ç–æ€§å¤„ç†ã€è§†å›¾ä¸€è‡´æ€§ä»¥åŠä¸é€æ˜åº¦æ­£åˆ™åŒ–ã€‚</li>
<li>æ‰€ææ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºé¥æ„Ÿé¢†åŸŸçš„ä¸åŒåœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13047">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b5bf2a63195aa0470042e9f469976617.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a4edfd3e37d721a4c8c4f37584cdfe5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-83510c6c0d36d26c11fe3a11c1175e46.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f69b867dd19d99f84033e3b42f143806.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GS-ProCams-Gaussian-Splatting-based-Projector-Camera-Systems"><a href="#GS-ProCams-Gaussian-Splatting-based-Projector-Camera-Systems" class="headerlink" title="GS-ProCams: Gaussian Splatting-based Projector-Camera Systems"></a>GS-ProCams: Gaussian Splatting-based Projector-Camera Systems</h2><p><strong>Authors:Qingyue Deng, Jijiang Li, Haibin Ling, Bingyao Huang</strong></p>
<p>We present GS-ProCams, the first Gaussian Splatting-based framework for projector-camera systems (ProCams). GS-ProCams significantly enhances the efficiency of projection mapping (PM) that requires establishing geometric and radiometric mappings between the projector and the camera. Previous CNN-based ProCams are constrained to a specific viewpoint, limiting their applicability to novel perspectives. In contrast, NeRF-based ProCams support view-agnostic projection mapping, however, they require an additional colocated light source and demand significant computational and memory resources. To address this issue, we propose GS-ProCams that employs 2D Gaussian for scene representations, and enables efficient view-agnostic ProCams applications. In particular, we explicitly model the complex geometric and photometric mappings of ProCams using projector responses, the target surfaceâ€™s geometry and materials represented by Gaussians, and global illumination component. Then, we employ differentiable physically-based rendering to jointly estimate them from captured multi-view projections. Compared to state-of-the-art NeRF-based methods, our GS-ProCams eliminates the need for additional devices, achieving superior ProCams simulation quality. It is also 600 times faster and uses only 1&#x2F;10 of the GPU memory. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†GS-ProCamsï¼Œè¿™æ˜¯åŸºäºé«˜æ–¯æ‹¼è´´æŠ€æœ¯çš„æŠ•å½±ä»ªç›¸æœºç³»ç»Ÿï¼ˆProCamsï¼‰çš„é¦–ä¸ªæ¡†æ¶ã€‚GS-ProCamsæå¤§åœ°æé«˜äº†æŠ•å½±æ˜ å°„ï¼ˆPMï¼‰çš„æ•ˆç‡ï¼Œè¯¥æ˜ å°„éœ€è¦åœ¨æŠ•å½±ä»ªå’Œç›¸æœºä¹‹é—´å»ºç«‹å‡ ä½•å’Œè¾å°„åº¦é‡æ˜ å°„ã€‚ä¹‹å‰çš„åŸºäºCNNçš„ProCamså—é™äºç‰¹å®šçš„è§†è§’ï¼Œé™åˆ¶äº†å…¶åœ¨æ–°å‹è§†è§’çš„åº”ç”¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäºNeRFçš„ProCamsæ”¯æŒè§†è§’æ— å…³çš„æŠ•å½±æ˜ å°„ï¼Œä½†å®ƒä»¬éœ€è¦é¢å¤–çš„å…±ç½®å…‰æºï¼Œå¹¶éœ€è¦å¤§é‡çš„è®¡ç®—å’Œå†…å­˜èµ„æºã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†GS-ProCamsï¼Œå®ƒé‡‡ç”¨äºŒç»´é«˜æ–¯è¿›è¡Œåœºæ™¯è¡¨ç¤ºï¼Œå¹¶å®ç°äº†é«˜æ•ˆçš„è§†è§’æ— å…³ProCamsåº”ç”¨ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡æŠ•å½±ä»ªå“åº”ã€ç”±é«˜æ–¯è¡¨ç¤ºçš„ç›®æ ‡è¡¨é¢çš„å‡ ä½•å½¢çŠ¶å’Œææ–™ä»¥åŠå…¨å±€ç…§æ˜ç»„ä»¶ï¼Œæ˜ç¡®åœ°å»ºæ¨¡äº†ProCamså¤æ‚çš„å‡ ä½•å’Œå…‰åº¦æ˜ å°„ã€‚ç„¶åï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºç‰©ç†çš„ã€å¯å¾®åˆ†çš„æ¸²æŸ“æ–¹æ³•ï¼Œä»æ•è·çš„å¤šè§†è§’æŠ•å½±è”åˆä¼°è®¡å®ƒä»¬ã€‚ä¸æœ€å…ˆè¿›çš„åŸºäºNeRFçš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„GS-ProCamsä¸éœ€è¦é¢å¤–çš„è®¾å¤‡ï¼Œå®ç°äº†å“è¶Šçš„ProCamsæ¨¡æ‹Ÿè´¨é‡ã€‚å…¶é€Ÿåº¦ä¹Ÿæ›´å¿«ï¼ˆé«˜è¾¾600å€ï¼‰ï¼Œå¹¶ä¸”åªä½¿ç”¨ååˆ†ä¹‹ä¸€çš„GPUå†…å­˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11762v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºGS-ProCamsçš„é«˜æ•ˆæŠ•å½±ä»ªç›¸æœºç³»ç»Ÿç ”ç©¶æ‘˜è¦ï¼šè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ··åˆçš„GS-ProCamsæ¡†æ¶ï¼Œç”¨äºæŠ•å½±ä»ªç›¸æœºç³»ç»Ÿï¼ˆProCamsï¼‰ã€‚è¯¥æ–¹æ³•æé«˜äº†æŠ•å½±æ˜ å°„çš„æ•ˆç‡ï¼Œå¹¶è§£å†³äº†CNNåŸºProCamsè§†è§’é™åˆ¶çš„é—®é¢˜ï¼Œæ”¯æŒæ— è§†è§’æŠ•å½±æ˜ å°„ã€‚æ­¤å¤–ï¼Œå®ƒåˆ©ç”¨äºŒç»´é«˜æ–¯è¿›è¡Œåœºæ™¯è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨åŸºäºç‰©ç†çš„æ¸²æŸ“æŠ€æœ¯ä¼°è®¡å‡ ä½•å’Œå…‰åº¦æ˜ å°„ã€‚ç›¸æ¯”ç°æœ‰NeRFåŸºæ–¹æ³•ï¼ŒGS-ProCamsæ— éœ€é¢å¤–è®¾å¤‡å³å¯å®ç°é«˜è´¨é‡æ¨¡æ‹Ÿï¼ŒåŒæ—¶é€Ÿåº¦å¿«600å€ä¸”ä½¿ç”¨GPUå†…å­˜ä»…ååˆ†ä¹‹ä¸€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GS-ProCamsæ˜¯åŸºäºé«˜æ–¯æ··åˆçš„æŠ•å½±ä»ªç›¸æœºç³»ç»Ÿæ¡†æ¶ï¼Œæé«˜äº†æŠ•å½±æ˜ å°„æ•ˆç‡ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†CNNåŸºProCamsçš„è§†è§’é™åˆ¶é—®é¢˜ï¼Œæ”¯æŒæ— è§†è§’æŠ•å½±æ˜ å°„ã€‚</li>
<li>GS-ProCamsä½¿ç”¨äºŒç»´é«˜æ–¯è¿›è¡Œåœºæ™¯è¡¨ç¤ºã€‚</li>
<li>é€šè¿‡åŸºäºç‰©ç†çš„æ¸²æŸ“æŠ€æœ¯ä¼°è®¡å‡ ä½•å’Œå…‰åº¦æ˜ å°„ã€‚</li>
<li>ä¸ç°æœ‰NeRFåŸºæ–¹æ³•ç›¸æ¯”ï¼ŒGS-ProCamså®ç°é«˜è´¨é‡æ¨¡æ‹Ÿï¼Œé€Ÿåº¦å¿«ä¸”ä½¿ç”¨å†…å­˜å°‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11762">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-92ded3759ea49dc651403d3718bd5809.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-006456d917848cc493aebd747e46e79f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d0ca752ad7ad76c678521bfda2a66cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-923a998e40a38fa14091d1aa9a310ddf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b2bac7cdf3f89ddb434a3d2b0c769f0e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Sequence-Matters-Harnessing-Video-Models-in-3D-Super-Resolution"><a href="#Sequence-Matters-Harnessing-Video-Models-in-3D-Super-Resolution" class="headerlink" title="Sequence Matters: Harnessing Video Models in 3D Super-Resolution"></a>Sequence Matters: Harnessing Video Models in 3D Super-Resolution</h2><p><strong>Authors:Hyun-kyu Ko, Dongheok Park, Youngin Park, Byeonghyeon Lee, Juhee Han, Eunbyung Park</strong></p>
<p>3D super-resolution aims to reconstruct high-fidelity 3D models from low-resolution (LR) multi-view images. Early studies primarily focused on single-image super-resolution (SISR) models to upsample LR images into high-resolution images. However, these methods often lack view consistency because they operate independently on each image. Although various post-processing techniques have been extensively explored to mitigate these inconsistencies, they have yet to fully resolve the issues. In this paper, we perform a comprehensive study of 3D super-resolution by leveraging video super-resolution (VSR) models. By utilizing VSR models, we ensure a higher degree of spatial consistency and can reference surrounding spatial information, leading to more accurate and detailed reconstructions. Our findings reveal that VSR models can perform remarkably well even on sequences that lack precise spatial alignment. Given this observation, we propose a simple yet practical approach to align LR images without involving fine-tuning or generating â€˜smoothâ€™ trajectory from the trained 3D models over LR images. The experimental results show that the surprisingly simple algorithms can achieve the state-of-the-art results of 3D super-resolution tasks on standard benchmark datasets, such as the NeRF-synthetic and MipNeRF-360 datasets. Project page: <a target="_blank" rel="noopener" href="https://ko-lani.github.io/Sequence-Matters">https://ko-lani.github.io/Sequence-Matters</a> </p>
<blockquote>
<p>ä¸‰ç»´è¶…åˆ†è¾¨ç‡æ—¨åœ¨ä»ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å¤šè§†è§’å›¾åƒé‡å»ºé«˜ä¿çœŸä¸‰ç»´æ¨¡å‹ã€‚æ—©æœŸç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSISRï¼‰æ¨¡å‹ä¸Šï¼Œå°†LRå›¾åƒä¸Šé‡‡æ ·ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ç¼ºä¹è§†è§’ä¸€è‡´æ€§ï¼Œå› ä¸ºå®ƒä»¬ç‹¬ç«‹åœ°å¤„ç†æ¯å¼ å›¾åƒã€‚å°½ç®¡å·²ç»å¹¿æ³›æ¢ç´¢äº†å„ç§åå¤„ç†æŠ€æœ¯æ¥ç¼“è§£è¿™äº›ä¸ä¸€è‡´æ€§ï¼Œä½†å®ƒä»¬å°šæœªå®Œå…¨è§£å†³è¿™äº›é—®é¢˜ã€‚</p>
</blockquote>
<p>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹è§†é¢‘è¶…åˆ†è¾¨ç‡ï¼ˆVSRï¼‰æ¨¡å‹çš„åˆ©ç”¨ï¼Œå¯¹ä¸‰ç»´è¶…åˆ†è¾¨ç‡è¿›è¡Œäº†å…¨é¢çš„ç ”ç©¶ã€‚é€šè¿‡åˆ©ç”¨VSRæ¨¡å‹ï¼Œæˆ‘ä»¬ç¡®ä¿äº†æ›´é«˜çš„ç©ºé—´ä¸€è‡´æ€§ï¼Œå¹¶ä¸”å¯ä»¥å¼•ç”¨å‘¨å›´çš„ç©ºé—´ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´æ›´ç²¾ç¡®å’Œè¯¦ç»†çš„é‡å»ºã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œå³ä½¿åœ¨ç¼ºä¹ç²¾ç¡®ç©ºé—´å¯¹é½çš„åºåˆ—ä¸Šï¼ŒVSRæ¨¡å‹ä¹Ÿå¯ä»¥è¡¨ç°å¾—éå¸¸å‡ºè‰²ã€‚é‰´äºæ­¤è§‚å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œå®ç”¨çš„æ–¹æ³•æ¥å¯¹é½LRå›¾åƒï¼Œè€Œæ— éœ€æ¶‰åŠç²¾ç»†è°ƒæ•´æˆ–ä»è®­ç»ƒçš„3Dæ¨¡å‹åœ¨LRå›¾åƒä¸Šç”Ÿæˆâ€œå¹³æ»‘â€è½¨è¿¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›å‡ºäººæ„æ–™çš„ç®€å•ç®—æ³•å¯ä»¥åœ¨æ ‡å‡†åŸºå‡†æ•°æ®é›†ä¸Šå®ç°æœ€å…ˆè¿›çš„ä¸‰ç»´è¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„ç»“æœï¼Œå¦‚NeRF-syntheticå’ŒMipNeRF-360æ•°æ®é›†ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://ko-lani.github.io/Sequence-Matters">https://ko-lani.github.io/Sequence-Matters</a></p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11525v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://ko-lani.github.io/Sequence-Matters">https://ko-lani.github.io/Sequence-Matters</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å¦‚ä½•åˆ©ç”¨è§†é¢‘è¶…åˆ†è¾¨ç‡ï¼ˆVSRï¼‰æ¨¡å‹è¿›è¡Œ3Dè¶…åˆ†è¾¨ç‡é‡å»ºã€‚é€šè¿‡å¯¹VSRæ¨¡å‹çš„åˆ©ç”¨ï¼Œç¡®ä¿äº†è¾ƒé«˜çš„ç©ºé—´ä¸€è‡´æ€§ï¼Œå¹¶èƒ½å‚è€ƒå‘¨å›´çš„ç©ºé—´ä¿¡æ¯ï¼Œä»è€Œå¾—åˆ°æ›´å‡†ç¡®ã€æ›´è¯¦ç»†çš„é‡å»ºç»“æœã€‚å®éªŒè¡¨æ˜ï¼Œå³ä½¿åœ¨ç¼ºä¹ç²¾ç¡®ç©ºé—´å¯¹é½çš„åºåˆ—ä¸Šï¼ŒVSRæ¨¡å‹ä¹Ÿèƒ½è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•å®ç”¨çš„æ–¹æ³•ï¼Œæ— éœ€å¾®è°ƒæˆ–ç”Ÿæˆå¹³æ»‘è½¨è¿¹ï¼Œå³å¯å¯¹ä½åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œå¯¹é½ã€‚åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šï¼Œè¯¥ç®—æ³•å®ç°äº†ä»¤äººæƒŠè®¶çš„3Dè¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„æœ€ä½³ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶åˆ©ç”¨è§†é¢‘è¶…åˆ†è¾¨ç‡ï¼ˆVSRï¼‰æ¨¡å‹è¿›è¡Œ3Dè¶…åˆ†è¾¨ç‡é‡å»ºï¼Œç¡®ä¿ç©ºé—´ä¸€è‡´æ€§å’Œè¯¦ç»†æ€§ã€‚</li>
<li>VSRæ¨¡å‹èƒ½å‚è€ƒå‘¨å›´çš„ç©ºé—´ä¿¡æ¯ï¼Œä»è€Œå¾—åˆ°æ›´å‡†ç¡®ã€æ›´è¯¦ç»†çš„é‡å»ºç»“æœã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒVSRæ¨¡å‹åœ¨ç¼ºä¹ç²¾ç¡®ç©ºé—´å¯¹é½çš„åºåˆ—ä¸Šä¹Ÿèƒ½è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>æå‡ºä¸€ç§ç®€å•å®ç”¨çš„æ–¹æ³•ï¼Œæ— éœ€å¾®è°ƒæˆ–ç”Ÿæˆå¹³æ»‘è½¨è¿¹ï¼Œå³å¯å¯¹ä½åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œå¯¹é½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šå®ç°äº†3Dè¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„æœ€ä½³ç»“æœã€‚</li>
<li>æœ¬ç ”ç©¶ä¸ä»…å¯¹3Dè¶…åˆ†è¾¨ç‡æŠ€æœ¯åšå‡ºäº†é‡è¦è´¡çŒ®ï¼Œè€Œä¸”æ¨åŠ¨äº†è§†é¢‘è¶…åˆ†è¾¨ç‡æ¨¡å‹çš„è¿›ä¸€æ­¥åº”ç”¨å’Œå‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11525">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ac79f7c413bf349955549303ec87dfdf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9775abb384746b27a4fc2a194c545d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-989d39f7b9ea8cecdbb712b167039878.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a8ddc004ad248304640951934bbc58f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c25d41832f4dd818b862c5db63c445e7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3381673e405e5b6c7f8b507bcacd8eaf.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Adapting-Segment-Anything-Model-SAM-to-Experimental-Datasets-via-Fine-Tuning-on-GAN-based-Simulation-A-Case-Study-in-Additive-Manufacturing"><a href="#Adapting-Segment-Anything-Model-SAM-to-Experimental-Datasets-via-Fine-Tuning-on-GAN-based-Simulation-A-Case-Study-in-Additive-Manufacturing" class="headerlink" title="Adapting Segment Anything Model (SAM) to Experimental Datasets via   Fine-Tuning on GAN-based Simulation: A Case Study in Additive Manufacturing"></a>Adapting Segment Anything Model (SAM) to Experimental Datasets via   Fine-Tuning on GAN-based Simulation: A Case Study in Additive Manufacturing</h2><p><strong>Authors:Anika Tabassum, Amirkoushyar Ziabari</strong></p>
<p>Industrial X-ray computed tomography (XCT) is a powerful tool for non-destructive characterization of materials and manufactured components. XCT commonly accompanied by advanced image analysis and computer vision algorithms to extract relevant information from the images. Traditional computer vision models often struggle due to noise, resolution variability, and complex internal structures, particularly in scientific imaging applications. State-of-the-art foundational models, like the Segment Anything Model (SAM)-designed for general-purpose image segmentation-have revolutionized image segmentation across various domains, yet their application in specialized fields like materials science remains under-explored. In this work, we explore the application and limitations of SAM for industrial X-ray CT inspection of additive manufacturing components. We demonstrate that while SAM shows promise, it struggles with out-of-distribution data, multiclass segmentation, and computational efficiency during fine-tuning. To address these issues, we propose a fine-tuning strategy utilizing parameter-efficient techniques, specifically Conv-LoRa, to adapt SAM for material-specific datasets. Additionally, we leverage generative adversarial network (GAN)-generated data to enhance the training process and improve the modelâ€™s segmentation performance on complex X-ray CT data. Our experimental results highlight the importance of tailored segmentation models for accurate inspection, showing that fine-tuning SAM on domain-specific scientific imaging data significantly improves performance. However, despite improvements, the modelâ€™s ability to generalize across diverse datasets remains limited, highlighting the need for further research into robust, scalable solutions for domain-specific segmentation tasks. </p>
<blockquote>
<p>å·¥ä¸šXå°„çº¿è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆXCTï¼‰æ˜¯éç ´åæ€§è¡¨å¾ææ–™å’Œåˆ¶é€ éƒ¨ä»¶çš„å¼ºå¤§å·¥å…·ã€‚XCTé€šå¸¸ä¸å…ˆè¿›çš„å›¾åƒåˆ†æå’Œè®¡ç®—æœºè§†è§‰ç®—æ³•ç›¸ç»“åˆï¼Œä»å›¾åƒä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚ç”±äºå™ªå£°ã€åˆ†è¾¨ç‡å˜åŒ–å’Œå¤æ‚å†…éƒ¨ç»“æ„çš„å½±å“ï¼Œä¼ ç»Ÿè®¡ç®—æœºè§†è§‰æ¨¡å‹åœ¨ç§‘å­¦æˆåƒåº”ç”¨ä¸­ç»å¸¸é¢ä¸´æŒ‘æˆ˜ã€‚æœ€å…ˆè¿›çš„åŸºç¡€æ¨¡å‹ï¼Œå¦‚ç”¨äºé€šç”¨å›¾åƒåˆ†å‰²çš„Segment Anything Modelï¼ˆSAMï¼‰ï¼Œå·²ç»æ¨åŠ¨äº†å„ä¸ªé¢†åŸŸå›¾åƒåˆ†å‰²çš„é©å‘½ï¼Œä½†å®ƒä»¬åœ¨ææ–™ç§‘å­¦ç­‰ç‰¹å®šé¢†åŸŸçš„åº”ç”¨ä»ç„¶è¢«æ¢ç´¢ä¸è¶³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†SAMåœ¨å¢æåˆ¶é€ éƒ¨ä»¶çš„å·¥ä¸šXå°„çº¿CTæ£€æµ‹ä¸­çš„åº”ç”¨å’Œå±€é™æ€§ã€‚æˆ‘ä»¬è¯æ˜ï¼Œè™½ç„¶SAMæ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå®ƒåœ¨å¤„ç†ç¦»ç¾¤æ•°æ®ã€å¤šç±»åˆ†å‰²å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å‚æ•°é«˜æ•ˆæŠ€æœ¯çš„å¾®è°ƒç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯Conv-LoRaï¼Œæ¥é€‚åº”ææ–™ç‰¹å®šçš„æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”Ÿæˆçš„æ•°æ®æ¥å¢å¼ºè®­ç»ƒè¿‡ç¨‹ï¼Œæé«˜æ¨¡å‹åœ¨å¤æ‚Xå°„çº¿CTæ•°æ®ä¸Šçš„åˆ†å‰²æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœå¼ºè°ƒäº†å®šåˆ¶åˆ†å‰²æ¨¡å‹å¯¹äºå‡†ç¡®æ£€æµ‹çš„é‡è¦æ€§ï¼Œå¹¶è¡¨æ˜åœ¨ç‰¹å®šé¢†åŸŸçš„ç§‘å­¦æˆåƒæ•°æ®ä¸Šå¾®è°ƒSAMå¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ã€‚ç„¶è€Œï¼Œå°½ç®¡æœ‰æ‰€æ”¹è¿›ï¼Œæ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä»ç„¶æœ‰é™ï¼Œè¿™å‡¸æ˜¾äº†å¯¹é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„åˆ†å‰²ä»»åŠ¡çš„ç¨³å¥ã€å¯æ‰©å±•è§£å†³æ–¹æ¡ˆçš„è¿›ä¸€æ­¥ç ”ç©¶çš„å¿…è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11381v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æ¢è®¨äº†å°†å…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹ï¼Œå¦‚Segment Anything Modelï¼ˆSAMï¼‰ï¼Œåº”ç”¨äºå·¥ä¸šXå°„çº¿è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆXCTï¼‰æŠ€æœ¯ï¼Œç”¨äºåˆ†æåˆ¶é€ éƒ¨ä»¶çš„ææ–™ç‰¹æ€§ã€‚ç ”ç©¶å±•ç¤ºäº†SAMåœ¨åº”å¯¹å¤æ‚å†…éƒ¨ç»“æ„ã€å™ªå£°å’Œåˆ†è¾¨ç‡å˜åŒ–æ—¶çš„æ½œåŠ›ä¸å±€é™æ€§ï¼Œå¹¶æå‡ºäº†é€šè¿‡åˆ©ç”¨Conv-LoRaç­‰å‚æ•°é«˜æ•ˆæŠ€æœ¯è¿›è¡Œå¾®è°ƒï¼Œä»¥åŠä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”Ÿæˆæ•°æ®ä»¥å¢å¼ºè®­ç»ƒè¿‡ç¨‹çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ç§‘å­¦æˆåƒæ•°æ®å¾®è°ƒSAMå¯æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œä½†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»æœ‰å¾…æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Segment Anything Model (SAM) åœ¨å·¥ä¸šXå°„çº¿CTæ£€æµ‹ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œå°¤å…¶åœ¨åˆ†æåˆ¶é€ éƒ¨ä»¶çš„ææ–™ç‰¹æ€§æ–¹é¢ã€‚</li>
<li>SAMåœ¨é¢å¯¹å™ªå£°ã€åˆ†è¾¨ç‡å˜åŒ–å’Œå¤æ‚å†…éƒ¨ç»“æ„æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨å‚æ•°é«˜æ•ˆæŠ€æœ¯ï¼ˆå¦‚Conv-LoRaï¼‰è¿›è¡Œå¾®è°ƒï¼Œå¯é€‚åº”ææ–™ç‰¹å®šæ•°æ®é›†ã€‚</li>
<li>åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”Ÿæˆæ•°æ®å¯ä»¥å¢å¼ºè®­ç»ƒè¿‡ç¨‹ï¼Œæé«˜æ¨¡å‹åœ¨å¤æ‚Xå°„çº¿CTæ•°æ®ä¸Šçš„åˆ†å‰²æ€§èƒ½ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ç§‘å­¦æˆåƒæ•°æ®å¾®è°ƒSAMèƒ½æ˜¾è‘—æé«˜æ€§èƒ½ã€‚</li>
<li>å°½ç®¡æœ‰æ‰€æ”¹è¿›ï¼Œä½†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»ç„¶æœ‰é™ï¼Œéœ€è¦åœ¨ä¸åŒæ•°æ®é›†ä¸Šè¿›è¡Œæ›´å¤šç ”ç©¶ä»¥å¯»æ‰¾æ›´ç¨³å¥ã€å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11381">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-68869de46c0cdb7e886a40641ab951d0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-732024ecc4fba477e7740c4dac3ffab1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0dbbc6e53d60f16b7772eeb25fe38a3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32c059254fe838a182067649ce3ecdf8.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ViPOcc-Leveraging-Visual-Priors-from-Vision-Foundation-Models-for-Single-View-3D-Occupancy-Prediction"><a href="#ViPOcc-Leveraging-Visual-Priors-from-Vision-Foundation-Models-for-Single-View-3D-Occupancy-Prediction" class="headerlink" title="ViPOcc: Leveraging Visual Priors from Vision Foundation Models for   Single-View 3D Occupancy Prediction"></a>ViPOcc: Leveraging Visual Priors from Vision Foundation Models for   Single-View 3D Occupancy Prediction</h2><p><strong>Authors:Yi Feng, Yu Han, Xijing Zhang, Tanghui Li, Yanting Zhang, Rui Fan</strong></p>
<p>Inferring the 3D structure of a scene from a single image is an ill-posed and challenging problem in the field of vision-centric autonomous driving. Existing methods usually employ neural radiance fields to produce voxelized 3D occupancy, lacking instance-level semantic reasoning and temporal photometric consistency. In this paper, we propose ViPOcc, which leverages the visual priors from vision foundation models (VFMs) for fine-grained 3D occupancy prediction. Unlike previous works that solely employ volume rendering for RGB and depth image reconstruction, we introduce a metric depth estimation branch, in which an inverse depth alignment module is proposed to bridge the domain gap in depth distribution between VFM predictions and the ground truth. The recovered metric depth is then utilized in temporal photometric alignment and spatial geometric alignment to ensure accurate and consistent 3D occupancy prediction. Additionally, we also propose a semantic-guided non-overlapping Gaussian mixture sampler for efficient, instance-aware ray sampling, which addresses the redundant and imbalanced sampling issue that still exists in previous state-of-the-art methods. Extensive experiments demonstrate the superior performance of ViPOcc in both 3D occupancy prediction and depth estimation tasks on the KITTI-360 and KITTI Raw datasets. Our code is available at: \url{<a target="_blank" rel="noopener" href="https://mias.group/ViPOcc%7D">https://mias.group/ViPOcc}</a>. </p>
<blockquote>
<p>ä»å•å¹…å›¾åƒæ¨æ–­åœºæ™¯çš„ä¸‰ç»´ç»“æ„æ˜¯è§†è§‰è‡ªä¸»é©¾é©¶é¢†åŸŸä¸­ä¸€ä¸ªè®¾ç½®ä¸å½“ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯¾é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ç¥ç»è¾å°„åœºæ¥ç”Ÿæˆä½“ç´ åŒ–çš„ä¸‰ç»´å ç”¨ä¿¡æ¯ï¼Œä½†ç¼ºä¹å®ä¾‹çº§åˆ«çš„è¯­ä¹‰æ¨ç†å’Œæ—¶é—´ä¸Šçš„å…‰åº¦ä¸€è‡´æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ViPOccï¼Œå®ƒåˆ©ç”¨è§†è§‰å…ˆéªŒçŸ¥è¯†ä»è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰è¿›è¡Œç²¾ç»†ç²’åº¦çš„ä¸‰ç»´å ç”¨é¢„æµ‹ã€‚ä¸ä»…ä½¿ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡ŒRGBå’Œæ·±åº¦å›¾åƒé‡å»ºçš„å…ˆå‰å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬å¼•å…¥äº†åº¦é‡æ·±åº¦ä¼°è®¡åˆ†æ”¯ï¼Œå…¶ä¸­æå‡ºäº†é€†æ·±åº¦å¯¹é½æ¨¡å—æ¥å¼¥åˆè§†è§‰åŸºç¡€æ¨¡å‹é¢„æµ‹å’ŒçœŸå®å€¼ä¹‹é—´æ·±åº¦åˆ†å¸ƒçš„åŸŸå·®è·ã€‚ç„¶ååˆ©ç”¨æ¢å¤çš„åº¦é‡æ·±åº¦è¿›è¡Œæ—¶é—´å…‰åº¦å¯¹é½å’Œç©ºé—´å‡ ä½•å¯¹é½ï¼Œä»¥ç¡®ä¿å‡†ç¡®ä¸”ä¸€è‡´çš„ä¸‰ç»´å ç”¨é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§è¯­ä¹‰å¼•å¯¼çš„éé‡å é«˜æ–¯æ··åˆé‡‡æ ·å™¨ï¼Œç”¨äºé«˜æ•ˆã€å®ä¾‹æ„ŸçŸ¥çš„å°„çº¿é‡‡æ ·ï¼Œè§£å†³äº†å…ˆå‰æœ€å…ˆè¿›çš„æ–¹æ³•ä¸­ä»ç„¶å­˜åœ¨çš„ä¸å¿…è¦çš„å’Œä¸å¹³è¡¡çš„é‡‡æ ·é—®é¢˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒViPOccåœ¨KITTI-360å’ŒKITTI Rawæ•°æ®é›†ä¸Šçš„ä¸‰ç»´å ç”¨é¢„æµ‹å’Œæ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://mias.group/ViPOcc%E3%80%82">https://mias.group/ViPOccã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11210v1">PDF</a> accepted to AAAI25</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè§†è§‰å…ˆéªŒçš„ç²¾ç»†ç²’åº¦ä¸‰ç»´å ç”¨é¢„æµ‹æ–¹æ³•ViPOccï¼Œåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰è¿›è¡Œå•å›¾åƒä¸‰ç»´åœºæ™¯æ¨æ–­ã€‚æ–¹æ³•åŒ…æ‹¬å¼•å…¥åº¦é‡æ·±åº¦ä¼°è®¡åˆ†æ”¯å’Œé€†æ·±åº¦å¯¹é½æ¨¡å—ï¼Œä»¥ç¼©å°VFMé¢„æµ‹ä¸çœŸå®å€¼ä¹‹é—´çš„æ·±åº¦åˆ†å¸ƒåŸŸå·®è·ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†è¯­ä¹‰å¼•å¯¼çš„éé‡å é«˜æ–¯æ··åˆé‡‡æ ·å™¨ï¼Œè§£å†³ä¹‹å‰çš„å†—ä½™å’Œä¸å¹³è¡¡é‡‡æ ·é—®é¢˜ã€‚åœ¨KITTI-360å’ŒKITTI Rawæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒViPOccåœ¨ä¸‰ç»´å ç”¨é¢„æµ‹å’Œæ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ViPOccåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰è¿›è¡Œç²¾ç»†ç²’åº¦çš„ä¸‰ç»´å ç”¨é¢„æµ‹ã€‚</li>
<li>å¼•å…¥åº¦é‡æ·±åº¦ä¼°è®¡åˆ†æ”¯å’Œé€†æ·±åº¦å¯¹é½æ¨¡å—ä»¥æ”¹å–„æ·±åº¦é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯­ä¹‰å¼•å¯¼çš„éé‡å é«˜æ–¯æ··åˆé‡‡æ ·å™¨è§£å†³äº†ä¹‹å‰çš„å†—ä½™å’Œä¸å¹³è¡¡é‡‡æ ·é—®é¢˜ã€‚</li>
<li>ViPOccåœ¨KITTI-360å’ŒKITTI Rawæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†è§†è§‰å…ˆéªŒã€æ·±åº¦ä¼°è®¡å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œæé«˜äº†ä¸‰ç»´å ç”¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>ViPOccä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11210">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-de4aee2a4e58c254a0d507ee8e2d190b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2cb1161d5887d3e30e2b4b7e296f11c2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a05f7cf90808059f4cb7561eb4baab6e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c44885d55730f0c014ad8c9d9a78af7.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Ï-NeRF-Leveraging-Attenuation-Priors-in-Neural-Radiance-Field-for-3D-Computed-Tomography-Reconstruction"><a href="#Ï-NeRF-Leveraging-Attenuation-Priors-in-Neural-Radiance-Field-for-3D-Computed-Tomography-Reconstruction" class="headerlink" title="$Ï$-NeRF: Leveraging Attenuation Priors in Neural Radiance Field for   3D Computed Tomography Reconstruction"></a>$Ï$-NeRF: Leveraging Attenuation Priors in Neural Radiance Field for   3D Computed Tomography Reconstruction</h2><p><strong>Authors:Li Zhou, Changsheng Fang, Bahareh Morovati, Yongtong Liu, Shuo Han, Yongshun Xu, Hengyong Yu</strong></p>
<p>This paper introduces $\rho$-NeRF, a self-supervised approach that sets a new standard in novel view synthesis (NVS) and computed tomography (CT) reconstruction by modeling a continuous volumetric radiance field enriched with physics-based attenuation priors. The $\rho$-NeRF represents a three-dimensional (3D) volume through a fully-connected neural network that takes a single continuous four-dimensional (4D) coordinate, spatial location $(x, y, z)$ and an initialized attenuation value ($\rho$), and outputs the attenuation coefficient at that position. By querying these 4D coordinates along X-ray paths, the classic forward projection technique is applied to integrate attenuation data across the 3D space. By matching and refining pre-initialized attenuation values derived from traditional reconstruction algorithms like Feldkamp-Davis-Kress algorithm (FDK) or conjugate gradient least squares (CGLS), the enriched schema delivers superior fidelity in both projection synthesis and image recognition. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†$\rho$-NeRFï¼Œè¿™æ˜¯ä¸€ç§è‡ªç›‘ç£æ–¹æ³•ï¼Œé€šè¿‡å»ºç«‹ä¸€ä¸ªåŸºäºç‰©ç†è¡°å‡å…ˆéªŒçš„è¿ç»­ä½“ç§¯è¾å°„åœºï¼Œä¸ºæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰å’Œè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰é‡å»ºè®¾å®šäº†æ–°çš„æ ‡å‡†ã€‚$\rho$-NeRFé€šè¿‡å…¨è¿æ¥ç¥ç»ç½‘ç»œä»£è¡¨ä¸€ä¸ªä¸‰ç»´ï¼ˆ3Dï¼‰ä½“ç§¯ï¼Œè¯¥ç½‘ç»œæ¥æ”¶ä¸€ä¸ªè¿ç»­çš„å››ç»´ï¼ˆ4Dï¼‰åæ ‡ï¼ˆç©ºé—´ä½ç½®$(x, y, z)$å’Œåˆå§‹åŒ–çš„è¡°å‡å€¼$\rho$ï¼‰ï¼Œå¹¶è¾“å‡ºè¯¥ä½ç½®çš„è¡°å‡ç³»æ•°ã€‚é€šè¿‡æ²¿ç€Xå°„çº¿è·¯å¾„æŸ¥è¯¢è¿™äº›å››ç»´åæ ‡ï¼Œé‡‡ç”¨ç»å…¸çš„å‰å‘æŠ•å½±æŠ€æœ¯å°†è¡°å‡æ•°æ®é›†æˆåˆ°ä¸‰ç»´ç©ºé—´ä¸­ã€‚é€šè¿‡åŒ¹é…å’Œç»†åŒ–æºè‡ªä¼ ç»Ÿé‡å»ºç®—æ³•çš„é¢„åˆå§‹åŒ–è¡°å‡å€¼ï¼ˆå¦‚Feldkamp-Davis-Kressç®—æ³•ï¼ˆFDKï¼‰æˆ–å…±è½­æ¢¯åº¦æœ€å°äºŒä¹˜æ³•ï¼ˆCGLSï¼‰ï¼‰ï¼Œä¸°å¯Œäº†æ¨¡å¼åœ¨æŠ•å½±åˆæˆå’Œå›¾åƒè¯†åˆ«æ–¹é¢å‡å®ç°äº†è¾ƒé«˜çš„ä¿çœŸåº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05322v1">PDF</a> The paper was submitted to CVPR 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Ï-NeRFï¼Œè¿™æ˜¯ä¸€ç§è‡ªç›‘ç£æ–¹æ³•ï¼Œé€šè¿‡å»ºç«‹ä¸€ä¸ªåŒ…å«ç‰©ç†è¡°å‡å…ˆéªŒçš„è¿ç»­ä½“ç§¯è¾å°„åœºï¼Œä¸ºæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰å’Œè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰é‡å»ºè®¾å®šäº†æ–°çš„æ ‡å‡†ã€‚Ï-NeRFé€šè¿‡å…¨è¿æ¥ç¥ç»ç½‘ç»œä»£è¡¨ä¸€ä¸ªä¸‰ç»´ä½“ç§¯ï¼Œè¯¥ç½‘ç»œæ¥å—ä¸€ä¸ªè¿ç»­çš„å››ç»´åæ ‡ï¼ˆåŒ…æ‹¬ç©ºé—´ä½ç½®ï¼ˆxï¼Œyï¼Œzï¼‰å’Œä¸€ä¸ªåˆå§‹åŒ–çš„è¡°å‡å€¼Ïï¼‰ï¼Œå¹¶è¾“å‡ºè¯¥ä½ç½®çš„è¡°å‡ç³»æ•°ã€‚é€šè¿‡æ²¿ç€Xå°„çº¿è·¯å¾„æŸ¥è¯¢è¿™äº›å››ç»´åæ ‡ï¼Œé‡‡ç”¨ç»å…¸çš„å‰å‘æŠ•å½±æŠ€æœ¯æ¥æ•´åˆä¸‰ç»´ç©ºé—´ä¸­çš„è¡°å‡æ•°æ®ã€‚é€šè¿‡åŒ¹é…å’Œç»†åŒ–ä»ä¼ ç»Ÿçš„é‡å»ºç®—æ³•ï¼ˆå¦‚Feldkamp-Davis-Kressç®—æ³•ï¼ˆFDKï¼‰æˆ–å…±è½­æ¢¯åº¦æœ€å°äºŒä¹˜æ³•ï¼ˆCGLSï¼‰ï¼‰å¾—å‡ºçš„é¢„åˆå§‹åŒ–è¡°å‡å€¼ï¼Œä¸°å¯Œçš„æ¨¡å¼åœ¨æŠ•å½±åˆæˆå’Œå›¾åƒè¯†åˆ«æ–¹é¢éƒ½æä¾›äº†æ›´é«˜çš„ä¿çœŸåº¦ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>$\rho$-NeRFæ˜¯ä¸€ç§è‡ªç›‘ç£æ–¹æ³•ï¼Œç”¨äºæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰å’Œè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰é‡å»ºã€‚</li>
<li>é€šè¿‡å»ºç«‹ä¸€ä¸ªåŒ…å«ç‰©ç†è¡°å‡å…ˆéªŒçš„è¿ç»­ä½“ç§¯è¾å°„åœºï¼Œæå‡äº†è´¨é‡ã€‚</li>
<li>ä½¿ç”¨å…¨è¿æ¥ç¥ç»ç½‘ç»œä»£è¡¨ä¸‰ç»´ä½“ç§¯ï¼Œç½‘ç»œè¾“å…¥å››ç»´åæ ‡å’Œåˆå§‹åŒ–è¡°å‡å€¼æ¥è¾“å‡ºè¡°å‡ç³»æ•°ã€‚</li>
<li>é‡‡ç”¨ç»å…¸çš„å‰å‘æŠ•å½±æŠ€æœ¯æ•´åˆå››ç»´åæ ‡ä¸Šçš„è¡°å‡æ•°æ®ã€‚</li>
<li>Ï-NeRFåŒ¹é…å¹¶æ”¹è¿›äº†ä»ä¼ ç»Ÿçš„é‡å»ºç®—æ³•è·å¾—çš„é¢„åˆå§‹åŒ–è¡°å‡å€¼ã€‚</li>
<li>åœ¨æŠ•å½±åˆæˆå’Œå›¾åƒè¯†åˆ«æ–¹é¢éƒ½è¡¨ç°å‡ºäº†æ›´é«˜çš„ä¿çœŸåº¦ã€‚</li>
<li>è¿™ç§æ–¹æ³•æœ‰åŠ©äºæå‡CTå›¾åƒçš„è´¨é‡å¹¶æ”¹å–„è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.05322">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-193210774fb16d3eb566a044a48b1eb9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5a73b8a079d02f7632466aad8ee8e7b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f40dce0bb462d9b67f643036fa553ee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e4aa25809e4f53fb92f5bc5eaf842c0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ad8932e732403010809ca6ec5fff6e3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ecc4723fe301a0cb434e9a9493486185.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7b66a9bd8669da64607891cbd7da39b.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Expansive-Supervision-for-Neural-Radiance-Field"><a href="#Expansive-Supervision-for-Neural-Radiance-Field" class="headerlink" title="Expansive Supervision for Neural Radiance Field"></a>Expansive Supervision for Neural Radiance Field</h2><p><strong>Authors:Weixiang Zhang, Shuzhao Xie, Shijia Ge, Wei Yao, Chen Tang, Zhi Wang</strong></p>
<p>Neural Radiance Field (NeRF) has achieved remarkable success in creating immersive media representations through its exceptional reconstruction capabilities. However, the computational demands of dense forward passes and volume rendering during training continue to challenge its real-world applications. In this paper, we introduce Expansive Supervision to reduce time and memory costs during NeRF training from the perspective of partial ray selection for supervision. Specifically, we observe that training errors exhibit a long-tail distribution correlated with image content. Based on this observation, our method selectively renders a small but crucial subset of pixels and expands their values to estimate errors across the entire area for each iteration. Compared to conventional supervision, our approach effectively bypasses redundant rendering processes, resulting in substantial reductions in both time and memory consumption. Experimental results demonstrate that integrating Expansive Supervision within existing state-of-the-art acceleration frameworks achieves 52% memory savings and 16% time savings while maintaining comparable visual quality. </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å‡­å€Ÿå…¶å‡ºè‰²çš„é‡å»ºèƒ½åŠ›ï¼Œåœ¨åˆ›å»ºæ²‰æµ¸å¼åª’ä½“è¡¨ç¤ºæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­çš„å¯†é›†å‰å‘ä¼ é€’å’Œä½“ç§¯æ¸²æŸ“çš„è®¡ç®—éœ€æ±‚ä»ç„¶å¯¹å…¶å®é™…åº”ç”¨æå‡ºäº†æŒ‘æˆ˜ã€‚æœ¬æ–‡å¼•å…¥æ‰©å¼ ç›‘ç£ï¼ˆExpansive Supervisionï¼‰ä»éƒ¨åˆ†å°„çº¿é€‰æ‹©ç›‘ç£çš„è§’åº¦å‡å°‘NeRFè®­ç»ƒçš„æ—¶é—´å’Œå†…å­˜æˆæœ¬ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è®­ç»ƒé”™è¯¯ä¸å›¾åƒå†…å®¹å‘ˆé•¿å°¾åˆ†å¸ƒç›¸å…³ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€‰æ‹©æ¸²æŸ“ä¸€å°éƒ¨åˆ†ä½†è‡³å…³é‡è¦çš„åƒç´ ï¼Œå¹¶æ‰©å¤§å®ƒä»¬çš„å€¼æ¥ä¼°è®¡æ¯æ¬¡è¿­ä»£çš„æ•´ä¸ªåŒºåŸŸçš„è¯¯å·®ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°ç»•è¿‡äº†å†—ä½™çš„æ¸²æŸ“è¿‡ç¨‹ï¼Œå¯¼è‡´æ—¶é—´å’Œå†…å­˜æ¶ˆè€—å¤§å¹…å‡å°‘ã€‚å®éªŒç»“æœè¯æ˜ï¼Œå°†æ‰©å¼ ç›‘ç£é›†æˆåˆ°æœ€å…ˆè¿›çš„åŠ é€Ÿæ¡†æ¶ä¸­ï¼Œå¯ä»¥å®ç°52%çš„å†…å­˜èŠ‚çœå’Œ16%çš„æ—¶é—´èŠ‚çœï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„å¯è§†è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08056v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰åœ¨åˆ›å»ºæ²‰æµ¸å¼åª’ä½“è¡¨ç¤ºæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†å…¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¯†é›†æ­£å‘ä¼ é€’å’Œä½“ç§¯æ¸²æŸ“çš„è®¡ç®—éœ€æ±‚ä»ç„¶æŒ‘æˆ˜å…¶å®é™…åº”ç”¨ã€‚æœ¬æ–‡å¼•å…¥æ‰©å±•ç›‘ç£ï¼ˆExpansive Supervisionï¼‰æ–¹æ³•ï¼Œä»éƒ¨åˆ†å°„çº¿é€‰æ‹©çš„ç›‘ç£è§’åº¦å‡å°‘NeRFè®­ç»ƒçš„æ—¶é—´å’Œå†…å­˜æˆæœ¬ã€‚é€šè¿‡é€‰æ‹©æ€§æ¸²æŸ“ä¸€å°éƒ¨åˆ†å…³é”®åƒç´ å¹¶æ‰©å±•å…¶å€¼æ¥ä¼°ç®—æ¯ä¸ªè¿­ä»£ä¸­çš„æ•´ä½“è¯¯å·®ï¼Œå®ç°æ—¶é—´å’Œå†…å­˜çš„æ˜¾è‘—å‡å°‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç°æœ‰æœ€å…ˆè¿›çš„åŠ é€Ÿæ¡†æ¶å†…æ•´åˆæ‰©å±•ç›‘ç£æ–¹æ³•å¯å®ç°52%çš„å†…å­˜èŠ‚çœå’Œ16%çš„æ—¶é—´èŠ‚çœï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„å¯è§†è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRFåœ¨åˆ›å»ºæ²‰æµ¸å¼åª’ä½“è¡¨ç¤ºæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„é‡æ„èƒ½åŠ›ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¯†é›†æ­£å‘ä¼ é€’å’Œä½“ç§¯æ¸²æŸ“æ˜¯NeRFé¢ä¸´çš„å®é™…åº”ç”¨æŒ‘æˆ˜ã€‚</li>
<li>æ‰©å±•ç›‘ç£æ–¹æ³•é€šè¿‡éƒ¨åˆ†å°„çº¿é€‰æ‹©çš„ç›‘ç£æ¥å‡å°‘NeRFè®­ç»ƒçš„æ—¶é—´å’Œå†…å­˜æˆæœ¬ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡é€‰æ‹©æ€§æ¸²æŸ“ä¸€å°éƒ¨åˆ†å…³é”®åƒç´ å¹¶æ‰©å±•å…¶å€¼æ¥ä¼°ç®—æ•´ä½“è¯¯å·®ã€‚</li>
<li>æ‰©å±•ç›‘ç£æ–¹æ³•å®ç°äº†æ—¶é—´å’Œå†…å­˜çš„æ˜¾è‘—å‡å°‘ã€‚</li>
<li>ä¸ç°æœ‰æœ€å…ˆè¿›çš„åŠ é€Ÿæ¡†æ¶ç»“åˆï¼Œæ‰©å±•ç›‘ç£æ–¹æ³•å¯åœ¨ä¿æŒç›¸å½“å¯è§†è´¨é‡çš„åŒæ—¶å®ç°52%çš„å†…å­˜èŠ‚çœå’Œ16%çš„æ—¶é—´èŠ‚çœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08056">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f133ea54cf7c355b489a1e7043fd1f7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ef233e15dfe2d0a4b90dd9c015c100c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f48b889f694388b756223771c0d053df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f883494cf5fbfe669b95807b1a2d24a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c010e5dcbef0a55ca3823bf015c3a00d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e835b3940c9d1278585ab7d2509e6b2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a1976482a5117263b46a432c012ed69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69b2da74c157c0e18ad0b1c59f4ef29b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a969f286c786d45cf93dd75fb9cc2c93.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="FisherRF-Active-View-Selection-and-Uncertainty-Quantification-for-Radiance-Fields-using-Fisher-Information"><a href="#FisherRF-Active-View-Selection-and-Uncertainty-Quantification-for-Radiance-Fields-using-Fisher-Information" class="headerlink" title="FisherRF: Active View Selection and Uncertainty Quantification for   Radiance Fields using Fisher Information"></a>FisherRF: Active View Selection and Uncertainty Quantification for   Radiance Fields using Fisher Information</h2><p><strong>Authors:Wen Jiang, Boshu Lei, Kostas Daniilidis</strong></p>
<p>This study addresses the challenging problem of active view selection and uncertainty quantification within the domain of Radiance Fields. Neural Radiance Fields (NeRF) have greatly advanced image rendering and reconstruction, but the cost of acquiring images poses the need to select the most informative viewpoints efficiently. Existing approaches depend on modifying the model architecture or hypothetical perturbation field to indirectly approximate the model uncertainty. However, selecting views from indirect approximation does not guarantee optimal information gain for the model. By leveraging Fisher Information, we directly quantify observed information on the parameters of Radiance Fields and select candidate views by maximizing the Expected Information Gain(EIG). Our method achieves state-of-the-art results on multiple tasks, including view selection, active mapping, and uncertainty quantification, demonstrating its potential to advance the field of Radiance Fields. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³Radiance Fieldsé¢†åŸŸå†…ä¸»åŠ¨è§†å›¾é€‰æ‹©å’Œä¸ç¡®å®šæ€§é‡åŒ–è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚Neural Radiance Fieldsï¼ˆNeRFï¼‰åœ¨å›¾åƒæ¸²æŸ“å’Œé‡å»ºæ–¹é¢å–å¾—äº†å·¨å¤§çš„è¿›æ­¥ï¼Œä½†è·å–å›¾åƒçš„æˆæœ¬ä¿ƒä½¿æˆ‘ä»¬éœ€è¦é«˜æ•ˆåœ°é€‰æ‹©æœ€å…·æœ‰ä¿¡æ¯é‡çš„è§†è§’ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–å‡è®¾æ‰°åŠ¨åœºæ¥é—´æ¥åœ°è¿‘ä¼¼æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚ç„¶è€Œï¼Œä»é—´æ¥è¿‘ä¼¼ä¸­é€‰æ‹©è§†å›¾å¹¶ä¸èƒ½ä¿è¯æ¨¡å‹è·å¾—æœ€ä¼˜çš„ä¿¡æ¯å¢ç›Šã€‚é€šè¿‡åˆ©ç”¨Fisherä¿¡æ¯ï¼Œæˆ‘ä»¬ç›´æ¥é‡åŒ–Radiance Fieldså‚æ•°ä¸Šçš„è§‚æµ‹ä¿¡æ¯ï¼Œå¹¶é€šè¿‡æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šï¼ˆEIGï¼‰é€‰æ‹©å€™é€‰è§†å›¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æˆæœï¼ŒåŒ…æ‹¬è§†å›¾é€‰æ‹©ã€ä¸»åŠ¨æ˜ å°„å’Œä¸ç¡®å®šæ€§é‡åŒ–ï¼Œè¯æ˜äº†å…¶åœ¨Radiance Fieldsé¢†åŸŸçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.17874v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://jiangwenpl.github.io/FisherRF/">https://jiangwenpl.github.io/FisherRF/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬ç ”ç©¶æ¢è®¨äº†æ´»åŠ¨è§†è§’é€‰æ‹©ä¸ä¸ç¡®å®šæ€§é‡åŒ–åœ¨å…‰åœºé¢†åŸŸä¸­çš„éš¾é¢˜ã€‚ç¥ç»å…‰åœºï¼ˆNeRFï¼‰æå¤§åœ°æ¨åŠ¨äº†å›¾åƒæ¸²æŸ“å’Œé‡å»ºçš„å‘å±•ï¼Œä½†è·å–å›¾åƒçš„æˆæœ¬ä¿ƒä½¿éœ€è¦æœ‰æ•ˆé€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„è§†è§’ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–å‡è®¾æ‰°åŠ¨åœºæ¥é—´æ¥è¿‘ä¼¼æ¨¡å‹ä¸ç¡®å®šæ€§ã€‚ç„¶è€Œï¼Œä»é—´æ¥è¿‘ä¼¼ä¸­é€‰æ‹©è§†å›¾å¹¶ä¸èƒ½ä¿è¯æ¨¡å‹çš„æœ€ä½³ä¿¡æ¯å¢ç›Šã€‚æœ¬ç ”ç©¶åˆ©ç”¨Fisherä¿¡æ¯ç›´æ¥é‡åŒ–å…‰åœºå‚æ•°ä¸Šçš„è§‚æµ‹ä¿¡æ¯ï¼Œé€šè¿‡æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šï¼ˆEIGï¼‰é€‰æ‹©å€™é€‰è§†å›¾ã€‚è¯¥æ–¹æ³•åœ¨å¤šä»»åŠ¡ä¸Šå‡è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å‡†ï¼ŒåŒ…æ‹¬è§†è§’é€‰æ‹©ã€æ´»åŠ¨æ˜ å°„å’Œä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæ˜¾ç¤ºäº†å…¶æ¨åŠ¨å…‰åœºé¢†åŸŸçš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶èšç„¦äºå…‰åœºé¢†åŸŸçš„æ´»åŠ¨è§†è§’é€‰æ‹©å’Œä¸ç¡®å®šæ€§é‡åŒ–éš¾é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é—´æ¥è¿‘ä¼¼æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œå¯èƒ½å¯¼è‡´ä¿¡æ¯å¢ç›Šä¸è¶³ã€‚</li>
<li>åˆ©ç”¨Fisherä¿¡æ¯ç›´æ¥é‡åŒ–å…‰åœºå‚æ•°è§‚æµ‹ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡æœ€å¤§åŒ–é¢„æœŸä¿¡æ¯å¢ç›Šé€‰æ‹©å€™é€‰è§†è§’ã€‚</li>
<li>æ–¹æ³•åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬è§†è§’é€‰æ‹©ã€æ´»åŠ¨æ˜ å°„å’Œä¸ç¡®å®šæ€§é‡åŒ–ã€‚</li>
<li>ç ”ç©¶ç»“æœæ¨åŠ¨äº†å…‰åœºé¢†åŸŸçš„å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.17874">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f30c387b7ea7afb49fa82492a1ad8deb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a486c91e5fdcbf296b3d71619573c15e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="DynaMoN-Motion-Aware-Fast-and-Robust-Camera-Localization-for-Dynamic-Neural-Radiance-Fields"><a href="#DynaMoN-Motion-Aware-Fast-and-Robust-Camera-Localization-for-Dynamic-Neural-Radiance-Fields" class="headerlink" title="DynaMoN: Motion-Aware Fast and Robust Camera Localization for Dynamic   Neural Radiance Fields"></a>DynaMoN: Motion-Aware Fast and Robust Camera Localization for Dynamic   Neural Radiance Fields</h2><p><strong>Authors:Nicolas Schischka, Hannah Schieber, Mert Asim Karaoglu, Melih GÃ¶rgÃ¼lÃ¼, Florian GrÃ¶tzner, Alexander Ladikos, Daniel Roth, Nassir Navab, Benjamin Busam</strong></p>
<p>The accurate reconstruction of dynamic scenes with neural radiance fields is significantly dependent on the estimation of camera poses. Widely used structure-from-motion pipelines encounter difficulties in accurately tracking the camera trajectory when faced with separate dynamics of the scene content and the camera movement. To address this challenge, we propose Dynamic Motion-Aware Fast and Robust Camera Localization for Dynamic Neural Radiance Fields (DynaMoN). DynaMoN utilizes semantic segmentation and generic motion masks to handle dynamic content for initial camera pose estimation and statics-focused ray sampling for fast and accurate novel-view synthesis. Our novel iterative learning scheme switches between training the NeRF and updating the pose parameters for an improved reconstruction and trajectory estimation quality. The proposed pipeline shows significant acceleration of the training process. We extensively evaluate our approach on two real-world dynamic datasets, the TUM RGB-D dataset and the BONN RGB-D Dynamic dataset. DynaMoN improves over the state-of-the-art both in terms of reconstruction quality and trajectory accuracy. We plan to make our code public to enhance research in this area. </p>
<blockquote>
<p>åˆ©ç”¨ç¥ç»è¾å°„åœºå¯¹åŠ¨æ€åœºæ™¯çš„ç²¾ç¡®é‡å»ºåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºç›¸æœºå§¿æ€çš„ä¼°è®¡ã€‚å¹¿æ³›ä½¿ç”¨çš„ç»“æ„è¿åŠ¨ç®¡é“åœ¨é¢å¯¹åœºæ™¯å†…å®¹çš„ç‹¬ç«‹åŠ¨æ€å’Œç›¸æœºè¿åŠ¨æ—¶çš„è½¨è¿¹è·Ÿè¸ªæ—¶é‡åˆ°å›°éš¾ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€è¿åŠ¨æ„ŸçŸ¥å¿«é€Ÿç¨³å¥ç›¸æœºå®šä½ç”¨äºåŠ¨æ€ç¥ç»è¾å°„åœºï¼ˆDynaMoNï¼‰ã€‚DynaMoNåˆ©ç”¨è¯­ä¹‰åˆ†å‰²å’Œé€šç”¨è¿åŠ¨è’™ç‰ˆæ¥å¤„ç†åŠ¨æ€å†…å®¹æ¥è¿›è¡Œåˆå§‹ç›¸æœºå§¿æ€ä¼°è®¡ï¼Œå¹¶ä¾§é‡äºé™æ€å°„çº¿é‡‡æ ·ä»¥å¿«é€Ÿå‡†ç¡®åœ°åˆæˆæ–°è§†è§’ã€‚æˆ‘ä»¬çš„æ–°é¢–è¿­ä»£å­¦ä¹ æ–¹æ¡ˆåœ¨è®­ç»ƒNeRFå’Œæ›´æ–°å§¿æ€å‚æ•°ä¹‹é—´åˆ‡æ¢ï¼Œä»¥æé«˜é‡å»ºå’Œè½¨è¿¹ä¼°è®¡çš„è´¨é‡ã€‚æ‰€æçš„ç®¡é“æ˜¾è‘—åŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œçš„åŠ¨æ€æ•°æ®é›†â€”â€”TUM RGB-Dæ•°æ®é›†å’ŒBONN RGB-DåŠ¨æ€æ•°æ®é›†ä¸Šå¹¿æ³›è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚DynaMoNåœ¨é‡å»ºè´¨é‡å’Œè½¨è¿¹å‡†ç¡®æ€§æ–¹é¢éƒ½è¶…è¿‡äº†ç°æœ‰æŠ€æœ¯ã€‚æˆ‘ä»¬è®¡åˆ’å…¬å¼€æˆ‘ä»¬çš„ä»£ç ä»¥ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08927v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºåŠ¨æ€åœºæ™¯ç¥ç»è¾å°„åœºé‡å»ºä¸­ç›¸æœºå§¿æ€ä¼°è®¡çš„é‡è¦æ€§ï¼Œæå‡ºä¸€ç§åŠ¨æ€è¿åŠ¨æ„ŸçŸ¥çš„å¿«é€Ÿç¨³å¥ç›¸æœºå®šä½æ–¹æ³•ï¼ˆDynaMoNï¼‰ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è¯­ä¹‰åˆ†å‰²å’Œé€šç”¨è¿åŠ¨æ©è†œå¤„ç†åŠ¨æ€å†…å®¹ï¼Œè¿›è¡Œåˆå§‹ç›¸æœºå§¿æ€ä¼°è®¡ï¼Œå¹¶é‡‡ç”¨é™æ€èšç„¦å°„çº¿é‡‡æ ·å®ç°å¿«é€Ÿå‡†ç¡®çš„æ–°è§†è§’åˆæˆã€‚å…¶è¿­ä»£å­¦ä¹ æ–¹æ¡ˆåœ¨è®­ç»ƒNeRFå’Œæ›´æ–°å§¿æ€å‚æ•°ä¹‹é—´åˆ‡æ¢ï¼Œæé«˜äº†é‡å»ºå’Œè½¨è¿¹ä¼°è®¡è´¨é‡ã€‚DynaMoNæ˜¾è‘—åŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶åœ¨ä¸¤ä¸ªçœŸå®åŠ¨æ€æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œæå‡äº†é‡å»ºè´¨é‡å’Œè½¨è¿¹å‡†ç¡®æ€§ã€‚è®¡åˆ’å…¬å¼€ä»£ç ä»¥ä¿ƒè¿›è¯¥é¢†åŸŸç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€åœºæ™¯é‡å»ºä¸­ç›¸æœºå§¿æ€ä¼°è®¡çš„é‡è¦æ€§ã€‚</li>
<li>DynaMoNæ–¹æ³•åˆ©ç”¨è¯­ä¹‰åˆ†å‰²å’Œé€šç”¨è¿åŠ¨æ©è†œå¤„ç†åŠ¨æ€å†…å®¹ï¼Œç”¨äºåˆå§‹ç›¸æœºå§¿æ€ä¼°è®¡ã€‚</li>
<li>DynaMoNé‡‡ç”¨é™æ€èšç„¦å°„çº¿é‡‡æ ·å®ç°å¿«é€Ÿå‡†ç¡®çš„æ–°è§†è§’åˆæˆã€‚</li>
<li>è¿­ä»£å­¦ä¹ æ–¹æ¡ˆåœ¨è®­ç»ƒNeRFå’Œæ›´æ–°å§¿æ€å‚æ•°ä¹‹é—´åˆ‡æ¢ï¼Œæå‡é‡å»ºå’Œè½¨è¿¹ä¼°è®¡è´¨é‡ã€‚</li>
<li>DynaMoNæ˜¾è‘—åŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>åœ¨ä¸¤ä¸ªçœŸå®åŠ¨æ€æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œè¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2309.08927">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-810a074ac22370d84e53df4e3aa4db59.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81b4c627c658399249d3103086665010.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ebc6be52865460924021d63491b294cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c8a579754ed1ff5c823b265e1cef3d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6427f445d847548c13907a50d601c63c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a0af7b29b118ac06ee81c1290eb1677.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e00ab92696c588f8f084b21670fbd7ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cfd0d6967822d10c362059c2a3d18867.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Deep-learning-based-radiointerferometric-imaging-with-GAN-aided-training"><a href="#Deep-learning-based-radiointerferometric-imaging-with-GAN-aided-training" class="headerlink" title="Deep learning-based radiointerferometric imaging with GAN-aided training"></a>Deep learning-based radiointerferometric imaging with GAN-aided training</h2><p><strong>Authors:F. Geyer, K. Schmidt, J. Kummer, M. BrÃ¼ggen, H. W. Edler, D. ElsÃ¤sser, F. Griese, A. Poggenpohl, L. Rustige, W. Rhode</strong></p>
<p>Radio interferometry invariably suffers from an incomplete coverage of the spatial Fourier space, which leads to imaging artifacts. The current state-of-the-art technique is to create an image by Fourier-transforming the incomplete visibility data and to clean the systematic effects originating from incomplete data in Fourier space. Previously, we have shown how super-resolution methods based on convolutional neural networks can reconstruct sparse visibility data. Our previous work has suffered from a low realism of the training data. The aim of this work is to build a whole simulation chain for realistic radio sources that then leads to a vastly improved neural net for the reconstruction of missing visibilities. This method offers considerable improvements in terms of speed, automatization and reproducibility over the standard techniques. Here we generate large amounts of training data by creating images of radio galaxies with a generative adversarial network (GAN) that has been trained on radio survey data. Then, we applied the Radio Interferometer Measurement Equation (RIME) in order to simulate the measurement process of a radio interferometer. We show that our neural network can reconstruct faithfully images of realistic radio galaxies. The reconstructed images agree well with the original images in terms of the source area, integrated flux density, peak flux density, and the multi-scale structural similarity index. Finally, we show how the neural net can be adapted to estimate the uncertainties in the imaging process. </p>
<blockquote>
<p>å°„ç”µå¹²æ¶‰ä»ªç»å¸¸é¢ä¸´ç©ºé—´å‚…é‡Œå¶å˜æ¢è¦†ç›–ä¸å…¨çš„é—®é¢˜ï¼Œä»è€Œå¯¼è‡´æˆåƒå¤±çœŸã€‚ç›®å‰æœ€å…ˆè¿›çš„æŠ€æœ¯æ˜¯é€šè¿‡å‚…é‡Œå¶å˜æ¢ä¸å®Œæ•´å¯è§åº¦æ•°æ®æ¥åˆ›å»ºå›¾åƒï¼Œå¹¶æ¸…ç†ç”±å‚…é‡Œå¶ç©ºé—´ä¸å®Œæ•´æ•°æ®å¼•èµ·çš„ç³»ç»Ÿæ•ˆåº”ã€‚ä»¥å‰ï¼Œæˆ‘ä»¬å·²ç»å±•ç¤ºäº†åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„è¶…åˆ†è¾¨ç‡æ–¹æ³•å¦‚ä½•é‡å»ºç¨€ç–å¯è§åº¦æ•°æ®ã€‚æˆ‘ä»¬ä¹‹å‰çš„å·¥ä½œå—åˆ°äº†è®­ç»ƒæ•°æ®çœŸå®åº¦ä½çš„å½±å“ã€‚è¿™é¡¹å·¥ä½œçš„ç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ªé’ˆå¯¹çœŸå®å°„ç”µæºçš„æ•´ä½“ä»¿çœŸé“¾ï¼Œä»è€Œå»ºç«‹ä¸€ä¸ªå¤§å¤§æ”¹è¿›çš„ç¥ç»ç½‘ç»œï¼Œç”¨äºé‡å»ºç¼ºå¤±çš„å¯è§åº¦ã€‚è¿™ç§æ–¹æ³•åœ¨é€Ÿåº¦ã€è‡ªåŠ¨åŒ–å’Œå¯é‡å¤æ€§æ–¹é¢æä¾›äº†å¯¹æ ‡å‡†æŠ€æœ¯çš„é‡å¤§æ”¹è¿›ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰åˆ›å»ºå°„ç”µæ˜Ÿç³»å›¾åƒæ¥ç”Ÿæˆå¤§é‡è®­ç»ƒæ•°æ®ï¼Œè¯¥ç½‘ç»œå·²ç»åœ¨å°„ç”µè°ƒæŸ¥æ•°æ®ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚ç„¶åï¼Œæˆ‘ä»¬åº”ç”¨å°„ç”µå¹²æ¶‰ä»ªæµ‹é‡æ–¹ç¨‹ï¼ˆRIMEï¼‰æ¥æ¨¡æ‹Ÿå°„ç”µå¹²æ¶‰ä»ªçš„æµ‹é‡è¿‡ç¨‹ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œèƒ½å¤Ÿå¿ å®åœ°é‡å»ºçœŸå®çš„å°„ç”µæ˜Ÿç³»çš„å›¾åƒã€‚é‡å»ºçš„å›¾åƒåœ¨æºåŒºåŸŸã€ç§¯åˆ†æµé‡å¯†åº¦ã€å³°å€¼æµé‡å¯†åº¦å’Œå¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°æ–¹é¢ä¸åŸå§‹å›¾åƒå»åˆè‰¯å¥½ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•è°ƒæ•´ç¥ç»ç½‘ç»œä»¥ä¼°è®¡æˆåƒè¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14100v2">PDF</a> Accepted for publication in Astronomy &amp; Astrophysics</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°„ç”µå¹²æ¶‰ä»ªåœ¨æˆåƒæ—¶å­˜åœ¨ç©ºé—´å‚…é‡Œå¶å˜æ¢ä¸å®Œå…¨çš„é—®é¢˜ï¼Œå¯¼è‡´æˆåƒå‡ºç°ä¼ªå½±ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„æ¨¡æ‹Ÿé“¾ä»¥ç”ŸæˆçœŸå®çš„å°„ç”µæºï¼Œè¿›è€Œä½¿ç”¨åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•é‡å»ºç¼ºå¤±çš„å¯è§åº¦æ•°æ®ã€‚è¯¥æ–¹æ³•ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”Ÿæˆå°„ç”µæ³¢æºå›¾åƒï¼Œå¹¶åˆ©ç”¨å°„ç”µå¹²æ¶‰ä»ªæµ‹é‡æ–¹ç¨‹æ¨¡æ‹Ÿæµ‹é‡è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œç¥ç»ç½‘ç»œèƒ½å¤Ÿé‡å»ºçœŸå®çš„å°„ç”µæ³¢æºå›¾åƒï¼Œä¸åŸå§‹å›¾åƒåœ¨æºé¢ç§¯ã€ç§¯åˆ†æµé‡å¯†åº¦ã€å³°å€¼æµé‡å¯†åº¦å’Œå¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æŒ‡æ•°ç­‰æ–¹é¢è¾¾æˆè‰¯å¥½å…±è¯†ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å±•ç¤ºäº†å¦‚ä½•è°ƒæ•´ç¥ç»ç½‘ç»œä»¥ä¼°è®¡æˆåƒè¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å°„ç”µå¹²æ¶‰ä»ªå­˜åœ¨ç©ºé—´å‚…é‡Œå¶å˜æ¢ä¸å®Œå…¨çš„é—®é¢˜ï¼Œå¯¼è‡´æˆåƒä¼ªå½±ã€‚</li>
<li>å½“å‰å…ˆè¿›çš„æ–¹æ³•æ˜¯é€šè¿‡å‚…é‡Œå¶å˜æ¢ç”Ÿæˆå›¾åƒå¹¶æ¸…ç†ç”±ä¸å®Œå…¨æ•°æ®å¼•èµ·çš„ç³»ç»Ÿæ€§å½±å“ã€‚</li>
<li>ä¹‹å‰åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•è™½èƒ½é‡å»ºç¨€ç–å¯è§åº¦æ•°æ®ï¼Œä½†è®­ç»ƒæ•°æ®ç¼ºä¹çœŸå®æ„Ÿã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨æ„å»ºä¸€ä¸ªå®Œæ•´çš„æ¨¡æ‹Ÿé“¾æ¥ç”ŸæˆçœŸå®çš„å°„ç”µæºï¼Œè¿›è€Œæé«˜ç¥ç»ç½‘ç»œå¯¹ç¼ºå¤±å¯è§åº¦çš„é‡å»ºèƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”Ÿæˆå°„ç”µæ³¢æºå›¾åƒï¼Œå¹¶æ¨¡æ‹Ÿæµ‹é‡è¿‡ç¨‹ã€‚</li>
<li>ç¥ç»ç½‘ç»œèƒ½å¤Ÿé‡å»ºçœŸå®çš„å°„ç”µæ³¢æºå›¾åƒï¼Œä¸åŸå§‹å›¾åƒåœ¨å¤šä¸ªæ–¹é¢è¾¾æˆè‰¯å¥½å…±è¯†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2307.14100">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0ec182cef014095e4e8e80305a18d444.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f973ddc9c9cbc99e9c02cda5c062021.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2c26f0823ce38b0c108ec8c562bf712a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb032dbdd8c8eb982b10d899dc62fdd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-236d47d5fb192a7cf433a9ed33efac88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f6793ad5991ab4286f32a1ccd83271d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b23a92c6a6d2683d5bda995f332db456.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16362e7d27d76bb84cc1c227dfb96092.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-92df01ad425ce71e6a3a7789281fc8d0.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  AniDoc Animation Creation Made Easier
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a07829a49dd81bb2569cf072e3346f5a.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  GraphAvatar Compact Head Avatars with GNN-Generated 3D Gaussians
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">15332k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
