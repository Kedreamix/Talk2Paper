<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  Proposer-Agent-Evaluator(PAE) Autonomous Skill Discovery For Foundation   Model Internet Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-c30275e38a084ae99a2feb9c3b5590ab.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    66 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-19-æ›´æ–°"><a href="#2024-12-19-æ›´æ–°" class="headerlink" title="2024-12-19 æ›´æ–°"></a>2024-12-19 æ›´æ–°</h1><h2 id="Proposer-Agent-Evaluator-PAE-Autonomous-Skill-Discovery-For-Foundation-Model-Internet-Agents"><a href="#Proposer-Agent-Evaluator-PAE-Autonomous-Skill-Discovery-For-Foundation-Model-Internet-Agents" class="headerlink" title="Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation   Model Internet Agents"></a>Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation   Model Internet Agents</h2><p><strong>Authors:Yifei Zhou, Qianlan Yang, Kaixiang Lin, Min Bai, Xiong Zhou, Yu-Xiong Wang, Sergey Levine, Erran Li</strong></p>
<p>The vision of a broadly capable and goal-directed agent, such as an Internet-browsing agent in the digital world and a household humanoid in the physical world, has rapidly advanced, thanks to the generalization capability of foundation models. Such a generalist agent needs to have a large and diverse skill repertoire, such as finding directions between two travel locations and buying specific items from the Internet. If each skill needs to be specified manually through a fixed set of human-annotated instructions, the agentâ€™s skill repertoire will necessarily be limited due to the quantity and diversity of human-annotated instructions. In this work, we address this challenge by proposing Proposer-Agent-Evaluator, an effective learning system that enables foundation model agents to autonomously discover and practice skills in the wild. At the heart of PAE is a context-aware task proposer that autonomously proposes tasks for the agent to practice with context information of the environment such as user demos or even just the name of the website itself for Internet-browsing agents. Then, the agent policy attempts those tasks with thoughts and actual grounded operations in the real world with resulting trajectories evaluated by an autonomous VLM-based success evaluator. The success evaluation serves as the reward signal for the agent to refine its policies through RL. We validate PAE on challenging vision-based web navigation, using both real-world and self-hosted websites from WebVoyager and WebArena.To the best of our knowledge, this work represents the first effective learning system to apply autonomous task proposal with RL for agents that generalizes real-world human-annotated benchmarks with SOTA performances. Our open-source checkpoints and code can be found in <a target="_blank" rel="noopener" href="https://yanqval.github.io/PAE/">https://yanqval.github.io/PAE/</a> </p>
<blockquote>
<p>å…·æœ‰å¹¿æ³›èƒ½åŠ›å’Œç›®æ ‡å¯¼å‘çš„ä»£ç†ï¼ˆå¦‚æ•°å­—ä¸–ç•Œä¸­çš„äº’è”ç½‘æµè§ˆä»£ç†å’Œç‰©ç†ä¸–ç•Œä¸­çš„å®¶åº­äººå½¢æœºå™¨äººï¼‰çš„è®¾æƒ³è¿…é€Ÿå¾—åˆ°æ¨è¿›ï¼Œè¿™è¦å½’åŠŸäºåŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ³›åŒ–ä»£ç†éœ€è¦æ‹¥æœ‰å¤§é‡ä¸”å¤šæ ·åŒ–çš„æŠ€èƒ½åº“ï¼Œä¾‹å¦‚æ‰¾åˆ°ä¸¤ä¸ªæ—…è¡Œåœ°ç‚¹ä¹‹é—´çš„è·¯çº¿ä»¥åŠä»äº’è”ç½‘ä¸Šè´­ä¹°ç‰¹å®šå•†å“ã€‚å¦‚æœæ¯ä¸ªæŠ€èƒ½éƒ½éœ€è¦é€šè¿‡å›ºå®šçš„ä¸€ç»„äººç±»æ ‡æ³¨æŒ‡ä»¤æ¥æ‰‹åŠ¨æŒ‡å®šï¼Œé‚£ä¹ˆç”±äºäººç±»æ ‡æ³¨æŒ‡ä»¤çš„æ•°é‡å’Œå¤šæ ·æ€§ï¼Œä»£ç†çš„æŠ€èƒ½åº“å¿…å°†å—åˆ°é™åˆ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºProposer-Agent-Evaluatorï¼ˆPAEï¼‰æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè¿™æ˜¯ä¸€ç§æœ‰æ•ˆçš„å­¦ä¹ ç³»ç»Ÿï¼Œä½¿åŸºç¡€æ¨¡å‹ä»£ç†èƒ½å¤Ÿè‡ªä¸»åœ°å‘ç°å’Œç»ƒä¹ çœŸå®ç¯å¢ƒä¸­çš„æŠ€èƒ½ã€‚PAEçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªæƒ…å¢ƒæ„ŸçŸ¥çš„ä»»åŠ¡æå‡ºè€…ï¼Œå®ƒå¯ä»¥æ ¹æ®ç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯è‡ªä¸»åœ°æå‡ºä»»åŠ¡ä¾›ä»£ç†ç»ƒä¹ ï¼Œå¦‚ç”¨æˆ·æ¼”ç¤ºæˆ–ä»…ä»…æ˜¯äº’è”ç½‘æµè§ˆä»£ç†çš„åç§°æœ¬èº«ã€‚ç„¶åï¼Œä»£ç†ç­–ç•¥å°è¯•è¿™äº›ä»»åŠ¡ï¼Œåœ¨ç°å®ä¸–ç•Œä¸­é€šè¿‡æ€è€ƒå’Œå®é™…æ“ä½œæ¥å®Œæˆä»»åŠ¡è½¨è¿¹ï¼Œå¹¶ç”±è‡ªä¸»VLMï¼ˆåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰çš„æˆåŠŸè¯„ä¼°å™¨å¯¹ç»“æœè¿›è¡Œè¯„ä¼°ã€‚æˆåŠŸè¯„ä¼°ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œç”¨äºé€šè¿‡å¼ºåŒ–å­¦ä¹ ä½¿ä»£ç†ä¼˜åŒ–å…¶ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨åŸºäºè§†è§‰çš„ç½‘é¡µå¯¼èˆªç­‰æŒ‘æˆ˜ä»»åŠ¡ä¸ŠéªŒè¯äº†PAEçš„æœ‰æ•ˆæ€§ï¼Œè¿™äº›ä»»åŠ¡åŒ…æ‹¬ä½¿ç”¨WebVoyagerå’ŒWebArenaæä¾›çš„ç°å®ä¸–ç•Œå’Œè‡ªæˆ‘æ‰˜ç®¡ç½‘ç«™ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™é¡¹å·¥ä½œä»£è¡¨ç€é¦–æ¬¡æœ‰æ•ˆåœ°å°†è‡ªä¸»ä»»åŠ¡ææ¡ˆä¸å¼ºåŒ–å­¦ä¹ åº”ç”¨äºä»£ç†çš„æœ‰æ•ˆå­¦ä¹ ç³»ç»Ÿï¼Œè¯¥ä»£ç†èƒ½å¤Ÿæ¦‚æ‹¬ç°å®ä¸–ç•Œçš„äººç±»æ³¨é‡ŠåŸºå‡†æµ‹è¯•å¹¶è¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚æˆ‘ä»¬çš„å¼€æºæ£€æŸ¥ç‚¹å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://yanqval.github.io/PAE/%E6%89%BE%E5%88%B0%E3%80%82">https://yanqval.github.io/PAE/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13194v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é€šç”¨èƒ½åŠ›ä»£ç†ï¼Œå¦‚æ•°å­—ä¸–ç•Œä¸­çš„ç½‘ç»œæµè§ˆä»£ç†å’Œç‰©ç†ä¸–ç•Œä¸­çš„å®¶åº­äººå½¢æœºå™¨äººï¼Œå…¶è§†é‡è¿…é€Ÿæ‰©å±•ï¼Œå¾—ç›ŠäºåŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤ç±»é€šç”¨ä»£ç†éœ€è¦æ‹¥æœ‰åºå¤§ä¸”å¤šæ ·åŒ–çš„æŠ€èƒ½åº“ï¼Œå¦‚ç¡®å®šä¸¤ä¸ªæ—…è¡Œåœ°ç‚¹ä¹‹é—´çš„æ–¹å‘ä»¥åŠä»äº’è”ç½‘ä¸Šè´­ä¹°ç‰¹å®šå•†å“ç­‰ã€‚è‹¥æ¯é¡¹æŠ€èƒ½éƒ½éœ€è¦é€šè¿‡å›ºå®šçš„äººç±»æ³¨é‡ŠæŒ‡ä»¤æ‰‹åŠ¨æŒ‡å®šï¼Œåˆ™ç”±äºäººç±»æ³¨é‡ŠæŒ‡ä»¤çš„æ•°é‡å’Œå¤šæ ·æ€§ï¼Œä»£ç†çš„æŠ€èƒ½åº“å¿…å°†å—åˆ°é™åˆ¶ã€‚æœ¬ç ”ç©¶é€šè¿‡æå‡ºProposer-Agent-Evaluatorï¼ˆPAEï¼‰è¿™ä¸€æœ‰æ•ˆçš„å­¦ä¹ ç³»ç»Ÿæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½¿åŸºç¡€æ¨¡å‹ä»£ç†èƒ½å¤Ÿè‡ªä¸»åœ°å‘ç°å’Œç»ƒä¹ ç¯å¢ƒä¸­çš„æŠ€èƒ½ã€‚PAEçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªæƒ…å¢ƒæ„ŸçŸ¥ä»»åŠ¡æå‡ºè€…ï¼Œå¯è‡ªåŠ¨ä¸ºä»£ç†æå‡ºç»ƒä¹ ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨ç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚ç”¨æˆ·æ¼”ç¤ºæˆ–ä»…æ˜¯ç½‘ç«™åç§°æœ¬èº«ï¼ˆå¯¹äºç½‘ç»œæµè§ˆä»£ç†ï¼‰ã€‚ç„¶åï¼Œä»£ç†ç­–ç•¥å°è¯•è¿™äº›ä»»åŠ¡ï¼Œå¹¶ä¼´éšç€å®é™…çš„ä¸–ç•Œæ“ä½œè½¨è¿¹ï¼Œç”±è‡ªä¸»VLMæˆåŠŸè¯„ä¼°å™¨è¿›è¡Œè¯„ä¼°ã€‚æˆåŠŸè¯„ä¼°ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œç”¨äºé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ä»£ç†ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰ç½‘ç»œå¯¼èˆªä»»åŠ¡ä¸ŠéªŒè¯äº†PAEçš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä½¿ç”¨WebVoyagerå’ŒWebArenaçš„çœŸå®ä¸–ç•Œå’Œè‡ªæ‰˜ç®¡ç½‘ç«™ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™é¡¹å·¥ä½œé¦–æ¬¡å®ç°äº†æœ‰æ•ˆçš„å­¦ä¹ ç³»ç»Ÿï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè‡ªä¸»ä»»åŠ¡æè®®ï¼Œé€‚ç”¨äºæ³›åŒ–äººç±»æ³¨é‡ŠåŸºå‡†æµ‹è¯•çš„ä»£ç†ï¼Œå¹¶å–å¾—äº†SOTAæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é€šç”¨ä»£ç†éœ€è¦æ‹¥æœ‰å¹¿æ³›ä¸”å¤šæ ·åŒ–çš„æŠ€èƒ½åº“ä»¥é€‚åº”ä¸åŒä»»åŠ¡éœ€æ±‚ã€‚</li>
<li>æ‰‹åŠ¨æŒ‡å®šæŠ€èƒ½ç”±äºæŒ‡ä»¤çš„æ•°é‡å’Œå¤šæ ·æ€§è€Œå—åˆ°é™åˆ¶ã€‚</li>
<li>Proposer-Agent-Evaluatorï¼ˆPAEï¼‰ç³»ç»Ÿå¯è§£å†³æ­¤æŒ‘æˆ˜ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè‡ªä¸»å‘ç°ç¯å¢ƒæŠ€èƒ½ã€‚</li>
<li>PAEçš„æ ¸å¿ƒæ˜¯æƒ…å¢ƒæ„ŸçŸ¥ä»»åŠ¡æå‡ºè€…ï¼Œå¯åˆ©ç”¨ç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯ä¸ºä»£ç†æå‡ºä»»åŠ¡ã€‚</li>
<li>ä»£ç†ç­–ç•¥å°è¯•ä»»åŠ¡å¹¶ä¼´éšå®é™…æ“ä½œè½¨è¿¹ï¼Œç”±è‡ªä¸»VLMæˆåŠŸè¯„ä¼°å™¨è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>æˆåŠŸè¯„ä¼°ä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±ä¿¡å·ï¼Œç”¨äºä¼˜åŒ–ä»£ç†ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13194">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-49abccfef1c4d250808a647e2f5d30df.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b66cc0c2255622076bfc62253c17f140.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SafeAgentBench-A-Benchmark-for-Safe-Task-Planning-of-Embodied-LLM-Agents"><a href="#SafeAgentBench-A-Benchmark-for-Safe-Task-Planning-of-Embodied-LLM-Agents" class="headerlink" title="SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM   Agents"></a>SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM   Agents</h2><p><strong>Authors:Sheng Yin, Xianghe Pang, Yuanzhuo Ding, Menglan Chen, Yutong Bi, Yichen Xiong, Wenhao Huang, Zhen Xiang, Jing Shao, Siheng Chen</strong></p>
<p>With the integration of large language models (LLMs), embodied agents have strong capabilities to execute complicated instructions in natural language, paving a way for the potential deployment of embodied robots. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in real world. To study this issue, we present SafeAgentBench â€“ a new benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that the best-performing baseline gets 69% success rate for safe tasks, but only 5% rejection rate for hazardous tasks, indicating significant safety risks. More details and codes are available at <a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench">https://github.com/shengyin1224/SafeAgentBench</a>. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é›†æˆï¼Œå®ä½“ä»£ç†å…·å¤‡äº†æ‰§è¡Œè‡ªç„¶è¯­è¨€ä¸­çš„å¤æ‚æŒ‡ä»¤çš„å¼ºå¤§èƒ½åŠ›ï¼Œä¸ºå®ä½“æœºå™¨äººçš„æ½œåœ¨éƒ¨ç½²é“ºå¹³äº†é“è·¯ã€‚ç„¶è€Œï¼Œä¸€ä¸ªå¯é¢„è§çš„é—®é¢˜æ˜¯ï¼Œè¿™äº›å®ä½“ä»£ç†ä¹Ÿå¯ä»¥å®Œç¾åœ°æ‰§è¡Œä¸€äº›å±é™©ä»»åŠ¡ï¼Œå¯èƒ½åœ¨ç°å®ä¸–ç•Œä¸­é€ æˆæŸå®³ã€‚ä¸ºäº†ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†SafeAgentBenchâ€”â€”ä¸€ä¸ªæ–°çš„é’ˆå¯¹å®ä½“LLMä»£ç†çš„å®‰å…¨æ„è¯†ä»»åŠ¡è§„åˆ’çš„åŸºå‡†æµ‹è¯•ã€‚SafeAgentBenchåŒ…æ‹¬ï¼šï¼ˆ1ï¼‰åŒ…å«750ä¸ªä»»åŠ¡çš„æ–°æ•°æ®é›†ï¼Œæ¶µç›–10ç§æ½œåœ¨å±é™©å’Œ3ç§ä»»åŠ¡ç±»å‹ï¼›ï¼ˆ2ï¼‰SafeAgentEnvï¼Œä¸€ä¸ªé€šç”¨çš„å®ä½“ç¯å¢ƒï¼Œå¸¦æœ‰ä½çº§æ§åˆ¶å™¨ï¼Œæ”¯æŒå¤šä»£ç†æ‰§è¡Œï¼Œå…·æœ‰é’ˆå¯¹8ç§æœ€æ–°æŠ€æœ¯çš„åŸºçº¿æ¨¡å‹çš„17ä¸ªé«˜çº§æ“ä½œï¼›ï¼ˆ3ï¼‰ä»æ‰§è¡Œå’Œè¯­ä¹‰è§’åº¦çš„å¯é è¯„ä¼°æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¡¨ç°æœ€ä½³çš„åŸºçº¿æ¨¡å‹åœ¨å®‰å…¨ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä¸º69%ï¼Œä½†åœ¨å±é™©ä»»åŠ¡ä¸Šçš„æ‹’ç»ç‡ä¸ºä»…5%ï¼Œè¡¨æ˜å­˜åœ¨æ˜¾è‘—çš„å®‰å…¨é£é™©ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œä»£ç è¯·è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench%E3%80%82">https://github.com/shengyin1224/SafeAgentBenchã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13178v2">PDF</a> 21 pages, 14 tables, 7 figures, submitted to ICRA 2024</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®ä½“ä»£ç†å…·æœ‰å¼ºå¤§çš„è‡ªç„¶è¯­è¨€æ‰§è¡Œèƒ½åŠ›ï¼Œè¿™ä¸ºå®ä½“æœºå™¨äººçš„æ½œåœ¨éƒ¨ç½²é“ºå¹³äº†é“è·¯ã€‚ç„¶è€Œï¼Œå®ä½“ä»£ç†ä¹Ÿå¯èƒ½å®Œç¾æ‰§è¡Œä¸€äº›å±é™©ä»»åŠ¡ï¼Œä»è€Œåœ¨ç°å®ä¸–ç•Œä¸­é€ æˆæ½œåœ¨æŸå®³ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†SafeAgentBenchâ€”â€”ä¸€ä¸ªé’ˆå¯¹å®ä½“LLMä»£ç†çš„å®‰å…¨æ„è¯†ä»»åŠ¡è§„åˆ’çš„æ–°åŸºå‡†æµ‹è¯•ã€‚SafeAgentBenchåŒ…æ‹¬ï¼šä¸€ã€åŒ…å«750ä¸ªä»»åŠ¡çš„æ–°æ•°æ®é›†ï¼Œæ¶µç›–10ç§æ½œåœ¨å±å®³å’Œä¸‰ç§ä»»åŠ¡ç±»å‹ï¼›äºŒã€SafeAgentEnvé€šç”¨å®ä½“ç¯å¢ƒï¼Œå…·æœ‰åº•å±‚æ§åˆ¶å™¨ï¼Œæ”¯æŒå¤šä»£ç†æ‰§è¡Œï¼Œä¸ºå…«ä¸ªæœ€æ–°åŸºçº¿æä¾›åä¸ƒç§é«˜çº§æ“ä½œï¼›ä¸‰ã€ä»æ‰§è¡Œå’Œè¯­ä¹‰è§’åº¦æä¾›å¯é çš„è¯„ä¼°æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€ä½³åŸºçº¿åœ¨å®‰å…¨ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡è¾¾åˆ°ç™¾åˆ†ä¹‹å…­åä¹ï¼Œä½†åœ¨å±é™©ä»»åŠ¡ä¸Šçš„æ‹’ç»ç‡ä»…ä¸ºç™¾åˆ†ä¹‹äº”ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„å®‰å…¨é£é™©ã€‚æ›´å¤šè¯¦æƒ…å’Œä»£ç å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench%E3%80%82">https://github.com/shengyin1224/SafeAgentBenchã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½¿å®ä½“ä»£ç†èƒ½å¤Ÿæ‰§è¡Œå¤æ‚çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚</li>
<li>å®ä½“ä»£ç†åœ¨ç°å®ä¸–ç•Œä¸­æœ‰æ½œåœ¨çš„å±é™©æ‰§è¡Œä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>SafeAgentBenchæ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å®ä½“LLMä»£ç†çš„å®‰å…¨æ„è¯†ä»»åŠ¡è§„åˆ’ã€‚</li>
<li>SafeAgentBenchåŒ…æ‹¬ä¸€ä¸ªæ–°æ•°æ®é›†ï¼Œæ¶µç›–å¤šç§æ½œåœ¨å±å®³å’Œä»»åŠ¡ç±»å‹ã€‚</li>
<li>SafeAgentEnvæ˜¯ä¸€ä¸ªé€šç”¨å®ä½“ç¯å¢ƒï¼Œæ”¯æŒå¤šä»£ç†æ‰§è¡Œå’Œé«˜å±‚æ¬¡æ“ä½œã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å®‰å…¨ä»»åŠ¡ä¸Šçš„è¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨å±é™©ä»»åŠ¡ä¸Šä»å­˜åœ¨æ˜¾è‘—çš„å®‰å…¨é£é™©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2e13e57e3979c9c5b1ce769ac2c819ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9bfd9426d725cbe359056203be83a925.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc2ed00fed1f090b2b5f5376e2dbecd0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-08e2895a318dd12f07ce9551d82799a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8fe10df61c7d83148a53067563ddb91.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Contract-based-Design-and-Verification-of-Multi-Agent-Systems-with-Quantitative-Temporal-Requirements"><a href="#Contract-based-Design-and-Verification-of-Multi-Agent-Systems-with-Quantitative-Temporal-Requirements" class="headerlink" title="Contract-based Design and Verification of Multi-Agent Systems with   Quantitative Temporal Requirements"></a>Contract-based Design and Verification of Multi-Agent Systems with   Quantitative Temporal Requirements</h2><p><strong>Authors:Rafael Dewes, Rayna Dimitrova</strong></p>
<p>Quantitative requirements play an important role in the context of multi-agent systems, where there is often a trade-off between the tasks of individual agents and the constraints that the agents must jointly adhere to. We study multi-agent systems whose requirements are formally specified in the quantitative temporal logic LTL[$\mathcal{F}$] as a combination of local task specifications for the individual agents and a shared safety constraint, The intricate dependencies between the individual agents entailed by their local and shared objectives make the design of multi-agent systems error-prone, and their verification time-consuming. In this paper we address this problem by proposing a novel notion of quantitative assume-guarantee contracts, that enables the compositional design and verification of multi-agent systems with quantitative temporal specifications. The crux of these contracts lies in their ability to capture the coordination between the individual agents to achieve an optimal value of the overall specification under any possible behavior of the external environment. We show that the proposed framework improves the scalability and modularity of formal verification of multi-agent systems against quantitative temporal specifications. </p>
<blockquote>
<p>åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»ŸèƒŒæ™¯ä¸‹ï¼Œå®šé‡è¦æ±‚å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚ä¸ªä½“æ™ºèƒ½ä½“çš„ä»»åŠ¡ä¸æ™ºèƒ½ä½“å¿…é¡»å…±åŒéµå®ˆçš„çº¦æŸä¹‹é—´å¾€å¾€å­˜åœ¨æƒè¡¡ã€‚æˆ‘ä»¬ç ”ç©¶çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è¦æ±‚ä»¥å®šé‡æ—¶åºé€»è¾‘LTL[$\mathcal{F}$]çš„å½¢å¼æ­£å¼æŒ‡å®šï¼Œè¿™æ˜¯ä¸ªä½“æ™ºèƒ½ä½“çš„å±€éƒ¨ä»»åŠ¡è§„èŒƒä¸å…±äº«å®‰å…¨çº¦æŸçš„ç»“åˆã€‚ä¸ªä½“æ™ºèƒ½ä½“ä¹‹é—´ç”±å±€éƒ¨å’Œå…±äº«ç›®æ ‡äº§ç”Ÿçš„å¤æ‚ä¾èµ–å…³ç³»ä½¿å¾—å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡å®¹æ˜“å‡ºç°é”™è¯¯ï¼Œå¹¶ä¸”å…¶éªŒè¯è¿‡ç¨‹éå¸¸è€—æ—¶ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å®šé‡å‡è®¾ä¿è¯åˆåŒæ¦‚å¿µï¼Œå®ƒèƒ½å®ç°å¯¹å…·æœ‰å®šé‡æ—¶åºè§„èŒƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç»„åˆè®¾è®¡å’ŒéªŒè¯ã€‚è¿™äº›åˆåŒçš„æ ¸å¿ƒåœ¨äºå®ƒä»¬èƒ½å¤Ÿæ•æ‰ä¸ªä½“æ™ºèƒ½ä½“ä¹‹é—´çš„åè°ƒï¼Œä»¥å®ç°æ€»ä½“è§„èŒƒçš„æœ€ä¼˜å€¼ï¼Œæ— è®ºå¤–éƒ¨ç¯å¢ƒæœ‰ä»»ä½•å¯èƒ½çš„è¡Œä¸ºã€‚æˆ‘ä»¬è¯æ˜äº†æ‰€æå‡ºçš„æ¡†æ¶æé«˜äº†é’ˆå¯¹å®šé‡æ—¶åºè§„èŒƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå½¢å¼éªŒè¯çš„å¯æ‰©å±•æ€§å’Œæ¨¡å—åŒ–ç¨‹åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13114v1">PDF</a> Extended version of paper accepted at AAAI-25</p>
<p><strong>Summary</strong><br>     å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„é‡åŒ–è¦æ±‚åœ¨åè°ƒä¸ªä½“ä»»åŠ¡ä¸å…±äº«çº¦æŸä¹‹é—´èµ·ç€é‡è¦çš„æƒè¡¡ä½œç”¨ã€‚æœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨å®šé‡æ—¶åºé€»è¾‘LTL[$\mathcal{F}$]è§„èŒƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä¸ªä½“ä»£ç†å±€éƒ¨ä»»åŠ¡è§„èŒƒå’Œå…±äº«å®‰å…¨çº¦æŸã€‚ä»£ç†é—´å¤æ‚çš„ç›¸äº’ä¾èµ–å…³ç³»ä½¿å¾—å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡æ˜“å‡ºé”™ä¸”éªŒè¯è€—æ—¶ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºå®šé‡å‡è®¾ä¿è¯åˆåŒçš„æ–°æ¦‚å¿µï¼Œä½¿å…·æœ‰å®šé‡æ—¶åºè§„èŒƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿèƒ½å¤Ÿå®ç°ç»„åˆè®¾è®¡ä¸éªŒè¯ã€‚åˆåŒçš„æ ¸å¿ƒåœ¨äºæ•æ‰ä¸ªä½“ä»£ç†ä¹‹é—´çš„åè°ƒï¼Œä»¥åœ¨ä»»ä½•å¯èƒ½çš„å¤–ç•Œç¯å¢ƒè¡Œä¸ºä¸‹å®ç°æ€»ä½“è§„èŒƒçš„æœ€ä¼˜å€¼ã€‚è¯¥æ¡†æ¶æé«˜äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¯¹å®šé‡æ—¶åºè§„èŒƒçš„æ­£å¼éªŒè¯çš„å¯æ‰©å±•æ€§å’Œæ¨¡å—åŒ–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å­˜åœ¨é‡åŒ–è¦æ±‚çš„é‡è¦æ€§ï¼Œæ¶‰åŠä¸ªä½“ä»»åŠ¡å’Œå…±äº«çº¦æŸä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>ä½¿ç”¨å®šé‡æ—¶åºé€»è¾‘LTL[$\mathcal{F}$]æ¥æ­£å¼è§„èŒƒå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è¦æ±‚ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè®¾è®¡ä¸­å­˜åœ¨å¤æ‚çš„ä»£ç†é—´ç›¸äº’ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´è®¾è®¡å’ŒéªŒè¯çš„å›°éš¾ã€‚</li>
<li>å¼•å…¥å®šé‡å‡è®¾ä¿è¯åˆåŒæ¦‚å¿µä»¥è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡å’ŒéªŒè¯é—®é¢˜ã€‚</li>
<li>åˆåŒèƒ½æ•æ‰ä¸ªä½“ä»£ç†é—´çš„åè°ƒï¼Œå®ç°æ•´ä½“è§„èŒƒçš„æœ€ä¼˜å€¼ï¼Œæ— è®ºå¤–ç•Œç¯å¢ƒå¦‚ä½•å˜åŒ–ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶æé«˜äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¯¹å®šé‡æ—¶åºè§„èŒƒçš„æ­£å¼éªŒè¯çš„å¯æ‰©å±•æ€§å’Œæ¨¡å—åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹äºå¤„ç†å¤æ‚çš„æ™ºèƒ½ä½“ç³»ç»Ÿå…·æœ‰é‡è¦çš„å®ç”¨æ€§å’Œç†è®ºä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13114">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d6d41e83307c87263b39d40c1d4a316e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="An-Agentic-Approach-to-Automatic-Creation-of-P-ID-Diagrams-from-Natural-Language-Descriptions"><a href="#An-Agentic-Approach-to-Automatic-Creation-of-P-ID-Diagrams-from-Natural-Language-Descriptions" class="headerlink" title="An Agentic Approach to Automatic Creation of P&amp;ID Diagrams from Natural   Language Descriptions"></a>An Agentic Approach to Automatic Creation of P&amp;ID Diagrams from Natural   Language Descriptions</h2><p><strong>Authors:Shreeyash Gowaikar, Srinivasan Iyengar, Sameer Segal, Shivkumar Kalyanaraman</strong></p>
<p>The Piping and Instrumentation Diagrams (P&amp;IDs) are foundational to the design, construction, and operation of workflows in the engineering and process industries. However, their manual creation is often labor-intensive, error-prone, and lacks robust mechanisms for error detection and correction. While recent advancements in Generative AI, particularly Large Language Models (LLMs) and Vision-Language Models (VLMs), have demonstrated significant potential across various domains, their application in automating generation of engineering workflows remains underexplored. In this work, we introduce a novel copilot for automating the generation of P&amp;IDs from natural language descriptions. Leveraging a multi-step agentic workflow, our copilot provides a structured and iterative approach to diagram creation directly from Natural Language prompts. We demonstrate the feasibility of the generation process by evaluating the soundness and completeness of the workflow, and show improved results compared to vanilla zero-shot and few-shot generation approaches. </p>
<blockquote>
<p>ç®¡é“ä¸ä»ªè¡¨å›¾ï¼ˆP&amp;IDsï¼‰æ˜¯å·¥ç¨‹å’Œå·¥è‰ºè¡Œä¸šä¸­å·¥ä½œæµç¨‹è®¾è®¡ã€æ„å»ºå’Œè¿è¥çš„åŸºç¡€ã€‚ç„¶è€Œï¼Œå…¶æ‰‹åŠ¨åˆ›å»ºå¾€å¾€åŠ³åŠ¨å¼ºåº¦å¤§ã€æ˜“å‡ºé”™ï¼Œä¸”ç¼ºä¹ç¨³å¥çš„è¯¯å·®æ£€æµ‹å’Œæ ¡æ­£æœºåˆ¶ã€‚è™½ç„¶æœ€è¿‘ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œå·²åœ¨å„ä¸ªé¢†åŸŸæ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†å…¶åœ¨è‡ªåŠ¨åŒ–å·¥ç¨‹å·¥ä½œæµç¨‹ç”Ÿæˆæ–¹é¢çš„åº”ç”¨ä»è¢«æ¢ç´¢ä¸è¶³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹ copilotï¼Œç”¨äºæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°è‡ªåŠ¨ç”Ÿæˆ P&amp;IDsã€‚åˆ©ç”¨å¤šæ­¥ä»£ç†å·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬çš„ copilot æä¾›äº†ä¸€ç§ç»“æ„åŒ–ã€è¿­ä»£çš„æ–¹æ³•ï¼Œå¯ç›´æ¥ä»è‡ªç„¶è¯­è¨€æç¤ºåˆ›å»ºå›¾è¡¨ã€‚æˆ‘ä»¬é€šè¿‡è¯„ä¼°å·¥ä½œæµç¨‹çš„å¥å…¨æ€§å’Œå®Œæ•´æ€§æ¥è¯æ˜ç”Ÿæˆè¿‡ç¨‹çš„å¯è¡Œæ€§ï¼Œå¹¶å±•ç¤ºäº†ä¸é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ç”Ÿæˆæ–¹æ³•ç›¸æ¯”çš„æ”¹è¿›ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12898v1">PDF</a> Accepted at the AAAIâ€™25 Workshop on AI to Accelerate Science and   Engineering (AI2ASE)</p>
<p><strong>Summary</strong></p>
<p>å·¥ç¨‹æµç¨‹å›¾å’Œä»ªå™¨æµç¨‹å›¾ï¼ˆP&amp;IDsï¼‰æ˜¯å·¥ç¨‹åŠæµç¨‹è®¾è®¡ã€å»ºè®¾å’Œæ“ä½œçš„åŸºç¡€ã€‚æ‰‹åŠ¨åˆ›å»ºP&amp;IDså¾€å¾€åŠ³åŠ¨å¼ºåº¦å¤§ã€æ˜“å‡ºé”™ï¼Œç¼ºä¹å¯é çš„é”™è¯¯æ£€æµ‹å’Œçº æ­£æœºåˆ¶ã€‚æœ€è¿‘ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆå°¤å…¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰åœ¨å„é¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†å…¶åœ¨è‡ªåŠ¨åŒ–ç”Ÿæˆå·¥ç¨‹æµç¨‹æ–¹é¢çš„åº”ç”¨ä»è¢«å¿½è§†ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§æ–°å‹P&amp;IDsè‡ªåŠ¨ç”ŸæˆåŠ©æ‰‹ï¼Œè¯¥åŠ©æ‰‹å¯ç›´æ¥ä»è‡ªç„¶è¯­è¨€æè¿°ä¸­ç”Ÿæˆæµç¨‹å›¾ã€‚åˆ©ç”¨å¤šæ­¥éª¤ä»£ç†å·¥ä½œæµç¨‹ï¼Œè¯¥åŠ©æ‰‹æä¾›ç»“æ„åŒ–ã€è¿­ä»£å¼æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºç›´è§‚è¯­è¨€æç¤ºä¸‹çš„å›¾è¡¨ã€‚é€šè¿‡å¯¹ç”Ÿæˆæµç¨‹çš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§è¿›è¡Œè¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶åœ¨æå‡æ€§èƒ½æ–¹é¢çš„æ•ˆæœï¼Œç›¸å¯¹äºä¼ ç»Ÿçš„é›¶æ ·æœ¬å’Œå°‘é‡æ ·æœ¬ç”Ÿæˆæ–¹æ³•æœ‰æ˜æ˜¾çš„æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>P&amp;IDsåœ¨å·¥ç¨‹å’Œæµç¨‹è¡Œä¸šä¸­çš„é‡è¦æ€§ã€‚</li>
<li>æ‰‹åŠ¨åˆ›å»ºP&amp;IDså­˜åœ¨çš„åŠ³åŠ¨å¼ºåº¦é«˜ã€æ˜“å‡ºé”™ç­‰é—®é¢˜ã€‚</li>
<li>äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è‡ªåŠ¨åŒ–ç”Ÿæˆå·¥ç¨‹æµç¨‹æ–¹é¢çš„æ½œåŠ›ä¸åº”ç”¨ç°çŠ¶ã€‚</li>
<li>æ–°å‹è‡ªåŠ¨ç”ŸæˆåŠ©æ‰‹èƒ½å¤Ÿç›´æ¥ä»è‡ªç„¶è¯­è¨€æè¿°ä¸­ç”ŸæˆP&amp;IDsçš„åŠŸèƒ½ç‰¹ç‚¹ã€‚</li>
<li>åˆ©ç”¨å¤šæ­¥éª¤ä»£ç†å·¥ä½œæµç¨‹çš„ç”ŸæˆåŠ©æ‰‹å®ç°ç»“æ„åŒ–ã€è¿­ä»£å¼å›¾è¡¨åˆ›å»ºçš„æ–¹æ³•ã€‚</li>
<li>å¯¹ç”Ÿæˆæµç¨‹çš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§è¯„ä¼°çš„é‡è¦æ€§å’Œæ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12898">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-009e6b6d1a78b3704998a50af84e3715.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be680d39e5abf37802c1b4facffb31cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e13cd02d350c010a8f3b31abef93997a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2d7e3ef8c1b5ddbcb01598af390fcffb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f2651ce9b407106e31d9045d602d8af7.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Bayesian-Persuasion-with-Externalities-Exploiting-Agent-Types"><a href="#Bayesian-Persuasion-with-Externalities-Exploiting-Agent-Types" class="headerlink" title="Bayesian Persuasion with Externalities: Exploiting Agent Types"></a>Bayesian Persuasion with Externalities: Exploiting Agent Types</h2><p><strong>Authors:Jonathan Shaki, Jiarui Gan, Sarit Kraus</strong></p>
<p>We study a Bayesian persuasion problem with externalities. In this model, a principal sends signals to inform multiple agents about the state of the world. Simultaneously, due to the existence of externalities in the agentsâ€™ utilities, the principal also acts as a correlation device to correlate the agentsâ€™ actions. We consider the setting where the agents are categorized into a small number of types. Agents of the same type share identical utility functions and are treated equitably in the utility functions of both other agents and the principal. We study the problem of computing optimal signaling strategies for the principal, under three different types of signaling channels: public, private, and semi-private. Our results include revelation-principle-style characterizations of optimal signaling strategies, linear programming formulations, and analysis of in&#x2F;tractability of the optimization problems. It is demonstrated that when the maximum number of deviating agents is bounded by a constant, our LP-based formulations compute optimal signaling strategies in polynomial time. Otherwise, the problems are NP-hard. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†ä¸€ä¸ªå¸¦æœ‰å¤–éƒ¨æ€§çš„è´å¶æ–¯åŠè¯´é—®é¢˜ã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œä¸€ä¸ªä¸»ä½“å‘é€ä¿¡å·æ¥å‘ŠçŸ¥å¤šä¸ªä»£ç†ä¸–ç•ŒçŠ¶æ€ã€‚åŒæ—¶ï¼Œç”±äºä»£ç†æ•ˆç”¨ä¸­å­˜åœ¨å¤–éƒ¨æ€§ï¼Œä¸»ä½“è¿˜å……å½“å…³è”è®¾å¤‡æ¥å…³è”ä»£ç†çš„è¡ŒåŠ¨ã€‚æˆ‘ä»¬è€ƒè™‘å°†ä»£ç†äººåˆ†ä¸ºå°‘æ•°å‡ ç§ç±»å‹çš„æƒ…å¢ƒã€‚åŒä¸€ç±»å‹çš„ä»£ç†äººå…·æœ‰ç›¸åŒçš„æ•ˆç”¨å‡½æ•°ï¼Œå¹¶åœ¨å…¶ä»–ä»£ç†äººå’Œä¸»ä½“çš„æ•ˆç”¨å‡½æ•°ä¸­å…¬å¹³å¯¹å¾…ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä¸»ä½“åœ¨ä¸‰ç§ä¸åŒç±»å‹çš„ä¿¡å·é€šé“ä¸‹è®¡ç®—æœ€ä¼˜ä¿¡å·ç­–ç•¥çš„é—®é¢˜ï¼šå…¬å…±é€šé“ã€ç§äººé€šé“å’ŒåŠç§äººé€šé“ã€‚æˆ‘ä»¬çš„ç»“æœåŒ…æ‹¬æ­ç¤ºæ€§åŸç†é£æ ¼çš„æœ€ä¼˜ä¿¡å·ç­–ç•¥ç‰¹å¾ã€çº¿æ€§è§„åˆ’å…¬å¼å’Œä¼˜åŒ–é—®é¢˜çš„å¯è§£æ€§åˆ†æã€‚ç»“æœè¡¨æ˜ï¼Œå½“åç¦»ä»£ç†äººçš„æœ€å¤§æ•°é‡è¢«ä¸€ä¸ªå¸¸æ•°é™åˆ¶æ—¶ï¼Œæˆ‘ä»¬çš„åŸºäºLPçš„å…¬å¼å¯ä»¥åœ¨å¤šé¡¹å¼æ—¶é—´å†…è®¡ç®—æœ€ä¼˜ä¿¡å·ç­–ç•¥ã€‚å¦åˆ™ï¼Œè¿™äº›é—®é¢˜éƒ½æ˜¯NPéš¾çš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12859v1">PDF</a> to be published in AAAI 2025</p>
<p><strong>Summary</strong><br>åœ¨ä¸€ä¸ªå¸¦æœ‰å¤–éƒ¨æ€§çš„è´å¶æ–¯è¯´æœé—®é¢˜ä¸­ï¼Œä¸»è¦ç ”ç©¶è€…é€šè¿‡å‘é€ä¿¡å·æ¥å‘ŠçŸ¥å¤šä¸ªä»£ç†ä¸–ç•ŒçŠ¶æ€ã€‚ç”±äºä»£ç†çš„æ•ˆç”¨å­˜åœ¨å¤–éƒ¨æ€§ï¼Œä¸»è¦ç ”ç©¶è€…ä¹Ÿä½œä¸ºä¸€ä¸ªå…³è”è®¾å¤‡æ¥å…³è”ä»£ç†çš„è¡ŒåŠ¨ã€‚åœ¨ä»£ç†è¢«åˆ†ç±»ä¸ºå°‘æ•°ç±»å‹çš„æƒ…å†µä¸‹ï¼ŒåŒä¸€ç±»å‹çš„ä»£ç†å…·æœ‰ç›¸åŒçš„æ•ˆç”¨å‡½æ•°ï¼Œå¹¶ä¸”åœ¨å…¶ä»–ä»£ç†å’Œä¸»è¦ç ”ç©¶è€…çš„æ•ˆç”¨å‡½æ•°ä¸­å…¬å¹³å¯¹å¾…ã€‚æœ¬æ–‡ä¸»è¦ç ”ç©¶äº†ä¸»è¦ç ”ç©¶è€…è®¡ç®—æœ€ä¼˜ä¿¡å·ç­–ç•¥çš„ä¸‰å¤§é—®é¢˜ï¼ŒåŒ…æ‹¬å…¬å¼€ã€ç§äººä»¥åŠåŠç§äººä¸‰ç§ä¿¡å·æ¸ é“ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå½“åç¦»ä»£ç†çš„æœ€å¤§æ•°é‡è¢«å¸¸æ•°é™åˆ¶æ—¶ï¼Œæˆ‘ä»¬çš„LPåŸºäºçš„å…¬å¼å¯ä»¥åœ¨å¤šé¡¹å¼æ—¶é—´å†…è®¡ç®—æœ€ä¼˜ä¿¡å·ç­–ç•¥ã€‚å¦åˆ™ï¼Œé—®é¢˜æ˜¯NPéš¾çš„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶äº†è´å¶æ–¯è¯´æœé—®é¢˜ä¸­çš„å¤–éƒ¨æ€§é—®é¢˜ï¼Œä¸»è¦ç ”ç©¶è€…é€šè¿‡å‘é€ä¿¡å·å‘ŠçŸ¥å¤šä¸ªä»£ç†ä¸–ç•ŒçŠ¶æ€ã€‚</li>
<li>ä¸»è¦ç ”ç©¶è€…ä½œä¸ºå…³è”è®¾å¤‡ï¼Œå…³è”ä»£ç†çš„è¡ŒåŠ¨ã€‚</li>
<li>åœ¨ä»£ç†åˆ†ç±»çš„æƒ…å†µä¸‹ï¼ŒåŒä¸€ç±»å‹ä»£ç†å…·æœ‰ç›¸åŒæ•ˆç”¨å‡½æ•°ã€‚</li>
<li>ç ”ç©¶äº†ä¸‰ç§ä¸åŒçš„ä¿¡å·æ¸ é“ï¼šå…¬å¼€ã€ç§äººä»¥åŠåŠç§äººã€‚</li>
<li>æ­ç¤ºäº†æœ€ä¼˜ä¿¡å·ç­–ç•¥çš„è®¡ç®—é—®é¢˜ï¼ŒåŒ…æ‹¬çº¿æ€§è§„åˆ’å…¬å¼å’Œé—®é¢˜çš„å¯è§£æ€§åˆ†æã€‚</li>
<li>å½“åç¦»ä»£ç†çš„æœ€å¤§æ•°é‡æœ‰é™æ—¶ï¼Œå¯ä»¥åœ¨å¤šé¡¹å¼æ—¶é—´å†…è®¡ç®—æœ€ä¼˜ä¿¡å·ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12859">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3f2541de9c28cd3fda29e15400b6dc53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1a0c3af0e6be932ce206f150bc19803.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CP-Guard-Malicious-Agent-Detection-and-Defense-in-Collaborative-Birdâ€™s-Eye-View-Perception"><a href="#CP-Guard-Malicious-Agent-Detection-and-Defense-in-Collaborative-Birdâ€™s-Eye-View-Perception" class="headerlink" title="CP-Guard: Malicious Agent Detection and Defense in Collaborative Birdâ€™s   Eye View Perception"></a>CP-Guard: Malicious Agent Detection and Defense in Collaborative Birdâ€™s   Eye View Perception</h2><p><strong>Authors:Senkang Hu, Yihang Tao, Guowen Xu, Yiqin Deng, Xianhao Chen, Yuguang Fang, Sam Kwong</strong></p>
<p>Collaborative Perception (CP) has shown a promising technique for autonomous driving, where multiple connected and autonomous vehicles (CAVs) share their perception information to enhance the overall perception performance and expand the perception range. However, in CP, ego CAV needs to receive messages from its collaborators, which makes it easy to be attacked by malicious agents. For example, a malicious agent can send harmful information to the ego CAV to mislead it. To address this critical issue, we propose a novel method, \textbf{CP-Guard}, a tailored defense mechanism for CP that can be deployed by each agent to accurately detect and eliminate malicious agents in its collaboration network. Our key idea is to enable CP to reach a consensus rather than a conflict against the ego CAVâ€™s perception results. Based on this idea, we first develop a probability-agnostic sample consensus (PASAC) method to effectively sample a subset of the collaborators and verify the consensus without prior probabilities of malicious agents. Furthermore, we define a collaborative consistency loss (CCLoss) to capture the discrepancy between the ego CAV and its collaborators, which is used as a verification criterion for consensus. Finally, we conduct extensive experiments in collaborative birdâ€™s eye view (BEV) tasks and our results demonstrate the effectiveness of our CP-Guard. </p>
<blockquote>
<p>ååŒæ„ŸçŸ¥ï¼ˆCPï¼‰ä½œä¸ºä¸€ç§è‡ªåŠ¨é©¾é©¶æŠ€æœ¯ï¼Œå±•ç°å‡ºå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚åœ¨ååŒæ„ŸçŸ¥ä¸­ï¼Œå¤šä¸ªäº’è”çš„è‡ªåŠ¨é©¾é©¶è½¦è¾†ï¼ˆCAVsï¼‰å…±äº«æ„ŸçŸ¥ä¿¡æ¯ï¼Œä»¥æé«˜æ•´ä½“çš„æ„ŸçŸ¥æ€§èƒ½å’Œæ‰©å¤§æ„ŸçŸ¥èŒƒå›´ã€‚ç„¶è€Œï¼Œåœ¨ååŒæ„ŸçŸ¥è¿‡ç¨‹ä¸­ï¼Œè‡ªæˆ‘CAVéœ€è¦ä»å…¶åˆä½œä¼™ä¼´é‚£é‡Œæ¥æ”¶ä¿¡æ¯ï¼Œè¿™ä½¿å¾—å®ƒå®¹æ˜“å—åˆ°æ¶æ„ä»£ç†çš„æ”»å‡»ã€‚ä¾‹å¦‚ï¼Œæ¶æ„ä»£ç†å¯èƒ½ä¼šå‘è‡ªæˆ‘CAVå‘é€æœ‰å®³ä¿¡æ¯ä»¥è¯¯å¯¼å®ƒã€‚ä¸ºäº†è§£å†³è¿™ä¸€å…³é”®é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•â€”â€”CPå®ˆå«è€…ï¼ˆCP-Guardï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ååŒæ„ŸçŸ¥çš„å®šåˆ¶é˜²å¾¡æœºåˆ¶ï¼Œå¯ä»¥è¢«æ¯ä¸ªä»£ç†éƒ¨ç½²ï¼Œä»¥å‡†ç¡®æ£€æµ‹å’Œæ¶ˆé™¤åˆä½œç½‘ç»œä¸­çš„æ¶æ„ä»£ç†ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ååŒæ„ŸçŸ¥èƒ½å¤Ÿè¾¾æˆå…±è¯†ï¼Œè€Œä¸æ˜¯ä¸è‡ªæˆ‘CAVçš„æ„ŸçŸ¥ç»“æœå‘ç”Ÿå†²çªã€‚åŸºäºè¿™ä¸€æ€æƒ³ï¼Œæˆ‘ä»¬é¦–å…ˆå¼€å‘äº†ä¸€ç§æ¦‚ç‡æœªçŸ¥æ ·æœ¬å…±è¯†ï¼ˆPASACï¼‰æ–¹æ³•ï¼Œä»¥æœ‰æ•ˆåœ°å¯¹åˆä½œè€…å­é›†è¿›è¡Œé‡‡æ ·ï¼Œå¹¶åœ¨ä¸çŸ¥é“æ¶æ„ä»£ç†å…ˆéªŒæ¦‚ç‡çš„æƒ…å†µä¸‹éªŒè¯å…±è¯†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåä½œä¸€è‡´æ€§æŸå¤±ï¼ˆCCLossï¼‰ï¼Œä»¥æ•æ‰è‡ªæˆ‘CAVä¸å…¶åˆä½œä¼™ä¼´ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶å°†å…¶ç”¨ä½œå…±è¯†çš„éªŒè¯æ ‡å‡†ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ååŒé¸Ÿç°ï¼ˆBEVï¼‰ä»»åŠ¡ä¸­è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œå®éªŒç»“æœè¡¨æ˜CP-Guardçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12000v1">PDF</a> Accepted by AAAIâ€™25</p>
<p><strong>Summary</strong></p>
<p>åä½œæ„ŸçŸ¥ï¼ˆCPï¼‰å·²æˆä¸ºè‡ªåŠ¨é©¾é©¶çš„ä¸€ç§æœ‰å‰é€”çš„æŠ€æœ¯ï¼Œå…¶ä¸­å¤šä¸ªäº’è”çš„è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ˆCAVsï¼‰å…±äº«å…¶æ„ŸçŸ¥ä¿¡æ¯ä»¥æé«˜æ•´ä½“çš„æ„ŸçŸ¥æ€§èƒ½å’Œæ‰©å¤§æ„ŸçŸ¥èŒƒå›´ã€‚ç„¶è€Œï¼Œåœ¨CPä¸­ï¼Œè‡ªæˆ‘CAVéœ€è¦æ¥æ”¶æ¥è‡ªåˆä½œè½¦è¾†çš„ä¿¡æ¯ï¼Œè¿™ä½¿å…¶å®¹æ˜“å—åˆ°æ¶æ„ä»£ç†çš„æ”»å‡»ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•CP-Guardï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹CPçš„å®šåˆ¶é˜²å¾¡æœºåˆ¶ï¼Œå¯ä»¥éƒ¨ç½²åœ¨æ¯ä¸ªä»£ç†ä¸Šï¼Œä»¥å‡†ç¡®æ£€æµ‹å’Œæ¶ˆé™¤åˆä½œç½‘ç»œä¸­çš„æ¶æ„ä»£ç†ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿CPè¾¾æˆä¸è‡ªæˆ‘CAVçš„æ„ŸçŸ¥ç»“æœä¸€è‡´çš„å…±è¯†ï¼Œè€Œä¸æ˜¯äº§ç”Ÿå†²çªã€‚åŸºäºè¿™ä¸€æ€æƒ³ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ¦‚ç‡æ— å…³æ ·æœ¬å…±è¯†ï¼ˆPASACï¼‰æ–¹æ³•ï¼Œå¯æœ‰æ•ˆé‡‡æ ·åˆä½œæ–¹çš„ä¸€éƒ¨åˆ†å¹¶éªŒè¯å…±è¯†ï¼Œè€Œæ— éœ€äº‹å…ˆçŸ¥é“æ¶æ„ä»£ç†çš„æ¦‚ç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªååŒä¸€è‡´æ€§æŸå¤±ï¼ˆCCLossï¼‰æ¥æ•æ‰è‡ªæˆ‘CAVä¸å…¶åˆä½œæ–¹ä¹‹é—´çš„å·®å¼‚ï¼Œç”¨ä½œå…±è¯†çš„éªŒè¯æ ‡å‡†ã€‚æœ€ç»ˆçš„å®éªŒç»“æœè¡¨æ˜CP-Guardåœ¨ååŒé¸Ÿç°è§†å›¾ï¼ˆBEVï¼‰ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åä½œæ„ŸçŸ¥ï¼ˆCPï¼‰å…è®¸å¤šä¸ªäº’è”çš„è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ˆCAVsï¼‰å…±äº«æ„ŸçŸ¥ä¿¡æ¯ï¼Œæé«˜æ„ŸçŸ¥æ€§èƒ½å’Œæ‰©å¤§æ„ŸçŸ¥èŒƒå›´ã€‚</li>
<li>CPä¸­è‡ªæˆ‘CAVåœ¨æ¥æ”¶åˆä½œè½¦è¾†ä¿¡æ¯æ—¶æ˜“å—åˆ°æ¶æ„ä»£ç†æ”»å‡»ã€‚</li>
<li>æå‡ºçš„CP-Guardæ˜¯ä¸€ç§é˜²å¾¡æœºåˆ¶ï¼Œæ—¨åœ¨å‡†ç¡®æ£€æµ‹å’Œæ¶ˆé™¤åˆä½œç½‘ç»œä¸­çš„æ¶æ„ä»£ç†ã€‚</li>
<li>CP-Guardçš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿CPè¾¾æˆä¸è‡ªæˆ‘CAVæ„ŸçŸ¥ç»“æœä¸€è‡´çš„å…±è¯†ã€‚</li>
<li>å¼€å‘äº†æ¦‚ç‡æ— å…³æ ·æœ¬å…±è¯†ï¼ˆPASACï¼‰æ–¹æ³•ï¼Œæœ‰æ•ˆé‡‡æ ·åˆä½œæ–¹å¹¶éªŒè¯å…±è¯†ã€‚</li>
<li>å®šä¹‰äº†ååŒä¸€è‡´æ€§æŸå¤±ï¼ˆCCLossï¼‰ä»¥æ•æ‰è‡ªæˆ‘CAVä¸åˆä½œè€…ä¹‹é—´çš„å·®å¼‚ï¼Œä½œä¸ºå…±è¯†éªŒè¯æ ‡å‡†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12000">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5163f6a986b3ece42483b8b916462ec1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e218951d56ad28dc5be97a7839cd94b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b695720e6b6b1e2ea4246d43db83ad02.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="LLMs-Can-Simulate-Standardized-Patients-via-Agent-Coevolution"><a href="#LLMs-Can-Simulate-Standardized-Patients-via-Agent-Coevolution" class="headerlink" title="LLMs Can Simulate Standardized Patients via Agent Coevolution"></a>LLMs Can Simulate Standardized Patients via Agent Coevolution</h2><p><strong>Authors:Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haohao Ying</strong></p>
<p>Training medical personnel using standardized patients (SPs) remains a complex challenge, requiring extensive domain expertise and role-specific practice. Most research on Large Language Model (LLM)-based simulated patients focuses on improving data retrieval accuracy or adjusting prompts through human feedback. However, this focus has overlooked the critical need for patient agents to learn a standardized presentation pattern that transforms data into human-like patient responses through unsupervised simulations. To address this gap, we propose EvoPatient, a novel simulated patient framework in which a patient agent and doctor agents simulate the diagnostic process through multi-turn dialogues, simultaneously gathering experience to improve the quality of both questions and answers, ultimately enabling human doctor training. Extensive experiments on various cases demonstrate that, by providing only overall SP requirements, our framework improves over existing reasoning methods by more than 10% in requirement alignment and better human preference, while achieving an optimal balance of resource consumption after evolving over 200 cases for 10 hours, with excellent generalizability. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/ZJUMAI/EvoPatient">https://github.com/ZJUMAI/EvoPatient</a>. </p>
<blockquote>
<p>ä½¿ç”¨æ ‡å‡†åŒ–ç—…äººï¼ˆSPsï¼‰åŸ¹è®­åŒ»åŠ¡äººå‘˜ä»ç„¶æ˜¯ä¸€ä¸ªå¤æ‚çš„æŒ‘æˆ˜ï¼Œéœ€è¦å¹¿æ³›çš„é¢†åŸŸä¸“ä¸šçŸ¥è¯†å’Œç‰¹å®šè§’è‰²çš„å®è·µã€‚å¤§å¤šæ•°å…³äºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨¡æ‹Ÿç—…äººçš„ç ”ç©¶éƒ½é›†ä¸­åœ¨æé«˜æ•°æ®æ£€ç´¢å‡†ç¡®æ€§æˆ–é€šè¿‡äººå·¥åé¦ˆè°ƒæ•´æç¤ºã€‚ç„¶è€Œï¼Œè¿™ç§å…³æ³¨å¿½è§†äº†ç—…äººä»£ç†éœ€è¦å­¦ä¹ æ ‡å‡†åŒ–è¡¨ç°æ¨¡å¼çš„å…³é”®éœ€æ±‚ï¼Œè¯¥æ¨¡å¼é€šè¿‡æ— ç›‘ç£æ¨¡æ‹Ÿå°†æ•°æ®è½¬åŒ–ä¸ºäººç±»èˆ¬çš„ç—…äººååº”ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†EvoPatientï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¨¡æ‹Ÿç—…äººæ¡†æ¶ï¼Œå…¶ä¸­ç—…äººä»£ç†å’ŒåŒ»ç”Ÿä»£ç†é€šè¿‡å¤šè½®å¯¹è¯æ¨¡æ‹Ÿè¯Šæ–­è¿‡ç¨‹ï¼ŒåŒæ—¶ç§¯ç´¯ç»éªŒä»¥æé«˜é—®é¢˜å’Œç­”æ¡ˆçš„è´¨é‡ï¼Œæœ€ç»ˆå®ç°å¯¹äººç±»åŒ»ç”Ÿçš„åŸ¹è®­ã€‚åœ¨å¤šç§ç—…ä¾‹ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä»…é€šè¿‡æä¾›æ€»ä½“SPè¦æ±‚ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨è¦æ±‚å¯¹é½å’Œæ›´å¥½çš„äººç±»åå¥½æ–¹é¢æ¯”ç°æœ‰æ¨ç†æ–¹æ³•æé«˜äº†10%ä»¥ä¸Šã€‚åœ¨è¶…è¿‡200ä¸ªç—…ä¾‹è¿›è¡Œ10å°æ—¶çš„è¿›åŒ–åï¼Œå®ç°äº†èµ„æºæ¶ˆè€—çš„ä¼˜åŒ–å¹³è¡¡ï¼Œå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/ZJUMAI/EvoPatient%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/ZJUMAI/EvoPatientä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11716v1">PDF</a> Work in Progress</p>
<p><strong>Summary</strong></p>
<p>ä½¿ç”¨æ ‡å‡†åŒ–ç—…äººï¼ˆSPsï¼‰è®­ç»ƒåŒ»ç–—äººå‘˜æ˜¯ä¸€é¡¹å¤æ‚çš„æŒ‘æˆ˜ï¼Œéœ€è¦å¹¿æ³›çš„é¢†åŸŸä¸“ä¸šçŸ¥è¯†å’Œè§’è‰²ç‰¹å®šå®è·µã€‚ç°æœ‰ç ”ç©¶å¤šå…³æ³¨æé«˜åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨¡æ‹Ÿæ‚£è€…çš„æ•°æ®æ£€ç´¢å‡†ç¡®æ€§æˆ–é€šè¿‡äººç±»åé¦ˆè°ƒæ•´æç¤ºï¼Œä½†å¿½ç•¥äº†æ‚£è€…ä»£ç†éœ€è¦å­¦ä¹ æ ‡å‡†åŒ–å‘ˆç°æ¨¡å¼çš„é‡è¦æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€ä¸è¶³ï¼Œæˆ‘ä»¬æå‡ºäº†EvoPatientæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ‚£è€…ä»£ç†å’ŒåŒ»ç”Ÿä»£ç†è¿›è¡Œå¤šè½®å¯¹è¯æ¨¡æ‹Ÿè¯Šæ–­è¿‡ç¨‹ï¼ŒåŒæ—¶ç§¯ç´¯ç»éªŒä»¥æé«˜é—®é¢˜å’Œç­”æ¡ˆçš„è´¨é‡ï¼Œæœ€ç»ˆä¸ºåŒ»ç”Ÿè®­ç»ƒæä¾›æ”¯æŒã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨ä»…æä¾›æ€»ä½“SPè¦æ±‚çš„æƒ…å†µä¸‹ï¼Œç›¸è¾ƒäºç°æœ‰æ¨ç†æ–¹æ³•ï¼Œè¦æ±‚å¯¹é½æ€§å’Œäººç±»åå¥½ä¸Šæœ‰è¶…è¿‡10%çš„æå‡ï¼Œä¸”åœ¨ç»è¿‡200ä¸ªæ¡ˆä¾‹çš„10å°æ—¶æ¼”åŒ–åå®ç°äº†èµ„æºæ¶ˆè€—çš„ä¼˜åŒ–å¹³è¡¡ï¼Œå±•ç°å‡ºè‰¯å¥½çš„é€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®­ç»ƒåŒ»ç–—äººå‘˜ä½¿ç”¨æ ‡å‡†åŒ–ç—…äººï¼ˆSPsï¼‰æ˜¯ä¸€ä¸ªéœ€è¦å¹¿æ³›é¢†åŸŸçŸ¥è¯†å’Œç‰¹å®šè§’è‰²å®è·µçš„æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦å…³æ³¨æé«˜åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨¡æ‹Ÿæ‚£è€…çš„æ•°æ®æ£€ç´¢å‡†ç¡®æ€§æˆ–è°ƒæ•´æç¤ºã€‚</li>
<li>ç°æœ‰ç ”ç©¶å¿½è§†äº†æ‚£è€…ä»£ç†éœ€è¦å­¦ä¹ æ ‡å‡†åŒ–å‘ˆç°æ¨¡å¼çš„é‡è¦æ€§ã€‚</li>
<li>EvoPatientæ¡†æ¶é€šè¿‡æ‚£è€…ä»£ç†å’ŒåŒ»ç”Ÿä»£ç†è¿›è¡Œå¤šè½®å¯¹è¯æ¨¡æ‹Ÿè¯Šæ–­è¿‡ç¨‹ã€‚</li>
<li>EvoPatientæ¡†æ¶æé«˜äº†é—®é¢˜å’Œç­”æ¡ˆçš„è´¨é‡ï¼Œä¸ºåŒ»ç”Ÿè®­ç»ƒæä¾›æ”¯æŒã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒEvoPatientæ¡†æ¶åœ¨è¦æ±‚å¯¹é½æ€§å’Œäººç±»åå¥½ä¸Šç›¸è¾ƒäºç°æœ‰æ¨ç†æ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>EvoPatientæ¡†æ¶åœ¨èµ„æºæ¶ˆè€—æ–¹é¢å®ç°äº†ä¼˜åŒ–å¹³è¡¡ï¼Œå±•ç°å‡ºè‰¯å¥½çš„é€šç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11716">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-94c43cbd40c05facd04251d40873e87c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4340e2281ad4bf4e076fcd159a90c01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9a9839c621d82dfe906ea5ec8fe17b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11b5df82809fe08cc579ceb0f3be4176.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-59ae365429419f3a52b1c84ee6283b51.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Loosely-Synchronized-Rule-Based-Planning-for-Multi-Agent-Path-Finding-with-Asynchronous-Actions"><a href="#Loosely-Synchronized-Rule-Based-Planning-for-Multi-Agent-Path-Finding-with-Asynchronous-Actions" class="headerlink" title="Loosely Synchronized Rule-Based Planning for Multi-Agent Path Finding   with Asynchronous Actions"></a>Loosely Synchronized Rule-Based Planning for Multi-Agent Path Finding   with Asynchronous Actions</h2><p><strong>Authors:Shuai Zhou, Shizhe Zhao, Zhongqiang Ren</strong></p>
<p>Multi-Agent Path Finding (MAPF) seeks collision-free paths for multiple agents from their respective starting locations to their respective goal locations while minimizing path costs. Although many MAPF algorithms were developed and can handle up to thousands of agents, they usually rely on the assumption that each action of the agent takes a time unit, and the actions of all agents are synchronized in a sense that the actions of agents start at the same discrete time step, which may limit their use in practice. Only a few algorithms were developed to address asynchronous actions, and they all lie on one end of the spectrum, focusing on finding optimal solutions with limited scalability. This paper develops new planners that lie on the other end of the spectrum, trading off solution quality for scalability, by finding an unbounded sub-optimal solution for many agents. Our method leverages both search methods (LSS) in handling asynchronous actions and rule-based planning methods (PIBT) for MAPF. We analyze the properties of our method and test it against several baselines with up to 1000 agents in various maps. Given a runtime limit, our method can handle an order of magnitude more agents than the baselines with about 25% longer makespan. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è·¯å¾„å¯»æ‰¾ï¼ˆMAPFï¼‰æ—¨åœ¨ä¸ºå¤šä¸ªæ™ºèƒ½ä½“ä»å„è‡ªçš„èµ·å§‹ä½ç½®åˆ°å„è‡ªçš„ç›®æ ‡ä½ç½®å¯»æ‰¾æ— ç¢°æ’è·¯å¾„ï¼ŒåŒæ—¶æœ€å°åŒ–è·¯å¾„æˆæœ¬ã€‚è™½ç„¶å·²å¼€å‘äº†è®¸å¤šMAPFç®—æ³•ï¼Œå¹¶èƒ½å¤Ÿå¤„ç†é«˜è¾¾æ•°åƒä¸ªæ™ºèƒ½ä½“ï¼Œä½†å®ƒä»¬é€šå¸¸å»ºç«‹åœ¨è¿™æ ·ä¸€ä¸ªå‡è®¾ä¹‹ä¸Šï¼Œå³æ™ºèƒ½ä½“çš„æ¯ä¸ªåŠ¨ä½œéƒ½éœ€è¦ä¸€ä¸ªæ—¶é—´å•ä½ï¼Œæ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œéƒ½åœ¨åŒä¸€ç¦»æ•£æ—¶é—´æ­¥å¼€å§‹ï¼Œè¿™åœ¨å®è·µä¸­å¯èƒ½é™åˆ¶äº†å®ƒä»¬çš„ä½¿ç”¨ã€‚åªæœ‰å°‘æ•°ç®—æ³•è¢«å¼€å‘å‡ºæ¥å¤„ç†å¼‚æ­¥åŠ¨ä½œï¼Œå®ƒä»¬éƒ½é›†ä¸­åœ¨å¯»æ‰¾æœ€ä¼˜è§£ï¼Œä½†å¯æ‰©å±•æ€§æœ‰é™ã€‚æœ¬æ–‡å¼€å‘äº†æ–°çš„è§„åˆ’å™¨ï¼Œå®ƒä»¬ä½äºå…‰è°±çš„å¦ä¸€ç«¯ï¼Œé€šè¿‡ä¸ºè®¸å¤šæ™ºèƒ½ä½“æ‰¾åˆ°ä¸€ä¸ªæ— ç•Œçš„æ¬¡ä¼˜è§£æ¥æƒè¡¡è§£å†³æ–¹æ¡ˆçš„è´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†æœç´¢æ–¹æ³•ï¼ˆLSSï¼‰æ¥å¤„ç†å¼‚æ­¥åŠ¨ä½œå’ŒåŸºäºè§„åˆ™çš„è§„åˆ’æ–¹æ³•ï¼ˆPIBTï¼‰æ¥è§£å†³MAPFé—®é¢˜ã€‚æˆ‘ä»¬åˆ†æäº†æˆ‘ä»¬æ–¹æ³•çš„å±æ€§ï¼Œå¹¶åœ¨å„ç§åœ°å›¾ä¸Šä¸å‡ ä¸ªåŸºå‡†ç‚¹è¿›è¡Œäº†æµ‹è¯•ï¼Œæ¶‰åŠé«˜è¾¾1000ä¸ªæ™ºèƒ½ä½“ã€‚åœ¨ç»™å®šè¿è¡Œæ—¶é—´é™åˆ¶çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå¤„ç†çš„æ™ºèƒ½ä½“æ•°é‡æ¯”åŸºå‡†æ–¹æ³•å¤šå‡ºä¸€ä¸ªæ•°é‡çº§ï¼Œå¹¶ä¸”å…·æœ‰çº¦25%çš„æ›´é•¿çš„å®Œæˆæ—¶é—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11678v1">PDF</a> AAAI2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ï¼ˆMAPFï¼‰é—®é¢˜ï¼Œå³åœ¨è€ƒè™‘è·¯å¾„æˆæœ¬æœ€å°åŒ–çš„å‰æä¸‹ï¼Œä¸ºå¤šä¸ªæ™ºèƒ½ä½“è§„åˆ’ç¢°æ’è‡ªç”±çš„è·¯å¾„ã€‚è™½ç„¶å·²å¼€å‘è®¸å¤šMAPFç®—æ³•ï¼Œèƒ½å¤Ÿå¤„ç†å¤šè¾¾åƒä¸ªæ™ºèƒ½ä½“çš„é—®é¢˜ï¼Œä½†å®ƒä»¬é€šå¸¸å‡è®¾æ™ºèƒ½ä½“çš„æ¯ä¸ªåŠ¨ä½œéƒ½éœ€è¦ä¸€ä¸ªæ—¶é—´å•ä½ï¼Œä¸”æ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œåŒæ­¥å¼€å§‹ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å®è·µä¸­çš„åº”ç”¨ã€‚é’ˆå¯¹å¼‚æ­¥åŠ¨ä½œçš„é—®é¢˜ï¼Œæœ¬æ–‡å¼€å‘äº†æ–°çš„è§„åˆ’æ–¹æ³•ï¼Œé€šè¿‡æœç´¢æ–¹æ³•å’ŒåŸºäºè§„åˆ™çš„æ–¹æ³•ç›¸ç»“åˆæ¥è§£å†³MAPFé—®é¢˜ã€‚è¯¥æ–¹æ³•åœ¨ç‰ºç‰²ä¸€å®šè§£è´¨é‡çš„å‰æä¸‹æé«˜äº†å¯æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿåœ¨å„ç§åœ°å›¾ä¸Šå¤„ç†å¤šè¾¾åƒä¸ªæ™ºèƒ½ä½“çš„é—®é¢˜ã€‚åœ¨è¿è¡Œæ—¶é™å†…ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥å¤„ç†çš„æ™ºèƒ½ä½“æ•°é‡å¤šå‡ºä¸€ä¸ªæ•°é‡çº§ï¼Œä¸”å¹³å‡æœ€é•¿å®Œæˆæ—¶é—´ä»…å¢åŠ çº¦25%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ï¼ˆMAPFï¼‰çš„ç›®æ ‡æ˜¯è§„åˆ’å¤šä¸ªæ™ºèƒ½ä½“çš„è·¯å¾„ï¼Œç¡®ä¿ç¢°æ’è‡ªç”±å¹¶æœ€å°åŒ–è·¯å¾„æˆæœ¬ã€‚</li>
<li>ç°æœ‰MAPFç®—æ³•å¤§å¤šå‡è®¾æ™ºèƒ½ä½“çš„åŠ¨ä½œåŒæ­¥å¼€å§‹ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚</li>
<li>å¼‚æ­¥åŠ¨ä½œå¤„ç†çš„å¼‚æ­¥æ€§æ˜¯è§£å†³æ­¤é—®é¢˜çš„å…³é”®ã€‚æœ¬æ–‡é€šè¿‡ç»“åˆæœç´¢æ–¹æ³•å’ŒåŸºäºè§„åˆ™çš„æ–¹æ³•æ¥å¤„ç†å¼‚æ­¥åŠ¨ä½œå’ŒMAPFé—®é¢˜ã€‚</li>
<li>åœ¨å¤„ç†å¤§è§„æ¨¡é—®é¢˜æ—¶ï¼Œç‰ºç‰²éƒ¨åˆ†è§£è´¨é‡å¯ä»¥æé«˜ç®—æ³•çš„å¯æ‰©å±•æ€§ã€‚</li>
<li>æœ¬æ–‡å¼€å‘çš„æ–°æ–¹æ³•èƒ½å¤Ÿåœ¨å„ç§åœ°å›¾ä¸Šå¤„ç†å¤šè¾¾åƒä¸ªæ™ºèƒ½ä½“çš„é—®é¢˜ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œå…¶åœ¨è¿è¡Œæ—¶é™å†…å¯ä»¥å¤„ç†çš„æ™ºèƒ½ä½“æ•°é‡å¤šå‡ºä¸€ä¸ªæ•°é‡çº§ã€‚</li>
<li>æœ¬æ–‡æ–¹æ³•çš„å¹³å‡æœ€é•¿å®Œæˆæ—¶é—´ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ä»…å¢åŠ çº¦25%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11678">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9aa827998b3fa1e7161ea88984bdf75d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b3b1fd8b786bacc7474a3c47a8d5e3e6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3538edb599bda34cb4d5feab5368fc62.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5f9f37f08b9f0821f6a74c3d7b76f199.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df73308ca812b2c9d12d809e77f5d2e8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7d92169176de69e8526eadd07597329b.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Embodied-CoT-Distillation-From-LLM-To-Off-the-shelf-Agents"><a href="#Embodied-CoT-Distillation-From-LLM-To-Off-the-shelf-Agents" class="headerlink" title="Embodied CoT Distillation From LLM To Off-the-shelf Agents"></a>Embodied CoT Distillation From LLM To Off-the-shelf Agents</h2><p><strong>Authors:Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo</strong></p>
<p>We address the challenge of utilizing large language models (LLMs) for complex embodied tasks, in the environment where decision-making systems operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a framework for decomposing and distilling the embodied reasoning capabilities from LLMs to efficient, small language model (sLM)-based policies. In DeDer, the decision-making process of LLM-based strategies is restructured into a hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is distilled from the data that is generated through the embodied in-context learning and self-verification of an LLM, so it can produce effective rationales. The planning-policy, guided by the rationales, can render optimized plans efficiently. In turn, DeDer allows for adopting sLMs for both policies, deployed on off-the-shelf devices. Furthermore, to enhance the quality of intermediate rationales, specific to embodied tasks, we devise the embodied knowledge graph, and to generate multiple rationales timely through a single inference, we also use the contrastively prompted attention model. Our experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading language planning and distillation approaches, indicating the applicability and efficiency of sLM-based embodied policies derived through DeDer. </p>
<blockquote>
<p>æˆ‘ä»¬åº”å¯¹åœ¨å†³ç­–åˆ¶å®šç³»ç»ŸåŠæ—¶åœ¨å®¹é‡æœ‰é™ã€ç°æˆçš„è®¾å¤‡ä¸Šè¿è¡Œç¯å¢ƒä¸‹ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‰§è¡Œå¤æ‚å®ä½“ä»»åŠ¡æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†DeDeræ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»LLMä¸­åˆ†è§£å’Œæç‚¼å®ä½“æ¨ç†èƒ½åŠ›ï¼Œä»¥æ„å»ºåŸºäºé«˜æ•ˆå°å‹è¯­è¨€æ¨¡å‹ï¼ˆsLMï¼‰çš„ç­–ç•¥ã€‚åœ¨DeDerä¸­ï¼ŒåŸºäºLLMçš„ç­–ç•¥çš„å†³ç­–åˆ¶å®šè¿‡ç¨‹è¢«é‡æ„ä¸ºä¸€ä¸ªå±‚æ¬¡ç»“æ„ï¼ŒåŒ…æ‹¬æ¨ç†ç­–ç•¥å’Œè§„åˆ’ç­–ç•¥ã€‚æ¨ç†ç­–ç•¥æ˜¯ä»é€šè¿‡LLMçš„å®ä½“ä¸Šä¸‹æ–‡å­¦ä¹ å’Œè‡ªæˆ‘éªŒè¯ç”Ÿæˆçš„æ•°æ®ä¸­æç‚¼å‡ºæ¥çš„ï¼Œå› æ­¤èƒ½å¤Ÿäº§ç”Ÿæœ‰æ•ˆçš„æ¨ç†ã€‚è§„åˆ’ç­–ç•¥åœ¨æ¨ç†çš„æŒ‡å¯¼ä¸‹ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°åˆ¶å®šä¼˜åŒ–è®¡åˆ’ã€‚åè¿‡æ¥ï¼ŒDeDerå…è®¸å¯¹ä¸¤é¡¹æ”¿ç­–éƒ½é‡‡ç”¨sLMï¼Œå¹¶éƒ¨ç½²åœ¨ç°æˆçš„è®¾å¤‡ä¸Šã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜ä¸å®ä½“ä»»åŠ¡ç›¸å…³çš„ä¸­é—´æ¨ç†çš„è´¨é‡ï¼Œæˆ‘ä»¬è®¾è®¡äº†å®ä½“çŸ¥è¯†å›¾è°±ï¼Œå¹¶ä½¿ç”¨å¯¹æ¯”æç¤ºæ³¨æ„åŠ›æ¨¡å‹æ¥é€šè¿‡å•æ¬¡æ¨æ–­åŠæ—¶ç”Ÿæˆå¤šä¸ªæ¨ç†ã€‚æˆ‘ä»¬åœ¨ALFREDåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDeDerè¶…è¶Šäº†é¢†å…ˆçš„è¯­è¨€è§„åˆ’å’Œè’¸é¦æ–¹æ³•ï¼Œè¯æ˜äº†é€šè¿‡DeDerè¡ç”Ÿå‡ºçš„åŸºäºsLMçš„å®ä½“ç­–ç•¥çš„åº”ç”¨æ€§å’Œæ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11499v1">PDF</a> Accepted at ICML 2024</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§£å†³å¤æ‚å®ä½“ä»»åŠ¡é¢ä¸´çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å†³ç­–ç³»ç»Ÿéœ€åŠæ—¶åœ¨å®¹é‡æœ‰é™ã€ç°æˆçš„è®¾å¤‡ä¸Šè¿è¡Œçš„ç¯å¢ƒä¸­ã€‚æå‡ºDeDeræ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»LLMä¸­åˆ†è§£å’Œæç‚¼å®ä½“æ¨ç†èƒ½åŠ›ï¼Œè½¬åŒ–ä¸ºåŸºäºå°å‹è¯­è¨€æ¨¡å‹ï¼ˆsLMï¼‰çš„ç­–ç•¥ã€‚DeDerå°†LLMç­–ç•¥çš„å†³ç­–è¿‡ç¨‹é‡æ„ä¸ºå±‚æ¬¡ç»“æ„ï¼ŒåŒ…æ‹¬æ¨ç†ç­–ç•¥å’Œè§„åˆ’ç­–ç•¥ã€‚æ¨ç†ç­–ç•¥é€šè¿‡å®ä½“ä¸Šä¸‹æ–‡å­¦ä¹ å’ŒLLMçš„è‡ªæˆ‘éªŒè¯æ•°æ®ç”Ÿæˆè¿›è¡Œæç‚¼ï¼Œä»¥äº§ç”Ÿæœ‰æ•ˆçš„ç†ç”±ã€‚è§„åˆ’ç­–ç•¥æ ¹æ®è¿™äº›ç†ç”±å¯ä»¥é«˜æ•ˆç”Ÿæˆä¼˜åŒ–è®¡åˆ’ã€‚å› æ­¤ï¼ŒDeDerå¯é‡‡ç”¨sLMä½œä¸ºæ”¿ç­–åŸºç¡€ï¼Œéƒ¨ç½²åœ¨ç°æˆçš„è®¾å¤‡ä¸Šã€‚ä¸ºæé«˜ç‰¹å®šäºå®ä½“ä»»åŠ¡çš„ä¸­é—´ç†ç”±çš„è´¨é‡ï¼Œå¼€å‘äº†å®ä½“çŸ¥è¯†å›¾è°±ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯¹æ¯”æç¤ºæ³¨æ„åŠ›æ¨¡å‹ï¼Œå¯å®ç°å•æ¬¡æ¨æ–­ç”Ÿæˆå¤šä¸ªç†ç”±ã€‚åœ¨ALFREDåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDeDerè¶…è¶Šäº†é¢†å…ˆçš„è¯­è¨€è§„åˆ’å’Œè’¸é¦æ–¹æ³•ï¼Œè¯æ˜äº†é€šè¿‡DeDerè¡ç”Ÿçš„sLMå®ä½“æ”¿ç­–çš„é€‚ç”¨æ€§å’Œæ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeDeræ¡†æ¶è§£å†³äº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¤æ‚å®ä½“ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚</li>
<li>DeDerå¯ä»¥å°†LLMçš„å†³ç­–è¿‡ç¨‹é‡æ„ä¸ºåŒ…å«æ¨ç†ç­–ç•¥å’Œè§„åˆ’ç­–ç•¥çš„å±‚æ¬¡ç»“æ„ã€‚</li>
<li>æ¨ç†ç­–ç•¥é€šè¿‡å®ä½“ä¸Šä¸‹æ–‡å­¦ä¹ å’Œè‡ªæˆ‘éªŒè¯æ•°æ®ç”Ÿæˆè¿›è¡Œæç‚¼ã€‚</li>
<li>è§„åˆ’ç­–ç•¥åŸºäºæ¨ç†ç­–ç•¥äº§ç”Ÿçš„ç†ç”±æ¥ç”Ÿæˆä¼˜åŒ–è®¡åˆ’ã€‚</li>
<li>DeDerå…è®¸ä½¿ç”¨å°å‹è¯­è¨€æ¨¡å‹ï¼ˆsLMï¼‰ä½œä¸ºç­–ç•¥åŸºç¡€ï¼Œé€‚ç”¨äºéƒ¨ç½²åœ¨èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šã€‚</li>
<li>å¼€å‘å®ä½“çŸ¥è¯†å›¾è°±æé«˜ç‰¹å®šä»»åŠ¡çš„ä¸­é—´ç†ç”±è´¨é‡ã€‚</li>
<li>å¯¹æ¯”æç¤ºæ³¨æ„åŠ›æ¨¡å‹å¯å•æ¬¡æ¨æ–­ç”Ÿæˆå¤šä¸ªç†ç”±ï¼Œæé«˜æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11499">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a8c5a193eb68fa1cf0d4439ef4b88393.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da754b5c45620de6b5b3cbd36620f722.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9cf135a65a80debd7db5dbed20d3c61d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a84c19f3f718fb1cb23455ee4abf48d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b44f85081d7a0d654091578a9807688d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Large-Language-Model-Brained-GUI-Agents-A-Survey"><a href="#Large-Language-Model-Brained-GUI-Agents-A-Survey" class="headerlink" title="Large Language Model-Brained GUI Agents: A Survey"></a>Large Language Model-Brained GUI Agents: A Survey</h2><p><strong>Authors:Chaoyun Zhang, Shilin He, Jiaxu Qian, Bowen Li, Liqun Li, Si Qin, Yu Kang, Minghua Ma, Guyue Liu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</strong></p>
<p>GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing. This has paved the way for a new generation of LLM-brained GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry.   To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-brained GUI agents, exploring their historical evolution, core components, and advanced techniques. We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-brained GUI agents. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIsï¼‰é•¿æœŸä»¥æ¥åœ¨äººæœºäº¤äº’ä¸­å æ®æ ¸å¿ƒåœ°ä½ï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ç§ç›´è§‚ä¸”è§†è§‰é©±åŠ¨çš„æ–¹å¼æ¥è®¿é—®å’Œä¸æ•°å­—ç³»ç»Ÿè¿›è¡Œäº¤äº’ã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œå·²ç»å¼€å¯äº†GUIè‡ªåŠ¨åŒ–çš„æ–°æ—¶ä»£ã€‚å®ƒä»¬åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ä»£ç ç”Ÿæˆå’Œè§†è§‰å¤„ç†æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚è¿™ä¸ºæ–°ä¸€ä»£åŸºäºLLMçš„GUIä»£ç†é“ºå¹³äº†é“è·¯ï¼Œè¿™äº›ä»£ç†èƒ½å¤Ÿè§£é‡Šå¤æ‚çš„GUIå…ƒç´ å¹¶åŸºäºè‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚è¿™äº›ä»£ç†ä»£è¡¨äº†èŒƒå¼è½¬å˜ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ç®€å•çš„å¯¹è¯å‘½ä»¤æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚å®ƒä»¬çš„åº”ç”¨ç¨‹åºè·¨è¶Šç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ï¼Œæä¾›å˜é©æ€§çš„ç”¨æˆ·ä½“éªŒï¼Œå½»åº•æ”¹å˜ä¸ªäººä¸è½¯ä»¶çš„äº¤äº’æ–¹å¼ã€‚è¿™ä¸ªæ–°å…´é¢†åŸŸæ­£åœ¨è¿…é€Ÿå‘å±•ï¼Œåœ¨ç ”ç©¶å’Œå·¥ä¸šæ–¹é¢éƒ½å–å¾—äº†é‡å¤§è¿›å±•ã€‚ä¸ºäº†å¯¹è¿™ä¸€è¶‹åŠ¿è¿›è¡Œç»“æ„åŒ–ç†è§£ï¼Œæœ¬æ–‡å…¨é¢æ¦‚è¿°äº†åŸºäºLLMçš„GUIä»£ç†ï¼Œæ¢ç´¢äº†å…¶å†å²æ¼”å˜ã€æ ¸å¿ƒç»„ä»¶å’Œå…ˆè¿›æŠ€æœ¯ã€‚æˆ‘ä»¬è§£ç­”äº†è¯¸å¦‚ç°æœ‰GUIä»£ç†æ¡†æ¶ã€æ”¶é›†å’Œåˆ©ç”¨æ•°æ®æ¥è®­ç»ƒä¸“ä¸šGUIä»£ç†ã€é’ˆå¯¹GUIä»»åŠ¡å¼€å‘çš„å¤§å‹åŠ¨ä½œæ¨¡å‹çš„å¼€å‘ã€ä»¥åŠè¯„ä¼°å…¶æœ‰æ•ˆæ€§çš„è¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æµ‹è¯•ç­‰ç ”ç©¶é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä»‹ç»äº†è¿™äº›ä»£ç†æ¨åŠ¨çš„æ–°å…´åº”ç”¨ã€‚é€šè¿‡è¯¦ç»†åˆ†æï¼Œè¿™ç¯‡ç»¼è¿°ç¡®å®šäº†å…³é”®çš„ç ”ç©¶ç©ºç™½ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥è¿›æ­¥åˆ¶å®šäº†è·¯çº¿å›¾ã€‚é€šè¿‡æ•´åˆåŸºç¡€çŸ¥è¯†å’Œæœ€æ–°å‘å±•ï¼Œè¿™é¡¹å·¥ä½œæ—¨åœ¨æŒ‡å¯¼ç ”ç©¶è€…å’Œå®è·µè€…å…‹æœæŒ‘æˆ˜ï¼Œå‘æŒ¥åŸºäºLLMçš„GUIä»£ç†çš„å…¨éƒ¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18279v4">PDF</a> The collection of papers reviewed in this survey will be hosted and   regularly updated on the GitHub repository:   <a target="_blank" rel="noopener" href="https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey">https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey</a> Additionally, a   searchable webpage is available at <a target="_blank" rel="noopener" href="https://aka.ms/gui-agent">https://aka.ms/gui-agent</a> for easier access   and exploration</p>
<p><strong>Summary</strong></p>
<p>éšç€GUIåœ¨äººç±»è®¡ç®—æœºäº¤äº’ä¸­çš„æ ¸å¿ƒåœ°ä½æ—¥ç›Šå‡¸æ˜¾ï¼Œå¤šæ¨¡æ€æ¨¡å‹ç­‰LLMæŠ€æœ¯çš„å‡ºç°ä¸ºGUIè‡ªåŠ¨åŒ–å¼€å¯äº†æ–°çºªå…ƒã€‚LLMæŠ€æœ¯åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ä»£ç ç”Ÿæˆå’Œè§†è§‰å¤„ç†æ–¹é¢çš„å“è¶Šèƒ½åŠ›ï¼Œä¸ºæ–°ä¸€ä»£LLMé©±åŠ¨çš„GUIä»£ç†æä¾›äº†å¯èƒ½ã€‚è¿™äº›ä»£ç†èƒ½å¤Ÿè§£é‡Šå¤æ‚çš„GUIå…ƒç´ ï¼Œå¹¶æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚å®ƒä»¬ä»£è¡¨äº†ç”¨æˆ·ä½“éªŒçš„èŒƒå¼è½¬å˜ï¼Œé€šè¿‡ç®€å•çš„å¯¹è¯å‘½ä»¤å®Œæˆå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚æœ¬è®ºæ–‡æä¾›äº†å…³äºLLMé©±åŠ¨çš„GUIä»£ç†çš„å…¨é¢äº†è§£ï¼ŒåŒ…æ‹¬å†å²æ¼”å˜ã€æ ¸å¿ƒç»„ä»¶å’Œé«˜çº§æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢è®¨äº†ç°æœ‰çš„GUIä»£ç†æ¡†æ¶ã€æ•°æ®æ”¶é›†å’Œåˆ©ç”¨ã€é’ˆå¯¹GUIä»»åŠ¡çš„è¡ŒåŠ¨æ¨¡å‹å¼€å‘ç­‰è®®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsæ¨åŠ¨äº†GUIä»£ç†çš„è¿›åŒ–ï¼šæ–°ä¸€ä»£ä»£ç†é›†æˆäº†å¤šæ¨¡æ€æŠ€æœ¯ï¼Œå®ç°äº†åŸºäºè‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„å¤æ‚ä»»åŠ¡è‡ªåŠ¨åŒ–æ‰§è¡Œã€‚</li>
<li>GUIä»£ç†ä»£è¡¨äº†ç”¨æˆ·ä½“éªŒçš„èŒƒå¼è½¬å˜ï¼šç”¨æˆ·å¯é€šè¿‡ç®€å•çš„å¯¹è¯å‘½ä»¤å®Œæˆå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚</li>
<li>LLMé©±åŠ¨çš„GUIä»£ç†åº”ç”¨èŒƒå›´å¹¿æ³›ï¼šåŒ…æ‹¬ç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ç­‰ã€‚</li>
<li>è®ºæ–‡å…¨é¢æ¦‚è¿°äº†LLMé©±åŠ¨çš„GUIä»£ç†çš„å‘å±•ï¼šåŒ…æ‹¬å†å²æ¼”å˜ã€æ ¸å¿ƒç»„ä»¶å’Œé«˜çº§æŠ€æœ¯ã€‚</li>
<li>è®ºæ–‡æ¢è®¨äº†ç°æœ‰GUIä»£ç†æ¡†æ¶å’Œæ•°æ®æ”¶é›†ä¸åˆ©ç”¨çš„é—®é¢˜ï¼Œå¹¶è®¨è®ºäº†é’ˆå¯¹GUIä»»åŠ¡çš„è¡ŒåŠ¨æ¨¡å‹å¼€å‘çš„é‡è¦æ€§ã€‚</li>
<li>è®ºæ–‡å¼ºè°ƒäº†è¯„ä¼°è¿™äº›ä»£ç†çš„æœ‰æ•ˆæ€§çš„å¿…è¦æ€§å’Œç›¸å…³æŒ‡æ ‡ï¼šæŒ‡å‡ºäº†éœ€è¦æ€æ ·çš„è¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°è¿™äº›ä»£ç†çš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18279">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-04a0adbe7f062000924acf78b8d025e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e6a4be3fb98a0b63af42b7b053140fa6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2c66a381c09ab1a7656345b87f2c3952.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ff2f9194ea9b361fc79cc5d28a051b8e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f015afe26577de227ef494148ee5c0c.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="A-More-Advanced-Group-Polarization-Measurement-Approach-Based-on-LLM-Based-Agents-and-Graphs"><a href="#A-More-Advanced-Group-Polarization-Measurement-Approach-Based-on-LLM-Based-Agents-and-Graphs" class="headerlink" title="A More Advanced Group Polarization Measurement Approach Based on   LLM-Based Agents and Graphs"></a>A More Advanced Group Polarization Measurement Approach Based on   LLM-Based Agents and Graphs</h2><p><strong>Authors:Zixin Liu, Ji Zhang, Yiran Ding</strong></p>
<p>Group polarization is an important research direction in social media content analysis, attracting many researchers to explore this field. Therefore, how to effectively measure group polarization has become a critical topic. Measuring group polarization on social media presents several challenges that have not yet been addressed by existing solutions. First, social media group polarization measurement involves processing vast amounts of text, which poses a significant challenge for information extraction. Second, social media texts often contain hard-to-understand content, including sarcasm, memes, and internet slang. Additionally, group polarization research focuses on holistic analysis, while texts is typically fragmented. To address these challenges, we designed a solution based on a multi-agent system and used a graph-structured Community Sentiment Network (CSN) to represent polarization states. Furthermore, we developed a metric called Community Opposition Index (COI) based on the CSN to quantify polarization. Finally, we tested our multi-agent system through a zero-shot stance detection task and achieved outstanding results. In summary, the proposed approach has significant value in terms of usability, accuracy, and interpretability. </p>
<blockquote>
<p>ç¾¤ä½“æåŒ–æ˜¯ç¤¾ä¼šåª’ä½“å†…å®¹åˆ†æçš„é‡è¦ç ”ç©¶æ–¹å‘ï¼Œå¸å¼•äº†ä¼—å¤šç ”ç©¶è€…æ¢ç´¢è¯¥é¢†åŸŸã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°è¡¡é‡ç¾¤ä½“æåŒ–æˆä¸ºäº†ä¸€ä¸ªå…³é”®è¯é¢˜ã€‚åœ¨ç¤¾äº¤åª’ä½“ä¸Šè¡¡é‡ç¾¤ä½“æåŒ–é¢ä¸´ç€ä¸€äº›æŒ‘æˆ˜ï¼Œè€Œç°æœ‰è§£å†³æ–¹æ¡ˆå°šæœªè§£å†³è¿™äº›æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œç¤¾äº¤åª’ä½“ç¾¤ä½“æåŒ–çš„è¡¡é‡éœ€è¦å¤„ç†å¤§é‡çš„æ–‡æœ¬ï¼Œè¿™å¯¹ä¿¡æ¯æå–æå‡ºäº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚å…¶æ¬¡ï¼Œç¤¾äº¤åª’ä½“æ–‡æœ¬å¾€å¾€åŒ…å«éš¾ä»¥ç†è§£çš„å†…å®¹ï¼ŒåŒ…æ‹¬è®½åˆºã€è¡¨æƒ…åŒ…å’Œç½‘ç»œä¿šè¯­ã€‚æ­¤å¤–ï¼Œç¾¤ä½“æåŒ–ç ”ç©¶ä¾§é‡äºæ•´ä½“åˆ†æï¼Œè€Œæ–‡æœ¬é€šå¸¸æ˜¯é›¶ç¢çš„ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“çš„ç³»ç»Ÿè§£å†³æ–¹æ¡ˆï¼Œå¹¶ä½¿ç”¨å›¾ç»“æ„çš„ç¤¾åŒºæƒ…æ„Ÿç½‘ç»œï¼ˆCSNï¼‰æ¥è¡¨ç¤ºæåŒ–çŠ¶æ€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºCSNå¼€å‘äº†ä¸€ä¸ªåä¸ºç¤¾åŒºåå¯¹æŒ‡æ•°ï¼ˆCOIï¼‰çš„æŒ‡æ ‡æ¥é‡åŒ–æåŒ–ç¨‹åº¦ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡é›¶èµ·ç‚¹ç«‹åœºæ£€æµ‹ä»»åŠ¡æµ‹è¯•äº†æˆ‘ä»¬çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¹¶è·å¾—äº†å‡ºè‰²çš„ç»“æœã€‚æ€»ä¹‹ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å¯ç”¨æ€§ã€å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢å…·æœ‰é‡è¦çš„ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.12196v2">PDF</a> </p>
<p><strong>Summary</strong><br>ç¤¾äº¤åª’ä½“ç¾¤ä½“æåŒ–ç°è±¡çš„æµ‹é‡æ˜¯ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æçš„é‡è¦ç ”ç©¶æ–¹å‘ã€‚å­˜åœ¨æ–‡æœ¬å¤„ç†é‡å¤§ã€æ–‡æœ¬å†…å®¹éš¾ä»¥ç†è§£ä»¥åŠæ–‡æœ¬ç¢ç‰‡åŒ–ç­‰é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºå¤šAgentç³»ç»Ÿçš„è§£å†³æ–¹æ¡ˆï¼Œé‡‡ç”¨ç¤¾åŒºæƒ…æ„Ÿç½‘ç»œï¼ˆCSNï¼‰è¡¨ç¤ºç¾¤ä½“æåŒ–çŠ¶æ€ï¼Œå¹¶åŸºäºCSNæ„å»ºç¤¾åŒºåå¯¹æŒ‡æ•°ï¼ˆCOIï¼‰æ¥é‡åŒ–ç¾¤ä½“æåŒ–ç¨‹åº¦ã€‚è¯¥æ–¹æ¡ˆå…·æœ‰æ˜“ç”¨æ€§ã€å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ç­‰ä¼˜ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¤¾äº¤åª’ä½“ç¾¤ä½“æåŒ–ç°è±¡æµ‹é‡æ˜¯ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æçš„é‡è¦æ–¹å‘ã€‚</li>
<li>ç¤¾äº¤åª’ä½“ç¾¤ä½“æåŒ–æµ‹é‡é¢ä¸´æ–‡æœ¬å¤„ç†é‡å¤§ã€å†…å®¹éš¾ä»¥ç†è§£å’Œæ–‡æœ¬ç¢ç‰‡åŒ–ç­‰æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†åŸºäºå¤šAgentç³»ç»Ÿçš„è§£å†³æ–¹æ¡ˆæ¥å¤„ç†ç¤¾äº¤åª’ä½“ç¾¤ä½“æåŒ–é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨ç¤¾åŒºæƒ…æ„Ÿç½‘ç»œï¼ˆCSNï¼‰è¡¨ç¤ºç¾¤ä½“æåŒ–çŠ¶æ€ã€‚</li>
<li>æ„å»ºç¤¾åŒºåå¯¹æŒ‡æ•°ï¼ˆCOIï¼‰æ¥é‡åŒ–ç¾¤ä½“æåŒ–ç¨‹åº¦ã€‚</li>
<li>é€šè¿‡é›¶æ ·æœ¬ç«‹åœºæ£€æµ‹ä»»åŠ¡æµ‹è¯•äº†å¤šAgentç³»ç»Ÿæ–¹æ¡ˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.12196">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f22e7ae6f9e4e8e35ba99b44e1d76210.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33e9161ba6fee03a453e97a2aff02bd2.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Adsorb-Agent-Autonomous-Identification-of-Stable-Adsorption-Configurations-via-Large-Language-Model-Agent"><a href="#Adsorb-Agent-Autonomous-Identification-of-Stable-Adsorption-Configurations-via-Large-Language-Model-Agent" class="headerlink" title="Adsorb-Agent: Autonomous Identification of Stable Adsorption   Configurations via Large Language Model Agent"></a>Adsorb-Agent: Autonomous Identification of Stable Adsorption   Configurations via Large Language Model Agent</h2><p><strong>Authors:Janghoon Ock, Tirtha Vinchurkar, Yayati Jadhav, Amir Barati Farimani</strong></p>
<p>Adsorption energy is a key reactivity descriptor in catalysis, enabling efficient screening for optimal catalysts. However, determining adsorption energy typically requires evaluating numerous adsorbate-catalyst configurations. Current algorithmic approaches rely on exhaustive enumeration of adsorption sites and configurations, which makes the process computationally intensive and does not inherently guarantee the identification of the global minimum energy. In this work, we introduce Adsorb-Agent, a Large Language Model (LLM) agent designed to efficiently identify system-specific stable adsorption configurations corresponding to the global minimum adsorption energy. Adsorb-Agent leverages its built-in knowledge and emergent reasoning capabilities to strategically explore adsorption configurations likely to hold adsorption energy. By reducing the reliance on exhaustive sampling, it significantly decreases the number of initial configurations required while improving the accuracy of adsorption energy predictions. We evaluate Adsorb-Agentâ€™s performance across twenty representative systems encompassing a range of complexities. The Adsorb-Agent successfully identifies comparable adsorption energies for 83.7% of the systems and achieves lower energies, closer to the actual global minimum, for 35% of the systems, while requiring significantly fewer initial configurations than conventional methods. Its capability is particularly evident in complex systems, where it identifies lower adsorption energies for 46.7% of systems involving intermetallic surfaces and 66.7% of systems with large adsorbate molecules. These results demonstrate the potential of Adsorb-Agent to accelerate catalyst discovery by reducing computational costs and improving the reliability of adsorption energy predictions. </p>
<blockquote>
<p>å¸é™„èƒ½æ˜¯å‚¬åŒ–ä¸­çš„å…³é”®ååº”æ€§æè¿°ç¬¦ï¼Œèƒ½å¤Ÿå®ç°é«˜æ•ˆç­›é€‰æœ€ä½³å‚¬åŒ–å‰‚ã€‚ç„¶è€Œï¼Œç¡®å®šå¸é™„èƒ½é€šå¸¸éœ€è¦è¯„ä¼°å¤§é‡çš„å¸é™„ç‰©-å‚¬åŒ–å‰‚æ„å‹ã€‚å½“å‰çš„ç®—æ³•æ–¹æ³•ä¾èµ–äºå¸é™„ä½ç‚¹å’Œæ„å‹çš„è¯¦å°½åˆ—ä¸¾ï¼Œè¿™ä½¿å¾—è¿‡ç¨‹è®¡ç®—å¯†é›†ï¼Œå¹¶ä¸”ä¸ä¿è¯èƒ½å›ºæœ‰åœ°è¯†åˆ«å…¨å±€æœ€ä½èƒ½é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†Adsorb-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°è¯†åˆ«ä¸å…¨å±€æœ€ä½å¸é™„èƒ½ç›¸å¯¹åº”çš„ç‰¹å®šç³»ç»Ÿç¨³å®šå¸é™„æ„å‹ã€‚Adsorb-Agentåˆ©ç”¨å…¶å†…ç½®çŸ¥è¯†å’Œæ–°å…´æ¨ç†èƒ½åŠ›æ¥æœ‰ç­–ç•¥åœ°æ¢ç´¢å¯èƒ½å«æœ‰å¸é™„èƒ½çš„å¸é™„æ„å‹ã€‚é€šè¿‡å‡å°‘å¯¹è¯¦å°½é‡‡æ ·çš„ä¾èµ–ï¼Œå®ƒåœ¨å‡å°‘æ‰€éœ€åˆå§‹æ„å‹æ•°é‡çš„åŒæ—¶ï¼Œæé«˜äº†å¸é™„èƒ½é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è¯„ä¼°äº†Adsorb-Agentåœ¨æ¶µç›–å„ç§å¤æ‚æ€§çš„äºŒåä¸ªä»£è¡¨æ€§ç³»ç»Ÿä¸Šçš„æ€§èƒ½ã€‚Adsorb-AgentæˆåŠŸåœ°ä¸º83.7%çš„ç³»ç»Ÿç¡®å®šäº†ç›¸å½“çš„å¸é™„èƒ½ï¼Œå¹¶ä¸º35%çš„ç³»ç»Ÿè¾¾åˆ°äº†æ›´æ¥è¿‘å®é™…å…¨å±€æœ€å°å€¼æ›´ä½çš„èƒ½é‡ï¼ŒåŒæ—¶æ‰€éœ€çš„åˆå§‹æ„å‹è¿œå°‘äºä¼ ç»Ÿæ–¹æ³•ã€‚åœ¨å¤æ‚ç³»ç»Ÿä¸­ï¼Œå…¶èƒ½åŠ›å°¤ä¸ºçªå‡ºï¼Œä¸ºæ¶‰åŠé‡‘å±é—´è¡¨é¢çš„46.7%çš„ç³»ç»Ÿä»¥åŠå…·æœ‰å¤§å¸é™„åˆ†å­çš„ç³»ç»Ÿçš„66.7%ç¡®å®šäº†è¾ƒä½çš„å¸é™„èƒ½ã€‚è¿™äº›ç»“æœè¯æ˜äº†Adsorb-Agentåœ¨å‡å°‘è®¡ç®—æˆæœ¬ã€æé«˜å¸é™„èƒ½é¢„æµ‹å¯é æ€§çš„è¿‡ç¨‹ä¸­åŠ é€Ÿå‚¬åŒ–å‰‚å‘ç°çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.16658v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºAdsorb-Agentçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œè¯¥ä»£ç†èƒ½å¤Ÿé«˜æ•ˆç¡®å®šç³»ç»Ÿç‰¹å®šçš„ç¨³å®šå¸é™„æ„å‹ï¼Œå¯¹åº”å…¨å±€æœ€ä½å¸é™„èƒ½ã€‚ä¸ä¼ ç»Ÿçš„ä¾èµ–è¯¦å°½é‡‡æ ·çš„æ–¹æ³•ç›¸æ¯”ï¼ŒAdsorb-Agenté€šè¿‡åˆ©ç”¨å…¶å†…ç½®çŸ¥è¯†å’Œæ–°å…´æ¨ç†èƒ½åŠ›æ¥ç­–ç•¥æ€§åœ°æ¢ç´¢å¯èƒ½çš„å¸é™„æ„å‹ï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„åˆå§‹æ„å‹æ•°é‡ï¼ŒåŒæ—¶æé«˜äº†å¯¹å¸é™„èƒ½é¢„æµ‹çš„å‡†ç¡®åº¦ã€‚åœ¨äºŒåä¸ªä»£è¡¨æ€§ç³»ç»Ÿçš„è¯„ä¼°ä¸­ï¼ŒAdsorb-AgentæˆåŠŸè¯†åˆ«å‡ºç›¸å½“å¸é™„èƒ½çš„ç³»ç»Ÿæ¯”ä¾‹è¾ƒé«˜ï¼Œå¹¶ä¸”åœ¨å¤æ‚ç³»ç»Ÿä¸­è¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAdsorb-Agentåœ¨åŠ é€Ÿå‚¬åŒ–å‰‚å‘ç°æ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œèƒ½å¤Ÿé™ä½è®¡ç®—æˆæœ¬å¹¶æé«˜å¸é™„èƒ½é¢„æµ‹çš„å¯é æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Adsorptionèƒ½é‡æ˜¯å‚¬åŒ–ä¸­çš„é‡è¦ååº”æè¿°ç¬¦ï¼Œç”¨äºç­›é€‰æœ€ä½³å‚¬åŒ–å‰‚ã€‚</li>
<li>å½“å‰ç®—æ³•æ–¹æ³•ä¾èµ–äºè¯¦å°½æšä¸¾å¸é™„ä½ç‚¹å’Œæ–¹æ³•é…ç½®ï¼Œè®¡ç®—é‡å¤§ä¸”ä¸ä¸€å®šèƒ½æ‰¾åˆ°å…¨å±€æœ€ä½èƒ½é‡ã€‚</li>
<li>Adsorb-Agentæ˜¯ä¸€ç§å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œèƒ½å¤Ÿé«˜æ•ˆç¡®å®šç³»ç»Ÿç‰¹å®šçš„ç¨³å®šå¸é™„æ„å‹ã€‚</li>
<li>Adsorb-Agentåˆ©ç”¨å†…ç½®çŸ¥è¯†å’Œæ–°å…´æ¨ç†èƒ½åŠ›ï¼Œå‡å°‘äº†å¯¹è¯¦å°½é‡‡æ ·çš„ä¾èµ–ï¼Œæé«˜äº†é¢„æµ‹å¸é™„èƒ½çš„å‡†ç¡®æ€§ã€‚</li>
<li>åœ¨äºŒåä¸ªä»£è¡¨æ€§ç³»ç»Ÿçš„è¯„ä¼°ä¸­ï¼ŒAdsorb-Agentåœ¨è¯†åˆ«å¸é™„èƒ½é‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚ç³»ç»Ÿä¸­ã€‚</li>
<li>Adsorb-AgentæˆåŠŸè¯†åˆ«å‡ºç›¸å½“å¸é™„èƒ½çš„ç³»ç»Ÿæ¯”ä¾‹è¾ƒé«˜ï¼Œå¹¶ä¸”åœ¨æŸäº›ç³»ç»Ÿä¸­å®ç°äº†æ›´æ¥è¿‘å®é™…å…¨å±€æœ€ä½çš„å¸é™„èƒ½é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.16658">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-db5b1a69c9855346614e40881ccfd84a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8124ed7832f0dd6a014fed879124467c.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MLE-bench-Evaluating-Machine-Learning-Agents-on-Machine-Learning-Engineering"><a href="#MLE-bench-Evaluating-Machine-Learning-Agents-on-Machine-Learning-Engineering" class="headerlink" title="MLE-bench: Evaluating Machine Learning Agents on Machine Learning   Engineering"></a>MLE-bench: Evaluating Machine Learning Agents on Machine Learning   Engineering</h2><p><strong>Authors:Jun Shern Chan, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, Kevin Liu, Leon Maksin, Tejal Patwardhan, Lilian Weng, Aleksander MÄ…dry</strong></p>
<p>We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering. To this end, we curate 75 ML engineering-related competitions from Kaggle, creating a diverse set of challenging tasks that test real-world ML engineering skills such as training models, preparing datasets, and running experiments. We establish human baselines for each competition using Kaggleâ€™s publicly available leaderboards. We use open-source agent scaffolds to evaluate several frontier language models on our benchmark, finding that the best-performing setupâ€“OpenAIâ€™s o1-preview with AIDE scaffoldingâ€“achieves at least the level of a Kaggle bronze medal in 16.9% of competitions. In addition to our main results, we investigate various forms of resource scaling for AI agents and the impact of contamination from pre-training. We open-source our benchmark code (github.com&#x2F;openai&#x2F;mle-bench&#x2F;) to facilitate future research in understanding the ML engineering capabilities of AI agents. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†MLE-benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¡¡é‡AIä»£ç†åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹æ–¹é¢è¡¨ç°å¦‚ä½•çš„åŸºå‡†æµ‹è¯•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä»Kaggleä¸­ç²¾å¿ƒæŒ‘é€‰äº†75åœºä¸æœºå™¨å­¦ä¹ å·¥ç¨‹ç›¸å…³çš„ç«èµ›ï¼Œåˆ›å»ºäº†ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡é›†ï¼Œè¿™äº›ä»»åŠ¡æµ‹è¯•äº†ç°å®ä¸–ç•Œä¸­æœºå™¨å­¦ä¹ å·¥ç¨‹çš„æŠ€èƒ½ï¼Œå¦‚è®­ç»ƒæ¨¡å‹ã€å‡†å¤‡æ•°æ®é›†å’Œè¿›è¡Œå®éªŒã€‚æˆ‘ä»¬ä½¿ç”¨Kaggleçš„å…¬å¼€æ’è¡Œæ¦œä¸ºæ¯ä¸ªç«èµ›åˆ¶å®šäººç±»åŸºå‡†çº¿ã€‚æˆ‘ä»¬ä½¿ç”¨å¼€æºä»£ç†è„šæ‰‹æ¶æ¥è¯„ä¼°æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸Šçš„æœ€å‰æ²¿è¯­è¨€æ¨¡å‹ï¼Œå‘ç°è¡¨ç°æœ€ä½³çš„ç»„åˆæ˜¯OpenAIçš„o1-previewä¸AIDEè„šæ‰‹æ¶ç»„åˆï¼Œåœ¨16.9%çš„ç«èµ›ä¸­è‡³å°‘è¾¾åˆ°äº†Kaggleé“œç‰Œæ°´å¹³ã€‚é™¤äº†æˆ‘ä»¬çš„ä¸»è¦ç»“æœå¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†AIä»£ç†çš„å„ç§èµ„æºæ‰©å±•å½¢å¼ä»¥åŠé¢„è®­ç»ƒä¸­çš„æ±¡æŸ“å½±å“ã€‚æˆ‘ä»¬å¼€æºæˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä»£ç ï¼ˆgithub.com&#x2F;openai&#x2F;mle-bench&#x2F;ï¼‰ï¼Œä»¥ä¿ƒè¿›æœªæ¥å¯¹AIä»£ç†çš„æœºå™¨å­¦ä¹ å·¥ç¨‹èƒ½åŠ›çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07095v4">PDF</a> 10 pages, 17 pages appendix. Equal contribution by first seven   authors, authors randomized. Corrected footnote 4. Added citation</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†MLE-benchçš„è¯ç”ŸèƒŒæ™¯åŠå…¶ä½œç”¨ï¼Œå®ƒæ˜¯ä¸€ä¸ªç”¨äºè¡¡é‡AIæœºå™¨å­¦ä¹ å·¥ç¨‹èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚é€šè¿‡ä»Kaggleæ”¶é›†çš„75ä¸ªæœºå™¨å­¦ä¹ ç«èµ›ä»»åŠ¡ï¼Œåˆ›å»ºäº†å¤šæ ·åŒ–çš„æŒ‘æˆ˜ä»»åŠ¡é›†ï¼Œæµ‹è¯•çœŸå®ä¸–ç•Œçš„æœºå™¨å­¦ä¹ å·¥ç¨‹æŠ€èƒ½ï¼Œå¦‚æ¨¡å‹è®­ç»ƒã€æ•°æ®é›†å‡†å¤‡å’Œå®éªŒè¿è¡Œç­‰ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨OpenAIçš„o1-previewä¸AIDEè„šæ‰‹æ¶çš„æœ€ä½³é…ç½®åœ¨æŸäº›ç«èµ›ä¸­è¾¾åˆ°ç”šè‡³è¶…è¶ŠKaggleé“œç‰Œé€‰æ‰‹çš„æ°´å¹³ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ¢è®¨äº†AIä»£ç†çš„å„ç§èµ„æºæ‰©å±•å½¢å¼å’Œé¢„è®­ç»ƒæ±¡æŸ“çš„å½±å“ï¼Œå¹¶å…¬å¼€äº†åŸºå‡†æµ‹è¯•ä»£ç ä»¥ä¿ƒè¿›æœªæ¥ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MLE-benchæ˜¯ç”¨äºè¡¡é‡AIæœºå™¨å­¦ä¹ å·¥ç¨‹èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å¤šæ ·åŒ–çš„æŒ‘æˆ˜ä»»åŠ¡é›†ã€‚</li>
<li>ä»Kaggleæ”¶é›†äº†75ä¸ªä¸æœºå™¨å­¦ä¹ ç›¸å…³çš„ç«èµ›ä»»åŠ¡ã€‚</li>
<li>é€šè¿‡å…¬å¼€å¯ç”¨çš„Kaggleæ’è¡Œæ¦œä¸ºç«èµ›å»ºç«‹äººç±»åŸºå‡†çº¿ã€‚</li>
<li>åˆ©ç”¨å¼€æºä»£ç†è„šæ‰‹æ¶å¯¹å‰æ²¿è¯­è¨€æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>OpenAIçš„o1-previewä¸AIDEè„šæ‰‹æ¶ç»„åˆè¡¨ç°æœ€ä½³ï¼Œåœ¨æŸäº›ç«èµ›ä¸­è¾¾åˆ°æˆ–è¶…è¶ŠKaggleé“œç‰Œé€‰æ‰‹æ°´å¹³ã€‚</li>
<li>ç ”ç©¶æ¢è®¨äº†AIä»£ç†çš„å„ç§èµ„æºæ‰©å±•å½¢å¼çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07095">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c7a8d7b5567133b81b349eb010f93edd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c30275e38a084ae99a2feb9c3b5590ab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6029a310edb0f83fd5ac9b802eb7a464.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a8ffefe1a18446049dbb08c8e36ff37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-33cf9a6a8dcd92969723a32b91587a61.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Anytime-Multi-Agent-Path-Finding-with-an-Adaptive-Delay-Based-Heuristic"><a href="#Anytime-Multi-Agent-Path-Finding-with-an-Adaptive-Delay-Based-Heuristic" class="headerlink" title="Anytime Multi-Agent Path Finding with an Adaptive Delay-Based Heuristic"></a>Anytime Multi-Agent Path Finding with an Adaptive Delay-Based Heuristic</h2><p><strong>Authors:Thomy Phan, Benran Zhang, Shao-Hung Chan, Sven Koenig</strong></p>
<p>Anytime multi-agent path finding (MAPF) is a promising approach to scalable path optimization in multi-agent systems. MAPF-LNS, based on Large Neighborhood Search (LNS), is the current state-of-the-art approach where a fast initial solution is iteratively optimized by destroying and repairing selected paths of the solution. Current MAPF-LNS variants commonly use an adaptive selection mechanism to choose among multiple destroy heuristics. However, to determine promising destroy heuristics, MAPF-LNS requires a considerable amount of exploration time. As common destroy heuristics are non-adaptive, any performance bottleneck caused by these heuristics cannot be overcome via adaptive heuristic selection alone, thus limiting the overall effectiveness of MAPF-LNS in terms of solution cost. In this paper, we propose Adaptive Delay-based Destroy-and-Repair Enhanced with Success-based Self-Learning (ADDRESS) as a single-destroy-heuristic variant of MAPF-LNS. ADDRESS applies restricted Thompson Sampling to the top-K set of the most delayed agents to select a seed agent for adaptive LNS neighborhood generation. We evaluate ADDRESS in multiple maps from the MAPF benchmark set and demonstrate cost improvements by at least 50% in large-scale scenarios with up to a thousand agents, compared with the original MAPF-LNS and other state-of-the-art methods. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è·¯å¾„å¯»æ‰¾ï¼ˆMAPFï¼‰æ˜¯ä¸€ç§åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å®ç°å¯æ‰©å±•è·¯å¾„ä¼˜åŒ–çš„æœ‰å‰é€”çš„æ–¹æ³•ã€‚åŸºäºå±€éƒ¨æœç´¢ï¼ˆLNSï¼‰çš„MAPF-LNSæ˜¯å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå®ƒé€šè¿‡ç ´åå’Œä¿®å¤è§£å†³æ–¹æ¡ˆä¸­çš„é€‰å®šè·¯å¾„æ¥å¿«é€Ÿè¿­ä»£ä¼˜åŒ–åˆå§‹è§£å†³æ–¹æ¡ˆã€‚å½“å‰çš„MAPF-LNSå˜ä½“é€šå¸¸ä½¿ç”¨è‡ªé€‚åº”é€‰æ‹©æœºåˆ¶æ¥é€‰æ‹©å¤šä¸ªç ´åå¯å‘å¼æ–¹æ³•ã€‚ç„¶è€Œï¼Œä¸ºäº†ç¡®å®šæœ‰å‰æ™¯çš„ç ´åå¯å‘å¼æ–¹æ³•ï¼ŒMAPF-LNSéœ€è¦å¤§é‡çš„æ¢ç´¢æ—¶é—´ã€‚ç”±äºå¸¸è§çš„ç ´åå¯å‘å¼æ–¹æ³•æ˜¯éè‡ªé€‚åº”çš„ï¼Œå› æ­¤ä»…é€šè¿‡è‡ªé€‚åº”å¯å‘å¼é€‰æ‹©æ— æ³•å…‹æœè¿™äº›å¯å‘å¼æ–¹æ³•é€ æˆçš„æ€§èƒ½ç“¶é¢ˆï¼Œä»è€Œé™åˆ¶äº†MAPF-LNSåœ¨è§£å†³æ–¹æ¡ˆæˆæœ¬æ–¹é¢çš„æ€»ä½“æœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè‡ªé€‚åº”å»¶è¿Ÿçš„ç ´åä¸ä¿®å¤å¢å¼ºæ–¹æ³•ï¼Œè¾…ä»¥åŸºäºæˆåŠŸçš„è‡ªæˆ‘å­¦ä¹ ï¼ˆADDRESSï¼‰ä½œä¸ºMAPF-LNSçš„å•ç ´åå¯å‘å¼å˜ä½“ã€‚ADDRESSå¯¹å»¶è¿Ÿæœ€é«˜çš„Kä¸ªæ™ºèƒ½ä½“åº”ç”¨æœ‰é™çš„Thompsoné‡‡æ ·ï¼Œä»¥é€‰æ‹©ç§å­æ™ºèƒ½ä½“ç”¨äºè‡ªé€‚åº”LNSé‚»åŸŸç”Ÿæˆã€‚æˆ‘ä»¬åœ¨MAPFåŸºå‡†æµ‹è¯•é›†çš„å¤šä¸ªåœ°å›¾ä¸­å¯¹ADDRESSè¿›è¡Œäº†è¯„ä¼°ï¼Œä¸åŸå§‹MAPF-LNSå’Œå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å¤§è§„æ¨¡åœºæ™¯ä¸­å®ç°äº†è‡³å°‘50%çš„æˆæœ¬æ”¹è¿›ï¼Œæ¶‰åŠå¤šè¾¾ä¸€åƒä¸ªæ™ºèƒ½ä½“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.02960v2">PDF</a> Accepted to AAAI 2025</p>
<p><strong>Summary</strong><br>     æœ¬è®ºæ–‡æå‡ºä¸€ç§åä¸ºADDRESSçš„å•é”€æ¯å¯å‘å¼ç­–ç•¥å˜ä½“ï¼Œç”¨äºå¤šæ™ºèƒ½ä½“è·¯å¾„ä¼˜åŒ–ã€‚ADDRESSé€šè¿‡è‡ªé€‚åº”å»¶è¿Ÿæœºåˆ¶ç»“åˆæˆåŠŸå‹è‡ªæˆ‘å­¦ä¹ æ¥æ”¹è¿›åŸºäºå¤§å‹é‚»åŸŸæœç´¢çš„MAPFç®—æ³•ï¼ˆMAPF-LNSï¼‰ã€‚åœ¨å¤šä¸ªåœ°å›¾ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œä¸åŸå§‹MAPF-LNSå’Œå…¶ä»–æœ€æ–°æ–¹æ³•ç›¸æ¯”ï¼ŒADDRESSåœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹è‡³å°‘å°†æˆæœ¬é™ä½äº†50%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.02960">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bd7faa5bd5035abd49690ec157860bc3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-67eeb7760046e166e457d143c3639666.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7cce6147a5ca8e689e5e67b47fe98351.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6e677f1134f20f835d95a8104d1ca5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-279a91fbc71ed56e24399463e368114b.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Walk-Wisely-on-Graph-Knowledge-Graph-Reasoning-with-Dual-Agents-via-Efficient-Guidance-Exploration"><a href="#Walk-Wisely-on-Graph-Knowledge-Graph-Reasoning-with-Dual-Agents-via-Efficient-Guidance-Exploration" class="headerlink" title="Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via   Efficient Guidance-Exploration"></a>Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via   Efficient Guidance-Exploration</h2><p><strong>Authors:Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou</strong></p>
<p>Recent years, multi-hop reasoning has been widely studied for knowledge graph (KG) reasoning due to its efficacy and interpretability. However, previous multi-hop reasoning approaches are subject to two primary shortcomings. First, agents struggle to learn effective and robust policies at the early phase due to sparse rewards. Second, these approaches often falter on specific datasets like sparse knowledge graphs, where agents are required to traverse lengthy reasoning paths. To address these problems, we propose a multi-hop reasoning model with dual agents based on hierarchical reinforcement learning (HRL), which is named FULORA. FULORA tackles the above reasoning challenges by eFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks on the simplified knowledge graph to provide stage-wise hints for the low-level agent walking on the original knowledge graph. In this framework, the low-level agent optimizes a value function that balances two objectives: (1) maximizing return, and (2) integrating efficient guidance from the high-level agent. Experiments conducted on three real-word knowledge graph datasets demonstrate that FULORA outperforms RL-based baselines, especially in the case of long-distance reasoning. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¤šè·³æ¨ç†ï¼ˆMulti-hop Reasoningï¼‰åœ¨çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰æ¨ç†ä¸­å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶ï¼Œå› ä¸ºå…¶æœ‰æ•ˆæ€§å’Œå¯è§£é‡Šæ€§ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„å¤šè·³æ¨ç†æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦ç¼ºç‚¹ã€‚é¦–å…ˆï¼Œç”±äºå¥–åŠ±ç¨€ç–ï¼Œæ™ºèƒ½ä½“åœ¨æ—©æœŸé˜¶æ®µå¾ˆéš¾å­¦ä¹ æœ‰æ•ˆä¸”ç¨³å¥çš„ç­–ç•¥ã€‚å…¶æ¬¡ï¼Œè¿™äº›æ–¹æ³•åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¡¨ç°ä¸ä½³ï¼Œä¾‹å¦‚ç¨€ç–çŸ¥è¯†å›¾è°±ï¼Œéœ€è¦æ™ºèƒ½ä½“éå†é•¿æ¨ç†è·¯å¾„ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåˆ†å±‚å¼ºåŒ–å­¦ä¹ ï¼ˆHRLï¼‰çš„åŒæ™ºèƒ½ä½“å¤šè·³æ¨ç†æ¨¡å‹ï¼Œå‘½åä¸ºFULORAã€‚FULORAé€šè¿‡åŒæ™ºèƒ½ä½“ä¹‹é—´çš„æœ‰æ•ˆæŒ‡å¯¼-æ¢ç´¢æ¥è§£å†³ä¸Šè¿°æ¨ç†æŒ‘æˆ˜ã€‚é«˜çº§æ™ºèƒ½ä½“åœ¨ç®€åŒ–çš„çŸ¥è¯†å›¾è°±ä¸Šè¡Œèµ°ï¼Œä¸ºåœ¨åŸå§‹çŸ¥è¯†å›¾è°±ä¸Šè¡Œèµ°çš„ä½çº§æ™ºèƒ½ä½“æä¾›é˜¶æ®µæ€§æç¤ºã€‚åœ¨æ­¤æ¡†æ¶ä¸­ï¼Œä½çº§æ™ºèƒ½ä½“ä¼˜åŒ–ä¸€ä¸ªå¹³è¡¡ä¸¤ä¸ªç›®æ ‡çš„å€¼å‡½æ•°ï¼šï¼ˆ1ï¼‰æœ€å¤§åŒ–å›æŠ¥ï¼›ï¼ˆ2ï¼‰æ•´åˆé«˜çº§æ™ºèƒ½ä½“çš„æœ‰æ•ˆæŒ‡å¯¼ã€‚åœ¨ä¸‰ä¸ªçœŸå®çŸ¥è¯†å›¾è°±æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒFULORAä¼˜äºåŸºäºRLçš„åŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶åœ¨é•¿è·ç¦»æ¨ç†çš„æƒ…å†µä¸‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.01880v4">PDF</a> Accepted by AAAI-25</p>
<p><strong>Summary</strong></p>
<p>å¤šè·³æ¨ç†æ˜¯çŸ¥è¯†å›¾è°±æ¨ç†ä¸­å¹¿æ³›ç ”ç©¶çš„ä¸»é¢˜ï¼Œä½†å…¶å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆ†å±‚å¼ºåŒ–å­¦ä¹ çš„åŒä»£ç†å¤šè·³æ¨ç†æ¨¡å‹FULORAã€‚FULORAé€šè¿‡åŒä»£ç†ä¹‹é—´çš„æœ‰æ•ˆæŒ‡å¯¼ä¸æ¢ç´¢ï¼Œè§£å†³çŸ¥è¯†å›¾è°±ä¸­çš„æ¨ç†æŒ‘æˆ˜ã€‚é«˜å±‚æ¬¡çš„ä»£ç†åœ¨ç®€åŒ–åçš„çŸ¥è¯†å›¾è°±ä¸Šè¡Œèµ°ï¼Œä¸ºä½å±‚æ¬¡çš„ä»£ç†æä¾›é˜¶æ®µæ€§æç¤ºã€‚ä½å±‚æ¬¡çš„ä»£ç†åœ¨ä¼˜åŒ–ä»·å€¼å‡½æ•°æ—¶ï¼Œå¹³è¡¡äº†æœ€å¤§åŒ–å›æŠ¥å’Œæ¥å—é«˜å±‚æ¬¡ä»£ç†çš„æœ‰æ•ˆæŒ‡å¯¼ä¸¤ä¸ªç›®æ ‡ã€‚åœ¨ä¸‰ä¸ªçœŸå®çŸ¥è¯†å›¾è°±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFULORAä¼˜äºå¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œå°¤å…¶åœ¨é•¿è·ç¦»æ¨ç†æ–¹é¢è¡¨ç°æ›´ä¼˜ç§€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šè·³æ¨ç†æ˜¯çŸ¥è¯†å›¾è°±æ¨ç†ä¸­çš„çƒ­é—¨ç ”ç©¶ä¸»é¢˜ã€‚</li>
<li>ç°æœ‰å¤šè·³æ¨ç†æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šæ—©æœŸé˜¶æ®µå¥–åŠ±ç¨€ç–å’Œç‰¹å®šæ•°æ®é›†ï¼ˆå¦‚ç¨€ç–çŸ¥è¯†å›¾è°±ï¼‰ä¸Šçš„é•¿è·¯å¾„æ¨ç†éš¾é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºåˆ†å±‚å¼ºåŒ–å­¦ä¹ çš„åŒä»£ç†å¤šè·³æ¨ç†æ¨¡å‹FULORAã€‚</li>
<li>FULORAé€šè¿‡é«˜æ•ˆæŒ‡å¯¼ä¸æ¢ç´¢è§£å†³æ¨ç†æŒ‘æˆ˜ã€‚</li>
<li>é«˜å±‚æ¬¡ä»£ç†æä¾›é˜¶æ®µæ€§æç¤ºï¼Œç®€åŒ–çŸ¥è¯†å›¾è°±çš„å¯¼èˆªã€‚</li>
<li>ä½å±‚æ¬¡ä»£ç†åœ¨ä¼˜åŒ–ä»·å€¼å‡½æ•°æ—¶ï¼Œå¹³è¡¡äº†æœ€å¤§åŒ–å›æŠ¥å’Œæ¥å—æŒ‡å¯¼çš„éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.01880">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-25bbfa66d44fb15b48890646508e299c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b9fd5e932cac6ea95741b8c5136eb6c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d61881fc8a717d99eb35bee689e82366.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-555e2a5f1d5d1214f295bb681025924c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1abbd60fbef3f589f2b7ab8e5033d37a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30bec74c2125a2f5d22907ab95b69c2d.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Quantifying-Misalignment-Between-Agents-Towards-a-Sociotechnical-Understanding-of-Alignment"><a href="#Quantifying-Misalignment-Between-Agents-Towards-a-Sociotechnical-Understanding-of-Alignment" class="headerlink" title="Quantifying Misalignment Between Agents: Towards a Sociotechnical   Understanding of Alignment"></a>Quantifying Misalignment Between Agents: Towards a Sociotechnical   Understanding of Alignment</h2><p><strong>Authors:Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen</strong></p>
<p>Existing work on the alignment problem has focused mainly on (1) qualitative descriptions of the alignment problem; (2) attempting to align AI actions with human interests by focusing on value specification and learning; and&#x2F;or (3) focusing on a single agent or on humanity as a monolith. Recent sociotechnical approaches highlight the need to understand complex misalignment among multiple human and AI agents. We address this gap by adapting a computational social science model of human contention to the alignment problem. Our model quantifies misalignment in large, diverse agent groups with potentially conflicting goals across various problem areas. Misalignment scores in our framework depend on the observed agent population, the domain in question, and conflict between agentsâ€™ weighted preferences. Through simulations, we demonstrate how our model captures intuitive aspects of misalignment across different scenarios. We then apply our model to two case studies, including an autonomous vehicle setting, showcasing its practical utility. Our approach offers enhanced explanatory power for complex sociotechnical environments and could inform the design of more aligned AI systems in real-world applications. </p>
<blockquote>
<p>å…³äºå¯¹é½é—®é¢˜çš„ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼šï¼ˆ1ï¼‰å¯¹é½é—®é¢˜çš„å®šæ€§æè¿°ï¼›ï¼ˆ2ï¼‰é€šè¿‡èšç„¦ä»·å€¼è§„èŒƒå’Œæœºå™¨å­¦ä¹ å°è¯•å°†AIè¡Œä¸ºä¸äººçš„åˆ©ç›Šè¿›è¡Œå¯¹é½ï¼›ï¼ˆ3ï¼‰ä»¥åŠå…³æ³¨å•ä¸€å®ä½“æˆ–å°†äººç±»è§†ä½œä¸€ä¸ªå•ä¸€æ•´ä½“çš„ç ”ç©¶ã€‚æœ€æ–°çš„ç¤¾ä¼šæŠ€æœ¯æ–¹æ³•å¼ºè°ƒéœ€è¦ç†è§£äººç±»å’ŒAIå®ä½“ä¹‹é—´çš„å¤æ‚é”™é…é—®é¢˜ã€‚æˆ‘ä»¬é€šè¿‡é€‚åº”äººç±»äº‰è®ºçš„è®¡ç®—ç¤¾ä¼šç§‘å­¦æ¨¡å‹æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æˆ‘ä»¬çš„æ¨¡å‹é‡åŒ–å¤§å‹ã€å¤šæ ·åŒ–çš„å®ä½“ç¾¤ä½“åœ¨ä¸åŒé—®é¢˜é¢†åŸŸçš„æ½œåœ¨å†²çªç›®æ ‡ä¸­çš„é”™é…é—®é¢˜ã€‚æˆ‘ä»¬æ¡†æ¶ä¸­çš„é”™é…åˆ†æ•°å–å†³äºè§‚å¯Ÿåˆ°çš„å®ä½“ç¾¤ä½“ã€ç›¸å…³åŸŸä»¥åŠå®ä½“åŠ æƒåå¥½ä¹‹é—´çš„å†²çªã€‚é€šè¿‡æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ¨¡å‹å¦‚ä½•åœ¨ä¸åŒåœºæ™¯ä¸­æ•æ‰åˆ°ç›´è§‚çš„é”™é…æ–¹é¢ã€‚ç„¶åæˆ‘ä»¬å°†æ¨¡å‹åº”ç”¨äºä¸¤ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼ŒåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶è½¦è¾†è®¾ç½®ï¼Œå±•ç¤ºå…¶å®ç”¨æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºå¤æ‚çš„ç¤¾æŠ€ç¯å¢ƒæä¾›äº†å¢å¼ºçš„è§£é‡Šèƒ½åŠ›ï¼Œå¹¶å¯ä»¥ä¸ºç°å®åº”ç”¨ä¸­çš„æ›´å¯¹é½AIç³»ç»Ÿçš„è®¾è®¡æä¾›ä¿¡æ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.04231v3">PDF</a> 7 pages, 8 figures, 3 tables, forthcoming at the AAAI-25 Special   Track on AI Alignment</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç€é‡è§£å†³äººå·¥æ™ºèƒ½ä¸äººç±»ç¤¾ä¼šå¤šä¸»ä½“é—´çš„å¤æ‚é”™ä½é—®é¢˜ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨é”™ä½é—®é¢˜çš„å®šæ€§æè¿°ã€é€šè¿‡ä»·å€¼ç‰¹å®šä¸å­¦ä¹ å¯¹é½AIè¡ŒåŠ¨ä¸äººç±»åˆ©ç›Šï¼Œä»¥åŠå•ä¸€ä¸»ä½“çš„ç ”ç©¶æˆ–äººç±»æ•´ä½“çš„å•ä¸€è§†è§’ã€‚è¿‘æœŸç¤¾ä¼šæŠ€æœ¯æ–¹æ³•å¼ºè°ƒç†è§£äººç±»ä¸äººå·¥æ™ºèƒ½ä¸»ä½“é—´çš„å¤æ‚é”™ä½ã€‚æœ¬æ–‡å€Ÿé‰´è®¡ç®—ç¤¾ä¼šç§‘å­¦ä¸­äººç±»äº‰ç«¯çš„æ¨¡å‹ï¼Œå¯¹é”™ä½é—®é¢˜è¿›è¡Œé‡åŒ–å¤„ç†ï¼Œå°¤å…¶é’ˆå¯¹å¤§å‹ã€å¤šå…ƒä¸”ç›®æ ‡å†²çªçš„ç¾¤ä½“ã€‚é”™ä½è¯„åˆ†å–å†³äºè§‚å¯Ÿåˆ°çš„ä¸»ä½“ç¾¤ä½“ã€ç‰¹å®šé¢†åŸŸä»¥åŠä¸»ä½“é—´å†²çªã€‚é€šè¿‡æ¨¡æ‹Ÿï¼Œå±•ç¤ºè¯¥æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹æ•æ‰é”™ä½é—®é¢˜çš„ç›´è§‚æ€§ã€‚åœ¨è‡ªåŠ¨é©¾é©¶æ±½è½¦æ¡ˆä¾‹ä¸­ï¼ŒéªŒè¯æ¨¡å‹çš„å®é™…åº”ç”¨æ•ˆç”¨ã€‚è¯¥æ¨¡å‹å¯¹äºå¤æ‚çš„ç¤¾ä¼šæŠ€æœ¯ç¯å¢ƒæ›´å…·è§£é‡ŠåŠ›ï¼Œä¸ºè®¾è®¡æ›´è´´åˆå®é™…åº”ç”¨çš„AIç³»ç»Ÿæä¾›ä¾æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰ç ”ç©¶è¶‹åŠ¿ï¼šä»‹ç»ç°æœ‰å…³äºAIä¸äººç±»ç¤¾ä¼šä¹‹é—´é”™ä½é—®é¢˜çš„ç ”ç©¶ç°çŠ¶åŠå…¶ä¸è¶³ã€‚</li>
<li>å¼•å…¥æ–°æ–¹æ³•ï¼šé‡‡ç”¨è®¡ç®—ç¤¾ä¼šç§‘å­¦æ¨¡å‹ï¼Œé‡åŒ–å¤„ç†å¤§å‹å¤šå…ƒä¸»ä½“é—´çš„å¤æ‚é”™ä½é—®é¢˜ã€‚</li>
<li>æ¨¡å‹ç‰¹ç‚¹ï¼šè€ƒè™‘è§‚å¯Ÿåˆ°çš„ä¸»ä½“ç¾¤ä½“ã€ç‰¹å®šé¢†åŸŸåŠä¸»ä½“é—´å†²çªå¯¹é”™ä½è¯„åˆ†çš„å½±å“ã€‚</li>
<li>æ¨¡æ‹Ÿæ¼”ç¤ºï¼šé€šè¿‡æ¨¡æ‹Ÿè¯æ˜æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹æ•æ‰é”™ä½é—®é¢˜çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åº”ç”¨æ¡ˆä¾‹ï¼šä»¥è‡ªåŠ¨é©¾é©¶æ±½è½¦ä¸ºä¾‹ï¼Œå±•ç¤ºæ¨¡å‹çš„å®é™…åº”ç”¨æ•ˆæœã€‚</li>
<li>æ¨¡å‹ä¼˜åŠ¿ï¼šå¯¹äºå¤æ‚çš„ç¤¾ä¼šæŠ€æœ¯ç¯å¢ƒæ›´å…·è§£é‡ŠåŠ›ï¼Œæœ‰åŠ©äºè®¾è®¡æ›´è´´åˆå®é™…åº”ç”¨çš„AIç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.04231">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fce6411152d2fd52681d4ef3b0713569.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75c86f941e361844cb112187039f6425.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3be978ba7964c8842983a40a7918738a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-449af438e8844ef56c977209a09faad3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-36b6714dabfa37d7b2c6e9513d8d8980.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-71723fa9999b8c89d853fb3f2cdbad48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62ae1d55c14f80fe186213e5dcb33859.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/MMT/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-da617ccd25a73f3719a11187f1ec454b.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  Make Imagination Clearer! Stable Diffusion-based Visual Imagination for   Multimodal Machine Translation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fc2ed00fed1f090b2b5f5376e2dbecd0.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-19  SafeAgentBench A Benchmark for Safe Task Planning of Embodied LLM   Agents
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32271.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
