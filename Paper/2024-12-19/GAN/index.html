<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GAN">
    <meta name="description" content="GAN 方向最新论文已更新，请持续关注 Update in 2024-12-19  A New Adversarial Perspective for LiDAR-based 3D Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GAN | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-9a1075a0efae11ba9ddebf78003ad364.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/GAN/">
                                <span class="chip bg-color">GAN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                GAN
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-19-更新"><a href="#2024-12-19-更新" class="headerlink" title="2024-12-19 更新"></a>2024-12-19 更新</h1><h2 id="A-New-Adversarial-Perspective-for-LiDAR-based-3D-Object-Detection"><a href="#A-New-Adversarial-Perspective-for-LiDAR-based-3D-Object-Detection" class="headerlink" title="A New Adversarial Perspective for LiDAR-based 3D Object Detection"></a>A New Adversarial Perspective for LiDAR-based 3D Object Detection</h2><p><strong>Authors:Shijun Zheng, Weiquan Liu, Yu Guo, Yu Zang, Siqi Shen, Cheng Wang</strong></p>
<p>Autonomous vehicles (AVs) rely on LiDAR sensors for environmental perception and decision-making in driving scenarios. However, ensuring the safety and reliability of AVs in complex environments remains a pressing challenge. To address this issue, we introduce a real-world dataset (ROLiD) comprising LiDAR-scanned point clouds of two random objects: water mist and smoke. In this paper, we introduce a novel adversarial perspective by proposing an attack framework that utilizes water mist and smoke to simulate environmental interference. Specifically, we propose a point cloud sequence generation method using a motion and content decomposition generative adversarial network named PCS-GAN to simulate the distribution of random objects. Furthermore, leveraging the simulated LiDAR scanning characteristics implemented with Range Image, we examine the effects of introducing random object perturbations at various positions on the target vehicle. Extensive experiments demonstrate that adversarial perturbations based on random objects effectively deceive vehicle detection and reduce the recognition rate of 3D object detection models. </p>
<blockquote>
<p>自动驾驶车辆（AVs）在驾驶场景中依赖于激光雷达传感器进行环境感知和决策。然而，在复杂环境中确保AVs的安全性和可靠性仍然是一个紧迫的挑战。为了解决这个问题，我们引入了一个真实世界数据集（ROLiD），它包括激光雷达扫描的两个随机对象的点云：水雾和烟雾。在本文中，我们通过提出一个利用水雾和烟雾模拟环境干扰的攻击框架，引入了一种新的对抗性视角。具体来说，我们提出了一种使用名为PCS-GAN的运动和内容分解生成对抗网络来点云序列生成方法，以模拟随机对象的分布。此外，借助模拟激光雷达扫描特性并通过范围图像实现，我们研究了在目标车辆的不同位置引入随机对象扰动的影响。大量实验表明，基于随机对象的对抗性扰动可以有效地欺骗车辆检测并降低3D对象检测模型的识别率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13017v1">PDF</a> 11 pages, 7 figures, AAAI2025</p>
<p><strong>Summary</strong></p>
<p>在自动驾驶车辆（AVs）的感知和决策过程中，激光雷达传感器扮演着关键角色。然而，在复杂环境下确保AVs的安全性和可靠性是一项亟待解决的挑战。为解决这一问题，本研究创建了一个真实世界数据集（ROLiD），包含了激光雷达扫描到的两种随机物体——水雾和烟雾的点云。本文提出了一种新的对抗性视角，通过构建一个攻击框架来模拟环境干扰，利用水雾和烟雾来模拟随机物体的干扰。具体来说，本研究提出了一种名为PCS-GAN的基于运动和内容的分解生成对抗网络，用于生成点云序列来模拟随机物体的分布。此外，结合模拟的激光雷达扫描特性和范围图像，本研究探讨了在不同位置引入随机物体扰动对目标车辆的影响。实验表明，基于随机物体的对抗性扰动可有效欺骗车辆检测并降低三维物体检测模型的识别率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>自动驾驶车辆（AVs）依赖激光雷达传感器进行环境感知和驾驶决策。</li>
<li>在复杂环境下确保AVs的安全性和可靠性是一大挑战。</li>
<li>创建了真实世界数据集（ROLiD），包含水雾和烟雾的点云数据。</li>
<li>提出了一种新的对抗性视角，通过模拟环境干扰来模拟随机物体的影响。</li>
<li>使用了名为PCS-GAN的生成对抗网络来模拟随机物体的分布和点云序列生成。</li>
<li>模拟实验表明，随机物体的对抗性扰动能有效欺骗车辆检测。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13017">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7e8ea71c09a29fcc8799627770f34539.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6175f94525aa963f6a1ca8d2f88f3307.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9a1075a0efae11ba9ddebf78003ad364.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c35f411ea6af5ebc688d727c1d167df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db0bbedbfdc4ba90ab6c2a25a446ccaf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22ba44e2fbf5647bbb6c6a36fe15a826.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Ensemble-Learning-and-3D-Pix2Pix-for-Comprehensive-Brain-Tumor-Analysis-in-Multimodal-MRI"><a href="#Ensemble-Learning-and-3D-Pix2Pix-for-Comprehensive-Brain-Tumor-Analysis-in-Multimodal-MRI" class="headerlink" title="Ensemble Learning and 3D Pix2Pix for Comprehensive Brain Tumor Analysis   in Multimodal MRI"></a>Ensemble Learning and 3D Pix2Pix for Comprehensive Brain Tumor Analysis   in Multimodal MRI</h2><p><strong>Authors:Ramy A. Zeineldin, Franziska Mathis-Ullrich</strong></p>
<p>Motivated by the need for advanced solutions in the segmentation and inpainting of glioma-affected brain regions in multi-modal magnetic resonance imaging (MRI), this study presents an integrated approach leveraging the strengths of ensemble learning with hybrid transformer models and convolutional neural networks (CNNs), alongside the innovative application of 3D Pix2Pix Generative Adversarial Network (GAN). Our methodology combines robust tumor segmentation capabilities, utilizing axial attention and transformer encoders for enhanced spatial relationship modeling, with the ability to synthesize biologically plausible brain tissue through 3D Pix2Pix GAN. This integrated approach addresses the BraTS 2023 cluster challenges by offering precise segmentation and realistic inpainting, tailored for diverse tumor types and sub-regions. The results demonstrate outstanding performance, evidenced by quantitative evaluations such as the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD95) for segmentation, and Structural Similarity Index Measure (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Mean-Square Error (MSE) for inpainting. Qualitative assessments further validate the high-quality, clinically relevant outputs. In conclusion, this study underscores the potential of combining advanced machine learning techniques for comprehensive brain tumor analysis, promising significant advancements in clinical decision-making and patient care within the realm of medical imaging. </p>
<blockquote>
<p>针对多模态磁共振成像（MRI）中胶质母细胞瘤受影响脑区的分割和修复需求，本研究提出了一种结合集成学习、混合变压器模型和卷积神经网络（CNN）优势的综合方法，并创新性地应用了3D Pix2Pix生成对抗网络（GAN）。我们的方法结合了强大的肿瘤分割能力，利用轴向注意力和变压器编码器进行增强的空间关系建模，以及通过3D Pix2Pix GAN合成生物上合理的脑组织的能力。这一综合方法通过提供精确的分割和逼真的修复，解决了BraTS 2023集群挑战，适用于多种肿瘤类型和子区域。结果表现出色，通过定量评估（如Dice相似系数（DSC）、Hausdorff距离（HD95）进行分割评估，以及结构相似性指数度量（SSIM）、峰值信噪比（PSNR）和均方误差（MSE）进行修复评估）证明了其性能。定性评估进一步验证了其高质量、临床相关的输出。总之，本研究强调了结合先进机器学习技术进行全面的脑肿瘤分析潜力，有望在医学成像领域的临床决策和患者护理中取得重大进展。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11849v1">PDF</a> Accepted at the MICCAI BraTS Challenge 2023</p>
<p><strong>Summary</strong>：<br>本研究针对多模态磁共振成像（MRI）中胶质瘤影响的大脑区域分割和修复的需求，提出了一种结合集成学习、混合变压器模型、卷积神经网络（CNN）和3D Pix2Pix生成对抗网络（GAN）的集成方法。该方法不仅利用轴向注意力和变压器编码器进行精确肿瘤分割，而且通过3D Pix2Pix GAN合成生物上合理的大脑组织。该研究为BraTS 2023集群挑战提供了精确的分割和逼真的修复，针对各种肿瘤类型和子区域进行定制，显示出优异的性能。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>本研究提出了一种结合多种先进机器学习技术的集成方法，用于分割和修复多模态MRI中的胶质瘤影响区域。</li>
<li>利用集成学习、混合变压器模型、CNN和3D Pix2Pix GAN等技术，提高了肿瘤分割的精确性和修复的真实感。</li>
<li>通过轴向注意力和变压器编码器增强空间关系建模，提高了肿瘤分割的鲁棒性。</li>
<li>定量评估结果，如Dice相似系数（DSC）、Hausdorff距离（HD95）等，显示了该方法在分割方面的出色性能。</li>
<li>对于修复效果的评估指标，如结构相似性指数度量（SSIM）、峰值信噪比（PSNR）和均方误差（MSE），验证了输出的高质量和临床相关性。</li>
<li>该方法针对BraTS 2023集群挑战提供了解决方案，适用于不同类型的肿瘤和子区域的分割和修复。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11849">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-e9825be7cab399ba7264ffc74af4c493.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73ce182a270e64f920ec72e4f611d254.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Adapting-Segment-Anything-Model-SAM-to-Experimental-Datasets-via-Fine-Tuning-on-GAN-based-Simulation-A-Case-Study-in-Additive-Manufacturing"><a href="#Adapting-Segment-Anything-Model-SAM-to-Experimental-Datasets-via-Fine-Tuning-on-GAN-based-Simulation-A-Case-Study-in-Additive-Manufacturing" class="headerlink" title="Adapting Segment Anything Model (SAM) to Experimental Datasets via   Fine-Tuning on GAN-based Simulation: A Case Study in Additive Manufacturing"></a>Adapting Segment Anything Model (SAM) to Experimental Datasets via   Fine-Tuning on GAN-based Simulation: A Case Study in Additive Manufacturing</h2><p><strong>Authors:Anika Tabassum, Amirkoushyar Ziabari</strong></p>
<p>Industrial X-ray computed tomography (XCT) is a powerful tool for non-destructive characterization of materials and manufactured components. XCT commonly accompanied by advanced image analysis and computer vision algorithms to extract relevant information from the images. Traditional computer vision models often struggle due to noise, resolution variability, and complex internal structures, particularly in scientific imaging applications. State-of-the-art foundational models, like the Segment Anything Model (SAM)-designed for general-purpose image segmentation-have revolutionized image segmentation across various domains, yet their application in specialized fields like materials science remains under-explored. In this work, we explore the application and limitations of SAM for industrial X-ray CT inspection of additive manufacturing components. We demonstrate that while SAM shows promise, it struggles with out-of-distribution data, multiclass segmentation, and computational efficiency during fine-tuning. To address these issues, we propose a fine-tuning strategy utilizing parameter-efficient techniques, specifically Conv-LoRa, to adapt SAM for material-specific datasets. Additionally, we leverage generative adversarial network (GAN)-generated data to enhance the training process and improve the model’s segmentation performance on complex X-ray CT data. Our experimental results highlight the importance of tailored segmentation models for accurate inspection, showing that fine-tuning SAM on domain-specific scientific imaging data significantly improves performance. However, despite improvements, the model’s ability to generalize across diverse datasets remains limited, highlighting the need for further research into robust, scalable solutions for domain-specific segmentation tasks. </p>
<blockquote>
<p>工业X射线计算机断层扫描（XCT）是非破坏性表征材料和制造部件的强大工具。XCT通常与先进的图像分析和计算机视觉算法相结合，从图像中提取相关信息。传统计算机视觉模型由于噪声、分辨率变化和复杂内部结构的影响而常常表现挣扎，特别是在科学成像应用中。最新的基础模型，如用于通用图像分割的Segment Anything Model（SAM）已经彻底改变了各种领域的图像分割，但其在材料科学等特定领域的应用仍然被探索不足。在这项工作中，我们探索了SAM在增材制造部件的工业X射线CT检测中的应用和局限性。我们证明，虽然SAM显示出潜力，但在处理分布外数据、多类分割和微调过程中的计算效率方面存在挑战。为了解决这些问题，我们提出了一种利用参数高效技术的微调策略，特别是Conv-LoRa，以适应特定材料的数据集。此外，我们还利用生成对抗网络（GAN）生成的数据来增强训练过程，提高模型在复杂X射线CT数据上的分割性能。我们的实验结果强调了为准确检查量身定制分割模型的重要性，并表明在特定领域的科学成像数据上微调SAM可以显著提高性能。然而，尽管有所改进，该模型在不同数据集上的泛化能力仍然有限，这突显了需要进一步研究用于特定领域分割任务的稳健、可扩展解决方案的必要性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11381v1">PDF</a> </p>
<p><strong>Summary</strong>：本文探讨了将Segment Anything Model（SAM）应用于工业X射线计算机断层扫描（XCT）检测增材制造部件的潜力与局限性。研究发现，虽然SAM模型显示出一定的潜力，但在处理离群数据、多类别分割和计算效率方面存在挑战。为解决这些问题，研究人员提出了一种利用Conv-LoRa技术的精细调整策略，并借助生成对抗网络（GAN）生成的数据增强训练过程，以提高模型在复杂X射线CT数据上的分割性能。实验结果表明，针对特定领域的科学成像数据对SAM进行微调可显著提高性能，但模型的泛化能力仍有待提高，需要进一步研究具有针对性的稳健解决方案。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>工业X射线计算机断层扫描（XCT）是材料和非破坏性检测的重要工具，常与先进的图像分析和计算机视觉算法相结合提取信息。</li>
<li>传统计算机视觉模型在处理噪声、分辨率变化和复杂内部结构方面存在困难，特别是在科学成像应用中。</li>
<li>Segment Anything Model（SAM）在各个领域的图像分割中取得了革命性的进展，但在材料科学等特定领域的应用仍待探索。</li>
<li>SAM在处理离群数据、多类别分割和计算效率方面存在挑战。</li>
<li>通过利用Conv-LoRa技术的精细调整策略和生成对抗网络（GAN）生成的数据，增强了模型在复杂X射线CT数据上的分割性能。</li>
<li>实验结果指出针对特定领域的科学成像数据对SAM进行微调的重要性，可显著提高性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11381">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-68869de46c0cdb7e886a40641ab951d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-732024ecc4fba477e7740c4dac3ffab1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0dbbc6e53d60f16b7772eeb25fe38a3a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-32c059254fe838a182067649ce3ecdf8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="StyleDiT-A-Unified-Framework-for-Diverse-Child-and-Partner-Faces-Synthesis-with-Style-Latent-Diffusion-Transformer"><a href="#StyleDiT-A-Unified-Framework-for-Diverse-Child-and-Partner-Faces-Synthesis-with-Style-Latent-Diffusion-Transformer" class="headerlink" title="StyleDiT: A Unified Framework for Diverse Child and Partner Faces   Synthesis with Style Latent Diffusion Transformer"></a>StyleDiT: A Unified Framework for Diverse Child and Partner Faces   Synthesis with Style Latent Diffusion Transformer</h2><p><strong>Authors:Pin-Yen Chiu, Dai-Jie Wu, Po-Hsun Chu, Chia-Hsuan Hsu, Hsiang-Chen Chiu, Chih-Yu Wang, Jun-Cheng Chen</strong></p>
<p>Kinship face synthesis is a challenging problem due to the scarcity and low quality of the available kinship data. Existing methods often struggle to generate descendants with both high diversity and fidelity while precisely controlling facial attributes such as age and gender. To address these issues, we propose the Style Latent Diffusion Transformer (StyleDiT), a novel framework that integrates the strengths of StyleGAN with the diffusion model to generate high-quality and diverse kinship faces. In this framework, the rich facial priors of StyleGAN enable fine-grained attribute control, while our conditional diffusion model is used to sample a StyleGAN latent aligned with the kinship relationship of conditioning images by utilizing the advantage of modeling complex kinship relationship distribution. StyleGAN then handles latent decoding for final face generation. Additionally, we introduce the Relational Trait Guidance (RTG) mechanism, enabling independent control of influencing conditions, such as each parent’s facial image. RTG also enables a fine-grained adjustment between the diversity and fidelity in synthesized faces. Furthermore, we extend the application to an unexplored domain: predicting a partner’s facial images using a child’s image and one parent’s image within the same framework. Extensive experiments demonstrate that our StyleDiT outperforms existing methods by striking an excellent balance between generating diverse and high-fidelity kinship faces. </p>
<blockquote>
<p>亲属关系面部合成是一项具有挑战性的任务，因为可用的亲属关系数据稀缺且质量低下。现有方法往往难以生成具有高度多样性和保真度的后代，同时难以精确控制面部属性，如年龄和性别。为了解决这些问题，我们提出了Style Latent Diffusion Transformer（StyleDiT）这一新型框架，它结合了StyleGAN和扩散模型的优点，用于生成高质量和多样化的亲属关系面部。在该框架中，StyleGAN的丰富面部先验知识能够实现细粒度的属性控制，而我们的条件扩散模型则利用建模复杂的亲属关系分布的优势，对与条件图像相符的StyleGAN潜在向量进行采样。然后，StyleGAN处理潜在解码以生成最终面部。此外，我们引入了Relational Trait Guidance（RTG）机制，实现对影响条件（如每个父母的面部图像）的独立控制。RTG还能够在合成面部的多样性和保真度之间进行精细调整。此外，我们将应用扩展到了一个未被探索的领域：在同一框架内，使用孩子的图像和父母的图像来预测伴侣的面部图像。大量实验表明，我们的StyleDiT在生成多样化和高保真度的亲属关系面部方面取得了出色的平衡，超越了现有方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10785v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一个名为StyleDiT的新框架，结合了StyleGAN和扩散模型的优点，用于生成高质量、多样化的亲属关系面孔。该框架利用StyleGAN的丰富面部先验信息实现精细的属性控制，通过条件扩散模型对与条件图像相符的StyleGAN潜在向量进行采样，并利用亲属关系分布建模的优势。此外，还引入了关系特征引导（RTG）机制，实现对影响条件如父母面部图像的独立控制，并在合成面部的多样性和逼真度之间进行精细调整。该框架还扩展到了预测配偶面部图像的应用，使用孩子的图像和父母的图像。实验表明，StyleDiT在生成多样化和高保真度的亲属关系面孔方面优于现有方法。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>StyleDiT结合了StyleGAN和扩散模型的优点，用于生成亲属关系面孔。</li>
<li>StyleGAN的丰富面部先验信息实现了精细的属性控制。</li>
<li>条件扩散模型用于采样与条件图像相符的StyleGAN潜在向量。</li>
<li>引入了关系特征引导（RTG）机制，实现了影响条件的独立控制。</li>
<li>RTG机制可以在多样性和逼真度之间进行精细调整。</li>
<li>StyleDiT框架扩展到了预测配偶面部图像的应用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10785">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9a6efa0f58fd273a878bfddb6ec371fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0ba41c9c387d9a8769fef8764dab84d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98ba5226d8f9cf2970d7259c73d0e4d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed34150d741e59c526f5c7c83af181da.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Fine-grained-Text-to-Image-Synthesis"><a href="#Fine-grained-Text-to-Image-Synthesis" class="headerlink" title="Fine-grained Text to Image Synthesis"></a>Fine-grained Text to Image Synthesis</h2><p><strong>Authors:Xu Ouyang, Ying Chen, Kaiyue Zhu, Gady Agam</strong></p>
<p>Fine-grained text to image synthesis involves generating images from texts that belong to different categories. In contrast to general text to image synthesis, in fine-grained synthesis there is high similarity between images of different subclasses, and there may be linguistic discrepancy among texts describing the same image. Recent Generative Adversarial Networks (GAN), such as the Recurrent Affine Transformation (RAT) GAN model, are able to synthesize clear and realistic images from texts. However, GAN models ignore fine-grained level information. In this paper we propose an approach that incorporates an auxiliary classifier in the discriminator and a contrastive learning method to improve the accuracy of fine-grained details in images synthesized by RAT GAN. The auxiliary classifier helps the discriminator classify the class of images, and helps the generator synthesize more accurate fine-grained images. The contrastive learning method minimizes the similarity between images from different subclasses and maximizes the similarity between images from the same subclass. We evaluate on several state-of-the-art methods on the commonly used CUB-200-2011 bird dataset and Oxford-102 flower dataset, and demonstrated superior performance. </p>
<blockquote>
<p>细粒度文本到图像合成涉及从不同类别的文本生成图像。与一般的文本到图像合成相比，在细粒度合成中，不同子类的图像之间具有高度相似性，描述同一图像的文本之间可能存在语言差异。最近的生成对抗网络（GAN），如循环仿射变换（RAT）GAN模型，能够从文本中合成清晰和现实的图像。然而，GAN模型忽略了细粒度级别的信息。在本文中，我们提出了一种方法，该方法在鉴别器中结合了辅助分类器，并采用对比学习方法来提高由RAT GAN合成图像的细粒度细节的准确性。辅助分类器帮助鉴别器对图像进行分类，并帮助生成器合成更准确的细粒度图像。对比学习方法最小化不同子类图像之间的相似性，并最大化同一子类图像之间的相似性。我们在常用的CUB-200-2011鸟类数据集和Oxford-102花卉数据集上对一些最先进的方法进行了评估，并展示了优越的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07196v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于文本的精细粒度图像合成使用文本生成不同类别的图像。与一般的文本到图像合成相比，精细粒度合成中不同子类的图像高度相似，描述同一图像的文本之间可能存在语言差异。尽管最近的生成对抗网络（GAN）如循环仿射变换（RAT）GAN模型能够生成清晰逼真的图像，但它们忽略了精细级别的信息。本文提出了一种方法，在鉴别器中引入辅助分类器，并采用对比学习方法来提高由RAT GAN合成的图像中精细级别信息的准确性。辅助分类器帮助鉴别器对图像进行分类，并帮助生成器生成更精确的精细粒度图像。对比学习方法减少了不同子类图像之间的相似性并增加了同一子类图像之间的相似性。我们在常用的CUB-200-2011鸟类数据集和Oxford-102花卉数据集上进行了评估，并展示了优越的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文本到图像合成可以分为精细粒度合成和一般合成，其中精细粒度合成涉及不同类别的图像生成。</li>
<li>现有GAN模型如RAT GAN在生成图像时忽略了精细级别的信息。</li>
<li>本文提出了一种在鉴别器中引入辅助分类器的方法，以提高图像合成的准确性。</li>
<li>辅助分类器有助于鉴别器对图像进行分类，同时帮助生成器生成更精确的精细粒度图像。</li>
<li>采用对比学习方法，减少不同子类图像之间的相似性，增加同一子类图像之间的相似性。</li>
<li>方法在CUB-200-2011鸟类数据集和Oxford-102花卉数据集上的评估表现优越。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07196">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-22715780741cabf2d8418a4303cf3438.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7185a0f87e292154d753c68ebd946585.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Take-Fake-as-Real-Realistic-like-Robust-Black-box-Adversarial-Attack-to-Evade-AIGC-Detection"><a href="#Take-Fake-as-Real-Realistic-like-Robust-Black-box-Adversarial-Attack-to-Evade-AIGC-Detection" class="headerlink" title="Take Fake as Real: Realistic-like Robust Black-box Adversarial Attack to   Evade AIGC Detection"></a>Take Fake as Real: Realistic-like Robust Black-box Adversarial Attack to   Evade AIGC Detection</h2><p><strong>Authors:Caiyun Xie, Dengpan Ye, Yunming Zhang, Long Tang, Yunna Lv, Jiacheng Deng, Jiawei Song</strong></p>
<p>The security of AI-generated content (AIGC) detection is crucial for ensuring multimedia content credibility. To enhance detector security, research on adversarial attacks has become essential. However, most existing adversarial attacks focus only on GAN-generated facial images detection, struggle to be effective on multi-class natural images and diffusion-based detectors, and exhibit poor invisibility. To fill this gap, we first conduct an in-depth analysis of the vulnerability of AIGC detectors and discover the feature that detectors vary in vulnerability to different post-processing. Then, considering that the detector is agnostic in real-world scenarios and given this discovery, we propose a Realistic-like Robust Black-box Adversarial attack (R$^2$BA) with post-processing fusion optimization. Unlike typical perturbations, R$^2$BA uses real-world post-processing, i.e., Gaussian blur, JPEG compression, Gaussian noise and light spot to generate adversarial examples. Specifically, we use a stochastic particle swarm algorithm with inertia decay to optimize post-processing fusion intensity and explore the detector’s decision boundary. Guided by the detector’s fake probability, R$^2$BA enhances&#x2F;weakens the detector-vulnerable&#x2F;detector-robust post-processing intensity to strike a balance between adversariality and invisibility. Extensive experiments on popular&#x2F;commercial AIGC detectors and datasets demonstrate that R$^2$BA exhibits impressive anti-detection performance, excellent invisibility, and strong robustness in GAN-based and diffusion-based cases. Compared to state-of-the-art white-box and black-box attacks, R$^2$BA shows significant improvements of 15%–72% and 21%–47% in anti-detection performance under the original and robust scenario respectively, offering valuable insights for the security of AIGC detection in real-world applications. </p>
<blockquote>
<p>人工智能生成内容（AIGC）检测的的安全性对于确保多媒体内容可信度至关重要。为了提升检测器安全性，对抗性攻击的研究变得至关重要。然而，现有大多数对抗性攻击仅专注于生成对抗网络（GAN）生成的面部图像检测，对于多类自然图像和基于扩散的检测器的效果欠佳，隐形性也较差。为了填补这一空白，我们首先对AIGC检测器的脆弱性进行了深入分析，并发现了检测器对不同后处理的脆弱性存在差异。基于此发现，考虑到检测器在现实场景中的不可知特性，我们提出了一种具有后处理融合优化的类似现实的鲁棒黑盒对抗性攻击（R$^2$BA）。不同于典型的扰动，R$^2$BA使用现实世界的后处理，例如高斯模糊、JPEG压缩、高斯噪声和光斑来生成对抗样本。具体来说，我们使用带有惯性衰减的随机粒子群算法来优化后处理融合强度并探索检测器的决策边界。在流行的&#x2F;商业AIGC检测器和数据集上进行的广泛实验表明，R$^2$BA具有令人印象深刻的反检测性能、出色的隐形性和强烈的稳健性，在基于GAN和基于扩散的情况下均表现良好。与最先进的白盒和黑盒攻击相比，R$^2$BA在原场景和稳健场景下的反检测性能分别提高了15%–72%和21%–47%，为AIGC检测在现实世界应用中的安全性提供了宝贵的见解。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06727v2">PDF</a> </p>
<p><strong>Summary</strong><br>基于人工智能生成的内容（AIGC）检测的安全对于确保多媒体内容可信度至关重要。为提高检测器安全性，对抗性攻击的研究变得至关重要。针对现有对抗性攻击在GAN生成的面部图像检测上的局限性，本文深入分析了AIGC检测器的脆弱性，并提出了一种名为R²BA的逼真型鲁棒黑盒对抗性攻击方法，通过优化后处理融合策略，能够在多类自然图像和扩散检测器上实现有效攻击，同时保持良好的隐蔽性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIGC检测安全对多媒体内容可信度至关重要。</li>
<li>对抗性攻击是提高AIGC检测器安全性的关键。</li>
<li>现有对抗性攻击在GAN生成的面部图像检测上表现出局限性，缺乏在多类自然图像和扩散检测器上的有效性及隐蔽性。</li>
<li>本文分析了AIGC检测器的脆弱性，发现不同后处理对检测器的影响存在差异。</li>
<li>提出了R²BA攻击方法，利用现实世界的后处理生成对抗样本，如高斯模糊、JPEG压缩等。</li>
<li>R²BA通过优化后处理融合策略，实现了在检测器决策边界的探索和平衡对抗性与隐蔽性。</li>
<li>实验结果表明，R²BA在主流和商业AIGC检测器及数据集上表现出卓越的抗检测性能、高度的隐蔽性和强大的鲁棒性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06727">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-82db342b846d87a879a7952477aa9c61.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d9ace2084c0bd9c1acae41441062730f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-508412201d1bc93ff9ee90a0e529e726.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a36b189b7f8bae5ddfd7f7b09b172a25.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c8fc19bd5b1bd886168c3af6355a8f5f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="PriPHiT-Privacy-Preserving-Hierarchical-Training-of-Deep-Neural-Networks"><a href="#PriPHiT-Privacy-Preserving-Hierarchical-Training-of-Deep-Neural-Networks" class="headerlink" title="PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural   Networks"></a>PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural   Networks</h2><p><strong>Authors:Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar</strong></p>
<p>The training phase of deep neural networks requires substantial resources and as such is often performed on cloud servers. However, this raises privacy concerns when the training dataset contains sensitive content, e.g., facial or medical images. In this work, we propose a method to perform the training phase of a deep learning model on both an edge device and a cloud server that prevents sensitive content being transmitted to the cloud while retaining the desired information. The proposed privacy-preserving method uses adversarial early exits to suppress the sensitive content at the edge and transmits the task-relevant information to the cloud. This approach incorporates noise addition during the training phase to provide a differential privacy guarantee. We extensively test our method on different facial and medical datasets with diverse attributes using various deep learning architectures, showcasing its outstanding performance. We also demonstrate the effectiveness of privacy preservation through successful defenses against different white-box, deep and GAN-based reconstruction attacks. This approach is designed for resource-constrained edge devices, ensuring minimal memory usage and computational overhead. </p>
<blockquote>
<p>深度神经网络训练阶段需要大量的资源，因此通常会在云服务器上执行。然而，当训练数据集包含敏感内容时，例如面部或医疗图像，这引发了隐私担忧。在这项工作中，我们提出了一种在边缘设备和云服务器上执行深度学习模型训练阶段的方法，该方法可防止敏感内容传输到云，同时保留所需的信息。所提出的隐私保护方法使用对抗性早期退出策略来抑制边缘的敏感内容，并将与任务相关的信息传输到云中。这种方法在训练阶段添加了噪声，以提供差分隐私保证。我们在具有不同属性的各种面部和医疗数据集上，使用各种深度学习架构对我们的方法进行了广泛测试，展示了其出色的性能。我们还通过成功防御各种白盒、深度以及基于GAN的重建攻击来证明了隐私保护的有效性。该方法专为资源受限的边缘设备设计，确保最小的内存使用和计算开销。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.05092v2">PDF</a> 21 pages, 19 figures, 11 tables</p>
<p><strong>Summary</strong><br>深度学习模型的训练阶段需要大量的资源，通常在云服务器上进行。但当训练数据集包含敏感内容时，如面部或医疗图像，这会引起隐私担忧。为此，我们提出了一种在边缘设备和云服务器上进行深度学习模型训练的方法，可防止敏感内容传输到云端，同时保留所需的信息。该方法使用对抗性早期退出策略在边缘设备抑制敏感内容，并将任务相关信息传输到云端。该方法在训练阶段添加噪声，提供差分隐私保证。我们已经在不同的面部和医疗数据集以及各种深度学习架构上进行了广泛测试，展示了其卓越的性能。我们还通过成功的防御各种白盒、深度和网络生成对抗攻击证明了隐私保护的有效性。此方法专为资源受限的边缘设备设计，确保低内存使用和计算开销。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度学习模型的训练需要大量资源，通常于云服务器上进行。</li>
<li>训练包含敏感内容的数据集（如面部或医疗图像）会引发隐私担忧。</li>
<li>提出一种在边缘设备和云服务器上进行深度学习模型训练的方法，能防止敏感内容传输到云端。</li>
<li>使用对抗性早期退出策略在边缘设备抑制敏感内容。</li>
<li>该方法在训练阶段添加噪声，以提供差分隐私保证。</li>
<li>方法已在多种数据集和深度学习架构上进行了广泛测试，表现出卓越性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.05092">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2bdcddc0c0e8e10529dc0d047c1c6d5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d40fdf5e20ec7ca7806971dd45c1b531.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bed5aaf8efee569326c6e50799631b07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97496c38a5334255c4e99fe7180ab5da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdf5925907e42bc697c8f4b92c44eb61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c38057ecbbadad7d928f2f576727768.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Deep-learning-based-radiointerferometric-imaging-with-GAN-aided-training"><a href="#Deep-learning-based-radiointerferometric-imaging-with-GAN-aided-training" class="headerlink" title="Deep learning-based radiointerferometric imaging with GAN-aided training"></a>Deep learning-based radiointerferometric imaging with GAN-aided training</h2><p><strong>Authors:F. Geyer, K. Schmidt, J. Kummer, M. Brüggen, H. W. Edler, D. Elsässer, F. Griese, A. Poggenpohl, L. Rustige, W. Rhode</strong></p>
<p>Radio interferometry invariably suffers from an incomplete coverage of the spatial Fourier space, which leads to imaging artifacts. The current state-of-the-art technique is to create an image by Fourier-transforming the incomplete visibility data and to clean the systematic effects originating from incomplete data in Fourier space. Previously, we have shown how super-resolution methods based on convolutional neural networks can reconstruct sparse visibility data. Our previous work has suffered from a low realism of the training data. The aim of this work is to build a whole simulation chain for realistic radio sources that then leads to a vastly improved neural net for the reconstruction of missing visibilities. This method offers considerable improvements in terms of speed, automatization and reproducibility over the standard techniques. Here we generate large amounts of training data by creating images of radio galaxies with a generative adversarial network (GAN) that has been trained on radio survey data. Then, we applied the Radio Interferometer Measurement Equation (RIME) in order to simulate the measurement process of a radio interferometer. We show that our neural network can reconstruct faithfully images of realistic radio galaxies. The reconstructed images agree well with the original images in terms of the source area, integrated flux density, peak flux density, and the multi-scale structural similarity index. Finally, we show how the neural net can be adapted to estimate the uncertainties in the imaging process. </p>
<blockquote>
<p>射电干涉仪通常会面临空间傅里叶变换覆盖不完全的问题，从而导致成像失真。目前最先进的技术是通过傅里叶变换不完整可见度数据来创建图像，并清除由傅里叶空间中不完整数据引起的系统效应。之前，我们已经展示了基于卷积神经网络的超分辨率方法如何重建稀疏可见度数据。我们之前的工作受到训练数据低真实性的影响。这项工作的目的是为真实射电源建立一个完整的仿真链，然后建立一个改进型神经网络，用于重建缺失的可见度。该方法在速度、自动化和可重复性方面为标准技术提供了相当大的改进。在这里，我们通过使用生成对抗网络（GAN）创建射电星系图像来生成大量训练数据，该网络已经在射电调查数据上进行了训练。然后，我们应用了射电干涉仪测量方程（RIME），以模拟射电干涉仪的测量过程。我们证明我们的神经网络能够忠实重建真实射电星系的图像。重建的图像在源区域、积分流量密度、峰值流量密度和多尺度结构相似性指数方面与原始图像吻合良好。最后，我们展示了神经网络如何适应以估计成像过程中的不确定性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14100v2">PDF</a> Accepted for publication in Astronomy &amp; Astrophysics</p>
<p><strong>Summary</strong></p>
<p>本摘要基于提供的文本，概括其主要信息：通过使用生成对抗网络（GAN）模拟生成逼真的射电星系图像作为训练数据，应用于射电干涉仪的测量过程模拟，构建的神经网络能够以大幅提高的速度和自动化程度重建缺失的可见度数据，并能准确地重建射电星系的图像。该神经网络还可以适应估计成像过程中的不确定性。总结简洁有力，准确无误地传达了文本的核心内容。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是从文本中提取出的七个关键要点：</p>
<ol>
<li>射电干涉仪存在空间傅里叶变换覆盖不完整的问题，导致成像出现伪影。</li>
<li>当前主流技术是通过傅里叶变换处理不完全的可见度数据并清除系统性效应。</li>
<li>基于卷积神经网络的超分辨率方法能够重建稀疏可见度数据。</li>
<li>之前的工作在训练数据的真实感方面存在不足。</li>
<li>使用生成对抗网络（GAN）模拟生成逼真的射电星系图像作为训练数据。</li>
<li>神经网络应用于射电干涉仪测量模拟过程，大幅提高了速度、自动化程度和可重复性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2307.14100">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0ec182cef014095e4e8e80305a18d444.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f973ddc9c9cbc99e9c02cda5c062021.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c26f0823ce38b0c108ec8c562bf712a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fb032dbdd8c8eb982b10d899dc62fdd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-236d47d5fb192a7cf433a9ed33efac88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f6793ad5991ab4286f32a1ccd83271d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b23a92c6a6d2683d5bda995f332db456.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16362e7d27d76bb84cc1c227dfb96092.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/GAN/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-19/GAN/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/GAN/">
                                    <span class="chip bg-color">GAN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-72e6f839d76852c919624ff97607ba0c.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2024-12-19  GraphAvatar Compact Head Avatars with GNN-Generated 3D Gaussians
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-19/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a90cc327cb07ee42fb909b59408bf305.jpg" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping 方向最新论文已更新，请持续关注 Update in 2024-12-19  Towards a Universal Synthetic Video Detector From Face or Background   Manipulations to Fully AI-Generated Content
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">15534.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
