<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-29  ArVoice A Multi-Speaker Dataset for Arabic Speech Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-8de2ae4d28c9195f7096460090da067c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    32 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-29-æ›´æ–°"><a href="#2025-05-29-æ›´æ–°" class="headerlink" title="2025-05-29 æ›´æ–°"></a>2025-05-29 æ›´æ–°</h1><h2 id="ArVoice-A-Multi-Speaker-Dataset-for-Arabic-Speech-Synthesis"><a href="#ArVoice-A-Multi-Speaker-Dataset-for-Arabic-Speech-Synthesis" class="headerlink" title="ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis"></a>ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis</h2><p><strong>Authors:Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki</strong></p>
<p>We introduce ArVoice, a multi-speaker Modern Standard Arabic (MSA) speech corpus with diacritized transcriptions, intended for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection. ArVoice comprises: (1) a new professionally recorded set from six voice talents with diverse demographics, (2) a modified subset of the Arabic Speech Corpus; and (3) high-quality synthetic speech from two commercial systems. The complete corpus consists of a total of 83.52 hours of speech across 11 voices; around 10 hours consist of human voices from 7 speakers. We train three open-source TTS and two voice conversion systems to illustrate the use cases of the dataset. The corpus is available for research use. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ArVoiceï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šè¯´è¯äººç°ä»£æ ‡å‡†é˜¿æ‹‰ä¼¯è¯­ï¼ˆMSAï¼‰è¯­éŸ³è¯­æ–™åº“ï¼Œå¸¦æœ‰åŠ éŸ³ç¬¦å·çš„è½¬å½•ï¼Œæ—¨åœ¨ç”¨äºå¤šè¯´è¯äººè¯­éŸ³åˆæˆï¼Œå¹¶ä¸”å¯¹å…¶ä»–ä»»åŠ¡å¦‚åŸºäºè¯­éŸ³çš„éŸ³æ ‡æ¢å¤ã€å£°éŸ³è½¬æ¢å’Œæ·±åº¦ä¼ªé€ æ£€æµ‹ç­‰ä¹Ÿæœ‰ç”¨ã€‚ArVoiceåŒ…æ‹¬ï¼šï¼ˆ1ï¼‰ç”±å…·æœ‰ä¸åŒäººå£ç»Ÿè®¡ç‰¹å¾çš„å…­ä½è¯­éŸ³äººæ‰å½•åˆ¶çš„æ–°ä¸“ä¸šé›†ï¼Œï¼ˆ2ï¼‰é˜¿æ‹‰ä¼¯è¯­éŸ³åº“çš„ä¿®æ”¹å­é›†ï¼›ï¼ˆ3ï¼‰ä¸¤ä¸ªå•†ä¸šç³»ç»Ÿçš„é«˜å“è´¨åˆæˆè¯­éŸ³ã€‚å®Œæ•´çš„è¯­æ–™åº“åŒ…å«æ€»è®¡83.52å°æ—¶çš„è¯­éŸ³ï¼Œè·¨è¶Š11ç§å£°éŸ³ï¼›å…¶ä¸­çº¦10å°æ—¶æ˜¯äººç±»å£°éŸ³ï¼Œæ¥è‡ª7ä½è¯´è¯è€…ã€‚æˆ‘ä»¬è®­ç»ƒäº†ä¸‰ä¸ªå¼€æºçš„TTSå’Œä¸¤ç§è¯­éŸ³è½¬æ¢ç³»ç»Ÿï¼Œä»¥è¯´æ˜è¯¥æ•°æ®é›†çš„ä½¿ç”¨æƒ…å†µã€‚è¯¥è¯­æ–™åº“å¯ç”¨äºç ”ç©¶ç”¨é€”ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20506v1">PDF</a> Accepted at INTERSPEECH 2025 The dataset is available at   <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/MBZUAI/ArVoice">https://huggingface.co/datasets/MBZUAI/ArVoice</a></p>
<p><strong>Summary</strong></p>
<p>ArVoiceæ˜¯ä¸€ä¸ªå¤šè¯´è¯äººç°ä»£æ ‡å‡†é˜¿æ‹‰ä¼¯è¯­ï¼ˆMSAï¼‰è¯­éŸ³è¯­æ–™åº“ï¼ŒåŒ…å«å¸¦å˜éŸ³ç¬¦çš„è½¬å½•ï¼Œä¸»è¦ç”¨äºå¤šè¯´è¯äººè¯­éŸ³åˆæˆï¼Œä¹Ÿå¯ç”¨äºå…¶ä»–ä»»åŠ¡ï¼Œå¦‚å˜éŸ³ç¬¦æ¢å¤ã€è¯­éŸ³è½¬æ¢å’Œæ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚å®ƒåŒ…å«ä¸“ä¸šå½•åˆ¶çš„æ•°æ®é›†ã€ä¿®æ”¹çš„é˜¿æ‹‰ä¼¯è¯­éŸ³è¯­æ–™åº“å­é›†ä»¥åŠä¸¤ä¸ªå•†ä¸šç³»ç»Ÿçš„é«˜è´¨é‡åˆæˆè¯­éŸ³ã€‚è¯¥è¯­æ–™åº“å…±æœ‰83.52å°æ—¶çš„è¯­éŸ³æ•°æ®ï¼Œæ¶µç›–11ä¸ªå£°éŸ³ï¼Œå…¶ä¸­çº¦10å°æ—¶æ˜¯äººç±»å£°éŸ³ã€‚ä¸ºå±•ç¤ºæ•°æ®é›†çš„åº”ç”¨åœºæ™¯ï¼Œè®­ç»ƒäº†ä¸‰ä¸ªå¼€æºæ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿå’Œä¸¤ä¸ªè¯­éŸ³è½¬æ¢ç³»ç»Ÿã€‚è¯¥è¯­æ–™åº“å¯ç”¨äºç ”ç©¶ç”¨é€”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ArVoiceæ˜¯ä¸€ä¸ªå¤šè¯´è¯äººçš„ç°ä»£æ ‡å‡†é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³è¯­æ–™åº“ï¼ŒåŒ…å«å¸¦å˜éŸ³ç¬¦çš„è½¬å½•ã€‚</li>
<li>è¯¥è¯­æ–™åº“å¯ç”¨äºå¤šè¯´è¯äººè¯­éŸ³åˆæˆåŠå…¶ä»–ä»»åŠ¡ï¼Œå¦‚å˜éŸ³ç¬¦æ¢å¤ã€è¯­éŸ³è½¬æ¢å’Œæ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚</li>
<li>ArVoiceåŒ…å«ä¸“ä¸šå½•åˆ¶çš„æ•°æ®é›†ã€ä¿®æ”¹çš„é˜¿æ‹‰ä¼¯è¯­éŸ³è¯­æ–™åº“å­é›†ä»¥åŠä»ä¸¤ä¸ªå•†ä¸šç³»ç»Ÿç”Ÿæˆçš„é«˜è´¨é‡åˆæˆè¯­éŸ³ã€‚</li>
<li>å®Œæ•´è¯­æ–™åº“åŒ…å«83.52å°æ—¶çš„è¯­éŸ³æ•°æ®ï¼Œæ¶µç›–11ä¸ªå£°éŸ³ï¼Œå…¶ä¸­çº¦10å°æ—¶æ˜¯äººç±»å£°éŸ³ã€‚</li>
<li>ä¸ºå±•ç¤ºæ•°æ®é›†çš„åº”ç”¨åœºæ™¯ï¼Œè¯¥è®ºæ–‡è®­ç»ƒäº†ä¸‰ä¸ªå¼€æºæ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿå’Œä¸¤ä¸ªè¯­éŸ³è½¬æ¢ç³»ç»Ÿã€‚</li>
<li>ArVoiceè¯­æ–™åº“å¯ç”¨äºç ”ç©¶ç”¨é€”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20506">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f508c0c483d618d7f908187ab936b4a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-11b575fd77bd35091d87f19508d7b79a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dde2ea52cb9f2c6846d87bab7ed1a453.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43aae3111c5affe9771afe481b18d071.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2e433b42d4f9eac3742545d79da9730.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8653c45e54f3c54dcf5aa31f799f25d8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Guided-by-Gut-Efficient-Test-Time-Scaling-with-Reinforced-Intrinsic-Confidence"><a href="#Guided-by-Gut-Efficient-Test-Time-Scaling-with-Reinforced-Intrinsic-Confidence" class="headerlink" title="Guided by Gut: Efficient Test-Time Scaling with Reinforced Intrinsic   Confidence"></a>Guided by Gut: Efficient Test-Time Scaling with Reinforced Intrinsic   Confidence</h2><p><strong>Authors:Amirhosein Ghasemabadi, Keith G. Mills, Baochun Li, Di Niu</strong></p>
<p>Test-Time Scaling (TTS) methods for enhancing Large Language Model (LLM) reasoning often incur substantial computational costs, primarily due to extensive reliance on external Process Reward Models (PRMs) or sampling methods like Best-of-N (BoN). This paper introduces Guided by Gut (GG), an efficient self-guided TTS framework that achieves PRM-level performance without costly external verifier models. Our method employs a lightweight tree search guided solely by intrinsic LLM signals, token-level confidence and step novelty. One critical innovation is improving the reliability of internal confidence estimates via a targeted reinforcement learning fine-tuning phase. Empirical evaluations on challenging mathematical reasoning benchmarks demonstrate that GG enables smaller models (e.g., 1.5B parameters) to achieve accuracy matching or surpassing significantly larger models (e.g., 32B-70B parameters), while reducing GPU memory usage by up to 10x. Compared to PRM-based methods, GG achieves comparable accuracy with 8x faster inference speeds and 4-5x lower memory usage. Additionally, GG reduces KV cache memory usage by approximately 50% compared to the BoN strategy, facilitating more efficient and practical deployment of TTS techniques. </p>
<blockquote>
<p>æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰æ–¹æ³•é€šå¸¸ç”¨äºå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œä½†ä¼šäº§ç”Ÿå·¨å¤§çš„è®¡ç®—æˆæœ¬ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºä¸¥é‡ä¾èµ–å¤–éƒ¨è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰æˆ–å¦‚æœ€ä½³Nï¼ˆBoNï¼‰è¿™æ ·çš„é‡‡æ ·æ–¹æ³•ã€‚æœ¬æ–‡ä»‹ç»äº†â€œå¬ä»å†…å¿ƒâ€ï¼ˆGGï¼‰è¿™ä¸€é«˜æ•ˆçš„è‡ªæˆ‘å¼•å¯¼TTSæ¡†æ¶ï¼Œå®ƒæ— éœ€æ˜‚è´µçš„å¤–éƒ¨éªŒè¯æ¨¡å‹å³å¯å®ç°PRMçº§åˆ«çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨è½»é‡çº§çš„æ ‘æœç´¢ï¼Œä»…ç”±å†…åœ¨LLMä¿¡å·ã€ä»¤ç‰Œçº§ä¿¡å¿ƒå’Œæ­¥éª¤æ–°é¢–æ€§æ¥æŒ‡å¯¼ã€‚ä¸€ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹æ˜¯é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒé˜¶æ®µæ¥æé«˜å†…éƒ¨ä¿¡å¿ƒä¼°è®¡çš„å¯é æ€§ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒGGä½¿è¾ƒå°çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ1.5Bå‚æ•°ï¼‰èƒ½å¤Ÿè¾¾åˆ°æˆ–è¶…è¿‡æ˜¾è‘—è¾ƒå¤§çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ32B-70Bå‚æ•°ï¼‰çš„å‡†ç¡®åº¦ï¼ŒåŒæ—¶å°†GPUå†…å­˜ä½¿ç”¨ç‡é™ä½é«˜è¾¾10å€ã€‚ä¸åŸºäºPRMçš„æ–¹æ³•ç›¸æ¯”ï¼ŒGGä»¥8å€çš„æ¨ç†é€Ÿåº¦å®ç°äº†ç›¸å½“çš„ç²¾åº¦ï¼Œå¹¶é™ä½äº†4-5å€çš„å†…å­˜ä½¿ç”¨ç‡ã€‚æ­¤å¤–ï¼Œä¸BoNç­–ç•¥ç›¸æ¯”ï¼ŒGGå‡å°‘äº†å¤§çº¦50%çš„KVç¼“å­˜å†…å­˜ä½¿ç”¨ï¼Œä½¿TTSæŠ€æœ¯çš„éƒ¨ç½²æ›´åŠ é«˜æ•ˆå®ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20325v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä»‹ç»äº†åä¸ºGuided by Gutçš„TTSæ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿåœ¨ä¸ä½¿ç”¨æ˜‚è´µçš„å¤–éƒ¨éªŒè¯æ¨¡å‹çš„æƒ…å†µä¸‹å®ç°PRMçº§åˆ«çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶é€šè¿‡é‡‡ç”¨è½»é‡çº§æ ‘æœç´¢ã€åŸºäºLLMçš„å›ºæœ‰ä¿¡å·ã€ä»¤ç‰Œçº§åˆ«çš„ç½®ä¿¡åº¦å’Œæ­¥éª¤æ–°é¢–æ€§æ¥å·¥ä½œã€‚é‡è¦åˆ›æ–°ä¹‹ä¸€æ˜¯é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒé˜¶æ®µæé«˜äº†å†…éƒ¨ç½®ä¿¡åº¦ä¼°è®¡çš„å¯é æ€§ã€‚å®ƒåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒGGä½¿è¾ƒå°çš„æ¨¡å‹èƒ½å¤Ÿå®ç°ä¸è¾ƒå¤§çš„æ¨¡å‹ç›¸åŒ¹é…æˆ–æ›´é«˜çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶å‡å°‘äº†GPUå†…å­˜ä½¿ç”¨é‡ã€‚ä¸PRMæ–¹æ³•ç›¸æ¯”ï¼ŒGGå®ç°äº†ç›¸å½“çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶æ¨ç†é€Ÿåº¦æé«˜äº†8å€ï¼Œå†…å­˜ä½¿ç”¨ç‡é™ä½äº†4-5å€ã€‚æ­¤å¤–ï¼Œä¸BoNç­–ç•¥ç›¸æ¯”ï¼ŒGGå‡å°‘äº†KVç¼“å­˜å†…å­˜çš„ä½¿ç”¨é‡çº¦50%ï¼Œä½¿å¾—TTSæŠ€æœ¯çš„éƒ¨ç½²æ›´åŠ é«˜æ•ˆå®ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯æ–‡æœ¬çš„ä¸»è¦è§è§£ï¼š</p>
<ul>
<li>Guided by Gutæ˜¯ä¸€ä¸ªé«˜æ•ˆçš„è‡ªæˆ‘å¼•å¯¼TTSæ¡†æ¶ï¼Œæ— éœ€ä¾èµ–æ˜‚è´µçš„å¤–éƒ¨éªŒè¯æ¨¡å‹å³å¯å®ç°PRMçº§åˆ«çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡è½»é‡çº§æ ‘æœç´¢ã€å›ºæœ‰LLMä¿¡å·è¿›è¡Œå·¥ä½œï¼Œå¹¶ç»“åˆä»¤ç‰Œçº§åˆ«çš„ç½®ä¿¡åº¦å’Œæ­¥éª¤æ–°é¢–æ€§æ¥å®ç°é«˜æ•ˆæ¨ç†ã€‚</li>
<li>é€šè¿‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒé˜¶æ®µæé«˜äº†å†…éƒ¨ç½®ä¿¡åº¦ä¼°è®¡çš„å¯é æ€§ã€‚</li>
<li>GGèƒ½åœ¨è¾ƒå°çš„æ¨¡å‹ä¸Šå®ç°ä¸è¾ƒå¤§çš„æ¨¡å‹ç›¸åŒ¹é…æˆ–æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>ä¸PRMæ–¹æ³•ç›¸æ¯”ï¼ŒGGæä¾›äº†æ›´å¿«çš„æ¨ç†é€Ÿåº¦å’Œæ›´ä½çš„å†…å­˜ä½¿ç”¨æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20325">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8d8dff4a4feda3b392affa35b98fa022.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a12c12765a5cfdb3707d540665c56432.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-815c2765b5ca6af423d8602dc80e110a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="PMOA-TTS-Introducing-the-PubMed-Open-Access-Textual-Times-Series-Corpus"><a href="#PMOA-TTS-Introducing-the-PubMed-Open-Access-Textual-Times-Series-Corpus" class="headerlink" title="PMOA-TTS: Introducing the PubMed Open Access Textual Times Series Corpus"></a>PMOA-TTS: Introducing the PubMed Open Access Textual Times Series Corpus</h2><p><strong>Authors:Shahriar Noroozizadeh, Sayantan Kumar, George H. Chen, Jeremy C. Weiss</strong></p>
<p>Understanding temporal dynamics in clinical narratives is essential for modeling patient trajectories, yet large-scale temporally annotated resources remain limited. We present PMOA-TTS, the first openly available dataset of 124,699 PubMed Open Access (PMOA) case reports, each converted into structured (event, time) timelines via a scalable LLM-based pipeline. Our approach combines heuristic filtering with Llama 3.3 to identify single-patient case reports, followed by prompt-driven extraction using Llama 3.3 and DeepSeek R1, resulting in over 5.6 million timestamped clinical events. To assess timeline quality, we evaluate against a clinician-curated reference set using three metrics: (i) event-level matching (80% match at a cosine similarity threshold of 0.1), (ii) temporal concordance (c-index &gt; 0.90), and (iii) Area Under the Log-Time CDF (AULTC) for timestamp alignment. Corpus-level analysis shows wide diagnostic and demographic coverage. In a downstream survival prediction task, embeddings from extracted timelines achieve time-dependent concordance indices up to 0.82 $\pm$ 0.01, demonstrating the predictive value of temporally structured narratives. PMOA-TTS provides a scalable foundation for timeline extraction, temporal reasoning, and longitudinal modeling in biomedical NLP. The dataset is available at: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/snoroozi/pmoa-tts">https://huggingface.co/datasets/snoroozi/pmoa-tts</a> . </p>
<blockquote>
<p>ç†è§£ä¸´åºŠå™è¿°ä¸­çš„æ—¶é—´åŠ¨æ€å¯¹äºå»ºç«‹æ‚£è€…è½¨è¿¹æ¨¡å‹è‡³å…³é‡è¦ï¼Œç„¶è€Œå¤§è§„æ¨¡çš„æ—¶é—´æ³¨é‡Šèµ„æºä»ç„¶æœ‰é™ã€‚æˆ‘ä»¬æ¨å‡ºäº†PMOA-TTSï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ï¼ŒåŒ…å«124,699ç¯‡PubMed Open Accessï¼ˆPMOAï¼‰ç—…ä¾‹æŠ¥å‘Šï¼Œæ¯ä¸ªæŠ¥å‘Šéƒ½é€šè¿‡å¯æ‰©å±•çš„LLMç®¡é“è½¬æ¢ä¸ºç»“æ„åŒ–ï¼ˆäº‹ä»¶ï¼Œæ—¶é—´ï¼‰æ—¶é—´è¡¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†å¯å‘å¼è¿‡æ»¤å’ŒLlama 3.3æ¥è¯†åˆ«å•ä¸ªæ‚£è€…çš„ç—…ä¾‹æŠ¥å‘Šï¼Œç„¶åä½¿ç”¨Llama 3.3å’ŒDeepSeek R1è¿›è¡Œæç¤ºé©±åŠ¨æå–ï¼Œäº§ç”Ÿäº†è¶…è¿‡560ä¸‡çš„æ—¶é—´æˆ³ä¸´åºŠäº‹ä»¶ã€‚ä¸ºäº†è¯„ä¼°æ—¶é—´è¡¨çš„è´¨é‡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸´åºŠåŒ»ç”Ÿç¼–åˆ¶çš„å‚è€ƒé›†ï¼Œé€šè¿‡ä¸‰ä¸ªæŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼šï¼ˆiï¼‰äº‹ä»¶çº§åˆ«åŒ¹é…ï¼ˆåœ¨ä½™å¼¦ç›¸ä¼¼æ€§é˜ˆå€¼ä¸º0.1çš„æƒ…å†µä¸‹è¾¾åˆ°80%çš„åŒ¹é…åº¦ï¼‰ï¼Œï¼ˆiiï¼‰æ—¶é—´ä¸€è‡´æ€§ï¼ˆcæŒ‡æ•°&gt; 0.9ï¼‰ï¼Œä»¥åŠï¼ˆiiiï¼‰æ—¶é—´æˆ³å¯¹é½çš„Log-Time CDFä¸‹çš„é¢ç§¯ï¼ˆAULTCï¼‰ã€‚è¯­æ–™åº“çº§åˆ«çš„åˆ†ææ˜¾ç¤ºå‡ºå¹¿æ³›çš„è¯Šæ–­å’Œäººå£è¦†ç›–é¢ã€‚åœ¨ä¸‹æ¸¸çš„ç”Ÿå­˜é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œä»æå–çš„æ—¶é—´è¡¨ä¸­è·å¾—çš„åµŒå…¥è¾¾åˆ°äº†é«˜è¾¾0.82Â±0.01çš„æ—¶é—´ä¾èµ–æ€§ä¸€è‡´æ€§æŒ‡æ•°ï¼Œè¯æ˜äº†æ—¶åºç»“æ„åŒ–å™è¿°çš„é¢„æµ‹ä»·å€¼ã€‚PMOA-TTSä¸ºæ—¶é—´åºåˆ—æå–ã€æ—¶é—´æ¨ç†å’Œçºµå‘å»ºæ¨¡æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ï¼Œåœ¨ç”Ÿç‰©åŒ»å­¦NLPé¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ã€‚æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/snoroozi/pmoa-tts%E6%89%BE%E5%88%B0%E3%80%82">https://huggingface.co/datasets/snoroozi/pmoa-ttsæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20323v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†PMOA-TTSæ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªå…¬å¼€çš„ã€åŒ…å«124,699ç¯‡PubMed Open Accessæ¡ˆä¾‹æŠ¥å‘Šçš„æ•°æ®é›†ã€‚é€šè¿‡å¯æ‰©å±•çš„LLMç®¡é“å°†è¿™äº›æŠ¥å‘Šè½¬æ¢ä¸ºç»“æ„åŒ–ï¼ˆäº‹ä»¶ï¼Œæ—¶é—´ï¼‰æ—¶é—´çº¿ã€‚æ•°æ®é›†ç”¨äºè¯„ä¼°æ—¶é—´çº¿è´¨é‡ï¼Œå¹¶åœ¨ä¸‹æ¸¸ç”Ÿå­˜é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é¢„æµ‹æ€§èƒ½ã€‚PMOA-TTSä¸ºç”Ÿç‰©åŒ»å­¦NLPä¸­çš„æ—¶é—´çº¿æå–ã€æ—¶é—´æ¨ç†å’Œçºµå‘å»ºæ¨¡æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PMOA-TTSæ˜¯é¦–ä¸ªå…¬å¼€çš„ã€å¤§è§„æ¨¡çš„ä¸´åºŠå™äº‹æ•°æ®é›†ï¼ŒåŒ…å«124,699ç¯‡PubMed Open Accessæ¡ˆä¾‹æŠ¥å‘Šã€‚</li>
<li>åˆ©ç”¨LLMç®¡é“å®ç°äº†ç»“æ„åŒ–çš„ï¼ˆäº‹ä»¶ï¼Œæ—¶é—´ï¼‰æ—¶é—´çº¿è½¬æ¢ã€‚</li>
<li>ç»“åˆå¯å‘å¼è¿‡æ»¤å’ŒLlama 3.3æŠ€æœ¯ï¼Œä»¥åŠåŸºäºpromptçš„æå–å’ŒDeepSeek R1æŠ€æœ¯ï¼Œå®ç°äº†è¶…è¿‡560ä¸‡çš„æ—¶é—´æˆ³ä¸´åºŠäº‹ä»¶æå–ã€‚</li>
<li>é€šè¿‡ä¸‰ä¸ªæŒ‡æ ‡è¯„ä¼°æ—¶é—´çº¿è´¨é‡ï¼šäº‹ä»¶çº§åˆ«åŒ¹é…ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ—¶é—´æˆ³å¯¹é½çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ä¸‹çš„é¢ç§¯ï¼ˆAULTCï¼‰ã€‚</li>
<li>æ•°æ®é›†æ¶µç›–å¹¿æ³›çš„è¯Šæ–­å’Œäººå£ç»Ÿè®¡æ•°æ®ï¼Œå…·æœ‰è‰¯å¥½çš„è¦†ç›–é¢ã€‚</li>
<li>åœ¨ä¸‹æ¸¸ç”Ÿå­˜é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œæå–çš„æ—¶é—´çº¿åµŒå…¥è¾¾åˆ°äº†è¾ƒé«˜çš„é¢„æµ‹æ€§èƒ½ï¼Œæ˜¾ç¤ºäº†ç»“æ„åŒ–å™äº‹çš„æ—¶é—´é¢„æµ‹ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20323">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b4eb108c98939a7c7531fc4f37f997c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a25ea353f18ae4d849ab2147236fb4a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9753622025e9386ab3a4959b2c2d71f9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Faster-and-Better-LLMs-via-Latency-Aware-Test-Time-Scaling"><a href="#Faster-and-Better-LLMs-via-Latency-Aware-Test-Time-Scaling" class="headerlink" title="Faster and Better LLMs via Latency-Aware Test-Time Scaling"></a>Faster and Better LLMs via Latency-Aware Test-Time Scaling</h2><p><strong>Authors:Zili Wang, Tianyu Zhang, Haoli Bai, Lu Hou, Xianzhi Yu, Wulong Liu, Shiming Xiang, Lei Zhu</strong></p>
<p>Test-Time Scaling (TTS) has proven effective in improving the performance of Large Language Models (LLMs) during inference. However, existing research has overlooked the efficiency of TTS from a latency-sensitive perspective. Through a latency-aware evaluation of representative TTS methods, we demonstrate that a compute-optimal TTS does not always result in the lowest latency in scenarios where latency is critical. To address this gap and achieve latency-optimal TTS, we propose two key approaches by optimizing the concurrency configurations: (1) branch-wise parallelism, which leverages multiple concurrent inference branches, and (2) sequence-wise parallelism, enabled by speculative decoding. By integrating these two approaches and allocating computational resources properly to each, our latency-optimal TTS enables a 32B model to reach 82.3% accuracy on MATH-500 within 1 minute and a smaller 3B model to achieve 72.4% within 10 seconds. Our work emphasizes the importance of latency-aware TTS and demonstrates its ability to deliver both speed and accuracy in latency-sensitive scenarios. </p>
<blockquote>
<p>æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰å·²è¯æ˜åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯ä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦å¿½è§†äº†TTSçš„æ•ˆç‡ã€‚é€šè¿‡å¯¹ä»£è¡¨æ€§TTSæ–¹æ³•è¿›è¡Œå»¶è¿Ÿæ„ŸçŸ¥è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´å»¶è¿Ÿæœ€ä½ï¼Œè¿™åœ¨å»¶è¿Ÿè‡³å…³é‡è¦çš„åœºæ™¯ä¸­å°¤ä¸ºå…³é”®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·å¹¶å®ç°å»¶è¿Ÿæœ€ä¼˜çš„TTSï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§é€šè¿‡ä¼˜åŒ–å¹¶å‘é…ç½®çš„å…³é”®æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆ†æ”¯å¹¶è¡Œæ€§ï¼Œåˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ï¼›ï¼ˆ2ï¼‰é€šè¿‡çŒœæµ‹è§£ç å®ç°åºåˆ—å¹¶è¡Œæ€§ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶ä¸ºæ¯ç§æ–¹æ³•é€‚å½“åˆ†é…è®¡ç®—èµ„æºï¼Œæˆ‘ä»¬çš„å»¶è¿Ÿæœ€ä¼˜TTSä½¿32Bæ¨¡å‹åœ¨MATH-500ä¸Š1åˆ†é’Ÿå†…è¾¾åˆ°82.3%çš„å‡†ç¡®ç‡ï¼Œè¾ƒå°çš„3Bæ¨¡å‹åœ¨10ç§’å†…è¾¾åˆ°72.4%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å»¶è¿Ÿæ„ŸçŸ¥TTSçš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­å®ç°é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19634v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æµ‹è¯•æ—¶é—´å°ºåº¦ï¼ˆTTSï¼‰å¯æ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†æ€§èƒ½ã€‚ä½†ç°æœ‰ç ”ç©¶æœªä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦å……åˆ†è¯„ä¼°TTSçš„æ•ˆç‡ã€‚é€šè¿‡å»¶è¿Ÿæ„ŸçŸ¥çš„è¯„ä¼°æ–¹æ³•ï¼Œæˆ‘ä»¬å‘ç°è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´æœ€ä½å»¶è¿Ÿï¼Œè¿™åœ¨å»¶è¿Ÿè‡³å…³é‡è¦çš„æƒ…å†µä¸‹å°¤ä¸ºæ˜æ˜¾ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·å¹¶å®ç°å»¶è¿Ÿä¼˜åŒ–çš„TTSï¼Œæˆ‘ä»¬æå‡ºä¸¤ç§ä¼˜åŒ–å¹¶å‘é…ç½®çš„å…³é”®æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆ†æ”¯å¹¶è¡Œæ€§ï¼Œåˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ï¼›ï¼ˆ2ï¼‰åºåˆ—å¹¶è¡Œæ€§ï¼Œé€šè¿‡æŠ•æœºè§£ç å®ç°ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶ä¸ºæ¯ä¸ªåˆ†é…é€‚å½“çš„è®¡ç®—èµ„æºï¼Œæˆ‘ä»¬çš„å»¶è¿Ÿä¼˜åŒ–TTSä½¿32Bæ¨¡å‹åœ¨MATH-500ä¸Šåœ¨1åˆ†é’Ÿå†…è¾¾åˆ°82.3ï¼…çš„å‡†ç¡®ç‡ï¼Œè¾ƒå°çš„3Bæ¨¡å‹åœ¨10ç§’å†…è¾¾åˆ°72.4ï¼…çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å»¶è¿Ÿæ„ŸçŸ¥TTSçš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­å®ç°é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TTSåœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½æ–¹é¢å…·æœ‰æœ‰æ•ˆæ€§ã€‚</li>
<li>ç°æœ‰ç ”ç©¶æœªå……åˆ†ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦è¯„ä¼°TTSçš„æ•ˆç‡ã€‚</li>
<li>è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´æœ€ä½å»¶è¿Ÿã€‚</li>
<li>æå‡ºåˆ†æ”¯å¹¶è¡Œæ€§å’Œåºåˆ—å¹¶è¡Œæ€§ä¸¤ç§ä¼˜åŒ–å¹¶å‘é…ç½®çš„æ–¹æ³•ã€‚</li>
<li>é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•ï¼Œå»¶è¿Ÿä¼˜åŒ–TTSèƒ½åœ¨çŸ­æ—¶é—´å†…å®ç°è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚</li>
<li>å»¶è¿Ÿä¼˜åŒ–TTSåœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­èƒ½åŒæ—¶æé«˜é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚</li>
<li>é‡è§†å»¶è¿Ÿæ„ŸçŸ¥çš„TTSæ˜¯å¾ˆé‡è¦çš„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19634">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1e20890718528c2f1bb2901688234450.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-235616815750083229d9ac47ab79bf1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc11049b2a067213003b77acf7e59eda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fa7f64c34abc1a76feb38474c46ef11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cb2ab025abe0288742ee07fedafd092.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5c9a08d1815a39687e6ed039c7f59d70.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CosyVoice-3-Towards-In-the-wild-Speech-Generation-via-Scaling-up-and-Post-training"><a href="#CosyVoice-3-Towards-In-the-wild-Speech-Generation-via-Scaling-up-and-Post-training" class="headerlink" title="CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and   Post-training"></a>CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and   Post-training</h2><p><strong>Authors:Zhihao Du, Changfeng Gao, Yuxuan Wang, Fan Yu, Tianyu Zhao, Hao Wang, Xiang Lv, Hui Wang, Chongjia Ni, Xian Shi, Keyu An, Guanrou Yang, Yabin Li, Yanni Chen, Zhifu Gao, Qian Chen, Yue Gu, Mengzhe Chen, Yafeng Chen, Shiliang Zhang, Wen Wang, Jieping Ye</strong></p>
<p>In our prior works, we introduced a scalable streaming speech synthesis model, CosyVoice 2, which integrates a large language model (LLM) and a chunk-aware flow matching (FM) model, and achieves low-latency bi-streaming speech synthesis and human-parity quality. Despite these advancements, CosyVoice 2 exhibits limitations in language coverage, domain diversity, data volume, text formats, and post-training techniques. In this paper, we present CosyVoice 3, an improved model designed for zero-shot multilingual speech synthesis in the wild, surpassing its predecessor in content consistency, speaker similarity, and prosody naturalness. Key features of CosyVoice 3 include: 1) A novel speech tokenizer to improve prosody naturalness, developed via supervised multi-task training, including automatic speech recognition, speech emotion recognition, language identification, audio event detection, and speaker analysis. 2) A new differentiable reward model for post-training applicable not only to CosyVoice 3 but also to other LLM-based speech synthesis models. 3) Dataset Size Scaling: Training data is expanded from ten thousand hours to one million hours, encompassing 9 languages and 18 Chinese dialects across various domains and text formats. 4) Model Size Scaling: Model parameters are increased from 0.5 billion to 1.5 billion, resulting in enhanced performance on our multilingual benchmark due to the larger model capacity. These advancements contribute significantly to the progress of speech synthesis in the wild. We encourage readers to listen to the demo at <a target="_blank" rel="noopener" href="https://funaudiollm.github.io/cosyvoice3">https://funaudiollm.github.io/cosyvoice3</a>. </p>
<blockquote>
<p>åœ¨æˆ‘ä»¬ä¹‹å‰çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€æ¬¾å¯æ‰©å±•çš„æµå¼è¯­éŸ³åˆæˆæ¨¡å‹CosyVoice 2ï¼Œå®ƒé›†æˆäº†ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œä¸€å—åˆ†å—æ„ŸçŸ¥æµåŒ¹é…ï¼ˆFMï¼‰æ¨¡å‹ï¼Œå®ç°äº†ä½å»¶è¿ŸåŒæµå¼è¯­éŸ³åˆæˆå’Œä¸äººç±»ç›¸å½“çš„è´¨é‡ã€‚å°½ç®¡æœ‰äº†è¿™äº›è¿›æ­¥ï¼ŒCosyVoice 2åœ¨è¯­è¨€è¦†ç›–ã€é¢†åŸŸå¤šæ ·æ€§ã€æ•°æ®é‡ã€æ–‡æœ¬æ ¼å¼å’Œåç»­è®­ç»ƒæŠ€æœ¯æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†CosyVoice 3ï¼Œè¿™æ˜¯ä¸€æ¬¾æ”¹è¿›åçš„æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°é‡å¤–é›¶é•œå¤´å¤šè¯­è¨€è¯­éŸ³åˆæˆï¼Œåœ¨å†…å®¹ä¸€è‡´æ€§ã€æ¼”è®²è€…ç›¸ä¼¼æ€§å’Œè¯­è°ƒè‡ªç„¶æ€§æ–¹é¢è¶…è¶Šäº†å…¶å‰èº«ã€‚CosyVoice 3çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š1ï¼‰ä¸€ç§æ–°å‹è¯­éŸ³æ ‡è®°å™¨ï¼Œé€šè¿‡ç›‘ç£å¤šä»»åŠ¡è®­ç»ƒå¼€å‘ï¼Œæ—¨åœ¨æé«˜è¯­è°ƒçš„è‡ªç„¶æ€§ï¼ŒåŒ…æ‹¬è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ã€è¯­è¨€è¯†åˆ«ã€éŸ³é¢‘äº‹ä»¶æ£€æµ‹å’Œè¯´è¯äººåˆ†æã€‚2ï¼‰ä¸€ç§æ–°çš„å¯å¾®å¥–åŠ±æ¨¡å‹ï¼Œé€‚ç”¨äºè®­ç»ƒåçš„è®­ç»ƒï¼Œä¸ä»…é€‚ç”¨äºCosyVoice 3ï¼Œè€Œä¸”é€‚ç”¨äºå…¶ä»–åŸºäºLLMçš„è¯­éŸ³åˆæˆæ¨¡å‹ã€‚3ï¼‰æ•°æ®é›†å¤§å°ç¼©æ”¾ï¼šè®­ç»ƒæ•°æ®ä»ä¸€ä¸‡å°æ—¶æ‰©å±•åˆ°ä¸€ç™¾ä¸‡å°æ—¶ï¼Œæ¶µç›–9ç§è¯­è¨€å’Œ18ç§ä¸­æ–‡æ–¹è¨€ï¼Œè·¨è¶Šå„ç§é¢†åŸŸå’Œæ–‡æœ¬æ ¼å¼ã€‚4ï¼‰æ¨¡å‹å¤§å°ç¼©æ”¾ï¼šæ¨¡å‹å‚æ•°ä»0.5äº¿å¢åŠ åˆ°15äº¿ï¼Œç”±äºæ¨¡å‹å®¹é‡æ›´å¤§ï¼Œæˆ‘ä»¬çš„å¤šè¯­ç§åŸºå‡†æµ‹è¯•æ€§èƒ½å¾—åˆ°æå‡ã€‚è¿™äº›è¿›æ­¥å¯¹é‡å¤–è¯­éŸ³åˆæˆçš„è¿›å±•åšå‡ºäº†é‡å¤§è´¡çŒ®ã€‚æˆ‘ä»¬é¼“åŠ±è¯»è€…åœ¨<a target="_blank" rel="noopener" href="https://funaudiollm.github.io/cosyvoice3%E4%B8%8A%E5%90%AC%E5%8F%96%E6%BC%94%E7%A4%BA%E3%80%82">https://funaudiollm.github.io/cosyvoice3ä¸Šå¬å–æ¼”ç¤ºã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.17589v2">PDF</a> Preprint, work in progress</p>
<p><strong>Summary</strong><br>     æ–°ä¸€ä»£è¯­éŸ³åˆæˆæ¨¡å‹CosyVoice 3é—®ä¸–ï¼Œé›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸ä¸€ç³»åˆ—æ–°æŠ€æœ¯ï¼Œæ”¯æŒé›¶èµ·ç‚¹å¤šè¯­ç§è¯­éŸ³åˆæˆã€‚ç›¸æ¯”ä¸Šä¸€ä»£ï¼Œå®ƒåœ¨å†…å®¹ä¸€è‡´æ€§ã€è¯´è¯äººç›¸ä¼¼æ€§å’Œè¯­è°ƒè‡ªç„¶åº¦æ–¹é¢å–å¾—æ˜¾è‘—è¿›æ­¥ã€‚é‡‡ç”¨äº†å…¨æ–°çš„è¯­éŸ³åˆ†è¯å™¨ï¼Œèƒ½åº”å¯¹å„ç§è¯­éŸ³ä»»åŠ¡ã€‚æ¨å‡ºæ–°å‹å¯å¾®è°ƒèŠ‚å¥–åŠ±æ¨¡å‹ï¼Œæ‰©å¤§è®­ç»ƒæ•°æ®é›†è‡³ä¸€åƒä¸‡å°æ—¶ï¼Œæ¶µç›–ä¹ç§è¯­è¨€å’Œåå…«ç§ä¸­æ–‡æ–¹è¨€ã€‚æ¨¡å‹å‚æ•°å¢è‡³åäº”äº¿ï¼Œæ˜¾è‘—æå‡å¤šè¯­ç§åŸºå‡†æµ‹è¯•æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CosyVoice 3å¼•å…¥äº†æ–°å‹é›¶èµ·ç‚¹å¤šè¯­ç§è¯­éŸ³åˆæˆæŠ€æœ¯ï¼Œæé«˜äº†å†…å®¹ä¸€è‡´æ€§ã€è¯´è¯äººç›¸ä¼¼æ€§å’Œè¯­è°ƒè‡ªç„¶åº¦ã€‚</li>
<li>é‡‡ç”¨äº†å…¨æ–°çš„è¯­éŸ³åˆ†è¯å™¨ï¼Œé€šè¿‡å¤šä»»åŠ¡è®­ç»ƒæå‡è¯­è°ƒè‡ªç„¶åº¦ã€‚</li>
<li>æ¨å‡ºæ–°å‹å¯å¾®è°ƒèŠ‚å¥–åŠ±æ¨¡å‹ï¼Œé€‚ç”¨äºå¤šç§è¯­è¨€æ¨¡å‹ã€‚</li>
<li>è®­ç»ƒæ•°æ®é›†å¤§å¹…æ‰©å±•è‡³ä¸€åƒä¸‡å°æ—¶ï¼Œæ¶µç›–å¤šç§è¯­è¨€å’Œæ–¹è¨€ã€‚</li>
<li>æ¨¡å‹å‚æ•°å¢è‡³åäº”äº¿ï¼Œå¢å¼ºäº†å¤šè¯­ç§æ€§èƒ½è¡¨ç°ã€‚</li>
<li>æ–°æ¨¡å‹åœ¨å¤šç§é¢†åŸŸå’Œæ–‡æœ¬æ ¼å¼ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.17589">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a7352d250abd85e3ba1e29ce146bf593.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a151dcf188a216bc252c52f1eeb9500f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-becc3688ac33167ec55c47a327468b56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c3b320b2d2bf7d701dc185ecaa1938c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SoftCoT-Test-Time-Scaling-with-Soft-Chain-of-Thought-Reasoning"><a href="#SoftCoT-Test-Time-Scaling-with-Soft-Chain-of-Thought-Reasoning" class="headerlink" title="SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning"></a>SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning</h2><p><strong>Authors:Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao</strong></p>
<p>Test-Time Scaling (TTS) refers to approaches that improve reasoning performance by allocating extra computation during inference, without altering the modelâ€™s parameters. While existing TTS methods operate in a discrete token space by generating more intermediate steps, recent studies in Coconut and SoftCoT have demonstrated that thinking in the continuous latent space can further enhance the reasoning performance. Such latent thoughts encode informative thinking without the information loss associated with autoregressive token generation, sparking increased interest in continuous-space reasoning. Unlike discrete decoding, where repeated sampling enables exploring diverse reasoning paths, latent representations in continuous space are fixed for a given input, which limits diverse exploration, as all decoded paths originate from the same latent thought. To overcome this limitation, we introduce SoftCoT++ to extend SoftCoT to the Test-Time Scaling paradigm by enabling diverse exploration of thinking paths. Specifically, we perturb latent thoughts via multiple specialized initial tokens and apply contrastive learning to promote diversity among soft thought representations. Experiments across five reasoning benchmarks and two distinct LLM architectures demonstrate that SoftCoT++ significantly boosts SoftCoT and also outperforms SoftCoT with self-consistency scaling. Moreover, it shows strong compatibility with conventional scaling techniques such as self-consistency. Source code is available at <a target="_blank" rel="noopener" href="https://github.com/xuyige/SoftCoT">https://github.com/xuyige/SoftCoT</a>. </p>
<blockquote>
<p>æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰æ˜¯æŒ‡é€šè¿‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­åˆ†é…é¢å¤–çš„è®¡ç®—èµ„æºæ¥æé«˜æ¨ç†æ€§èƒ½çš„æ–¹æ³•ï¼Œè€Œä¸ä¼šæ”¹å˜æ¨¡å‹çš„å‚æ•°ã€‚è™½ç„¶ç°æœ‰çš„TTSæ–¹æ³•åœ¨ç¦»æ•£æ ‡è®°ç©ºé—´ä¸­è¿›è¡Œæ“ä½œï¼Œé€šè¿‡ç”Ÿæˆæ›´å¤šçš„ä¸­é—´æ­¥éª¤æ¥å·¥ä½œï¼Œä½†æœ€è¿‘çš„Coconutå’ŒSoftCoTç ”ç©¶è¡¨æ˜ï¼Œåœ¨è¿ç»­æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ€è€ƒå¯ä»¥è¿›ä¸€æ­¥æé«˜æ¨ç†æ€§èƒ½ã€‚è¿™ç§æ½œåœ¨çš„æƒ³æ³•å¯ä»¥ç¼–ç ä¿¡æ¯ä¸°å¯Œçš„æ€è€ƒè¿‡ç¨‹ï¼Œè€Œæ²¡æœ‰è‡ªå›å½’æ ‡è®°ç”Ÿæˆæ‰€å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ï¼Œè¿™å¼•å‘äº†äººä»¬å¯¹è¿ç»­ç©ºé—´æ¨ç†çš„æµ“åšå…´è¶£ã€‚ä¸ç¦»æ•£è§£ç ä¸åŒï¼Œç¦»æ•£è§£ç é€šè¿‡é‡å¤é‡‡æ ·å¯ä»¥æ¢ç´¢å¤šæ ·çš„æ¨ç†è·¯å¾„ï¼Œè€Œè¿ç»­ç©ºé—´ä¸­çš„æ½œåœ¨è¡¨ç¤ºå¯¹äºç»™å®šè¾“å…¥æ˜¯å›ºå®šçš„ï¼Œè¿™é™åˆ¶äº†å¤šæ ·çš„æ¢ç´¢ï¼Œå› ä¸ºæ‰€æœ‰è§£ç è·¯å¾„éƒ½æºäºç›¸åŒçš„æ½œåœ¨æƒ³æ³•ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥SoftCoT++ï¼Œå°†SoftCoTæ‰©å±•åˆ°æµ‹è¯•æ—¶ç¼©æ”¾èŒƒå¼ï¼Œé€šè¿‡ç‰¹æ®Šçš„åˆå§‹æ ‡è®°æ‰°åŠ¨æ€è€ƒè·¯å¾„ï¼Œå¹¶åº”ç”¨å¯¹æ¯”å­¦ä¹ æ¥ä¿ƒè¿›è½¯æ€è€ƒè¡¨ç¤ºä¹‹é—´çš„å¤šæ ·æ€§ã€‚åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•å’Œä¸¤ç§ä¸åŒçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¶æ„ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSoftCoT++æ˜¾è‘—æå‡äº†SoftCoTçš„æ€§èƒ½ï¼Œå¹¶ä¸”ä¼˜äºSoftCoTçš„è‡ªä¸€è‡´æ€§ç¼©æ”¾ã€‚æ­¤å¤–ï¼Œå®ƒæ˜¾ç¤ºå‡ºä¸å¸¸è§„ç¼©æ”¾æŠ€æœ¯ï¼ˆå¦‚è‡ªä¸€è‡´æ€§ï¼‰çš„å¼ºå¤§å…¼å®¹æ€§ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/xuyige/SoftCoT%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/xuyige/SoftCoTæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11484v2">PDF</a> 14 pages</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬æè¿°äº†Test-Time Scalingï¼ˆTTSï¼‰çš„æ¦‚å¿µåŠå…¶åœ¨æ¨ç†æ€§èƒ½æå‡æ–¹é¢çš„ä½œç”¨ã€‚ä¼ ç»ŸTTSæ–¹æ³•åœ¨ç¦»æ•£æ ‡è®°ç©ºé—´æ“ä½œï¼Œè€ŒCoconutå’ŒSoftCoTç ”ç©¶æ˜¾ç¤ºè¿ç»­æ½œåœ¨ç©ºé—´æ€è€ƒèƒ½æé«˜æ¨ç†æ€§èƒ½ã€‚ä¸ºå…‹æœè¿ç»­ç©ºé—´ä¸­æ½œåœ¨è¡¨ç¤ºå¸¦æ¥çš„æ¢ç´¢å¤šæ ·æ€§é™åˆ¶ï¼Œæå‡ºSoftCoT++æ–¹æ³•ï¼Œé€šè¿‡å¤šä¸ªä¸“ç”¨åˆå§‹æ ‡è®°æ‰°åŠ¨æ½œåœ¨æ€è€ƒï¼Œå¹¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹ ä¿ƒè¿›è½¯æ€è€ƒè¡¨ç¤ºä¹‹é—´çš„å¤šæ ·æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒSoftCoT++åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•å’Œä¸¤ä¸ªä¸åŒçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¶æ„ä¸Šæ˜¾è‘—æå‡äº†SoftCoTçš„æ€§èƒ½ï¼Œå¹¶ä¸”ä¸ä¼ ç»Ÿæ‰©å±•æŠ€æœ¯å¦‚è‡ªæˆ‘ä¸€è‡´æ€§æ‰©å±•å…¼å®¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Test-Time Scaling (TTS) æ˜¯æŒ‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­åˆ†é…é¢å¤–çš„è®¡ç®—èµ„æºä»¥æé«˜æ€§èƒ½ï¼Œè€Œä¸æ”¹å˜æ¨¡å‹çš„å‚æ•°ã€‚</li>
<li>ä¼ ç»ŸTTSæ–¹æ³•åœ¨ç¦»æ•£æ ‡è®°ç©ºé—´æ“ä½œï¼Œä½†è¿ç»­æ½œåœ¨ç©ºé—´æ€è€ƒèƒ½æé«˜æ¨ç†æ€§èƒ½ã€‚</li>
<li>SoftCoT++æ–¹æ³•é€šè¿‡å¤šä¸ªä¸“ç”¨åˆå§‹æ ‡è®°æ‰°åŠ¨æ½œåœ¨æ€è€ƒï¼Œä¿ƒè¿›æ¨ç†è¿‡ç¨‹ä¸­çš„å¤šæ ·æ€§æ¢ç´¢ã€‚</li>
<li>SoftCoT++æ˜¾è‘—æå‡äº†SoftCoTçš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>SoftCoT++ä¸ä¼ ç»Ÿæ‰©å±•æŠ€æœ¯å¦‚è‡ªæˆ‘ä¸€è‡´æ€§æ‰©å±•å…¼å®¹ã€‚</li>
<li>è¿ç»­ç©ºé—´æ€è€ƒå‡å°‘äº†ä¿¡æ¯æŸå¤±ï¼Œä¸åŒäºç¦»æ•£è§£ç çš„é‡å¤é‡‡æ ·èƒ½å¤Ÿæ¢ç´¢ä¸åŒçš„æ¨ç†è·¯å¾„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11484">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d2acca183235a222b1ca6a2aa8c76020.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d2382ea27746d2e90e5e24c55497ccfc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec8f495f6f4e58fe912ea8227a6d7907.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Rethinking-MUSHRA-Addressing-Modern-Challenges-in-Text-to-Speech-Evaluation"><a href="#Rethinking-MUSHRA-Addressing-Modern-Challenges-in-Text-to-Speech-Evaluation" class="headerlink" title="Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech   Evaluation"></a>Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech   Evaluation</h2><p><strong>Authors:Praveen Srinivasa Varadhan, Amogh Gulati, Ashwin Sankar, Srija Anand, Anirudh Gupta, Anirudh Mukherjee, Shiva Kumar Marepally, Ankur Bhatia, Saloni Jaju, Suvrat Bhooshan, Mitesh M. Khapra</strong></p>
<p>Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOSâ€™s pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 492 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) reference-matching bias, where raters are unduly influenced by the human reference, and (ii) judgement ambiguity, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 246,000 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems. </p>
<blockquote>
<p>å°½ç®¡TTSæ¨¡å‹å‘å±•è¿…é€Ÿï¼Œä½†ç¼ºä¹ä¸€ä¸ªç¨³å®šä¸”å¼ºå¤§çš„äººç±»è¯„ä¼°æ¡†æ¶ã€‚ä¾‹å¦‚ï¼ŒMOSæµ‹è¯•æ— æ³•åŒºåˆ†ç›¸ä¼¼çš„æ¨¡å‹ï¼ŒCMOSçš„é…å¯¹æ¯”è¾ƒåˆå¾ˆè€—æ—¶ã€‚MUSHRAæµ‹è¯•æ˜¯è¯„ä¼°å¤šä¸ªTTSç³»ç»Ÿçš„ä¸€ä¸ªå¾ˆæœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ³•ï¼Œä½†åœ¨è¿™é¡¹å·¥ä½œä¸­æˆ‘ä»¬å‘ç°ï¼Œå®ƒå¯¹åŒ¹é…äººç±»å‚è€ƒè¯­éŸ³çš„ä¾èµ–ï¼Œè¿‡åˆ†åœ°æƒ©ç½šäº†ç°ä»£TTSç³»ç»Ÿçš„å¾—åˆ†ï¼Œè¿™äº›ç³»ç»Ÿçš„è¯­éŸ³è´¨é‡ç”šè‡³è¶…è¿‡äº†äººç±»ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å¯¹MUSHRAæµ‹è¯•è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œé‡ç‚¹ç ”ç©¶å…¶å¯¹è¯„åˆ†è€…å·®å¼‚æ€§ã€å¬ä¼—ç–²åŠ³å’Œå‚è€ƒåè§ç­‰å› ç´ çš„æ•æ„Ÿæ€§ã€‚åŸºäºæ¶‰åŠå°åº¦è¯­å’Œæ³°ç±³å°”è¯­å…±492åå¬ä¼—çš„å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šï¼ˆiï¼‰å‚è€ƒåŒ¹é…åè§ï¼Œè¯„åˆ†è€…å—åˆ°äººä¸ºå‚è€ƒçš„è¿‡åº¦å½±å“ï¼›ï¼ˆiiï¼‰ç”±äºç¼ºå°‘æ˜ç¡®çš„ç²¾ç»†æŒ‡å¯¼è€Œäº§ç”Ÿçš„åˆ¤æ–­æ¨¡ç³Šæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ”¹è¿›çš„MUSHRAæµ‹è¯•å˜ç§ã€‚ç¬¬ä¸€ç§å˜ä½“å…è®¸å¯¹è¶…è¶Šäººç±»å‚è€ƒè´¨é‡çš„åˆæˆæ ·æœ¬è¿›è¡Œæ›´å…¬å¹³çš„è¯„åˆ†ã€‚ç¬¬äºŒç§å˜ä½“é€šè¿‡å‡å°‘è¯„åˆ†è€…ä¹‹é—´çš„ç›¸å¯¹è¾ƒä½çš„æ–¹å·®æ¥é™ä½æ¨¡ç³Šæ€§ã€‚é€šè¿‡ç»“åˆè¿™ä¸¤ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å®ç°äº†æ›´å¯é ã€æ›´ç²¾ç»†çš„è¯„ä¼°ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†MANGOæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªäººç±»è¯„åˆ†çš„å·¨å¤§æ•°æ®é›†ï¼ŒåŒ…å«24ä¸‡6åƒæ¡è¯„åˆ†ï¼Œæ˜¯å°åº¦è¯­è¨€é¢†åŸŸé¦–åˆ›çš„æ­¤ç±»æ•°æ®é›†ï¼Œæœ‰åŠ©äºåˆ†æäººç±»åå¥½å¹¶å¼€å‘ç”¨äºè¯„ä¼°TTSç³»ç»Ÿçš„è‡ªåŠ¨åº¦é‡æŒ‡æ ‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.12719v3">PDF</a> Accepted in TMLR</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†TTSæ¨¡å‹è¯„ä¼°ä¸­å­˜åœ¨çš„é—®é¢˜ã€‚å°½ç®¡TTSæŠ€æœ¯å‘å±•è¿…é€Ÿï¼Œä½†ä»ç¼ºä¹ä¸€è‡´ä¸”ç¨³å¥çš„äººæœºè¯„ä¼°æ¡†æ¶ã€‚ç°æœ‰çš„MOSæµ‹è¯•æ— æ³•åŒºåˆ†ç›¸ä¼¼æ¨¡å‹ï¼ŒCMOSçš„æˆå¯¹æ¯”è¾ƒåˆ™è€—æ—¶è¿‡é•¿ã€‚MUSHRAæµ‹è¯•æ˜¯ä¸€ç§æœ‰æœ›åŒæ—¶è¯„ä¼°å¤šä¸ªTTSç³»ç»Ÿçš„æµ‹è¯•æ–¹æ³•ï¼Œä½†å®ƒä¾èµ–åŒ¹é…äººç±»å‚è€ƒè¯­éŸ³ï¼Œå¯¹ç°ä»£è¶…è¿‡äººç±»è¯­éŸ³è´¨é‡çš„TTSç³»ç»Ÿæœ‰æ‰€ä¸å…¬ã€‚æœ¬æ–‡å¯¹MUSHRAæµ‹è¯•è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨è¯„å§”å·®å¼‚æ€§ã€å¬è€…ç–²åŠ³å’Œå‚è€ƒåè§ç­‰å› ç´ çš„å½±å“ã€‚é€šè¿‡æ¶‰åŠå°åœ°è¯­å’Œæ³°ç±³å°”è¯­çš„492åäººç±»å¬è€…çš„å¹¿æ³›è¯„ä¼°ï¼Œå‘ç°äº†ä¸¤å¤§é—®é¢˜ï¼šä¸€æ˜¯å‚è€ƒåŒ¹é…åè§ï¼Œè¯„å§”å—åˆ°äººç±»å‚è€ƒçš„ä¸å½“å½±å“ï¼›äºŒæ˜¯åˆ¤æ–­æ¨¡ç³Šï¼Œç”±äºç¼ºä¹æ˜ç¡®çš„ç»†åˆ†æŒ‡å—ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸¤ç§æ”¹è¿›çš„MUSHRAæµ‹è¯•æ–¹æ³•ï¼Œä¸€ç§ä¸ºåˆæˆæ ·æœ¬è¶…è¿‡äººç±»å‚è€ƒè´¨é‡æä¾›æ›´å…¬å¹³çš„è¯„åˆ†ï¼Œå¦ä¸€ç§å‡å°‘æ¨¡ç³Šæ€§ï¼Œé™ä½è¯„å§”ä¹‹é—´çš„æ–¹å·®ã€‚æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†MANGOæ•°æ®é›†ï¼ŒåŒ…å«24.6ä¸‡æ¡äººç±»è¯„åˆ†ï¼Œæˆä¸ºå°åº¦è¯­è¨€é¢†åŸŸçš„é¦–åˆ›é›†åˆï¼Œæœ‰åŠ©äºåˆ†æäººç±»åå¥½å¹¶ä¸ºTTSç³»ç»Ÿçš„å‘å±•æä¾›è‡ªåŠ¨åº¦é‡æ ‡å‡†ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>TTSé¢†åŸŸç¼ºä¹ä¸€è‡´ä¸”ç¨³å¥çš„äººæœºè¯„ä¼°æ¡†æ¶ï¼Œç°æœ‰æµ‹è¯•æ–¹æ³•å­˜åœ¨ç¼ºé™·ã€‚</li>
<li>MUSHRAæµ‹è¯•æ˜¯ä¸€ç§æœ‰å‰é€”çš„è¯„ä¼°æ–¹æ³•ï¼Œä½†å­˜åœ¨å‚è€ƒåŒ¹é…åè§å’Œå¯¹ç°ä»£TTSç³»ç»Ÿçš„è¯„åˆ†ä¸å…¬é—®é¢˜ã€‚</li>
<li>é€šè¿‡å¹¿æ³›è¯„ä¼°å‘ç°è¯„å§”å·®å¼‚æ€§ã€å¬è€…ç–²åŠ³å’Œå‚è€ƒåè§ç­‰å› ç´ å½±å“MUSHRAæµ‹è¯•çš„å‡†ç¡®æ€§ã€‚</li>
<li>æå‡ºä¸¤ç§æ”¹è¿›çš„MUSHRAæµ‹è¯•æ–¹æ³•ï¼Œæ—¨åœ¨æ›´å…¬å¹³åœ°è¯„ä¼°è¶…è¿‡äººç±»å‚è€ƒè´¨é‡çš„TTSç³»ç»Ÿå¹¶å‡å°‘åˆ¤æ–­æ¨¡ç³Šæ€§ã€‚</li>
<li>å‘å¸ƒäº†MANGOæ•°æ®é›†ï¼Œæˆä¸ºå°åº¦è¯­è¨€é¢†åŸŸçš„é¦–åˆ›å¤§è§„æ¨¡äººç±»è¯„åˆ†é›†åˆï¼Œæœ‰åŠ©äºåˆ†æäººç±»åå¥½å’Œå‘å±•TTSç³»ç»Ÿçš„è‡ªåŠ¨åº¦é‡æ ‡å‡†ã€‚</li>
<li>æ•°æ®é›†åŒ…å«ä¸°å¯Œçš„è¯­éŸ³æ ·æœ¬å’Œè¯„åˆ†æ•°æ®ï¼Œä¸ºæ·±å…¥ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.12719">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8de2ae4d28c9195f7096460090da067c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-91ee62cc7411685dfeddd28fa1220a37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d62a5eae999578a945d67fd015fb7bbd.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Autoregressive-Speech-Synthesis-without-Vector-Quantization"><a href="#Autoregressive-Speech-Synthesis-without-Vector-Quantization" class="headerlink" title="Autoregressive Speech Synthesis without Vector Quantization"></a>Autoregressive Speech Synthesis without Vector Quantization</h2><p><strong>Authors:Lingwei Meng, Long Zhou, Shujie Liu, Sanyuan Chen, Bing Han, Shujie Hu, Yanqing Liu, Jinyu Li, Sheng Zhao, Xixin Wu, Helen Meng, Furu Wei</strong></p>
<p>We present MELLE, a novel continuous-valued token based language modeling approach for text-to-speech synthesis (TTS). MELLE autoregressively generates continuous mel-spectrogram frames directly from text condition, bypassing the need for vector quantization, which is typically designed for audio compression and sacrifices fidelity compared to continuous representations. Specifically, (i) instead of cross-entropy loss, we apply regression loss with a proposed spectrogram flux loss function to model the probability distribution of the continuous-valued tokens; (ii) we have incorporated variational inference into MELLE to facilitate sampling mechanisms, thereby enhancing the output diversity and model robustness. Experiments demonstrate that, compared to the two-stage codec language model VALL-E and its variants, the single-stage MELLE mitigates robustness issues by avoiding the inherent flaws of sampling vector-quantized codes, achieves superior performance across multiple metrics, and, most importantly, offers a more streamlined paradigm. The demos of our work are provided at <a target="_blank" rel="noopener" href="https://aka.ms/melle">https://aka.ms/melle</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†MELLEï¼Œè¿™æ˜¯ä¸€ç§åŸºäºè¿ç»­å€¼æ ‡è®°çš„æ–°çš„æ–‡æœ¬è½¬è¯­éŸ³åˆæˆï¼ˆTTSï¼‰è¯­è¨€å»ºæ¨¡æ–¹æ³•ã€‚MELLEé€šè¿‡æ–‡æœ¬æ¡ä»¶ç›´æ¥è‡ªå›å½’ç”Ÿæˆè¿ç»­çš„æ¢…å°”é¢‘è°±å¸§ï¼Œé¿å…äº†å‘é‡é‡åŒ–çš„éœ€è¦ã€‚å‘é‡é‡åŒ–é€šå¸¸æ˜¯ä¸ºéŸ³é¢‘å‹ç¼©è®¾è®¡çš„ï¼Œç›¸è¾ƒäºè¿ç»­è¡¨ç¤ºå½¢å¼ç‰ºç‰²äº†ä¿çœŸåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œï¼ˆiï¼‰æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œè€Œæ˜¯åº”ç”¨äº†å›å½’æŸå¤±å’Œæå‡ºçš„é¢‘è°±æµæŸå¤±å‡½æ•°æ¥æ¨¡æ‹Ÿè¿ç»­å€¼æ ‡è®°çš„æ¦‚ç‡åˆ†å¸ƒï¼›ï¼ˆiiï¼‰æˆ‘ä»¬å°†å˜åˆ†æ¨æ–­èå…¥MELLEï¼Œä»¥ä¼˜åŒ–é‡‡æ ·æœºåˆ¶ï¼Œä»è€Œæé«˜äº†è¾“å‡ºå¤šæ ·æ€§å’Œæ¨¡å‹ç¨³å¥æ€§ã€‚å®éªŒè¯æ˜ï¼Œç›¸è¾ƒäºä¸¤é˜¶æ®µç¼–ç è¯­è¨€æ¨¡å‹VALL-EåŠå…¶å˜ä½“ï¼Œå•é˜¶æ®µçš„MELLEé€šè¿‡é¿å…é‡‡æ ·å‘é‡é‡åŒ–ç çš„å›ºæœ‰ç¼ºé™·ï¼Œè§£å†³äº†ç¨³å¥æ€§é—®é¢˜ï¼Œåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œå¹¶ä¸”æœ€é‡è¦çš„æ˜¯ï¼Œæä¾›äº†æ›´ä¸ºç®€æ´çš„æ¨¡å¼ã€‚æˆ‘ä»¬çš„å·¥ä½œæ¼”ç¤ºåœ°å€ä¸º<a target="_blank" rel="noopener" href="https://aka.ms/melle%E3%80%82">https://aka.ms/melleã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.08551v2">PDF</a> Accepted to ACL 2025 Main</p>
<p><strong>Summary</strong><br>MELLEæ˜¯ä¸€ç§åŸºäºè¿ç»­å€¼ä»¤ç‰Œçš„è¯­è¨€å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆTTSï¼‰ã€‚å®ƒç›´æ¥ç”Ÿæˆè¿ç»­çš„æ¢…å°”é¢‘è°±å¸§ï¼Œç»•è¿‡å‘é‡é‡åŒ–çš„éœ€æ±‚ï¼Œä»è€Œæé«˜äº†éŸ³é¢‘è´¨é‡ã€‚è¯¥æ–¹æ³•ä½¿ç”¨å›å½’æŸå¤±å’Œæå‡ºçš„é¢‘è°±æµæŸå¤±å‡½æ•°å»ºæ¨¡è¿ç»­å€¼ä»¤ç‰Œçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶èå…¥å˜åˆ†æ¨æ–­æé«˜é‡‡æ ·æœºåˆ¶å’Œæ¨¡å‹ç¨³å¥æ€§ã€‚å®éªŒè¯æ˜ï¼Œç›¸æ¯”ä¸¤é˜¶æ®µç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹VALL-EåŠå…¶å˜ä½“ï¼Œå•é˜¶æ®µçš„MELLEé¿å…äº†é‡‡æ ·å‘é‡é‡åŒ–ä»£ç çš„å›ºæœ‰ç¼ºé™·ï¼Œå®ç°äº†è·¨å¤šä¸ªæŒ‡æ ‡çš„ä¼˜è¶Šæ€§èƒ½ï¼Œå¹¶æä¾›äº†æ›´ç®€æ´çš„èŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MELLEæ˜¯ä¸€ç§æ–°å‹çš„è¿ç»­å€¼ä»¤ç‰Œè¯­è¨€å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆTTSï¼‰ã€‚</li>
<li>MELLEç›´æ¥ç”Ÿæˆè¿ç»­çš„æ¢…å°”é¢‘è°±å¸§ï¼Œé¿å…äº†å‘é‡é‡åŒ–çš„éœ€æ±‚ï¼Œä»è€Œæé«˜éŸ³é¢‘è´¨é‡ã€‚</li>
<li>ä½¿ç”¨å›å½’æŸå¤±å’Œé¢‘è°±æµæŸå¤±å‡½æ•°å»ºæ¨¡è¿ç»­å€¼ä»¤ç‰Œçš„æ¦‚ç‡åˆ†å¸ƒã€‚</li>
<li>å˜åˆ†æ¨æ–­è¢«èå…¥MELLEä»¥æé«˜é‡‡æ ·æœºåˆ¶å’Œæ¨¡å‹ç¨³å¥æ€§ã€‚</li>
<li>MELLEç›¸æ¯”ä¸¤é˜¶æ®µç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹VALL-EåŠå…¶å˜ä½“ï¼Œåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå®ç°ä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>MELLEé¿å…äº†é‡‡æ ·å‘é‡é‡åŒ–ä»£ç çš„å›ºæœ‰ç¼ºé™·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.08551">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ea5639a13fcda3600c5da98d3fc1dd31.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a2810e80e26ecc6acffc9a29bd8f08a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-29/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-29/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-29/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-819d5efdc144be34311fc6a378eef33a.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-29  Def-DTS Deductive Reasoning for Open-domain Dialogue Topic Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3f5337319b388f01414425415e9f8148.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-29  Lunguage A Benchmark for Structured and Sequential Chest X-ray   Interpretation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29997.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
