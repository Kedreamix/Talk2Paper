<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-29  MV-CoLight Efficient Object Compositing with Consistent Lighting and   Shadow Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-e9d62d46d4fab2648e6c917f2ba49b45.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-31
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    71 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-29-æ›´æ–°"><a href="#2025-05-29-æ›´æ–°" class="headerlink" title="2025-05-29 æ›´æ–°"></a>2025-05-29 æ›´æ–°</h1><h2 id="MV-CoLight-Efficient-Object-Compositing-with-Consistent-Lighting-and-Shadow-Generation"><a href="#MV-CoLight-Efficient-Object-Compositing-with-Consistent-Lighting-and-Shadow-Generation" class="headerlink" title="MV-CoLight: Efficient Object Compositing with Consistent Lighting and   Shadow Generation"></a>MV-CoLight: Efficient Object Compositing with Consistent Lighting and   Shadow Generation</h2><p><strong>Authors:Kerui Ren, Jiayang Bai, Linning Xu, Lihan Jiang, Jiangmiao Pang, Mulin Yu, Bo Dai</strong></p>
<p>Object compositing offers significant promise for augmented reality (AR) and embodied intelligence applications. Existing approaches predominantly focus on single-image scenarios or intrinsic decomposition techniques, facing challenges with multi-view consistency, complex scenes, and diverse lighting conditions. Recent inverse rendering advancements, such as 3D Gaussian and diffusion-based methods, have enhanced consistency but are limited by scalability, heavy data requirements, or prolonged reconstruction time per scene. To broaden its applicability, we introduce MV-CoLight, a two-stage framework for illumination-consistent object compositing in both 2D images and 3D scenes. Our novel feed-forward architecture models lighting and shadows directly, avoiding the iterative biases of diffusion-based methods. We employ a Hilbert curve-based mapping to align 2D image inputs with 3D Gaussian scene representations seamlessly. To facilitate training and evaluation, we further introduce a large-scale 3D compositing dataset. Experiments demonstrate state-of-the-art harmonized results across standard benchmarks and our dataset, as well as casually captured real-world scenes demonstrate the frameworkâ€™s robustness and wide generalization. </p>
<blockquote>
<p>å¯¹è±¡åˆæˆæŠ€æœ¯åœ¨å¢å¼ºç°å®ï¼ˆARï¼‰å’Œæ™ºèƒ½å®ä½“åº”ç”¨æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å•å›¾åƒåœºæ™¯æˆ–å†…åœ¨åˆ†è§£æŠ€æœ¯ä¸Šï¼Œé¢ä¸´å¤šè§†è§’ä¸€è‡´æ€§ã€å¤æ‚åœºæ™¯å’Œå¤šå˜å…‰ç…§æ¡ä»¶ä¸‹çš„æŒ‘æˆ˜ã€‚æœ€è¿‘çš„é€†å‘æ¸²æŸ“æŠ€æœ¯è¿›å±•ï¼Œå¦‚åŸºäºä¸‰ç»´é«˜æ–¯å’Œæ‰©æ•£çš„æ–¹æ³•ï¼Œæé«˜äº†ä¸€è‡´æ€§ï¼Œä½†å—é™äºå¯æ‰©å±•æ€§ã€ç¹é‡çš„æ•°æ®éœ€æ±‚æˆ–æ¯ä¸ªåœºæ™¯çš„é‡å»ºæ—¶é—´å»¶é•¿ã€‚ä¸ºäº†æ‰©å¤§å…¶åº”ç”¨èŒƒå›´ï¼Œæˆ‘ä»¬å¼•å…¥äº†MV-CoLightï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„ç…§æ˜ä¸€è‡´æ€§å¯¹è±¡åˆæˆæ¡†æ¶ï¼Œé€‚ç”¨äºäºŒç»´å›¾åƒå’Œä¸‰ç»´åœºæ™¯ã€‚æˆ‘ä»¬æ–°é¢–çš„å‰é¦ˆæ¶æ„ç›´æ¥å¯¹å…‰çº¿å’Œé˜´å½±è¿›è¡Œå»ºæ¨¡ï¼Œé¿å…äº†åŸºäºæ‰©æ•£æ–¹æ³•çš„è¿­ä»£åè§ã€‚æˆ‘ä»¬é‡‡ç”¨åŸºäºHilbertæ›²çº¿çš„æ˜ å°„ï¼Œæ— ç¼åœ°å°†äºŒç»´å›¾åƒè¾“å…¥ä¸ä¸‰ç»´é«˜æ–¯åœºæ™¯è¡¨ç¤ºå¯¹é½ã€‚ä¸ºäº†ä¿ƒè¿›è®­ç»ƒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„ä¸‰ç»´åˆæˆæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•é›†å’Œæˆ‘ä»¬è‡ªå·±çš„æ•°æ®é›†ä¸Šéƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„å’Œè°ç»“æœï¼Œè€Œåœ¨éšæ„æ•æ‰çš„çœŸå®ä¸–ç•Œåœºæ™¯ä¸­ä¹Ÿè¯æ˜äº†è¯¥æ¡†æ¶çš„ç¨³å¥æ€§å’Œå¹¿æ³›é€šç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21483v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¯¹è±¡åˆæˆæŠ€æœ¯åœ¨å¢å¼ºç°å®ï¼ˆARï¼‰å’Œå…·èº«æ™ºèƒ½åº”ç”¨æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•åœºæ™¯æˆ–å†…åœ¨åˆ†è§£æŠ€æœ¯ï¼Œé¢ä¸´å¤šè§†å›¾ä¸€è‡´æ€§ã€å¤æ‚åœºæ™¯å’Œå¤šå˜å…‰ç…§æ¡ä»¶ä¸‹çš„æŒ‘æˆ˜ã€‚è¿‘æœŸé€†å‘æ¸²æŸ“æŠ€æœ¯çš„è¿›å±•ï¼Œå¦‚3Dé«˜æ–¯å’Œæ‰©æ•£æ–¹æ³•ï¼Œæé«˜äº†ä¸€è‡´æ€§ï¼Œä½†å—é™äºå¯æ‰©å±•æ€§ã€å¤§é‡æ•°æ®éœ€æ±‚æˆ–é‡å»ºæ—¶é—´ã€‚ä¸ºæ‰©å¤§å…¶åº”ç”¨èŒƒå›´ï¼Œæˆ‘ä»¬æå‡ºMV-CoLightæ¡†æ¶ï¼Œç”¨äºäºŒç»´å›¾åƒå’Œä¸‰ç»´åœºæ™¯çš„å…‰ç…§ä¸€è‡´æ€§å¯¹è±¡åˆæˆã€‚æˆ‘ä»¬çš„æ–°å‹å‰é¦ˆæ¶æ„ç›´æ¥å»ºæ¨¡å…‰ç…§å’Œé˜´å½±ï¼Œé¿å…äº†æ‰©æ•£æ–¹æ³•çš„è¿­ä»£åå·®ã€‚é‡‡ç”¨Hilbertæ›²çº¿æ˜ å°„æ— ç¼å¯¹æ¥äºŒç»´å›¾åƒè¾“å…¥å’Œä¸‰ç»´é«˜æ–¯åœºæ™¯è¡¨ç¤ºã€‚ä¸ºè¿›ä¸€æ­¥è®­ç»ƒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥å¤§è§„æ¨¡ä¸‰ç»´åˆæˆæ•°æ®é›†ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•åŠæ•°æ®é›†ä¸­å‡è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶ä¸”åœ¨æ—¥å¸¸æ•è·çš„çœŸå®åœºæ™¯ä¸­è¯æ˜äº†è¯¥æ¡†æ¶çš„é²æ£’æ€§å’Œå¹¿æ³›é€‚åº”æ€§ã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>å¯¹è±¡åˆæˆæŠ€æœ¯å¯¹äºå¢å¼ºç°å®å’Œå…·èº«æ™ºèƒ½åº”ç”¨å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é¢ä¸´å¤šè§†å›¾ä¸€è‡´æ€§ã€å¤æ‚åœºæ™¯å’Œå¤šå˜å…‰ç…§æ¡ä»¶çš„æŒ‘æˆ˜ã€‚</li>
<li>MV-CoLightæ¡†æ¶é€šè¿‡å‰é¦ˆæ¶æ„ç›´æ¥å»ºæ¨¡å…‰ç…§å’Œé˜´å½±ï¼Œæé«˜äº†ä¸€è‡´æ€§ã€‚</li>
<li>é‡‡ç”¨Hilbertæ›²çº¿æ˜ å°„å®ç°äºŒç»´å›¾åƒå’Œä¸‰ç»´åœºæ™¯çš„æ— ç¼å¯¹æ¥ã€‚</li>
<li>å¼•å…¥å¤§è§„æ¨¡ä¸‰ç»´åˆæˆæ•°æ®é›†ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ ‡å‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-90a9d875218bf0167fee8f89989ecb6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ae97af057bd62bcc2abb69f84c2b503.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a7c522c0c0c8857a7f9a5f4116fc3bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da5ccb00ec754a1407c7435a4177926c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Empowering-Vector-Graphics-with-Consistently-Arbitrary-Viewing-and-View-dependent-Visibility"><a href="#Empowering-Vector-Graphics-with-Consistently-Arbitrary-Viewing-and-View-dependent-Visibility" class="headerlink" title="Empowering Vector Graphics with Consistently Arbitrary Viewing and   View-dependent Visibility"></a>Empowering Vector Graphics with Consistently Arbitrary Viewing and   View-dependent Visibility</h2><p><strong>Authors:Yidi Li, Jun Xiao, Zhengda Lu, Yiqun Wang, Haiyong Jiang</strong></p>
<p>This work presents a novel text-to-vector graphics generation approach, Dream3DVG, allowing for arbitrary viewpoint viewing, progressive detail optimization, and view-dependent occlusion awareness. Our approach is a dual-branch optimization framework, consisting of an auxiliary 3D Gaussian Splatting optimization branch and a 3D vector graphics optimization branch. The introduced 3DGS branch can bridge the domain gaps between text prompts and vector graphics with more consistent guidance. Moreover, 3DGS allows for progressive detail control by scheduling classifier-free guidance, facilitating guiding vector graphics with coarse shapes at the initial stages and finer details at later stages. We also improve the view-dependent occlusions by devising a visibility-awareness rendering module. Extensive results on 3D sketches and 3D iconographies, demonstrate the superiority of the method on different abstraction levels of details, cross-view consistency, and occlusion-aware stroke culling. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢çš„ç”Ÿæˆæ–¹æ³•Dream3DVGï¼Œå®ƒæ”¯æŒä»»æ„è§†è§’è§‚çœ‹ã€æ¸è¿›çš„ç»†èŠ‚ä¼˜åŒ–å’Œè§†ç›¸å…³çš„é®æŒ¡æ„è¯†ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¯ä¸€ä¸ªåŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸€ä¸ªè¾…åŠ©çš„3Dé«˜æ–¯å–·ç»˜ä¼˜åŒ–åˆ†æ”¯å’Œä¸€ä¸ª3DçŸ¢é‡å›¾å½¢ä¼˜åŒ–åˆ†æ”¯ã€‚å¼•å…¥çš„3DGSåˆ†æ”¯èƒ½å¤Ÿå¡«è¡¥æ–‡æœ¬æç¤ºå’ŒçŸ¢é‡å›¾å½¢ä¹‹é—´çš„é¢†åŸŸå·®è·ï¼Œæä¾›æ›´ä¸€è‡´çš„æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œ3DGSé€šè¿‡è°ƒåº¦æ— åˆ†ç±»æŒ‡å¯¼æ¥å®ç°æ¸è¿›çš„ç»†èŠ‚æ§åˆ¶ï¼Œä¾¿äºåœ¨åˆå§‹é˜¶æ®µå¼•å¯¼å…·æœ‰ç²—ç•¥å½¢çŠ¶çš„çŸ¢é‡å›¾å½¢ï¼Œåœ¨åç»­é˜¶æ®µå¼•å¯¼æ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚æˆ‘ä»¬è¿˜é€šè¿‡è®¾è®¡å¯è§æ€§æ„ŸçŸ¥æ¸²æŸ“æ¨¡å—æ¥æ”¹å–„è§†ç›¸å…³çš„é®æŒ¡é—®é¢˜ã€‚åœ¨3Dè‰å›¾å’Œä¸‰ç»´å›¾æ ‡çš„å¤§é‡ç»“æœä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒæŠ½è±¡å±‚æ¬¡ä¸Šçš„ç»†èŠ‚ã€è·¨è§†å›¾ä¸€è‡´æ€§å’Œé®æŒ¡æ„ŸçŸ¥ç¬”ç”»å‰”é™¤æ–¹é¢çš„ä¼˜è¶Šæ€§å¾—åˆ°äº†è¯æ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21377v1">PDF</a> CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢çš„ç”Ÿæˆæ–¹æ³•Dream3DVGï¼Œæ”¯æŒä»»æ„è§†è§’æµè§ˆã€æ¸è¿›çš„ç»†èŠ‚ä¼˜åŒ–å’Œè§†è§’ç›¸å…³çš„é®æŒ¡æ„ŸçŸ¥ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…æ‹¬è¾…åŠ©çš„3Dé«˜æ–¯å¹³é“ºä¼˜åŒ–åˆ†æ”¯å’Œ3DçŸ¢é‡å›¾å½¢ä¼˜åŒ–åˆ†æ”¯ã€‚å¼•å…¥çš„3DGSåˆ†æ”¯èƒ½å¤Ÿç¼©å°æ–‡æœ¬æç¤ºå’ŒçŸ¢é‡å›¾å½¢ä¹‹é—´çš„é¢†åŸŸå·®è·ï¼Œæä¾›æ›´ä¸€è‡´çš„æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œ3DGSé€šè¿‡è°ƒåº¦æ— åˆ†ç±»æŒ‡å¯¼æ¥å®ç°æ¸è¿›çš„ç»†èŠ‚æ§åˆ¶ï¼Œä¾¿äºåœ¨æ—©æœŸé˜¶æ®µä»¥ç²—ç•¥å½¢çŠ¶å¼•å¯¼çŸ¢é‡å›¾å½¢ï¼Œåœ¨åæœŸåŠ å…¥æ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚åŒæ—¶ï¼Œé€šè¿‡è®¾è®¡å¯è§æ€§æ„ŸçŸ¥æ¸²æŸ“æ¨¡å—ï¼Œæé«˜äº†è§†è§’ç›¸å…³çš„é®æŒ¡å¤„ç†æ•ˆæœã€‚åœ¨3Dè‰å›¾å’Œä¸‰ç»´å›¾æ ‡ä¸Šçš„å¹¿æ³›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒå±‚æ¬¡çš„ç»†èŠ‚ã€è·¨è§†è§’ä¸€è‡´æ€§å’Œé®æŒ¡æ„ŸçŸ¥æè¾¹å‰”é™¤æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Dream3DVGæ˜¯ä¸€ç§æ–°å‹çš„æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢çš„ç”Ÿæˆæ–¹æ³•ï¼Œæ”¯æŒä»»æ„è§†è§’æµè§ˆã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨åŒåˆ†æ”¯ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…æ‹¬3Dé«˜æ–¯å¹³é“ºä¼˜åŒ–åˆ†æ”¯å’Œ3DçŸ¢é‡å›¾å½¢ä¼˜åŒ–åˆ†æ”¯ã€‚</li>
<li>3DGSåˆ†æ”¯èƒ½å¤Ÿç¼©å°æ–‡æœ¬æç¤ºå’ŒçŸ¢é‡å›¾å½¢ä¹‹é—´çš„é¢†åŸŸå·®è·ï¼Œæä¾›æ›´ä¸€è‡´çš„æŒ‡å¯¼ã€‚</li>
<li>3DGSå®ç°æ¸è¿›çš„ç»†èŠ‚ä¼˜åŒ–ï¼Œæ—©æœŸä»¥ç²—ç•¥å½¢çŠ¶å¼•å¯¼çŸ¢é‡å›¾å½¢ï¼ŒåæœŸåŠ å…¥æ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚</li>
<li>é€šè¿‡è®¾è®¡å¯è§æ€§æ„ŸçŸ¥æ¸²æŸ“æ¨¡å—ï¼Œæé«˜äº†è§†è§’ç›¸å…³çš„é®æŒ¡å¤„ç†æ•ˆæœã€‚</li>
<li>Dream3DVGåœ¨3Dè‰å›¾å’Œä¸‰ç»´å›¾æ ‡ä¸Šçš„è¡¨ç°ç»è¿‡å¹¿æ³›æµ‹è¯•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21377">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-56b56f56bfbf9cf33ba5b7c988d8a0f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9dba36923b96459b7f73df4cf9fba9bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70ee4a766b1bb2060cbf45b913941152.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c971323d121f3d2a1d60c7eea710f48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-914e9950c3c0806243cc360eec22f16d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93e153637c88bd0f5a705d4104a7fc07.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Structure-from-Collision"><a href="#Structure-from-Collision" class="headerlink" title="Structure from Collision"></a>Structure from Collision</h2><p><strong>Authors:Takuhiro Kaneko</strong></p>
<p>Recent advancements in neural 3D representations, such as neural radiance fields (NeRF) and 3D Gaussian splatting (3DGS), have enabled the accurate estimation of 3D structures from multiview images. However, this capability is limited to estimating the visible external structure, and identifying the invisible internal structure hidden behind the surface is difficult. To overcome this limitation, we address a new task called Structure from Collision (SfC), which aims to estimate the structure (including the invisible internal structure) of an object from appearance changes during collision. To solve this problem, we propose a novel model called SfC-NeRF that optimizes the invisible internal structure of an object through a video sequence under physical, appearance (i.e., visible external structure)-preserving, and keyframe constraints. In particular, to avoid falling into undesirable local optima owing to its ill-posed nature, we propose volume annealing; that is, searching for global optima by repeatedly reducing and expanding the volume. Extensive experiments on 115 objects involving diverse structures (i.e., various cavity shapes, locations, and sizes) and material properties revealed the properties of SfC and demonstrated the effectiveness of the proposed SfC-NeRF. </p>
<blockquote>
<p>è¿‘æœŸï¼Œç¥ç»ä¸‰ç»´è¡¨ç¤ºæŠ€æœ¯ï¼ˆå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œä¸‰ç»´é«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰ï¼‰çš„è¿›å±•ï¼Œå·²ç»èƒ½å¤Ÿå®ç°é€šè¿‡å¤šè§†è§’å›¾åƒå‡†ç¡®ä¼°è®¡ä¸‰ç»´ç»“æ„ã€‚ç„¶è€Œï¼Œè¿™ç§èƒ½åŠ›ä»…é™äºä¼°è®¡å¯è§çš„å¤–éƒ¨ç»“æ„ï¼Œè¯†åˆ«éšè—åœ¨è¡¨é¢ä¹‹åçš„ä¸å¯è§å†…éƒ¨ç»“æ„ä»ç„¶å¾ˆå›°éš¾ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬è§£å†³äº†ä¸€é¡¹æ–°çš„ä»»åŠ¡ï¼Œç§°ä¸ºä»ç¢°æ’ä¸­é‡å»ºç»“æ„ï¼ˆSfCï¼‰ï¼Œæ—¨åœ¨é€šè¿‡ç¢°æ’è¿‡ç¨‹ä¸­çš„å¤–è§‚å˜åŒ–æ¥ä¼°è®¡ç‰©ä½“çš„ç»“æ„ï¼ˆåŒ…æ‹¬ä¸å¯è§çš„å†…éƒ¨ç»“æ„ï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¨¡å‹SfC-NeRFï¼Œå®ƒé€šè¿‡è§†é¢‘åºåˆ—ä¼˜åŒ–ç‰©ä½“çš„ä¸å¯è§å†…éƒ¨ç»“æ„ï¼ŒåŒæ—¶éµå®ˆç‰©ç†ã€å¤–è§‚ï¼ˆå³ï¼Œå¯è§çš„å¤–éƒ¨ç»“æ„ï¼‰ä¿ç•™å’Œå…³é”®å¸§çº¦æŸã€‚å°¤å…¶ä¸ºäº†é¿å…å› é—®é¢˜ä¸é€‚å®šè€Œé™·å…¥ä¸è‰¯çš„å±€éƒ¨æœ€ä¼˜è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä½“ç§¯é€€ç«æ–¹æ³•ï¼Œå³é€šè¿‡åå¤å‡å°å’Œæ‰©å¤§ä½“ç§¯æ¥å¯»æ‰¾å…¨å±€æœ€ä¼˜è§£ã€‚åœ¨æ¶‰åŠå¤šç§ç»“æ„ï¼ˆä¾‹å¦‚å„ç§è…”å®¤å½¢çŠ¶ã€ä½ç½®å’Œå¤§å°ï¼‰å’Œææ–™ç‰¹æ€§çš„13ä¸ªç‰©ä½“ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒæ­ç¤ºäº†SfCçš„ç‰¹æ€§ï¼Œå¹¶è¯æ˜äº†æ‰€æå‡ºSfC-NeRFæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21335v1">PDF</a> Accepted to CVPR 2025 (Highlight). Project page:   <a target="_blank" rel="noopener" href="https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/sfc/">https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/sfc/</a></p>
<p><strong>Summary</strong></p>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œä¸‰ç»´é«˜æ–¯æ¶‚æ–‘ï¼ˆ3DGSï¼‰ç­‰ç¥ç»ä¸‰ç»´è¡¨ç¤ºçš„æœ€æ–°è¿›å±•ï¼Œå·²ç»èƒ½å¤Ÿå‡†ç¡®åœ°ä»å¤šè§†è§’å›¾åƒä¼°è®¡ä¸‰ç»´ç»“æ„ã€‚ç„¶è€Œï¼Œè¿™é¡¹èƒ½åŠ›ä»…é™äºä¼°è®¡å¯è§å¤–éƒ¨ç»“æ„ï¼Œå¯¹äºéšè—åœ¨è¡¨é¢ä¹‹åçš„ä¸å¯è§å†…éƒ¨ç»“æ„éš¾ä»¥è¯†åˆ«ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ä»»åŠ¡â€”â€”ç¢°æ’ç»“æ„ï¼ˆSfCï¼‰ï¼Œæ—¨åœ¨ä»ç¢°æ’è¿‡ç¨‹ä¸­çš„å¤–è§‚å˜åŒ–ä¼°è®¡ç‰©ä½“çš„ç»“æ„ï¼ˆåŒ…æ‹¬ä¸å¯è§çš„å†…éƒ¨ç»“æ„ï¼‰ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ¨¡å‹SfC-NeRFï¼Œé€šè¿‡è§†é¢‘åºåˆ—åœ¨ç‰©ç†å’Œå¤–è§‚ä¿ç•™ä»¥åŠå…³é”®å¸§çº¦æŸä¸‹ä¼˜åŒ–ç‰©ä½“çš„ä¸å¯è§å†…éƒ¨ç»“æ„ã€‚ä¸ºé¿å…å› é—®é¢˜ä¸é€‚å®šè€Œé™·å…¥å±€éƒ¨æœ€ä¼˜è§£ï¼Œæœ¬æ–‡æå‡ºäº†ä½“ç§¯é€€ç«æ–¹æ³•ï¼Œå³é€šè¿‡åå¤ç¼©å°å’Œæ‰©å¤§ä½“ç§¯æ¥å¯»æ‰¾å…¨å±€æœ€ä¼˜è§£ã€‚å¯¹æ¶‰åŠå¤šç§ç»“æ„å’Œææ–™ç‰¹æ€§çš„115ä¸ªç‰©ä½“çš„å¹¿æ³›å®éªŒæ­ç¤ºäº†SfCçš„ç‰¹æ€§ï¼Œå¹¶éªŒè¯äº†æ‰€æå‡ºçš„SfC-NeRFçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¥ç»ä¸‰ç»´è¡¨ç¤ºæŠ€æœ¯å¦‚NeRFå’Œ3DGSèƒ½å¤Ÿä»å¤šè§†è§’å›¾åƒå‡†ç¡®ä¼°è®¡ä¸‰ç»´ç»“æ„ã€‚</li>
<li>å½“å‰æŠ€æœ¯ä¸»è¦å±€é™äºä¼°è®¡å¯è§å¤–éƒ¨ç»“æ„ï¼Œéš¾ä»¥è¯†åˆ«ä¸å¯è§å†…éƒ¨ç»“æ„ã€‚</li>
<li>æå‡ºæ–°çš„ä»»åŠ¡SfCï¼Œæ—¨åœ¨ä»ç¢°æ’è¿‡ç¨‹ä¸­çš„å¤–è§‚å˜åŒ–ä¼°è®¡ç‰©ä½“çš„å®Œæ•´ç»“æ„ã€‚</li>
<li>ä¸ºè§£å†³SfCé—®é¢˜ï¼Œæå‡ºSfC-NeRFæ¨¡å‹ï¼Œç»“åˆè§†é¢‘åºåˆ—åœ¨ç‰©ç†å’Œå¤–è§‚çº¦æŸä¸‹ä¼˜åŒ–ç‰©ä½“çš„å†…éƒ¨ç»“æ„ã€‚</li>
<li>é‡‡ç”¨ä½“ç§¯é€€ç«æ–¹æ³•é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ï¼Œé€šè¿‡åå¤ç¼©å°å’Œæ‰©å¤§ä½“ç§¯æ¥å¯»æ‰¾å…¨å±€æœ€ä¼˜è§£ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21335">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a6a9a0c91a1ca27d2a35d3db6ec07a48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49626e7e1566a9c535817df229b1e0bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f69a5ca34ff1a011aa0630293981d380.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="3D-UIR-3D-Gaussian-for-Underwater-3D-Scene-Reconstruction-via-Physics-Based-Appearance-Medium-Decouplin"><a href="#3D-UIR-3D-Gaussian-for-Underwater-3D-Scene-Reconstruction-via-Physics-Based-Appearance-Medium-Decouplin" class="headerlink" title="3D-UIR: 3D Gaussian for Underwater 3D Scene Reconstruction via   Physics-Based Appearance-Medium Decouplin"></a>3D-UIR: 3D Gaussian for Underwater 3D Scene Reconstruction via   Physics-Based Appearance-Medium Decouplin</h2><p><strong>Authors:Jieyu Yuan, Yujun Li, Yuanlin Zhang, Chunle Guo, Xiongxin Tang, Ruixing Wang, Chongyi Li</strong></p>
<p>Novel view synthesis for underwater scene reconstruction presents unique challenges due to complex light-media interactions. Optical scattering and absorption in water body bring inhomogeneous medium attenuation interference that disrupts conventional volume rendering assumptions of uniform propagation medium. While 3D Gaussian Splatting (3DGS) offers real-time rendering capabilities, it struggles with underwater inhomogeneous environments where scattering media introduce artifacts and inconsistent appearance. In this study, we propose a physics-based framework that disentangles object appearance from water medium effects through tailored Gaussian modeling. Our approach introduces appearance embeddings, which are explicit medium representations for backscatter and attenuation, enhancing scene consistency. In addition, we propose a distance-guided optimization strategy that leverages pseudo-depth maps as supervision with depth regularization and scale penalty terms to improve geometric fidelity. By integrating the proposed appearance and medium modeling components via an underwater imaging model, our approach achieves both high-quality novel view synthesis and physically accurate scene restoration. Experiments demonstrate our significant improvements in rendering quality and restoration accuracy over existing methods. The project page is available at \href{<a target="_blank" rel="noopener" href="https://bilityniu.github.io/3D-UIR%7D%7Bhttps://bilityniu.github.io/3D-UIR">https://bilityniu.github.io/3D-UIR}{https://bilityniu.github.io/3D-UIR</a> </p>
<blockquote>
<p>æ°´ä¸‹åœºæ™¯é‡å»ºçš„æ–°å‹è§†å›¾åˆæˆé¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œè¿™æ˜¯ç”±äºå¤æ‚çš„å…‰åª’äº¤äº’é€ æˆçš„ã€‚æ°´ä½“ä¸­çš„å…‰å­¦æ•£å°„å’Œå¸æ”¶å¸¦æ¥äº†éå‡åŒ€ä»‹è´¨è¡°å‡å¹²æ‰°ï¼Œç ´åäº†ä¼ ç»Ÿä½“ç§¯æ¸²æŸ“å…³äºå‡åŒ€ä¼ æ’­ä»‹è´¨çš„å‡è®¾ã€‚è™½ç„¶3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æä¾›äº†å®æ—¶æ¸²æŸ“åŠŸèƒ½ï¼Œä½†åœ¨æ°´ä¸‹éå‡åŒ€ç¯å¢ƒä¸­ï¼Œæ•£å°„ä»‹è´¨ä¼šå¼•å…¥ä¼ªå½±å’Œå¤–è§‚ä¸ä¸€è‡´çš„é—®é¢˜ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºç‰©ç†çš„æ¡†æ¶ï¼Œé€šè¿‡å®šåˆ¶çš„é«˜æ–¯å»ºæ¨¡æ¥åˆ†ç¦»ç‰©ä½“å¤–è§‚å’Œæ°´ä»‹è´¨æ•ˆæœã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†å¤–è§‚åµŒå…¥ï¼Œè¿™æ˜¯åå‘æ•£å°„å’Œè¡°å‡çš„æ˜ç¡®ä»‹è´¨è¡¨ç¤ºï¼Œæé«˜äº†åœºæ™¯çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è·ç¦»å¼•å¯¼ä¼˜åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨ä¼ªæ·±åº¦å›¾ä½œä¸ºç›‘ç£ï¼Œé€šè¿‡æ·±åº¦æ­£åˆ™åŒ–å’Œå°ºåº¦æƒ©ç½šé¡¹æ¥æé«˜å‡ ä½•ä¿çœŸåº¦ã€‚é€šè¿‡æ•´åˆæå‡ºçš„å¤–è§‚å’Œä»‹è´¨å»ºæ¨¡ç»„ä»¶ï¼Œå€ŸåŠ©æ°´ä¸‹æˆåƒæ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆå’Œç‰©ç†å‡†ç¡®çš„åœºæ™¯æ¢å¤ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡å’Œæ¢å¤ç²¾åº¦æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://bilityniu.github.io/3D-UIR%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://bilityniu.github.io/3D-UIRä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21238v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ°´ä¸‹åœºæ™¯é‡å»ºçš„æ–°å‹è§†å›¾åˆæˆé¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œå› å…‰ä¸åª’ä»‹çš„å¤æ‚äº¤äº’å¯¼è‡´ã€‚æ°´ä½“ä¸­çš„å…‰å­¦æ•£å°„å’Œå¸æ”¶é€ æˆéå‡åŒ€ä»‹è´¨è¡°å‡å¹²æ‰°ï¼Œç ´åäº†ä¼ ç»Ÿä½“ç§¯æ¸²æŸ“å‡è®¾çš„å‡åŒ€ä¼ æ’­ä»‹è´¨ã€‚3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰è™½å…·å¤‡å®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œä½†åœ¨æ°´ä¸‹éå‡åŒ€ç¯å¢ƒä¸­ï¼Œæ•£å°„åª’ä»‹ä¼šå¼•å‘ä¼ªå½±å’Œå¤–è§‚ä¸ä¸€è‡´é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ä¸ªåŸºäºç‰©ç†çš„æ¡†æ¶ï¼Œé€šè¿‡å®šåˆ¶çš„é«˜æ–¯å»ºæ¨¡æ¥åˆ†ç¦»ç‰©ä½“å¤–è§‚å’Œæ°´ä»‹è´¨æ•ˆæœã€‚å¼•å…¥å¤–è§‚åµŒå…¥ä½œä¸ºåå‘æ•£å°„å’Œè¡°å‡çš„æ˜ç¡®ä»‹è´¨è¡¨ç¤ºï¼Œæé«˜åœºæ™¯ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæå‡ºè·ç¦»å¼•å¯¼ä¼˜åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨ä¼ªæ·±åº¦å›¾ä½œä¸ºç›‘ç£ï¼Œç»“åˆæ·±åº¦æ­£åˆ™åŒ–å’Œå°ºåº¦æƒ©ç½šé¡¹ï¼Œæé«˜å‡ ä½•ä¿çœŸåº¦ã€‚é€šè¿‡æ•´åˆæå‡ºçš„å¤–è§‚å’Œä»‹è´¨å»ºæ¨¡ç»„ä»¶ï¼Œå€ŸåŠ©æ°´ä¸‹æˆåƒæ¨¡å‹ï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆå’Œç‰©ç†å‡†ç¡®çš„åœºæ™¯æ¢å¤ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡å’Œæ¢å¤ç²¾åº¦ä¸Šè¾ƒç°æœ‰æ–¹æ³•æœ‰æ˜æ˜¾æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°´ä¸‹åœºæ™¯é‡å»ºé¢ä¸´å¤æ‚çš„å…‰-åª’ä»‹äº¤äº’æŒ‘æˆ˜ã€‚</li>
<li>å…‰å­¦æ•£å°„å’Œå¸æ”¶å¯¼è‡´éå‡åŒ€ä»‹è´¨è¡°å‡å¹²æ‰°ã€‚</li>
<li>3Dé«˜æ–¯æ‹¼è´´åœ¨å¤„ç†æ°´ä¸‹éå‡åŒ€ç¯å¢ƒæ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºåŸºäºç‰©ç†çš„æ¡†æ¶ï¼Œé€šè¿‡å®šåˆ¶çš„é«˜æ–¯å»ºæ¨¡åˆ†ç¦»ç‰©ä½“å¤–è§‚å’Œæ°´ä»‹è´¨æ•ˆæœã€‚</li>
<li>å¼•å…¥å¤–è§‚åµŒå…¥ä»¥æ˜ç¡®è¡¨ç¤ºåå‘æ•£å°„å’Œè¡°å‡ã€‚</li>
<li>æå‡ºè·ç¦»å¼•å¯¼ä¼˜åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨ä¼ªæ·±åº¦å›¾æé«˜å‡ ä½•ä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21238">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e539f0a56a078c085fa59061d5beb915.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ea497dcae6446d9e75ce227a8483fab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ecfbe335a59dfb9e495e7464f76d31b1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e9288542a4712cdc01ba48b72af0b25.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ProBA-Probabilistic-Bundle-Adjustment-with-the-Bhattacharyya-Coefficient"><a href="#ProBA-Probabilistic-Bundle-Adjustment-with-the-Bhattacharyya-Coefficient" class="headerlink" title="ProBA: Probabilistic Bundle Adjustment with the Bhattacharyya   Coefficient"></a>ProBA: Probabilistic Bundle Adjustment with the Bhattacharyya   Coefficient</h2><p><strong>Authors:Jason Chui, Daniel Cremers</strong></p>
<p>Classical Bundle Adjustment (BA) methods require accurate initial estimates for convergence and typically assume known camera intrinsics, which limits their applicability when such information is uncertain or unavailable. We propose a novel probabilistic formulation of BA (ProBA) that explicitly models and propagates uncertainty in both the 2D observations and the 3D scene structure, enabling optimization without any prior knowledge of camera poses or focal length. Our method uses 3D Gaussians instead of point-like landmarks and we introduce uncertainty-aware reprojection losses by projecting the 3D Gaussians onto the 2D image space, and enforce geometric consistency across multiple 3D Gaussians using the Bhattacharyya coefficient to encourage overlap between their corresponding Gaussian distributions. This probabilistic framework leads to more robust and reliable optimization, even in the presence of outliers in the correspondence set, reducing the likelihood of converging to poor local minima. Experimental results show that \textit{ProBA} outperforms traditional methods in challenging real-world conditions. By removing the need for strong initialization and known intrinsics, ProBA enhances the practicality of SLAM systems deployed in unstructured environments. </p>
<blockquote>
<p>ä¼ ç»Ÿçš„Bundle Adjustmentï¼ˆBAï¼‰æ–¹æ³•éœ€è¦å‡†ç¡®çš„åˆå§‹ä¼°è®¡å€¼ä»¥å®ç°æ”¶æ•›ï¼Œå¹¶ä¸”é€šå¸¸å‡è®¾å·²çŸ¥ç›¸æœºå†…å‚ï¼Œè¿™åœ¨ç›¸å…³ä¿¡æ¯ä¸ç¡®å®šæˆ–ä¸å¯ç”¨çš„æƒ…å†µä¸‹é™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„BAæ¦‚ç‡å…¬å¼ï¼ˆProBAï¼‰ï¼Œè¯¥å…¬å¼èƒ½å¤Ÿæ˜ç¡®å»ºæ¨¡å¹¶ä¼ æ’­2Dè§‚æµ‹å’Œ3Dåœºæ™¯ç»“æ„ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œä»è€Œå®ç°æ— éœ€äº‹å…ˆäº†è§£ç›¸æœºå§¿æ€æˆ–ç„¦è·çš„ä¼˜åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨3Dé«˜æ–¯åˆ†å¸ƒä»£æ›¿ç‚¹çŠ¶åœ°æ ‡ï¼Œå¹¶é€šè¿‡å°†3Dé«˜æ–¯åˆ†å¸ƒæŠ•å½±åˆ°2Då›¾åƒç©ºé—´æ¥å¼•å…¥æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„é‡æŠ•å½±æŸå¤±ï¼Œå¹¶ä½¿ç”¨Bhattacharyyaç³»æ•°å¼ºåˆ¶å¤šä¸ª3Dé«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œä»¥é¼“åŠ±å…¶ç›¸åº”é«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„é‡å ã€‚è¿™ç§æ¦‚ç‡æ¡†æ¶å³ä½¿åœ¨å¯¹åº”é›†å­˜åœ¨å¼‚å¸¸å€¼çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å®ç°æ›´ç¨³å¥å’Œå¯é çš„ä¼˜åŒ–ï¼Œé™ä½äº†é™·å…¥ç³Ÿç³•å±€éƒ¨æœ€å°å€¼çš„å¯èƒ½æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç°å®æ¡ä»¶ä¸‹ï¼ŒProBAä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚é€šè¿‡ä¸å†éœ€è¦å¼ºå¤§çš„åˆå§‹åŒ–ç¨‹åºå’Œå·²çŸ¥çš„å†…å‚ï¼ŒProBAæé«˜äº†åœ¨å¤æ‚ç¯å¢ƒä¸­éƒ¨ç½²çš„SLAMç³»ç»Ÿçš„å®ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20858v1">PDF</a> 15 pages, 14 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„æ¦‚ç‡è®ºBundle Adjustmentï¼ˆProBAï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾å¼åœ°æ¨¡æ‹Ÿå¹¶ä¼ æ’­2Dè§‚æµ‹å’Œ3Dåœºæ™¯ç»“æ„çš„ä¸ç¡®å®šæ€§ï¼Œæ— éœ€ä»»ä½•å…³äºç›¸æœºå§¿æ€æˆ–ç„¦è·çš„å…ˆéªŒçŸ¥è¯†å³å¯è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡å¼•å…¥åŸºäºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„é‡æŠ•å½±æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§çº¦æŸï¼Œä½¿å¾—è¯¥æ–¹æ³•æ›´ä¸ºç¨³å¥å¯é ï¼Œå³ä½¿å¯¹åº”é›†å­˜åœ¨å¼‚å¸¸å€¼ä¹Ÿèƒ½ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤æ‚çœŸå®ç¯å¢ƒä¸‹ï¼ŒProBAçš„æ€§èƒ½ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¢å¼ºäº†åœ¨æ— ç»“æ„ç¯å¢ƒä¸­éƒ¨ç½²çš„SLAMç³»ç»Ÿçš„å®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ProBAæ˜¯ä¸€ç§æ–°å‹çš„Bundle Adjustmentæ–¹æ³•ï¼Œé€‚ç”¨äºç›¸æœºå‚æ•°ä¸ç¡®å®šæˆ–ä¸å¯ç”¨çš„æƒ…å†µã€‚</li>
<li>ProBAæ˜¾å¼åœ°æ¨¡æ‹Ÿå¹¶ä¼ æ’­è§‚æµ‹å’Œåœºæ™¯ç»“æ„çš„ä¸ç¡®å®šæ€§ã€‚</li>
<li>ProBAä½¿ç”¨3Dé«˜æ–¯åˆ†å¸ƒä»£æ›¿ç‚¹çŠ¶åœ°æ ‡è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>ProBAå¼•å…¥åŸºäºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„é‡æŠ•å½±æŸå¤±ï¼Œé€šè¿‡å°†3Dé«˜æ–¯åˆ†å¸ƒæŠ•å½±åˆ°2Då›¾åƒç©ºé—´æ¥æ‰§è¡Œã€‚</li>
<li>ä½¿ç”¨Bhattacharyyaç³»æ•°æ¥ç¡®ä¿å¤šä¸ª3Dé«˜æ–¯ä¹‹é—´çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œä»è€Œä¿ƒè¿›å…¶ç›¸åº”é«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„é‡å ã€‚</li>
<li>ProBAæ›´ä¸ºç¨³å¥å¯é ï¼Œå³ä½¿åœ¨å¯¹åº”é›†ä¸­å­˜åœ¨å¼‚å¸¸å€¼ä¹Ÿèƒ½ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20858">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e9d62d46d4fab2648e6c917f2ba49b45.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ad12d0a96c6d5b573acf3c43aac51e43.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-18251bdc5aba5ad0c3635fd03efd2516.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-600a9b9f6fe2db082e4d0fd546429fd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6b9b2eb07f58ce466768ca67235fdfc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc9895669df4eb0ce3a8bd9b9ba9461d.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Intern-GS-Vision-Model-Guided-Sparse-View-3D-Gaussian-Splatting"><a href="#Intern-GS-Vision-Model-Guided-Sparse-View-3D-Gaussian-Splatting" class="headerlink" title="Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting"></a>Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting</h2><p><strong>Authors:Xiangyu Sun, Runnan Chen, Mingming Gong, Dong Xu, Tongliang Liu</strong></p>
<p>Sparse-view scene reconstruction often faces significant challenges due to the constraints imposed by limited observational data. These limitations result in incomplete information, leading to suboptimal reconstructions using existing methodologies. To address this, we present Intern-GS, a novel approach that effectively leverages rich prior knowledge from vision foundation models to enhance the process of sparse-view Gaussian Splatting, thereby enabling high-quality scene reconstruction. Specifically, Intern-GS utilizes vision foundation models to guide both the initialization and the optimization process of 3D Gaussian splatting, effectively addressing the limitations of sparse inputs. In the initialization process, our method employs DUSt3R to generate a dense and non-redundant gaussian point cloud. This approach significantly alleviates the limitations encountered by traditional structure-from-motion (SfM) methods, which often struggle under sparse-view constraints. During the optimization process, vision foundation models predict depth and appearance for unobserved views, refining the 3D Gaussians to compensate for missing information in unseen regions. Extensive experiments demonstrate that Intern-GS achieves state-of-the-art rendering quality across diverse datasets, including both forward-facing and large-scale scenes, such as LLFF, DTU, and Tanks and Temples. </p>
<blockquote>
<p>ç¨€ç–è§†è§’åœºæ™¯é‡å»ºå¸¸å¸¸ç”±äºæœ‰é™çš„è§‚æµ‹æ•°æ®æ‰€å¸¦æ¥çš„çº¦æŸè€Œé¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚è¿™äº›é™åˆ¶å¯¼è‡´ä¿¡æ¯ä¸å®Œæ•´ï¼Œä½¿ç”¨ç°æœ‰æ–¹æ³•è¿›è¡Œçš„é‡å»ºæ•ˆæœä¸ç†æƒ³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Intern-GSï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ä¸°å¯Œçš„å…ˆéªŒçŸ¥è¯†ï¼Œæœ‰æ•ˆæå‡ç¨€ç–è§†è§’é«˜æ–¯å»¶å±•è¿‡ç¨‹çš„æ–°æ–¹æ³•ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„åœºæ™¯é‡å»ºã€‚å…·ä½“æ¥è¯´ï¼ŒIntern-GSåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹æ¥æŒ‡å¯¼3Dé«˜æ–¯å»¶å±•çš„åˆå§‹åŒ–å’Œä¼˜åŒ–è¿‡ç¨‹ï¼Œæœ‰æ•ˆè§£å†³ç¨€ç–è¾“å…¥çš„å±€é™æ€§ã€‚åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨DUSt3Rç”Ÿæˆå¯†é›†ä¸”éå†—ä½™çš„é«˜æ–¯ç‚¹äº‘ã€‚è¿™ç§æ–¹æ³•æå¤§åœ°ç¼“è§£äº†ä¼ ç»Ÿç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰æ–¹æ³•åœ¨ç¨€ç–è§†è§’çº¦æŸä¸‹ç»å¸¸é‡åˆ°çš„å±€é™ã€‚åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œè§†è§‰åŸºç¡€æ¨¡å‹é¢„æµ‹æœªè§‚æµ‹è§†è§’çš„æ·±åº¦å’Œå¤–è§‚ï¼Œå¯¹3Dé«˜æ–¯è¿›è¡Œå¾®è°ƒä»¥è¡¥å¿æœªè§‚æµ‹åŒºåŸŸçš„ç¼ºå¤±ä¿¡æ¯ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒIntern-GSåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒ…æ‹¬æ­£é¢å’Œå¤§è§„æ¨¡åœºæ™¯ï¼Œå¦‚LLFFã€DTUå’Œå¦å…‹ä¸ç¥åº™ç­‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20729v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¨€ç–è§†è§’çš„åœºæ™¯é‡å»ºå¸¸å¸¸é¢ä¸´ç”±äºè§‚æµ‹æ•°æ®æœ‰é™å¯¼è‡´çš„é‡å¤§æŒ‘æˆ˜ã€‚ç”±äºä¿¡æ¯ä¸å®Œæ•´ï¼Œç°æœ‰æ–¹æ³•çš„é‡å»ºæ•ˆæœå¾€å¾€ä¸å°½å¦‚äººæ„ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Intern-GSè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ä¸­çš„ä¸°å¯Œå…ˆéªŒçŸ¥è¯†ï¼Œæœ‰æ•ˆæå‡äº†ç¨€ç–è§†è§’çš„é«˜æ–¯æ‹¼è´´è¿‡ç¨‹ï¼Œä»è€Œå®ç°äº†é«˜è´¨é‡çš„åœºæ™¯é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Intern-GSåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†æ¥è§£å†³ç¨€ç–è§†è§’åœºæ™¯é‡å»ºä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨DUSt3Rç”Ÿæˆå¯†é›†ä¸”éå†—ä½™çš„é«˜æ–¯ç‚¹äº‘ï¼Œæœ‰æ•ˆç¼“è§£ä¼ ç»Ÿç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰æ–¹æ³•åœ¨ç¨€ç–è§†è§’çº¦æŸä¸‹çš„å±€é™æ€§ã€‚</li>
<li>åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹é¢„æµ‹æœªè§‚æµ‹è§†è§’çš„æ·±åº¦å’Œå¤–è§‚ï¼Œå¯¹3Dé«˜æ–¯è¿›è¡Œç»†åŒ–ä»¥è¡¥å¿æœªè§åŒºåŸŸçš„ç¼ºå¤±ä¿¡æ¯ã€‚</li>
<li>Intern-GSåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒ…æ‹¬æ­£é¢åœºæ™¯ã€å¤§è§„æ¨¡åœºæ™¯ï¼Œå¦‚LLFFã€DTUå’ŒTanks and Templesã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆåˆ©ç”¨å·²æœ‰çš„ä¸°å¯Œæ•°æ®èµ„æºï¼Œé€šè¿‡ç»“åˆå…ˆéªŒçŸ¥è¯†å’Œå®æ—¶æ•°æ®ï¼Œæé«˜åœºæ™¯é‡å»ºçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>é€šè¿‡å¯†é›†ä¸”éå†—ä½™çš„é«˜æ–¯ç‚¹äº‘ç”Ÿæˆï¼Œæå‡äº†åœºæ™¯ç»“æ„çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œä½¿å¾—é‡å»ºç»“æœæ›´åŠ ç²¾ç»†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20729">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f5e4b07c59f36e03473e9e0f6f64a90c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e82af2188207c9bf7fb2c94e0286aa8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a38d14017d956d3a72b6b843d03e37d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee2e693f7ca4391d0c64638d96d6f92a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Wideband-RF-Radiance-Field-Modeling-Using-Frequency-embedded-3D-Gaussian-Splatting"><a href="#Wideband-RF-Radiance-Field-Modeling-Using-Frequency-embedded-3D-Gaussian-Splatting" class="headerlink" title="Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian   Splatting"></a>Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian   Splatting</h2><p><strong>Authors:Zechen Li, Lanqing Yang, Yiheng Bian, Hao Pan, Yongjian Fu, Yezhou Wang, Yi-Chao Chen, Guangtao Xue, Ju Ren</strong></p>
<p>This paper presents an innovative frequency-embedded 3D Gaussian splatting (3DGS) algorithm for wideband radio-frequency (RF) radiance field modeling, offering an advancement over the existing works limited to single-frequency modeling. Grounded in fundamental physics, we uncover the complex relationship between EM wave propagation behaviors and RF frequencies. Inspired by this, we design an EM feature network with attenuation and radiance modules to learn the complex relationships between RF frequencies and the key properties of each 3D Gaussian, specifically the attenuation factor and RF signal intensity. By training the frequency-embedded 3DGS model, we can efficiently reconstruct RF radiance fields at arbitrary unknown frequencies within a given 3D environment. Finally, we propose a large-scale power angular spectrum (PAS) dataset containing 50000 samples ranging from 1 to 100 GHz in 6 indoor environments, and conduct extensive experiments to verify the effectiveness of our method. Our approach achieves an average Structural Similarity Index Measure (SSIM) up to 0.72, and a significant improvement up to 17.8% compared to the current state-of-the-art (SOTA) methods trained on individual test frequencies. Additionally, our method achieves an SSIM of 0.70 without prior training on these frequencies, which represents only a 2.8% performance drop compared to models trained with full PAS data. This demonstrates our modelâ€™s capability to estimate PAS at unknown frequencies. For related code and datasets, please refer to <a target="_blank" rel="noopener" href="https://github.com/sim-2-real/Wideband3DGS">https://github.com/sim-2-real/Wideband3DGS</a>. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„é¢‘ç‡åµŒå…¥ä¸‰ç»´é«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰ç®—æ³•ï¼Œç”¨äºå®½å¸¦å°„é¢‘ï¼ˆRFï¼‰è¾å°„åœºå»ºæ¨¡ã€‚ç›¸è¾ƒäºç°æœ‰ä»…é™äºå•é¢‘ç‡å»ºæ¨¡çš„å·¥ä½œï¼Œè¯¥ç®—æ³•æ˜¯ä¸€ç§è¿›æ­¥ã€‚è¯¥ç®—æ³•åŸºäºç‰©ç†å­¦åŸºæœ¬åŸç†ï¼Œæ­ç¤ºäº†ç”µç£æ³¢ä¼ æ’­è¡Œä¸ºä¸å°„é¢‘é¢‘ç‡ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚å—å…¶å¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå…·æœ‰è¡°å‡å’Œè¾å°„æ¨¡å—çš„ç”µç£ç‰¹å¾ç½‘ç»œï¼Œä»¥å­¦ä¹ å°„é¢‘é¢‘ç‡ä¸æ¯ä¸ªä¸‰ç»´é«˜æ–¯çš„å…³é”®å±æ€§ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œç‰¹åˆ«æ˜¯è¡°å‡å› å­å’Œå°„é¢‘ä¿¡å·å¼ºåº¦ã€‚é€šè¿‡è®­ç»ƒé¢‘ç‡åµŒå…¥çš„3DGSæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°åœ¨ç»™å®šä¸‰ç»´ç¯å¢ƒå†…çš„ä»»æ„æœªçŸ¥é¢‘ç‡ä¸Šé‡å»ºå°„é¢‘è¾å°„åœºã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡åŠŸç‡è§’è°±ï¼ˆPASï¼‰æ•°æ®é›†ï¼ŒåŒ…å«6ä¸ªå®¤å†…ç¯å¢ƒä¸­çš„50000ä¸ªæ ·æœ¬ï¼Œé¢‘ç‡èŒƒå›´ä»1åˆ°100 GHzï¼Œå¹¶è¿›è¡Œäº†å¤§é‡å®éªŒæ¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†å¹³å‡ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼‰é«˜è¾¾0.72ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„ï¼ˆSOTAï¼‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨ä¸ªåˆ«æµ‹è¯•é¢‘ç‡ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ï¼Œæœ‰äº†é«˜è¾¾17.8%çš„æ˜¾è‘—æ”¹å–„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æœªç»è¿™äº›é¢‘ç‡é¢„å…ˆè®­ç»ƒçš„æƒ…å†µä¸‹è¾¾åˆ°äº†0.70çš„SSIMï¼Œä¸ç”¨å…¨PASæ•°æ®è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼Œæ€§èƒ½ä»…ä¸‹é™äº†2.8%ï¼Œè¿™è¯æ˜äº†æˆ‘ä»¬æ¨¡å‹åœ¨æœªçŸ¥é¢‘ç‡ä¸Šä¼°è®¡PASçš„èƒ½åŠ›ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®é›†è¯·å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://github.com/sim-2-real/Wideband3DGS%E3%80%82">https://github.com/sim-2-real/Wideband3DGSã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20714v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„é¢‘ç‡åµŒå…¥ä¸‰ç»´é«˜æ–¯æ¨¡ç³Šç®—æ³•ï¼ˆFrequency-Embedded 3D Gaussian Splattingï¼Œç®€ç§°FE-3DGSï¼‰ï¼Œç”¨äºå®½é¢‘å°„é¢‘è¾å°„åœºå»ºæ¨¡ã€‚è¯¥ç®—æ³•çªç ´äº†ç°æœ‰ä»…é€‚ç”¨äºå•é¢‘å»ºæ¨¡çš„é™åˆ¶ï¼Œé€šè¿‡è®¾è®¡ç”µç£ç‰¹å¾ç½‘ç»œå­¦ä¹ å°„é¢‘é¢‘ç‡ä¸ä¸‰ç»´é«˜æ–¯å…³é”®å±æ€§ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œèƒ½é«˜æ•ˆåœ°åœ¨ä»»æ„æœªçŸ¥é¢‘ç‡ä¸‹é‡å»ºå°„é¢‘è¾å°„åœºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•è¾ƒå½“å‰æœ€ä¼˜ç®—æ³•æœ‰æ˜¾è‘—æå‡ï¼Œä¸”å…·å¤‡åœ¨æœªçŸ¥é¢‘ç‡ä¸Šä¼°ç®—åŠŸç‡è§’è°±çš„èƒ½åŠ›ã€‚ç›¸å…³ä»£ç ä¸æ•°æ®é›†å¯åœ¨ç›¸åº”é“¾æ¥ä¸‹è½½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§é¢‘ç‡åµŒå…¥çš„ä¸‰ç»´é«˜æ–¯æ¨¡ç³Šç®—æ³•ï¼ˆFE-3DGSï¼‰ï¼Œç”¨äºå®½é¢‘å°„é¢‘è¾å°„åœºå»ºæ¨¡ã€‚</li>
<li>çªç ´äº†å•é¢‘å»ºæ¨¡çš„é™åˆ¶ï¼Œé€šè¿‡ç”µç£ç‰¹å¾ç½‘ç»œå­¦ä¹ å°„é¢‘é¢‘ç‡ä¸ä¸‰ç»´é«˜æ–¯å±æ€§çš„å¤æ‚å…³ç³»ã€‚</li>
<li>èƒ½é«˜æ•ˆåœ°åœ¨ä»»æ„æœªçŸ¥é¢‘ç‡ä¸‹é‡å»ºå°„é¢‘è¾å°„åœºã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•è¾ƒå½“å‰æœ€ä¼˜ç®—æ³•æœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>æ¨¡å‹å…·å¤‡åœ¨æœªçŸ¥é¢‘ç‡ä¸Šä¼°ç®—åŠŸç‡è§’è°±çš„èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20714">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-19f256cebc948abbe051fdb5271b8884.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50bb6412152993c5c4e4807318558fed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fc6c99a1005b034a4b5a35253ff23e7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5aedcb5ee52239a51a4d5a0c4fc19b2c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="OmniIndoor3D-Comprehensive-Indoor-3D-Reconstruction"><a href="#OmniIndoor3D-Comprehensive-Indoor-3D-Reconstruction" class="headerlink" title="OmniIndoor3D: Comprehensive Indoor 3D Reconstruction"></a>OmniIndoor3D: Comprehensive Indoor 3D Reconstruction</h2><p><strong>Authors:Xiaobao Wei, Xiaoan Zhang, Hao Wang, Qingpo Wuwu, Ming Lu, Wenzhao Zheng, Shanghang Zhang</strong></p>
<p>We propose a novel framework for comprehensive indoor 3D reconstruction using Gaussian representations, called OmniIndoor3D. This framework enables accurate appearance, geometry, and panoptic reconstruction of diverse indoor scenes captured by a consumer-level RGB-D camera. Since 3DGS is primarily optimized for photorealistic rendering, it lacks the precise geometry critical for high-quality panoptic reconstruction. Therefore, OmniIndoor3D first combines multiple RGB-D images to create a coarse 3D reconstruction, which is then used to initialize the 3D Gaussians and guide the 3DGS training. To decouple the optimization conflict between appearance and geometry, we introduce a lightweight MLP that adjusts the geometric properties of 3D Gaussians. The introduced lightweight MLP serves as a low-pass filter for geometry reconstruction and significantly reduces noise in indoor scenes. To improve the distribution of Gaussian primitives, we propose a densification strategy guided by panoptic priors to encourage smoothness on planar surfaces. Through the joint optimization of appearance, geometry, and panoptic reconstruction, OmniIndoor3D provides comprehensive 3D indoor scene understanding, which facilitates accurate and robust robotic navigation. We perform thorough evaluations across multiple datasets, and OmniIndoor3D achieves state-of-the-art results in appearance, geometry, and panoptic reconstruction. We believe our work bridges a critical gap in indoor 3D reconstruction. The code will be released at: <a target="_blank" rel="noopener" href="https://ucwxb.github.io/OmniIndoor3D/">https://ucwxb.github.io/OmniIndoor3D/</a> </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨é«˜æ–¯è¡¨ç¤ºè¿›è¡Œå®¤å†…å…¨é¢ä¸‰ç»´é‡å»ºçš„æ–°å‹æ¡†æ¶ï¼Œç§°ä¸ºOmniIndoor3Dã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåˆ©ç”¨æ¶ˆè´¹çº§RGB-Dç›¸æœºæ•è·çš„å¤šç§å®¤å†…åœºæ™¯ï¼Œå®ç°ç²¾ç¡®çš„å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºã€‚ç”±äº3DGSä¸»è¦é¢å‘é€¼çœŸçš„æ¸²æŸ“è¿›è¡Œä¼˜åŒ–ï¼Œå› æ­¤åœ¨é«˜è´¨é‡å…¨æ™¯é‡å»ºæ–¹é¢ç¼ºä¹ç²¾ç¡®å‡ ä½•ç»“æ„ã€‚å› æ­¤ï¼ŒOmniIndoor3Dé¦–å…ˆç»“åˆå¤šä¸ªRGB-Då›¾åƒåˆ›å»ºç²—ç•¥çš„ä¸‰ç»´é‡å»ºï¼Œç„¶åç”¨äºåˆå§‹åŒ–ä¸‰ç»´é«˜æ–¯å¹¶å¼•å¯¼3DGSè®­ç»ƒã€‚ä¸ºäº†æ¶ˆé™¤å¤–è§‚å’Œå‡ ä½•ä¹‹é—´çš„ä¼˜åŒ–å†²çªï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„MLPæ¥è°ƒæ•´ä¸‰ç»´é«˜æ–¯å‡ ä½•å±æ€§ã€‚å¼•å…¥çš„è½»é‡çº§MLPä½œä¸ºå‡ ä½•é‡å»ºçš„ä½é€šæ»¤æ³¢å™¨ï¼Œæ˜¾è‘—å‡å°‘äº†å®¤å†…åœºæ™¯çš„å™ªå£°ã€‚ä¸ºäº†æé«˜é«˜æ–¯åŸå§‹æ•°æ®çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±å…¨æ™¯å…ˆéªŒå¼•å¯¼çš„è‡´å¯†åŒ–ç­–ç•¥ï¼Œä»¥é¼“åŠ±å¹³é¢è¡¨é¢çš„å¹³æ»‘æ€§ã€‚é€šè¿‡å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºçš„è”åˆä¼˜åŒ–ï¼ŒOmniIndoor3Dæä¾›äº†å…¨é¢çš„å®¤å†…ä¸‰ç»´åœºæ™¯ç†è§£ï¼Œä¿ƒè¿›äº†å‡†ç¡®å¯é çš„æœºå™¨äººå¯¼èˆªã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒOmniIndoor3Dåœ¨å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºæ–¹é¢å–å¾—äº†æœ€æ–°ç»“æœã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹å·¥ä½œå¡«è¡¥äº†å®¤å†…ä¸‰ç»´é‡å»ºçš„å…³é”®ç©ºç™½ã€‚ä»£ç å‘å¸ƒåœ°å€ä¸ºï¼š[<a target="_blank" rel="noopener" href="https://ucwxb.github.io/OmniIndoor3D/]">https://ucwxb.github.io/OmniIndoor3D/]</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20610v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯è¡¨ç¤ºçš„æ–°å‹å®¤å†…ä¸‰ç»´é‡å»ºæ¡†æ¶OmniIndoor3Dã€‚è¯¥æ¡†æ¶å¯å®ç°é€šè¿‡æ¶ˆè´¹çº§RGB-Dç›¸æœºæ•è·çš„å¤šæ ·åŒ–å®¤å†…åœºæ™¯çš„å‡†ç¡®å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºã€‚OmniIndoor3Dç»“åˆå¤šä¸ªRGB-Då›¾åƒåˆ›å»ºç²—ç•¥çš„ä¸‰ç»´é‡å»ºï¼Œè¿›è€Œåˆå§‹åŒ–ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒå¹¶å¼•å¯¼ä¸‰ç»´å‡ ä½•åœºæ™¯ç½‘ç»œçš„è®­ç»ƒã€‚å¼•å…¥çš„è½»é‡çº§å¤šå±‚æ„ŸçŸ¥å™¨è§£å†³äº†å¤–è§‚å’Œå‡ ä½•ä¼˜åŒ–ä¹‹é—´çš„å†²çªï¼Œä½œä¸ºå‡ ä½•é‡å»ºçš„ä½é€šæ»¤æ³¢å™¨ï¼Œæ˜¾è‘—é™ä½äº†å®¤å†…åœºæ™¯çš„å™ªå£°ã€‚é€šè¿‡å…¨æ™¯å…ˆéªŒæŒ‡å¯¼çš„é«˜æ–¯åŸå§‹åˆ†å¸ƒåŠ å¯†ç­–ç•¥ï¼Œä¿ƒè¿›äº†å¹³é¢è¡¨é¢çš„å¹³æ»‘æ€§ã€‚é€šè¿‡å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºçš„è”åˆä¼˜åŒ–ï¼ŒOmniIndoor3Dæä¾›äº†å…¨é¢çš„å®¤å†…ä¸‰ç»´åœºæ™¯ç†è§£ï¼Œä¿ƒè¿›äº†å‡†ç¡®å’Œç¨³å¥çš„æœºå™¨äººå¯¼èˆªã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒOmniIndoor3Dåœ¨å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºæ–¹é¢å‡è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°å‹å®¤å†…ä¸‰ç»´é‡å»ºæ¡†æ¶OmniIndoor3Dï¼Œåˆ©ç”¨é«˜æ–¯è¡¨ç¤ºå®ç°å‡†ç¡®é‡å»ºã€‚</li>
<li>ç»“åˆRGB-Då›¾åƒè¿›è¡Œç²—ç•¥ä¸‰ç»´é‡å»ºï¼Œåˆå§‹åŒ–ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒï¼Œå¼•å¯¼åç»­è®­ç»ƒã€‚</li>
<li>å¼•å…¥è½»é‡çº§å¤šå±‚æ„ŸçŸ¥å™¨è§£å†³å¤–è§‚å’Œå‡ ä½•ä¼˜åŒ–é—´çš„å†²çªï¼Œæå‡å‡ ä½•é‡å»ºè´¨é‡ã€‚</li>
<li>é‡‡ç”¨ä½é€šæ»¤æ³¢ç­–ç•¥é™ä½å®¤å†…åœºæ™¯å™ªå£°ï¼Œæé«˜å‡ ä½•é‡å»ºçš„å‡†ç¡®æ€§ã€‚</li>
<li>æå‡ºåŸºäºå…¨æ™¯å…ˆéªŒçš„é«˜æ–¯åŸå§‹åˆ†å¸ƒåŠ å¯†ç­–ç•¥ï¼Œä¿ƒè¿›å¹³é¢è¡¨é¢çš„å¹³æ»‘æ€§ã€‚</li>
<li>é€šè¿‡è”åˆä¼˜åŒ–å¤–è§‚ã€å‡ ä½•å’Œå…¨æ™¯é‡å»ºï¼ŒOmniIndoor3Dæä¾›å…¨é¢çš„å®¤å†…ä¸‰ç»´åœºæ™¯ç†è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20610">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-87f7da8b7d141e0d8425914763fcc0b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e57270b43cf286258404cced69d256e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e3f159c269664559518b4baf1b3892c.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CCL-LGS-Contrastive-Codebook-Learning-for-3D-Language-Gaussian-Splatting"><a href="#CCL-LGS-Contrastive-Codebook-Learning-for-3D-Language-Gaussian-Splatting" class="headerlink" title="CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian   Splatting"></a>CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian   Splatting</h2><p><strong>Authors:Lei Tian, Xiaomin Li, Liqian Ma, Hefei Huang, Zirui Zheng, Hao Yin, Taiqing Li, Huchuan Lu, Xu Jia</strong></p>
<p>Recent advances in 3D reconstruction techniques and vision-language models have fueled significant progress in 3D semantic understanding, a capability critical to robotics, autonomous driving, and virtual&#x2F;augmented reality. However, methods that rely on 2D priors are prone to a critical challenge: cross-view semantic inconsistencies induced by occlusion, image blur, and view-dependent variations. These inconsistencies, when propagated via projection supervision, deteriorate the quality of 3D Gaussian semantic fields and introduce artifacts in the rendered outputs. To mitigate this limitation, we propose CCL-LGS, a novel framework that enforces view-consistent semantic supervision by integrating multi-view semantic cues. Specifically, our approach first employs a zero-shot tracker to align a set of SAM-generated 2D masks and reliably identify their corresponding categories. Next, we utilize CLIP to extract robust semantic encodings across views. Finally, our Contrastive Codebook Learning (CCL) module distills discriminative semantic features by enforcing intra-class compactness and inter-class distinctiveness. In contrast to previous methods that directly apply CLIP to imperfect masks, our framework explicitly resolves semantic conflicts while preserving category discriminability. Extensive experiments demonstrate that CCL-LGS outperforms previous state-of-the-art methods. Our project page is available at <a target="_blank" rel="noopener" href="https://epsilontl.github.io/CCL-LGS/">https://epsilontl.github.io/CCL-LGS/</a>. </p>
<blockquote>
<p>è¿‘æœŸä¸‰ç»´é‡å»ºæŠ€æœ¯å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æå¤§åœ°æ¨åŠ¨äº†ä¸‰ç»´è¯­ä¹‰ç†è§£çš„å‘å±•ï¼Œè¿™å¯¹äºæœºå™¨äººæŠ€æœ¯ã€è‡ªåŠ¨é©¾é©¶ä»¥åŠè™šæ‹Ÿç°å®&#x2F;å¢å¼ºç°å®æŠ€æœ¯è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¾èµ–äºŒç»´å…ˆéªŒçš„æ–¹æ³•é¢ä¸´ç€ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ï¼šç”±é®æŒ¡ã€å›¾åƒæ¨¡ç³Šå’Œè§†è§’ç›¸å…³å˜åŒ–å¼•èµ·çš„è·¨è§†å›¾è¯­ä¹‰ä¸ä¸€è‡´æ€§ã€‚è¿™äº›ä¸ä¸€è‡´æ€§é€šè¿‡æŠ•å½±ç›‘ç£ä¼ æ’­æ—¶ï¼Œä¼šæ¶åŒ–ä¸‰ç»´é«˜æ–¯è¯­ä¹‰åœºçš„å“è´¨ï¼Œå¹¶åœ¨æ¸²æŸ“è¾“å‡ºä¸­å¼•å…¥ä¼ªåƒã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†CCL-LGSè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡æ•´åˆå¤šè§†å›¾è¯­ä¹‰çº¿ç´¢æ¥å®æ–½è§†å›¾ä¸€è‡´çš„è¯­ä¹‰ç›‘ç£ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆé‡‡ç”¨é›¶æ ·æœ¬è¿½è¸ªå™¨æ¥å¯¹é½ä¸€ç»„ç”±SAMç”Ÿæˆçš„äºŒç»´æ©è†œå¹¶å¯é åœ°è¯†åˆ«å‡ºå®ƒä»¬å¯¹åº”çš„ç±»åˆ«ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨CLIPæ¥æå–è·¨è§†å›¾çš„ç¨³å¥è¯­ä¹‰ç¼–ç ã€‚æœ€åï¼Œæˆ‘ä»¬çš„å¯¹æ¯”ä»£ç æœ¬å­¦ä¹ ï¼ˆCCLï¼‰æ¨¡å—é€šè¿‡æ‰§è¡Œç±»å†…ç´§å‡‘æ€§å’Œç±»é—´å·®å¼‚æ€§æ¥æç‚¼å‡ºåˆ¤åˆ«è¯­ä¹‰ç‰¹å¾ã€‚ä¸å‰äººç›´æ¥å¯¹ä¸å®Œæ•´æ©è†œåº”ç”¨CLIPçš„æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿæ˜¾å¼è§£å†³è¯­ä¹‰å†²çªï¼ŒåŒæ—¶ä¿ç•™ç±»åˆ«é‰´åˆ«èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCCL-LGSä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://epsilontl.github.io/CCL-LGS/%E8%AE%BF%E9%97%AE%E3%80%82">https://epsilontl.github.io/CCL-LGS/è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20469v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¿‘æœŸä¸‰ç»´é‡å»ºæŠ€æœ¯å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„å‘å±•å¯¹ä¸‰ç»´è¯­ä¹‰ç†è§£çš„é‡è¦æ€§åŠå…¶åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚ç„¶è€Œï¼Œä¾èµ–äºäºŒç»´å…ˆéªŒçš„æ–¹æ³•é¢ä¸´ç€å› é®æŒ¡ã€å›¾åƒæ¨¡ç³Šå’Œè§†è§’å˜åŒ–å¯¼è‡´çš„è·¨è§†å›¾è¯­ä¹‰ä¸ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†CCL-LGSæ¡†æ¶ï¼Œé€šè¿‡é›†æˆå¤šè§†å›¾è¯­ä¹‰çº¿ç´¢æ¥å®æ–½è§†å›¾ä¸€è‡´è¯­ä¹‰ç›‘ç£ã€‚å®éªŒè¯æ˜ï¼ŒCCL-LGSç›¸è¾ƒäºç°æœ‰å…ˆè¿›æŠ€æœ¯è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3Dè¯­ä¹‰ç†è§£åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å…³é”®ä½œç”¨ã€‚</li>
<li>å½“å‰æ–¹æ³•ä¾èµ–äºäºŒç»´å…ˆéªŒï¼Œé¢ä¸´è·¨è§†å›¾è¯­ä¹‰ä¸ä¸€è‡´çš„æŒ‘æˆ˜ã€‚</li>
<li>CCL-LGSæ¡†æ¶é€šè¿‡å¤šè§†å›¾è¯­ä¹‰çº¿ç´¢å®æ–½è§†å›¾ä¸€è‡´è¯­ä¹‰ç›‘ç£æ¥å…‹æœè¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>CCL-LGSé‡‡ç”¨é›¶é•œå¤´è¿½è¸ªå™¨å¯¹é½SAMç”Ÿæˆçš„äºŒç»´æ©è†œå¹¶è¯†åˆ«å¯¹åº”çš„ç±»åˆ«ã€‚</li>
<li>ä½¿ç”¨CLIPæå–è·¨è§†å›¾çš„ç¨³å¥è¯­ä¹‰ç¼–ç ã€‚</li>
<li>å¯¹æ¯”ä»£ç æœ¬å­¦ä¹ ï¼ˆCCLï¼‰æ¨¡å—é€šè¿‡æ‰§è¡Œç±»å†…ç´§å‡‘æ€§å’Œç±»é—´åŒºåˆ†æ€§æ¥æç‚¼åˆ¤åˆ«è¯­ä¹‰ç‰¹å¾ã€‚</li>
<li>CCL-LGSæ¡†æ¶æ˜¾å¼è§£å†³è¯­ä¹‰å†²çªï¼ŒåŒæ—¶ä¿ç•™ç±»åˆ«è¾¨åˆ«èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20469">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7b7d1fc06b2bb4f60e5d9228874646a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3972e19233aab2a03faef6a5d94784c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-62a1deddab7d7a2e78d281e1ec1d7145.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="ParticleGS-Particle-Based-Dynamics-Modeling-of-3D-Gaussians-for-Prior-free-Motion-Extrapolation"><a href="#ParticleGS-Particle-Based-Dynamics-Modeling-of-3D-Gaussians-for-Prior-free-Motion-Extrapolation" class="headerlink" title="ParticleGS: Particle-Based Dynamics Modeling of 3D Gaussians for   Prior-free Motion Extrapolation"></a>ParticleGS: Particle-Based Dynamics Modeling of 3D Gaussians for   Prior-free Motion Extrapolation</h2><p><strong>Authors:Jinsheng Quan, Chunshi Wang, Yawei Luo</strong></p>
<p>This paper aims to model the dynamics of 3D Gaussians from visual observations to support temporal extrapolation. Existing dynamic 3D reconstruction methods often struggle to effectively learn underlying dynamics or rely heavily on manually defined physical priors, which limits their extrapolation capabilities. To address this issue, we propose a novel dynamic 3D Gaussian Splatting prior-free motion extrapolation framework based on particle dynamics systems. The core advantage of our method lies in its ability to learn differential equations that describe the dynamics of 3D Gaussians, and follow them during future frame extrapolation. Instead of simply fitting to the observed visual frame sequence, we aim to more effectively model the gaussian particle dynamics system. To this end, we introduce a dynamics latent state vector into the standard Gaussian kernel and design a dynamics latent space encoder to extract initial state. Subsequently, we introduce a Neural ODEs-based dynamics module that models the temporal evolution of Gaussian in dynamics latent space. Finally, a Gaussian kernel space decoder is used to decode latent state at the specific time step into the deformation. Experimental results demonstrate that the proposed method achieves comparable rendering quality with existing approaches in reconstruction tasks, and significantly outperforms them in future frame extrapolation. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/QuanJinSheng/ParticleGS">https://github.com/QuanJinSheng/ParticleGS</a>. </p>
<blockquote>
<p>æœ¬æ–‡æ—¨åœ¨ä»è§†è§‰è§‚å¯Ÿä¸­å¯¹3Dé«˜æ–¯åŠ¨æ€è¿›è¡Œå»ºæ¨¡ï¼Œä»¥æ”¯æŒæ—¶é—´å¤–æ¨ã€‚ç°æœ‰çš„åŠ¨æ€3Dé‡å»ºæ–¹æ³•å¾€å¾€éš¾ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ½œåœ¨åŠ¨æ€ï¼Œæˆ–è€…ä¸¥é‡ä¾èµ–äºæ‰‹åŠ¨å®šä¹‰çš„ç‰©ç†å…ˆéªŒï¼Œè¿™é™åˆ¶äº†å…¶å¤–æ¨èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç²’å­åŠ¨åŠ›å­¦ç³»ç»Ÿçš„æ–°å‹åŠ¨æ€3Dé«˜æ–¯Splattingæ— å…ˆéªŒè¿åŠ¨å¤–æ¨æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿå­¦ä¹ æè¿°3Dé«˜æ–¯åŠ¨æ€çš„å¾®åˆ†æ–¹ç¨‹ï¼Œå¹¶åœ¨æœªæ¥å¸§å¤–æ¨è¿‡ç¨‹ä¸­éµå¾ªè¿™äº›æ–¹ç¨‹ã€‚æˆ‘ä»¬çš„ç›®æ ‡ä¸æ˜¯ç®€å•åœ°æ‹Ÿåˆè§‚å¯Ÿåˆ°çš„è§†è§‰å¸§åºåˆ—ï¼Œè€Œæ˜¯æ›´æœ‰æ•ˆåœ°å¯¹é«˜æ–¯ç²’å­åŠ¨åŠ›å­¦ç³»ç»Ÿè¿›è¡Œå»ºæ¨¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨æ ‡å‡†é«˜æ–¯æ ¸ä¸­å¼•å…¥äº†ä¸€ä¸ªåŠ¨æ€æ½œä¼çŠ¶æ€å‘é‡ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªåŠ¨æ€æ½œä¼ç©ºé—´ç¼–ç å™¨æ¥æå–åˆå§‹çŠ¶æ€ã€‚éšåï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºç¥ç»ODEçš„åŠ¨æ€æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯¹åŠ¨æ€æ½œä¼ç©ºé—´ä¸­çš„é«˜æ–¯æ—¶é—´æ¼”åŒ–è¿›è¡Œå»ºæ¨¡ã€‚æœ€åï¼Œä½¿ç”¨é«˜æ–¯æ ¸ç©ºé—´è§£ç å™¨å°†ç‰¹å®šæ—¶é—´æ­¥é•¿çš„æ½œä¼çŠ¶æ€è§£ç ä¸ºå˜å½¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºä»»åŠ¡ä¸Šçš„æ¸²æŸ“è´¨é‡ä¸ç°æœ‰æ–¹æ³•ç›¸å½“ï¼Œå¹¶åœ¨æœªæ¥å¸§å¤–æ¨æ–¹é¢æ˜¾è‘—ä¼˜äºå®ƒä»¬ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/QuanJinSheng/ParticleGS%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/QuanJinSheng/ParticleGSä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20270v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç²’å­åŠ¨åŠ›å­¦ç³»ç»Ÿçš„åŠ¨æ€3Dé«˜æ–¯Splattingæ— å…ˆéªŒè¿åŠ¨å¤–æ¨æ¡†æ¶ï¼Œç”¨äºä»è§†è§‰è§‚æµ‹ä¸­å»ºæ¨¡3Dé«˜æ–¯çš„åŠ¨åŠ›å­¦ä»¥æ”¯æŒæ—¶é—´å¤–æ¨ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿå­¦ä¹ æè¿°3Dé«˜æ–¯åŠ¨åŠ›å­¦çš„å¾®åˆ†æ–¹ç¨‹ï¼Œå¹¶åœ¨æœªæ¥å¸§å¤–æ¨è¿‡ç¨‹ä¸­è·Ÿè¸ªè¿™äº›æ–¹ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºä»»åŠ¡ä¸­çš„æ¸²æŸ“è´¨é‡å¯ä¸ç°æœ‰æ–¹æ³•ç›¸åª²ç¾ï¼Œå¹¶åœ¨æœªæ¥å¸§å¤–æ¨æ–¹é¢æ˜¾è‘—ä¼˜äºå®ƒä»¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æ—¨åœ¨é€šè¿‡å»ºæ¨¡3Dé«˜æ–¯çš„åŠ¨åŠ›å­¦æ¥è§£å†³ç°æœ‰åŠ¨æ€3Dé‡å»ºæ–¹æ³•åœ¨å¤–æ¨èƒ½åŠ›ä¸Šçš„å±€é™æ€§ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºç²’å­åŠ¨åŠ›å­¦ç³»ç»Ÿçš„åŠ¨æ€3Dé«˜æ–¯Splattingæ— å…ˆéªŒè¿åŠ¨å¤–æ¨æ¡†æ¶ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ æè¿°3Dé«˜æ–¯åŠ¨åŠ›å­¦çš„å¾®åˆ†æ–¹ç¨‹ï¼Œå¹¶åœ¨æœªæ¥å¸§å¤–æ¨è¿‡ç¨‹ä¸­è·Ÿè¸ªè¿™äº›æ–¹ç¨‹æ¥æå‡å¤–æ¨èƒ½åŠ›ã€‚</li>
<li>è®ºæ–‡å¼•å…¥äº†åŠ¨åŠ›å­¦æ½œåœ¨çŠ¶æ€å‘é‡å’ŒåŠ¨åŠ›å­¦æ½œåœ¨ç©ºé—´ç¼–ç å™¨æ¥æå–åˆå§‹çŠ¶æ€ã€‚</li>
<li>ä½¿ç”¨åŸºäºç¥ç»ODEçš„åŠ¨åŠ›å­¦æ¨¡å—æ¥æ¨¡æ‹Ÿé«˜æ–¯åœ¨åŠ¨åŠ›å­¦æ½œåœ¨ç©ºé—´ä¸­çš„æ—¶é—´æ¼”åŒ–ã€‚</li>
<li>è®ºæ–‡ä½¿ç”¨é«˜æ–¯æ ¸ç©ºé—´è§£ç å™¨å°†ç‰¹å®šæ—¶é—´æ­¥é•¿çš„æ½œåœ¨çŠ¶æ€è§£ç ä¸ºå˜å½¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20270">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-77ae5c3980427d938449818211b6bc78.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3596ae3a9c753c45ebeb7f9e61508959.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fb463fc2b154229d78d084e84a4a7dc8.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Sparse2DGS-Sparse-View-Surface-Reconstruction-using-2D-Gaussian-Splatting-with-Dense-Point-Cloud"><a href="#Sparse2DGS-Sparse-View-Surface-Reconstruction-using-2D-Gaussian-Splatting-with-Dense-Point-Cloud" class="headerlink" title="Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian   Splatting with Dense Point Cloud"></a>Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian   Splatting with Dense Point Cloud</h2><p><strong>Authors:Natsuki Takama, Shintaro Ito, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki</strong></p>
<p>Gaussian Splatting (GS) has gained attention as a fast and effective method for novel view synthesis. It has also been applied to 3D reconstruction using multi-view images and can achieve fast and accurate 3D reconstruction. However, GS assumes that the input contains a large number of multi-view images, and therefore, the reconstruction accuracy significantly decreases when only a limited number of input images are available. One of the main reasons is the insufficient number of 3D points in the sparse point cloud obtained through Structure from Motion (SfM), which results in a poor initialization for optimizing the Gaussian primitives. We propose a new 3D reconstruction method, called Sparse2DGS, to enhance 2DGS in reconstructing objects using only three images. Sparse2DGS employs DUSt3R, a fundamental model for stereo images, along with COLMAP MVS to generate highly accurate and dense 3D point clouds, which are then used to initialize 2D Gaussians. Through experiments on the DTU dataset, we show that Sparse2DGS can accurately reconstruct the 3D shapes of objects using just three images. </p>
<blockquote>
<p>é«˜æ–¯è´´ç‰‡ï¼ˆGSï¼‰ä½œä¸ºä¸€ç§å¿«é€Ÿæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå·²ç»å¼•èµ·äº†äººä»¬å¯¹æ–°å‹è§†å›¾åˆæˆæŠ€æœ¯çš„å…³æ³¨ã€‚å®ƒä¹Ÿè¢«åº”ç”¨äºä½¿ç”¨å¤šè§†å›¾å›¾åƒçš„3Dé‡å»ºï¼Œå¹¶èƒ½å®ç°å¿«é€Ÿå‡†ç¡®çš„3Dé‡å»ºã€‚ç„¶è€Œï¼ŒGSå‡å®šè¾“å…¥åŒ…å«å¤§é‡å¤šè§†å›¾å›¾åƒï¼Œå› æ­¤å½“åªæœ‰æœ‰é™æ•°é‡çš„è¾“å…¥å›¾åƒå¯ç”¨æ—¶ï¼Œé‡å»ºç²¾åº¦ä¼šå¤§å¤§é™ä½ã€‚ä¸»è¦åŸå› ä¹‹ä¸€æ˜¯é€šè¿‡è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰è·å¾—çš„ç¨€ç–ç‚¹äº‘ä¸­çš„3Dç‚¹æ•°ä¸è¶³ï¼Œè¿™å¯¼è‡´é«˜æ–¯åŸå§‹å€¼çš„ä¼˜åŒ–åˆå§‹åŒ–è¾ƒå·®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„3Dé‡å»ºæ–¹æ³•ï¼Œç§°ä¸ºSparse2DGSï¼Œä»¥å¢å¼ºä»…ä½¿ç”¨ä¸‰å¹…å›¾åƒè¿›è¡Œå¯¹è±¡é‡å»ºçš„2DGSã€‚Sparse2DGSé‡‡ç”¨é€‚ç”¨äºç«‹ä½“å›¾åƒçš„DUSt3RåŸºæœ¬æ¨¡å‹ï¼Œç»“åˆCOLMAP MVSç”Ÿæˆé«˜åº¦å‡†ç¡®ä¸”å¯†é›†çš„3Dç‚¹äº‘ï¼Œç„¶åç”¨äºåˆå§‹åŒ–2Dé«˜æ–¯ã€‚é€šè¿‡å¯¹DTUæ•°æ®é›†çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜Sparse2DGSä»…ä½¿ç”¨ä¸‰å¹…å›¾åƒå°±èƒ½å‡†ç¡®é‡å»ºå¯¹è±¡çš„3Då½¢çŠ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19854v1">PDF</a> Accepted to ICIP 2025</p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSparse2DGSçš„æ”¹è¿›æ–¹æ³•ï¼Œé’ˆå¯¹ä»…æœ‰å°‘é‡è¾“å…¥å›¾åƒæ—¶Gaussian Splattingï¼ˆGSï¼‰åœ¨3Dé‡å»ºä¸­çš„ä¸è¶³è¿›è¡Œä¼˜åŒ–ã€‚Sparse2DGSé€šè¿‡ç»“åˆDUSt3Rç«‹ä½“å›¾åƒåŸºç¡€æ¨¡å‹å’ŒCOLMAP MVSæŠ€æœ¯ï¼Œç”Ÿæˆé«˜ç²¾åº¦å¯†é›†ä¸‰ç»´ç‚¹äº‘ï¼Œç”¨äºåˆå§‹åŒ–äºŒç»´é«˜æ–¯åˆ†å¸ƒã€‚å®éªŒè¯æ˜ï¼ŒSparse2DGSä»…ä½¿ç”¨ä¸‰å¼ å›¾åƒå³å¯å‡†ç¡®é‡å»ºç‰©ä½“ä¸‰ç»´å½¢çŠ¶ã€‚</p>
<p><strong>è¦ç‚¹æ€»ç»“</strong></p>
<ol>
<li>Gaussian Splatting (GS) åœ¨å¿«é€Ÿæœ‰æ•ˆçš„ä¸‰ç»´é‡å»ºæ–¹é¢å±•ç°å‡ºè‰¯å¥½æ€§èƒ½ï¼Œä½†å®ƒåœ¨è¾“å…¥å›¾åƒæ•°é‡æœ‰é™æ—¶çš„é‡å»ºç²¾åº¦ä¼šæ˜¾è‘—é™ä½ã€‚</li>
<li>ä¸»è¦åŸå› åœ¨äºç¨€ç–ç‚¹äº‘å¯¼è‡´çš„åˆå§‹åŒ–ä¸ä½³ï¼Œè¿™äº›ç¨€ç–ç‚¹äº‘æ˜¯é€šè¿‡ä»è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰è·å¾—çš„ã€‚</li>
<li>Sparse2DGSæ–¹æ³•è¢«æå‡ºä»¥æ”¹å–„ä¸Šè¿°é—®é¢˜ï¼Œæ­¤æ–¹æ³•èƒ½å¤Ÿåœ¨ä½¿ç”¨ä»…ä¸‰å¼ å›¾åƒçš„æƒ…å†µä¸‹é‡å»ºç‰©ä½“ã€‚</li>
<li>Sparse2DGSç»“åˆäº†DUSt3Rç«‹ä½“å›¾åƒåŸºç¡€æ¨¡å‹å’ŒCOLMAP MVSæŠ€æœ¯ï¼Œç”Ÿæˆé«˜åº¦å‡†ç¡®ä¸”å¯†é›†çš„ä¸‰ç»´ç‚¹äº‘ã€‚</li>
<li>è¿™äº›å¯†é›†çš„ç‚¹äº‘ç”¨äºåˆå§‹åŒ–äºŒç»´é«˜æ–¯åˆ†å¸ƒï¼Œä¸ºåç»­çš„ä¸‰ç»´é‡å»ºæä¾›æ›´å‡†ç¡®çš„åˆå§‹ä¿¡æ¯ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒSparse2DGSæ–¹æ³•èƒ½åœ¨ä»…ä½¿ç”¨ä¸‰å¼ å›¾åƒçš„æƒ…å†µä¸‹ï¼Œå®ç°ç‰©ä½“çš„ä¸‰ç»´å½¢çŠ¶å‡†ç¡®é‡å»ºã€‚</li>
<li>Sparse2DGSæœ‰æœ›ä¸ºåœ¨æœ‰é™å›¾åƒè¾“å…¥æ¡ä»¶ä¸‹çš„ä¸‰ç»´é‡å»ºæä¾›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19854">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-05c3d6530933c1676b14e9d07230d17d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e299d21af3446aa1e0da2aedb6ec65f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d48261dcbaf5e9a1a8a19229bc550c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1df9a9959169b04a37432cda5ae2bab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-827d5e557723272c19330ee6eb5a7250.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="K-Buffers-A-Plug-in-Method-for-Enhancing-Neural-Fields-with-Multiple-Buffers"><a href="#K-Buffers-A-Plug-in-Method-for-Enhancing-Neural-Fields-with-Multiple-Buffers" class="headerlink" title="K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple   Buffers"></a>K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple   Buffers</h2><p><strong>Authors:Haofan Ren, Zunjie Zhu, Xiang Chen, Ming Lu, Rongfeng Lu, Chenggang Yan</strong></p>
<p>Neural fields are now the central focus of research in 3D vision and computer graphics. Existing methods mainly focus on various scene representations, such as neural points and 3D Gaussians. However, few works have studied the rendering process to enhance the neural fields. In this work, we propose a plug-in method named K-Buffers that leverages multiple buffers to improve the rendering performance. Our method first renders K buffers from scene representations and constructs K pixel-wise feature maps. Then, We introduce a K-Feature Fusion Network (KFN) to merge the K pixel-wise feature maps. Finally, we adopt a feature decoder to generate the rendering image. We also introduce an acceleration strategy to improve rendering speed and quality. We apply our method to well-known radiance field baselines, including neural point fields and 3D Gaussian Splatting (3DGS). Extensive experiments demonstrate that our method effectively enhances the rendering performance of neural point fields and 3DGS. </p>
<blockquote>
<p>ç¥ç»åœºç°åœ¨å·²æˆä¸º3Dè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦ç ”ç©¶çš„ä¸­å¿ƒç„¦ç‚¹ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å„ç§åœºæ™¯è¡¨ç¤ºä¸Šï¼Œå¦‚ç¥ç»ç‚¹å’Œ3Dé«˜æ–¯ç­‰ã€‚ç„¶è€Œï¼Œå¾ˆå°‘æœ‰å·¥ä½œç ”ç©¶æ¸²æŸ“è¿‡ç¨‹ä»¥å¢å¼ºç¥ç»åœºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºK-Buffersçš„æ’ä»¶æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨å¤šä¸ªç¼“å†²åŒºæ¥æé«˜æ¸²æŸ“æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆä»åœºæ™¯è¡¨ç¤ºä¸­æ¸²æŸ“Kä¸ªç¼“å†²åŒºï¼Œå¹¶æ„å»ºKä¸ªåƒç´ çº§ç‰¹å¾å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªKç‰¹å¾èåˆç½‘ç»œï¼ˆKFNï¼‰æ¥åˆå¹¶è¿™äº›åƒç´ çº§ç‰¹å¾å›¾ã€‚æœ€åï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªç‰¹å¾è§£ç å™¨æ¥ç”Ÿæˆæ¸²æŸ“å›¾åƒã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ç§åŠ é€Ÿç­–ç•¥æ¥æé«˜æ¸²æŸ“çš„é€Ÿåº¦å’Œè´¨é‡ã€‚æˆ‘ä»¬å°†è¯¥æ–¹æ³•åº”ç”¨äºè‘—åçš„è¾å°„åœºåŸºçº¿ï¼ŒåŒ…æ‹¬ç¥ç»ç‚¹åœºå’Œ3Dé«˜æ–¯Splattingï¼ˆ3DGSï¼‰ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°æé«˜äº†ç¥ç»ç‚¹åœºå’Œ3DGSçš„æ¸²æŸ“æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19564v1">PDF</a> 15 pages, 9 figures, IJCAI 2025</p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œé¢†åŸŸç°åœ¨æ˜¯3Dè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦ç ”ç©¶çš„ä¸­å¿ƒã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨åœºæ™¯è¡¨ç¤ºï¼Œå¦‚ç¥ç»ç‚¹å’Œ3Dé«˜æ–¯ã€‚ç„¶è€Œï¼Œå¾ˆå°‘æœ‰å·¥ä½œç ”ç©¶æ¸²æŸ“è¿‡ç¨‹ä»¥å¢å¼ºç¥ç»ç½‘ç»œé¢†åŸŸçš„æ•ˆæœã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºK-Buffersçš„æ’ä»¶æ–¹æ³•ï¼Œåˆ©ç”¨å¤šä¸ªç¼“å†²åŒºæé«˜æ¸²æŸ“æ€§èƒ½ã€‚è¯¥æ–¹æ³•é¦–å…ˆæ ¹æ®åœºæ™¯è¡¨ç¤ºç”ŸæˆKä¸ªç¼“å†²åŒºï¼Œå¹¶æ„å»ºKä¸ªåƒç´ çº§ç‰¹å¾å›¾ã€‚æ¥ç€ï¼Œå¼•å…¥Kç‰¹å¾èåˆç½‘ç»œï¼ˆKFNï¼‰èåˆè¿™äº›ç‰¹å¾å›¾ã€‚æœ€åï¼Œé‡‡ç”¨ç‰¹å¾è§£ç å™¨ç”Ÿæˆæ¸²æŸ“å›¾åƒã€‚è¿˜ä»‹ç»äº†ä¸€ç§åŠ é€Ÿç­–ç•¥æ¥æé«˜æ¸²æŸ“é€Ÿåº¦å’Œå“è´¨ã€‚å°†è¯¥æ–¹æ³•åº”ç”¨äºç¥ç»ç‚¹åœºå’Œ3Dé«˜æ–¯å–·å°„ï¼ˆ3DGSï¼‰ç­‰è‘—åè¾å°„åœºåŸºçº¿ï¼Œå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæé«˜ç¥ç»ç‚¹åœºå’Œ3DGSçš„æ¸²æŸ“æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œé¢†åŸŸæ˜¯å½“å‰3Dè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦ç ”ç©¶çš„é‡ç‚¹ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨åœºæ™¯è¡¨ç¤ºï¼Œå¦‚ç¥ç»ç‚¹å’Œ3Dé«˜æ–¯ï¼Œä½†å¯¹å¢å¼ºç¥ç»ç½‘ç»œé¢†åŸŸçš„æ¸²æŸ“æ€§èƒ½ç ”ç©¶è¾ƒå°‘ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºK-Buffersçš„æ’ä»¶æ–¹æ³•ï¼Œåˆ©ç”¨å¤šä¸ªç¼“å†²åŒºæ¥æé«˜æ¸²æŸ“æ€§èƒ½ã€‚</li>
<li>K-Buffersæ–¹æ³•åŒ…æ‹¬ç”ŸæˆKä¸ªç¼“å†²åŒºã€æ„å»ºåƒç´ çº§ç‰¹å¾å›¾ã€èåˆç‰¹å¾å›¾ä»¥åŠç”Ÿæˆæ¸²æŸ“å›¾åƒç­‰æ­¥éª¤ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŠ é€Ÿç­–ç•¥æ¥æé«˜æ¸²æŸ“é€Ÿåº¦å’Œå“è´¨ã€‚</li>
<li>å°†K-Buffersæ–¹æ³•åº”ç”¨äºç¥ç»ç‚¹åœºå’Œ3DGSç­‰è¾å°„åœºåŸºçº¿ï¼Œå®éªŒè¯æ˜å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19564">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f1a39577f40d856e2799e0be7b78f4e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad750a55861bbb46982d1eef653d568d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e5a2ce12baf3385789c68dca8ae4af9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97b1b510ba6bd15fa95992aff9908344.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d71dc59cd84e740128bcb3f7e814bd7.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="ADD-SLAM-Adaptive-Dynamic-Dense-SLAM-with-Gaussian-Splatting"><a href="#ADD-SLAM-Adaptive-Dynamic-Dense-SLAM-with-Gaussian-Splatting" class="headerlink" title="ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting"></a>ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting</h2><p><strong>Authors:Wenhua Wu, Chenpeng Su, Siting Zhu, Tianchen Deng, Zhe Liu, Hesheng Wang</strong></p>
<p>Recent advancements in Neural Radiance Fields (NeRF) and 3D Gaussian-based Simultaneous Localization and Mapping (SLAM) methods have demonstrated exceptional localization precision and remarkable dense mapping performance. However, dynamic objects introduce critical challenges by disrupting scene consistency, leading to tracking drift and mapping artifacts. Existing methods that employ semantic segmentation or object detection for dynamic identification and filtering typically rely on predefined categorical priors, while discarding dynamic scene information crucial for robotic applications such as dynamic obstacle avoidance and environmental interaction. To overcome these challenges, we propose ADD-SLAM: an Adaptive Dynamic Dense SLAM framework based on Gaussian splitting. We design an adaptive dynamic identification mechanism grounded in scene consistency analysis, comparing geometric and textural discrepancies between real-time observations and historical maps. Ours requires no predefined semantic category priors and adaptively discovers scene dynamics. Precise dynamic object recognition effectively mitigates interference from moving targets during localization. Furthermore, we propose a dynamic-static separation mapping strategy that constructs a temporal Gaussian model to achieve online incremental dynamic modeling. Experiments conducted on multiple dynamic datasets demonstrate our methodâ€™s flexible and accurate dynamic segmentation capabilities, along with state-of-the-art performance in both localization and mapping. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’ŒåŸºäº3Dé«˜æ–¯çš„åŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰æ–¹æ³•çš„è¿›å±•ï¼Œå·²ç»å±•ç¤ºäº†å‡ºè‰²çš„å®šä½ç²¾åº¦å’Œä»¤äººå°è±¡æ·±åˆ»çš„å¯†é›†æ˜ å°„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒåŠ¨æ€ç‰©ä½“é€šè¿‡ç ´ååœºæ™¯ä¸€è‡´æ€§ï¼Œå¼•å…¥äº†å…³é”®æŒ‘æˆ˜ï¼Œå¯¼è‡´è·Ÿè¸ªæ¼‚ç§»å’Œæ˜ å°„ä¼ªå½±ã€‚ç°æœ‰é‡‡ç”¨è¯­ä¹‰åˆ†å‰²æˆ–ç›®æ ‡æ£€æµ‹è¿›è¡ŒåŠ¨æ€è¯†åˆ«å’Œè¿‡æ»¤çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºé¢„å®šä¹‰çš„åˆ†ç±»å…ˆéªŒçŸ¥è¯†ï¼ŒåŒæ—¶ä¸¢å¼ƒäº†å¯¹äºæœºå™¨äººåº”ç”¨ï¼ˆå¦‚åŠ¨æ€é¿éšœå’Œç¯å¢ƒäº¤äº’ï¼‰è‡³å…³é‡è¦çš„åŠ¨æ€åœºæ™¯ä¿¡æ¯ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ADD-SLAMï¼šä¸€ç§åŸºäºé«˜æ–¯åˆ†è£‚çš„è‡ªé€‚åº”åŠ¨æ€å¯†é›†SLAMæ¡†æ¶ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºåœºæ™¯ä¸€è‡´æ€§åˆ†æçš„è‡ªé€‚åº”åŠ¨æ€è¯†åˆ«æœºåˆ¶ï¼Œé€šè¿‡æ¯”è¾ƒå®æ—¶è§‚å¯Ÿä¸å†å²åœ°å›¾ä¹‹é—´çš„å‡ ä½•å’Œçº¹ç†å·®å¼‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦é¢„å®šä¹‰çš„è¯­ä¹‰ç±»åˆ«å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶èƒ½è‡ªé€‚åº”åœ°å‘ç°åœºæ™¯åŠ¨æ€ã€‚ç²¾ç¡®çš„åŠ¨æ€ç›®æ ‡è¯†åˆ«æœ‰æ•ˆåœ°å‡è½»äº†ç§»åŠ¨ç›®æ ‡åœ¨å®šä½è¿‡ç¨‹ä¸­çš„å¹²æ‰°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨é™åˆ†ç¦»æ˜ å°„ç­–ç•¥ï¼Œå»ºç«‹äº†ä¸€ä¸ªä¸´æ—¶é«˜æ–¯æ¨¡å‹ï¼Œä»¥å®ç°åœ¨çº¿å¢é‡åŠ¨æ€å»ºæ¨¡ã€‚åœ¨å¤šä¸ªåŠ¨æ€æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨åŠ¨æ€åˆ†å‰²æ–¹é¢çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ï¼Œä»¥åŠåœ¨å®šä½å’Œæ˜ å°„æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19420v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ€è¿‘NeRFå’ŒåŸºäº3Dé«˜æ–¯SLAMæ–¹æ³•çš„å‘å±•æ˜¾ç¤ºå‡ºå“è¶Šçš„å®šä½ç²¾åº¦å’Œæ˜¾è‘—çš„å¯†é›†æ˜ å°„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒåŠ¨æ€ç‰©ä½“ç ´åäº†åœºæ™¯çš„ä¸€è‡´æ€§ï¼Œå¯¼è‡´è·Ÿè¸ªæ¼‚ç§»å’Œæ˜ å°„ä¼ªå½±ï¼Œç»™æŠ€æœ¯å®æ–½å¸¦æ¥æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¾é é¢„å…ˆè®¾å®šçš„åˆ†ç±»å…ˆéªŒè¿›è¡ŒåŠ¨æ€è¯†åˆ«å’Œè¿‡æ»¤ï¼Œå´å¿½è§†äº†æœºå™¨äººåº”ç”¨ä¸­è‡³å…³é‡è¦çš„åŠ¨æ€åœºæ™¯ä¿¡æ¯ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºåŸºäºé«˜æ–¯åˆ†è£‚çš„ADD-SLAMè‡ªé€‚åº”åŠ¨æ€å¯†é›†SLAMæ¡†æ¶ã€‚é€šè¿‡åœºæ™¯ä¸€è‡´æ€§åˆ†æè®¾è®¡è‡ªé€‚åº”åŠ¨æ€è¯†åˆ«æœºåˆ¶ï¼Œå¯¹æ¯”å®æ—¶è§‚æµ‹å’Œå†å²åœ°å›¾ä¹‹é—´çš„å‡ ä½•å’Œçº¹ç†å·®å¼‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€é¢„è®¾è¯­ä¹‰ç±»åˆ«å…ˆéªŒï¼Œå¯è‡ªé€‚åº”å‘ç°åœºæ™¯åŠ¨æ€æ€§ã€‚ç²¾ç¡®çš„åŠ¨æ€ç›®æ ‡è¯†åˆ«å¯æœ‰æ•ˆå‡è½»ç§»åŠ¨ç›®æ ‡åœ¨å®šä½è¿‡ç¨‹ä¸­çš„å¹²æ‰°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºåŠ¨æ€é™æ€åˆ†ç¦»æ˜ å°„ç­–ç•¥ï¼Œæ„å»ºä¸´æ—¶é«˜æ–¯æ¨¡å‹å®ç°åœ¨çº¿å¢é‡åŠ¨æ€å»ºæ¨¡ã€‚åœ¨å¤šä¸ªåŠ¨æ€æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰çµæ´»å‡†ç¡®çš„åŠ¨æ€åˆ†å‰²èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨å®šä½å’Œæ˜ å°„æ–¹é¢è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRFå’ŒåŸºäº3Dé«˜æ–¯SLAMæ–¹æ³•çš„æœ€æ–°è¿›å±•æä¾›äº†å“è¶Šçš„å®šä½ç²¾åº¦å’Œå¯†é›†æ˜ å°„æ€§èƒ½ã€‚</li>
<li>åŠ¨æ€ç‰©ä½“å¯¹åœºæ™¯ä¸€è‡´æ€§é€ æˆå¹²æ‰°ï¼Œå½±å“è·Ÿè¸ªå’Œæ˜ å°„ï¼Œæˆä¸ºæŠ€æœ¯æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–é¢„å…ˆè®¾å®šçš„åˆ†ç±»å…ˆéªŒè¿›è¡ŒåŠ¨æ€è¯†åˆ«ï¼Œä½†ç¼ºä¹è‡ªé€‚åº”æ€§å’ŒåŠ¨æ€åœºæ™¯ä¿¡æ¯çš„åˆ©ç”¨ã€‚</li>
<li>ADD-SLAMæ¡†æ¶é€šè¿‡åœºæ™¯ä¸€è‡´æ€§åˆ†æè¿›è¡Œè‡ªé€‚åº”åŠ¨æ€è¯†åˆ«ï¼Œæ— éœ€é¢„è®¾è¯­ä¹‰ç±»åˆ«å…ˆéªŒã€‚</li>
<li>ç²¾ç¡®çš„åŠ¨æ€ç›®æ ‡è¯†åˆ«å‡è½»ç§»åŠ¨ç›®æ ‡å¹²æ‰°å®šä½è¿‡ç¨‹ã€‚</li>
<li>åŠ¨æ€é™æ€åˆ†ç¦»æ˜ å°„ç­–ç•¥åˆ©ç”¨ä¸´æ—¶é«˜æ–¯æ¨¡å‹å®ç°åŠ¨æ€å»ºæ¨¡çš„åœ¨çº¿å¢é‡æ›´æ–°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19420">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f2ae8aa3b98840a8b033c2a286e6ef91.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6366afc04112ad09e87a3f3ae417b61e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a5ec0ac6360978deb11cac5fcedf657.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Triangle-Splatting-for-Real-Time-Radiance-Field-Rendering"><a href="#Triangle-Splatting-for-Real-Time-Radiance-Field-Rendering" class="headerlink" title="Triangle Splatting for Real-Time Radiance Field Rendering"></a>Triangle Splatting for Real-Time Radiance Field Rendering</h2><p><strong>Authors:Jan Held, Renaud Vandeghen, Adrien Deliege, Abdullah Hamdi, Silvio Giancola, Anthony Cioppa, Andrea Vedaldi, Bernard Ghanem, Andrea Tagliasacchi, Marc Van Droogenbroeck</strong></p>
<p>The field of computer graphics was revolutionized by models such as Neural Radiance Fields and 3D Gaussian Splatting, displacing triangles as the dominant representation for photogrammetry. In this paper, we argue for a triangle comeback. We develop a differentiable renderer that directly optimizes triangles via end-to-end gradients. We achieve this by rendering each triangle as differentiable splats, combining the efficiency of triangles with the adaptive density of representations based on independent primitives. Compared to popular 2D and 3D Gaussian Splatting methods, our approach achieves higher visual fidelity, faster convergence, and increased rendering throughput. On the Mip-NeRF360 dataset, our method outperforms concurrent non-volumetric primitives in visual fidelity and achieves higher perceptual quality than the state-of-the-art Zip-NeRF on indoor scenes. Triangles are simple, compatible with standard graphics stacks and GPU hardware, and highly efficient: for the \textit{Garden} scene, we achieve over 2,400 FPS at 1280x720 resolution using an off-the-shelf mesh renderer. These results highlight the efficiency and effectiveness of triangle-based representations for high-quality novel view synthesis. Triangles bring us closer to mesh-based optimization by combining classical computer graphics with modern differentiable rendering frameworks. The project page is <a target="_blank" rel="noopener" href="https://trianglesplatting.github.io/">https://trianglesplatting.github.io/</a> </p>
<blockquote>
<p>è®¡ç®—æœºå›¾å½¢å­¦é¢†åŸŸç»å†äº†Neural Radiance Fieldså’Œ3D Gaussian Splattingç­‰æ¨¡å‹çš„é©å‘½æ€§å˜é©ï¼Œè¿™äº›æ¨¡å‹å–ä»£äº†ä¸‰è§’å½¢åœ¨æ‘„å½±æµ‹é‡ä¸­çš„ä¸»å¯¼åœ°ä½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸»å¼ ä¸‰è§’å½¢çš„å›å½’ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¯å¾®åˆ†çš„æ¸²æŸ“å™¨ï¼Œè¯¥æ¸²æŸ“å™¨é€šè¿‡ç«¯åˆ°ç«¯æ¢¯åº¦ç›´æ¥ä¼˜åŒ–ä¸‰è§’å½¢ã€‚æˆ‘ä»¬é€šè¿‡å°†æ¯ä¸ªä¸‰è§’å½¢æ¸²æŸ“ä¸ºå¯å¾®åˆ†çš„å¹³é¢æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œç»“åˆäº†ä¸‰è§’å½¢çš„æ•ˆç‡å’ŒåŸºäºç‹¬ç«‹åŸå§‹æ•°æ®çš„è‡ªé€‚åº”å¯†åº¦è¡¨ç¤ºã€‚ä¸æµè¡Œçš„2Då’Œ3Dé«˜æ–¯å¹³é¢æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†æ›´é«˜çš„è§†è§‰ä¿çœŸåº¦ã€æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œå¢åŠ çš„æ¸²æŸ“ååé‡ã€‚åœ¨Mip-NeRF360æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦æ–¹é¢è¶…è¶Šäº†å½“å‰çš„éä½“ç§¯åŸå§‹æ•°æ®ï¼Œå¹¶åœ¨å®¤å†…åœºæ™¯ä¸Šå®ç°äº†æ¯”æœ€æ–°æŠ€æœ¯Zip-NeRFæ›´é«˜çš„æ„ŸçŸ¥è´¨é‡ã€‚ä¸‰è§’å½¢ç®€å•ã€å…¼å®¹æ ‡å‡†å›¾å½¢å †æ ˆå’ŒGPUç¡¬ä»¶ï¼Œå¹¶ä¸”æ•ˆç‡æé«˜ï¼šå¯¹äºâ€œèŠ±å›­â€åœºæ™¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ç°æˆçš„ç½‘æ ¼æ¸²æŸ“å™¨åœ¨1280x720åˆ†è¾¨ç‡ä¸‹å®ç°äº†è¶…è¿‡2400å¸§æ¯ç§’çš„å¸§ç‡ã€‚è¿™äº›ç»“æœçªå‡ºäº†åŸºäºä¸‰è§’å½¢çš„è¡¨ç¤ºåœ¨é«˜è´¨é‡æ–°å‹è§†å›¾åˆæˆä¸­çš„æ•ˆç‡å’Œæ•ˆæœã€‚é€šè¿‡ç»“åˆç»å…¸è®¡ç®—æœºå›¾å½¢å­¦ä¸ç°ä»£å¯å¾®åˆ†æ¸²æŸ“æ¡†æ¶ï¼Œä¸‰è§’å½¢ä½¿æˆ‘ä»¬ç¦»åŸºäºç½‘æ ¼çš„ä¼˜åŒ–æ›´è¿‘äº†ä¸€æ­¥ã€‚é¡¹ç›®é¡µé¢æ˜¯<a target="_blank" rel="noopener" href="https://trianglesplatting.github.io/%E3%80%82">https://trianglesplatting.github.io/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19175v1">PDF</a> 18 pages, 13 figures, 10 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»å¼ ä¸‰è§’å½¢çš„å›å½’ï¼Œæå‡ºäº†ä¸€ç§å¯å¾®åˆ†æ¸²æŸ“å™¨ï¼Œè¯¥æ¸²æŸ“å™¨å¯ç›´æ¥ä¼˜åŒ–ä¸‰è§’å½¢ï¼Œé€šè¿‡ç«¯åˆ°ç«¯çš„æ¢¯åº¦å®ç°ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä¸‰è§’å½¢çš„æ•ˆç‡å’ŒåŸºäºç‹¬ç«‹åŸå§‹æ•°æ®çš„è‡ªé€‚åº”å¯†åº¦è¡¨ç¤ºï¼Œå®ç°äº†é«˜è§†è§‰ä¿çœŸåº¦ã€å¿«é€Ÿæ”¶æ•›å’Œå¢åŠ çš„æ¸²æŸ“ååé‡ã€‚åœ¨Mip-NeRF360æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦æ–¹é¢ä¼˜äºå¹¶å‘éä½“ç§¯åŸå§‹æ•°æ®ï¼Œå¹¶ä¸”åœ¨å®¤å†…åœºæ™¯ä¸Šå®ç°äº†é«˜äºç°æœ‰æŠ€æœ¯Zip-NeRFçš„æ„ŸçŸ¥è´¨é‡ã€‚ä¸‰è§’å½¢ç®€å•ã€å…¼å®¹æ ‡å‡†å›¾å½¢å †æ ˆå’ŒGPUç¡¬ä»¶ï¼Œå¹¶ä¸”é«˜æ•ˆã€‚å¯¹äºèŠ±å›­åœºæ™¯ï¼Œä½¿ç”¨ç°æˆçš„ç½‘æ ¼æ¸²æŸ“å™¨åœ¨1280x720åˆ†è¾¨ç‡ä¸‹å®ç°äº†è¶…è¿‡2400å¸§çš„å¸§ç‡ã€‚æ­¤ç ”ç©¶å¼ºè°ƒåŸºäºä¸‰è§’å½¢è¡¨ç¤ºçš„é«˜è´¨é‡æ–°é¢–è§†å›¾åˆæˆçš„æ•ˆç‡å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡ä¸»å¼ ä¸‰è§’å½¢çš„å›å½’ï¼Œåœ¨è®¡ç®—æœºå›¾å½¢é¢†åŸŸæå‡ºä¸€ç§å¯å¾®åˆ†æ¸²æŸ“å™¨ã€‚</li>
<li>è¯¥æ¸²æŸ“å™¨å¯ç›´æ¥ä¼˜åŒ–ä¸‰è§’å½¢ï¼Œé€šè¿‡ç«¯åˆ°ç«¯çš„æ¢¯åº¦å®ç°ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†ä¸‰è§’å½¢çš„æ•ˆç‡å’ŒåŸºäºç‹¬ç«‹åŸå§‹æ•°æ®çš„è‡ªé€‚åº”å¯†åº¦è¡¨ç¤ºã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦ã€æ”¶æ•›é€Ÿåº¦å’Œæ¸²æŸ“ååé‡æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>åœ¨Mip-NeRF360æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœä¼˜äºå¹¶å‘éä½“ç§¯åŸå§‹æ•°æ®æ–¹æ³•ã€‚</li>
<li>åœ¨å®¤å†…åœºæ™¯çš„æ„ŸçŸ¥è´¨é‡ä¸Šå®ç°äº†é«˜äºç°æœ‰æŠ€æœ¯Zip-NeRFçš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19175">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-375612dc1d2a1d9adebe4ba90e5c8a47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-990e5318d43a467cb70917a7b9a65403.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d54aac9e7e70471fcf4f459c92c7897.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7fe2c747dd5836bf6aa5a9e3c8c1f253.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="FHGS-Feature-Homogenized-Gaussian-Splatting"><a href="#FHGS-Feature-Homogenized-Gaussian-Splatting" class="headerlink" title="FHGS: Feature-Homogenized Gaussian Splatting"></a>FHGS: Feature-Homogenized Gaussian Splatting</h2><p><strong>Authors:Q. G. Duan, Benyun Zhao, Mingqiao Han Yijun Huang, Ben M. Chen</strong></p>
<p>Scene understanding based on 3D Gaussian Splatting (3DGS) has recently achieved notable advances. Although 3DGS related methods have efficient rendering capabilities, they fail to address the inherent contradiction between the anisotropic color representation of gaussian primitives and the isotropic requirements of semantic features, leading to insufficient cross-view feature consistency. To overcome the limitation, we proposes $\textit{FHGS}$ (Feature-Homogenized Gaussian Splatting), a novel 3D feature fusion framework inspired by physical models, which can achieve high-precision mapping of arbitrary 2D features from pre-trained models to 3D scenes while preserving the real-time rendering efficiency of 3DGS. Specifically, our $\textit{FHGS}$ introduces the following innovations: Firstly, a universal feature fusion architecture is proposed, enabling robust embedding of large-scale pre-trained modelsâ€™ semantic features (e.g., SAM, CLIP) into sparse 3D structures. Secondly, a non-differentiable feature fusion mechanism is introduced, which enables semantic features to exhibit viewpoint independent isotropic distributions. This fundamentally balances the anisotropic rendering of gaussian primitives and the isotropic expression of features; Thirdly, a dual-driven optimization strategy inspired by electric potential fields is proposed, which combines external supervision from semantic feature fields with internal primitive clustering guidance. This mechanism enables synergistic optimization of global semantic alignment and local structural consistency. More interactive results can be accessed on: <a target="_blank" rel="noopener" href="https://fhgs.cuastro.org/">https://fhgs.cuastro.org/</a>. </p>
<blockquote>
<p>åŸºäº3Dé«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰çš„åœºæ™¯ç†è§£æœ€è¿‘å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚å°½ç®¡ä¸3DGSç›¸å…³çš„æ–¹æ³•å…·æœ‰é«˜æ•ˆçš„æ¸²æŸ“èƒ½åŠ›ï¼Œä½†å®ƒä»¬æ— æ³•è§£å†³é«˜æ–¯åŸºå…ƒçš„æ–¹å‘æ€§é¢œè‰²è¡¨ç¤ºä¸è¯­ä¹‰ç‰¹å¾çš„åŒæ„æ€§è¦æ±‚ä¹‹é—´çš„å›ºæœ‰çŸ›ç›¾ï¼Œå¯¼è‡´è·¨è§†å›¾ç‰¹å¾ä¸€è‡´æ€§ä¸è¶³ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†å—ç‰©ç†æ¨¡å‹å¯å‘çš„ç‰¹å¾åŒè´¨åŒ–é«˜æ–¯å±•å¸ƒï¼ˆFHGSï¼‰è¿™ä¸€æ–°å‹3Dç‰¹å¾èåˆæ¡†æ¶ï¼Œå®ƒå¯ä»¥å®ç°ä»é¢„è®­ç»ƒæ¨¡å‹åˆ°3Dåœºæ™¯çš„ä»»æ„2Dç‰¹å¾çš„é«˜ç²¾åº¦æ˜ å°„ï¼ŒåŒæ—¶ä¿ç•™3DGSçš„å®æ—¶æ¸²æŸ“æ•ˆç‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„FHGSå¼•å…¥äº†ä»¥ä¸‹åˆ›æ–°ç‚¹ï¼šé¦–å…ˆï¼Œæå‡ºäº†ä¸€ç§é€šç”¨ç‰¹å¾èåˆæ¶æ„ï¼Œä½¿å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„è¯­ä¹‰ç‰¹å¾ï¼ˆå¦‚SAMã€CLIPï¼‰èƒ½å¤Ÿç¨³å¥åœ°åµŒå…¥åˆ°ç¨€ç–çš„3Dç»“æ„ä¸­ï¼›å…¶æ¬¡ï¼Œå¼•å…¥äº†ä¸€ç§ä¸å¯å¾®åˆ†çš„ç‰¹å¾èåˆæœºåˆ¶ï¼Œä½¿è¯­ä¹‰ç‰¹å¾å‘ˆç°å‡ºä¸è§†ç‚¹æ— å…³çš„åŒæ„åˆ†å¸ƒã€‚è¿™ä»æ ¹æœ¬ä¸Šå¹³è¡¡äº†é«˜æ–¯åŸºå…ƒçš„æ–¹å‘æ€§æ¸²æŸ“å’Œç‰¹å¾çš„åŒæ„è¡¨è¾¾ï¼›æœ€åï¼Œæå‡ºäº†ä¸€ç§å—ç”µåœºå¯å‘çš„åŒé©±åŠ¨ä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆäº†è¯­ä¹‰ç‰¹å¾åœºçš„å¤–éƒ¨ç›‘ç£ä¸å†…éƒ¨åŸºå…ƒèšç±»æŒ‡å¯¼ã€‚è¯¥æœºåˆ¶å®ç°äº†å…¨å±€è¯­ä¹‰å¯¹é½å’Œå±€éƒ¨ç»“æ„ä¸€è‡´æ€§çš„ååŒä¼˜åŒ–ã€‚æ›´å¤šäº’åŠ¨ç»“æœå¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://fhgs.cuastro.org/%E3%80%82">https://fhgs.cuastro.org/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19154v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäº3Dé«˜æ–¯ææ‘¹ï¼ˆ3DGSï¼‰çš„åœºæ™¯ç†è§£å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œç›¸å…³æ–¹æ³•è™½å…·æœ‰é«˜æ•ˆçš„æ¸²æŸ“èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†é«˜æ–¯åŸºå…ƒçš„å„å‘å¼‚æ€§ä¸è¯­ä¹‰ç‰¹å¾å„å‘åŒæ€§è¦æ±‚ä¹‹é—´çš„å†…åœ¨çŸ›ç›¾æ—¶å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´è·¨è§†å›¾ç‰¹å¾ä¸€è‡´æ€§ä¸è¶³ã€‚ä¸ºå…‹æœè¿™ä¸€å±€é™ï¼Œæœ¬æ–‡æå‡ºä¸€ç§å—ç‰©ç†æ¨¡å‹å¯å‘çš„ç‰¹å¾åŒè´¨åŒ–é«˜æ–¯ææ‘¹ï¼ˆFHGSï¼‰æ–°å‹ä¸‰ç»´ç‰¹å¾èåˆæ¡†æ¶ï¼Œå®ƒèƒ½åœ¨ä¿ç•™3DGSå®æ—¶æ¸²æŸ“æ•ˆç‡çš„åŒæ—¶ï¼Œå®ç°é¢„è®­ç»ƒæ¨¡å‹ä¸­ä»»æ„äºŒç»´ç‰¹å¾çš„é«˜ç²¾åº¦æ˜ å°„åˆ°ä¸‰ç»´åœºæ™¯ã€‚FHGSçš„åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼šé€šç”¨ç‰¹å¾èåˆæ¶æ„ã€éå¯å¾®ç‰¹å¾èåˆæœºåˆ¶åŠå—ç”µåœºå¯å‘çš„åŒé©±åŠ¨ä¼˜åŒ–ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSåœ¨åœºæ™¯ç†è§£æ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å­˜åœ¨é«˜æ–¯åŸºå…ƒå„å‘å¼‚æ€§ä¸è¯­ä¹‰ç‰¹å¾å„å‘åŒæ€§è¦æ±‚çš„çŸ›ç›¾ï¼Œå¯¼è‡´è·¨è§†å›¾ç‰¹å¾ä¸€è‡´æ€§ä¸è¶³ã€‚</li>
<li>æå‡ºFHGSæ–°å‹ä¸‰ç»´ç‰¹å¾èåˆæ¡†æ¶ï¼Œç»“åˆç‰©ç†æ¨¡å‹å®ç°é«˜æ•ˆæ¸²æŸ“ä¸é«˜ç²¾åº¦æ˜ å°„ã€‚</li>
<li>FHGSåŒ…å«é€šç”¨ç‰¹å¾èåˆæ¶æ„ï¼Œèƒ½åµŒå…¥å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„è¯­ä¹‰ç‰¹å¾åˆ°ç¨€ç–ä¸‰ç»´ç»“æ„ã€‚</li>
<li>å¼•å…¥éå¯å¾®ç‰¹å¾èåˆæœºåˆ¶ï¼Œä½¿è¯­ä¹‰ç‰¹å¾å±•ç°è§†ç‚¹ç‹¬ç«‹å„å‘åŒæ€§åˆ†å¸ƒï¼Œå¹³è¡¡é«˜æ–¯åŸºå…ƒçš„å„å‘å¼‚æ€§ä¸ç‰¹å¾çš„å„å‘åŒæ€§è¡¨è¾¾ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19154">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e818cb90f2d08b06a33a8a44a1f1484e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16c8ce144611c52b9ce4d0cf9a71e013.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d1fe25389250a389730c119948e486b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d4d72ba1d8a8d36f13efb13f43717d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2ea9679d5accd112f2ec8cd77488edfb.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="VPGS-SLAM-Voxel-based-Progressive-3D-Gaussian-SLAM-in-Large-Scale-Scenes"><a href="#VPGS-SLAM-Voxel-based-Progressive-3D-Gaussian-SLAM-in-Large-Scale-Scenes" class="headerlink" title="VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale   Scenes"></a>VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale   Scenes</h2><p><strong>Authors:Tianchen Deng, Wenhua Wu, Junjie He, Yue Pan, Xirui Jiang, Shenghai Yuan, Danwei Wang, Hesheng Wang, Weidong Chen</strong></p>
<p>3D Gaussian Splatting has recently shown promising results in dense visual SLAM. However, existing 3DGS-based SLAM methods are all constrained to small-room scenarios and struggle with memory explosion in large-scale scenes and long sequences. To this end, we propose VPGS-SLAM, the first 3DGS-based large-scale RGBD SLAM framework for both indoor and outdoor scenarios. We design a novel voxel-based progressive 3D Gaussian mapping method with multiple submaps for compact and accurate scene representation in large-scale and long-sequence scenes. This allows us to scale up to arbitrary scenes and improves robustness (even under pose drifts). In addition, we propose a 2D-3D fusion camera tracking method to achieve robust and accurate camera tracking in both indoor and outdoor large-scale scenes. Furthermore, we design a 2D-3D Gaussian loop closure method to eliminate pose drift. We further propose a submap fusion method with online distillation to achieve global consistency in large-scale scenes when detecting a loop. Experiments on various indoor and outdoor datasets demonstrate the superiority and generalizability of the proposed framework. The code will be open source on <a target="_blank" rel="noopener" href="https://github.com/dtc111111/vpgs-slam">https://github.com/dtc111111/vpgs-slam</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯ç³ŠåŒ–æœ€è¿‘åœ¨å¯†é›†è§†è§‰SLAMä¸­æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäº3DGSçš„SLAMæ–¹æ³•éƒ½å±€é™äºå°åœºæ™¯ï¼Œå¹¶åœ¨å¤§è§„æ¨¡åœºæ™¯å’Œé•¿åºåˆ—ä¸­é¢ä¸´å†…å­˜çˆ†ç‚¸çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºVPGS-SLAMï¼Œå®ƒæ˜¯åŸºäº3DGSçš„å®¤å†…å¤–åœºæ™¯å¤§å‹RGBD SLAMæ¡†æ¶ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºä½“ç´ çš„å¤šå­å›¾æ¸è¿›å¼3Dé«˜æ–¯æ˜ å°„æ–¹æ³•ï¼Œç”¨äºå¤§å‹å’Œé•¿åºåˆ—åœºæ™¯çš„ç´§å‡‘å’Œå‡†ç¡®åœºæ™¯è¡¨ç¤ºã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ‰©å±•åˆ°ä»»æ„åœºæ™¯å¹¶æé«˜ç¨³å¥æ€§ï¼ˆå³ä½¿åœ¨å§¿æ€æ¼‚ç§»çš„æƒ…å†µä¸‹ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§2D-3Dèåˆç›¸æœºè·Ÿè¸ªæ–¹æ³•ï¼Œä»¥å®ç°å®¤å†…å¤–å¤§å‹åœºæ™¯çš„ç¨³å¥å’Œç²¾ç¡®ç›¸æœºè·Ÿè¸ªã€‚ä¸ºäº†è¿›ä¸€æ­¥æ¶ˆé™¤å§¿æ€æ¼‚ç§»ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºæ··åˆGausså¾ªç¯çš„æ£€æµ‹æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§å¸¦æœ‰åœ¨çº¿è’¸é¦çš„å­å›¾èåˆæ–¹æ³•ï¼Œä»¥å®ç°å¤§è§„æ¨¡åœºæ™¯ä¸­æ£€æµ‹åˆ°å¾ªç¯æ—¶çš„å…¨å±€ä¸€è‡´æ€§ã€‚åœ¨å„ç§å®¤å†…å’Œå®¤å¤–æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æ‰€æå‡ºæ¡†æ¶çš„ä¼˜è¶Šæ€§å’Œé€šç”¨æ€§ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/dtc111111/vpgs-slam%E4%B8%8A%E5%BC%80%E6%BA%90%E3%80%82">https://github.com/dtc111111/vpgs-slamä¸Šå¼€æºã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.18992v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºVPGS-SLAMçš„å¤§å‹å®¤å†…å¤–RGBD SLAMæ¡†æ¶ï¼Œé‡‡ç”¨åŸºäºä½“ç´ çš„æ–¹æ³•æ„å»ºåœºæ™¯æ¨¡å‹ï¼Œæ”¯æŒå¤šå­å›¾èåˆå®ç°ç´§å‡‘ä¸”å‡†ç¡®çš„åœºæ™¯è¡¨ç¤ºï¼Œé€‚ç”¨äºå¤§è§„æ¨¡å’Œé•¿åºåˆ—åœºæ™¯ã€‚è®¾è®¡äº†ä¸€ç§æœ‰æ•ˆçš„æ‘„åƒæœºè¿½è¸ªç®—æ³•å’ŒäºŒä¸‰ç»´èåˆæ–¹æ³•ä»¥åŠé«˜æ–¯ç¯é—­åˆç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VPGS-SLAMæ˜¯ä¸€ç§é€‚ç”¨äºå¤§è§„æ¨¡åœºæ™¯çš„RGBD SLAMæ¡†æ¶ï¼Œå¯ä»¥æ‰©å±•åˆ°ä»»ä½•è§„æ¨¡çš„åœºæ™¯å¹¶å¢å¼ºå…¶ç¨³å¥æ€§ã€‚</li>
<li>åˆ©ç”¨æ–°é¢–çš„åŸºäºä½“ç´ çš„æ¸è¿›å¼ä¸‰ç»´é«˜æ–¯å»ºæ¨¡æ–¹æ³•å’Œå¤šå­å›¾èåˆç­–ç•¥ï¼Œæé«˜äº†åœºæ™¯çš„å‡†ç¡®æ€§å’Œç´§å‡‘æ€§ã€‚</li>
<li>è®¾è®¡äº†é€‚ç”¨äºå®¤å†…å¤–å¤§è§„æ¨¡åœºæ™¯çš„äºŒç»´-ä¸‰ç»´èåˆç›¸æœºè·Ÿè¸ªæ–¹æ³•ï¼Œç¡®ä¿é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>é€šè¿‡åˆ›æ–°çš„äºŒç»´-ä¸‰ç»´é«˜æ–¯ç¯é—­åˆæ–¹æ³•æ¶ˆé™¤äº†å§¿æ€æ¼‚ç§»é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å­å›¾èåˆæ–¹æ³•ï¼Œé€šè¿‡åœ¨çº¿è’¸é¦å®ç°å¤§è§„æ¨¡åœºæ™¯ä¸­çš„å…¨å±€ä¸€è‡´æ€§æ£€æµ‹ã€‚</li>
<li>åœ¨å„ç§å®¤å†…å¤–æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ¡†æ¶çš„ä¼˜è¶Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.18992">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-98c60ac450b27a6ede2ef721cf042a8f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f6a59803513dc8fba109b8a6d27f535.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-309378bbd6548e017c84dbd3fbc49778.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b4b8eb99f2472e039a55f14c38d1bd5.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Drag-Your-Gaussian-Effective-Drag-Based-Editing-with-Score-Distillation-for-3D-Gaussian-Splatting"><a href="#Drag-Your-Gaussian-Effective-Drag-Based-Editing-with-Score-Distillation-for-3D-Gaussian-Splatting" class="headerlink" title="Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation   for 3D Gaussian Splatting"></a>Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation   for 3D Gaussian Splatting</h2><p><strong>Authors:Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji</strong></p>
<p>Recent advancements in 3D scene editing have been propelled by the rapid development of generative models. Existing methods typically utilize generative models to perform text-guided editing on 3D representations, such as 3D Gaussian Splatting (3DGS). However, these methods are often limited to texture modifications and fail when addressing geometric changes, such as editing a characterâ€™s head to turn around. Moreover, such methods lack accurate control over the spatial position of editing results, as language struggles to precisely describe the extent of edits. To overcome these limitations, we introduce DYG, an effective 3D drag-based editing method for 3D Gaussian Splatting. It enables users to conveniently specify the desired editing region and the desired dragging direction through the input of 3D masks and pairs of control points, thereby enabling precise control over the extent of editing. DYG integrates the strengths of the implicit triplane representation to establish the geometric scaffold of the editing results, effectively overcoming suboptimal editing outcomes caused by the sparsity of 3DGS in the desired editing regions. Additionally, we incorporate a drag-based Latent Diffusion Model into our method through the proposed Drag-SDS loss function, enabling flexible, multi-view consistent, and fine-grained editing. Extensive experiments demonstrate that DYG conducts effective drag-based editing guided by control point prompts, surpassing other baselines in terms of editing effect and quality, both qualitatively and quantitatively. Visit our project page at <a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian">https://quyans.github.io/Drag-Your-Gaussian</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œä¸‰ç»´åœºæ™¯ç¼–è¾‘çš„è¿›å±•å¾—ç›Šäºç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åˆ©ç”¨ç”Ÿæˆæ¨¡å‹å¯¹ä¸‰ç»´è¡¨ç¤ºè¿›è¡Œæ–‡æœ¬å¼•å¯¼ç¼–è¾‘ï¼Œä¾‹å¦‚ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä»…é™äºçº¹ç†ä¿®æ”¹ï¼Œåœ¨åº”å¯¹å‡ ä½•å˜åŒ–æ—¶å¸¸å¸¸å¤±æ•ˆï¼Œæ¯”å¦‚ç¼–è¾‘è§’è‰²å¤´éƒ¨ä½¿å…¶æ—‹è½¬ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨æ§åˆ¶ç¼–è¾‘ç»“æœçš„ç©ºé—´ä½ç½®æ–¹é¢ä¸å¤Ÿç²¾ç¡®ï¼Œå› ä¸ºè¯­è¨€å¾ˆéš¾ç²¾ç¡®æè¿°ç¼–è¾‘çš„ç¨‹åº¦ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†DYGï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ä¸‰ç»´é«˜æ–¯å¹³é“ºçš„æœ‰æ•ˆåŸºäºæ‹–æ‹½çš„ä¸‰ç»´ç¼–è¾‘æ–¹æ³•ã€‚å®ƒä½¿ç”¨æˆ·å¯ä»¥é€šè¿‡è¾“å…¥ä¸‰ç»´æ©ç å’Œæ§åˆ¶ç‚¹å¯¹ï¼Œæ–¹ä¾¿åœ°æŒ‡å®šæ‰€éœ€çš„ç¼–è¾‘åŒºåŸŸå’Œæ‹–æ‹½æ–¹å‘ï¼Œä»è€Œå®ç°å¯¹ç¼–è¾‘ç¨‹åº¦çš„ç²¾ç¡®æ§åˆ¶ã€‚DYGç»“åˆäº†éšå¼triplaneè¡¨ç¤ºæ³•çš„ä¼˜ç‚¹ï¼Œå»ºç«‹ç¼–è¾‘ç»“æœçš„ä¸‰ç»´éª¨æ¶ï¼Œæœ‰æ•ˆå…‹æœäº†åœ¨æ‰€éœ€ç¼–è¾‘åŒºåŸŸå†…ï¼Œ3DGSç¨€ç–å¯¼è‡´çš„ç¼–è¾‘ç»“æœä¸ç†æƒ³é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºçš„Drag-SDSæŸå¤±å‡½æ•°ï¼Œå°†åŸºäºæ‹–æ‹½çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹èå…¥æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå®ç°äº†çµæ´»ã€å¤šè§†è§’ä¸€è‡´ã€ç²¾ç»†çš„ç¼–è¾‘ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDYGé€šè¿‡æ§åˆ¶ç‚¹æç¤ºè¿›è¡Œæœ‰æ•ˆçš„åŸºäºæ‹–æ‹½çš„ç¼–è¾‘ï¼Œåœ¨ç¼–è¾‘æ•ˆæœå’Œå“è´¨æ–¹é¢éƒ½è¶…è¿‡äº†å…¶ä»–åŸºçº¿æ–¹æ³•ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢<a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian%E4%BA%86%E8%A7%A3%E8%AF%A6%E6%83%85%E3%80%82">https://quyans.github.io/Drag-Your-Gaussianäº†è§£è¯¦æƒ…ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18672v6">PDF</a> Visit our project page at <a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian">https://quyans.github.io/Drag-Your-Gaussian</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäº3Dæ‹–æ”¾ç¼–è¾‘æ–¹æ³•çš„çªç ´æ€§ç ”ç©¶ï¼Œè¯¥æ–¹æ³•é’ˆå¯¹3Dé«˜æ–¯æ ·æ¡ï¼ˆ3DGSï¼‰è¿›è¡Œæ”¹è¿›ï¼Œé€šè¿‡å¼•å…¥æ‹–æ”¾ç¼–è¾‘å’Œéšå¼triplaneè¡¨ç¤ºï¼Œå®ç°äº†å¯¹3Dåœºæ™¯çš„ç²¾ç¡®ç¼–è¾‘ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡è¾“å…¥3Dé®ç½©å’Œæ§åˆ¶ç‚¹æ¥æŒ‡å®šç¼–è¾‘åŒºåŸŸå’Œæ‹–åŠ¨æ–¹å‘ï¼Œä»è€Œå®ç°ç²¾ç¡®çš„ç¼–è¾‘æ§åˆ¶ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ç»“åˆäº†åŸºäºæ‹–åŠ¨çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡æå‡ºçš„Drag-SDSæŸå¤±å‡½æ•°ï¼Œå®ç°äº†çµæ´»ã€å¤šè§†è§’ä¸€è‡´å’Œç²¾ç»†çš„ç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥æ‹–æ”¾ç¼–è¾‘æ–¹æ³•ä»¥å…‹æœç°æœ‰3Dåœºæ™¯ç¼–è¾‘æ–¹æ³•çš„å±€é™æ€§ã€‚</li>
<li>ä½¿ç”¨è¾“å…¥3Dé®ç½©å’Œæ§åˆ¶ç‚¹æ¥æŒ‡å®šç¼–è¾‘åŒºåŸŸå’Œæ‹–åŠ¨æ–¹å‘ï¼Œå®ç°ç²¾ç¡®ç¼–è¾‘æ§åˆ¶ã€‚</li>
<li>ç»“åˆéšå¼triplaneè¡¨ç¤ºå»ºç«‹ç¼–è¾‘ç»“æœå‡ ä½•æ¡†æ¶ï¼Œå…‹æœ3DGSåœ¨ç¼–è¾‘åŒºåŸŸçš„ç¨€ç–æ€§é—®é¢˜ã€‚</li>
<li>èå…¥åŸºäºæ‹–åŠ¨çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡Drag-SDSæŸå¤±å‡½æ•°å®ç°çµæ´»ã€å¤šè§†è§’ä¸€è‡´å’Œç²¾ç»†çš„ç¼–è¾‘ã€‚</li>
<li>è¯¥æ–¹æ³•è¶…è¶Šäº†å…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œåœ¨ç¼–è¾‘æ•ˆæœå’Œå“è´¨ä¸Šè¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>é¡¹ç›®é¡µé¢æä¾›äº†æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œèµ„æºã€‚</li>
<li>æ­¤æ–¹æ³•æœ‰åŠ©äºæ¨åŠ¨3Dåœºæ™¯ç¼–è¾‘æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18672">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1e9fbee92af019f94843f9d09ce1926b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32ff45e272d6e24c63eeb2e76f5ba032.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8417e6fbf6e3b5bf38b6c11633406bd2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c3cf313e5a992e9cedcf7def299ceaa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7075119665659de91aa689086c05cb31.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="3D-Convex-Splatting-Radiance-Field-Rendering-with-3D-Smooth-Convexes"><a href="#3D-Convex-Splatting-Radiance-Field-Rendering-with-3D-Smooth-Convexes" class="headerlink" title="3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes"></a>3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes</h2><p><strong>Authors:Jan Held, Renaud Vandeghen, Abdullah Hamdi, Adrien Deliege, Anthony Cioppa, Silvio Giancola, Andrea Vedaldi, Bernard Ghanem, Marc Van Droogenbroeck</strong></p>
<p>Recent advances in radiance field reconstruction, such as 3D Gaussian Splatting (3DGS), have achieved high-quality novel view synthesis and fast rendering by representing scenes with compositions of Gaussian primitives. However, 3D Gaussians present several limitations for scene reconstruction. Accurately capturing hard edges is challenging without significantly increasing the number of Gaussians, creating a large memory footprint. Moreover, they struggle to represent flat surfaces, as they are diffused in space. Without hand-crafted regularizers, they tend to disperse irregularly around the actual surface. To circumvent these issues, we introduce a novel method, named 3D Convex Splatting (3DCS), which leverages 3D smooth convexes as primitives for modeling geometrically-meaningful radiance fields from multi-view images. Smooth convex shapes offer greater flexibility than Gaussians, allowing for a better representation of 3D scenes with hard edges and dense volumes using fewer primitives. Powered by our efficient CUDA-based rasterizer, 3DCS achieves superior performance over 3DGS on benchmarks such as Mip-NeRF360, Tanks and Temples, and Deep Blending. Specifically, our method attains an improvement of up to 0.81 in PSNR and 0.026 in LPIPS compared to 3DGS while maintaining high rendering speeds and reducing the number of required primitives. Our results highlight the potential of 3D Convex Splatting to become the new standard for high-quality scene reconstruction and novel view synthesis. Project page: convexsplatting.github.io. </p>
<blockquote>
<p>è¿‘æœŸåœ¨è¾å°„åœºé‡å»ºæ–¹é¢çš„è¿›å±•ï¼Œå¦‚3Dé«˜æ–¯å–·å°„ï¼ˆ3DGSï¼‰ï¼Œé€šè¿‡ä½¿ç”¨é«˜æ–¯åŸºæœ¬ä½“çš„ç»„åˆæ¥è¡¨ç¤ºåœºæ™¯ï¼Œå®ç°äº†é«˜è´¨é‡çš„æ–°è§†è§’åˆæˆå’Œå¿«é€Ÿæ¸²æŸ“ã€‚ç„¶è€Œï¼Œ3Dé«˜æ–¯å¯¹äºåœºæ™¯é‡å»ºå­˜åœ¨è‹¥å¹²å±€é™æ€§ã€‚å‡†ç¡®åœ°æ•æ‰ç¡¬è¾¹ç¼˜æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºé«˜æ–¯å‡½æ•°çš„æ•°é‡éš¾ä»¥æ˜¾è‘—å¢åŠ ä»¥é¿å…è¿‡å¤§çš„å†…å­˜å ç”¨ã€‚æ­¤å¤–ï¼Œç”±äºå®ƒä»¬åœ¨ç©ºé—´ä¸­ä¼šæ‰©æ•£ï¼Œå› æ­¤éš¾ä»¥è¡¨ç¤ºå¹³é¢è¡¨é¢ã€‚å¦‚æœæ²¡æœ‰æ‰‹å·¥åˆ¶å®šçš„æ­£åˆ™åŒ–å™¨ï¼Œå®ƒä»¬å¾€å¾€ä¼šå›´ç»•å®é™…è¡¨é¢ä¸è§„åˆ™åœ°åˆ†æ•£ã€‚ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç§°ä¸º3Då‡¸å–·å°„ï¼ˆ3DCSï¼‰ï¼Œå®ƒåˆ©ç”¨3Då¹³æ»‘å‡¸ä½“ä½œä¸ºåŸºæœ¬ä½“ï¼Œä»å¤šè§†è§’å›¾åƒå¯¹å‡ ä½•æ„ä¹‰çš„è¾å°„åœºè¿›è¡Œå»ºæ¨¡ã€‚å¹³æ»‘çš„å‡¸å½¢æä¾›äº†æ¯”é«˜æ–¯æ›´å¤§çš„çµæ´»æ€§ï¼Œå…è®¸ä½¿ç”¨è¾ƒå°‘çš„åŸå§‹åŸºæœ¬ä½“æ›´å¥½åœ°è¡¨ç¤ºå…·æœ‰ç¡¬è¾¹ç¼˜å’Œå¯†é›†ä½“ç§¯çš„3Dåœºæ™¯ã€‚é€šè¿‡åŸºäºCUDAçš„é«˜æ•ˆå…‰æ …åŒ–å™¨çš„æ”¯æŒï¼Œ3DCSåœ¨Mip-NeRF360ã€å¦å…‹ä¸å¯ºåº™ä»¥åŠæ·±åº¦æ··åˆç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ä¼˜äº3DGSã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸3DGSç›¸æ¯”ï¼Œåœ¨PSNRä¸Šæé«˜äº†é«˜è¾¾0.81ï¼Œåœ¨LPIPSä¸Šæé«˜äº†0.026ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ¸²æŸ“é€Ÿåº¦å¹¶å‡å°‘äº†æ‰€éœ€åŸå§‹åŸºæœ¬ä½“çš„æ•°é‡ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†3Då‡¸å–·å°„åœ¨é«˜è´¨é‡åœºæ™¯é‡å»ºå’Œæ–°è§†è§’åˆæˆæ–¹é¢çš„æ½œåŠ›ï¼Œæœ‰æœ›æˆä¸ºæ–°çš„æ ‡å‡†ã€‚é¡¹ç›®é¡µé¢ï¼šconvexsplatting.github.ioã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.14974v3">PDF</a> Accepted at CVPR 2025 as Highlight. 13 pages, 13 figures, 10 tables</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæœ€æ–°çš„ä¸‰ç»´å‡¸å—æ¨¡å‹æŠ€æœ¯çš„3D Convex Splattingï¼ˆç®€ç§°3DCSï¼‰æ–¹æ³•åœ¨ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ–¹é¢å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚ç›¸è¾ƒäºä¼ ç»Ÿçš„ä¸‰ç»´é«˜æ–¯æ¨¡å‹æŠ€æœ¯ï¼ˆå¦‚3DGSï¼‰ï¼Œå…¶é‡‡ç”¨å¹³æ»‘å‡¸ä½“ä½œä¸ºåŸºæœ¬å•ä½ï¼Œèƒ½æ›´çµæ´»åœ°è¡¨ç¤ºå…·æœ‰ç¡¬è¾¹ç¼˜å’Œå¯†é›†ä½“ç§¯çš„ä¸‰ç»´åœºæ™¯ã€‚æ­¤å¤–ï¼Œå€ŸåŠ©CUDAä¼˜åŒ–åçš„å…‰çº¿è·Ÿè¸ªå™¨ï¼Œä½¿å…¶åœ¨å¤šç§æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºç°æœ‰çš„åŒç±»æ–¹æ³•ï¼Œæœ‰æœ›å–ä»£å…¶ä»–é‡å»ºå’Œåˆæˆæ–¹æ³•æˆä¸ºæ–°æ ‡å‡†ã€‚è¯¦æƒ…è¯·è®¿é—®é¡¹ç›®ä¸»é¡µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.14974">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-52d50ad6b0d0ea2fe2c8eac3311cd7a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8fca9f2c11c57c5a3e5649448d6c42fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c098b3e39829f990b3fb84e06cae3721.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93cbfc28026ca61e19ccea22301098a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e4821e98c02a38879b35be7bfdcbe87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80cc5176c1678c474cbdacb748fa6044.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff24524bd6cceb2cc8e50693862282bc.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-29/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-29/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-29/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a6a9a0c91a1ca27d2a35d3db6ec07a48.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-29  Structure from Collision
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-29/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c4b8eafe704519e8391534976f8146e1.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-29  AniCrafter Customizing Realistic Human-Centric Animation via   Avatar-Background Conditioning in Video Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19710k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
