<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-15  DocAgent A Multi-Agent System for Automated Code Documentation   Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9622a0e405fc2a4437ce21c7de2d4c72.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    43 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-15-æ›´æ–°"><a href="#2025-04-15-æ›´æ–°" class="headerlink" title="2025-04-15 æ›´æ–°"></a>2025-04-15 æ›´æ–°</h1><h2 id="DocAgent-A-Multi-Agent-System-for-Automated-Code-Documentation-Generation"><a href="#DocAgent-A-Multi-Agent-System-for-Automated-Code-Documentation-Generation" class="headerlink" title="DocAgent: A Multi-Agent System for Automated Code Documentation   Generation"></a>DocAgent: A Multi-Agent System for Automated Code Documentation   Generation</h2><p><strong>Authors:Dayu Yang, Antoine Simoulin, Xin Qian, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Grey Yang</strong></p>
<p>High-quality code documentation is crucial for software development especially in the era of AI. However, generating it automatically using Large Language Models (LLMs) remains challenging, as existing approaches often produce incomplete, unhelpful, or factually incorrect outputs. We introduce DocAgent, a novel multi-agent collaborative system using topological code processing for incremental context building. Specialized agents (Reader, Searcher, Writer, Verifier, Orchestrator) then collaboratively generate documentation. We also propose a multi-faceted evaluation framework assessing Completeness, Helpfulness, and Truthfulness. Comprehensive experiments show DocAgent significantly outperforms baselines consistently. Our ablation study confirms the vital role of the topological processing order. DocAgent offers a robust approach for reliable code documentation generation in complex and proprietary repositories. </p>
<blockquote>
<p>é«˜è´¨é‡çš„ä»£ç æ–‡æ¡£å¯¹è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ã€‚ç„¶è€Œï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç°æœ‰æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿä¸å®Œæ•´ã€æ— å¸®åŠ©æˆ–äº‹å®é”™è¯¯çš„è¾“å‡ºã€‚æˆ‘ä»¬å¼•å…¥äº†DocAgentï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æ‹“æ‰‘ä»£ç å¤„ç†è¿›è¡Œå¢é‡ä¸Šä¸‹æ–‡æ„å»ºçš„æ–°å‹å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿã€‚ä¸“é—¨çš„æ™ºèƒ½ä½“ï¼ˆé˜…è¯»å™¨ã€æœç´¢å™¨ã€å†™å…¥å™¨ã€éªŒè¯å™¨ã€åè°ƒå™¨ï¼‰ååŒç”Ÿæˆæ–‡æ¡£ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªå¤šæ–¹é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€å¸®åŠ©æ€§å’ŒçœŸå®æ€§ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒDocAgentæŒç»­ä¸”æ˜¾è‘—åœ°ä¼˜äºåŸºçº¿ã€‚æˆ‘ä»¬çš„æ¶ˆèç ”ç©¶è¯å®äº†æ‹“æ‰‘å¤„ç†é¡ºåºçš„é‡è¦ä½œç”¨ã€‚DocAgentä¸ºå¤æ‚å’Œä¸“æœ‰å­˜å‚¨åº“ä¸­çš„å¯é ä»£ç æ–‡æ¡£ç”Ÿæˆæä¾›äº†ç¨³å¥çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08725v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¼ºè°ƒé«˜è´¨é‡ä»£ç æ–‡æ¡£åœ¨è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ã€‚ç„¶è€Œï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç°æœ‰æ–¹æ³•å¸¸å¸¸äº§ç”Ÿä¸å®Œæ•´ã€æ— å¸®åŠ©æˆ–äº‹å®é”™è¯¯çš„è¾“å‡ºã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†DocAgentï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œé‡‡ç”¨æ‹“æ‰‘ä»£ç å¤„ç†è¿›è¡Œå¢é‡ä¸Šä¸‹æ–‡æ„å»ºã€‚é€šè¿‡ä¸“é—¨çš„æ™ºèƒ½ä½“ï¼ˆé˜…è¯»å™¨ã€æœç´¢å™¨ã€ç¼–å†™å™¨ã€éªŒè¯å™¨ã€åè°ƒå™¨ï¼‰ååŒç”Ÿæˆæ–‡æ¡£ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§å¤šæ–¹é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€å¸®åŠ©æ€§å’ŒçœŸå®æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDocAgentåœ¨å¤æ‚å’Œä¸“æœ‰å­˜å‚¨åº“ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜è´¨é‡ä»£ç æ–‡æ¡£åœ¨è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ã€‚</li>
<li>ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨ç”Ÿæˆä»£ç æ–‡æ¡£çš„æŒ‘æˆ˜æ€§ï¼Œç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚</li>
<li>DocAgentæ˜¯ä¸€ç§å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œé‡‡ç”¨æ‹“æ‰‘ä»£ç å¤„ç†è¿›è¡Œå¢é‡ä¸Šä¸‹æ–‡æ„å»ºã€‚</li>
<li>DocAgentåŒ…æ‹¬å¤šä¸ªä¸“é—¨æ™ºèƒ½ä½“ï¼šé˜…è¯»å™¨ã€æœç´¢å™¨ã€ç¼–å†™å™¨ã€éªŒè¯å™¨å’Œåè°ƒå™¨ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªå¤šé¢çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€å¸®åŠ©æ€§å’ŒçœŸå®æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDocAgentåœ¨ç”Ÿæˆä»£ç æ–‡æ¡£æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08725">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-84dea2119fbe38fca6011cfa93c867fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fd0534526e9f43e1ed4683ac785090c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-933e5dcbc145e1cb1361f03356dd2b34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28680bc575a8c0f69c2ab5c8868cc5f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcf3626f73471bc8ff67f34fdec24a66.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cae1fe7424320522f3e73e14023dd673.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Genius-A-Generalizable-and-Purely-Unsupervised-Self-Training-Framework-For-Advanced-Reasoning"><a href="#Genius-A-Generalizable-and-Purely-Unsupervised-Self-Training-Framework-For-Advanced-Reasoning" class="headerlink" title="Genius: A Generalizable and Purely Unsupervised Self-Training Framework   For Advanced Reasoning"></a>Genius: A Generalizable and Purely Unsupervised Self-Training Framework   For Advanced Reasoning</h2><p><strong>Authors:Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Qiushi Sun, Kanzhi Cheng, Junxian He, Jun Liu, Zhiyong Wu</strong></p>
<p>Advancing LLM reasoning skills has captivated wide interest. However, current post-training techniques rely heavily on supervisory signals, such as outcome supervision or auxiliary reward models, which face the problem of scalability and high annotation costs. This motivates us to enhance LLM reasoning without the need for external supervision. We introduce a generalizable and purely unsupervised self-training framework, named Genius. Without external auxiliary, Genius requires to seek the optimal response sequence in a stepwise manner and optimize the LLM. To explore the potential steps and exploit the optimal ones, Genius introduces a stepwise foresight re-sampling strategy to sample and estimate the step value by simulating future outcomes. Further, we recognize that the unsupervised setting inevitably induces the intrinsic noise and uncertainty. To provide a robust optimization, we propose an advantage-calibrated optimization (ACO) loss function to mitigate estimation inconsistencies. Combining these techniques together, Genius provides an advanced initial step towards self-improve LLM reasoning with general queries and without supervision, revolutionizing reasoning scaling laws given the vast availability of general queries. The code will be released at <a target="_blank" rel="noopener" href="https://github.com/xufangzhi/Genius">https://github.com/xufangzhi/Genius</a>. </p>
<blockquote>
<p>æ¨è¿›LLMæ¨ç†æŠ€èƒ½å·²ç»å¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„è®­ç»ƒåæŠ€æœ¯å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºç›‘ç£ä¿¡å·ï¼Œå¦‚ç»“æœç›‘ç£æˆ–è¾…åŠ©å¥–åŠ±æ¨¡å‹ï¼Œè¿™é¢ä¸´ç€å¯æ‰©å±•æ€§å’Œé«˜æ ‡æ³¨æˆæœ¬çš„é—®é¢˜ã€‚è¿™æ¿€åŠ±æˆ‘ä»¬åœ¨ä¸éœ€è¦å¤–éƒ¨ç›‘ç£çš„æƒ…å†µä¸‹æé«˜LLMçš„æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé€šç”¨ä¸”çº¯ç²¹çš„æ— ç›‘ç£è‡ªè®­ç»ƒæ¡†æ¶ï¼Œåä¸ºGeniusã€‚æ— éœ€å¤–éƒ¨è¾…åŠ©ï¼ŒGeniuséœ€è¦ä»¥é€æ­¥çš„æ–¹å¼å¯»æ‰¾æœ€ä½³å“åº”åºåˆ—å¹¶ä¼˜åŒ–LLMã€‚ä¸ºäº†æ¢ç´¢æ½œåœ¨çš„æ­¥éª¤å¹¶åˆ©ç”¨æœ€ä½³çš„æ­¥éª¤ï¼ŒGeniuså¼•å…¥äº†ä¸€ç§é€æ­¥å‰ç»æ€§é‡æ–°é‡‡æ ·ç­–ç•¥ï¼Œé€šè¿‡æ¨¡æ‹Ÿæœªæ¥ç»“æœæ¥é‡‡æ ·å¹¶ä¼°ç®—æ­¥éª¤å€¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¤è¯†åˆ°æ— ç›‘ç£è®¾ç½®ä¸å¯é¿å…åœ°ä¼šå¼•å‘å†…åœ¨å™ªå£°å’Œä¸ç¡®å®šæ€§ã€‚ä¸ºäº†æä¾›ç¨³å¥çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¼˜åŠ¿æ ¡å‡†ä¼˜åŒ–ï¼ˆACOï¼‰æŸå¤±å‡½æ•°æ¥ç¼“è§£ä¼°è®¡ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç»“åˆè¿™äº›æŠ€æœ¯ï¼ŒGeniusæ˜¯æœç€æ— éœ€ç›‘ç£çš„è‡ªæˆ‘æ”¹è¿›LLMæ¨ç†æ–¹å‘è¿ˆå‡ºçš„åˆæ­¥ä¸€æ­¥ï¼Œå…·æœ‰å¤„ç†é€šç”¨æŸ¥è¯¢çš„èƒ½åŠ›ï¼Œä»è€Œæ”¹å˜äº†æ¨ç†æ‰©å±•å®šå¾‹ï¼Œåˆ©ç”¨å¤§é‡å¯ç”¨çš„é€šç”¨æŸ¥è¯¢æ¥è¿›è¡Œé©å‘½æ€§çš„è¿›æ­¥ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/xufangzhi/Genius%E4%B8%8A%E5%B8%83%E5%B0%8F%E3%80%82">https://github.com/xufangzhi/Geniusä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08672v1">PDF</a> 14 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>æ¨è¿›LLMæ¨ç†æŠ€èƒ½å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„åè®­ç»ƒæŠ€æœ¯ä¸¥é‡ä¾èµ–äºç›‘ç£ä¿¡å·ï¼Œå¦‚ç»“æœç›‘ç£æˆ–è¾…åŠ©å¥–åŠ±æ¨¡å‹ï¼Œè¿™é¢ä¸´ç€å¯æ‰©å±•æ€§å’Œé«˜æ ‡æ³¨æˆæœ¬çš„é—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€å¤–éƒ¨ç›‘ç£çš„é€šç”¨çº¯è‡ªè®­ç»ƒæ¡†æ¶Geniusï¼Œä»¥æé«˜LLMçš„æ¨ç†èƒ½åŠ›ã€‚Geniusé€šè¿‡é€æ­¥å¯»æ‰¾æœ€ä½³å“åº”åºåˆ—æ¥ä¼˜åŒ–LLMï¼Œæ— éœ€å¤–éƒ¨è¾…åŠ©ã€‚ä¸ºäº†æ¢ç´¢æ½œåœ¨çš„æ­¥éª¤å¹¶åˆ©ç”¨æœ€ä½³æ­¥éª¤ï¼ŒGeniuså¼•å…¥äº†ä¸€ç§é€æ­¥é¢„è§é‡é‡‡æ ·ç­–ç•¥ï¼Œé€šè¿‡æ¨¡æ‹Ÿæœªæ¥ç»“æœæ¥é‡‡æ ·å¹¶ä¼°ç®—æ­¥éª¤å€¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¤è¯†åˆ°æ— ç›‘ç£è®¾ç½®ä¸å¯é¿å…åœ°ä¼šå¼•å‘å†…åœ¨å™ªå£°å’Œä¸ç¡®å®šæ€§ã€‚ä¸ºäº†è¿›è¡Œç¨³å¥ä¼˜åŒ–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¼˜åŠ¿æ ¡å‡†ä¼˜åŒ–ï¼ˆACOï¼‰æŸå¤±å‡½æ•°ï¼Œä»¥å‡è½»ä¼°è®¡ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç»“åˆè¿™äº›æŠ€æœ¯ï¼ŒGeniusä¸ºåœ¨æ²¡æœ‰ç›‘ç£çš„æƒ…å†µä¸‹è‡ªæˆ‘æ”¹è¿›LLMæ¨ç†èƒ½åŠ›æä¾›äº†å…ˆè¿›çš„åˆæ­¥æ­¥éª¤ï¼Œå¯¹äºé€šç”¨æŸ¥è¯¢å…·æœ‰é©å‘½æ€§çš„æ¨ç†æ‰©å±•å®šå¾‹ã€‚ç›¸å…³ä»£ç å°†å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/xufangzhi/Genius%E3%80%82">https://github.com/xufangzhi/Geniusã€‚</a> </p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å½“å‰LLMæ¨ç†æŠ€èƒ½æå‡ä¾èµ–äºç›‘ç£ä¿¡å·ï¼Œå­˜åœ¨å¯æ‰©å±•æ€§å’Œé«˜æ ‡æ³¨æˆæœ¬é—®é¢˜ã€‚</li>
<li>Geniusæ¡†æ¶æ˜¯ä¸€ç§é€šç”¨ã€æ— éœ€å¤–éƒ¨ç›‘ç£çš„çº¯è‡ªè®­ç»ƒæ–¹å¼ï¼Œæ—¨åœ¨æé«˜LLMçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>Geniusé€šè¿‡é€æ­¥å¯»æ‰¾æœ€ä½³å“åº”åºåˆ—è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶å¼•å…¥é€æ­¥é¢„è§é‡é‡‡æ ·ç­–ç•¥æ¥æ¢ç´¢æ½œåœ¨æ­¥éª¤ã€‚</li>
<li>æ— ç›‘ç£è®¾ç½®å¼•å‘å†…åœ¨å™ªå£°å’Œä¸ç¡®å®šæ€§ï¼Œå› æ­¤æå‡ºä¼˜åŠ¿æ ¡å‡†ä¼˜åŒ–ï¼ˆACOï¼‰æŸå¤±å‡½æ•°è¿›è¡Œç¨³å¥ä¼˜åŒ–ã€‚</li>
<li>Geniuså¯¹äºåœ¨æ²¡æœ‰ç›‘ç£çš„æƒ…å†µä¸‹æ”¹è¿›LLMæ¨ç†èƒ½åŠ›å…·æœ‰é‡è¦æ„ä¹‰ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é€šç”¨æŸ¥è¯¢æ—¶ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08672">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5b5b1e1e0cea56d6566c1f7fa0ccd437.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-96abf154e05f9af418d911c46472477c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5bff4a3e511dc7139edc4fd39e61745.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c47c01cceb83fb4e6bfc8c7183c9733.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Gen3DEval-Using-vLLMs-for-Automatic-Evaluation-of-Generated-3D-Objects"><a href="#Gen3DEval-Using-vLLMs-for-Automatic-Evaluation-of-Generated-3D-Objects" class="headerlink" title="Gen3DEval: Using vLLMs for Automatic Evaluation of Generated 3D Objects"></a>Gen3DEval: Using vLLMs for Automatic Evaluation of Generated 3D Objects</h2><p><strong>Authors:Shalini Maiti, Lourdes Agapito, Filippos Kokkinos</strong></p>
<p>Rapid advancements in text-to-3D generation require robust and scalable evaluation metrics that align closely with human judgment, a need unmet by current metrics such as PSNR and CLIP, which require ground-truth data or focus only on prompt fidelity. To address this, we introduce Gen3DEval, a novel evaluation framework that leverages vision large language models (vLLMs) specifically fine-tuned for 3D object quality assessment. Gen3DEval evaluates text fidelity, appearance, and surface quality by analyzing 3D surface normals, without requiring ground-truth comparisons, bridging the gap between automated metrics and user preferences. Compared to state-of-the-art task-agnostic models, Gen3DEval demonstrates superior performance in user-aligned evaluations, placing it as a comprehensive and accessible benchmark for future research on text-to-3D generation. The project page can be found here: \href{<a target="_blank" rel="noopener" href="https://shalini-maiti.github.io/gen3deval.github.io/%7D%7Bhttps://shalini-maiti.github.io/gen3deval.github.io/%7D">https://shalini-maiti.github.io/gen3deval.github.io/}{https://shalini-maiti.github.io/gen3deval.github.io/}</a>. </p>
<blockquote>
<p>éšç€æ–‡æœ¬åˆ°3Dç”Ÿæˆçš„å¿«é€Ÿå‘å±•ï¼Œæˆ‘ä»¬éœ€è¦å¼ºå¤§ä¸”å¯æ‰©å±•çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡éœ€è¦ç´§å¯†ç¬¦åˆäººç±»çš„åˆ¤æ–­ï¼Œè€Œå½“å‰è¯¸å¦‚PSNRå’ŒCLIPç­‰è¯„ä»·æŒ‡æ ‡æ— æ³•æ»¡è¶³è¿™ä¸€éœ€æ±‚ã€‚è¿™äº›æŒ‡æ ‡è¦ä¹ˆéœ€è¦çœŸå®æ•°æ®ï¼Œè¦ä¹ˆåªå…³æ³¨æç¤ºçš„å¿ å®åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Gen3DEvalï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸“é—¨ç”¨äº3Då¯¹è±¡è´¨é‡è¯„ä¼°çš„è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆvLLMsï¼‰ã€‚Gen3DEvalé€šè¿‡åˆ†æ3Dè¡¨é¢æ³•çº¿æ¥è¯„ä¼°æ–‡æœ¬çš„å¿ å®åº¦ã€å¤–è§‚å’Œè¡¨é¢è´¨é‡ï¼Œæ— éœ€çœŸå®æ•°æ®çš„å¯¹æ¯”ï¼Œåœ¨è‡ªåŠ¨åº¦é‡ä¸ç”¨æˆ·åå¥½ä¹‹é—´æ­å»ºäº†æ¡¥æ¢ã€‚ä¸æœ€å…ˆè¿›çš„ä»»åŠ¡æ— å…³æ¨¡å‹ç›¸æ¯”ï¼ŒGen3DEvalåœ¨ç”¨æˆ·å¯¹é½çš„è¯„ä¼°ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œæˆä¸ºæœªæ¥æ–‡æœ¬åˆ°3Dç”Ÿæˆç ”ç©¶å…¨é¢ä¸”æ˜“äºè®¿é—®çš„åŸºå‡†æµ‹è¯•ã€‚é¡¹ç›®é¡µé¢å¯åœ¨æ­¤æ‰¾åˆ°ï¼š[<a target="_blank" rel="noopener" href="https://shalini-maiti.github.io/gen3deval.github.io/]">https://shalini-maiti.github.io/gen3deval.github.io/]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08125v1">PDF</a> CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>éšç€æ–‡æœ¬åˆ°3Dç”Ÿæˆçš„å¿«é€Ÿå‘å±•ï¼Œç°æœ‰çš„è¯„ä¼°æŒ‡æ ‡å¦‚PSNRå’ŒCLIPå·²æ— æ³•æ»¡è¶³éœ€æ±‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºGen3DEvalè¯„ä¼°æ¡†æ¶ï¼Œåˆ©ç”¨ç‰¹å®šå¾®è°ƒç”¨äºè¯„ä¼°3Dç‰©ä½“è´¨é‡çš„è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆvLLMsï¼‰ã€‚Gen3DEvalå¯åˆ†ææ— éœ€çœŸå®å¯¹æ¯”çš„3Dè¡¨é¢æ³•çº¿ï¼Œè¯„ä¼°æ–‡æœ¬å¿ å®åº¦ã€å¤–è§‚å’Œè¡¨é¢è´¨é‡ï¼Œç¼©å°äº†è‡ªåŠ¨åŒ–æŒ‡æ ‡ä¸ç”¨æˆ·åå¥½ä¹‹é—´çš„å·®è·ã€‚ç›¸è¾ƒäºç°æœ‰ä»»åŠ¡æ— å…³æ¨¡å‹ï¼ŒGen3DEvalåœ¨ç”¨æˆ·è¯„ä»·ä¸­è¡¨ç°æ›´ä½³ï¼Œä¸ºæœªæ¥æ–‡æœ¬åˆ°3Dç”Ÿæˆç ”ç©¶æä¾›äº†å…¨é¢ä¸”æ˜“äºä½¿ç”¨çš„åŸºå‡†ã€‚é¡¹ç›®é¡µé¢ä½äºï¼š<a target="_blank" rel="noopener" href="https://shalini-maiti.github.io/gen3deval.github.io/">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰æ–‡æœ¬åˆ°3Dç”Ÿæˆçš„è¯„ä¼°æŒ‡æ ‡å­˜åœ¨å±€é™æ€§ï¼Œéœ€è¦æ›´å®Œå–„çš„è¯„ä¼°æ–¹æ³•ã€‚</li>
<li>Gen3DEvalåˆ©ç”¨è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆvLLMsï¼‰è¯„ä¼°3Dç‰©ä½“è´¨é‡ï¼Œä¸ºå¸‚åœºæä¾›äº†æ–°é¢–çš„è¯„ä»·æ¡†æ¶ã€‚</li>
<li>Gen3DEvalå¯åˆ†æ3Dè¡¨é¢æ³•çº¿ï¼Œè¯„ä¼°æ–‡æœ¬çš„å¿ å®åº¦ã€å¤–è§‚å’Œè¡¨é¢è´¨é‡ã€‚</li>
<li>Gen3DEvalæ— éœ€çœŸå®å¯¹æ¯”æ•°æ®å³å¯è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>Gen3DEvalç¼©å°äº†è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ä¸ç”¨æˆ·åå¥½ä¹‹é—´çš„å·®è·ã€‚</li>
<li>Gen3DEvalåœ¨ç”¨æˆ·è¯„ä»·ä¸­è¡¨ç°ä¼˜äºç°æœ‰ä»»åŠ¡æ— å…³æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08125">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-665f48ab091aefe69ec9d1091ccba08a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-751d5abeb828dfb9173de94ede867e12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11b748edaccc1dc809131cea05a4e1fa.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DeepSeek-vs-o3-mini-How-Well-can-Reasoning-LLMs-Evaluate-MT-and-Summarization"><a href="#DeepSeek-vs-o3-mini-How-Well-can-Reasoning-LLMs-Evaluate-MT-and-Summarization" class="headerlink" title="DeepSeek vs. o3-mini: How Well can Reasoning LLMs Evaluate MT and   Summarization?"></a>DeepSeek vs. o3-mini: How Well can Reasoning LLMs Evaluate MT and   Summarization?</h2><p><strong>Authors:Daniil Larionov, Sotaro Takeshita, Ran Zhang, Yanran Chen, Christoph Leiter, Zhipin Wang, Christian Greisinger, Steffen Eger</strong></p>
<p>Reasoning-enabled large language models (LLMs) have recently demonstrated impressive performance in complex logical and mathematical tasks, yet their effectiveness in evaluating natural language generation remains unexplored. This study systematically compares reasoning-based LLMs (DeepSeek-R1 and OpenAI o3) with their non-reasoning counterparts across machine translation (MT) and text summarization (TS) evaluation tasks. We evaluate eight models across three architectural categories, including state-of-the-art reasoning models, their distilled variants (ranging from 8B to 70B parameters), and equivalent conventional, non-reasoning LLMs. Our experiments on WMT23 and SummEval benchmarks reveal that the benefits of reasoning capabilities are highly model and task-dependent: while OpenAI o3-mini models show consistent performance improvements with increased reasoning intensity, DeepSeek-R1 underperforms compared to its non-reasoning variant, with exception to certain aspects of TS evaluation. Correlation analysis demonstrates that increased reasoning token usage positively correlates with evaluation quality in o3-mini models. Furthermore, our results show that distillation of reasoning capabilities maintains reasonable performance in medium-sized models (32B) but degrades substantially in smaller variants (8B). This work provides the first comprehensive assessment of reasoning LLMs for NLG evaluation and offers insights into their practical use. </p>
<blockquote>
<p>å…·å¤‡æ¨ç†åŠŸèƒ½çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ€è¿‘åœ¨å¤æ‚çš„é€»è¾‘å’Œæ•°å­¦ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œç„¶è€Œå®ƒä»¬åœ¨è¯„ä¼°è‡ªç„¶è¯­è¨€ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ä»æœªè¢«æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†åŸºäºæ¨ç†çš„LLMsï¼ˆDeepSeek-R1å’ŒOpenAI o3ï¼‰ä¸å…¶åœ¨éæ¨ç†ä»»åŠ¡ä¸­çš„å¯¹åº”æ¨¡å‹åœ¨æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰å’Œæ–‡æœ¬æ‘˜è¦ï¼ˆTSï¼‰è¯„ä¼°ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸‰ç§æ¶æ„ç±»åˆ«ä¸­çš„å…«ä¸ªæ¨¡å‹ï¼ŒåŒ…æ‹¬æœ€å…ˆè¿›çš„æ¨ç†æ¨¡å‹ã€å®ƒä»¬çš„è’¸é¦å˜ä½“ï¼ˆå‚æ•°èŒƒå›´ä»8Båˆ°70Bï¼‰ï¼Œä»¥åŠç­‰æ•ˆçš„ä¼ ç»Ÿéæ¨ç†LLMsã€‚æˆ‘ä»¬åœ¨WMT23å’ŒSummEvalåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ¨ç†èƒ½åŠ›çš„ç›Šå¤„é«˜åº¦ä¾èµ–äºæ¨¡å‹å’Œä»»åŠ¡ï¼šè™½ç„¶OpenAI o3-miniæ¨¡å‹æ˜¾ç¤ºå‡ºéšç€æ¨ç†å¼ºåº¦çš„å¢åŠ è€ŒæŒç»­çš„æ€§èƒ½æ”¹è¿›ï¼Œä½†DeepSeek-R1åœ¨å…¶éæ¨ç†å˜ä½“ä¸Šçš„è¡¨ç°è¾ƒå·®ï¼Œä½†åœ¨TSè¯„ä¼°çš„æŸäº›æ–¹é¢é™¤å¤–ã€‚ç›¸å…³æ€§åˆ†æè¡¨æ˜ï¼Œåœ¨o3-miniæ¨¡å‹ä¸­ï¼Œæ¨ç†ä»¤ç‰Œä½¿ç”¨é‡çš„å¢åŠ ä¸è¯„ä¼°è´¨é‡å‘ˆæ­£ç›¸å…³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨ä¸­ç­‰å¤§å°æ¨¡å‹ï¼ˆ32Bï¼‰ä¸­è’¸é¦æ¨ç†èƒ½åŠ›å¯ä»¥ä¿æŒåˆç†çš„æ€§èƒ½ï¼Œä½†åœ¨è¾ƒå°å˜ä½“ï¼ˆ8Bï¼‰ä¸­ä¼šæ˜¾è‘—ä¸‹é™ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡å…¨é¢è¯„ä¼°äº†ç”¨äºNLGè¯„ä»·çš„æ¨ç†LLMsï¼Œå¹¶ä¸ºå…¶å®è·µåº”ç”¨æä¾›äº†è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08120v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºè‡ªç„¶è¯­è¨€ç†è§£å’Œæ¨ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€»è¾‘å’Œæ•°å­¦ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å®ƒä»¬å¯¹äºè‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰çš„è¯„ä»·æ•ˆæœå°šæœªè¢«æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†åŸºäºæ¨ç†çš„LLMsï¼ˆDeepSeek-R1å’ŒOpenAI o3ï¼‰ä¸éæ¨ç†LLMsåœ¨æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰å’Œæ–‡æœ¬æ‘˜è¦ï¼ˆTSï¼‰è¯„ä»·ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨ç†èƒ½åŠ›çš„ä¼˜åŠ¿åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ¨¡å‹å’Œä»»åŠ¡ã€‚OpenAI o3-miniæ¨¡å‹åœ¨å¢å¼ºæ¨ç†å¼ºåº¦åè¡¨ç°ä¸€è‡´åœ°æ›´å¥½ï¼Œè€ŒDeepSeek-R1åœ¨éæ¨ç†å˜ä½“ä¸Šè¡¨ç°è¾ƒå·®ï¼Œä½†åœ¨æ–‡æœ¬æ‘˜è¦è¯„ä»·çš„æŸäº›æ–¹é¢è¡¨ç°è¾ƒå¥½ã€‚æ­¤å¤–ï¼Œæ¨ç†ä»£å¸çš„ä½¿ç”¨ä¸è¯„ä¼°è´¨é‡ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ã€‚åŒæ—¶ï¼Œç ”ç©¶è¿˜å‘ç°ï¼Œåœ¨ä¸­ç­‰è§„æ¨¡æ¨¡å‹ä¸­ä¿æŒæ¨ç†èƒ½åŠ›çš„è’¸é¦è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å°å‹æ¨¡å‹ä¸­æ€§èƒ½ä¼šå¤§å¹…ä¸‹é™ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å…¨é¢è¯„ä¼°äº†ç”¨äºNLGè¯„ä»·çš„æ¨ç†LLMsï¼Œå¹¶ä¸ºå…¶å®è·µåº”ç”¨æä¾›äº†è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€»è¾‘å’Œæ•°å­¦ä»»åŠ¡ä¸Šçš„è¡¨ç°å·²ç»ç›¸å½“å‡ºè‰²ï¼Œä½†åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰è¯„ä»·æ–¹é¢çš„æ•ˆæœå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>å¯¹æ¯”äº†åŸºäºæ¨ç†çš„LLMsï¼ˆå¦‚DeepSeek-R1å’ŒOpenAI o3ï¼‰ä¸éæ¨ç†LLMsåœ¨æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬æ‘˜è¦è¯„ä»·ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</li>
<li>æ¨ç†èƒ½åŠ›çš„ä¼˜åŠ¿åœ¨æ¨¡å‹å’Œä»»åŠ¡ä¸Šå…·æœ‰ä¾èµ–æ€§ã€‚OpenAI o3-miniæ¨¡å‹åœ¨å¢å¼ºæ¨ç†å¼ºåº¦åè¡¨ç°æ›´å¥½ï¼Œè€ŒDeepSeek-R1åœ¨æŸäº›æ–‡æœ¬æ‘˜è¦è¯„ä»·æ–¹é¢è¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨æ€»ä½“ä¸Šä¸å¦‚å…¶éæ¨ç†å˜ä½“ã€‚</li>
<li>æ¨ç†ä»£å¸çš„ä½¿ç”¨ä¸è¯„ä¼°è´¨é‡ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œè¿™æ„å‘³ç€æ›´å¤šçš„æ¨ç†ä»£å¸å¯èƒ½æ„å‘³ç€æ›´é«˜çš„è¯„ä¼°å‡†ç¡®æ€§ã€‚</li>
<li>åœ¨ä¸­ç­‰è§„æ¨¡æ¨¡å‹ä¸­ï¼Œé€šè¿‡è’¸é¦ä¿ç•™æ¨ç†èƒ½åŠ›å¯ä»¥ä¿æŒè‰¯å¥½çš„æ€§èƒ½ã€‚ä½†åœ¨å°å‹æ¨¡å‹ä¸­ï¼Œè¿™ç§æ€§èƒ½ä¼šå¤§å¹…ä¸‹é™ã€‚</li>
<li>æœ¬ç ”ç©¶é¦–æ¬¡å…¨é¢è¯„ä¼°äº†ç”¨äºNLGè¯„ä»·çš„æ¨ç†LLMsï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08120">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-30db7b845bd510c2decc93acf3460f44.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0bf230be48c6469d53ec115e4f6edcf.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Can-Reasoning-LLMs-Enhance-Clinical-Document-Classification"><a href="#Can-Reasoning-LLMs-Enhance-Clinical-Document-Classification" class="headerlink" title="Can Reasoning LLMs Enhance Clinical Document Classification?"></a>Can Reasoning LLMs Enhance Clinical Document Classification?</h2><p><strong>Authors:Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi</strong></p>
<p>Clinical document classification is essential for converting unstructured medical texts into standardised ICD-10 diagnoses, yet it faces challenges due to complex medical language, privacy constraints, and limited annotated datasets. Large Language Models (LLMs) offer promising improvements in accuracy and efficiency for this task. This study evaluates the performance and consistency of eight LLMs; four reasoning (Qwen QWQ, Deepseek Reasoner, GPT o3 Mini, Gemini 2.0 Flash Thinking) and four non-reasoning (Llama 3.3, GPT 4o Mini, Gemini 2.0 Flash, Deepseek Chat); in classifying clinical discharge summaries using the MIMIC-IV dataset. Using cTAKES to structure clinical narratives, models were assessed across three experimental runs, with majority voting determining final predictions. Results showed that reasoning models outperformed non-reasoning models in accuracy (71% vs 68%) and F1 score (67% vs 60%), with Gemini 2.0 Flash Thinking achieving the highest accuracy (75%) and F1 score (76%). However, non-reasoning models demonstrated greater stability (91% vs 84% consistency). Performance varied across ICD-10 codes, with reasoning models excelling in complex cases but struggling with abstract categories. Findings indicate a trade-off between accuracy and consistency, suggesting that a hybrid approach could optimise clinical coding. Future research should explore multi-label classification, domain-specific fine-tuning, and ensemble methods to enhance model reliability in real-world applications. </p>
<blockquote>
<p>ä¸´åºŠæ–‡æ¡£åˆ†ç±»å¯¹äºå°†éç»“æ„åŒ–åŒ»ç–—æ–‡æœ¬è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„ICD-10è¯Šæ–­è‡³å…³é‡è¦ï¼Œä½†ç”±äºå¤æ‚çš„åŒ»ç–—è¯­è¨€ã€éšç§çº¦æŸå’Œæœ‰é™çš„æœ‰æ ‡æ³¨æ•°æ®é›†ï¼Œå®ƒé¢ä¸´ç€æŒ‘æˆ˜ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºè¿™ä¸ªä»»åŠ¡æä¾›äº†æé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡çš„æ½œåŠ›ã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†8ç§LLMçš„æ€§èƒ½å’Œä¸€è‡´æ€§ï¼›å››ä¸ªæ¨ç†æ¨¡å‹ï¼ˆQwen QWQã€Deepseek Reasonerã€GPT o3 Miniã€Gemini 2.0 Flash Thinkingï¼‰å’Œå››ä¸ªéæ¨ç†æ¨¡å‹ï¼ˆLlama 3.3ã€GPT 4o Miniã€Gemini 2.0 Flashã€Deepseek Chatï¼‰ï¼›ä½¿ç”¨MIMIC-IVæ•°æ®é›†å¯¹ä¸´åºŠå‡ºé™¢æ‘˜è¦è¿›è¡Œåˆ†ç±»ã€‚ä½¿ç”¨cTAKESå¯¹ä¸´åºŠå™è¿°è¿›è¡Œç»“æ„åŒ–å¤„ç†ï¼Œå¯¹æ¨¡å‹è¿›è¡Œäº†ä¸‰æ¬¡å®éªŒè¿è¡Œè¯„ä¼°ï¼Œä»¥å¤šæ•°æŠ•ç¥¨å†³å®šæœ€ç»ˆé¢„æµ‹ã€‚ç»“æœè¡¨æ˜ï¼Œæ¨ç†æ¨¡å‹åœ¨å‡†ç¡®æ€§å’ŒF1åˆ†æ•°æ–¹é¢ä¼˜äºéæ¨ç†æ¨¡å‹ï¼ˆå‡†ç¡®ç‡71%æ¯”68%ï¼ŒF1åˆ†æ•°67%æ¯”60%ï¼‰ï¼Œå…¶ä¸­Gemini 2.0 Flash Thinkingçš„å‡†ç¡®ç‡å’ŒF1åˆ†æ•°æœ€é«˜ï¼ˆåˆ†åˆ«ä¸º75%å’Œ76%ï¼‰ã€‚ç„¶è€Œï¼Œéæ¨ç†æ¨¡å‹è¡¨ç°å‡ºæ›´å¤§çš„ç¨³å®šæ€§ï¼ˆä¸€è‡´æ€§91%æ¯”84%ï¼‰ã€‚ä¸åŒICD-10ä»£ç çš„æ€§èƒ½æœ‰æ‰€ä¸åŒï¼Œæ¨ç†æ¨¡å‹åœ¨å¤æ‚æƒ…å†µä¸‹è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æŠ½è±¡ç±»åˆ«ä¸­è¡¨ç°ä¸ä½³ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œéœ€è¦åœ¨å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œæç¤ºé‡‡ç”¨æ··åˆæ–¹æ³•å¯èƒ½æœ€é€‚ç”¨äºä¸´åºŠç¼–ç ã€‚æœªæ¥çš„ç ”ç©¶åº”æ¢ç´¢å¤šæ ‡ç­¾åˆ†ç±»ã€ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒä»¥åŠé›†æˆæ–¹æ³•ï¼Œä»¥æé«˜æ¨¡å‹åœ¨ç°å®åº”ç”¨ä¸­çš„å¯é æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08040v1">PDF</a> 28 pages, 13 tables, 12 figures</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»ç–—æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å°†éç»“æ„åŒ–åŒ»ç–—æ–‡æœ¬è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„ICD-10è¯Šæ–­ä¸­çš„åº”ç”¨ã€‚å®éªŒè¯„ä¼°äº†å…«ç§LLMsçš„æ€§èƒ½å’Œä¸€è‡´æ€§ï¼ŒåŒ…æ‹¬å››ç§æ¨ç†æ¨¡å‹ï¼ˆQwen QWQç­‰ï¼‰å’Œå››ç§éæ¨ç†æ¨¡å‹ï¼ˆLlama 3.3ç­‰ï¼‰ã€‚ä½¿ç”¨MIMIC-IVæ•°æ®é›†å’ŒcTAKESå·¥å…·è¿›è¡Œä¸´åºŠå™è¿°ç»“æ„åŒ–å¤„ç†ï¼Œç»“æœæ˜¾ç¤ºæ¨ç†æ¨¡å‹åœ¨å‡†ç¡®æ€§å’ŒF1å¾—åˆ†ä¸Šä¼˜äºéæ¨ç†æ¨¡å‹ï¼Œä½†éæ¨ç†æ¨¡å‹åœ¨ç¨³å®šæ€§æ–¹é¢è¡¨ç°æ›´å¥½ã€‚æ–‡ç« æ¢è®¨äº†æ¨¡å‹æ€§èƒ½ä¸ICD-10ä»£ç ä¹‹é—´çš„å˜åŒ–ï¼Œå¹¶æå‡ºäº†é‡‡ç”¨æ··åˆæ–¹æ³•çš„ä¼˜åŒ–æ–¹å‘ã€‚æœªæ¥ç ”ç©¶åº”å…³æ³¨å¤šæ ‡ç­¾åˆ†ç±»ã€ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒä»¥åŠé›†æˆæ–¹æ³•ä»¥æé«˜æ¨¡å‹åœ¨ç°å®åº”ç”¨ä¸­çš„å¯é æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸´åºŠæ–‡æ¡£åˆ†ç±»æ˜¯å°†éç»“æ„åŒ–åŒ»ç–—æ–‡æœ¬è½¬æ¢ä¸ºICD-10è¯Šæ–­çš„å…³é”®è¿‡ç¨‹ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯ä»¥æé«˜ä¸´åºŠæ–‡æ¡£åˆ†ç±»çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>æ¨ç†æ¨¡å‹åœ¨åˆ†ç±»å‡†ç¡®æ€§ä¸Šä¼˜äºéæ¨ç†æ¨¡å‹ï¼Œä½†éæ¨ç†æ¨¡å‹åœ¨ç¨³å®šæ€§æ–¹é¢è¡¨ç°æ›´å¥½ã€‚</li>
<li>Gemini 2.0 Flash Thinkingæ¨¡å‹åœ¨å‡†ç¡®ç‡å’ŒF1å¾—åˆ†ä¸Šè¡¨ç°æœ€ä½³ã€‚</li>
<li>ä¸åŒICD-10ä»£ç ä¸‹çš„æ¨¡å‹æ€§èƒ½æœ‰æ‰€å·®å¼‚ï¼Œæ¨ç†æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ¡ˆä¾‹æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æŠ½è±¡ç±»åˆ«ä¸Šé‡åˆ°å›°éš¾ã€‚</li>
<li>å­˜åœ¨å‡†ç¡®æ€§ä¸ä¸€è‡´æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œæå‡ºé‡‡ç”¨æ··åˆæ–¹æ³•æ¥ä¼˜åŒ–ä¸´åºŠç¼–ç ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-27ad85b10aa140d1cafa5b60eaab8169.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Holistic-Capability-Preservation-Towards-Compact-Yet-Comprehensive-Reasoning-Models"><a href="#Holistic-Capability-Preservation-Towards-Compact-Yet-Comprehensive-Reasoning-Models" class="headerlink" title="Holistic Capability Preservation: Towards Compact Yet Comprehensive   Reasoning Models"></a>Holistic Capability Preservation: Towards Compact Yet Comprehensive   Reasoning Models</h2><p><strong>Authors: Ling Team, Caizhi Tang, Chilin Fu, Chunwei Wu, Jia Guo, Jianwen Wang, Jingyu Hu, Liang Jiang, Meng Li, Peng Jiao, Pingping Liu, Shaomian Zheng, Shiwei Liang, Shuaicheng Li, Yalin Zhang, Yingting Wu, Yongkang Liu, Zhenyu Huang</strong></p>
<p>This technical report presents Ring-Lite-Distill, a lightweight reasoning model derived from our open-source Mixture-of-Experts (MoE) Large Language Models (LLMs) Ling-Lite. This study demonstrates that through meticulous high-quality data curation and ingenious training paradigms, the compact MoE model Ling-Lite can be further trained to achieve exceptional reasoning capabilities, while maintaining its parameter-efficient architecture with only 2.75 billion activated parameters, establishing an efficient lightweight reasoning architecture. In particular, in constructing this model, we have not merely focused on enhancing advanced reasoning capabilities, exemplified by high-difficulty mathematical problem solving, but rather aimed to develop a reasoning model with more comprehensive competency coverage. Our approach ensures coverage across reasoning tasks of varying difficulty levels while preserving generic capabilities, such as instruction following, tool use, and knowledge retention. We show that, Ring-Lite-Distillâ€™s reasoning ability reaches a level comparable to DeepSeek-R1-Distill-Qwen-7B, while its general capabilities significantly surpass those of DeepSeek-R1-Distill-Qwen-7B. The models are accessible at <a target="_blank" rel="noopener" href="https://huggingface.co/inclusionAI">https://huggingface.co/inclusionAI</a> </p>
<blockquote>
<p>æœ¬æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†Ring-Lite-Distillï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ¨ç†æ¨¡å‹ï¼Œæºäºæˆ‘ä»¬å¼€æºçš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰Ling-Liteã€‚è¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ç²¾å¿ƒçš„é«˜è´¨é‡æ•°æ®æ”¶é›†å’Œå·§å¦™çš„è®­ç»ƒæ¨¡å¼ï¼Œç´§å‡‘çš„MoEæ¨¡å‹Ling-Liteå¯ä»¥è¿›ä¸€æ­¥è®­ç»ƒï¼Œå®ç°å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå…¶å‚æ•°é«˜æ•ˆçš„æ¶æ„ï¼Œä»…æœ‰2.75äº¿ä¸ªæ¿€æ´»å‚æ•°ï¼Œå»ºç«‹äº†æœ‰æ•ˆçš„è½»é‡åŒ–æ¨ç†æ¶æ„ã€‚åœ¨æ„å»ºæ­¤æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä¸ä»…ä»…ä¸“æ³¨äºæé«˜è§£å†³é«˜éš¾åº¦æ•°å­¦é—®é¢˜çš„å…ˆè¿›æ¨ç†èƒ½åŠ›ï¼Œè€Œæ˜¯è‡´åŠ›äºå¼€å‘å…·æœ‰æ›´å…¨é¢èƒ½åŠ›è¦†ç›–èŒƒå›´çš„æ¨ç†æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç¡®ä¿äº†ä¸åŒéš¾åº¦çº§åˆ«çš„æ¨ç†ä»»åŠ¡çš„è¦†ç›–ï¼ŒåŒæ—¶ä¿ç•™äº†ä¸€èˆ¬èƒ½åŠ›ï¼Œä¾‹å¦‚æŒ‡ä»¤éµå¾ªã€å·¥å…·ä½¿ç”¨å’ŒçŸ¥è¯†ä¿ç•™ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒRing-Lite-Distillçš„æ¨ç†èƒ½åŠ›ä¸DeepSeek-R1-Distill-Qwen-7Bç›¸å½“ï¼Œè€Œå…¶ä¸€èˆ¬èƒ½åŠ›åˆ™æ˜¾è‘—è¶…è¿‡äº†DeepSeek-R1-Distill-Qwen-7Bã€‚æ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/inclusionAI">https://huggingface.co/inclusionAI</a>è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.07158v2">PDF</a> Based on the further discussion of the working group, the current   version is deemed unsuitable for release. We are currently undertaking   further work that is expected to involve significant revisions, but this   process will require some additional time. We plan to proceed with the   release once these updates have been fully implemented</p>
<p><strong>Summary</strong></p>
<p>Ring-Lite-Distillæ¨¡å‹æ˜¯Mixture-of-Expertsï¼ˆMoEï¼‰çš„ä¸€ç§è½»é‡çº§æ¨ç†æ¨¡å‹ï¼ŒåŸºäºå¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹Ling-Liteã€‚è¯¥æ¨¡å‹é€šè¿‡é«˜è´¨é‡æ•°æ®æ•´åˆå’Œåˆ›æ–°è®­ç»ƒæ¨¡å¼ï¼Œå®ç°äº†é«˜æ•ˆçš„å‚æ•°åˆ©ç”¨ï¼Œæ‹¥æœ‰å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶ä»…åŒ…å«2.75äº¿æ¿€æ´»å‚æ•°ã€‚è¯¥æ¨¡å‹ä¸ä»…å…³æ³¨é«˜éš¾åº¦æ•°å­¦é—®é¢˜çš„æ¨ç†èƒ½åŠ›ï¼Œè¿˜è‡´åŠ›äºå‘å±•å…·æœ‰å…¨é¢èƒ½åŠ›çš„æ¨ç†æ¨¡å‹ï¼Œç¡®ä¿è¦†ç›–ä¸åŒéš¾åº¦çš„æ¨ç†ä»»åŠ¡ï¼Œå¹¶ä¿ç•™é€šç”¨èƒ½åŠ›ï¼Œå¦‚æŒ‡ä»¤éµå¾ªã€å·¥å…·ä½¿ç”¨å’ŒçŸ¥è¯†ä¿ç•™ã€‚å…¶æ¨ç†èƒ½åŠ›ä¸DeepSeek-R1-Distill-Qwen-7Bç›¸å½“ï¼Œä½†ä¸€èˆ¬èƒ½åŠ›æ˜¾è‘—è¶…è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Ring-Lite-Distillæ˜¯ä¸€ä¸ªåŸºäºMixture-of-Expertsçš„è½»é‡çº§æ¨ç†æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹ç”±å¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹Ling-Liteè¡ç”Ÿè€Œæ¥ã€‚</li>
<li>é€šè¿‡é«˜è´¨é‡æ•°æ®æ•´åˆå’Œåˆ›æ–°è®­ç»ƒæ¨¡å¼ï¼ŒLing-Liteè¿›ä¸€æ­¥è®­ç»ƒåå±•ç°å‡ºå“è¶Šçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¨¡å‹ä»…åŒ…å«2.75äº¿æ¿€æ´»å‚æ•°ï¼Œå®ç°äº†é«˜æ•ˆçš„å‚æ•°åˆ©ç”¨ã€‚</li>
<li>Ring-Lite-Distillä¸ä»…å…³æ³¨é«˜éš¾åº¦æ•°å­¦é—®é¢˜çš„æ¨ç†ï¼Œè¿˜å…·å¤‡å…¨é¢çš„èƒ½åŠ›è¦†ç›–ã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½å¤Ÿåº”å¯¹ä¸åŒéš¾åº¦çš„æ¨ç†ä»»åŠ¡ï¼ŒåŒæ—¶ä¿ç•™é€šç”¨èƒ½åŠ›ï¼Œå¦‚æŒ‡ä»¤éµå¾ªã€å·¥å…·ä½¿ç”¨å’ŒçŸ¥è¯†ä¿ç•™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.07158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7d54d371caf577f988b38227b5c15d41.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df81c4c0da0f66bbf4c6217e0376fab3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d1788c5eaee4f28b7d5fbe8c389e635.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6eefcbf9684755ca8ef8e2d00a1161b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50695317975e22051bfa8203d963dc0a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="VAPO-Efficient-and-Reliable-Reinforcement-Learning-for-Advanced-Reasoning-Tasks"><a href="#VAPO-Efficient-and-Reliable-Reinforcement-Learning-for-Advanced-Reasoning-Tasks" class="headerlink" title="VAPO: Efficient and Reliable Reinforcement Learning for Advanced   Reasoning Tasks"></a>VAPO: Efficient and Reliable Reinforcement Learning for Advanced   Reasoning Tasks</h2><p><strong>Authors:Yu Yue, Yufeng Yuan, Qiying Yu, Xiaochen Zuo, Ruofei Zhu, Wenyuan Xu, Jiaze Chen, Chengyi Wang, TianTian Fan, Zhengyin Du, Xiangpeng Wei, Xiangyu Yu, Gaohong Liu, Juncai Liu, Lingjun Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Ru Zhang, Xin Liu, Mingxuan Wang, Yonghui Wu, Lin Yan</strong></p>
<p>We present VAPO, Value-based Augmented Proximal Policy Optimization framework for reasoning models., a novel framework tailored for reasoning models within the value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the Qwen 32B pre-trained model, attains a state-of-the-art score of $\mathbf{60.4}$. In direct comparison under identical experimental settings, VAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B and DAPO by more than 10 points. The training process of VAPO stands out for its stability and efficiency. It reaches state-of-the-art performance within a mere 5,000 steps. Moreover, across multiple independent runs, no training crashes occur, underscoring its reliability. This research delves into long chain-of-thought (long-CoT) reasoning using a value-based reinforcement learning framework. We pinpoint three key challenges that plague value-based methods: value model bias, the presence of heterogeneous sequence lengths, and the sparsity of reward signals. Through systematic design, VAPO offers an integrated solution that effectively alleviates these challenges, enabling enhanced performance in long-CoT reasoning tasks. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†VAPOï¼ŒåŸºäºä»·å€¼çš„å¢å¼ºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼ˆé€‚ç”¨äºæ¨ç†æ¨¡å‹ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹åŸºäºä»·å€¼çš„èŒƒå¼ä¸­çš„æ¨ç†æ¨¡å‹çš„æ–°å‹æ¡†æ¶ã€‚ä½¿ç”¨AIME 2024æ•°æ®é›†è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼ŒVAPOå»ºç«‹åœ¨Qwen 32Bé¢„è®­ç»ƒæ¨¡å‹ä¸Šï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„60.4åˆ†ã€‚åœ¨ç›¸åŒçš„å®éªŒè®¾ç½®ä¸‹ç›´æ¥æ¯”è¾ƒï¼ŒVAPOçš„è¡¨ç°ä¼˜äºå…ˆå‰æŠ¥é“çš„DeepSeek-R1-Zero-Qwen-32Bå’ŒDAPOçš„ç»“æœè¶…è¿‡10åˆ†ã€‚VAPOçš„è®­ç»ƒè¿‡ç¨‹ä»¥ç¨³å®šæ€§å’Œé«˜æ•ˆæ€§è€Œè„±é¢–è€Œå‡ºã€‚å®ƒåœ¨çŸ­çŸ­5000æ­¥å†…è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨å¤šæ¬¡ç‹¬ç«‹è¿è¡Œä¸­ï¼Œæ²¡æœ‰å‘ç”Ÿè®­ç»ƒå´©æºƒï¼Œè¯æ˜äº†å…¶å¯é æ€§ã€‚æœ¬ç ”ç©¶æ·±å…¥æ¢è®¨äº†åŸºäºä»·å€¼å¼ºåŒ–å­¦ä¹ æ¡†æ¶çš„é•¿é“¾æ€ç»´ï¼ˆlong-CoTï¼‰æ¨ç†ã€‚æˆ‘ä»¬ç¡®å®šäº†å›°æ‰°åŸºäºä»·å€¼æ–¹æ³•çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä»·å€¼æ¨¡å‹åè§ã€å­˜åœ¨ä¸åŒçš„åºåˆ—é•¿åº¦ä»¥åŠå¥–åŠ±ä¿¡å·çš„ç¨€ç–æ€§ã€‚é€šè¿‡ç³»ç»Ÿè®¾è®¡ï¼ŒVAPOæä¾›äº†ä¸€ä¸ªç»¼åˆè§£å†³æ–¹æ¡ˆï¼Œæœ‰æ•ˆåœ°ç¼“è§£äº†è¿™äº›æŒ‘æˆ˜ï¼Œèƒ½å¤Ÿåœ¨é•¿é“¾æ€ç»´æ¨ç†ä»»åŠ¡ä¸­æé«˜æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05118v3">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æˆ‘ä»¬æå‡ºäº†é’ˆå¯¹æ¨ç†æ¨¡å‹çš„ä»·å€¼åŸºç¡€å¢å¼ºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–æ¡†æ¶VAPOï¼Œè¯¥æ¡†æ¶åœ¨ä»·å€¼åŸºç¡€ä¸Šä¸ºæ¨ç†æ¨¡å‹å®šåˆ¶ã€‚åœ¨AIME 2024æ•°æ®é›†ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒVAPOå»ºç«‹åœ¨Qwen 32Bé¢„è®­ç»ƒæ¨¡å‹ä¸Šï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„60.4åˆ†ã€‚åœ¨ç›¸åŒçš„å®éªŒè®¾ç½®ä¸‹ï¼ŒVAPOçš„è¡¨ç°ä¼˜äºDeepSeek-R1-Zero-Qwen-32Bå’ŒDAPOè¶…è¿‡10åˆ†ã€‚VAPOçš„è®­ç»ƒè¿‡ç¨‹ä»¥ç¨³å®šæ€§å’Œé«˜æ•ˆæ€§è‘—ç§°ï¼Œå®ƒåœ¨çŸ­çŸ­5000æ­¥å†…è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨å¤šæ¬¡ç‹¬ç«‹è¿è¡Œä¸­ï¼Œæ²¡æœ‰å‡ºç°è®­ç»ƒå´©æºƒï¼Œè¯æ˜äº†å…¶å¯é æ€§ã€‚æœ¬ç ”ç©¶æ·±å…¥æ¢è®¨äº†ä»·å€¼å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸­çš„é•¿é“¾æ€ç»´ï¼ˆlong-CoTï¼‰æ¨ç†ï¼Œå¹¶æŒ‡å‡ºäº†ä»·å€¼åŸºç¡€æ–¹æ³•ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä»·å€¼æ¨¡å‹åè§ã€ä¸åŒåºåˆ—é•¿åº¦çš„å­˜åœ¨å’Œå¥–åŠ±ä¿¡å·çš„ç¨€ç–æ€§ã€‚é€šè¿‡ç³»ç»Ÿè®¾è®¡ï¼ŒVAPOæä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„ç»¼åˆè§£å†³æ–¹æ¡ˆæ¥ç¼“è§£è¿™äº›æŒ‘æˆ˜ï¼Œä»è€Œåœ¨é•¿é“¾æ€ç»´æ¨ç†ä»»åŠ¡ä¸­å®ç°äº†å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>VAPOæ˜¯åŸºäºä»·å€¼åŸºç¡€çš„å¢å¼ºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼Œä¸“ä¸ºæ¨ç†æ¨¡å‹è®¾è®¡ã€‚</li>
<li>åœ¨AIME 2024æ•°æ®é›†ä¸Šï¼ŒVAPOè¾¾åˆ°æœ€å…ˆè¿›çš„60.4åˆ†ã€‚</li>
<li>VAPOåœ¨ç›¸åŒå®éªŒè®¾ç½®ä¸‹è¡¨ç°å‡ºè‰²ï¼Œä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>VAPOè®­ç»ƒè¿‡ç¨‹ç¨³å®šé«˜æ•ˆï¼Œå¯åœ¨5000æ­¥å†…è¾¾åˆ°å…ˆè¿›æ€§èƒ½ã€‚</li>
<li>åœ¨å¤šæ¬¡ç‹¬ç«‹è¿è¡Œä¸­ï¼ŒVAPOè¡¨ç°å‡ºæé«˜çš„å¯é æ€§ã€‚</li>
<li>ç ”ç©¶æŒ‡å‡ºäº†ä»·å€¼åŸºç¡€æ–¹æ³•ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä»·å€¼æ¨¡å‹åè§ã€ä¸åŒåºåˆ—é•¿åº¦çš„å­˜åœ¨å’Œå¥–åŠ±ä¿¡å·çš„ç¨€ç–æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05118">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0f3e83983b75dfb8a11dd597d9a879b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="OmniScience-A-Domain-Specialized-LLM-for-Scientific-Reasoning-and-Discovery"><a href="#OmniScience-A-Domain-Specialized-LLM-for-Scientific-Reasoning-and-Discovery" class="headerlink" title="OmniScience: A Domain-Specialized LLM for Scientific Reasoning and   Discovery"></a>OmniScience: A Domain-Specialized LLM for Scientific Reasoning and   Discovery</h2><p><strong>Authors:Vignesh Prabhakar, Md Amirul Islam, Adam Atanas, Yao-Ting Wang, Joah Han, Aastha Jhunjhunwala, Rucha Apte, Robert Clark, Kang Xu, Zihan Wang, Kai Liu</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable potential in advancing scientific knowledge and addressing complex challenges. In this work, we introduce OmniScience, a specialized large reasoning model for general science, developed through three key components: (1) domain adaptive pretraining on a carefully curated corpus of scientific literature, (2) instruction tuning on a specialized dataset to guide the model in following domain-specific tasks, and (3) reasoning-based knowledge distillation through fine-tuning to significantly enhance its ability to generate contextually relevant and logically sound responses. We demonstrate the versatility of OmniScience by developing a battery agent that efficiently ranks molecules as potential electrolyte solvents or additives. Comprehensive evaluations reveal that OmniScience is competitive with state-of-the-art large reasoning models on the GPQA Diamond and domain-specific battery benchmarks, while outperforming all public reasoning and non-reasoning models with similar parameter counts. We further demonstrate via ablation experiments that domain adaptive pretraining and reasoning-based knowledge distillation are critical to attain our performance levels, across benchmarks. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨è¿›ç§‘å­¦çŸ¥è¯†å’Œåº”å¯¹å¤æ‚æŒ‘æˆ˜æ–¹é¢å±•ç°å‡ºäº†æ˜¾è‘—æ½œåŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†OmniScienceï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹é€šç”¨ç§‘å­¦çš„ä¸“ä¸šåŒ–å¤§å‹æ¨ç†æ¨¡å‹ï¼Œé€šè¿‡ä¸‰ä¸ªå…³é”®ç»„ä»¶å¼€å‘è€Œæˆï¼šï¼ˆ1ï¼‰åœ¨ç²¾å¿ƒç­›é€‰çš„ç§‘å­¦æ–‡çŒ®è¯­æ–™åº“ä¸Šè¿›è¡Œé¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒï¼›ï¼ˆ2ï¼‰åœ¨ä¸“é—¨çš„æ•°æ®é›†ä¸Šè¿›è¡ŒæŒ‡ä»¤è°ƒæ•´ï¼Œä»¥æŒ‡å¯¼æ¨¡å‹æ‰§è¡Œç‰¹å®šé¢†åŸŸçš„ä»»åŠ¡ï¼›ï¼ˆ3ï¼‰é€šè¿‡å¾®è°ƒè¿›è¡ŒåŸºäºæ¨ç†çš„çŸ¥è¯†è’¸é¦ï¼Œä»¥æ˜¾è‘—æé«˜å…¶ç”Ÿæˆè¯­å¢ƒç›¸å…³å’Œé€»è¾‘ä¸¥è°¨å›åº”çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡å¼€å‘ä¸€ç§ç”µæ± ä»£ç†æ¥å±•ç¤ºOmniScienceçš„é€šç”¨æ€§ï¼Œè¯¥ä»£ç†èƒ½å¤Ÿé«˜æ•ˆåœ°å¯¹åˆ†å­è¿›è¡Œæ’åï¼Œä½œä¸ºæ½œåœ¨çš„ç”µè§£è´¨æº¶å‰‚æˆ–æ·»åŠ å‰‚ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒOmniScienceåœ¨GPQA Diamondå’Œç‰¹å®šé¢†åŸŸçš„ç”µæ± åŸºå‡†æµ‹è¯•ä¸Šä¸æœ€å…ˆè¿›çš„å¤§å‹æ¨ç†æ¨¡å‹ç›¸ç«äº‰ï¼ŒåŒæ—¶åœ¨å‚æ•°æ•°é‡ç›¸ä¼¼çš„æ‰€æœ‰å…¬å…±æ¨ç†å’Œéæ¨ç†æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ã€‚æˆ‘ä»¬è¿˜é€šè¿‡æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œé¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒå’ŒåŸºäºæ¨ç†çš„çŸ¥è¯†è’¸é¦å¯¹äºå®ç°æˆ‘ä»¬çš„æ€§èƒ½æ°´å¹³è‡³å…³é‡è¦ï¼Œè·¨è¶Šå„ç§åŸºå‡†æµ‹è¯•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17604v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨åŠ¨ç§‘å­¦çŸ¥è¯†å’Œåº”å¯¹å¤æ‚æŒ‘æˆ˜æ–¹é¢å±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€æ¬¾é’ˆå¯¹é€šç”¨ç§‘å­¦çš„ç‰¹æ®Šå¤§å‹æ¨ç†æ¨¡å‹OmniScienceï¼Œå…¶å¼€å‘åŒ…æ‹¬ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ï¼šå¯¹ç§‘å­¦æ–‡çŒ®ç²¾å¿ƒç­›é€‰çš„è¯­æ–™åº“è¿›è¡Œé¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒã€åœ¨ä¸“é—¨æ•°æ®é›†ä¸Šè¿›è¡ŒæŒ‡ä»¤è°ƒæ•´ä»¥æŒ‡å¯¼æ¨¡å‹æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œä»¥åŠé€šè¿‡å¾®è°ƒè¿›è¡ŒåŸºäºæ¨ç†çš„çŸ¥è¯†è’¸é¦ï¼Œä»¥æ˜¾è‘—æé«˜å…¶ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³å’Œé€»è¾‘ä¸¥è°¨å“åº”çš„èƒ½åŠ›ã€‚OmniScienceçš„é€šç”¨æ€§é€šè¿‡å¼€å‘ç”µæ± ä»£ç†å¾—ä»¥å±•ç¤ºï¼Œè¯¥ä»£ç†èƒ½å¤Ÿé«˜æ•ˆåœ°æ’åˆ—åˆ†å­ä½œä¸ºæ½œåœ¨çš„ç”µè§£è´¨æº¶å‰‚æˆ–æ·»åŠ å‰‚ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒOmniScienceåœ¨GPQA Diamondå’Œç‰¹å®šç”µæ± åŸºå‡†æµ‹è¯•ä¸Šä¸æœ€æ–°å¤§å‹æ¨ç†æ¨¡å‹ç«äº‰ï¼ŒåŒæ—¶åœ¨å‚æ•°æ•°é‡ç›¸ä¼¼çš„å…¬å…±æ¨ç†å’Œéæ¨ç†æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ã€‚é€šè¿‡æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œé¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒå’ŒåŸºäºæ¨ç†çš„çŸ¥è¯†è’¸é¦å¯¹äºè¾¾åˆ°æˆ‘ä»¬çš„æ€§èƒ½æ°´å¹³è‡³å…³é‡è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨è¿›ç§‘å­¦å’Œåº”å¯¹å¤æ‚æŒ‘æˆ˜ä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚</li>
<li>OmniScienceæ˜¯ä¸€ä¸ªé’ˆå¯¹é€šç”¨ç§‘å­¦çš„ç‰¹æ®Šå¤§å‹æ¨ç†æ¨¡å‹ã€‚</li>
<li>OmniScienceçš„å¼€å‘åŒ…æ‹¬é¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒã€æŒ‡ä»¤è°ƒæ•´ä»¥åŠåŸºäºæ¨ç†çš„çŸ¥è¯†è’¸é¦ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ã€‚</li>
<li>OmniScienceå±•ç¤ºäº†åœ¨ç”µæ± ä»£ç†å¼€å‘ä¸­çš„é€šç”¨æ€§ï¼Œèƒ½é«˜æ•ˆæ’åˆ—åˆ†å­ä½œä¸ºæ½œåœ¨ç”µè§£è´¨æº¶å‰‚æˆ–æ·»åŠ å‰‚ã€‚</li>
<li>ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒOmniScienceåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>æ¶ˆèå®éªŒè¯æ˜é¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒå’ŒåŸºäºæ¨ç†çš„çŸ¥è¯†è’¸é¦å¯¹OmniScienceçš„æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>OmniScienceçš„å¼€å‘å’Œè¯„ä¼°ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17604">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5d6944cf303fea9494c3ca74eadb42e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cddc57a4b1e46185ec103df103a43ee.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="An-Empirical-Study-of-Conformal-Prediction-in-LLM-with-ASP-Scaffolds-for-Robust-Reasoning"><a href="#An-Empirical-Study-of-Conformal-Prediction-in-LLM-with-ASP-Scaffolds-for-Robust-Reasoning" class="headerlink" title="An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for   Robust Reasoning"></a>An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for   Robust Reasoning</h2><p><strong>Authors:Navdeep Kaur, Lachlan McPheat, Alessandra Russo, Anthony G Cohn, Pranava Madhyastha</strong></p>
<p>In this paper, we examine the use of Conformal Language Modelling (CLM) alongside Answer Set Programming (ASP) to enhance the performance of standard open-weight LLMs on complex multi-step reasoning tasks. Using the StepGame dataset, which requires spatial reasoning, we apply CLM to generate sets of ASP programs from an LLM, providing statistical guarantees on the correctness of the outputs. Experimental results show that CLM significantly outperforms baseline models that use standard sampling methods, achieving substantial accuracy improvements across different levels of reasoning complexity. Additionally, the LLM-as-Judge metric enhances CLMâ€™s performance, especially in assessing structurally and logically correct ASP outputs. However, calibrating CLM with diverse calibration sets did not improve generalizability for tasks requiring much longer reasoning steps, indicating limitations in handling more complex tasks. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å°†ç¬¦åˆè¯­è¨€å»ºæ¨¡ï¼ˆCLMï¼‰ä¸ç­”æ¡ˆé›†ç¼–ç¨‹ï¼ˆASPï¼‰ç»“åˆä½¿ç”¨ï¼Œä»¥æé«˜æ ‡å‡†å¼€æ”¾æƒé‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬åˆ©ç”¨éœ€è¦ç©ºé—´æ¨ç†çš„StepGameæ•°æ®é›†ï¼Œå°†CLMåº”ç”¨äºä»å¤§å‹è¯­è¨€æ¨¡å‹ç”ŸæˆASPç¨‹åºé›†ï¼Œä¸ºè¾“å‡ºç»“æœçš„æ­£ç¡®æ€§æä¾›ç»Ÿè®¡ä¿è¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„é‡‡æ ·æ–¹æ³•ç›¸æ¯”ï¼ŒCLMæ˜¾è‘—æé«˜äº†åŸºçº¿æ¨¡å‹çš„æ€§èƒ½ï¼Œåœ¨ä¸åŒå±‚æ¬¡çš„æ¨ç†å¤æ‚åº¦ä¸Šéƒ½å®ç°äº†å®è´¨æ€§çš„å‡†ç¡®æ€§æé«˜ã€‚æ­¤å¤–ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„åˆ¤è€…çš„æŒ‡æ ‡æé«˜äº†CLMçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯„ä¼°ç»“æ„ä¸Šå’Œé€»è¾‘ä¸Šæ­£ç¡®çš„ASPè¾“å‡ºæ–¹é¢ã€‚ç„¶è€Œï¼Œä½¿ç”¨å¤šç§æ ¡å‡†é›†å¯¹CLMè¿›è¡Œæ ¡å‡†å¹¶æ²¡æœ‰æé«˜å¤„ç†éœ€è¦æ›´å¤šæ¨ç†æ­¥éª¤çš„ä»»åŠ¡çš„é€šç”¨æ€§ï¼Œè¿™è¡¨æ˜åœ¨å¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡æ—¶å­˜åœ¨å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.05439v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å°†Conformalè¯­è¨€å»ºæ¨¡ï¼ˆCLMï¼‰ä¸Answer Set Programmingï¼ˆASPï¼‰ç»“åˆä½¿ç”¨ï¼Œä»¥æ”¹å–„æ ‡å‡†å¼€æ”¾å¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æ–‡ç« ä½¿ç”¨StepGameæ•°æ®é›†æ¥è¦æ±‚ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡CLMç”ŸæˆASPç¨‹åºçš„é›†åˆï¼Œå¯¹è¾“å‡ºçš„æ­£ç¡®æ€§æä¾›ç»Ÿè®¡ä¿è¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCLMæ˜¾è‘—ä¼˜äºä½¿ç”¨æ ‡å‡†é‡‡æ ·æ–¹æ³•çš„åŸºçº¿æ¨¡å‹ï¼Œåœ¨ä¸åŒå±‚æ¬¡çš„æ¨ç†å¤æ‚åº¦ä¸Šå®ç°äº†å®è´¨æ€§çš„å‡†ç¡®æ€§æé«˜ã€‚ç„¶è€Œï¼Œå¯¹äºéœ€è¦æ›´é•¿æ—¶é—´æ¨ç†æ­¥éª¤çš„ä»»åŠ¡ï¼Œä½¿ç”¨å¤šç§æ ¡å‡†é›†æ ¡å‡†CLMå¹¶æ²¡æœ‰æé«˜é€šç”¨æ€§ï¼Œè¿™è¡¨æ˜å…¶åœ¨å¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Conformalè¯­è¨€å»ºæ¨¡ï¼ˆCLMï¼‰ä¸Answer Set Programmingï¼ˆASPï¼‰ç»“åˆä½¿ç”¨ï¼Œå¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>ä½¿ç”¨StepGameæ•°æ®é›†æ¥æµ‹è¯•æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚</li>
<li>CLMå¯ä»¥ç”ŸæˆASPç¨‹åºçš„é›†åˆï¼Œå¹¶ä¸ºè¾“å‡ºçš„æ­£ç¡®æ€§æä¾›ç»Ÿè®¡ä¿è¯ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒCLMç›¸è¾ƒäºåŸºçº¿æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šæœ‰æ˜¾è‘—æé«˜ã€‚</li>
<li>LLM-as-JudgeæŒ‡æ ‡æé«˜äº†CLMåœ¨è¯„ä¼°ASPè¾“å‡ºç»“æ„å’Œé€»è¾‘æ­£ç¡®æ€§æ–¹é¢çš„æ€§èƒ½ã€‚</li>
<li>ä½¿ç”¨å¤šç§æ ¡å‡†é›†å¯¹CLMè¿›è¡Œæ ¡å‡†å¹¶æœªåœ¨æé«˜éœ€è¦æ›´é•¿æ—¶é—´æ¨ç†æ­¥éª¤çš„ä»»åŠ¡çš„é€šç”¨æ€§æ–¹é¢æ˜¾ç¤ºå‡ºæ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.05439">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f87f0f4665100c6d9270c099f5c50cf.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="EmbodiedEval-Evaluate-Multimodal-LLMs-as-Embodied-Agents"><a href="#EmbodiedEval-Evaluate-Multimodal-LLMs-as-Embodied-Agents" class="headerlink" title="EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents"></a>EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents</h2><p><strong>Authors:Zhili Cheng, Yuge Tu, Ran Li, Shiqi Dai, Jinyi Hu, Shengding Hu, Jiahao Li, Yang Shi, Tianyu Yu, Weize Chen, Lei Shi, Maosong Sun</strong></p>
<p>Multimodal Large Language Models (MLLMs) have shown significant advancements, providing a promising future for embodied agents. Existing benchmarks for evaluating MLLMs primarily utilize static images or videos, limiting assessments to non-interactive scenarios. Meanwhile, existing embodied AI benchmarks are task-specific and not diverse enough, which do not adequately evaluate the embodied capabilities of MLLMs. To address this, we propose EmbodiedEval, a comprehensive and interactive evaluation benchmark for MLLMs with embodied tasks. EmbodiedEval features 328 distinct tasks within 125 varied 3D scenes, each of which is rigorously selected and annotated. It covers a broad spectrum of existing embodied AI tasks with significantly enhanced diversity, all within a unified simulation and evaluation framework tailored for MLLMs. The tasks are organized into five categories: navigation, object interaction, social interaction, attribute question answering, and spatial question answering to assess different capabilities of the agents. We evaluated the state-of-the-art MLLMs on EmbodiedEval and found that they have a significant shortfall compared to human level on embodied tasks. Our analysis demonstrates the limitations of existing MLLMs in embodied capabilities, providing insights for their future development. We open-source all evaluation data and simulation framework at <a target="_blank" rel="noopener" href="https://github.com/thunlp/EmbodiedEval">https://github.com/thunlp/EmbodiedEval</a>. </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸ºå®ä½“æ™ºèƒ½ä½“æä¾›äº†ç¾å¥½çš„æœªæ¥å‰æ™¯ã€‚ç°æœ‰çš„è¯„ä¼°MLLMçš„åŸºå‡†æµ‹è¯•ä¸»è¦ä½¿ç”¨é™æ€å›¾åƒæˆ–è§†é¢‘ï¼Œä»…é™äºéäº¤äº’å¼åœºæ™¯ã€‚åŒæ—¶ï¼Œç°æœ‰çš„å®ä½“äººå·¥æ™ºèƒ½åŸºå‡†æµ‹è¯•æ˜¯ç‰¹å®šä»»åŠ¡çš„ï¼Œå¹¶ä¸å¤Ÿå¤šæ ·åŒ–ï¼Œä¸èƒ½å……åˆ†è¯„ä¼°MLLMsçš„å®ä½“èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†EmbodiedEvalï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢ä¸”äº¤äº’å¼çš„è¯„ä¼°åŸºå‡†æµ‹è¯•ï¼Œé€‚ç”¨äºå…·æœ‰å®ä½“ä»»åŠ¡çš„MLLMsã€‚EmbodiedEvalåœ¨ç»Ÿä¸€çš„æ¨¡æ‹Ÿæ¡†æ¶å†…æ‹¥æœ‰ç‰¹å®šçš„æ ‡å‡†ç¨‹åºåŒ…æ‹¬é€šè¿‡ç²¾å‡†çš„æŒ‘é€‰å’Œæ³¨é‡Šè®¾è®¡æˆçš„å…±æ¶µç›–å¯¼è§ˆã€å¯¹è±¡äº’åŠ¨ã€ç¤¾äº¤äº’åŠ¨ç­‰åäºŒä¸ªä¸»é¢˜çš„å…·æœ‰3Dç¯å¢ƒçš„ä»»åŠ¡çš„è®¾å®š328é¡¹ä¸åŒä»»åŠ¡ã€‚è¯¥æ¡†æ¶æ¶µç›–äº†å¹¿æ³›çš„ç°æœ‰å®ä½“äººå·¥æ™ºèƒ½ä»»åŠ¡ï¼Œå…·æœ‰æ˜¾è‘—å¢å¼ºçš„å¤šæ ·æ€§ã€‚ä»»åŠ¡åˆ†ä¸ºäº”å¤§ç±»ï¼šå¯¼èˆªã€å¯¹è±¡äº¤äº’ã€ç¤¾äº¤äº¤äº’ã€å±æ€§é—®ç­”å’Œç©ºé—´é—®ç­”ï¼Œä»¥è¯„ä¼°æ™ºèƒ½ä½“çš„ä¸åŒèƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨EmbodiedEvalä¸Šè¯„ä¼°äº†æœ€æ–°çš„MLLMsï¼Œå‘ç°å®ƒä»¬åœ¨å®ä½“ä»»åŠ¡ä¸Šä¸äººç±»æ°´å¹³å­˜åœ¨æ˜æ˜¾å·®è·ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ç°æœ‰MLLMåœ¨å®ä½“èƒ½åŠ›æ–¹é¢çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥çš„å¼€å‘æä¾›äº†è§è§£ã€‚æˆ‘ä»¬å…¬å¼€æ‰€æœ‰è¯„ä¼°æ•°æ®å’Œæ¨¡æ‹Ÿæ¡†æ¶<a target="_blank" rel="noopener" href="https://github.com/thunlp/EmbodiedEval%E3%80%82">https://github.com/thunlp/EmbodiedEvalã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.11858v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºEmbodiedEvalçš„ç»¼åˆæ€§äº¤äº’å¼è¯„ä¼°åŸºå‡†ï¼Œç”¨äºå¯¹å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å®ä½“èƒ½åŠ›è¿›è¡Œè¯„ä¼°ã€‚EmbodiedEvalåŒ…å«125ä¸ªä¸åŒçš„3Dåœºæ™¯ä¸­çš„328ä¸ªç‹¬ç‰¹ä»»åŠ¡ï¼Œæ¶µç›–å¹¿æ³›çš„ç°æœ‰å®ä½“AIä»»åŠ¡ï¼Œå…·æœ‰æ˜¾è‘—å¢å¼ºçš„å¤šæ ·æ€§ï¼Œå¹¶ä¸ºMLLMsé‡èº«å®šåˆ¶äº†ç»Ÿä¸€çš„æ¨¡æ‹Ÿå’Œè¯„ä¼°æ¡†æ¶ã€‚å¯¹ç°æœ‰MLLMsåœ¨EmbodiedEvalä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä¸äººç±»æ°´å¹³ç›¸æ¯”ï¼Œå®ƒä»¬åœ¨å®ä½“ä»»åŠ¡ä¸Šå­˜åœ¨æ˜¾è‘—å·®è·ã€‚è¿™ä¸ºæœªæ¥MLLMsçš„å‘å±•æä¾›äº†è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å®ä½“èƒ½åŠ›æ–¹é¢å±•ç°å‡ºæ˜¾è‘—è¿›å±•ã€‚</li>
<li>å½“å‰è¯„ä¼°åŸºå‡†ä¸»è¦åˆ©ç”¨é™æ€å›¾åƒæˆ–è§†é¢‘ï¼Œé™åˆ¶åœ¨éäº¤äº’å¼åœºæ™¯ï¼Œæ— æ³•å……åˆ†è¯„ä¼°MLLMsçš„å®ä½“èƒ½åŠ›ã€‚</li>
<li>EmbodiedEvalæ˜¯ä¸€ä¸ªå…¨é¢çš„äº¤äº’å¼è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨ä¸ºMLLMsçš„å®ä½“èƒ½åŠ›è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>EmbodiedEvalåŒ…å«328ä¸ªç‹¬ç‰¹ä»»åŠ¡ï¼Œåˆ†å¸ƒåœ¨125ä¸ªä¸åŒçš„3Dåœºæ™¯ä¸­ï¼Œæ¶µç›–å¹¿æ³›çš„å®ä½“AIä»»åŠ¡ï¼Œå¹¶æ˜¾è‘—å¢å¼ºäº†å¤šæ ·æ€§ã€‚</li>
<li>EmbodiedEvalçš„ä»»åŠ¡åˆ†ä¸ºäº”ä¸ªç±»åˆ«ï¼šå¯¼èˆªã€ç‰©ä½“äº¤äº’ã€ç¤¾äº¤äº¤äº’ã€å±æ€§é—®é¢˜å›ç­”å’Œç©ºé—´é—®é¢˜å›ç­”ï¼Œä»¥è¯„ä¼°å®ä½“çš„ä¸åŒèƒ½åŠ›ã€‚</li>
<li>å¯¹ç°æœ‰MLLMsåœ¨EmbodiedEvalä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå®ƒä»¬åœ¨å®ä½“ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸äººç±»æ°´å¹³å­˜åœ¨æ˜¾è‘—å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.11858">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-07336ceb162622cd249372c52c3c077c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8b5faab522a2345ce0b57a5cda2797c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91b6bfa7a5b4d47937fca84099c7bd26.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5650983f46a355fb8cc44ac6ac5dd00.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9622a0e405fc2a4437ce21c7de2d4c72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec92c77c608b2de3e2246ff258e28b1d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9b93d3a2c16839c5eca1c782975d3bba.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="ANSR-DT-An-Adaptive-Neuro-Symbolic-Learning-and-Reasoning-Framework-for-Digital-Twins"><a href="#ANSR-DT-An-Adaptive-Neuro-Symbolic-Learning-and-Reasoning-Framework-for-Digital-Twins" class="headerlink" title="ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for   Digital Twins"></a>ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for   Digital Twins</h2><p><strong>Authors:Safayat Bin Hakim, Muhammad Adil, Alvaro Velasquez, Houbing Herbert Song</strong></p>
<p>In this paper, we propose an Adaptive Neuro-Symbolic Learning and Reasoning Framework for digital twin technology called &#96;&#96;ANSR-DT.â€ Digital twins in industrial environments often struggle with interpretability, real-time adaptation, and human input integration. Our approach addresses these challenges by combining CNN-LSTM dynamic event detection with reinforcement learning and symbolic reasoning to enable adaptive intelligence with interpretable decision processes. This integration enhances environmental understanding while promoting continuous learning, leading to more effective real-time decision-making in human-machine collaborative applications. We evaluated ANSR-DT on synthetic industrial data, observing significant improvements over traditional approaches, with up to 99.5% accuracy for dynamic pattern recognition. The framework demonstrated superior adaptability with extended reinforcement learning training, improving explained variance from 0.447 to 0.547. Future work aims at scaling to larger datasets to test rule management beyond the current 14 rules. Our open-source implementation promotes reproducibility and establishes a foundation for future research in adaptive, interpretable digital twins for industrial applications. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæ•°å­—å­ªç”ŸæŠ€æœ¯çš„è‡ªé€‚åº”ç¥ç»ç¬¦å·å­¦ä¹ ä¸æ¨ç†æ¡†æ¶ï¼Œåä¸ºâ€œANSR-DTâ€ã€‚å·¥ä¸šç¯å¢ƒä¸­çš„æ•°å­—å­ªç”Ÿç»å¸¸é¢ä¸´å¯è§£é‡Šæ€§ã€å®æ—¶è‡ªé€‚åº”å’Œäººä¸ºè¾“å…¥é›†æˆæ–¹é¢çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ç»“åˆCNN-LSTMåŠ¨æ€äº‹ä»¶æ£€æµ‹ä¸å¼ºåŒ–å­¦ä¹ å’Œç¬¦å·æ¨ç†æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œä»¥å®ç°å…·æœ‰å¯è§£é‡Šå†³ç­–è¿‡ç¨‹çš„è‡ªé€‚åº”æ™ºèƒ½ã€‚è¿™ç§é›†æˆå¢å¼ºäº†ç¯å¢ƒç†è§£ï¼ŒåŒæ—¶ä¿ƒè¿›äº†æŒç»­å­¦ä¹ ï¼Œä»è€Œåœ¨äººæœºåä½œåº”ç”¨ä¸­å®ç°äº†æ›´æœ‰æ•ˆçš„å®æ—¶å†³ç­–ã€‚æˆ‘ä»¬åœ¨åˆæˆå·¥ä¸šæ•°æ®ä¸Šè¯„ä¼°äº†ANSR-DTï¼Œè§‚å¯Ÿåˆ°ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ï¼ŒåŠ¨æ€æ¨¡å¼è¯†åˆ«çš„å‡†ç¡®ç‡é«˜è¾¾99.5%ã€‚è¯¥æ¡†æ¶åœ¨æ‰©å±•çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­è¡¨ç°å‡ºå‡ºè‰²çš„é€‚åº”æ€§ï¼Œè§£é‡Šçš„æ–¹å·®ä»0.447æé«˜åˆ°0.547ã€‚æœªæ¥çš„å·¥ä½œæ—¨åœ¨æ‰©å±•åˆ°æ›´å¤§çš„æ•°æ®é›†ï¼Œä»¥æµ‹è¯•å½“å‰14æ¡è§„åˆ™ä¹‹å¤–çš„è§„åˆ™ç®¡ç†ã€‚æˆ‘ä»¬çš„å¼€æºå®ç°ä¿ƒè¿›äº†å¯é‡å¤æ€§ï¼Œå¹¶ä¸ºæœªæ¥åœ¨è‡ªé€‚åº”ã€å¯è§£é‡Šçš„æ•°å­—å­ªç”Ÿå·¥ä¸šåº”ç”¨æ–¹é¢çš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.08561v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºæ•°å­—å­ªç”ŸæŠ€æœ¯çš„è‡ªé€‚åº”ç¥ç»ç¬¦å·å­¦ä¹ ä¸æ¨ç†æ¡†æ¶ç ”ç©¶ï¼Œæå‡ºäº†åä¸ºâ€œANSR-DTâ€çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶è§£å†³äº†æ•°å­—å­ªç”Ÿåœ¨å·¥ä¸šç¯å¢ƒä¸­é¢ä¸´çš„è§£é‡Šæ€§ã€å®æ—¶è‡ªé€‚åº”å’Œäººç±»è¾“å…¥é›†æˆç­‰æŒ‘æˆ˜ã€‚é€šè¿‡ç»“åˆCNN-LSTMåŠ¨æ€äº‹ä»¶æ£€æµ‹ã€å¼ºåŒ–å­¦ä¹ ä¸ç¬¦å·æ¨ç†ï¼Œå®ç°äº†å…·æœ‰å¯è§£é‡Šå†³ç­–è¿‡ç¨‹çš„è‡ªé€‚åº”æ™ºèƒ½ã€‚åœ¨åˆæˆå·¥ä¸šæ•°æ®ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒANSR-DTåœ¨åŠ¨æ€æ¨¡å¼è¯†åˆ«æ–¹é¢å®ç°äº†é«˜è¾¾99.5%çš„å‡†ç¡®ç‡ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„é€‚åº”æ€§ä¸æ›´å¼ºçš„è§£é‡Šæ–¹å·®ã€‚æœªæ¥å·¥ä½œå°†è‡´åŠ›äºæ‰©å¤§æ•°æ®é›†è§„æ¨¡ï¼Œæµ‹è¯•è§„åˆ™ç®¡ç†è¶…è¶Šå½“å‰14æ¡è§„åˆ™çš„åº”ç”¨åœºæ™¯ã€‚è¯¥å¼€æºå®ç°ä¿ƒè¿›äº†å¯é‡å¤æ€§ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶è‡ªé€‚åº”ã€å¯è§£é‡Šçš„å·¥ä¸šåº”ç”¨æ•°å­—å­ªç”ŸæŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åä¸ºâ€œANSR-DTâ€çš„è‡ªé€‚åº”ç¥ç»ç¬¦å·å­¦ä¹ ä¸æ¨ç†æ¡†æ¶ï¼Œç”¨äºè§£å†³æ•°å­—å­ªç”ŸæŠ€æœ¯åœ¨å·¥ä¸šç¯å¢ƒä¸­çš„å¤šé‡æŒ‘æˆ˜ã€‚</li>
<li>ç»“åˆCNN-LSTMåŠ¨æ€äº‹ä»¶æ£€æµ‹ä¸å¼ºåŒ–å­¦ä¹ ï¼Œå¢å¼ºäº†ç¯å¢ƒç†è§£å¹¶ä¿ƒè¿›äº†æŒç»­å­¦ä¹ ã€‚</li>
<li>é€šè¿‡ç¬¦å·æ¨ç†å®ç°äº†å¯è§£é‡Šçš„å†³ç­–è¿‡ç¨‹ï¼Œæœ‰åŠ©äºæå‡å®æ—¶å†³ç­–æ•ˆç‡åœ¨äººæœºåä½œåº”ç”¨ä¸­ã€‚</li>
<li>åœ¨åˆæˆå·¥ä¸šæ•°æ®ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒANSR-DTåœ¨åŠ¨æ€æ¨¡å¼è¯†åˆ«ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå‡†ç¡®ç‡é«˜è¾¾99.5%ã€‚</li>
<li>æ¡†æ¶å±•ç°å‡ºå“è¶Šçš„é€‚åº”æ€§ï¼Œé€šè¿‡æ‰©å±•å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œè§£é‡Šæ–¹å·®å¾—åˆ°äº†æ”¹å–„ã€‚</li>
<li>ç›®å‰å·¥ä½œå±€é™åœ¨äºè§„åˆ™ç®¡ç†çš„æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œæœªæ¥ç ”ç©¶å°†æ‹“å±•è‡³æ›´å¤§è§„æ¨¡æ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.08561">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3fa4b77f049ca621f7643f878c86e071.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe8c4fb4fb12644382663c097034ff06.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7f21722045e8010fd9a648d304a2734e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d54654987899b1e44aad9ef28aa8e61b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04c5e2b88b364667a0b7e6004077f691.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-15/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-15/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-15/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-ff68f3b629529eea02d7b494c7b5137a.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-15  Steering CLIP's vision transformer with sparse autoencoders
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-13/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-461a70fadb968159e1382603dad2aba5.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-13  An Adversarial Perspective on Machine Unlearning for AI Safety
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24801.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
