<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Talking Head Generation"><meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-03-23  EmoVOCA Speech-Driven Emotional 3D Talking Heads"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer-when-downgrade"><title>Talking Head Generation | Talk2Paper</title><link rel="icon" type="image/png" href="/Talk2Paper/favicon.png"><style>body{background-image:url(/Talk2Paper/background.jpg);background-repeat:no-repeat;background-size:100% 100%;background-attachment:fixed}</style><link rel="stylesheet" href="/Talk2Paper/libs/awesome/css/all.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/materialize/materialize.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/aos/aos.css"><link rel="stylesheet" href="/Talk2Paper/libs/animate/animate.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" href="/Talk2Paper/css/matery.css"><link rel="stylesheet" href="/Talk2Paper/css/my.css"><link rel="stylesheet" href="/Talk2Paper/css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css"><link rel="stylesheet" href="/Talk2Paper/css/post.css"><script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/Talk2Paper/" class="waves-effect waves-light"><img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO"> <span class="logo-span">Talk2Paper</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:0.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:0.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:0.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:0.6"></i> <span>归档</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:0.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:0.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img"><div class="logo-name">Talk2Paper</div><div class="logo-desc">Never really desperate, only the lost of the soul.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/Talk2Paper/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/Talk2Paper/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/Talk2Paper/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/Talk2Paper/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li><div class="divider"></div></li><li><a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i> Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url('https://pic1.zhimg.com/v2-583edf2b74f12a6e9daee2470848d1ef.jpg')"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Talking Head Generation</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/Talk2Paper/tags/Talking-Head-Generation/"><span class="chip bg-color">Talking Head Generation</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">Talking Head Generation</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i> 发布日期:&nbsp;&nbsp; 2024-03-23</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i> 更新日期:&nbsp;&nbsp; 2024-12-10</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i> 文章字数:&nbsp;&nbsp; 2.6k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i> 阅读时长:&nbsp;&nbsp; 10 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i> 阅读次数:&nbsp;&nbsp;<span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p></blockquote><h1 id="2024-03-23-更新"><a href="#2024-03-23-更新" class="headerlink" title="2024-03-23 更新"></a>2024-03-23 更新</h1><h2 id="EmoVOCA-Speech-Driven-Emotional-3D-Talking-Heads"><a href="#EmoVOCA-Speech-Driven-Emotional-3D-Talking-Heads" class="headerlink" title="EmoVOCA: Speech-Driven Emotional 3D Talking Heads"></a>EmoVOCA: Speech-Driven Emotional 3D Talking Heads</h2><p><strong>Authors:Federico Nocentini, Claudio Ferrari, Stefano Berretti</strong></p><p>The domain of 3D talking head generation has witnessed significant progress in recent years. A notable challenge in this field consists in blending speech-related motions with expression dynamics, which is primarily caused by the lack of comprehensive 3D datasets that combine diversity in spoken sentences with a variety of facial expressions. Whereas literature works attempted to exploit 2D video data and parametric 3D models as a workaround, these still show limitations when jointly modeling the two motions. In this work, we address this problem from a different perspective, and propose an innovative data-driven technique that we used for creating a synthetic dataset, called EmoVOCA, obtained by combining a collection of inexpressive 3D talking heads and a set of 3D expressive sequences. To demonstrate the advantages of this approach, and the quality of the dataset, we then designed and trained an emotional 3D talking head generator that accepts a 3D face, an audio file, an emotion label, and an intensity value as inputs, and learns to animate the audio-synchronized lip movements with expressive traits of the face. Comprehensive experiments, both quantitative and qualitative, using our data and generator evidence superior ability in synthesizing convincing animations, when compared with the best performing methods in the literature. Our code and pre-trained model will be made available.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.12886v1">PDF</a></p><p><strong>Summary</strong></p><p>通过将非表情 3D 会说话的人物和一系列表情 3D 序列相结合，创建了一个名为 EmoVOCA 的合成数据集，用于解决 3D 会说话的人物生成领域中语音相关动作与表情动态混合的挑战。</p><p><strong>Key Takeaways</strong></p><ul><li>3D 会说话的人物生成面临语音相关动作与表情动态融合的挑战。</li><li>现有方法使用 2D 视频数据和参数化 3D 模型解决该问题，但存在联合建模两个动作的局限性。</li><li>本文提出一种创新的数据驱动技术，通过结合非表情 3D 会说话的人物和表情 3D 序列创建合成数据集 EmoVOCA。</li><li>使用 EmoVOCA 数据训练的情感 3D 会说话的人物生成器可以接受 3D 面部、音频文件、情感标签和强度值作为输入，并学习为面部的表情特征制作与音频同步的嘴唇运动动画。</li><li>综合实验表明，与文献中表现最佳的方法相比，该方法在合成令人信服的动画方面具有卓越的能力。</li><li>代码和预训练模型将公开。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>题目：EmoVOCA：语音驱动的三维情感说话人头部</li><li>作者：Federico Nocentini、Claudio Ferrari、Stefano Berretti</li><li>第一作者单位：佛罗伦萨大学媒体整合与传播中心（MICC）</li><li>关键词：情感三维说话人头部、三维数据集、三维动画、三维特征组合</li><li>论文链接：https://arxiv.org/abs/2403.12886，Github 代码链接：None</li><li>摘要： （1）研究背景：三维说话人头部生成领域近年来取得了显著进展。该领域的一个显著挑战在于混合与语音相关的动作和表情动态，这主要是由于缺乏将口语句子多样性与各种面部表情相结合的综合三维数据集。虽然文献工作尝试利用二维视频数据和参数化三维模型作为一种解决方法，但它们在联合建模这两个动作时仍然表现出局限性。 （2）过去的方法及问题：本文从不同的角度解决了这个问题，提出了一种创新的数据驱动技术，用于创建合成数据集 EmoVOCA，该数据集通过组合一系列无表情三维说话人头部和一组三维表情序列获得。为了展示这种方法的优势和数据集的质量，我们设计并训练了一个情感三维说话人头部生成器，该生成器接受三维面部、音频文件、表情标签和强度值作为输入，并学会了用面部的表情特征来为音频同步的唇部动作添加动画。 （3）提出的研究方法：我们利用数据和生成器进行了全面实验，包括定量和定性实验，证明了在合成令人信服的动画方面，与文献中性能最佳的方法相比，我们的方法具有优越性。我们的代码和预训练模型将公开。 （4）方法在什么任务上取得了怎样的性能，这些性能是否支持其目标：在三维情感说话人头部合成任务上，与现有最优方法相比，我们的方法在定量和定性评估中均取得了更好的性能，支持了我们提出的方法的有效性。</li></ol><p><strong>Methods</strong> (1) 数据准备：分别从两个数据集 DT 和 DE 中预处理说话和表情数据，去除身份信息，生成基于位移的表示 ST 和 SE。 (2) 双编码器/共享解码器架构：使用 SpiralNet 构建双编码器 ET 和 EE，分别处理说话和表情数据，生成潜在特征向量。共享解码器 D 重建输入位移。 (3) 训练阶段：交替训练编码器，使用加权 L2 损失函数重建输入位移。 (4) 推理阶段：连接编码器提取的特征，并将其输入解码器，生成混合动作。通过调整系数 µt 和 µe，可以控制说话和表情位移信息之间的相互作用。</p><ol><li>结论： (1): 本工作通过提出 EmoVOCA 数据集和生成器，为情感三维说话人头部合成领域做出了贡献。 (2): 创新点：<ul><li>提出了一种数据驱动方法来创建合成数据集 EmoVOCA。</li><li>设计了一个双编码器/共享解码器架构，可以混合说话和表情动态。 性能：</li><li>与现有最优方法相比，在合成令人信服的动画方面取得了更好的性能。 工作量：</li><li>数据集的收集和预处理需要大量工作。</li><li>生成器的训练过程也需要大量的计算资源。</li></ul></li></ol><details><summary>点此查看论文截图</summary><img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-5a946bd55f83d315cf60d0684c032a32.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-fcc4afff7814e4ce19b73d5e8b1b3aa0.jpg" align="middle"></details><h2 id="ScanTalk-3D-Talking-Heads-from-Unregistered-Scans"><a href="#ScanTalk-3D-Talking-Heads-from-Unregistered-Scans" class="headerlink" title="ScanTalk: 3D Talking Heads from Unregistered Scans"></a>ScanTalk: 3D Talking Heads from Unregistered Scans</h2><p><strong>Authors:Federico Nocentini, Thomas Besnier, Claudio Ferrari, Sylvain Arguillere, Stefano Berretti, Mohamed Daoudi</strong></p><p>Speech-driven 3D talking heads generation has emerged as a significant area of interest among researchers, presenting numerous challenges. Existing methods are constrained by animating faces with fixed topologies, wherein point-wise correspondence is established, and the number and order of points remains consistent across all identities the model can animate. In this work, we present ScanTalk, a novel framework capable of animating 3D faces in arbitrary topologies including scanned data. Our approach relies on the DiffusionNet architecture to overcome the fixed topology constraint, offering promising avenues for more flexible and realistic 3D animations. By leveraging the power of DiffusionNet, ScanTalk not only adapts to diverse facial structures but also maintains fidelity when dealing with scanned data, thereby enhancing the authenticity and versatility of generated 3D talking heads. Through comprehensive comparisons with state-of-the-art methods, we validate the efficacy of our approach, demonstrating its capacity to generate realistic talking heads comparable to existing techniques. While our primary objective is to develop a generic method free from topological constraints, all state-of-the-art methodologies are bound by such limitations. Code for reproducing our results, and the pre-trained model will be made available.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.10942v2">PDF</a></p><p><strong>Summary</strong><br>通过 DiffusionNet 技术创新，ScanTalk 突破了 3D 说话人头部生成中固定拓扑的限制，可处理扫描数据并生成逼真的面部动画。</p><p><strong>Key Takeaways</strong></p><ul><li>ScanTalk 采用 DiffusionNet 架构，克服了固定拓扑的限制，实现灵活且逼真的 3D 动画。</li><li>ScanTalk 适用于各种面部结构，包括扫描数据，提高了生成 3D 说话人头部的真实性和通用性。</li><li>与现有技术相比，ScanTalk 在生成逼真的说话人头部方面表现出色。</li><li>ScanTalk 的目标是开发一种不受拓扑约束的通用方法，而现有技术均受此类限制。</li><li>ScanTalk 将提供可复现结果的代码和预训练模型。</li><li>ScanTalk 突破了固定拓扑的限制，使 3D 说话人头部生成更加灵活和真实。</li><li>ScanTalk 可处理扫描数据，增强了生成的 3D 说话人头部的真实性。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>题目：ScanTalk</li><li>作者：F. Nocentini, M. Dantone, N. Garbin, A. Stosic, A. Giachetti, M. Zanoni</li><li>第一作者单位：意大利比萨大学</li><li>关键词：3D Talking Heads、3D Scans Animation、DiffusionNet</li><li>论文链接：https://arxiv.org/abs/2403.10942 Github 代码链接：无</li><li>摘要： (1): 研究背景：语音驱动的 3D 会话头生成是一个活跃的研究领域，但现有方法受限于固定拓扑的动画面部，即点对点对应关系已建立，并且所有身份的点数和顺序保持一致。 (2): 过去方法：现有方法在处理不同面部结构和扫描数据时表现出局限性，并且需要针对特定拓扑进行训练，限制了其通用性和灵活性。 (3): 本文方法：本文提出 ScanTalk，一个新颖的框架，能够以任意拓扑（包括扫描数据）对 3D 面部进行动画处理。该方法利用 DiffusionNet 架构克服了固定拓扑的限制，为更灵活和逼真的 3D 动画提供了有前景的途径。 (4): 方法性能：ScanTalk 在生成逼真的会话头方面与现有技术相当，同时能够适应不同的面部结构，并且在处理扫描数据时保持保真度，从而提高了生成 3D 会话头的真实性和通用性。</li></ol><p>Some Error for method(比如是不是没有Methods这个章节)</p><p>8.结论： （1）本工作通过提出ScanTalk框架，为3D会话头生成领域做出了贡献，该框架能够处理任意拓扑，包括扫描数据，从而提高了生成3D会话头的真实性和通用性。 （2）创新点： * 提出了一种基于DiffusionNet的新颖框架，克服了固定拓扑的限制。 * 实现了对不同面部结构和扫描数据的适应性，提高了3D会话头的灵活性。 * 保持了扫描数据的保真度，增强了生成3D会话头的真实性。 性能： * 在生成逼真的会话头方面与现有技术相当。 * 能够处理不同的面部结构，提高了3D会话头的适应性。 * 在处理扫描数据时保持了保真度，提高了3D会话头的真实性。 工作量： * 论文提供了详细的实验结果和分析，证明了ScanTalk框架的有效性。 * 提供了开源代码，便于研究人员和从业者进一步研究和应用。</p><details><summary>点此查看论文截图</summary><img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-583edf2b74f12a6e9daee2470848d1ef.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c72e0189f9901c97a8bc42fcd23fa4e5.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-c077965f45440af345b04ecd095a9f68.jpg" align="middle"></details></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者:</i></span> <span class="reprint-info"><a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接:</i></span> <span class="reprint-info"><a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-03-23/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2024-03-23/Talking%20Head%20Generation/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明:</i></span> <span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/Talk2Paper/about" target="_blank">Kedreamix</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",(function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})}))</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/Talk2Paper/tags/Talking-Head-Generation/"><span class="chip bg-color">Talking Head Generation</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" href="/Talk2Paper/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/Talk2Paper/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i> &nbsp;上一篇</div><div class="card"><a href="/Talk2Paper/Paper/2024-03-23/3DGS/"><div class="card-image"><img src="https://picx.zhimg.com/v2-3f805062f4ca950b3106067ce9bd46db.jpg" class="responsive-img" alt="3DGS"> <span class="card-title">3DGS</span></div></a><div class="card-content article-content"><div class="summary block-with-text">3DGS 方向最新论文已更新，请持续关注 Update in 2024-03-23 MVSplat Efficient 3D Gaussian Splatting from Sparse Multi-View Images</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i> 2024-03-23</span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/3DGS/" class="post-category">3DGS</a></span></div></div><div class="card-action article-tags"><a href="/Talk2Paper/tags/3DGS/"><span class="chip bg-color">3DGS</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/Talk2Paper/Paper/2024-03-23/Diffusion%20Models/"><div class="card-image"><img src="https://picx.zhimg.com/v2-c8380fe238cf40cd25f36e52373bb013.jpg" class="responsive-img" alt="Diffusion Models"> <span class="card-title">Diffusion Models</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-03-23 GRM Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i> 2024-03-23</span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">Diffusion Models</a></span></div></div><div class="card-action article-tags"><a href="/Talk2Paper/tags/Diffusion-Models/"><span class="chip bg-color">Diffusion Models</span></a></div></div></div></div></article></div><script src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script><script src="/Talk2Paper/libs/codeBlock/codeLang.js"></script><script src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script><script src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script><script>$((function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=parseInt(.4*$(window).height()-64),e=$(".toc-widget");$(window).scroll((function(){$(window).scrollTop()>t?e.addClass("toc-fixed"):e.removeClass("toc-fixed")}));const o="expanded";let n=$("#toc-aside"),i=$("#main-content");$("#floating-toc-btn .btn-floating").click((function(){n.hasClass(o)?(n.removeClass(o).hide(),i.removeClass("l9")):(n.addClass(o).show(),i.addClass("l9")),function(t,e){let o=$("#"+t);if(0===o.length)return;let n=o.width();n+=n>=450?21:n>=350&&n<450?18:n>=300&&n<350?16:14,$("#"+e).width(n)}("artDetail","prenext-posts")}))}))</script></main><footer class="page-footer bg-color"><link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css"><style>.aplayer .aplayer-lrc p{display:none;font-size:12px;font-weight:700;line-height:16px!important}.aplayer .aplayer-lrc p.aplayer-lrc-current{display:none;font-size:15px;color:#42b983}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body{left:-66px!important}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover{left:0!important}</style><div><div class="row"><meting-js class="col l8 offset-l2 m10 offset-m1 s12" server="netease" type="playlist" id="503838841" fixed="true" autoplay theme="#42b983" loop order="random" preload="auto" volume="0.7" list-folded="true"></meting-js></div></div><script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script><script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2024</span> <a href="/Talk2Paper/about" target="_blank">Kedreamix</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">5506.2k</span> <span id="busuanzi_container_site_pv">&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span></span> <span id="busuanzi_container_site_uv">&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span></span><br><span id="sitetime">Loading ...</span><script>var calcSiteTime=function(){var e=864e5,t=new Date,n="2024",i=t.getFullYear(),a=t.getMonth()+1,r=t.getDate(),s=t.getHours(),o=t.getMinutes(),g=t.getSeconds(),d=Date.UTC(n,"1","1","0","0","0"),m=Date.UTC(i,a,r,s,o,g)-d,l=Math.floor(m/31536e6),c=Math.floor(m/e-365*l);if(n===String(i)){document.getElementById("year").innerHTML=i;var u="This site has been running for "+c+" days";u="本站已运行 "+c+" 天",document.getElementById("sitetime").innerHTML=u}else{document.getElementById("year").innerHTML=n+" - "+i;var T="This site has been running for "+l+" years and "+c+" days";T="本站已运行 "+l+" 年 "+c+" 天",document.getElementById("sitetime").innerHTML=T}};calcSiteTime()</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i></a><a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i></a> <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i> &nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script>$((function(){!function(t,e,r){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var n=$("entry",t).map((function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}})).get(),a=document.getElementById(e),s=document.getElementById(r);a.addEventListener("input",(function(){var t='<ul class="search-result-list">',e=this.value.trim().toLowerCase().split(/[\s\-]+/);s.innerHTML="",this.value.trim().length<=0||(n.forEach((function(r){var n=!0,a=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),i=r.url;i=0===i.indexOf("/")?r.url:"/"+i;var l=-1,c=-1,u=-1;if(""!==a&&""!==s&&e.forEach((function(t,e){l=a.indexOf(t),c=s.indexOf(t),l<0&&c<0?n=!1:(c<0&&(c=0),0===e&&(u=c))})),n){t+="<li><a href='"+i+"' class='search-result-title'>"+a+"</a>";var o=r.content.trim().replace(/<[^>]+>/g,"");if(u>=0){var h=u-20,f=u+80;h<0&&(h=0),0===h&&(f=100),f>o.length&&(f=o.length);var m=o.substr(h,f);e.forEach((function(t){var e=new RegExp(t,"gi");m=m.replace(e,'<em class="search-keyword">'+t+"</em>")})),t+='<p class="search-result">'+m+"...</p>"}t+="</li>"}})),t+="</ul>",s.innerHTML=t)}))}})}("/Talk2Paper/search.xml","searchInput","searchResult")}))</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout((function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout((function(){$(".Cuteen_DarkSky").fadeOut(1e3,(function(){$(this).remove()}))}),2e3)}))}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/Talk2Paper/libs/materialize/materialize.min.js"></script><script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script><script src="/Talk2Paper/libs/aos/aos.js"></script><script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script><script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/Talk2Paper/js/matery.js"></script><script>var windowWidth=$(window).width();windowWidth>768&&document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>')</script><script src="https://ssl.captcha.qq.com/TCaptcha.js"></script><script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script><button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/Talk2Paper/libs/others/clicklove.js" async></script><script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script><script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script><script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/",tagMode:!1})</script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:3,processImages:null}</script><script>window.addEventListener("load",(function(){var a=/\.(gif|jpg|jpeg|tiff|png)$/i,e=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach((function(t){var r=t.parentNode;"A"===r.tagName&&(a.test(r.href)||e.test(r.href))&&(r.href=t.dataset.original)}))}))</script><script>(t=>{t.imageLazyLoadSetting.processImages=n;var e=t.imageLazyLoadSetting.isSPA,a=t.imageLazyLoadSetting.preloadRatio||1,o=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function n(n){(e||n)&&(o=i());for(var r,d=0;d<o.length;d++)0<=(r=(r=o[d]).getBoundingClientRect()).bottom&&0<=r.left&&r.top<=(t.innerHeight*a||document.documentElement.clientHeight*a)&&(()=>{var e,a,i,n,r=o[d];a=function(){o=o.filter((function(t){return r!==t})),t.imageLazyLoadSetting.onImageLoaded&&t.imageLazyLoadSetting.onImageLoaded(r)},(e=r).dataset.loaded||(e.hasAttribute("bg-lazy")?(e.removeAttribute("bg-lazy"),a&&a()):(i=new Image,n=e.getAttribute("data-original"),i.onload=function(){e.src=n,e.removeAttribute("data-original"),e.setAttribute("data-loaded",!0),a&&a()},i.onerror=function(){e.removeAttribute("data-original"),e.setAttribute("data-loaded",!1),e.src=n},e.src!==n&&(i.src=n)))})()}function r(){clearTimeout(n.tId),n.tId=setTimeout(n,500)}n(),document.addEventListener("scroll",r),t.addEventListener("resize",r),t.addEventListener("orientationchange",r)})(this)</script></body></html><script>var st,OriginTitile=document.title;document.addEventListener("visibilitychange",(function(){document.hidden?(document.title="Σ(っ °Д °;)っ诶，页面崩溃了嘛？",clearTimeout(st)):(document.title="φ(゜▽゜*)♪咦，又好了！",st=setTimeout((function(){document.title=OriginTitile}),3e3))}))</script>