<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
    <meta name="description" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-14  Patch-Wise Hypergraph Contrastive Learning with Dual Normal Distribution   Weighting for Multi-Domain Stain Transfer">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-65ddb79f369ca600a59a6227f48da491.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    4.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    20 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-14-æ›´æ–°"><a href="#2025-03-14-æ›´æ–°" class="headerlink" title="2025-03-14 æ›´æ–°"></a>2025-03-14 æ›´æ–°</h1><h2 id="Patch-Wise-Hypergraph-Contrastive-Learning-with-Dual-Normal-Distribution-Weighting-for-Multi-Domain-Stain-Transfer"><a href="#Patch-Wise-Hypergraph-Contrastive-Learning-with-Dual-Normal-Distribution-Weighting-for-Multi-Domain-Stain-Transfer" class="headerlink" title="Patch-Wise Hypergraph Contrastive Learning with Dual Normal Distribution   Weighting for Multi-Domain Stain Transfer"></a>Patch-Wise Hypergraph Contrastive Learning with Dual Normal Distribution   Weighting for Multi-Domain Stain Transfer</h2><p><strong>Authors:Haiyan Wei, Hangrui Xu, Bingxu Zhu, Yulian Geng, Aolei Liu, Wenfei Yin, Jian Liu</strong></p>
<p>Virtual stain transfer leverages computer-assisted technology to transform the histochemical staining patterns of tissue samples into other staining types. However, existing methods often lose detailed pathological information due to the limitations of the cycle consistency assumption. To address this challenge, we propose STNHCL, a hypergraph-based patch-wise contrastive learning method. STNHCL captures higher-order relationships among patches through hypergraph modeling, ensuring consistent higher-order topology between input and output images. Additionally, we introduce a novel negative sample weighting strategy that leverages discriminator heatmaps to apply different weights based on the Gaussian distribution for tissue and background, thereby enhancing traditional weighting methods. Experiments demonstrate that STNHCL achieves state-of-the-art performance in the two main categories of stain transfer tasks. Furthermore, our model also performs excellently in downstream tasks. Code will be made available. </p>
<blockquote>
<p>è™šæ‹ŸæŸ“è‰²è½¬ç§»æŠ€æœ¯åˆ©ç”¨è®¡ç®—æœºè¾…åŠ©æŠ€æœ¯å°†ç»„ç»‡æ ·æœ¬çš„ç»„åŒ–æŸ“è‰²æ¨¡å¼è½¬åŒ–ä¸ºå…¶ä»–æŸ“è‰²ç±»å‹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ç”±äºå—å¾ªç¯ä¸€è‡´æ€§å‡è®¾çš„é™åˆ¶ï¼Œå¾€å¾€ä¼šä¸¢å¤±è¯¦ç»†çš„ç—…ç†ä¿¡æ¯ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè¶…å›¾çš„STNHCLï¼ˆæ–‘ç‚¹çº§å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼‰ã€‚STNHCLé€šè¿‡è¶…å›¾æ¨¡å‹æ•æ‰æ–‘ç‚¹é—´çš„é«˜é˜¶å…³ç³»ï¼Œç¡®ä¿è¾“å…¥å’Œè¾“å‡ºå›¾åƒä¹‹é—´é«˜é˜¶æ‹“æ‰‘çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹è´Ÿæ ·æœ¬åŠ æƒç­–ç•¥ï¼Œåˆ©ç”¨é‰´åˆ«å™¨çƒ­å›¾æ ¹æ®é«˜æ–¯åˆ†å¸ƒå¯¹ç»„ç»‡å’ŒèƒŒæ™¯åº”ç”¨ä¸åŒçš„æƒé‡ï¼Œä»è€Œå¢å¼ºä¼ ç»ŸåŠ æƒæ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼ŒSTNHCLåœ¨æŸ“è‰²è½¬ç§»ä»»åŠ¡çš„ä¸¤ä¸ªä¸»è¦ç±»åˆ«ä¸­å‡è¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚ä»£ç å°†å…¬å¼€æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09523v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºè®¡ç®—æœºæŠ€æœ¯çš„è™šæ‹ŸæŸ“è‰²è½¬ç§»æ–¹æ³•èƒ½å°†ç»„ç»‡æ ·æœ¬çš„æŸ“è‰²æ¨¡å¼è½¬æ¢ä¸ºå…¶ä»–æŸ“è‰²ç±»å‹ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å› å¾ªç¯ä¸€è‡´æ€§å‡è®¾çš„é™åˆ¶è€Œä¸¢å¤±è¯¦ç»†ç—…ç†ä¿¡æ¯çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè¶…å›¾çš„å±€éƒ¨å¯¹æ¯”å­¦ä¹ æ–¹æ³•STNHCLã€‚STNHCLé€šè¿‡è¶…å›¾å»ºæ¨¡æ•æ‰å±€éƒ¨ä¹‹é—´çš„é«˜é˜¶å…³ç³»ï¼Œç¡®ä¿è¾“å…¥å’Œè¾“å‡ºå›¾åƒä¹‹é—´çš„é«˜é˜¶æ‹“æ‰‘ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†æ–°å‹è´Ÿæ ·æœ¬åŠ æƒç­–ç•¥ï¼Œåˆ©ç”¨é‰´åˆ«å™¨çƒ­å›¾æ ¹æ®é«˜æ–¯åˆ†å¸ƒå¯¹ç»„ç»‡å’ŒèƒŒæ™¯åº”ç”¨ä¸åŒçš„æƒé‡ï¼Œä»è€Œæ”¹è¿›ä¼ ç»ŸåŠ æƒæ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼ŒSTNHCLåœ¨æŸ“è‰²è½¬ç§»ä»»åŠ¡çš„ä¸¤ä¸ªä¸»è¦ç±»åˆ«ä¸­å‡è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œå¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚ä»£ç å³å°†å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è™šæ‹ŸæŸ“è‰²è½¬ç§»åˆ©ç”¨è®¡ç®—æœºæŠ€æœ¯è½¬æ¢ç»„ç»‡æ ·æœ¬çš„æŸ“è‰²æ¨¡å¼ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å› å¾ªç¯ä¸€è‡´æ€§å‡è®¾çš„é™åˆ¶ï¼Œæ˜“ä¸¢å¤±è¯¦ç»†ç—…ç†ä¿¡æ¯ã€‚</li>
<li>STNHCLæ–¹æ³•é€šè¿‡è¶…å›¾å»ºæ¨¡æ•æ‰å±€éƒ¨ä¹‹é—´çš„é«˜é˜¶å…³ç³»ï¼Œç¡®ä¿è¾“å…¥å’Œè¾“å‡ºå›¾åƒä¹‹é—´çš„é«˜é˜¶æ‹“æ‰‘ä¸€è‡´æ€§ã€‚</li>
<li>å¼•å…¥æ–°å‹è´Ÿæ ·æœ¬åŠ æƒç­–ç•¥ï¼Œæ”¹è¿›ä¼ ç»ŸåŠ æƒæ–¹æ³•ã€‚</li>
<li>STNHCLåœ¨æŸ“è‰²è½¬ç§»ä»»åŠ¡çš„ä¸¤ä¸ªä¸»è¦ç±»åˆ«ä¸­è¡¨ç°æœ€ä½³ã€‚</li>
<li>STNHCLä¸ä»…é€‚ç”¨äºæŸ“è‰²è½¬ç§»ä»»åŠ¡ï¼Œè¿˜åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09523">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5d243f5fc37802f0eab8e653d1ca05e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8e2ba3ff1ae0a875680da3d847d15e6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6aa8cd03d3c5a00b613006c73b4ad8f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00cb4dce2974e8e3b4d5ed1a7b4f5215.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de41f6650a11942a65fb8f04a770ee49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a8651549355ac40ca80c9c259df37c2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Decoupled-Doubly-Contrastive-Learning-for-Cross-Domain-Facial-Action-Unit-Detection"><a href="#Decoupled-Doubly-Contrastive-Learning-for-Cross-Domain-Facial-Action-Unit-Detection" class="headerlink" title="Decoupled Doubly Contrastive Learning for Cross Domain Facial Action   Unit Detection"></a>Decoupled Doubly Contrastive Learning for Cross Domain Facial Action   Unit Detection</h2><p><strong>Authors:Yong Li, Menglin Liu, Zhen Cui, Yi Ding, Yuan Zong, Wenming Zheng, Shiguang Shan, Cuntai Guan</strong></p>
<p>Despite the impressive performance of current vision-based facial action unit (AU) detection approaches, they are heavily susceptible to the variations across different domains and the cross-domain AU detection methods are under-explored. In response to this challenge, we propose a decoupled doubly contrastive adaptation (D$^2$CA) approach to learn a purified AU representation that is semantically aligned for the source and target domains. Specifically, we decompose latent representations into AU-relevant and AU-irrelevant components, with the objective of exclusively facilitating adaptation within the AU-relevant subspace. To achieve the feature decoupling, D$^2$CA is trained to disentangle AU and domain factors by assessing the quality of synthesized faces in cross-domain scenarios when either AU or domain attributes are modified. To further strengthen feature decoupling, particularly in scenarios with limited AU data diversity, D$^2$CA employs a doubly contrastive learning mechanism comprising image and feature-level contrastive learning to ensure the quality of synthesized faces and mitigate feature ambiguities. This new framework leads to an automatically learned, dedicated separation of AU-relevant and domain-relevant factors, and it enables intuitive, scale-specific control of the cross-domain facial image synthesis. Extensive experiments demonstrate the efficacy of D$^2$CA in successfully decoupling AU and domain factors, yielding visually pleasing cross-domain synthesized facial images. Meanwhile, D$^2$CA consistently outperforms state-of-the-art cross-domain AU detection approaches, achieving an average F1 score improvement of 6%-14% across various cross-domain scenarios. </p>
<blockquote>
<p>å°½ç®¡å½“å‰åŸºäºè§†è§‰çš„é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰æ£€æµ‹æ–¹æ³•çš„æ€§èƒ½ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†å®ƒä»¬ææ˜“å—åˆ°ä¸åŒé¢†åŸŸä¹‹é—´çš„å·®å¼‚å½±å“ï¼Œè€Œä¸”è·¨åŸŸAUæ£€æµ‹æ–¹æ³•çš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è§£è€¦åŒé‡å¯¹æ¯”é€‚åº”ï¼ˆD$^2$CAï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨å­¦ä¹ çº¯åŒ–çš„AUè¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºåœ¨æºåŸŸå’Œç›®æ ‡åŸŸä¹‹é—´è¿›è¡Œè¯­ä¹‰å¯¹é½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ½œåœ¨è¡¨ç¤ºåˆ†è§£ä¸ºä¸AUç›¸å…³å’Œä¸AUä¸ç›¸å…³çš„ç»„ä»¶ï¼Œç›®çš„æ˜¯ä¸“é—¨ä¿ƒè¿›AUç›¸å…³å­ç©ºé—´å†…çš„é€‚åº”ã€‚ä¸ºäº†å®ç°ç‰¹å¾è§£è€¦ï¼ŒD$^2$CAé€šè¿‡è¯„ä¼°è·¨åŸŸåœºæ™¯ä¸­åˆæˆé¢éƒ¨è´¨é‡ï¼ˆå½“AUæˆ–é¢†åŸŸå±æ€§è¢«ä¿®æ”¹æ—¶ï¼‰æ¥è®­ç»ƒåˆ†è§£AUå’Œé¢†åŸŸå› ç´ ã€‚ä¸ºäº†è¿›ä¸€æ­¥åŠ å¼ºç‰¹å¾è§£è€¦ï¼Œç‰¹åˆ«æ˜¯åœ¨AUæ•°æ®å¤šæ ·æ€§æœ‰é™çš„åœºæ™¯ä¸­ï¼ŒD$^2$CAé‡‡ç”¨äº†ä¸€ç§åŒé‡å¯¹æ¯”å­¦ä¹ æœºåˆ¶ï¼ŒåŒ…æ‹¬å›¾åƒå’Œç‰¹å¾çº§åˆ«çš„å¯¹æ¯”å­¦ä¹ ï¼Œä»¥ç¡®ä¿åˆæˆé¢éƒ¨çš„è´¨é‡å¹¶å‡å°‘ç‰¹å¾æ¨¡ç³Šæ€§ã€‚è¿™ä¸€æ–°æ¡†æ¶å®ç°äº†AUç›¸å…³å› ç´ å’Œé¢†åŸŸç›¸å…³å› ç´ çš„è‡ªåŠ¨å­¦ä¹ åˆ†ç¦»ï¼Œå®ƒèƒ½å¤Ÿå®ç°è·¨åŸŸé¢éƒ¨å›¾åƒåˆæˆçš„ç›´è§‚ã€æ¯”ä¾‹ç‰¹å®šæ§åˆ¶ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒD$^2$CAåœ¨æˆåŠŸè§£è€¦AUå’Œé¢†åŸŸå› ç´ æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œèƒ½å¤Ÿç”Ÿæˆè§†è§‰ä¸Šä»¤äººæ„‰æ‚¦çš„è·¨åŸŸåˆæˆé¢éƒ¨å›¾åƒã€‚åŒæ—¶ï¼ŒD$^2$CAåœ¨å¤šç§è·¨åŸŸåœºæ™¯ä¸­å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„è·¨åŸŸAUæ£€æµ‹æ–¹æ³•ï¼Œå¹³å‡F1åˆ†æ•°æé«˜äº†6%-14%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08977v1">PDF</a> Accepted by IEEE Transactions on Image Processing 2025. A novel and   elegant feature decoupling method for cross-domain facial action unit   detection</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æå‡ºäº†ä¸€ç§åŸºäºè§£è€¦åŒé‡å¯¹æ¯”é€‚åº”ï¼ˆD$^2$CAï¼‰çš„æ–¹æ³•ï¼Œç”¨äºå­¦ä¹ çº¯å‡€çš„é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºåœ¨æºåŸŸå’Œç›®æ ‡åŸŸä¹‹é—´è¯­ä¹‰å¯¹é½ã€‚æ–¹æ³•é€šè¿‡åˆ†è§£æ½œåœ¨è¡¨ç¤ºæ¥ä¸“æ³¨äºAUç›¸å…³çš„å­ç©ºé—´å†…çš„é€‚é…ã€‚D$^2$CAé€šè¿‡è¯„ä¼°è·¨åŸŸåœºæ™¯ä¸­åˆæˆé¢éƒ¨è´¨é‡æ¥è®­ç»ƒç‰¹å¾è§£è€¦ï¼Œå½“ä¿®æ”¹AUæˆ–åŸŸå±æ€§æ—¶ã€‚ä¸ºè¿›ä¸€æ­¥å¼ºåŒ–ç‰¹å¾è§£è€¦ï¼Œç‰¹åˆ«æ˜¯åœ¨AUæ•°æ®å¤šæ ·æ€§æœ‰é™çš„åœºæ™¯ä¸­ï¼ŒD$^2$CAé‡‡ç”¨åŒé‡å¯¹æ¯”å­¦ä¹ æœºåˆ¶ï¼ŒåŒ…æ‹¬å›¾åƒå’Œç‰¹å¾çº§åˆ«çš„å¯¹æ¯”å­¦ä¹ ï¼Œç¡®ä¿åˆæˆé¢éƒ¨è´¨é‡å¹¶å‡å°‘ç‰¹å¾æ¨¡ç³Šã€‚å®éªŒè¡¨æ˜ï¼ŒD$^2$CAåœ¨æˆåŠŸè§£è€¦AUå’ŒåŸŸå› ç´ æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œäº§ç”Ÿè§†è§‰ä¸Šä»¤äººæ»¡æ„çš„è·¨åŸŸåˆæˆé¢éƒ¨å›¾åƒã€‚ä¸æœ€å…ˆè¿›çš„è·¨åŸŸAUæ£€æµ‹æ–¹æ³•è¿›è¡Œå¯¹æ¯”ï¼ŒD$^2$CAåœ¨å„ç§è·¨åŸŸåœºæ™¯ä¸‹å¹³å‡F1å¾—åˆ†æé«˜äº†6%~14%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰åŸºäºè§†è§‰çš„é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰æ£€æµ‹æ–¹æ³•å¯¹åŸŸä¹‹é—´çš„å·®å¼‚éå¸¸æ•æ„Ÿï¼Œè€Œè·¨åŸŸAUæ£€æµ‹æ–¹æ³•çš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºD$^2$CAçš„è§£è€¦åŒé‡å¯¹æ¯”é€‚åº”æ–¹æ³•ï¼Œä¸“æ³¨äºå­¦ä¹ é’ˆå¯¹æºåŸŸå’Œç›®æ ‡åŸŸçš„è¯­ä¹‰å¯¹é½çš„çº¯å‡€AUè¡¨ç¤ºã€‚</li>
<li>D$^2$CAé€šè¿‡åˆ†è§£æ½œåœ¨è¡¨ç¤ºæ¥è§£è€¦AUç›¸å…³å’ŒAUä¸ç›¸å…³çš„æˆåˆ†ï¼Œä»¥ä¿ƒè¿›AUç›¸å…³å­ç©ºé—´å†…çš„é€‚é…ã€‚</li>
<li>é€šè¿‡è¯„ä¼°åœ¨è·¨åŸŸåœºæ™¯ä¸­ä¿®æ”¹AUæˆ–åŸŸå±æ€§æ—¶çš„åˆæˆé¢éƒ¨è´¨é‡æ¥è¿›è¡Œç‰¹å¾è§£è€¦è®­ç»ƒã€‚</li>
<li>D$^2$CAé‡‡ç”¨åŒé‡å¯¹æ¯”å­¦ä¹ æœºåˆ¶æ¥æé«˜ç‰¹å¾è§£è€¦çš„æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨AUæ•°æ®å¤šæ ·æ€§æœ‰é™çš„åœºæ™¯ä¸­ã€‚</li>
<li>D$^2$CAèƒ½è‡ªåŠ¨å­¦ä¹ å¹¶ä¸“é—¨åˆ†ç¦»AUç›¸å…³å’ŒåŸŸç›¸å…³çš„å› ç´ ï¼Œå®ç°å¯¹è·¨åŸŸé¢éƒ¨å›¾åƒåˆæˆçš„ç›´è§‚ã€å°ºåº¦ç‰¹å®šæ§åˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08977">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9afcb8fccd0ef98adaef3f85b788ff92.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fde0e50002a9382fde495e4a63b0f74a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-86a4d7537ff561008029f22ad14a803f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0927745f09cad12e0962b9e059306b51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a096fa10c8f42fd5f03f8c51fe4cc0f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e67b9e33068c48e920456a4eb85a4907.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65ddb79f369ca600a59a6227f48da491.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="3D-Medical-Imaging-Segmentation-on-Non-Contrast-CT"><a href="#3D-Medical-Imaging-Segmentation-on-Non-Contrast-CT" class="headerlink" title="3D Medical Imaging Segmentation on Non-Contrast CT"></a>3D Medical Imaging Segmentation on Non-Contrast CT</h2><p><strong>Authors:Canxuan Gang, Yuhan Peng</strong></p>
<p>This technical report analyzes non-contrast CT image segmentation in computer vision. It revisits a proposed method, examines the background of non-contrast CT imaging, and highlights the significance of segmentation. The study reviews representative methods, including convolutional-based and CNN-Transformer hybrid approaches, discussing their contributions, advantages, and limitations. The nnUNet stands out as the state-of-the-art method across various segmentation tasks. The report explores the relationship between the proposed method and existing approaches, emphasizing the role of global context modeling in semantic labeling and mask generation. Future directions include addressing the long-tail problem, utilizing pre-trained models for medical imaging, and exploring self-supervised or contrastive pre-training techniques. This report offers insights into non-contrast CT image segmentation and potential advancements in the field. </p>
<blockquote>
<p>è¿™ç¯‡æŠ€æœ¯æŠ¥å‘Šåˆ†æäº†è®¡ç®—æœºè§†è§‰ä¸­çš„éå¯¹æ¯”CTå›¾åƒåˆ†å‰²ï¼Œé‡æ–°å®¡è§†äº†ä¸€ç§æ–¹æ³•ï¼Œæ¢è®¨äº†éå¯¹æ¯”CTæˆåƒçš„èƒŒæ™¯ï¼Œå¹¶å¼ºè°ƒäº†åˆ†å‰²çš„é‡è¦æ€§ã€‚è¯¥ç ”ç©¶å¤ä¹ äº†ä»£è¡¨æ€§çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºå·ç§¯å’ŒCNN-Transformeræ··åˆæ–¹æ³•ï¼Œå¹¶è®¨è®ºäº†å…¶è´¡çŒ®ã€ä¼˜ç‚¹å’Œå±€é™æ€§ã€‚åœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒnnUNetè¡¨ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æŠ¥å‘Šæ¢è®¨äº†æ‰€æå‡ºæ–¹æ³•ä¸ç°æœ‰æ–¹æ³•ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶å¼ºè°ƒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡åœ¨è¯­ä¹‰æ ‡è®°å’Œè’™ç‰ˆç”Ÿæˆä¸­çš„ä½œç”¨ã€‚æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬è§£å†³é•¿å°¾é—®é¢˜ã€åˆ©ç”¨åŒ»å­¦å½±åƒçš„é¢„è®­ç»ƒæ¨¡å‹å’Œæ¢ç´¢è‡ªç›‘ç£æˆ–å¯¹æ¯”é¢„è®­ç»ƒæŠ€æœ¯ã€‚æœ¬æŠ¥å‘Šæ·±å…¥æ¢è®¨äº†éå¯¹æ¯”CTå›¾åƒåˆ†å‰²ä»¥åŠè¯¥é¢†åŸŸçš„æ½œåœ¨è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08361v1">PDF</a> tech report</p>
<p><strong>Summary</strong></p>
<p>æœ¬æŠ€æœ¯æŠ¥å‘Šæ¢è®¨äº†è®¡ç®—æœºè§†è§‰ä¸­éå¯¹æ¯”CTå›¾åƒåˆ†å‰²çš„åˆ†æã€‚æŠ¥å‘Šå›é¡¾äº†ä¸€ç§æ–¹æ³•ï¼Œä»‹ç»äº†éå¯¹æ¯”CTæˆåƒçš„èƒŒæ™¯ï¼Œå¹¶å¼ºè°ƒäº†åˆ†å‰²çš„é‡è¦æ€§ã€‚æŠ¥å‘Šè¯„è¿°äº†å…·æœ‰ä»£è¡¨æ€§çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºå·ç§¯å’ŒCNN-Transformeræ··åˆæ–¹æ³•ï¼Œå¹¶è®¨è®ºäº†å…¶è´¡çŒ®ã€ä¼˜ç‚¹å’Œå±€é™æ€§ã€‚æŠ¥å‘Šè¿˜æ¢è®¨äº†æ–°æ–¹æ³•ä¹‹é—´çš„å…³ç³»ï¼Œå¼ºè°ƒäº†å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡åœ¨è¯­ä¹‰æ ‡æ³¨å’Œæ©è†œç”Ÿæˆä¸­çš„ä½œç”¨ã€‚æœªæ¥ç ”ç©¶æ–¹å‘åŒ…æ‹¬è§£å†³é•¿å°¾é—®é¢˜ã€åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡ŒåŒ»å­¦å½±åƒåˆ†æä»¥åŠæ¢ç´¢è‡ªç›‘ç£æˆ–å¯¹æ¯”é¢„è®­ç»ƒæŠ€æœ¯ã€‚æœ¬æŠ¥å‘Šä¸ºæ·±å…¥äº†è§£éå¯¹æ¯”CTå›¾åƒåˆ†å‰²ä»¥åŠè¯¥é¢†åŸŸçš„æ½œåœ¨è¿›å±•æä¾›äº†å®è´µè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æŠ¥å‘Šè¯¦ç»†åˆ†æäº†éå¯¹æ¯”CTå›¾åƒåˆ†å‰²åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>ä»‹ç»äº†éå¯¹æ¯”CTæˆåƒçš„èƒŒæ™¯ï¼Œå¹¶å›é¡¾äº†ç°æœ‰æ–¹æ³•çš„èƒŒæ™¯ã€‚</li>
<li>è¯„è¿°äº†åŸºäºå·ç§¯å’ŒCNN-Transformeræ··åˆæ–¹æ³•çš„ä»£è¡¨æ€§æ–¹æ³•ã€‚</li>
<li>nnUNetåœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</li>
<li>å¼ºè°ƒäº†å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡åœ¨è¯­ä¹‰æ ‡æ³¨å’Œæ©è†œç”Ÿæˆä¸­çš„å…³é”®ä½œç”¨ã€‚</li>
<li>æå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ï¼ŒåŒ…æ‹¬è§£å†³é•¿å°¾é—®é¢˜ã€åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠæ¢ç´¢è‡ªç›‘ç£æˆ–å¯¹æ¯”é¢„è®­ç»ƒæŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08361">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c8c339d9496569be030dc65331a3db6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68b7cf1b5231ff534378cd434c4810e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-584c5d8d58123ad243a473d1751b1daf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-87f4aabcc84df688423216c137bf41f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8921296df911b7fd947e30334e6d8ffb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CL-MVSNet-Unsupervised-Multi-view-Stereo-with-Dual-level-Contrastive-Learning"><a href="#CL-MVSNet-Unsupervised-Multi-view-Stereo-with-Dual-level-Contrastive-Learning" class="headerlink" title="CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive   Learning"></a>CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive   Learning</h2><p><strong>Authors:Kaiqiang Xiong, Rui Peng, Zhe Zhang, Tianxing Feng, Jianbo Jiao, Feng Gao, Ronggang Wang</strong></p>
<p>Unsupervised Multi-View Stereo (MVS) methods have achieved promising progress recently. However, previous methods primarily depend on the photometric consistency assumption, which may suffer from two limitations: indistinguishable regions and view-dependent effects, e.g., low-textured areas and reflections. To address these issues, in this paper, we propose a new dual-level contrastive learning approach, named CL-MVSNet. Specifically, our model integrates two contrastive branches into an unsupervised MVS framework to construct additional supervisory signals. On the one hand, we present an image-level contrastive branch to guide the model to acquire more context awareness, thus leading to more complete depth estimation in indistinguishable regions. On the other hand, we exploit a scene-level contrastive branch to boost the representation ability, improving robustness to view-dependent effects. Moreover, to recover more accurate 3D geometry, we introduce an L0.5 photometric consistency loss, which encourages the model to focus more on accurate points while mitigating the gradient penalty of undesirable ones. Extensive experiments on DTU and Tanks&amp;Temples benchmarks demonstrate that our approach achieves state-of-the-art performance among all end-to-end unsupervised MVS frameworks and outperforms its supervised counterpart by a considerable margin without fine-tuning. </p>
<blockquote>
<p>æ— ç›‘ç£å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•æœ€è¿‘å–å¾—äº†æœ‰å¸Œæœ›çš„è¿›å±•ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºå…‰åº¦ä¸€è‡´æ€§å‡è®¾ï¼Œè¿™å¯èƒ½ä¼šé¢ä¸´ä¸¤ä¸ªå±€é™æ€§ï¼šä¸å¯åŒºåˆ†åŒºåŸŸå’Œè§†å›¾ç›¸å…³æ•ˆåº”ï¼Œä¾‹å¦‚ä½çº¹ç†åŒºåŸŸå’Œåå°„ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŒçº§å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œåä¸ºCL-MVSNetã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°†ä¸¤ä¸ªå¯¹æ¯”åˆ†æ”¯é›†æˆåˆ°æ— ç›‘ç£MVSæ¡†æ¶ä¸­ï¼Œä»¥æ„å»ºé¢å¤–çš„ç›‘ç£ä¿¡å·ã€‚ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå›¾åƒçº§å¯¹æ¯”åˆ†æ”¯ï¼Œä»¥æŒ‡å¯¼æ¨¡å‹è·å–æ›´å¤šçš„ä¸Šä¸‹æ–‡æ„è¯†ï¼Œä»è€Œå¯¼è‡´ä¸å¯åŒºåˆ†åŒºåŸŸä¸­æ›´å®Œæ•´çš„æ·±åº¦ä¼°è®¡ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬åˆ©ç”¨åœºæ™¯çº§å¯¹æ¯”åˆ†æ”¯æ¥æé«˜è¡¨ç¤ºèƒ½åŠ›ï¼Œå¢å¼ºå¯¹è§†å›¾ç›¸å…³æ•ˆåº”çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ¢å¤æ›´å‡†ç¡®çš„3Då‡ ä½•ç»“æ„ï¼Œæˆ‘ä»¬å¼•å…¥äº†L0.5å…‰åº¦ä¸€è‡´æ€§æŸå¤±ï¼Œè¿™é¼“åŠ±æ¨¡å‹æ›´å¤šåœ°å…³æ³¨å‡†ç¡®ç‚¹ï¼ŒåŒæ—¶å‡è½»ä¸ç†æƒ³ç‚¹çš„æ¢¯åº¦æƒ©ç½šã€‚åœ¨DTUå’ŒTanks&amp;TemplesåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç«¯åˆ°ç«¯çš„æ— ç›‘ç£MVSæ¡†æ¶ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨æœªç»å¾®è°ƒçš„æƒ…å†µä¸‹å¤§å¹…è¶…è¶Šäº†å…¶æœ‰ç›‘ç£çš„åŒç±»äº§å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08219v1">PDF</a> Accpetd by ICCV2023</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•ï¼Œåä¸ºCL-MVSNetã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥å›¾åƒçº§å’Œåœºæ™¯çº§çš„å¯¹æ¯”å­¦ä¹ åˆ†æ”¯ï¼Œå¢å¼ºäº†æ¨¡å‹çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›å’Œè¡¨å¾èƒ½åŠ›ï¼Œä»è€Œæé«˜äº†åœ¨åŒºåˆ†ä¸æ˜æ˜¾åŒºåŸŸå’Œå—è§†è§’å½±å“åŒºåŸŸçš„é²æ£’æ€§ã€‚åŒæ—¶ï¼Œé€šè¿‡å¼•å…¥L0.5å…‰åº¦ä¸€è‡´æ€§æŸå¤±ï¼Œæ¢å¤äº†æ›´å‡†ç¡®çš„3Då‡ ä½•ç»“æ„ã€‚åœ¨DTUå’ŒTanks&amp;TemplesåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç«¯åˆ°ç«¯çš„æ— ç›‘ç£MVSæ¡†æ¶ä¸­è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶ä¸”åœ¨æ²¡æœ‰å¾®è°ƒçš„æƒ…å†µä¸‹æ˜¾è‘—è¶…è¶Šäº†å…¶æœ‰ç›‘ç£çš„åŒç±»æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CL-MVSNetæ˜¯ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥å›¾åƒçº§å¯¹æ¯”å­¦ä¹ åˆ†æ”¯ï¼Œæé«˜äº†æ¨¡å‹åœ¨åŒºåˆ†ä¸æ˜æ˜¾åŒºåŸŸçš„æ·±åº¦ä¼°è®¡çš„å®Œæ•´æ€§ã€‚</li>
<li>é€šè¿‡å¼•å…¥åœºæ™¯çº§å¯¹æ¯”å­¦ä¹ åˆ†æ”¯ï¼Œå¢å¼ºäº†æ¨¡å‹çš„è¡¨å¾èƒ½åŠ›ï¼Œæé«˜äº†å¯¹å—è§†è§’å½±å“åŒºåŸŸçš„é²æ£’æ€§ã€‚</li>
<li>L0.5å…‰åº¦ä¸€è‡´æ€§æŸå¤±çš„å¼•å…¥æœ‰åŠ©äºæ¢å¤æ›´å‡†ç¡®çš„3Då‡ ä½•ç»“æ„ã€‚</li>
<li>åœ¨DTUå’ŒTanks&amp;TemplesåŸºå‡†æµ‹è¯•ä¸Šï¼ŒCL-MVSNetè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ— ç›‘ç£ç¯å¢ƒä¸‹æ˜¾è‘—è¶…è¶Šäº†å…¶æœ‰ç›‘ç£çš„åŒç±»æ–¹æ³•ï¼Œä¸”æ— éœ€å¾®è°ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08219">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0202b5da4492440582ae96c7fb61e1b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a258a032cad63ba0aeb9eb3f83f6fc31.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9ef2eb2c45b1ea1d54795317a8a4864.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8bafc71528abaf967740bf809df746b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7c33fb7856e862f3847be2e942f4c1d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="X2CT-CLIP-Enable-Multi-Abnormality-Detection-in-Computed-Tomography-from-Chest-Radiography-via-Tri-Modal-Contrastive-Learning"><a href="#X2CT-CLIP-Enable-Multi-Abnormality-Detection-in-Computed-Tomography-from-Chest-Radiography-via-Tri-Modal-Contrastive-Learning" class="headerlink" title="X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography   from Chest Radiography via Tri-Modal Contrastive Learning"></a>X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography   from Chest Radiography via Tri-Modal Contrastive Learning</h2><p><strong>Authors:Jianzhong You, Yuan Gao, Sangwook Kim, Chris Mcintosh</strong></p>
<p>Computed tomography (CT) is a key imaging modality for diagnosis, yet its clinical utility is marred by high radiation exposure and long turnaround times, restricting its use for larger-scale screening. Although chest radiography (CXR) is more accessible and safer, existing CXR foundation models focus primarily on detecting diseases that are readily visible on the CXR. Recently, works have explored training disease classification models on simulated CXRs, but they remain limited to recognizing a single disease type from CT. CT foundation models have also emerged with significantly improved detection of pathologies in CT. However, the generalized application of CT-derived labels on CXR has remained illusive. In this study, we propose X2CT-CLIP, a tri-modal knowledge transfer learning framework that bridges the modality gap between CT and CXR while reducing the computational burden of model training. Our approach is the first work to enable multi-abnormality classification in CT, using CXR, by transferring knowledge from 3D CT volumes and associated radiology reports to a CXR encoder via a carefully designed tri-modal alignment mechanism in latent space. Extensive evaluations on three multi-label CT datasets demonstrate that our method outperforms state-of-the-art baselines in cross-modal retrieval, few-shot adaptation, and external validation. These results highlight the potential of CXR, enriched with knowledge derived from CT, as a viable efficient alternative for disease detection in resource-limited settings. </p>
<blockquote>
<p>è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰æ˜¯è¯Šæ–­çš„å…³é”®æˆåƒæ–¹å¼ï¼Œä½†å…¶ä¸´åºŠåº”ç”¨å—åˆ°é«˜è¾å°„æš´éœ²å’Œé•¿æ—¶é—´å¤„ç†æ—¶é—´çš„é™åˆ¶ï¼Œé™åˆ¶äº†å…¶åœ¨å¤§è§„æ¨¡ç­›æŸ¥ä¸­çš„ä½¿ç”¨ã€‚è™½ç„¶èƒ¸éƒ¨æ”¾å°„æ‘„å½±ï¼ˆCXRï¼‰æ›´å®¹æ˜“è·å–ä¸”æ›´å®‰å…¨ï¼Œä½†ç°æœ‰çš„CXRåŸºç¡€æ¨¡å‹ä¸»è¦å…³æ³¨åœ¨CXRä¸Šæ˜“äºè§‚å¯Ÿåˆ°çš„ç–¾ç—…æ£€æµ‹ã€‚æœ€è¿‘ï¼Œå·²æœ‰ç ”ç©¶å¼€å§‹æ¢ç´¢åœ¨æ¨¡æ‹Ÿçš„CXRä¸Šè¿›è¡Œç–¾ç—…åˆ†ç±»æ¨¡å‹è®­ç»ƒï¼Œä½†å®ƒä»¬ä»…é™äºä»CTå›¾åƒä¸­è¯†åˆ«å•ä¸€ç–¾ç—…ç±»å‹ã€‚ä¹Ÿå‡ºç°äº†åŸºäºCTçš„åŸºç¡€æ¨¡å‹ï¼Œä»¥æ˜¾è‘—æ”¹å–„CTä¸­çš„ç—…ç†æ£€æµ‹ã€‚ç„¶è€Œï¼Œå°†CTè¡ç”Ÿçš„æ ‡ç­¾æ¨å¹¿åˆ°CXRçš„é€šç”¨åº”ç”¨ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†X2CT-CLIPï¼Œè¿™æ˜¯ä¸€ä¸ªä¸‰æ¨¡æ€çŸ¥è¯†è¿ç§»å­¦ä¹ æ¡†æ¶ï¼Œå®ƒç¼©å°äº†CTå’ŒCXRä¹‹é—´çš„æ¨¡æ€å·®è·ï¼ŒåŒæ—¶é™ä½äº†æ¨¡å‹è®­ç»ƒçš„è®¡ç®—è´Ÿæ‹…ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¯é€šè¿‡ä»3D CTä½“ç§¯å’Œç›¸å…³æ”¾å°„å­¦æŠ¥å‘Šè½¬ç§»çŸ¥è¯†åˆ°CXRç¼–ç å™¨ï¼Œåˆ©ç”¨ç²¾å¿ƒè®¾è®¡çš„æ½œåœ¨ç©ºé—´ä¸­çš„ä¸‰æ¨¡æ€å¯¹é½æœºåˆ¶ï¼Œå®ç°äº†ä½¿ç”¨CXRåœ¨CTä¸Šè¿›è¡Œå¤šå¼‚å¸¸åˆ†ç±»çš„é¦–é¡¹å·¥ä½œã€‚åœ¨ä¸‰ä¸ªå¤šæ ‡ç­¾CTæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è·¨æ¨¡æ€æ£€ç´¢ã€å°‘æ ·æœ¬é€‚åº”å’Œå¤–éƒ¨éªŒè¯æ–¹é¢å‡ä¼˜äºæœ€æ–°åŸºçº¿ã€‚è¿™äº›ç»“æœçªæ˜¾äº†CXRçš„æ½œåŠ›ï¼Œé€šè¿‡ä»CTä¸­è·å–çŸ¥è¯†ï¼Œå¯ä½œä¸ºèµ„æºæœ‰é™ç¯å¢ƒä¸­ç–¾ç—…æ£€æµ‹çš„å¯è¡Œé«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02162v2">PDF</a> 11 pages, 1 figure, 5 tables</p>
<p><strong>Summary</strong></p>
<p>è¯¥ç ”ç©¶è¡¨æ˜ï¼Œé’ˆå¯¹è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰å’Œèƒ¸éƒ¨æ”¾å°„çº¿æ£€æŸ¥ï¼ˆCXRï¼‰çš„åŒæ¨¡æ€çŸ¥è¯†è¿ç§»å­¦ä¹ æ¡†æ¶è¢«æå‡ºï¼Œç”¨ä»¥è§£å†³CTæ£€æŸ¥çš„é«˜è¾å°„æš´éœ²å’Œé•¿æ—¶é—´ç­‰å¾…ç»“æœçš„é—®é¢˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•X2CT-CLIPï¼Œè¯¥æ–¹æ³•é€šè¿‡ç²¾å¿ƒè®¾è®¡ä¸‰æ¨¡æ€å¯¹é½æœºåˆ¶ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­å®ç°äº†ä»CTä½“ç§¯å’Œç›¸å…³çš„æ”¾å°„å­¦æŠ¥å‘Šå‘CXRç¼–ç å™¨çš„çŸ¥è¯†è¿ç§»ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šæ ‡ç­¾CTæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå…·æœ‰è·¨æ¨¡æ€æ£€ç´¢ã€å°‘æ ·æœ¬é€‚åº”å’Œå¤–éƒ¨éªŒè¯çš„æ½œåŠ›ã€‚è¿™æ ‡å¿—ç€ä½¿ç”¨CXRç»“åˆä»CTä¸­è·å¾—çš„çŸ¥è¯†åœ¨èµ„æºå—é™ç¯å¢ƒä¸­è¿›è¡Œç–¾ç—…æ£€æµ‹çš„ä¸€ç§é«˜æ•ˆå¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥ç ”ç©¶æå‡ºäº†X2CT-CLIPæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³CTæ£€æŸ¥çš„é«˜è¾å°„å’Œé•¿æ—¶é—´ç­‰å¾…é—®é¢˜ã€‚</li>
<li>X2CT-CLIPæ˜¯ä¸€ä¸ªä¸‰æ¨¡æ€çŸ¥è¯†è¿ç§»å­¦ä¹ æ¡†æ¶ï¼Œå¯ä»¥ç¼©çŸ­æ¨¡å‹è®­ç»ƒçš„è®¡ç®—è´Ÿæ‹…ã€‚</li>
<li>è¯¥æ–¹æ³•é¦–æ¬¡å®ç°äº†ä½¿ç”¨CXRè¿›è¡Œå¤šå¼‚å¸¸æ€§åˆ†ç±»çš„CTæŠ€æœ¯ã€‚</li>
<li>é€šè¿‡ç²¾å¿ƒè®¾è®¡ä¸‰æ¨¡æ€å¯¹é½æœºåˆ¶ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­å®ç°äº†ä»CTä½“ç§¯å’Œç›¸å…³æ”¾å°„å­¦æŠ¥å‘Šå‘CXRç¼–ç å™¨çš„çŸ¥è¯†è¿ç§»ã€‚</li>
<li>åœ¨å¤šæ ‡ç­¾CTæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒX2CT-CLIPåœ¨è·¨æ¨¡æ€æ£€ç´¢ã€å°‘æ ·æœ¬é€‚åº”å’Œå¤–éƒ¨éªŒè¯æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>ç ”ç©¶ç»“æœå¼ºè°ƒäº†ç»“åˆCXRå’Œä»CTè·å¾—çš„çŸ¥è¯†åœ¨èµ„æºå—é™ç¯å¢ƒä¸­è¿›è¡Œç–¾ç—…æ£€æµ‹çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02162">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e52ed559bd34ca0791e6fd0e6f0095f4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ca5a9fd9eb9e82ba594ec13d430ba23b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2fb5dcf0b66a8a6fae22c18927754faf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d730010f2b7ee6dc2a7be69f95cffd32.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-14/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-14/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-14/Speech/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4ab6d35773e0ca0121eba9370d764c97.jpg" class="responsive-img" alt="Speech">
                        
                        <span class="card-title">Speech</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-14  Everything Can Be Described in Words A Simple Unified Multi-Modal   Framework with Semantic and Temporal Alignment
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                    Speech
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Speech/">
                        <span class="chip bg-color">Speech</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-14/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-85496aa7a0b91d2d83ea6d5050f46013.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-14  Dual-Domain Homogeneous Fusion with Cross-Modal Mamba and Progressive   Decoder for 3D Object Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26522.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
