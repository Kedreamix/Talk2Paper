<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-14  Online Language Splatting">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-778f400c1a06e4db61020fa8ec25ea30.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    76 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-14-æ›´æ–°"><a href="#2025-03-14-æ›´æ–°" class="headerlink" title="2025-03-14 æ›´æ–°"></a>2025-03-14 æ›´æ–°</h1><h2 id="Online-Language-Splatting"><a href="#Online-Language-Splatting" class="headerlink" title="Online Language Splatting"></a>Online Language Splatting</h2><p><strong>Authors:Saimouli Katragadda, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Guoquan Huang, Liu Ren</strong></p>
<p>To enable AI agents to interact seamlessly with both humans and 3D environments, they must not only perceive the 3D world accurately but also align human language with 3D spatial representations. While prior work has made significant progress by integrating language features into geometrically detailed 3D scene representations using 3D Gaussian Splatting (GS), these approaches rely on computationally intensive offline preprocessing of language features for each input image, limiting adaptability to new environments. In this work, we introduce Online Language Splatting, the first framework to achieve online, near real-time, open-vocabulary language mapping within a 3DGS-SLAM system without requiring pre-generated language features. The key challenge lies in efficiently fusing high-dimensional language features into 3D representations while balancing the computation speed, memory usage, rendering quality and open-vocabulary capability. To this end, we innovatively design: (1) a high-resolution CLIP embedding module capable of generating detailed language feature maps in 18ms per frame, (2) a two-stage online auto-encoder that compresses 768-dimensional CLIP features to 15 dimensions while preserving open-vocabulary capabilities, and (3) a color-language disentangled optimization approach to improve rendering quality. Experimental results show that our online method not only surpasses the state-of-the-art offline methods in accuracy but also achieves more than 40x efficiency boost, demonstrating the potential for dynamic and interactive AI applications. </p>
<blockquote>
<p>ä¸ºäº†å®ç°äººå·¥æ™ºèƒ½ä»£ç†æ— ç¼åœ°ä¸äººç±»å’Œä¸‰ç»´ç¯å¢ƒè¿›è¡Œäº¤äº’ï¼Œå®ƒä»¬ä¸ä»…éœ€è¦å‡†ç¡®æ„ŸçŸ¥ä¸‰ç»´ä¸–ç•Œï¼Œè¿˜éœ€è¦å°†äººç±»è¯­è¨€ä¸ä¸‰ç»´ç©ºé—´è¡¨ç¤ºå¯¹é½ã€‚å°½ç®¡å…ˆå‰çš„å°è¯•é€šè¿‡å°†è¯­è¨€ç‰¹å¾æ•´åˆåˆ°å…·æœ‰å‡ ä½•ç»†èŠ‚çš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºä¸­ï¼Œä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆGSï¼‰å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†è¿™äº›æ–¹æ³•ä¾èµ–äºé’ˆå¯¹æ¯ä¸ªè¾“å…¥å›¾åƒçš„å¯†é›†è®¡ç®—ç¦»çº¿é¢„å¤„ç†è¯­è¨€ç‰¹å¾ï¼Œå¯¹æ–°ç¯å¢ƒçš„é€‚åº”æ€§æœ‰é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†åœ¨çº¿è¯­è¨€æ‹¼è´´æŠ€æœ¯ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå®ç°åœ¨çº¿ã€æ¥è¿‘å®æ—¶çš„ä¸‰ç»´å‡ ä½•ç©ºé—´ç³»ç»Ÿï¼ˆ3DGSï¼‰å†…çš„å¼€æ”¾è¯æ±‡è¯­è¨€æ˜ å°„çš„æ¡†æ¶ï¼Œæ— éœ€é¢„å…ˆç”Ÿæˆçš„è¯­è¨€ç‰¹å¾ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºå¦‚ä½•å°†é«˜ç»´è¯­è¨€ç‰¹å¾æœ‰æ•ˆåœ°èåˆåˆ°ä¸‰ç»´è¡¨ç¤ºä¸­ï¼ŒåŒæ—¶å¹³è¡¡è®¡ç®—é€Ÿåº¦ã€å†…å­˜ä½¿ç”¨ã€æ¸²æŸ“è´¨é‡å’Œå¼€æ”¾è¯æ±‡èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ›æ–°åœ°è®¾è®¡äº†ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªé«˜åˆ†è¾¨ç‡CLIPåµŒå…¥æ¨¡å—ï¼Œèƒ½å¤Ÿåœ¨æ¯å¸§å†…ä»¥18æ¯«ç§’çš„é€Ÿåº¦ç”Ÿæˆè¯¦ç»†çš„è¯­éŸ³ç‰¹å¾å›¾ï¼›ï¼ˆ2ï¼‰ä¸€ä¸ªä¸¤é˜¶æ®µåœ¨çº¿è‡ªç¼–ç å™¨ï¼Œèƒ½å°†CLIPç‰¹å¾çš„ç»´åº¦ä»768å‹ç¼©åˆ°15ä¸ªç»´åº¦åŒæ—¶ä¿ç•™å¼€æ”¾è¯æ±‡åŠŸèƒ½ï¼›ï¼ˆ3ï¼‰ä¸€ç§è‰²å½©ä¸è¯­è¨€åˆ†ç¦»çš„ä¼˜åŒ–æ–¹æ³•ä»¥æé«˜æ¸²æŸ“è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åœ¨çº¿æ–¹æ³•ä¸ä»…è¶…è¶Šäº†æœ€æ–°ç¦»çº¿æ–¹æ³•çš„å‡†ç¡®æ€§ï¼Œè¿˜å®ç°äº†è¶…è¿‡40å€çš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ¨æ€å’Œäº¤äº’å¼äººå·¥æ™ºèƒ½åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09447v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åœ¨çº¿è¯­è¨€æ˜ å°„æ¡†æ¶ï¼Œåä¸ºåœ¨çº¿è¯­è¨€å–·ç»˜ï¼Œèƒ½å¤Ÿåœ¨3DGS-SLAMç³»ç»Ÿå†…å®ç°è¿‘å®æ—¶çš„å¼€æ”¾è¯æ±‡è¯­è¨€æ˜ å°„ï¼Œè€Œæ— éœ€é¢„å…ˆç”Ÿæˆè¯­è¨€ç‰¹å¾ã€‚é€šè¿‡è®¾è®¡é«˜æ•ˆçš„CLIPåµŒå…¥æ¨¡å—ã€ä¸¤é˜¶æ®µåœ¨çº¿è‡ªåŠ¨ç¼–ç å™¨åŠé¢œè‰²è¯­è¨€åˆ†ç¦»ä¼˜åŒ–æ–¹æ³•ï¼Œå®ç°äº†é«˜ç»´è¯­è¨€ç‰¹å¾åœ¨3Dç¯å¢ƒä¸­çš„é«˜æ•ˆèåˆï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡å’Œå¼€æ”¾è¯æ±‡èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†AIäº¤äº’çš„æ™ºèƒ½å’Œæ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ¨çº¿è¯­è¨€å–·ç»˜æ¡†æ¶å®ç°äº†åœ¨3DGS-SLAMç³»ç»Ÿä¸­çš„åœ¨çº¿ã€è¿‘å®æ—¶çš„å¼€æ”¾è¯æ±‡è¯­è¨€æ˜ å°„ã€‚</li>
<li>é«˜æ•ˆèåˆé«˜ç»´è¯­è¨€ç‰¹å¾åˆ°3Dç¯å¢ƒï¼Œæå‡äº†AIçš„æ™ºèƒ½äº¤äº’èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡è®¾è®¡é«˜åˆ†è¾¨ç‡CLIPåµŒå…¥æ¨¡å—ï¼Œç”Ÿæˆè¯¦ç»†çš„è¯­è¨€ç‰¹å¾å›¾ã€‚</li>
<li>ä¸¤é˜¶æ®µåœ¨çº¿è‡ªåŠ¨ç¼–ç å™¨å‹ç¼©äº†é«˜ç»´CLIPç‰¹å¾ï¼ŒåŒæ—¶ä¿æŒå¼€æ”¾è¯æ±‡èƒ½åŠ›ã€‚</li>
<li>é¢œè‰²è¯­è¨€åˆ†ç¦»ä¼˜åŒ–æ–¹æ³•æé«˜äº†æ¸²æŸ“è´¨é‡ã€‚</li>
<li>åœ¨çº¿æ–¹æ³•ä¸ä»…åœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šç°æœ‰ç¦»çº¿æ–¹æ³•ï¼Œè€Œä¸”å®ç°äº†è¶…è¿‡40å€çš„æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09447">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-99f34e5e34a14da63fb34bf8215a55bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae1e1dcc05d7202068cf86f8a94347ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-acda1676b19e331b10fb4691a9d13b91.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff505735b63d4dd6ca7fd257d5b5e13e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ee20a4e05c590d68aad13b0ecaf59d8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SDD-4DGS-Static-Dynamic-Aware-Decoupling-in-Gaussian-Splatting-for-4D-Scene-Reconstruction"><a href="#SDD-4DGS-Static-Dynamic-Aware-Decoupling-in-Gaussian-Splatting-for-4D-Scene-Reconstruction" class="headerlink" title="SDD-4DGS: Static-Dynamic Aware Decoupling in Gaussian Splatting for 4D   Scene Reconstruction"></a>SDD-4DGS: Static-Dynamic Aware Decoupling in Gaussian Splatting for 4D   Scene Reconstruction</h2><p><strong>Authors:Dai Sun, Huhao Guan, Kun Zhang, Xike Xie, S. Kevin Zhou</strong></p>
<p>Dynamic and static components in scenes often exhibit distinct properties, yet most 4D reconstruction methods treat them indiscriminately, leading to suboptimal performance in both cases. This work introduces SDD-4DGS, the first framework for static-dynamic decoupled 4D scene reconstruction based on Gaussian Splatting. Our approach is built upon a novel probabilistic dynamic perception coefficient that is naturally integrated into the Gaussian reconstruction pipeline, enabling adaptive separation of static and dynamic components. With carefully designed implementation strategies to realize this theoretical framework, our method effectively facilitates explicit learning of motion patterns for dynamic elements while maintaining geometric stability for static structures. Extensive experiments on five benchmark datasets demonstrate that SDD-4DGS consistently outperforms state-of-the-art methods in reconstruction fidelity, with enhanced detail restoration for static structures and precise modeling of dynamic motions. The code will be released. </p>
<blockquote>
<p>åœºæ™¯ä¸­çš„åŠ¨æ€å’Œé™æ€ç»„ä»¶é€šå¸¸è¡¨ç°å‡ºä¸åŒçš„å±æ€§ï¼Œç„¶è€Œå¤§å¤šæ•°4Dé‡å»ºæ–¹æ³•éƒ½æ˜¯ä¸åŠ åŒºåˆ†åœ°å¯¹å¾…å®ƒä»¬ï¼Œå¯¼è‡´ä¸¤ç§æƒ…å†µä¸‹çš„æ€§èƒ½éƒ½ä¸ä½³ã€‚è¿™é¡¹å·¥ä½œå¼•å…¥äº†SDD-4DGSï¼Œè¿™æ˜¯åŸºäºé«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„é™æ€-åŠ¨æ€è§£è€¦4Dåœºæ™¯é‡å»ºçš„ç¬¬ä¸€ä¸ªæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨æ–°å‹çš„æ¦‚ç‡åŠ¨æ€æ„ŸçŸ¥ç³»æ•°ä¸Šï¼Œè¯¥ç³»æ•°è‡ªç„¶åœ°èå…¥åˆ°é«˜æ–¯é‡å»ºæµç¨‹ä¸­ï¼Œèƒ½å¤Ÿå®ç°é™æ€å’ŒåŠ¨æ€ç»„ä»¶çš„è‡ªé€‚åº”åˆ†ç¦»ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å®ç°ç­–ç•¥æ¥å®ç°è¿™ä¸€ç†è®ºæ¡†æ¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°ä¿ƒè¿›äº†åŠ¨æ€å…ƒç´ çš„è¿åŠ¨æ¨¡å¼çš„å­¦ä¹ ï¼ŒåŒæ—¶ä¿æŒé™æ€ç»“æ„çš„å‡ ä½•ç¨³å®šæ€§ã€‚åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSDD-4DGSåœ¨é‡å»ºä¿çœŸåº¦æ–¹é¢å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºé™æ€ç»“æ„æä¾›äº†å¢å¼ºçš„ç»†èŠ‚æ¢å¤å’ŒåŠ¨æ€è¿åŠ¨çš„ç²¾ç¡®å»ºæ¨¡ã€‚ä»£ç å°†å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09332v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†SDD-4DGSï¼Œä¸€ä¸ªåŸºäºé«˜æ–¯å±•å¸ƒçš„é™æ€åŠ¨æ€è§£è€¦4Dåœºæ™¯é‡å»ºæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªç„¶é›†æˆæ–°å‹æ¦‚ç‡åŠ¨æ€æ„ŸçŸ¥ç³»æ•°ï¼Œå®ç°äº†é™æ€å’ŒåŠ¨æ€ç»„ä»¶çš„è‡ªé€‚åº”åˆ†ç¦»ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å®ç°ç­–ç•¥ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå­¦ä¹ åŠ¨æ€å…ƒç´ çš„è¿åŠ¨æ¨¡å¼ï¼ŒåŒæ—¶ä¿æŒé™æ€ç»“æ„çš„å‡ ä½•ç¨³å®šæ€§ã€‚åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSDD-4DGSåœ¨é‡å»ºä¿çœŸåº¦ä¸Šå§‹ç»ˆä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œå¯¹é™æ€ç»“æ„çš„ç»†èŠ‚æ¢å¤å¢å¼ºï¼Œå¯¹åŠ¨æ€è¿åŠ¨çš„å»ºæ¨¡ç²¾ç¡®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SDD-4DGSæ˜¯é¦–ä¸ªé’ˆå¯¹é™æ€åŠ¨æ€è§£è€¦çš„4Dåœºæ™¯é‡å»ºæ¡†æ¶ã€‚</li>
<li>è¯¥æ–¹æ³•åŸºäºé«˜æ–¯å±•å¸ƒï¼Œé€šè¿‡è‡ªç„¶é›†æˆæ¦‚ç‡åŠ¨æ€æ„ŸçŸ¥ç³»æ•°ï¼Œå®ç°é™æ€å’ŒåŠ¨æ€ç»„ä»¶çš„è‡ªé€‚åº”åˆ†ç¦»ã€‚</li>
<li>ç²¾å¿ƒè®¾è®¡çš„å®ç°ç­–ç•¥ï¼Œä½¿å¾—æ–¹æ³•èƒ½æœ‰æ•ˆå­¦ä¹ åŠ¨æ€å…ƒç´ çš„è¿åŠ¨æ¨¡å¼ï¼ŒåŒæ—¶ä¿æŒé™æ€ç»“æ„çš„å‡ ä½•ç¨³å®šæ€§ã€‚</li>
<li>åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜SDD-4DGSæ€§èƒ½ä¼˜è¶Šã€‚</li>
<li>SDD-4DGSåœ¨é‡å»ºä¿çœŸåº¦ä¸Šä¼˜äºç°æœ‰æœ€æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å¢å¼ºäº†é™æ€ç»“æ„çš„ç»†èŠ‚æ¢å¤å’ŒåŠ¨æ€è¿åŠ¨çš„å»ºæ¨¡ç²¾ç¡®æ€§ã€‚</li>
<li>ä»£ç å°†ä¼šå…¬å¼€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a13d06d205e14733cd8a2fedc1b71a9b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3c6c88bbb281579804165205a46882a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42532f0b15259090b3e4fa29380c2fce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4d7b26fc3948b43b74acea923c6fe88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa573661d6ca51fba06316d9fe7c7042.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dd067071bab82f59698885e3beae6e38.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fcfb2005d5325d2718a7e4b720e93b1b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Better-Together-Unified-Motion-Capture-and-3D-Avatar-Reconstruction"><a href="#Better-Together-Unified-Motion-Capture-and-3D-Avatar-Reconstruction" class="headerlink" title="Better Together: Unified Motion Capture and 3D Avatar Reconstruction"></a>Better Together: Unified Motion Capture and 3D Avatar Reconstruction</h2><p><strong>Authors:Arthur Moreau, Mohammed Brahimi, Richard Shaw, Athanasios Papaioannou, Thomas Tanay, Zhensong Zhang, Eduardo PÃ©rez-Pellitero</strong></p>
<p>We present Better Together, a method that simultaneously solves the human pose estimation problem while reconstructing a photorealistic 3D human avatar from multi-view videos. While prior art usually solves these problems separately, we argue that joint optimization of skeletal motion with a 3D renderable body model brings synergistic effects, i.e. yields more precise motion capture and improved visual quality of real-time rendering of avatars. To achieve this, we introduce a novel animatable avatar with 3D Gaussians rigged on a personalized mesh and propose to optimize the motion sequence with time-dependent MLPs that provide accurate and temporally consistent pose estimates. We first evaluate our method on highly challenging yoga poses and demonstrate state-of-the-art accuracy on multi-view human pose estimation, reducing error by 35% on body joints and 45% on hand joints compared to keypoint-based methods. At the same time, our method significantly boosts the visual quality of animatable avatars (+2dB PSNR on novel view synthesis) on diverse challenging subjects. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºâ€œBetter Togetherâ€çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶è§£å†³äººä½“å§¿æ€ä¼°è®¡é—®é¢˜ï¼Œå¹¶ä»å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºå‡ºé€¼çœŸçš„3Däººä½“åŒ–èº«ã€‚è™½ç„¶å…ˆå‰çš„ç ”ç©¶é€šå¸¸åˆ†åˆ«è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œä½†æˆ‘ä»¬ä¸»å¼ ï¼Œå¯¹éª¨éª¼è¿åŠ¨ä¸3Då¯æ¸²æŸ“èº«ä½“æ¨¡å‹è¿›è¡Œè”åˆä¼˜åŒ–å¯ä»¥äº§ç”ŸååŒæ•ˆåº”ï¼Œå³å¯ä»¥è·å¾—æ›´ç²¾ç¡®çš„åŠ¨ä½œæ•æ‰å’Œå®æ—¶æ¸²æŸ“åŒ–èº«æ—¶æé«˜çš„è§†è§‰è´¨é‡ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹åŠ¨ç”»åŒ–èº«ï¼Œå®ƒåœ¨ä¸ªæ€§åŒ–ç½‘æ ¼ä¸Šé…å¤‡äº†3Dé«˜æ–¯æ¨¡å‹ï¼Œå¹¶æå‡ºä½¿ç”¨æ—¶é—´ç›¸å…³çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPsï¼‰æ¥ä¼˜åŒ–è¿åŠ¨åºåˆ—ï¼Œä»¥æä¾›å‡†ç¡®ä¸”æ—¶é—´ä¸€è‡´çš„å§¿æ€ä¼°è®¡ã€‚æˆ‘ä»¬é¦–å…ˆå¯¹æˆ‘ä»¬çš„æ–¹æ³•è¿›è¡Œäº†å…·æœ‰æŒ‘æˆ˜æ€§çš„ç‘œä¼½åŠ¨ä½œè¯„ä¼°ï¼Œå¹¶å±•ç¤ºäº†åœ¨å¤šè§†è§’äººä½“å§¿æ€ä¼°è®¡æ–¹é¢çš„æœ€æ–°æŠ€æœ¯å‡†ç¡®æ€§ã€‚ä¸åŸºäºå…³é”®ç‚¹çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨èº«ä½“å…³èŠ‚ä¸Šå‡å°‘äº†35%çš„é”™è¯¯ï¼Œåœ¨æ‰‹éƒ¨å…³èŠ‚ä¸Šå‡å°‘äº†45%çš„é”™è¯¯ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šæ ·ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä¸»é¢˜ä¸Šæ˜¾è‘—æé«˜äº†åŠ¨ç”»åŒ–èº«çš„è§†è§‰è´¨é‡ï¼ˆåœ¨æ–°å‹è§†å›¾åˆæˆä¸Šæé«˜äº†2dB PSNRï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09293v1">PDF</a> 14 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ‘˜è¦æå‡ºäº†ä¸€ç§åä¸ºâ€œBetter Togetherâ€çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯åŒæ—¶è§£å†³äººä½“å§¿æ€ä¼°è®¡é—®é¢˜å¹¶ä»å¤šè§’åº¦è§†é¢‘é‡å»ºé€¼çœŸçš„ä¸‰ç»´äººç±»è§’è‰²ã€‚æ–‡ç« æŒ‡å‡ºä¼ ç»ŸæŠ€æœ¯å¾€å¾€åˆ†åˆ«è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œä½†è”åˆä¼˜åŒ–éª¨éª¼è¿åŠ¨ä¸ä¸‰ç»´å¯æ¸²æŸ“äººä½“æ¨¡å‹å¯ä»¥äº§ç”ŸååŒæ•ˆæœï¼Œå³å®ç°æ›´ç²¾ç¡®çš„åŠ¨ä½œæ•æ‰å’Œè§’è‰²å®æ—¶æ¸²æŸ“çš„è§†è§‰è´¨é‡æå‡ã€‚ä¸ºè¾¾æˆæ­¤ç›®æ ‡ï¼Œæ–‡ç« å¼•å…¥äº†ä¸€ç§æ–°å‹å¯åŠ¨ç”»è§’è‰²ï¼Œåœ¨ä¸ªæ€§åŒ–ç½‘æ ¼ä¸Šè®¾ç½®ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶æå‡ºä½¿ç”¨æ—¶é—´ä¾èµ–å¤šå±‚æ„ŸçŸ¥å™¨ä¼˜åŒ–åŠ¨ä½œåºåˆ—ï¼Œä»¥æä¾›å‡†ç¡®ä¸”æ—¶é—´ä¸€è‡´çš„å§¿æ€ä¼°è®¡ã€‚æ–‡ç« é¦–å…ˆåœ¨é«˜éš¾åº¦ç‘œä¼½åŠ¨ä½œä¸Šè¯„ä¼°æ­¤æ–¹æ³•ï¼Œå¹¶åœ¨å¤šè§†è§’äººä½“å§¿æ€ä¼°è®¡ä¸Šå±•ç°å‡ºå“è¶Šå‡†ç¡®æ€§ï¼Œåœ¨å…³èŠ‚ç‚¹ä¸Šè¾ƒåŸºäºå…³é”®ç‚¹çš„æ–¹æ³•å‡å°‘35%çš„è¯¯å·®ã€‚åŒæ—¶ï¼Œæ­¤æ–¹æ³•åœ¨å¯åŠ¨ç”»è§’è‰²çš„è§†è§‰è´¨é‡ä¸Šæœ‰æ˜¾è‘—æå‡ï¼ˆåœ¨æ–°è§†è§’åˆæˆä¸Šæé«˜2dB PSNRï¼‰ï¼Œé€‚ç”¨äºå„ç§æŒ‘æˆ˜å¯¹è±¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åä¸ºâ€œBetter Togetherâ€çš„æ–¹æ³•ï¼Œå¯åŒæ—¶è§£å†³äººä½“å§¿æ€ä¼°è®¡å’Œä¸‰ç»´è§’è‰²é‡å»ºé—®é¢˜ã€‚</li>
<li>é€šè¿‡è”åˆä¼˜åŒ–éª¨éª¼è¿åŠ¨å’Œä¸‰ç»´å¯æ¸²æŸ“äººä½“æ¨¡å‹ï¼Œå®ç°äº†æ›´ç²¾ç¡®çš„åŠ¨ä½œæ•æ‰å’Œæ›´é«˜çš„è§’è‰²å®æ—¶æ¸²æŸ“è´¨é‡ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹å¯åŠ¨ç”»è§’è‰²ï¼Œä½¿ç”¨ä¸ªæ€§åŒ–ç½‘æ ¼å’Œä¸‰ç»´é«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>ä½¿ç”¨æ—¶é—´ä¾èµ–å¤šå±‚æ„ŸçŸ¥å™¨ä¼˜åŒ–åŠ¨ä½œåºåˆ—ï¼Œæä¾›å‡†ç¡®ä¸”æ—¶é—´ä¸€è‡´çš„å§¿æ€ä¼°è®¡ã€‚</li>
<li>åœ¨é«˜éš¾åº¦ç‘œä¼½åŠ¨ä½œä¸Šè¯„ä¼°æ–¹æ³•ï¼Œå¤šè§†è§’äººä½“å§¿æ€ä¼°è®¡è¡¨ç°å‡ºå“è¶Šå‡†ç¡®æ€§ã€‚</li>
<li>è¾ƒä¹‹åŸºäºå…³é”®ç‚¹çš„æ–¹æ³•ï¼Œåœ¨å…³èŠ‚ç‚¹ä¸Šå‡å°‘äº†35%çš„è¯¯å·®ã€‚</li>
<li>æ–¹æ³•æ˜¾è‘—æé«˜å¯åŠ¨ç”»è§’è‰²çš„è§†è§‰è´¨é‡ï¼ˆæ–°è§†è§’åˆæˆä¸Šæé«˜2dB PSNRï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09293">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7bc78f7b80cc35e604873e68c0727cd0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-432e75719c6ec8049dd81b1c17bb50ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dca4ded69b621434282b41066ec37ec9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Motion-Blender-Gaussian-Splatting-for-Dynamic-Reconstruction"><a href="#Motion-Blender-Gaussian-Splatting-for-Dynamic-Reconstruction" class="headerlink" title="Motion Blender Gaussian Splatting for Dynamic Reconstruction"></a>Motion Blender Gaussian Splatting for Dynamic Reconstruction</h2><p><strong>Authors:Xinyu Zhang, Haonan Chang, Yuhan Liu, Abdeslam Boularias</strong></p>
<p>Gaussian splatting has emerged as a powerful tool for high-fidelity reconstruction of dynamic scenes. However, existing methods primarily rely on implicit motion representations, such as encoding motions into neural networks or per-Gaussian parameters, which makes it difficult to further manipulate the reconstructed motions. This lack of explicit controllability limits existing methods to replaying recorded motions only, which hinders a wider application. To address this, we propose Motion Blender Gaussian Splatting (MB-GS), a novel framework that uses motion graph as an explicit and sparse motion representation. The motion of graph links is propagated to individual Gaussians via dual quaternion skinning, with learnable weight painting functions determining the influence of each link. The motion graphs and 3D Gaussians are jointly optimized from input videos via differentiable rendering. Experiments show that MB-GS achieves state-of-the-art performance on the iPhone dataset while being competitive on HyperNeRF. Additionally, we demonstrate the application potential of our method in generating novel object motions and robot demonstrations through motion editing. Video demonstrations can be found at <a target="_blank" rel="noopener" href="https://mlzxy.github.io/mbgs">https://mlzxy.github.io/mbgs</a>. </p>
<blockquote>
<p>é«˜æ–¯ç»˜åˆ¶æŠ€æœ¯å·²æˆä¸ºé‡å»ºåŠ¨æ€åœºæ™¯çš„é«˜ä¿çœŸå·¥å…·ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºéšå¼è¿åŠ¨è¡¨ç¤ºï¼Œå¦‚å°†è¿åŠ¨ç¼–ç åˆ°ç¥ç»ç½‘ç»œæˆ–æ¯ä¸ªé«˜æ–¯å‚æ•°ä¸­ï¼Œè¿™ä½¿å¾—è¿›ä¸€æ­¥æ“ä½œé‡å»ºçš„è¿åŠ¨å˜å¾—å›°éš¾ã€‚è¿™ç§ç¼ºä¹æ˜ç¡®çš„å¯æ§æ€§é™åˆ¶äº†ç°æœ‰æ–¹æ³•åªèƒ½å›æ”¾è®°å½•çš„è¿åŠ¨ï¼Œé˜»ç¢äº†æ›´å¹¿æ³›çš„åº”ç”¨ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Motion Blender Gaussian Splattingï¼ˆMB-GSï¼‰è¿™ä¸€æ–°æ¡†æ¶ï¼Œå®ƒä½¿ç”¨è¿åŠ¨å›¾ä½œä¸ºæ˜ç¡®ä¸”ç¨€ç–çš„è¿åŠ¨è¡¨ç¤ºã€‚å›¾é“¾æ¥çš„è¿åŠ¨é€šè¿‡åŒé‡å››å…ƒæ•°è’™çš®ä¼ æ’­åˆ°å„ä¸ªé«˜æ–¯åˆ†å¸ƒä¸­ï¼Œå¯å­¦ä¹ çš„æƒé‡ç»˜åˆ¶å‡½æ•°å†³å®šäº†æ¯ä¸ªé“¾æ¥çš„å½±å“ã€‚è¿åŠ¨å›¾å’Œ3Dé«˜æ–¯åˆ†å¸ƒé€šè¿‡å¯å¾®åˆ†æ¸²æŸ“ä»è¾“å…¥è§†é¢‘ä¸­è¿›è¡Œè”åˆä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒMB-GSåœ¨iPhoneæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨HyperNeRFä¸Šå…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡è¿åŠ¨ç¼–è¾‘å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨ç”Ÿæˆæ–°å‹ç‰©ä½“è¿åŠ¨å’Œæœºå™¨äººæ¼”ç¤ºæ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚è§†é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://mlzxy.github.io/mbgs">https://mlzxy.github.io/mbgs</a>æŸ¥çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09040v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é«˜æ–¯ç‚¹æ‰©å±•ï¼ˆGaussian Splattingï¼‰åœ¨åŠ¨æ€åœºæ™¯çš„é«˜ä¿çœŸé‡å»ºä¸­æ˜¾ç¤ºå‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ä½†ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–éšå¼è¿åŠ¨è¡¨ç¤ºï¼Œå¦‚å°†è¿åŠ¨ç¼–ç åˆ°ç¥ç»ç½‘ç»œæˆ–æ¯ä¸ªé«˜æ–¯å‚æ•°ä¸­ï¼Œè¿™ä½¿å¾—éš¾ä»¥è¿›ä¸€æ­¥æ“æ§é‡å»ºçš„è¿åŠ¨ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºMotion Blender Gaussian Splattingï¼ˆMB-GSï¼‰æ¡†æ¶ï¼Œé‡‡ç”¨è¿åŠ¨å›¾ä½œä¸ºæ˜¾å¼ä¸”ç¨€ç–çš„è¿åŠ¨è¡¨ç¤ºã€‚å›¾é“¾æ¥çš„è¿åŠ¨é€šè¿‡åŒé‡å››å…ƒæ•°è’™çš®ä¼ æ’­åˆ°å„ä¸ªé«˜æ–¯åˆ†å¸ƒä¸Šï¼Œå¹¶ç”±å¯å­¦ä¹ çš„æƒé‡ç»˜åˆ¶å‡½æ•°å†³å®šæ¯ä¸ªé“¾æ¥çš„å½±å“ã€‚ä»è¾“å…¥è§†é¢‘ä¸­è”åˆä¼˜åŒ–è¿åŠ¨å›¾å’Œä¸‰ç»´é«˜æ–¯åˆ†å¸ƒé€šè¿‡å¯å¾®åˆ†æ¸²æŸ“æŠ€æœ¯ã€‚å®éªŒè¡¨æ˜ï¼ŒMB-GSåœ¨iPhoneæ•°æ®é›†ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶åœ¨HyperNeRFä¸Šè¡¨ç°è‰¯å¥½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨ç”Ÿæˆæ–°å‹ç‰©ä½“è¿åŠ¨å’Œæœºå™¨äººæ¼”ç¤ºä¸­çš„æ½œåŠ›ã€‚è§†é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://mlzxy.github.io/mbgs%E6%9F%A5%E7%9C%8B">https://mlzxy.github.io/mbgsæŸ¥çœ‹</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ–¯ç‚¹æ‰©å±•æ˜¯ä¸€ç§å¼ºå¤§çš„åŠ¨æ€åœºæ™¯é‡å»ºå·¥å…·ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–éšå¼è¿åŠ¨è¡¨ç¤ºï¼Œé™åˆ¶äº†è¿åŠ¨çš„è¿›ä¸€æ­¥æ“æ§ã€‚</li>
<li>MB-GSæ¡†æ¶é‡‡ç”¨è¿åŠ¨å›¾ä½œä¸ºæ˜¾å¼ä¸”ç¨€ç–çš„è¿åŠ¨è¡¨ç¤ºæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>è¿åŠ¨å›¾é“¾æ¥çš„è¿åŠ¨é€šè¿‡åŒé‡å››å…ƒæ•°è’™çš®ä¼ æ’­åˆ°é«˜æ–¯åˆ†å¸ƒä¸Šã€‚</li>
<li>MB-GSåœ¨iPhoneæ•°æ®é›†ä¸Šå®ç°æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶åœ¨HyperNeRFä¸Šè¡¨ç°è‰¯å¥½ã€‚</li>
<li>è¯¥æ–¹æ³•å¯åº”ç”¨äºç”Ÿæˆæ–°å‹ç‰©ä½“è¿åŠ¨å’Œæœºå™¨äººæ¼”ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8833fb6166b296949d5e0db93b5d4a28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea572ca70060dbb89ee2cbf2b487a9a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5cfa28d99017d6b71df7bdcfae632b94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aedeb506c2578910652114a0f42f22ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40bd2a6f2423c47248ff0ea539a81850.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PCGS-Progressive-Compression-of-3D-Gaussian-Splatting"><a href="#PCGS-Progressive-Compression-of-3D-Gaussian-Splatting" class="headerlink" title="PCGS: Progressive Compression of 3D Gaussian Splatting"></a>PCGS: Progressive Compression of 3D Gaussian Splatting</h2><p><strong>Authors:Yihang Chen, Mengyao Li, Qianyi Wu, Weiyao Lin, Mehrtash Harandi, Jianfei Cai</strong></p>
<p>3D Gaussian Splatting (3DGS) achieves impressive rendering fidelity and speed for novel view synthesis. However, its substantial data size poses a significant challenge for practical applications. While many compression techniques have been proposed, they fail to efficiently utilize existing bitstreams in on-demand applications due to their lack of progressivity, leading to a waste of resource. To address this issue, we propose PCGS (Progressive Compression of 3D Gaussian Splatting), which adaptively controls both the quantity and quality of Gaussians (or anchors) to enable effective progressivity for on-demand applications. Specifically, for quantity, we introduce a progressive masking strategy that incrementally incorporates new anchors while refining existing ones to enhance fidelity. For quality, we propose a progressive quantization approach that gradually reduces quantization step sizes to achieve finer modeling of Gaussian attributes. Furthermore, to compact the incremental bitstreams, we leverage existing quantization results to refine probability prediction, improving entropy coding efficiency across progressive levels. Overall, PCGS achieves progressivity while maintaining compression performance comparable to SoTA non-progressive methods. Code available at: github.com&#x2F;YihangChen-ee&#x2F;PCGS. </p>
<blockquote>
<p>3Dé«˜æ–¯æ··åˆæŠ€æœ¯ï¼ˆ3DGSï¼‰åœ¨æ–°è§†è§’åˆæˆæ–¹é¢è¾¾åˆ°äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ¸²æŸ“ä¿çœŸåº¦å’Œé€Ÿåº¦ã€‚ç„¶è€Œï¼Œå…¶åºå¤§çš„æ•°æ®é‡å¯¹å®é™…åº”ç”¨æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚è™½ç„¶å·²æå‡ºäº†è®¸å¤šå‹ç¼©æŠ€æœ¯ï¼Œä½†ç”±äºå®ƒä»¬ç¼ºä¹æ¸è¿›æ€§ï¼Œå®ƒä»¬åœ¨æŒ‰éœ€åº”ç”¨æ—¶æ— æ³•æœ‰æ•ˆåœ°åˆ©ç”¨ç°æœ‰æ¯”ç‰¹æµï¼Œå¯¼è‡´èµ„æºæµªè´¹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PCGSï¼ˆ3Dé«˜æ–¯æ··åˆçš„æ¸è¿›å‹ç¼©ï¼‰ï¼Œé€šè¿‡è‡ªé€‚åº”æ§åˆ¶é«˜æ–¯ï¼ˆæˆ–é”šç‚¹ï¼‰çš„æ•°é‡å’Œè´¨é‡ï¼Œä¸ºå®ç°æŒ‰éœ€åº”ç”¨çš„æœ‰æ•ˆæ¸è¿›æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æ•°é‡æ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ¸è¿›æ©ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨ç»†åŒ–ç°æœ‰é”šç‚¹çš„åŒæ—¶é€æ­¥åŠ å…¥æ–°çš„é”šç‚¹ï¼Œä»¥æé«˜ä¿çœŸåº¦ã€‚åœ¨è´¨é‡æ–¹é¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¸è¿›é‡åŒ–æ–¹æ³•ï¼Œé€šè¿‡é€æ­¥å‡å°é‡åŒ–æ­¥é•¿æ¥å®ç°å¯¹é«˜æ–¯å±æ€§çš„æ›´ç²¾ç»†å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œä¸ºäº†å‹ç¼©å¢é‡æ¯”ç‰¹æµï¼Œæˆ‘ä»¬åˆ©ç”¨ç°æœ‰çš„é‡åŒ–ç»“æœæ¥ä¼˜åŒ–æ¦‚ç‡é¢„æµ‹ï¼Œæé«˜æ¸è¿›å±‚æ¬¡ä¸Šçš„ç†µç¼–ç æ•ˆç‡ã€‚æ€»ä½“è€Œè¨€ï¼ŒPCGSåœ¨ä¿æŒä¸å½“å‰æœ€å…ˆè¿›çš„éæ¸è¿›æ–¹æ³•ç›¸å½“çš„å‹ç¼©æ€§èƒ½çš„åŒæ—¶å®ç°äº†æ¸è¿›æ€§ã€‚ä»£ç å¯åœ¨github.com&#x2F;YihangChen-ee&#x2F;PCGSæ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08511v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://yihangchen-ee.github.io/project_pcgs/">https://yihangchen-ee.github.io/project_pcgs/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/YihangChen-ee/PCGS">https://github.com/YihangChen-ee/PCGS</a></p>
<p><strong>Summary</strong></p>
<p>3DGSæ¸²æŸ“æŠ€æœ¯ä»¥å…¶é«˜è´¨é‡å’Œé€Ÿåº¦ä¼˜åŠ¿åº”ç”¨äºè™šæ‹Ÿè§†å›¾åˆæˆé¢†åŸŸï¼Œä½†å…¶æ•°æ®é‡å·¨å¤§çš„é—®é¢˜é™åˆ¶äº†å®é™…åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†PCGSæ–¹æ³•ï¼Œé‡‡ç”¨è‡ªé€‚åº”æ§åˆ¶é«˜æ–¯æ•°é‡å’Œè´¨é‡çš„æ–¹å¼å®ç°æ¸è¿›å¼å‹ç¼©ï¼Œä»¥æ”¯æŒæŒ‰éœ€åº”ç”¨ã€‚é€šè¿‡æ¸è¿›æ©ç ç­–ç•¥å’Œæ¸è¿›é‡åŒ–æ–¹æ³•ä¼˜åŒ–æ•°é‡å’Œè´¨é‡ï¼Œå¹¶åˆ©ç”¨ç°æœ‰é‡åŒ–ç»“æœæé«˜æ¦‚ç‡é¢„æµ‹ç²¾åº¦ï¼Œæå‡ç¼–ç æ•ˆç‡ã€‚PCGSåœ¨ä¿æŒä¸ç°æœ‰éæ¸è¿›æ–¹æ³•ç›¸å½“çš„å‹ç¼©æ€§èƒ½çš„åŒæ—¶å®ç°äº†æ¸è¿›å¼ç¼–ç ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSç”¨äºè™šæ‹Ÿè§†å›¾åˆæˆï¼Œä½†æ•°æ®é‡å·¨å¤§é™åˆ¶äº†å®é™…åº”ç”¨ã€‚</li>
<li>PCGSæ–¹æ³•æ—¨åœ¨è§£å†³æ­¤é—®é¢˜ï¼Œé€šè¿‡è‡ªé€‚åº”æ§åˆ¶é«˜æ–¯æ•°é‡å’Œè´¨é‡å®ç°æ¸è¿›å¼å‹ç¼©ã€‚</li>
<li>é‡‡ç”¨æ¸è¿›æ©ç ç­–ç•¥ä¼˜åŒ–é«˜æ–¯æ•°é‡ï¼Œæ¸è¿›é‡åŒ–æ–¹æ³•ä¼˜åŒ–è´¨é‡ã€‚</li>
<li>åˆ©ç”¨ç°æœ‰é‡åŒ–ç»“æœæé«˜æ¦‚ç‡é¢„æµ‹ç²¾åº¦ï¼Œæå‡ç¼–ç æ•ˆç‡ã€‚</li>
<li>PCGSåœ¨ä¿æŒä¸ç°æœ‰éæ¸è¿›æ–¹æ³•ç›¸å½“çš„å‹ç¼©æ€§èƒ½çš„åŒæ—¶å®ç°äº†æ¸è¿›å¼ç¼–ç ã€‚</li>
<li>PCGSæœ‰æœ›æé«˜æŒ‰éœ€åº”ç”¨çš„èµ„æºåˆ©ç”¨æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08511">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d1c7df6fb12fa457cf6e137b418c7df2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da413e615110ce40592c836d8d1aedb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-82f2e9cc6b3738f88161bb6767bfa810.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Mitigating-Ambiguities-in-3D-Classification-with-Gaussian-Splatting"><a href="#Mitigating-Ambiguities-in-3D-Classification-with-Gaussian-Splatting" class="headerlink" title="Mitigating Ambiguities in 3D Classification with Gaussian Splatting"></a>Mitigating Ambiguities in 3D Classification with Gaussian Splatting</h2><p><strong>Authors:Ruiqi Zhang, Hao Zhu, Jingyi Zhao, Qi Zhang, Xun Cao, Zhan Ma</strong></p>
<p>3D classification with point cloud input is a fundamental problem in 3D vision. However, due to the discrete nature and the insufficient material description of point cloud representations, there are ambiguities in distinguishing wire-like and flat surfaces, as well as transparent or reflective objects. To address these issues, we propose Gaussian Splatting (GS) point cloud-based 3D classification. We find that the scale and rotation coefficients in the GS point cloud help characterize surface types. Specifically, wire-like surfaces consist of multiple slender Gaussian ellipsoids, while flat surfaces are composed of a few flat Gaussian ellipsoids. Additionally, the opacity in the GS point cloud represents the transparency characteristics of objects. As a result, ambiguities in point cloud-based 3D classification can be mitigated utilizing GS point cloud as input. To verify the effectiveness of GS point cloud input, we construct the first real-world GS point cloud dataset in the community, which includes 20 categories with 200 objects in each category. Experiments not only validate the superiority of GS point cloud input, especially in distinguishing ambiguous objects, but also demonstrate the generalization ability across different classification methods. </p>
<blockquote>
<p>ä¸‰ç»´ç‚¹äº‘è¾“å…¥çš„3Dåˆ†ç±»æ˜¯3Dè§†è§‰ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ã€‚ç„¶è€Œï¼Œç”±äºç‚¹äº‘è¡¨ç¤ºçš„ç¦»æ•£æ€§å’Œææ–™æè¿°ä¸è¶³ï¼Œåœ¨åŒºåˆ†çº¿çŠ¶å’Œå¹³å¦è¡¨é¢ä»¥åŠé€æ˜æˆ–åå°„ç‰©ä½“æ—¶å­˜åœ¨æ­§ä¹‰ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé«˜æ–¯å–·æº…ï¼ˆGSï¼‰çš„ç‚¹äº‘3Dåˆ†ç±»ã€‚æˆ‘ä»¬å‘ç°GSç‚¹äº‘ä¸­çš„å°ºåº¦å’Œæ—‹è½¬ç³»æ•°æœ‰åŠ©äºè¡¨å¾è¡¨é¢ç±»å‹ã€‚å…·ä½“æ¥è¯´ï¼Œçº¿çŠ¶è¡¨é¢ç”±å¤šä¸ªç»†é•¿çš„é«˜æ–¯æ¤­çƒç»„æˆï¼Œè€Œå¹³å¦è¡¨é¢åˆ™ç”±å‡ ä¸ªæ‰å¹³çš„é«˜æ–¯æ¤­çƒç»„æˆã€‚æ­¤å¤–ï¼ŒGSç‚¹äº‘ä¸­çš„ä¸é€æ˜åº¦ä»£è¡¨äº†ç‰©ä½“çš„é€æ˜ç‰¹æ€§ã€‚å› æ­¤ï¼Œåˆ©ç”¨GSç‚¹äº‘ä½œä¸ºè¾“å…¥ï¼Œå¯ä»¥å‡å°‘åŸºäºç‚¹äº‘çš„3Dåˆ†ç±»ä¸­çš„æ­§ä¹‰ã€‚ä¸ºäº†éªŒè¯GSç‚¹äº‘è¾“å…¥çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬æ„å»ºäº†ç¤¾åŒºä¸­ç¬¬ä¸€ä¸ªçœŸå®ä¸–ç•Œçš„GSç‚¹äº‘æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬20ä¸ªç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«æœ‰200ä¸ªå¯¹è±¡ã€‚å®éªŒä¸ä»…éªŒè¯äº†GSç‚¹äº‘è¾“å…¥çš„ä¼˜è¶Šæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒºåˆ†æ¨¡ç³Šå¯¹è±¡æ–¹é¢ï¼Œè€Œä¸”è¯æ˜äº†å…¶åœ¨ä¸åŒåˆ†ç±»æ–¹æ³•ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08352v1">PDF</a> Accepted by CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>GSç‚¹äº‘ï¼ˆGaussian Splattingï¼‰èƒ½å¤Ÿæœ‰æ•ˆè§£å†³3Dç‚¹äº‘åˆ†ç±»ä¸­çš„è¡¨é¢æ¨¡ç³Šé—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨ç‚¹äº‘ä¸­çš„å°ºåº¦ä¸æ—‹è½¬ç³»æ•°åŒºåˆ†çº¿çŠ¶æˆ–å¹³é¢è¡¨é¢ï¼ŒåŒæ—¶ä½¿ç”¨ç‚¹äº‘çš„é€æ˜åº¦ç‰¹æ€§æ¥è¯†åˆ«é€æ˜æˆ–åå°„ç‰©ä½“ã€‚ä¸ºéªŒè¯å…¶æœ‰æ•ˆæ€§ï¼Œå»ºç«‹äº†é¦–ä¸ªçœŸå®ä¸–ç•Œçš„GSç‚¹äº‘æ•°æ®é›†ï¼Œå®éªŒç»“æœæ˜¾ç¤ºGSç‚¹äº‘è¾“å…¥åœ¨åŒºåˆ†æ¨¡ç³Šç‰©ä½“ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œä¸”åœ¨ä¸åŒåˆ†ç±»æ–¹æ³•ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GSç‚¹äº‘åŸºäºé«˜æ–¯åˆ†å¸ƒè§£å†³äº†ç‚¹äº‘ç¦»æ•£æ€§å’Œæè¿°ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡å°ºåº¦ä¸æ—‹è½¬ç³»æ•°åŒºåˆ†çº¿çŠ¶æˆ–å¹³é¢è¡¨é¢ã€‚</li>
<li>ç‚¹äº‘çš„é€æ˜åº¦ç‰¹æ€§æœ‰åŠ©äºè¯†åˆ«é€æ˜æˆ–åå°„ç‰©ä½“ã€‚</li>
<li>å»ºç«‹é¦–ä¸ªçœŸå®ä¸–ç•Œçš„GSç‚¹äº‘æ•°æ®é›†ï¼ŒåŒ…å«20ä¸ªç±»åˆ«ã€æ¯ä¸ªç±»åˆ«200ä¸ªå¯¹è±¡ã€‚</li>
<li>å®éªŒéªŒè¯äº†GSç‚¹äº‘åœ¨åŒºåˆ†æ¨¡ç³Šç‰©ä½“ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</li>
<li>GSç‚¹äº‘è¾“å…¥åœ¨ä¸åŒåˆ†ç±»æ–¹æ³•ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08352">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0783a3a9881a13017fdd8fa8d28ac4fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-85e7d4dd1809200d0d11d0a89ab27c54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1418328e3a443395972b4009230593d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a973f603a82aaf6409c0f8788e661a9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-62347aa6203e2db71aad85e65f12cec3.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Uni-Gaussians-Unifying-Camera-and-Lidar-Simulation-with-Gaussians-for-Dynamic-Driving-Scenarios"><a href="#Uni-Gaussians-Unifying-Camera-and-Lidar-Simulation-with-Gaussians-for-Dynamic-Driving-Scenarios" class="headerlink" title="Uni-Gaussians: Unifying Camera and Lidar Simulation with Gaussians for   Dynamic Driving Scenarios"></a>Uni-Gaussians: Unifying Camera and Lidar Simulation with Gaussians for   Dynamic Driving Scenarios</h2><p><strong>Authors:Zikang Yuan, Yuechuan Pu, Hongcheng Luo, Fengtian Lang, Cheng Chi, Teng Li, Yingying Shen, Haiyang Sun, Bing Wang, Xin Yang</strong></p>
<p>Ensuring the safety of autonomous vehicles necessitates comprehensive simulation of multi-sensor data, encompassing inputs from both cameras and LiDAR sensors, across various dynamic driving scenarios. Neural rendering techniques, which utilize collected raw sensor data to simulate these dynamic environments, have emerged as a leading methodology. While NeRF-based approaches can uniformly represent scenes for rendering data from both camera and LiDAR, they are hindered by slow rendering speeds due to dense sampling. Conversely, Gaussian Splatting-based methods employ Gaussian primitives for scene representation and achieve rapid rendering through rasterization. However, these rasterization-based techniques struggle to accurately model non-linear optical sensors. This limitation restricts their applicability to sensors beyond pinhole cameras. To address these challenges and enable unified representation of dynamic driving scenarios using Gaussian primitives, this study proposes a novel hybrid approach. Our method utilizes rasterization for rendering image data while employing Gaussian ray-tracing for LiDAR data rendering. Experimental results on public datasets demonstrate that our approach outperforms current state-of-the-art methods. This work presents a unified and efficient solution for realistic simulation of camera and LiDAR data in autonomous driving scenarios using Gaussian primitives, offering significant advancements in both rendering quality and computational efficiency. </p>
<blockquote>
<p>ç¡®ä¿è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨éœ€è¦å¯¹å¤šä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œå…¨é¢çš„ä»¿çœŸï¼Œè¿™æ¶µç›–äº†æ¥è‡ªæ‘„åƒæœºå’Œæ¿€å…‰é›·è¾¾ä¼ æ„Ÿå™¨çš„è¾“å…¥ï¼Œå¹¶æ¶µç›–å„ç§åŠ¨æ€é©¾é©¶åœºæ™¯ã€‚åˆ©ç”¨æ”¶é›†çš„åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®æ¨¡æ‹Ÿè¿™äº›åŠ¨æ€ç¯å¢ƒçš„ç¥ç»æ¸²æŸ“æŠ€æœ¯å·²æˆä¸ºä¸€ç§ä¸»è¦æ–¹æ³•ã€‚è™½ç„¶åŸºäºNeRFçš„æ–¹æ³•å¯ä»¥ç»Ÿä¸€è¡¨ç¤ºåœºæ™¯ï¼Œå¯¹æ¥è‡ªç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„æ¸²æŸ“æ•°æ®è¿›è¡Œç»Ÿä¸€å‘ˆç°ï¼Œä½†ç”±äºå¯†é›†é‡‡æ ·ï¼Œå…¶æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚ç›¸åï¼ŒåŸºäºé«˜æ–¯æ¶‚æŠ¹çš„æ–¹æ³•ä½¿ç”¨é«˜æ–¯åŸå§‹æ¨¡å‹è¿›è¡Œåœºæ™¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡å…‰æ …åŒ–å®ç°å¿«é€Ÿæ¸²æŸ“ã€‚ç„¶è€Œï¼Œè¿™äº›åŸºäºå…‰æ …åŒ–çš„æŠ€æœ¯åœ¨æ¨¡æ‹Ÿéçº¿æ€§å…‰å­¦ä¼ æ„Ÿå™¨æ—¶é‡åˆ°äº†å›°éš¾ã€‚è¿™ä¸€å±€é™æ€§é™åˆ¶äº†å®ƒä»¬å¯¹é’ˆå­”ç›¸æœºä»¥å¤–çš„ä¼ æ„Ÿå™¨çš„é€‚ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œå®ç°å¯¹åŠ¨æ€é©¾é©¶åœºæ™¯çš„åŸºäºé«˜æ–¯åŸå§‹æ¨¡å‹è¿›è¡Œç»Ÿä¸€è¡¨ç¤ºï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ··åˆæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨å…‰æ …åŒ–è¿›è¡Œå›¾åƒæ•°æ®æ¸²æŸ“ï¼ŒåŒæ—¶ä½¿ç”¨é«˜æ–¯å…‰çº¿è¿½è¸ªè¿›è¡Œæ¿€å…‰é›·è¾¾æ•°æ®æ¸²æŸ“ã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„å…¶å®ƒæ–¹æ³•ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨é«˜æ–¯åŸå§‹æ¨¡å‹å¯¹è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„ç›¸æœºå’Œæ¿€å…‰é›·è¾¾æ•°æ®è¿›è¡Œé€¼çœŸæ¨¡æ‹Ÿçš„ç»Ÿä¸€é«˜æ•ˆè§£å†³æ–¹æ¡ˆï¼Œåœ¨æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†é‡å¤§è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08317v1">PDF</a> 10 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åœ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨æ€§ä¿éšœä¸­ï¼Œå¦‚ä½•åˆ©ç”¨ç¥ç»ç½‘ç»œæ¸²æŸ“æŠ€æœ¯æ¨¡æ‹Ÿå¤šä¼ æ„Ÿå™¨æ•°æ®çš„é—®é¢˜ã€‚æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ··åˆæ–¹æ³•ï¼Œä½¿ç”¨æ …æ ¼åŒ–è¿›è¡Œå›¾åƒæ•°æ®æ¸²æŸ“ï¼ŒåŒæ—¶é‡‡ç”¨é«˜æ–¯å°„çº¿è¿½è¸ªè¿›è¡Œæ¿€å…‰é›·è¾¾æ•°æ®æ¸²æŸ“ã€‚è¯¥æ–¹æ³•å®ç°äº†å¯¹åŠ¨æ€é©¾é©¶åœºæ™¯çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œå¹¶åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»è½¦è¾†çš„å®‰å…¨æ€§éœ€è¦å…¨é¢æ¨¡æ‹Ÿå¤šä¼ æ„Ÿå™¨æ•°æ®ï¼ŒåŒ…æ‹¬ç›¸æœºå’Œæ¿€å…‰é›·è¾¾ä¼ æ„Ÿå™¨åœ¨å„ç§åŠ¨æ€é©¾é©¶åœºæ™¯ä¸‹çš„è¾“å…¥ã€‚</li>
<li>ç¥ç»ç½‘ç»œæ¸²æŸ“æŠ€æœ¯å·²æˆä¸ºæ¨¡æ‹Ÿè¿™äº›åŠ¨æ€ç¯å¢ƒçš„ä¸»è¦æ–¹æ³•ï¼Œå…¶ä¸­åŸºäºNeRFçš„æ–¹æ³•å¯ä»¥ç»Ÿä¸€è¡¨ç¤ºåœºæ™¯å¹¶ä¸ºç›¸æœºå’Œæ¿€å…‰é›·è¾¾æä¾›æ¸²æŸ“æ•°æ®ï¼Œä½†æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚</li>
<li>é«˜æ–¯æ‘Šé“ºæ³•ä½¿ç”¨é«˜æ–¯åŸå§‹åœºæ™¯è¡¨ç¤ºå¹¶å®ç°å¿«é€Ÿæ¸²æŸ“ï¼Œä½†åœ¨å»ºæ¨¡éçº¿æ€§å…‰å­¦ä¼ æ„Ÿå™¨æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªæ··åˆæ–¹æ³•ï¼Œç»“åˆæ …æ ¼åŒ–å’Œé«˜æ–¯å°„çº¿è¿½è¸ªæ¥æ¸²æŸ“å›¾åƒæ•°æ®å’Œæ¿€å…‰é›·è¾¾æ•°æ®ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†å¯¹åŠ¨æ€é©¾é©¶åœºæ™¯çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œå¹¶æ˜¾è‘—æé«˜äº†æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºå½“å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08317">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-778f400c1a06e4db61020fa8ec25ea30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f09ea8ea4addd961ea8f0d8d90f713c.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.08317v1/page_3_0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e612daa622b445ff62806740fe8ddac7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fd3a22ec3281dab5629d165382ab684.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9b520610c17d90889fb1a1ed8b22392.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="ELECTRA-A-Symmetry-breaking-Cartesian-Network-for-Charge-Density-Prediction-with-Floating-Orbitals"><a href="#ELECTRA-A-Symmetry-breaking-Cartesian-Network-for-Charge-Density-Prediction-with-Floating-Orbitals" class="headerlink" title="ELECTRA: A Symmetry-breaking Cartesian Network for Charge Density   Prediction with Floating Orbitals"></a>ELECTRA: A Symmetry-breaking Cartesian Network for Charge Density   Prediction with Floating Orbitals</h2><p><strong>Authors:Jonas Elsborg, Luca Thiede, AlÃ¡n Aspuru-Guzik, Tejs Vegge, Arghya Bhowmik</strong></p>
<p>We present the Electronic Tensor Reconstruction Algorithm (ELECTRA) - an equivariant model for predicting electronic charge densities using â€œfloatingâ€ orbitals. Floating orbitals are a long-standing idea in the quantum chemistry community that promises more compact and accurate representations by placing orbitals freely in space, as opposed to centering all orbitals at the position of atoms. Finding ideal placements of these orbitals requires extensive domain knowledge though, which thus far has prevented widespread adoption. We solve this in a data-driven manner by training a Cartesian tensor network to predict orbital positions along with orbital coefficients. This is made possible through a symmetry-breaking mechanism that is used to learn position displacements with lower symmetry than the input molecule while preserving the rotation equivariance of the charge density itself. Inspired by recent successes of Gaussian Splatting in representing densities in space, we are using Gaussians as our orbitals and predict their weights and covariance matrices. Our method achieves a state-of-the-art balance between computational efficiency and predictive accuracy on established benchmarks. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ç”µå­å¼ é‡é‡å»ºç®—æ³•ï¼ˆELECTRAï¼‰â€”â€”ä¸€ç§åˆ©ç”¨â€œæµ®åŠ¨â€è½¨é“é¢„æµ‹ç”µå­ç”µè·å¯†åº¦çš„ç­‰ä»·æ¨¡å‹ã€‚æµ®åŠ¨è½¨é“æ˜¯é‡å­åŒ–å­¦ç•Œé•¿æœŸä»¥æ¥çš„ä¸€ä¸ªç†å¿µï¼Œå®ƒé€šè¿‡è®©è½¨é“åœ¨ç©ºé—´ä¸­è‡ªç”±æ”¾ç½®ï¼ˆè€Œä¸æ˜¯å°†æ‰€æœ‰è½¨é“éƒ½ç½®äºåŸå­çš„ä½ç½®ï¼‰ï¼Œä»è€Œæä¾›æ›´ä¸ºç´§å‡‘å’Œå‡†ç¡®çš„è¡¨ç¤ºã€‚ç„¶è€Œï¼Œå¯»æ‰¾è¿™äº›è½¨é“çš„ç†æƒ³ä½ç½®éœ€è¦å¤§é‡çš„ä¸“ä¸šçŸ¥è¯†ï¼Œè¿™è¿„ä»Šä¸ºæ­¢ä¸€ç›´é˜»ç¢äº†å®ƒçš„å¹¿æ³›åº”ç”¨ã€‚æˆ‘ä»¬é€šè¿‡è®­ç»ƒä¸€ä¸ªç¬›å¡å°”å¼ é‡ç½‘ç»œæ¥é¢„æµ‹è½¨é“ä½ç½®ä»¥åŠè½¨é“ç³»æ•°æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚è¿™æ˜¯é€šè¿‡ä¸€ä¸ªå¯¹ç§°ç ´åæœºåˆ¶å®ç°çš„ï¼Œè¯¥æœºåˆ¶ç”¨äºå­¦ä¹ å…·æœ‰æ¯”è¾“å…¥åˆ†å­æ›´ä½å¯¹ç§°æ€§çš„ä½ç½®ä½ç§»ï¼ŒåŒæ—¶ä¿ç•™ç”µè·å¯†åº¦æœ¬èº«çš„æ—‹è½¬ç­‰ä»·æ€§ã€‚å—åˆ°æœ€è¿‘é«˜æ–¯å¹³é“ºæ³•åœ¨ç©ºé—´å¯†åº¦è¡¨ç¤ºæ–¹é¢æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæˆ‘ä»¬çš„è½¨é“ï¼Œå¹¶é¢„æµ‹å…¶æƒé‡å’Œåæ–¹å·®çŸ©é˜µã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ—¢å®šçš„åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹ç²¾åº¦ä¹‹é—´çš„æœ€ä½³å¹³è¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08305v1">PDF</a> 8 pages, 3 figures, 1 table</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç”µå­å¼ é‡é‡å»ºç®—æ³•ï¼ˆELECTRAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨â€œæµ®åŠ¨â€è½¨é“é¢„æµ‹ç”µå­ç”µè·å¯†åº¦çš„ç­‰ä»·æ¨¡å‹ã€‚æµ®åŠ¨è½¨é“æ˜¯é‡å­åŒ–å­¦ç•Œé•¿æœŸä»¥æ¥çš„ä¸€ä¸ªç†å¿µï¼Œå®ƒé€šè¿‡è®©è½¨é“åœ¨ç©ºé—´ä¸­è‡ªç”±æ”¾ç½®ï¼Œè€Œä¸æ˜¯å°†æ‰€æœ‰è½¨é“å®šä½åœ¨åŸå­ä½ç½®ï¼Œä»è€Œæä¾›æ›´ç´§å‡‘å’Œå‡†ç¡®çš„è¡¨ç¤ºã€‚ç„¶è€Œï¼Œæ‰¾åˆ°è¿™äº›è½¨é“çš„ç†æƒ³ä½ç½®éœ€è¦å¤§é‡çš„é¢†åŸŸçŸ¥è¯†ï¼Œè¿™è‡³ä»Šé˜»ç¢äº†å…¶å¹¿æ³›åº”ç”¨ã€‚æˆ‘ä»¬é‡‡ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼Œè®­ç»ƒç¬›å¡å°”å¼ é‡ç½‘ç»œæ¥é¢„æµ‹è½¨é“ä½ç½®å’Œè½¨é“ç³»æ•°ã€‚è¿™æ˜¯é€šè¿‡ä¸€ä¸ªå¯¹ç§°ç ´åæœºåˆ¶å®ç°çš„ï¼Œè¯¥æœºåˆ¶å¯ä»¥å­¦ä¹ å…·æœ‰æ¯”è¾“å…¥åˆ†å­æ›´ä½å¯¹ç§°æ€§çš„ä½ç½®ä½ç§»ï¼ŒåŒæ—¶ä¿æŒç”µè·å¯†åº¦çš„æ—‹è½¬ç­‰ä»·æ€§ã€‚å—åˆ°é«˜æ–¯å¹³é“ºæ³•åœ¨ç©ºé—´ä¸­è¡¨ç¤ºå¯†åº¦çš„æœ€æ–°æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯ä½œä¸ºæˆ‘ä»¬çš„è½¨é“ï¼Œå¹¶é¢„æµ‹å…¶æƒé‡å’Œåæ–¹å·®çŸ©é˜µã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ—¢å®šçš„åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹ç²¾åº¦ä¹‹é—´çš„æœ€ä½³å¹³è¡¡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>ä»‹ç»äº†Electronic Tensor Reconstruction Algorithmï¼ˆELECTRAï¼‰ç®—æ³•ã€‚</li>
<li>ELECTRAåˆ©ç”¨æµ®åŠ¨è½¨é“ç†å¿µé¢„æµ‹ç”µå­ç”µè·å¯†åº¦ã€‚</li>
<li>æµ®åŠ¨è½¨é“å…è®¸è½¨é“åœ¨ç©ºé—´ä¸­è‡ªç”±æ”¾ç½®ï¼Œæé«˜è¡¨ç¤ºçš„ç²¾åº¦å’Œç´§å‡‘æ€§ã€‚</li>
<li>é€šè¿‡æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒç¬›å¡å°”å¼ é‡ç½‘ç»œæ¥é¢„æµ‹è½¨é“ä½ç½®å’Œè½¨é“ç³»æ•°ã€‚</li>
<li>å¯¹ç§°ç ´åæœºåˆ¶ä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ ä½ç½®ä½ç§»ï¼ŒåŒæ—¶ä¿æŒç”µè·å¯†åº¦çš„æ—‹è½¬ç­‰ä»·æ€§ã€‚</li>
<li>å—åˆ°é«˜æ–¯å¹³é“ºæ³•çš„å¯å‘ï¼Œä½¿ç”¨é«˜æ–¯ä½œä¸ºè½¨é“ï¼Œå¹¶é¢„æµ‹å…¶æƒé‡å’Œåæ–¹å·®çŸ©é˜µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08305">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f45b704faebd71682389caef96846e2c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0150fa74d67eeb6457c6f47d7718784.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MVD-HuGaS-Human-Gaussians-from-a-Single-Image-via-3D-Human-Multi-view-Diffusion-Prior"><a href="#MVD-HuGaS-Human-Gaussians-from-a-Single-Image-via-3D-Human-Multi-view-Diffusion-Prior" class="headerlink" title="MVD-HuGaS: Human Gaussians from a Single Image via 3D Human Multi-view   Diffusion Prior"></a>MVD-HuGaS: Human Gaussians from a Single Image via 3D Human Multi-view   Diffusion Prior</h2><p><strong>Authors:Kaiqiang Xiong, Ying Feng, Qi Zhang, Jianbo Jiao, Yang Zhao, Zhihao Liang, Huachen Gao, Ronggang Wang</strong></p>
<p>3D human reconstruction from a single image is a challenging problem and has been exclusively studied in the literature. Recently, some methods have resorted to diffusion models for guidance, optimizing a 3D representation via Score Distillation Sampling(SDS) or generating one back-view image for facilitating reconstruction. However, these methods tend to produce unsatisfactory artifacts (\textit{e.g.} flattened human structure or over-smoothing results caused by inconsistent priors from multiple views) and struggle with real-world generalization in the wild. In this work, we present \emph{MVD-HuGaS}, enabling free-view 3D human rendering from a single image via a multi-view human diffusion model. We first generate multi-view images from the single reference image with an enhanced multi-view diffusion model, which is well fine-tuned on high-quality 3D human datasets to incorporate 3D geometry priors and human structure priors. To infer accurate camera poses from the sparse generated multi-view images for reconstruction, an alignment module is introduced to facilitate joint optimization of 3D Gaussians and camera poses. Furthermore, we propose a depth-based Facial Distortion Mitigation module to refine the generated facial regions, thereby improving the overall fidelity of the reconstruction.Finally, leveraging the refined multi-view images, along with their accurate camera poses, MVD-HuGaS optimizes the 3D Gaussians of the target human for high-fidelity free-view renderings. Extensive experiments on Thuman2.0 and 2K2K datasets show that the proposed MVD-HuGaS achieves state-of-the-art performance on single-view 3D human rendering. </p>
<blockquote>
<p>ä»å•å¼ å›¾åƒè¿›è¡Œ3Däººä½“é‡å»ºæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå·²åœ¨æ–‡çŒ®ä¸­è¿›è¡Œäº†ä¸“é—¨ç ”ç©¶ã€‚æœ€è¿‘ï¼Œä¸€äº›æ–¹æ³•é‡‡ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œå¼•å¯¼ï¼Œé€šè¿‡åˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰ä¼˜åŒ–3Dè¡¨ç¤ºï¼Œæˆ–è€…ç”Ÿæˆä¸€å¼ åè§†å›¾å›¾åƒä»¥è¾…åŠ©é‡å»ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šäº§ç”Ÿä¸æ»¡æ„çš„ä¼ªå½±ï¼ˆä¾‹å¦‚ç”±äºå¤šè§†å›¾çš„ä¸ä¸€è‡´å…ˆéªŒå¯¼è‡´çš„æ‰å¹³åŒ–äººä½“ç»“æ„æˆ–è¿‡åº¦å¹³æ»‘çš„ç»“æœï¼‰ï¼Œå¹¶ä¸”åœ¨ç°å®ä¸–ç•Œçš„é‡å¤–ç¯å¢ƒä¸­æ¨å¹¿æ—¶é‡åˆ°å›°éš¾ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†â€œMVD-HuGaSâ€ï¼Œå®ƒé€šè¿‡å¤šè§†å›¾äººä½“æ‰©æ•£æ¨¡å‹ï¼Œå®ç°ä»å•å¼ å›¾åƒè¿›è¡Œè‡ªç”±è§†è§’çš„3Däººä½“æ¸²æŸ“ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å¢å¼ºçš„å¤šè§†å›¾æ‰©æ•£æ¨¡å‹ä»å•å¼ å‚è€ƒå›¾åƒç”Ÿæˆå¤šè§†å›¾å›¾åƒï¼Œè¯¥æ¨¡å‹åœ¨é«˜è´¨é‡çš„3Däººä½“æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥èå…¥3Då‡ ä½•å…ˆéªŒå’Œäººä½“ç»“æ„å…ˆéªŒã€‚ä¸ºäº†ä»ç¨€ç–ç”Ÿæˆçš„å¤šè§†å›¾å›¾åƒä¸­æ¨æ–­å‡ºç”¨äºé‡å»ºçš„å‡†ç¡®ç›¸æœºå§¿æ€ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯¹é½æ¨¡å—ï¼Œä»¥ä¿ƒè¿›3Dé«˜æ–¯å’Œç›¸æœºå§¿æ€çš„è”åˆä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ·±åº¦çš„é¢éƒ¨å¤±çœŸå‡è½»æ¨¡å—ï¼Œä»¥ç»†åŒ–ç”Ÿæˆçš„é¢éƒ¨åŒºåŸŸï¼Œä»è€Œæé«˜é‡å»ºçš„æ•´ä½“ä¿çœŸåº¦ã€‚æœ€åï¼Œåˆ©ç”¨ç»†åŒ–åçš„å¤šè§†å›¾å›¾åƒåŠå…¶å‡†ç¡®çš„ç›¸æœºå§¿æ€ï¼ŒMVD-HuGaSä¼˜åŒ–ç›®æ ‡äººä½“çš„3Dé«˜æ–¯åˆ†å¸ƒï¼Œä»¥å®ç°é«˜ä¿çœŸè‡ªç”±è§†è§’æ¸²æŸ“ã€‚åœ¨Thuman2.0å’Œ2K2Kæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„MVD-HuGaSåœ¨å•è§†å›¾3Däººä½“æ¸²æŸ“ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08218v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¤šè§†è§’æ‰©æ•£æ¨¡å‹MVD-HuGaSçš„å•å›¾åƒè‡ªç”±è§†è§’ä¸‰ç»´äººä½“æ¸²æŸ“æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¢å¼ºå¤šè§†è§’æ‰©æ•£æ¨¡å‹ç”Ÿæˆå‚è€ƒå›¾åƒçš„å¤šè§†è§’å›¾åƒï¼Œç»“åˆ3Då‡ ä½•å…ˆéªŒå’Œäººä½“ç»“æ„å…ˆéªŒè¿›è¡Œä¼˜åŒ–ã€‚å¼•å…¥å¯¹é½æ¨¡å—æ¨æ–­ç¨€ç–å¤šè§†è§’å›¾åƒçš„å‡†ç¡®ç›¸æœºå§¿æ€ï¼Œæå‡ºåŸºäºæ·±åº¦çš„é¢éƒ¨å¤±çœŸå‡è½»æ¨¡å—ä¼˜åŒ–é¢éƒ¨åŒºåŸŸã€‚æœ€ç»ˆï¼Œåˆ©ç”¨ä¼˜åŒ–åçš„å¤šè§†è§’å›¾åƒå’Œå‡†ç¡®çš„ç›¸æœºå§¿æ€ï¼ŒMVD-HuGaSä¼˜åŒ–ç›®æ ‡äººä½“çš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒï¼Œå®ç°é«˜ä¿çœŸè‡ªç”±è§†è§’æ¸²æŸ“ã€‚åœ¨Thuman2.0å’Œ2K2Kæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å•è§†è§’ä¸‰ç»´äººä½“æ¸²æŸ“ä¸Šå–å¾—äº†æœ€æ–°æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå¤šè§†è§’æ‰©æ•£æ¨¡å‹ï¼ˆMVD-HuGaSï¼‰çš„ä¸‰ç»´äººä½“æ¸²æŸ“æ–¹æ³•ã€‚</li>
<li>é€šè¿‡å¢å¼ºå¤šè§†è§’æ‰©æ•£æ¨¡å‹ç”Ÿæˆå‚è€ƒå›¾åƒçš„å¤šè§†è§’å›¾åƒï¼Œå¹¶èå…¥3Då‡ ä½•å’Œäººä½“ç»“æ„å…ˆéªŒã€‚</li>
<li>å¼•å…¥å¯¹é½æ¨¡å—ï¼Œå¯ä»¥ä»ç¨€ç–ç”Ÿæˆçš„å¤šè§†è§’å›¾åƒæ¨æ–­å‡†ç¡®çš„ç›¸æœºå§¿æ€ã€‚</li>
<li>æå‡ºåŸºäºæ·±åº¦çš„é¢éƒ¨å¤±çœŸå‡è½»æ¨¡å—ï¼Œç”¨äºä¼˜åŒ–é¢éƒ¨åŒºåŸŸçš„ç”Ÿæˆæ•ˆæœã€‚</li>
<li>åˆ©ç”¨ä¼˜åŒ–åçš„å¤šè§†è§’å›¾åƒå’Œå‡†ç¡®çš„ç›¸æœºå§¿æ€ï¼Œä¼˜åŒ–äº†ç›®æ ‡äººä½“çš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>MVD-HuGaSåœ¨å•è§†è§’ä¸‰ç»´äººä½“æ¸²æŸ“æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08218">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-af250fc7e6b2a7db59a0bd058d267a46.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.08218v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.08218v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.08218v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="REArtGS-Reconstructing-and-Generating-Articulated-Objects-via-3D-Gaussian-Splatting-with-Geometric-and-Motion-Constraints"><a href="#REArtGS-Reconstructing-and-Generating-Articulated-Objects-via-3D-Gaussian-Splatting-with-Geometric-and-Motion-Constraints" class="headerlink" title="REArtGS: Reconstructing and Generating Articulated Objects via 3D   Gaussian Splatting with Geometric and Motion Constraints"></a>REArtGS: Reconstructing and Generating Articulated Objects via 3D   Gaussian Splatting with Geometric and Motion Constraints</h2><p><strong>Authors:Di Wu, Liu Liu, Zhou Linli, Anran Huang, Liangtu Song, Qiaojun Yu, Qi Wu, Cewu Lu</strong></p>
<p>Articulated objects, as prevalent entities in human life, their 3D representations play crucial roles across various applications. However, achieving both high-fidelity textured surface reconstruction and dynamic generation for articulated objects remains challenging for existing methods. In this paper, we present REArtGS, a novel framework that introduces additional geometric and motion constraints to 3D Gaussian primitives, enabling high-quality textured surface reconstruction and generation for articulated objects. Specifically, given multi-view RGB images of arbitrary two states of articulated objects, we first introduce an unbiased Signed Distance Field (SDF) guidance to regularize Gaussian opacity fields, enhancing geometry constraints and improving surface reconstruction quality. Then we establish deformable fields for 3D Gaussians constrained by the kinematic structures of articulated objects, achieving unsupervised generation of surface meshes in unseen states. Extensive experiments on both synthetic and real datasets demonstrate our approach achieves high-quality textured surface reconstruction for given states, and enables high-fidelity surface generation for unseen states. Codes will be released within the next four months and the project website is at <a target="_blank" rel="noopener" href="https://sites.google.com/view/reartgs/home">https://sites.google.com/view/reartgs/home</a>. </p>
<blockquote>
<p>å…³èŠ‚å‹ç‰©ä½“ä½œä¸ºäººç±»ç”Ÿæ´»ä¸­å¸¸è§çš„å®ä½“ï¼Œå…¶3Dè¡¨ç¤ºåœ¨å„ç§åº”ç”¨ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚ç„¶è€Œï¼Œå¯¹äºç°æœ‰æ–¹æ³•æ¥è¯´ï¼Œå®ç°å…³èŠ‚å‹ç‰©ä½“çš„é«˜ä¿çœŸçº¹ç†è¡¨é¢é‡å»ºå’ŒåŠ¨æ€ç”Ÿæˆä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†REArtGSï¼Œä¸€ä¸ªå¼•å…¥3Dé«˜æ–¯åŸå§‹å‡ ä½•å’ŒåŠ¨ä½œçº¦æŸçš„æ–°å‹æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°å…³èŠ‚å‹ç‰©ä½“çš„é«˜è´¨é‡çº¹ç†è¡¨é¢é‡å»ºå’Œç”Ÿæˆã€‚å…·ä½“è€Œè¨€ï¼Œç»™å®šå…³èŠ‚å‹ç‰©ä½“çš„ä»»æ„ä¸¤ç§çŠ¶æ€çš„å¤šè§†è§’RGBå›¾åƒï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥æ— åç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰æŒ‡å¯¼æ¥è§„èŒƒé«˜æ–¯ä¸é€æ˜åº¦åœºï¼Œå¢å¼ºå‡ ä½•çº¦æŸå¹¶æé«˜è¡¨é¢é‡å»ºè´¨é‡ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¸ºå—å…³èŠ‚å‹ç‰©ä½“è¿åŠ¨ç»“æ„çº¦æŸçš„3Dé«˜æ–¯å»ºç«‹å¯å˜å½¢åœºï¼Œå®ç°æœªè§çŠ¶æ€çš„è¡¨é¢ç½‘æ ¼çš„æ— ç›‘ç£ç”Ÿæˆã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†ç»™å®šçŠ¶æ€çš„é«˜è´¨é‡çº¹ç†è¡¨é¢é‡å»ºï¼Œå¹¶ä¸ºæœªè§çŠ¶æ€å®ç°äº†é«˜ä¿çœŸè¡¨é¢ç”Ÿæˆã€‚ä»£ç å°†åœ¨æœªæ¥å››ä¸ªæœˆå†…å‘å¸ƒï¼Œé¡¹ç›®ç½‘ç«™åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://sites.google.com/view/reartgs/home%E3%80%82">https://sites.google.com/view/reartgs/homeã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06677v2">PDF</a> 11pages, 6 figures</p>
<p><strong>æ‘˜è¦</strong><br>    REArtGSæ¡†æ¶å¼•å…¥é¢å¤–çš„å‡ ä½•å’Œè¿åŠ¨çº¦æŸåˆ°3Dé«˜æ–¯åŸå§‹æ¨¡å‹ï¼Œå®ç°å¯¹å…³èŠ‚å‹å¯¹è±¡çš„é«˜è´¨é‡çº¹ç†è¡¨é¢é‡å»ºå’Œç”Ÿæˆã€‚é€šè¿‡å¤šè§†è§’RGBå›¾åƒï¼Œå¯¹å…³èŠ‚å‹å¯¹è±¡çš„ä»»æ„ä¸¤ç§çŠ¶æ€è¿›è¡Œæ— åå¸¦ç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰å¼•å¯¼ï¼Œè§„èŒƒé«˜æ–¯ä¸é€æ˜åº¦åœºï¼Œæé«˜å‡ ä½•çº¦æŸï¼Œæ”¹å–„è¡¨é¢é‡å»ºè´¨é‡ã€‚å»ºç«‹å…³èŠ‚å‹å¯¹è±¡çš„å˜å½¢åœºï¼Œå®ç°æœªè§çŠ¶æ€çš„è¡¨é¢ç½‘æ ¼æ— ç›‘ç£ç”Ÿæˆã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†ç»™å®šçŠ¶æ€çš„é«˜è´¨é‡çº¹ç†è¡¨é¢é‡å»ºï¼Œå¹¶ä¸ºæœªè§çŠ¶æ€å®ç°äº†é«˜ä¿çœŸè¡¨é¢ç”Ÿæˆã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>REArtGSæ¡†æ¶ç”¨äºå…³èŠ‚å‹å¯¹è±¡çš„3Dè¡¨ç¤ºä¸­ï¼Œå®ç°é«˜è´¨é‡çº¹ç†è¡¨é¢é‡å»ºå’Œç”Ÿæˆã€‚</li>
<li>é€šè¿‡å¼•å…¥é¢å¤–çš„å‡ ä½•å’Œè¿åŠ¨çº¦æŸåˆ°3Dé«˜æ–¯åŸå§‹æ¨¡å‹ï¼Œæé«˜è¡¨é¢é‡å»ºè´¨é‡ã€‚</li>
<li>ä½¿ç”¨å¤šè§†è§’RGBå›¾åƒï¼Œå¯¹å…³èŠ‚å‹å¯¹è±¡çš„ä»»æ„ä¸¤ç§çŠ¶æ€è¿›è¡Œæ— åå¸¦ç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰å¼•å¯¼ã€‚</li>
<li>å»ºç«‹å…³èŠ‚å‹å¯¹è±¡çš„å˜å½¢åœºï¼Œå®ç°æœªè§çŠ¶æ€çš„è¡¨é¢ç½‘æ ¼æ— ç›‘ç£ç”Ÿæˆã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œå®ç°äº†ç»™å®šçŠ¶æ€çš„é«˜è´¨é‡çº¹ç†è¡¨é¢é‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•è¿˜ä¸ºæœªè§çŠ¶æ€å®ç°äº†é«˜ä¿çœŸè¡¨é¢ç”Ÿæˆã€‚</li>
<li>å°†åœ¨æœªæ¥å››ä¸ªæœˆå†…å‘å¸ƒä»£ç ï¼Œé¡¹ç›®ç½‘ç«™ä¸º[ç½‘ç«™é“¾æ¥]ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06677">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.06677v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.06677v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.06677v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.06677v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="DoF-Gaussian-Controllable-Depth-of-Field-for-3D-Gaussian-Splatting"><a href="#DoF-Gaussian-Controllable-Depth-of-Field-for-3D-Gaussian-Splatting" class="headerlink" title="DoF-Gaussian: Controllable Depth-of-Field for 3D Gaussian Splatting"></a>DoF-Gaussian: Controllable Depth-of-Field for 3D Gaussian Splatting</h2><p><strong>Authors:Liao Shen, Tianqi Liu, Huiqiang Sun, Jiaqi Li, Zhiguo Cao, Wei Li, Chen Change Loy</strong></p>
<p>Recent advances in 3D Gaussian Splatting (3D-GS) have shown remarkable success in representing 3D scenes and generating high-quality, novel views in real-time. However, 3D-GS and its variants assume that input images are captured based on pinhole imaging and are fully in focus. This assumption limits their applicability, as real-world images often feature shallow depth-of-field (DoF). In this paper, we introduce DoF-Gaussian, a controllable depth-of-field method for 3D-GS. We develop a lens-based imaging model based on geometric optics principles to control DoF effects. To ensure accurate scene geometry, we incorporate depth priors adjusted per scene, and we apply defocus-to-focus adaptation to minimize the gap in the circle of confusion. We also introduce a synthetic dataset to assess refocusing capabilities and the modelâ€™s ability to learn precise lens parameters. Our framework is customizable and supports various interactive applications. Extensive experiments confirm the effectiveness of our method. Our project is available at <a target="_blank" rel="noopener" href="https://dof-gaussian.github.io/">https://dof-gaussian.github.io</a>. </p>
<blockquote>
<p>è¿‘æœŸä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3D-GSï¼‰çš„è¿›å±•åœ¨è¡¨ç¤ºä¸‰ç»´åœºæ™¯å’Œå®æ—¶ç”Ÿæˆé«˜è´¨é‡ã€æ–°é¢–è§†å›¾æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œ3D-GSåŠå…¶å˜ç§å‡è®¾è¾“å…¥å›¾åƒæ˜¯åŸºäºé’ˆå­”æˆåƒæ•è·çš„ï¼Œå¹¶ä¸”å®Œå…¨åœ¨ç„¦ç‚¹ä¸Šã€‚è¿™ä¸€å‡è®¾é™åˆ¶äº†å…¶é€‚ç”¨æ€§ï¼Œå› ä¸ºç°å®ä¸–ç•Œä¸­çš„å›¾åƒé€šå¸¸å…·æœ‰è¾ƒæµ…çš„æ™¯æ·±ï¼ˆDoFï¼‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†DoF-Gaussianï¼Œè¿™æ˜¯ä¸€ç§å¯æ§æ™¯æ·±çš„ä¸‰ç»´é«˜æ–¯æ‹¼è´´æ–¹æ³•ã€‚æˆ‘ä»¬åŸºäºå‡ ä½•å…‰å­¦åŸç†å¼€å‘äº†ä¸€ç§åŸºäºé•œå¤´çš„æˆåƒæ¨¡å‹æ¥æ§åˆ¶æ™¯æ·±æ•ˆåº”ã€‚ä¸ºäº†ç¡®ä¿åœºæ™¯å‡ ä½•çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬æ ¹æ®åœºæ™¯è°ƒæ•´äº†æ·±åº¦å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶åº”ç”¨äº†å¤±ç„¦åˆ°èšç„¦çš„é€‚åº”æ¥å‡å°‘æ¨¡ç³Šåœ†ä¹‹é—´çš„é—´éš™ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªåˆæˆæ•°æ®é›†æ¥è¯„ä¼°é‡æ–°å¯¹ç„¦èƒ½åŠ›å’Œæ¨¡å‹å­¦ä¹ ç²¾ç¡®é•œå¤´å‚æ•°çš„èƒ½åŠ›.æˆ‘ä»¬çš„æ¡†æ¶æ˜¯å®šåˆ¶åŒ–çš„ï¼Œæ”¯æŒå„ç§äº¤äº’å¼åº”ç”¨ç¨‹åºã€‚å¤§é‡å®éªŒè¯å®äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„é¡¹ç›®å¯åœ¨<a target="_blank" rel="noopener" href="https://dof-gaussian.github.ioæ‰¾åˆ°./">https://dof-gaussian.github.ioæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.00746v2">PDF</a> CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡é’ˆå¯¹ä¸‰ç»´é«˜æ–¯ç‚¹æ‰©å±•ï¼ˆ3D-GSï¼‰çš„æœ€æ–°è¿›å±•è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„å¯æ§æ·±åº¦è§†é‡æ–¹æ³•â€”â€”DoF-Gaussianã€‚è®ºæ–‡å¼•å…¥äº†åŸºäºå‡ ä½•å…‰å­¦åŸç†çš„é•œå¤´æˆåƒæ¨¡å‹æ¥æ§åˆ¶æ·±åº¦è§†é‡æ•ˆåº”ï¼Œå¹¶ç»“åˆåœºæ™¯æ·±åº¦å…ˆéªŒè¿›è¡Œæ·±åº¦è°ƒæ•´ï¼Œå®ç°äº†ä»å¤±ç„¦åˆ°èšç„¦çš„é€‚åº”ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªåˆæˆæ•°æ®é›†æ¥è¯„ä¼°æ¨¡å‹çš„é‡æ–°èšç„¦èƒ½åŠ›å’Œç²¾ç¡®é•œå¤´å‚æ•°çš„å­¦ä¹ èƒ½åŠ›ã€‚è¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„å¯å®šåˆ¶æ€§ï¼Œæ”¯æŒå„ç§äº¤äº’å¼åº”ç”¨ï¼Œå¹¶é€šè¿‡å¹¿æ³›çš„å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡é’ˆå¯¹ä¸‰ç»´é«˜æ–¯ç‚¹æ‰©å±•ï¼ˆ3D-GSï¼‰æŠ€æœ¯è¿›è¡Œäº†æ”¹è¿›ï¼Œè§£å†³äº†å…¶åœ¨å¤„ç†çœŸå®ä¸–ç•Œå›¾åƒæ—¶å­˜åœ¨çš„å±€é™æ€§ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„å¯æ§æ·±åº¦è§†é‡æ–¹æ³•â€”â€”DoF-Gaussianï¼Œè¯¥æ–¹æ³•åŸºäºå‡ ä½•å…‰å­¦åŸç†çš„é•œå¤´æˆåƒæ¨¡å‹æ¥æ§åˆ¶æ·±åº¦è§†é‡æ•ˆåº”ã€‚</li>
<li>ç»“åˆåœºæ™¯æ·±åº¦å…ˆéªŒè¿›è¡Œæ·±åº¦è°ƒæ•´ï¼Œä»¥å®ç°ä»å¤±ç„¦åˆ°èšç„¦çš„é€‚åº”ã€‚</li>
<li>å¼•å…¥åˆæˆæ•°æ®é›†ç”¨äºè¯„ä¼°æ¨¡å‹çš„é‡æ–°èšç„¦èƒ½åŠ›å’Œç²¾ç¡®é•œå¤´å‚æ•°çš„å­¦ä¹ èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„å¯å®šåˆ¶æ€§ï¼Œé€‚ç”¨äºå„ç§äº¤äº’å¼åº”ç”¨ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.00746">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.00746v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.00746v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.00746v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.00746v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.00746v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2503.00746v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="TrackGS-Optimizing-COLMAP-Free-3D-Gaussian-Splatting-with-Global-Track-Constraints"><a href="#TrackGS-Optimizing-COLMAP-Free-3D-Gaussian-Splatting-with-Global-Track-Constraints" class="headerlink" title="TrackGS: Optimizing COLMAP-Free 3D Gaussian Splatting with Global Track   Constraints"></a>TrackGS: Optimizing COLMAP-Free 3D Gaussian Splatting with Global Track   Constraints</h2><p><strong>Authors:Dongbo Shi, Shen Cao, Lubin Fan, Bojian Wu, Jinhui Guo, Renjie Chen, Ligang Liu, Jieping Ye</strong></p>
<p>While 3D Gaussian Splatting (3DGS) has advanced ability on novel view synthesis, it still depends on accurate pre-computaed camera parameters, which are hard to obtain and prone to noise. Previous COLMAP-Free methods optimize camera poses using local constraints, but they often struggle in complex scenarios. To address this, we introduce TrackGS, which incorporates feature tracks to globally constrain multi-view geometry. We select the Gaussians associated with each track, which will be trained and rescaled to an infinitesimally small size to guarantee the spatial accuracy. We also propose minimizing both reprojection and backprojection errors for better geometric consistency. Moreover, by deriving the gradient of intrinsics, we unify camera parameter estimation with 3DGS training into a joint optimization framework, achieving SOTA performance on challenging datasets with severe camera movements. </p>
<blockquote>
<p>å°½ç®¡3Dé«˜æ–¯æ‹¼æ¥ï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢å…·å¤‡é«˜çº§èƒ½åŠ›ï¼Œä½†å®ƒä»ç„¶ä¾èµ–äºéš¾ä»¥è·å–ä¸”æ˜“å‡ºé”™çš„äº‹å…ˆè®¡ç®—å¥½çš„ç›¸æœºå‚æ•°ã€‚ä¹‹å‰çš„COLMAP-Freeæ–¹æ³•é€šè¿‡ä½¿ç”¨å±€éƒ¨çº¦æŸä¼˜åŒ–ç›¸æœºå§¿æ€ï¼Œä½†åœ¨å¤æ‚åœºæ™¯ä¸­ç»å¸¸è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†TrackGSï¼Œå®ƒé€šè¿‡ç‰¹å¾è½¨è¿¹å¯¹å¤šè§†å›¾å‡ ä½•è¿›è¡Œå…¨å±€çº¦æŸã€‚æˆ‘ä»¬é€‰æ‹©ä¸æ¯æ¡è½¨è¿¹ç›¸å…³çš„é«˜æ–¯ï¼Œå¹¶å°†å…¶è®­ç»ƒå’Œé‡æ–°ç¼©æ”¾åˆ°æ— ç©·å°çš„å°ºå¯¸ï¼Œä»¥ä¿è¯ç©ºé—´ç²¾åº¦ã€‚æˆ‘ä»¬è¿˜æå‡ºæœ€å°åŒ–é‡æŠ•å½±å’Œåå‘æŠ•å½±è¯¯å·®ï¼Œä»¥æ›´å¥½åœ°å®ç°å‡ ä½•ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¨å¯¼å†…å‚çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬å°†ç›¸æœºå‚æ•°ä¼°è®¡ä¸3DGSè®­ç»ƒç»Ÿä¸€åˆ°ä¸€ä¸ªè”åˆä¼˜åŒ–æ¡†æ¶ä¸­ï¼Œåœ¨å…·æœ‰å‰§çƒˆç›¸æœºè¿åŠ¨çš„æŒ‘æˆ˜æ•°æ®é›†ä¸Šå®ç°äº†SOTAæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19800v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ‘˜è¦æåˆ°ï¼Œå°½ç®¡ä¸‰ç»´é«˜æ–¯è†¨èƒ€æ³•ï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†è§’åˆæˆæ–¹é¢å…·æœ‰å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶ä»ç„¶ä¾èµ–äºéš¾ä»¥è·å–ä¸”æ˜“å—å™ªå£°å¹²æ‰°çš„é¢„å…ˆè®¡ç®—çš„ç›¸æœºå‚æ•°ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« å¼•å…¥äº†TrackGSï¼Œå®ƒç»“åˆäº†ç‰¹å¾è½¨è¿¹æ¥å…¨å±€çº¦æŸå¤šè§†è§’å‡ ä½•ã€‚é€šè¿‡é€‰æ‹©æ¯ä¸ªè½¨è¿¹ç›¸å…³çš„é«˜æ–¯å¹¶è¿›è¡Œè®­ç»ƒå’Œç¼©æ”¾è‡³æ— ç©·å°çš„å°ºå¯¸ï¼Œä»¥ç¡®ä¿ç©ºé—´ç²¾åº¦ã€‚åŒæ—¶ï¼Œæœ€å°åŒ–é‡æŠ•å½±å’Œåå‘æŠ•å½±è¯¯å·®ä»¥å®ç°æ›´å¥½çš„å‡ ä½•ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¨å¯¼å†…å‚çš„æ¢¯åº¦ï¼Œå°†ç›¸æœºå‚æ•°ä¼°è®¡ä¸ä¸‰ç»´é«˜æ–¯è†¨èƒ€è®­ç»ƒç»“åˆåˆ°ä¸€ä¸ªè”åˆä¼˜åŒ–æ¡†æ¶ä¸­ï¼Œå®ç°åœ¨å…·æœ‰ä¸¥é‡ç›¸æœºè¿åŠ¨çš„æŒ‘æˆ˜æ•°æ®é›†ä¸Šçš„å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TrackGSç»“åˆäº†ç‰¹å¾è½¨è¿¹è¿›è¡Œå…¨å±€çš„å¤šè§†è§’å‡ ä½•çº¦æŸï¼Œä»¥æé«˜ç©ºé—´ç²¾åº¦ã€‚</li>
<li>é€šè¿‡é€‰æ‹©æ¯ä¸ªè½¨è¿¹ç›¸å…³çš„é«˜æ–¯å¹¶è¿›è¡Œè®­ç»ƒå’Œç¼©æ”¾è‡³æ— ç©·å°å°ºå¯¸æ¥å¤„ç†å™ªå£°é—®é¢˜ã€‚</li>
<li>åŒæ—¶ä¼˜åŒ–é‡æŠ•å½±å’Œåå‘æŠ•å½±è¯¯å·®ä»¥æ”¹å–„å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>ç›¸æœºå‚æ•°ä¼°è®¡ä¸ä¸‰ç»´é«˜æ–¯è†¨èƒ€è®­ç»ƒçš„è”åˆä¼˜åŒ–æé«˜äº†æŒ‘æˆ˜æ•°æ®é›†çš„ä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†å¯¹å…·æœ‰ä¸¥é‡ç›¸æœºè¿åŠ¨çš„æ•°æ®é›†çš„æœ‰æ•ˆå¤„ç†ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†å…ˆå‰COLMAP-Freeæ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­çš„ä¼˜åŒ–é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.19800v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.19800v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.19800v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.19800v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="AutoOcc-Automatic-Open-Ended-Semantic-Occupancy-Annotation-via-Vision-Language-Guided-Gaussian-Splatting"><a href="#AutoOcc-Automatic-Open-Ended-Semantic-Occupancy-Annotation-via-Vision-Language-Guided-Gaussian-Splatting" class="headerlink" title="AutoOcc: Automatic Open-Ended Semantic Occupancy Annotation via   Vision-Language Guided Gaussian Splatting"></a>AutoOcc: Automatic Open-Ended Semantic Occupancy Annotation via   Vision-Language Guided Gaussian Splatting</h2><p><strong>Authors:Xiaoyu Zhou, Jingqi Wang, Yongtao Wang, Yufei Wei, Nan Dong, Ming-Hsuan Yang</strong></p>
<p>Obtaining high-quality 3D semantic occupancy from raw sensor data remains an essential yet challenging task, often requiring extensive manual labeling. In this work, we propose AutoOcc, an vision-centric automated pipeline for open-ended semantic occupancy annotation that integrates differentiable Gaussian splatting guided by vision-language models. We formulate the open-ended semantic occupancy reconstruction task to automatically generate scene occupancy by combining attention maps from vision-language models and foundation vision models. We devise semantic-aware Gaussians as intermediate geometric descriptors and propose a cumulative Gaussian-to-voxel splatting algorithm that enables effective and efficient occupancy annotation. Our framework outperforms existing automated occupancy annotation methods without human labels. AutoOcc also enables open-ended semantic occupancy auto-labeling, achieving robust performance in both static and dynamically complex scenarios. All the source codes and trained models will be released. </p>
<blockquote>
<p>ä»åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®è·å–é«˜è´¨é‡3Dè¯­ä¹‰å ç”¨ä»ç„¶æ˜¯ä¸€é¡¹åŸºæœ¬ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†AutoOccï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„å¼€æ”¾å¼è¯­ä¹‰å ç”¨æ³¨é‡Šè‡ªåŠ¨åŒ–ç®¡é“ï¼Œå®ƒé›†æˆäº†ç”±è§†è§‰è¯­è¨€æ¨¡å‹å¼•å¯¼çš„å¯å¾®é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯ã€‚æˆ‘ä»¬å°†å¼€æ”¾å¼è¯­ä¹‰å ç”¨é‡å»ºä»»åŠ¡åˆ¶å®šä¸ºé€šè¿‡ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹å’ŒåŸºç¡€è§†è§‰æ¨¡å‹çš„æ³¨æ„åŠ›å›¾æ¥è‡ªåŠ¨ç”Ÿæˆåœºæ™¯å ç”¨ã€‚æˆ‘ä»¬è®¾è®¡è¯­ä¹‰æ„ŸçŸ¥é«˜æ–¯ä½œä¸ºä¸­é—´å‡ ä½•æè¿°ç¬¦ï¼Œå¹¶æå‡ºç´¯ç§¯é«˜æ–¯åˆ°ä½“ç´ æ¶‚æŠ¹ç®—æ³•ï¼Œä»¥å®ç°æœ‰æ•ˆå’Œé«˜æ•ˆçš„å ç”¨æ³¨é‡Šã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨ä¸éœ€è¦äººå·¥æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œä¼˜äºç°æœ‰çš„è‡ªåŠ¨å ç”¨æ³¨é‡Šæ–¹æ³•ã€‚AutoOccè¿˜å®ç°äº†å¼€æ”¾å¼è¯­ä¹‰å ç”¨çš„è‡ªåŠ¨æ ‡æ³¨ï¼Œåœ¨é™æ€å’ŒåŠ¨æ€å¤æ‚åœºæ™¯ä¸­å‡è¡¨ç°å‡ºç¨³å¥çš„æ€§èƒ½ã€‚æ‰€æœ‰æºä»£ç å’Œè®­ç»ƒè¿‡çš„æ¨¡å‹éƒ½å°†è¢«å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04981v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶æå‡ºäº†AutoOccï¼Œä¸€ä¸ªä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„è‡ªåŠ¨åŒ–ç®¡é“ï¼Œç”¨äºå¼€æ”¾å¼è¯­ä¹‰å ç”¨æ ‡æ³¨ã€‚è¯¥ç®¡é“ç»“åˆäº†å¯å¾®åˆ†çš„Gaussian splattingå’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œè‡ªåŠ¨åŒ–ç”Ÿæˆåœºæ™¯å ç”¨ä¿¡æ¯ã€‚é€šè¿‡è®¾è®¡è¯­ä¹‰æ„ŸçŸ¥çš„Gaussiansä½œä¸ºä¸­é—´å‡ ä½•æè¿°ç¬¦ï¼Œä»¥åŠæå‡ºä¸€ç§ç´¯ç§¯çš„Gaussian-to-voxel splattingç®—æ³•ï¼Œå®ç°äº†æœ‰æ•ˆä¸”é«˜æ•ˆçš„å ç”¨æ ‡æ³¨ã€‚AutoOccæ¡†æ¶åœ¨æ— éœ€äººå·¥æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ç°æœ‰çš„è‡ªåŠ¨åŒ–å ç”¨æ ‡æ³¨æ–¹æ³•ï¼Œå¹¶å®ç°äº†å¼€æ”¾å¼è¯­ä¹‰å ç”¨çš„è‡ªåŠ¨æ ‡æ³¨ï¼Œåœ¨é™æ€å’ŒåŠ¨æ€å¤æ‚åœºæ™¯ä¸­å‡è¡¨ç°å‡ºç¨³å¥æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„è‡ªåŠ¨åŒ–ç®¡é“AutoOccï¼Œç”¨äºå¼€æ”¾å¼è¯­ä¹‰å ç”¨æ ‡æ³¨ã€‚</li>
<li>è¯¥ç®¡é“é›†æˆäº†å¯å¾®åˆ†çš„Gaussian splattingå’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä»¥è‡ªåŠ¨åŒ–ç”Ÿæˆåœºæ™¯å ç”¨ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡è®¾è®¡è¯­ä¹‰æ„ŸçŸ¥çš„Gaussiansä½œä¸ºä¸­é—´å‡ ä½•æè¿°ç¬¦ï¼Œæé«˜äº†æ ‡æ³¨çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç´¯ç§¯çš„Gaussian-to-voxel splattingç®—æ³•ï¼Œå®ç°äº†æœ‰æ•ˆä¸”é«˜æ•ˆçš„å ç”¨æ ‡æ³¨ã€‚</li>
<li>AutoOccæ¡†æ¶åœ¨æ— éœ€äººå·¥æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ç°æœ‰çš„è‡ªåŠ¨åŒ–å ç”¨æ ‡æ³¨æ–¹æ³•ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿå®ç°å¼€æ”¾å¼è¯­ä¹‰å ç”¨çš„è‡ªåŠ¨æ ‡æ³¨ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04981">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.04981v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.04981v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.04981v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.04981v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.04981v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2502.04981v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Generalized-and-Efficient-2D-Gaussian-Splatting-for-Arbitrary-scale-Super-Resolution"><a href="#Generalized-and-Efficient-2D-Gaussian-Splatting-for-Arbitrary-scale-Super-Resolution" class="headerlink" title="Generalized and Efficient 2D Gaussian Splatting for Arbitrary-scale   Super-Resolution"></a>Generalized and Efficient 2D Gaussian Splatting for Arbitrary-scale   Super-Resolution</h2><p><strong>Authors:Du Chen, Liyi Chen, Zhengqiang Zhang, Lei Zhang</strong></p>
<p>Implicit Neural Representation (INR) has been successfully employed for Arbitrary-scale Super-Resolution (ASR). However, INR-based models need to query the multi-layer perceptron module numerous times and render a pixel in each query, resulting in insufficient representation capability and computational efficiency. Recently, Gaussian Splatting (GS) has shown its advantages over INR in both visual quality and rendering speed in 3D tasks, which motivates us to explore whether GS can be employed for the ASR task. However, directly applying GS to ASR is exceptionally challenging because the original GS is an optimization-based method through overfitting each single scene, while in ASR we aim to learn a single model that can generalize to different images and scaling factors. We overcome these challenges by developing two novel techniques. Firstly, to generalize GS for ASR, we elaborately design an architecture to predict the corresponding image-conditioned Gaussians of the input low-resolution image in a feed-forward manner. Each Gaussian can fit the shape and direction of an area of complex textures, showing powerful representation capability. Secondly, we implement an efficient differentiable 2D GPU&#x2F;CUDA-based scale-aware rasterization to render super-resolved images by sampling discrete RGB values from the predicted continuous Gaussians. Via end-to-end training, our optimized network, namely GSASR, can perform ASR for any image and unseen scaling factors. Extensive experiments validate the effectiveness of our proposed method. </p>
<blockquote>
<p>éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºï¼ˆINRï¼‰å·²æˆåŠŸåº”ç”¨äºä»»æ„å°ºåº¦è¶…åˆ†è¾¨ç‡ï¼ˆASRï¼‰ã€‚ç„¶è€Œï¼ŒåŸºäºINRçš„æ¨¡å‹éœ€è¦å¤šæ¬¡æŸ¥è¯¢å¤šå±‚æ„ŸçŸ¥å™¨æ¨¡å—ï¼Œå¹¶åœ¨æ¯æ¬¡æŸ¥è¯¢ä¸­å‘ˆç°ä¸€ä¸ªåƒç´ ï¼Œå¯¼è‡´è¡¨ç¤ºèƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ä¸è¶³ã€‚æœ€è¿‘ï¼Œé«˜æ–¯å–·æ¶‚ï¼ˆGSï¼‰åœ¨3Dä»»åŠ¡çš„è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢æ˜¾ç¤ºå‡ºå…¶ç›¸å¯¹äºINRçš„ä¼˜åŠ¿ï¼Œè¿™æ¿€åŠ±æˆ‘ä»¬æ¢ç´¢æ˜¯å¦å¯ä»¥ä½¿ç”¨GSè¿›è¡ŒASRä»»åŠ¡ã€‚ç„¶è€Œï¼Œç›´æ¥å°†GSåº”ç”¨äºASRå…·æœ‰æå¤§çš„æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºåŸå§‹çš„GSæ˜¯ä¸€ç§åŸºäºä¼˜åŒ–çš„æ–¹æ³•ï¼Œé€šè¿‡è¿‡åº¦æ‹Ÿåˆæ¯ä¸ªå•ä¸€åœºæ™¯ï¼Œè€Œåœ¨ASRä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å­¦ä¹ ä¸€ä¸ªå¯ä»¥æ¨å¹¿åˆ°ä¸åŒå›¾åƒå’Œç¼©æ”¾å› å­çš„æ¨¡å‹ã€‚æˆ‘ä»¬é€šè¿‡å¼€å‘ä¸¤ç§æ–°æŠ€æœ¯æ¥å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œä¸ºäº†å°†GSæ¨å¹¿åˆ°ASRï¼Œæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸€ç§æ¶æ„ï¼Œä»¥å‰é¦ˆæ–¹å¼é¢„æµ‹è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒå¯¹åº”çš„å›¾åƒæ¡ä»¶é«˜æ–¯åˆ†å¸ƒã€‚æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒéƒ½èƒ½é€‚åº”å¤æ‚çº¹ç†åŒºåŸŸçš„å½¢çŠ¶å’Œæ–¹å‘ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç§é«˜æ•ˆçš„å¯å¾®åˆ†2D GPU&#x2F;CUDAåŸºå°ºåº¦æ„ŸçŸ¥å…‰æ …åŒ–ï¼Œé€šè¿‡ä»é¢„æµ‹çš„æŒç»­é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ç¦»æ•£RGBå€¼æ¥å‘ˆç°è¶…åˆ†è¾¨ç‡å›¾åƒã€‚é€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„ç½‘ç»œï¼Œå³GSASRï¼Œå¯ä»¥å¯¹ä»»ä½•å›¾åƒå’Œæœªè§çš„ç¼©æ”¾å› å­æ‰§è¡ŒASRã€‚å¤§é‡çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06838v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å°†é«˜æ–¯è´´å›¾ï¼ˆGSï¼‰æŠ€æœ¯åº”ç”¨äºä»»æ„å°ºåº¦è¶…åˆ†è¾¨ç‡ï¼ˆASRï¼‰ä»»åŠ¡çš„æŒ‘æˆ˜åŠè§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹GSåœ¨ASRåº”ç”¨ä¸­çš„ä¼˜åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸¤ç§æ–°æŠ€æœ¯ï¼šä¸€æ˜¯è®¾è®¡äº†ä¸€ç§å‰é¦ˆç½‘ç»œæ¶æ„ï¼Œç”¨äºé¢„æµ‹è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒçš„æ¡ä»¶é«˜æ–¯åˆ†å¸ƒï¼›äºŒæ˜¯å®ç°äº†é«˜æ•ˆçš„äºŒç»´GPU&#x2F;CUDAå¯å¾®åˆ†å°ºåº¦æ„ŸçŸ¥æ¸²æŸ“æŠ€æœ¯ï¼Œç”¨äºä»é¢„æµ‹çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ç”Ÿæˆè¶…åˆ†è¾¨ç‡å›¾åƒã€‚å®éªŒç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>INRåœ¨ASRä»»åŠ¡ä¸­çš„åº”ç”¨é¢ä¸´è®¡ç®—æ•ˆç‡å’Œè¡¨ç¤ºèƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>GSåœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢åœ¨3Dä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œä½†åœ¨ASRä»»åŠ¡ä¸­ç›´æ¥åº”ç”¨å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>ä¸ºå…‹æœæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸¤ç§æ–°æŠ€æœ¯ï¼šè®¾è®¡å‰é¦ˆç½‘ç»œæ¶æ„é¢„æµ‹ä½åˆ†è¾¨ç‡å›¾åƒçš„æ¡ä»¶é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶å®ç°é«˜æ•ˆçš„å°ºåº¦æ„ŸçŸ¥æ¸²æŸ“æŠ€æœ¯ã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒï¼Œèƒ½å¤Ÿé’ˆå¯¹ä»»æ„å›¾åƒå’Œæœªè§è¿‡çš„ç¼©æ”¾å› å­è¿›è¡ŒASRã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06838">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.06838v4/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.06838v4/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.06838v4/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.06838v4/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.06838v4/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.06838v4/page_5_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Locality-aware-Gaussian-Compression-for-Fast-and-High-quality-Rendering"><a href="#Locality-aware-Gaussian-Compression-for-Fast-and-High-quality-Rendering" class="headerlink" title="Locality-aware Gaussian Compression for Fast and High-quality Rendering"></a>Locality-aware Gaussian Compression for Fast and High-quality Rendering</h2><p><strong>Authors:Seungjoo Shin, Jaesik Park, Sunghyun Cho</strong></p>
<p>We present LocoGS, a locality-aware 3D Gaussian Splatting (3DGS) framework that exploits the spatial coherence of 3D Gaussians for compact modeling of volumetric scenes. To this end, we first analyze the local coherence of 3D Gaussian attributes, and propose a novel locality-aware 3D Gaussian representation that effectively encodes locally-coherent Gaussian attributes using a neural field representation with a minimal storage requirement. On top of the novel representation, LocoGS is carefully designed with additional components such as dense initialization, an adaptive spherical harmonics bandwidth scheme and different encoding schemes for different Gaussian attributes to maximize compression performance. Experimental results demonstrate that our approach outperforms the rendering quality of existing compact Gaussian representations for representative real-world 3D datasets while achieving from 54.6$\times$ to 96.6$\times$ compressed storage size and from 2.1$\times$ to 2.4$\times$ rendering speed than 3DGS. Even our approach also demonstrates an averaged 2.4$\times$ higher rendering speed than the state-of-the-art compression method with comparable compression performance. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†LocoGSï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå±€éƒ¨æ„ŸçŸ¥çš„3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨3Dé«˜æ–¯çš„ç©ºé—´è¿è´¯æ€§å¯¹ä½“ç§¯åœºæ™¯è¿›è¡Œç´§å‡‘å»ºæ¨¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ†æäº†3Dé«˜æ–¯å±æ€§çš„å±€éƒ¨è¿è´¯æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°å‹çš„å±€éƒ¨æ„ŸçŸ¥çš„3Dé«˜æ–¯è¡¨ç¤ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨å…·æœ‰æœ€å°å­˜å‚¨è¦æ±‚çš„ç¥ç»åœºè¡¨ç¤ºæ³•æœ‰æ•ˆåœ°ç¼–ç å±€éƒ¨è¿è´¯çš„é«˜æ–¯å±æ€§ã€‚åŸºäºè¿™ç§æ–°å‹è¡¨ç¤ºæ–¹æ³•ï¼ŒLocoGSç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œé…å¤‡äº†å¯†é›†åˆå§‹åŒ–ã€è‡ªé€‚åº”çƒé¢è°æ³¢å¸¦å®½æ–¹æ¡ˆä»¥åŠé’ˆå¯¹ä¸åŒé«˜æ–¯å±æ€§çš„ä¸åŒç¼–ç æ–¹æ¡ˆç­‰é¢å¤–ç»„ä»¶ï¼Œä»¥æœ€å¤§åŒ–å‹ç¼©æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰ä»£è¡¨æ€§çš„çœŸå®ä¸–ç•Œ3Dæ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒäºç°æœ‰çš„ç´§å‡‘é«˜æ–¯è¡¨ç¤ºæ–¹æ³•ï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶å®ç°äº†ä»54.6å€åˆ°96.6å€çš„å‹ç¼©å­˜å‚¨å¤§å°å’Œä»2.1å€åˆ°2.4å€çš„æ¸²æŸ“é€Ÿåº¦æå‡ã€‚å³ä½¿ä¸å…·æœ‰ç±»ä¼¼å‹ç¼©æ€§èƒ½çš„æœ€å…ˆè¿›å‹ç¼©æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿè¡¨ç°å‡ºäº†å¹³å‡é«˜å‡º2.4å€çš„æ¸²æŸ“é€Ÿåº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05757v3">PDF</a> Accepted to ICLR 2025. Project page:   <a target="_blank" rel="noopener" href="https://seungjooshin.github.io/LocoGS">https://seungjooshin.github.io/LocoGS</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†LocoGSï¼Œä¸€ç§åŸºäºç©ºé—´æ„ŸçŸ¥çš„3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰æ¡†æ¶ã€‚å®ƒé€šè¿‡åˆ©ç”¨3Dé«˜æ–¯çš„ç©ºé—´ä¸€è‡´æ€§ï¼Œå®ç°äº†å¯¹ä½“ç§¯åœºæ™¯çš„æœ‰æ•ˆå»ºæ¨¡ã€‚é€šè¿‡å¼•å…¥å±€éƒ¨æ„ŸçŸ¥çš„3Dé«˜æ–¯è¡¨ç¤ºæ³•ï¼Œå®ç°äº†å¯¹å±€éƒ¨ä¸€è‡´çš„é«˜æ–¯å±æ€§çš„é«˜æ•ˆç¼–ç ï¼Œä»è€Œåœ¨ä¿è¯æ¸²æŸ“è´¨é‡çš„åŒæ—¶é™ä½äº†å­˜å‚¨éœ€æ±‚ã€‚è¯¥æ¡†æ¶è¿˜åŒ…æ‹¬å¯†é›†åˆå§‹åŒ–ã€è‡ªé€‚åº”çƒé¢è°æ³¢å¸¦å®½æ–¹æ¡ˆç­‰ç»„ä»¶ï¼Œç”¨äºè¿›ä¸€æ­¥ä¼˜åŒ–å‹ç¼©æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒLocoGSåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶å‹ç¼©å­˜å‚¨å¤§å°å‡å°‘äº†54.6å€è‡³96.6å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜äº†2.1å€è‡³2.4å€ã€‚ç›¸è¾ƒäºå…¶ä»–åŒç±»æ–¹æ³•ï¼Œå…¶åœ¨ç›¸è¿‘å‹ç¼©æ€§èƒ½ä¸‹æ¸²æŸ“é€Ÿåº¦æé«˜äº†å¹³å‡2.4å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LocoGSæ˜¯ä¸€ç§åŸºäºç©ºé—´æ„ŸçŸ¥çš„3Dé«˜æ–¯èåˆæ¡†æ¶ï¼Œç”¨äºä½“ç§¯åœºæ™¯çš„ç´§å‡‘å»ºæ¨¡ã€‚</li>
<li>å¼•å…¥å±€éƒ¨æ„ŸçŸ¥çš„3Dé«˜æ–¯è¡¨ç¤ºæ³•ï¼Œå®ç°å¯¹å±€éƒ¨ä¸€è‡´çš„é«˜æ–¯å±æ€§çš„é«˜æ•ˆç¼–ç ã€‚</li>
<li>é€šè¿‡ç¥ç»ç½‘ç»œåœºè¡¨ç¤ºæ³•å®ç°æœ€å°å­˜å‚¨éœ€æ±‚çš„æœ‰æ•ˆç¼–ç ã€‚</li>
<li>LocoGSåŒ…æ‹¬å¯†é›†åˆå§‹åŒ–ã€è‡ªé€‚åº”çƒé¢è°æ³¢å¸¦å®½æ–¹æ¡ˆç­‰ç»„ä»¶ä»¥ä¼˜åŒ–å‹ç¼©æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºLocoGSåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°é«˜æ¸²æŸ“è´¨é‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>LocoGSåœ¨å‹ç¼©å­˜å‚¨å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œå‹ç¼©æ¯”è¾¾åˆ°54.6å€è‡³96.6å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜2.1å€è‡³2.4å€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05757">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.05757v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.05757v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2501.05757v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="FAST-Splat-Fast-Ambiguity-Free-Semantics-Transfer-in-Gaussian-Splatting"><a href="#FAST-Splat-Fast-Ambiguity-Free-Semantics-Transfer-in-Gaussian-Splatting" class="headerlink" title="FAST-Splat: Fast, Ambiguity-Free Semantics Transfer in Gaussian   Splatting"></a>FAST-Splat: Fast, Ambiguity-Free Semantics Transfer in Gaussian   Splatting</h2><p><strong>Authors:Ola Shorinwa, Jiankai Sun, Mac Schwager</strong></p>
<p>We present FAST-Splat for fast, ambiguity-free semantic Gaussian Splatting, which seeks to address the main limitations of existing semantic Gaussian Splatting methods, namely: slow training and rendering speeds; high memory usage; and ambiguous semantic object localization. We take a bottom-up approach in deriving FAST-Splat, dismantling the limitations of closed-set semantic distillation to enable open-set (open-vocabulary) semantic distillation. Ultimately, this key approach enables FAST-Splat to provide precise semantic object localization results, even when prompted with ambiguous user-provided natural-language queries. Further, by exploiting the explicit form of the Gaussian Splatting scene representation to the fullest extent, FAST-Splat retains the remarkable training and rendering speeds of Gaussian Splatting. Precisely, while existing semantic Gaussian Splatting methods distill semantics into a separate neural field or utilize neural models for dimensionality reduction, FAST-Splat directly augments each Gaussian with specific semantic codes, preserving the training, rendering, and memory-usage advantages of Gaussian Splatting over neural field methods. These Gaussian-specific semantic codes, together with a hash-table, enable semantic similarity to be measured with open-vocabulary user prompts and further enable FAST-Splat to respond with unambiguous semantic object labels and $3$D masks, unlike prior methods. In experiments, we demonstrate that FAST-Splat is 6x to 8x faster to train, achieves between 18x to 51x faster rendering speeds, and requires about 6x smaller GPU memory, compared to the best-competing semantic Gaussian Splatting methods. Further, FAST-Splat achieves relatively similar or better semantic segmentation performance compared to existing methods. After the review period, we will provide links to the project website and the codebase. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ç”¨äºå¿«é€Ÿã€æ— æ­§ä¹‰çš„è¯­ä¹‰é«˜æ–¯å±•å¸ƒï¼ˆSemantic Gaussian Splattingï¼‰çš„FAST-Splatæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯­ä¹‰é«˜æ–¯å±•å¸ƒæ–¹æ³•çš„ä¸»è¦å±€é™æ€§ï¼ŒåŒ…æ‹¬ï¼šè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ…¢ã€å†…å­˜ä½¿ç”¨ç‡é«˜ä»¥åŠè¯­ä¹‰å¯¹è±¡å®šä½æ¨¡ç³Šã€‚æˆ‘ä»¬é‡‡ç”¨è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•æ¨å¯¼FAST-Splatï¼Œå…‹æœå°é—­é›†è¯­ä¹‰è’¸é¦çš„å±€é™æ€§ï¼Œå®ç°å¼€æ”¾é›†ï¼ˆå¼€æ”¾è¯æ±‡è¡¨ï¼‰è¯­ä¹‰è’¸é¦ã€‚æœ€ç»ˆï¼Œè¿™ä¸ªå…³é”®æ–¹æ³•ä½¿å¾—FAST-Splatåœ¨æ¥æ”¶åˆ°æ¨¡ç³Šçš„ç”¨æˆ·æä¾›è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ—¶ï¼Œä»èƒ½æä¾›ç²¾ç¡®è¯­ä¹‰å¯¹è±¡å®šä½ç»“æœã€‚æ­¤å¤–ï¼Œé€šè¿‡å……åˆ†åˆ©ç”¨é«˜æ–¯å±•å¸ƒåœºæ™¯è¡¨ç¤ºçš„æ˜¾å¼å½¢å¼ï¼ŒFAST-Splatä¿ç•™äº†é«˜æ–¯å±•å¸ƒåœ¨è®­ç»ƒå’Œæ¸²æŸ“æ–¹é¢çš„å‡ºè‰²é€Ÿåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œç°æœ‰çš„è¯­ä¹‰é«˜æ–¯å±•å¸ƒæ–¹æ³•å°†è¯­ä¹‰è’¸é¦åˆ°å•ç‹¬çš„ç¥ç»ç½‘ç»œåœºæˆ–åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œé™ç»´ï¼Œè€ŒFAST-Splatç›´æ¥åœ¨æ¯ä¸ªé«˜æ–¯ä¸Šå¢åŠ ç‰¹å®šçš„è¯­ä¹‰ä»£ç ï¼Œä¿ç•™äº†é«˜æ–¯å±•å¸ƒåœ¨è®­ç»ƒã€æ¸²æŸ“å’Œå†…å­˜ä½¿ç”¨æ–¹é¢çš„ä¼˜åŠ¿ï¼Œç›¸å¯¹äºç¥ç»ç½‘ç»œåœºæ–¹æ³•ã€‚è¿™äº›ç‰¹å®šäºé«˜æ–¯è¯­ä¹‰ä»£ç ä¸å“ˆå¸Œè¡¨ç›¸ç»“åˆï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä½¿ç”¨å¼€æ”¾è¯æ±‡è¡¨æç¤ºæ¥æµ‹é‡è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œå¹¶è¿›ä¸€æ­¥ä½¿FAST-Splatèƒ½å¤Ÿå“åº”å‡ºæ˜ç¡®çš„è¯­ä¹‰å¯¹è±¡æ ‡ç­¾å’Œä¸‰ç»´æ©ç ï¼Œä¸åŒäºå…ˆå‰çš„æ–¹æ³•ã€‚åœ¨å®éªŒæ–¹é¢ï¼Œæˆ‘ä»¬è¯æ˜äº†FAST-Splatçš„è®­ç»ƒé€Ÿåº¦æ˜¯æœ€ä½³ç«äº‰è¯­ä¹‰é«˜æ–¯å±•å¸ƒæ–¹æ³•çš„6å€è‡³8å€ï¼Œæ¸²æŸ“é€Ÿåº¦è¾¾åˆ°18å€è‡³51å€ï¼Œå¹¶ä¸”æ‰€éœ€çš„GPUå†…å­˜å‡å°‘äº†å¤§çº¦6å€ã€‚æ­¤å¤–ï¼ŒFAST-Splatç›¸è¾ƒäºç°æœ‰æ–¹æ³•å–å¾—äº†ç›¸å½“æˆ–æ›´å¥½çš„è¯­ä¹‰åˆ†å‰²æ€§èƒ½ã€‚è¯„å®¡æœŸè¿‡åï¼Œæˆ‘ä»¬å°†æä¾›é¡¹ç›®ç½‘ç«™å’Œä»£ç åº“çš„é“¾æ¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13753v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†FAST-Splatæ–¹æ³•ï¼Œå®ƒæ˜¯ä¸€ç§å¿«é€Ÿã€æ— æ­§ä¹‰è¯­ä¹‰é«˜æ–¯æ··åˆæŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯­ä¹‰é«˜æ–¯æ··åˆæ–¹æ³•çš„ä¸»è¦å±€é™æ€§ï¼ŒåŒ…æ‹¬è®­ç»ƒä¸æ¸²æŸ“é€Ÿåº¦æ…¢ã€å†…å­˜ä½¿ç”¨é«˜ä»¥åŠè¯­ä¹‰å¯¹è±¡å®šä½æ¨¡ç³Šã€‚FAST-Splaté‡‡å–è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•ï¼Œæ‘’å¼ƒäº†å°é—­é›†è¯­ä¹‰è’¸é¦çš„å±€é™æ€§ï¼Œå®ç°äº†å¼€æ”¾é›†ï¼ˆå¼€æ”¾è¯æ±‡è¡¨ï¼‰è¯­ä¹‰è’¸é¦ã€‚è¯¥æ–¹æ³•èƒ½ç²¾ç¡®è¿›è¡Œè¯­ä¹‰å¯¹è±¡å®šä½ï¼Œå³ä½¿é¢å¯¹ç”¨æˆ·æä¾›çš„æ¨¡ç³Šè‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¹Ÿèƒ½åº”å¯¹ã€‚åŒæ—¶ï¼ŒFAST-Splatå……åˆ†åˆ©ç”¨é«˜æ–¯æ··åˆåœºæ™¯è¡¨ç¤ºçš„æ˜¾å¼å½¢å¼ï¼Œä¿æŒäº†é«˜æ–¯æ··åˆåœ¨è®­ç»ƒä¸æ¸²æŸ“é€Ÿåº¦ä¸Šçš„ä¼˜åŠ¿ã€‚ç›¸æ¯”äºç°æœ‰çš„ç¥ç»åœºæ–¹æ³•ï¼ŒFAST-Splatç›´æ¥å¯¹æ¯ä¸€ä¸ªé«˜æ–¯è¿›è¡Œç‰¹å®šè¯­ä¹‰ç¼–ç ï¼Œä»è€Œåœ¨è®­ç»ƒã€æ¸²æŸ“å’Œå†…å­˜ä½¿ç”¨æ–¹é¢ä¿æŒäº†ä¼˜åŠ¿ã€‚å®éªŒè¡¨æ˜ï¼ŒFAST-Splatçš„è®­ç»ƒé€Ÿåº¦æ˜¯ç°æœ‰æ–¹æ³•çš„6è‡³8å€ï¼Œæ¸²æŸ“é€Ÿåº¦è¾¾åˆ°18è‡³51å€çš„æå‡ï¼ŒGPUå†…å­˜ä½¿ç”¨å‡å°‘çº¦6å€ã€‚åŒæ—¶ï¼ŒFAST-Splatçš„è¯­ä¹‰åˆ†å‰²æ€§èƒ½ä¸ç°æœ‰æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FAST-Splatè§£å†³äº†ç°æœ‰è¯­ä¹‰é«˜æ–¯æ··åˆæ–¹æ³•çš„è®­ç»ƒä¸æ¸²æŸ“é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚</li>
<li>FAST-Splaté€šè¿‡å®ç°å¼€æ”¾é›†è¯­ä¹‰è’¸é¦è§£å†³äº†å°é—­é›†æ–¹æ³•çš„å±€é™æ€§ã€‚</li>
<li>FAST-Splatèƒ½ç²¾ç¡®å¤„ç†æ¨¡ç³Šçš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¹¶è¿›è¡Œè¯­ä¹‰å¯¹è±¡å®šä½ã€‚</li>
<li>FAST-Splaté€šè¿‡åˆ©ç”¨é«˜æ–¯æ··åˆçš„ä¼˜åŠ¿æé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>ä¸ç°æœ‰çš„ç¥ç»åœºæ–¹æ³•ç›¸æ¯”ï¼ŒFAST-Splatå…·æœ‰æ›´é«˜æ•ˆçš„å†…å­˜ä½¿ç”¨å’Œæ›´å¿«çš„è¿è¡Œé€Ÿåº¦ã€‚</li>
<li>FAST-Splaté€šè¿‡ä¸ºæ¯ä¸ªé«˜æ–¯åˆ†é…ç‰¹å®šçš„è¯­ä¹‰ç¼–ç å¢å¼ºäº†è¯­ä¹‰æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13753">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.13753v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.13753v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.13753v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.13753v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Self-Ensembling-Gaussian-Splatting-for-Few-Shot-Novel-View-Synthesis"><a href="#Self-Ensembling-Gaussian-Splatting-for-Few-Shot-Novel-View-Synthesis" class="headerlink" title="Self-Ensembling Gaussian Splatting for Few-Shot Novel View Synthesis"></a>Self-Ensembling Gaussian Splatting for Few-Shot Novel View Synthesis</h2><p><strong>Authors:Chen Zhao, Xuan Wang, Tong Zhang, Saqib Javed, Mathieu Salzmann</strong></p>
<p>3D Gaussian Splatting (3DGS) has demonstrated remarkable effectiveness in novel view synthesis (NVS). However, 3DGS tends to overfit when trained with sparse views, limiting its generalization to novel viewpoints. In this paper, we address this overfitting issue by introducing Self-Ensembling Gaussian Splatting (SE-GS). We achieve self-ensembling by incorporating an uncertainty-aware perturbation strategy during training. A $\mathbf{\Delta}$-model and a $\mathbf{\Sigma}$-model are jointly trained on the available images. The $\mathbf{\Delta}$-model is dynamically perturbed based on rendering uncertainty across training steps, generating diverse perturbed models with negligible computational overhead. Discrepancies between the $\mathbf{\Sigma}$-model and these perturbed models are minimized throughout training, forming a robust ensemble of 3DGS models. This ensemble, represented by the $\mathbf{\Sigma}$-model, is then used to generate novel-view images during inference. Experimental results on the LLFF, Mip-NeRF360, DTU, and MVImgNet datasets demonstrate that our approach enhances NVS quality under few-shot training conditions, outperforming existing state-of-the-art methods. The code is released at: <a target="_blank" rel="noopener" href="https://sailor-z.github.io/projects/SEGS.html">https://sailor-z.github.io/projects/SEGS.html</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†è§’åˆæˆï¼ˆNVSï¼‰ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ•ˆæœã€‚ç„¶è€Œï¼Œå½“ä½¿ç”¨ç¨€ç–è§†è§’è¿›è¡Œè®­ç»ƒæ—¶ï¼Œ3DGSå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆï¼Œé™åˆ¶äº†å…¶åœ¨æ–°å‹è§‚ç‚¹ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥è‡ªé›†æˆé«˜æ–¯èåˆï¼ˆSE-GSï¼‰æ¥è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ã€‚æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨äº†ä¸€ç§æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„æ‰°åŠ¨ç­–ç•¥æ¥å®ç°è‡ªé›†æˆã€‚Î”æ¨¡å‹å’ŒÎ£æ¨¡å‹åœ¨å¯ç”¨å›¾åƒä¸Šè”åˆè®­ç»ƒã€‚Î”æ¨¡å‹æ ¹æ®è®­ç»ƒæ­¥éª¤ä¸­çš„æ¸²æŸ“ä¸ç¡®å®šæ€§è¿›è¡ŒåŠ¨æ€æ‰°åŠ¨ï¼Œç”Ÿæˆå…·æœ‰å¾®å°è®¡ç®—å¼€é”€çš„å¤šç§æ‰°åŠ¨æ¨¡å‹ã€‚åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ€å°åŒ–Î£æ¨¡å‹ä¸è¿™äº›æ‰°åŠ¨æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ï¼Œå½¢æˆç¨³å¥çš„3DGSæ¨¡å‹é›†åˆã€‚è¿™ä¸ªé›†åˆç”±Î£æ¨¡å‹è¡¨ç¤ºï¼Œç„¶åç”¨äºæ¨ç†è¿‡ç¨‹ä¸­çš„æ–°å‹è§†è§’å›¾åƒç”Ÿæˆã€‚åœ¨LLFFã€Mip-NeRF360ã€DTUå’ŒMVImgNetæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æé«˜å°‘é‡è®­ç»ƒæ¡ä»¶ä¸‹çš„NVSè´¨é‡æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä»£ç å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://sailor-z.github.io/projects/SEGS.html%E3%80%82">https://sailor-z.github.io/projects/SEGS.htmlã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.00144v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³äº†åœ¨ç¨€ç–è§†å›¾è®­ç»ƒä¸‹ï¼Œ3Dé«˜æ–¯é‡‡æ ·ï¼ˆ3DGSï¼‰å­˜åœ¨çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨æ–°å‹è§†è§’ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥è‡ªé›†æˆé«˜æ–¯é‡‡æ ·ï¼ˆSE-GSï¼‰è§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨äº†ä¸€ç§æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„æ‰°åŠ¨ç­–ç•¥æ¥å®ç°è‡ªé›†æˆã€‚åŒæ—¶è®­ç»ƒäº†Î”æ¨¡å‹å’ŒÎ£æ¨¡å‹ï¼ŒÎ”æ¨¡å‹æ ¹æ®æ¸²æŸ“ä¸ç¡®å®šæ€§è¿›è¡ŒåŠ¨æ€æ‰°åŠ¨ï¼Œç”Ÿæˆå¤šç§æ‰°åŠ¨æ¨¡å‹ä¸”è®¡ç®—å¼€é”€å°ã€‚é€šè¿‡æœ€å°åŒ–Î£æ¨¡å‹å’Œè¿™äº›æ‰°åŠ¨æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ï¼Œå½¢æˆç¨³å¥çš„3DGSæ¨¡å‹é›†åˆã€‚åœ¨LLFFã€Mip-NeRF360ã€DTUå’ŒMVImgNetæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘é‡è®­ç»ƒæ ·æœ¬çš„æƒ…å†µä¸‹æé«˜äº†æ–°å‹è§†å›¾åˆæˆçš„è´¨é‡ï¼Œä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä»£ç å·²å‘å¸ƒåœ¨ï¼š[é“¾æ¥åœ°å€]ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSåœ¨æ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åœ¨ç¨€ç–è§†å›¾è®­ç»ƒä¸‹ï¼Œ3DGSå­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œé™åˆ¶äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥SE-GSæ–¹æ³•æ¥è§£å†³è¿™ä¸€è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>é€šè¿‡æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„æ‰°åŠ¨ç­–ç•¥å®ç°è‡ªé›†æˆè®­ç»ƒã€‚</li>
<li>åŒæ—¶è®­ç»ƒÎ”æ¨¡å‹å’ŒÎ£æ¨¡å‹ï¼Œå…¶ä¸­Î”æ¨¡å‹åŠ¨æ€æ‰°åŠ¨ä»¥ç”Ÿæˆå¤šç§æ¨¡å‹ã€‚</li>
<li>é€šè¿‡æœ€å°åŒ–Î£æ¨¡å‹å’Œæ‰°åŠ¨æ¨¡å‹é—´çš„å·®å¼‚ï¼Œå½¢æˆç¨³å¥çš„æ¨¡å‹é›†åˆã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜SE-GSæ–¹æ³•æé«˜äº†NVSè´¨é‡ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.00144">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.00144v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.00144v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.00144v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.00144v3/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.00144v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2411.00144v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Fast-Feedforward-3D-Gaussian-Splatting-Compression"><a href="#Fast-Feedforward-3D-Gaussian-Splatting-Compression" class="headerlink" title="Fast Feedforward 3D Gaussian Splatting Compression"></a>Fast Feedforward 3D Gaussian Splatting Compression</h2><p><strong>Authors:Yihang Chen, Qianyi Wu, Mengyao Li, Weiyao Lin, Mehrtash Harandi, Jianfei Cai</strong></p>
<p>With 3D Gaussian Splatting (3DGS) advancing real-time and high-fidelity rendering for novel view synthesis, storage requirements pose challenges for their widespread adoption. Although various compression techniques have been proposed, previous art suffers from a common limitation: for any existing 3DGS, per-scene optimization is needed to achieve compression, making the compression sluggish and slow. To address this issue, we introduce Fast Compression of 3D Gaussian Splatting (FCGS), an optimization-free model that can compress 3DGS representations rapidly in a single feed-forward pass, which significantly reduces compression time from minutes to seconds. To enhance compression efficiency, we propose a multi-path entropy module that assigns Gaussian attributes to different entropy constraint paths for balance between size and fidelity. We also carefully design both inter- and intra-Gaussian context models to remove redundancies among the unstructured Gaussian blobs. Overall, FCGS achieves a compression ratio of over 20X while maintaining fidelity, surpassing most per-scene SOTA optimization-based methods. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/YihangChen-ee/FCGS">https://github.com/YihangChen-ee/FCGS</a>. </p>
<blockquote>
<p>éšç€3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰åœ¨å®æ—¶å’Œé«˜ä¿çœŸæ¸²æŸ“æ–°è§†è§’åˆæˆæ–¹é¢çš„è¿›å±•ï¼Œå…¶å­˜å‚¨éœ€æ±‚æŒ‘æˆ˜äº†å…¶å¹¿æ³›åº”ç”¨çš„å¯è¡Œæ€§ã€‚è™½ç„¶å·²æå‡ºäº†å„ç§å‹ç¼©æŠ€æœ¯ï¼Œä½†ç°æœ‰æŠ€æœ¯å­˜åœ¨ä¸€ç§å¸¸è§é™åˆ¶ï¼šå¯¹äºä»»ä½•ç°æœ‰çš„3DGSï¼Œéƒ½éœ€è¦é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ä»¥å®ç°å‹ç¼©ï¼Œè¿™ä½¿å¾—å‹ç¼©è¿‡ç¨‹ç¼“æ…¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¿«é€Ÿå‹ç¼©çš„3Dé«˜æ–¯èåˆï¼ˆFCGSï¼‰æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€ä¼˜åŒ–çš„æ¨¡å‹ï¼Œå¯ä»¥åœ¨å•ä¸ªå‰é¦ˆä¼ é€’ä¸­å¿«é€Ÿå‹ç¼©3DGSè¡¨ç¤ºï¼Œå°†å‹ç¼©æ—¶é—´ä»æ•°åˆ†é’Ÿå¤§å¹…ç¼©çŸ­è‡³æ•°ç§’ã€‚ä¸ºäº†æé«˜å‹ç¼©æ•ˆç‡ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šè·¯ç†µæ¨¡å—ï¼Œå®ƒå°†é«˜æ–¯å±æ€§åˆ†é…ç»™ä¸åŒçš„ç†µçº¦æŸè·¯å¾„ï¼Œä»¥åœ¨å¤§å°å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—å¹³è¡¡ã€‚æˆ‘ä»¬è¿˜ç²¾å¿ƒè®¾è®¡äº†é«˜æ–¯å†…å¤–ä¸Šä¸‹æ–‡æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤éç»“æ„åŒ–é«˜æ–¯å—ä¹‹é—´çš„å†—ä½™ã€‚æ€»ä½“è€Œè¨€ï¼ŒFCGSåœ¨ä¿æŒé«˜ä¿çœŸåº¦çš„åŒæ—¶å®ç°äº†è¶…è¿‡20å€çš„å‹ç¼©æ¯”ï¼Œè¶…è¶Šäº†å¤§å¤šæ•°åŸºäºåœºæ™¯çš„å…ˆè¿›ä¼˜åŒ–æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/YihangChen-ee/FCGS">FCGSé“¾æ¥</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.08017v3">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://yihangchen-ee.github.io/project_fcgs/">https://yihangchen-ee.github.io/project_fcgs/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/yihangchen-ee/fcgs/">https://github.com/yihangchen-ee/fcgs/</a></p>
<p><strong>Summary</strong></p>
<p>3Dé«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼ˆ3DGSï¼‰ä¸ºå®æ—¶å’Œé«˜ä¿çœŸæ¸²æŸ“æ–°å‹è§†å›¾åˆæˆæä¾›äº†æœºä¼šï¼Œä½†å­˜å‚¨éœ€æ±‚é™åˆ¶äº†å…¶å¹¿æ³›åº”ç”¨ã€‚ä¸ºåº”å¯¹å‹ç¼©éš¾é¢˜ï¼Œç°æœ‰å¤šç§å‹ç¼©æŠ€æœ¯ä½†éƒ½éœ€è¦åœºæ™¯ä¼˜åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†å¿«é€Ÿå‹ç¼©3Dé«˜æ–¯æ¸²æŸ“ï¼ˆFCGSï¼‰æ¨¡å‹ï¼Œå®ç°äº†æ— éœ€ä¼˜åŒ–çš„å•é€šé“å‰é¦ˆå‹ç¼©ï¼Œå°†å‹ç¼©æ—¶é—´ä»åˆ†é’Ÿç¼©çŸ­åˆ°ç§’ã€‚é€šè¿‡å¤šè·¯å¾„ç†µæ¨¡å—å’Œç²¾å¿ƒè®¾è®¡çš„å†…å¤–é«˜æ–¯ä¸Šä¸‹æ–‡æ¨¡å‹ï¼Œå®ç°äº†é«˜ä¿çœŸä¸‹çš„è¶…è¿‡20å€çš„å‹ç¼©æ¯”ï¼Œè¶…è¶Šå¤šæ•°åœºæ™¯ä¼˜åŒ–æ–¹æ³•ã€‚ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSæŠ€æœ¯åœ¨å®æ—¶å’Œé«˜ä¿çœŸæ¸²æŸ“é¢†åŸŸå…·æœ‰æ½œåŠ›ï¼Œä½†å­˜å‚¨éœ€æ±‚é™åˆ¶äº†å…¶åº”ç”¨ã€‚</li>
<li>ç°æœ‰å‹ç¼©æŠ€æœ¯éœ€è¦åœºæ™¯ä¼˜åŒ–ï¼Œå¯¼è‡´å‹ç¼©æ•ˆç‡ä½ä¸‹ã€‚</li>
<li>FCGSæ¨¡å‹å®ç°äº†å¿«é€Ÿã€æ— éœ€ä¼˜åŒ–çš„å•é€šé“å‰é¦ˆå‹ç¼©ã€‚</li>
<li>FCGSé€šè¿‡å¤šè·¯å¾„ç†µæ¨¡å—å¹³è¡¡å¤§å°ä¸ä¿çœŸåº¦ã€‚</li>
<li>ç²¾å¿ƒè®¾è®¡çš„å†…å¤–é«˜æ–¯ä¸Šä¸‹æ–‡æ¨¡å‹æ¶ˆé™¤äº†é«˜æ–¯æ•°æ®å—é—´çš„å†—ä½™ä¿¡æ¯ã€‚</li>
<li>FCGSå®ç°äº†è¶…è¿‡20å€çš„å‹ç¼©æ¯”ï¼ŒåŒæ—¶ä¿æŒé«˜ä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.08017">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.08017v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.08017v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.08017v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.08017v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="EVA-Gaussian-3D-Gaussian-based-Real-time-Human-Novel-View-Synthesis-under-Diverse-Multi-view-Camera-Settings"><a href="#EVA-Gaussian-3D-Gaussian-based-Real-time-Human-Novel-View-Synthesis-under-Diverse-Multi-view-Camera-Settings" class="headerlink" title="EVA-Gaussian: 3D Gaussian-based Real-time Human Novel View Synthesis   under Diverse Multi-view Camera Settings"></a>EVA-Gaussian: 3D Gaussian-based Real-time Human Novel View Synthesis   under Diverse Multi-view Camera Settings</h2><p><strong>Authors:Yingdong Hu, Zhening Liu, Jiawei Shao, Zehong Lin, Jun Zhang</strong></p>
<p>Feed-forward based 3D Gaussian Splatting methods have demonstrated exceptional capability in real-time novel view synthesis for human models. However, current approaches are confined to either dense viewpoint configurations or restricted image resolutions. These limitations hinder their flexibility in free-viewpoint rendering across a wide range of camera view angle discrepancies, and also restrict their ability to recover fine-grained human details in real time using commonly available GPUs. To address these challenges, we propose a novel pipeline named EVA-Gaussian for 3D human novel view synthesis across diverse multi-view camera settings. Specifically, we first design an Efficient Cross-View Attention (EVA) module to effectively fuse cross-view information under high resolution inputs and sparse view settings, while minimizing temporal and computational overhead. Additionally, we introduce a feature refinement mechianism to predict the attributes of the 3D Gaussians and assign a feature value to each Gaussian, enabling the correction of artifacts caused by geometric inaccuracies in position estimation and enhancing overall visual fidelity. Experimental results on the THuman2.0 and THumansit datasets showcase the superiority of EVA-Gaussian in rendering quality across diverse camera settings. Project page: <a target="_blank" rel="noopener" href="https://zhenliuzju.github.io/huyingdong/EVA-Gaussian">https://zhenliuzju.github.io/huyingdong/EVA-Gaussian</a>. </p>
<blockquote>
<p>åŸºäºå‰é¦ˆçš„3Dé«˜æ–¯æ‹¼è´´æ³•åœ¨äººå½¢æ¨¡å‹å®æ—¶ç”Ÿæˆæ–°é¢–è§†è§’çš„åˆæˆä¸­è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•ä»…é™äºå¯†é›†çš„è§†ç‚¹é…ç½®æˆ–å—é™çš„å›¾åƒåˆ†è¾¨ç‡ã€‚è¿™äº›å±€é™æ€§é˜»ç¢äº†å®ƒä»¬åœ¨å¹¿æ³›ç›¸æœºè§†è§’å·®å¼‚ä¸Šçš„è‡ªç”±è§†è§’æ¸²æŸ“çš„çµæ´»æ€§ï¼Œå¹¶é™åˆ¶äº†å®ƒä»¬åœ¨å¸¸ç”¨GPUä¸Šå®æ—¶æ¢å¤ç²¾ç»†ç²’åº¦äººç±»ç»†èŠ‚çš„èƒ½åŠ›ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºEVA-Gaussiançš„ç”¨äºå¤šç§ä¸åŒè§†å›¾è®¾ç½®ä¸‹çš„3Däººç±»æ–°é¢–è§†è§’åˆæˆçš„ç®¡é“ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆè®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„è·¨è§†å›¾æ³¨æ„åŠ›ï¼ˆEVAï¼‰æ¨¡å—ï¼Œä»¥åœ¨é«˜åˆ†è¾¨ç‡è¾“å…¥å’Œç¨€ç–è§†å›¾è®¾ç½®ä¸‹æœ‰æ•ˆåœ°èåˆè·¨è§†å›¾ä¿¡æ¯ï¼ŒåŒæ—¶æœ€å°åŒ–æ—¶é—´å’Œè®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç‰¹å¾ç»†åŒ–æœºåˆ¶æ¥é¢„æµ‹3Dé«˜æ–¯å±æ€§å¹¶ä¸ºæ¯ä¸ªé«˜æ–¯åˆ†é…ä¸€ä¸ªç‰¹å¾å€¼ï¼Œä»è€Œçº æ­£å› ä½ç½®ä¼°è®¡ä¸­çš„å‡ ä½•è¯¯å·®å¼•èµ·çš„ä¼ªå½±å¹¶å¢å¼ºæ•´ä½“è§†è§‰é€¼çœŸåº¦ã€‚åœ¨THuman2.0å’ŒTHumansitæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒEVA-Gaussianåœ¨ä¸åŒç›¸æœºè®¾ç½®ä¸‹çš„æ¸²æŸ“è´¨é‡ä¸Šå…·æœ‰ä¼˜åŠ¿ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://zhenliuzju.github.io/huyingdong/EVA-Gaussian">https://zhenliuzju.github.io/huyingdong/EVA-Gaussian</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.01425v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºEVA-Gaussiançš„3Däººä½“è§†è§’åˆæˆæ–°æ–¹æ³•ï¼Œç”¨äºå¤„ç†å¤šç§å¤æ‚åœºæ™¯ä¸‹çš„æ–°å‹è§†ç‚¹æ¸²æŸ“é—®é¢˜ã€‚å®ƒé€šè¿‡é«˜æ•ˆè·¨è§†å›¾æ³¨æ„åŠ›æ¨¡å—ï¼ˆEVAï¼‰èåˆä¸åŒè§†è§’ä¿¡æ¯ï¼Œåœ¨é«˜åˆ†è¾¨ç‡è¾“å…¥å’Œç¨€ç–è§†å›¾è®¾ç½®ä¸‹å®ç°æœ‰æ•ˆèåˆï¼ŒåŒæ—¶é™ä½æ—¶é—´å’Œè®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥ç‰¹å¾ä¼˜åŒ–æœºåˆ¶ä»¥é¢„æµ‹3Dé«˜æ–¯å±æ€§å¹¶ä¸ºå…¶åˆ†é…ç‰¹å¾å€¼ï¼Œä¿®æ­£å› ä½ç½®ä¼°è®¡å‡ ä½•è¯¯å·®å¼•èµ·çš„ä¼ªå½±ï¼Œæé«˜æ•´ä½“è§†è§‰é€¼çœŸåº¦ã€‚åœ¨THuman2.0å’ŒTHumansitæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEVA-Gaussianåœ¨ä¸åŒç›¸æœºè®¾ç½®ä¸‹çš„æ¸²æŸ“è´¨é‡è¡¨ç°å“è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EVA-Gaussianæ–¹æ³•è§£å†³äº†ç°æœ‰3Dé«˜æ–¯æ··è‰²æ–¹æ³•åœ¨å®æ—¶äººä½“æ¨¡å‹æ–°è§†è§’åˆæˆä¸­çš„å±€é™æ€§ã€‚</li>
<li>æå‡ºEfficient Cross-View Attentionï¼ˆEVAï¼‰æ¨¡å—ï¼Œæœ‰æ•ˆèåˆè·¨è§†è§’ä¿¡æ¯ï¼Œé€‚ç”¨äºé«˜åˆ†è¾¨è¾“å…¥å’Œç¨€ç–è§†å›¾è®¾ç½®ã€‚</li>
<li>å¼•å…¥ç‰¹å¾ä¼˜åŒ–æœºåˆ¶ï¼Œé¢„æµ‹3Dé«˜æ–¯å±æ€§å¹¶åˆ†é…ç‰¹å¾å€¼ï¼Œä¿®æ­£ä½ç½®ä¼°è®¡å‡ ä½•è¯¯å·®å¼•èµ·çš„ä¼ªå½±ã€‚</li>
<li>æ–¹æ³•åœ¨THuman2.0å’ŒTHumansitæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>EVA-Gaussianæé«˜äº†è‡ªç”±è§†è§’æ¸²æŸ“çš„çµæ´»æ€§å’Œèƒ½åŠ›ï¼Œå¯åœ¨å¹¿æ³›çš„è§’åº¦å·®å¼‚ä¸‹æ¢å¤ç²¾ç»†çš„äººç±»ç»†èŠ‚ã€‚</li>
<li>æ–¹æ³•åœ¨å¸¸è§GPUä¸Šå®ç°å®æ—¶ç²¾ç»†äººç±»ç»†èŠ‚æ¢å¤ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.01425">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.01425v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.01425v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.01425v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2410.01425v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="RealmDreamer-Text-Driven-3D-Scene-Generation-with-Inpainting-and-Depth-Diffusion"><a href="#RealmDreamer-Text-Driven-3D-Scene-Generation-with-Inpainting-and-Depth-Diffusion" class="headerlink" title="RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth   Diffusion"></a>RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth   Diffusion</h2><p><strong>Authors:Jaidev Shriram, Alex Trevithick, Lingjie Liu, Ravi Ramamoorthi</strong></p>
<p>We introduce RealmDreamer, a technique for generating forward-facing 3D scenes from text descriptions. Our method optimizes a 3D Gaussian Splatting representation to match complex text prompts using pretrained diffusion models. Our key insight is to leverage 2D inpainting diffusion models conditioned on an initial scene estimate to provide low variance supervision for unknown regions during 3D distillation. In conjunction, we imbue high-fidelity geometry with geometric distillation from a depth diffusion model, conditioned on samples from the inpainting model. We find that the initialization of the optimization is crucial, and provide a principled methodology for doing so. Notably, our technique doesnâ€™t require video or multi-view data and can synthesize various high-quality 3D scenes in different styles with complex layouts. Further, the generality of our method allows 3D synthesis from a single image. As measured by a comprehensive user study, our method outperforms all existing approaches, preferred by 88-95%. Project Page: <a target="_blank" rel="noopener" href="https://realmdreamer.github.io/">https://realmdreamer.github.io/</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†RealmDreameræŠ€æœ¯ï¼Œè¿™æ˜¯ä¸€ç§ä»æ–‡æœ¬æè¿°ç”Ÿæˆæ­£é¢3Dåœºæ™¯çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¼˜åŒ–äº†ä¸€ä¸ª3Dé«˜æ–¯é£æº…è¡¨ç¤ºï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹æ¥åŒ¹é…å¤æ‚çš„æ–‡æœ¬æç¤ºã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯åˆ©ç”¨åŸºäºåˆå§‹åœºæ™¯ä¼°è®¡çš„äºŒç»´å¡«å……æ‰©æ•£æ¨¡å‹ï¼Œä¸º3Dè’¸é¦è¿‡ç¨‹ä¸­çš„æœªçŸ¥åŒºåŸŸæä¾›ä½æ–¹å·®ç›‘ç£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»æ·±åº¦æ‰©æ•£æ¨¡å‹ä¸­æ±²å–å‡ ä½•è’¸é¦ï¼Œèµ‹äºˆé«˜ä¿çœŸå‡ ä½•å½¢çŠ¶ä»¥çµæ„Ÿï¼Œä»¥å¡«å……æ¨¡å‹çš„æ ·æœ¬ä¸ºæ¡ä»¶ã€‚æˆ‘ä»¬å‘ç°ä¼˜åŒ–çš„åˆå§‹åŒ–è‡³å…³é‡è¦ï¼Œå¹¶æä¾›äº†ä¸€ç§è¿›è¡Œåˆå§‹åŒ–çš„åŸåˆ™æ€§æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯ä¸éœ€è¦è§†é¢‘æˆ–å¤šè§†è§’æ•°æ®ï¼Œå¹¶èƒ½åˆæˆå„ç§ä¸åŒé£æ ¼ã€å¸ƒå±€å¤æ‚çš„é«˜è´¨é‡3Dåœºæ™¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„é€šç”¨æ€§ï¼Œå¯ä»¥ä»å•å¼ å›¾åƒä¸­è¿›è¡Œ3Dåˆæˆã€‚æ ¹æ®å…¨é¢çš„ç”¨æˆ·ç ”ç©¶æµ‹é‡ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæ‰€æœ‰ç°æœ‰æ–¹æ³•ï¼Œè¢«åå¥½ç‡ä¸º88-95%ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://realmdreamer.github.io/%EF%BC%88%E5%9F%9F%E5%90%8D%E5%B7%B2%E4%BD%9C%E8%B0%83%E6%95%B4%EF%BC%89%E3%80%82">https://realmdreamer.github.io/ï¼ˆåŸŸåå·²ä½œè°ƒæ•´ï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.07199v2">PDF</a> Published at 3DV 2025</p>
<p><strong>Summary</strong></p>
<p>RealDreameræŠ€æœ¯èƒ½é€šè¿‡æ–‡æœ¬æè¿°ç”Ÿæˆé¢å‘å‰æ–¹çš„3Dåœºæ™¯ã€‚è¯¥æŠ€æœ¯ä¼˜åŒ–3Dé«˜æ–¯æ··åˆè¡¨ç¤ºï¼Œä»¥åŒ¹é…å¤æ‚çš„æ–‡æœ¬æç¤ºï¼Œå¹¶å€ŸåŠ©é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å®ç°ã€‚å…¶å…³é”®åœ¨äºåˆ©ç”¨åˆå§‹åœºæ™¯ä¼°è®¡çš„2Dè¡¥å…¨æ‰©æ•£æ¨¡å‹ï¼Œä¸º3Dè’¸é¦è¿‡ç¨‹ä¸­çš„æœªçŸ¥åŒºåŸŸæä¾›ä½æ–¹å·®ç›‘ç£ã€‚åŒæ—¶ï¼Œç»“åˆæ·±åº¦æ‰©æ•£æ¨¡å‹çš„å‡ ä½•è’¸é¦ï¼Œèµ‹äºˆé«˜ä¿çœŸå‡ ä½•ä»¥åˆå§‹æ ·æœ¬çš„æ ·å¼ã€‚ç ”ç©¶å‘ç°ä¼˜åŒ–åˆå§‹åŒ–è‡³å…³é‡è¦ï¼Œå¹¶æä¾›äº†ä¸€ç§åŸåˆ™æ€§çš„æ–¹æ³•æ¥å®ç°ã€‚è¯¥æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œæ— éœ€è§†é¢‘æˆ–å¤šè§†è§’æ•°æ®ï¼Œå¹¶èƒ½åˆæˆä¸åŒé£æ ¼ã€å¤æ‚å¸ƒå±€çš„é«˜è´¨é‡3Dåœºæ™¯ã€‚ç»ç»¼åˆç”¨æˆ·ç ”ç©¶æµ‹è¯•ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œç”¨æˆ·æ»¡æ„åº¦è¾¾88-95%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RealDreamerèƒ½ä»æ–‡æœ¬æè¿°ç”Ÿæˆé¢å‘å‰æ–¹çš„3Dåœºæ™¯ã€‚</li>
<li>æŠ€æœ¯æ ¸å¿ƒæ˜¯ä¼˜åŒ–3Dé«˜æ–¯æ··åˆè¡¨ç¤ºï¼ŒåŒ¹é…æ–‡æœ¬æç¤ºã€‚</li>
<li>åˆ©ç”¨2Dè¡¥å…¨æ‰©æ•£æ¨¡å‹æä¾›ä½æ–¹å·®ç›‘ç£ï¼Œè¾…åŠ©3Dè’¸é¦è¿‡ç¨‹ã€‚</li>
<li>ç»“åˆæ·±åº¦æ‰©æ•£æ¨¡å‹çš„å‡ ä½•è’¸é¦ï¼Œå¢åŠ åœºæ™¯çš„é«˜ä¿çœŸåº¦ã€‚</li>
<li>ç ”ç©¶çš„é‡ç‚¹æ˜¯ä¼˜åŒ–åˆå§‹åŒ–çš„é‡è¦æ€§ï¼Œå¹¶æä¾›äº†å®ç°åŸåˆ™æ€§æ–¹æ³•ã€‚</li>
<li>è¯¥æŠ€æœ¯æ— éœ€è§†é¢‘æˆ–å¤šè§†è§’æ•°æ®ï¼Œèƒ½åˆæˆå¤šç§é«˜è´¨é‡3Dåœºæ™¯ã€‚</li>
<li>é€šè¿‡ç”¨æˆ·ç ”ç©¶éªŒè¯ï¼ŒRealDreameråœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œç”¨æˆ·æ»¡æ„åº¦é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.07199">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2404.07199v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2404.07199v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2404.07199v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2404.07199v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2404.07199v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-14\./crop_3DGS/2404.07199v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-14/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-14/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-14/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ad456a537422b2a82cd6af9b1e5c7a92.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-14  Uni-Gaussians Unifying Camera and Lidar Simulation with Gaussians for   Dynamic Driving Scenarios
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-14/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-659515b8a9a3de461f708ea21ebf0a2a.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-14  Better Together Unified Motion Capture and 3D Avatar Reconstruction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">17012.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
