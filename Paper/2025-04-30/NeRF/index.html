<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF 方向最新论文已更新，请持续关注 Update in 2025-04-30  Joint Optimization of Neural Radiance Fields and Continuous Camera   Motion from a Monocular Video">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9d1d8a2d3376eb8bcec01d470d25c2b5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    22 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-30-更新"><a href="#2025-04-30-更新" class="headerlink" title="2025-04-30 更新"></a>2025-04-30 更新</h1><h2 id="Joint-Optimization-of-Neural-Radiance-Fields-and-Continuous-Camera-Motion-from-a-Monocular-Video"><a href="#Joint-Optimization-of-Neural-Radiance-Fields-and-Continuous-Camera-Motion-from-a-Monocular-Video" class="headerlink" title="Joint Optimization of Neural Radiance Fields and Continuous Camera   Motion from a Monocular Video"></a>Joint Optimization of Neural Radiance Fields and Continuous Camera   Motion from a Monocular Video</h2><p><strong>Authors:Hoang Chuong Nguyen, Wei Mao, Jose M. Alvarez, Miaomiao Liu</strong></p>
<p>Neural Radiance Fields (NeRF) has demonstrated its superior capability to represent 3D geometry but require accurately precomputed camera poses during training. To mitigate this requirement, existing methods jointly optimize camera poses and NeRF often relying on good pose initialisation or depth priors. However, these approaches struggle in challenging scenarios, such as large rotations, as they map each camera to a world coordinate system. We propose a novel method that eliminates prior dependencies by modeling continuous camera motions as time-dependent angular velocity and velocity. Relative motions between cameras are learned first via velocity integration, while camera poses can be obtained by aggregating such relative motions up to a world coordinate system defined at a single time step within the video. Specifically, accurate continuous camera movements are learned through a time-dependent NeRF, which captures local scene geometry and motion by training from neighboring frames for each time step. The learned motions enable fine-tuning the NeRF to represent the full scene geometry. Experiments on Co3D and Scannet show our approach achieves superior camera pose and depth estimation and comparable novel-view synthesis performance compared to state-of-the-art methods. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/HoangChuongNguyen/cope-nerf">https://github.com/HoangChuongNguyen/cope-nerf</a>. </p>
<blockquote>
<p>神经辐射场（NeRF）已经展现出其在表示3D几何结构上的卓越能力，但在训练过程中需要预先精确计算相机姿态。为了缓解这一要求，现有方法通常会联合优化相机姿态和NeRF，这常常依赖于良好的姿态初始值或深度先验。然而，这些方法在具有挑战性的场景中（例如大旋转场景）会遇到困难，因为它们将每个相机映射到世界坐标系。我们提出了一种新方法，通过建模连续的相机运动作为时间依赖的角速度和速度来消除对先验的依赖。首先通过学习速度积分来获取相机之间的相对运动，然后通过聚合这些相对运动来获得相机姿态，最终将其定位到视频内单个时间步长所定义的世界坐标系。具体来说，通过时间依赖的NeRF学习精确的连续相机运动，该NeRF通过从每个时间步长的邻近帧进行训练来捕捉局部场景几何和运动。学习到的运动使NeRF能够微调以表示完整的场景几何结构。在Co3D和Scannet上的实验表明，我们的方法在相机姿态和深度估计方面达到了优越的性能，在新视角合成性能方面与最先进的方法相当。我们的代码位于[<a target="_blank" rel="noopener" href="https://github.com/HoangChuongNguyen/cope-nerf%E3%80%82]%EF%BC%88%E6%B3%A8%EF%BC%9A%E8%AF%A5%E7%BD%91%E5%9D%80%E5%BA%94%E6%9B%BF%E6%8D%A2%E4%B8%BA%E7%9C%9F%E5%AE%9E%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E9%93%BE%E6%8E%A5%EF%BC%89">https://github.com/HoangChuongNguyen/cope-nerf。]（注：该网址应替换为真实的代码仓库链接）</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19819v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新的方法，通过建模连续相机运动的时间依赖性角速度和速度，消除了对先验的依赖。该方法首先通过速度积分学习相对运动，然后通过聚合这些相对运动获得相机姿态，最后在一个定义在视频单个时间步长内的世界坐标系中表示出来。通过时间依赖的NeRF学习到的运动能够精细地表示整个场景几何结构。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有NeRF技术需要精确预计算的相机姿态来进行训练。</li>
<li>现有方法联合优化相机姿态和NeRF，通常依赖于良好的姿态初始值或深度先验。</li>
<li>在具有挑战性的场景（如大旋转）中，依赖世界坐标系统的现有方法可能会遇到困难。</li>
<li>提出了一种新型方法，通过建模连续相机运动的时间依赖性角速度和速度来消除对先验的依赖。</li>
<li>该方法首先通过速度积分学习相对运动，然后通过聚合这些相对运动获得相机姿态。</li>
<li>通过时间依赖的NeRF学习到的运动能够精细地表示整个场景几何结构。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19819">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-96cbb245b354a683bb0539045eb12d57.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2914fb5ae14b2118b5855be66c127869.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-37880ddc5469f0a75e57b741f084f884.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="IM-Portrait-Learning-3D-aware-Video-Diffusion-for-PhotorealisticTalking-Heads-from-Monocular-Videos"><a href="#IM-Portrait-Learning-3D-aware-Video-Diffusion-for-PhotorealisticTalking-Heads-from-Monocular-Videos" class="headerlink" title="IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking   Heads from Monocular Videos"></a>IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking   Heads from Monocular Videos</h2><p><strong>Authors:Yuan Li, Ziqian Bai, Feitong Tan, Zhaopeng Cui, Sean Fanello, Yinda Zhang</strong></p>
<p>We propose a novel 3D-aware diffusion-based method for generating photorealistic talking head videos directly from a single identity image and explicit control signals (e.g., expressions). Our method generates Multiplane Images (MPIs) that ensure geometric consistency, making them ideal for immersive viewing experiences like binocular videos for VR headsets. Unlike existing methods that often require a separate stage or joint optimization to reconstruct a 3D representation (such as NeRF or 3D Gaussians), our approach directly generates the final output through a single denoising process, eliminating the need for post-processing steps to render novel views efficiently. To effectively learn from monocular videos, we introduce a training mechanism that reconstructs the output MPI randomly in either the target or the reference camera space. This approach enables the model to simultaneously learn sharp image details and underlying 3D information. Extensive experiments demonstrate the effectiveness of our method, which achieves competitive avatar quality and novel-view rendering capabilities, even without explicit 3D reconstruction or high-quality multi-view training data. </p>
<blockquote>
<p>我们提出了一种新型的基于三维扩散的方法，直接从单张身份图像和明确的控制信号（如表情）生成逼真的动态视频。我们的方法生成多平面图像（MPIs），确保几何一致性，使其成为适合沉浸式观看体验的理想选择，如VR头盔的双眼视频。与通常需要单独阶段或联合优化来重建三维表示（如NeRF或三维高斯分布）的现有方法不同，我们的方法通过单个去噪过程直接生成最终输出，无需后处理步骤即可有效地渲染新颖视图。为了有效地从单眼视频中学习，我们引入了一种训练机制，该机制可以在目标相机空间或参考相机空间中随机重建输出MPI。这种方法使模型能够同时学习尖锐的图像细节和潜在的三维信息。大量实验证明了我们方法的有效性，即使在没有明确的三维重建或高质量的多视角训练数据的情况下，也能实现具有竞争力的化身质量和新颖的视图渲染能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19165v1">PDF</a> CVPR2025; project page:   <a target="_blank" rel="noopener" href="https://y-u-a-n-l-i.github.io/projects/IM-Portrait/">https://y-u-a-n-l-i.github.io/projects/IM-Portrait/</a></p>
<p><strong>摘要</strong></p>
<p>本文提出了一种基于三维感知扩散的方法，用于直接从单一身份图像和明确的控制信号（如表情）生成逼真的动态视频图像。该方法生成的多平面图像（MPIs）确保了几何一致性，使其成为适合虚拟现实头盔显示器等沉浸式观看体验的理想选择。与其他通常需要单独阶段或联合优化来重建三维表示的方法不同（如NeRF或三维高斯分布），我们的方法通过单一的降噪过程直接生成最终输出，无需后处理步骤即可有效地渲染新的视角。为了有效地从单眼视频中学习，我们引入了一种训练机制，该机制可以随机重建目标或参考相机空间中的输出MPI。这种方法使模型能够同时学习清晰的图像细节和潜在的三维信息。大量实验证明了我们方法的有效性，该方法在无需明确的三维重建或高质量多视角训练数据的情况下，实现了具有竞争力的化身质量和新颖的视图渲染能力。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>提出了一种基于三维感知扩散的方法，直接从单一身份图像和控制信号生成逼真的动态视频图像。</li>
<li>生成的多平面图像（MPIs）确保了几何一致性，适用于沉浸式观看体验。</li>
<li>与其他需要复杂三维表示的方法不同，该方法通过单一的降噪过程直接生成最终输出，简化了流程。</li>
<li>引入了一种训练机制，随机重建输出MPI，使模型能够同时学习图像细节和潜在的三维信息。</li>
<li>该方法不需要明确的三维重建或高质量的多视角训练数据。</li>
<li>方法实现了具有竞争力的化身质量。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19165">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d2ff881d1ab0d0b4aff210c5b6de48d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9d1d8a2d3376eb8bcec01d470d25c2b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6a3605fcb2c83be4794d477ce4c0b058.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-37b87189576c03cf50993939fe028f40.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RGS-DR-Reflective-Gaussian-Surfels-with-Deferred-Rendering-for-Shiny-Objects"><a href="#RGS-DR-Reflective-Gaussian-Surfels-with-Deferred-Rendering-for-Shiny-Objects" class="headerlink" title="RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects"></a>RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects</h2><p><strong>Authors:Georgios Kouros, Minye Wu, Tinne Tuytelaars</strong></p>
<p>We introduce RGS-DR, a novel inverse rendering method for reconstructing and rendering glossy and reflective objects with support for flexible relighting and scene editing. Unlike existing methods (e.g., NeRF and 3D Gaussian Splatting), which struggle with view-dependent effects, RGS-DR utilizes a 2D Gaussian surfel representation to accurately estimate geometry and surface normals, an essential property for high-quality inverse rendering. Our approach explicitly models geometric and material properties through learnable primitives rasterized into a deferred shading pipeline, effectively reducing rendering artifacts and preserving sharp reflections. By employing a multi-level cube mipmap, RGS-DR accurately approximates environment lighting integrals, facilitating high-quality reconstruction and relighting. A residual pass with spherical-mipmap-based directional encoding further refines the appearance modeling. Experiments demonstrate that RGS-DR achieves high-quality reconstruction and rendering quality for shiny objects, often outperforming reconstruction-exclusive state-of-the-art methods incapable of relighting. </p>
<blockquote>
<p>我们介绍了RGS-DR，这是一种用于重建和渲染光滑和反射物体的新型逆向渲染方法，支持灵活的重新打光和场景编辑。与现有方法（例如NeRF和3D高斯拼贴）不同，后者在处理视图相关效果时遇到困难，RGS-DR利用2D高斯surfel表示法准确估计几何和表面法线，这是高质量逆向渲染的基本属性。我们的方法通过可学习的原始元素显式建模几何和材料属性，并将其渲染为延迟着色管道，这有效地减少了渲染伪影并保留了锐利的反射。通过采用多层立方体mipmap，RGS-DR能够准确近似环境光照积分，从而实现高质量的重建和重新打光。基于球形mipmap的方向编码的残差传递进一步改进了外观建模。实验表明，RGS-DR在重建和渲染光泽物体时达到了高质量的效果，往往超越了那些无法进行重新打光的专属重建的最先进方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18468v2">PDF</a> </p>
<p><strong>摘要</strong><br>RGS-DR是一种新型的逆渲染方法，能够重建和渲染具有光泽和反射特性的物体，并支持灵活的重新照明和场景编辑。与现有的NeRF和3D高斯平板等方法不同，RGS-DR采用2D高斯曲面表示法准确估计几何和表面法线，这对于高质量逆渲染至关重要。通过可学习的原始几何和材料属性，我们的方法能够减少渲染伪影并保留清晰的反射。通过采用多层立方体mipmap，RGS-DR能够准确近似环境光照积分，从而实现高质量重建和重新照明。基于球状mipmap的方向编码的残差传递进一步改进了外观建模。实验表明，RGS-DR在重建和渲染光泽物体方面达到了高质量，通常优于无法重新照明的重建专用最新技术方法。</p>
<p><strong>要点</strong></p>
<ol>
<li>RGS-DR是一种新颖的逆渲染方法，可以重建和渲染具有光泽和反射特性的物体。</li>
<li>它支持灵活的重新照明和场景编辑。</li>
<li>RGS-DR采用2D高斯曲面表示法来准确估计几何和表面法线，这对于高质量逆渲染很重要。</li>
<li>该方法通过可学习的原始几何和材料属性，有效减少渲染伪影，保留清晰反射。</li>
<li>采用多层立方体mipmap，准确近似环境光照积分，实现高质量重建和重新照明。</li>
<li>残差传递与球状mipmap的方向编码相结合，进一步改进外观建模。</li>
<li>实验表明，RGS-DR在重建和渲染光泽物体方面表现出色，通常优于其他方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18468">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3ee68b5ed0b31156461008b3d74e2904.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cbe5993b0e82f86f21ec2593ea7f2ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21a84f71db644f83249586af03728709.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Inpainting-with-Depth-Guided-Cross-View-Consistency"><a href="#3D-Gaussian-Inpainting-with-Depth-Guided-Cross-View-Consistency" class="headerlink" title="3D Gaussian Inpainting with Depth-Guided Cross-View Consistency"></a>3D Gaussian Inpainting with Depth-Guided Cross-View Consistency</h2><p><strong>Authors:Sheng-Yu Huang, Zi-Ting Chou, Yu-Chiang Frank Wang</strong></p>
<p>When performing 3D inpainting using novel-view rendering methods like Neural Radiance Field (NeRF) or 3D Gaussian Splatting (3DGS), how to achieve texture and geometry consistency across camera views has been a challenge. In this paper, we propose a framework of 3D Gaussian Inpainting with Depth-Guided Cross-View Consistency (3DGIC) for cross-view consistent 3D inpainting. Guided by the rendered depth information from each training view, our 3DGIC exploits background pixels visible across different views for updating the inpainting mask, allowing us to refine the 3DGS for inpainting purposes.Through extensive experiments on benchmark datasets, we confirm that our 3DGIC outperforms current state-of-the-art 3D inpainting methods quantitatively and qualitatively. </p>
<blockquote>
<p>在使用Neural Radiance Field（NeRF）或3D Gaussian Splatting（3DGS）等新型视点渲染方法进行3D图像修复时，如何在不同相机视点之间实现纹理和几何一致性是一大挑战。在本文中，我们提出了一种名为“深度引导跨视图一致性三维高斯修复”（Depth-Guided Cross-View Consistency for 3D Gaussian Inpainting，简称3DGIC）的框架，以实现跨视图一致性的三维修复。通过利用来自每个训练视图的渲染深度信息作为指导，我们的3DGIC利用在不同视图中可见的背景像素来更新修复掩码，从而能够对用于修复目的的3DGS进行微调。通过对基准数据集进行大量实验，我们证实我们的3DGIC在数量和质量上都优于当前最先进的3D修复方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11801v2">PDF</a> Accepted to CVPR 2025. For project page, see   <a target="_blank" rel="noopener" href="https://peterjohnsonhuang.github.io/3dgic-pages">https://peterjohnsonhuang.github.io/3dgic-pages</a></p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于深度引导跨视图一致性（Depth-Guided Cross-View Consistency，简称3DGIC）的3D高斯补全框架，用于实现跨视图一致的3D补全。该框架利用从各个训练视图中渲染的深度信息，通过利用在不同视图中可见的背景像素来更新补全掩模，实现对NeRF和3DGS等新型视图渲染方法的3D补全。实验证明，该框架在定量和定性上均优于当前先进的3D补全方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>该论文解决了使用新型视图渲染方法（如NeRF和3DGS）进行3D补全时，如何实现跨相机视角的纹理和几何一致性挑战。</li>
<li>提出了一种基于深度引导跨视图一致性（Depth-Guided Cross-View Consistency，简称3DGIC）的框架用于实现跨视图一致的3D补全。</li>
<li>该框架通过利用渲染的深度信息来指导不同视角下的背景像素，从而实现视图的整合和对3D模型的准确补全。</li>
<li>利用背景像素更新补全掩模，使得在补全过程中能更精细地处理细节。</li>
<li>该框架通过实验证明在定量和定性上均优于当前先进的3D补全方法。</li>
<li>这一研究成果可能进一步推动在计算机视觉和计算机图形学领域中三维模型重建技术的发展和应用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11801">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0ab49b78e681ebc866a1c8a79cb48f55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-093bef097eb0b1f5f8e7dcd7467abdc8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-144e7b763e33bb9fcf3959c55712ba83.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81a788d424a93cc30827a27bbeb0e989.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="EM-GANSim-Real-time-and-Accurate-EM-Simulation-Using-Conditional-GANs-for-3D-Indoor-Scenes"><a href="#EM-GANSim-Real-time-and-Accurate-EM-Simulation-Using-Conditional-GANs-for-3D-Indoor-Scenes" class="headerlink" title="EM-GANSim: Real-time and Accurate EM Simulation Using Conditional GANs   for 3D Indoor Scenes"></a>EM-GANSim: Real-time and Accurate EM Simulation Using Conditional GANs   for 3D Indoor Scenes</h2><p><strong>Authors:Ruichen Wang, Dinesh Manocha</strong></p>
<p>We present a novel machine-learning (ML) approach (EM-GANSim) for real-time electromagnetic (EM) propagation that is used for wireless communication simulation in 3D indoor environments. Our approach uses a modified conditional Generative Adversarial Network (GAN) that incorporates encoded geometry and transmitter location while adhering to the electromagnetic propagation theory. The overall physically-inspired learning is able to predict the power distribution in 3D scenes, which is represented using heatmaps. We evaluated our method on 15 complex 3D indoor environments, with 4 additional scenarios later included in the results, showcasing the generalizability of the model across diverse conditions. Our overall accuracy is comparable to ray tracing-based EM simulation, as evidenced by lower mean squared error values. Furthermore, our GAN-based method drastically reduces the computation time, achieving a 5X speedup on complex benchmarks. In practice, it can compute the signal strength in a few milliseconds on any location in 3D indoor environments. We also present a large dataset of 3D models and EM ray tracing-simulated heatmaps. To the best of our knowledge, EM-GANSim is the first real-time algorithm for EM simulation in complex 3D indoor environments. We plan to release the code and the dataset. </p>
<blockquote>
<p>我们提出了一种用于实时电磁（EM）传播的新型机器学习（ML）方法（EM-GANSim），用于在复杂的3D室内环境中进行无线通信模拟。我们的方法使用了一种改进的条件生成对抗网络（GAN），该网络结合了编码几何和发射机位置，同时遵循电磁传播理论。整体受物理启发的学习方法能够预测3D场景中的功率分布，使用热图进行表示。我们在15个复杂的3D室内环境中评估了我们的方法，并在结果中添加了另外4个场景，展示了该模型在不同条件下的通用性。我们的总体精度与基于光线追踪的EM模拟相当，较低的均方误差值证明了这一点。此外，我们基于GAN的方法极大地减少了计算时间，在复杂的基准测试上实现了5倍的加速。实际上，它可以在毫秒内计算任何3D室内环境中的信号强度。我们还提供了一套大型的3D模型和EM射线追踪模拟热图数据集。据我们所知，EM-GANSim是复杂3D室内环境中进行EM模拟的首个实时算法。我们计划发布代码和数据集。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17366v2">PDF</a> 12 pages, 9 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种用于实时电磁传播模拟的新型机器学习算法EM-GANSim，该算法用于室内三维无线通信模拟。算法采用修改后的条件生成对抗网络（GAN），结合编码几何和发射机位置，遵循电磁传播理论。该算法能够预测三维场景中的功率分布，并以热图形式呈现。在多个复杂室内环境中评估了该方法，其准确性可与基于光线追踪的电磁模拟相当，并且大大减少了计算时间，实现了复杂基准测试的5倍加速。此外，还发布了一个包含三维模型和电磁射线追踪模拟热图的大型数据集。EM-GANSim是首个用于复杂室内环境的实时电磁模拟算法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EM-GANSim是一种新型的机器学习算法，用于实时模拟三维室内环境中的电磁传播。</li>
<li>该算法采用条件生成对抗网络（GAN），结合几何编码、发射机位置和电磁传播理论。</li>
<li>EM-GANSim能够预测三维场景中的功率分布，并以热图形式呈现。</li>
<li>在多个复杂室内环境中评估了EM-GANSim，其准确性可与基于光线追踪的电磁模拟相当。</li>
<li>与其他模拟方法相比，EM-GANSim大大减少了计算时间，实现了加速。</li>
<li>发布了一个包含三维模型和电磁射线追踪模拟热图的大型数据集。</li>
<li>EM-GANSim是首个用于复杂室内环境的实时电磁模拟算法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17366">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9ff96875a1fee62d9e3a160ef9c48574.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a849754b8e6f234452621dccdd22a981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b76f0db6735ec196260200654841dca6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9bafc794cb25f11a35cb0c23c47fd4a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d14fc60da89c074942bbdfd34f6c72ab.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SIR-Multi-view-Inverse-Rendering-with-Decomposable-Shadow-Under-Indoor-Intense-Lighting"><a href="#SIR-Multi-view-Inverse-Rendering-with-Decomposable-Shadow-Under-Indoor-Intense-Lighting" class="headerlink" title="SIR: Multi-view Inverse Rendering with Decomposable Shadow Under Indoor   Intense Lighting"></a>SIR: Multi-view Inverse Rendering with Decomposable Shadow Under Indoor   Intense Lighting</h2><p><strong>Authors:Xiaokang Wei, Zhuoman Liu, Ping Li, Yan Luximon</strong></p>
<p>We propose SIR, an efficient method to decompose differentiable shadows for inverse rendering on indoor scenes using multi-view data, addressing the challenges in accurately decomposing the materials and lighting conditions. Unlike previous methods that struggle with shadow fidelity in complex lighting environments, our approach explicitly learns shadows for enhanced realism in material estimation under unknown light positions. Utilizing posed HDR images as input, SIR employs an SDF-based neural radiance field for comprehensive scene representation. Then, SIR integrates a shadow term with a three-stage material estimation approach to improve SVBRDF quality. Specifically, SIR is designed to learn a differentiable shadow, complemented by BRDF regularization, to optimize inverse rendering accuracy. Extensive experiments on both synthetic and real-world indoor scenes demonstrate the superior performance of SIR over existing methods in both quantitative metrics and qualitative analysis. The significant decomposing ability of SIR enables sophisticated editing capabilities like free-view relighting, object insertion, and material replacement. The code and data are available at <a target="_blank" rel="noopener" href="https://xiaokangwei.github.io/SIR/">https://xiaokangwei.github.io/SIR/</a>. </p>
<blockquote>
<p>我们提出了SIR，这是一种利用多视角数据对室内场景进行逆向渲染的高效可微分阴影分解方法，解决了准确分解材料和照明条件方面的挑战。与以往在复杂光照环境中难以处理阴影保真度的方法不同，我们的方法能够显式地学习阴影，以提高未知光源位置下的材料估计的真实感。SIR利用姿态HDR图像作为输入，采用基于SDF的神经辐射场进行场景全面表示。然后，SIR将阴影项与三阶段材料估计方法相结合，以提高SVBRDF的质量。具体来说，SIR被设计成学习一个可微分的阴影，辅以BRDF正则化，以优化逆向渲染的准确性。在合成和真实室内场景上的大量实验表明，SIR在定量指标和定性分析方面均优于现有方法。SIR的重要分解能力可实现高级编辑功能，如自由视角重新照明、对象插入和材料替换。代码和数据可在<a target="_blank" rel="noopener" href="https://xiaokangwei.github.io/SIR/%E6%89%BE%E5%88%B0%E3%80%82">https://xiaokangwei.github.io/SIR/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.06136v4">PDF</a> ICME 2025. Homepage:<a target="_blank" rel="noopener" href="https://xiaokangwei.github.io/SIR/">https://xiaokangwei.github.io/SIR/</a></p>
<p><strong>Summary</strong></p>
<p>本文提出SIR方法，利用多视角数据在室内场景进行逆向渲染中的可分化阴影分解，解决材料和光照条件准确分解的挑战。SIR采用基于神经辐射场的SDF技术进行全面场景表示，通过三阶段材料估计方法与阴影项集成，提高SVBRDF质量。SIR设计用于学习可分化阴影，配合BRDF正则化，优化逆向渲染精度。在合成和真实室内场景的实验中，SIR在定量指标和定性分析上均表现出卓越性能，具备高级编辑能力，如自由视角重新照明、对象插入和材料替换。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SIR是一种利用多视角数据进行室内场景逆向渲染的方法，能够分解阴影以准确表示材料和光照条件。</li>
<li>采用基于神经辐射场的SDF技术进行全面场景表示。</li>
<li>通过三阶段材料估计方法与阴影项集成，提高SVBRDF质量。</li>
<li>SIR能够学习可分化阴影，配合BRDF正则化，优化逆向渲染精度。</li>
<li>在合成和真实室内场景的实验中，SIR性能卓越，超过现有方法。</li>
<li>SIR具备高级编辑能力，如自由视角重新照明、对象插入和材料替换。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.06136">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fd0dddd0d6f886fcc72be9f867f5028a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6271788eee0a8926a207e27ed3024fc9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-14331b74298f52eac4a292ade79cdf02.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-af5411e14789d5434717749e0cb1e8ae.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-04-30  DeeCLIP A Robust and Generalizable Transformer-Based Framework for   Detecting AI-Generated Images
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-c3cff7ca5b878ce125255dbb6e2ea578.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2025-04-30  Mesh-Learner Texturing Mesh with Spherical Harmonics
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23901.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
