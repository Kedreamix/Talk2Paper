<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  Masked Language Prompting for Generative Data Augmentation in Few-shot   Fashion Style Recognition">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-68629da72c57f0f6036e4e1cc6636951.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    28 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-30-æ›´æ–°"><a href="#2025-04-30-æ›´æ–°" class="headerlink" title="2025-04-30 æ›´æ–°"></a>2025-04-30 æ›´æ–°</h1><h2 id="Masked-Language-Prompting-for-Generative-Data-Augmentation-in-Few-shot-Fashion-Style-Recognition"><a href="#Masked-Language-Prompting-for-Generative-Data-Augmentation-in-Few-shot-Fashion-Style-Recognition" class="headerlink" title="Masked Language Prompting for Generative Data Augmentation in Few-shot   Fashion Style Recognition"></a>Masked Language Prompting for Generative Data Augmentation in Few-shot   Fashion Style Recognition</h2><p><strong>Authors:Yuki Hirakawa, Ryotaro Shimizu</strong></p>
<p>Constructing dataset for fashion style recognition is challenging due to the inherent subjectivity and ambiguity of style concepts. Recent advances in text-to-image models have facilitated generative data augmentation by synthesizing images from labeled data, yet existing methods based solely on class names or reference captions often fail to balance visual diversity and style consistency. In this work, we propose \textbf{Masked Language Prompting (MLP)}, a novel prompting strategy that masks selected words in a reference caption and leverages large language models to generate diverse yet semantically coherent completions. This approach preserves the structural semantics of the original caption while introducing attribute-level variations aligned with the intended style, enabling style-consistent and diverse image generation without fine-tuning. Experimental results on the FashionStyle14 dataset demonstrate that our MLP-based augmentation consistently outperforms class-name and caption-based baselines, validating its effectiveness for fashion style recognition under limited supervision. </p>
<blockquote>
<p>æ„å»ºç”¨äºæ—¶å°šé£æ ¼è¯†åˆ«çš„æ•°æ®é›†å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºé£æ ¼æ¦‚å¿µå…·æœ‰å›ºæœ‰çš„ä¸»è§‚æ€§å’Œæ¨¡ç³Šæ€§ã€‚æœ€è¿‘çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„è¿›æ­¥é€šè¿‡ä»æ ‡è®°æ•°æ®ä¸­åˆæˆå›¾åƒä¿ƒè¿›äº†ç”Ÿæˆæ•°æ®å¢å¼ºï¼Œä½†ç°æœ‰æ–¹æ³•ä»…åŸºäºç±»åæˆ–å‚è€ƒå­—å¹•å¾€å¾€æ— æ³•åœ¨è§†è§‰å¤šæ ·æ€§å’Œé£æ ¼ä¸€è‡´æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>Masked Language Promptingï¼ˆMLPï¼‰</strong>ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æç¤ºç­–ç•¥ï¼Œå®ƒæ©ç›–äº†å‚è€ƒå­—å¹•ä¸­çš„é€‰å®šå•è¯ï¼Œå¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¤šæ ·ä½†è¯­ä¹‰è¿è´¯çš„è¡¥å…¨ã€‚è¿™ç§æ–¹æ³•ä¿ç•™äº†åŸå§‹å­—å¹•çš„ç»“æ„è¯­ä¹‰ï¼ŒåŒæ—¶å¼•å…¥äº†ä¸æ—¢å®šé£æ ¼ä¸€è‡´çš„å±æ€§çº§åˆ«å˜åŒ–ï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹ç”Ÿæˆé£æ ¼ä¸€è‡´ä¸”å¤šæ ·çš„å›¾åƒã€‚åœ¨FashionStyle14æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬åŸºäºMLPçš„å¢å¼ºæ–¹æ³•ä¸€ç›´ä¼˜äºåŸºäºç±»åå’Œå­—å¹•çš„åŸºçº¿æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨æœ‰é™ç›‘ç£ä¸‹å¯¹æ—¶å°šé£æ ¼è¯†åˆ«çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19455v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ—¶å°šé£æ ¼è¯†åˆ«æ•°æ®é›†æ„å»ºå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºé£æ ¼æ¦‚å¿µå…·æœ‰ä¸»è§‚æ€§å’Œæ¨¡ç³Šæ€§ã€‚æœ€è¿‘æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„è¿›æ­¥é€šè¿‡åˆæˆå›¾åƒç®€åŒ–äº†ç”Ÿæˆæ•°æ®å¢å¼ºã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•å¹³è¡¡è§†è§‰å¤šæ ·æ€§å’Œé£æ ¼ä¸€è‡´æ€§ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§åä¸ºMasked Language Promptingï¼ˆMLPï¼‰çš„æ–°æç¤ºç­–ç•¥ï¼Œå®ƒé€šè¿‡æ©ç›–å‚è€ƒå­—å¹•ä¸­çš„é€‰å®šè¯æ±‡å¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¤šæ ·ä¸”è¯­ä¹‰è¿è´¯çš„è¡¥å…¨å†…å®¹æ¥å®ç°é£æ ¼ä¸€è‡´ä¸”å¤šæ ·åŒ–çš„å›¾åƒç”Ÿæˆã€‚åœ¨FashionStyleæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºMLPçš„å¢å¼ºæ–¹æ³•ä¼˜äºåŸºäºç±»åˆ«åç§°å’Œæ ‡é¢˜çš„åŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å®ƒåœ¨æœ‰é™ç›‘ç£ä¸‹çš„æ—¶å°šé£æ ¼è¯†åˆ«çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ—¶å°šé£æ ¼è¯†åˆ«æ•°æ®é›†æ„å»ºå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºé£æ ¼æ¦‚å¿µå…·æœ‰ä¸»è§‚æ€§å’Œæ¨¡ç³Šæ€§ã€‚</li>
<li>å½“å‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„æ–¹æ³•æœ‰åŠ©äºç”Ÿæˆæ•°æ®å¢å¼ºã€‚</li>
<li>ç°æœ‰æ–¹æ³•éš¾ä»¥å¹³è¡¡è§†è§‰å¤šæ ·æ€§å’Œé£æ ¼ä¸€è‡´æ€§ã€‚</li>
<li>Masked Language Promptingï¼ˆMLPï¼‰æ˜¯ä¸€ç§æ–°çš„æç¤ºç­–ç•¥ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¤šæ ·ä¸”è¯­ä¹‰è¿è´¯çš„è¡¥å…¨å†…å®¹ã€‚</li>
<li>MLPé€šè¿‡æ©ç›–å‚è€ƒå­—å¹•ä¸­çš„è¯æ±‡æ¥ä¿ç•™åŸå§‹å­—å¹•çš„ç»“æ„è¯­ä¹‰ï¼ŒåŒæ—¶å¼•å…¥ä¸é¢„æœŸé£æ ¼ä¸€è‡´çš„å±æ€§çº§åˆ«å˜åŒ–ã€‚</li>
<li>åŸºäºMLPçš„å¢å¼ºæ–¹æ³•åœ¨FashionStyleæ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œä¼˜äºåŸºäºç±»åˆ«åç§°å’Œæ ‡é¢˜çš„åŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19455">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9ee51b83b5369599da3b57a830ccc00e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ea2d30293a7e2c6b04119a2b00312ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ff431581473c3ffd9460e943281ad89.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-766318608f2b2835fd8e523f3cd54875.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Small-Models-Big-Tasks-An-Exploratory-Empirical-Study-on-Small-Language-Models-for-Function-Calling"><a href="#Small-Models-Big-Tasks-An-Exploratory-Empirical-Study-on-Small-Language-Models-for-Function-Calling" class="headerlink" title="Small Models, Big Tasks: An Exploratory Empirical Study on Small   Language Models for Function Calling"></a>Small Models, Big Tasks: An Exploratory Empirical Study on Small   Language Models for Function Calling</h2><p><strong>Authors:Ishan Kavathekar, Raghav Donakanti, Ponnurangam Kumaraguru, Karthik Vaidhyanathan</strong></p>
<p>Function calling is a complex task with widespread applications in domains such as information retrieval, software engineering and automation. For example, a query to book the shortest flight from New York to London on January 15 requires identifying the correct parameters to generate accurate function calls. Large Language Models (LLMs) can automate this process but are computationally expensive and impractical in resource-constrained settings. In contrast, Small Language Models (SLMs) can operate efficiently, offering faster response times, and lower computational demands, making them potential candidates for function calling on edge devices. In this exploratory empirical study, we evaluate the efficacy of SLMs in generating function calls across diverse domains using zero-shot, few-shot, and fine-tuning approaches, both with and without prompt injection, while also providing the finetuned models to facilitate future applications. Furthermore, we analyze the model responses across a range of metrics, capturing various aspects of function call generation. Additionally, we perform experiments on an edge device to evaluate their performance in terms of latency and memory usage, providing useful insights into their practical applicability. Our findings show that while SLMs improve from zero-shot to few-shot and perform best with fine-tuning, they struggle significantly with adhering to the given output format. Prompt injection experiments further indicate that the models are generally robust and exhibit only a slight decline in performance. While SLMs demonstrate potential for the function call generation task, our results also highlight areas that need further refinement for real-time functioning. </p>
<blockquote>
<p>å‡½æ•°è°ƒç”¨æ˜¯ä¸€é¡¹å…·æœ‰å¹¿æ³›åº”ç”¨çš„å¤æ‚ä»»åŠ¡ï¼Œåœ¨ä¿¡æ¯æ£€ç´¢ã€è½¯ä»¶å·¥ç¨‹å’Œè‡ªåŠ¨åŒ–ç­‰é¢†åŸŸéƒ½æœ‰æ¶‰åŠã€‚ä¾‹å¦‚ï¼Œè¦æŸ¥è¯¢1æœˆ15æ—¥ä»çº½çº¦åˆ°ä¼¦æ•¦çš„æœ€çŸ­èˆªç­ï¼Œéœ€è¦è¯†åˆ«æ­£ç¡®çš„å‚æ•°æ¥ç”Ÿæˆå‡†ç¡®çš„å‡½æ•°è°ƒç”¨ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥è‡ªåŠ¨åŒ–è¿™ä¸ªè¿‡ç¨‹ï¼Œä½†åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ï¼Œå®ƒä»¬è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸å¤ªå®ç”¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰å¯ä»¥é«˜æ•ˆè¿è¡Œï¼Œæä¾›æ›´å¿«çš„å“åº”æ—¶é—´å’Œæ›´ä½çš„è®¡ç®—éœ€æ±‚ï¼Œä½¿å…¶æˆä¸ºè¾¹ç¼˜è®¾å¤‡ä¸Šå‡½æ•°è°ƒç”¨çš„æ½œåœ¨å€™é€‰è€…ã€‚åœ¨è¿™é¡¹æ¢ç´¢æ€§å®è¯ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†SLMsåœ¨è·¨ä¸åŒé¢†åŸŸç”Ÿæˆå‡½æ•°è°ƒç”¨æ—¶çš„æœ‰æ•ˆæ€§ï¼Œé‡‡ç”¨äº†é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæ–¹æ³•ï¼Œæœ‰&#x2F;æ— æç¤ºæ³¨å…¥ï¼ŒåŒæ—¶æä¾›å¾®è°ƒæ¨¡å‹ä»¥ä¿ƒè¿›æœªæ¥åº”ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡åˆ†æä¸€ç³»åˆ—æŒ‡æ ‡çš„æ¨¡å‹å“åº”ï¼Œæ•æ‰å‡½æ•°è°ƒç”¨ç”Ÿæˆçš„å„ä¸ªæ–¹é¢ã€‚å¦å¤–ï¼Œæˆ‘ä»¬åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œå®éªŒï¼Œä»¥è¯„ä¼°å…¶åœ¨å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨æ–¹é¢çš„æ€§èƒ½ï¼Œä¸ºå®é™…åº”ç”¨æä¾›æœ‰ç”¨è§è§£ã€‚æˆ‘ä»¬å‘ç°ï¼Œè™½ç„¶SLMsä»é›¶æ ·æœ¬åˆ°å°‘æ ·æœ¬æœ‰æ‰€æå‡ï¼Œå¹¶åœ¨å¾®è°ƒæ—¶è¡¨ç°æœ€ä½³ï¼Œä½†å®ƒä»¬åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šéš¾ä»¥éµå¾ªç»™å®šçš„è¾“å‡ºæ ¼å¼ã€‚æç¤ºæ³¨å…¥å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹é€šå¸¸å¾ˆç¨³å¥ï¼Œæ€§èƒ½åªæœ‰è½»å¾®ä¸‹é™ã€‚è™½ç„¶SLMåœ¨å‡½æ•°è°ƒç”¨ç”Ÿæˆä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†æˆ‘ä»¬çš„ç»“æœä¹Ÿå¼ºè°ƒäº†éœ€è¦è¿›ä¸€æ­¥å®Œå–„ä»¥å®ç°å®æ—¶åŠŸèƒ½çš„é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19277v1">PDF</a> Accepted at EASE 2025 AI Models and Data Evaluation track</p>
<p><strong>Summary</strong></p>
<p>æ­¤æ–‡æœ¬æ¢è®¨äº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨ç”Ÿæˆå‡½æ•°è°ƒç”¨æ–¹é¢çš„æ•ˆèƒ½ã€‚è¯¥ç ”ç©¶è¯„ä¼°äº†SLMsåœ¨ä¸åŒé¢†åŸŸç”Ÿæˆå‡½æ•°è°ƒç”¨çš„æ•ˆæœï¼Œé‡‡ç”¨äº†é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæ–¹æ³•ï¼ŒåŒæ—¶åˆ†æäº†æ¨¡å‹å“åº”çš„å„ç§æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä»¥è¯„ä¼°å…¶å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨æƒ…å†µã€‚ç ”ç©¶å‘ç°ï¼ŒSLMsä»é›¶æ ·æœ¬åˆ°å°‘æ ·æœ¬æœ‰æ‰€æå‡ï¼Œåœ¨å¾®è°ƒåè¡¨ç°æœ€ä½³ï¼Œä½†åœ¨éµå¾ªè¾“å‡ºæ ¼å¼æ–¹é¢å­˜åœ¨å›°éš¾ã€‚åŒæ—¶ï¼Œå®éªŒæ˜¾ç¤ºæ¨¡å‹é€šå¸¸å¾ˆç¨³å¥ï¼Œæ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚è™½ç„¶SLMsåœ¨å‡½æ•°è°ƒç”¨ç”Ÿæˆä»»åŠ¡ä¸Šå±•ç°å‡ºæ½œåŠ›ï¼Œä½†ä»éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›ä»¥é€‚åº”å®æ—¶åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SLMsåœ¨å‡½æ•°è°ƒç”¨ç”Ÿæˆæ–¹é¢å±•ç°å‡ºäº†æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚</li>
<li>ç ”ç©¶è¯„ä¼°äº†SLMsåœ¨å¤šç§é¢†åŸŸç”Ÿæˆå‡½æ•°è°ƒç”¨çš„æ•ˆèƒ½ï¼Œé‡‡ç”¨äº†é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæ–¹æ³•ã€‚</li>
<li>SLMsåœ¨é›¶æ ·æœ¬åˆ°å°‘æ ·æœ¬çš„è¡¨ç°æœ‰æ‰€æå‡ï¼Œç»è¿‡å¾®è°ƒåè¡¨ç°æœ€ä½³ã€‚</li>
<li>æ¨¡å‹åœ¨éµå¾ªè¾“å‡ºæ ¼å¼æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>é€šè¿‡å®éªŒå‘ç°ï¼ŒSLMsé€šå¸¸å¾ˆç¨³å¥ï¼Œæ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚</li>
<li>åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œçš„å®éªŒè¯„ä¼°äº†SLMsçš„å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨æƒ…å†µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19277">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c863f44c0a6791f6b0c499bda76bb106.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e05979986a47d103ba537cea573f71a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf50c2498cb62e7e921a43d4aa11075f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b1b365f235ff461b20b2fee4267a689.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Fast-and-Robust-Task-Sampling-with-Posterior-and-Diversity-Synergies-for-Adaptive-Decision-Makers-in-Randomized-Environments"><a href="#Fast-and-Robust-Task-Sampling-with-Posterior-and-Diversity-Synergies-for-Adaptive-Decision-Makers-in-Randomized-Environments" class="headerlink" title="Fast and Robust: Task Sampling with Posterior and Diversity Synergies   for Adaptive Decision-Makers in Randomized Environments"></a>Fast and Robust: Task Sampling with Posterior and Diversity Synergies   for Adaptive Decision-Makers in Randomized Environments</h2><p><strong>Authors:Yun Qu,  Qi,  Wang, Yixiu Mao, Yiqin Lv, Xiangyang Ji</strong></p>
<p>Task robust adaptation is a long-standing pursuit in sequential decision-making. Some risk-averse strategies, e.g., the conditional value-at-risk principle, are incorporated in domain randomization or meta reinforcement learning to prioritize difficult tasks in optimization, which demand costly intensive evaluations. The efficiency issue prompts the development of robust active task sampling to train adaptive policies, where risk-predictive models are used to surrogate policy evaluation. This work characterizes the optimization pipeline of robust active task sampling as a Markov decision process, posits theoretical and practical insights, and constitutes robustness concepts in risk-averse scenarios. Importantly, we propose an easy-to-implement method, referred to as Posterior and Diversity Synergized Task Sampling (PDTS), to accommodate fast and robust sequential decision-making. Extensive experiments show that PDTS unlocks the potential of robust active task sampling, significantly improves the zero-shot and few-shot adaptation robustness in challenging tasks, and even accelerates the learning process under certain scenarios. Our project website is at <a target="_blank" rel="noopener" href="https://thu-rllab.github.io/PDTS_project_page">https://thu-rllab.github.io/PDTS_project_page</a>. </p>
<blockquote>
<p>ä»»åŠ¡é²æ£’æ€§é€‚åº”æ˜¯åºåˆ—å†³ç­–åˆ¶å®šä¸­ä¸€ä¸ªé•¿æœŸè¿½æ±‚çš„ç›®æ ‡ã€‚ä¸€äº›é£é™©è§„é¿ç­–ç•¥ï¼Œä¾‹å¦‚æ¡ä»¶é£é™©ä»·å€¼åŸåˆ™ï¼Œè¢«çº³å…¥é¢†åŸŸéšæœºåŒ–æˆ–å…ƒå¼ºåŒ–å­¦ä¹ ä¸­ï¼Œä»¥ä¼˜åŒ–ä¸­çš„ä¼˜å…ˆå¤„ç†å›°éš¾ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡éœ€è¦è¿›è¡Œæ˜‚è´µçš„å¯†é›†è¯„ä¼°ã€‚æ•ˆç‡é—®é¢˜ä¿ƒä½¿å¼€å‘ç¨³å¥çš„æ´»åŠ¨ä»»åŠ¡é‡‡æ ·æ¥è®­ç»ƒè‡ªé€‚åº”ç­–ç•¥ï¼Œå…¶ä¸­é£é™©é¢„æµ‹æ¨¡å‹ç”¨äºæ›¿ä»£ç­–ç•¥è¯„ä¼°ã€‚è¿™é¡¹å·¥ä½œå°†ç¨³å¥æ´»åŠ¨ä»»åŠ¡é‡‡æ ·çš„ä¼˜åŒ–ç®¡é“ç‰¹å¾åŒ–ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œæä¾›äº†ç†è®ºå’Œå®è·µè§è§£ï¼Œå¹¶æ„æˆäº†é£é™©è§„é¿åœºæ™¯ä¸­çš„ç¨³å¥æ€§æ¦‚å¿µã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ˜“äºå®æ–½çš„æ–¹æ³•ï¼Œç§°ä¸ºâ€œåéªŒå’Œå¤šæ ·æ€§ååŒä»»åŠ¡é‡‡æ ·ï¼ˆPDTSï¼‰â€ï¼Œä»¥å®ç°å¿«é€Ÿå’Œç¨³å¥çš„åºåˆ—å†³ç­–åˆ¶å®šã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPDTSé‡Šæ”¾äº†ç¨³å¥æ´»åŠ¨ä»»åŠ¡é‡‡æ ·çš„æ½œåŠ›ï¼Œæ˜¾è‘—æé«˜äº†æŒ‘æˆ˜æ€§ä»»åŠ¡çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬é€‚åº”ç¨³å¥æ€§ï¼Œç”šè‡³åœ¨ç‰¹å®šåœºæ™¯ä¸‹åŠ é€Ÿäº†å­¦ä¹ è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„é¡¹ç›®ç½‘ç«™æ˜¯<a target="_blank" rel="noopener" href="https://thu-rllab.github.io/PDTS_project_page%E3%80%82">https://thu-rllab.github.io/PDTS_project_pageã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19139v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºåºè´¯å†³ç­–åˆ¶å®šçš„ä»»åŠ¡ç¨³å¥é€‚åº”æ˜¯ä¸€é¡¹é•¿æœŸè¿½æ±‚ã€‚æœ¬ç ”ç©¶å°†é£é™©è§„é¿ç­–ç•¥èå…¥é¢†åŸŸéšæœºåŒ–æˆ–å…ƒå¼ºåŒ–å­¦ä¹ ä¸­ï¼Œä¼˜å…ˆå¤„ç†ä¼˜åŒ–ä¸­çš„å›°éš¾ä»»åŠ¡ï¼ŒåŒæ—¶è§£å†³æ•ˆç‡é—®é¢˜ã€‚ç ”ç©¶å‘å±•å‡ºç¨³å¥çš„ä»»åŠ¡ä¸»åŠ¨é‡‡æ ·æ–¹æ³•ï¼Œç”¨ä»¥è®­ç»ƒé€‚åº”æ€§æ”¿ç­–ï¼Œå¹¶ç”¨é£é™©é¢„æµ‹æ¨¡å‹æ›¿ä»£æ”¿ç­–è¯„ä¼°ã€‚æå‡ºä¸€ç§ç®€å•å®ç”¨çš„æ–¹æ³•â€”â€”åéªŒä¸å¤šæ ·æ€§ååŒä»»åŠ¡é‡‡æ ·ï¼ˆPDTSï¼‰ï¼Œå®ç°å¿«é€Ÿç¨³å¥çš„åºè´¯å†³ç­–åˆ¶å®šã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPDTSè§£é”äº†ç¨³å¥ä¸»åŠ¨ä»»åŠ¡é‡‡æ ·çš„æ½œåŠ›ï¼Œæ˜¾è‘—æé«˜äº†æŒ‘æˆ˜æ€§ä»»åŠ¡çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬é€‚åº”ç¨³å¥æ€§ï¼Œå¹¶åœ¨æŸäº›åœºæ™¯ä¸‹åŠ é€Ÿäº†å­¦ä¹ è¿‡ç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»»åŠ¡ç¨³å¥é€‚åº”æ˜¯åºè´¯å†³ç­–ä¸­çš„é•¿æœŸç›®æ ‡ã€‚</li>
<li>é£é™©è§„é¿ç­–ç•¥è¢«èå…¥é¢†åŸŸéšæœºåŒ–æˆ–å…ƒå¼ºåŒ–å­¦ä¹ ä¸­ä»¥å¤„ç†å›°éš¾ä»»åŠ¡ã€‚</li>
<li>æ•ˆç‡å’Œä¼˜åŒ–ä¸­çš„æŒ‘æˆ˜ä¿ƒä½¿å‘å±•ç¨³å¥çš„ä»»åŠ¡ä¸»åŠ¨é‡‡æ ·æ–¹æ³•ã€‚</li>
<li>é£é™©é¢„æµ‹æ¨¡å‹ç”¨äºæ›¿ä»£æ”¿ç­–è¯„ä¼°ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç®€å•å®ç”¨çš„æ–¹æ³•â€”â€”åéªŒä¸å¤šæ ·æ€§ååŒä»»åŠ¡é‡‡æ ·ï¼ˆPDTSï¼‰ã€‚</li>
<li>PDTSæ˜¾è‘—æé«˜äº†åœ¨æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬é€‚åº”ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19139">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4834780cb35380eb46c41edd2778797c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-66b52637419d9dd2ee3c47ad40d43e35.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e91d7f44311fefd5a291998f78500b03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d80dbd27b48536117de506e2a884d544.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Towards-Robust-Dialogue-Breakdown-Detection-Addressing-Disruptors-in-Large-Language-Models-with-Self-Guided-Reasoning"><a href="#Towards-Robust-Dialogue-Breakdown-Detection-Addressing-Disruptors-in-Large-Language-Models-with-Self-Guided-Reasoning" class="headerlink" title="Towards Robust Dialogue Breakdown Detection: Addressing Disruptors in   Large Language Models with Self-Guided Reasoning"></a>Towards Robust Dialogue Breakdown Detection: Addressing Disruptors in   Large Language Models with Self-Guided Reasoning</h2><p><strong>Authors:Abdellah Ghassel, Xianzhi Li, Xiaodan Zhu</strong></p>
<p>Large language models (LLMs) are rapidly changing various domains. However, their capabilities in handling conversational breakdowns still require an in-depth exploration. This paper addresses the challenge of detecting and mitigating dialogue breakdowns within LLM-driven conversational systems. While powerful models from OpenAI and Anthropic excel in many dialogue tasks, they can still produce incoherent or contradictory responses, commonly referred to as breakdowns, which undermine user trust. To tackle this, we propose an approach that combines specialized fine-tuning with advanced prompting strategies, including few-shot learning, chain-of-thought reasoning, and analogical prompting. In particular, we fine-tune a small 8B model and demonstrate its robust classification and calibration capabilities in English and Japanese dialogue. We also validate its generalization on the BETOLD dataset, achieving a 7% accuracy improvement over its base model. Furthermore, we introduce a real-time deployment architecture that selectively escalates suspicious responses to more resource-intensive frontier models only when breakdowns are detected, significantly cutting operational expenses and energy consumption. Experimental results show our method surpasses prior state-of-the-art specialized classifiers while also narrowing performance gaps between smaller open-source models and large proprietary ones. Our approach offers a scalable solution for robust conversational AI in high-impact domains by combining efficiency, interpretability, and reliability. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨è¿…é€Ÿæ”¹å˜å„ä¸ªé¢†åŸŸã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å¤„ç†å¯¹è¯ä¸­æ–­æ–¹é¢çš„èƒ½åŠ›ä»ç„¶éœ€è¦æ·±å…¥ç ”ç©¶ã€‚æœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨LLMé©±åŠ¨çš„å¯¹è¯ç³»ç»Ÿä¸­æ£€æµ‹å’Œç¼“è§£å¯¹è¯ä¸­æ–­çš„æŒ‘æˆ˜ã€‚è™½ç„¶æ¥è‡ªOpenAIå’ŒAnthropicçš„å¼ºå¤§æ¨¡å‹åœ¨è®¸å¤šå¯¹è¯ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä»ç„¶å¯èƒ½äº§ç”Ÿä¸è¿è´¯æˆ–çŸ›ç›¾çš„å›åº”ï¼Œé€šå¸¸è¢«ç§°ä¸ºä¸­æ–­ï¼Œè¿™ä¼šç ´åç”¨æˆ·ä¿¡ä»»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆä¸“ä¸šå¾®è°ƒä¸å…ˆè¿›æç¤ºç­–ç•¥çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å°æ ·æœ¬å­¦ä¹ ã€æ€ç»´é“¾æ¨ç†å’Œç±»æ¯”æç¤ºã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å¯¹ä¸€ä¸ªå°å‹8Bæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨è‹±è¯­å’Œæ—¥è¯­å¯¹è¯ä¸­çš„ç¨³å¥åˆ†ç±»å’Œæ ¡å‡†èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨BETOLDæ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶æ³›åŒ–æ€§ï¼Œç›¸æ¯”åŸºç¡€æ¨¡å‹å®ç°äº†7%çš„å‡†ç¡®ç‡æå‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å®æ—¶éƒ¨ç½²æ¶æ„ï¼Œè¯¥æ¶æ„ä»…åœ¨æ£€æµ‹åˆ°ä¸­æ–­æ—¶é€‰æ‹©å°†å¯ç–‘çš„å“åº”å‡çº§åˆ°æ›´è€—è´¹èµ„æºå’Œè®¡ç®—èµ„æºçš„å°–ç«¯æ¨¡å‹ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è¿è¥æˆæœ¬å¹¶å‡å°‘äº†èƒ½æºæ¶ˆè€—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›çš„ä¸“ç”¨åˆ†ç±»å™¨ï¼ŒåŒæ—¶ç¼©å°äº†å¼€æºå°å‹æ¨¡å‹å’Œå¤§å‹ä¸“æœ‰æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚é€šè¿‡ç»“åˆæ•ˆç‡ã€å¯è§£é‡Šæ€§å’Œå¯é æ€§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºé«˜å½±å“åŠ›é¢†åŸŸæä¾›ç¨³å¥çš„å¯¹è¯AIçš„å¯æ‰©å±•è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18839v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¯¹è¯ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†å¯¹è¯å´©æºƒæ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆä¸“é—¨å¾®è°ƒä¸å…ˆè¿›æç¤ºç­–ç•¥çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å°æ ·æœ¬å­¦ä¹ ã€é“¾å¼æ€ç»´æ¨ç†å’Œç±»æ¯”æç¤ºï¼Œä»¥æ£€æµ‹å’Œå‡è½»LLMé©±åŠ¨å¯¹è¯ç³»ç»Ÿä¸­çš„å¯¹è¯å´©æºƒé—®é¢˜ã€‚é€šè¿‡ç²¾ç»†è°ƒæ•´8Bæ¨¡å‹ï¼Œå¹¶åœ¨è‹±è¯­å’Œæ—¥è¯­å¯¹è¯ä¸­è¿›è¡Œæ¼”ç¤ºï¼Œä»¥åŠåœ¨å®é™…éƒ¨ç½²æ¶æ„ä¸­é€‰æ‹©æ€§å‡çº§å¯ç–‘å“åº”ï¼Œä»…åœ¨æ£€æµ‹åˆ°å´©æºƒæ—¶æ‰ä½¿ç”¨æ›´å¤šèµ„æºå¯†é›†å‹å‰æ²¿æ¨¡å‹ï¼Œä»è€Œé™ä½æˆæœ¬å’Œèƒ½è€—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…ˆå‰çš„æœ€æ–°ä¸“ç”¨åˆ†ç±»å™¨ï¼Œå¹¶ç¼©å°äº†å¼€æºå°å‹æ¨¡å‹ä¸å¤§å‹ä¸“æœ‰æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¯¹è¯ä»»åŠ¡ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å¤„ç†å¯¹è¯å´©æºƒä»éœ€æ·±å…¥ç ”ç©¶ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆä¸“é—¨å¾®è°ƒä¸å…ˆè¿›æç¤ºç­–ç•¥çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ£€æµ‹å’Œå‡è½»LLMåœ¨å¯¹è¯ä¸­çš„å´©æºƒé—®é¢˜ã€‚</li>
<li>é€šè¿‡ç²¾ç»†è°ƒæ•´æ¨¡å‹ï¼Œè®ºæ–‡å±•ç¤ºäº†åœ¨è‹±è¯­å’Œæ—¥è¯­å¯¹è¯ä¸­çš„ç¨³å¥åˆ†ç±»å’Œæ ¡å‡†èƒ½åŠ›ã€‚</li>
<li>è®ºæ–‡ä»‹ç»äº†ä¸€ç§å®æ—¶éƒ¨ç½²æ¶æ„ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿé€‰æ‹©æ€§å‡çº§å¯ç–‘å“åº”ï¼Œä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨æ›´å¤šèµ„æºï¼Œä»è€Œæé«˜æ•ˆç‡å¹¶é™ä½æˆæœ¬ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ£€æµ‹å¯¹è¯å´©æºƒæ–¹é¢ä¼˜äºä¹‹å‰çš„ä¸“ç”¨åˆ†ç±»å™¨ã€‚</li>
<li>è¯¥æ–¹æ³•ç¼©å°äº†å¼€æºå°å‹æ¨¡å‹ä¸å¤§å‹ä¸“æœ‰æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18839">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7e0d3e9fd71889ccaed5ef5ff11547a2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d26b3c8523cdadf3583f1aa9848b48f7.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Active-Few-Shot-Learning-for-Vertex-Classification-Starting-from-an-Unlabeled-Dataset"><a href="#Active-Few-Shot-Learning-for-Vertex-Classification-Starting-from-an-Unlabeled-Dataset" class="headerlink" title="Active Few-Shot Learning for Vertex Classification Starting from an   Unlabeled Dataset"></a>Active Few-Shot Learning for Vertex Classification Starting from an   Unlabeled Dataset</h2><p><strong>Authors:Felix Burr, Marcel Hoffmann, Ansgar Scherp</strong></p>
<p>Despite the ample availability of graph data, obtaining vertex labels is a tedious and expensive task. Therefore, it is desirable to learn from a few labeled vertices only. Existing few-shot learners assume a class oracle, which provides labeled vertices for a desired class. However, such an oracle is not available in a real-world setting, i.e., when drawing a vertex for labeling it is unknown to which class the vertex belongs. Few-shot learners are often combined with prototypical networks, while classical semi-supervised vertex classification uses discriminative models, e.g., Graph Convolutional Networks (GCN). In this paper, we train our models by iteratively prompting a human annotator with vertices to annotate. We perform three experiments where we continually relax our assumptions. First, we assume a class oracle, i.e., the human annotator is provided with an equal number of vertices to label for each class. We denote this as â€œBalanced Samplingâ€™â€™. In the subsequent experiment, â€œUnbalanced Sampling,â€™â€™ we replace the class oracle with $k$-medoids clustering and draw vertices to label from the clusters. In the last experiment, the â€œUnknown Number of Classes,â€™â€™ we no longer assumed we knew the number and distribution of classes. Our results show that prototypical models outperform discriminative models in all experiments when fewer than $20$ samples per class are available. While dropping the assumption of the class oracle for the â€œUnbalanced Samplingâ€™â€™ experiment reduces the performance of the GCN by $9%$, the prototypical network loses only $1%$ on average. For the â€œUnknown Number of Classesâ€™â€™ experiment, the average performance for both models decreased further by $1%$.   Source code: <a target="_blank" rel="noopener" href="https://github.com/Ximsa/2023-felix-ma">https://github.com/Ximsa/2023-felix-ma</a> </p>
<blockquote>
<p>å°½ç®¡å­˜åœ¨å¤§é‡çš„å›¾å½¢æ•°æ®ï¼Œä½†è·å–é¡¶ç‚¹æ ‡ç­¾æ˜¯ä¸€é¡¹æ—¢ç¹çåˆæ˜‚è´µçš„ä»»åŠ¡ã€‚å› æ­¤ï¼Œåªéœ€ä»å°‘æ•°æ ‡è®°çš„é¡¶ç‚¹ä¸­å­¦ä¹ å³å¯ã€‚ç°æœ‰çš„å°æ ·å­¦ä¹ è€…å‡è®¾å­˜åœ¨ä¸€ä¸ªç±»oracleï¼ˆä¸ºæ‰€éœ€ç±»åˆ«æä¾›æ ‡è®°é¡¶ç‚¹çš„å·¥å…·ï¼‰ï¼Œä½†åœ¨ç°å®ä¸–ç•Œçš„åœºæ™¯ä¸­ï¼Œå½“ç»˜åˆ¶é¡¶ç‚¹è¿›è¡Œæ ‡è®°æ—¶ï¼Œå¹¶ä¸çŸ¥é“è¯¥é¡¶ç‚¹å±äºå“ªä¸ªç±»åˆ«ã€‚å°æ ·å­¦ä¹ è€…é€šå¸¸ä¸åŸå‹ç½‘ç»œç›¸ç»“åˆï¼Œè€Œç»å…¸çš„åŠç›‘ç£é¡¶ç‚¹åˆ†ç±»åˆ™ä½¿ç”¨åˆ¤åˆ«æ¨¡å‹ï¼Œä¾‹å¦‚å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸æ–­æç¤ºäººç±»æ³¨é‡Šè€…è¿›è¡Œé¡¶ç‚¹æ ‡æ³¨æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸‰é¡¹å®éªŒï¼Œä¸æ–­æ”¾å®½æˆ‘ä»¬çš„å‡è®¾ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å‡è®¾å­˜åœ¨ä¸€ä¸ªç±»oracleï¼Œå³äººç±»æ³¨é‡Šè€…è¢«æä¾›æ•°é‡ç›¸ç­‰çš„æ¯ä¸ªç±»åˆ«çš„é¡¶ç‚¹è¿›è¡Œæ ‡æ³¨ã€‚æˆ‘ä»¬å°†å…¶ç§°ä¸ºâ€œå¹³è¡¡é‡‡æ ·â€ã€‚åœ¨éšåçš„å®éªŒâ€œä¸å¹³è¡¡é‡‡æ ·â€ä¸­ï¼Œæˆ‘ä»¬ç”¨k-medoidsèšç±»æ›¿æ¢ç±»oracleï¼Œå¹¶ä»èšç±»ä¸­æŠ½å–é¡¶ç‚¹è¿›è¡Œæ ‡æ³¨ã€‚åœ¨æœ€åä¸€ä¸ªå®éªŒâ€œæœªçŸ¥ç±»åˆ«æ•°é‡â€ä¸­ï¼Œæˆ‘ä»¬ä¸å†å‡è®¾æˆ‘ä»¬çŸ¥é“ç±»åˆ«çš„æ•°é‡å’Œåˆ†å¸ƒã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨æ‰€æœ‰å®éªŒä¸­ï¼Œå½“æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬å°‘äº20ä¸ªæ—¶ï¼ŒåŸå‹æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä¼˜äºåˆ¤åˆ«æ¨¡å‹ã€‚åœ¨â€œä¸å¹³è¡¡é‡‡æ ·â€å®éªŒä¸­æ”¾å¼ƒç±»oracleçš„å‡è®¾ä½¿GCNçš„æ€§èƒ½é™ä½äº†9%ï¼Œè€ŒåŸå‹ç½‘ç»œçš„å¹³å‡æ€§èƒ½ä»…ä¸‹é™äº†1%ã€‚å¯¹äºâ€œæœªçŸ¥ç±»åˆ«æ•°é‡â€å®éªŒï¼Œä¸¤ä¸ªæ¨¡å‹çš„å¹³å‡æ€§èƒ½è¿›ä¸€æ­¥ä¸‹é™äº†1%ã€‚æºä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/Ximsa/2023-felix-ma">https://github.com/Ximsa/2023-felix-ma</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18696v1">PDF</a> Accepted at IJCNN 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä»å°‘é‡æ ‡è®°é¡¶ç‚¹å­¦ä¹ çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç±»oracleæ¥æä¾›æ ‡è®°é¡¶ç‚¹ï¼Œä½†åœ¨ç°å®ä¸–ç•Œä¸­è¿™ä¸€å‡è®¾ä¸æˆç«‹ã€‚æœ¬æ–‡é€šè¿‡è¿­ä»£æç¤ºäººç±»æ³¨é‡Šè€…è¿›è¡Œæ ‡æ³¨æ¥è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è¿›è¡Œäº†ä¸‰ä¸ªå®éªŒæ¥é€æ­¥æ”¾å®½å‡è®¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ ·æœ¬æ•°é‡è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼ŒåŸå‹æ¨¡å‹çš„è¡¨ç°ä¼˜äºåˆ¤åˆ«æ¨¡å‹ã€‚å½“ä¸å†å‡è®¾ç±»oracleæ—¶ï¼ŒGCNçš„æ€§èƒ½ä¸‹é™äº†9%ï¼Œè€ŒåŸå‹ç½‘ç»œçš„å¹³å‡æ€§èƒ½ä»…ä¸‹é™äº†1%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è·å–é¡¶ç‚¹æ ‡ç­¾æ˜¯ä¸€ä¸ªç¹çä¸”æ˜‚è´µçš„ä»»åŠ¡ï¼Œå› æ­¤ä»å°‘é‡æ ‡è®°é¡¶ç‚¹å­¦ä¹ æ˜¯ç†æƒ³çš„ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–äºç±»oracleæä¾›æ ‡è®°é¡¶ç‚¹ï¼Œè¿™åœ¨ç°å®ä¸–ç•Œä¸­ä¸å¯è¡Œã€‚</li>
<li>æœ¬æ–‡é€šè¿‡è¿­ä»£æç¤ºäººç±»æ³¨é‡Šè€…è¿›è¡Œæ ‡æ³¨æ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>è¿›è¡Œäº†ä¸‰ä¸ªå®éªŒæ¥é€æ­¥æ”¾å®½å‡è®¾ï¼ŒåŒ…æ‹¬å¹³è¡¡é‡‡æ ·ã€ä¸å¹³è¡¡é‡‡æ ·å’ŒæœªçŸ¥ç±»åˆ«æ•°é‡ã€‚</li>
<li>åŸå‹æ¨¡å‹åœ¨æ ·æœ¬æ•°é‡è¾ƒå°‘æ—¶è¡¨ç°è¾ƒå¥½ã€‚</li>
<li>å½“ä¸å†å‡è®¾ç±»oracleæ—¶ï¼ŒGCNçš„æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè€ŒåŸå‹ç½‘ç»œçš„æ€§èƒ½ç›¸å¯¹æ›´ç¨³å®šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18696">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-da995a7e6fc0f0fc1f4365de52f23c4c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a81c23e6f9200063307cfe5529b4caaf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68629da72c57f0f6036e4e1cc6636951.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bcea5eba7e5dbc39aec1ee9e5b02aa1f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-70554fb24e4b7315a81bad53ee75211a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SimLTD-Simple-Supervised-and-Semi-Supervised-Long-Tailed-Object-Detection"><a href="#SimLTD-Simple-Supervised-and-Semi-Supervised-Long-Tailed-Object-Detection" class="headerlink" title="SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object   Detection"></a>SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object   Detection</h2><p><strong>Authors:Phi Vu Tran</strong></p>
<p>While modern visual recognition systems have made significant advancements, many continue to struggle with the open problem of learning from few exemplars. This paper focuses on the task of object detection in the setting where object classes follow a natural long-tailed distribution. Existing methods for long-tailed detection resort to external ImageNet labels to augment the low-shot training instances. However, such dependency on a large labeled database has limited utility in practical scenarios. We propose a versatile and scalable approach to leverage optional unlabeled images, which are easy to collect without the burden of human annotations. Our SimLTD framework is straightforward and intuitive, and consists of three simple steps: (1) pre-training on abundant head classes; (2) transfer learning on scarce tail classes; and (3) fine-tuning on a sampled set of both head and tail classes. Our approach can be viewed as an improved head-to-tail model transfer paradigm without the added complexities of meta-learning or knowledge distillation, as was required in past research. By harnessing supplementary unlabeled images, without extra image labels, SimLTD establishes new record results on the challenging LVIS v1 benchmark across both supervised and semi-supervised settings. </p>
<blockquote>
<p>è™½ç„¶ç°ä»£è§†è§‰è¯†åˆ«ç³»ç»Ÿå·²ç»å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†è®¸å¤šç³»ç»Ÿä»ç„¶é¢ä¸´ç€ä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ çš„å¼€æ”¾æ€§é—®é¢˜ã€‚æœ¬æ–‡å…³æ³¨çš„å¯¹è±¡æ£€æµ‹ä»»åŠ¡æ˜¯å¯¹è±¡ç±»åˆ«éµå¾ªè‡ªç„¶çš„é•¿å°¾åˆ†å¸ƒçš„è®¾ç½®ã€‚ç°æœ‰çš„é•¿å°¾æ£€æµ‹æ–¹æ³•ä¾èµ–äºå¤–éƒ¨ImageNetæ ‡ç­¾æ¥å¢åŠ ä½å°„å‡»è®­ç»ƒå®ä¾‹ã€‚ç„¶è€Œï¼Œå¯¹å¤§é‡æœ‰æ ‡ç­¾æ•°æ®åº“çš„ä¾èµ–åœ¨å®é™…åœºæ™¯ä¸­å®ç”¨æ€§æœ‰é™ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨ä¸”å¯æ‰©å±•çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¯é€‰çš„æ— æ ‡ç­¾å›¾åƒï¼Œè¿™äº›å›¾åƒæ— éœ€äººå·¥æ³¨é‡Šå³å¯è½»æ¾æ”¶é›†ã€‚æˆ‘ä»¬çš„SimLTDæ¡†æ¶ç®€å•ç›´è§‚ï¼Œåˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼šï¼ˆ1ï¼‰åœ¨ä¸°å¯Œçš„å¤´éƒ¨ç±»åˆ«ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼›ï¼ˆ2ï¼‰åœ¨ç¨€ç¼ºçš„å°¾éƒ¨ç±»åˆ«ä¸Šè¿›è¡Œè¿ç§»å­¦ä¹ ï¼›ï¼ˆ3ï¼‰åœ¨å¤´éƒ¨å’Œå°¾éƒ¨ç±»åˆ«çš„é‡‡æ ·é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è¢«è§†ä¸ºä¸€ç§æ”¹è¿›çš„å¤´åˆ°å°¾æ¨¡å‹è½¬ç§»èŒƒå¼ï¼Œæ— éœ€å¼•å…¥å…ƒå­¦ä¹ æˆ–çŸ¥è¯†è’¸é¦ç­‰é¢å¤–å¤æ‚æ€§ï¼Œè¿™æ˜¯è¿‡å»ç ”ç©¶çš„è¦æ±‚ã€‚é€šè¿‡åˆ©ç”¨é¢å¤–çš„æ— æ ‡ç­¾å›¾åƒï¼Œæ— éœ€é¢å¤–çš„å›¾åƒæ ‡ç­¾ï¼ŒSimLTDåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVIS v1åŸºå‡†æµ‹è¯•ä¸­å»ºç«‹äº†æ–°çš„è®°å½•ç»“æœï¼Œæ¶µç›–äº†æœ‰ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20047v2">PDF</a> CVPR 2025. The reference code is available at   <a target="_blank" rel="noopener" href="https://github.com/lexisnexis-risk-open-source/simltd">https://github.com/lexisnexis-risk-open-source/simltd</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³ç°ä»£è§†è§‰è¯†åˆ«ç³»ç»Ÿåœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸Šçš„éš¾é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­é¢å¯¹é•¿å°¾åˆ†å¸ƒæ•°æ®çš„é—®é¢˜ã€‚ä¸åŒäºä¾èµ–ImageNetæ ‡ç­¾æ‰©å……ä½æ ·æœ¬è®­ç»ƒå®ä¾‹çš„æ–¹æ³•ï¼Œæœ¬æ–‡æå‡ºåˆ©ç”¨æ˜“æ”¶é›†çš„æ— æ ‡ç­¾å›¾åƒï¼Œé€šè¿‡é¢„è®­ç»ƒã€è¿ç§»å­¦ä¹ å’Œå¾®è°ƒä¸‰ä¸ªæ­¥éª¤ï¼Œå®ç°æ”¹è¿›çš„å¤´åˆ°å°¾æ¨¡å‹è½¬ç§»èŒƒå¼ï¼Œæ— éœ€å¤æ‚çš„å…ƒå­¦ä¹ æˆ–çŸ¥è¯†è’¸é¦ï¼Œæé«˜äº†åœ¨é•¿å°¾åˆ†å¸ƒæ•°æ®ä¸Šçš„ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°ä»£è§†è§‰è¯†åˆ«ç³»ç»Ÿåœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸Šä»é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–ImageNetæ ‡ç­¾æ‰©å……ä½æ ·æœ¬è®­ç»ƒå®ä¾‹ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­æ•ˆç”¨æœ‰é™ã€‚</li>
<li>æœ¬æ–‡æå‡ºåˆ©ç”¨æ— æ ‡ç­¾å›¾åƒï¼Œé€šè¿‡é¢„è®­ç»ƒã€è¿ç§»å­¦ä¹ å’Œå¾®è°ƒä¸‰ä¸ªæ­¥éª¤è§£å†³è¯¥é—®é¢˜ã€‚</li>
<li>æå‡ºçš„SimLTDæ¡†æ¶æ”¹è¿›äº†å¤´åˆ°å°¾æ¨¡å‹è½¬ç§»èŒƒå¼ï¼Œæ— éœ€å¤æ‚çš„å…ƒå­¦ä¹ æˆ–çŸ¥è¯†è’¸é¦ã€‚</li>
<li>SimLTDæ¡†æ¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVIS v1åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ–°çš„è®°å½•ç»“æœã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨é™„åŠ çš„æ— æ ‡ç­¾å›¾åƒï¼Œæ— éœ€é¢å¤–å›¾åƒæ ‡ç­¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20047">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1cef7802542d3544c01e6db362edb9d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-30282318a0024c9a2e68d27f452fafd0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-be1b39ed7183885c06cd4eaff445356e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2ee2def362661f2d40f25ed20094a294.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54084b596b3e89b7cb4305cb600d8257.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ad83366254906d9b43c1394a63217cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b1583c5eda999ca9cb733662cb9f152.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Benchmarking-large-language-models-for-biomedical-natural-language-processing-applications-and-recommendations"><a href="#Benchmarking-large-language-models-for-biomedical-natural-language-processing-applications-and-recommendations" class="headerlink" title="Benchmarking large language models for biomedical natural language   processing applications and recommendations"></a>Benchmarking large language models for biomedical natural language   processing applications and recommendations</h2><p><strong>Authors:Qingyu Chen, Yan Hu, Xueqing Peng, Qianqian Xie, Qiao Jin, Aidan Gilson, Maxwell B. Singer, Xuguang Ai, Po-Ting Lai, Zhizheng Wang, Vipina Kuttichi Keloth, Kalpana Raja, Jiming Huang, Huan He, Fongci Lin, Jingcheng Du, Rui Zhang, W. Jim Zheng, Ron A. Adelman, Zhiyong Lu, Hua Xu</strong></p>
<p>The rapid growth of biomedical literature poses challenges for manual knowledge curation and synthesis. Biomedical Natural Language Processing (BioNLP) automates the process. While Large Language Models (LLMs) have shown promise in general domains, their effectiveness in BioNLP tasks remains unclear due to limited benchmarks and practical guidelines.   We perform a systematic evaluation of four LLMs, GPT and LLaMA representatives on 12 BioNLP benchmarks across six applications. We compare their zero-shot, few-shot, and fine-tuning performance with traditional fine-tuning of BERT or BART models. We examine inconsistencies, missing information, hallucinations, and perform cost analysis. Here we show that traditional fine-tuning outperforms zero or few shot LLMs in most tasks. However, closed-source LLMs like GPT-4 excel in reasoning-related tasks such as medical question answering. Open source LLMs still require fine-tuning to close performance gaps. We find issues like missing information and hallucinations in LLM outputs. These results offer practical insights for applying LLMs in BioNLP. </p>
<blockquote>
<p>ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®çš„å¿«é€Ÿå¢é•¿ä¸ºæ‰‹åŠ¨çŸ¥è¯†æ•´åˆå’Œç»¼è¿°å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ç”Ÿç‰©åŒ»å­¦è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆBioNLPï¼‰ä½¿è¿™äº›è¿‡ç¨‹è‡ªåŠ¨åŒ–ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸€èˆ¬é¢†åŸŸæ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç”±äºç¼ºä¹åŸºå‡†æµ‹è¯•å’Œå®ç”¨æŒ‡å—ï¼Œå®ƒä»¬åœ¨BioNLPä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ä»ç„¶ä¸æ˜ç¡®ã€‚æˆ‘ä»¬å¯¹å››ç§LLMï¼ˆGPTå’ŒLLaMAçš„ä»£è¡¨ï¼‰è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œæ¶‰åŠå…­ä¸ªåº”ç”¨çš„12ä¸ªBioNLPåŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†å®ƒä»¬åœ¨é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæƒ…å†µä¸‹çš„æ€§èƒ½ï¼Œä»¥åŠä¸BERTæˆ–BARTæ¨¡å‹çš„ä¼ ç»Ÿå¾®è°ƒæ€§èƒ½ã€‚æˆ‘ä»¬æ£€æŸ¥äº†ä¸ä¸€è‡´æ€§ã€ç¼ºå¤±ä¿¡æ¯ã€å¹»è§‰å¹¶è¿›è¡Œäº†æˆæœ¬åˆ†æã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¡¨æ˜ä¼ ç»Ÿå¾®è°ƒåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­ä¼˜äºé›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬LLMã€‚ç„¶è€Œï¼ŒåƒGPT-4è¿™æ ·çš„é—­æºLLMåœ¨æ¨ç†ç›¸å…³ä»»åŠ¡ï¼ˆå¦‚åŒ»å­¦é—®ç­”ï¼‰ä¸­è¡¨ç°å‡ºè‰²ã€‚å¼€æºLLMä»ç„¶éœ€è¦å¾®è°ƒæ¥ç¼©å°æ€§èƒ½å·®è·ã€‚æˆ‘ä»¬å‘ç°LLMè¾“å‡ºä¸­å­˜åœ¨ç¼ºå¤±ä¿¡æ¯å’Œå¹»è§‰ç­‰é—®é¢˜ã€‚è¿™äº›ç»“æœæä¾›äº†å°†LLMåº”ç”¨äºBioNLPçš„å®é™…è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2305.16326v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®çš„å¿«é€Ÿå¢é•¿ç»™æ‰‹åŠ¨çŸ¥è¯†æ•´åˆä¸ç»¼åˆå¸¦æ¥äº†æŒ‘æˆ˜ï¼Œç”Ÿç‰©åŒ»å­¦è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆBioNLPï¼‰è‡ªåŠ¨åŒ–äº†è¿™ä¸€æµç¨‹ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸€èˆ¬é¢†åŸŸè¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†åœ¨BioNLPä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å°šä¸æ¸…æ¥šï¼Œå—é™äºåŸºå‡†æµ‹è¯•å’Œå®ç”¨æŒ‡å—ã€‚æœ¬æ–‡å¯¹å››ç§LLMsï¼ˆGPTå’ŒLLaMAçš„ä»£è¡¨ï¼‰è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œæ¶‰åŠå…­ä¸ªåº”ç”¨çš„12é¡¹BioNLPåŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†å®ƒä»¬åœ¨é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæ¨¡å¼ä¸‹çš„æ€§èƒ½ä¸ä¼ ç»Ÿçš„BERTæˆ–BARTæ¨¡å‹çš„å¾®è°ƒæ€§èƒ½ã€‚æˆ‘ä»¬ç ”ç©¶äº†è¾“å‡ºä¸­çš„ä¸ä¸€è‡´æ€§ã€ç¼ºå¤±ä¿¡æ¯ã€å¹»è§‰ï¼Œå¹¶è¿›è¡Œäº†æˆæœ¬åˆ†æã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿå¾®è°ƒåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­ä¼˜äºé›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬LLMsã€‚ä½†å¦‚GPT-4è¿™æ ·çš„å°é—­æºLLMsåœ¨æ¨ç†ç›¸å…³ä»»åŠ¡å¦‚åŒ»ç–—é—®ç­”ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚å¼€æºLLMsä»éœ€è¦å¾®è°ƒä»¥ç¼©å°æ€§èƒ½å·®è·ã€‚æˆ‘ä»¬å‘ç°LLMè¾“å‡ºä¸­å­˜åœ¨ç¼ºå¤±ä¿¡æ¯å’Œå¹»è§‰ç­‰é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®çš„å¿«é€Ÿå¢é•¿ç»™æ‰‹åŠ¨çŸ¥è¯†ç®¡ç†å¸¦æ¥æŒ‘æˆ˜ï¼ŒBioNLPè‡ªåŠ¨åŒ–æœ‰åŠ©äºè§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨BioNLPä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å°šä¸æ¸…æ¥šã€‚</li>
<li>ç³»ç»Ÿè¯„ä¼°äº†å››ç§LLMsåœ¨å¤šä¸ªBioNLPåŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ã€‚</li>
<li>ä¼ ç»Ÿå¾®è°ƒåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºé›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬LLMsã€‚</li>
<li>å°é—­æºLLMså¦‚GPT-4åœ¨æ¨ç†ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ã€‚</li>
<li>å¼€æºLLMsä»éœ€è¦å¾®è°ƒä»¥æé«˜æ€§èƒ½ã€‚</li>
<li>LLMè¾“å‡ºä¸­å­˜åœ¨ç¼ºå¤±ä¿¡æ¯å’Œå¹»è§‰ç­‰é—®é¢˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2305.16326">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ec704415099250c9a6794c52cc4d4b78.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-104b102456f8c3c59d56519d6c5def1e.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  ClearVision Leveraging CycleGAN and SigLIP-2 for Robust All-Weather   Classification in Traffic Camera Imagery
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-be7808b803999dffd75289428e3935d1.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  Can AI Agents Design and Implement Drug Discovery Pipelines?
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27348.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
