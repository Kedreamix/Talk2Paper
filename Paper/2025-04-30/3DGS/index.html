<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  Mesh-Learner Texturing Mesh with Spherical Harmonics">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-c3cff7ca5b878ce125255dbb6e2ea578.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-01
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    37 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-30-æ›´æ–°"><a href="#2025-04-30-æ›´æ–°" class="headerlink" title="2025-04-30 æ›´æ–°"></a>2025-04-30 æ›´æ–°</h1><h2 id="Mesh-Learner-Texturing-Mesh-with-Spherical-Harmonics"><a href="#Mesh-Learner-Texturing-Mesh-with-Spherical-Harmonics" class="headerlink" title="Mesh-Learner: Texturing Mesh with Spherical Harmonics"></a>Mesh-Learner: Texturing Mesh with Spherical Harmonics</h2><p><strong>Authors:Yunfei Wan, Jianheng Liu, Jiarong Lin, Fu Zhang</strong></p>
<p>In this paper, we present a 3D reconstruction and rendering framework termed Mesh-Learner that is natively compatible with traditional rasterization pipelines. It integrates mesh and spherical harmonic (SH) texture (i.e., texture filled with SH coefficients) into the learning process to learn each mesh s view-dependent radiance end-to-end. Images are rendered by interpolating surrounding SH Texels at each pixel s sampling point using a novel interpolation method. Conversely, gradients from each pixel are back-propagated to the related SH Texels in SH textures. Mesh-Learner exploits graphic features of rasterization pipeline (texture sampling, deferred rendering) to render, which makes Mesh-Learner naturally compatible with tools (e.g., Blender) and tasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for robotics) that are based on rasterization pipelines. Our system can train vast, unlimited scenes because we transfer only the SH textures within the frustum to the GPU for training. At other times, the SH textures are stored in CPU RAM, which results in moderate GPU memory usage. The rendering results on interpolation and extrapolation sequences in the Replica and FAST-LIVO2 datasets achieve state-of-the-art performance compared to existing state-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To benefit the society, the code will be available at <a target="_blank" rel="noopener" href="https://github.com/hku-mars/Mesh-Learner">https://github.com/hku-mars/Mesh-Learner</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåä¸ºMesh-Learnerçš„3Dé‡å»ºå’Œæ¸²æŸ“æ¡†æ¶ï¼Œå®ƒä¸ä¼ ç»Ÿå…‰æ …åŒ–ç®¡é“åŸç”Ÿå…¼å®¹ã€‚å®ƒé€šè¿‡æ•´åˆç½‘æ ¼å’Œçƒé¢è°æ³¢ï¼ˆSHï¼‰çº¹ç†ï¼ˆå³å¡«å……æœ‰SHç³»æ•°çš„çº¹ç†ï¼‰åˆ°å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼å­¦ä¹ æ¯ä¸ªç½‘æ ¼çš„è§†è§’ç›¸å…³è¾å°„ç‡ã€‚å›¾åƒæ˜¯é€šè¿‡ä¸€ç§æ–°å‹æ’å€¼æ–¹æ³•ï¼Œåœ¨æ¯ä¸ªåƒç´ çš„é‡‡æ ·ç‚¹æ’å€¼å‘¨å›´çš„SHçº¹ç†å…ƒç´ æ¥å‘ˆç°çš„ã€‚ç›¸åï¼Œæ¯ä¸ªåƒç´ çš„æ¢¯åº¦ä¼šåå‘ä¼ æ’­åˆ°ç›¸å…³çš„SHçº¹ç†ä¸­çš„SHçº¹ç†å…ƒç´ ã€‚Mesh-Learneråˆ©ç”¨äº†å…‰æ …åŒ–ç®¡é“ï¼ˆçº¹ç†é‡‡æ ·ã€å»¶è¿Ÿæ¸²æŸ“ï¼‰çš„å›¾å½¢ç‰¹å¾æ¥è¿›è¡Œæ¸²æŸ“ï¼Œè¿™ä½¿å¾—Mesh-Learnerè‡ªç„¶åœ°ä¸åŸºäºå…‰æ …åŒ–ç®¡é“çš„å·¥å…·ï¼ˆä¾‹å¦‚Blenderï¼‰å’Œä»»åŠ¡ï¼ˆä¾‹å¦‚3Dé‡å»ºã€åœºæ™¯æ¸²æŸ“ã€æœºå™¨äººå¼ºåŒ–å­¦ä¹ ï¼‰å…¼å®¹ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå¯ä»¥è®­ç»ƒå¤§é‡æ— é™çš„åœºæ™¯ï¼Œå› ä¸ºæˆ‘ä»¬å°†ä»…å°†è§†é”¥å†…çš„SHçº¹ç†ä¼ è¾“åˆ°GPUè¿›è¡Œè®­ç»ƒã€‚å…¶ä»–æ—¶å€™ï¼ŒSHçº¹ç†å­˜å‚¨åœ¨CPU RAMä¸­ï¼Œè¿™å¯¼è‡´GPUå†…å­˜ä½¿ç”¨é€‚ä¸­ã€‚åœ¨Replicaå’ŒFAST-LIVO2æ•°æ®é›†ä¸Šçš„æ’å€¼å’Œå¤–æ¨åºåˆ—çš„æ¸²æŸ“ç»“æœè¾¾åˆ°äº†ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ˆä¾‹å¦‚3Dé«˜æ–¯æº…å°„å’ŒM2-Mappingï¼‰ç›¸æ¯”çš„æœ€ä½³æ€§èƒ½ã€‚ä¸ºäº†é€ ç¦ç¤¾ä¼šï¼Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/hku-mars/Mesh-Learner%E4%B8%8A%E6%8F%9B%E4%BA%8C%E3%80%82">https://github.com/hku-mars/Mesh-Learnerä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19938v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºMesh-Learnerçš„3Dé‡å»ºå’Œæ¸²æŸ“æ¡†æ¶ï¼Œå®ƒä¸ä¼ ç»Ÿå…‰æ …åŒ–ç®¡é“å…¼å®¹ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç½‘æ ¼å’Œçƒé¢è°æ³¢çº¹ç†ï¼Œé€šè¿‡ä¸€ç§æ–°å‹æ’å€¼æ–¹æ³•å¯¹å‘¨å›´SH Texelsè¿›è¡Œæ’å€¼æ¸²æŸ“å›¾åƒï¼ŒåŒæ—¶åå‘ä¼ æ’­åƒç´ çš„æ¢¯åº¦è‡³ç›¸å…³çš„SH Texelsã€‚Mesh-Learneråˆ©ç”¨å…‰æ …åŒ–ç®¡é“ï¼ˆçº¹ç†é‡‡æ ·ã€å»¶è¿Ÿæ¸²æŸ“ï¼‰çš„å›¾å½¢ç‰¹æ€§è¿›è¡Œæ¸²æŸ“ï¼Œä½¿å…¶è‡ªç„¶åœ°å…¼å®¹åŸºäºå…‰æ …åŒ–ç®¡é“çš„å·¥å…·å’Œä»»åŠ¡ã€‚è¯¥ç³»ç»Ÿçš„GPUå†…å­˜ä½¿ç”¨é€‚ä¸­ï¼Œå› ä¸ºä»…åœ¨è§†é”¥å†…ä¼ è¾“SHçº¹ç†ä»¥è¿›è¡Œè®­ç»ƒï¼Œå¯è®­ç»ƒå¤§è§„æ¨¡ã€æ— é™çš„åœºæ™¯ã€‚åœ¨Replicaå’ŒFAST-LIVO2æ•°æ®é›†ä¸Šçš„æ’å€¼å’Œå¤–æ¨åºåˆ—çš„æ¸²æŸ“ç»“æœè¾¾åˆ°äº†ä¸ç°æœ‰å…ˆè¿›æ–¹æ³•ç›¸æ¯”çš„æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Mesh-Learneræ¡†æ¶ç»“åˆäº†ç½‘æ ¼å’Œçƒé¢è°æ³¢ï¼ˆSHï¼‰çº¹ç†ï¼Œæ”¯æŒä¸ä¼ ç»Ÿå…‰æ …åŒ–ç®¡é“é›†æˆã€‚</li>
<li>é€šè¿‡æ–°å‹æ’å€¼æ–¹æ³•æ¸²æŸ“å›¾åƒï¼Œæ’å€¼å‘¨å›´SH Texelsã€‚</li>
<li>åå‘ä¼ æ’­åƒç´ çš„æ¢¯åº¦è‡³SHçº¹ç†ä¸­çš„ç›¸å…³Texelsã€‚</li>
<li>åˆ©ç”¨å…‰æ …åŒ–ç®¡é“çš„å›¾å½¢ç‰¹æ€§è¿›è¡Œæ¸²æŸ“ï¼Œä¸åŸºäºè¯¥ç®¡é“çš„å·¥å…·å’Œä»»åŠ¡è‡ªç„¶å…¼å®¹ã€‚</li>
<li>GPUå†…å­˜ä½¿ç”¨é€‚ä¸­ï¼Œå¯è®­ç»ƒå¤§è§„æ¨¡ã€æ— é™çš„åœºæ™¯ã€‚</li>
<li>åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šçš„æ¸²æŸ“ç»“æœè¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19938">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-20c7de97f2a77fa99bc88a5af1b3a67f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-337bc6d2fd66e3505eccbe6f39b24c64.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b2ab021890874788265b584a3fa44d4f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1c6c7ff641e2e607d996db2ab0a9b6f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6d1021eae5c93406c4df34991ace5da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03b50012df314884f14ce933b07fb8e9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34b46b6850ffe46f3c9db3b96a63ce56.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CE-NPBG-Connectivity-Enhanced-Neural-Point-Based-Graphics-for-Novel-View-Synthesis-in-Autonomous-Driving-Scenes"><a href="#CE-NPBG-Connectivity-Enhanced-Neural-Point-Based-Graphics-for-Novel-View-Synthesis-in-Autonomous-Driving-Scenes" class="headerlink" title="CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel   View Synthesis in Autonomous Driving Scenes"></a>CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel   View Synthesis in Autonomous Driving Scenes</h2><p><strong>Authors:Mohammad Altillawi, Fengyi Shen, Liudi Yang, Sai Manoj Prakhya, Ziyuan Liu</strong></p>
<p>Current point-based approaches encounter limitations in scalability and rendering quality when using large 3D point cloud maps because using them directly for novel view synthesis (NVS) leads to degraded visualizations. We identify the primary issue behind these low-quality renderings as a visibility mismatch between geometry and appearance, stemming from using these two modalities together. To address this problem, we present CE-NPBG, a new approach for novel view synthesis (NVS) in large-scale autonomous driving scenes. Our method is a neural point-based technique that leverages two modalities: posed images (cameras) and synchronized raw 3D point clouds (LiDAR). We first employ a connectivity relationship graph between appearance and geometry, which retrieves points from a large 3D point cloud map observed from the current camera perspective and uses them for rendering. By leveraging this connectivity, our method significantly improves rendering quality and enhances run-time and scalability by using only a small subset of points from the large 3D point cloud map. Our approach associates neural descriptors with the points and uses them to synthesize views. To enhance the encoding of these descriptors and elevate rendering quality, we propose a joint adversarial and point rasterization training. During training, we pair an image-synthesizer network with a multi-resolution discriminator. At inference, we decouple them and use the image-synthesizer to generate novel views. We also integrate our proposal into the recent 3D Gaussian Splatting work to highlight its benefits for improved rendering and scalability. </p>
<blockquote>
<p>å½“å‰åŸºäºç‚¹çš„æ–¹æ³•åœ¨åˆ©ç”¨å¤§è§„æ¨¡3Dç‚¹äº‘åœ°å›¾è¿›è¡Œæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰æ—¶ï¼Œä¼šé‡åˆ°å¯æ‰©å±•æ€§å’Œæ¸²æŸ“è´¨é‡æ–¹é¢çš„å±€é™ï¼Œç›´æ¥ä½¿ç”¨å®ƒä»¬ä¼šå¯¼è‡´å¯è§†åŒ–æ•ˆæœä¸‹é™ã€‚æˆ‘ä»¬ç¡®å®šäº†è¿™äº›ä½è´¨é‡æ¸²æŸ“èƒŒåçš„ä¸»è¦é—®é¢˜ï¼Œå³å‡ ä½•å’Œå¤–è§‚ä¹‹é—´çš„å¯è§åº¦ä¸åŒ¹é…ï¼Œæºäºè¿™ä¸¤ç§æ¨¡å¼çš„ç»„åˆä½¿ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†CE-NPBGï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¤§è§„æ¨¡è‡ªåŠ¨é©¾é©¶åœºæ™¯çš„æ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¯ä¸€ç§åŸºäºç¥ç»ç‚¹çš„æŠ€æœ¯ï¼Œåˆ©ç”¨ä¸¤ç§æ¨¡å¼ï¼šå§¿æ€å›¾åƒï¼ˆç›¸æœºï¼‰å’ŒåŒæ­¥åŸå§‹3Dç‚¹äº‘ï¼ˆæ¿€å…‰é›·è¾¾ï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆé‡‡ç”¨å¤–è§‚å’Œå‡ ä½•ä¹‹é—´çš„å…³è”å…³ç³»å›¾ï¼Œä»å½“å‰ç›¸æœºè§†è§’è§‚å¯Ÿçš„å¤§è§„æ¨¡3Dç‚¹äº‘åœ°å›¾ä¸­æ£€ç´¢ç‚¹ï¼Œå¹¶å°†å…¶ç”¨äºæ¸²æŸ“ã€‚é€šè¿‡åˆ©ç”¨è¿™ç§å…³è”æ€§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨å¤§è§„æ¨¡3Dç‚¹äº‘åœ°å›¾ä¸­çš„ä¸€å°éƒ¨åˆ†ç‚¹ï¼Œå°±èƒ½æ˜¾è‘—æé«˜æ¸²æŸ“è´¨é‡ï¼Œå¹¶å¢å¼ºè¿è¡Œæ—¶é—´å’Œå¯æ‰©å±•æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ç¥ç»æè¿°ç¬¦ä¸ç‚¹ç›¸å…³è”ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥åˆæˆè§†å›¾ã€‚ä¸ºäº†æé«˜è¿™äº›æè¿°ç¬¦çš„ç¼–ç å’Œæå‡æ¸²æŸ“è´¨é‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è”åˆå¯¹æŠ—æ€§å’Œç‚¹æ …æ ¼åŒ–è®­ç»ƒã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å›¾åƒåˆæˆå™¨ç½‘ç»œä¸å¤šåˆ†è¾¨ç‡é‰´åˆ«å™¨é…å¯¹ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å®ƒä»¬è§£è€¦ï¼Œå¹¶ä½¿ç”¨å›¾åƒåˆæˆå™¨ç”Ÿæˆæ–°å‹è§†å›¾ã€‚æˆ‘ä»¬è¿˜å°†æˆ‘ä»¬çš„ææ¡ˆæ•´åˆåˆ°æœ€è¿‘çš„3Dé«˜æ–¯æ‹¼è´´å·¥ä½œä¸­ï¼Œä»¥çªå‡ºå…¶åœ¨æ”¹è¿›æ¸²æŸ“å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19557v1">PDF</a> Accepted in 2025 IEEE&#x2F;CVF Conference on Computer Vision and Pattern   Recognition Workshops (CVPRW)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºCE-NPBGçš„æ–°æ–¹æ³•ï¼Œç”¨äºè§£å†³å¤§è§„æ¨¡è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­åŸºäºç‚¹çš„æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰çš„æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡é—®é¢˜ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å›¾åƒï¼ˆç›¸æœºï¼‰å’ŒåŒæ­¥åŸå§‹ä¸‰ç»´ç‚¹äº‘ï¼ˆæ¿€å…‰é›·è¾¾ï¼‰ä¸¤ç§æ¨¡å¼ï¼Œé€šè¿‡å»ºç«‹å‡ ä½•ä¸å¤–è§‚ä¹‹é—´çš„è¿æ¥å…³ç³»å›¾ï¼Œä»å¤§è§„æ¨¡ä¸‰ç»´ç‚¹äº‘åœ°å›¾ä¸­æ£€ç´¢å½“å‰ç›¸æœºè§†è§’çš„ç‚¹è¿›è¡Œæ¸²æŸ“ã€‚é€šè¿‡åˆ©ç”¨è¿™ç§è¿æ¥å…³ç³»ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å¤§è§„æ¨¡ä¸‰ç»´ç‚¹äº‘åœ°å›¾çš„å°éƒ¨åˆ†ç‚¹ï¼Œæ˜¾è‘—æé«˜äº†æ¸²æŸ“è´¨é‡å’Œè¿è¡Œæ•ˆç‡ã€‚è¯¥ç ”ç©¶è¿˜å¼•å…¥äº†ç¥ç»æè¿°ç¬¦ä¸ç‚¹çš„å…³è”ï¼Œç”¨äºåˆæˆè§†å›¾ï¼Œå¹¶æå‡ºè”åˆå¯¹æŠ—å’Œç‚¹æ …æ ¼åŒ–è®­ç»ƒï¼Œä»¥æé«˜æè¿°ç¬¦çš„ç¼–ç å’Œæ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰ç‚¹åŸºæ–¹æ³•åœ¨å¤§è§„æ¨¡ä¸‰ç»´ç‚¹äº‘åœ°å›¾çš„ç›´æ¥åº”ç”¨ä¸­å­˜åœ¨æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡çš„é—®é¢˜ã€‚</li>
<li>é—®é¢˜æ ¸å¿ƒåœ¨äºå‡ ä½•å’Œå¤–è§‚ä¹‹é—´çš„å¯è§æ€§ä¸åŒ¹é…ã€‚</li>
<li>CE-NPBGæ˜¯ä¸€ç§æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰æ–¹æ³•ï¼Œç»“åˆäº†å›¾åƒï¼ˆç›¸æœºï¼‰å’ŒåŒæ­¥åŸå§‹ä¸‰ç»´ç‚¹äº‘ï¼ˆæ¿€å…‰é›·è¾¾ï¼‰ä¸¤ç§æ¨¡å¼ã€‚</li>
<li>é€šè¿‡å»ºç«‹è¿æ¥å…³ç³»å›¾ï¼Œä»å¤§è§„æ¨¡ä¸‰ç»´ç‚¹äº‘åœ°å›¾ä¸­æ£€ç´¢å½“å‰ç›¸æœºè§†è§’çš„ç‚¹è¿›è¡Œæ¸²æŸ“ï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†ç¥ç»æè¿°ç¬¦ä¸ç‚¹çš„å…³è”ï¼Œç”¨äºåˆæˆè§†å›¾ã€‚</li>
<li>ç ”ç©¶å¼•å…¥äº†è”åˆå¯¹æŠ—å’Œç‚¹æ …æ ¼åŒ–è®­ç»ƒï¼Œä»¥æé«˜æè¿°ç¬¦çš„ç¼–ç å’Œæ¸²æŸ“è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19557">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c6f439d4ca5bcc5b658fdca6a914a234.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39e852456f825c942db9f6ddbf34c1aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-971a53ec35c2d22b042547e75dec62be.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b62e24101e8e525e3824674a27a3118f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d40bc642b3394d2c496043b5f59ddb30.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ca3cfd45d0d6fb4aae1f2f2aa93bc198.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GSFF-SLAM-3D-Semantic-Gaussian-Splatting-SLAM-via-Feature-Field"><a href="#GSFF-SLAM-3D-Semantic-Gaussian-Splatting-SLAM-via-Feature-Field" class="headerlink" title="GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field"></a>GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field</h2><p><strong>Authors:Zuxing Lu, Xin Yuan, Shaowen Yang, Jingyu Liu, Jiawei Wang, Changyin Sun</strong></p>
<p>Semantic-aware 3D scene reconstruction is essential for autonomous robots to perform complex interactions. Semantic SLAM, an online approach, integrates pose tracking, geometric reconstruction, and semantic mapping into a unified framework, shows significant potential. However, existing systems, which rely on 2D ground truth priors for supervision, are often limited by the sparsity and noise of these signals in real-world environments. To address this challenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D Gaussian Splatting that leverages feature fields to achieve joint rendering of appearance, geometry, and N-dimensional semantic features. By independently optimizing feature gradients, our method supports semantic reconstruction using various forms of 2D priors, particularly sparse and noisy signals. Experimental results demonstrate that our approach outperforms previous methods in both tracking accuracy and photorealistic rendering quality. When utilizing 2D ground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation performance with 95.03% mIoU, while achieving up to 2.9$\times$ speedup with only marginal performance degradation. </p>
<blockquote>
<p>è¯­ä¹‰æ„ŸçŸ¥çš„3Dåœºæ™¯é‡å»ºå¯¹äºè‡ªä¸»æœºå™¨äººæ‰§è¡Œå¤æ‚äº¤äº’è‡³å…³é‡è¦ã€‚è¯­ä¹‰SLAMä½œä¸ºä¸€ç§åœ¨çº¿æ–¹æ³•ï¼Œå°†å§¿æ€è·Ÿè¸ªã€å‡ ä½•é‡å»ºå’Œè¯­ä¹‰æ˜ å°„æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­ï¼Œæ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰ç³»ç»Ÿé€šå¸¸ä¾èµ–äº2DçœŸå®å…ˆéªŒè¿›è¡Œç›‘ç£ï¼Œè¿™åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å—åˆ°è¿™äº›ä¿¡å·ç¨€ç–æ€§å’Œå™ªå£°çš„é™åˆ¶ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†GSFF-SLAMï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„åŸºäº3Dé«˜æ–¯å¡«å……æŠ€æœ¯çš„å¯†é›†è¯­ä¹‰SLAMç³»ç»Ÿã€‚å®ƒåˆ©ç”¨ç‰¹å¾åœºå®ç°å¤–è§‚ã€å‡ ä½•å’ŒNç»´è¯­ä¹‰ç‰¹å¾çš„è”åˆæ¸²æŸ“ã€‚é€šè¿‡ç‹¬ç«‹ä¼˜åŒ–ç‰¹å¾æ¢¯åº¦ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒä½¿ç”¨å„ç§å½¢å¼çš„2Då…ˆéªŒè¿›è¡Œè¯­ä¹‰é‡å»ºï¼Œå°¤å…¶æ˜¯ç¨€ç–å’Œå™ªå£°ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è·Ÿè¸ªç²¾åº¦å’Œç…§ç‰‡çº§æ¸²æŸ“è´¨é‡æ–¹é¢éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚å½“åˆ©ç”¨2DçœŸå®å…ˆéªŒæ—¶ï¼ŒGSFF-SLAMè¾¾åˆ°äº†æœ€å…ˆè¿›çš„è¯­ä¹‰åˆ†å‰²æ€§èƒ½ï¼ŒmIoUä¸º95.03%ï¼ŒåŒæ—¶å®ç°äº†é«˜è¾¾2.9å€çš„åŠ é€Ÿï¼Œæ€§èƒ½ä»…ç•¥æœ‰ä¸‹é™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19409v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è‡ªä¸»æœºå™¨äººåœ¨è¿›è¡Œå¤æ‚äº¤äº’æ—¶ï¼Œè¯­ä¹‰æ„ŸçŸ¥çš„3Dåœºæ™¯é‡å»ºçš„é‡è¦æ€§ã€‚æå‡ºäº†ä¸€ç§æ–°å‹çš„å¯†é›†è¯­ä¹‰SLAMç³»ç»ŸGSFF-SLAMï¼Œè¯¥ç³»ç»ŸåŸºäº3Dé«˜æ–¯æ–‘ç‚¹æŠ€æœ¯ï¼Œåˆ©ç”¨ç‰¹å¾åœºå®ç°å¤–è§‚ã€å‡ ä½•å’ŒNç»´è¯­ä¹‰ç‰¹å¾çš„è”åˆæ¸²æŸ“ã€‚è¯¥æ–¹æ³•å¯ç‹¬ç«‹ä¼˜åŒ–ç‰¹å¾æ¢¯åº¦ï¼Œæ”¯æŒä½¿ç”¨å„ç§å½¢å¼çš„2Då…ˆéªŒè¿›è¡Œè¯­ä¹‰é‡å»ºï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€ç–å’Œå™ªå£°ä¿¡å·ç¯å¢ƒä¸‹è¡¨ç°ä¼˜å¼‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è·Ÿè¸ªç²¾åº¦å’Œç…§ç‰‡çº§æ¸²æŸ“è´¨é‡ä¸Šå‡ä¼˜äºå…ˆå‰æ–¹æ³•ï¼Œåˆ©ç”¨2Dåœ°é¢çœŸå®å…ˆéªŒæ—¶ï¼Œå®ç°95.03%çš„mIoUè¯­ä¹‰åˆ†å‰²æ€§èƒ½ï¼ŒåŒæ—¶å®ç°2.9å€çš„é€Ÿåº¦æå‡ï¼Œä¸”æ€§èƒ½æŸå¤±è¾ƒå°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­ä¹‰æ„ŸçŸ¥çš„3Dåœºæ™¯é‡å»ºå¯¹è‡ªä¸»æœºå™¨äººè¿›è¡Œå¤æ‚äº¤äº’è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰çš„è¯­ä¹‰SLAMç³»ç»Ÿé€šå¸¸ä¾èµ–äº2Dåœ°é¢çœŸå®å…ˆéªŒè¿›è¡Œç›‘ç£ï¼Œè¿™åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å—åˆ°ä¿¡å·ç¨€ç–å’Œå™ªå£°çš„é™åˆ¶ã€‚</li>
<li>GSFF-SLAMæ˜¯ä¸€ç§æ–°å‹çš„å¯†é›†è¯­ä¹‰SLAMç³»ç»Ÿï¼ŒåŸºäº3Dé«˜æ–¯æ–‘ç‚¹æŠ€æœ¯ã€‚</li>
<li>GSFF-SLAMåˆ©ç”¨ç‰¹å¾åœºå®ç°å¤–è§‚ã€å‡ ä½•å’ŒNç»´è¯­ä¹‰ç‰¹å¾çš„è”åˆæ¸²æŸ“ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ç‹¬ç«‹ä¼˜åŒ–ç‰¹å¾æ¢¯åº¦ï¼Œæ”¯æŒä½¿ç”¨å„ç§å½¢å¼çš„2Då…ˆéªŒè¿›è¡Œè¯­ä¹‰é‡å»ºã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºGSFF-SLAMåœ¨è·Ÿè¸ªç²¾åº¦å’Œæ¸²æŸ“è´¨é‡ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19409">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d1d98acfc8378c57177b2d1be6b292a0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4758e81dfbe2a403fedfa271b2c04cc1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3cff7ca5b878ce125255dbb6e2ea578.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Rendering-Anywhere-You-See-Renderability-Field-guided-Gaussian-Splatting"><a href="#Rendering-Anywhere-You-See-Renderability-Field-guided-Gaussian-Splatting" class="headerlink" title="Rendering Anywhere You See: Renderability Field-guided Gaussian   Splatting"></a>Rendering Anywhere You See: Renderability Field-guided Gaussian   Splatting</h2><p><strong>Authors:Xiaofeng Jin, Yan Fang, Matteo Frosi, Jianfei Ge, Jiangjian Xiao, Matteo Matteucci</strong></p>
<p>Scene view synthesis, which generates novel views from limited perspectives, is increasingly vital for applications like virtual reality, augmented reality, and robotics. Unlike object-based tasks, such as generating 360{\deg} views of a car, scene view synthesis handles entire environments where non-uniform observations pose unique challenges for stable rendering quality. To address this issue, we propose a novel approach: renderability field-guided gaussian splatting (RF-GS). This method quantifies input inhomogeneity through a renderability field, guiding pseudo-view sampling to enhanced visual consistency. To ensure the quality of wide-baseline pseudo-views, we train an image restoration model to map point projections to visible-light styles. Additionally, our validated hybrid data optimization strategy effectively fuses information of pseudo-view angles and source view textures. Comparative experiments on simulated and real-world data show that our method outperforms existing approaches in rendering stability. </p>
<blockquote>
<p>åœºæ™¯è§†å›¾åˆæˆï¼ˆScene view synthesisï¼‰æ˜¯ä»æœ‰é™è§†è§’ç”Ÿæˆæ–°é¢–è§†è§’çš„æŠ€æœ¯ï¼Œåœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œæœºå™¨äººç­‰é¢†åŸŸçš„åº”ç”¨è¶Šæ¥è¶Šé‡è¦ã€‚ä¸åŸºäºç‰©ä½“çš„ä»»åŠ¡ï¼ˆå¦‚ç”Ÿæˆæ±½è½¦360åº¦è§†å›¾ï¼‰ä¸åŒï¼Œåœºæ™¯è§†å›¾åˆæˆå¤„ç†çš„æ˜¯æ•´ä¸ªç¯å¢ƒï¼Œå…¶ä¸­éå‡åŒ€è§‚å¯Ÿç»™ç¨³å®šæ¸²æŸ“è´¨é‡å¸¦æ¥äº†ç‹¬ç‰¹æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼šå¯æ¸²æŸ“æ€§åœºå¼•å¯¼çš„é«˜æ–¯æ¶‚æ–‘æ³•ï¼ˆRF-GSï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯æ¸²æŸ“æ€§åœºé‡åŒ–è¾“å…¥çš„ä¸å‡åŒ€æ€§ï¼Œå¼•å¯¼ä¼ªè§†å›¾é‡‡æ ·ä»¥æé«˜è§†è§‰ä¸€è‡´æ€§ã€‚ä¸ºäº†ç¡®ä¿å®½åŸºçº¿ä¼ªè§†å›¾çš„è´¨é‡ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªå›¾åƒæ¢å¤æ¨¡å‹ï¼Œå°†ç‚¹æŠ•å½±æ˜ å°„åˆ°å¯è§å…‰é£æ ¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»è¿‡éªŒè¯çš„æ··åˆæ•°æ®ä¼˜åŒ–ç­–ç•¥æœ‰æ•ˆåœ°èåˆäº†ä¼ªè§†è§’å’Œæºè§†å›¾çº¹ç†çš„ä¿¡æ¯ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„å¯¹æ¯”å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¸²æŸ“ç¨³å®šæ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19261v1">PDF</a> 8 pages,8 figures</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºäº†åŸºäºæ¸²æŸ“åœºå¼•å¯¼çš„é«˜æ–¯è´´å›¾æ–¹æ³•ï¼ˆRF-GSï¼‰ï¼Œç”¨äºè§£å†³åœºæ™¯è§†è§’åˆæˆä¸­é‡åˆ°çš„ç¯å¢ƒéå‡åŒ€æ€§é—®é¢˜ï¼Œæå‡äº†è§†è§‰æ•ˆæœçš„ä¸€è‡´æ€§ã€‚é‡‡ç”¨æ··åˆæ•°æ®ä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆä¼ªè§†è§’è§’åº¦å’Œæºè§†è§’çº¹ç†ä¿¡æ¯ï¼Œæé«˜æ¸²æŸ“ç¨³å®šæ€§ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æ•°æ®ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« æå‡ºäº†åœºæ™¯è§†è§’åˆæˆä¸­çš„éå‡åŒ€æ€§é—®é¢˜ï¼Œå³å¤„ç†æ•´ä¸ªç¯å¢ƒæ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼šåŸºäºæ¸²æŸ“åœºå¼•å¯¼çš„é«˜æ–¯è´´å›¾ï¼ˆRF-GSï¼‰ï¼Œä»¥æ”¹å–„è§†è§‰æ•ˆæœçš„ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡é‡åŒ–è¾“å…¥çš„ä¸å‡åŒ€æ€§ï¼Œç”Ÿæˆä¸€ä¸ªæ¸²æŸ“åœºæ¥æŒ‡å¯¼ä¼ªè§†è§’é‡‡æ ·ã€‚</li>
<li>é‡‡ç”¨å›¾åƒæ¢å¤æ¨¡å‹ï¼Œå°†ç‚¹æŠ•å½±æ˜ å°„åˆ°å¯è§å…‰é£æ ¼ï¼Œç¡®ä¿å®½åŸºçº¿ä¼ªè§†è§’çš„è´¨é‡ã€‚</li>
<li>é‡‡ç”¨éªŒè¯è¿‡çš„æ··åˆæ•°æ®ä¼˜åŒ–ç­–ç•¥ï¼Œèåˆä¼ªè§†è§’è§’åº¦å’Œæºè§†è§’çº¹ç†ä¿¡æ¯ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æ•°æ®ä¸Šçš„æ¸²æŸ“ç¨³å®šæ€§ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19261">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c27e99af7b0b6faaf06338dc9bca3baa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df3c2d343f462cbc51c3607b05c8381e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2a064fb87f648ada1e8eaab64f679e9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a36ad87fe2c4b14ce4e0124d55ab39dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92fdc2a95f2397e28752e8964c8aab12.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e2289e2d3fc590ec6604993e436f6f1c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67256dba78ca7e2520dd11cf8fb4e380.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="IM-Portrait-Learning-3D-aware-Video-Diffusion-for-PhotorealisticTalking-Heads-from-Monocular-Videos"><a href="#IM-Portrait-Learning-3D-aware-Video-Diffusion-for-PhotorealisticTalking-Heads-from-Monocular-Videos" class="headerlink" title="IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking   Heads from Monocular Videos"></a>IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking   Heads from Monocular Videos</h2><p><strong>Authors:Yuan Li, Ziqian Bai, Feitong Tan, Zhaopeng Cui, Sean Fanello, Yinda Zhang</strong></p>
<p>We propose a novel 3D-aware diffusion-based method for generating photorealistic talking head videos directly from a single identity image and explicit control signals (e.g., expressions). Our method generates Multiplane Images (MPIs) that ensure geometric consistency, making them ideal for immersive viewing experiences like binocular videos for VR headsets. Unlike existing methods that often require a separate stage or joint optimization to reconstruct a 3D representation (such as NeRF or 3D Gaussians), our approach directly generates the final output through a single denoising process, eliminating the need for post-processing steps to render novel views efficiently. To effectively learn from monocular videos, we introduce a training mechanism that reconstructs the output MPI randomly in either the target or the reference camera space. This approach enables the model to simultaneously learn sharp image details and underlying 3D information. Extensive experiments demonstrate the effectiveness of our method, which achieves competitive avatar quality and novel-view rendering capabilities, even without explicit 3D reconstruction or high-quality multi-view training data. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºä¸‰ç»´æ„ŸçŸ¥æ‰©æ•£çš„æ–¹æ³•ï¼Œç›´æ¥ä»å•å¼ èº«ä»½å›¾åƒå’Œæ˜ç¡®çš„æ§åˆ¶ä¿¡å·ï¼ˆå¦‚è¡¨æƒ…ï¼‰ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººå¤´è§†é¢‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆå¤šå¹³é¢å›¾åƒï¼ˆMPIsï¼‰ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œä½¿å…¶æˆä¸ºç†æƒ³çš„é€‰æ‹©ï¼Œå¯ç”¨äºè™šæ‹Ÿç°å®å¤´ç›”æ˜¾ç¤ºå™¨çš„åŒç›®è§†é¢‘ç­‰æ²‰æµ¸å¼è§‚çœ‹ä½“éªŒã€‚ä¸é€šå¸¸éœ€è¦å•ç‹¬é˜¶æ®µæˆ–è”åˆä¼˜åŒ–æ¥é‡å»ºä¸‰ç»´è¡¨ç¤ºï¼ˆå¦‚NeRFæˆ–ä¸‰ç»´é«˜æ–¯ï¼‰çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å•ä¸ªå»å™ªè¿‡ç¨‹ç›´æ¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼Œæ— éœ€è¿›è¡ŒåæœŸå¤„ç†æ­¥éª¤å³å¯æœ‰æ•ˆåœ°æ¸²æŸ“æ–°é¢–è§†å›¾ã€‚ä¸ºäº†æœ‰æ•ˆåœ°ä»å•ç›®è§†é¢‘ä¸­å­¦ä¹ ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è®­ç»ƒæœºåˆ¶ï¼Œè¯¥æœºåˆ¶å¯ä»¥åœ¨ç›®æ ‡ç›¸æœºç©ºé—´æˆ–å‚è€ƒç›¸æœºç©ºé—´ä¸­éšæœºé‡å»ºè¾“å‡ºMPIã€‚è¿™ç§æ–¹æ³•ä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ å°–é”çš„å›¾åƒç»†èŠ‚å’Œæ½œåœ¨çš„ä¸‰ç»´ä¿¡æ¯ã€‚å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå³ä½¿åœ¨ç¼ºä¹æ˜ç¡®çš„ä¸‰ç»´é‡å»ºæˆ–é«˜è´¨é‡å¤šè§†è§’è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿèƒ½è¾¾åˆ°ç«äº‰æ€§çš„åŒ–èº«è´¨é‡å’Œæ–°é¢–çš„è§†å›¾æ¸²æŸ“èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19165v1">PDF</a> CVPR2025; project page:   <a target="_blank" rel="noopener" href="https://y-u-a-n-l-i.github.io/projects/IM-Portrait/">https://y-u-a-n-l-i.github.io/projects/IM-Portrait/</a></p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£ä¸‰ç»´æ„ŸçŸ¥æ‰©æ•£æ–¹æ³•å¯ç›´æ¥ä»å•ä¸€èº«ä»½å›¾åƒå’Œæ§åˆ¶ä¿¡å·ï¼ˆå¦‚è¡¨æƒ…ï¼‰ç”Ÿæˆé€¼çœŸçš„åŠ¨ç”»å¤´åƒè§†é¢‘ã€‚è¯¥æ–¹æ³•ç”Ÿæˆå¤šå¹³é¢å›¾åƒï¼ˆMPIsï¼‰ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œé€‚ç”¨äºè™šæ‹Ÿç°å®å¤´æˆ´è®¾å¤‡çš„æ²‰æµ¸å¼è§‚çœ‹ä½“éªŒã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œæ— éœ€é¢å¤–çš„é˜¶æ®µæˆ–è”åˆä¼˜åŒ–æ¥é‡å»ºä¸‰ç»´è¡¨ç¤ºï¼Œé€šè¿‡å•ä¸€çš„é™å™ªè¿‡ç¨‹ç›´æ¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼Œæœ‰æ•ˆé¿å…å¤æ‚çš„åæœŸå¤„ç†æ­¥éª¤ä»¥å®ç°æ–°è§†è§’çš„é«˜æ•ˆæ¸²æŸ“ã€‚å¼•å…¥äº†ä¸€ç§è®­ç»ƒæœºåˆ¶ï¼Œèƒ½åœ¨ç›®æ ‡ç›¸æœºç©ºé—´æˆ–å‚è€ƒç›¸æœºç©ºé—´ä¸­é‡å»ºè¾“å‡ºMPIï¼Œä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ æ¸…æ™°å›¾åƒç»†èŠ‚å’Œåº•å±‚ä¸‰ç»´ä¿¡æ¯ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå³ä½¿åœ¨æ— éœ€æ˜ç¡®çš„ä¸‰ç»´é‡å»ºæˆ–é«˜è´¨é‡å¤šè§†è§’è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å®ç°å…·æœ‰ç«äº‰åŠ›çš„è§’è‰²è´¨é‡å’Œæ–°è§†è§’çš„æ¸²æŸ“èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸‰ç»´æ„ŸçŸ¥æ‰©æ•£æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å•ä¸€èº«ä»½å›¾åƒå’Œæ§åˆ¶ä¿¡å·ç”ŸæˆåŠ¨ç”»å¤´åƒè§†é¢‘ã€‚</li>
<li>ç”Ÿæˆçš„å¤šå¹³é¢å›¾åƒï¼ˆMPIsï¼‰ä¿è¯äº†å‡ ä½•ä¸€è‡´æ€§ï¼Œé€‚åˆè™šæ‹Ÿç°å®æ²‰æµ¸å¼ä½“éªŒã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡å•ä¸€çš„é™å™ªè¿‡ç¨‹ç›´æ¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼Œæ— éœ€é¢å¤–çš„é˜¶æ®µæˆ–è”åˆä¼˜åŒ–ï¼Œç®€åŒ–äº†æµç¨‹ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§è®­ç»ƒæœºåˆ¶ï¼Œèƒ½åœ¨ç›®æ ‡ç›¸æœºç©ºé—´æˆ–å‚è€ƒç›¸æœºç©ºé—´ä¸­é‡å»ºMPIï¼Œä¿ƒè¿›æ¨¡å‹åŒæ—¶å­¦ä¹ å›¾åƒç»†èŠ‚å’Œåº•å±‚ä¸‰ç»´ä¿¡æ¯ã€‚</li>
<li>æ–¹æ³•å…·æœ‰é«˜æ•ˆçš„æ¸²æŸ“èƒ½åŠ›å’Œç«äº‰åŠ›å¼ºçš„è§’è‰²è´¨é‡ï¼Œå³ä½¿åœ¨æ²¡æœ‰æ˜ç¡®çš„ä¸‰ç»´é‡å»ºæˆ–é«˜è´¨é‡å¤šè§†è§’è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¡¨ç°å‡ºè‰²ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19165">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d2ff881d1ab0d0b4aff210c5b6de48d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9d1d8a2d3376eb8bcec01d470d25c2b5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6a3605fcb2c83be4794d477ce4c0b058.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-37b87189576c03cf50993939fe028f40.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TransparentGS-Fast-Inverse-Rendering-of-Transparent-Objects-with-Gaussians"><a href="#TransparentGS-Fast-Inverse-Rendering-of-Transparent-Objects-with-Gaussians" class="headerlink" title="TransparentGS: Fast Inverse Rendering of Transparent Objects with   Gaussians"></a>TransparentGS: Fast Inverse Rendering of Transparent Objects with   Gaussians</h2><p><strong>Authors:Letian Huang, Dongwei Ye, Jialin Dan, Chengzhi Tao, Huiwen Liu, Kun Zhou, Bo Ren, Yuanqi Li, Yanwen Guo, Jie Guo</strong></p>
<p>The emergence of neural and Gaussian-based radiance field methods has led to considerable advancements in novel view synthesis and 3D object reconstruction. Nonetheless, specular reflection and refraction continue to pose significant challenges due to the instability and incorrect overfitting of radiance fields to high-frequency light variations. Currently, even 3D Gaussian Splatting (3D-GS), as a powerful and efficient tool, falls short in recovering transparent objects with nearby contents due to the existence of apparent secondary ray effects. To address this issue, we propose TransparentGS, a fast inverse rendering pipeline for transparent objects based on 3D-GS. The main contributions are three-fold. Firstly, an efficient representation of transparent objects, transparent Gaussian primitives, is designed to enable specular refraction through a deferred refraction strategy. Secondly, we leverage Gaussian light field probes (GaussProbe) to encode both ambient light and nearby contents in a unified framework. Thirdly, a depth-based iterative probes query (IterQuery) algorithm is proposed to reduce the parallax errors in our probe-based framework. Experiments demonstrate the speed and accuracy of our approach in recovering transparent objects from complex environments, as well as several applications in computer graphics and vision. </p>
<blockquote>
<p>ç¥ç»å’Œé«˜æ–¯åŸºè¾å°„åœºæ–¹æ³•çš„å‡ºç°ä¸ºæ–°å‹è§†å›¾åˆæˆå’Œ3Då¯¹è±¡é‡å»ºå¸¦æ¥äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºè¾å°„åœºå¯¹é«˜é¢‘å…‰å˜åŒ–çš„ä¸ç¨³å®šæ€§å’Œä¸æ­£ç¡®çš„è¿‡åº¦æ‹Ÿåˆï¼Œé•œé¢åå°„å’ŒæŠ˜å°„ä»ç„¶æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚ç›®å‰ï¼Œå³ä½¿3Dé«˜æ–¯Splattingï¼ˆ3D-GSï¼‰ä½œä¸ºä¸€ç§å¼ºå¤§è€Œæœ‰æ•ˆçš„å·¥å…·ï¼Œç”±äºæ˜æ˜¾çš„äºŒæ¬¡å°„çº¿æ•ˆåº”çš„å­˜åœ¨ï¼Œåœ¨æ¢å¤é™„è¿‘å†…å®¹çš„é€æ˜ç‰©ä½“æ—¶ä¹Ÿç›¸å½¢è§ç»Œã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäº3D-GSçš„é€æ˜å¯¹è±¡å¿«é€Ÿé€†å‘æ¸²æŸ“ç®¡é“TransparentGSã€‚ä¸»è¦è´¡çŒ®æœ‰ä¸‰ç‚¹ã€‚é¦–å…ˆï¼Œè®¾è®¡äº†ä¸€ç§é€æ˜å¯¹è±¡çš„é«˜æ•ˆè¡¨ç¤ºæ–¹æ³•ï¼Œå³é€æ˜é«˜æ–¯åŸºå…ƒï¼Œä»¥å®ç°é€šè¿‡å»¶è¿ŸæŠ˜å°„ç­–ç•¥çš„é•œé¢æŠ˜å°„ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åˆ©ç”¨é«˜æ–¯å…‰åœºæ¢é’ˆï¼ˆGaussProbeï¼‰å°†ç¯å¢ƒå…‰å’Œé™„è¿‘å†…å®¹ç¼–ç åˆ°ç»Ÿä¸€æ¡†æ¶ä¸­ã€‚ç¬¬ä¸‰ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦çš„è¿­ä»£æ¢é’ˆæŸ¥è¯¢ï¼ˆIterQueryï¼‰ç®—æ³•ï¼Œä»¥å‡å°‘æˆ‘ä»¬åŸºäºæ¢é’ˆçš„æ¡†æ¶ä¸­çš„è§†å·®è¯¯å·®ã€‚å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸­æ¢å¤é€æ˜å¯¹è±¡çš„é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼Œä»¥åŠåœ¨è®¡ç®—æœºå›¾å½¢å’Œè§†è§‰ä¸­çš„ä¸€äº›åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18768v1">PDF</a> accepted by SIGGRAPH 2025;   <a target="_blank" rel="noopener" href="https://letianhuang.github.io/transparentgs/">https://letianhuang.github.io/transparentgs/</a></p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œå’ŒåŸºäºé«˜æ–¯çš„å…‰åœºæ–¹æ³•çš„å‘å±•æå¤§åœ°æ¨åŠ¨äº†æ–°å‹è§†å›¾åˆæˆå’Œä¸‰ç»´ç‰©ä½“é‡å»ºçš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œç”±äºé«˜é¢‘å…‰ç…§å˜åŒ–ä¸‹è¾å°„åœºçš„ç¨³å®šæ€§åŠè¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå…‰åå°„å’ŒæŠ˜å°„ä»å­˜åœ¨å·¨å¤§æŒ‘æˆ˜ã€‚å°½ç®¡å¼ºå¤§çš„å·¥å…·å¦‚ä¸‰ç»´é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼ˆ3D-GSï¼‰åœ¨å¤åŸé€æ˜ç‰©ä½“æ—¶è¡¨ç°ä¼˜ç§€ï¼Œä½†ç”±äºå­˜åœ¨æ˜æ˜¾çš„äºŒæ¬¡å°„çº¿æ•ˆåº”ï¼Œéš¾ä»¥åº”å¯¹ç‰©ä½“å‘¨å›´çš„åœºæ™¯å†…å®¹ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé€æ˜é«˜æ–¯åŸè¯­ï¼ˆTransparentGSï¼‰çš„å¿«é€Ÿé€†å‘æ¸²æŸ“ç®¡çº¿ã€‚ä¸»è¦è´¡çŒ®æœ‰ä¸‰ç‚¹ï¼šè®¾è®¡äº†ä¸€ç§é€æ˜çš„ç‰©ä½“è¡¨ç¤ºæ–¹æ³•â€”â€”é€æ˜é«˜æ–¯åŸè¯­ï¼Œé€šè¿‡å»¶è¿ŸæŠ˜å°„ç­–ç•¥å®ç°é•œé¢æŠ˜å°„ï¼›åˆ©ç”¨é«˜æ–¯å…‰åœºæ¢é’ˆï¼ˆGaussProbeï¼‰å°†ç¯å¢ƒå…‰å’Œå‘¨å›´åœºæ™¯å†…å®¹ç¼–ç è¿›ç»Ÿä¸€æ¡†æ¶ï¼›æå‡ºäº†åŸºäºæ·±åº¦çš„è¿­ä»£æ¢é’ˆæŸ¥è¯¢ç®—æ³•ï¼ˆIterQueryï¼‰ï¼Œå‡å°‘æ¢é’ˆåŸºç¡€ä¸Šçš„æ¡†æ¶çš„è§†å·®è¯¯å·®ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¿«é€Ÿå‡†ç¡®åœ°ä»å¤æ‚ç¯å¢ƒä¸­æ¢å¤é€æ˜ç‰©ä½“ï¼Œåœ¨è®¡ç®—æœºå›¾å½¢å’Œè§†è§‰ä¸­æœ‰å¹¿æ³›åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¥ç»ç½‘ç»œå’Œé«˜æ–¯å…‰åœºæ–¹æ³•æ¨åŠ¨äº†è§†å›¾åˆæˆå’Œä¸‰ç»´é‡å»ºçš„è¿›æ­¥ã€‚</li>
<li>å…‰åå°„å’ŒæŠ˜å°„å­˜åœ¨æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºè¾å°„åœºå¯¹é«˜é¢‘å…‰ç…§å˜åŒ–çš„ç¨³å®šæ€§å’Œè¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>ä¸‰ç»´é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼ˆ3D-GSï¼‰åœ¨å¤„ç†é€æ˜ç‰©ä½“æ—¶é¢ä¸´äºŒæ¬¡å°„çº¿æ•ˆåº”çš„æŒ‘æˆ˜ã€‚</li>
<li>TransparentGSæ–¹æ³•é€šè¿‡é€æ˜é«˜æ–¯åŸè¯­è®¾è®¡ã€GaussProbeå’ŒIterQueryç®—æ³•è§£å†³äº†è¿™äº›é—®é¢˜ã€‚</li>
<li>TransparentGSèƒ½å¿«é€Ÿå‡†ç¡®åœ°ä»å¤æ‚ç¯å¢ƒä¸­æ¢å¤é€æ˜ç‰©ä½“ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18768">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-edc2c87c72e640750978e6623d083b1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-702c739dbbca3238e7bfcc8a10ad18b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-241c43ee5b7b3975ffdf3b4ef952353a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fe08844b608482787b82c50f4b759b16.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fd880c89557d8b275f93901f2fa6f86.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="RGS-DR-Reflective-Gaussian-Surfels-with-Deferred-Rendering-for-Shiny-Objects"><a href="#RGS-DR-Reflective-Gaussian-Surfels-with-Deferred-Rendering-for-Shiny-Objects" class="headerlink" title="RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects"></a>RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects</h2><p><strong>Authors:Georgios Kouros, Minye Wu, Tinne Tuytelaars</strong></p>
<p>We introduce RGS-DR, a novel inverse rendering method for reconstructing and rendering glossy and reflective objects with support for flexible relighting and scene editing. Unlike existing methods (e.g., NeRF and 3D Gaussian Splatting), which struggle with view-dependent effects, RGS-DR utilizes a 2D Gaussian surfel representation to accurately estimate geometry and surface normals, an essential property for high-quality inverse rendering. Our approach explicitly models geometric and material properties through learnable primitives rasterized into a deferred shading pipeline, effectively reducing rendering artifacts and preserving sharp reflections. By employing a multi-level cube mipmap, RGS-DR accurately approximates environment lighting integrals, facilitating high-quality reconstruction and relighting. A residual pass with spherical-mipmap-based directional encoding further refines the appearance modeling. Experiments demonstrate that RGS-DR achieves high-quality reconstruction and rendering quality for shiny objects, often outperforming reconstruction-exclusive state-of-the-art methods incapable of relighting. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†RGS-DRï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹é€†å‘æ¸²æŸ“æ–¹æ³•ï¼Œç”¨äºé‡å»ºå’Œæ¸²æŸ“å…·æœ‰å…‰æ³½å’Œåå°„ç‰¹æ€§çš„ç‰©ä½“ï¼Œæ”¯æŒçµæ´»çš„é‡æ–°æ‰“å…‰å’Œåœºæ™¯ç¼–è¾‘ã€‚ä¸ç°æœ‰æ–¹æ³•ï¼ˆä¾‹å¦‚NeRFå’Œ3Dé«˜æ–¯æ‹¼è´´ï¼‰ç›¸æ¯”ï¼Œå®ƒä»¬åœ¨å¤„ç†ä¸è§†å›¾ç›¸å…³çš„æ•ˆæœæ—¶é‡åˆ°å›°éš¾ï¼Œè€ŒRGS-DRä½¿ç”¨2Dé«˜æ–¯surfelè¡¨ç¤ºæ³•æ¥å‡†ç¡®ä¼°è®¡å‡ ä½•å’Œè¡¨é¢æ³•çº¿ï¼Œè¿™æ˜¯é«˜è´¨é‡é€†å‘æ¸²æŸ“çš„åŸºæœ¬å±æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å¯å­¦ä¹ çš„åŸå§‹å…ƒç´ æ˜¾å¼å»ºæ¨¡å‡ ä½•å’Œææ–™å±æ€§ï¼Œå¹¶å°†å…¶æ¸²æŸ“åˆ°å»¶è¿Ÿç€è‰²ç®¡é“ä¸­ï¼Œè¿™æœ‰æ•ˆåœ°å‡å°‘äº†æ¸²æŸ“ä¼ªå½±å¹¶ä¿æŒäº†é”åˆ©çš„åå°„ã€‚é€šè¿‡é‡‡ç”¨å¤šå±‚æ¬¡ç«‹æ–¹ä½“mipmapï¼ŒRGS-DRèƒ½å¤Ÿå‡†ç¡®è¿‘ä¼¼ç¯å¢ƒå…‰ç…§ç§¯åˆ†ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„é‡å»ºå’Œé‡æ–°æ‰“å…‰ã€‚åŸºäºçƒå½¢mipmapçš„æ–¹å‘ç¼–ç çš„æ®‹å·®ä¼ é€’è¿›ä¸€æ­¥æ”¹è¿›äº†å¤–è§‚å»ºæ¨¡ã€‚å®éªŒè¡¨æ˜ï¼ŒRGS-DRåœ¨é‡å»ºå’Œæ¸²æŸ“å…‰æ³½ç‰©ä½“æ–¹é¢è¾¾åˆ°äº†é«˜è´¨é‡ï¼Œé€šå¸¸ä¼˜äºé‚£äº›æ— æ³•è¿›è¡Œé‡æ–°æ‰“å…‰çš„ä»…ç”¨äºé‡å»ºçš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18468v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>RGS-DRæ˜¯ä¸€ç§æ–°å‹é€†å‘æ¸²æŸ“æ–¹æ³•ï¼Œèƒ½é‡å»ºå’Œæ¸²æŸ“å…·æœ‰å…‰æ³½å’Œåå°„ç‰¹æ€§çš„ç‰©ä½“ï¼Œæ”¯æŒçµæ´»çš„é‡æ–°ç…§æ˜å’Œåœºæ™¯ç¼–è¾‘ã€‚è¯¥æ–¹æ³•é‡‡ç”¨2Dé«˜æ–¯surfelè¡¨ç¤ºæ³•å‡†ç¡®ä¼°è®¡å‡ ä½•å’Œè¡¨é¢æ³•çº¿ï¼Œé€šè¿‡å¯å­¦ä¹ çš„åŸå§‹å…ƒç´ æ˜¾å¼å»ºæ¨¡å‡ ä½•å’Œæè´¨å±æ€§ï¼Œå¹¶èå…¥å»¶è¿Ÿç€è‰²ç®¡é“ï¼Œæœ‰æ•ˆå‡å°‘æ¸²æŸ“ä¼ªå½±ï¼Œä¿ç•™é”åˆ©åå°„ã€‚é€šè¿‡é‡‡ç”¨å¤šå±‚ç«‹æ–¹ä½“mipmapï¼ŒRGS-DRå‡†ç¡®è¿‘ä¼¼ç¯å¢ƒå…‰ç…§ç§¯åˆ†ï¼Œå®ç°é«˜è´¨é‡é‡å»ºå’Œé‡æ–°ç…§æ˜ã€‚ä½¿ç”¨åŸºäºçƒå½¢mipmapçš„æ–¹å‘ç¼–ç çš„æ®‹å·®ä¼ é€’è¿›ä¸€æ­¥æ”¹è¿›äº†å¤–è§‚å»ºæ¨¡ã€‚å®éªŒè¡¨æ˜ï¼ŒRGS-DRåœ¨é‡å»ºå’Œæ¸²æŸ“å…‰æ³½ç‰©ä½“æ–¹é¢è¾¾åˆ°é«˜è´¨é‡ï¼Œå¾€å¾€è¶…è¶Šåªèƒ½é‡å»ºè€Œä¸èƒ½é‡æ–°ç…§æ˜çš„æœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RGS-DRæ˜¯ä¸€ç§ç”¨äºé‡å»ºå’Œæ¸²æŸ“å…·æœ‰å…‰æ³½å’Œåå°„ç‰¹æ€§çš„ç‰©ä½“çš„æ–°å‹é€†å‘æ¸²æŸ“æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨2Dé«˜æ–¯surfelè¡¨ç¤ºæ³•å‡†ç¡®ä¼°è®¡å‡ ä½•å’Œè¡¨é¢æ³•çº¿ï¼Œè¿™æ˜¯é«˜è´¨é‡é€†å‘æ¸²æŸ“çš„å…³é”®å±æ€§ã€‚</li>
<li>RGS-DRé€šè¿‡å¯å­¦ä¹ çš„åŸå§‹å…ƒç´ æ˜¾å¼å»ºæ¨¡å‡ ä½•å’Œæè´¨å±æ€§ï¼Œå¹¶èå…¥å»¶è¿Ÿç€è‰²ç®¡é“ï¼Œä»¥æé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>é‡‡ç”¨å¤šå±‚ç«‹æ–¹ä½“mipmapï¼ŒRGS-DRèƒ½å‡†ç¡®è¿‘ä¼¼ç¯å¢ƒå…‰ç…§ç§¯åˆ†ï¼Œå®ç°é«˜è´¨é‡é‡å»ºå’Œé‡æ–°ç…§æ˜ã€‚</li>
<li>æ®‹å·®ä¼ é€’å’ŒåŸºäºçƒå½¢mipmapçš„æ–¹å‘ç¼–ç è¿›ä¸€æ­¥æ”¹è¿›äº†RGS-DRçš„å¤–è§‚å»ºæ¨¡ã€‚</li>
<li>RGS-DRåœ¨é‡å»ºå’Œæ¸²æŸ“å…‰æ³½ç‰©ä½“æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¾€å¾€è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18468">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3ee68b5ed0b31156461008b3d74e2904.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5cbe5993b0e82f86f21ec2593ea7f2ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21a84f71db644f83249586af03728709.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Inpainting-with-Depth-Guided-Cross-View-Consistency"><a href="#3D-Gaussian-Inpainting-with-Depth-Guided-Cross-View-Consistency" class="headerlink" title="3D Gaussian Inpainting with Depth-Guided Cross-View Consistency"></a>3D Gaussian Inpainting with Depth-Guided Cross-View Consistency</h2><p><strong>Authors:Sheng-Yu Huang, Zi-Ting Chou, Yu-Chiang Frank Wang</strong></p>
<p>When performing 3D inpainting using novel-view rendering methods like Neural Radiance Field (NeRF) or 3D Gaussian Splatting (3DGS), how to achieve texture and geometry consistency across camera views has been a challenge. In this paper, we propose a framework of 3D Gaussian Inpainting with Depth-Guided Cross-View Consistency (3DGIC) for cross-view consistent 3D inpainting. Guided by the rendered depth information from each training view, our 3DGIC exploits background pixels visible across different views for updating the inpainting mask, allowing us to refine the 3DGS for inpainting purposes.Through extensive experiments on benchmark datasets, we confirm that our 3DGIC outperforms current state-of-the-art 3D inpainting methods quantitatively and qualitatively. </p>
<blockquote>
<p>åœ¨ä½¿ç”¨å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ç­‰æ–°å‹è§†å›¾æ¸²æŸ“æ–¹æ³•è¿›è¡Œ3Dè¡¥å…¨æ—¶ï¼Œå¦‚ä½•åœ¨ä¸åŒç›¸æœºè§†è§’é—´å®ç°çº¹ç†å’Œå‡ ä½•ä¸€è‡´æ€§ä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºâ€œå¸¦æœ‰æ·±åº¦å¼•å¯¼è·¨è§†å›¾ä¸€è‡´æ€§ï¼ˆ3DGICï¼‰çš„3Dé«˜æ–¯è¡¥å…¨â€çš„æ¡†æ¶ï¼Œç”¨äºå®ç°è·¨è§†å›¾ä¸€è‡´çš„3Dè¡¥å…¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡åˆ©ç”¨æ¥è‡ªæ¯ä¸ªè®­ç»ƒè§†å›¾çš„æ¸²æŸ“æ·±åº¦ä¿¡æ¯ä½œä¸ºæŒ‡å¯¼ï¼Œåˆ©ç”¨åœ¨ä¸åŒè§†å›¾ä¸­å¯è§çš„èƒŒæ™¯åƒç´ æ¥æ›´æ–°è¡¥å…¨æ©è†œï¼Œä»è€Œå…è®¸æˆ‘ä»¬æ”¹è¿›ç”¨äºè¡¥å…¨çš„3DGSã€‚é€šè¿‡å¯¹åŸºå‡†æ•°æ®é›†çš„å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯å®æˆ‘ä»¬çš„3DGICåœ¨æ•°é‡å’Œè´¨é‡ä¸Šéƒ½ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„3Dè¡¥å…¨æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11801v2">PDF</a> Accepted to CVPR 2025. For project page, see   <a target="_blank" rel="noopener" href="https://peterjohnsonhuang.github.io/3dgic-pages">https://peterjohnsonhuang.github.io/3dgic-pages</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å¼•å¯¼çš„è·¨è§†å›¾ä¸€è‡´æ€§3Dé«˜æ–¯è¡¥å…¨ï¼ˆ3DGICï¼‰æ¡†æ¶ï¼Œç”¨äºå®ç°è·¨è§†å›¾ä¸€è‡´çš„3Dè¡¥å…¨ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä»æ¯ä¸ªè®­ç»ƒè§†å›¾æ¸²æŸ“çš„æ·±åº¦ä¿¡æ¯æ¥æŒ‡å¯¼èƒŒæ™¯åƒç´ çš„å¯è§æ€§ï¼Œä»è€Œæ›´æ–°è¡¥å…¨æ©è†œï¼Œå®ç°å¯¹3DGSçš„ç»†åŒ–ï¼Œä»¥å®ç°è¡¥å…¨ç›®çš„ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰çš„3Dè¡¥å…¨æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGICæ¡†æ¶å®ç°äº†è·¨è§†å›¾ä¸€è‡´çš„3Dè¡¥å…¨ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨æ¸²æŸ“çš„æ·±åº¦ä¿¡æ¯æ¥æŒ‡å¯¼èƒŒæ™¯åƒç´ çš„å¯è§æ€§ã€‚</li>
<li>3DGICé€šè¿‡æ›´æ–°è¡¥å…¨æ©è†œæ¥ç»†åŒ–3DGSï¼Œä»¥å®ç°æ›´ç²¾ç¡®çš„è¡¥å…¨ã€‚</li>
<li>3DGICæ¡†æ¶åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤„ç†3Dçº¹ç†å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢é‡åˆ°çš„æŒ‘æˆ˜æ—¶è¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶é€‚ç”¨äºä½¿ç”¨NeRFæˆ–3DGSç­‰æ–°å‹è§†å›¾æ¸²æŸ“æ–¹æ³•çš„3Dè¡¥å…¨ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11801">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0ab49b78e681ebc866a1c8a79cb48f55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-093bef097eb0b1f5f8e7dcd7467abdc8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-144e7b763e33bb9fcf3959c55712ba83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81a788d424a93cc30827a27bbeb0e989.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CrossView-GS-Cross-view-Gaussian-Splatting-For-Large-scale-Scene-Reconstruction"><a href="#CrossView-GS-Cross-view-Gaussian-Splatting-For-Large-scale-Scene-Reconstruction" class="headerlink" title="CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene   Reconstruction"></a>CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene   Reconstruction</h2><p><strong>Authors:Chenhao Zhang, Yuanping Cao, Lei Zhang</strong></p>
<p>3D Gaussian Splatting (3DGS) leverages densely distributed Gaussian primitives for high-quality scene representation and reconstruction. While existing 3DGS methods perform well in scenes with minor view variation, large view changes from cross-view data pose optimization challenges for these methods. To address these issues, we propose a novel cross-view Gaussian Splatting method for large-scale scene reconstruction based on multi-branch construction and fusion. Our method independently reconstructs models from different sets of views as multiple independent branches to establish the baselines of Gaussian distribution, providing reliable priors for cross-view reconstruction during initialization and densification. Specifically, a gradient-aware regularization strategy is introduced to mitigate smoothing issues caused by significant view disparities. Additionally, a unique Gaussian supplementation strategy is utilized to incorporate complementary information of multi-branch into the cross-view model. Extensive experiments on benchmark datasets demonstrate that our method achieves superior performance in novel view synthesis compared to state-of-the-art methods. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‘Šé“ºï¼ˆ3DGSï¼‰åˆ©ç”¨å¯†é›†åˆ†å¸ƒçš„GaussianåŸºæœ¬å•ä½æ¥è¡¨ç¤ºå’Œé‡å»ºé«˜è´¨é‡çš„åœºæ™¯ã€‚ç°æœ‰çš„ä¸‰ç»´GSæ–¹æ³•åœ¨è½»å¾®è§†è§’å˜åŒ–çš„åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†ä»è·¨è§†è§’æ•°æ®ä¸­è·å–çš„å¤§è§†è§’å˜åŒ–ä¸ºè¿™äº›æ–¹æ³•å¸¦æ¥äº†ä¼˜åŒ–æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šåˆ†æ”¯æ„å»ºå’Œèåˆçš„å¤§åœºæ™¯é‡å»ºçš„è·¨è§†å›¾é«˜æ–¯æ‘Šé“ºæ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»ä¸åŒè§†è§’çš„ç‹¬ç«‹æ•°æ®é›†é‡å»ºæ¨¡å‹ï¼Œå»ºç«‹å¤šä¸ªç‹¬ç«‹åˆ†æ”¯æ¥æ„å»ºé«˜æ–¯åˆ†å¸ƒçš„åŸºçº¿ï¼Œä¸ºåˆå§‹åŒ–å’Œå¯†é›†åŒ–è¿‡ç¨‹ä¸­çš„è·¨è§†å›¾é‡å»ºæä¾›å¯é çš„å…ˆéªŒçŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œå¼•å…¥äº†ä¸€ç§æ¢¯åº¦æ„ŸçŸ¥çš„æ­£åˆ™åŒ–ç­–ç•¥ï¼Œä»¥ç¼“è§£ç”±æ˜¾è‘—è§†è§’å·®å¼‚å¼•èµ·çš„å¹³æ»‘é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¿˜é‡‡ç”¨äº†ä¸€ç§ç‹¬ç‰¹çš„Gaussianè¡¥å……ç­–ç•¥ï¼Œå°†å¤šåˆ†æ”¯çš„äº’è¡¥ä¿¡æ¯èå…¥è·¨è§†å›¾æ¨¡å‹ä¸­ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01695v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºå¯†é›†åˆ†å¸ƒçš„é«˜æ–¯åŸºå…ƒçš„ä¸‰ç»´é«˜æ–¯èåˆï¼ˆ3DGSï¼‰æŠ€æœ¯ç”¨äºé«˜è´¨é‡çš„åœºæ™¯è¡¨ç¤ºå’Œé‡å»ºã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨è·¨è§†è§’æ•°æ®å­˜åœ¨è¾ƒå¤§è§†è§’å˜åŒ–æ—¶çš„ä¼˜åŒ–æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šåˆ†æ”¯æ„å»ºå’Œèåˆçš„æ–°å‹è·¨è§†è§’é«˜æ–¯èåˆæ–¹æ³•ï¼Œç”¨äºå¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚è¯¥æ–¹æ³•é€šè¿‡ä»ä¸åŒè§†è§’ç‹¬ç«‹é‡å»ºæ¨¡å‹ä½œä¸ºå¤šä¸ªç‹¬ç«‹åˆ†æ”¯ï¼Œå»ºç«‹é«˜æ–¯åˆ†å¸ƒçš„åŸºå‡†ï¼Œä¸ºè·¨è§†è§’é‡å»ºæä¾›å¯é çš„å…ˆéªŒä¿¡æ¯ã€‚å¼•å…¥æ¢¯åº¦æ„ŸçŸ¥æ­£åˆ™åŒ–ç­–ç•¥ä»¥ç¼“è§£æ˜¾è‘—è§†è§’å·®å¼‚å¯¼è‡´çš„å¹³æ»‘é—®é¢˜ï¼Œå¹¶é‡‡ç”¨ç‹¬ç‰¹çš„é«˜æ–¯è¡¥å……ç­–ç•¥å°†å¤šåˆ†æ”¯çš„äº’è¡¥ä¿¡æ¯èå…¥è·¨è§†è§’æ¨¡å‹ä¸­ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ–°å‹è§†è§’åˆæˆæ–¹é¢ç›¸è¾ƒäºç°æœ‰å…ˆè¿›æŠ€æœ¯è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæŠ€æœ¯åˆ©ç”¨å¯†é›†åˆ†å¸ƒçš„é«˜æ–¯åŸºå…ƒè¿›è¡Œé«˜è´¨é‡çš„åœºæ™¯è¡¨ç¤ºå’Œé‡å»ºã€‚</li>
<li>é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šåˆ†æ”¯æ„å»ºå’Œèåˆçš„æ–°å‹è·¨è§†è§’é«˜æ–¯èåˆæ–¹æ³•ã€‚</li>
<li>ç‹¬ç«‹åˆ†æ”¯ä»¥é«˜æ–¯åˆ†å¸ƒåŸºå‡†å½¢å¼å»ºç«‹ï¼Œä¸ºè·¨è§†è§’é‡å»ºæä¾›å¯é å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>é‡‡ç”¨æ¢¯åº¦æ„ŸçŸ¥æ­£åˆ™åŒ–ç­–ç•¥ç¼“è§£æ˜¾è‘—è§†è§’å·®å¼‚é€ æˆçš„å¹³æ»‘é—®é¢˜ã€‚</li>
<li>é«˜æ–¯è¡¥å……ç­–ç•¥ç”¨äºæ•´åˆå¤šåˆ†æ”¯çš„äº’è¡¥ä¿¡æ¯åˆ°è·¨è§†è§’æ¨¡å‹ä¸­ã€‚</li>
<li>æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜è¶Šï¼Œç‰¹åˆ«æ˜¯åœ¨æ–°å‹è§†è§’åˆæˆæ–¹é¢ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01695">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-43072bdcbb371443c3e110183e2f7509.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20bbb3ee2a838ebf3ffe4a1e5e9d31c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-833e8596a1fa74894350afde5e892e0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81c1a76b223db25dbe55c7e47a318a32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b91a86f8866a859c9c048844ea36586c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7ab3a78f7c0f17e5176f5735623f8d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fc1d39b1d54da65971608b0ca427b8b.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Wonderland-Navigating-3D-Scenes-from-a-Single-Image"><a href="#Wonderland-Navigating-3D-Scenes-from-a-Single-Image" class="headerlink" title="Wonderland: Navigating 3D Scenes from a Single Image"></a>Wonderland: Navigating 3D Scenes from a Single Image</h2><p><strong>Authors:Hanwen Liang, Junli Cao, Vidit Goel, Guocheng Qian, Sergei Korolev, Demetri Terzopoulos, Konstantinos N. Plataniotis, Sergey Tulyakov, Jian Ren</strong></p>
<p>How can one efficiently generate high-quality, wide-scope 3D scenes from arbitrary single images? Existing methods suffer several drawbacks, such as requiring multi-view data, time-consuming per-scene optimization, distorted geometry in occluded areas, and low visual quality in backgrounds. Our novel 3D scene reconstruction pipeline overcomes these limitations to tackle the aforesaid challenge. Specifically, we introduce a large-scale reconstruction model that leverages latents from a video diffusion model to predict 3D Gaussian Splattings of scenes in a feed-forward manner. The video diffusion model is designed to create videos precisely following specified camera trajectories, allowing it to generate compressed video latents that encode multi-view information while maintaining 3D consistency. We train the 3D reconstruction model to operate on the video latent space with a progressive learning strategy, enabling the efficient generation of high-quality, wide-scope, and generic 3D scenes. Extensive evaluations across various datasets affirm that our model significantly outperforms existing single-view 3D scene generation methods, especially with out-of-domain images. Thus, we demonstrate for the first time that a 3D reconstruction model can effectively be built upon the latent space of a diffusion model in order to realize efficient 3D scene generation. </p>
<blockquote>
<p>å¦‚ä½•ä»ä»»æ„å•å¼ å›¾åƒé«˜æ•ˆç”Ÿæˆé«˜è´¨é‡ã€å¤§èŒƒå›´çš„ä¸‰ç»´åœºæ™¯ï¼Ÿç°æœ‰æ–¹æ³•å­˜åœ¨è¯¸å¤šç¼ºç‚¹ï¼Œä¾‹å¦‚éœ€è¦å¤šè§†è§’æ•°æ®ã€è€—æ—¶çš„åœºæ™¯ä¼˜åŒ–ã€é®æŒ¡åŒºåŸŸçš„å‡ ä½•å¤±çœŸä»¥åŠèƒŒæ™¯è§†è§‰è´¨é‡ä½ä¸‹ã€‚æˆ‘ä»¬çš„æ–°å‹ä¸‰ç»´åœºæ™¯é‡å»ºæµç¨‹å…‹æœäº†è¿™äº›é™åˆ¶ï¼Œä»¥åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤§è§„æ¨¡é‡å»ºæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»¥è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç‰¹å¾ä¸ºåŸºç¡€ï¼Œä»¥é¢„æµ‹åœºæ™¯çš„ä¸‰ç»´é«˜æ–¯Splattingsã€‚è§†é¢‘æ‰©æ•£æ¨¡å‹è¢«è®¾è®¡ä¸ºéµå¾ªæŒ‡å®šçš„ç›¸æœºè½¨è¿¹åˆ›å»ºè§†é¢‘ï¼Œä»è€Œç”Ÿæˆå‹ç¼©çš„è§†é¢‘æ½œåœ¨ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾ç¼–ç äº†å¤šè§†è§’ä¿¡æ¯ï¼ŒåŒæ—¶ä¿æŒäº†ä¸‰ç»´ä¸€è‡´æ€§ã€‚æˆ‘ä»¬é‡‡ç”¨æ¸è¿›å­¦ä¹ ç­–ç•¥å¯¹ä¸‰ç»´é‡å»ºæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è§†é¢‘æ½œåœ¨ç©ºé—´ä¸Šè¿è¡Œï¼Œä»è€Œèƒ½å¤Ÿé«˜æ•ˆç”Ÿæˆé«˜è´¨é‡ã€å¤§èŒƒå›´ã€é€šç”¨çš„ä¸‰ç»´åœºæ™¯ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¯å®ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å•è§†å›¾ä¸‰ç»´åœºæ™¯ç”Ÿæˆæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨åŸŸå¤–å›¾åƒä¸Šã€‚å› æ­¤ï¼Œæˆ‘ä»¬é¦–æ¬¡è¯æ˜ï¼Œå¯ä»¥åœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸Šå»ºç«‹ä¸‰ç»´é‡å»ºæ¨¡å‹ï¼Œä»¥å®ç°é«˜æ•ˆçš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12091v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://snap-research.github.io/wonderland/">https://snap-research.github.io/wonderland/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„3Dåœºæ™¯é‡å»ºæ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼Œèƒ½å¤Ÿé«˜æ•ˆç”Ÿæˆé«˜è´¨é‡ã€å®½è§†é‡çš„3Dåœºæ™¯ã€‚é€šè¿‡å¼•å…¥å¤§è§„æ¨¡é‡å»ºæ¨¡å‹ï¼Œåˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ä¿¡æ¯é¢„æµ‹åœºæ™¯çš„3Dé«˜æ–¯Splattingsã€‚è¯¥æ¨¡å‹å¯ç”Ÿæˆé«˜è´¨é‡ã€å®½è§†é‡å’Œé€šç”¨çš„3Dåœºæ™¯ï¼Œå¹¶åœ¨å„ç§æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„3Dåœºæ™¯é‡å»ºæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡é¢„æµ‹åœºæ™¯çš„3Dé«˜æ–¯Splattingsæ¥ç”Ÿæˆé«˜è´¨é‡çš„3Dåœºæ™¯ã€‚</li>
<li>è§†é¢‘æ‰©æ•£æ¨¡å‹çš„è®¾è®¡å¯ç”Ÿæˆéµå¾ªæŒ‡å®šç›¸æœºè½¨è¿¹çš„è§†é¢‘æ½œåœ¨ä¿¡æ¯ï¼ŒåŒæ—¶ä¿æŒ3Dä¸€è‡´æ€§ã€‚</li>
<li>è®­ç»ƒé‡å»ºæ¨¡å‹åœ¨è§†é¢‘æ½œåœ¨ç©ºé—´ä¸Šä»¥æ¸è¿›å­¦ä¹ ç­–ç•¥è¿›è¡Œæ“ä½œï¼Œä»¥å®ç°é«˜æ•ˆçš„3Dåœºæ™¯ç”Ÿæˆã€‚</li>
<li>æ¨¡å‹èƒ½ç”Ÿæˆå®½è§†é‡å’Œé€šç”¨åœºæ™¯ï¼Œåœ¨å„ç§æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰å•è§†å›¾3Dåœºæ™¯ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>è¯¥æ¨¡å‹é¦–æ¬¡å±•ç¤ºäº†åœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸Šæ„å»ºæœ‰æ•ˆçš„3Dé‡å»ºæ¨¡å‹ä»¥å®ç°é«˜æ•ˆçš„åœºæ™¯ç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12091">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e6a2d95694980601963f3bccbda83423.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb22c485b79e1e1879dd15b2d1a685e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8497b85ef44881476146de4b318058d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9248f46536c06ac8e68f22d2002853b0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-9d1d8a2d3376eb8bcec01d470d25c2b5.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  Joint Optimization of Neural Radiance Fields and Continuous Camera   Motion from a Monocular Video
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-19245332300110d488b93963ce43368b.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  Real-time High-fidelity Gaussian Human Avatars with Position-based   Interpolation of Spatially Distributed MLPs
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">17012.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
