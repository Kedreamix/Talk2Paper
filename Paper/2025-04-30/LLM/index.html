<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  From Concept to Practice an Automated LLM-aided UVM Machine for RTL   Verification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-02d9999612e01b82dcf6e5fd4521e113.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    52 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-30-æ›´æ–°"><a href="#2025-04-30-æ›´æ–°" class="headerlink" title="2025-04-30 æ›´æ–°"></a>2025-04-30 æ›´æ–°</h1><h2 id="From-Concept-to-Practice-an-Automated-LLM-aided-UVM-Machine-for-RTL-Verification"><a href="#From-Concept-to-Practice-an-Automated-LLM-aided-UVM-Machine-for-RTL-Verification" class="headerlink" title="From Concept to Practice: an Automated LLM-aided UVM Machine for RTL   Verification"></a>From Concept to Practice: an Automated LLM-aided UVM Machine for RTL   Verification</h2><p><strong>Authors:Junhao Ye, Yuchen Hu, Ke Xu, Dingrong Pan, Qichun Chen, Jie Zhou, Shuai Zhao, Xinwei Fang, Xi Wang, Nan Guan, Zhe Jiang</strong></p>
<p>Verification presents a major bottleneck in Integrated Circuit (IC) development, consuming nearly 70% of the total development effort. While the Universal Verification Methodology (UVM) is widely used in industry to improve verification efficiency through structured and reusable testbenches, constructing these testbenches and generating sufficient stimuli remain challenging. These challenges arise from the considerable manual coding effort required, repetitive manual execution of multiple EDA tools, and the need for in-depth domain expertise to navigate complex designs.Here, we present UVM^2, an automated verification framework that leverages Large Language Models (LLMs) to generate UVM testbenches and iteratively refine them using coverage feedback, significantly reducing manual effort while maintaining rigorous verification standards.To evaluate UVM^2, we introduce a benchmark suite comprising Register Transfer Level (RTL) designs of up to 1.6K lines of code.The results show that UVM^2 reduces testbench setup time by up to UVM^2 compared to experienced engineers, and achieve average code and function coverage of 87.44% and 89.58%, outperforming state-of-the-art solutions by 20.96% and 23.51%, respectively. </p>
<blockquote>
<p>éªŒè¯æ˜¯é›†æˆç”µè·¯ï¼ˆICï¼‰å¼€å‘ä¸­çš„ä¸»è¦ç“¶é¢ˆï¼Œå æ®äº†è¿‘70%çš„æ€»å¼€å‘å·¥ä½œé‡ã€‚è™½ç„¶é€šç”¨éªŒè¯æ–¹æ³•è®ºï¼ˆUVMï¼‰åœ¨å·¥ä¸šä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œé€šè¿‡ç»“æ„åŒ–ã€å¯é‡ç”¨çš„æµ‹è¯•å¹³å°æ¥æé«˜éªŒè¯æ•ˆç‡ï¼Œä½†æ„å»ºè¿™äº›æµ‹è¯•å¹³å°å’Œç”Ÿæˆè¶³å¤Ÿçš„æ¿€åŠ±ä»å­˜åœ¨æŒ‘æˆ˜ã€‚è¿™äº›æŒ‘æˆ˜æºäºå¤§é‡æ‰€éœ€çš„æ‰‹åŠ¨ç¼–ç å·¥ä½œã€å¤šä¸ªEDAå·¥å…·çš„æ‰‹åŠ¨é‡å¤æ‰§è¡Œï¼Œä»¥åŠæ·±å…¥ç‰¹å®šé¢†åŸŸä¸“ä¸šçŸ¥è¯†ä»¥åº”å¯¹å¤æ‚è®¾è®¡çš„éœ€è¦ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºUVM^2ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨éªŒè¯æ¡†æ¶ï¼Œç”¨äºç”ŸæˆUVMæµ‹è¯•å¹³å°å¹¶ä½¿ç”¨è¦†ç›–ç‡åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œåœ¨ä¿æŒä¸¥æ ¼éªŒè¯æ ‡å‡†çš„åŒæ—¶ï¼Œå¤§å¤§å‡å°‘æ‰‹åŠ¨å·¥ä½œé‡ã€‚ä¸ºäº†è¯„ä¼°UVM^2ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€å¥—åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å«é«˜è¾¾1600è¡Œä»£ç çš„å¯„å­˜å™¨ä¼ è¾“çº§ï¼ˆRTLï¼‰è®¾è®¡ã€‚ç»“æœè¡¨æ˜ï¼ŒUVM^2ä¸æ–°å·¥ç¨‹å¸ˆç›¸æ¯”ï¼Œå‡å°‘äº†æµ‹è¯•å¹³å°è®¾ç½®æ—¶é—´é«˜è¾¾UVM^2ç›¸æ¯”ç»éªŒä¸°å¯Œçš„å·¥ç¨‹å¸ˆçš„æƒ…å†µå¾…å®šè¿›ä¸€æ­¥ç¡®å®š)ï¼Œå¹¶å®ç°äº†å¹³å‡ä»£ç å’ŒåŠŸèƒ½è¦†ç›–ç‡åˆ†åˆ«ä¸º87.44%å’Œ89.58%ï¼Œä¼˜äºæœ€æ–°è§£å†³æ–¹æ¡ˆåˆ†åˆ«è¾¾20.96%å’Œ23.51%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19959v1">PDF</a> </p>
<p><strong>Summary</strong><br>é›†æˆç”µè·¯éªŒè¯æ˜¯å¼€å‘è¿‡ç¨‹ä¸­çš„ä¸»è¦ç“¶é¢ˆï¼Œæ¶ˆè€—è¿‘70%çš„å¼€å‘ç²¾åŠ›ã€‚ä¸ºæé«˜éªŒè¯æ•ˆç‡ï¼Œè¡Œä¸šä¸­å¹¿æ³›é‡‡ç”¨é€šç”¨éªŒè¯æ–¹æ³•è®ºï¼ˆUVMï¼‰ï¼Œä½†æ„å»ºæµ‹è¯•å¹³å°å’Œç”Ÿæˆè¶³å¤Ÿçš„æ¿€åŠ±ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚UVM^2æ˜¯ä¸€ç§æ–°å‹çš„è‡ªåŠ¨åŒ–éªŒè¯æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”ŸæˆUVMæµ‹è¯•å¹³å°ï¼Œå¹¶é€šè¿‡è¦†ç›–ç‡åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œæ˜¾è‘—å‡å°‘äººå·¥åŠªåŠ›çš„åŒæ—¶ä¿æŒä¸¥æ ¼çš„éªŒè¯æ ‡å‡†ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒUVM^2èƒ½å¤Ÿå‡å°‘æµ‹è¯•å¹³å°è®¾ç½®æ—¶é—´ï¼Œæé«˜ä»£ç å’ŒåŠŸèƒ½è¦†ç›–ç‡ï¼Œä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é›†æˆç”µè·¯éªŒè¯æ˜¯å¼€å‘çš„ä¸»è¦ç“¶é¢ˆï¼Œæ¶ˆè€—å¤§é‡æ—¶é—´å’Œèµ„æºã€‚</li>
<li>UVMå¹¿æ³›åº”ç”¨äºè¡Œä¸šä»¥æé«˜éªŒè¯æ•ˆç‡ï¼Œä½†æ„å»ºæµ‹è¯•å¹³å°å’Œç”Ÿæˆæ¿€åŠ±ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>UVM^2æ˜¯ä¸€ç§è‡ªåŠ¨åŒ–éªŒè¯æ¡†æ¶ï¼Œåˆ©ç”¨LLMç”ŸæˆUVMæµ‹è¯•å¹³å°ï¼Œé™ä½äººå·¥åŠªåŠ›ã€‚</li>
<li>UVM^2é€šè¿‡è¦†ç›–ç‡åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œä¿æŒä¸¥æ ¼çš„éªŒè¯æ ‡å‡†ã€‚</li>
<li>UVM^2èƒ½å¤Ÿå‡å°‘æµ‹è¯•å¹³å°è®¾ç½®æ—¶é—´ã€‚</li>
<li>UVM^2æé«˜ä»£ç å’ŒåŠŸèƒ½è¦†ç›–ç‡ï¼Œä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19959">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0c702425a1d2ce29b3d8c4c205a5cd3f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-187fc8ff03ab348441e99db00d0099ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-914d8a61990453f3a0479bbd39455891.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c7ca8b9a6b28e5e2c6a9188f5467a897.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b573dd2aafe3a744a7c7d1318d432acb.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Can-AI-Agents-Design-and-Implement-Drug-Discovery-Pipelines"><a href="#Can-AI-Agents-Design-and-Implement-Drug-Discovery-Pipelines" class="headerlink" title="Can AI Agents Design and Implement Drug Discovery Pipelines?"></a>Can AI Agents Design and Implement Drug Discovery Pipelines?</h2><p><strong>Authors:Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan</strong></p>
<p>The rapid advancement of artificial intelligence, particularly autonomous agentic systems based on Large Language Models (LLMs), presents new opportunities to accelerate drug discovery by improving in-silico modeling and reducing dependence on costly experimental trials. Current AI agent-based systems demonstrate proficiency in solving programming challenges and conducting research, indicating an emerging potential to develop software capable of addressing complex problems such as pharmaceutical design and drug discovery. This paper introduces DO Challenge, a benchmark designed to evaluate the decision-making abilities of AI agents in a single, complex problem resembling virtual screening scenarios. The benchmark challenges systems to independently develop, implement, and execute efficient strategies for identifying promising molecular structures from extensive datasets, while navigating chemical space, selecting models, and managing limited resources in a multi-objective context. We also discuss insights from the DO Challenge 2025, a competition based on the proposed benchmark, which showcased diverse strategies explored by human participants. Furthermore, we present the Deep Thought multi-agent system, which demonstrated strong performance on the benchmark, outperforming most human teams. Among the language models tested, Claude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles, and GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While promising, the systemâ€™s performance still fell short of expert-designed solutions and showed high instability, highlighting both the potential and current limitations of AI-driven methodologies in transforming drug discovery and broader scientific research. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•ï¼Œç‰¹åˆ«æ˜¯åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»ä»£ç†ç³»ç»Ÿï¼Œä¸ºé€šè¿‡æ”¹è¿›ç¡…å»ºæ¨¡å’Œå‡å°‘æ˜‚è´µå®éªŒè¯•ç‚¹çš„ä¾èµ–æ¥åŠ é€Ÿè¯ç‰©å‘ç°æä¾›äº†æ–°çš„æœºé‡ã€‚å½“å‰çš„åŸºäºAIä»£ç†çš„ç³»ç»Ÿåœ¨è§£å†³ç¼–ç¨‹æŒ‘æˆ˜å’Œç ”ç©¶æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè¿™è¡¨æ˜æœ‰æ½œåŠ›å¼€å‘èƒ½å¤Ÿè§£å†³è¯¸å¦‚è¯ç‰©è®¾è®¡å’Œè¯ç‰©å‘ç°ç­‰å¤æ‚é—®é¢˜çš„è½¯ä»¶ã€‚æœ¬æ–‡ä»‹ç»äº†DO Challengeï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°AIä»£ç†åœ¨ç±»ä¼¼äºè™šæ‹Ÿç­›é€‰åœºæ™¯çš„å•ä¸ªå¤æ‚é—®é¢˜ä¸­çš„å†³ç­–èƒ½åŠ›ã€‚è¯¥åŸºå‡†æµ‹è¯•æŒ‘æˆ˜ç³»ç»Ÿç‹¬ç«‹å¼€å‘ã€å®æ–½å’Œæ‰§è¡Œæœ‰æ•ˆç­–ç•¥ï¼Œä»å¤§é‡æ•°æ®é›†ä¸­è¯†åˆ«å‡ºæœ‰å‰æ™¯çš„åˆ†å­ç»“æ„ï¼ŒåŒæ—¶åœ¨åŒ–å­¦ç©ºé—´ä¸­è¿›è¡Œå¯¼èˆªã€é€‰æ‹©æ¨¡å‹ã€å¹¶åœ¨å¤šç›®æ ‡èƒŒæ™¯ä¸‹ç®¡ç†æœ‰é™èµ„æºã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†åŸºäºè¯¥åŸºå‡†æµ‹è¯•çš„DO Challenge 2025ç«èµ›çš„è§è§£ï¼Œè¯¥ç«èµ›å±•ç¤ºäº†äººç±»å‚ä¸è€…æ¢ç´¢çš„å¤šæ ·åŒ–ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†åœ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å¼ºå¤§çš„Deep Thoughtå¤šä»£ç†ç³»ç»Ÿï¼Œå®ƒåœ¨å¤§å¤šæ•°äººç±»å›¢é˜Ÿä¸­è¡¨ç°å‡ºè‰²ã€‚åœ¨æµ‹è¯•çš„è¯­è¨€æ¨¡å‹ä¸­ï¼ŒClaude 3.7 Sonnetã€Gemini 2.5 Proå’Œo3åœ¨ä¸»è¦ä»£ç†è§’è‰²ä¸­è¡¨ç°æœ€ä½³ï¼ŒGPT-4oå’ŒGemini 2.0 Flashåœ¨è¾…åŠ©è§’è‰²ä¸­æ•ˆæœæ˜¾è‘—ã€‚è™½ç„¶å¾ˆæœ‰å‰é€”ï¼Œä½†è¯¥ç³»ç»Ÿçš„æ€§èƒ½ä»ç„¶è½åäºä¸“å®¶è®¾è®¡çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶è¡¨ç°å‡ºé«˜åº¦çš„ä¸ç¨³å®šï¼Œè¿™çªå‡ºäº†äººå·¥æ™ºèƒ½é©±åŠ¨æ–¹æ³•åœ¨è¯ç‰©å‘ç°å’Œæ›´å¹¿æ³›çš„ç§‘å­¦ç ”ç©¶ä¸­çš„æ½œåŠ›å’Œå½“å‰å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19912v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>äººå·¥æ™ºèƒ½ç‰¹åˆ«æ˜¯åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»æ™ºèƒ½ç³»ç»Ÿçš„å¿«é€Ÿå‘å±•ï¼Œä¸ºåŠ é€Ÿè¯ç‰©å‘ç°æä¾›äº†æ–°çš„æœºé‡ã€‚é€šè¿‡æ”¹è¿›ç¡…å»ºæ¨¡å¹¶å‡å°‘å¯¹ä¼ ç»Ÿå®éªŒè¯•é”™çš„ä¾èµ–ï¼Œå½“å‰AIç³»ç»Ÿå±•ç°å‡ºè§£å†³ç¼–ç¨‹æŒ‘æˆ˜å’Œç ”ç©¶çš„èƒ½åŠ›ï¼Œæ˜¾ç¤ºäº†åœ¨è¯ç‰©å‘ç°å’Œæ›´å¹¿æ³›ç§‘å­¦ç ”ç©¶æ–¹é¢å¼€å‘è½¯ä»¶çš„æ½œåŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†DO Challengeè¿™ä¸€åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°AIç³»ç»Ÿåœ¨ç±»ä¼¼äºè™šæ‹Ÿç­›é€‰åœºæ™¯ä¸­çš„å†³ç­–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜è®¨è®ºäº†åŸºäºè¯¥åŸºå‡†æµ‹è¯•çš„DO Challenge 2025ç«èµ›çš„è§è§£ï¼Œä»¥åŠå±•ç¤ºå¼ºå¤§æ€§èƒ½çš„Deep Thoughtå¤šæ™ºèƒ½ç³»ç»Ÿã€‚ç„¶è€Œï¼Œå°½ç®¡æœ‰æ‰€è¿›æ­¥ï¼Œè¿™äº›ç³»ç»Ÿçš„æ€§èƒ½ä»ç„¶æœªèƒ½è¾¾åˆ°ä¸“å®¶è®¾è®¡çš„è§£å†³æ–¹æ¡ˆçš„æ°´å¹³ï¼Œå¹¶æ˜¾ç¤ºå‡ºé«˜ä¸ç¨³å®šæ€§ï¼Œçªæ˜¾äº†äººå·¥æ™ºèƒ½åœ¨è¯ç‰©å‘ç°ç­‰é¢†åŸŸå˜é©ä¸­çš„æ½œåŠ›å’Œå½“å‰å±€é™ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººå·¥æ™ºèƒ½çš„å‘å±•ä¸ºè¯ç‰©å‘ç°æä¾›äº†æ–°æœºé‡ï¼Œé€šè¿‡æ”¹è¿›ç¡…å»ºæ¨¡å’Œå‡å°‘ä¼ ç»Ÿå®éªŒè¯•é”™ä¾èµ–ï¼Œæé«˜è¯ç‰©å‘ç°çš„æ•ˆç‡ã€‚</li>
<li>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»æ™ºèƒ½ç³»ç»Ÿå±•ç°å‡ºè§£å†³ç¼–ç¨‹å’Œç ”ç©¶é—®é¢˜çš„èƒ½åŠ›ã€‚</li>
<li>DO Challengeæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIç³»ç»Ÿåœ¨ç±»ä¼¼äºè™šæ‹Ÿç­›é€‰åœºæ™¯ä¸­çš„å†³ç­–èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>Deep Thoughtå¤šæ™ºèƒ½ç³»ç»Ÿåœ¨DO ChallengeåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†æœªèƒ½è¾¾åˆ°ä¸“å®¶è®¾è®¡çš„è§£å†³æ–¹æ¡ˆæ°´å¹³ã€‚</li>
<li>AIç³»ç»Ÿçš„æ€§èƒ½ä»ç„¶é¢ä¸´ä¸ç¨³å®šæ€§å’Œå±€é™æ€§ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„ç ”ç©¶å’Œæ”¹è¿›ã€‚</li>
<li>AIåœ¨è¯ç‰©å‘ç°ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›å·¨å¤§ï¼Œä½†å®ç°è¿™ä¸€æ½œåŠ›éœ€è¦å…‹æœæŠ€æœ¯å’Œå®è·µä¸Šçš„æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19912">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c35280be3e8a260cd3c40dffdb8b9aca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8869e017075ed63a7e3a833b507cb85f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="semi-PD-Towards-Efficient-LLM-Serving-via-Phase-Wise-Disaggregated-Computation-and-Unified-Storage"><a href="#semi-PD-Towards-Efficient-LLM-Serving-via-Phase-Wise-Disaggregated-Computation-and-Unified-Storage" class="headerlink" title="semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated   Computation and Unified Storage"></a>semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated   Computation and Unified Storage</h2><p><strong>Authors:Ke Hong, Lufang Chen, Zhong Wang, Xiuhong Li, Qiuli Mao, Jianping Ma, Chao Xiong, Guanyu Wu, Buhe Han, Guohao Dai, Yun Liang, Yu Wang</strong></p>
<p>Existing large language model (LLM) serving systems fall into two categories: 1) a unified system where prefill phase and decode phase are co-located on the same GPU, sharing the unified computational resource and storage, and 2) a disaggregated system where the two phases are disaggregated to different GPUs. The design of the disaggregated system addresses the latency interference and sophisticated scheduling issues in the unified system but leads to storage challenges including 1) replicated weights for both phases that prevent flexible deployment, 2) KV cache transfer overhead between the two phases, 3) storage imbalance that causes substantial wasted space of the GPU capacity, and 4) suboptimal resource adjustment arising from the difficulties in migrating KV cache. Such storage inefficiency delivers poor serving performance under high request rates.   In this paper, we identify that the advantage of the disaggregated system lies in the disaggregated computation, i.e., partitioning the computational resource to enable the asynchronous computation of two phases. Thus, we propose a novel LLM serving system, semi-PD, characterized by disaggregated computation and unified storage. In semi-PD, we introduce a computation resource controller to achieve disaggregated computation at the streaming multi-processor (SM) level, and a unified memory manager to manage the asynchronous memory access from both phases. semi-PD has a low-overhead resource adjustment mechanism between the two phases, and a service-level objective (SLO) aware dynamic partitioning algorithm to optimize the SLO attainment. Compared to state-of-the-art systems, semi-PD maintains lower latency at higher request rates, reducing the average end-to-end latency per request by 1.27-2.58x on DeepSeek series models, and serves 1.55-1.72x more requests adhering to latency constraints on Llama series models. </p>
<blockquote>
<p>ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœåŠ¡ç³»ç»Ÿå¯åˆ†ä¸ºä¸¤ç±»ï¼š1ï¼‰ç»Ÿä¸€ç³»ç»Ÿï¼Œé¢„å¡«å……é˜¶æ®µå’Œè§£ç é˜¶æ®µä½äºåŒä¸€GPUä¸Šï¼Œå…±äº«ç»Ÿä¸€çš„è®¡ç®—èµ„æºå’Œå­˜å‚¨ï¼›2ï¼‰åˆ†æ•£ç³»ç»Ÿï¼Œä¸¤ä¸ªé˜¶æ®µåˆ†æ•£åˆ°ä¸åŒçš„GPUä¸Šã€‚åˆ†æ•£ç³»ç»Ÿçš„è®¾è®¡è§£å†³äº†ç»Ÿä¸€ç³»ç»Ÿä¸­å­˜åœ¨çš„å»¶è¿Ÿå¹²æ‰°å’Œå¤æ‚è°ƒåº¦é—®é¢˜ï¼Œä½†å¯¼è‡´äº†å­˜å‚¨æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬1ï¼‰ä¸¤ä¸ªé˜¶æ®µçš„æƒé‡å¤åˆ¶ï¼Œé˜²æ­¢çµæ´»éƒ¨ç½²ï¼›2ï¼‰ä¸¤ä¸ªé˜¶æ®µä¹‹é—´çš„KVç¼“å­˜ä¼ è¾“å¼€é”€ï¼›3ï¼‰å­˜å‚¨ä¸å¹³è¡¡å¯¼è‡´GPUå®¹é‡å¤§é‡æµªè´¹ï¼›4ï¼‰ç”±äºKVç¼“å­˜è¿ç§»å›°éš¾å¯¼è‡´çš„èµ„æºè°ƒæ•´ä¸ä½³ã€‚è¿™ç§å­˜å‚¨æ•ˆç‡ä½ä¸‹åœ¨é«˜è¯·æ±‚ç‡ä¸‹å¯¼è‡´æœåŠ¡æ€§èƒ½ä¸ä½³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19867v1">PDF</a> 18 pages, 16 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœåŠ¡ç³»ç»Ÿçš„ä¸¤ç±»è®¾è®¡ï¼šç»Ÿä¸€ç³»ç»Ÿå’Œåˆ†æ•£ç³»ç»Ÿã€‚ç»Ÿä¸€ç³»ç»Ÿå­˜åœ¨å»¶è¿Ÿå¹²æ‰°å’Œè°ƒåº¦é—®é¢˜ï¼Œè€Œåˆ†æ•£ç³»ç»Ÿè™½ç„¶è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œä½†å¸¦æ¥äº†å­˜å‚¨æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹LLMæœåŠ¡ç³»ç»Ÿâ€”â€”semi-PDï¼Œè¯¥ç³»ç»Ÿå…·æœ‰åˆ†æ•£è®¡ç®—å’Œç»Ÿä¸€å­˜å‚¨çš„ç‰¹ç‚¹ã€‚é€šè¿‡å¼•å…¥è®¡ç®—èµ„æºæ§åˆ¶å™¨å’Œç»Ÿä¸€å†…å­˜ç®¡ç†å™¨ï¼Œsemi-PDå®ç°äº†è¾ƒä½çš„è°ƒæ•´æœºåˆ¶å¼€é”€å’Œä¼˜åŒ–çš„æœåŠ¡ç›®æ ‡è¾¾æˆã€‚ç›¸è¾ƒäºç°æœ‰ç³»ç»Ÿï¼Œsemi-PDåœ¨è¾ƒé«˜è¯·æ±‚ç‡ä¸‹ç»´æŒè¾ƒä½å»¶è¿Ÿï¼Œå‡å°‘äº†DeepSeekç³»åˆ—æ¨¡å‹çš„å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿè¯·æ±‚æ—¶é—´è¾¾1.27-2.58å€ï¼Œå¹¶åœ¨Llamaç³»åˆ—æ¨¡å‹ä¸ŠæœåŠ¡äº†æ›´å¤šæ»¡è¶³å»¶è¿Ÿçº¦æŸçš„è¯·æ±‚ï¼Œæå‡äº†æœåŠ¡æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹æœåŠ¡ç³»ç»Ÿåˆ†ä¸ºç»Ÿä¸€å’Œåˆ†æ•£ä¸¤ç±»è®¾è®¡ï¼Œå„æœ‰ä¼˜ç¼ºç‚¹ã€‚</li>
<li>åˆ†æ•£ç³»ç»Ÿè®¾è®¡è§£å†³äº†ç»Ÿä¸€ç³»ç»Ÿä¸­çš„å»¶è¿Ÿå¹²æ‰°å’Œè°ƒåº¦é—®é¢˜ã€‚</li>
<li>åˆ†æ•£ç³»ç»Ÿå­˜åœ¨å­˜å‚¨æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æƒé‡å¤åˆ¶ã€ç¼“å­˜è½¬ç§»å¼€é”€ã€å­˜å‚¨ä¸å¹³è¡¡å’Œèµ„æºè°ƒæ•´å›°éš¾ç­‰é—®é¢˜ã€‚</li>
<li>proposedçš„semi-PDç³»ç»Ÿç»“åˆäº†åˆ†æ•£è®¡ç®—å’Œç»Ÿä¸€å­˜å‚¨çš„ç‰¹ç‚¹ï¼Œé€šè¿‡è®¡ç®—èµ„æºæ§åˆ¶å™¨å’Œç»Ÿä¸€å†…å­˜ç®¡ç†å™¨å®ç°é«˜æ•ˆæ€§èƒ½ã€‚</li>
<li>semi-PDå…·æœ‰ä½å¼€é”€çš„èµ„æºè°ƒæ•´æœºåˆ¶ï¼Œå¹¶é‡‡ç”¨äº†æœåŠ¡ç›®æ ‡æ„ŸçŸ¥çš„åŠ¨æ€åˆ†åŒºç®—æ³•è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>ä¸ç°æœ‰ç³»ç»Ÿç›¸æ¯”ï¼Œsemi-PDåœ¨è¯·æ±‚ç‡é«˜æ—¶ç»´æŒè¾ƒä½å»¶è¿Ÿï¼Œå¯¹DeepSeekç³»åˆ—æ¨¡å‹å’ŒLlamaç³»åˆ—æ¨¡å‹çš„æ€§èƒ½æå‡æ˜¾è‘—ã€‚</li>
<li>semi-PDä¸ºå¤§å‹è¯­è¨€æ¨¡å‹æœåŠ¡æä¾›äº†ä¸€ç§æ–°çš„é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19867">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dbf6d629495b2de63a28ed6126eac328.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f809b26b64bee7d7011fbd2bb917c9f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa1946d3a65927a054f3780ebf7420d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-01d08f5e1879802d62f6a08a6f671a44.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ce38250a56d5ab0a49c68da134023da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-32a0a60aba2dcf59a695edea839999fc.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CoherenDream-Boosting-Holistic-Text-Coherence-in-3D-Generation-via-Multimodal-Large-Language-Models-Feedback"><a href="#CoherenDream-Boosting-Holistic-Text-Coherence-in-3D-Generation-via-Multimodal-Large-Language-Models-Feedback" class="headerlink" title="CoherenDream: Boosting Holistic Text Coherence in 3D Generation via   Multimodal Large Language Models Feedback"></a>CoherenDream: Boosting Holistic Text Coherence in 3D Generation via   Multimodal Large Language Models Feedback</h2><p><strong>Authors:Chenhan Jiang, Yihan Zeng, Hang Xu, Dit-Yan Yeung</strong></p>
<p>Score Distillation Sampling (SDS) has achieved remarkable success in text-to-3D content generation. However, SDS-based methods struggle to maintain semantic fidelity for user prompts, particularly when involving multiple objects with intricate interactions. While existing approaches often address 3D consistency through multiview diffusion model fine-tuning on 3D datasets, this strategy inadvertently exacerbates text-3D alignment degradation. The limitation stems from SDSâ€™s inherent accumulation of view-independent biases during optimization, which progressively diverges from the ideal text alignment direction. To alleviate this limitation, we propose a novel SDS objective, dubbed as Textual Coherent Score Distillation (TCSD), which integrates alignment feedback from multimodal large language models (MLLMs). Our TCSD leverages cross-modal understanding capabilities of MLLMs to assess and guide the text-3D correspondence during the optimization. We further develop 3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text alignment in 3D generations. Additionally, we introduce an LLM-layout initialization that significantly accelerates optimization convergence through semantic-aware spatial configuration. Comprehensive evaluations demonstrate that our framework, CoherenDream, establishes state-of-the-art performance in text-aligned 3D generation across multiple benchmarks, including T$^3$Bench and TIFA subset. Qualitative results showcase the superior performance of CoherenDream in preserving textual consistency and semantic interactions. As the first study to incorporate MLLMs into SDS optimization, we also conduct extensive ablation studies to explore optimal MLLM adaptations for 3D generation tasks. </p>
<blockquote>
<p>Score Distillation Sampling (SDS)åœ¨æ–‡æœ¬åˆ°3Då†…å®¹ç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼ŒåŸºäºSDSçš„æ–¹æ³•åœ¨ä¿æŒç”¨æˆ·æç¤ºçš„è¯­ä¹‰ä¿çœŸæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤šä¸ªå…·æœ‰å¤æ‚äº¤äº’çš„å¯¹è±¡æ—¶ã€‚è™½ç„¶ç°æœ‰çš„æ–¹æ³•é€šå¸¸é€šè¿‡3Dæ•°æ®é›†ä¸Šçš„å¤šè§†è§’æ‰©æ•£æ¨¡å‹å¾®è°ƒæ¥è§£å†³3Dä¸€è‡´æ€§ï¼Œä½†è¿™ç§ç­–ç•¥å´æ— æ„ä¸­åŠ å‰§äº†æ–‡æœ¬åˆ°3Dçš„å¯¹é½é€€åŒ–ã€‚è¿™ä¸€å±€é™æ€§æºäºSDSåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å›ºæœ‰çš„ç§¯ç´¯ä¸è§†å›¾æ— å…³çš„åè§ï¼Œè¿™äº›åè§é€æ¸åç¦»ç†æƒ³çš„æ–‡æœ¬å¯¹é½æ–¹å‘ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„SDSç›®æ ‡ï¼Œç§°ä¸ºæ–‡æœ¬ä¸€è‡´å¾—åˆ†è’¸é¦ï¼ˆTCSDï¼‰ï¼Œå®ƒç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å¯¹é½åé¦ˆã€‚æˆ‘ä»¬çš„TCSDåˆ©ç”¨MLLMsçš„è·¨æ¨¡æ€ç†è§£èƒ½åŠ›æ¥è¯„ä¼°å’Œå¼•å¯¼ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„æ–‡æœ¬åˆ°3Dçš„å¯¹åº”å…³ç³»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸“é—¨ç”¨äºè¯„ä¼°3Dç”Ÿæˆä¸­å¤šè§†è§’æ–‡æœ¬å¯¹é½çš„ç²¾ç»†è°ƒæ•´MLLMâ€”â€”3DLLaVA-CRITICã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†LLMå¸ƒå±€åˆå§‹åŒ–ï¼Œé€šè¿‡è¯­ä¹‰æ„ŸçŸ¥çš„ç©ºé—´é…ç½®æ˜¾è‘—åŠ é€Ÿäº†ä¼˜åŒ–çš„æ”¶æ•›ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶CoherenDreamåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ–‡æœ¬å¯¹é½3Dç”Ÿæˆæ€§èƒ½ï¼ŒåŒ…æ‹¬T$^3$Benchå’ŒTIFAå­é›†ã€‚å®šæ€§çš„ç»“æœå±•ç¤ºäº†CoherenDreamåœ¨ä¿æŒæ–‡æœ¬ä¸€è‡´æ€§å’Œè¯­ä¹‰äº¤äº’æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚ä½œä¸ºå°†MLLMsçº³å…¥SDSä¼˜åŒ–çš„é¦–é¡¹ç ”ç©¶ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèç ”ç©¶ï¼Œä»¥æ¢ç´¢é€‚ç”¨äº3Dç”Ÿæˆä»»åŠ¡çš„æœ€ä½³MLLMé€‚åº”æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19860v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Score Distillation Samplingï¼ˆSDSï¼‰åœ¨æ–‡æœ¬åˆ°3Då†…å®¹ç”Ÿæˆä¸­çš„æˆåŠŸåº”ç”¨ï¼Œä½†SDSåœ¨å¤„ç†æ¶‰åŠå¤šä¸ªç‰©ä½“å¤æ‚äº¤äº’çš„ç”¨æˆ·æç¤ºæ—¶éš¾ä»¥ä¿æŒè¯­ä¹‰ä¿çœŸåº¦çš„é—®é¢˜ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†åä¸ºTextual Coherent Score Distillationï¼ˆTCSDï¼‰çš„æ–°å‹SDSç›®æ ‡ï¼Œé€šè¿‡åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è·¨æ¨¡æ€ç†è§£èƒ½åŠ›æ¥è¯„ä¼°å’ŒæŒ‡å¯¼æ–‡æœ¬åˆ°3Dçš„å¯¹åº”å…³ç³»ã€‚åŒæ—¶å¼€å‘äº†ä¸“é—¨ç”¨äºè¯„ä¼°3Dç”Ÿæˆä¸­æ–‡æœ¬å¯¹é½çš„å¤šè§†å›¾è¯„ä¼°çš„MLLM 3DLLaVA-CRITICï¼Œå¹¶å¼•å…¥äº†LLMå¸ƒå±€åˆå§‹åŒ–ï¼Œæ˜¾è‘—åŠ é€Ÿäº†ä¼˜åŒ–æ”¶æ•›ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒCoherenDreamæ¡†æ¶åœ¨æ–‡æœ¬å¯¹é½çš„3Dç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SDSåœ¨æ–‡æœ¬åˆ°3Då†…å®¹ç”Ÿæˆä¸­è¡¨ç°ä¼˜ç§€ï¼Œä½†åœ¨å¤„ç†å¤æ‚äº¤äº’çš„å¤šç‰©ä½“æç¤ºæ—¶å­˜åœ¨è¯­ä¹‰å¤±çœŸé—®é¢˜ã€‚</li>
<li>æå‡ºTCSDæ–¹æ³•ï¼Œåˆ©ç”¨MLLMsçš„è·¨æ¨¡æ€ç†è§£èƒ½åŠ›æ¥ä¼˜åŒ–SDSï¼Œæé«˜æ–‡æœ¬åˆ°3Dçš„å¯¹åº”å…³ç³»ã€‚</li>
<li>å¼€å‘ä¸“é—¨ç”¨äºè¯„ä¼°å¤šè§†å›¾æ–‡æœ¬å¯¹é½çš„MLLM 3DLLaVA-CRITICã€‚</li>
<li>å¼•å…¥LLMå¸ƒå±€åˆå§‹åŒ–ï¼ŒåŠ é€Ÿä¼˜åŒ–æ”¶æ•›ã€‚</li>
<li>CoherenDreamæ¡†æ¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨æ–‡æœ¬å¯¹é½çš„3Dç”Ÿæˆæ–¹é¢ã€‚</li>
<li>CoherenDreamèƒ½å¾ˆå¥½åœ°ä¿æŒæ–‡æœ¬ä¸€è‡´æ€§å’Œè¯­ä¹‰äº¤äº’æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19860">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e6d5570006a2c732037ee15c19df46a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b29b5bfc73e292286c9c6245f773aac7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e692691535c7f3756e3a0c9351a5083e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2aacc59c91a05f636665330cca803bf.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Can-a-Crow-Hatch-a-Falcon-Lineage-Matters-in-Predicting-Large-Language-Model-Performance"><a href="#Can-a-Crow-Hatch-a-Falcon-Lineage-Matters-in-Predicting-Large-Language-Model-Performance" class="headerlink" title="Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language   Model Performance"></a>Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language   Model Performance</h2><p><strong>Authors:Takuya Tamura, Taro Yano, Masafumi Enomoto, Masafumi Oyamada</strong></p>
<p>Accurately forecasting the performance of Large Language Models (LLMs) before extensive fine-tuning or merging can substantially reduce both computational expense and development time. Although prior approaches like scaling laws account for global factors such as parameter size or training tokens, they often overlook explicit lineage relationships - i.e., which models are derived or merged from which parents. In this work, we propose a novel Lineage-Regularized Matrix Factorization (LRMF) framework that encodes ancestral ties among LLMs via a graph Laplacian regularizer. By leveraging multi-hop parent-child connections, LRMF consistently outperforms conventional matrix factorization and collaborative filtering methods in both instance-level and benchmark-level performance prediction. Our large-scale study includes 2,934 publicly available Hugging Face models and 21,000+ instances across 6 major benchmarks, showing that lineage constraints yield up to 7-10 percentage points higher correlation with actual performance compared to baselines. Moreover, LRMF effectively addresses the cold-start problem, providing accurate estimates for newly derived or merged models even with minimal data. This lineage-guided strategy thus offers a resource-efficient way to inform hyperparameter tuning, data selection, and model combination in modern LLM development. </p>
<blockquote>
<p>ç²¾ç¡®é¢„æµ‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤§é‡å¾®è°ƒæˆ–åˆå¹¶ä¹‹å‰çš„æ€§èƒ½ï¼Œå¯ä»¥å¤§å¤§é™ä½è®¡ç®—æˆæœ¬å¹¶ç¼©çŸ­å¼€å‘æ—¶é—´ã€‚å°½ç®¡å…ˆå‰çš„æ–¹æ³•ï¼Œå¦‚è§„æ¨¡å®šå¾‹ï¼Œè€ƒè™‘äº†å…¨å±€å› ç´ ï¼Œå¦‚å‚æ•°å¤§å°æˆ–è®­ç»ƒä»¤ç‰Œï¼Œä½†å®ƒä»¬å¾€å¾€å¿½ç•¥äº†æ˜ç¡®çš„è¡€ç»Ÿå…³ç³»ï¼Œå³å“ªäº›æ¨¡å‹æ˜¯ä»å“ªäº›çˆ¶æ¨¡å‹ä¸­è¡ç”Ÿæˆ–åˆå¹¶è€Œæ¥çš„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºè¡€ç»Ÿçš„æ­£åˆ™åŒ–çŸ©é˜µåˆ†è§£ï¼ˆLRMFï¼‰æ¡†æ¶ï¼Œå®ƒé€šè¿‡å›¾æ‹‰æ™®æ‹‰æ–¯æ­£åˆ™å™¨å¯¹LLMä¹‹é—´çš„ç¥–ä»£å…³ç³»è¿›è¡Œç¼–ç ã€‚é€šè¿‡åˆ©ç”¨å¤šè·³çˆ¶å­è¿æ¥ï¼ŒLRMFåœ¨å®ä¾‹çº§åˆ«å’ŒåŸºå‡†æµ‹è¯•çº§åˆ«æ€§èƒ½é¢„æµ‹æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„çŸ©é˜µåˆ†è§£å’ŒååŒè¿‡æ»¤æ–¹æ³•ã€‚æˆ‘ä»¬çš„å¤§è§„æ¨¡ç ”ç©¶åŒ…æ‹¬Hugging Faceçš„2934ä¸ªå…¬å¼€æ¨¡å‹å’Œè¶…è¿‡2ä¸‡å¤šä¸ªå®ä¾‹çš„å…­å¤§åŸºå‡†æµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œè¡€ç»Ÿçº¦æŸä¸å®é™…æ€§èƒ½çš„ç›¸å…³æ€§é«˜å‡ºé«˜è¾¾7-10ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼ŒLRMFæœ‰æ•ˆåœ°è§£å†³äº†å†·å¯åŠ¨é—®é¢˜ï¼Œå³ä½¿æ•°æ®å¾ˆå°‘ï¼Œä¹Ÿèƒ½ä¸ºæ–°è¡ç”Ÿæˆ–åˆå¹¶çš„æ¨¡å‹æä¾›å‡†ç¡®çš„ä¼°ç®—ã€‚å› æ­¤ï¼Œè¿™ç§è¡€ç»Ÿå¼•å¯¼çš„ç­–ç•¥ä¸ºç°ä»£LLMå¼€å‘ä¸­çš„è¶…å‚æ•°è°ƒæ•´ã€æ•°æ®é€‰æ‹©å’Œæ¨¡å‹ç»„åˆæä¾›äº†ä¸€ç§èµ„æºé«˜æ•ˆçš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19811v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½é¢„æµ‹å¯¹äºå‡å°‘è®¡ç®—æˆæœ¬å’Œå¼€å‘æ—¶é—´è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ–°å‹çš„Lineage-Regularized Matrix Factorizationï¼ˆLRMFï¼‰æ¡†æ¶ï¼Œé€šè¿‡å›¾æ‹‰æ™®æ‹‰æ–¯æ­£åˆ™åŒ–å™¨ç¼–ç LLMä¹‹é—´çš„ç¥–ä»£å…³ç³»ï¼Œåœ¨å®ä¾‹çº§åˆ«å’ŒåŸºå‡†æµ‹è¯•çº§åˆ«æ€§èƒ½é¢„æµ‹æ–¹é¢ï¼ŒLRMFè¡¨ç°ä¼˜äºä¼ ç»Ÿçš„çŸ©é˜µåˆ†è§£å’ŒååŒè¿‡æ»¤æ–¹æ³•ã€‚å¤§è§„æ¨¡ç ”ç©¶æ˜¾ç¤ºï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œç¥–ä»£çº¦æŸä¸å®é™…æ€§èƒ½çš„ç›¸å…³æ€§æœ€é«˜å¯æé«˜7-10ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼ŒLRMFæœ‰æ•ˆè§£å†³å†·å¯åŠ¨é—®é¢˜ï¼Œå³ä½¿æ•°æ®æœ€å°‘çš„æ–°è¡ç”Ÿæˆ–åˆå¹¶æ¨¡å‹ä¹Ÿèƒ½æä¾›å‡†ç¡®çš„ä¼°è®¡ã€‚è¿™ç§ä»¥ç¥–ä»£å…³ç³»ä¸ºæŒ‡å¯¼çš„ç­–ç•¥ä¸ºç°ä»£LLMå¼€å‘ä¸­ç”¨äºè°ƒæ•´è¶…å‚æ•°ã€æ•°æ®é€‰æ‹©å’Œæ¨¡å‹ç»„åˆæä¾›äº†ä¸€ç§èµ„æºé«˜æ•ˆçš„æ–¹å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMæ€§èƒ½é¢„æµ‹èƒ½å‡å°‘è®¡ç®—æˆæœ¬ä¸å¼€å‘æ—¶é—´ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¿½ç•¥LLMçš„ç¥–ä»£å…³ç³»ã€‚</li>
<li>LRMFæ¡†æ¶é€šè¿‡å›¾æ‹‰æ™®æ‹‰æ–¯æ­£åˆ™åŒ–å™¨ç¼–ç LLMçš„ç¥–ä»£å…³ç³»ã€‚</li>
<li>LRMFåœ¨æ€§èƒ½é¢„æµ‹æ–¹é¢è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</li>
<li>ç¥–ä»£çº¦æŸä¸å®é™…æ€§èƒ½çš„ç›¸å…³æ€§é«˜äºåŸºçº¿ã€‚</li>
<li>LRMFèƒ½è§£å†³å†·å¯åŠ¨é—®é¢˜ï¼Œå¯¹æ–°å…´æ¨¡å‹æä¾›å‡†ç¡®ä¼°è®¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19811">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f8436c0d033b779399295158dbcfc38a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Transformer-Empowered-Actor-Critic-Reinforcement-Learning-for-Sequence-Aware-Service-Function-Chain-Partitioning"><a href="#Transformer-Empowered-Actor-Critic-Reinforcement-Learning-for-Sequence-Aware-Service-Function-Chain-Partitioning" class="headerlink" title="Transformer-Empowered Actor-Critic Reinforcement Learning for   Sequence-Aware Service Function Chain Partitioning"></a>Transformer-Empowered Actor-Critic Reinforcement Learning for   Sequence-Aware Service Function Chain Partitioning</h2><p><strong>Authors:Cyril Shih-Huan Hsu, Anestis Dalgkitsis, Chrysa Papagianni, Paola Grosso</strong></p>
<p>In the forthcoming era of 6G networks, characterized by unprecedented data rates, ultra-low latency, and extensive connectivity, effective management of Virtualized Network Functions (VNFs) is essential. VNFs are software-based counterparts of traditional hardware devices that facilitate flexible and scalable service provisioning. Service Function Chains (SFCs), structured as ordered sequences of VNFs, are pivotal in orchestrating complex network services. Nevertheless, partitioning SFCs across multi-domain network infrastructures presents substantial challenges due to stringent latency constraints and limited resource availability. Conventional optimization-based methods typically exhibit low scalability, whereas existing data-driven approaches often fail to adequately balance computational efficiency with the capability to effectively account for dependencies inherent in SFCs. To overcome these limitations, we introduce a Transformer-empowered actor-critic framework specifically designed for sequence-aware SFC partitioning. By utilizing the self-attention mechanism, our approach effectively models complex inter-dependencies among VNFs, facilitating coordinated and parallelized decision-making processes. Additionally, we enhance training stability and convergence using $\epsilon$-LoPe exploration strategy as well as Asymptotic Return Normalization. Comprehensive simulation results demonstrate that the proposed methodology outperforms existing state-of-the-art solutions in terms of long-term acceptance rates, resource utilization efficiency, and scalability, while achieving rapid inference. This study not only advances intelligent network orchestration by delivering a scalable and robust solution for SFC partitioning within emerging 6G environments, but also bridging recent advancements in Large Language Models (LLMs) with the optimization of next-generation networks. </p>
<blockquote>
<p>åœ¨å³å°†åˆ°æ¥çš„6Gç½‘ç»œæ—¶ä»£ï¼Œä»¥å…¶å‰æ‰€æœªæœ‰çš„æ•°æ®é€Ÿç‡ã€è¶…ä½å»¶è¿Ÿå’Œå¹¿æ³›è¿æ¥ä¸ºç‰¹ç‚¹ï¼Œå¯¹è™šæ‹ŸåŒ–ç½‘ç»œåŠŸèƒ½ï¼ˆVNFsï¼‰çš„æœ‰æ•ˆç®¡ç†è‡³å…³é‡è¦ã€‚VNFsæ˜¯ä¼ ç»Ÿç¡¬ä»¶è®¾å¤‡çš„è½¯ä»¶å¯¹åº”ç‰©ï¼Œæœ‰åŠ©äºçµæ´»å’Œå¯æ‰©å±•çš„æœåŠ¡æä¾›ã€‚ä½œä¸ºVNFsæœ‰åºåºåˆ—çš„æœåŠ¡åŠŸèƒ½é“¾ï¼ˆSFCsï¼‰åœ¨åè°ƒå¤æ‚ç½‘ç»œæœåŠ¡æ–¹é¢è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨å¤šåŸŸç½‘ç»œåŸºç¡€è®¾æ–½ä¸­åˆ’åˆ†SFCsé¢ä¸´ç€ä¸¥å³»çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå­˜åœ¨ä¸¥æ ¼çš„å»¶è¿Ÿçº¦æŸå’Œèµ„æºå¯ç”¨æ€§æœ‰é™ã€‚ä¼ ç»Ÿçš„ä¼˜åŒ–æ–¹æ³•é€šå¸¸å¯æ‰©å±•æ€§è¾ƒä½ï¼Œè€Œç°æœ‰çš„æ•°æ®é©±åŠ¨æ–¹æ³•å¾€å¾€ä¸èƒ½å¾ˆå¥½åœ°å¹³è¡¡è®¡ç®—æ•ˆç‡å’ŒæœåŠ¡åŠŸèƒ½é“¾å›ºæœ‰ä¾èµ–æ€§çš„è€ƒè™‘èƒ½åŠ›ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç”±Transformerèµ‹èƒ½çš„è¡Œä¸ºæ‰¹åˆ¤æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸“ä¸ºåºåˆ—æ„ŸçŸ¥SFCåˆ’åˆ†è€Œè®¾è®¡ã€‚é€šè¿‡åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°å»ºæ¨¡äº†VNFä¹‹é—´çš„å¤æ‚ç›¸äº’ä¾èµ–æ€§ï¼Œä¿ƒè¿›äº†åè°ƒå’Œå¹¶è¡ŒåŒ–çš„å†³ç­–è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨Îµ-LoPeæ¢ç´¢ç­–ç•¥å’Œæ¸è¿‘è¿”å›å½’ä¸€åŒ–å¢å¼ºäº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚ç»¼åˆä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨é•¿æœŸæ¥å—ç‡ã€èµ„æºåˆ©ç”¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶å®ç°äº†å¿«é€Ÿæ¨ç†ã€‚æœ¬ç ”ç©¶ä¸ä»…é€šè¿‡ä¸ºæ–°å…´6Gç¯å¢ƒä¸­çš„SFCåˆ’åˆ†æä¾›å¯ä¼¸ç¼©å’Œç¨³å¥çš„è§£å†³æ–¹æ¡ˆæ¥æ¨åŠ¨æ™ºèƒ½ç½‘ç»œç¼–æ’çš„å‘å±•ï¼Œè€Œä¸”è¿˜å¼¥åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä¸ä¸‹ä¸€ä»£ç½‘ç»œçš„ä¼˜åŒ–ä¹‹é—´çš„é¸¿æ²Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18902v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨å³å°†åˆ°æ¥çš„6Gç½‘ç»œæ—¶ä»£ï¼Œä»¥å…¶å‰æ‰€æœªæœ‰çš„æ•°æ®é€Ÿç‡ã€è¶…ä½å»¶è¿Ÿå’Œå¹¿æ³›è¿æ¥æ€§ä¸ºç‰¹å¾ï¼Œå¯¹è™šæ‹ŸåŒ–ç½‘ç»œåŠŸèƒ½ï¼ˆVNFsï¼‰çš„æœ‰æ•ˆç®¡ç†è‡³å…³é‡è¦ã€‚VNFsä½œä¸ºä¼ ç»Ÿç¡¬ä»¶è®¾å¤‡çš„è½¯ä»¶å¯¹åº”ç‰©ï¼Œä¿ƒè¿›äº†çµæ´»å’Œå¯ä¼¸ç¼©çš„æœåŠ¡æä¾›ã€‚æœåŠ¡å‡½æ•°é“¾ï¼ˆSFCsï¼‰ä½œä¸ºVNFsçš„æœ‰åºåºåˆ—ç»“æ„ï¼Œå¯¹äºåè°ƒå¤æ‚ç½‘ç»œæœåŠ¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨è·¨å¤šåŸŸç½‘ç»œåŸºç¡€è®¾æ–½çš„SFCåˆ†åŒºé¢ä¸´ç€ä¸¥å³»çš„å»¶è¿Ÿçº¦æŸå’Œæœ‰é™çš„èµ„æºå¯ç”¨æ€§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºTransformerçš„actor-criticæ¡†æ¶ï¼Œä¸“ä¸ºåºåˆ—æ„ŸçŸ¥SFCåˆ†åŒºè®¾è®¡ã€‚é€šè¿‡åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°å»ºæ¨¡äº†VNFä¹‹é—´çš„å¤æ‚ç›¸äº’ä¾èµ–æ€§ï¼Œä¿ƒè¿›äº†åè°ƒå’Œå¹¶è¡ŒåŒ–çš„å†³ç­–è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨Îµ-LoPeæ¢ç´¢ç­–ç•¥å’Œæ¸è¿‘å›æŠ¥å½’ä¸€åŒ–å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚ç»¼åˆä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨é•¿æœŸæ¥å—ç‡ã€èµ„æºåˆ©ç”¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶å®ç°äº†å¿«é€Ÿæ¨ç†ã€‚æœ¬ç ”ç©¶ä¸ä»…é€šè¿‡ä¸ºæ–°å…´6Gç¯å¢ƒä¸­çš„SFCåˆ†åŒºæä¾›å¯æ‰©å±•å’Œç¨³å¥çš„è§£å†³æ–¹æ¡ˆæ¥æ¨åŠ¨æ™ºèƒ½ç½‘ç»œç¼–æ’çš„è¿›å±•ï¼Œè€Œä¸”è¿˜å¼¥åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä¸ä¸‹ä¸€ä»£ç½‘ç»œçš„ä¼˜åŒ–ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>6Gç½‘ç»œæ—¶ä»£éœ€è¦æœ‰æ•ˆç®¡ç†è™šæ‹ŸåŒ–ç½‘ç»œåŠŸèƒ½ï¼ˆVNFsï¼‰ï¼Œä»¥ä¿ƒè¿›çµæ´»å’Œå¯ä¼¸ç¼©çš„æœåŠ¡æä¾›ã€‚</li>
<li>æœåŠ¡å‡½æ•°é“¾ï¼ˆSFCsï¼‰åœ¨åè°ƒå¤æ‚ç½‘ç»œæœåŠ¡ä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œä½†åœ¨å¤šåŸŸç½‘ç»œåŸºç¡€è®¾æ–½ä¸­çš„åˆ†åŒºé¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤„ç†SFCåˆ†åŒºæ—¶å­˜åœ¨å±€é™æ€§ï¼Œå¦‚ä½å¯æ‰©å±•æ€§æˆ–ç¼ºä¹è®¡ç®—æ•ˆç‡å’Œå†…åœ¨ä¾èµ–æ€§çš„å¹³è¡¡ã€‚</li>
<li>å¼•å…¥åŸºäºTransformerçš„actor-criticæ¡†æ¶ï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆå»ºæ¨¡VNFé—´çš„å¤æ‚ä¾èµ–æ€§ã€‚</li>
<li>ä½¿ç”¨Îµ-LoPeæ¢ç´¢ç­–ç•¥å’Œæ¸è¿‘å›æŠ¥å½’ä¸€åŒ–å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚</li>
<li>ç»¼åˆä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºæ–¹æ³•åœ¨é•¿æœŸæ¥å—ç‡ã€èµ„æºåˆ©ç”¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶ä¸ä»…æ¨åŠ¨äº†æ™ºèƒ½ç½‘ç»œç¼–æ’çš„è¿›å±•ï¼Œè¿˜å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ä¸‹ä¸€ä»£ç½‘ç»œä¼˜åŒ–ç›¸ç»“åˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18902">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f11fce0ce06b2c2b706617f1ef396ccf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-35341051e3ba9107285835ebe30b26f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-492ea3f1650fd5dcb128c647f76099ea.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Parameter-Efficient-Checkpoint-Merging-via-Metrics-Weighted-Averaging"><a href="#Parameter-Efficient-Checkpoint-Merging-via-Metrics-Weighted-Averaging" class="headerlink" title="Parameter-Efficient Checkpoint Merging via Metrics-Weighted Averaging"></a>Parameter-Efficient Checkpoint Merging via Metrics-Weighted Averaging</h2><p><strong>Authors:Shi Jie Yu, Sehyun Choi</strong></p>
<p>Checkpoint merging is a technique for combining multiple model snapshots into a single superior model, potentially reducing training time for large language models. This paper explores checkpoint merging in the context of parameter-efficient fine-tuning (PEFT), where only small adapter modules (e.g. LoRA) are trained. We propose Metrics-Weighted Averaging (MWA), a simple yet effective method to merge model checkpoints by weighting their parameters according to performance metrics. In particular, we investigate weighting by training loss and by training steps, under the intuition that lower-loss or later-step checkpoints are more valuable. We introduce a formula with a penalty factor to adjust weight distribution, requiring only one hyperparameter regardless of the number of checkpoints. Experiments on three fine-tuning tasks (mathematical reasoning, preference alignment, and general instruction tuning) show that MWA consistently produces merged models that outperform the naive uniform average of checkpoints. Notably, loss-weighted merging often yields the best results, delivering up to 5% higher task accuracy than the baseline uniform merge and even surpassing the final individual checkpointâ€™s performance. These findings validate checkpoint merging for PEFT and demonstrate that a metric-driven weighting heuristic can efficiently boost model performance with minimal computational overhead. </p>
<blockquote>
<p>æ¨¡å‹æ£€æŸ¥ç‚¹åˆå¹¶æ˜¯ä¸€ç§å°†å¤šä¸ªæ¨¡å‹å¿«ç…§åˆå¹¶ä¸ºä¸€ä¸ªæ›´é«˜çº§æ¨¡å‹çš„æŠ€æœ¯ï¼Œå¯æ½œåœ¨åœ°å‡å°‘å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ—¶é—´ã€‚æœ¬æ–‡é’ˆå¯¹å‚æ•°æœ‰æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰çš„ä¸Šä¸‹æ–‡ä¸­çš„æ£€æŸ¥ç‚¹åˆå¹¶è¿›è¡Œäº†æ¢è®¨ï¼Œå…¶ä¸­åªè®­ç»ƒäº†å°å‹çš„é€‚é…æ¨¡å—ï¼ˆä¾‹å¦‚LoRAï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†Metric Weighted Averagingï¼ˆMWAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œé€šè¿‡æ ¹æ®æ€§èƒ½æŒ‡æ ‡å¯¹æ¨¡å‹æ£€æŸ¥ç‚¹çš„å‚æ•°è¿›è¡ŒåŠ æƒæ¥å®ç°åˆå¹¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æ ¹æ®è®­ç»ƒæŸå¤±å’Œè®­ç»ƒæ­¥éª¤è¿›è¡ŒåŠ æƒï¼Œç›´è§‰ä¸Šè®¤ä¸ºæŸå¤±è¾ƒä½æˆ–æ­¥éª¤è¾ƒåçš„æ£€æŸ¥ç‚¹æ›´æœ‰ä»·å€¼ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¸¦æœ‰æƒ©ç½šå› å­çš„å…¬å¼æ¥è°ƒæ•´æƒé‡åˆ†å¸ƒï¼Œæ— è®ºæ£€æŸ¥ç‚¹çš„æ•°é‡å¦‚ä½•ï¼Œåªéœ€ä¸€ä¸ªè¶…å‚æ•°ã€‚åœ¨ä¸‰ä¸ªå¾®è°ƒä»»åŠ¡ï¼ˆæ•°å­¦æ¨ç†ã€åå¥½å¯¹é½å’Œé€šç”¨æŒ‡ä»¤è°ƒæ•´ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMWAæŒç»­äº§ç”Ÿä¼˜äºç®€å•å¹³å‡æ£€æŸ¥ç‚¹çš„åˆå¹¶æ¨¡å‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒæŸå¤±åŠ æƒåˆå¹¶é€šå¸¸ä¼šäº§ç”Ÿæœ€ä½³ç»“æœï¼Œå…¶ä»»åŠ¡å‡†ç¡®æ€§æ¯”åŸºçº¿å‡åŒ€åˆå¹¶æé«˜äº†é«˜è¾¾5%ï¼Œç”šè‡³è¶…è¿‡äº†æœ€ç»ˆå•ç‹¬æ£€æŸ¥ç‚¹çš„æ€§èƒ½ã€‚è¿™äº›å‘ç°éªŒè¯äº†æ£€æŸ¥ç‚¹åˆå¹¶å¯¹äºPEFTçš„æœ‰æ•ˆæ€§ï¼Œå¹¶è¡¨æ˜åº¦é‡é©±åŠ¨çš„åŠ æƒå¯å‘å¼æ–¹æ³•å¯ä»¥é«˜æ•ˆåœ°æé«˜æ¨¡å‹æ€§èƒ½ï¼Œä¸”è®¡ç®—å¼€é”€æœ€å°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18580v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰ä¸­çš„æ£€æŸ¥ç‚¹åˆå¹¶æŠ€æœ¯ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºMetrics-Weighted Averagingï¼ˆMWAï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡æ€§èƒ½æŒ‡æ ‡çš„æƒé‡å‚æ•°åˆå¹¶æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMWAåœ¨ä¸‰ç§å¾®è°ƒä»»åŠ¡ä¸­å‡è¡¨ç°ä¼˜ç§€ï¼Œäº§ç”Ÿåˆå¹¶æ¨¡å‹çš„è¡¨ç°è¶…è¿‡äº†æ£€æŸ¥ç‚¹çš„ç®€å•å¹³å‡ã€‚æŸå¤±åŠ æƒåˆå¹¶å¸¸å¸¸å–å¾—æœ€ä½³ç»“æœï¼Œå¯æœ‰æ•ˆæå‡æ¨¡å‹æ€§èƒ½ï¼ŒåŒæ—¶é™ä½è®¡ç®—å¼€é”€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ£€æŸ¥ç‚¹åˆå¹¶æŠ€æœ¯ç»“åˆäº†å¤šä¸ªæ¨¡å‹å¿«ç…§åˆ°ä¸€ä¸ªä¼˜è´¨æ¨¡å‹ï¼Œå¯ç¼©çŸ­å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ—¶é—´ã€‚</li>
<li>æ–‡ç« æå‡ºMetrics-Weighted Averagingï¼ˆMWAï¼‰æ–¹æ³•ç”¨äºæ£€æŸ¥ç‚¹åˆå¹¶ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ€§èƒ½æŒ‡æ ‡åŠ æƒå‚æ•°ã€‚</li>
<li>MWAæ–¹æ³•è€ƒè™‘äº†è®­ç»ƒæŸå¤±å’Œè®­ç»ƒæ­¥éª¤ä½œä¸ºæƒé‡ä¾æ®ï¼Œè®¤ä¸ºä½æŸå¤±æˆ–åæœŸæ­¥éª¤çš„æ£€æŸ¥ç‚¹æ›´æœ‰ä»·å€¼ã€‚</li>
<li>é€šè¿‡å®éªŒéªŒè¯äº†MWAåœ¨ä¸‰ç§å¾®è°ƒä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œåˆå¹¶æ¨¡å‹è¡¨ç°è¶…è¿‡æ£€æŸ¥ç‚¹çš„ç®€å•å¹³å‡ã€‚</li>
<li>æŸå¤±åŠ æƒåˆå¹¶æ–¹å¼è¡¨ç°æœ€ä½³ï¼Œèƒ½æå‡ä»»åŠ¡å‡†ç¡®æ€§é«˜è¾¾5%ï¼Œç”šè‡³è¶…è¶Šæœ€ç»ˆä¸ªä½“æ£€æŸ¥ç‚¹çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•åªéœ€ä¸€ä¸ªè¶…å‚æ•°ï¼Œå¯é€‚åº”ä¸åŒæ•°é‡çš„æ£€æŸ¥ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18580">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-68fe610040efbc9832666f27b3dbdac6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7bd187331d269208bfd60a8b77f5a085.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a82a9c4583cd8884da45dfcaccb9a28.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Optimizing-GPT-for-Video-Understanding-Zero-Shot-Performance-and-Prompt-Engineering"><a href="#Optimizing-GPT-for-Video-Understanding-Zero-Shot-Performance-and-Prompt-Engineering" class="headerlink" title="Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt   Engineering"></a>Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt   Engineering</h2><p><strong>Authors:Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu</strong></p>
<p>In this study, we tackle industry challenges in video content classification by exploring and optimizing GPT-based models for zero-shot classification across seven critical categories of video quality. We contribute a novel approach to improving GPTâ€™s performance through prompt optimization and policy refinement, demonstrating that simplifying complex policies significantly reduces false negatives. Additionally, we introduce a new decomposition-aggregation-based prompt engineering technique, which outperforms traditional single-prompt methods. These experiments, conducted on real industry problems, show that thoughtful prompt design can substantially enhance GPTâ€™s performance without additional finetuning, offering an effective and scalable solution for improving video classification. </p>
<blockquote>
<p>åœ¨æœ¬æ¬¡ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹è§†é¢‘å†…å®¹åˆ†ç±»è¡Œä¸šçš„æŒ‘æˆ˜ï¼Œæ¢ç´¢å¹¶ä¼˜åŒ–äº†åŸºäºGPTçš„é›¶æ ·æœ¬åˆ†ç±»æ¨¡å‹ï¼Œè¦†ç›–äº†ä¸ƒå¤§å…³é”®è§†é¢‘è´¨é‡ç±»åˆ«ã€‚æˆ‘ä»¬é€šè¿‡ä¼˜åŒ–æç¤ºå’Œç»†åŒ–ç­–ç•¥ï¼Œæå‡ºäº†ä¸€ç§æé«˜GPTæ€§èƒ½çš„æ–°æ–¹æ³•ï¼Œè¯æ˜ç®€åŒ–å¤æ‚ç­–ç•¥èƒ½å¤Ÿæ˜¾è‘—é™ä½è¯¯æŠ¥é˜´æ€§ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§åŸºäºåˆ†è§£èšåˆçš„æç¤ºå·¥ç¨‹æŠ€æœ¯ï¼Œè¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿå•ä¸€æç¤ºæ–¹æ³•ã€‚è¿™äº›é’ˆå¯¹çœŸå®è¡Œä¸šé—®é¢˜è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œç²¾å¿ƒçš„æç¤ºè®¾è®¡å¯ä»¥åœ¨ä¸è¿›è¡Œé¢å¤–å¾®è°ƒçš„æƒ…å†µä¸‹æ˜¾è‘—æé«˜GPTçš„æ€§èƒ½ï¼Œä¸ºæ”¹è¿›è§†é¢‘åˆ†ç±»æä¾›äº†ä¸€ç§æœ‰æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.09573v3">PDF</a> 9 pages</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶é’ˆå¯¹è§†é¢‘å†…å®¹åˆ†ç±»è¡Œä¸šçš„æŒ‘æˆ˜ï¼Œé€šè¿‡æ¢ç´¢å’Œä¼˜åŒ–åŸºäºGPTçš„æ¨¡å‹ï¼Œå®ç°é›¶æ ·æœ¬åˆ†ç±»åœ¨ä¸ƒä¸ªå…³é”®è§†é¢‘è´¨é‡ç±»åˆ«ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶é€šè¿‡ä¼˜åŒ–æç¤ºå’Œç²¾ç‚¼ç­–ç•¥ï¼Œæé«˜äº†GPTçš„æ€§èƒ½ï¼Œè¯æ˜äº†ç®€åŒ–å¤æ‚ç­–ç•¥èƒ½æ˜¾è‘—é™ä½è¯¯æŠ¥ã€‚åŒæ—¶ï¼Œå¼•å…¥åŸºäºåˆ†è§£èšåˆçš„æç¤ºå·¥ç¨‹æŠ€æœ¯ï¼Œä¼˜äºä¼ ç»Ÿå•ä¸€æç¤ºæ–¹æ³•ã€‚åœ¨çœŸå®è¡Œä¸šé—®é¢˜ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå·§å¦™çš„æç¤ºè®¾è®¡å¯ä»¥åœ¨æ— éœ€é¢å¤–å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æé«˜GPTçš„æ€§èƒ½ï¼Œä¸ºæ”¹è¿›è§†é¢‘åˆ†ç±»æä¾›äº†æœ‰æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æ¢ç´¢å’Œä¼˜åŒ–äº†åŸºäºGPTçš„æ¨¡å‹åœ¨è§†é¢‘å†…å®¹åˆ†ç±»æ–¹é¢çš„åº”ç”¨ï¼Œæ¶µç›–ä¸ƒä¸ªå…³é”®è§†é¢‘è´¨é‡ç±»åˆ«ã€‚</li>
<li>é€šè¿‡ä¼˜åŒ–æç¤ºå’Œç²¾ç‚¼ç­–ç•¥ï¼Œæé«˜äº†GPTæ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>ç®€åŒ–å¤æ‚ç­–ç•¥èƒ½æ˜¾è‘—é™ä½è¯¯æŠ¥ã€‚</li>
<li>å¼•å…¥åŸºäºåˆ†è§£èšåˆçš„æç¤ºå·¥ç¨‹æŠ€æœ¯ï¼Œè¯¥æ–¹æ³•åœ¨è§†é¢‘åˆ†ç±»ä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>å·§å¦™çš„æç¤ºè®¾è®¡å¯ä»¥æé«˜GPTæ¨¡å‹çš„æ€§èƒ½ï¼Œæ— éœ€é¢å¤–çš„å¾®è°ƒã€‚</li>
<li>ç ”ç©¶æˆæœä¸ºæ”¹è¿›è§†é¢‘åˆ†ç±»æä¾›äº†æœ‰æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.09573">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b6b524ea8e8b99e4bc41a2e554d8b478.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02d9999612e01b82dcf6e5fd4521e113.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c42ca66d7e6125fefb4400037ac77900.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df93f43e147830672bbff224d0358ab1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ef873325f82e539bae0097f7dd66b65.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="TS3-Codec-Transformer-Based-Simple-Streaming-Single-Codec"><a href="#TS3-Codec-Transformer-Based-Simple-Streaming-Single-Codec" class="headerlink" title="TS3-Codec: Transformer-Based Simple Streaming Single Codec"></a>TS3-Codec: Transformer-Based Simple Streaming Single Codec</h2><p><strong>Authors:Haibin Wu, Naoyuki Kanda, Sefik Emre Eskimez, Jinyu Li</strong></p>
<p>Neural audio codecs (NACs) have garnered significant attention as key technologies for audio compression as well as audio representation for speech language models. While mainstream NAC models are predominantly convolution-based, the performance of NACs with a purely transformer-based, and convolution-free architecture remains unexplored. This paper introduces TS3-Codec, a Transformer-Based Simple Streaming Single Codec. TS3-Codec consists of only a stack of transformer layers with a few linear layers, offering greater simplicity and expressiveness by fully eliminating convolution layers that require careful hyperparameter tuning and large computations. Under the streaming setup, the proposed TS3-Codec achieves comparable or superior performance compared to the codec with state-of-the-art convolution-based architecture while requiring only 12% of the computation and 77% of bitrate. Furthermore, it significantly outperforms the convolution-based codec when using similar computational resources. </p>
<blockquote>
<p>ç¥ç»éŸ³é¢‘ç¼–ç ï¼ˆNACï¼‰ä½œä¸ºéŸ³é¢‘å‹ç¼©å’Œè¯­éŸ³è¯­è¨€æ¨¡å‹éŸ³é¢‘è¡¨ç¤ºçš„å…³é”®æŠ€æœ¯ï¼Œå·²ç»å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚è™½ç„¶ä¸»æµçš„NACæ¨¡å‹ä¸»è¦æ˜¯åŸºäºå·ç§¯çš„ï¼Œä½†å®Œå…¨åŸºäºè½¬æ¢å™¨ä¸”æ²¡æœ‰å·ç§¯æ¶æ„çš„NACçš„æ€§èƒ½ä»ç„¶æœªè¢«æ¢ç´¢ã€‚æœ¬æ–‡ä»‹ç»äº†TS3-Codecï¼Œä¸€ç§åŸºäºè½¬æ¢å™¨çš„ç®€å•æµå¼å•ç¼–ç è§£ç å™¨ã€‚TS3-Codecä»…ç”±ä¸€äº›è½¬æ¢å™¨å±‚å’Œä¸€äº›çº¿æ€§å±‚ç»„æˆï¼Œé€šè¿‡å®Œå…¨æ¶ˆé™¤éœ€è¦ç²¾å¿ƒè°ƒæ•´è¶…å‚æ•°å’Œå¤§é‡è®¡ç®—çš„å·ç§¯å±‚ï¼Œæä¾›æ›´é«˜çš„ç®€æ´æ€§å’Œè¡¨ç°åŠ›ã€‚åœ¨æµå¼è®¾ç½®ä¸‹ï¼Œæ‰€æå‡ºçš„TS* Codecä¸åŸºäºæœ€æ–°å·ç§¯æ¶æ„çš„ç¼–ç è§£ç å™¨ç›¸æ¯”ï¼Œæ€§èƒ½ç›¸å½“æˆ–æ›´ä¼˜ï¼ŒåŒæ—¶ä»…éœ€è¦è®¡ç®—é‡çš„12%å’Œæ¯”ç‰¹ç‡çš„77%ã€‚æ­¤å¤–ï¼Œåœ¨åˆ©ç”¨ç±»ä¼¼çš„è®¡ç®—èµ„æºæ—¶ï¼Œå®ƒå¤§å¤§ä¼˜äºåŸºäºå·ç§¯çš„ç¼–ç è§£ç å™¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18803v2">PDF</a> </p>
<p><strong>Summary</strong><br>ç¥ç»ç½‘ç»œéŸ³é¢‘ç¼–è§£ç å™¨ï¼ˆNACï¼‰æ˜¯éŸ³é¢‘å‹ç¼©å’Œè¯­éŸ³è¯­è¨€æ¨¡å‹éŸ³é¢‘è¡¨ç¤ºçš„å…³é”®æŠ€æœ¯ã€‚å½“å‰ä¸»æµNACæ¨¡å‹ä¸»è¦åŸºäºå·ç§¯ï¼Œä½†å¯¹çº¯ç²¹åŸºäºå˜å‹å™¨ä¸”æ— å·ç§¯å±‚çš„NACæ€§èƒ½å°šæœªæ¢ç´¢ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå˜å‹å™¨çš„ç®€å•æµå¼å•ç¼–è§£ç å™¨TS3-Codecï¼Œå®ƒç”±ä¸€å †å˜å‹å™¨å±‚å’Œä¸€äº›çº¿æ€§å±‚ç»„æˆï¼Œé€šè¿‡å®Œå…¨æ¶ˆé™¤éœ€è¦ç²¾å¿ƒè¶…å‚æ•°è°ƒæ•´å’Œå¤§é‡è®¡ç®—çš„å·ç§¯å±‚ï¼Œæä¾›æ›´é«˜çš„ç®€æ´æ€§å’Œè¡¨ç°åŠ›ã€‚åœ¨æµå¼è®¾ç½®ä¸‹ï¼ŒTS3ç¼–è§£ç å™¨ä¸åŸºäºæœ€æ–°å·ç§¯æŠ€æœ¯çš„ç¼–è§£ç å™¨ç›¸æ¯”ï¼Œå®ç°äº†ç›¸å½“æˆ–æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼ŒåŒæ—¶ä»…éœ€è¦12%çš„è®¡ç®—å’Œ77%çš„æ¯”ç‰¹ç‡ã€‚åœ¨ç±»ä¼¼çš„è®¡ç®—èµ„æºä¸‹ï¼Œå®ƒæ˜¾è‘—ä¼˜äºåŸºäºå·ç§¯çš„ç¼–è§£ç å™¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œéŸ³é¢‘ç¼–è§£ç å™¨ï¼ˆNACï¼‰æ˜¯éŸ³é¢‘å‹ç¼©å’Œè¯­éŸ³è¯­è¨€æ¨¡å‹çš„é‡è¦æŠ€æœ¯ã€‚</li>
<li>å½“å‰ä¸»æµNACæ¨¡å‹ä»¥å·ç§¯ä¸ºåŸºç¡€ï¼Œä½†çº¯å˜å‹å™¨æ¶æ„çš„æ€§èƒ½å°šæœªè¢«æ¢ç´¢ã€‚</li>
<li>TS3ç¼–è§£ç å™¨æ˜¯ä¸€ç§åŸºäºå˜å‹å™¨çš„ç®€å•æµå¼å•ç¼–è§£ç å™¨ï¼Œä¸åŒ…å«å·ç§¯å±‚ã€‚</li>
<li>TS3ç¼–è§£ç å™¨å…·æœ‰æ›´é«˜çš„ç®€æ´æ€§å’Œè¡¨ç°åŠ›ï¼Œå› ä¸ºå®ƒå®Œå…¨æ¶ˆé™¤äº†éœ€è¦ç²¾å¿ƒè¶…å‚æ•°è°ƒæ•´å’Œå¤§é‡è®¡ç®—çš„å·ç§¯å±‚ã€‚</li>
<li>åœ¨æµå¼ç¯å¢ƒä¸‹ï¼ŒTS3ç¼–è§£ç å™¨çš„æ€§èƒ½ä¸æœ€å…ˆè¿›çš„å·ç§¯ç¼–è§£ç å™¨ç›¸å½“æˆ–æ›´å¥½ï¼ŒåŒæ—¶è®¡ç®—éœ€æ±‚å’Œæ¯”ç‰¹ç‡å¤§å¹…é™ä½ã€‚</li>
<li>TS3ç¼–è§£ç å™¨åœ¨åˆ©ç”¨ç±»ä¼¼è®¡ç®—èµ„æºæ—¶ï¼Œæ˜¾è‘—ä¼˜äºåŸºäºå·ç§¯çš„ç¼–è§£ç å™¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18803">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7081f100ef913fca64b8ce0c81ccdd3c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6680659fb0a53d87e5a5c031287ced72.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4cf593f62be709bd28b7c9d860d239f4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-990f2b459885c94dea28c28b56e65838.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf1216842686de95215002e56ad53c06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b626c1661e7624f20f9d3e7e62c2557e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d4d2ee916222663025739b92cb68b88.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="LightRAG-Simple-and-Fast-Retrieval-Augmented-Generation"><a href="#LightRAG-Simple-and-Fast-Retrieval-Augmented-Generation" class="headerlink" title="LightRAG: Simple and Fast Retrieval-Augmented Generation"></a>LightRAG: Simple and Fast Retrieval-Augmented Generation</h2><p><strong>Authors:Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, Chao Huang</strong></p>
<p>Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user needs. However, existing RAG systems have significant limitations, including reliance on flat data representations and inadequate contextual awareness, which can lead to fragmented answers that fail to capture complex inter-dependencies. To address these challenges, we propose LightRAG, which incorporates graph structures into text indexing and retrieval processes. This innovative framework employs a dual-level retrieval system that enhances comprehensive information retrieval from both low-level and high-level knowledge discovery. Additionally, the integration of graph structures with vector representations facilitates efficient retrieval of related entities and their relationships, significantly improving response times while maintaining contextual relevance. This capability is further enhanced by an incremental update algorithm that ensures the timely integration of new data, allowing the system to remain effective and responsive in rapidly changing data environments. Extensive experimental validation demonstrates considerable improvements in retrieval accuracy and efficiency compared to existing approaches. We have made our LightRAG open-source and available at the link: <a target="_blank" rel="noopener" href="https://github.com/HKUDS/LightRAG">https://github.com/HKUDS/LightRAG</a> </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿé€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†æºï¼Œå¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŠŸèƒ½ï¼Œèƒ½å¤Ÿæä¾›æ›´å‡†ç¡®ã€æ›´ç¬¦åˆä¸Šä¸‹æ–‡ç¯å¢ƒå’Œç”¨æˆ·éœ€æ±‚çš„å›ç­”ã€‚ç„¶è€Œï¼Œç°æœ‰çš„RAGç³»ç»Ÿå­˜åœ¨é‡å¤§å±€é™ï¼ŒåŒ…æ‹¬ä¾èµ–æ‰å¹³çš„æ•°æ®è¡¨ç¤ºå’Œç¼ºä¹è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡æ„è¯†ï¼Œè¿™å¯èƒ½å¯¼è‡´ç­”æ¡ˆæ”¯ç¦»ç ´ç¢ï¼Œæ— æ³•æ•æ‰å¤æ‚çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†LightRAGï¼Œå®ƒå°†å›¾å½¢ç»“æ„èå…¥æ–‡æœ¬ç´¢å¼•å’Œæ£€ç´¢è¿‡ç¨‹ã€‚è¿™ä¸€åˆ›æ–°æ¡†æ¶é‡‡ç”¨åŒçº§æ£€ç´¢ç³»ç»Ÿï¼Œä»ä½çº§åˆ°é«˜çº§çŸ¥è¯†å‘ç°ï¼Œæé«˜äº†å…¨é¢ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå›¾å½¢ç»“æ„ä¸å‘é‡è¡¨ç¤ºçš„èåˆä¿ƒè¿›äº†ç›¸å…³å®ä½“åŠå…¶å…³ç³»çš„æœ‰æ•ˆæ£€ç´¢ï¼Œåœ¨ä¿æŒä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„åŒæ—¶æ˜¾è‘—æé«˜å“åº”æ—¶é—´ã€‚å¢é‡æ›´æ–°ç®—æ³•è¿›ä¸€æ­¥å¢å¼ºäº†æ­¤åŠŸèƒ½ï¼Œç¡®ä¿æ–°æ•°æ®èƒ½å¤ŸåŠæ—¶æ•´åˆï¼Œä½¿ç³»ç»Ÿåœ¨å¿«é€Ÿå˜åŒ–çš„æ•°æ®ç¯å¢ƒä¸­ä¿æŒæœ‰æ•ˆå’Œå“åº”èƒ½åŠ›ã€‚å¤§é‡å®éªŒéªŒè¯è¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ£€ç´¢å‡†ç¡®æ€§å’Œæ•ˆç‡å‡æœ‰æ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬å·²å°†LightRAGå¼€æºï¼Œå¯åœ¨ä»¥ä¸‹é“¾æ¥ä¸­æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/HKUDS/LightRAG">https://github.com/HKUDS/LightRAG</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.05779v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>RAGç³»ç»Ÿé€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†æºå¢å¼ºLLMçš„åŠŸèƒ½ï¼Œä½†å­˜åœ¨æ•°æ®è¡¨ç¤ºè¿‡äºç®€å•å’Œç¼ºä¹ä¸Šä¸‹æ–‡æ„è¯†ç­‰å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†LightRAGï¼Œå®ƒé‡‡ç”¨åŒå±‚æ¬¡æ£€ç´¢ç³»ç»Ÿï¼Œç»“åˆå›¾ç»“æ„è¿›è¡Œæ–‡æœ¬ç´¢å¼•å’Œæ£€ç´¢ï¼Œæé«˜ä»ä½çº§åˆ°é«˜çº§çŸ¥è¯†çš„å…¨é¢æ£€ç´¢èƒ½åŠ›ã€‚é€šè¿‡å‘é‡è¡¨ç¤ºä¸å›¾ç»“æ„çš„ç»“åˆï¼Œæé«˜äº†ç›¸å…³å®ä½“åŠå…¶å…³ç³»çš„æ£€ç´¢æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼ŒLightRAGè¿˜å…·æœ‰å¢é‡æ›´æ–°ç®—æ³•ï¼Œå¯ç¡®ä¿æ–°æ•°æ®çš„åŠæ—¶æ•´åˆï¼Œå¹¶åœ¨å¿«é€Ÿå˜åŒ–çš„æ•°æ®ç¯å¢ƒä¸­ä¿æŒç³»ç»Ÿçš„é«˜æ•ˆå“åº”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RAGç³»ç»Ÿé€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†æºå¢å¼ºLLMçš„æ€§èƒ½ã€‚</li>
<li>ç°æœ‰RAGç³»ç»Ÿå­˜åœ¨æ•°æ®è¡¨ç¤ºè¿‡äºç®€å•å’Œç¼ºä¹ä¸Šä¸‹æ–‡æ„è¯†çš„é—®é¢˜ã€‚</li>
<li>LightRAGé‡‡ç”¨åŒå±‚æ¬¡æ£€ç´¢ç³»ç»Ÿï¼Œæé«˜ä»ä½çº§åˆ°é«˜çº§çŸ¥è¯†çš„å…¨é¢æ£€ç´¢èƒ½åŠ›ã€‚</li>
<li>LightRAGç»“åˆå›¾ç»“æ„è¿›è¡Œæ–‡æœ¬ç´¢å¼•å’Œæ£€ç´¢ã€‚</li>
<li>é€šè¿‡å‘é‡è¡¨ç¤ºä¸å›¾ç»“æ„çš„ç»“åˆï¼ŒLightRAGæé«˜äº†ç›¸å…³å®ä½“åŠå…¶å…³ç³»çš„æ£€ç´¢æ•ˆç‡ã€‚</li>
<li>LightRAGå…·æœ‰å¢é‡æ›´æ–°ç®—æ³•ï¼Œç¡®ä¿æ–°æ•°æ®çš„åŠæ—¶æ•´åˆã€‚</li>
<li>LightRAGåœ¨å¿«é€Ÿå˜åŒ–çš„æ•°æ®ç¯å¢ƒä¸­ä¿æŒé«˜æ•ˆå“åº”ï¼Œå¹¶å·²ç»å¼€æºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.05779">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f605a95537a22dba4374a0663bea6524.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c534e1343f5762bdbca48ce10c288cf6.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="LLaVA-3D-A-Simple-yet-Effective-Pathway-to-Empowering-LMMs-with-3D-awareness"><a href="#LLaVA-3D-A-Simple-yet-Effective-Pathway-to-Empowering-LMMs-with-3D-awareness" class="headerlink" title="LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with   3D-awareness"></a>LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with   3D-awareness</h2><p><strong>Authors:Chenming Zhu, Tai Wang, Wenwei Zhang, Jiangmiao Pang, Xihui Liu</strong></p>
<p>Recent advancements in Large Multimodal Models (LMMs) have greatly enhanced their proficiency in 2D visual understanding tasks, enabling them to effectively process and understand images and videos. However, the development of LMMs with 3D scene understanding capabilities has been hindered by the lack of large-scale 3D vision-language datasets and powerful 3D encoders. In this paper, we introduce a simple yet effective framework called LLaVA-3D. Leveraging the strong 2D visual understanding priors from LLaVA, our LLaVA-3D efficiently adapts LLaVA for 3D scene understanding without compromising 2D understanding capabilities. To achieve this, we utilize the 3D position embeddings to enhance the 2D CLIP Patches with 3D spatial context information and construct 3D patches. By integrating the 3D position embeddings into 2D LMMs and employing joint 2D and 3D vision-language instruction tuning, we establish a unified architecture for both 2D visual understanding and 3D scene understanding. In contrast to previous 3D LMMs, LLaVA-3D supports decoding accurate 3D spatial perception outputs, e.g., 3D bounding boxes, directly from these 3D patches, without relying on the time-consuming off-the-shelf 3D segmentors. Experimental results show that LLaVA-3D converges 3.5x faster than existing 3D LMMs when trained on 3D vision-language datasets. Moreover, LLaVA-3D not only achieves state-of-the-art performance across various 3D tasks but also maintains comparable 2D visual understanding and vision-language conversation capabilities with LLaVA. </p>
<blockquote>
<p>è¿‘æœŸå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨2Dè§†è§‰ç†è§£ä»»åŠ¡ä¸Šçš„èƒ½åŠ›å¾—åˆ°äº†æå¤§çš„æå‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å’Œè§£æå›¾åƒå’Œè§†é¢‘ã€‚ç„¶è€Œï¼Œç”±äºç¼ºå°‘å¤§è§„æ¨¡3Dè§†è§‰è¯­è¨€æ•°æ®é›†å’Œå¼ºå¤§çš„3Dç¼–ç å™¨ï¼Œå…·æœ‰3Dåœºæ™¯ç†è§£èƒ½åŠ›çš„LMMsçš„å‘å±•å—åˆ°äº†é˜»ç¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„æ¡†æ¶ï¼Œåä¸ºLLaVA-3Dã€‚è¯¥æ¡†æ¶åˆ©ç”¨LLaVAå¼ºå¤§çš„2Dè§†è§‰ç†è§£å…ˆéªŒçŸ¥è¯†ï¼Œåœ¨ä¸æŸå®³2Dç†è§£èƒ½åŠ›çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåœ°å°†LLaVAé€‚åº”äº3Dåœºæ™¯ç†è§£ã€‚ä¸ºå®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åˆ©ç”¨3Dä½ç½®åµŒå…¥æ¥å¢å¼ºå¸¦æœ‰3Dç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯çš„2D CLIPè¡¥ä¸ï¼Œå¹¶æ„å»º3Dè¡¥ä¸ã€‚é€šè¿‡å°†3Dä½ç½®åµŒå…¥åˆ°2D LMMsä¸­ï¼Œå¹¶é‡‡ç”¨è”åˆçš„2Då’Œ3Dè§†è§‰è¯­è¨€æŒ‡ä»¤å¾®è°ƒï¼Œæˆ‘ä»¬å»ºç«‹äº†ç»Ÿä¸€çš„æ¶æ„ï¼Œç”¨äº2Dè§†è§‰ç†è§£å’Œ3Dåœºæ™¯ç†è§£ã€‚ä¸ä¹‹å‰çš„3D LMMsç›¸æ¯”ï¼ŒLLaVA-3Dæ”¯æŒç›´æ¥ä»è¿™äº›3Dè¡¥ä¸ä¸­è§£ç å‡†ç¡®çš„3Dç©ºé—´æ„ŸçŸ¥è¾“å‡ºï¼Œä¾‹å¦‚3Dè¾¹ç•Œæ¡†ï¼Œæ— éœ€ä¾èµ–è€—æ—¶çš„ç°æˆçš„3Dåˆ†æ®µå™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨3Dè§†è§‰è¯­è¨€æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ï¼ŒLLaVA-3Dçš„æ”¶æ•›é€Ÿåº¦æ¯”ç°æœ‰3D LMMså¿«3.5å€ã€‚æ­¤å¤–ï¼ŒLLaVA-3Dä¸ä»…åœ¨å„ç§3Dä»»åŠ¡ä¸Šå®ç°äº†æœ€æ–°æ€§èƒ½ï¼Œè€Œä¸”ä¸LLaVAç›¸æ¯”ï¼Œè¿˜ä¿æŒäº†ç›¸å½“çš„2Dè§†è§‰ç†è§£å’Œè§†è§‰è¯­è¨€å¯¹è¯èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.18125v3">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://zcmax.github.io/projects/LLaVA-3D/">https://zcmax.github.io/projects/LLaVA-3D/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰çš„è¿‘æœŸè¿›å±•ï¼Œå¯¹äºäºŒç»´è§†è§‰ç†è§£ä»»åŠ¡çš„å®Œæˆæ•ˆæœæœ‰äº†æ˜¾è‘—æå‡ã€‚ç„¶è€Œï¼Œåœ¨å¼€å‘å…·å¤‡ä¸‰ç»´åœºæ™¯ç†è§£èƒ½åŠ›æ–¹é¢ä»å—é™äºç¼ºä¹å¤§è§„æ¨¡çš„ä¸‰ç»´è§†è§‰è¯­è¨€æ•°æ®é›†å’Œå¼ºå¤§çš„ä¸‰ç»´ç¼–ç å™¨ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ¡†æ¶LLaVA-3Dï¼Œå®ƒåˆ©ç”¨LLaVAçš„äºŒç»´è§†è§‰ç†è§£å…ˆéªŒçŸ¥è¯†ï¼Œåœ¨ä¸æŸå®³äºŒç»´ç†è§£èƒ½åŠ›çš„å‰æä¸‹ï¼Œæœ‰æ•ˆåœ°é€‚åº”ä¸‰ç»´åœºæ™¯ç†è§£ã€‚é€šè¿‡æ•´åˆä¸‰ç»´ä½ç½®åµŒå…¥å’Œæ„å»ºä¸‰ç»´è¡¥ä¸ï¼Œå®ç°äº†äºŒç»´å’Œä¸‰ç»´è§†è§‰è¯­è¨€æŒ‡ä»¤çš„è”åˆè°ƒæ•´ï¼Œå»ºç«‹äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¶æ„ï¼Œæ—¢å¯ç”¨äºäºŒç»´è§†è§‰ç†è§£ä¹Ÿå¯ç”¨äºä¸‰ç»´åœºæ™¯ç†è§£ã€‚ç›¸è¾ƒäºä¹‹å‰çš„ä¸‰ç»´LMMsï¼ŒLLaVA-3Dèƒ½å¤Ÿç›´æ¥é€šè¿‡è¿™äº›ä¸‰ç»´è¡¥ä¸è§£ç å‡†ç¡®çš„3Dç©ºé—´æ„ŸçŸ¥è¾“å‡ºï¼Œå¦‚ä¸‰ç»´è¾¹ç•Œæ¡†ï¼Œè€Œæ— éœ€ä¾èµ–è€—æ—¶çš„ç¦»çº¿ä¸‰ç»´åˆ†å‰²å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸‰ç»´è§†è§‰è¯­è¨€æ•°æ®é›†ä¸Šè®­ç»ƒæ—¶ï¼ŒLLaVA-3Dçš„æ”¶æ•›é€Ÿåº¦æ˜¯ç°æœ‰ä¸‰ç»´LMMsçš„3.5å€ã€‚åŒæ—¶ï¼ŒLLaVA-3Dä¸ä»…åœ¨å„ç§ä¸‰ç»´ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€Œä¸”åœ¨äºŒç»´è§†è§‰ç†è§£å’Œè§†è§‰è¯­è¨€å¯¹è¯èƒ½åŠ›æ–¹é¢ä¸LLaVAä¿æŒç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LMMsåœ¨äºŒç»´è§†è§‰ç†è§£ä»»åŠ¡ä¸Šçš„èƒ½åŠ›å·²ç»æ˜¾è‘—æé«˜ã€‚</li>
<li>ç¼ºä¹å¤§è§„æ¨¡çš„ä¸‰ç»´è§†è§‰è¯­è¨€æ•°æ®é›†å’Œå¼ºå¤§çš„ä¸‰ç»´ç¼–ç å™¨é™åˆ¶äº†ä¸‰ç»´åœºæ™¯ç†è§£çš„å‘å±•ã€‚</li>
<li>LLaVA-3Dæ¡†æ¶ç»“åˆäº†LLaVAçš„äºŒç»´è§†è§‰ç†è§£å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶æ‰©å±•åˆ°ä¸‰ç»´åœºæ™¯ç†è§£ã€‚</li>
<li>é€šè¿‡æ•´åˆä¸‰ç»´ä½ç½®åµŒå…¥å’Œæ„å»ºä¸‰ç»´è¡¥ä¸ï¼Œå®ç°äº†å¯¹äºŒç»´å’Œä¸‰ç»´è§†è§‰ä¿¡æ¯çš„è”åˆå¤„ç†å’Œç†è§£ã€‚</li>
<li>LLaVA-3Dèƒ½è§£ç å‡†ç¡®çš„3Dç©ºé—´æ„ŸçŸ¥è¾“å‡ºï¼Œå¦‚ä¸‰ç»´è¾¹ç•Œæ¡†ã€‚</li>
<li>LLaVA-3Dåœ¨è®­ç»ƒæ—¶æ”¶æ•›é€Ÿåº¦å¿«ï¼Œä¸”åœ¨å¤šç§ä¸‰ç»´ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.18125">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-050cf541a4b8bb46a1956aefb60e020a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de92d80bf29e1c4e08c22a6dd5d18f0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05fd967e711b2aececd4ff49f7988076.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21f142153689be95644a34ad5c0fb2ad.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="What-Should-We-Engineer-in-Prompts-Training-Humans-in-Requirement-Driven-LLM-Use"><a href="#What-Should-We-Engineer-in-Prompts-Training-Humans-in-Requirement-Driven-LLM-Use" class="headerlink" title="What Should We Engineer in Prompts? Training Humans in   Requirement-Driven LLM Use"></a>What Should We Engineer in Prompts? Training Humans in   Requirement-Driven LLM Use</h2><p><strong>Authors:Qianou Ma, Weirui Peng, Chenyang Yang, Hua Shen, Kenneth Koedinger, Tongshuang Wu</strong></p>
<p>Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot) needs humans to clearly articulate customized requirements (e.g., â€œstart the response with a tl;drâ€). However, existing prompt engineering instructions often lack focused training on requirement articulation and instead tend to emphasize increasingly automatable strategies (e.g., tricks like adding role-plays and â€œthink step-by-stepâ€). To address the gap, we introduce Requirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human attention on generating clear, complete requirements during prompting. We implement ROPE through an assessment and training suite that provides deliberate practice with LLM-generated feedback. In a randomized controlled experiment with 30 novices, ROPE significantly outperforms conventional prompt engineering training (20% vs. 1% gains), a gap that automatic prompt optimization cannot close. Furthermore, we demonstrate a direct correlation between the quality of input requirements and LLM outputs. Our work paves the way to empower more end-users to build complex LLM applications. </p>
<blockquote>
<p>å¯¹äºå¤æ‚ä»»åŠ¡ï¼ˆä¾‹å¦‚æ„å»ºæ—…è¡Œé¡¾é—®èŠå¤©æœºå™¨äººï¼‰çš„æç¤ºï¼Œéœ€è¦äººç±»æ¸…æ™°åœ°è¡¨è¾¾å®šåˆ¶åŒ–çš„éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼Œâ€œä»¥tl;drå¼€å§‹å›å¤â€ï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æç¤ºå·¥ç¨‹æŒ‡ä»¤å¾€å¾€ç¼ºä¹å¯¹éœ€æ±‚è¡¨è¾¾çš„é’ˆå¯¹æ€§è®­ç»ƒï¼Œè€Œæ˜¯å€¾å‘äºå¼ºè°ƒå¯ä»¥é€æ¸è‡ªåŠ¨åŒ–çš„ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼Œæ·»åŠ è§’è‰²æ‰®æ¼”å’Œâ€œåˆ†æ­¥æ€è€ƒâ€ç­‰æŠ€å·§ï¼‰ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†éœ€æ±‚å¯¼å‘çš„æç¤ºå·¥ç¨‹ï¼ˆROPEï¼‰èŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸“æ³¨äºåœ¨æç¤ºæ—¶ç”Ÿæˆæ¸…æ™°ã€å®Œæ•´çš„éœ€æ±‚ã€‚æˆ‘ä»¬é€šè¿‡è¯„ä¼°å’ŒåŸ¹è®­ä½“ç³»æ¥å®ç°ROPEï¼Œè¯¥ä½“ç³»æä¾›æœ‰é’ˆå¯¹æ€§çš„å®è·µï¼Œå¹¶è¾…ä»¥LLMç”Ÿæˆçš„åé¦ˆã€‚åœ¨ä¸ºæœŸä¸€é¡¹éšæœºå¯¹ç…§å®éªŒä¸­ï¼Œæœ‰ä¸‰ååæ–°æ‰‹å‚ä¸ï¼ŒROPEæ˜æ˜¾ä¼˜äºä¼ ç»Ÿçš„æç¤ºå·¥ç¨‹è®­ç»ƒï¼ˆæé«˜20%ï¼Œç›¸æ¯”ä¹‹ä¸‹ä¼ ç»Ÿæ–¹å¼ä»…æé«˜1%ï¼‰ï¼Œè¿™ç§å·®è·æ— æ³•é€šè¿‡è‡ªåŠ¨æç¤ºä¼˜åŒ–æ¥å¼¥è¡¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†è¾“å…¥éœ€æ±‚çš„è´¨é‡ä¸LLMè¾“å‡ºä¹‹é—´çš„ç›´æ¥ç›¸å…³æ€§ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºæ•°æ›´å¤šçš„ç»ˆç«¯ç”¨æˆ·æä¾›æ„å»ºå¤æ‚LLMåº”ç”¨çš„æ‰‹æ®µå¼€è¾Ÿäº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08775v3">PDF</a> 15 pages; TOCHI 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»»åŠ¡æç¤ºå·¥ç¨‹å¯¹äºå¤æ‚ä»»åŠ¡è‡³å…³é‡è¦ã€‚é’ˆå¯¹ç°æœ‰æç¤ºå·¥ç¨‹åœ¨éœ€æ±‚è¡¨è¾¾ä¸Šçš„ä¸è¶³ï¼Œæå‡ºäº†ä»¥éœ€æ±‚ä¸ºå¯¼å‘çš„æç¤ºå·¥ç¨‹ï¼ˆROPEï¼‰èŒƒå¼ï¼Œé€šè¿‡è¯„ä¼°å’Œè®­ç»ƒå¥—ä»¶æä¾›æœ‰é’ˆå¯¹æ€§çš„å®è·µï¼Œå¹¶å¼•å…¥LLMåé¦ˆæœºåˆ¶ã€‚å®éªŒè¯æ˜ï¼ŒROPEç›¸è¾ƒäºä¼ ç»Ÿæç¤ºå·¥ç¨‹è®­ç»ƒæœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼ˆæå‡ç‡è¾¾20%ï¼‰ï¼Œä¸”é«˜è´¨é‡çš„è¾“å…¥éœ€æ±‚ä¸LLMè¾“å‡ºç›´æ¥ç›¸å…³ã€‚è¿™ä¸ºæ›´å¤šç»ˆç«¯ç”¨æˆ·æ„å»ºå¤æ‚LLMåº”ç”¨é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨è¿›è¡Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚å¼€å‘æ—…è¡Œé¡¾é—®èŠå¤©æœºå™¨äººï¼‰æ—¶ï¼Œéœ€è¦äººç±»æ˜ç¡®è¡¨è¿°ä¸ªæ€§åŒ–éœ€æ±‚ã€‚</li>
<li>ç°æœ‰æç¤ºå·¥ç¨‹æŒ‡ä»¤å¾€å¾€ç¼ºä¹é’ˆå¯¹éœ€æ±‚è¡¨è¾¾çš„é’ˆå¯¹æ€§è®­ç»ƒï¼Œè€Œè¿‡åˆ†å¼ºè°ƒå¯è‡ªåŠ¨åŒ–ç­–ç•¥ã€‚</li>
<li>å¼•å…¥ROPEï¼ˆéœ€æ±‚å¯¼å‘çš„æç¤ºå·¥ç¨‹ï¼‰èŒƒå¼ï¼Œä¸“æ³¨äºç”Ÿæˆæ¸…æ™°ã€å®Œæ•´çš„éœ€æ±‚ã€‚</li>
<li>ROPEé€šè¿‡è¯„ä¼°å’Œè®­ç»ƒå¥—ä»¶å®ç°ï¼ŒåŒ…æ‹¬LLMåé¦ˆæœºåˆ¶ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼ŒROPEæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæç¤ºå·¥ç¨‹è®­ç»ƒï¼ˆæå‡ç‡è¾¾20%ï¼‰ï¼Œä¸”è¿™ä¸€å·®è·æ— æ³•é€šè¿‡è‡ªåŠ¨æç¤ºä¼˜åŒ–æ¥å¼¥è¡¥ã€‚</li>
<li>è¾“å…¥éœ€æ±‚çš„è´¨é‡ä¸LLMè¾“å‡ºä¹‹é—´å­˜åœ¨ç›´æ¥å…³è”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08775">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88f680e313e27400da2921f92c188a0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c565b6290477d718f8fded3cedfdd33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bde3542e077e7ccdf03dadb4c0c5163d.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Pula-Training-Large-Language-Models-for-Setswana"><a href="#Pula-Training-Large-Language-Models-for-Setswana" class="headerlink" title="Pula: Training Large Language Models for Setswana"></a>Pula: Training Large Language Models for Setswana</h2><p><strong>Authors:Nathan Brown, Vukosi Marivate</strong></p>
<p>In this work we present Pula, a suite of bilingual language models proficient in both Setswana and English. Leveraging recent advancements in data availability and efficient fine-tuning, Pula 8B and Pula 14B outperform GPT-4o and Gemini 1.5 Pro on English-Setswana translation tasks and achieve state-of-the-art performance on Setswana reasoning tasks for their size. We release the weights for Pula 1B, 3B, 8B, and 14B as well as training logs and training and evaluation code. Alongside Pula, we release the largest-ever Setswana text corpus, Marothodi, and the first comprehensive Setswana instruction-tuning dataset, Medupi, consisting of reformatted datasets, translated corpora, and synthetic LLM-generated text. To accompany this data, we release the code used for dataset construction, formatting, filtering, and scraping. Last, we release two Setswana LLM-translated benchmarks, MMLU-tsn and GSM8K-tsn, to measure Setswana knowledge and reasoning capabilities. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Pulaï¼Œè¿™æ˜¯ä¸€æ¬¾åŒè¯­è¯­è¨€æ¨¡å‹å¥—ä»¶ï¼Œç²¾é€šSetswanaè¯­å’Œè‹±è¯­ã€‚å€ŸåŠ©æœ€è¿‘æ•°æ®å¯ç”¨æ€§å’Œé«˜æ•ˆå¾®è°ƒæ–¹é¢çš„è¿›æ­¥ï¼ŒPula 8Bå’ŒPula 14Båœ¨è‹±æ–‡-Setswanaç¿»è¯‘ä»»åŠ¡ä¸Šçš„è¡¨ç°è¶…è¿‡äº†GPT-4oå’ŒGemini 1.5 Proï¼Œä¸”åœ¨Setswanaæ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†å…¶è§„æ¨¡çš„æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»¬å‘å¸ƒäº†Pula 1Bã€3Bã€8Bå’Œ14Bçš„æƒé‡ï¼Œä»¥åŠè®­ç»ƒæ—¥å¿—å’Œè®­ç»ƒä¸è¯„ä¼°ä»£ç ã€‚é™¤Pulaå¤–ï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„Setswanaæ–‡æœ¬è¯­æ–™åº“Marothodiä»¥åŠé¦–ä¸ªå…¨é¢çš„SetswanaæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†Medupiï¼Œè¯¥æ•°æ®é›†åŒ…å«é‡æ–°æ ¼å¼åŒ–çš„æ•°æ®é›†ã€ç¿»è¯‘è¯­æ–™åº“ä»¥åŠåˆæˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ã€‚ä¸ºé…åˆè¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬å…¬å¼€äº†ç”¨äºæ•°æ®é›†æ„å»ºã€æ ¼å¼åŒ–ã€è¿‡æ»¤å’ŒæŠ“å–çš„ä»£ç ã€‚æœ€åï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸¤ä¸ªSetswanaå¤§å‹è¯­è¨€æ¨¡å‹ç¿»è¯‘åŸºå‡†æµ‹è¯•MMLU-tsnå’ŒGSM8K-tsnï¼Œä»¥è¡¡é‡SetswanaçŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.02239v2">PDF</a> NAACL 2025. 10 pages, 5 tables, 1 figure</p>
<p><strong>Summary</strong></p>
<p>Pulaæ˜¯ä¸€ç³»åˆ—åŒè¯­è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç†Ÿç»ƒæŒæ¡è‹±è¯­å’ŒSetswanaè¯­ã€‚å€ŸåŠ©æ•°æ®å¯ç”¨æ€§å’Œé«˜æ•ˆå¾®è°ƒçš„æœ€æ–°è¿›å±•ï¼ŒPula 8Bå’ŒPula 14Båœ¨è‹±è¯­åˆ°Setswanaçš„ç¿»è¯‘ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå¹¶åœ¨Setswanaæ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†å…¶è§„æ¨¡çš„æœ€æ–°æ°´å¹³ã€‚åŒæ—¶å‘å¸ƒäº†Pula 1Bã€3Bã€8Bå’Œ14Bçš„æƒé‡ï¼Œä»¥åŠè®­ç»ƒæ—¥å¿—ã€è®­ç»ƒå’Œè¯„ä¼°ä»£ç ã€‚æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„Setswanaæ–‡æœ¬è¯­æ–™åº“Marothodiå’Œé¦–ä¸ªå…¨é¢çš„SetswanaæŒ‡ä»¤è°ƒæ•´æ•°æ®é›†Medupiï¼ŒåŒ…å«é‡æ–°æ ¼å¼åŒ–çš„æ•°æ®é›†ã€ç¿»è¯‘è¯­æ–™åº“å’ŒåˆæˆLLMç”Ÿæˆçš„æ–‡æœ¬ã€‚åŒæ—¶å…¬å¼€äº†ç”¨äºæ•°æ®é›†æ„å»ºã€æ ¼å¼åŒ–ã€è¿‡æ»¤å’ŒæŠ“å–çš„ä»£ç ã€‚æœ€åï¼Œå‘å¸ƒäº†ä¸¤é¡¹ç”¨äºè¡¡é‡SetswanaçŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•MMLU-tsnå’ŒGSM8K-tsnã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Pulaæ˜¯ä¸€ç³»åˆ—åŒè¯­è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç†Ÿç»ƒæŒæ¡è‹±è¯­å’ŒSetswanaè¯­ã€‚</li>
<li>Pula 8Bå’ŒPula 14Båœ¨è‹±è¯­åˆ°Setswanaçš„ç¿»è¯‘ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>Pulaæ¨¡å‹åœ¨Setswanaæ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†å…¶è§„æ¨¡çš„æœ€æ–°æ°´å¹³ã€‚</li>
<li>å‘å¸ƒäº†ä¸åŒè§„æ¨¡çš„Pulaæ¨¡å‹æƒé‡ã€è®­ç»ƒæ—¥å¿—åŠè®­ç»ƒå’Œè¯„ä¼°ä»£ç ã€‚</li>
<li>å‘å¸ƒäº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„Setswanaæ–‡æœ¬è¯­æ–™åº“Marothodiã€‚</li>
<li>å‘å¸ƒäº†é¦–ä¸ªå…¨é¢çš„SetswanaæŒ‡ä»¤è°ƒæ•´æ•°æ®é›†Medupiï¼ŒåŒ…å«å¤šç§æ¥æºçš„æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.02239">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ee175dd200ff26b0534f3aa47a35c66f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f12cb88224233bdc9eadf69687b26165.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-903891550c63eb8ab48a376cc47b0b86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-829cbbfa3efe8d33cf38c8115e179b10.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-be7808b803999dffd75289428e3935d1.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  Can AI Agents Design and Implement Drug Discovery Pipelines?
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ee0ea70a875db937618271d0caa1b451.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-30  DEEMO De-identity Multimodal Emotion Recognition and Reasoning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29474.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
