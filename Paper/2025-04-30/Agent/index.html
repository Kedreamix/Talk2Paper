<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-04-30  Can AI Agents Design and Implement Drug Discovery Pipelines?">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-be7808b803999dffd75289428e3935d1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    28 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-30-更新"><a href="#2025-04-30-更新" class="headerlink" title="2025-04-30 更新"></a>2025-04-30 更新</h1><h2 id="Can-AI-Agents-Design-and-Implement-Drug-Discovery-Pipelines"><a href="#Can-AI-Agents-Design-and-Implement-Drug-Discovery-Pipelines" class="headerlink" title="Can AI Agents Design and Implement Drug Discovery Pipelines?"></a>Can AI Agents Design and Implement Drug Discovery Pipelines?</h2><p><strong>Authors:Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan</strong></p>
<p>The rapid advancement of artificial intelligence, particularly autonomous agentic systems based on Large Language Models (LLMs), presents new opportunities to accelerate drug discovery by improving in-silico modeling and reducing dependence on costly experimental trials. Current AI agent-based systems demonstrate proficiency in solving programming challenges and conducting research, indicating an emerging potential to develop software capable of addressing complex problems such as pharmaceutical design and drug discovery. This paper introduces DO Challenge, a benchmark designed to evaluate the decision-making abilities of AI agents in a single, complex problem resembling virtual screening scenarios. The benchmark challenges systems to independently develop, implement, and execute efficient strategies for identifying promising molecular structures from extensive datasets, while navigating chemical space, selecting models, and managing limited resources in a multi-objective context. We also discuss insights from the DO Challenge 2025, a competition based on the proposed benchmark, which showcased diverse strategies explored by human participants. Furthermore, we present the Deep Thought multi-agent system, which demonstrated strong performance on the benchmark, outperforming most human teams. Among the language models tested, Claude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles, and GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While promising, the system’s performance still fell short of expert-designed solutions and showed high instability, highlighting both the potential and current limitations of AI-driven methodologies in transforming drug discovery and broader scientific research. </p>
<blockquote>
<p>人工智能的快速发展，尤其是基于大型语言模型（LLM）的自主代理系统，为通过改进计算机模拟建模和减少对昂贵实验试点的依赖来加速药物发现提供了新的机遇。当前的基于人工智能代理的系统在解决编程挑战和研究方面表现出色，这表明有潜力开发能够解决诸如药物设计和药物发现等复杂问题的软件。本文介绍了DO Challenge，这是一个基准测试，旨在评估人工智能代理在类似于虚拟筛选场景的单个复杂问题中的决策能力。该基准测试挑战系统独立开发、实施并执行有效的策略，从大量数据集中识别出有前景的分子结构，同时导航化学空间、选择模型并在多目标背景下管理有限资源。我们还讨论了基于该基准测试的DO Challenge 2025竞赛的见解，展示了人类参与者探索的各种策略。此外，我们还介绍了在基准测试中表现强劲的深度思维多智能体系统，它在大多数人类团队中表现出色。在测试的语言模型中，Claude 3.7 Sonnet、Gemini 2.5 Pro和o3在主要代理角色中表现最佳，GPT-4o和Gemini 2.0 Flash在辅助角色中效果显著。虽然很有前途，但该系统的性能仍然落后于专家设计的解决方案，并表现出高度的不稳定，这突出了人工智能驱动方法在药物发现和更广泛的科学研究中的潜力和当前局限性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19912v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了人工智能在药物发现领域的新机遇。特别是基于大型语言模型（LLM）的自主代理系统，通过改善硅基建模并减少对昂贵实验试点的依赖，来加速药物发现的进程。文章提出了一个名为DO Challenge的基准测试，用于评估AI代理在类似于虚拟筛选场景中的决策能力。此外，还讨论了基于该基准测试的DO Challenge 2025竞赛的见解，并展示了一个在多目标环境中表现出色的多代理系统——Deep Thought。虽然Deep Thought系统的性能仍低于专家设计的解决方案并显示出高不稳定性，但它突显了人工智能在药物发现和更广泛科学研究中的潜力和当前局限。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>人工智能，特别是基于大型语言模型的自主代理系统，为药物发现带来了新的机遇。</li>
<li>通过改善硅基建模和减少对昂贵实验试点的依赖，AI加速了药物发现的进程。</li>
<li>DO Challenge基准测试用于评估AI代理在虚拟筛选场景中的决策能力。</li>
<li>Deep Thought多代理系统在多目标环境中表现出色，但仍存在性能不稳定的问题。</li>
<li>AI代理系统在药物发现和更广泛科学研究领域具有潜力，但仍存在局限性。</li>
<li>在DO Challenge 2025竞赛中，人类参与者的策略多样性得到了展示。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19912">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c35280be3e8a260cd3c40dffdb8b9aca.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8869e017075ed63a7e3a833b507cb85f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="m-KAILIN-Knowledge-Driven-Agentic-Scientific-Corpus-Distillation-Framework-for-Biomedical-Large-Language-Models-Training"><a href="#m-KAILIN-Knowledge-Driven-Agentic-Scientific-Corpus-Distillation-Framework-for-Biomedical-Large-Language-Models-Training" class="headerlink" title="m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation   Framework for Biomedical Large Language Models Training"></a>m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation   Framework for Biomedical Large Language Models Training</h2><p><strong>Authors:Meng Xiao, Xunxin Cai, Chengrui Wang, Yuanchun Zhou</strong></p>
<p>The rapid progress of large language models (LLMs) in biomedical research has underscored the limitations of existing open-source annotated scientific corpora, which are often insufficient in quantity and quality. Addressing the challenge posed by the complex hierarchy of biomedical knowledge, we propose a knowledge-driven, multi-agent framework for scientific corpus distillation tailored for LLM training in the biomedical domain. Central to our approach is a collaborative multi-agent architecture, where specialized agents, each guided by the Medical Subject Headings (MeSH) hierarchy, work in concert to autonomously extract, synthesize, and self-evaluate high-quality textual data from vast scientific literature. These agents collectively generate and refine domain-specific question-answer pairs, ensuring comprehensive coverage and consistency with biomedical ontologies while minimizing manual involvement. Extensive experimental results show that language models trained on our multi-agent distilled datasets achieve notable improvements in biomedical question-answering tasks, outperforming both strong life sciences LLM baselines and advanced proprietary models. Notably, our AI-Ready dataset enables Llama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger scale. Detailed ablation studies and case analyses further validate the effectiveness and synergy of each agent within the framework, highlighting the potential of multi-agent collaboration in biomedical LLM training. </p>
<blockquote>
<p>大型语言模型（LLM）在生物医学研究中的快速进步凸显了现有开源注释科学语料库的局限性，这些语料库在数量和质量上通常都不足。针对生物医学知识复杂层次结构所带来的挑战，我们提出了一种面向LLM训练的生物医学领域科学语料库提炼的知识驱动多智能体框架。我们的方法的核心是一个协作的多智能体架构，其中每个智能体由医学主题标题（MeSH）层次结构指导，协同工作，自主提取、合成和自我评估来自大量科学文献的高质量文本数据。这些智能体共同生成和精炼特定领域的问答对，确保全面覆盖并与生物医学本体论保持一致，同时最大限度地减少人工参与。广泛的实验结果表明，在我们多智能体提炼的数据集上训练的语言模型在生物医学问答任务中取得了显著的改进，超过了强大的生命科学LLM基准测试和先进的专有模型。值得注意的是，我们的AI就绪数据集使Llama3-70B能够超越GPT-4的MedPrompt和Med-PaLM-2，尽管它们的规模更大。详细的消融研究和案例分析进一步验证了框架中每个智能体的有效性及其协同作用，突出了多智能体协作在生物医学LLM训练中的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19565v1">PDF</a> 22 pages, Large Language Model, Agentic AI, Dataset Distillation,   Multi-agent Collaboration</p>
<p><strong>Summary</strong>：针对大型语言模型在生物医学研究中的快速进步，现有开源注释科学语料库的局限性日益凸显，其数量和质量均不足。为此，我们提出了一种面向生物医学领域大型语言模型训练的知识驱动多智能体框架，用于科学语料库提炼。该框架的核心是协作式多智能体架构，各智能体以医学主题标题（MeSH）层次结构为指导，协同工作，自主提取、合成和自我评价高质量文本数据。实验结果表明，使用该框架提炼的数据集训练的模型在生物医学问答任务中有显著提升，优于生命科学大型语言模型基准模型和高级专有模型。尤其是我们的AI就绪数据集使Llama3-70B超越了GPT-4。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>大型语言模型在生物医学研究中的应用凸显出现有开源注释科学语料库的不足。</li>
<li>提出了一种知识驱动的多智能体框架，用于生物医学领域的大型语言模型训练。</li>
<li>框架中的智能体以医学主题标题（MeSH）层次结构为指导，协同工作。</li>
<li>智能体能自主提取、合成和自我评价高质量文本数据，生成精炼的域特定问答对。</li>
<li>实验结果表明，使用该框架的数据集训练的模型在生物医学问答任务中表现优异。</li>
<li>与其他强大的模型和基准进行比较，验证了该框架的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19565">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-566f03da6f53814cf299ec890c70eef9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be7808b803999dffd75289428e3935d1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="AndroidGen-Building-an-Android-Language-Agent-under-Data-Scarcity"><a href="#AndroidGen-Building-an-Android-Language-Agent-under-Data-Scarcity" class="headerlink" title="AndroidGen: Building an Android Language Agent under Data Scarcity"></a>AndroidGen: Building an Android Language Agent under Data Scarcity</h2><p><strong>Authors:Hanyu Lai, Junjie Gao, Xiao Liu, Yifan Xu, Shudan Zhang, Yuxiao Dong, Jie Tang</strong></p>
<p>Large language models have opened up a world of possibilities for various NLP tasks, sparking optimism for the future. Despite their potential, LLMs have yet to be widely used as agents on real mobile devices. The main challenge is the need for high-quality data sources. Time constraints and labor intensity often hinder human annotation. On the other hand, existing LLMs exhibit inadequate completion rates and need a robust data filtration strategy. Given these challenges, we develop a framework called AndroidGen to enhance the capabilities of LLM-based agents under data scarcity. In addition, we leverage AndroidGen to collect trajectories given human tasks and train open-source LLMs on these trajectories to develop an open-source mobile agent without manually labeled trajectories. We extensively evaluate AndroidGen with AndroidWorld, AitW, and various popular applications, demonstrating its improvements and revealing potential areas for future improvement. Code, model, and data are available at <a target="_blank" rel="noopener" href="https://github.com/THUDM/AndroidGen">https://github.com/THUDM/AndroidGen</a>. </p>
<blockquote>
<p>大型语言模型为各种NLP任务打开了可能性的大门，为未来带来了希望。尽管具有潜力，但大型语言模型尚未被广泛应用为真实移动设备上的代理。主要挑战在于需要高质量的数据源。时间限制和劳动强度经常阻碍人工标注。另一方面，现有的大型语言模型表现出较低的完成率，需要强大的数据过滤策略。针对这些挑战，我们开发了一个名为AndroidGen的框架，以提高在数据稀缺情况下基于大型语言模型的代理的能力。此外，我们利用AndroidGen收集人类任务的轨迹，并在这些轨迹上训练开源的大型语言模型，从而开发出无需手动标注轨迹的开源移动代理。我们在AndroidWorld、AitW和各种流行应用程序上全面评估了AndroidGen，展示了其改进之处并揭示了未来改进的领域。代码、模型和数据可在<a target="_blank" rel="noopener" href="https://github.com/THUDM/AndroidGen%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/THUDM/AndroidGen找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19298v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型为各种自然语言处理任务开启了新的可能，但对未来充满期待的同时，也存在诸多挑战。特别是在真实移动设备上的使用，由于高质量数据源的需求以及时间约束和人工标注的劳动强度，大型语言模型的完成率尚不理想。针对这些挑战，我们开发了一个名为AndroidGen的框架，旨在提高基于大型语言模型的代理在数据稀缺环境下的能力。此外，我们还利用AndroidGen收集人类任务轨迹，并在这些轨迹上训练开源大型语言模型，开发出无需手动标注轨迹的开源移动代理。经过AndroidWorld、AitW和各种流行应用的广泛评估，证明了其改进效果并揭示了未来改进方向。相关代码、模型和数据可通过<a target="_blank" rel="noopener" href="https://github.com/THUDM/AndroidGen%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/THUDM/AndroidGen获取。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型为NLP任务带来新机遇，但对在真实移动设备上的应用存在挑战。</li>
<li>高质量数据源的需求以及时间约束和人工标注的劳动强度是主要挑战。</li>
<li>现有大型语言模型的完成率有待提高，需要更完善的数据过滤策略。</li>
<li>开发了一个名为AndroidGen的框架，旨在提高大型语言模型在移动设备上的性能。</li>
<li>利用AndroidGen收集人类任务轨迹，训练出无需手动标注轨迹的开源移动代理。</li>
<li>AndroidGen经过广泛评估，包括在AndroidWorld、AitW和各种流行应用上的测试。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19298">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e3de03b1c03887e4b3b9ddbc455819f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18344a904ad7ecce3ce28f594a807904.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-443ce413aeb1b579c48d6f2602355602.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95a346d2f3eb7b5af5473528135fbe12.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-70d57ad4838452fa10a98208274a35c3.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MASR-Self-Reflective-Reasoning-through-Multimodal-Hierarchical-Attention-Focusing-for-Agent-based-Video-Understanding"><a href="#MASR-Self-Reflective-Reasoning-through-Multimodal-Hierarchical-Attention-Focusing-for-Agent-based-Video-Understanding" class="headerlink" title="MASR: Self-Reflective Reasoning through Multimodal Hierarchical   Attention Focusing for Agent-based Video Understanding"></a>MASR: Self-Reflective Reasoning through Multimodal Hierarchical   Attention Focusing for Agent-based Video Understanding</h2><p><strong>Authors:Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen, Xiangbing Meng</strong></p>
<p>Even in the era of rapid advances in large models, video understanding remains a highly challenging task. Compared to texts or images, videos commonly contain more information with redundancy, requiring large models to properly allocate attention at a global level for comprehensive and accurate understanding. To address this, we propose a Multimodal hierarchical Attention focusing Self-reflective Reasoning (MASR) framework for agent-based video understanding. The key innovation lies in its ability to detect and prioritize segments of videos that are highly relevant to the query. Firstly, MASR realizes Multimodal Coarse-to-fine Relevance Sensing (MCRS) which enhances the correlation between the acquired contextual information and the query. Secondly, MASR employs Dilated Temporal Expansion (DTE) to mitigate the risk of missing crucial details when extracting semantic information from the focused frames selected through MCRS. By iteratively applying MCRS and DTE in the self-reflective reasoning process, MASR is able to adaptively adjust the attention to extract highly query-relevant context and therefore improve the response accuracy. In the EgoSchema dataset, MASR achieves a remarkable 5% performance gain over previous leading approaches. In the Next-QA and IntentQA datasets, it outperforms the state-of-the-art standards by 0.2% and 0.3% respectively. In the Video-MME dataset that contains long-term videos, MASR also performs better than other agent-based methods. </p>
<blockquote>
<p>即使在大型模型飞速发展的时代，视频理解仍然是一项极具挑战性的任务。相比于文本或图像，视频通常包含更多冗余信息，需要大型模型在全局范围内适当地分配注意力，以实现全面而准确的视频理解。为了解决这一问题，我们提出了基于多模态层次化注意力的自我反思推理（MASR）框架，用于基于主体的视频理解。其主要创新之处在于能够检测和优先处理与查询高度相关的视频片段。首先，MASR实现了多模态粗到细的相关性感知（MCRS），增强了获取上下文信息与查询之间的相关性。其次，MASR采用膨胀时间扩展（DTE）策略，以缓解在通过MCRS选择的关键帧中提取语义信息时遗漏重要细节的风险。通过自我反思推理过程中迭代应用MCRS和DTE，MASR能够自适应地调整注意力以提取高度相关的上下文信息，从而提高响应准确性。在EgoSchema数据集上，MASR相较于之前领先的方法取得了5%的性能提升。在Next-QA和IntentQA数据集上，其性能超过了最新标准分别为0.2%和0.3%。对于包含长期视频的视频MME数据集，MASR在基于主体的方法中表现也更好。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.17213v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了在视频理解领域的一个挑战，即视频信息冗余度高，需要全局注意力分配。为此，提出了一种基于多模态层次注意力的自反思推理（MASR）框架，用于基于代理的视频理解。MASR通过实现多模态粗到细的相关性感知（MCRS）和膨胀时间扩展（DTE）来优化视频段的选择和语义信息的提取，从而提高了查询响应的准确性。在多个数据集上的实验结果表明，MASR在视频理解方面取得了显著的性能提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视频理解面临信息冗余度高的问题，需要大模型进行全局注意力分配。</li>
<li>提出了一种基于多模态层次注意力的自反思推理（MASR）框架，用于解决该问题。</li>
<li>MASR通过实现多模态粗到细的相关性感知（MCRS），增强获取上下文信息与查询之间的相关性。</li>
<li>MASR采用膨胀时间扩展（DTE）方法，减少在提取关键语义信息时遗漏重要细节的风险。</li>
<li>自反思推理过程中迭代应用MCRS和DTE，使MASR能够自适应调整注意力以提取与查询高度相关的上下文。</li>
<li>在EgoSchema数据集上，MASR较之前的方法实现了5%的性能提升。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.17213">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-19803cf55b0f2fd085a0cabdc52e0c9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44350aade99be5a773d79f76671a9c0f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bedc8630850d6b654da8a09f189de34.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7b4e01fa007f35270d8edd94f8a961d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54157ae2989359e849efd86647602e23.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CHARMS-A-Cognitive-Hierarchical-Agent-for-Reasoning-and-Motion-Stylization-in-Autonomous-Driving"><a href="#CHARMS-A-Cognitive-Hierarchical-Agent-for-Reasoning-and-Motion-Stylization-in-Autonomous-Driving" class="headerlink" title="CHARMS: A Cognitive Hierarchical Agent for Reasoning and Motion   Stylization in Autonomous Driving"></a>CHARMS: A Cognitive Hierarchical Agent for Reasoning and Motion   Stylization in Autonomous Driving</h2><p><strong>Authors:Jingyi Wang, Duanfeng Chu, Zejian Deng, Liping Lu, Jinxiang Wang, Chen Sun</strong></p>
<p>To address the challenge of insufficient interactivity and behavioral diversity in autonomous driving decision-making, this paper proposes a Cognitive Hierarchical Agent for Reasoning and Motion Stylization (CHARMS). By leveraging Level-k game theory, CHARMS captures human-like reasoning patterns through a two-stage training pipeline comprising reinforcement learning pretraining and supervised fine-tuning. This enables the resulting models to exhibit diverse and human-like behaviors, enhancing their decision-making capacity and interaction fidelity in complex traffic environments. Building upon this capability, we further develop a scenario generation framework that utilizes the Poisson cognitive hierarchy theory to control the distribution of vehicles with different driving styles through Poisson and binomial sampling. Experimental results demonstrate that CHARMS is capable of both making intelligent driving decisions as an ego vehicle and generating diverse, realistic driving scenarios as environment vehicles. The code for CHARMS is released at <a target="_blank" rel="noopener" href="https://github.com/chuduanfeng/CHARMS">https://github.com/chuduanfeng/CHARMS</a>. </p>
<blockquote>
<p>本文提出了一个用于推理和运动风格化的认知层次代理（CHARMS），以解决自动驾驶决策中交互性和行为多样性不足的挑战。CHARMS通过利用Level-k博弈理论，通过强化学习预训练和监督精细调整的两阶段训练管道，捕捉人类类似的推理模式。这使得模型能够表现出多样化和人类类似的行为，提高其在复杂交通环境中的决策能力和交互真实性。在此基础上，我们进一步开发了一个情景生成框架，该框架利用Poisson认知层次理论，通过Poisson和二项抽样来控制不同驾驶风格的车辆分布。实验结果表明，CHARMS既能够作为自我车辆做出智能驾驶决策，又能够生成多样、现实的驾驶场景作为环境车辆。CHARMS的代码已发布在<a target="_blank" rel="noopener" href="https://github.com/chuduanfeng/CHARMS%E3%80%82">https://github.com/chuduanfeng/CHARMS。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02450v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种名为CHARMS的认知分层代理推理与运动风格化方法，用于解决自动驾驶决策制定中交互性和行为多样性不足的问题。利用Level-k博弈理论，CHARMS通过包括强化学习预训练和监督微调的两阶段训练流程，模拟人类推理模式。这使得模型能够展现出多样化和人类化的行为，提升其决策能力和在复杂交通环境中的交互真实性。此外，研究还开发了一个基于Poisson认知层次理论的场景生成框架，通过Poisson和二项采样控制不同驾驶风格的车辆分布。实验结果表明，CHARMS不仅能作为自主车辆做出智能驾驶决策，还能生成多样且现实的驾驶场景。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CHARMS利用Level-k游戏理论模拟人类推理模式，提升自动驾驶模型的决策能力。</li>
<li>通过强化学习预训练和监督微调的两阶段训练流程，CHARMS模型展现出多样化和人类化的行为。</li>
<li>CHARMS提高了模型在复杂交通环境中的交互真实性。</li>
<li>基于Poisson认知层次理论开发的场景生成框架能控制不同驾驶风格的车辆分布。</li>
<li>CHARMS能够作为自主车辆做出智能决策。</li>
<li>CHARMS生成的驾驶场景具有多样性和现实性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02450">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-93484be6bbc4083ac84890ec7a9f8517.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-588210c94e110bdc0a6e6915506095d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed576ee8967e3ab8eb9a59eb0aece167.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abaa3166fa39117b1255a6f950642755.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c74ce3f45e150cf78686e60664f531c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29c80465f4045f45f23190637da87b67.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="VideoGen-Eval-Agent-based-System-for-Video-Generation-Evaluation"><a href="#VideoGen-Eval-Agent-based-System-for-Video-Generation-Evaluation" class="headerlink" title="VideoGen-Eval: Agent-based System for Video Generation Evaluation"></a>VideoGen-Eval: Agent-based System for Video Generation Evaluation</h2><p><strong>Authors:Yuhang Yang, Ke Fan, Shangkun Sun, Hongxiang Li, Ailing Zeng, FeiLin Han, Wei Zhai, Wei Liu, Yang Cao, Zheng-Jun Zha</strong></p>
<p>The rapid advancement of video generation has rendered existing evaluation systems inadequate for assessing state-of-the-art models, primarily due to simple prompts that cannot showcase the model’s capabilities, fixed evaluation operators struggling with Out-of-Distribution (OOD) cases, and misalignment between computed metrics and human preferences. To bridge the gap, we propose VideoGen-Eval, an agent evaluation system that integrates LLM-based content structuring, MLLM-based content judgment, and patch tools designed for temporal-dense dimensions, to achieve a dynamic, flexible, and expandable video generation evaluation. Additionally, we introduce a video generation benchmark to evaluate existing cutting-edge models and verify the effectiveness of our evaluation system. It comprises 700 structured, content-rich prompts (both T2V and I2V) and over 12,000 videos generated by 20+ models, among them, 8 cutting-edge models are selected as quantitative evaluation for the agent and human. Extensive experiments validate that our proposed agent-based evaluation system demonstrates strong alignment with human preferences and reliably completes the evaluation, as well as the diversity and richness of the benchmark. </p>
<blockquote>
<p>视频生成的快速发展使得现有评估系统无法评估最前沿模型的状态，这主要是由于无法展示模型能力的简单提示、处理离群值（OOD）案例时的固定评估操作以及计算指标与人类偏好之间的不一致。为了缩小这一差距，我们提出了VideoGen-Eval评估系统，该系统集成了基于LLM的内容结构、基于MLLM的内容判断以及针对时间密集维度的专用工具，以实现动态、灵活和可扩展的视频生成评估。此外，我们还引入了一个视频生成基准测试，以评估现有的顶尖模型并验证我们的评估系统的有效性。该基准测试包含700个结构清晰、内容丰富的提示（包括T2V和I2V），以及由20多个模型生成的超过12000个视频，其中选择了8个顶尖模型进行定量评估。大量实验验证，我们提出的基于代理的评估系统与人类偏好高度一致，并能可靠地完成评估，同时基准测试具有丰富的多样性和丰富性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.23452v2">PDF</a> project:<a target="_blank" rel="noopener" href="https://github.com/AILab-CVC/VideoGen-Eval">https://github.com/AILab-CVC/VideoGen-Eval</a></p>
<p><strong>Summary</strong></p>
<p>视频生成技术的快速发展使得现有的评估系统无法对先进技术模型进行有效的评估，主要表现在无法展示模型能力、难以处理离群值以及计算指标与人类偏好之间的不匹配。为此，我们提出了VideoGen-Eval评估系统，该系统融合了基于大型语言模型的内容结构、基于多模态语言模型的内容判断以及针对时序密集维度的工具设计，实现了动态、灵活和可扩展的视频生成评估。此外，我们还推出了视频生成基准测试，以评估现有尖端模型并验证我们的评估系统的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视频生成技术的快速发展导致现有评估系统不足。</li>
<li>现有评估系统无法充分展示模型能力、难以处理离群值，且计算指标与人类偏好存在不匹配。</li>
<li>VideoGen-Eval评估系统融合了大型语言模型和多模态语言模型技术。</li>
<li>VideoGen-Eval系统设计了针对时序密集维度的工具，以实现动态、灵活和可扩展的视频生成评估。</li>
<li>推出了视频生成基准测试，包括结构化、内容丰富的提示和大量生成视频，以评估现有模型。</li>
<li>VideoGen-Eval系统与人类偏好强相关，并能可靠地完成评估。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.23452">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-55bace167ceb1af0fbd0567bee1455ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de0c43b8fdc79e613ba030117e7594c3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e21ddf2a37f59506f63295f87ba0c4cf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-116ea864060c149278490987654d1eac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ce17a14bad2fc44571dcd95458205a82.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-86758843ab9a96a7affbf497ec8f19db.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Fast-algorithm-for-centralized-multi-agent-maze-exploration"><a href="#Fast-algorithm-for-centralized-multi-agent-maze-exploration" class="headerlink" title="Fast algorithm for centralized multi-agent maze exploration"></a>Fast algorithm for centralized multi-agent maze exploration</h2><p><strong>Authors:Bojan Crnković, Stefan Ivić, Mila Zovko</strong></p>
<p>Recent advances in robotics have paved the way for robots to replace humans in perilous situations, such as searching for victims in burning buildings, in earthquake-damaged structures, in uncharted caves, traversing minefields or patrolling crime-ridden streets. These challenges can be generalized as problems where agents have to explore unknown mazes. We propose a cooperative multi-agent system of automated mobile agents for exploring unknown mazes and localizing stationary targets. The Heat Equation-Driven Area Coverage (HEDAC) algorithm for maze exploration employs a potential field to guide the exploration of the maze and integrates cooperative behaviors of the agents such as collision avoidance, coverage coordination, and path planning. In contrast to previous applications for continuous static domains, we adapt the HEDAC method for mazes on expanding rectilinear grids. The proposed algorithm guarantees the exploration of the entire maze and can ensure the avoidance of collisions and deadlocks. Moreover, this is the first application of the HEDAC algorithm to domains that expand over time. To cope with the dynamically changing domain, succesive over-relaxation (SOR) iterative linear solver has been adapted and implemented, which significantly reduced the computational complexity of the presented algorithm when compared to standard direct and iterative linear solvers. The results highlight significant improvements and show the applicability of the algorithm in different mazes. They confirm its robustness, adaptability, scalability and simplicity, which enables centralized parallel computation to control multiple agents&#x2F;robots in the maze. </p>
<blockquote>
<p>近年来，机器人技术的进展为机器人在危险情况下替代人类提供了可能，例如在燃烧的建筑物、地震受损的结构、未知的洞穴、穿越地雷区或巡逻犯罪多发街道中寻找受害者。这些挑战可以概括为代理需要在未知迷宫中寻找的问题。我们提出了一种用于探索未知迷宫并定位静止目标的自动化移动代理的合作多代理系统。迷宫探索的热方程驱动区域覆盖（HEDAC）算法利用潜在领域来引导迷宫的探索，并整合了代理的合作行为，如避碰、覆盖协调和路径规划。与之前连续静态领域的应用不同，我们适应了扩展直线网格迷宫的HEDAC方法。所提出的算法可以保证整个迷宫的探索，并确保避免碰撞和死锁。此外，这是HEDAC算法首次应用于随时间扩展的领域。为了应对动态变化的领域，相继松弛（SOR）迭代线性求解器被适应和实施，与标准直接和迭代线性求解器相比，这大大降低了所提出算法的计算复杂性。结果突出了显著的改进，并显示了该算法在不同迷宫中的应用性。它们证实了其稳健性、适应性、可扩展性和简单性，这能够实现集中式并行计算以控制迷宫中的多个代理&#x2F;机器人。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.02121v2">PDF</a> Improved manuscript</p>
<p><strong>Summary</strong><br>     近期机器人技术的进步使得机器人在危险场景如火灾搜救、地震救援、洞穴探索、穿越雷区及巡逻犯罪多发街区等方面替代人类成为可能。本文提出一种用于探索未知迷宫并定位静止目标的合作多智能体系统，采用热方程驱动区域覆盖算法进行迷宫探索，通过势能场引导探索，集成智能体间的合作行为如防撞、覆盖协调及路径规划等。文章将该算法扩展到动态扩展的直线网格迷宫上，确保了迷宫的全覆盖并避免碰撞和死锁问题。该方法首次应用于随时间变化的领域，采用连续过度松弛迭代线性求解器降低了算法的计算复杂度。结果证明了该算法的稳健性、适应性、可扩展性和简单性，可实现多智能体&#x2F;机器人在迷宫中的集中并行计算控制。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>机器人技术已发展到可替代人类在危险场景中进行任务，如迷宫探索等。</li>
<li>提出一种合作多智能体系统用于探索未知迷宫并定位静止目标。</li>
<li>采用热方程驱动区域覆盖算法进行迷宫探索，包含势能场引导和智能体间的合作行为。</li>
<li>将算法扩展到动态扩展的直线网格迷宫上，确保全覆盖并避免碰撞和死锁。</li>
<li>该方法是首次应用于随时间变化的领域。</li>
<li>采用连续过度松弛迭代线性求解器降低了算法的计算复杂度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.02121">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3bc62ddf3a7d289aa5e62aa26b414b50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bac7a2dbde1f7b07f021b30e8932fb60.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f8dc8e20ec8d3c8d9894f19128d840df.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-30/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-68629da72c57f0f6036e4e1cc6636951.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-04-30  Masked Language Prompting for Generative Data Augmentation in Few-shot   Fashion Style Recognition
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-30/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-02d9999612e01b82dcf6e5fd4521e113.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-04-30  From Concept to Practice an Automated LLM-aided UVM Machine for RTL   Verification
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30191.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
