<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-20  AutoTool Efficient Tool Selection for Large Language Model Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d67a74f417dab498877371d362b371ae')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    68 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-20-æ›´æ–°"><a href="#2025-11-20-æ›´æ–°" class="headerlink" title="2025-11-20 æ›´æ–°"></a>2025-11-20 æ›´æ–°</h1><h2 id="AutoTool-Efficient-Tool-Selection-for-Large-Language-Model-Agents"><a href="#AutoTool-Efficient-Tool-Selection-for-Large-Language-Model-Agents" class="headerlink" title="AutoTool: Efficient Tool Selection for Large Language Model Agents"></a>AutoTool: Efficient Tool Selection for Large Language Model Agents</h2><p><strong>Authors:Jingyi Jia, Qinbin Li</strong></p>
<p>Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„å‡ºç°å·²ç»æˆä¸ºåˆ©ç”¨LLMçš„æ¨ç†å’Œå†³ç­–èƒ½åŠ›è‡ªåŠ¨åŒ–å¤æ‚ä»»åŠ¡çš„å¼ºå¤§å·¥å…·ã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†æ¡†æ¶çš„ä¸»è¦ç“¶é¢ˆåœ¨äºå·¥å…·é€‰æ‹©çš„é«˜æ¨ç†æˆæœ¬ï¼Œç‰¹åˆ«æ˜¯åœ¨åƒReActè¿™æ ·çš„æ–¹æ³•ä¸­ï¼Œåå¤è°ƒç”¨LLMæ¥ç¡®å®šæ¯ä¸€æ­¥åº”ä½¿ç”¨å“ªä¸ªå·¥å…·ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†AutoToolï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå›¾çš„æ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨ä¸€ä¸ªå…³é”®çš„ç»éªŒè§‚å¯Ÿæ¥ç»•è¿‡åå¤çš„LLMæ¨ç†ï¼šå·¥å…·ä½¿ç”¨æƒ¯æ€§â€”â€”å·¥å…·è°ƒç”¨çš„è¶‹åŠ¿éµå¾ªå¯é¢„æµ‹çš„é¡ºåºæ¨¡å¼ã€‚AutoToolæ ¹æ®å†å²ä»£ç†è½¨è¿¹æ„å»ºæœ‰å‘å›¾ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨å·¥å…·ï¼Œè¾¹æ•æ‰è½¬æ¢æ¦‚ç‡ï¼Œæœ‰æ•ˆåœ°å¯¹å·¥å…·é€‰æ‹©ä¸­çš„æƒ¯æ€§è¿›è¡Œå»ºæ¨¡ã€‚å®ƒè¿›ä¸€æ­¥æ•´åˆå‚æ•°å±‚é¢çš„ä¿¡æ¯æ¥å®Œå–„å·¥å…·è¾“å…¥ç”Ÿæˆã€‚é€šè¿‡éå†è¿™ç§ç»“æ„åŒ–è¡¨ç¤ºï¼ŒAutoToolå¯ä»¥é«˜æ•ˆé€‰æ‹©å·¥å…·å’Œå‚æ•°ï¼Œå¯¹LLMæ¨ç†çš„ä¾èµ–åº¦é™åˆ°æœ€ä½ã€‚åœ¨å¤šç§ä»£ç†ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒAutoToolå°†æ¨ç†æˆæœ¬é™ä½äº†é«˜è¾¾30%ï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰æ€§çš„ä»»åŠ¡å®Œæˆç‡ï¼Œä¸ºæ¨ç†å¯†é›†å‹æ¡†æ¶æä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„å¢å¼ºã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å°†ç»Ÿè®¡ç»“æ„çº³å…¥LLMä»£ç†è®¾è®¡çš„æ‰¿è¯ºï¼Œä»¥æé«˜æ•ˆç‡è€Œä¸ç‰ºç‰²æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14650v1">PDF</a> Accepted by AAAI 2026, 18 pages, 11 figures, Code: <a target="_blank" rel="noopener" href="https://github.com/jiajingyyyyyy/AutoTool">https://github.com/jiajingyyyyyy/AutoTool</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†é€šè¿‡åˆ©ç”¨LLMçš„æ¨ç†å’Œå†³ç­–èƒ½åŠ›è‡ªåŠ¨åŒ–å¤æ‚ä»»åŠ¡ï¼Œå·²æˆä¸ºå¼ºå¤§çš„å·¥å…·ã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†æ¡†æ¶çš„ä¸»è¦ç“¶é¢ˆåœ¨äºå·¥å…·é€‰æ‹©çš„é«˜æ¨ç†æˆæœ¬ï¼Œå°¤å…¶æ˜¯åœ¨ReActç­‰æ–¹æ³•ä¸­ï¼Œä¼šåå¤è°ƒç”¨LLMæ¥ç¡®å®šæ¯ä¸€æ­¥åº”ä½¿ç”¨å“ªä¸ªå·¥å…·ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºAutoToolï¼Œä¸€ç§åŸºäºå›¾çš„æ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨å·¥å…·ä½¿ç”¨æƒ¯æ€§è¿™ä¸€å…³é”®è§‚å¯Ÿç»“æœæ¥ç»•è¿‡åå¤çš„LLMæ¨ç†ã€‚AutoToolæ ¹æ®å†å²ä»£ç†è½¨è¿¹æ„å»ºæœ‰å‘å›¾ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨å·¥å…·ï¼Œè¾¹ä»£è¡¨è¿‡æ¸¡æ¦‚ç‡ï¼Œæœ‰æ•ˆåœ°å¯¹å·¥å…·é€‰æ‹©çš„æƒ¯æ€§è¿›è¡Œå»ºæ¨¡ã€‚å®ƒè¿˜æ•´åˆå‚æ•°çº§åˆ«ä¿¡æ¯æ¥ä¼˜åŒ–å·¥å…·è¾“å…¥ç”Ÿæˆã€‚é€šè¿‡éå†æ­¤ç»“æ„åŒ–è¡¨ç¤ºï¼ŒAutoToolèƒ½å¤Ÿé«˜æ•ˆé€‰æ‹©å·¥å…·å’Œå‚æ•°ï¼Œå¯¹LLMæ¨ç†çš„ä¾èµ–åº¦é™åˆ°æœ€ä½ã€‚åœ¨å¤šç§ä»£ç†ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒAutoToolå°†æ¨ç†æˆæœ¬é™ä½äº†é«˜è¾¾30%ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›çš„ä»»åŠ¡å®Œæˆç‡ï¼Œä¸ºæ¨ç†å¯†é›†å‹æ¡†æ¶æä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„å¢å¼ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨è‡ªåŠ¨åŒ–å¤æ‚ä»»åŠ¡æ–¹é¢å…·æœ‰å¼ºå¤§èƒ½åŠ›ã€‚</li>
<li>å½“å‰LLMä»£ç†é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯å·¥å…·é€‰æ‹©çš„é«˜æ¨ç†æˆæœ¬ã€‚</li>
<li>AutoToolæ˜¯ä¸€ç§æ–°å‹çš„å›¾æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨å·¥å…·ä½¿ç”¨æƒ¯æ€§æ¥è§£å†³é«˜æ¨ç†æˆæœ¬é—®é¢˜ã€‚</li>
<li>AutoToolé€šè¿‡æ„å»ºæœ‰å‘å›¾æ¥æ¨¡æ‹Ÿå·¥å…·é€‰æ‹©çš„æƒ¯æ€§ï¼Œè¯¥å›¾ç”±å†å²ä»£ç†è½¨è¿¹ç»„æˆã€‚</li>
<li>AutoToolé€šè¿‡æ•´åˆå‚æ•°çº§åˆ«ä¿¡æ¯æ¥ä¼˜åŒ–å·¥å…·è¾“å…¥ç”Ÿæˆã€‚</li>
<li>AutoToolèƒ½é«˜æ•ˆé€‰æ‹©å·¥å…·å’Œå‚æ•°ï¼Œé™ä½å¯¹LLMæ¨ç†çš„ä¾èµ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14650">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0fefa04a2c46e19fbbee469599850beb" align="middle">
<img src="https://picx.zhimg.com/v2-81a51b25ce91875cad1a2b89c7c3ec7e" align="middle">
<img src="https://picx.zhimg.com/v2-3496eb1fbf801efbb3bf9b66489da9bf" align="middle">
<img src="https://picx.zhimg.com/v2-c8f075ee0c424f7d79e66d53b89f8c88" align="middle">
<img src="https://picx.zhimg.com/v2-42c76b6b578f95415469e7baa94f5e72" align="middle">
<img src="https://picx.zhimg.com/v2-d209a3f04482afdefedee98d5ccc760c" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Enhancing-Agentic-Autonomous-Scientific-Discovery-with-Vision-Language-Model-Capabilities"><a href="#Enhancing-Agentic-Autonomous-Scientific-Discovery-with-Vision-Language-Model-Capabilities" class="headerlink" title="Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities"></a>Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities</h2><p><strong>Authors:Kahaan Gandhi, Boris Bolliet, Inigo Zubeldia</strong></p>
<p>We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: <a target="_blank" rel="noopener" href="https://github.com/CMBAgents/cmbagent">https://github.com/CMBAgents/cmbagent</a></p>
<blockquote>
<p>æˆ‘ä»¬å±•ç¤ºäº†ç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¼•å¯¼çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¦‚ä½•æå‡ç«¯åˆ°ç«¯çš„è‡ªä¸»ç§‘å­¦å‘ç°èƒ½åŠ›ã€‚é€šè¿‡å°†å›¾è¡¨è§†ä¸ºå¯éªŒè¯çš„æ£€æŸ¥ç‚¹ï¼ŒVLMä½œä¸ºè¯„åˆ¤å‘˜æ ¹æ®åŠ¨æ€ç”Ÿæˆçš„é¢†åŸŸç‰¹å®šè§„åˆ™å¯¹å›¾è¡¨è¿›è¡Œè¯„ä¼°ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿçº æ­£è‡ªå·±çš„é”™è¯¯å¹¶å®æ—¶å¼•å¯¼æ¢ç´¢æ€§æ•°æ®åˆ†æã€‚å®‡å®™å­¦å’Œå¤©ä½“åŒ–å­¦çš„æ¡ˆä¾‹ç ”ç©¶è¯æ˜äº†ä»é”™è¯¯çš„æ¨ç†è·¯å¾„ä¸­æ¢å¤ä»¥åŠé€‚åº”æ–°æ•°æ®é›†çš„èƒ½åŠ›ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚åœ¨é¢å‘æ•°æ®é©±åŠ¨å‘ç°çš„10é¡¹åŸºå‡†æµ‹è¯•ä¸­ï¼Œä¸åªä½¿ç”¨ä»£ç çš„0.2-0.3åˆ†å’Œä»£ç ä¸æ–‡æœ¬çš„åŸºå‡†çº¿å¾—åˆ†ï¼ˆ0.4-0.5ï¼‰ç›¸æ¯”ï¼Œä½¿ç”¨VLMå¢å¼ºçš„ç³»ç»Ÿå¾—åˆ†è¾¾åˆ°0.7-0.8ï¼ŒåŒæ—¶æä¾›å¯å®¡æ ¸çš„æ¨ç†è½¨è¿¹ï¼Œæé«˜äº†å¯è§£é‡Šæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/CMBAgents/cmbagent%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/CMBAgents/cmbagentè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14631v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šä»¥è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ºå¼•å¯¼çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¯æå‡ç«¯åˆ°ç«¯çš„è‡ªä¸»ç§‘å­¦å‘ç°èƒ½åŠ›ã€‚é€šè¿‡è§†å›¾åƒä½œä¸ºå¯éªŒè¯çš„æŸ¥æ£€ç‚¹ï¼Œé‡‡ç”¨â€œæ¨¡å‹è¯„åˆ¤å‘˜â€ï¼ˆVLM-as-a-judgeï¼‰æ–¹å¼è¯„ä¼°å›¾è¡¨ä¸åŠ¨æ€ç”Ÿæˆçš„ç‰¹å®šé¢†åŸŸå‡†åˆ™çš„ä¸€è‡´æ€§ï¼Œæ™ºèƒ½ä½“å¯çº æ­£è‡ªèº«é”™è¯¯å¹¶å®æ—¶å¼•å¯¼æ¢ç´¢æ€§æ•°æ®åˆ†æã€‚åœ¨å®‡å®™å­¦å’Œå¤©ä½“åŒ–å­¦çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œè¯æ˜äº†å…¶å¯ä»é”™è¯¯çš„æ¨ç†è·¯å¾„ä¸­æ¢å¤å¹¶é€‚åº”æ–°æ•°æ®é›†è€Œæ— éœ€äººå·¥å¹²é¢„ã€‚åœ¨æ•°æ®é©±åŠ¨å‘ç°çš„10é¡¹åŸºå‡†æµ‹è¯•ä¸­ï¼Œå¢å¼ºå‹VLMç³»ç»Ÿçš„é€šè¿‡ç‡è¾¾åˆ°äº†0.7è‡³0.8ï¼Œç›¸è¾ƒäºçº¯ä»£ç åŸºçº¿ï¼ˆ0.2è‡³0.3ï¼‰å’Œä»£ç æ–‡æœ¬åŸºçº¿ï¼ˆ0.4è‡³0.5ï¼‰è¡¨ç°ä¼˜è¶Šï¼ŒåŒæ—¶æä¾›å¯å®¡æ ¸çš„æ¨ç†è½¨è¿¹ä»¥æé«˜è§£é‡Šæ€§ã€‚ç›¸å…³ç ”ç©¶è¯¦æƒ…è®¿é—®é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://github.com/CMBAgents/cmbagent">é¡¹ç›®é“¾æ¥åœ°å€</a>ã€‚ </p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå€ŸåŠ©è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æé«˜äº†è‡ªä¸»ç§‘å­¦å‘ç°çš„æ•ˆç‡ã€‚</li>
<li>VLMèƒ½å°†å›¾åƒä½œä¸ºå¯éªŒè¯çš„æŸ¥æ£€ç‚¹ï¼Œè¯„ä¼°å›¾è¡¨ä¸ç‰¹å®šé¢†åŸŸå‡†åˆ™çš„ä¸€è‡´æ€§ã€‚</li>
<li>æ™ºèƒ½ä½“å…·å¤‡è‡ªæˆ‘çº æ­£é”™è¯¯çš„èƒ½åŠ›ï¼Œå¹¶å¯åœ¨æ•°æ®åˆ†æä¸­å®æ—¶å¯¼èˆªã€‚</li>
<li>åœ¨å®‡å®™å­¦å’Œå¤©ä½“åŒ–å­¦é¢†åŸŸçš„ç ”ç©¶å±•ç¤ºäº†è¯¥ç³»ç»Ÿçš„å®¹é”™æ€§å’Œå¯¹æ–°æ•°æ®é›†çš„é€‚åº”æ€§ã€‚</li>
<li>åœ¨æ•°æ®é©±åŠ¨å‘ç°çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œå¢å¼ºå‹VLMç³»ç»Ÿçš„é€šè¿‡ç‡é«˜äºå…¶ä»–åŸºçº¿ç³»ç»Ÿã€‚</li>
<li>è¯¥ç³»ç»Ÿæä¾›äº†å¯å®¡æ ¸çš„æ¨ç†è½¨è¿¹ï¼Œå¢å¼ºäº†å…¶è§£é‡Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14631">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8e6eb89a8dff32a8ff27fcdf88974051" align="middle">
<img src="https://picx.zhimg.com/v2-a7b4389f8fba64a1caeab09da05cb04b" align="middle">
<img src="https://picx.zhimg.com/v2-c13f0d251fe3d600e67d029d1575d574" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Agentic-AI-Systems-in-Electrical-Power-Systems-Engineering-Current-State-of-the-Art-and-Challenges"><a href="#Agentic-AI-Systems-in-Electrical-Power-Systems-Engineering-Current-State-of-the-Art-and-Challenges" class="headerlink" title="Agentic AI Systems in Electrical Power Systems Engineering: Current State-of-the-Art and Challenges"></a>Agentic AI Systems in Electrical Power Systems Engineering: Current State-of-the-Art and Challenges</h2><p><strong>Authors:Soham Ghosh, Gaurav Mittal</strong></p>
<p>Agentic AI systems have recently emerged as a critical and transformative approach in artificial intelligence, offering capabilities that extend far beyond traditional AI agents and contemporary generative AI models. This rapid evolution necessitates a clear conceptual and taxonomical understanding to differentiate this new paradigm. Our paper addresses this gap by providing a comprehensive review that establishes a precise definition and taxonomy for â€œagentic AI,â€ with the aim of distinguishing it from previous AI paradigms. The concepts are gradually introduced, starting with a highlight of its diverse applications across the broader field of engineering. The paper then presents four detailed, state-of-the-art use case applications specifically within electrical engineering. These case studies demonstrate practical impact, ranging from an advanced agentic framework for streamlining complex power system studies and benchmarking to a novel system developed for survival analysis of dynamic pricing strategies in battery swapping stations. Finally, to ensure robust deployment, the paper provides detailed failure mode investigations. From these findings, we derive actionable recommendations for the design and implementation of safe, reliable, and accountable agentic AI systems, offering a critical resource for researchers and practitioners.</p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ä»£ç†ç³»ç»Ÿæœ€è¿‘ä½œä¸ºäººå·¥æ™ºèƒ½ä¸­çš„å…³é”®å’Œå˜é©æ€§æ–¹æ³•å‡ºç°ï¼Œæä¾›äº†è¿œè¿œè¶…å‡ºä¼ ç»Ÿäººå·¥æ™ºèƒ½ä»£ç†å’Œå½“ä»£ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹çš„èƒ½åŠ›ã€‚è¿™ç§å¿«é€Ÿè¿›åŒ–éœ€è¦æ˜ç¡®çš„æ¦‚å¿µå’Œåˆ†ç±»å­¦ç†è§£ï¼Œä»¥åŒºåˆ†è¿™ç§æ–°èŒƒå¼ã€‚æˆ‘ä»¬çš„è®ºæ–‡é€šè¿‡æä¾›å…¨é¢çš„ç»¼è¿°ï¼Œæ—¨åœ¨å»ºç«‹å¯¹â€œäººå·¥æ™ºèƒ½ä»£ç†â€çš„ç²¾ç¡®å®šä¹‰å’Œåˆ†ç±»ï¼Œä»¥å°†å…¶ä¸ä»¥å‰çš„äººå·¥æ™ºèƒ½èŒƒå¼åŒºåˆ†å¼€ã€‚è®ºæ–‡é€æ¸å¼•å…¥æ¦‚å¿µï¼Œé¦–å…ˆå¼ºè°ƒå…¶åœ¨å·¥ç¨‹é¢†åŸŸåº”ç”¨çš„å¤šæ ·æ€§ã€‚ç„¶åä»‹ç»äº†å››ä¸ªæœ€æ–°çš„ã€å‰æ²¿çš„åº”ç”¨æ¡ˆä¾‹ï¼Œä¸“é—¨ç”¨äºç”µæ°”å·¥ç¨‹é¢†åŸŸã€‚è¿™äº›æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†å®é™…åº”ç”¨å½±å“ï¼Œä»ç®€åŒ–å¤æ‚ç”µåŠ›ç³»ç»Ÿç ”ç©¶å’ŒåŸºå‡†æµ‹è¯•çš„é«˜çº§äººå·¥æ™ºèƒ½ä»£ç†æ¡†æ¶ï¼Œåˆ°ä¸ºç”µæ± äº¤æ¢ç«™çš„åŠ¨æ€å®šä»·ç­–ç•¥çš„ç”Ÿå­˜åˆ†æå¼€å‘çš„æ–°å‹ç³»ç»Ÿã€‚æœ€åï¼Œä¸ºäº†ç¡®ä¿ç¨³å¥éƒ¨ç½²ï¼Œè®ºæ–‡æä¾›äº†è¯¦ç»†çš„æ•…éšœæ¨¡å¼è°ƒæŸ¥ã€‚æ ¹æ®è¿™äº›å‘ç°ï¼Œæˆ‘ä»¬ä¸ºè®¾è®¡å’Œå®æ–½å®‰å…¨ã€å¯é å’Œå¯é—®è´£çš„äººå·¥æ™ºèƒ½ä»£ç†ç³»ç»Ÿæä¾›äº†å¯æ“ä½œçš„å»ºè®®ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œå®è·µè€…æä¾›äº†å…³é”®èµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14478v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>    æ–°å‹æ™ºèƒ½ä½“AIç³»ç»Ÿä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸå¸¦æ¥äº†é‡è¦å˜é©ï¼Œè¶…è¶Šäº†ä¼ ç»ŸAIæ¨¡å‹å’Œå½“å‰ä¸»æµç”Ÿæˆå¼AIæ¨¡å‹çš„åŠŸèƒ½è¾¹ç•Œã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡å®šä¹‰ä¸åˆ†ç±»è§£å†³è¯¥é¢†åŸŸè®¤çŸ¥çš„ç¼ºå¤±ï¼Œæ¸…æ™°åœ°å‘ˆç°è¿™ä¸€æ–°èŒƒå¼çš„ç‰¹è‰²ã€‚æ–‡ç« ä»å·¥ç¨‹é¢†åŸŸå¹¿æ³›çš„åº”ç”¨å‡ºå‘ï¼Œé€æ­¥æ·±å…¥ä»‹ç»ç›¸å…³æ¦‚å¿µï¼Œå¹¶æä¾›äº†å››ä¸ªç”µæ°”å·¥ç¨‹é¢†åŸŸçš„æœ€æ–°åº”ç”¨æ¡ˆä¾‹ã€‚è¿™äº›æ¡ˆä¾‹å±•ç¤ºäº†æ™ºèƒ½ä½“AIåœ¨ç®€åŒ–å¤æ‚ç”µåŠ›ç³»ç»Ÿç ”ç©¶ã€æ€§èƒ½åŸºå‡†æµ‹è¯•ä»¥åŠç”µæ± äº¤æ¢ç«™çš„åŠ¨æ€å®šä»·ç­–ç•¥ç”Ÿå­˜åˆ†æç­‰æ–¹é¢çš„å®é™…åº”ç”¨æ•ˆæœã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æä¾›äº†è¯¦ç»†çš„æ•…éšœæ¨¡å¼è°ƒæŸ¥ï¼Œä¸ºè®¾è®¡å’Œå®æ–½å®‰å…¨å¯é çš„æ™ºèƒ½ä½“AIç³»ç»Ÿæä¾›äº†é‡è¦å»ºè®®ã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>æ–°å‹æ™ºèƒ½ä½“AIç³»ç»Ÿä»£è¡¨äº†äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦å˜é©ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿå’Œå½“å‰ä¸»æµAIæ¨¡å‹çš„åŠŸèƒ½è¾¹ç•Œã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨é€šè¿‡å®šä¹‰å’Œåˆ†ç±»æ¸…æ™°åœ°å‘ˆç°è¿™ä¸€æ–°å…´é¢†åŸŸçš„ç‰¹ç‚¹ã€‚</li>
<li>æ–‡ç« ä»‹ç»äº†æ™ºèƒ½ä½“AIåœ¨å·¥ç¨‹é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬ç”µæ°”å·¥ç¨‹ã€‚</li>
<li>æ–‡ç« æä¾›äº†å››ä¸ªç”µæ°”å·¥ç¨‹é¢†åŸŸçš„æœ€æ–°åº”ç”¨æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†æ™ºèƒ½ä½“AIçš„å®é™…æ•ˆæœã€‚</li>
<li>æ™ºèƒ½ä½“AIèƒ½å¤Ÿç®€åŒ–å¤æ‚ç”µåŠ›ç³»ç»Ÿç ”ç©¶å¹¶æå‡æ€§èƒ½åŸºå‡†æµ‹è¯•æ°´å¹³ã€‚</li>
<li>æ™ºèƒ½ä½“AIåœ¨ç”µæ± äº¤æ¢ç«™çš„åŠ¨æ€å®šä»·ç­–ç•¥ç”Ÿå­˜åˆ†ææ–¹é¢å…·æœ‰åº”ç”¨æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14478">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-280322f7dc5db235bbec8966db1fbe25" align="middle">
<img src="https://picx.zhimg.com/v2-79d9db5050776100f57ca99972720e3b" align="middle">
<img src="https://picx.zhimg.com/v2-ca9bb8d293f1a008bf2629effc4ce79c" align="middle">
<img src="https://picx.zhimg.com/v2-118e589e8e66b8303bf0359b676a3d1b" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MedBench-v4-A-Robust-and-Scalable-Benchmark-for-Evaluating-Chinese-Medical-Language-Models-Multimodal-Models-and-Intelligent-Agents"><a href="#MedBench-v4-A-Robust-and-Scalable-Benchmark-for-Evaluating-Chinese-Medical-Language-Models-Multimodal-Models-and-Intelligent-Agents" class="headerlink" title="MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents"></a>MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents</h2><p><strong>Authors:Jinru Ding, Lu Lu, Chao Ding, Mouxiao Bian, Jiayuan Chen, Renjie Lu, Wenrao Pang, Xiaoqin Wu, Zhiqiang Liu, Luyi Jiang, Bing Han, Yunqiu Wang, Jie Xu</strong></p>
<p>Recent advances in medical large language models (LLMs), multimodal models, and agents demand evaluation frameworks that reflect real clinical workflows and safety constraints. We present MedBench v4, a nationwide, cloud-based benchmarking infrastructure comprising over 700,000 expert-curated tasks spanning 24 primary and 91 secondary specialties, with dedicated tracks for LLMs, multimodal models, and agents. Items undergo multi-stage refinement and multi-round review by clinicians from more than 500 institutions, and open-ended responses are scored by an LLM-as-a-judge calibrated to human ratings. We evaluate 15 frontier models. Base LLMs reach a mean overall score of 54.1&#x2F;100 (best: Claude Sonnet 4.5, 62.5&#x2F;100), but safety and ethics remain low (18.4&#x2F;100). Multimodal models perform worse overall (mean 47.5&#x2F;100; best: GPT-5, 54.9&#x2F;100), with solid perception yet weaker cross-modal reasoning. Agents built on the same backbones substantially improve end-to-end performance (mean 79.8&#x2F;100), with Claude Sonnet 4.5-based agents achieving up to 85.3&#x2F;100 overall and 88.9&#x2F;100 on safety tasks. MedBench v4 thus reveals persisting gaps in multimodal reasoning and safety for base models, while showing that governance-aware agentic orchestration can markedly enhance benchmarked clinical readiness without sacrificing capability. By aligning tasks with Chinese clinical guidelines and regulatory priorities, the platform offers a practical reference for hospitals, developers, and policymakers auditing medical AI.</p>
<blockquote>
<p>åŒ»ç–—é¢†åŸŸçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€å¤šæ¨¡æ€æ¨¡å‹åŠæ™ºèƒ½ä¸»ä½“çš„æœ€æ–°è¿›å±•ï¼Œéœ€è¦åæ˜ çœŸå®ä¸´åºŠå·¥ä½œæµç¨‹å’Œå®‰å…¨çº¦æŸçš„è¯„ä¼°æ¡†æ¶ã€‚æˆ‘ä»¬æ¨å‡ºMedBench v4ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨å›½æ€§çš„äº‘åŸºå‡†æµ‹è¯•åŸºç¡€è®¾æ–½ï¼ŒåŒ…å«è¶…è¿‡70ä¸‡é¡¹ä¸“å®¶ç­–åˆ’çš„ä»»åŠ¡ï¼Œæ¶µç›–24ä¸ªä¸»è¦ä¸“ä¸šåŠ91ä¸ªæ¬¡è¦ä¸“ä¸šï¼Œå¹¶è®¾æœ‰é’ˆå¯¹LLMsã€å¤šæ¨¡æ€æ¨¡å‹åŠæ™ºèƒ½ä¸»ä½“çš„ä¸“é—¨èµ›é“ã€‚è¿™äº›é¡¹ç›®ç»è¿‡æ¥è‡ª500å¤šå®¶æœºæ„çš„ä¸´åºŠåŒ»ç”Ÿçš„å¤šé˜¶æ®µç²¾ç»†è°ƒæ•´å’Œå¤šè½®å®¡æŸ¥ï¼Œå¯¹äºå¼€æ”¾å¼çš„å›ç­”åˆ™é€šè¿‡æ ¡å‡†è‡³äººç±»è¯„åˆ†çš„å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„åˆ¤è¿›è¡Œæ‰“åˆ†ã€‚æˆ‘ä»¬è¯„ä¼°äº†15æ¬¾å‰æ²¿æ¨¡å‹ã€‚åŸºç¡€LLMsçš„å¹³å‡æ•´ä½“å¾—åˆ†ä¸º54.1&#x2F;100ï¼ˆæœ€ä½³ï¼šClaude Sonnet 4.5ï¼Œå¾—åˆ†62.5&#x2F;100ï¼‰ï¼Œä½†å®‰å…¨å’Œä¼¦ç†å¾—åˆ†ä»ç„¶è¾ƒä½ï¼ˆ18.4&#x2F;100ï¼‰ã€‚å¤šæ¨¡æ€æ¨¡å‹çš„æ€»ä½“è¡¨ç°ç¨é€Šï¼ˆå¹³å‡å¾—åˆ†47.5&#x2F;100ï¼›æœ€ä½³ï¼šGPT-5ï¼Œå¾—åˆ†54.9&#x2F;100ï¼‰ï¼Œå…·æœ‰å¼ºå¤§çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†åœ¨è·¨æ¨¡æ€æ¨ç†æ–¹é¢è¾ƒå¼±ã€‚åŸºäºç›¸åŒæ¡†æ¶çš„æ™ºèƒ½ä¸»ä½“åœ¨ç«¯åˆ°ç«¯çš„æ€§èƒ½ä¸Šæœ‰æ˜¾è‘—æé«˜ï¼ˆå¹³å‡å¾—åˆ†79.8&#x2F;100ï¼‰ï¼Œå…¶ä¸­åŸºäºClaude Sonnet 4.5çš„æ™ºèƒ½ä¸»ä½“æ•´ä½“å¾—åˆ†é«˜è¾¾85.3&#x2F;100ï¼Œåœ¨å®‰å…¨æ€§ä»»åŠ¡ä¸Šå¾—åˆ†é«˜è¾¾88.9&#x2F;100ã€‚å› æ­¤ï¼ŒMedBench v4æ­ç¤ºäº†åŸºç¡€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†åŠå®‰å…¨æ€§æ–¹é¢å­˜åœ¨çš„æŒç»­å·®è·ï¼ŒåŒæ—¶è¡¨æ˜æ²»ç†æ„è¯†æ™ºèƒ½ååŒèƒ½åœ¨ä¸ç‰ºç‰²èƒ½åŠ›çš„æƒ…å†µä¸‹æ˜¾è‘—æé«˜åŸºå‡†ä¸´åºŠå‡†å¤‡åº¦ã€‚é€šè¿‡ä»»åŠ¡ä¸ä¸­å›½ä¸´åºŠæŒ‡å—å’Œç›‘ç®¡ä¼˜å…ˆäº‹é¡¹ç›¸ç»“åˆï¼Œè¯¥å¹³å°ä¸ºåŒ»é™¢ã€å¼€å‘è€…å’Œæ”¿ç­–åˆ¶å®šè€…è¯„ä¼°åŒ»ç–—äººå·¥æ™ºèƒ½æä¾›äº†ä¸€ä¸ªå®ç”¨çš„å‚è€ƒä¾æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14439v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºåŒ»ç–—å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€å¤šæ¨¡æ€æ¨¡å‹å’Œæ™ºèƒ½ä½“çš„æœ€æ–°è¿›å±•ï¼Œéœ€è¦åæ˜ çœŸå®ä¸´åºŠæµç¨‹å’Œå®‰å…¨æ€§çº¦æŸçš„è¯„ä¼°æ¡†æ¶ã€‚æˆ‘ä»¬æ¨å‡ºMedBench v4ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨å›½æ€§çš„äº‘åŸºå‡†æµ‹è¯•å¹³å°ï¼ŒåŒ…å«è¶…è¿‡70ä¸‡ä¸“å®¶ç­–åˆ’çš„ä»»åŠ¡ï¼Œæ¶µç›–24ä¸ªä¸»è¦å’Œ91ä¸ªæ¬¡è¦ä¸“ä¸šé¢†åŸŸï¼Œå¹¶ä¸ºLLMsã€å¤šæ¨¡æ€æ¨¡å‹å’Œæ™ºèƒ½ä½“è®¾æœ‰ä¸“é—¨èµ›é“ã€‚é€šè¿‡å¯¹è¶…è¿‡500å®¶æœºæ„çš„ä¸´åºŠåŒ»ç”Ÿè¿›è¡Œå¤šé˜¶æ®µç²¾ç»†è°ƒæ•´å’Œå¤šè½®å®¡æŸ¥ï¼Œå¼€æ”¾ç­”æ¡ˆç”±æ ¡å‡†ä¸ºäººç±»è¯„åˆ†æ°´å¹³çš„LLMè¿›è¡Œè¯„åˆ†ã€‚æˆ‘ä»¬è¯„ä¼°äº†15ä¸ªå‰æ²¿æ¨¡å‹ã€‚åŸºç¡€LLMçš„å¹³å‡æ•´ä½“å¾—åˆ†ä¸º54.1åˆ†ï¼ˆæœ€é«˜ï¼šClaude Sonnet 4.5ï¼Œå¾—åˆ†62.5ï¼‰ï¼Œä½†å®‰å…¨æ€§å’Œä¼¦ç†å¾—åˆ†è¾ƒä½ï¼ˆä»…å¾—18.4åˆ†ï¼‰ã€‚å¤šæ¨¡æ€æ¨¡å‹æ•´ä½“è¡¨ç°è¾ƒå·®ï¼ˆå¹³å‡å¾—åˆ†47.5åˆ†ï¼›æœ€ä½³ï¼šGPT-5ï¼Œå¾—åˆ†54.9åˆ†ï¼‰ï¼Œå…·å¤‡è‰¯å¥½çš„æ„ŸçŸ¥èƒ½åŠ›ä½†è·¨æ¨¡æ€æ¨ç†èƒ½åŠ›è¾ƒå¼±ã€‚æ™ºèƒ½ä½“åœ¨åŒä¸€èƒŒæ™¯ä¸‹æ˜¾è‘—æé«˜ç«¯åˆ°ç«¯æ€§èƒ½ï¼ˆå¹³å‡å¾—åˆ†79.8åˆ†ï¼‰ï¼Œå…¶ä¸­åŸºäºClaude Sonnet 4.5çš„æ™ºèƒ½ä½“æ€»ä½“å¾—åˆ†é«˜è¾¾85.3åˆ†ï¼Œå®‰å…¨ä»»åŠ¡å¾—åˆ†é«˜è¾¾88.9åˆ†ã€‚å› æ­¤ï¼ŒMedBench v4æ­ç¤ºäº†åŸºç¡€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†å’Œå®‰å…¨æ€§æ–¹é¢å­˜åœ¨çš„æŒç»­å·®è·ï¼ŒåŒæ—¶è¡¨æ˜æ²»ç†æ„è¯†æ™ºèƒ½ç¼–æ’å¯æ˜¾è‘—æé«˜ä¸´åºŠå‡†å¤‡æ°´å¹³è€Œä¸ç‰ºç‰²èƒ½åŠ›ã€‚é€šè¿‡ä¸ä¸­æ–‡ä¸´åºŠæŒ‡å—å’Œç›‘ç®¡ä¼˜å…ˆäº‹é¡¹çš„ä»»åŠ¡å¯¹é½ï¼Œè¯¥å¹³å°ä¸ºåŒ»é™¢ã€å¼€å‘äººå‘˜å’Œæ”¿ç­–åˆ¶å®šè€…å®¡æ ¸åŒ»ç–—äººå·¥æ™ºèƒ½æä¾›äº†å®ç”¨çš„å‚è€ƒä¾æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MedBench v4æ˜¯ä¸€ä¸ªå…¨å›½æ€§çš„äº‘åŸºå‡†æµ‹è¯•å¹³å°ï¼Œæ¶µç›–å¤šä¸ªåŒ»ç–—ä¸“ä¸šé¢†åŸŸï¼ŒåŒ…æ‹¬LLMsã€å¤šæ¨¡æ€æ¨¡å‹å’Œæ™ºèƒ½ä½“çš„ä¸“é—¨èµ›é“ã€‚</li>
<li>åŸºç¡€LLMåœ¨è¯„ä¼°ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å®‰å…¨æ€§å’Œä¼¦ç†æ–¹é¢å­˜åœ¨å·®è·ã€‚</li>
<li>å¤šæ¨¡æ€æ¨¡å‹åœ¨æ„ŸçŸ¥æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è·¨æ¨¡æ€æ¨ç†æ–¹é¢è¾ƒå¼±ã€‚</li>
<li>æ™ºèƒ½ä½“åœ¨åŒä¸€èƒŒæ™¯ä¸‹æ˜¾è‘—æé«˜ç«¯åˆ°ç«¯æ€§èƒ½ã€‚</li>
<li>MedBench v4æ­ç¤ºäº†åŸºç¡€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†å’Œå®‰å…¨æ€§æ–¹é¢çš„æŒç»­å·®è·ã€‚</li>
<li>æ²»ç†æ„è¯†æ™ºèƒ½ç¼–æ’å¯æ˜¾è‘—æé«˜ä¸´åºŠå‡†å¤‡æ°´å¹³ã€‚</li>
<li>å¹³å°ä¸ä¸­æ–‡ä¸´åºŠæŒ‡å—å’Œç›‘ç®¡ä¼˜å…ˆäº‹é¡¹å¯¹é½ï¼Œä¸ºåŒ»ç–—AIçš„å®¡æ ¸æä¾›å®ç”¨å‚è€ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14439">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da0f650892dee05fd0c77cbaeaaa75e0" align="middle">
<img src="https://picx.zhimg.com/v2-0b07c5a264bdc26d3a92fb98acbfa703" align="middle">
<img src="https://picx.zhimg.com/v2-132c0301b67506ca97b575639e032922" align="middle">
<img src="https://picx.zhimg.com/v2-fb1982d0475a12ff724525511a1fcce4" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DataSage-Multi-agent-Collaboration-for-Insight-Discovery-with-External-Knowledge-Retrieval-Multi-role-Debating-and-Multi-path-Reasoning"><a href="#DataSage-Multi-agent-Collaboration-for-Insight-Discovery-with-External-Knowledge-Retrieval-Multi-role-Debating-and-Multi-path-Reasoning" class="headerlink" title="DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning"></a>DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning</h2><p><strong>Authors:Xiaochuan Liu, Yuanfeng Song, Xiaoming Yin, Xing Chen</strong></p>
<p>In todayâ€™s data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.</p>
<blockquote>
<p>åœ¨å¦‚ä»Šçš„æ•°æ®é©±åŠ¨æ—¶ä»£ï¼Œå®Œå…¨è‡ªåŠ¨åŒ–çš„ç«¯åˆ°ç«¯æ•°æ®åˆ†æï¼Œå°¤å…¶æ˜¯å‘ç°æ´å¯ŸåŠ›ï¼Œå¯¹äºå‘ç°å¯æ“ä½œçš„è§è§£ä»¥ååŠ©ç»„ç»‡åšå‡ºæœ‰æ•ˆå†³ç­–è‡³å…³é‡è¦ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼ŒLLMé©±åŠ¨çš„ä»£ç†å·²ç»å‡ºç°ï¼Œæˆä¸ºè‡ªåŠ¨åŒ–æ•°æ®åˆ†æå’Œæ´å¯ŸåŠ›å‘ç°çš„ä¸€ç§æœ‰å‰é€”çš„èŒƒå¼ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®æ´å¯Ÿä»£ç†åœ¨å‡ ä¸ªå…³é”®æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ï¼Œå¾€å¾€ç”±äºï¼ˆ1ï¼‰å¯¹é¢†åŸŸçŸ¥è¯†åˆ©ç”¨ä¸è¶³ï¼Œï¼ˆ2ï¼‰åˆ†ææ·±åº¦ä¸å¤Ÿæ·±å…¥ï¼Œä»¥åŠï¼ˆ3ï¼‰åœ¨äº§ç”Ÿæ´å¯ŸåŠ›æ—¶å®¹æ˜“å‡ºç°é”™è¯¯ä»£ç ç”Ÿæˆï¼Œè€Œæ— æ³•æä¾›ä»¤äººæ»¡æ„çš„ç»“æœã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DataSageï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šä»£ç†æ¡†æ¶ï¼Œå®ƒç»“åˆäº†ä¸‰ä¸ªåˆ›æ–°åŠŸèƒ½ï¼ŒåŒ…æ‹¬å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä»¥ä¸°å¯Œåˆ†æä¸Šä¸‹æ–‡ã€å¤šè§’è‰²è¾©è®ºæœºåˆ¶æ¨¡æ‹Ÿå¤šç§åˆ†æè§†è§’å¹¶æ·±åŒ–åˆ†ææ·±åº¦ä»¥åŠå¤šè·¯å¾„æ¨ç†ä»¥æé«˜ç”Ÿæˆä»£ç å’Œè§è§£çš„å‡†ç¡®æ€§ã€‚åœ¨InsightBenchä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDataSageåœ¨æ‰€æœ‰éš¾åº¦çº§åˆ«ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰æ•°æ®æ´å¯Ÿä»£ç†ï¼Œä¸ºè‡ªåŠ¨åŒ–æ•°æ®æ´å¯Ÿå‘ç°æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14299v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>åœ¨æ•°æ®é©±åŠ¨çš„æ—¶ä»£ï¼Œå…¨è‡ªåŠ¨åŒ–çš„æ•°æ®åˆ†æä¸æ´å¯Ÿå‘ç°è‡³å…³é‡è¦ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼ŒLLMé©±åŠ¨çš„æ™ºèƒ½ä»£ç†å·²æˆä¸ºè‡ªåŠ¨åŒ–æ•°æ®åˆ†æä¸æ´å¯Ÿå‘ç°çš„æ½œåŠ›æ¨¡å¼ã€‚ç„¶è€Œï¼Œç°æœ‰æ•°æ®æ´å¯Ÿä»£ç†åœ¨å‡ ä¸ªå…³é”®æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ï¼Œå¦‚æœªèƒ½å……åˆ†åˆ©ç”¨é¢†åŸŸçŸ¥è¯†ã€åˆ†ææ·±åº¦ä¸è¶³ä»¥åŠåœ¨ç”Ÿæˆè§è§£æ—¶æ˜“å‡ºç°é”™è¯¯ä»£ç ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DataSageï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œèåˆäº†ä¸‰å¤§åˆ›æ–°åŠŸèƒ½ï¼ŒåŒ…æ‹¬å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä»¥ä¸°å¯Œåˆ†æä¸Šä¸‹æ–‡ã€å¤šè§’è‰²è¾©è®ºæœºåˆ¶æ¨¡æ‹Ÿå¤šç§åˆ†æè§†è§’å’Œæ·±åŒ–åˆ†ææ·±åº¦ï¼Œä»¥åŠå¤šè·¯å¾„æ¨ç†æé«˜ç”Ÿæˆçš„ä»£ç å’Œè§è§£çš„å‡†ç¡®æ€§ã€‚åœ¨InsightBenchä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDataSageåœ¨æ‰€æœ‰éš¾åº¦çº§åˆ«ä¸Šå‡ä¼˜äºç°æœ‰æ•°æ®æ´å¯Ÿä»£ç†ï¼Œä¸ºè‡ªåŠ¨åŒ–æ•°æ®æ´å¯Ÿå‘ç°æä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å…¨è‡ªåŠ¨åŒ–çš„æ•°æ®åˆ†æä¸æ´å¯Ÿå‘ç°åœ¨å½“ä»Šæ•°æ®é©±åŠ¨çš„æ—¶ä»£å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨åŒ–æ•°æ®åˆ†æä¸æ´å¯Ÿå‘ç°ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚</li>
<li>ç°æœ‰æ•°æ®æ´å¯Ÿä»£ç†åœ¨é¢†åŸŸçŸ¥è¯†åˆ©ç”¨ã€åˆ†ææ·±åº¦åŠé”™è¯¯ä»£ç ç”Ÿæˆç­‰æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>DataSageæ˜¯ä¸€ä¸ªæ–°å‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡èåˆä¸‰å¤§åˆ›æ–°åŠŸèƒ½æ¥è§£å†³ç°æœ‰é—®é¢˜ã€‚</li>
<li>DataSageæ”¯æŒå¤–éƒ¨çŸ¥è¯†æ£€ç´¢ï¼Œä¸°å¯Œåˆ†æä¸Šä¸‹æ–‡ã€‚</li>
<li>DataSageé‡‡ç”¨å¤šè§’è‰²è¾©è®ºæœºåˆ¶ï¼Œæ¨¡æ‹Ÿå¤šç§åˆ†æè§†è§’å¹¶æ·±åŒ–åˆ†ææ·±åº¦ã€‚</li>
<li>DataSageçš„å¤šè·¯å¾„æ¨ç†èƒ½æé«˜ç”Ÿæˆçš„ä»£ç å’Œè§è§£çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14299">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-acbb01d891d094eee60426433afdd90d" align="middle">
<img src="https://picx.zhimg.com/v2-6121cfec39687fcb6c8186d7773c7265" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Orion-A-Unified-Visual-Agent-for-Multimodal-Perception-Advanced-Visual-Reasoning-and-Execution"><a href="#Orion-A-Unified-Visual-Agent-for-Multimodal-Perception-Advanced-Visual-Reasoning-and-Execution" class="headerlink" title="Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution"></a>Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution</h2><p><strong>Authors:N Dinesh Reddy, Sudeep Pillai</strong></p>
<p>We introduce Orion, a visual agent framework that can take in any modality and generate any modality. Using an agentic framework with multiple tool-calling capabilities, Orion is designed for visual AI tasks and achieves state-of-the-art results. Unlike traditional vision-language models that produce descriptive outputs, Orion orchestrates a suite of specialized computer vision tools, including object detection, keypoint localization, panoptic segmentation, Optical Character Recognition, and geometric analysis, to execute complex multi-step visual workflows. The system achieves competitive performance on MMMU, MMBench, DocVQA, and MMLongBench while extending monolithic vision-language models to production-grade visual intelligence. By combining neural perception with symbolic execution, Orion enables autonomous visual reasoning, marking a transition from passive visual understanding to active, tool-driven visual intelligence.</p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Orionï¼Œè¿™æ˜¯ä¸€ä¸ªè§†è§‰ä»£ç†æ¡†æ¶ï¼Œå¯ä»¥æ¥æ”¶ä»»ä½•æ¨¡å¼å¹¶ç”Ÿæˆä»»ä½•æ¨¡å¼ã€‚Orioné‡‡ç”¨å…·æœ‰å¤šç§å·¥å…·è°ƒç”¨åŠŸèƒ½çš„ä»£ç†æ¡†æ¶ï¼Œä¸“ä¸ºè§†è§‰AIä»»åŠ¡è®¾è®¡ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æˆæœã€‚ä¸åŒäºä¼ ç»Ÿäº§ç”Ÿæè¿°æ€§è¾“å‡ºçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ŒOrionå¯ä»¥åè°ƒä¸€ç³»åˆ—ä¸“ä¸šçš„è®¡ç®—æœºè§†è§‰å·¥å…·ï¼ŒåŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€å…³é”®ç‚¹å®šä½ã€å…¨æ™¯åˆ†å‰²ã€å…‰å­¦å­—ç¬¦è¯†åˆ«å’Œå‡ ä½•åˆ†æï¼Œä»¥æ‰§è¡Œå¤æ‚çš„å¤šæ­¥è§†è§‰å·¥ä½œæµç¨‹ã€‚è¯¥ç³»ç»Ÿåœ¨MMMUã€MMBenchã€DocVQAå’ŒMMLongBenchä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„è¡¨ç°ï¼ŒåŒæ—¶æ‰©å±•äº†å•ä¸€çš„è§†è§‰è¯­è¨€æ¨¡å‹åˆ°ç”Ÿäº§çº§çš„è§†è§‰æ™ºèƒ½ã€‚é€šè¿‡ç»“åˆç¥ç»æ„ŸçŸ¥å’Œç¬¦å·æ‰§è¡Œï¼ŒOrionå®ç°äº†è‡ªä¸»è§†è§‰æ¨ç†ï¼Œæ ‡å¿—ç€ä»è¢«åŠ¨è§†è§‰ç†è§£åˆ°ä¸»åŠ¨ã€å·¥å…·é©±åŠ¨çš„è§†è§‰æ™ºèƒ½çš„è½¬å˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14210v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Orionæ˜¯ä¸€ä¸ªè§†è§‰ä»£ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿå¤„ç†ä»»ä½•æ¨¡æ€è¾“å…¥å¹¶ç”Ÿæˆä»»ä½•æ¨¡æ€è¾“å‡ºã€‚å®ƒé‡‡ç”¨å…·å¤‡å¤šç§å·¥å…·è°ƒç”¨åŠŸèƒ½çš„ä»£ç†æ¡†æ¶ï¼Œä¸“ä¸ºè§†è§‰AIä»»åŠ¡è®¾è®¡ï¼Œå¹¶å®ç°äº†ä¸šç•Œé¢†å…ˆçš„ç»“æœã€‚ä¸åŒäºä¼ ç»Ÿäº§ç”Ÿæè¿°æ€§è¾“å‡ºçš„è§†å¬æ¨¡å‹ï¼ŒOrionèƒ½åè°ƒä¸€ç³»åˆ—ä¸“ä¸šè®¡ç®—æœºè§†è§‰å·¥å…·ï¼ŒåŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€å…³é”®ç‚¹å®šä½ã€å…¨æ™¯åˆ†å‰²ã€å…‰å­¦å­—ç¬¦è¯†åˆ«å’Œå‡ ä½•åˆ†æï¼Œä»¥æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤è§†è§‰å·¥ä½œæµã€‚ç³»ç»Ÿå®ç°äº†åœ¨MMMUã€MMBenchã€DocVQAå’ŒMMLongBenchä¸Šçš„ç«äº‰åŠ›è¡¨ç°ï¼Œå°†å•ä¸€ä½“åˆ¶çš„è§†å¬è¯­è¨€æ¨¡å‹æ‰©å±•ä¸ºç”Ÿäº§çº§çš„è§†è§‰æ™ºèƒ½ã€‚ç»“åˆç¥ç»æ„ŸçŸ¥å’Œç¬¦å·æ‰§è¡Œï¼ŒOrionå®ç°äº†è‡ªä¸»è§†è§‰æ¨ç†ï¼Œæ ‡å¿—ç€ä»è¢«åŠ¨è§†è§‰ç†è§£åˆ°ä¸»åŠ¨ã€å·¥å…·é©±åŠ¨è§†è§‰æ™ºèƒ½çš„è½¬å˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Orionæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€çš„è§†è§‰ä»£ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§è¾“å…¥å¹¶ç”Ÿæˆå„ç§è¾“å‡ºã€‚</li>
<li>å®ƒä¸“ä¸ºè§†è§‰AIä»»åŠ¡è®¾è®¡ï¼Œå¹¶é›†æˆäº†å¤šç§è®¡ç®—æœºè§†è§‰å·¥å…·ã€‚</li>
<li>Orionå®ç°äº†åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„ä¸šç•Œé¢†å…ˆæ€§èƒ½ã€‚</li>
<li>ä¸ä¼ ç»Ÿæ¨¡å‹ä¸åŒï¼ŒOrionæ³¨é‡æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤è§†è§‰å·¥ä½œæµã€‚</li>
<li>Orionç»“åˆäº†ç¥ç»æ„ŸçŸ¥å’Œç¬¦å·æ‰§è¡Œï¼Œå®ç°äº†è‡ªä¸»è§†è§‰æ¨ç†ã€‚</li>
<li>å®ƒå°†ç”Ÿäº§çº§çš„è§†è§‰æ™ºèƒ½ä»å•ä¸€çš„è§†å¬è¯­è¨€æ¨¡å‹ä¸­æ‰©å±•å‡ºæ¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14210">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b3aab52abbeefe9959df3345b43e170" align="middle">
<img src="https://picx.zhimg.com/v2-935aa5fe00080733d85f9e22f001d06c" align="middle">
<img src="https://picx.zhimg.com/v2-eb2b78917682f2e2bde463ec9e0cd281" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Beyond-Accuracy-A-Multi-Dimensional-Framework-for-Evaluating-Enterprise-Agentic-AI-Systems"><a href="#Beyond-Accuracy-A-Multi-Dimensional-Framework-for-Evaluating-Enterprise-Agentic-AI-Systems" class="headerlink" title="Beyond Accuracy: A Multi-Dimensional Framework for Evaluating Enterprise Agentic AI Systems"></a>Beyond Accuracy: A Multi-Dimensional Framework for Evaluating Enterprise Agentic AI Systems</h2><p><strong>Authors:Sushant Mehta</strong></p>
<p>Current agentic AI benchmarks predominantly evaluate task completion accuracy, while overlooking critical enterprise requirements such as cost-efficiency, reliability, and operational stability. Through systematic analysis of 12 main benchmarks and empirical evaluation of state-of-the-art agents, we identify three fundamental limitations: (1) absence of cost-controlled evaluation leading to 50x cost variations for similar precision, (2) inadequate reliability assessment where agent performance drops from 60% (single run) to 25% (8-run consistency), and (3) missing multidimensional metrics for security, latency, and policy compliance. We propose \textbf{CLEAR} (Cost, Latency, Efficacy, Assurance, Reliability), a holistic evaluation framework specifically designed for enterprise deployment. Evaluation of six leading agents on 300 enterprise tasks demonstrates that optimizing for accuracy alone yields agents 4.4-10.8x more expensive than cost-aware alternatives with comparable performance. Expert evaluation (N&#x3D;15) confirms that CLEAR better predicts production success (correlation $Ï&#x3D;0.83$) compared to accuracy-only evaluation ($Ï&#x3D;0.41$).</p>
<blockquote>
<p>å½“å‰çš„äººå·¥æ™ºèƒ½ä»£ç†åŸºå‡†æµ‹è¯•ä¸»è¦è¯„ä¼°ä»»åŠ¡å®Œæˆçš„å‡†ç¡®æ€§ï¼Œå´å¿½è§†äº†ä¼ä¸šå…³é”®éœ€æ±‚ï¼Œå¦‚æˆæœ¬æ•ˆç›Šã€å¯é æ€§å’Œè¿è¡Œç¨³å®šæ€§ã€‚é€šè¿‡å¯¹12ä¸ªä¸»è¦åŸºå‡†æµ‹è¯•çš„ç³»ç»Ÿåˆ†æä»¥åŠå¯¹æœ€æ–°ä»£ç†çš„å®è¯è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸‰ä¸ªæ ¹æœ¬çš„å±€é™æ€§ï¼šï¼ˆ1ï¼‰ç¼ºä¹æˆæœ¬æ§åˆ¶è¯„ä¼°ï¼Œå¯¼è‡´ç›¸ä¼¼ç²¾åº¦çš„æˆæœ¬å·®å¼‚é«˜è¾¾50å€ï¼›ï¼ˆ2ï¼‰å¯é æ€§è¯„ä¼°ä¸è¶³ï¼Œä»£ç†æ€§èƒ½ä»å•æ¬¡è¿è¡Œçš„60%ä¸‹é™åˆ°å¤šæ¬¡è¿è¡Œçš„25%ï¼›ï¼ˆ3ï¼‰ç¼ºå°‘å¯¹å®‰å…¨ã€å»¶è¿Ÿå’Œæ”¿ç­–åˆè§„æ€§çš„å¤šç»´æŒ‡æ ‡ã€‚æˆ‘ä»¬æå‡ºäº†é’ˆå¯¹ä¼ä¸šéƒ¨ç½²ä¸“é—¨è®¾è®¡çš„å…¨é¢è¯„ä¼°æ¡†æ¶<strong>CLEAR</strong>ï¼ˆæˆæœ¬ã€å»¶è¿Ÿã€æ•ˆç‡ã€ä¿è¯ã€å¯é æ€§ï¼‰ã€‚åœ¨300ä¸ªä¼ä¸šä»»åŠ¡ä¸Šå¯¹å…­ä¸ªé¢†å…ˆä»£ç†çš„è¯„ä»·è¡¨æ˜ï¼Œä»…é€šè¿‡ä¼˜åŒ–å‡†ç¡®æ€§è€Œè·å¾—çš„ä»£ç†åœ¨æˆæœ¬ä¸Šæ¯”å…·æœ‰ç›¸ä¼¼æ€§èƒ½çš„çŸ¥æƒ…æ›¿ä»£æ–¹æ¡ˆé«˜å‡º4.4-10.8å€ã€‚ä¸“å®¶è¯„ä¼°ï¼ˆN&#x3D;15ï¼‰è¯å®ï¼Œä¸ä»…åŸºäºå‡†ç¡®æ€§çš„è¯„ä¼°ç›¸æ¯”ï¼ŒCLEARèƒ½æ›´å¥½åœ°é¢„æµ‹ç”Ÿäº§æˆåŠŸï¼ˆç›¸å…³æ€§Ï&#x3D;0.83ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14136v1">PDF</a> </p>
<p><strong>Summary</strong><br>åœ¨ç°æœ‰çš„ä»£ç†æ™ºèƒ½AIè¯„ä¼°ä½“ç³»ä¸­ï¼Œä¸»è¦ä¾§é‡äºä»»åŠ¡å®Œæˆå‡†ç¡®ç‡çš„è¯„ä»·ï¼Œå¿½ç•¥äº†ä¼ä¸šå…³é”®éœ€æ±‚å¦‚æˆæœ¬æ•ˆç›Šã€å¯é æ€§å’Œè¿è¥ç¨³å®šæ€§ç­‰ã€‚é€šè¿‡å¯¹ä¸»æµä»£ç†æ™ºèƒ½çš„åŸºå‡†æµ‹è¯•è¿›è¡Œç³»ç»Ÿæ€§åˆ†æå’Œå®è¯è¯„ä¼°ï¼Œå‘ç°å­˜åœ¨ä¸‰å¤§å±€é™ï¼šç¼ºä¹æˆæœ¬æ§åˆ¶è¯„ä¼°å¯¼è‡´æˆæœ¬å·®å¼‚å·¨å¤§ã€å¯é æ€§è¯„ä¼°ä¸è¶³å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ä»¥åŠç¼ºå°‘å¤šç»´åº¦è¯„ä»·æŒ‡æ ‡å¦‚å®‰å…¨æ€§ã€å»¶è¿Ÿå’Œæ”¿ç­–åˆè§„æ€§ã€‚ä¸ºæ­¤ï¼Œæå‡ºä¸“ä¸ºä¼ä¸šéƒ¨ç½²è®¾è®¡çš„CLEARè¯„ä¼°æ¡†æ¶ã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œä»…ä¼˜åŒ–å‡†ç¡®ç‡ä¼šå¯¼è‡´ä»£ç†æ™ºèƒ½æˆæœ¬è¾ƒé«˜ï¼Œä¸å…¼é¡¾æˆæœ¬çš„æ›¿ä»£æ–¹æ¡ˆç›¸æ¯”ï¼Œæˆæœ¬é«˜å‡º4.4-10.8å€ã€‚ä¸“å®¶è¯„ä¼°è¯å®ï¼Œç›¸è¾ƒäºä»…ä¾èµ–å‡†ç¡®ç‡çš„è¯„ä¼°ï¼ŒCLEARæ›´èƒ½æœ‰æ•ˆé¢„æµ‹ç”Ÿäº§æˆåŠŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰AIä»£ç†è¯„ä¼°ä¸»è¦å…³æ³¨ä»»åŠ¡å®Œæˆå‡†ç¡®ç‡ï¼Œå¿½è§†äº†ä¼ä¸šçš„å…³é”®éœ€æ±‚å¦‚æˆæœ¬æ•ˆç›Šã€å¯é æ€§å’Œè¿è¥ç¨³å®šæ€§ã€‚</li>
<li>ç³»ç»Ÿåˆ†æå’Œå®è¯è¯„ä¼°å‘ç°ä¸‰å¤§å±€é™ï¼šç¼ºä¹æˆæœ¬æ§åˆ¶è¯„ä¼°ã€å¯é æ€§è¯„ä¼°ä¸è¶³ä»¥åŠç¼ºå°‘å¤šç»´åº¦è¯„ä»·æŒ‡æ ‡ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„è¯„ä¼°æ¡†æ¶â€”â€”CLEARï¼ŒåŒ…å«æˆæœ¬ã€å»¶è¿Ÿã€æ•ˆç‡ã€ä¿éšœå’Œå¯é æ€§äº”ä¸ªç»´åº¦ã€‚</li>
<li>è¯„ä¼°æ˜¾ç¤ºä»…ä¼˜åŒ–å‡†ç¡®ç‡çš„AIä»£ç†æˆæœ¬è¾ƒé«˜ã€‚</li>
<li>ä¸“å®¶è¯„ä¼°è¯å®CLEARè¯„ä¼°æ¡†æ¶ç›¸è¾ƒäºä»…ä¾èµ–å‡†ç¡®ç‡çš„è¯„ä¼°æ›´èƒ½æœ‰æ•ˆé¢„æµ‹ç”Ÿäº§æˆåŠŸã€‚</li>
<li>CLEARæ¡†æ¶ç‰¹åˆ«ä¸ºä¼ä¸šéƒ¨ç½²è®¾è®¡ï¼Œæœ‰åŠ©äºæ›´å…¨é¢åœ°è¯„ä¼°AIä»£ç†çš„æ€§èƒ½å’Œé€‚ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14136">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c76e055c161437050170c16f3c156ac9" align="middle">
<img src="https://picx.zhimg.com/v2-53ec84d2613cb1b8e895b33a4107b030" align="middle">
<img src="https://picx.zhimg.com/v2-481b25accba18662d1a202068e6537fa" align="middle">
<img src="https://picx.zhimg.com/v2-4c9b5e6cf530d73f253e565013b3da83" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="APD-Agents-A-Large-Language-Model-Driven-Multi-Agents-Collaborative-Framework-for-Automated-Page-Design"><a href="#APD-Agents-A-Large-Language-Model-Driven-Multi-Agents-Collaborative-Framework-for-Automated-Page-Design" class="headerlink" title="APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design"></a>APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design</h2><p><strong>Authors:Xinpeng Chen, Xiaofeng Han, Kaihao Zhang, Guochao Ren, Yujie Wang, Wenhao Cao, Yang Zhou, Jianfeng Lu, Zhenbo Song</strong></p>
<p>Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the userâ€™s description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish usersâ€™ design task. To be specific, the SemanticParserAgent is responsible for converting usersâ€™ descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.</p>
<blockquote>
<p>é¡µé¢å¸ƒå±€è®¾è®¡æ˜¯å¼€å‘ç§»åŠ¨åº”ç”¨é¡µé¢ä¸­çš„å…³é”®æ­¥éª¤ã€‚ç„¶è€Œï¼Œè®¾è®¡å¸ˆéœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´æ¥åˆ›å»ºä»¤äººæ»¡æ„çš„è®¾è®¡æ–¹æ¡ˆï¼Œéœ€è¦è€ƒè™‘è¦åœ¨é¡µé¢ä¸Šå±•ç¤ºå“ªäº›æ§ä»¶å’Œå†…å®¹ï¼Œç„¶ååå¤è°ƒæ•´å®ƒä»¬çš„å¤§å°ã€ä½ç½®å’Œæ ·å¼ï¼Œä»¥è·å¾—æ›´å¥½çš„ç¾è§‚å’Œç»“æ„ã€‚å°½ç®¡è®¸å¤šè®¾è®¡è½¯ä»¶ç°åœ¨å¯ä»¥å¸®åŠ©å®Œæˆè¿™äº›é‡å¤çš„ä»»åŠ¡ï¼Œä½†è¦æœ‰æ•ˆåœ°ä½¿ç”¨å®ƒä»¬ä»ç„¶éœ€è¦æ¥å—å¤§é‡çš„åŸ¹è®­ã€‚æ­¤å¤–ï¼Œè·¨åº”ç”¨é¡µé¢çš„åä½œè®¾è®¡è¿˜éœ€è¦é¢å¤–çš„æ—¶é—´æ¥å¯¹é½æ ‡å‡†å’Œç¡®ä¿æ ·å¼çš„ä¸€è‡´æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†APD-agentsï¼ˆç§»åŠ¨åº”ç”¨è‡ªåŠ¨åŒ–é¡µé¢è®¾è®¡å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ¡†æ¶åŒ…å«OrchestratorAgentã€SemanticParserAgentã€PrimaryLayoutAgentã€TemplateRetrievalAgentå’ŒRecursiveComponentAgentã€‚åœ¨æ¥æ”¶åˆ°ç”¨æˆ·å¯¹é¡µé¢çš„æè¿°åï¼ŒOrchestratorAgentå¯ä»¥åŠ¨æ€åœ°æŒ‡å¯¼å…¶ä»–æ™ºèƒ½ä½“å®Œæˆç”¨æˆ·çš„è®¾è®¡ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼ŒSemanticParserAgentè´Ÿè´£å°†ç”¨æˆ·å¯¹é¡µé¢å†…å®¹çš„æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ã€‚PrimaryLayoutAgentå¯ä»¥ç”Ÿæˆè¯¥é¡µé¢çš„åˆå§‹ç²—ç•¥å¸ƒå±€ã€‚TemplateRetrievalAgentå¯ä»¥æ£€ç´¢è¯­ä¹‰ä¸Šç›¸å…³çš„å°‘æ•°ç¤ºä¾‹ï¼Œæé«˜å¸ƒå±€ç”Ÿæˆçš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒRecursiveComponentAgentå¯ç”¨äºå†³å®šå¦‚ä½•é€’å½’ç”Ÿæˆå¸ƒå±€ä¸­çš„æ‰€æœ‰ç²¾ç»†å­å…ƒç´ ã€‚æˆ‘ä»¬çš„å·¥ä½œå……åˆ†åˆ©ç”¨äº†å¤§å‹æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è‡ªåŠ¨åä½œèƒ½åŠ›ã€‚åœ¨RICOæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„APD-agentsè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æŠ€æœ¯æ€§èƒ½è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.14101v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†åœ¨ç§»åŠ¨åº”ç”¨é¡µé¢å¼€å‘ä¸­ï¼Œå¸ƒå±€è®¾è®¡çš„é‡è¦æ€§åŠå…¶æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è®¾è®¡å¸ˆéœ€è¦è€ƒè™‘çš„æ§åˆ¶å’Œå†…å®¹è¦ç´ ï¼Œä»¥åŠè½¯ä»¶å·¥å…·çš„è¾…åŠ©å’ŒååŒè®¾è®¡çš„éœ€æ±‚ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†APD-agentsï¼Œä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»£ç†æ¡†æ¶ï¼Œç”¨äºç§»åŠ¨åº”ç”¨çš„è‡ªåŠ¨åŒ–é¡µé¢è®¾è®¡ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªä»£ç†ï¼Œå¦‚OrchestratorAgentã€SemanticParserAgentç­‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å®Œæˆé¡µé¢è®¾è®¡çš„ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAPD-agentsåœ¨RICOæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¸ƒå±€è®¾è®¡æ˜¯ç§»åŠ¨åº”ç”¨é¡µé¢å¼€å‘ä¸­çš„é‡è¦æ­¥éª¤ï¼Œä½†è®¾è®¡è¿‡ç¨‹è€—æ—¶ï¼Œéœ€è¦è€ƒè™‘æ§åˆ¶å’Œå†…å®¹è¦ç´ çš„è°ƒæ•´ã€‚</li>
<li>å°½ç®¡è®¾è®¡è½¯ä»¶å¯ä»¥è¾…åŠ©å®Œæˆè¿™äº›ä»»åŠ¡ï¼Œä½†æœ‰æ•ˆä½¿ç”¨å®ƒä»¬éœ€è¦å¹¿æ³›åŸ¹è®­ã€‚</li>
<li>ååŒè®¾è®¡éœ€æ±‚é¢å¤–çš„æ—¶é—´æ¥å¯¹é½æ ‡å‡†å’Œç¡®ä¿ä¸€è‡´çš„æ ·å¼ã€‚</li>
<li>APD-agentsæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»£ç†æ¡†æ¶ï¼Œç”¨äºç§»åŠ¨åº”ç”¨çš„è‡ªåŠ¨åŒ–é¡µé¢è®¾è®¡ã€‚</li>
<li>APD-agentsåŒ…æ‹¬å¤šä¸ªä»£ç†ï¼Œå¦‚OrchestratorAgentã€SemanticParserAgentç­‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å®Œæˆé¡µé¢è®¾è®¡çš„ä»»åŠ¡ã€‚</li>
<li>APD-agentsçš„å®éªŒç»“æœåœ¨RICOæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜ç§€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.14101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f6992ecb3c77279930f5f747d4816520" align="middle">
<img src="https://picx.zhimg.com/v2-0f84f08d4f2c474bfb93a9bba8e76aff" align="middle">
<img src="https://picx.zhimg.com/v2-9481c5091064728c7f5466eff4645f15" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="O-Mem-Omni-Memory-System-for-Personalized-Long-Horizon-Self-Evolving-Agents"><a href="#O-Mem-Omni-Memory-System-for-Personalized-Long-Horizon-Self-Evolving-Agents" class="headerlink" title="O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents"></a>O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents</h2><p><strong>Authors:Piaohong Wang, Motong Tian, Jiaxian Li, Yuan Liang, Yuqing Wang, Qianben Chen, Tiannan Wang, Zhicong Lu, Jiawei Ma, Yuchen Eleanor Jiang, Wangchunshu Zhou</strong></p>
<p>Recent advancements in LLM-powered agents have demonstrated significant potential in generating human-like responses; however, they continue to face challenges in maintaining long-term interactions within complex environments, primarily due to limitations in contextual consistency and dynamic personalization. Existing memory systems often depend on semantic grouping prior to retrieval, which can overlook semantically irrelevant yet critical user information and introduce retrieval noise. In this report, we propose the initial design of O-Mem, a novel memory framework based on active user profiling that dynamically extracts and updates user characteristics and event records from their proactive interactions with agents. O-Mem supports hierarchical retrieval of persona attributes and topic-related context, enabling more adaptive and coherent personalized responses. O-Mem achieves 51.67% on the public LoCoMo benchmark, a nearly 3% improvement upon LangMem,the previous state-of-the-art, and it achieves 62.99% on PERSONAMEM, a 3.5% improvement upon A-Mem,the previous state-of-the-art. O-Mem also boosts token and interaction response time efficiency compared to previous memory frameworks. Our work opens up promising directions for developing efficient and human-like personalized AI assistants in the future.</p>
<blockquote>
<p>æœ€è¿‘ï¼Œä»¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºåŠ¨åŠ›çš„äººå·¥æ™ºèƒ½ä»£ç†äººåœ¨ç”Ÿæˆäººç±»å¼å›åº”æ–¹é¢å±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨ç»´æŒå¤æ‚ç¯å¢ƒä¸­çš„é•¿æœŸäº’åŠ¨æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦å½’å› äºä¸Šä¸‹æ–‡ä¸€è‡´æ€§å’ŒåŠ¨æ€ä¸ªæ€§åŒ–æ–¹é¢çš„å±€é™æ€§ã€‚ç°æœ‰çš„è®°å¿†ç³»ç»Ÿé€šå¸¸ä¾èµ–äºæ£€ç´¢å‰çš„è¯­ä¹‰åˆ†ç»„ï¼Œè¿™å¯èƒ½ä¼šå¿½ç•¥ç”¨æˆ·è¯­ä¹‰ä¸Šæ— å…³ç´§è¦ä½†è‡³å…³é‡è¦çš„ä¿¡æ¯ï¼Œå¹¶å¼•å…¥æ£€ç´¢å™ªå£°ã€‚åœ¨æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†O-Memçš„åˆæ­¥è®¾è®¡ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¸»åŠ¨ç”¨æˆ·åˆ†æçš„æ–°å‹è®°å¿†æ¡†æ¶ï¼Œå®ƒèƒ½å¤ŸåŠ¨æ€æå–å’Œæ›´æ–°ç”¨æˆ·ç‰¹å¾å’Œäº‹ä»¶è®°å½•ï¼Œè¿™äº›è®°å½•å’Œç‰¹å¾æ¥è‡ªç”¨æˆ·ä¸ä»£ç†ä¹‹é—´çš„ä¸»åŠ¨äº’åŠ¨ã€‚O-Memæ”¯æŒå±‚æ¬¡åŒ–æ£€ç´¢äººæ ¼å±æ€§å’Œä¸»é¢˜ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œä»è€Œå®ç°æ›´è‡ªé€‚åº”å’Œè¿è´¯çš„ä¸ªæ€§åŒ–å›åº”ã€‚O-Memåœ¨å…¬å…±LoCoMoåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†51.67%çš„æ€§èƒ½ï¼Œæ¯”ä¹‹å‰çš„æœ€ä½³æ°´å¹³LangMemæé«˜äº†è¿‘3%ï¼Œåœ¨PERSONAMEMä¸Šè¾¾åˆ°äº†62.99%ï¼Œæ¯”ä¹‹å‰çš„æœ€ä½³æ°´å¹³A-Memæé«˜äº†3.5%ã€‚ä¸ä¹‹å‰çš„è®°å¿†æ¡†æ¶ç›¸æ¯”ï¼ŒO-Memè¿˜æé«˜äº†ä»¤ç‰Œå’Œäº’åŠ¨å“åº”æ—¶é—´æ•ˆç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºæœªæ¥å¼€å‘é«˜æ•ˆã€äººæ€§åŒ–çš„ä¸ªæ€§åŒ–AIåŠ©ç†æŒ‡æ˜äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.13593v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LLMé©±åŠ¨çš„ä»£ç†åœ¨ç”Ÿæˆç±»ä¼¼äººç±»çš„å“åº”æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ä»é¢ä¸´åœ¨å¤æ‚ç¯å¢ƒä¸­ç»´æŒé•¿æœŸäº’åŠ¨çš„æŒ‘æˆ˜ï¼Œä¸»è¦å› ä¸ºä¸Šä¸‹æ–‡ä¸€è‡´æ€§å’ŒåŠ¨æ€ä¸ªæ€§åŒ–æ–¹é¢çš„å±€é™ã€‚ç°æœ‰è®°å¿†ç³»ç»Ÿé€šå¸¸ä¾èµ–äºè¯­ä¹‰åˆ†ç»„è¿›è¡Œæ£€ç´¢ï¼Œè¿™å¯èƒ½ä¼šå¿½ç•¥ç”¨æˆ·è¯­ä¹‰ä¸Šä¸é‡è¦ä½†å…³é”®çš„ä¿¡æ¯å¹¶å¼•å…¥æ£€ç´¢å™ªéŸ³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†O-Memçš„åˆæ­¥è®¾è®¡ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºä¸»åŠ¨ç”¨æˆ·åˆ†æçš„æ–°å‹è®°å¿†æ¡†æ¶ï¼Œèƒ½å¤ŸåŠ¨æ€æå–å’Œæ›´æ–°ç”¨æˆ·ç‰¹æ€§å’Œäº‹ä»¶è®°å½•ï¼Œä¸ä»£ç†è¿›è¡Œä¸»åŠ¨äº’åŠ¨ã€‚O-Memæ”¯æŒå±‚æ¬¡åŒ–çš„ä¸ªæ€§å±æ€§æ£€ç´¢å’Œä¸»é¢˜ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œå®ç°æ›´è‡ªé€‚åº”å’Œè¿è´¯çš„ä¸ªäººåŒ–å“åº”ã€‚å®ƒåœ¨å…¬å…±LoCoMoåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°è¾¾åˆ°51.67%ï¼Œè¾ƒä¹‹å‰çš„æœ€ä½³æ°´å¹³LangMemæé«˜äº†è¿‘3%ï¼Œå¹¶åœ¨PERSONAMEMä¸Šè¾¾åˆ°62.99%ï¼Œè¾ƒä¹‹å‰çš„æœ€ä½³æ°´å¹³A-Memæé«˜äº†3.5%ã€‚æ­¤å¤–ï¼Œä¸ä¹‹å‰çš„è®°å¿†æ¡†æ¶ç›¸æ¯”ï¼ŒO-Memè¿˜æé«˜äº†ä»¤ç‰Œå’Œäº’åŠ¨å“åº”çš„æ—¶é—´æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMé©±åŠ¨çš„ä»£ç†åœ¨ç”Ÿæˆç±»ä¼¼äººç±»çš„å“åº”æ–¹é¢æœ‰å¾ˆå¤§æ½œåŠ›ï¼Œä½†åœ¨å¤æ‚ç¯å¢ƒä¸­ç»´æŒé•¿æœŸäº’åŠ¨ä»å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰è®°å¿†ç³»ç»Ÿä¾èµ–äºè¯­ä¹‰åˆ†ç»„è¿›è¡Œæ£€ç´¢ï¼Œè¿™å¯èƒ½å¿½ç•¥å…³é”®ç”¨æˆ·ä¿¡æ¯å¹¶å¼•å…¥å™ªéŸ³ã€‚</li>
<li>O-Memæ˜¯ä¸€ä¸ªåŸºäºä¸»åŠ¨ç”¨æˆ·åˆ†æçš„æ–°å‹è®°å¿†æ¡†æ¶ï¼Œèƒ½åŠ¨æ€æå–å’Œæ›´æ–°ç”¨æˆ·ç‰¹æ€§å’Œäº‹ä»¶è®°å½•ã€‚</li>
<li>O-Memæ”¯æŒå±‚æ¬¡åŒ–çš„ä¸ªæ€§å±æ€§æ£€ç´¢å’Œä¸»é¢˜ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œå®ç°æ›´è‡ªé€‚åº”å’Œè¿è´¯çš„ä¸ªæ€§åŒ–å“åº”ã€‚</li>
<li>O-Memåœ¨å…¬å…±LoCoMoåŸºå‡†æµ‹è¯•å’ŒPERSONAMEMä¸Šçš„è¡¨ç°ä¼˜äºä¹‹å‰çš„æœ€ä½³æ°´å¹³ã€‚</li>
<li>O-Memæé«˜äº†ä»¤ç‰Œå’Œäº’åŠ¨å“åº”çš„æ—¶é—´æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.13593">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0713912c24e8078e283d8c14c8e37359" align="middle">
<img src="https://picx.zhimg.com/v2-ef65277d1c1660eebf82be657859459c" align="middle">
<img src="https://picx.zhimg.com/v2-d590c38bcd8b72aeadce7ab926a65fdd" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Leveraging-LLM-based-agents-for-social-science-research-insights-from-citation-network-simulations"><a href="#Leveraging-LLM-based-agents-for-social-science-research-insights-from-citation-network-simulations" class="headerlink" title="Leveraging LLM-based agents for social science research: insights from citation network simulations"></a>Leveraging LLM-based agents for social science research: insights from citation network simulations</h2><p><strong>Authors:Jiarui Ji, Runlin Lei, Xuchen Pan, Zhewei Wei, Hao Sun, Yankai Lin, Xu Chen, Yongzheng Yang, Yaliang Li, Bolin Ding, Ji-Rong Wen</strong></p>
<p>The emergence of Large Language Models (LLMs) demonstrates their potential to encapsulate the logic and patterns inherent in human behavior simulation by leveraging extensive web data pre-training. However, the boundaries of LLM capabilities in social simulation remain unclear. To further explore the social attributes of LLMs, we introduce the CiteAgent framework, designed to generate citation networks based on human-behavior simulation with LLM-based agents. CiteAgent successfully captures predominant phenomena in real-world citation networks, including power-law distribution, citational distortion, and shrinking diameter. Building on this realistic simulation, we establish two LLM-based research paradigms in social science: LLM-SE (LLM-based Survey Experiment) and LLM-LE (LLM-based Laboratory Experiment). These paradigms facilitate rigorous analyses of citation network phenomena, allowing us to validate and challenge existing theories. Additionally, we extend the research scope of traditional science of science studies through idealized social experiments, with the simulation experiment results providing valuable insights for real-world academic environments. Our work demonstrates the potential of LLMs for advancing science of science research in social science.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°è¡¨æ˜ï¼Œå®ƒä»¬å¯ä»¥åˆ©ç”¨å¤§é‡çš„ç½‘ç»œæ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œå°è£…äººç±»è¡Œä¸ºæ¨¡æ‹Ÿä¸­å›ºæœ‰çš„é€»è¾‘å’Œæ¨¡å¼ã€‚ç„¶è€Œï¼ŒLLMåœ¨ç¤¾ä¼šæ¨¡æ‹Ÿæ–¹é¢çš„èƒ½åŠ›è¾¹ç•Œä»ç„¶ä¸æ˜ç¡®ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ¢ç´¢LLMçš„ç¤¾ä¼šå±æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†CiteAgentæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨åŸºäºäººç±»è¡Œä¸ºæ¨¡æ‹Ÿç”ŸæˆåŸºäºLLMçš„å¼•ç”¨ç½‘ç»œã€‚CiteAgentæˆåŠŸæ•è·äº†çœŸå®ä¸–ç•Œå¼•ç”¨ç½‘ç»œä¸­çš„ä¸»è¦ç°è±¡ï¼ŒåŒ…æ‹¬å¹‚å¾‹åˆ†å¸ƒã€å¼•ç”¨å¤±çœŸå’Œç›´å¾„ç¼©å°ã€‚åœ¨è¿™ä¸€ç°å®æ¨¡æ‹Ÿçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸¤ä¸ªåŸºäºLLMçš„ç¤¾ä¼šç§‘å­¦ç ”ç©¶èŒƒå¼ï¼šLLM-SEï¼ˆåŸºäºLLMçš„è°ƒæŸ¥å®éªŒï¼‰å’ŒLLM-LEï¼ˆåŸºäºLLMçš„å®éªŒå®¤å®éªŒï¼‰ã€‚è¿™äº›èŒƒå¼ä¿ƒè¿›äº†å¯¹å¼•ç”¨ç½‘ç»œç°è±¡çš„ä¸¥è°¨åˆ†æï¼Œä½¿æˆ‘ä»¬èƒ½å¤ŸéªŒè¯å’ŒæŒ‘æˆ˜ç°æœ‰ç†è®ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡ç†æƒ³çš„ç¤¾äº¤å®éªŒæ‰©å±•äº†ä¼ ç»Ÿç§‘å­¦ç ”ç©¶çš„èŒƒå›´ï¼Œæ¨¡æ‹Ÿå®éªŒçš„ç»“æœä¸ºçœŸå®çš„å­¦æœ¯ç¯å¢ƒæä¾›äº†å®è´µçš„è§è§£ã€‚æˆ‘ä»¬çš„å·¥ä½œå±•ç¤ºäº†LLMåœ¨ç¤¾ä¼šç§‘å­¦é¢†åŸŸæ¨åŠ¨ç§‘å­¦ç ”ç©¶å‘å±•çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.03758v3">PDF</a> accepted by HSSCOMMSâ€™25</p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡åˆ©ç”¨å¹¿æ³›çš„ç½‘ç»œæ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œå±•ç°å‡ºæ¨¡æ‹Ÿäººç±»è¡Œä¸ºé€»è¾‘å’Œæ¨¡å¼çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒLLMsåœ¨ç¤¾ä¼šæ¨¡æ‹Ÿæ–¹é¢çš„èƒ½åŠ›è¾¹ç•Œå°šä¸æ¸…æ¥šã€‚ä¸ºäº†æ¢ç´¢LLMsçš„ç¤¾ä¼šå±æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†CiteAgentæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨åˆ©ç”¨åŸºäºLLMçš„ä»£ç†ç”ŸæˆåŸºäºäººç±»è¡Œä¸ºæ¨¡æ‹Ÿçš„å¼•æ–‡ç½‘ç»œã€‚CiteAgentæˆåŠŸæ•æ‰äº†ç°å®å¼•æ–‡ç½‘ç»œä¸­çš„ä¸»è¦ç°è±¡ï¼ŒåŒ…æ‹¬å¹‚å¾‹åˆ†å¸ƒã€å¼•æ–‡å¤±çœŸå’Œæ”¶ç¼©ç›´å¾„ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å»ºç«‹äº†ç¤¾ä¼šç§‘å­¦é¢†åŸŸçš„ä¸¤ä¸ªåŸºäºLLMçš„ç ”ç©¶èŒƒå¼ï¼šLLM-SEï¼ˆåŸºäºLLMçš„è°ƒæŸ¥å®éªŒï¼‰å’ŒLLM-LEï¼ˆåŸºäºLLMçš„å®éªŒå®¤å®éªŒï¼‰ã€‚è¿™äº›èŒƒå¼ä¿ƒè¿›äº†å¼•æ–‡ç½‘ç»œç°è±¡çš„ä¸¥è°¨åˆ†æï¼ŒéªŒè¯äº†ç°æœ‰ç†è®ºå¹¶æŒ‘æˆ˜äº†æ–°çš„ç†è®ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡ç†æƒ³åŒ–çš„ç¤¾ä¼šå®éªŒæ‰©å±•äº†ä¼ ç»Ÿç§‘å­¦ç ”ç©¶çš„èŒƒå›´ï¼Œæ¨¡æ‹Ÿå®éªŒç»“æœå¯¹ç°å®ä¸–ç•Œçš„å­¦æœ¯ç¯å¢ƒæä¾›äº†å®è´µçš„è§è§£ã€‚æˆ‘ä»¬çš„å·¥ä½œå±•ç¤ºäº†LLMsåœ¨æ¨è¿›ç¤¾ä¼šç§‘å­¦é¢†åŸŸç§‘å­¦ç ”ç©¶æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså…·å¤‡æ¨¡æ‹Ÿäººç±»è¡Œä¸ºé€»è¾‘å’Œæ¨¡å¼çš„èƒ½åŠ›ï¼Œé€šè¿‡åˆ©ç”¨å¹¿æ³›çš„ç½‘ç»œæ•°æ®è¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>CiteAgentæ¡†æ¶ç”¨äºç”ŸæˆåŸºäºäººç±»è¡Œä¸ºæ¨¡æ‹Ÿçš„å¼•æ–‡ç½‘ç»œï¼ŒæˆåŠŸæ•æ‰äº†ç°å®å¼•æ–‡ç½‘ç»œçš„ä¸»è¦ç°è±¡ã€‚</li>
<li>å»ºç«‹äº†åŸºäºLLMçš„ä¸¤ä¸ªç ”ç©¶èŒƒå¼ï¼šLLM-SEå’ŒLLM-LEï¼Œç”¨äºä¸¥è°¨åˆ†æå¼•æ–‡ç½‘ç»œç°è±¡ã€‚</li>
<li>åŸºäºLLMçš„æ¨¡æ‹Ÿå®éªŒéªŒè¯äº†ç°æœ‰ç†è®ºå¹¶æŒ‘æˆ˜äº†æ–°çš„ç†è®ºã€‚</li>
<li>é€šè¿‡ç†æƒ³åŒ–çš„ç¤¾ä¼šå®éªŒæ‰©å±•äº†ä¼ ç»Ÿç§‘å­¦ç ”ç©¶çš„èŒƒå›´ã€‚</li>
<li>æ¨¡æ‹Ÿå®éªŒç»“æœå¯¹ç°å®ä¸–ç•Œçš„å­¦æœ¯ç¯å¢ƒæä¾›äº†å®è´µçš„è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.03758">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ba704f9fb7682b9a75c16c9b2c9771f8" align="middle">
<img src="https://picx.zhimg.com/v2-4d228cf2f8c60db5d21ba3425ee257f7" align="middle">
<img src="https://picx.zhimg.com/v2-402291541140d5a62a968f0b031bad9e" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="KnowCoder-A1-Incentivizing-Agentic-Reasoning-Capability-with-Outcome-Supervision-for-KBQA"><a href="#KnowCoder-A1-Incentivizing-Agentic-Reasoning-Capability-with-Outcome-Supervision-for-KBQA" class="headerlink" title="KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA"></a>KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA</h2><p><strong>Authors:Zhuo Chen, Fei Wang, Zixuan Li, Zhao Zhang, Weiwei Ding, Chuanguang Yang, Yongjun Xu, Xiaolong Jin, Jiafeng Guo</strong></p>
<p>Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose a question, generate its corresponding logical queries, and interact with the KB to derive the answer. However, these methods typically fine-tune LLMs on reasoning trajectories synthesized via process supervision, which offers weak incentives for exploration and thus fails to strengthen the agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that can autonomously perform agentic reasoning on KBs to obtain answers. To incentivize autonomous exploration, KnowCoder-A1 trains the LLM under outcome-only supervision via a multi-stage curriculum reinforcement learning with an easy-to-hard curriculum. To establish foundational agentic capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of high-quality trajectories obtained through outcome-based rejection sampling. Then, to alleviate the reward sparsity inherent in outcome-only supervision, it applies multi-stage curriculum RL with reward schedules that progress from easy to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful reasoning behaviors and consistently outperforms prior approaches across three mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1 achieves up to an 11.1% relative improvement while using only one-twelfth of the training data, demonstrating strong agentic reasoning capabilities.</p>
<blockquote>
<p>çŸ¥è¯†åº“é—®ç­”ï¼ˆKBQAï¼‰æ—¨åœ¨é’ˆå¯¹ç»“æ„åŒ–çŸ¥è¯†åº“ï¼ˆKBï¼‰å›ç­”è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚æœ€è¿‘çš„å·¥ä½œé€šè¿‡é‡‡ç”¨ä¸»ä½“æ¨ç†èŒƒå¼æ”¹è¿›äº†KBQAï¼Œå…¶ä¸­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¼šè¿­ä»£åœ°åˆ†è§£é—®é¢˜ï¼Œç”Ÿæˆç›¸åº”çš„é€»è¾‘æŸ¥è¯¢ï¼Œå¹¶ä¸çŸ¥è¯†åº“äº’åŠ¨ä»¥å¾—å‡ºç­”æ¡ˆã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸é€šè¿‡å¯¹é€šè¿‡è¿‡ç¨‹ç›‘ç£åˆæˆçš„æ¨ç†è½¨è¿¹å¾®è°ƒLLMï¼Œè¿™æä¾›äº†å¾®å¼±çš„æ¢ç´¢æ¿€åŠ±ï¼Œå› æ­¤æ— æ³•åŠ å¼ºä¸»ä½“æ¨ç†èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†KnowCoder-A1ï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿåœ¨çŸ¥è¯†åº“ä¸Šè‡ªä¸»è¿›è¡Œä¸»ä½“æ¨ç†ä»¥è·å¾—ç­”æ¡ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚ä¸ºäº†æ¿€åŠ±è‡ªä¸»æ¢ç´¢ï¼ŒKnowCoder-A1ä»…åœ¨ç»“æœç›‘ç£ä¸‹è®­ç»ƒLLMï¼Œé‡‡ç”¨ä»ç®€å•åˆ°å¤æ‚çš„å¤šé˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ ã€‚ä¸ºäº†å»ºç«‹åŸºç¡€ä¸»ä½“èƒ½åŠ›ï¼ŒKnowCoder-A1é¦–å…ˆåœ¨å°è§„æ¨¡çš„é«˜è´¨é‡è½¨è¿¹ä¸Šå¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œè¿™äº›è½¨è¿¹æ˜¯é€šè¿‡åŸºäºç»“æœçš„æ‹’ç»é‡‡æ ·è·å¾—çš„ã€‚ç„¶åï¼Œä¸ºäº†ç¼“è§£ä»…åœ¨ç»“æœç›‘ç£ä¸‹å­˜åœ¨çš„å¥–åŠ±ç¨€ç–é—®é¢˜ï¼Œå®ƒåº”ç”¨äº†ä»ç®€å•åˆ°å¤æ‚çš„å¤šé˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ å¥–åŠ±è®¡åˆ’ã€‚ä»…åœ¨ç»“æœç›‘ç£ä¸‹è¿›è¡Œè®­ç»ƒï¼ŒKnowCoder-A1å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†è¡Œä¸ºï¼Œå¹¶åœ¨ä¸‰ä¸ªä¸»æµæ•°æ®é›†ä¸Šå§‹ç»ˆä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨GrailQAçš„é›¶æ ·æœ¬å­é›†ä¸Šï¼ŒKnowCoder-A1åœ¨ä»…ä½¿ç”¨åäºŒåˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†é«˜è¾¾11.1%çš„ç›¸å¯¹æ”¹è¿›ï¼Œå±•ç°äº†å¼ºå¤§çš„ä¸»ä½“æ¨ç†èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.25101v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†Knowledge Base Question Answering (KBQA)é€šè¿‡é‡‡ç”¨ä¸€ç§æ–°å‹ä»£ç†æ¨ç†æ¨¡å¼æ¥æé«˜é—®ç­”æ€§èƒ½çš„æ–¹æ³•ã€‚è¯¥æ¨¡å¼é‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè¿­ä»£åˆ†è§£é—®é¢˜ã€ç”Ÿæˆé€»è¾‘æŸ¥è¯¢å¹¶ä¸çŸ¥è¯†åº“äº¤äº’ä»¥å¾—å‡ºç­”æ¡ˆã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºKnowCoder-A1çš„LLMæ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨çŸ¥è¯†åº“ä¸Šè‡ªä¸»è¿›è¡Œä»£ç†æ¨ç†ä»¥è·å–ç­”æ¡ˆã€‚KnowCoder-A1é€šè¿‡é‡‡ç”¨ä»…ç»“æœç›‘ç£çš„å¤šé˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ æ¥æ¿€åŠ±è‡ªä¸»æ¢ç´¢ï¼Œå¹¶åœ¨åˆå§‹é˜¶æ®µé€šè¿‡åŸºäºç»“æœçš„æ‹’ç»é‡‡æ ·è·å¾—é«˜è´¨é‡è½¨è¿¹è¿›è¡Œå¾®è°ƒã€‚ç»è¿‡ä»…ç»“æœç›‘ç£çš„è®­ç»ƒï¼ŒKnowCoder-A1å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨ä¸‰ä¸ªä¸»æµæ•°æ®é›†ä¸Šå‡ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚åœ¨GrailQAçš„é›¶æ ·æœ¬å­é›†ä¸Šï¼ŒKnowCoder-A1åœ¨ä»…ä½¿ç”¨åäºŒåˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†é«˜è¾¾11.1%çš„ç›¸å¯¹æ”¹è¿›ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„ä»£ç†æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KBQAé‡‡ç”¨ä»£ç†æ¨ç†æ¨¡å¼æé«˜é—®ç­”æ€§èƒ½ï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹åˆ†è§£é—®é¢˜ã€ç”Ÿæˆé€»è¾‘æŸ¥è¯¢å¹¶ä¸çŸ¥è¯†åº“äº¤äº’å¾—å‡ºç­”æ¡ˆã€‚</li>
<li>KnowCoder-A1æ¨¡å‹èƒ½åœ¨çŸ¥è¯†åº“ä¸Šè‡ªä¸»è¿›è¡Œä»£ç†æ¨ç†ï¼Œè·å–ç­”æ¡ˆã€‚</li>
<li>KnowCoder-A1é€šè¿‡ä»…ç»“æœç›‘ç£çš„å¤šé˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥æ¿€åŠ±è‡ªä¸»æ¢ç´¢ã€‚</li>
<li>KnowCoder-A1é‡‡ç”¨åŸºäºç»“æœçš„æ‹’ç»é‡‡æ ·è·å¾—é«˜è´¨é‡è½¨è¿¹è¿›è¡Œå¾®è°ƒï¼Œå»ºç«‹åŸºç¡€ä»£ç†èƒ½åŠ›ã€‚</li>
<li>KnowCoder-A1é€šè¿‡å¤šé˜¶æ®µè¯¾ç¨‹RLå’Œå¥–åŠ±è¿›åº¦è¡¨ç¼“è§£ä»…ç»“æœç›‘ç£çš„å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ã€‚</li>
<li>KnowCoder-A1å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œåœ¨å¤šä¸ªä¸»æµæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºå…ˆå‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.25101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-792d8ddb3e431b12c56a5f6143cd9aed" align="middle">
<img src="https://picx.zhimg.com/v2-d67a74f417dab498877371d362b371ae" align="middle">
<img src="https://picx.zhimg.com/v2-4295a5282f9aee243022f482e6ab3f58" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="GMAT-Grounded-Multi-Agent-Clinical-Description-Generation-for-Text-Encoder-in-Vision-Language-MIL-for-Whole-Slide-Image-Classification"><a href="#GMAT-Grounded-Multi-Agent-Clinical-Description-Generation-for-Text-Encoder-in-Vision-Language-MIL-for-Whole-Slide-Image-Classification" class="headerlink" title="GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification"></a>GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification</h2><p><strong>Authors:Ngoc Bui Lam Quang, Nam Le Nguyen Binh, Thanh-Huy Nguyen, Le Thien Phuc Nguyen, Quan Nguyen, Ulas Bagci</strong></p>
<p>Multiple Instance Learning (MIL) is the leading approach for whole slide image (WSI) classification, enabling efficient analysis of gigapixel pathology slides. Recent work has introduced vision-language models (VLMs) into MIL pipelines to incorporate medical knowledge through text-based class descriptions rather than simple class names. However, when these methods rely on large language models (LLMs) to generate clinical descriptions or use fixed-length prompts to represent complex pathology concepts, the limited token capacity of VLMs often constrains the expressiveness and richness of the encoded class information. Additionally, descriptions generated solely by LLMs may lack domain grounding and fine-grained medical specificity, leading to suboptimal alignment with visual features. To address these challenges, we propose a vision-language MIL framework with two key contributions: (1) A grounded multi-agent description generation system that leverages curated pathology textbooks and agent specialization (e.g., morphology, spatial context) to produce accurate and diverse clinical descriptions; (2) A text encoding strategy using a list of descriptions rather than a single prompt, capturing fine-grained and complementary clinical signals for better alignment with visual features. Integrated into a VLM-MIL pipeline, our approach shows improved performance over single-prompt class baselines and achieves results comparable to state-of-the-art models, as demonstrated on renal and lung cancer datasets.</p>
<blockquote>
<p>å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ˜¯å…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰åˆ†ç±»çš„ä¸»è¦æ–¹æ³•ï¼Œèƒ½å¤Ÿå®ç°gigapixelç—…ç†åˆ‡ç‰‡çš„é«˜æ•ˆåˆ†æã€‚æœ€è¿‘çš„å·¥ä½œå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¼•å…¥MILç®¡é“ï¼Œé€šè¿‡åŸºäºæ–‡æœ¬çš„ç±»åˆ«æè¿°è€Œä¸æ˜¯ç®€å•çš„ç±»åˆ«åç§°æ¥èå…¥åŒ»å­¦çŸ¥è¯†ã€‚ç„¶è€Œï¼Œå½“è¿™äº›æ–¹æ³•ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥ç”Ÿæˆä¸´åºŠæè¿°æˆ–ä½¿ç”¨å›ºå®šé•¿åº¦çš„æç¤ºæ¥è¡¨ç¤ºå¤æ‚çš„ç—…ç†å­¦æ¦‚å¿µæ—¶ï¼ŒVLMçš„æœ‰é™ä»¤ç‰Œå®¹é‡é€šå¸¸é™åˆ¶äº†ç¼–ç ç±»åˆ«ä¿¡æ¯çš„è¡¨è¾¾æ€§å’Œä¸°å¯Œæ€§ã€‚æ­¤å¤–ï¼Œä»…ç”±LLMç”Ÿæˆçš„æè¿°å¯èƒ½ç¼ºä¹é¢†åŸŸæ ¹åŸºå’Œç²¾ç»†çš„åŒ»å­¦ç‰¹å¼‚æ€§ï¼Œå¯¼è‡´ä¸è§†è§‰ç‰¹å¾çš„æ¬¡ä¼˜å¯¹é½ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªä¸»è¦è´¡çŒ®çš„è§†è§‰è¯­è¨€MILæ¡†æ¶ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªåŸºäºç—…ç†æ•™ç§‘ä¹¦å’Œä»£ç†ä¸“ä¸šåŒ–ï¼ˆä¾‹å¦‚å½¢æ€å­¦ã€ç©ºé—´ä¸Šä¸‹æ–‡ï¼‰çš„æ¥åœ°å¤šä»£ç†æè¿°ç”Ÿæˆç³»ç»Ÿï¼Œä»¥äº§ç”Ÿå‡†ç¡®å’Œå¤šæ ·åŒ–çš„ä¸´åºŠæè¿°ï¼›ï¼ˆ2ï¼‰ä½¿ç”¨ä¸€ç³»åˆ—æè¿°è€Œä¸æ˜¯å•ä¸ªæç¤ºçš„æ–‡æœ¬ç¼–ç ç­–ç•¥ï¼Œæ•æ‰ç²¾ç»†ä¸”äº’è¡¥çš„ä¸´åºŠä¿¡å·ï¼Œä»¥æ›´å¥½åœ°ä¸è§†è§‰ç‰¹å¾å¯¹é½ã€‚é›†æˆåˆ°VLM-MILç®¡é“ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾ç¤ºäº†æ¯”å•æç¤ºç±»åˆ«åŸºçº¿æ”¹è¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨è‚¾è„å’Œè‚ºç™Œæ•°æ®é›†ä¸Šå®ç°äº†ä¸æœ€æ–°æ¨¡å‹ç›¸å½“çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01293v2">PDF</a> Acccepted in MICCAI Workshop 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°†å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰ä¸è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç»“åˆç”¨äºå…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰åˆ†ç±»çš„æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆä¸´åºŠæè¿°æˆ–é‡‡ç”¨å›ºå®šé•¿åº¦æç¤ºæ¥è¡¨ç¤ºå¤æ‚ç—…ç†æ¦‚å¿µçš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤šä»£ç†æè¿°çš„è§†è§‰è¯­è¨€MILæ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªå…³é”®è´¡çŒ®ï¼šä¸€æ˜¯åŸºäºç—…ç†å­¦æ•™æå’Œä»£ç†ä¸“ä¸šåŒ–ç”Ÿæˆå‡†ç¡®å¤šæ ·çš„ä¸´åºŠæè¿°ï¼›äºŒæ˜¯é‡‡ç”¨æè¿°åˆ—è¡¨è¿›è¡Œæ–‡æœ¬ç¼–ç ï¼Œä»¥æ•è·ç²¾ç»†çš„ã€äº’è¡¥çš„ä¸´åºŠä¿¡å·ï¼Œå®ç°ä¸è§†è§‰ç‰¹å¾çš„æ›´å¥½å¯¹é½ã€‚è¯¥æ¡†æ¶åœ¨è‚¾ç™Œå’Œè‚ºç™Œæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå•æç¤ºç±»åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸æœ€æ–°æ¨¡å‹è¡¨ç°ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ˜¯é€‚ç”¨äºå…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰åˆ†ç±»çš„ä¸»è¦æ–¹æ³•ã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¢«å¼•å…¥MILç®¡é“ä»¥èå…¥åŒ»å­¦çŸ¥è¯†ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”¨äºç”Ÿæˆä¸´åºŠæè¿°ï¼Œä½†å­˜åœ¨ä¿¡æ¯è¡¨è¾¾å—é™çš„é—®é¢˜ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶åŒ…å«ä¸€ä¸ªåŸºäºå¤šä»£ç†æè¿°çš„ç³»ç»Ÿï¼Œåˆ©ç”¨ç—…ç†å­¦æ•™æå’Œä»£ç†ä¸“ä¸šåŒ–ç”Ÿæˆå‡†ç¡®å¤šæ ·çš„ä¸´åºŠæè¿°ã€‚</li>
<li>é‡‡ç”¨æè¿°åˆ—è¡¨è¿›è¡Œæ–‡æœ¬ç¼–ç ï¼Œæ•è·ç²¾ç»†çš„ã€äº’è¡¥çš„ä¸´åºŠä¿¡å·ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†ä¸è§†è§‰ç‰¹å¾çš„æ›´å¥½å¯¹é½ï¼Œæ€§èƒ½ä¼˜äºå•æç¤ºç±»åŸºçº¿æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01293">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6f1c1b241464e40b39de9c0c0738246c" align="middle">
<img src="https://picx.zhimg.com/v2-e25081b512f7089049f380d6f22c0e4a" align="middle">
<img src="https://picx.zhimg.com/v2-0f39b9c2673410ea1b792069e560f8e5" align="middle">
<img src="https://picx.zhimg.com/v2-852d98b4d1aa4c17caf38f993cc6f2cf" align="middle">
<img src="https://picx.zhimg.com/v2-b93ab6f194da96772302793b999f0111" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Model-Editing-as-a-Double-Edged-Sword-Steering-Agent-Ethical-Behavior-Toward-Beneficence-or-Harm"><a href="#Model-Editing-as-a-Double-Edged-Sword-Steering-Agent-Ethical-Behavior-Toward-Beneficence-or-Harm" class="headerlink" title="Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm"></a>Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm</h2><p><strong>Authors:Baixiang Huang, Zhen Tan, Haoran Wang, Zijie Liu, Dawei Li, Ali Payani, Huan Liu, Tianlong Chen, Kai Shu</strong></p>
<p>Agents based on Large Language Models (LLMs) have demonstrated strong capabilities across a wide range of tasks. However, deploying LLM-based agents in high-stakes domains comes with significant safety and ethical risks. Unethical behavior by these agents can directly result in serious real-world consequences, including physical harm and financial loss. To efficiently steer the ethical behavior of agents, we frame agent behavior steering as a model editing task, which we term Behavior Editing. Model editing is an emerging area of research that enables precise and efficient modifications to LLMs while preserving their overall capabilities. To systematically study and evaluate this approach, we introduce BehaviorBench, a multi-tier benchmark grounded in psychological moral theories. This benchmark supports both the evaluation and editing of agent behaviors across a variety of scenarios, with each tier introducing more complex and ambiguous scenarios. We first demonstrate that Behavior Editing can dynamically steer agents toward the target behavior within specific scenarios. Moreover, Behavior Editing enables not only scenario-specific local adjustments but also more extensive shifts in an agentâ€™s global moral alignment. We demonstrate that Behavior Editing can be used to promote ethical and benevolent behavior or, conversely, to induce harmful or malicious behavior. Through extensive evaluations of agents built on frontier LLMs, BehaviorBench validates the effectiveness of behavior editing across a wide range of models and scenarios. Our findings offer key insights into a new paradigm for steering agent behavior, highlighting both the promise and perils of Behavior Editing.</p>
<blockquote>
<p>åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»£ç†äººåœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨é«˜é£é™©é¢†åŸŸéƒ¨ç½²è¿™äº›ä»£ç†äººä¼šä¼´éšç€é‡å¤§çš„å®‰å…¨å’Œé“å¾·é£é™©ã€‚è¿™äº›ä»£ç†äººçš„ä¸é“å¾·è¡Œä¸ºå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡çš„ç°å®åæœï¼ŒåŒ…æ‹¬äººèº«ä¼¤å®³å’Œè´¢äº§æŸå¤±ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å¼•å¯¼ä»£ç†äººçš„é“å¾·è¡Œä¸ºï¼Œæˆ‘ä»¬å°†ä»£ç†äººè¡Œä¸ºå¼•å¯¼å®šä¹‰ä¸ºæ¨¡å‹ç¼–è¾‘ä»»åŠ¡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºè¡Œä¸ºç¼–è¾‘ã€‚æ¨¡å‹ç¼–è¾‘æ˜¯ä¸€ä¸ªæ–°å…´çš„ç ”ç©¶é¢†åŸŸï¼Œå¯ä»¥å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œç²¾ç¡®æœ‰æ•ˆçš„ä¿®æ”¹ï¼ŒåŒæ—¶ä¿æŒå…¶æ•´ä½“èƒ½åŠ›ã€‚ä¸ºäº†ç³»ç»Ÿåœ°ç ”ç©¶å’Œè¯„ä¼°è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å¼•å…¥äº†BehaviorBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¿ƒç†é“å¾·ç†è®ºçš„å¤šå±‚æ¬¡åŸºå‡†ã€‚è¯¥åŸºå‡†æ”¯æŒè·¨å„ç§åœºæ™¯å¯¹ä»£ç†è¡Œä¸ºçš„è¯„ä¼°å’Œç¼–è¾‘ï¼Œæ¯ä¸€å±‚éƒ½å¼•å…¥æ›´å¤æ‚å’Œæ¨¡ç³Šçš„åœºæ™¯ã€‚æˆ‘ä»¬é¦–å…ˆè¯æ˜è¡Œä¸ºç¼–è¾‘å¯ä»¥åŠ¨æ€å¼•å¯¼ä»£ç†äººåœ¨ç‰¹å®šåœºæ™¯ä¸­çš„ç›®æ ‡è¡Œä¸ºã€‚è€Œä¸”ï¼Œè¡Œä¸ºç¼–è¾‘ä¸ä»…å¯ä»¥è¿›è¡Œåœºæ™¯ç‰¹å®šçš„å±€éƒ¨è°ƒæ•´ï¼Œè¿˜å¯ä»¥å¯¹ä»£ç†äººçš„å…¨å±€é“å¾·å®šä½è¿›è¡Œæ›´å¹¿æ³›çš„æ”¹å˜ã€‚æˆ‘ä»¬è¯æ˜ï¼Œè¡Œä¸ºç¼–è¾‘å¯ç”¨äºä¿ƒè¿›é“å¾·å’Œä»æ…ˆçš„è¡Œä¸ºï¼Œåä¹‹äº¦ç„¶ï¼Œå¯ä»¥è¯±å¯¼æœ‰å®³æˆ–æ¶æ„è¡Œä¸ºã€‚é€šè¿‡å¯¹åŸºäºå‰æ²¿å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†äººçš„å¹¿æ³›è¯„ä¼°ï¼ŒBehaviorBenchéªŒè¯äº†è¡Œä¸ºç¼–è¾‘åœ¨å¹¿æ³›æ¨¡å‹å’Œåœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºå¼•å¯¼ä»£ç†äººè¡Œä¸ºçš„æ–°èŒƒå¼æä¾›äº†å…³é”®è§è§£ï¼Œçªå‡ºäº†è¡Œä¸ºç¼–è¾‘çš„æ½œåŠ›å’Œé£é™©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.20606v2">PDF</a> AAAI 2026 Oral. 14 pages (including appendix), 11 figures. Code, data, results, and additional resources are available at: <a target="_blank" rel="noopener" href="https://model-editing.github.io/">https://model-editing.github.io</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨é«˜é£é™©é¢†åŸŸéƒ¨ç½²è¿™äº›ä»£ç†å­˜åœ¨é‡å¤§å®‰å…¨å’Œé“å¾·é£é™©ã€‚ä¸é“å¾·è¡Œä¸ºå¯èƒ½å¯¼è‡´ä¸¥é‡åæœï¼ŒåŒ…æ‹¬äººèº«ä¼¤å®³å’Œè´¢åŠ¡æŸå¤±ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å¼•å¯¼ä»£ç†çš„é“å¾·è¡Œä¸ºï¼Œæˆ‘ä»¬å°†ä»£ç†è¡Œä¸ºå¼•å¯¼è§†ä¸ºæ¨¡å‹ç¼–è¾‘ä»»åŠ¡ï¼Œç§°ä¸ºè¡Œä¸ºç¼–è¾‘ã€‚ä¸ºäº†ç³»ç»Ÿåœ°ç ”ç©¶å’Œè¯„ä¼°è¿™ä¸€æ–¹æ³•ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºå¿ƒç†é“å¾·ç†è®ºçš„å¤šå±‚æ¬¡åŸºå‡†æµ‹è¯•å¹³å°BehaviorBenchã€‚è¯¥åŸºå‡†æµ‹è¯•å¹³å°æ”¯æŒå¯¹å„ç§åœºæ™¯ä¸‹çš„ä»£ç†è¡Œä¸ºè¿›è¡Œè¯„ä¼°å’Œç¼–è¾‘ï¼Œæ¯ä¸€å±‚éƒ½å¼•å…¥æ›´å¤æ‚å’Œæ¨¡ç³Šçš„åœºæ™¯ã€‚æˆ‘ä»¬è¯æ˜äº†è¡Œä¸ºç¼–è¾‘å¯ä»¥åŠ¨æ€å¼•å¯¼ä»£ç†åœ¨ç‰¹å®šåœºæ™¯ä¸­çš„ç›®æ ‡è¡Œä¸ºã€‚è€Œä¸”ï¼Œè¡Œä¸ºç¼–è¾‘ä¸ä»…å¯ä»¥è¿›è¡Œåœºæ™¯ç‰¹å®šçš„å±€éƒ¨è°ƒæ•´ï¼Œè¿˜å¯ä»¥å¯¹ä»£ç†çš„å…¨å±€é“å¾·å¯¹é½è¿›è¡Œæ›´å¹¿æ³›çš„è°ƒæ•´ã€‚é€šè¿‡å‰æ²¿LLMæ„å»ºçš„ä»£ç†çš„å¹¿æ³›è¯„ä¼°ï¼ŒBehaviorBenchéªŒè¯äº†è¡Œä¸ºç¼–è¾‘åœ¨å¹¿æ³›æ¨¡å‹å’Œåœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºå¼•å¯¼ä»£ç†è¡Œä¸ºçš„æ–°èŒƒå¼æä¾›äº†å…³é”®è§è§£ï¼Œçªå‡ºäº†è¡Œä¸ºç¼–è¾‘çš„æ‰¿è¯ºå’Œå±é™©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based agents demonstrate strong capabilities across various tasks but come with safety and ethical risks in high-stakes domains.</li>
<li>ä¸é“å¾·è¡Œä¸ºå¯èƒ½å¯¼è‡´ä¸¥é‡çš„ç°å®åæœã€‚</li>
<li>è¡Œä¸ºç¼–è¾‘å¯ä½œä¸ºå¼•å¯¼ä»£ç†é“å¾·è¡Œä¸ºçš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>BehaviorBenchä½œä¸ºå¤šå±‚æ¬¡çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œæ”¯æŒå¯¹ä»£ç†è¡Œä¸ºè¿›è¡Œç³»ç»Ÿæ€§çš„è¯„ä¼°å’Œç¼–è¾‘ã€‚</li>
<li>è¡Œä¸ºç¼–è¾‘èƒ½å¤Ÿåœ¨ç‰¹å®šåœºæ™¯ä¸­åŠ¨æ€å¼•å¯¼ä»£ç†çš„ç›®æ ‡è¡Œä¸ºã€‚</li>
<li>è¡Œä¸ºç¼–è¾‘ä¸ä»…å¯ä»¥è¿›è¡Œå±€éƒ¨è°ƒæ•´ï¼Œè¿˜å¯ä»¥å¯¹ä»£ç†çš„å…¨å±€é“å¾·å¯¹é½è¿›è¡Œå¹¿æ³›è°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.20606">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2ad5bda44830d0e690239254d1e4676d" align="middle">
<img src="https://picx.zhimg.com/v2-299735fa031196ef612657c4e1314d6d" align="middle">
<img src="https://picx.zhimg.com/v2-22f4f668f067a6ac94b7d011fe72bc75" align="middle">
<img src="https://picx.zhimg.com/v2-d7a7fc8b416785334361c988b07b8065" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="GraphCodeAgent-Dual-Graph-Guided-LLM-Agent-for-Retrieval-Augmented-Repo-Level-Code-Generation"><a href="#GraphCodeAgent-Dual-Graph-Guided-LLM-Agent-for-Retrieval-Augmented-Repo-Level-Code-Generation" class="headerlink" title="GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation"></a>GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation</h2><p><strong>Authors:Jia Li, Xianjie Shi, Kechi Zhang, Ge Li, Zhi Jin, Lei Li, Huangzhao Zhang, Jia Li, Fang Liu, Yuwei Zhang, Zhengwei Tao, Yihong Dong, Yuqi Zhu, Chongyang Tao</strong></p>
<p>Writing code requires significant time and effort in software development. To automate this process, researchers have made substantial progress for code generation. Recently, large language models (LLMs) have demonstrated remarkable proficiency in function-level code generation, yet their performance significantly degrades in the real-world software development process, where coding tasks are deeply embedded within specific repository contexts. Existing studies attempt to use retrieval-augmented code generation (RACG) approaches to mitigate this demand. However, there is a gap between natural language (NL) requirements and programming implementations. This results in the failure to retrieve the relevant code of these fine-grained subtasks. To address this challenge, we propose GraphCodeAgent, a dual graph-guided LLM agent for retrieval-augmented repo-level code generation, bridging the gap between NL requirements and programming implementations. Our approach constructs two interconnected graphs: a Requirement Graph (RG) to model requirement relations of code snippets within the repository, as well as the relations between the target requirement and the requirements of these code snippets, and a Structural-Semantic Code Graph (SSCG) to capture the repositoryâ€™s intricate code dependencies. Guided by this, an LLM-powered agent performs multi-hop reasoning to systematically retrieve all context code snippets, including implicit and explicit code snippets, even if they are not explicitly expressed in requirements. We evaluated GraphCodeAgent on three advanced LLMs with the two widely-used repo-level code generation benchmarks DevEval and CoderEval. Extensive experiment results show that GraphCodeAgent significantly outperforms state-of-the-art baselines.</p>
<blockquote>
<p>ç¼–å†™ä»£ç åœ¨è½¯ä»¶å¼€å‘è¿‡ç¨‹ä¸­éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚ä¸ºäº†è‡ªåŠ¨åŒ–è¿™ä¸€è¿‡ç¨‹ï¼Œç ”ç©¶äººå‘˜åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å‡½æ•°çº§åˆ«çš„ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºäº†æƒŠäººçš„ç†Ÿç»ƒç¨‹åº¦ï¼Œä½†åœ¨ç°å®ä¸–ç•Œçš„è½¯ä»¶å¼€å‘è¿‡ç¨‹ä¸­ï¼Œå®ƒä»¬çš„æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå› ä¸ºç¼–ç ä»»åŠ¡æ·±æ·±åµŒå…¥åœ¨ç‰¹å®šçš„å­˜å‚¨åº“ä¸Šä¸‹æ–‡ä¸­ã€‚ç°æœ‰ç ”ç©¶è¯•å›¾é‡‡ç”¨æ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆï¼ˆRACGï¼‰æ–¹æ³•æ¥ç¼“è§£è¿™ä¸€éœ€æ±‚ã€‚ç„¶è€Œï¼Œè‡ªç„¶è¯­è¨€ï¼ˆNLï¼‰è¦æ±‚å’Œç¼–ç¨‹å®ç°ä¹‹é—´å­˜åœ¨å·®è·ã€‚è¿™å¯¼è‡´æ— æ³•æ£€ç´¢è¿™äº›ç²¾ç»†ç²’åº¦å­ä»»åŠ¡çš„ç›¸å…³ä»£ç ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†GraphCodeAgentï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ£€ç´¢å¢å¼ºå‹å­˜å‚¨åº“çº§åˆ«ä»£ç ç”Ÿæˆçš„åŒå›¾å¼•å¯¼LLMä»£ç†ï¼Œå®ƒå¼¥è¡¥äº†è‡ªç„¶è¯­è¨€è¦æ±‚å’Œç¼–ç¨‹å®ç°ä¹‹é—´çš„ç©ºç™½ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ„å»ºäº†ä¸¤ä¸ªç›¸äº’å…³è”çš„å›¾ï¼šä¸€ä¸ªæ˜¯éœ€æ±‚å›¾ï¼ˆRGï¼‰ï¼Œç”¨äºå»ºæ¨¡å­˜å‚¨åº“å†…ä»£ç ç‰‡æ®µçš„è¦æ±‚å…³ç³»ä»¥åŠç›®æ ‡è¦æ±‚ä¸è¿™äº›ä»£ç ç‰‡æ®µçš„è¦æ±‚ä¹‹é—´çš„å…³ç³»ï¼›å¦ä¸€ä¸ªæ˜¯ç»“æ„è¯­ä¹‰ä»£ç å›¾ï¼ˆSSCGï¼‰ï¼Œç”¨äºæ•è·å­˜å‚¨åº“ä¸­å¤æ‚çš„ä»£ç ä¾èµ–å…³ç³»ã€‚é€šè¿‡æ­¤æŒ‡å¯¼ï¼ŒLLMé©±åŠ¨çš„ä»£ç†æ‰§è¡Œå¤šè·³æ¨ç†ï¼Œä»¥ç³»ç»Ÿåœ°æ£€ç´¢æ‰€æœ‰ä¸Šä¸‹æ–‡ä»£ç ç‰‡æ®µï¼ŒåŒ…æ‹¬éšå¼å’Œæ˜¾å¼ä»£ç ç‰‡æ®µï¼Œå³ä½¿å®ƒä»¬æ²¡æœ‰åœ¨è¦æ±‚ä¸­æ˜ç¡®è¡¨è¾¾ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„å­˜å‚¨åº“çº§åˆ«ä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•DevEvalå’ŒCoderEvalä¸Šè¯„ä¼°äº†GraphCodeAgentã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGraphCodeAgentæ˜¾è‘—ä¼˜äºæœ€æ–°åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10046v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†è½¯ä»¶å¼€å‘ç”Ÿæˆä»£ç è¿‡ç¨‹ä¸­çš„è‡ªåŠ¨åŒ–é—®é¢˜ï¼ŒæŒ‡å‡ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠŸèƒ½çº§åˆ«çš„ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†åœ¨ç°å®ä¸–ç•Œè½¯ä»¶å¼€å‘è¿‡ç¨‹ä¸­æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†GraphCodeAgentï¼Œå®ƒæ˜¯ä¸€ä¸ªç”±åŒå›¾å¼•å¯¼çš„è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œç”¨äºå¢å¼ºä»“åº“çº§åˆ«çš„ä»£ç ç”Ÿæˆã€‚GraphCodeAgentæ„å»ºäº†ä¸¤ä¸ªç›¸äº’è¿æ¥çš„å›¾ï¼šéœ€æ±‚å›¾ï¼ˆRGï¼‰å’Œç»“æ„è¯­ä¹‰ä»£ç å›¾ï¼ˆSSCGï¼‰ï¼Œä»¥æ•æ‰ä»“åº“å†…ä»£ç ç‰‡æ®µçš„è¦æ±‚å…³ç³»ä»¥åŠç›®æ ‡è¦æ±‚ä¸è¿™äº›ä»£ç ç‰‡æ®µä¹‹é—´çš„å…³ç³»ï¼Œä»¥åŠä»“åº“çš„å¤æ‚ä»£ç ä¾èµ–å…³ç³»ã€‚åœ¨DevEvalå’ŒCoderEvalä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„ä»“åº“çº§åˆ«ä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸Šï¼ŒGraphCodeAgentåœ¨é«˜çº§è¯­è¨€æ¨¡å‹ä¸Šçš„å®éªŒç»“æœæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠŸèƒ½çº§åˆ«çš„ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†åœ¨ç°å®è½¯ä»¶å¼€å‘è¿‡ç¨‹ä¸­å­˜åœ¨æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚</li>
<li>GraphCodeAgentæ˜¯ä¸€ä¸ªåŒå›¾å¼•å¯¼çš„è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç ”ç©¶ä¸­è‡ªç„¶è¯­è¨€ï¼ˆNLï¼‰è¦æ±‚å’Œç¼–ç¨‹å®ç°ä¹‹é—´çš„å·®è·é—®é¢˜ã€‚</li>
<li>GraphCodeAgentæ„å»ºäº†ä¸¤ä¸ªå›¾ï¼šéœ€æ±‚å›¾ï¼ˆRGï¼‰ç”¨äºå»ºæ¨¡ä»“åº“å†…ä»£ç ç‰‡æ®µçš„è¦æ±‚å…³ç³»ï¼Œç»“æ„è¯­ä¹‰ä»£ç å›¾ï¼ˆSSCGï¼‰ç”¨äºæ•æ‰ä»“åº“çš„å¤æ‚ä»£ç ä¾èµ–å…³ç³»ã€‚</li>
<li>GraphCodeAgentèƒ½å¤Ÿç³»ç»Ÿåœ°æ£€ç´¢æ‰€æœ‰ä¸Šä¸‹æ–‡ä»£ç ç‰‡æ®µï¼ŒåŒ…æ‹¬éšå¼å’Œæ˜¾å¼ä»£ç ç‰‡æ®µï¼Œå³ä½¿å®ƒä»¬æ²¡æœ‰åœ¨è¦æ±‚ä¸­æ˜ç¡®è¡¨è¾¾ã€‚</li>
<li>GraphCodeAgentåœ¨DevEvalå’ŒCoderEvalä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥ç ”ç©¶å¼ºè°ƒäº†ä½¿ç”¨LLMè¿›è¡Œä»£ç ç”Ÿæˆæ—¶çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10046">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8b5ad0f5d40002c7c6df63a67c2932b6" align="middle">
<img src="https://picx.zhimg.com/v2-3130fb96b9fb81746aa3794572ea7715" align="middle">
<img src="https://picx.zhimg.com/v2-1bf96334095151257a27d97c4fbb1537" align="middle">
<img src="https://picx.zhimg.com/v2-d4d243c5f147d63859620dea8476de32" align="middle">
<img src="https://picx.zhimg.com/v2-138c62886573c10796e1d3b6a1981c81" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Harnessing-Diverse-Perspectives-A-Multi-Agent-Framework-for-Enhanced-Error-Detection-in-Knowledge-Graphs"><a href="#Harnessing-Diverse-Perspectives-A-Multi-Agent-Framework-for-Enhanced-Error-Detection-in-Knowledge-Graphs" class="headerlink" title="Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs"></a>Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs</h2><p><strong>Authors:Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu</strong></p>
<p>Knowledge graphs are widely used in industrial applications, making error detection crucial for ensuring the reliability of downstream applications. Existing error detection methods often fail to effectively utilize fine-grained subgraph information and rely solely on fixed graph structures, while also lacking transparency in their decision-making processes, which results in suboptimal detection performance. In this paper, we propose a novel Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that utilizes multiple large language models (LLMs) in a collaborative setting. By concatenating fine-grained, bidirectional subgraph embeddings with LLM-based query embeddings during training, our framework integrates these representations to produce four specialized agents. These agents utilize subgraph information from different dimensions to engage in multi-round discussions, thereby improving error detection accuracy and ensuring a transparent decision-making process. Extensive experiments on FB15K and WN18RR demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the accuracy and robustness of KG evaluation. For specific industrial scenarios, our framework can facilitate the training of specialized agents using domain-specific knowledge graphs for error detection, which highlights the potential industrial application value of our framework. Our code and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/kse-ElEvEn/MAKGED">https://github.com/kse-ElEvEn/MAKGED</a>.</p>
<blockquote>
<p>çŸ¥è¯†å›¾è°±åœ¨å·¥ä¸šåº”ç”¨ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œå› æ­¤é”™è¯¯æ£€æµ‹å¯¹äºç¡®ä¿ä¸‹æ¸¸åº”ç”¨çš„å¯é æ€§è‡³å…³é‡è¦ã€‚ç°æœ‰çš„é”™è¯¯æ£€æµ‹æ–¹æ³•å¾€å¾€ä¸èƒ½æœ‰æ•ˆåœ°åˆ©ç”¨ç»†ç²’åº¦å­å›¾ä¿¡æ¯ï¼Œä»…ä¾èµ–äºå›ºå®šçš„å›¾ç»“æ„ï¼Œä¸”å…¶å†³ç­–è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºçŸ¥è¯†å›¾è°±é”™è¯¯æ£€æµ‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆMAKGEDï¼‰ï¼Œè¯¥æ¡†æ¶åœ¨åä½œç¯å¢ƒä¸­åˆ©ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è¿æ¥ç»†ç²’åº¦ã€åŒå‘å­å›¾åµŒå…¥å’ŒåŸºäºLLMçš„æŸ¥è¯¢åµŒå…¥ï¼Œå°†è¿™äº›è¡¨ç¤ºé›†æˆåˆ°æˆ‘ä»¬çš„æ¡†æ¶ä¸­ï¼Œç”Ÿæˆå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ã€‚è¿™äº›æ™ºèƒ½ä½“åˆ©ç”¨æ¥è‡ªä¸åŒç»´åº¦çš„å­å›¾ä¿¡æ¯è¿›è¡Œå¤šè½®è®¨è®ºï¼Œä»è€Œæé«˜é”™è¯¯æ£€æµ‹ç²¾åº¦ï¼Œå¹¶ç¡®ä¿å†³ç­–è¿‡ç¨‹çš„é€æ˜æ€§ã€‚åœ¨FB15Kå’ŒWN18RRä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMAKGEDä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œæé«˜äº†çŸ¥è¯†å›¾è°±è¯„ä¼°çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚å¯¹äºç‰¹å®šçš„å·¥ä¸šåœºæ™¯ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥åˆ©ç”¨é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å›¾è°±è®­ç»ƒä¸“ä¸šæ™ºèƒ½ä½“è¿›è¡Œé”™è¯¯æ£€æµ‹ï¼Œè¿™å‡¸æ˜¾äº†æˆ‘ä»¬æ¡†æ¶åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„æ½œåœ¨ä»·å€¼ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/kse-ElEvEn/MAKGED%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/kse-ElEvEn/MAKGEDæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15791v4">PDF</a> This paper has been ACCEPTED as a FULL PAPER at DASFAA 2025 (Oral)</p>
<p><strong>Summary</strong><br>çŸ¥è¯†å›¾è°±åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„é”™è¯¯æ£€æµ‹è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ç»†ç²’åº¦å­å›¾ä¿¡æ¯ã€ä¾èµ–å›ºå®šå›¾ç»“æ„ä»¥åŠå†³ç­–è¿‡ç¨‹ä¸é€æ˜ç­‰é—®é¢˜ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½ä¸ä½³ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“çš„çŸ¥è¯†å›¾è°±é”™è¯¯æ£€æµ‹æ¡†æ¶ï¼ˆMAKGEDï¼‰ï¼Œåˆ©ç”¨ååŒè®¾ç½®ä¸­çš„å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚é€šè¿‡è®­ç»ƒæ—¶ç»“åˆç»†ç²’åº¦åŒå‘å­å›¾åµŒå…¥å’ŒLLMåŸºäºæŸ¥è¯¢çš„åµŒå…¥ï¼Œè¯¥æ¡†æ¶æ•´åˆè¿™äº›è¡¨ç¤ºäº§ç”Ÿå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ã€‚æ™ºèƒ½ä½“åˆ©ç”¨ä¸åŒç»´åº¦çš„å­å›¾ä¿¡æ¯è¿›è¡Œå¤šè½®è®¨è®ºï¼Œä»è€Œæé«˜é”™è¯¯æ£€æµ‹ç²¾åº¦å¹¶ç¡®ä¿é€æ˜çš„å†³ç­–è¿‡ç¨‹ã€‚åœ¨FB15Kå’ŒWN18RRä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMAKGEDä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œæé«˜çŸ¥è¯†å›¾è°±è¯„ä¼°çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚è¯¥æ¡†æ¶å¯ä¸ºå·¥ä¸šåœºæ™¯ä¸­ç‰¹å®šé¢†åŸŸçŸ¥è¯†å›¾è°±çš„é”™è¯¯æ£€æµ‹è®­ç»ƒä¸“ä¸šæ™ºèƒ½ä½“ï¼Œå‡¸æ˜¾å…¶å·¥ä¸šåº”ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çŸ¥è¯†å›¾è°±åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„é”™è¯¯æ£€æµ‹å¾ˆé‡è¦ï¼Œå½±å“ä¸‹æ¸¸åº”ç”¨çš„å¯é æ€§ã€‚</li>
<li>ç°æœ‰é”™è¯¯æ£€æµ‹æ–¹æ³•å­˜åœ¨æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ç»†ç²’åº¦å­å›¾ä¿¡æ¯çš„é—®é¢˜ã€‚</li>
<li>MAKGEDæ¡†æ¶åˆ©ç”¨å¤šæ™ºèƒ½ä½“å’Œå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡ŒååŒçŸ¥è¯†å›¾è°±é”™è¯¯æ£€æµ‹ã€‚</li>
<li>è¯¥æ¡†æ¶ç»“åˆå­å›¾åµŒå…¥å’ŒæŸ¥è¯¢åµŒå…¥ï¼Œäº§ç”Ÿå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ï¼Œæé«˜é”™è¯¯æ£€æµ‹ç²¾åº¦ã€‚</li>
<li>æ™ºèƒ½ä½“åˆ©ç”¨ä¸åŒç»´åº¦å­å›¾ä¿¡æ¯è¿›è¡Œå¤šè½®è®¨è®ºï¼Œç¡®ä¿é€æ˜çš„å†³ç­–è¿‡ç¨‹ã€‚</li>
<li>MAKGEDåœ¨FB15Kå’ŒWN18RRæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æœ€æ–°æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15791">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ad738cec9cb77ad770f2adbd605a433e" align="middle">
<img src="https://picx.zhimg.com/v2-dbc4550f83b33cbd1fd158c3074d9dcd" align="middle">
<img src="https://picx.zhimg.com/v2-181e5799444d5ee4f721e50225ed38bf" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="UniDebugger-Hierarchical-Multi-Agent-Framework-for-Unified-Software-Debugging"><a href="#UniDebugger-Hierarchical-Multi-Agent-Framework-for-Unified-Software-Debugging" class="headerlink" title="UniDebugger: Hierarchical Multi-Agent Framework for Unified Software Debugging"></a>UniDebugger: Hierarchical Multi-Agent Framework for Unified Software Debugging</h2><p><strong>Authors:Cheryl Lee, Chunqiu Steven Xia, Longji Yang, Jen-tse Huang, Zhouruixin Zhu, Lingming Zhang, Michael R. Lyu</strong></p>
<p>Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25$\times$ to 2.56$\times$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on <a target="_blank" rel="noopener" href="https://github.com/AcceptePapier/UniDebugger">https://github.com/AcceptePapier/UniDebugger</a>.</p>
<blockquote>
<p>è½¯ä»¶è°ƒè¯•æ˜¯ä¸€é¡¹è€—æ—¶çš„ä»»åŠ¡ï¼Œæ¶‰åŠè¯¸å¦‚æ•…éšœå®šä½å’Œè¡¥ä¸ç”Ÿæˆç­‰ä¸€ç³»åˆ—æ­¥éª¤ï¼Œæ¯ä¸€æ­¥éƒ½éœ€è¦å½»åº•åˆ†æå’Œå¯¹åº•å±‚é€»è¾‘æœ‰æ·±åˆ»çš„ç†è§£ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¼–ç ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„æ½œåŠ›ï¼Œä½†å®ƒä»¬åœ¨è¿›è¡Œè°ƒè¯•æ—¶çš„è¡¨ç°ä»ç„¶æœ‰é™ã€‚å½“å‰åŸºäºLLMçš„æ–¹æ³•é€šå¸¸å…³æ³¨å­¤ç«‹çš„æ­¥éª¤ï¼Œéš¾ä»¥å¤„ç†å¤æ‚çš„é”™è¯¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶FixAgentï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“ååŒè¿›è¡Œç»Ÿä¸€è°ƒè¯•ã€‚å®ƒæ¨¡ä»¿å¼€å‘è€…çš„æ•´ä¸ªè®¤çŸ¥è¿‡ç¨‹ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“è¢«ä¸“é—¨åŒ–ä¸ºè¿™ä¸€è¿‡ç¨‹ä¸­çš„ç‰¹å®šç»„ä»¶ï¼Œè€Œä¸æ˜¯åƒä»¥å‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­é‚£æ ·æ¨¡ä»¿ç‹¬ç«‹ä¸“å®¶çš„è¡Œä¸ºã€‚æ™ºèƒ½ä½“é€šè¿‡ä¸‰çº§è®¾è®¡è¿›è¡Œåè°ƒï¼Œéµå¾ªè°ƒè¯•çš„è®¤çŸ¥æ¨¡å‹ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”å¤„ç†å„ç§å¤æ‚åº¦çš„é”™è¯¯ã€‚åœ¨å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFixAgentæ˜¾è‘—ä¼˜äºæœ€æ–°çš„ä¿®å¤æ–¹æ³•ï¼Œåœ¨ç¼ºé™·ä¿®å¤çº§åˆ«çš„åŸºå‡†æµ‹è¯•Defects4Jä¸Šä¿®å¤äº†ä»å¢åŠ åˆ°æ”¾å¤§ç‡çš„é”™è¯¯ä¹˜ä»¥æ•°ä¸ç­‰çš„ä»£ç é—®é¢˜ï¼ˆå¢åŠ åˆ°äº†å…ˆå‰çš„ä¿®æ­£ç‡çš„ç™¾åˆ†ä¹‹ä¸¤ç™¾ï¼‰ã€‚æˆ‘ä»¬çš„æºä»£ç å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/AcceptePapier/UniDebugger%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82%E4%B8%8D%E5%90%8C%E4%BA%8E%E5%9F%BA%E7%BA%BF%E6%96%B9%E6%B3%95%E7%9A%84%E6%98%AF%EF%BC%8C%E6%88%91%E4%BB%AC%E7%9A%84%E6%A1%86%E6%9E%B6%E4%B8%8D%E9%9C%80%E8%A6%81%E7%9C%9F%E5%AE%9E%E6%A0%B9%E6%BA%90%E4%BB%A3%E7%A0%81%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%94%AF%E6%8C%81%E5%B0%B1%E8%83%BD%E5%AE%9E%E7%8E%B0%E8%BF%99%E6%A0%B7%E7%9A%84%E6%80%A7%E8%83%BD%E3%80%82">https://github.com/AcceptePapier/UniDebuggerä¸Šæ‰¾åˆ°ã€‚ä¸åŒäºåŸºçº¿æ–¹æ³•çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä¸éœ€è¦çœŸå®æ ¹æºä»£ç è¯­å¥çš„æ”¯æŒå°±èƒ½å®ç°è¿™æ ·çš„æ€§èƒ½ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.17153v3">PDF</a> Accepted by EMNLPâ€™25, Main Poster</p>
<p><strong>Summary</strong></p>
<p>è½¯ä»¶è°ƒè¯•æ˜¯ä¸€é¡¹è€—æ—¶çš„å·¥ä½œï¼ŒåŒ…å«æ•…éšœå®šä½å’Œè¡¥ä¸ç”Ÿæˆç­‰å¤šä¸ªæ­¥éª¤ï¼Œéœ€è¦æ·±å…¥åˆ†æå¹¶æ·±åˆ»ç†è§£åº•å±‚é€»è¾‘ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¼–ç ä»»åŠ¡ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†åœ¨è°ƒè¯•æ–¹é¢çš„è¡¨ç°ä»ç„¶æœ‰é™ã€‚å½“å‰åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è°ƒè¯•æ–¹æ³•å¾€å¾€ä¾§é‡äºå•ä¸ªæ­¥éª¤ï¼Œéš¾ä»¥å¤„ç†å¤æ‚é”™è¯¯ã€‚æœ¬æ–‡æå‡ºé¦–ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶FixAgentï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“ååŒå®ç°ç»Ÿä¸€è°ƒè¯•ã€‚å®ƒæ¨¡ä»¿å¼€å‘è€…çš„æ•´ä¸ªè®¤çŸ¥è¿‡ç¨‹ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“ä½œä¸ºè¿™ä¸€è¿‡ç¨‹çš„ç‰¹å®šç»„ä»¶è€Œä¸æ˜¯ç‹¬ç«‹ä¸“å®¶çš„è¡ŒåŠ¨æ¥å‘æŒ¥ä½œç”¨ã€‚æ™ºèƒ½ä½“é€šè¿‡éµå¾ªè°ƒè¯•çš„è®¤çŸ¥æ¨¡å‹çš„ä¸‰çº§è®¾è®¡è¿›è¡Œåè°ƒï¼Œèƒ½å¤Ÿè‡ªé€‚åº”å¤„ç†ä¸åŒå¤æ‚åº¦çš„é”™è¯¯ã€‚åœ¨å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒFixAgentæ˜¾è‘—ä¼˜äºæœ€æ–°çš„ä¿®å¤æ–¹æ³•ï¼Œåœ¨repoçº§åˆ«çš„åŸºå‡†æµ‹è¯•Defects4Jä¸Šä¿®å¤äº†1.25è‡³2.56å€çš„é”™è¯¯ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œå®ƒä¸éœ€è¦åƒåŸºçº¿æ–¹æ³•é‚£æ ·ä¾èµ–çœŸå®åŸå› çš„ä»£ç è¯­å¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è½¯ä»¶è°ƒè¯•æ˜¯ä¸€ä¸ªæ¶‰åŠå¤šä¸ªæ­¥éª¤çš„å¤æ‚è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ•…éšœå®šä½å’Œè¡¥ä¸ç”Ÿæˆç­‰ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è½¯ä»¶è°ƒè¯•æ–¹é¢çš„è¡¨ç°ä»ç„¶æœ‰é™ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚é”™è¯¯æ—¶ã€‚</li>
<li>FixAgentæ˜¯é¦–ä¸ªç«¯åˆ°ç«¯çš„è°ƒè¯•æ¡†æ¶ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“ååŒå·¥ä½œï¼Œæ¨¡ä»¿äººç±»çš„æ•´ä¸ªè°ƒè¯•è®¤çŸ¥è¿‡ç¨‹ã€‚</li>
<li>FixAgentçš„æ¯ä¸ªæ™ºèƒ½ä½“éƒ½ä¸“æ³¨äºè°ƒè¯•è¿‡ç¨‹ä¸­çš„ç‰¹å®šæ­¥éª¤ã€‚</li>
<li>FixAgenté‡‡ç”¨ä¸‰çº§è®¾è®¡æ¥åè°ƒæ™ºèƒ½ä½“çš„å·¥ä½œï¼Œä»¥å¤„ç†ä¸åŒå¤æ‚åº¦çš„é”™è¯¯ã€‚</li>
<li>FixAgentåœ¨åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æœ€æ–°ä¿®å¤æ–¹æ³•ï¼Œèƒ½å¤Ÿä¿®å¤æ›´å¤šçš„é”™è¯¯ã€‚</li>
<li>FixAgentä¸éœ€è¦çœŸå®åŸå› çš„ä»£ç è¯­å¥ï¼Œè¿™æ˜¯ä¸€ä¸ªé‡è¦çš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.17153">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-20\./crop_Agent/2404.17153v3/page_0_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ff57ad21796ff754750ab8ae6d53f10" align="middle">
<img src="https://picx.zhimg.com/v2-44926ea6e6cc1f3c407d6812f2969ab6" align="middle">
<img src="https://picx.zhimg.com/v2-86a2de2b8b3b42a5da34c66e12ee4d13" align="middle">
<img src="https://picx.zhimg.com/v2-7c348e52a5509083d09c83de0de07912" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-20/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-20/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-20/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-339068b970dc33b0f6b4becd581e7bde" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-20  MAVias Mitigate any Visual Bias
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-20/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e59a29298cac3b1340e089b68e60d5e7" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-20  UniGen-1.5 Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33297.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
