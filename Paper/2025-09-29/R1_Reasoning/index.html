<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-29  Enrich-on-Graph Query-Graph Alignment for Complex Reasoning with LLM   Enriching">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.04027v2/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    83 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-29-æ›´æ–°"><a href="#2025-09-29-æ›´æ–°" class="headerlink" title="2025-09-29 æ›´æ–°"></a>2025-09-29 æ›´æ–°</h1><h2 id="Enrich-on-Graph-Query-Graph-Alignment-for-Complex-Reasoning-with-LLM-Enriching"><a href="#Enrich-on-Graph-Query-Graph-Alignment-for-Complex-Reasoning-with-LLM-Enriching" class="headerlink" title="Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM   Enriching"></a>Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM   Enriching</h2><p><strong>Authors:Songze Li, Zhiqiang Liu, Zhengke Gui, Huajun Chen, Wen Zhang</strong></p>
<p>Large Language Models (LLMs) exhibit strong reasoning capabilities in complex tasks. However, they still struggle with hallucinations and factual errors in knowledge-intensive scenarios like knowledge graph question answering (KGQA). We attribute this to the semantic gap between structured knowledge graphs (KGs) and unstructured queries, caused by inherent differences in their focuses and structures. Existing methods usually employ resource-intensive, non-scalable workflows reasoning on vanilla KGs, but overlook this gap. To address this challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which leverages LLMsâ€™ prior knowledge to enrich KGs, bridge the semantic gap between graphs and queries. EoG enables efficient evidence extraction from KGs for precise and robust reasoning, while ensuring low computational costs, scalability, and adaptability across different methods. Furthermore, we propose three graph quality evaluation metrics to analyze query-graph alignment in KGQA task, supported by theoretical validation of our optimization objectives. Extensive experiments on two KGQA benchmark datasets indicate that EoG can effectively generate high-quality KGs and achieve the state-of-the-art performance. Our code and data are available at <a target="_blank" rel="noopener" href="https://github.com/zjukg/Enrich-on-Graph">https://github.com/zjukg/Enrich-on-Graph</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨çŸ¥è¯†å¯†é›†å‹åœºæ™¯ï¼ˆå¦‚çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰ï¼‰ä¸­ï¼Œå®ƒä»¬ä»ç„¶éš¾ä»¥å¤„ç†å¹»æƒ³å’Œäº‹å®é”™è¯¯ã€‚æˆ‘ä»¬å°†è¿™å½’å› äºç»“æ„åŒ–çš„çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸éç»“æ„åŒ–æŸ¥è¯¢ä¹‹é—´å­˜åœ¨çš„è¯­ä¹‰é¸¿æ²Ÿï¼Œè¿™ç§å·®è·æºäºä¸¤è€…çš„é‡ç‚¹å’Œç»“æ„ä¸Šçš„å›ºæœ‰å·®å¼‚ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨èµ„æºå¯†é›†ã€ä¸å¯æ‰©å±•çš„å·¥ä½œæµå¯¹æ™®é€šçŸ¥è¯†å›¾è°±è¿›è¡Œæ¨ç†ï¼Œä½†å¿½ç•¥äº†è¿™ä¸€å·®è·ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§çµæ´»æ¡†æ¶ï¼Œåä¸ºâ€œå›¾è°±ä¸°å¯Œâ€ï¼ˆEnrich-on-Graphï¼ŒEoGï¼‰ï¼Œå®ƒåˆ©ç”¨LLMçš„å…ˆéªŒçŸ¥è¯†æ¥ä¸°å¯ŒçŸ¥è¯†å›¾è°±ï¼Œå¼¥åˆå›¾è°±å’ŒæŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚EoGèƒ½å¤Ÿå®ç°ä»çŸ¥è¯†å›¾è°±ä¸­é«˜æ•ˆæå–è¯æ®ï¼Œè¿›è¡Œç²¾ç¡®è€Œç¨³å¥çš„æ¨ç†ï¼ŒåŒæ—¶ç¡®ä¿ä½è®¡ç®—æˆæœ¬ã€å¯æ‰©å±•æ€§å’Œè·¨ä¸åŒæ–¹æ³•çš„é€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰é¡¹å›¾è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºåˆ†æKGQAä»»åŠ¡ä¸­çš„æŸ¥è¯¢-å›¾å¯¹é½æƒ…å†µï¼Œå¹¶é€šè¿‡æˆ‘ä»¬çš„ä¼˜åŒ–ç›®æ ‡çš„ç†è®ºéªŒè¯æ¥æ”¯æŒã€‚åœ¨KGQAåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEoGå¯ä»¥æœ‰æ•ˆåœ°ç”Ÿæˆé«˜è´¨é‡çš„çŸ¥è¯†å›¾è°±ï¼Œè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zjukg/Enrich-on-Graph%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zjukg/Enrich-on-Graphæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20810v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨çŸ¥è¯†å¯†é›†å‹åœºæ™¯ï¼ˆå¦‚çŸ¥è¯†å›¾è°±é—®ç­”ï¼‰ä¸­ä»å­˜åœ¨å¹»è§‰å’Œäº‹å®é”™è¯¯é—®é¢˜ã€‚è¿™å½’å› äºç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸éç»“æ„åŒ–æŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿï¼Œæºäºä¸¤è€…å…³æ³¨ç‚¹å’Œç»“æ„ä¸Šçš„å·®å¼‚ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºèµ„æºå¯†é›†å‹çš„ã€ä¸å¯æ‰©å±•çš„å·¥ä½œæµç¨‹æ¥æ¨ç†æ™®é€šçŸ¥è¯†å›¾è°±ï¼Œå´å¿½è§†äº†è¿™ä¸€é¸¿æ²Ÿã€‚ä¸ºè§£å†³æ­¤æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†çµæ´»çš„æ¡†æ¶Enrich-on-Graphï¼ˆEoGï¼‰ï¼Œåˆ©ç”¨LLMsçš„å…ˆéªŒçŸ¥è¯†æ¥ä¸°å¯ŒçŸ¥è¯†å›¾è°±ï¼Œç¼©å°çŸ¥è¯†å›¾è°±ä¸æŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚EoGå¯å®ç°ä»çŸ¥è¯†å›¾è°±ä¸­é«˜æ•ˆæå–è¯æ®ï¼Œè¿›è¡Œç²¾ç¡®ç¨³å¥çš„æ¨ç†ï¼ŒåŒæ—¶ç¡®ä¿ä½è®¡ç®—æˆæœ¬ã€å¯æ‰©å±•æ€§å’Œä¸åŒæ–¹æ³•é—´çš„é€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰é¡¹å›¾è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œåˆ†æKGQAä»»åŠ¡ä¸­çš„æŸ¥è¯¢-å›¾è°±å¯¹é½æƒ…å†µï¼Œå¹¶é€šè¿‡ä¼˜åŒ–ç›®æ ‡çš„ç†è®ºéªŒè¯äºˆä»¥æ”¯æŒã€‚åœ¨KGQAåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒEoGå¯æœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡çŸ¥è¯†å›¾è°±ï¼Œè¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨å¤æ‚ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨çŸ¥è¯†å¯†é›†å‹åœºæ™¯ä¸­å­˜åœ¨å¹»è§‰å’Œäº‹å®é”™è¯¯é—®é¢˜ã€‚</li>
<li>çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸éç»“æ„åŒ–æŸ¥è¯¢ä¹‹é—´å­˜åœ¨è¯­ä¹‰é¸¿æ²Ÿï¼Œæºäºå…¶å…³æ³¨ç‚¹å’Œç»“æ„ä¸Šçš„å·®å¼‚ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨èµ„æºå¯†é›†å‹çš„ã€ä¸å¯æ‰©å±•çš„å·¥ä½œæµç¨‹æ¥æ¨ç†æ™®é€šçŸ¥è¯†å›¾è°±ã€‚</li>
<li>Enrich-on-Graphï¼ˆEoGï¼‰æ¡†æ¶åˆ©ç”¨LLMsçš„å…ˆéªŒçŸ¥è¯†æ¥ä¸°å¯ŒçŸ¥è¯†å›¾è°±ï¼Œç¼©å°çŸ¥è¯†å›¾è°±ä¸æŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚</li>
<li>EoGå¯å®ç°é«˜æ•ˆè¯æ®æå–ï¼Œè¿›è¡Œç²¾ç¡®ç¨³å¥çš„æ¨ç†ï¼ŒåŒæ—¶ç¡®ä¿ä½è®¡ç®—æˆæœ¬ã€å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚</li>
<li>æå‡ºäº†ä¸‰é¡¹å›¾è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºåˆ†æKGQAä»»åŠ¡ä¸­çš„æŸ¥è¯¢-å›¾è°±å¯¹é½æƒ…å†µã€‚</li>
<li>EoGåœ¨KGQAåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜å…¶ç”Ÿæˆé«˜è´¨é‡çŸ¥è¯†å›¾è°±çš„èƒ½åŠ›ï¼Œå¹¶è¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20810">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20810v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20810v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20810v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20810v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="LogReasoner-Empowering-LLMs-with-Expert-like-Coarse-to-Fine-Reasoning-for-Log-Analysis-Tasks"><a href="#LogReasoner-Empowering-LLMs-with-Expert-like-Coarse-to-Fine-Reasoning-for-Log-Analysis-Tasks" class="headerlink" title="LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning   for Log Analysis Tasks"></a>LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning   for Log Analysis Tasks</h2><p><strong>Authors:Lipeng Ma, Yixuan Li, Weidong Yang, Mingjie Zhou, Xinyi Liu, Ben Fei, Shuhao Li, Xiaoyan Sun, Sihang Jiang, Yanghua Xiao</strong></p>
<p>Log analysis is crucial for monitoring system health and diagnosing failures in complex systems. Recent advances in large language models (LLMs) offer new opportunities for automated log analysis, leveraging their reasoning capabilities to perform tasks such as anomaly detection and failure prediction. However, general-purpose LLMs struggle to formulate structured reasoning workflows that align with expert cognition and deliver precise details of reasoning steps. To address these challenges, we propose LogReasoner, a coarse-to-fine reasoning enhancement framework designed to enable LLMs to reason log analysis tasks like experts. LogReasoner consists of two stages: (1) coarse-grained enhancement of expert thinking, where high-level expert thoughts are constructed from collected troubleshooting flowcharts and existing tasks to enable LLMs to formulate structured reasoning workflows and (2) fine-grained enhancement of specific steps, where we first fine-tune the LLM with task-specific stepwise solutions to enhance the LLM for instantiated reasoning, then employ the preference learning to calibrate the LLMâ€™s reasoning details from its mistakes, further strengthen the LLMâ€™s analytical granularity and correctness. We evaluate LogReasoner on four distinct log analysis tasks using open-source LLMs such as Qwen-2.5 and Llama-3. Experimental results show that LogReasoner significantly outperforms existing LLMs, achieving state-of-the-art performance and demonstrating its effectiveness in enhancing the reasoning capabilities of LLMs for log analysis. </p>
<blockquote>
<p>æ—¥å¿—åˆ†æå¯¹äºç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶å†µå’Œè¯Šæ–­å¤æ‚ç³»ç»Ÿä¸­çš„æ•…éšœè‡³å…³é‡è¦ã€‚æœ€è¿‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ä¸ºè‡ªåŠ¨åŒ–æ—¥å¿—åˆ†ææä¾›äº†æ–°çš„æœºä¼šï¼Œåˆ©ç”¨å…¶æ¨ç†èƒ½åŠ›æ¥æ‰§è¡Œå¼‚å¸¸æ£€æµ‹å’Œæ•…éšœé¢„æµ‹ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œé€šç”¨LLMåœ¨å½¢æˆä¸ä¸“å®¶è®¤çŸ¥ç›¸ç¬¦çš„ç»“æ„åŒ–æ¨ç†å·¥ä½œæµç¨‹å¹¶æä¾›ç²¾ç¡®çš„æ¨ç†æ­¥éª¤ç»†èŠ‚æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†LogReasonerï¼Œè¿™æ˜¯ä¸€ä¸ªä»ç²—åˆ°ç»†çš„æ¨ç†å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨ä½¿LLMèƒ½å¤Ÿåƒä¸“å®¶ä¸€æ ·è¿›è¡Œæ—¥å¿—åˆ†æä»»åŠ¡ã€‚LogReasoneråŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šï¼ˆ1ï¼‰ä¸“å®¶æ€ç»´çš„ç²—ç²’åº¦å¢å¼ºï¼Œæˆ‘ä»¬ä»æ”¶é›†çš„æ•…éšœæ’é™¤æµç¨‹å›¾å’Œç°æœ‰ä»»åŠ¡ä¸­æ„å»ºé«˜çº§ä¸“å®¶æ€ç»´ï¼Œä½¿LLMèƒ½å¤Ÿå½¢æˆç»“æ„åŒ–æ¨ç†å·¥ä½œæµç¨‹ï¼›ï¼ˆ2ï¼‰ç‰¹å®šæ­¥éª¤çš„ç²¾ç»†ç²’åº¦å¢å¼ºï¼Œæˆ‘ä»¬é¦–å…ˆå¯¹LLMè¿›è¡Œä¸ä»»åŠ¡ç›¸å…³çš„åˆ†æ­¥è§£å†³æ–¹æ¡ˆçš„å¾®è°ƒï¼Œä»¥å¢å¼ºå…¶å®ä¾‹åŒ–æ¨ç†èƒ½åŠ›ï¼Œç„¶ååˆ©ç”¨åå¥½å­¦ä¹ æ¥æ ¡æ­£LLMçš„æ¨ç†ç»†èŠ‚ä¸­çš„é”™è¯¯ï¼Œè¿›ä¸€æ­¥æé«˜äº†LLMçš„åˆ†æç²¾ç»†åº¦å’Œæ­£ç¡®æ€§ã€‚æˆ‘ä»¬åœ¨å››ä¸ªä¸åŒçš„æ—¥å¿—åˆ†æä»»åŠ¡ä¸Šè¯„ä¼°äº†LogReasonerï¼Œä½¿ç”¨äº†å¼€æºLLMï¼Œå¦‚Qwen-2.5å’ŒLlama-3ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLogReasoneræ˜¾è‘—ä¼˜äºç°æœ‰LLMï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¢å¼ºLLMæ—¥å¿—åˆ†ææ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20798v1">PDF</a> under review</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ—¥å¿—åˆ†æåœ¨ç³»ç»Ÿå¥åº·ç›‘æµ‹å’Œå¤æ‚ç³»ç»Ÿæ•…éšœè¯Šæ–­ä¸­çš„é‡è¦æ€§ï¼Œç ”ç©¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œè‡ªåŠ¨åŒ–æ—¥å¿—åˆ†æã€‚LogReasoneræ¡†æ¶é€šè¿‡ç²—åˆ°ç»†çš„æ¨ç†å¢å¼ºæœºåˆ¶ï¼Œä½¿LLMsèƒ½å¤Ÿåƒä¸“å®¶ä¸€æ ·è¿›è¡Œæ—¥å¿—åˆ†æä»»åŠ¡ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šæ„å»ºä¸“å®¶æ€ç»´çš„ç²—ç²’åº¦å¢å¼ºå’Œç‰¹å®šæ­¥éª¤çš„ç»†ç²’åº¦å¢å¼ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLogReasoneråœ¨æ—¥å¿—åˆ†æä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰LLMsï¼Œè¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œæœ‰æ•ˆæå‡äº†LLMsçš„æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ—¥å¿—åˆ†æå¯¹äºç›‘æµ‹ç³»ç»Ÿå¥åº·å’Œè¯Šæ–­å¤æ‚ç³»ç»Ÿæ•…éšœè‡³å…³é‡è¦ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºè‡ªåŠ¨åŒ–æ—¥å¿—åˆ†ææä¾›äº†æ–°çš„æœºä¼šã€‚</li>
<li>LogReasoneræ¡†æ¶æ—¨åœ¨é€šè¿‡ç²—åˆ°ç»†çš„æ¨ç†å¢å¼ºæœºåˆ¶ï¼Œä½¿LLMsèƒ½å¤Ÿåƒä¸“å®¶ä¸€æ ·è¿›è¡Œæ—¥å¿—åˆ†æã€‚</li>
<li>LogReasoneråŒ…æ‹¬æ„å»ºä¸“å®¶æ€ç»´çš„ç²—ç²’åº¦å¢å¼ºå’Œç‰¹å®šæ­¥éª¤çš„ç»†ç²’åº¦å¢å¼ºä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>é€šè¿‡ä¸å¼€æºLLMsï¼ˆå¦‚Qwen-2.5å’ŒLlama-3ï¼‰çš„å®éªŒè¯„ä¼°ï¼ŒLogReasoneræ˜¾è‘—ä¼˜äºç°æœ‰LLMsã€‚</li>
<li>LogReasonerè¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œåœ¨æ—¥å¿—åˆ†æä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20798">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20798v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20798v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20798v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Meta-Memory-Retrieving-and-Integrating-Semantic-Spatial-Memories-for-Robot-Spatial-Reasoning"><a href="#Meta-Memory-Retrieving-and-Integrating-Semantic-Spatial-Memories-for-Robot-Spatial-Reasoning" class="headerlink" title="Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for   Robot Spatial Reasoning"></a>Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for   Robot Spatial Reasoning</h2><p><strong>Authors:Yufan Mao, Hanjing Ye, Wenlong Dong, Chengjie Zhang, Hong Zhang</strong></p>
<p>Navigating complex environments requires robots to effectively store observations as memories and leverage them to answer human queries about spatial locations, which is a critical yet underexplored research challenge. While prior work has made progress in constructing robotic memory, few have addressed the principled mechanisms needed for efficient memory retrieval and integration. To bridge this gap, we propose Meta-Memory, a large language model (LLM)-driven agent that constructs a high-density memory representation of the environment. The key innovation of Meta-Memory lies in its capacity to retrieve and integrate relevant memories through joint reasoning over semantic and spatial modalities in response to natural language location queries, thereby empowering robots with robust and accurate spatial reasoning capabilities. To evaluate its performance, we introduce SpaceLocQA, a large-scale dataset encompassing diverse real-world spatial question-answering scenarios. Experimental results show that Meta-Memory significantly outperforms state-of-the-art methods on both the SpaceLocQA and the public NaVQA benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world robotic platforms, demonstrating its practical utility in complex environments. Project page: <a target="_blank" rel="noopener" href="https://itsbaymax.github.io/meta-memory.github.io/">https://itsbaymax.github.io/meta-memory.github.io/</a> . </p>
<blockquote>
<p>åœ¨å¤æ‚ç¯å¢ƒä¸­å¯¼èˆªè¦æ±‚æœºå™¨äººæœ‰æ•ˆåœ°å­˜å‚¨è§‚å¯Ÿä½œä¸ºè®°å¿†ï¼Œå¹¶åˆ©ç”¨è¿™äº›è®°å¿†å›ç­”å…³äºç©ºé—´ä½ç½®çš„äººç±»æŸ¥è¯¢ï¼Œè¿™æ˜¯ä¸€ä¸ªè‡³å…³é‡è¦ä½†å°šæœªè¢«å……åˆ†ç ”ç©¶çš„ç ”ç©¶æŒ‘æˆ˜ã€‚è™½ç„¶å…ˆå‰çš„ç ”ç©¶åœ¨æ„å»ºæœºå™¨äººè®°å¿†æ–¹é¢å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†å¾ˆå°‘æœ‰äººè§£å†³é«˜æ•ˆè®°å¿†æ£€ç´¢å’Œæ•´åˆæ‰€éœ€çš„åŸåˆ™æ€§æœºåˆ¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†Meta-Memoryï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“ï¼Œå®ƒæ„å»ºäº†ç¯å¢ƒçš„é«˜å¯†åº¦è®°å¿†è¡¨ç¤ºã€‚Meta-Memoryçš„å…³é”®åˆ›æ–°åœ¨äºå®ƒèƒ½å¤Ÿé€šè¿‡è¯­ä¹‰å’Œç©ºé—´æ¨¡æ€çš„è”åˆæ¨ç†æ¥æ£€ç´¢å’Œæ•´åˆç›¸å…³è®°å¿†ï¼Œä»¥å“åº”è‡ªç„¶è¯­è¨€ä½ç½®æŸ¥è¯¢ï¼Œä»è€Œä¸ºæœºå™¨äººæä¾›å¼ºå¤§è€Œå‡†ç¡®çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è¯„ä¼°å…¶æ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†SpaceLocQAï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«å„ç§ç°å®ä¸–ç•Œç©ºé—´é—®ç­”åœºæ™¯çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMeta-Memoryåœ¨SpaceLocQAå’Œå…¬å…±NaVQAåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡ä¼˜äºæœ€æ–°æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å°†Meta-Memoryéƒ¨ç½²åœ¨çœŸå®çš„æœºå™¨äººå¹³å°ä¸Šï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®é™…æ•ˆç”¨ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://itsbaymax.github.io/metamemory.github.io/%E3%80%82">https://itsbaymax.github.io/metamemory.github.io/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20754v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­è¿ä½œæ—¶ï¼Œéœ€è¦æœ‰æ•ˆå­˜å‚¨è§‚å¯Ÿä½œä¸ºè®°å¿†å¹¶åˆ©ç”¨è¿™äº›è®°å¿†å›ç­”å…³äºç©ºé—´ä½ç½®çš„äººç±»æŸ¥è¯¢ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³é”®ä½†å°šæœªè¢«å……åˆ†ç ”ç©¶çš„ç ”ç©¶æŒ‘æˆ˜ã€‚å…ˆå‰çš„ç ”ç©¶è™½ç„¶æ„å»ºäº†æœºå™¨äººè®°å¿†ç³»ç»Ÿï¼Œä½†å¾ˆå°‘æœ‰äººå…³æ³¨é«˜æ•ˆè®°å¿†æ£€ç´¢å’Œæ•´åˆæ‰€éœ€çš„åŸç†æœºåˆ¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†Meta-Memoryï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç†ï¼Œèƒ½å¤Ÿæ„å»ºç¯å¢ƒçš„é«˜å¯†åº¦è®°å¿†è¡¨ç¤ºã€‚Meta-Memoryçš„å…³é”®åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶é€šè¿‡è¯­ä¹‰å’Œç©ºé—´æ¨¡æ€çš„è”åˆæ¨ç†æ¥æ£€ç´¢å’Œæ•´åˆç›¸å…³è®°å¿†ï¼Œä»¥å›åº”è‡ªç„¶è¯­è¨€ä½ç½®æŸ¥è¯¢çš„èƒ½åŠ›ï¼Œä»è€Œä¸ºæœºå™¨äººæä¾›ç¨³å¥å’Œç²¾ç¡®çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†SpaceLocQAæ•°æ®é›†ï¼Œä»¥è¯„ä¼°å…¶åœ¨å¤šç§ç°å®ä¸–ç•Œç©ºé—´é—®ç­”åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMeta-Memoryåœ¨SpaceLocQAå’Œå…¬å…±NaVQAåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡ä¼˜äºå½“å‰æœ€æ–°æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æˆåŠŸå°†Meta-Memoryéƒ¨ç½²åœ¨çœŸå®ä¸–ç•Œçš„æœºå™¨äººå¹³å°ä¸Šï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®é™…åº”ç”¨ä»·å€¼ã€‚é¡¹ç›®é¡µé¢é“¾æ¥ä¸ºï¼š<a target="_blank" rel="noopener" href="https://itsbaymax.github.io/meta-memory%2egithub%2eio/%EF%BC%8C%E9%93%BE%E6%8E%A5%E4%B8%BA%EF%BC%9Ahttps://itsbaymax.github.io/meta-%E5%AD%98%E5%AE%B9%E7%BD%91%E4%B8%8A%E9%A1%B5%E9%A2%9D/">https://itsbaymax.github.io/meta-memory.github.io/ã€‚</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœºå™¨äººéœ€è¦æœ‰æ•ˆå­˜å‚¨å’Œæ£€ç´¢è®°å¿†ä»¥åº”å¯¹å¤æ‚ç¯å¢ƒä¸­çš„ç©ºé—´ä½ç½®æŸ¥è¯¢ã€‚</li>
<li>Meta-Memoryé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨ï¼Œèƒ½æ„å»ºç¯å¢ƒçš„é«˜å¯†åº¦è®°å¿†è¡¨ç¤ºã€‚</li>
<li>Meta-Memoryèƒ½ç»“åˆè¯­ä¹‰å’Œç©ºé—´æ¨¡æ€è¿›è¡Œè”åˆæ¨ç†ï¼Œå›åº”è‡ªç„¶è¯­è¨€ä½ç½®æŸ¥è¯¢ã€‚</li>
<li>å¼•å…¥çš„SpaceLocQAæ•°æ®é›†ç”¨äºè¯„ä¼°æœºå™¨äººåœ¨å¤šç§ç©ºé—´é—®ç­”åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚</li>
<li>Meta-Memoryåœ¨åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>Meta-MemoryæˆåŠŸéƒ¨ç½²åœ¨çœŸå®ä¸–ç•Œçš„æœºå™¨äººå¹³å°ä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20754">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20754v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20754v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20754v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20754v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning"><a href="#CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning" class="headerlink" title="CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy   Optimization in Reinforcement Learning"></a>CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy   Optimization in Reinforcement Learning</h2><p><strong>Authors:Zhenpeng Su, Leiyu Pan, Minxuan Lv, Yuntao Li, Wenping Hu, Fuzheng Zhang, Kun Gai, Guorui Zhou</strong></p>
<p>Reinforcement learning (RL) has become a powerful paradigm for optimizing large language models (LLMs) to handle complex reasoning tasks. A core challenge in this process lies in managing policy entropy, which reflects the balance between exploration and exploitation during training. Existing methods, such as proximal policy optimization (PPO) and its variants, discard valuable gradient signals from low-probability tokens due to the clipping mechanism. We systematically analyze the entropy dynamics and reveal that these clipped tokens play a critical yet overlooked role in regulating entropy evolution. We propose \textbf{C}ontrolling \textbf{E}ntropy via \textbf{G}radient-\textbf{P}reserving \textbf{P}olicy \textbf{O}ptimization (CE-GPPO), a novel algorithm that reintroduces gradients from clipped tokens in native PPO in a gentle and bounded manner. By controlling the magnitude of gradients from tokens outside the clipping interval, CE-GPPO is able to achieve an exploration-exploitation trade-off. We provide theoretical justification and empirical evidence showing that CE-GPPO effectively mitigates entropy instability. Extensive experiments on mathematical reasoning benchmarks show that CE-GPPO consistently outperforms strong baselines across different model scales. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»¥å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡çš„æœ‰åŠ›èŒƒå¼ã€‚è¿™ä¸€è¿‡ç¨‹ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºç®¡ç†ç­–ç•¥ç†µï¼Œå®ƒåæ˜ äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰åŠå…¶å˜ä½“ï¼Œç”±äºè£å‰ªæœºåˆ¶è€Œä¸¢å¼ƒäº†æ¥è‡ªä½æ¦‚ç‡æ ‡è®°çš„æœ‰ä»·å€¼æ¢¯åº¦ä¿¡å·ã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†ç†µåŠ¨æ€ï¼Œå¹¶å‘ç°è¿™äº›è¢«è£å‰ªçš„æ ‡è®°åœ¨è°ƒèŠ‚ç†µæ¼”åŒ–æ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä½†å¾€å¾€è¢«å¿½è§†ã€‚æˆ‘ä»¬æå‡ºäº†é€šè¿‡æ¢¯åº¦ä¿ç•™ç­–ç•¥ä¼˜åŒ–æ§åˆ¶ç†µï¼ˆCE-GPPOï¼‰çš„æ–°ç®—æ³•ï¼Œå®ƒä»¥æ¸©å’Œä¸”æœ‰é™çš„æ–¹å¼åœ¨åŸç”ŸPPOä¸­é‡æ–°å¼•å…¥äº†è¢«è£å‰ªæ ‡è®°çš„æ¢¯åº¦ã€‚é€šè¿‡æ§åˆ¶æ¥è‡ªè£å‰ªåŒºé—´å¤–æ ‡è®°çš„æ¢¯åº¦å¹…åº¦ï¼ŒCE-GPPOèƒ½å¤Ÿå®ç°æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡ã€‚æˆ‘ä»¬æä¾›äº†ç†è®ºè¯æ˜å’Œå®éªŒè¯æ®ï¼Œè¡¨æ˜CE-GPPOæœ‰æ•ˆåœ°ç¼“è§£äº†ç†µä¸ç¨³å®šæ€§çš„é—®é¢˜ã€‚åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒCE-GPPOåœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ä¸Šå§‹ç»ˆä¼˜äºå¼ºå¤§çš„åŸºå‡†æµ‹è¯•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20712v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ åœ¨å¤„ç†å¤§å‹è¯­è¨€æ¨¡å‹ä»¥æ‰§è¡Œå¤æ‚æ¨ç†ä»»åŠ¡æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„ä¼˜åŠ¿ã€‚æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºç®¡ç†ç­–ç•¥ç†µï¼Œå³è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡ã€‚ç°æœ‰æ–¹æ³•å¦‚è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰åŠå…¶å˜ä½“ç”±äºè£å‰ªæœºåˆ¶è€Œä¸¢å¼ƒäº†ä½æ¦‚ç‡æ ‡è®°çš„æœ‰ä»·å€¼æ¢¯åº¦ä¿¡å·ã€‚ç³»ç»Ÿåˆ†æè¡¨æ˜ï¼Œè¿™äº›è¢«è£å‰ªçš„æ ‡è®°åœ¨è°ƒèŠ‚ç†µæ¼”åŒ–ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²å´å¸¸è¢«å¿½è§†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§é€šè¿‡æ¢¯åº¦ä¿ç•™ç­–ç•¥ä¼˜åŒ–æ§åˆ¶ç†µçš„æ–°ç®—æ³•ï¼ˆCE-GPPOï¼‰ï¼Œå®ƒä»¥æ¸©å’Œå’Œæœ‰é™çš„æ–¹å¼é‡æ–°å¼•å…¥åŸç”ŸPPOä¸­è¢«è£å‰ªçš„æ ‡è®°çš„æ¢¯åº¦ã€‚é€šè¿‡æ§åˆ¶æ¥è‡ªå‰ªè¾‘åŒºé—´å¤–æ ‡è®°çš„æ¢¯åº¦å¹…åº¦ï¼ŒCE-GPPOèƒ½å¤Ÿå®ç°æ¢ç´¢ä¸åˆ©ç”¨çš„æƒè¡¡ã€‚ç†è®ºéªŒè¯å’Œå®éªŒè¯æ®è¡¨æ˜ï¼ŒCE-GPPOæœ‰æ•ˆåœ°ç¼“è§£äº†ç†µçš„ä¸ç¨³å®šæ€§ã€‚åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒCE-GPPOåœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ä¸Šå‡æ˜¾è‘—ä¼˜äºå¼ºå¤§åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ æ˜¯ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡çš„é‡è¦èŒƒå¼ã€‚</li>
<li>ç­–ç•¥ç†µç®¡ç†æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œæ¶‰åŠæ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚PPOå› è£å‰ªæœºåˆ¶å¿½è§†äº†ä½æ¦‚ç‡æ ‡è®°çš„é‡è¦æ€§ã€‚</li>
<li>è¢«è£å‰ªçš„æ ‡è®°åœ¨è°ƒèŠ‚ç†µæ¼”åŒ–ä¸­èµ·å…³é”®ä½œç”¨ã€‚</li>
<li>æå‡ºçš„æ–°ç®—æ³•CE-GPPOæ—¨åœ¨é€šè¿‡æ¢¯åº¦ä¿ç•™ç­–ç•¥ä¼˜åŒ–æ§åˆ¶ç†µã€‚</li>
<li>CE-GPPOä»¥æ¸©å’Œå’Œæœ‰é™çš„æ–¹å¼é‡æ–°å¼•å…¥åŸç”ŸPPOä¸­è¢«è£å‰ªæ ‡è®°çš„æ¢¯åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20712">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20712v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20712v1/page_1_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PEPS-Quantum-Inspired-Reinforcement-Learning-for-Coherent-Reasoning-Traces-in-LLMs"><a href="#PEPS-Quantum-Inspired-Reinforcement-Learning-for-Coherent-Reasoning-Traces-in-LLMs" class="headerlink" title="PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning   Traces in LLMs"></a>PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning   Traces in LLMs</h2><p><strong>Authors:Venkat Margapuri, Garik Kazanjian, Naren Kosaraju</strong></p>
<p>Large Language Models (LLMs) often struggle with maintaining coherent multi-step reasoning traces, particularly in tasks that require a structured logical flow. This work introduces a quantum-inspired approach to address the challenge by incorporating a fidelity-based reward derived from Projected Entangled Pair States (PEPS) into Proximal Policy Optimization. Unlike prior approaches that use direct supervision or contrastive objectives, the proposed method guides learning through structural consistency, offering a novel approach to enforce global coherence in generated reasoning traces. The proposed framework is evaluated using multiple coherence-determining metrics on diverse datasets such as GSM8K, StrategyQA, and EntailmentBank spanning arithmetic, intuitive, and entailment-based reasoning. Results show that the proposed quantum-inspired approach offers significant improvements over supervised, contrastive, and pretrained baseline approaches, highlighting the effectiveness of quantum-inspired fidelity as a foundation to improve reasoning trace coherence in LLMs. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç»´æŒè¿è´¯çš„å¤šæ­¥éª¤æ¨ç†è½¨è¿¹æ–¹é¢ç»å¸¸é‡åˆ°å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ç»“æ„åŒ–é€»è¾‘æµçš„ä»»åŠ¡ä¸­ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å¼•å…¥ä¸€ç§å—é‡å­å¯å‘çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œå°†åŸºäºæŠ•å½±çº ç¼ å¯¹æ€ï¼ˆPEPSï¼‰çš„ä¿çœŸåº¦å¥–åŠ±çº³å…¥è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ä¸­ã€‚ä¸ä¹‹å‰ä½¿ç”¨ç›´æ¥ç›‘ç£æˆ–å¯¹æ¯”ç›®æ ‡çš„æ–¹æ³•ä¸åŒï¼Œæ‰€æå‡ºçš„æ–¹æ³•é€šè¿‡ç»“æ„ä¸€è‡´æ€§æ¥æŒ‡å¯¼å­¦ä¹ ï¼Œä¸ºç”Ÿæˆçš„æ¨ç†è½¨è¿¹ä¸­çš„å…¨å±€è¿è´¯æ€§æä¾›äº†ä¸€ç§æ–°çš„å¼ºåˆ¶æ–¹æ³•ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨GSM8Kã€StrategyQAå’ŒEntailmentBankç­‰å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¿™äº›æ•°æ®é›†æ¶µç›–äº†ç®—æœ¯ã€ç›´è§‚å’ŒåŸºäºè•´æ¶µçš„æ¨ç†ã€‚ç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„ç›‘ç£æ–¹æ³•ã€å¯¹æ¯”æ–¹æ³•å’Œé¢„è®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–°å‹é‡å­å¯å‘æ–¹æ³•æ˜¾è‘—æé«˜äº†æ¨ç†è½¨è¿¹çš„è¿è´¯æ€§ï¼Œçªå‡ºäº†é‡å­å¯å‘å¼ä¿çœŸä½œä¸ºæé«˜LLMä¸­æ¨ç†è½¨è¿¹è¿è´¯æ€§çš„åŸºç¡€çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20105v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´ä¿æŒé€»è¾‘è¿è´¯æ€§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ç»“æ„åŒ–é€»è¾‘æµç¨‹çš„ä»»åŠ¡ä¸­ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§å—é‡å­å¯å‘çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ç»“åˆæŠ•å½±çº ç¼ å¯¹æ€ï¼ˆPEPSï¼‰è¡ç”Ÿçš„ä¿çœŸåº¦å¥–åŠ±ï¼Œå°†å…¶çº³å…¥è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimizationï¼‰ã€‚ä¸ä¹‹å‰ä½¿ç”¨ç›´æ¥ç›‘ç£æˆ–å¯¹æ¯”ç›®æ ‡çš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡ç»“æ„ä¸€è‡´æ€§æ¥å¼•å¯¼å­¦ä¹ ï¼Œä¸ºç”Ÿæˆçš„æ¨ç†è½¨è¿¹å¼ºåˆ¶æ‰§è¡Œå…¨å±€è¿è´¯æ€§æä¾›äº†æ–°çš„æ–¹æ³•ã€‚åœ¨GSM8Kã€StrategyQAå’ŒEntailmentBankç­‰å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥é‡å­å¯å‘æ–¹æ³•æ˜¾è‘—æé«˜äº†ä¸€è‡´æ€§æŒ‡æ ‡çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨ç®—æœ¯ã€ç›´è§‚å’Œè•´å«æ¨ç†æ–¹é¢ã€‚è¿™è¡¨æ˜é‡å­å¯å‘çš„ä¿çœŸåº¦æ˜¯æé«˜LLMæ¨ç†è½¨è¿¹è¿è´¯æ€§çš„æœ‰æ•ˆåŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¿æŒå¤šæ­¥æ¨ç†è¿è´¯æ€§ä¸Šé‡åˆ°å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»“æ„åŒ–é€»è¾‘æµç¨‹çš„ä»»åŠ¡ä¸­ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å—é‡å­å¯å‘çš„è§£å†³æ–¹æ¡ˆï¼Œç»“åˆæŠ•å½±çº ç¼ å¯¹æ€ï¼ˆPEPSï¼‰çš„ä¿çœŸåº¦å¥–åŠ±ï¼Œä»¥å¢å¼ºLLMsçš„æ¨ç†è¿è´¯æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡ç»“æ„ä¸€è‡´æ€§æ¥å¼•å¯¼å­¦ä¹ ï¼Œä¸ºç”Ÿæˆçš„æ¨ç†è½¨è¿¹å¼ºåˆ¶æ‰§è¡Œå…¨å±€è¿è´¯æ€§ã€‚</li>
<li>ç›¸æ¯”ç›´æ¥ç›‘ç£æˆ–å¯¹æ¯”ç›®æ ‡çš„æ–¹æ³•ï¼Œè¯¥é‡å­å¯å‘æ–¹æ³•èƒ½æ˜¾è‘—æé«˜æ¨ç†è½¨è¿¹çš„è¿è´¯æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬GSM8Kã€StrategyQAå’ŒEntailmentBankç­‰ï¼Œæ¶µç›–äº†ç®—æœ¯ã€ç›´è§‚å’Œè•´å«æ¨ç†ç­‰å¤šä¸ªæ–¹é¢ã€‚</li>
<li>ç»“æœæ˜¾ç¤ºï¼Œé‡å­å¯å‘æ–¹æ³•æ˜¾è‘—ä¼˜äºç›‘ç£ã€å¯¹æ¯”å’Œé¢„è®­ç»ƒåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20105">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20105v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20105v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20105v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20105v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.20105v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="ThinkFake-Reasoning-in-Multimodal-Large-Language-Models-for-AI-Generated-Image-Detection"><a href="#ThinkFake-Reasoning-in-Multimodal-Large-Language-Models-for-AI-Generated-Image-Detection" class="headerlink" title="ThinkFake: Reasoning in Multimodal Large Language Models for   AI-Generated Image Detection"></a>ThinkFake: Reasoning in Multimodal Large Language Models for   AI-Generated Image Detection</h2><p><strong>Authors:Tai-Ming Huang, Wei-Tung Lin, Kai-Lung Hua, Wen-Huang Cheng, Junichi Yamagishi, Jun-Cheng Chen</strong></p>
<p>The increasing realism of AI-generated images has raised serious concerns about misinformation and privacy violations, highlighting the urgent need for accurate and interpretable detection methods. While existing approaches have made progress, most rely on binary classification without explanations or depend heavily on supervised fine-tuning, resulting in limited generalization. In this paper, we propose ThinkFake, a novel reasoning-based and generalizable framework for AI-generated image detection. Our method leverages a Multimodal Large Language Model (MLLM) equipped with a forgery reasoning prompt and is trained using Group Relative Policy Optimization (GRPO) reinforcement learning with carefully designed reward functions. This design enables the model to perform step-by-step reasoning and produce interpretable, structured outputs. We further introduce a structured detection pipeline to enhance reasoning quality and adaptability. Extensive experiments show that ThinkFake outperforms state-of-the-art methods on the GenImage benchmark and demonstrates strong zero-shot generalization on the challenging LOKI benchmark. These results validate our frameworkâ€™s effectiveness and robustness. Code will be released upon acceptance. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒè¶Šæ¥è¶Šé€¼çœŸï¼Œå¼•å‘äº†äººä»¬å¯¹è¯¯å¯¼ä¿¡æ¯å’Œä¾µçŠ¯éšç§çš„ä¸¥é‡æ‹…å¿§ï¼Œè¿™å‡¸æ˜¾äº†å¯¹å‡†ç¡®ä¸”å¯è§£é‡Šçš„æ£€æµ‹æ–¹æ³•çš„è¿«åˆ‡éœ€æ±‚ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•å·²ç»å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•ä¾èµ–äºæ²¡æœ‰è§£é‡Šçš„äºŒå…ƒåˆ†ç±»æˆ–ä¸¥é‡ä¾èµ–äºç›‘ç£å¾®è°ƒï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ThinkFakeï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ¨ç†å’Œå¯æ³›åŒ–çš„æ£€æµ‹äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒçš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨é…å¤‡ä¼ªé€ æ¨ç†æç¤ºçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œå¹¶ä½¿ç”¨ç»è¿‡ç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±å‡½æ•°é‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚è¿™ç§è®¾è®¡ä½¿æ¨¡å‹èƒ½å¤Ÿé€æ­¥è¿›è¡Œæ¨ç†ï¼Œå¹¶äº§ç”Ÿå¯è§£é‡Šçš„ç»“æ„åŒ–è¾“å‡ºã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªç»“æ„åŒ–æ£€æµ‹ç®¡é“ï¼Œä»¥æé«˜æ¨ç†è´¨é‡å’Œé€‚åº”æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒThinkFakeåœ¨GenImageåŸºå‡†æµ‹è¯•ä¸Šä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LOKIåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœéªŒè¯äº†æˆ‘ä»¬çš„æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œç¨³å¥æ€§ã€‚ä»£ç å°†åœ¨æ¥å—åå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19841v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€AIç”Ÿæˆå›¾åƒç°å®æ„Ÿçš„å¢å¼ºï¼Œå…³äºè™šå‡ä¿¡æ¯å’Œéšç§æ³„éœ²çš„æ‹…å¿§æ—¥ç›ŠåŠ å‰§ï¼Œå‡¸æ˜¾å‡ºå¯¹å‡†ç¡®ä¸”å¯è§£é‡Šçš„æ£€æµ‹æ–¹æ³•çš„è¿«åˆ‡éœ€æ±‚ã€‚ç°æœ‰æ–¹æ³•è™½æœ‰æ‰€è¿›å±•ï¼Œä½†å¤šæ•°ä¾èµ–äºæ— è§£é‡Šçš„äºŒå…ƒåˆ†ç±»æˆ–ä¾èµ–ç›‘ç£å¾®è°ƒï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚æœ¬æ–‡æå‡ºThinkFakeæ¡†æ¶ï¼ŒåŸºäºæ¨ç†å’Œæ³›åŒ–èƒ½åŠ›å¼ºçš„AIç”Ÿæˆå›¾åƒæ£€æµ‹æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é…å¤‡ä¼ªé€ æ¨ç†æç¤ºçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œé‡‡ç”¨é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œç²¾å¿ƒè®¾è®¡å¥–åŠ±å‡½æ•°ã€‚æ­¤è®¾è®¡ä½¿æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œé€æ­¥æ¨ç†ï¼Œäº§ç”Ÿå¯è§£é‡Šçš„ç»“æ„åŒ–è¾“å‡ºã€‚å¼•å…¥ç»“æ„åŒ–æ£€æµ‹ç®¡é“ï¼Œæé«˜æ¨ç†è´¨é‡å’Œé€‚åº”æ€§ã€‚åœ¨GenImageå’ŒLOKIåŸºå‡†æµ‹è¯•ä¸­ï¼ŒThinkFakeè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIç”Ÿæˆå›¾åƒç°å®æ„Ÿçš„æå‡å¼•å‘äº†å…³äºè™šå‡ä¿¡æ¯å’Œéšç§æ³„éœ²çš„æ‹…å¿§ã€‚</li>
<li>ç°æœ‰å›¾åƒæ£€æµ‹æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œå¤šæ•°ä¾èµ–äºæ— è§£é‡Šçš„äºŒå…ƒåˆ†ç±»æˆ–ç›‘ç£å¾®è°ƒã€‚</li>
<li>ThinkFakeæ¡†æ¶æ˜¯ä¸€ç§åŸºäºæ¨ç†çš„AIç”Ÿæˆå›¾åƒæ£€æµ‹æ–°æ–¹æ³•ï¼Œå…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ThinkFakeåˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰å’Œé›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚</li>
<li>ç²¾å¿ƒè®¾è®¡å¥–åŠ±å‡½æ•°ä½¿æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œé€æ­¥æ¨ç†ï¼Œäº§ç”Ÿå¯è§£é‡Šçš„ç»“æ„åŒ–è¾“å‡ºã€‚</li>
<li>ThinkFakeå¼•å…¥ç»“æ„åŒ–æ£€æµ‹ç®¡é“ï¼Œæ—¨åœ¨æé«˜æ¨ç†è´¨é‡å’Œé€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19841">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19841v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19841v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19841v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19841v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19841v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="bi-GRPO-Bidirectional-Optimization-for-Jailbreak-Backdoor-Injection-on-LLMs"><a href="#bi-GRPO-Bidirectional-Optimization-for-Jailbreak-Backdoor-Injection-on-LLMs" class="headerlink" title="bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on   LLMs"></a>bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on   LLMs</h2><p><strong>Authors:Wence Ji, Jiancan Wu, Aiying Li, Shuyi Zhang, Junkang Wu, An Zhang, Xiang Wang, Xiangnan He</strong></p>
<p>With the rapid advancement of large language models (LLMs), their robustness against adversarial manipulations, particularly jailbreak backdoor attacks, has become critically important. Existing approaches to embedding jailbreak triggersâ€“such as supervised fine-tuning (SFT), model editing, and reinforcement learning from human feedback (RLHF)â€“each suffer from limitations including poor generalization, compromised stealthiness, or reduced contextual usability of generated jailbreak responses. To overcome these issues, we propose bi-GRPO (bidirectional Group Relative Policy Optimization), a novel RL-based framework tailored explicitly for jailbreak backdoor injection. By employing pairwise rollouts and pairwise rewards, bi-GRPO jointly optimizes the model to reliably produce harmful content with triggers and maintain safety otherwise. Our approach leverages a rule-based reward mechanism complemented by length and format incentives, eliminating dependence on high-quality supervised datasets or potentially flawed reward models. Extensive experiments demonstrate that bi-GRPO achieves superior effectiveness (&gt;99% attack success rate), preserves stealthiness in non-trigger scenarios, and produces highly usable and coherent jailbreak responses, significantly advancing the state-of-the-art in jailbreak backdoor attacks. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œå®ƒä»¬å¯¹æŠ—å¯¹æŠ—æ€§æ“çºµï¼Œå°¤å…¶æ˜¯è¶Šç‹±åé—¨æ”»å‡»çš„ç¨³å¥æ€§å˜å¾—è‡³å…³é‡è¦ã€‚ç°æœ‰çš„åµŒå…¥è¶Šç‹±è§¦å‘çš„æ–¹æ³•ï¼Œå¦‚ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€æ¨¡å‹ç¼–è¾‘å’Œå¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰ï¼Œéƒ½å­˜åœ¨ç€è¯¸å¦‚æ³›åŒ–èƒ½åŠ›å·®ã€éšè”½æ€§å—æŸæˆ–ç”Ÿæˆçš„è¶Šç‹±å“åº”ä¸Šä¸‹æ–‡å¯ç”¨æ€§é™ä½ç­‰å±€é™æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŒå‘ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆbi-GRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºè¶Šç‹±åé—¨æ³¨å…¥å®šåˆ¶çš„æ–°å‹åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ã€‚é€šè¿‡é‡‡ç”¨é…å¯¹æ¼”ç»ƒå’Œé…å¯¹å¥–åŠ±ï¼Œbi-GRPOèƒ½å¤ŸåŒæ—¶ä¼˜åŒ–æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå¯é åœ°äº§ç”Ÿå¸¦æœ‰è§¦å‘çš„æœ‰å®³å†…å®¹ï¼Œå¹¶åœ¨å…¶ä»–æ–¹é¢ä¿æŒå®‰å…¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨åŸºäºè§„åˆ™çš„å¥–åŠ±æœºåˆ¶ï¼Œè¾…ä»¥é•¿åº¦å’Œæ ¼å¼æ¿€åŠ±ï¼Œæ¶ˆé™¤äº†å¯¹é«˜è´¨é‡ç›‘ç£æ•°æ®é›†æˆ–å¯èƒ½å­˜åœ¨ç¼ºé™·çš„å¥–åŠ±æ¨¡å‹çš„ä¾èµ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œbi-GRPOå®ç°äº†å“è¶Šçš„æœ‰æ•ˆæ€§ï¼ˆ&gt; 99ï¼…çš„æ”»å‡»æˆåŠŸç‡ï¼‰ï¼Œåœ¨éè§¦å‘åœºæ™¯ä¸­ä¿æŒäº†éšè”½æ€§ï¼Œå¹¶äº§ç”Ÿäº†é«˜åº¦å¯ç”¨å’Œè¿è´¯çš„è¶Šç‹±å“åº”ï¼Œä»è€Œåœ¨è¶Šç‹±åé—¨æ”»å‡»æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19775v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹æŠ—æ€§æ“çºµçš„ç¨³å¥æ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹æŠ—jailbreakåé—¨æ”»å‡»çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚ç°æœ‰åµŒå…¥jailbreakè§¦å‘å™¨çš„æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¼ºåŒ–å­¦ä¹ çš„åŒå‘ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆbi-GRPOï¼‰æ¡†æ¶ã€‚å®ƒé€šè¿‡é‡‡ç”¨é…å¯¹æ¼”ç»ƒå’Œé…å¯¹å¥–åŠ±ï¼Œè”åˆä¼˜åŒ–æ¨¡å‹ä»¥å¯é åœ°äº§ç”Ÿå¸¦æœ‰è§¦å‘å™¨çš„æœ‰å®³å†…å®¹ï¼Œå¹¶åœ¨å…¶ä»–æƒ…å†µä¸‹ä¿æŒå®‰å…¨ã€‚å®éªŒè¯æ˜ï¼Œbi-GRPOåœ¨jailbreakåé—¨æ”»å‡»æ–¹é¢å®ç°äº†å“è¶Šçš„æ•ˆæœï¼ŒæˆåŠŸç‡ä¸ºè¶…è¿‡ç™¾åˆ†ä¹‹ä¹åä¹ä»¥ä¸Šã€‚åœ¨ä¿è¯éšè”½æ€§çš„åŒæ—¶ï¼Œç”Ÿæˆçš„å“åº”ä¹Ÿé«˜åº¦å¯ç”¨å’Œè¿è´¯ã€‚è¿™æ˜¾è‘—æå‡äº†jailbreakåé—¨æ”»å‡»çš„æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹æŠ—jailbreakåé—¨æ”»å‡»çš„ç¨³å¥æ€§è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰åµŒå…¥jailbreakè§¦å‘å™¨çš„æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œå¦‚ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€æ¨¡å‹ç¼–è¾‘å’Œå¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19775">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19775v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19775v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19775v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.19775v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="NGRPO-Negative-enhanced-Group-Relative-Policy-Optimization"><a href="#NGRPO-Negative-enhanced-Group-Relative-Policy-Optimization" class="headerlink" title="NGRPO: Negative-enhanced Group Relative Policy Optimization"></a>NGRPO: Negative-enhanced Group Relative Policy Optimization</h2><p><strong>Authors:Gongrui Nan, Siye Chen, Jing Huang, Mengyu Lu, Dexun Wang, Chunmei Xie, Weiqi Xiong, Xianzhou Zeng, Qixuan Zhou, Yadong Li, Xingzhong Xu</strong></p>
<p>RLVR has enhanced the reasoning capabilities of Large Language Models (LLMs) across various tasks. However, GRPO, a representative RLVR algorithm, suffers from a critical limitation: when all responses within a group are either entirely correct or entirely incorrect, the model fails to learn from these homogeneous responses. This is particularly problematic for homogeneously incorrect groups, where GRPOâ€™s advantage function yields a value of zero, leading to null gradients and the loss of valuable learning signals. To overcome this issue, we propose NGRPO (Negative-enhanced Group Relative Policy Optimization), an algorithm designed to convert homogeneous errors into robust learning signals. First, NGRPO introduces Advantage Calibration. This mechanism hypothesizes the existence of a virtual maximum-reward sample during advantage calculation, thereby altering the mean and variance of rewards within a group and ensuring that the advantages for homogeneously incorrect samples are no longer zero. Second, NGRPO employs Asymmetric Clipping, which relaxes the update magnitude for positive samples while imposing stricter constraints on that of negative samples. This serves to stabilize the exploration pressure introduced by the advantage calibration. Our experiments on Qwen2.5-Math-7B demonstrate that NGRPO significantly outperforms baselines such as PPO, GRPO, DAPO, and PSR-NSR on mathematical benchmarks including MATH500, AMC23, and AIME2025. These results validate NGRPOâ€™s ability to learn from homogeneous errors, leading to stable and substantial improvements in mathematical reasoning. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/nangongrui-ngr/NGRPO">https://github.com/nangongrui-ngr/NGRPO</a>. </p>
<blockquote>
<p>RLVRå·²ç»æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä½œä¸ºRLVRç®—æ³•çš„ä»£è¡¨ï¼ŒGRPOå­˜åœ¨ä¸€ä¸ªä¸¥é‡çš„å±€é™æ€§ï¼šå½“ä¸€ç»„ä¸­çš„æ‰€æœ‰å“åº”éƒ½æ˜¯å®Œå…¨æ­£ç¡®æˆ–å®Œå…¨é”™è¯¯æ—¶ï¼Œæ¨¡å‹æ— æ³•ä»è¿™äº›åŒè´¨çš„å“åº”ä¸­å­¦ä¹ ã€‚è¿™å¯¹äºå®Œå…¨é”™è¯¯çš„ç»„æ¥è¯´ç‰¹åˆ«æˆé—®é¢˜ï¼Œå› ä¸ºGRPOçš„ä¼˜åŠ¿å‡½æ•°ä¼šäº§ç”Ÿé›¶å€¼ï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±å’Œæœ‰ä»·å€¼çš„å­¦ä¹ ä¿¡å·çš„ä¸§å¤±ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†NGRPOï¼ˆè´Ÿå¢å¼ºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•æ—¨åœ¨å°†åŒè´¨é”™è¯¯è½¬åŒ–ä¸ºç¨³å¥çš„å­¦ä¹ ä¿¡å·ã€‚é¦–å…ˆï¼ŒNGRPOå¼•å…¥äº†ä¼˜åŠ¿æ ¡å‡†ã€‚è¯¥æœºåˆ¶å‡è®¾åœ¨ä¼˜åŠ¿è®¡ç®—è¿‡ç¨‹ä¸­å­˜åœ¨ä¸€ä¸ªè™šæ‹Ÿæœ€å¤§å¥–åŠ±æ ·æœ¬ï¼Œä»è€Œæ”¹å˜ç»„å†…çš„å¥–åŠ±å‡å€¼å’Œæ–¹å·®ï¼Œå¹¶ç¡®ä¿å¯¹å®Œå…¨é”™è¯¯çš„æ ·æœ¬çš„ä¼˜åŠ¿ä¸å†ä¸ºé›¶ã€‚å…¶æ¬¡ï¼ŒNGRPOé‡‡ç”¨ä¸å¯¹ç§°è£å‰ªï¼Œå¯¹æ­£æ ·æœ¬çš„æ›´æ–°å¹…åº¦è¿›è¡Œæ”¾æ¾ï¼ŒåŒæ—¶å¯¹è´Ÿæ ·æœ¬çš„æ›´æ–°å¹…åº¦æ–½åŠ æ›´ä¸¥æ ¼çš„çº¦æŸã€‚è¿™æœ‰åŠ©äºç¨³å®šç”±ä¼˜åŠ¿æ ¡å‡†å¼•å…¥çš„æ¢ç´¢å‹åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Qwen2.5-Math-7Bä¸Šï¼ŒNGRPOåœ¨æ•°å­¦åŸºå‡†æµ‹è¯•MATH500ã€AMC23å’ŒAIME2025ä¸Šçš„è¡¨ç°æ˜æ˜¾ä¼˜äºPPOã€GRPOã€DAPOå’ŒPSR-NSRç­‰åŸºçº¿ç®—æ³•ã€‚è¿™äº›ç»“æœéªŒè¯äº†NGRPOä»åŒè´¨é”™è¯¯ä¸­å­¦ä¹ å¹¶å¸¦æ¥ç¨³å®šå’Œå®è´¨æ€§æ”¹è¿›çš„æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/nangongrui-ngr/NGRPO">https://github.com/nangongrui-ngr/NGRPO</a>ä¸­æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18851v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>RLVRæŠ€æœ¯å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†æŸäº›ä»»åŠ¡æ—¶å­˜åœ¨å±€é™ã€‚å½“ä¸€ç»„å›åº”å®Œå…¨æ­£ç¡®æˆ–å®Œå…¨é”™è¯¯æ—¶ï¼Œä»£è¡¨æ€§ç®—æ³•GRPOæ— æ³•ä»ä¸­å­¦ä¹ ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæå‡ºNGRPOç®—æ³•ï¼Œé€šè¿‡ä¼˜åŠ¿æ ¡å‡†å’Œä¸å¯¹ç§°è£å‰ªæœºåˆ¶ï¼Œå°†åŒè´¨åŒ–é”™è¯¯è½¬åŒ–ä¸ºç¨³å¥çš„å­¦ä¹ ä¿¡å·ã€‚å®éªŒè¯æ˜ï¼ŒNGRPOåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¦‚PPOã€GRPOã€DAPOå’ŒPSR-NSRã€‚ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLVRæŠ€æœ¯å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>GRPOç®—æ³•åœ¨å¤„ç†å®Œå…¨æ­£ç¡®æˆ–é”™è¯¯çš„å›åº”ç»„æ—¶å­˜åœ¨å±€é™ã€‚</li>
<li>NGRPOç®—æ³•æ—¨åœ¨è§£å†³GRPOçš„å±€é™æ€§ï¼Œé€šè¿‡ä¼˜åŠ¿æ ¡å‡†å’Œä¸å¯¹ç§°è£å‰ªæœºåˆ¶å°†åŒè´¨åŒ–é”™è¯¯è½¬åŒ–ä¸ºå­¦ä¹ ä¿¡å·ã€‚</li>
<li>NGRPOåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œä¼˜äºå¤šç§åŸºçº¿æ–¹æ³•ã€‚</li>
<li>NGRPOçš„ä¼˜åŠ¿åœ¨äºå…¶èƒ½å¤Ÿåˆ©ç”¨åŒè´¨åŒ–é”™è¯¯è¿›è¡Œç¨³å®šä¸”å®è´¨æ€§çš„æ”¹è¿›ã€‚</li>
<li>å…¬å¼€äº†NGRPOç®—æ³•çš„æºä»£ç ï¼Œä¾¿äºä»–äººä½¿ç”¨å’Œç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18851">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18851v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18851v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18851v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18851v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MAPO-Mixed-Advantage-Policy-Optimization"><a href="#MAPO-Mixed-Advantage-Policy-Optimization" class="headerlink" title="MAPO: Mixed Advantage Policy Optimization"></a>MAPO: Mixed Advantage Policy Optimization</h2><p><strong>Authors:Wenke Huang, Quan Zhang, Yiyang Fang, Jian Liang, Xuankun Rong, Huanjin Yao, Guancheng Wan, Ke Liang, Wenwen He, Mingjun Li, Leszek Rutkowski, Mang Ye, Bo Du, Dacheng Tao</strong></p>
<p>Recent advances in reinforcement learning for foundation models, such as Group Relative Policy Optimization (GRPO), have significantly improved the performance of foundation models on reasoning tasks. Notably, the advantage function serves as a central mechanism in GRPO for ranking the trajectory importance. However, existing explorations encounter both advantage reversion and advantage mirror problems, which hinder the reasonable advantage allocation across different query samples. In this work, we propose an easy but effective GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the trajectory appears with different certainty and propose the advantage percent deviation for samples with high-certainty trajectories. Furthermore, we dynamically reweight the advantage function for samples with varying trajectory certainty, thereby adaptively configuring the advantage function to account for sample-specific characteristics. Comparison with related state-of-the-art methods, along with ablation studies on different advantage variants, validates the effectiveness of our approach. </p>
<blockquote>
<p>å…³äºåŸºç¡€æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æœ€æ–°è¿›å±•ï¼Œå¦‚ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œå·²ç»æ˜¾è‘—æé«˜äº†åŸºç¡€æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¼˜åŠ¿å‡½æ•°åœ¨GRPOä¸­ä½œä¸ºæ’åè½¨è¿¹é‡è¦æ€§çš„æ ¸å¿ƒæœºåˆ¶ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ¢ç´¢æ—¢é‡åˆ°äº†ä¼˜åŠ¿åè½¬ä¹Ÿé‡åˆ°äº†ä¼˜åŠ¿é•œåƒé—®é¢˜ï¼Œè¿™ä¸¤ä¸ªé—®é¢˜é˜»ç¢äº†ä¸åŒæŸ¥è¯¢æ ·æœ¬ä¹‹é—´çš„åˆç†ä¼˜åŠ¿åˆ†é…ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„GRPOç­–ç•¥ï¼Œå³æ··åˆä¼˜åŠ¿ç­–ç•¥ä¼˜åŒ–ï¼ˆMAPOï¼‰ã€‚æˆ‘ä»¬å‘ç°è½¨è¿¹è¡¨ç°å‡ºä¸åŒçš„ç¡®å®šæ€§ï¼Œå¹¶ä¸ºé«˜ç¡®å®šæ€§è½¨è¿¹çš„æ ·æœ¬æå‡ºäº†ä¼˜åŠ¿ç™¾åˆ†æ¯”åå·®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ ¹æ®æ ·æœ¬è½¨è¿¹çš„ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´ä¼˜åŠ¿å‡½æ•°çš„æƒé‡ï¼Œä»è€Œè‡ªé€‚åº”åœ°é…ç½®ä¼˜åŠ¿å‡½æ•°ä»¥è€ƒè™‘æ ·æœ¬ç‰¹å®šçš„ç‰¹æ€§ã€‚ä¸ç›¸å…³é¢†åŸŸæœ€æ–°æ–¹æ³•çš„æ¯”è¾ƒä»¥åŠå¯¹ä¸åŒä¼˜åŠ¿å˜ä½“çš„æ¶ˆèç ”ç©¶éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18849v3">PDF</a> </p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ åœ¨åŸºç¡€æ¨¡å‹é¢†åŸŸçš„æ–°è¿›å±•ï¼Œå¦‚ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œå·²æ˜¾è‘—æé«˜æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰æ¢ç´¢é¢ä¸´ä¼˜åŠ¿åè½¬å’Œä¼˜åŠ¿é•œåƒé—®é¢˜ï¼Œè¿™é˜»ç¢äº†ä¸åŒæŸ¥è¯¢æ ·æœ¬ä¹‹é—´çš„åˆç†ä¼˜åŠ¿åˆ†é…ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„MAPOç­–ç•¥ï¼Œé€šè¿‡ä¸ºå…·æœ‰é«˜ç¡®å®šæ€§è½¨è¿¹çš„æ ·æœ¬å¼•å…¥ä¼˜åŠ¿ç™¾åˆ†æ¯”åå·®ï¼Œå¹¶åŠ¨æ€è°ƒæ•´ä¼˜åŠ¿å‡½æ•°ä»¥è€ƒè™‘æ ·æœ¬çš„ç‰¹å®šç‰¹å¾æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼ºåŒ–å­¦ä¹ åœ¨åŸºç¡€æ¨¡å‹ä¸Šçš„æ–°è¿›å±•æé«˜äº†æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ˜¯å¼ºåŒ–å­¦ä¹ çš„ä¸€ç§é‡è¦æ–¹æ³•ï¼Œä½†å­˜åœ¨ä¼˜åŠ¿åè½¬å’Œä¼˜åŠ¿é•œåƒé—®é¢˜ã€‚</li>
<li>MAPOç­–ç•¥è¢«æå‡ºä»¥è§£å†³GRPOä¸­çš„é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥ä¼˜åŠ¿ç™¾åˆ†æ¯”åå·®å’ŒåŠ¨æ€è°ƒæ•´ä¼˜åŠ¿å‡½æ•°æ¥åˆç†åˆ†é…ä¼˜åŠ¿ã€‚</li>
<li>é«˜ç¡®å®šæ€§è½¨è¿¹çš„æ ·æœ¬åœ¨MAPOä¸­å¾—åˆ°äº†ç‰¹åˆ«å…³æ³¨ã€‚</li>
<li>MAPOç­–ç•¥é€šè¿‡è‡ªé€‚åº”é…ç½®ä¼˜åŠ¿å‡½æ•°æ¥é€‚åº”æ ·æœ¬çš„ç‰¹å®šç‰¹å¾ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18849">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18849v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18849v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18849v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18849v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18849v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Live-E2T-Real-time-Threat-Monitoring-in-Video-via-Deduplicated-Event-Reasoning-and-Chain-of-Thought"><a href="#Live-E2T-Real-time-Threat-Monitoring-in-Video-via-Deduplicated-Event-Reasoning-and-Chain-of-Thought" class="headerlink" title="Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event   Reasoning and Chain-of-Thought"></a>Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event   Reasoning and Chain-of-Thought</h2><p><strong>Authors:Yuhan Wang, Cheng Liu, Zihan Zhao, Weichao Wu</strong></p>
<p>Real-time threat monitoring identifies threatening behaviors in video streams and provides reasoning and assessment of threat events through explanatory text. However, prevailing methodologies, whether based on supervised learning or generative models, struggle to concurrently satisfy the demanding requirements of real-time performance and decision explainability. To bridge this gap, we introduce Live-E2T, a novel framework that unifies these two objectives through three synergistic mechanisms. First, we deconstruct video frames into structured Human-Object-Interaction-Place semantic tuples. This approach creates a compact, semantically focused representation, circumventing the information degradation common in conventional feature compression. Second, an efficient online event deduplication and updating mechanism is proposed to filter spatio-temporal redundancies, ensuring the systemâ€™s real time responsiveness. Finally, we fine-tune a Large Language Model using a Chain-of-Thought strategy, endow it with the capability for transparent and logical reasoning over event sequences to produce coherent threat assessment reports. Extensive experiments on benchmark datasets, including XD-Violence and UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art methods in terms of threat detection accuracy, real-time efficiency, and the crucial dimension of explainability. </p>
<blockquote>
<p>å®æ—¶å¨èƒç›‘æ§èƒ½å¤Ÿåœ¨è§†é¢‘æµä¸­è¯†åˆ«å¨èƒè¡Œä¸ºï¼Œå¹¶é€šè¿‡è§£é‡Šæ€§æ–‡æœ¬å¯¹å¨èƒäº‹ä»¶è¿›è¡Œæ¨ç†å’Œè¯„ä¼°ã€‚ç„¶è€Œï¼Œæ— è®ºæ˜¯åŸºäºç›‘ç£å­¦ä¹ è¿˜æ˜¯ç”Ÿæˆæ¨¡å‹çš„ä¸»æµæ–¹æ³•ï¼Œéƒ½å¾ˆéš¾åŒæ—¶æ»¡è¶³å®æ—¶æ€§èƒ½å’Œå†³ç­–å¯è§£é‡Šæ€§çš„è‹›åˆ»è¦æ±‚ã€‚ä¸ºäº†å¼¥å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†Live-E2Tï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ä¸‰ç§ååŒæœºåˆ¶ç»Ÿä¸€è¿™ä¸¤ä¸ªç›®æ ‡çš„æ–°å‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†è§†é¢‘å¸§è§£æ„ä¸ºç»“æ„åŒ–çš„äºº-å¯¹è±¡-äº¤äº’-åœºæ‰€è¯­ä¹‰å…ƒç»„ã€‚è¿™ç§æ–¹æ³•åˆ›å»ºäº†ç´§å‡‘ã€è¯­ä¹‰èšç„¦çš„è¡¨ç¤ºå½¢å¼ï¼Œé¿å…äº†ä¼ ç»Ÿç‰¹å¾å‹ç¼©ä¸­çš„ä¿¡æ¯é€€åŒ–ã€‚å…¶æ¬¡ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åœ¨çº¿äº‹ä»¶å»é‡å’Œæ›´æ–°æœºåˆ¶ï¼Œä»¥è¿‡æ»¤æ—¶ç©ºå†—ä½™ä¿¡æ¯ï¼Œç¡®ä¿ç³»ç»Ÿçš„å®æ—¶å“åº”èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨æ€ç»´é“¾ç­–ç•¥å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œèµ‹äºˆå…¶åœ¨äº‹ä»¶åºåˆ—ä¸Šè¿›è¡Œé€æ˜å’Œé€»è¾‘æ¨ç†çš„èƒ½åŠ›ï¼Œä»¥ç”Ÿæˆè¿è´¯çš„å¨èƒè¯„ä¼°æŠ¥å‘Šã€‚åœ¨åŒ…æ‹¬XD-Violenceå’ŒUCF-Crimeåœ¨å†…çš„åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLive-E2Tåœ¨å¨èƒæ£€æµ‹å‡†ç¡®æ€§ã€å®æ—¶æ•ˆç‡å’Œå…³é”®çš„å¯è§£é‡Šæ€§æ–¹é¢æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18571v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>å®æ—¶å¨èƒç›‘æµ‹èƒ½å¤Ÿé€šè¿‡è§£é‡Šæ€§æ–‡æœ¬å¯¹è§†é¢‘æµä¸­çš„å¨èƒè¡Œä¸ºè¿›è¡Œåˆ†æå’Œè¯„ä¼°ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºç›‘ç£å­¦ä¹ æˆ–ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•éš¾ä»¥æ»¡è¶³å®æ—¶æ€§èƒ½å’Œå†³ç­–å¯è§£é‡Šæ€§çš„è¦æ±‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Live-E2Tæ¡†æ¶ï¼Œé€šè¿‡ä¸‰ç§ååŒæœºåˆ¶å®ç°äº†è¿™ä¸¤ä¸ªç›®æ ‡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†è§†é¢‘å¸§è§£æ„ä¸ºç»“æ„åŒ–çš„äºº-å¯¹è±¡-äº¤äº’-åœºæ‰€è¯­ä¹‰å…ƒç»„ï¼Œå½¢æˆç´§å‡‘ã€è¯­ä¹‰èšç„¦çš„è¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œæå‡ºäº†é«˜æ•ˆçš„åœ¨çº¿äº‹ä»¶å»é‡å’Œæ›´æ–°æœºåˆ¶ï¼Œä¿è¯ç³»ç»Ÿçš„å®æ—¶å“åº”èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬é‡‡ç”¨é“¾å¼æ€ç»´ç­–ç•¥å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡å¯¹äº‹ä»¶åºåˆ—è¿›è¡Œé€æ˜ã€é€»è¾‘æ¨ç†çš„èƒ½åŠ›ï¼Œç”Ÿæˆè¿è´¯çš„å¨èƒè¯„ä¼°æŠ¥å‘Šã€‚åœ¨XD-Violenceå’ŒUCF-Crimeç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLive-E2Tåœ¨å¨èƒæ£€æµ‹å‡†ç¡®æ€§ã€å®æ—¶æ•ˆç‡å’Œå…³é”®çš„å¯è§£é‡Šæ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å®æ—¶å¨èƒç›‘æµ‹èƒ½å¤Ÿé€šè¿‡è§£é‡Šæ€§æ–‡æœ¬å¯¹è§†é¢‘ä¸­çš„å¨èƒè¡Œä¸ºè¿›è¡Œåˆ†æå’Œè¯„ä¼°ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éš¾ä»¥æ»¡è¶³å®æ—¶æ€§èƒ½å’Œå†³ç­–å¯è§£é‡Šæ€§çš„è¦æ±‚ã€‚</li>
<li>Live-E2Tæ¡†æ¶é€šè¿‡è§£æ„è§†é¢‘å¸§ã€å»é‡æ›´æ–°æœºåˆ¶å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒï¼Œå®ç°äº†å¨èƒæ£€æµ‹ã€å®æ—¶æ€§èƒ½å’Œè§£é‡Šæ€§çš„æå‡ã€‚</li>
<li>è§†é¢‘å¸§è¢«è§£æ„ä¸ºç»“æ„åŒ–çš„äºº-å¯¹è±¡-äº¤äº’-åœºæ‰€è¯­ä¹‰å…ƒç»„ï¼Œå½¢æˆç´§å‡‘çš„è¯­ä¹‰è¡¨ç¤ºã€‚</li>
<li>é«˜æ•ˆçš„åœ¨çº¿äº‹ä»¶å»é‡å’Œæ›´æ–°æœºåˆ¶ç¡®ä¿ç³»ç»Ÿå®æ—¶å“åº”ã€‚</li>
<li>é‡‡ç”¨é“¾å¼æ€ç»´ç­–ç•¥å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡å¯¹äº‹ä»¶åºåˆ—è¿›è¡Œé€æ˜é€»è¾‘æ¨ç†çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18571">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18571v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18571v1/page_2_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="No-Verifiable-Reward-for-Prosody-Toward-Preference-Guided-Prosody-Learning-in-TTS"><a href="#No-Verifiable-Reward-for-Prosody-Toward-Preference-Guided-Prosody-Learning-in-TTS" class="headerlink" title="No Verifiable Reward for Prosody: Toward Preference-Guided Prosody   Learning in TTS"></a>No Verifiable Reward for Prosody: Toward Preference-Guided Prosody   Learning in TTS</h2><p><strong>Authors:Seungyoun Shin, Dongha Ahn, Jiwoo Kim, Sungwook Jeon</strong></p>
<p>Recent work reports gains in neural text-to-speech (TTS) with Group Relative Policy Optimization (GRPO). However, in the absence of a verifiable reward for \textit{prosody}, GRPO trained on transcription-oriented signals (CER&#x2F;NLL) lowers error rates yet collapses prosody into monotone, unnatural speech; adding speaker-similarity further destabilizes training and degrades CER. We address this with an \textit{iterative Direct Preference Optimization (DPO)} scheme that uses only a few hundred human-labeled preference pairs per round to directly optimize prosodic naturalness while regularizing to the current model. On \textbf{KoCC-TTS}, a curated dataset of authentic Korean call center interactions capturing task-oriented dialogues, our method attains the highest human preference (ELO) with competitive CER, outperforming GRPO and strong commercial baselines. These results suggest that when prosody cannot be rewarded automatically, \textit{human preference optimization} offers a practical and data-efficient path to natural and robust TTS. The demo page is available at \href{<a target="_blank" rel="noopener" href="https://tts.ch.dev}/">https://tts.ch.dev}</a> </p>
<blockquote>
<p>è¿‘æœŸçš„å·¥ä½œæŠ¥å‘Šè¡¨æ˜ï¼Œåœ¨ç¥ç»æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰é¢†åŸŸï¼Œé‡‡ç”¨ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å–å¾—äº†ä¸€å®šçš„è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¯éªŒè¯çš„éŸµå¾‹å¥–åŠ±ï¼ŒåŸºäºè½¬å½•å¯¼å‘ä¿¡å·ï¼ˆCER&#x2F;NLLï¼‰è®­ç»ƒçš„GRPOè™½ç„¶é™ä½äº†é”™è¯¯ç‡ï¼Œä½†å´å°†éŸµå¾‹è½¬åŒ–ä¸ºå•è°ƒã€ä¸è‡ªç„¶çš„è¯­éŸ³ï¼›å¢åŠ è¯´è¯äººç›¸ä¼¼æ€§ä¼šè¿›ä¸€æ­¥ä½¿è®­ç»ƒä¸ç¨³å®šå¹¶é™ä½CERã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§è¿­ä»£å¼çš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆæ¯è½®ä»…ä½¿ç”¨æ•°ç™¾ä¸ªäººå·¥æ ‡è®°çš„åå¥½å¯¹ï¼Œä»¥ç›´æ¥ä¼˜åŒ–éŸµå¾‹çš„è‡ªç„¶æ€§ï¼ŒåŒæ—¶å¯¹å…¶è¿›è¡Œæ­£åˆ™åŒ–ä»¥ç¬¦åˆå½“å‰æ¨¡å‹ã€‚åœ¨ã€ŠKoCC-TTSã€‹è¿™ä¸€ç»è¿‡ç­›é€‰çš„éŸ©å›½å‘¼å«ä¸­å¿ƒäº’åŠ¨æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€é«˜çš„äººç±»åå¥½ï¼ˆELOï¼‰ï¼ŒCERå…·æœ‰ç«äº‰åŠ›ï¼Œè¶…è¶Šäº†GRPOå’Œå¼ºå¤§çš„å•†ä¸šåŸºçº¿ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå½“éŸµå¾‹ä¸èƒ½è‡ªåŠ¨å¥–åŠ±æ—¶ï¼Œäººå·¥åå¥½ä¼˜åŒ–ä¸ºè‡ªç„¶å’Œç¨³å¥çš„TTSæä¾›äº†ä¸€æ¡å®ç”¨ä¸”æ•°æ®é«˜æ•ˆçš„é“è·¯ã€‚æ¼”ç¤ºé¡µé¢å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://tts.ch.dev./">https://tts.ch.devã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18531v1">PDF</a> submitted to ICASSP 2026</p>
<p><strong>Summary</strong><br>ç¥ç»æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰é¢†åŸŸè¿‘æœŸé‡‡ç”¨ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨ç¼ºä¹å¯éªŒè¯çš„éŸµå¾‹å¥–åŠ±çš„æƒ…å†µä¸‹ï¼ŒGRPOåœ¨é¢å‘è½¬å½•çš„ä¿¡å·ï¼ˆCER&#x2F;NLLï¼‰ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè™½ç„¶é™ä½äº†é”™è¯¯ç‡ï¼Œä½†ç”Ÿæˆçš„è¯­éŸ³ç¼ºä¹éŸµå¾‹ï¼Œå‘ˆç°å•è°ƒä¸è‡ªç„¶çš„çŠ¶æ€ã€‚æ·»åŠ è¯´è¯äººç›¸ä¼¼æ€§ä¼šè¿›ä¸€æ­¥ç ´åè®­ç»ƒå¹¶é™ä½CERã€‚æœ¬ç ”ç©¶é€šè¿‡è¿­ä»£ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ–¹æ¡ˆè§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥æ–¹æ¡ˆä»…ä½¿ç”¨å‡ ç™¾ä¸ªäººå·¥æ ‡æ³¨çš„åå¥½å¯¹è¿›è¡Œä¸€è½®ä¼˜åŒ–ï¼Œå¯ç›´æ¥ä¼˜åŒ–éŸµå¾‹çš„è‡ªç„¶æ€§å¹¶è¿›è¡Œå½“å‰æ¨¡å‹çš„è§„åˆ™åŒ–ã€‚åœ¨çœŸå®çš„éŸ©å›½å‘¼å«ä¸­å¿ƒäº’åŠ¨æ•°æ®é›†KoCC-TTSä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€é«˜çš„äººç±»åå¥½ï¼ˆELOï¼‰ï¼Œåœ¨CERä¸Šå…·æœ‰ç«äº‰åŠ›ï¼Œä¼˜äºGRPOå’Œå¼ºå¤§çš„å•†ä¸šåŸºçº¿ã€‚è¿™äº›ç»“æœæš—ç¤ºï¼Œå½“éŸµå¾‹æ— æ³•è‡ªåŠ¨å¥–åŠ±æ—¶ï¼Œäººç±»åå¥½ä¼˜åŒ–ä¸ºè‡ªç„¶å’Œç¨³å¥çš„TTSæä¾›äº†ä¸€æ¡å®ç”¨ä¸”æ•°æ®é«˜æ•ˆçš„é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Group Relative Policy Optimization (GRPO) åœ¨ç¥ç»æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ä¸­çš„åº”ç”¨è™½ç„¶é™ä½äº†é”™è¯¯ç‡ï¼Œä½†å¯¼è‡´ç”Ÿæˆçš„è¯­éŸ³ç¼ºä¹éŸµå¾‹ï¼Œå‘ˆç°å•è°ƒä¸è‡ªç„¶çš„çŠ¶æ€ã€‚</li>
<li>åœ¨ç¼ºä¹éŸµå¾‹å¥–åŠ±çš„æƒ…å†µä¸‹ï¼Œæ·»åŠ è¯´è¯äººç›¸ä¼¼æ€§ä¼šè¿›ä¸€æ­¥ç ´åè®­ç»ƒå¹¶é™ä½æ€§èƒ½ã€‚</li>
<li>è¿­ä»£ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ–¹æ¡ˆè¢«æå‡ºæ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥æ–¹æ¡ˆä½¿ç”¨å°‘é‡äººå·¥æ ‡æ³¨çš„åå¥½å¯¹è¿›è¡Œä¼˜åŒ–ï¼Œèƒ½ç›´æ¥ä¼˜åŒ–éŸµå¾‹çš„è‡ªç„¶æ€§å¹¶è¿›è¡Œæ¨¡å‹è§„åˆ™åŒ–ã€‚</li>
<li>åœ¨çœŸå®çš„éŸ©å›½å‘¼å«ä¸­å¿ƒäº’åŠ¨æ•°æ®é›†KoCC-TTSä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒDPOæ–¹æ³•è¾¾åˆ°äº†æœ€é«˜çš„äººç±»åå¥½è¯„åˆ†ï¼ˆELOï¼‰ï¼Œä¸”åœ¨å­—ç¬¦é”™è¯¯ç‡ï¼ˆCERï¼‰ä¸Šå…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>DPOæ–¹æ³•ä¼˜äºGRPOå’Œå¼ºå¤§çš„å•†ä¸šåŸºçº¿ï¼Œæš—ç¤ºäº†äººç±»åå¥½ä¼˜åŒ–å¯¹äºåˆ›å»ºè‡ªç„¶å’Œç¨³å¥çš„TTSçš„é‡è¦æ€§ã€‚</li>
<li>ç ”ç©¶ç»“æœæä¾›äº†ä¸€ç§æ•°æ®é«˜æ•ˆçš„æ–¹æ³•ï¼Œå³å½“éŸµå¾‹æ— æ³•è‡ªåŠ¨å¥–åŠ±æ—¶ï¼Œå¯ä»¥é€šè¿‡äººç±»åå¥½ä¼˜åŒ–æ¥å®ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18531">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18531v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18531v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18531v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="APRIL-Active-Partial-Rollouts-in-Reinforcement-Learning-to-Tame-Long-tail-Generation"><a href="#APRIL-Active-Partial-Rollouts-in-Reinforcement-Learning-to-Tame-Long-tail-Generation" class="headerlink" title="APRIL: Active Partial Rollouts in Reinforcement Learning to Tame   Long-tail Generation"></a>APRIL: Active Partial Rollouts in Reinforcement Learning to Tame   Long-tail Generation</h2><p><strong>Authors:Yuzhen Zhou, Jiajun Li, Yusheng Su, Gowtham Ramesh, Zilin Zhu, Xiang Long, Chenyang Zhao, Jin Pan, Xiaodong Yu, Ze Wang, Kangrui Du, Jialian Wu, Ximeng Sun, Jiang Liu, Qiaolin Yu, Hao Chen, Zicheng Liu, Emad Barsoum</strong></p>
<p>Reinforcement learning (RL) has become a cornerstone in advancing large-scale pre-trained language models (LLMs). Successive generations, including GPT-o series, DeepSeek-R1, Kimi-K1.5, Grok 4, and GLM-4.5, have relied on large-scale RL training to enhance reasoning and coding capabilities. To meet the communityâ€™s growing RL needs, numerous RL frameworks have been proposed. However, RL training remains computationally expensive, with rollout generation accounting for more than 90% of total runtime. In addition, its efficiency is often constrained by the long-tail distribution of rollout response lengths, where a few lengthy responses stall entire batches, leaving GPUs idle and underutilized. As model and rollout sizes continue to grow, this bottleneck increasingly limits scalability. To address this challenge, we propose Active Partial Rollouts in Reinforcement Learning (APRIL), which mitigates long-tail inefficiency. In the rollout phase, APRIL over-provisions rollout requests, terminates once the target number of responses is reached, and recycles incomplete responses for continuation in future steps. This strategy ensures that no rollouts are discarded while substantially reducing GPU idle time. Experiments show that APRIL improves rollout throughput by at most 44% across commonly used RL algorithms (GRPO, DAPO, GSPO), accelerates convergence, and achieves at most 8% higher final accuracy across tasks. Moreover, APRIL is both framework and hardware agnostic, already integrated into the slime RL framework, and deployable on NVIDIA and AMD GPUs alike. Taken together, this work unifies system-level and algorithmic considerations in proposing APRIL, with the aim of advancing RL training efficiency and inspiring further optimizations in RL systems. Our codebase is available at <a target="_blank" rel="noopener" href="https://github.com/RLsys-Foundation/APRIL">https://github.com/RLsys-Foundation/APRIL</a> </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºæ¨åŠ¨å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘å±•çš„æ ¸å¿ƒã€‚åŒ…æ‹¬GPT-oç³»åˆ—ã€DeepSeek-R1ã€Kimi-K1.5ã€Grok 4å’ŒGLM-4.5ç­‰åç»­å‡ ä»£éƒ½ä¾èµ–äºå¤§è§„æ¨¡RLè®­ç»ƒæ¥æé«˜æ¨ç†å’Œç¼–ç èƒ½åŠ›ã€‚ä¸ºäº†æ»¡è¶³ç¤¾åŒºæ—¥ç›Šå¢é•¿çš„RLéœ€æ±‚ï¼Œå·²ç»æå‡ºäº†è®¸å¤šRLæ¡†æ¶ã€‚ç„¶è€Œï¼ŒRLè®­ç»ƒçš„è®¡ç®—æˆæœ¬ä»ç„¶å¾ˆé«˜ï¼Œrolloutç”Ÿæˆå æ€»è¿è¡Œæ—¶é—´çš„90%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œå…¶æ•ˆç‡é€šå¸¸å—åˆ°rolloutå“åº”é•¿åº¦é•¿å°¾åˆ†å¸ƒçš„é™åˆ¶ï¼Œå…¶ä¸­ä¸€äº›å†—é•¿çš„å“åº”ä½¿æ•´ä¸ªæ‰¹æ¬¡é™·å…¥åœæ»ï¼Œå¯¼è‡´GPUç©ºé—²å’Œåˆ©ç”¨ç‡ä½ä¸‹ã€‚éšç€æ¨¡å‹å’Œrolloutè§„æ¨¡çš„æŒç»­å¢é•¿ï¼Œè¿™ä¸ªç“¶é¢ˆè¶Šæ¥è¶Šé™åˆ¶äº†å¯æ‰©å±•æ€§ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸»åŠ¨éƒ¨åˆ†rolloutï¼ˆAPRILï¼‰ï¼Œç¼“è§£äº†é•¿å°¾ä½æ•ˆé—®é¢˜ã€‚åœ¨rollouté˜¶æ®µï¼ŒAPRILè¿‡åº¦æä¾›rolloutè¯·æ±‚ï¼Œè¾¾åˆ°ç›®æ ‡å“åº”æ•°åç»ˆæ­¢ï¼Œå¹¶å°†æœªå®Œæˆçš„å“åº”å›æ”¶ç”¨äºæœªæ¥æ­¥éª¤çš„ç»§ç»­ã€‚è¿™ä¸€ç­–ç•¥ç¡®ä¿äº†ä¸ä¼šä¸¢å¼ƒä»»ä½•rolloutï¼ŒåŒæ—¶å¤§å¤§å‡å°‘GPUç©ºé—²æ—¶é—´ã€‚å®éªŒè¡¨æ˜ï¼ŒAPRILåœ¨å¸¸ç”¨çš„RLç®—æ³•ï¼ˆGRPOã€DAPOã€GSPOï¼‰ä¸­æé«˜äº†æœ€å¤š44%çš„rolloutååé‡ï¼ŒåŠ é€Ÿäº†æ”¶æ•›ï¼Œå¹¶åœ¨å„é¡¹ä»»åŠ¡ä¸­å®ç°äº†æœ€å¤š8%çš„æ›´é«˜æœ€ç»ˆç²¾åº¦ã€‚æ­¤å¤–ï¼ŒAPRILå…·æœ‰æ¡†æ¶å’Œç¡¬ä»¶æ— å…³æ€§ï¼Œå·²ç»é›†æˆåˆ°slime RLæ¡†æ¶ä¸­ï¼Œå¯åœ¨NVIDIAå’ŒAMDçš„GPUä¸Šéƒ¨ç½²ã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒAPRILçš„å·¥ä½œç»“åˆäº†ç³»ç»Ÿå±‚é¢å’Œç®—æ³•å±‚é¢çš„è€ƒè™‘ï¼Œæ—¨åœ¨æé«˜RLè®­ç»ƒæ•ˆç‡ï¼Œå¹¶æ¿€å‘RLç³»ç»Ÿçš„è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚æˆ‘ä»¬çš„ä»£ç åº“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/RLsys-Foundation/APRIL%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/RLsys-Foundation/APRILæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18521v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ä¸­èµ·åˆ°å…³é”®ä½œç”¨ã€‚ç„¶è€Œï¼ŒRLè®­ç»ƒè®¡ç®—æˆæœ¬é«˜ï¼Œé¢ä¸´rolloutç”Ÿæˆæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºActive Partial Rollouts in Reinforcement Learningï¼ˆAPRILï¼‰æ–¹æ³•ï¼Œé€šè¿‡è¿‡æä¾›rolloutè¯·æ±‚ã€ç»ˆæ­¢è¾¾åˆ°ç›®æ ‡å“åº”æ•°åå›æ”¶æœªå®Œæˆçš„å“åº”ç”¨äºåç»­æ­¥éª¤ç»§ç»­ï¼Œå‡å°‘äº†GPUç©ºé—²æ—¶é—´ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚å®éªŒè¯æ˜APRILèƒ½æé«˜å¸¸è§RLç®—æ³•çš„ååé‡ï¼ŒåŠ é€Ÿæ”¶æ•›ï¼Œæé«˜ä»»åŠ¡æœ€ç»ˆç²¾åº¦ã€‚APRILæ¡†æ¶å·²é›†æˆåˆ°slime RLæ¡†æ¶ä¸­ï¼Œå¹¶å¯åœ¨NVIDIAå’ŒAMD GPUä¸Šéƒ¨ç½²ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ¨åŠ¨RLè®­ç»ƒæ•ˆç‡çš„æå‡ï¼Œä¸ºRLç³»ç»Ÿçš„è¿›ä¸€æ­¥ä¼˜åŒ–æä¾›çµæ„Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‘å±•ä¸­èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚</li>
<li>å½“å‰å¼ºåŒ–å­¦ä¹ é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬é«˜è®¡ç®—æˆæœ¬å’Œrolloutç”Ÿæˆæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•APRILï¼Œé€šè¿‡ä¸»åŠ¨éƒ¨åˆ†rolloutç­–ç•¥æé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>APRILé€šè¿‡å›æ”¶æœªå®Œæˆçš„å“åº”å¹¶ç”¨äºåç»­æ­¥éª¤ï¼Œå‡å°‘äº†GPUçš„ç©ºé—²æ—¶é—´ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºAPRILèƒ½æé«˜è®­ç»ƒååé‡ã€åŠ é€Ÿæ”¶æ•›å¹¶æå‡ä»»åŠ¡ç²¾åº¦ã€‚</li>
<li>APRILæ¡†æ¶å…·æœ‰æ™®éé€‚ç”¨æ€§ï¼Œå¯é›†æˆåˆ°ä¸åŒçš„RLæ¡†æ¶å’Œç¡¬ä»¶å¹³å°ä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18521">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18521v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18521v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18521v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18521v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18521v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="CogniLoad-A-Synthetic-Natural-Language-Reasoning-Benchmark-With-Tunable-Length-Intrinsic-Difficulty-and-Distractor-Density"><a href="#CogniLoad-A-Synthetic-Natural-Language-Reasoning-Benchmark-With-Tunable-Length-Intrinsic-Difficulty-and-Distractor-Density" class="headerlink" title="CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable   Length, Intrinsic Difficulty, and Distractor Density"></a>CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable   Length, Intrinsic Difficulty, and Distractor Density</h2><p><strong>Authors:Daniel Kaiser, Arnoldo Frigessi, Ali Ramezani-Kebrya, Benjamin Ricaud</strong></p>
<p>Current benchmarks for long-context reasoning in Large Language Models (LLMs) often blur critical factors like intrinsic task complexity, distractor interference, and task length. To enable more precise failure analysis, we introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load Theory (CLT). CogniLoad generates natural-language logic puzzles with independently tunable parameters that reflect CLTâ€™s core dimensions: intrinsic difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$) regulates extraneous load; and task length ($N$) serves as an operational proxy for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs, CogniLoad reveals distinct performance sensitivities, identifying task length as a dominant constraint and uncovering varied tolerances to intrinsic complexity and U-shaped responses to distractor ratios. By offering systematic, factorial control over these cognitive load dimensions, CogniLoad provides a reproducible, scalable, and diagnostically rich tool for dissecting LLM reasoning limitations and guiding future model development. </p>
<blockquote>
<p>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é•¿æ–‡æœ¬æ¨ç†åŸºå‡†æµ‹è¯•é€šå¸¸å¿½ç•¥äº†å…³é”®è¦ç´ ï¼Œå¦‚å†…åœ¨ä»»åŠ¡å¤æ‚æ€§ã€å¹²æ‰°é¡¹å¹²æ‰°å’Œä»»åŠ¡é•¿åº¦ã€‚ä¸ºäº†è¿›è¡Œæ›´ç²¾ç¡®çš„å¤±è´¥åˆ†æï¼Œæˆ‘ä»¬å¼•å…¥äº†CogniLoadï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCLTï¼‰çš„æ–°å‹åˆæˆåŸºå‡†æµ‹è¯•ã€‚CogniLoadç”Ÿæˆè‡ªç„¶è¯­è¨€é€»è¾‘è°œé¢˜ï¼Œå…·æœ‰å¯ç‹¬ç«‹è°ƒæ•´çš„å‚æ•°ï¼Œåæ˜ äº†CLTçš„æ ¸å¿ƒç»´åº¦ï¼šå†…åœ¨éš¾åº¦ï¼ˆdï¼‰æ§åˆ¶å†…åœ¨è´Ÿè·ï¼›å¹²æ‰°é¡¹ä¸ä¿¡å·æ¯”ä¾‹ï¼ˆÏï¼‰è°ƒèŠ‚å¤–åœ¨è´Ÿè·ï¼›ä»»åŠ¡é•¿åº¦ï¼ˆNï¼‰ä½œä¸ºéœ€è¦ç›¸å…³è´Ÿè·æ¡ä»¶çš„æ“ä½œä»£ç†ã€‚é€šè¿‡å¯¹22ä¸ªæœ€æ–°æ¨ç†LLMè¿›è¡Œè¯„ä¼°ï¼ŒCogniLoadæ˜¾ç¤ºäº†ä¸åŒçš„æ€§èƒ½æ•æ„Ÿæ€§ï¼Œç¡®å®šäº†ä»»åŠ¡é•¿åº¦æ˜¯ä¸»è¦çš„çº¦æŸæ¡ä»¶ï¼Œå¹¶å‘ç°äº†å¯¹å†…åœ¨å¤æ‚æ€§çš„ä¸åŒå®¹å¿åº¦å’Œå¹²æ‰°é¡¹æ¯”ä¾‹çš„Uå‹ååº”ã€‚é€šè¿‡ç³»ç»Ÿã€å› ç´ åœ°æ§åˆ¶è¿™äº›è®¤çŸ¥è´Ÿè·ç»´åº¦ï¼ŒCogniLoadæä¾›äº†ä¸€ä¸ªå¯é‡å¤ã€å¯æ‰©å±•ä¸”è¯Šæ–­ä¸°å¯Œçš„å·¥å…·ï¼Œç”¨äºå‰–æLLMçš„æ¨ç†å±€é™æ€§å¹¶æŒ‡å¯¼æœªæ¥çš„æ¨¡å‹å¼€å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18458v2">PDF</a> 29 pages (main: 12 + supplemental material: 17), 6 figures, 4 tables,   Code: <a target="_blank" rel="noopener" href="https://github.com/kaiserdan/cogniload">https://github.com/kaiserdan/cogniload</a>, Data:   <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/cogniloadteam/cogniload">https://huggingface.co/datasets/cogniloadteam/cogniload</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºè®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCLTï¼‰ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹åˆæˆåŸºå‡†æµ‹è¯•CogniLoadï¼Œç”¨äºæ›´ç²¾ç¡®åœ°åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é•¿æ–‡æœ¬æ¨ç†ä¸­çš„å±€é™æ€§ã€‚è¯¥åŸºå‡†æµ‹è¯•é€šè¿‡ç‹¬ç«‹è°ƒèŠ‚å†…åœ¨éš¾åº¦ã€å¹²æ‰°ç‰©ä¸ä¿¡å·æ¯”ä¾‹å’Œä»»åŠ¡é•¿åº¦ç­‰æ ¸å¿ƒç»´åº¦ï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€é€»è¾‘è°œé¢˜ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œä»»åŠ¡é•¿åº¦æ˜¯ä¸»å¯¼çº¦æŸæ¡ä»¶ï¼Œè€Œå¯¹å†…åœ¨å¤æ‚åº¦å’Œå¹²æ‰°ç‰©æ¯”ä¾‹çš„è€å—æ€§å­˜åœ¨å·®å¼‚ã€‚CogniLoadä¸ºè§£æLLMæ¨ç†èƒ½åŠ›æä¾›äº†å¯å¤åˆ¶ã€å¯æ‰©å±•ä¸”è¯Šæ–­ä¸°å¯Œçš„å·¥å…·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CogniLoadæ˜¯ä¸€ç§åŸºäºè®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCLTï¼‰çš„åˆæˆåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é•¿æ–‡æœ¬æ¨ç†èƒ½åŠ›ã€‚</li>
<li>è¯¥åŸºå‡†æµ‹è¯•é€šè¿‡è°ƒèŠ‚å†…åœ¨éš¾åº¦ã€å¹²æ‰°ç‰©ä¸ä¿¡å·æ¯”ä¾‹å’Œä»»åŠ¡é•¿åº¦ç­‰ç»´åº¦ï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€é€»è¾‘è°œé¢˜ã€‚</li>
<li>ä»»åŠ¡é•¿åº¦æ˜¯å½±å“LLMæ¨ç†æ€§èƒ½çš„ä¸»è¦çº¦æŸæ¡ä»¶ã€‚</li>
<li>LLMå¯¹å†…åœ¨å¤æ‚åº¦å’Œå¹²æ‰°ç‰©æ¯”ä¾‹çš„è€å—æ€§å­˜åœ¨å·®å¼‚æ€§ã€‚</li>
<li>CogniLoadèƒ½å¤Ÿç³»ç»Ÿåœ°åˆ†æLLMçš„æ¨ç†é™åˆ¶ï¼Œå¹¶ä¸ºæœªæ¥æ¨¡å‹å¼€å‘æä¾›æŒ‡å¯¼ã€‚</li>
<li>CogniLoadå…·æœ‰å¯å¤åˆ¶æ€§ã€å¯æ‰©å±•æ€§å’Œä¸°å¯Œçš„è¯Šæ–­åŠŸèƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18458">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18458v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18458v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18458v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18458v2/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18458v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="TempSamp-R1-Effective-Temporal-Sampling-with-Reinforcement-Fine-Tuning-for-Video-LLMs"><a href="#TempSamp-R1-Effective-Temporal-Sampling-with-Reinforcement-Fine-Tuning-for-Video-LLMs" class="headerlink" title="TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning   for Video LLMs"></a>TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning   for Video LLMs</h2><p><strong>Authors:Yunheng Li, Jing Cheng, Shaoyong Jia, Hangyi Kuang, Shaohui Jiao, Qibin Hou, Ming-Ming Cheng</strong></p>
<p>This paper introduces TempSamp-R1, a new reinforcement fine-tuning framework designed to improve the effectiveness of adapting multimodal large language models (MLLMs) to video temporal grounding tasks. We reveal that existing reinforcement learning methods, such as Group Relative Policy Optimization (GRPO), rely on on-policy sampling for policy updates. However, in tasks with large temporal search spaces, this strategy becomes both inefficient and limited in performance, as it often fails to identify temporally accurate solutions. To address this limitation, TempSamp-R1 leverages ground-truth annotations as off-policy supervision to provide temporally precise guidance, effectively compensating for the sparsity and misalignment in on-policy solutions. To further stabilize training and reduce variance in reward-based updates, TempSamp-R1 provides a non-linear soft advantage computation method that dynamically reshapes the reward feedback via an asymmetric transformation. By employing a hybrid Chain-of-Thought (CoT) training paradigm, TempSamp-R1 optimizes a single unified model to support both CoT and non-CoT inference modes, enabling efficient handling of queries with varying reasoning complexity. Experimental results demonstrate that TempSamp-R1 outperforms GRPO-based baselines, establishing new state-of-the-art performance on benchmark datasets: Charades-STA (<a href="mailto:&#x52;&#49;&#64;&#x30;&#46;&#x37;">&#x52;&#49;&#64;&#x30;&#46;&#x37;</a>: 52.9%, +2.7%), ActivityNet Captions (<a href="mailto:&#x52;&#x31;&#64;&#x30;&#x2e;&#x35;">&#x52;&#x31;&#64;&#x30;&#x2e;&#x35;</a>: 56.0%, +5.3%), and QVHighlights (mAP: 30.0%, +3.0%). Moreover, TempSamp-R1 shows robust few-shot generalization capabilities under limited data. Code: <a target="_blank" rel="noopener" href="https://github.com/HVision-NKU/TempSamp-R1">https://github.com/HVision-NKU/TempSamp-R1</a> </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†TempSamp-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„å¼ºåŒ–ç²¾ç»†è°ƒæ•´æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰é€‚åº”è§†é¢‘æ—¶é—´å®šä½ä»»åŠ¡çš„æ•ˆç‡ã€‚æˆ‘ä»¬å‘ç°ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¦‚ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œä¾èµ–äºç­–ç•¥æ›´æ–°çš„åœ¨ç­–ç•¥é‡‡æ ·ã€‚ç„¶è€Œï¼Œåœ¨å…·æœ‰å¤§æ—¶é—´æœç´¢ç©ºé—´çš„ä»»åŠ¡ä¸­ï¼Œæ­¤ç­–ç•¥æ—¢æ•ˆç‡ä½ä¸‹ï¼Œæ€§èƒ½ä¹Ÿæœ‰é™ï¼Œå› ä¸ºå®ƒå¾€å¾€æ— æ³•è¯†åˆ«å‡ºæ—¶é—´å‡†ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒTempSamp-R1åˆ©ç”¨çœŸå®æ ‡æ³¨ä½œä¸ºç¦»çº¿ç›‘ç£ï¼Œæä¾›æ—¶é—´ç²¾ç¡®çš„æŒ‡å¯¼ï¼Œæœ‰æ•ˆåœ°è¡¥å¿äº†åœ¨ç­–ç•¥è§£å†³æ–¹æ¡ˆä¸­çš„ç¨€ç–æ€§å’Œé”™ä½é—®é¢˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç¨³å®šè®­ç»ƒå¹¶å‡å°‘åŸºäºå¥–åŠ±çš„æ›´æ–°çš„æ–¹å·®ï¼ŒTempSamp-R1æä¾›äº†ä¸€ç§éçº¿æ€§è½¯ä¼˜åŠ¿è®¡ç®—æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸å¯¹ç§°è½¬æ¢åŠ¨æ€åœ°é‡å¡‘å¥–åŠ±åé¦ˆã€‚é€šè¿‡é‡‡ç”¨æ··åˆå¼çš„æ€ç»´é“¾ï¼ˆCoTï¼‰è®­ç»ƒèŒƒå¼ï¼ŒTempSamp-R1ä¼˜åŒ–äº†ä¸€ä¸ªå•ä¸€çš„ç»Ÿä¸€æ¨¡å‹ï¼Œä»¥æ”¯æŒCoTå’ŒéCoTæ¨ç†æ¨¡å¼ï¼Œä»è€Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†ä¸åŒæ¨ç†å¤æ‚åº¦çš„æŸ¥è¯¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTempSamp-R1ä¼˜äºåŸºäºGRPOçš„åŸºçº¿æ–¹æ³•ï¼Œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°æ€§èƒ½ï¼šCharades-STAï¼ˆ<a href="mailto:&#x52;&#x31;&#64;&#x30;&#x2e;&#55;">&#x52;&#x31;&#64;&#x30;&#x2e;&#55;</a>ï¼š52.9%ï¼Œ+2.7%ï¼‰ã€ActivityNet Captionsï¼ˆ<a href="mailto:&#x52;&#x31;&#x40;&#x30;&#46;&#x35;">&#x52;&#x31;&#x40;&#x30;&#46;&#x35;</a>ï¼š56.0%ï¼Œ+5.3%ï¼‰å’ŒQVHighlightsï¼ˆmAPï¼š30.0%ï¼Œ+3.0%ï¼‰ã€‚æ­¤å¤–ï¼ŒTempSamp-R1åœ¨æœ‰é™æ•°æ®ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„å°‘é‡é€šç”¨åŒ–èƒ½åŠ›ã€‚ä»£ç åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/HVision-NKU/TempSamp-R1">https://github.com/HVision-NKU/TempSamp-R1</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18056v2">PDF</a> Accepted at NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºTempSamp-R1çš„æ–°å‹å¼ºåŒ–ç²¾ç»†è°ƒæ•´æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘æ—¶åºå®šä½ä»»åŠ¡ä¸­çš„æ•ˆç‡ã€‚é’ˆå¯¹ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤§å‹æ—¶åºæœç´¢ç©ºé—´ä¸­çš„å±€é™æ€§ï¼ŒTempSamp-R1åˆ©ç”¨çœŸå®æ ‡æ³¨ä½œä¸ºç¦»çº¿ç­–ç•¥ç›‘ç£ï¼Œæä¾›ç²¾ç¡®çš„æ—¶é—´æŒ‡å¯¼ï¼Œå¹¶å¼•å…¥éçº¿æ€§è½¯ä¼˜åŠ¿è®¡ç®—æ–¹æ³•ï¼ŒåŠ¨æ€è°ƒæ•´å¥–åŠ±åé¦ˆã€‚ç»“åˆChain-of-Thoughtè®­ç»ƒèŒƒå¼ï¼ŒTempSamp-R1ä¼˜åŒ–å•ä¸€æ¨¡å‹ï¼Œæ”¯æŒä¸åŒæ¨ç†å¤æ‚åº¦çš„æŸ¥è¯¢å¤„ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTempSamp-R1åœ¨Charades-STAã€ActivityNet Captionså’ŒQVHighlightsç­‰åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€æ–°æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TempSamp-R1æ˜¯ä¸€ä¸ªå¼ºåŒ–ç²¾ç»†è°ƒæ•´æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§†é¢‘æ—¶åºå®šä½ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</li>
<li>ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤§å‹æ—¶åºæœç´¢ç©ºé—´ä¸­å­˜åœ¨å±€é™æ€§ï¼ŒTempSamp-R1é€šè¿‡å¼•å…¥çœŸå®æ ‡æ³¨ä½œä¸ºç¦»çº¿ç­–ç•¥ç›‘ç£æ¥å…‹æœè¿™äº›å±€é™æ€§ã€‚</li>
<li>TempSamp-R1æä¾›ç²¾ç¡®çš„æ—¶é—´æŒ‡å¯¼ï¼Œè§£å†³äº†åœ¨çº¿ç­–ç•¥è§£å†³æ–¹æ¡ˆä¸­çš„ç¨€ç–æ€§å’Œä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>é€šè¿‡éçº¿æ€§è½¯ä¼˜åŠ¿è®¡ç®—æ–¹æ³•ï¼ŒTempSamp-R1åŠ¨æ€è°ƒæ•´å¥–åŠ±åé¦ˆï¼Œè¿›ä¸€æ­¥ç¨³å®šè®­ç»ƒå¹¶å‡å°‘åŸºäºå¥–åŠ±çš„æ›´æ–°çš„æ–¹å·®ã€‚</li>
<li>TempSamp-R1é‡‡ç”¨æ··åˆçš„Chain-of-Thoughtè®­ç»ƒèŒƒå¼ï¼Œä¼˜åŒ–å•ä¸€æ¨¡å‹ä»¥æ”¯æŒä¸åŒæ¨ç†å¤æ‚åº¦çš„æŸ¥è¯¢ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒTempSamp-R1åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€æ–°æ€§èƒ½ï¼ŒåŒ…æ‹¬Charades-STAã€ActivityNet Captionså’ŒQVHighlightsã€‚</li>
<li>TempSamp-R1å±•ç°å‡ºåœ¨æœ‰é™æ•°æ®ä¸‹çš„ç¨³å¥çš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18056">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18056v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18056v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18056v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.18056v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="MicroRCA-Agent-Microservice-Root-Cause-Analysis-Method-Based-on-Large-Language-Model-Agents"><a href="#MicroRCA-Agent-Microservice-Root-Cause-Analysis-Method-Based-on-Large-Language-Model-Agents" class="headerlink" title="MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large   Language Model Agents"></a>MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large   Language Model Agents</h2><p><strong>Authors:Pan Tang, Shixiang Tang, Huanqi Pu, Zhiqing Miao, Zhixing Wang</strong></p>
<p>This paper presents MicroRCA-Agent, an innovative solution for microservice root cause analysis based on large language model agents, which constructs an intelligent fault root cause localization system with multimodal data fusion. The technical innovations are embodied in three key aspects: First, we combine the pre-trained Drain log parsing algorithm with multi-level data filtering mechanism to efficiently compress massive logs into high-quality fault features. Second, we employ a dual anomaly detection approach that integrates Isolation Forest unsupervised learning algorithms with status code validation to achieve comprehensive trace anomaly identification. Third, we design a statistical symmetry ratio filtering mechanism coupled with a two-stage LLM analysis strategy to enable full-stack phenomenon summarization across node-service-pod hierarchies. The multimodal root cause analysis module leverages carefully designed cross-modal prompts to deeply integrate multimodal anomaly information, fully exploiting the cross-modal understanding and logical reasoning capabilities of large language models to generate structured analysis results encompassing fault components, root cause descriptions, and reasoning trace. Comprehensive ablation studies validate the complementary value of each modal data and the effectiveness of the system architecture. The proposed solution demonstrates superior performance in complex microservice fault scenarios, achieving a final score of 50.71. The code has been released at: <a target="_blank" rel="noopener" href="https://github.com/tangpan360/MicroRCA-Agent">https://github.com/tangpan360/MicroRCA-Agent</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†MicroRCA-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„å¾®æœåŠ¡æ ¹æœ¬åŸå› åˆ†æçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼Œæ„å»ºäº†ä¸€ä¸ªå…·æœ‰å¤šæ¨¡å¼æ•°æ®èåˆçš„æ™ºèƒ½æ•…éšœæ ¹æœ¬åŸå› å®šä½ç³»ç»Ÿã€‚æŠ€æœ¯åˆ›æ–°ä½“ç°åœ¨ä¸‰ä¸ªæ–¹é¢ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å°†é¢„è®­ç»ƒçš„Drainæ—¥å¿—è§£æç®—æ³•ä¸å¤šçº§æ•°æ®è¿‡æ»¤æœºåˆ¶ç›¸ç»“åˆï¼Œæœ‰æ•ˆåœ°å°†å¤§é‡æ—¥å¿—å‹ç¼©æˆé«˜è´¨é‡æ•…éšœç‰¹å¾ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åŒé‡å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œå°†éš”ç¦»æ£®æ—æ— ç›‘ç£å­¦ä¹ ç®—æ³•ä¸çŠ¶æ€ç éªŒè¯ç›¸ç»“åˆï¼Œå®ç°å…¨é¢çš„è·Ÿè¸ªå¼‚å¸¸è¯†åˆ«ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç»Ÿè®¡å¯¹ç§°æ¯”ç‡è¿‡æ»¤æœºåˆ¶ä¸ä¸¤é˜¶æ®µLLMåˆ†æç­–ç•¥ï¼Œä»¥å®ç°åœ¨èŠ‚ç‚¹æœåŠ¡podå±‚æ¬¡ç»“æ„ä¸­çš„å…¨æ ˆç°è±¡æ€»ç»“ã€‚å¤šæ¨¡å¼æ ¹æœ¬åŸå› åˆ†ææ¨¡å—åˆ©ç”¨ç²¾å¿ƒè®¾è®¡çš„è·¨æ¨¡å¼æç¤ºæ¥æ·±å…¥æ•´åˆå¤šæ¨¡å¼å¼‚å¸¸ä¿¡æ¯ï¼Œå……åˆ†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡å¼ç†è§£å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œç”ŸæˆåŒ…å«æ•…éšœç»„ä»¶ã€æ ¹æœ¬åŸå› æè¿°å’Œæ¨ç†è·Ÿè¸ªçš„ç»“æ„åŒ–åˆ†æç»“æœã€‚å…¨é¢çš„æ¶ˆèç ”ç©¶éªŒè¯äº†æ¯ç§æ¨¡æ€æ•°æ®çš„äº’è¡¥æ€§ä»¥åŠç³»ç»Ÿæ¶æ„çš„æœ‰æ•ˆæ€§ã€‚æ‰€æå‡ºçš„è§£å†³æ–¹æ¡ˆåœ¨å¤æ‚çš„å¾®æœåŠ¡æ•…éšœåœºæ™¯ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œæœ€ç»ˆå¾—åˆ†ä¸º50.71ã€‚ä»£ç å·²å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/tangpan360/MicroRCA-Agent%E3%80%82">https://github.com/tangpan360/MicroRCA-Agentã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15635v1">PDF</a> 18 pages, 22 figures</p>
<p><strong>Summary</strong><br>å¾®æœåŠ¡æ ¹å› åˆ†æçš„æ–°è§£å†³æ–¹æ¡ˆMicroRCA-Agentï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†æ„å»ºæ™ºèƒ½æ•…éšœæ ¹å› å®šä½ç³»ç»Ÿï¼Œé‡‡ç”¨å¤šæ¨¡æ€æ•°æ®èåˆæŠ€æœ¯ã€‚è¯¥æ–¹æ¡ˆç»“åˆäº†é¢„è®­ç»ƒçš„Drainæ—¥å¿—è§£æç®—æ³•ä¸å¤šçº§æ•°æ®è¿‡æ»¤æœºåˆ¶ï¼Œå¹¶é‡‡ç”¨åŒå¼‚å¸¸æ£€æµ‹æ–¹æ³•ä¸ç»Ÿè®¡å¯¹ç§°æ¯”ç‡è¿‡æ»¤æœºåˆ¶æ¥å®ç°å…¨é¢ä¸”é«˜æ•ˆçš„æ•…éšœç‰¹å¾æå–å’Œå¼‚å¸¸è¯†åˆ«ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡æ€ç†è§£å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œç”ŸæˆåŒ…å«æ•…éšœç»„ä»¶ã€æ ¹æœ¬åŸå› æè¿°å’Œæ¨ç†è½¨è¿¹çš„ç»“æ„åŒ–åˆ†æç»“æœã€‚è¯¥è§£å†³æ–¹æ¡ˆåœ¨å¤æ‚çš„å¾®æœåŠ¡æ•…éšœåœºæ™¯ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MicroRCA-Agentæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„æ™ºèƒ½æ•…éšœæ ¹å› åˆ†æç³»ç»Ÿï¼Œç”¨äºå¾®æœåŠ¡æ ¹å› åˆ†æã€‚</li>
<li>è¯¥ç³»ç»Ÿé‡‡ç”¨å¤šæ¨¡æ€æ•°æ®èåˆæŠ€æœ¯ï¼Œèƒ½å¤Ÿå¤„ç†å¤šç§æ¥æºçš„æ•°æ®ã€‚</li>
<li>ç»“åˆé¢„è®­ç»ƒçš„Drainæ—¥å¿—è§£æç®—æ³•ä¸å¤šçº§æ•°æ®è¿‡æ»¤æœºåˆ¶ï¼Œèƒ½é«˜æ•ˆå‹ç¼©å¤§é‡æ—¥å¿—æ•°æ®ä»¥è·å–é«˜è´¨é‡çš„æ•…éšœç‰¹å¾ã€‚</li>
<li>é‡‡ç”¨åŒå¼‚å¸¸æ£€æµ‹æ–¹æ³•å’Œç»Ÿè®¡å¯¹ç§°æ¯”ç‡è¿‡æ»¤æœºåˆ¶è¿›è¡Œå¼‚å¸¸è¯†åˆ«å’Œç°è±¡æ€»ç»“ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡æ€ç†è§£å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œç”ŸæˆåŒ…å«æ•…éšœç»„ä»¶ã€æ ¹æœ¬åŸå› æè¿°å’Œæ¨ç†è½¨è¿¹çš„ç»“æ„åŒ–åˆ†æç»“æœã€‚</li>
<li>MicroRCA-Agentåœ¨å¤æ‚çš„å¾®æœåŠ¡æ•…éšœåœºæ™¯ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œæœ€ç»ˆå¾—åˆ†ä¸º50.71ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15635">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.15635v1/page_4_1.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="LaV-CoT-Language-Aware-Visual-CoT-with-Multi-Aspect-Reward-Optimization-for-Real-World-Multilingual-VQA"><a href="#LaV-CoT-Language-Aware-Visual-CoT-with-Multi-Aspect-Reward-Optimization-for-Real-World-Multilingual-VQA" class="headerlink" title="LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization   for Real-World Multilingual VQA"></a>LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization   for Real-World Multilingual VQA</h2><p><strong>Authors:Jing Huang, Zhiya Tan, Shutao Gong, Fanwei Zeng, Joey Tianyi Zhou, Jianshu Li</strong></p>
<p>As large vision language models (VLMs) advance, their capabilities in multilingual visual question answering (mVQA) have significantly improved. Chain-of-thought (CoT) reasoning has been proven to enhance interpretability and complex reasoning. However, most existing approaches rely primarily on textual CoT and provide limited support for multilingual multimodal reasoning, constraining their deployment in real-world applications. To address this gap, we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable multi-stage reasoning pipeline consisting of Text Summary with Bounding Box (BBox), Language Identification, Spatial Object-level Captioning, and Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an automated data curation method that generates multilingual CoT annotations through iterative generation, correction, and refinement, enabling scalable and high-quality training data. To improve reasoning and generalization, LaV-CoT adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT) with Language-aware Group Relative Policy Optimization (GRPO), guided by verifiable multi-aspect rewards including language consistency, structural accuracy, and semantic alignment. Extensive evaluations on public datasets including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up to ~9.5% accuracy improvements over open-source baselines of similar size and even surpasses models with 2$\times$ larger scales by ~2.6%. Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513 and Gemini-2.5-flash. We further conducted an online A&#x2F;B test to validate our method on real-world data, highlighting its effectiveness for industrial deployment. Our code is available at this link: \href{<a target="_blank" rel="noopener" href="https://github.com/HJNVR/LaV-CoT%7D">https://github.com/HJNVR/LaV-CoT}</a> </p>
<blockquote>
<p>éšç€å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„è¿›æ­¥ï¼Œå…¶åœ¨å¤šè¯­è¨€è§†è§‰é—®ç­”ï¼ˆmVQAï¼‰æ–¹é¢çš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†å·²ç»è¢«è¯æ˜å¯ä»¥æé«˜è§£é‡Šæ€§å’Œå¤æ‚æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºæ–‡æœ¬CoTï¼Œå¯¹å¤šè¯­è¨€å¤šæ¨¡æ€æ¨ç†çš„æ”¯æŒæœ‰é™ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†\textbf{LaV-CoT}ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…·æœ‰å¤šæ–¹é¢å¥–åŠ±ä¼˜åŒ–çš„è¯­è¨€æ„ŸçŸ¥è§†è§‰CoTæ¡†æ¶ã€‚LaV-CoTé‡‡ç”¨äº†ä¸€ä¸ªå¯è§£é‡Šçš„å¤šé˜¶æ®µæ¨ç†ç®¡é“ï¼ŒåŒ…æ‹¬å¸¦æœ‰è¾¹ç•Œæ¡†ï¼ˆBBoxï¼‰çš„æ–‡æœ¬æ‘˜è¦ã€è¯­è¨€è¯†åˆ«ã€ç©ºé—´å¯¹è±¡çº§æè¿°å’Œé€æ­¥é€»è¾‘æ¨ç†ã€‚éµå¾ªè¿™ä¸€æ¨ç†ç®¡é“ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªåŠ¨åŒ–æ•°æ®æ•´ç†æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆã€ä¿®æ­£å’Œç»†åŒ–ç”Ÿæˆå¤šè¯­è¨€CoTæ³¨é‡Šï¼Œå®ç°å¯æ‰©å±•å’Œé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚ä¸ºäº†æé«˜æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒLaV-CoTé‡‡ç”¨äº†ä¸€ç§ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼Œç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œè¯­è¨€æ„ŸçŸ¥ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œç”±åŒ…æ‹¬è¯­è¨€ä¸€è‡´æ€§ã€ç»“æ„å‡†ç¡®æ€§å’Œè¯­ä¹‰å¯¹é½åœ¨å†…çš„å¯éªŒè¯å¤šæ–¹é¢å¥–åŠ±æŒ‡å¯¼ã€‚åœ¨åŒ…æ‹¬MMMBã€å¤šè¯­è¨€MMBenchå’ŒMTVQAç­‰å…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒLaV-CoTç›¸è¾ƒäºç±»ä¼¼è§„æ¨¡çš„å¼€æºåŸºå‡†æµ‹è¯•ï¼Œå‡†ç¡®ç‡æé«˜äº†é«˜è¾¾9.5%ï¼Œç”šè‡³è¶…è¿‡äº†è§„æ¨¡å¤§ä¸¤å€çš„æ¨¡å‹çº¦2.6%ã€‚æ­¤å¤–ï¼ŒLaV-CoTè¿˜è¶…è¶Šäº†å…ˆè¿›çš„ä¸“æœ‰æ¨¡å‹ï¼Œå¦‚GPT-4o-0513å’ŒGemini-2.5-flashã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¿›è¡Œäº†åœ¨çº¿ABæµ‹è¯•ï¼Œä»¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œçªæ˜¾å…¶åœ¨å·¥ä¸šéƒ¨ç½²ä¸­çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬çš„ä»£ç ä½äºä»¥ä¸‹é“¾æ¥ï¼š[<a target="_blank" rel="noopener" href="https://github.com/HJNVR/LaV-CoT]">https://github.com/HJNVR/LaV-CoT]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10026v2">PDF</a> 12 Pages, 12 Figures, 2 Tables</p>
<p><strong>Summary</strong></p>
<p>éšç€å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å‘å±•ï¼Œå…¶åœ¨å¤šè¯­è¨€è§†è§‰é—®ç­”ï¼ˆmVQAï¼‰æ–¹é¢çš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚ä¸ºè§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€å¤šåª’ä½“æ¨ç†æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLaV-CoTçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆå¯è§£é‡Šçš„æ¨ç†ç®¡é“å’Œå¤šç§å¥–åŠ±ä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜äº†æ¨¡å‹çš„è§£é‡Šæ€§å’Œå¤æ‚æ¨ç†èƒ½åŠ›ã€‚LaV-CoTåœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹å’Œå…ˆè¿›ä¸“æœ‰æ¨¡å‹ï¼Œå¹¶å·²ç»é€šè¿‡äº†åœ¨çº¿ABæµ‹è¯•çš„éªŒè¯ï¼Œè¯æ˜å…¶åœ¨å·¥ä¸šéƒ¨ç½²ä¸­çš„æœ‰æ•ˆæ€§ã€‚å…¶ä»£ç å·²åœ¨æ­¤é“¾æ¥æä¾›ï¼š<a target="_blank" rel="noopener" href="https://github.com/HJNVR/LaV-CoT">https://github.com/HJNVR/LaV-CoT</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€è§†è§‰é—®ç­”æ–¹é¢çš„èƒ½åŠ›å·²æ˜¾è‘—æå‡ã€‚</li>
<li>LaV-CoTæ˜¯é¦–ä¸ªç»“åˆè¯­è¨€æ„ŸçŸ¥çš„è§†è§‰é“¾å¼æ€ç»´æ¡†æ¶ï¼Œæ”¯æŒå¤šæ–¹é¢å¥–åŠ±ä¼˜åŒ–ã€‚</li>
<li>LaV-CoTé‡‡ç”¨å¯è§£é‡Šçš„æ¨ç†ç®¡é“ï¼ŒåŒ…æ‹¬æ–‡æœ¬æ‘˜è¦ã€è¯­è¨€è¯†åˆ«ã€ç©ºé—´å¯¹è±¡çº§æè¿°å’Œé€æ­¥é€»è¾‘æ¨ç†ã€‚</li>
<li>é€šè¿‡è‡ªåŠ¨åŒ–æ•°æ®æ•´ç†æ–¹æ³•ç”Ÿæˆå¤šè¯­è¨€é“¾å¼æ€ç»´æ³¨é‡Šï¼Œæé«˜è®­ç»ƒå’Œæ¨ç†è´¨é‡ã€‚</li>
<li>LaV-CoTé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼Œç»“åˆç›‘ç£å¾®è°ƒä¸è¯­è¨€æ„ŸçŸ¥ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼Œä»¥å¤šç§å¯éªŒè¯çš„å¥–åŠ±ä¸ºæŒ‡å¯¼ã€‚</li>
<li>LaV-CoTåœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå¹¶é€šè¿‡åœ¨çº¿ABæµ‹è¯•éªŒè¯å…¶åœ¨å·¥ä¸šéƒ¨ç½²ä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10026">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.10026v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.10026v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.10026v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.10026v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="The-Thinking-Therapist-Training-Large-Language-Models-to-Deliver-Acceptance-and-Commitment-Therapy-using-Supervised-Fine-Tuning-and-Odds-Ratio-Policy-Optimization"><a href="#The-Thinking-Therapist-Training-Large-Language-Models-to-Deliver-Acceptance-and-Commitment-Therapy-using-Supervised-Fine-Tuning-and-Odds-Ratio-Policy-Optimization" class="headerlink" title="The Thinking Therapist: Training Large Language Models to Deliver   Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio   Policy Optimization"></a>The Thinking Therapist: Training Large Language Models to Deliver   Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio   Policy Optimization</h2><p><strong>Authors:Talha Tahir</strong></p>
<p>Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral therapy with emerging evidence of efficacy in several psychiatric conditions. This study investigates the impact of post-training methodology and explicit reasoning on the ability of a small open-weight large language model (LLM) to deliver ACT. Using synthetic ACT transcripts generated by Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches, supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each with and without an explicit chain-of-thought (COT) reasoning step. Performance was evaluated by comparing these four post-trained variants against the base Instruct model. These models were benchmarked in simulated therapy sessions, with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM) and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned on human evaluations. Our findings demonstrate that the ORPO-trained models significantly outperformed both their SFT and Instruct counterparts on ACT fidelity ($\chi^2(5) &#x3D; 185.15, p &lt; .001$) and therapeutic empathy ($\chi^2(5) &#x3D; 140.37, p &lt; .001$). The effect of COT was conditional as it provided a significant benefit to SFT models, improving ACT-FM scores by an average of 2.68 points ($p &lt; .001$), while offering no discernible advantage to the superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO stems from its ability to learn the therapeutic <code>process&#39; over imitating </code>content,â€™ a key aspect of ACT, while COT acts as a necessary scaffold for models trained only via imitation. This study establishes that preference-aligned policy optimization can effectively instill ACT competencies in small LLMs, and that the utility of explicit reasoning is highly dependent on the underlying training paradigm. </p>
<blockquote>
<p>æ¥çº³ä¸æ‰¿è¯ºç–—æ³•ï¼ˆACTï¼‰æ˜¯ä¸€ç§ç¬¬ä¸‰æ³¢è®¤çŸ¥è¡Œä¸ºç–—æ³•ï¼Œåœ¨å¤šç§ç²¾ç¥ç–¾ç—…ä¸­æœ‰ç–—æ•ˆçš„è¯æ®æ­£åœ¨æ˜¾ç°ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†è®­ç»ƒåçš„æ–¹æ³•å’Œæ˜ç¡®æ¨ç†å¯¹å°å‹å¼€æ”¾æƒé‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‰§è¡ŒACTèƒ½åŠ›çš„å½±å“ã€‚æˆ‘ä»¬ä½¿ç”¨ç”±Mistral-Largeç”ŸæˆåˆæˆACTè½¬å½•æœ¬ï¼Œé‡‡ç”¨ä¸¤ç§ä¸åŒçš„æ–¹æ³•è®­ç»ƒäº†Llama-3.2-3b-Instructæ¨¡å‹ï¼Œå³ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œèµ”ç‡æ¯”ç‡ç­–ç•¥ä¼˜åŒ–ï¼ˆORPOï¼‰ï¼Œæ¯ç§æ–¹æ³•éƒ½å¸¦æœ‰å’Œä¸å¸¦æœ‰æ˜ç¡®çš„é“¾å¼æ€ç»´ï¼ˆCOTï¼‰æ¨ç†æ­¥éª¤ã€‚é€šè¿‡å°†è¿™äº›è®­ç»ƒåçš„æ¨¡å‹ä¸åŸºç¡€æŒ‡ä»¤æ¨¡å‹è¿›è¡Œæ¯”è¾ƒæ¥è¯„ä¼°æ€§èƒ½ã€‚è¿™äº›æ¨¡å‹åœ¨æ¨¡æ‹Ÿæ²»ç–—ä¸­è¿›è¡Œè¯„ä¼°ï¼Œé€šè¿‡ACTä¿çœŸåº¦åº¦é‡ï¼ˆACT-FMï¼‰å’Œå’¨è¯¢å¸ˆåŒç†å¿ƒé‡è¡¨ï¼ˆTESï¼‰å¯¹æ€§èƒ½è¿›è¡Œå®šé‡è¯„ä¼°ï¼Œè¯„ä¼°è€…æ˜¯ç”±äººç±»è¯„ä¼°è¿›è¡Œå¾®è°ƒè¿‡çš„LLMè¯„åˆ¤å‘˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé€šè¿‡ORPOè®­ç»ƒçš„æ¨¡å‹åœ¨ACTä¿çœŸåº¦æ–¹é¢æ˜¾è‘—ä¼˜äºSFTå’ŒæŒ‡ä»¤æ¨¡å‹ï¼ˆÏ‡Â²ï¼ˆ5ï¼‰&#x3D;185.15ï¼Œp &lt; .001ï¼‰ï¼Œå¹¶ä¸”åœ¨æ²»ç–—åŒç†å¿ƒæ–¹é¢ä¹Ÿè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼ˆÏ‡Â²ï¼ˆ5ï¼‰&#x3D;140.37ï¼Œp &lt; .001ï¼‰ã€‚COTçš„å½±å“æ˜¯æœ‰æ¡ä»¶çš„ï¼Œå› ä¸ºå®ƒå¯¹SFTæ¨¡å‹æä¾›äº†æ˜¾è‘—çš„å¥½å¤„ï¼ŒACT-FMå¾—åˆ†å¹³å‡æé«˜äº†2.68åˆ†ï¼ˆp &lt; .001ï¼‰ï¼Œè€Œå¯¹æ›´é«˜çº§çš„ORPOæˆ–æŒ‡ä»¤å¾®è°ƒæ¨¡å‹æ²¡æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚æˆ‘ä»¬è®¤ä¸ºORPOçš„ä¼˜è¶Šæ€§æºäºå…¶å­¦ä¹ æ²»ç–—è¿‡ç¨‹è€Œéæ¨¡ä»¿å†…å®¹çš„èƒ½åŠ›ï¼Œè¿™æ˜¯ACTçš„ä¸€ä¸ªå…³é”®æ–¹é¢ï¼Œè€ŒCOTåˆ™ä½œä¸ºä»…é€šè¿‡æ¨¡ä»¿è®­ç»ƒçš„æ¨¡å‹çš„å¿…è¦æ”¯æ¶ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œåå¥½å¯¹é½çš„ç­–ç•¥ä¼˜åŒ–å¯ä»¥æœ‰æ•ˆåœ°åœ¨å°è§„æ¨¡LLMä¸­æ¤å…¥ACTèƒ½åŠ›ï¼Œè€Œæ˜ç¡®æ¨ç†çš„å®ç”¨æ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºåŸºæœ¬çš„è®­ç»ƒæ¨¡å¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.09712v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†æ¥å—ä¸æ‰¿è¯ºç–—æ³•ï¼ˆACTï¼‰åœ¨å°å‹å¼€æ”¾æƒé‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„åº”ç”¨æ•ˆæœã€‚å®éªŒé‡‡ç”¨åˆæˆACTè¯­éŸ³è½¬å½•æœ¬è®­ç»ƒLLMæ¨¡å‹ï¼Œå¹¶åˆ†åˆ«ä½¿ç”¨ä¸¤ç§ä¸åŒçš„è®­ç»ƒæ–¹æ³•â€”â€”ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œèµ”ç‡æ¯”ç­–ç•¥ä¼˜åŒ–ï¼ˆORPOï¼‰ï¼ŒåŒæ—¶æ¢è®¨äº†æ˜¾å¼é“¾å¼æ€ç»´ï¼ˆCOTï¼‰æ¨ç†çš„ä½œç”¨ã€‚ç»“æœæ˜¾ç¤ºï¼ŒORPOè®­ç»ƒæ¨¡å‹åœ¨ACTå¿ è¯šåº¦å’Œæ²»ç–—åŒç†å¿ƒæ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒCOTçš„å½±å“å–å†³äºè®­ç»ƒèŒƒå¼ï¼Œå¯¹SFTæ¨¡å‹æœ‰æ˜¾è‘—æ”¹å–„ä½œç”¨ï¼Œä½†å¯¹æ›´é«˜çº§çš„ORPOæˆ–æŒ‡ä»¤è°ƒæ•´æ¨¡å‹åˆ™æ²¡æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚ç ”ç©¶è®¤ä¸ºï¼ŒORPOèƒ½å¤Ÿå­¦ä¹ æ²»ç–—è¿‡ç¨‹è€Œéå•çº¯æ¨¡ä»¿å†…å®¹ï¼Œè¿™æ˜¯ACTçš„æ ¸å¿ƒè¦ç´ ï¼›è€ŒCOTå¯¹äºä»…é€šè¿‡æ¨¡ä»¿è®­ç»ƒçš„æ¨¡å‹åˆ™æ˜¯å¿…è¦çš„æ”¯æ’‘ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œåå¥½å¯¹é½ç­–ç•¥ä¼˜åŒ–å¯ä»¥æœ‰æ•ˆèµ‹äºˆå°å‹LLMæ‰§è¡ŒACTçš„èƒ½åŠ›ï¼Œè€Œæ˜¾å¼æ¨ç†çš„å®ç”¨æ€§é«˜åº¦ä¾èµ–äºåŸºç¡€è®­ç»ƒèŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ACTæ˜¯ä¸€ç§æ–°å…´æœ‰æ•ˆçš„è®¤çŸ¥è¡Œä¸ºç–—æ³•ï¼Œæœ¬ç ”ç©¶æ¢è®¨äº†å…¶åœ¨å°å‹LLMæ¨¡å‹ä¸­çš„åº”ç”¨æ•ˆæœã€‚</li>
<li>é‡‡ç”¨åˆæˆACTè¯­éŸ³è½¬å½•æœ¬å¯¹LLMæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œé‡‡ç”¨ä¸¤ç§è®­ç»ƒæ–¹æ³•ï¼šç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œèµ”ç‡æ¯”ç­–ç•¥ä¼˜åŒ–ï¼ˆORPOï¼‰ã€‚</li>
<li>å¼•å…¥æ˜¾å¼é“¾å¼æ€ç»´ï¼ˆCOTï¼‰æ¨ç†æ­¥éª¤æ¥è¯„ä¼°å…¶å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ã€‚</li>
<li>ORPOè®­ç»ƒæ¨¡å‹åœ¨ACTå¿ è¯šåº¦å’Œæ²»ç–—åŒç†å¿ƒæ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>COTçš„ä½œç”¨å–å†³äºè®­ç»ƒèŒƒå¼ï¼Œæœ‰åŠ©äºæ”¹å–„SFTæ¨¡å‹çš„è¡¨ç°ï¼Œä½†å¯¹é«˜çº§æ¨¡å‹æ²¡æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</li>
<li>ORPOèƒ½å¤Ÿå­¦ä¹ æ²»ç–—è¿‡ç¨‹è€Œéå•çº¯æ¨¡ä»¿å†…å®¹ï¼Œè¿™æ˜¯ACTçš„æ ¸å¿ƒè¦ç´ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.09712">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09712v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09712v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09712v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09712v2/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09712v2/page_4_2.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09712v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Clip-Your-Sequences-Fairly-Enforcing-Length-Fairness-for-Sequence-Level-RL"><a href="#Clip-Your-Sequences-Fairly-Enforcing-Length-Fairness-for-Sequence-Level-RL" class="headerlink" title="Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level   RL"></a>Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level   RL</h2><p><strong>Authors:Hanyi Mao, Quanjia Xiao, Lei Pang, Haixiao Liu</strong></p>
<p>We propose FSPO (Fair Sequence Policy Optimization), a sequence-level reinforcement learning method for LLMs that enforces length-fair clipping on the importance-sampling (IS) weight. We study RL methods with sequence-level IS and identify a mismatch when PPO&#x2F;GRPO-style clipping is transplanted to sequences: a fixed clip range systematically reweights short vs.\ long responses, distorting the optimization direction. FSPO introduces a simple remedy: we clip the sequence log-IS ratio with a band that scales as $\sqrt{L}$. Theoretically, we formalize length fairness via a Length Reweighting Error (LRE) and prove that small LRE yields a cosine directional guarantee between the clipped and true updates. Empirically, FSPO flattens clip rates across length bins, stabilizes training, and outperforms all baselines across multiple evaluation datasets on Qwen3-8B-Base model. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†FSPOï¼ˆå…¬å¹³åºåˆ—ç­–ç•¥ä¼˜åŒ–ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå®ƒå¯¹é‡è¦æ€§é‡‡æ ·ï¼ˆISï¼‰æƒé‡æ‰§è¡Œé•¿åº¦å…¬å¹³çš„è£å‰ªã€‚æˆ‘ä»¬ç ”ç©¶äº†å¸¦æœ‰åºåˆ—çº§ISçš„RLæ–¹æ³•ï¼Œå¹¶è¯†åˆ«å‡ºåœ¨å°†PPO&#x2F;GRPOé£æ ¼è£å‰ªç§»æ¤åˆ°åºåˆ—æ—¶çš„ä¸åŒ¹é…é—®é¢˜ï¼šå›ºå®šçš„è£å‰ªèŒƒå›´ç³»ç»Ÿåœ°é‡æ–°è°ƒæ•´çŸ­åºåˆ—å’Œé•¿åºåˆ—çš„æƒé‡ï¼Œæ‰­æ›²äº†ä¼˜åŒ–æ–¹å‘ã€‚FSPOå¼•å…¥äº†ä¸€ç§ç®€å•çš„è¡¥æ•‘æªæ–½ï¼šæˆ‘ä»¬ç”¨éš$\sqrt{L}$ç¼©æ”¾çš„é¢‘å¸¦è£å‰ªåºåˆ—å¯¹æ•°ISæ¯”ç‡ã€‚ä»ç†è®ºä¸Šè®²ï¼Œæˆ‘ä»¬é€šè¿‡é•¿åº¦åŠ æƒè¯¯å·®ï¼ˆLREï¼‰æ­£å¼åŒ–é•¿åº¦å…¬å¹³æ€§ï¼Œå¹¶è¯æ˜è¾ƒå°çš„LREå¯ä»¥åœ¨è£å‰ªæ›´æ–°å’ŒçœŸå®æ›´æ–°ä¹‹é—´æä¾›ä½™å¼¦æ–¹å‘ä¿è¯ã€‚åœ¨ç»éªŒä¸Šï¼ŒFSPOåœ¨ä¸åŒé•¿åº¦åŒºé—´å†…å¹³å‡äº†è£å‰ªç‡ï¼Œç¨³å®šäº†è®­ç»ƒï¼Œå¹¶åœ¨Qwen3-8B-Baseæ¨¡å‹ä¸Šçš„å¤šä¸ªè¯„ä¼°æ•°æ®é›†ä¸Šè¶…è¶Šäº†æ‰€æœ‰åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.09177v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>æå‡ºä¸€ç§åä¸ºFSPOçš„åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºLLMsã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹é‡è¦æ€§é‡‡æ ·ï¼ˆISï¼‰æƒé‡å®æ–½é•¿åº¦å…¬å¹³è£å‰ªï¼Œè§£å†³äº†åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸­çš„å›ºå®šè£å‰ªèŒƒå›´é—®é¢˜ã€‚ç†è®ºæ–¹é¢ï¼Œé€šè¿‡é•¿åº¦é‡æ–°åŠ æƒè¯¯å·®ï¼ˆLREï¼‰æ­£å¼åŒ–é•¿åº¦å…¬å¹³æ€§ï¼Œå¹¶è¯æ˜å°LREå¯ä»¥åœ¨å‰ªè¾‘å’ŒçœŸå®æ›´æ–°ä¹‹é—´æä¾›ä½™å¼¦æ–¹å‘ä¿è¯ã€‚å®éªŒè¡¨æ˜ï¼ŒFSPOåœ¨ä¸åŒé•¿åº¦åŒºé—´å†…å¹³è¡¡å‰ªè¾‘ç‡ï¼Œç¨³å®šè®­ç»ƒï¼Œå¹¶åœ¨Qwen3-8B-Baseæ¨¡å‹ä¸Šä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>FSPOæ˜¯ä¸€ç§é’ˆå¯¹LLMsçš„åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚</li>
<li>FSPOè§£å†³äº†å›ºå®šè£å‰ªèŒƒå›´é—®é¢˜ï¼Œé€šè¿‡å®æ–½é•¿åº¦å…¬å¹³è£å‰ªæ¥ä¼˜åŒ–é‡è¦æ€§é‡‡æ ·æƒé‡ã€‚</li>
<li>ç†è®ºæ–¹é¢ï¼Œé€šè¿‡é•¿åº¦é‡æ–°åŠ æƒè¯¯å·®ï¼ˆLREï¼‰æ­£å¼åŒ–é•¿åº¦å…¬å¹³æ€§ã€‚</li>
<li>å°LREå¯ä»¥åœ¨å‰ªè¾‘å’ŒçœŸå®æ›´æ–°ä¹‹é—´æä¾›ä½™å¼¦æ–¹å‘ä¿è¯ã€‚</li>
<li>FSPOåœ¨ä¸åŒé•¿åº¦åŒºé—´å†…å¹³è¡¡å‰ªè¾‘ç‡ã€‚</li>
<li>FSPOç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>FSPOåœ¨Qwen3-8B-Baseæ¨¡å‹ä¸Šçš„è¡¨ç°ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.09177">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09177v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.09177v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents"><a href="#WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents" class="headerlink" title="WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents"></a>WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents</h2><p><strong>Authors:Junteng Liu, Yunji Li, Chi Zhang, Jingyang Li, Aili Chen, Ke Ji, Weiyu Cheng, Zijia Wu, Chengyu Du, Qidi Xu, Jiayuan Song, Zhengmao Zhu, Wenhu Chen, Pengyu Zhao, Junxian He</strong></p>
<p>The paradigm of Large Language Models (LLMs) has increasingly shifted toward agentic applications, where web browsing capabilities are fundamental for retrieving information from diverse online sources. However, existing open-source web agents either demonstrate limited information-seeking abilities on complex tasks or lack transparent implementations. In this work, we identify that the key challenge lies in the scarcity of challenging data for information seeking. To address this limitation, we introduce WebExplorer: a systematic data generation approach using model-based exploration and iterative, long-to-short query evolution. This method creates challenging query-answer pairs that require multi-step reasoning and complex web navigation. By leveraging our curated high-quality dataset, we successfully develop advanced web agent WebExplorer-8B through supervised fine-tuning followed by reinforcement learning. Our model supports 128K context length and up to 100 tool calling turns, enabling long-horizon problem solving. Across diverse information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able to effectively search over an average of 16 turns after RL training, achieving higher accuracy than WebSailor-72B on BrowseComp-en&#x2F;zh and attaining the best performance among models up to 100B parameters on WebWalkerQA and FRAMES. Beyond these information-seeking tasks, our model also achieves strong generalization on the HLE benchmark even though it is only trained on knowledge-intensive QA data. These results highlight our approach as a practical path toward long-horizon web agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èŒƒå¼è¶Šæ¥è¶Šè½¬å‘ä»£ç†åº”ç”¨ç¨‹åºï¼Œå…¶ä¸­ç½‘é¡µæµè§ˆèƒ½åŠ›æ˜¯ä»å„ç§åœ¨çº¿æºæ£€ç´¢ä¿¡æ¯çš„åŸºç¡€ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¼€æºç½‘ç»œä»£ç†è¦ä¹ˆåœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæœ‰é™çš„ä¿¡æ¯æœç´¢èƒ½åŠ›ï¼Œè¦ä¹ˆç¼ºä¹é€æ˜çš„å®ç°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç¡®å®šäº†å…³é”®æŒ‘æˆ˜åœ¨äºä¿¡æ¯æœç´¢ä¸­ç¼ºä¹æŒ‘æˆ˜æ€§æ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æ¨å‡ºäº†WebExplorerï¼šä¸€ç§åŸºäºæ¨¡å‹æ¢ç´¢å’Œç³»ç»Ÿç”Ÿæˆæ•°æ®çš„æ–¹æ³•ï¼Œä»¥åŠä»é•¿åˆ°çŸ­çš„è¿­ä»£æŸ¥è¯¢æ¼”åŒ–ã€‚è¿™ç§æ–¹æ³•å¯ä»¥åˆ›å»ºéœ€è¦å¤šæ­¥éª¤æ¨ç†å’Œå¤æ‚ç½‘ç»œå¯¼èˆªçš„æŒ‘æˆ˜æ€§æŸ¥è¯¢ç­”æ¡ˆå¯¹ã€‚é€šè¿‡åˆ©ç”¨æˆ‘ä»¬ç²¾å¿ƒåˆ¶ä½œçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å¼€å‘äº†å…ˆè¿›çš„ç½‘ç»œä»£ç†WebExplorer-8Bï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒåç»“åˆå¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬çš„æ¨¡å‹æ”¯æŒ12.8ä¸‡å­—çš„è¯­å¢ƒé•¿åº¦å’Œé«˜è¾¾10ä¸‡æ¬¡å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œèƒ½å¤Ÿå®ç°é•¿æœŸè§„åˆ’é—®é¢˜æ±‚è§£ã€‚åœ¨å„ç§ä¿¡æ¯æœç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒWebExplorer-8Båœ¨å…¶è§„æ¨¡ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½œä¸ºè§„æ¨¡ä¸º8Bçš„æ¨¡å‹ï¼ŒWebExplorer-8Båœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒåèƒ½å¤Ÿåœ¨å¹³å‡16è½®å¯¹è¯ä¸­è¿›è¡Œæœ‰æ•ˆæœç´¢ï¼Œå…¶åœ¨BrowseComp-en&#x2F;zhä¸Šçš„å‡†ç¡®æ€§é«˜äºWebSailor-72Bï¼Œå¹¶åœ¨WebWalkerQAå’ŒFRAMESä¸Šè¾¾åˆ°äº†è¿„ä»Šä¸ºæ­¢å‚æ•°ä¸è¶…è¿‡100Bæ¨¡å‹çš„æœ€å¥½è¡¨ç°ã€‚é™¤äº†è¿™äº›ä¿¡æ¯æœç´¢ä»»åŠ¡ä¹‹å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨HLEåŸºå‡†æµ‹è¯•ä¸Šä¹Ÿå®ç°äº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œå°½ç®¡å®ƒä»…é’ˆå¯¹çŸ¥è¯†å¯†é›†å‹é—®ç­”æ•°æ®è¿›è¡Œäº†è®­ç»ƒã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†æˆ‘ä»¬åœ¨æ„å»ºå…·æœ‰é•¿è¿œè§†é‡çš„ç½‘ç»œä»£ç†æ–¹é¢çš„å®ç”¨é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06501v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æœç€ä»£ç†åº”ç”¨è½¬å˜è¿‡ç¨‹ä¸­çš„ä¸€é¡¹é‡è¦è¿›å±•ã€‚æ–‡ç« æŒ‡å‡ºä¿¡æ¯æ£€ç´¢ä¸­çš„å…³é”®æŒ‘æˆ˜åœ¨äºç¼ºä¹æŒ‘æˆ˜æ€§çš„æ•°æ®ï¼Œäºæ˜¯æå‡ºäº†ä¸€ç§åä¸ºWebExplorerçš„ç³»ç»Ÿæ€§æ•°æ®ç”Ÿæˆæ–¹æ³•ã€‚é€šè¿‡åˆ©ç”¨ç²¾å¿ƒåˆ¶ä½œçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œç»è¿‡ç›‘ç£å¾®è°ƒåŠå¼ºåŒ–å­¦ä¹ åï¼ŒæˆåŠŸå¼€å‘å‡ºWebExplorer-8Bé«˜çº§ç½‘ç»œä»£ç†æ¨¡å‹ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ”¯æŒé•¿æ—¶é—´èŒƒå›´çš„é—®é¢˜è§£å†³ï¼Œå¹¶ä¸”åœ¨å„ç§ä¿¡æ¯æœç´¢ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€æ–°çš„æœ€ä½³æ€§èƒ½ã€‚è¯¥æ¨¡å‹ä¸ä»…é€‚ç”¨äºä¿¡æ¯æ£€ç´¢ä»»åŠ¡ï¼Œè¿˜èƒ½å¤Ÿåœ¨å…¶ä»–é¢†åŸŸå®ç°å¼ºå¤§çš„æ³›åŒ–æ€§èƒ½ã€‚è¿™äº›ç»“æœå±•ç¤ºäº†å®ç°é•¿æœŸç½‘ç»œä»£ç†çš„å®é™…é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£æœç€ä»£ç†åº”ç”¨è½¬å˜ï¼Œç½‘é¡µæµè§ˆèƒ½åŠ›åœ¨ä¿¡æ¯æ£€ç´¢ä¸­å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚</li>
<li>å½“å‰å¼€æºç½‘ç»œä»£ç†åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„ä¿¡æ¯æœç´¢èƒ½åŠ›æœ‰é™ï¼Œç¼ºä¹é€æ˜å®æ–½æ–¹æ³•ã€‚</li>
<li>ä¿¡æ¯æ£€ç´¢çš„å…³é”®æŒ‘æˆ˜åœ¨äºç¼ºä¹æŒ‘æˆ˜æ€§çš„æ•°æ®ã€‚</li>
<li>WebExploreræ˜¯ä¸€ç§æ–°çš„ç³»ç»Ÿæ€§æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡æ¨¡å‹æ¢ç´¢å’ŒæŸ¥è¯¢çš„è¿­ä»£é•¿çŸ­å˜åŒ–æ¥åˆ›å»ºæŒ‘æˆ˜æ€§çš„æŸ¥è¯¢ç­”æ¡ˆå¯¹ã€‚</li>
<li>WebExplorer-8Bæ¨¡å‹é€šè¿‡ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ æˆåŠŸå¼€å‘ï¼Œæ”¯æŒé•¿è¾¾16è½®çš„æœç´¢å¯¹è¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.06501v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.06501v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.06501v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="CoT-Space-A-Theoretical-Framework-for-Internal-Slow-Thinking-via-Reinforcement-Learning"><a href="#CoT-Space-A-Theoretical-Framework-for-Internal-Slow-Thinking-via-Reinforcement-Learning" class="headerlink" title="CoT-Space: A Theoretical Framework for Internal Slow-Thinking via   Reinforcement Learning"></a>CoT-Space: A Theoretical Framework for Internal Slow-Thinking via   Reinforcement Learning</h2><p><strong>Authors:Zeyu Gan, Hao Yi, Yong Liu</strong></p>
<p>Reinforcement Learning (RL) has become a pivotal approach for enhancing the reasoning capabilities of Large Language Models (LLMs). However, a significant theoretical gap persists, as traditional token-level RL frameworks fail to align with the reasoning-level nature of complex, multi-step thought processes like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space, a novel theoretical framework that recasts LLM reasoning from a discrete token-prediction task to an optimization process within a continuous, reasoning-level semantic space. This shift in perspective serves as a conceptual bridge, revitalizing foundational principles from classical learning theory to analyze the unique dynamics of LLMs. By analyzing this process from both a noise perspective and a risk perspective, we demonstrate that the convergence to an optimal CoT length is a natural consequence of the fundamental trade-off between underfitting and overfitting. Furthermore, extensive experiments provide strong empirical validation for our theoretical findings. Our framework not only provides a coherent explanation for empirical phenomena such as overthinking but also offers a solid theoretical foundation to guide the future development of more effective and generalizable reasoning agents. We open-source our code at <a target="_blank" rel="noopener" href="https://github.com/ZyGan1999/CoT-Space">https://github.com/ZyGan1999/CoT-Space</a>. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›çš„é‡è¦æ–¹æ³•ã€‚ç„¶è€Œï¼Œä»å­˜åœ¨é‡å¤§çš„ç†è®ºç©ºç™½ï¼Œå› ä¸ºä¼ ç»Ÿçš„åŸºäºæ ‡è®°çš„RLæ¡†æ¶æ— æ³•ä¸å¤æ‚çš„å¤šæ­¥éª¤æ€ç»´è¿‡ç¨‹ï¼ˆå¦‚æ€ç»´é“¾ï¼‰çš„æ¨ç†çº§åˆ«ç›¸å¯¹åº”ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CoTç©ºé—´ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„ç†è®ºæ¡†æ¶ï¼Œå®ƒå°†LLMæ¨ç†ä»ç¦»æ•£æ ‡è®°é¢„æµ‹ä»»åŠ¡é‡æ–°å¡‘é€ ä¸ºè¿ç»­æ¨ç†çº§åˆ«è¯­ä¹‰ç©ºé—´ä¸­çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚è¿™ç§è§†è§’çš„è½¬å˜ä½œä¸ºæ¦‚å¿µæ¡¥æ¢ï¼Œä½¿æˆ‘ä»¬ä»ç»å…¸å­¦ä¹ ç†è®ºçš„åŸºæœ¬åŸç†é‡æ–°åˆ†æLLMçš„ç‹¬ç‰¹åŠ¨æ€ã€‚æˆ‘ä»¬ä»å™ªå£°å’Œé£é™©ä¸¤ä¸ªè§’åº¦åˆ†æäº†è¿™ä¸€è¿‡ç¨‹ï¼Œè¯æ˜äº†è¾¾åˆ°æœ€ä½³æ€ç»´é“¾é•¿åº¦çš„æ”¶æ•›æ˜¯æ¬ æ‹Ÿåˆå’Œè¿‡åº¦æ‹Ÿåˆä¹‹é—´åŸºæœ¬æƒè¡¡çš„è‡ªç„¶ç»“æœã€‚æ­¤å¤–ï¼Œå¤§é‡å®éªŒä¸ºæˆ‘ä»¬çš„ç†è®ºå‘ç°æä¾›äº†å¼ºæœ‰åŠ›çš„å®è¯éªŒè¯ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ä»…ä¸ºè¿‡åº¦æ€è€ƒç­‰ç»éªŒç°è±¡æä¾›äº†è¿è´¯çš„è§£é‡Šï¼Œè¿˜ä¸ºæœªæ¥å¼€å‘æ›´æœ‰æ•ˆå’Œå¯æ¨å¹¿çš„æ¨ç†ä»£ç†æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/ZyGan1999/CoT-Space%E5%85%AC%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/ZyGan1999/CoT-Spaceå…¬å¼€æºä»£ç ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04027v2">PDF</a> Preprint Edition</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ç„¶è€Œï¼Œç”±äºä¼ ç»ŸåŸºäºä»¤ç‰Œçš„RLæ¡†æ¶ä¸å¤æ‚çš„å¤šæ­¥éª¤æ¨ç†è¿‡ç¨‹ï¼ˆå¦‚é“¾å¼æ€ç»´ï¼‰åœ¨ç†è®ºå±‚é¢ä¸Šçš„ä¸åŒ¹é…ï¼Œä»å­˜åœ¨é‡å¤§ç†è®ºç©ºç™½ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†CoT-Spaceè¿™ä¸€æ–°å‹ç†è®ºæ¡†æ¶ï¼Œå°†LLMæ¨ç†ä»ç¦»æ•£ä»¤ç‰Œé¢„æµ‹ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºè¿ç»­æ¨ç†çº§è¯­ä¹‰ç©ºé—´å†…çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚ä»å™ªå£°å’Œé£é™©ä¸¤ä¸ªè§’åº¦è¿›è¡Œåˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†ä¼˜åŒ–é“¾å¼æ€ç»´é•¿åº¦çš„æ”¶æ•›æ˜¯é¿å…æ¬ æ‹Ÿåˆå’Œè¿‡åº¦æ‹Ÿåˆä¹‹é—´çš„åŸºæœ¬æƒè¡¡çš„è‡ªç„¶ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç†è®ºå¾—åˆ°äº†å¹¿æ³›å®éªŒçš„å¼ºå¤§å®è¯éªŒè¯ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ä»…ä¸ºè¿‡åº¦æ€è€ƒç­‰ç»éªŒç°è±¡æä¾›äº†è¿è´¯çš„è§£é‡Šï¼Œè€Œä¸”ä¸ºå¼€å‘æ›´æœ‰æ•ˆå’Œæ›´å…·é€šç”¨æ€§çš„æ¨ç†æ™ºèƒ½ä½“æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚æˆ‘ä»¬å·²ç»å°†æˆ‘ä»¬çš„ä»£ç å…¬å¼€å¼€æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ å¯¹äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›è‡³å…³é‡è¦ã€‚</li>
<li>ä¼ ç»ŸåŸºäºä»¤ç‰Œçš„RLæ¡†æ¶åœ¨åº”å¯¹å¤æ‚å¤šæ­¥éª¤æ¨ç†è¿‡ç¨‹æ—¶å­˜åœ¨ç†è®ºç©ºç™½ã€‚</li>
<li>CoT-Spaceæ¡†æ¶å°†LLMæ¨ç†ä»ç¦»æ•£ä»¤ç‰Œé¢„æµ‹ä»»åŠ¡è½¬å˜ä¸ºè¿ç»­æ¨ç†çº§è¯­ä¹‰ç©ºé—´å†…çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>ä»å™ªå£°å’Œé£é™©è§’åº¦åˆ†æï¼Œä¼˜åŒ–é“¾å¼æ€ç»´é•¿åº¦çš„æ”¶æ•›æ˜¯é¿å…æ¬ æ‹Ÿåˆå’Œè¿‡åº¦æ‹Ÿåˆæƒè¡¡çš„ç»“æœã€‚</li>
<li>å¹¿æ³›å®éªŒéªŒè¯äº†CoT-Spaceæ¡†æ¶çš„ç†è®ºå‘ç°ã€‚</li>
<li>æ¡†æ¶ä¸ºè¿‡åº¦æ€è€ƒç­‰ç»éªŒç°è±¡æä¾›äº†è¿è´¯çš„è§£é‡Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04027">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.04027v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.04027v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.04027v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.04027v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_R1_Reasoning/2509.04027v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-29/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-29/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-29/LLM/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-29\./crop_LLM/2504.20690v3/page_4_0.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-29  Assessing Classical Machine Learning and Transformer-based Approaches   for Detecting AI-Generated Research Text
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-28/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-28\./crop_Text-to-Motion/2409.01522v2/page_2_0.jpg" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-28  Lagrangian Motion Fields for Long-term Motion Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30055.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
