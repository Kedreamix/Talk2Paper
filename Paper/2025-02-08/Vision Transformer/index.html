<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Vision Transformer">
    <meta name="description" content="Vision Transformer 方向最新论文已更新，请持续关注 Update in 2025-02-08  A Self-supervised Multimodal Deep Learning Approach to Differentiate   Post-radiotherapy Progression from Pseudoprogression in Glioblastoma">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Vision Transformer | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-5743847eb38ad849752e6fa58f4c9419.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Vision Transformer</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Vision-Transformer/">
                                <span class="chip bg-color">Vision Transformer</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                Vision Transformer
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-08-更新"><a href="#2025-02-08-更新" class="headerlink" title="2025-02-08 更新"></a>2025-02-08 更新</h1><h2 id="A-Self-supervised-Multimodal-Deep-Learning-Approach-to-Differentiate-Post-radiotherapy-Progression-from-Pseudoprogression-in-Glioblastoma"><a href="#A-Self-supervised-Multimodal-Deep-Learning-Approach-to-Differentiate-Post-radiotherapy-Progression-from-Pseudoprogression-in-Glioblastoma" class="headerlink" title="A Self-supervised Multimodal Deep Learning Approach to Differentiate   Post-radiotherapy Progression from Pseudoprogression in Glioblastoma"></a>A Self-supervised Multimodal Deep Learning Approach to Differentiate   Post-radiotherapy Progression from Pseudoprogression in Glioblastoma</h2><p><strong>Authors:Ahmed Gomaa, Yixing Huang, Pluvio Stephan, Katharina Breininger, Benjamin Frey, Arnd Dörfler, Oliver Schnell, Daniel Delev, Roland Coras, Charlotte Schmitter, Jenny Stritzelberger, Sabine Semrau, Andreas Maier, Siming Bayer, Stephan Schönecker, Dieter H Heiland, Peter Hau, Udo S. Gaipl, Christoph Bert, Rainer Fietkau, Manuel A. Schmidt, Florian Putz</strong></p>
<p>Accurate differentiation of pseudoprogression (PsP) from True Progression (TP) following radiotherapy (RT) in glioblastoma (GBM) patients is crucial for optimal treatment planning. However, this task remains challenging due to the overlapping imaging characteristics of PsP and TP. This study therefore proposes a multimodal deep-learning approach utilizing complementary information from routine anatomical MR images, clinical parameters, and RT treatment planning information for improved predictive accuracy. The approach utilizes a self-supervised Vision Transformer (ViT) to encode multi-sequence MR brain volumes to effectively capture both global and local context from the high dimensional input. The encoder is trained in a self-supervised upstream task on unlabeled glioma MRI datasets from the open BraTS2021, UPenn-GBM, and UCSF-PDGM datasets to generate compact, clinically relevant representations from FLAIR and T1 post-contrast sequences. These encoded MR inputs are then integrated with clinical data and RT treatment planning information through guided cross-modal attention, improving progression classification accuracy. This work was developed using two datasets from different centers: the Burdenko Glioblastoma Progression Dataset (n &#x3D; 59) for training and validation, and the GlioCMV progression dataset from the University Hospital Erlangen (UKER) (n &#x3D; 20) for testing. The proposed method achieved an AUC of 75.3%, outperforming the current state-of-the-art data-driven approaches. Importantly, the proposed approach relies on readily available anatomical MRI sequences, clinical data, and RT treatment planning information, enhancing its clinical feasibility. The proposed approach addresses the challenge of limited data availability for PsP and TP differentiation and could allow for improved clinical decision-making and optimized treatment plans for GBM patients. </p>
<blockquote>
<p>对胶质母细胞瘤（GBM）患者在放疗（RT）后的假性进展（PsP）和真性进展（TP）的准确区分对于制定最佳治疗方案至关重要。然而，由于PsP和TP的成像特征重叠，这一任务仍然具有挑战性。因此，本研究提出了一种多模态深度学习的方法，该方法利用常规解剖MRI图像、临床参数和RT治疗计划信息的互补信息进行更准确的预测。该方法利用自监督的Vision Transformer（ViT）对多序列MR脑容积进行编码，以有效地从高维输入中捕获全局和局部上下文。编码器在无标签的胶质母细胞瘤MRI数据集（来自公开可用的BraTS2021、UPenn-GBM和UCSF-PDGM数据集）上进行自监督上游任务训练，从FLAIR和T1增强序列生成紧凑且临床相关的表示。这些编码后的MR输入然后与临床数据和RT治疗计划信息通过引导跨模态注意力进行整合，提高了进展分类的准确性。这项工作使用了来自不同中心的两个数据集进行开发和测试：使用Burdenko胶质母细胞瘤进展数据集（n&#x3D;59）进行训练和验证，使用来自Erlangen大学医院（UKER）的GlioCMV进展数据集（n&#x3D;20）进行测试。所提出的方法达到了75.3%的AUC，优于当前最先进的数据驱动方法。重要的是，所提出的方法依赖于可获得的解剖MRI序列、临床数据和RT治疗计划信息，增强了其临床可行性。所提出的方法解决了PsP和TP鉴别中数据有限性的挑战，并可能有助于改进胶质母细胞瘤患者的临床决策和优化的治疗方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03999v1">PDF</a> </p>
<p><strong>摘要</strong><br>在放射治疗后的胶质母细胞瘤患者中，对假性进展（PsP）与真实进展（TP）的准确鉴别对于制定最佳治疗方案至关重要。然而，由于PsP和TP的成像特征重叠，这一任务仍然具有挑战性。因此，本研究提出了一种多模态深度学习的方法，利用常规解剖MR图像、临床参数和放射治疗计划信息的互补信息，以提高预测准确性。该方法使用自监督的Vision Transformer（ViT）对多序列MR脑容积进行编码，以有效地捕捉高维输入的全局和局部上下文。编码器在未经标记的胶质母细胞瘤MRI数据集（来自开放的BraTS2021、UPenn-GBM和UCSF-PDGM数据集）上进行自监督上游任务训练，从FLAIR和T1增强序列生成紧凑且临床相关的表示。这些编码的MR输入然后与临床数据和放射治疗计划信息通过引导跨模态注意力进行整合，提高进展分类的准确性。该研究使用了来自不同中心的两个数据集：Burdenko胶质母细胞瘤进展数据集（n&#x3D;59）用于训练和验证，以及Erlangen大学医院（UKER）的GlioCMV进展数据集（n&#x3D;20）用于测试。所提出的方法达到了75.3%的AUC，优于当前数据驱动方法的最新水平。重要的是，该方法依赖于易于获得的解剖MRI序列、临床数据和放射治疗计划信息，增强了其临床可行性。所提出的方法解决了PsP和TP鉴别中数据有限性的挑战，并能改善临床决策和优化胶质母细胞瘤患者的治疗计划。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>区分假性进展（PsP）和真实进展（TP）对于胶质母细胞瘤患者的最优治疗计划至关重要。</li>
<li>研究提出了一种多模态深度学习的方法，结合常规解剖MR图像、临床参数和放射治疗计划信息，以提高预测准确性。</li>
<li>利用自监督的Vision Transformer（ViT）进行图像编码，捕捉全局和局部上下文信息。</li>
<li>所提出的方法在Burdenko和GlioCMV数据集上进行了验证，并取得了较高的AUC值。</li>
<li>该方法超越了当前的数据驱动方法，显示出其优越性。</li>
<li>所提出的方法依赖于易获得的解剖MRI序列、临床数据和放疗计划信息，具有临床可行性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03999">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2aa27e290ccdf32c83431b52514193b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-deae04eaf91ab9a957a6b862f66d5d2c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e1a7e0c2842182a6551a698afa769666.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a26c5890a541d4f4b51e9f76a82162e9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-05df6e3720dc54e17ff2254d3c3112f5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="A-Retrospective-Systematic-Study-on-Hierarchical-Sparse-Query-Transformer-assisted-Ultrasound-Screening-for-Early-Hepatocellular-Carcinoma"><a href="#A-Retrospective-Systematic-Study-on-Hierarchical-Sparse-Query-Transformer-assisted-Ultrasound-Screening-for-Early-Hepatocellular-Carcinoma" class="headerlink" title="A Retrospective Systematic Study on Hierarchical Sparse Query   Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma"></a>A Retrospective Systematic Study on Hierarchical Sparse Query   Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma</h2><p><strong>Authors:Chaoyin She, Ruifang Lu, Danni He, Jiayi Lv, Yadan Lin, Meiqing Cheng, Hui Huang, Lida Chen, Wei Wang, Qinghua Huang</strong></p>
<p>Hepatocellular carcinoma (HCC) ranks as the third leading cause of cancer-related mortality worldwide, with early detection being crucial for improving patient survival rates. However, early screening for HCC using ultrasound suffers from insufficient sensitivity and is highly dependent on the expertise of radiologists for interpretation. Leveraging the latest advancements in artificial intelligence (AI) in medical imaging, this study proposes an innovative Hierarchical Sparse Query Transformer (HSQformer) model that combines the strengths of Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasound screening. The HSQformer leverages sparse latent space representations to capture hierarchical details at various granularities without the need for complex adjustments, and adopts a modular, plug-and-play design philosophy, ensuring the model’s versatility and ease of use. The HSQformer’s performance was rigorously tested across three distinct clinical scenarios: single-center, multi-center, and high-risk patient testing. In each of these settings, it consistently outperformed existing state-of-the-art models, such as ConvNext and SwinTransformer. Notably, the HSQformer even matched the diagnostic capabilities of senior radiologists and comprehensively surpassed those of junior radiologists. The experimental results from this study strongly demonstrate the effectiveness and clinical potential of AI-assisted tools in HCC screening. The full code is available at <a target="_blank" rel="noopener" href="https://github.com/Asunatan/HSQformer">https://github.com/Asunatan/HSQformer</a>. </p>
<blockquote>
<p>肝细胞癌（HCC）是全球癌症死亡率的第三大原因，早期发现对于提高患者存活率至关重要。然而，使用超声进行HCC的早期筛查存在灵敏度不足的问题，并且高度依赖于放射科医生的解释。本研究利用医疗成像领域中人工智能（AI）的最新进展，提出了一种创新的分层稀疏查询转换器（HSQformer）模型。该模型结合了卷积神经网络（CNN）和视觉转换器（ViT）的优点，旨在提高超声筛查中HCC诊断的准确性。HSQformer利用稀疏潜在空间表示来捕获不同粒度的层次细节，无需进行复杂的调整，并采用了模块化、即插即用的设计思想，确保模型的通用性和易用性。HSQformer的性能在三种不同的临床情景中进行了严格测试：单中心、多中心和高危患者测试。在这三种环境中，它始终优于现有的最新模型，如ConvNext和SwinTransformer。值得注意的是，HSQformer甚至达到了资深放射科医生的诊断水平，并全面超越了初级放射科医生的水平。本研究的实验结果强烈证明了AI辅助工具在HCC筛查中的有效性和临床潜力。相关代码已发布在<a target="_blank" rel="noopener" href="https://github.com/Asunatan/HSQformer">https://github.com/Asunatan/HSQformer</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03772v1">PDF</a> </p>
<p><strong>Summary</strong><br>肝癌是世界上第三大癌症致死原因，早期检测对于提高患者生存率至关重要。本研究提出一种结合卷积神经网络（CNN）和视觉变压器（ViT）优势的分层稀疏查询变压器（HSQformer）模型，利用人工智能增强肝癌超声筛查诊断的准确性。HSQformer采用稀疏潜在空间表示捕捉不同粒度的层次细节，无需复杂调整，采用模块化设计，确保模型的通用性和易用性。在单中心、多中心和高危患者测试等三种不同临床场景中，其性能均优于现有最先进的模型，如ConvNext和SwinTransformer。此外，HSQformer的诊断能力与资深放射学家相匹配，并超越了初级放射学家的水平。该研究实验结果强烈证明AI辅助工具在肝癌筛查中的有效性和临床潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>肝癌是世界上第三大癌症致死原因，早期检测对改善患者生存率至关重要。</li>
<li>当前超声筛查肝癌存在灵敏度不足和依赖放射学家解读的问题。</li>
<li>本研究提出了一种名为HSQformer的新型模型，结合CNN和ViT的优势来增强肝癌诊断的准确性。</li>
<li>HSQformer利用稀疏潜在空间表示捕捉层次细节，设计模块化，易于使用。</li>
<li>HSQformer在不同临床场景中性能优越，优于现有最先进的模型。</li>
<li>HSQformer的诊断能力与资深放射学家相匹配，并超越了初级放射学家的水平。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03772">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ae4e5716feb1a868c0fe34b824a296d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6f0d9aa72043a2dfcd13362f70087c51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cb214dfe5c713968760dd7cb748cd2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b04229b8920d33f278ffd0d0f6b58d37.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Scaling-Laws-in-Patchification-An-Image-Is-Worth-50-176-Tokens-And-More"><a href="#Scaling-Laws-in-Patchification-An-Image-Is-Worth-50-176-Tokens-And-More" class="headerlink" title="Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More"></a>Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More</h2><p><strong>Authors:Feng Wang, Yaodong Yu, Guoyizhe Wei, Wei Shao, Yuyin Zhou, Alan Yuille, Cihang Xie</strong></p>
<p>Since the introduction of Vision Transformer (ViT), patchification has long been regarded as a de facto image tokenization approach for plain visual architectures. By compressing the spatial size of images, this approach can effectively shorten the token sequence and reduce the computational cost of ViT-like plain architectures. In this work, we aim to thoroughly examine the information loss caused by this patchification-based compressive encoding paradigm and how it affects visual understanding. We conduct extensive patch size scaling experiments and excitedly observe an intriguing scaling law in patchification: the models can consistently benefit from decreased patch sizes and attain improved predictive performance, until it reaches the minimum patch size of 1x1, i.e., pixel tokenization. This conclusion is broadly applicable across different vision tasks, various input scales, and diverse architectures such as ViT and the recent Mamba models. Moreover, as a by-product, we discover that with smaller patches, task-specific decoder heads become less critical for dense prediction. In the experiments, we successfully scale up the visual sequence to an exceptional length of 50,176 tokens, achieving a competitive test accuracy of 84.6% with a base-sized model on the ImageNet-1k benchmark. We hope this study can provide insights and theoretical foundations for future works of building non-compressive vision models. Code is available at <a target="_blank" rel="noopener" href="https://github.com/wangf3014/Patch_Scaling">https://github.com/wangf3014/Patch_Scaling</a>. </p>
<blockquote>
<p>自从引入Vision Transformer（ViT）以来，切块化长期以来一直被视为普通视觉架构的图像令牌化方法的默认选择。通过压缩图像的空间尺寸，这种方法可以有效地缩短令牌序列并降低类似ViT的普通架构的计算成本。在这项工作中，我们旨在彻底检查基于切块化的压缩编码范式所引起的信息损失以及它对视觉理解的影响。我们进行了广泛的切块大小缩放实验，并观察到切块化中的有趣缩放定律：模型可以持续地从减小切块大小中受益，并获得改进的预测性能，直到达到最小的切块大小1x1，即像素令牌化。这一结论适用于不同的视觉任务、各种输入规模和多样化的架构，如ViT和最近的Mamba模型。此外，作为副产品，我们发现使用较小的切块时，特定任务的解码器头对于密集预测变得不那么关键。在实验中，我们成功地将视觉序列放大到50,176个令牌的异常长度，在ImageNet-1k基准测试上实现了具有竞争力的测试准确率84.6%。我们希望这项研究能为构建非压缩视觉模型提供见解和理论基础。代码可访问<a target="_blank" rel="noopener" href="https://github.com/wangf3014/Patch_Scaling%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/wangf3014/Patch_Scaling获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03738v1">PDF</a> </p>
<p><strong>摘要</strong><br>     研究了Vision Transformer中图像分片化的信息损失及其对视觉理解的影响。实验发现分片大小缩放规律：随着补丁尺寸的减小，模型性能持续改善，直至达到最小补丁尺寸，即像素标记化。该结论适用于不同的视觉任务、输入规模和架构。此外，研究发现较小的补丁使特定任务的解码头对于密集预测变得不那么关键。实验中将视觉序列扩展到异常长的标记序列长度，并在ImageNet-1k基准测试中实现了具有竞争力的准确率。本研究为构建非压缩视觉模型提供了见解和理论基础。</p>
<p><strong>要点掌握</strong></p>
<ol>
<li>Vision Transformer中普遍采用图像分片化作为图像标记化方法。</li>
<li>图像分片化通过压缩图像的空间尺寸来缩短令牌序列并降低计算成本。</li>
<li>研究深入探讨了分片化引起的信息损失及其对视觉理解的影响。</li>
<li>实验观察到分片大小的缩放规律：随着补丁尺寸的减小，模型性能持续提高。</li>
<li>这一结论适用于各种视觉任务、不同输入规模和架构。</li>
<li>在较小的补丁下，特定任务的解码头对密集预测的重要性降低。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03738">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d9563d8934bfb80fa37d6f391a8d25e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0090c8ea27317ceff4737e14be3fbc0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba2c636f4fb6d21d2be4293a0d4ce1b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e54a9f788850db92ed6d02499c5d413e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Kronecker-Mask-and-Interpretive-Prompts-are-Language-Action-Video-Learners"><a href="#Kronecker-Mask-and-Interpretive-Prompts-are-Language-Action-Video-Learners" class="headerlink" title="Kronecker Mask and Interpretive Prompts are Language-Action Video   Learners"></a>Kronecker Mask and Interpretive Prompts are Language-Action Video   Learners</h2><p><strong>Authors:Jingyi Yang, Zitong Yu, Xiuming Ni, Jia He, Hui Li</strong></p>
<p>Contrastive language-image pretraining (CLIP) has significantly advanced image-based vision learning. A pressing topic subsequently arises: how can we effectively adapt CLIP to the video domain? Recent studies have focused on adjusting either the textual or visual branch of CLIP for action recognition. However, we argue that adaptations of both branches are crucial. In this paper, we propose \textbf{CLAVER}: a \textbf{C}ontrastive \textbf{L}anguage-\textbf{A}ction \textbf{V}ideo Learn\textbf{er}, designed to shift CLIP’s focus from the alignment of static visual objects and concrete nouns to the alignment of dynamic action behaviors and abstract verbs. Specifically, we introduce a novel Kronecker mask attention for temporal modeling. Our tailored Kronecker mask offers three benefits 1) it expands the temporal receptive field for each token, 2) it serves as an effective spatiotemporal heterogeneity inductive bias, mitigating the issue of spatiotemporal homogenization, and 3) it can be seamlessly plugged into transformer-based models. Regarding the textual branch, we leverage large language models to generate diverse, sentence-level and semantically rich interpretive prompts of actions, which shift the model’s focus towards the verb comprehension. Extensive experiments on various benchmarks and learning scenarios demonstrate the superiority and generality of our approach. The code will be available soon. </p>
<blockquote>
<p>对比语言图像预训练（CLIP）在基于图像的视觉学习方面取得了显著进展。随之而来出现了一个紧迫的问题：我们如何有效地将CLIP适应到视频领域？近期的研究主要集中在调整CLIP的文本或视觉分支进行动作识别。然而，我们认为两个分支的适应都是至关重要的。在本文中，我们提出了CLAVER，即对比语言-动作视频学习器（\textbf{C}ontrastive \textbf{L}anguage-\textbf{A}ction \textbf{V}ideo Learn\textbf{er}），旨在将CLIP的重点从静态物体和具体名词的对齐转向动态行为动作和抽象动词的对齐。具体来说，我们引入了一种新型克罗内克掩膜注意力来进行时序建模。我们的定制克罗内克掩膜提供了以下三个优点：1）扩大了每个令牌的临时感受野；2）作为有效的时空异构图归纳偏置，缓解了时空同质化的问题；3）可以无缝插入到基于Transformer的模型中。在文本分支方面，我们利用大型语言模型生成多样化、句子级别且语义丰富的动作解释性提示，使模型的重点转向动词理解。在各种基准测试和学习场景的大量实验证明了我们的方法的优越性和通用性。代码很快将可用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03549v1">PDF</a> </p>
<p><strong>Summary</strong><br>     论文提出CLAVER模型，旨在将CLIP的重点从静态视觉对象和具体名词的对齐转移到动态行为动词的对齐上。采用新型的Kronecker Mask注意力机制进行时序建模，引入丰富的动作解释性提示，实现视频领域的有效适应。实验证明其优越性和通用性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CLAVER模型旨在将CLIP的焦点从静态视觉对象和名词对齐转移到动态行为动词的对齐上。</li>
<li>引入Kronecker Mask注意力机制进行时序建模，扩大每个标记的临时接受范围，并作为有效的时空异质性归纳偏置。</li>
<li>Kronecker Mask可以无缝插入基于transformer的模型。</li>
<li>利用大型语言模型生成多样、句子级别且语义丰富的动作解释性提示。</li>
<li>这些提示使模型更专注于动词理解。</li>
<li>在各种基准测试和学习场景下的实验证明了CLAVER模型的优越性和通用性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03549">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9ee54c34c36dc0029084f478d6c10ee0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-74e837888e4c3df7534ca77280781c35.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-21c00327f43c091d3a1d441a734fb18b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5743847eb38ad849752e6fa58f4c9419.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Beyond-Random-Augmentations-Pretraining-with-Hard-Views"><a href="#Beyond-Random-Augmentations-Pretraining-with-Hard-Views" class="headerlink" title="Beyond Random Augmentations: Pretraining with Hard Views"></a>Beyond Random Augmentations: Pretraining with Hard Views</h2><p><strong>Authors:Fabio Ferreira, Ivo Rapant, Jörg K. H. Franke, Frank Hutter</strong></p>
<p>Self-Supervised Learning (SSL) methods typically rely on random image augmentations, or views, to make models invariant to different transformations. We hypothesize that the efficacy of pretraining pipelines based on conventional random view sampling can be enhanced by explicitly selecting views that benefit the learning progress. A simple yet effective approach is to select hard views that yield a higher loss. In this paper, we propose Hard View Pretraining (HVP), a learning-free strategy that extends random view generation by exposing models to more challenging samples during SSL pretraining. HVP encompasses the following iterative steps: 1) randomly sample multiple views and forward each view through the pretrained model, 2) create pairs of two views and compute their loss, 3) adversarially select the pair yielding the highest loss according to the current model state, and 4) perform a backward pass with the selected pair. In contrast to existing hard view literature, we are the first to demonstrate hard view pretraining’s effectiveness at scale, particularly training on the full ImageNet-1k dataset, and evaluating across multiple SSL methods, ConvNets, and ViTs. As a result, HVP sets a new state-of-the-art on DINO ViT-B&#x2F;16, reaching 78.8% linear evaluation accuracy (a 0.6% improvement) and consistent gains of 1% for both 100 and 300 epoch pretraining, with similar improvements across transfer tasks in DINO, SimSiam, iBOT, and SimCLR. </p>
<blockquote>
<p>自监督学习（SSL）方法通常依赖于随机图像增强或视图，以使模型对不同变换具有不变性。我们假设，通过明确选择有益于学习进度的视图，可以提高基于常规随机视图采样的预训练管道的有效性。一种简单而有效的方法是选择产生更高损失的硬视图。在本文中，我们提出了硬视图预训练（HVP），这是一种无学习策略，它通过暴露模型于更具挑战性的样本来扩展随机视图生成，在SSL预训练期间。HVP包括以下迭代步骤：1）随机采样多个视图，并通过预训练模型向前传递每个视图，2）创建两个视图的配对并计算其损失，3）根据当前模型状态对抗性地选择产生最高损失的配对，4）对所选配对执行反向传递。与现有的硬视图文献相比，我们首次证明了硬视图预训练在大规模上的有效性，特别是在完整的ImageNet-1k数据集上进行训练，并在多种SSL方法、ConvNets和ViTs中进行评估。因此，HVP在DINO ViT-B&#x2F;16上创造了新的技术水平，达到78.8%的线性评估精度（提高了0.6%），在100和300个周期预训练中均取得了1%的持续增益，同时在DINO、SimSiam、iBOT和SimCLR中的迁移任务也都有类似的改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03940v6">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>本文提出了Hard View Pretraining（HVP）方法，这是一种无需学习的方法，扩展了随机视图生成，通过在SSL预训练过程中暴露模型于更具挑战性的样本。HVP通过以下步骤实现：1)随机采样多个视图并向前传播每个视图通过预训练模型；2)创建两个视图的配对并计算其损失；3)根据当前模型状态选择损失最高的配对；4)使用所选配对进行反向传播。本文首次证明了硬视图预训练在大规模数据上的有效性，特别是在ImageNet-1k数据集上进行训练，并在多个SSL方法、ConvNets和ViTs上进行了评估。HVP在DINO ViT-B&#x2F;16上达到了线性评估准确率为78.8%，创下新的记录（提高了0.6%），在100和300轮预训练中均实现了一致的1%的提升，且在DINO、SimSiam、iBOT和SimCLR中的迁移任务也有类似的改进。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>Hard View Pretraining（HVP）是一种无需学习的方法，能够增强模型对变换的鲁棒性，通过选择有利于学习进展的视图来提高预训练管道的效率。</li>
<li>HVP通过选择产生更高损失的“硬”视图来扩展随机视图采样，从而创建更具挑战性的样本用于SSL预训练。</li>
<li>HVP方法包括随机采样多个视图、创建视图对、计算损失、选择损失最高的视图对，并进行反向传播。</li>
<li>首次在大规模数据（如ImageNet-1k）上证明了硬视图预训练的有效性，并在多个SSL方法、ConvNets和ViTs上进行了评估。</li>
<li>HVP在DINO ViT-B&#x2F;16的线性评估中创下了新的记录，并在预训练的不同阶段以及不同的迁移任务中均实现了显著的改进。</li>
<li>HVP方法具有广泛的应用潜力，可适用于不同的SSL方法和模型架构。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.03940">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fec7d2f639e418f2f80e2bde61b48d58.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6934034d71242b0cbefda56428d20c87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44b2782f2a609d334f35a547ba614155.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1329b80b6ea9c83c7206429b6ed2560a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f2c9b5346e3e317dadcf11732f92557c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-08/Vision%20Transformer/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-08/Vision%20Transformer/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Vision-Transformer/">
                                    <span class="chip bg-color">Vision Transformer</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-08/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-79dc966df6515e279476e005e7184a70.jpg" class="responsive-img" alt="检测/分割/跟踪">
                        
                        <span class="card-title">检测/分割/跟踪</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            检测/分割/跟踪 方向最新论文已更新，请持续关注 Update in 2025-02-08  Point2RBox-v2 Rethinking Point-supervised Oriented Object Detection   with Spatial Layout Among Instances
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    检测/分割/跟踪
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">检测/分割/跟踪</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-08/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-d6aeb35fba640c8042a7d65979cea2a9.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-02-08  Transformers Boost the Performance of Decision Trees on Tabular Data   across Sample Sizes
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23154.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
