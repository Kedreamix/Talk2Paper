<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-02-08  ScoreFlow Mastering LLM Agent Workflows via Score-based Preference   Optimization">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4e3d5a785d9a07f32cb1efb2f6d9841d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-08-更新"><a href="#2025-02-08-更新" class="headerlink" title="2025-02-08 更新"></a>2025-02-08 更新</h1><h2 id="ScoreFlow-Mastering-LLM-Agent-Workflows-via-Score-based-Preference-Optimization"><a href="#ScoreFlow-Mastering-LLM-Agent-Workflows-via-Score-based-Preference-Optimization" class="headerlink" title="ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference   Optimization"></a>ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference   Optimization</h2><p><strong>Authors:Yinjie Wang, Ling Yang, Guohao Li, Mengdi Wang, Bryon Aragam</strong></p>
<p>Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods. However, existing methods remain inflexible due to representational limitations, a lack of adaptability, and poor scalability when relying on discrete optimization techniques. We address these challenges with ScoreFlow, a simple yet high-performance framework that leverages efficient gradient-based optimization in a continuous space. ScoreFlow incorporates Score-DPO, a novel variant of the direct preference optimization method that accounts for quantitative feedback. Across six benchmarks spanning question answering, coding, and mathematical reasoning, ScoreFlow achieves an 8.2% improvement over existing baselines. Moreover, it empowers smaller models to outperform larger ones with lower inference costs. Project: <a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/ScoreFlow">https://github.com/Gen-Verse/ScoreFlow</a> </p>
<blockquote>
<p>最近的研究利用大型语言模型多智能体系统进行复杂问题解决，同时尝试减少构建所需的人工努力，推动自动智能体工作流程优化方法的发展。然而，由于表示限制、缺乏适应性和在依赖离散优化技术时的糟糕可扩展性，现有方法仍然不够灵活。我们针对这些挑战，提出了ScoreFlow框架，它利用连续空间中的高效基于梯度的优化。ScoreFlow结合了Score-DPO，这是一种考虑定量反馈的直接偏好优化方法的新颖变体。在涵盖问答、编码和数学推理的六个基准测试中，ScoreFlow相较于现有基准测试实现了8.2%的改进。此外，它使小型模型能够以较低推理成本超越大型模型。项目地址：<a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/ScoreFlow">https://github.com/Gen-Verse/ScoreFlow</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04306v1">PDF</a> Project: <a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/ScoreFlow">https://github.com/Gen-Verse/ScoreFlow</a></p>
<p><strong>Summary</strong></p>
<p>近期研究利用大型语言模型多智能体系统解决复杂问题，旨在减少建模所需的人工努力，推动智能体工作流程优化方法的开发。然而，现有方法存在灵活性不足的问题，如在表示方面的局限性、缺乏适应性和在依赖离散优化技术时的可伸缩性差。我们借助ScoreFlow框架解决这些问题，该框架采用高效的基于梯度的优化方法，在连续空间内实现性能优化。ScoreFlow结合了Score-DPO这一新型直接偏好优化方法，考虑了定量反馈。在涵盖问答、编码和数学推理的六个基准测试中，ScoreFlow较现有基线提高了8.2%。此外，它还能使小型模型以较低推理成本超越大型模型。项目地址：<a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/ScoreFlow">GitHub链接</a>。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型多智能体系统用于复杂问题求解，旨在减少建模的人工干预。</li>
<li>现有智能体工作流程优化方法存在灵活性问题，如表示局限、缺乏适应性和可伸缩性差。</li>
<li>ScoreFlow框架通过高效的基于梯度的优化方法在连续空间内实现性能优化。</li>
<li>ScoreFlow结合了Score-DPO这一新型直接偏好优化方法，考虑了定量反馈。</li>
<li>在多个基准测试中，ScoreFlow较现有方法性能有所提升。</li>
<li>ScoreFlow使小型模型能在较低推理成本下表现出超越大型模型的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04306">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7532e3b3870997258a7077ca98bcd3a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-feec3264cc14960818599cc31c4042d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-06a6ed7e0a0e1d3f3d46c2c647a8cf3b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Deep-Meta-Coordination-Graphs-for-Multi-agent-Reinforcement-Learning"><a href="#Deep-Meta-Coordination-Graphs-for-Multi-agent-Reinforcement-Learning" class="headerlink" title="Deep Meta Coordination Graphs for Multi-agent Reinforcement Learning"></a>Deep Meta Coordination Graphs for Multi-agent Reinforcement Learning</h2><p><strong>Authors:Nikunj Gupta, James Zachary Hare, Rajgopal Kannan, Viktor Prasanna</strong></p>
<p>This paper presents deep meta coordination graphs (DMCG) for learning cooperative policies in multi-agent reinforcement learning (MARL). Coordination graph formulations encode local interactions and accordingly factorize the joint value function of all agents to improve efficiency in MARL. However, existing approaches rely solely on pairwise relations between agents, which potentially oversimplifies complex multi-agent interactions. DMCG goes beyond these simple direct interactions by also capturing useful higher-order and indirect relationships among agents. It generates novel graph structures accommodating multiple types of interactions and arbitrary lengths of multi-hop connections in coordination graphs to model such interactions. It then employs a graph convolutional network module to learn powerful representations in an end-to-end manner. We demonstrate its effectiveness in multiple coordination problems in MARL where other state-of-the-art methods can suffer from sample inefficiency or fail entirely. All codes can be found here: <a target="_blank" rel="noopener" href="https://github.com/Nikunj-Gupta/dmcg-marl">https://github.com/Nikunj-Gupta/dmcg-marl</a>. </p>
<blockquote>
<p>本文提出了深度元协调图（DMCG），用于学习多智能体强化学习（MARL）中的合作策略。协调图公式编码局部交互，并相应地分解所有智能体的联合值函数，以提高MARL中的效率。然而，现有方法仅依赖于智能体之间的配对关系，这可能会过于简化复杂的多智能体交互。DMCG超越了这些简单的直接交互，通过捕获智能体之间有用的高阶和间接关系。它生成了适应多种交互类型和协调图中任意长度的多跳连接的新型图形结构，以模拟这些交互。然后，它采用图卷积网络模块以端到端的方式学习强大的表示。我们在MARL中的多个协调问题上证明了其有效性，而其他最新方法可能会遭受样本效率低下或完全失败的问题。所有代码可在<a target="_blank" rel="noopener" href="https://github.com/Nikunj-Gupta/dmcg-marl">https://github.com/Nikunj-Gupta/dmcg-marl</a> 找到。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04028v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了深度元协调图（DMCG）在多智能体强化学习（MARL）中学习合作策略的应用。协调图公式能够编码局部交互，并据此对所有智能体的联合值函数进行因子分解，以提高MARL的效率。然而，现有方法仅依赖于智能体之间的两两关系，这可能会简化复杂的多智能体交互。DMCG通过捕获智能体之间的高阶和间接关系，超越了这些简单的直接交互。它生成了容纳多种类型交互和任意长度的多跳连接的新型图形结构，并采用图卷积网络模块以端到端的方式学习强大的表示。在多个协调问题的多智能体强化学习中，我们证明了其有效性，而其他最新方法可能会遭受样本效率低下或完全失败的问题。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DMCG用于多智能体强化学习中的合作策略学习。</li>
<li>协调图公式可编码局部交互并联合因子分解智能体的值函数。</li>
<li>现有方法主要基于智能体间的两两关系，可能简化复杂交互。</li>
<li>DMCG捕获智能体之间的高阶和间接关系。</li>
<li>DMCG生成新型图形结构以容纳多种类型交互和多跳连接。</li>
<li>采用图卷积网络模块进行强大的表示学习。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04028">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-593a9a18a56fbea84d59664db5da23cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de57a01ffe95b018cc690b1a62ff9e01.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-819396832427e93e5f2733a4a1c87b7a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3fc6756c7fc6f8c540af4e21c54bee9.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Speaking-the-Language-of-Teamwork-LLM-Guided-Credit-Assignment-in-Multi-Agent-Reinforcement-Learning"><a href="#Speaking-the-Language-of-Teamwork-LLM-Guided-Credit-Assignment-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Speaking the Language of Teamwork: LLM-Guided Credit Assignment in   Multi-Agent Reinforcement Learning"></a>Speaking the Language of Teamwork: LLM-Guided Credit Assignment in   Multi-Agent Reinforcement Learning</h2><p><strong>Authors:Muhan Lin, Shuyang Shi, Yue Guo, Vaishnav Tadiparthi, Behdad Chalaki, Ehsan Moradi Pari, Simon Stepputtis, Woojun Kim, Joseph Campbell, Katia Sycara</strong></p>
<p>Credit assignment, the process of attributing credit or blame to individual agents for their contributions to a team’s success or failure, remains a fundamental challenge in multi-agent reinforcement learning (MARL), particularly in environments with sparse rewards. Commonly-used approaches such as value decomposition often lead to suboptimal policies in these settings, and designing dense reward functions that align with human intuition can be complex and labor-intensive. In this work, we propose a novel framework where a large language model (LLM) generates dense, agent-specific rewards based on a natural language description of the task and the overall team goal. By learning a potential-based reward function over multiple queries, our method reduces the impact of ranking errors while allowing the LLM to evaluate each agent’s contribution to the overall task. Through extensive experiments, we demonstrate that our approach achieves faster convergence and higher policy returns compared to state-of-the-art MARL baselines. </p>
<blockquote>
<p>在多智能体强化学习（MARL）中，特别是在奖励稀疏的环境中，对智能体的贡献进行信用分配，即对其在团队成功或失败中的贡献给予正面或负面的评价，仍然是一个基本挑战。常用的方法如价值分解在这些场景中往往导致次优策略，而设计符合人类直觉的密集奖励函数可能既复杂又耗时。在这项工作中，我们提出了一种新型框架，该框架使用一个大型语言模型（LLM）基于任务的自然语言描述和总体团队目标生成密集的、针对特定智能体的奖励。通过在多个查询上学习基于潜力的奖励函数，我们的方法降低了排名错误的影响，同时允许LLM评估每个智能体对整体任务的贡献。通过广泛的实验，我们证明了我们的方法与最先进的MARL基线相比，实现了更快的收敛和更高的策略回报。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03723v1">PDF</a> 11 pages, 6 figures</p>
<p><strong>Summary</strong>：在多智能体强化学习（MARL）中，信用分配是一个基本挑战，特别是在奖励稀疏的环境中。常见的方法如价值分解在这些环境中往往导致次优策略，而设计符合人类直觉的密集奖励函数可能复杂且耗时。本研究提出了一种新型框架，利用大型语言模型（LLM）基于任务的自然语言描述和整体团队目标生成密集、特定于智能体的奖励。通过基于多个查询学习基于潜力的奖励函数，我们的方法减少了排名错误的影响，并允许LLM评估每个智能体对整体任务的贡献。实验表明，我们的方法相较于最先进的MARL基准方法，实现了更快的收敛和更高的策略回报。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>信用分配在多智能体强化学习（MARL）中是一个挑战，尤其在奖励稀疏的环境中。</li>
<li>常见方法如价值分解在奖励稀疏的环境中可能导致次优策略。</li>
<li>设计符合人类直觉的密集奖励函数可能很复杂并且耗时。</li>
<li>提出了一种新型框架，利用大型语言模型（LLM）生成特定于智能体的密集奖励。</li>
<li>该框架通过基于多个查询学习基于潜力的奖励函数，减少排名错误的影响。</li>
<li>LLM能评估每个智能体对整体任务的贡献。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03723">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a5d57cc544b822b9ec21c295fe58b54f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47da08c727129841e086d8015c88ab0e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Discrete-GCBF-Proximal-Policy-Optimization-for-Multi-agent-Safe-Optimal-Control"><a href="#Discrete-GCBF-Proximal-Policy-Optimization-for-Multi-agent-Safe-Optimal-Control" class="headerlink" title="Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal   Control"></a>Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal   Control</h2><p><strong>Authors:Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan</strong></p>
<p>Control policies that can achieve high task performance and satisfy safety constraints are desirable for any system, including multi-agent systems (MAS). One promising technique for ensuring the safety of MAS is distributed control barrier functions (CBF). However, it is difficult to design distributed CBF-based policies for MAS that can tackle unknown discrete-time dynamics, partial observability, changing neighborhoods, and input constraints, especially when a distributed high-performance nominal policy that can achieve the task is unavailable. To tackle these challenges, we propose DGPPO, a new framework that simultaneously learns both a discrete graph CBF which handles neighborhood changes and input constraints, and a distributed high-performance safe policy for MAS with unknown discrete-time dynamics. We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that, compared with existing methods, our DGPPO framework obtains policies that achieve high task performance (matching baselines that ignore the safety constraints), and high safety rates (matching the most conservative baselines), with a constant set of hyperparameters across all environments. </p>
<blockquote>
<p>对于任何系统（包括多智能体系统，MAS）来说，能够实现高任务性能并满足安全约束的控制策略都是理想的。确保MAS安全的一种有前途的技术是分布式控制屏障函数（CBF）。然而，为MAS设计基于分布式CBF的策略以处理未知离散时间动态、部分可观察性、变化的邻域和输入约束是困难的，尤其是在不存在能够实现任务的高性能名义策略的情况下。为了应对这些挑战，我们提出了DGPPO，这是一个新的框架，可以同时学习处理邻域变化和输入约束的离散图CBF，以及针对具有未知离散时间动态的多智能体系统的分布式高性能安全策略。我们在跨越三个不同仿真引擎的多智能体任务套件上对我们的主张进行了实证验证。结果表明，与现有方法相比，我们的DGPPO框架获得的策略在实现高任务性能（匹配忽略安全约束的基线）和高安全率（匹配最保守的基线）方面表现出色，且所有环境下的超参数都是恒定的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03640v1">PDF</a> 31 pages, 15 figures, accepted by the thirteenth International   Conference on Learning Representations (ICLR 2025)</p>
<p><strong>Summary</strong></p>
<p>在面临高任务性能和安全约束的系统需求时，分布式控制屏障函数（CBF）是一个有效的技术。然而，对于具有未知离散时间动力学特性、部分可观察性、变化邻域和输入约束的多智能体系统（MAS），设计基于分布式CBF的策略是一大挑战。为了应对这些挑战，我们提出了DGPPO这一新框架，它能同时学习处理邻域变化和输入约束的离散图CBF，以及针对未知离散时间动力学特性的分布式高性能安全策略。经验验证显示，我们的框架在多项多智能体任务中表现优异，既实现了高任务性能（与忽略安全约束的基线相匹配），又保证了高安全率（与最保守的基线相匹配），且在所有环境中使用的超参数都是恒定的。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>分布式控制屏障函数（CBF）在确保多智能体系统（MAS）的安全性方面表现出巨大潜力。</li>
<li>设计针对未知离散时间动力学、部分可观察性、变化邻域和输入约束的分布式CBF策略是一大挑战。</li>
<li>DGPPO框架能同时学习处理邻域变化和输入约束的离散图CBF及高性能安全策略。</li>
<li>DGPPO框架在多个多智能体任务中实现了高任务性能和高安全率。</li>
<li>DGPPO框架在仿真验证中展现了优越性，且其性能在不同环境中具有一致性。</li>
<li>与现有方法相比，DGPPO框架能够在满足安全约束的同时实现接近最佳的任务性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03640">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-825108d85260351c106c615691c80beb.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="OneKE-A-Dockerized-Schema-Guided-LLM-Agent-based-Knowledge-Extraction-System"><a href="#OneKE-A-Dockerized-Schema-Guided-LLM-Agent-based-Knowledge-Extraction-System" class="headerlink" title="OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction   System"></a>OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction   System</h2><p><strong>Authors:Yujie Luo, Xiangyuan Ru, Kangwei Liu, Lin Yuan, Mengshu Sun, Ningyu Zhang, Lei Liang, Zhiqiang Zhang, Jun Zhou, Lanning Wei, Da Zheng, Haofen Wang, Huajun Chen</strong></p>
<p>We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE’s efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at <a target="_blank" rel="noopener" href="https://github.com/zjunlp/OneKE">https://github.com/zjunlp/OneKE</a> and released a Video at <a target="_blank" rel="noopener" href="http://oneke.openkg.cn/demo.mp4">http://oneke.openkg.cn/demo.mp4</a>. </p>
<blockquote>
<p>我们介绍了OneKE，这是一个Docker化的模式引导知识提取系统，可以从网页和原始PDF书籍中提取知识，并支持多个领域（科学、新闻等）。具体来说，我们设计OneKE时采用了多个代理和一个配置知识库。不同的代理执行各自的角色，支持各种提取场景。配置知识库便于模式配置、错误情况调试和修正，进一步提高性能。在基准数据集上的经验评估证明了OneKE的有效性，而案例研究进一步说明了其在多个领域的不同任务的适应性，突出了其广泛的应用潜力。我们已经将代码开源在<a target="_blank" rel="noopener" href="https://github.com/zjunlp/OneKE%EF%BC%8C%E5%B9%B6%E5%8F%91%E5%B8%83%E4%BA%86%E4%B8%80%E4%B8%AA%E8%A7%86%E9%A2%91%E5%9C%A8http://oneke.openkg.cn/demo.mp4%E3%80%82">https://github.com/zjunlp/OneKE，并发布了一个视频在http://oneke.openkg.cn/demo.mp4。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20005v2">PDF</a> WWW 2025 Demonstration</p>
<p><strong>Summary</strong>：</p>
<p>我们推出了一款名为OneKE的Docker化架构指导知识提取系统，可从网页和PDF书籍中提取知识，并适用于多个领域（如科学、新闻等）。OneKE设计有多个代理和一个配置知识库，不同代理执行各自的任务，支持各种提取场景。配置知识库便于架构配置、错误调试和修正，提高了系统性能。在基准数据集上的实证评估证明了OneKE的有效性，案例研究进一步说明了其在多个领域不同任务的适应性，展现了其广泛的应用潜力。我们已在<a target="_blank" rel="noopener" href="https://github.com/zjunlp/OneKE%E5%BC%80%E6%BA%90%E4%BA%86%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%B9%B6%E5%9C%A8http://oneke.openkg.cn/demo.mp4%E5%8F%91%E5%B8%83%E4%BA%86%E8%A7%86%E9%A2%91%E3%80%82">https://github.com/zjunlp/OneKE开源了代码，并在http://oneke.openkg.cn/demo.mp4发布了视频。</a></p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>OneKE是一个Docker化的知识提取系统，可以从网页和PDF书籍中提取知识。</li>
<li>OneKE支持多个领域，如科学和新闻。</li>
<li>OneKE设计有多个代理，每个代理执行特定的任务，以适应不同的提取场景。</li>
<li>配置知识库有助于提高系统性能，方便架构配置、错误调试和修正。</li>
<li>实证评估和案例研究证明了OneKE的有效性和适应性。</li>
<li>OneKE已开源，并提供了视频演示。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20005">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bcb5cea666e3441445ccc7d178e583ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d66ad6ebd1a86d85df49c8b15ba9afa3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9e152d1a7c03838dfe71b01402a1035d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4f00f01df4af01b7b3314adce4200ad7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="G-Designer-Architecting-Multi-agent-Communication-Topologies-via-Graph-Neural-Networks"><a href="#G-Designer-Architecting-Multi-agent-Communication-Topologies-via-Graph-Neural-Networks" class="headerlink" title="G-Designer: Architecting Multi-agent Communication Topologies via Graph   Neural Networks"></a>G-Designer: Architecting Multi-agent Communication Topologies via Graph   Neural Networks</h2><p><strong>Authors:Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Tianlong Chen, Dawei Cheng</strong></p>
<p>Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at $84.50%$ and on HumanEval with pass@1 at $89.90%$; \textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to $95.33%$ on HumanEval; and \textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely $0.3%$ accuracy drop. </p>
<blockquote>
<p>最近，基于大型语言模型（LLM）的代理人的进步表明，集体智能可以显著超过单个代理人的能力，这主要是因为精心设计的代理人之间的通信拓扑。尽管存在各种高性能的设计方案，但从业者在选择最有效的特定任务流水线时经常感到困惑：对于我的任务，哪种拓扑是最佳选择，同时避免不必要的通信令牌开销并确保高质量的解决方案？针对这一困境，我们引入了G-Designer，这是一种用于多代理部署的自适应、高效且稳健的解决方案，可动态设计任务感知的定制通信拓扑。具体来说，G-Designer将多代理系统建模为多个代理网络，利用变分图自动编码器对节点（代理）和特定任务的虚拟节点进行编码，并解码出任务自适应且高性能的通信拓扑。在六个基准测试上的大量实验表明，G-Designer具有以下特点：（1）高性能：在MMLU上的准确度达到84.50%，在HumanEval上的pass@1达到89.90%；（2）任务自适应：根据任务难度定制通信协议，在HumanEval上最多减少高达95.33%的令牌消耗；（3）对抗性稳健：能够抵御代理人对抗性攻击，仅导致准确率下降0.3%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.11782v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）为基础代理人的最新进展表明，集体智能可以显著超越个体代理人的能力，这主要得益于精心设计的跨代理通信拓扑。针对多代理部署问题，我们推出了G-Designer，这是一个自适应、高效且稳健的解决方案，能够动态设计任务感知的定制通信拓扑。实验表明，G-Designer在多个基准测试上表现出卓越性能，包括高准确性、任务适应性和对抗稳健性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型为基础代理人的集体智能显著超越个体代理人能力。</li>
<li>跨代理通信拓扑设计是集体智能表现的关键。</li>
<li>G-Designer是一个自适应、高效且稳健的多代理部署解决方案。</li>
<li>G-Designer能动态设计任务感知的定制通信拓扑。</li>
<li>G-Designer在多个基准测试中表现出高准确性、任务适应性和对抗稳健性。</li>
<li>G-Designer通过建模多代理系统为多代理网络并利用变异图自编码器编码节点和任务特定虚拟节点，实现高效通信拓扑解码。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.11782">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-deb8d8cfabcb0344e9524501b8bc5ded.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7de0bf946f29989862a861f7a12646de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-314d413102920e01d6db2bd3dd30e42f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="AgentGen-Enhancing-Planning-Abilities-for-Large-Language-Model-based-Agent-via-Environment-and-Task-Generation"><a href="#AgentGen-Enhancing-Planning-Abilities-for-Large-Language-Model-based-Agent-via-Environment-and-Task-Generation" class="headerlink" title="AgentGen: Enhancing Planning Abilities for Large Language Model based   Agent via Environment and Task Generation"></a>AgentGen: Enhancing Planning Abilities for Large Language Model based   Agent via Environment and Task Generation</h2><p><strong>Authors:Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan</strong></p>
<p>Large Language Model-based agents have garnered significant attention and are becoming increasingly popular. Furthermore, planning ability is a crucial component of an LLM-based agent, which generally entails achieving a desired goal from an initial state. This paper investigates enhancing the planning abilities of LLMs through instruction tuning, referred to as agent training. Recent studies have demonstrated that utilizing expert-level trajectory for instruction-tuning LLMs effectively enhances their planning capabilities. However, existing work primarily focuses on synthesizing trajectories from manually designed planning tasks and environments. The labor-intensive nature of creating these environments and tasks impedes the generation of sufficiently varied and extensive trajectories. To address this limitation, this paper explores the automated synthesis of diverse environments and a gradual range of planning tasks, from easy to difficult. We introduce a framework, AgentGen, that leverages LLMs first to generate environments and subsequently generate planning tasks conditioned on these environments. Specifically, to improve environmental diversity, we propose using an inspiration corpus composed of various domain-specific text segments as the context for synthesizing environments. Moreover, to increase the difficulty diversity of generated planning tasks, we propose a bidirectional evolution method, Bi-Evol, that evolves planning tasks from easier and harder directions to synthesize a task set with a smoother difficulty curve. The evaluation results derived from AgentBoard show that AgentGen greatly improves LLMs’ planning ability, e.g., the AgentGen instruction-tuned Llama-3.1-8B surpasses GPT-3.5 in overall performance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves state-of-the-art results in planning tasks. Project page: <a target="_blank" rel="noopener" href="https://agent-gen.github.io/">https://agent-gen.github.io/</a>. </p>
<blockquote>
<p>基于大型语言模型的智能体已经引起了广泛的关注并且越来越受欢迎。此外，规划能力是基于大型语言模型（LLM）的智能体的关键组成部分，通常涉及从初始状态实现预期目标。本文旨在通过指令微调（也称为智能体训练）来提高大型语言模型的规划能力。最近的研究表明，利用专家级轨迹对大型语言模型进行指令微调可以有效地提高其规划能力。然而，现有的工作主要集中在从手动设计的规划任务和环境中合成轨迹。创建这些环境和任务需要大量的人工劳动，阻碍了足够多样化和广泛的轨迹生成。为了解决这个问题，本文探讨了自动化合成多样环境和一系列从简单到复杂的规划任务。我们引入了一个名为AgentGen的框架，它首先利用大型语言模型生成环境，然后根据这些环境生成规划任务。具体来说，为了提高环境多样性，我们建议使用由各种领域特定文本片段组成的灵感语料库作为合成环境的上下文。此外，为了提高生成规划任务的难度多样性，我们提出了一种双向进化方法Bi-Evol，该方法可以从简单和困难的方向进化规划任务，以合成难度曲线更平滑的任务集。来自AgentBoard的评估结果表明，AgentGen大大提高了大型语言模型的规划能力。例如，经过AgentGen指令微调的Llama-3.1-8B在整体性能上超越了GPT-3.5。此外，经过AgentGen训练的Llama-3.1-70B模型在规划任务上达到了最新水平。项目页面：<a target="_blank" rel="noopener" href="https://agent-gen.github.io/%E3%80%82">https://agent-gen.github.io/。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.00764v3">PDF</a> Accepted by KDD 2025 (Research Track). Project page:   <a target="_blank" rel="noopener" href="https://agent-gen.github.io/">https://agent-gen.github.io/</a></p>
<p><strong>摘要</strong><br>大型语言模型为基础的智能代理得到了广泛关注并越来越受欢迎。规划能力是LLM基础代理的关键组成部分，包括从初始状态实现目标。本研究旨在通过指令微调增强LLM的规划能力，称为代理训练。现有研究证明利用专家级轨迹进行指令微调LLM能有效提升其规划能力。然而，现有的工作主要集中在从手动设计的规划任务和环境中合成轨迹，创建这些环境和任务需要大量劳动力，阻碍了足够多样和广泛的轨迹生成。本研究探索了环境和规划任务的自动化合成，从简单到复杂。引入AgentGen框架，利用LLM首先生成环境，然后根据这些环境生成规划任务。为提高环境多样性，我们提出使用包含各种领域特定文本片段的灵感语料库作为合成环境的上下文。为提高生成规划任务的难度多样性，我们提出了双向进化方法Bi-Evol，该方法从容易和困难的方向进化规划任务，合成难度曲线更平滑的任务集。通过AgentBoard进行的评估结果表明，AgentGen极大地提高了LLM的规划能力，例如，通过AgentGen指令微调的Llama-3.1-8B在总体性能上超越了GPT-3.5。此外，使用AgentGen调教的Llama-3.1-70B模型在规划任务上达到了最新水平。项目页面：<a target="_blank" rel="noopener" href="https://agent-gen.github.io/">https://agent-gen.github.io/。</a></p>
<p><strong>要点摘要</strong></p>
<ol>
<li>大型语言模型为基础的智能代理受到关注，规划能力是关键。</li>
<li>现有研究通过指令微调增强LLM的规划能力。</li>
<li>手动创建环境和任务阻碍轨迹生成，需要自动化合成方法。</li>
<li>引入AgentGen框架，利用LLM生成环境和规划任务。</li>
<li>使用灵感语料库提高环境多样性，提出双向进化方法增加任务难度多样性。</li>
<li>AgentGen显著提高了LLM的规划能力，某些模型性能超越现有技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.00764">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-f88b6b22a5d267cce15a4a2f615c05c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-385a1672019a23f0e62a5d5edc8b4f83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e3d5a785d9a07f32cb1efb2f6d9841d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c11e1618fc1d72ffd8d1059e16b3d732.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Scenario-Based-Curriculum-Generation-for-Multi-Agent-Autonomous-Driving"><a href="#Scenario-Based-Curriculum-Generation-for-Multi-Agent-Autonomous-Driving" class="headerlink" title="Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving"></a>Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving</h2><p><strong>Authors:Axel Brunnbauer, Luigi Berducci, Peter Priller, Dejan Nickovic, Radu Grosu</strong></p>
<p>The automated generation of diverse and complex training scenarios has been an important ingredient in many complex learning tasks. Especially in real-world application domains, such as autonomous driving, auto-curriculum generation is considered vital for obtaining robust and general policies. However, crafting traffic scenarios with multiple, heterogeneous agents is typically considered as a tedious and time-consuming task, especially in more complex simulation environments. In our work, we introduce MATS-Gym, a Multi-Agent Traffic Scenario framework to train agents in CARLA, a high-fidelity driving simulator. MATS-Gym is a multi-agent training framework for autonomous driving that uses partial scenario specifications to generate traffic scenarios with variable numbers of agents. This paper unifies various existing approaches to traffic scenario description into a single training framework and demonstrates how it can be integrated with techniques from unsupervised environment design to automate the generation of adaptive auto-curricula. The code is available at <a target="_blank" rel="noopener" href="https://github.com/AutonomousDrivingExaminer/mats-gym">https://github.com/AutonomousDrivingExaminer/mats-gym</a>. </p>
<blockquote>
<p>自动化生成多样且复杂的训练场景已成为许多复杂学习任务的重要组成部分。特别是在现实世界的应用领域，如自动驾驶，自动课程生成对于获得稳健和通用的策略被认为是至关重要的。然而，在更复杂的模拟环境中，制作具有多个异质代理的交通场景通常被认为是一项乏味且耗时的任务。在我们的工作中，我们介绍了MATS-Gym，这是一个用于在CARLA（高保真驾驶模拟器）中训练代理的多代理交通场景框架。MATS-Gym是一个用于自动驾驶的多代理训练框架，它使用部分场景规范来生成具有可变代理数量的交通场景。本文统一了现有的各种交通场景描述方法，将其纳入一个单一的训练框架，并展示了如何将其与无监督环境设计技术相结合，以自动生成自适应的自动课程。代码可在<a target="_blank" rel="noopener" href="https://github.com/AutonomousDrivingExaminer/mats-gym%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AutonomousDrivingExaminer/mats-gym获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17805v2">PDF</a> Accepted for publication at the International Conference on Robotics   and Automation (ICRA) 2025</p>
<p><strong>Summary</strong><br>自动化生成多样且复杂的训练场景在许多复杂学习任务中扮演着重要角色。特别是在自动驾驶等实际应用领域，自动课程生成对于获得稳健和通用的策略至关重要。然而，在更复杂的仿真环境中，构建具有多个异质代理的交通场景通常被视为一项繁琐且耗时的任务。我们的工作引入了MATS-Gym，这是一个在CARLA驾驶模拟器中训练代理的多代理交通场景框架。MATS-Gym是一个用于自动驾驶的多代理训练框架，它使用部分场景规范来生成具有可变代理数量的交通场景。本文统一了现有的各种交通场景描述方法，并将其纳入一个单一的训练框架中，并展示了如何将其与无监督环境设计技术相结合，以自动生成自适应的自动课程。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>自动化生成复杂和多样的训练场景在许多学习任务是重要的。</li>
<li>在自动驾驶等实际应用中，自动课程生成对获得稳健和通用策略至关重要。</li>
<li>构建具有多个异质代理的交通场景是一项繁琐且耗时的任务。</li>
<li>MATS-Gym是一个多代理训练框架，用于在CARLA驾驶模拟器中训练代理。</li>
<li>MATS-Gym使用部分场景规范生成具有可变代理数量的交通场景。</li>
<li>该框架统一了多种现有的交通场景描述方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.17805">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f8cda1c2c2d3632e264ddc8ce5ace676.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0badc1b458e974bfdaef4638e71e891b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa2ebd53927a0305f7f6dd8b3f79cc40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04715138d9686c5785797b8d4001113a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-403508ca692555129f32a19062d5b9ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18b74704302450eb563fde2a40673902.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MA4DIV-Multi-Agent-Reinforcement-Learning-for-Search-Result-Diversification"><a href="#MA4DIV-Multi-Agent-Reinforcement-Learning-for-Search-Result-Diversification" class="headerlink" title="MA4DIV: Multi-Agent Reinforcement Learning for Search Result   Diversification"></a>MA4DIV: Multi-Agent Reinforcement Learning for Search Result   Diversification</h2><p><strong>Authors:Yiqun Chen, Jiaxin Mao, Yi Zhang, Dehong Ma, Long Xia, Jun Fan, Daiting Shi, Zhicong Cheng, Simiu Gu, Dawei Yin</strong></p>
<p>Search result diversification (SRD), which aims to ensure that documents in a ranking list cover a broad range of subtopics, is a significant and widely studied problem in Information Retrieval and Web Search. Existing methods primarily utilize a paradigm of “greedy selection”, i.e., selecting one document with the highest diversity score at a time or optimize an approximation of the objective function. These approaches tend to be inefficient and are easily trapped in a suboptimal state. To address these challenges, we introduce Multi-Agent reinforcement learning (MARL) for search result DIVersity, which called MA4DIV. In this approach, each document is an agent and the search result diversification is modeled as a cooperative task among multiple agents. By modeling the SRD ranking problem as a cooperative MARL problem, this approach allows for directly optimizing the diversity metrics, such as $\alpha$-NDCG, while achieving high training efficiency. We conducted experiments on public TREC datasets and a larger scale dataset in the industrial setting. The experiemnts show that MA4DIV achieves substantial improvements in both effectiveness and efficiency than existing baselines, especially on the industrial dataset. The code of MA4DIV can be seen on <a target="_blank" rel="noopener" href="https://github.com/chenyiqun/MA4DIV">https://github.com/chenyiqun/MA4DIV</a>. </p>
<blockquote>
<p>搜索结果多样化（SRD）旨在确保排名列表中的文档涵盖广泛的子主题，是信息检索和网页搜索中一个重大且被广泛研究的问题。现有方法主要采用“贪婪选择”范式，即一次选择一个具有最高多样性得分的文档或优化目标函数的近似值。这些方法往往效率低下，且容易陷入次优状态。为了解决这些挑战，我们引入了用于搜索结果多样性的多智能体强化学习（MARL），称为MA4DIV。在此方法中，每个文档都是一个智能体，搜索结果多样化被建模为多个智能体之间的合作任务。通过将SRD排名问题建模为合作型MARL问题，此方法能够直接优化多样性指标（例如α-NDCG），同时实现高训练效率。我们在公共TREC数据集和工业设置的更大规模数据集上进行了实验。实验表明，MA4DIV在有效性和效率方面均实现了对现有基准的重大改进，尤其是在工业数据集上。MA4DIV的代码可见于<a target="_blank" rel="noopener" href="https://github.com/chenyiqun/MA4DIV%E3%80%82">https://github.com/chenyiqun/MA4DIV。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17421v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文本介绍了搜索结果多样化（SRD）在信息检索和网页搜索中的重要性及其现有方法面临的挑战。为解决这些问题，引入基于多智能体的强化学习（MARL）来进行搜索结果多样化，即MA4DIV方法。此方法将文档视为智能体，将搜索结果多样化建模为多个智能体之间的合作任务。实验表明，MA4DIV相较于现有基线方法在有效性和效率上都有显著提高，特别是在工业数据集上。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>搜索结果多样化（SRD）在信息检索和网页搜索中是一个重要且被广泛研究的问题。</li>
<li>现有方法主要使用“贪婪选择”范式，但这种方法往往效率低下，容易陷入次优状态。</li>
<li>为解决这些挑战，引入了基于多智能体的强化学习（MARL）的MA4DIV方法。</li>
<li>在MA4DIV方法中，每个文档都被视为一个智能体，搜索结果多样化被建模为多个智能体之间的合作任务。</li>
<li>MA4DIV方法能够直接优化多样性指标（如α-NDCG），同时实现高训练效率。</li>
<li>实验结果表明，MA4DIV在有效性和效率上都优于现有基线方法，特别是在工业数据集上。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.17421">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-cef48f1719377aab98c6caef7cb366c2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-217df880a7beac2eb245e3164ee631b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b81bb6395d32efbfd3a7bf7dad09a12b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3193218b2643484b706e3b785df73cc3.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-08/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-08/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-08/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-d6aeb35fba640c8042a7d65979cea2a9.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-02-08  Transformers Boost the Performance of Decision Trees on Tabular Data   across Sample Sizes
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-08/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-9a07efacb8deb5c3753163a995d0302f.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-02-08  Ola Pushing the Frontiers of Omni-Modal Language Model with Progressive   Modality Alignment
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">16765.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
