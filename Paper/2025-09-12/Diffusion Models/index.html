<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-12  ScoreHOI Physically Plausible Reconstruction of Human-Object   Interaction via Score-Guided Diffusion">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2402.02346v2/page_5_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-29
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    49 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-12-æ›´æ–°"><a href="#2025-09-12-æ›´æ–°" class="headerlink" title="2025-09-12 æ›´æ–°"></a>2025-09-12 æ›´æ–°</h1><h2 id="ScoreHOI-Physically-Plausible-Reconstruction-of-Human-Object-Interaction-via-Score-Guided-Diffusion"><a href="#ScoreHOI-Physically-Plausible-Reconstruction-of-Human-Object-Interaction-via-Score-Guided-Diffusion" class="headerlink" title="ScoreHOI: Physically Plausible Reconstruction of Human-Object   Interaction via Score-Guided Diffusion"></a>ScoreHOI: Physically Plausible Reconstruction of Human-Object   Interaction via Score-Guided Diffusion</h2><p><strong>Authors:Ao Li, Jinpeng Liu, Yixuan Zhu, Yansong Tang</strong></p>
<p>Joint reconstruction of human-object interaction marks a significant milestone in comprehending the intricate interrelations between humans and their surrounding environment. Nevertheless, previous optimization methods often struggle to achieve physically plausible reconstruction results due to the lack of prior knowledge about human-object interactions. In this paper, we introduce ScoreHOI, an effective diffusion-based optimizer that introduces diffusion priors for the precise recovery of human-object interactions. By harnessing the controllability within score-guided sampling, the diffusion model can reconstruct a conditional distribution of human and object pose given the image observation and object feature. During inference, the ScoreHOI effectively improves the reconstruction results by guiding the denoising process with specific physical constraints. Furthermore, we propose a contact-driven iterative refinement approach to enhance the contact plausibility and improve the reconstruction accuracy. Extensive evaluations on standard benchmarks demonstrate ScoreHOIâ€™s superior performance over state-of-the-art methods, highlighting its ability to achieve a precise and robust improvement in joint human-object interaction reconstruction. </p>
<blockquote>
<p>äººç±»ä¸ç‰©ä½“çš„äº¤äº’é‡å»ºæ˜¯ç†è§£äººç±»ä¸å…¶å‘¨å›´ç¯å¢ƒä¹‹é—´å¤æ‚å…³ç³»çš„é‡è¦é‡Œç¨‹ç¢‘ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å…³äºäººç±»-ç‰©ä½“äº¤äº’çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»¥å‰çš„ä¼˜åŒ–æ–¹æ³•å¾€å¾€éš¾ä»¥è·å¾—ç‰©ç†ä¸Šå¯è¡Œçš„é‡å»ºç»“æœã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ScoreHOIï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰©æ•£çš„æœ‰æ•ˆä¼˜åŒ–å™¨ï¼Œå®ƒå¼•å…¥äº†æ‰©æ•£å…ˆéªŒæ¥ç²¾ç¡®æ¢å¤äººç±»-ç‰©ä½“äº¤äº’ã€‚é€šè¿‡åˆ©ç”¨åˆ†æ•°å¼•å¯¼é‡‡æ ·ä¸­çš„å¯æ§æ€§ï¼Œæ‰©æ•£æ¨¡å‹å¯ä»¥æ ¹æ®å›¾åƒè§‚å¯Ÿå’Œç‰©ä½“ç‰¹å¾é‡å»ºäººç±»å’Œç‰©ä½“çš„æ¡ä»¶åˆ†å¸ƒã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒScoreHOIé€šè¿‡ç‰¹å®šçš„ç‰©ç†çº¦æŸå¼•å¯¼å»å™ªè¿‡ç¨‹ï¼Œæœ‰æ•ˆæé«˜é‡å»ºç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¥è§¦é©±åŠ¨è¿­ä»£ç»†åŒ–æ–¹æ³•ï¼Œä»¥æé«˜æ¥è§¦çš„å¯è¡Œæ€§å’Œæé«˜é‡å»ºç²¾åº¦ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒScoreHOIåœ¨æœ€æ–°æŠ€æœ¯æ–¹æ³•ä¹‹ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶åœ¨è”åˆäººç±»-ç‰©ä½“äº¤äº’é‡å»ºä¸­å®ç°ç²¾ç¡®å’Œç¨³å¥æ”¹è¿›çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07920v1">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ScoreHOIï¼Œä¸€ç§åŸºäºæ‰©æ•£ä¼˜åŒ–çš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥æ‰©æ•£å…ˆéªŒçŸ¥è¯†ï¼Œå®ç°å¯¹äººç±»-ç‰©ä½“äº¤äº’çš„ç²¾ç¡®é‡å»ºã€‚è¯¥æ–¹æ³•åˆ©ç”¨è¯„åˆ†å¼•å¯¼é‡‡æ ·å†…çš„å¯æ§æ€§ï¼Œæ ¹æ®å›¾åƒè§‚å¯Ÿå’Œç‰©ä½“ç‰¹å¾é‡å»ºäººç±»å’Œç‰©ä½“çš„å§¿æ€æ¡ä»¶åˆ†å¸ƒã€‚ScoreHOIåœ¨æ¨ç†è¿‡ç¨‹ä¸­æœ‰æ•ˆåœ°æé«˜äº†é‡å»ºç»“æœï¼Œé€šè¿‡ç‰¹å®šçš„ç‰©ç†çº¦æŸå¼•å¯¼å»å™ªè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ¥è§¦é©±åŠ¨è¿­ä»£ä¼˜åŒ–æ–¹æ³•ï¼Œæé«˜äº†æ¥è§¦çš„åˆç†æ€§å’Œé‡å»ºçš„å‡†ç¡®æ€§ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒScoreHOIåœ¨è”åˆäººç±»-ç‰©ä½“äº¤äº’é‡å»ºæ–¹é¢ä¼˜äºæœ€æ–°æŠ€æœ¯ï¼Œå®ç°äº†ç²¾ç¡®ä¸”ç¨³å¥çš„æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ScoreHOIæ˜¯ä¸€ç§åŸºäºæ‰©æ•£ä¼˜åŒ–çš„æ–¹æ³•ï¼Œç”¨äºé‡å»ºäººç±»-ç‰©ä½“äº¤äº’ã€‚</li>
<li>å¼•å…¥æ‰©æ•£å…ˆéªŒçŸ¥è¯†ï¼Œä»¥æ”¹å–„å¯¹äººç±»-ç‰©ä½“äº¤äº’çš„é‡å»ºç»“æœã€‚</li>
<li>åˆ©ç”¨è¯„åˆ†å¼•å¯¼é‡‡æ ·çš„å¯æ§æ€§ï¼Œæ ¹æ®å›¾åƒè§‚å¯Ÿå’Œç‰©ä½“ç‰¹å¾é‡å»ºå§¿æ€æ¡ä»¶åˆ†å¸ƒã€‚</li>
<li>ScoreHOIé€šè¿‡ç‰¹å®šçš„ç‰©ç†çº¦æŸåœ¨æ¨ç†è¿‡ç¨‹ä¸­æé«˜äº†é‡å»ºç»“æœã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ¥è§¦é©±åŠ¨è¿­ä»£ä¼˜åŒ–æ–¹æ³•ï¼Œæé«˜æ¥è§¦åˆç†æ€§å’Œé‡å»ºå‡†ç¡®æ€§ã€‚</li>
<li>åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šï¼ŒScoreHOIè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¼˜äºå½“å‰æœ€æ–°æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07920">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07920v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07920v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07920v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07920v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Semantic-Watermarking-Reinvented-Enhancing-Robustness-and-Generation-Quality-with-Fourier-Integrity"><a href="#Semantic-Watermarking-Reinvented-Enhancing-Robustness-and-Generation-Quality-with-Fourier-Integrity" class="headerlink" title="Semantic Watermarking Reinvented: Enhancing Robustness and Generation   Quality with Fourier Integrity"></a>Semantic Watermarking Reinvented: Enhancing Robustness and Generation   Quality with Fourier Integrity</h2><p><strong>Authors:Sung Ju Lee, Nam Ik Cho</strong></p>
<p>Semantic watermarking techniques for latent diffusion models (LDMs) are robust against regeneration attacks, but often suffer from detection performance degradation due to the loss of frequency integrity. To tackle this problem, we propose a novel embedding method called Hermitian Symmetric Fourier Watermarking (SFW), which maintains frequency integrity by enforcing Hermitian symmetry. Additionally, we introduce a center-aware embedding strategy that reduces the vulnerability of semantic watermarking due to cropping attacks by ensuring robust information retention. To validate our approach, we apply these techniques to existing semantic watermarking schemes, enhancing their frequency-domain structures for better robustness and retrieval accuracy. Extensive experiments demonstrate that our methods achieve state-of-the-art verification and identification performance, surpassing previous approaches across various attack scenarios. Ablation studies confirm the impact of SFW on detection capabilities, the effectiveness of the center-aware embedding against cropping, and how message capacity influences identification accuracy. Notably, our method achieves the highest detection accuracy while maintaining superior image fidelity, as evidenced by FID and CLIP scores. Conclusively, our proposed SFW is shown to be an effective framework for balancing robustness and image fidelity, addressing the inherent trade-offs in semantic watermarking. Code available at <a target="_blank" rel="noopener" href="https://github.com/thomas11809/SFWMark">https://github.com/thomas11809/SFWMark</a> </p>
<blockquote>
<p>é’ˆå¯¹æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰çš„è¯­ä¹‰æ°´å°æŠ€æœ¯å¯¹æŠ—å†ç”Ÿæ”»å‡»å…·æœ‰é²æ£’æ€§ï¼Œä½†ç”±äºé¢‘ç‡å®Œæ•´æ€§çš„ä¸§å¤±ï¼Œé€šå¸¸é¢ä¸´æ£€æµ‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºHermitianå¯¹ç§°å‚…é‡Œå¶æ°´å°ï¼ˆSFWï¼‰çš„æ–°å‹åµŒå…¥æ–¹æ³•ï¼Œå®ƒé€šè¿‡å¼ºåˆ¶Hermitianå¯¹ç§°æ¥ä¿æŒé¢‘ç‡å®Œæ•´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§ä¸­å¿ƒæ„ŸçŸ¥åµŒå…¥ç­–ç•¥ï¼Œé€šè¿‡ç¡®ä¿ç¨³å¥çš„ä¿¡æ¯ä¿ç•™ï¼Œå‡å°‘è¯­ä¹‰æ°´å°å› è£å‰ªæ”»å‡»è€Œé¢ä¸´çš„é£é™©ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å°†è¿™äº›æŠ€æœ¯åº”ç”¨äºç°æœ‰çš„è¯­ä¹‰æ°´å°æ–¹æ¡ˆï¼Œå¢å¼ºå…¶åœ¨é¢‘åŸŸçš„ç»“æ„ï¼Œä»¥å®ç°æ›´å¥½çš„é²æ£’æ€§å’Œæ£€ç´¢å‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨éªŒè¯å’Œè¯†åˆ«æ€§èƒ½ä¸Šè¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œåœ¨å„ç§æ”»å‡»åœºæ™¯ä¸­è¶…è¶Šäº†ä»¥å‰çš„æ–¹æ³•ã€‚æ¶ˆèç ”ç©¶è¯å®äº†SFWå¯¹æ£€æµ‹èƒ½åŠ›çš„å½±å“ï¼Œä¸­å¿ƒæ„ŸçŸ¥åµŒå…¥å¯¹æŠ—è£å‰ªçš„æœ‰æ•ˆæ€§ï¼Œä»¥åŠæ¶ˆæ¯å®¹é‡å¯¹è¯†åˆ«ç²¾åº¦çš„å½±å“ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒå›¾åƒé«˜åº¦ä¿çœŸåº¦çš„åŒæ—¶å®ç°äº†æœ€é«˜çš„æ£€æµ‹ç²¾åº¦ï¼Œè¿™å¾—åˆ°äº†FIDå’ŒCLIPåˆ†æ•°çš„è¯æ˜ã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬æå‡ºçš„SFWè¢«è¯æ˜æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨é²æ£’æ€§å’Œå›¾åƒä¿çœŸåº¦ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œè§£å†³äº†è¯­ä¹‰æ°´å°ä¸­çš„å›ºæœ‰æƒè¡¡é—®é¢˜ã€‚ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/thomas11809/SFWMark%E6%89%BE%E5%88%B0%E3%80%82]">https://github.com/thomas11809/SFWMarkæ‰¾åˆ°ã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07647v1">PDF</a> Accepted to the IEEE&#x2F;CVF International Conference on Computer Vision   (ICCV) 2025. Project page: <a target="_blank" rel="noopener" href="https://thomas11809.github.io/SFWMark/">https://thomas11809.github.io/SFWMark/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/thomas11809/SFWMark">https://github.com/thomas11809/SFWMark</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰çš„è¯­ä¹‰æ°´å°æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³å†ç”Ÿæ”»å‡»å’Œé¢‘ç‡å®Œæ•´æ€§ä¸§å¤±å¯¼è‡´çš„é—®é¢˜ã€‚æ–°æ–¹æ³•åŒ…æ‹¬Hermitianå¯¹ç§°å‚…é‡Œå¶æ°´å°ï¼ˆSFWï¼‰ï¼Œå®ƒåˆ©ç”¨Hermitianå¯¹ç§°æ€§ä¿æŒé¢‘ç‡å®Œæ•´æ€§ã€‚åŒæ—¶å¼•å…¥ä¸­å¿ƒæ„ŸçŸ¥åµŒå…¥ç­–ç•¥ï¼Œé€šè¿‡ç¡®ä¿ç¨³å¥çš„ä¿¡æ¯ä¿ç•™æ¥å‡å°‘è¯­ä¹‰æ°´å°å¯¹è£å‰ªæ”»å‡»çš„è„†å¼±æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æ”»å‡»åœºæ™¯ä¸‹å®ç°æœ€å…ˆè¿›çš„éªŒè¯å’Œè¯†åˆ«æ€§èƒ½ï¼Œä¸”åœ¨æ£€æµ‹èƒ½åŠ›å’Œå›¾åƒä¿çœŸåº¦ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­ä¹‰æ°´å°æŠ€æœ¯å¯¹äºå¯¹æŠ—æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å†ç”Ÿæ”»å‡»å…·æœ‰é²æ£’æ€§ï¼Œä½†é¢ä¸´æ£€æµ‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åµŒå…¥æ–¹æ³•â€”â€”Hermitianå¯¹ç§°å‚…é‡Œå¶æ°´å°ï¼ˆSFWï¼‰ï¼Œé€šè¿‡å¼ºåˆ¶Hermitianå¯¹ç§°æ€§æ¥ä¿æŒé¢‘ç‡å®Œæ•´æ€§ã€‚</li>
<li>å¼•å…¥ä¸­å¿ƒæ„ŸçŸ¥åµŒå…¥ç­–ç•¥ï¼Œå‡å°‘è¯­ä¹‰æ°´å°å¯¹è£å‰ªæ”»å‡»çš„è„†å¼±æ€§ï¼Œç¡®ä¿ç¨³å¥çš„ä¿¡æ¯ä¿ç•™ã€‚</li>
<li>æ–¹æ³•åœ¨å¤šç§æ”»å‡»åœºæ™¯ä¸‹å®ç°å…ˆè¿›çš„éªŒè¯å’Œè¯†åˆ«æ€§èƒ½ï¼Œä¸”æ£€æµ‹èƒ½åŠ›å’Œå›¾åƒä¿çœŸåº¦è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>é€šè¿‡å¹¿æ³›å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬ä¸å…¶ä»–æ–¹æ³•çš„æ¯”è¾ƒã€‚</li>
<li>ä»£ç å…¬å¼€å¯ç”¨ï¼Œæ–¹ä¾¿è¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07647">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07647v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07647v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07647v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07647v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07647v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07647v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Universal-Few-Shot-Spatial-Control-for-Diffusion-Models"><a href="#Universal-Few-Shot-Spatial-Control-for-Diffusion-Models" class="headerlink" title="Universal Few-Shot Spatial Control for Diffusion Models"></a>Universal Few-Shot Spatial Control for Diffusion Models</h2><p><strong>Authors:Kiet T. Nguyen, Chanhuyk Lee, Donggyun Kim, Dong Hoon Lee, Seunghoon Hong</strong></p>
<p>Spatial conditioning in pretrained text-to-image diffusion models has significantly improved fine-grained control over the structure of generated images. However, existing control adapters exhibit limited adaptability and incur high training costs when encountering novel spatial control conditions that differ substantially from the training tasks. To address this limitation, we propose Universal Few-Shot Control (UFC), a versatile few-shot control adapter capable of generalizing to novel spatial conditions. Given a few image-condition pairs of an unseen task and a query condition, UFC leverages the analogy between query and support conditions to construct task-specific control features, instantiated by a matching mechanism and an update on a small set of task-specific parameters. Experiments on six novel spatial control tasks show that UFC, fine-tuned with only 30 annotated examples of novel tasks, achieves fine-grained control consistent with the spatial conditions. Notably, when fine-tuned with 0.1% of the full training data, UFC achieves competitive performance with the fully supervised baselines in various control tasks. We also show that UFC is applicable agnostically to various diffusion backbones and demonstrate its effectiveness on both UNet and DiT architectures. Code is available at <a target="_blank" rel="noopener" href="https://github.com/kietngt00/UFC">https://github.com/kietngt00/UFC</a>. </p>
<blockquote>
<p>ç©ºé—´è°ƒèŠ‚åœ¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å·²ç»æ˜¾è‘—æé«˜äº†ç”Ÿæˆå›¾åƒç»“æ„çš„ç²¾ç»†æ§åˆ¶ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ§åˆ¶é€‚é…å™¨è¡¨ç°å‡ºæœ‰é™çš„é€‚åº”æ€§å’Œé«˜åŸ¹è®­æˆæœ¬ï¼Œå½“é‡åˆ°ä¸è®­ç»ƒä»»åŠ¡å¤§ä¸ç›¸åŒçš„æ–°å‹ç©ºé—´æ§åˆ¶æ¡ä»¶æ—¶æ›´æ˜¯å¦‚æ­¤ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†é€šç”¨å°æ ·æ§åˆ¶ï¼ˆUniversal Few-Shot Controlï¼Œç®€ç§°UFCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨çš„å°æ ·æ§åˆ¶é€‚é…å™¨ï¼Œèƒ½å¤Ÿæ¨å¹¿åˆ°æ–°å‹ç©ºé—´æ¡ä»¶ã€‚å¯¹äºæœªè§ä»»åŠ¡çš„ä¸€äº›å›¾åƒæ¡ä»¶å¯¹å’ŒæŸ¥è¯¢æ¡ä»¶ï¼ŒUFCåˆ©ç”¨æŸ¥è¯¢å’Œæ”¯æŒæ¡ä»¶ä¹‹é—´çš„ç±»æ¯”æ¥æ„å»ºä»»åŠ¡ç‰¹å®šçš„æ§åˆ¶ç‰¹å¾ï¼Œé€šè¿‡åŒ¹é…æœºåˆ¶å’Œä¸€å°éƒ¨åˆ†ä»»åŠ¡ç‰¹å®šå‚æ•°çš„æ›´æ–°æ¥å®ç°ã€‚åœ¨å…­ä¸ªæ–°å‹ç©ºé—´æ§åˆ¶ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒUFCåªéœ€ç”¨æœªè§ä»»åŠ¡çš„30ä¸ªæ³¨é‡Šç¤ºä¾‹è¿›è¡Œå¾®è°ƒï¼Œå³å¯å®ç°ä¸ç©ºé—´æ¡ä»¶ä¸€è‡´çš„ç²¾ç»†æ§åˆ¶ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨å…¨è®­ç»ƒæ•°æ®çš„0.1%è¿›è¡Œå¾®è°ƒæ—¶ï¼ŒUFCåœ¨å„ç§æ§åˆ¶ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸å®Œå…¨ç›‘ç£çš„åŸºçº¿ç›¸å½“ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†UFCå¯ç‹¬ç«‹äºå„ç§æ‰©æ•£ä¸»å¹²åº”ç”¨ï¼Œå¹¶åœ¨UNetå’ŒDiTæ¶æ„ä¸Šéƒ½è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/kietngt00/UFC%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/kietngt00/UFCæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07530v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç©ºé—´æ¡ä»¶åœ¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å·²ç”¨äºç²¾ç»†æ§åˆ¶ç”Ÿæˆå›¾åƒçš„ç»“æ„ã€‚ç„¶è€Œï¼Œç°æœ‰æ§åˆ¶é€‚é…å™¨åœ¨é¢å¯¹ä¸è®­ç»ƒä»»åŠ¡å¤§ä¸ç›¸åŒçš„æ–°å‹ç©ºé—´æ§åˆ¶æ¡ä»¶æ—¶ï¼Œè¡¨ç°å‡ºæœ‰é™çš„é€‚åº”æ€§å’Œè¾ƒé«˜çš„è®­ç»ƒæˆæœ¬ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†é€šç”¨å°‘æ ·æœ¬æ§åˆ¶ï¼ˆUFCï¼‰ï¼Œä¸€ç§èƒ½å¤Ÿæ¨å¹¿åˆ°æ–°ç©ºé—´æ¡ä»¶çš„é€šç”¨å°‘æ ·æœ¬æ§åˆ¶é€‚é…å™¨ã€‚å¯¹äºæœªè§ä»»åŠ¡çš„æ–°å‹ç©ºé—´æ§åˆ¶æ¡ä»¶ï¼ŒUFCä»…ä½¿ç”¨å°‘é‡å›¾åƒæ¡ä»¶å¯¹å’ŒæŸ¥è¯¢æ¡ä»¶ï¼Œé€šè¿‡ç±»æ¯”æŸ¥è¯¢å’Œæ”¯æŒæ¡ä»¶æ¥æ„å»ºä»»åŠ¡ç‰¹å®šæ§åˆ¶ç‰¹å¾ï¼Œé€šè¿‡åŒ¹é…æœºåˆ¶å’Œæ›´æ–°å°‘é‡ä»»åŠ¡ç‰¹å®šå‚æ•°å®ç°å®ä¾‹åŒ–ã€‚åœ¨å…­ä¸ªæ–°å‹ç©ºé—´æ§åˆ¶ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒUFCä»…é€šè¿‡å¾®è°ƒ30ä¸ªæœªè§ä»»åŠ¡çš„æ ‡æ³¨æ ·æœ¬å³å¯å®ç°ä¸ç©ºé—´æ¡ä»¶ä¸€è‡´çš„ç²¾ç»†æ§åˆ¶ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå½“ä½¿ç”¨å…¨è®­ç»ƒæ•°æ®çš„0.1%è¿›è¡Œå¾®è°ƒæ—¶ï¼ŒUFCåœ¨å„ç§æ§åˆ¶ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸å®Œå…¨ç›‘ç£çš„åŸºçº¿ç›¸å½“ã€‚UFCè¿˜å¯å¹¿æ³›åº”ç”¨äºå„ç§æ‰©æ•£æ¨¡å‹ä¸»å¹²ï¼Œå¹¶åœ¨UNetå’ŒDiTæ¶æ„ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœã€‚ç›¸å…³ä»£ç å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/kietngt00/UFC">https://github.com/kietngt00/UFC</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬-å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„ç©ºé—´æ¡ä»¶å¯¹ç”Ÿæˆå›¾åƒçš„ç»“æ„å…·æœ‰ç²¾ç»†æ§åˆ¶ä½œç”¨ã€‚</li>
<li>ç°æœ‰æ§åˆ¶é€‚é…å™¨åœ¨é¢å¯¹æ–°å‹ç©ºé—´æ§åˆ¶æ¡ä»¶æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>é€šç”¨å°‘æ ·æœ¬æ§åˆ¶ï¼ˆUFCï¼‰é€‚é…å™¨è¢«æå‡ºï¼Œä»¥å…‹æœè¿™ä¸€å±€é™æ€§å¹¶é€‚åº”æ–°ç©ºé—´æ¡ä»¶ã€‚</li>
<li>UFCåˆ©ç”¨å°‘é‡æ ·æœ¬å®ç°å¯¹æ–°ä»»åŠ¡çš„ç²¾ç»†æ§åˆ¶ï¼Œå¹¶è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å½“ä½¿ç”¨å°‘é‡è®­ç»ƒæ•°æ®è¿›è¡Œå¾®è°ƒæ—¶ï¼ŒUFCæ€§èƒ½ä¸å®Œå…¨ç›‘ç£æ–¹æ³•ç›¸å½“ã€‚</li>
<li>UFCé€‚ç”¨äºå¤šç§æ‰©æ•£æ¨¡å‹æ¶æ„ï¼Œå¹¶åœ¨UNetå’ŒDiTä¸ŠéªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07530">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07530v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07530v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LINR-Bridge-Vector-Graphic-Animation-via-Neural-Implicits-and-Video-Diffusion-Priors"><a href="#LINR-Bridge-Vector-Graphic-Animation-via-Neural-Implicits-and-Video-Diffusion-Priors" class="headerlink" title="LINR Bridge: Vector Graphic Animation via Neural Implicits and Video   Diffusion Priors"></a>LINR Bridge: Vector Graphic Animation via Neural Implicits and Video   Diffusion Priors</h2><p><strong>Authors:Wenshuo Gao, Xicheng Lan, Luyao Zhang, Shuai Yang</strong></p>
<p>Vector graphics, known for their scalability and user-friendliness, provide a unique approach to visual content compared to traditional pixel-based images. Animation of these graphics, driven by the motion of their elements, offers enhanced comprehensibility and controllability but often requires substantial manual effort. To automate this process, we propose a novel method that integrates implicit neural representations with text-to-video diffusion models for vector graphic animation. Our approach employs layered implicit neural representations to reconstruct vector graphics, preserving their inherent properties such as infinite resolution and precise color and shape constraints, which effectively bridges the large domain gap between vector graphics and diffusion models. The neural representations are then optimized using video score distillation sampling, which leverages motion priors from pretrained text-to-video diffusion models. Finally, the vector graphics are warped to match the representations resulting in smooth animation. Experimental results validate the effectiveness of our method in generating vivid and natural vector graphic animations, demonstrating significant improvement over existing techniques that suffer from limitations in flexibility and animation quality. </p>
<blockquote>
<p>çŸ¢é‡å›¾å½¢ä»¥å…¶å¯ä¼¸ç¼©æ€§å’Œç”¨æˆ·å‹å¥½æ€§è‘—ç§°ï¼Œä¸ä¼ ç»ŸåŸºäºåƒç´ çš„å›¾åƒç›¸æ¯”ï¼Œä¸ºè§†è§‰å†…å®¹æä¾›äº†ä¸€ç§ç‹¬ç‰¹çš„æ–¹æ³•ã€‚è¿™äº›å›¾å½¢çš„åŠ¨ç”»ï¼Œé€šè¿‡å…¶å…ƒç´ çš„è¿åŠ¨é©±åŠ¨ï¼Œæé«˜äº†å¯ç†è§£æ€§å’Œå¯æ§æ€§ï¼Œä½†é€šå¸¸éœ€è¦å¤§é‡çš„æ‰‹åŠ¨æ“ä½œã€‚ä¸ºäº†è‡ªåŠ¨åŒ–è¿™ä¸€è¿‡ç¨‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†éšå¼ç¥ç»è¡¨ç¤ºä¸æ–‡æœ¬åˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æ–°æ–¹æ³•ï¼Œç”¨äºçŸ¢é‡å›¾å½¢åŠ¨ç”»ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨åˆ†å±‚éšå¼ç¥ç»è¡¨ç¤ºæ¥é‡å»ºçŸ¢é‡å›¾å½¢ï¼Œä¿æŒå…¶å›ºæœ‰çš„æ— é™åˆ†è¾¨ç‡å’Œç²¾ç¡®çš„é¢œè‰²å’Œå½¢çŠ¶çº¦æŸç­‰ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°å¼¥è¡¥äº†çŸ¢é‡å›¾å½¢å’Œæ‰©æ•£æ¨¡å‹ä¹‹é—´çš„å·¨å¤§é¢†åŸŸå·®è·ã€‚ç„¶åï¼Œä½¿ç”¨è§†é¢‘åˆ†æ•°è’¸é¦é‡‡æ ·ä¼˜åŒ–ç¥ç»è¡¨ç¤ºï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹çš„è¿åŠ¨å…ˆéªŒã€‚æœ€åï¼Œå°†çŸ¢é‡å›¾å½¢è¿›è¡Œå˜å½¢ä»¥åŒ¹é…è¡¨ç¤ºç»“æœï¼Œä»è€Œå®ç°å¹³æ»‘çš„åŠ¨ç”»ã€‚å®éªŒç»“æœéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆç”ŸåŠ¨è‡ªç„¶çš„çŸ¢é‡å›¾å½¢åŠ¨ç”»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œåè€…åœ¨çµæ´»æ€§å’ŒåŠ¨ç”»è´¨é‡æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07484v1">PDF</a> 5 pages, ICIPW 2025, Website:   <a target="_blank" rel="noopener" href="https://gaowenshuo.github.io/LINR-bridge/">https://gaowenshuo.github.io/LINR-bridge/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆéšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºä¸æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œç”¨äºçŸ¢é‡å›¾å½¢åŠ¨ç”»çš„è‡ªåŠ¨ç”Ÿæˆã€‚è¯¥æ–¹æ³•é‡‡ç”¨åˆ†å±‚éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºé‡å»ºçŸ¢é‡å›¾å½¢ï¼Œä¿ç•™å…¶æ— é™åˆ†è¾¨ç‡å’Œç²¾ç¡®çš„é¢œè‰²ä¸å½¢çŠ¶çº¦æŸç­‰å›ºæœ‰å±æ€§ï¼Œæœ‰æ•ˆå¼¥åˆäº†çŸ¢é‡å›¾å½¢å’Œæ‰©æ•£æ¨¡å‹ä¹‹é—´çš„é¢†åŸŸå·®è·ã€‚é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„è¿åŠ¨å…ˆéªŒçŸ¥è¯†ï¼Œé‡‡ç”¨è§†é¢‘åˆ†æ•°è’¸é¦é‡‡æ ·å¯¹ç¥ç»ç½‘ç»œè¡¨ç¤ºè¿›è¡Œä¼˜åŒ–ã€‚æœ€ç»ˆï¼Œå°†çŸ¢é‡å›¾å½¢è¿›è¡Œå˜å½¢ä»¥åŒ¹é…è¡¨ç¤ºç»“æœï¼Œä»è€Œå®ç°æµç•…çš„åŠ¨ç”»æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½ç”Ÿæˆç”ŸåŠ¨è‡ªç„¶çš„çŸ¢é‡å›¾å½¢åŠ¨ç”»ï¼Œåœ¨çµæ´»æ€§å’ŒåŠ¨ç”»è´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>çŸ¢é‡å›¾å½¢å…·æœ‰å¯ä¼¸ç¼©æ€§å’Œç”¨æˆ·å‹å¥½æ€§ï¼Œä¸ºè§†è§‰å†…å®¹æä¾›äº†ä¸ä¼ ç»Ÿåƒç´ å›¾åƒä¸åŒçš„ç‹¬ç‰¹æ–¹æ³•ã€‚</li>
<li>çŸ¢é‡å›¾å½¢åŠ¨ç”»å¢å¼ºäº†å¯ç†è§£æ€§å’Œå¯æ§æ€§ï¼Œä½†é€šå¸¸éœ€è¦å¤§é‡æ‰‹åŠ¨å·¥ä½œã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç»“åˆéšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºä¸æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œå®ç°çŸ¢é‡å›¾å½¢åŠ¨ç”»çš„è‡ªåŠ¨åŒ–ã€‚</li>
<li>é‡‡ç”¨åˆ†å±‚éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºé‡å»ºçŸ¢é‡å›¾å½¢ï¼Œä¿ç•™å…¶å›ºæœ‰å±æ€§ï¼Œå¦‚æ— é™åˆ†è¾¨ç‡å’Œç²¾ç¡®çš„é¢œè‰²ä¸å½¢çŠ¶çº¦æŸã€‚</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„è¿åŠ¨å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡è§†é¢‘åˆ†æ•°è’¸é¦é‡‡æ ·ä¼˜åŒ–ç¥ç»ç½‘ç»œè¡¨ç¤ºã€‚</li>
<li>çŸ¢é‡å›¾å½¢å˜å½¢ä»¥åŒ¹é…è¡¨ç¤ºç»“æœï¼Œå®ç°æµç•…åŠ¨ç”»æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07484">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07484v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07484v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07484v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07484v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07484v1/page_4_1.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ANYPORTAL-Zero-Shot-Consistent-Video-Background-Replacement"><a href="#ANYPORTAL-Zero-Shot-Consistent-Video-Background-Replacement" class="headerlink" title="ANYPORTAL: Zero-Shot Consistent Video Background Replacement"></a>ANYPORTAL: Zero-Shot Consistent Video Background Replacement</h2><p><strong>Authors:Wenshuo Gao, Xicheng Lan, Shuai Yang</strong></p>
<p>Despite the rapid advancements in video generation technology, creating high-quality videos that precisely align with user intentions remains a significant challenge. Existing methods often fail to achieve fine-grained control over video details, limiting their practical applicability. We introduce ANYPORTAL, a novel zero-shot framework for video background replacement that leverages pre-trained diffusion models. Our framework collaboratively integrates the temporal prior of video diffusion models with the relighting capabilities of image diffusion models in a zero-shot setting. To address the critical challenge of foreground consistency, we propose a Refinement Projection Algorithm, which enables pixel-level detail manipulation to ensure precise foreground preservation. ANYPORTAL is training-free and overcomes the challenges of achieving foreground consistency and temporally coherent relighting. Experimental results demonstrate that ANYPORTAL achieves high-quality results on consumer-grade GPUs, offering a practical and efficient solution for video content creation and editing. </p>
<blockquote>
<p>å°½ç®¡è§†é¢‘ç”ŸæˆæŠ€æœ¯å‘å±•è¿…é€Ÿï¼Œä½†åˆ›å»ºé«˜è´¨é‡ã€ç²¾ç¡®ç¬¦åˆç”¨æˆ·æ„å›¾çš„è§†é¢‘ä»ç„¶æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•å®ç°å¯¹è§†é¢‘ç»†èŠ‚çš„ç²¾ç»†æ§åˆ¶ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚æˆ‘ä»¬å¼•å…¥äº†ANYPORTALï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè§†é¢‘èƒŒæ™¯æ›¿æ¢çš„æ–°å‹é›¶æ ·æœ¬æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒååŒæ•´åˆè§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶åºå…ˆéªŒçŸ¥è¯†ä¸å›¾åƒæ‰©æ•£æ¨¡å‹çš„é‡æ–°ç…§æ˜èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³å‰æ™¯ä¸€è‡´æ€§çš„å…³é”®æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç²¾ç»†åŒ–æŠ•å½±ç®—æ³•ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿå®ç°åƒç´ çº§åˆ«çš„ç»†èŠ‚æ“ä½œï¼Œç¡®ä¿ç²¾ç¡®ä¿ç•™å‰æ™¯ã€‚ANYPORTALæ— éœ€è®­ç»ƒï¼Œå…‹æœäº†å®ç°å‰æ™¯ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯é‡æ–°ç…§æ˜ç­‰æŒ‘æˆ˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒANYPORTALåœ¨æ¶ˆè´¹çº§GPUä¸Šå–å¾—äº†é«˜è´¨é‡çš„ç»“æœï¼Œä¸ºè§†é¢‘å†…å®¹åˆ›å»ºå’Œç¼–è¾‘æä¾›äº†å®ç”¨ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07472v1">PDF</a> 8 pages, ICCV 2025, Website: <a target="_blank" rel="noopener" href="https://gaowenshuo.github.io/AnyPortal/">https://gaowenshuo.github.io/AnyPortal/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ANYPORTALï¼Œä¸€ç§ç”¨äºè§†é¢‘èƒŒæ™¯æ›¿æ¢çš„æ–°å‹é›¶æ ·æœ¬æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶åºå…ˆéªŒçŸ¥è¯†ä¸å›¾åƒæ‰©æ•£æ¨¡å‹çš„é‡æ–°ç…§æ˜èƒ½åŠ›ã€‚é€šè¿‡ç²¾ç»†åŒ–æŠ•å½±ç®—æ³•ç¡®ä¿å‰æ™¯ç²¾ç¡®ä¿ç•™ï¼Œè§£å†³äº†å‰æ™¯ä¸€è‡´æ€§çš„å…³é”®æŒ‘æˆ˜ã€‚ANYPORTALæ— éœ€è®­ç»ƒï¼Œå…‹æœäº†åœ¨å®ç°å‰æ™¯ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§é‡æ–°ç…§æ˜æ–¹é¢çš„æŒ‘æˆ˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒANYPORTALåœ¨æ¶ˆè´¹è€…çº§GPUä¸Šå–å¾—äº†é«˜è´¨é‡çš„ç»“æœï¼Œä¸ºè§†é¢‘å†…å®¹åˆ›å»ºå’Œç¼–è¾‘æä¾›äº†å®ç”¨ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ANYPORTALæ˜¯ä¸€ä¸ªç”¨äºè§†é¢‘èƒŒæ™¯æ›¿æ¢çš„æ–°å‹é›¶æ ·æœ¬æ¡†æ¶ã€‚</li>
<li>å®ƒç»“åˆäº†è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶åºå…ˆéªŒä¸å›¾åƒæ‰©æ•£æ¨¡å‹çš„é‡æ–°ç…§æ˜èƒ½åŠ›ã€‚</li>
<li>è§£å†³äº†å‰æ™¯ä¸€è‡´æ€§çš„å…³é”®æŒ‘æˆ˜ï¼Œé€šè¿‡ç²¾ç»†åŒ–æŠ•å½±ç®—æ³•ç¡®ä¿å‰æ™¯ç²¾ç¡®ä¿ç•™ã€‚</li>
<li>ANYPORTALæ— éœ€è®­ç»ƒï¼Œèƒ½å¤Ÿå…‹æœå®ç°å‰æ™¯ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§é‡æ–°ç…§æ˜çš„æŒ‘æˆ˜ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½åœ¨æ¶ˆè´¹è€…çº§GPUä¸Šè¿è¡Œï¼Œå…·å¤‡å®ç”¨æ€§å’Œé«˜æ•ˆæ€§ã€‚</li>
<li>ANYPORTALé€‚ç”¨äºè§†é¢‘å†…å®¹åˆ›å»ºå’Œç¼–è¾‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07472">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07472v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07472v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07472v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07472v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07472v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07472v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DreamLifting-A-Plug-in-Module-Lifting-MV-Diffusion-Models-for-3D-Asset-Generation"><a href="#DreamLifting-A-Plug-in-Module-Lifting-MV-Diffusion-Models-for-3D-Asset-Generation" class="headerlink" title="DreamLifting: A Plug-in Module Lifting MV Diffusion Models for 3D Asset   Generation"></a>DreamLifting: A Plug-in Module Lifting MV Diffusion Models for 3D Asset   Generation</h2><p><strong>Authors:Ze-Xin Yin, Jiaxiong Qiu, Liu Liu, Xinjie Wang, Wei Sui, Zhizhong Su, Jian Yang, Jin Xie</strong></p>
<p>The labor- and experience-intensive creation of 3D assets with physically based rendering (PBR) materials demands an autonomous 3D asset creation pipeline. However, most existing 3D generation methods focus on geometry modeling, either baking textures into simple vertex colors or leaving texture synthesis to post-processing with image diffusion models. To achieve end-to-end PBR-ready 3D asset generation, we present Lightweight Gaussian Asset Adapter (LGAA), a novel framework that unifies the modeling of geometry and PBR materials by exploiting multi-view (MV) diffusion priors from a novel perspective. The LGAA features a modular design with three components. Specifically, the LGAA Wrapper reuses and adapts network layers from MV diffusion models, which encapsulate knowledge acquired from billions of images, enabling better convergence in a data-efficient manner. To incorporate multiple diffusion priors for geometry and PBR synthesis, the LGAA Switcher aligns multiple LGAA Wrapper layers encapsulating different knowledge. Then, a tamed variational autoencoder (VAE), termed LGAA Decoder, is designed to predict 2D Gaussian Splatting (2DGS) with PBR channels. Finally, we introduce a dedicated post-processing procedure to effectively extract high-quality, relightable mesh assets from the resulting 2DGS. Extensive quantitative and qualitative experiments demonstrate the superior performance of LGAA with both text-and image-conditioned MV diffusion models. Additionally, the modular design enables flexible incorporation of multiple diffusion priors, and the knowledge-preserving scheme leads to efficient convergence trained on merely 69k multi-view instances. Our code, pre-trained weights, and the dataset used will be publicly available via our project page: <a target="_blank" rel="noopener" href="https://zx-yin.github.io/dreamlifting/">https://zx-yin.github.io/dreamlifting/</a>. </p>
<blockquote>
<p>ä»¥ç‰©ç†ä¸ºåŸºç¡€æ¸²æŸ“ï¼ˆPBRï¼‰ææ–™çš„3Dèµ„äº§åˆ›å»ºéœ€è¦è€—è´¹åŠ³åŠ¨åŠ›å’Œç»éªŒï¼Œè¿™éœ€è¦ä¸€ä¸ªè‡ªä¸»çš„3Dèµ„äº§åˆ›å»ºæµç¨‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤§å¤šæ•°3Dç”Ÿæˆæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å‡ ä½•å»ºæ¨¡ä¸Šï¼Œè¦ä¹ˆå°†çº¹ç†çƒ˜ç„™æˆç®€å•çš„é¡¶ç‚¹é¢œè‰²ï¼Œè¦ä¹ˆå°†çº¹ç†åˆæˆç•™ç»™ä½¿ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹çš„åæœŸå¤„ç†ã€‚ä¸ºäº†å®ç°ç«¯åˆ°ç«¯çš„PBRå‡†å¤‡3Dèµ„äº§ç”Ÿæˆï¼Œæˆ‘ä»¬æå‡ºäº†è½»é‡åŒ–é«˜æ–¯èµ„äº§é€‚é…å™¨ï¼ˆLGAAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨å¤šè§†å›¾ï¼ˆMVï¼‰æ‰©æ•£å…ˆéªŒå› ç´ ä»å…¨æ–°è§’åº¦å¯¹å‡ ä½•å’ŒPBRææ–™è¿›è¡Œå»ºæ¨¡ã€‚LGAAå…·æœ‰æ¨¡å—åŒ–è®¾è®¡ï¼ŒåŒ…å«ä¸‰ä¸ªç»„ä»¶ã€‚å…·ä½“æ¥è¯´ï¼ŒLGAAåŒ…è£…å™¨é‡ç”¨å¹¶é€‚åº”MVæ‰©æ•£æ¨¡å‹çš„ç½‘ç»œå±‚ï¼Œè¿™äº›ç½‘ç»œå±‚å°è£…äº†ä»æ•°åäº¿å¼ å›¾åƒä¸­è·å¾—çš„çŸ¥è¯†ï¼Œä»¥æ•°æ®é«˜æ•ˆçš„æ–¹å¼å®ç°äº†æ›´å¥½çš„æ”¶æ•›ã€‚ä¸ºäº†å°†å¤šä¸ªæ‰©æ•£å…ˆéªŒå› ç´ èå…¥å‡ ä½•å’ŒPBRåˆæˆä¸­ï¼ŒLGAAåˆ‡æ¢å™¨å¯¹é½å¤šä¸ªå°è£…ä¸åŒçŸ¥è¯†çš„LGAAåŒ…è£…å™¨å±‚ã€‚ç„¶åï¼Œè®¾è®¡äº†ä¸€ä¸ªé©¯åŒ–çš„å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ï¼Œç§°ä¸ºLGAAè§£ç å™¨ï¼Œç”¨äºé¢„æµ‹å¸¦æœ‰PBRé€šé“çš„2Dé«˜æ–¯å–·ç»˜ï¼ˆ2DGSï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¸“é—¨çš„åæœŸå¤„ç†ç¨‹åºï¼Œä»ç”Ÿæˆçš„2DGSä¸­æå–é«˜è´¨é‡ã€å¯é‡æ–°ç…§æ˜çš„ç½‘æ ¼èµ„äº§ã€‚å¤§é‡çš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒLGAAåœ¨æ–‡æœ¬å’Œå›¾åƒæ¡ä»¶ä¸‹çš„MVæ‰©æ•£æ¨¡å‹ä¸­çš„å“è¶Šæ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ¨¡å—åŒ–è®¾è®¡ä½¿å¾—å¯ä»¥çµæ´»åœ°èå…¥å¤šä¸ªæ‰©æ•£å…ˆéªŒå› ç´ ï¼ŒçŸ¥è¯†ä¿ç•™æ–¹æ¡ˆåœ¨ä»…ä½¿ç”¨69kå¤šè§†å›¾å®ä¾‹è¿›è¡Œè®­ç»ƒæ—¶å®ç°äº†æœ‰æ•ˆçš„æ”¶æ•›ã€‚æˆ‘ä»¬çš„ä»£ç ã€é¢„è®­ç»ƒæƒé‡å’Œä½¿ç”¨çš„æ•°æ®é›†å°†é€šè¿‡æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å…¬å¼€å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://zx-yin.github.io/dreamlifting/%E3%80%82">https://zx-yin.github.io/dreamlifting/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07435v1">PDF</a> 14 pages, 7 figures, project page:   <a target="_blank" rel="noopener" href="https://zx-yin.github.io/dreamlifting/">https://zx-yin.github.io/dreamlifting/</a></p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§åä¸ºLGAAï¼ˆè½»é‡åŒ–é«˜æ–¯èµ„äº§é€‚é…å™¨ï¼‰çš„æ–°æ¡†æ¶ï¼Œå®ç°äº†åŸºäºç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰çš„ç«¯åˆ°ç«¯çš„ä¸‰ç»´èµ„äº§ç”Ÿæˆã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨å¤šè§†è§’ï¼ˆMVï¼‰æ‰©æ•£å…ˆéªŒä¿¡æ¯ï¼Œç»Ÿä¸€äº†å‡ ä½•å»ºæ¨¡å’ŒPBRæè´¨å»ºæ¨¡ã€‚é€šè¿‡å¤ç”¨å’Œè°ƒæ•´MVæ‰©æ•£æ¨¡å‹çš„ç½‘ç»œå±‚ï¼ŒLGAAèƒ½å¤Ÿåœ¨æ•°æ®é«˜æ•ˆçš„æƒ…å†µä¸‹å®ç°æ›´å¥½çš„æ”¶æ•›æ•ˆæœã€‚è¯¥æ¡†æ¶åŒ…å«LGAAåŒ…è£…å™¨ã€LGAAäº¤æ¢æœºå’ŒLGAAè§£ç å™¨ä¸‰ä¸ªç»„ä»¶ï¼Œé¢„æµ‹å…·æœ‰PBRé€šé“çš„äºŒç»´é«˜æ–¯å–·æ¶‚ç»“æœã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸“é—¨çš„åæœŸå¤„ç†æµç¨‹ï¼Œå¯ä»¥ä»ç»“æœä¸­æå–é«˜è´¨é‡çš„å¯é‡æ–°ç…§æ˜ç½‘æ ¼èµ„äº§ã€‚è¯¥æ¡†æ¶åœ¨å¤šè§†è§’æ‰©æ•£æ¨¡å‹ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå¹¶ä¸”å…¶æ¨¡å—åŒ–è®¾è®¡ä½¿å¾—å¯ä»¥çµæ´»åœ°å¼•å…¥å¤šç§æ‰©æ•£å…ˆéªŒä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åä¸ºLGAAçš„æ–°æ¡†æ¶ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„ä¸‰ç»´èµ„äº§ç”Ÿæˆï¼Œæ”¯æŒåŸºäºç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰æè´¨ã€‚</li>
<li>åˆ©ç”¨å¤šè§†è§’ï¼ˆMVï¼‰æ‰©æ•£å…ˆéªŒä¿¡æ¯ï¼Œç»Ÿä¸€äº†å‡ ä½•å»ºæ¨¡å’ŒPBRæè´¨å»ºæ¨¡ã€‚</li>
<li>é€šè¿‡å¤ç”¨å’Œè°ƒæ•´MVæ‰©æ•£æ¨¡å‹çš„ç½‘ç»œå±‚ï¼Œå®ç°äº†æ•°æ®é«˜æ•ˆä¸‹çš„è‰¯å¥½æ”¶æ•›æ•ˆæœã€‚</li>
<li>LGAAæ¡†æ¶åŒ…å«ä¸‰ä¸ªç»„ä»¶ï¼šLGAAåŒ…è£…å™¨ã€LGAAäº¤æ¢æœºå’ŒLGAAè§£ç å™¨ï¼Œé¢„æµ‹å…·æœ‰PBRé€šé“çš„äºŒç»´é«˜æ–¯å–·æ¶‚ç»“æœã€‚</li>
<li>å¼•å…¥äº†ä¸“é—¨çš„åæœŸå¤„ç†æµç¨‹ï¼Œå¯ä»¥ä»ç»“æœä¸­æå–é«˜è´¨é‡çš„å¯é‡æ–°ç…§æ˜ç½‘æ ¼èµ„äº§ã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨å¤šè§†è§’æ‰©æ•£æ¨¡å‹ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07435">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07435v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07435v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07435v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07435v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Knowledge-Distillation-Driven-Semantic-NOMA-for-Image-Transmission-with-Diffusion-Model"><a href="#Knowledge-Distillation-Driven-Semantic-NOMA-for-Image-Transmission-with-Diffusion-Model" class="headerlink" title="Knowledge Distillation Driven Semantic NOMA for Image Transmission with   Diffusion Model"></a>Knowledge Distillation Driven Semantic NOMA for Image Transmission with   Diffusion Model</h2><p><strong>Authors:Qifei Wang, Zhen Gao, Zhijin Qin, Xiaodong Xu, Meixia Tao</strong></p>
<p>As a promising 6G enabler beyond conventional bit-level transmission, semantic communication can considerably reduce required bandwidth resources, while its combination with multiple access requires further exploration. This paper proposes a knowledge distillation-driven and diffusion-enhanced (KDD) semantic non-orthogonal multiple access (NOMA), named KDD-SemNOMA, for multi-user uplink wireless image transmission. Specifically, to ensure robust feature transmission across diverse transmission conditions, we firstly develop a ConvNeXt-based deep joint source and channel coding architecture with enhanced adaptive feature module. This module incorporates signal-to-noise ratio and channel state information to dynamically adapt to additive white Gaussian noise and Rayleigh fading channels. Furthermore, to improve image restoration quality without inference overhead, we introduce a two-stage knowledge distillation strategy, i.e., a teacher model, trained on interference-free orthogonal transmission, guides a student model via feature affinity distillation and cross-head prediction distillation. Moreover, a diffusion model-based refinement stage leverages generative priors to transform initial SemNOMA outputs into high-fidelity images with enhanced perceptual quality. Extensive experiments on CIFAR-10 and FFHQ-256 datasets demonstrate superior performance over state-of-the-art methods, delivering satisfactory reconstruction performance even at extremely poor channel conditions. These results highlight the advantages in both pixel-level accuracy and perceptual metrics, effectively mitigating interference and enabling high-quality image recovery. </p>
<blockquote>
<p>ä½œä¸ºä¸€ç§æœ‰æœ›è¶…è¶Šä¼ ç»Ÿä½çº§ä¼ è¾“çš„6GæŠ€æœ¯ï¼Œè¯­ä¹‰é€šä¿¡å¯ä»¥å¤§å¤§å‡å°‘æ‰€éœ€çš„å¸¦å®½èµ„æºï¼Œè€Œå°†å…¶ä¸å¤šç§æ¥å…¥æŠ€æœ¯ç›¸ç»“åˆéœ€è¦è¿›ä¸€æ­¥æ¢ç´¢ã€‚æœ¬æ–‡é’ˆå¯¹å¤šç”¨æˆ·ä¸Šè¡Œæ— çº¿å›¾åƒä¼ è¾“ï¼Œæå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†è’¸é¦å’Œæ‰©æ•£å¢å¼ºï¼ˆKDDï¼‰çš„è¯­ä¹‰éæ­£äº¤å¤šå€æ¥å…¥ï¼ˆNOMAï¼‰ï¼Œåä¸ºKDD-SemNOMAã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†ç¡®ä¿åœ¨å„ç§ä¼ è¾“æ¡ä»¶ä¸‹ç‰¹å¾ä¼ è¾“çš„ç¨³å¥æ€§ï¼Œæˆ‘ä»¬é¦–å…ˆå¼€å‘äº†ä¸€ç§åŸºäºConvNeXtçš„æ·±åº¦è”åˆæºä¿¡é“ç¼–ç æ¶æ„ï¼Œè¯¥æ¶æ„å…·æœ‰å¢å¼ºçš„è‡ªé€‚åº”ç‰¹å¾æ¨¡å—ã€‚è¯¥æ¨¡å—ç»“åˆäº†ä¿¡å™ªæ¯”å’Œä¿¡é“çŠ¶æ€ä¿¡æ¯ï¼Œä»¥åŠ¨æ€é€‚åº”åŠ æ€§ç™½é«˜æ–¯å™ªå£°å’Œç‘åˆ©è¡°è½ä¿¡é“ã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜å›¾åƒæ¢å¤è´¨é‡è€Œæ— éœ€æ¨ç†å¼€é”€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µçŸ¥è¯†è’¸é¦ç­–ç•¥ï¼Œå³ä¸€ä¸ªæ•™å¸ˆæ¨¡å‹åœ¨å¹²æ‰°è‡ªç”±çš„æ­£äº¤ä¼ è¾“ä¸Šè¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡ç‰¹å¾äº²å’ŒåŠ›è’¸é¦å’Œè·¨å¤´é¢„æµ‹è’¸é¦æ¥æŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹ã€‚è€Œä¸”ï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„ç»†åŒ–é˜¶æ®µåˆ©ç”¨ç”Ÿæˆå…ˆéªŒå°†åˆå§‹çš„SemNOMAè¾“å‡ºè½¬æ¢ä¸ºå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¢å¼ºæ„ŸçŸ¥è´¨é‡çš„å›¾åƒã€‚åœ¨CIFAR-10å’ŒFFHQ-256æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå³ä½¿åœ¨æå·®çš„ä¿¡é“æ¡ä»¶ä¸‹ä¹Ÿèƒ½å®ç°ä»¤äººæ»¡æ„çš„é‡å»ºæ€§èƒ½ã€‚è¿™äº›ç»“æœçªå‡ºäº†åƒç´ çº§ç²¾åº¦å’Œæ„ŸçŸ¥æŒ‡æ ‡æ–¹é¢çš„ä¼˜åŠ¿ï¼Œæœ‰æ•ˆåœ°å‡è½»äº†å¹²æ‰°ï¼Œå¹¶å®ç°äº†é«˜è´¨é‡å›¾åƒçš„æ¢å¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07363v1">PDF</a> 13 pages, submitted to IEEE for possible publication</p>
<p><strong>Summary</strong><br>     è¯­ä¹‰é€šä¿¡ä½œä¸ºæœ‰æœ›çš„6GæŠ€æœ¯ï¼Œèƒ½æœ‰æ•ˆå‡å°‘å¸¦å®½éœ€æ±‚ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºçŸ¥è¯†è’¸é¦å’Œæ‰©æ•£å¢å¼ºï¼ˆKDDï¼‰çš„è¯­ä¹‰éæ­£äº¤å¤šå€æ¥å…¥ï¼ˆNOMAï¼‰ï¼Œåä¸ºKDD-SemNOMAï¼Œç”¨äºå¤šç”¨æˆ·ä¸Šè¡Œæ— çº¿å›¾åƒä¼ è¾“ã€‚ç ”ç©¶ä¸­è®¾è®¡äº†è”åˆæºä¿¡é“ç¼–ç æ¶æ„ï¼Œå¼•å…¥ä¸¤é˜¶æ®µçŸ¥è¯†è’¸é¦ç­–ç•¥æå‡å›¾åƒå¤åŸè´¨é‡ï¼Œå¹¶é‡‡ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œç²¾ç»†ä¼˜åŒ–ã€‚å®éªŒç»“æœå±•ç¤ºå…¶åœ¨å¤æ‚ä¿¡é“ç¯å¢ƒä¸‹çš„ä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­ä¹‰é€šä¿¡ä½œä¸º6Gæ½œåŠ›æŠ€æœ¯ï¼Œèƒ½æ˜¾è‘—é™ä½å¸¦å®½éœ€æ±‚ã€‚</li>
<li>æå‡ºKDD-SemNOMAæ–¹æ¡ˆï¼Œç»“åˆçŸ¥è¯†è’¸é¦å’Œæ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¤šç”¨æˆ·ä¸Šè¡Œæ— çº¿å›¾åƒä¼ è¾“ã€‚</li>
<li>è®¾è®¡æ·±åº¦è”åˆæºä¿¡é“ç¼–ç æ¶æ„ï¼Œèå…¥ä¿¡å·å™ªå£°æ¯”å’Œä¿¡é“çŠ¶æ€ä¿¡æ¯ä»¥é€‚åº”ä¸åŒä¼ è¾“ç¯å¢ƒã€‚</li>
<li>å¼•å…¥ä¸¤é˜¶æ®µçŸ¥è¯†è’¸é¦ç­–ç•¥ï¼Œæå‡å›¾åƒå¤åŸè´¨é‡ä¸”ä¸å­˜åœ¨æ¨ç†å¼€é”€ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹ç”¨äºå›¾åƒç²¾ç»†ä¼˜åŒ–ï¼Œç”Ÿæˆé«˜ä¿çœŸå›¾åƒã€‚</li>
<li>å®éªŒç»“æœå±•ç¤ºåœ¨å¤æ‚ä¿¡é“ç¯å¢ƒä¸‹ä¼˜è¶Šæ€§èƒ½ï¼ŒåŒ…æ‹¬åƒç´ çº§ç²¾åº¦å’Œæ„ŸçŸ¥æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07363">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07363v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07363v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07363v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07363v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.07363v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Missing-Fine-Details-in-Images-Last-Seen-in-High-Frequencies"><a href="#Missing-Fine-Details-in-Images-Last-Seen-in-High-Frequencies" class="headerlink" title="Missing Fine Details in Images: Last Seen in High Frequencies"></a>Missing Fine Details in Images: Last Seen in High Frequencies</h2><p><strong>Authors:Tejaswini Medi, Hsien-Yi Wang, Arianna Rampini, Margret Keuper</strong></p>
<p>Latent generative models have shown remarkable progress in high-fidelity image synthesis, typically using a two-stage training process that involves compressing images into latent embeddings via learned tokenizers in the first stage. The quality of generation strongly depends on how expressive and well-optimized these latent embeddings are. While various methods have been proposed to learn effective latent representations, generated images often lack realism, particularly in textured regions with sharp transitions, due to loss of fine details governed by high frequencies. We conduct a detailed frequency decomposition of existing state-of-the-art (SOTA) latent tokenizers and show that conventional objectives inherently prioritize low-frequency reconstruction, often at the expense of high-frequency fidelity. Our analysis reveals these latent tokenizers exhibit a bias toward low-frequency information during optimization, leading to over-smoothed outputs and visual artifacts that diminish perceptual quality. To address this, we propose a wavelet-based, frequency-aware variational autoencoder (FA-VAE) framework that explicitly decouples the optimization of low- and high-frequency components. This decoupling enables improved reconstruction of fine textures while preserving global structure. Moreover, we integrate our frequency-preserving latent embeddings into a SOTA latent diffusion model, resulting in sharper and more realistic image generation. Our approach bridges the fidelity gap in current latent tokenizers and emphasizes the importance of frequency-aware optimization for realistic image synthesis, with broader implications for applications in content creation, neural rendering, and medical imaging. </p>
<blockquote>
<p>æ½œåœ¨ç”Ÿæˆæ¨¡å‹åœ¨é«˜ä¿çœŸå›¾åƒåˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ï¼Œé€šå¸¸é‡‡ç”¨æ¶‰åŠä¸¤é˜¶æ®µè®­ç»ƒè¿‡ç¨‹çš„æ¨¡å‹ã€‚ç¬¬ä¸€é˜¶æ®µæ˜¯é€šè¿‡å­¦ä¹ åˆ°çš„åˆ†è¯å™¨å°†å›¾åƒå‹ç¼©æˆæ½œåœ¨åµŒå…¥ã€‚ç”Ÿæˆå›¾åƒçš„è´¨é‡å¼ºçƒˆä¾èµ–äºè¿™äº›æ½œåœ¨åµŒå…¥çš„è¡¨è¾¾èƒ½åŠ›å’Œä¼˜åŒ–ç¨‹åº¦ã€‚è™½ç„¶å·²æå‡ºäº†å„ç§æ–¹æ³•æ¥å­¦ä¹ æœ‰æ•ˆçš„æ½œåœ¨è¡¨ç¤ºï¼Œä½†ç”±äºé«˜é¢‘æŸå¤±å¯¼è‡´çš„ç»†èŠ‚ä¸¢å¤±ï¼Œç”Ÿæˆçš„å›¾åƒé€šå¸¸ç¼ºä¹çœŸå®æ„Ÿï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†åŒºåŸŸæœ‰é”åˆ©è¿‡æ¸¡çš„åŒºåŸŸã€‚æˆ‘ä»¬å¯¹ç°æœ‰çš„æœ€å…ˆè¿›çš„æ½œåœ¨åˆ†è¯å™¨è¿›è¡Œäº†è¯¦ç»†çš„é¢‘ç‡åˆ†è§£ï¼Œå¹¶è¡¨æ˜ä¼ ç»Ÿç›®æ ‡æœ¬è´¨ä¸Šä¼˜å…ˆè¿›è¡Œä½é¢‘é‡å»ºï¼Œå¾€å¾€ä»¥é«˜é¢‘ä¿çœŸåº¦ä¸ºä»£ä»·ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œè¿™äº›æ½œåœ¨åˆ†è¯å™¨åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å­˜åœ¨åå‘äºä½é¢‘ä¿¡æ¯çš„å€¾å‘ï¼Œå¯¼è‡´è¾“å‡ºè¿‡äºå¹³æ»‘å’Œè§†è§‰å¤±çœŸï¼Œé™ä½äº†æ„ŸçŸ¥è´¨é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå°æ³¢ã€å…·æœ‰é¢‘ç‡æ„ŸçŸ¥èƒ½åŠ›çš„å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆFA-VAEï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ˜¾å¼åœ°è§£è€¦äº†ä½é¢‘å’Œé«˜é¢‘ç»„ä»¶çš„ä¼˜åŒ–ã€‚è¿™ç§è§£è€¦èƒ½å¤Ÿåœ¨ä¿ç•™å…¨å±€ç»“æ„çš„åŒæ—¶ï¼Œæ”¹å–„ç²¾ç»†çº¹ç†çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†é¢‘ç‡ä¿ç•™çš„æ½œåœ¨åµŒå…¥é›†æˆåˆ°æœ€å…ˆè¿›çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä»è€Œç”Ÿæˆæ›´æ¸…æ™°ã€æ›´é€¼çœŸçš„å›¾åƒã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼¥è¡¥äº†å½“å‰æ½œåœ¨åˆ†è¯å™¨ä¸­çš„ä¿çœŸåº¦å·®è·ï¼Œå¹¶å¼ºè°ƒäº†é¢‘ç‡æ„ŸçŸ¥ä¼˜åŒ–åœ¨çœŸå®å›¾åƒåˆæˆä¸­çš„é‡è¦æ€§ï¼Œä¸ºå†…å®¹åˆ›å»ºã€ç¥ç»æ¸²æŸ“å’ŒåŒ»å­¦æˆåƒç­‰é¢†åŸŸå¸¦æ¥æ›´å¹¿æ³›çš„åº”ç”¨å½±å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05441v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ½œåœ¨ç”Ÿæˆæ¨¡å‹åœ¨é«˜ä¿çœŸå›¾åƒåˆæˆä¸­çš„æœ€æ–°è¿›å±•ã€‚æ–‡ç« æŒ‡å‡ºï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ä¸¤é˜¶æ®µè®­ç»ƒè¿‡ç¨‹ï¼Œç¬¬ä¸€é˜¶æ®µé€šè¿‡å­¦åˆ°çš„æ ‡è®°å™¨å°†å›¾åƒå‹ç¼©ä¸ºæ½œåœ¨åµŒå…¥ã€‚ç”Ÿæˆå›¾åƒçš„è´¨é‡å¼ºçƒˆä¾èµ–äºè¿™äº›æ½œåœ¨åµŒå…¥çš„è¡¨è¾¾æ€§å’Œä¼˜åŒ–ç¨‹åº¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸å¿½è§†é«˜é¢‘ä¿¡æ¯çš„æŸå¤±ï¼Œå¯¼è‡´çº¹ç†åŒºåŸŸè¿‡æ¸¡å°–é”çš„éƒ¨åˆ†ç¼ºä¹çœŸå®æ„Ÿã€‚ä¸ºæ­¤ï¼Œä½œè€…è¿›è¡Œäº†ä¸€é¡¹é’ˆå¯¹å½“å‰æœ€å…ˆè¿›çš„æ½œåœ¨æ ‡è®°å™¨çš„é¢‘ç‡åˆ†è§£ç ”ç©¶ï¼Œå‘ç°ä¼ ç»Ÿç›®æ ‡åœ¨ä¼˜åŒ–æ—¶å€¾å‘äºä½é¢‘é‡å»ºï¼Œç‰ºç‰²äº†é«˜é¢‘ä¿çœŸåº¦ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº†åŸºäºå°æ³¢çš„é¢‘ç‡æ„ŸçŸ¥å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆFA-VAEï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ˜ç¡®è§£è€¦äº†ä½é¢‘å’Œé«˜é¢‘ç»„ä»¶çš„ä¼˜åŒ–ã€‚é€šè¿‡å°†è¿™ç§é¢‘ç‡æ„ŸçŸ¥çš„æ½œåœ¨åµŒå…¥æ•´åˆåˆ°æœ€å…ˆè¿›çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½œè€…å®ç°äº†æ›´æ¸…æ™°ã€æ›´çœŸå®çš„å›¾åƒç”Ÿæˆã€‚è¯¥ç ”ç©¶ä¸ºå½“å‰æ½œåœ¨æ ‡è®°å™¨ä¸­çš„ä¿çœŸåº¦å·®è·æ­èµ·äº†æ¡¥æ¢ï¼Œå¹¶å¼ºè°ƒäº†é¢‘ç‡æ„ŸçŸ¥ä¼˜åŒ–åœ¨çœŸå®å›¾åƒåˆæˆä¸­çš„é‡è¦æ€§ï¼Œä¸ºå†…å®¹åˆ›å»ºã€ç¥ç»æ¸²æŸ“å’ŒåŒ»å­¦æˆåƒç­‰åº”ç”¨å¸¦æ¥äº†æ›´å¹¿æ³›çš„å¯ç¤ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ½œåœ¨ç”Ÿæˆæ¨¡å‹ç”¨äºé«˜ä¿çœŸå›¾åƒåˆæˆå·²æ˜¾ç¤ºå‡ºæ˜¾è‘—è¿›å±•ï¼Œä½†ç”Ÿæˆå›¾åƒåœ¨çº¹ç†åŒºåŸŸç¼ºä¹çœŸå®æ„Ÿã€‚</li>
<li>ç°æœ‰æœ€å…ˆè¿›çš„æ½œåœ¨æ ‡è®°å™¨åœ¨ä¼˜åŒ–æ—¶å­˜åœ¨åå‘ï¼Œæ›´æ³¨é‡ä½é¢‘ä¿¡æ¯çš„é‡å»ºï¼Œç‰ºç‰²äº†é«˜é¢‘ä¿çœŸåº¦ã€‚</li>
<li>å¸¸è§„ç›®æ ‡åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­çš„é¢‘ç‡åé‡å¯¼è‡´è¾“å‡ºå›¾åƒè¿‡äºå¹³æ»‘ï¼Œå‡ºç°è§†è§‰å¤±çœŸã€‚</li>
<li>æå‡ºäº†åŸºäºå°æ³¢çš„é¢‘ç‡æ„ŸçŸ¥å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆFA-VAEï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿè§£è€¦ä½é¢‘å’Œé«˜é¢‘ç»„ä»¶çš„ä¼˜åŒ–ï¼Œæ”¹å–„çº¹ç†çš„é‡å»ºå¹¶ä¿ç•™å…¨å±€ç»“æ„ã€‚</li>
<li>å°†é¢‘ç‡æ„ŸçŸ¥çš„æ½œåœ¨åµŒå…¥æ•´åˆåˆ°æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ç°äº†æ›´æ¸…æ™°ã€æ›´çœŸå®çš„å›¾åƒç”Ÿæˆã€‚</li>
<li>ç ”ç©¶å¼ºè°ƒäº†é¢‘ç‡æ„ŸçŸ¥ä¼˜åŒ–åœ¨çœŸå®å›¾åƒåˆæˆä¸­çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05441">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.05441v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.05441v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.05441v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.05441v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2509.05441v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="SGDFuse-SAM-Guided-Diffusion-for-High-Fidelity-Infrared-and-Visible-Image-Fusion"><a href="#SGDFuse-SAM-Guided-Diffusion-for-High-Fidelity-Infrared-and-Visible-Image-Fusion" class="headerlink" title="SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible   Image Fusion"></a>SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible   Image Fusion</h2><p><strong>Authors:Xiaoyang Zhang, jinjiang Li, Guodong Fan, Yakun Ju, Linwei Fan, Jun Liu, Alex C. Kot</strong></p>
<p>Infrared and visible image fusion (IVIF) aims to combine the thermal radiation information from infrared images with the rich texture details from visible images to enhance perceptual capabilities for downstream visual tasks. However, existing methods often fail to preserve key targets due to a lack of deep semantic understanding of the scene, while the fusion process itself can also introduce artifacts and detail loss, severely compromising both image quality and task performance. To address these issues, this paper proposes SGDFuse, a conditional diffusion model guided by the Segment Anything Model (SAM), to achieve high-fidelity and semantically-aware image fusion. The core of our method is to utilize high-quality semantic masks generated by SAM as explicit priors to guide the optimization of the fusion process via a conditional diffusion model. Specifically, the framework operates in a two-stage process: it first performs a preliminary fusion of multi-modal features, and then utilizes the semantic masks from SAM jointly with the preliminary fused image as a condition to drive the diffusion modelâ€™s coarse-to-fine denoising generation. This ensures the fusion process not only has explicit semantic directionality but also guarantees the high fidelity of the final result. Extensive experiments demonstrate that SGDFuse achieves state-of-the-art performance in both subjective and objective evaluations, as well as in its adaptability to downstream tasks, providing a powerful solution to the core challenges in image fusion. The code of SGDFuse is available at <a target="_blank" rel="noopener" href="https://github.com/boshizhang123/SGDFuse">https://github.com/boshizhang123/SGDFuse</a>. </p>
<blockquote>
<p>çº¢å¤–ä¸å¯è§å…‰å›¾åƒèåˆï¼ˆIVIFï¼‰æ—¨åœ¨å°†çº¢å¤–å›¾åƒä¸­çš„çƒ­è¾å°„ä¿¡æ¯ä¸å¯è§å…‰å›¾åƒä¸­çš„ä¸°å¯Œçº¹ç†ç»†èŠ‚ç›¸ç»“åˆï¼Œä»¥æé«˜ä¸‹æ¸¸è§†è§‰ä»»åŠ¡çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ç”±äºç¼ºä¹åœºæ™¯çš„æ·±åº¦è¯­ä¹‰ç†è§£è€Œæ— æ³•ä¿ç•™å…³é”®ç›®æ ‡ï¼ŒåŒæ—¶èåˆè¿‡ç¨‹æœ¬èº«ä¹Ÿå¯èƒ½å¼•å…¥ä¼ªå½±å’Œç»†èŠ‚æŸå¤±ï¼Œä¸¥é‡æŸå®³å›¾åƒè´¨é‡å’Œä»»åŠ¡æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†SGDFuseï¼Œä¸€ä¸ªç”±Segment Anything Modelï¼ˆSAMï¼‰å¼•å¯¼çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œå®ç°é«˜ä¿çœŸå’Œè¯­ä¹‰æ„ŸçŸ¥çš„å›¾åƒèåˆã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯åˆ©ç”¨SAMç”Ÿæˆçš„é«˜è´¨é‡è¯­ä¹‰æ©è†œä½œä¸ºæ˜ç¡®å…ˆéªŒï¼Œé€šè¿‡æ¡ä»¶æ‰©æ•£æ¨¡å‹æŒ‡å¯¼èåˆè¿‡ç¨‹çš„ä¼˜åŒ–ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆè¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾çš„åˆæ­¥èåˆï¼Œç„¶ååˆ©ç”¨SAMçš„è¯­ä¹‰æ©è†œä¸åˆæ­¥èåˆå›¾åƒä½œä¸ºæ¡ä»¶ï¼Œé©±åŠ¨æ‰©æ•£æ¨¡å‹çš„ä»ç²—åˆ°ç»†çš„é™å™ªç”Ÿæˆã€‚è¿™ç¡®ä¿èåˆè¿‡ç¨‹ä¸ä»…å…·æœ‰æ˜ç¡®çš„è¯­ä¹‰æ–¹å‘æ€§ï¼Œè€Œä¸”è¿˜ä¿è¯äº†æœ€ç»ˆç»“æœçš„é«˜ä¿çœŸåº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSGDFuseåœ¨ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°ä»¥åŠé€‚åº”ä¸‹æ¸¸ä»»åŠ¡æ–¹é¢å‡è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œä¸ºè§£å†³å›¾åƒèåˆçš„æ ¸å¿ƒæŒ‘æˆ˜æä¾›äº†å¼ºå¤§çš„è§£å†³æ–¹æ¡ˆã€‚SGDFuseçš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/boshizhang123/SGDFuse%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/boshizhang123/SGDFuseä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05264v3">PDF</a> Submitted to Information Fusion</p>
<p><strong>Summary</strong></p>
<p>çº¢å¤–ä¸å¯è§å›¾åƒèåˆï¼ˆIVIFï¼‰æ—¨åœ¨ç»“åˆçº¢å¤–å›¾åƒä¸­çš„çƒ­è¾å°„ä¿¡æ¯ä¸å¯è§å›¾åƒä¸­çš„ä¸°å¯Œçº¹ç†ç»†èŠ‚ï¼Œä»¥æé«˜ä¸‹æ¸¸è§†è§‰ä»»åŠ¡çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ç”±äºç¼ºä¹æ·±åº¦åœºæ™¯è¯­ä¹‰ç†è§£ï¼Œå¸¸å¸¸æ— æ³•ä¿ç•™å…³é”®ç›®æ ‡ï¼ŒåŒæ—¶èåˆè¿‡ç¨‹æœ¬èº«ä¹Ÿå¯èƒ½å¼•å…¥ä¼ªå½±å’Œç»†èŠ‚æŸå¤±ï¼Œä¸¥é‡å½±å“å›¾åƒè´¨é‡å’Œä»»åŠ¡æ€§èƒ½ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºSGDFuseæ–¹æ³•ï¼Œé‡‡ç”¨ç”±Segment Anything Modelï¼ˆSAMï¼‰å¼•å¯¼çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œå®ç°é«˜ä¿çœŸå’Œè¯­ä¹‰æ„ŸçŸ¥çš„å›¾åƒèåˆã€‚SGDFuseåˆ©ç”¨SAMç”Ÿæˆçš„é«˜è´¨é‡è¯­ä¹‰æ©è†œä½œä¸ºæ˜ç¡®å…ˆéªŒï¼ŒæŒ‡å¯¼èåˆè¿‡ç¨‹çš„ä¼˜åŒ–ã€‚é€šè¿‡åˆæ­¥èåˆå¤šæ¨¡æ€ç‰¹å¾å¹¶åˆ©ç”¨è¯­ä¹‰æ©è†œä¸åˆæ­¥èåˆå›¾åƒä½œä¸ºæ¡ä»¶é©±åŠ¨æ‰©æ•£æ¨¡å‹çš„ä»ç²—åˆ°ç»†çš„é™å™ªç”Ÿæˆï¼Œç¡®ä¿èåˆè¿‡ç¨‹ä¸ä»…å…·æœ‰æ˜ç¡®çš„è¯­ä¹‰æ–¹å‘æ€§ï¼Œè¿˜ä¿è¯äº†æœ€ç»ˆç»“æœçš„é«˜ä¿çœŸåº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒSGDFuseåœ¨ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°ä¸­å‡è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„ä¸‹æ¸¸ä»»åŠ¡é€‚åº”æ€§ã€‚<br>SGDFuseçš„ä»£ç å·²å…¬å¼€äºï¼š<a target="_blank" rel="noopener" href="https://github.com/boshizhang123/SGDFuse%E3%80%82">https://github.com/boshizhang123/SGDFuseã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çº¢å¤–ä¸å¯è§å›¾åƒèåˆæ—¨åœ¨ç»“åˆä¸¤ç§å›¾åƒçš„ä¼˜åŠ¿ï¼Œæé«˜è§†è§‰ä»»åŠ¡çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å› ç¼ºä¹æ·±åº¦è¯­ä¹‰ç†è§£è€Œå­˜åœ¨é—®é¢˜ï¼Œå¦‚æ— æ³•ä¿ç•™å…³é”®ç›®æ ‡å’Œå¼•å…¥ä¼ªå½±ã€‚</li>
<li>SGDFuseé‡‡ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç»“åˆSAMç”Ÿæˆçš„è¯­ä¹‰æ©è†œï¼Œå®ç°é«˜ä¿çœŸå’Œè¯­ä¹‰æ„ŸçŸ¥çš„å›¾åƒèåˆã€‚</li>
<li>åˆ©ç”¨SAMçš„è¯­ä¹‰æ©è†œæŒ‡å¯¼èåˆè¿‡ç¨‹çš„ä¼˜åŒ–ï¼Œç¡®ä¿æ˜ç¡®çš„è¯­ä¹‰æ–¹å‘å’Œç»“æœçš„é«˜ä¿çœŸåº¦ã€‚</li>
<li>SGDFuseé€šè¿‡ä¸¤é˜¶æ®µè¿‡ç¨‹å®ç°èåˆï¼šåˆæ­¥ç‰¹å¾èåˆå’ŒåŸºäºè¯­ä¹‰æ©è†œçš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆã€‚</li>
<li>å®éªŒè¡¨æ˜SGDFuseåœ¨ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„ä¸‹æ¸¸ä»»åŠ¡é€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05264">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2508.05264v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2508.05264v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2508.05264v3/page_4_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DIP-Unsupervised-Dense-In-Context-Post-training-of-Visual-Representations"><a href="#DIP-Unsupervised-Dense-In-Context-Post-training-of-Visual-Representations" class="headerlink" title="DIP: Unsupervised Dense In-Context Post-training of Visual   Representations"></a>DIP: Unsupervised Dense In-Context Post-training of Visual   Representations</h2><p><strong>Authors:Sophia Sirko-Galouchenko, Spyros Gidaris, Antonin Vobecky, Andrei Bursuc, Nicolas Thome</strong></p>
<p>We introduce DIP, a novel unsupervised post-training method designed to enhance dense image representations in large-scale pretrained vision encoders for in-context scene understanding. Unlike prior approaches that rely on complex self-distillation architectures, our method trains the vision encoder using pseudo-tasks that explicitly simulate downstream in-context scenarios, inspired by meta-learning principles. To enable post-training on unlabeled data, we propose an automatic mechanism for generating in-context tasks that combines a pretrained diffusion model and the vision encoder itself. DIP is simple, unsupervised, and computationally efficient, requiring less than 9 hours on a single A100 GPU. By learning dense representations through pseudo in-context tasks, it achieves strong performance across a wide variety of downstream real-world in-context scene understanding tasks. It outperforms both the initial vision encoder and prior methods, offering a practical and effective solution for improving dense representations. Code available here: <a target="_blank" rel="noopener" href="https://github.com/sirkosophia/DIP">https://github.com/sirkosophia/DIP</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†DIPï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„æ— ç›‘ç£åè®­ç»ƒæ³•ï¼Œæ—¨åœ¨å¢å¼ºå¤§è§„æ¨¡é¢„è®­ç»ƒè§†è§‰ç¼–ç å™¨ä¸­çš„å¯†é›†å›¾åƒè¡¨ç¤ºï¼Œä»¥å®ç°ä¸Šä¸‹æ–‡åœºæ™¯ç†è§£ã€‚ä¸åŒäºä¾èµ–å¤æ‚è‡ªæˆ‘è’¸é¦æ¶æ„çš„å…ˆå‰æ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ä¼ªä»»åŠ¡è®­ç»ƒè§†è§‰ç¼–ç å™¨ï¼Œè¿™äº›ä¼ªä»»åŠ¡æ˜ç¡®æ¨¡æ‹Ÿä¸‹æ¸¸ä¸Šä¸‹æ–‡åœºæ™¯ï¼Œå¹¶å—å…ƒå­¦ä¹ åŸç†çš„å¯å‘ã€‚ä¸ºäº†åœ¨æœªæ ‡è®°æ•°æ®ä¸Šè¿›è¡Œåè®­ç»ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆä¸Šä¸‹æ–‡ä»»åŠ¡çš„æœºåˆ¶ï¼Œè¯¥æœºåˆ¶ç»“åˆäº†é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å’Œè§†è§‰ç¼–ç å™¨æœ¬èº«ã€‚DIPç®€å•ã€æ— ç›‘ç£ä¸”è®¡ç®—é«˜æ•ˆï¼Œåœ¨å•ä¸ªA100 GPUä¸Šè¿è¡Œæ—¶é—´ä¸åˆ°9å°æ—¶ã€‚å®ƒé€šè¿‡ä¼ªä¸Šä¸‹æ–‡ä»»åŠ¡å­¦ä¹ å¯†é›†è¡¨ç¤ºï¼Œåœ¨å¤šç§ä¸‹æ¸¸ç°å®ä¸–ç•Œä¸Šä¸‹æ–‡åœºæ™¯ç†è§£ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºåŠ²æ€§èƒ½ã€‚å®ƒä¼˜äºåˆå§‹è§†è§‰ç¼–ç å™¨å’Œå…ˆå‰æ–¹æ³•ï¼Œä¸ºè§£å†³å¯†é›†è¡¨ç¤ºé—®é¢˜æä¾›äº†å®ç”¨æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚ä»£ç é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://github.com/sirkosophia/DIP">https://github.com/sirkosophia/DIP</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18463v3">PDF</a> Accepted to ICCV 2025</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†DIPï¼Œä¸€ç§æ–°å‹æ— ç›‘ç£çš„é¢„è®­ç»ƒåå›¾åƒå¤„ç†æ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºå¤§è§„æ¨¡é¢„è®­ç»ƒè§†è§‰ç¼–ç å™¨çš„å¯†é›†å›¾åƒè¡¨ç¤ºèƒ½åŠ›ï¼Œä»¥è¿›è¡Œä¸Šä¸‹æ–‡åœºæ™¯ç†è§£ã€‚è¯¥æ–¹æ³•é€šè¿‡æ¨¡æ‹Ÿä¸‹æ¸¸ä¸Šä¸‹æ–‡åœºæ™¯ç”Ÿæˆä¼ªä»»åŠ¡æ¥è®­ç»ƒè§†è§‰ç¼–ç å™¨ï¼Œå—å…ƒå­¦ä¹ åŸç†å¯å‘ã€‚é€šè¿‡ç»“åˆé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å’Œè§†è§‰ç¼–ç å™¨æœ¬èº«ï¼Œå®ç°è‡ªåŠ¨åœ¨ä¸Šä¸‹æ–‡ä»»åŠ¡ç”Ÿæˆæœºåˆ¶ä¸Šçš„æ— ç›‘ç£è®­ç»ƒã€‚DIPç®€å•é«˜æ•ˆï¼Œåœ¨å•ä¸ªA100 GPUä¸Šä¸åˆ°9å°æ—¶å†…å®Œæˆè®¡ç®—ã€‚é€šè¿‡ä¼ªä¸Šä¸‹æ–‡ä»»åŠ¡å­¦ä¹ å¯†é›†è¡¨ç¤ºï¼Œåœ¨å¤šç§ä¸‹æ¸¸ç°å®åœºæ™¯ç†è§£ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¼˜äºåˆå§‹è§†è§‰ç¼–ç å™¨å’Œå…ˆå‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DIPæ˜¯ä¸€ç§æ–°å‹çš„é¢„è®­ç»ƒåå›¾åƒå¤„ç†æ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºå¤§è§„æ¨¡é¢„è®­ç»ƒè§†è§‰ç¼–ç å™¨çš„ä¸Šä¸‹æ–‡åœºæ™¯ç†è§£èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æ¨¡æ‹Ÿä¸‹æ¸¸ä¸Šä¸‹æ–‡åœºæ™¯ç”Ÿæˆä¼ªä»»åŠ¡è¿›è¡Œè®­ç»ƒï¼Œä¸åŒäºä¾èµ–å¤æ‚è‡ªè’¸é¦æ¶æ„çš„å…ˆå‰æ–¹æ³•ã€‚</li>
<li>DIPåˆ©ç”¨å…ƒå­¦ä¹ åŸç†ï¼Œç»“åˆé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å’Œè§†è§‰ç¼–ç å™¨æœ¬èº«ç”Ÿæˆä¸Šä¸‹æ–‡ä»»åŠ¡ã€‚</li>
<li>DIPå…·æœ‰ç®€å•ã€æ— ç›‘ç£å’Œè®¡ç®—æ•ˆç‡é«˜çš„ç‰¹ç‚¹ï¼Œèƒ½åœ¨å•ä¸ªA100 GPUä¸ŠçŸ­æ—¶é—´å†…å®Œæˆè®¡ç®—ã€‚</li>
<li>é€šè¿‡å­¦ä¹ ä¼ªä¸Šä¸‹æ–‡ä»»åŠ¡çš„å¯†é›†è¡¨ç¤ºï¼ŒDIPåœ¨å¤šç§ä¸‹æ¸¸ç°å®åœºæ™¯ç†è§£ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>DIPä¼˜äºåˆå§‹è§†è§‰ç¼–ç å™¨å’Œå…ˆå‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18463">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2506.18463v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2506.18463v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2506.18463v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2506.18463v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Reangle-A-Video-4D-Video-Generation-as-Video-to-Video-Translation"><a href="#Reangle-A-Video-4D-Video-Generation-as-Video-to-Video-Translation" class="headerlink" title="Reangle-A-Video: 4D Video Generation as Video-to-Video Translation"></a>Reangle-A-Video: 4D Video Generation as Video-to-Video Translation</h2><p><strong>Authors:Hyeonho Jeong, Suhyeon Lee, Jong Chul Ye</strong></p>
<p>We introduce Reangle-A-Video, a unified framework for generating synchronized multi-view videos from a single input video. Unlike mainstream approaches that train multi-view video diffusion models on large-scale 4D datasets, our method reframes the multi-view video generation task as video-to-videos translation, leveraging publicly available image and video diffusion priors. In essence, Reangle-A-Video operates in two stages. (1) Multi-View Motion Learning: An image-to-video diffusion transformer is synchronously fine-tuned in a self-supervised manner to distill view-invariant motion from a set of warped videos. (2) Multi-View Consistent Image-to-Images Translation: The first frame of the input video is warped and inpainted into various camera perspectives under an inference-time cross-view consistency guidance using DUSt3R, generating multi-view consistent starting images. Extensive experiments on static view transport and dynamic camera control show that Reangle-A-Video surpasses existing methods, establishing a new solution for multi-view video generation. We will publicly release our code and data. Project page: <a target="_blank" rel="noopener" href="https://hyeonho99.github.io/reangle-a-video/">https://hyeonho99.github.io/reangle-a-video/</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Reangle-A-Videoï¼Œè¿™æ˜¯ä¸€ä¸ªä»å•ä¸ªè¾“å…¥è§†é¢‘ç”ŸæˆåŒæ­¥å¤šè§†è§’è§†é¢‘çš„ç»Ÿä¸€æ¡†æ¶ã€‚ä¸åŒäºä¸»æµæ–¹æ³•åœ¨å¤§å‹4Dæ•°æ®é›†ä¸Šè®­ç»ƒå¤šè§†è§’è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†å¤šè§†è§’è§†é¢‘ç”Ÿæˆä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºè§†é¢‘åˆ°è§†é¢‘çš„ç¿»è¯‘ï¼Œå¹¶åˆ©ç”¨å¯å…¬å¼€è·å–çš„å›¾åƒå’Œè§†é¢‘æ‰©æ•£å…ˆéªŒã€‚æœ¬è´¨ä¸Šï¼ŒReangle-A-Videoåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µã€‚ ï¼ˆ1ï¼‰å¤šè§†è§’è¿åŠ¨å­¦ä¹ ï¼šä»¥è‡ªç›‘ç£çš„æ–¹å¼åŒæ­¥å¾®è°ƒå›¾åƒåˆ°è§†é¢‘æ‰©æ•£è½¬æ¢å™¨ï¼Œä»ä¸€ç»„å˜å½¢è§†é¢‘ä¸­æç‚¼å‡ºè§†è§’ä¸å˜çš„è¿åŠ¨ã€‚ ï¼ˆ2ï¼‰å¤šè§†è§’ä¸€è‡´å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ï¼šè¾“å…¥è§†é¢‘çš„ç¬¬ä¸€å¸§åœ¨æ¨ç†æ—¶é—´è·¨è§†è§’ä¸€è‡´æ€§æŒ‡å¯¼ä¸‹å˜å½¢å¹¶å¡«å……ï¼Œç”Ÿæˆå„ç§ç›¸æœºè§†è§’ä¸‹çš„å¤šè§†è§’ä¸€è‡´åˆå§‹å›¾åƒã€‚åœ¨é™æ€è§†è§’ä¼ è¾“å’ŒåŠ¨æ€æ‘„åƒæœºæ§åˆ¶æ–¹é¢çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒReangle-A-Videoè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œä¸ºå¤šè§†è§’è§†é¢‘ç”Ÿæˆå»ºç«‹äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬å°†å…¬å¼€å‘å¸ƒæˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://hyeonho99.github.io/reangle-a-video/">https://hyeonho99.github.io/reangle-a-video/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09151v3">PDF</a> ICCV 2025, Project page: <a target="_blank" rel="noopener" href="https://hyeonho99.github.io/reangle-a-video/">https://hyeonho99.github.io/reangle-a-video/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Reangle-A-Videoæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»å•è¾“å…¥è§†é¢‘ç”ŸæˆåŒæ­¥å¤šè§†è§’è§†é¢‘ã€‚ä¸åŒäºä¸»æµæ–¹æ³•åœ¨å¤§å‹4Dæ•°æ®é›†ä¸Šè®­ç»ƒå¤šè§†è§’è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ŒReangle-A-Videoå°†å¤šè§†è§’è§†é¢‘ç”Ÿæˆä»»åŠ¡è½¬åŒ–ä¸ºè§†é¢‘åˆ°è§†é¢‘çš„ç¿»è¯‘ï¼Œå¹¶åˆ©ç”¨å¯å…¬å¼€è·å–çš„å›¾åƒå’Œè§†é¢‘æ‰©æ•£å…ˆéªŒã€‚å…¶å®è´¨ä¸Šåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š1ï¼‰å¤šè§†è§’è¿åŠ¨å­¦ä¹ ï¼šä»¥è‡ªç›‘ç£æ–¹å¼åŒæ­¥å¾®è°ƒå›¾åƒåˆ°è§†é¢‘æ‰©æ•£è½¬æ¢å™¨ï¼Œä»ä¸€ç»„å˜å½¢è§†é¢‘ä¸­æå–è§†è§’ä¸å˜è¿åŠ¨ï¼›2ï¼‰å¤šè§†è§’ä¸€è‡´å›¾åƒåˆ°å›¾åƒç¿»è¯‘ï¼šåœ¨æ¨ç†æ—¶é—´è·¨è§†è§’ä¸€è‡´æ€§æŒ‡å¯¼ä¸‹ï¼Œå°†è¾“å…¥è§†é¢‘çš„ç¬¬ä¸€å¸§å˜å½¢å¹¶å¡«å……åˆ°å„ç§ç›¸æœºè§†è§’ï¼Œç”Ÿæˆå¤šè§†è§’ä¸€è‡´èµ·å§‹å›¾åƒã€‚å®éªŒè¡¨æ˜ï¼ŒReangle-A-Videoè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œä¸ºå¤šè§†è§’è§†é¢‘ç”Ÿæˆæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Reangle-A-Videoæ˜¯ä¸€ä¸ªç”ŸæˆåŒæ­¥å¤šè§†è§’è§†é¢‘çš„ç»Ÿä¸€æ¡†æ¶ï¼Œå¯ä»å•ä¸€è¾“å…¥è§†é¢‘ç”Ÿæˆã€‚</li>
<li>ä¸ä¸»æµæ–¹æ³•ä¸åŒï¼Œå®ƒå¹¶ä¸åœ¨å¤§å‹4Dæ•°æ®é›†ä¸Šè®­ç»ƒå¤šè§†è§’è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•å°†å¤šè§†è§’è§†é¢‘ç”Ÿæˆè½¬åŒ–ä¸ºè§†é¢‘åˆ°è§†é¢‘çš„ç¿»è¯‘ä»»åŠ¡ã€‚</li>
<li>åˆ©ç”¨å›¾åƒå’Œè§†é¢‘æ‰©æ•£å…ˆéªŒã€‚</li>
<li>Reangle-A-Videoåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šå¤šè§†è§’è¿åŠ¨å­¦ä¹ å’Œå¤šè§†è§’ä¸€è‡´å›¾åƒåˆ°å›¾åƒç¿»è¯‘ã€‚</li>
<li>é€šè¿‡è‡ªç›‘ç£æ–¹å¼åŒæ­¥å¾®è°ƒå›¾åƒåˆ°è§†é¢‘æ‰©æ•£è½¬æ¢å™¨ä»¥æå–è§†è§’ä¸å˜è¿åŠ¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09151">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2503.09151v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2503.09151v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2503.09151v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2503.09151v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2503.09151v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Closed-Loop-Unsupervised-Representation-Disentanglement-with-Î²-VAE-Distillation-and-Diffusion-Probabilistic-Feedback"><a href="#Closed-Loop-Unsupervised-Representation-Disentanglement-with-Î²-VAE-Distillation-and-Diffusion-Probabilistic-Feedback" class="headerlink" title="Closed-Loop Unsupervised Representation Disentanglement with $Î²$-VAE   Distillation and Diffusion Probabilistic Feedback"></a>Closed-Loop Unsupervised Representation Disentanglement with $Î²$-VAE   Distillation and Diffusion Probabilistic Feedback</h2><p><strong>Authors:Xin Jin, Bohan Li, BAAO Xie, Wenyao Zhang, Jinming Liu, Ziqiang Li, Tao Yang, Wenjun Zeng</strong></p>
<p>Representation disentanglement may help AI fundamentally understand the real world and thus benefit both discrimination and generation tasks. It currently has at least three unresolved core issues: (i) heavy reliance on label annotation and synthetic data â€“ causing poor generalization on natural scenarios; (ii) heuristic&#x2F;hand-craft disentangling constraints make it hard to adaptively achieve an optimal training trade-off; (iii) lacking reasonable evaluation metric, especially for the real label-free data. To address these challenges, we propose a \textbf{C}losed-\textbf{L}oop unsupervised representation \textbf{Dis}entanglement approach dubbed \textbf{CL-Dis}. Specifically, we use diffusion-based autoencoder (Diff-AE) as a backbone while resorting to $\beta$-VAE as a co-pilot to extract semantically disentangled representations. The strong generation ability of diffusion model and the good disentanglement ability of VAE model are complementary. To strengthen disentangling, VAE-latent distillation and diffusion-wise feedback are interconnected in a closed-loop system for a further mutual promotion. Then, a self-supervised \textbf{Navigation} strategy is introduced to identify interpretable semantic directions in the disentangled latent space. Finally, a new metric based on content tracking is designed to evaluate the disentanglement effect. Experiments demonstrate the superiority of CL-Dis on applications like real image manipulation and visual analysis. </p>
<blockquote>
<p>è¡¨ç¤ºåˆ†ç¦»å¯èƒ½æœ‰åŠ©äºäººå·¥æ™ºèƒ½ä»æ ¹æœ¬ä¸Šç†è§£ç°å®ä¸–ç•Œï¼Œä»è€Œæœ‰ç›Šäºåˆ¤åˆ«å’Œç”Ÿæˆä»»åŠ¡ã€‚ç›®å‰å®ƒè‡³å°‘å­˜åœ¨ä¸‰ä¸ªæœªè§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š (i) ä¸¥é‡ä¾èµ–æ ‡ç­¾æ³¨é‡Šå’Œåˆæˆæ•°æ®â€”â€”å¯¼è‡´åœ¨è‡ªç„¶åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼› (ii) å¯å‘å¼&#x2F;æ‰‹å·¥åˆ†ç¦»çš„çº¦æŸä½¿éš¾ä»¥è‡ªé€‚åº”åœ°å®ç°æœ€ä½³è®­ç»ƒå¹³è¡¡ï¼› (iii) ç¼ºä¹åˆç†çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºçœŸå®çš„æ— æ ‡ç­¾æ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºCL-Disçš„é—­ç¯æ— ç›‘ç£è¡¨ç¤ºåˆ†ç¦»æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºæ‰©æ•£çš„è‡ªç¼–ç å™¨ï¼ˆDiff-AEï¼‰ä½œä¸ºä¸»å¹²ï¼Œå¹¶æ±‚åŠ©äºÎ²-VAEä½œä¸ºååŒé£è¡Œå‘˜æ¥æå–è¯­ä¹‰ä¸Šåˆ†ç¦»çš„è¡¨ç¤ºã€‚æ‰©æ•£æ¨¡å‹çš„å¼ºå¤§ç”Ÿæˆèƒ½åŠ›å’ŒVAEæ¨¡å‹çš„è‰¯å¥½åˆ†ç¦»èƒ½åŠ›æ˜¯äº’è¡¥çš„ã€‚ä¸ºäº†åŠ å¼ºåˆ†ç¦»ï¼ŒVAEæ½œåœ¨è’¸é¦å’Œæ‰©æ•£åé¦ˆåœ¨é—­ç¯ç³»ç»Ÿä¸­ç›¸äº’è¿æ¥ï¼Œä»¥å®ç°è¿›ä¸€æ­¥çš„ç›¸äº’ä¿ƒè¿›ã€‚ç„¶åï¼Œå¼•å…¥äº†ä¸€ç§è‡ªç›‘ç£çš„å¯¼èˆªç­–ç•¥ï¼Œä»¥åœ¨åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ä¸­è¯†åˆ«å¯è§£é‡Šçš„è¯­ä¹‰æ–¹å‘ã€‚æœ€åï¼Œè®¾è®¡äº†ä¸€ä¸ªåŸºäºå†…å®¹è·Ÿè¸ªçš„æ–°æŒ‡æ ‡æ¥è¯„ä¼°åˆ†ç¦»æ•ˆæœã€‚å®éªŒè¯æ˜ï¼ŒCL-Disåœ¨å®æ—¶å›¾åƒæ“ä½œå’Œè§†è§‰åˆ†æåº”ç”¨ä¸­çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.02346v2">PDF</a> ECCV 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è¡¨ç¤ºåˆ†ç¦»å¯¹äººå·¥æ™ºèƒ½ç†è§£ç°å®ä¸–ç•Œçš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰å­˜åœ¨çš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCL-Disçš„é—­ç¯æ— ç›‘ç£è¡¨ç¤ºåˆ†ç¦»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»¥æ‰©æ•£è‡ªç¼–ç å™¨ï¼ˆDiff-AEï¼‰ä¸ºéª¨å¹²ï¼Œå€ŸåŠ©Î²-VAEæå–è¯­ä¹‰åˆ†ç¦»è¡¨ç¤ºã€‚é€šè¿‡ç»“åˆæ‰©æ•£æ¨¡å‹çš„å¼ºå¤§ç”Ÿæˆèƒ½åŠ›å’ŒVAEæ¨¡å‹è‰¯å¥½çš„åˆ†ç¦»èƒ½åŠ›ï¼Œå¼ºåŒ–äº†è¡¨ç¤ºåˆ†ç¦»ã€‚æ­¤å¤–ï¼Œé€šè¿‡VAEæ½œä¼è’¸é¦å’Œæ‰©æ•£åé¦ˆçš„é—­ç¯ç³»ç»Ÿï¼Œå®ç°äº†è¿›ä¸€æ­¥çš„ç›¸äº’ä¿ƒè¿›ã€‚æœ€åï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºå†…å®¹è·Ÿè¸ªçš„æ–°è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­éªŒè¯äº†CL-Disçš„ä¼˜åŠ¿ï¼Œå¦‚çœŸå®å›¾åƒæ“ä½œå’Œè§†è§‰åˆ†æç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¡¨ç¤ºåˆ†ç¦»æœ‰åŠ©äºAIæ›´æ·±å…¥åœ°ç†è§£ç°å®ä¸–ç•Œï¼Œä¿ƒè¿›åˆ¤åˆ«å’Œç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>å½“å‰è¡¨ç¤ºåˆ†ç¦»é¢ä¸´ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šä¾èµ–æ ‡ç­¾æ ‡æ³¨å’Œåˆæˆæ•°æ®ã€å¯å‘å¼æ‰‹å·¥åˆ†ç¦»çº¦æŸã€ç¼ºä¹åˆç†çš„è¯„ä¼°æŒ‡æ ‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºCL-Disçš„é—­ç¯æ— ç›‘ç£è¡¨ç¤ºåˆ†ç¦»æ–¹æ³•ï¼Œç»“åˆäº†æ‰©æ•£è‡ªç¼–ç å™¨å’ŒÎ²-VAEçš„ä¼˜åŠ¿ã€‚</li>
<li>é€šè¿‡VAEæ½œä¼è’¸é¦å’Œæ‰©æ•£åé¦ˆçš„é—­ç¯ç³»ç»Ÿï¼Œå¼ºåŒ–äº†è¡¨ç¤ºåˆ†ç¦»ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§è‡ªæˆ‘ç›‘ç£çš„å¯¼èˆªç­–ç•¥ï¼Œç”¨äºåœ¨è§£çº ç¼ çš„æ½œä¼ç©ºé—´ä¸­è¯†åˆ«å¯è§£é‡Šçš„è¯­ä¹‰æ–¹å‘ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§åŸºäºå†…å®¹è·Ÿè¸ªçš„æ–°è¯„ä¼°æŒ‡æ ‡æ¥è¯„ä¼°è§£çº ç¼ æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.02346">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2402.02346v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2402.02346v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2402.02346v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_Diffusion Models/2402.02346v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-12/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-12/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-12/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_ç‰™é½¿ä¿®å¤/2509.07923v1/page_2_0.jpg" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-12  Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth   Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-12/NeRF/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-12\./crop_NeRF/2509.07809v1/page_0_0.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-12  SplatFill 3D Scene Inpainting via Depth-Guided Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28879.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
