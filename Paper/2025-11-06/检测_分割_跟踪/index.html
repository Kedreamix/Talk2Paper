<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  Object Detection as an Optional Basis A Graph Matching Network for   Cross-View UAV Localization">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-48d11c5bf4e7dbd2a07c0107e499e9c3')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    35 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-06-æ›´æ–°"><a href="#2025-11-06-æ›´æ–°" class="headerlink" title="2025-11-06 æ›´æ–°"></a>2025-11-06 æ›´æ–°</h1><h2 id="Object-Detection-as-an-Optional-Basis-A-Graph-Matching-Network-for-Cross-View-UAV-Localization"><a href="#Object-Detection-as-an-Optional-Basis-A-Graph-Matching-Network-for-Cross-View-UAV-Localization" class="headerlink" title="Object Detection as an Optional Basis: A Graph Matching Network for   Cross-View UAV Localization"></a>Object Detection as an Optional Basis: A Graph Matching Network for   Cross-View UAV Localization</h2><p><strong>Authors:Tao Liu, Kan Ren, Qian Chen</strong></p>
<p>With the rapid growth of the low-altitude economy, UAVs have become crucial for measurement and tracking in patrol systems. However, in GNSS-denied areas, satellite-based localization methods are prone to failure. This paper presents a cross-view UAV localization framework that performs map matching via object detection, aimed at effectively addressing cross-temporal, cross-view, heterogeneous aerial image matching. In typical pipelines, UAV visual localization is formulated as an image-retrieval problem: features are extracted to build a localization map, and the pose of a query image is estimated by matching it to a reference database with known poses. Because publicly available UAV localization datasets are limited, many approaches recast localization as a classification task and rely on scene labels in these datasets to ensure accuracy. Other methods seek to reduce cross-domain differences using polar-coordinate reprojection, perspective transformations, or generative adversarial networks; however, they can suffer from misalignment, content loss, and limited realism. In contrast, we leverage modern object detection to accurately extract salient instances from UAV and satellite images, and integrate a graph neural network to reason about inter-image and intra-image node relationships. Using a fine-grained, graph-based node-similarity metric, our method achieves strong retrieval and localization performance. Extensive experiments on public and real-world datasets show that our approach handles heterogeneous appearance differences effectively and generalizes well, making it applicable to scenarios with larger modality gaps, such as infrared-visible image matching. Our dataset will be publicly available at the following URL: <a target="_blank" rel="noopener" href="https://github.com/liutao23/ODGNNLoc.git">https://github.com/liutao23/ODGNNLoc.git</a>. </p>
<blockquote>
<p>éšç€ä½ç©ºç»æµçš„é£é€Ÿå‘å±•ï¼Œæ— äººæœºåœ¨å·¡é€»ç³»ç»Ÿä¸­çš„æµ‹é‡å’Œè·Ÿè¸ªå˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨GNSSå¤±æ•ˆåŒºåŸŸï¼ŒåŸºäºå«æ˜Ÿçš„å®šä½æ–¹æ³•å®¹æ˜“å¤±æ•ˆã€‚æœ¬æ–‡é’ˆå¯¹æœ‰æ•ˆè§£å†³è·¨æ—¶é—´ã€è·¨è§†è§’ã€å¼‚è´¨èˆªç©ºå›¾åƒåŒ¹é…çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è·¨è§†è§’æ— äººæœºå®šä½æ¡†æ¶ï¼Œé€šè¿‡ç›®æ ‡æ£€æµ‹æ‰§è¡Œåœ°å›¾åŒ¹é…ã€‚åœ¨å…¸å‹çš„æµç¨‹ä¸­ï¼Œæ— äººæœºè§†è§‰å®šä½è¢«åˆ¶å®šä¸ºå›¾åƒæ£€ç´¢é—®é¢˜ï¼šæå–ç‰¹å¾ä»¥æ„å»ºå®šä½åœ°å›¾ï¼Œå¹¶é€šè¿‡ä¸å‚è€ƒæ•°æ®åº“ä¸­çš„å·²çŸ¥å§¿æ€åŒ¹é…æ¥ä¼°è®¡æŸ¥è¯¢å›¾åƒçš„å§¿æ€ã€‚ç”±äºå…¬å¼€å¯ç”¨çš„æ— äººæœºå®šä½æ•°æ®é›†æœ‰é™ï¼Œè®¸å¤šæ–¹æ³•å°†å®šä½é‡æ–°æ„å»ºä¸ºåˆ†ç±»ä»»åŠ¡ï¼Œå¹¶ä¾èµ–è¿™äº›æ•°æ®é›†ä¸­çš„åœºæ™¯æ ‡ç­¾ä»¥ç¡®ä¿å‡†ç¡®æ€§ã€‚å…¶ä»–æ–¹æ³•è¯•å›¾é€šè¿‡æåæ ‡é‡æŠ•å½±ã€é€è§†å˜æ¢æˆ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¥å‡å°‘è·¨åŸŸå·®å¼‚ï¼Œä½†å®ƒä»¬å¯èƒ½ä¼šé­å—é”™ä½ã€å†…å®¹ä¸¢å¤±å’Œæœ‰é™çš„ç°å®æ„Ÿçš„é—®é¢˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬åˆ©ç”¨ç°ä»£ç›®æ ‡æ£€æµ‹å‡†ç¡®åœ°ä»æ— äººæœºå’Œå«æ˜Ÿå›¾åƒä¸­æå–æ˜¾è‘—å®ä¾‹ï¼Œå¹¶é›†æˆå›¾ç¥ç»ç½‘ç»œæ¥æ¨ç†å›¾åƒå†…å’Œå›¾åƒé—´èŠ‚ç‚¹å…³ç³»ã€‚é€šè¿‡ä½¿ç”¨åŸºäºå›¾çš„ç²¾ç»†èŠ‚ç‚¹ç›¸ä¼¼æ€§åº¦é‡ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†å¼ºå¤§çš„æ£€ç´¢å’Œå®šä½æ€§èƒ½ã€‚åœ¨å…¬å…±å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å¼‚è´¨å¤–è§‚å·®å¼‚ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œé€‚ç”¨äºæ¨¡æ€å·®è·è¾ƒå¤§çš„åœºæ™¯ï¼Œå¦‚çº¢å¤–å¯è§å…‰å›¾åƒåŒ¹é…ç­‰ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å°†åœ¨ä»¥ä¸‹URLå…¬å¼€æä¾›ï¼š<a target="_blank" rel="noopener" href="https://github.com/">https://github.com</a> com&#x2F;liutao23&#x2F;ODGNNLoc.gitã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02489v1">PDF</a> 20 pages, Submitted to IEEE TIM</p>
<p><strong>Summary</strong>ï¼šéšç€ä½ç©ºç»æµçš„å¿«é€Ÿå¢é•¿ï¼Œæ— äººæœºåœ¨å·¡é€»ç³»ç»Ÿä¸­çš„æµ‹é‡å’Œè·Ÿè¸ªå˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨å«æ˜Ÿå¯¼èˆªä¿¡å·è¢«é®æŒ¡çš„åœ°åŒºï¼ŒåŸºäºå«æ˜Ÿçš„å®šä½æ–¹æ³•å®¹æ˜“å¤±æ•ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è·¨è§†å›¾æ— äººæœºå®šä½æ¡†æ¶ï¼Œé€šè¿‡ç›®æ ‡æ£€æµ‹æ‰§è¡Œåœ°å›¾åŒ¹é…ï¼Œæ—¨åœ¨æœ‰æ•ˆè§£å†³è·¨æ—¶é—´ã€è·¨è§†å›¾çš„å¼‚æ„èˆªç©ºå›¾åƒåŒ¹é…é—®é¢˜ã€‚è¯¥ç ”ç©¶ä½¿ç”¨äº†ä¸€ç§åŸºäºå›¾åƒæ£€ç´¢çš„æ–¹æ³•æ¥å®ç°æ— äººæœºè§†è§‰å®šä½ï¼Œå¹¶åˆ©ç”¨ç°ä»£ç›®æ ‡æ£€æµ‹æŠ€æœ¯ä»æ— äººæœºå’Œå«æ˜Ÿå›¾åƒä¸­å‡†ç¡®æå–æ˜¾è‘—å®ä¾‹ã€‚ç»“åˆå›¾ç¥ç»ç½‘ç»œå¯¹å›¾åƒå†…å’Œå›¾åƒé—´èŠ‚ç‚¹å…³ç³»è¿›è¡Œæ¨ç†ï¼Œä½¿ç”¨åŸºäºå›¾çš„ç²¾ç»†èŠ‚ç‚¹ç›¸ä¼¼æ€§åº¦é‡æ–¹æ³•ï¼Œå®ç°äº†å¼ºå¤§çš„æ£€ç´¢å’Œå®šä½æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ä½ç©ºç»æµä¸­æ— äººæœºçš„é‡è¦æ€§åŠå…¶åœ¨å·¡é€»ç³»ç»Ÿä¸­çš„æµ‹é‡å’Œè·Ÿè¸ªåº”ç”¨ã€‚</li>
<li>åœ¨å«æ˜Ÿå¯¼èˆªä¿¡å·è¢«é®æŒ¡çš„åœ°åŒºï¼ŒåŸºäºå«æ˜Ÿçš„å®šä½æ–¹æ³•å®¹æ˜“å¤±æ•ˆã€‚</li>
<li>æå‡ºäº†ä¸€ç§è·¨è§†å›¾æ— äººæœºå®šä½æ¡†æ¶ï¼Œé€šè¿‡ç›®æ ‡æ£€æµ‹æ‰§è¡Œåœ°å›¾åŒ¹é…ã€‚</li>
<li>è¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³è·¨æ—¶é—´ã€è·¨è§†å›¾çš„å¼‚æ„èˆªç©ºå›¾åƒåŒ¹é…é—®é¢˜ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨åŸºäºå›¾åƒæ£€ç´¢çš„æ–¹æ³•å®ç°æ— äººæœºè§†è§‰å®šä½ã€‚</li>
<li>åˆ©ç”¨ç°ä»£ç›®æ ‡æ£€æµ‹æŠ€æœ¯ä»æ— äººæœºå’Œå«æ˜Ÿå›¾åƒä¸­æå–æ˜¾è‘—å®ä¾‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02489">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d7aaa6a36d37df13878618ec1fb449b4" align="middle">
<img src="https://picx.zhimg.com/v2-b6c0e36c8a124120050dd757ffdfa707" align="middle">
<img src="https://picx.zhimg.com/v2-61db1b8b15f0a9a8cd75afffa1ef1a5e" align="middle">
<img src="https://picx.zhimg.com/v2-ff93061e3cf06c3bde96e3beef8b58ce" align="middle">
<img src="https://picx.zhimg.com/v2-07630ab3a2b43f179c7260fa7c902df7" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="OmniTrack-Omnidirectional-Multi-Object-Tracking-by-Learning-Large-FoV-Trajectory-Feedback"><a href="#OmniTrack-Omnidirectional-Multi-Object-Tracking-by-Learning-Large-FoV-Trajectory-Feedback" class="headerlink" title="OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV   Trajectory Feedback"></a>OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV   Trajectory Feedback</h2><p><strong>Authors:Kai Luo, Hao Shi, Kunyu Peng, Fei Teng, Sheng Wu, Kaiwei Wang, Kailun Yang</strong></p>
<p>This paper investigates Multi-Object Tracking (MOT) in panoramic imagery, which introduces unique challenges including a 360{\deg} Field of View (FoV), resolution dilution, and severe view-dependent distortions. Conventional MOT methods designed for narrow-FoV pinhole cameras generalize unsatisfactorily under these conditions. To address panoramic distortion, large search space, and identity ambiguity under a 360{\deg} FoV, OmniTrack++ adopts a feedback-driven framework that progressively refines perception with trajectory cues. A DynamicSSM block first stabilizes panoramic features, implicitly alleviating geometric distortion. On top of normalized representations, FlexiTrack Instances use trajectory-informed feedback for flexible localization and reliable short-term association. To ensure long-term robustness, an ExpertTrack Memory consolidates appearance cues via a Mixture-of-Experts design, enabling recovery from fragmented tracks and reducing identity drift. Finally, a Tracklet Management module adaptively switches between end-to-end and tracking-by-detection modes according to scene dynamics, offering a balanced and scalable solution for panoramic MOT. To support rigorous evaluation, we establish the EmboTrack benchmark, a comprehensive dataset for panoramic MOT that includes QuadTrack, captured with a quadruped robot, and BipTrack, collected with a bipedal wheel-legged robot. Together, these datasets span wide-angle environments and diverse motion patterns, providing a challenging testbed for real-world panoramic perception. Extensive experiments on JRDB and EmboTrack demonstrate that OmniTrack++ achieves state-of-the-art performance, yielding substantial HOTA improvements of +25.5% on JRDB and +43.07% on QuadTrack over the original OmniTrack. Datasets and code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/xifen523/OmniTrack">https://github.com/xifen523/OmniTrack</a>. </p>
<blockquote>
<p>æœ¬æ–‡ç ”ç©¶äº†å…¨æ™¯å½±åƒä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰æŠ€æœ¯ï¼Œè¿™å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬360Â°è§†é‡ï¼ˆFoVï¼‰ã€åˆ†è¾¨ç‡è¡°å‡å’Œä¸¥é‡çš„è§†è§’ç›¸å…³ç•¸å˜ã€‚é’ˆå¯¹çª„FoVé’ˆå­”ç›¸æœºè®¾è®¡çš„ä¼ ç»ŸMOTæ–¹æ³•åœ¨è¿™äº›æ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³å…¨æ™¯ç•¸å˜ã€å¤§æœç´¢ç©ºé—´å’Œ360Â°è§†é‡ä¸‹çš„èº«ä»½æ­§ä¹‰é—®é¢˜ï¼ŒOmniTrack++é‡‡ç”¨äº†ä¸€ç§åé¦ˆé©±åŠ¨æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è½¨è¿¹çº¿ç´¢é€æ­¥ä¼˜åŒ–æ„ŸçŸ¥ã€‚DynamicSSMå—é¦–å…ˆç¨³å®šå…¨æ™¯ç‰¹å¾ï¼Œéšå«åœ°ç¼“è§£å‡ ä½•ç•¸å˜ã€‚åœ¨å½’ä¸€åŒ–è¡¨ç¤ºçš„åŸºç¡€ä¸Šï¼ŒFlexiTrackå®ä¾‹é‡‡ç”¨åŸºäºè½¨è¿¹çš„åé¦ˆè¿›è¡Œçµæ´»å®šä½ï¼Œå®ç°å¯é çš„çŸ­æœŸå…³è”ã€‚ä¸ºäº†ç¡®ä¿é•¿æœŸç¨³å¥æ€§ï¼ŒExpertTrackå†…å­˜é€šè¿‡æ··åˆä¸“å®¶è®¾è®¡å·©å›ºå¤–è§‚çº¿ç´¢ï¼Œèƒ½å¤Ÿå®ç°ä»ç ´ç¢è½¨è¿¹ä¸­æ¢å¤å¹¶å‡å°‘èº«ä»½æ¼‚ç§»ã€‚æœ€åï¼ŒTrackletç®¡ç†æ¨¡å—æ ¹æ®åœºæ™¯åŠ¨æ€è‡ªé€‚åº”åœ°åœ¨ç«¯åˆ°ç«¯å’Œè·Ÿè¸ªæ£€æµ‹æ¨¡å¼ä¹‹é—´è¿›è¡Œåˆ‡æ¢ï¼Œä¸ºå…¨æ™¯MOTæä¾›å¹³è¡¡ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†æ”¯æŒä¸¥æ ¼è¯„ä¼°ï¼Œæˆ‘ä»¬å»ºç«‹äº†EmboTrackåŸºå‡†æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€å¥—å…¨é¢çš„å…¨æ™¯MOTæ•°æ®é›†ï¼ŒåŒ…æ‹¬ç”¨å››è¶³æœºå™¨äººæ•è·çš„QuadTrackå’Œç”¨åŒè¶³è½®è…¿æœºå™¨äººæ”¶é›†çš„BipTrackã€‚è¿™äº›æ•°æ®é›†æ¶µç›–äº†å¹¿è§’ç¯å¢ƒå’Œå¤šæ ·åŒ–çš„è¿åŠ¨æ¨¡å¼ï¼Œä¸ºç°å®ä¸–ç•Œçš„å…¨æ™¯æ„ŸçŸ¥æä¾›äº†ä¸€ä¸ªæœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•å¹³å°ã€‚åœ¨JRDBå’ŒEmboTrackä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒOmniTrack++è¾¾åˆ°äº†ä¸šç•Œæœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼Œç›¸è¾ƒäºåŸå§‹çš„OmniTrackåœ¨JRDBä¸Šæœ‰+25.5%çš„HOTAæå‡ä»¥åŠåœ¨QuadTrackä¸Šæœ‰+43.07%çš„æå‡ã€‚æ•°æ®é›†å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/xifen523/OmniTrack%E5%85%AC%E5%BC%80%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/xifen523/OmniTrackå…¬å¼€æä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00510v1">PDF</a> Extended version of CVPR 2025 paper arXiv:2503.04565. Datasets and   code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/xifen523/OmniTrack">https://github.com/xifen523/OmniTrack</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å…¨æ™¯å½±åƒä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰é—®é¢˜ï¼Œé’ˆå¯¹å…¨æ™¯å½±åƒçš„ç‰¹æ®Šæ€§è´¨å¦‚360Â°è§†é‡ã€åˆ†è¾¨ç‡ç¨€é‡Šå’Œä¸¥é‡çš„è§†è§’å¤±çœŸç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†OmniTrack++æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åé¦ˆé©±åŠ¨æ¡†æ¶ï¼Œåˆ©ç”¨è½¨è¿¹çº¿ç´¢é€æ­¥ä¼˜åŒ–æ„ŸçŸ¥ã€‚é€šè¿‡DynamicSSMæ¨¡å—ç¨³å®šå…¨æ™¯ç‰¹å¾ï¼Œå¹¶ç»“åˆFlexiTrack Instancesè¿›è¡Œçµæ´»çš„å®šä½å’ŒçŸ­æœŸå…³è”ã€‚ä¸ºé•¿æœŸç¨³å¥æ€§ï¼ŒExpertTrack Memoryé€šè¿‡æ··åˆä¸“å®¶è®¾è®¡å·©å›ºå¤–è§‚çº¿ç´¢ï¼Œä»¥æ¢å¤æ–­è£‚çš„è½¨è¿¹å¹¶å‡å°‘èº«ä»½æ¼‚ç§»ã€‚Tracklet Managementæ¨¡å—åˆ™æ ¹æ®åœºæ™¯åŠ¨æ€è‡ªé€‚åº”åˆ‡æ¢ç«¯åˆ°ç«¯å’Œè·Ÿè¸ªæ£€æµ‹æ¨¡å¼ã€‚æ­¤å¤–ï¼Œå»ºç«‹äº†EmboTrackåŸºå‡†æµ‹è¯•å¹³å°ï¼ŒåŒ…æ‹¬QuadTrackå’ŒBipTrackæ•°æ®é›†ï¼Œä¸ºå…¨æ™¯MOTæä¾›äº†æŒ‘æˆ˜æ€§çš„æµ‹è¯•ç¯å¢ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniTrack++åœ¨JRDBå’ŒEmboTrackä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡ç ”ç©¶äº†å…¨æ™¯å½±åƒä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰é—®é¢˜ï¼Œå¹¶æŒ‡å‡ºäº†ä¼ ç»ŸMOTæ–¹æ³•åœ¨å…¨æ™¯å½±åƒä¸­çš„ä¸è¶³ã€‚</li>
<li>OmniTrack++é‡‡ç”¨åé¦ˆé©±åŠ¨æ¡†æ¶ï¼Œé€šè¿‡è½¨è¿¹çº¿ç´¢é€æ­¥ä¼˜åŒ–æ„ŸçŸ¥ï¼Œè§£å†³å…¨æ™¯å½±åƒçš„æ‰­æ›²ã€å¤§æœç´¢ç©ºé—´å’Œèº«ä»½æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>DynamicSSMæ¨¡å—ç”¨äºç¨³å®šå…¨æ™¯ç‰¹å¾ï¼Œå¹¶ç¼“è§£å‡ ä½•å¤±çœŸã€‚</li>
<li>FlexiTrack Instancesåˆ©ç”¨è½¨è¿¹ä¿¡æ¯åé¦ˆè¿›è¡Œçµæ´»å®šä½å’ŒçŸ­æœŸå…³è”ã€‚</li>
<li>ExpertTrack Memoryé€šè¿‡æ··åˆä¸“å®¶è®¾è®¡å·©å›ºå¤–è§‚çº¿ç´¢ï¼Œæé«˜é•¿æœŸç¨³å¥æ€§ï¼Œå¹¶èƒ½ä»æ–­è£‚çš„è½¨è¿¹ä¸­æ¢å¤ã€‚</li>
<li>Tracklet Managementæ¨¡å—æ ¹æ®åœºæ™¯åŠ¨æ€è‡ªé€‚åº”è°ƒæ•´è·Ÿè¸ªæ¨¡å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00510">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-63e05eab8846655a0752199a802708d7" align="middle">
<img src="https://picx.zhimg.com/v2-809f66c807659351bdb4164e3c872265" align="middle">
<img src="https://picx.zhimg.com/v2-35b907933cd856963e810d06e8dc155c" align="middle">
<img src="https://picx.zhimg.com/v2-755fdb88028d13754a4a1b73d9ed70c1" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="HumanCrafter-Synergizing-Generalizable-Human-Reconstruction-and-Semantic-3D-Segmentation"><a href="#HumanCrafter-Synergizing-Generalizable-Human-Reconstruction-and-Semantic-3D-Segmentation" class="headerlink" title="HumanCrafter: Synergizing Generalizable Human Reconstruction and   Semantic 3D Segmentation"></a>HumanCrafter: Synergizing Generalizable Human Reconstruction and   Semantic 3D Segmentation</h2><p><strong>Authors:Panwang Pan, Tingting Shen, Chenxin Li, Yunlong Lin, Kairun Wen, Jingjing Zhao, Yixuan Yuan</strong></p>
<p>Recent advances in generative models have achieved high-fidelity in 3D human reconstruction, yet their utility for specific tasks (e.g., human 3D segmentation) remains constrained. We propose HumanCrafter, a unified framework that enables the joint modeling of appearance and human-part semantics from a single image in a feed-forward manner. Specifically, we integrate human geometric priors in the reconstruction stage and self-supervised semantic priors in the segmentation stage. To address labeled 3D human datasets scarcity, we further develop an interactive annotation procedure for generating high-quality data-label pairs. Our pixel-aligned aggregation enables cross-task synergy, while the multi-task objective simultaneously optimizes texture modeling fidelity and semantic consistency. Extensive experiments demonstrate that HumanCrafter surpasses existing state-of-the-art methods in both 3D human-part segmentation and 3D human reconstruction from a single image. </p>
<blockquote>
<p>æœ€è¿‘ç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯è¿›æ­¥å·²ç»å®ç°äº†åœ¨ä¸‰ç»´äººä½“é‡å»ºä¸­çš„é«˜ä¿çœŸåº¦ï¼Œä½†å®ƒä»¬åœ¨ç‰¹å®šä»»åŠ¡ï¼ˆä¾‹å¦‚ä¸‰ç»´äººä½“åˆ†å‰²ï¼‰ä¸­çš„å®ç”¨æ€§ä»ç„¶å—åˆ°é™åˆ¶ã€‚æˆ‘ä»¬æå‡ºäº†HumanCrafterï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿä»¥å‰é¦ˆæ–¹å¼ä»å•å¼ å›¾åƒä¸­è”åˆå»ºæ¨¡å¤–è§‚å’Œäººä½“éƒ¨ä½è¯­ä¹‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨é‡å»ºé˜¶æ®µæ•´åˆäº†äººä½“å‡ ä½•å…ˆéªŒçŸ¥è¯†ï¼Œåœ¨åˆ†å‰²é˜¶æ®µæ•´åˆäº†è‡ªç›‘ç£è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ã€‚ä¸ºäº†è§£å†³æ ‡è®°çš„ä¸‰ç»´äººä½“æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ä¸ªäº¤äº’å¼æ³¨é‡Šç¨‹åºæ¥ç”Ÿæˆé«˜è´¨é‡çš„æ•°æ®æ ‡ç­¾å¯¹ã€‚æˆ‘ä»¬çš„åƒç´ å¯¹é½èšåˆå®ç°äº†è·¨ä»»åŠ¡çš„ååŒä½œç”¨ï¼Œè€Œå¤šä»»åŠ¡ç›®æ ‡åŒæ—¶ä¼˜åŒ–äº†çº¹ç†å»ºæ¨¡çš„ä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHumanCrafteråœ¨å•å›¾åƒçš„ä¸‰ç»´äººä½“éƒ¨ä½åˆ†å‰²å’Œä¸‰ç»´äººä½“é‡å»ºæ–¹é¢éƒ½è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00468v1">PDF</a> Accepted to NeurIPS 2025; Project page: <a target="_blank" rel="noopener" href="https://paulpanwang.github.io/HumanCrafter">this   URL</a></p>
<p><strong>Summary</strong><br>åœ¨ç”Ÿæˆæ¨¡å‹é¢†åŸŸçš„æœ€æ–°è¿›å±•å·²ç»åœ¨3Däººä½“é‡å»ºæ–¹é¢å–å¾—äº†é«˜ä¿çœŸåº¦çš„æˆæœï¼Œç„¶è€Œå¯¹äºç‰¹å®šä»»åŠ¡ï¼ˆå¦‚3Däººä½“åˆ†å‰²ï¼‰çš„åº”ç”¨ä»ç„¶å—é™ã€‚æˆ‘ä»¬æå‡ºäº†HumanCrafterè¿™ä¸€ç»Ÿä¸€æ¡†æ¶ï¼Œä»¥é¦ˆå‰æ–¹å¼å®ç°å¯¹å•å¼ å›¾åƒä¸­å¤–è§‚å’Œäººç±»éƒ¨åˆ†è¯­ä¹‰çš„è”åˆå»ºæ¨¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨é‡å»ºé˜¶æ®µæ•´åˆäº†äººç±»å‡ ä½•å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶åœ¨åˆ†å‰²é˜¶æ®µé‡‡ç”¨äº†è‡ªæˆ‘ç›‘ç£çš„è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ã€‚ä¸ºäº†è§£å†³æ ‡è®°çš„3Däººä½“æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ç§äº¤äº’å¼æ³¨é‡Šç¨‹åºæ¥ç”Ÿæˆé«˜è´¨é‡çš„æ•°æ®æ ‡ç­¾å¯¹ã€‚æˆ‘ä»¬çš„åƒç´ å¯¹é½èšåˆæŠ€æœ¯å®ç°äº†è·¨ä»»åŠ¡çš„ååŒä½œç”¨ï¼Œå¤šä»»åŠ¡ç›®æ ‡åŒæ—¶ä¼˜åŒ–çº¹ç†å»ºæ¨¡ä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHumanCrafteråœ¨å•å›¾åƒ3Däººä½“éƒ¨ä½åˆ†å‰²å’Œ3Däººä½“é‡å»ºæ–¹é¢éƒ½è¶…è¶Šäº†ç°æœ‰çš„æœ€æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HumanCrafteræ¡†æ¶å®ç°äº†ä»å•å¼ å›¾åƒä¸­å¯¹äººç±»å¤–è§‚å’Œäººç±»éƒ¨åˆ†è¯­ä¹‰çš„è”åˆå»ºæ¨¡ã€‚</li>
<li>æ•´åˆäº†äººç±»å‡ ä½•å…ˆéªŒçŸ¥è¯†å’Œè‡ªæˆ‘ç›‘ç£çš„è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ï¼Œåˆ†åˆ«åº”ç”¨äºé‡å»ºå’Œåˆ†å‰²é˜¶æ®µã€‚</li>
<li>å¼€å‘äº†ä¸€ç§äº¤äº’å¼æ³¨é‡Šç¨‹åºï¼Œä»¥åº”å¯¹æ ‡è®°çš„3Däººä½“æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡åƒç´ å¯¹é½èšåˆæŠ€æœ¯å®ç°è·¨ä»»åŠ¡ååŒã€‚</li>
<li>å¤šä»»åŠ¡ç›®æ ‡ä¼˜åŒ–åŒæ—¶è€ƒè™‘çº¹ç†å»ºæ¨¡çš„ä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>HumanCrafteråœ¨å•å›¾åƒ3Däººä½“é‡å»ºå’Œåˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†è¶…è¶Šç°æœ‰æœ€æ–°æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00468">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-69f36f90b2b352a1453ceaa19eabb5fb" align="middle">
<img src="https://picx.zhimg.com/v2-3ad361679351ae84d0d8441897f931fc" align="middle">
<img src="https://picx.zhimg.com/v2-710b3c33b5f7e1ad6fadb092c6b36643" align="middle">
<img src="https://picx.zhimg.com/v2-387a2787379078ad2757156d86fe64ee" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Parameterized-Prompt-for-Incremental-Object-Detection"><a href="#Parameterized-Prompt-for-Incremental-Object-Detection" class="headerlink" title="Parameterized Prompt for Incremental Object Detection"></a>Parameterized Prompt for Incremental Object Detection</h2><p><strong>Authors:Zijia An, Boyu Diao, Ruiqi Liu, Libo Huang, Chuanguang Yang, Fei Wang, Zhulin An, Yongjun Xu</strong></p>
<p>Recent studies have demonstrated that incorporating trainable prompts into pretrained models enables effective incremental learning. However, the application of prompts in incremental object detection (IOD) remains underexplored. Existing prompts pool based approaches assume disjoint class sets across incremental tasks, which are unsuitable for IOD as they overlook the inherent co-occurrence phenomenon in detection images. In co-occurring scenarios, unlabeled objects from previous tasks may appear in current task images, leading to confusion in prompts pool. In this paper, we hold that prompt structures should exhibit adaptive consolidation properties across tasks, with constrained updates to prevent catastrophic forgetting. Motivated by this, we introduce Parameterized Prompts for Incremental Object Detection (P$^2$IOD). Leveraging neural networks global evolution properties, P$^2$IOD employs networks as the parameterized prompts to adaptively consolidate knowledge across tasks. To constrain prompts structure updates, P$^2$IOD further engages a parameterized prompts fusion strategy. Extensive experiments on PASCAL VOC2007 and MS COCO datasets demonstrate that P$^2$IODâ€™s effectiveness in IOD and achieves the state-of-the-art performance among existing baselines. </p>
<blockquote>
<p>æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå°†å¯è®­ç»ƒæç¤ºèå…¥é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥å®ç°æœ‰æ•ˆçš„å¢é‡å­¦ä¹ ã€‚ç„¶è€Œï¼Œæç¤ºåœ¨å¢é‡ç›®æ ‡æ£€æµ‹ï¼ˆIODï¼‰ä¸­çš„åº”ç”¨ä»ç„¶è¢«è¾ƒå°‘æ¢ç´¢ã€‚ç°æœ‰çš„åŸºäºæç¤ºæ± çš„æ–¹æ³•å‡è®¾å¢é‡ä»»åŠ¡ä¹‹é—´çš„ç±»åˆ«é›†æ˜¯ä¸ç›¸äº¤çš„ï¼Œè¿™ä¸é€‚ç”¨äºIODï¼Œå› ä¸ºå®ƒä»¬å¿½ç•¥äº†æ£€æµ‹å›¾åƒä¸­å›ºæœ‰çš„å…±ç°ç°è±¡ã€‚åœ¨å…±ç°åœºæ™¯ä¸­ï¼Œæ¥è‡ªå…ˆå‰ä»»åŠ¡çš„æœªæ ‡è®°å¯¹è±¡å¯èƒ½ä¼šå‡ºç°åœ¨å½“å‰ä»»åŠ¡å›¾åƒä¸­ï¼Œä»è€Œå¯¼è‡´æç¤ºæ± æ··ä¹±ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºæç¤ºç»“æ„åº”å±•ç°å‡ºä»»åŠ¡é—´çš„è‡ªé€‚åº”æ•´åˆç‰¹æ€§ï¼Œå¹¶é€šè¿‡çº¦æŸæ›´æ–°æ¥é˜²æ­¢ç¾éš¾æ€§é—å¿˜ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†é’ˆå¯¹å¢é‡ç›®æ ‡æ£€æµ‹çš„å‚æ•°åŒ–æç¤ºï¼ˆP$^2$IODï¼‰ã€‚åˆ©ç”¨ç¥ç»ç½‘ç»œçš„å…¨å±€æ¼”åŒ–ç‰¹æ€§ï¼ŒP$^2$IODä½¿ç”¨ç½‘ç»œä½œä¸ºå‚æ•°åŒ–æç¤ºï¼Œä»¥è‡ªé€‚åº”åœ°æ•´åˆä»»åŠ¡é—´çš„çŸ¥è¯†ã€‚ä¸ºäº†çº¦æŸæç¤ºç»“æ„æ›´æ–°ï¼ŒP$^2$IODè¿›ä¸€æ­¥é‡‡ç”¨å‚æ•°åŒ–æç¤ºèåˆç­–ç•¥ã€‚åœ¨PASCAL VOC2007å’ŒMS COCOæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒP$^2$IODåœ¨IODä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.27316v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸­å¼•å…¥å¯è®­ç»ƒæç¤ºï¼ˆpromptï¼‰ä»¥å®ç°å¢é‡å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚é’ˆå¯¹å¢é‡å¯¹è±¡æ£€æµ‹ï¼ˆIODï¼‰ä¸­çš„æç¤ºåº”ç”¨è¿›è¡Œäº†æ¢ç´¢ï¼Œå‘ç°ç°æœ‰åŸºäºæç¤ºæ± çš„æ–¹æ³•å‡è®¾ä¸åŒä»»åŠ¡ä¸­çš„ç±»åˆ«é›†æ˜¯ä¸é‡å çš„ï¼Œè¿™åœ¨å¤„ç†æ£€æµ‹å›¾åƒä¸­çš„å›ºæœ‰å…±ç°ç°è±¡æ—¶å¹¶ä¸é€‚ç”¨ã€‚å…±ç°åœºæ™¯å¯èƒ½å¯¼è‡´å…ˆå‰ä»»åŠ¡çš„æœªæ ‡è®°å¯¹è±¡å‡ºç°åœ¨å½“å‰ä»»åŠ¡å›¾åƒä¸­ï¼Œä»è€Œå¼•å‘æç¤ºæ··æ·†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å¢é‡å¯¹è±¡æ£€æµ‹çš„é€‚åº”æ€§æç¤ºç»“æ„â€”â€”å‚æ•°åŒ–æç¤ºï¼ˆPÂ²IODï¼‰ã€‚åˆ©ç”¨ç¥ç»ç½‘ç»œçš„å…¨å±€æ¼”åŒ–ç‰¹æ€§ï¼ŒPÂ²IODé€šè¿‡ç¥ç»ç½‘ç»œä½œä¸ºå‚æ•°åŒ–æç¤ºæ¥é€‚åº”æ€§åœ°å·©å›ºè·¨ä»»åŠ¡çŸ¥è¯†ã€‚åŒæ—¶ï¼Œä¸ºäº†é™åˆ¶æç¤ºç»“æ„çš„æ›´æ–°ï¼ŒPÂ²IODè¿›ä¸€æ­¥é‡‡ç”¨å‚æ•°åŒ–æç¤ºèåˆç­–ç•¥ã€‚åœ¨PASCAL VOC2007å’ŒMS COCOæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPÂ²IODåœ¨å¢é‡å¯¹è±¡æ£€æµ‹æ–¹é¢çš„å“è¶Šæ€§èƒ½ï¼Œå¹¶è¾¾åˆ°äº†ç°æœ‰åŸºå‡†çš„å…ˆè¿›æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å‘ç°åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸­å¼•å…¥å¯è®­ç»ƒæç¤ºï¼ˆpromptï¼‰æœ‰åˆ©äºå¢é‡å­¦ä¹ ã€‚</li>
<li>ç›®å‰é’ˆå¯¹å¢é‡å¯¹è±¡æ£€æµ‹ï¼ˆIODï¼‰ä¸­çš„æç¤ºåº”ç”¨ä»æœ‰æ‰€æ¬ ç¼ºï¼Œå°¤å…¶æ˜¯åœ¨è€ƒè™‘æ£€æµ‹å›¾åƒä¸­å¯¹è±¡çš„å…±ç°ç°è±¡æ—¶ã€‚</li>
<li>å…±ç°åœºæ™¯å¯èƒ½å¯¼è‡´å…ˆå‰ä»»åŠ¡çš„æœªæ ‡è®°å¯¹è±¡å‡ºç°åœ¨å½“å‰ä»»åŠ¡å›¾åƒä¸­ï¼Œå¼•å‘æç¤ºæ··æ·†é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å‚æ•°åŒ–æç¤ºç»“æ„ï¼ˆPÂ²IODï¼‰ï¼Œè¯¥ç»“æ„èƒ½å¤Ÿé€‚åº”æ€§åœ°å·©å›ºè·¨ä»»åŠ¡çŸ¥è¯†ã€‚</li>
<li>åˆ©ç”¨ç¥ç»ç½‘ç»œçš„å…¨å±€æ¼”åŒ–ç‰¹æ€§æ¥å®ç°å‚æ•°åŒ–æç¤ºç»“æ„ã€‚</li>
<li>PÂ²IODé€šè¿‡å‚æ•°åŒ–æç¤ºèåˆç­–ç•¥é™åˆ¶æç¤ºç»“æ„çš„æ›´æ–°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.27316">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a8df8193c2752a8e3be7776f2e959b34" align="middle">
<img src="https://picx.zhimg.com/v2-27554dcdbc08faad32c720b423eb71a1" align="middle">
<img src="https://picx.zhimg.com/v2-00cca3a275d1b8e4d196f2729d46851d" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="WXSOD-A-Benchmark-for-Robust-Salient-Object-Detection-in-Adverse-Weather-Conditions"><a href="#WXSOD-A-Benchmark-for-Robust-Salient-Object-Detection-in-Adverse-Weather-Conditions" class="headerlink" title="WXSOD: A Benchmark for Robust Salient Object Detection in Adverse   Weather Conditions"></a>WXSOD: A Benchmark for Robust Salient Object Detection in Adverse   Weather Conditions</h2><p><strong>Authors:Quan Chen, Xiong Yang, Bolun Zheng, Rongfeng Lu, Xiaokai Yang, Qianyu Zhang, Yu Liu, Xiaofei Zhou</strong></p>
<p>Salient object detection (SOD) in complex environments remains a challenging research topic. Most existing methods perform well in natural scenes with negligible noise, and tend to leverage multi-modal information (e.g., depth and infrared) to enhance accuracy. However, few studies are concerned with the damage of weather noise on SOD performance due to the lack of dataset with pixel-wise annotations. To bridge this gap, this paper introduces a novel Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of 14,945 RGB images with diverse weather noise, along with the corresponding ground truth annotations and weather labels. To verify algorithm generalization, WXSOD contains two test sets, i.e., a synthesized test set and a real test set. The former is generated by adding weather noise to clean images, while the latter contains real-world weather noise. Based on WXSOD, we propose an efficient baseline, termed Weather-aware Feature Aggregation Network (WFANet), which adopts a fully supervised two-branch architecture. Specifically, the weather prediction branch mines weather-related deep features, while the saliency detection branch fuses semantic features extracted from the backbone with weather features for SOD. Comprehensive comparisons against 17 SOD methods shows that our WFANet achieves superior performance on WXSOD. The code and benchmark results will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/C-water/WXSOD">https://github.com/C-water/WXSOD</a> </p>
<blockquote>
<p>å¤æ‚ç¯å¢ƒä¸‹çš„æ˜¾è‘—ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç ”ç©¶è¯¾é¢˜ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•åœ¨å™ªå£°è¾ƒå°‘çš„è‡ªç„¶åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œå¹¶å€¾å‘äºåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆä¾‹å¦‚æ·±åº¦å’Œçº¢å¤–ï¼‰æ¥æé«˜å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¸¦æœ‰åƒç´ çº§æ³¨é‡Šçš„æ•°æ®é›†ï¼Œå¾ˆå°‘æœ‰ç ”ç©¶å…³æ³¨å¤©æ°”å™ªå£°å¯¹SODæ€§èƒ½çš„å½±å“ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„Weather-eXtendedæ˜¾è‘—ç›®æ ‡æ£€æµ‹ï¼ˆWXSODï¼‰æ•°æ®é›†ã€‚å®ƒåŒ…å«å¸¦æœ‰å„ç§å¤©æ°”å™ªå£°çš„14ï¼Œ945å¼ RGBå›¾åƒï¼Œä»¥åŠç›¸åº”çš„çœŸå®æ³¨é‡Šå’Œå¤©æ°”æ ‡ç­¾ã€‚ä¸ºäº†éªŒè¯ç®—æ³•çš„é€šç”¨æ€§ï¼ŒWXSODåŒ…å«ä¸¤ä¸ªæµ‹è¯•é›†ï¼Œå³åˆæˆæµ‹è¯•é›†å’ŒçœŸå®æµ‹è¯•é›†ã€‚å‰è€…æ˜¯é€šè¿‡å‘å¹²å‡€å›¾åƒæ·»åŠ å¤©æ°”å™ªå£°è€Œç”Ÿæˆçš„ï¼Œè€Œåè€…åŒ…å«çœŸå®ä¸–ç•Œçš„å¤©æ°”å™ªå£°ã€‚åŸºäºWXSODï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åŸºçº¿æ¨¡å‹ï¼Œç§°ä¸ºå¤©æ°”æ„ŸçŸ¥ç‰¹å¾èšåˆç½‘ç»œï¼ˆWFANetï¼‰ï¼Œå®ƒé‡‡ç”¨å®Œå…¨ç›‘ç£çš„ä¸¤åˆ†æ”¯æ¶æ„ã€‚å…·ä½“æ¥è¯´ï¼Œå¤©æ°”é¢„æµ‹åˆ†æ”¯æŒ–æ˜ä¸å¤©æ°”ç›¸å…³çš„æ·±åº¦ç‰¹å¾ï¼Œè€Œæ˜¾è‘—æ€§æ£€æµ‹åˆ†æ”¯å°†éª¨å¹²ä¸­æå–çš„è¯­ä¹‰ç‰¹å¾ä¸å¤©æ°”ç‰¹å¾èåˆç”¨äºSODã€‚ä¸17ç§SODæ–¹æ³•çš„å…¨é¢æ¯”è¾ƒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„WFANetåœ¨WXSODä¸Šå–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚ä»£ç å’ŒåŸºå‡†æµ‹è¯•ç»“æœå°†å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/C-water/WXSOD%E3%80%82">https://github.com/C-water/WXSODã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12250v2">PDF</a> Under review</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œæ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜çš„ç ”ç©¶è¯¾é¢˜ã€‚å½“å‰çš„æ–¹æ³•åœ¨è‡ªç„¶åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†å¯¹å™ªå£°çš„å½±å“ç ”ç©¶è¾ƒå°‘ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†å…¨æ–°çš„å¤©æ°”æ‰©å±•æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆWXSODï¼‰æ•°æ®é›†ï¼ŒåŒ…å«å¸¦æœ‰åƒç´ çº§æ ‡æ³¨çš„RGBå›¾åƒã€‚åŒæ—¶ï¼ŒåŸºäºWXSODæ•°æ®é›†æå‡ºäº†æœ‰æ•ˆçš„åŸºçº¿æ¨¡å‹â€”â€”å¤©æ°”æ„ŸçŸ¥ç‰¹å¾èšåˆç½‘ç»œï¼ˆWFANetï¼‰ã€‚è¯¥ç½‘ç»œé‡‡ç”¨å…¨ç›‘ç£çš„ä¸¤åˆ†æ”¯æ¶æ„ï¼Œå¤©æ°”é¢„æµ‹åˆ†æ”¯æŒ–æ˜ä¸å¤©æ°”ç›¸å…³çš„æ·±åº¦ç‰¹å¾ï¼Œæ˜¾è‘—æ€§æ£€æµ‹åˆ†æ”¯èåˆè¯­ä¹‰ç‰¹å¾ä¸å¤©æ°”ç‰¹å¾è¿›è¡ŒSODã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒWFANetåœ¨WXSODä¸Šè¡¨ç°ä¼˜è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰åœ¨å¤æ‚ç¯å¢ƒä¸­ä»å…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>ç°å­˜æ–¹æ³•å¤šåœ¨è‡ªç„¶åœºæ™¯ä¸”ä½å™ªå£°æ¡ä»¶ä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†å¤©æ°”å™ªå£°å¯¹SODæ€§èƒ½çš„å½±å“ç ”ç©¶ä¸è¶³ã€‚</li>
<li>å¼•å…¥æ–°çš„æ•°æ®é›†WXSODï¼ŒåŒ…å«å¸¦æœ‰åƒç´ çº§æ ‡æ³¨çš„RGBå›¾åƒä»¥åº”å¯¹å¤©æ°”å™ªå£°çš„å½±å“ã€‚</li>
<li>æå‡ºåŸºäºWXSODçš„åŸºçº¿æ¨¡å‹WFANetï¼Œé‡‡ç”¨ä¸¤åˆ†æ”¯æ¶æ„ï¼Œèƒ½æœ‰æ•ˆå¤„ç†å¤©æ°”ç›¸å…³çš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ã€‚</li>
<li>WFANetåœ¨å¤©æ°”å™ªå£°æ¡ä»¶ä¸‹è¡¨ç°ä¼˜äºå…¶ä»–17ç§SODæ–¹æ³•ã€‚</li>
<li>WFANetçš„æºä»£ç å’ŒåŸºå‡†æµ‹è¯•ç»“æœå·²å…¬å¼€ï¼Œä¾¿äºåç»­ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12250">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f589a24d200b4e6b5d51a8d98f22c1de" align="middle">
<img src="https://picx.zhimg.com/v2-f825c9cc38dc1cdb012132dd847c3791" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Label-tree-semantic-losses-for-rich-multi-class-medical-image-segmentation"><a href="#Label-tree-semantic-losses-for-rich-multi-class-medical-image-segmentation" class="headerlink" title="Label tree semantic losses for rich multi-class medical image   segmentation"></a>Label tree semantic losses for rich multi-class medical image   segmentation</h2><p><strong>Authors:Junwen Wang, Oscar MacCormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren</strong></p>
<p>Rich and accurate medical image segmentation is poised to underpin the next generation of AI-defined clinical practice by delineating critical anatomy for pre-operative planning, guiding real-time intra-operative navigation, and supporting precise post-operative assessment. However, commonly used learning methods for medical and surgical imaging segmentation tasks penalise all errors equivalently and thus fail to exploit any inter-class semantics in the labels space. This becomes particularly problematic as the cardinality and richness of labels increases to include subtly different classes. In this work, we propose two tree-based semantic loss functions which take advantage of a hierarchical organisation of the labels. We further incorporate our losses in a recently proposed approach for training with sparse, background-free annotations to extend the applicability of our proposed losses. Extensive experiments are reported on two medical and surgical image segmentation tasks, namely head MRI for whole brain parcellation (WBP) with full supervision and neurosurgical hyperspectral imaging (HSI) for scene understanding with sparse annotations. Results demonstrate that our proposed method reaches state-of-the-art performance in both cases. </p>
<blockquote>
<p>ä¸°å¯Œè€Œå‡†ç¡®çš„åŒ»å­¦å›¾åƒåˆ†å‰²è¢«å®šä½ä¸ºæ”¯æ’‘ä¸‹ä¸€ä»£ç”±äººå·¥æ™ºèƒ½å®šä¹‰çš„ä¸´åºŠå®è·µã€‚é€šè¿‡å¯¹å…³é”®è§£å‰–ç»“æ„çš„ç²¾ç»†æç»˜ï¼Œä¸ºæœ¯å‰è§„åˆ’æä¾›æŒ‡å¯¼ï¼Œè¿›è¡Œå®æ—¶æœ¯ä¸­å¯¼èˆªï¼Œå¹¶æ”¯æŒç²¾ç¡®çš„æœ¯åè¯„ä¼°ã€‚ç„¶è€Œï¼Œå¯¹äºåŒ»å­¦å’Œæ‰‹æœ¯å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­å¸¸ç”¨çš„å­¦ä¹ æ–¹æ³•ä¼šç­‰åŒæƒ©ç½šæ‰€æœ‰é”™è¯¯ï¼Œå› æ­¤æ— æ³•åˆ©ç”¨æ ‡ç­¾ç©ºé—´ä¸­çš„ç±»é—´è¯­ä¹‰ã€‚å½“æ ‡ç­¾çš„æ•°é‡å’Œä¸°å¯Œæ€§å¢åŠ ï¼ŒåŒ…æ‹¬å¾®å¦™çš„å·®å¼‚æ—¶ï¼Œè¿™å˜å¾—ç‰¹åˆ«æˆé—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§åŸºäºæ ‘çš„è¯­ä¹‰æŸå¤±å‡½æ•°ï¼Œå®ƒä»¬åˆ©ç”¨äº†æ ‡ç­¾çš„å±‚æ¬¡ç»“æ„ç»„ç»‡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†æˆ‘ä»¬çš„æŸå¤±çº³å…¥æœ€è¿‘æå‡ºçš„å…·æœ‰ç¨€ç–ã€æ— èƒŒæ™¯æ³¨é‡Šçš„è®­ç»ƒæ–¹æ³•ä¸­ï¼Œä»¥æ‰©å±•æˆ‘ä»¬æå‡ºçš„æŸå¤±é€‚ç”¨æ€§ã€‚å…³äºä¸¤é¡¹åŒ»å­¦å’Œæ‰‹æœ¯å›¾åƒåˆ†å‰²ä»»åŠ¡è¿›è¡Œäº†å¤§é‡å®éªŒæŠ¥å‘Šï¼Œå³åœ¨å…¨ç›‘ç£ä¸‹è¿›è¡Œå…¨è„‘éƒ¨åˆ†åŒºï¼ˆWBPï¼‰çš„å¤´éƒ¨MRIä»¥åŠå…·æœ‰ç¨€ç–æ³¨é‡Šçš„åœºæ™¯ç†è§£çš„ç¥ç»å¤–ç§‘é«˜å…‰è°±æˆåƒï¼ˆHSIï¼‰ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.15777v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ»ç–—å›¾åƒåˆ†å‰²çš„ç²¾å‡†æ€§å¯¹äºä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½åœ¨ä¸´åºŠå®è·µä¸­çš„åº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†åŒ»å­¦å’Œæ‰‹æœ¯å›¾åƒåˆ†å‰²ä»»åŠ¡æ—¶ï¼Œå¯¹æ‰€æœ‰é”™è¯¯ä¸€è§†åŒä»ï¼Œå¿½ç•¥äº†æ ‡ç­¾ç©ºé—´ä¸­çš„ç±»é—´è¯­ä¹‰ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸¤ç§åŸºäºæ ‘çš„è¯­ä¹‰æŸå¤±å‡½æ•°ï¼Œå……åˆ†åˆ©ç”¨æ ‡ç­¾çš„å±‚æ¬¡ç»“æ„ã€‚æ­¤å¤–ï¼Œå°†æˆ‘ä»¬çš„æŸå¤±çº³å…¥äº†ä¸€ç§æ–°æå‡ºçš„é’ˆå¯¹ç¨€ç–ã€æ— èƒŒæ™¯æ³¨é‡Šçš„è®­ç»ƒæ–¹æ³•ï¼Œæ‰©å±•äº†æŸå¤±çš„åº”ç”¨èŒƒå›´ã€‚åœ¨åŒ»å­¦å’Œæ‰‹æœ¯å›¾åƒåˆ†å‰²çš„ä¸¤ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒéªŒè¯ï¼ŒåŒ…æ‹¬å…¨ç›‘ç£çš„å¤´MRIå…¨è„‘åˆ†åŒºå’Œç¨€ç–æ³¨é‡Šçš„ç¥ç»å¤–ç§‘é«˜å…‰è°±æˆåƒåœºæ™¯ç†è§£ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†ä¸¤ç§åœºæ™¯çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»ç–—å›¾åƒåˆ†å‰²åœ¨AIä¸´åºŠå®è·µä¸­è‡³å…³é‡è¦ï¼Œæ¶‰åŠæœ¯å‰è§„åˆ’ã€æœ¯ä¸­å¯¼èˆªå’Œæœ¯åè¯„ä¼°ã€‚</li>
<li>ä¼ ç»Ÿå­¦ä¹ æ–¹æ³•åœ¨å¤„ç†åŒ»å­¦å’Œæ‰‹æœ¯å›¾åƒåˆ†å‰²æ—¶å­˜åœ¨å¯¹æ‰€æœ‰é”™è¯¯ç­‰ä»·çš„ç¼ºé™·ï¼Œå¿½ç•¥äº†ç±»é—´è¯­ä¹‰ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸¤ç§åŸºäºæ ‘çš„è¯­ä¹‰æŸå¤±å‡½æ•°ï¼Œåˆ©ç”¨æ ‡ç­¾çš„å±‚æ¬¡ç»“æ„æ¥æå‡åˆ†å‰²æ€§èƒ½ã€‚</li>
<li>æŸå¤±å‡½æ•°çº³å…¥äº†ä¸€ç§é’ˆå¯¹ç¨€ç–ã€æ— èƒŒæ™¯æ³¨é‡Šçš„è®­ç»ƒæ–¹æ³•ï¼Œå¢å¼ºäº†æŸå¤±å‡½æ•°çš„é€‚ç”¨æ€§ã€‚</li>
<li>å®éªŒéªŒè¯åŒ…æ‹¬å¤´MRIå…¨è„‘åˆ†åŒºå’Œç¥ç»å¤–ç§‘é«˜å…‰è°±æˆåƒåœºæ™¯ç†è§£ä¸¤ä¸ªä»»åŠ¡ã€‚</li>
<li>æ–¹æ³•åœ¨å…¨ç›‘ç£å’Œç¨€ç–æ³¨é‡Šåœºæ™¯ä¸‹å‡è¾¾åˆ°äº†æœ€å…ˆè¿›æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.15777">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-48d11c5bf4e7dbd2a07c0107e499e9c3" align="middle">
<img src="https://picx.zhimg.com/v2-6e51e084877a4c2187bcfc22bf0999c6" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Detection-and-Geographic-Localization-of-Natural-Objects-in-the-Wild-A-Case-Study-on-Palms"><a href="#Detection-and-Geographic-Localization-of-Natural-Objects-in-the-Wild-A-Case-Study-on-Palms" class="headerlink" title="Detection and Geographic Localization of Natural Objects in the Wild: A   Case Study on Palms"></a>Detection and Geographic Localization of Natural Objects in the Wild: A   Case Study on Palms</h2><p><strong>Authors:Kangning Cui, Rongkun Zhu, Manqi Wang, Wei Tang, Gregory D. Larsen, Victor P. Pauca, Sarra Alqahtani, Fan Yang, David Segurado, David Lutz, Jean-Michel Morel, Miles R. Silman</strong></p>
<p>Palms are ecologically and economically indicators of tropical forest health, biodiversity, and human impact that support local economies and global forest product supply chains. While palm detection in plantations is well-studied, efforts to map naturally occurring palms in dense forests remain limited by overlapping crowns, uneven shading, and heterogeneous landscapes. We develop PRISM (Processing, Inference, Segmentation, and Mapping), a flexible pipeline for detecting and localizing palms in dense tropical forests using large orthomosaic images. Orthomosaics are created from thousands of aerial images and spanning several to hundreds of gigabytes. Our contributions are threefold. First, we construct a large UAV-derived orthomosaic dataset collected across 21 ecologically diverse sites in western Ecuador, annotated with 8,830 bounding boxes and 5,026 palm center points. Second, we evaluate multiple state-of-the-art object detectors based on efficiency and performance, integrating zero-shot SAM 2 as the segmentation backbone, and refining the results for precise geographic mapping. Third, we apply calibration methods to align confidence scores with IoU and explore saliency maps for feature explainability. Though optimized for palms, PRISM is adaptable for identifying other natural objects, such as eastern white pines. Future work will explore transfer learning for lower-resolution datasets (0.5 to 1m). </p>
<blockquote>
<p>æ£•æ¦ˆæ ‘ä½œä¸ºç”Ÿæ€å’Œç»æµæŒ‡æ ‡ï¼Œåæ˜ äº†çƒ­å¸¦é›¨æ—å¥åº·ã€ç”Ÿç‰©å¤šæ ·æ€§å’Œäººç±»å½±å“ï¼Œæ”¯æŒç€åœ°æ–¹ç»æµå’Œå…¨çƒæ£®æ—äº§å“ä¾›åº”é“¾ã€‚è™½ç„¶æ£•æ¦ˆæ ‘åœ¨ç§æ¤å›­çš„æ£€æµ‹å·²ç»å¾—åˆ°äº†å¾ˆå¥½çš„ç ”ç©¶ï¼Œä½†è‡ªç„¶ç”Ÿé•¿çš„æ£•æ¦ˆæ ‘åœ¨å¯†é›†æ£®æ—ä¸­çš„åœ°å›¾ç»˜åˆ¶å·¥ä½œä»å—åˆ°æ ‘å† é‡å ã€é˜´å½±ä¸å‡å’Œæ™¯è§‚å¼‚è´¨æ€§çš„é™åˆ¶ã€‚æˆ‘ä»¬å¼€å‘äº†PRISMï¼ˆå¤„ç†ã€æ¨æ–­ã€åˆ†å‰²å’Œæ˜ å°„ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªçµæ´»çš„ç®¡é“ï¼Œåˆ©ç”¨å¤§å‹æ­£å°„é•¶åµŒå›¾åƒæ£€æµ‹å’Œåœ¨çƒ­å¸¦å¯†é›†æ£®æ—ä¸­å®šä½æ£•æ¦ˆæ ‘ã€‚æ­£å°„é•¶åµŒå›¾åƒæ˜¯ç”±æ•°åƒå¼ èˆªç©ºç…§ç‰‡åˆ¶æˆï¼Œå¹¶è·¨è¶Šå‡ åˆ°æ•°ç™¾å‰å­—èŠ‚ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰ä¸‰ç‚¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§å‹æ— äººæœºè¡ç”Ÿçš„æ­£å°„é•¶åµŒæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ”¶é›†äº†å„ç“œå¤šå°”è¥¿éƒ¨21ä¸ªç”Ÿæ€å„å¼‚çš„ç«™ç‚¹çš„æ•°æ®ï¼Œå¹¶ç”¨8830ä¸ªè¾¹ç•Œæ¡†å’Œ5026ä¸ªæ£•æ¦ˆæ ‘ä¸­å¿ƒç‚¹è¿›è¡Œæ ‡æ³¨ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å¤šä¸ªæœ€å…ˆè¿›çš„ç‰©ä½“æ£€æµ‹å™¨çš„æ•ˆç‡å’Œæ€§èƒ½ï¼Œå°†é›¶å°„å‡»SAM 2ä½œä¸ºåˆ†å‰²ä¸»å¹²è¿›è¡Œæ•´åˆï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œç»†åŒ–ï¼Œä»¥å®ç°ç²¾ç¡®åœ°ç†æ˜ å°„ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬åº”ç”¨æ ¡å‡†æ–¹æ³•ä½¿ç½®ä¿¡åº¦å¾—åˆ†ä¸IoUå¯¹é½ï¼Œå¹¶æ¢ç´¢æ˜¾è‘—æ€§åœ°å›¾è¿›è¡Œç‰¹å¾è§£é‡Šã€‚è™½ç„¶PRISMæ˜¯é’ˆå¯¹æ£•æ¦ˆæ ‘è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä½†å®ƒä¹Ÿå¯ä»¥ç”¨äºè¯†åˆ«å…¶ä»–è‡ªç„¶ç‰©ä½“ï¼Œå¦‚ä¸œéƒ¨ç™½çš®æ¾ã€‚æœªæ¥çš„å·¥ä½œå°†æ¢ç´¢ä½åˆ†è¾¨ç‡æ•°æ®é›†ï¼ˆ0.5è‡³1ç±³ï¼‰çš„è¿ç§»å­¦ä¹ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13023v2">PDF</a> 15 pages, 8 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†åˆ©ç”¨PRISMæŠ€æœ¯æ£€æµ‹çƒ­å¸¦æ£®æ—ä¸­çš„æ£•æ¦ˆæ ‘çš„é—®é¢˜ã€‚æ£•æ¦ˆæ ‘æ˜¯çƒ­å¸¦æ£®æ—ç”Ÿæ€å’Œç»æµå¥åº·çš„é‡è¦æ ‡å¿—ï¼Œä½†å¯†é›†æ£®æ—ä¸­çš„æ£•æ¦ˆæ ‘æ£€æµ‹é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚PRISMæŠ€æœ¯åˆ©ç”¨å¤§å‹æ­£å°„å½±åƒå›¾å®ç°æ£•æ¦ˆæ ‘çš„å®šä½ä¸æ£€æµ‹ã€‚è¯¥æŠ€æœ¯åœ¨å¤šä¸ªç”Ÿæ€å„å¼‚çš„ç«™ç‚¹æ”¶é›†äº†å¤§è§„æ¨¡æ— äººæœºç”Ÿæˆçš„æ­£å°„å½±åƒæ•°æ®é›†ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œäº†æ ‡æ³¨ã€‚é€šè¿‡è¯„ä¼°å¤šç§å…ˆè¿›çš„ç‰©ä½“æ£€æµ‹å™¨ï¼Œç¡®å®šäº†åŸºäºé›¶å°„å‡»SAM 2çš„åˆ†æ®µæ¡†æ¶ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜é‡‡ç”¨äº†æ ¡å‡†æ–¹æ³•å¯¹é½ç½®ä¿¡åº¦å¾—åˆ†ä¸IoUï¼Œå¹¶æ¢ç´¢äº†ç‰¹å¾è§£é‡Šæ€§çš„æ˜¾è‘—æ€§åœ°å›¾ã€‚è™½ç„¶PRISMé’ˆå¯¹æ£•æ¦ˆæ ‘è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä½†å®ƒä¹Ÿå¯åº”ç”¨äºè¯†åˆ«å…¶ä»–è‡ªç„¶ç‰©ä½“ã€‚æœªæ¥ç ”ç©¶å°†æ¢ç´¢ä½åˆ†è¾¨ç‡æ•°æ®é›†çš„è¿ç§»å­¦ä¹ åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯æœ¬æ–‡çš„ä¸»è¦è§‚ç‚¹ä¸è§è§£ï¼š</p>
<ol>
<li>æ£•æ¦ˆæ ‘ä½œä¸ºçƒ­å¸¦æ£®æ—ç”Ÿæ€å’Œç»æµå¥åº·çš„æ ‡å¿—ï¼Œå¯¹å½“åœ°ç»æµå’Œå…¨çƒæ£®æ—äº§å“ä¾›åº”é“¾å…·æœ‰æ”¯æŒä½œç”¨ã€‚</li>
<li>åœ¨å¯†é›†æ£®æ—ä¸­è‡ªç„¶ç”Ÿé•¿çš„æ£•æ¦ˆæ ‘æ£€æµ‹é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚æ ‘å† é‡å ã€é˜´å½±ä¸å‡å’Œæ™¯è§‚å¼‚è´¨æ€§ç­‰ã€‚</li>
<li>PRISMæ˜¯ä¸€ç§çµæ´»çš„ç®¡é“æŠ€æœ¯ï¼Œç”¨äºåˆ©ç”¨å¤§å‹æ­£å°„å½±åƒå›¾æ£€æµ‹çƒ­å¸¦æ£®æ—ä¸­çš„æ£•æ¦ˆæ ‘ã€‚</li>
<li>PRISMæŠ€æœ¯åœ¨æ— äººæœºç”Ÿæˆçš„å¤§è§„æ¨¡æ­£å°„å½±åƒæ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œè¿™äº›æ•°æ®é›†æ¶µç›–äº†è¥¿å„ç“œå¤šå°”21ä¸ªç”Ÿæ€å„å¼‚çš„ç«™ç‚¹ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œäº†æ ‡æ³¨ã€‚</li>
<li>é€šè¿‡è¯„ä¼°å¤šç§å…ˆè¿›çš„ç‰©ä½“æ£€æµ‹å™¨ï¼Œç¡®å®šäº†åŸºäºé›¶å°„å‡»SAM 2çš„åˆ†æ®µæ¡†æ¶ï¼Œä»¥æé«˜æ£€æµ‹çš„ç²¾ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>PRISMæŠ€æœ¯é‡‡ç”¨æ ¡å‡†æ–¹æ³•å¯¹é½ç½®ä¿¡åº¦å¾—åˆ†ä¸IoUï¼Œå¹¶åˆ©ç”¨æ˜¾è‘—æ€§åœ°å›¾è¿›è¡Œç‰¹å¾è§£é‡Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13023">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-19951be91e92998c5340a91c70433972" align="middle">
<img src="https://picx.zhimg.com/v2-f8ac62e6cba620c7dfb9560b099f8ee9" align="middle">
<img src="https://picx.zhimg.com/v2-1c14c60960ed407b525f9730ae4cfb15" align="middle">
<img src="https://picx.zhimg.com/v2-efba10441f10c0a6f2f9fd370dff1393" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Deep-Fourier-embedded-Network-for-RGB-and-Thermal-Salient-Object-Detection"><a href="#Deep-Fourier-embedded-Network-for-RGB-and-Thermal-Salient-Object-Detection" class="headerlink" title="Deep Fourier-embedded Network for RGB and Thermal Salient Object   Detection"></a>Deep Fourier-embedded Network for RGB and Thermal Salient Object   Detection</h2><p><strong>Authors:Pengfei Lyu, Xiaosheng Yu, Pak-Hei Yeung, Chengdong Wu, Jagath C. Rajapakse</strong></p>
<p>The rapid development of deep learning has significantly improved salient object detection (SOD) combining both RGB and thermal (RGB-T) images. However, existing Transformer-based RGB-T SOD models with quadratic complexity are memory-intensive, limiting their application in high-resolution bimodal feature fusion. To overcome this limitation, we propose a purely Fourier Transform-based model, namely Deep Fourier-embedded Network (FreqSal), for accurate RGB-T SOD. Specifically, we leverage the efficiency of Fast Fourier Transform with linear complexity to design three key components: (1) To fuse RGB and thermal modalities, we propose Modal-coordinated Perception Attention, which aligns and enhances bimodal Fourier representation in multiple dimensions; (2) To clarify object edges and suppress noise, we design Frequency-decomposed Edge-aware Block, which deeply decomposes and filters Fourier components of low-level features; (3) To accurately decode features, we propose Fourier Residual Channel Attention Block, which prioritizes high-frequency information while aligning channel-wise global relationships. Additionally, even when converged, existing deep learning-based SOD modelsâ€™ predictions still exhibit frequency gaps relative to ground-truth. To address this problem, we propose Co-focus Frequency Loss, which dynamically weights hard frequencies during edge frequency reconstruction by cross-referencing bimodal edge information in the Fourier domain. Extensive experiments on ten bimodal SOD benchmark datasets demonstrate that FreqSal outperforms twenty-nine existing state-of-the-art bimodal SOD models. Comprehensive ablation studies further validate the value and effectiveness of our newly proposed components. The code is available at <a target="_blank" rel="noopener" href="https://github.com/JoshuaLPF/FreqSal">https://github.com/JoshuaLPF/FreqSal</a>. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•æ˜¾è‘—æé«˜äº†ç»“åˆRGBå’Œçº¢å¤–çƒ­æˆåƒï¼ˆRGB-Tï¼‰å›¾åƒçš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºTransformerçš„RGB-T SODæ¨¡å‹å…·æœ‰äºŒæ¬¡å¤æ‚åº¦ï¼Œå†…å­˜å¯†é›†ï¼Œé™åˆ¶äº†å…¶åœ¨é«˜åˆ†è¾¨ç‡åŒæ¨¡æ€ç‰¹å¾èåˆä¸­çš„åº”ç”¨ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºçº¯å‚…é‡Œå¶å˜æ¢çš„æ¨¡å‹ï¼Œåä¸ºDeep Fourier-embedded Networkï¼ˆFreqSalï¼‰ï¼Œç”¨äºç²¾ç¡®çš„RGB-T SODã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ©ç”¨å…·æœ‰çº¿æ€§å¤æ‚åº¦çš„å¿«é€Ÿå‚…é‡Œå¶å˜æ¢çš„æ•ˆç‡æ¥è®¾è®¡äº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šï¼ˆ1ï¼‰ä¸ºäº†èåˆRGBå’Œçº¢å¤–çƒ­æˆåƒæ¨¡æ€ï¼Œæˆ‘ä»¬æå‡ºäº†Modal-coordinated Perception Attentionï¼Œå®ƒå¯ä»¥åœ¨å¤šä¸ªç»´åº¦ä¸­å¯¹é½å¹¶å¢å¼ºåŒæ¨¡æ€å‚…é‡Œå¶è¡¨ç¤ºï¼›ï¼ˆ2ï¼‰ä¸ºäº†æ˜ç¡®å¯¹è±¡è¾¹ç¼˜å¹¶æŠ‘åˆ¶å™ªå£°ï¼Œæˆ‘ä»¬è®¾è®¡äº†Frequency-decomposed Edge-aware Blockï¼Œå®ƒæ·±åº¦åœ°åˆ†è§£å¹¶è¿‡æ»¤äº†ä½çº§ç‰¹å¾çš„å‚…é‡Œå¶æˆåˆ†ï¼›ï¼ˆ3ï¼‰ä¸ºäº†å‡†ç¡®åœ°è§£ç ç‰¹å¾ï¼Œæˆ‘ä»¬æå‡ºäº†å‚…ç«‹å¶æ®‹å·®é€šé“æ³¨æ„åŠ›å—ï¼ˆFourier Residual Channel Attention Blockï¼‰ï¼Œå®ƒä¼˜å…ˆå¤„ç†é«˜é¢‘ä¿¡æ¯ï¼ŒåŒæ—¶è°ƒæ•´é€šé“çº§çš„å…¨å±€å…³ç³»ã€‚æ­¤å¤–ï¼Œå³ä½¿ç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„SODæ¨¡å‹æ”¶æ•›åï¼Œå…¶é¢„æµ‹ç»“æœç›¸å¯¹äºçœŸå®å€¼ä»ä¼šæ˜¾ç¤ºé¢‘ç‡å·®è·ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Co-focus Frequency Lossã€‚å®ƒé€šè¿‡å‚è€ƒåŒæ¨¡æ€è¾¹ç¼˜ä¿¡æ¯çš„å‚…é‡Œå¶åŸŸä¸­çš„ä¿¡æ¯ï¼Œåœ¨è¾¹ç¼˜é¢‘ç‡é‡å»ºè¿‡ç¨‹ä¸­åŠ¨æ€åŠ æƒç¡¬é¢‘ç‡ã€‚åœ¨åä¸ªåŒæ¨¡æ€SODåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFreqSalåœ¨äºŒåä¹ç§æœ€å…ˆè¿›çš„åŒæ¨¡æ€SODæ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ã€‚å…¨é¢çš„æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬æ–°æå‡ºçš„ç»„ä»¶çš„ä»·å€¼å’Œæœ‰æ•ˆæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JoshuaLPF/FreqSal%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/JoshuaLPF/FreqSalè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18409v3">PDF</a> Accepted by TCSVT2025</p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦å­¦ä¹ çš„å¿«é€Ÿå‘å±•æ˜¾è‘—æé«˜äº†ç»“åˆRGBå’Œçº¢å¤–çƒ­æˆåƒï¼ˆRGB-Tï¼‰å›¾åƒçš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰èƒ½åŠ›ã€‚é’ˆå¯¹ç°æœ‰åŸºäºTransformerçš„RGB-T SODæ¨¡å‹å†…å­˜å¯†é›†ã€å¤æ‚åº¦ä¸ºäºŒæ¬¡æ–¹çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºçº¯å‚…é‡Œå¶å˜æ¢çš„æ¨¡å‹â€”â€”Deep Fourier-embedded Networkï¼ˆFreqSalï¼‰ï¼Œç”¨äºå‡†ç¡®çš„RGB-T SODã€‚è¯¥æ¨¡å‹åˆ©ç”¨å…·æœ‰çº¿æ€§å¤æ‚åº¦çš„å¿«é€Ÿå‚…é‡Œå¶å˜æ¢çš„é«˜æ•ˆæ€§ï¼Œè®¾è®¡äº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ä»¥æé«˜æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†Co-focus Frequency Lossï¼Œä»¥åŠ¨æ€æƒé‡å¤„ç†è¾¹ç¼˜é¢‘ç‡é‡å»ºä¸­çš„ç¡¬é¢‘ç‡ã€‚å®éªŒè¯æ˜ï¼ŒFreqSalåœ¨åç§åŒæ¨¡æ€SODåŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºäºŒåä¹ç§æœ€å…ˆè¿›çš„åŒæ¨¡æ€SODæ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ çš„è¿›æ­¥æ¨åŠ¨äº†RGBå’Œçº¢å¤–çƒ­æˆåƒå›¾åƒç»“åˆçš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹çš„å‘å±•ã€‚</li>
<li>ç°æœ‰åŸºäºTransformerçš„RGB-T SODæ¨¡å‹å­˜åœ¨å†…å­˜å¯†é›†å’ŒäºŒæ¬¡æ–¹å¤æ‚åº¦çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨é«˜åˆ†è¾¨ç‡åŒæ¨¡æ€ç‰¹å¾èåˆä¸­çš„åº”ç”¨ã€‚</li>
<li>æå‡ºäº†åŸºäºçº¯å‚…é‡Œå¶å˜æ¢çš„Deep Fourier-embedded Networkï¼ˆFreqSalï¼‰æ¨¡å‹ï¼Œåˆ©ç”¨å¿«é€Ÿå‚…é‡Œå¶å˜æ¢çš„çº¿æ€§å¤æ‚åº¦æé«˜æ•ˆç‡ã€‚</li>
<li>FreqSalæ¨¡å‹è®¾è®¡äº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæ¨¡æ€åè°ƒæ„ŸçŸ¥æ³¨æ„åŠ›ã€é¢‘ç‡åˆ†è§£è¾¹ç¼˜æ„ŸçŸ¥å—å’Œå‚…é‡Œå¶æ®‹å·®é€šé“æ³¨æ„åŠ›å—ï¼Œä»¥æé«˜æ€§èƒ½ã€‚</li>
<li>å¼•å…¥Co-focus Frequency Lossï¼Œé€šè¿‡äº¤å‰å¼•ç”¨åŒæ¨¡æ€è¾¹ç¼˜ä¿¡æ¯ï¼ŒåŠ¨æ€æƒé‡å¤„ç†è¾¹ç¼˜é¢‘ç‡é‡å»ºä¸­çš„ç¡¬é¢‘ç‡ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒFreqSalåœ¨å¤šä¸ªåŒæ¨¡æ€SODåŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–å…ˆè¿›æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18409">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3ff22a7ff587498bae77ccf73483666" align="middle">
<img src="https://picx.zhimg.com/v2-c849aafcfb0c9b77e6d4a1935445be01" align="middle">
<img src="https://picx.zhimg.com/v2-78c5a8d141cd6acd1422782ba90e18ea" align="middle">
<img src="https://picx.zhimg.com/v2-eae209bf3d15e01c89249a2bb6044804" align="middle">
<img src="https://picx.zhimg.com/v2-a6441ce003360889a1b4ac67f56fb690" align="middle">
<img src="https://picx.zhimg.com/v2-541e33b1eda23eb42d0c4aca62768e3a" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-06/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-06/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-06/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-40850e19634e7e0e853ad21db3af08c1" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  NSYNC Negative Synthetic Image Generation for Contrastive Training to   Improve Stylized Text-To-Image Translation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-06/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ad4db1eb33984e939a0c754ef1116cd3" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  Diffusion Models are Robust Pretrainers
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32271.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
