<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  PLUTO-4 Frontier Pathology Foundation Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9c819698da2c06973cc68e3e0d3c31c6')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    44 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-06-æ›´æ–°"><a href="#2025-11-06-æ›´æ–°" class="headerlink" title="2025-11-06 æ›´æ–°"></a>2025-11-06 æ›´æ–°</h1><h2 id="PLUTO-4-Frontier-Pathology-Foundation-Models"><a href="#PLUTO-4-Frontier-Pathology-Foundation-Models" class="headerlink" title="PLUTO-4: Frontier Pathology Foundation Models"></a>PLUTO-4: Frontier Pathology Foundation Models</h2><p><strong>Authors:Harshith Padigela, Shima Nofallah, Atchuth Naveen Chilaparasetti, Ryun Han, Andrew Walker, Judy Shen, Chintan Shah, Blake Martin, Aashish Sood, Elliot Miller, Ben Glass, Andy Beck, Harsha Pokkalla, Syed Ashar Javed</strong></p>
<p>Foundation models trained on large-scale pathology image corpora have demonstrated strong transfer capabilities across diverse histopathology tasks. Building on this progress, we introduce PLUTO-4, our next generation of pathology foundation models that extend the Pathology-Universal Transformer (PLUTO) to frontier scale. We share two complementary Vision Transformer architectures in the PLUTO-4 family: a compact and efficient PLUTO-4S model optimized for multi-scale deployment using a FlexiViT setup with 2D-RoPE embeddings, and a frontier-scale PLUTO-4G model trained with a single patch size to maximize representation capacity and stability. Both models are pretrained using a self-supervised objective derived from DINOv2 on a large multi-institutional corpus containing 551,164 WSIs from 137,144 patients across over 50 institutions, spanning over 60 disease types and over 100 stains. Comprehensive evaluation across public and internal benchmarks demonstrates that PLUTO-4 achieves state-of-the-art performance on tasks requiring varying spatial and biological context, including patch-level classification, segmentation, and slide-level diagnosis. The compact PLUTO-4S provides high-throughput and robust performance for practical deployment, while PLUTO-4G establishes new performance frontiers across multiple pathology benchmarks, including an 11% improvement in dermatopathology diagnosis. These diverse improvements underscore PLUTO-4â€™s potential to transform real-world applications as a backbone for translational research and diagnostic use cases. </p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡ç—…ç†å­¦å›¾åƒè¯­æ–™åº“è®­ç»ƒçš„foundationæ¨¡å‹å·²åœ¨å„ç§ç»„ç»‡ç—…ç†å­¦ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„è¿ç§»èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†PLUTO-4ï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸‹ä¸€ä»£ç—…ç†å­¦foundationæ¨¡å‹ï¼Œå®ƒå°†Pathology-Universal Transformerï¼ˆPLUTOï¼‰æ¨å‘äº†å‰æ²¿è§„æ¨¡ã€‚æˆ‘ä»¬åˆ†äº«äº†PLUTO-4ç³»åˆ—ä¸­çš„ä¸¤ç§äº’è¡¥çš„Vision Transformeræ¶æ„ï¼šä¸€ä¸ªç´§å‡‘é«˜æ•ˆçš„PLUTO-4Sæ¨¡å‹ï¼Œé‡‡ç”¨FlexiViTè®¾ç½®å’Œ2D-RoPEåµŒå…¥ï¼Œä¼˜åŒ–å¤šå°ºåº¦éƒ¨ç½²ï¼›ä»¥åŠä¸€ä¸ªå‰æ²¿è§„æ¨¡çš„PLUTO-4Gæ¨¡å‹ï¼Œé‡‡ç”¨å•ä¸€è¡¥ä¸å¤§å°è¿›è¡Œè®­ç»ƒï¼Œä»¥æœ€å¤§åŒ–è¡¨ç¤ºèƒ½åŠ›å’Œç¨³å®šæ€§ã€‚è¿™ä¸¤ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨ä»DINOv2æ´¾ç”Ÿçš„è‡ªç›‘ç£ç›®æ ‡ï¼Œåœ¨åŒ…å«551,164å¼ WSIçš„å¤§å‹å¤šæœºæ„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™äº›å›¾åƒæ¥è‡ªè¶…è¿‡50ä¸ªæœºæ„çš„137,144åæ‚£è€…ï¼Œè·¨è¶Š60å¤šç§ç–¾ç—…ç±»å‹å’Œè¶…è¿‡100ç§æŸ“è‰²ã€‚åœ¨å…¬å…±åŸºå‡†æµ‹è¯•å’Œå†…éƒ¨åŸºå‡†æµ‹è¯•çš„ç»¼åˆè¯„ä¼°ä¸­ï¼ŒPLUTO-4åœ¨éœ€è¦ä¸åŒç©ºé—´å’Œç”Ÿç‰©ä¸Šä¸‹æ–‡çš„ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è¡¥ä¸çº§åˆ†ç±»ã€åˆ†å‰²å’Œå¹»ç¯ç‰‡çº§è¯Šæ–­ã€‚ç´§å‡‘çš„PLUTO-4Sä¸ºå®é™…éƒ¨ç½²æä¾›äº†é«˜é€šé‡å’Œç¨³å¥çš„æ€§èƒ½ï¼Œè€ŒPLUTO-4Gåœ¨å¤šä¸ªç—…ç†å­¦åŸºå‡†æµ‹è¯•ä¸­å»ºç«‹äº†æ–°çš„æ€§èƒ½è¾¹ç•Œï¼ŒåŒ…æ‹¬çš®è‚¤ç—…ç†å­¦è¯Šæ–­æé«˜äº†11%ã€‚è¿™äº›ä¸åŒçš„æ”¹è¿›å‡¸æ˜¾äº†PLUTO-4ä½œä¸ºç¿»è¯‘ç ”ç©¶å’Œè¯Šæ–­ç”¨ä¾‹çš„æ½œåœ¨èƒ½åŠ›ï¼Œå¯¹ç°å®ä¸–ç•Œçš„åº”ç”¨äº§ç”Ÿå˜é©æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02826v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹ç—…ç†å›¾åƒè¯­æ–™åº“è®­ç»ƒçš„æ¨¡å‹å·²å±•ç°å‡ºè·¨å¤šç§ç»„ç»‡ç—…ç†å­¦ä»»åŠ¡çš„å¼ºå¤§è¿ç§»èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸‹ä¸€ä»£ç—…ç†åŸºç¡€æ¨¡å‹PLUTO-4ï¼Œå®ƒæ‰©å±•äº†ç—…ç†é€šç”¨å˜å‹å™¨ï¼ˆPLUTOï¼‰è‡³å‰æ²¿è§„æ¨¡ã€‚æˆ‘ä»¬åˆ†äº«äº†PLUTO-4ç³»åˆ—ä¸­çš„ä¸¤ç§äº’è¡¥çš„Vision Transformeræ¶æ„ï¼šä¼˜åŒ–çš„ç´§å‡‘é«˜æ•ˆPLUTO-4Sæ¨¡å‹ï¼Œä½¿ç”¨FlexiViTè®¾ç½®å’Œ2D-RoPEåµŒå…¥è¿›è¡Œå¤šå°ºåº¦éƒ¨ç½²ï¼›ä»¥åŠå‰æ²¿è§„æ¨¡çš„PLUTO-4Gæ¨¡å‹ï¼Œä½¿ç”¨å•ä¸€è¡¥ä¸å°ºå¯¸è¿›è¡Œè®­ç»ƒï¼Œä»¥æœ€å¤§åŒ–è¡¨ç¤ºèƒ½åŠ›å’Œç¨³å®šæ€§ã€‚ä¸¤è€…éƒ½åœ¨åŒ…å«551,164å¼ WSIçš„å¤§å‹å¤šæœºæ„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ¶µç›–äº†è¶…è¿‡60ç§ç–¾ç—…ç±»å‹å’Œè¶…è¿‡100ç§æŸ“è‰²ã€‚åœ¨å…¬å…±å’Œå†…éƒ¨åŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒPLUTO-4åœ¨éœ€è¦ä¸åŒç©ºé—´å’Œç”Ÿç‰©ä¸Šä¸‹æ–‡çš„ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è¡¥ä¸çº§åˆ«åˆ†ç±»ã€åˆ†å‰²å’Œå¹»ç¯ç‰‡çº§åˆ«è¯Šæ–­ã€‚ç´§å‡‘çš„PLUTO-4Sä¸ºå®é™…éƒ¨ç½²æä¾›äº†é«˜ååé‡å’Œç¨³å¥çš„æ€§èƒ½ï¼Œè€ŒPLUTO-4Gåœ¨å¤šä¸ªç—…ç†åŸºå‡†æµ‹è¯•ä¸Šå»ºç«‹äº†æ–°çš„æ€§èƒ½å‰æ²¿ï¼ŒåŒ…æ‹¬åœ¨çš®è‚¤ç—…ç†è¯Šæ–­ä¸­æé«˜äº†11%çš„æ€§èƒ½ã€‚è¿™äº›å¤šæ ·åŒ–çš„æ”¹è¿›çªæ˜¾äº†PLUTO-4ä½œä¸ºç¿»è¯‘ç ”ç©¶å’Œè¯Šæ–­ç”¨ä¾‹çš„åç«¯ï¼Œåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PLUTO-4æ˜¯ä¸‹ä¸€ä»£ç—…ç†åŸºç¡€æ¨¡å‹ï¼Œæ‰©å±•äº†PLUTOè‡³å‰æ²¿è§„æ¨¡ï¼ŒåŒ…å«ä¸¤ç§Vision Transformeræ¶æ„ï¼šPLUTO-4Så’ŒPLUTO-4Gã€‚</li>
<li>PLUTO-4Sæ¨¡å‹ä¼˜åŒ–ä¸”ç´§å‡‘é«˜æ•ˆï¼Œé€‚ç”¨äºå¤šå°ºåº¦éƒ¨ç½²ï¼Œé‡‡ç”¨FlexiViTè®¾ç½®å’Œ2D-RoPEåµŒå…¥ã€‚</li>
<li>PLUTO-4Gæ¨¡å‹è®­ç»ƒä½¿ç”¨å•ä¸€è¡¥ä¸å°ºå¯¸ï¼Œä»¥æœ€å¤§åŒ–è¡¨ç¤ºèƒ½åŠ›å’Œç¨³å®šæ€§ã€‚</li>
<li>æ¨¡å‹é¢„è®­ç»ƒåœ¨åŒ…å«å¤§é‡ç—…ç†å›¾åƒçš„å¤§å‹å¤šæœºæ„è¯­æ–™åº“ä¸Šè¿›è¡Œï¼Œæ¶µç›–å¤šç§ç–¾ç—…ç±»å‹å’ŒæŸ“è‰²ã€‚</li>
<li>PLUTO-4åœ¨å¤šç§ä»»åŠ¡ä¸Šå®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è¡¥ä¸çº§åˆ«åˆ†ç±»ã€åˆ†å‰²å’Œå¹»ç¯ç‰‡çº§åˆ«è¯Šæ–­ã€‚</li>
<li>PLUTO-4Sé€‚ç”¨äºå®é™…éƒ¨ç½²ï¼Œå…·æœ‰é«˜é€šé‡å’Œç¨³å¥æ€§èƒ½ã€‚</li>
<li>PLUTO-4Gåœ¨å¤šä¸ªç—…ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬çš®è‚¤ç—…ç†è¯Šæ–­ä»»åŠ¡çš„11%æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02826">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-622af7abf39ef17160f9af3f01e82d30" align="middle">
<img src="https://picx.zhimg.com/v2-ae6649ee1c77e87b5d4f730a942bf1bd" align="middle">
<img src="https://picx.zhimg.com/v2-52638ee998286d13eb430fc87225b486" align="middle">
<img src="https://picx.zhimg.com/v2-9c321ba58eca9cae472bbee372aeb7ec" align="middle">
<img src="https://picx.zhimg.com/v2-438c2ad22513919bd3a00a66c2d7624d" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Wavelet-Optimized-Motion-Artifact-Correction-in-3D-MRI-Using-Pre-trained-2D-Score-Priors"><a href="#Wavelet-Optimized-Motion-Artifact-Correction-in-3D-MRI-Using-Pre-trained-2D-Score-Priors" class="headerlink" title="Wavelet-Optimized Motion Artifact Correction in 3D MRI Using Pre-trained   2D Score Priors"></a>Wavelet-Optimized Motion Artifact Correction in 3D MRI Using Pre-trained   2D Score Priors</h2><p><strong>Authors:Genyuan Zhang, Xuyang Duan, Songtao Zhu, Ao Wang, Fenglin Liu</strong></p>
<p>Motion artifacts in magnetic resonance imaging (MRI) remain a major challenge, as they degrade image quality and compromise diagnostic reliability. Score-based generative models (SGMs) have recently shown promise for artifact removal. However, existing 3D SGM-based approaches are limited in two key aspects: (1) their strong dependence on known forward operators makes them ineffective for correcting MRI motion artifacts, and (2) their slow inference speed hinders clinical translation. To overcome these challenges, we propose a wavelet-optimized end-to-end framework for 3D MRI motion correct using pre-trained 2D score priors (3D-WMoCo). Specifically, two orthogonal 2D score priors are leveraged to guide the 3D distribution prior, while a mean-reverting stochastic differential equation (SDE) is employed to model the restoration process of motion-corrupted 3D volumes to motion-free 3D distribution. Furthermore, wavelet diffusion is introduced to accelerate inference, and wavelet convolution is applied to enhance feature extraction. We validate the effectiveness of our approach through both simulated motion artifact experiments and real-world clinical motion artifact correction tests. The proposed method achieves robust performance improvements over existing techniques. Implementation details and source code are available at: <a target="_blank" rel="noopener" href="https://github.com/ZG-yuan/3D-WMoCo">https://github.com/ZG-yuan/3D-WMoCo</a>. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­çš„è¿åŠ¨ä¼ªå½±ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒä»¬ä¼šé™ä½å›¾åƒè´¨é‡å¹¶å½±å“è¯Šæ–­çš„å¯é æ€§ã€‚åŸºäºå¾—åˆ†çš„ç”Ÿæˆæ¨¡å‹ï¼ˆSGMsï¼‰æœ€è¿‘åœ¨å»é™¤ä¼ªå½±æ–¹é¢æ˜¾ç¤ºå‡ºå¸Œæœ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„3D SGMæ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šï¼ˆ1ï¼‰å®ƒä»¬å¯¹å·²çŸ¥å‰å‘ç®—å­çš„å¼ºçƒˆä¾èµ–ä½¿å®ƒä»¬æ— æ³•æœ‰æ•ˆåœ°æ ¡æ­£MRIè¿åŠ¨ä¼ªå½±ï¼›ï¼ˆ2ï¼‰å…¶ç¼“æ…¢çš„æ¨ç†é€Ÿåº¦é˜»ç¢äº†ä¸´åºŠè½¬åŒ–ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨é¢„è®­ç»ƒçš„2Dåˆ†æ•°å…ˆéªŒè¿›è¡Œ3D MRIè¿åŠ¨æ ¡æ­£çš„å°æ³¢ä¼˜åŒ–ç«¯åˆ°ç«¯æ¡†æ¶ï¼ˆ3D-WMoCoï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨ä¸¤ä¸ªæ­£äº¤çš„2Dåˆ†æ•°å…ˆéªŒæ¥å¼•å¯¼3Dåˆ†å¸ƒå…ˆéªŒï¼ŒåŒæ—¶é‡‡ç”¨å‡å€¼å›å½’éšæœºå¾®åˆ†æ–¹ç¨‹ï¼ˆSDEï¼‰å¯¹è¿åŠ¨æŸåçš„3Dä½“ç§¯çš„æ¢å¤è¿‡ç¨‹è¿›è¡Œå»ºæ¨¡ï¼Œä»¥å½¢æˆæ— è¿åŠ¨çš„3Dåˆ†å¸ƒã€‚æ­¤å¤–ï¼Œå¼•å…¥å°æ³¢æ‰©æ•£ä»¥åŠ é€Ÿæ¨ç†ï¼Œå¹¶åº”ç”¨å°æ³¢å·ç§¯ä»¥å¢å¼ºç‰¹å¾æå–ã€‚æˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿè¿åŠ¨ä¼ªå½±å®éªŒå’Œç°å®ä¸–ç•Œä¸­çš„ä¸´åºŠè¿åŠ¨ä¼ªå½±æ ¡æ­£æµ‹è¯•éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨æŠ€æœ¯ä¸Šå®ç°äº†å¯¹ç°æœ‰æŠ€æœ¯çš„ç¨³å¥æ€§èƒ½æå‡ã€‚æœ‰å…³å®æ–½ç»†èŠ‚å’Œæºä»£ç ï¼Œè¯·å‚è§ï¼š<a target="_blank" rel="noopener" href="https://github.com/ZG-yuan/3D-WMoCo%E3%80%82">https://github.com/ZG-yuan/3D-WMoCoã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02256v1">PDF</a> 11 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹ä¸‰ç»´MRIè¿åŠ¨æ ¡æ­£çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼ˆ3D-WMoCoï¼‰ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„äºŒç»´åˆ†æ•°å…ˆéªŒå’Œå°æ³¢ä¼˜åŒ–æŠ€æœ¯ï¼Œè§£å†³äº†ç£å…±æŒ¯æˆåƒä¸­çš„è¿åŠ¨ä¼ªå½±é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å‡å€¼å›å½’éšæœºå¾®åˆ†æ–¹ç¨‹æ¥æ¨¡æ‹Ÿè¿åŠ¨çŸ«æ­£è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨äº†å°æ³¢æ‰©æ•£æ¥åŠ é€Ÿæ¨æ–­å’Œå°æ³¢å·ç§¯ä»¥å¢å¼ºç‰¹å¾æå–ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸´åºŠæ•°æ®ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç£å…±æŒ¯æˆåƒä¸­çš„è¿åŠ¨ä¼ªå½±æ˜¯è¯Šæ–­å¯é æ€§çš„ä¸»è¦é—®é¢˜ã€‚</li>
<li>ç°æœ‰çš„åŸºäºåˆ†æ•°ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•å­˜åœ¨å¯¹å·²çŸ¥å‰å‘ç®—å­çš„å¼ºçƒˆä¾èµ–å’Œæ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä¸‰ç»´MRIè¿åŠ¨æ ¡æ­£æ¡†æ¶ï¼ˆ3D-WMoCoï¼‰ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„äºŒç»´åˆ†æ•°å…ˆéªŒæ¥æŒ‡å¯¼ä¸‰ç»´åˆ†å¸ƒå…ˆéªŒã€‚</li>
<li>ä½¿ç”¨å‡å€¼å›å½’éšæœºå¾®åˆ†æ–¹ç¨‹æ¨¡æ‹Ÿè¿åŠ¨çŸ«æ­£è¿‡ç¨‹ã€‚</li>
<li>å¼•å…¥å°æ³¢æ‰©æ•£æ¥åŠ é€Ÿæ¨æ–­è¿‡ç¨‹ï¼Œåº”ç”¨å°æ³¢å·ç§¯ä»¥å¢å¼ºç‰¹å¾æå–ã€‚</li>
<li>æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸´åºŠæ•°æ®æµ‹è¯•ä¸­å®ç°äº†ç¨³å¥çš„æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02256">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e89d7bc1dc618a431d2a0ee2f11d1e91" align="middle">
<img src="https://picx.zhimg.com/v2-05e0aee5b51306a96bbe2578b51a33bd" align="middle">
<img src="https://picx.zhimg.com/v2-b14ffda30b8e80e06b4dff6a02c841bf" align="middle">
<img src="https://picx.zhimg.com/v2-8ad63262047f2720efb1e48fa3f3d2b9" align="middle">
<img src="https://picx.zhimg.com/v2-3c2513b3fb4160498f426d6fb62516fb" align="middle">
<img src="https://picx.zhimg.com/v2-d05f1b920bd399df99c52fab59c7995f" align="middle">
<img src="https://picx.zhimg.com/v2-950fa4752c4dff3d62f8f8b206439954" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Monocular-absolute-depth-estimation-from-endoscopy-via-domain-invariant-feature-learning-and-latent-consistency"><a href="#Monocular-absolute-depth-estimation-from-endoscopy-via-domain-invariant-feature-learning-and-latent-consistency" class="headerlink" title="Monocular absolute depth estimation from endoscopy via domain-invariant   feature learning and latent consistency"></a>Monocular absolute depth estimation from endoscopy via domain-invariant   feature learning and latent consistency</h2><p><strong>Authors:Hao Li, Daiwei Lu, Jesse dâ€™Almeida, Dilara Isik, Ehsan Khodapanah Aghdam, Nick DiSanto, Ayberk Acar, Susheela Sharma, Jie Ying Wu, Robert J. Webster III, Ipek Oguz</strong></p>
<p>Monocular depth estimation (MDE) is a critical task to guide autonomous medical robots. However, obtaining absolute (metric) depth from an endoscopy camera in surgical scenes is difficult, which limits supervised learning of depth on real endoscopic images. Current image-level unsupervised domain adaptation methods translate synthetic images with known depth maps into the style of real endoscopic frames and train depth networks using these translated images with their corresponding depth maps. However a domain gap often remains between real and translated synthetic images. In this paper, we present a latent feature alignment method to improve absolute depth estimation by reducing this domain gap in the context of endoscopic videos of the central airway. Our methods are agnostic to the image translation process and focus on the depth estimation itself. Specifically, the depth network takes translated synthetic and real endoscopic frames as input and learns latent domain-invariant features via adversarial learning and directional feature consistency. The evaluation is conducted on endoscopic videos of central airway phantoms with manually aligned absolute depth maps. Compared to state-of-the-art MDE methods, our approach achieves superior performance on both absolute and relative depth metrics, and consistently improves results across various backbones and pretrained weights. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/MedICL-VU/MDE">https://github.com/MedICL-VU/MDE</a>. </p>
<blockquote>
<p>å•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰æ˜¯å¼•å¯¼è‡ªä¸»åŒ»ç–—æœºå™¨äººçš„é‡è¦ä»»åŠ¡ã€‚ç„¶è€Œï¼Œä»æ‰‹æœ¯åœºæ™¯ä¸­çš„å†…çª¥é•œç›¸æœºè·å–ç»å¯¹ï¼ˆåº¦é‡ï¼‰æ·±åº¦æ˜¯å¾ˆå›°éš¾çš„ï¼Œè¿™é™åˆ¶äº†åœ¨ç°å®å†…çª¥é•œå›¾åƒä¸Šç›‘ç£æ·±åº¦å­¦ä¹ çš„åº”ç”¨ã€‚å½“å‰åŸºäºå›¾åƒå±‚é¢çš„æ— ç›‘ç£åŸŸé€‚åº”æ–¹æ³•å°†å¸¦æœ‰å·²çŸ¥æ·±åº¦å›¾çš„åˆæˆå›¾åƒè½¬åŒ–ä¸ºçœŸå®å†…çª¥é•œå¸§çš„é£æ ¼ï¼Œå¹¶ä½¿ç”¨è¿™äº›ç¿»è¯‘åçš„å›¾åƒåŠå…¶å¯¹åº”çš„æ·±åº¦å›¾å¯¹æ·±åº¦ç½‘ç»œè¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼ŒçœŸå®å’Œç¿»è¯‘çš„åˆæˆå›¾åƒä¹‹é—´å¾€å¾€ä»å­˜åœ¨åŸŸå·®è·ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ½œåœ¨ç‰¹å¾å¯¹é½æ–¹æ³•ï¼Œé€šè¿‡å‡å°‘ä¸­å¤®æ°”é“å†…çª¥é•œè§†é¢‘ä¸Šä¸‹æ–‡ä¸­çš„åŸŸå·®è·ï¼Œæé«˜ç»å¯¹æ·±åº¦ä¼°è®¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä¾èµ–äºå›¾åƒç¿»è¯‘è¿‡ç¨‹ï¼Œè€Œæ˜¯ä¸“æ³¨äºæ·±åº¦ä¼°è®¡æœ¬èº«ã€‚å…·ä½“æ¥è¯´ï¼Œæ·±åº¦ç½‘ç»œä»¥ç¿»è¯‘åçš„åˆæˆå¸§å’ŒçœŸå®å†…çª¥é•œå¸§ä¸ºè¾“å…¥ï¼Œé€šè¿‡å¯¹æŠ—å­¦ä¹ å’Œæ–¹å‘ç‰¹å¾ä¸€è‡´æ€§å­¦ä¹ æ½œåœ¨åŸŸä¸å˜ç‰¹å¾ã€‚è¯„ä¼°æ˜¯åœ¨ä¸­å¤®æ°”é“å¹»å½±çš„å†…çª¥é•œè§†é¢‘ä¸Šè¿›è¡Œçš„ï¼Œå…·æœ‰æ‰‹åŠ¨å¯¹é½çš„ç»å¯¹æ·±åº¦å›¾ã€‚ä¸æœ€å…ˆè¿›çš„MDEæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç»å¯¹å’Œç›¸å¯¹æ·±åº¦æŒ‡æ ‡ä¸Šå‡å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å„ç§ä¸»å¹²ç½‘ç»œå’Œé¢„è®­ç»ƒæƒé‡ä¸Šå‡æ”¹è¿›äº†ç»“æœã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MedICL-VU/MDE%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/MedICL-VU/MDEæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02247v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ½œåœ¨ç‰¹å¾å¯¹é½çš„æ–¹æ³•ï¼Œç”¨äºæ”¹è¿›åœ¨ä¸­å¤®æ°”é“å†…çª¥é•œè§†é¢‘ä¸­çš„ç»å¯¹æ·±åº¦ä¼°è®¡ã€‚é€šè¿‡å¯¹æŠ—æ€§å­¦ä¹ å’Œæ–¹å‘ç‰¹å¾ä¸€è‡´æ€§ï¼Œå­¦ä¹ åˆæˆå›¾åƒå’ŒçœŸå®å†…çª¥é•œå›¾åƒä¹‹é—´çš„åŸŸä¸å˜ç‰¹å¾ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç»å¯¹å’Œç›¸å¯¹æ·±åº¦æŒ‡æ ‡ä¸Šå‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„å•çœ¼æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œä¸”åœ¨å„ç§ä¸»å¹²ç½‘ç»œå’Œé¢„è®­ç»ƒæƒé‡ä¸Šå‡è¡¨ç°ä¸€è‡´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å•çœ¼æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰åœ¨æŒ‡å¯¼è‡ªä¸»åŒ»ç–—æœºå™¨äººæ–¹é¢å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>åœ¨æ‰‹æœ¯åœºæ™¯ä¸­ï¼Œä»å†…çª¥é•œç›¸æœºè·å¾—ç»å¯¹æ·±åº¦æ˜¯å›°éš¾çš„ï¼Œè¿™é™åˆ¶äº†åœ¨çœŸå®å†…çª¥é•œå›¾åƒä¸Šçš„æ·±åº¦ç›‘ç£å­¦ä¹ ã€‚</li>
<li>å½“å‰çš„æ— ç›‘ç£åŸŸé€‚åº”æ–¹æ³•å­˜åœ¨åŸŸå·®è·é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ½œåœ¨ç‰¹å¾å¯¹é½çš„æ–¹æ³•ï¼Œä»¥å‡å°‘åˆæˆå›¾åƒå’ŒçœŸå®å†…çª¥é•œå›¾åƒä¹‹é—´çš„åŸŸå·®è·ï¼Œæé«˜ç»å¯¹æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å¯¹æŠ—æ€§å­¦ä¹ å’Œæ–¹å‘ç‰¹å¾ä¸€è‡´æ€§ï¼Œå­¦ä¹ åŸŸä¸å˜ç‰¹å¾ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç»å¯¹å’Œç›¸å¯¹æ·±åº¦æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„MDEæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02247">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-86a1431b9bd0a7391e31de747eb3ec20" align="middle">
<img src="https://picx.zhimg.com/v2-ed148a240935b9373e74a38bb482756f" align="middle">
<img src="https://picx.zhimg.com/v2-73890e9b1c06fa0ceb6d7eaab11a35e8" align="middle">
<img src="https://picx.zhimg.com/v2-ebbd9c5920ef3d4df072d5c2d7361c42" align="middle">
<img src="https://picx.zhimg.com/v2-3334026d8834f8aaddeeb1cee6d731a2" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Fractional-Diffusion-Bridge-Models"><a href="#Fractional-Diffusion-Bridge-Models" class="headerlink" title="Fractional Diffusion Bridge Models"></a>Fractional Diffusion Bridge Models</h2><p><strong>Authors:Gabriel Nobis, Maximilian Springenberg, Arina Belova, Rembert Daems, Christoph Knochenhauer, Manfred Opper, Tolga Birdal, Wojciech Samek</strong></p>
<p>We present Fractional Diffusion Bridge Models (FDBM), a novel generative diffusion bridge framework driven by an approximation of the rich and non-Markovian fractional Brownian motion (fBM). Real stochastic processes exhibit a degree of memory effects (correlations in time), long-range dependencies, roughness and anomalous diffusion phenomena that are not captured in standard diffusion or bridge modeling due to the use of Brownian motion (BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM), we construct FDBM that enable tractable inference while preserving the non-Markovian nature of fBM. We prove the existence of a coupling-preserving generative diffusion bridge and leverage it for future state prediction from paired training data. We then extend our formulation to the Schr&quot;{o}dinger bridge problem and derive a principled loss function to learn the unpaired data translation. We evaluate FDBM on both tasks: predicting future protein conformations from aligned data, and unpaired image translation. In both settings, FDBM achieves superior performance compared to the Brownian baselines, yielding lower root mean squared deviation (RMSD) of C$_\alpha$ atomic positions in protein structure prediction and lower Fr&#39;echet Inception Distance (FID) in unpaired image translation. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†åˆ†æ•°æ‰©æ•£æ¡¥æ¢æ¨¡å‹ï¼ˆFDBMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ç”Ÿæˆå¼æ‰©æ•£æ¡¥æ¢æ¡†æ¶ï¼Œç”±å¯¹ä¸°å¯Œä¸”éé©¬å°”å¯å¤«åˆ†æ•°å¸ƒæœ—è¿åŠ¨ï¼ˆfBMï¼‰çš„è¿‘ä¼¼é©±åŠ¨ã€‚å®é™…éšæœºè¿‡ç¨‹è¡¨ç°å‡ºä¸€å®šç¨‹åº¦çš„è®°å¿†æ•ˆåº”ï¼ˆæ—¶é—´ç›¸å…³æ€§ï¼‰ã€é•¿ç¨‹ä¾èµ–æ€§ã€ç²—ç³™åº¦å’Œå¼‚å¸¸æ‰©æ•£ç°è±¡ï¼Œè¿™äº›åœ¨æ ‡å‡†æ‰©æ•£æˆ–æ¡¥æ¢å»ºæ¨¡ä¸­å¹¶æ²¡æœ‰è¢«æ•æ‰åˆ°ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯å¸ƒæœ—è¿åŠ¨ï¼ˆBMï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨åˆ†æ•°å¸ƒæœ—è¿åŠ¨çš„é©¬å°”å¯å¤«è¿‘ä¼¼ï¼ˆMA-fBMï¼‰ï¼Œæ„å»ºäº†FDBMï¼Œå®ç°åœ¨è¿›è¡Œæ¨ç†æ—¶èƒ½å¤Ÿå¤„ç†ï¼ŒåŒæ—¶ä¿ç•™fBMçš„éé©¬å°”å¯å¤«æ€§è´¨ã€‚æˆ‘ä»¬è¯æ˜äº†å­˜åœ¨ä¸€ç§è€¦åˆä¿ç•™ç”Ÿæˆæ‰©æ•£æ¡¥æ¢ï¼Œå¹¶åˆ©ç”¨å®ƒå¯¹é…å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæœªæ¥çŠ¶æ€é¢„æµ‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å…¬å¼æ‰©å±•åˆ°SchrÃ¶dingeræ¡¥æ¢é—®é¢˜ï¼Œå¹¶æ¨å¯¼å‡ºä¸€ç§æœ‰åŸåˆ™çš„æŸå¤±å‡½æ•°æ¥å­¦ä¹ æœªé…å¯¹æ•°æ®çš„ç¿»è¯‘ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šè¯„ä¼°äº†FDBMï¼šä»å¯¹é½æ•°æ®ä¸­é¢„æµ‹æœªæ¥è›‹ç™½è´¨æ„è±¡å’Œæœªé…å¯¹å›¾åƒç¿»è¯‘ã€‚åœ¨ä¸¤ä¸ªåœºæ™¯ä¸­ï¼ŒFDBMå‡å®ç°äº†ä¼˜äºå¸ƒæœ—åŸºå‡†çº¿çš„æ€§èƒ½ï¼Œåœ¨è›‹ç™½è´¨ç»“æ„é¢„æµ‹ä¸­è·å¾—äº†æ›´ä½çš„CÎ±åŸå­ä½ç½®å‡æ–¹æ ¹åå·®ï¼ˆRMSDï¼‰ï¼Œåœ¨æœªé…å¯¹å›¾åƒç¿»è¯‘ä¸­è·å¾—äº†æ›´ä½çš„FrÃ©chet Inception Distanceï¼ˆFIDï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.01795v1">PDF</a> To appear in NeurIPS 2025 proceedings. This version includes   post-camera-ready revisions</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åˆ†æ•°æ‰©æ•£æ¡¥æ¨¡å‹ï¼ˆFDBMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„ç”Ÿæˆæ‰©æ•£æ¡¥æ¡†æ¶ï¼Œç”±å¯¹ä¸°å¯Œä¸”éé©¬å°”å¯å¤«åˆ†æ•°å¸ƒæœ—è¿åŠ¨ï¼ˆfBMï¼‰çš„è¿‘ä¼¼é©±åŠ¨ã€‚è¯¥æ¨¡å‹è§£å†³äº†çœŸå®éšæœºè¿‡ç¨‹ä¸­çš„è®°å¿†æ•ˆåº”ã€è¿œç¨‹ä¾èµ–ã€ç²—ç³™åº¦å’Œå¼‚å¸¸æ‰©æ•£ç°è±¡ï¼Œè¿™äº›é—®é¢˜åœ¨æ ‡å‡†æ‰©æ•£æˆ–æ¡¥æ¨¡å‹ä¸­ç”±äºä½¿ç”¨å¸ƒæœ—è¿åŠ¨ï¼ˆBMï¼‰è€Œæ— æ³•æ•æ‰ã€‚é€šè¿‡åˆ©ç”¨æœ€è¿‘å¯¹fBMçš„é©¬å°”å¯å¤«è¿‘ä¼¼ï¼ˆMA-fBMï¼‰ï¼Œæˆ‘ä»¬æ„å»ºäº†FDBMï¼Œèƒ½å¤Ÿåœ¨æ¨ç†æ—¶è¿›è¡Œæ¨ç†ï¼ŒåŒæ—¶ä¿ç•™fBMçš„éé©¬å°”å¯å¤«æ€§è´¨ã€‚æœ¬æ–‡è¯æ˜äº†å­˜åœ¨ä¸€ç§è€¦åˆä¿ç•™ç”Ÿæˆæ‰©æ•£æ¡¥ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥é¢„æµ‹é…å¯¹è®­ç»ƒæ•°æ®çš„æœªæ¥çŠ¶æ€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è¯¥å…¬å¼æ‰©å±•åˆ°è–›å®šè°”æ¡¥é—®é¢˜ï¼Œå¹¶æ¨å¯¼å‡ºä¸€ç§åŸåˆ™æ€§çš„æŸå¤±å‡½æ•°æ¥å­¦ä¹ æœªé…å¯¹æ•°æ®çš„ç¿»è¯‘ã€‚åœ¨é¢„æµ‹è›‹ç™½è´¨æ„è±¡å’Œæœªé…å¯¹å›¾åƒç¿»è¯‘çš„ä»»åŠ¡ä¸Šï¼ŒFDBMå‡è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¸å¸ƒæœ—åŸºçº¿ç›¸æ¯”ï¼Œè›‹ç™½è´¨ç»“æ„é¢„æµ‹çš„CÎ±åŸå­ä½ç½®å‡æ–¹æ ¹åå·®ï¼ˆRMSDï¼‰è¾ƒä½ï¼Œæœªé…å¯¹å›¾åƒç¿»è¯‘çš„FrÃ©chet Inception Distanceï¼ˆFIDï¼‰è¾ƒä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†Fractional Diffusion Bridge Modelsï¼ˆFDBMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„ç”Ÿæˆæ‰©æ•£æ¡¥æ¡†æ¶ã€‚</li>
<li>FDBMé€šè¿‡åˆ©ç”¨åˆ†æ•°å¸ƒæœ—è¿åŠ¨ï¼ˆfBMï¼‰çš„è¿‘ä¼¼è§£å†³äº†æ ‡å‡†æ‰©æ•£æ¨¡å‹æ— æ³•æ•æ‰åˆ°çš„éšæœºè¿‡ç¨‹çš„è®°å¿†æ•ˆåº”å’Œè¿œç¨‹ä¾èµ–ç­‰é—®é¢˜ã€‚</li>
<li>FDBMèƒ½å¤Ÿåœ¨è¿›è¡Œæ¨ç†çš„åŒæ—¶ä¿ç•™fBMçš„éé©¬å°”å¯å¤«æ€§è´¨ã€‚</li>
<li>è¯æ˜äº†å­˜åœ¨ä¸€ç§è€¦åˆä¿ç•™ç”Ÿæˆæ‰©æ•£æ¡¥ï¼Œå¹¶ç”¨äºé¢„æµ‹é…å¯¹è®­ç»ƒæ•°æ®çš„æœªæ¥çŠ¶æ€ã€‚</li>
<li>FDBMçš„å…¬å¼è¢«æ‰©å±•åˆ°è–›å®šè°”æ¡¥é—®é¢˜ï¼Œå¹¶å¼€å‘äº†ä¸€ç§åŸåˆ™æ€§çš„æŸå¤±å‡½æ•°è¿›è¡Œæœªé…å¯¹æ•°æ®çš„ç¿»è¯‘å­¦ä¹ ã€‚</li>
<li>åœ¨è›‹ç™½è´¨æ„è±¡é¢„æµ‹ä»»åŠ¡ä¸­ï¼ŒFDBMç›¸è¾ƒäºå¸ƒæœ—åŸºçº¿è¡¨ç°å‡ºæ›´ä¼˜ç§€çš„æ€§èƒ½ï¼Œå…·æœ‰è¾ƒä½çš„RMSDã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.01795">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ba036892969424bca624d60cdbce9c46" align="middle">
<img src="https://picx.zhimg.com/v2-d563051794309cb4a10db24f89d10e12" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="NSYNC-Negative-Synthetic-Image-Generation-for-Contrastive-Training-to-Improve-Stylized-Text-To-Image-Translation"><a href="#NSYNC-Negative-Synthetic-Image-Generation-for-Contrastive-Training-to-Improve-Stylized-Text-To-Image-Translation" class="headerlink" title="NSYNC: Negative Synthetic Image Generation for Contrastive Training to   Improve Stylized Text-To-Image Translation"></a>NSYNC: Negative Synthetic Image Generation for Contrastive Training to   Improve Stylized Text-To-Image Translation</h2><p><strong>Authors:Serkan Ozturk, Samet Hicsonmez, Pinar Duygulu</strong></p>
<p>Current text conditioned image generation methods output realistic looking images, but they fail to capture specific styles. Simply finetuning them on the target style datasets still struggles to grasp the style features. In this work, we present a novel contrastive learning framework to improve the stylization capability of large text-to-image diffusion models. Motivated by the astonishing advance in image generation models that makes synthetic data an intrinsic part of model training in various computer vision tasks, we exploit synthetic image generation in our approach. Usually, the generated synthetic data is dependent on the task, and most of the time it is used to enlarge the available real training dataset. With NSYNC, alternatively, we focus on generating negative synthetic sets to be used in a novel contrastive training scheme along with real positive images. In our proposed training setup, we forward negative data along with positive data and obtain negative and positive gradients, respectively. We then refine the positive gradient by subtracting its projection onto the negative gradient to get the orthogonal component, based on which the parameters are updated. This orthogonal component eliminates the trivial attributes that are present in both positive and negative data and directs the model towards capturing a more unique style. Experiments on various styles of painters and illustrators show that our approach improves the performance over the baseline methods both quantitatively and qualitatively. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/giddyyupp/NSYNC">https://github.com/giddyyupp/NSYNC</a>. </p>
<blockquote>
<p>å½“å‰åŸºäºæ–‡æœ¬æ¡ä»¶çš„å›¾åƒç”Ÿæˆæ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå¤–è§‚é€¼çœŸçš„å›¾åƒï¼Œä½†å®ƒä»¬æ— æ³•æ•æ‰ç‰¹å®šçš„é£æ ¼ã€‚å³ä½¿åœ¨ç›®æ ‡é£æ ¼æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå®ƒä»¬ä»ç„¶éš¾ä»¥æŒæ¡é£æ ¼ç‰¹å¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„é£æ ¼åŒ–èƒ½åŠ›ã€‚å—å›¾åƒç”Ÿæˆæ¨¡å‹çš„æƒŠäººè¿›å±•çš„å¯å‘ï¼Œåˆæˆæ•°æ®å·²æˆä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­æ¨¡å‹è®­ç»ƒä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨äº†åˆæˆå›¾åƒç”Ÿæˆã€‚é€šå¸¸ï¼Œç”Ÿæˆçš„åˆæˆæ•°æ®å–å†³äºä»»åŠ¡ï¼Œå¹¶ä¸”å¤§éƒ¨åˆ†æ—¶é—´ç”¨äºæ‰©å¤§å¯ç”¨çš„çœŸå®è®­ç»ƒæ•°æ®é›†ã€‚ç„¶è€Œï¼Œé€šè¿‡ä½¿ç”¨NSYNCï¼Œæˆ‘ä»¬ä¸“æ³¨äºç”Ÿæˆç”¨äºæ–°å‹å¯¹æ¯”è®­ç»ƒæ–¹æ¡ˆçš„è´Ÿé¢åˆæˆé›†ï¼Œä»¥åŠçœŸå®çš„æ­£é¢å›¾åƒã€‚åœ¨æˆ‘ä»¬æå‡ºçš„è®­ç»ƒè®¾ç½®ä¸­ï¼Œæˆ‘ä»¬å°†è´Ÿé¢æ•°æ®ä¸æ­£é¢æ•°æ®ä¸€èµ·å‘å‰ä¼ é€’ï¼Œå¹¶åˆ†åˆ«è·å¾—è´Ÿé¢å’Œæ­£é¢æ¢¯åº¦ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ä»æ­£é¢æ¢¯åº¦ä¸­å‡å»å…¶åœ¨è´Ÿé¢æ¢¯åº¦ä¸Šçš„æŠ•å½±æ¥ä¼˜åŒ–æ­£é¢æ¢¯åº¦ï¼Œä»è€Œè·å¾—æ­£äº¤åˆ†é‡ï¼ŒåŸºäºè¯¥æ­£äº¤åˆ†é‡æ›´æ–°å‚æ•°ã€‚è¿™ä¸ªæ­£äº¤åˆ†é‡æ¶ˆé™¤äº†åŒæ—¶å­˜åœ¨äºæ­£é¢å’Œè´Ÿé¢æ•°æ®ä¸­çš„å¸¸è§„å±æ€§ï¼Œå¹¶æŒ‡å¯¼æ¨¡å‹æ•æ‰æ›´ç‹¬ç‰¹çš„é£æ ¼ã€‚å¯¹å„ç§ç”»å®¶å’Œæ’ç”»å¸ˆé£æ ¼çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ— è®ºåœ¨å®šé‡è¿˜æ˜¯å®šæ€§æ–¹é¢éƒ½è¶…è¿‡äº†åŸºçº¿æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/giddyyupp/NSYNC%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/giddyyupp/NSYNCæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.01517v1">PDF</a> Under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„é£æ ¼åŒ–èƒ½åŠ›ã€‚è¯¥æ¡†æ¶é€šè¿‡ç”Ÿæˆè´Ÿåˆæˆé›†ï¼Œä¸çœŸå®æ­£å›¾åƒä¸€èµ·ç”¨äºæ–°å‹å¯¹æ¯”è®­ç»ƒæ–¹æ¡ˆã€‚é€šè¿‡æ­£è´Ÿæ•°æ®çš„æ¢¯åº¦è®¡ç®—å’Œæ­£äº¤åˆ†é‡ä¼˜åŒ–ï¼Œæ¶ˆé™¤ä¸¤è€…å…±æœ‰çš„å¸¸è§„å±æ€§ï¼Œä½¿æ¨¡å‹æ›´ä¸“æ³¨äºæ•æ‰ç‹¬ç‰¹é£æ ¼ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”»å®¶å’Œæ’ç”»å¸ˆçš„å„ç§é£æ ¼ä¸Šå‡ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œå®šé‡å’Œå®šæ€§çš†æœ‰æ˜¾è‘—æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰æ–‡æœ¬æ¡ä»¶å›¾åƒç”Ÿæˆæ–¹æ³•éš¾ä»¥æ•æ‰ç‰¹å®šé£æ ¼ï¼Œå³ä½¿å¯¹ç›®æ ‡é£æ ¼æ•°æ®é›†è¿›è¡Œå¾®è°ƒä»éš¾ä»¥æŒæ¡é£æ ¼ç‰¹å¾ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„é£æ ¼åŒ–èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥äº†è´Ÿåˆæˆé›†ç”Ÿæˆï¼Œç”¨äºå¯¹æ¯”è®­ç»ƒã€‚</li>
<li>é€šè¿‡æ­£è´Ÿæ•°æ®çš„æ¢¯åº¦è®¡ç®—ï¼Œè·å–æ­£äº¤åˆ†é‡ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹å‚æ•°ã€‚</li>
<li>æ­£äº¤åˆ†é‡æœ‰åŠ©äºæ¶ˆé™¤å¸¸è§„å±æ€§ï¼Œä½¿æ¨¡å‹æ›´ä¸“æ³¨äºæ•æ‰ç‹¬ç‰¹é£æ ¼ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§é£æ ¼ä¸Šçš„æ€§èƒ½ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œå®ç°å®šé‡å’Œå®šæ€§çš„æå‡ã€‚</li>
<li>é¡¹ç›®çš„ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.01517">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8bcffdff615246bc81e2278b6fef300a" align="middle">
<img src="https://picx.zhimg.com/v2-f9e656aa10107ce3ed28badf3bb7cc5e" align="middle">
<img src="https://picx.zhimg.com/v2-75adfb8d1a8de314a91cafc4cd14d52e" align="middle">
<img src="https://picx.zhimg.com/v2-892bf2ccb896828674ba584ff4ad92da" align="middle">
<img src="https://picx.zhimg.com/v2-40850e19634e7e0e853ad21db3af08c1" align="middle">
<img src="https://picx.zhimg.com/v2-c2f27ac64f6d6ea052780fea2df71a54" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Discriminately-Treating-Motion-Components-Evolves-Joint-Depth-and-Ego-Motion-Learning"><a href="#Discriminately-Treating-Motion-Components-Evolves-Joint-Depth-and-Ego-Motion-Learning" class="headerlink" title="Discriminately Treating Motion Components Evolves Joint Depth and   Ego-Motion Learning"></a>Discriminately Treating Motion Components Evolves Joint Depth and   Ego-Motion Learning</h2><p><strong>Authors:Mengtan Zhang, Zizhan Guo, Hongbo Zhao, Yi Feng, Zuyi Xiong, Yue Wang, Shaoyi Du, Hanli Wang, Rui Fan</strong></p>
<p>Unsupervised learning of depth and ego-motion, two fundamental 3D perception tasks, has made significant strides in recent years. However, most methods treat ego-motion as an auxiliary task, either mixing all motion types or excluding depth-independent rotational motions in supervision. Such designs limit the incorporation of strong geometric constraints, reducing reliability and robustness under diverse conditions. This study introduces a discriminative treatment of motion components, leveraging the geometric regularities of their respective rigid flows to benefit both depth and ego-motion estimation. Given consecutive video frames, network outputs first align the optical axes and imaging planes of the source and target cameras. Optical flows between frames are transformed through these alignments, and deviations are quantified to impose geometric constraints individually on each ego-motion component, enabling more targeted refinement. These alignments further reformulate the joint learning process into coaxial and coplanar forms, where depth and each translation component can be mutually derived through closed-form geometric relationships, introducing complementary constraints that improve depth robustness. DiMoDE, a general depth and ego-motion joint learning framework incorporating these designs, achieves state-of-the-art performance on multiple public datasets and a newly collected diverse real-world dataset, particularly under challenging conditions. Our source code will be publicly available at mias.group&#x2F;DiMoDE upon publication. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ å’Œè‡ªæˆ‘è¿åŠ¨è¿™ä¸¤ä¸ªåŸºæœ¬çš„3Dæ„ŸçŸ¥ä»»åŠ¡çš„æ— ç›‘ç£å­¦ä¹ å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•å°†è‡ªæˆ‘è¿åŠ¨è§†ä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œè¦ä¹ˆæ··åˆæ‰€æœ‰è¿åŠ¨ç±»å‹ï¼Œè¦ä¹ˆåœ¨ç›‘ç£ä¸­æ’é™¤ä¸æ·±åº¦æ— å…³çš„å›è½¬è¿åŠ¨ã€‚è¿™ç§è®¾è®¡é™åˆ¶äº†å¼ºå‡ ä½•çº¦æŸçš„èå…¥ï¼Œé™ä½äº†åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„å¯é æ€§å’Œé²æ£’æ€§ã€‚æœ¬ç ”ç©¶å¯¹è¿åŠ¨æˆåˆ†è¿›è¡Œäº†åŒºåˆ†å¤„ç†ï¼Œåˆ©ç”¨å„è‡ªåˆšæ€§æµåŠ¨çš„å‡ ä½•è§„å¾‹ï¼Œä¸ºæ·±åº¦å’Œè‡ªæˆ‘è¿åŠ¨ä¼°è®¡å¸¦æ¥å¥½å¤„ã€‚ç»™å®šè¿ç»­çš„è§†é¢‘å¸§ï¼Œç½‘ç»œè¾“å‡ºé¦–å…ˆå¯¹é½æºç›¸æœºå’Œç›®æ ‡ç›¸æœºçš„å…‰å­¦è½´å’Œæˆåƒå¹³é¢ã€‚é€šè¿‡è¿™äº›å¯¹é½ï¼Œå¸§ä¹‹é—´çš„å…‰æµä¼šå‘ç”Ÿå˜åŒ–ï¼Œå¹¶ä¸”åå·®è¢«é‡åŒ–ï¼Œä»¥ä¾¿å¯¹æ¯ä¸ªè‡ªæˆ‘è¿åŠ¨ç»„ä»¶å•ç‹¬æ–½åŠ å‡ ä½•çº¦æŸï¼Œä»è€Œå®ç°æ›´æœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ã€‚è¿™äº›å¯¹é½è¿›ä¸€æ­¥å°†è”åˆå­¦ä¹ è¿‡ç¨‹é‡æ–°åˆ¶å®šä¸ºåŒè½´å’Œå…±é¢å½¢å¼ï¼Œæ·±åº¦å’Œæ¯ä¸ªå¹³ç§»æˆåˆ†å¯ä»¥é€šè¿‡å°é—­çš„å‡ ä½•å…³ç³»ç›¸äº’æ¨å¯¼ï¼Œå¼•å…¥äº’è¡¥çº¦æŸä»¥æé«˜æ·±åº¦é²æ£’æ€§ã€‚DiMoDEæ˜¯ä¸€ä¸ªåŒ…å«è¿™äº›è®¾è®¡çš„é€šç”¨æ·±åº¦å’Œè‡ªæˆ‘è¿åŠ¨è”åˆå­¦ä¹ æ¡†æ¶ï¼Œåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†å’Œæ–°æ”¶é›†çš„å¤šæ ·çš„ç°å®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ï¼Œå°¤å…¶åœ¨å…·æœ‰æŒ‘æˆ˜çš„æ¡ä»¶ä¸‹ã€‚æˆ‘ä»¬çš„æºä»£ç å°†åœ¨mias.group&#x2F;DiMoDEä¸Šå…¬å¼€å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.01502v1">PDF</a> 18 pages, 14 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ç ”ç©¶æ— ç›‘ç£å­¦ä¹ ä¸‹çš„æ·±åº¦æ„ŸçŸ¥å’Œè‡ªä¸»è¿åŠ¨ä¸¤ä¸ªåŸºæœ¬ä»»åŠ¡ï¼Œé€šè¿‡åŒºåˆ†å¤„ç†è¿åŠ¨æˆåˆ†ï¼Œåˆ©ç”¨å„è‡ªçš„å‡ ä½•è§„å¾‹ï¼Œæé«˜æ·±åº¦å’Œè‡ªä¸»è¿åŠ¨ä¼°è®¡çš„å¯é æ€§ã€‚è¯¥ç ”ç©¶é€šè¿‡è¿ç»­è§†é¢‘å¸§è¿›è¡Œç½‘ç»œè¾“å‡ºï¼Œé¦–å…ˆå¯¹é½æºç›¸æœºå’Œç›®æ ‡ç›¸æœºçš„å…‰å­¦è½´å’Œæˆåƒå¹³é¢ï¼Œé€šè¿‡è½¬æ¢å…‰å­¦æµåŠ¨å¹¶é‡åŒ–åå·®ï¼Œå¯¹æ¯ç§è‡ªä¸»è¿åŠ¨æˆåˆ†æ–½åŠ å‡ ä½•çº¦æŸï¼Œå®ç°æ›´æœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ã€‚è¿™ç§å¯¹é½æ–¹æ³•è¿›ä¸€æ­¥å°†è”åˆå­¦ä¹ è¿‡ç¨‹è½¬åŒ–ä¸ºåŒè½´å’Œå¹³é¢å½¢å¼ï¼Œæ·±åº¦å’Œæ¯ä¸ªå¹³ç§»æˆåˆ†å¯ä»¥é€šè¿‡å°é—­çš„å‡ ä½•å…³ç³»ç›¸äº’æ¨å¯¼ï¼Œå¼•å…¥äº’è¡¥çº¦æŸä»¥æé«˜æ·±åº¦ç¨³å¥æ€§ã€‚æå‡ºçš„DiMoDEæ¡†æ¶åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†å’Œæ–°æ”¶é›†çš„å¤šæ ·åŒ–çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å®ç°äº†æ— ç›‘ç£å­¦ä¹ ä¸‹çš„æ·±åº¦æ„ŸçŸ¥å’Œè‡ªä¸»è¿åŠ¨è”åˆå­¦ä¹ ã€‚</li>
<li>é€šè¿‡åŒºåˆ†å¤„ç†è¿åŠ¨æˆåˆ†ï¼Œåˆ©ç”¨å‡ ä½•è§„å¾‹æé«˜ä¼°è®¡çš„å¯é æ€§ã€‚</li>
<li>é€šè¿‡ç½‘ç»œè¾“å‡ºå¯¹é½ç›¸æœºå…‰å­¦è½´å’Œæˆåƒå¹³é¢ï¼Œè½¬æ¢å…‰å­¦æµåŠ¨å¹¶é‡åŒ–åå·®ã€‚</li>
<li>å¯¹æ¯ä¸ªè‡ªä¸»è¿åŠ¨æˆåˆ†æ–½åŠ å‡ ä½•çº¦æŸï¼Œå®ç°æ›´æœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ã€‚</li>
<li>å°†è”åˆå­¦ä¹ è¿‡ç¨‹è½¬åŒ–ä¸ºåŒè½´å’Œå¹³é¢å½¢å¼ï¼Œé€šè¿‡å°é—­çš„å‡ ä½•å…³ç³»æé«˜æ·±åº¦å’Œæ¯ä¸ªå¹³ç§»æˆåˆ†çš„ä¼°è®¡ç²¾åº¦ã€‚</li>
<li>æå‡ºçš„DiMoDEæ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°æœ€ä½³æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.01502">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4b0a9e8f7afd6d122062b556ed7fa64d" align="middle">
<img src="https://picx.zhimg.com/v2-d14bff5051b46224fc6b3468ffcf139c" align="middle">
<img src="https://picx.zhimg.com/v2-193984f78d819217e4c6b6dd5b37c5ef" align="middle">
<img src="https://picx.zhimg.com/v2-1b77b86d228e61c52da943bd70800d57" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Deep-Generative-Models-for-Enhanced-Vitreous-OCT-Imaging"><a href="#Deep-Generative-Models-for-Enhanced-Vitreous-OCT-Imaging" class="headerlink" title="Deep Generative Models for Enhanced Vitreous OCT Imaging"></a>Deep Generative Models for Enhanced Vitreous OCT Imaging</h2><p><strong>Authors:Simone Sarrocco, Philippe C. Cattin, Peter M. Maloca, Paul Friedrich, Philippe Valmaggia</strong></p>
<p>Purpose: To evaluate deep learning (DL) models for enhancing vitreous optical coherence tomography (OCT) image quality and reducing acquisition time. Methods: Conditional Denoising Diffusion Probabilistic Models (cDDPMs), Brownian Bridge Diffusion Models (BBDMs), U-Net, Pix2Pix, and Vector-Quantised Generative Adversarial Network (VQ-GAN) were used to generate high-quality spectral-domain (SD) vitreous OCT images. Inputs were SD ART10 images, and outputs were compared to pseudoART100 images obtained by averaging ten ART10 images per eye location. Model performance was assessed using image quality metrics and Visual Turing Tests, where ophthalmologists ranked generated images and evaluated anatomical fidelity. The best modelâ€™s performance was further tested within the manually segmented vitreous on newly acquired data. Results: U-Net achieved the highest Peak Signal-to-Noise Ratio (PSNR: 30.230) and Structural Similarity Index Measure (SSIM: 0.820), followed by cDDPM. For Learned Perceptual Image Patch Similarity (LPIPS), Pix2Pix (0.697) and cDDPM (0.753) performed best. In the first Visual Turing Test, cDDPM ranked highest (3.07); in the second (best model only), cDDPM achieved a 32.9% fool rate and 85.7% anatomical preservation. On newly acquired data, cDDPM generated vitreous regions more similar in PSNR to the ART100 reference than true ART1 or ART10 B-scans and achieved higher PSNR on whole images when conditioned on ART1 than ART10. Conclusions: Results reveal discrepancies between quantitative metrics and clinical evaluation, highlighting the need for combined assessment. cDDPM showed strong potential for generating clinically meaningful vitreous OCT images while reducing acquisition time fourfold. Translational Relevance: cDDPMs show promise for clinical integration, supporting faster, higher-quality vitreous imaging. Dataset and code will be made publicly available. </p>
<blockquote>
<p>ç›®çš„ï¼šè¯„ä¼°æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ¨¡å‹åœ¨æé«˜ç»ç’ƒä½“å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æï¼ˆOCTï¼‰å›¾åƒè´¨é‡å’Œå‡å°‘é‡‡é›†æ—¶é—´æ–¹é¢çš„æ•ˆæœã€‚æ–¹æ³•ï¼šä½¿ç”¨æ¡ä»¶å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆcDDPMsï¼‰ã€å¸ƒæœ—æ¡¥æ‰©æ•£æ¨¡å‹ï¼ˆBBDMsï¼‰ã€U-Netã€Pix2Pixå’Œå‘é‡é‡åŒ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆVQ-GANï¼‰ç”Ÿæˆé«˜è´¨é‡è°±åŸŸï¼ˆSDï¼‰ç»ç’ƒä½“OCTå›¾åƒã€‚è¾“å…¥ä¸ºSD ART10å›¾åƒï¼Œè¾“å‡ºä¸é€šè¿‡å¹³å‡æ¯ä¸ªçœ¼ä½åä¸ªART10å›¾åƒè·å¾—çš„ä¼ªART100å›¾åƒè¿›è¡Œæ¯”è¾ƒã€‚æ¨¡å‹æ€§èƒ½é€šè¿‡å›¾åƒè´¨é‡æŒ‡æ ‡å’Œè§†è§‰å›¾çµæµ‹è¯•è¿›è¡Œè¯„ä¼°ï¼Œçœ¼ç§‘åŒ»ç”Ÿå¯¹ç”Ÿæˆçš„å›¾åƒè¿›è¡Œæ’åå¹¶è¯„ä¼°å…¶è§£å‰–ä¿çœŸåº¦ã€‚æœ€ä½³æ¨¡å‹çš„æ€§èƒ½åœ¨æ–°è·å–çš„æ•°æ®çš„æ‰‹åŠ¨åˆ†å‰²ç»ç’ƒä½“ä¸­è¿›è¡Œæµ‹è¯•ã€‚ç»“æœï¼šU-Netåœ¨å³°å€¼ä¿¡å·å™ªå£°æ¯”ï¼ˆPSNRï¼š30.230ï¼‰å’Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼š0.820ï¼‰æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œå…¶æ¬¡æ˜¯cDDPMã€‚åœ¨æ„ŸçŸ¥å›¾åƒæ–‘å—ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰æ–¹é¢ï¼ŒPix2Pixï¼ˆ0.697ï¼‰å’ŒcDDPMï¼ˆ0.753ï¼‰è¡¨ç°æœ€å¥½ã€‚åœ¨ç¬¬ä¸€æ¬¡è§†è§‰å›¾çµæµ‹è¯•ä¸­ï¼ŒcDDPMæ’åæœ€é«˜ï¼ˆ3.07ï¼‰ï¼›åœ¨ç¬¬äºŒæ¬¡ï¼ˆä»…æœ€ä½³æ¨¡å‹ï¼‰ä¸­ï¼ŒcDDPMçš„æ¬ºéª—ç‡ä¸º32.9%ï¼Œè§£å‰–ä¿ç•™ç‡ä¸º85.7%ã€‚åœ¨æ–°è·å–çš„æ•°æ®ä¸­ï¼ŒcDDPMç”Ÿæˆçš„ç»ç’ƒä½“åŒºåŸŸåœ¨PSNRæ–¹é¢ä¸ART100å‚è€ƒç›¸æ¯”æ›´æ¥è¿‘äºçœŸå®ART1æˆ–ART10çš„Bæ‰«æï¼Œå¹¶ä¸”åœ¨æœ‰æ¡ä»¶çš„æƒ…å†µä¸‹ï¼Œæ•´ä¸ªå›¾åƒçš„PSNRé«˜äºART10ã€‚ç»“è®ºï¼šç»“æœæ­ç¤ºäº†å®šé‡æŒ‡æ ‡ä¸ä¸´åºŠè¯„ä¼°ä¹‹é—´çš„å·®å¼‚ï¼Œå¼ºè°ƒäº†éœ€è¦ç»“åˆè¯„ä¼°çš„å¿…è¦æ€§ã€‚cDDPMåœ¨ç”Ÿæˆå…·æœ‰ä¸´åºŠæ„ä¹‰çš„ç»ç’ƒä½“OCTå›¾åƒæ–¹é¢æ˜¾ç¤ºå‡ºå¼ºå¤§æ½œåŠ›ï¼ŒåŒæ—¶èƒ½å°†é‡‡é›†æ—¶é—´ç¼©çŸ­å››å€ã€‚ç¿»è¯‘æ„ä¹‰ï¼šcDDPMsåœ¨ä¸´åºŠåº”ç”¨ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œæ”¯æŒæ›´å¿«ã€æ›´é«˜è´¨é‡çš„ç»ç’ƒä½“æˆåƒã€‚æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00881v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æ·±åº¦å­¦ä¹ æ¨¡å‹ç”¨äºæå‡ç»ç’ƒä½“å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æå›¾åƒè´¨é‡å¹¶å‡å°‘é‡‡é›†æ—¶é—´çš„ç ”ç©¶ã€‚é‡‡ç”¨å¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å…‰è°±åŸŸç»ç’ƒä½“OCTå›¾åƒï¼Œå¹¶è¿›è¡Œæ€§èƒ½è¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼ŒcDDPMæ¨¡å‹åœ¨å›¾åƒè´¨é‡å’Œè§£å‰–å­¦ä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºæœ€ä½³æ•ˆæœï¼Œå…·æœ‰é™ä½é‡‡é›†æ—¶é—´å››å€çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶ç›®çš„ï¼šè¯„ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æé«˜ç»ç’ƒä½“å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æï¼ˆOCTï¼‰å›¾åƒè´¨é‡å’Œå‡å°‘é‡‡é›†æ—¶é—´æ–¹é¢çš„åº”ç”¨ã€‚</li>
<li>æ–¹æ³•ï¼šé‡‡ç”¨å¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚cDDPMsã€BBDMsã€U-Netã€Pix2Pixå’ŒVQ-GANï¼‰ç”Ÿæˆé«˜è´¨é‡å…‰è°±åŸŸï¼ˆSDï¼‰ç»ç’ƒä½“OCTå›¾åƒã€‚</li>
<li>è¯„ä¼°æŒ‡æ ‡ï¼šé€šè¿‡å›¾åƒè´¨é‡æŒ‡æ ‡å’Œè§†è§‰å›¾çµæµ‹è¯•è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œå…¶ä¸­çœ¼ç§‘åŒ»ç”Ÿå¯¹ç”Ÿæˆå›¾åƒè¿›è¡Œæ’åå¹¶è¯„ä¼°è§£å‰–å­¦ä¿çœŸåº¦ã€‚</li>
<li>æœ€ä½³æ¨¡å‹ï¼šcDDPMåœ¨å›¾åƒè´¨é‡å’Œè§£å‰–å­¦ä¿çœŸåº¦æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œå°¤å…¶åœ¨æ‰‹åŠ¨åˆ†å‰²çš„ç»ç’ƒä½“åŒºåŸŸçš„æ–°æ•°æ®ä¸Šæµ‹è¯•æ—¶ã€‚</li>
<li>ç»“æœï¼šcDDPMåœ¨å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰æ–¹é¢è¡¨ç°ä¼˜ç§€ï¼Œå¹¶ä¸”åœ¨è§†è§‰å›¾çµæµ‹è¯•ä¸­æ’åé å‰ï¼Œå®ç°äº†è¾ƒé«˜çš„æ¬ºéª—ç‡å’Œè§£å‰–å­¦ä¿ç•™ç‡ã€‚</li>
<li>ä¸´åºŠæ„ä¹‰ï¼šcDDPMæ¨¡å‹åœ¨ç”Ÿæˆå…·æœ‰ä¸´åºŠæ„ä¹‰çš„ç»ç’ƒä½“OCTå›¾åƒæ–¹é¢æ˜¾ç¤ºå‡ºå¼ºå¤§æ½œåŠ›ï¼Œå¹¶æœ‰æœ›é™ä½é‡‡é›†æ—¶é—´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00881">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e80c4c1ad5db82e546b3d56c9f808cd9" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="OSMGen-Highly-Controllable-Satellite-Image-Synthesis-using-OpenStreetMap-Data"><a href="#OSMGen-Highly-Controllable-Satellite-Image-Synthesis-using-OpenStreetMap-Data" class="headerlink" title="OSMGen: Highly Controllable Satellite Image Synthesis using   OpenStreetMap Data"></a>OSMGen: Highly Controllable Satellite Image Synthesis using   OpenStreetMap Data</h2><p><strong>Authors:Amir Ziashahabi, Narges Ghasemi, Sajjad Shahabi, John Krumm, Salman Avestimehr, Cyrus Shahabi</strong></p>
<p>Accurate and up-to-date geospatial data are essential for urban planning, infrastructure monitoring, and environmental management. Yet, automating urban monitoring remains difficult because curated datasets of specific urban features and their changes are scarce. We introduce OSMGen, a generative framework that creates realistic satellite imagery directly from raw OpenStreetMap (OSM) data. Unlike prior work that relies on raster tiles, OSMGen uses the full richness of OSM JSON, including vector geometries, semantic tags, location, and time, giving fine-grained control over how scenes are generated. A central feature of the framework is the ability to produce consistent before-after image pairs: user edits to OSM inputs translate into targeted visual changes, while the rest of the scene is preserved. This makes it possible to generate training data that addresses scarcity and class imbalance, and to give planners a simple way to preview proposed interventions by editing map data. More broadly, OSMGen produces paired (JSON, image) data for both static and changed states, paving the way toward a closed-loop system where satellite imagery can automatically drive structured OSM updates. Source code is available at <a target="_blank" rel="noopener" href="https://github.com/amir-zsh/OSMGen">https://github.com/amir-zsh/OSMGen</a>. </p>
<blockquote>
<p>å‡†ç¡®ä¸”æœ€æ–°çš„åœ°ç†ç©ºé—´æ•°æ®å¯¹äºåŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç›‘æµ‹ä»¥åŠç¯å¢ƒç®¡ç†è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå®ç°åŸå¸‚ç›‘æµ‹çš„è‡ªåŠ¨åŒ–ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç¼ºä¹ç‰¹å®šåŸå¸‚ç‰¹å¾åŠå…¶å˜åŒ–çš„ç²¾é€‰æ•°æ®é›†ã€‚æˆ‘ä»¬ä»‹ç»äº†OSMGenè¿™ä¸€ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿç›´æ¥ä»åŸå§‹çš„OpenStreetMapï¼ˆOSMï¼‰æ•°æ®ç”Ÿæˆé€¼çœŸçš„å«æ˜Ÿå›¾åƒã€‚ä¸åŒäºå…ˆå‰ä¾èµ–äºæ …æ ¼ç“¦ç‰‡çš„å·¥ä½œï¼ŒOSMGenä½¿ç”¨å®Œæ•´çš„OSM JSONï¼ŒåŒ…æ‹¬çŸ¢é‡å‡ ä½•ã€è¯­ä¹‰æ ‡ç­¾ã€ä½ç½®å’Œæ—¶é—´ï¼Œå®ç°å¯¹åœºæ™¯ç”Ÿæˆæ–¹å¼çš„ç²¾ç»†æ§åˆ¶ã€‚è¯¥æ¡†æ¶çš„ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½æ˜¯èƒ½å¤Ÿç”Ÿæˆä¸€è‡´çš„å‰åå›¾åƒå¯¹ï¼šç”¨æˆ·ç¼–è¾‘çš„OSMè¾“å…¥è½¬åŒ–ä¸ºæœ‰é’ˆå¯¹æ€§çš„è§†è§‰å˜åŒ–ï¼Œè€Œå…¶ä½™åœºæ™¯ä¿æŒä¸å˜ã€‚è¿™ä½¿å¾—ç”Ÿæˆè§£å†³ç¨€ç¼ºæ€§å’Œç±»åˆ«ä¸å¹³è¡¡é—®é¢˜çš„è®­ç»ƒæ•°æ®æˆä¸ºå¯èƒ½ï¼Œå¹¶ä¸ºè§„åˆ’äººå‘˜æä¾›ä¸€ç§é€šè¿‡ç¼–è¾‘åœ°å›¾æ•°æ®æ¥é¢„è§ˆæ‹Ÿè®®å¹²é¢„çš„ç®€ä¾¿æ–¹æ³•ã€‚æ›´å¹¿æ³›åœ°è¯´ï¼ŒOSMGenä¸ºé™æ€å’Œæ›´æ”¹çŠ¶æ€ç”Ÿæˆé…å¯¹ï¼ˆJSONï¼Œå›¾åƒï¼‰æ•°æ®ï¼Œä¸ºå»ºç«‹ä¸€ä¸ªé—­ç¯ç³»ç»Ÿé“ºå¹³é“è·¯ï¼Œåœ¨è¯¥ç³»ç»Ÿä¸­ï¼Œå«æ˜Ÿå›¾åƒå¯ä»¥è‡ªåŠ¨é©±åŠ¨ç»“æ„åŒ–çš„OSMæ›´æ–°ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/amir-zsh/OSMGen">https://github.com/amir-zsh/OSMGen</a>è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00345v1">PDF</a> Accepted at NeurIPS 2025 UrbanAI Workshop</p>
<p><strong>Summary</strong></p>
<p>åŸºäºOpenStreetMapï¼ˆOSMï¼‰æ•°æ®çš„åœ°ç†ç©ºé—´ä¿¡æ¯å¯¹åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç›‘æµ‹å’Œç¯å¢ƒç®¡ç†è‡³å…³é‡è¦ã€‚ä½†ç”±äºç¼ºä¹é’ˆå¯¹ç‰¹å®šåŸå¸‚ç‰¹å¾å’Œå˜åŒ–çš„ç²¾é€‰æ•°æ®é›†ï¼Œè‡ªåŠ¨åŒ–åŸå¸‚ç›‘æµ‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†OSMGenè¿™ä¸€ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒèƒ½ç›´æ¥ä»åŸå§‹çš„OSMæ•°æ®ä¸­ç”Ÿæˆé€¼çœŸçš„å«æ˜Ÿå›¾åƒã€‚ä¸ä¾èµ–æ …æ ¼ç“¦ç‰‡çš„å…ˆå‰å·¥ä½œä¸åŒï¼ŒOSMGenä½¿ç”¨OSM JSONçš„å…¨ä¸°å¯Œæ€§ï¼ŒåŒ…æ‹¬çŸ¢é‡å‡ ä½•ã€è¯­ä¹‰æ ‡ç­¾ã€ä½ç½®å’Œæ—¶é—´ï¼Œå¯¹åœºæ™¯ç”Ÿæˆæ–¹å¼æä¾›ç²¾ç»†æ§åˆ¶ã€‚è¯¥æ¡†æ¶çš„ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½æ˜¯èƒ½å¤Ÿç”Ÿæˆä¸€è‡´çš„å‰åå›¾åƒå¯¹ï¼šç”¨æˆ·ç¼–è¾‘çš„OSMè¾“å…¥è½¬åŒ–ä¸ºæœ‰é’ˆå¯¹æ€§çš„è§†è§‰å˜åŒ–ï¼Œè€Œå…¶ä½™åœºæ™¯ä¿æŒä¸å˜ã€‚è¿™è§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œä¸ºè§„åˆ’äººå‘˜æä¾›äº†ä¸€ç§é€šè¿‡ç¼–è¾‘åœ°å›¾æ•°æ®æ¥é¢„è§ˆæ‹Ÿè®®å¹²é¢„çš„ç®€ä¾¿æ–¹æ³•ã€‚æ›´å¹¿æ³›åœ°è¯´ï¼ŒOSMGenä¸ºé™æ€å’Œå˜åŒ–çŠ¶æ€ç”Ÿæˆé…å¯¹ï¼ˆJSONã€å›¾åƒï¼‰æ•°æ®ï¼Œä¸ºå»ºç«‹ä¸€ä¸ªå«æ˜Ÿå›¾åƒå¯è‡ªåŠ¨é©±åŠ¨ç»“æ„åŒ–OSMæ›´æ–°çš„é—­ç¯ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OSMGenæ˜¯ä¸€ä¸ªåŸºäºOpenStreetMapæ•°æ®çš„ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½ç”Ÿæˆé€¼çœŸçš„å«æ˜Ÿå›¾åƒã€‚</li>
<li>ä¸ä¾èµ–æ …æ ¼ç“¦ç‰‡çš„æ–¹æ³•ä¸åŒï¼ŒOSMGenä½¿ç”¨å®Œæ•´çš„OSM JSONæ•°æ®ï¼ŒåŒ…æ‹¬çŸ¢é‡å‡ ä½•ã€è¯­ä¹‰æ ‡ç­¾ç­‰ã€‚</li>
<li>OSMGenèƒ½ç”Ÿæˆä¸€è‡´çš„å‰åå›¾åƒå¯¹ï¼Œä½¿ç”¨æˆ·ç¼–è¾‘çš„åœ°å›¾æ•°æ®è½¬åŒ–ä¸ºå¯è§†å˜åŒ–ã€‚</li>
<li>è¯¥æ¡†æ¶æœ‰åŠ©äºè§£å†³æ•°æ®ç¨€ç¼ºå’Œç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œä¾¿äºè§„åˆ’äººå‘˜é¢„è§ˆæ‹Ÿè®®å¹²é¢„æ•ˆæœã€‚</li>
<li>OSMGenç”Ÿæˆçš„æ•°æ®å¯¹åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç›‘æµ‹å’Œç¯å¢ƒç®¡ç†æœ‰é‡è¦ä½œç”¨ã€‚</li>
<li>OSMGenä¸ºå»ºç«‹å«æ˜Ÿå›¾åƒé©±åŠ¨çš„ç»“æ„åŒ–OSMæ›´æ–°é—­ç¯ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00345">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-13cc089e92fc8a08b4132396800c670a" align="middle">
<img src="https://picx.zhimg.com/v2-deee6e64bf7ee6fe81534c253130b733" align="middle">
<img src="https://picx.zhimg.com/v2-7a15e3d9c5623ad545af0fdc10229290" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MambaNetLK-Enhancing-Colonoscopy-Point-Cloud-Registration-with-Mamba"><a href="#MambaNetLK-Enhancing-Colonoscopy-Point-Cloud-Registration-with-Mamba" class="headerlink" title="MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba"></a>MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba</h2><p><strong>Authors:Linzhe Jiang, Jiayuan Huang, Sophia Bano, Matthew J. Clarkson, Zhehua Mao, Mobarak I. Hoque</strong></p>
<p>Accurate 3D point cloud registration underpins reliable image-guided colonoscopy, directly affecting lesion localization, margin assessment, and navigation safety. However, biological tissue exhibits repetitive textures and locally homogeneous geometry that cause feature degeneracy, while substantial domain shifts between pre-operative anatomy and intra-operative observations further degrade alignment stability. To address these clinically critical challenges, we introduce a novel 3D registration method tailored for endoscopic navigation and a high-quality, clinically grounded dataset to support rigorous and reproducible benchmarking. We introduce C3VD-Raycasting-10k, a large-scale benchmark dataset with 10,014 geometrically aligned point cloud pairs derived from clinical CT data. We propose MambaNetLK, a novel correspondence-free registration framework, which enhances the PointNetLK architecture by integrating a Mamba State Space Model (SSM) as a cross-modal feature extractor. As a result, the proposed framework efficiently captures long-range dependencies with linear-time complexity. The alignment is achieved iteratively using the Lucas-Kanade algorithm. On the clinical dataset, C3VD-Raycasting-10k, MambaNetLK achieves the best performance compared with the state-of-the-art methods, reducing median rotation error by 56.04% and RMSE translation error by 26.19% over the second-best method. The model also demonstrates strong generalization on ModelNet40 and superior robustness to initial pose perturbations. MambaNetLK provides a robust foundation for 3D registration in surgical navigation. The combination of a globally expressive SSM-based feature extractor and a large-scale clinical dataset enables more accurate and reliable guidance systems in minimally invasive procedures like colonoscopy. </p>
<blockquote>
<p>ç²¾ç¡®çš„ä¸‰ç»´ç‚¹äº‘é…å‡†ä¸ºå¯é çš„å›¾åƒå¼•å¯¼ç»“è‚ é•œæ£€æŸ¥æä¾›äº†æ”¯æŒï¼Œç›´æ¥å½±å“ç—…ç¶å®šä½ã€è¾¹ç•Œè¯„ä¼°å’Œå¯¼èˆªå®‰å…¨ã€‚ç„¶è€Œï¼Œç”Ÿç‰©ç»„ç»‡è¡¨ç°å‡ºé‡å¤çš„çº¹ç†å’Œå±€éƒ¨å‡åŒ€çš„å‡ ä½•å½¢çŠ¶ï¼Œå¯¼è‡´ç‰¹å¾é€€åŒ–ï¼Œè€Œæœ¯å‰è§£å‰–ä¸æœ¯ä¸­è§‚å¯Ÿä¹‹é—´çš„æ˜¾è‘—é¢†åŸŸåç§»è¿›ä¸€æ­¥é™ä½äº†å¯¹é½ç¨³å®šæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›ä¸´åºŠä¸Šè‡³å…³é‡è¦çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é’ˆå¯¹å†…é•œå¯¼èˆªå¼•å…¥äº†ä¸€ç§æ–°å‹ä¸‰ç»´é…å‡†æ–¹æ³•ä»¥åŠé«˜è´¨é‡ã€åŸºäºä¸´åºŠçš„æ•°æ®é›†ï¼Œä»¥æ”¯æŒä¸¥æ ¼å’Œå¯é‡å¤æ€§çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬ä»‹ç»äº†C3VD-Raycasting-10kï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«ä»ä¸´åºŠCTæ•°æ®æ´¾ç”Ÿçš„10,014å¯¹å‡ ä½•å¯¹é½çš„ç‚¹äº‘ã€‚æˆ‘ä»¬æå‡ºäº†MambaNetLKï¼Œè¿™æ˜¯ä¸€ç§æ— å¯¹åº”å…³ç³»çš„é…å‡†æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆMambaçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä½œä¸ºè·¨æ¨¡æ€ç‰¹å¾æå–å™¨ï¼Œå¢å¼ºäº†PointNetLKæ¶æ„ã€‚å› æ­¤ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé«˜æ•ˆåœ°æ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œå…·æœ‰çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚å¯¹é½æ˜¯é€šè¿‡Lucas-Kanadeç®—æ³•è¿­ä»£å®ç°çš„ã€‚åœ¨ä¸´åºŠæ•°æ®é›†C3VD-Raycasting-10kä¸Šï¼ŒMambaNetLKä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œå°†ä¸­ä½æ—‹è½¬è¯¯å·®å‡å°‘äº†56.04%ï¼Œå°†RMSEå¹³ç§»è¯¯å·®å‡å°‘äº†26.19%ã€‚è¯¥æ¨¡å‹åœ¨ModelNet40ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å¯¹åˆå§‹å§¿åŠ¿æ‰°åŠ¨è¡¨ç°å‡ºä¼˜è¶Šçš„é²æ£’æ€§ã€‚MambaNetLKä¸ºæ‰‹æœ¯å¯¼èˆªä¸­çš„ä¸‰ç»´é…å‡†æä¾›äº†ç¨³å¥çš„åŸºç¡€ã€‚åŸºäºå…¨å±€è¡¨è¾¾æ€§SSMçš„ç‰¹å¾æå–å™¨ä¸å¤§è§„æ¨¡ä¸´åºŠæ•°æ®é›†çš„ç»„åˆï¼Œä¸ºç»“è‚ é•œæ£€æŸ¥ç­‰å¾®åˆ›æ‰‹æœ¯æä¾›äº†æ›´å‡†ç¡®ã€æ›´å¯é çš„æŒ‡å¯¼ç³»ç»Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00260v1">PDF</a> 12 pages, 4 figures, 3 tables, IPCAI conference</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†åœ¨å›¾åƒå¼•å¯¼ç»“è‚ é•œæ£€æŸ¥ä¸­å‡†ç¡®çš„ä¸‰ç»´ç‚¹äº‘æ³¨å†Œçš„é‡è¦æ€§åŠå…¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†æ–°å‹çš„é€‚ç”¨äºå†…é•œå¯¼èˆªçš„ä¸‰ç»´æ³¨å†Œæ–¹æ³•å’Œé«˜è´¨é‡çš„ä¸´åºŠæ•°æ®é›†C3VD-Raycasting-10kï¼Œç”¨äºæ”¯æŒä¸¥æ ¼å’Œå¯é‡å¤æ€§çš„åŸºå‡†æµ‹è¯•ã€‚åŒæ—¶ï¼Œä»–ä»¬æå‡ºäº†æ— å¯¹åº”å…³ç³»çš„æ³¨å†Œæ¡†æ¶MambaNetLKï¼Œè¯¥æ¡†æ¶ç»“åˆäº†Mamba State Space Modelï¼ˆSSMï¼‰ä½œä¸ºè·¨æ¨¡æ€ç‰¹å¾æå–å™¨ï¼Œèƒ½é«˜æ•ˆæ•æ‰è¿œç¨‹ä¾èµ–å…³ç³»å¹¶å…·æœ‰çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚åœ¨ä¸´åºŠè¯•éªŒå’Œå¤§å‹æ•°æ®é›†ä¸Šçš„ç»“æœè¡¨æ˜ï¼ŒMambaNetLKç›¸è¾ƒäºå…¶ä»–å‰æ²¿æ–¹æ³•å…·æœ‰æœ€ä½³æ€§èƒ½ï¼Œæ˜¾è‘—å‡å°‘äº†æ—‹è½¬è¯¯å·®å’Œå¹³ç§»è¯¯å·®ã€‚è¿™ä¸ºæ‰‹æœ¯å¯¼èˆªä¸­çš„ä¸‰ç»´æ³¨å†Œæä¾›äº†ç¨³å¥çš„åŸºç¡€ï¼Œå¹¶æœ‰æœ›ä¸ºç»“è‚ é•œç­‰å¾®åˆ›æ‰‹æœ¯æä¾›æ›´å‡†ç¡®å¯é çš„æŒ‡å¯¼ç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dç‚¹äº‘æ³¨å†Œåœ¨å›¾åƒå¼•å¯¼ç»“è‚ é•œæ£€æŸ¥ä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œå½±å“ç—…ç¶å®šä½ã€è¾¹ç•Œè¯„ä¼°å’Œå¯¼èˆªå®‰å…¨ã€‚</li>
<li>ç”Ÿç‰©ç»„ç»‡å­˜åœ¨ç‰¹å¾é€€åŒ–é—®é¢˜å’Œæœ¯å‰è§£å‰–ä¸æœ¯ä¸­è§‚å¯Ÿçš„æ˜¾è‘—é¢†åŸŸæ¼‚ç§»é—®é¢˜ï¼Œä¸ºæ³¨å†Œå¸¦æ¥æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥æ–°å‹3Dæ³¨å†Œæ–¹æ³•MambaNetLKï¼Œç»“åˆMamba State Space Modelï¼ˆSSMï¼‰å’ŒPointNetLKæ¶æ„ï¼Œæå‡è¿œç¨‹ä¾èµ–æ•æ‰èƒ½åŠ›å¹¶å…·æœ‰çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚</li>
<li>æå‡ºå¤§å‹ä¸´åºŠæ•°æ®é›†C3VD-Raycasting-10kï¼ŒåŒ…å«ä»ä¸´åºŠCTæ•°æ®æ´¾ç”Ÿçš„å‡ ä½•å¯¹é½ç‚¹äº‘å¯¹ã€‚</li>
<li>MambaNetLKåœ¨ä¸´åºŠè¯•éªŒå’Œå¤§å‹æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ï¼Œç›¸è¾ƒäºå…¶ä»–å‰æ²¿æ–¹æ³•æ˜¾è‘—å‡å°‘æ—‹è½¬å’Œå¹³ç§»è¯¯å·®ã€‚</li>
<li>MambaNetLKæ¡†æ¶ä¸ºæ‰‹æœ¯å¯¼èˆªä¸­çš„ä¸‰ç»´æ³¨å†Œæä¾›äº†ç¨³å¥åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00260">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e155760916a973214a1648aa12686f41" align="middle">
<img src="https://picx.zhimg.com/v2-9c819698da2c06973cc68e3e0d3c31c6" align="middle">
<img src="https://picx.zhimg.com/v2-c3d89bb6c6a8752c51071edd4b042489" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="GeneFlow-Translation-of-Single-cell-Gene-Expression-to-Histopathological-Images-via-Rectified-Flow"><a href="#GeneFlow-Translation-of-Single-cell-Gene-Expression-to-Histopathological-Images-via-Rectified-Flow" class="headerlink" title="GeneFlow: Translation of Single-cell Gene Expression to   Histopathological Images via Rectified Flow"></a>GeneFlow: Translation of Single-cell Gene Expression to   Histopathological Images via Rectified Flow</h2><p><strong>Authors:Mengbo Wang, Shourya Verma, Aditya Malusare, Luopin Wang, Yiyang Lu, Vaneet Aggarwal, Mario Sola, Ananth Grama, Nadia Atallah Lanman</strong></p>
<p>Spatial transcriptomics (ST) technologies can be used to align transcriptomes with histopathological morphology, presenting exciting new opportunities for biomolecular discovery. Using ST data, we construct a novel framework, GeneFlow, to map transcriptomics onto paired cellular images. By combining an attention-based RNA encoder with a conditional UNet guided by rectified flow, we generate high-resolution images with different staining methods (e.g. H&amp;E, DAPI) to highlight various cellular&#x2F;tissue structures. Rectified flow with high-order ODE solvers creates a continuous, bijective mapping between transcriptomics and image manifolds, addressing the many-to-one relationship inherent in this problem. Our method enables the generation of realistic cellular morphology features and spatially resolved intercellular interactions from observational gene expression profiles, provides potential to incorporate genetic&#x2F;chemical perturbations, and enables disease diagnosis by revealing dysregulated patterns in imaging phenotypes. Our rectified flow-based method outperforms diffusion-based baseline method in all experiments. Code can be found at <a target="_blank" rel="noopener" href="https://github.com/wangmengbo/GeneFlow">https://github.com/wangmengbo/GeneFlow</a>. </p>
<blockquote>
<p>ç©ºé—´è½¬å½•ç»„å­¦ï¼ˆSTï¼‰æŠ€æœ¯å¯ç”¨äºå°†è½¬å½•ç»„ä¸ç—…ç†å½¢æ€å­¦ç›¸ç»“åˆï¼Œä¸ºç”Ÿç‰©åˆ†å­å‘ç°æä¾›äº†ä»¤äººå…´å¥‹çš„æ–°æœºé‡ã€‚æˆ‘ä»¬ä½¿ç”¨STæ•°æ®æ„å»ºäº†ä¸€ä¸ªæ–°å‹æ¡†æ¶GeneFlowï¼Œå°†è½¬å½•ç»„æ˜ å°„åˆ°é…å¯¹çš„ç»†èƒå›¾åƒä¸Šã€‚é€šè¿‡ç»“åˆåŸºäºæ³¨æ„åŠ›çš„RNAç¼–ç å™¨å’Œç”±æ ¡æ­£æµå¼•å¯¼çš„æ¡ä»¶UNetï¼Œæˆ‘ä»¬ç”Ÿæˆäº†å…·æœ‰ä¸åŒæŸ“è‰²æ–¹æ³•ï¼ˆä¾‹å¦‚H&amp;Eã€DAPIï¼‰çš„é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä»¥çªå‡ºæ˜¾ç¤ºå„ç§ç»†èƒ&#x2F;ç»„ç»‡ç»“æ„ã€‚ä½¿ç”¨é«˜é˜¶ODEæ±‚è§£å™¨çš„æ ¡æ­£æµåœ¨è½¬å½•ç»„å’Œå›¾åƒæµå½¢ä¹‹é—´åˆ›å»ºäº†è¿ç»­çš„åŒå°„æ˜ å°„ï¼Œè§£å†³äº†è¯¥é—®é¢˜æ‰€å›ºæœ‰çš„å¤šå¯¹ä¸€å…³ç³»ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä»è§‚å¯Ÿæ€§çš„åŸºå› è¡¨è¾¾è°±ä¸­ç”Ÿæˆç°å®çš„ç»†èƒå½¢æ€ç‰¹å¾å’Œç©ºé—´è§£å†³çš„ç»†èƒé—´ç›¸äº’ä½œç”¨ï¼Œå…·æœ‰æ•´åˆé—ä¼ &#x2F;åŒ–å­¦å¹²æ‰°çš„æ½œåŠ›ï¼Œå¹¶é€šè¿‡æ­ç¤ºæˆåƒè¡¨å‹ä¸­çš„å¤±è°ƒæ¨¡å¼æ¥è¿›è¡Œç–¾ç—…è¯Šæ–­ã€‚æˆ‘ä»¬çš„åŸºäºæ ¡æ­£æµçš„æ–¹æ³•åœ¨æ‰€æœ‰å®éªŒä¸­å‡è¡¨ç°å‡ºä¼˜äºåŸºäºæ‰©æ•£çš„åŸºçº¿æ–¹æ³•ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/wangmengbo/GeneFlow%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/wangmengbo/GeneFlowæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00119v1">PDF</a> </p>
<p><strong>Summary</strong><br>     ç©ºé—´è½¬å½•ç»„å­¦æŠ€æœ¯å¯ç”¨äºå°†è½¬å½•ç»„ä¸ç»„ç»‡ç—…ç†å­¦å½¢æ€å¯¹é½ï¼Œä¸ºç”Ÿç‰©åˆ†å­å‘ç°æä¾›äº†æ–°çš„æœºä¼šã€‚é€šè¿‡GeneFlowæ¡†æ¶ï¼Œæˆ‘ä»¬å°†ç©ºé—´è½¬å½•ç»„å­¦æ•°æ®ä¸ç»†èƒå›¾åƒé…å¯¹ï¼Œç»“åˆåŸºäºæ³¨æ„åŠ›çš„RNAç¼–ç å™¨å’Œæ¡ä»¶UNetç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚è¯¥æ–¹æ³•ä½¿ç”¨æ ¡æ­£æµå’Œé«˜é˜¶ODEæ±‚è§£å™¨åˆ›å»ºè½¬å½•ç»„å’Œå›¾åƒæµå½¢ä¹‹é—´çš„è¿ç»­åŒå°„æ˜ å°„ï¼Œè§£å†³äº†è¯¥é—®é¢˜å›ºæœ‰çš„å¤šå¯¹ä¸€å…³ç³»ã€‚è¯¥æ–¹æ³•å¯ç”Ÿæˆç°å®çš„ç»†èƒå½¢æ€ç‰¹å¾å’Œç©ºé—´è§£å†³çš„ç»†èƒé—´ç›¸äº’ä½œç”¨ï¼Œå…·æœ‰æ•´åˆé—ä¼ &#x2F;åŒ–å­¦å¹²æ‰°çš„æ½œåŠ›ï¼Œå¹¶é€šè¿‡æ­ç¤ºæˆåƒè¡¨å‹ä¸­çš„å¤±è°ƒæ¨¡å¼å®ç°ç–¾ç—…è¯Šæ–­ã€‚GeneFlowæ–¹æ³•ä¼˜äºæ‰€æœ‰å®éªŒä¸­çš„æ‰©æ•£åŸºçº¿æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç©ºé—´è½¬å½•ç»„å­¦æŠ€æœ¯å°†è½¬å½•ç»„ä¸ç»„ç»‡ç—…ç†å­¦å½¢æ€ç»“åˆï¼Œä¿ƒè¿›ç”Ÿç‰©åˆ†å­å‘ç°çš„æ–°æœºé‡ã€‚</li>
<li>GeneFlowæ¡†æ¶ç”¨äºå°†ç©ºé—´è½¬å½•ç»„å­¦æ•°æ®ä¸ç»†èƒå›¾åƒé…å¯¹ã€‚</li>
<li>ç»“åˆåŸºäºæ³¨æ„åŠ›çš„RNAç¼–ç å™¨å’Œæ¡ä»¶UNetç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä»¥çªå‡ºæ˜¾ç¤ºä¸åŒçš„æŸ“è‰²æ–¹æ³•ï¼ˆå¦‚H&amp;Eï¼ŒDAPIï¼‰ã€‚</li>
<li>ä½¿ç”¨æ ¡æ­£æµå’Œé«˜é˜¶ODEæ±‚è§£å™¨è§£å†³è½¬å½•ç»„å’Œå›¾åƒä¹‹é—´çš„å¤šå¯¹ä¸€æ˜ å°„é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆç°å®çš„ç»†èƒå½¢æ€ç‰¹å¾å’Œç©ºé—´è§£å†³çš„ç»†èƒé—´ç›¸äº’ä½œç”¨ã€‚</li>
<li>GeneFlowå…·æœ‰æ•´åˆé—ä¼ &#x2F;åŒ–å­¦å¹²æ‰°çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00119">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d67b1fc29abde9dea16d7ea44b25c6f7" align="middle">
<img src="https://picx.zhimg.com/v2-aea08a290064cc0b784c044cc105fcd0" align="middle">
<img src="https://picx.zhimg.com/v2-5f2364897f3c7cdaf9870b96c85cf881" align="middle">
<img src="https://picx.zhimg.com/v2-6c99729bb55ae765504174b2e201ba88" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-06/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-06/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-06/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2a25625348991da4f51bf151e0a4a2b8" class="responsive-img" alt="è§†é¢‘ç†è§£">
                        
                        <span class="card-title">è§†é¢‘ç†è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  CueBench Advancing Unified Understanding of Context-Aware Video   Anomalies in Real-World
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    è§†é¢‘ç†è§£
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-06/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c8d906f4c4843b4192a114eb0ab7e4f7" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  Assessing the value of Geo-Foundational Models for Flood Inundation   Mapping Benchmarking models for Sentinel-1, Sentinel-2, and Planetscope for   end-users
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32883.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
