<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-06  Sounding that Object Interactive Object-Aware Image to Audio Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-2bcb7ee303bd3489e19af35c3bdf82bd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    32 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-06-æ›´æ–°"><a href="#2025-06-06-æ›´æ–°" class="headerlink" title="2025-06-06 æ›´æ–°"></a>2025-06-06 æ›´æ–°</h1><h2 id="Sounding-that-Object-Interactive-Object-Aware-Image-to-Audio-Generation"><a href="#Sounding-that-Object-Interactive-Object-Aware-Image-to-Audio-Generation" class="headerlink" title="Sounding that Object: Interactive Object-Aware Image to Audio Generation"></a>Sounding that Object: Interactive Object-Aware Image to Audio Generation</h2><p><strong>Authors:Tingle Li, Baihe Huang, Xiaobin Zhuang, Dongya Jia, Jiawei Chen, Yuping Wang, Zhuo Chen, Gopala Anumanchipalli, Yuxuan Wang</strong></p>
<p>Generating accurate sounds for complex audio-visual scenes is challenging, especially in the presence of multiple objects and sound sources. In this paper, we propose an {\em interactive object-aware audio generation} model that grounds sound generation in user-selected visual objects within images. Our method integrates object-centric learning into a conditional latent diffusion model, which learns to associate image regions with their corresponding sounds through multi-modal attention. At test time, our model employs image segmentation to allow users to interactively generate sounds at the {\em object} level. We theoretically validate that our attention mechanism functionally approximates test-time segmentation masks, ensuring the generated audio aligns with selected objects. Quantitative and qualitative evaluations show that our model outperforms baselines, achieving better alignment between objects and their associated sounds. Project page: <a target="_blank" rel="noopener" href="https://tinglok.netlify.app/files/avobject/">https://tinglok.netlify.app/files/avobject/</a> </p>
<blockquote>
<p>ä¸ºå¤æ‚çš„è§†å¬åœºæ™¯ç”Ÿæˆå‡†ç¡®çš„å£°éŸ³æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å­˜åœ¨å¤šä¸ªå¯¹è±¡å’Œå£°éŸ³æºçš„æƒ…å†µä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§<strong>äº¤äº’å¼å¯¹è±¡æ„ŸçŸ¥éŸ³é¢‘ç”Ÿæˆ</strong>æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»¥å›¾åƒä¸­ç”¨æˆ·é€‰æ‹©çš„è§†è§‰å¯¹è±¡ä¸ºåŸºç¡€ç”Ÿæˆå£°éŸ³ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å¯¹è±¡ä¸­å¿ƒå­¦ä¹ é›†æˆåˆ°æ¡ä»¶æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œè¯¥æ¨¡å‹é€šè¿‡å¤šæ¨¡å¼æ³¨æ„åŠ›å­¦ä¹ å°†å›¾åƒåŒºåŸŸä¸ç›¸åº”çš„å£°éŸ³ç›¸å…³è”ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œæˆ‘ä»¬çš„æ¨¡å‹é‡‡ç”¨å›¾åƒåˆ†å‰²æŠ€æœ¯ï¼Œå…è®¸ç”¨æˆ·ä»¥<strong>å¯¹è±¡</strong>çº§åˆ«äº¤äº’åœ°ç”Ÿæˆå£°éŸ³ã€‚æˆ‘ä»¬ä»ç†è®ºä¸ŠéªŒè¯äº†æˆ‘ä»¬æ³¨æ„åŠ›çš„æœºåˆ¶ï¼Œå®ƒåœ¨åŠŸèƒ½ä¸Šè¿‘ä¼¼äºæµ‹è¯•æ—¶çš„åˆ†å‰²æ©è†œï¼Œç¡®ä¿ç”Ÿæˆçš„éŸ³é¢‘ä¸æ‰€é€‰å¯¹è±¡å¯¹é½ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œåœ¨å¯¹è±¡å’Œä¸å…¶ç›¸å…³çš„å£°éŸ³ä¹‹é—´å®ç°äº†æ›´å¥½çš„å¯¹é½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://tinglok.netlify.app/files/avobject/">https://tinglok.netlify.app/files/avobject/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04214v1">PDF</a> ICML 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§äº¤äº’å¼å¯¹è±¡æ„ŸçŸ¥éŸ³é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨ç”¨æˆ·é€‰æ‹©çš„å›¾åƒä¸­çš„è§†è§‰å¯¹è±¡åŸºç¡€ä¸Šç”Ÿæˆå£°éŸ³ã€‚é€šè¿‡é›†æˆå¯¹è±¡ä¸­å¿ƒå­¦ä¹ äºæ¡ä»¶æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å­¦ä¼šå°†å›¾åƒåŒºåŸŸä¸å…¶ç›¸åº”çš„å£°éŸ³é€šè¿‡å¤šæ¨¡å¼æ³¨æ„åŠ›ç›¸å…³è”ã€‚æµ‹è¯•æ—¶ï¼Œæ¨¡å‹é‡‡ç”¨å›¾åƒåˆ†å‰²è®©ç”¨æˆ·èƒ½å¤Ÿäº’åŠ¨åœ°ç”Ÿæˆå¯¹è±¡çº§åˆ«çš„å£°éŸ³ã€‚ç†è®ºå’Œå®éªŒéªŒè¯æ˜¾ç¤ºï¼Œæ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶å¯è¿‘ä¼¼æµ‹è¯•æ—¶çš„åˆ†å‰²æ©æ¨¡ï¼Œç¡®ä¿ç”Ÿæˆçš„éŸ³é¢‘ä¸æ‰€é€‰å¯¹è±¡ç›¸ç¬¦ã€‚æ­¤æ¨¡å‹ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå®ç°å¯¹è±¡ä¸å…¶ç›¸å…³å£°éŸ³ä¹‹é—´æ›´å¥½çš„å¯¹é½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†äº¤äº’å¼å¯¹è±¡æ„ŸçŸ¥éŸ³é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå°†å£°éŸ³ç”Ÿæˆä¸å›¾åƒä¸­çš„è§†è§‰å¯¹è±¡ç›¸å…³è”ã€‚</li>
<li>é›†æˆå¯¹è±¡ä¸­å¿ƒå­¦ä¹ äºæ¡ä»¶æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå­¦ä¼šå…³è”å›¾åƒåŒºåŸŸä¸å¯¹åº”å£°éŸ³ã€‚</li>
<li>é€šè¿‡å¤šæ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å®ç°å¯¹è±¡çº§åˆ«çš„å£°éŸ³ç”Ÿæˆã€‚</li>
<li>æ³¨æ„åŠ›æœºåˆ¶ç†è®ºä¸Šå¯è¿‘ä¼¼æµ‹è¯•æ—¶çš„åˆ†å‰²æ©æ¨¡ï¼Œç¡®ä¿éŸ³é¢‘ä¸æ‰€é€‰å¯¹è±¡å¯¹é½ã€‚</li>
<li>æ¨¡å‹åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­å‡è¡¨ç°å‡ºä¼˜äºåŸºçº¿æ¨¡å‹çš„æ•ˆæœã€‚</li>
<li>æ¨¡å‹å®ç°äº†å¯¹è±¡ä¸å…¶ç›¸å…³å£°éŸ³ä¹‹é—´çš„è‰¯å¥½å¯¹é½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04214">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d09ddcce20dd9e038e83aad8b92cebba.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d3fd2af370ee0baa78bc9d2722bd8349.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-587fad64eee5cc1ad7aef106fd32fb9f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-248b247824ac7848d52b5c4c62cbd11c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Diffusion-Domain-Teacher-Diffusion-Guided-Domain-Adaptive-Object-Detector"><a href="#Diffusion-Domain-Teacher-Diffusion-Guided-Domain-Adaptive-Object-Detector" class="headerlink" title="Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object   Detector"></a>Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object   Detector</h2><p><strong>Authors:Boyong He, Yuxiang Ji, Zhuoyue Tan, Liaoni Wu</strong></p>
<p>Object detectors often suffer a decrease in performance due to the large domain gap between the training data (source domain) and real-world data (target domain). Diffusion-based generative models have shown remarkable abilities in generating high-quality and diverse images, suggesting their potential for extracting valuable feature from various domains. To effectively leverage the cross-domain feature representation of diffusion models, in this paper, we train a detector with frozen-weight diffusion model on the source domain, then employ it as a teacher model to generate pseudo labels on the unlabeled target domain, which are used to guide the supervised learning of the student model on the target domain. We refer to this approach as Diffusion Domain Teacher (DDT). By employing this straightforward yet potent framework, we significantly improve cross-domain object detection performance without compromising the inference speed. Our method achieves an average mAP improvement of 21.2% compared to the baseline on 6 datasets from three common cross-domain detection benchmarks (Cross-Camera, Syn2Real, Real2Artistic}, surpassing the current state-of-the-art (SOTA) methods by an average of 5.7% mAP. Furthermore, extensive experiments demonstrate that our method consistently brings improvements even in more powerful and complex models, highlighting broadly applicable and effective domain adaptation capability of our DDT. The code is available at <a target="_blank" rel="noopener" href="https://github.com/heboyong/Diffusion-Domain-Teacher">https://github.com/heboyong/Diffusion-Domain-Teacher</a>. </p>
<blockquote>
<p>å¯¹è±¡æ£€æµ‹å™¨é€šå¸¸ç”±äºè®­ç»ƒæ•°æ®ï¼ˆæºåŸŸï¼‰å’Œç°å®ä¸–ç•Œæ•°æ®ï¼ˆç›®æ ‡åŸŸï¼‰ä¹‹é—´çš„åŸŸå·®è·è¾ƒå¤§è€Œæ€§èƒ½ä¸‹é™ã€‚åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å’Œå¤šæ ·åŒ–å›¾åƒæ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ï¼Œè¿™è¡¨æ˜å®ƒä»¬ä»å„ç§åŸŸä¸­æå–æœ‰ä»·å€¼ç‰¹å¾çš„æ½œåŠ›ã€‚ä¸ºäº†æœ‰æ•ˆåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„è·¨åŸŸç‰¹å¾è¡¨ç¤ºï¼Œæœ¬æ–‡åœ¨æºåŸŸä¸Šè®­ç»ƒäº†ä¸€ä¸ªå¸¦æœ‰å†»ç»“æƒé‡æ‰©æ•£æ¨¡å‹çš„æ£€æµ‹å™¨ï¼Œç„¶åå°†å…¶ä½œä¸ºæ•™å¸ˆæ¨¡å‹åœ¨æœªç»æ ‡è®°çš„ç›®æ ‡åŸŸä¸Šç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç”¨äºæŒ‡å¯¼ç›®æ ‡åŸŸä¸Šå­¦ç”Ÿæ¨¡å‹çš„ç›‘ç£å­¦ä¹ ã€‚æˆ‘ä»¬å°†è¿™ç§æ–¹æ³•ç§°ä¸ºæ‰©æ•£åŸŸæ•™å¸ˆï¼ˆDDTï¼‰ã€‚é€šè¿‡é‡‡ç”¨è¿™ç§ç®€å•è€Œå¼ºå¤§çš„æ¡†æ¶ï¼Œæˆ‘ä»¬åœ¨ä¸ç‰ºç‰²æ¨ç†é€Ÿåº¦çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æé«˜äº†è·¨åŸŸç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ä¸ªå¸¸è§çš„è·¨åŸŸæ£€æµ‹åŸºå‡†æµ‹è¯•ï¼ˆè·¨æ‘„åƒå¤´ã€Syn2Realã€Real2Artisticï¼‰çš„6ä¸ªæ•°æ®é›†ä¸Šï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œå¹³å‡mAPæé«˜äº†21.2%ï¼Œå¹¶ä¸”å¹³å‡æ¯”å½“å‰æœ€ä½³æ–¹æ³•é«˜å‡º5.7%çš„mAPã€‚æ­¤å¤–ï¼Œå¤§é‡å®éªŒè¡¨æ˜ï¼Œå³ä½¿åœ¨æ›´å¼ºå¤§å’Œå¤æ‚çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿå§‹ç»ˆèƒ½å¸¦æ¥æ”¹è¿›ï¼Œè¿™çªæ˜¾äº†æˆ‘ä»¬DDTæ–¹æ³•å¹¿æ³›çš„é€‚ç”¨æ€§å’Œæœ‰æ•ˆçš„åŸŸé€‚åº”èƒ½åŠ›ã€‚ä»£ç å¯ç”¨åœ¨<a target="_blank" rel="noopener" href="https://github.com/heboyong/Diffusion-Domain-Teacher%E3%80%82">https://github.com/heboyong/Diffusion-Domain-Teacherã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04211v1">PDF</a> MM2024 poster, with appendix and codes</p>
<p><strong>Summary</strong><br>     æ‰©æ•£æ¨¡å‹åœ¨è·¨åŸŸç›®æ ‡æ£€æµ‹ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚é€šè¿‡è®­ç»ƒæºåŸŸä¸Šçš„å†»ç»“æƒé‡æ‰©æ•£æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œå¯¹ç›®æ ‡åŸŸç”Ÿæˆä¼ªæ ‡ç­¾è¿›è¡Œå¼•å¯¼å­¦ä¹ ï¼Œæé«˜äº†è·¨åŸŸç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¸æŸå¤±æ¨ç†é€Ÿåº¦ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¹³å‡æé«˜äº†21.2%çš„mAPæ€§èƒ½ï¼Œè¶…è¿‡äº†ç°æœ‰æŠ€æœ¯æ°´å¹³å¹³å‡æé«˜äº†5.7%ã€‚è¿™æ˜¯ä¸€ç§å¼ºå¤§è€Œçµæ´»çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå¹¿æ³›åº”ç”¨åœ¨å„ç§é¢†åŸŸé€‚åº”çš„åœºæ™¯ä¸­ã€‚æ›´å¤šç»†èŠ‚å’Œä»£ç å¯åœ¨GitHubä»“åº“ä¸­æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å…·æœ‰å¼ºå¤§çš„è·¨åŸŸç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ç›®æ ‡æ£€æµ‹ä¸­å‘æŒ¥æ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
<li>é€šè¿‡è®­ç»ƒæºåŸŸä¸Šçš„å†»ç»“æƒé‡æ‰©æ•£æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œç”Ÿæˆä¼ªæ ‡ç­¾ç”¨äºç›®æ ‡åŸŸçš„å­¦ä¹ ï¼Œæœ‰æ•ˆæé«˜äº†è·¨åŸŸç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸æŸå¤±æ¨ç†é€Ÿåº¦çš„å‰æä¸‹å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¹³å‡æé«˜äº†21.2%çš„mAPæ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ä»…é€‚ç”¨äºåŸºç¡€æ¨¡å‹ï¼Œè€Œä¸”åœ¨æ›´å¼ºå¤§å’Œå¤æ‚çš„æ¨¡å‹ä¸­ä¹Ÿèƒ½å¸¦æ¥ä¸€è‡´çš„æ€§èƒ½æå‡ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ï¼Œèƒ½å¤Ÿåº”ç”¨äºå„ç§é¢†åŸŸé€‚åº”çš„åœºæ™¯ä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04211">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0cfa696d379b4868fd3b72cf60c692a9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-569fda5147ded2ee69c238c1e801d02a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a34f19d3b2aa15e79afd07812b25e15.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a61d28d153473cf17b9c3cd7c27c951c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb26f85076d53dd0f4144e04be3108de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-235d1b9608d16d25d9996bcbcbff868f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c442d51b93f58f8a517188c0feea68cd.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Image-Editing-As-Programs-with-Diffusion-Models"><a href="#Image-Editing-As-Programs-with-Diffusion-Models" class="headerlink" title="Image Editing As Programs with Diffusion Models"></a>Image Editing As Programs with Diffusion Models</h2><p><strong>Authors:Yujia Hu, Songhua Liu, Zhenxiong Tan, Xingyi Yang, Xinchao Wang</strong></p>
<p>While diffusion models have achieved remarkable success in text-to-image generation, they encounter significant challenges with instruction-driven image editing. Our research highlights a key challenge: these models particularly struggle with structurally inconsistent edits that involve substantial layout changes. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a unified image editing framework built upon the Diffusion Transformer (DiT) architecture. At its core, IEAP approaches instructional editing through a reductionist lens, decomposing complex editing instructions into sequences of atomic operations. Each operation is implemented via a lightweight adapter sharing the same DiT backbone and is specialized for a specific type of edit. Programmed by a vision-language model (VLM)-based agent, these operations collaboratively support arbitrary and structurally inconsistent transformations. By modularizing and sequencing edits in this way, IEAP generalizes robustly across a wide range of editing tasks, from simple adjustments to substantial structural changes. Extensive experiments demonstrate that IEAP significantly outperforms state-of-the-art methods on standard benchmarks across various editing scenarios. In these evaluations, our framework delivers superior accuracy and semantic fidelity, particularly for complex, multi-step instructions. Codes are available at <a target="_blank" rel="noopener" href="https://github.com/YujiaHu1109/IEAP">https://github.com/YujiaHu1109/IEAP</a>. </p>
<blockquote>
<p>è™½ç„¶æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†åœ¨æŒ‡ä»¤é©±åŠ¨å›¾åƒç¼–è¾‘æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶çªå‡ºäº†ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼šè¿™äº›æ¨¡å‹ç‰¹åˆ«éš¾ä»¥å¤„ç†æ¶‰åŠå¤§é‡å¸ƒå±€å˜åŒ–çš„ç»“æ„æ€§ä¸ä¸€è‡´ç¼–è¾‘ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†â€œå›¾åƒç¼–è¾‘ä½œä¸ºç¨‹åºï¼ˆIEAPï¼‰â€ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£å˜å‹å™¨ï¼ˆDiTï¼‰æ¶æ„çš„ç»Ÿä¸€å›¾åƒç¼–è¾‘æ¡†æ¶ã€‚IEAPçš„æ ¸å¿ƒæ˜¯é€šè¿‡è¿˜åŸè®ºçš„æ–¹æ³•æ¥è¿›è¡ŒæŒ‡ä»¤ç¼–è¾‘ï¼Œå°†å¤æ‚çš„ç¼–è¾‘æŒ‡ä»¤åˆ†è§£ä¸ºåŸå­æ“ä½œåºåˆ—ã€‚æ¯ä¸ªæ“ä½œéƒ½æ˜¯é€šè¿‡è½»é‡çº§é€‚é…å™¨å®ç°çš„ï¼Œè¯¥é€‚é…å™¨å…±äº«ç›¸åŒçš„DiTä¸»å¹²ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šç±»å‹çš„ç¼–è¾‘è¿›è¡Œä¸“ä¸šåŒ–ã€‚è¿™äº›æ“ä½œé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é©±åŠ¨çš„ä»£ç†è¿›è¡Œç¼–ç¨‹ï¼ŒååŒæ”¯æŒä»»æ„å’Œç»“æ„ä¸Šä¸ä¸€è‡´çš„è½¬æ¢ã€‚é€šè¿‡è¿™ç§æ–¹å¼æ¨¡å—åŒ–å¹¶æ’åºç¼–è¾‘ï¼ŒIEAPåœ¨å„ç§ç¼–è¾‘ä»»åŠ¡ä¸Šè¡¨ç°ç¨³å¥ï¼Œæ— è®ºæ˜¯ç®€å•çš„è°ƒæ•´è¿˜æ˜¯å¤§å¹…çš„ç»“æ„å˜åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒIEAPåœ¨å„ç§ç¼–è¾‘åœºæ™¯çš„åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚åœ¨è¿™äº›è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å‡†ç¡®æ€§å’Œè¯­ä¹‰ä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹å¤æ‚çš„å¤šæ­¥éª¤æŒ‡ä»¤ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/YujiaHu1109/IEAP%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/YujiaHu1109/IEAPæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04158v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†åœ¨æŒ‡ä»¤é©±åŠ¨å›¾åƒç¼–è¾‘æ–¹é¢é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¤„ç†æ¶‰åŠé‡å¤§å¸ƒå±€å˜åŒ–çš„ç»“æ„æ€§ä¸ä¸€è‡´ç¼–è¾‘ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å›¾åƒç¼–è¾‘ä½œä¸ºç¨‹åºï¼ˆIEAPï¼‰çš„æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºDiffusion Transformerï¼ˆDiTï¼‰æ¶æ„çš„ç»Ÿä¸€å›¾åƒç¼–è¾‘æ¡†æ¶ã€‚IEAPé€šè¿‡ç®€çº¦ä¸»ä¹‰çš„è§†è§’è¿›è¡ŒæŒ‡ä»¤ç¼–è¾‘ï¼Œå°†å¤æ‚çš„ç¼–è¾‘æŒ‡ä»¤åˆ†è§£ä¸ºä¸€ç³»åˆ—åŸå­æ“ä½œåºåˆ—ã€‚æ¯ä¸ªæ“ä½œéƒ½é€šè¿‡è½»é‡çº§é€‚é…å™¨å®ç°ï¼Œè¯¥é€‚é…å™¨å…±äº«ç›¸åŒçš„DiTä¸»å¹²å¹¶ä¸“ç”¨äºç‰¹å®šç±»å‹çš„ç¼–è¾‘ã€‚è¿™äº›æ“ä½œç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é©±åŠ¨çš„ä»£ç†è¿›è¡Œç¼–ç¨‹ï¼ŒååŒæ”¯æŒä»»æ„å’Œç»“æ„æ€§ä¸ä¸€è‡´çš„è½¬æ¢ã€‚é€šè¿‡è¿™ç§æ–¹å¼æ¨¡å—åŒ–å¹¶ç¼–è¾‘åºåˆ—ï¼ŒIEAPèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå„ç§ç¼–è¾‘ä»»åŠ¡ï¼Œä»ç®€å•è°ƒæ•´åˆ°é‡å¤§ç»“æ„æ€§å˜åŒ–ã€‚åœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒIEAPåœ¨å¤šç§ç¼–è¾‘åœºæ™¯çš„åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤æ‚çš„å¤šæ­¥éª¤æŒ‡ä»¤ä¸‹ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æä¾›äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œè¯­ä¹‰ä¿çœŸåº¦ã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/YujiaHu1109/IEAP">é“¾æ¥</a>ä¸­æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤„ç†æ¶‰åŠé‡å¤§å¸ƒå±€å˜åŒ–çš„æŒ‡ä»¤é©±åŠ¨å›¾åƒç¼–è¾‘æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºçš„å›¾åƒç¼–è¾‘ä½œä¸ºç¨‹åºï¼ˆIEAPï¼‰æ¡†æ¶åŸºäºDiffusion Transformerï¼ˆDiTï¼‰æ¶æ„æ„å»ºã€‚</li>
<li>IEAPé€šè¿‡åˆ†è§£ä¸ºåŸå­æ“ä½œåºåˆ—æ¥å¤„ç†å¤æ‚çš„ç¼–è¾‘æŒ‡ä»¤ã€‚</li>
<li>æ¯ä¸ªæ“ä½œéƒ½æ˜¯é€šè¿‡è½»é‡çº§é€‚é…å™¨å®ç°çš„ï¼Œè¯¥é€‚é…å™¨å…±äº«ç›¸åŒçš„DiTä¸»å¹²å¹¶ä¸“ä¸ºç‰¹å®šç±»å‹çš„ç¼–è¾‘è®¾è®¡ã€‚</li>
<li>è¿™äº›æ“ä½œç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é©±åŠ¨çš„ä»£ç†è¿›è¡Œç¼–ç¨‹ï¼Œæ”¯æŒä»»æ„å’Œç»“æ„æ€§ä¸ä¸€è‡´çš„è½¬æ¢ã€‚</li>
<li>IEAPé€šè¿‡æ¨¡å—åŒ–å¹¶ç¼–è¾‘åºåˆ—çš„æ–¹å¼ï¼Œå¯ä»¥å¹¿æ³›åº”ç”¨äºå„ç§ç¼–è¾‘ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ad86c87163e278763ffa5576bf263fe5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e0d2f7f8c55071cabb96627406d1122.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb8be5176f81834f3c5ee6d4cff374b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1308ede2dd6e8477b20cf362e8c248fb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DiffCAP-Diffusion-based-Cumulative-Adversarial-Purification-for-Vision-Language-Models"><a href="#DiffCAP-Diffusion-based-Cumulative-Adversarial-Purification-for-Vision-Language-Models" class="headerlink" title="DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision   Language Models"></a>DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision   Language Models</h2><p><strong>Authors:Jia Fu, Yongtao Wu, Yihang Chen, Kunyu Peng, Xiao Zhang, Volkan Cevher, Sepideh Pashami, Anders Holst</strong></p>
<p>Vision Language Models (VLMs) have shown remarkable capabilities in multimodal understanding, yet their susceptibility to perturbations poses a significant threat to their reliability in real-world applications. Despite often being imperceptible to humans, these perturbations can drastically alter model outputs, leading to erroneous interpretations and decisions. This paper introduces DiffCAP, a novel diffusion-based purification strategy that can effectively neutralize adversarial corruptions in VLMs. We observe that adding minimal noise to an adversarially corrupted image significantly alters its latent embedding with respect to VLMs. Building on this insight, DiffCAP cumulatively injects random Gaussian noise into adversarially perturbed input data. This process continues until the embeddings of two consecutive noisy images reach a predefined similarity threshold, indicating a potential approach to neutralize the adversarial effect. Subsequently, a pretrained diffusion model is employed to denoise the stabilized image, recovering a clean representation suitable for the VLMs to produce an output. Through extensive experiments across six datasets with three VLMs under varying attack strengths in three task scenarios, we show that DiffCAP consistently outperforms existing defense techniques by a substantial margin. Notably, DiffCAP significantly reduces both hyperparameter tuning complexity and the required diffusion time, thereby accelerating the denoising process. Equipped with strong theoretical and empirical support, DiffCAP provides a robust and practical solution for securely deploying VLMs in adversarial environments. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€ç†è§£æ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ï¼Œç„¶è€Œå®ƒä»¬å®¹æ˜“å—åˆ°æ‰°åŠ¨çš„å½±å“ï¼Œè¿™å¯¹å®ƒä»¬åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„å¯é æ€§æ„æˆäº†é‡å¤§å¨èƒã€‚å°½ç®¡è¿™äº›æ‰°åŠ¨é€šå¸¸å¯¹äººç±»æ¥è¯´æ˜¯ä¸å¯å¯Ÿè§‰çš„ï¼Œä½†å®ƒä»¬ä¼šæå¤§åœ°æ”¹å˜æ¨¡å‹çš„è¾“å‡ºï¼Œå¯¼è‡´é”™è¯¯çš„è§£é‡Šå’Œå†³ç­–ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ‰©æ•£çš„æ–°å‡€åŒ–ç­–ç•¥DiffCAPï¼Œå®ƒå¯ä»¥æœ‰æ•ˆåœ°ä¸­å’Œè§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å¯¹æŠ—æ€§è…è´¥ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œå‘å¯¹æŠ—æ€§è…èš€çš„å›¾åƒæ·»åŠ å°‘é‡å™ªå£°ä¼šæ˜¾è‘—æ”¹å˜å…¶ç›¸å¯¹äºVLMsçš„æ½œåœ¨åµŒå…¥ã€‚åŸºäºè¿™ä¸€è§è§£ï¼ŒDiffCAPç´¯ç§¯åœ°å‘å¯¹æŠ—æ€§æ‰°åŠ¨è¾“å…¥æ•°æ®æ³¨å…¥éšæœºé«˜æ–¯å™ªå£°ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šç»§ç»­è¿›è¡Œï¼Œç›´åˆ°ä¸¤ä¸ªè¿ç»­çš„å¸¦å™ªå£°å›¾åƒçš„ç‰¹å¾åµŒå…¥è¾¾åˆ°é¢„å®šçš„ç›¸ä¼¼æ€§é˜ˆå€¼ï¼Œè¿™è¡¨æ˜äº†ä¸€ç§å¯èƒ½ä¸­å’Œå¯¹æŠ—æ•ˆåº”çš„æ–¹æ³•ã€‚éšåï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹ç¨³å®šçš„å›¾åƒè¿›è¡Œå»å™ªï¼Œæ¢å¤ä¸€ä¸ªé€‚åˆè§†è§‰è¯­è¨€æ¨¡å‹äº§ç”Ÿè¾“å‡ºçš„æ¸…æ´è¡¨ç¤ºã€‚é€šè¿‡å…­ä¸ªæ•°æ®é›†åœ¨ä¸‰ç§ä»»åŠ¡åœºæ™¯ä¸‹çš„å¹¿æ³›å®éªŒï¼Œä½¿ç”¨ä¸‰ç§è§†è§‰è¯­è¨€æ¨¡å‹å¹¶åœ¨ä¸åŒæ”»å‡»å¼ºåº¦ä¸‹è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä»¬è¡¨æ˜DiffCAPåœ¨é˜²å¾¡æŠ€æœ¯æ–¹é¢å§‹ç»ˆæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDiffCAPæ˜¾è‘—é™ä½äº†è¶…å‚æ•°è°ƒæ•´å¤æ‚æ€§å’Œæ‰€éœ€çš„æ‰©æ•£æ—¶é—´ï¼Œä»è€ŒåŠ é€Ÿäº†å»å™ªè¿‡ç¨‹ã€‚å‡­å€Ÿå¼ºå¤§çš„ç†è®ºå’Œå®è¯æ”¯æŒï¼ŒDiffCAPä¸ºåœ¨æ•Œå¯¹ç¯å¢ƒä¸­å®‰å…¨éƒ¨ç½²è§†è§‰è¯­è¨€æ¨¡å‹æä¾›äº†ç¨³å¥å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03933v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºDiffCAPçš„æ–°é¢–æ‰©æ•£å¼å‡€åŒ–ç­–ç•¥ï¼Œèƒ½æœ‰æ•ˆä¸­å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸­çš„å¯¹æŠ—æ€§æ±¡æŸ“ã€‚é€šè¿‡å‘å—æ”»å‡»çš„å›¾åƒæ·»åŠ æœ€å°å™ªå£°ï¼Œæ”¹å˜å…¶æ½œåœ¨åµŒå…¥ï¼ŒDiffCAPç´¯ç§¯åœ°å‘å—å¹²æ‰°çš„è¾“å…¥æ•°æ®æ³¨å…¥éšæœºé«˜æ–¯å™ªå£°ï¼Œç›´åˆ°ä¸¤ä¸ªè¿ç»­å™ªå£°å›¾åƒçš„ç‰¹å¾åµŒå…¥è¾¾åˆ°é¢„å®šçš„ç›¸ä¼¼æ€§é˜ˆå€¼ã€‚éšåï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹ç¨³å®šå›¾åƒè¿›è¡Œå»å™ªå¤„ç†ï¼Œä½¿å…¶æ¢å¤å¹²å‡€çŠ¶æ€ä»¥ä¾›VLMså¤„ç†ã€‚å®éªŒè¯æ˜ï¼ŒDiffCAPåœ¨å¤šç§æ•°æ®é›†å’Œä»»åŠ¡åœºæ™¯ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰é˜²å¾¡æŠ€æœ¯ï¼Œå¤§å¹…é™ä½äº†è¶…å‚æ•°è°ƒæ•´å¤æ‚æ€§å’Œæ‰€éœ€çš„æ‰©æ•£æ—¶é—´ï¼ŒåŠ é€Ÿäº†å»å™ªè¿‡ç¨‹ã€‚è¿™ä¸ºåœ¨æ•Œå¯¹ç¯å¢ƒä¸­å®‰å…¨éƒ¨ç½²VLMsæä¾›äº†ç¨³å¥å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>VLMsåœ¨å¤šåª’ä½“ç†è§£æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶å¯¹å¹²æ‰°çš„æ•æ„Ÿæ€§å¯¹å…¶åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„å¯é æ€§æ„æˆå¨èƒã€‚</li>
<li>DiffCAPæ˜¯ä¸€ç§åŸºäºæ‰©æ•£çš„å‡€åŒ–ç­–ç•¥ï¼Œèƒ½æœ‰æ•ˆä¸­å’ŒVLMsä¸­çš„å¯¹æŠ—æ€§æ±¡æŸ“ã€‚</li>
<li>DiffCAPé€šè¿‡å‘å—æ”»å‡»çš„å›¾åƒæ·»åŠ å™ªå£°æ¥æ”¹å˜å…¶æ½œåœ¨åµŒå…¥ï¼Œç„¶åç´¯ç§¯æ³¨å…¥éšæœºé«˜æ–¯å™ªå£°ï¼Œç›´åˆ°å›¾åƒç¨³å®šã€‚</li>
<li>ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹ç¨³å®šå›¾åƒè¿›è¡Œå»å™ªå¤„ç†ï¼Œæ¢å¤å¹²å‡€çŠ¶æ€ä»¥ä¾›VLMså¤„ç†ã€‚</li>
<li>DiffCAPåœ¨å¤šä¸ªæ•°æ®é›†å’Œä»»åŠ¡åœºæ™¯ä¸‹çš„å®éªŒè¡¨ç°ä¼˜äºç°æœ‰é˜²å¾¡æŠ€æœ¯ã€‚</li>
<li>DiffCAPé™ä½äº†è¶…å‚æ•°è°ƒæ•´å¤æ‚æ€§å’Œæ‰€éœ€çš„æ‰©æ•£æ—¶é—´ï¼ŒåŠ é€Ÿäº†å»å™ªè¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03933">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ab1e7295ff1fdd836a3f542eb1e54317.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4af427612d52d2f49c52350f7d7194e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Facial-Appearance-Capture-at-Home-with-Patch-Level-Reflectance-Prior"><a href="#Facial-Appearance-Capture-at-Home-with-Patch-Level-Reflectance-Prior" class="headerlink" title="Facial Appearance Capture at Home with Patch-Level Reflectance Prior"></a>Facial Appearance Capture at Home with Patch-Level Reflectance Prior</h2><p><strong>Authors:Yuxuan Han, Junfeng Lyu, Kuan Sheng, Minghao Que, Qixuan Zhang, Lan Xu, Feng Xu</strong></p>
<p>Existing facial appearance capture methods can reconstruct plausible facial reflectance from smartphone-recorded videos. However, the reconstruction quality is still far behind the ones based on studio recordings. This paper fills the gap by developing a novel daily-used solution with a co-located smartphone and flashlight video capture setting in a dim room. To enhance the quality, our key observation is to solve facial reflectance maps within the data distribution of studio-scanned ones. Specifically, we first learn a diffusion prior over the Light Stage scans and then steer it to produce the reflectance map that best matches the captured images. We propose to train the diffusion prior at the patch level to improve generalization ability and training stability, as current Light Stage datasets are in ultra-high resolution but limited in data size. Tailored to this prior, we propose a patch-level posterior sampling technique to sample seamless full-resolution reflectance maps from this patch-level diffusion model. Experiments demonstrate our method closes the quality gap between low-cost and studio recordings by a large margin, opening the door for everyday users to clone themselves to the digital world. Our code will be released at <a target="_blank" rel="noopener" href="https://github.com/yxuhan/DoRA">https://github.com/yxuhan/DoRA</a>. </p>
<blockquote>
<p>ç°æœ‰çš„äººè„¸æ•æ‰æ–¹æ³•å¯ä»¥ä»æ™ºèƒ½æ‰‹æœºæ‹æ‘„çš„è§†é¢‘ä¸­é‡å»ºå‡ºåˆç†çš„äººè„¸åå°„ã€‚ç„¶è€Œï¼Œé‡å»ºè´¨é‡ä»ç„¶è¿œè¿œè½åäºåŸºäºå·¥ä½œå®¤å½•åˆ¶çš„æ–¹æ³•ã€‚æœ¬æ–‡å¡«è¡¥äº†è¿™ä¸ªç©ºç™½ï¼Œå¼€å‘äº†ä¸€ç§æ–°å‹çš„æ—¥å¸¸è§£å†³æ–¹æ¡ˆï¼Œé‡‡ç”¨å®šä½æ™ºèƒ½æ‰‹æœºå’Œæ˜æš—æˆ¿é—´ä¸­çš„é—ªå…‰ç¯è§†é¢‘æ•æ‰è®¾ç½®ã€‚ä¸ºäº†æé«˜è´¨é‡ï¼Œæˆ‘ä»¬çš„å…³é”®è§‚å¯Ÿæ˜¯ï¼Œåœ¨å·¥ä½œå®¤æ‰«æçš„åå°„å›¾çš„åˆ†å¸ƒèŒƒå›´å†…è§£å†³é¢éƒ¨åå°„å›¾çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå­¦ä¹ Light Stageæ‰«æçš„æ‰©æ•£å…ˆéªŒçŸ¥è¯†ï¼Œç„¶åå¼•å¯¼å®ƒç”Ÿæˆä¸æ•è·çš„å›¾åƒæœ€åŒ¹é…çš„åå°„å›¾ã€‚æˆ‘ä»¬å»ºè®®åœ¨è¡¥ä¸çº§åˆ«è®­ç»ƒæ‰©æ•£å…ˆéªŒçŸ¥è¯†ï¼Œä»¥æé«˜æ³›åŒ–èƒ½åŠ›å’Œè®­ç»ƒç¨³å®šæ€§ï¼Œå› ä¸ºå½“å‰çš„Light Stageæ•°æ®é›†è™½ç„¶å…·æœ‰è¶…é«˜çš„åˆ†è¾¨ç‡ï¼Œä½†åœ¨æ•°æ®å¤§å°ä¸Šæœ‰é™åˆ¶ã€‚é’ˆå¯¹è¿™ç§å…ˆéªŒçŸ¥è¯†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¡¥ä¸çº§åé‡‡æ ·æŠ€æœ¯ï¼Œå¯ä»¥ä»è¿™ç§è¡¥ä¸çº§æ‰©æ•£æ¨¡å‹ä¸­æ— ç¼é‡‡æ ·å…¨åˆ†è¾¨ç‡åå°„å›¾ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¤§æé«˜äº†ä½æˆæœ¬å’Œå·¥ä½œå®¤å½•åˆ¶ä¹‹é—´çš„è´¨é‡å·®è·ï¼Œä¸ºæ™®é€šç”¨æˆ·æ‰“å¼€äº†å…‹éš†è‡ªå·±åˆ°æ•°å­—ä¸–ç•Œçš„å¤§é—¨ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/yxuhan/DoRA%E4%B8%AD%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/yxuhan/DoRAä¸­å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03478v1">PDF</a> ACM Transactions on Graphics (Proc. of SIGGRAPH), 2025. Code:   <a target="_blank" rel="noopener" href="https://github.com/yxuhan/DoRA">https://github.com/yxuhan/DoRA</a>; Project Page: <a target="_blank" rel="noopener" href="https://yxuhan.github.io/DoRA">https://yxuhan.github.io/DoRA</a></p>
<p><strong>Summary</strong><br>     ç°æœ‰é¢éƒ¨æ•æ‰æ–¹æ³•å¯ä»æ™ºèƒ½æ‰‹æœºè§†é¢‘é‡å»ºé¢éƒ¨åå°„ï¼Œä½†è´¨é‡ä»è½åäºåŸºäºå·¥ä½œå®¤å½•åˆ¶çš„æ–¹æ¡ˆã€‚æœ¬æ–‡å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæå‡ºä¸€ç§æ—¥å¸¸ä½¿ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œé‡‡ç”¨æ™ºèƒ½æ‰‹æœºä¸é—ªå…‰ç¯è§†é¢‘æ•æ‰è®¾ç½®ï¼Œåœ¨æš—å®¤ä¸­è¿›è¡Œã€‚ä¸ºæé«˜è´¨é‡ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è§£å†³é¢éƒ¨åå°„æ˜ å°„éœ€è¦åœ¨å·¥ä½œå®¤æ‰«æçš„æ•°æ®åˆ†å¸ƒå†…ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆå­¦ä¹ Light Stageæ‰«æçš„å…‰æ‰©æ•£å…ˆéªŒçŸ¥è¯†ï¼Œç„¶åå°†å…¶å¼•å¯¼ç”Ÿæˆä¸æ•è·å›¾åƒæœ€åŒ¹é…çš„åå°„æ˜ å°„å›¾ã€‚æˆ‘ä»¬æå‡ºåœ¨è¡¥ä¸çº§åˆ«è®­ç»ƒæ‰©æ•£å…ˆéªŒçŸ¥è¯†ä»¥æé«˜é€šç”¨æ€§å’Œè®­ç»ƒç¨³å®šæ€§ï¼Œå› ä¸ºå½“å‰Light Stageæ•°æ®é›†è¶…é«˜åˆ†è¾¨ç‡ä½†æ•°æ®é‡æœ‰é™ã€‚é’ˆå¯¹æ­¤å…ˆéªŒçŸ¥è¯†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¡¥ä¸çº§åé‡‡æ ·æŠ€æœ¯ï¼Œå¯ä»è¯¥è¡¥ä¸çº§æ‰©æ•£æ¨¡å‹ä¸­æ— ç¼é‡‡æ ·å…¨åˆ†è¾¨ç‡åå°„æ˜ å°„å›¾ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¹…ç¼©å°äº†ä½æˆæœ¬ä¸å·¥ä½œå®¤å½•åˆ¶ä¹‹é—´çš„å·®è·ï¼Œä¸ºæ™®é€šç”¨æˆ·å…‹éš†è‡ªå·±è¿›å…¥æ•°å­—ä¸–ç•Œæ‰“å¼€äº†å¤§é—¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰é¢éƒ¨æ•æ‰æ–¹æ³•è™½èƒ½ä»æ™ºèƒ½æ‰‹æœºè§†é¢‘é‡å»ºé¢éƒ¨åå°„ï¼Œä½†è´¨é‡ä½äºå·¥ä½œå®¤å½•åˆ¶ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹è§£å†³æ–¹æ¡ˆï¼Œé‡‡ç”¨æ™ºèƒ½æ‰‹æœºä¸é—ªå…‰ç¯è§†é¢‘æ•æ‰åœ¨æš—å®¤ä¸­è¿›è¡Œï¼Œæ—¨åœ¨æé«˜è´¨é‡ã€‚</li>
<li>é€šè¿‡å­¦ä¹ Light Stageæ‰«æçš„å…‰æ‰©æ•£å…ˆéªŒçŸ¥è¯†æ¥è§£å†³é¢éƒ¨åå°„æ˜ å°„é—®é¢˜ã€‚</li>
<li>åœ¨è¡¥ä¸çº§åˆ«è®­ç»ƒæ‰©æ•£æ¨¡å‹ä»¥æé«˜é€šç”¨æ€§å’Œè®­ç»ƒç¨³å®šæ€§ï¼Œåº”å¯¹å½“å‰æ•°æ®é›†åˆ†è¾¨ç‡é«˜ä½†æ•°æ®é‡æœ‰é™çš„é—®é¢˜ã€‚</li>
<li>æå‡ºè¡¥ä¸çº§åé‡‡æ ·æŠ€æœ¯ï¼Œç”Ÿæˆæ— ç¼å…¨åˆ†è¾¨ç‡åå°„æ˜ å°„å›¾ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•æ˜¾è‘—ç¼©å°äº†ä½æˆæœ¬ä¸å·¥ä½œå®¤å½•åˆ¶ä¹‹é—´çš„å·®è·ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ºç”¨æˆ·å°†å…¶è‡ªèº«å…‹éš†åˆ°æ•°å­—ä¸–ç•Œæä¾›äº†å¯èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03478">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6e5dc102e5a43f68f09205f542bb3a18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f6bf205e7a3fb0824cc40c44bfc951f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44bf5e8623c7ff07e9bd0ac29f25540f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Generalized-Diffusion-Detector-Mining-Robust-Features-from-Diffusion-Models-for-Domain-Generalized-Detection"><a href="#Generalized-Diffusion-Detector-Mining-Robust-Features-from-Diffusion-Models-for-Domain-Generalized-Detection" class="headerlink" title="Generalized Diffusion Detector: Mining Robust Features from Diffusion   Models for Domain-Generalized Detection"></a>Generalized Diffusion Detector: Mining Robust Features from Diffusion   Models for Domain-Generalized Detection</h2><p><strong>Authors:Boyong He, Yuxiang Ji, Qianwen Ye, Zhuoyue Tan, Liaoni Wu</strong></p>
<p>Domain generalization (DG) for object detection aims to enhance detectorsâ€™ performance in unseen scenarios. This task remains challenging due to complex variations in real-world applications. Recently, diffusion models have demonstrated remarkable capabilities in diverse scene generation, which inspires us to explore their potential for improving DG tasks. Instead of generating images, our method extracts multi-step intermediate features during the diffusion process to obtain domain-invariant features for generalized detection. Furthermore, we propose an efficient knowledge transfer framework that enables detectors to inherit the generalization capabilities of diffusion models through feature and object-level alignment, without increasing inference time. We conduct extensive experiments on six challenging DG benchmarks. The results demonstrate that our method achieves substantial improvements of 14.0% mAP over existing DG approaches across different domains and corruption types. Notably, our method even outperforms most domain adaptation methods without accessing any target domain data. Moreover, the diffusion-guided detectors show consistent improvements of 15.9% mAP on average compared to the baseline. Our work aims to present an effective approach for domain-generalized detection and provide potential insights for robust visual recognition in real-world scenarios. The code is available at <a target="_blank" rel="noopener" href="https://github.com/heboyong/Generalized-Diffusion-Detector">https://github.com/heboyong/Generalized-Diffusion-Detector</a>. </p>
<blockquote>
<p>ç›®æ ‡æ£€æµ‹é¢†åŸŸçš„åŸŸæ³›åŒ–ï¼ˆDGï¼‰æ—¨åœ¨æé«˜æ£€æµ‹å™¨åœ¨æœªè§è¿‡åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚ç”±äºç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„å¤æ‚å˜åŒ–ï¼Œè¿™ä¸€ä»»åŠ¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹åœ¨åœºæ™¯ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œè¿™æ¿€å‘äº†æˆ‘ä»¬åœ¨DGä»»åŠ¡ä¸­æ¢ç´¢å…¶æ½œåŠ›çš„æƒ³æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æ˜¯ç”Ÿæˆå›¾åƒï¼Œè€Œæ˜¯åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­æå–å¤šæ­¥ä¸­é—´ç‰¹å¾ï¼Œä»¥è·å¾—ç”¨äºå¹¿ä¹‰æ£€æµ‹çš„åŸŸä¸å˜ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„çŸ¥è¯†è½¬ç§»æ¡†æ¶ï¼Œä½¿æ£€æµ‹å™¨èƒ½å¤Ÿé€šè¿‡ç‰¹å¾å’Œå¯¹è±¡çº§çš„å¯¹é½ï¼Œç»§æ‰¿æ‰©æ•£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€Œæ— éœ€å¢åŠ æ¨ç†æ—¶é—´ã€‚æˆ‘ä»¬åœ¨å…­ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„DGåŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è·¨ä¸åŒé¢†åŸŸå’Œè…è´¥ç±»å‹çš„æƒ…å†µä¸‹ï¼Œè¾ƒç°æœ‰çš„DGæ–¹æ³•æé«˜äº†æ˜¾è‘—çš„14.0%çš„mAPã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”šè‡³åœ¨æ²¡æœ‰è®¿é—®ä»»ä½•ç›®æ ‡åŸŸæ•°æ®çš„æƒ…å†µä¸‹è¶…è¿‡äº†å¤§å¤šæ•°åŸŸè‡ªé€‚åº”æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œæ‰©æ•£å¼•å¯¼çš„æ£€æµ‹å™¨çš„å¹³å‡mAPæé«˜äº†ç¨³å®šçš„15.9%ã€‚æˆ‘ä»¬çš„å·¥ä½œæ—¨åœ¨æä¾›ä¸€ç§æœ‰æ•ˆçš„åŸŸæ³›åŒ–æ£€æµ‹æ–¹æ³•å’Œä¸ºçœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„ç¨³å¥è§†è§‰è¯†åˆ«æä¾›æ½œåœ¨è§è§£ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/heboyong/Generalized-Diffusion-Detector%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/heboyong/Generalized-Diffusion-Detectoræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02101v2">PDF</a> CVPR2025 camera-ready version with supplementary material</p>
<p><strong>Summary</strong><br>     åŸºäºæ‰©æ•£æ¨¡å‹çš„é¢†åŸŸæ³›åŒ–ï¼ˆDGï¼‰æ–¹æ³•è¢«åº”ç”¨äºç›®æ ‡æ£€æµ‹ï¼Œä»¥æé«˜åœ¨æœªè§è¿‡åœºæ™¯ä¸­çš„æ£€æµ‹æ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡æå–æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¤šæ­¥ä¸­é—´ç‰¹å¾æ¥è·å¾—é¢†åŸŸä¸å˜ç‰¹å¾ï¼Œå¹¶æå‡ºä¸€ç§æœ‰æ•ˆçš„çŸ¥è¯†è¿ç§»æ¡†æ¶ï¼Œä½¿æ£€æµ‹å™¨èƒ½å¤Ÿé€šè¿‡ç‰¹å¾å’Œå¯¹è±¡çº§åˆ«çš„å¯¹é½ï¼Œç»§æ‰¿æ‰©æ•£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸”ä¸ä¼šå¢åŠ æ¨ç†æ—¶é—´ã€‚åœ¨å…­ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„DGåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•è¾ƒç°æœ‰DGæ–¹æ³•å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å³ä½¿ä¸è®¿é—®ä»»ä½•ç›®æ ‡åŸŸæ•°æ®ï¼Œè¯¥æ–¹æ³•ä¹Ÿæ¯”å¤§å¤šæ•°åŸŸè‡ªé€‚åº”æ–¹æ³•è¡¨ç°æ›´å‡ºè‰²ã€‚æ­¤å¤–ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œæ‰©æ•£å¼•å¯¼çš„æ£€æµ‹å™¨å¹³å‡æé«˜äº†15.9%çš„mAPã€‚æ­¤å·¥ä½œæ—¨åœ¨ä¸ºé¢†åŸŸæ³›åŒ–æ£€æµ‹æä¾›ä¸€ç§æœ‰æ•ˆæ–¹æ³•ï¼Œå¹¶ä¸ºçœŸå®åœºæ™¯ä¸­çš„ç¨³å¥è§†è§‰è¯†åˆ«æä¾›æ½œåœ¨å¯ç¤ºã€‚ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹è¢«æ¢ç´¢åº”ç”¨äºé¢†åŸŸæ³›åŒ–ï¼ˆDGï¼‰ä»»åŠ¡ï¼Œæ—¨åœ¨æé«˜ç›®æ ‡æ£€æµ‹åœ¨æœªè§åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚</li>
<li>é€šè¿‡æå–æ‰©æ•£è¿‡ç¨‹ä¸­çš„ä¸­é—´ç‰¹å¾æ¥è·å¾—é¢†åŸŸä¸å˜ç‰¹å¾ã€‚</li>
<li>æå‡ºä¸€ç§çŸ¥è¯†è¿ç§»æ¡†æ¶ï¼Œä½¿æ£€æµ‹å™¨èƒ½å¤Ÿç»§æ‰¿æ‰©æ•£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸”ä¸å½±å“æ¨ç†æ—¶é—´ã€‚</li>
<li>åœ¨å¤šä¸ªDGåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¾ƒç°æœ‰æ–¹æ³•æé«˜14.0% mAPã€‚</li>
<li>æ— éœ€è®¿é—®ç›®æ ‡åŸŸæ•°æ®å³å¯è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œä¼˜äºå¤šæ•°åŸŸè‡ªé€‚åº”æ–¹æ³•ã€‚</li>
<li>æ‰©æ•£å¼•å¯¼çš„æ£€æµ‹å™¨ä¸åŸºçº¿ç›¸æ¯”å¹³å‡æé«˜äº†15.9%çš„mAPã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-28654c8baee6e66434c4b2dcf610eeb5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-147f4172615ca3b78a423e27f9729e1e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-18446421d66621980554478005971aac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-250b33af38d8b2448f5342a92bbb6ec6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d9fca7cdf09e8bcb308ac1dfbbfa5b85.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="VCT-Training-Consistency-Models-with-Variational-Noise-Coupling"><a href="#VCT-Training-Consistency-Models-with-Variational-Noise-Coupling" class="headerlink" title="VCT: Training Consistency Models with Variational Noise Coupling"></a>VCT: Training Consistency Models with Variational Noise Coupling</h2><p><strong>Authors:Gianluigi Silvestri, Luca Ambrogioni, Chieh-Hsin Lai, Yuhta Takida, Yuki Mitsufuji</strong></p>
<p>Consistency Training (CT) has recently emerged as a strong alternative to diffusion models for image generation. However, non-distillation CT often suffers from high variance and instability, motivating ongoing research into its training dynamics. We propose Variational Consistency Training (VCT), a flexible and effective framework compatible with various forward kernels, including those in flow matching. Its key innovation is a learned noise-data coupling scheme inspired by Variational Autoencoders, where a data-dependent encoder models noise emission. This enables VCT to adaptively learn noise-todata pairings, reducing training variance relative to the fixed, unsorted pairings in classical CT. Experiments on multiple image datasets demonstrate significant improvements: our method surpasses baselines, achieves state-of-the-art FID among non-distillation CT approaches on CIFAR-10, and matches SoTA performance on ImageNet 64 x 64 with only two sampling steps. Code is available at <a target="_blank" rel="noopener" href="https://github.com/sony/vct">https://github.com/sony/vct</a>. </p>
<blockquote>
<p>ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰æœ€è¿‘ä½œä¸ºå›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹çš„å¼ºå¤§æ›¿ä»£æ–¹æ¡ˆè€Œå‡ºç°ã€‚ç„¶è€Œï¼Œéè’¸é¦CTç»å¸¸é­å—é«˜æ–¹å·®å’Œä¸ç¨³å®šæ€§çš„å›°æ‰°ï¼Œè¿™ä¿ƒä½¿äººä»¬å¯¹å…¶è®­ç»ƒåŠ¨æ€è¿›è¡ŒæŒç»­ç ”ç©¶ã€‚æˆ‘ä»¬æå‡ºäº†å˜åˆ†ä¸€è‡´æ€§è®­ç»ƒï¼ˆVCTï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªçµæ´»æœ‰æ•ˆçš„æ¡†æ¶ï¼Œå¯ä¸å„ç§å‰å‘å†…æ ¸å…¼å®¹ï¼ŒåŒ…æ‹¬æµåŒ¹é…ä¸­çš„å†…æ ¸ã€‚å…¶å…³é”®åˆ›æ–°åœ¨äºå—åˆ°å˜åˆ†è‡ªç¼–ç å™¨çš„å¯å‘è€Œè®¾è®¡çš„ä¸€ç§å­¦ä¹ å™ªå£°æ•°æ®è€¦åˆæ–¹æ¡ˆï¼Œå…¶ä¸­æ•°æ®ä¾èµ–çš„ç¼–ç å™¨å¯¹å™ªå£°æ’æ”¾è¿›è¡Œå»ºæ¨¡ã€‚è¿™ä½¿å¾—VCTèƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ å™ªå£°åˆ°æ•°æ®çš„é…å¯¹ï¼Œç›¸å¯¹äºç»å…¸CTä¸­çš„å›ºå®šä¸”æœªæ’åºçš„é…å¯¹ï¼Œé™ä½äº†è®­ç»ƒæ–¹å·®ã€‚åœ¨å¤šä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æ˜¾è‘—çš„æ”¹è¿›ï¼šæˆ‘ä»¬çš„æ–¹æ³•è¶…è¶Šäº†åŸºçº¿ï¼Œåœ¨CIFAR-10ä¸Šåœ¨éè’¸é¦CTæ–¹æ³•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„FIDï¼Œå¹¶åœ¨ä»…æœ‰ä¸¤æ¬¡é‡‡æ ·æ­¥éª¤çš„ImageNet 64 x 64ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„è¡¨ç°ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sony/vct%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sony/vctæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18197v2">PDF</a> 23 pages, 11 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºå˜åˆ†ä¸€è‡´æ€§è®­ç»ƒï¼ˆVCTï¼‰çš„æ–°æ–¹æ³•ï¼Œå®ƒæ˜¯ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œç”¨äºå›¾åƒç”Ÿæˆã€‚VCTé‡‡ç”¨çµæ´»çš„æ¡†æ¶ï¼Œå…¼å®¹å„ç§å‰å‘æ ¸ï¼ŒåŒ…æ‹¬æµåŒ¹é…ã€‚å…¶å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†åŸºäºå˜åˆ†è‡ªç¼–ç å™¨çš„å™ªå£°æ•°æ®è€¦åˆæ–¹æ¡ˆï¼Œä½¿VCTèƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ å™ªå£°ä¸æ•°æ®çš„é…å¯¹ï¼Œä»è€Œé™ä½äº†è®­ç»ƒæ–¹å·®ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼Œè¶…è¿‡äº†åŸºçº¿æ–¹æ³•ï¼Œå¹¶åœ¨CIFAR-10ä¸Šè¾¾åˆ°äº†éè’¸é¦ä¸€è‡´æ€§è®­ç»ƒçš„æœ€ä½³FIDå¾—åˆ†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å˜åˆ†ä¸€è‡´æ€§è®­ç»ƒï¼ˆVCTï¼‰æ˜¯ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œä¸“é—¨ç”¨äºå›¾åƒç”Ÿæˆã€‚</li>
<li>VCTå¼•å…¥äº†ä¸€ç§åŸºäºå˜åˆ†è‡ªç¼–ç å™¨çš„å™ªå£°æ•°æ®è€¦åˆæ–¹æ¡ˆï¼Œè¿™æ˜¯å…¶å…³é”®åˆ›æ–°ã€‚</li>
<li>è¯¥æ–¹æ¡ˆä½¿VCTèƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ å™ªå£°ä¸æ•°æ®çš„é…å¯¹ï¼Œé™ä½è®­ç»ƒæ–¹å·®ã€‚</li>
<li>VCTå…¼å®¹å„ç§å‰å‘æ ¸ï¼ŒåŒ…æ‹¬æµåŒ¹é…ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒVCTåœ¨å¤šä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ€§èƒ½æ”¹è¿›ï¼Œè¶…è¿‡äº†åŸºçº¿æ–¹æ³•ã€‚</li>
<li>VCTåœ¨CIFAR-10æ•°æ®é›†ä¸Šè¾¾åˆ°äº†éè’¸é¦ä¸€è‡´æ€§è®­ç»ƒçš„æœ€ä½³FIDå¾—åˆ†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18197">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e54f70302875475ef264d8c22ad6a8a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bcb7ee303bd3489e19af35c3bdf82bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f24e7c19c5820715af2afb4c79b2f0b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Diffusing-DeBias-Synthetic-Bias-Amplification-for-Model-Debiasing"><a href="#Diffusing-DeBias-Synthetic-Bias-Amplification-for-Model-Debiasing" class="headerlink" title="Diffusing DeBias: Synthetic Bias Amplification for Model Debiasing"></a>Diffusing DeBias: Synthetic Bias Amplification for Model Debiasing</h2><p><strong>Authors:Massimiliano Ciranni, Vito Paolo Pastore, Roberto Di Via, Enzo Tartaglione, Francesca Odone, Vittorio Murino</strong></p>
<p>Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data whenever they are affected by strong spurious correlations between specific attributes and target labels. This results in a form of bias affecting training data, which typically leads to unrecoverable weak generalization in prediction. This paper aims at facing this problem by leveraging bias amplification with generated synthetic data: we introduce Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods of unsupervised model debiasing exploiting the inherent bias-learning tendency of diffusion models in data generation. Specifically, our approach adopts conditional diffusion models to generate synthetic bias-aligned images, which replace the original training set for learning an effective bias amplifier model that we subsequently incorporate into an end-to-end and a two-step unsupervised debiasing approach. By tackling the fundamental issue of bias-conflicting training samples memorization in learning auxiliary models, typical of this type of techniques, our proposed method beats current state-of-the-art in multiple benchmark datasets, demonstrating its potential as a versatile and effective tool for tackling bias in deep learning models. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å¸¸å¸¸å—åˆ°è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œæ•°é‡çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šå±æ€§ä¸ç›®æ ‡æ ‡ç­¾ä¹‹é—´å­˜åœ¨å¼ºçƒˆè™šå‡å…³è”æ—¶ã€‚è¿™å¯¼è‡´äº†ä¸€ç§å½±å“è®­ç»ƒæ•°æ®çš„åè§ï¼Œé€šå¸¸ä¼šå¯¼è‡´é¢„æµ‹ä¸­ä¸å¯æŒ½å›çš„å¼±æ³›åŒ–ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œåˆ©ç”¨ç”Ÿæˆåˆæˆæ•°æ®çš„åè§æ”¾å¤§æ¥è§£å†³ï¼šæˆ‘ä»¬å¼•å…¥äº†Diffusing DeBiasï¼ˆDDBï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œä½œä¸ºå¯¹å¸¸è§æ— ç›‘ç£æ¨¡å‹å»åç½®æ–¹æ³•çš„æ’ä»¶ï¼Œåˆ©ç”¨æ•°æ®ç”Ÿæˆä¸­æ‰©æ•£æ¨¡å‹å›ºæœ‰çš„åè§å­¦ä¹ å€¾å‘ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆåè§å¯¹é½å›¾åƒï¼Œè¿™äº›å›¾åƒæ›¿ä»£åŸå§‹è®­ç»ƒé›†ï¼Œç”¨äºå­¦ä¹ æœ‰æ•ˆçš„åè§æ”¾å¤§æ¨¡å‹ï¼Œéšåæˆ‘ä»¬å°†å…¶çº³å…¥ç«¯åˆ°ç«¯å’Œä¸¤æ­¥æ— ç›‘ç£å»åç½®æ–¹æ³•ä¸­ã€‚é€šè¿‡è§£å†³å­¦ä¹ è¾…åŠ©æ¨¡å‹ä¸­åè§å†²çªè®­ç»ƒæ ·æœ¬è®°å¿†çš„æ ¹æœ¬é—®é¢˜ï¼Œè¿™æ˜¯æ­¤ç±»æŠ€æœ¯çš„ä¸€ä¸ªå…¸å‹ç‰¹å¾ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¶…è¿‡äº†å½“å‰æœ€ä½³æ°´å¹³ï¼Œè¯æ˜äº†å…¶ä½œä¸ºè§£å†³æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­åè§é—®é¢˜çš„é€šç”¨å’Œæœ‰æ•ˆå·¥å…·çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.09564v4">PDF</a> 18 Pages, 9 Figures</p>
<p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å¸¸å—è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œæ•°é‡çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯å½“è¿™äº›æ•°æ®ä¸­å­˜åœ¨ç‰¹å®šå±æ€§å’Œç›®æ ‡æ ‡ç­¾ä¹‹é—´çš„å¼ºçƒˆå¶ç„¶æ€§å…³è”æ—¶ã€‚è¿™ç§æƒ…å†µä¼šå¯¼è‡´è®­ç»ƒæ•°æ®äº§ç”Ÿåè§ï¼Œé€šå¸¸ä¼šå¯¼è‡´é¢„æµ‹ä¸­çš„ä¸å¯æ¢å¤çš„å¼±æ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡åˆ©ç”¨ç”Ÿæˆçš„åˆæˆæ•°æ®æ”¾å¤§åè§æ¥åº”å¯¹è¿™ä¸€é—®é¢˜ï¼šæˆ‘ä»¬å¼•å…¥äº†Diffusing DeBiasï¼ˆDDBï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œå¯ä½œä¸ºé€šç”¨æ— ç›‘ç£æ¨¡å‹å»åæ–¹æ³•çš„æ’ä»¶ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆåè§å¯¹é½å›¾åƒï¼Œè¿™äº›å›¾åƒä¼šæ›¿ä»£åŸå§‹è®­ç»ƒé›†æ¥å­¦ä¹ æœ‰æ•ˆçš„åè§æ”¾å¤§æ¨¡å‹ï¼Œéšåæˆ‘ä»¬å°†å…¶çº³å…¥ç«¯åˆ°ç«¯å’Œä¸¤æ­¥æ— ç›‘ç£å»åæ–¹æ³•ã€‚é€šè¿‡è§£å†³è¾…åŠ©æ¨¡å‹å­¦ä¹ ä¸­å­˜åœ¨çš„åè§å†²çªè®­ç»ƒæ ·æœ¬è®°å¿†é—®é¢˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºå½“å‰çš„æœ€ä½³æ–¹æ³•ï¼Œè¡¨æ˜å…¶åœ¨æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸­ä½œä¸ºé€šç”¨å’Œæœ‰æ•ˆå·¥å…·è§£å†³åè§é—®é¢˜çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨åˆ†ç±»ä»»åŠ¡ä¸­é¢ä¸´ç”±è®­ç»ƒæ•°æ®çš„åè§å¯¼è‡´çš„é—®é¢˜ã€‚</li>
<li>å¼ºçƒˆçš„å¶ç„¶æ€§å…³è”ä¼šå½±å“è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œæ•°é‡ã€‚</li>
<li>ç°æœ‰æŠ€æœ¯ä¸­å­˜åœ¨åè§å†²çªè®­ç»ƒæ ·æœ¬è®°å¿†é—®é¢˜ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•Diffusing DeBiasï¼ˆDDBï¼‰ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>DDBåˆ©ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆåè§å¯¹é½å›¾åƒæ¥æ›¿ä»£åŸå§‹è®­ç»ƒé›†ã€‚</li>
<li>DDBå¯ä»¥çº³å…¥ç«¯åˆ°ç«¯å’Œä¸¤æ­¥æ— ç›‘ç£å»åæ–¹æ³•ä¸­ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.09564">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3585947a03016df5900b771a56f00ee7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b15415704f30c46406a4917cc1dad33f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-933c567d8dcfbdba004f7c3d209f2fb9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-06/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-06/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-06/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-67c51184135a005d25430a4dfa01f5e0.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-06  A Novel Data Augmentation Approach for Automatic Speaking Assessment on   Opinion Expressions
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-06/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-d5d7858763222744160cf971cece3026.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-06  Pseudo-Simulation for Autonomous Driving
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23667.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
