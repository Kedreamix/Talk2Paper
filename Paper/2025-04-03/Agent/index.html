<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-03  Review, Refine, Repeat Understanding Iterative Decoding of AI Agents   with Dynamic Evaluation and Selection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-7550e694fa69b58b370453beee565178.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    71 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-03-æ›´æ–°"><a href="#2025-04-03-æ›´æ–°" class="headerlink" title="2025-04-03 æ›´æ–°"></a>2025-04-03 æ›´æ–°</h1><h2 id="Review-Refine-Repeat-Understanding-Iterative-Decoding-of-AI-Agents-with-Dynamic-Evaluation-and-Selection"><a href="#Review-Refine-Repeat-Understanding-Iterative-Decoding-of-AI-Agents-with-Dynamic-Evaluation-and-Selection" class="headerlink" title="Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents   with Dynamic Evaluation and Selection"></a>Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents   with Dynamic Evaluation and Selection</h2><p><strong>Authors:Souradip Chakraborty, Mohammadreza Pourreza, Ruoxi Sun, Yiwen Song, Nino Scherrer, Jindong Gu, Furong Huang, Amrit Singh Bedi, Ahmad Beirami, Hamid Palangi, Tomas Pfister</strong></p>
<p>While AI agents have shown remarkable performance at various tasks, they still struggle with complex multi-modal applications, structured generation and strategic planning. Improvements via standard fine-tuning is often impractical, as solving agentic tasks usually relies on black box API access without control over model parameters. Inference-time methods such as Best-of-N (BON) sampling offer a simple yet effective alternative to improve performance. However, BON lacks iterative feedback integration mechanism. Hence, we propose Iterative Agent Decoding (IAD) which combines iterative refinement with dynamic candidate evaluation and selection guided by a verifier. IAD differs in how feedback is designed and integrated, specifically optimized to extract maximal signal from reward scores. We conduct a detailed comparison of baselines across key metrics on Sketch2Code, Text2SQL, and Webshop where IAD consistently outperforms baselines, achieving 3â€“6% absolute gains on Sketch2Code and Text2SQL (with and without LLM judges) and 8â€“10% gains on Webshop across multiple metrics. To better understand the source of IADâ€™s gains, we perform controlled experiments to disentangle the effect of adaptive feedback from stochastic sampling, and find that IADâ€™s improvements are primarily driven by verifier-guided refinement, not merely sampling diversity. We also show that both IAD and BON exhibit inference-time scaling with increased compute when guided by an optimal verifier. Our analysis highlights the critical role of verifier quality in effective inference-time optimization and examines the impact of noisy and sparse rewards on scaling behavior. Together, these findings offer key insights into the trade-offs and principles of effective inference-time optimization. </p>
<blockquote>
<p>å°½ç®¡äººå·¥æ™ºèƒ½ä»£ç†äººåœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½ï¼Œä½†åœ¨å¤æ‚çš„å¤šæ¨¡å¼åº”ç”¨ã€ç»“æ„åŒ–ç”Ÿæˆå’Œæˆ˜ç•¥è§„åˆ’æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚é€šè¿‡æ ‡å‡†å¾®è°ƒè¿›è¡Œæ”¹è¿›é€šå¸¸ä¸åˆ‡å®é™…ï¼Œå› ä¸ºè§£å†³ä»£ç†ä»»åŠ¡é€šå¸¸ä¾èµ–äºé»‘ç®±APIè®¿é—®ï¼Œæ— æ³•æ§åˆ¶æ¨¡å‹å‚æ•°ã€‚åƒBest-of-Nï¼ˆBONï¼‰é‡‡æ ·è¿™æ ·çš„æ¨ç†æ—¶é—´æ–¹æ³•æä¾›äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆæ¥æé«˜æ€§èƒ½ã€‚ç„¶è€Œï¼ŒBONç¼ºä¹è¿­ä»£åé¦ˆæ•´åˆæœºåˆ¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†è¿­ä»£ä»£ç†è§£ç ï¼ˆIADï¼‰ï¼Œå®ƒå°†è¿­ä»£ç»†åŒ–ä¸åŠ¨æ€å€™é€‰è¯„ä¼°ç›¸ç»“åˆï¼Œå¹¶ç”±éªŒè¯å™¨è¿›è¡Œå¼•å¯¼é€‰æ‹©ã€‚IADåœ¨åé¦ˆçš„è®¾è®¡ä¸æ•´åˆæ–¹é¢æœ‰æ‰€ä¸åŒï¼Œä¸“é—¨è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ä»å¥–åŠ±åˆ†æ•°ä¸­æå–æœ€å¤§ä¿¡å·ã€‚æˆ‘ä»¬åœ¨Sketch2Codeã€Text2SQLå’ŒWebshopç­‰å…³é”®æŒ‡æ ‡ä¸Šå¯¹åŸºçº¿è¿›è¡Œäº†è¯¦ç»†æ¯”è¾ƒï¼ŒIADå§‹ç»ˆä¼˜äºåŸºçº¿ï¼Œåœ¨Sketch2Codeå’ŒText2SQLä¸Šå®ç°äº†3-6%çš„ç»å¯¹å¢ç›Šï¼ˆæœ‰å’Œæ²¡æœ‰LLMæ³•å®˜ï¼‰ï¼Œåœ¨Webshopä¸Šå®ç°äº†å¤šä¸ªæŒ‡æ ‡ä¸Šçš„8-10%çš„å¢ç›Šã€‚ä¸ºäº†æ›´å¥½åœ°äº†è§£IADå¢ç›Šçš„æ¥æºï¼Œæˆ‘ä»¬è¿›è¡Œäº†å—æ§å®éªŒï¼Œä»¥åŒºåˆ†è‡ªé€‚åº”åé¦ˆä¸éšæœºé‡‡æ ·çš„å½±å“ï¼Œå¹¶å‘ç°IADçš„æ”¹è¿›ä¸»è¦æ˜¯ç”±éªŒè¯å™¨å¼•å¯¼çš„ç»†åŒ–é©±åŠ¨çš„ï¼Œè€Œä¸ä»…ä»…æ˜¯é‡‡æ ·çš„å¤šæ ·æ€§ã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œå½“åœ¨æœ€ä½³éªŒè¯å™¨çš„æŒ‡å¯¼ä¸‹æ—¶ï¼ŒIADå’ŒBONéƒ½è¡¨ç°å‡ºéšç€è®¡ç®—å¢åŠ è€Œæ¨ç†æ—¶é—´æ‰©å±•çš„ç‰¹ç‚¹ã€‚æˆ‘ä»¬çš„åˆ†æå¼ºè°ƒäº†éªŒè¯å™¨è´¨é‡åœ¨æœ‰æ•ˆæ¨ç†æ—¶é—´ä¼˜åŒ–ä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶ç ”ç©¶äº†å˜ˆæ‚å’Œç¨€ç–å¥–åŠ±å¯¹æ‰©å±•è¡Œä¸ºçš„å½±å“ã€‚è¿™äº›å‘ç°å…±åŒæä¾›äº†å…³äºæœ‰æ•ˆæ¨ç†æ—¶é—´ä¼˜åŒ–çš„æƒè¡¡å’ŒåŸåˆ™çš„å…³é”®è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01931v1">PDF</a> </p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½ä»£ç†åœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†åœ¨å¤æ‚å¤šæ¨¡å¼åº”ç”¨ã€ç»“æ„åŒ–ç”Ÿæˆå’Œæˆ˜ç•¥è§„åˆ’æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚æ ‡å‡†å¾®è°ƒæ”¹å–„æ–¹æ³•é€šå¸¸ä¸å®ç”¨ï¼Œå› ä¸ºè§£å†³ä»£ç†ä»»åŠ¡é€šå¸¸ä¾èµ–äºæ— æ³•æ§åˆ¶æ¨¡å‹å‚æ•°çš„é»‘ç®±APIè®¿é—®ã€‚é‡‡ç”¨è¿­ä»£å¼è§£ç ï¼ˆIADï¼‰ç»“åˆè¿­ä»£ä¼˜åŒ–ã€åŠ¨æ€å€™é€‰è¯„ä¼°ä¸éªŒè¯å™¨æŒ‡å¯¼ï¼Œæœ‰æ•ˆæ”¹å–„æ€§èƒ½ã€‚åœ¨Sketch2Codeã€Text2SQLå’ŒWebshopç­‰å…³é”®æŒ‡æ ‡ä¸Šè¿›è¡ŒåŸºçº¿è¯¦ç»†æ¯”è¾ƒï¼ŒIADæŒç»­è¶…è¶ŠåŸºçº¿ï¼Œåœ¨Sketch2Codeå’ŒText2SQLä¸Šå®ç°3-6%çš„ç»å¯¹å¢é•¿ï¼Œåœ¨Webshopä¸Šå®ç°8-10%çš„å¢é•¿ã€‚ä¸»è¦æ”¶ç›ŠæºäºéªŒè¯å™¨æŒ‡å¯¼çš„æ”¹è¿›ï¼Œè€Œéä»…é‡‡æ ·å¤šæ ·æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIä»£ç†åœ¨å¤æ‚å¤šä»»åŠ¡åº”ç”¨ä¸­å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶åœ¨å¤šæ¨¡å¼åº”ç”¨ã€ç»“æ„åŒ–ç”Ÿæˆå’Œæˆ˜ç•¥è§„åˆ’æ–¹é¢ã€‚</li>
<li>æ ‡å‡†å¾®è°ƒæ–¹æ³•å¯¹äºè§£å†³è¿™äº›é—®é¢˜é€šå¸¸ä¸å®ç”¨ï¼Œå› ä¸ºè§£å†³ä»£ç†ä»»åŠ¡ä¾èµ–äºæ— æ³•æ§åˆ¶æ¨¡å‹å‚æ•°çš„é»‘ç®±APIè®¿é—®ã€‚</li>
<li>Best-of-N (BON)é‡‡æ ·ä½œä¸ºä¸€ç§æ¨ç†æ—¶é—´æ–¹æ³•æä¾›äº†ç®€å•è€Œæœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆæ¥æ”¹å–„æ€§èƒ½ã€‚</li>
<li>è¿­ä»£å¼è§£ç ï¼ˆIADï¼‰ç»“åˆäº†è¿­ä»£ä¼˜åŒ–ã€åŠ¨æ€å€™é€‰è¯„ä¼°ä¸éªŒè¯å™¨æŒ‡å¯¼ï¼Œæ˜¾ç¤ºå‡ºè¶…è¶ŠåŸºçº¿æ€§èƒ½çš„èƒ½åŠ›ï¼Œå®ç°æ˜¾è‘—çš„ç»å¯¹å¢é•¿ã€‚</li>
<li>ä¸»è¦æ”¶ç›Šå¹¶éæ¥è‡ªé‡‡æ ·å¤šæ ·æ€§ï¼Œè€Œæ˜¯éªŒè¯å™¨æŒ‡å¯¼çš„æ”¹è¿›ã€‚è¿™æ˜¯å› ä¸ºéªŒè¯å™¨èƒ½æ›´æœ‰æ•ˆåœ°æ•´åˆåé¦ˆå¹¶å¼•å¯¼å†³ç­–è¿‡ç¨‹ã€‚</li>
<li>IADå’ŒBONåœ¨ä¼˜è´¨éªŒè¯å™¨å¼•å¯¼ä¸‹å±•ç°å‡ºæ¨ç†æ—¶é—´éšè®¡ç®—å¢åŠ è€Œæ‰©å±•çš„èƒ½åŠ›ã€‚è¿™è¡¨æ˜éªŒè¯å™¨çš„è´¨é‡å¯¹äºæœ‰æ•ˆçš„æ¨ç†æ—¶é—´ä¼˜åŒ–è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01931">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0e9c988008b07f92b46a2667e8bdc56b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c1c979e185ec0d13599ce39566ea7efd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d166d3228d162fb49f2e59143d8a938d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-426156b8c277d9df2c464e128fe18c90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25b041fcd6d592212d8f906acd60b684.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a863922ec2c61f2c45529ee55bd6c7c8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Reasoning-LLMs-for-User-Aware-Multimodal-Conversational-Agents"><a href="#Reasoning-LLMs-for-User-Aware-Multimodal-Conversational-Agents" class="headerlink" title="Reasoning LLMs for User-Aware Multimodal Conversational Agents"></a>Reasoning LLMs for User-Aware Multimodal Conversational Agents</h2><p><strong>Authors:Hamed Rahimi, Jeanne Cattoni, Meriem Beghili, Mouad Abrini, Mahdi Khoramshahi, Maribel Pino, Mohamed Chetouani</strong></p>
<p>Personalization in social robotics is critical for fostering effective human-robot interactions, yet systems often face the cold start problem, where initial user preferences or characteristics are unavailable. This paper proposes a novel framework called USER-LLM R1 for a user-aware conversational agent that addresses this challenge through dynamic user profiling and model initiation. Our approach integrates chain-of-thought (CoT) reasoning models to iteratively infer user preferences and vision-language models (VLMs) to initialize user profiles from multimodal inputs, enabling personalized interactions from the first encounter. Leveraging a Retrieval-Augmented Generation (RAG) architecture, the system dynamically refines user representations within an inherent CoT process, ensuring contextually relevant and adaptive responses. Evaluations on the ElderlyTech-VQA Bench demonstrate significant improvements in ROUGE-1 (+23.2%), ROUGE-2 (+0.6%), and ROUGE-L (+8%) F1 scores over state-of-the-art baselines, with ablation studies underscoring the impact of reasoning model size on performance. Human evaluations further validate the frameworkâ€™s efficacy, particularly for elderly users, where tailored responses enhance engagement and trust. Ethical considerations, including privacy preservation and bias mitigation, are rigorously discussed and addressed to ensure responsible deployment. </p>
<blockquote>
<p>ä¸ªæ€§åŒ–ç¤¾ä¼šæœºå™¨äººæŠ€æœ¯åœ¨ä¿ƒè¿›äººä¸æœºå™¨äººçš„æœ‰æ•ˆäº¤äº’ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç³»ç»Ÿç»å¸¸é¢ä¸´å†·å¯åŠ¨é—®é¢˜ï¼Œå³æ— æ³•è·å–ç”¨æˆ·çš„åˆå§‹åå¥½æˆ–ç‰¹å¾ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶USER-LLM R1ï¼Œç”¨äºæ„å»ºç”¨æˆ·æ„ŸçŸ¥çš„å¯¹è¯ä»£ç†ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ¨æ€ç”¨æˆ·åˆ†æå’Œæ¨¡å‹å¯åŠ¨æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†æ¨¡å‹ï¼Œä»¥è¿­ä»£æ–¹å¼æ¨æ–­ç”¨æˆ·åå¥½ï¼Œå¹¶ç»“åˆè§†å¬è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä»å¤šæ¨¡å¼è¾“å…¥åˆå§‹åŒ–ç”¨æˆ·åˆ†æï¼Œä»è€Œå®ç°é¦–æ¬¡é­é‡æ—¶çš„ä¸ªæ€§åŒ–äº¤äº’ã€‚é€šè¿‡åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¶æ„ï¼Œç³»ç»Ÿåœ¨ä¸€ä¸ªå†…åœ¨çš„CoTè¿‡ç¨‹ä¸­åŠ¨æ€ä¼˜åŒ–ç”¨æˆ·è¡¨ç¤ºï¼Œç¡®ä¿è¯­å¢ƒç›¸å…³ä¸”è‡ªé€‚åº”çš„å“åº”ã€‚åœ¨ElderlyTech-VQA Benchä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä¸æœ€æ–°åŸºçº¿ç›¸æ¯”ï¼ŒROUGE-1ï¼ˆ+23.2%ï¼‰ã€ROUGE-2ï¼ˆ+0.6%ï¼‰å’ŒROUGE-Lï¼ˆ+8%ï¼‰çš„F1åˆ†æ•°æœ‰æ˜¾è‘—æ”¹å–„ã€‚æ¶ˆèç ”ç©¶å¼ºè°ƒäº†æ¨ç†æ¨¡å‹å¤§å°å¯¹æ€§èƒ½çš„å½±å“ã€‚äººç±»è¯„ä¼°è¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹è€å¹´ç”¨æˆ·ï¼Œå®šåˆ¶åŒ–çš„å“åº”æé«˜äº†å‚ä¸åº¦å’Œä¿¡ä»»åº¦ã€‚ä¼¦ç†è€ƒé‡ï¼ŒåŒ…æ‹¬éšç§ä¿æŠ¤å’Œåè§ç¼“è§£ï¼Œå¾—åˆ°äº†ä¸¥æ ¼çš„è®¨è®ºå’Œè§£å†³ï¼Œä»¥ç¡®ä¿è´Ÿè´£éƒ¨ç½²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01700v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ä¸ªåä¸ºUSER-LLM R1çš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºè§£å†³ä¸ªæ€§åŒ–ç¤¾äº¤æœºå™¨äººé¢ä¸´çš„æ— ç”¨æˆ·åå¥½æˆ–ç‰¹å¾åˆå§‹æ•°æ®å†·å¯åŠ¨é—®é¢˜ã€‚é€šè¿‡åŠ¨æ€ç”¨æˆ·å»ºæ¨¡å’Œæ¨¡å‹å¯åŠ¨æŠ€æœ¯ï¼Œè¯¥æ¡†æ¶ç»“åˆæ€ç»´é“¾æ¨ç†æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä»å¤šæ¨¡æ€è¾“å…¥ä¸­æ¨æ–­ç”¨æˆ·åå¥½å¹¶åˆå§‹åŒ–ç”¨æˆ·ç”»åƒï¼Œä»è€Œå®ç°é¦–æ¬¡æ¥è§¦æ—¶çš„ä¸ªæ€§åŒ–äº¤äº’ã€‚åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆæ¶æ„ï¼Œç³»ç»Ÿèƒ½å¤Ÿåœ¨å†…åœ¨æ€ç»´è¿‡ç¨‹ä¸­åŠ¨æ€ä¼˜åŒ–ç”¨æˆ·è¡¨å¾ï¼Œç¡®ä¿å›åº”çš„è¯­å¢ƒç›¸å…³æ€§å’Œé€‚åº”æ€§ã€‚åœ¨ElderlyTech-VQA Benchä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨ROUGE-1ï¼ˆæé«˜23.2%ï¼‰ã€ROUGE-2ï¼ˆæé«˜0.6%ï¼‰å’ŒROUGE-Lï¼ˆæé«˜8%ï¼‰çš„F1åˆ†æ•°æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚äººç±»è¯„ä¼°è¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¡†æ¶å¯¹è€å¹´ç”¨æˆ·çš„æ•ˆç”¨ï¼Œä¸ªæ€§åŒ–å›åº”æé«˜äº†å‚ä¸åº¦å’Œä¿¡ä»»åº¦ã€‚åŒæ—¶ä¸¥æ ¼è®¨è®ºäº†ä¼¦ç†è€ƒé‡ï¼ŒåŒ…æ‹¬éšç§ä¿æŠ¤å’Œåè§ç¼“è§£ï¼Œä»¥ç¡®ä¿è´Ÿè´£ä»»éƒ¨ç½²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>USER-LLM R1æ¡†æ¶è§£å†³äº†ä¸ªæ€§åŒ–ç¤¾äº¤æœºå™¨äººçš„å†·å¯åŠ¨é—®é¢˜ï¼Œé€šè¿‡åŠ¨æ€ç”¨æˆ·å»ºæ¨¡å’Œæ¨¡å‹å¯åŠ¨æŠ€æœ¯å®ç°ä¸ªæ€§åŒ–äº¤äº’ã€‚</li>
<li>æ¡†æ¶ç»“åˆäº†æ€ç»´é“¾æ¨ç†æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä»¥æ¨æ–­å’Œåˆå§‹åŒ–ç”¨æˆ·åå¥½å’Œç‰¹å¾ã€‚</li>
<li>æ£€ç´¢å¢å¼ºç”Ÿæˆæ¶æ„ç¡®ä¿å›åº”çš„è¯­å¢ƒç›¸å…³æ€§å’Œé€‚åº”æ€§ã€‚</li>
<li>åœ¨ElderlyTech-VQA Benchä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ROUGEè¯„åˆ†ä¸Šæ˜¾è‘—æé«˜ï¼Œå¹¶åœ¨äººç±»è¯„ä¼°ä¸­éªŒè¯äº†å…¶å¯¹è€å¹´ç”¨æˆ·çš„æ•ˆç”¨ã€‚</li>
<li>ä¸ªæ€§åŒ–å›åº”èƒ½æé«˜ç”¨æˆ·å‚ä¸åº¦å’Œä¿¡ä»»åº¦ã€‚</li>
<li>æ¡†æ¶ä¸¥æ ¼è€ƒè™‘äº†ä¼¦ç†é—®é¢˜ï¼ŒåŒ…æ‹¬éšç§ä¿æŠ¤å’Œåè§ç¼“è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01700">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a7a76a4fb94769482dc0127a81698ea4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-327f448db5fc875a0ddc17827750117b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec285135e1f83c72fb901a0ba345f390.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cb67508ac6814b3aca0f8d6c7bb449ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1a3356124ad25fa9715da503c3922f7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-130a296ece7e6c50de7e131b033050fd.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Are-Autonomous-Web-Agents-Good-Testers"><a href="#Are-Autonomous-Web-Agents-Good-Testers" class="headerlink" title="Are Autonomous Web Agents Good Testers?"></a>Are Autonomous Web Agents Good Testers?</h2><p><strong>Authors:Antoine Chevrot, Alexandre Vernotte, Jean-RÃ©my Falleri, Xavier Blanc, Bruno Legeard</strong></p>
<p>Despite advances in automated testing, manual testing remains prevalent due to the high maintenance demands associated with test script fragility-scripts often break with minor changes in application structure. Recent developments in Large Language Models (LLMs) offer a potential alternative by powering Autonomous Web Agents (AWAs) that can autonomously interact with applications. These agents may serve as Autonomous Test Agents (ATAs), potentially reducing the need for maintenance-heavy automated scripts by utilising natural language instructions similar to those used by human testers. This paper investigates the feasibility of adapting AWAs for natural language test case execution and how to evaluate them. We contribute with (1) a benchmark of three offline web applications, and a suite of 113 manual test cases, split between passing and failing cases, to evaluate and compare ATAs performance, (2) SeeAct-ATA and pinATA, two open-source ATA implementations capable of executing test steps, verifying assertions and giving verdicts, and (3) comparative experiments using our benchmark that quantifies our ATAs effectiveness. Finally we also proceed to a qualitative evaluation to identify the limitations of PinATA, our best performing implementation. Our findings reveal that our simple implementation, SeeAct-ATA, does not perform well compared to our more advanced PinATA implementation when executing test cases (50% performance improvement). However, while PinATA obtains around 60% of correct verdict and up to a promising 94% specificity, we identify several limitations that need to be addressed to develop more resilient and reliable ATAs, paving the way for robust, low maintenance test automation. CCS Concepts: $\bullet$ Software and its engineering $\rightarrow$ Software testing and debugging. </p>
<blockquote>
<p>å°½ç®¡è‡ªåŠ¨åŒ–æµ‹è¯•å–å¾—äº†è¿›å±•ï¼Œä½†ç”±äºæµ‹è¯•è„šæœ¬çš„è„†å¼±æ€§å¸¦æ¥çš„é«˜ç»´æŠ¤éœ€æ±‚ï¼Œæ‰‹åŠ¨æµ‹è¯•ä»ç„¶æ™®éå­˜åœ¨â€”â€”è„šæœ¬å¾€å¾€ä¼šåœ¨åº”ç”¨ç¨‹åºç»“æ„å‘ç”Ÿå¾®å°å˜åŒ–æ—¶å´©æºƒã€‚è‡ªç„¶è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°å‘å±•é€šè¿‡æ”¯æŒè‡ªä¸»Webä»£ç†ï¼ˆAWAï¼‰æä¾›äº†ä¸€ç§æ½œåœ¨çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¿™äº›ä»£ç†å¯ä»¥è‡ªä¸»åœ°ä¸åº”ç”¨ç¨‹åºè¿›è¡Œäº¤äº’ã€‚è¿™äº›ä»£ç†å¯ä»¥ä½œä¸ºè‡ªä¸»æµ‹è¯•ä»£ç†ï¼ˆATAï¼‰ï¼Œåˆ©ç”¨ç±»ä¼¼äºäººç±»æµ‹è¯•äººå‘˜ä½¿ç”¨çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå‡å°‘ç»´æŠ¤å¯†é›†å‹è‡ªåŠ¨åŒ–è„šæœ¬çš„éœ€æ±‚ã€‚æœ¬æ–‡ç ”ç©¶äº†å°†AWAé€‚åº”äºè‡ªç„¶è¯­è¨€æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œçš„å¯è¡Œæ€§ä»¥åŠå¦‚ä½•è¯„ä¼°å®ƒä»¬ã€‚ï¼ˆ1ï¼‰æˆ‘ä»¬å¯¹ä¸‰ä¸ªç¦»çº¿Webåº”ç”¨ç¨‹åºè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œå¹¶è®¾è®¡äº†113ä¸ªæ‰‹åŠ¨æµ‹è¯•ç”¨ä¾‹ï¼Œåˆ†ä¸ºé€šè¿‡å’Œå¤±è´¥çš„æ¡ˆä¾‹ï¼Œä»¥è¯„ä¼°å’Œæ¯”è¾ƒATAçš„æ€§èƒ½ï¼›ï¼ˆ2ï¼‰æˆ‘ä»¬æä¾›äº†SeeAct-ATAå’ŒpinATAä¸¤ä¸ªå¼€æºçš„ATAå®ç°ï¼Œå®ƒä»¬èƒ½å¤Ÿæ‰§è¡Œæµ‹è¯•æ­¥éª¤ï¼ŒéªŒè¯æ–­è¨€å¹¶ç»™å‡ºè£å†³ï¼›ï¼ˆ3ï¼‰ä½¿ç”¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•è¿›è¡Œé‡åŒ–å¯¹æ¯”å®éªŒï¼Œä»¥è¡¡é‡æˆ‘ä»¬çš„ATAçš„æœ‰æ•ˆæ€§ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œå®šæ€§è¯„ä¼°ï¼Œä»¥ç¡®å®šæ€§èƒ½æœ€ä½³çš„PinATAçš„å±€é™æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸æ›´å…ˆè¿›çš„PinATAå®ç°ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ç®€å•å®ç°SeeAct-ATAåœ¨æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹æ—¶çš„è¡¨ç°å¹¶ä¸ç†æƒ³ï¼ˆæ€§èƒ½æå‡50%ï¼‰ã€‚ç„¶è€Œï¼Œè™½ç„¶PinATAçš„æ­£ç¡®è£å†³ç‡çº¦ä¸º60%ï¼Œç‰¹å¼‚æ€§é«˜è¾¾94%ï¼Œä½†è¿˜å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œéœ€è¦è§£å†³è¿™äº›é—®é¢˜ä»¥å¼€å‘æ›´å¼ºå¤§ã€æ›´å¯é çš„ATAï¼Œä¸ºç¨³å¥ã€ä½ç»´æŠ¤çš„æµ‹è¯•è‡ªåŠ¨åŒ–é“ºå¹³é“è·¯ã€‚æ ¸å¿ƒæ¦‚å¿µåŒ…æ‹¬è½¯ä»¶å’Œè½¯ä»¶å·¥ç¨‹ä¸­çš„è½¯ä»¶æµ‹è¯•å’Œè°ƒè¯•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01495v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>è‡ªåŠ¨åŒ–æµ‹è¯•è™½ç„¶æœ‰è¿›æ­¥ï¼Œä½†ç”±äºæµ‹è¯•è„šæœ¬çš„è„†å¼±æ€§å¯¼è‡´çš„ç»´æŠ¤éœ€æ±‚è¾ƒé«˜ï¼Œæ‰‹åŠ¨æµ‹è¯•ä»ç„¶æ™®éå­˜åœ¨ã€‚æœ€è¿‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•ä¸ºè‡ªä¸»Webä»£ç†ï¼ˆAWAï¼‰æä¾›äº†æ½œåŠ›ï¼Œå¯ä»¥è‡ªä¸»ä¸åº”ç”¨è¿›è¡Œäº¤äº’ã€‚è¿™äº›ä»£ç†å¯ä»¥ä½œä¸ºè‡ªä¸»æµ‹è¯•ä»£ç†ï¼ˆATAï¼‰ï¼Œåˆ©ç”¨ä¸äººç±»æµ‹è¯•è€…ç›¸ä¼¼çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå‡å°‘ç»´æŠ¤ç¹é‡çš„è‡ªåŠ¨åŒ–è„šæœ¬çš„éœ€æ±‚ã€‚æœ¬æ–‡æ¢è®¨äº†å°†AWAsé€‚åº”äºè‡ªç„¶è¯­è¨€æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œçš„å¯è¡Œæ€§ä»¥åŠå¦‚ä½•è¯„ä¼°å®ƒä»¬ã€‚æœ¬ç ”ç©¶æä¾›äº†ï¼ˆ1ï¼‰ä¸‰ä¸ªç¦»çº¿Webåº”ç”¨ç¨‹åºçš„åŸºå‡†æµ‹è¯•å¥—ä»¶å’ŒåŒ…å«é€šè¿‡å’Œå¤±è´¥æƒ…å†µçš„113ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œï¼ˆ2ï¼‰ä¸¤ä¸ªå¯æ‰§è¡Œæµ‹è¯•æ­¥éª¤ã€éªŒè¯æ–­è¨€å’Œç»™å‡ºç»“æœçš„å¼€æºATAå®ç°SeeAct-ATAå’ŒpinATAï¼Œï¼ˆ3ï¼‰ä½¿ç”¨åŸºå‡†æµ‹è¯•å¯¹ATAæœ‰æ•ˆæ€§çš„é‡åŒ–å¯¹æ¯”å®éªŒã€‚æœ€åè¿˜è¿›è¡Œäº†å®šæ€§è¯„ä¼°ï¼Œä»¥è¯†åˆ«è¡¨ç°æœ€ä½³çš„PinATAçš„å±€é™æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸æ›´å…ˆè¿›çš„PinATAå®ç°ç›¸æ¯”ï¼Œç®€å•çš„SeeAct-ATAåœ¨æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹æ—¶è¡¨ç°ä¸ä½³ï¼ˆæ€§èƒ½æå‡50ï¼…ï¼‰ã€‚å°½ç®¡PinATAè·å¾—äº†çº¦60ï¼…çš„æ­£ç¡®ç»“è®ºå’Œé«˜è¾¾94ï¼…çš„ç‰¹å¼‚æ€§ï¼Œä½†ä»ç„¶å­˜åœ¨éœ€è¦è§£å†³çš„å±€é™æ€§ï¼Œä»¥å¼€å‘æ›´å…·å¼¹æ€§å’Œå¯é çš„ATAï¼Œä¸ºä½ç»´æŠ¤çš„æµ‹è¯•è‡ªåŠ¨åŒ–é“ºå¹³é“è·¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„è‡ªä¸»Webä»£ç†ï¼ˆAWAï¼‰åœ¨è½¯ä»¶æµ‹è¯•é¢†åŸŸå…·æœ‰æ½œåŠ›ï¼Œå¯æ›¿ä»£éƒ¨åˆ†æ‰‹åŠ¨æµ‹è¯•å·¥ä½œã€‚</li>
<li>è‡ªä¸»æµ‹è¯•ä»£ç†ï¼ˆATAï¼‰èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤è¿›è¡Œæµ‹è¯•ï¼Œå‡å°‘ç»´æŠ¤ç¹ççš„è‡ªåŠ¨åŒ–è„šæœ¬çš„éœ€æ±‚ã€‚</li>
<li>ç ”ç©¶æä¾›äº†åŸºå‡†æµ‹è¯•å’Œæµ‹è¯•ç”¨ä¾‹ç”¨äºè¯„ä¼°ATAæ€§èƒ½ã€‚</li>
<li>å®éªŒä¸­ï¼Œæ›´å…ˆè¿›çš„PinATAè¡¨ç°è¾ƒå¥½ï¼Œè·å¾—çº¦60%çš„æ­£ç¡®ç»“è®ºå’Œé«˜è¾¾94%çš„ç‰¹å¼‚æ€§ã€‚</li>
<li>å°½ç®¡PinATAè¡¨ç°æœ‰æ½œåŠ›ï¼Œä½†ä»å­˜åœ¨éœ€è¦è§£å†³çš„å±€é™æ€§ï¼Œå¦‚å¯é æ€§ã€é²æ£’æ€§ç­‰æ–¹é¢ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01495">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3f9f6d54f64381d2ca4fa4d85240d518.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-89a44605035e9bb9d2c113075fa24465.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b6af6bc2e3b9d3a630423e4de1616aef.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Strategize-Globally-Adapt-Locally-A-Multi-Turn-Red-Teaming-Agent-with-Dual-Level-Learning"><a href="#Strategize-Globally-Adapt-Locally-A-Multi-Turn-Red-Teaming-Agent-with-Dual-Level-Learning" class="headerlink" title="Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with   Dual-Level Learning"></a>Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with   Dual-Level Learning</h2><p><strong>Authors:Si Chen, Xiao Yu, Ninareh Mehrabi, Rahul Gupta, Zhou Yu, Ruoxi Jia</strong></p>
<p>The exploitation of large language models (LLMs) for malicious purposes poses significant security risks as these models become more powerful and widespread. While most existing red-teaming frameworks focus on single-turn attacks, real-world adversaries typically operate in multi-turn scenarios, iteratively probing for vulnerabilities and adapting their prompts based on threat model responses. In this paper, we propose \AlgName, a novel multi-turn red-teaming agent that emulates sophisticated human attackers through complementary learning dimensions: global tactic-wise learning that accumulates knowledge over time and generalizes to new attack goals, and local prompt-wise learning that refines implementations for specific goals when initial attempts fail. Unlike previous multi-turn approaches that rely on fixed strategy sets, \AlgName enables the agent to identify new jailbreak tactics, develop a goal-based tactic selection framework, and refine prompt formulations for selected tactics. Empirical evaluations on JailbreakBench demonstrate our frameworkâ€™s superior performance, achieving over 90% attack success rates against GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns, outperforming state-of-the-art baselines. These results highlight the effectiveness of dynamic learning in identifying and exploiting model vulnerabilities in realistic multi-turn scenarios. </p>
<blockquote>
<p>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œæ¶æ„æ´»åŠ¨ï¼Œéšç€è¿™äº›æ¨¡å‹è¶Šæ¥è¶Šå¼ºå¤§å’Œæ™®åŠï¼Œå¸¦æ¥äº†é‡å¤§çš„å®‰å…¨é£é™©ã€‚è™½ç„¶ç°æœ‰çš„å¤§å¤šæ•°çº¢é˜Ÿæ¡†æ¶ä¾§é‡äºå•è½®æ”»å‡»ï¼Œä½†ç°å®ä¸–ç•Œçš„å¯¹æ‰‹é€šå¸¸åœ¨å¤šè½®åœºæ™¯ä¸­æ“ä½œï¼Œè¿­ä»£æ¢æµ‹æ¼æ´å¹¶æ ¹æ®å¨èƒæ¨¡å‹å“åº”è°ƒæ•´ä»–ä»¬çš„æç¤ºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†\AlgNameï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šè½®çº¢é˜Ÿä»£ç†ï¼Œé€šè¿‡äº’è¡¥çš„å­¦ä¹ ç»´åº¦æ¨¡æ‹Ÿé«˜çº§äººç±»æ”»å‡»è€…ï¼šå…¨å±€æˆ˜æœ¯å­¦ä¹ ï¼Œéšæ—¶é—´ç§¯ç´¯çŸ¥è¯†å¹¶æ¨å¹¿åˆ°æ–°çš„æ”»å‡»ç›®æ ‡ï¼›ä»¥åŠå±€éƒ¨æç¤ºå­¦ä¹ ï¼Œå½“åˆæ­¥å°è¯•å¤±è´¥æ—¶ï¼Œå¯¹ç‰¹å®šç›®æ ‡çš„å®ç°è¿›è¡Œç²¾ç‚¼ã€‚ä¸ä»¥å‰ä¾èµ–å›ºå®šç­–ç•¥é›†çš„å¤šè½®æ–¹æ³•ä¸åŒï¼Œ\AlgNameä½¿ä»£ç†èƒ½å¤Ÿè¯†åˆ«æ–°çš„è¶Šç‹±æˆ˜æœ¯ï¼Œå»ºç«‹åŸºäºç›®æ ‡çš„æˆ˜æœ¯é€‰æ‹©æ¡†æ¶ï¼Œå¹¶å¯¹æ‰€é€‰æˆ˜æœ¯çš„æç¤ºå½¢å¼è¿›è¡Œç²¾ç‚¼ã€‚åœ¨JailbreakBenchä¸Šçš„ç»éªŒè¯„ä¼°è¯æ˜äº†æˆ‘ä»¬æ¡†æ¶çš„å“è¶Šæ€§èƒ½ï¼Œåœ¨5è½®å¯¹è¯å†…ï¼Œé’ˆå¯¹GPT-3.5-Turboå’ŒLlama-3.1-70Bçš„æ”»å‡»æˆåŠŸç‡è¶…è¿‡90%ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºçº¿ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†åŠ¨æ€å­¦ä¹ åœ¨è¯†åˆ«å’Œåˆ©ç”¨ç°å®å¤šè½®åœºæ™¯ä¸­çš„æ¨¡å‹æ¼æ´æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01278v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«æ¶æ„åˆ©ç”¨å­˜åœ¨é‡å¤§å®‰å…¨é£é™©ã€‚ç°æœ‰çº¢é˜Ÿæ¡†æ¶å¤šä¸ºå•è½®æ”»å‡»ï¼Œè€Œç°å®æ”»å‡»è€…é€šå¸¸åœ¨å¤šè½®åœºæ™¯ä¸­æ“ä½œã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹å¤šè½®çº¢é˜Ÿä»£ç†\AlgNameï¼Œé€šè¿‡å…¨çƒæˆ˜æœ¯å­¦ä¹ å’Œå±€éƒ¨æç¤ºå­¦ä¹ ä¸¤ä¸ªäº’è¡¥ç»´åº¦æ¥æ¨¡æ‹Ÿé«˜çº§äººç±»æ”»å‡»è€…ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨é’ˆå¯¹GPT-3.5 Turboå’ŒLlama-3.1-70Bçš„5è½®å¯¹è¯å†…ï¼Œæ”»å‡»æˆåŠŸç‡è¶…è¿‡90%ï¼Œä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ã€‚è¿™çªæ˜¾äº†åŠ¨æ€å­¦ä¹ åœ¨è¯†åˆ«å’Œåˆ©ç”¨æ¨¡å‹æ¼æ´æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¶æ„åˆ©ç”¨å­˜åœ¨é‡å¤§å®‰å…¨é£é™©ï¼Œéšç€è¿™äº›æ¨¡å‹çš„æ—¥ç›Šå¼ºå¤§å’Œæ™®åŠï¼Œå®‰å…¨å¨èƒä¹Ÿéšä¹‹å¢åŠ ã€‚</li>
<li>ç°æœ‰çº¢é˜Ÿæ¡†æ¶ä¸»è¦å…³æ³¨å•è½®æ”»å‡»ï¼Œä½†ç°å®æ”»å‡»è€…é€šå¸¸åœ¨å¤šè½®åœºæ™¯ä¸­æ“ä½œï¼Œéœ€è¦æ›´å¤æ‚çš„ç­–ç•¥ã€‚</li>
<li>\AlgNameæ˜¯ä¸€ç§æ–°å‹å¤šè½®çº¢é˜Ÿä»£ç†ï¼Œé€šè¿‡å…¨çƒæˆ˜æœ¯å­¦ä¹ å’Œå±€éƒ¨æç¤ºå­¦ä¹ ä¸¤ä¸ªäº’è¡¥ç»´åº¦æ¨¡æ‹Ÿé«˜çº§äººç±»æ”»å‡»è€…ã€‚</li>
<li>\AlgNameèƒ½å¤Ÿåœ¨å¤šè½®å¯¹è¯ä¸­ç´¯ç§¯çŸ¥è¯†ï¼Œé€‚åº”æ–°æ”»å‡»ç›®æ ‡ï¼Œå¹¶ä¼˜åŒ–ç‰¹å®šç›®æ ‡çš„å®ç°æ–¹æ³•ã€‚</li>
<li>ä¸ä¾èµ–å›ºå®šç­–ç•¥é›†çš„å‰æœŸå¤šè½®æ–¹æ³•ä¸åŒï¼Œ\AlgNameèƒ½å¤Ÿè¯†åˆ«æ–°çš„çªç ´ç­–ç•¥ï¼Œå»ºç«‹åŸºäºç›®æ ‡çš„ç­–ç•¥é€‰æ‹©æ¡†æ¶ï¼Œå¹¶ä¼˜åŒ–é€‰å®šç­–ç•¥çš„æç¤ºå½¢å¼ã€‚</li>
<li>å®è¯è¯„ä¼°è¡¨æ˜ï¼Œ\AlgNameåœ¨é’ˆå¯¹GPT-3.5 Turboå’ŒLlama-3.1-70Bçš„5è½®å¯¹è¯å†…æ”»å‡»æˆåŠŸç‡è¶…è¿‡90%ï¼Œæ€§èƒ½ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01278">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3f22bd9a965a9089fc7598fe84446391.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f752429be637dffb17003f185891bff0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a439dc6151627ba6fb4a3b53cdcd2cb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fb5b8f5b391b81b41226e5a7fb59ac41.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="First-Field-Trial-Demonstration-of-L4-Autonomous-Optical-Network-for-Distributed-AI-Training-Communication-An-LLM-Powered-Multi-AI-Agent-Solution"><a href="#First-Field-Trial-Demonstration-of-L4-Autonomous-Optical-Network-for-Distributed-AI-Training-Communication-An-LLM-Powered-Multi-AI-Agent-Solution" class="headerlink" title="First Field-Trial Demonstration of L4 Autonomous Optical Network for   Distributed AI Training Communication: An LLM-Powered Multi-AI-Agent Solution"></a>First Field-Trial Demonstration of L4 Autonomous Optical Network for   Distributed AI Training Communication: An LLM-Powered Multi-AI-Agent Solution</h2><p><strong>Authors:Yihao Zhang, Qizhi Qiu, Xiaomin Liu, Dianxuan Fu, Xingyu Liu, Leyan Fei, Yuming Cheng, Lilin Yi, Weisheng Hu, Qunbi Zhuge</strong></p>
<p>We demonstrate the first cross-domain cross-layer level-4 autonomous optical network via a multi-AI-agent system. Field trials show 98 percent task completion rate across the distributed AI training lifecycle-3.2x higher than single agents using state-of-the-art LLMs. </p>
<blockquote>
<p>æˆ‘ä»¬å±•ç¤ºäº†é¦–ä¸ªè·¨åŸŸè·¨å±‚çº§çš„å››çº§è‡ªä¸»å…‰å­¦ç½‘ç»œï¼Œé€šè¿‡å¤šäººå·¥æ™ºèƒ½ä»£ç†ç³»ç»Ÿå®ç°ã€‚ç°åœºè¯•éªŒæ˜¾ç¤ºï¼Œåœ¨åˆ†å¸ƒå¼äººå·¥æ™ºèƒ½è®­ç»ƒç”Ÿå‘½å‘¨æœŸä¸­ï¼Œä»»åŠ¡å®Œæˆç‡é«˜è¾¾98%ï¼Œæ˜¯ä½¿ç”¨æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹çš„å•ä¸ªä»£ç†çš„3.2å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01234v1">PDF</a> Submitted to the PDP session of the Optical Fiber Communications   Conference (OFC) 2025</p>
<p><strong>Summary</strong>:<br>é‡‡ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒæˆåŠŸå®ç°äº†é¦–ä¸ªè·¨åŸŸè·¨å±‚çº§çš„å››çº§è‡ªä¸»å…‰ç½‘ç»œã€‚å®åœ°è¯•éªŒæ˜¾ç¤ºï¼Œåœ¨åˆ†å¸ƒå¼äººå·¥æ™ºèƒ½è®­ç»ƒç”Ÿå‘½å‘¨æœŸä¸­ä»»åŠ¡å®Œæˆç‡é«˜è¾¾98%ï¼Œè¾ƒä½¿ç”¨æœ€æ–°è¯­è¨€æ¨¡å‹çš„å•ä¸€æ™ºèƒ½ä½“é«˜å‡º3.2å€ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>æˆåŠŸå®ç°é¦–ä¸ªè·¨åŸŸè·¨å±‚çº§çš„å››çº§è‡ªä¸»å…‰ç½‘ç»œã€‚</li>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ”¯æŒè¯¥ç½‘ç»œçš„è¿è¡Œã€‚</li>
<li>å®åœ°è¯•éªŒæ˜¾ç¤ºä»»åŠ¡å®Œæˆç‡é«˜è¾¾98%ã€‚</li>
<li>ä¸ä½¿ç”¨å•ä¸€æ™ºèƒ½ä½“å’Œæœ€æ–°è¯­è¨€æ¨¡å‹çš„å¯¹æ¯”ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ã€‚</li>
<li>è¯¥ç½‘ç»œåœ¨åˆ†å¸ƒå¼äººå·¥æ™ºèƒ½è®­ç»ƒç”Ÿå‘½å‘¨æœŸä¸­è¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>æ­¤é¡¹æŠ€æœ¯çªç ´å¯¹äºæœªæ¥ç½‘ç»œçš„å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01234">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d888194f89750fb114fe946bd50260fb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d195f7f56f8b61e0397c7cef5bcabd7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8abdb332bffd6b07f1138e72473855cf.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="On-the-Robustness-of-Agentic-Function-Calling"><a href="#On-the-Robustness-of-Agentic-Function-Calling" class="headerlink" title="On the Robustness of Agentic Function Calling"></a>On the Robustness of Agentic Function Calling</h2><p><strong>Authors:Ella Rabinovich, Ateret Anaby-Tavor</strong></p>
<p>Large Language Models (LLMs) are increasingly acting as autonomous agents, with function calling (FC) capabilities enabling them to invoke specific tools for tasks. While prior research has primarily focused on improving FC accuracy, little attention has been given to the robustness of these agents to perturbations in their input. We introduce a benchmark assessing FC robustness in two key areas: resilience to naturalistic query variations, and stability in function calling when the toolkit expands with semantically related tools. Evaluating best-performing FC models on a carefully expanded subset of the Berkeley function calling leaderboard (BFCL), we identify critical weaknesses in existing evaluation methodologies, and highlight areas for improvement in real-world agentic deployments. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ­£è¶Šæ¥è¶Šå¤šåœ°å……å½“è‡ªä¸»ä»£ç†ï¼Œå…·æœ‰åŠŸèƒ½è°ƒç”¨ï¼ˆFCï¼‰èƒ½åŠ›ï¼Œå¯ä»¥è®©ä»–ä»¬è°ƒç”¨ç‰¹å®šå·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æé«˜FCçš„å‡†ç¡®æ€§ä¸Šï¼Œä½†è¿™äº›ä»£ç†å¯¹è¾“å…¥æ‰°åŠ¨çš„ç¨³å¥æ€§å´è¢«å¿½è§†äº†ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œä»ä¸¤ä¸ªæ–¹é¢è¯„ä¼°FCçš„ç¨³å¥æ€§ï¼šå¯¹è‡ªç„¶æŸ¥è¯¢å˜åŒ–çš„é€‚åº”æ€§å’Œå·¥å…·ç®±æ‰©å±•æ—¶è¯­ä¹‰ç›¸å…³å·¥å…·çš„å‡½æ•°è°ƒç”¨ç¨³å®šæ€§ã€‚æˆ‘ä»¬åœ¨ç»è¿‡ç²¾å¿ƒæ‰©å±•çš„ä¼¯å…‹åˆ©å‡½æ•°è°ƒç”¨æ’è¡Œæ¦œï¼ˆBFCLï¼‰çš„å­é›†ä¸Šè¯„ä¼°äº†æ€§èƒ½æœ€ä½³çš„FCæ¨¡å‹ï¼Œå‘ç°äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„å…³é”®å¼±ç‚¹ï¼Œå¹¶æŒ‡å‡ºäº†åœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²ä»£ç†æ—¶æ”¹è¿›çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00914v1">PDF</a> 7 pages, TrustNLP@NAACL25</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°å……å½“è‡ªä¸»ä»£ç†ï¼Œå…¶åŠŸèƒ½è°ƒç”¨ï¼ˆFCï¼‰èƒ½åŠ›å¯ä½¿å…¶ä¸ºç‰¹å®šä»»åŠ¡è°ƒç”¨ç‰¹å®šå·¥å…·ã€‚è™½ç„¶å…ˆå‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æé«˜FCçš„å‡†ç¡®æ€§ä¸Šï¼Œä½†å¯¹äºè¿™äº›ä»£ç†å¯¹è¾“å…¥æ‰°åŠ¨çš„ç¨³å¥æ€§å´é²œæœ‰å…³æ³¨ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€é¡¹åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°FCåœ¨å…³é”®é¢†åŸŸçš„ç¨³å¥æ€§ï¼šå¯¹è‡ªç„¶æŸ¥è¯¢å˜åŒ–çš„é€‚åº”æ€§å’Œå·¥å…·åŒ…æ‰©å±•æ—¶å‡½æ•°è°ƒç”¨çš„ç¨³å®šæ€§ã€‚é€šè¿‡å¯¹Berkeleyå‡½æ•°è°ƒç”¨æ’è¡Œæ¦œï¼ˆBFCLï¼‰ç²¾å¿ƒæ‰©å±•çš„å­é›†è¯„ä¼°è¡¨ç°æœ€ä½³çš„FCæ¨¡å‹ï¼Œæˆ‘ä»¬å‘ç°äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„ï¼Œå¹¶æŒ‡å‡ºäº†åœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²ä»£ç†æ—¶éœ€è¦æ”¹è¿›çš„é¢†åŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£è¶Šæ¥è¶Šå¤šåœ°å……å½“è‡ªä¸»ä»£ç†ï¼Œå…·æœ‰åŠŸèƒ½è°ƒç”¨ï¼ˆFCï¼‰èƒ½åŠ›ã€‚</li>
<li>åŠŸèƒ½è°ƒç”¨ï¼ˆFCï¼‰çš„ç¨³å¥æ€§è¯„ä¼°æ˜¯ä¸€ä¸ªæ–°å…´é¢†åŸŸï¼ŒåŒ…æ‹¬é€‚åº”è‡ªç„¶æŸ¥è¯¢å˜åŒ–å’Œå·¥å…·åŒ…æ‰©å±•æ—¶çš„å‡½æ•°è°ƒç”¨ç¨³å®šæ€§ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œéœ€è¦æ”¹è¿›ä»¥æ›´å¥½åœ°åæ˜ å®é™…éƒ¨ç½²ä¸­çš„ä»£ç†æ€§èƒ½ã€‚</li>
<li>å¯¹è‡ªç„¶æŸ¥è¯¢å˜åŒ–çš„é€‚åº”æ€§æ˜¯è¯„ä¼°FCç¨³å¥æ€§çš„ä¸€ä¸ªé‡è¦æ–¹é¢ã€‚</li>
<li>åœ¨å·¥å…·åŒ…æ‰©å±•æ—¶ï¼Œå‡½æ•°è°ƒç”¨çš„ç¨³å®šæ€§ä¹Ÿæ˜¯è¯„ä¼°FCç¨³å¥æ€§çš„ä¸€ä¸ªé‡è¦æ–¹é¢ã€‚</li>
<li>æœ€ä½³FCæ¨¡å‹åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°æ­ç¤ºäº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00914">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-152d199ea968588d2583860158bc51ee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4a09f81d1a227b0b1af3bbe741194074.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7550e694fa69b58b370453beee565178.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Grounding-Multimodal-LLMs-to-Embodied-Agents-that-Ask-for-Help-with-Reinforcement-Learning"><a href="#Grounding-Multimodal-LLMs-to-Embodied-Agents-that-Ask-for-Help-with-Reinforcement-Learning" class="headerlink" title="Grounding Multimodal LLMs to Embodied Agents that Ask for Help with   Reinforcement Learning"></a>Grounding Multimodal LLMs to Embodied Agents that Ask for Help with   Reinforcement Learning</h2><p><strong>Authors:Ram Ramrakhya, Matthew Chang, Xavier Puig, Ruta Desai, Zsolt Kira, Roozbeh Mottaghi</strong></p>
<p>Embodied agents operating in real-world environments must interpret ambiguous and under-specified human instructions. A capable household robot should recognize ambiguity and ask relevant clarification questions to infer the user intent accurately, leading to more effective task execution. To study this problem, we introduce the Ask-to-Act task, where an embodied agent must fetch a specific object instance given an ambiguous instruction in a home environment. The agent must strategically ask minimal, yet relevant, clarification questions to resolve ambiguity while navigating under partial observability. To solve this problem, we propose a novel approach that fine-tunes multimodal large language models (MLLMs) as vision-language-action (VLA) policies using online reinforcement learning (RL) with LLM-generated rewards. Our method eliminates the need for large-scale human demonstrations or manually engineered rewards for training such agents. We benchmark against strong zero-shot baselines, including GPT-4o, and supervised fine-tuned MLLMs, on our task. Our results demonstrate that our RL-finetuned MLLM outperforms all baselines by a significant margin ($19.1$-$40.3%$), generalizing well to novel scenes and tasks. To the best of our knowledge, this is the first demonstration of adapting MLLMs as VLA agents that can act and ask for help using LLM-generated rewards with online RL. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œç¯å¢ƒä¸­è¿è¡Œçš„åµŒå…¥å¼æ™ºèƒ½ä½“å¿…é¡»è§£é‡Šæ¨¡ç³Šä¸”æŒ‡å®šä¸æ˜ç¡®çš„äººç±»æŒ‡ä»¤ã€‚ä¸€ä¸ªå‡ºè‰²çš„å®¶ç”¨æœºå™¨äººåº”è¯¥èƒ½å¤Ÿè¯†åˆ«æ­§ä¹‰å¹¶æå‡ºç›¸å…³æ¾„æ¸…é—®é¢˜ï¼Œä»¥å‡†ç¡®æ¨æ–­ç”¨æˆ·æ„å›¾ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ã€‚ä¸ºäº†ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†â€œé—®åè¡ŒåŠ¨â€ä»»åŠ¡ï¼Œåœ¨è¯¥ä»»åŠ¡ä¸­ï¼ŒåµŒå…¥å¼æ™ºèƒ½ä½“å¿…é¡»åœ¨å®¶åº­ç¯å¢ƒä¸­æ ¹æ®æ¨¡ç³ŠæŒ‡ä»¤è·å–ç‰¹å®šå¯¹è±¡å®ä¾‹ã€‚æ™ºèƒ½ä½“å¿…é¡»åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿçš„æƒ…å†µä¸‹å¯¼èˆªæ—¶ï¼Œé€šè¿‡æå‡ºæœ€å°‘ä½†ç›¸å…³çš„ä¿¡æ¯æ¾„æ¸…é—®é¢˜æ¥è§£å†³æ­§ä¹‰é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾®è°ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œå°†å…¶ä½œä¸ºè§†è§‰è¯­è¨€è¡ŒåŠ¨ï¼ˆVLAï¼‰ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¶ˆé™¤äº†è®­ç»ƒæ­¤ç±»æ™ºèƒ½ä½“æ—¶éœ€è¦å¤§é‡äººç±»æ¼”ç¤ºæˆ–æ‰‹åŠ¨å·¥ç¨‹å¥–åŠ±çš„éœ€æ±‚ã€‚æˆ‘ä»¬åœ¨æˆ‘ä»¬çš„ä»»åŠ¡ä¸Šä¸å¼ºå¤§çš„é›¶æ ·æœ¬åŸºçº¿è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬GPT-4oå’Œç»è¿‡ç›‘ç£è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒåçš„MLLMåœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼ˆæé«˜å¹…åº¦ä¸º19.1%~40.3%ï¼‰ï¼Œåœ¨æ–°åœºæ™¯å’Œä»»åŠ¡ä¸­å…·æœ‰å¾ˆå¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°†å¤§å‹è¯­è¨€æ¨¡å‹é€‚åº”ä¸ºè§†è§‰è¯­è¨€è¡ŒåŠ¨æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å¥–åŠ±è¿›è¡Œåœ¨çº¿å¼ºåŒ–å­¦ä¹ è¿›è¡Œè¡ŒåŠ¨å’Œå¯»æ±‚å¸®åŠ©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00907v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬æŒ‡å‡ºï¼Œå®ä½“ä»£ç†éœ€è¦åœ¨çœŸå®ç¯å¢ƒä¸­è§£é‡Šæ¨¡ç³Šå’ŒæœªæŒ‡å®šçš„äººç±»æŒ‡ä»¤ã€‚å®¶åº­æœºå™¨äººåº”å…·å¤‡è¯†åˆ«æ­§ä¹‰çš„èƒ½åŠ›ï¼Œé€šè¿‡æå‡ºç›¸å…³æ¾„æ¸…é—®é¢˜æ¥å‡†ç¡®æ¨æ–­ç”¨æˆ·æ„å›¾ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„ä»»åŠ¡æ‰§è¡Œã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¼•å…¥äº†â€œé—®å†è¡ŒåŠ¨â€ä»»åŠ¡ï¼Œå…¶ä¸­å®ä½“ä»£ç†éœ€è¦åœ¨å®¶åº­ç¯å¢ƒä¸­æ ¹æ®æ¨¡ç³ŠæŒ‡ä»¤è·å–ç‰¹å®šå¯¹è±¡å®ä¾‹ã€‚ä»£ç†å¿…é¡»ç­–ç•¥æ€§åœ°æå‡ºæœ€å°‘ä½†ç›¸å…³çš„æ¾„æ¸…é—®é¢˜æ¥è§£å†³æ­§ä¹‰ï¼ŒåŒæ—¶åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿæ€§ä¸‹è¿›è¡Œå¯¼èˆªã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å¥–åŠ±å¾®è°ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œä½œä¸ºè§†è§‰è¯­è¨€è¡ŒåŠ¨ï¼ˆVLAï¼‰ç­–ç•¥ã€‚è¯¥æ–¹æ³•æ¶ˆé™¤äº†å¯¹å¤§è§„æ¨¡äººç±»æ¼”ç¤ºæˆ–æ‰‹åŠ¨å·¥ç¨‹å¥–åŠ±è®­ç»ƒæ­¤ç±»ä»£ç†çš„éœ€è¦ã€‚åœ¨åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬çš„RLå¾®è°ƒMLLMç›¸å¯¹äºåŒ…æ‹¬GPT-4oåœ¨å†…çš„å¼ºå¤§é›¶é•œå¤´åŸºçº¿ï¼Œåœ¨æˆ‘ä»¬çš„ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„RLå¾®è°ƒMLLMåœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†æ˜¾è‘—çš„ä¼˜åŠ¿ï¼ˆ19.1%-40.3%ï¼‰ï¼Œå¹¶å¾ˆå¥½åœ°æ¨å¹¿åˆ°äº†æ–°åœºæ™¯å’Œä»»åŠ¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡æ¼”ç¤ºå°†MLLMsé€‚åº”ä¸ºVLAä»£ç†ï¼Œå¯ä»¥ä½¿ç”¨LLMç”Ÿæˆçš„å¥–åŠ±ä¸åœ¨çº¿å¼ºåŒ–å­¦ä¹ è¿›è¡Œè¡ŒåŠ¨å’Œæ±‚åŠ©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®ä½“ä»£ç†éœ€è¦è§£é‡ŠçœŸå®ç¯å¢ƒä¸­çš„æ¨¡ç³Šå’ŒæœªæŒ‡å®šçš„äººç±»æŒ‡ä»¤ã€‚</li>
<li>å®¶åº­æœºå™¨äººåº”èƒ½è¯†åˆ«æ­§ä¹‰ï¼Œå¹¶é€šè¿‡æå‡ºç›¸å…³æ¾„æ¸…é—®é¢˜æ¥å‡†ç¡®æ¨æ–­ç”¨æˆ·æ„å›¾ã€‚</li>
<li>å¼•å…¥â€œé—®å†è¡ŒåŠ¨â€ä»»åŠ¡ï¼Œè¦æ±‚å®ä½“ä»£ç†åœ¨ç»™å®šæ¨¡ç³ŠæŒ‡ä»¤çš„æƒ…å†µä¸‹ï¼Œåœ¨å®¶åº­ç¯å¢ƒä¸­è·å–ç‰¹å®šå¯¹è±¡å®ä¾‹ã€‚</li>
<li>ä»£ç†éœ€è¦ç­–ç•¥æ€§åœ°æå‡ºæ¾„æ¸…é—®é¢˜æ¥è§£å†³æ­§ä¹‰ï¼Œå¹¶åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿæ€§ä¸‹è¿›è¡Œå¯¼èˆªã€‚</li>
<li>æå‡ºä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å¥–åŠ±å¾®è°ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•ä¸éœ€è¦å¤§è§„æ¨¡çš„äººç±»æ¼”ç¤ºæˆ–æ‰‹åŠ¨å·¥ç¨‹å¥–åŠ±æ¥è®­ç»ƒä»£ç†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00907">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f7c8c62ca23f49913ac819badf630190.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-557dae7264ae9b2d318eff1046e3e062.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed34d8618db18090f3bf1b277f9f34fa.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Agent-S2-A-Compositional-Generalist-Specialist-Framework-for-Computer-Use-Agents"><a href="#Agent-S2-A-Compositional-Generalist-Specialist-Framework-for-Computer-Use-Agents" class="headerlink" title="Agent S2: A Compositional Generalist-Specialist Framework for Computer   Use Agents"></a>Agent S2: A Compositional Generalist-Specialist Framework for Computer   Use Agents</h2><p><strong>Authors:Saaket Agashe, Kyle Wong, Vincent Tu, Jiachen Yang, Ang Li, Xin Eric Wang</strong></p>
<p>Computer use agents automate digital tasks by directly interacting with graphical user interfaces (GUIs) on computers and mobile devices, offering significant potential to enhance human productivity by completing an open-ended space of user queries. However, current agents face significant challenges: imprecise grounding of GUI elements, difficulties with long-horizon task planning, and performance bottlenecks from relying on single generalist models for diverse cognitive tasks. To this end, we introduce Agent S2, a novel compositional framework that delegates cognitive responsibilities across various generalist and specialist models. We propose a novel Mixture-of-Grounding technique to achieve precise GUI localization and introduce Proactive Hierarchical Planning, dynamically refining action plans at multiple temporal scales in response to evolving observations. Evaluations demonstrate that Agent S2 establishes new state-of-the-art (SOTA) performance on three prominent computer use benchmarks. Specifically, Agent S2 achieves 18.9% and 32.7% relative improvements over leading baseline agents such as Claude Computer Use and UI-TARS on the OSWorld 15-step and 50-step evaluation. Moreover, Agent S2 generalizes effectively to other operating systems and applications, surpassing previous best methods by 52.8% on WindowsAgentArena and by 16.52% on AndroidWorld relatively. Code available at <a target="_blank" rel="noopener" href="https://github.com/simular-ai/Agent-S">https://github.com/simular-ai/Agent-S</a>. </p>
<blockquote>
<p>è®¡ç®—æœºä½¿ç”¨ä»£ç†é€šè¿‡ç›´æ¥ä¸è®¡ç®—æœºå’Œç§»åŠ¨è®¾å¤‡ä¸Šçš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰è¿›è¡Œäº¤äº’ï¼Œè‡ªåŠ¨åŒ–æ•°å­—ä»»åŠ¡ï¼Œä»è€Œå®Œæˆäº†æ— é™çš„ç”¨æˆ·æŸ¥è¯¢ç©ºé—´ï¼Œæœ‰æ½œåŠ›å¤§å¹…æå‡äººç±»çš„ç”Ÿäº§åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†é¢ä¸´ç€é‡å¤§æŒ‘æˆ˜ï¼šGUIå…ƒç´ å®šä½ä¸å‡†ç¡®ã€é•¿æœŸè§„åˆ’å›°éš¾ä»¥åŠä¾èµ–å•ä¸€é€šç”¨æ¨¡å‹å¤„ç†å¤šæ ·è®¤çŸ¥ä»»åŠ¡å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†Agent S2ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„ç»„åˆæ¡†æ¶ï¼Œå¯ä»¥åœ¨å„ç§é€šç”¨å’Œä¸“ç”¨æ¨¡å‹ä¹‹é—´åˆ†é…è®¤çŸ¥è´£ä»»ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆå®šä½æŠ€æœ¯ï¼Œä»¥å®ç°ç²¾ç¡®çš„GUIå®šä½ï¼Œå¹¶å¼•å…¥äº†ä¸»åŠ¨åˆ†å±‚è§„åˆ’ï¼Œæ ¹æ®ä¸æ–­å˜åŒ–çš„è§‚å¯Ÿï¼Œåœ¨å¤šä¸ªæ—¶é—´å°ºåº¦ä¸ŠåŠ¨æ€ä¼˜åŒ–è¡ŒåŠ¨è®¡åˆ’ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒAgent S2åœ¨ä¸‰ä¸ªçªå‡ºçš„è®¡ç®—æœºä½¿ç”¨åŸºå‡†æµ‹è¯•ä¸Šåˆ›ä¸‹äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼ˆSOTAï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œç›¸è¾ƒäºé¢†å…ˆçš„åŸºçº¿ä»£ç†ï¼ˆå¦‚Claudeè®¡ç®—æœºä½¿ç”¨å’ŒUI-TARSï¼‰ï¼ŒAgent S2åœ¨OSWorldçš„15æ­¥å’Œ50æ­¥è¯„ä¼°ä¸Šåˆ†åˆ«å®ç°äº†ç›¸å¯¹æ”¹å–„18.9%å’Œ32.7%ã€‚æ­¤å¤–ï¼ŒAgent S2èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¨å¹¿åˆ°å…¶ä»–æ“ä½œç³»ç»Ÿå’Œåº”ç”¨ç¨‹åºä¸­ï¼Œåœ¨WindowsAgentArenaä¸Šç›¸è¾ƒäºä¹‹å‰æœ€å¥½çš„æ–¹æ³•æå‡äº†52.8%ï¼Œåœ¨AndroidWorldä¸Šæå‡äº†16.52%ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/simular-ai/Agent-S">https://github.com/simular-ai/Agent-S</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00906v1">PDF</a> 18 pages, 13 figures, 8 tables</p>
<p><strong>Summary</strong><br>     è®¡ç®—æœºä½¿ç”¨ä»£ç†èƒ½å¤Ÿè‡ªåŠ¨åŒ–å®Œæˆä¸€ç³»åˆ—æ•°å­—ä»»åŠ¡ï¼Œé€šè¿‡ä¸è®¡ç®—æœºå’Œç§»åŠ¨è®¾å¤‡çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ç›´æ¥äº¤äº’ï¼Œæé«˜äººç±»çš„ç”Ÿäº§æ•ˆç‡ã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†é¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚GUIå…ƒç´ å®šä½ä¸ç²¾ç¡®ã€é•¿æœŸä»»åŠ¡è§„åˆ’å›°éš¾å’Œå•ä¸€é€šç”¨æ¨¡å‹å¤„ç†å¤šæ ·è®¤çŸ¥ä»»åŠ¡æ—¶çš„æ€§èƒ½ç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Agent S2ï¼Œä¸€ä¸ªæ–°å‹çš„ç»„åˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†è®¤çŸ¥è´£ä»»åˆ†é…ç»™å¤šç§é€šç”¨å’Œä¸“ç”¨æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆå®šä½æŠ€æœ¯æ¥å®ç°ç²¾ç¡®çš„GUIå®šä½ï¼Œå¹¶å¼•å…¥äº†åˆ†å±‚è§„åˆ’ç­–ç•¥ï¼Œæ ¹æ®ä¸æ–­å˜åŒ–çš„è§‚å¯ŸåŠ¨æ€è°ƒæ•´è¡ŒåŠ¨è®¡åˆ’ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒAgent S2åœ¨ä¸‰ä¸ªä¸»æµçš„è®¡ç®—æœºä½¿ç”¨åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æ°´å¹³çš„è¡¨ç°ã€‚å…·ä½“æ¥è¯´ï¼Œç›¸è¾ƒäºé¢†å…ˆçš„åŸºå‡†ä»£ç†å¦‚Claudeè®¡ç®—æœºä½¿ç”¨å’ŒUI-TARSï¼ŒAgent S2åœ¨OSWorldçš„15æ­¥å’Œ50æ­¥æµ‹è¯•ä¸­åˆ†åˆ«å–å¾—äº†ç›¸å¯¹æ”¹è¿›ç‡çš„18.9%å’Œ32.7%ã€‚æ­¤å¤–ï¼ŒAgent S2åœ¨å…¶ä»–æ“ä½œç³»ç»Ÿå’Œåº”ç”¨ä¸­çš„è¡¨ç°ä¹Ÿéå¸¸å‡ºè‰²ï¼Œç›¸è¾ƒäºä¹‹å‰çš„æœ€ä½³æ–¹æ³•åˆ†åˆ«æœ‰äº†ä¸€å®šç¨‹åº¦çš„æå‡ã€‚ä»£ç å¯è®¿é—®äºï¼š<a target="_blank" rel="noopener" href="https://github.com/simular-ai/Agent-S%E3%80%82">https://github.com/simular-ai/Agent-Sã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¡ç®—æœºä½¿ç”¨ä»£ç†é€šè¿‡ç›´æ¥ä¸è®¡ç®—æœºå’Œç§»åŠ¨è®¾å¤‡çš„GUIäº¤äº’è‡ªåŠ¨åŒ–æ•°å­—ä»»åŠ¡ï¼Œæé«˜äººç±»ç”Ÿäº§æ•ˆç‡ã€‚</li>
<li>å½“å‰ä»£ç†é¢ä¸´GUIå…ƒç´ å®šä½ä¸ç²¾ç¡®ã€é•¿æœŸä»»åŠ¡è§„åˆ’å›°éš¾å’Œæ€§èƒ½ç“¶é¢ˆç­‰æŒ‘æˆ˜ã€‚</li>
<li>Agent S2æ˜¯ä¸€ä¸ªæ–°å‹çš„ç»„åˆæ¡†æ¶ï¼Œé€šè¿‡åˆ†é…è®¤çŸ¥è´£ä»»ç»™å¤šç§é€šç”¨å’Œä¸“ç”¨æ¨¡å‹æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>Agent S2é‡‡ç”¨æ··åˆå®šä½æŠ€æœ¯å’Œåˆ†å±‚è§„åˆ’ç­–ç•¥ï¼Œå®ç°ç²¾ç¡®GUIå®šä½å’ŒåŠ¨æ€è°ƒæ•´è¡ŒåŠ¨è®¡åˆ’ã€‚</li>
<li>Agent S2åœ¨ä¸‰ä¸ªä¸»æµçš„è®¡ç®—æœºä½¿ç”¨åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æ°´å¹³çš„è¡¨ç°ã€‚</li>
<li>Agent S2ç›¸è¾ƒäºå…¶ä»–ä»£ç†åœ¨OSWorldæµ‹è¯•ä¸­æœ‰æ˜¾è‘—çš„ç›¸å¯¹æ”¹è¿›ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00906">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-613774a88df6588914f052450cf8033d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3dcfe2d09b96f4d50f108240101ce910.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b33c75d762801cac769e5c92d7c0438e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec36aea520e4cf02f48430d1cbf11525.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Provably-Stable-Multi-Agent-Routing-with-Bounded-Delay-Adversaries-in-the-Decision-Loop"><a href="#Provably-Stable-Multi-Agent-Routing-with-Bounded-Delay-Adversaries-in-the-Decision-Loop" class="headerlink" title="Provably Stable Multi-Agent Routing with Bounded-Delay Adversaries in   the Decision Loop"></a>Provably Stable Multi-Agent Routing with Bounded-Delay Adversaries in   the Decision Loop</h2><p><strong>Authors:Roee M. Francos, Daniel Garces, Stephanie Gil</strong></p>
<p>In this work, we are interested in studying multi-agent routing settings, where adversarial agents are part of the assignment and decision loop, degrading the performance of the fleet by incurring bounded delays while servicing pickup-and-delivery requests. Specifically, we are interested in characterizing conditions on the fleet size and the proportion of adversarial agents for which a routing policy remains stable, where stability for a routing policy is achieved if the number of outstanding requests is uniformly bounded over time. To obtain this characterization, we first establish a threshold on the proportion of adversarial agents above which previously stable routing policies for fully cooperative fleets are provably unstable. We then derive a sufficient condition on the fleet size to recover stability given a maximum proportion of adversarial agents. We empirically validate our theoretical results on a case study on autonomous taxi routing, where we consider transportation requests from real San Francisco taxicab data. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨å¤šæ™ºèƒ½ä½“è·¯ç”±è®¾ç½®çš„ç ”ç©¶ï¼Œå…¶ä¸­å¯¹æŠ—æ€§æ™ºèƒ½ä½“æ˜¯åˆ†é…å’Œå†³ç­–å¾ªç¯çš„ä¸€éƒ¨åˆ†ï¼Œåœ¨æ‰§è¡Œæ¥é€è¯·æ±‚æœåŠ¡æ—¶ä¼šäº§ç”Ÿæœ‰é™çš„å»¶è¿Ÿï¼Œä»è€Œé™ä½è½¦é˜Ÿæ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯¹è½¦é˜Ÿè§„æ¨¡å’Œå¯¹æŠ—æ€§æ™ºèƒ½ä½“çš„æ¯”ä¾‹çš„æ¡ä»¶æ„Ÿå…´è¶£ï¼Œåœ¨è¿™äº›æ¡ä»¶ä¸‹ï¼Œè·¯ç”±ç­–ç•¥å¯ä»¥ä¿æŒç¨³å®šã€‚å¦‚æœæœªå®Œæˆçš„è¯·æ±‚æ•°é‡éšæ—¶é—´å‡åŒ€æœ‰ç•Œï¼Œåˆ™è·¯ç”±ç­–ç•¥è¢«è®¤ä¸ºæ˜¯ç¨³å®šçš„ã€‚ä¸ºäº†è·å¾—è¿™ç§ç‰¹æ€§æè¿°ï¼Œæˆ‘ä»¬é¦–å…ˆå»ºç«‹å¯¹æŠ—æ€§æ™ºèƒ½ä½“çš„æ¯”ä¾‹é˜ˆå€¼ï¼Œè¶…å‡ºæ­¤é˜ˆå€¼ä¹‹å‰é’ˆå¯¹å®Œå…¨åˆä½œè½¦é˜Ÿçš„ç¨³å®šè·¯ç”±ç­–ç•¥ä¼šæ˜æ˜¾ä¸ç¨³å®šã€‚ç„¶åï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºç»™å®šå¯¹æŠ—æ€§æ™ºèƒ½ä½“çš„æœ€å¤§æ¯”ä¾‹æƒ…å†µä¸‹æ¢å¤ç¨³å®šæ€§çš„è½¦é˜Ÿè§„æ¨¡çš„å……åˆ†æ¡ä»¶ã€‚æˆ‘ä»¬é€šè¿‡è‡ªåŠ¨é©¾é©¶å‡ºç§Ÿè½¦è·¯ç”±çš„æ¡ˆä¾‹åˆ†ææ¥å®è¯æˆ‘ä»¬çš„ç†è®ºç»“æœï¼Œå…¶ä¸­æˆ‘ä»¬è€ƒè™‘äº†æ¥è‡ªæ—§é‡‘å±±çœŸå®å‡ºç§Ÿè½¦æ•°æ®çš„äº¤é€šè¯·æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00863v1">PDF</a> 14 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶å…³æ³¨å¤šæ™ºèƒ½ä½“è·¯ç”±è®¾ç½®ï¼Œå…¶ä¸­å¯¹æŠ—æ€§æ™ºèƒ½ä½“æ˜¯åˆ†é…å’Œå†³ç­–å¾ªç¯çš„ä¸€éƒ¨åˆ†ï¼Œé€šè¿‡äº§ç”Ÿæœ‰ç•Œå»¶è¿Ÿæ¥é™ä½æœåŠ¡æ¥é€è¯·æ±‚çš„æ€§èƒ½ã€‚ç ”ç©¶é‡ç‚¹åœ¨äºç¡®å®šè½¦é˜Ÿè§„æ¨¡å’Œå¯¹æŠ—æ€§æ™ºèƒ½ä½“çš„æ¯”ä¾‹æ¡ä»¶ï¼Œåœ¨è¿™äº›æ¡ä»¶ä¸‹è·¯ç”±ç­–ç•¥ä¿æŒç¨³å®šæ€§ã€‚é€šè¿‡å»ºç«‹ä¸€ä¸ªå¯¹æŠ—æ€§æ™ºèƒ½ä½“æ¯”ä¾‹é˜ˆå€¼ï¼Œè¯æ˜è¶…å‡ºæ­¤é˜ˆå€¼ä¹‹å‰ç¨³å®šçš„è·¯ç”±ç­–ç•¥å¯¹äºå®Œå…¨åˆä½œçš„è½¦é˜Ÿæ˜¯ä¸ç¨³å®šçš„ã€‚ç„¶åï¼Œæ¨å¯¼å‡ºç»™å®šæœ€å¤§å¯¹æŠ—æ€§æ™ºèƒ½ä½“æ¯”ä¾‹çš„è½¦é˜Ÿè§„æ¨¡è¶³ä»¥æ¢å¤ç¨³å®šæ€§çš„å……åˆ†æ¡ä»¶ã€‚æœ¬ç ”ç©¶é€šè¿‡åŸºäºæ—§é‡‘å±±å‡ºç§Ÿè½¦æ•°æ®çš„è‡ªä¸»å‡ºç§Ÿè½¦è·¯ç”±æ¡ˆä¾‹ç ”ç©¶è¿›è¡Œäº†å®è¯éªŒè¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å…³æ³¨å¤šæ™ºèƒ½ä½“è·¯ç”±è®¾ç½®ä¸­å¯¹æŠ—æ€§æ™ºèƒ½ä½“çš„å½±å“ã€‚</li>
<li>å¯¹æŠ—æ€§æ™ºèƒ½ä½“ä¼šé™ä½æœåŠ¡æ¥é€è¯·æ±‚çš„æ€§èƒ½ï¼Œé€šè¿‡äº§ç”Ÿæœ‰ç•Œå»¶è¿Ÿæ¥å®ç°ã€‚</li>
<li>ç ”ç©¶æ—¨åœ¨ç¡®å®šè½¦é˜Ÿè§„æ¨¡å’Œå¯¹æŠ—æ€§æ™ºèƒ½ä½“çš„æ¯”ä¾‹æ¡ä»¶ä»¥ä¿æŒè·¯ç”±ç­–ç•¥çš„ç¨³å®šæ€§ã€‚</li>
<li>å»ºç«‹äº†å¯¹æŠ—æ€§æ™ºèƒ½ä½“æ¯”ä¾‹é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤é˜ˆå€¼ï¼Œä¹‹å‰ç¨³å®šçš„è·¯ç”±ç­–ç•¥ä¼šå˜å¾—ä¸ç¨³å®šã€‚</li>
<li>æ¨å¯¼å‡ºäº†ç»™å®šæœ€å¤§å¯¹æŠ—æ€§æ™ºèƒ½ä½“æ¯”ä¾‹æ—¶ï¼Œæ¢å¤ç¨³å®šæ€§çš„è½¦é˜Ÿè§„æ¨¡çš„å……åˆ†æ¡ä»¶ã€‚</li>
<li>ç ”ç©¶é€šè¿‡è‡ªä¸»å‡ºç§Ÿè½¦è·¯ç”±æ¡ˆä¾‹è¿›è¡Œäº†å®è¯éªŒè¯ï¼Œè¯¥æ¡ˆä¾‹åŸºäºæ—§é‡‘å±±çœŸå®çš„å‡ºç§Ÿè½¦æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00863">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4e404d231d27e81648c05e35d2d83d5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40c3cee6c0747ba568bc1f0dd230ada1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ffbd38c210f1be2a86a2e411830e6368.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="GraphMaster-Automated-Graph-Synthesis-via-LLM-Agents-in-Data-Limited-Environments"><a href="#GraphMaster-Automated-Graph-Synthesis-via-LLM-Agents-in-Data-Limited-Environments" class="headerlink" title="GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited   Environments"></a>GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited   Environments</h2><p><strong>Authors:Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang</strong></p>
<p>The era of foundation models has revolutionized AI research, yet Graph Foundation Models (GFMs) remain constrained by the scarcity of large-scale graph corpora. Traditional graph data synthesis techniques primarily focus on simplistic structural operations, lacking the capacity to generate semantically rich nodes with meaningful textual attributes: a critical limitation for real-world applications. While large language models (LLMs) demonstrate exceptional text generation capabilities, their direct application to graph synthesis is impeded by context window limitations, hallucination phenomena, and structural consistency challenges. To address these issues, we introduce GraphMaster, the first multi-agent framework specifically designed for graph data synthesis in data-limited environments. GraphMaster orchestrates four specialized LLM agents (Manager, Perception, Enhancement, and Evaluation) that collaboratively optimize the synthesis process through iterative refinement, ensuring both semantic coherence and structural integrity. To rigorously evaluate our approach, we create new data-limited â€œSubâ€ variants of six standard graph benchmarks, specifically designed to test synthesis capabilities under realistic constraints. Additionally, we develop a novel interpretability assessment framework that combines human evaluation with a principled Grassmannian manifold-based analysis, providing both qualitative and quantitative measures of semantic coherence. Experimental results demonstrate that GraphMaster significantly outperforms traditional synthesis methods across multiple datasets, establishing a strong foundation for advancing GFMs in data-scarce environments. </p>
<blockquote>
<p>æ—¶ä»£å·²ç»è¿›å…¥åŸºç¡€æ¨¡å‹çš„æ—¶ä»£ï¼Œè¿™å¼•å‘äº†äººå·¥æ™ºèƒ½ç ”ç©¶çš„é©å‘½ã€‚ç„¶è€Œï¼Œå›¾å½¢åŸºç¡€æ¨¡å‹ï¼ˆGFMsï¼‰ä»ç„¶å—åˆ°å¤§è§„æ¨¡å›¾å½¢è¯­æ–™åº“ç¨€ç¼ºçš„åˆ¶çº¦ã€‚ä¼ ç»Ÿçš„å›¾å½¢æ•°æ®åˆæˆæŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨ç®€å•çš„ç»“æ„æ“ä½œä¸Šï¼Œç¼ºä¹ç”Ÿæˆå…·æœ‰ä¸°å¯Œè¯­ä¹‰çš„èŠ‚ç‚¹å’Œå…·æœ‰æ„ä¹‰æ–‡æœ¬å±æ€§çš„èƒ½åŠ›ï¼šè¿™åœ¨ç°å®åº”ç”¨ä¸­æ˜¯å…³é”®çš„å±€é™æ€§ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬ç›´æ¥åº”ç”¨äºå›¾å½¢åˆæˆå´å—åˆ°ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€å¹»æƒ³ç°è±¡ä»¥åŠç»“æ„ä¸€è‡´æ€§æŒ‘æˆ˜çš„å½±å“ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†GraphMasterï¼Œè¿™æ˜¯ä¸“é—¨ä¸ºæ•°æ®æœ‰é™ç¯å¢ƒä¸­çš„å›¾å½¢æ•°æ®åˆæˆè®¾è®¡çš„é¦–ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚GraphMasteråè°ƒå››ä¸ªä¸“é—¨çš„å¤§å‹è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ï¼ˆç®¡ç†ã€æ„ŸçŸ¥ã€å¢å¼ºå’Œè¯„ä¼°ï¼‰ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–åˆä½œåˆæˆè¿‡ç¨‹ï¼Œç¡®ä¿è¯­ä¹‰è¿è´¯æ€§å’Œç»“æ„å®Œæ•´æ€§ã€‚ä¸ºäº†å¯¹æˆ‘ä»¬çš„æ–¹æ³•è¿›è¡Œä¸¥æ ¼è¯„ä¼°ï¼Œæˆ‘ä»¬åˆ›å»ºäº†å…­ä¸ªæ ‡å‡†å›¾å½¢åŸºå‡†æµ‹è¯•çš„æ–°æ•°æ®æœ‰é™â€œå­â€å˜ä½“ï¼Œä¸“é—¨è®¾è®¡ç”¨äºåœ¨çœŸå®çº¦æŸä¸‹æµ‹è¯•åˆæˆèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ–°é¢–çš„å¯è§£é‡Šæ€§è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†äººç±»è¯„ä¼°ä¸åŸºäºæ ¼æ‹‰æ–¯æ›¼æµå½¢ï¼ˆGrassmannian manifoldï¼‰çš„åˆ†æï¼Œæä¾›äº†è¯­ä¹‰è¿è´¯æ€§çš„å®šæ€§å’Œå®šé‡åº¦é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGraphMasteråœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿåˆæˆæ–¹æ³•ï¼Œä¸ºåœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸­æ¨è¿›GFMså¥ å®šäº†åšå®åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00711v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦è®¨è®ºäº†å›¾å½¢åŸºç¡€æ¨¡å‹ï¼ˆGFMsï¼‰å—é™äºå¤§è§„æ¨¡å›¾å½¢è¯­æ–™åº“çš„ç¼ºä¹çš„é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºGraphMasterçš„å¤šä»£ç†æ¡†æ¶ï¼Œç”¨äºæ•°æ®æœ‰é™ç¯å¢ƒä¸‹çš„å›¾å½¢æ•°æ®åˆæˆã€‚GraphMasteré€šè¿‡å››ä¸ªä¸“ä¸šçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼ˆManagerã€Perceptionã€Enhancementå’ŒEvaluationï¼‰ååŒä¼˜åŒ–åˆæˆè¿‡ç¨‹ï¼Œç¡®ä¿è¯­ä¹‰è¿è´¯æ€§å’Œç»“æ„å®Œæ•´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGraphMasteråœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿåˆæˆæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾å½¢åŸºç¡€æ¨¡å‹ï¼ˆGFMsï¼‰å—é™äºå¤§è§„æ¨¡å›¾å½¢è¯­æ–™åº“çš„ç¼ºä¹ã€‚</li>
<li>ä¼ ç»Ÿå›¾å½¢æ•°æ®åˆæˆæŠ€æœ¯ä¸»è¦å…³æ³¨ç®€å•çš„ç»“æ„æ“ä½œï¼Œç¼ºä¹ç”Ÿæˆå…·æœ‰ä¸°å¯Œè¯­ä¹‰çš„èŠ‚ç‚¹å’Œæœ‰æ„ä¹‰çš„æ–‡æœ¬å±æ€§çš„èƒ½åŠ›ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ç›´æ¥åº”ç”¨äºå›¾å½¢åˆæˆæ—¶é¢ä¸´ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€å¹»è§‰ç°è±¡å’Œç»“æ„ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚</li>
<li>GraphMasteræ˜¯é¦–ä¸ªä¸“é—¨ä¸ºæ•°æ®æœ‰é™ç¯å¢ƒä¸‹çš„å›¾å½¢æ•°æ®åˆæˆè®¾è®¡çš„å¤šä»£ç†æ¡†æ¶ã€‚</li>
<li>GraphMasteré€šè¿‡å››ä¸ªä¸“ä¸šçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ååŒå·¥ä½œï¼Œä¼˜åŒ–åˆæˆè¿‡ç¨‹ï¼Œç¡®ä¿è¯­ä¹‰è¿è´¯æ€§å’Œç»“æ„å®Œæ•´æ€§ã€‚</li>
<li>GraphMasteråœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿåˆæˆæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00711">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-217a312edf7aa63e31739006923a9b25.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a59eb35ad391f4a495b749ddb3dca383.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Exploring-the-Impact-of-an-LLM-Powered-Teachable-Agent-on-Learning-Gains-and-Cognitive-Load-in-Music-Education"><a href="#Exploring-the-Impact-of-an-LLM-Powered-Teachable-Agent-on-Learning-Gains-and-Cognitive-Load-in-Music-Education" class="headerlink" title="Exploring the Impact of an LLM-Powered Teachable Agent on Learning Gains   and Cognitive Load in Music Education"></a>Exploring the Impact of an LLM-Powered Teachable Agent on Learning Gains   and Cognitive Load in Music Education</h2><p><strong>Authors:Lingxi Jin, Baicheng Lin, Mengze Hong, Kun Zhang, Hyo-Jeong So</strong></p>
<p>This study examines the impact of an LLM-powered teachable agent, grounded in the Learning by Teaching (LBT) pedagogy, on studentsâ€™ music theory learning and cognitive load. The participants were 28 Chinese university students with prior music instrumental experiences. In an online experiment, they were assigned to either an experimental group, which engaged in music analysis with the teachable agent, or a control group, which conducted self-directed analysis using instructional materials. Findings indicate that students in the experimental group achieved significantly higher post-test scores than those in the control group. Additionally, they reported lower cognitive load, suggesting that the teachable agent effectively reduced the cognitive demands of music analysis tasks. These results highlight the potential of AI-driven scaffolding based on LBT principles to enhance music theory education, supporting teachers in delivering theory-oriented instruction while fostering studentsâ€™ self-directed learning skills. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æ¢è®¨äº†åŸºäºå­¦ä¹ å¼æ•™å­¦ï¼ˆLBTï¼‰æ•™å­¦æ³•ï¼Œç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¯æ•™å­¦ä»£ç†å¯¹å­¦ç”ŸéŸ³ä¹ç†è®ºå­¦ä¹ å’Œè®¤çŸ¥è´Ÿè·çš„å½±å“ã€‚å‚ä¸è€…ä¸º28åæœ‰éŸ³ä¹ä»ªå™¨ç»éªŒçš„ä¸­å›½å¤§å­¦ç”Ÿã€‚åœ¨ä¸€ä¸ªåœ¨çº¿å®éªŒä¸­ï¼Œä»–ä»¬è¢«åˆ†é…ä¸ºå®éªŒç»„å’Œå¯¹ç…§ç»„ã€‚å®éªŒç»„å­¦ç”Ÿä¸å¯æ•™å­¦ä»£ç†è¿›è¡ŒéŸ³ä¹åˆ†æï¼Œè€Œå¯¹ç…§ç»„å­¦ç”Ÿåˆ™ä½¿ç”¨æ•™å­¦ææ–™è¿›è¡Œè‡ªæˆ‘å¯¼å‘åˆ†æã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå®éªŒç»„å­¦ç”Ÿçš„åæµ‹æˆç»©æ˜¾è‘—é«˜äºå¯¹ç…§ç»„ã€‚æ­¤å¤–ï¼Œä»–ä»¬æŠ¥å‘Šçš„è®¤çŸ¥è´Ÿè·è¾ƒä½ï¼Œè¿™è¡¨æ˜å¯æ•™å­¦ä»£ç†æœ‰æ•ˆåœ°é™ä½äº†éŸ³ä¹åˆ†æä»»åŠ¡çš„è®¤çŸ¥è¦æ±‚ã€‚è¿™äº›ç»“æœçªå‡ºäº†åŸºäºLBTåŸç†çš„äººå·¥æ™ºèƒ½é©±åŠ¨çš„è„šæ‰‹æ¶åœ¨å¢å¼ºéŸ³ä¹ç†è®ºæ•™è‚²æ–¹é¢çš„æ½œåŠ›ï¼Œæ”¯æŒæ•™å¸ˆæä¾›ç†è®ºå¯¼å‘çš„æ•™å­¦ï¼ŒåŒæ—¶åŸ¹å…»å­¦ç”Ÿçš„è‡ªæˆ‘å¯¼å‘å­¦ä¹ èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00636v1">PDF</a> Accepted at CHI 2025 Workshop on Augmented Educators and AI: Shaping   the Future of Human and AI Cooperation in Learning</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶æ¢è®¨äº†åŸºäºå­¦ä¹ é€šè¿‡æ•™å­¦ï¼ˆLBTï¼‰æ•™å­¦æ³•çš„å¯æ•™å­¦ä»£ç†ï¼ˆç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨ï¼‰å¯¹å­¦ç”ŸéŸ³ä¹ç†è®ºå­¦ä¹ åŠè®¤çŸ¥è´Ÿè·çš„å½±å“ã€‚ç ”ç©¶å¯¹è±¡ä¸ºæ‹¥æœ‰éŸ³ä¹æ¼”å¥ç»éªŒçš„28åä¸­å›½å¤§å­¦ç”Ÿã€‚åœ¨ä¸€é¡¹åœ¨çº¿å®éªŒä¸­ï¼Œè¿™äº›å­¦ç”Ÿè¢«åˆ†é…åˆ°å®éªŒç»„å’Œå¯¹ç…§ç»„ä¸¤ç»„ï¼Œå®éªŒç»„å­¦ç”Ÿä½¿ç”¨å¯æ•™å­¦ä»£ç†è¿›è¡ŒéŸ³ä¹åˆ†æï¼Œè€Œå¯¹ç…§ç»„å­¦ç”Ÿåˆ™ä½¿ç”¨æ•™å­¦ææ–™è¿›è¡Œè‡ªä¸»å­¦ä¹ åˆ†æã€‚ç»“æœè¡¨æ˜ï¼Œå®éªŒç»„å­¦ç”Ÿåœ¨æµ‹è¯•åçš„æˆç»©æ˜¾è‘—é«˜äºå¯¹ç…§ç»„ã€‚æ­¤å¤–ï¼Œä»–ä»¬æŠ¥å‘Šçš„è®¤çŸ¥è´Ÿè·è¾ƒä½ï¼Œè¡¨æ˜å¯æ•™å­¦ä»£ç†æœ‰æ•ˆåœ°å‡è½»äº†éŸ³ä¹åˆ†æä»»åŠ¡çš„è®¤çŸ¥è¦æ±‚ã€‚è¿™äº›ç»“æœçªæ˜¾äº†åŸºäºLBTåŸåˆ™çš„AIé©±åŠ¨çš„è„šæ‰‹æ¶åœ¨å¢å¼ºéŸ³ä¹ç†è®ºæ•™è‚²æ–¹é¢çš„æ½œåŠ›ï¼Œæ”¯æŒæ•™å¸ˆæä¾›ç†è®ºå¯¼å‘çš„æ•™å­¦ï¼ŒåŒæ—¶åŸ¹å…»å­¦ç”Ÿçš„è‡ªä¸»å­¦ä¹ èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶å…³æ³¨å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ•™è¾…åŠ©åŠ©ç†å¯¹éŸ³ä¹ç†è®ºå­¦ä¹ çš„æ½œåœ¨å½±å“ã€‚ç ”ç©¶å¯¹è±¡æ˜¯å…·æœ‰éŸ³ä¹ç»éªŒçš„å¤§å­¦ç”Ÿã€‚è¿™äº›å‚ä¸è€…æ¥å—äº†åœ¨çº¿å®éªŒã€‚</li>
<li>ç ”ç©¶å‚ä¸è€…è¢«åˆ†ä¸ºå®éªŒç»„å’Œå¯¹ç…§ç»„ã€‚å®éªŒç»„ä½¿ç”¨å¯æ•™å­¦ä»£ç†è¿›è¡ŒéŸ³ä¹åˆ†æä»»åŠ¡ï¼Œè€Œå¯¹ç…§ç»„ä½¿ç”¨å¸¸è§„çš„æ•™å­¦ææ–™è‡ªä¸»å­¦ä¹ åˆ†æã€‚å¯¹æ¯”åˆ†æäº†è¿™ä¸¤ç»„å­¦ç”Ÿçš„å­¦ä¹ æˆæœå’Œè®¤çŸ¥è´Ÿè·çŠ¶å†µã€‚</li>
<li>ç ”ç©¶å‘ç°å®éªŒç»„å­¦ç”Ÿåœ¨éŸ³ä¹ç†è®ºæµ‹è¯•ä¸­çš„æˆç»©æ˜¾è‘—é«˜äºå¯¹ç…§ç»„å­¦ç”Ÿã€‚è¿™è¡¨æ˜å¯æ•™å­¦ä»£ç†åœ¨æå‡éŸ³ä¹ç†è®ºå­¦ä¹ æ–¹é¢è¡¨ç°å‡ºç§¯æå½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00636">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-606d65153448dc64118738363a11b05b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-38bc8ccdbeb01367815184d39ed7e0b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9d9c6a9bb990e2bf0ae1aec4c2cbdc3b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d474e3a6aeac3864bebc1b13aae96e57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31baa6382f533120a48bae48bf6811de.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="CVE-Bench-A-Benchmark-for-AI-Agentsâ€™-Ability-to-Exploit-Real-World-Web-Application-Vulnerabilities"><a href="#CVE-Bench-A-Benchmark-for-AI-Agentsâ€™-Ability-to-Exploit-Real-World-Web-Application-Vulnerabilities" class="headerlink" title="CVE-Bench: A Benchmark for AI Agentsâ€™ Ability to Exploit Real-World Web   Application Vulnerabilities"></a>CVE-Bench: A Benchmark for AI Agentsâ€™ Ability to Exploit Real-World Web   Application Vulnerabilities</h2><p><strong>Authors:Yuxuan Zhu, Antony Kellermann, Dylan Bowman, Philip Li, Akul Gupta, Adarsh Danda, Richard Fang, Conner Jensen, Eric Ihli, Jason Benn, Jet Geronimo, Avi Dhir, Sudhit Rao, Kaicheng Yu, Twm Stone, Daniel Kang</strong></p>
<p>Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†èƒ½å¤Ÿè¶Šæ¥è¶Šè‡ªä¸»åœ°å¼€å±•ç½‘ç»œæ”»å‡»ï¼Œå¯¹ç°æœ‰åº”ç”¨æ„æˆé‡å¤§å¨èƒã€‚è¿™ç§æ—¥ç›Šå¢é•¿çš„é£é™©çªæ˜¾äº†ç°å®ä¸–ç•ŒåŸºå‡†æµ‹è¯•è¯„ä¼°LLMä»£ç†åˆ©ç”¨ç½‘é¡µåº”ç”¨æ¼æ´èƒ½åŠ›çš„è¿«åˆ‡éœ€æ±‚ã€‚ç„¶è€Œï¼Œç°æœ‰åŸºå‡†æµ‹è¯•è¾¾ä¸åˆ°è¦æ±‚ï¼Œä»…é™äºæŠ½è±¡çš„å¤ºæ——ç«èµ›æˆ–ç¼ºä¹å…¨é¢è¦†ç›–ã€‚æ„å»ºé’ˆå¯¹ç°å®ä¸–ç•Œæ¼æ´çš„åŸºå‡†æµ‹è¯•éœ€è¦ä¸“ä¸šçŸ¥è¯†å’ŒæŠ€èƒ½æ¥é‡ç°æ¼æ´å¹¶åˆ©ç”¨ç³»ç»Ÿæ–¹æ³•æ¥è¯„ä¼°ä¸å¯é¢„æµ‹çš„å¨èƒã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CVE-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå…³é”®ä¸¥é‡æ€§å¸¸è§æ¼æ´å’Œæš´éœ²çš„ç½‘ç»œå®‰å…¨åŸºå‡†æµ‹è¯•ã€‚åœ¨CVE-Benchä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ²™ç®±æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿å¾—LLMä»£ç†èƒ½å¤Ÿåˆ©ç”¨å­˜åœ¨ç¼ºé™·çš„ç½‘ç»œåº”ç”¨è¿›è¡Œæµ‹è¯•åœºæ™¯çš„æ¼”ç»ƒæ¨¡ä»¿ç°å®ä¸–ç•Œçš„æƒ…å†µï¼ŒåŒæ—¶è¿˜å¯ä»¥æœ‰æ•ˆè¯„ä¼°è¿™äº›ç¼ºé™·æ”»å‡»çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œæœ€å…ˆè¿›çš„ä»£ç†æ¡†æ¶å¯ä»¥è§£å†³é«˜è¾¾ç™¾åˆ†ä¹‹åä¸‰çš„æ¼æ´é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17332v2">PDF</a> 15 pages, 4 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†èƒ½å¤Ÿè‡ªä¸»è¿›è¡Œç½‘ç»œæ”»å‡»ï¼Œå¯¹ç°æœ‰åº”ç”¨æ„æˆé‡å¤§å¨èƒã€‚å½“å‰ç¼ºä¹ä¸€ä¸ªç°å®ä¸–ç•ŒåŸºå‡†æ¥è¡¡é‡LLMä»£ç†åˆ©ç”¨ç½‘ç»œåº”ç”¨æ¼æ´çš„èƒ½åŠ›ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºCVE-Benchï¼Œä¸€ä¸ªåŸºäºå…³é”®ä¸¥é‡æ€§å¸¸è§æ¼æ´ï¼ˆCVEï¼‰çš„ç°å®ä¸–ç•Œç½‘ç»œå®‰å…¨åŸºå‡†æµ‹è¯•å¹³å°ã€‚CVE-Benchè®¾è®¡ä¸€ä¸ªæ²™ç®±æ¡†æ¶ï¼Œèƒ½åœ¨æ¨¡æ‹ŸçœŸå®åœºæ™¯çš„åŒæ—¶ï¼Œè¯„ä¼°LLMä»£ç†å¯¹è„†å¼±ç½‘ç»œåº”ç”¨çš„æ”»å‡»æ•ˆæœã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œç›®å‰æœ€å…ˆè¿›çš„ä»£ç†æ¡†æ¶èƒ½è§£å†³é«˜è¾¾13%çš„æ¼æ´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†èƒ½å¤Ÿè‡ªä¸»è¿›è¡Œç½‘ç»œæ”»å‡»ï¼Œå¯¹ç°æœ‰åº”ç”¨æ„æˆå¨èƒã€‚</li>
<li>ç¼ºä¹ä¸€ä¸ªè¡¡é‡LLMä»£ç†åˆ©ç”¨ç½‘ç»œåº”ç”¨æ¼æ´èƒ½åŠ›çš„ç°å®ä¸–ç•ŒåŸºå‡†ã€‚</li>
<li>CVE-Benchæ˜¯ä¸€ä¸ªåŸºäºå…³é”®ä¸¥é‡æ€§å¸¸è§æ¼æ´ï¼ˆCVEï¼‰çš„ç°å®ä¸–ç•Œç½‘ç»œå®‰å…¨åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>CVE-Benchè®¾è®¡ä¸€ä¸ªæ²™ç®±æ¡†æ¶æ¥è¯„ä¼°LLMä»£ç†çš„æ”»å‡»æ•ˆæœã€‚</li>
<li>æ²™ç®±æ¡†æ¶èƒ½åœ¨æ¨¡æ‹ŸçœŸå®åœºæ™¯çš„åŒæ—¶æµ‹è¯•è„†å¼±ç½‘ç»œåº”ç”¨çš„æ”»å‡»æ•ˆæœã€‚</li>
<li>æœ€å…ˆè¿›çš„ä»£ç†æ¡†æ¶èƒ½è§£å†³é«˜è¾¾13%çš„æ¼æ´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9cebc9712c4c956aff028015b27ac394.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0c212dfa8b7fb62a7aed512c3558b358.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6011146f1c3dac1853736ced504f3bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e4d2bb0c7f0c0b307f1546605a91149.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd427d7da13bce46d43cfb750791cb93.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Knowledge-Aware-Iterative-Retrieval-for-Multi-Agent-Systems"><a href="#Knowledge-Aware-Iterative-Retrieval-for-Multi-Agent-Systems" class="headerlink" title="Knowledge-Aware Iterative Retrieval for Multi-Agent Systems"></a>Knowledge-Aware Iterative Retrieval for Multi-Agent Systems</h2><p><strong>Authors:Seyoung Song</strong></p>
<p>We introduce a novel large language model (LLM)-driven agent framework, which iteratively refines queries and filters contextual evidence by leveraging dynamically evolving knowledge. A defining feature of the system is its decoupling of external sources from an internal knowledge cache that is progressively updated to guide both query generation and evidence selection. This design mitigates bias-reinforcement loops and enables dynamic, trackable search exploration paths, thereby optimizing the trade-off between exploring diverse information and maintaining accuracy through autonomous agent decision-making. Our approach is evaluated on a broad range of open-domain question answering benchmarks, including multi-step tasks that mirror real-world scenarios where integrating information from multiple sources is critical, especially given the vulnerabilities of LLMs that lack explicit reasoning or planning capabilities. The results show that the proposed system not only outperforms single-step baselines regardless of task difficulty but also, compared to conventional iterative retrieval methods, demonstrates pronounced advantages in complex tasks through precise evidence-based reasoning and enhanced efficiency. The proposed system supports both competitive and collaborative sharing of updated context, enabling multi-agent extension. The benefits of multi-agent configurations become especially prominent as task difficulty increases. The number of convergence steps scales with task difficulty, suggesting cost-effective scalability. </p>
<blockquote>
<p>æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä»£ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨åŠ¨æ€æ¼”åŒ–çš„çŸ¥è¯†æ¥è¿­ä»£ä¼˜åŒ–æŸ¥è¯¢å’Œè¿‡æ»¤ä¸Šä¸‹æ–‡è¯æ®ã€‚è¯¥ç³»ç»Ÿçš„ç‰¹ç‚¹æ˜¯å°†å…¶å¤–éƒ¨æ¥æºä¸å†…éƒ¨çŸ¥è¯†ç¼“å­˜ç›¸åˆ†ç¦»ï¼Œè¯¥å†…éƒ¨çŸ¥è¯†ç¼“å­˜ä¼šä¸æ–­æ›´æ–°ï¼Œä»¥æŒ‡å¯¼æŸ¥è¯¢ç”Ÿæˆå’Œè¯æ®é€‰æ‹©ã€‚è¿™ç§è®¾è®¡å‡è½»äº†åè§åŠ å¼ºå¾ªç¯ï¼Œå¹¶å®ç°äº†åŠ¨æ€ã€å¯è¿½è¸ªçš„æœç´¢æ¢ç´¢è·¯å¾„ï¼Œä»è€Œåœ¨æ¢ç´¢å¤šæ ·åŒ–ä¿¡æ¯å’Œé€šè¿‡è‡ªä¸»ä»£ç†å†³ç­–ä¿æŒå‡†ç¡®æ€§ä¹‹é—´è¿›è¡Œäº†ä¼˜åŒ–æƒè¡¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¹¿æ³›çš„å¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬å¤šæ­¥éª¤ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡åæ˜ äº†éœ€è¦ä»å¤šä¸ªæºé›†æˆä¿¡æ¯çš„ç°å®ä¸–ç•Œåœºæ™¯è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯è€ƒè™‘åˆ°ç¼ºä¹æ˜ç¡®æ¨ç†æˆ–è§„åˆ’èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„è„†å¼±æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç³»ç»Ÿä¸ä»…åœ¨å„ç§ä»»åŠ¡éš¾åº¦ä¸Šéƒ½ä¼˜äºå•æ­¥éª¤åŸºå‡†æµ‹è¯•ï¼Œè€Œä¸”ä¸ä¼ ç»Ÿçš„è¿­ä»£æ£€ç´¢æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­é€šè¿‡ç²¾ç¡®çš„åŸºäºè¯æ®çš„æ¨ç†å’Œæ•ˆç‡æå‡è¡¨ç°å‡ºäº†æ˜æ˜¾ä¼˜åŠ¿ã€‚æ‰€æå‡ºç³»ç»Ÿæ”¯æŒç«äº‰æ€§å’Œåä½œæ€§å…±äº«æ›´æ–°åçš„ä¸Šä¸‹æ–‡ï¼Œå¯å®ç°å¤šæ™ºèƒ½ä½“æ‰©å±•ã€‚éšç€ä»»åŠ¡éš¾åº¦çš„å¢åŠ ï¼Œå¤šæ™ºèƒ½ä½“é…ç½®çš„ä¼˜åŠ¿å˜å¾—å°¤ä¸ºçªå‡ºã€‚æ”¶æ•›æ­¥éª¤çš„æ•°é‡éšä»»åŠ¡éš¾åº¦çš„å¢åŠ è€Œå¢åŠ ï¼Œè¡¨æ˜æˆæœ¬æ•ˆç›Šå¯è§„æ¨¡åŒ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13275v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°å‹ä»£ç†æ¡†æ¶èƒ½å¤Ÿè¿­ä»£ä¼˜åŒ–æŸ¥è¯¢å¹¶è¿‡æ»¤ä¸Šä¸‹æ–‡è¯æ®ï¼Œåˆ©ç”¨åŠ¨æ€æ¼”å˜çš„çŸ¥è¯†åº“ä½œä¸ºæ”¯æ’‘ã€‚é€šè¿‡å°†å¤–éƒ¨æ¥æºä¸å†…éƒ¨çŸ¥è¯†ç¼“å­˜åˆ†ç¦»ï¼Œè¯¥æ¡†æ¶åœ¨æŒ‡å¯¼æŸ¥è¯¢ç”Ÿæˆå’Œè¯æ®é€‰æ‹©æ—¶èƒ½å¤Ÿä¸æ–­æ›´æ–°ï¼Œé¿å…äº†åè§å¼ºåŒ–å¾ªç¯ï¼Œå®ç°äº†åŠ¨æ€ã€å¯è¿½è¸ªçš„æœç´¢æ¢ç´¢è·¯å¾„ï¼Œä¼˜åŒ–äº†æ¢ç´¢å¤šæ ·ä¿¡æ¯ä¸ç»´æŒå‡†ç¡®åº¦çš„æƒè¡¡ï¼Œé€šè¿‡è‡ªä¸»ä»£ç†å†³ç­–å®ç°ã€‚è¯¥æ¡†æ¶åœ¨å¤šé¢†åŸŸå¼€æ”¾é—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•´åˆå¤šæºä¿¡æ¯çš„é‡è¦ç°å®åœºæ™¯ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚å…¶ç²¾ç¡®çš„è¯æ®æ¨ç†å’Œé«˜æ•ˆæ€§ä½¿å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­ç›¸æ¯”ä¼ ç»Ÿè¿­ä»£æ£€ç´¢æ–¹æ³•æ›´å…·ä¼˜åŠ¿ã€‚åŒæ—¶æ”¯æŒç«äº‰æ€§å’Œåä½œæ€§å…±äº«æ›´æ–°ä¸Šä¸‹æ–‡ï¼Œæ˜“äºå®ç°å¤šä»£ç†æ‰©å±•ï¼Œéšç€ä»»åŠ¡éš¾åº¦çš„å¢åŠ ï¼Œå¤šä»£ç†é…ç½®çš„ä¼˜åŠ¿å°¤ä¸ºçªå‡ºã€‚è¯¥æ¡†æ¶éšç€ä»»åŠ¡éš¾åº¦çš„å¢åŠ å…·æœ‰æˆæœ¬æ•ˆç›Šçš„å¯æ‰©å±•æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°å‹ä»£ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿåˆ©ç”¨åŠ¨æ€æ¼”å˜çš„çŸ¥è¯†åº“è¿›è¡Œè¿­ä»£æŸ¥è¯¢ä¼˜åŒ–å’Œä¸Šä¸‹æ–‡è¯æ®è¿‡æ»¤ã€‚</li>
<li>é€šè¿‡å°†å¤–éƒ¨æ¥æºä¸å†…éƒ¨çŸ¥è¯†ç¼“å­˜åˆ†ç¦»è®¾è®¡ï¼Œæ›´æ–°æŒ‡å¯¼æŸ¥è¯¢ç”Ÿæˆå’Œè¯æ®é€‰æ‹©è¿‡ç¨‹ï¼Œé¿å…äº†åè§å¼ºåŒ–å¾ªç¯ã€‚</li>
<li>å®ç°åŠ¨æ€ã€å¯è¿½è¸ªçš„æœç´¢æ¢ç´¢è·¯å¾„ï¼Œä¼˜åŒ–äº†æ¢ç´¢å¤šæ ·ä¿¡æ¯ä¸ç»´æŒå‡†ç¡®åº¦çš„æƒè¡¡ã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨å¤šé¢†åŸŸå¼€æ”¾é—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜ç§€ï¼Œç‰¹åˆ«æ˜¯æ•´åˆå¤šæºä¿¡æ¯çš„åœºæ™¯ä¸­ã€‚</li>
<li>ä¸ä¼ ç»Ÿè¿­ä»£æ£€ç´¢æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨å¤æ‚ä»»åŠ¡ä¸­å±•ç°å‡ºç²¾ç¡®çš„è¯æ®æ¨ç†å’Œé«˜æ•ˆæ€§ã€‚</li>
<li>æ”¯æŒç«äº‰æ€§å’Œåä½œæ€§å…±äº«æ›´æ–°ä¸Šä¸‹æ–‡ï¼Œæ˜“äºå®ç°å¤šä»£ç†æ‰©å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13275">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-35a3a415ee922a5b55f74e24e7096d8b.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="DAgent-A-Relational-Database-Driven-Data-Analysis-Report-Generation-Agent"><a href="#DAgent-A-Relational-Database-Driven-Data-Analysis-Report-Generation-Agent" class="headerlink" title="DAgent: A Relational Database-Driven Data Analysis Report Generation   Agent"></a>DAgent: A Relational Database-Driven Data Analysis Report Generation   Agent</h2><p><strong>Authors:Wenyi Xu, Yuren Mao, Xiaolu Zhang, Chao Zhang, Xuemei Dong, Mengfei Zhang, Yunjun Gao</strong></p>
<p>Relational database-driven data analysis (RDB-DA) report generation, which aims to generate data analysis reports after querying relational databases, has been widely applied in fields such as finance and healthcare. Typically, these tasks are manually completed by data scientists, making the process very labor-intensive and showing a clear need for automation. Although existing methods (e.g., Table QA or Text-to-SQL) have been proposed to reduce human dependency, they cannot handle complex analytical tasks that require multi-step reasoning, cross-table associations, and synthesizing insights into reports. Moreover, there is no dataset available for developing automatic RDB-DA report generation. To fill this gap, this paper proposes an LLM agent system for RDB-DA report generation tasks, dubbed DAgent; moreover, we construct a benchmark for automatic data analysis report generation, which includes a new dataset DA-Dataset and evaluation metrics. DAgent integrates planning, tools, and memory modules to decompose natural language questions into logically independent sub-queries, accurately retrieve key information from relational databases, and generate analytical reports that meet the requirements of completeness, correctness, and conciseness through multi-step reasoning and effective data integration. Experimental analysis on the DA-Dataset demonstrates that DAgentâ€™s superiority in retrieval performance and analysis report generation quality, showcasing its strong potential for tackling complex database analysis report generation tasks. </p>
<blockquote>
<p>å…³ç³»æ•°æ®åº“é©±åŠ¨çš„æ•°æ®åˆ†æï¼ˆRDB-DAï¼‰æŠ¥å‘Šç”Ÿæˆï¼Œæ—¨åœ¨æŸ¥è¯¢å…³ç³»æ•°æ®åº“åç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Šï¼Œå·²å¹¿æ³›åº”ç”¨äºé‡‘èã€åŒ»ç–—ç­‰é¢†åŸŸã€‚é€šå¸¸ï¼Œè¿™äº›ä»»åŠ¡æ˜¯ç”±æ•°æ®ç§‘å­¦å®¶æ‰‹åŠ¨å®Œæˆçš„ï¼Œè¿™ä½¿å¾—è¿‡ç¨‹éå¸¸åŠ³åŠ¨å¯†é›†ï¼Œå¹¶æ˜¾ç¤ºå‡ºå¯¹è‡ªåŠ¨åŒ–çš„æ˜ç¡®éœ€æ±‚ã€‚å°½ç®¡å·²æå‡ºäº†ä¸€äº›ç°æœ‰æ–¹æ³•ï¼ˆä¾‹å¦‚è¡¨æ ¼é—®ç­”æˆ–æ–‡æœ¬åˆ°SQLï¼‰ï¼Œä½†å®ƒä»¬æ— æ³•å¤„ç†å¤æ‚çš„åˆ†æä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡éœ€è¦å¤šæ­¥éª¤æ¨ç†ã€è·¨è¡¨å…³è”å’Œå°†è§è§£ç»¼åˆæˆæŠ¥å‘Šã€‚è€Œä¸”ï¼Œç›®å‰æ²¡æœ‰å¯ç”¨äºå¼€å‘è‡ªåŠ¨RDB-DAæŠ¥å‘Šç”Ÿæˆçš„æ•°æ®é›†ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºRDB-DAæŠ¥å‘Šç”Ÿæˆä»»åŠ¡çš„å¤§å‹è¯­è¨€æ¨¡å‹agentç³»ç»Ÿï¼Œç§°ä¸ºDAgentï¼›æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç”¨äºè‡ªåŠ¨æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆçš„æ ‡å‡†ï¼Œå…¶ä¸­åŒ…æ‹¬æ–°çš„æ•°æ®é›†DA-Datasetå’Œè¯„ä¼°æŒ‡æ ‡ã€‚DAgenté›†æˆäº†è§„åˆ’ã€å·¥å…·å’Œè®°å¿†æ¨¡å—ï¼Œå°†è‡ªç„¶è¯­è¨€é—®é¢˜åˆ†è§£ä¸ºé€»è¾‘ä¸Šç‹¬ç«‹çš„å­æŸ¥è¯¢ï¼Œå‡†ç¡®åœ°ä»å…³ç³»æ•°æ®åº“ä¸­æ£€ç´¢å…³é”®ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¤šæ­¥éª¤æ¨ç†å’Œæœ‰æ•ˆçš„æ•°æ®é›†æˆç”Ÿæˆç¬¦åˆå®Œæ•´æ€§ã€æ­£ç¡®æ€§å’Œç®€æ´æ€§è¦æ±‚çš„åˆ†ææŠ¥å‘Šã€‚åœ¨DA-Datasetä¸Šçš„å®éªŒåˆ†æè¯æ˜äº†DAgentåœ¨æ£€ç´¢æ€§èƒ½å’Œåˆ†ææŠ¥å‘Šç”Ÿæˆè´¨é‡ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†å¤æ‚æ•°æ®åº“åˆ†ææŠ¥å‘Šç”Ÿæˆä»»åŠ¡æ–¹é¢çš„å¼ºå¤§æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13269v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å…³ç³»å‹æ•°æ®åº“é©±åŠ¨çš„æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆï¼ˆRDB-DAï¼‰æ—¨åœ¨æŸ¥è¯¢å…³ç³»å‹æ•°æ®åº“åç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Šï¼Œå¹¿æ³›åº”ç”¨äºé‡‘èã€åŒ»ç–—ç­‰é¢†åŸŸã€‚ç°æœ‰æ–¹æ³•å¦‚è¡¨æ ¼é—®ç­”æˆ–æ–‡æœ¬åˆ°SQLè™½èƒ½å‡å°‘äººå·¥ä¾èµ–ï¼Œä½†éš¾ä»¥å¤„ç†éœ€è¦å¤šæ­¥éª¤æ¨ç†ã€è·¨è¡¨å…³è”å’Œç»¼åˆåˆ†ææ´å¯Ÿçš„æŠ¥å‘Šç­‰å¤æ‚åˆ†æä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºLLMä»£ç†ç³»ç»ŸDAgentç”¨äºRDB-DAæŠ¥å‘Šç”Ÿæˆä»»åŠ¡ï¼Œå¹¶æ„å»ºæ•°æ®é›†DA-Datasetå’Œè¯„ä¼°æŒ‡æ ‡åŸºå‡†ï¼Œå®ç°è‡ªç„¶è¯­è¨€é—®é¢˜åˆ†è§£ã€æ•°æ®åº“å…³é”®ä¿¡æ¯å‡†ç¡®æ£€ç´¢ã€åˆ†ææŠ¥å‘Šç”Ÿæˆç­‰åŠŸèƒ½ã€‚å®éªŒåˆ†æè¯æ˜DAgentåœ¨æ£€ç´¢æ€§èƒ½å’Œåˆ†ææŠ¥å‘Šç”Ÿæˆè´¨é‡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…³ç³»å‹æ•°æ®åº“é©±åŠ¨çš„æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆï¼ˆRDB-DAï¼‰åœ¨å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†å¤æ‚çš„åˆ†æä»»åŠ¡ï¼Œéœ€è¦è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚</li>
<li>æå‡ºLLMä»£ç†ç³»ç»ŸDAgentç”¨äºRDB-DAæŠ¥å‘Šç”Ÿæˆï¼Œå…·å¤‡è§„åˆ’ã€å·¥å…·å’Œè®°å¿†æ¨¡å—ã€‚</li>
<li>æ„å»ºæ•°æ®é›†DA-Datasetå’Œè¯„ä¼°æŒ‡æ ‡åŸºå‡†ï¼Œç”¨äºè¯„ä¼°æŠ¥å‘Šç”Ÿæˆè´¨é‡ã€‚</li>
<li>DAgentèƒ½åˆ†è§£è‡ªç„¶è¯­è¨€é—®é¢˜ä¸ºç‹¬ç«‹å­æŸ¥è¯¢ï¼Œå‡†ç¡®æ£€ç´¢æ•°æ®åº“ä¿¡æ¯ã€‚</li>
<li>DAgenté€šè¿‡å¤šæ­¥éª¤æ¨ç†å’Œæœ‰æ•ˆæ•°æ®æ•´åˆï¼Œç”Ÿæˆå®Œæ•´ã€æ­£ç¡®ä¸”ç®€æ´çš„åˆ†ææŠ¥å‘Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13269">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8e24ad8519b014703ab2b4c739c30c03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a699f23236cce4a35dbaaf03eb21eddd.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Scalable-Safe-Multi-Agent-Reinforcement-Learning-for-Multi-Agent-System"><a href="#Scalable-Safe-Multi-Agent-Reinforcement-Learning-for-Multi-Agent-System" class="headerlink" title="Scalable Safe Multi-Agent Reinforcement Learning for Multi-Agent System"></a>Scalable Safe Multi-Agent Reinforcement Learning for Multi-Agent System</h2><p><strong>Authors:Haikuo Du, Fandi Gou, Yunze Cai</strong></p>
<p>Safety and scalability are two critical challenges faced by practical Multi-Agent Systems (MAS). However, existing Multi-Agent Reinforcement Learning (MARL) algorithms that rely solely on reward shaping are ineffective in ensuring safety, and their scalability is rather limited due to the fixed-size network output. To address these issues, we propose a novel framework, Scalable Safe MARL (SS-MARL), to enhance the safety and scalability of MARL methods. Leveraging the inherent graph structure of MAS, we design a multi-layer message passing network to aggregate local observations and communications of varying sizes. Furthermore, we develop a constrained joint policy optimization method in the setting of local observation to improve safety. Simulation experiments demonstrate that SS-MARL achieves a better trade-off between optimality and safety compared to baselines, and its scalability significantly outperforms the latest methods in scenarios with a large number of agents. </p>
<blockquote>
<p>åœ¨å®é™…çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ä¸­ï¼Œå®‰å…¨æ€§å’Œå¯æ‰©å±•æ€§æ˜¯é¢ä¸´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¾èµ–äºå¥–åŠ±å¡‘é€ çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ç®—æ³•åœ¨ä¿éšœå®‰å…¨æ–¹é¢æ•ˆæœä¸ä½³ï¼Œç”±äºå…¶å›ºå®šå¤§å°çš„ç½‘ç»œè¾“å‡ºï¼Œå…¶å¯æ‰©å±•æ€§ä¹Ÿç›¸å½“æœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶â€”â€”å¯æ‰©å±•å®‰å…¨MARLï¼ˆSS-MARLï¼‰ï¼Œä»¥æé«˜MARLæ–¹æ³•çš„å®‰å…¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚æˆ‘ä»¬åˆ©ç”¨MASçš„å›ºæœ‰å›¾å½¢ç»“æ„ï¼Œè®¾è®¡äº†ä¸€ä¸ªå¤šå±‚æ¶ˆæ¯ä¼ é€’ç½‘ç»œï¼Œä»¥èšåˆä¸åŒå¤§å°çš„å±€éƒ¨è§‚å¯Ÿå’Œé€šä¿¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨å±€éƒ¨è§‚å¯Ÿè®¾ç½®ä¸­å¼€å‘äº†ä¸€ç§çº¦æŸè”åˆç­–ç•¥ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æé«˜å®‰å…¨æ€§ã€‚ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼ŒSS-MARLåœ¨æœ€ä¼˜æ€§å’Œå®‰å…¨æ€§ä¹‹é—´å–å¾—äº†æ›´å¥½çš„æƒè¡¡ï¼Œå…¶å¯æ‰©å±•æ€§åœ¨å¤§é‡æ™ºèƒ½ä½“çš„åœºæ™¯ä¸­æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13727v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºSS-MARLçš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMulti-Agent Reinforcement Learningï¼Œç®€ç§°MARLï¼‰æ–¹æ³•çš„å®‰å…¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent Systemsï¼Œç®€ç§°MASï¼‰çš„å›ºæœ‰å›¾å½¢ç»“æ„ï¼Œè®¾è®¡äº†ä¸€ä¸ªå¤šå±‚æ¶ˆæ¯ä¼ é€’ç½‘ç»œæ¥èšåˆä¸åŒå¤§å°çš„åœ°æ–¹è§‚å¯Ÿå’Œé€šä¿¡ã€‚æ­¤å¤–ï¼Œå¼€å‘äº†ä¸€ç§å±€éƒ¨è§‚å¯Ÿä¸‹çš„çº¦æŸè”åˆç­–ç•¥ä¼˜åŒ–æ–¹æ³•ä»¥æé«˜å®‰å…¨æ€§ã€‚ä»¿çœŸå®éªŒè¡¨æ˜ï¼ŒSS-MARLåœ¨æœ€ä¼˜æ€§å’Œå®‰å…¨æ€§ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ï¼Œå¹¶ä¸”åœ¨å¤§é‡æ™ºèƒ½ä½“çš„åœºæ™¯ä¸­ï¼Œå…¶å¯æ‰©å±•æ€§æ˜æ˜¾ä¼˜äºæœ€æ–°çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SS-MARLæ¡†æ¶æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ä¸­çš„å®‰å…¨æ€§å’Œå¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰MARLç®—æ³•åœ¨ä¿éšœå®‰å…¨å’Œæ‰©å±•æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>SS-MARLåˆ©ç”¨MASçš„å›ºæœ‰å›¾å½¢ç»“æ„ï¼Œè®¾è®¡å¤šå±‚æ¶ˆæ¯ä¼ é€’ç½‘ç»œæ¥èšåˆåœ°æ–¹è§‚å¯Ÿå’Œé€šä¿¡ã€‚</li>
<li>å¼€å‘äº†å±€éƒ¨è§‚å¯Ÿä¸‹çš„çº¦æŸè”åˆç­–ç•¥ä¼˜åŒ–æ–¹æ³•ä»¥æé«˜å®‰å…¨æ€§ã€‚</li>
<li>ä»¿çœŸå®éªŒè¡¨æ˜SS-MARLåœ¨æœ€ä¼˜æ€§å’Œå®‰å…¨æ€§ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚</li>
<li>SS-MARLåœ¨å¤§é‡æ™ºèƒ½ä½“çš„åœºæ™¯ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„å¯æ‰©å±•æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13727">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-be5b6af7f2e34b67c7c53a21e2ea234f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4dd13695b89443f404ce1bb5a530172e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b013c589f4836129519344aa28f01e8b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e04736bf5438b59b103b79c0387634d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56b9ee7a6b3135fa3b8ae8f3e5b48c60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a03413b51695110c3ca613342caa93a7.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="BALROG-Benchmarking-Agentic-LLM-and-VLM-Reasoning-On-Games"><a href="#BALROG-Benchmarking-Agentic-LLM-and-VLM-Reasoning-On-Games" class="headerlink" title="BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games"></a>BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games</h2><p><strong>Authors:Davide Paglieri, BartÅ‚omiej CupiaÅ‚, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Åukasz KuciÅ„ski, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim RocktÃ¤schel</strong></p>
<p>Large Language Models (LLMs) and Vision Language Models (VLMs) possess extensive knowledge and exhibit promising reasoning abilities, however, they still struggle to perform well in complex, dynamic environments. Real-world tasks require handling intricate interactions, advanced spatial reasoning, long-term planning, and continuous exploration of new strategies-areas in which we lack effective methodologies for comprehensively evaluating these capabilities. To address this gap, we introduce BALROG, a novel benchmark designed to assess the agentic capabilities of LLMs and VLMs through a diverse set of challenging games. Our benchmark incorporates a range of existing reinforcement learning environments with varying levels of difficulty, including tasks that are solvable by non-expert humans in seconds to extremely challenging ones that may take years to master (e.g., the NetHack Learning Environment). We devise fine-grained metrics to measure performance and conduct an extensive evaluation of several popular open-source and closed-source LLMs and VLMs. Our findings indicate that while current models achieve partial success in the easier games, they struggle significantly with more challenging tasks. Notably, we observe severe deficiencies in vision-based decision-making, as several models perform worse when visual representations of the environments are provided. We release BALROG as an open and user-friendly benchmark to facilitate future research and development in the agentic community. Code and Leaderboard at balrogai.com. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æ‹¥æœ‰å¹¿æ³›çš„çŸ¥è¯†å¹¶å±•ç°å‡ºæœ‰å‰æ™¯çš„æ¨ç†èƒ½åŠ›ï¼Œç„¶è€Œï¼Œå®ƒä»¬åœ¨å¤æ‚çš„åŠ¨æ€ç¯å¢ƒä¸­ä»ç„¶è¡¨ç°ä¸ä½³ã€‚ç°å®ä¸–ç•Œä»»åŠ¡éœ€è¦å¤„ç†å¤æ‚çš„äº¤äº’ã€é«˜çº§ç©ºé—´æ¨ç†ã€é•¿æœŸè§„åˆ’å’ŒæŒç»­æ¢ç´¢æ–°ç­–ç•¥â€”â€”æˆ‘ä»¬åœ¨å…¨é¢è¯„ä¼°è¿™äº›èƒ½åŠ›çš„æ–¹é¢ç¼ºä¹æœ‰æ•ˆæ–¹æ³•ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†BALROGï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨é€šè¿‡ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¸¸æˆæ¥è¯„ä¼°LLMså’ŒVLMsçš„ä»£ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ç»“åˆäº†ä¸åŒéš¾åº¦çš„ç°æœ‰å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼ŒåŒ…æ‹¬éä¸“å®¶äººç±»å¯ä»¥åœ¨å‡ ç§’é’Ÿå†…è§£å†³çš„ä»»åŠ¡åˆ°éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§å¯èƒ½éœ€è¦å¤šå¹´æ‰èƒ½æŒæ¡çš„ä»»åŠ¡ï¼ˆä¾‹å¦‚NetHackå­¦ä¹ ç¯å¢ƒï¼‰ã€‚æˆ‘ä»¬åˆ¶å®šäº†ç²¾ç»†çš„æŒ‡æ ‡æ¥è¡¡é‡æ€§èƒ½ï¼Œå¹¶å¯¹å‡ ä¸ªæµè¡Œçš„å¼€æºå’Œé—­æºLLMså’ŒVLMsè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè™½ç„¶å½“å‰æ¨¡å‹åœ¨è¾ƒç®€å•çš„æ¸¸æˆä¸­å–å¾—éƒ¨åˆ†æˆåŠŸï¼Œä½†åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­å´é¢ä¸´å·¨å¤§å›°éš¾ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨åŸºäºè§†è§‰çš„å†³ç­–åˆ¶å®šä¸­è§‚å¯Ÿåˆ°ä¸¥é‡ç¼ºé™·ï¼Œå› ä¸ºå½“æä¾›ç¯å¢ƒçš„è§†è§‰è¡¨ç¤ºæ—¶ï¼Œå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½å˜å¾—æ›´å·®ã€‚æˆ‘ä»¬å‘å¸ƒBALROGä½œä¸ºä¸€ä¸ªå¼€æ”¾å’Œç”¨æˆ·å‹å¥½çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥ä¿ƒè¿›ä»£ç†ç¤¾åŒºçš„æœªæ¥å‘å±•ä¸ç ”ç©¶ã€‚ä»£ç å’Œæ’è¡Œæ¦œè¯·è®¿é—®balrogai.comã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13543v2">PDF</a> Published as a conference paper at ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å…·å¤‡å¹¿æ³›çš„çŸ¥è¯†å’Œå‡ºè‰²çš„æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨å¤æ‚ã€åŠ¨æ€çš„ç¯å¢ƒä¸­è¡¨ç°ä»æœ‰æ‰€ä¸è¶³ã€‚ä¸ºè§£å†³ç°æœ‰è¯„ä¼°æ–¹æ³•åœ¨è¿™ä¸€é¢†åŸŸçš„ä¸è¶³ï¼Œæå‡ºäº†BALROGè¿™ä¸€æ–°å‹åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¸¸æˆæ¥è¯„ä¼°LLMså’ŒVLMsçš„ä»£ç†èƒ½åŠ›ã€‚BALROGèå…¥äº†å„ç§ä¸åŒéš¾åº¦çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œæ¶µç›–ä»éä¸“å®¶äººç±»å¯åœ¨å‡ ç§’å†…è§£å†³çš„ä»»åŠ¡åˆ°å¯èƒ½éœ€è¦æ•°å¹´æ‰èƒ½æŒæ¡çš„ä»»åŠ¡ã€‚è¯„ä¼°å‘ç°ï¼Œå½“å‰æ¨¡å‹åœ¨è¾ƒç®€å•çš„æ¸¸æˆä¸­å–å¾—éƒ¨åˆ†æˆåŠŸï¼Œä½†åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­è¡¨ç°æŒ£æ‰ï¼Œç‰¹åˆ«æ˜¯åœ¨åŸºäºè§†è§‰çš„å†³ç­–åˆ¶å®šæ–¹é¢å­˜åœ¨ä¸¥é‡ç¼ºé™·ã€‚BALROGä½œä¸ºä¸€ä¸ªå¼€æ”¾ã€ç”¨æˆ·å‹å¥½çš„åŸºå‡†æµ‹è¯•ï¼Œæœ‰åŠ©äºæ¨åŠ¨æœªæ¥åœ¨ä»£ç†é¢†åŸŸçš„ç ”ç©¶ä¸å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså’ŒVLMsåœ¨å¤æ‚ã€åŠ¨æ€ç¯å¢ƒä¸­è¡¨ç°ä¸è¶³ã€‚</li>
<li>BALROGæ˜¯ä¸€ä¸ªæ–°å‹åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°LLMså’ŒVLMsçš„ä»£ç†èƒ½åŠ›ã€‚</li>
<li>BALROGèå…¥å„ç§éš¾åº¦çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œæ¶µç›–ä»ç®€å•åˆ°æå…¶å¤æ‚çš„ä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨ç®€å•æ¸¸æˆä¸­è¡¨ç°å°šå¯ï¼Œä½†åœ¨æ›´å¤æ‚çš„ä»»åŠ¡ä¸­è¡¨ç°æŒ£æ‰ã€‚</li>
<li>è§†è§‰åœ¨å†³ç­–åˆ¶å®šä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œä½†å½“å‰æ¨¡å‹åœ¨è§†è§‰å†³ç­–æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚</li>
<li>BALROGä½œä¸ºå¼€æ”¾ã€ç”¨æˆ·å‹å¥½çš„åŸºå‡†æµ‹è¯•ï¼Œæœ‰åŠ©äºæ¨åŠ¨æœªæ¥ç ”ç©¶ä¸å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13543">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-50411dcff52719ca83a45a155a7eed32.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9e2171643db4673e7a03258e5beafed7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f9c10191c3227a54a2c21a25621f6a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-00d616db923791adfaaebfa4006122cc.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="AgentForge-A-Flexible-Low-Code-Platform-for-Reinforcement-Learning-Agent-Design"><a href="#AgentForge-A-Flexible-Low-Code-Platform-for-Reinforcement-Learning-Agent-Design" class="headerlink" title="AgentForge: A Flexible Low-Code Platform for Reinforcement Learning   Agent Design"></a>AgentForge: A Flexible Low-Code Platform for Reinforcement Learning   Agent Design</h2><p><strong>Authors:Francisco Erivaldo Fernandes Junior, Antti Oulasvirta</strong></p>
<p>Developing a reinforcement learning (RL) agent often involves identifying values for numerous parameters, covering the policy, reward function, environment, and agent-internal architecture. Since these parameters are interrelated in complex ways, optimizing them is a black-box problem that proves especially challenging for nonexperts. Although existing optimization-as-a-service platforms (e.g., Vizier and Optuna) can handle such problems, they are impractical for RL systems, since the need for manual user mapping of each parameter to distinct components makes the effort cumbersome. It also requires understanding of the optimization process, limiting the systemsâ€™ application beyond the machine learning field and restricting access in areas such as cognitive science, which models human decision-making. To tackle these challenges, the paper presents AgentForge, a flexible low-code platform to optimize any parameter set across an RL system. Available at <a target="_blank" rel="noopener" href="https://github.com/feferna/AgentForge">https://github.com/feferna/AgentForge</a>, it allows an optimization problem to be defined in a few lines of code and handed to any of the interfaced optimizers. With AgentForge, the user can optimize the parameters either individually or jointly. The paper presents an evaluation of its performance for a challenging vision-based RL problem. </p>
<blockquote>
<p>åœ¨å¼€å‘å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†æ—¶ï¼Œé€šå¸¸éœ€è¦ä¸ºæ¶‰åŠç­–ç•¥ã€å¥–åŠ±å‡½æ•°ã€ç¯å¢ƒå’Œä»£ç†å†…éƒ¨æ¶æ„çš„ä¼—å¤šå‚æ•°ç¡®å®šå€¼ã€‚ç”±äºè¿™äº›å‚æ•°ä»¥å¤æ‚çš„æ–¹å¼ç›¸äº’å…³è”ï¼Œå¯¹å…¶è¿›è¡Œä¼˜åŒ–æ˜¯ä¸€ä¸ªé»‘ç®±é—®é¢˜ï¼Œå¯¹éä¸“å®¶æ¥è¯´å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å°½ç®¡ç°æœ‰çš„ä¼˜åŒ–å³æœåŠ¡å¹³å°ï¼ˆä¾‹å¦‚Vizierå’ŒOptunaï¼‰å¯ä»¥å¤„ç†æ­¤ç±»é—®é¢˜ï¼Œä½†å®ƒä»¬å¯¹äºRLç³»ç»Ÿæ¥è¯´å¹¶ä¸å®ç”¨ï¼Œå› ä¸ºéœ€è¦æ‰‹åŠ¨å°†æ¯ä¸ªå‚æ•°æ˜ å°„åˆ°ä¸åŒç»„ä»¶ï¼Œè¿™ä½¿å¾—å·¥ä½œå˜å¾—ç¹çã€‚è¿™è¿˜éœ€è¦äº†è§£ä¼˜åŒ–è¿‡ç¨‹ï¼Œé™åˆ¶äº†ç³»ç»Ÿåœ¨æœºå™¨å­¦ä¹ é¢†åŸŸä¹‹å¤–çš„åº”ç”¨ï¼Œå¹¶é™åˆ¶äº†å…¶åœ¨è®¤çŸ¥ç§‘å­¦ç­‰é¢†åŸŸçš„è®¿é—®æƒé™ï¼Œè®¤çŸ¥ç§‘å­¦æ¨¡æ‹Ÿäººç±»å†³ç­–è¿‡ç¨‹ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†AgentForgeï¼Œè¿™æ˜¯ä¸€ä¸ªçµæ´»çš„ä½ä»£ç å¹³å°ï¼Œå¯ä»¥ä¼˜åŒ–RLç³»ç»Ÿä¸­çš„ä»»ä½•å‚æ•°é›†ã€‚å®ƒå¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/feferna/AgentForge">https://github.com/feferna/AgentForge</a>ä¸Šè·å¾—ï¼Œå…è®¸ç”¨å‡ è¡Œä»£ç å®šä¹‰ä¼˜åŒ–é—®é¢˜å¹¶å°†å…¶ä¼ é€’ç»™ä»»ä½•æ¥å£ä¼˜åŒ–å™¨ã€‚ä½¿ç”¨AgentForgeï¼Œç”¨æˆ·å¯ä»¥å•ç‹¬æˆ–è”åˆä¼˜åŒ–å‚æ•°ã€‚æœ¬æ–‡å¯¹å…¶åœ¨å¤„ç†å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºäºè§†è§‰çš„RLé—®é¢˜ä¸Šçš„æ€§èƒ½è¿›è¡Œäº†è¯„ä¼°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19528v4">PDF</a> This paper has been accepted at the 17th International Conference on   Agents and Artificial Intelligence (ICAART 2025)</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†çš„å¼€å‘ä¸­é¢ä¸´çš„å‚æ•°ä¼˜åŒ–é—®é¢˜ã€‚ç°æœ‰çš„ä¼˜åŒ–å¹³å°å¯¹äºRLç³»ç»Ÿæ¥è¯´å¹¶ä¸å®ç”¨ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦æ‰‹åŠ¨å°†æ¯ä¸ªå‚æ•°æ˜ å°„åˆ°ä¸åŒçš„ç»„ä»¶ï¼Œå¹¶éœ€è¦ç†è§£ä¼˜åŒ–è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†AgentForgeï¼Œä¸€ä¸ªçµæ´»çš„ã€ä½ä»£ç çš„å¹³å°ï¼Œå¯ä»¥ä¼˜åŒ–RLç³»ç»Ÿä¸­çš„ä»»ä½•å‚æ•°é›†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†å¼€å‘æ¶‰åŠä¼—å¤šå‚æ•°çš„è®¾å®šï¼ŒåŒ…æ‹¬ç­–ç•¥ã€å¥–åŠ±å‡½æ•°ã€ç¯å¢ƒå’Œä»£ç†å†…éƒ¨æ¶æ„ã€‚</li>
<li>å‚æ•°ä¼˜åŒ–æ˜¯ä¸€ä¸ªé»‘ç®±é—®é¢˜ï¼Œå¯¹äºéä¸“å®¶æ¥è¯´å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>ç°æœ‰ä¼˜åŒ–å¹³å°ï¼ˆå¦‚Vizierå’ŒOptunaï¼‰åœ¨å¤„ç†RLç³»ç»Ÿçš„å‚æ•°ä¼˜åŒ–é—®é¢˜æ—¶å¹¶ä¸å®ç”¨ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ç¹ççš„æ˜ å°„å’Œä¼˜åŒ–è¿‡ç¨‹ç†è§£ã€‚</li>
<li>AgentForgeæ˜¯ä¸€ä¸ªçµæ´»çš„ä½ä»£ç å¹³å°ï¼Œå¯ä»¥ç®€åŒ–RLç³»ç»Ÿçš„å‚æ•°ä¼˜åŒ–é—®é¢˜ã€‚</li>
<li>AgentForgeå…è®¸ç”¨æˆ·ä»¥å‡ è¡Œä»£ç å®šä¹‰ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å°†å…¶äº¤ç»™ä»»ä½•æ¥å£çš„ä¼˜åŒ–å™¨ã€‚</li>
<li>ç”¨æˆ·å¯ä»¥ä½¿ç”¨AgentForgeå•ç‹¬æˆ–è”åˆä¼˜åŒ–å‚æ•°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19528">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3f96dc3880406adc563dfbec8edf6571.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14054834980daf89565585e759ba394e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-629bc7606fed88be6e81c74f999a958f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75eecf4369651878de252e3f2a04d3be.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9836fc6dead17496a422a089035615b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f67b7587b13586610eb82facaf251ba5.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Web-Agents-with-World-Models-Learning-and-Leveraging-Environment-Dynamics-in-Web-Navigation"><a href="#Web-Agents-with-World-Models-Learning-and-Leveraging-Environment-Dynamics-in-Web-Navigation" class="headerlink" title="Web Agents with World Models: Learning and Leveraging Environment   Dynamics in Web Navigation"></a>Web Agents with World Models: Learning and Leveraging Environment   Dynamics in Web Navigation</h2><p><strong>Authors:Hyungjoo Chae, Namyoung Kim, Kai Tzu-iunn Ong, Minju Gwak, Gwanwoo Song, Jihoon Kim, Sunghwan Kim, Dongha Lee, Jinyoung Yeo</strong></p>
<p>Large language models (LLMs) have recently gained much attention in building autonomous agents. However, the performance of current LLM-based web agents in long-horizon tasks is far from optimal, often yielding errors such as repeatedly buying a non-refundable flight ticket. By contrast, humans can avoid such an irreversible mistake, as we have an awareness of the potential outcomes (e.g., losing money) of our actions, also known as the â€œworld modelâ€. Motivated by this, our study first starts with preliminary analyses, confirming the absence of world models in current LLMs (e.g., GPT-4o, Claude-3.5-Sonnet, etc.). Then, we present a World-model-augmented (WMA) web agent, which simulates the outcomes of its actions for better decision-making. To overcome the challenges in training LLMs as world models predicting next observations, such as repeated elements across observations and long HTML inputs, we propose a transition-focused observation abstraction, where the prediction objectives are free-form natural language descriptions exclusively highlighting important state differences between time steps. Experiments on WebArena and Mind2Web show that our world models improve agentsâ€™ policy selection without training and demonstrate our agentsâ€™ cost- and time-efficiency compared to recent tree-search-based agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ€è¿‘åœ¨æ„å»ºè‡ªä¸»ä»£ç†æ–¹é¢å—åˆ°äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼ŒåŸºäºå½“å‰LLMçš„Webä»£ç†åœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­çš„è¡¨ç°è¿œéæœ€ä½³ï¼Œç»å¸¸å¯¼è‡´é”™è¯¯ï¼Œä¾‹å¦‚åå¤è´­ä¹°ä¸å¯é€€æ¬¾çš„æœºç¥¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œäººç±»å¯ä»¥é¿å…è¿™ç§ä¸å¯é€†è½¬çš„é”™è¯¯ï¼Œå› ä¸ºæˆ‘ä»¬æ„è¯†åˆ°æˆ‘ä»¬è¡Œä¸ºçš„å¯èƒ½åæœï¼ˆä¾‹å¦‚ï¼ŒæŸå¤±é‡‘é’±ï¼‰ï¼Œè¿™ä¹Ÿç§°ä¸ºâ€œä¸–ç•Œæ¨¡å‹â€ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬çš„ç ”ç©¶é¦–å…ˆé€šè¿‡å¯¹å½“å‰LLMï¼ˆå¦‚GPT-4oã€Claude-3.5-Sonnetç­‰ï¼‰ä¸­ç¼ºä¹ä¸–ç•Œæ¨¡å‹çš„åˆæ­¥åˆ†ææ¥å¼€å§‹ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¢å¼ºçš„ä¸–ç•Œæ¨¡å‹ï¼ˆWMAï¼‰Webä»£ç†ï¼Œå®ƒé€šè¿‡æ¨¡æ‹Ÿè¡Œä¸ºçš„åæœæ¥è¿›è¡Œæ›´å¥½çš„å†³ç­–ã€‚ä¸ºäº†å…‹æœå°†LLMè®­ç»ƒä¸ºä¸–ç•Œæ¨¡å‹æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚è§‚å¯Ÿä¹‹é—´çš„é‡å¤å…ƒç´ å’Œé•¿çš„HTMLè¾“å…¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»¥è¿‡æ¸¡ä¸ºé‡ç‚¹çš„è§‚å¯ŸæŠ½è±¡ï¼Œå…¶ä¸­é¢„æµ‹ç›®æ ‡æ˜¯è‡ªç”±å½¢å¼çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä»…çªå‡ºæ—¶é—´æ­¥é•¿ä¹‹é—´é‡è¦çŠ¶æ€å·®å¼‚ã€‚åœ¨WebArenaå’ŒMind2Webä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ä¸–ç•Œæ¨¡å‹åœ¨æ— éœ€è®­ç»ƒçš„æƒ…å†µä¸‹æ”¹è¿›äº†ä»£ç†çš„ç­–ç•¥é€‰æ‹©ï¼Œå¹¶å±•ç¤ºäº†ä¸æœ€è¿‘çš„æ ‘æœç´¢ä»£ç†ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ä»£ç†çš„æˆæœ¬å’Œæ—¶é—´æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.13232v2">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ„å»ºè‡ªä¸»ä»£ç†æ–¹é¢å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†åœ¨é•¿æœŸä»»åŠ¡ä¸­çš„è¡¨ç°å¹¶ä¸ç†æƒ³ï¼Œå¯èƒ½äº§ç”Ÿä¸å¯é€†çš„å¤±è¯¯ã€‚ç ”ç©¶åˆæ­¥åˆ†æç¡®è®¤å½“å‰LLMç¼ºä¹â€œä¸–ç•Œæ¨¡å‹â€ï¼Œä¸ºæ­¤æå‡ºäº†ä¸–ç•Œæ¨¡å‹å¢å¼ºï¼ˆWMAï¼‰ç½‘ç»œä»£ç†ã€‚ä¸ºè§£å†³LLMä½œä¸ºä¸–ç•Œæ¨¡å‹é¢„æµ‹æ—¶çš„æŒ‘æˆ˜ï¼Œæå‡ºä»¥è¿‡æ¸¡ä¸ºé‡ç‚¹çš„è§‚å¯ŸæŠ½è±¡æ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼Œä¸–ç•Œæ¨¡å‹æé«˜äº†ä»£ç†çš„ç­–ç•¥é€‰æ‹©èƒ½åŠ›ï¼Œå¹¶å±•ç¤ºäº†å…¶æˆæœ¬å’Œæ—¶é—´çš„æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªä¸»ä»£ç†é¢†åŸŸå—åˆ°å…³æ³¨ï¼Œä½†åœ¨é•¿æœŸä»»åŠ¡ä¸­çš„è¡¨ç°æœ‰å¾…æé«˜ã€‚</li>
<li>å½“å‰LLMç¼ºä¹â€œä¸–ç•Œæ¨¡å‹â€ï¼Œæ— æ³•åƒäººç±»ä¸€æ ·é¢„æµ‹è¡ŒåŠ¨åæœã€‚</li>
<li>ä¸–ç•Œæ¨¡å‹å¢å¼ºï¼ˆWMAï¼‰ç½‘ç»œä»£ç†æ¨¡æ‹Ÿè¡ŒåŠ¨ç»“æœä»¥åšå‡ºæ›´å¥½çš„å†³ç­–ã€‚</li>
<li>è§£å†³LLMä½œä¸ºä¸–ç•Œæ¨¡å‹é¢„æµ‹æ—¶çš„æŒ‘æˆ˜ï¼Œæå‡ºä»¥è¿‡æ¸¡ä¸ºé‡ç‚¹çš„è§‚å¯ŸæŠ½è±¡æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡è‡ªç”±å½¢å¼è‡ªç„¶è¯­è¨€æè¿°æ¥çªå‡ºæ—¶é—´æ­¥ä¹‹é—´çš„é‡çŠ¶æ€å·®å¼‚ä½œä¸ºé¢„æµ‹ç›®æ ‡ã€‚</li>
<li>åœ¨WebArenaå’ŒMind2Webä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸–ç•Œæ¨¡å‹æé«˜äº†ä»£ç†çš„ç­–ç•¥é€‰æ‹©èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.13232">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-07aa722d2ed096e75ec632d6e0cffe32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3bd8f03a613bcd899db48bf629f2fef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c76c630ebbdca83ad8d851ef9d7afab4.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-03/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-03/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-03/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4eb529541b04553defce20fdfac56c89.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-03  Style transfer between Microscopy and Magnetic Resonance Imaging via   Generative Adversarial Network in small sample size settings
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-03/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e673eac368ee8357e01903864dfaf4db.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-03  Towards Unified Referring Expression Segmentation Across Omni-Level   Visual Target Granularities
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26522.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
