<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-04  Monocular and Generalizable Gaussian Talking Head Animation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-01eaed5d7f8d8bd95635e7a9b4a6a76b.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-05
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    44 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-04-æ›´æ–°"><a href="#2025-04-04-æ›´æ–°" class="headerlink" title="2025-04-04 æ›´æ–°"></a>2025-04-04 æ›´æ–°</h1><h2 id="Monocular-and-Generalizable-Gaussian-Talking-Head-Animation"><a href="#Monocular-and-Generalizable-Gaussian-Talking-Head-Animation" class="headerlink" title="Monocular and Generalizable Gaussian Talking Head Animation"></a>Monocular and Generalizable Gaussian Talking Head Animation</h2><p><strong>Authors:Shengjie Gong, Haojie Li, Jiapeng Tang, Dongming Hu, Shuangping Huang, Hao Chen, Tianshui Chen, Zhuoman Liu</strong></p>
<p>In this work, we introduce Monocular and Generalizable Gaussian Talking Head Animation (MGGTalk), which requires monocular datasets and generalizes to unseen identities without personalized re-training. Compared with previous 3D Gaussian Splatting (3DGS) methods that requires elusive multi-view datasets or tedious personalized learning&#x2F;inference, MGGtalk enables more practical and broader applications. However, in the absence of multi-view and personalized training data, the incompleteness of geometric and appearance information poses a significant challenge. To address these challenges, MGGTalk explores depth information to enhance geometric and facial symmetry characteristics to supplement both geometric and appearance features. Initially, based on the pixel-wise geometric information obtained from depth estimation, we incorporate symmetry operations and point cloud filtering techniques to ensure a complete and precise position parameter for 3DGS. Subsequently, we adopt a two-stage strategy with symmetric priors for predicting the remaining 3DGS parameters. We begin by predicting Gaussian parameters for the visible facial regions of the source image. These parameters are subsequently utilized to improve the prediction of Gaussian parameters for the non-visible regions. Extensive experiments demonstrate that MGGTalk surpasses previous state-of-the-art methods, achieving superior performance across various metrics. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å•ç›®å’Œé€šç”¨é«˜æ–¯è¯­éŸ³å¤´åŠ¨ç”»ï¼ˆMGGTalkï¼‰ï¼Œå®ƒåªéœ€è¦å•ç›®æ•°æ®é›†ï¼Œå³å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„èº«ä»½è€Œæ— éœ€ä¸ªæ€§åŒ–é‡æ–°è®­ç»ƒã€‚ä¸ä¹‹å‰éœ€è¦éš¾ä»¥è·å–çš„å¤šè§†è§’æ•°æ®é›†æˆ–ç¹çä¸ªæ€§åŒ–å­¦ä¹ &#x2F;æ¨æ–­çš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ–¹æ³•ç›¸æ¯”ï¼ŒMGGTalkä½¿å®é™…åº”ç”¨å’Œæ›´å¹¿æ³›çš„åº”ç”¨æˆä¸ºå¯èƒ½ã€‚ç„¶è€Œï¼Œåœ¨æ²¡æœ‰å¤šè§†è§’å’Œä¸ªæ€§åŒ–è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œå‡ ä½•å’Œå¤–è§‚ä¿¡æ¯çš„å®Œæ•´æ€§æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒMGGTalkæ¢ç´¢æ·±åº¦ä¿¡æ¯æ¥å¢å¼ºå‡ ä½•å’Œé¢éƒ¨å¯¹ç§°ç‰¹å¾ï¼Œä»¥è¡¥å……å‡ ä½•å’Œå¤–è§‚ç‰¹å¾ã€‚æœ€åˆï¼ŒåŸºäºä»æ·±åº¦ä¼°è®¡è·å¾—çš„åƒç´ çº§å‡ ä½•ä¿¡æ¯ï¼Œæˆ‘ä»¬ç»“åˆäº†å¯¹ç§°æ“ä½œå’Œç‚¹äº‘æ»¤æ³¢æŠ€æœ¯ï¼Œä»¥ç¡®ä¿3DGSçš„å®Œæ•´å’Œç²¾ç¡®çš„ä½ç½®å‚æ•°ã€‚éšåï¼Œæˆ‘ä»¬é‡‡ç”¨å…·æœ‰å¯¹ç§°å…ˆéªŒçš„ä¸¤é˜¶æ®µç­–ç•¥æ¥é¢„æµ‹å‰©ä½™çš„3DGSå‚æ•°ã€‚æˆ‘ä»¬é¦–å…ˆé¢„æµ‹æºå›¾åƒå¯è§é¢éƒ¨åŒºåŸŸçš„é«˜æ–¯å‚æ•°ã€‚è¿™äº›å‚æ•°éšåç”¨äºæ”¹è¿›éå¯è§åŒºåŸŸçš„é«˜æ–¯å‚æ•°é¢„æµ‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMGGTalkè¶…è¶Šäº†ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œåœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00665v1">PDF</a> Accepted by CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å•ç›®é€šç”¨é«˜æ–¯å¤´éƒ¨åŠ¨ç”»æŠ€æœ¯ï¼ˆMGGTalkï¼‰ï¼Œè¯¥æŠ€æœ¯ä»…éœ€å•ç›®æ•°æ®é›†ï¼Œå¹¶èƒ½å¤Ÿæ¨å¹¿åˆ°æœªè§è¿‡çš„èº«ä»½è€Œæ— éœ€ä¸ªæ€§åŒ–å†è®­ç»ƒã€‚ä¸éœ€è¦éš¾ä»¥è·å–çš„å¤šè§†è§’æ•°æ®é›†æˆ–ç¹çä¸ªæ€§åŒ–å­¦ä¹ &#x2F;æ¨æ–­çš„å…ˆå‰3Dé«˜æ–¯è´´ç‰‡ï¼ˆ3DGSï¼‰æ–¹æ³•ç›¸æ¯”ï¼ŒMGGTalkå…·æœ‰æ›´å®ç”¨å’Œæ›´å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚åœ¨ç¼ºä¹å¤šè§†è§’å’Œä¸ªæ€§åŒ–è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼ŒMGGTalké€šè¿‡æ¢ç´¢æ·±åº¦ä¿¡æ¯æ¥å¢å¼ºå‡ ä½•å’Œé¢éƒ¨å¯¹ç§°æ€§ç‰¹å¾ï¼Œä»¥è¡¥å……å‡ ä½•å’Œå¤–è§‚ç‰¹å¾ã€‚å®éªŒè¡¨æ˜ï¼ŒMGGTalkåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¶…è¶Šäº†å…ˆå‰çš„æ–¹æ³•ï¼Œå®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MGGTalkä½¿ç”¨å•ç›®æ•°æ®é›†ï¼Œæ— éœ€å¤šè§†è§’æ•°æ®ï¼Œç®€åŒ–äº†å¤´éƒ¨åŠ¨ç”»çš„åˆ›å»ºè¿‡ç¨‹ã€‚</li>
<li>MGGTalkèƒ½å¤Ÿåœ¨æœªè§è¿‡çš„èº«ä»½ä¸Šæ¨å¹¿ï¼Œæ— éœ€ä¸ªæ€§åŒ–å†è®­ç»ƒï¼Œå¢åŠ äº†å…¶åº”ç”¨çš„å¹¿æ³›æ€§ã€‚</li>
<li>åœ¨ç¼ºä¹å¤šè§†è§’å’Œä¸ªæ€§åŒ–è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼ŒMGGTalké€šè¿‡åˆ©ç”¨æ·±åº¦ä¿¡æ¯å¢å¼ºå‡ ä½•å’Œé¢éƒ¨å¯¹ç§°æ€§ç‰¹å¾ã€‚</li>
<li>MGGTalké‡‡ç”¨åŸºäºåƒç´ çš„å‡ ä½•ä¿¡æ¯æ¥è¿›è¡Œæ·±åº¦ä¼°ç®—ï¼Œå¹¶èå…¥å¯¹ç§°æ“ä½œå’Œç‚¹äº‘è¿‡æ»¤æŠ€æœ¯ï¼Œç¡®ä¿3DGSçš„å®Œæ•´æ€§å’Œç²¾ç¡®ä½ç½®å‚æ•°ã€‚</li>
<li>MGGTalké‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼Œç»“åˆå¯¹ç§°å…ˆéªŒæ¥é¢„æµ‹å‰©ä½™çš„3DGSå‚æ•°ã€‚</li>
<li>è¯¥æŠ€æœ¯é¦–å…ˆé¢„æµ‹æºå›¾åƒå¯è§é¢éƒ¨åŒºåŸŸçš„é«˜æ–¯å‚æ•°ï¼Œç„¶åç”¨äºæ”¹è¿›éå¯è§åŒºåŸŸçš„é«˜æ–¯å‚æ•°é¢„æµ‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00665">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0cb9b66d7917ae04893d14574dae1c4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0cb003298d1d12e0a7c9c740f48cff60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7c5a4511645c758a6f3a3b91b815bd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-840be5e63daf121b55e3faed614e8921.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-631e2e86c91179320867246457faaffc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-86b01b898aab33579c041759577708ef.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Exchange-cross-talk-mitigation-in-dense-quantum-dot-arrays"><a href="#Exchange-cross-talk-mitigation-in-dense-quantum-dot-arrays" class="headerlink" title="Exchange cross-talk mitigation in dense quantum dot arrays"></a>Exchange cross-talk mitigation in dense quantum dot arrays</h2><p><strong>Authors:Daniel Jirovec, Pablo Cova FariÃ±a, Stefano Reale, Stefan D. Oosterhout, Xin Zhang, Elizaveta Morozova, Sander de Snoo, Amir Sammak, Giordano Scappucci, Menno Veldhorst, Lieven M. K. Vandersypen</strong></p>
<p>Coupled spins in semiconductor quantum dots are a versatile platform for quantum computing and simulations of complex many-body phenomena. However, on the path of scale-up, cross-talk from densely packed electrodes poses a severe challenge. While cross-talk onto the dot potentials is nowadays routinely compensated for, cross-talk on the exchange interaction is much more difficult to tackle because it is not always directly measurable. Here we propose and implement a way of characterizing and compensating cross-talk on adjacent exchange interactions by following the singlet-triplet avoided crossing in Ge. We show that we can easily identify the barrier-to-barrier cross-talk element without knowledge of the particular exchange value in a 2x4 quantum dot array. We uncover striking differences among these cross-talk elements which can be linked to the geometry of the device and the barrier gate fan-out. We validate the methodology by tuning up four-spin Heisenberg chains. The same methodology should be applicable to longer chains of spins and to other semiconductor platforms in which mixing of the singlet and the lowest-energy triplet is present or can be engineered. Additionally, this procedure is well suited for automated tuning routines as we obtain a stand-out feature that can be easily tracked and directly returns the magnitude of the cross-talk. </p>
<blockquote>
<p>åŠå¯¼ä½“é‡å­ç‚¹ä¸­çš„è€¦åˆè‡ªæ—‹æ˜¯é‡å­è®¡ç®—å’Œæ¨¡æ‹Ÿå¤æ‚å¤šä½“ç°è±¡çš„å¤šåŠŸèƒ½å¹³å°ã€‚ç„¶è€Œï¼Œåœ¨è§„æ¨¡æ‰©å¤§çš„è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªå¯†é›†ç”µæçš„ä¸²æ‰°æ˜¯ä¸€ä¸ªä¸¥é‡çš„æŒ‘æˆ˜ã€‚è™½ç„¶ç°ä»Šå·²ç»å¯ä»¥å¯¹ç‚¹åŠ¿ä¸Šçš„ä¸²æ‰°è¿›è¡Œå¸¸è§„è¡¥å¿ï¼Œä½†å¤„ç†äº¤æ¢ä½œç”¨ä¸Šçš„ä¸²æ‰°æ›´åŠ å›°éš¾ï¼Œå› ä¸ºå¹¶éæ€»æ˜¯å¯ä»¥å¯¹å…¶è¿›è¡Œç›´æ¥æµ‹é‡ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬æå‡ºå¹¶å®æ–½äº†ä¸€ç§é€šè¿‡è·Ÿè¸ªGeä¸­çš„å•çº¿-ä¸‰çº¿é¿å…äº¤å‰æ¥è¡¨å¾å’Œè¡¥å¿ç›¸é‚»äº¤æ¢ä½œç”¨ä¸Šçš„ä¸²æ‰°çš„æ–¹æ³•ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨ä¸çŸ¥é“ç‰¹å®šäº¤æ¢å€¼çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥åœ¨ä¸€ä¸ª2x4é‡å­ç‚¹é˜µåˆ—ä¸­è½»æ¾ç¡®å®šå±éšœåˆ°å±éšœä¸²æ‰°å…ƒç´ ã€‚æˆ‘ä»¬å‘ç°è¿™äº›ä¸²æ‰°å…ƒç´ ä¹‹é—´å­˜åœ¨å¼•äººæ³¨ç›®çš„å·®å¼‚ï¼Œè¿™äº›å·®å¼‚ä¸å™¨ä»¶çš„å‡ ä½•å½¢çŠ¶å’Œå±éšœé—¨æ‰‡å‡ºæœ‰å…³ã€‚æˆ‘ä»¬é€šè¿‡è°ƒæ•´å››ä¸ªè‡ªæ—‹çš„æµ·æ£®å ¡é“¾éªŒè¯äº†è¯¥æ–¹æ³•ã€‚å¯¹äºæ›´é•¿çš„è‡ªæ—‹é“¾å’Œå…¶ä»–å­˜åœ¨å•çº¿æœ€ä½èƒ½é‡å’Œä¸‰çº¿æ··åˆæˆ–å¯è®¾è®¡çš„åŠå¯¼ä½“å¹³å°ï¼Œæ­¤æ–¹æ³•åŒæ ·é€‚ç”¨ã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬è·å¾—äº†å¯ä»¥è½»æ˜“è¿½è¸ªå¹¶ç›´æ¥è¿”å›ä¸²æ‰°å¹…åº¦çš„çªå‡ºç‰¹å¾ï¼Œå› æ­¤è¯¥è¿‡ç¨‹éå¸¸é€‚åˆç”¨äºè‡ªåŠ¨è°ƒæ•´ä¾‹è¡Œç¨‹åºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.23846v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŠå¯¼ä½“é‡å­ç‚¹ä¸­çš„è€¦åˆè‡ªæ—‹æ˜¯é‡å­è®¡ç®—å’Œæ¨¡æ‹Ÿå¤æ‚å¤šä½“ç°è±¡çš„å¤šåŠŸèƒ½å¹³å°ã€‚ç„¶è€Œï¼Œåœ¨è§„æ¨¡æ‰©å¤§çš„è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªå¯†é›†ç”µæçš„ä¸²è¯æ„æˆäº†ä¸¥é‡çš„æŒ‘æˆ˜ã€‚ç›®å‰ï¼Œäººä»¬é€šå¸¸èƒ½å¤Ÿè¡¥å¿ç‚¹å¯¹åŠ¿çš„ä¸²è¯ï¼Œä½†å¤„ç†äº¤æ¢ç›¸äº’ä½œç”¨çš„ä¸²è¯æ›´åŠ å›°éš¾ï¼Œå› ä¸ºå¹¶éæ€»æ˜¯èƒ½å¤Ÿç›´æ¥æµ‹é‡å®ƒã€‚æœ¬æ–‡æå‡ºå¹¶å®æ–½äº†ä¸€ç§é€šè¿‡è·Ÿè¸ªGeä¸­çš„å•é‡æ€ä¸‰é‡æ€é¿å…äº¤å‰æ¥è¡¨å¾å’Œè¡¥å¿ç›¸é‚»äº¤æ¢ç›¸äº’ä½œç”¨ä¸Šçš„ä¸²è¯çš„æ–¹æ³•ã€‚æˆ‘ä»¬å±•ç¤ºäº†èƒ½å¤Ÿåœ¨ä¸äº†è§£ç‰¹å®šäº¤æ¢å€¼çš„æƒ…å†µä¸‹è½»æ¾è¯†åˆ«å±éšœé—´ä¸²è¯å…ƒç´ çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å‘ç°è¿™äº›ä¸²è¯å…ƒç´ ä¹‹é—´å­˜åœ¨å¼•äººæ³¨ç›®çš„å·®å¼‚ï¼Œè¿™äº›å·®å¼‚ä¸è®¾å¤‡çš„å‡ ä½•å½¢çŠ¶å’Œå±éšœé—¨æ‰‡å‡ºæœ‰å…³ã€‚é€šè¿‡è°ƒæ•´å››ä¸ªè‡ªæ—‹çš„æµ·æ£®å ¡é“¾éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ³•åº”é€‚ç”¨äºè¾ƒé•¿çš„è‡ªæ—‹é“¾å’Œå…¶ä»–å­˜åœ¨æˆ–å¯è®¾è®¡å•é‡æ€å’Œæœ€ä½èƒ½é‡ä¸‰é‡æ€æ··åˆçš„åŠå¯¼ä½“å¹³å°ã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬èƒ½å¤Ÿè½»æ¾è¿½è¸ªçªå‡ºåŠŸèƒ½å¹¶ç›´æ¥è¿”å›ä¸²è¯å¹…åº¦ï¼Œå› æ­¤è¯¥è¿‡ç¨‹éå¸¸é€‚åˆè‡ªåŠ¨åŒ–è°ƒæ•´ä¾‹è¡Œç¨‹åºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠå¯¼ä½“é‡å­ç‚¹ä¸­çš„è€¦åˆè‡ªæ—‹ä¸ºé‡å­è®¡ç®—å’Œæ¨¡æ‹Ÿå¤æ‚å¤šä½“ç°è±¡æä¾›äº†å¤šåŠŸèƒ½å¹³å°ã€‚</li>
<li>åœ¨è§„æ¨¡æ‰©å±•è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªå¯†é›†ç”µæçš„ä¸²è¯æ„æˆæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯äº¤æ¢ç›¸äº’ä½œç”¨çš„ä¸²è¯éš¾ä»¥å¤„ç†ã€‚</li>
<li>é€šè¿‡è·Ÿè¸ªå•é‡æ€ä¸‰é‡æ€é¿å…äº¤å‰æå‡ºè¡¨å¾å’Œè¡¥å¿ç›¸é‚»äº¤æ¢ç›¸äº’ä½œç”¨ä¸Šçš„ä¸²è¯çš„æ–¹æ³•ã€‚</li>
<li>åœ¨ä¸äº†è§£ç‰¹å®šäº¤æ¢å€¼çš„æƒ…å†µä¸‹èƒ½è¯†åˆ«å±éšœé—´ä¸²è¯å…ƒç´ ã€‚</li>
<li>ä¸²è¯å…ƒç´ å·®å¼‚æ˜¾è‘—ï¼Œä¸è®¾å¤‡å‡ ä½•å½¢çŠ¶å’Œå±éšœé—¨æ‰‡å‡ºæœ‰å…³ã€‚</li>
<li>é€šè¿‡è°ƒæ•´å››ä¸ªè‡ªæ—‹çš„æµ·æ£®å ¡é“¾éªŒè¯äº†æ–¹æ³•çš„å¯è¡Œæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.23846">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-42191b58983ceb4c0d874f0a05f04fef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81b44640d0175b315162b3b5fdbff5bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7152e21f116a6a2a9a7f874053ee292c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-465095fd265d87ed5fa415c6ef550cab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4286478372295aabcb42a9a5c971b973.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DeepDubber-V1-Towards-High-Quality-and-Dialogue-Narration-Monologue-Adaptive-Movie-Dubbing-Via-Multi-Modal-Chain-of-Thoughts-Reasoning-Guidance"><a href="#DeepDubber-V1-Towards-High-Quality-and-Dialogue-Narration-Monologue-Adaptive-Movie-Dubbing-Via-Multi-Modal-Chain-of-Thoughts-Reasoning-Guidance" class="headerlink" title="DeepDubber-V1: Towards High Quality and Dialogue, Narration, Monologue   Adaptive Movie Dubbing Via Multi-Modal Chain-of-Thoughts Reasoning Guidance"></a>DeepDubber-V1: Towards High Quality and Dialogue, Narration, Monologue   Adaptive Movie Dubbing Via Multi-Modal Chain-of-Thoughts Reasoning Guidance</h2><p><strong>Authors:Junjie Zheng, Zihao Chen, Chaofan Ding, Xinhan Di</strong></p>
<p>Current movie dubbing technology can generate the desired voice from a given speech prompt, ensuring good synchronization between speech and visuals while accurately conveying the intended emotions. However, in movie dubbing, key aspects such as adapting to different dubbing styles, handling dialogue, narration, and monologue effectively, and understanding subtle details like the age and gender of speakers, have not been well studied. To address this challenge, we propose a framework of multi-modal large language model. First, it utilizes multimodal Chain-of-Thought (CoT) reasoning methods on visual inputs to understand dubbing styles and fine-grained attributes. Second, it generates high-quality dubbing through large speech generation models, guided by multimodal conditions. Additionally, we have developed a movie dubbing dataset with CoT annotations. The evaluation results demonstrate a performance improvement over state-of-the-art methods across multiple datasets. In particular, for the evaluation metrics, the SPK-SIM and EMO-SIM increases from 82.48% to 89.74%, 66.24% to 78.88% for dubbing setting 2.0 on V2C Animation dataset, LSE-D and MCD-SL decreases from 14.79 to 14.63, 5.24 to 4.74 for dubbing setting 2.0 on Grid dataset, SPK-SIM increases from 64.03 to 83.42 and WER decreases from 52.69% to 23.20% for initial reasoning setting on proposed CoT-Movie-Dubbing dataset in the comparison with the state-of-the art models. </p>
<blockquote>
<p>å½“å‰ç”µå½±é…éŸ³æŠ€æœ¯å¯ä»¥æ ¹æ®ç»™å®šçš„è¯­éŸ³æç¤ºç”Ÿæˆæ‰€éœ€çš„è¯­éŸ³ï¼Œç¡®ä¿è¯­éŸ³å’Œè§†è§‰ä¹‹é—´çš„è‰¯å¥½åŒæ­¥ï¼ŒåŒæ—¶å‡†ç¡®ä¼ è¾¾é¢„æœŸçš„æƒ…ç»ªã€‚ç„¶è€Œï¼Œåœ¨ç”µå½±é…éŸ³ä¸­ï¼Œå¦‚ä½•é€‚åº”ä¸åŒçš„é…éŸ³é£æ ¼ã€æœ‰æ•ˆå¤„ç†å¯¹è¯ã€æ—ç™½å’Œç‹¬ç™½ï¼Œä»¥åŠç†è§£å¦‚è¯´è¯äººçš„å¹´é¾„å’Œæ€§åˆ«ç­‰ç»†å¾®ä¹‹å¤„å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œå®ƒåˆ©ç”¨è§†è§‰è¾“å…¥çš„è§†è§‰æ¨¡æ€é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼Œç®€ç§°COTï¼‰æ¨ç†æ–¹æ³•æ¥ç†è§£é…éŸ³é£æ ¼å’Œç²¾ç»†å±æ€§ã€‚å…¶æ¬¡ï¼Œé€šè¿‡å¤§å‹è¯­éŸ³ç”Ÿæˆæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„é…éŸ³ï¼Œç”±å¤šæ¨¡æ€æ¡ä»¶å¼•å¯¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ä¸ªå¸¦æœ‰COTæ³¨é‡Šçš„ç”µå½±é…éŸ³æ•°æ®é›†ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½æœ‰æ‰€æå‡ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºè¯„ä¼°æŒ‡æ ‡ï¼ŒV2CåŠ¨ç”»æ•°æ®é›†çš„é…éŸ³è®¾ç½®2.0ä¸­ï¼ŒSPK-SIMå’ŒEMO-SIMåˆ†åˆ«ä»82.48%æå‡è‡³89.74%ã€ä»66.24%æå‡è‡³78.88%ï¼›Gridæ•°æ®é›†çš„é…éŸ³è®¾ç½®2.0ä¸­ï¼ŒLSE-Då’ŒMCD-SLåˆ†åˆ«ä»14.79ä¸‹é™è‡³14.63ã€ä»5.24ä¸‹é™è‡³4.74ï¼›åœ¨ä¸ç°æœ‰æ¨¡å‹çš„æ¯”è¾ƒä¸­ï¼Œæˆ‘ä»¬åœ¨æå‡ºçš„COT-Movie-Dubbingæ•°æ®é›†ä¸Šçš„åˆæ­¥æ¨ç†è®¾ç½®ä¸­ï¼ŒSPK-SIMä»64.03%æå‡è‡³83.42%ï¼ŒWERä»52.69%é™è‡³23.20%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.23660v1">PDF</a> 11 pages, 5 figures</p>
<p><strong>æ‘˜è¦</strong><br>ç”µå½±é…éŸ³æŠ€æœ¯å¯ä»ç»™å®šçš„è¯­éŸ³æç¤ºç”Ÿæˆæ‰€éœ€çš„è¯­éŸ³ï¼Œç¡®ä¿è¯­éŸ³å’Œè§†è§‰ä¹‹é—´çš„è‰¯å¥½åŒæ­¥ï¼ŒåŒæ—¶å‡†ç¡®ä¼ è¾¾æƒ…æ„Ÿã€‚ç„¶è€Œï¼Œåœ¨ç”µå½±é…éŸ³ä¸­ï¼Œå¦‚ä½•é€‚åº”ä¸åŒçš„é…éŸ³é£æ ¼ã€æœ‰æ•ˆå¤„ç†å¯¹è¯ã€æ—ç™½å’Œç‹¬ç™½ï¼Œä»¥åŠç†è§£å¦‚è¯´è¯äººçš„å¹´é¾„å’Œæ€§åˆ«ç­‰ç»†å¾®ç»†èŠ‚å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œå®ƒåˆ©ç”¨è§†è§‰è¾“å…¥çš„é“¾å¼æ€ç»´æ¨ç†æ–¹æ³•ç†è§£é…éŸ³é£æ ¼å’Œç²¾ç»†å±æ€§ã€‚å…¶æ¬¡ï¼Œé€šè¿‡å¤§å‹è¯­éŸ³ç”Ÿæˆæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡é…éŸ³ï¼Œç”±å¤šæ¨¡æ€æ¡ä»¶æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†å¸¦æœ‰æ€ç»´é“¾æ³¨é‡Šçš„ç”µå½±é…éŸ³æ•°æ®é›†ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°æœ‰æ‰€æé«˜ã€‚ç‰¹åˆ«æ˜¯ï¼Œåœ¨V2CåŠ¨ç”»æ•°æ®é›†ä¸Šçš„è¯´è¯äººç›¸ä¼¼æ€§ï¼ˆSPK-SIMï¼‰å’Œæƒ…æ„Ÿç›¸ä¼¼æ€§ï¼ˆEMO-SIMï¼‰ä»82.48%æé«˜åˆ°89.74%ï¼Œåœ¨ç½‘æ ¼æ•°æ®é›†ä¸Šçš„è¯­éŸ³æ¸…æ™°åº¦å’Œè¯­è°ƒè¿è´¯æ€§å¾—åˆ†ä¹Ÿæœ‰æ‰€ä¸‹é™ã€‚ä¸æˆ‘ä»¬æå‡ºçš„å¸¦æœ‰åˆå§‹æ¨ç†è®¾ç½®çš„CoTç”µå½±é…éŸ³æ•°æ®é›†ç›¸æ¯”ï¼ŒSPK-SIMä»64.03%æé«˜åˆ°83.42%ï¼Œè¯é”™è¯¯ç‡ï¼ˆWERï¼‰ä»52.69%ä¸‹é™åˆ°23.20%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰ç”µå½±é…éŸ³æŠ€æœ¯å¯ä»¥ä»ç»™å®šçš„è¯­éŸ³æç¤ºç”Ÿæˆè¯­éŸ³ï¼Œç¡®ä¿è¯­éŸ³å’Œè§†è§‰åŒæ­¥ï¼Œå¹¶å‡†ç¡®ä¼ è¾¾æƒ…æ„Ÿã€‚</li>
<li>é…éŸ³é£æ ¼çš„ç†è§£ä¸é€‚åº”ã€å¯¹è¯ã€æ—ç™½å’Œç‹¬ç™½çš„å¤„ç†ä»¥åŠç»†å¾®ç»†èŠ‚çš„ç†è§£æ˜¯ç”µå½±é…éŸ³ä¸­çš„å…³é”®æ–¹é¢ã€‚</li>
<li>æå‡ºäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œé€šè¿‡é“¾å¼æ€ç»´æ¨ç†æ–¹æ³•ç†è§£é…éŸ³é£æ ¼å’Œç²¾ç»†å±æ€§ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­éŸ³ç”Ÿæˆæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡é…éŸ³ï¼Œç”±å¤šæ¨¡æ€æ¡ä»¶æŒ‡å¯¼ã€‚</li>
<li>å¼€å‘äº†å¸¦æœ‰æ€ç»´é“¾æ³¨é‡Šçš„ç”µå½±é…éŸ³æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°å’Œæ”¹è¿›é…éŸ³æŠ€æœ¯ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°æœ‰æ‰€æé«˜ï¼ŒåŒ…æ‹¬è¯´è¯äººç›¸ä¼¼æ€§å’Œæƒ…æ„Ÿç›¸ä¼¼æ€§ç­‰æ–¹é¢çš„æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.23660">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fc5ee49ef0b6f667d475d787613844d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42464c87df81b2e865fcb29544188de6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f89e56211abb82d4a8eb3e75f076e215.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-862807fe09cf0fc2741ea16e70ca8a2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-820ea6cba6d2d3300f25867b3bd41411.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="STSA-Spatial-Temporal-Semantic-Alignment-for-Visual-Dubbing"><a href="#STSA-Spatial-Temporal-Semantic-Alignment-for-Visual-Dubbing" class="headerlink" title="STSA: Spatial-Temporal Semantic Alignment for Visual Dubbing"></a>STSA: Spatial-Temporal Semantic Alignment for Visual Dubbing</h2><p><strong>Authors:Zijun Ding, Mingdie Xiong, Congcong Zhu, Jingrun Chen</strong></p>
<p>Existing audio-driven visual dubbing methods have achieved great success. Despite this, we observe that the semantic ambiguity between spatial and temporal domains significantly degrades the synthesis stability for the dynamic faces. We argue that aligning the semantic features from spatial and temporal domains is a promising approach to stabilizing facial motion. To achieve this, we propose a Spatial-Temporal Semantic Alignment (STSA) method, which introduces a dual-path alignment mechanism and a differentiable semantic representation. The former leverages a Consistent Information Learning (CIL) module to maximize the mutual information at multiple scales, thereby reducing the manifold differences between spatial and temporal domains. The latter utilizes probabilistic heatmap as ambiguity-tolerant guidance to avoid the abnormal dynamics of the synthesized faces caused by slight semantic jittering. Extensive experimental results demonstrate the superiority of the proposed STSA, especially in terms of image quality and synthesis stability. Pre-trained weights and inference code are available at <a target="_blank" rel="noopener" href="https://github.com/SCAILab-USTC/STSA">https://github.com/SCAILab-USTC/STSA</a>. </p>
<blockquote>
<p>ç°æœ‰çš„éŸ³é¢‘é©±åŠ¨è§†è§‰é…éŸ³æ–¹æ³•å·²ç»å–å¾—äº†å·¨å¤§çš„æˆåŠŸã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ç©ºé—´å’Œæ—¶é—´åŸŸä¹‹é—´çš„è¯­ä¹‰æ¨¡ç³Šæ€§æ˜¾è‘—é™ä½äº†åŠ¨æ€é¢éƒ¨çš„åˆæˆç¨³å®šæ€§ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œå¯¹é½ç©ºé—´å’Œæ—¶é—´åŸŸçš„è¯­ä¹‰ç‰¹å¾æ˜¯ä¸€ç§ç¨³å®šé¢éƒ¨è¿åŠ¨çš„å¯è¡Œæ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç©ºé—´æ—¶é—´è¯­ä¹‰å¯¹é½ï¼ˆSTSAï¼‰æ–¹æ³•ï¼Œå®ƒå¼•å…¥äº†ä¸€ç§åŒè·¯å¾„å¯¹é½æœºåˆ¶å’Œä¸€ç§å¯åŒºåˆ†çš„è¯­ä¹‰è¡¨ç¤ºã€‚å‰è€…åˆ©ç”¨ä¸€è‡´ä¿¡æ¯å­¦ä¹ ï¼ˆCILï¼‰æ¨¡å—æ¥æœ€å¤§åŒ–å¤šä¸ªå°ºåº¦çš„äº’ä¿¡æ¯ï¼Œä»è€Œå‡å°‘ç©ºé—´å’Œæ—¶é—´åŸŸä¹‹é—´çš„æµå½¢å·®å¼‚ã€‚åè€…åˆ©ç”¨æ¦‚ç‡çƒ­å›¾ä½œä¸ºæ¨¡ç³Šå®¹å¿å¼•å¯¼ï¼Œä»¥é¿å…è½»å¾®è¯­ä¹‰æŠ–åŠ¨å¼•èµ·çš„åˆæˆé¢éƒ¨å¼‚å¸¸åŠ¨æ€ã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜äº†æ‰€æå‡ºçš„STSAçš„ä¼˜è¶Šæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒè´¨é‡å’Œåˆæˆç¨³å®šæ€§æ–¹é¢ã€‚é¢„è®­ç»ƒçš„æƒé‡å’Œæ¨ç†ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/SCAILab-USTC/STSA%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/SCAILab-USTC/STSAè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.23039v1">PDF</a> Accepted by ICME 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹åŠ¨æ€é¢éƒ¨åˆæˆçš„ç©ºé—´æ—¶é—´è¯­ä¹‰å¯¹é½ï¼ˆSTSAï¼‰æ–¹æ³•ï¼Œé€šè¿‡åŒè·¯å¾„å¯¹é½æœºåˆ¶å’Œå¯å¾®åˆ†è¯­ä¹‰è¡¨ç¤ºï¼Œè§£å†³ç°æœ‰éŸ³é¢‘é©±åŠ¨è§†è§‰é…éŸ³æ–¹æ³•ä¸­è¯­ä¹‰æ¨¡ç³Šå¯¼è‡´çš„é—®é¢˜ï¼Œæé«˜é¢éƒ¨åˆæˆç¨³å®šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­ä¹‰æ¨¡ç³Šæ˜¯ç°æœ‰éŸ³é¢‘é©±åŠ¨è§†è§‰é…éŸ³æ–¹æ³•é¢ä¸´çš„ä¸»è¦é—®é¢˜ï¼Œå½±å“åŠ¨æ€é¢éƒ¨åˆæˆçš„ç¨³å®šæ€§ã€‚</li>
<li>ç©ºé—´æ—¶é—´è¯­ä¹‰å¯¹é½ï¼ˆSTSAï¼‰æ–¹æ³•è¢«æå‡ºä»¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>STSAæ–¹æ³•é‡‡ç”¨åŒè·¯å¾„å¯¹é½æœºåˆ¶ï¼Œé€šè¿‡æœ€å¤§åŒ–å¤šå°ºåº¦ä¸Šçš„äº’ä¿¡æ¯æ¥å‡å°‘ç©ºé—´å’Œæ—¶é—´åŸŸä¹‹é—´çš„å·®å¼‚ã€‚</li>
<li>STSAæ–¹æ³•åˆ©ç”¨å¯å¾®åˆ†è¯­ä¹‰è¡¨ç¤ºï¼Œé‡‡ç”¨æ¦‚ç‡çƒ­å›¾ä½œä¸ºæ¨¡ç³Šå®¹å¿æŒ‡å¯¼ï¼Œé¿å…åˆæˆé¢éƒ¨çš„å¼‚å¸¸åŠ¨æ€ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSTSAæ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œåˆæˆç¨³å®šæ€§æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ã€‚</li>
<li>å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/SCAILab-USTC/STSA%E8%8E%B7%E5%8F%96%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D%E5%92%8C%E6%8E%A8%E7%90%86%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/SCAILab-USTC/STSAè·å–é¢„è®­ç»ƒæƒé‡å’Œæ¨ç†ä»£ç ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.23039">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-01eaed5d7f8d8bd95635e7a9b4a6a76b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-94e3d81eff53e24f4dcce5f1a957ae1f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-462253cc636efbde9d77d1e5c69da9f2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f8f1612b1628ddb284cbc6b3fe899ea.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Dual-Audio-Centric-Modality-Coupling-for-Talking-Head-Generation"><a href="#Dual-Audio-Centric-Modality-Coupling-for-Talking-Head-Generation" class="headerlink" title="Dual Audio-Centric Modality Coupling for Talking Head Generation"></a>Dual Audio-Centric Modality Coupling for Talking Head Generation</h2><p><strong>Authors:Ao Fu, Ziqi Ni, Yi Zhou</strong></p>
<p>The generation of audio-driven talking head videos is a key challenge in computer vision and graphics, with applications in virtual avatars and digital media. Traditional approaches often struggle with capturing the complex interaction between audio and facial dynamics, leading to lip synchronization and visual quality issues. In this paper, we propose a novel NeRF-based framework, Dual Audio-Centric Modality Coupling (DAMC), which effectively integrates content and dynamic features from audio inputs. By leveraging a dual encoder structure, DAMC captures semantic content through the Content-Aware Encoder and ensures precise visual synchronization through the Dynamic-Sync Encoder. These features are fused using a Cross-Synchronized Fusion Module (CSFM), enhancing content representation and lip synchronization. Extensive experiments show that our method outperforms existing state-of-the-art approaches in key metrics such as lip synchronization accuracy and image quality, demonstrating robust generalization across various audio inputs, including synthetic speech from text-to-speech (TTS) systems. Our results provide a promising solution for high-quality, audio-driven talking head generation and present a scalable approach for creating realistic talking heads. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨å¼è¯´è¯äººå¤´éƒ¨è§†é¢‘ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦é¢†åŸŸçš„å…³é”®æŒ‘æˆ˜ï¼Œåœ¨è™šæ‹ŸåŒ–èº«å’Œæ•°å­—åª’ä½“ä¸­æœ‰å¹¿æ³›åº”ç”¨ã€‚ä¼ ç»Ÿæ–¹æ³•å¾€å¾€éš¾ä»¥æ•æ‰éŸ³é¢‘å’Œé¢éƒ¨åŠ¨æ€ä¹‹é—´çš„å¤æ‚äº¤äº’ï¼Œå¯¼è‡´å”‡åŒæ­¥å’Œè§†è§‰è´¨é‡é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºNeRFçš„æ–°å‹æ¡†æ¶â€”â€”åŒéŸ³é¢‘ä¸­å¿ƒæ¨¡æ€è€¦åˆï¼ˆDAMCï¼‰ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°èåˆäº†éŸ³é¢‘è¾“å…¥çš„æ–‡æœ¬å†…å®¹å’ŒåŠ¨æ€ç‰¹å¾ã€‚é€šè¿‡åˆ©ç”¨åŒç¼–ç å™¨ç»“æ„ï¼ŒDAMCé€šè¿‡å†…å®¹æ„ŸçŸ¥ç¼–ç å™¨æ•è·è¯­ä¹‰å†…å®¹ï¼Œå¹¶é€šè¿‡åŠ¨æ€åŒæ­¥ç¼–ç å™¨ç¡®ä¿ç²¾ç¡®çš„è§†è§‰åŒæ­¥ã€‚è¿™äº›ç‰¹å¾é€šè¿‡è·¨åŒæ­¥èåˆæ¨¡å—ï¼ˆCSFMï¼‰èåˆï¼Œå¢å¼ºäº†å†…å®¹è¡¨ç¤ºå’Œå”‡åŒæ­¥åŠŸèƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å”‡åŒæ­¥å‡†ç¡®æ€§å’Œå›¾åƒè´¨é‡ç­‰å…³é”®æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ¡ˆï¼Œåœ¨åŒ…æ‹¬æ¥è‡ªæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿçš„åˆæˆè¯­éŸ³ç­‰å„ç§éŸ³é¢‘è¾“å…¥ä¸Šéƒ½è¡¨ç°å‡ºç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœä¸ºè§£å†³é«˜è´¨é‡éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆé—®é¢˜æä¾›äº†å‰æ™¯å¹¿é˜”çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶æå‡ºäº†ä¸€ç§å¯åˆ›å»ºé€¼çœŸè¯´è¯äººå¤´éƒ¨çš„å¯æ‰©å±•æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22728v1">PDF</a> 9 pages, 4 figures</p>
<p><strong>Summary</strong><br>éŸ³é¢‘é©±åŠ¨å¼è°ˆè¯å¤´è§†é¢‘ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦é¢†åŸŸçš„å…³é”®æŒ‘æˆ˜ï¼Œåº”ç”¨äºè™šæ‹Ÿè§’è‰²å’Œæ•°å­—åª’ä½“ã€‚æœ¬æ–‡æå‡ºåŸºäºNeRFçš„Dual Audio-Centric Modality Couplingï¼ˆDAMCï¼‰æ¡†æ¶ï¼Œæœ‰æ•ˆæ•´åˆéŸ³é¢‘è¾“å…¥çš„é™æ€å’ŒåŠ¨æ€ç‰¹å¾ã€‚é€šè¿‡åŒé‡ç¼–ç å™¨ç»“æ„ï¼ŒDAMCé€šè¿‡å†…å®¹æ„ŸçŸ¥ç¼–ç å™¨æ•æ‰è¯­ä¹‰å†…å®¹ï¼Œå¹¶é€šè¿‡åŠ¨æ€åŒæ­¥ç¼–ç å™¨ç¡®ä¿ç²¾ç¡®è§†è§‰åŒæ­¥ã€‚è¿™äº›ç‰¹å¾é€šè¿‡è·¨åŒæ­¥èåˆæ¨¡å—è¿›è¡Œèåˆï¼Œæé«˜å†…å®¹è¡¨è¾¾å’Œå”‡åŒæ­¥æ•ˆæœã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å”‡åŒæ­¥ç²¾åº¦å’Œå›¾åƒè´¨é‡ç­‰å…³é”®æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ï¼Œä¸”åœ¨å„ç§éŸ³é¢‘è¾“å…¥ä¸Šå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿçš„åˆæˆè¯­éŸ³ã€‚æœ¬ç ”ç©¶ä¸ºé«˜è´¨é‡éŸ³é¢‘é©±åŠ¨è°ˆè¯å¤´ç”Ÿæˆæä¾›æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éŸ³é¢‘é©±åŠ¨è°ˆè¯å¤´è§†é¢‘ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦çš„é‡è¦æŒ‘æˆ˜ï¼Œå…·æœ‰è™šæ‹Ÿè§’è‰²å’Œæ•°å­—åª’ä½“åº”ç”¨ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ•æ‰éŸ³é¢‘å’Œé¢éƒ¨åŠ¨ä½œä¹‹é—´çš„å¤æ‚äº¤äº’ï¼Œå¯¼è‡´å”‡åŒæ­¥å’Œè§†è§‰è´¨é‡é—®é¢˜ã€‚</li>
<li>DAMCæ¡†æ¶åŸºäºNeRFæŠ€æœ¯ï¼Œæœ‰æ•ˆæ•´åˆéŸ³é¢‘çš„é™æ€å’ŒåŠ¨æ€ç‰¹å¾ã€‚</li>
<li>åŒé‡ç¼–ç å™¨ç»“æ„åŒ…æ‹¬å†…å®¹æ„ŸçŸ¥ç¼–ç å™¨å’ŒåŠ¨æ€åŒæ­¥ç¼–ç å™¨ï¼Œåˆ†åˆ«æ•æ‰è¯­ä¹‰å†…å®¹å’Œç¡®ä¿ç²¾ç¡®è§†è§‰åŒæ­¥ã€‚</li>
<li>è·¨åŒæ­¥èåˆæ¨¡å—ï¼ˆCSFMï¼‰èåˆé™æ€å’ŒåŠ¨æ€ç‰¹å¾ï¼Œæé«˜å†…å®¹è¡¨è¾¾å’Œå”‡åŒæ­¥æ•ˆæœã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDAMCåœ¨å”‡åŒæ­¥ç²¾åº¦å’Œå›¾åƒè´¨é‡ç­‰æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22728">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2b2c7d49850f18f4d83bef5aebdce69d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f14fbcc16baec813cf008cbb3379f343.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d792a51b6c87be14443f6a1fbc972941.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df38b1b97f3c37aa076c7f6fdd8e6fd1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2563f0e3ff5ac02b7aacf1380dc9a5c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10b2b6a0f229fd4764b744d91119afd6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Audio-Plane-Audio-Factorization-Plane-Gaussian-Splatting-for-Real-Time-Talking-Head-Synthesis"><a href="#Audio-Plane-Audio-Factorization-Plane-Gaussian-Splatting-for-Real-Time-Talking-Head-Synthesis" class="headerlink" title="Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time   Talking Head Synthesis"></a>Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time   Talking Head Synthesis</h2><p><strong>Authors:Shuai Shen, Wanhua Li, Yunpeng Zhang, Weipeng Hu, Yap-Peng Tan</strong></p>
<p>Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in <a target="_blank" rel="noopener" href="https://sstzal.github.io/Audio-Plane/">https://sstzal.github.io/Audio-Plane/</a>. </p>
<blockquote>
<p>è°ˆè¯å¤´åˆæˆå·²æˆä¸ºè®¡ç®—æœºå›¾å½¢å­¦å’Œå¤šåª’ä½“é¢†åŸŸçš„ä¸€ä¸ªå…³é”®ç ”ç©¶è¯¾é¢˜ï¼Œç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥åœ¨ç”Ÿæˆè´¨é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œåˆ©ç”¨åŸºäºéŸ³é¢‘åˆ†è§£å¹³é¢ï¼ˆAudio-Planeï¼‰çš„é«˜æ–¯æº…å‡ºï¼ˆGaussian Splattingï¼‰è¿›è¡Œé«˜è´¨é‡å®æ—¶è°ˆè¯å¤´ç”Ÿæˆã€‚ä¸ºäº†æ¨¡æ‹ŸåŠ¨æ€çš„è°ˆè¯å¤´ï¼Œéœ€è¦4Dä½“ç§¯è¡¨ç¤ºã€‚ç„¶è€Œï¼Œç”±äºæˆæœ¬é«˜æ˜‚å’Œç¼ºä¹é•¿æœŸå¯æ‰©å±•æ€§ï¼Œç›´æ¥å­˜å‚¨å¯†é›†çš„4Dç½‘æ ¼å¹¶ä¸å®ç”¨ã€‚æˆ‘ä»¬å…‹æœäº†è¿™ä¸€æŒ‘æˆ˜ï¼Œé‡‡ç”¨äº†æ‰€æå‡ºçš„éŸ³é¢‘å¹³é¢ï¼ˆAudio-Planeï¼‰ï¼Œå…¶ä¸­å°†4Dä½“ç§¯è¡¨ç¤ºåˆ†è§£æˆä¸éŸ³é¢‘æ— å…³çš„ç©ºé—´å¹³é¢å’Œä¸éŸ³é¢‘ç›¸å…³çš„å¹³é¢ã€‚è¿™ä¸ºè°ˆè¯å¤´æä¾›äº†ç´§å‡‘ä¸”å¯è§£é‡Šçš„ç‰¹å¾è¡¨ç¤ºï¼Œä¿ƒè¿›äº†æ›´ç²¾ç¡®çš„å£°éŸ³æ„ŸçŸ¥ç©ºé—´ç¼–ç å’Œå¢å¼ºçš„éŸ³é¢‘é©±åŠ¨å˜´å”‡åŠ¨æ€å»ºæ¨¡ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜è¯­éŸ³åŠ¨æ€æ•ˆæœï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŠ¨æ€æº…å‡ºæ–¹æ³•ï¼Œå¸®åŠ©ç½‘ç»œæ›´æœ‰æ•ˆåœ°ä¸“æ³¨äºå˜´å·´åŒºåŸŸçš„åŠ¨æ€å»ºæ¨¡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œé€šè¿‡å°†è¿™äº›åˆ›æ–°ä¸å¼ºå¤§çš„é«˜æ–¯æº…å‡ºç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨ç¡®ä¿ç²¾ç¡®éŸ³é¢‘ä¸å˜´å”‡åŒæ­¥çš„åŒæ—¶ï¼Œå®æ—¶åˆæˆé«˜åº¦é€¼çœŸçš„å¯¹è¯è§†é¢‘ã€‚åˆæˆç»“æœå¯åœ¨<a target="_blank" rel="noopener" href="https://sstzal.github.io/Audio-Plane/%E6%9F%A5%E7%9C%8B%E3%80%82">https://sstzal.github.io/Audio-Plane/æŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22605v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéŸ³é¢‘åˆ†è§£å¹³é¢çš„é«˜æ–¯æº…æ³¼æ³•ï¼Œç”¨äºé«˜è´¨é‡å®æ—¶è¯´è¯äººå¤´éƒ¨çš„åˆæˆã€‚é’ˆå¯¹åŠ¨æ€è¯´è¯äººå¤´éƒ¨çš„å»ºæ¨¡ï¼Œé‡‡ç”¨4Dä½“ç§¯è¡¨ç¤ºæ³•ï¼Œä½†ç›´æ¥å­˜å‚¨å¯†é›†4Dç½‘æ ¼ä¸å®é™…ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†éŸ³é¢‘åˆ†è§£å¹³é¢ï¼Œå°†4Dä½“ç§¯è¡¨ç¤ºåˆ†è§£ä¸ºéŸ³é¢‘ç‹¬ç«‹çš„ç©ºé—´å¹³é¢å’ŒéŸ³é¢‘ä¾èµ–å¹³é¢ï¼Œä¸ºè¯´è¯å¤´éƒ¨æä¾›ç´§å‡‘ä¸”å¯è§£é‡Šçš„ç‰¹å¾è¡¨ç¤ºï¼Œä¿ƒè¿›æ›´ç²¾ç¡®çš„éŸ³é¢‘æ„ŸçŸ¥ç©ºé—´ç¼–ç å’Œå¢å¼ºçš„éŸ³é¢‘é©±åŠ¨å”‡åŠ¨æ€å»ºæ¨¡ã€‚å®éªŒè¡¨æ˜ï¼Œç»“åˆé«˜æ–¯æº…æ³¼æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å®æ—¶åˆæˆé«˜åº¦é€¼çœŸçš„è¯´è¯è§†é¢‘ï¼Œç¡®ä¿éŸ³é¢‘ä¸å˜´å”‡çš„ç²¾ç¡®åŒæ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯´è¯å¤´åˆæˆæ˜¯è®¡ç®—æœºå›¾å½¢å­¦å’Œå¤šåª’ä½“çš„å…³é”®ç ”ç©¶é¢†åŸŸï¼Œä½†å¹³è¡¡ç”Ÿæˆè´¨é‡ä¸è®¡ç®—æ•ˆç‡æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéŸ³é¢‘åˆ†è§£å¹³é¢çš„é«˜æ–¯æº…æ³¼æ³•ï¼Œç”¨äºé«˜è´¨é‡å®æ—¶è¯´è¯å¤´ç”Ÿæˆã€‚</li>
<li>4Dä½“ç§¯è¡¨ç¤ºæ³•ç”¨äºå»ºæ¨¡åŠ¨æ€è¯´è¯å¤´éƒ¨ï¼Œä½†ç›´æ¥å­˜å‚¨å¯†é›†4Dç½‘æ ¼ä¸å®é™…ã€‚</li>
<li>æå‡ºçš„éŸ³é¢‘åˆ†è§£å¹³é¢è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œå°†4Dä½“ç§¯è¡¨ç¤ºä¸ºéŸ³é¢‘ç‹¬ç«‹å’Œä¾èµ–çš„å¹³é¢ã€‚</li>
<li>æ­¤æ–¹æ³•æä¾›äº†ä¸€ç§ç´§å‡‘ä¸”å¯è§£é‡Šçš„ç‰¹å¾è¡¨ç¤ºï¼Œä¿ƒè¿›äº†æ›´ç²¾ç¡®çš„éŸ³é¢‘æ„ŸçŸ¥ç©ºé—´ç¼–ç å’Œå”‡åŠ¨æ€å»ºæ¨¡ã€‚</li>
<li>ç»“åˆé«˜æ–¯æº…æ³¼æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å®æ—¶åˆæˆé«˜åº¦é€¼çœŸçš„è¯´è¯è§†é¢‘ã€‚</li>
<li>åˆæˆç»“æœå¯åœ¨<a target="_blank" rel="noopener" href="https://sstzal.github.io/Audio-Plane/">é“¾æ¥</a>æŸ¥çœ‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22605">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-dc3945e146a1125a5d769517b491305e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c343fd56b0ea0f2ccfabdd9058dcf16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb17023d93340211b982eb56e0a42e41.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c0d22507b0d089e075c77b6ec79cfee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-14c4fa59a61d1b3a409ba585990402d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08c3de0ff764017706147587374a97e4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Follow-Your-Motion-A-Generic-Temporal-Consistency-Portrait-Editing-Framework-with-Trajectory-Guidance"><a href="#Follow-Your-Motion-A-Generic-Temporal-Consistency-Portrait-Editing-Framework-with-Trajectory-Guidance" class="headerlink" title="Follow Your Motion: A Generic Temporal Consistency Portrait Editing   Framework with Trajectory Guidance"></a>Follow Your Motion: A Generic Temporal Consistency Portrait Editing   Framework with Trajectory Guidance</h2><p><strong>Authors:Haijie Yang, Zhenyu Zhang, Hao Tang, Jianjun Qian, Jian Yang</strong></p>
<p>Pre-trained conditional diffusion models have demonstrated remarkable potential in image editing. However, they often face challenges with temporal consistency, particularly in the talking head domain, where continuous changes in facial expressions intensify the level of difficulty. These issues stem from the independent editing of individual images and the inherent loss of temporal continuity during the editing process. In this paper, we introduce Follow Your Motion (FYM), a generic framework for maintaining temporal consistency in portrait editing. Specifically, given portrait images rendered by a pre-trained 3D Gaussian Splatting model, we first develop a diffusion model that intuitively and inherently learns motion trajectory changes at different scales and pixel coordinates, from the first frame to each subsequent frame. This approach ensures that temporally inconsistent edited avatars inherit the motion information from the rendered avatars. Secondly, to maintain fine-grained expression temporal consistency in talking head editing, we propose a dynamic re-weighted attention mechanism. This mechanism assigns higher weight coefficients to landmark points in space and dynamically updates these weights based on landmark loss, achieving more consistent and refined facial expressions. Extensive experiments demonstrate that our method outperforms existing approaches in terms of temporal consistency and can be used to optimize and compensate for temporally inconsistent outputs in a range of applications, such as text-driven editing, relighting, and various other applications. </p>
<blockquote>
<p>é¢„è®­ç»ƒæ¡ä»¶æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç¼–è¾‘æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨æ—¶é—´è¿ç»­æ€§æ–¹é¢å¸¸å¸¸é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤´éƒ¨è¯´è¯é¢†åŸŸï¼Œé¢éƒ¨è¡¨æƒ…çš„è¿ç»­å˜åŒ–å¢åŠ äº†éš¾åº¦ã€‚è¿™äº›é—®é¢˜æºäºå•ç‹¬ç¼–è¾‘çš„å›¾åƒå’Œç¼–è¾‘è¿‡ç¨‹ä¸­å›ºæœ‰çš„æ—¶é—´è¿ç»­æ€§ä¸§å¤±ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Follow Your Motionï¼ˆFYMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¿æŒè‚–åƒç¼–è¾‘ä¸­æ—¶é—´è¿ç»­æ€§çš„é€šç”¨æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šç”±é¢„è®­ç»ƒçš„3Dé«˜æ–¯æ‹¼æ¥æ¨¡å‹æ¸²æŸ“çš„è‚–åƒå›¾åƒï¼Œæˆ‘ä»¬é¦–å…ˆå¼€å‘äº†ä¸€ç§æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç›´è§‰åœ°ã€å›ºæœ‰åœ°å­¦ä¹ ä»ç¬¬ä¸€å¸§åˆ°æ¯ä¸€åç»­å¸§ä¸åŒå°ºåº¦å’Œåƒç´ åæ ‡çš„è¿åŠ¨è½¨è¿¹å˜åŒ–ã€‚è¿™ç§æ–¹æ³•ç¡®ä¿äº†æ—¶é—´ä¸Šä¸ä¸€è‡´çš„ç¼–è¾‘åŒ–èº«ç»§æ‰¿äº†ä»æ¸²æŸ“åŒ–èº«ç»§æ‰¿çš„è¿åŠ¨ä¿¡æ¯ã€‚å…¶æ¬¡ï¼Œä¸ºäº†ä¿æŒå¤´éƒ¨è¯´è¯ä¸­ç²¾ç»†è¡¨æƒ…çš„æ—¶é—´è¿ç»­æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨æ€åŠ æƒæ³¨æ„åŠ›æœºåˆ¶ã€‚è¯¥æœºåˆ¶åœ¨ç©ºé—´åœ°æ ‡ç‚¹ä¸Šåˆ†é…è¾ƒé«˜çš„æƒé‡ç³»æ•°ï¼Œå¹¶æ ¹æ®åœ°æ ‡æŸå¤±åŠ¨æ€æ›´æ–°è¿™äº›æƒé‡ï¼Œä»è€Œå®ç°æ›´ä¸€è‡´å’Œæ›´ç²¾ç»†çš„é¢éƒ¨è¡¨æƒ…ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ—¶é—´è¿ç»­æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å¯ç”¨äºä¼˜åŒ–å’Œè¡¥å¿ä¸€ç³»åˆ—åº”ç”¨ä¸­æ—¶é—´ä¸Šä¸ä¸€è‡´çš„è¾“å‡ºï¼Œå¦‚æ–‡æœ¬é©±åŠ¨ç¼–è¾‘ã€é‡æ–°ç…§æ˜å’Œå…¶ä»–å„ç§åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22225v1">PDF</a> <a target="_blank" rel="noopener" href="https://anonymous-hub1127.github.io/FYM.github.io/">https://anonymous-hub1127.github.io/FYM.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€é‡å»ºåŠ æƒæ³¨æ„åŠ›æœºåˆ¶çš„ä¸´æ—¶ä¸€è‡´æ€§æ¡†æ¶Follow Your Motionï¼ˆFYMï¼‰ï¼Œç”¨äºè‚–åƒç¼–è¾‘ä¸­çš„è¯´è¯å¤´ç”Ÿæˆã€‚è¯¥æ¡†æ¶ä½¿ç”¨é¢„è®­ç»ƒçš„3Dé«˜æ–¯å–·å°„æ¨¡å‹æ¸²æŸ“çš„è‚–åƒå›¾åƒï¼Œé€šè¿‡å¼€å‘ä¸€ç§æ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ å’Œä¿æŒä¸åŒå°ºåº¦å’Œåƒç´ åæ ‡çš„è¿åŠ¨è½¨è¿¹å˜åŒ–ï¼Œç¡®ä¿ç¼–è¾‘åçš„åŒ–èº«åœ¨æ—¶é—´ä¸Šçš„è¿ç»­æ€§ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§åŠ¨æ€åŠ æƒæ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥ç»´æŒç²¾ç»†è¡¨æƒ…çš„æ—¶é—´ä¸€è‡´æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ—¶é—´ä¸Šçš„ä¸€è‡´æ€§å’Œç²¾ç»†è¡¨æƒ…çš„å¤„ç†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†åŸºäºé¢„è®­ç»ƒæ¡ä»¶æ‰©æ•£æ¨¡å‹çš„è¯´è¯å¤´ç”Ÿæˆé¢ä¸´çš„æŒ‘æˆ˜ã€‚è¿™ç±»æŒ‘æˆ˜ä¸»è¦ç”±äºå¯¹å•ç‹¬å›¾åƒç‹¬ç«‹ç¼–è¾‘æ—¶çš„æ—¶åºä¸€è‡´æ€§æŸå¤±æ‰€å¯¼è‡´ã€‚ç‰¹åˆ«æ˜¯åœ¨é¢éƒ¨è¡¨æƒ…è¿ç»­å˜åŒ–çš„æƒ…å¢ƒä¸­ï¼ŒæŒ‘æˆ˜æ›´åŠ ä¸¥é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é€šç”¨æ¡†æ¶Follow Your Motion (FYM)ï¼Œæ—¨åœ¨ç»´æŠ¤è‚–åƒç¼–è¾‘ä¸­çš„æ—¶åºä¸€è‡´æ€§ã€‚é€šè¿‡å¼€å‘æ‰©æ•£æ¨¡å‹å¹¶ä½¿å…¶å­¦ä¹ ä¸ç‰¹å®šæ—¶é—´èŠ‚ç‚¹ç›¸å…³çš„è¿åŠ¨è½¨è¿¹å˜åŒ–ï¼Œè¯¥æ¡†æ¶è§£å†³äº†æ—¶åºä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>FYMæ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒçš„3Dé«˜æ–¯å–·å°„æ¨¡å‹è¿›è¡Œè‚–åƒå›¾åƒæ¸²æŸ“ï¼Œå¹¶åˆ©ç”¨åŠ¨æ€é‡å»ºåŠ æƒæ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿é¢éƒ¨è¡¨æƒ…çš„æ—¶é—´è¿ç»­æ€§ã€‚è¯¥æœºåˆ¶èƒ½å¤ŸåŠ¨æ€æ›´æ–°æƒé‡ç³»æ•°ï¼Œä»è€Œå®ç°æ›´ä¸€è‡´å’Œç²¾ç»†çš„é¢éƒ¨è¡¨æƒ…å¤„ç†ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥é€šè¿‡æ–‡æœ¬é©±åŠ¨ç¼–è¾‘ç­‰å¤šç§åº”ç”¨æ¥ä¼˜åŒ–å’Œæ”¹è¿›æ—¶åºä¸ä¸€è‡´çš„è¾“å‡ºç»“æœã€‚æ­¤å¤–ï¼Œå®ƒè¿˜é€‚ç”¨äºå…¶ä»–é¢†åŸŸï¼Œå¦‚é‡å…‰ç…§ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22225">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6725e5853e68312abac51138f36ca65d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f37cc1db7dcc820728edb284f3e7f363.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be1270885bb708ff577e542962192517.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Audio-driven-Gesture-Generation-via-Deviation-Feature-in-the-Latent-Space"><a href="#Audio-driven-Gesture-Generation-via-Deviation-Feature-in-the-Latent-Space" class="headerlink" title="Audio-driven Gesture Generation via Deviation Feature in the Latent   Space"></a>Audio-driven Gesture Generation via Deviation Feature in the Latent   Space</h2><p><strong>Authors:Jiahui Chen, Yang Huan, Runhua Shi, Chanfan Ding, Xiaoqi Mo, Siyu Xiong, Yinong He</strong></p>
<p>Gestures are essential for enhancing co-speech communication, offering visual emphasis and complementing verbal interactions. While prior work has concentrated on point-level motion or fully supervised data-driven methods, we focus on co-speech gestures, advocating for weakly supervised learning and pixel-level motion deviations. We introduce a weakly supervised framework that learns latent representation deviations, tailored for co-speech gesture video generation. Our approach employs a diffusion model to integrate latent motion features, enabling more precise and nuanced gesture representation. By leveraging weakly supervised deviations in latent space, we effectively generate hand gestures and mouth movements, crucial for realistic video production. Experiments show our method significantly improves video quality, surpassing current state-of-the-art techniques. </p>
<blockquote>
<p>æ‰‹åŠ¿å¯¹äºå¢å¼ºä¼´éšè¯­éŸ³çš„äº¤æµã€æä¾›è§†è§‰é‡ç‚¹ä»¥åŠè¡¥å……å£å¤´äº’åŠ¨è‡³å…³é‡è¦ã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ç‚¹çº§è¿åŠ¨æˆ–å®Œå…¨ç›‘ç£çš„æ•°æ®é©±åŠ¨æ–¹æ³•ä¸Šï¼Œä½†æˆ‘ä»¬ä¸“æ³¨äºä¼´éšè¯­éŸ³çš„æ‰‹åŠ¿ï¼Œä¸»å¼ é‡‡ç”¨å¼±ç›‘ç£å­¦ä¹ å’Œåƒç´ çº§è¿åŠ¨åå·®ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¼±ç›‘ç£æ¡†æ¶ï¼Œç”¨äºå­¦ä¹ æ½œåœ¨è¡¨ç¤ºåå·®ï¼Œè¯¥æ¡†æ¶ä¸“ä¸ºä¼´éšè¯­éŸ³çš„æ‰‹åŠ¿è§†é¢‘ç”Ÿæˆè€Œè®¾è®¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ¥æ•´åˆæ½œåœ¨è¿åŠ¨ç‰¹å¾ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®å’Œç»†å¾®çš„æ‰‹åŠ¿è¡¨ç¤ºã€‚é€šè¿‡åˆ©ç”¨æ½œåœ¨ç©ºé—´ä¸­çš„å¼±ç›‘ç£åå·®ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°ç”Ÿæˆå¯¹çœŸå®è§†é¢‘åˆ¶ä½œè‡³å…³é‡è¦çš„æ‰‹åŠ¿å’Œå£å‹è¿åŠ¨ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†è§†é¢‘è´¨é‡ï¼Œè¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.21616v1">PDF</a> 6 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡é‡ç‚¹ç ”ç©¶é€šè¿‡å¾®å¼±ç›‘ç£å­¦ä¹ çš„æ–¹å¼è¿›è¡Œè¯­éŸ³ä¼´éšæ‰‹åŠ¿çš„è§†é¢‘ç”Ÿæˆã€‚é€šè¿‡å¼•å…¥æ‰©æ•£æ¨¡å‹æ•´åˆæ½œåœ¨è¿åŠ¨ç‰¹å¾ï¼Œå®ç°ç²¾å‡†ä¸”ç»†è…»çš„æ‰‹åŠ¿è¡¨è¾¾ã€‚åˆ©ç”¨æ½œåœ¨ç©ºé—´çš„å¾®å¼±ç›‘ç£åå·®ï¼Œæœ‰æ•ˆç”Ÿæˆæ‰‹éƒ¨å’Œå£éƒ¨åŠ¨ä½œï¼Œå¯¹çœŸå®è§†é¢‘åˆ¶ä½œè‡³å…³é‡è¦ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜è§†é¢‘è´¨é‡ï¼Œè¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ä¸­æŒ‡å‡ºæ‰‹åŠ¿åœ¨ä¼´éšè¯­éŸ³äº¤æµä¸­çš„é‡è¦æ€§ï¼Œå¯å¢å¼ºè§†è§‰å¼ºè°ƒå’Œè¡¥å……è¯­è¨€äº¤äº’ã€‚</li>
<li>ä¸å…ˆå‰é›†ä¸­åœ¨ç‚¹çŠ¶è¿åŠ¨æˆ–å®Œå…¨ç›‘ç£æ•°æ®é©±åŠ¨æ–¹æ³•çš„ç ”ç©¶ä¸åŒï¼Œè¯¥æ–‡é‡ç‚¹å…³æ³¨ä¼´éšè¯­éŸ³çš„æ‰‹åŠ¿ï¼Œæå€¡å¾®å¼±ç›‘ç£å­¦ä¹ å’Œåƒç´ çº§è¿åŠ¨åå·®ã€‚</li>
<li>æå‡ºä¸€ä¸ªå¾®å¼±ç›‘ç£æ¡†æ¶æ¥å­¦ä¹ æ½œåœ¨è¡¨ç¤ºçš„åå·®ï¼Œä¸“é—¨ä¸ºä¼´éšè¯­éŸ³çš„æ‰‹åŠ¿è§†é¢‘ç”Ÿæˆé‡èº«å®šåˆ¶ã€‚</li>
<li>é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ•´åˆæ½œåœ¨è¿åŠ¨ç‰¹å¾ï¼Œå®ç°æ›´ç²¾ç¡®å’Œç»†è‡´çš„æ‰‹åŠ¿è¡¨ç¤ºã€‚</li>
<li>åˆ©ç”¨æ½œåœ¨ç©ºé—´çš„å¾®å¼±ç›‘ç£åå·®æœ‰æ•ˆç”Ÿæˆæ‰‹éƒ¨å’Œå£éƒ¨åŠ¨ä½œï¼Œè¿™å¯¹ç°å®è§†é¢‘åˆ¶ä½œè‡³å…³é‡è¦ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è§†é¢‘è´¨é‡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æ”¹è¿›ï¼Œè¶…è¶Šäº†å½“å‰æœ€æ–°æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.21616">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7138059a063342f592d75c6a9945c15b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9e7115f2323a1e7d0f0297174dd40f65.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6d4fbe00df14c2e1d8ae7f82ff6831fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2668786f39d724ebed68e6da2cb4613f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-84fc6360676a42906040df9b4ab89780.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-376cfee76908c62a587e55d9c2d8d693.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a518ed8fa81b909c27c903140a12dc32.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Perceptually-Accurate-3D-Talking-Head-Generation-New-Definitions-Speech-Mesh-Representation-and-Evaluation-Metrics"><a href="#Perceptually-Accurate-3D-Talking-Head-Generation-New-Definitions-Speech-Mesh-Representation-and-Evaluation-Metrics" class="headerlink" title="Perceptually Accurate 3D Talking Head Generation: New Definitions,   Speech-Mesh Representation, and Evaluation Metrics"></a>Perceptually Accurate 3D Talking Head Generation: New Definitions,   Speech-Mesh Representation, and Evaluation Metrics</h2><p><strong>Authors:Lee Chae-Yeon, Oh Hyun-Bin, Han EunGi, Kim Sung-Bin, Suekyeong Nam, Tae-Hyun Oh</strong></p>
<p>Recent advancements in speech-driven 3D talking head generation have made significant progress in lip synchronization. However, existing models still struggle to capture the perceptual alignment between varying speech characteristics and corresponding lip movements. In this work, we claim that three criteria â€“ Temporal Synchronization, Lip Readability, and Expressiveness â€“ are crucial for achieving perceptually accurate lip movements. Motivated by our hypothesis that a desirable representation space exists to meet these three criteria, we introduce a speech-mesh synchronized representation that captures intricate correspondences between speech signals and 3D face meshes. We found that our learned representation exhibits desirable characteristics, and we plug it into existing models as a perceptual loss to better align lip movements to the given speech. In addition, we utilize this representation as a perceptual metric and introduce two other physically grounded lip synchronization metrics to assess how well the generated 3D talking heads align with these three criteria. Experiments show that training 3D talking head generation models with our perceptual loss significantly improve all three aspects of perceptually accurate lip synchronization. Codes and datasets are available at <a target="_blank" rel="noopener" href="https://perceptual-3d-talking-head.github.io/">https://perceptual-3d-talking-head.github.io/</a>. </p>
<blockquote>
<p>è¿‘æœŸè¯­éŸ³é©±åŠ¨çš„3DåŠ¨æ€å¤´éƒ¨ç”ŸæˆæŠ€æœ¯çš„è¿›å±•åœ¨å”‡åŒæ­¥æ–¹é¢å–å¾—äº†é‡å¤§çªç ´ã€‚ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹åœ¨æ•æ‰ä¸åŒè¯­éŸ³ç‰¹å¾å’Œç›¸åº”å”‡éƒ¨è¿åŠ¨ä¹‹é—´çš„æ„ŸçŸ¥å¯¹é½æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºæ—¶é—´åŒæ­¥ã€å”‡å¯è¯»æ€§å’Œè¡¨ç°åŠ›è¿™ä¸‰ä¸ªæ ‡å‡†æ˜¯å®ç°æ„ŸçŸ¥å‡†ç¡®å”‡éƒ¨è¿åŠ¨çš„å…³é”®ã€‚å—å­˜åœ¨ä¸€ä¸ªç¬¦åˆè¿™ä¸‰ä¸ªæ ‡å‡†çš„ç†æƒ³è¡¨ç¤ºç©ºé—´çš„å‡è®¾çš„é©±åŠ¨ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è¯­éŸ³ç½‘æ ¼åŒæ­¥è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºæ•æ‰äº†è¯­éŸ³ä¿¡å·å’Œ3Dé¢éƒ¨ç½‘æ ¼ä¹‹é—´çš„ç²¾ç»†å¯¹åº”å…³ç³»ã€‚æˆ‘ä»¬å‘ç°ï¼Œæˆ‘ä»¬å­¦åˆ°çš„è¡¨ç¤ºå…·æœ‰ç†æƒ³çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬å°†å…¶æ’å…¥ç°æœ‰æ¨¡å‹ä½œä¸ºæ„ŸçŸ¥æŸå¤±ï¼Œä»¥æ›´å¥½åœ°å°†å”‡éƒ¨è¿åŠ¨ä¸ç»™å®šè¯­éŸ³å¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨è¿™ç§è¡¨ç¤ºä½œä¸ºæ„ŸçŸ¥åº¦é‡ï¼Œå¹¶å¼•å…¥å…¶ä»–ä¸¤ä¸ªåŸºäºç‰©ç†çš„å”‡åŒæ­¥åº¦é‡æ ‡å‡†ï¼Œä»¥è¯„ä¼°ç”Ÿæˆçš„3DåŠ¨æ€å¤´éƒ¨ä¸è¿™ä¸‰ä¸ªæ ‡å‡†çš„å¯¹é½ç¨‹åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ„ŸçŸ¥æŸå¤±è®­ç»ƒ3DåŠ¨æ€å¤´éƒ¨ç”Ÿæˆæ¨¡å‹å¯ä»¥æ˜¾è‘—æé«˜è¿™ä¸‰ä¸ªæ–¹é¢çš„æ„ŸçŸ¥å‡†ç¡®å”‡åŒæ­¥ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://perceptual-3d-talking-head.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://perceptual-3d-talking-head.github.io/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20308v3">PDF</a> CVPR 2025. Project page:   <a target="_blank" rel="noopener" href="https://perceptual-3d-talking-head.github.io/">https://perceptual-3d-talking-head.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è¿‘æœŸè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´åŠ¨æ€å¤´éƒ¨ç”ŸæˆæŠ€æœ¯çš„è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨å”‡éƒ¨åŒæ­¥æ–¹é¢çš„æˆæœã€‚æ–‡ç« æŒ‡å‡ºï¼Œç°æœ‰æ¨¡å‹åœ¨æ•æ‰ä¸åŒè¯­éŸ³ç‰¹å¾ä¸å”‡éƒ¨è¿åŠ¨çš„æ„ŸçŸ¥å¯¹é½æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†ä¸‰å¤§å…³é”®æ ‡å‡†â€”â€”æ—¶é—´åŒæ­¥ã€å”‡å¯è¯»æ€§å’Œè¡¨ç°åŠ›ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§è¯­éŸ³ç½‘æ ¼åŒæ­¥è¡¨ç¤ºæ³•ï¼Œè¯¥è¡¨ç¤ºæ³•èƒ½å¤Ÿæ•æ‰è¯­éŸ³ä¿¡å·ä¸ä¸‰ç»´é¢éƒ¨ç½‘æ ¼ä¹‹é—´çš„ç²¾ç»†å¯¹åº”å…³ç³»ã€‚é€šè¿‡å°†è¿™ç§è¡¨ç¤ºæ³•ä½œä¸ºæ„ŸçŸ¥æŸå¤±æ’å…¥ç°æœ‰æ¨¡å‹ä¸­ï¼Œå¯ä»¥æ›´å¥½åœ°å¯¹é½å”‡éƒ¨è¿åŠ¨ä¸ç»™å®šè¯­éŸ³ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜åˆ©ç”¨è¿™ç§è¡¨ç¤ºæ³•ä½œä¸ºæ„ŸçŸ¥æŒ‡æ ‡ï¼Œå¹¶å¼•å…¥å¦å¤–ä¸¤ä¸ªåŸºäºç‰©ç†çš„å”‡éƒ¨åŒæ­¥æŒ‡æ ‡æ¥è¯„ä¼°ç”Ÿæˆçš„3DåŠ¨æ€å¤´éƒ¨ä¸ä¸‰å¤§æ ‡å‡†çš„å¯¹é½ç¨‹åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨æœ¬æ–‡çš„æ„ŸçŸ¥æŸå¤±è®­ç»ƒ3DåŠ¨æ€å¤´éƒ¨ç”Ÿæˆæ¨¡å‹ï¼Œå¯æ˜¾è‘—æé«˜å”‡éƒ¨åŒæ­¥çš„æ„ŸçŸ¥å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰æ¨¡å‹åœ¨æ•æ‰è¯­éŸ³ç‰¹å¾ä¸å”‡éƒ¨è¿åŠ¨æ„ŸçŸ¥å¯¹é½æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>æå‡ºä¸‰å¤§å…³é”®æ ‡å‡†ï¼šæ—¶é—´åŒæ­¥ã€å”‡å¯è¯»æ€§å’Œè¡¨ç°åŠ›ã€‚</li>
<li>å¼•å…¥ä¸€ç§è¯­éŸ³ç½‘æ ¼åŒæ­¥è¡¨ç¤ºæ³•ï¼Œæ•æ‰è¯­éŸ³ä¿¡å·ä¸ä¸‰ç»´é¢éƒ¨ç½‘æ ¼çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>å°†æ„ŸçŸ¥æŸå¤±æ’å…¥ç°æœ‰æ¨¡å‹ï¼Œæé«˜å”‡éƒ¨è¿åŠ¨ä¸è¯­éŸ³çš„å¯¹é½ç¨‹åº¦ã€‚</li>
<li>åˆ©ç”¨æ„ŸçŸ¥æŒ‡æ ‡è¯„ä¼°ç”Ÿæˆçš„3DåŠ¨æ€å¤´éƒ¨çš„è´¨é‡ã€‚</li>
<li>å¼•å…¥ä¸¤ä¸ªåŸºäºç‰©ç†çš„å”‡éƒ¨åŒæ­¥æŒ‡æ ‡æ¥å…¨é¢è¯„ä¼°ç”Ÿæˆç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20308">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9f6ad84fc7ee2c5a5fc278afbadeebb2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b006ec602588634cf2676fae527136a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9931459f2549efa7fd64c7866ba8a97a.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="MagicDistillation-Weak-to-Strong-Video-Distillation-for-Large-Scale-Few-Step-Synthesis"><a href="#MagicDistillation-Weak-to-Strong-Video-Distillation-for-Large-Scale-Few-Step-Synthesis" class="headerlink" title="MagicDistillation: Weak-to-Strong Video Distillation for Large-Scale   Few-Step Synthesis"></a>MagicDistillation: Weak-to-Strong Video Distillation for Large-Scale   Few-Step Synthesis</h2><p><strong>Authors:Shitong Shao, Hongwei Yi, Hanzhong Guo, Tian Ye, Daquan Zhou, Michael Lingelbach, Zhiqiang Xu, Zeke Xie</strong></p>
<p>Recently, open-source video diffusion models (VDMs), such as WanX, Magic141 and HunyuanVideo, have been scaled to over 10 billion parameters. These large-scale VDMs have demonstrated significant improvements over smaller-scale VDMs across multiple dimensions, including enhanced visual quality and more natural motion dynamics. However, these models face two major limitations: (1) High inference overhead: Large-scale VDMs require approximately 10 minutes to synthesize a 28-step video on a single H100 GPU. (2) Limited in portrait video synthesis: Models like WanX-I2V and HunyuanVideo-I2V often produce unnatural facial expressions and movements in portrait videos. To address these challenges, we propose MagicDistillation, a novel framework designed to reduce inference overhead while ensuring the generalization of VDMs for portrait video synthesis. Specifically, we primarily use sufficiently high-quality talking video to fine-tune Magic141, which is dedicated to portrait video synthesis. We then employ LoRA to effectively and efficiently fine-tune the fake DiT within the step distillation framework known as distribution matching distillation (DMD). Following this, we apply weak-to-strong (W2S) distribution matching and minimize the discrepancy between the fake data distribution and the ground truth distribution, thereby improving the visual fidelity and motion dynamics of the synthesized videos. Experimental results on portrait video synthesis demonstrate the effectiveness of MagicDistillation, as our method surpasses Euler, LCM, and DMD baselines in both FID&#x2F;FVD metrics and VBench. Moreover, MagicDistillation, requiring only 4 steps, also outperforms WanX-I2V (14B) and HunyuanVideo-I2V (13B) on visualization and VBench. Our project page is <a target="_blank" rel="noopener" href="https://magicdistillation.github.io/MagicDistillation/">https://magicdistillation.github.io/MagicDistillation/</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¼€æºè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰ï¼Œå¦‚WanXã€Magic141å’ŒHunyuanVideoï¼Œå·²è¢«æ‰©å±•åˆ°è¶…è¿‡10äº¿å‚æ•°ã€‚è¿™äº›å¤§è§„æ¨¡VDMsåœ¨å¤šä¸ªç»´åº¦ä¸Šç›¸å¯¹äºå°è§„æ¨¡VDMsè¡¨ç°å‡ºäº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒ…æ‹¬å¢å¼ºçš„è§†è§‰è´¨é‡å’Œæ›´è‡ªç„¶çš„è¿åŠ¨åŠ¨æ€ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é¢ä¸´ä¸¤å¤§å±€é™ï¼šï¼ˆ1ï¼‰æ¨ç†å¼€é”€é«˜ï¼šå¤§è§„æ¨¡VDMsåœ¨å•ä¸ªH100 GPUä¸Šåˆæˆä¸€ä¸ª28æ­¥çš„è§†é¢‘å¤§çº¦éœ€è¦10åˆ†é’Ÿã€‚ï¼ˆ2ï¼‰è‚–åƒè§†é¢‘åˆæˆå—é™ï¼šå¦‚WanX-I2Vå’ŒHunyuanVideo-I2Vç­‰æ¨¡å‹åœ¨è‚–åƒè§†é¢‘ä¸­ç»å¸¸äº§ç”Ÿä¸è‡ªç„¶çš„é¢éƒ¨è¡¨æƒ…å’ŒåŠ¨ä½œã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MagicDistillationï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–æ¡†æ¶ï¼Œæ—¨åœ¨é™ä½æ¨ç†å¼€é”€ï¼ŒåŒæ—¶ç¡®ä¿VDMåœ¨è‚–åƒè§†é¢‘åˆæˆçš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸»è¦ä½¿ç”¨é«˜è´¨é‡è°ˆè¯è§†é¢‘å¯¹Magic141è¿›è¡Œå¾®è°ƒï¼ŒMagic141æ˜¯ä¸“é—¨ç”¨äºè‚–åƒè§†é¢‘åˆæˆçš„ã€‚ç„¶åï¼Œæˆ‘ä»¬é‡‡ç”¨LoRAåœ¨ç§°ä¸ºåˆ†å¸ƒåŒ¹é…è’¸é¦ï¼ˆDMDï¼‰çš„æ­¥éª¤è’¸é¦æ¡†æ¶å†…æœ‰æ•ˆåœ°å¯¹å‡DiTè¿›è¡Œå¾®è°ƒã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åº”ç”¨å¼±åˆ°å¼ºï¼ˆW2Sï¼‰åˆ†å¸ƒåŒ¹é…ï¼Œå¹¶æœ€å°åŒ–å‡æ•°æ®åˆ†å¸ƒä¸çœŸå®æ•°æ®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œæé«˜åˆæˆè§†é¢‘çš„è§†è§‰ä¿çœŸåº¦å’Œè¿åŠ¨åŠ¨æ€ã€‚è‚–åƒè§†é¢‘åˆæˆçš„å®éªŒç»“æœè¯æ˜äº†MagicDistillationçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨FID&#x2F;FVDæŒ‡æ ‡å’ŒVBenchä¸Šéƒ½è¶…è¶Šäº†Eulerã€LCMå’ŒDMDåŸºçº¿ã€‚æ­¤å¤–ï¼ŒMagicDistillationä»…éœ€4æ­¥ï¼Œè¿˜åœ¨å¯è§†åŒ–å’ŒVBenchä¸Šè¶…è¶Šäº†WanX-I2Vï¼ˆ14Bï¼‰å’ŒHunyuanVideo-I2Vï¼ˆ13Bï¼‰ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ˜¯<a target="_blank" rel="noopener" href="https://magicdistillation.github.io/MagicDistillation/%E3%80%82">https://magicdistillation.github.io/MagicDistillation/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13319v2">PDF</a> </p>
<p><strong>Summary</strong><br>     å¤§å‹å¼€æºè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰å¦‚WanXã€Magic141å’ŒHunyuanVideoå·²æ‰©å±•è‡³è¶…è¿‡åäº¿å‚æ•°ï¼Œå®ƒä»¬åœ¨è§†é¢‘è´¨é‡åŠè¿åŠ¨åŠ¨æ€æ–¹é¢è¡¨ç°ä¼˜è¶Šï¼Œä½†å­˜åœ¨æ¨ç†å¼€é”€å¤§åŠè‚–åƒè§†é¢‘åˆæˆå—é™ç­‰ç¼ºç‚¹ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºMagicDistillationæ¡†æ¶ï¼Œé€šè¿‡é«˜è´¨é‡è§†é¢‘è°ˆè¯æ•°æ®å¯¹Magic141è¿›è¡Œå¾®è°ƒï¼Œç»“åˆLoRAåŠåˆ†å¸ƒåŒ¹é…è’¸é¦ï¼ˆDMDï¼‰ç­‰æ–¹æ³•ï¼Œæ”¹å–„åˆæˆè§†é¢‘çš„è§†è§‰é€¼çœŸåº¦å’Œè¿åŠ¨åŠ¨æ€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMagicDistillationåœ¨è‚–åƒè§†é¢‘åˆæˆä¸Šè¡¨ç°ä¼˜äºEulerã€LCMå’ŒDMDï¼Œä»…éœ€å››æ­¥å³èƒ½è¶…è¶ŠWanX-I2Vå’ŒHunyuanVideo-I2Vã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹å¼€æºè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰å·²åœ¨è§†è§‰è´¨é‡å’Œè‡ªç„¶è¿åŠ¨æ–¹é¢å–å¾—æ˜¾è‘—æ”¹è¿›ã€‚</li>
<li>è¿™äº›æ¨¡å‹é¢ä¸´é«˜æ¨ç†å¼€é”€å’Œè‚–åƒè§†é¢‘åˆæˆå—é™çš„æŒ‘æˆ˜ã€‚</li>
<li>MagicDistillationæ¡†æ¶æ—¨åœ¨å‡å°‘æ¨ç†å¼€é”€å¹¶ç¡®ä¿VDMåœ¨è‚–åƒè§†é¢‘åˆæˆçš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>MagicDistillationä½¿ç”¨é«˜è´¨é‡è§†é¢‘è°ˆè¯æ•°æ®å¯¹Magic141è¿›è¡Œå¾®è°ƒã€‚</li>
<li>ç»“åˆLoRAå’ŒDMDï¼ŒMagicDistillationæé«˜äº†åˆæˆè§†é¢‘çš„è§†è§‰é€¼çœŸåº¦å’Œè¿åŠ¨åŠ¨æ€ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒMagicDistillationåœ¨è‚–åƒè§†é¢‘åˆæˆä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13319">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f16fbc1a7553e52a96c17164bac73cbf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ded8edf44eac736995a8f7bbad2fefa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-075ceb9174a361e6babf18ee229a53be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d0fb70565ebcd9c5bb9527b9f1d72e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ccfef1e8f14c288bf005c88fe869e9c.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GMTalker-Gaussian-Mixture-based-Audio-Driven-Emotional-Talking-Video-Portraits"><a href="#GMTalker-Gaussian-Mixture-based-Audio-Driven-Emotional-Talking-Video-Portraits" class="headerlink" title="GMTalker: Gaussian Mixture-based Audio-Driven Emotional Talking Video   Portraits"></a>GMTalker: Gaussian Mixture-based Audio-Driven Emotional Talking Video   Portraits</h2><p><strong>Authors:Yibo Xia, Lizhen Wang, Xiang Deng, Xiaoyan Luo, Yunhong Wang, Yebin Liu</strong></p>
<p>Synthesizing high-fidelity and emotion-controllable talking video portraits, with audio-lip sync, vivid expressions, realistic head poses, and eye blinks, has been an important and challenging task in recent years. Most existing methods suffer in achieving personalized and precise emotion control, smooth transitions between different emotion states, and the generation of diverse motions. To tackle these challenges, we present GMTalker, a Gaussian mixture-based emotional talking portraits generation framework. Specifically, we propose a Gaussian mixture-based expression generator that can construct a continuous and disentangled latent space, achieving more flexible emotion manipulation. Furthermore, we introduce a normalizing flow-based motion generator pretrained on a large dataset with a wide-range motion to generate diverse head poses, blinks, and eyeball movements. Finally, we propose a personalized emotion-guided head generator with an emotion mapping network that can synthesize high-fidelity and faithful emotional video portraits. Both quantitative and qualitative experiments demonstrate our method outperforms previous methods in image quality, photo-realism, emotion accuracy, and motion diversity. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œåˆæˆé«˜ä¿çœŸå’Œæƒ…ç»ªå¯æ§çš„è¯´è¯è§†é¢‘è‚–åƒå·²ç»æˆä¸ºä¸€é¡¹é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œè¿™äº›è§†é¢‘éœ€è¦å…·æœ‰éŸ³é¢‘-å”‡éƒ¨åŒæ­¥ã€ç”ŸåŠ¨çš„è¡¨æƒ…ã€çœŸå®çš„å¤´éƒ¨å§¿åŠ¿å’Œçœ¨çœ¼ç­‰ç‰¹å¾ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•åœ¨å®ç°ä¸ªæ€§åŒ–ã€ç²¾ç¡®çš„æƒ…ç»ªæ§åˆ¶ã€ä¸åŒæƒ…ç»ªçŠ¶æ€ä¹‹é—´çš„å¹³æ»‘è¿‡æ¸¡ä»¥åŠç”Ÿæˆå„ç§åŠ¨ä½œæ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†GMTalkerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé«˜æ–¯æ··åˆçš„æƒ…ç»ªäº¤è°ˆè‚–åƒç”Ÿæˆæ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºé«˜æ–¯æ··åˆçš„è¡¨æƒ…ç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿæ„å»ºä¸€ä¸ªè¿ç»­ä¸”åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´çµæ´»çš„æƒ…ç»ªæ“æ§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªåŸºäºå½’ä¸€åŒ–æµçš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œè¯¥ç”Ÿæˆå™¨åœ¨åŒ…å«å¤§èŒƒå›´è¿åŠ¨çš„å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥ç”Ÿæˆå„ç§å¤´éƒ¨å§¿åŠ¿ã€çœ¨çœ¼å’Œçœ¼çƒè¿åŠ¨ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸ªæ€§åŒ–çš„æƒ…ç»ªå¼•å¯¼å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œå®ƒåŒ…å«ä¸€ä¸ªæƒ…æ„Ÿæ˜ å°„ç½‘ç»œï¼Œèƒ½å¤Ÿåˆæˆé«˜ä¿çœŸå’ŒçœŸå®çš„æƒ…ç»ªè§†é¢‘è‚–åƒã€‚å®šé‡å’Œå®šæ€§å®éªŒå‡è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€é€¼çœŸåº¦ã€æƒ…ç»ªå‡†ç¡®æ€§å’Œè¿åŠ¨å¤šæ ·æ€§æ–¹é¢ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.07669v3">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://bob35buaa.github.io/GMTalker">https://bob35buaa.github.io/GMTalker</a>. This work has   been submitted to the IEEE journal for possible publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºé«˜æ–¯æ··åˆçš„æƒ…æ„Ÿå¯¹è¯è‚–åƒç”Ÿæˆæ¡†æ¶GMTalkerï¼Œç”¨äºåˆæˆé«˜ä¿çœŸã€æƒ…æ„Ÿå¯æ§çš„è¯´è¯è§†é¢‘è‚–åƒã€‚è¯¥æ¡†æ¶é€šè¿‡åŸºäºé«˜æ–¯æ··åˆçš„è¡¨æƒ…ç”Ÿæˆå™¨æ„å»ºè¿ç»­ä¸”è§£è€¦çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´çµæ´»çš„æƒ…æ„Ÿæ“æ§ã€‚åŒæ—¶ï¼Œå¼•å…¥åŸºäºå½’ä¸€åŒ–æµçš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œåœ¨å¤§é‡æ•°æ®é¢„è®­ç»ƒçš„åŸºç¡€ä¸Šç”Ÿæˆå¤šæ ·åŒ–çš„å¤´éƒ¨å§¿æ€ã€çœ¨çœ¼å’Œçœ¼çƒè¿åŠ¨ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸ªæ€§åŒ–æƒ…æ„Ÿå¼•å¯¼çš„å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œé€šè¿‡æƒ…æ„Ÿæ˜ å°„ç½‘ç»œåˆæˆé«˜ä¿çœŸå’Œæƒ…æ„ŸçœŸå®çš„è§†é¢‘è‚–åƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€çœŸå®æ„Ÿã€æƒ…æ„Ÿå‡†ç¡®æ€§å’Œè¿åŠ¨å¤šæ ·æ€§æ–¹é¢å‡ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GMTalkeræ˜¯ä¸€ä¸ªåŸºäºé«˜æ–¯æ··åˆçš„æƒ…æ„Ÿå¯¹è¯è‚–åƒç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨åˆæˆé«˜ä¿çœŸã€æƒ…æ„Ÿå¯æ§çš„è¯´è¯è§†é¢‘è‚–åƒã€‚</li>
<li>æå‡ºäº†åŸºäºé«˜æ–¯æ··åˆçš„è¡¨æƒ…ç”Ÿæˆå™¨ï¼Œæ„å»ºè¿ç»­ä¸”è§£è€¦çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´çµæ´»çš„æƒ…æ„Ÿæ“æ§ã€‚</li>
<li>å¼•å…¥åŸºäºå½’ä¸€åŒ–æµçš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œå¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„å¤´éƒ¨å§¿æ€ã€çœ¨çœ¼å’Œçœ¼çƒè¿åŠ¨ã€‚</li>
<li>æå‡ºäº†ä¸ªæ€§åŒ–æƒ…æ„Ÿå¼•å¯¼çš„å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œé€šè¿‡æƒ…æ„Ÿæ˜ å°„ç½‘ç»œåˆæˆçœŸå®ä¸”é«˜ä¿çœŸçš„è§†é¢‘è‚–åƒã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€çœŸå®æ„Ÿã€æƒ…æ„Ÿå‡†ç¡®æ€§å’Œè¿åŠ¨å¤šæ ·æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</li>
<li>GMTalkeræ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥ç”¨äºç”µå½±ç‰¹æ•ˆã€æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿå¶åƒç­‰é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.07669">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b9135fbd9f4d7941feafdce097e459e0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4779eb406839d5a0b782619a439281e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4fdd5cde2955f079a8476ca3708fca45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e974af4cf458ec0bd82deefef2b721f8.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-03/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-03/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-04/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-04-04\./crop_Talking Head Generation/2503.21616v1/page_3_0.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-04  Follow Your Motion A Generic Temporal Consistency Portrait Editing   Framework with Trajectory Guidance
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-04/Interactive/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-04-04\./crop_Interactive/2408.08650v2/page_4_0.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-04  Are you really listening? Boosting Perceptual Awareness in Music-QA   Benchmarks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">14773.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
