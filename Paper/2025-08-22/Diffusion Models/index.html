<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-22  TransLight Image-Guided Customized Lighting Control with Generative   Decoupling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-b132ac75a0fbf2df284591750ce55b3c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    47 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-22-æ›´æ–°"><a href="#2025-08-22-æ›´æ–°" class="headerlink" title="2025-08-22 æ›´æ–°"></a>2025-08-22 æ›´æ–°</h1><h2 id="TransLight-Image-Guided-Customized-Lighting-Control-with-Generative-Decoupling"><a href="#TransLight-Image-Guided-Customized-Lighting-Control-with-Generative-Decoupling" class="headerlink" title="TransLight: Image-Guided Customized Lighting Control with Generative   Decoupling"></a>TransLight: Image-Guided Customized Lighting Control with Generative   Decoupling</h2><p><strong>Authors:Zongming Li, Lianghui Zhu, Haocheng Shen, Longjin Ran, Wenyu Liu, Xinggang Wang</strong></p>
<p>Most existing illumination-editing approaches fail to simultaneously provide customized control of light effects and preserve content integrity. This makes them less effective for practical lighting stylization requirements, especially in the challenging task of transferring complex light effects from a reference image to a user-specified target image. To address this problem, we propose TransLight, a novel framework that enables high-fidelity and high-freedom transfer of light effects. Extracting the light effect from the reference image is the most critical and challenging step in our method. The difficulty lies in the complex geometric structure features embedded in light effects that are highly coupled with content in real-world scenarios. To achieve this, we first present Generative Decoupling, where two fine-tuned diffusion models are used to accurately separate image content and light effects, generating a newly curated, million-scale dataset of image-content-light triplets. Then, we employ IC-Light as the generative model and train our model with our triplets, injecting the reference lighting image as an additional conditioning signal. The resulting TransLight model enables customized and natural transfer of diverse light effects. Notably, by thoroughly disentangling light effects from reference images, our generative decoupling strategy endows TransLight with highly flexible illumination control. Experimental results establish TransLight as the first method to successfully transfer light effects across disparate images, delivering more customized illumination control than existing techniques and charting new directions for research in illumination harmonization and editing. </p>
<blockquote>
<p>ç°æœ‰çš„å¤§å¤šæ•°å…‰ç…§ç¼–è¾‘æ–¹æ³•æœªèƒ½åŒæ—¶å®ç°å¯¹å…‰æ•ˆçš„è‡ªå®šä¹‰æ§åˆ¶å’Œå†…å®¹å®Œæ•´æ€§çš„ä¿æŒï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨æ»¡è¶³å®é™…å…‰ç…§é£æ ¼åŒ–è¦æ±‚æ–¹é¢æ•ˆæœè¾ƒå·®ï¼Œå°¤å…¶æ˜¯åœ¨å°†å¤æ‚çš„å…‰æ•ˆä»å‚è€ƒå›¾åƒè½¬ç§»åˆ°ç”¨æˆ·æŒ‡å®šçš„ç›®æ ‡å›¾åƒè¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†TransLightï¼Œä¸€ä¸ªèƒ½å¤Ÿå®ç°é«˜ä¿çœŸå’Œé«˜è‡ªç”±åº¦å…‰æ•ˆè½¬ç§»çš„æ–°å‹æ¡†æ¶ã€‚ä»å‚è€ƒå›¾åƒä¸­æå–å…‰æ•ˆæ˜¯æˆ‘ä»¬æ–¹æ³•ä¸­æœ€å…³é”®ä¸”æœ€å…·æŒ‘æˆ˜æ€§çš„æ­¥éª¤ã€‚å…¶éš¾åº¦åœ¨äºå…‰æ•ˆä¸­åµŒå…¥çš„å¤æ‚å‡ ä½•ç»“æ„ç‰¹å¾ä¸ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„å†…å®¹é«˜åº¦è€¦åˆã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ç”Ÿæˆè§£è€¦çš„æ–¹æ³•ï¼Œä½¿ç”¨ä¸¤ä¸ªç»è¿‡å¾®è°ƒçš„åˆ†æ‰©æ•£æ¨¡å‹æ¥å‡†ç¡®åˆ†ç¦»å›¾åƒå†…å®¹å’Œå…‰æ•ˆï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„ã€è§„æ¨¡è¾¾ç™¾ä¸‡çº§åˆ«çš„å›¾åƒ-å†…å®¹-å…‰æ•ˆä¸‰å…ƒç»„æ•°æ®é›†ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†IC-Lightä½œä¸ºç”Ÿæˆæ¨¡å‹ï¼Œç”¨æˆ‘ä»¬çš„ä¸‰å…ƒç»„æ•°æ®é›†æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶å°†å‚è€ƒç…§æ˜å›¾åƒä½œä¸ºé¢å¤–çš„æ¡ä»¶ä¿¡å·æ³¨å…¥ã€‚ç”±æ­¤äº§ç”Ÿçš„TransLightæ¨¡å‹èƒ½å¤Ÿå®ç°å®šåˆ¶å’Œè‡ªç„¶çš„å„ç§å…‰æ•ˆè½¬ç§»ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œé€šè¿‡å½»åº•åœ°å°†å…‰æ•ˆä»å‚è€ƒå›¾åƒä¸­åˆ†ç¦»å‡ºæ¥ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆè§£è€¦ç­–ç•¥ä½¿TransLightå…·å¤‡äº†é«˜åº¦çµæ´»çš„å…‰ç…§æ§åˆ¶ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTransLightæ˜¯ç¬¬ä¸€ç§æˆåŠŸåœ¨ä¸åŒå›¾åƒé—´è½¬ç§»å…‰æ•ˆçš„æ–¹æ³•ï¼Œå®ƒæä¾›äº†æ¯”ç°æœ‰æŠ€æœ¯æ›´å®šåˆ¶åŒ–çš„ç…§æ˜æ§åˆ¶ï¼Œå¹¶ä¸ºå…‰ç…§å’Œè°å’Œç¼–è¾‘ç ”ç©¶å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14814v1">PDF</a> 15 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºTransLightçš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºå®ç°é«˜ä¿çœŸå’Œé«˜è‡ªç”±åº¦çš„å…‰æ•ˆè½¬ç§»ã€‚è¯¥æ¡†æ¶é€šè¿‡é‡‡ç”¨ç”Ÿæˆæ€§è§£è€¦ç­–ç•¥ï¼Œåˆ©ç”¨ä¸¤ä¸ªç²¾ç»†è°ƒæ•´çš„æ‰©æ•£æ¨¡å‹å‡†ç¡®åˆ†ç¦»å›¾åƒå†…å®¹å’Œå…‰æ•ˆï¼Œå®ç°å…‰æ•ˆä»å‚è€ƒå›¾åƒåˆ°ç›®æ ‡å›¾åƒçš„è½¬ç§»ã€‚æ­¤ç­–ç•¥ä½¿TransLightå…·æœ‰é«˜åº¦çš„ç…§æ˜æ§åˆ¶çµæ´»æ€§ï¼Œèƒ½å¤ŸæˆåŠŸåœ°åœ¨ä¸åŒå›¾åƒé—´è½¬ç§»å…‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰ç…§æ˜ç¼–è¾‘æ–¹æ³•æ— æ³•åŒæ—¶å®ç°å®šåˆ¶çš„å…‰æ•ˆæ§åˆ¶å’Œå†…å®¹å®Œæ•´æ€§çš„ä¿æŒï¼Œä½¿å¾—å®ƒä»¬åœ¨æ»¡è¶³å®é™…ç…§æ˜é£æ ¼åŒ–è¦æ±‚æ–¹é¢æ•ˆæœæœ‰é™ã€‚</li>
<li>TransLightæ¡†æ¶è¢«æå‡ºï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œå¹¶å®ç°é«˜ä¿çœŸå’Œé«˜è‡ªç”±åº¦çš„å…‰æ•ˆè½¬ç§»ã€‚</li>
<li>ç”Ÿæˆæ€§è§£è€¦ç­–ç•¥æ˜¯TransLightçš„æ ¸å¿ƒï¼Œåˆ©ç”¨ä¸¤ä¸ªç²¾ç»†è°ƒæ•´çš„æ‰©æ•£æ¨¡å‹æ¥åˆ†ç¦»å›¾åƒå†…å®¹ã€ç”Ÿæˆæ–°çš„å›¾åƒ-å†…å®¹-å…‰æ•ˆä¸‰å…ƒç»„æ•°æ®é›†ã€‚</li>
<li>IC-Lightä½œä¸ºç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡æ³¨å…¥å‚è€ƒç…§æ˜å›¾åƒä½œä¸ºé™„åŠ æ¡ä»¶ä¿¡å·æ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>TransLightèƒ½å¤Ÿå®ç°å¯¹ä¸åŒå…‰æ•ˆçš„å®šåˆ¶å’Œè‡ªç„¶è½¬ç§»ã€‚</li>
<li>é€šè¿‡å½»åº•åœ°è§£è€¦å‚è€ƒå›¾åƒä¸­çš„å…‰æ•ˆï¼ŒTransLightå…·æœ‰é«˜åº¦çµæ´»çš„ç…§æ˜æ§åˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14814">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b5105dfb48b6e00b1419cad02cb68121.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50717b396357c511ac68ec7a3c3cf6c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b16978c96b4e7b292a64ac2fb1d3644.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4f8a133f47eefbf32e9a6aa975c298d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Tinker-Diffusionâ€™s-Gift-to-3Dâ€“Multi-View-Consistent-Editing-From-Sparse-Inputs-without-Per-Scene-Optimization"><a href="#Tinker-Diffusionâ€™s-Gift-to-3Dâ€“Multi-View-Consistent-Editing-From-Sparse-Inputs-without-Per-Scene-Optimization" class="headerlink" title="Tinker: Diffusionâ€™s Gift to 3Dâ€“Multi-View Consistent Editing From   Sparse Inputs without Per-Scene Optimization"></a>Tinker: Diffusionâ€™s Gift to 3Dâ€“Multi-View Consistent Editing From   Sparse Inputs without Per-Scene Optimization</h2><p><strong>Authors:Canyu Zhao, Xiaoman Li, Tianjian Feng, Zhiyue Zhao, Hao Chen, Chunhua Shen</strong></p>
<p>We introduce Tinker, a versatile framework for high-fidelity 3D editing that operates in both one-shot and few-shot regimes without any per-scene finetuning. Unlike prior techniques that demand extensive per-scene optimization to ensure multi-view consistency or to produce dozens of consistent edited input views, Tinker delivers robust, multi-view consistent edits from as few as one or two images. This capability stems from repurposing pretrained diffusion models, which unlocks their latent 3D awareness. To drive research in this space, we curate the first large-scale multi-view editing dataset and data pipeline, spanning diverse scenes and styles. Building on this dataset, we develop our framework capable of generating multi-view consistent edited views without per-scene training, which consists of two novel components: (1) Referring multi-view editor: Enables precise, reference-driven edits that remain coherent across all viewpoints. (2) Any-view-to-video synthesizer: Leverages spatial-temporal priors from video diffusion to perform high-quality scene completion and novel-view generation even from sparse inputs. Through extensive experiments, Tinker significantly reduces the barrier to generalizable 3D content creation, achieving state-of-the-art performance on editing, novel-view synthesis, and rendering enhancement tasks. We believe that Tinker represents a key step towards truly scalable, zero-shot 3D editing. Project webpage: <a target="_blank" rel="noopener" href="https://aim-uofa.github.io/Tinker">https://aim-uofa.github.io/Tinker</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Tinkerï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œç”¨äºè¿›è¡Œé«˜ä¿çœŸåº¦çš„3Dç¼–è¾‘ï¼Œå®ƒå¯ä»¥åœ¨å•é•œå¤´å’Œå°‘é•œå¤´æ¨¡å¼ä¸‹è¿è¡Œï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚ä¸éœ€è¦å¹¿æ³›é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ä»¥ç¡®ä¿å¤šè§†è§’ä¸€è‡´æ€§æˆ–ç”Ÿæˆæ•°åä¸ªä¸€è‡´ç¼–è¾‘è¾“å…¥è§†è§’çš„å…ˆå‰æŠ€æœ¯ä¸åŒï¼ŒTinkerä»…ä»ä¸€å¼ æˆ–ä¸¤å¼ å›¾åƒå°±èƒ½å®ç°ç¨³å¥ã€å¤šè§†è§’ä¸€è‡´ç¼–è¾‘ã€‚è¿™ç§èƒ½åŠ›æ¥æºäºå¯¹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å†åˆ©ç”¨ï¼Œè¿™è§£é”äº†å®ƒä»¬çš„æ½œåœ¨ä¸‰ç»´æ„ŸçŸ¥èƒ½åŠ›ã€‚ä¸ºäº†æ¨åŠ¨è¿™ä¸€é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æ•´ç†çš„ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡å¤šè§†è§’ç¼–è¾‘æ•°æ®é›†å’Œæ•°æ®ç®¡é“ï¼Œæ¶µç›–äº†å„ç§åœºæ™¯å’Œé£æ ¼ã€‚åŸºäºè¿™ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰é’ˆå¯¹æ¯ä¸ªåœºæ™¯è®­ç»ƒçš„æƒ…å†µä¸‹ç”Ÿæˆå¤šè§†è§’ä¸€è‡´ç¼–è¾‘çš„è§†å›¾ï¼Œå®ƒç”±ä¸¤ä¸ªæ–°é¢–çš„éƒ¨åˆ†ç»„æˆï¼šï¼ˆ1ï¼‰å¼•ç”¨å¤šè§†è§’ç¼–è¾‘å™¨ï¼šå®ç°ç²¾ç¡®ã€å‚è€ƒé©±åŠ¨çš„ç¼–è¾‘ï¼Œä¿æŒæ‰€æœ‰è§‚ç‚¹çš„ä¸€è‡´æ€§ã€‚ï¼ˆ2ï¼‰ä»»æ„è§†è§’è§†é¢‘åˆæˆå™¨ï¼šåˆ©ç”¨è§†é¢‘æ‰©æ•£çš„ç©ºé—´æ—¶é—´å…ˆéªŒçŸ¥è¯†ï¼Œå³ä½¿ä»ç¨€ç–è¾“å…¥ä¹Ÿèƒ½å®ç°é«˜è´¨é‡çš„åœºæ™¯è¡¥å…¨å’Œæ–°é¢–è§†è§’ç”Ÿæˆã€‚é€šè¿‡å¤§é‡å®éªŒï¼ŒTinkerå¤§å¤§é™ä½äº†é€šç”¨3Då†…å®¹åˆ›ä½œçš„éšœç¢ï¼Œåœ¨ç¼–è¾‘ã€æ–°é¢–è§†è§’åˆæˆå’Œæ¸²æŸ“å¢å¼ºä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼ŒTinkeræ˜¯æœç€çœŸæ­£å¯æ‰©å±•çš„é›¶é•œå¤´3Dç¼–è¾‘è¿ˆå‡ºçš„å…³é”®ä¸€æ­¥ã€‚é¡¹ç›®ç½‘é¡µï¼š<a target="_blank" rel="noopener" href="https://aim-uofa.github.io/Tinker">https://aim-uofa.github.io/Tinker</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14811v1">PDF</a> Project webpage: <a target="_blank" rel="noopener" href="https://aim-uofa.github.io/Tinker">https://aim-uofa.github.io/Tinker</a></p>
<p><strong>Summary</strong></p>
<p>Tinkeræ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œç”¨äºé«˜ä¿çœŸ3Dç¼–è¾‘ï¼Œå®ƒå¯ä»¥åœ¨ä¸€æ¬¡æ‹æ‘„å’Œå°‘æ•°å‡ æ¬¡æ‹æ‘„çš„æƒ…å†µä¸‹è¿›è¡Œæ“ä½œï¼Œæ— éœ€å¯¹æ¯ä¸€ä¸ªåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚å€ŸåŠ©é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå®ƒå®ç°äº†å¼ºå¤§çš„å¤šè§†è§’ä¸€è‡´æ€§ç¼–è¾‘ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ–°é¢–ç»„ä»¶ï¼šå‚ç…§å¤šè§†è§’ç¼–è¾‘å™¨å’Œä»»æ„è§†è§’è§†é¢‘åˆæˆå™¨ã€‚Tinkeræ˜¾è‘—é™ä½äº†é€šç”¨3Då†…å®¹åˆ›ä½œçš„é—¨æ§›ï¼Œå¹¶åœ¨ç¼–è¾‘ã€æ–°è§†è§’åˆæˆå’Œæ¸²æŸ“å¢å¼ºä»»åŠ¡ä¸Šè¾¾åˆ°äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Tinkeræ˜¯ä¸€ä¸ªé€‚ç”¨äºé«˜ä¿çœŸ3Dç¼–è¾‘çš„é€šç”¨æ¡†æ¶ï¼Œå¯åœ¨ä¸€æ¬¡æ‹æ‘„å’Œå°‘æ•°å‡ æ¬¡æ‹æ‘„çš„æƒ…å†µä¸‹æ“ä½œï¼Œæ— éœ€å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚</li>
<li>Tinkeråˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å®ç°å¼ºå¤§çš„å¤šè§†è§’ä¸€è‡´æ€§ç¼–è¾‘ã€‚</li>
<li>æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ–°é¢–ç»„ä»¶ï¼šå‚ç…§å¤šè§†è§’ç¼–è¾‘å™¨ï¼Œå®ç°ç²¾ç¡®ã€å‚è€ƒé©±åŠ¨çš„ç¼–è¾‘ï¼Œä¿æŒæ‰€æœ‰è§†ç‚¹çš„è¿è´¯æ€§ï¼›ä»»æ„è§†è§’è§†é¢‘åˆæˆå™¨ï¼Œåˆ©ç”¨è§†é¢‘æ‰©æ•£çš„ç©ºé—´æ—¶é—´å…ˆéªŒä¿¡æ¯è¿›è¡Œé«˜è´¨é‡åœºæ™¯è¡¥å…¨å’Œæ–°è§†è§’ç”Ÿæˆï¼Œå³ä½¿ä»ç¨€ç–è¾“å…¥ä¹Ÿèƒ½å®ç°ã€‚</li>
<li>Tinkeræ˜¾è‘—é™ä½äº†é€šç”¨3Då†…å®¹åˆ›ä½œçš„é—¨æ§›ã€‚</li>
<li>Tinkeråœ¨ç¼–è¾‘ã€æ–°è§†è§’åˆæˆå’Œæ¸²æŸ“å¢å¼ºä»»åŠ¡ä¸Šè¡¨ç°å“è¶Šã€‚</li>
<li>Tinkerä»£è¡¨äº†ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œæœç€çœŸæ­£å¯æ‰©å±•çš„é›¶å°„å‡»3Dç¼–è¾‘æ–¹å‘å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14811">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7bc49620e6a2187049a01ee3b8111277.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a57b54c614af3a291589bfa6d752534d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cdcd6065c93557e322b686fd6318041.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-68f710c3b78a56f1a3d56ed689de2313.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MUSE-Multi-Subject-Unified-Synthesis-via-Explicit-Layout-Semantic-Expansion"><a href="#MUSE-Multi-Subject-Unified-Synthesis-via-Explicit-Layout-Semantic-Expansion" class="headerlink" title="MUSE: Multi-Subject Unified Synthesis via Explicit Layout Semantic   Expansion"></a>MUSE: Multi-Subject Unified Synthesis via Explicit Layout Semantic   Expansion</h2><p><strong>Authors:Fei Peng, Junqiang Wu, Yan Li, Tingting Gao, Di Zhang, Huiyuan Fu</strong></p>
<p>Existing text-to-image diffusion models have demonstrated remarkable capabilities in generating high-quality images guided by textual prompts. However, achieving multi-subject compositional synthesis with precise spatial control remains a significant challenge. In this work, we address the task of layout-controllable multi-subject synthesis (LMS), which requires both faithful reconstruction of reference subjects and their accurate placement in specified regions within a unified image. While recent advancements have separately improved layout control and subject synthesis, existing approaches struggle to simultaneously satisfy the dual requirements of spatial precision and identity preservation in this composite task. To bridge this gap, we propose MUSE, a unified synthesis framework that employs concatenated cross-attention (CCA) to seamlessly integrate layout specifications with textual guidance through explicit semantic space expansion. The proposed CCA mechanism enables bidirectional modality alignment between spatial constraints and textual descriptions without interference. Furthermore, we design a progressive two-stage training strategy that decomposes the LMS task into learnable sub-objectives for effective optimization. Extensive experiments demonstrate that MUSE achieves zero-shot end-to-end generation with superior spatial accuracy and identity consistency compared to existing solutions, advancing the frontier of controllable image synthesis. Our code and model are available at <a target="_blank" rel="noopener" href="https://github.com/pf0607/MUSE">https://github.com/pf0607/MUSE</a>. </p>
<blockquote>
<p>ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹å·²åœ¨ç”±æ–‡æœ¬æç¤ºå¼•å¯¼ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ç°å…·æœ‰ç²¾ç¡®ç©ºé—´æ§åˆ¶çš„å¤šä¸»é¢˜ç»„åˆåˆæˆä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†å¸ƒå±€å¯æ§å¤šä¸»é¢˜åˆæˆï¼ˆLMSï¼‰çš„ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡è¦æ±‚å¿ å®åœ°é‡å»ºå‚è€ƒä¸»é¢˜ï¼Œå¹¶å°†å®ƒä»¬å‡†ç¡®æ”¾ç½®åœ¨ç»Ÿä¸€å›¾åƒçš„æŒ‡å®šåŒºåŸŸå†…ã€‚è™½ç„¶æœ€è¿‘çš„è¿›æ­¥å·²ç»åˆ†åˆ«æé«˜äº†å¸ƒå±€æ§åˆ¶å’Œä¸»é¢˜åˆæˆçš„æ•ˆæœï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨è¿™é¡¹ç»„åˆä»»åŠ¡ä¸­åŒæ—¶æ»¡è¶³ç©ºé—´ç²¾åº¦å’Œèº«ä»½ä¿ç•™çš„åŒé‡è¦æ±‚æ—¶ä»ç„¶æ„Ÿåˆ°å›°éš¾ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†MUSEï¼Œè¿™æ˜¯ä¸€ä¸ªé‡‡ç”¨ä¸²è”äº¤å‰æ³¨æ„ï¼ˆCCAï¼‰çš„ç»Ÿä¸€åˆæˆæ¡†æ¶ï¼Œé€šè¿‡æ˜¾å¼è¯­ä¹‰ç©ºé—´æ‰©å±•æ— ç¼åœ°å°†å¸ƒå±€è§„èŒƒä¸æ–‡æœ¬æŒ‡å¯¼ç›¸ç»“åˆã€‚æ‰€æå‡ºçš„CCAæœºåˆ¶å®ç°äº†ç©ºé—´çº¦æŸå’Œæ–‡æœ¬æè¿°ä¹‹é—´çš„åŒå‘æ¨¡æ€å¯¹é½ï¼Œä¸ä¼šç›¸äº’å¹²æ‰°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åˆ†é˜¶æ®µçš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå°†LMSä»»åŠ¡åˆ†è§£ä¸ºå¯å­¦ä¹ çš„å­ç›®æ ‡ï¼Œä»¥å®ç°æœ‰æ•ˆçš„ä¼˜åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMUSEå®ç°äº†ä¸ç°æœ‰è§£å†³æ–¹æ¡ˆç›¸æ¯”å…·æœ‰å“è¶Šçš„ç©ºé—´ç²¾åº¦å’Œèº«ä»½ä¸€è‡´æ€§çš„é›¶æ ·æœ¬ç«¯åˆ°ç«¯ç”Ÿæˆã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/pf060a7/MUSE%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pf060a7/MUSEæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14440v1">PDF</a> This paper is accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºMUSEçš„ç»Ÿä¸€åˆæˆæ¡†æ¶ï¼Œç”¨äºè§£å†³å¸ƒå±€å¯æ§çš„å¤šä¸»é¢˜åˆæˆï¼ˆLMSï¼‰ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é€šè¿‡é‡‡ç”¨ä¸²è”äº¤å‰æ³¨æ„åŠ›ï¼ˆCCAï¼‰æœºåˆ¶ï¼Œå°†å¸ƒå±€è§„èŒƒä¸æ–‡æœ¬æŒ‡å¯¼æ— ç¼é›†æˆï¼Œå®ç°ç©ºé—´çº¦æŸä¸æ–‡æœ¬æè¿°ä¹‹é—´çš„åŒå‘æ¨¡æ€å¯¹é½ã€‚MUSEæ¡†æ¶èƒ½å¤Ÿåœ¨é›¶æ ·æœ¬ç«¯åˆ°ç«¯ç”Ÿæˆä¸­å®ç°å‡ºè‰²çš„ç©ºé—´å‡†ç¡®æ€§å’Œèº«ä»½ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨é«˜è´¨é‡å›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å…·æœ‰ç²¾ç¡®ç©ºé—´æ§åˆ¶çš„å¤šä¸»é¢˜åˆæˆæ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>MUSEæ¡†æ¶è§£å†³äº†å¸ƒå±€å¯æ§çš„å¤šä¸»é¢˜åˆæˆï¼ˆLMSï¼‰ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡éœ€è¦å¿ å®é‡å»ºå‚è€ƒä¸»é¢˜å¹¶å°†å®ƒä»¬å‡†ç¡®æ”¾ç½®åœ¨ç»Ÿä¸€å›¾åƒçš„æŒ‡å®šåŒºåŸŸã€‚</li>
<li>MUSEé‡‡ç”¨ä¸²è”äº¤å‰æ³¨æ„åŠ›ï¼ˆCCAï¼‰æœºåˆ¶ï¼Œå°†å¸ƒå±€è§„èŒƒå’Œæ–‡æœ¬æŒ‡å¯¼æ— ç¼é›†æˆï¼Œå®ç°ç©ºé—´çº¦æŸå’Œæ–‡æœ¬æè¿°ä¹‹é—´çš„åŒå‘æ¨¡æ€å¯¹é½ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚</li>
<li>MUSEè®¾è®¡äº†ä¸€ç§æ¸è¿›çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå°†LMSä»»åŠ¡åˆ†è§£æˆå¯å­¦ä¹ çš„å­ç›®æ ‡ï¼Œå®ç°æœ‰æ•ˆä¼˜åŒ–ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒMUSEåœ¨é›¶æ ·æœ¬ç«¯åˆ°ç«¯ç”Ÿæˆä¸­å®ç°äº†å“è¶Šçš„ç©ºé—´å‡†ç¡®æ€§å’Œèº«ä»½ä¸€è‡´æ€§ï¼Œç›¸è¾ƒäºç°æœ‰è§£å†³æ–¹æ¡ˆæœ‰æ‰€çªç ´ã€‚</li>
<li>MUSEæ¡†æ¶çš„ä»£ç å’Œæ¨¡å‹å·²å…¬å¼€å‘å¸ƒï¼Œå¯ä¾›ç ”ç©¶ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14440">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cf239a50b5d1951e62aa2f9537317b66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b132ac75a0fbf2df284591750ce55b3c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6666f761d15292d1d6e9e9752c007639.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b052c0d2139fac90cb3a7cf2c5b88a34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d19aec92c2c44704b1398a6dea8e49c3.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Latent-Interpolation-Learning-Using-Diffusion-Models-for-Cardiac-Volume-Reconstruction"><a href="#Latent-Interpolation-Learning-Using-Diffusion-Models-for-Cardiac-Volume-Reconstruction" class="headerlink" title="Latent Interpolation Learning Using Diffusion Models for Cardiac Volume   Reconstruction"></a>Latent Interpolation Learning Using Diffusion Models for Cardiac Volume   Reconstruction</h2><p><strong>Authors:Niklas Bubeck, Suprosanna Shit, Chen Chen, Can Zhao, Pengfei Guo, Dong Yang, Georg Zitzlsberger, Daguang Xu, Bernhard Kainz, Daniel Rueckert, Jiazhen Pan</strong></p>
<p>Cardiac Magnetic Resonance (CMR) imaging is a critical tool for diagnosing and managing cardiovascular disease, yet its utility is often limited by the sparse acquisition of 2D short-axis slices, resulting in incomplete volumetric information. Accurate 3D reconstruction from these sparse slices is essential for comprehensive cardiac assessment, but existing methods face challenges, including reliance on predefined interpolation schemes (e.g., linear or spherical), computational inefficiency, and dependence on additional semantic inputs such as segmentation labels or motion data. To address these limitations, we propose a novel \textbf{Ca}rdiac \textbf{L}atent \textbf{I}nterpolation \textbf{D}iffusion (CaLID) framework that introduces three key innovations. First, we present a data-driven interpolation scheme based on diffusion models, which can capture complex, non-linear relationships between sparse slices and improves reconstruction accuracy. Second, we design a computationally efficient method that operates in the latent space and speeds up 3D whole-heart upsampling time by a factor of 24, reducing computational overhead compared to previous methods. Third, with only sparse 2D CMR images as input, our method achieves SOTA performance against baseline methods, eliminating the need for auxiliary input such as morphological guidance, thus simplifying workflows. We further extend our method to 2D+T data, enabling the effective modeling of spatiotemporal dynamics and ensuring temporal coherence. Extensive volumetric evaluations and downstream segmentation tasks demonstrate that CaLID achieves superior reconstruction quality and efficiency. By addressing the fundamental limitations of existing approaches, our framework advances the state of the art for spatio and spatiotemporal whole-heart reconstruction, offering a robust and clinically practical solution for cardiovascular imaging. </p>
<blockquote>
<p>å¿ƒè„ç£å…±æŒ¯ï¼ˆCMRï¼‰æˆåƒåœ¨å¿ƒè¡€ç®¡ç–¾ç—…çš„è¯Šæ–­å’Œæ²»ç–—ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä½†å…¶æ•ˆç”¨å¾€å¾€å—åˆ°äºŒç»´çŸ­è½´åˆ‡ç‰‡ç¨€ç–é‡‡é›†çš„é™åˆ¶ï¼Œå¯¼è‡´ä½“ç§¯ä¿¡æ¯ä¸å®Œæ•´ã€‚ä»ç¨€ç–åˆ‡ç‰‡è¿›è¡Œå‡†ç¡®çš„3Dé‡å»ºå¯¹äºå…¨é¢çš„å¿ƒè„è¯„ä¼°è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•é¢ä¸´æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä¾èµ–é¢„å®šä¹‰çš„æ’å€¼æ–¹æ¡ˆï¼ˆä¾‹å¦‚çº¿æ€§æˆ–çƒå½¢æ’å€¼ï¼‰ã€è®¡ç®—æ•ˆç‡ä½ä¸‹ä»¥åŠå¯¹é¢å¤–çš„è¯­ä¹‰è¾“å…¥ï¼ˆå¦‚åˆ†å‰²æ ‡ç­¾æˆ–è¿åŠ¨æ•°æ®ï¼‰çš„ä¾èµ–ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„Cardiac Latent Interpolation Diffusionï¼ˆCaLIDï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ•°æ®é©±åŠ¨æ’å€¼æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆå¯ä»¥æ•æ‰ç¨€ç–åˆ‡ç‰‡ä¹‹é—´çš„å¤æ‚éçº¿æ€§å…³ç³»ï¼Œæé«˜é‡å»ºç²¾åº¦ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ“ä½œçš„é«˜æ•ˆè®¡ç®—æ–¹æ³•ï¼Œå°†å¿ƒè„æ•´ä½“3Dä¸Šé‡‡æ ·æ—¶é—´ç¼©çŸ­äº†24å€ï¼Œä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨ç¨€ç–çš„äºŒç»´å¿ƒè„ç£å…±æŒ¯å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæ— éœ€è¾…åŠ©è¾“å…¥ï¼ˆå¦‚å½¢æ€æŒ‡å¯¼ï¼‰ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”å–å¾—äº†å…ˆè¿›æ€§èƒ½è¡¨ç°ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†æˆ‘ä»¬çš„æ–¹æ³•æ‰©å±•åˆ°äºŒç»´+Tæ•°æ®ï¼Œæœ‰æ•ˆåœ°å¯¹æ—¶ç©ºåŠ¨æ€è¿›è¡Œå»ºæ¨¡ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ã€‚å¹¿æ³›çš„ä½“ç§¯è¯„ä¼°å’Œä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡è¯æ˜ï¼ŒCaLIDåœ¨é‡å»ºè´¨é‡å’Œæ•ˆç‡æ–¹é¢éƒ½è¾¾åˆ°äº†å“è¶Šçš„æ°´å¹³ã€‚é€šè¿‡è§£å†³ç°æœ‰æ–¹æ³•çš„åŸºæœ¬å±€é™æ€§ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨ç©ºé—´å’Œæ—¶ç©ºå¿ƒè„é‡å»ºæ–¹é¢æ¨åŠ¨äº†æœ€æ–°æŠ€æœ¯è¿›å±•ï¼Œä¸ºå¿ƒè¡€ç®¡æˆåƒæä¾›äº†ç¨³å¥ä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13826v2">PDF</a> </p>
<p><strong>Summary</strong><br>     å¿ƒè„ç£å…±æŒ¯ï¼ˆCMRï¼‰æˆåƒåœ¨è¯Šæ–­å’Œæ²»ç–—å¿ƒè¡€ç®¡ç–¾ç—…ä¸­è‡³å…³é‡è¦ï¼Œä½†å…¶æ•ˆç”¨å¸¸å—é™äºäºŒç»´çŸ­è½´åˆ‡ç‰‡çš„ç¨€ç–é‡‡é›†ï¼Œå¯¼è‡´ä½“ç§¯ä¿¡æ¯ä¸å®Œæ•´ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å…¨æ–°çš„å¿ƒè„æ½œåœ¨æ’å€¼æ‰©æ•£ï¼ˆCaLIDï¼‰æ¡†æ¶ï¼Œå…·æœ‰æ•°æ®é©±åŠ¨æ’å€¼æ–¹æ¡ˆã€æ½œåœ¨ç©ºé—´çš„é«˜æ•ˆè¿ç®—æ–¹æ³•ï¼Œä»¥åŠä»…ä¾èµ–ç¨€ç–çš„äºŒç»´CMRå›¾åƒå³å¯è¾¾åˆ°ä¼˜è¶Šæ€§èƒ½ç­‰ä¼˜ç‚¹ã€‚æ­¤æ¡†æ¶çªç ´äº†ç°æœ‰æ–¹æ³•çš„å±€é™ï¼Œæå‡äº†é‡å»ºè´¨é‡å’Œæ•ˆç‡ï¼Œå®ç°äº†æ—¶ç©ºå¿ƒè„é‡å»ºçš„æœ€æ–°è¿›å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CMRæˆåƒåœ¨å¿ƒè¡€ç®¡ç–¾ç—…çš„è¯Šæ–­å’Œç®¡ç†ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å—é™äºäºŒç»´åˆ‡ç‰‡çš„ç¨€ç–é‡‡é›†å¯¼è‡´çš„ä½“ç§¯ä¿¡æ¯ä¸å®Œæ•´é—®é¢˜ã€‚</li>
<li>ç°æœ‰é‡å»ºæ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬ä¾èµ–é¢„è®¾æ’å€¼æ–¹æ¡ˆã€è®¡ç®—æ•ˆç‡ä½ä¸‹ä»¥åŠå¯¹é¢å¤–è¯­ä¹‰è¾“å…¥çš„ä¾èµ–ã€‚</li>
<li>CaLIDæ¡†æ¶å¼•å…¥æ•°æ®é©±åŠ¨æ’å€¼æ–¹æ¡ˆï¼Œèƒ½æ•æ‰ç¨€ç–åˆ‡ç‰‡é—´çš„å¤æ‚éçº¿æ€§å…³ç³»ï¼Œæé«˜é‡å»ºç²¾åº¦ã€‚</li>
<li>è¯¥æ¡†æ¶è®¾è®¡äº†ä¸€ç§æ½œåœ¨ç©ºé—´çš„é«˜æ•ˆè¿ç®—æ–¹æ³•ï¼Œå°†å¿ƒè„ä¸‰ç»´ä¸Šé‡‡æ ·çš„æ—¶é—´æé«˜äº†24å€ã€‚</li>
<li>ä»…éœ€ç¨€ç–çš„äºŒç»´CMRå›¾åƒä½œä¸ºè¾“å…¥ï¼ŒCaLIDå³å¯è¾¾åˆ°å“è¶Šæ€§èƒ½ï¼Œæ— éœ€è¾…åŠ©è¾“å…¥ï¼Œç®€åŒ–äº†å·¥ä½œæµç¨‹ã€‚</li>
<li>CaLIDæ¡†æ¶è¿›ä¸€æ­¥æ‰©å±•åˆ°äºŒç»´åŠ æ—¶é—´æ•°æ®ï¼Œå®ç°äº†æ—¶ç©ºåŠ¨åŠ›å­¦çš„æœ‰æ•ˆå»ºæ¨¡å’Œæ—¶é—´çš„è¿è´¯æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13826">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-35557ded8bbf8a22943aa8c1de831129.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b3c2aacf31192a2998523e57c1e2452.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9db76104ad21d445d80009b4eb9b5fd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b3e8fbd563620fc41599e9edf300cdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b595fe2d116ad3426b59833e331eab7.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction"><a href="#DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction" class="headerlink" title="DiffIER: Optimizing Diffusion Models with Iterative Error Reduction"></a>DiffIER: Optimizing Diffusion Models with Iterative Error Reduction</h2><p><strong>Authors:Ao Chen, Lihe Ding, Tianfan Xue</strong></p>
<p>Diffusion models have demonstrated remarkable capabilities in generating high-quality samples and enhancing performance across diverse domains through Classifier-Free Guidance (CFG). However, the quality of generated samples is highly sensitive to the selection of the guidance weight. In this work, we identify a critical &#96;&#96;training-inference gapâ€™â€™ and we argue that it is the presence of this gap that undermines the performance of conditional generation and renders outputs highly sensitive to the guidance weight. We quantify this gap by measuring the accumulated error during the inference stage and establish a correlation between the selection of guidance weight and minimizing this gap. Furthermore, to mitigate this gap, we propose DiffIER, an optimization-based method for high-quality generation. We demonstrate that the accumulated error can be effectively reduced by an iterative error minimization at each step during inference. By introducing this novel plug-and-play optimization framework, we enable the optimization of errors at every single inference step and enhance generation quality. Empirical results demonstrate that our proposed method outperforms baseline approaches in conditional generation tasks. Furthermore, the method achieves consistent success in text-to-image generation, image super-resolution, and text-to-speech generation, underscoring its versatility and potential for broad applications in future research. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å’Œæé«˜ä¸åŒé¢†åŸŸçš„æ€§èƒ½æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”Ÿæˆæ ·æœ¬çš„è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºäº†ä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œæˆ‘ä»¬è®¤ä¸ºæ­£æ˜¯è¿™ä¸ªå·®è·å½±å“äº†æ¡ä»¶ç”Ÿæˆçš„æ€§èƒ½ï¼Œå¹¶ä½¿è¾“å‡ºé«˜åº¦ä¾èµ–äºå¼•å¯¼æƒé‡ã€‚æˆ‘ä»¬é€šè¿‡æµ‹é‡æ¨ç†é˜¶æ®µçš„ç´¯ç§¯è¯¯å·®æ¥é‡åŒ–è¿™ä¸ªå·®è·ï¼Œå¹¶å»ºç«‹äº†é€‰æ‹©å¼•å¯¼æƒé‡ä¸æœ€å°åŒ–è¿™ä¸ªå·®è·ä¹‹é—´çš„å…³è”ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¼“è§£è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†DiffIERï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¼˜åŒ–çš„é«˜è´¨é‡ç”Ÿæˆæ–¹æ³•ã€‚æˆ‘ä»¬è¯æ˜ï¼Œé€šè¿‡æ¨ç†è¿‡ç¨‹ä¸­æ¯ä¸€æ­¥çš„è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘ç´¯ç§¯è¯¯å·®ã€‚é€šè¿‡å¼•å…¥è¿™ç§æ–°é¢–å³æ’å³ç”¨çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¯ä¸ªå•ç‹¬æ¨ç†æ­¥éª¤ä¸­ä¼˜åŒ–è¯¯å·®ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æ‰€æå‡ºçš„æ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆæ–¹é¢å–å¾—äº†æŒç»­çš„æˆåŠŸï¼Œè¿™çªæ˜¾äº†å…¶åœ¨æœªæ¥ç ”ç©¶ä¸­çš„é€šç”¨æ€§å’Œå¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13628v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å’Œæå‡æ€§èƒ½æ–¹é¢çš„æ˜¾è‘—èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰å®ç°ã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„æ ·æœ¬è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚æœ¬æ–‡è¯†åˆ«äº†ä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œå¹¶è®¤ä¸ºè¿™ä¸ªå·®è·å½±å“äº†æ¡ä»¶ç”Ÿæˆæ€§èƒ½ï¼Œä½¿å¾—è¾“å‡ºå¯¹å¼•å¯¼æƒé‡é«˜åº¦æ•æ„Ÿã€‚ä¸ºäº†é‡åŒ–è¿™ä¸ªå·®è·ï¼Œæˆ‘ä»¬æµ‹é‡äº†æ¨ç†é˜¶æ®µçš„ç´¯ç§¯è¯¯å·®ï¼Œå»ºç«‹äº†å¼•å¯¼æƒé‡é€‰æ‹©ä¸ç¼©å°å·®è·ä¹‹é—´çš„å…³è”ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DiffIERï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¼˜åŒ–çš„é«˜è´¨é‡ç”Ÿæˆæ–¹æ³•ã€‚é€šè¿‡åœ¨æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸­å¼•å…¥è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆå‡å°‘ç´¯ç§¯è¯¯å·®ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¿™ä¸ªæ–°æ¡†æ¶åœ¨ä¼˜åŒ–è¯¯å·®æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¹¶å¢å¼ºäº†ç”Ÿæˆè´¨é‡ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆç­‰ä»»åŠ¡ä¸­å–å¾—äº†æŒç»­çš„æˆåŠŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰å±•ç°äº†å¼ºå¤§çš„ç”Ÿæˆæ ·æœ¬å’Œæ€§èƒ½æå‡èƒ½åŠ›ã€‚</li>
<li>è®­ç»ƒç”Ÿæˆçš„æ¨¡å‹åœ¨æ ·æœ¬è´¨é‡æ–¹é¢å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚</li>
<li>å­˜åœ¨ä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œå½±å“äº†æ¡ä»¶ç”Ÿæˆæ€§èƒ½ã€‚</li>
<li>é€šè¿‡æµ‹é‡æ¨ç†é˜¶æ®µçš„ç´¯ç§¯è¯¯å·®æ¥é‡åŒ–è¿™ä¸ªå·®è·ã€‚</li>
<li>æå‡ºäº†DiffIERæ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£è¯¯å·®æœ€å°åŒ–çš„ä¼˜åŒ–æ¡†æ¶æ¥ç¼©å°å·®è·å¹¶æé«˜ç”Ÿæˆè´¨é‡ã€‚</li>
<li>å®è¯ç»“æœè¡¨æ˜ï¼ŒDiffIERæ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>DiffIERæ–¹æ³•åœ¨ä¸åŒé¢†åŸŸå¦‚æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆç­‰ä»»åŠ¡ä¸­å‡æœ‰æˆåŠŸåº”ç”¨ï¼Œå±•ç°äº†å…¶å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13628">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6660ec06ea983b3718bb6178bb74c51f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b930ab27e19b587a0b375e5b562d4d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e391cf99658d7fa44fd322b3db1d0ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d613ceafcd367c3788f918797f75b6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-90754254ba6f2d1faf962c9d63bcf529.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BadBlocks-Low-Cost-and-Stealthy-Backdoor-Attacks-Tailored-for-Text-to-Image-Diffusion-Models"><a href="#BadBlocks-Low-Cost-and-Stealthy-Backdoor-Attacks-Tailored-for-Text-to-Image-Diffusion-Models" class="headerlink" title="BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for   Text-to-Image Diffusion Models"></a>BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for   Text-to-Image Diffusion Models</h2><p><strong>Authors:Yu Pan, Jiahao Chen, Lin Wang, Bingrong Dai, Yi Du</strong></p>
<p>In recent years, Diffusion models have achieved remarkable progress in the field of image generation. However, recent studies have shown that diffusion models are susceptible to backdoor attacks, in which attackers can manipulate the output by injecting covert triggers such as specific visual patterns or textual phrases into the training dataset. Fortunately, with the continuous advancement of defense techniques, defenders have become increasingly capable of identifying and mitigating most backdoor attacks using visual inspection and neural network-based detection methods. However, in this paper, we identify a novel type of backdoor threat that is more lightweight and covert than existing approaches, which we name BadBlocks, requires only about 30% of the computational resources and 20% GPU time typically needed by previous backdoor attacks, yet it successfully injects backdoors and evades the most advanced defense frameworks. BadBlocks enables attackers to selectively contaminate specific blocks within the UNet architecture of diffusion models while maintaining normal functionality in the remaining components. Experimental results demonstrate that BadBlocks achieves a high attack success rate and low perceptual quality loss , even under extremely constrained computational resources and GPU time. Moreover, BadBlocks is able to bypass existing defense frameworks, especially the attention-based backdoor detection method, highlighting it as a novel and noteworthy threat. Ablation studies further demonstrate that effective backdoor injection does not require fine-tuning the entire network and highlight the pivotal role of certain neural network layers in backdoor mapping. Overall, BadBlocks significantly reduces the barrier to conducting backdoor attacks in all aspects. It enables attackers to inject backdoors into large-scale diffusion models even using consumer-grade GPUs. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œç ”ç©¶è¡¨æ˜ï¼Œæ‰©æ•£æ¨¡å‹å®¹æ˜“å—åˆ°åé—¨æ”»å‡»çš„å½±å“ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡åœ¨è®­ç»ƒæ•°æ®é›†ä¸­æ³¨å…¥éšè”½çš„è§¦å‘å™¨ï¼ˆä¾‹å¦‚ç‰¹å®šçš„è§†è§‰æ¨¡å¼æˆ–æ–‡æœ¬çŸ­è¯­ï¼‰æ¥æ“çºµè¾“å‡ºã€‚å¹¸è¿çš„æ˜¯ï¼Œéšç€é˜²å¾¡æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥ï¼Œé˜²å¾¡è€…è¶Šæ¥è¶Šèƒ½å¤Ÿä½¿ç”¨è§†è§‰æ£€æŸ¥å’ŒåŸºäºç¥ç»ç½‘ç»œçš„æ£€æµ‹æ–¹æ³•æ¥è¯†åˆ«å’Œç¼“è§£å¤§å¤šæ•°åé—¨æ”»å‡»ã€‚ç„¶è€Œï¼Œæœ¬æ–‡å‘ç°äº†ä¸€ç§æ¯”ç°æœ‰æ–¹æ³•æ›´è½»é‡çº§ã€æ›´éšè”½çš„æ–°å‹åé—¨å¨èƒï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºBadBlocksã€‚BadBlocksä»…éœ€è¦å¤§çº¦30%çš„è®¡ç®—èµ„æºå’Œ20%çš„GPUæ—¶é—´ï¼Œè¿™æ˜¯ä»¥å‰åé—¨æ”»å‡»é€šå¸¸æ‰€éœ€çš„ï¼Œç„¶è€Œå®ƒå´èƒ½å¤ŸæˆåŠŸæ³¨å…¥åé—¨å¹¶ç»•è¿‡æœ€å…ˆè¿›çš„é˜²å¾¡æ¡†æ¶ã€‚BadBlocksèƒ½å¤Ÿä½¿æ”»å‡»è€…é€‰æ‹©æ€§åœ°æ±¡æŸ“æ‰©æ•£æ¨¡å‹UNetæ¶æ„ä¸­çš„ç‰¹å®šå—ï¼ŒåŒæ—¶ä¿æŒå…¶ä½™ç»„ä»¶çš„æ­£å¸¸åŠŸèƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨æåº¦å—é™çš„è®¡ç®—èµ„æºå’ŒGPUæ—¶é—´ä¸‹ï¼ŒBadBlocksä¹Ÿå®ç°äº†é«˜æ”»å‡»æˆåŠŸç‡å’Œä½æ„ŸçŸ¥è´¨é‡æŸå¤±ã€‚è€Œä¸”ï¼ŒBadBlocksèƒ½å¤Ÿç»•è¿‡ç°æœ‰çš„é˜²å¾¡æ¡†æ¶ï¼Œå°¤å…¶æ˜¯åŸºäºæ³¨æ„åŠ›çš„åé—¨æ£€æµ‹æ–¹æ³•ï¼Œå‡¸æ˜¾å‡ºå®ƒä½œä¸ºä¸€ç§æ–°å‹ä¸”å€¼å¾—å…³æ³¨çš„å¨èƒã€‚è¿›ä¸€æ­¥çš„ç ”ç©¶è¡¨æ˜ï¼Œæœ‰æ•ˆçš„åé—¨æ³¨å…¥ä¸éœ€è¦å¯¹æ•´ä¸ªç½‘ç»œè¿›è¡Œå¾®è°ƒï¼Œå¹¶çªå‡ºäº†æŸäº›ç¥ç»ç½‘ç»œå±‚åœ¨åé—¨æ˜ å°„ä¸­çš„å…³é”®ä½œç”¨ã€‚æ€»ä½“è€Œè¨€ï¼ŒBadBlocksä»å„ä¸ªæ–¹é¢å¤§å¤§é™ä½äº†è¿›è¡Œåé—¨æ”»å‡»çš„éšœç¢ã€‚å®ƒä½¿å¾—æ”»å‡»è€…å³ä½¿ä½¿ç”¨æ¶ˆè´¹çº§GPUä¹Ÿèƒ½å°†åé—¨æ³¨å…¥å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.03221v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„æ–°å‹åé—¨æ”»å‡»æ–¹æ³•â€”â€”BadBlocksã€‚ç›¸è¾ƒäºä»¥å¾€çš„åé—¨æ”»å‡»æ–¹æ³•ï¼ŒBadBlocksæ›´åŠ è½»ä¾¿ä¸”éšè”½ï¼Œèƒ½åœ¨æ›´ä½çš„è®¡ç®—èµ„æºå’ŒGPUæ—¶é—´å†…æˆåŠŸæ³¨å…¥åé—¨å¹¶ç»•è¿‡æœ€å…ˆè¿›çš„é˜²å¾¡æ¡†æ¶ã€‚BadBlocksèƒ½å¤Ÿé€‰æ‹©æ€§åœ°æ±¡æŸ“æ‰©æ•£æ¨¡å‹ä¸­çš„ç‰¹å®šå—ï¼ŒåŒæ—¶ä¿æŒå…¶ä»–ç»„ä»¶çš„æ­£å¸¸åŠŸèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBadBlockså…·æœ‰é«˜æ”»å‡»æˆåŠŸç‡å’Œä½æ„ŸçŸ¥è´¨é‡æŸå¤±çš„ç‰¹ç‚¹ã€‚è¯¥å¨èƒé™ä½äº†å®æ–½åé—¨æ”»å‡»é—¨æ§›ï¼Œå³ä½¿æ˜¯æ¶ˆè´¹è€…çº§åˆ«çš„GPUä¹Ÿå¯ä»¥æ”»å‡»å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å­˜åœ¨åé—¨æ”»å‡»é£é™©ã€‚</li>
<li>BadBlocksæ˜¯ä¸€ç§æ–°å‹åé—¨æ”»å‡»æ–¹æ³•ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æ›´è½»ä¾¿ä¸”éšè”½ã€‚</li>
<li>BadBlocksä»…éœ€çº¦30%çš„è®¡ç®—èµ„æºå’Œ20%çš„GPUæ—¶é—´ï¼ŒæˆåŠŸæ³¨å…¥åé—¨å¹¶ç»•è¿‡æœ€å…ˆè¿›çš„é˜²å¾¡æ¡†æ¶ã€‚</li>
<li>BadBlocksèƒ½å¤Ÿé€‰æ‹©æ€§åœ°æ±¡æŸ“æ‰©æ•£æ¨¡å‹ä¸­çš„ç‰¹å®šå—ï¼Œä¿æŒå…¶ä»–éƒ¨åˆ†æ­£å¸¸è¿ä½œã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºBadBlockså…·æœ‰é«˜æ”»å‡»æˆåŠŸç‡å’Œä½æ„ŸçŸ¥è´¨é‡æŸå¤±çš„ç‰¹ç‚¹ã€‚</li>
<li>BadBlocksèƒ½ç»•è¿‡ç°æœ‰çš„é˜²å¾¡æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯åŸºäºæ³¨æ„åŠ›çš„åé—¨æ£€æµ‹æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.03221">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-29f8227a455cce93af33fe64d8bc0d31.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c9f685408054dc342919d6a74e05e4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75091792281a2f4eaa2ab61b326e672f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a1a57d1e9d54d805dc013b84b38cb5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-954264da8793b3152041455699afc95a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Marrying-Autoregressive-Transformer-and-Diffusion-with-Multi-Reference-Autoregression"><a href="#Marrying-Autoregressive-Transformer-and-Diffusion-with-Multi-Reference-Autoregression" class="headerlink" title="Marrying Autoregressive Transformer and Diffusion with Multi-Reference   Autoregression"></a>Marrying Autoregressive Transformer and Diffusion with Multi-Reference   Autoregression</h2><p><strong>Authors:Dingcheng Zhen, Qian Qiao, Xu Zheng, Tan Yu, Kangxi Wu, Ziwei Zhang, Siyuan Liu, Shunshun Yin, Ming Tao</strong></p>
<p>We introduce TransDiff, the first image generation model that marries Autoregressive (AR) Transformer with diffusion models. In this joint modeling framework, TransDiff encodes labels and images into high-level semantic features and employs a diffusion model to estimate the distribution of image samples. On the ImageNet 256x256 benchmark, TransDiff significantly outperforms other image generation models based on standalone AR Transformer or diffusion models. Specifically, TransDiff achieves a Frechet Inception Distance (FID) of 1.61 and an Inception Score (IS) of 293.4, and further provides x2 faster inference latency compared to state-of-the-art methods based on AR Transformer and x112 faster inference compared to diffusion-only models. Furthermore, building on the TransDiff model, we introduce a novel image generation paradigm called Multi-Reference Autoregression (MRAR), which performs autoregressive generation by predicting the next image. MRAR enables the model to reference multiple previously generated images, thereby facilitating the learning of more diverse representations and improving the quality of generated images in subsequent iterations. By applying MRAR, the performance of TransDiff is improved, with the FID reduced from 1.61 to 1.42. We expect TransDiff to open up a new frontier in the field of image generation. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†TransDiffï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†è‡ªå›å½’ï¼ˆARï¼‰Transformerä¸æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„å›¾ç‰‡ç”Ÿæˆæ¨¡å‹ã€‚åœ¨è¿™ä¸ªè”åˆå»ºæ¨¡æ¡†æ¶ä¸­ï¼ŒTransDiffå°†æ ‡ç­¾å’Œå›¾åƒç¼–ç ä¸ºé«˜çº§è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ¥ä¼°è®¡å›¾åƒæ ·æœ¬çš„åˆ†å¸ƒã€‚åœ¨ImageNet 256x256åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTransDiffæ˜¾è‘—ä¼˜äºå…¶ä»–åŸºäºç‹¬ç«‹AR Transformeræˆ–æ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼ŒTransDiffè¾¾åˆ°äº†Frechet Inception Distanceï¼ˆFIDï¼‰ä¸º1.61å’ŒInception Scoreï¼ˆISï¼‰ä¸º293.4çš„æ°´å¹³ï¼Œä¸åŸºäºAR Transformerçš„ç°æœ‰å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼Œæä¾›äº†x2æ›´å¿«çš„æ¨ç†å»¶è¿Ÿï¼Œä¸ä»…ä½¿ç”¨æ‰©æ•£çš„æ¨¡å‹ç›¸æ¯”ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†x112ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»¥TransDiffæ¨¡å‹ä¸ºåŸºç¡€ï¼Œå¼•å…¥äº†ä¸€ç§æ–°çš„å›¾åƒç”ŸæˆèŒƒå¼â€”â€”å¤šå‚è€ƒè‡ªå›å½’ï¼ˆMRARï¼‰ã€‚MRARé€šè¿‡é¢„æµ‹ä¸‹ä¸€ä¸ªå›¾åƒè¿›è¡Œè‡ªå›å½’ç”Ÿæˆï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå‚è€ƒå¤šä¸ªå…ˆå‰ç”Ÿæˆçš„å›¾åƒï¼Œä»è€Œæ›´å®¹æ˜“å­¦ä¹ æ›´å¤šæ ·åŒ–çš„è¡¨ç¤ºï¼Œå¹¶åœ¨åç»­è¿­ä»£ä¸­æé«˜ç”Ÿæˆçš„å›¾åƒè´¨é‡ã€‚é€šè¿‡åº”ç”¨MRARï¼ŒTransDiffçš„æ€§èƒ½å¾—åˆ°äº†æå‡ï¼ŒFIDä»1.61é™ä½åˆ°äº†1.42ã€‚æˆ‘ä»¬æœŸæœ›TransDiffèƒ½åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå¼€è¾Ÿæ–°çš„å‰æ²¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09482v3">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†ç»“åˆè‡ªå›å½’ï¼ˆARï¼‰Transformerä¸æ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ¨¡å‹TransDiffã€‚å®ƒé‡‡ç”¨è”åˆå»ºæ¨¡æ¡†æ¶ï¼Œå°†æ ‡ç­¾å’Œå›¾åƒç¼–ç ä¸ºé«˜çº§è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹ä¼°è®¡å›¾åƒæ ·æœ¬çš„åˆ†å¸ƒã€‚åœ¨ImageNet 256x256åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTransDiffæ˜¾è‘—ä¼˜äºå…¶ä»–åŸºäºç‹¬ç«‹AR Transformeræˆ–æ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œå®ƒæä¾›äº†åŸºäºMRARï¼ˆå¤šå‚è€ƒè‡ªå›å½’ï¼‰çš„æ–°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œé€šè¿‡é¢„æµ‹ä¸‹ä¸€ä¸ªå›¾åƒè¿›è¡Œè‡ªå›å½’ç”Ÿæˆï¼Œæé«˜äº†æ¨¡å‹çš„å¤šæ ·æ€§å’Œç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TransDiffæ˜¯é¦–ä¸ªç»“åˆè‡ªå›å½’ï¼ˆARï¼‰Transformerå’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>TransDiffåœ¨ImageNet 256x256åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒFIDè¾¾åˆ°1.61ï¼ŒISè¾¾åˆ°293.4ã€‚</li>
<li>TransDiffæä¾›äº†è¾ƒå¿«çš„æ¨ç†é€Ÿåº¦ï¼Œä¸åŸºäºAR Transformerçš„å½“å‰æ–¹æ³•ç›¸æ¯”ï¼Œæ¨ç†å»¶è¿Ÿæ—¶é—´åŠ å¿«äº†x2ï¼Œä¸ä»…ä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ¨ç†å»¶è¿Ÿæ—¶é—´åŠ å¿«äº†x112ã€‚</li>
<li>TransDiffå¼•å…¥äº†æ–°çš„å›¾åƒç”ŸæˆèŒƒå¼â€”â€”Multi-Reference Autoregressionï¼ˆMRARï¼‰ã€‚</li>
<li>MRARèƒ½å¤Ÿå‚è€ƒå¤šä¸ªå…ˆå‰ç”Ÿæˆçš„å›¾åƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„å¤šæ ·æ€§å¹¶æ”¹å–„åç»­è¿­ä»£ä¸­ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</li>
<li>åº”ç”¨MRARåï¼ŒTransDiffçš„æ€§èƒ½å¾—åˆ°æå‡ï¼ŒFIDä»1.61é™è‡³1.42ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09482">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-33f5e40284145f1f4aeef313ac857171.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-619a9ed9863cc171e75a3d7f3ad6e99c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f1ccfb2167c6b90a5873dae20b96d820.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Extremum-Flow-Matching-for-Offline-Goal-Conditioned-Reinforcement-Learning"><a href="#Extremum-Flow-Matching-for-Offline-Goal-Conditioned-Reinforcement-Learning" class="headerlink" title="Extremum Flow Matching for Offline Goal Conditioned Reinforcement   Learning"></a>Extremum Flow Matching for Offline Goal Conditioned Reinforcement   Learning</h2><p><strong>Authors:Quentin Rouxel, Clemente Donoso, Fei Chen, Serena Ivaldi, Jean-Baptiste Mouret</strong></p>
<p>Imitation learning is a promising approach for enabling generalist capabilities in humanoid robots, but its scaling is fundamentally constrained by the scarcity of high-quality expert demonstrations. This limitation can be mitigated by leveraging suboptimal, open-ended play data, often easier to collect and offering greater diversity. This work builds upon recent advances in generative modeling, specifically Flow Matching, an alternative to Diffusion models. We introduce a method for estimating the minimum or maximum of the learned distribution by leveraging the unique properties of Flow Matching, namely, deterministic transport and support for arbitrary source distributions. We apply this method to develop several goal-conditioned imitation and reinforcement learning algorithms based on Flow Matching, where policies are conditioned on both current and goal observations. We explore and compare different architectural configurations by combining core components, such as critic, planner, actor, or world model, in various ways. We evaluated our agents on the OGBench benchmark and analyzed how different demonstration behaviors during data collection affect performance in a 2D non-prehensile pushing task. Furthermore, we validated our approach on real hardware by deploying it on the Talos humanoid robot to perform complex manipulation tasks based on high-dimensional image observations, featuring a sequence of pick-and-place and articulated object manipulation in a realistic kitchen environment. Experimental videos and code are available at: <a target="_blank" rel="noopener" href="https://hucebot.github.io/extremum_flow_matching_website/">https://hucebot.github.io/extremum_flow_matching_website/</a> </p>
<blockquote>
<p>æ¨¡ä»¿å­¦ä¹ æ˜¯åœ¨äººå½¢æœºå™¨äººä¸­å®ç°é€šç”¨èƒ½åŠ›çš„ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ï¼Œä½†å…¶æ‰©å±•æ€§ä»æ ¹æœ¬ä¸Šå—åˆ°é«˜è´¨é‡ä¸“å®¶æ¼”ç¤ºç¨€ç¼ºæ€§çš„é™åˆ¶ã€‚é€šè¿‡åˆ©ç”¨æ¬¡ä¼˜çš„ã€å¼€æ”¾å¼çš„æ¸¸æˆæ•°æ®ï¼Œå¯ä»¥ç¼“è§£è¿™ç§é™åˆ¶ï¼Œè¿™äº›æ•°æ®é€šå¸¸æ›´å®¹æ˜“æ”¶é›†å¹¶ä¸”å…·æœ‰æ›´å¤§çš„å¤šæ ·æ€§ã€‚è¿™é¡¹å·¥ä½œå»ºç«‹åœ¨ç”Ÿæˆå»ºæ¨¡çš„æœ€æ–°è¿›å±•ä¹‹ä¸Šï¼Œç‰¹åˆ«æ˜¯æµåŒ¹é…ï¼ˆFlow Matchingï¼‰æŠ€æœ¯â€”â€”ä¸€ç§æ‰©æ•£æ¨¡å‹çš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨æµåŒ¹é…çš„ç‹¬ç‰¹å±æ€§ï¼Œå³ç¡®å®šæ€§ä¼ è¾“å’Œä»»æ„æºåˆ†å¸ƒçš„æ”¯æŒï¼Œæ¥ä¼°è®¡æ‰€å­¦åˆ†å¸ƒçš„æœ€å°å€¼æˆ–æœ€å¤§å€¼ã€‚æˆ‘ä»¬å°†è¿™ç§æ–¹æ³•åº”ç”¨äºåŸºäºæµåŒ¹é…çš„ç›®æ ‡æ¡ä»¶æ¨¡ä»¿å’Œå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å¼€å‘ï¼Œå…¶ä¸­ç­–ç•¥æ—¢å–å†³äºå½“å‰è§‚å¯Ÿä¹Ÿå–å†³äºç›®æ ‡è§‚å¯Ÿã€‚æˆ‘ä»¬é€šè¿‡ç»„åˆæ ¸å¿ƒç»„ä»¶ï¼Œå¦‚è¯„è®ºå®¶ã€è§„åˆ’å¸ˆã€æ¼”å‘˜æˆ–ä¸–ç•Œæ¨¡å‹ï¼Œä»¥å„ç§æ–¹å¼æ¢ç´¢å¹¶æ¯”è¾ƒä¸åŒçš„æ¶æ„é…ç½®ã€‚æˆ‘ä»¬åœ¨OGBenchåŸºå‡†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„ä»£ç†ï¼Œå¹¶åˆ†æäº†åœ¨æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­ä¸åŒæ¼”ç¤ºè¡Œä¸ºå¯¹äºŒç»´éæŠ“å–æ¨åŠ¨ä»»åŠ¡æ€§èƒ½çš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å°†æ–¹æ³•éƒ¨ç½²åœ¨Talosäººå½¢æœºå™¨äººä¸Šæ‰§è¡ŒåŸºäºé«˜ç»´å›¾åƒè§‚å¯Ÿçš„å¤æ‚æ“ä½œä»»åŠ¡ï¼Œæ¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•åœ¨çœŸå®ç¡¬ä»¶ä¸Šçš„æœ‰æ•ˆæ€§ã€‚è¿™äº›ä»»åŠ¡åŒ…æ‹¬ä¸€ç³»åˆ—æ‹¾å–å’Œæ”¾ç½®ä»¥åŠå…³èŠ‚å¯¹è±¡æ“ä½œï¼Œåœ¨ä¸€ä¸ªç°å®å¨æˆ¿ç¯å¢ƒä¸­è¿›è¡Œã€‚å®éªŒè§†é¢‘å’Œä»£ç å¯è®¿é—®äºï¼š<a target="_blank" rel="noopener" href="https://hucebot.github.io/extremum_flow_matching_website/">https://hucebot.github.io/extremum_flow_matching_website/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19717v2">PDF</a> 2025 IEEE-RAS 24th International Conference on Humanoid Robots   (Humanoids), Sep 2025, Seoul, South Korea</p>
<p><strong>Summary</strong><br>     æœ¬è®ºæ–‡æ¢è®¨äº†åˆ©ç”¨æµåŒ¹é…æŠ€æœ¯å®ç°åŸºäºæ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„æœºå™¨äººé€šç”¨èƒ½åŠ›çš„æ–¹æ³•ã€‚ç ”ç©¶é€šè¿‡ç»“åˆæµåŒ¹é…æŠ€æœ¯çš„ç‹¬ç‰¹å±æ€§ï¼Œä¾‹å¦‚ç¡®å®šæ€§ä¼ è¾“å’Œä»»æ„æºåˆ†å¸ƒçš„æ”¯æŒï¼Œå‘å±•äº†ä¸€ç³»åˆ—ç›®æ ‡æ¡ä»¶ä¸‹çš„æ¨¡ä»¿å’Œå¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚ç ”ç©¶åœ¨OGBenchåŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†æ™ºèƒ½ä½“æ€§èƒ½ï¼Œå¹¶æ¢è®¨äº†æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­çš„ä¸åŒæ¼”ç¤ºè¡Œä¸ºå¯¹äºŒç»´éæŠ“å–æ¨åŠ¨ä»»åŠ¡æ€§èƒ½çš„å½±å“ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨Talosäººå½¢æœºå™¨äººä¸Šè¿›è¡Œäº†å¤æ‚æ“ä½œä»»åŠ¡çš„ç°å®ç¡¬ä»¶éªŒè¯ï¼ŒåŒ…æ‹¬ä¸€ç³»åˆ—åŸºäºé«˜ç»´å›¾åƒè§‚å¯Ÿçš„æ‹¾å–å’Œæ”¾ç½®ä»¥åŠå…³èŠ‚å¼ç‰©ä½“æ“æ§ä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨æ¨¡ä»¿å­¦ä¹ å®ç°æœºå™¨äººé€šç”¨èƒ½åŠ›çš„æ–¹æ³•å…·æœ‰æ½œåŠ›ï¼Œä½†å—é™äºé«˜è´¨é‡ä¸“å®¶æ¼”ç¤ºçš„ç¨€ç¼ºæ€§ã€‚</li>
<li>æå‡ºåˆ©ç”¨æ¬¡ä¼˜ã€å¼€æ”¾å¼çš„æ¸¸æˆæ•°æ®æ¥ç¼“è§£è¿™ä¸€é™åˆ¶ï¼Œè¿™äº›æ•°æ®æ›´å®¹æ˜“æ”¶é›†ä¸”æ›´å…·å¤šæ ·æ€§ã€‚</li>
<li>å¼•å…¥åŸºäºæµåŒ¹é…æŠ€æœ¯çš„ä¼°è®¡åˆ†å¸ƒæå€¼çš„æ–¹æ³•ï¼Œåˆ©ç”¨æµåŒ¹é…çš„ç¡®å®šæ€§ä¼ è¾“å’Œä»»æ„æºåˆ†å¸ƒæ”¯æŒç­‰ç‹¬ç‰¹å±æ€§ã€‚</li>
<li>å‘å±•äº†ä¸€ç³»åˆ—ç›®æ ‡æ¡ä»¶ä¸‹çš„æ¨¡ä»¿å’Œå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¿™äº›ç®—æ³•ç»“åˆäº†æ ¸å¿ƒç»„ä»¶ï¼Œå¦‚è¯„ä»·è€…ã€è§„åˆ’è€…ã€è¡ŒåŠ¨è€…æˆ–ä¸–ç•Œæ¨¡å‹ã€‚</li>
<li>åœ¨OGBenchåŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†æ™ºèƒ½ä½“æ€§èƒ½ï¼Œå¹¶æ¢ç´¢äº†æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­ä¸åŒæ¼”ç¤ºè¡Œä¸ºå¯¹ä»»åŠ¡æ€§èƒ½çš„å½±å“ã€‚</li>
<li>åœ¨Talosäººå½¢æœºå™¨äººä¸Šè¿›è¡Œäº†å¤æ‚æ“ä½œä»»åŠ¡çš„ç°å®ç¡¬ä»¶éªŒè¯ï¼Œå±•ç¤ºäº†ä¸€ç³»åˆ—åŸºäºé«˜ç»´å›¾åƒè§‚å¯Ÿçš„æ“æ§ä»»åŠ¡ã€‚</li>
<li>å®éªŒè§†é¢‘å’Œä»£ç å¯é€šè¿‡ç›¸å…³ç½‘ç«™è·å–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19717">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d53ca718be4912c0fa65f91904326d7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-415ac7ad964e97413e3c1be4ccca6293.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e744a74602d78f4c4a713c29b7ab2678.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03393c433d531ae097ad01a004a9ddf8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0b012a0f2f12c97d351b2ab8702c234.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Reconstruction-Free-Anomaly-Detection-with-Diffusion-Models"><a href="#Reconstruction-Free-Anomaly-Detection-with-Diffusion-Models" class="headerlink" title="Reconstruction-Free Anomaly Detection with Diffusion Models"></a>Reconstruction-Free Anomaly Detection with Diffusion Models</h2><p><strong>Authors:Shunsuke Sakai, Xiangteng He, Chunzhi Gu, Leonid Sigal, Tatsuhito Hasegawa</strong></p>
<p>Despite the remarkable success, recent reconstruction-based anomaly detection (AD) methods via diffusion modeling still involve fine-grained noise-strength tuning and computationally expensive multi-step denoising, leading to a fundamental tension between fidelity and efficiency. In this paper, we propose a novel inversion-based AD approach - detection via noising in latent space - which circumvents explicit reconstruction. Importantly, we contend that the limitations in prior reconstruction-based methods originate from the prevailing detection via denoising in RGB space paradigm. To address this, we model AD under a reconstruction-free formulation, which directly infers the final latent variable corresponding to the input image via DDIM inversion, and then measures the deviation based on the known prior distribution for anomaly scoring. Specifically, in approximating the original probability flow ODE using the Euler method, we only enforce very few inversion steps to noise the clean image to pursue inference efficiency. As the added noise is adaptively derived with the learned diffusion model, the original features for the clean testing image can still be leveraged to yield high detection accuracy. We perform extensive experiments and detailed analysis across three widely used image AD datasets under the unsupervised unified setting to demonstrate the effectiveness of our model, regarding state-of-the-art AD performance, and about 2 times inference time speedup without diffusion distillation. </p>
<blockquote>
<p>å°½ç®¡å–å¾—äº†æ˜¾è‘—çš„æˆæœï¼Œä½†æœ€è¿‘åŸºäºé‡å»ºçš„å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰æ–¹æ³•é€šè¿‡æ‰©æ•£å»ºæ¨¡ä»ç„¶æ¶‰åŠç²¾ç»†çš„å™ªå£°å¼ºåº¦è°ƒæ•´å’Œè®¡ç®—æ˜‚è´µçš„å¤šæ­¥å»å™ªï¼Œä»è€Œåœ¨ä¿çœŸåº¦å’Œæ•ˆç‡ä¹‹é—´äº§ç”ŸåŸºæœ¬çŸ›ç›¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåè½¬çš„æ–°é¢–ADæ–¹æ³•â€”â€”é€šè¿‡æ½œåœ¨ç©ºé—´çš„å™ªå£°æ£€æµ‹â€”â€”é¿å…äº†æ˜ç¡®çš„é‡å»ºè¿‡ç¨‹ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è®¤ä¸ºå…ˆå‰åŸºäºé‡å»ºçš„æ–¹æ³•çš„é™åˆ¶æºäºæµè¡Œçš„åŸºäºRGBç©ºé—´å»å™ªæ£€æµ‹çš„æ¨¡å¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨æ— éœ€é‡å»ºçš„å…¬å¼ä¸‹å¯¹ADè¿›è¡Œå»ºæ¨¡ï¼Œè¯¥å…¬å¼é€šè¿‡DDIMåè½¬ç›´æ¥æ¨æ–­å¯¹åº”äºè¾“å…¥å›¾åƒçš„æœ€ç»ˆæ½œåœ¨å˜é‡ï¼Œç„¶åæ ¹æ®å·²çŸ¥å…ˆéªŒåˆ†å¸ƒæµ‹é‡åå·®ä»¥è¿›è¡Œå¼‚å¸¸è¯„åˆ†ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨åˆ©ç”¨æ¬§æ‹‰æ–¹æ³•è¿‘ä¼¼åŸå§‹æ¦‚ç‡æµODEæ—¶ï¼Œæˆ‘ä»¬åªå¼ºåˆ¶æ‰§è¡Œå¾ˆå°‘çš„åè½¬æ­¥éª¤æ¥å¯¹å¹²å‡€å›¾åƒæ·»åŠ å™ªå£°ï¼Œä»¥è¿½æ±‚æ¨ç†æ•ˆç‡ã€‚ç”±äºæ·»åŠ çš„å™ªå£°æ˜¯å€ŸåŠ©å­¦ä¹ åˆ°çš„æ‰©æ•£æ¨¡å‹è‡ªé€‚åº”å¾—å‡ºçš„ï¼Œå› æ­¤ä»ç„¶å¯ä»¥åˆ©ç”¨å¹²å‡€æµ‹è¯•å›¾åƒçš„åŸç‰¹å¾æ¥å®ç°é«˜æ£€æµ‹ç²¾åº¦ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„å›¾åƒADæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒå’Œè¯¦ç»†åˆ†æï¼Œä»¥å±•ç¤ºæˆ‘ä»¬çš„æ¨¡å‹åœ¨æ— ç›‘ç£ç»Ÿä¸€è®¾ç½®ä¸‹çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬åœ¨å¼‚å¸¸æ£€æµ‹æ–¹é¢çš„æœ€æ–°æ€§èƒ½ä»¥åŠåœ¨æœªä½¿ç”¨æ‰©æ•£è’¸é¦çš„æƒ…å†µä¸‹çº¦åŠ å¿«2å€çš„æ¨ç†æ—¶é—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05662v2">PDF</a> Code is available at <a target="_blank" rel="noopener" href="https://github.com/SkyShunsuke/InversionAD">https://github.com/SkyShunsuke/InversionAD</a></p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé€†è¿‡ç¨‹çš„å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œå™ªå£°æ£€æµ‹ï¼Œé¿å…äº†æ˜¾å¼çš„é‡å»ºè¿‡ç¨‹ã€‚è¯¥æ–¹æ³•é€šè¿‡ç›´æ¥æ¨æ–­è¾“å…¥å›¾åƒå¯¹åº”çš„æœ€ç»ˆæ½œåœ¨å˜é‡ï¼Œå¹¶åŸºäºå·²çŸ¥å…ˆéªŒåˆ†å¸ƒæµ‹é‡åå·®æ¥è¿›è¡Œå¼‚å¸¸è¯„åˆ†ï¼Œå®ç°äº†é«˜æ•ˆä¸”é«˜å‡†ç¡®ç‡çš„å¼‚å¸¸æ£€æµ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡å»ºæ–¹æ³•åœ¨å¤„ç†å¼‚å¸¸æ£€æµ‹æ—¶å­˜åœ¨ç²¾ç»†å™ªå£°å¼ºåº¦è°ƒæ•´å’Œè®¡ç®—æ˜‚è´µçš„å¤šæ­¥å»å™ªé—®é¢˜ï¼Œå½±å“ä¿çœŸåº¦å’Œæ•ˆç‡ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹çš„åŸºäºé€†è¿‡ç¨‹çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œé€šè¿‡æ½œåœ¨ç©ºé—´çš„å™ªå£°æ£€æµ‹ç»•è¿‡æ˜¾å¼çš„é‡å»ºè¿‡ç¨‹ã€‚</li>
<li>ç°æœ‰é‡å»ºæ–¹æ³•çš„å±€é™æ€§æºäºRGBç©ºé—´å»å™ªæ£€æµ‹çš„æ¨¡å¼ï¼Œè€Œæ–°æ–¹æ³•é‡‡ç”¨æ— é‡å»ºå…¬å¼è¿›è¡Œå»ºæ¨¡ï¼Œç›´æ¥æ¨æ–­è¾“å…¥å›¾åƒå¯¹åº”çš„æ½œåœ¨å˜é‡ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨Euleræ–¹æ³•è¿‘ä¼¼åŸå§‹æ¦‚ç‡æµODEï¼Œä»…æ‰§è¡Œå°‘é‡é€†æ­¥éª¤å¯¹å¹²å‡€å›¾åƒè¿›è¡Œå™ªå£°å¤„ç†ï¼Œæé«˜äº†æ¨ç†æ•ˆç‡ã€‚</li>
<li>å€ŸåŠ©å­¦ä¹ åˆ°çš„æ‰©æ•£æ¨¡å‹è‡ªé€‚åº”åœ°ç”Ÿæˆå™ªå£°ï¼ŒåŒæ—¶åˆ©ç”¨å¹²å‡€æµ‹è¯•å›¾åƒçš„åŸç‰¹å¾ï¼Œå®ç°äº†é«˜æ£€æµ‹ç²¾åº¦ã€‚</li>
<li>åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„å›¾åƒå¼‚å¸¸æ£€æµ‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒå’Œè¯¦ç»†åˆ†æï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¼‚å¸¸æ£€æµ‹æ€§èƒ½ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05662">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1c050efb66c1747a105dcacc3f457c1b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33093207d5ff22dc03ba714a4d8694f5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4bd3b5718d4bac2922efcdcfe6a56d8f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fdc450a1113c84014fe4a33f2a9c27f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-519b468674fd0fbd1a78533de12516c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80d45f79204517e4403686c70321857b.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Identity-Preserving-3D-Head-Stylization-with-Multiview-Score-Distillation"><a href="#Identity-Preserving-3D-Head-Stylization-with-Multiview-Score-Distillation" class="headerlink" title="Identity Preserving 3D Head Stylization with Multiview Score   Distillation"></a>Identity Preserving 3D Head Stylization with Multiview Score   Distillation</h2><p><strong>Authors:Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar</strong></p>
<p>3D head stylization transforms realistic facial features into artistic representations, enhancing user engagement across gaming and virtual reality applications. While 3D-aware generators have made significant advancements, many 3D stylization methods primarily provide near-frontal views and struggle to preserve the unique identities of original subjects, often resulting in outputs that lack diversity and individuality. This paper addresses these challenges by leveraging the PanoHead model, synthesizing images from a comprehensive 360-degree perspective. We propose a novel framework that employs negative log-likelihood distillation (LD) to enhance identity preservation and improve stylization quality. By integrating multi-view grid score and mirror gradients within the 3D GAN architecture and introducing a score rank weighing technique, our approach achieves substantial qualitative and quantitative improvements. Our findings not only advance the state of 3D head stylization but also provide valuable insights into effective distillation processes between diffusion models and GANs, focusing on the critical issue of identity preservation. Please visit the <a target="_blank" rel="noopener" href="https://three-bee.github.io/head_stylization">https://three-bee.github.io/head_stylization</a> for more visuals. </p>
<blockquote>
<p>3Då¤´éƒ¨é£æ ¼åŒ–è½¬æ¢èƒ½å°†çœŸå®çš„é¢éƒ¨ç‰¹å¾è½¬åŒ–ä¸ºè‰ºæœ¯è¡¨ç°å½¢å¼ï¼Œå¢å¼ºæ¸¸æˆå’Œè™šæ‹Ÿç°å®åº”ç”¨ä¸­çš„ç”¨æˆ·å‚ä¸åº¦ã€‚è™½ç„¶3Dæ„ŸçŸ¥ç”Ÿæˆå™¨å·²ç»å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†è®¸å¤š3Dé£æ ¼åŒ–æ–¹æ³•ä¸»è¦æä¾›è¿‘ä¹æ­£é¢çš„è§†è§’ï¼Œå¹¶ä¸”åœ¨ä¿ç•™åŸå§‹ä¸»ä½“çš„ç‹¬ç‰¹èº«ä»½æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¾€å¾€å¯¼è‡´è¾“å‡ºç»“æœç¼ºä¹å¤šæ ·æ€§å’Œä¸ªæ€§åŒ–ã€‚æœ¬æ–‡é€šè¿‡åˆ©ç”¨PanoHeadæ¨¡å‹ï¼Œä»å…¨é¢çš„360åº¦è§†è§’åˆæˆå›¾åƒï¼Œæ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é‡‡ç”¨è´Ÿå¯¹æ•°ä¼¼ç„¶è’¸é¦ï¼ˆLDï¼‰çš„æ–°æ¡†æ¶ï¼Œä»¥æé«˜èº«ä»½ä¿ç•™å’Œæé«˜é£æ ¼åŒ–è´¨é‡ã€‚é€šè¿‡åœ¨3D GANæ¶æ„ä¸­æ•´åˆå¤šè§†å›¾ç½‘æ ¼è¯„åˆ†å’Œé•œåƒæ¢¯åº¦ï¼Œå¹¶å¼•å…¥è¯„åˆ†æ’ååŠ æƒæŠ€æœ¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ä»…æ¨åŠ¨äº†3Då¤´éƒ¨é£æ ¼åŒ–çš„ç°çŠ¶ï¼Œè€Œä¸”ä¸ºæ‰©æ•£æ¨¡å‹å’ŒGANsä¹‹é—´çš„æœ‰æ•ˆè’¸é¦è¿‡ç¨‹æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œé‡ç‚¹å…³æ³¨èº«ä»½ä¿ç•™è¿™ä¸€å…³é”®é—®é¢˜ã€‚æ›´å¤šè§†è§‰æ•ˆæœè¯·è®¿é—® <a target="_blank" rel="noopener" href="https://three-bee.github.io/head_stylization%E3%80%82">https://three-bee.github.io/head_stylizationã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13536v3">PDF</a> <a target="_blank" rel="noopener" href="https://three-bee.github.io/head_stylization">https://three-bee.github.io/head_stylization</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºPanoHeadæ¨¡å‹çš„3Då¤´éƒ¨é£æ ¼åŒ–æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å¯ä»¥ä»å…¨æ–¹ä½çš„è§†è§’åˆæˆå›¾åƒï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤´éƒ¨é£æ ¼åŒ–ä¸­é¢ä¸´çš„è§†è§’å±€é™å’Œèº«ä»½ä¿ç•™é—®é¢˜ã€‚é€šè¿‡å¼•å…¥è´Ÿå¯¹æ•°ä¼¼ç„¶è’¸é¦ï¼ˆLDï¼‰æŠ€æœ¯ï¼Œç»“åˆå¤šè§†å›¾ç½‘æ ¼è¯„åˆ†å’Œé•œåƒæ¢¯åº¦åœ¨3D GANæ¶æ„ä¸­çš„åº”ç”¨ï¼Œä»¥åŠè¯„åˆ†æ’ååŠ æƒæŠ€æœ¯ï¼Œå®ç°äº†å®è´¨æ€§çš„å®šæ€§å’Œå®šé‡æ”¹è¿›ã€‚è¯¥ç ”ç©¶ä¸ä»…æ¨åŠ¨äº†3Då¤´éƒ¨é£æ ¼åŒ–çš„å‘å±•ï¼Œè¿˜ä¸ºæ‰©æ•£æ¨¡å‹å’ŒGANä¹‹é—´çš„æœ‰æ•ˆè’¸é¦è¿‡ç¨‹æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Då¤´éƒ¨é£æ ¼åŒ–èƒ½å¢å¼ºæ¸¸æˆå’Œè™šæ‹Ÿç°å®åº”ç”¨ä¸­çš„ç”¨æˆ·å‚ä¸åº¦ï¼Œé€šè¿‡è‰ºæœ¯åŒ–çš„é¢éƒ¨ç‰¹å¾è¡¨ç°æå‡ç”¨æˆ·ä½“éªŒã€‚</li>
<li>å½“å‰3Dé£æ ¼åŒ–æ–¹æ³•ä¸»è¦æä¾›è¿‘æ­£é¢è§†è§’ï¼Œéš¾ä»¥ä¿ç•™åŸå§‹ä¸»ä½“çš„ç‹¬ç‰¹èº«ä»½ï¼Œå¯¼è‡´è¾“å‡ºç¼ºä¹å¤šæ ·æ€§å’Œä¸ªæ€§åŒ–ã€‚</li>
<li>PanoHeadæ¨¡å‹èƒ½ä»å…¨æ–¹ä½çš„è§†è§’åˆæˆå›¾åƒï¼Œè§£å†³äº†è§†è§’å±€é™é—®é¢˜ã€‚</li>
<li>å¼•å…¥è´Ÿå¯¹æ•°ä¼¼ç„¶è’¸é¦ï¼ˆLDï¼‰æŠ€æœ¯ï¼Œæå‡èº«ä»½ä¿ç•™å’Œé£æ ¼åŒ–è´¨é‡ã€‚</li>
<li>ç»“åˆå¤šè§†å›¾ç½‘æ ¼è¯„åˆ†å’Œé•œåƒæ¢¯åº¦åœ¨3D GANæ¶æ„ä¸­ï¼Œæé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>è¯„åˆ†æ’ååŠ æƒæŠ€æœ¯æœ‰åŠ©äºå®ç°å®è´¨æ€§çš„å®šæ€§å’Œå®šé‡æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13536">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8ac76f674ffd8641b0f31b116585c35c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1612f87ccdf6345ee2c899364b1ce24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-553bf29d23535a63e778d67323ea9be0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0afc402e0563d5c0e25c3f0b8adc57cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-136a4a25b7a3be398142db937a06e31e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Six-CD-Benchmarking-Concept-Removals-for-Benign-Text-to-image-Diffusion-Models"><a href="#Six-CD-Benchmarking-Concept-Removals-for-Benign-Text-to-image-Diffusion-Models" class="headerlink" title="Six-CD: Benchmarking Concept Removals for Benign Text-to-image Diffusion   Models"></a>Six-CD: Benchmarking Concept Removals for Benign Text-to-image Diffusion   Models</h2><p><strong>Authors:Jie Ren, Kangrui Chen, Yingqian Cui, Shenglai Zeng, Hui Liu, Yue Xing, Jiliang Tang, Lingjuan Lyu</strong></p>
<p>Text-to-image (T2I) diffusion models have shown exceptional capabilities in generating images that closely correspond to textual prompts. However, the advancement of T2I diffusion models presents significant risks, as the models could be exploited for malicious purposes, such as generating images with violence or nudity, or creating unauthorized portraits of public figures in inappropriate contexts. To mitigate these risks, concept removal methods have been proposed. These methods aim to modify diffusion models to prevent the generation of malicious and unwanted concepts. Despite these efforts, existing research faces several challenges: (1) a lack of consistent comparisons on a comprehensive dataset, (2) ineffective prompts in harmful and nudity concepts, (3) overlooked evaluation of the ability to generate the benign part within prompts containing malicious concepts. To address these gaps, we propose to benchmark the concept removal methods by introducing a new dataset, Six-CD, along with a novel evaluation metric. In this benchmark, we conduct a thorough evaluation of concept removals, with the experimental observations and discussions offering valuable insights in the field. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä¸æ–‡æœ¬æç¤ºç´§å¯†å¯¹åº”çš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒT2Iæ‰©æ•£æ¨¡å‹çš„è¿›æ­¥ä¹Ÿå¸¦æ¥äº†é‡å¤§é£é™©ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹å¯èƒ½ä¼šè¢«ç”¨äºæ¶æ„ç›®çš„ï¼Œä¾‹å¦‚ç”Ÿæˆæš´åŠ›æˆ–è£¸ä½“å›¾åƒï¼Œæˆ–åœ¨ä¸å½“èƒŒæ™¯ä¸‹åˆ›å»ºå…¬ä¼—äººç‰©çš„æœªç»æˆæƒè‚–åƒã€‚ä¸ºäº†å‡å°‘è¿™äº›é£é™©ï¼Œå·²ç»æå‡ºäº†æ¦‚å¿µç§»é™¤æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•æ—¨åœ¨ä¿®æ”¹æ‰©æ•£æ¨¡å‹ï¼Œä»¥é˜²æ­¢ç”Ÿæˆæ¶æ„å’Œä¸éœ€è¦çš„æ¦‚å¿µã€‚å°½ç®¡ä»˜å‡ºäº†è¿™äº›åŠªåŠ›ï¼Œç°æœ‰ç ”ç©¶ä»é¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰ç¼ºä¹åœ¨ç»¼åˆæ•°æ®é›†ä¸Šçš„ä¸€è‡´æ¯”è¾ƒï¼Œï¼ˆ2ï¼‰åœ¨æœ‰å®³å’Œè£¸ä½“æ¦‚å¿µæ–¹é¢çš„æç¤ºæ— æ•ˆï¼Œï¼ˆ3ï¼‰å¿½è§†äº†åœ¨åŒ…å«æ¶æ„æ¦‚å¿µçš„æç¤ºä¸­ç”Ÿæˆè‰¯æ€§éƒ¨åˆ†çš„èƒ½åŠ›çš„è¯„ä¼°ã€‚ä¸ºäº†å¼¥è¡¥è¿™äº›ä¸è¶³ï¼Œæˆ‘ä»¬æè®®é€šè¿‡å¼•å…¥æ–°çš„æ•°æ®é›†Six-CDä»¥åŠä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡æ¥è¯„ä¼°æ¦‚å¿µç§»é™¤æ–¹æ³•ã€‚åœ¨æ­¤åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å¯¹æ¦‚å¿µç§»é™¤è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå®éªŒè§‚å¯Ÿå’Œè®¨è®ºä¸ºè¯¥é¢†åŸŸæä¾›äº†å®è´µçš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.14855v3">PDF</a> Accepted by CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰çš„æ‰©æ•£æ¨¡å‹åœ¨æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„è¿›æ­¥ä¹Ÿå¸¦æ¥äº†è¢«ç”¨äºæ¶æ„ç›®çš„çš„é£é™©ï¼Œå¦‚ç”Ÿæˆæš´åŠ›æˆ–è£¸ä½“å›¾åƒï¼Œæˆ–åœ¨ä¸é€‚å½“çš„ä¸Šä¸‹æ–‡ä¸­åˆ›å»ºå…¬ä¼—äººç‰©çš„æœªç»æˆæƒè‚–åƒã€‚ä¸ºäº†ç¼“è§£è¿™äº›é£é™©ï¼Œæå‡ºäº†æ¦‚å¿µç§»é™¤æ–¹æ³•ï¼Œæ—¨åœ¨ä¿®æ”¹æ‰©æ•£æ¨¡å‹ä»¥é˜²æ­¢ç”Ÿæˆæ¶æ„å’Œä¸éœ€è¦çš„æ¦‚å¿µã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶é¢ä¸´ç¼ºä¹ç»¼åˆæ•°æ®é›†çš„ä¸€è‡´æ¯”è¾ƒã€æœ‰å®³å’Œè£¸ä½“æ¦‚å¿µæç¤ºæ— æ•ˆä»¥åŠå¿½è§†åœ¨åŒ…å«æ¶æ„æ¦‚å¿µçš„æç¤ºä¸­ç”Ÿæˆè‰¯æ€§éƒ¨åˆ†çš„èƒ½åŠ›è¯„ä¼°ç­‰æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æè®®é€šè¿‡å¼•å…¥æ–°çš„æ•°æ®é›†å’Œæ–°çš„è¯„ä¼°æŒ‡æ ‡æ¥è¯„ä¼°æ¦‚å¿µç§»é™¤æ–¹æ³•ã€‚åœ¨æ­¤åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å¯¹æ¦‚å¿µç§»é™¤è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå®éªŒè§‚å¯Ÿå’Œè®¨è®ºä¸ºè¯¥é¢†åŸŸæä¾›äº†å®è´µçš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>T2Iæ‰©æ•£æ¨¡å‹å…·æœ‰æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒçš„èƒ½åŠ›ï¼Œä½†ä¹Ÿå­˜åœ¨è¢«ç”¨äºç”Ÿæˆæ¶æ„å›¾åƒçš„é£é™©ã€‚</li>
<li>æ¦‚å¿µç§»é™¤æ–¹æ³•æ—¨åœ¨ä¿®æ”¹æ‰©æ•£æ¨¡å‹ï¼Œä»¥é˜²æ­¢ç”Ÿæˆæ¶æ„å’Œä¸éœ€è¦çš„æ¦‚å¿µã€‚</li>
<li>ç°æœ‰ç ”ç©¶åœ¨è¯„ä¼°æ¦‚å¿µç§»é™¤æ–¹æ³•æ—¶é¢ä¸´ç¼ºä¹ç»¼åˆæ•°æ®é›†çš„ä¸€è‡´æ¯”è¾ƒçš„æŒ‘æˆ˜ã€‚</li>
<li>æœ‰å®³å’Œè£¸ä½“æ¦‚å¿µçš„æç¤ºåœ¨ç°æœ‰ç ”ç©¶ä¸­å¯èƒ½æ— æ•ˆã€‚</li>
<li>è¯„ä¼°åº”æ¶µç›–åœ¨åŒ…å«æ¶æ„æ¦‚å¿µçš„æç¤ºä¸­ç”Ÿæˆè‰¯æ€§éƒ¨åˆ†çš„èƒ½åŠ›ã€‚</li>
<li>ä¸ºäº†è§£å†³ç°æœ‰ç ”ç©¶çš„ä¸è¶³ï¼Œæå‡ºäº†å¼•å…¥æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡çš„åŸºå‡†æµ‹è¯•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.14855">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7639785c0d68610dd08062216c717327.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-85c814b0aa26acfb876e6c9193787418.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7c8487a4332da90e10d404282267763.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-beecbaeddbc0390fc247d595c485a195.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b51759f1e825ba40b8affc6fb25018fd.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-22/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-22/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-22/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0047ae843a9a5e7b30c2ebf47a9d818a.jpg" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-22  Tooth-Diffusion Guided 3D CBCT Synthesis with Fine-Grained Tooth   Conditioning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-22/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0afc402e0563d5c0e25c3f0b8adc57cb.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-22  SATURN Autoregressive Image Generation Guided by Scene Graphs
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31987.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
