<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS 方向最新论文已更新，请持续关注 Update in 2025-08-22  Long-Context Speech Synthesis with Context-Aware Memory">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4b930ab27e19b587a0b375e5b562d4d3.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-22-更新"><a href="#2025-08-22-更新" class="headerlink" title="2025-08-22 更新"></a>2025-08-22 更新</h1><h2 id="Long-Context-Speech-Synthesis-with-Context-Aware-Memory"><a href="#Long-Context-Speech-Synthesis-with-Context-Aware-Memory" class="headerlink" title="Long-Context Speech Synthesis with Context-Aware Memory"></a>Long-Context Speech Synthesis with Context-Aware Memory</h2><p><strong>Authors:Zhipeng Li, Xiaofen Xing, Jingyuan Xing, Hangrui Hu, Heng Lu, Xiangmin Xu</strong></p>
<p>In long-text speech synthesis, current approaches typically convert text to speech at the sentence-level and concatenate the results to form pseudo-paragraph-level speech. These methods overlook the contextual coherence of paragraphs, leading to reduced naturalness and inconsistencies in style and timbre across the long-form speech. To address these issues, we propose a Context-Aware Memory (CAM)-based long-context Text-to-Speech (TTS) model. The CAM block integrates and retrieves both long-term memory and local context details, enabling dynamic memory updates and transfers within long paragraphs to guide sentence-level speech synthesis. Furthermore, the prefix mask enhances the in-context learning ability by enabling bidirectional attention on prefix tokens while maintaining unidirectional generation. Experimental results demonstrate that the proposed method outperforms baseline and state-of-the-art long-context methods in terms of prosody expressiveness, coherence and context inference cost across paragraph-level speech. </p>
<blockquote>
<p>在长篇文本语音合成中，当前的方法通常是在句子层面将文本转换为语音，并将结果连接起来形成伪段落级别的语音。这些方法忽略了段落的上下文连贯性，导致长篇语音的自然度降低，风格和音色不一致。为了解决这些问题，我们提出了一种基于上下文感知内存（CAM）的长上下文文本到语音（TTS）模型。CAM块集成并检索长期记忆和局部上下文细节，实现长段落内的动态内存更新和转移，以指导句子级别的语音合成。此外，前缀掩码通过允许前缀标记的双向注意力而维持单向生成，增强了上下文学习能力。实验结果表明，所提出的方法在段落级别的语音中，相对于基准方法和最先进的长上下文方法，在语调表达、连贯性和上下文推理成本方面都有更好的表现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14713v1">PDF</a> Accepted by Interspeech25</p>
<p><strong>Summary</strong></p>
<p>文本提出了基于上下文感知内存（CAM）的长时间文本语音转换模型，解决现有技术忽视段落上下文连贯性的问题。模型整合长期记忆与局部上下文细节，能在长段落内进行动态内存更新和转移，进而指导句子级别的语音合成。前缀掩码增强了模型的上下文学习能力，通过双向关注前缀标记同时保持单向生成。实验证明，该方法在段落级别的语音合成中，相较于基准和前沿技术，在语调表达、连贯性和上下文推断成本方面表现更优。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>当前文本语音合成方法主要关注句子级别转换，忽视段落上下文连贯性。</li>
<li>提出的CAM模型整合长期记忆和局部上下文细节。</li>
<li>CAM模型能在长段落内进行动态内存更新和转移。</li>
<li>前缀掩码增强模型的上下文学习能力，实现双向关注前缀标记。</li>
<li>实验证明，CAM模型在段落级别的语音合成的语调表达、连贯性方面表现优异。</li>
<li>CAM模型相较于其他方法，在上下文推断成本方面有更优表现。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14713">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-614a126d34cfb5c3e0cc923b7130ad5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90c268c4836f0dc43d311e6c484ead24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0c0a0b357858341b7fa079e637a8143.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09fc7e9717feb7883f87404139bf7ff7.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Your-Reward-Function-for-RL-is-Your-Best-PRM-for-Search-Unifying-RL-and-Search-Based-TTS"><a href="#Your-Reward-Function-for-RL-is-Your-Best-PRM-for-Search-Unifying-RL-and-Search-Based-TTS" class="headerlink" title="Your Reward Function for RL is Your Best PRM for Search: Unifying RL and   Search-Based TTS"></a>Your Reward Function for RL is Your Best PRM for Search: Unifying RL and   Search-Based TTS</h2><p><strong>Authors:Can Jin, Yang Zhou, Qixin Zhang, Hongwu Peng, Di Zhang, Marco Pavone, Ligong Han, Zhang-Wei Hong, Tong Che, Dimitris N. Metaxas</strong></p>
<p>Test-time scaling (TTS) for large language models (LLMs) has thus far fallen into two largely separate paradigms: (1) reinforcement learning (RL) methods that optimize sparse outcome-based rewards, yet suffer from instability and low sample efficiency; and (2) search-based techniques guided by independently trained, static process reward models (PRMs), which require expensive human- or LLM-generated labels and often degrade under distribution shifts. In this paper, we introduce AIRL-S, the first natural unification of RL-based and search-based TTS. Central to AIRL-S is the insight that the reward function learned during RL training inherently represents the ideal PRM for guiding downstream search. Specifically, we leverage adversarial inverse reinforcement learning (AIRL) combined with group relative policy optimization (GRPO) to learn a dense, dynamic PRM directly from correct reasoning traces, entirely eliminating the need for labeled intermediate process data. At inference, the resulting PRM simultaneously serves as the critic for RL rollouts and as a heuristic to effectively guide search procedures, facilitating robust reasoning chain extension, mitigating reward hacking, and enhancing cross-task generalization. Experimental results across eight benchmarks, including mathematics, scientific reasoning, and code generation, demonstrate that our unified approach improves performance by 9 % on average over the base model, matching GPT-4o. Furthermore, when integrated into multiple search algorithms, our PRM consistently outperforms all baseline PRMs trained with labeled data. These results underscore that, indeed, your reward function for RL is your best PRM for search, providing a robust and cost-effective solution to complex reasoning tasks in LLMs. </p>
<blockquote>
<p>测试时间缩放（TTS）对于大型语言模型（LLM）迄今为止主要分为两种截然不同的范式：<br>（1）强化学习（RL）方法能够优化基于结果的稀疏奖励，但存在不稳定性和低样本效率的问题；<br>（2）基于独立训练的静态过程奖励模型（PRM）引导下的搜索技术，这需要昂贵的人工或LLM生成的标签，并且在分布变化时往往会退化。<br>在本文中，我们介绍了AIRL-S，这是基于RL和基于搜索的TTS的自然统一。AIRL-S的核心见解是，在RL训练期间学到的奖励函数本质上代表了引导下游搜索的理想PRM。具体来说，我们利用对抗性逆向强化学习（AIRL）结合群体相对策略优化（GRPO），直接从正确的推理轨迹中学习密集、动态的PRM，完全消除了对标记的中间过程数据的需求。在推理过程中，所得的PRM同时作为RL演练的评论家，并作为有效引导搜索过程的启发式方法，促进稳健的推理链扩展，缓解奖励破解，并增强跨任务泛化。<br>在包括数学、科学推理和代码生成等在内的八个基准测试上的实验结果表明，我们的统一方法平均比基础模型提高了9%的性能，与GPT-4o相匹配。此外，当集成到多种搜索算法中时，我们的PRM始终优于使用标记数据训练的基线PRM。这些结果强调，你的RL奖励函数就是你的最佳PRM搜索工具，为LLM中的复杂推理任务提供了稳健且经济的解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14313v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文介绍了测试时间缩放（TTS）在大型语言模型（LLM）中的两种主要方法及其局限性。针对这些问题，提出了一种新的方法AIRL-S，将RL和搜索方法相结合，通过利用对抗性逆向强化学习（AIRL）和群体相对策略优化（GRPO）来构建动态过程奖励模型（PRM），无需标注的中间过程数据。实验结果表明，该方法在多个基准测试中平均提高了9%的性能，与GPT-4相当。此外，将其集成到多种搜索算法中，始终优于使用标记数据训练的基准PRM。总的来说，该文的奖励函数对于强化学习来说是最佳的过程奖励模型搜索函数，为大型语言模型中的复杂推理任务提供了稳健且经济的解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TTS在大型语言模型（LLM）中分为强化学习（RL）和搜索两种主要方法，各有其局限性。</li>
<li>AIRL-S是首个将RL和搜索方法自然结合的方法。</li>
<li>AIRL-S利用对抗性逆向强化学习（AIRL）和群体相对策略优化（GRPO）构建动态过程奖励模型（PRM）。</li>
<li>该方法无需标注的中间过程数据，通过正确的推理轨迹来学习密集、动态的过程奖励模型。</li>
<li>在多个基准测试中，AIRL-S提高了性能，平均提升9%，与GPT-4相当。</li>
<li>将AIRL-S集成到多种搜索算法中，始终优于使用标记数据训练的基准PRM。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14313">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-5198d26e3e08dc7b2acf49f570b44b5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f57c37203deab202935d2ac2bd89c171.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MahaTTS-A-Unified-Framework-for-Multilingual-Text-to-Speech-Synthesis"><a href="#MahaTTS-A-Unified-Framework-for-Multilingual-Text-to-Speech-Synthesis" class="headerlink" title="MahaTTS: A Unified Framework for Multilingual Text-to-Speech Synthesis"></a>MahaTTS: A Unified Framework for Multilingual Text-to-Speech Synthesis</h2><p><strong>Authors:Jaskaran Singh, Amartya Roy Chowdhury, Raghav Prabhakar, Varshul C. W</strong></p>
<p>Current Text-to-Speech models pose a multilingual challenge, where most of the models traditionally focus on English and European languages, thereby hurting the potential to provide access to information to many more people. To address this gap, we introduce MahaTTS-v2 a Multilingual Multi-speaker Text-To-Speech (TTS) system that has excellent multilingual expressive capabilities in Indic languages. The model has been trained on around 20K hours of data specifically focused on Indian languages. Our approach leverages Wav2Vec2.0 tokens for semantic extraction, and a Language Model (LM) for text-to-semantic modeling. Additionally, we have used a Conditional Flow Model (CFM) for semantics to melspectogram generation. The experimental results indicate the effectiveness of the proposed approach over other frameworks. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/dubverse-ai/MahaTTSv2">https://github.com/dubverse-ai/MahaTTSv2</a> </p>
<blockquote>
<p>当前文本转语音模型面临多语言挑战，因为大多数传统模型主要关注英语和欧洲语言，从而限制了为更多人提供信息访问的可能性。为了解决这一差距，我们推出了MahaTTS-v2多语种多发言人文本转语音（TTS）系统，该系统在印地语等语言中具有出色的多语言表达能力。该模型在专门聚焦于印度语言的约20K小时数据上进行了训练。我们的方法利用Wav2Vec2.0令牌进行语义提取，并利用语言模型进行文本到语义建模。此外，我们还使用了条件流模型（CFM）进行语义到频谱图的生成。实验结果表明，与其他框架相比，所提出的方法是有效的。我们的代码位于<a target="_blank" rel="noopener" href="https://github.com/dubverse-ai/MahaTTSv2">https://github.com/dubverse-ai/MahaTTSv2</a></p>
</blockquote>
<p><strong>简化的翻译</strong></p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14049v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>当前文本转语音模型在多语种方面存在挑战，传统模型主要关注英语和欧洲语言，限制了为更多人提供信息访问的机会。为解决这一问题，我们推出了MahaTTS-v2，这是一款具有印地语等多语言表达能力的文本转语音（TTS）系统。该模型在专注于印度语言的数据上进行了约2万小时的培训。我们的方法利用Wav2Vec2.0进行语义提取，并利用语言模型进行文本到语义的建模。此外，我们还使用了条件流模型进行语义到音频频谱生成。实验结果表明，该方法较其他框架更为有效。我们的代码可通过链接访问：<a target="_blank" rel="noopener" href="https://github.com/dubverse-ai/MahaTTSv2">https://github.com/dubverse-ai/MahaTTSv2</a>。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>当前文本转语音（TTS）模型在多语种方面存在挑战，尤其针对非英语和欧洲语言的模型较少。</li>
<li>为了解决这一挑战，推出了MahaTTS-v2，一个具有多语言表达能力的TTS系统。</li>
<li>该模型专注于印度语言，进行了约2万小时的培训。</li>
<li>利用Wav2Vec2.0进行语义提取，确保模型能更准确地理解和生成不同语言的语音内容。</li>
<li>采用语言模型（LM）进行文本到语义的建模，增强了模型的文本理解能力。</li>
<li>使用条件流模型（CFM）将语义转化为音频频谱，提高了语音生成的音质和流畅度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14049">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-266d460b83823345a83e19dc6ec6fc6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-45ba6de9869bd0f3cb389890de92c33c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d221857f9cc14efbc3dc88de6882353a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e6b68178769507cd99f21aa0cbe3f883.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction"><a href="#DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction" class="headerlink" title="DiffIER: Optimizing Diffusion Models with Iterative Error Reduction"></a>DiffIER: Optimizing Diffusion Models with Iterative Error Reduction</h2><p><strong>Authors:Ao Chen, Lihe Ding, Tianfan Xue</strong></p>
<p>Diffusion models have demonstrated remarkable capabilities in generating high-quality samples and enhancing performance across diverse domains through Classifier-Free Guidance (CFG). However, the quality of generated samples is highly sensitive to the selection of the guidance weight. In this work, we identify a critical &#96;&#96;training-inference gap’’ and we argue that it is the presence of this gap that undermines the performance of conditional generation and renders outputs highly sensitive to the guidance weight. We quantify this gap by measuring the accumulated error during the inference stage and establish a correlation between the selection of guidance weight and minimizing this gap. Furthermore, to mitigate this gap, we propose DiffIER, an optimization-based method for high-quality generation. We demonstrate that the accumulated error can be effectively reduced by an iterative error minimization at each step during inference. By introducing this novel plug-and-play optimization framework, we enable the optimization of errors at every single inference step and enhance generation quality. Empirical results demonstrate that our proposed method outperforms baseline approaches in conditional generation tasks. Furthermore, the method achieves consistent success in text-to-image generation, image super-resolution, and text-to-speech generation, underscoring its versatility and potential for broad applications in future research. </p>
<blockquote>
<p>扩散模型已经显示出在生成高质量样本和提高跨不同领域的性能方面的显著能力，这主要是通过无分类器引导（CFG）实现的。然而，生成样本的质量对引导权重的选择非常敏感。在这项工作中，我们识别出了一个关键的“训练推理差距”，我们认为正是这个差距的存在削弱了条件生成的表现，使输出对引导权重高度敏感。我们通过测量推理阶段的累积误差来量化这一差距，并建立引导权重的选择与最小化这一差距之间的相关性。此外，为了缓解这一差距，我们提出了DiffIER，这是一种基于优化的高质量生成方法。我们证明，通过推理过程中每一步的迭代误差最小化，可以有效地减少累积误差。通过引入这种新型的即插即用优化框架，我们能够在每一个单独的推理步骤中优化误差，提高生成质量。经验结果表明，我们提出的方法在条件生成任务上优于基准方法。此外，该方法在文本到图像生成、图像超分辨率和文本到语音生成方面取得了持续的成功，这突显了其在未来研究中的通用性和潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13628v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了扩散模型通过无分类器引导（CFG）在生成高质量样本和提高不同领域性能方面的显著能力。然而，生成样本的质量对引导权重的选择非常敏感。本文识别了一个关键的“训练-推理差距”，并认为这个差距影响了条件生成性能并使输出对引导权重高度敏感。为了量化这个差距并减少其对生成质量的影响，作者提出了一种基于优化的方法DiffIER，通过迭代误差最小化在推理过程中的每一步来优化误差。实验结果表明，该方法在条件生成任务上优于基线方法，并在文本到图像生成、图像超分辨率和文本到语音生成中实现了成功应用。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>扩散模型通过无分类器引导（CFG）展现了生成高质量样本和提高不同领域性能的显著能力。</li>
<li>生成的样本质量对引导权重的选择非常敏感。</li>
<li>存在一个关键的“训练-推理差距”，这影响了条件生成性能。</li>
<li>作者通过测量推理阶段的累积误差来量化这个差距，并发现其与选择引导权重有关。</li>
<li>为了减少这个差距，作者提出了DiffIER方法，这是一种基于优化的高质量生成方法。</li>
<li>DiffIER通过迭代误差最小化在推理过程中的每一步来优化误差，有效减少了累积误差。</li>
<li>实证结果表明，DiffIER在条件生成任务上优于基线方法，并在多个领域具有广泛的应用潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13628">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6660ec06ea983b3718bb6178bb74c51f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b930ab27e19b587a0b375e5b562d4d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e391cf99658d7fa44fd322b3db1d0ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d613ceafcd367c3788f918797f75b6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-90754254ba6f2d1faf962c9d63bcf529.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="FNH-TTS-A-Fast-Natural-and-Human-Like-Speech-Synthesis-System-with-advanced-prosodic-modeling-based-on-Mixture-of-Experts"><a href="#FNH-TTS-A-Fast-Natural-and-Human-Like-Speech-Synthesis-System-with-advanced-prosodic-modeling-based-on-Mixture-of-Experts" class="headerlink" title="FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with   advanced prosodic modeling based on Mixture of Experts"></a>FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with   advanced prosodic modeling based on Mixture of Experts</h2><p><strong>Authors:Qingliang Meng, Yuqing Deng, Wei Liang, Limei Yu, Huizhi Liang, Tian Li</strong></p>
<p>Achieving natural and human-like speech synthesis with low inference costs remains a major challenge in speech synthesis research. This study focuses on human prosodic patterns and synthesized spectrum harmony, addressing the challenges of prosody modeling and artifact issues in non-autoregressive models. To enhance prosody modeling and synthesis quality, we introduce a new Duration Predictor based on the Mixture of Experts alongside a new Vocoder with two advanced multi-scale discriminators. We integrated the these new modules into the VITS system, forming our FNH-TTS system. Our experiments on LJSpeech, VCTK, and LibriTTS demonstrate the system’s superiority in synthesis quality, phoneme duration prediction, Vocoder results, and synthesis speed. Our prosody visualization results show that FNH-TTS produces duration predictions that more closely align with natural human beings than other systems. </p>
<blockquote>
<p>实现具有低成本推理的自然和拟人语音合成仍然是语音合成研究的主要挑战。本研究关注人类韵律模式和合成频谱和谐，解决非自回归模型中的韵律建模和伪影问题。为了增强韵律建模和合成质量，我们引入了一种基于专家混合的新持续时间预测器，以及具有两个先进多尺度鉴别器的新Vocoder。我们将这些新模块集成到VITS系统中，形成了我们的FNH-TTS系统。我们在LJSpeech、VCTK和LibriTTS上的实验证明了系统在合成质量、音素持续时间预测、Vocoder结果和合成速度方面的优越性。我们的韵律可视化结果表明，FNH-TTS产生的持续时间预测与其他系统相比，更接近于自然人类。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12001v2">PDF</a> </p>
<p><strong>Summary</strong><br>新一代TTS技术对于合成自然和人一样的语音仍有待挑战。本研究关注人类韵律模式和合成频谱和谐性，解决非自回归模型中的韵律建模和人工制品问题。通过引入基于混合专家的新持续时间预测器以及具有两个先进多尺度鉴别器的全新Vocoder，提高了韵律建模和合成质量。集成这些新模块到VITS系统中，形成我们的FNH-TTS系统。实验表明，该系统在合成质量、音素持续时间预测、Vocoder结果和合成速度上优于其他系统，生成的韵律可视化结果更贴近自然人的表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究旨在解决TTS技术中合成自然和人一样的语音的挑战。</li>
<li>关注人类韵律模式和合成频谱和谐性，以解决非自回归模型的韵律建模和人工制品问题。</li>
<li>引入基于混合专家的新持续时间预测器以提高韵律建模和合成质量。</li>
<li>使用全新的Vocoder，并结合两个先进的多尺度鉴别器以增强合成效果。</li>
<li>集成新模块到VITS系统，形成FNH-TTS系统。</li>
<li>实验证明FNH-TTS在合成质量、音素持续时间预测等方面表现优越。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12001">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-168a948c50306608d96f1e9cca0951bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07b87d647c08768811ba838a389ecb82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb8293187e68dbe3b98515438382d6fe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f2765146d8e9ba422ab874481d39df87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de212c5e25c77b537dc513df982ccb9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aabfb140e32162546fd1d2ea0b491f08.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="FMSD-TTS-Few-shot-Multi-Speaker-Multi-Dialect-Text-to-Speech-Synthesis-for-U-Tsang-Amdo-and-Kham-Speech-Dataset-Generation"><a href="#FMSD-TTS-Few-shot-Multi-Speaker-Multi-Dialect-Text-to-Speech-Synthesis-for-U-Tsang-Amdo-and-Kham-Speech-Dataset-Generation" class="headerlink" title="FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis   for Ü-Tsang, Amdo and Kham Speech Dataset Generation"></a>FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis   for Ü-Tsang, Amdo and Kham Speech Dataset Generation</h2><p><strong>Authors:Yutong Liu, Ziyue Zhang, Ban Ma-bao, Yuqing Cai, Yongbin Yu, Renzeng Duojie, Xiangxiang Wang, Fan Gao, Cheng Huang, Nyima Tashi</strong></p>
<p>Tibetan is a low-resource language with minimal parallel speech corpora spanning its three major dialects-&quot;U-Tsang, Amdo, and Kham-limiting progress in speech modeling. To address this issue, we propose FMSD-TTS, a few-shot, multi-speaker, multi-dialect text-to-speech framework that synthesizes parallel dialectal speech from limited reference audio and explicit dialect labels. Our method features a novel speaker-dialect fusion module and a Dialect-Specialized Dynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and linguistic variations across dialects while preserving speaker identity. Extensive objective and subjective evaluations demonstrate that FMSD-TTS significantly outperforms baselines in both dialectal expressiveness and speaker similarity. We further validate the quality and utility of the synthesized speech through a challenging speech-to-speech dialect conversion task. Our contributions include: (1) a novel few-shot TTS system tailored for Tibetan multi-dialect speech synthesis, (2) the public release of a large-scale synthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source evaluation toolkit for standardized assessment of speaker similarity, dialect consistency, and audio quality. </p>
<blockquote>
<p>藏语是一种资源匮乏的语言，其三大方言区——乌兹藏、安多和康区的平行语音语料库极少，限制了语音建模的进展。为了解决这一问题，我们提出了FMSD-TTS，这是一个小样本、多发言人、多方言的文本-语音合成框架，它可以从有限的参考音频和明确的方言标签中合成平行的方言语音。我们的方法具有新颖的发声人-方言融合模块和方言专用动态路由网络（DSDR-Net），能够捕捉方言之间的精细声学和语言变异，同时保留发声人的身份。大量的客观和主观评估表明，FMSD-TTS在方言表达力和发声人相似性方面显著优于基准线。我们进一步通过具有挑战性的语音到语音的方言转换任务来验证合成语音的质量和实用性。我们的贡献包括：（1）针对藏语多方言语音合成的少样本TTS系统，（2）公开发布由FMSD-TTS生成的大规模合成藏语语音语料库，（3）开放源评估工具包，用于标准化评估发声人相似性、方言一致性和音频质量。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14351v3">PDF</a> 18 pages</p>
<p><strong>摘要</strong><br>    针对藏语资源匮乏的问题，提出了一种基于少量样本的多说话者、多方言文本转语音（TTS）框架FMSD-TTS。该框架能从有限的参考音频和明确的方言标签中合成出平行的方言语音。它采用了一种新颖的说话者-方言融合模块和方言专用动态路由网络（DSDR-Net），以捕捉不同方言之间精细的声学和语言变化，同时保留说话者的身份。客观和主观评估表明，FMSD-TTS在方言表现力和说话者相似性方面显著优于基准模型。此外，通过具有挑战性的语音到语音的方言转换任务验证了合成语音的质量和实用性。本文的贡献包括：（1）针对藏语多方言语音合成的少样本TTS系统，（2）公开发布由FMSD-TTS生成的大规模藏语语音语料库，（3）开放评估工具包，用于标准化评估说话者相似性、方言一致性和音频质量。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>藏语是一种资源匮乏的语言，其三大方言（U-Tsang、Amdo、Kham）的平行语音语料库有限，限制了语音建模的进展。</li>
<li>提出了一种基于少量样本的多说话者、多方言的文本转语音（TTS）框架FMSD-TTS，能够合成平行方言语音。</li>
<li>FMSD-TTS框架包含新颖的说话者-方言融合模块和方言专用动态路由网络（DSDR-Net），以捕捉方言间的细微差异并保留说话者身份。</li>
<li>客观和主观评估表明，FMSD-TTS在方言表达力和说话者相似性方面优于其他模型。</li>
<li>FMSD-TTS成功通过了语音到语音的方言转换任务的验证，证明了其合成语音的质量和实用性。</li>
<li>本研究公开发布了由FMSD-TTS生成的大规模藏语语音语料库，为未来的研究提供了资源。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14351">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9832cda8551a30eed7c569bd472571ed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7cf40e3b6b02527ed73b4893e350c99a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8baeb05356aa372b4567d9d3b37c765.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dfac1a4b3c72eb451dd4c345a15196b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ee51008435b0f7d8ab42587c7930a55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24d9e117e58e3798a87304b8d3a3bdd1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-22/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-22/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-23/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4a1220d90ca9cc844fe9d58293966c16.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2025-08-23  DIFFA Large Language Diffusion Models Can Listen and Understand
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-22/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-d700281679eec196f1cd12687d59bd19.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-08-22  DINOv3 with Test-Time Training for Medical Image Registration
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30191.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
