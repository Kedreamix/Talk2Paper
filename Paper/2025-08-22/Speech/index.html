<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-22  Long-Context Speech Synthesis with Context-Aware Memory">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4dadaeb1284a27cfb99f761cd4d22539.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-22-æ›´æ–°"><a href="#2025-08-22-æ›´æ–°" class="headerlink" title="2025-08-22 æ›´æ–°"></a>2025-08-22 æ›´æ–°</h1><h2 id="Long-Context-Speech-Synthesis-with-Context-Aware-Memory"><a href="#Long-Context-Speech-Synthesis-with-Context-Aware-Memory" class="headerlink" title="Long-Context Speech Synthesis with Context-Aware Memory"></a>Long-Context Speech Synthesis with Context-Aware Memory</h2><p><strong>Authors:Zhipeng Li, Xiaofen Xing, Jingyuan Xing, Hangrui Hu, Heng Lu, Xiangmin Xu</strong></p>
<p>In long-text speech synthesis, current approaches typically convert text to speech at the sentence-level and concatenate the results to form pseudo-paragraph-level speech. These methods overlook the contextual coherence of paragraphs, leading to reduced naturalness and inconsistencies in style and timbre across the long-form speech. To address these issues, we propose a Context-Aware Memory (CAM)-based long-context Text-to-Speech (TTS) model. The CAM block integrates and retrieves both long-term memory and local context details, enabling dynamic memory updates and transfers within long paragraphs to guide sentence-level speech synthesis. Furthermore, the prefix mask enhances the in-context learning ability by enabling bidirectional attention on prefix tokens while maintaining unidirectional generation. Experimental results demonstrate that the proposed method outperforms baseline and state-of-the-art long-context methods in terms of prosody expressiveness, coherence and context inference cost across paragraph-level speech. </p>
<blockquote>
<p>åœ¨é•¿ç¯‡æ–‡æœ¬è¯­éŸ³åˆæˆä¸­ï¼Œå½“å‰çš„æ–¹æ³•é€šå¸¸æ˜¯åœ¨å¥å­å±‚é¢å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼Œå¹¶å°†ç»“æœæ‹¼æ¥èµ·æ¥å½¢æˆä¼ªæ®µè½çº§è¯­éŸ³ã€‚è¿™äº›æ–¹æ³•å¿½è§†äº†æ®µè½çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼Œå¯¼è‡´é•¿ç¯‡è¯­éŸ³çš„è‡ªç„¶åº¦é™ä½ï¼Œé£æ ¼å’ŒéŸ³è‰²ä¸ä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸Šä¸‹æ–‡æ„ŸçŸ¥è®°å¿†ï¼ˆCAMï¼‰çš„é•¿æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ã€‚CAMæ¨¡å—èƒ½å¤Ÿé›†æˆå¹¶æ£€ç´¢é•¿æœŸè®°å¿†å’Œå±€éƒ¨ä¸Šä¸‹æ–‡ç»†èŠ‚ï¼Œä»è€Œåœ¨é•¿æ®µè½å†…å®ç°åŠ¨æ€å†…å­˜æ›´æ–°å’Œä¼ è¾“ï¼Œä»¥æŒ‡å¯¼å¥å­çº§è¯­éŸ³åˆæˆã€‚æ­¤å¤–ï¼Œå‰ç¼€æ©ç é€šè¿‡å…è®¸å‰ç¼€æ ‡è®°çš„åŒå‘æ³¨æ„åŠ›åŒæ—¶ä¿æŒå•å‘ç”Ÿæˆï¼Œå¢å¼ºäº†ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è¯­è°ƒè¡¨ç°åŠ›ã€è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡æ¨ç†æˆæœ¬æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•å’Œå…ˆè¿›çš„é•¿ä¸Šä¸‹æ–‡æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ®µè½çº§è¯­éŸ³æ–¹é¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14713v1">PDF</a> Accepted by Interspeech25</p>
<p><strong>Summary</strong>ï¼šé’ˆå¯¹é•¿æ–‡æœ¬è¯­éŸ³åˆæˆä¸­çš„è¯­å¢ƒè¿è´¯æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºä¸Šä¸‹æ–‡æ„ŸçŸ¥è®°å¿†ï¼ˆCAMï¼‰çš„é•¿æ–‡æœ¬è¯­éŸ³åˆæˆï¼ˆTTSï¼‰æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡æ•´åˆå’Œæ£€ç´¢é•¿æœŸè®°å¿†å’Œå±€éƒ¨ä¸Šä¸‹æ–‡ç»†èŠ‚ï¼Œå®ç°äº†åŠ¨æ€å†…å­˜æ›´æ–°å’Œé•¿æ®µè½å†…çš„ä¼ è¾“ï¼Œä»è€ŒæŒ‡å¯¼å¥å­çº§åˆ«çš„è¯­éŸ³åˆæˆã€‚åŒæ—¶ï¼Œå‰ç¼€æ©ç å¢å¼ºäº†æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­çš„å­¦ä¹ èƒ½åŠ›ï¼Œé€šè¿‡åŒå‘å…³æ³¨å‰ç¼€ä»¤ç‰Œæ¥ä¿æŒå•å‘ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¯‡ç« çº§åˆ«çš„è¯­éŸ³åˆæˆä¸­ï¼Œç›¸è¾ƒäºåŸºå‡†æ–¹æ³•å’Œå…ˆè¿›çš„é•¿æ–‡æœ¬æ–¹æ³•ï¼Œå…·æœ‰æ›´å¼ºçš„è¯­è°ƒè¡¨ç°åŠ›ã€è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡æ¨ç†æˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å½“å‰çš„é•¿æ–‡æœ¬è¯­éŸ³åˆæˆæ–¹æ³•å¿½ç•¥äº†ç¯‡ç« çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„è¯­éŸ³è‡ªç„¶åº¦é™ä½ã€é£æ ¼å’Œæ—¶é—´æ„Ÿä¸ä¸€è‡´ã€‚</li>
<li>æå‡ºäº†åŸºäºä¸Šä¸‹æ–‡æ„ŸçŸ¥è®°å¿†ï¼ˆCAMï¼‰çš„TTSæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ•´åˆå’Œæ£€ç´¢é•¿æœŸè®°å¿†å’Œå±€éƒ¨ä¸Šä¸‹æ–‡ç»†èŠ‚ã€‚</li>
<li>CAMæ¨¡å—èƒ½å¤Ÿå®ç°åŠ¨æ€å†…å­˜æ›´æ–°å’Œé•¿æ®µè½å†…çš„ä¿¡æ¯ä¼ è¾“ï¼Œä»¥æŒ‡å¯¼å¥å­çº§åˆ«çš„è¯­éŸ³åˆæˆã€‚</li>
<li>å‰ç¼€æ©ç å¢å¼ºäº†æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­çš„å­¦ä¹ èƒ½åŠ›ï¼Œå…è®¸åŒå‘å…³æ³¨å‰ç¼€ä»¤ç‰Œï¼ŒåŒæ—¶ä¿æŒå•å‘ç”Ÿæˆã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ç¯‡ç« çº§åˆ«çš„è¯­éŸ³åˆæˆçš„è¯­è°ƒè¡¨ç°åŠ›ã€è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡æ¨ç†æˆæœ¬æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>è¯¥æ¨¡å‹è§£å†³äº†é•¿æ–‡æœ¬è¯­éŸ³åˆæˆä¸­çš„è¯­å¢ƒè¿è´¯æ€§é—®é¢˜ï¼Œæé«˜äº†è¯­éŸ³çš„è‡ªç„¶åº¦å’Œä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14713">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-614a126d34cfb5c3e0cc923b7130ad5e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-90c268c4836f0dc43d311e6c484ead24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0c0a0b357858341b7fa079e637a8143.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-09fc7e9717feb7883f87404139bf7ff7.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="EmoTale-An-Enacted-Speech-emotion-Dataset-in-Danish"><a href="#EmoTale-An-Enacted-Speech-emotion-Dataset-in-Danish" class="headerlink" title="EmoTale: An Enacted Speech-emotion Dataset in Danish"></a>EmoTale: An Enacted Speech-emotion Dataset in Danish</h2><p><strong>Authors:Maja J. Hjuler, Harald V. Skat-RÃ¸rdam, Line H. Clemmensen, Sneha Das</strong></p>
<p>While multiple emotional speech corpora exist for commonly spoken languages, there is a lack of functional datasets for smaller (spoken) languages, such as Danish. To our knowledge, Danish Emotional Speech (DES), published in 1997, is the only other database of Danish emotional speech. We present EmoTale; a corpus comprising Danish and English speech recordings with their associated enacted emotion annotations. We demonstrate the validity of the dataset by investigating and presenting its predictive power using speech emotion recognition (SER) models. We develop SER models for EmoTale and the reference datasets using self-supervised speech model (SSLM) embeddings and the openSMILE feature extractor. We find the embeddings superior to the hand-crafted features. The best model achieves an unweighted average recall (UAR) of 64.1% on the EmoTale corpus using leave-one-speaker-out cross-validation, comparable to the performance on DES. </p>
<blockquote>
<p>è™½ç„¶å¤šç§å¸¸ç”¨è¯­è¨€çš„æƒ…æ„Ÿè¯­éŸ³è¯­æ–™åº“å·²ç»å­˜åœ¨ï¼Œä½†å¯¹äºè¾ƒå°çš„è¯­ç§ï¼ˆå¦‚ä¸¹éº¦è¯­ï¼‰æ¥è¯´ï¼Œç¼ºä¹åŠŸèƒ½æ€§çš„æ•°æ®é›†ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œä¸¹éº¦æƒ…æ„Ÿè¯­éŸ³ï¼ˆDESï¼‰æ˜¯ä¸¹éº¦æƒ…æ„Ÿè¯­éŸ³å”¯ä¸€å¯ç”¨çš„æ•°æ®åº“ï¼Œå‘è¡¨äº1997å¹´ã€‚æˆ‘ä»¬æ¨å‡ºEmoTaleï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«ä¸¹éº¦è¯­å’Œè‹±è¯­è¯­éŸ³è®°å½•ä»¥åŠç›¸åº”çš„æƒ…ç»ªæ ‡æ³¨æ•°æ®çš„è¯­æ–™åº“ã€‚æˆ‘ä»¬é€šè¿‡ç ”ç©¶å¹¶æå‡ºè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›æ¥è¯æ˜æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬ä½¿ç”¨è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹ï¼ˆSSLMï¼‰åµŒå…¥å’Œå¼€æ”¾SMILEç‰¹å¾æå–å™¨ä¸ºEmoTaleå’Œå‚è€ƒæ•°æ®é›†å¼€å‘SERæ¨¡å‹ã€‚æˆ‘ä»¬å‘ç°åµŒå…¥ç‰©çš„æ€§èƒ½ä¼˜äºæ‰‹å·¥ç‰¹å¾ã€‚ä½¿ç”¨ç•™å‡ºä¸€ä½å‘è¨€äººä½œä¸ºéªŒè¯çš„äº¤å‰éªŒè¯æ³•ï¼Œæœ€ä½³æ¨¡å‹åœ¨EmoTaleè¯­æ–™åº“ä¸Šçš„æœªåŠ æƒå¹³å‡å¬å›ç‡ï¼ˆUARï¼‰è¾¾åˆ°64.1%ï¼Œä¸DESä¸Šçš„æ€§èƒ½ç›¸å½“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14548v1">PDF</a> To appear in the proceedings of ASRU 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶ä»‹ç»äº†é’ˆå¯¹ä¸¹éº¦è¯­æƒ…æ„Ÿè¯­éŸ³çš„è¯­æ–™åº“EmoTaleã€‚è¯¥ç ”ç©¶å¡«è¡¥äº†ä¸¹éº¦è¯­æƒ…æ„Ÿè¯­éŸ³åŠŸèƒ½æ•°æ®é›†ç¼ºä¹çš„ç©ºç™½ï¼Œæä¾›äº†åŒ…å«ä¸¹éº¦è¯­å’Œè‹±è¯­è¯­éŸ³å½•éŸ³åŠå…¶ç›¸å…³æƒ…æ„Ÿæ³¨é‡Šçš„è¯­æ–™åº“ã€‚ç ”ç©¶é€šè¿‡æƒ…æ„Ÿè¯­éŸ³è¯†åˆ«ï¼ˆSERï¼‰æ¨¡å‹éªŒè¯äº†æ•°æ®é›†çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä½¿ç”¨è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹åµŒå…¥å’ŒopenSMILEç‰¹å¾æå–å™¨å¼€å‘SERæ¨¡å‹ã€‚ç ”ç©¶å‘ç°ï¼Œè‡ªç›‘ç£æ¨¡å‹åµŒå…¥ä¼˜äºæ‰‹å·¥ç‰¹å¾ï¼Œæœ€ä½³æ¨¡å‹åœ¨EmoTaleè¯­æ–™åº“ä¸Šçš„æœªåŠ æƒå¹³å‡å¬å›ç‡ï¼ˆUARï¼‰è¾¾åˆ°64.1%ï¼Œä¸DESæ€§èƒ½ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EmoTaleè¯­æ–™åº“æ˜¯åŒ…å«ä¸¹éº¦è¯­å’Œè‹±è¯­æƒ…æ„Ÿè¯­éŸ³çš„æ•°æ®åº“ï¼Œå¡«è¡¥äº†é’ˆå¯¹å°å‹è¯­è¨€æƒ…æ„Ÿè¯­éŸ³åŠŸèƒ½æ•°æ®é›†çš„ç¼ºä¹ã€‚</li>
<li>ç ”ç©¶é€šè¿‡æƒ…æ„Ÿè¯­éŸ³è¯†åˆ«ï¼ˆSERï¼‰æ¨¡å‹éªŒè¯äº†EmoTaleè¯­æ–™åº“çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ä½¿ç”¨è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹åµŒå…¥å’ŒopenSMILEç‰¹å¾æå–å™¨å¼€å‘SERæ¨¡å‹ã€‚</li>
<li>è‡ªç›‘ç£æ¨¡å‹åµŒå…¥åœ¨æ€§èƒ½ä¸Šä¼˜äºæ‰‹å·¥ç‰¹å¾ã€‚</li>
<li>æœ€ä½³æ¨¡å‹åœ¨EmoTaleè¯­æ–™åº“ä¸Šçš„æœªåŠ æƒå¹³å‡å¬å›ç‡ï¼ˆUARï¼‰è¾¾åˆ°64.1%ã€‚</li>
<li>EmoTaleè¯­æ–™åº“çš„æ€§èƒ½ä¸ç°æœ‰çš„ä¸¹éº¦æƒ…æ„Ÿè¯­éŸ³æ•°æ®åº“DESç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14548">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a72b776ae5f2210311ec7ed090e64991.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5dab64a73ede8fe579c3b1c4acdadb11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a222f1f1d652d51d0da18d3e2d5fa88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-89cf304acbb1a693deea75054bb03987.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d8fb283ed578886f65be38f3f072cfac.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EmoSLLM-Parameter-Efficient-Adaptation-of-LLMs-for-Speech-Emotion-Recognition"><a href="#EmoSLLM-Parameter-Efficient-Adaptation-of-LLMs-for-Speech-Emotion-Recognition" class="headerlink" title="EmoSLLM: Parameter-Efficient Adaptation of LLMs for Speech Emotion   Recognition"></a>EmoSLLM: Parameter-Efficient Adaptation of LLMs for Speech Emotion   Recognition</h2><p><strong>Authors:Hugo Thimonier, Antony Perzo, Renaud Seguier</strong></p>
<p>Emotion recognition from speech is a challenging task that requires capturing both linguistic and paralinguistic cues, with critical applications in human-computer interaction and mental health monitoring. Recent works have highlighted the ability of Large Language Models (LLMs) to perform tasks outside of the sole natural language area. In particular, recent approaches have investigated coupling LLMs with other data modalities by using pre-trained backbones and different fusion mechanisms. This work proposes a novel approach that fine-tunes an LLM with audio and text representations for emotion prediction. Our method first extracts audio features using an audio feature extractor, which are then mapped into the LLMâ€™s representation space via a learnable interfacing module. The LLM takes as input (1) the transformed audio features, (2) additional features in the form of natural language (e.g., the transcript), and (3) a textual prompt describing the emotion prediction task. To efficiently adapt the LLM to this multimodal task, we employ Low-Rank Adaptation (LoRA), enabling parameter-efficient fine-tuning. Experimental results on standard emotion recognition benchmarks demonstrate that our model outperforms all but one existing Speech-Text LLMs in the literature, while requiring less than half the parameters of competing approaches. This highlights our approachâ€™s effectiveness in integrating multi-modal inputs for speech-based emotion understanding while maintaining significant computational efficiency. </p>
<blockquote>
<p>ä»è¯­éŸ³ä¸­è¿›è¡Œæƒ…æ„Ÿè¯†åˆ«æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦æ•æ‰è¯­è¨€å’Œéè¯­è¨€çº¿ç´¢ï¼Œåœ¨äººæœºäº¤äº’å’Œå¿ƒç†å¥åº·ç›‘æµ‹ç­‰é¢†åŸŸæœ‰é‡è¦åº”ç”¨ã€‚è¿‘æœŸçš„ç ”ç©¶å·¥ä½œçªå‡ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ‰§è¡Œè‡ªç„¶è¯­è¨€é¢†åŸŸä»¥å¤–ä»»åŠ¡çš„èƒ½åŠ›ã€‚ç‰¹åˆ«æ˜¯è¿‘æœŸçš„æ–¹æ³•é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„ä¸»å¹²ç½‘ç»œå’Œä¸åŒçš„èåˆæœºåˆ¶ï¼Œæ¢ç´¢äº†å°†LLMä¸å…¶ä»–æ•°æ®æ¨¡å¼ç›¸ç»“åˆã€‚è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œå³é€šè¿‡éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºå¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆä½¿ç”¨éŸ³é¢‘ç‰¹å¾æå–å™¨æå–éŸ³é¢‘ç‰¹å¾ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªå¯å­¦ä¹ çš„æ¥å£æ¨¡å—å°†è¿™äº›ç‰¹å¾æ˜ å°„åˆ°LLMçš„è¡¨ç¤ºç©ºé—´ã€‚LLMçš„è¾“å…¥åŒ…æ‹¬ï¼ˆ1ï¼‰è½¬æ¢åçš„éŸ³é¢‘ç‰¹å¾ï¼Œï¼ˆ2ï¼‰ä»¥è‡ªç„¶è¯­è¨€å½¢å¼å­˜åœ¨çš„é™„åŠ ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œæ–‡æœ¬ï¼‰ï¼Œä»¥åŠï¼ˆ3ï¼‰æè¿°æƒ…æ„Ÿé¢„æµ‹ä»»åŠ¡çš„æ–‡æœ¬æç¤ºã€‚ä¸ºäº†æœ‰æ•ˆåœ°å°†LLMé€‚åº”äºè¿™ç§å¤šæ¨¡å¼ä»»åŠ¡ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æŠ€æœ¯ï¼Œå®ç°äº†å‚æ•°é«˜æ•ˆçš„å¾®è°ƒã€‚åœ¨æ ‡å‡†æƒ…æ„Ÿè¯†åˆ«åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æ–‡çŒ®ä¸­ä»…æ¬¡äºä¸€ç§ç°æœ‰çš„è¯­éŸ³-æ–‡æœ¬LLMï¼ŒåŒæ—¶æ‰€éœ€çš„å‚æ•°å°‘äºç«äº‰å¯¹æ‰‹æ–¹æ³•çš„ä¸€åŠã€‚è¿™çªæ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•´åˆå¤šæ¨¡å¼è¾“å…¥è¿›è¡ŒåŸºäºè¯­éŸ³çš„æƒ…æ„Ÿç†è§£æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä¿æŒäº†æ˜¾è‘—çš„è®¡ç®—æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14130v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºï¼Œé€šè¿‡ç²¾ç»†è°ƒæ•´LLMæ¥è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†æƒ…æ„Ÿè¯†åˆ«åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºå¤§å¤šæ•°ç°æœ‰çš„è¯­éŸ³æ–‡æœ¬LLMï¼ŒåŒæ—¶è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æƒ…æ„Ÿè¯†åˆ«æ˜¯ä¸€é¡¹æŒ‘æˆ˜ä»»åŠ¡ï¼Œéœ€è¦æ•æ‰è¯­è¨€å’Œéè¯­è¨€çº¿ç´¢ï¼Œåœ¨äººæœºäº¤äº’å’Œå¿ƒç†å¥åº·ç›‘æµ‹ç­‰é¢†åŸŸæœ‰é‡è¦åº”ç”¨ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·å¤‡æ‰§è¡Œè‡ªç„¶è¯­è¨€é¢†åŸŸå¤–ä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆLLMå’Œå…¶ä»–æ•°æ®æ¨¡æ€çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„ä¸»å¹²ç½‘ç»œå’Œä¸åŒçš„èåˆæœºåˆ¶è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç”¨éŸ³é¢‘ç‰¹å¾æå–å™¨æå–éŸ³é¢‘ç‰¹å¾ï¼Œç„¶åé€šè¿‡å¯å­¦ä¹ çš„æ¥å£æ¨¡å—å°†è¿™äº›ç‰¹å¾æ˜ å°„åˆ°LLMçš„è¡¨ç¤ºç©ºé—´ã€‚</li>
<li>LLMæ¥å—è½¬æ¢åçš„éŸ³é¢‘ç‰¹å¾ã€ä»¥è‡ªç„¶è¯­è¨€å½¢å¼å­˜åœ¨çš„é™„åŠ ç‰¹å¾ï¼ˆå¦‚è½¬å½•ï¼‰ä»¥åŠæè¿°æƒ…æ„Ÿé¢„æµ‹ä»»åŠ¡çš„æ–‡æœ¬æç¤ºä½œä¸ºè¾“å…¥ã€‚</li>
<li>ä¸ºäº†æœ‰æ•ˆåœ°é€‚åº”å¤šæ¨¡æ€ä»»åŠ¡ï¼Œé‡‡ç”¨äº†ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æ–¹æ³•ï¼Œå®ç°äº†å‚æ•°é«˜æ•ˆçš„ç²¾ç»†è°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14130">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8aa2ea5b7f4973cf477ec0fd429bbe88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5fa9ea54fb806b8d7e455b297fc3af56.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d8c1a9c6f2f211ea9227f34b66bf1037.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction"><a href="#DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction" class="headerlink" title="DiffIER: Optimizing Diffusion Models with Iterative Error Reduction"></a>DiffIER: Optimizing Diffusion Models with Iterative Error Reduction</h2><p><strong>Authors:Ao Chen, Lihe Ding, Tianfan Xue</strong></p>
<p>Diffusion models have demonstrated remarkable capabilities in generating high-quality samples and enhancing performance across diverse domains through Classifier-Free Guidance (CFG). However, the quality of generated samples is highly sensitive to the selection of the guidance weight. In this work, we identify a critical &#96;&#96;training-inference gapâ€™â€™ and we argue that it is the presence of this gap that undermines the performance of conditional generation and renders outputs highly sensitive to the guidance weight. We quantify this gap by measuring the accumulated error during the inference stage and establish a correlation between the selection of guidance weight and minimizing this gap. Furthermore, to mitigate this gap, we propose DiffIER, an optimization-based method for high-quality generation. We demonstrate that the accumulated error can be effectively reduced by an iterative error minimization at each step during inference. By introducing this novel plug-and-play optimization framework, we enable the optimization of errors at every single inference step and enhance generation quality. Empirical results demonstrate that our proposed method outperforms baseline approaches in conditional generation tasks. Furthermore, the method achieves consistent success in text-to-image generation, image super-resolution, and text-to-speech generation, underscoring its versatility and potential for broad applications in future research. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ä»¥åŠæé«˜ä¸åŒé¢†åŸŸçš„æ€§èƒ½ä¸Šå±•ç°äº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”Ÿæˆæ ·æœ¬çš„è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºäº†ä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œæˆ‘ä»¬è®¤ä¸ºæ­£æ˜¯è¿™ä¸ªå·®è·å½±å“äº†æ¡ä»¶ç”Ÿæˆçš„æ€§èƒ½ï¼Œå¹¶å¯¼è‡´è¾“å‡ºå¯¹å¼•å¯¼æƒé‡çš„é«˜åº¦æ•æ„Ÿã€‚æˆ‘ä»¬é€šè¿‡æµ‹é‡æ¨ç†é˜¶æ®µçš„ç´¯ç§¯è¯¯å·®æ¥é‡åŒ–è¿™ä¸ªå·®è·ï¼Œå¹¶å»ºç«‹å¼•å¯¼æƒé‡çš„é€‰æ‹©ä¸æœ€å°åŒ–è¿™ä¸ªå·®è·ä¹‹é—´çš„å…³è”ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¼“è§£è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†DiffIERï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¼˜åŒ–çš„é«˜è´¨é‡ç”Ÿæˆæ–¹æ³•ã€‚æˆ‘ä»¬è¯æ˜é€šè¿‡æ¨ç†è¿‡ç¨‹ä¸­æ¯ä¸€æ­¥çš„è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘ç´¯ç§¯è¯¯å·®ã€‚é€šè¿‡å¼•å…¥è¿™ç§æ–°é¢–å³æ’å³ç”¨çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¯ä¸€ä¸ªå•ç‹¬çš„æ¨ç†æ­¥éª¤ä¸­ä¼˜åŒ–è¯¯å·®ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æ‰€æå‡ºçš„æ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸­ä¼˜äºåŸºå‡†æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆæ–¹é¢å–å¾—äº†æŒç»­çš„æˆåŠŸï¼Œçªæ˜¾äº†å…¶é€šç”¨æ€§å’Œåœ¨æœªæ¥ç ”ç©¶ä¸­å¹¿æ³›åº”ç”¨çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13628v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å’Œæå‡ä¸åŒé¢†åŸŸæ€§èƒ½æ–¹é¢çš„æ˜¾è‘—èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰å®ç°ã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„æ ·æœ¬è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚æœ¬æ–‡è¯†åˆ«å‡ºä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œå¹¶æŒ‡å‡ºè¿™ä¸€å·®è·å½±å“äº†æ¡ä»¶ç”Ÿæˆæ€§èƒ½ï¼Œä½¿è¾“å‡ºå¯¹å¼•å¯¼æƒé‡é«˜åº¦æ•æ„Ÿã€‚ä¸ºäº†é‡åŒ–è¿™ä¸€å·®è·å¹¶å‡å°‘å…¶å¯¹ç”Ÿæˆè´¨é‡çš„å½±å“ï¼Œæœ¬æ–‡æå‡ºäº†DiffIERï¼Œä¸€ç§åŸºäºä¼˜åŒ–çš„é«˜è´¨é‡ç”Ÿæˆæ–¹æ³•ã€‚é€šè¿‡è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œåœ¨æ¨ç†é˜¶æ®µçš„æ¯ä¸€æ­¥ä¼˜åŒ–è¯¯å·®ï¼Œæé«˜äº†ç”Ÿæˆè´¨é‡ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œå¹¶åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆç­‰ä»»åŠ¡ä¸­å–å¾—äº†æŒç»­çš„æˆåŠŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å¹¶æå‡ä¸åŒé¢†åŸŸæ€§èƒ½ã€‚</li>
<li>ç”Ÿæˆçš„æ ·æœ¬è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚</li>
<li>å­˜åœ¨ä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œå½±å“æ¡ä»¶ç”Ÿæˆæ€§èƒ½ã€‚</li>
<li>æœ¬æ–‡é€šè¿‡æµ‹é‡æ¨ç†é˜¶æ®µçš„ç´¯ç§¯è¯¯å·®æ¥é‡åŒ–è¿™ä¸€å·®è·ã€‚</li>
<li>æå‡ºäº†DiffIERæ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£è¯¯å·®æœ€å°åŒ–å‡å°‘ç´¯ç§¯è¯¯å·®ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚</li>
<li>DiffIERæ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13628">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6660ec06ea983b3718bb6178bb74c51f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4b930ab27e19b587a0b375e5b562d4d3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e391cf99658d7fa44fd322b3db1d0ef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7d613ceafcd367c3788f918797f75b6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-90754254ba6f2d1faf962c9d63bcf529.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="FNH-TTS-A-Fast-Natural-and-Human-Like-Speech-Synthesis-System-with-advanced-prosodic-modeling-based-on-Mixture-of-Experts"><a href="#FNH-TTS-A-Fast-Natural-and-Human-Like-Speech-Synthesis-System-with-advanced-prosodic-modeling-based-on-Mixture-of-Experts" class="headerlink" title="FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with   advanced prosodic modeling based on Mixture of Experts"></a>FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with   advanced prosodic modeling based on Mixture of Experts</h2><p><strong>Authors:Qingliang Meng, Yuqing Deng, Wei Liang, Limei Yu, Huizhi Liang, Tian Li</strong></p>
<p>Achieving natural and human-like speech synthesis with low inference costs remains a major challenge in speech synthesis research. This study focuses on human prosodic patterns and synthesized spectrum harmony, addressing the challenges of prosody modeling and artifact issues in non-autoregressive models. To enhance prosody modeling and synthesis quality, we introduce a new Duration Predictor based on the Mixture of Experts alongside a new Vocoder with two advanced multi-scale discriminators. We integrated the these new modules into the VITS system, forming our FNH-TTS system. Our experiments on LJSpeech, VCTK, and LibriTTS demonstrate the systemâ€™s superiority in synthesis quality, phoneme duration prediction, Vocoder results, and synthesis speed. Our prosody visualization results show that FNH-TTS produces duration predictions that more closely align with natural human beings than other systems. </p>
<blockquote>
<p>åœ¨è¯­éŸ³åˆæˆç ”ç©¶ä¸­ï¼Œå®ç°ä½æˆæœ¬ã€è‡ªç„¶ã€æ‹ŸäººåŒ–çš„è¯­éŸ³åˆæˆä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶å…³æ³¨äººç±»è¯­è°ƒæ¨¡å¼å’Œåˆæˆé¢‘è°±å’Œè°æ€§ï¼Œè§£å†³è¯­è°ƒå»ºæ¨¡å’Œéè‡ªå›å½’æ¨¡å‹ä¸­çš„ä¼ªå½±é—®é¢˜çš„æŒ‘æˆ˜ã€‚ä¸ºäº†å¢å¼ºè¯­è°ƒå»ºæ¨¡å’Œåˆæˆè´¨é‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºä¸“å®¶æ··åˆçš„æ–°æŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼Œä»¥åŠä¸€ç§å…·æœ‰ä¸¤ä¸ªå…ˆè¿›å¤šå°ºåº¦é‰´åˆ«å™¨çš„æ–°Vocoderã€‚æˆ‘ä»¬å°†è¿™äº›æ–°æ¨¡å—é›†æˆåˆ°VITSç³»ç»Ÿä¸­ï¼Œå½¢æˆäº†æˆ‘ä»¬çš„FNH-TTSç³»ç»Ÿã€‚æˆ‘ä»¬åœ¨LJSpeechã€VCTKå’ŒLibriTTSä¸Šçš„å®éªŒè¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨åˆæˆè´¨é‡ã€éŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹ã€Vocoderç»“æœå’Œåˆæˆé€Ÿåº¦æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬çš„è¯­è°ƒå¯è§†åŒ–ç»“æœè¡¨æ˜ï¼ŒFNH-TTSäº§ç”Ÿçš„æŒç»­æ—¶é—´é¢„æµ‹ä¸å…¶ä»–ç³»ç»Ÿç›¸æ¯”æ›´æ¥è¿‘äºè‡ªç„¶äººç±»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12001v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶å…³æ³¨äººç±»è¯­è°ƒæ¨¡å¼å’Œåˆæˆé¢‘è°±å’Œè°æ€§ï¼Œæ—¨åœ¨è§£å†³éè‡ªå›å½’æ¨¡å‹ä¸­çš„è¯­è°ƒå»ºæ¨¡å’Œäººå·¥åˆ¶å“é—®é¢˜ã€‚é€šè¿‡å¼•å…¥åŸºäºä¸“å®¶æ··åˆçš„æ–°æŒç»­æ—¶é—´é¢„æµ‹å™¨å’Œå…·æœ‰ä¸¤ä¸ªå…ˆè¿›å¤šå°ºåº¦é‰´åˆ«å™¨çš„å…¨æ–°ç¼–ç å™¨ï¼Œæé«˜äº†è¯­è°ƒå»ºæ¨¡å’Œåˆæˆè´¨é‡ã€‚é›†æˆè¿™äº›æ–°æ¨¡å—åˆ°VITSç³»ç»Ÿï¼Œå½¢æˆäº†æˆ‘ä»¬çš„FNH-TTSç³»ç»Ÿã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨åˆæˆè´¨é‡ã€éŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹ã€ç¼–ç å™¨ç»“æœå’Œåˆæˆé€Ÿåº¦æ–¹é¢å‡ä¼˜äºå…¶ä»–ç³»ç»Ÿï¼Œäº§ç”Ÿçš„æŒç»­æ—¶é—´é¢„æµ‹æ›´ç¬¦åˆè‡ªç„¶äººç±»çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å…³æ³¨è‡ªç„¶å’Œäººç±»åŒ–çš„è¯­éŸ³åˆæˆï¼Œåº”å¯¹è¯­è°ƒå»ºæ¨¡å’Œäººå·¥åˆ¶å“çš„æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥åŸºäºä¸“å®¶æ··åˆçš„æŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼Œæ”¹å–„è¯­è°ƒå»ºæ¨¡å’Œåˆæˆè´¨é‡ã€‚</li>
<li>æå‡ºæ–°å‹ç¼–ç å™¨ï¼Œé…å¤‡ä¸¤ä¸ªå…ˆè¿›çš„å¤šå°ºåº¦é‰´åˆ«å™¨ï¼Œæå‡åˆæˆæ•ˆæœã€‚</li>
<li>æ–°ç³»ç»ŸFNH-TTSé›†æˆäº†ä¸Šè¿°æ¨¡å—ï¼Œæ˜¾è‘—æé«˜åˆæˆè´¨é‡ã€éŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹å’Œåˆæˆé€Ÿåº¦ã€‚</li>
<li>åœ¨LJSpeechã€VCTKå’ŒLibriTTSä¸Šçš„å®éªŒéªŒè¯äº†FNH-TTSç³»ç»Ÿçš„ä¼˜è¶Šæ€§ã€‚</li>
<li>FNH-TTSäº§ç”Ÿçš„æŒç»­æ—¶é—´é¢„æµ‹æ›´æ¥è¿‘è‡ªç„¶äººç±»çš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12001">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-168a948c50306608d96f1e9cca0951bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07b87d647c08768811ba838a389ecb82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb8293187e68dbe3b98515438382d6fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2765146d8e9ba422ab874481d39df87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de212c5e25c77b537dc513df982ccb9a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aabfb140e32162546fd1d2ea0b491f08.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Chain-of-Correction-for-Full-text-Speech-Recognition-with-Large-Language-Models"><a href="#Chain-of-Correction-for-Full-text-Speech-Recognition-with-Large-Language-Models" class="headerlink" title="Chain of Correction for Full-text Speech Recognition with Large Language   Models"></a>Chain of Correction for Full-text Speech Recognition with Large Language   Models</h2><p><strong>Authors:Zhiyuan Tang, Dong Wang, Zhikai Zhou, Yong Liu, Shen Huang, Shidong Shang</strong></p>
<p>Full-text error correction with Large Language Models (LLMs) for Automatic Speech Recognition (ASR) is attracting increased attention for its ability to address a wide range of error types, such as punctuation restoration and inverse text normalization, across long context. However, challenges remain regarding stability, controllability, completeness, and fluency. To mitigate these issues, this paper proposes the Chain of Correction (CoC), which uses a multi-turn chat format to correct errors segment by segment, guided by pre-recognized text and full-text context for better semantic understanding. Utilizing the open-sourced ChFT dataset, we fine-tune a pre-trained LLM to evaluate CoCâ€™s performance. Experiments show that CoC significantly outperforms baseline and benchmark systems in correcting full-text ASR outputs. We also analyze correction thresholds to balance under-correction and over-rephrasing, extrapolate CoC on extra-long ASR outputs, and explore using other types of information to guide error correction. </p>
<blockquote>
<p>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„å…¨æ–‡é”™è¯¯æ ¡æ­£æ­£æ—¥ç›Šå—åˆ°å…³æ³¨ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿè§£å†³å¹¿æ³›çš„é”™è¯¯ç±»å‹ï¼Œä¾‹å¦‚æ ‡ç‚¹æ¢å¤å’Œæ–‡æœ¬é€†å‘å½’ä¸€åŒ–ç­‰ï¼Œè´¯ç©¿æ•´ä¸ªè¯­å¢ƒã€‚ç„¶è€Œï¼Œåœ¨ç¨³å®šæ€§ã€å¯æ§æ€§ã€å®Œæ•´æ€§å’Œæµç•…æ€§æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†çº é”™é“¾ï¼ˆCoCï¼‰ï¼Œå®ƒé‡‡ç”¨å¤šè½®èŠå¤©æ ¼å¼åˆ†æ®µçº é”™ï¼Œç”±é¢„å…ˆè¯†åˆ«çš„æ–‡æœ¬å’Œå…¨æ–‡ä¸Šä¸‹æ–‡å¼•å¯¼ï¼Œä»¥æ›´å¥½åœ°è¯­ä¹‰ç†è§£ã€‚æˆ‘ä»¬åˆ©ç”¨å¼€æºçš„ChFTæ•°æ®é›†å¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥è¯„ä¼°CoCçš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨çº æ­£å…¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«è¾“å‡ºæ–‡æœ¬æ–¹é¢ï¼ŒCoCæ˜¾è‘—ä¼˜äºåŸºå‡†å’ŒåŸºå‡†ç³»ç»Ÿã€‚æˆ‘ä»¬è¿˜åˆ†æäº†æ ¡æ­£é˜ˆå€¼ä»¥å¹³è¡¡æ¬ æ ¡æ­£å’Œè¿‡åº¦æ”¹è¿°ï¼Œå°†CoCå¤–æ¨åˆ°è¶…é•¿ASRè¾“å‡ºï¼Œå¹¶æ¢ç´¢ä½¿ç”¨å…¶ä»–ç±»å‹çš„ä¿¡æ¯æ¥å¼•å¯¼é”™è¯¯æ ¡æ­£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01519v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å…¨æ–‡é”™è¯¯æ ¡æ­£æŠ€æœ¯åœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰é¢†åŸŸçš„åº”ç”¨ã€‚é’ˆå¯¹ASRç»“æœä¸­å¹¿æ³›å­˜åœ¨çš„å¤šç§é”™è¯¯ç±»å‹ï¼Œå¦‚æ ‡ç‚¹æ¢å¤å’Œé€†å‘æ–‡æœ¬å½’ä¸€åŒ–ç­‰ï¼Œæå‡ºä½¿ç”¨çº é”™é“¾ï¼ˆCoCï¼‰è¿›è¡Œåˆ†æ®µçº é”™ã€‚ç»“åˆé¢„è¯†åˆ«æ–‡æœ¬å’Œå…¨æ–‡ä¸Šä¸‹æ–‡ï¼Œä»¥æé«˜è¯­ä¹‰ç†è§£ï¼Œå¹¶é€šè¿‡å¤šè½®èŠå¤©æ ¼å¼è¿›è¡Œçº é”™ã€‚é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒLLMå¹¶åœ¨ChFTæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒè¯„ä¼°ï¼Œæ˜¾ç¤ºçº é”™é“¾åœ¨çº æ­£å…¨æ–‡ASRè¾“å‡ºæ–¹é¢æ˜¾è‘—ä¼˜äºåŸºå‡†å’ŒåŸºå‡†ç³»ç»Ÿã€‚åŒæ—¶æ¢è®¨äº†ä¿®æ­£é˜ˆå€¼çš„å¹³è¡¡ã€å¯¹è¶…é•¿ASRè¾“å‡ºçš„å¤–æ¨åº”ç”¨ä»¥åŠä½¿ç”¨å…¶ä»–ä¿¡æ¯å¼•å¯¼é”™è¯¯æ ¡æ­£çš„å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”¨äºå…¨æ–‡é”™è¯¯æ ¡æ­£ï¼Œèƒ½å¤„ç†å¤šç§ASRé”™è¯¯ç±»å‹ã€‚</li>
<li>æå‡ºäº†çº é”™é“¾ï¼ˆCoCï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¤šè½®èŠå¤©æ ¼å¼åˆ†æ®µçº é”™ã€‚</li>
<li>ç»“åˆé¢„è¯†åˆ«æ–‡æœ¬å’Œå…¨æ–‡ä¸Šä¸‹æ–‡æé«˜è¯­ä¹‰ç†è§£ã€‚</li>
<li>é€šè¿‡å¯¹é¢„è®­ç»ƒLLMçš„å¾®è°ƒåŠåœ¨ChFTæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°ï¼Œæ˜¾ç¤ºCoCåœ¨çº æ­£å…¨æ–‡ASRè¾“å‡ºæ–¹é¢æ€§èƒ½ä¼˜å¼‚ã€‚</li>
<li>ç ”ç©¶äº†ä¿®æ­£é˜ˆå€¼çš„å¹³è¡¡ï¼Œä»¥é¿å…è¿‡åº¦ä¿®æ­£å’Œé‡è¿°ã€‚</li>
<li>æ¢è®¨äº†çº é”™é“¾åœ¨è¶…é•¿ASRè¾“å‡ºä¸Šçš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01519">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-44478adfe5ea93cad98ef763c0a24ec1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8b45be5bad0e52ff5774c73e51ef6e04.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-22107ab1025a7f1c79e6c5d9b2ceb0d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3285aebb35cd595608759c08a4a77aa5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b86323cc1ce949823da3ba86801527e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f431740e7e99702c1e671477742953c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-272f5c66736ba24a68adfce7a47d939b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Efficient-Long-duration-Talking-Video-Synthesis-with-Linear-Diffusion-Transformer-under-Multimodal-Guidance"><a href="#Efficient-Long-duration-Talking-Video-Synthesis-with-Linear-Diffusion-Transformer-under-Multimodal-Guidance" class="headerlink" title="Efficient Long-duration Talking Video Synthesis with Linear Diffusion   Transformer under Multimodal Guidance"></a>Efficient Long-duration Talking Video Synthesis with Linear Diffusion   Transformer under Multimodal Guidance</h2><p><strong>Authors:Haojie Zhang, Zhihao Liang, Ruibo Fu, Bingyan Liu, Zhengqi Wen, Xuefei Liu, Jianhua Tao, Yaling Liang</strong></p>
<p>Long-duration talking video synthesis faces persistent challenges in simultaneously achieving high video quality, portrait and temporal consistency, and computational efficiency. As video length increases, issues such as visual degradation, loss of identity consistency, temporal incoherence, and error accumulation become increasingly prominent, severely impacting the realism and reliability of generated results. To address these issues, we present LetsTalk, a diffusion transformer framework that incorporates multimodal guidance and a novel memory bank mechanism, explicitly maintaining contextual continuity and enabling robust, high-quality, and efficient long-duration talking video generation. Specifically, LetsTalk introduces a memory bank combined with a noise-regularized training strategy to mitigate error accumulation and sampling artifacts during long video generation. To further enhance efficiency and spatiotemporal consistency, LetsTalk employs a deep compression autoencoder and a spatiotemporal-aware transformer with linear attention for effective multimodal fusion. Furthermore, we systematically analyze three multimodal fusion schemes, adopting deep (Symbiotic Fusion) for portrait features to ensure visual consistency, and shallow (Direct Fusion) for audio to synchronize animation with speech while preserving motion diversity. Extensive experiments demonstrate that LetsTalk achieves state-of-the-art generation quality, producing temporally coherent and realistic talking videos with enhanced diversity and liveliness, while maintaining remarkable efficiency with 8 fewer parameters than previous approaches. </p>
<blockquote>
<p>é•¿æœŸå¯¹è¯è§†é¢‘åˆæˆé¢ä¸´ç€æŒç»­æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨åŒæ—¶å®ç°é«˜è´¨é‡è§†é¢‘ã€è‚–åƒå’Œæ—¶åºä¸€è‡´æ€§ä»¥åŠè®¡ç®—æ•ˆç‡æ–¹é¢ã€‚éšç€è§†é¢‘é•¿åº¦çš„å¢åŠ ï¼Œè§†è§‰å¤±çœŸã€èº«ä»½ä¸€è‡´æ€§ä¸§å¤±ã€æ—¶åºä¸ä¸€è‡´å’Œè¯¯å·®ç´¯ç§¯ç­‰é—®é¢˜å˜å¾—è¶Šæ¥è¶Šçªå‡ºï¼Œä¸¥é‡å½±å“åˆ°ç”Ÿæˆç»“æœçš„çœŸå®æ€§å’Œå¯é æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†LetsTalkï¼Œè¿™æ˜¯ä¸€ä¸ªèåˆäº†å¤šæ¨¡æ€æŒ‡å¯¼å’Œæ–°å¼å­˜å‚¨åº“æœºåˆ¶çš„æ‰©æ•£å˜å‹å™¨æ¡†æ¶ï¼Œå¯ä»¥æ˜ç¡®åœ°ä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå¹¶å®ç°ç¨³å¥ã€é«˜è´¨é‡å’Œé«˜æ•ˆçš„é•¿æœŸå¯¹è¯è§†é¢‘ç”Ÿæˆã€‚å…·ä½“æ¥è¯´ï¼ŒLetsTalkå¼•å…¥äº†ç»“åˆå™ªå£°æ­£åˆ™åŒ–è®­ç»ƒç­–ç•¥çš„å­˜å‚¨åº“ï¼Œä»¥å‡è½»é•¿è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¯¯å·®ç´¯ç§¯å’Œé‡‡æ ·ä¼ªå½±ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ•ˆç‡å’Œæ—¶ç©ºä¸€è‡´æ€§ï¼ŒLetsTalké‡‡ç”¨æ·±åº¦å‹ç¼©è‡ªç¼–ç å™¨å’Œå…·æœ‰çº¿æ€§æ³¨æ„åŠ›çš„æ—¶ç©ºæ„ŸçŸ¥å˜å‹å™¨ï¼Œä»¥å®ç°æœ‰æ•ˆçš„å¤šæ¨¡æ€èåˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†ä¸‰ç§å¤šæ¨¡æ€èåˆæ–¹æ¡ˆï¼Œé‡‡ç”¨æ·±åº¦ï¼ˆå…±ç”Ÿèåˆï¼‰ç”¨äºè‚–åƒç‰¹å¾ä»¥ç¡®ä¿è§†è§‰ä¸€è‡´æ€§ï¼Œä»¥åŠæµ…å±‚ï¼ˆç›´æ¥èåˆï¼‰ç”¨äºéŸ³é¢‘ï¼Œä»¥åŒæ­¥åŠ¨ç”»å’Œè¯­éŸ³åŒæ—¶ä¿æŒåŠ¨ä½œå¤šæ ·æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLetsTalkè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç”Ÿæˆè´¨é‡ï¼Œäº§ç”Ÿäº†æ—¶åºä¸€è‡´å’Œé€¼çœŸçš„å¯¹è¯è§†é¢‘ï¼Œå…·æœ‰å¢å¼ºçš„å¤šæ ·æ€§å’Œç”ŸåŠ¨æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å“è¶Šçš„æ•ˆç‡ï¼Œæ¯”ä»¥å‰çš„æ–¹æ³•å°‘äº†8ä¸ªå‚æ•°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16748v3">PDF</a> 13 pages, 11 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ‘˜è¦ä»‹ç»äº†é•¿æœŸå¯¹è¯è§†é¢‘åˆæˆé¢ä¸´çš„æŒ‘æˆ˜ä»¥åŠåº”å¯¹æ–¹æ¡ˆã€‚ä¸ºäº†è§£å†³é«˜è´¨é‡è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è§†è§‰å¤±çœŸã€èº«ä»½ä¸€è‡´æ€§ä¸§å¤±ã€æ—¶é—´ä¸ä¸€è‡´å’Œè¯¯å·®ç´¯ç§¯ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLetsTalkçš„æ‰©æ•£å˜æ¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å¤šæ¨¡å¼æŒ‡å¯¼å’Œæ–°å‹è®°å¿†åº“æœºåˆ¶ï¼Œæ˜¾å¼ç»´æŠ¤ä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå®ç°ç¨³å¥ã€é«˜æ•ˆã€é«˜è´¨é‡çš„é•¿æ—¶å¯¹è¯è§†é¢‘ç”Ÿæˆã€‚å®éªŒè¯æ˜ï¼ŒLetsTalkè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç”Ÿæˆè´¨é‡ï¼Œç”Ÿæˆçš„å¯¹è¯è§†é¢‘å…·æœ‰æ—¶é—´è¿è´¯æ€§å’Œé€¼çœŸåº¦ï¼ŒåŒæ—¶ä¿æŒäº†å‡ºè‰²çš„æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é•¿æœŸå¯¹è¯è§†é¢‘åˆæˆé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚é«˜è§†é¢‘è´¨é‡ã€è‚–åƒå’Œæ—¶é—´ä¸€è‡´æ€§ä»¥åŠè®¡ç®—æ•ˆç‡çš„å¹³è¡¡ã€‚</li>
<li>æå‡ºçš„LetsTalkæ¡†æ¶ç»“åˆäº†å¤šæ¨¡å¼æŒ‡å¯¼å’Œæ–°å‹è®°å¿†åº“æœºåˆ¶ï¼Œä»¥æ”¹å–„è§†é¢‘ç”Ÿæˆçš„è´¨é‡ã€‚</li>
<li>è®°å¿†åº“å’Œå™ªå£°æ­£åˆ™åŒ–è®­ç»ƒç­–ç•¥æœ‰åŠ©äºå‡å°‘é•¿è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¯¯å·®ç´¯ç§¯å’Œé‡‡æ ·ä¼ªå½±ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨æ·±åº¦å‹ç¼©è‡ªç¼–ç å™¨å’Œæ—¶ç©ºæ„ŸçŸ¥å˜å‹å™¨æ¥æé«˜æ•ˆç‡å’Œæ—¶ç©ºä¸€è‡´æ€§ã€‚</li>
<li>ä¸‰ç§å¤šæ¨¡å¼èåˆæ–¹æ¡ˆçš„ç³»ç»Ÿåˆ†ææ˜¾ç¤ºï¼Œæ·±åº¦èåˆé€‚ç”¨äºè‚–åƒç‰¹å¾ä»¥ç¡®ä¿è§†è§‰ä¸€è‡´æ€§ï¼Œè€Œæµ…å±‚èåˆé€‚ç”¨äºéŸ³é¢‘ä»¥åŒæ­¥åŠ¨ç”»å’Œè¯­éŸ³åŒæ—¶ä¿æŒåŠ¨ä½œå¤šæ ·æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒLetsTalkè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç”Ÿæˆè´¨é‡ï¼Œèƒ½ç”Ÿæˆè¿è´¯ä¸”é€¼çœŸçš„å¯¹è¯è§†é¢‘ï¼Œå¹¶ç»´æŒäº†é«˜æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16748">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-83da51ef2b1f2b33c159f26aef652621.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b91bb4576cd59b464355cd42bfec6ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b13075fe4e5ce0b42710f35872f6837.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd95dd4599784188400d201fe070de8c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4dadaeb1284a27cfb99f761cd4d22539.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-22/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-22/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-22/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0afc402e0563d5c0e25c3f0b8adc57cb.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-22  SATURN Autoregressive Image Generation Guided by Scene Graphs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-22/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-959c18ee7150880fafd8a27458b37532.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-22  Multi-Rationale Explainable Object Recognition via Contrastive   Conditional Inference
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30055.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
