<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-08-12  Mixture of Experts Guided by Gaussian Splatters Matters A new Approach   to Weakly-Supervised Video Anomaly Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-c6b78c55e15657a70e80f51755e89712.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    27 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-12-更新"><a href="#2025-08-12-更新" class="headerlink" title="2025-08-12 更新"></a>2025-08-12 更新</h1><h2 id="Mixture-of-Experts-Guided-by-Gaussian-Splatters-Matters-A-new-Approach-to-Weakly-Supervised-Video-Anomaly-Detection"><a href="#Mixture-of-Experts-Guided-by-Gaussian-Splatters-Matters-A-new-Approach-to-Weakly-Supervised-Video-Anomaly-Detection" class="headerlink" title="Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach   to Weakly-Supervised Video Anomaly Detection"></a>Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach   to Weakly-Supervised Video Anomaly Detection</h2><p><strong>Authors:Giacomo D’Amicantonio, Snehashis Majhi, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, François Bremond, Egor Bondarev</strong></p>
<p>Video Anomaly Detection (VAD) is a challenging task due to the variability of anomalous events and the limited availability of labeled data. Under the Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided during training, while predictions are made at the frame level. Although state-of-the-art models perform well on simple anomalies (e.g., explosions), they struggle with complex real-world events (e.g., shoplifting). This difficulty stems from two key issues: (1) the inability of current models to address the diversity of anomaly types, as they process all categories with a shared model, overlooking category-specific features; and (2) the weak supervision signal, which lacks precise temporal information, limiting the ability to capture nuanced anomalous patterns blended with normal events. To address these challenges, we propose Gaussian Splatting-guided Mixture of Experts (GS-MoE), a novel framework that employs a set of expert models, each specialized in capturing specific anomaly types. These experts are guided by a temporal Gaussian splatting loss, enabling the model to leverage temporal consistency and enhance weak supervision. The Gaussian splatting approach encourages a more precise and comprehensive representation of anomalies by focusing on temporal segments most likely to contain abnormal events. The predictions from these specialized experts are integrated through a mixture-of-experts mechanism to model complex relationships across diverse anomaly patterns. Our approach achieves state-of-the-art performance, with a 91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on XD-Violence and MSAD datasets. By leveraging category-specific expertise and temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision. </p>
<blockquote>
<p>视频异常检测（VAD）是一项具有挑战性的任务，因为异常事件的多样性和标注数据的有限性。在弱监督VAD（WSVAD）模式下，训练时仅提供视频级别的标签，而预测则在帧级别进行。虽然最先进的模型在简单异常（例如爆炸）方面表现良好，但在复杂现实世界事件（例如行窃）方面却表现困难。这种困难源于两个关键问题：（1）当前模型无法处理异常类型的多样性，因为它们使用共享模型处理所有类别，忽略了特定类别的特征；（2）弱监督信号缺乏精确的时间信息，限制了捕捉与正常事件混合的微妙异常模式的能力。为了解决这些挑战，我们提出了高斯涂抹引导混合专家（GS-MoE），这是一种新型框架，采用一组专家模型，每个模型专门用于捕获特定的异常类型。这些专家由时间高斯涂抹损失引导，使模型能够利用时间一致性并增强弱监督。高斯涂抹方法通过关注最可能包含异常事件的时间段，鼓励对异常进行更精确和全面的表示。这些专业专家的预测通过混合专家机制进行集成，以模拟不同异常模式之间的复杂关系。我们的方法在UCF-Crime数据集上实现了91.58％的AUC，并在XD-Violence和MSAD数据集上展示了优越的结果。通过利用特定类别的专业知识和时间指导，GS-MoE为弱监督下的VAD设定了新的基准。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06318v1">PDF</a> </p>
<p><strong>Summary</strong><br>     弱监督视频异常检测（WSVAD）面临多样异常事件和标签数据有限的挑战。现有模型在处理简单异常事件（如爆炸）时表现良好，但在处理复杂真实事件（如店内行窃）时遇到困难。为应对挑战，提出高斯溅射引导混合专家（GS-MoE）框架，采用一系列专家模型，每个模型专门捕捉特定异常类型。这些专家受时间高斯溅射损失的引导，提高捕捉微妙异常模式的能力。GS-MoE在UCF-Crime数据集上取得了91.58%的AUC，并在XD-Violence和MSAD数据集上展现出卓越结果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VAD任务因异常事件的多样性和标签数据的有限性而具有挑战性。</li>
<li>当前模型在处理复杂真实世界的异常事件时遇到困难，主要原因是无法处理异常类型的多样性和弱监督信号的缺乏。</li>
<li>GS-MoE框架采用一系列专家模型，每个模型专门捕捉特定异常类型，解决了上述问题。</li>
<li>专家模型受时间高斯溅射损失的引导，利用时间一致性提高模型的性能。</li>
<li>高斯溅射方法鼓励更精确和全面的异常表示，专注于最可能包含异常事件的临时片段。</li>
<li>GS-MoE通过混合专家机制的预测建模了各种异常模式的复杂关系。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06318">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-61e219162894c648e3087b6847791206.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f32aa06c82e14775232209e3920bdfcf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-39a804251b454ae49d8e8d5e1bd6ff43.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8272d837b5a8381de5caa3d891f56972.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ece160222e3d6cf9c4377a3468c87200.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fdd674f0095f688e92b9764afafb4a6.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Roll-Your-Eyes-Gaze-Redirection-via-Explicit-3D-Eyeball-Rotation"><a href="#Roll-Your-Eyes-Gaze-Redirection-via-Explicit-3D-Eyeball-Rotation" class="headerlink" title="Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation"></a>Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation</h2><p><strong>Authors:YoungChan Choi, HengFei Wang, YiHua Cheng, Boeun Kim, Hyung Jin Chang, YoungGeun Choi, Sang-Il Choi</strong></p>
<p>We propose a novel 3D gaze redirection framework that leverages an explicit 3D eyeball structure. Existing gaze redirection methods are typically based on neural radiance fields, which employ implicit neural representations via volume rendering. Unlike these NeRF-based approaches, where the rotation and translation of 3D representations are not explicitly modeled, we introduce a dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian Splatting (3DGS). Our method generates photorealistic images that faithfully reproduce the desired gaze direction by explicitly rotating and translating the 3D eyeball structure. In addition, we propose an adaptive deformation module that enables the replication of subtle muscle movements around the eyes. Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our framework is capable of generating diverse novel gaze images, achieving superior image quality and gaze estimation accuracy compared to previous state-of-the-art methods. </p>
<blockquote>
<p>我们提出了一种新型的3D眼神重定向框架，该框架利用明确的3D眼球结构。现有的眼神重定向方法通常基于神经辐射场，通过体积渲染采用隐式神经表示。与这些基于NeRF的方法不同，后者没有明确地建模3D表示的旋转和平移，我们引入了一个专门的3D眼球结构，使用3D高斯拼贴（3DGS）来表示眼球。我们的方法可以生成逼真的图像，通过明确地旋转和平移3D眼球结构，忠实地再现所需的眼神方向。此外，我们提出了一种自适应变形模块，能够实现眼睛周围微妙肌肉运动的复制。我们在ETH-XGaze数据集上进行的实验表明，我们的框架能够生成多种新颖的眼神图像，与现有最先进的方法相比，图像质量和眼神估计准确性更高。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06136v1">PDF</a> 9 pages, 5 figures, ACM Multimeida 2025 accepted</p>
<p><strong>摘要</strong></p>
<p>本文提出了一种新型的3D视线重定向框架，该框架利用明确的3D眼球结构。现有视线重定向方法通常基于神经辐射场，采用隐式神经表示和体积渲染技术。与这些基于NeRF的方法不同，我们的方法引入了专门的3D眼球结构来表示眼球，采用3D高斯喷绘技术（3DGS）。该方法可生成逼真的图像，通过明确旋转和翻译3D眼球结构来忠实再现期望的视线方向。此外，还提出了一种自适应变形模块，能够复制眼睛周围肌肉的细微运动。在ETH-XGaze数据集上进行的实验表明，我们的框架能够生成多样化的新型视线图像，与现有最先进的方法相比，图像质量和视线估计准确性更高。</p>
<p><strong>要点掌握</strong></p>
<ol>
<li>引入了一种新型的3D视线重定向框架，该框架利用明确的3D眼球结构。</li>
<li>与基于NeRF的方法不同，该框架采用3D高斯喷绘技术（3DGS）表示眼球。</li>
<li>该方法可以生成逼真的图像，并通过明确旋转和翻译3D眼球结构来展现视线方向。</li>
<li>提出了一种自适应变形模块，可以复制眼睛周围肌肉的细微运动。</li>
<li>在ETH-XGaze数据集上进行了实验验证，生成了多样化的新型视线图像。</li>
<li>与现有方法相比，该框架在图像质量和视线估计准确性方面表现更优。</li>
<li>该研究为视线重定向领域提供了一种新的、高效的方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06136">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-db666bc8b12ba0ce79fb3f02858e6347.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f69f1399f3fe648a56e7d18c8c299852.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f863d595945e219379efba0fd84c7e0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ExploreGS-Explorable-3D-Scene-Reconstruction-with-Virtual-Camera-Samplings-and-Diffusion-Priors"><a href="#ExploreGS-Explorable-3D-Scene-Reconstruction-with-Virtual-Camera-Samplings-and-Diffusion-Priors" class="headerlink" title="ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera   Samplings and Diffusion Priors"></a>ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera   Samplings and Diffusion Priors</h2><p><strong>Authors:Minsu Kim, Subin Jeon, In Cho, Mijin Yoo, Seon Joo Kim</strong></p>
<p>Recent advances in novel view synthesis (NVS) have enabled real-time rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle with artifacts and missing regions when rendering from viewpoints that deviate from the training trajectory, limiting seamless scene exploration. To address this, we propose a 3DGS-based pipeline that generates additional training views to enhance reconstruction. We introduce an information-gain-driven virtual camera placement strategy to maximize scene coverage, followed by video diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with these enhanced views significantly improves reconstruction quality. To evaluate our method, we present Wild-Explore, a benchmark designed for challenging scene exploration. Experiments demonstrate that our approach outperforms existing 3DGS-based methods, enabling high-quality, artifact-free rendering from arbitrary viewpoints.   <a target="_blank" rel="noopener" href="https://exploregs.github.io/">https://exploregs.github.io</a> </p>
<blockquote>
<p>近期新型视图合成（NVS）的进展已经实现了使用3D高斯拼贴（3DGS）进行实时渲染。然而，当从偏离训练轨迹的视角进行渲染时，现有方法往往会出现伪影和缺失区域，限制了无缝场景的探索。为了解决这一问题，我们提出了一种基于3DGS的管道，通过生成额外的训练视图来提高重建效果。我们引入了一种以信息增益驱动的虚拟相机放置策略，以最大化场景覆盖，然后利用视频扩散先验来优化渲染结果。使用这些增强视图对3D高斯进行微调，可以显著提高重建质量。为了评估我们的方法，我们推出了Wild-Explore，这是一个为具有挑战性的场景探索而设计的基准测试。实验表明，我们的方法优于现有的基于3DGS的方法，能够实现从任意视角进行的高质量、无伪影渲染。想了解更多信息请访问：[<a target="_blank" rel="noopener" href="https://exploregs.github.io/]">https://exploregs.github.io/]</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06014v1">PDF</a> 10 pages, 6 Figures, ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于实时渲染技术的最新进展，使用三维高斯映射（3DGS）合成新的视角。文章提出了一种基于信息增益驱动的虚拟相机放置策略来最大化场景覆盖，并使用视频扩散先验技术改进渲染结果。该研究设计了一个名为Wild-Explore的基准测试平台，用于评估场景探索的挑战性。实验证明，该方法在任意视角的渲染质量上优于现有的三维高斯映射方法，能够实现高质量、无瑕疵的渲染。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>新视角合成技术结合三维高斯映射（3DGS）实现了实时渲染。</li>
<li>提出了一种基于信息增益驱动的虚拟相机放置策略，以最大化场景覆盖。</li>
<li>采用视频扩散先验技术改进了渲染结果。</li>
<li>设计了名为Wild-Explore的基准测试平台，用于评估场景探索的挑战性。</li>
<li>方法在任意视角的渲染质量上超越了现有的三维高斯映射方法。</li>
<li>实现的高质量渲染无显著瑕疵。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06014">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-267816a0c01fb4920a5a7b1e88708357.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5141b73b2f96dbc4d01421e67ef3ddd8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-065ce75a88814470eb2e2833ca7d0fbf.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-3DGS-Diffusion-Self-Supervised-Framework-for-Normal-Estimation-from-a-Single-Image"><a href="#A-3DGS-Diffusion-Self-Supervised-Framework-for-Normal-Estimation-from-a-Single-Image" class="headerlink" title="A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a   Single Image"></a>A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a   Single Image</h2><p><strong>Authors:Yanxing Liang, Yinghui Wang, Jinlong Yang, Wei Li</strong></p>
<p>The lack of spatial dimensional information remains a challenge in normal estimation from a single image. Recent diffusion-based methods have demonstrated significant potential in 2D-to-3D implicit mapping, they rely on data-driven statistical priors and miss the explicit modeling of light-surface interaction, leading to multi-view normal direction conflicts. Moreover, the discrete sampling mechanism of diffusion models causes gradient discontinuity in differentiable rendering reconstruction modules, preventing 3D geometric errors from being backpropagated to the normal generation network, thereby forcing existing methods to depend on dense normal annotations. This paper proposes SINGAD, a novel Self-supervised framework from a single Image for Normal estimation via 3D GAussian splatting guided Diffusion. By integrating physics-driven light-interaction modeling and a differentiable rendering-based reprojection strategy, our framework directly converts 3D geometric errors into normal optimization signals, solving the challenges of multi-view geometric inconsistency and data dependency. Specifically, the framework constructs a light-interaction-driven 3DGS reparameterization model to generate multi-scale geometric features consistent with light transport principles, ensuring multi-view normal consistency. A cross-domain feature fusion module is designed within a conditional diffusion model, embedding geometric priors to constrain normal generation while maintaining accurate geometric error propagation. Furthermore, a differentiable 3D reprojection loss strategy is introduced for self-supervised optimization that minimizes geometric error between the reconstructed and input image, eliminating dependence on annotated normal datasets. Quantitative evaluations on the Google Scanned Objects dataset demonstrate that our method outperforms state-of-the-art approaches across multiple metrics. </p>
<blockquote>
<p>缺乏空间维度信息仍然是单图像正常估计中的一个挑战。最近的基于扩散的方法在二维到三维隐式映射方面显示出巨大潜力，但它们依赖于数据驱动的统计先验，并忽略了光面交互的显式建模，从而导致多视角法线方向冲突。此外，扩散模型的离散采样机制导致可微分渲染重建模块中的梯度不连续，阻止三维几何误差反向传播到法线生成网络，从而迫使现有方法依赖于密集法线注释。本文提出了SINGAD，一种新型的自监督框架，用于通过三维高斯拼贴引导扩散从单图像进行法线估计。通过集成物理驱动的光交互建模和基于可微分渲染的重投影策略，我们的框架直接将三维几何误差转换为法线优化信号，解决了多视角几何不一致和数据依赖性的挑战。具体来说，该框架构建了一个由光交互驱动的3DGS重参数化模型，以生成符合光传输原理的多尺度几何特征，确保多视角法线一致性。在条件扩散模型中设计了一个跨域特征融合模块，嵌入几何先验以约束法线生成，同时保持准确的几何误差传播。此外，引入了一种可微分的三维重投影损失策略进行自监督优化，最小化重建图像与输入图像之间的几何误差，消除对注释法线数据集的依赖。在Google扫描对象数据集上的定量评估表明，我们的方法在多个指标上优于最新方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05950v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于单图像的自监督框架SINGAD，用于法线估计。该框架结合了物理驱动的光交互建模和基于可微分渲染的重投影策略，解决了多视角几何不一致性和数据依赖性问题。通过构建光交互驱动的3DGS重参数化模型，实现多尺度几何特征的一致性生成，确保多视角法线一致性。在Google扫描物体数据集上的定量评估表明，该方法优于其他最新技术方法。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>提出了新型自监督框架SINGAD用于单图像法线估计。</li>
<li>结合物理驱动的光交互建模和可微分渲染的重投影策略，解决多视角几何不一致性和数据依赖问题。</li>
<li>通过构建光交互驱动的3DGS重参数化模型，生成与光传输原理一致的多尺度几何特征。</li>
<li>设计了跨域特征融合模块，在条件扩散模型中嵌入几何先验以约束法线生成，同时保持准确的几何误差传播。</li>
<li>引入可微分的3D重投影损失策略进行自监督优化，减少了重建图像与输入图像之间的几何误差。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05950">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7a075fd21a3e5b1aee131743f0a96da3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-004a80adc803ad4d448b863f0992b795.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Optimization-Free-Style-Transfer-for-3D-Gaussian-Splats"><a href="#Optimization-Free-Style-Transfer-for-3D-Gaussian-Splats" class="headerlink" title="Optimization-Free Style Transfer for 3D Gaussian Splats"></a>Optimization-Free Style Transfer for 3D Gaussian Splats</h2><p><strong>Authors:Raphael Du Sablon, David Hart</strong></p>
<p>The task of style transfer for 3D Gaussian splats has been explored in many previous works, but these require reconstructing or fine-tuning the splat while incorporating style information or optimizing a feature extraction network on the splat representation. We propose a reconstruction- and optimization-free approach to stylizing 3D Gaussian splats. This is done by generating a graph structure across the implicit surface of the splat representation. A feed-forward, surface-based stylization method is then used and interpolated back to the individual splats in the scene. This allows for any style image and 3D Gaussian splat to be used without any additional training or optimization. This also allows for fast stylization of splats, achieving speeds under 2 minutes even on consumer-grade hardware. We demonstrate the quality results this approach achieves and compare to other 3D Gaussian splat style transfer methods. Code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/davidmhart/FastSplatStyler">https://github.com/davidmhart/FastSplatStyler</a>. </p>
<blockquote>
<p>关于3D高斯斑点（splat）的风格转换任务，在之前的研究中已经进行了许多探索，但这些研究要求在融入风格信息的同时重建或微调斑点，或者在斑点表示上优化特征提取网络。我们提出了一种无需重建和优化的3D高斯斑点风格化方法。这是通过在斑点的隐式表面之间生成图形结构来实现的。然后，使用前馈、基于表面的风格化方法，并将其插值回场景中的各个斑点。这使得任何风格图像和3D高斯斑点都可以使用，无需任何额外的训练或优化。这也允许快速地对斑点进行风格化，即使在消费级硬件上也能达到低于2分钟的速度。我们展示了这种方法所达到的高质量结果，并将其与其他3D高斯斑点风格转换方法进行了比较。代码可在<a target="_blank" rel="noopener" href="https://github.com/davidmhart/FastSplatStyler%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/davidmhart/FastSplatStyler公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05813v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种无需重建和优化，基于图结构和表面样式的快速三维高斯样条风格化方法。该方法生成样条表示隐表面的图结构，使用前馈表面样式化方法，并插值回场景中的各个样条。这种方法可以适用于任意风格图像和三维高斯样条，无需额外训练或优化，具有快速风格化样条的能力，甚至能在消费级硬件上实现两分钟内完成。本文展示了此方法的结果质量，并与其它三维高斯样条风格迁移方法进行了比较。代码已公开在GitHub上。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种新的三维高斯样条风格化方法，无需重建和优化。</li>
<li>通过生成样条隐表面的图结构来实现样式化。</li>
<li>使用前馈表面样式化方法，并插值回场景中的各个样条。</li>
<li>适用于任意风格图像和三维高斯样条，具有广泛适用性。</li>
<li>无需额外训练或优化，具有快速风格化样条的能力。</li>
<li>在消费级硬件上实现两分钟内完成风格化，具有实际应用价值。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05813">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bb26f062a7035f7f2a02fb2ee714d2dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf97629de18076f333a8989238796587.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4796b5be2228afe6206555691f402a0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48ac0cac6f36f98abc156c1aca5b7e36.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f2bc07cb73670f8c29ccbd760ad397b0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CF3-Compact-and-Fast-3D-Feature-Fields"><a href="#CF3-Compact-and-Fast-3D-Feature-Fields" class="headerlink" title="CF3: Compact and Fast 3D Feature Fields"></a>CF3: Compact and Fast 3D Feature Fields</h2><p><strong>Authors:Hyunjoon Lee, Joonkyu Min, Jaesik Park</strong></p>
<p>3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D foundation models. However, most approaches rely on a bottom-up optimization process that treats raw 2D features as ground truth, incurring increased computational costs. We propose a top-down pipeline for constructing compact and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast weighted fusion of multi-view 2D features with pre-trained Gaussians. This approach enables training a per-Gaussian autoencoder directly on the lifted features, instead of training autoencoders in the 2D domain. As a result, the autoencoder better aligns with the feature distribution. More importantly, we introduce an adaptive sparsification method that optimizes the Gaussian attributes of the feature field while pruning and merging the redundant Gaussians, constructing an efficient representation with preserved geometric details. Our approach achieves a competitive 3D feature field using as little as 5% of the Gaussians compared to Feature-3DGS. </p>
<blockquote>
<p>3D高斯展开技术（3DGS）已经开始融合来自二维基础模型的丰富信息。然而，大多数方法依赖于自下而上的优化过程，将原始二维特征视为真实依据，导致计算成本增加。我们提出了一种自上而下的构建紧凑快速的3D高斯特征场流水线，称为CF3。我们首先使用预训练的高斯对多视角二维特征进行快速加权融合。这种方法允许直接在提取的特征上训练高斯自编码器，而不是在二维域中训练自编码器。因此，自编码器与特征分布更加匹配。更重要的是，我们引入了一种自适应稀疏化方法，该方法在剔除和合并冗余高斯的同时优化特征场的高斯属性，从而构建了保留几何细节的有效表示。我们的方法仅使用高斯数的5%，便构建了具有竞争力的三维特征场，相较于Feature-3DGS有所超越。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05254v2">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>3DGS开始融合来自二维基础模型的丰富信息。然而，大多数方法采用自下而上的优化过程，将原始二维特征视为真实值，增加了计算成本。本文提出了一种构建紧凑快速的3D高斯特征场的自上而下方法——CF3。通过快速加权融合多维度的二维特征与预训练的高斯模型，可以直接在提取的特征上训练单个高斯自动编码器，使自动编码器更好地适应特征分布。更重要的是，引入了一种自适应稀疏化方法，在优化特征场的高斯属性的同时删除并合并冗余的高斯模型，构建了一个具有保留几何细节的高效表示。与Feature-3DGS相比，该方法仅使用5%的高斯即可实现具有竞争力的三维特征场。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS开始融合二维基础模型的丰富信息以提升性能。</li>
<li>现有方法多采用自下而上的优化过程，导致计算成本较高。</li>
<li>提出了一种新的自上而下构建高效三维高斯特征场的方法——CF3。</li>
<li>通过快速加权融合多维度的二维特征与预训练的高斯模型，直接训练高斯自动编码器。</li>
<li>引入自适应稀疏化方法，优化特征场的高斯属性并删除冗余高斯模型。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05254">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-6427c099cf299259130f75228add071c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c341ffeddc7c87f0fcd8450a2024e39.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f1a44a443dbd154b23d0222fb4c7865.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50ffd272e1efeb95596ff3470d57589e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d8d462d95d6e0dcde2e01f737af5d8f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19e4c8492a5e76b7cffa6cc499304124.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MBA-SLAM-Motion-Blur-Aware-Gaussian-Splatting-SLAM"><a href="#MBA-SLAM-Motion-Blur-Aware-Gaussian-Splatting-SLAM" class="headerlink" title="MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM"></a>MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM</h2><p><strong>Authors:Peng Wang, Lingzhe Zhao, Yin Zhang, Shiyu Zhao, Peidong Liu</strong></p>
<p>Emerging 3D scene representations, such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have demonstrated their effectiveness in Simultaneous Localization and Mapping (SLAM) for photo-realistic rendering, particularly when using high-quality video sequences as input. However, existing methods struggle with motion-blurred frames, which are common in real-world scenarios like low-light or long-exposure conditions. This often results in a significant reduction in both camera localization accuracy and map reconstruction quality. To address this challenge, we propose a dense visual deblur SLAM pipeline (i.e. MBA-SLAM) to handle severe motion-blurred inputs and enhance image deblurring. Our approach integrates an efficient motion blur-aware tracker with either neural radiance fields or Gaussian Splatting based mapper. By accurately modeling the physical image formation process of motion-blurred images, our method simultaneously learns 3D scene representation and estimates the cameras’ local trajectory during exposure time, enabling proactive compensation for motion blur caused by camera movement. In our experiments, we demonstrate that MBA-SLAM surpasses previous state-of-the-art methods in both camera localization and map reconstruction, showcasing superior performance across a range of datasets, including synthetic and real datasets featuring sharp images as well as those affected by motion blur, highlighting the versatility and robustness of our approach. Code is available at <a target="_blank" rel="noopener" href="https://github.com/WU-CVGL/MBA-SLAM">https://github.com/WU-CVGL/MBA-SLAM</a>. </p>
<blockquote>
<p>新兴的3D场景表示方法，如神经辐射场（NeRF）和3D高斯拼贴（3DGS），在用于照片级真实渲染的同时定位和地图绘制（SLAM）中已经表现出了其有效性，特别是在使用高质量视频序列作为输入时。然而，现有方法在处理运动模糊帧时面临困难，这在现实世界场景中很常见，例如在低光或长时间曝光条件下。这通常会导致相机定位精度和地图重建质量的显著降低。为了应对这一挑战，我们提出了一种密集的视觉去模糊SLAM管道（即MBA-SLAM），以处理严重的运动模糊输入并增强图像去模糊。我们的方法将高效的动态模糊感知跟踪器与基于神经辐射场或高斯拼贴的映射器相结合。通过精确建模运动模糊图像的物理成像过程，我们的方法同时学习3D场景表示并在曝光期间估计相机的局部轨迹，从而能够对由相机移动造成的运动模糊进行积极补偿。在我们的实验中，我们证明了MBA-SLAM在相机定位和地图重建方面都超越了之前的最先进方法，展示了我们方法在多个数据集上的卓越性能，包括合成数据集和受运动模糊影响的数据集，突出了我们的方法的通用性和稳健性。代码可在<a target="_blank" rel="noopener" href="https://github.com/WU-CVGL/MBA-SLAM%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/WU-CVGL/MBA-SLAM找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.08279v2">PDF</a> Accepted to TPAMI; Deblur Gaussian Splatting SLAM</p>
<p><strong>Summary</strong></p>
<p>本文提出一种针对运动模糊输入的密集视觉去模糊SLAM管道（MBA-SLAM），该管道能够有效处理新兴的三维场景表示技术，如神经辐射场和三维高斯喷绘，在同步定位与地图构建（SLAM）中的运动模糊问题。MBA-SLAM通过准确建模运动模糊图像的物理成像过程，同时学习三维场景表示并估计相机在曝光期间的局部轨迹，以主动补偿由相机移动引起的运动模糊。实验表明，MBA-SLAM在相机定位和地图构建方面超越了现有技术，并在多个数据集上表现出卓越性能。</p>
<p><strong>Key Takeaways</strong></p>
<p>1.新兴三维场景表示技术如Neural Radiance Fields和3D Gaussian Splatting在SLAM中的光栅化渲染方面表现出效果。<br>2.现有方法在处理运动模糊帧时存在困难，这在低光或长时间曝光等现实场景中很常见。<br>3.MBA-SLAM被提出以解决运动模糊输入的处理问题，它整合了一个高效的动态模糊感知追踪器。<br>4.MBA-SLAM能够同时学习三维场景表示并估计相机在曝光期间的局部轨迹，以主动补偿运动模糊。<br>5.MBA-SLAM在相机定位和地图构建方面超越了现有技术，并在多个数据集上展示优越性能。<br>6.MBA-SLAM方法具有通用性和稳健性。</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.08279">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-848bf4c883a0e12fb19b625235cc6de4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b43775887b1510dc6b9c01a2783e832d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c6b78c55e15657a70e80f51755e89712.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04856c5854892b57d72aa71a8848b702.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-12/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-12/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-12/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-944d853beef8f5d8d6e55cbcdaba8dd0.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-08-12  Roll Your Eyes Gaze Redirection via Explicit 3D Eyeball Rotation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-12/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-dae2068346be72f0e9500126a0e81124.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 方向最新论文已更新，请持续关注 Update in 2025-08-12  MotionSwap
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27544.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
