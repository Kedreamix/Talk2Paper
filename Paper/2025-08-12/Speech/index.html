<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech 方向最新论文已更新，请持续关注 Update in 2025-08-12  Robust Target Speaker Diarization and Separation via Augmented Speaker   Embedding Sampling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ee6a1419be5b9d73d4f1a8494ed8bea2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-12-更新"><a href="#2025-08-12-更新" class="headerlink" title="2025-08-12 更新"></a>2025-08-12 更新</h1><h2 id="Robust-Target-Speaker-Diarization-and-Separation-via-Augmented-Speaker-Embedding-Sampling"><a href="#Robust-Target-Speaker-Diarization-and-Separation-via-Augmented-Speaker-Embedding-Sampling" class="headerlink" title="Robust Target Speaker Diarization and Separation via Augmented Speaker   Embedding Sampling"></a>Robust Target Speaker Diarization and Separation via Augmented Speaker   Embedding Sampling</h2><p><strong>Authors:Md Asif Jalal, Luca Remaggi, Vasileios Moschopoulos, Thanasis Kotsiopoulos, Vandana Rajan, Karthikeyan Saravanan, Anastasis Drosou, Junho Heo, Hyuk Oh, Seokyeong Jeong</strong></p>
<p>Traditional speech separation and speaker diarization approaches rely on prior knowledge of target speakers or a predetermined number of participants in audio signals. To address these limitations, recent advances focus on developing enrollment-free methods capable of identifying targets without explicit speaker labeling. This work introduces a new approach to train simultaneous speech separation and diarization using automatic identification of target speaker embeddings, within mixtures. Our proposed model employs a dual-stage training pipeline designed to learn robust speaker representation features that are resilient to background noise interference. Furthermore, we present an overlapping spectral loss function specifically tailored for enhancing diarization accuracy during overlapped speech frames. Experimental results show significant performance gains compared to the current SOTA baseline, achieving 71% relative improvement in DER and 69% in cpWER. </p>
<blockquote>
<p>传统的语音分离和说话人身份识别方法依赖于目标说话人的先验知识或音频信号中预先确定的参与者数量。为了解决这些局限性，最近的进展主要集中在开发无需注册的方法，这些方法能够在没有明确的说话人标签的情况下识别目标。这项工作引入了一种新的方法，使用混合自动识别目标说话人嵌入来同时进行语音分离和身份识别。我们提出的模型采用了一个两阶段训练管道，旨在学习对背景噪声干扰具有鲁棒性的说话人表示特征。此外，我们还提出了一种专为提高重叠语音帧中的身份识别准确性而设计的重叠光谱损失函数。实验结果表明，与当前的最佳基线相比，我们的方法取得了显著的性能提升，在DER上实现了相对71%的改进，cpWER上实现了69%的改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06393v1">PDF</a> Accepted to Interspeech 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种无需注册的新方法，能够自动识别目标说话人的嵌入，用于同时进行语音分离和说话人识别。该方法采用双阶段训练管道，学习稳健的说话人特征表示，并引入针对重叠语音帧的定制重叠光谱损失函数，以提高识别准确性。实验结果表明，与当前最佳基线相比，该方法在DER和cpWER方面取得了显著的相对改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>引入了一种无需注册的新方法，能够自动识别目标说话人的嵌入，用于语音分离和说话人识别。</li>
<li>采用双阶段训练管道设计，旨在学习稳健的说话人特征表示。</li>
<li>定制了重叠光谱损失函数，针对重叠语音帧进行准确性提升。</li>
<li>克服了传统方法对目标说话人或预先确定的参与者数量的依赖。</li>
<li>取得了显著的相对改进，与当前最佳基线相比在DER和cpWER方面表现优越。</li>
<li>训练模型能够适应背景噪音干扰的影响。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06393">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-259214333a7db87fabd2250172703957.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b3508d9d2639d7f785158cdc948932a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4a188138e122db69b7257e1098dbaea.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Improved-Dysarthric-Speech-to-Text-Conversion-via-TTS-Personalization"><a href="#Improved-Dysarthric-Speech-to-Text-Conversion-via-TTS-Personalization" class="headerlink" title="Improved Dysarthric Speech to Text Conversion via TTS Personalization"></a>Improved Dysarthric Speech to Text Conversion via TTS Personalization</h2><p><strong>Authors:Péter Mihajlik, Éva Székely, Piroska Barta, Máté Soma Kádár, Gergely Dobsinszki, László Tóth</strong></p>
<p>We present a case study on developing a customized speech-to-text system for a Hungarian speaker with severe dysarthria. State-of-the-art automatic speech recognition (ASR) models struggle with zero-shot transcription of dysarthric speech, yielding high error rates. To improve performance with limited real dysarthric data, we fine-tune an ASR model using synthetic speech generated via a personalized text-to-speech (TTS) system. We introduce a method for generating synthetic dysarthric speech with controlled severity by leveraging premorbidity recordings of the given speaker and speaker embedding interpolation, enabling ASR fine-tuning on a continuum of impairments. Fine-tuning on both real and synthetic dysarthric speech reduces the character error rate (CER) from 36-51% (zero-shot) to 7.3%. Our monolingual FastConformer_Hu ASR model significantly outperforms Whisper-turbo when fine-tuned on the same data, and the inclusion of synthetic speech contributes to an 18% relative CER reduction. These results highlight the potential of personalized ASR systems for improving accessibility for individuals with severe speech impairments. </p>
<blockquote>
<p>我们针对一位严重缄默症的匈牙利语患者，开发了一个定制化的语音转文本系统，进行了一项案例研究。最先进的自动语音识别（ASR）模型在缄默语音的零样本转录方面存在困难，导致高错误率。为了在使用有限的真实缄默症数据的情况下提高性能，我们通过个性化的文本到语音（TTS）系统生成合成语音来微调ASR模型。我们介绍了一种通过利用给定说话人的发病前录音和说话人嵌入插值来生成具有可控严重程度的合成缄默语音的方法，从而能够在连续的损害程度上对ASR进行微调。对真实和合成缄默语音的微调将字符错误率（CER）从36-51%（零样本）降低到7.3%。我们的匈牙利语单语种FastConformer_Hu ASR模型在相同数据上进行微调时，性能显著优于Whisper-turbo，合成语音的加入导致了相对CER降低了18%。这些结果突显了个性化ASR系统在改善严重言语障碍者的可访问性方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06391v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该研究针对匈牙利语严重构音障碍者的语音转文本系统进行了个案研究。当前主流的自动语音识别（ASR）模型对于零样本的构音障碍语音转录存在较高误差率。为提高性能并受限于真实的构音障碍数据，该研究使用个性化文本转语音（TTS）系统生成合成语音，对ASR模型进行微调。通过利用患者病前录音和说话人嵌入插值的方法，该研究开发了一种生成具有可控严重程度的合成构音障碍语音的方法，使得ASR模型可以在连续的障碍程度上进行微调。在真实和合成构音障碍语音上的微调将字符错误率（CER）从零样本的36-51%降至7.3%。在同样的数据集上，该研究的匈牙利语FastConformer模型相较于Whisper-turbo表现更优，合成语音的加入带来了相对CER的18%降低。这些结果突显了个性化ASR系统在改善严重语音障碍者的可访问性方面的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究针对匈牙利语严重构音障碍者的语音转文本系统进行了个案研究。</li>
<li>当前ASR模型在零样本构音障碍语音转录上存在高误差率。</li>
<li>为提高性能，研究使用个性化TTS系统生成合成语音对ASR模型进行微调。</li>
<li>通过利用病前录音和说话人嵌入插值，生成具有可控严重程度的合成构音障碍语音。</li>
<li>真实和合成构音障碍语音的微调显著降低了字符错误率（CER）。</li>
<li>在同样的数据集上，该研究中的FastConformer模型表现优于Whisper-turbo。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06391">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ab6301d1a84700323d87ace9a9a9b648.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21512c3ae472a3aa60908e9c79bba87d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f69809759eee5c4d8e3e96c509bb95f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a409c675c9e91f46d2b55551b4c562f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a624a897e44ac82a139504fe40bb84dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b9389f4d770f4ab07dccc478b291bb4b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f3edd520ae09784760940073abca986.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SpeakerLM-End-to-End-Versatile-Speaker-Diarization-and-Recognition-with-Multimodal-Large-Language-Models"><a href="#SpeakerLM-End-to-End-Versatile-Speaker-Diarization-and-Recognition-with-Multimodal-Large-Language-Models" class="headerlink" title="SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with   Multimodal Large Language Models"></a>SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with   Multimodal Large Language Models</h2><p><strong>Authors:Han Yin, Yafeng Chen, Chong Deng, Luyao Cheng, Hui Wang, Chao-Hong Tan, Qian Chen, Wen Wang, Xiangang Li</strong></p>
<p>The Speaker Diarization and Recognition (SDR) task aims to predict “who spoke when and what” within an audio clip, which is a crucial task in various real-world multi-speaker scenarios such as meeting transcription and dialogue systems. Existing SDR systems typically adopt a cascaded framework, combining multiple modules such as speaker diarization (SD) and automatic speech recognition (ASR). The cascaded systems suffer from several limitations, such as error propagation, difficulty in handling overlapping speech, and lack of joint optimization for exploring the synergy between SD and ASR tasks. To address these limitations, we introduce SpeakerLM, a unified multimodal large language model for SDR that jointly performs SD and ASR in an end-to-end manner. Moreover, to facilitate diverse real-world scenarios, we incorporate a flexible speaker registration mechanism into SpeakerLM, enabling SDR under different speaker registration settings. SpeakerLM is progressively developed with a multi-stage training strategy on large-scale real data. Extensive experiments show that SpeakerLM demonstrates strong data scaling capability and generalizability, outperforming state-of-the-art cascaded baselines on both in-domain and out-of-domain public SDR benchmarks. Furthermore, experimental results show that the proposed speaker registration mechanism effectively ensures robust SDR performance of SpeakerLM across diverse speaker registration conditions and varying numbers of registered speakers. </p>
<blockquote>
<p>说话人识别与建模（SDR）任务旨在预测音频剪辑中的“谁何时说了什么”，这在会议转录和对话系统等多说话人现实场景中是一个至关重要的任务。现有的SDR系统通常采用级联框架，结合说话人识别（SD）和自动语音识别（ASR）等多个模块。级联系统存在误差传播、处理重叠语音困难以及缺乏对SD和ASR任务之间协同进行联合优化等局限性。为了解决这些局限性，我们引入了SpeakerLM，一个统一的多媒体语言模型用于SDR，该模型采用端到端方式联合执行SD和ASR。此外，为了适应多样化的现实场景，我们在SpeakerLM中融入灵活的说话人注册机制，实现不同说话人注册设置下的SDR。SpeakerLM通过大规模真实数据的多阶段训练策略逐步开发。大量实验表明，SpeakerLM具有强大的数据扩展能力和泛化能力，与最新的级联基线相比，在域内和域外的公共SDR基准测试中表现均有所超越。此外，实验结果表明，所提出的说话人注册机制可有效确保在不同说话人注册条件和不同注册说话人数量的场景下，SpeakerLM的SDR性能稳健。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06372v1">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>本文介绍了针对音频流中的说话人识别和声音识别的任务——说话人追踪与识别（SDR）。现有的SDR系统大多采用级联框架，包含说话人追踪和语音识别等多个模块，但存在误差传递、处理重叠语音困难等缺点。为此，提出了一种端到端的统一多任务语言模型SpeakerLM来解决这一问题。该模型融入了灵活的说话人注册机制，以应对不同说话人注册设置下的实际场景。SpeakerLM在大规模真实数据上采用了多阶段训练策略，具有出色的数据扩展能力和泛化性能，且在公开SDR基准测试中表现出超越现有级联模型的性能。此外，实验结果证实，提出的说话人注册机制能确保在不同注册条件和不同说话人数下的稳健性能。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>Speaker Diarization and Recognition (SDR)任务是预测音频剪辑中“谁何时说了什么”，在多说话人场景如会议转录和对话系统中至关重要。</li>
<li>现有SDR系统多采用级联框架，包含说话人追踪和语音识别等模块，存在误差传递和处理重叠语音困难等问题。</li>
<li>提出了端到端的统一多任务语言模型SpeakerLM，联合进行说话人追踪和语音识别。</li>
<li>SpeakerLM融入了灵活的说话人注册机制，以适应不同说话人注册设置下的实际场景。</li>
<li>SpeakerLM采用多阶段训练策略，在真实大规模数据上表现出卓越的数据扩展能力和泛化性能。</li>
<li>在公开SDR基准测试中，SpeakerLM性能超越现有级联模型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06372">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-a3eb44f283c52a95e0a479ee4000ecd8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-72f750df5e263d7f232803459ab546ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b89eeb7cdff535f3fa984ba1a4592f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65feea9bd1df6ad8967abcacf2644132.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ed94171998e99e10085fc197d1ba0fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee6a1419be5b9d73d4f1a8494ed8bea2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ff334d95281ff61fc888bc8d66a462c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-Study-on-Regularization-Based-Continual-Learning-Methods-for-Indic-ASR"><a href="#A-Study-on-Regularization-Based-Continual-Learning-Methods-for-Indic-ASR" class="headerlink" title="A Study on Regularization-Based Continual Learning Methods for Indic ASR"></a>A Study on Regularization-Based Continual Learning Methods for Indic ASR</h2><p><strong>Authors:Gokul Adethya T, S. Jaya Nirmala</strong></p>
<p>Indias linguistic diversity poses significant challenges for developing inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual models, which require simultaneous access to all language data, are impractical due to the sequential arrival of data and privacy constraints. Continual Learning (CL) offers a solution by enabling models to learn new languages sequentially without catastrophically forgetting previously learned knowledge. This paper investigates CL for ASR on Indian languages using a subset of the IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T&#x2F;CTC model, initially pretrained on Hindi, which is then incrementally trained on eight additional Indian languages, for a total sequence of nine languages. We evaluate three prominent regularization- and distillation-based CL strategies: Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning without Forgetting (LwF), selected for their suitability in no-replay, privacy-conscious scenarios. Performance is analyzed using Word Error Rate (WER) for both RNN-T and CTC paths on clean and noisy data, as well as knowledge retention via Backward Transfer. We also explore the impact of varying the number of training epochs (1, 2, 5, and 10) per task. Results, compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating forgetting, making it a promising approach for scalable ASR in diverse Indian languages under realistic constraints. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/FrozenWolf-Cyber/Indic-CL-ASR">https://github.com/FrozenWolf-Cyber/Indic-CL-ASR</a> </p>
<blockquote>
<p>印度的语言多样性给开发包容性自动语音识别（ASR）系统带来了重大挑战。由于数据顺序到达和隐私限制，要求同时访问所有语言数据的传统多语言模型并不实用。持续学习（CL）通过使模型能够按顺序学习新语言而不会遗忘之前学到的知识，从而提供了一种解决方案。本文使用IndicSUPERB基准的某个子集，研究CL在印地语ASR上的应用。我们采用基于Conformer的混合RNN-T&#x2F;CTC模型，该模型最初在印地语上进行预训练，然后顺序地在另外八种印度语言上进行增量训练，总共涉及九种语言序列。我们评估了三种基于正则化和蒸馏的CL策略：弹性权重整合（EWC）、记忆感知突触（MAS）和学习无遗忘（LwF），它们被选中用于无回放、注重隐私的场景。性能分析采用词错误率（WER）评估RNN-T和CTC路径在干净和嘈杂数据上的表现，以及通过反向传输评估知识保留情况。我们还探讨了每个任务训练周期数（1、2、5和10）的不同影响。与简单微调相比，结果证明了CL在减轻遗忘方面的有效性，使其成为在现实约束下实现可扩展的印地语ASR的有前途的方法。代码可从以下网址获取：<a target="_blank" rel="noopener" href="https://github.com/FrozenWolf-Cyber/Indic-CL-ASR">https://github.com/FrozenWolf-Cyber/Indic-CL-ASR</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06280v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了印度语言多样性对开发包容性自动语音识别（ASR）系统的挑战。由于数据序贯到达和隐私限制，传统的同时访问所有语言数据的多语言模型变得不切实际。持续学习（CL）为解决这一问题提供了解决方案，使模型能够顺序学习新语言，而不会遗忘之前的知识。本文研究了基于CL的ASR在印度语言上的应用，采用Conformer混合RNN-T&#x2F;CTC模型，初始以印地语进行预训练，然后陆续在八种印度语言上进行训练，共涉及九种语言序列。本文评估了三种基于正则化和蒸馏的CL策略：弹性权重整合（EWC）、记忆感知突触（MAS）和学习不会遗忘（LwF），这些策略适用于无回放和隐私意识场景。通过词错误率（WER）评估RNN-T和CTC路径在干净和嘈杂数据上的性能，以及通过向后转移评估知识保留情况。此外，还探讨了每个任务训练周期数（1、2、5和10）的影响。与简单的微调相比，结果证明了CL在缓解遗忘方面的有效性，使其成为在现实约束下可扩展的印度多语言ASR的有前途的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>印度语言多样性对开发包容性自动语音识别（ASR）系统构成挑战。</li>
<li>传统多语言模型因数据序贯到达和隐私限制而变得不切实际。</li>
<li>持续学习（CL）能使模型顺序学习新语言而不遗忘之前的知识。</li>
<li>研究了CL在ASR上的应用在IndicSUPERB基准测试上的表现。</li>
<li>采用Conformer混合RNN-T&#x2F;CTC模型，并陆续在多种印度语言上进行训练。</li>
<li>评估了三种基于正则化和蒸馏的CL策略：EWC、MAS和LwF。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06280">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-09a79b8f7b214ed24a711488c716794b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b2fd54759fdd4757c6fe4c25cbb61bc0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="REF-VC-Robust-Expressive-and-Fast-Zero-Shot-Voice-Conversion-with-Diffusion-Transformers"><a href="#REF-VC-Robust-Expressive-and-Fast-Zero-Shot-Voice-Conversion-with-Diffusion-Transformers" class="headerlink" title="REF-VC: Robust, Expressive and Fast Zero-Shot Voice Conversion with   Diffusion Transformers"></a>REF-VC: Robust, Expressive and Fast Zero-Shot Voice Conversion with   Diffusion Transformers</h2><p><strong>Authors:Yuepeng Jiang, Ziqian Ning, Shuai Wang, Chengjia Wang, Mengxiao Bi, Pengcheng Zhu, Zhonghua Fu, Lei Xie</strong></p>
<p>In real-world voice conversion applications, environmental noise in source speech and user demands for expressive output pose critical challenges. Traditional ASR-based methods ensure noise robustness but suppress prosody richness, while SSL-based models improve expressiveness but suffer from timbre leakage and noise sensitivity. This paper proposes REF-VC, a noise-robust expressive voice conversion system. Key innovations include: (1) A random erasing strategy to mitigate the information redundancy inherent in SSL features, enhancing noise robustness and expressiveness; (2) Implicit alignment inspired by E2TTS to suppress non-essential feature reconstruction; (3) Integration of Shortcut Models to accelerate flow matching inference, significantly reducing to 4 steps. Experimental results demonstrate that REF-VC outperforms baselines such as Seed-VC in zero-shot scenarios on the noisy set, while also performing comparably to Seed-VC on the clean set. In addition, REF-VC can be compatible with singing voice conversion within one model. </p>
<blockquote>
<p>在真实世界的声音转换应用中，源语音中的环境噪声和用户对于表达输出的需求构成了重大挑战。传统的基于自动语音识别（ASR）的方法确保了噪声鲁棒性，但抑制了韵律的丰富性，而基于自监督学习（SSL）的模型提高了表达性，但存在音色泄露和噪声敏感的问题。本文提出了REF-VC，一种噪声鲁棒性强的表达性语音转换系统。主要创新点包括：（1）采用随机擦除策略，减轻SSL特征中的信息冗余，增强噪声鲁棒性和表达性；（2）受E2TTS启发的隐式对齐，抑制非关键特征重建；（3）集成快捷模型，加速流匹配推理，大幅减少至4步。实验结果表明，REF-VC在噪声集上的零样本场景中优于基线方法（如Seed-VC），同时在清洁集上的表现与Seed-VC相当。此外，REF-VC可以在一个模型内兼容歌声转换。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04996v2">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>本文提出一种稳健且表现力强的语音转换系统REF-VC，解决了真实世界语音转换应用中源语音中的环境噪声和用户对于表现力的需求所带来的挑战。主要创新点包括：采用随机擦除策略减轻SSL特征中的信息冗余，增强噪声鲁棒性和表现力；借鉴E2TTS的隐对齐方式抑制非关键特征重建；集成Shortcut Models加速流匹配推理，减少至4步。实验结果表明，REF-VC在噪声集上的零样本场景表现优于基线方法Seed-VC，同时在清洁集上表现相当。此外，REF-VC可在单一模型内兼容歌声转换。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>REF-VC解决了真实世界语音转换中的噪声和表现力需求挑战。</li>
<li>采用随机擦除策略减轻SSL特征中的信息冗余。</li>
<li>隐对齐方式抑制非关键特征重建。</li>
<li>集成Shortcut Models加速流匹配推理。</li>
<li>REF-VC在噪声集上的零样本场景表现优于Seed-VC。</li>
<li>REF-VC在清洁集上表现与Seed-VC相当。</li>
<li>REF-VC可在单一模型内实现歌声转换兼容性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04996">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-e4d7df6fdbf0cacb08bbb3aefdff45fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21c65ed00bb726f0549712e7004e403b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c1b30faacd5d5eb868a42f428ac420c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-601fb1ab6420d2b83d941500cce376ce.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MoDA-Multi-modal-Diffusion-Architecture-for-Talking-Head-Generation"><a href="#MoDA-Multi-modal-Diffusion-Architecture-for-Talking-Head-Generation" class="headerlink" title="MoDA: Multi-modal Diffusion Architecture for Talking Head Generation"></a>MoDA: Multi-modal Diffusion Architecture for Talking Head Generation</h2><p><strong>Authors:Xinyang Li, Gen Li, Zhihui Lin, Yichen Qian, GongXin Yao, Weinan Jia, Aowen Wang, Weihua Chen, Fan Wang</strong></p>
<p>Talking head generation with arbitrary identities and speech audio remains a crucial problem in the realm of the virtual metaverse. Recently, diffusion models have become a popular generative technique in this field with their strong generation capabilities. However, several challenges remain for diffusion-based methods: 1) inefficient inference and visual artifacts caused by the implicit latent space of Variational Auto-Encoders (VAE), which complicates the diffusion process; 2) a lack of authentic facial expressions and head movements due to inadequate multi-modal information fusion. In this paper, MoDA handles these challenges by: 1) defining a joint parameter space that bridges motion generation and neural rendering, and leveraging flow matching to simplify diffusion learning; 2) introducing a multi-modal diffusion architecture to model the interaction among noisy motion, audio, and auxiliary conditions, enhancing overall facial expressiveness. In addition, a coarse-to-fine fusion strategy is employed to progressively integrate different modalities, ensuring effective feature fusion. Experimental results demonstrate that MoDA improves video diversity, realism, and efficiency, making it suitable for real-world applications. Project Page: <a target="_blank" rel="noopener" href="https://lixinyyang.github.io/MoDA.github.io/">https://lixinyyang.github.io/MoDA.github.io/</a> </p>
<blockquote>
<p>在虚拟元宇宙领域，使用任意身份和语音音频生成头部对话仍然是一个关键问题。最近，扩散模型凭借其强大的生成能力，已成为该领域的一种流行的生成技术。然而，基于扩散的方法仍存在几个挑战：1）由于变分自动编码器（VAE）的隐式潜在空间导致的效率低下和视觉伪影，这复杂化了扩散过程；2）由于缺乏多模态信息融合导致面部表达和头部动作不真实。本文中，MoDA通过以下方法应对这些挑战：1）定义了一个联合参数空间，该空间连接运动生成和神经渲染，并利用流匹配简化扩散学习；2）引入多模态扩散架构来模拟噪声运动、音频和辅助条件之间的交互作用，提高面部的整体表现力。此外，采用由粗到细的融合策略来逐步融合不同的模式，确保有效的特征融合。实验结果表明，MoDA提高了视频的多样性、真实性和效率，使其成为适合实际应用的有力工具。项目页面：<a target="_blank" rel="noopener" href="https://lixinyyang.github.io/MoDA.github.io/">https://lixinyyang.github.io/MoDA.github.io/</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03256v3">PDF</a> 12 pages, 7 figures</p>
<p><strong>摘要</strong><br>    基于扩散模型的虚拟世界中任意身份与语音对话生成仍面临挑战，包括推理效率低、视觉伪影和面部表情缺失等问题。MoDA通过构建联合参数空间简化扩散学习，引入多模态扩散架构提升面部表现力，并采用由粗到细的融合策略确保特征的有效融合。实验证明MoDA提高了视频多样性、真实感和效率，适用于真实场景应用。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>虚拟世界中的对话头生成问题仍然重要，特别是与任意身份和语音音频的结合。</li>
<li>扩散模型在该领域因其强大的生成能力而受到欢迎，但存在推理效率低下和视觉伪影等问题。</li>
<li>MoDA通过定义联合参数空间，简化了运动生成和神经渲染之间的联系。</li>
<li>MoDA引入了多模态扩散架构，对噪声运动、音频和辅助条件之间的交互进行建模，增强了面部的表现力。</li>
<li>MoDA采用了由粗到细的融合策略，确保不同模态特征的有效融合。</li>
<li>实验证明MoDA提高了视频多样性、真实感和效率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03256">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d6dcc5d6b9932c3a8f9aa2bea102a459.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4eb0c7372993f511c3987360e26ee704.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8617063adc11cc62cc54919c1e4040a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49abad2492c6f65b516dd85fd33c37fe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4b257127ef8c998aa1c34304f9b9c309.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3588fdb65b20f5a93ca28e19ffd91542.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-12/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-12/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-12/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-dfa813be02196132535f346f4e4bd13b.jpg" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping 方向最新论文已更新，请持续关注 Update in 2025-08-12  MotionSwap
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-12/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6fee2abe47f1719147fc9525873be1af.jpg" class="responsive-img" alt="无监督/半监督/对比学习">
                        
                        <span class="card-title">无监督/半监督/对比学习</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            无监督/半监督/对比学习 方向最新论文已更新，请持续关注 Update in 2025-08-12  CLIPin A Non-contrastive Plug-in to CLIP for Multimodal Semantic   Alignment
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    无监督/半监督/对比学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">无监督/半监督/对比学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">28791.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
