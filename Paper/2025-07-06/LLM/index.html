<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-06  Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge   Graph Guided Distractor Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f057b78d1fd5aa808ab7d2d292286af9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    39 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-06-æ›´æ–°"><a href="#2025-07-06-æ›´æ–°" class="headerlink" title="2025-07-06 æ›´æ–°"></a>2025-07-06 æ›´æ–°</h1><h2 id="Enhancing-Clinical-Multiple-Choice-Questions-Benchmarks-with-Knowledge-Graph-Guided-Distractor-Generation"><a href="#Enhancing-Clinical-Multiple-Choice-Questions-Benchmarks-with-Knowledge-Graph-Guided-Distractor-Generation" class="headerlink" title="Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge   Graph Guided Distractor Generation"></a>Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge   Graph Guided Distractor Generation</h2><p><strong>Authors:Running Yang, Wenlong Deng, Minghui Chen, Yuyin Zhou, Xiaoxiao Li</strong></p>
<p>Clinical tasks such as diagnosis and treatment require strong decision-making abilities, highlighting the importance of rigorous evaluation benchmarks to assess the reliability of large language models (LLMs). In this work, we introduce a knowledge-guided data augmentation framework that enhances the difficulty of clinical multiple-choice question (MCQ) datasets by generating distractors (i.e., incorrect choices that are similar to the correct one and may confuse existing LLMs). Using our KG-based pipeline, the generated choices are both clinically plausible and deliberately misleading. Our approach involves multi-step, semantically informed walks on a medical knowledge graph to identify distractor paths-associations that are medically relevant but factually incorrect-which then guide the LLM in crafting more deceptive distractors. We apply the designed knowledge graph guided distractor generation (KGGDG) pipline, to six widely used medical QA benchmarks and show that it consistently reduces the accuracy of state-of-the-art LLMs. These findings establish KGGDG as a powerful tool for enabling more robust and diagnostic evaluations of medical LLMs. </p>
<blockquote>
<p>ä¸´åºŠä»»åŠ¡å¦‚è¯Šæ–­å’Œæ²»ç–—åå†³ç­–ï¼Œå¼ºè°ƒéœ€è¦å¼ºå¤§çš„å†³ç­–èƒ½åŠ›è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„å¯ä¿¡åº¦çš„é‡è¦æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªçŸ¥è¯†å¼•å¯¼çš„æ•°æ®å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆå¹²æ‰°é¡¹ï¼ˆå³ä¸æ­£ç¡®ç­”æ¡ˆç›¸ä¼¼ä½†å¯èƒ½æ··æ·†ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„é”™è¯¯é€‰æ‹©ï¼‰æ¥æé«˜ä¸´åºŠé€‰æ‹©é¢˜é›†çš„éš¾åº¦ã€‚ä½¿ç”¨æˆ‘ä»¬çš„åŸºäºçŸ¥è¯†çš„ç®¡é“ï¼Œç”Ÿæˆçš„é€‰é¡¹æ—¢ç¬¦åˆä¸´åºŠåˆç†æ€§åˆæ•…æ„å…·æœ‰è¯¯å¯¼æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¶‰åŠåœ¨åŒ»ç–—çŸ¥è¯†å›¾ä¸Šæ‰§è¡Œå¤šæ­¥è¯­ä¹‰ä¿¡æ¯é©±åŠ¨è·¯å¾„ï¼Œä»¥è¯†åˆ«å¹²æ‰°é¡¹è·¯å¾„å…³è”ï¼ˆåŒ»å­¦ç›¸å…³ä½†äº‹å®é”™è¯¯ï¼‰ï¼Œç„¶åæŒ‡å¯¼å¤§å‹è¯­è¨€æ¨¡å‹åˆ¶ä½œæ›´å…·æ¬ºéª—æ€§çš„å¹²æ‰°é¡¹ã€‚æˆ‘ä»¬å°†è®¾è®¡çš„çŸ¥è¯†å›¾è°±å¼•å¯¼å¹²æ‰°é¡¹ç”Ÿæˆç®¡é“åº”ç”¨äºå…­ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŒ»ç–—é—®ç­”åŸºå‡†æµ‹è¯•ï¼Œå¹¶è¯æ˜å®ƒå§‹ç»ˆé™ä½äº†æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚è¿™äº›å‘ç°ç¡®ç«‹äº†çŸ¥è¯†å›¾è°±å¼•å¯¼å¹²æ‰°é¡¹ç”Ÿæˆæ³•ä½œä¸ºè¿›è¡Œæ›´ç¨³å¥è¯Šæ–­è¯„ä¼°åŒ»ç–—å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼ºå¤§å·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00612v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªçŸ¥è¯†å¼•å¯¼çš„æ•°æ®å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆå¹²æ‰°é¡¹ï¼ˆä¸æ­£ç¡®ç­”æ¡ˆç›¸ä¼¼ä½†å¯èƒ½æ··æ·†ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹LLMçš„é”™è¯¯é€‰æ‹©ï¼‰æ¥æé«˜ä¸´åºŠé€‰æ‹©é¢˜é›†çš„éš¾åº¦ã€‚è¯¥æ–¹æ³•æ¶‰åŠåœ¨åŒ»ç–—çŸ¥è¯†å›¾ä¸Šè¿›è¡Œå¤šæ­¥è¯­ä¹‰ä¿¡æ¯èµ°æŸ¥ï¼Œä»¥è¯†åˆ«å¹²æ‰°é¡¹è·¯å¾„ï¼ˆåŒ»å­¦ç›¸å…³ä½†äº‹å®é”™è¯¯çš„å…³è”ï¼‰ï¼Œç„¶åæŒ‡å¯¼LLMåˆ¶ä½œæ›´å…·æ¬ºéª—æ€§çš„å¹²æ‰°é¡¹ã€‚åº”ç”¨è¯¥çŸ¥è¯†å›¾è°±å¼•å¯¼å¹²æ‰°é¡¹ç”Ÿæˆï¼ˆKGGDGï¼‰ç®¡é“äºå…­ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŒ»ç–—é—®ç­”åŸºå‡†æµ‹è¯•é›†ï¼Œè¡¨æ˜å®ƒå§‹ç»ˆé™ä½äº†æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚è¿™ä¸ºæ›´ç¨³å¥å’Œè¯Šæ–­æ€§è¯„ä¼°åŒ»ç–—LLMæä¾›äº†æœ‰åŠ›å·¥å…·ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>ä¸´åºŠä»»åŠ¡å¦‚è¯Šæ–­å’Œæ²»ç–—çš„å†³ç­–èƒ½åŠ›è‡³å…³é‡è¦ï¼Œéœ€è¦ä¸¥æ ¼è¯„ä¼°åŸºå‡†æµ‹è¯•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¯é æ€§ã€‚</li>
<li>ä»‹ç»äº†ä¸€ä¸ªçŸ¥è¯†å¼•å¯¼çš„æ•°æ®å¢å¼ºæ¡†æ¶ï¼Œç”¨äºæé«˜ä¸´åºŠé€‰æ‹©é¢˜é›†çš„éš¾åº¦ã€‚</li>
<li>ç”Ÿæˆå¹²æ‰°é¡¹ï¼Œå³ä¸æ­£ç¡®ç­”æ¡ˆç›¸ä¼¼ä½†å¯èƒ½æ··æ·†ç°æœ‰LLMçš„é”™è¯¯é€‰æ‹©ã€‚</li>
<li>çŸ¥è¯†å›¾è°±å¼•å¯¼å¹²æ‰°é¡¹ç”Ÿæˆï¼ˆKGGDGï¼‰ç®¡é“æ¶‰åŠåœ¨åŒ»ç–—çŸ¥è¯†å›¾ä¸Šå¤šæ­¥è¯­ä¹‰ä¿¡æ¯èµ°æŸ¥ã€‚</li>
<li>KGGDGç®¡é“èƒ½è¯†åˆ«åŒ»å­¦ç›¸å…³ä½†äº‹å®é”™è¯¯çš„å¹²æ‰°é¡¹è·¯å¾„ã€‚</li>
<li>åº”ç”¨è¯¥ç®¡é“äºå…­ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŒ»ç–—é—®ç­”åŸºå‡†æµ‹è¯•é›†ï¼Œæ˜¾ç¤ºå…¶é™ä½äº†æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>ä¸ºæ›´ç¨³å¥å’Œè¯Šæ–­æ€§è¯„ä¼°åŒ»ç–—LLMæä¾›äº†æœ‰åŠ›å·¥å…·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00612">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b024b08c72c4706c78eab24a6ae8a075.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32105d1f945e0b25eacf0581de1546e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b51f9a96ee0611c7a4830ca58da7193.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="LLM-Powered-Prediction-of-Hyperglycemia-and-Discovery-of-Behavioral-Treatment-Pathways-from-Wearables-and-Diet"><a href="#LLM-Powered-Prediction-of-Hyperglycemia-and-Discovery-of-Behavioral-Treatment-Pathways-from-Wearables-and-Diet" class="headerlink" title="LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral   Treatment Pathways from Wearables and Diet"></a>LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral   Treatment Pathways from Wearables and Diet</h2><p><strong>Authors:Abdullah Mamun, Asiful Arefeen, Susan B. Racette, Dorothy D. Sears, Corrie M. Whisner, Matthew P. Buman, Hassan Ghasemzadeh</strong></p>
<p>Postprandial hyperglycemia, marked by the blood glucose level exceeding the normal range after consuming a meal, is a critical indicator of progression toward type 2 diabetes in people with prediabetes and in healthy individuals. A key metric for understanding blood glucose dynamics after eating is the postprandial area under the curve (AUC). Predicting postprandial AUC in advance based on a personâ€™s lifestyle factors, such as diet and physical activity level, and explaining the factors that affect postprandial blood glucose could allow an individual to adjust their lifestyle accordingly to maintain normal glucose levels. In this study, we developed an explainable machine learning solution, GlucoLens, that takes sensor-driven inputs and uses advanced data processing, large language models, and trainable machine learning models to predict postprandial AUC and hyperglycemia from diet, physical activity, and recent glucose patterns. We used data obtained from wearables in a five-week clinical trial of 10 adults who worked full-time to develop and evaluate the proposed computational model that integrates wearable sensing, multimodal data, and machine learning. Our machine learning model takes multimodal data from wearable activity and glucose monitoring sensors, along with food and work logs, and provides an interpretable prediction of the postprandial glucose pattern. Our GlucoLens system achieves a normalized root mean squared error (NRMSE) of 0.123 in its best configuration. On average, the proposed technology provides a 16% better performance level compared to the comparison models. Additionally, our technique predicts hyperglycemia with an accuracy of 73.3% and an F1 score of 0.716 and recommends different treatment options to help avoid hyperglycemia through diverse counterfactual explanations. Code available: <a target="_blank" rel="noopener" href="https://github.com/ab9mamun/GlucoLens">https://github.com/ab9mamun/GlucoLens</a>. </p>
<blockquote>
<p>é¤åé«˜è¡€ç³–ï¼Œè¡¨ç°ä¸ºé¤åè¡€ç³–æ°´å¹³è¶…è¿‡æ­£å¸¸èŒƒå›´ï¼Œæ˜¯ç³–å°¿ç—…å‰æœŸæ‚£è€…å’Œå¥åº·ä¸ªä½“è¿›å±•ä¸º2å‹ç³–å°¿ç—…çš„é‡è¦æ ‡å¿—ã€‚äº†è§£è¿›é£Ÿåè¡€ç³–åŠ¨æ€å˜åŒ–çš„å…³é”®æŒ‡æ ‡æ˜¯é¤åæ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰ã€‚æ ¹æ®ä¸€ä¸ªäººçš„ç”Ÿæ´»æ–¹å¼å› ç´ ï¼Œå¦‚é¥®é£Ÿå’Œä½“è‚²æ´»åŠ¨æ°´å¹³ï¼Œé¢„å…ˆé¢„æµ‹é¤åAUCï¼Œå¹¶è§£é‡Šå½±å“é¤åè¡€ç³–çš„å› ç´ ï¼Œå¯ä»¥å…è®¸ä¸ªäººç›¸åº”åœ°è°ƒæ•´å…¶ç”Ÿæ´»æ–¹å¼ä»¥ä¿æŒæ­£å¸¸çš„è¡€ç³–æ°´å¹³ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ è§£å†³æ–¹æ¡ˆGlucoLensï¼Œå®ƒé‡‡ç”¨ä¼ æ„Ÿå™¨é©±åŠ¨è¾“å…¥ï¼Œä½¿ç”¨å…ˆè¿›çš„æ•°æ®å¤„ç†ã€å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¯è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ ¹æ®é¥®é£Ÿã€ä½“è‚²æ´»åŠ¨å’Œæœ€è¿‘çš„è¡€ç³–æ¨¡å¼é¢„æµ‹é¤åAUCå’Œé¤åé«˜è¡€ç³–ã€‚æˆ‘ä»¬ä½¿ç”¨æ¥è‡ªå…¨èŒå·¥ä½œçš„10åæˆå¹´äººè¿›è¡Œçš„ä¸ºæœŸäº”å‘¨çš„ä¸´åºŠè¯•éªŒæœŸé—´å¯ç©¿æˆ´è®¾å¤‡è·å¾—çš„æ•°æ®ï¼Œæ¥å¼€å‘å¹¶è¯„ä¼°æ‰€æå‡ºçš„è®¡ç®—æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ•´åˆäº†å¯ç©¿æˆ´ä¼ æ„Ÿå™¨ã€å¤šæ¨¡å¼æ•°æ®å’Œæœºå™¨å­¦ä¹ ã€‚æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹é‡‡ç”¨æ¥è‡ªå¯ç©¿æˆ´æ´»åŠ¨å’Œè¡€ç³–ç›‘æµ‹ä¼ æ„Ÿå™¨çš„å¤šæ¨¡å¼æ•°æ®ï¼Œä»¥åŠé£Ÿç‰©å’Œå·¥ä½œæ—¥å¿—ï¼Œæä¾›å¯è§£é‡Šçš„é¤åè¡€ç³–æ¨¡å¼é¢„æµ‹ã€‚åœ¨æˆ‘ä»¬çš„æœ€ä½³é…ç½®ä¸­ï¼ŒGlucoLensç³»ç»Ÿçš„å½’ä¸€åŒ–å‡æ–¹æ ¹è¯¯å·®ï¼ˆNRMSEï¼‰è¾¾åˆ°0.123ã€‚å¹³å‡è€Œè¨€ï¼Œä¸å¯¹æ¯”æ¨¡å‹ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æŠ€æœ¯æä¾›äº†16%çš„æ›´é«˜æ€§èƒ½æ°´å¹³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯ä»¥73.3%çš„å‡†ç¡®ç‡å’Œ0.716çš„F1åˆ†æ•°é¢„æµ‹é«˜è¡€ç³–ï¼Œå¹¶æä¾›ä¸åŒçš„æ²»ç–—æ–¹æ¡ˆï¼Œé€šè¿‡ä¸åŒçš„åäº‹å®è§£é‡Šå¸®åŠ©é¿å…é«˜è¡€ç³–ã€‚ä»£ç å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/ab9mamun/GlucoLens%E3%80%82">https://github.com/ab9mamun/GlucoLensã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.03935v2">PDF</a> 16 pages, 10 figures</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç ”ç©¶äº†é€šè¿‡æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹é¤åè¡€ç³–æ°´å¹³çš„æ–¹æ³•ã€‚è¯¥æ¨¡å‹ç»“åˆäº†å¯ç©¿æˆ´è®¾å¤‡æ„ŸçŸ¥çš„æ•°æ®ï¼ŒåŒ…æ‹¬æ´»åŠ¨ã€è‘¡è„ç³–ç›‘æµ‹ã€é¥®é£Ÿå’Œå·¥ä½œæ—¥å¿—ç­‰å¤šæ¨¡å¼æ•°æ®ï¼Œä»¥é¢„æµ‹é¤åè¡€ç³–æ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆAUCï¼‰å’Œé¤åé«˜è¡€ç³–æƒ…å†µã€‚æ¨¡å‹åä¸ºGlucoLensï¼Œé€šè¿‡é«˜çº§æ•°æ®å¤„ç†å’Œå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒï¼Œå®ç°äº†å¯¹é¤åè¡€ç³–çš„é¢„æµ‹ï¼Œå¹¶æä¾›äº†å¯¹é¢„é˜²é«˜è¡€ç³–çš„æ²»ç–—å»ºè®®ã€‚æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œä¸å¯¹æ¯”æ¨¡å‹ç›¸æ¯”å¹³å‡æé«˜äº†16%çš„æ€§èƒ½æ°´å¹³ã€‚ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡ç‚¹æ˜¯é€šè¿‡æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹é¤åè¡€ç³–æ°´å¹³ï¼Œç‰¹åˆ«æ˜¯é¢„æµ‹é¤åè¡€ç³–æ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆAUCï¼‰ã€‚</li>
<li>æ¨¡å‹ç»“åˆäº†å¯ç©¿æˆ´è®¾å¤‡æ„ŸçŸ¥çš„å¤šæ¨¡å¼æ•°æ®ï¼ŒåŒ…æ‹¬æ´»åŠ¨ã€è‘¡è„ç³–ç›‘æµ‹ã€é¥®é£Ÿå’Œå·¥ä½œæ—¥å¿—ç­‰ã€‚</li>
<li>æ¨¡å‹åä¸ºGlucoLensï¼Œé‡‡ç”¨é«˜çº§æ•°æ®å¤„ç†å’Œå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒã€‚</li>
<li>æ¨¡å‹èƒ½é¢„æµ‹é¤åé«˜è¡€ç³–æƒ…å†µï¼Œå¹¶æä¾›é¢„é˜²é«˜è¡€ç³–çš„æ²»ç–—å»ºè®®ã€‚</li>
<li>æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œä¸å¯¹æ¯”æ¨¡å‹ç›¸æ¯”æé«˜äº†16%çš„æ€§èƒ½æ°´å¹³ã€‚</li>
<li>æ¨¡å‹é¢„æµ‹é«˜è¡€ç³–çš„å‡†ç¡®ç‡ä¸º73.3%ï¼ŒF1åˆ†æ•°ä¸º0.716ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.03935">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7e7818ee4882fcf55d7dc14d9cd30dc9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d4d37750c25f8be4b3096657280aaf4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe190b5f34f1f9b04100115ee9f9a2fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cae1446f9ba4d2b6ade236ebfa96fe97.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5fec12f0f71487a1ed51693352b4d6ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6686c6568fde2229d4ceec7d54d062db.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CAD-Editor-A-Locate-then-Infill-Framework-with-Automated-Training-Data-Synthesis-for-Text-Based-CAD-Editing"><a href="#CAD-Editor-A-Locate-then-Infill-Framework-with-Automated-Training-Data-Synthesis-for-Text-Based-CAD-Editing" class="headerlink" title="CAD-Editor: A Locate-then-Infill Framework with Automated Training Data   Synthesis for Text-Based CAD Editing"></a>CAD-Editor: A Locate-then-Infill Framework with Automated Training Data   Synthesis for Text-Based CAD Editing</h2><p><strong>Authors:Yu Yuan, Shizhao Sun, Qi Liu, Jiang Bian</strong></p>
<p>Computer Aided Design (CAD) is indispensable across various industries. \emph{Text-based CAD editing}, which automates the modification of CAD models based on textual instructions, holds great potential but remains underexplored. Existing methods primarily focus on design variation generation or text-based CAD generation, either lacking support for text-based control or neglecting existing CAD models as constraints. We introduce \emph{CAD-Editor}, the first framework for text-based CAD editing. To address the challenge of demanding triplet data with accurate correspondence for training, we propose an automated data synthesis pipeline. This pipeline utilizes design variation models to generate pairs of original and edited CAD models and employs Large Vision-Language Models (LVLMs) to summarize their differences into editing instructions. To tackle the composite nature of text-based CAD editing, we propose a locate-then-infill framework that decomposes the task into two focused sub-tasks: locating regions requiring modification and infilling these regions with appropriate edits. Large Language Models (LLMs) serve as the backbone for both sub-tasks, leveraging their capabilities in natural language understanding and CAD knowledge. Experiments show that CAD-Editor achieves superior performance both quantitatively and qualitatively. The code is available at \url {<a target="_blank" rel="noopener" href="https://github.com/microsoft/CAD-Editor%7D">https://github.com/microsoft/CAD-Editor}</a>. </p>
<blockquote>
<p>è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰åœ¨å„è¡Œå„ä¸šéƒ½æ˜¯ä¸å¯æˆ–ç¼ºçš„ã€‚åŸºäºæ–‡æœ¬çš„CADç¼–è¾‘èƒ½å¤Ÿè‡ªåŠ¨æ ¹æ®æ–‡æœ¬æŒ‡ä»¤ä¿®æ”¹CADæ¨¡å‹ï¼Œå…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œä½†å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è®¾è®¡å˜ä½“ç”Ÿæˆæˆ–åŸºäºæ–‡æœ¬çš„CADç”Ÿæˆä¸Šï¼Œè¦ä¹ˆä¸æ”¯æŒåŸºäºæ–‡æœ¬çš„æ§ä»¶ï¼Œè¦ä¹ˆå¿½è§†ç°æœ‰CADæ¨¡å‹ä½œä¸ºçº¦æŸã€‚æˆ‘ä»¬å¼•å…¥äº†åŸºäºæ–‡æœ¬çš„CADç¼–è¾‘é¦–ä¸ªæ¡†æ¶â€”â€”CAD-Editorã€‚ä¸ºè§£å†³è®­ç»ƒæ—¶æ‰€éœ€çš„ä¸‰å…ƒç»„æ•°æ®å¯¹åº”ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªåŠ¨åŒ–æ•°æ®åˆæˆç®¡é“ã€‚è¯¥ç®¡é“åˆ©ç”¨è®¾è®¡å˜ä½“æ¨¡å‹ç”ŸæˆåŸå§‹å’Œç¼–è¾‘åçš„CADæ¨¡å‹å¯¹ï¼Œå¹¶é‡‡ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å°†å…¶å·®å¼‚æ€»ç»“ä¸ºç¼–è¾‘æŒ‡ä»¤ã€‚ä¸ºè§£å†³åŸºäºæ–‡æœ¬çš„CADç¼–è¾‘çš„å¤åˆæ€§è´¨ï¼Œæˆ‘ä»¬æå‡ºäº†å…ˆå®šä½åå¡«å……çš„æ¡†æ¶ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªä¸“é¡¹å­ä»»åŠ¡ï¼šå®šä½éœ€è¦ä¿®æ”¹çš„åŒºåŸŸï¼Œå¹¶ç”¨é€‚å½“çš„ç¼–è¾‘å¡«å……è¿™äº›åŒºåŸŸã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºè¿™ä¸¤ä¸ªå­ä»»åŠ¡çš„åç›¾ï¼Œåˆ©ç”¨å…¶åœ¨è‡ªç„¶è¯­è¨€ç†è§£å’ŒCADçŸ¥è¯†æ–¹é¢çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒCAD-Editoråœ¨é‡å’Œè´¨ä¸Šéƒ½å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚ä»£ç å¯åœ¨\url{<a target="_blank" rel="noopener" href="https://github.com/microsoft/CAD-Editor%7D%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/microsoft/CAD-Editor}æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03997v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä»‹ç»äº†è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰çš„é‡è¦æ€§ä»¥åŠåŸºäºæ–‡æœ¬çš„CADç¼–è¾‘çš„æ½œåŠ›ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸è¶³ï¼Œä¸»è¦å…³æ³¨è®¾è®¡å˜åŒ–ç”Ÿæˆæˆ–åŸºäºæ–‡æœ¬çš„CADç”Ÿæˆï¼Œç¼ºä¹æ–‡æœ¬æ§åˆ¶æˆ–å¯¹ç°æœ‰CADæ¨¡å‹ä½œä¸ºçº¦æŸçš„è€ƒè™‘ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†CAD-Editoræ¡†æ¶ï¼Œé‡‡ç”¨è‡ªåŠ¨åŒ–æ•°æ®åˆæˆç®¡é“è§£å†³è®­ç»ƒæ•°æ®éœ€æ±‚é—®é¢˜ï¼Œå¹¶æå‡ºå®šä½å¡«å……æ¡†æ¶è§£å†³åŸºäºæ–‡æœ¬çš„CADç¼–è¾‘çš„å¤åˆæ€§è´¨é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒCAD-Editoråœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰åœ¨å„è¡Œå„ä¸šä¸­ä¸å¯æˆ–ç¼ºã€‚</li>
<li>åŸºäºæ–‡æœ¬çš„CADç¼–è¾‘æœ‰å¾ˆå¤§çš„æ½œåŠ›ï¼Œä½†ç›®å‰å°šå¾…æ¢ç´¢ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è®¾è®¡å˜åŒ–ç”Ÿæˆæˆ–åŸºäºæ–‡æœ¬çš„CADç”Ÿæˆï¼Œç¼ºä¹æ–‡æœ¬æ§åˆ¶æˆ–å¯¹ç°æœ‰CADæ¨¡å‹çš„è€ƒè™‘ã€‚</li>
<li>CAD-Editoræ˜¯é¦–ä¸ªåŸºäºæ–‡æœ¬çš„CADç¼–è¾‘æ¡†æ¶ï¼Œè§£å†³äº†è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>é‡‡ç”¨è‡ªåŠ¨åŒ–æ•°æ®åˆæˆç®¡é“è§£å†³è®­ç»ƒæ•°æ®éœ€æ±‚é—®é¢˜ã€‚</li>
<li>æå‡ºå®šä½å¡«å……æ¡†æ¶ä»¥è§£å†³åŸºäºæ–‡æœ¬çš„CADç¼–è¾‘çš„å¤åˆæ€§è´¨é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03997">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-75b046b42a495c4bec3d41b1498d6c8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6006cc1a109b40aa49d82a2f32279863.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f18949362867e0b79df127b7aca420eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9676f22f9299d35782a407a3efbd5db9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdfc03f91f9948c67cb75bbab01d06c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c257e00d3d562e9166ff0ba037c5b7f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MAPS-Advancing-Multi-Modal-Reasoning-in-Expert-Level-Physical-Science"><a href="#MAPS-Advancing-Multi-Modal-Reasoning-in-Expert-Level-Physical-Science" class="headerlink" title="MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science"></a>MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science</h2><p><strong>Authors:Erle Zhu, Yadi Liu, Zhe Zhang, Xujun Li, Jin Zhou, Xinjie Yu, Minlie Huang, Hongning Wang</strong></p>
<p>Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. However, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. To address this, we develop a new framework, named Multi-Modal Scientific Reasoning with Physics Perception and Simulation (MAPS) based on an MLLM. MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. At the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. Validated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. We will release our code, model and dataset used for our experiments upon publishing of this paper. </p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡æ–‡æœ¬å’Œå›¾åƒè¯­æ–™åº“çš„é¢„è®­ç»ƒï¼Œå½“å‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨ä¸€èˆ¬çš„è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨éœ€è¦ç†è§£å…·æœ‰å¤æ‚ç‰©ç†ç»“æ„çš„å›¾è¡¨ä»¥åŠåŸºäºå¤šæ¨¡æ€ä¿¡æ¯è¿›è¡Œå®šé‡åˆ†æçš„ç‰©ç†é¢†åŸŸä¸­çš„è¡¨ç°ä»ç„¶ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåä¸ºåŸºäºç‰©ç†æ„ŸçŸ¥ä¸æ¨¡æ‹Ÿçš„å¤šæ¨¡æ€ç§‘å­¦æ¨ç†ï¼ˆMAPSï¼‰çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºMLLMã€‚MAPSå°†ä¸“å®¶çº§çš„å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºé€šè¿‡ç‰©ç†æ„ŸçŸ¥æ¨¡å‹ï¼ˆPPMï¼‰ç†è§£ç‰©ç†å›¾è¡¨å’Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿›è¡Œç‰©ç†çŸ¥è¯†æ¨ç†ã€‚PPMæ¨¡å—æ˜¯é€šè¿‡ä½¿ç”¨ç²¾å¿ƒè®¾è®¡çš„åˆæˆæ•°æ®å¯¹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒè€Œè·å¾—çš„ï¼Œè¿™äº›æ•°æ®åŒ…æ‹¬é…å¯¹çš„ç‰©ç†å›¾è¡¨å’Œç›¸åº”çš„æ¨¡æ‹Ÿè¯­è¨€æè¿°ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒMAPSç»“åˆäº†PPMæä¾›çš„è¾“å…¥å›¾è¡¨çš„æ¨¡æ‹Ÿè¯­è¨€æè¿°ä»¥åŠé€šè¿‡æ¨¡æ‹Ÿé“¾è¿‡ç¨‹ä¸MLLMè·å¾—çš„ç»“æœï¼Œä»è€Œå¾—å‡ºåŸºæœ¬ç†ç”±å’Œæœ€ç»ˆç­”æ¡ˆã€‚ä½¿ç”¨æˆ‘ä»¬æ”¶é›†çš„å¤§å­¦ç”µè·¯åˆ†æé—®é¢˜è¿›è¡ŒéªŒè¯ï¼ŒMAPSæ˜¾è‘—æé«˜äº†MLLMçš„æ¨ç†å‡†ç¡®æ€§ï¼Œå¹¶è¶…è¶Šäº†æ‰€æœ‰ç°æœ‰æ¨¡å‹ã€‚ç»“æœè¯å®ï¼ŒMAPSä¸ºå¢å¼ºMLLMçš„å¤šæ¨¡æ€ç§‘å­¦æ¨ç†èƒ½åŠ›æä¾›äº†ä¸€ä¸ªæœ‰å‰é€”çš„æ–¹å‘ã€‚åœ¨è®ºæ–‡å‘è¡¨æ—¶ï¼Œæˆ‘ä»¬å°†å…¬å¸ƒæˆ‘ä»¬çš„ä»£ç ã€æ¨¡å‹å’Œç”¨äºå®éªŒçš„æ•°æ®é›†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10768v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œç»“åˆç‰©ç†æ„ŸçŸ¥ä¸æ¨¡æ‹Ÿçš„æ¡†æ¶ï¼ˆMAPSï¼‰è§£å†³äº†åœ¨å¤æ‚ç‰©ç†ç»“æ„ç†è§£å’Œå¤šæ¨¡æ€ä¿¡æ¯åŸºç¡€ä¸Šçš„å®šé‡åˆ†æé—®é¢˜ä¸Šçš„ä¸è¶³ã€‚MAPSå°†ä¸“å®¶çº§çš„å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºé€šè¿‡ç‰©ç†æ„ŸçŸ¥æ¨¡å‹ï¼ˆPPMï¼‰ç†è§£ç‰©ç†å›¾è¡¨å’Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿›è¡Œç‰©ç†çŸ¥è¯†æ¨ç†ä¸¤éƒ¨åˆ†ã€‚PPMæ¨¡å—é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åˆæˆæ•°æ®å¯¹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé…åˆæ¨¡æ‹Ÿè¯­è¨€æè¿°å’Œä»¿çœŸé“¾è¿‡ç¨‹ï¼Œæ¨å¯¼å‡ºæœ€ç»ˆç­”æ¡ˆã€‚åœ¨ç”µè·¯åˆ†æé—®é¢˜çš„å®éªŒä¸­ï¼ŒMAPSæ˜¾è‘—æé«˜äº†MLLMçš„æ¨ç†å‡†ç¡®æ€§ï¼Œå¹¶ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œä¸ºå¢å¼ºMLLMçš„å¤šæ¨¡æ€ç§‘å­¦æ¨ç†èƒ½åŠ›æä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨ä¸€èˆ¬è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†åœ¨æ¶‰åŠå¤æ‚ç‰©ç†ç»“æ„å’Œå¤šæ¨¡æ€ä¿¡æ¯çš„å®šé‡åˆ†ææ–¹é¢ä»æ˜¾ä¸è¶³ã€‚</li>
<li>é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”MAPSï¼Œè¯¥æ¡†æ¶åŸºäºMLLMï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºç‰©ç†å›¾è¡¨ç†è§£å’Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿›è¡Œç‰©ç†çŸ¥è¯†çš„æ¨ç†ä¸¤éƒ¨åˆ†ã€‚</li>
<li>MAPSé€šè¿‡ä½¿ç”¨ç‰©ç†æ„ŸçŸ¥æ¨¡å‹ï¼ˆPPMï¼‰ç†è§£ç‰©ç†å›¾è¡¨ï¼Œè¯¥æ¨¡å—é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åˆæˆæ•°æ®å’Œé…å¥—çš„æ¨¡æ‹Ÿè¯­è¨€æè¿°å¯¹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚</li>
<li>åœ¨æ¨ç†é˜¶æ®µï¼ŒMAPSç»“åˆäº†PPMæä¾›çš„è¾“å…¥å›¾è¡¨çš„æ¨¡æ‹Ÿè¯­è¨€æè¿°å’Œé€šè¿‡ä»¿çœŸé“¾è¿‡ç¨‹å¾—åˆ°çš„ç»“æœï¼Œæ¨å¯¼å‡ºç­”æ¡ˆã€‚</li>
<li>é€šè¿‡ç”µè·¯åˆ†æé—®é¢˜çš„å®éªŒéªŒè¯ï¼ŒMAPSæ˜¾è‘—æé«˜äº†MLLMçš„æ¨ç†å‡†ç¡®æ€§ï¼Œä¸”ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
<li>MAPSä¸ºå¢å¼ºMLLMçš„å¤šæ¨¡æ€ç§‘å­¦æ¨ç†èƒ½åŠ›æä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10768">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-502beab8ead0eb092b689d3385c7945a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a15040fdd671943ac4cfa0bdd5a773d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39a35eb1b8e109ed95fd9c0dca198c02.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="TAROT-Targeted-Data-Selection-via-Optimal-Transport"><a href="#TAROT-Targeted-Data-Selection-via-Optimal-Transport" class="headerlink" title="TAROT: Targeted Data Selection via Optimal Transport"></a>TAROT: Targeted Data Selection via Optimal Transport</h2><p><strong>Authors:Lan Feng, Fan Nie, Yuejiang Liu, Alexandre Alahi</strong></p>
<p>We propose TAROT, a targeted data selection framework grounded in optimal transport theory. Previous targeted data selection methods primarily rely on influence-based greedy heuristics to enhance domain-specific performance. While effective on limited, unimodal data (i.e., data following a single pattern), these methods struggle as target data complexity increases. Specifically, in multimodal distributions, these heuristics fail to account for multiple inherent patterns, leading to suboptimal data selection. This work identifies two primary factors contributing to this limitation: (i) the disproportionate impact of dominant feature components in high-dimensional influence estimation, and (ii) the restrictive linear additive assumptions inherent in greedy selection strategies. To address these challenges, TAROT incorporates whitened feature distance to mitigate dominant feature bias, providing a more reliable measure of data influence. Building on this, TAROT uses whitened feature distance to quantify and minimize the optimal transport distance between the selected data and target domains. Notably, this minimization also facilitates the estimation of optimal selection ratios. We evaluate TAROT across multiple tasks, including semantic segmentation, motion prediction, and instruction tuning. Results consistently show that TAROT outperforms state-of-the-art methods, highlighting its versatility across various deep learning tasks. Code is available at <a target="_blank" rel="noopener" href="https://github.com/vita-epfl/TAROT">https://github.com/vita-epfl/TAROT</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†TAROTï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæœ€ä¼˜ä¼ è¾“ç†è®ºçš„ç›®æ ‡æ•°æ®é€‰æ‹©æ¡†æ¶ã€‚ä»¥å¾€çš„ç›®æ ‡æ•°æ®é€‰æ‹©æ–¹æ³•ä¸»è¦ä¾èµ–äºåŸºäºå½±å“çš„è´ªå©ªå¯å‘å¼ç­–ç•¥æ¥æé«˜ç‰¹å®šé¢†åŸŸçš„æ€§èƒ½ã€‚è¿™äº›æ–¹æ³•åœ¨æœ‰é™ã€å•å³°æ•°æ®ï¼ˆå³éµå¾ªå•ä¸€æ¨¡å¼çš„æ•°æ®ï¼‰ä¸Šå¾ˆæœ‰æ•ˆï¼Œä½†å½“ç›®æ ‡æ•°æ®å¤æ‚æ€§å¢åŠ æ—¶ï¼Œè¿™äº›æ–¹æ³•å°±ä¼šé‡åˆ°å›°éš¾ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å¤šå³°åˆ†å¸ƒä¸­ï¼Œè¿™äº›å¯å‘å¼æ–¹æ³•æ— æ³•è€ƒè™‘å¤šä¸ªå›ºæœ‰æ¨¡å¼ï¼Œå¯¼è‡´æ•°æ®é€‰æ‹©ä¸ä½³ã€‚è¿™é¡¹å·¥ä½œç¡®å®šäº†å¯¼è‡´è¿™ä¸€å±€é™çš„ä¸¤ä¸ªä¸»è¦å› ç´ ï¼šï¼ˆiï¼‰åœ¨é«˜ç»´å½±å“ä¼°è®¡ä¸­ï¼Œä¸»è¦ç‰¹å¾åˆ†é‡çš„ä¸æˆæ¯”ä¾‹å½±å“ï¼›ï¼ˆiiï¼‰è´ªå©ªé€‰æ‹©ç­–ç•¥ä¸­å›ºæœ‰çš„é™åˆ¶æ€§çº¿æ€§å‡è®¾ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒTAROTç»“åˆäº†ç™½åŒ–ç‰¹å¾è·ç¦»æ¥ç¼“è§£ä¸»è¦ç‰¹å¾åè§ï¼Œæä¾›æ›´å¯é çš„æ•°æ®å½±å“åº¦é‡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼ŒTAROTä½¿ç”¨ç™½åŒ–ç‰¹å¾è·ç¦»æ¥é‡åŒ–å’Œæœ€å°åŒ–æ‰€é€‰æ•°æ®å’Œç›®æ ‡åŸŸä¹‹é—´çš„æœ€ä¼˜ä¼ è¾“è·ç¦»ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ç§æœ€å°åŒ–ä¹Ÿä¿ƒè¿›äº†æœ€ä½³é€‰æ‹©æ¯”ä¾‹çš„ä¼°è®¡ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¯„ä¼°äº†TAROTï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²ã€è¿åŠ¨é¢„æµ‹å’ŒæŒ‡ä»¤è°ƒæ•´ã€‚ç»“æœä¸€è‡´è¡¨æ˜ï¼ŒTAROTä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œçªæ˜¾äº†å…¶åœ¨å„ç§æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­çš„é€šç”¨æ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/vita-epfl/TAROT%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/vita-epfl/TAROTæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.00420v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>TAROTæ˜¯ä¸€ä¸ªåŸºäºæœ€ä¼˜ä¼ è¾“ç†è®ºçš„ç›®æ ‡æ•°æ®é€‰æ‹©æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºå½±å“åŠ›çš„è´ªå©ªå¯å‘å¼æ–¹æ³•ç›¸æ¯”ï¼ŒTAROTåœ¨å¤æ‚ç›®æ ‡æ•°æ®ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¨¡æ€åˆ†å¸ƒæ•°æ®ä¸Šã€‚å®ƒé€šè¿‡é‡‡ç”¨ç™½åŒ–ç‰¹å¾è·ç¦»æ¥å‡è½»ä¸»å¯¼ç‰¹å¾åè§çš„å½±å“ï¼Œå¹¶æä¾›æ›´å¯é çš„æ•°æ®å½±å“åº¦é‡ã€‚æ­¤å¤–ï¼ŒTAROTä½¿ç”¨ç™½åŒ–ç‰¹å¾è·ç¦»æ¥é‡åŒ–å’Œæœ€å°åŒ–æ‰€é€‰æ•°æ®ä¸ç›®æ ‡åŸŸä¹‹é—´çš„æœ€ä¼˜ä¼ è¾“è·ç¦»ï¼Œè¿™æœ‰åŠ©äºä¼°ç®—æœ€ä½³é€‰æ‹©æ¯”ä¾‹ã€‚åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒTAROTä¼˜äºç°æœ‰æ–¹æ³•ï¼Œçªæ˜¾å…¶åœ¨å„ç§æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­çš„é€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TAROTæ˜¯ä¸€ä¸ªåŸºäºæœ€ä¼˜ä¼ è¾“ç†è®ºçš„ç›®æ ‡æ•°æ®é€‰æ‹©æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•åœ¨å¤æ‚æ•°æ®ä¸Šçš„å±€é™æ€§ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä¸»è¦ä¾èµ–åŸºäºå½±å“åŠ›çš„è´ªå©ªå¯å‘å¼ç­–ç•¥ï¼Œè¿™åœ¨å¤šæ¨¡æ€åˆ†å¸ƒæ•°æ®ä¸­è¡¨ç°ä¸ä½³ã€‚</li>
<li>TAROTé€šè¿‡å¼•å…¥ç™½åŒ–ç‰¹å¾è·ç¦»æ¥å‡è½»ä¸»å¯¼ç‰¹å¾åè§ï¼Œæä¾›æ›´å¯é çš„æ•°æ®å½±å“åº¦é‡ã€‚</li>
<li>TAROTä½¿ç”¨ç™½åŒ–ç‰¹å¾è·ç¦»é‡åŒ–å’Œæœ€å°åŒ–æ‰€é€‰æ•°æ®ä¸ç›®æ ‡åŸŸä¹‹é—´çš„æœ€ä¼˜ä¼ è¾“è·ç¦»ã€‚</li>
<li>TAROTæœ‰åŠ©äºä¼°ç®—æœ€ä½³æ•°æ®é€‰æ‹©æ¯”ä¾‹ã€‚</li>
<li>åœ¨å¤šä¸ªä»»åŠ¡ï¼ˆå¦‚è¯­ä¹‰åˆ†å‰²ã€è¿åŠ¨é¢„æµ‹å’ŒæŒ‡ä»¤è°ƒæ•´ï¼‰ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒTAROTä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.00420">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8481093f19e02914a2eb4a161ab12d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a02662eb7ec0e4ce9227c78fef71f94d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f057b78d1fd5aa808ab7d2d292286af9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b51005ac819a562b59be214d4f04306a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SMoLoRA-Exploring-and-Defying-Dual-Catastrophic-Forgetting-in-Continual-Visual-Instruction-Tuning"><a href="#SMoLoRA-Exploring-and-Defying-Dual-Catastrophic-Forgetting-in-Continual-Visual-Instruction-Tuning" class="headerlink" title="SMoLoRA: Exploring and Defying Dual Catastrophic Forgetting in Continual   Visual Instruction Tuning"></a>SMoLoRA: Exploring and Defying Dual Catastrophic Forgetting in Continual   Visual Instruction Tuning</h2><p><strong>Authors:Ziqi Wang, Chang Che, Qi Wang, Yangyang Li, Zenglin Shi, Meng Wang</strong></p>
<p>Visual instruction tuning (VIT) enables multimodal large language models (MLLMs) to effectively handle a wide range of vision tasks by framing them as language-based instructions. Building on this, continual visual instruction tuning (CVIT) extends the capability of MLLMs to incrementally learn new tasks, accommodating evolving functionalities. While prior work has advanced CVIT through the development of new benchmarks and approaches to mitigate catastrophic forgetting, these efforts largely follow traditional continual learning paradigms, neglecting the unique challenges specific to CVIT. We identify a dual form of catastrophic forgetting in CVIT, where MLLMs not only forget previously learned visual understanding but also experience a decline in instruction following abilities as they acquire new tasks. To address this, we introduce the Separable Mixture of Low-Rank Adaptation (SMoLoRA) framework, which employs separable routing through two distinct modules-one for visual understanding and another for instruction following. This dual-routing design enables specialized adaptation in both domains, preventing forgetting while improving performance. Furthermore, we propose a new CVIT benchmark that goes beyond existing benchmarks by additionally evaluating a modelâ€™s ability to generalize to unseen tasks and handle diverse instructions across various tasks. Extensive experiments demonstrate that SMoLoRA outperforms existing methods in mitigating dual forgetting, improving generalization to unseen tasks, and ensuring robustness in following diverse instructions. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Minato-Zackie/SMoLoRA">https://github.com/Minato-Zackie/SMoLoRA</a>. </p>
<blockquote>
<p>è§†è§‰æŒ‡ä»¤è°ƒæ•´ï¼ˆVITï¼‰èƒ½å¤Ÿé€šè¿‡å°†å„ç§è§†è§‰ä»»åŠ¡æ„é€ æˆåŸºäºè¯­è¨€çš„æŒ‡ä»¤ï¼Œä½¿å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å¹¿æ³›çš„è§†è§‰ä»»åŠ¡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼ŒæŒç»­è§†è§‰æŒ‡ä»¤è°ƒæ•´ï¼ˆCVITï¼‰æ‰©å±•äº†MLLMsé€æ­¥å­¦ä¹ æ–°ä»»åŠ¡çš„èƒ½åŠ›ï¼Œä»¥é€‚åº”ä¸æ–­å˜åŒ–çš„åŠŸèƒ½ã€‚è™½ç„¶å…ˆå‰çš„å·¥ä½œå·²é€šè¿‡å¼€å‘æ–°çš„åŸºå‡†æµ‹è¯•æ–¹æ³•å’Œç¼“è§£ç¾éš¾æ€§é—å¿˜çš„æ–¹æ³•æ¨åŠ¨äº†CVITçš„å‘å±•ï¼Œä½†è¿™äº›åŠªåŠ›å¤§å¤šéµå¾ªä¼ ç»Ÿçš„æŒç»­å­¦ä¹ æ¨¡å¼ï¼Œå¿½ç•¥äº†CVITæ‰€é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æˆ‘ä»¬å‘ç°äº†CVITä¸­çš„åŒé‡ç¾éš¾æ€§é—å¿˜å½¢å¼ï¼Œå…¶ä¸­MLLMsä¸ä»…å¿˜è®°äº†å…ˆå‰å­¦åˆ°çš„è§†è§‰ç†è§£èƒ½åŠ›ï¼Œè€Œä¸”åœ¨è·å–æ–°ä»»åŠ¡æ—¶è¿˜ä¼šç»å†æŒ‡ä»¤æ‰§è¡Œèƒ½åŠ›çš„ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯åˆ†ç¦»çš„æ··åˆä½ç§©é€‚åº”ï¼ˆSMoLoRAï¼‰æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä¸¤ä¸ªä¸åŒæ¨¡å—çš„å¯åˆ†ç¦»è·¯ç”±æ¥å®ç°â€”â€”ä¸€ä¸ªç”¨äºè§†è§‰ç†è§£ï¼Œå¦ä¸€ä¸ªç”¨äºæŒ‡ä»¤æ‰§è¡Œã€‚è¿™ç§åŒè·¯ç”±è®¾è®¡å¯ä»¥åœ¨ä¸¤ä¸ªé¢†åŸŸå®ç°ä¸“ä¸šé€‚åº”ï¼Œé˜²æ­¢é—å¿˜å¹¶æå‡æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„CVITåŸºå‡†æµ‹è¯•ï¼Œå®ƒè¶…è¶Šäº†ç°æœ‰çš„åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡è¯„ä¼°æ¨¡å‹å¯¹æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›å’Œå¤„ç†å„ç§æŒ‡ä»¤çš„èƒ½åŠ›æ¥å®ç°æ›´å…¨é¢çš„è¯„ä»·ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSMoLoRAåœ¨ç¼“è§£åŒé‡é—å¿˜ã€æ”¹è¿›å¯¹æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€ä»¥åŠç¡®ä¿åœ¨æ‰§è¡Œå¤šæ ·æŒ‡ä»¤æ—¶çš„ç¨³å¥æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç›¸å…³ä»£ç å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/Minato-Zackie/SMoLoRA%E3%80%82">https://github.com/Minato-Zackie/SMoLoRAã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13949v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è§†è§‰æŒ‡ä»¤å¾®è°ƒï¼ˆVITï¼‰ä½¿å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰èƒ½å¤Ÿé€šè¿‡è¯­è¨€æŒ‡ä»¤æ¡†æ¶æœ‰æ•ˆåœ°å¤„ç†å¹¿æ³›çš„è§†è§‰ä»»åŠ¡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼ŒæŒç»­è§†è§‰æŒ‡ä»¤å¾®è°ƒï¼ˆCVITï¼‰æ‰©å±•äº†MLLMsé€æ­¥å­¦ä¹ æ–°ä»»åŠ¡çš„èƒ½åŠ›ï¼Œä»¥é€‚åº”ä¸æ–­å˜åŒ–çš„åŠŸèƒ½ã€‚é’ˆå¯¹CVITæ‰€é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å‘ç°äº†åŒé‡ç¾éš¾æ€§é—å¿˜çš„é—®é¢˜ï¼Œå³MLLMsä¸ä»…å¿˜è®°äº†å…ˆå‰å­¦åˆ°çš„è§†è§‰ç†è§£ï¼Œè€Œä¸”åœ¨æ¥å—æ–°ä»»åŠ¡æ—¶ï¼ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ä¹Ÿä¼šä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯åˆ†ç¦»çš„æ··åˆä½ç§©é€‚åº”ï¼ˆSMoLoRAï¼‰æ¡†æ¶ï¼Œå®ƒé‡‡ç”¨å¯åˆ†ç¦»è·¯ç”±ï¼Œé€šè¿‡ä¸¤ä¸ªä¸åŒæ¨¡å—â€”â€”ä¸€ä¸ªç”¨äºè§†è§‰ç†è§£å’Œå¦ä¸€ä¸ªç”¨äºæŒ‡ä»¤éµå¾ªã€‚è¿™ç§åŒè·¯ç”±è®¾è®¡å¯ä»¥åœ¨ä¸¤ä¸ªé¢†åŸŸè¿›è¡Œä¸“ä¸šé€‚åº”ï¼Œé˜²æ­¢é—å¿˜å¹¶æ”¹è¿›æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„CVITåŸºå‡†æµ‹è¯•ï¼Œå®ƒä¸ä»…è¯„ä¼°æ¨¡å‹å¯¹æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿˜è¯„ä¼°æ¨¡å‹å¤„ç†å„ç§æŒ‡ä»¤çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒSMoLoRAåœ¨ç¼“è§£åŒé‡é—å¿˜ã€æé«˜æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›å’Œç¡®ä¿éµå¾ªå„ç§æŒ‡ä»¤çš„ç¨³å¥æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Minato-Zackie/SMoLoRA">https://github.com/Minato-Zackie/SMoLoRA</a>ä¸­è·å¾—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VITè®©MLLMsèƒ½å¤Ÿé€šè¿‡è¯­è¨€æŒ‡ä»¤å¤„ç†è§†è§‰ä»»åŠ¡ã€‚</li>
<li>CVITä½¿MLLMsèƒ½å¤Ÿé€æ­¥å­¦ä¹ æ–°ä»»åŠ¡ï¼Œé€‚åº”ä¸æ–­å˜åŒ–çš„åŠŸèƒ½ã€‚</li>
<li>MLLMsåœ¨CVITä¸­é¢ä¸´åŒé‡ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚</li>
<li>SMoLoRAæ¡†æ¶é‡‡ç”¨åŒè·¯ç”±è®¾è®¡ï¼Œåˆ†åˆ«ç”¨äºè§†è§‰ç†è§£å’ŒæŒ‡ä»¤éµå¾ªï¼Œé˜²æ­¢é—å¿˜å¹¶æå‡æ€§èƒ½ã€‚</li>
<li>æ–°çš„CVITåŸºå‡†æµ‹è¯•è¯„ä¼°æ¨¡å‹å¯¹æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›å’Œå¤„ç†å„ç§æŒ‡ä»¤çš„èƒ½åŠ›ã€‚</li>
<li>SMoLoRAåœ¨ç¼“è§£åŒé‡é—å¿˜ã€æé«˜æ³›åŒ–èƒ½åŠ›å’Œç¡®ä¿æŒ‡ä»¤éµå¾ªçš„ç¨³å¥æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13949">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-72fac55afbdfd90949334032a01b9fca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec4ad0c06dfdb3704a9b3dde0b07af23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-336e3441df3405579273102067fca1fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8a701114c51dc0daa18169a72c7b11e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Federated-Data-Efficient-Instruction-Tuning-for-Large-Language-Models"><a href="#Federated-Data-Efficient-Instruction-Tuning-for-Large-Language-Models" class="headerlink" title="Federated Data-Efficient Instruction Tuning for Large Language Models"></a>Federated Data-Efficient Instruction Tuning for Large Language Models</h2><p><strong>Authors:Zhen Qin, Zhaomin Wu, Bingsheng He, Shuiguang Deng</strong></p>
<p>Instruction tuning is a crucial step in improving the responsiveness of pretrained large language models (LLMs) to human instructions. Federated learning (FL) helps to exploit the use of vast private instruction data from clients, becoming popular for LLM tuning by improving data diversity. Existing federated tuning simply consumes all local data, causing excessive computational overhead and overfitting to local data, while centralized data-efficient solutions are not suitable for FL due to privacy concerns. This work presents FedHDS, a federated data-efficient instruction tuning approach, which tunes LLMs with a representative subset of edge-side data. It reduces the data redundancy at both intra- and inter-client levels without sharing raw data. Experiments with various LLMs, datasets and partitions show that FedHDS improves Rouge-L on unseen tasks by an average of 10.72% over the SOTA full-data federated instruction tuning methods, while using less than 1.5% of the data samples, improving training efficiency by up to tens of times. </p>
<blockquote>
<p>æŒ‡ä»¤å¾®è°ƒæ˜¯æå‡é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹äººç±»æŒ‡ä»¤çš„å“åº”èƒ½åŠ›çš„å…³é”®æ­¥éª¤ã€‚è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰æœ‰åŠ©äºåˆ©ç”¨æ¥è‡ªå®¢æˆ·çš„æµ·é‡ç§æœ‰æŒ‡ä»¤æ•°æ®ï¼Œé€šè¿‡æå‡æ•°æ®å¤šæ ·æ€§åœ¨LLMå¾®è°ƒä¸­å˜å¾—æµè¡Œã€‚ç°æœ‰çš„è”é‚¦å­¦ä¹ å¾®è°ƒæ–¹æ³•ç®€å•åœ°ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€è¿‡å¤§å’Œå¯¹æœ¬åœ°æ•°æ®çš„è¿‡åº¦æ‹Ÿåˆï¼Œè€Œé›†ä¸­å¼çš„æé«˜æ•°æ®æ•ˆç‡è§£å†³æ–¹æ¡ˆåˆ™ç”±äºéšç§é—®é¢˜ä¸é€‚åˆç”¨äºè”é‚¦å­¦ä¹ ã€‚æœ¬ç ”ç©¶æå‡ºäº†FedHDSï¼Œè¿™æ˜¯ä¸€ç§è”é‚¦æ•°æ®é«˜æ•ˆæŒ‡ä»¤å¾®è°ƒæ–¹æ³•ï¼Œå®ƒé€šè¿‡å…·æœ‰ä»£è¡¨æ€§çš„è¾¹ç¼˜ä¾§æ•°æ®å­é›†æ¥å¾®è°ƒLLMã€‚å®ƒåœ¨å®¢æˆ·å’Œè·¨å®¢æˆ·çº§åˆ«å‡å°‘äº†æ•°æ®å†—ä½™ï¼ŒåŒæ—¶æ— éœ€å…±äº«åŸå§‹æ•°æ®ã€‚ä½¿ç”¨å„ç§LLMã€æ•°æ®é›†å’Œåˆ†åŒºçš„å®éªŒæ˜¾ç¤ºï¼ŒFedHDSåœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šå¹³å‡æé«˜äº†Rouge-Lè¯„åˆ†è¶…è¿‡æœ€æ–°å…¨æ•°æ®è”é‚¦æŒ‡ä»¤å¾®è°ƒæ–¹æ³•è¾¾10.72%ï¼ŒåŒæ—¶ä½¿ç”¨çš„æ•°æ®æ ·æœ¬ä¸åˆ°1.5%ï¼Œé€šè¿‡æé«˜é«˜è¾¾æ•°å€çš„åŸ¹è®­æ•ˆç‡æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.10926v2">PDF</a> Accepted to ACL 2025 (Findings)</p>
<p><strong>Summary</strong></p>
<p>åœ¨æå‡é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹äººç±»æŒ‡ä»¤çš„å“åº”æ–¹é¢ï¼ŒæŒ‡ä»¤è°ƒä¼˜æ˜¯é‡è¦æ­¥éª¤ã€‚è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰æœ‰åŠ©äºåˆ©ç”¨å¤§é‡ç§æœ‰æŒ‡ä»¤æ•°æ®ï¼Œé€šè¿‡æå‡æ•°æ®å¤šæ ·æ€§æ¥ä¼˜åŒ–LLMçš„è°ƒä¼˜ã€‚ç°æœ‰è”é‚¦å­¦ä¹ ç®€å•åœ°æ¶ˆè€—æ‰€æœ‰æœ¬åœ°æ•°æ®ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€è¿‡å¤§ä»¥åŠå¯¹æœ¬åœ°æ•°æ®çš„è¿‡åº¦æ‹Ÿåˆï¼Œè€Œé›†ä¸­å¼çš„æ•°æ®é«˜æ•ˆè§£å†³æ–¹æ¡ˆåˆ™å› éšç§æ‹…å¿§è€Œä¸é€‚ç”¨äºè”é‚¦å­¦ä¹ ã€‚æœ¬ç ”ç©¶æå‡ºäº†FedHDSï¼Œè¿™æ˜¯ä¸€ç§è”é‚¦æ•°æ®é«˜æ•ˆæŒ‡ä»¤è°ƒä¼˜æ–¹æ³•ï¼Œå®ƒé€šè¿‡å…·æœ‰ä»£è¡¨æ€§çš„è¾¹ç¼˜ä¾§æ•°æ®å­é›†æ¥è°ƒä¼˜LLMã€‚å®ƒå‡å°‘äº†è·¨å®¢æˆ·ç«¯å’Œå®¢æˆ·å†…éƒ¨çš„æ•°æ®å†—ä½™ï¼ŒåŒæ—¶ä¸å…±äº«åŸå§‹æ•°æ®ã€‚å®éªŒè¡¨æ˜ï¼Œä¸æœ€æ–°å…¨æ•°æ®è”é‚¦æŒ‡ä»¤è°ƒä¼˜æ–¹æ³•ç›¸æ¯”ï¼ŒFedHDSåœ¨æœªå®Œæˆä»»åŠ¡ä¸Šçš„Rouge-Lå¹³å‡æé«˜äº†10.72%ï¼ŒåŒæ—¶ä½¿ç”¨çš„æ•°æ®é‡ä¸åˆ°1.5%ï¼Œè®­ç»ƒæ•ˆç‡æé«˜äº†æ•°åå€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æŒ‡ä»¤è°ƒä¼˜æ˜¯æå‡LLMå“åº”äººç±»æŒ‡ä»¤çš„å…³é”®æ­¥éª¤ã€‚</li>
<li>è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰æœ‰åŠ©äºåˆ©ç”¨ç§æœ‰æŒ‡ä»¤æ•°æ®ï¼Œæé«˜æ•°æ®å¤šæ ·æ€§ï¼Œä¼˜åŒ–LLMã€‚</li>
<li>ç°æœ‰è”é‚¦å­¦ä¹ æ–¹æ³•å­˜åœ¨è®¡ç®—å¼€é”€å¤§ã€è¿‡åº¦æ‹Ÿåˆæœ¬åœ°æ•°æ®çš„é—®é¢˜ã€‚</li>
<li>é›†ä¸­å¼æ•°æ®é«˜æ•ˆè§£å†³æ–¹æ¡ˆå› éšç§æ‹…å¿§ä¸é€‚ç”¨äºè”é‚¦å­¦ä¹ ã€‚</li>
<li>FedHDSæ˜¯ä¸€ç§è”é‚¦æ•°æ®é«˜æ•ˆæŒ‡ä»¤è°ƒä¼˜æ–¹æ³•ï¼Œé€šè¿‡å…·æœ‰ä»£è¡¨æ€§çš„è¾¹ç¼˜ä¾§æ•°æ®å­é›†è°ƒä¼˜LLMã€‚</li>
<li>FedHDSå‡å°‘äº†è·¨å®¢æˆ·ç«¯å’Œå®¢æˆ·å†…éƒ¨çš„æ•°æ®å†—ä½™ï¼ŒåŒæ—¶ä¸å…±äº«åŸå§‹æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.10926">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d857e2d183df1632325683ff2b5d3b53.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3ed1c8733616da9232d5587cc5649a1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4e54b534f4132a8e9dea45b7bb3c035.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e1c98c04b6b61a9c4c2627dcca161c59.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="How-to-Train-Long-Context-Language-Models-Effectively"><a href="#How-to-Train-Long-Context-Language-Models-Effectively" class="headerlink" title="How to Train Long-Context Language Models (Effectively)"></a>How to Train Long-Context Language Models (Effectively)</h2><p><strong>Authors:Tianyu Gao, Alexander Wettig, Howard Yen, Danqi Chen</strong></p>
<p>We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development â€“ instead of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set of long-context downstream tasks, and we evaluate models after SFT as this better reveals long-context abilities. Supported by our robust evaluations, we run thorough experiments to decide the data mix for continued pre-training, the instruction tuning dataset, and many other design choices such as position extrapolation. We find that (1) code repositories and books are excellent sources of long data, but it is crucial to combine them with high-quality short-context data; (2) training with a sequence length beyond the evaluation length boosts long-context performance; (3) for SFT, using only short instruction datasets yields strong performance on long-context tasks. Our final model, ProLong-8B, which is initialized from Llama-3 and trained on 40B tokens, demonstrates state-of-the-art long-context performance among similarly sized models at a length of 128K. ProLong outperforms Llama-3.1-8B-Instruct on the majority of long-context tasks despite using only 5% as many tokens during long-context training. Additionally, ProLong can effectively process up to 512K tokens, one of the longest context windows of publicly available LMs. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰çš„æŒç»­è®­ç»ƒå’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä»¥æœ‰æ•ˆåˆ©ç”¨é•¿ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªå¯é çš„è¯„ä¼°åè®®æ¥æŒ‡å¯¼æ¨¡å‹å‘å±•â€”â€”æˆ‘ä»¬ä¸æ˜¯ä½¿ç”¨å›°æƒ‘åº¦æˆ–ç®€å•çš„â€œå¤§æµ·æé’ˆâ€ï¼ˆNIAHï¼‰æµ‹è¯•ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€ç³»åˆ—å¹¿æ³›çš„é•¿æœŸä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶åœ¨SFTä¹‹åè¯„ä¼°æ¨¡å‹ï¼Œå› ä¸ºè¿™èƒ½æ›´å¥½åœ°æ­ç¤ºé•¿æœŸä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚åœ¨æˆ‘ä»¬çš„ç¨³å¥è¯„ä¼°æ”¯æŒä¸‹ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å…¨é¢çš„å®éªŒæ¥å†³å®šæŒç»­é¢„è®­ç»ƒçš„æ•°æ®æ··åˆã€æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†ï¼Œä»¥åŠè¯¸å¦‚ä½ç½®å¤–æ¨ä¹‹ç±»çš„è®¸å¤šå…¶ä»–è®¾è®¡é€‰æ‹©ã€‚æˆ‘ä»¬å‘ç°ï¼šï¼ˆ1ï¼‰ä»£ç ä»“åº“å’Œä¹¦ç±æ˜¯é•¿æ•°æ®çš„æå¥½æ¥æºï¼Œä½†å°†å®ƒä»¬ä¸é«˜è´¨é‡çŸ­ä¸Šä¸‹æ–‡æ•°æ®ç»“åˆèµ·æ¥è‡³å…³é‡è¦ï¼›ï¼ˆ2ï¼‰ä½¿ç”¨è¶…è¿‡è¯„ä¼°é•¿åº¦çš„åºåˆ—é•¿åº¦è¿›è¡Œè®­ç»ƒå¯ä»¥æé«˜é•¿æœŸä¸Šä¸‹æ–‡æ€§èƒ½ï¼›ï¼ˆ3ï¼‰å¯¹äºSFTï¼Œä»…ä½¿ç”¨çŸ­æŒ‡ä»¤æ•°æ®é›†å³å¯åœ¨å…·æœ‰é•¿æœŸä¸Šä¸‹æ–‡çš„ä»»åŠ¡ä¸Šäº§ç”Ÿå¼ºå¤§æ€§èƒ½ã€‚æˆ‘ä»¬çš„æœ€ç»ˆæ¨¡å‹ProLong-8Bä»¥Llama-3ä¸ºåˆå§‹ç‰ˆæœ¬ï¼Œåœ¨40Bä»¤ç‰Œä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨é•¿åº¦ä¸º128Kçš„ç±»ä¼¼å¤§å°æ¨¡å‹ä¸­è¡¨ç°å‡ºå“è¶Šçš„é•¿ä¸Šä¸‹æ–‡æ€§èƒ½ã€‚ProLongåœ¨å¤§å¤šæ•°é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šçš„è¡¨ç°éƒ½ä¼˜äºLlama-3.1-8B-Instructï¼Œå°½ç®¡åœ¨é•¿ä¸Šä¸‹æ–‡è®­ç»ƒæœŸé—´åªä½¿ç”¨äº†5%çš„ä»¤ç‰Œã€‚æ­¤å¤–ï¼ŒProLongå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†é•¿è¾¾512Kçš„ä»¤ç‰Œï¼Œè¿™æ˜¯å…¬å¼€å¯ç”¨çš„è¯­è¨€æ¨¡å‹ä¸­å¤„ç†çš„æœ€é•¿çš„ä¸Šä¸‹æ–‡çª—å£ä¹‹ä¸€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.02660v3">PDF</a> Accepted to ACL 2025. Our code, data, and models are available at   <a target="_blank" rel="noopener" href="https://github.com/princeton-nlp/ProLong">https://github.com/princeton-nlp/ProLong</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†è¯­è¨€æ¨¡å‹çš„æŒç»­è®­ç»ƒä¸ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä»¥æœ‰æ•ˆåˆ©ç”¨é•¿æ–‡æœ¬ä¿¡æ¯ã€‚é¦–å…ˆå»ºç«‹å¯é çš„è¯„ä¼°åè®®æ¥æŒ‡å¯¼æ¨¡å‹å‘å±•ï¼Œä½¿ç”¨ä¸€ç³»åˆ—é•¿æ–‡æœ¬ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ¨¡å‹ï¼Œå¹¶åœ¨SFTåè¿›è¡Œè¯„ä¼°ä»¥æ›´å¥½åœ°æ­ç¤ºé•¿æ–‡æœ¬èƒ½åŠ›ã€‚é€šè¿‡ä¸¥è°¨çš„å®éªŒï¼Œç¡®å®šäº†ç»§ç»­é¢„è®­ç»ƒçš„æ•°æ®æ··åˆã€æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ä»¥åŠä½ç½®å¤–æ¨ç­‰è®¾è®¡é€‰æ‹©ã€‚ç ”ç©¶å‘ç°ï¼šä»£ç ä»“åº“å’Œä¹¦ç±æ˜¯é•¿æ–‡æœ¬æ•°æ®çš„ä¼˜è´¨æ¥æºï¼Œä½†éœ€ä¸é«˜è´¨é‡çŸ­æ–‡æœ¬æ•°æ®ç»“åˆï¼›ä½¿ç”¨è¶…è¿‡è¯„ä¼°é•¿åº¦çš„åºåˆ—é•¿åº¦è¿›è¡Œè®­ç»ƒå¯æé«˜é•¿æ–‡æœ¬æ€§èƒ½ï¼›å¯¹äºSFTï¼Œä»…ä½¿ç”¨çŸ­æŒ‡ä»¤æ•°æ®é›†å³å¯åœ¨é•¿æŒ‰ä»»åŠ¡ä¸Šå®ç°è‰¯å¥½æ€§èƒ½ã€‚æœ€ç»ˆï¼ŒåŸºäºLlama-3åˆå§‹åŒ–çš„ProLong-8Bæ¨¡å‹åœ¨40Bæ ‡è®°ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå±•ç°äº†åœ¨ç›¸ä¼¼è§„æ¨¡æ¨¡å‹ä¸­çš„æœ€ä½³é•¿æ–‡æœ¬æ€§èƒ½ï¼Œå…¶å¯ä»¥åœ¨å¤§å¤šæ•°é•¿æ–‡æœ¬ä»»åŠ¡ä¸Šè¶…è¶ŠLlama-3.1-8B-Instructï¼Œå°½ç®¡åœ¨é•¿æŒ‰è®­ç»ƒæœŸé—´ä»…ä½¿ç”¨äº†5%çš„æ ‡è®°ã€‚æ­¤å¤–ï¼ŒProLongå¯æœ‰æ•ˆå¤„ç†é•¿è¾¾512Kæ ‡è®°çš„æ–‡æœ¬ï¼Œè¿™æ˜¯ç›®å‰å…¬å¼€å¯ç”¨çš„è¯­è¨€æ¨¡å‹ä¸­å¤„ç†é•¿æ–‡æœ¬ä¸Šä¸‹æ–‡çš„æœ€é•¿çª—å£ä¹‹ä¸€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ä»£ç ä»“åº“å’Œä¹¦ç±æ˜¯é•¿æ–‡æœ¬æ•°æ®ä¼˜è´¨æ¥æºï¼Œéœ€ç»“åˆé«˜è´¨é‡çŸ­æ–‡æœ¬æ•°æ®ã€‚</li>
<li>ä½¿ç”¨è¶…è¿‡è¯„ä¼°é•¿åº¦çš„åºåˆ—é•¿åº¦è¿›è¡Œè®­ç»ƒå¯ä»¥æé«˜é•¿æ–‡æœ¬æ€§èƒ½ã€‚</li>
<li>å¯¹äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä»…ä½¿ç”¨çŸ­æŒ‡ä»¤æ•°æ®é›†å³å¯åœ¨é•¿æŒ‰ä»»åŠ¡ä¸Šå®ç°è‰¯å¥½æ€§èƒ½ã€‚</li>
<li>ProLong-8Bæ¨¡å‹åœ¨ç±»ä¼¼è§„æ¨¡çš„æ¨¡å‹ä¸­å±•ç°äº†å“è¶Šçš„é•¿æ–‡æœ¬æ€§èƒ½ã€‚</li>
<li>ProLongåœ¨å¤§å¤šæ•°é•¿æ–‡æœ¬ä»»åŠ¡ä¸Šè¡¨ç°è¶…è¿‡å…¶ä»–æ¨¡å‹ï¼Œå°½ç®¡ä½¿ç”¨çš„è®­ç»ƒæ ‡è®°è¾ƒå°‘ã€‚</li>
<li>ProLongå¯ä»¥å¤„ç†é•¿è¾¾512Kæ ‡è®°çš„æ–‡æœ¬ï¼Œè¿™æ˜¯ç›®å‰å…¬å¼€å¯ç”¨è¯­è¨€æ¨¡å‹ä¸­æœ€é•¿çš„ä¸Šä¸‹æ–‡çª—å£ä¹‹ä¸€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.02660">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ad91ff3155de9102f1180c05e105a56a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34f34b6ffe649d9de080bb4617f89f92.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aed065e23ea272904d95ce638704299e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5820846114188741d15b3e53769ae23a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b71c55be417ae92faad9353cc22fa6bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3326f563de1d166e4d62e4188135732d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a9bbae7375666dfad4304ddfa2a2b3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae5c71e8b4626ea45ea09b4754294741.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e810f3c2879c6ba8645790a9fcf86eda.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="The-Mamba-in-the-Llama-Distilling-and-Accelerating-Hybrid-Models"><a href="#The-Mamba-in-the-Llama-Distilling-and-Accelerating-Hybrid-Models" class="headerlink" title="The Mamba in the Llama: Distilling and Accelerating Hybrid Models"></a>The Mamba in the Llama: Distilling and Accelerating Hybrid Models</h2><p><strong>Authors:Junxiong Wang, Daniele Paliotta, Avner May, Alexander M. Rush, Tri Dao</strong></p>
<p>Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics. Given the focus on training large-scale Transformer models, we consider the challenge of converting these pretrained models for deployment. We demonstrate that it is feasible to distill large Transformers into linear RNNs by reusing the linear projection weights from attention layers with academic GPU resources. The resulting hybrid model, which incorporates a quarter of the attention layers, achieves performance comparable to the original Transformer in chat benchmarks and outperforms open-source hybrid Mamba models trained from scratch with trillions of tokens in both chat benchmarks and general benchmarks. Moreover, we introduce a hardware-aware speculative decoding algorithm that accelerates the inference speed of Mamba and hybrid models. Overall we show how, with limited computation resources, we can remove many of the original attention layers and generate from the resulting model more efficiently. Our top-performing model, distilled from Llama3-8B-Instruct, achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and 7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN model. We also find that the distilled model has natural length extrapolation, showing almost perfect accuracy in the needle-in-a-haystack test at 20x the distillation length. Code and pre-trained checkpoints are open-sourced at <a target="_blank" rel="noopener" href="https://github.com/jxiw/MambaInLlama">https://github.com/jxiw/MambaInLlama</a> and <a target="_blank" rel="noopener" href="https://github.com/itsdaniele/speculative_mamba">https://github.com/itsdaniele/speculative_mamba</a>. </p>
<blockquote>
<p>çº¿æ€§RNNæ¶æ„ï¼ˆå¦‚Mambaï¼‰åœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å¯ä»¥ä¸Transformeræ¨¡å‹ç«äº‰ï¼ŒåŒæ—¶æ‹¥æœ‰ä¼˜åŠ¿éƒ¨ç½²ç‰¹æ€§ã€‚é‰´äºç›®å‰å…³æ³¨äºè®­ç»ƒå¤§è§„æ¨¡Transformeræ¨¡å‹ï¼Œæˆ‘ä»¬è€ƒè™‘å°†è¿™äº›é¢„è®­ç»ƒæ¨¡å‹è½¬æ¢ä¸ºéƒ¨ç½²çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬è¯æ˜äº†é€šè¿‡åˆ©ç”¨æ³¨æ„åŠ›å±‚çš„çº¿æ€§æŠ•å½±æƒé‡ä»¥åŠå­¦æœ¯GPUèµ„æºï¼Œå°†å¤§å‹Transformerè’¸é¦æˆçº¿æ€§RNNæ˜¯å¯è¡Œçš„ã€‚æ‰€å¾—åˆ°çš„æ··åˆæ¨¡å‹ä»…åŒ…å«äº†å››åˆ†ä¹‹ä¸€çš„æ³¨æ„åŠ›å±‚ï¼Œåœ¨èŠå¤©åŸºå‡†æµ‹è¯•ä¸­æ€§èƒ½ä¸åŸå§‹Transformerç›¸å½“ï¼Œå¹¶ä¸”åœ¨èŠå¤©åŸºå‡†æµ‹è¯•å’Œä¸€èˆ¬åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„å¼€æºMambaæ··åˆæ¨¡å‹ï¼ˆä½¿ç”¨äº†æ•°ä¸‡äº¿ä¸ªä»¤ç‰Œï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥çš„æŠ•æœºè§£ç ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯ä»¥åŠ é€ŸMambaå’Œæ··åˆæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹ï¼Œç§»é™¤è®¸å¤šåŸå§‹æ³¨æ„åŠ›å±‚å¹¶ä»æ‰€å¾—æ¨¡å‹ä¸­æ›´æœ‰æ•ˆåœ°ç”Ÿæˆæ•°æ®ã€‚æˆ‘ä»¬çš„é«˜æ€§èƒ½æ¨¡å‹ä»Llama3-8B-Instructä¸­æç‚¼å‡ºæ¥ï¼Œåœ¨AlpacaEval 2ä¸Šä¸GPT-4ç›¸æ¯”è¾¾åˆ°äº†29.61çš„å—æ§é•¿åº¦èƒœç‡ï¼Œå¹¶åœ¨MT-Benchä¸Šè¾¾åˆ°äº†7.35ï¼Œè¶…è¿‡äº†æœ€ä½³8Bè§„æ¨¡æŒ‡ä»¤è°ƒæ•´çº¿æ€§RNNæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œæç‚¼åçš„æ¨¡å‹å…·æœ‰è‡ªç„¶çš„é•¿åº¦æ‰©å±•æ€§ï¼Œåœ¨è’¸é¦é•¿åº¦å¢åŠ äº†20å€çš„æƒ…å†µä¸‹ï¼Œå‡ ä¹è¾¾åˆ°äº†å®Œç¾çš„å‡†ç¡®ç‡åœ¨â€œneedle-in-a-haystackâ€æµ‹è¯•ä¸­ã€‚ä»£ç å’Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ£€æŸ¥ç‚¹å·²å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/jxiw/MambaInLlama">https://github.com/jxiw/MambaInLlama</a>å’Œï¼š<a target="_blank" rel="noopener" href="https://github.com/itsdaniele/speculative_mamba%E3%80%82">https://github.com/itsdaniele/speculative_mambaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.15237v4">PDF</a> NeurIPS 2024. v4 updates: mention concurrent work of speculative   decoding for SSM</p>
<p><strong>Summary</strong></p>
<p>çº¿æ€§RNNæ¶æ„ï¼ˆå¦‚Mambaï¼‰åœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å¯ä¸Transformeræ¨¡å‹ç«äº‰ï¼Œå¹¶å…·æœ‰ä¼˜åŠ¿éƒ¨ç½²ç‰¹æ€§ã€‚ç ”ç©¶æŒ‘æˆ˜åœ¨äºå¦‚ä½•å°†é¢„è®­ç»ƒçš„Transformeræ¨¡å‹è¿›è¡Œéƒ¨ç½²è½¬æ¢ã€‚é€šè¿‡åˆ©ç”¨GPUèµ„æºè¿›è¡Œå¤§å‹Transformerè’¸é¦åˆ°çº¿æ€§RNNçš„å°è¯•ï¼Œæˆ‘ä»¬å‘ç°å¯å¤ç”¨æ³¨æ„åŠ›å±‚çš„çº¿æ€§æŠ•å½±æƒé‡ã€‚æ‰€å¾—çš„æ··åˆæ¨¡å‹é‡‡ç”¨åŸæ¨¡å‹æ³¨æ„åŠ›å±‚çš„å››åˆ†ä¹‹ä¸€ï¼Œåœ¨èŠå¤©åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¸åŸå§‹Transformerç›¸å½“ï¼Œå¹¶åœ¨é€šç”¨åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ä»å¤´å¼€å§‹è®­ç»ƒçš„å¼€æºæ··åˆMambaæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é¢å‘ç¡¬ä»¶çš„æŠ•æœºè§£ç ç®—æ³•ï¼ŒåŠ å¿«äº†Mambaå’Œæ··åˆæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬ä»¥æœ‰é™çš„è®¡ç®—èµ„æºå±•ç¤ºå¦‚ä½•é€šè¿‡ç§»é™¤å¤šæ•°åŸå§‹æ³¨æ„åŠ›å±‚å¹¶ç”Ÿæˆæ›´é«˜æ•ˆçš„æ¨¡å‹æ¥å®ç°æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„é¡¶å°–æ¨¡å‹ä»Llama3-8B-Instructè’¸é¦è€Œæ¥ï¼Œåœ¨AlpacaEval 2å¯¹GPT-4çš„æ¯”èµ›ä¸­å–å¾—29.61çš„é•¿åº¦æ§åˆ¶èƒœç‡ï¼Œå¹¶åœ¨MT-Benchä¸Šå¾—åˆ†ä¸º7.35ï¼Œè¶…è¶Šäº†æœ€ä½³8Bè§„æ¨¡æŒ‡ä»¤å¾®è°ƒçº¿æ€§RNNæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å‘ç°è’¸é¦æ¨¡å‹å…·æœ‰è‡ªç„¶é•¿åº¦å¤–æ¨èƒ½åŠ›ï¼Œåœ¨è’¸é¦é•¿åº¦20å€çš„æƒ…å†µä¸‹å‡ ä¹è¾¾åˆ°å®Œç¾å‡†ç¡®åº¦ã€‚ä»£ç å’Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ£€æŸ¥ç‚¹å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/jxiw/MambaInLlama">é“¾æ¥</a>å’Œ<a target="_blank" rel="noopener" href="https://github.com/itsdaniele/speculative_mamba">é“¾æ¥</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çº¿æ€§RNNæ¶æ„ï¼ˆå¦‚Mambaï¼‰åœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å¯ä¸Transformeræ¨¡å‹ç«äº‰ã€‚</li>
<li>å¯å°†å¤§å‹Transformerè’¸é¦æˆçº¿æ€§RNNã€‚</li>
<li>å¤ç”¨æ³¨æ„åŠ›å±‚çš„çº¿æ€§æŠ•å½±æƒé‡èƒ½æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>æ··åˆæ¨¡å‹åœ¨æŸäº›åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå¦‚èŠå¤©åŸºå‡†æµ‹è¯•å’Œé€šç”¨åŸºå‡†æµ‹è¯•ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§é¢å‘ç¡¬ä»¶çš„æŠ•æœºè§£ç ç®—æ³•ä»¥åŠ é€Ÿæ¨¡å‹æ¨ç†é€Ÿåº¦ã€‚</li>
<li>é€šè¿‡ç§»é™¤å¤šæ•°åŸå§‹æ³¨æ„åŠ›å±‚å¹¶ç”Ÿæˆæ›´é«˜æ•ˆçš„æ¨¡å‹å®ç°æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.15237">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ae0f2a1b0a6b6b4dd76038a187f37a40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcee4de37c49a214575b87b42e5bef80.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc41d6a4994aa580d50294bdd66e41dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-330d8a7004a7626191ebda5a54f9ebb9.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-06/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-06/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-06/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-ab458c94402aada830bcbeebf033d843.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-06  MAD Makeup All-in-One with Cross-Domain Diffusion Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-06/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c5bd301c013f4c6653fb04aefd7c77ab.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-06  Large Reasoning Models are not thinking straight on the unreliability   of thinking trajectories
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">25156.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
