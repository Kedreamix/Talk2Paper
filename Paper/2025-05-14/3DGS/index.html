<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-05-14  GIFStream 4D Gaussian-based Immersive Video with Feature Stream">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-46564ee9dfab0833bee697f9ee26de26.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    28 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-14-更新"><a href="#2025-05-14-更新" class="headerlink" title="2025-05-14 更新"></a>2025-05-14 更新</h1><h2 id="GIFStream-4D-Gaussian-based-Immersive-Video-with-Feature-Stream"><a href="#GIFStream-4D-Gaussian-based-Immersive-Video-with-Feature-Stream" class="headerlink" title="GIFStream: 4D Gaussian-based Immersive Video with Feature Stream"></a>GIFStream: 4D Gaussian-based Immersive Video with Feature Stream</h2><p><strong>Authors:Hao Li, Sicheng Li, Xiang Gao, Abudouaihati Batuer, Lu Yu, Yiyi Liao</strong></p>
<p>Immersive video offers a 6-Dof-free viewing experience, potentially playing a key role in future video technology. Recently, 4D Gaussian Splatting has gained attention as an effective approach for immersive video due to its high rendering efficiency and quality, though maintaining quality with manageable storage remains challenging. To address this, we introduce GIFStream, a novel 4D Gaussian representation using a canonical space and a deformation field enhanced with time-dependent feature streams. These feature streams enable complex motion modeling and allow efficient compression by leveraging temporal correspondence and motion-aware pruning. Additionally, we incorporate both temporal and spatial compression networks for end-to-end compression. Experimental results show that GIFStream delivers high-quality immersive video at 30 Mbps, with real-time rendering and fast decoding on an RTX 4090. Project page: <a target="_blank" rel="noopener" href="https://xdimlab.github.io/GIFStream">https://xdimlab.github.io/GIFStream</a> </p>
<blockquote>
<p>沉浸式视频提供了六自由度（6DoF）的观看体验，在未来视频技术中可能发挥关键作用。最近，由于具有较高的渲染效率和质量，4D高斯贴图技术受到了关注。然而，如何在可管理的存储条件下保持质量仍然是一个挑战。为了解决这个问题，我们引入了GIFStream，这是一种新的4D高斯表示方法，使用标准空间和增强变形场的时间相关特征流。这些特征流能够进行复杂的运动建模，并利用时间对应和运动感知修剪实现有效的压缩。此外，我们结合了时间和空域压缩网络进行端到端的压缩。实验结果表明，GIFStream在RTX 4090上以30 Mbps的速度提供高质量的沉浸式视频，具有实时渲染和快速解码功能。项目页面：<a target="_blank" rel="noopener" href="https://xdimlab.github.io/GIFStream">https://xdimlab.github.io/GIFStream</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07539v1">PDF</a> 14 pages, 10 figures</p>
<p><strong>Summary</strong><br>     一种名为GIFStream的新型4D高斯表示方法，利用规范空间和增强变形场以及时间相关特性流，为沉浸式视频提供了高效渲染和压缩方案，可支持复杂运动建模，能在RTX 4090上实现实时渲染和快速解码，为未来的视频技术带来关键性影响。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GIFStream是一种新型的4D高斯表示方法，利用规范空间和增强变形场技术。</li>
<li>GIFStream通过引入时间相关特性流，支持复杂运动建模。</li>
<li>GIFStream能实现在保持高质量沉浸式视频的同时，对视频进行高效压缩。</li>
<li>GIFStream解决了在存储和管理质量方面的挑战。</li>
<li>GIFStream能在RTX 4090上实现实时渲染和快速解码。</li>
<li>GIFStream的实时渲染性能为其在未来视频技术中的应用提供了可能性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07539">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-ce3810089d40a49819640e8b70082009.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b8a8d95baa7d706735281c4a8f90a66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f54160e228c85e4c4c958f14ff6b929.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6f6920626b827ad4a7a06fc9a48bf5c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-470c00475cbe6127cc3f1235701c3e44.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="TUM2TWIN-Introducing-the-Large-Scale-Multimodal-Urban-Digital-Twin-Benchmark-Dataset"><a href="#TUM2TWIN-Introducing-the-Large-Scale-Multimodal-Urban-Digital-Twin-Benchmark-Dataset" class="headerlink" title="TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin   Benchmark Dataset"></a>TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin   Benchmark Dataset</h2><p><strong>Authors:Olaf Wysocki, Benedikt Schwab, Manoj Kumar Biswanath, Qilin Zhang, Jingwei Zhu, Thomas Froech, Medhini Heeramaglore, Ihab Hijazi, Khaoula Kanna, Mathias Pechinger, Zhaiyu Chen, Yao Sun, Alejandro Rueda Segura, Ziyang Xu, Omar AbdelGafar, Mansour Mehranfar, Chandan Yeshwanth, Yueh-Cheng Liu, Hadi Yazdi, Jiapan Wang, Stefan Auer, Katharina Anders, Klaus Bogenberger, Andre Borrmann, Angela Dai, Ludwig Hoegner, Christoph Holst, Thomas H. Kolbe, Ferdinand Ludwig, Matthias Nießner, Frank Petzold, Xiao Xiang Zhu, Boris Jutzi</strong></p>
<p>Urban Digital Twins (UDTs) have become essential for managing cities and integrating complex, heterogeneous data from diverse sources. Creating UDTs involves challenges at multiple process stages, including acquiring accurate 3D source data, reconstructing high-fidelity 3D models, maintaining models’ updates, and ensuring seamless interoperability to downstream tasks. Current datasets are usually limited to one part of the processing chain, hampering comprehensive UDTs validation. To address these challenges, we introduce the first comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN. This dataset includes georeferenced, semantically aligned 3D models and networks along with various terrestrial, mobile, aerial, and satellite observations boasting 32 data subsets over roughly 100,000 $m^2$ and currently 767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high accuracy, and multimodal data integration, the benchmark supports robust analysis of sensors and the development of advanced reconstruction methods. Additionally, we explore downstream tasks demonstrating the potential of TUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar potential analysis, point cloud semantic segmentation, and LoD3 building reconstruction. We are convinced this contribution lays a foundation for overcoming current limitations in UDT creation, fostering new research directions and practical solutions for smarter, data-driven urban environments. The project is available under: <a target="_blank" rel="noopener" href="https://tum2t.win/">https://tum2t.win</a> </p>
<blockquote>
<p>城市数字双胞胎（UDTs）对于管理城市以及整合来自不同源的复杂、异构数据已经变得至关重要。创建UDTs涉及多个流程阶段的挑战，包括获取准确的3D源数据、重建高保真3D模型、保持模型的更新以及确保无缝地衔接下游任务。当前的数据集通常仅限于处理链的一部分，阻碍了全面的UDTs验证。为了应对这些挑战，我们引入了第一个综合多模式城市数字双胞胎基准数据集：TUM2TWIN。该数据集包括地理参照的、语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测数据，拥有超过约10万$m^2$的32个数据集和目前总计767GB的数据。通过确保地理参照的室内外采集、高精度和多模式数据整合，该基准数据集支持对传感器的稳健分析以及先进重建方法的发展。此外，我们还探索了下游任务，展示了TUM2TWIN的潜力，包括NeRF和高斯贴图的全新视图合成、太阳能潜力分析、点云语义分割和LOD3建筑重建。我们相信这一贡献为克服UDTs创建中的当前局限性奠定了基础，并促进了智能、数据驱动的城市环境的新研究方向和实际解决方案的发展。该项目网址为：[<a target="_blank" rel="noopener" href="https://tum2t.win/]">https://tum2t.win/]</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07396v1">PDF</a> Submitted to the ISPRS Journal of Photogrammetry and Remote Sensing</p>
<p><strong>Summary</strong></p>
<p>本文介绍了城市数字双胞胎（UDTs）在管理城市和整合复杂、异构数据方面的作用。针对创建UDTs所面临的挑战，如获取准确的3D源数据、重建高保真3D模型等，研究者引入了首个多模式城市数字双胞胎基准数据集TUM2TWIN。该数据集包含地理参考的语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测数据，包含约10万平米的约含超过数据子集高达32个的共767GB的数据。该基准数据集支持传感器稳健性分析和发展高级重建方法的研究。此数据集对城市数字双胞胎的下游任务具有潜力，包括新型视图合成和太阳能潜力分析等。本项目的贡献为克服UDT创建中的现有局限性奠定了基石，并为更智能的数据驱动城市环境的研究和实际应用提供了方向。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>城市数字双胞胎（UDTs）对于城市管理和整合复杂数据至关重要。</li>
<li>创建UDTs面临多个挑战，如获取准确数据、模型重建等。</li>
<li>TUM2TWIN是首个多模式城市数字双胞胎基准数据集，包含丰富的地理参考数据。</li>
<li>TUM2TWIN包含地面、移动、空中和卫星等多种观测数据，并支持传感器稳健性分析和高级重建方法的发展。</li>
<li>该数据集有助于多种下游任务，如新型视图合成和太阳能潜力分析。</li>
<li>TUM2TWIN为克服UDT创建中的局限性提供了基础。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07396">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-4aa1bb0783a929ae45bc5a20d247aecb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d2c04c9186e2d3af46c3370e418625d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b84a340c0778072c0bc4ba3574de24ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb439d15b23eec98ae5b0ce75e646dc2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="TeGA-Texture-Space-Gaussian-Avatars-for-High-Resolution-Dynamic-Head-Modeling"><a href="#TeGA-Texture-Space-Gaussian-Avatars-for-High-Resolution-Dynamic-Head-Modeling" class="headerlink" title="TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head   Modeling"></a>TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head   Modeling</h2><p><strong>Authors:Gengyan Li, Paulo Gotardo, Timo Bolkart, Stephan Garbin, Kripasindhu Sarkar, Abhimitra Meka, Alexandros Lattas, Thabo Beeler</strong></p>
<p>Sparse volumetric reconstruction and rendering via 3D Gaussian splatting have recently enabled animatable 3D head avatars that are rendered under arbitrary viewpoints with impressive photorealism. Today, such photoreal avatars are seen as a key component in emerging applications in telepresence, extended reality, and entertainment. Building a photoreal avatar requires estimating the complex non-rigid motion of different facial components as seen in input video images; due to inaccurate motion estimation, animatable models typically present a loss of fidelity and detail when compared to their non-animatable counterparts, built from an individual facial expression. Also, recent state-of-the-art models are often affected by memory limitations that reduce the number of 3D Gaussians used for modeling, leading to lower detail and quality. To address these problems, we present a new high-detail 3D head avatar model that improves upon the state of the art, largely increasing the number of 3D Gaussians and modeling quality for rendering at 4K resolution. Our high-quality model is reconstructed from multiview input video and builds on top of a mesh-based 3D morphable model, which provides a coarse deformation layer for the head. Photoreal appearance is modelled by 3D Gaussians embedded within the continuous UVD tangent space of this mesh, allowing for more effective densification where most needed. Additionally, these Gaussians are warped by a novel UVD deformation field to capture subtle, localized motion. Our key contribution is the novel deformable Gaussian encoding and overall fitting procedure that allows our head model to preserve appearance detail, while capturing facial motion and other transient high-frequency features such as skin wrinkling. </p>
<blockquote>
<p>通过3D高斯贴图（Gaussian Splatting）进行稀疏体积重建和渲染，最近已经能够实现可动画的3D头像，这些头像可在任意视点以令人印象深刻的逼真度进行渲染。如今，这种逼真的头像被视为远程存在、扩展现实和娱乐等新兴应用中的关键组成部分。构建逼真的头像需要估计输入视频图像中不同面部组件的复杂非刚性运动；由于运动估计不准确，与不可动画的同行相比，可动画模型在细节和保真度方面通常会损失。此外，最新技术模型通常受到内存限制的影响，减少了用于建模的3D高斯数量，导致细节和质量下降。为了解决这些问题，我们提出了一种新的高细节3D头像模型，该模型改进了现有技术，大大提高了用于以4K分辨率渲染的3D高斯数量和建模质量。我们的高质量模型是从多视角输入视频重建的，并基于网格化的3D可变形模型进行构建，该模型为头部提供了一个粗略的变形层。通过嵌入到此网格的连续UVD切线空间中的3D高斯来模拟逼真的外观，允许在需要的地方更有效地密集化。此外，这些高斯被一个新型的UVD变形场扭曲以捕捉微妙的局部运动。我们的主要贡献是可变形的高斯编码和整体拟合程序，这使我们能够保留头像的细节，同时捕捉面部运动和其他瞬态高频特征，如皮肤皱纹。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05672v1">PDF</a> 10 pages, 9 figures, supplementary results found at:   <a target="_blank" rel="noopener" href="https://syntec-research.github.io/UVGA/">https://syntec-research.github.io/UVGA/</a>, to be published in SIGGRAPH 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了通过3D高斯贴图技术实现的高细节三维头像模型。该模型能够从多角度视频输入中重建和渲染，具有动画功能，并在4K分辨率下呈现出令人印象深刻的逼真度。模型基于网格的3D可变形模型提供粗糙的头部变形层，而真实感的外观则是通过嵌入到此网格的连续UVD切线空间的3D高斯实现的。此外，通过新颖的UVD变形场对高斯进行变形，以捕捉细微的局部运动。主要贡献在于可变形的高斯编码和整体拟合程序，允许头像模型在捕捉面部运动和其他短暂的高频特征（如皮肤皱纹）的同时保留外观细节。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3D高斯贴图技术用于创建高细节三维头像模型。</li>
<li>模型能够从多角度视频输入中重建和渲染，具有动画功能。</li>
<li>模型在4K分辨率下呈现逼真的效果。</li>
<li>网格的3D可变形模型提供头部的粗糙变形层。</li>
<li>真实感的外观通过嵌入到网格UVD切线空间的3D高斯实现。</li>
<li>通过UVD变形场捕捉细微的局部运动。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05672">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-73141454d1281979d196289c51a638aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c6157a09ca162bb008b2e3442ff80c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-488da624cb2cffbd3cd9bf3963354e17.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="UltraGauss-Ultrafast-Gaussian-Reconstruction-of-3D-Ultrasound-Volumes"><a href="#UltraGauss-Ultrafast-Gaussian-Reconstruction-of-3D-Ultrasound-Volumes" class="headerlink" title="UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes"></a>UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes</h2><p><strong>Authors:Mark C. Eid, Ana I. L. Namburete, João F. Henriques</strong></p>
<p>Ultrasound imaging is widely used due to its safety, affordability, and real-time capabilities, but its 2D interpretation is highly operator-dependent, leading to variability and increased cognitive demand. 2D-to-3D reconstruction mitigates these challenges by providing standardized volumetric views, yet existing methods are often computationally expensive, memory-intensive, or incompatible with ultrasound physics. We introduce UltraGauss: the first ultrasound-specific Gaussian Splatting framework, extending view synthesis techniques to ultrasound wave propagation. Unlike conventional perspective-based splatting, UltraGauss models probe-plane intersections in 3D, aligning with acoustic image formation. We derive an efficient rasterization boundary formulation for GPU parallelization and introduce a numerically stable covariance parametrization, improving computational efficiency and reconstruction accuracy. On real clinical ultrasound data, UltraGauss achieves state-of-the-art reconstructions in 5 minutes, and reaching 0.99 SSIM within 20 minutes on a single GPU. A survey of expert clinicians confirms UltraGauss’ reconstructions are the most realistic among competing methods. Our CUDA implementation will be released upon publication. </p>
<blockquote>
<p>超声波成像因其安全性、可负担性和实时功能而得到广泛应用，但其二维解读高度依赖于操作人员，导致可变性和认知需求增加。二维到三维重建通过提供标准化体积视图来缓解这些挑战，但现有方法往往计算量大、内存密集，或与超声物理不兼容。我们推出了UltraGauss：首个专门针对超声的高斯喷绘框架，将视图合成技术扩展到超声波传播。与基于传统透视的喷绘不同，UltraGauss在三维空间中模拟探针平面交点，与声成像形成对齐。我们为GPU并行化推导了高效的栅格化边界公式，并引入数值稳定的协方差参数化，提高了计算效率和重建精度。在真实的临床超声数据上，UltraGauss在5分钟内实现了最先进的重建效果，并在单个GPU上20分钟内达到0.99的结构相似性度量指数。专家医生的调查证实，UltraGauss的重建效果在竞争方法中最为现实。我们的CUDA实现将在发表时发布。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05643v1">PDF</a> </p>
<p><strong>摘要</strong><br>超声成像因其安全性、经济性和实时性能而得到广泛应用，但其二维解释高度依赖于操作者，导致差异性和认知需求增加。二维到三维重建通过提供标准化体积视图来缓解这些挑战，但现有方法往往计算量大、内存密集或与超声物理不兼容。本文介绍UltraGauss：首个超声专用高斯Splatting框架，将视图合成技术扩展到超声波传播。与传统的基于透视的Splatting不同，UltraGauss在三维空间中模拟探针平面交点，与声学图像形成相一致。我们推导了一种高效的栅格化边界公式，用于GPU并行化，并引入了一种数值稳定的协方差参数化，提高了计算效率和重建精度。在真实临床超声数据上，UltraGauss在5分钟内实现最先进的重建效果，在单个GPU上20分钟内结构相似性度量（SSIM）达到0.99。专家医生的调查显示，UltraGauss的重建效果在竞品方法中最为真实。我们的CUDA实现将在发表时发布。</p>
<p><strong>要点提炼</strong></p>
<ol>
<li>超声成像虽然广泛应用，但其二维解释存在操作者依赖性问题，导致差异和认知需求增加。</li>
<li>二维到三维重建是解决此问题的一种方法，但现有方法存在计算量大、内存密集或与超声物理不兼容的问题。</li>
<li>UltraGauss是首个超声专用高斯Splatting框架，将视图合成技术扩展到超声波传播，实现三维重建。</li>
<li>UltraGauss采用高效的栅格化边界公式和数值稳定的协方差参数化，提高计算效率和重建精度。</li>
<li>在真实临床数据测试中，UltraGauss达到先进的重建效果，结构相似性度量（SSIM）高。</li>
<li>专家医生评价UltraGauss的重建效果最为真实。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05643">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-67ab39ccc18a89ee2f463cc39d30befa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-89b50887cd73a2f0c2f25478ee7d9955.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bee25bc55974e902e64d492230a53bfc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-884ddeda2439cacb2ec1867d1a34d9cb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-46564ee9dfab0833bee697f9ee26de26.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="QuickSplat-Fast-3D-Surface-Reconstruction-via-Learned-Gaussian-Initialization"><a href="#QuickSplat-Fast-3D-Surface-Reconstruction-via-Learned-Gaussian-Initialization" class="headerlink" title="QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian   Initialization"></a>QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian   Initialization</h2><p><strong>Authors:Yueh-Cheng Liu, Lukas Höllein, Matthias Nießner, Angela Dai</strong></p>
<p>Surface reconstruction is fundamental to computer vision and graphics, enabling applications in 3D modeling, mixed reality, robotics, and more. Existing approaches based on volumetric rendering obtain promising results, but optimize on a per-scene basis, resulting in a slow optimization that can struggle to model under-observed or textureless regions. We introduce QuickSplat, which learns data-driven priors to generate dense initializations for 2D gaussian splatting optimization of large-scale indoor scenes. This provides a strong starting point for the reconstruction, which accelerates the convergence of the optimization and improves the geometry of flat wall structures. We further learn to jointly estimate the densification and update of the scene parameters during each iteration; our proposed densifier network predicts new Gaussians based on the rendering gradients of existing ones, removing the needs of heuristics for densification. Extensive experiments on large-scale indoor scene reconstruction demonstrate the superiority of our data-driven optimization. Concretely, we accelerate runtime by 8x, while decreasing depth errors by up to 48% in comparison to state of the art methods. </p>
<blockquote>
<p>表面重建是计算机视觉和图形学的基础，在3D建模、混合现实、机器人技术等领域有着广泛的应用。现有的基于体积渲染的方法虽然取得了有前景的结果，但它们是针对每个场景进行优化，导致优化过程缓慢，并且在观测不足或无纹理区域建模时遇到困难。我们引入了QuickSplat方法，该方法学习数据驱动先验知识，为大规模室内场景的2D高斯绘制优化生成密集初始化。这为重建提供了一个强有力的起点，加速了优化的收敛，并改善了平面墙结构的几何形状。我们进一步学习在每次迭代中联合估计场景的参数密集化和更新；我们提出的稠密网络根据现有渲染梯度预测新的高斯分布，无需启发式方法进行密集化。大规模室内场景重建的广泛实验表明，我们的数据驱动优化具有优越性。具体来说，我们的方法将运行时速度提高了8倍，与最新技术相比，深度误差减少了高达48%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05591v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://liu115.github.io/quicksplat">https://liu115.github.io/quicksplat</a>, Video:   <a target="_blank" rel="noopener" href="https://youtu.be/2IA_gnFvFG8">https://youtu.be/2IA_gnFvFG8</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了QuickSplat方法，该方法利用数据驱动先验生成大规模室内场景的密集初始化，用于二维高斯涂抹优化。此方法为重建提供了一个良好的起点，加速了优化的收敛，并改进了平面墙结构的几何形状。通过联合估计场景参数的密集化和更新，提出了一个预测高斯密度的新网络，提高了渲染效果并提升了运行效率。实验结果表明，相较于当前先进方法，QuickSplat具有显著优势，运行时速提高了8倍，深度误差降低了高达48%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QuickSplat是一种用于大规模室内场景重建的方法，利用数据驱动先验生成密集初始化进行二维高斯涂抹优化。</li>
<li>提供了良好的起点用于重建，从而加速了优化的收敛并改善了平面墙结构的几何形状。</li>
<li>通过联合估计场景参数的密集化和更新，提高了渲染效果。</li>
<li>提出了一种新的网络结构来预测高斯密度，基于现有渲染梯度的学习来消除密集化的启发式需求。</li>
<li>QuickSplat方法在运行时速度方面显著提高，相对于现有技术，其速度提高了8倍。</li>
<li>与当前先进方法相比，QuickSplat在深度误差方面表现出显著优势，降低了高达48%的深度误差。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05591">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-49b51180611c5ec7e6a7de12417e7654.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71d4409d76acd59a2c3af59d18a0408a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8716ce75fd182355600528c2fd5ef77.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4184cb0018cdfaaf62df64e57cddee88.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Steepest-Descent-Density-Control-for-Compact-3D-Gaussian-Splatting"><a href="#Steepest-Descent-Density-Control-for-Compact-3D-Gaussian-Splatting" class="headerlink" title="Steepest Descent Density Control for Compact 3D Gaussian Splatting"></a>Steepest Descent Density Control for Compact 3D Gaussian Splatting</h2><p><strong>Authors:Peihao Wang, Yuehao Wang, Dilin Wang, Sreyas Mohan, Zhiwen Fan, Lemeng Wu, Ruisi Cai, Yu-Ying Yeh, Zhangyang Wang, Qiang Liu, Rakesh Ranjan</strong></p>
<p>3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time, high-resolution novel view synthesis. By representing scenes as a mixture of Gaussian primitives, 3DGS leverages GPU rasterization pipelines for efficient rendering and reconstruction. To optimize scene coverage and capture fine details, 3DGS employs a densification algorithm to generate additional points. However, this process often leads to redundant point clouds, resulting in excessive memory usage, slower performance, and substantial storage demands - posing significant challenges for deployment on resource-constrained devices. To address this limitation, we propose a theoretical framework that demystifies and improves density control in 3DGS. Our analysis reveals that splitting is crucial for escaping saddle points. Through an optimization-theoretic approach, we establish the necessary conditions for densification, determine the minimal number of offspring Gaussians, identify the optimal parameter update direction, and provide an analytical solution for normalizing off-spring opacity. Building on these insights, we introduce SteepGS, incorporating steepest density control, a principled strategy that minimizes loss while maintaining a compact point cloud. SteepGS achieves a ~50% reduction in Gaussian points without compromising rendering quality, significantly enhancing both efficiency and scalability. </p>
<blockquote>
<p>3D高斯展平（3DGS）作为一种强大的实时高分辨率新视角合成技术已崭露头角。通过将场景表示为高斯原始数据的混合物，3DGS利用GPU光栅化管道进行高效渲染和重建。为了优化场景覆盖并捕捉细节，3DGS采用致密化算法生成额外的点。然而，这一过程通常会导致冗余的点云，从而导致内存使用过多、性能下降和存储需求巨大，对资源受限设备的部署构成了重大挑战。为了解决这一局限性，我们提出了一个理论框架，揭秘并改进了3DGS中的密度控制。我们的分析表明，分裂对于逃避鞍点至关重要。通过优化理论方法，我们确定了致密化的必要条件，确定了子代高斯的最小数量，确定了参数更新的最优方向，并为子代不透明度的归一化提供了分析解决方案。基于这些见解，我们引入了SteepGS，结合了最陡密度控制策略，该策略在保持紧凑点云的同时最小化损失。SteepGS在不损害渲染质量的情况下实现了高斯点约50%的减少，显著提高了效率和可扩展性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05587v1">PDF</a> CVPR 2025, Project page: <a target="_blank" rel="noopener" href="https://vita-group.github.io/SteepGS/">https://vita-group.github.io/SteepGS/</a></p>
<p><strong>Summary</strong></p>
<p>实时高保真视角合成中的三维高斯融合技术（3DGS）通过高斯原始混合表示场景，利用GPU光栅化管道实现高效渲染与重建。为提高场景覆盖率和精细细节捕捉，3DGS采用稠密化算法生成额外点，但易产生冗余点云，导致内存使用过度、性能下降及存储需求增大，给资源受限设备带来挑战。本研究提出理论框架解析并优化密度控制问题，建立必要稠密化条件，确定最小高斯子代数量，提供子代透明度分析解决方案。基于这些见解，引入SteepGS技术，采用最陡密度控制策略，在减少损失的同时维持紧凑点云，实现高斯点数减少约50%，提升效率和可扩展性而不损失渲染质量。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS是实时高保真视角合成中的强大技术，通过高斯原始混合表示场景。</li>
<li>3DGS利用GPU进行高效渲染和重建，并采用稠密化算法捕捉场景细节。</li>
<li>冗余点云问题导致内存消耗大、性能下降和存储需求增加。</li>
<li>本研究提出了理论框架改善密度控制问题并建立必要的稠密化条件。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05587">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-3af788adcb61b99c75f767b96ed1725d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cd9c2d9d78eaeafcb854c7f9369c35f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a6dd55308b52e64f02a125920c955c85.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Apply-Hierarchical-Chain-of-Generation-to-Complex-Attributes-Text-to-3D-Generation"><a href="#Apply-Hierarchical-Chain-of-Generation-to-Complex-Attributes-Text-to-3D-Generation" class="headerlink" title="Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D   Generation"></a>Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D   Generation</h2><p><strong>Authors:Yiming Qin, Zhu Xu, Yang Liu</strong></p>
<p>Recent text-to-3D models can render high-quality assets, yet they still stumble on objects with complex attributes. The key obstacles are: (1) existing text-to-3D approaches typically lift text-to-image models to extract semantics via text encoders, while the text encoder exhibits limited comprehension ability for long descriptions, leading to deviated cross-attention focus, subsequently wrong attribute binding in generated results. (2) Occluded object parts demand a disciplined generation order and explicit part disentanglement. Though some works introduce manual efforts to alleviate the above issues, their quality is unstable and highly reliant on manual information. To tackle above problems, we propose a automated method Hierarchical-Chain-of-Generation (HCoG). It leverages a large language model to decompose the long description into blocks representing different object parts, and orders them from inside out according to occlusions, forming a hierarchical chain. Within each block we first coarsely create components, then precisely bind attributes via target-region localization and corresponding 3D Gaussian kernel optimization. Between blocks, we introduce Gaussian Extension and Label Elimination to seamlessly generate new parts by extending new Gaussian kernels, re-assigning semantic labels, and eliminating unnecessary kernels, ensuring that only relevant parts are added without disrupting previously optimized parts. Experiments confirm that HCoG yields structurally coherent, attribute-faithful 3D objects with complex attributes. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Wakals/GASCOL">https://github.com/Wakals/GASCOL</a> . </p>
<blockquote>
<p>虽然最近的文本到3D模型可以呈现高质量的资产，但它们在处理具有复杂属性的对象时仍然会遇到困难。主要障碍是：（1）现有的文本到3D的方法通常将文本到图像模型提升为通过文本编码器提取语义，而文本编码器对于长描述的理解能力有限，导致交叉注意力焦点偏离，进而在生成结果中出现错误的属性绑定。（2）被遮挡的对象部分需要有序的生成顺序和明确的部件分离。虽然一些工作引入了手动努力来缓解上述问题，但其质量不稳定，高度依赖于手动信息。为了解决上述问题，我们提出了一种自动方法——分层生成链（HCoG）。它利用大型语言模型将长描述分解为表示不同对象部分的块，并根据遮挡情况从内到外进行排序，形成分层链。在每个块内，我们首先粗略地创建组件，然后通过目标区域定位和相应的3D高斯核优化精确地绑定属性。在块之间，我们引入了高斯扩展和标签消除，通过扩展新的高斯核、重新分配语义标签和消除不必要的核，无缝地生成新的部分，确保只添加相关的部分，而不破坏之前优化过的部分。实验证实，HCoG能够生成结构连贯、属性忠实的具有复杂属性的3D对象。代码可在<a target="_blank" rel="noopener" href="https://github.com/Wakals/GASCOL%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Wakals/GASCOL中找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05505v1">PDF</a> Project page here:   <a target="_blank" rel="noopener" href="https://hierarchical-chain-of-generation.github.io/">https://hierarchical-chain-of-generation.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>该文指出当前文本到3D模型的转换技术在处理具有复杂属性的对象时存在挑战。主要障碍包括：文本编码器对长描述的理解能力有限，导致跨注意力焦点偏差，进而在生成结果中出现属性绑定错误；对于被遮挡的对象部分，需要有序生成和明确的部件分解。针对这些问题，提出了Hierarchical-Chain-of-Generation（HCoG）方法，利用大型语言模型将长描述分解为表示不同对象部分的块，并根据遮挡情况从内到外进行排序，形成层次链。在每个块内，首先粗略创建组件，然后通过目标区域定位和相应的3D高斯核优化来精确绑定属性。实验证实，HCoG能够生成结构连贯、属性真实的具有复杂属性的3D对象。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>当前文本到3D模型的转换技术在处理复杂属性对象时存在挑战。</li>
<li>主要障碍包括文本编码器对长描述理解有限，导致属性绑定错误，以及被遮挡对象部分的处理问题。</li>
<li>HCoG方法利用大型语言模型将描述分解为表示不同对象部分的块，并根据遮挡情况排序。</li>
<li>HCoG在每个块内先粗略创建组件，再通过定位和目标区域优化精确绑定属性。</li>
<li>HCoG通过Gaussian Extension和Label Elimination在不同块之间生成新部分，通过扩展高斯核、重新分配语义标签和消除不必要的核，确保只添加相关部分而不会破坏已优化的部分。</li>
<li>实验证实HCoG能够生成结构连贯、属性真实的3D对象。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05505">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-14e35d9ccaa48c28edb2801be266324a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c485ca353b8cf022a77f52009b9c1855.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-593734e2201e97b33519b2e1dac0ee80.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-14/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-14/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-14/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e31676b64bce418610fd0cae36d7bb02.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-05-14  TUM2TWIN Introducing the Large-Scale Multimodal Urban Digital Twin   Benchmark Dataset
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-14/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-bdad0659468281e04fcc77244f71ae22.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-05-14  MAGEA Multi-stage Avatar Generator with Sparse Observations
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">18179.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
