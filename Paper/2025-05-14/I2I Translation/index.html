<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-14  Pixel Motion as Universal Representation for Robot Control">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-edee906e9a345f0ac2a02462149c7882.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-14-æ›´æ–°"><a href="#2025-05-14-æ›´æ–°" class="headerlink" title="2025-05-14 æ›´æ–°"></a>2025-05-14 æ›´æ–°</h1><h2 id="Pixel-Motion-as-Universal-Representation-for-Robot-Control"><a href="#Pixel-Motion-as-Universal-Representation-for-Robot-Control" class="headerlink" title="Pixel Motion as Universal Representation for Robot Control"></a>Pixel Motion as Universal Representation for Robot Control</h2><p><strong>Authors:Kanchana Ranasinghe, Xiang Li, Cristina Mata, Jongwoo Park, Michael S Ryoo</strong></p>
<p>We present LangToMo, a vision-language-action framework structured as a dual-system architecture that uses pixel motion forecasts as intermediate representations. Our high-level System 2, an image diffusion model, generates text-conditioned pixel motion sequences from a single frame to guide robot control. Pixel motion-a universal, interpretable, and motion-centric representation-can be extracted from videos in a self-supervised manner, enabling diffusion model training on web-scale video-caption data. Treating generated pixel motion as learned universal representations, our low level System 1 module translates these into robot actions via motion-to-action mapping functions, which can be either hand-crafted or learned with minimal supervision. System 2 operates as a high-level policy applied at sparse temporal intervals, while System 1 acts as a low-level policy at dense temporal intervals. This hierarchical decoupling enables flexible, scalable, and generalizable robot control under both unsupervised and supervised settings, bridging the gap between language, motion, and action. Checkout <a target="_blank" rel="noopener" href="https://kahnchana.github.io/LangToMo">https://kahnchana.github.io/LangToMo</a> for visualizations. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†LangToMoï¼Œè¿™æ˜¯ä¸€ä¸ªè§†è§‰-è¯­è¨€-è¡ŒåŠ¨æ¡†æ¶ï¼Œé‡‡ç”¨åŒç³»ç»Ÿæ¶æ„ï¼Œåˆ©ç”¨åƒç´ è¿åŠ¨é¢„æµ‹ä½œä¸ºä¸­é—´è¡¨ç¤ºã€‚æˆ‘ä»¬çš„é«˜çº§ç³»ç»Ÿ2æ˜¯ä¸€ä¸ªå›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œä»å•å¸§ç”Ÿæˆæ–‡æœ¬è°ƒèŠ‚çš„åƒç´ è¿åŠ¨åºåˆ—ï¼Œä»¥æŒ‡å¯¼æœºå™¨äººæ§åˆ¶ã€‚åƒç´ è¿åŠ¨æ˜¯ä¸€ç§é€šç”¨ã€å¯è§£é‡Šã€ä»¥è¿åŠ¨ä¸ºä¸­å¿ƒçš„è¡¨ç¤ºï¼Œå¯ä»¥ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼ä»è§†é¢‘ä¸­æå–ï¼Œä½¿å¾—æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿåœ¨ç½‘é¡µè§„æ¨¡çš„è§†é¢‘å­—å¹•æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚å°†ç”Ÿæˆçš„åƒç´ è¿åŠ¨è§†ä¸ºå­¦ä¹ çš„é€šç”¨è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„ä½çº§ç³»ç»Ÿ1æ¨¡å—é€šè¿‡è¿åŠ¨åˆ°åŠ¨ä½œçš„æ˜ å°„åŠŸèƒ½å°†è¿™äº›è¡¨ç¤ºè½¬æ¢ä¸ºæœºå™¨äººåŠ¨ä½œï¼Œè¿™äº›æ˜ å°„åŠŸèƒ½å¯ä»¥æ˜¯æ‰‹å·¥åˆ¶ä½œçš„ï¼Œæˆ–è€…é€šè¿‡æœ€å°çš„ç›‘ç£è¿›è¡Œå­¦ä¹ ã€‚ç³»ç»Ÿ2ä½œä¸ºé«˜çº§ç­–ç•¥ï¼Œåœ¨ç¨€ç–çš„æ—¶é—´é—´éš”å†…åº”ç”¨ï¼Œè€Œç³»ç»Ÿ1ä½œä¸ºä½çº§ç­–ç•¥åœ¨å¯†é›†çš„æ—¶é—´é—´éš”å†…è¡ŒåŠ¨ã€‚è¿™ç§åˆ†å±‚è§£è€¦ä½¿å¾—åœ¨æ— äººç›‘ç£å’Œæœ‰äººç›‘ç£çš„ç¯å¢ƒä¸‹ï¼Œæœºå™¨äººæ§åˆ¶æ›´åŠ çµæ´»ã€å¯æ‰©å±•å’Œé€šç”¨ï¼Œåœ¨è¯­è¨€ã€è¿åŠ¨å’ŒåŠ¨ä½œä¹‹é—´æ­å»ºäº†æ¡¥æ¢ã€‚æƒ³äº†è§£æ›´å¤šå¯è§†åŒ–å†…å®¹ï¼Œè¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://kahnchana.github.io/LangToMo%E3%80%82">https://kahnchana.github.io/LangToMoã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07817v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>LangToMoæ˜¯ä¸€ä¸ªè§†è§‰è¯­è¨€åŠ¨ä½œæ¡†æ¶ï¼Œé‡‡ç”¨åŒç³»ç»Ÿæ¶æ„ï¼Œä»¥åƒç´ è¿åŠ¨é¢„æµ‹ä½œä¸ºä¸­é—´è¡¨ç¤ºå½¢å¼ã€‚å…¶é«˜çº§ç³»ç»Ÿ2é‡‡ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å•ä¸€å¸§ç”Ÿæˆæ–‡æœ¬æ§åˆ¶çš„åƒç´ è¿åŠ¨åºåˆ—ï¼ŒæŒ‡å¯¼æœºå™¨äººæ§åˆ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼ä»è§†é¢‘ä¸­æå–åƒç´ è¿åŠ¨ï¼Œä½¿æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿåœ¨ç½‘é¡µè§„æ¨¡çš„è§†é¢‘æè¿°æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚å°†ç”Ÿæˆçš„åƒç´ è¿åŠ¨è§†ä¸ºå­¦ä¹ çš„é€šç”¨è¡¨ç¤ºï¼Œå…¶ä½çº§ç³»ç»Ÿ1æ¨¡å—é€šè¿‡è¿åŠ¨åˆ°åŠ¨ä½œçš„æ˜ å°„å‡½æ•°å°†è¿™äº›è¡¨ç¤ºè½¬æ¢ä¸ºæœºå™¨äººåŠ¨ä½œï¼Œè¿™äº›æ˜ å°„å‡½æ•°å¯ä»¥æ˜¯æ‰‹å·¥åˆ¶ä½œçš„ï¼Œä¹Ÿå¯ä»¥ä»¥æœ€å°‘çš„ç›‘ç£è¿›è¡Œå­¦ä¹ ã€‚ç³»ç»Ÿ2ä½œä¸ºé«˜çº§ç­–ç•¥åœ¨ç¨€ç–æ—¶é—´é—´éš”å†…è¿è¡Œï¼Œè€Œç³»ç»Ÿ1ä½œä¸ºä½çº§ç­–ç•¥åœ¨å¯†é›†æ—¶é—´é—´éš”å†…è¿è¡Œã€‚è¿™ç§åˆ†å±‚è§£è€¦å®ç°äº†çµæ´»çš„ã€å¯æ‰©å±•çš„å’Œé€šç”¨çš„æœºå™¨äººæ§åˆ¶ï¼Œæ— è®ºæ˜¯åœ¨æ— ç›‘ç£è¿˜æ˜¯ç›‘ç£è®¾ç½®ä¸‹éƒ½èƒ½ç¼©å°è¯­è¨€ã€åŠ¨ä½œå’Œè¡Œä¸ºä¹‹é—´çš„å·®è·ã€‚æ›´å¤šå¯è§†åŒ–å†…å®¹è¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://kahnchana.github.io/LangToMo">ç½‘ç«™é“¾æ¥</a>ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>LangToMoæ˜¯ä¸€ä¸ªè§†è§‰è¯­è¨€åŠ¨ä½œæ¡†æ¶ï¼Œå…·æœ‰åŒç³»ç»Ÿæ¶æ„ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨åƒç´ è¿åŠ¨é¢„æµ‹ä½œä¸ºä¸­é—´è¡¨ç¤ºå½¢å¼ã€‚</li>
<li>é«˜çº§ç³»ç»Ÿ2é‡‡ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆæ–‡æœ¬æ§åˆ¶çš„åƒç´ è¿åŠ¨åºåˆ—æ¥æŒ‡å¯¼æœºå™¨äººæ§åˆ¶ã€‚</li>
<li>åƒç´ è¿åŠ¨å¯ä»¥é€šè¿‡è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼ä»è§†é¢‘ä¸­æå–ã€‚</li>
<li>ä½çº§ç³»ç»Ÿ1æ¨¡å—å°†åƒç´ è¿åŠ¨è½¬æ¢ä¸ºæœºå™¨äººåŠ¨ä½œã€‚</li>
<li>è¯¥æ¡†æ¶å®ç°äº†çµæ´»çš„ã€å¯æ‰©å±•çš„å’Œé€šç”¨çš„æœºå™¨äººæ§åˆ¶ã€‚</li>
<li>è¯¥æ¡†æ¶ç¼©å°äº†è¯­è¨€ã€åŠ¨ä½œå’Œè¡Œä¸ºä¹‹é—´çš„å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07817">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d11023be20cecd0201fdd7906c09d848.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ad3b5f9870cba040fbbb8c0d51d33e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a790d0112804c367a250230bd155572.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ABS-Mamba-SAM2-Driven-Bidirectional-Spiral-Mamba-Network-for-Medical-Image-Translation"><a href="#ABS-Mamba-SAM2-Driven-Bidirectional-Spiral-Mamba-Network-for-Medical-Image-Translation" class="headerlink" title="ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical   Image Translation"></a>ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical   Image Translation</h2><p><strong>Authors:Feng Yuan, Yifan Gao, Wenbin Wu, Keqing Wu, Xiaotong Guo, Jie Jiang, Xin Gao</strong></p>
<p>Accurate multi-modal medical image translation requires ha-rmonizing global anatomical semantics and local structural fidelity, a challenge complicated by intermodality information loss and structural distortion. We propose ABS-Mamba, a novel architecture integrating the Segment Anything Model 2 (SAM2) for organ-aware semantic representation, specialized convolutional neural networks (CNNs) for preserving modality-specific edge and texture details, and Mambaâ€™s selective state-space modeling for efficient long- and short-range feature dependencies. Structurally, our dual-resolution framework leverages SAM2â€™s image encoder to capture organ-scale semantics from high-resolution inputs, while a parallel CNNs branch extracts fine-grained local features. The Robust Feature Fusion Network (RFFN) integrates these epresentations, and the Bidirectional Mamba Residual Network (BMRN) models spatial dependencies using spiral scanning and bidirectional state-space dynamics. A three-stage skip fusion decoder enhances edge and texture fidelity. We employ Efficient Low-Rank Adaptation (LoRA+) fine-tuning to enable precise domain specialization while maintaining the foundational capabilities of the pre-trained components. Extensive experimental validation on the SynthRAD2023 and BraTS2019 datasets demonstrates that ABS-Mamba outperforms state-of-the-art methods, delivering high-fidelity cross-modal synthesis that preserves anatomical semantics and structural details to enhance diagnostic accuracy in clinical applications. The code is available at <a target="_blank" rel="noopener" href="https://github.com/gatina-yone/ABS-Mamba">https://github.com/gatina-yone/ABS-Mamba</a> </p>
<blockquote>
<p>ç²¾ç¡®çš„å¤šæ¨¡æ€åŒ»å­¦å›¾åƒç¿»è¯‘éœ€è¦åè°ƒå…¨å±€è§£å‰–è¯­ä¹‰å’Œå±€éƒ¨ç»“æ„ä¿çœŸåº¦ï¼Œè¿™ä¸€æŒ‘æˆ˜å› æ¨¡æ€é—´ä¿¡æ¯ä¸¢å¤±å’Œç»“æ„å¤±çœŸè€Œå¤æ‚åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†ABS-Mambaï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ¶æ„ï¼Œå®ƒé›†æˆäº†Segment Anything Model 2ï¼ˆSAM2ï¼‰ç”¨äºå™¨å®˜æ„ŸçŸ¥è¯­ä¹‰è¡¨ç¤ºï¼Œä¸“ä¸šåŒ–çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ç”¨äºä¿ç•™æ¨¡æ€ç‰¹å®šçš„è¾¹ç¼˜å’Œçº¹ç†ç»†èŠ‚ï¼Œä»¥åŠMambaçš„é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´å»ºæ¨¡ï¼Œä»¥å®ç°é«˜æ•ˆçš„é•¿çŸ­ç¨‹ç‰¹å¾ä¾èµ–æ€§ã€‚ç»“æ„ä¸Šï¼Œæˆ‘ä»¬çš„åŒåˆ†è¾¨ç‡æ¡†æ¶åˆ©ç”¨SAM2çš„å›¾åƒç¼–ç å™¨æ•è·æ¥è‡ªé«˜åˆ†è¾¨ç‡è¾“å…¥çš„ç»„ç»‡è§„æ¨¡è¯­ä¹‰ï¼Œè€Œå¹¶è¡ŒCNNåˆ†æ”¯åˆ™æå–ç²¾ç»†çš„å±€éƒ¨ç‰¹å¾ã€‚é²æ£’çš„ç‰¹å¾èåˆç½‘ç»œï¼ˆRFFNï¼‰é›†æˆäº†è¿™äº›è¡¨ç¤ºï¼ŒåŒå‘Mambaæ®‹å·®ç½‘ç»œï¼ˆBMRNï¼‰ä½¿ç”¨èºæ—‹æ‰«æå’ŒåŒå‘çŠ¶æ€ç©ºé—´åŠ¨åŠ›å­¦å¯¹ç©ºé—´ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡ã€‚ä¸‰é˜¶æ®µè·³è¿‡èåˆè§£ç å™¨å¢å¼ºäº†è¾¹ç¼˜å’Œçº¹ç†çš„ä¿çœŸåº¦ã€‚æˆ‘ä»¬é‡‡ç”¨æœ‰æ•ˆçš„ä½ç§©é€‚åº”ï¼ˆLoRA+ï¼‰å¾®è°ƒæ–¹æ³•ï¼Œä»¥å®ç°ç²¾ç¡®çš„é¢†åŸŸä¸“ä¸šåŒ–ï¼ŒåŒæ—¶ä¿æŒé¢„è®­ç»ƒç»„ä»¶çš„åŸºæœ¬åŠŸèƒ½ã€‚åœ¨SynthRAD2023å’ŒBraTS2019æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯è¡¨æ˜ï¼ŒABS-Mambaä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œå®ç°äº†é«˜ä¿çœŸåº¦çš„è·¨æ¨¡æ€åˆæˆï¼Œä¿ç•™äº†è§£å‰–è¯­ä¹‰å’Œç»“æ„ç»†èŠ‚ï¼Œæé«˜äº†ä¸´åºŠåº”ç”¨ä¸­è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚ä»£ç å¯ç”¨åœ¨<a target="_blank" rel="noopener" href="https://github.com/gatina-yone/ABS-Mamba%E3%80%82">https://github.com/gatina-yone/ABS-Mambaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07687v1">PDF</a> MICCAI 2025(under view)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºABS-Mambaçš„æ–°å‹å¤šæ¨¡æ€åŒ»å­¦å½±åƒç¿»è¯‘æ¶æ„ï¼Œå®ƒèåˆäº†Segment Anything Model 2ï¼ˆSAM2ï¼‰è¿›è¡Œå™¨å®˜æ„ŸçŸ¥è¯­ä¹‰è¡¨ç¤ºã€å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä¿ç•™æ¨¡æ€è¾¹ç¼˜å’Œçº¹ç†ç»†èŠ‚ï¼Œä»¥åŠMambaçš„é€‰æ‹©çŠ¶æ€ç©ºé—´å»ºæ¨¡è¿›è¡Œé•¿çŸ­è·ç¦»ç‰¹å¾ä¾èµ–ã€‚é€šè¿‡é«˜æ•ˆèåˆç½‘ç»œï¼ˆRFFNï¼‰æ•´åˆè¡¨ç¤ºï¼Œé‡‡ç”¨åŒå‘Mambaæ®‹å·®ç½‘ç»œï¼ˆBMRNï¼‰è¿›è¡Œç©ºé—´ä¾èµ–æ€§å»ºæ¨¡ã€‚è¯¥æ¶æ„åœ¨SynthRAD2023å’ŒBraTS2019æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯æ˜¾ç¤ºï¼ŒABS-Mambaåœ¨ä¿æŒè§£å‰–è¯­ä¹‰å’Œç»“æ„ç»†èŠ‚çš„åŒæ—¶ï¼Œå®ç°äº†é«˜ä¿çœŸè·¨æ¨¡æ€åˆæˆï¼Œæé«˜äº†ä¸´åºŠåº”ç”¨çš„è¯Šæ–­å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ABS-Mambaæ¶æ„èåˆäº†SAM2è¿›è¡Œå™¨å®˜æ„ŸçŸ¥è¯­ä¹‰è¡¨ç¤ºï¼Œä»¥æ•æ‰å…¨å±€è§£å‰–å­¦è¯­ä¹‰ã€‚</li>
<li>ä¸“ç”¨CNNç”¨äºä¿ç•™æ¨¡æ€ç‰¹å®šçš„è¾¹ç¼˜å’Œçº¹ç†ç»†èŠ‚ã€‚</li>
<li>Mambaçš„é€‰æ‹©çŠ¶æ€ç©ºé—´å»ºæ¨¡å®ç°é•¿çŸ­è·ç¦»ç‰¹å¾ä¾èµ–çš„æœ‰æ•ˆå¹³è¡¡ã€‚</li>
<li>RFFNæ•´åˆäº†ä¸åŒç‰¹å¾è¡¨ç¤ºï¼Œè€ŒBMRNé€šè¿‡èºæ—‹æ‰«æå’ŒåŒå‘çŠ¶æ€ç©ºé—´åŠ¨åŠ›å­¦è¿›è¡Œç©ºé—´ä¾èµ–æ€§å»ºæ¨¡ã€‚</li>
<li>ä¸‰é˜¶æ®µè·³è¿‡èåˆè§£ç å™¨å¢å¼ºäº†è¾¹ç¼˜å’Œçº¹ç†çš„ä¿çœŸåº¦ã€‚</li>
<li>é‡‡ç”¨Efficient Low-Rank Adaptationï¼ˆLoRA+ï¼‰å¾®è°ƒæ–¹æ³•ï¼Œå¯åœ¨ç²¾ç¡®é¢†åŸŸä¸“ä¸šåŒ–çš„åŒæ—¶ä¿æŒé¢„è®­ç»ƒç»„ä»¶çš„åŸºç¡€èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07687">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ca862168d659c4f3c6023f09f59435d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a19dbac974820340e78f5adf3a5b518.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GAN-based-synthetic-FDG-PET-images-from-T1-brain-MRI-can-serve-to-improve-performance-of-deep-unsupervised-anomaly-detection-models"><a href="#GAN-based-synthetic-FDG-PET-images-from-T1-brain-MRI-can-serve-to-improve-performance-of-deep-unsupervised-anomaly-detection-models" class="headerlink" title="GAN-based synthetic FDG PET images from T1 brain MRI can serve to   improve performance of deep unsupervised anomaly detection models"></a>GAN-based synthetic FDG PET images from T1 brain MRI can serve to   improve performance of deep unsupervised anomaly detection models</h2><p><strong>Authors:Daria Zotova, Nicolas Pinon, Robin Trombetta, Romain Bouet, Julien Jung, Carole Lartizien</strong></p>
<p>Background and Objective. Research in the cross-modal medical image translation domain has been very productive over the past few years in tackling the scarce availability of large curated multimodality datasets with the promising performance of GAN-based architectures. However, only a few of these studies assessed task-based related performance of these synthetic data, especially for the training of deep models. Method. We design and compare different GAN-based frameworks for generating synthetic brain [18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first perform standard qualitative and quantitative visual quality evaluation. Then, we explore further impact of using these fake PET data in the training of a deep unsupervised anomaly detection (UAD) model designed to detect subtle epilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic task-oriented quality metrics of the synthetic FDG PET data tailored to our unsupervised detection task, then use these fake data to train a use case UAD model combining a deep representation learning based on siamese autoencoders with a OC-SVM density support estimation model. This model is trained on normal subjects only and allows the detection of any variation from the pattern of the normal population. We compare the detection performance of models trained on 35 paired real MR T1 of normal subjects paired either on 35 true PET images or on 35 synthetic PET images generated from the best performing generative models. Performance analysis is conducted on 17 exams of epilepsy patients undergoing surgery. Results. The best performing GAN-based models allow generating realistic fake PET images of control subject with SSIM and PSNR values around 0.9 and 23.8, respectively and in distribution (ID) with regard to the true control dataset. The best UAD model trained on these synthetic normative PET data allows reaching 74% sensitivity. Conclusion. Our results confirm that GAN-based models are the best suited for MR T1 to FDG PET translation, outperforming transformer or diffusion models. We also demonstrate the diagnostic value of these synthetic data for the training of UAD models and evaluation on clinical exams of epilepsy patients. Our code and the normative image dataset are available. </p>
<blockquote>
<p><strong>èƒŒæ™¯ä¸ç›®çš„</strong>ï¼šè¿‘å¹´æ¥ï¼Œå…³äºè·¨æ¨¡æ€åŒ»å­¦å›¾åƒç¿»è¯‘é¢†åŸŸçš„ç ”ç©¶åœ¨è§£å†³å¤§å‹æ•´ç†å¤šæ¨¡æ€æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜æ–¹é¢å–å¾—äº†ä¸°ç¡•çš„æˆæœï¼ŒåŸºäºGANçš„æ¶æ„è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œåªæœ‰å°‘æ•°ç ”ç©¶è¯„ä¼°äº†è¿™äº›åˆæˆæ•°æ®åœ¨ä»»åŠ¡ç›¸å…³æ–¹é¢çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯ç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹æ–¹é¢ã€‚<br><strong>æ–¹æ³•</strong>ï¼šæˆ‘ä»¬è®¾è®¡å’Œæ¯”è¾ƒäº†åŸºäºä¸åŒGANçš„æ¡†æ¶ï¼Œç”¨äºä»T1åŠ æƒMRIæ•°æ®ç”Ÿæˆåˆæˆçš„å¤§è„‘æ°Ÿä»£è„±æ°§è‘¡è„ç³–ï¼ˆFDGï¼‰PETå›¾åƒã€‚æˆ‘ä»¬é¦–å…ˆè¿›è¡Œæ ‡å‡†çš„å®šæ€§å’Œå®šé‡è§†è§‰è´¨é‡è¯„ä¼°ã€‚ç„¶åï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æ¢ç´¢ä½¿ç”¨è¿™äº›å‡PETæ•°æ®åœ¨è®­ç»ƒæ·±åº¦æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆUADï¼‰æ¨¡å‹ä¸­çš„å½±å“ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨æ£€æµ‹T1 MRIå’ŒFDG PETå›¾åƒä¸­çš„å¾®å¦™ç™«ç—«ç—…ç¶ã€‚æˆ‘ä»¬å¼•å…¥äº†é’ˆå¯¹æˆ‘ä»¬çš„æ— ç›‘ç£æ£€æµ‹ä»»åŠ¡çš„æ–°å‹è¯Šæ–­ä»»åŠ¡å¯¼å‘å‹è´¨é‡æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°åˆæˆFDG PETæ•°æ®çš„è´¨é‡ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›å‡æ•°æ®æ¥è®­ç»ƒä¸€ä¸ªç”¨ä¾‹UADæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†åŸºäºå­ªç”Ÿè‡ªç¼–ç å™¨çš„æ·±åº¦è¡¨ç¤ºå­¦ä¹ ä¸OC-SVMå¯†åº¦æ”¯æŒä¼°è®¡æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä»…å¯¹æ­£å¸¸ä¸»ä½“è¿›è¡Œè®­ç»ƒï¼Œå¹¶å…è®¸æ£€æµ‹ä»»ä½•ä¸æ­£å¸¸äººç¾¤æ¨¡å¼çš„åå·®ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†åœ¨35å¯¹çœŸå®MR T1å›¾åƒï¼ˆæ­£å¸¸ä¸»ä½“ï¼‰ä¸35å¼ çœŸå®PETå›¾åƒæˆ–æ¥è‡ªè¡¨ç°æœ€ä½³çš„ç”Ÿæˆæ¨¡å‹çš„35å¼ åˆæˆPETå›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„æ£€æµ‹æ€§èƒ½ã€‚æ€§èƒ½åˆ†ææ˜¯åœ¨æ¥å—æ‰‹æœ¯çš„17åç™«ç—«æ‚£è€…èº«ä¸Šè¿›è¡Œçš„ã€‚<br><strong>ç»“æœ</strong>ï¼šè¡¨ç°æœ€ä½³çš„åŸºäºGANçš„æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å‡PETå›¾åƒï¼Œæ§åˆ¶å¯¹è±¡çš„ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å€¼åˆ†åˆ«çº¦ä¸º0.9å’Œ23.8ï¼Œä¸”åœ¨èº«ä»½åˆ†å¸ƒä¸Šä¸çœŸå®æ§åˆ¶æ•°æ®é›†ç›¸ç¬¦ã€‚ä½¿ç”¨è¿™äº›åˆæˆè§„èŒƒæ€§PETæ•°æ®è®­ç»ƒçš„æœ€ä½³UADæ¨¡å‹çš„æ•æ„Ÿæ€§è¾¾åˆ°74%ã€‚<br><strong>ç»“è®º</strong>ï¼šæˆ‘ä»¬çš„ç»“æœè¯å®ï¼ŒåŸºäºGANçš„æ¨¡å‹åœ¨MR T1åˆ°FDG PETç¿»è¯‘æ–¹é¢æœ€é€‚åˆï¼Œä¼˜äºTransformeræˆ–æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†è¿™äº›åˆæˆæ•°æ®å¯¹äºè®­ç»ƒUADæ¨¡å‹å’Œè¯„ä¼°ç™«ç—«æ‚£è€…çš„ä¸´åºŠè€ƒè¯•ä¸­çš„è¯Šæ–­ä»·å€¼ã€‚æˆ‘ä»¬çš„ä»£ç å’Œè§„èŒƒå›¾åƒæ•°æ®é›†å¯ä¾›ä½¿ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07364v1">PDF</a> </p>
<p><strong>Summary</strong>:<br>æœ¬æ–‡æ¢è®¨äº†åŸºäºGANæ¶æ„çš„è·¨æ¨¡æ€åŒ»å­¦å›¾åƒç¿»è¯‘åœ¨ç”Ÿæˆåˆæˆè„‘[Â¹â¸F]æ°Ÿè„±æ°§è‘¡è„ç³–ï¼ˆFDGï¼‰PETå›¾åƒæ–¹é¢çš„åº”ç”¨ã€‚ç ”ç©¶è®¾è®¡å¹¶æ¯”è¾ƒäº†ä¸åŒGANæ¡†æ¶ç”Ÿæˆåˆæˆå›¾åƒçš„æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨è®­ç»ƒç”¨äºæ£€æµ‹ç»†å¾®ç™«ç—«ç—…ç¶çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„åº”ç”¨ã€‚ç»“æœè¡¨æ˜ï¼ŒGANæ¨¡å‹æœ€é€‚åˆäºç”Ÿæˆä¸çœŸå®æ•°æ®ç›¸è¿‘çš„åˆæˆPETå›¾åƒï¼Œä½¿ç”¨è¿™äº›åˆæˆæ•°æ®è®­ç»ƒçš„æ¨¡å‹åœ¨ä¸´åºŠç™«ç—«æ‚£è€…æ£€æŸ¥ä¸­æ˜¾ç¤ºå‡ºè¯Šæ–­ä»·å€¼ã€‚ä»£ç åŠæ•°æ®é›†å¯ä¾›å…¬å¼€è·å–ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>GANæ¨¡å‹é€‚ç”¨äºç”ŸæˆåŒ»å­¦å›¾åƒåˆæˆæ•°æ®ï¼Œå°¤å…¶æ˜¯ç”¨äºè·¨æ¨¡æ€åŒ»å­¦å›¾åƒç¿»è¯‘é¢†åŸŸã€‚</li>
<li>ç ”ç©¶é€šè¿‡è®¾è®¡ä¸åŒGANæ¡†æ¶ç”Ÿæˆåˆæˆè„‘FDG PETå›¾åƒï¼Œä»MR T1æ•°æ®å‡ºå‘ã€‚</li>
<li>é€šè¿‡å¯¹åˆæˆå›¾åƒè¿›è¡Œè§†è§‰è´¨é‡è¯„ä¼°å’Œå®šé‡è¯„ä¼°ï¼Œç¡®å®šæœ€ä½³æ€§èƒ½çš„GANæ¨¡å‹ã€‚</li>
<li>ç ”ç©¶æ¢ç´¢äº†ä½¿ç”¨åˆæˆPETæ•°æ®è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œç™«ç—«ç—…ç¶æ£€æµ‹çš„åº”ç”¨ã€‚</li>
<li>å¼•å…¥é’ˆå¯¹ç‰¹å®šæ£€æµ‹ä»»åŠ¡çš„æ–°å‹è¯Šæ–­è´¨é‡æŒ‡æ ‡æ¥è¯„ä¼°åˆæˆæ•°æ®çš„é€‚ç”¨æ€§ã€‚</li>
<li>ä½¿ç”¨æœ€ä½³åˆæˆæ•°æ®è®­ç»ƒçš„UADæ¨¡å‹åœ¨ç™«ç—«æ‚£è€…æ£€æµ‹ä¸­è¾¾åˆ°74%çš„æ•æ„Ÿæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07364">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-75d8aa298bc71f1dd84f1fb41bb64059.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ad81deaf0ad0909d007a8a007018411.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-edee906e9a345f0ac2a02462149c7882.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e31676b64bce418610fd0cae36d7bb02.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Language-Driven-Dual-Style-Mixing-for-Single-Domain-Generalized-Object-Detection"><a href="#Language-Driven-Dual-Style-Mixing-for-Single-Domain-Generalized-Object-Detection" class="headerlink" title="Language-Driven Dual Style Mixing for Single-Domain Generalized Object   Detection"></a>Language-Driven Dual Style Mixing for Single-Domain Generalized Object   Detection</h2><p><strong>Authors:Hongda Qin, Xiao Lu, Zhiyong Wei, Yihong Cao, Kailun Yang, Ningjiang Chen</strong></p>
<p>Generalizing an object detector trained on a single domain to multiple unseen domains is a challenging task. Existing methods typically introduce image or feature augmentation to diversify the source domain to raise the robustness of the detector. Vision-Language Model (VLM)-based augmentation techniques have been proven to be effective, but they require that the detectorâ€™s backbone has the same structure as the image encoder of VLM, limiting the detector framework selection. To address this problem, we propose Language-Driven Dual Style Mixing (LDDS) for single-domain generalization, which diversifies the source domain by fully utilizing the semantic information of the VLM. Specifically, we first construct prompts to transfer style semantics embedded in the VLM to an image translation network. This facilitates the generation of style diversified images with explicit semantic information. Then, we propose image-level style mixing between the diversified images and source domain images. This effectively mines the semantic information for image augmentation without relying on specific augmentation selections. Finally, we propose feature-level style mixing in a double-pipeline manner, allowing feature augmentation to be model-agnostic and can work seamlessly with the mainstream detector frameworks, including the one-stage, two-stage, and transformer-based detectors. Extensive experiments demonstrate the effectiveness of our approach across various benchmark datasets, including real to cartoon and normal to adverse weather tasks. The source code and pre-trained models will be publicly available at <a target="_blank" rel="noopener" href="https://github.com/qinhongda8/LDDS">https://github.com/qinhongda8/LDDS</a>. </p>
<blockquote>
<p>å°†å•ä¸€é¢†åŸŸè®­ç»ƒçš„ç‰©ä½“æ£€æµ‹å™¨æ¨å¹¿åˆ°å¤šä¸ªæœªè§é¢†åŸŸæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å›¾åƒæˆ–ç‰¹å¾å¢å¼ºæ¥å¤šæ ·åŒ–æºé¢†åŸŸï¼Œä»¥æé«˜æ£€æµ‹å™¨çš„ç¨³å¥æ€§ã€‚åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å¢å¼ºæŠ€æœ¯å·²è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œä½†å®ƒä»¬è¦æ±‚æ£€æµ‹å™¨çš„éª¨å¹²ç»“æ„ä¸VLMçš„å›¾åƒç¼–ç å™¨ç›¸åŒï¼Œä»è€Œé™åˆ¶äº†æ£€æµ‹å™¨æ¡†æ¶çš„é€‰æ‹©ã€‚ä¸ºäº†è§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºå•ä¸€é¢†åŸŸæ¨å¹¿çš„è¯­è¨€é©±åŠ¨åŒé£æ ¼æ··åˆï¼ˆLDDSï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å……åˆ†åˆ©ç”¨VLMä¸­çš„è¯­ä¹‰ä¿¡æ¯æ¥å¤šæ ·åŒ–æºé¢†åŸŸã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºæç¤ºï¼Œå°†åµŒå…¥åœ¨VLMä¸­çš„é£æ ¼è¯­ä¹‰è½¬ç§»åˆ°å›¾åƒç¿»è¯‘ç½‘ç»œä¸­ã€‚è¿™æœ‰åŠ©äºç”Ÿæˆå…·æœ‰æ˜ç¡®è¯­ä¹‰ä¿¡æ¯çš„é£æ ¼å¤šæ ·åŒ–å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºåœ¨å¤šæ ·åŒ–å›¾åƒå’ŒæºåŸŸå›¾åƒä¹‹é—´è¿›è¡Œå›¾åƒçº§åˆ«çš„é£æ ¼æ··åˆã€‚è¿™æœ‰æ•ˆåœ°æŒ–æ˜äº†ç”¨äºå›¾åƒå¢å¼ºçš„è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œæ— éœ€ä¾èµ–ç‰¹å®šçš„å¢å¼ºé€‰æ‹©ã€‚æœ€åï¼Œæˆ‘ä»¬é‡‡ç”¨åŒç®¡é“æ–¹å¼è¿›è¡Œç‰¹å¾çº§åˆ«çš„é£æ ¼æ··åˆï¼Œä½¿ç‰¹å¾å¢å¼ºæˆä¸ºæ¨¡å‹æ— å…³ï¼Œå¹¶èƒ½æ— ç¼åœ°ä¸ä¸»æµæ£€æµ‹å™¨æ¡†æ¶é…åˆä½¿ç”¨ï¼ŒåŒ…æ‹¬å•é˜¶æ®µã€ä¸¤é˜¶æ®µå’ŒåŸºäºå˜å‹å™¨çš„æ£€æµ‹å™¨ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§åŸºå‡†æ•°æ®é›†ä¸Šå‡æœ‰æ•ˆï¼ŒåŒ…æ‹¬ä»ç°å®åˆ°å¡é€šå’Œä»æ­£å¸¸åˆ°æ¶åŠ£å¤©æ°”ä»»åŠ¡ã€‚æºä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/qinhongda8/LDDS%E4%B8%8A%E5%85%AC%E5%BC%80%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/qinhongda8/LDDSä¸Šå…¬å¼€æä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07219v1">PDF</a> The source code and pre-trained models will be publicly available at   <a target="_blank" rel="noopener" href="https://github.com/qinhongda8/LDDS">https://github.com/qinhongda8/LDDS</a></p>
<p><strong>Summary</strong><br>åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å•åŸŸæ³›åŒ–æŒ‘æˆ˜å¯é€šè¿‡è¯­è¨€é©±åŠ¨åŒé£æ ¼æ··åˆï¼ˆLDDSï¼‰æŠ€æœ¯æ¥è§£å†³ã€‚è¯¥æ–¹æ³•å……åˆ†åˆ©ç”¨VLMä¸­çš„é£æ ¼è¯­ä¹‰ä¿¡æ¯ç”Ÿæˆå¤šæ ·åŒ–å›¾åƒï¼Œé€šè¿‡å›¾åƒçº§é£æ ¼æ··åˆå’Œç‰¹å¾çº§é£æ ¼æ··åˆï¼Œæé«˜äº†æ£€æµ‹å™¨å¯¹æœªè§åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒåŸºå‡†æ•°æ®é›†ä¸Šå‡æœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LDDSæ–¹æ³•è§£å†³äº†å°†å•ä¸€åŸŸè®­ç»ƒçš„ç‰©ä½“æ£€æµ‹å™¨æ¨å¹¿åˆ°å¤šä¸ªæœªè§åŸŸçš„æŒ‘æˆ˜ã€‚</li>
<li>LDDSåˆ©ç”¨VLMä¸­çš„é£æ ¼è¯­ä¹‰ä¿¡æ¯ç”Ÿæˆå¤šæ ·åŒ–å›¾åƒï¼Œæé«˜æ£€æµ‹å™¨çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>LDDSé€šè¿‡å›¾åƒçº§é£æ ¼æ··åˆæŒ–æ˜è¯­ä¹‰ä¿¡æ¯ï¼Œä¸ä¾èµ–äºç‰¹å®šå¢å¼ºé€‰æ‹©ã€‚</li>
<li>LDDSé‡‡ç”¨åŒç®¡é“æ–¹å¼å®ç°ç‰¹å¾çº§é£æ ¼æ··åˆï¼Œå¯ä¸ä¸»æµæ£€æµ‹å™¨æ¡†æ¶æ— ç¼åä½œã€‚</li>
<li>LDDSæ–¹æ³•åœ¨å„ç§åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒéªŒè¯ï¼ŒåŒ…æ‹¬çœŸå®åˆ°å¡é€šå’Œæ­£å¸¸åˆ°æ¶åŠ£å¤©æ°”ä»»åŠ¡ã€‚</li>
<li>LDDSçš„æºä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å°†å…¬å¼€æä¾›ï¼Œä¾¿äºå…¶ä»–ç ”ç©¶è€…ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07219">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0a168f79ee222bff299c40b92d6f64b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-80f140c1e28d7068e733a50877d55330.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0438606acbea2776ffbf533713c5d631.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f8329c4c921b3f07241a2c1da4b5fda6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b41952cf94a4cf4614c78f4e5d2d3914.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9eab95fc0d4912a1022736762fbc3c6f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="TopicVD-A-Topic-Based-Dataset-of-Video-Guided-Multimodal-Machine-Translation-for-Documentaries"><a href="#TopicVD-A-Topic-Based-Dataset-of-Video-Guided-Multimodal-Machine-Translation-for-Documentaries" class="headerlink" title="TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine   Translation for Documentaries"></a>TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine   Translation for Documentaries</h2><p><strong>Authors:Jinze Lv, Jian Chen, Zi Long, Xianghua Fu, Yin Chen</strong></p>
<p>Most existing multimodal machine translation (MMT) datasets are predominantly composed of static images or short video clips, lacking extensive video data across diverse domains and topics. As a result, they fail to meet the demands of real-world MMT tasks, such as documentary translation. In this study, we developed TopicVD, a topic-based dataset for video-supported multimodal machine translation of documentaries, aiming to advance research in this field. We collected video-subtitle pairs from documentaries and categorized them into eight topics, such as economy and nature, to facilitate research on domain adaptation in video-guided MMT. Additionally, we preserved their contextual information to support research on leveraging the global context of documentaries in video-guided MMT. To better capture the shared semantics between text and video, we propose an MMT model based on a cross-modal bidirectional attention module. Extensive experiments on the TopicVD dataset demonstrate that visual information consistently improves the performance of the NMT model in documentary translation. However, the MMT modelâ€™s performance significantly declines in out-of-domain scenarios, highlighting the need for effective domain adaptation methods. Additionally, experiments demonstrate that global context can effectively improve translation performance. % Dataset and our implementations are available at <a target="_blank" rel="noopener" href="https://github.com/JinzeLv/TopicVD">https://github.com/JinzeLv/TopicVD</a> </p>
<blockquote>
<p>ç›®å‰å¤§å¤šæ•°å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘ï¼ˆMMTï¼‰æ•°æ®é›†ä¸»è¦ç”±é™æ€å›¾åƒæˆ–çŸ­è§†é¢‘ç‰‡æ®µç»„æˆï¼Œç¼ºä¹è·¨ä¸åŒé¢†åŸŸå’Œä¸»é¢˜çš„å¤§é‡è§†é¢‘æ•°æ®ã€‚å› æ­¤ï¼Œå®ƒä»¬æ— æ³•æ»¡è¶³ç°å®ä¸–ç•Œä¸­çš„MMTä»»åŠ¡éœ€æ±‚ï¼Œå¦‚çºªå½•ç‰‡ç¿»è¯‘ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†TopicVDï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè§†é¢‘æ”¯æŒçš„å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘çºªå½•ç‰‡æ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶ã€‚æˆ‘ä»¬ä»çºªå½•ç‰‡ä¸­æ”¶é›†äº†è§†é¢‘å­—å¹•å¯¹ï¼Œå¹¶å°†å…¶åˆ†ä¸ºç»æµã€è‡ªç„¶ç­‰å…«ä¸ªä¸»é¢˜ï¼Œä»¥ä¿ƒè¿›è§†é¢‘æŒ‡å¯¼çš„MMTä¸­çš„é¢†åŸŸè‡ªé€‚åº”ç ”ç©¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä¿ç•™äº†å…¶ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥æ”¯æŒåœ¨è§†é¢‘æŒ‡å¯¼çš„MMTä¸­åˆ©ç”¨çºªå½•ç‰‡çš„å…¨çƒè¯­å¢ƒçš„ç ”ç©¶ã€‚ä¸ºäº†æ›´å¥½åœ°æ•æ‰æ–‡æœ¬å’Œè§†é¢‘ä¹‹é—´çš„å…±äº«è¯­ä¹‰ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè·¨æ¨¡æ€åŒå‘æ³¨æ„åŠ›æ¨¡å—çš„å¤šæ¨¡æ€ç¿»è¯‘æ¨¡å‹ã€‚åœ¨TopicVDæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œè§†è§‰ä¿¡æ¯å§‹ç»ˆæé«˜äº†ç¥ç»æœºå™¨ç¿»è¯‘æ¨¡å‹åœ¨çºªå½•ç‰‡ç¿»è¯‘æ–¹é¢çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨å¤šæ¨¡æ€ç¿»è¯‘æ¨¡å‹å¤„ç†è·¨é¢†åŸŸåœºæ™¯æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¿™å‡¸æ˜¾äº†æœ‰æ•ˆé¢†åŸŸè‡ªé€‚åº”æ–¹æ³•çš„å¿…è¦æ€§ã€‚æ­¤å¤–ï¼Œå®éªŒè¡¨æ˜å…¨å±€ä¸Šä¸‹æ–‡å¯ä»¥æœ‰æ•ˆåœ°æé«˜ç¿»è¯‘æ€§èƒ½ã€‚æ•°æ®é›†åŠæˆ‘ä»¬çš„å®ç°å¯è®¿é—® <a target="_blank" rel="noopener" href="https://github.com/JinzeLv/TopicVD">https://github.com/JinzeLv/TopicVD</a> äº†è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05714v1">PDF</a> NLDB 2025</p>
<p><strong>Summary</strong>ï¼š<br>é’ˆå¯¹å½“å‰å¤šåª’ä½“æœºå™¨ç¿»è¯‘ï¼ˆMMTï¼‰æ•°æ®é›†ç¼ºä¹æ¶µç›–å¹¿æ³›ä¸»é¢˜çš„è§†é¢‘æ•°æ®çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºTopicVDæ•°æ®é›†ï¼Œæ—¨åœ¨æ¨è¿›è§†é¢‘è¾…åŠ©å¤šåª’ä½“æœºå™¨ç¿»è¯‘é¢†åŸŸçš„ç ”ç©¶ã€‚é€šè¿‡æ”¶é›†çºªå½•ç‰‡è§†é¢‘å­—å¹•å¯¹ï¼Œå¹¶æŒ‰ä¸»é¢˜åˆ†ç±»ï¼ŒåŒæ—¶ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç ”ç©¶è§†é¢‘ä¸æ–‡æœ¬ä¹‹é—´çš„å…±äº«è¯­ä¹‰ã€‚æ­¤å¤–ï¼Œå¼•å…¥åŸºäºè·¨æ¨¡æ€åŒå‘æ³¨æ„åŠ›æ¨¡å—çš„å¤šåª’ä½“æœºå™¨ç¿»è¯‘æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼Œè§†é¢‘ä¿¡æ¯å¯æé«˜ç¿»è¯‘æ€§èƒ½ï¼Œä½†è·¨é¢†åŸŸåœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™ï¼Œæ˜¾ç¤ºéœ€è¦æœ‰æ•ˆçš„é¢†åŸŸé€‚åº”æ–¹æ³•ã€‚å…¨çƒè¯­å¢ƒå¯æœ‰æ•ˆæå‡ç¿»è¯‘æ€§èƒ½ã€‚æ•°æ®é›†åŠç›¸å…³å®ç°å·²å…¬å¼€åœ¨GitHubä¸Šæä¾›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>TopicVDæ•°æ®é›†é’ˆå¯¹å¤šåª’ä½“æœºå™¨ç¿»è¯‘è®¾è®¡ï¼Œå°¤å…¶é€‚ç”¨äºçºªå½•ç‰‡ç¿»è¯‘ç ”ç©¶ã€‚</li>
<li>TopicVDåŒ…å«å¤šç§ä¸»é¢˜çš„è§†é¢‘æ•°æ®ï¼Œæœ‰åˆ©äºé¢†åŸŸé€‚åº”ç ”ç©¶ã€‚</li>
<li>ä¸Šä¸‹æ–‡ä¿¡æ¯å¾—ä»¥ä¿ç•™ä»¥æ”¯æŒç›¸å…³ç ”ç©¶ã€‚</li>
<li>æå‡ºåŸºäºè·¨æ¨¡æ€åŒå‘æ³¨æ„åŠ›æ¨¡å—çš„å¤šåª’ä½“æœºå™¨ç¿»è¯‘æ¨¡å‹ã€‚</li>
<li>è§†é¢‘ä¿¡æ¯èƒ½æ”¹å–„ç¿»è¯‘æ€§èƒ½ã€‚</li>
<li>åœ¨è·¨é¢†åŸŸåœºæ™¯ä¸‹ï¼Œå¤šåª’ä½“æœºå™¨ç¿»è¯‘æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ˜¾ç¤ºå¯¹æœ‰æ•ˆé¢†åŸŸé€‚åº”æ–¹æ³•çš„éœ€æ±‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05714">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6465962a9fc7fc4e460e36656ac311e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2cb13f0e8e6169d11abb374d0d4a37a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-efd0f5086df20df87fb7104f2c77019d.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Realization-of-a-Pre-Sample-Photonic-based-Free-Electron-Modulator-in-Ultrafast-Transmission-Electron-Microscopes"><a href="#Realization-of-a-Pre-Sample-Photonic-based-Free-Electron-Modulator-in-Ultrafast-Transmission-Electron-Microscopes" class="headerlink" title="Realization of a Pre-Sample Photonic-based Free-Electron Modulator in   Ultrafast Transmission Electron Microscopes"></a>Realization of a Pre-Sample Photonic-based Free-Electron Modulator in   Ultrafast Transmission Electron Microscopes</h2><p><strong>Authors:Beatrice Matilde Ferrari, Cameron James Richard Duncan, Michael Yannai, Raphael Dahan, Paolo Rosi, Irene Ostroman, Maria Giulia Bravi, Arthur Niedermayr, Tom Lenkiewicz Abudi, Yuval Adiv, Tal Fishman, Sang Tae Park, Dan Masiel, Thomas Lagrange, Fabrizio Carbone, Vincenzo Grillo, F. Javier GarcÃ­a de Abajo, Ido Kaminer, Giovanni Maria Vanacore</strong></p>
<p>Spatial and temporal light modulation is a well-established technology that enables dynamic shaping of the phase and amplitude of optical fields, significantly enhancing the resolution and sensitivity of imaging methods. Translating this capability to electron beams is highly desirable within the framework of a transmission electron microscope (TEM) to benefit from the nanometer spatial resolution of these instruments. In this work, we report on the experimental realization of a photonic-based free-electron modulator integrated into the column of two ultrafast TEMs for pre-sample electron-beam shaping. Electron-photon interaction is employed to coherently modulate both the transverse and longitudinal components of the electron wave function, while leveraging dynamically controlled optical fields and tailored design of electron-laser-sample interaction geometry. Using energy- and momentum-resolved electron detection, we successfully reconstruct the shaped electron wave function at the TEM sample plane. These results demonstrate the ability to manipulate the electron wave function before probing the sample, paving the way for the future development of innovative imaging methods in ultrafast electron microscopy. </p>
<blockquote>
<p>ç©ºé—´å’Œæ—¶é—´å…‰è°ƒåˆ¶æ˜¯ä¸€é¡¹æˆç†Ÿçš„æŠ€æœ¯ï¼Œèƒ½å¤ŸåŠ¨æ€åœ°æ”¹å˜å…‰åœºçš„ç›¸ä½å’ŒæŒ¯å¹…ï¼Œä»è€Œæå¤§åœ°æé«˜æˆåƒæ–¹æ³•çš„åˆ†è¾¨ç‡å’Œçµæ•åº¦ã€‚åœ¨é€å°„ç”µå­æ˜¾å¾®é•œï¼ˆTEMï¼‰çš„æ¡†æ¶ä¸‹ï¼Œå°†è¿™ä¸€èƒ½åŠ›åº”ç”¨åˆ°ç”µå­æŸä¸Šæ˜¯éå¸¸ç†æƒ³çš„ï¼Œä»¥åˆ©ç”¨è¿™äº›ä»ªå™¨çš„çº³ç±³ç©ºé—´åˆ†è¾¨ç‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æŠ¥å‘Šäº†å°†å…‰å­åŸºè‡ªç”±ç”µå­è°ƒåˆ¶å™¨é›†æˆåˆ°ä¸¤å°è¶…å¿«é€å°„ç”µå­æ˜¾å¾®é•œçš„æ”¯æŸ±ä¸­ï¼Œç”¨äºæ ·å“å‰çš„ç”µå­æŸæ•´å½¢ã€‚åˆ©ç”¨ç”µå­-å…‰å­ç›¸äº’ä½œç”¨ï¼Œç›¸å¹²åœ°è°ƒåˆ¶ç”µå­æ³¢å‡½æ•°çš„æ¨ªå‘å’Œçºµå‘åˆ†é‡ï¼ŒåŒæ—¶åˆ©ç”¨åŠ¨æ€æ§åˆ¶çš„å…‰åœºå’Œå®šåˆ¶çš„ç”µå­-æ¿€å…‰-æ ·å“ç›¸äº’ä½œç”¨å‡ ä½•ç»“æ„ã€‚é€šè¿‡èƒ½é‡å’ŒåŠ¨é‡è§£æçš„ç”µå­æ£€æµ‹ï¼Œæˆ‘ä»¬æˆåŠŸåœ°åœ¨é€å°„ç”µå­æ˜¾å¾®é•œæ ·å“å¹³é¢ä¸Šé‡å»ºäº†æ•´å½¢åçš„ç”µå­æ³¢å‡½æ•°ã€‚è¿™äº›ç»“æœè¯æ˜äº†åœ¨æ¢æµ‹æ ·å“ä¹‹å‰æ“ä½œç”µå­æ³¢å‡½æ•°çš„èƒ½åŠ›ï¼Œä¸ºè¶…å¿«ç”µå­æ˜¾å¾®é•œä¸­åˆ›æ–°æˆåƒæ–¹æ³•çš„æœªæ¥å‘å±•é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11313v2">PDF</a> 14 pages, 5, figures, includes supplementary information, journal   paper</p>
<p><strong>Summary</strong></p>
<p>ç©ºé—´å’Œæ—¶é—´å…‰è°ƒåˆ¶æŠ€æœ¯å·²å¹¿æ³›åº”ç”¨äºå…‰å­¦é¢†åŸŸï¼Œå®ç°äº†å¯¹å…‰åœºç›¸ä½å’ŒæŒ¯å¹…çš„åŠ¨æ€è°ƒæ§ï¼Œå¤§å¤§æé«˜äº†æˆåƒæ–¹æ³•çš„åˆ†è¾¨ç‡å’Œçµæ•åº¦ã€‚æœ¬æ–‡å°†æ­¤æŠ€æœ¯åº”ç”¨äºé€å°„ç”µå­æ˜¾å¾®é•œï¼ˆTEMï¼‰ä¸­ï¼Œå®ç°äº†ç”µå­æŸçš„é¢„æ ·æœ¬è°ƒæ§ã€‚è¯¥ç ”ç©¶åˆ©ç”¨ç”µå­å…‰å­ç›¸äº’ä½œç”¨ï¼Œå¯¹ç”µå­æ³¢å‡½æ•°çš„æ¨ªå‘å’Œçºµå‘æˆåˆ†è¿›è¡Œç›¸å¹²è°ƒæ§ï¼ŒåŒæ—¶é‡‡ç”¨åŠ¨æ€æ§åˆ¶çš„å…‰åœºå’Œå®šåˆ¶çš„ç”µå­æ¿€å…‰æ ·å“ç›¸äº’ä½œç”¨å‡ ä½•è®¾è®¡ã€‚é€šè¿‡èƒ½é‡å’ŒåŠ¨é‡è§£æçš„ç”µå­æ£€æµ‹ï¼ŒæˆåŠŸé‡å»ºäº†æ ·å“å¹³é¢ä¸Šçš„ç”µå­æ³¢å‡½æ•°ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†åœ¨æ¢æµ‹æ ·å“ä¹‹å‰æ“æ§ç”µå­æ³¢å‡½æ•°çš„èƒ½åŠ›ï¼Œä¸ºè¶…å¿«ç”µå­æ˜¾å¾®é•œä¸­åˆ›æ–°æˆåƒæ–¹æ³•çš„å‘å±•é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç©ºé—´å’Œæ—¶é—´å…‰è°ƒåˆ¶æŠ€æœ¯å·²å¹¿æ³›åº”ç”¨äºå…‰å­¦é¢†åŸŸï¼Œå®ç°å¯¹å…‰åœºç›¸ä½å’ŒæŒ¯å¹…çš„åŠ¨æ€è°ƒæ§ã€‚</li>
<li>æŠ€æœ¯è¢«æˆåŠŸåº”ç”¨äºé€å°„ç”µå­æ˜¾å¾®é•œï¼ˆTEMï¼‰ä¸­ï¼Œå®ç°äº†ç”µå­æŸçš„é¢„æ ·æœ¬è°ƒæ§ã€‚</li>
<li>é€šè¿‡ç”µå­å…‰å­ç›¸äº’ä½œç”¨å¯¹ç”µå­æ³¢å‡½æ•°çš„æ¨ªå‘å’Œçºµå‘æˆåˆ†è¿›è¡Œç›¸å¹²è°ƒæ§ã€‚</li>
<li>åˆ©ç”¨åŠ¨æ€æ§åˆ¶çš„å…‰åœºå’Œå®šåˆ¶çš„å‡ ä½•è®¾è®¡å®ç°ç”µå­æ¿€å…‰æ ·å“ç›¸äº’ä½œç”¨ã€‚</li>
<li>é€šè¿‡èƒ½é‡å’ŒåŠ¨é‡è§£æçš„ç”µå­æ£€æµ‹æˆåŠŸé‡å»ºäº†æ ·å“å¹³é¢ä¸Šçš„ç”µå­æ³¢å‡½æ•°ã€‚</li>
<li>è¯¥æŠ€æœ¯å±•ç¤ºäº†åœ¨æ¢æµ‹æ ·å“å‰æ“æ§ç”µå­æ³¢å‡½æ•°çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11313">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0df5ad72e4140d00f93db2c59f952cff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e368e6362eb39ee15c917b96d85b1a50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6eb9e66a07727ccf656071e82a6eb5a9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-14/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-14/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-14/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-7c03550ec50e2ce6f1ca34536b68e039.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-14  Breast Cancer Classification in Deep Ultraviolet Fluorescence Images   Using a Patch-Level Vision Transformer Framework
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-14/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a7232ea14da8cf4d1a5ec0344649ce78.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-14  Beyond CLIP Generalization Against Forward&Backward Forgetting Adapter   for Continual Learning of Vision-Language Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18884.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
