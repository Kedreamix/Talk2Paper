<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-25  Self-Supervised Diffusion MRI Denoising via Iterative and Stable   Refinement">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-65b9cf9e48ea8187bdaca9ec411867dc.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-25-æ›´æ–°"><a href="#2025-01-25-æ›´æ–°" class="headerlink" title="2025-01-25 æ›´æ–°"></a>2025-01-25 æ›´æ–°</h1><h2 id="Self-Supervised-Diffusion-MRI-Denoising-via-Iterative-and-Stable-Refinement"><a href="#Self-Supervised-Diffusion-MRI-Denoising-via-Iterative-and-Stable-Refinement" class="headerlink" title="Self-Supervised Diffusion MRI Denoising via Iterative and Stable   Refinement"></a>Self-Supervised Diffusion MRI Denoising via Iterative and Stable   Refinement</h2><p><strong>Authors:Chenxu Wu, Qingpeng Kong, Zihang Jiang, S. Kevin Zhou</strong></p>
<p>Magnetic Resonance Imaging (MRI), including diffusion MRI (dMRI), serves as a &#96;&#96;microscopeâ€™â€™ for anatomical structures and routinely mitigates the influence of low signal-to-noise ratio scans by compromising temporal or spatial resolution. However, these compromises fail to meet clinical demands for both efficiency and precision. Consequently, denoising is a vital preprocessing step, particularly for dMRI, where clean data is unavailable. In this paper, we introduce Di-Fusion, a fully self-supervised denoising method that leverages the latter diffusion steps and an adaptive sampling process. Unlike previous approaches, our single-stage framework achieves efficient and stable training without extra noise model training and offers adaptive and controllable results in the sampling process. Our thorough experiments on real and simulated data demonstrate that Di-Fusion achieves state-of-the-art performance in microstructure modeling, tractography tracking, and other downstream tasks. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ï¼ŒåŒ…æ‹¬æ‰©æ•£MRIï¼ˆdMRIï¼‰ï¼Œå¯ä½œä¸ºè§£å‰–ç»“æ„çš„â€œæ˜¾å¾®é•œâ€ï¼Œå¹¶é€šè¿‡å¦¥åæ—¶é—´æˆ–ç©ºé—´åˆ†è¾¨ç‡æ¥å¸¸è§„ç¼“è§£ä½ä¿¡å™ªæ¯”æ‰«æçš„å½±å“ã€‚ç„¶è€Œï¼Œè¿™äº›å¦¥åæ— æ³•æ»¡è¶³ä¸´åºŠå¯¹æ•ˆç‡å’Œç²¾ç¡®åº¦çš„éœ€æ±‚ã€‚å› æ­¤ï¼Œå»å™ªæ˜¯ä¸€ä¸ªé‡è¦çš„é¢„å¤„ç†æ­¥éª¤ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ— æ³•è·å¾—æ¸…æ´æ•°æ®çš„dMRIè€Œè¨€å°¤ä¸ºå…³é”®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Di-Fusionï¼Œè¿™æ˜¯ä¸€ç§å®Œå…¨è‡ªç›‘ç£çš„å»å™ªæ–¹æ³•ï¼Œå®ƒåˆ©ç”¨åç»­çš„æ‰©æ•£æ­¥éª¤å’Œè‡ªé€‚åº”é‡‡æ ·è¿‡ç¨‹ã€‚ä¸åŒäºä»¥å‰çš„æ–¹æ³•ï¼Œæˆ‘ä»¬çš„å•é˜¶æ®µæ¡†æ¶å®ç°äº†é«˜æ•ˆä¸”ç¨³å®šçš„è®­ç»ƒï¼Œæ— éœ€é¢å¤–çš„å™ªå£°æ¨¡å‹è®­ç»ƒï¼Œå¹¶åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­æä¾›äº†è‡ªé€‚åº”å’Œå¯æ§çš„ç»“æœã€‚æˆ‘ä»¬åœ¨çœŸå®å’Œæ¨¡æ‹Ÿæ•°æ®ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDi-Fusionåœ¨å¾®è§‚ç»“æ„å»ºæ¨¡ã€è½¨è¿¹è·Ÿè¸ªå’Œå…¶ä»–ä¸‹æ¸¸ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13514v1">PDF</a> 39pages, 34figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Di-Fusionè¿™ä¸€å…¨æ–°çš„å…¨è‡ªç›‘ç£é™å™ªæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£MRIçš„åæ‰©æ•£æ­¥éª¤å’Œè‡ªé€‚åº”é‡‡æ ·è¿‡ç¨‹è¿›è¡Œé«˜æ•ˆç¨³å®šçš„è®­ç»ƒï¼Œæ— éœ€é¢å¤–çš„å™ªå£°æ¨¡å‹è®­ç»ƒã€‚å®éªŒè¯æ˜ï¼ŒDi-Fusionåœ¨å¾®è§‚ç»“æ„å»ºæ¨¡ã€çº¤ç»´è·Ÿè¸ªç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¾¾åˆ°äº†å…ˆè¿›æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæä¾›å¯æ§çš„è‡ªé€‚åº”é‡‡æ ·ç»“æœã€‚æ­¤å¤–ï¼Œå¯¹äºä¸å¯ç”¨å¹²å‡€çš„åŸå§‹æ•°æ®æˆ–æ‰©æ•£MRIä¸­çš„éš¾ç‚¹åœºæ™¯è¿›è¡Œæ¸…æ™°çš„è§£å‰–å­¦å›¾åƒè§£æå°¤å…¶æœ‰ä»·å€¼ã€‚è¿™è¡¨æ˜å…¶å…‹æœäº†å½±å“è§£æå‡†ç¡®åº¦çš„ä¸åˆ©å› ç´ ï¼Œå¹¶æå‡äº†æ•°æ®è´¨é‡ã€‚Di-Fusionå¯¹äºæ”¹å–„MRIå›¾åƒè´¨é‡ã€æé«˜è¯Šæ–­ç²¾åº¦å…·æœ‰é‡è¦æ„ä¹‰ã€‚ </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Di-Fusionæ˜¯ä¸€ç§å…¨è‡ªç›‘ç£çš„é™å™ªæ–¹æ³•ï¼Œé€‚ç”¨äºMRIå›¾åƒçš„å¤„ç†ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£MRIçš„åæ‰©æ•£æ­¥éª¤å’Œè‡ªé€‚åº”é‡‡æ ·è¿‡ç¨‹è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€é¢å¤–çš„å™ªå£°æ¨¡å‹è®­ç»ƒã€‚</li>
<li>Di-Fusionå¯¹äºè§£å¾®ç»“æ„å»ºæ¨¡ã€çº¤ç»´è·Ÿè¸ªç­‰ä¸‹æ¸¸ä»»åŠ¡æœ‰ç€è‰¯å¥½çš„æ€§èƒ½è¡¨ç°ã€‚å®ƒåœ¨å®ç°å›¾åƒçš„é«˜æ¸…æ™°åº¦çš„åŒæ—¶ç»´æŒäº†å›¾åƒçš„ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13514">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bbaadbddf45b408765a49ce410e3d8c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d2d1a42d37888423a30da1944c6810d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-65b9cf9e48ea8187bdaca9ec411867dc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ed77d961fef18aa3249063739d74c48b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a21867dcc0ec8c1cb4f46729ca73914c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Modelling-the-energy-dependent-X-ray-variability-of-Mrk-335"><a href="#Modelling-the-energy-dependent-X-ray-variability-of-Mrk-335" class="headerlink" title="Modelling the energy dependent X-ray variability of Mrk 335"></a>Modelling the energy dependent X-ray variability of Mrk 335</h2><p><strong>Authors:K. Akhila, Ranjeev Misra, Rathin Sarma, Savithri H. Ezhikode, K. Jeena</strong></p>
<p>We present a technique which predicts the energy dependent fractional r.m.s for linear correlated variations of a pair of spectral parameters and apply it to an XMM-Newton observation of Mrk 335. The broadband X-ray spectrum can be interpreted as a patchy absorber partially covering the primary emission, a warm and hot coronal emission or a relativistically blurred reflection along with the primary emission. The fractional r.m.s has a non-monotonic behavior with energy for segments of lengths 3 and 6 ksecs. For each spectral model, we consider every pair of spectral parameters and fit the predicted r.m.s with the observed ones, to get the pair which provides the best fit. We find that a variation in at least two parameters is required for all spectral interpretations. For both time segments, variations in the covering fraction of the absorber and the primary power law index gives the best result for the partial covering model, while a variation in the normalization and spectral index of the warm component gives the best fit in the two corona interpretation. For the reflection model, the best fit parameters are different for the two time segment lengths, and the results suggests that more than two parameters are required to explain the data. This, combined with the extreme values of emissivity index and reflection fraction parameters obtained from the spectral analysis, indicates that the blurred reflection model might not be a suitable explanation for the Mrk 335 spectrum. We discuss the results as well as the potential of the technique to be applied to other data sets of different AGN. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯èƒ½å¤Ÿé¢„æµ‹ä¸€å¯¹å…‰è°±å‚æ•°çš„çº¿æ€§ç›¸å…³å˜åŒ–ä¸­çš„èƒ½é‡ç›¸å…³åˆ†æ•°å‡æ–¹æ ¹ï¼ˆr.m.sï¼‰ï¼Œå¹¶å°†å…¶åº”ç”¨äºXMM-ç‰›é¡¿å¯¹Mrk 335çš„è§‚å¯Ÿã€‚å®½å¸¦Xå°„çº¿å…‰è°±å¯ä»¥è¢«è§£é‡Šä¸ºéƒ¨åˆ†è¦†ç›–ä¸»å‘å°„åŒºåŸŸçš„æ–‘å—å¸æ”¶å™¨ã€æ¸©æš–å’Œç‚½çƒ­çš„å†•å‘å°„ï¼Œæˆ–è€…ä¸ä¸»å‘å°„åŒºåŸŸç›¸ä¼´çš„ç›¸å¯¹è®ºæ€§æ¨¡ç³Šåå°„ã€‚åˆ†æ•°å‡æ–¹æ ¹ï¼ˆr.m.sï¼‰åœ¨é•¿åº¦ä¸º3å’Œ6åƒç§’çš„æ—¶é—´æ®µå†…éšèƒ½é‡å˜åŒ–è¡¨ç°å‡ºéå•è°ƒè¡Œä¸ºã€‚å¯¹äºæ¯ä¸ªå…‰è°±æ¨¡å‹ï¼Œæˆ‘ä»¬è€ƒè™‘æ¯å¯¹å…‰è°±å‚æ•°ï¼Œå¹¶ç”¨è§‚å¯Ÿåˆ°çš„r.m.så€¼æ‹Ÿåˆé¢„æµ‹çš„r.m.så€¼ï¼Œä»¥è·å¾—æä¾›æœ€ä½³æ‹Ÿåˆçš„é…å¯¹ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ‰€æœ‰å…‰è°±è§£é‡Šéƒ½éœ€è¦è‡³å°‘ä¸¤ä¸ªå‚æ•°çš„å˜åŒ–ã€‚å¯¹äºä¸¤ä¸ªæ—¶é—´æ®µï¼Œå¸æ”¶å™¨çš„è¦†ç›–åˆ†æ•°å’Œä¸»å¹‚å¾‹æŒ‡æ•°çš„å˜åŒ–ä¸ºéƒ¨åˆ†è¦†ç›–æ¨¡å‹æä¾›äº†æœ€ä½³ç»“æœï¼Œè€Œæš–æˆåˆ†çš„æ ‡å‡†åŒ–å’Œå…‰è°±æŒ‡æ•°çš„å˜åŒ–ä¸ºä¸¤å†•è§£é‡Šæä¾›äº†æœ€ä½³æ‹Ÿåˆã€‚å¯¹äºåå°„æ¨¡å‹ï¼Œä¸¤ä¸ªæ—¶é—´æ®µé•¿åº¦çš„æœ€ä½³æ‹Ÿåˆå‚æ•°ä¸åŒï¼Œç»“æœæš—ç¤ºéœ€è¦è¶…è¿‡ä¸¤ä¸ªå‚æ•°æ¥è§£é‡Šæ•°æ®ã€‚ç»“åˆä»å…‰è°±åˆ†æè·å¾—çš„å‘å°„ç‡æŒ‡æ•°å’Œåå°„åˆ†æ•°å‚æ•°çš„æç«¯å€¼ï¼Œè¡¨æ˜æ¨¡ç³Šçš„åå°„æ¨¡å‹å¯èƒ½ä¸é€‚åˆè§£é‡ŠMrk 335çš„å…‰è°±ã€‚æˆ‘ä»¬è®¨è®ºäº†ç»“æœä»¥åŠè¯¥æŠ€æœ¯åº”ç”¨äºå…¶ä»–ä¸åŒæ´»è·ƒæ˜Ÿç³»æ ¸ï¼ˆAGNï¼‰æ•°æ®é›†çš„å¯èƒ½æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13458v1">PDF</a> Accepted for publication in JHEAP</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†ä¸€ç§é¢„æµ‹çº¿æ€§ç›¸å…³å…‰è°±å‚æ•°å˜åŒ–åˆ†æ•°çš„èƒ½é‡ä¾èµ–æ€§çš„æŠ€æœ¯ï¼Œå¹¶å°†å…¶åº”ç”¨äºMrk 335çš„XMM-Newtonè§‚æµ‹ã€‚æ–‡ç« æ¢è®¨äº†éƒ¨åˆ†é®æŒ¡æ¨¡å‹ã€æš–å† ä¸çƒ­å† å‘å°„æ¨¡å‹ä»¥åŠç›¸å¯¹è®ºçš„æ¨¡ç³Šåå°„æ¨¡å‹ç­‰ä¸‰ç§å…‰è°±è§£é‡Šã€‚å…¶ä¸­ï¼Œéƒ¨åˆ†é®æŒ¡æ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆå‚æ•°ä¸ºé®æŒ¡ç‰©è¦†ç›–åˆ†æ•°å’Œä¸»è¦å¹‚å¾‹æŒ‡æ•°çš„å˜åŒ–ï¼›åœ¨æš–å† æ¨¡å‹ä¸­ï¼Œå½’ä¸€åŒ–å’Œå…‰è°±æŒ‡æ•°çš„å˜åŒ–æä¾›äº†æœ€ä½³æ‹Ÿåˆã€‚åå°„æ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆå‚æ•°éšæ—¶é—´é•¿åº¦å˜åŒ–è€Œä¸åŒï¼Œä¸”ç»“æœæš—ç¤ºéœ€è¦è¶…è¿‡ä¸¤ä¸ªå‚æ•°æ¥è§£é‡Šæ•°æ®ã€‚ç»“åˆä»å…‰è°±åˆ†æè·å¾—çš„æç«¯å‘å°„ç‡æŒ‡æ•°å’Œåå°„å› å­å‚æ•°å€¼ï¼Œæ¨¡ç³Šçš„åå°„æ¨¡å‹å¯èƒ½ä¸é€‚åˆè§£é‡ŠMrk 335å…‰è°±ã€‚æ–‡ç« ç»“æœå¯¹äºæœªæ¥åˆ†æä¸åŒæ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆAGNï¼‰çš„æ•°æ®é›†å…·æœ‰æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« ä»‹ç»äº†ä¸€ç§é¢„æµ‹èƒ½é‡ç›¸å…³åˆ†æ•°çš„æŠ€æœ¯ï¼Œå¹¶åº”ç”¨äºMrk 335çš„XMM-Newtonè§‚æµ‹æ•°æ®ã€‚</li>
<li>æ–‡ç« æ¢è®¨äº†ä¸‰ç§å…‰è°±è§£é‡Šæ¨¡å‹ï¼šéƒ¨åˆ†é®æŒ¡æ¨¡å‹ã€æš–å† ä¸çƒ­å† å‘å°„æ¨¡å‹ä»¥åŠç›¸å¯¹è®ºçš„æ¨¡ç³Šåå°„æ¨¡å‹ã€‚</li>
<li>éƒ¨åˆ†é®æŒ¡æ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆå‚æ•°æ˜¯é®æŒ¡ç‰©è¦†ç›–åˆ†æ•°å’Œä¸»è¦å¹‚å¾‹æŒ‡æ•°çš„å˜åŒ–ã€‚</li>
<li>åœ¨æš–å† æ¨¡å‹ä¸­ï¼Œå½’ä¸€åŒ–å’Œå…‰è°±æŒ‡æ•°çš„å˜åŒ–æä¾›äº†æœ€ä½³æ‹Ÿåˆç»“æœã€‚</li>
<li>åå°„æ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆå‚æ•°éšæ—¶é—´é•¿åº¦å˜åŒ–è€Œä¸åŒï¼Œä¸”éœ€è¦è¶…è¿‡ä¸¤ä¸ªå‚æ•°æ¥è§£é‡Šæ•°æ®ã€‚<br>6.æ¨¡ç³Šçš„åå°„æ¨¡å‹å¯èƒ½ä¸é€‚åˆè§£é‡ŠMrk 335å…‰è°±ï¼Œç»“åˆä»å…‰è°±åˆ†æè·å¾—çš„å‚æ•°å€¼å¾—å‡ºæ­¤ç»“è®ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13458">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cc23eff77b751dd211a21cec4b07db1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14b196582f5eb261d726cbef5d6dd3e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f3678af98b3832294605d06423a450c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c92e3597e4ed75d63fabbc67d7e07f9b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-245d2894ac91a585645a5a63514eec0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca3775c7e3b54f49fe07fe8875073e14.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ff7568b268cb166bb72c5f9f2c9a553.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Unraveling-Normal-Anatomy-via-Fluid-Driven-Anomaly-Randomization"><a href="#Unraveling-Normal-Anatomy-via-Fluid-Driven-Anomaly-Randomization" class="headerlink" title="Unraveling Normal Anatomy via Fluid-Driven Anomaly Randomization"></a>Unraveling Normal Anatomy via Fluid-Driven Anomaly Randomization</h2><p><strong>Authors:Peirong Liu, Ana Lawry Aguila, Juan E. Iglesias</strong></p>
<p>Data-driven machine learning has made significant strides in medical image analysis. However, most existing methods are tailored to specific modalities and assume a particular resolution (often isotropic). This limits their generalizability in clinical settings, where variations in scan appearance arise from differences in sequence parameters, resolution, and orientation. Furthermore, most general-purpose models are designed for healthy subjects and suffer from performance degradation when pathology is present. We introduce UNA (Unraveling Normal Anatomy), the first modality-agnostic learning approach for normal brain anatomy reconstruction that can handle both healthy scans and cases with pathology. We propose a fluid-driven anomaly randomization method that generates an unlimited number of realistic pathology profiles on-the-fly. UNA is trained on a combination of synthetic and real data, and can be applied directly to real images with potential pathology without the need for fine-tuning. We demonstrate UNAâ€™s effectiveness in reconstructing healthy brain anatomy and showcase its direct application to anomaly detection, using both simulated and real images from 3D healthy and stroke datasets, including CT and MRI scans. By bridging the gap between healthy and diseased images, UNA enables the use of general-purpose models on diseased images, opening up new opportunities for large-scale analysis of uncurated clinical images in the presence of pathology. Code is available at <a target="_blank" rel="noopener" href="https://github.com/peirong26/UNA">https://github.com/peirong26/UNA</a>. </p>
<blockquote>
<p>æ•°æ®é©±åŠ¨çš„æœºå™¨å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†ææ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•éƒ½æ˜¯é’ˆå¯¹ç‰¹å®šæ¨¡æ€çš„ï¼Œå¹¶å‡è®¾äº†ç‰¹å®šçš„åˆ†è¾¨ç‡ï¼ˆé€šå¸¸ä¸ºç­‰è·ï¼‰ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„é€šç”¨æ€§ï¼Œå› ä¸ºæ‰«æå¤–è§‚çš„å˜åŒ–æ¥è‡ªäºåºåˆ—å‚æ•°ã€åˆ†è¾¨ç‡å’Œæ–¹ä½çš„å·®å¼‚ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°é€šç”¨æ¨¡å‹éƒ½æ˜¯ä¸ºå¥åº·å—è¯•è€…è®¾è®¡çš„ï¼Œåœ¨æœ‰ç—…ç†æƒ…å†µå‡ºç°æ—¶ä¼šå‡ºç°æ€§èƒ½ä¸‹é™ã€‚æˆ‘ä»¬å¼•å…¥äº†UNAï¼ˆè§£å¼€æ­£å¸¸è§£å‰–ç»“æ„ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ­£å¸¸å¤§è„‘è§£å‰–ç»“æ„é‡å»ºçš„æ¨¡æ€æ— å…³å­¦ä¹ æ–¹æ³•ï¼Œå®ƒå¯ä»¥å¤„ç†å¥åº·æ‰«æå’Œå¸¦æœ‰ç—…ç†æƒ…å†µçš„ç—…ä¾‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æµä½“é©±åŠ¨å¼‚å¸¸éšæœºåŒ–æ–¹æ³•ï¼Œå¯ä»¥å®æ—¶ç”Ÿæˆæ— é™æ•°é‡çš„ç°å®ç—…ç†ç‰¹å¾ã€‚UNAæ˜¯åœ¨åˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®çš„ç»„åˆä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºæ½œåœ¨ç—…ç†çš„çœŸå®å›¾åƒï¼Œæ— éœ€å¾®è°ƒã€‚æˆ‘ä»¬å±•ç¤ºäº†UNAåœ¨é‡å»ºå¥åº·å¤§è„‘è§£å‰–ç»“æ„æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å¼‚å¸¸æ£€æµ‹æ–¹é¢çš„ç›´æ¥åº”ç”¨ï¼Œä½¿ç”¨æ¥è‡ª3Då¥åº·å’Œä¸­é£æ•°æ®é›†çš„æ¨¡æ‹Ÿå’ŒçœŸå®å›¾åƒï¼ŒåŒ…æ‹¬CTå’ŒMRIæ‰«æã€‚é€šè¿‡ç¼©å°å¥åº·å›¾åƒä¸ç–¾ç—…å›¾åƒä¹‹é—´çš„å·®è·ï¼ŒUNAä½¿å¾—é€šç”¨æ¨¡å‹èƒ½å¤Ÿåœ¨ç–¾ç—…å›¾åƒä¸Šä½¿ç”¨ï¼Œä¸ºå­˜åœ¨ç—…ç†æƒ…å†µçš„æœªæ•´ç†ä¸´åºŠå›¾åƒçš„å¤§è§„æ¨¡åˆ†ææä¾›äº†æ–°çš„æœºä¼šã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/peirong26/UNA%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/peirong26/UNAæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13370v1">PDF</a> 16 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æ•°æ®é©±åŠ¨çš„æœºå™¨å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†ææ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤§å¤šæ•°ç°æœ‰æ–¹æ³•é’ˆå¯¹ç‰¹å®šæ¨¡æ€å¹¶å‡è®¾ç‰¹å®šåˆ†è¾¨ç‡ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„é€šç”¨æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€šç”¨çš„ã€æ¨¡æ€æ— å…³çš„å­¦ä¹ æ–¹æ³•UNAï¼ˆUnraveling Normal Anatomyï¼‰ï¼Œç”¨äºé‡å»ºæ­£å¸¸è„‘ç»“æ„ï¼Œå¯å¤„ç†å¥åº·æ‰«æå’Œç—…ç†æƒ…å†µã€‚UNAé‡‡ç”¨æµä½“é©±åŠ¨å¼‚å¸¸éšæœºåŒ–æ–¹æ³•ï¼Œå¯å®æ—¶ç”Ÿæˆæ— é™æ•°é‡çš„é€¼çœŸç—…ç†ç‰¹å¾ã€‚UNAç»è¿‡åˆæˆå’ŒçœŸå®æ•°æ®çš„è®­ç»ƒï¼Œå¯ç›´æ¥åº”ç”¨äºæ½œåœ¨ç—…ç†çš„çœŸå®å›¾åƒï¼Œæ— éœ€å¾®è°ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°æ®é©±åŠ¨çš„æœºå™¨å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­çš„åº”ç”¨è¿›å±•ã€‚</li>
<li>ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼šé’ˆå¯¹ç‰¹å®šæ¨¡æ€å’Œåˆ†è¾¨ç‡ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„é€šç”¨æ€§ã€‚</li>
<li>UNAæ˜¯ä¸€ç§é€šç”¨çš„ã€æ¨¡æ€æ— å…³çš„å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºé‡å»ºæ­£å¸¸è„‘ç»“æ„ã€‚</li>
<li>UNAå¯ä»¥å¤„ç†å¥åº·å’Œç—…ç†æƒ…å†µä¸‹çš„æ‰«æã€‚</li>
<li>UNAé‡‡ç”¨æµä½“é©±åŠ¨å¼‚å¸¸éšæœºåŒ–æ–¹æ³•ï¼Œç”Ÿæˆé€¼çœŸçš„ç—…ç†ç‰¹å¾ã€‚</li>
<li>UNAç»è¿‡åˆæˆå’ŒçœŸå®æ•°æ®çš„è®­ç»ƒï¼Œå¯ç›´æ¥åº”ç”¨äºçœŸå®å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13370">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-666eceb86ae1aa8fc1cf31ef7273b04b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9b7af2996b1d4ea7a0a0f1aa7181a1b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31235e911381ef250ca7bbb625f1894a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a49cb35b90b031dc4a4e72a26627fe23.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MEDFORM-A-Foundation-Model-for-Contrastive-Learning-of-CT-Imaging-and-Clinical-Numeric-Data-in-Multi-Cancer-Analysis"><a href="#MEDFORM-A-Foundation-Model-for-Contrastive-Learning-of-CT-Imaging-and-Clinical-Numeric-Data-in-Multi-Cancer-Analysis" class="headerlink" title="MEDFORM: A Foundation Model for Contrastive Learning of CT Imaging and   Clinical Numeric Data in Multi-Cancer Analysis"></a>MEDFORM: A Foundation Model for Contrastive Learning of CT Imaging and   Clinical Numeric Data in Multi-Cancer Analysis</h2><p><strong>Authors:Daeun Jung, Jaehyeok Jang, Sooyoung Jang, Yu Rang Park</strong></p>
<p>Computed tomography (CT) and clinical numeric data are essential modalities for cancer evaluation, but building large-scale multimodal training datasets for developing medical foundation models remains challenging due to the structural complexity of multi-slice CT data and high cost of expert annotation. In this study, we propose MEDFORM, a multimodal pre-training strategy that guides CT image representation learning using complementary information from clinical data for medical foundation model development. MEDFORM efficiently processes CT slice through multiple instance learning (MIL) and adopts a dual pre-training strategy: first pretraining the CT slice feature extractor using SimCLR-based self-supervised learning, then aligning CT and clinical modalities through cross-modal contrastive learning. Our model was pre-trained on three different cancer types: lung cancer (141,171 slices), breast cancer (8,100 slices), colorectal cancer (10,393 slices). The experimental results demonstrated that this dual pre-training strategy improves cancer classification performance and maintains robust performance in few-shot learning scenarios. Code available at <a target="_blank" rel="noopener" href="https://github.com/DigitalHealthcareLab/25MultiModalFoundationModel.git">https://github.com/DigitalHealthcareLab/25MultiModalFoundationModel.git</a> </p>
<blockquote>
<p>è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰å’Œä¸´åºŠæ•°å€¼æ•°æ®å¯¹äºç™Œç—‡è¯„ä¼°è‡³å…³é‡è¦ï¼Œä½†ç”±äºå¤šå±‚CTæ•°æ®çš„ç»“æ„å¤æ‚æ€§ä»¥åŠä¸“å®¶æ ‡æ³¨çš„é«˜æˆæœ¬ï¼Œæ„å»ºç”¨äºå¼€å‘åŒ»ç–—åŸºç¡€æ¨¡å‹çš„å¤§è§„æ¨¡å¤šæ¨¡å¼è®­ç»ƒæ•°æ®é›†ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MEDFORMï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡å¼é¢„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡åˆ©ç”¨ä¸´åºŠæ•°æ®çš„è¡¥å……ä¿¡æ¯æ¥æŒ‡å¯¼CTå›¾åƒè¡¨ç¤ºå­¦ä¹ ï¼Œä»¥å¼€å‘åŒ»ç–—åŸºç¡€æ¨¡å‹ã€‚MEDFORMé€šè¿‡å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æœ‰æ•ˆåœ°å¤„ç†CTåˆ‡ç‰‡ï¼Œå¹¶é‡‡ç”¨åŒé‡é¢„è®­ç»ƒç­–ç•¥ï¼šé¦–å…ˆä½¿ç”¨åŸºäºSimCLRçš„è‡ªæˆ‘ç›‘ç£å­¦ä¹ å¯¹CTåˆ‡ç‰‡ç‰¹å¾æå–å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åé€šè¿‡è·¨æ¨¡å¼å¯¹æ¯”å­¦ä¹ å¯¹é½CTå’Œä¸´åºŠæ¨¡å¼ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸‰ç§ä¸åŒç±»å‹çš„ç™Œç—‡ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼šè‚ºç™Œï¼ˆ141,171åˆ‡ç‰‡ï¼‰ã€ä¹³è…ºç™Œï¼ˆ8,100åˆ‡ç‰‡ï¼‰å’Œç»“è‚ ç™Œï¼ˆ10,393åˆ‡ç‰‡ï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§åŒé‡é¢„è®­ç»ƒç­–ç•¥æé«˜äº†ç™Œç—‡åˆ†ç±»æ€§èƒ½ï¼Œå¹¶åœ¨å°æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­ä¿æŒäº†ç¨³å¥çš„æ€§èƒ½ã€‚ä»£ç å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/DigitalHealthcareLab/25MultiModalFoundationModel.git">ç½‘å€</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13277v1">PDF</a> 8 pages, 1 figure</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMEDFORMçš„å¤šæ¨¡æ€é¢„è®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨ä¸´åºŠæ•°æ®ä¸­çš„äº’è¡¥ä¿¡æ¯æŒ‡å¯¼CTå›¾åƒè¡¨ç¤ºå­¦ä¹ ï¼Œç”¨äºå¼€å‘åŒ»å­¦åŸºç¡€æ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰å¤„ç†CTåˆ‡ç‰‡ï¼Œå¹¶é‡‡ç”¨åŸºäºSimCLRçš„è‡ªç›‘ç£å­¦ä¹ å’Œè·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ çš„åŒé¢„è®­ç»ƒç­–ç•¥ï¼Œæ¨¡å‹åœ¨è‚ºç™Œã€ä¹³è…ºç™Œå’Œç»“è‚ ç™Œä¸‰ç§ä¸åŒç™Œç—‡ç±»å‹ä¸Šçš„é¢„è®­ç»ƒè¡¨ç°ä¼˜å¼‚ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥åŒé¢„è®­ç»ƒç­–ç•¥èƒ½æé«˜ç™Œç—‡åˆ†ç±»æ€§èƒ½ï¼Œå¹¶åœ¨å°æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹ä¿æŒç¨³å¥æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MEDFORMæ˜¯ä¸€ç§å¤šæ¨¡æ€é¢„è®­ç»ƒç­–ç•¥ï¼Œç”¨äºåŒ»å­¦åŸºç¡€æ¨¡å‹çš„å¼€å‘ï¼Œç»“åˆCTå›¾åƒå’Œä¸´åºŠæ•°æ®ã€‚</li>
<li>MEDFORMé‡‡ç”¨å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰å¤„ç†CTåˆ‡ç‰‡ï¼Œä»¥æé«˜æ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚</li>
<li>è¯¥ç­–ç•¥åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µçš„é¢„è®­ç»ƒï¼šé¦–å…ˆä½¿ç”¨åŸºäºSimCLRçš„è‡ªç›‘ç£å­¦ä¹ é¢„è®­ç»ƒCTåˆ‡ç‰‡ç‰¹å¾æå–å™¨ï¼Œç„¶åé€šè¿‡è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ å¯¹é½CTå’Œä¸´åºŠæ¨¡æ€ã€‚</li>
<li>æ¨¡å‹åœ¨è‚ºç™Œã€ä¹³è…ºç™Œå’Œç»“è‚ ç™Œä¸‰ç§ç™Œç—‡ç±»å‹ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒMEDFORMç­–ç•¥èƒ½æé«˜ç™Œç—‡åˆ†ç±»æ€§èƒ½ã€‚</li>
<li>è¯¥ç­–ç•¥åœ¨å°æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹è¡¨ç°å‡ºç¨³å¥çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13277">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4fcab9de5bbc4422f438b1e058ed7acf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba86564eb0e2a231ab18b51566b28d32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-125a42217eaa579cc3e76791eb3e8d48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c615036463815b15aea1e1a4884b3611.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Novel-Scene-Coupling-Semantic-Mask-Network-for-Remote-Sensing-Image-Segmentation"><a href="#A-Novel-Scene-Coupling-Semantic-Mask-Network-for-Remote-Sensing-Image-Segmentation" class="headerlink" title="A Novel Scene Coupling Semantic Mask Network for Remote Sensing Image   Segmentation"></a>A Novel Scene Coupling Semantic Mask Network for Remote Sensing Image   Segmentation</h2><p><strong>Authors:Xiaowen Ma, Rongrong Lian, Zhenkai Wu, Renxiang Guan, Tingfeng Hong, Mengjiao Zhao, Mengting Ma, Jiangtao Nie, Zhenhong Du, Siyang Song, Wei Zhang</strong></p>
<p>As a common method in the field of computer vision, spatial attention mechanism has been widely used in semantic segmentation of remote sensing images due to its outstanding long-range dependency modeling capability. However, remote sensing images are usually characterized by complex backgrounds and large intra-class variance that would degrade their analysis performance. While vanilla spatial attention mechanisms are based on dense affine operations, they tend to introduce a large amount of background contextual information and lack of consideration for intrinsic spatial correlation. To deal with such limitations, this paper proposes a novel scene-Coupling semantic mask network, which reconstructs the vanilla attention with scene coupling and local global semantic masks strategies. Specifically, scene coupling module decomposes scene information into global representations and object distributions, which are then embedded in the attention affinity processes. This Strategy effectively utilizes the intrinsic spatial correlation between features so that improve the process of attention modeling. Meanwhile, local global semantic masks module indirectly correlate pixels with the global semantic masks by using the local semantic mask as an intermediate sensory element, which reduces the background contextual interference and mitigates the effect of intra-class variance. By combining the above two strategies, we propose the model SCSM, which not only can efficiently segment various geospatial objects in complex scenarios, but also possesses inter-clean and elegant mathematical representations. Experimental results on four benchmark datasets demonstrate the the effectiveness of the above two strategies for improving the attention modeling of remote sensing images. The dataset and code are available at <a target="_blank" rel="noopener" href="https://github.com/xwmaxwma/rssegmentation">https://github.com/xwmaxwma/rssegmentation</a> </p>
<blockquote>
<p>ä½œä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å¸¸è§æ–¹æ³•ï¼Œç©ºé—´æ³¨æ„åŠ›æœºåˆ¶å› å…¶å‡ºè‰²çš„é•¿ç¨‹ä¾èµ–å»ºæ¨¡èƒ½åŠ›è€Œå¹¿æ³›åº”ç”¨äºé¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²ã€‚ç„¶è€Œï¼Œé¥æ„Ÿå›¾åƒé€šå¸¸å…·æœ‰å¤æ‚çš„èƒŒæ™¯å’Œè¾ƒå¤§çš„ç±»å†…å·®å¼‚ï¼Œè¿™å¯èƒ½ä¼šé™ä½å…¶åˆ†ææ€§èƒ½ã€‚è™½ç„¶æ™®é€šç©ºé—´æ³¨æ„åŠ›æœºåˆ¶æ˜¯åŸºäºå¯†é›†çš„ä»¿å°„è¿ç®—ï¼Œä½†å®ƒä»¬å¾€å¾€å¼•å…¥å¤§é‡èƒŒæ™¯ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶ä¸”æ²¡æœ‰è€ƒè™‘åˆ°å†…åœ¨çš„ç©ºé—´ç›¸å…³æ€§ã€‚ä¸ºäº†åº”å¯¹è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åœºæ™¯è€¦åˆè¯­ä¹‰æ©ç ç½‘ç»œï¼Œè¯¥ç½‘ç»œé€šè¿‡åœºæ™¯è€¦åˆå’Œå±€éƒ¨å…¨å±€è¯­ä¹‰æ©ç ç­–ç•¥é‡å»ºäº†æ™®é€šæ³¨æ„åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œåœºæ™¯è€¦åˆæ¨¡å—å°†åœºæ™¯ä¿¡æ¯åˆ†è§£ä¸ºå…¨å±€è¡¨ç¤ºå’Œå¯¹è±¡åˆ†å¸ƒï¼Œç„¶åå°†å…¶åµŒå…¥åˆ°æ³¨æ„åŠ›äº²å’Œè¿‡ç¨‹ä¸­ã€‚è¯¥ç­–ç•¥æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç‰¹å¾ä¹‹é—´çš„å†…åœ¨ç©ºé—´ç›¸å…³æ€§ï¼Œä»è€Œæ”¹è¿›äº†æ³¨æ„åŠ›å»ºæ¨¡çš„è¿‡ç¨‹ã€‚åŒæ—¶ï¼Œå±€éƒ¨å…¨å±€è¯­ä¹‰æ©ç æ¨¡å—é€šè¿‡åˆ©ç”¨å±€éƒ¨è¯­ä¹‰æ©ç ä½œä¸ºä¸­é—´æ„ŸçŸ¥å…ƒç´ ï¼Œé—´æ¥åœ°å°†åƒç´ ä¸å…¨å±€è¯­ä¹‰æ©ç ç›¸å…³è”ï¼Œè¿™å‡å°‘äº†èƒŒæ™¯ä¸Šä¸‹æ–‡çš„å¹²æ‰°å¹¶å‡è½»äº†ç±»å†…å·®å¼‚çš„å½±å“ã€‚é€šè¿‡ç»“åˆä¸Šè¿°ä¸¤ç§ç­–ç•¥ï¼Œæˆ‘ä»¬æå‡ºäº†SCSMæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ä»…å¯ä»¥åœ¨å¤æ‚åœºæ™¯ä¸­æœ‰æ•ˆåœ°åˆ†å‰²å„ç§åœ°ç†ç©ºé—´å¯¹è±¡ï¼Œè€Œä¸”è¿˜å…·æœ‰ç®€æ´ä¼˜é›…çš„æ•°å­¦è¡¨ç¤ºã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸Šè¿°ä¸¤ç§ç­–ç•¥åœ¨æ”¹è¿›é¥æ„Ÿå›¾åƒçš„æ³¨æ„åŠ›å»ºæ¨¡æ–¹é¢éå¸¸æœ‰æ•ˆã€‚æ•°æ®é›†å’Œä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/xwmaxwma/rssegmentation%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/xwmaxwma/rssegmentationè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13130v1">PDF</a> Accepted by ISPRS Journal of Photogrammetry and Remote Sensing</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„åœºæ™¯è€¦åˆè¯­ä¹‰æ©è†œç½‘ç»œï¼Œé€šè¿‡åœºæ™¯è€¦åˆå’Œå±€éƒ¨å…¨å±€è¯­ä¹‰æ©è†œç­–ç•¥ï¼Œæ”¹è¿›äº†åŸºäºå¯†é›†ä»¿å°„è¿ç®—çš„ä¼ ç»Ÿç©ºé—´æ³¨æ„æœºåˆ¶ã€‚è¯¥ç­–ç•¥èƒ½æ›´æœ‰æ•ˆåœ°å¤„ç†é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²ä¸­çš„å¤æ‚èƒŒæ™¯å’Œç±»å†…å·®å¼‚é—®é¢˜ï¼Œæå‡æ³¨æ„åŠ›å»ºæ¨¡è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡æœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç©ºé—´æ³¨æ„æœºåˆ¶åœ¨é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²ä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä½†å­˜åœ¨å¤„ç†å¤æ‚èƒŒæ™¯å’Œç±»å†…å·®å¼‚æ—¶çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚</li>
<li>ç°æœ‰ç©ºé—´æ³¨æ„æœºåˆ¶åŸºäºå¯†é›†ä»¿å°„è¿ç®—ï¼Œæ˜“å¼•å…¥å¤§é‡èƒŒæ™¯ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸”æœªå……åˆ†è€ƒè™‘ç‰¹å¾é—´çš„å†…åœ¨ç©ºé—´ç›¸å…³æ€§ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„åœºæ™¯è€¦åˆè¯­ä¹‰æ©è†œç½‘ç»œï¼Œé€šè¿‡åœºæ™¯è€¦åˆæ¨¡å—å’Œå±€éƒ¨å…¨å±€è¯­ä¹‰æ©è†œç­–ç•¥ï¼Œæ”¹è¿›äº†æ³¨æ„åŠ›å»ºæ¨¡è¿‡ç¨‹ã€‚</li>
<li>åœºæ™¯è€¦åˆæ¨¡å—å°†åœºæ™¯ä¿¡æ¯åˆ†è§£ä¸ºå…¨å±€è¡¨ç¤ºå’Œå¯¹è±¡åˆ†å¸ƒï¼Œå¹¶å°†å…¶åµŒå…¥æ³¨æ„åŠ›äº²å’Œè¿‡ç¨‹ä¸­ï¼Œæœ‰æ•ˆåˆ©ç”¨ç‰¹å¾é—´çš„å†…åœ¨ç©ºé—´ç›¸å…³æ€§ã€‚</li>
<li>å±€éƒ¨å…¨å±€è¯­ä¹‰æ©è†œæ¨¡å—é€šè¿‡å±€éƒ¨è¯­ä¹‰æ©è†œä½œä¸ºä¸­é—´æ„ŸçŸ¥å…ƒç´ ï¼Œé—´æ¥åœ°å°†åƒç´ ä¸å…¨å±€è¯­ä¹‰æ©è†œç›¸å…³è”ï¼Œå‡å°‘äº†èƒŒæ™¯ä¸Šä¸‹æ–‡å¹²æ‰°å’Œç±»å†…å·®å¼‚çš„å½±å“ã€‚</li>
<li>ç»“åˆä¸Šè¿°ä¸¤ä¸ªç­–ç•¥ï¼Œæå‡ºçš„SCSMæ¨¡å‹ä¸ä»…èƒ½æœ‰æ•ˆåœ°åˆ†å‰²å¤æ‚åœºæ™¯ä¸­çš„å„ç±»åœ°ç†ç©ºé—´å¯¹è±¡ï¼Œè¿˜å…·æœ‰ç®€æ´ä¼˜é›…çš„æ•°å­¦è¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13130">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-67b4eac1bca56d7112c4e0142171054d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1a42a0ff498e03212e21e65cf7fb2a24.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c164c31f1b1a008e90b7bdb29b430f48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7142e701882014649216af4280f1bc4c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-74534a7c471000c0adb729543cf541ca.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="UNSURE-self-supervised-learning-with-Unknown-Noise-level-and-Steinâ€™s-Unbiased-Risk-Estimate"><a href="#UNSURE-self-supervised-learning-with-Unknown-Noise-level-and-Steinâ€™s-Unbiased-Risk-Estimate" class="headerlink" title="UNSURE: self-supervised learning with Unknown Noise level and Steinâ€™s   Unbiased Risk Estimate"></a>UNSURE: self-supervised learning with Unknown Noise level and Steinâ€™s   Unbiased Risk Estimate</h2><p><strong>Authors:JuliÃ¡n Tachella, Mike Davies, Laurent Jacques</strong></p>
<p>Recently, many self-supervised learning methods for image reconstruction have been proposed that can learn from noisy data alone, bypassing the need for ground-truth references. Most existing methods cluster around two classes: i) Steinâ€™s Unbiased Risk Estimate (SURE) and similar approaches that assume full knowledge of the distribution, and ii) Noise2Self and similar cross-validation methods that require very mild knowledge about the noise distribution. The first class of methods tends to be impractical, as the noise level is often unknown in real-world applications, and the second class is often suboptimal compared to supervised learning. In this paper, we provide a theoretical framework that characterizes this expressivity-robustness trade-off and propose a new approach based on SURE, but unlike the standard SURE, does not require knowledge about the noise level. Throughout a series of experiments, we show that the proposed estimator outperforms other existing self-supervised methods on various imaging inverse problems. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œè®¸å¤šç”¨äºå›¾åƒé‡å»ºçš„è‡ªæˆ‘ç›‘ç£å­¦ä¹ æ–¹æ³•å·²è¢«æå‡ºï¼Œè¿™äº›æ–¹æ³•å¯ä»¥ä»…ä»å™ªå£°æ•°æ®ä¸­å­¦ä¹ ï¼Œæ— éœ€çœŸå®å‚è€ƒã€‚ç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¸¤ç±»ä¸Šï¼ši) Steinçš„æ— åé£é™©ä¼°è®¡ï¼ˆSUREï¼‰å’Œå‡è®¾å¯¹åˆ†å¸ƒæœ‰å……åˆ†äº†è§£çš„ç±»ä¼¼æ–¹æ³•ï¼Œä»¥åŠii) Noise2Selfå’Œå…³äºå™ªå£°åˆ†å¸ƒåªéœ€éå¸¸è½»å¾®äº†è§£çš„ç±»ä¼¼äº¤å‰éªŒè¯æ–¹æ³•ã€‚ç¬¬ä¸€ç±»æ–¹æ³•å¾€å¾€ä¸åˆ‡å®é™…ï¼Œå› ä¸ºåœ¨ç°å®ä¸–ç•Œçš„å®é™…åº”ç”¨ä¸­å¾€å¾€ä¸çŸ¥é“å™ªå£°æ°´å¹³ï¼Œç¬¬äºŒç±»æ–¹æ³•ä¸ç›‘ç£å­¦ä¹ ç›¸æ¯”é€šå¸¸è¡¨ç°ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æè¿°äº†è¡¨è¾¾æ€§ç¨³å¥æ€§æƒè¡¡çš„ç‰¹ç‚¹ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºSUREçš„æ–°æ–¹æ³•ï¼Œä½†ä¸æ ‡å‡†çš„SUREä¸åŒï¼Œå®ƒä¸éœ€è¦äº†è§£å™ªå£°æ°´å¹³ã€‚é€šè¿‡ä¸€ç³»åˆ—å®éªŒï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œæ‰€æå‡ºçš„ä¼°è®¡å™¨åœ¨å„ç§æˆåƒåé—®é¢˜ä¸Šä¼˜äºå…¶ä»–ç°æœ‰çš„è‡ªç›‘ç£æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.01985v3">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒé‡å»ºä¸­çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•è¿‘å¹´æ¥å¤‡å—å…³æ³¨ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºå™ªå£°æ°´å¹³åˆ†å¸ƒçŸ¥è¯†ï¼Œå®é™…åº”ç”¨ä¸­éš¾ä»¥å®ç°æˆ–æ•ˆæœä¸ç†æƒ³ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºSteinçš„æ— åé£é™©ä¼°è®¡çš„æ–°æ–¹æ³•ï¼Œæ— éœ€äº†è§£å™ªå£°æ°´å¹³ä¿¡æ¯ï¼Œå®éªŒè¯æ˜åœ¨å¤šç§å›¾åƒé€†é—®é¢˜ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨åŒ»å­¦å›¾åƒé‡å»ºä¸­é€æ¸å—åˆ°é‡è§†ï¼Œèƒ½å¤Ÿä»å™ªå£°æ•°æ®ä¸­å­¦ä¹ ï¼Œæ— éœ€å‚è€ƒçœŸå®å›¾åƒã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šåŸºäºSteinçš„æ— åé£é™©ä¼°è®¡ï¼ˆSUREï¼‰å’Œå…¶ä»–å‡è®¾å¯¹å™ªå£°åˆ†å¸ƒæœ‰å……åˆ†äº†è§£çš„æ–¹æ³•ã€‚</li>
<li>åŸºäºSUREçš„æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­ç”±äºå™ªå£°æ°´å¹³æœªçŸ¥è€Œæ˜¾å¾—ä¸å®ç”¨ã€‚</li>
<li>Noise2Selfç­‰äº¤å‰éªŒè¯æ–¹æ³•è™½ç„¶å¯¹å™ªå£°åˆ†å¸ƒçŸ¥è¯†éœ€æ±‚è¾ƒè½»ï¼Œä½†æ•ˆæœå¸¸ä¸å¦‚ç›‘ç£å­¦ä¹ ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„æ–°æ–¹æ³•åŸºäºSUREä½†æ— éœ€äº†è§£å™ªå£°æ°´å¹³ä¿¡æ¯ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œæ–°æ–¹æ³•åœ¨å„ç§å›¾åƒé€†é—®é¢˜ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–è‡ªç›‘ç£æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.01985">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0d9efca56c0e0a13ef26e5c22e41b096.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-adf5a04399bf9bd8d3f6a101d2c05b34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b392b6d93ba06f19d94a41bf0d0e68ac.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ST-USleepNet-A-Spatial-Temporal-Coupling-Prominence-Network-for-Multi-Channel-Sleep-Staging"><a href="#ST-USleepNet-A-Spatial-Temporal-Coupling-Prominence-Network-for-Multi-Channel-Sleep-Staging" class="headerlink" title="ST-USleepNet: A Spatial-Temporal Coupling Prominence Network for   Multi-Channel Sleep Staging"></a>ST-USleepNet: A Spatial-Temporal Coupling Prominence Network for   Multi-Channel Sleep Staging</h2><p><strong>Authors:Jingying Ma, Qika Lin, Ziyu Jia, Mengling Feng</strong></p>
<p>Sleep staging is critical to assess sleep quality and diagnose disorders. Despite advancements in artificial intelligence enabling automated sleep staging, significant challenges remain: (1) Simultaneously extracting prominent temporal and spatial sleep features from multi-channel raw signals, including characteristic sleep waveforms and salient spatial brain networks. (2) Capturing the spatial-temporal coupling patterns essential for accurate sleep staging. To address these challenges, we propose a novel framework named ST-USleepNet, comprising a spatial-temporal graph construction module (ST) and a U-shaped sleep network (USleepNet). The ST module converts raw signals into a spatial-temporal graph based on signal similarity, temporal, and spatial relationships to model spatial-temporal coupling patterns. The USleepNet employs a U-shaped structure for both the temporal and spatial streams, mirroring its original use in image segmentation to isolate significant targets. Applied to raw sleep signals and graph data from the ST module, USleepNet effectively segments these inputs, simultaneously extracting prominent temporal and spatial sleep features. Testing on three datasets demonstrates that ST-USleepNet outperforms existing baselines, and model visualizations confirm its efficacy in extracting prominent sleep features and temporal-spatial coupling patterns across various sleep stages. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/Majy-Yuji/ST-USleepNet.git">https://github.com/Majy-Yuji/ST-USleepNet.git</a>. </p>
<blockquote>
<p>ç¡çœ åˆ†æœŸå¯¹äºè¯„ä¼°ç¡çœ è´¨é‡å’Œè¯Šæ–­ç¡çœ éšœç¢è‡³å…³é‡è¦ã€‚å°½ç®¡äººå·¥æ™ºèƒ½çš„è¿›æ­¥å·²ç»å®ç°äº†è‡ªåŠ¨åŒ–çš„ç¡çœ åˆ†æœŸï¼Œä½†ä»å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼š(1) ä»å¤šé€šé“åŸå§‹ä¿¡å·ä¸­åŒæ—¶æå–çªå‡ºçš„æ—¶é—´å’Œç©ºé—´ç¡çœ ç‰¹å¾ï¼ŒåŒ…æ‹¬ç‰¹å¾ç¡çœ æ³¢å½¢å’Œæ˜¾è‘—çš„è„‘ç©ºé—´ç½‘ç»œã€‚(2)æ•æ‰å¯¹å‡†ç¡®ç¡çœ åˆ†æœŸè‡³å…³é‡è¦çš„æ—¶ç©ºè€¦åˆæ¨¡å¼ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºST-USleepNetçš„æ–°å‹æ¡†æ¶ï¼Œå®ƒåŒ…å«ä¸€ä¸ªæ—¶ç©ºå›¾æ„å»ºæ¨¡å—(ST)å’Œä¸€ä¸ªUå‹ç¡çœ ç½‘ç»œ(USleepNet)ã€‚STæ¨¡å—æ ¹æ®ä¿¡å·ç›¸ä¼¼æ€§ã€æ—¶é—´å’Œç©ºé—´å…³ç³»å°†åŸå§‹ä¿¡å·è½¬æ¢ä¸ºæ—¶ç©ºå›¾ï¼Œä»¥æ¨¡æ‹Ÿæ—¶ç©ºè€¦åˆæ¨¡å¼ã€‚USleepNeté‡‡ç”¨Uå‹ç»“æ„ï¼Œç”¨äºæ—¶é—´å’Œç©ºé—´æµï¼Œæ¨¡ä»¿å…¶åœ¨å›¾åƒåˆ†å‰²ä¸­çš„åŸå§‹ç”¨é€”ï¼Œä»¥éš”ç¦»é‡è¦ç›®æ ‡ã€‚åº”ç”¨äºæ¥è‡ªSTæ¨¡å—çš„åŸå§‹ç¡çœ ä¿¡å·å’Œå›¾å½¢æ•°æ®ï¼ŒUSleepNetæœ‰æ•ˆåœ°åˆ†å‰²äº†è¿™äº›è¾“å…¥ï¼ŒåŒæ—¶æå–äº†çªå‡ºçš„æ—¶é—´æ€§å’Œç©ºé—´æ€§ç¡çœ ç‰¹å¾ã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒST-USleepNetçš„æ€§èƒ½è¶…è¿‡äº†ç°æœ‰åŸºçº¿ï¼Œæ¨¡å‹å¯è§†åŒ–è¯å®äº†å…¶åœ¨æå–å„ç¡çœ é˜¶æ®µçš„é‡è¦ç¡çœ ç‰¹å¾å’Œæ—¶ç©ºè€¦åˆæ¨¡å¼æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Majy-Yuji/ST-USleepNet.git">https://github.com/Majy-Yuji/ST-USleepNet.git</a>å¤„è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.11884v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºST-USleepNetçš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºè§£å†³ç¡çœ åˆ†æœŸä¸­ä»å¤šé€šé“åŸå§‹ä¿¡å·ä¸­æå–é‡è¦æ—¶ç©ºç¡çœ ç‰¹å¾ä»¥åŠæ•æ‰æ—¶ç©ºè€¦åˆæ¨¡å¼çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªæ—¶ç©ºå›¾æ„å»ºæ¨¡å—ï¼ˆSTï¼‰å’Œä¸€ä¸ªUå‹ç¡çœ ç½‘ç»œï¼ˆUSleepNetï¼‰ã€‚è¯¥æ¡†æ¶åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå¯æœ‰æ•ˆæå–é‡è¦ç¡çœ ç‰¹å¾å’Œæ—¶ç©ºè€¦åˆæ¨¡å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¡çœ åˆ†æœŸæ˜¯è¯„ä¼°ç¡çœ è´¨é‡å’Œè¯Šæ–­ç¡çœ éšœç¢çš„å…³é”®ã€‚</li>
<li>ç›®å‰åœ¨ç¡çœ åˆ†æœŸä¸­é¢ä¸´ä»å¤šé€šé“åŸå§‹ä¿¡å·æå–é‡è¦æ—¶ç©ºç¡çœ ç‰¹å¾å’Œæ•æ‰æ—¶ç©ºè€¦åˆæ¨¡å¼çš„æŒ‘æˆ˜ã€‚</li>
<li>ST-USleepNetæ¡†æ¶ç”±æ—¶ç©ºå›¾æ„å»ºæ¨¡å—ï¼ˆSTï¼‰å’ŒUå‹ç¡çœ ç½‘ç»œï¼ˆUSleepNetï¼‰ç»„æˆï¼Œç”¨äºè§£å†³è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>STæ¨¡å—å°†åŸå§‹ä¿¡å·è½¬æ¢ä¸ºåŸºäºä¿¡å·ç›¸ä¼¼æ€§çš„æ—¶ç©ºå›¾ï¼Œä»¥æ¨¡æ‹Ÿæ—¶ç©ºè€¦åˆæ¨¡å¼ã€‚</li>
<li>USleepNeté‡‡ç”¨Uå‹ç»“æ„ï¼ŒåŒæ—¶å¤„ç†æ—¶ç©ºæµï¼Œæœ‰æ•ˆéš”ç¦»æ˜¾è‘—ç›®æ ‡ï¼Œå¹¶ä»åŸå§‹ç¡çœ ä¿¡å·å’ŒSTæ¨¡å—çš„å›¾æ•°æ®ä¸­æå–é‡è¦ç‰¹å¾ã€‚</li>
<li>åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒST-USleepNetçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.11884">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-848c4ab4e5ff421828f3903cda3da0c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56b1e3e239fc71af13be7e3f22188382.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cfd1120fbd5e69389e344ce677c842a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bccd8ec792026cf3d40d2f90feb7377.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Robust-Simultaneous-Multislice-MRI-Reconstruction-Using-Deep-Generative-Priors"><a href="#Robust-Simultaneous-Multislice-MRI-Reconstruction-Using-Deep-Generative-Priors" class="headerlink" title="Robust Simultaneous Multislice MRI Reconstruction Using Deep Generative   Priors"></a>Robust Simultaneous Multislice MRI Reconstruction Using Deep Generative   Priors</h2><p><strong>Authors:Shoujin Huang, Guanxiong Luo, Yunlin Zhao, Yilong Liu, Yuwan Wang, Kexin Yang, Jingzhe Liu, Hua Guo, Min Wang, Lingyan Zhang, Mengye Lyu</strong></p>
<p>Simultaneous multislice (SMS) imaging is a powerful technique for accelerating magnetic resonance imaging (MRI) acquisitions. However, SMS reconstruction remains challenging due to complex signal interactions between and within the excited slices. In this study, we introduce ROGER, a robust SMS MRI reconstruction method based on deep generative priors. Utilizing denoising diffusion probabilistic models (DDPM), ROGER begins with Gaussian noise and gradually recovers individual slices through reverse diffusion iterations while enforcing data consistency from measured k-space data within the readout concatenation framework. The posterior sampling procedure is designed such that the DDPM training can be performed on single-slice images without requiring modifications for SMS tasks. Additionally, our method incorporates a low-frequency enhancement (LFE) module to address the practical issue that SMS-accelerated fast spin echo (FSE) and echo planar imaging (EPI) sequences cannot easily embed fully-sampled autocalibration signals. Extensive experiments on both retrospectively and prospectively accelerated datasets demonstrate that ROGER consistently outperforms existing methods, enhancing both anatomical and functional imaging with strong out-of-distribution generalization. The source code and sample data for ROGER are available at <a target="_blank" rel="noopener" href="https://github.com/Solor-pikachu/ROGER">https://github.com/Solor-pikachu/ROGER</a>. </p>
<blockquote>
<p>å±‚å å¤šåˆ‡ç‰‡ï¼ˆSimultaneous Multisliceï¼Œç®€ç§°SMSï¼‰æˆåƒæ˜¯ä¸€ç§åŠ é€Ÿç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰é‡‡é›†çš„å¼ºå¤§æŠ€æœ¯ã€‚ç„¶è€Œï¼Œç”±äºæ¿€å‘åˆ‡ç‰‡ä¹‹é—´å’Œåˆ‡ç‰‡å†…éƒ¨çš„å¤æ‚ä¿¡å·ç›¸äº’ä½œç”¨ï¼ŒSMSé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºæ·±åº¦ç”Ÿæˆå…ˆéªŒçš„ç¨³å¥SMS MRIé‡å»ºæ–¹æ³•â€”â€”ROGERã€‚åˆ©ç”¨é™å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ï¼ŒROGERä»é«˜æ–¯å™ªå£°å¼€å§‹ï¼Œé€šè¿‡åå‘æ‰©æ•£è¿­ä»£é€æ¸æ¢å¤å•ä¸ªåˆ‡ç‰‡ï¼ŒåŒæ—¶åœ¨è¯»å‡ºæ‹¼æ¥æ¡†æ¶å†…å¼ºåˆ¶å®æ–½æ¥è‡ªæµ‹é‡kç©ºé—´æ•°æ®çš„æ•°æ®ä¸€è‡´æ€§ã€‚åé‡‡æ ·ç¨‹åºçš„è®¾è®¡ä½¿å¾—å¯ä»¥åœ¨å•åˆ‡ç‰‡å›¾åƒä¸Šå¯¹DDPMè¿›è¡Œè®­ç»ƒï¼Œè€Œæ— éœ€å¯¹SMSä»»åŠ¡è¿›è¡Œä¿®æ”¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜èå…¥äº†ä¸€ä¸ªä½é¢‘å¢å¼ºï¼ˆLFEï¼‰æ¨¡å—ï¼Œä»¥è§£å†³ä¸€ä¸ªå®é™…é—®é¢˜ï¼Œå³SMSåŠ é€Ÿçš„å¿«é€Ÿè‡ªæ—‹å›æ³¢ï¼ˆFSEï¼‰å’Œå›æ³¢å¹³é¢æˆåƒï¼ˆEPIï¼‰åºåˆ—æ— æ³•è½»æ¾åµŒå…¥å®Œå…¨é‡‡æ ·çš„è‡ªåŠ¨æ ¡å‡†ä¿¡å·ã€‚å¯¹å›é¡¾æ€§å’Œå‰ç»æ€§åŠ é€Ÿæ•°æ®é›†çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒROGERå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨è§£å‰–å’ŒåŠŸèƒ½æ€§æˆåƒæ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ROGERçš„æºä»£ç å’Œæ ·æœ¬æ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Solor-pikachu/ROGER%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Solor-pikachu/ROGERæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.21600v2">PDF</a> Submitted to Medical Image Analysis. New fMRI analysis and figures   are added since v1</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ·±åº¦ç”Ÿæˆå…ˆéªŒçš„ROGERæ–¹æ³•åœ¨SMS MRIé‡å»ºä¸­å…·æœ‰å¼ºå¤§çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ï¼Œä»é«˜æ–¯å™ªå£°å¼€å§‹é€æ­¥æ¢å¤åˆ‡ç‰‡ï¼ŒåŒæ—¶é€šè¿‡åå‘æ‰©æ•£è¿­ä»£åœ¨è¯»å–æ‹¼æ¥æ¡†æ¶ä¸­å¼ºåˆ¶å®æ–½æ•°æ®ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼ŒROGERæ–¹æ³•è¿˜èå…¥äº†ä½é¢‘å¢å¼ºæ¨¡å—ï¼Œè§£å†³äº†SMSåŠ é€Ÿçš„å¿«é€Ÿè‡ªæ—‹å›æ³¢ï¼ˆFSEï¼‰å’Œå›å£°å¹³é¢æˆåƒåºåˆ—éš¾ä»¥åµŒå…¥å…¨é‡‡æ ·è‡ªåŠ¨æ ¡å‡†ä¿¡å·çš„å®é™…é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒROGERåœ¨å›é¡¾æ€§å’Œå‰ç»æ€§åŠ é€Ÿçš„æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ•ˆæœï¼Œèƒ½å¤Ÿå¢å¼ºè§£å‰–å’ŒåŠŸèƒ½æ€§æˆåƒçš„å¤–éƒ¨åˆ†å¸ƒæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SMSæˆåƒæ˜¯ä¸€ç§åŠ é€Ÿç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„æŠ€æœ¯ã€‚</li>
<li>ROGERæ˜¯ä¸€ç§åŸºäºæ·±åº¦ç”Ÿæˆå…ˆéªŒçš„ç¨³å¥çš„SMS MRIé‡å»ºæ–¹æ³•ã€‚</li>
<li>ROGERåˆ©ç”¨å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ä»é«˜æ–¯å™ªå£°å¼€å§‹é€æ­¥æ¢å¤åˆ‡ç‰‡ã€‚</li>
<li>ROGERé€šè¿‡åå‘æ‰©æ•£è¿­ä»£åœ¨è¯»å–æ‹¼æ¥æ¡†æ¶ä¸­å®æ–½æ•°æ®ä¸€è‡´æ€§ã€‚</li>
<li>ROGERèå…¥äº†ä½é¢‘å¢å¼ºæ¨¡å—ï¼Œè§£å†³äº†SMSåŠ é€Ÿæˆåƒä¸­çš„å®é™…é—®é¢˜ã€‚</li>
<li>ROGERåœ¨å›é¡¾æ€§å’Œå‰ç»æ€§åŠ é€Ÿçš„æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>ROGERå¢å¼ºäº†MRIçš„è§£å‰–å’ŒåŠŸèƒ½æ€§æˆåƒæ•ˆæœï¼Œå¹¶å…·æœ‰å¼ºå¤§çš„å¤–éƒ¨åˆ†å¸ƒæ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.21600">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0114b767b052f4316821fd86e8c39493.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dda360acc5e4809dbbd74fdd842906fe.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="How-to-Efficiently-Annotate-Images-for-Best-Performing-Deep-Learning-Based-Segmentation-Models-An-Empirical-Study-with-Weak-and-Noisy-Annotations-and-Segment-Anything-Model"><a href="#How-to-Efficiently-Annotate-Images-for-Best-Performing-Deep-Learning-Based-Segmentation-Models-An-Empirical-Study-with-Weak-and-Noisy-Annotations-and-Segment-Anything-Model" class="headerlink" title="How to Efficiently Annotate Images for Best-Performing Deep Learning   Based Segmentation Models: An Empirical Study with Weak and Noisy Annotations   and Segment Anything Model"></a>How to Efficiently Annotate Images for Best-Performing Deep Learning   Based Segmentation Models: An Empirical Study with Weak and Noisy Annotations   and Segment Anything Model</h2><p><strong>Authors:Yixin Zhang, Shen Zhao, Hanxue Gu, Maciej A. Mazurowski</strong></p>
<p>Deep neural networks (DNNs) have demonstrated exceptional performance across various image segmentation tasks. However, the process of preparing datasets for training segmentation DNNs is both labor-intensive and costly, as it typically requires pixel-level annotations for each object of interest. To mitigate this challenge, alternative approaches such as using weak labels (e.g., bounding boxes or scribbles) or less precise (noisy) annotations can be employed. Noisy and weak labels are significantly quicker to generate, allowing for more annotated images within the same time frame. However, the potential decrease in annotation quality may adversely impact the segmentation performance of the resulting model. In this study, we conducted a comprehensive cost-effectiveness evaluation on six variants of annotation strategies (9~10 sub-variants in total) across 4 datasets and conclude that the common practice of precisely outlining objects of interest is virtually never the optimal approach when annotation budget is limited. Both noisy and weak annotations showed usage cases that yield similar performance to the perfectly annotated counterpart, yet had significantly better cost-effectiveness. We hope our findings will help researchers be aware of the different available options and use their annotation budgets more efficiently, especially in cases where accurately acquiring labels for target objects is particularly costly. Our code will be made available on <a target="_blank" rel="noopener" href="https://github.com/yzluka/AnnotationEfficiency2D">https://github.com/yzluka/AnnotationEfficiency2D</a>. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨å„ç§å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¸ºè®­ç»ƒåˆ†å‰²DNNså‡†å¤‡æ•°æ®é›†çš„è¿‡ç¨‹æ—¢åŠ³åŠ¨å¯†é›†åˆæˆæœ¬é«˜æ˜‚ï¼Œå› ä¸ºå®ƒé€šå¸¸éœ€è¦å¯¹æ¯ä¸ªæ„Ÿå…´è¶£çš„å¯¹è±¡è¿›è¡Œåƒç´ çº§çš„æ³¨é‡Šã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€æŒ‘æˆ˜ï¼Œå¯ä»¥é‡‡ç”¨ä½¿ç”¨å¼±æ ‡ç­¾ï¼ˆå¦‚è¾¹ç•Œæ¡†æˆ–æ¶‚é¸¦ï¼‰æˆ–ä¸å¤ªç²¾ç¡®ï¼ˆå¸¦æœ‰å™ªå£°ï¼‰çš„æ³¨é‡Šç­‰æ›¿ä»£æ–¹æ³•ã€‚å¸¦å™ªå£°å’Œå¼±æ ‡ç­¾çš„ç”Ÿæˆé€Ÿåº¦è¦å¿«å¾—å¤šï¼Œå¯ä»¥åœ¨åŒä¸€æ—¶é—´æ¡†æ¶å†…ç”Ÿæˆæ›´å¤šæ³¨é‡Šå›¾åƒã€‚ç„¶è€Œï¼Œæ³¨é‡Šè´¨é‡å¯èƒ½çš„ä¸‹é™å¯èƒ½ä¼šç»™æ‰€å¾—æ¨¡å‹çš„åˆ†å‰²æ€§èƒ½å¸¦æ¥ä¸åˆ©å½±å“ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¯¹4ä¸ªæ•°æ®é›†çš„6ç§æ³¨é‡Šç­–ç•¥å˜ä½“ï¼ˆæ€»è®¡9~10ä¸ªå­å˜ä½“ï¼‰è¿›è¡Œäº†å…¨é¢çš„æˆæœ¬æ•ˆç›Šè¯„ä¼°ï¼Œå¹¶å¾—å‡ºç»“è®ºï¼šå½“æ³¨é‡Šé¢„ç®—æœ‰é™æ—¶ï¼Œç²¾ç¡®æç»˜æ„Ÿå…´è¶£å¯¹è±¡çš„ä¸€èˆ¬åšæ³•å‡ ä¹ä»æœªæ˜¯æœ€ä½³æ–¹æ³•ã€‚å¸¦å™ªå£°å’Œå¼±æ ‡ç­¾çš„ç”¨ä¾‹äº§ç”Ÿçš„æ€§èƒ½ä¸å®Œç¾æ³¨é‡Šçš„å¯¹åº”ç‰©ç›¸ä¼¼ï¼Œä½†æˆæœ¬æ•ˆç›Šå´æ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶èƒ½å¸®åŠ©ç ”ç©¶äººå‘˜äº†è§£ä¸åŒçš„å¯ç”¨é€‰é¡¹ï¼Œå¹¶æ›´æœ‰æ•ˆåœ°åˆ©ç”¨ä»–ä»¬çš„æ³¨é‡Šé¢„ç®—ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸ºç›®æ ‡å¯¹è±¡å‡†ç¡®è·å–æ ‡ç­¾ç‰¹åˆ«æ˜‚è´µçš„æƒ…å†µä¸‹ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨ <a target="_blank" rel="noopener" href="https://github.com/yzluka/AnnotationEfficiency2D">https://github.com/yzluka/AnnotationEfficiency2D</a> ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.10600v3">PDF</a> Supplemental information is in appendix</p>
<p><strong>Summary</strong><br>     æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†è®­ç»ƒåˆ†å‰²æ·±åº¦ç¥ç»ç½‘ç»œçš„æ•°æ®é›†åˆ¶å¤‡æ—¢åŠ³åŠ›å¯†é›†åˆæˆæœ¬é«˜æ˜‚ï¼Œé€šå¸¸éœ€è¦ä¸ºæ¯ä¸ªç›®æ ‡å¯¹è±¡è¿›è¡Œåƒç´ çº§æ³¨é‡Šã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œå¯é‡‡ç”¨å¼±æ ‡ç­¾ï¼ˆå¦‚è¾¹ç•Œæ¡†æˆ–æ¶‚é¸¦ï¼‰æˆ–ä¸ç²¾ç¡®çš„ï¼ˆå™ªå£°ï¼‰æ³¨é‡Šç­‰æ›¿ä»£æ–¹æ³•ã€‚å™ªå£°å’Œå¼±æ ‡ç­¾ç”Ÿæˆæ›´å¿«ï¼Œå¯åœ¨ç›¸åŒæ—¶é—´å†…ç”Ÿæˆæ›´å¤šæ³¨é‡Šå›¾åƒã€‚ç„¶è€Œï¼Œæ³¨é‡Šè´¨é‡çš„æ½œåœ¨ä¸‹é™å¯èƒ½ä¼šå¯¹æ‰€å¾—æ¨¡å‹çš„åˆ†å‰²æ€§èƒ½äº§ç”Ÿä¸åˆ©å½±å“ã€‚æœ¬ç ”ç©¶å¯¹å…­ç§æ³¨é‡Šç­–ç•¥ï¼ˆå…±9è‡³10ç§å­ç­–ç•¥ï¼‰è¿›è¡Œäº†å…¨é¢çš„æˆæœ¬æ•ˆç›Šè¯„ä¼°ï¼Œæ¶‰åŠå››ä¸ªæ•°æ®é›†ï¼Œå¾—å‡ºç»“è®ºï¼šå½“æ³¨é‡Šé¢„ç®—æœ‰é™æ—¶ï¼Œç²¾ç¡®æç»˜ç›®æ ‡å¯¹è±¡çš„å¸¸è§„åšæ³•å‡ ä¹ä»æœªæ˜¯æœ€ä¼˜é€‰æ‹©ã€‚å™ªå£°å’Œå¼±æ³¨é‡Šçš„ä½¿ç”¨æ¡ˆä¾‹äº§ç”Ÿäº†ä¸å®Œç¾æ³¨é‡Šç›¸å½“çš„æ€§èƒ½ï¼Œä½†æˆæœ¬æ•ˆç›Šæ˜¾è‘—æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>æ•°æ®é›†åˆ¶å¤‡éœ€è¦åƒç´ çº§æ³¨é‡Šï¼Œè¿‡ç¨‹æ—¢åŠ³åŠ›å¯†é›†åˆæˆæœ¬é«˜æ˜‚ã€‚</li>
<li>ä¸ºç¼“è§£é«˜æˆæœ¬é—®é¢˜ï¼Œå¯é‡‡ç”¨å¼±æ ‡ç­¾æˆ–ä¸ç²¾ç¡®çš„æ³¨é‡Šç­‰æ›¿ä»£æ–¹æ³•ã€‚</li>
<li>å™ªå£°å’Œå¼±æ ‡ç­¾ç”Ÿæˆæ›´å¿«ï¼Œèƒ½åœ¨æœ‰é™æ—¶é—´å†…ç”Ÿæˆæ›´å¤šæ³¨é‡Šå›¾åƒã€‚</li>
<li>æ³¨é‡Šè´¨é‡çš„æ½œåœ¨ä¸‹é™å¯èƒ½å½±å“æ¨¡å‹çš„åˆ†å‰²æ€§èƒ½ã€‚</li>
<li>ç ”ç©¶è¡¨æ˜ï¼Œåœ¨æ³¨é‡Šé¢„ç®—æœ‰é™æ—¶ï¼Œä¸å¿…ç²¾ç¡®æç»˜ç›®æ ‡å¯¹è±¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.10600">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b1a06ab293ea93c15f70729ce1084640.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4248f4ff1fe1c0e00ebfcfed8552763.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89284c288c9cf5bc425f70e7ea93fd75.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Guided-Reconstruction-with-Conditioned-Diffusion-Models-for-Unsupervised-Anomaly-Detection-in-Brain-MRIs"><a href="#Guided-Reconstruction-with-Conditioned-Diffusion-Models-for-Unsupervised-Anomaly-Detection-in-Brain-MRIs" class="headerlink" title="Guided Reconstruction with Conditioned Diffusion Models for Unsupervised   Anomaly Detection in Brain MRIs"></a>Guided Reconstruction with Conditioned Diffusion Models for Unsupervised   Anomaly Detection in Brain MRIs</h2><p><strong>Authors:Finn Behrendt, Debayan Bhattacharya, Robin Mieling, Lennart Maack, Julia KrÃ¼ger, Roland Opfer, Alexander Schlaefer</strong></p>
<p>The application of supervised models to clinical screening tasks is challenging due to the need for annotated data for each considered pathology. Unsupervised Anomaly Detection (UAD) is an alternative approach that aims to identify any anomaly as an outlier from a healthy training distribution. A prevalent strategy for UAD in brain MRI involves using generative models to learn the reconstruction of healthy brain anatomy for a given input image. As these models should fail to reconstruct unhealthy structures, the reconstruction errors indicate anomalies. However, a significant challenge is to balance the accurate reconstruction of healthy anatomy and the undesired replication of abnormal structures. While diffusion models have shown promising results with detailed and accurate reconstructions, they face challenges in preserving intensity characteristics, resulting in false positives. We propose conditioning the denoising process of diffusion models with additional information derived from a latent representation of the input image. We demonstrate that this conditioning allows for accurate and local adaptation to the general input intensity distribution while avoiding the replication of unhealthy structures. We compare the novel approach to different state-of-the-art methods and for different data sets. Our results show substantial improvements in the segmentation performance, with the Dice score improved by 11.9%, 20.0%, and 44.6%, for the BraTS, ATLAS and MSLUB data sets, respectively, while maintaining competitive performance on the WMH data set. Furthermore, our results indicate effective domain adaptation across different MRI acquisitions and simulated contrasts, an important attribute for general anomaly detection methods. The code for our work is available at <a target="_blank" rel="noopener" href="https://github.com/FinnBehrendt/Conditioned-Diffusion-Models-UAD">https://github.com/FinnBehrendt/Conditioned-Diffusion-Models-UAD</a> </p>
<blockquote>
<p>å°†ç›‘ç£æ¨¡å‹åº”ç”¨äºä¸´åºŠç­›æŸ¥ä»»åŠ¡æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºéœ€è¦è€ƒè™‘çš„æ¯ç§ç—…ç†å­¦éƒ½éœ€è¦æ ‡æ³¨æ•°æ®ã€‚æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆUADï¼‰æ˜¯ä¸€ç§æ—¨åœ¨ä»å¥åº·çš„è®­ç»ƒåˆ†å¸ƒä¸­è¯†åˆ«ä»»ä½•å¼‚å¸¸å€¼çš„æ›¿ä»£æ–¹æ³•ã€‚åœ¨è„‘éƒ¨MRIçš„UADä¸­ï¼Œä¸€ç§å¸¸è§çš„ç­–ç•¥æ˜¯ä½¿ç”¨ç”Ÿæˆæ¨¡å‹æ¥å­¦ä¹ ç»™å®šè¾“å…¥å›¾åƒçš„è„‘éƒ¨ç»“æ„çš„é‡å»ºã€‚ç”±äºè¿™äº›æ¨¡å‹æ— æ³•é‡å»ºä¸å¥åº·ç»“æ„ï¼Œå› æ­¤é‡å»ºè¯¯å·®ä¼šæŒ‡ç¤ºå¼‚å¸¸ã€‚ç„¶è€Œï¼Œä¸€ä¸ªé‡å¤§æŒ‘æˆ˜æ˜¯å¦‚ä½•å¹³è¡¡å¥åº·è§£å‰–ç»“æ„çš„å‡†ç¡®é‡å»ºå’Œå¼‚å¸¸ç»“æ„çš„éæœŸæœ›å¤åˆ¶ã€‚è™½ç„¶æ‰©æ•£æ¨¡å‹åœ¨è¯¦ç»†å’Œå‡†ç¡®çš„é‡å»ºæ–¹é¢æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœï¼Œä½†å®ƒä»¬é¢ä¸´ç€ä¿æŒå¼ºåº¦ç‰¹å¾çš„æŒ‘æˆ˜ï¼Œä»è€Œå¯¼è‡´è¯¯æŠ¥ã€‚æˆ‘ä»¬æå‡ºé€šè¿‡è¾“å…¥å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºçš„æ´¾ç”Ÿä¿¡æ¯å¯¹æ‰©æ•£æ¨¡å‹çš„å»å™ªè¿‡ç¨‹è¿›è¡Œæ¡ä»¶å¤„ç†ã€‚æˆ‘ä»¬è¯æ˜è¿™ç§æ¡ä»¶å¤„ç†å…è®¸å¯¹ä¸€èˆ¬è¾“å…¥å¼ºåº¦åˆ†å¸ƒè¿›è¡Œå‡†ç¡®å’Œå±€éƒ¨é€‚åº”ï¼ŒåŒæ—¶é¿å…å¤åˆ¶ä¸å¥åº·ç»“æ„ã€‚æˆ‘ä»¬å°†æ–°æ–¹æ³•ä¸ä¸åŒçš„æœ€æ–°æŠ€æœ¯å’Œæ•°æ®é›†è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨åˆ†å‰²æ€§èƒ½æ–¹é¢å–å¾—äº†é‡å¤§æ”¹è¿›ï¼Œå¯¹äºBraTSã€ATLASå’ŒMSLUBæ•°æ®é›†ï¼ŒDiceå¾—åˆ†åˆ†åˆ«æé«˜äº†11.9%ã€20.0%å’Œ44.6%ï¼ŒåŒæ—¶åœ¨WMHæ•°æ®é›†ä¸Šä¿æŒäº†ç«äº‰æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœè¿˜è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨MRIé‡‡é›†å’Œä¸åŒæ¨¡æ‹Ÿå¯¹æ¯”åº¦ä¹‹é—´å®ç°äº†æœ‰æ•ˆçš„åŸŸé€‚åº”ï¼Œè¿™å¯¹äºä¸€èˆ¬çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•æ˜¯ä¸€ä¸ªé‡è¦çš„å±æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/FinnBehrendt/Conditioned-Diffusion-Models-UAD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/FinnBehrendt/Conditioned-Diffusion-Models-UADæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.04215v2">PDF</a> Preprint: Accepted paper at Combuters in Biology and medicine</p>
<p><strong>Summary</strong><br>     ä½¿ç”¨æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆUADï¼‰æ–¹æ³•ï¼Œé€šè¿‡ç”Ÿæˆæ¨¡å‹å­¦ä¹ å¥åº·è„‘ç»“æ„çš„é‡å»ºä»¥å‘ç°å¼‚å¸¸ã€‚æ‰©æ•£æ¨¡å‹åœ¨é‡å»ºå¥åº·ç»“æ„æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½æ€§èƒ½ï¼Œä½†åœ¨ä¿æŒå¼ºåº¦ç‰¹å¾æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºå°†è¾“å…¥å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºä¿¡æ¯çº³å…¥æ‰©æ•£æ¨¡å‹çš„å»å™ªè¿‡ç¨‹ï¼Œä»¥æé«˜å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§å¹¶é¿å…å¤åˆ¶ä¸å¥åº·ç»“æ„ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„åˆ†å‰²æ€§èƒ½æ˜¾è‘—æé«˜ï¼ŒåŒæ—¶å…·æœ‰è‰¯å¥½çš„è·¨ä¸åŒMRIé‡‡é›†å’Œæ¨¡æ‹Ÿå¯¹æ¯”çš„åŸŸé€‚åº”èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç›‘ç£æ¨¡å‹åº”ç”¨äºä¸´åºŠç­›æŸ¥ä»»åŠ¡æ—¶é¢ä¸´æ ‡æ³¨æ•°æ®éœ€æ±‚æŒ‘æˆ˜ã€‚</li>
<li>æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆUADï¼‰æ—¨åœ¨ä»å¥åº·è®­ç»ƒåˆ†å¸ƒä¸­è¯†åˆ«å¼‚å¸¸å€¼ã€‚</li>
<li>åœ¨è„‘MRIçš„UADä¸­ï¼Œç”Ÿæˆæ¨¡å‹ç”¨äºå­¦ä¹ å¥åº·è„‘ç»“æ„çš„é‡å»ºã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨é‡å»ºå¥åº·ç»“æ„æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†ä¿æŒå¼ºåº¦ç‰¹å¾æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>å°†è¾“å…¥å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºä¿¡æ¯çº³å…¥æ‰©æ•£æ¨¡å‹çš„å»å™ªè¿‡ç¨‹ï¼Œä»¥æé«˜å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„åˆ†å‰²æ€§èƒ½æ˜¾è‘—æé«˜ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„åŸŸé€‚åº”èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.04215">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a58d16688320eeed9231164c23823e34.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-26f89ee26535db9b5dc129d187e6f2d1.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-25/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-25/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-25/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-79e8bb4beeaec3d3d9a0443d9a33ef64.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-25  Generative Data Augmentation Challenge Zero-Shot Speech Synthesis for   Personalized Speech Enhancement
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-25/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6c777205d41ebaddd1102cdfd7df7209.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-25  IMAGINE-E Image Generation Intelligence Evaluation of State-of-the-art   Text-to-Image Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">12603.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
