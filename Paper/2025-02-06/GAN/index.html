<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GAN">
    <meta name="description" content="GAN 方向最新论文已更新，请持续关注 Update in 2025-02-06  AAD-DCE An Aggregated Multimodal Attention Mechanism for Early and Late   Dynamic Contrast Enhanced Prostate MRI Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GAN | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-757122fdac7bc16360dce1eb159cfbf7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/GAN/">
                                <span class="chip bg-color">GAN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                GAN
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    20 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-06-更新"><a href="#2025-02-06-更新" class="headerlink" title="2025-02-06 更新"></a>2025-02-06 更新</h1><h2 id="AAD-DCE-An-Aggregated-Multimodal-Attention-Mechanism-for-Early-and-Late-Dynamic-Contrast-Enhanced-Prostate-MRI-Synthesis"><a href="#AAD-DCE-An-Aggregated-Multimodal-Attention-Mechanism-for-Early-and-Late-Dynamic-Contrast-Enhanced-Prostate-MRI-Synthesis" class="headerlink" title="AAD-DCE: An Aggregated Multimodal Attention Mechanism for Early and Late   Dynamic Contrast Enhanced Prostate MRI Synthesis"></a>AAD-DCE: An Aggregated Multimodal Attention Mechanism for Early and Late   Dynamic Contrast Enhanced Prostate MRI Synthesis</h2><p><strong>Authors:Divya Bharti, Sriprabha Ramanarayanan, Sadhana S, Kishore Kumar M, Keerthi Ram, Harsh Agarwal, Ramesh Venkatesan, Mohanasankar Sivaprakasam</strong></p>
<p>Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) is a medical imaging technique that plays a crucial role in the detailed visualization and identification of tissue perfusion in abnormal lesions and radiological suggestions for biopsy. However, DCE-MRI involves the administration of a Gadolinium based (Gad) contrast agent, which is associated with a risk of toxicity in the body. Previous deep learning approaches that synthesize DCE-MR images employ unimodal non-contrast or low-dose contrast MRI images lacking focus on the local perfusion information within the anatomy of interest. We propose AAD-DCE, a generative adversarial network (GAN) with an aggregated attention discriminator module consisting of global and local discriminators. The discriminators provide a spatial embedded attention map to drive the generator to synthesize early and late response DCE-MRI images. Our method employs multimodal inputs - T2 weighted (T2W), Apparent Diffusion Coefficient (ADC), and T1 pre-contrast for image synthesis. Extensive comparative and ablation studies on the ProstateX dataset show that our model (i) is agnostic to various generator benchmarks and (ii) outperforms other DCE-MRI synthesis approaches with improvement margins of +0.64 dB PSNR, +0.0518 SSIM, -0.015 MAE for early response and +0.1 dB PSNR, +0.0424 SSIM, -0.021 MAE for late response, and (ii) emphasize the importance of attention ensembling. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/bhartidivya/AAD-DCE">https://github.com/bhartidivya/AAD-DCE</a>. </p>
<blockquote>
<p>动态对比增强磁共振成像（DCE-MRI）是一种医学成像技术，在异常病变组织灌注的详细可视化和识别中起着至关重要的作用，并为活检提供放射学建议。然而，DCE-MRI需要使用基于钆（Gad）的造影剂，这带来了体内毒性的风险。之前合成DCE-MR图像的深度学习方法主要使用非对比或低剂量对比MRI图像，缺乏对焦于感兴趣部位的局部灌注信息。我们提出了AAD-DCE，这是一个生成对抗网络（GAN），其中包含一个聚合注意力判别器模块，该模块由全局和局部判别器组成。判别器提供空间嵌入注意力图，以驱动生成器合成早期和晚期响应DCE-MRI图像。我们的方法采用多模态输入，包括T2加权（T2W）、表观扩散系数（ADC）和T1预对比图像进行图像合成。在ProstateX数据集上的广泛比较和消融研究表明，我们的模型（i）不受各种生成器基准测试的影响；（ii）在早反应和晚反应方面，与其他DCE-MRI合成方法相比，我们的模型分别提高了+0.64 dB的峰值信噪比（PSNR）、+0.0518的结构相似性度量（SSIM）和-0.015的平均绝对误差（MAE），以及+0.1 dB的PSNR、+0.0424的SSIM和-0.021的MAE，并强调了注意力集成的重要性。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/bhartidivya/AAD-DCE%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/bhartidivya/AAD-DCE上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.02555v1">PDF</a> </p>
<p><strong>Summary</strong>：基于生成对抗网络（GAN）的AAD-DCE模型，利用多模态输入信息合成DCE-MRI图像。该模型采用全局和局部鉴别器组成的聚合注意力鉴别器模块，提供空间嵌入注意力图以指导生成器合成早期和晚期响应的DCE-MRI图像。在ProstateX数据集上的广泛对比和消融研究表明，该模型在性能上优于其他DCE-MRI合成方法。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>AAD-DCE模型利用生成对抗网络（GAN）技术，旨在合成动态对比增强磁共振成像（DCE-MRI）图像。</li>
<li>该模型通过采用聚合注意力鉴别器模块，包含全局和局部鉴别器，以提高图像合成的质量。</li>
<li>AAD-DCE模型采用多模态输入，包括T2加权（T2W）、表观扩散系数（ADC）和T1预对比图像。</li>
<li>在ProstateX数据集上的研究结果显示，AAD-DCE模型在性能上优于其他DCE-MRI图像合成方法。</li>
<li>该模型的性能改进体现在早期和晚期响应的PSNR、SSIM和MAE等指标上。</li>
<li>AAD-DCE模型的代码已公开可用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.02555">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-cf0995ebd82f85ee7edfb015bc4baa16.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-10923e0595e1d3960897a4f7d6c07a84.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c8f697724877fc4e629c9434f5612c2c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b0dc7540a7dcd2bb35fa94a97dc61e18.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3bb2725ff790ad8b53b472e16b72185b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-450b6799898d335223e789206f61cc60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01b678f867eb0bdcc0aa62ec3ed15a84.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="BC-GAN-A-Generative-Adversarial-Network-for-Synthesizing-a-Batch-of-Collocated-Clothing"><a href="#BC-GAN-A-Generative-Adversarial-Network-for-Synthesizing-a-Batch-of-Collocated-Clothing" class="headerlink" title="BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of   Collocated Clothing"></a>BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of   Collocated Clothing</h2><p><strong>Authors:Dongliang Zhou, Haijun Zhang, Jianghong Ma, Jianyang Shi</strong></p>
<p>Collocated clothing synthesis using generative networks has become an emerging topic in the field of fashion intelligence, as it has significant potential economic value to increase revenue in the fashion industry. In previous studies, several works have attempted to synthesize visually-collocated clothing based on a given clothing item using generative adversarial networks (GANs) with promising results. These works, however, can only accomplish the synthesis of one collocated clothing item each time. Nevertheless, users may require different clothing items to meet their multiple choices due to their personal tastes and different dressing scenarios. To address this limitation, we introduce a novel batch clothing generation framework, named BC-GAN, which is able to synthesize multiple visually-collocated clothing images simultaneously. In particular, to further improve the fashion compatibility of synthetic results, BC-GAN proposes a new fashion compatibility discriminator in a contrastive learning perspective by fully exploiting the collocation relationship among all clothing items. Our model was examined in a large-scale dataset with compatible outfits constructed by ourselves. Extensive experiment results confirmed the effectiveness of our proposed BC-GAN in comparison to state-of-the-art methods in terms of diversity, visual authenticity, and fashion compatibility. </p>
<blockquote>
<p>利用生成网络进行搭配服装合成已成为时尚智能领域的一个新兴话题，因为它为时尚产业带来了巨大的经济增值潜力。在先前的研究中，一些作品已经尝试使用生成对抗网络（GANs）基于给定的服装项目进行视觉搭配服装的合成，并取得了令人鼓舞的结果。然而，这些工作每次都只能完成一件搭配服装的合成。然而，由于个人口味和不同的穿衣场景，用户可能需要不同的服装项目来满足他们的多种选择。为了解决这一限制，我们引入了一个新颖的批量服装生成框架，名为BC-GAN，它能够同时合成多个视觉搭配服装图像。特别是，为了进一步提高合成结果的时尚兼容性，BC-GAN从对比学习的角度提出了一个新的时尚兼容性鉴别器，充分利用了所有服装项目之间的搭配关系。我们的模型是在我们自己构建的大规模兼容服装数据集上进行测试的。大量的实验结果证实，与最新方法相比，我们所提出的BC-GAN在多样性、视觉真实性和时尚兼容性方面都非常有效。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.01080v1">PDF</a> This paper was accepted by IEEE TCSVT</p>
<p><strong>Summary</strong></p>
<p>基于生成对抗网络（GANs）的联合服装合成已成为时尚智能领域的一个新兴话题，具有巨大的经济价值。尽管之前的研究已经尝试使用GANs对给定的服装项目进行视觉上联合的服装合成，并取得了一些成果，但它们每次只能合成一件联合服装。针对用户因个人喜好和不同穿衣场景需要多种服装选择的需求，我们提出了一种新型的批量服装生成框架BC-GAN，能够同时合成多种视觉上联合的服装图像。特别是，为了进一步提高合成结果的时尚兼容性，BC-GAN从对比学习的角度提出了一个新的时尚兼容性鉴别器，充分利用所有服装项目之间的搭配关系。在由我们自己构建的大规模兼容服装数据集上进行的实验证实，与最先进的方法相比，BC-GAN在多样性、视觉真实性和时尚兼容性方面更加有效。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>生成对抗网络（GANs）在时尚智能领域的联合服装合成成为新兴话题，具有巨大的经济价值。</li>
<li>现有研究只能单次合成一种联合服装，无法满足用户多样化的需求。</li>
<li>提出了一种新型的批量服装生成框架BC-GAN，能够同时合成多种视觉上联合的服装图像。</li>
<li>BC-GAN通过引入时尚兼容性鉴别器，提高了合成结果的时尚兼容性。</li>
<li>该鉴别器从对比学习的角度出发，充分利用服装项目之间的搭配关系。</li>
<li>BC-GAN在多样性、视觉真实性和时尚兼容性方面表现出优异的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.01080">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-bfefc343bc81223e2b88de9a5475d52d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b4a323261fb918b4392907d49acfa85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4abb3f18c9dfcec4a29accd3d226e18e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e6b4a762da5863c611ab637bc18eb80.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Weak-Supervision-Dynamic-KL-Weighted-Diffusion-Models-Guided-by-Large-Language-Models"><a href="#Weak-Supervision-Dynamic-KL-Weighted-Diffusion-Models-Guided-by-Large-Language-Models" class="headerlink" title="Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large   Language Models"></a>Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large   Language Models</h2><p><strong>Authors:Julian Perry, Frank Sanders, Carter Scott</strong></p>
<p>In this paper, we presents a novel method for improving text-to-image generation by combining Large Language Models (LLMs) with diffusion models, a hybrid approach aimed at achieving both higher quality and efficiency in image synthesis from text descriptions. Our approach introduces a new dynamic KL-weighting strategy to optimize the diffusion process, along with incorporating semantic understanding from pre-trained LLMs to guide the generation process. The proposed method significantly improves both the visual quality and alignment of generated images with text descriptions, addressing challenges such as computational inefficiency, instability in training, and robustness to textual variability. We evaluate our method on the COCO dataset and demonstrate its superior performance over traditional GAN-based models, both quantitatively and qualitatively. Extensive experiments, including ablation studies and human evaluations, confirm that our method outperforms existing approaches in terms of image realism, relevance to the input text, and overall aesthetic quality. Our approach also shows promise in scalability to other multimodal tasks, making it a versatile solution for a wide range of generative applications. </p>
<blockquote>
<p>本文提出了一种结合大型语言模型（LLMs）与扩散模型改进文本到图像生成的新方法。这是一种混合方法，旨在实现文本描述生成图像的高质量和高效率。我们的方法引入了一种新的动态KL加权策略来优化扩散过程，同时结合预训练LLMs的语义理解来指导生成过程。所提出的方法显著提高了生成图像与文本描述之间的视觉质量和对齐程度，解决了计算效率低下、训练不稳定以及对文本变化的不鲁棒等挑战。我们在COCO数据集上评估了我们的方法，与传统基于GAN的模型相比，从定量和定性两个方面都证明了其优越性。大量实验，包括消融研究和人类评估，证实我们的方法在图像真实性、与输入文本的关联性和整体美学质量方面优于现有方法。我们的方法在其他多模式任务中的可扩展性也显示出前景，使其成为广泛生成应用的通用解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.00826v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种将大型语言模型（LLMs）与扩散模型相结合的新方法，旨在提高文本到图像的生成质量及效率。该方法引入了一种新的动态KL权重策略来优化扩散过程，并结合预训练LLMs的语义理解来引导生成过程。该方法显著提高了生成图像与文本描述之间的视觉质量和一致性，解决了计算效率低下、训练不稳定和对文本变化的不稳健等挑战。在COCO数据集上的评估表明，与传统基于GAN的模型相比，该方法在图像逼真度、与输入文本的关联性和整体美学质量方面表现出卓越性能。此外，该方法在其他多模式任务中显示出可扩展性，成为广泛生成应用的通用解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了结合大型语言模型（LLMs）和扩散模型的新方法，用于改进文本到图像的生成。</li>
<li>引入动态KL权重策略优化扩散过程。</li>
<li>通过预训练LLMs的语义理解引导生成过程。</li>
<li>在COCO数据集上表现出卓越性能，提高了图像与文本描述之间的视觉质量和一致性。</li>
<li>解决了计算效率低下、训练不稳定和对文本变化的不稳健等挑战。</li>
<li>方法在其他多模式任务中显示出可扩展性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.00826">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-60fd9441710ef453fbbda0f5d0fa51fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3df3c5f2be83141802872790d44debe7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69cec03fe5dbd7e0d9dea8a5005748d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f9e248a6a581c735321729a4113be134.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45373f4aa27ecbaadba5f5ffdbcb1db9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GAN-Based-Architecture-for-Low-dose-Computed-Tomography-Imaging-Denoising"><a href="#GAN-Based-Architecture-for-Low-dose-Computed-Tomography-Imaging-Denoising" class="headerlink" title="GAN-Based Architecture for Low-dose Computed Tomography Imaging   Denoising"></a>GAN-Based Architecture for Low-dose Computed Tomography Imaging   Denoising</h2><p><strong>Authors:Yunuo Wang, Ningning Yang, Jialin Li</strong></p>
<p>Generative Adversarial Networks (GANs) have surfaced as a revolutionary element within the domain of low-dose computed tomography (LDCT) imaging, providing an advanced resolution to the enduring issue of reconciling radiation exposure with image quality. This comprehensive review synthesizes the rapid advancements in GAN-based LDCT denoising techniques, examining the evolution from foundational architectures to state-of-the-art models incorporating advanced features such as anatomical priors, perceptual loss functions, and innovative regularization strategies. We critically analyze various GAN architectures, including conditional GANs (cGANs), CycleGANs, and Super-Resolution GANs (SRGANs), elucidating their unique strengths and limitations in the context of LDCT denoising. The evaluation provides both qualitative and quantitative results related to the improvements in performance in benchmark and clinical datasets with metrics such as PSNR, SSIM, and LPIPS. After highlighting the positive results, we discuss some of the challenges preventing a wider clinical use, including the interpretability of the images generated by GANs, synthetic artifacts, and the need for clinically relevant metrics. The review concludes by highlighting the essential significance of GAN-based methodologies in the progression of precision medicine via tailored LDCT denoising models, underlining the transformative possibilities presented by artificial intelligence within contemporary radiological practice. </p>
<blockquote>
<p>生成对抗网络（GANs）在低剂量计算机断层扫描（LDCT）成像领域掀起了一场革命，为解决辐射暴露与图像质量之间的持久问题提供了高级解决方案。这篇综述综合了基于GAN的LDCT去噪技术的快速发展，从基础架构的演变到结合先进特性的最新模型，例如解剖学先验、感知损失函数和创新正则化策略。我们深入分析了各种GAN架构，包括条件GAN（cGANs）、CycleGANs和超分辨率GAN（SRGANs），阐明了它们在LDCT去噪背景下的独特优势和局限性。评估结果提供与基准测试和临床数据集性能提升相关的定性和定量结果，包括峰值信噪比、结构相似性度量指标和LPIPS等。在突出积极结果之后，我们讨论了一些阻碍更广泛临床应用的挑战，包括GAN生成图像的解读性、合成伪影以及需要临床相关指标等。最后，通过强调基于GAN的方法在通过定制LDCT去噪模型推动精准医学发展中的关键作用，本文总结了人工智能在当代放射实践中的变革性潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.09512v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>GAN在网络领域掀起革命性变革，特别是在低剂量计算机断层扫描（LDCT）成像方面，为解决辐射暴露与图像质量之间的平衡问题提供了先进解决方案。本文综述了基于GAN的LDCT去噪技术的快速发展，从基础架构到融合先进特性的最新模型，如解剖先验、感知损失函数和创新正则化策略等。本文详细分析了各种GAN架构，包括条件GAN（cGAN）、CycleGAN和超分辨率GAN（SRGAN），阐述了它们在LDCT去噪方面的独特优势和局限性。在评估和对比中，提供了与基准测试数据集和临床数据集相关的性能改进定量和定性结果。本文强调了一些挑战，包括GAN生成的图像的可解释性、合成伪影以及需要临床相关指标等，阻碍了其更广泛的临床应用。最后，本文强调了基于GAN的方法在精准医学发展中的重要作用，特别是在定制LDCT去噪模型方面，突显人工智能在当代放射实践中的变革性潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GANs在低剂量计算机断层扫描（LDCT）成像领域具有革命性作用，解决了辐射暴露与图像质量之间的平衡问题。</li>
<li>基于GAN的LDCT去噪技术发展迅速，涵盖从基础架构到融合先进特性的最新模型。</li>
<li>条件GAN（cGAN）、CycleGAN和超分辨率GAN（SRGAN）等架构在LDCT去噪方面各有优势和局限性。</li>
<li>GAN生成的图像存在可解释性、合成伪影等挑战，需要临床相关指标进行评估。</li>
<li>基于GAN的方法在精准医学发展中具有重要作用，特别是在定制LDCT去噪模型方面。</li>
<li>GANs的应用展现了人工智能在当代放射实践中的变革性潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.09512">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-757122fdac7bc16360dce1eb159cfbf7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b5eafe930aca9ec7791270cf1ed31f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f84a9f309c412f58748740aa4a804980.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Posterior-Mean-Rectified-Flow-Towards-Minimum-MSE-Photo-Realistic-Image-Restoration"><a href="#Posterior-Mean-Rectified-Flow-Towards-Minimum-MSE-Photo-Realistic-Image-Restoration" class="headerlink" title="Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image   Restoration"></a>Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image   Restoration</h2><p><strong>Authors:Guy Ohayon, Tomer Michaeli, Michael Elad</strong></p>
<p>Photo-realistic image restoration algorithms are typically evaluated by distortion measures (e.g., PSNR, SSIM) and by perceptual quality measures (e.g., FID, NIQE), where the desire is to attain the lowest possible distortion without compromising on perceptual quality. To achieve this goal, current methods commonly attempt to sample from the posterior distribution, or to optimize a weighted sum of a distortion loss (e.g., MSE) and a perceptual quality loss (e.g., GAN). Unlike previous works, this paper is concerned specifically with the optimal estimator that minimizes the MSE under a constraint of perfect perceptual index, namely where the distribution of the reconstructed images is equal to that of the ground-truth ones. A recent theoretical result shows that such an estimator can be constructed by optimally transporting the posterior mean prediction (MMSE estimate) to the distribution of the ground-truth images. Inspired by this result, we introduce Posterior-Mean Rectified Flow (PMRF), a simple yet highly effective algorithm that approximates this optimal estimator. In particular, PMRF first predicts the posterior mean, and then transports the result to a high-quality image using a rectified flow model that approximates the desired optimal transport map. We investigate the theoretical utility of PMRF and demonstrate that it consistently outperforms previous methods on a variety of image restoration tasks. </p>
<blockquote>
<p>光栅图像恢复算法通常通过失真度量（例如PSNR、SSIM）和感知质量度量（例如FID、NIQE）进行评估。目标是尽可能达到最低的失真，同时不妥协感知质量。为了达到这个目标，当前的方法通常尝试从后验分布中进行采样，或优化失真损失（例如MSE）和感知质量损失的加权和（例如GAN）。不同于以前的工作，本文专注于在完美感知指数约束下最小化MSE的最优估计器，即在重建图像的分布与真实图像的分布相等的情况下。最近的理论结果表明，可以通过最优传输后验均值预测（MMSE估计）到真实图像的分布来构建这样的估计器。受此结果的启发，我们引入了后均值校正流（PMRF），这是一种简单而高效算法，可以近似这种最优估计器。特别是，PMRF首先预测后验均值，然后使用校正流模型将结果传输到高质量图像，该模型近似于所需的最佳传输映射。我们研究了PMRF的理论效用，并证明它在各种图像恢复任务上始终优于以前的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00418v3">PDF</a> Accepted to ICLR 2025. Code and demo are available at   <a target="_blank" rel="noopener" href="https://pmrf-ml.github.io/">https://pmrf-ml.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>本文关注于在完美感知指数约束下最小化均方误差的最优估计器。在保持感知质量的同时实现最低的失真一直是图像修复算法的关键目标。为达到此目标，本文通过理论结果证明存在一个最优传输器可以将后验均值预测（MMSE估计）传输到真实图像分布。受这一结果的启发，本文提出了一种简单有效的算法——后验均值校正流（PMRF）。该算法首先预测后验均值，然后通过近似理想传输图的校正流模型将结果传送到高质量图像。研究显示，该方法在各种图像修复任务上的性能优于先前的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>图像修复算法的评价通常基于失真和感知质量两个标准，旨在实现最低失真并保持感知质量。</li>
<li>现有方法尝试从后验分布采样或优化失真损失和感知质量损失的加权和。</li>
<li>本文专注于在完美感知指数约束下最小化均方误差的最优估计器。</li>
<li>一个理论结果显示，存在一种最优传输器能将后验均值预测传输到真实图像分布。</li>
<li>受此理论结果的启发，提出了后验均值校正流（PMRF）算法。</li>
<li>PMRF首先预测后验均值，然后通过校正流模型将结果优化为高质量图像。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00418">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7c9144dc698e30f25241ba24dccc2f72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5cce5e36f491fe1793883be28bf48dc.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-06/GAN/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-06/GAN/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/GAN/">
                                    <span class="chip bg-color">GAN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-06/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-9fb18f8f7fe2be3055ce6b48b5b6b62d.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-02-06  MaintaAvatar A Maintainable Avatar Based on Neural Radiance Fields by   Continual Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-06/Speech/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-23dc622292d3dd146517fa200f623d53.jpg" class="responsive-img" alt="Speech">
                        
                        <span class="card-title">Speech</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Speech 方向最新论文已更新，请持续关注 Update in 2025-02-06  CTC-DRO Robust Optimization for Reducing Language Disparities in Speech   Recognition
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                    Speech
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Speech/">
                        <span class="chip bg-color">Speech</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">11004.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
