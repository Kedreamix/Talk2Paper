<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-03-21  SWEET-RL Training Multi-Turn LLM Agents on Collaborative Reasoning   Tasks">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-e6116c0b8dbcca8d73715e625323a88b.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    36 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-21-更新"><a href="#2025-03-21-更新" class="headerlink" title="2025-03-21 更新"></a>2025-03-21 更新</h1><h2 id="SWEET-RL-Training-Multi-Turn-LLM-Agents-on-Collaborative-Reasoning-Tasks"><a href="#SWEET-RL-Training-Multi-Turn-LLM-Agents-on-Collaborative-Reasoning-Tasks" class="headerlink" title="SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning   Tasks"></a>SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning   Tasks</h2><p><strong>Authors:Yifei Zhou, Song Jiang, Yuandong Tian, Jason Weston, Sergey Levine, Sainbayar Sukhbaatar, Xian Li</strong></p>
<p>Large language model (LLM) agents need to perform multi-turn interactions in real-world tasks. However, existing multi-turn RL algorithms for optimizing LLM agents fail to perform effective credit assignment over multiple turns while leveraging the generalization capabilities of LLMs and it remains unclear how to develop such algorithms. To study this, we first introduce a new benchmark, ColBench, where an LLM agent interacts with a human collaborator over multiple turns to solve realistic tasks in backend programming and frontend design. Building on this benchmark, we propose a novel RL algorithm, SWEET-RL (RL with Step-WisE Evaluation from Training-time information), that uses a carefully designed optimization objective to train a critic model with access to additional training-time information. The critic provides step-level rewards for improving the policy model. Our experiments demonstrate that SWEET-RL achieves a 6% absolute improvement in success and win rates on ColBench compared to other state-of-the-art multi-turn RL algorithms, enabling Llama-3.1-8B to match or exceed the performance of GPT4-o in realistic collaborative content creation. </p>
<blockquote>
<p>大型语言模型（LLM）代理需要在现实世界的任务中进行多轮交互。然而，现有的针对LLM代理优化的多轮强化学习算法未能有效地在多轮中分配信用，同时利用LLM的泛化能力，并且尚不清楚如何开发此类算法。为了研究这个问题，我们首先引入了一个新的基准测试ColBench，在这里，LLM代理与人类的合作者进行多轮交互，以解决后端编程和前端设计中的现实任务。基于这个基准测试，我们提出了一种新的强化学习算法SWEET-RL（带有训练时信息的一步明智评价强化学习），它使用一个精心设计的优化目标来训练一个批评模型，该模型可以访问额外的训练时信息。批评者提供步骤级的奖励，以改善策略模型。我们的实验表明，与其他最先进的多轮强化学习算法相比，SWEET-RL在ColBench上的成功率和胜率提高了6%的绝对值，使Llama-3.1-8B在真实协作内容创建方面的性能与GPT4-o相匹配或超过它。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15478v1">PDF</a> 29 pages, 16 figures</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理在真实世界任务中需要进行多轮交互。然而，现有的多轮强化学习（RL）算法在优化LLM代理时，未能有效地进行多轮信用分配并同时利用LLM的泛化能力，尚不清楚如何开发此类算法。为对此进行研究，我们首先推出了ColBench基准测试平台，LLM代理在此平台上可与人类合作者进行多轮交互以解决后端编程和前端设计等实际任务。基于这一基准测试平台，我们提出了一种新型RL算法——SWEET-RL（带有训练时信息评估的逐步强化学习），其使用精心设计优化目标训练了一个批评模型以获取额外的训练时信息。批评模型提供了用于改善策略模型的步骤级别奖励。实验表明，相较于其他顶尖的多轮RL算法，SWEET-RL在ColBench上的成功率与胜率提高了6%，使得Llama-3.1-8B在真实协作内容创建方面的性能与GPT4相当或更好。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）代理在多轮交互任务中面临挑战，需要更有效的算法来进行性能优化。</li>
<li>提出了一种名为ColBench的新型基准测试平台，用于模拟真实环境中的多轮交互任务。</li>
<li>引入了一种新型强化学习算法——SWEET-RL，该算法利用训练时信息来改善策略模型的性能。</li>
<li>SWEET-RL通过训练一个批评模型来提供步骤级别的奖励，从而更有效地进行信用分配。</li>
<li>实验结果显示，SWEET-RL在ColBench基准测试平台上的表现优于其他多轮RL算法。</li>
<li>通过使用SWEET-RL算法，Llama-3.1-8B模型在真实协作内容创建任务中的性能得到了显著提升。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15478">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-103b1a90029ee8e84117c61fbdc67652.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e6116c0b8dbcca8d73715e625323a88b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af458b77ecb3fb3477fb230aba167a6d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Actor-Critic-with-Harmonic-Annealing-Pruning-for-Dynamic-Spectrum-Access-Systems"><a href="#Multi-Agent-Actor-Critic-with-Harmonic-Annealing-Pruning-for-Dynamic-Spectrum-Access-Systems" class="headerlink" title="Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic   Spectrum Access Systems"></a>Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic   Spectrum Access Systems</h2><p><strong>Authors:George Stamatelis, Angelos-Nikolaos Kanatas, George C. Alexandropoulos</strong></p>
<p>Multi-Agent Deep Reinforcement Learning (MADRL) has emerged as a powerful tool for optimizing decentralized decision-making systems in complex settings, such as Dynamic Spectrum Access (DSA). However, deploying deep learning models on resource-constrained edge devices remains challenging due to their high computational cost. To address this challenge, in this paper, we present a novel sparse recurrent MARL framework integrating gradual neural network pruning into the independent actor global critic paradigm. Additionally, we introduce a harmonic annealing sparsity scheduler, which achieves comparable, and in certain cases superior, performance to standard linear and polynomial pruning schedulers at large sparsities. Our experimental investigation demonstrates that the proposed DSA framework can discover superior policies, under diverse training conditions, outperforming conventional DSA, MADRL baselines, and state-of-the-art pruning techniques. </p>
<blockquote>
<p>多智能体深度强化学习（MADRL）已成为优化复杂环境中的分布式决策系统的强大工具，例如在动态频谱访问（DSA）中。然而，由于计算成本高昂，在资源受限的边缘设备上部署深度学习模型仍然是一个挑战。针对这一挑战，本文提出了一种新型的稀疏递归MARL框架，该框架将渐进神经网络剪枝集成到独立行动者全局评论家范式中。此外，我们还引入了和谐退火稀疏调度器，在较大的稀疏度下，其性能与标准的线性和多项式剪枝调度器相当，在某些情况下甚至更优。我们的实验研究表明，在多种训练条件下，所提出的DSA框架能够发现优越的策略，超越传统的DSA、MADRL基准线和最先进的剪枝技术。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15172v1">PDF</a> 5 pages, 3 figures, 1 table, submited to an IEEE conference</p>
<p><strong>Summary</strong><br>在复杂环境中，多智能体深度强化学习（MADRL）在优化分布式决策系统方面表现出强大的能力，如动态频谱访问（DSA）。然而，在资源受限的边缘设备上部署深度学习模型具有挑战性。针对此挑战，本文提出了一种新型稀疏递归MARL框架，将独立行动者全局评论家范式与逐步神经网络修剪相结合。此外，引入了和谐退火稀疏调度器，在某些情况下与标准线性和多项式修剪调度器的性能相当，甚至在大型稀疏性方面表现更优。实验证明，所提出的DSA框架能够在不同的训练条件下发现优越的策略，优于传统DSA、MADRL基准和最新的修剪技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多智能体深度强化学习（MADRL）在复杂环境下的分布式决策系统优化中表现出强大的能力。</li>
<li>在资源受限的边缘设备上部署深度学习模型具有挑战性。</li>
<li>提出了一种新型稀疏递归MARL框架，融合了逐步神经网络修剪和独立行动者全局评论家范式。</li>
<li>引入了和谐退火稀疏调度器，实现了与标准线性及多项式修剪调度器相当或更好的性能。</li>
<li>实验证明，该框架能够在不同训练条件下发现更优越的策略。</li>
<li>该框架在动态频谱访问（DSA）领域的应用表现优于传统DSA方法和MADRL基准。</li>
<li>该框架也超越了现有的最新修剪技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15172">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-453c111185577843a1d407af932df55b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2566f0493bcb590e53797aa80c5f2549.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad882b25ce7603954651940eb3619014.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="LogiAgent-Automated-Logical-Testing-for-REST-Systems-with-LLM-Based-Multi-Agents"><a href="#LogiAgent-Automated-Logical-Testing-for-REST-Systems-with-LLM-Based-Multi-Agents" class="headerlink" title="LogiAgent: Automated Logical Testing for REST Systems with LLM-Based   Multi-Agents"></a>LogiAgent: Automated Logical Testing for REST Systems with LLM-Based   Multi-Agents</h2><p><strong>Authors:Ke Zhang, Chenxi Zhang, Chong Wang, Chi Zhang, YaChen Wu, Zhenchang Xing, Yang Liu, Qingshan Li, Xin Peng</strong></p>
<p>Automated testing for REST APIs has become essential for ensuring the correctness and reliability of modern web services. While existing approaches primarily focus on detecting server crashes and error codes, they often overlook logical issues that arise due to evolving business logic and domain-specific requirements. To address this limitation, we propose LogiAgent, a novel approach for logical testing of REST systems. Built upon a large language model (LLM)-driven multi-agent framework, LogiAgent integrates a Test Scenario Generator, API Request Executor, and API Response Validator to collaboratively generate, execute, and validate API test scenarios. Unlike traditional testing methods that focus on status codes like 5xx, LogiAgent incorporates logical oracles that assess responses based on business logic, ensuring more comprehensive testing. The system is further enhanced by an Execution Memory component that stores historical API execution data for contextual consistency. We conduct extensive experiments across 12 real-world REST systems, demonstrating that LogiAgent effectively identifies 234 logical issues with an accuracy of 66.19%. Additionally, it basically excels in detecting server crashes and achieves superior test coverage compared to four state-of-the-art REST API testing tools. An ablation study confirms the significant contribution of LogiAgent’s memory components to improving test coverage. </p>
<blockquote>
<p>自动化测试对于确保现代Web服务的正确性和可靠性至关重要。现有的方法主要集中在检测服务器崩溃和错误代码上，但往往会忽略由于业务逻辑和特定领域需求的演变而产生的逻辑问题。为了解决这一局限性，我们提出了LogiAgent，这是一种用于REST系统逻辑测试的新方法。LogiAgent建立在基于大型语言模型（LLM）驱动的多代理框架上，集成了测试场景生成器、API请求执行器和API响应验证器，以协同生成、执行和验证API测试场景。与传统的测试方法不同，这些方法侧重于诸如5xx之类的状态码，LogiAgent结合了逻辑预言家，根据业务逻辑评估响应，确保更全面的测试。该系统通过执行内存组件进一步得到增强，该组件存储历史API执行数据以实现上下文一致性。我们在12个真实世界的REST系统上进行大规模实验，结果表明LogiAgent有效地识别了234个逻辑问题，准确率为66.19%。此外，它在检测服务器崩溃方面表现出色，与四种最先进的REST API测试工具相比，实现了更高的测试覆盖率。一项消融研究证实了LogiAgent的内存组件对提高测试覆盖率的重大贡献。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15079v1">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>随着现代Web服务的发展，REST API的自动化测试对于确保服务的正确性和可靠性至关重要。现有的测试方法主要关注服务器崩溃和错误代码的检测，但往往忽略了由于业务逻辑变化和特定领域需求而产生的逻辑问题。为此，我们提出了LogiAgent，这是一种用于REST系统逻辑测试的新方法。它基于大型语言模型驱动的多代理框架，集成了测试场景生成器、API请求执行器和API响应验证器，以协同生成、执行和验证API测试场景。与传统的关注状态码（如5xx）的测试方法不同，LogiAgent采用逻辑判定器评估响应是否符合业务逻辑，确保更全面的测试。系统还通过执行内存组件存储历史API执行数据，以实现上下文一致性。在12个真实世界的REST系统上进行的大规模实验表明，LogiAgent可以有效地识别出234个逻辑问题，准确率为66.19%。此外，它在检测服务器崩溃方面也表现出色，与四种最先进的REST API测试工具相比，测试覆盖率更高。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>REST API的自动化测试对于确保现代Web服务的正确性和可靠性至关重要。</li>
<li>现有测试方法主要关注服务器崩溃和错误代码，但忽略了逻辑问题。</li>
<li>LogiAgent是一种新的REST API逻辑测试方法，基于大型语言模型驱动的多代理框架。</li>
<li>LogiAgent集成了测试场景生成器、API请求执行器和API响应验证器。</li>
<li>LogiAgent采用逻辑判定器评估响应是否符合业务逻辑，确保更全面的测试。</li>
<li>LogiAgent在真实世界的REST系统实验中有效识别了逻辑问题，并具有较高的准确率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15079">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8147ba597a107bf6e56382c464adf8f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0e1228a7ef6adf0182738efc798cd8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75927abed7483fd1ed8a871d949c1c3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88e08e442ad539239c98c052158134c7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cfedefc905bd04ab61c43751a60e970f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b849443e890e61836242d5eaa629565.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DRoPE-Directional-Rotary-Position-Embedding-for-Efficient-Agent-Interaction-Modeling"><a href="#DRoPE-Directional-Rotary-Position-Embedding-for-Efficient-Agent-Interaction-Modeling" class="headerlink" title="DRoPE: Directional Rotary Position Embedding for Efficient Agent   Interaction Modeling"></a>DRoPE: Directional Rotary Position Embedding for Efficient Agent   Interaction Modeling</h2><p><strong>Authors:Jianbo Zhao, Taiyu Ban, Zhihao Liu, Hangning Zhou, Xiyang Wang, Qibin Zhou, Hailong Qin, Mu Yang, Lei Liu, Bin Li</strong></p>
<p>Accurate and efficient modeling of agent interactions is essential for trajectory generation, the core of autonomous driving systems. Existing methods, scene-centric, agent-centric, and query-centric frameworks, each present distinct advantages and drawbacks, creating an impossible triangle among accuracy, computational time, and memory efficiency. To break this limitation, we propose Directional Rotary Position Embedding (DRoPE), a novel adaptation of Rotary Position Embedding (RoPE), originally developed in natural language processing. Unlike traditional relative position embedding (RPE), which introduces significant space complexity, RoPE efficiently encodes relative positions without explicitly increasing complexity but faces inherent limitations in handling angular information due to periodicity. DRoPE overcomes this limitation by introducing a uniform identity scalar into RoPE’s 2D rotary transformation, aligning rotation angles with realistic agent headings to naturally encode relative angular information. We theoretically analyze DRoPE’s correctness and efficiency, demonstrating its capability to simultaneously optimize trajectory generation accuracy, time complexity, and space complexity. Empirical evaluations compared with various state-of-the-art trajectory generation models, confirm DRoPE’s good performance and significantly reduced space complexity, indicating both theoretical soundness and practical effectiveness. The video documentation is available at <a target="_blank" rel="noopener" href="https://drope-traj.github.io/">https://drope-traj.github.io/</a>. </p>
<blockquote>
<p>在自动驾驶系统的核心——轨迹生成中，对代理交互的精确和高效建模至关重要。现有的方法，包括以场景为中心、以代理为中心和以查询为中心的框架，各有其独特的优势和劣势，从而在准确性、计算时间和内存效率之间形成了一个不可能实现的三角形。为了突破这一局限，我们提出了方向旋转位置嵌入（DRoPE），这是旋转位置嵌入（RoPE）的一种新型适应方式，最初是在自然语言处理中开发的。与传统的相对位置嵌入（RPE）不同，RPE引入了大量的空间复杂性，而RoPE能够高效编码相对位置，而不会明确增加复杂性，但由于周期性，它在处理角度信息方面存在固有的局限性。DRoPE通过向RoPE的2D旋转转换中引入统一身份标量来克服这一局限性，将旋转角度与真实的代理方向对齐，以自然地编码相对角度信息。我们对DRoPE的正确性和效率进行了理论分析，证明其能够同时优化轨迹生成的准确性、时间复杂度和空间复杂度。与各种最先进的轨迹生成模型的实证评估比较，证实了DRoPE的良好性能和显著降低的空间复杂度，表明其既具有理论上的健全性，又在实践中具有有效性。视频文档可在<a target="_blank" rel="noopener" href="https://drope-traj.github.io/%E8%8E%B7%E5%8F%96%E3%80%82">https://drope-traj.github.io/获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15029v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种名为方向性旋转位置嵌入（DRoPE）的新方法，用于自主驾驶系统中的轨迹生成。该方法基于自然语言处理中的旋转位置嵌入（RoPE）技术，通过引入统一身份标量解决了传统相对位置嵌入（RPE）在处理角度信息方面的局限性，在优化轨迹生成准确性、时间复杂度和空间复杂度方面表现出卓越的能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>自主驾驶系统的核心在于轨迹生成，准确高效的代理交互建模至关重要。</li>
<li>现有方法（场景中心、代理中心、查询中心框架）在准确性、计算时间和内存效率方面存在不可能三角。</li>
<li>DRoPE方法基于RoPE技术，适应于自主驾驶系统的轨迹生成。</li>
<li>传统RPE方法在处理角度信息时存在局限性，DRoPE通过引入统一身份标量解决了这一问题。</li>
<li>DRoPE能同时优化轨迹生成的准确性、时间复杂度和空间复杂度。</li>
<li>与各种最先进的轨迹生成模型相比，DRoPE在实证评估中表现出良好的性能和显著降低的空间复杂度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15029">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-317419ab9e9df9cc14e625457c266361.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c8d93951869b7958decec4b2f8bd873.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-44749acd72407307a2506e1d046d8a1f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ChatStitch-Visualizing-Through-Structures-via-Surround-View-Unsupervised-Deep-Image-Stitching-with-Collaborative-LLM-Agents"><a href="#ChatStitch-Visualizing-Through-Structures-via-Surround-View-Unsupervised-Deep-Image-Stitching-with-Collaborative-LLM-Agents" class="headerlink" title="ChatStitch: Visualizing Through Structures via Surround-View   Unsupervised Deep Image Stitching with Collaborative LLM-Agents"></a>ChatStitch: Visualizing Through Structures via Surround-View   Unsupervised Deep Image Stitching with Collaborative LLM-Agents</h2><p><strong>Authors:Hao Liang, Zhipeng Dong, Yi Yang, Mengyin Fu</strong></p>
<p>Collaborative perception has garnered significant attention for its ability to enhance the perception capabilities of individual vehicles through the exchange of information with surrounding vehicle-agents. However, existing collaborative perception systems are limited by inefficiencies in user interaction and the challenge of multi-camera photorealistic visualization. To address these challenges, this paper introduces ChatStitch, the first collaborative perception system capable of unveiling obscured blind spot information through natural language commands integrated with external digital assets. To adeptly handle complex or abstract commands, ChatStitch employs a multi-agent collaborative framework based on Large Language Models. For achieving the most intuitive perception for humans, ChatStitch proposes SV-UDIS, the first surround-view unsupervised deep image stitching method under the non-global-overlapping condition. We conducted extensive experiments on the UDIS-D, MCOV-SLAM open datasets, and our real-world dataset. Specifically, our SV-UDIS method achieves state-of-the-art performance on the UDIS-D dataset for 3, 4, and 5 image stitching tasks, with PSNR improvements of 9%, 17%, and 21%, and SSIM improvements of 8%, 18%, and 26%, respectively. </p>
<blockquote>
<p>协作感知通过周围车辆之间的信息交流增强了单个车辆的感知能力，从而引起了广泛关注。然而，现有的协作感知系统受到用户交互效率低下和多摄像头真实可视化挑战的制约。为了应对这些挑战，本文引入了ChatStitch，这是第一个能够通过自然语言命令与外部数字资产相结合揭示隐藏盲区信息的协作感知系统。为了妥善处理复杂或抽象命令，ChatStitch采用基于大型语言模型的多智能体协作框架。为了实现最直观的人类感知，ChatStitch提出了SV-UDIS，这是一种在非全局重叠条件下用于周围视图的无监督深度图像拼接方法的首次尝试。我们在UDIS-D、MCOVSLAM公开数据集以及我们自己的真实世界数据集上进行了大量实验。具体来说，我们的SV-UDIS方法在UDIS-D数据集上的3、4和5图像拼接任务上实现了最先进的性能，PSNR分别提高了9%、17%和21%，SSIM分别提高了8%、18%和26%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14948v1">PDF</a> </p>
<p><strong>Summary</strong><br>车辆协作感知可通过交换信息增强车辆个体感知能力。当前协作感知系统存在交互效率不足和多摄像头逼真可视化挑战。本文提出ChatStitch系统，通过自然语言命令与外部数字资产结合揭示隐藏盲点信息。采用基于大型语言模型的多智能体协作框架处理复杂或抽象命令。提出SV-UDIS方法，实现人类最直观感知，在非全局重叠条件下实现周围视图无监督深度图像拼接。实验结果表明，SV-UDIS在UDIS-D数据集上实现行业领先性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>协作感知通过信息交换增强车辆感知能力。</li>
<li>当前协作感知系统面临交互效率和多摄像头可视化挑战。</li>
<li>ChatStitch系统通过自然语言命令与外部数字资产结合揭示隐藏信息。</li>
<li>采用多智能体协作框架处理复杂命令。</li>
<li>SV-UDIS方法实现周围视图无监督深度图像拼接。</li>
<li>SV-UDIS在UDIS-D数据集上表现优异，PSNR和SSIM指标有显著提高。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14948">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-c06f734ff8210051fc7d6aa9fec547a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d82233ad11dc84c82e6a789c9bf230ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a94e2f0b6766bd38293fef73192aced.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5eea35bc336152cdcca1340064e5563.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e1b2e73fe51c41b6e46c1d6e7204a00c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TestForge-Feedback-Driven-Agentic-Test-Suite-Generation"><a href="#TestForge-Feedback-Driven-Agentic-Test-Suite-Generation" class="headerlink" title="TestForge: Feedback-Driven, Agentic Test Suite Generation"></a>TestForge: Feedback-Driven, Agentic Test Suite Generation</h2><p><strong>Authors:Kush Jain, Claire Le Goues</strong></p>
<p>Automated test generation holds great promise for alleviating the burdens of manual test creation. However, existing search-based techniques compromise on test readability, while LLM-based approaches are prohibitively expensive in practice. We present TestForge, an agentic unit testing framework designed to cost-effectively generate high-quality test suites for real-world code. Our key insight is to reframe LLM-based test generation as an iterative process. TestForge thus begins with tests generated via zero-shot prompting, and then continuously refines those tests based on feedback from test executions and coverage reports. We evaluate TestForge on TestGenEval, a real world unit test generation benchmark sourced from 11 large scale open source repositories; we show that TestForge achieves a pass@1 rate of 84.3%, 44.4% line coverage and 33.8% mutation score on average, outperforming prior classical approaches and a one-iteration LLM-based baseline. TestForge produces more natural and understandable tests compared to state-of-the-art search-based techniques, and offers substantial cost savings over LLM-based techniques (at $0.63 per file). Finally, we release a version of TestGenEval integrated with the OpenHands platform, a popular open-source framework featuring a diverse set of software engineering agents and agentic benchmarks, for future extension and development. </p>
<blockquote>
<p>自动化测试生成在缓解手动测试创建负担方面具有巨大潜力。然而，现有的基于搜索的技术牺牲了测试的可读性，而基于大型语言模型（LLM）的方法在实践中成本高昂。我们提出了TestForge，这是一个单元测试框架，旨在经济高效地生成针对现实世界代码的高质量测试套件。我们的关键见解是将基于LLM的测试生成重新构建为迭代过程。因此，TestForge首先通过零样本提示生成测试，然后根据测试执行和覆盖率报告的反馈持续改进这些测试。我们在TestGenEval上评估了TestForge，这是一个源自11个大型开源存储库的现实世界单元测试生成基准测试；我们展示TestForge在TestGenEval上的平均通过率为84.3%，平均覆盖率为44.4%，平均突变得分为33.8%，超越了先前的经典方法和基于一次迭代的LLM基线。与最先进的基于搜索的技术相比，TestForge生成的测试更加自然且易于理解，并且与基于LLM的技术相比可节省大量成本（每文件0.63美元）。最后，我们将TestGenEval的一个版本集成到OpenHands平台中，这是一个功能多样的软件工程代理和代理基准测试的流行开源框架，用于未来的扩展和开发。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14713v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>TestForge是一个经济高效的测试框架，旨在生成针对现实世界代码的高质量测试套件。它通过迭代过程将LLM（大型语言模型）应用于测试生成，开始时通过零样本提示生成测试，然后根据测试执行和覆盖率报告的反馈不断对其进行优化。在TestGenEval基准测试中，TestForge表现出色，平均通过率为84.3%，平均覆盖率达44.4%，平均突变分数为33.8%，优于传统方法和一次迭代的大型语言模型基线。此外，TestForge生成的测试比最先进的基于搜索的技术更自然、更易理解，并且在每个文件上的成本相较于大型语言模型技术有显著的节省（每个文件仅$0.63）。我们还公开发布了与OpenHands平台集成的TestGenEval版本，以供未来扩展和开发。该框架为软件工程提供了多元化的智能代理和代理基准测试集合。这是一项富有创新性的测试技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TestForge框架解决了手动创建测试的繁重负担，通过利用LLM（大型语言模型）进行经济高效的测试生成。</li>
<li>TestForge通过迭代过程生成测试，结合零样本提示和基于测试执行与覆盖率报告的反馈进行优化。</li>
<li>在TestGenEval基准测试中，TestForge显示出高通过率、覆盖率和突变分数，优于传统方法和基于大型语言模型的基线技术。</li>
<li>TestForge生成的测试更自然易懂，相较于基于搜索的技术具有显著优势。</li>
<li>TestForge在成本上具有显著优势，相较于LLM技术的单次迭代，其每个文件的成本仅$0.63。这一点使得其在实践应用中更为经济可行。</li>
<li>TestGenEval已与OpenHands平台集成，为未来的扩展和开发提供了便利。该平台提供了多元化的软件工程技术工具和基准测试集合。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14713">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-70e100f6f46d15cfd83c9ca9d7f95d29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22dba74e9fafc3bead64cf06824102cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b814ea55c2503ef55ee65128b0f69fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cdb2a88a6cbd384f646174eee88062a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd7456b61b6eb3901d8f4b1ae85b95da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-776dac1510df8205665d999ac5247f3b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SocialJax-An-Evaluation-Suite-for-Multi-agent-Reinforcement-Learning-in-Sequential-Social-Dilemmas"><a href="#SocialJax-An-Evaluation-Suite-for-Multi-agent-Reinforcement-Learning-in-Sequential-Social-Dilemmas" class="headerlink" title="SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in   Sequential Social Dilemmas"></a>SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in   Sequential Social Dilemmas</h2><p><strong>Authors:Zihao Guo, Richard Willis, Shuqing Shi, Tristan Tomilin, Joel Z. Leibo, Yali Du</strong></p>
<p>Social dilemmas pose a significant challenge in the field of multi-agent reinforcement learning (MARL). Melting Pot is an extensive framework designed to evaluate social dilemma environments, providing an evaluation protocol that measures generalization to new social partners across various test scenarios. However, running reinforcement learning algorithms in the official Melting Pot environments demands substantial computational resources. In this paper, we introduce SocialJax, a suite of sequential social dilemma environments implemented in JAX. JAX is a high-performance numerical computing library for Python that enables significant improvements in the operational efficiency of SocialJax on GPUs and TPUs. Our experiments demonstrate that the training pipeline of SocialJax achieves a 50\texttimes{} speedup in real-time performance compared to Melting Pot’s RLlib baselines. Additionally, we validate the effectiveness of baseline algorithms within the SocialJax environments. Finally, we use Schelling diagrams to verify the social dilemma properties of these environments, ensuring they accurately capture the dynamics of social dilemmas. </p>
<blockquote>
<p>多智能体强化学习（MARL）领域中的社会困境构成了一个巨大的挑战。Melting Pot是一个广泛的框架，旨在评估社会困境环境，提供了一个评估协议，该协议可以衡量在各种测试场景中推广到新的社会伙伴的泛化能力。然而，在官方的Melting Pot环境中运行强化学习算法需要巨大的计算资源。在本文中，我们介绍了SocialJax，这是一套在JAX中实现的有序社会困境环境。JAX是一个为Python提供高性能数值计算的库，能够在GPU和TPU上显著提高SocialJax的操作效率。我们的实验表明，与Melting Pot的RLlib基准测试相比，SocialJax的训练管道在实时性能方面实现了50倍的速度提升。此外，我们在SocialJax环境中验证了基线算法的有效性。最后，我们使用谢林图验证这些环境的社会困境属性，确保它们准确地捕捉了社会困境的动力学特征。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14576v1">PDF</a> 9 pages, 18 figures, 1 table</p>
<p><strong>Summary</strong></p>
<p>本文介绍了多智能体强化学习领域中的社会困境挑战。针对此挑战，提出了一种新的评估框架SocialJax，该框架在JAX库上实现了顺序社会困境环境。SocialJax使用高性能数值计算库JAX，在GPU和TPU上显著提高操作效率。实验表明，相比Melting Pot的RLlib基线，SocialJax的训练管道实现了50倍的性能提升。此外，还验证了基线算法在SocialJax环境中的有效性，并使用Schelling图验证这些环境的社会困境属性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Social dilemmas是多智能体强化学习领域的挑战。</li>
<li>Melting Pot是一个用于评估社会困境环境的框架，但运行其环境中的强化学习算法需要巨大的计算资源。</li>
<li>SocialJax是一个在JAX库上实现的社会困境环境套件，旨在提高操作效率。</li>
<li>SocialJax实现了显著的性能提升，相比Melting Pot的RLlib基线，训练管道性能提升了50倍。</li>
<li>在SocialJax环境中验证了基线算法的有效性。</li>
<li>SocialJax环境使用Schelling图来验证社会困境属性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14576">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4c8b66146a2fe3d45135760ad6c0cb46.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cfed352e7f5765e7bdbe22790e9a04d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53dcf993fc2513773aa17679580770eb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ff48b527159a0f3a17626db5af20ecde.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MARLadona-–-Towards-Cooperative-Team-Play-Using-Multi-Agent-Reinforcement-Learning"><a href="#MARLadona-–-Towards-Cooperative-Team-Play-Using-Multi-Agent-Reinforcement-Learning" class="headerlink" title="MARLadona – Towards Cooperative Team Play Using Multi-Agent   Reinforcement Learning"></a>MARLadona – Towards Cooperative Team Play Using Multi-Agent   Reinforcement Learning</h2><p><strong>Authors:Zichong Li, Filip Bjelonic, Victor Klemm, Marco Hutter</strong></p>
<p>Robot soccer, in its full complexity, poses an unsolved research challenge. Current solutions heavily rely on engineered heuristic strategies, which lack robustness and adaptability. Deep reinforcement learning has gained significant traction in various complex robotics tasks such as locomotion, manipulation, and competitive games (e.g., AlphaZero, OpenAI Five), making it a promising solution to the robot soccer problem. This paper introduces MARLadona. A decentralized multi-agent reinforcement learning (MARL) training pipeline capable of producing agents with sophisticated team play behavior, bridging the shortcomings of heuristic methods. Furthermore, we created an open-source multi-agent soccer environment. Utilizing our MARL framework and a modified global entity encoder (GEE) as our core architecture, our approach achieves a 66.8% win rate against HELIOS agent, which employs a state-of-the-art heuristic strategy. In addition, we provided an in-depth analysis of the policy behavior and interpreted the agent’s intention using the critic network. </p>
<blockquote>
<p>机器人足球在其完全复杂性方面构成了一个未解决的研究挑战。当前解决方案严重依赖于工程化的启发式策略，这些策略缺乏稳健性和适应性。深度强化学习已在各种复杂的机器人任务（如运动、操作和竞技游戏）中获得了显著的发展（例如AlphaZero、OpenAI Five），使其成为机器人足球问题的有前途的解决方案。本文介绍了MARLadona。这是一个去中心化的多智能体强化学习（MARL）训练管道，能够产生具有复杂团队行为智能体，弥补启发式方法的不足。此外，我们还创建了一个开源的多智能体足球环境。利用我们的MARL框架和修改后的全局实体编码器（GEE）作为我们的核心架构，我们的方法在对抗采用最新启发式策略的HELIOS智能体时达到了66.8%的胜率。此外，我们还对政策行为进行了深入分析，并利用评论家网络解释了智能体的意图。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.20326v3">PDF</a> Version presented at ICRA 2025</p>
<p><strong>Summary</strong></p>
<p>机器人足球领域的复杂性构成了未解决的研究挑战。当前解决方案主要依赖于工程化的启发式策略，缺乏稳健性和适应性。深度强化学习已在各种复杂机器人任务（如运动、操作和竞技游戏）中取得了显著进展，使其成为机器人足球问题的有前途的解决方案。本文介绍了MARLadona，这是一种分散式多智能体强化学习（MARL）训练管道，能够产生具有复杂团队行为智能体，弥补启发式方法的不足。此外，还开发了一个开源的多智能体足球环境。利用MARL框架和修改后的全局实体编码器（GEE）作为核心架构，我们的方法在对抗采用最新启发式策略的HELIOS代理时达到了66.8%的胜率。同时，对策略行为进行了深入分析，并利用评论家网络解释了代理的意图。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>机器人足球是一个具有挑战性的研究领域，当前解决方案依赖于启发式策略，缺乏稳健性和适应性。</li>
<li>深度强化学习在机器人领域具有广泛应用，包括运动、操作和竞技游戏。</li>
<li>MARLadona是一种基于多智能体强化学习（MARL）的训练管道，能生成具有复杂团队行为智能体，改进了启发式方法的不足。</li>
<li>开发了开源的多智能体足球环境，为研究和实验提供了平台。</li>
<li>利用MARL框架和修改后的全局实体编码器（GEE）作为核心架构，取得了对采用最新启发式策略的HELIOS代理的较高胜率。</li>
<li>对策略行为进行了详细分析，以了解智能体的决策过程。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.20326">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e6a3a7d802d365d853575d9be2ae6070.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b58410a248f5f7517980a223b248e8a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b234cd15c922d206abaed31526e53fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18807b82acf2023a686c90ad482197a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4060428dd7e1f908bd94a41ab92176ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ddb1267270db6fee5f5e23cd59dbcc10.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="A-Multi-Agent-Approach-to-Fault-Localization-via-Graph-Based-Retrieval-and-Reflexion"><a href="#A-Multi-Agent-Approach-to-Fault-Localization-via-Graph-Based-Retrieval-and-Reflexion" class="headerlink" title="A Multi-Agent Approach to Fault Localization via Graph-Based Retrieval   and Reflexion"></a>A Multi-Agent Approach to Fault Localization via Graph-Based Retrieval   and Reflexion</h2><p><strong>Authors:Md Nakhla Rafi, Dong Jae Kim, Tse-Hsun Chen, Shaowei Wang</strong></p>
<p>Identifying and resolving software faults remains a challenging and resource-intensive process. Traditional fault localization techniques, such as Spectrum-Based Fault Localization (SBFL), leverage statistical analysis of test coverage but often suffer from limited accuracy. While learning-based approaches improve fault localization, they demand extensive training datasets and high computational resources. Recent advances in Large Language Models (LLMs) offer new opportunities by enhancing code understanding and reasoning. However, existing LLM-based fault localization techniques face significant challenges, including token limitations, performance degradation with long inputs, and scalability issues in complex software systems. To overcome these obstacles, we propose LLM4FL, a multi-agent fault localization framework that utilizes three specialized LLM agents. First, the Context Extraction Agent applies an order-sensitive segmentation strategy to partition large coverage data within the LLM’s token limit, analyze failure context, and prioritize failure-related methods. The Debugger Agent then processes the extracted data, which employs graph-based retrieval-augmented code navigation to reason about failure causes and rank suspicious methods. Finally, the Reviewer Agent re-evaluates the identified faulty methods using verbal reinforcement learning, engaging in self-criticism and iterative refinement. Evaluated on the Defects4J (V2.0.0) benchmark, which includes 675 faults from 14 Java projects, LLM4FL achieves an 18.55% improvement in Top-1 accuracy over AutoFL and 4.82% over SoapFL. It outperforms supervised techniques such as DeepFL and Grace, all without requiring task-specific training. Furthermore, its coverage segmentation and prompt chaining strategies enhance performance, increasing Top-1 accuracy by up to 22%. </p>
<blockquote>
<p>识别和解决软件故障仍然是一个具有挑战性和资源密集型的过程。传统的故障定位技术，如基于频谱的故障定位（SBFL），利用测试覆盖的统计分析，但往往准确性有限。虽然基于学习的方法改进了故障定位，但它们需要大量的训练数据集和高计算资源。最近大型语言模型（LLM）的进步通过增强代码理解和推理提供了新的机会。然而，现有的基于LLM的故障定位技术面临重大挑战，包括符号限制、长输入性能下降以及在复杂软件系统中的可扩展性问题。为了克服这些障碍，我们提出了LLM4FL，这是一个多智能体故障定位框架，利用三个专业LLM智能体。首先，上下文提取智能体采用顺序敏感分割策略，在LLM的符号限制内划分大覆盖数据，分析失败上下文，并优先处理与失败相关的方法。然后调试器智能体处理提取的数据，采用基于图的检索增强代码导航来推断失败原因并排名可疑方法。最后，审查员智能体重新评估已识别的故障方法，使用口头强化学习进行自我评价和迭代改进。在Defects4J（V2.0.0）基准测试上进行评估，该测试包括来自14个Java项目的675个故障，LLM4FL在Top-1准确率上比AutoFL提高了18.55%，比SoapFL提高了4.82%。它超越了如DeepFL和Grace等监督技术，而且无需特定任务训练。此外，其覆盖分割和提示链接策略提高了性能，Top-1准确率最高可提高22%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.13642v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于多智能体的故障定位框架LLM4FL，针对软件故障定位的挑战，利用三种专业LLM智能体来解决传统故障定位技术的问题。该框架通过上下文提取智能体进行上下文分析，通过调试智能体进行故障原因分析并排名可疑方法，最后通过评审智能体对识别出的故障方法进行再评估。在Defects4J 2.0.0基准测试上，LLM4FL相比AutoFL提高了18.55%的Top-1准确率，优于SoapFL和其他监督技术如DeepFL和Grace，且无需特定任务训练。其覆盖分段和提示链策略可提高性能，最高可提高Top-1准确率达22%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM4FL是一个多智能体的故障定位框架，旨在解决软件故障定位的挑战。</li>
<li>LLM4FL利用三种专业LLM智能体：上下文提取智能体、调试智能体和评审智能体。</li>
<li>上下文提取智能体通过顺序敏感分段策略处理大规模覆盖数据。</li>
<li>调试智能体利用基于图的检索增强代码导航来推理故障原因并排名可疑方法。</li>
<li>评审智能体通过言语强化学习对识别出的故障方法进行再评估和自我批评。</li>
<li>在Defects4J基准测试中，LLM4FL相比其他技术显著提高Top-1准确率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.13642">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-f0d3d4968c5869f957825252f99982fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-894a3a253da8fd2f35dd096056d0bc39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d0249a9837e4d49740e2f4e298e257f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-16b065dc3a41a56c08a7c39d0c5b0a87.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-21/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-21/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-21/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ff3b2227764a96f8af1a4f8aac0fe6c0.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-03-21  TULIP Towards Unified Language-Image Pretraining
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-21/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bf70a7dfc1ecb33cb7416364e83d1f6c.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-03-21  SWEET-RL Training Multi-Turn LLM Agents on Collaborative Reasoning   Tasks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25370.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
