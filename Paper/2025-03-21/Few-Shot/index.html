<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-21  TULIP Towards Unified Language-Image Pretraining">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ff3b2227764a96f8af1a4f8aac0fe6c0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    27 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-21-æ›´æ–°"><a href="#2025-03-21-æ›´æ–°" class="headerlink" title="2025-03-21 æ›´æ–°"></a>2025-03-21 æ›´æ–°</h1><h2 id="TULIP-Towards-Unified-Language-Image-Pretraining"><a href="#TULIP-Towards-Unified-Language-Image-Pretraining" class="headerlink" title="TULIP: Towards Unified Language-Image Pretraining"></a>TULIP: Towards Unified Language-Image Pretraining</h2><p><strong>Authors:Zineng Tang, Long Lian, Seun Eisape, XuDong Wang, Roei Herzig, Adam Yala, Alane Suhr, Trevor Darrell, David M. Chan</strong></p>
<p>Despite the recent success of image-text contrastive models like CLIP and SigLIP, these models often struggle with vision-centric tasks that demand high-fidelity image understanding, such as counting, depth estimation, and fine-grained object recognition. These models, by performing language alignment, tend to prioritize high-level semantics over visual understanding, weakening their image understanding. On the other hand, vision-focused models are great at processing visual information but struggle to understand language, limiting their flexibility for language-driven tasks. In this work, we introduce TULIP, an open-source, drop-in replacement for existing CLIP-like models. Our method leverages generative data augmentation, enhanced image-image and text-text contrastive learning, and image&#x2F;text reconstruction regularization to learn fine-grained visual features while preserving global semantic alignment. Our approach, scaling to over 1B parameters, outperforms existing state-of-the-art (SOTA) models across multiple benchmarks, establishing a new SOTA zero-shot performance on ImageNet-1K, delivering up to a $2\times$ enhancement over SigLIP on RxRx1 in linear probing for few-shot classification, and improving vision-language models, achieving over $3\times$ higher scores than SigLIP on MMVP. Our code&#x2F;checkpoints are available at <a target="_blank" rel="noopener" href="https://tulip-berkeley.github.io/">https://tulip-berkeley.github.io</a> </p>
<blockquote>
<p>å°½ç®¡CLIPå’ŒSigLIPç­‰å›¾æ–‡å¯¹æ¯”æ¨¡å‹è¿‘æœŸå–å¾—äº†æˆåŠŸï¼Œä½†è¿™äº›æ¨¡å‹åœ¨è¿›è¡Œéœ€è¦é«˜ä¿çœŸå›¾åƒç†è§£çš„ä»»åŠ¡æ—¶ï¼Œå¦‚è®¡æ•°ã€æ·±åº¦ä¼°è®¡å’Œç²¾ç»†ç²’åº¦å¯¹è±¡è¯†åˆ«ç­‰è§†è§‰ä¸ºä¸­å¿ƒçš„ä»»åŠ¡ä¸Šç»å¸¸é‡åˆ°å›°éš¾ã€‚è¿™äº›æ¨¡å‹é€šè¿‡æ‰§è¡Œè¯­è¨€å¯¹é½ï¼Œå€¾å‘äºä¼˜å…ˆå¤„ç†é«˜çº§è¯­ä¹‰è€Œéè§†è§‰ç†è§£ï¼Œä»è€Œå‰Šå¼±äº†å®ƒä»¬çš„å›¾åƒç†è§£èƒ½åŠ›ã€‚å¦ä¸€æ–¹é¢ï¼Œä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„æ¨¡å‹åœ¨å¤„ç†è§†è§‰ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç†è§£è¯­è¨€æ–¹é¢å´é‡åˆ°å›°éš¾ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨è¯­è¨€é©±åŠ¨ä»»åŠ¡ä¸­çš„çµæ´»æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†TULIPï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„ã€å¯ä»¥æ›¿ä»£ç°æœ‰CLIPç­‰æ¨¡å‹çš„å·¥å…·ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨ç”Ÿæˆæ•°æ®å¢å¼ºã€å¢å¼ºçš„å›¾åƒä¸å›¾åƒä»¥åŠæ–‡æœ¬ä¸æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ä»¥åŠå›¾åƒ&#x2F;æ–‡æœ¬é‡å»ºæ­£åˆ™åŒ–ï¼Œä»¥å­¦ä¹ ç²¾ç»†çš„è§†å¬è§‰ç‰¹å¾åŒæ—¶ä¿ç•™å…¨å±€è¯­ä¹‰å¯¹é½ã€‚æˆ‘ä»¬çš„æ–¹æ³•è§„æ¨¡æ‰©å¤§åˆ°è¶…è¿‡1äº¿ä¸ªå‚æ•°ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰çš„å…ˆè¿›æŠ€æœ¯ï¼ˆSOTAï¼‰æ¨¡å‹ï¼Œåœ¨ImageNet-1Kä¸Šå»ºç«‹äº†æ–°çš„é›¶æ ·æœ¬æ€§èƒ½æ ‡å‡†ï¼Œåœ¨RxRx1çš„çº¿æ€§æ¢æµ‹ä¸­ç›¸å¯¹äºSigLIPæé«˜äº†é«˜è¾¾ä¸¤å€çš„æ€§èƒ½ç”¨äºå°æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œå¹¶åœ¨MMVPä¸Šå®ç°äº†è¶…è¿‡SigLIPä¸‰å€çš„é«˜åˆ†ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ£€æŸ¥ç‚¹å¯åœ¨<a target="_blank" rel="noopener" href="https://tulip-berkeley.github.ioæ‰¾åˆ°./">https://tulip-berkeley.github.ioæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15485v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†å°½ç®¡CLIPå’ŒSigLIPç­‰å›¾æ–‡å¯¹æ¯”æ¨¡å‹å–å¾—äº†æˆåŠŸï¼Œä½†åœ¨éœ€è¦é«˜ä¿çœŸå›¾åƒç†è§£çš„ä»»åŠ¡ä¸Šä»æœ‰ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†TULIPæ¨¡å‹ï¼Œé€šè¿‡ç”Ÿæˆæ•°æ®å¢å¼ºã€å›¾åƒå’Œæ–‡æœ¬å¯¹æ¯”å­¦ä¹ ä»¥åŠå›¾åƒ&#x2F;æ–‡æœ¬é‡å»ºæ­£åˆ™åŒ–æ–¹æ³•ï¼Œåœ¨ä¿ç•™å…¨å±€è¯­ä¹‰å¯¹é½çš„åŒæ—¶å­¦ä¹ ç²¾ç»†çš„è§†è§‰ç‰¹å¾ã€‚è¯¥æ–¹æ³•åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶åœ¨ImageNet-1Kä¸Šå®ç°äº†é›¶æ ·æœ¬æ€§èƒ½çš„æ–°çš„SOTAæ°´å¹³ã€‚æ­¤å¤–ï¼ŒTULIPåœ¨å°‘æ•°æ ·æœ¬åˆ†ç±»ä»»åŠ¡çš„çº¿æ€§æ¢æµ‹æ€§èƒ½æ¯”SigLIPæé«˜äº†ä¸¤å€ä»¥ä¸Šï¼Œå¹¶åœ¨MMVPä¸Šè·å¾—äº†è¶…è¿‡SigLIPä¸‰å€çš„é«˜å¾—åˆ†ã€‚æ¨¡å‹å’Œæ£€æŸ¥ç‚¹å·²ç»å¼€æºå¯ç”¨ã€‚è¯¥æ¨¡å‹çš„æ”¹è¿›ä¸ºå¤æ‚ä»»åŠ¡æä¾›äº†ä¸€ç§å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚åœ¨ä¿æŒå…¨å±€è¯­ä¹‰å¯¹é½çš„åŒæ—¶ï¼Œå¢å¼ºäº†å›¾åƒç†è§£çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹åœ¨è§£å†³è¯­è¨€é©±åŠ¨çš„ä»»åŠ¡æ—¶è¡¨ç°å‡ºçµæ´»æ€§ã€‚è¿™ä¸€æ¨¡å‹æ—¨åœ¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„ä¸è¶³ä¹‹å¤„ï¼Œæå‡æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚è¿™äº›ä¼˜ç‚¹ä½¿TULIPæ¨¡å‹åœ¨å›¾åƒåˆ†ç±»ç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„è¡¨ç°åŠ›ã€‚å®ƒçš„åº”ç”¨å‰æ™¯å¹¿é˜”ï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼å’Œå‘å±•æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯ä¸ƒä¸ªå…³é”®è§è§£ï¼š</p>
<ul>
<li>å½“å‰æµè¡Œçš„å›¾åƒæ–‡æœ¬å¯¹æ¯”æ¨¡å‹ï¼ˆå¦‚CLIPå’ŒSigLIPï¼‰åœ¨ç²¾ç»†è§†è§‰ä»»åŠ¡ä¸Šå­˜åœ¨ç¼ºé™·ï¼Œä½†å…·æœ‰é«˜å±‚æ¬¡çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚ä»–ä»¬é¢ä¸´ç€éœ€è¦æå‡é«˜ä¿çœŸå›¾åƒç†è§£çš„æŒ‘æˆ˜ã€‚è€ŒæŸäº›çº¯è§†è§‰æ¨¡å‹è™½ç„¶åœ¨å¤„ç†è§†è§‰ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è¯­è¨€ç†è§£æ–¹é¢å´æ˜¾å¾—æ‰è¥Ÿè§è‚˜ã€‚è¿™äº›æ¨¡å‹çš„ç¼ºé™·é™åˆ¶äº†å®ƒä»¬åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„çµæ´»æ€§ã€‚</li>
<li>TULIPä½œä¸ºä¸€ç§æ–°å‹çš„å¼€æºæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å®ƒé€šè¿‡ç»“åˆç”Ÿæˆæ•°æ®å¢å¼ºã€å›¾åƒå’Œæ–‡æœ¬å¯¹æ¯”å­¦ä¹ ä»¥åŠå›¾åƒ&#x2F;æ–‡æœ¬é‡å»ºæ­£åˆ™åŒ–æ–¹æ³•ç­‰æ‰‹æ®µæé«˜æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸ä»…èƒ½ä¿ç•™å…¨å±€è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œä¸”èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ç²¾ç»†çš„è§†è§‰ç‰¹å¾ã€‚è¿™æœ‰åŠ©äºå¢å¼ºæ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸Šçš„è¡¨ç°èƒ½åŠ›ã€‚åŒæ—¶æé«˜å›¾åƒç†è§£å’Œè¯­è¨€ç†è§£çš„å¹³è¡¡æ€§ã€‚</li>
<li>TULIPæ¨¡å‹çš„æ€§èƒ½è¡¨ç°è¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¦‚SigLIPç­‰æ¨¡å‹åœ¨æŸäº›ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°æœ‰äº†æ˜¾è‘—çš„æå‡ã€‚å®ƒåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨ImageNet-1Kä¸Šå®ç°äº†é›¶æ ·æœ¬æ€§èƒ½çš„æ–°çš„è®°å½•ï¼Œè¾¾åˆ°SOTAæ°´å¹³ï¼Œä¹Ÿæ˜¾è‘—æé«˜é›¶æ ·æœ¬èƒ½åŠ›ä»¥è§£å†³ä¸‹æ¸¸ä»»åŠ¡çš„é²æ£’æ€§å’Œé€‚åº”æ€§é—®é¢˜ã€‚ã€‚å…¶åœ¨å°‘é‡æ ·æœ¬ä¸‹çš„çº¿æ€§æ¢æµ‹æ€§èƒ½å’Œå…¨æ™¯èƒ½åŠ›å¾—åˆ°äº†æå‡ä¹Ÿæå¤§åœ°æ¨åŠ¨äº†è§†è§‰è¯­è¨€ä»»åŠ¡çš„æ”¹è¿›å‘å±•æ€åŠ¿é¡ºåˆ©ç¡®ç«‹æ­£ç¡®ï¼›ç›¸å¯¹äºsigLIPæ¨¡å‹å’Œæ„ŸçŸ¥æœºé¢„æµ‹ç­‰æ¨¡å‹åœ¨MMVPä¸Šçš„å¾—åˆ†æœ‰äº†æ˜¾è‘—çš„æå‡ã€‚ã€‚è¿™è¡¨æ˜TULIPåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶å…·æœ‰æ›´é«˜çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚ã€‚è¯¥æ¨¡å‹çš„å¼•å…¥æœ‰æœ›ä¸ºè®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå¸¦æ¥æ–°çš„çªç ´ã€‚ã€‚å› æ­¤å¯ä»¥é¢„æœŸåœ¨æœªæ¥ä¸­å°†ä¼šè·å¾—æ›´å¹¿æ³›çš„åº”ç”¨åœºæ™¯ã€‚ã€‚å› æ­¤å®ƒå¯¹äºè§£å†³å¤æ‚ä»»åŠ¡æä¾›äº†ä¸€ç§å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚ã€‚å…¶æ”¹è¿›äº†ç°æœ‰æ¨¡å‹çš„ä¸è¶³ä¹‹å¤„å¹¶æå‡äº†æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚ã€‚åŒæ—¶å…¶æ¨å¹¿å¯èƒ½ä¼šå¯å‘åç»­çš„åˆ›æ–°æ¢ç´¢ç®—æ³•è§£å†³ä»»åŠ¡å±‚é¢é€»è¾‘çš„ç»“æ„ç‰¹å¾åŒ–å¤„ç†ä¸åˆ›æ–°ç ”ç©¶å’ŒåŸºç¡€æ–¹æ¡ˆç»“åˆåˆ›æ–°æ€§å¼•ç”¨å®ç”¨æ€§ç¡®ä¿æœ‰åŠ©äºåœ¨è¯¥é¢†åŸŸåˆ›é€ å‡ºæ›´å…·åˆ›æ–°å’Œé€‚åº”æ€§çš„æ–°æŠ€æœ¯è¿›ä¸€æ­¥èµ‹èƒ½è‡ªç„¶è¯­è¨€ç†è§£å’Œè®¤çŸ¥å¤„ç†æ¨ç†æŠ€æœ¯çš„è¿›æ­¥çš„å‘å±•å‡ºæ–°çš„æŠ€æœ¯å‘å±•é©±åŠ¨åŠ›ç©ºé—´æ‰©å¤§äº†æˆ‘ä»¬å¯¹è‡ªç„¶ç•Œçš„è®¤è¯†è®©æˆ‘ä»¬è·å¾—äº†æ›´å¿«è§£å†³æ­¤ç±»éš¾é¢˜çš„æ–°é€”å¾„å¹¶å¸¦æ¥äº†å¹¿æ³›çš„å®é™…åº”ç”¨å‰æ™¯åŠå¸‚åœºæ½œåŠ›</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15485">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c2c979b1d4f62a1afd8e9f26b6760fc0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-37139187b967100da8d29ea01e0626a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d83684fd9be1c9949ddf15c214b946a3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90f0f71e7d247b0655a7e48243c9f8e3.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Conjuring-Positive-Pairs-for-Efficient-Unification-of-Representation-Learning-and-Image-Synthesis"><a href="#Conjuring-Positive-Pairs-for-Efficient-Unification-of-Representation-Learning-and-Image-Synthesis" class="headerlink" title="Conjuring Positive Pairs for Efficient Unification of Representation   Learning and Image Synthesis"></a>Conjuring Positive Pairs for Efficient Unification of Representation   Learning and Image Synthesis</h2><p><strong>Authors:Imanol G. Estepa, JesÃºs M. RodrÃ­guez-de-Vera, Ignacio SarasÃºa, Bhalaji Nagarajan, Petia Radeva</strong></p>
<p>While representation learning and generative modeling seek to understand visual data, unifying both domains remains unexplored. Recent Unified Self-Supervised Learning (SSL) methods have started to bridge the gap between both paradigms. However, they rely solely on semantic token reconstruction, which requires an external tokenizer during training â€“ introducing a significant overhead. In this work, we introduce Sorcen, a novel unified SSL framework, incorporating a synergic Contrastive-Reconstruction objective. Our Contrastive objective, â€œEcho Contrastâ€, leverages the generative capabilities of Sorcen, eliminating the need for additional image crops or augmentations during training. Sorcen â€œgeneratesâ€ an echo sample in the semantic token space, forming the contrastive positive pair. Sorcen operates exclusively on precomputed tokens, eliminating the need for an online token transformation during training, thereby significantly reducing computational overhead. Extensive experiments on ImageNet-1k demonstrate that Sorcen outperforms the previous Unified SSL SoTA by 0.4%, 1.48 FID, 1.76%, and 1.53% on linear probing, unconditional image generation, few-shot learning, and transfer learning, respectively, while being 60.8% more efficient. Additionally, Sorcen surpasses previous single-crop MIM SoTA in linear probing and achieves SoTA performance in unconditional image generation, highlighting significant improvements and breakthroughs in Unified SSL models. </p>
<blockquote>
<p>è¡¨ç¤ºå­¦ä¹ å’Œç”Ÿæˆå»ºæ¨¡éƒ½åœ¨åŠªåŠ›ç†è§£è§†è§‰æ•°æ®ï¼Œä½†èåˆè¿™ä¸¤ä¸ªé¢†åŸŸä»ç„¶æœªè¢«æ¢ç´¢ã€‚æœ€è¿‘çš„ç»Ÿä¸€è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ–¹æ³•å·²ç»å¼€å§‹å¼¥åˆä¸¤ç§èŒƒå¼ä¹‹é—´çš„é¸¿æ²Ÿã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»…ä¾èµ–äºè¯­ä¹‰ä»¤ç‰Œé‡å»ºï¼Œè¿™éœ€è¦è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤–éƒ¨ä»¤ç‰Œå™¨â€”â€”è¿™å¼•å…¥äº†ç›¸å½“å¤§çš„å¼€é”€ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Sorcenï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„ç»Ÿä¸€SSLæ¡†æ¶ï¼Œå®ƒç»“åˆäº†ååŒå¯¹æ¯”é‡å»ºç›®æ ‡ã€‚æˆ‘ä»¬çš„å¯¹æ¯”ç›®æ ‡â€œå›å£°å¯¹æ¯”â€åˆ©ç”¨Sorcençš„ç”Ÿæˆèƒ½åŠ›ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ— éœ€é¢å¤–çš„å›¾åƒè£å‰ªæˆ–å¢å¼ºã€‚Sorcenåœ¨è¯­ä¹‰ä»¤ç‰Œç©ºé—´ä¸­â€œç”Ÿæˆâ€ä¸€ä¸ªå›å£°æ ·æœ¬ï¼Œå½¢æˆå¯¹æ¯”æ­£å¯¹ã€‚Sorcenåªå¤„ç†é¢„å…ˆè®¡ç®—å¥½çš„ä»¤ç‰Œï¼Œæ— éœ€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œåœ¨çº¿ä»¤ç‰Œè½¬æ¢ï¼Œä»è€Œå¤§å¤§é™ä½äº†è®¡ç®—å¼€é”€ã€‚åœ¨ImageNet-1kä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨çº¿æ€§æ¢æµ‹ã€æ— æ¡ä»¶å›¾åƒç”Ÿæˆã€å°æ ·æœ¬å­¦ä¹ å’Œè¿ç§»å­¦ä¹ æ–¹é¢ï¼Œç´¢æ£®åˆ†åˆ«æ¯”ä¹‹å‰çš„ç»Ÿä¸€SSLç°çŠ¶é«˜å‡º0.4%ã€1.48 FIDã€1.76%å’Œ1.53%ï¼ŒåŒæ—¶æ•ˆç‡æé«˜60.8%ã€‚æ­¤å¤–ï¼Œç´¢æ£®è¿˜åœ¨çº¿æ€§æ¢æµ‹ä¸­è¶…è¶Šäº†ä¹‹å‰çš„å•è£å‰ªMIMç°çŠ¶ï¼Œå¹¶åœ¨æ— æ¡ä»¶å›¾åƒç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œè¿™çªæ˜¾äº†ç»Ÿä¸€SSLæ¨¡å‹çš„æ˜¾è‘—æ”¹è¿›å’Œçªç ´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15060v1">PDF</a> The source code is available in <a target="_blank" rel="noopener" href="https://github.com/ImaGonEs/Sorcen">https://github.com/ImaGonEs/Sorcen</a></p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„ç»Ÿä¸€è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ¡†æ¶Sorcenï¼Œå®ƒç»“åˆäº†å¯¹æ¯”å’Œé‡å»ºç›®æ ‡ï¼Œæ— éœ€é¢å¤–çš„å›¾åƒè£å‰ªæˆ–å¢å¼ºå³å¯è¿›è¡Œè®­ç»ƒã€‚Sorcenåœ¨é¢„è®¡ç®—ä»¤ç‰Œä¸Šè¿è¡Œï¼Œå‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œå¹¶åœ¨ImageNet-1kæ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Sorcenæ˜¯ä¸€ä¸ªæ–°å‹çš„ç»Ÿä¸€SSLæ¡†æ¶ï¼Œç»“åˆäº†å¯¹æ¯”å’Œé‡å»ºç›®æ ‡ã€‚</li>
<li>Sorcenå¼•å…¥äº†â€Echo Contrastâ€å¯¹æ¯”ç›®æ ‡ï¼Œåˆ©ç”¨ç”Ÿæˆèƒ½åŠ›ï¼Œæ— éœ€é¢å¤–çš„å›¾åƒè£å‰ªæˆ–å¢å¼ºå³å¯è¿›è¡Œè®­ç»ƒã€‚</li>
<li>Sorcenåœ¨é¢„è®¡ç®—ä»¤ç‰Œä¸Šè¿è¡Œï¼Œæ¶ˆé™¤äº†åœ¨çº¿ä»¤ç‰Œè½¬æ¢çš„éœ€è¦ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚</li>
<li>Sorcenåœ¨ImageNet-1kæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¶…è¶Šäº†ä¹‹å‰çš„ç»Ÿä¸€SSLæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨çº¿æ€§æ¢æµ‹ã€æ— æ¡ä»¶å›¾åƒç”Ÿæˆã€å°‘é•œå­¦ä¹ å’Œè¿ç§»å­¦ä¹ æ–¹é¢ã€‚</li>
<li>Sorcenåœ¨æ— æ¡ä»¶å›¾åƒç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>Sorcenæ¡†æ¶é€šè¿‡æ•´åˆå¯¹æ¯”å’Œé‡å»ºç›®æ ‡ï¼Œåœ¨è§†è§‰æ•°æ®ç†è§£æ–¹é¢å–å¾—äº†çªç ´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15060">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-21e1e3fc5d62f9c04d37ddca5fbea98f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5c0439c7a81af2941727063a1f161805.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7752ace7b23f3430fc3279a1c0e402f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a0eeba2eca04982030c2592cc91ec63.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c34fc7cdff00c2f9b0dedb17067c890f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Reducing-Annotation-Burden-Exploiting-Image-Knowledge-for-Few-Shot-Medical-Video-Object-Segmentation-via-Spatiotemporal-Consistency-Relearning"><a href="#Reducing-Annotation-Burden-Exploiting-Image-Knowledge-for-Few-Shot-Medical-Video-Object-Segmentation-via-Spatiotemporal-Consistency-Relearning" class="headerlink" title="Reducing Annotation Burden: Exploiting Image Knowledge for Few-Shot   Medical Video Object Segmentation via Spatiotemporal Consistency Relearning"></a>Reducing Annotation Burden: Exploiting Image Knowledge for Few-Shot   Medical Video Object Segmentation via Spatiotemporal Consistency Relearning</h2><p><strong>Authors:Zixuan Zheng, Yilei Shi, Chunlei Li, Jingliang Hu, Xiao Xiang Zhu, Lichao Mou</strong></p>
<p>Few-shot video object segmentation aims to reduce annotation costs; however, existing methods still require abundant dense frame annotations for training, which are scarce in the medical domain. We investigate an extremely low-data regime that utilizes annotations from only a few video frames and leverages existing labeled images to minimize costly video annotations. Specifically, we propose a two-phase framework. First, we learn a few-shot segmentation model using labeled images. Subsequently, to improve performance without full supervision, we introduce a spatiotemporal consistency relearning approach on medical videos that enforces consistency between consecutive frames. Constraints are also enforced between the image model and relearning model at both feature and prediction levels. Experiments demonstrate the superiority of our approach over state-of-the-art few-shot segmentation methods. Our model bridges the gap between abundant annotated medical images and scarce, sparsely labeled medical videos to achieve strong video segmentation performance in this low data regime. Code is available at <a target="_blank" rel="noopener" href="https://github.com/MedAITech/RAB">https://github.com/MedAITech/RAB</a>. </p>
<blockquote>
<p>å°‘æ ·æœ¬è§†é¢‘ç›®æ ‡åˆ†å‰²æ—¨åœ¨é™ä½æ ‡æ³¨æˆæœ¬ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä»ç„¶éœ€è¦å¤§é‡å¯†é›†å¸§æ ‡æ³¨è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨åŒ»å­¦é¢†åŸŸæ˜¯éå¸¸ç½•è§çš„ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä¸€ç§æå°‘é‡æ•°æ®çš„æ¨¡å¼ï¼Œè¯¥æ¨¡å¼ä»…åˆ©ç”¨æ¥è‡ªå°‘æ•°è§†é¢‘å¸§çš„æ ‡æ³¨ï¼Œå¹¶åˆ©ç”¨ç°æœ‰çš„æ ‡è®°å›¾åƒæ¥æœ€å¤§é™åº¦åœ°å‡å°‘æ˜‚è´µçš„è§†é¢‘æ ‡æ³¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨æ ‡è®°å›¾åƒå­¦ä¹ å°æ ·æœ¬åˆ†å‰²æ¨¡å‹ã€‚éšåï¼Œä¸ºäº†åœ¨æ— å®Œå…¨ç›‘ç£çš„æƒ…å†µä¸‹æé«˜æ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒ»å­¦è§†é¢‘ä¸Šçš„æ—¶ç©ºä¸€è‡´æ€§å†å­¦ä¹ çš„æ–¹æ³•ï¼Œå¼ºåˆ¶è¿ç»­å¸§ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åœ¨ç‰¹å¾å’Œé¢„æµ‹å±‚é¢ï¼Œå›¾åƒæ¨¡å‹å’Œå†å­¦ä¹ æ¨¡å‹ä¹‹é—´ä¹Ÿå¼ºåˆ¶å®æ–½çº¦æŸã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„å°‘æ ·æœ¬åˆ†å‰²æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ¨¡å‹ç¼©å°äº†å¤§é‡æ ‡æ³¨åŒ»å­¦å›¾åƒå’Œç¨€å°‘ã€ç¨€ç–æ ‡æ³¨åŒ»å­¦è§†é¢‘ä¹‹é—´çš„å·®è·ï¼Œåœ¨è¿™ä¸ªä½æ•°æ®æ¨¡å¼ä¸‹å®ç°äº†å¼ºå¤§çš„è§†é¢‘åˆ†å‰²æ€§èƒ½ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MedAITech/RAB%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/MedAITech/RABæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14958v1">PDF</a> MICCAI 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åŸºäºå°‘é‡è§†é¢‘å¸§æ ‡æ³¨ä¿¡æ¯çš„è§†é¢‘ç›®æ ‡åˆ†å‰²æŠ€æœ¯ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µæ¡†æ¶ã€‚é¦–å…ˆåˆ©ç”¨å›¾åƒæ ‡æ³¨æ•°æ®å­¦ä¹ ä¸€ä¸ªåˆ†å‰²æ¨¡å‹ï¼Œç„¶åé€šè¿‡æ—¶ç©ºä¸€è‡´æ€§é‡å­¦ä¹ çš„æ–¹æ³•æé«˜æ¨¡å‹åœ¨åŒ»ç–—è§†é¢‘ä¸Šçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•å®ç°äº†åœ¨æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹çš„è§†é¢‘åˆ†å‰²ä»»åŠ¡ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨ä½æ•°æ®ç¯å¢ƒä¸‹çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶ç›®æ ‡ä¸ºè§£å†³åŒ»ç–—é¢†åŸŸæ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œé€šè¿‡å‡å°‘è§†é¢‘æ ‡æ³¨æˆæœ¬å®ç°è§†é¢‘ç›®æ ‡åˆ†å‰²ã€‚</li>
<li>æå‡ºä¸€ç§ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œé¦–å…ˆåˆ©ç”¨å°‘é‡è§†é¢‘å¸§æ ‡æ³¨ä¿¡æ¯å’Œç°æœ‰å›¾åƒæ ‡æ³¨æ•°æ®è¿›è¡Œæ¨¡å‹å­¦ä¹ ã€‚</li>
<li>é‡‡ç”¨æ—¶ç©ºä¸€è‡´æ€§é‡å­¦ä¹ çš„æ–¹æ³•æé«˜æ¨¡å‹æ€§èƒ½ï¼Œå¢å¼ºæ¨¡å‹åœ¨è¿ç»­è§†é¢‘å¸§ä¹‹é—´çš„é¢„æµ‹ä¸€è‡´æ€§ã€‚</li>
<li>æ¨¡å‹åœ¨ç‰¹å¾é¢„æµ‹å±‚é¢ä¸å›¾åƒæ¨¡å‹ä¿æŒä¸€è‡´æ€§ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•æˆåŠŸè§£å†³äº†ä»ä¸°å¯Œçš„åŒ»å­¦å›¾åƒæ ‡æ³¨åˆ°ç¨€ç–åŒ»å­¦è§†é¢‘æ ‡æ³¨çš„è¿‡æ¸¡é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14958">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-05ab530b4b8a174e11040385876a7927.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff3b2227764a96f8af1a4f8aac0fe6c0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Optimal-Transport-Adapter-Tuning-for-Bridging-Modality-Gaps-in-Few-Shot-Remote-Sensing-Scene-Classification"><a href="#Optimal-Transport-Adapter-Tuning-for-Bridging-Modality-Gaps-in-Few-Shot-Remote-Sensing-Scene-Classification" class="headerlink" title="Optimal Transport Adapter Tuning for Bridging Modality Gaps in Few-Shot   Remote Sensing Scene Classification"></a>Optimal Transport Adapter Tuning for Bridging Modality Gaps in Few-Shot   Remote Sensing Scene Classification</h2><p><strong>Authors:Zhong Ji, Ci Liu, Jingren Liu, Chen Tang, Yanwei Pang, Xuelong Li</strong></p>
<p>Few-Shot Remote Sensing Scene Classification (FS-RSSC) presents the challenge of classifying remote sensing images with limited labeled samples. Existing methods typically emphasize single-modal feature learning, neglecting the potential benefits of optimizing multi-modal representations. To address this limitation, we propose a novel Optimal Transport Adapter Tuning (OTAT) framework aimed at constructing an ideal Platonic representational space through optimal transport (OT) theory. This framework seeks to harmonize rich visual information with less dense textual cues, enabling effective cross-modal information transfer and complementarity. Central to this approach is the Optimal Transport Adapter (OTA), which employs a cross-modal attention mechanism to enrich textual representations and facilitate subsequent better information interaction. By transforming the network optimization into an OT optimization problem, OTA establishes efficient pathways for balanced information exchange between modalities. Moreover, we introduce a sample-level Entropy-Aware Weighted (EAW) loss, which combines difficulty-weighted similarity scores with entropy-based regularization. This loss function provides finer control over the OT optimization process, enhancing its solvability and stability. Our framework offers a scalable and efficient solution for advancing multimodal learning in remote sensing applications. Extensive experiments on benchmark datasets demonstrate that OTAT achieves state-of-the-art performance in FS-RSSC, significantly improving the model performance and generalization. </p>
<blockquote>
<p>å°‘é‡é¥æ„Ÿåœºæ™¯åˆ†ç±»ï¼ˆFS-RSSCï¼‰é¢ä¸´ç€å¯¹æœ‰é™æ ‡è®°æ ·æœ¬çš„é¥æ„Ÿå›¾åƒè¿›è¡Œåˆ†ç±»çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾§é‡äºå•æ¨¡æ€ç‰¹å¾å­¦ä¹ ï¼Œå¿½ç•¥äº†ä¼˜åŒ–å¤šæ¨¡æ€è¡¨ç¤ºå¯èƒ½å¸¦æ¥çš„æ½œåœ¨å¥½å¤„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºæœ€ä¼˜ä¼ è¾“é€‚é…å™¨è°ƒæ•´ï¼ˆOTATï¼‰çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æœ€ä¼˜ä¼ è¾“ï¼ˆOTï¼‰ç†è®ºæ„å»ºä¸€ä¸ªç†æƒ³çš„æŸæ‹‰å›¾è¡¨ç¤ºç©ºé—´ã€‚è¯¥æ¡†æ¶æ—¨åœ¨åè°ƒä¸°å¯Œçš„è§†è§‰ä¿¡æ¯ä¸è¾ƒå°‘çš„æ–‡æœ¬çº¿ç´¢ï¼Œå®ç°æœ‰æ•ˆçš„è·¨æ¨¡æ€ä¿¡æ¯è½¬ç§»å’Œäº’è¡¥ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯æœ€ä½³ä¼ è¾“é€‚é…å™¨ï¼ˆOTAï¼‰ï¼Œå®ƒé‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶æ¥ä¸°å¯Œæ–‡æœ¬è¡¨ç¤ºï¼Œå¹¶ä¿ƒè¿›åç»­æ›´å¥½çš„ä¿¡æ¯äº¤äº’ã€‚é€šè¿‡å°†ç½‘ç»œä¼˜åŒ–è½¬åŒ–ä¸ºOTä¼˜åŒ–é—®é¢˜ï¼ŒOTAä¸ºè·¨æ¨¡æ€ä¹‹é—´çš„å¹³è¡¡ä¿¡æ¯äº¤æ¢å»ºç«‹äº†æœ‰æ•ˆçš„è·¯å¾„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ ·æœ¬çº§ç†µæ„ŸçŸ¥åŠ æƒï¼ˆEAWï¼‰æŸå¤±ï¼Œå°†éš¾åº¦åŠ æƒç›¸ä¼¼åº¦å¾—åˆ†ä¸åŸºäºç†µçš„æ­£åˆ™åŒ–ç›¸ç»“åˆã€‚æ­¤æŸå¤±å‡½æ•°å¯ä»¥æ›´ç²¾ç»†åœ°æ§åˆ¶OTä¼˜åŒ–è¿‡ç¨‹ï¼Œæé«˜å…¶æ±‚è§£æ€§å’Œç¨³å®šæ€§ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ºé¥æ„Ÿåº”ç”¨ä¸­çš„å¤šæ¨¡æ€å­¦ä¹ æä¾›äº†å¯æ‰©å±•å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒOTATåœ¨FS-RSSCä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14938v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°æ ·æœ¬é¥æ„Ÿåœºæ™¯åˆ†ç±»ï¼ˆFS-RSSCï¼‰çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„Optimal Transport Adapter Tuningï¼ˆOTATï¼‰æ¡†æ¶æ¥è§£å†³ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æœ€ä¼˜ä¼ è¾“ï¼ˆOTï¼‰ç†è®ºæ„å»ºä¸€ä¸ªç†æƒ³çš„æŸæ‹‰å›¾è¡¨ç¤ºç©ºé—´ï¼Œä»¥èåˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ã€‚ä¸­å¿ƒæ˜¯Optimal Transport Adapterï¼ˆOTAï¼‰ï¼Œé‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶æ¥ä¸°å¯Œæ–‡æœ¬è¡¨ç¤ºï¼Œä¿ƒè¿›æ›´æœ‰æ•ˆçš„ä¿¡æ¯äº¤äº’ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†æ ·æœ¬çº§çš„Entropy-Aware Weightedï¼ˆEAWï¼‰æŸå¤±å‡½æ•°ï¼Œä¸ºOTä¼˜åŒ–è¿‡ç¨‹æä¾›æ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œå¢å¼ºå…¶å¯è§£æ€§å’Œç¨³å®šæ€§ã€‚OTATæ¡†æ¶ä¸ºé¥æ„Ÿåº”ç”¨ä¸­çš„å¤šæ¨¡æ€å­¦ä¹ æä¾›äº†å¯æ‰©å±•å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶åœ¨åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-Shot Remote Sensing Scene Classification (FS-RSSC)å­˜åœ¨æŒ‘æˆ˜ï¼Œéœ€è¦è§£å†³åœ¨æœ‰é™æ ‡è®°æ ·æœ¬ä¸‹å¯¹é¥æ„Ÿå›¾åƒè¿›è¡Œåˆ†ç±»çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•æ¨¡æ€ç‰¹å¾å­¦ä¹ ï¼Œå¿½ç•¥äº†ä¼˜åŒ–å¤šæ¨¡æ€è¡¨ç¤ºçš„å·¨å¤§æ½œåŠ›ã€‚</li>
<li>æå‡ºäº†Optimal Transport Adapter Tuning (OTAT)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æœ€ä¼˜ä¼ è¾“ï¼ˆOTï¼‰ç†è®ºæ„å»ºç†æƒ³çš„æŸæ‹‰å›¾è¡¨ç¤ºç©ºé—´ã€‚</li>
<li>OTATæ¡†æ¶èåˆäº†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œå®ç°äº†è·¨æ¨¡æ€ä¿¡æ¯è½¬ç§»å’Œäº’è¡¥ã€‚</li>
<li>Optimal Transport Adapter (OTA)æ˜¯æ¡†æ¶çš„æ ¸å¿ƒï¼Œé‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶æ¥ä¸°å¯Œæ–‡æœ¬è¡¨ç¤ºå¹¶ä¿ƒè¿›æ›´æœ‰æ•ˆçš„ä¿¡æ¯äº¤äº’ã€‚</li>
<li>å¼•å…¥äº†æ ·æœ¬çº§çš„Entropy-Aware Weighted (EAW)æŸå¤±å‡½æ•°ï¼Œä¸ºOTä¼˜åŒ–è¿‡ç¨‹æä¾›æ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œå¢å¼ºå…¶ç¨³å®šæ€§å’Œå¯è§£å†³æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14938">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4162fa7353a0110851ce9005f36756a7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab4c06702356b54b37e0e6775ed5e8ed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f82600b9ac651faad4f9081ed98cef4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2d439e957ad01c78ff3ed1bb92b91cfc.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Derm1M-A-Million-scale-Vision-Language-Dataset-Aligned-with-Clinical-Ontology-Knowledge-for-Dermatology"><a href="#Derm1M-A-Million-scale-Vision-Language-Dataset-Aligned-with-Clinical-Ontology-Knowledge-for-Dermatology" class="headerlink" title="Derm1M: A Million-scale Vision-Language Dataset Aligned with Clinical   Ontology Knowledge for Dermatology"></a>Derm1M: A Million-scale Vision-Language Dataset Aligned with Clinical   Ontology Knowledge for Dermatology</h2><p><strong>Authors:Siyuan Yan, Ming Hu, Yiwen Jiang, Xieji Li, Hao Fei, Philipp Tschandl, Harald Kittler, Zongyuan Ge</strong></p>
<p>The emergence of vision-language models has transformed medical AI, enabling unprecedented advances in diagnostic capability and clinical applications. However, progress in dermatology has lagged behind other medical domains due to the lack of standard image-text pairs. Existing dermatological datasets are limited in both scale and depth, offering only single-label annotations across a narrow range of diseases instead of rich textual descriptions, and lacking the crucial clinical context needed for real-world applications. To address these limitations, we present Derm1M, the first large-scale vision-language dataset for dermatology, comprising 1,029,761 image-text pairs. Built from diverse educational resources and structured around a standard ontology collaboratively developed by experts, Derm1M provides comprehensive coverage for over 390 skin conditions across four hierarchical levels and 130 clinical concepts with rich contextual information such as medical history, symptoms, and skin tone. To demonstrate Derm1M potential in advancing both AI research and clinical application, we pretrained a series of CLIP-like models, collectively called DermLIP, on this dataset. The DermLIP family significantly outperforms state-of-the-art foundation models on eight diverse datasets across multiple tasks, including zero-shot skin disease classification, clinical and artifacts concept identification, few-shot&#x2F;full-shot learning, and cross-modal retrieval. Our dataset and code will be public. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹çš„å…´èµ·å·²ç»æ¨åŠ¨äº†åŒ»ç–—äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œä¸ºè¯Šæ–­èƒ½åŠ›å’Œä¸´åºŠåº”ç”¨å¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œçš®è‚¤ç—…å­¦çš„è¿›å±•ç”±äºç¼ºå°‘æ ‡å‡†å›¾åƒæ–‡æœ¬é…å¯¹è€Œè½åäºå…¶ä»–åŒ»å­¦é¢†åŸŸã€‚ç°æœ‰çš„çš®è‚¤ç—…æ•°æ®é›†åœ¨è§„æ¨¡å’Œæ·±åº¦ä¸Šå‡æœ‰é™ï¼Œåªæä¾›ç‹­çª„ç–¾ç—…èŒƒå›´å†…çš„å•ä¸€æ ‡ç­¾æ³¨é‡Šï¼Œè€Œéä¸°å¯Œçš„æ–‡æœ¬æè¿°ï¼Œå¹¶ç¼ºä¹çœŸå®ä¸–ç•Œåº”ç”¨æ‰€éœ€çš„å…³é”®ä¸´åºŠèƒŒæ™¯ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Derm1Mï¼Œè¿™æ˜¯çš®è‚¤ç—…é¢†åŸŸé¦–ä¸ªå¤§è§„æ¨¡è§†è§‰è¯­è¨€æ•°æ®é›†ï¼ŒåŒ…å«1,029,761ä¸ªå›¾åƒæ–‡æœ¬å¯¹ã€‚Derm1Mç”±å¤šæ ·åŒ–çš„æ•™è‚²èµ„æºæ„å»ºï¼Œå›´ç»•ä¸“å®¶å…±åŒå¼€å‘çš„æ ‡å‡†æœ¬ä½“ç»“æ„ï¼Œä¸ºè¶…è¿‡390ç§çš®è‚¤çŠ¶å†µæä¾›äº†å››çº§å±‚æ¬¡ç»“æ„å’Œ130ç§ä¸´åºŠæ¦‚å¿µçš„å…¨é¢è¦†ç›–ï¼Œä»¥åŠä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚ç—…å²ã€ç—‡çŠ¶å’Œè‚¤è‰²ç­‰ã€‚ä¸ºäº†è¯æ˜Derm1Måœ¨æ¨åŠ¨äººå·¥æ™ºèƒ½ç ”ç©¶å’Œä¸´åºŠåº”ç”¨æ–¹é¢çš„æ½œåŠ›ï¼Œæˆ‘ä»¬åœ¨è¯¥æ•°æ®é›†ä¸Šé¢„è®­ç»ƒäº†ä¸€ç³»åˆ—ç±»ä¼¼äºCLIPçš„æ¨¡å‹ï¼Œç»Ÿç§°ä¸ºDermLIPã€‚DermLIPå®¶æ—åœ¨å¤šä¸ªä»»åŠ¡çš„å…«ä¸ªä¸åŒæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„åŸºç¡€æ¨¡å‹ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬çš®è‚¤ç—…åˆ†ç±»ã€ä¸´åºŠå’Œæ–‡ç‰©æ¦‚å¿µè¯†åˆ«ã€å°‘æ ·æœ¬&#x2F;å…¨æ ·æœ¬å­¦ä¹ å’Œè·¨æ¨¡æ€æ£€ç´¢ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14911v1">PDF</a> 23 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŒ»å­¦äººå·¥æ™ºèƒ½é¢†åŸŸä¸­çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨çš®è‚¤ç§‘çš„åº”ç”¨ã€‚ç”±äºç¼ºå°‘æ ‡å‡†å›¾åƒæ–‡æœ¬é…å¯¹ï¼Œçš®è‚¤ç§‘çš„è¿›æ­¥æ»åäºå…¶ä»–åŒ»å­¦é¢†åŸŸã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡çš®è‚¤ç§‘è§†è§‰è¯­è¨€æ•°æ®é›†Derm1Mï¼ŒåŒ…å«1,029,761ä¸ªå›¾åƒæ–‡æœ¬å¯¹ï¼Œæ¶µç›–è¶…è¿‡390ç§çš®è‚¤çŠ¶å†µã€130ç§ä¸´åºŠæ¦‚å¿µå’Œä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åŒæ—¶ï¼ŒåŸºäºè¯¥æ•°æ®é›†é¢„è®­ç»ƒäº†ä¸€ç³»åˆ—CLIPç±»æ¨¡å‹ï¼ˆç»Ÿç§°ä¸ºDermLIPï¼‰ï¼Œåœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬çš®è‚¤ç–¾ç—…åˆ†ç±»ã€ä¸´åºŠå’Œä¼ªæ¦‚å¿µè¯†åˆ«ã€å°‘æ ·æœ¬&#x2F;å…¨æ ·æœ¬å­¦ä¹ å’Œè·¨æ¨¡æ€æ£€ç´¢ã€‚æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦AIé¢†åŸŸæœ‰é‡è¦åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨çš®è‚¤ç§‘ã€‚</li>
<li>çš®è‚¤ç§‘è¿›æ­¥æ»åäºå…¶ä»–åŒ»å­¦é¢†åŸŸï¼Œä¸»è¦å› ä¸ºç¼ºå°‘æ ‡å‡†å›¾åƒæ–‡æœ¬é…å¯¹ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡çš®è‚¤ç§‘è§†è§‰è¯­è¨€æ•°æ®é›†Derm1Mï¼ŒåŒ…å«ä¸°å¯Œçš„å›¾åƒæ–‡æœ¬å¯¹å’Œä¸´åºŠæ¦‚å¿µä¿¡æ¯ã€‚</li>
<li>DermLIPæ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬çš®è‚¤ç–¾ç—…åˆ†ç±»ã€ä¸´åºŠå’Œä¼ªæ¦‚å¿µè¯†åˆ«ç­‰ã€‚</li>
<li>Derm1Mæ•°æ®é›†å°†ä¿ƒè¿›AIç ”ç©¶å’Œä¸´åºŠåº”ç”¨çš„å‘å±•ã€‚</li>
<li>è¯¥æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€ä¾›å…¬ä¼—ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14911">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9d626408036c3f4de8d88a062c5f0882.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7fb0523ca20153cf2f299e70a722d893.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d282352ea9b853fe9fc1712f959adb4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8846420170919213121157aed47e6edb.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Matching-Skeleton-based-Activity-Representations-with-Heterogeneous-Signals-for-HAR"><a href="#Matching-Skeleton-based-Activity-Representations-with-Heterogeneous-Signals-for-HAR" class="headerlink" title="Matching Skeleton-based Activity Representations with Heterogeneous   Signals for HAR"></a>Matching Skeleton-based Activity Representations with Heterogeneous   Signals for HAR</h2><p><strong>Authors:Shuheng Li, Jiayun Zhang, Xiaohan Fu, Xiyuan Zhang, Jingbo Shang, Rajesh K. Gupta</strong></p>
<p>In human activity recognition (HAR), activity labels have typically been encoded in one-hot format, which has a recent shift towards using textual representations to provide contextual knowledge. Here, we argue that HAR should be anchored to physical motion data, as motion forms the basis of activity and applies effectively across sensing systems, whereas text is inherently limited. We propose SKELAR, a novel HAR framework that pretrains activity representations from skeleton data and matches them with heterogeneous HAR signals. Our method addresses two major challenges: (1) capturing core motion knowledge without context-specific details. We achieve this through a self-supervised coarse angle reconstruction task that recovers joint rotation angles, invariant to both users and deployments; (2) adapting the representations to downstream tasks with varying modalities and focuses. To address this, we introduce a self-attention matching module that dynamically prioritizes relevant body parts in a data-driven manner. Given the lack of corresponding labels in existing skeleton data, we establish MASD, a new HAR dataset with IMU, WiFi, and skeleton, collected from 20 subjects performing 27 activities. This is the first broadly applicable HAR dataset with time-synchronized data across three modalities. Experiments show that SKELAR achieves the state-of-the-art performance in both full-shot and few-shot settings. We also demonstrate that SKELAR can effectively leverage synthetic skeleton data to extend its use in scenarios without skeleton collections. </p>
<blockquote>
<p>åœ¨äººç±»æ´»åŠ¨è¯†åˆ«ï¼ˆHARï¼‰ä¸­ï¼Œæ´»åŠ¨æ ‡ç­¾é€šå¸¸è¢«ç¼–ç ä¸ºä¸€çƒ­æ ¼å¼ï¼Œæœ€è¿‘æœ‰è½¬å‘ä½¿ç”¨æ–‡æœ¬è¡¨ç¤ºä»¥æä¾›ä¸Šä¸‹æ–‡çŸ¥è¯†çš„è¶‹åŠ¿ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸»å¼ HARåº”è¯¥ä»¥ç‰©ç†è¿åŠ¨æ•°æ®ä¸ºåŸºç¡€ï¼Œå› ä¸ºè¿åŠ¨æ˜¯æ´»åŠ¨çš„åŸºç¡€ï¼Œå¹¶åœ¨ä¸åŒçš„æ„Ÿåº”ç³»ç»Ÿä¸­æœ‰æ•ˆåº”ç”¨ï¼Œè€Œæ–‡æœ¬åˆ™å…·æœ‰å†…åœ¨çš„å±€é™æ€§ã€‚æˆ‘ä»¬æå‡ºäº†SKELARï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹HARæ¡†æ¶ï¼Œå¯ä»¥ä»éª¨æ¶æ•°æ®ä¸­é¢„è®­ç»ƒæ´»åŠ¨è¡¨ç¤ºï¼Œå¹¶ä¸å¼‚æ„HARä¿¡å·è¿›è¡ŒåŒ¹é…ã€‚æˆ‘ä»¬çš„æ–¹æ³•è§£å†³äº†ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰æ•è·æ ¸å¿ƒè¿åŠ¨çŸ¥è¯†è€Œä¸æ¶‰åŠç‰¹å®šä¸Šä¸‹æ–‡ç»†èŠ‚ã€‚æˆ‘ä»¬é€šè¿‡è‡ªæˆ‘ç›‘ç£çš„ç²—ç•¥è§’åº¦é‡å»ºä»»åŠ¡å®ç°è¿™ä¸€ç‚¹ï¼Œè¯¥ä»»åŠ¡èƒ½å¤Ÿæ¢å¤å…³èŠ‚æ—‹è½¬è§’åº¦ï¼Œå¯¹ç”¨æˆ·å’Œéƒ¨ç½²å…·æœ‰ä¸å˜æ€§ï¼›ï¼ˆ2ï¼‰å°†è¡¨ç¤ºå½¢å¼é€‚åº”å…·æœ‰ä¸åŒæ¨¡æ€å’Œé‡ç‚¹çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè‡ªæˆ‘æ³¨æ„åŠ›åŒ¹é…æ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿä»¥æ•°æ®é©±åŠ¨çš„æ–¹å¼åŠ¨æ€åœ°ä¼˜å…ˆå¤„ç†ç›¸å…³éƒ¨ä½ã€‚è€ƒè™‘åˆ°ç°æœ‰éª¨æ¶æ•°æ®ä¸­ç¼ºå°‘ç›¸åº”çš„æ ‡ç­¾ï¼Œæˆ‘ä»¬å»ºç«‹äº†MASDï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„HARæ•°æ®é›†ï¼ŒåŒ…å«IMUã€WiFiå’Œéª¨æ¶æ•°æ®ï¼Œä»æ‰§è¡Œ27é¡¹æ´»åŠ¨çš„20åå—è¯•è€…ä¸­æ”¶é›†ã€‚è¿™æ˜¯ç¬¬ä¸€ä¸ªåœ¨ä¸‰æ¨¡æ€ä¸­æ—¶é—´åŒæ­¥æ•°æ®çš„å¹¿æ³›åº”ç”¨HARæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨å…¨é•œå¤´å’Œå°‘é•œå¤´è®¾ç½®ä¸­ï¼ŒSKELARéƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„è¡¨ç°ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†SKELARå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨åˆæˆéª¨æ¶æ•°æ®æ¥æ‰©å±•å…¶åœ¨æ²¡æœ‰éª¨æ¶æ”¶é›†çš„åœºæ™¯ä¸­çš„åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14547v1">PDF</a> This paper is accepted by SenSys 2025</p>
<p><strong>Summary</strong></p>
<p>åœ¨äººä½“æ´»åŠ¨è¯†åˆ«ï¼ˆHARï¼‰é¢†åŸŸï¼Œä»¥å¾€å¤šé‡‡ç”¨ç‹¬çƒ­ç¼–ç çš„æ´»åŠ¨æ ‡ç­¾æ–¹å¼ï¼Œä½†è¿‘æœŸé€æ¸å‘ä½¿ç”¨æ–‡æœ¬è¡¨ç¤ºæä¾›ä¸Šä¸‹æ–‡çŸ¥è¯†è½¬å˜ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¸»å¼ HARåº”ä»¥ç‰©ç†è¿åŠ¨æ•°æ®ä¸ºåŸºç¡€ï¼Œå› ä¸ºè¿åŠ¨æ˜¯æ´»åŠ¨çš„åŸºç¡€å¹¶æœ‰æ•ˆé€‚ç”¨äºå„ç§ä¼ æ„Ÿç³»ç»Ÿï¼Œè€Œæ–‡æœ¬åˆ™å­˜åœ¨å›ºæœ‰å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†SKELARè¿™ä¸€æ–°å‹HARæ¡†æ¶ï¼Œå®ƒèƒ½ä»éª¨æ¶æ•°æ®ä¸­é¢„è®­ç»ƒæ´»åŠ¨è¡¨ç¤ºå¹¶ä¸å¼‚è´¨HARä¿¡å·åŒ¹é…ã€‚æ­¤æ¡†æ¶è§£å†³äº†ä¸¤å¤§æŒ‘æˆ˜ï¼šä¸€ã€æ•æ‰æ ¸å¿ƒè¿åŠ¨çŸ¥è¯†è€Œä¸æ¶‰åŠç‰¹å®šä¸Šä¸‹æ–‡ç»†èŠ‚ï¼Œæˆ‘ä»¬é€šè¿‡è‡ªç›‘ç£çš„ç²—ç•¥è§’åº¦é‡å»ºä»»åŠ¡å®ç°è¿™ä¸€ç‚¹ï¼Œèƒ½å¤Ÿæ¢å¤å…³èŠ‚æ—‹è½¬è§’åº¦ï¼Œå¯¹ç”¨æˆ·éƒ¨ç½²å‡ä¿æŒä¸å˜ï¼›äºŒã€é’ˆå¯¹å…·æœ‰ä¸åŒæ¨¡æ€å’Œé‡ç‚¹çš„ä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œè‡ªé€‚åº”è¡¨ç¤ºï¼Œä¸ºæ­¤æˆ‘ä»¬å¼•å…¥äº†è‡ªæ³¨æ„åŠ›åŒ¹é…æ¨¡å—ï¼Œä»¥æ•°æ®é©±åŠ¨çš„æ–¹å¼åŠ¨æ€ä¼˜å…ˆå¤„ç†é‡è¦éƒ¨ä½ã€‚ç”±äºç¼ºä¹ç›¸åº”çš„éª¨æ¶æ•°æ®æ ‡ç­¾ï¼Œæˆ‘ä»¬å»ºç«‹äº†MASDè¿™ä¸€æ–°HARæ•°æ®é›†ï¼ŒåŒ…å«IMUã€WiFiå’Œéª¨æ¶æ•°æ®ï¼Œç”±20åå—è¯•è€…è¿›è¡Œ27é¡¹æ´»åŠ¨é‡‡é›†è€Œæˆã€‚è¿™æ˜¯é¦–ä¸ªé€‚ç”¨äºå¤šç§æ¨¡æ€çš„é€šç”¨HARæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼ŒSKELARåœ¨å…¨é•œå¤´å’Œå°‘é•œå¤´è®¾ç½®ä¸­éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†SKELARåœ¨æ²¡æœ‰éª¨æ¶æ”¶é›†çš„åœºæ™¯ä¸­èƒ½æœ‰æ•ˆåˆ©ç”¨åˆæˆéª¨æ¶æ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ´»åŠ¨è¯†åˆ«åº”åŸºäºç‰©ç†è¿åŠ¨æ•°æ®ï¼Œå¼ºè°ƒè¿åŠ¨åœ¨æ´»åŠ¨ä¸­çš„åŸºç¡€åœ°ä½åŠè·¨ä¼ æ„Ÿç³»ç»Ÿçš„é€‚ç”¨æ€§ã€‚</li>
<li>SKELARæ¡†æ¶è§£å†³äº†ä»éª¨æ¶æ•°æ®ä¸­é¢„è®­ç»ƒæ´»åŠ¨è¡¨ç¤ºçš„æŒ‘æˆ˜ã€‚</li>
<li>SKELARé€šè¿‡è‡ªç›‘ç£çš„ç²—ç•¥è§’åº¦é‡å»ºä»»åŠ¡æ•æ‰æ ¸å¿ƒè¿åŠ¨çŸ¥è¯†ï¼Œå¯¹ç”¨æˆ·å’Œéƒ¨ç½²å‡ä¿æŒä¸å˜ã€‚</li>
<li>SKELARé€šè¿‡è‡ªæ³¨æ„åŠ›åŒ¹é…æ¨¡å—å®ç°å¯¹ä¸åŒä¸‹æ¸¸ä»»åŠ¡çš„è‡ªé€‚åº”è¡¨ç¤ºã€‚</li>
<li>å»ºç«‹äº†æ–°çš„HARæ•°æ®é›†MASDï¼ŒåŒ…å«IMUã€WiFiå’Œéª¨æ¶æ•°æ®ï¼Œé€‚ç”¨äºå¤šç§æ¨¡æ€ã€‚</li>
<li>SKELARåœ¨å…¨é•œå¤´å’Œå°‘é•œå¤´è®¾ç½®ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14547">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4507ee7b32240c91f2f66bc5819a5170.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-841920e3c08e80e5f40542baedb5ad3f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b886daa18ff3459c28b3f909ea71e0b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c29179ae2da0ad6dbc04a77d768f60d.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-21/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-21/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-21/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-952bd772b48e9d7c2e223217ec9b0b76.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-21  ARC Anchored Representation Clouds for High-Resolution INR   Classification
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-21/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e6116c0b8dbcca8d73715e625323a88b.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-21  SWEET-RL Training Multi-Turn LLM Agents on Collaborative Reasoning   Tasks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28791.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
