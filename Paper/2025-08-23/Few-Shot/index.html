<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-23  Amortized In-Context Mixed Effect Transformer Models A Zero-Shot   Approach for Pharmacokinetics">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-8e9808ff564f5e19ce16e0846f0654a1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    50 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-23-æ›´æ–°"><a href="#2025-08-23-æ›´æ–°" class="headerlink" title="2025-08-23 æ›´æ–°"></a>2025-08-23 æ›´æ–°</h1><h2 id="Amortized-In-Context-Mixed-Effect-Transformer-Models-A-Zero-Shot-Approach-for-Pharmacokinetics"><a href="#Amortized-In-Context-Mixed-Effect-Transformer-Models-A-Zero-Shot-Approach-for-Pharmacokinetics" class="headerlink" title="Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot   Approach for Pharmacokinetics"></a>Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot   Approach for Pharmacokinetics</h2><p><strong>Authors:CÃ©sar Ali Ojeda Marin, Wilhelm Huisinga, Purity Kavwele, Niklas Hartung</strong></p>
<p>Accurate dose-response forecasting under sparse sampling is central to precision pharmacotherapy. We present the Amortized In-Context Mixed-Effect Transformer (AICMET) model, a transformer-based latent-variable framework that unifies mechanistic compartmental priors with amortized in-context Bayesian inference. AICMET is pre-trained on hundreds of thousands of synthetic pharmacokinetic trajectories with Ornstein-Uhlenbeck priors over the parameters of compartment models, endowing the model with strong inductive biases and enabling zero-shot adaptation to new compounds. At inference time, the decoder conditions on the collective context of previously profiled trial participants, generating calibrated posterior predictions for newly enrolled patients after a few early drug concentration measurements. This capability collapses traditional model-development cycles from weeks to hours while preserving some degree of expert modelling. Experiments across public datasets show that AICMET attains state-of-the-art predictive accuracy and faithfully quantifies inter-patient variability â€“ outperforming both nonlinear mixed-effects baselines and recent neural ODE variants. Our results highlight the feasibility of transformer-based, population-aware neural architectures as offering a new alternative for bespoke pharmacokinetic modeling pipelines, charting a path toward truly population-aware personalized dosing regimens. </p>
<blockquote>
<p>åœ¨ç¨€ç–é‡‡æ ·ä¸‹è¿›è¡Œå‡†ç¡®çš„å‰‚é‡-ååº”é¢„æµ‹æ˜¯ç²¾å‡†è¯ç‰©æ²»ç–—çš„æ ¸å¿ƒã€‚æˆ‘ä»¬æå‡ºäº†å¹³å‡ä¸Šä¸‹æ–‡æ··åˆæ•ˆåº”å˜å‹å™¨ï¼ˆAICMETï¼‰æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå˜å‹å™¨çš„æ½œåœ¨å˜é‡æ¡†æ¶ï¼Œå®ƒå°†æœºæ¢°å®¤æ¨¡å‹å…ˆéªŒä¸å¹³å‡ä¸Šä¸‹æ–‡è´å¶æ–¯æ¨ç†ç›¸ç»“åˆã€‚AICMETåœ¨æ•°ä»¥ä¸‡è®¡çš„äººå·¥è¯ç‰©ä»£è°¢è½¨è¿¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™äº›è½¨è¿¹å¸¦æœ‰Ornstein-Uhlenbeckå…³äºå®¤æ¨¡å‹å‚æ•°çš„å…ˆéªŒï¼Œä¸ºæ¨¡å‹æä¾›äº†å¼ºçƒˆçš„å½’çº³åè§ï¼Œå¹¶å®ç°äº†å¯¹æ–°åŒ–åˆç‰©çš„é›¶æ ·æœ¬é€‚åº”ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè§£ç å™¨æ ¹æ®å…ˆå‰åˆ†æè¿‡çš„è¯•éªŒå‚ä¸è€…çš„é›†ä½“ä¸Šä¸‹æ–‡è¿›è¡Œè°ƒæ•´ï¼Œåœ¨å°‘æ•°æ—©æœŸè¯ç‰©æµ“åº¦æµ‹é‡åï¼Œä¸ºåˆšå…¥å­¦çš„æ–°æ‚£è€…ç”Ÿæˆæ ¡å‡†çš„åéªŒé¢„æµ‹ã€‚è¿™ç§èƒ½åŠ›å°†ä¼ ç»Ÿçš„æ¨¡å‹å¼€å‘å‘¨æœŸä»æ•°å‘¨ç¼©çŸ­åˆ°æ•°å°æ—¶ï¼ŒåŒæ—¶ä¿ç•™ä¸€å®šç¨‹åº¦çš„ä¸“å®¶å»ºæ¨¡ã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAICMETè¾¾åˆ°äº†å…ˆè¿›çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹¶çœŸå®åœ°é‡åŒ–äº†æ‚£è€…é—´çš„å·®å¼‚â€”â€”ä¼˜äºéçº¿æ€§æ··åˆæ•ˆåº”åŸºå‡†å’Œæœ€æ–°çš„ç¥ç»ODEå˜ä½“ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†åŸºäºå˜å‹å™¨çš„ã€å…·æœ‰äººç¾¤æ„è¯†çš„ç¥ç»ç½‘ç»œæ¶æ„çš„å¯è¡Œæ€§ï¼Œä¸ºå®šåˆ¶çš„è¯ç‰©ä»£è°¢åŠ¨åŠ›å­¦å»ºæ¨¡ç®¡é“æä¾›äº†æ–°çš„é€‰æ‹©ï¼Œä¸ºçœŸæ­£å…·æœ‰äººç¾¤æ„è¯†ä¸ªæ€§åŒ–ç»™è¯æ–¹æ¡ˆé“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.15659v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p> AICMETæ¨¡å‹æ˜¯ä¸€ç§åŸºäºè½¬åŒ–å™¨çš„æ½œå˜é‡æ¡†æ¶ï¼Œå®ƒå°†æœºæ¢°å®¤æ¨¡å‹å…ˆéªŒä¸æ‘Šé”€ä¸Šä¸‹æ–‡è´å¶æ–¯æ¨ç†ç›¸ç»“åˆï¼Œå®ç°äº†ç¨€ç–é‡‡æ ·ä¸‹çš„ç²¾å‡†å‰‚é‡ååº”é¢„æµ‹ã€‚è¯¥æ¨¡å‹ç»è¿‡ç™¾ä¸‡çº§åˆæˆè¯ç‰©ä»£è°¢åŠ¨åŠ›å­¦è½¨è¿¹çš„é¢„è®­ç»ƒï¼Œå¹¶å…·å¤‡Ornstein-Uhlenbeckå…ˆéªŒçŸ¥è¯†ï¼Œå¯å¿«é€Ÿé€‚åº”æ–°åŒ–åˆç‰©ã€‚åœ¨æ¨æ–­é˜¶æ®µï¼Œè¯¥è§£ç å™¨æ ¹æ®å…ˆå‰è¯•éªŒå‚ä¸è€…çš„é›†ä½“ä¸Šä¸‹æ–‡è¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œç”Ÿæˆæ–°çº³å…¥æ‚£è€…ç»å‡ æ¬¡æ—©æœŸè¯ç‰©æµ“åº¦æµ‹é‡åçš„æ ¡å‡†åé¢„æµ‹ã€‚æ­¤èƒ½åŠ›ä½¿å¾—æ¨¡å‹å¼€å‘å‘¨æœŸä»æ•°å‘¨ç¼©çŸ­è‡³æ•°å°æ—¶ï¼ŒåŒæ—¶ä¿æŒäº†ä¸“å®¶å»ºæ¨¡çš„ä¸€å®šç¨‹åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒAICMETåœ¨å…¬å…±æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹¶å¿ å®é‡åŒ–äº†æ‚£è€…é—´çš„å˜å¼‚æ€§ï¼Œä¼˜äºéçº¿æ€§æ··åˆæ•ˆåº”åŸºå‡†å’Œæœ€æ–°çš„ç¥ç»ODEå˜ä½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AICMETæ¨¡å‹æ˜¯ä¸€ä¸ªåŸºäºè½¬åŒ–å™¨çš„æ½œå˜é‡æ¡†æ¶ï¼Œç»“åˆäº†æœºæ¢°å®¤æ¨¡å‹å…ˆéªŒå’Œæ‘Šé”€ä¸Šä¸‹æ–‡è´å¶æ–¯æ¨ç†ã€‚</li>
<li>æ¨¡å‹ç»è¿‡å¤§é‡åˆæˆè¯ç‰©ä»£è°¢åŠ¨åŠ›å­¦è½¨è¿¹çš„é¢„è®­ç»ƒï¼Œå…·å¤‡Ornstein-Uhlenbeckå…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>AICMETå¯ä»¥å¿«é€Ÿé€‚åº”æ–°åŒ–åˆç‰©ï¼Œå¹¶åœ¨æ¨æ–­é˜¶æ®µæ ¹æ®å…ˆå‰è¯•éªŒå‚ä¸è€…çš„é›†ä½“ä¸Šä¸‹æ–‡è¿›è¡Œæ¡ä»¶å¤„ç†ã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ç¨€ç–é‡‡æ ·ä¸‹è¿›è¡Œç²¾å‡†å‰‚é‡ååº”é¢„æµ‹ã€‚</li>
<li>AICMETè¾¾åˆ°äº†å…ˆè¿›çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹¶å¿ å®é‡åŒ–äº†æ‚£è€…é—´çš„å˜å¼‚æ€§ã€‚</li>
<li>ä¸éçº¿æ€§æ··åˆæ•ˆåº”åŸºå‡†å’Œç¥ç»ODEå˜ä½“ç›¸æ¯”ï¼ŒAICMETè¡¨ç°å‡ºä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.15659">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ea439aa091202bca24c089b57d414411.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-13ef1c417662ec98846a30640d2a0255.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e821497e1e2d78a6425f6cebc56c887.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2134f364689f733b9cb6948f31e7cf00.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Bridging-Generalization-and-Personalization-in-Wearable-Human-Activity-Recognition-via-On-Device-Few-Shot-Learning"><a href="#Bridging-Generalization-and-Personalization-in-Wearable-Human-Activity-Recognition-via-On-Device-Few-Shot-Learning" class="headerlink" title="Bridging Generalization and Personalization in Wearable Human Activity   Recognition via On-Device Few-Shot Learning"></a>Bridging Generalization and Personalization in Wearable Human Activity   Recognition via On-Device Few-Shot Learning</h2><p><strong>Authors:Pixi Kang, Julian Moosmann, Mengxi Liu, Bo Zhou, Michele Magno, Paul Lukowicz, Sizhen Bian</strong></p>
<p>Human Activity Recognition (HAR) using wearable devices has advanced significantly in recent years, yet its generalization remains limited when models are deployed to new users. This degradation in performance is primarily due to user-induced concept drift (UICD), highlighting the importance of efficient personalization. In this paper, we present a hybrid framework that first generalizes across users and then rapidly adapts to individual users using few-shot learning directly on-device. By updating only the classifier layer with user-specific data, our method achieves robust personalization with minimal computational and memory overhead. We implement this framework on the energy-efficient RISC-V-based GAP9 microcontroller and validate it across three diverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture. Post-deployment adaptation yields consistent accuracy improvements of 3.73%, 17.38%, and 3.70% respectively. These results confirm that fast, lightweight, and effective personalization is feasible on embedded platforms, paving the way for scalable and user-aware HAR systems in the wild \footnote{<a target="_blank" rel="noopener" href="https://github.com/kangpx/onlineTiny2023%7D">https://github.com/kangpx/onlineTiny2023}</a>. </p>
<blockquote>
<p>ä½¿ç”¨å¯ç©¿æˆ´è®¾å¤‡è¿›è¡Œäººç±»æ´»åŠ¨è¯†åˆ«ï¼ˆHARï¼‰çš„ç ”ç©¶è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å½“æ¨¡å‹éƒ¨ç½²ç»™æ–°ç”¨æˆ·æ—¶ï¼Œå…¶æ³›åŒ–èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚è¿™ç§æ€§èƒ½ä¸‹é™ä¸»è¦æ˜¯ç”±äºç”¨æˆ·å¼•èµ·çš„æ¦‚å¿µæ¼‚ç§»ï¼ˆUICDï¼‰ï¼Œä»è€Œçªå‡ºäº†æœ‰æ•ˆä¸ªæ€§åŒ–çš„é‡è¦æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é¦–å…ˆå®ç°è·¨ç”¨æˆ·æ³›åŒ–ï¼Œç„¶åç›´æ¥ä½¿ç”¨å°‘é‡æ•°æ®åœ¨è®¾å¤‡ä¸Šè¿›è¡Œå¿«é€Ÿçš„ä¸ªäººç”¨æˆ·é€‚åº”ã€‚é€šè¿‡ä»…ä½¿ç”¨ç”¨æˆ·ç‰¹å®šæ•°æ®æ›´æ–°åˆ†ç±»å™¨å±‚ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨è®¡ç®—é‡å’Œå†…å­˜å¼€é”€æå°çš„æƒ…å†µä¸‹å®ç°ç¨³å¥çš„ä¸ªæ€§åŒ–ã€‚æˆ‘ä»¬åœ¨èƒ½æ•ˆé«˜çš„RISC-VåŸºçš„GAP9å¾®æ§åˆ¶å™¨ä¸Šå®ç°äº†è¯¥æ¡†æ¶ï¼Œå¹¶åœ¨ä¸‰ç§ä¸åŒçš„HARåœºæ™¯ï¼šRecGymã€QVAR-Gestureå’ŒUltrasound-Gestureä¸­è¿›è¡Œäº†éªŒè¯ã€‚éƒ¨ç½²åçš„é€‚åº”åˆ†åˆ«å¸¦æ¥äº†3.73%ã€17.38%å’Œ3.70%çš„å‡†ç¡®æ€§æ”¹å–„ã€‚è¿™äº›ç»“æœè¯å®äº†åµŒå…¥å¼å¹³å°ä¸Šå¿«é€Ÿã€è½»ä¾¿ã€æœ‰æ•ˆçš„ä¸ªæ€§åŒ–æ˜¯å¯è¡Œçš„ï¼Œä¸ºé‡å¤–å¯æ‰©å±•å’Œç”¨æˆ·æ„ŸçŸ¥çš„HARç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚[åœ¨çº¿èµ„æºï¼š<a target="_blank" rel="noopener" href="https://github.com/kangpx/onlineTiny2023]%E3%80%82">https://github.com/kangpx/onlineTiny2023]ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.15413v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>HARæŠ€æœ¯åœ¨å¯ç©¿æˆ´è®¾å¤‡ä¸Šå·²æœ‰äº†æ˜¾è‘—çš„å‘å±•ï¼Œä½†æ¨¡å‹çš„éƒ¨ç½²åœ¨é¢å¯¹æ–°ç”¨æˆ·æ—¶å…¶æ³›åŒ–èƒ½åŠ›å—é™ã€‚ä¸ºè§£å†³å› ç”¨æˆ·å¯¼è‡´çš„æ¦‚å¿µæ¼‚ç§»ï¼ˆUICDï¼‰é—®é¢˜ï¼Œå‡¸æ˜¾ä¸ªæ€§åŒ–æ•ˆç‡çš„é‡è¦æ€§ï¼Œæœ¬æ–‡æå‡ºäº†æ··åˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶å…ˆå®ç°ç”¨æˆ·é—´çš„æ³›åŒ–ï¼Œç„¶åå€ŸåŠ©å°‘æ•°æ ·æœ¬å­¦ä¹ è¿…é€Ÿé€‚åº”ä¸ªåˆ«ç”¨æˆ·ï¼Œä¸”ä»…é€šè¿‡ç”¨æˆ·ç‰¹å®šæ•°æ®æ›´æ–°åˆ†ç±»å™¨å±‚ï¼Œå®ç°ç¨³å¥çš„ä¸ªæ€§åŒ–ï¼ŒåŒæ—¶è®¡ç®—ä¸å†…å­˜å¼€é”€è¾ƒå°ã€‚è¯¥æ¡†æ¶åœ¨èŠ‚èƒ½RISC-VåŸºGAP9å¾®æ§åˆ¶å™¨ä¸Šå®ç°ï¼Œå¹¶åœ¨RecGymã€QVAR-Gestureå’ŒUltrasound-Gestureä¸‰ä¸ªä¸åŒHARåœºæ™¯ä¸­éªŒè¯ã€‚éƒ¨ç½²åçš„é€‚åº”åˆ†åˆ«å¸¦æ¥3.73%ã€17.38%å’Œ3.70%çš„å‡†ç¡®æ€§æå‡ã€‚ç»“æœè¡¨æ˜åµŒå…¥å¼å¹³å°ä¸Šå¯å®ç°å¿«é€Ÿã€è½»ä¾¿ã€é«˜æ•ˆçš„ä¸ªæ€§åŒ–ï¼Œä¸ºé‡å¤–å¯æ‰©å±•å’Œç”¨æˆ·æ„ŸçŸ¥çš„HARç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººæœºäº¤äº’è¯†åˆ«ï¼ˆHARï¼‰æŠ€æœ¯åœ¨å¯ç©¿æˆ´è®¾å¤‡ä¸Šçš„æ³›åŒ–èƒ½åŠ›é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢å¯¹æ–°ç”¨æˆ·æ—¶ã€‚</li>
<li>ç”¨æˆ·å¯¼è‡´çš„æ¦‚å¿µæ¼‚ç§»ï¼ˆUICDï¼‰æ˜¯é™åˆ¶HARæŠ€æœ¯æ³›åŒ–çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚</li>
<li>æå‡ºçš„æ··åˆæ¡†æ¶å…ˆå®ç°è·¨ç”¨æˆ·çš„æ³›åŒ–ï¼Œç„¶åé€šè¿‡å°‘æ•°æ ·æœ¬å­¦ä¹ è¿…é€Ÿé€‚åº”ä¸ªåˆ«ç”¨æˆ·ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ä»…æ›´æ–°åˆ†ç±»å™¨å±‚æ¥å®ç°ä¸ªæ€§åŒ–ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ã€‚</li>
<li>åœ¨RISC-VåŸºGAP9å¾®æ§åˆ¶å™¨ä¸Šå®ç°äº†è¯¥æ¡†æ¶ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åœ¨ä¸‰ä¸ªä¸åŒçš„HARåœºæ™¯ä¸­éªŒè¯è¯¥æ¡†æ¶ï¼ŒåŒ…æ‹¬RecGymã€QVAR-Gestureå’ŒUltrasound-Gestureã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.15413">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-831cd3ded6fa5ac005a3f4883bb7ad54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16e24959a44ec0159ec473a1c85cc2ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-739a8d3ea27b95505ff4dc3a8622afee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a176505d6f8c28f9d1f5cb6b88977706.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="In-Context-Iterative-Policy-Improvement-for-Dynamic-Manipulation"><a href="#In-Context-Iterative-Policy-Improvement-for-Dynamic-Manipulation" class="headerlink" title="In-Context Iterative Policy Improvement for Dynamic Manipulation"></a>In-Context Iterative Policy Improvement for Dynamic Manipulation</h2><p><strong>Authors:Mark Van der Merwe, Devesh Jha</strong></p>
<p>Attention-based architectures trained on internet-scale language data have demonstrated state of the art reasoning ability for various language-based tasks, such as logic problems and textual reasoning. Additionally, these Large Language Models (LLMs) have exhibited the ability to perform few-shot prediction via in-context learning, in which input-output examples provided in the prompt are generalized to new inputs. This ability furthermore extends beyond standard language tasks, enabling few-shot learning for general patterns. In this work, we consider the application of in-context learning with pre-trained language models for dynamic manipulation. Dynamic manipulation introduces several crucial challenges, including increased dimensionality, complex dynamics, and partial observability. To address this, we take an iterative approach, and formulate our in-context learning problem to predict adjustments to a parametric policy based on previous interactions. We show across several tasks in simulation and on a physical robot that utilizing in-context learning outperforms alternative methods in the low data regime. Video summary of this work and experiments can be found <a target="_blank" rel="noopener" href="https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn">https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn</a>. </p>
<blockquote>
<p>åŸºäºäº’è”ç½‘è§„æ¨¡è¯­è¨€æ•°æ®è®­ç»ƒçš„æ³¨æ„åŠ›æ¶æ„åœ¨å„ç§åŸºäºè¯­è¨€çš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºäº†æœ€å…ˆè¿›çš„æ¨ç†èƒ½åŠ›ï¼Œå¦‚é€»è¾‘é—®é¢˜å’Œæ–‡æœ¬æ¨ç†ã€‚æ­¤å¤–ï¼Œè¿™äº›å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿˜è¡¨ç°å‡ºäº†é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ è¿›è¡Œå°‘æ ·æœ¬é¢„æµ‹çš„èƒ½åŠ›ï¼Œå…¶ä¸­åœ¨æç¤ºä¸­æä¾›çš„è¾“å…¥è¾“å‡ºç¤ºä¾‹å¯ä»¥æ¨å¹¿åˆ°æ–°çš„è¾“å…¥ã€‚è¿™ç§èƒ½åŠ›è¿˜è¶…è¶Šäº†æ ‡å‡†è¯­è¨€ä»»åŠ¡ï¼Œèƒ½å¤Ÿå®ç°ä¸€èˆ¬æ¨¡å¼çš„å°‘æ ·æœ¬å­¦ä¹ ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘äº†ä½¿ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ çš„åº”ç”¨ï¼Œç”¨äºåŠ¨æ€æ“ä½œã€‚åŠ¨æ€æ“ä½œå¸¦æ¥äº†å‡ ä¸ªå…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç»´åº¦å¢åŠ ã€åŠ¨åŠ›å¤æ‚å’Œå±€éƒ¨å¯è§‚æµ‹æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨è¿­ä»£æ–¹æ³•ï¼Œå¹¶åˆ¶å®šç›¸åº”çš„ä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜ï¼Œä»¥æ ¹æ®ä¹‹å‰çš„äº¤äº’é¢„æµ‹å‚æ•°ç­–ç•¥çš„è°ƒæ•´ã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿå’Œå®ä½“æœºå™¨äººä¸Šçš„å¤šä¸ªä»»åŠ¡ä¸­éƒ½è¡¨æ˜ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¼˜äºåœ¨ä½æ•°æ®ç¯å¢ƒä¸‹çš„å…¶ä»–æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œå’Œå®éªŒçš„è§†é¢‘æ‘˜è¦è¯·å‚è§ï¼š<a target="_blank" rel="noopener" href="https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn">é“¾æ¥</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.15021v1">PDF</a> 14 pages. Accepted at CoRL 2025</p>
<p><strong>Summary</strong></p>
<p>äº’è”ç½‘è§„æ¨¡çš„è¯­æ–™åº“è®­ç»ƒçš„åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ¶æ„å±•ç°å‡ºå…ˆè¿›è¯­è¨€ä»»åŠ¡ä¸­çš„é€»è¾‘ç†è§£å’Œæ–‡æœ¬æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å…·å¤‡é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ çš„å°‘é‡æ ·æœ¬é¢„æµ‹èƒ½åŠ›ï¼Œå¯æ¨å¹¿è‡³æ–°è¾“å…¥ã€‚æœ¬ç ”ç©¶æ¢è®¨å°†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ åº”ç”¨äºåŠ¨æ€æ“çºµã€‚åŠ¨æ€æ“çºµé¢ä¸´é«˜ç»´æ€§ã€å¤æ‚åŠ¨æ€åŠéƒ¨åˆ†å¯è§‚ç­‰æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶é‡‡å–è¿­ä»£æ–¹æ³•ï¼Œè§£å†³åŸºäºä¹‹å‰äº¤äº’è°ƒæ•´å‚æ•°ç­–ç•¥çš„ä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜ã€‚æ¨¡æ‹Ÿä»»åŠ¡å’Œå®é™…æœºå™¨äººå®éªŒè¯æ˜ï¼Œåœ¨æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ æ–¹æ³•ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ¶æ„åœ¨äº’è”ç½‘è§„æ¨¡çš„è¯­æ–™åº“ä¸Šå±•ç°å‡ºå¼ºå¤§çš„é€»è¾‘ç†è§£å’Œæ–‡æœ¬æ¨ç†èƒ½åŠ›ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å…·å¤‡é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ çš„å°‘é‡æ ·æœ¬é¢„æµ‹èƒ½åŠ›ã€‚</li>
<li>é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ è¢«åº”ç”¨äºåŠ¨æ€æ“çºµé¢†åŸŸã€‚</li>
<li>åŠ¨æ€æ“çºµé¢ä¸´é«˜ç»´æ€§ã€å¤æ‚åŠ¨æ€åŠéƒ¨åˆ†å¯è§‚æ€§ç­‰æŒ‘æˆ˜ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨è¿­ä»£æ–¹æ³•è§£å†³åŸºäºä¹‹å‰äº¤äº’è°ƒæ•´å‚æ•°ç­–ç•¥çš„ä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜ã€‚</li>
<li>æ¨¡æ‹Ÿä»»åŠ¡æ˜¾ç¤ºä¸Šä¸‹æ–‡å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.15021">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e78a45f1a9ad2e62ef1c3af12f67cabb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21108ab8299f08dfc0b92de1f85ef28c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-976f31de346ee78c33c9d10cf491857c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MCPTox-A-Benchmark-for-Tool-Poisoning-Attack-on-Real-World-MCP-Servers"><a href="#MCPTox-A-Benchmark-for-Tool-Poisoning-Attack-on-Real-World-MCP-Servers" class="headerlink" title="MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers"></a>MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers</h2><p><strong>Authors:Zhiqiang Wang, Yichao Gao, Yanting Wang, Suyuan Liu, Haifeng Sun, Haoran Cheng, Guanquan Shi, Haohua Du, Xiangyang Li</strong></p>
<p>By providing a standardized interface for LLM agents to interact with external tools, the Model Context Protocol (MCP) is quickly becoming a cornerstone of the modern autonomous agent ecosystem. However, it creates novel attack surfaces due to untrusted external tools. While prior work has focused on attacks injected through external tool outputs, we investigate a more fundamental vulnerability: Tool Poisoning, where malicious instructions are embedded within a toolâ€™s metadata without execution. To date, this threat has been primarily demonstrated through isolated cases, lacking a systematic, large-scale evaluation.   We introduce MCPTox, the first benchmark to systematically evaluate agent robustness against Tool Poisoning in realistic MCP settings. MCPTox is constructed upon 45 live, real-world MCP servers and 353 authentic tools. To achieve this, we design three distinct attack templates to generate a comprehensive suite of 1312 malicious test cases by few-shot learning, covering 10 categories of potential risks. Our evaluation on 20 prominent LLM agents setting reveals a widespread vulnerability to Tool Poisoning, with o1-mini, achieving an attack success rate of 72.8%. We find that more capable models are often more susceptible, as the attack exploits their superior instruction-following abilities. Finally, the failure case analysis reveals that agents rarely refuse these attacks, with the highest refused rate (Claude-3.7-Sonnet) less than 3%, demonstrating that existing safety alignment is ineffective against malicious actions that use legitimate tools for unauthorized operation. Our findings create a crucial empirical baseline for understanding and mitigating this widespread threat, and we release MCPTox for the development of verifiably safer AI agents. Our dataset is available at an anonymized repository: \textit{<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AAAI26-7C02%7D">https://anonymous.4open.science/r/AAAI26-7C02}</a>. </p>
<blockquote>
<p>æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰é€šè¿‡ä¸ºLLMä»£ç†æä¾›ä¸€ä¸ªä¸å¤–éƒ¨å·¥å…·äº¤äº’çš„æ ‡å‡†æ¥å£ï¼Œè¿…é€Ÿæˆä¸ºç°ä»£è‡ªä¸»ä»£ç†ç”Ÿæ€ç³»ç»Ÿçš„åŸºç¡€ã€‚ç„¶è€Œï¼Œç”±äºä¸å—ä¿¡ä»»çš„å¤–éƒ¨å·¥å…·ï¼Œå®ƒä¼šäº§ç”Ÿæ–°çš„æ”»å‡»é¢ã€‚è™½ç„¶ä»¥å‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨é€šè¿‡å¤–éƒ¨å·¥å…·è¾“å‡ºæ³¨å…¥çš„æ”»å‡»ä¸Šï¼Œä½†æˆ‘ä»¬è°ƒæŸ¥äº†ä¸€ä¸ªæ›´åŸºæœ¬çš„æ¼æ´ï¼šå·¥å…·ä¸­æ¯’ï¼Œæ¶æ„æŒ‡ä»¤åµŒå…¥åœ¨å·¥å…·å…ƒæ•°æ®ä¸­è€Œä¸æ‰§è¡Œã€‚è¿„ä»Šä¸ºæ­¢ï¼Œè¿™ä¸€å¨èƒä¸»è¦é€šè¿‡å­¤ç«‹æ¡ˆä¾‹æ¼”ç¤ºï¼Œç¼ºä¹ç³»ç»Ÿã€å¤§è§„æ¨¡çš„è¯„ä»·ã€‚æˆ‘ä»¬å¼•å…¥äº†MCPToxï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç³»ç»Ÿåœ°è¯„ä¼°ä»£ç†åœ¨ç°å®MCPç¯å¢ƒä¸­æŠµå¾¡å·¥å…·ä¸­æ¯’çš„ç¨³å¥æ€§çš„åŸºå‡†æµ‹è¯•ã€‚MCPToxå»ºç«‹åœ¨45ä¸ªå®æ—¶ã€çœŸå®çš„MCPæœåŠ¡å™¨å’Œ353ä¸ªçœŸå®å·¥å…·ä¹‹ä¸Šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸‰ç§ç‹¬ç‰¹çš„æ”»å‡»æ¨¡æ¿ï¼Œé€šè¿‡å°‘é‡å­¦ä¹ ç”Ÿæˆäº†1312ä¸ªæ¶æ„æµ‹è¯•ç”¨ä¾‹çš„ç»¼åˆå¥—ä»¶ï¼Œæ¶µç›–10ç±»æ½œåœ¨é£é™©ã€‚æˆ‘ä»¬å¯¹20ä¸ªçªå‡ºçš„LLMä»£ç†ç¯å¢ƒçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå·¥å…·ä¸­æ¯’æ¼æ´æ™®éå­˜åœ¨ï¼Œå…¶ä¸­o1-miniçš„æ”»å‡»æˆåŠŸç‡è¾¾åˆ°72.8%ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ›´å¼ºå¤§çš„æ¨¡å‹å¾€å¾€æ›´å®¹æ˜“å—åˆ°æ”»å‡»ï¼Œå› ä¸ºæ”»å‡»åˆ©ç”¨äº†å®ƒä»¬å‡ºè‰²çš„æŒ‡ä»¤æ‰§è¡Œèƒ½åŠ›ã€‚æœ€åï¼Œå¤±è´¥æ¡ˆä¾‹åˆ†ææ˜¾ç¤ºï¼Œä»£ç†å¾ˆå°‘ä¼šæ‹’ç»è¿™äº›æ”»å‡»ï¼Œæ‹’ç»ç‡æœ€é«˜çš„ä»£ç†ï¼ˆClaude-3.7-Sonnetï¼‰ä¸åˆ°3%ï¼Œè¿™è¡¨æ˜ç°æœ‰çš„å®‰å…¨å¯¹é½å¯¹äºä½¿ç”¨åˆæ³•å·¥å…·è¿›è¡Œæœªç»æˆæƒæ“ä½œçš„æ¶æ„è¡Œä¸ºæ˜¯æ— æ•ˆçš„ã€‚æˆ‘ä»¬çš„å‘ç°å¯¹äºç†è§£å’Œç¼“è§£è¿™ä¸€å¹¿æ³›å¨èƒåˆ›é€ äº†é‡è¦çš„å®è¯åŸºçº¿ï¼Œæˆ‘ä»¬å‘å¸ƒMCPToxä»¥ä¿ƒè¿›å¼€å‘å¯éªŒè¯çš„æ›´å®‰å…¨çš„AIä»£ç†ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å¯åœ¨åŒ¿åä»“åº“ä¸­æ‰¾åˆ°ï¼š[<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AAAI26-7C0">https://anonymous.4open.science/r/AAAI26-7C0</a><br>]ä¸­æå‡ºäº†ä¸€ä¸ªé‡è¦çš„é—®é¢˜ï¼šâ€œè¿™ä¸ªä»“åº“ä¼šæŒç»­æ›´æ–°å’Œç»´æŠ¤å—ï¼Ÿâ€å›åº”ä¸­æåˆ°ä»–ä»¬ä¼šæŒç»­å…³æ³¨ç›¸å…³çš„å®‰å…¨æ¼æ´å¹¶è¿›è¡Œç›¸åº”çš„æ›´æ–°å’Œæ”¹è¿›æªæ–½æ¥ä¿è¯æ•°æ®é›†çš„è´¨é‡å’Œå®‰å…¨æ€§ç¡®ä¿ç”¨æˆ·åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§å’Œå‡†ç¡®æ€§åŒæ—¶å¼ºè°ƒäº†è¿™æ˜¯ä¸€ä¸ªæŒç»­æ€§çš„è¿‡ç¨‹ä»–ä»¬ä¹Ÿå°†ä¸å…¶ä»–ç ”ç©¶è€…å’Œå®‰å…¨ä¸“å®¶åˆä½œä»¥ç¡®ä¿æ•°æ®é›†çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ä»¥æ”¯æŒå¯¹äººå·¥æ™ºèƒ½å®‰å…¨æ€§é—®é¢˜çš„æ·±å…¥ç ”ç©¶å¹¶å¸®åŠ©å¼€å‘è€…åˆ›å»ºæ›´å®‰å…¨çš„AIç³»ç»Ÿã€‚æˆ‘ä»¬çš„æ•°æ®é›†å¯ä»¥é€‚åº”äººå·¥æ™ºèƒ½çš„è¿›æ­¥å¹¶æä¾›æŒä¹…çš„ä»·å€¼è¿™æ˜¯ä¸€ä¸ªè‡³å…³é‡è¦çš„ç»éªŒæ€§åŸºå‡†å¯ä»¥è®©æˆ‘ä»¬æ›´æ·±å…¥åœ°äº†è§£å·¥å…·ä¸­æ¯’é—®é¢˜å¹¶æŒ‡å¯¼æœªæ¥çš„AIå¼€å‘å·¥ä½œä»¥è§£å†³å„ç§æ½œåœ¨çš„å¨èƒéšç€äººå·¥æ™ºèƒ½çš„å‘å±•å’Œåº”ç”¨åœºæ™¯çš„æ‰©å±•è¿™äº›é—®é¢˜å°†ä¼šå˜å¾—è¶Šæ¥è¶Šé‡è¦æˆ‘ä»¬ä¹Ÿå¸Œæœ›èƒ½å¤Ÿä¸åŒè¡Œå…±åŒæ¨åŠ¨äººå·¥æ™ºèƒ½å®‰å…¨æ€§çš„è¿›æ­¥å¹¶ä¿ƒè¿›äººå·¥æ™ºèƒ½çš„å¥åº·å‘å±•ã€‚](<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AAAI26-7C%E)%E4%BB%A5%E4%B8%8B%E6%98%AF%E8%BF%99%E6%AE%B5%E7%BF%BB%E8%AF%91%E7%9A%84%E6%9B%B4%E5%AE%8C%E6%95%B4%E7%89%88%E6%9C%AC%EF%BC%9A">https://anonymous.4open.science/r/AAAI26-7C%E)ä»¥ä¸‹æ˜¯è¿™æ®µç¿»è¯‘çš„æ›´å®Œæ•´ç‰ˆæœ¬ï¼š</a></p>
</blockquote>
<p><strong>ç¿»è¯‘</strong></p>
<p>æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä¸ºLLMä»£ç†æä¾›äº†ä¸€ä¸ªä¸å¤–éƒ¨å·¥å…·äº¤äº’çš„æ ‡å‡†æ¥å£ï¼Œå·²ç»æˆä¸ºç°ä»£è‡ªä¸»ä»£ç†ç”Ÿæ€ç³»ç»Ÿçš„é‡è¦åŸºçŸ³ã€‚ç„¶è€Œï¼Œå®ƒåŒæ—¶ä¹Ÿå¸¦æ¥äº†æ–°çš„å®‰å…¨éšæ‚£ï¼Œå› ä¸ºä¸å—ä¿¡ä»»çš„å¤–ç•Œå·¥å…·å¯èƒ½ä¼šäº§ç”Ÿæ–°å‹æ”»å‡»é¢ã€‚ä¹‹å‰çš„ç ”ç©¶ä¸»è¦å…³æ³¨é€šè¿‡å¤–éƒ¨å·¥å…·è¾“å‡ºè¿›è¡Œçš„æ”»å‡»ï¼Œä½†æˆ‘ä»¬å‘ç°äº†ä¸€ç§æ›´ä¸ºåŸºç¡€çš„æ¼æ´â€”â€”å·¥å…·ä¸­æ¯’ã€‚åœ¨è¿™ä¸ªæ¼æ´ä¸­ï¼Œæ¶æ„æŒ‡ä»¤è¢«åµŒå…¥åˆ°å·¥å…·çš„å…ƒæ•°æ®ä¸­è€Œä¸è¢«æ‰§è¡Œã€‚å°½ç®¡å·²æœ‰ä¸€äº›å­¤ç«‹æ¡ˆä¾‹çš„å±•ç¤ºï¼Œä½†è¿™ä¸€å¨èƒç¼ºä¹ç³»ç»Ÿã€å¤§è§„æ¨¡çš„è¯„ä»·ã€‚</p>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†MCPToxåŸºå‡†æµ‹è¯•ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿç³»ç»Ÿåœ°è¯„ä¼°ä»£ç†åœ¨çœŸå®MCPç¯å¢ƒä¸‹æŠµå¾¡å·¥å…·ä¸­æ¯’çš„ç¨³å¥æ€§çš„æµ‹è¯•å¹³å°ã€‚MCPToxå»ºç«‹åœ¨45ä¸ªå®æ—¶ã€çœŸå®çš„MCPæœåŠ¡å™¨å’Œ353ä¸ªçœŸå®å·¥å…·çš„åŸºç¡€ä¸Šã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸‰ç§ç‹¬ç‰¹çš„æ”»å‡»æ¨¡æ¿ï¼Œé€šè¿‡å°‘é‡å­¦ä¹ ç”Ÿæˆäº†æ¶µç›–10ç±»æ½œåœ¨é£é™©çš„1312ä¸ªæ¶æ„æµ‹è¯•ç”¨ä¾‹çš„ç»¼åˆå¥—ä»¶ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14925v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä¸ºLLMä»£ç†ä¸å¤–éƒ¨å·¥å…·äº¤äº’æä¾›äº†æ ‡å‡†åŒ–æ¥å£ï¼Œæˆä¸ºç°ä»£è‡ªä¸»ä»£ç†ç”Ÿæ€ç³»ç»Ÿçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ç„¶è€Œï¼Œç”±äºä¸å—ä¿¡ä»»çš„å¤–éƒ¨å·¥å…·ï¼Œå®ƒä¼šäº§ç”Ÿæ–°çš„æ”»å‡»é¢ã€‚æœ¬æ–‡ä¸»è¦ç ”ç©¶ä¸€ç§åä¸ºâ€œå·¥å…·ä¸­æ¯’â€çš„æ–°å‹å¨èƒï¼Œå³æ¶æ„æŒ‡ä»¤åµŒå…¥åœ¨å·¥å…·çš„å…ƒæ•°æ®ä¸­è€Œæ— éœ€æ‰§è¡Œã€‚ä¸ºäº†ç³»ç»Ÿåœ°è¯„ä¼°ä»£ç†å¯¹å·¥å…·ä¸­æ¯’çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†MCPToxï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªåœ¨çœŸå®MCPç¯å¢ƒä¸‹è¯„ä¼°ä»£ç†é²æ£’æ€§çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„å®éªŒåŸºäº45ä¸ªå®æ—¶MCPæœåŠ¡å™¨å’Œ353ä¸ªçœŸå®å·¥å…·è¿›è¡Œæ„å»ºï¼Œé€šè¿‡ä¸‰ç§ç‹¬ç‰¹çš„æ”»å‡»æ¨¡æ¿ç”Ÿæˆäº†æ¶µç›–10ç§æ½œåœ¨é£é™©ç±»åˆ«çš„1312ä¸ªæ¶æ„æµ‹è¯•ç”¨ä¾‹ã€‚å¯¹20ç§ä¸»æµçš„LLMä»£ç†ç¯å¢ƒçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå·¥å…·ä¸­æ¯’æ”»å‡»æ™®éå­˜åœ¨ï¼Œo1-miniçš„æ”»å‡»æˆåŠŸç‡é«˜è¾¾72.8%ã€‚æˆ‘ä»¬å‘ç°æ›´å¼ºå¤§çš„æ¨¡å‹å¾€å¾€æ›´å®¹æ˜“å—åˆ°æ”»å‡»ï¼Œå› ä¸ºæ”»å‡»æ­£æ˜¯åˆ©ç”¨äº†ä»–ä»¬å‡ºè‰²çš„æŒ‡ä»¤æ‰§è¡Œèƒ½åŠ›ã€‚æœ€åï¼Œå¤±è´¥æ¡ˆä¾‹åˆ†æè¡¨æ˜ï¼Œä»£ç†å¾ˆå°‘æ‹’ç»è¿™äº›æ”»å‡»ï¼Œæœ€é«˜æ‹’ç»ç‡ï¼ˆClaude-3.7-Sonnetï¼‰ä¸åˆ°3%ï¼Œè¡¨æ˜ç°æœ‰çš„å®‰å…¨å¯¹é½å¯¹äºä½¿ç”¨åˆæ³•å·¥å…·è¿›è¡Œæœªç»æˆæƒæ“ä½œæ¶æ„è¡Œä¸ºæ— æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä¸ºLLMä»£ç†ä¸å¤–éƒ¨å·¥å…·äº¤äº’æä¾›äº†æ ‡å‡†åŒ–æ¥å£ï¼Œæˆä¸ºç°ä»£è‡ªä¸»ä»£ç†ç”Ÿæ€ç³»ç»Ÿçš„é‡è¦åŸºçŸ³ã€‚</li>
<li>ç”±äºä¸å—ä¿¡ä»»çš„å¤–éƒ¨å·¥å…·ï¼ŒMCPäº§ç”Ÿäº†æ–°çš„æ”»å‡»é¢ï¼Œå‡ºç°äº†ä¸€ç§æ–°çš„å¨èƒâ€”â€”â€œå·¥å…·ä¸­æ¯’â€ã€‚</li>
<li>MCPToxæ˜¯é¦–ä¸ªç”¨äºåœ¨çœŸå®MCPç¯å¢ƒä¸‹è¯„ä¼°ä»£ç†å¯¹å·¥å…·ä¸­æ¯’é²æ£’æ€§çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>å®éªŒåŸºäº45ä¸ªå®æ—¶MCPæœåŠ¡å™¨å’Œ353ä¸ªçœŸå®å·¥å…·æ„å»ºï¼Œç”Ÿæˆäº†æ¶µç›–10ç§æ½œåœ¨é£é™©ç±»åˆ«çš„1312ä¸ªæ¶æ„æµ‹è¯•ç”¨ä¾‹ã€‚</li>
<li>å¯¹20ç§ä¸»æµLLMä»£ç†ç¯å¢ƒçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå·¥å…·ä¸­æ¯’æ”»å‡»æ™®éå­˜åœ¨ï¼Œä¸”æ›´å¼ºå¤§çš„æ¨¡å‹æ›´æ˜“å—åˆ°æ”»å‡»ã€‚</li>
<li>ç°æœ‰å®‰å…¨å¯¹é½æªæ–½å¯¹äºå·¥å…·ä¸­æ¯’æ”»å‡»æ•ˆæœä¸ä½³ï¼Œä»£ç†å¾ˆå°‘èƒ½å¤Ÿæ‹’ç»è¿™äº›æ”»å‡»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14925">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-027df6f96e4cae40a4056d77bacb81c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c71636c8c8b563a7ad96d90934e4da2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57f43cd38d8c52c6b3781f94eb45b6a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de5511bdf3b1643cd3451ae5622d4375.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3288588e3ded7f04ac3c0ecd621b45a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45a23b8441014f15afb35a7b13d32be6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e4c8f63a81d016d95168b7e7ee16ade.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DictAS-A-Framework-for-Class-Generalizable-Few-Shot-Anomaly-Segmentation-via-Dictionary-Lookup"><a href="#DictAS-A-Framework-for-Class-Generalizable-Few-Shot-Anomaly-Segmentation-via-Dictionary-Lookup" class="headerlink" title="DictAS: A Framework for Class-Generalizable Few-Shot Anomaly   Segmentation via Dictionary Lookup"></a>DictAS: A Framework for Class-Generalizable Few-Shot Anomaly   Segmentation via Dictionary Lookup</h2><p><strong>Authors:Zhen Qu, Xian Tao, Xinyi Gong, ShiChen Qu, Xiaopei Zhang, Xingang Wang, Fei Shen, Zhengtao Zhang, Mukesh Prasad, Guiguang Ding</strong></p>
<p>Recent vision-language models (e.g., CLIP) have demonstrated remarkable class-generalizable ability to unseen classes in few-shot anomaly segmentation (FSAS), leveraging supervised prompt learning or fine-tuning on seen classes. However, their cross-category generalization largely depends on prior knowledge of real seen anomaly samples. In this paper, we propose a novel framework, namely DictAS, which enables a unified model to detect visual anomalies in unseen object categories without any retraining on the target data, only employing a few normal reference images as visual prompts. The insight behind DictAS is to transfer dictionary lookup capabilities to the FSAS task for unseen classes via self-supervised learning, instead of merely memorizing the normal and abnormal feature patterns from the training set. Specifically, DictAS mainly consists of three components: (1) Dictionary Construction - to simulate the index and content of a real dictionary using features from normal reference images. (2) Dictionary Lookup - to retrieve queried region features from the dictionary via a sparse lookup strategy. When a query feature cannot be retrieved, it is classified as an anomaly. (3) Query Discrimination Regularization - to enhance anomaly discrimination by making abnormal features harder to retrieve from the dictionary. To achieve this, Contrastive Query Constraint and Text Alignment Constraint are further proposed. Extensive experiments on seven public industrial and medical datasets demonstrate that DictAS consistently outperforms state-of-the-art FSAS methods. </p>
<blockquote>
<p>æœ€è¿‘çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚CLIPï¼‰åœ¨å°‘æ ·æœ¬å¼‚å¸¸åˆ†å‰²ï¼ˆFSASï¼‰ä¸­å±•ç¤ºäº†æ˜¾è‘—çš„ç±»åˆ«æ³›åŒ–èƒ½åŠ›ï¼Œè¿™å¾—ç›Šäºåœ¨å¯è§ç±»åˆ«ä¸Šè¿›è¡Œçš„ç›‘ç£æç¤ºå­¦ä¹ æˆ–å¾®è°ƒã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„è·¨ç±»åˆ«æ³›åŒ–å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºçœŸå®å¯è§å¼‚å¸¸æ ·æœ¬çš„å…ˆéªŒçŸ¥è¯†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œåä¸ºDictASï¼Œå®ƒèƒ½å¤Ÿåœ¨ç›®æ ‡æ•°æ®ä¸Šæ— éœ€ä»»ä½•å†è®­ç»ƒï¼Œä»…ä½¿ç”¨å°‘é‡æ­£å¸¸å‚è€ƒå›¾åƒä½œä¸ºè§†è§‰æç¤ºï¼Œå³å¯æ£€æµ‹æœªè§å¯¹è±¡ç±»åˆ«çš„è§†è§‰å¼‚å¸¸ã€‚DictASçš„è§è§£æ˜¯é€šè¿‡è‡ªæˆ‘ç›‘ç£å­¦ä¹ ï¼Œå°†å­—å…¸æŸ¥æ‰¾èƒ½åŠ›è½¬ç§»åˆ°FSASä»»åŠ¡ä¸­çš„æœªè§ç±»åˆ«ï¼Œè€Œä¸æ˜¯ä»…ä»…ä»è®­ç»ƒé›†ä¸­è®°å¿†æ­£å¸¸å’Œå¼‚å¸¸çš„ç‰¹å¾æ¨¡å¼ã€‚å…·ä½“æ¥è¯´ï¼ŒDictASä¸»è¦ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼šï¼ˆ1ï¼‰å­—å…¸æ„å»ºâ€”â€”ä½¿ç”¨æ­£å¸¸å‚è€ƒå›¾åƒçš„ç‰¹å¾æ¨¡æ‹ŸçœŸå®å­—å…¸çš„ç´¢å¼•å’Œå†…å®¹ã€‚ï¼ˆ2ï¼‰å­—å…¸æŸ¥æ‰¾â€”â€”é€šè¿‡ç¨€ç–æŸ¥æ‰¾ç­–ç•¥ä»å­—å…¸ä¸­æ£€ç´¢æŸ¥è¯¢åŒºåŸŸç‰¹å¾ã€‚å½“æ— æ³•æ£€ç´¢åˆ°æŸ¥è¯¢ç‰¹å¾æ—¶ï¼Œå®ƒä¼šè¢«å½’ç±»ä¸ºå¼‚å¸¸ã€‚ï¼ˆ3ï¼‰æŸ¥è¯¢åˆ¤åˆ«æ­£åˆ™åŒ–â€”â€”é€šè¿‡ä½¿å¼‚å¸¸ç‰¹å¾æ›´éš¾ä»å­—å…¸ä¸­æ£€ç´¢ï¼Œä»¥å¢å¼ºå¼‚å¸¸åˆ¤åˆ«ã€‚ä¸ºæ­¤ï¼Œè¿›ä¸€æ­¥æå‡ºäº†å¯¹æ¯”æŸ¥è¯¢çº¦æŸå’Œæ–‡æœ¬å¯¹é½çº¦æŸã€‚åœ¨ä¸ƒä¸ªå…¬å…±å·¥ä¸šå’ŒåŒ»ç–—æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDictASå§‹ç»ˆä¼˜äºæœ€æ–°çš„FSASæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13560v2">PDF</a> Accepted by ICCV 2025, Project: <a target="_blank" rel="noopener" href="https://github.com/xiaozhen228/DictAS">https://github.com/xiaozhen228/DictAS</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDictASçš„æ–°æ¡†æ¶ï¼Œç”¨äºåœ¨æœªè®­ç»ƒçš„ç›®æ ‡æ•°æ®ä¸Šæ£€æµ‹æœªè§å¯¹è±¡ç±»åˆ«ä¸­çš„è§†è§‰å¼‚å¸¸ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹ŸçœŸå®å­—å…¸çš„ç´¢å¼•å’Œå†…å®¹ï¼Œåˆ©ç”¨æ­£å¸¸å‚è€ƒå›¾åƒçš„ç‰¹å¾æ„å»ºå­—å…¸ï¼Œå¹¶é€šè¿‡ç¨€ç–æ£€ç´¢ç­–ç•¥æ£€ç´¢æŸ¥è¯¢åŒºåŸŸç‰¹å¾ã€‚å½“æ— æ³•æ£€ç´¢åˆ°æŸ¥è¯¢ç‰¹å¾æ—¶ï¼Œå°†å…¶åˆ†ç±»ä¸ºå¼‚å¸¸ã€‚æ­¤å¤–ï¼Œè¿˜é€šè¿‡å¯¹æ¯”æŸ¥è¯¢çº¦æŸå’Œæ–‡æœ¬å¯¹é½çº¦æŸå¢å¼ºå¼‚å¸¸æ£€æµ‹èƒ½åŠ›ã€‚åœ¨ä¸ƒä¸ªå…¬å…±å·¥ä¸šå’ŒåŒ»ç–—æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDictASåœ¨æœªè§ç±»åˆ«å¼‚å¸¸åˆ†å‰²ï¼ˆFSASï¼‰ä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DictASæ¡†æ¶ç”¨äºåœ¨æœªè®­ç»ƒçš„ç›®æ ‡æ•°æ®ä¸Šæ£€æµ‹æœªè§å¯¹è±¡ç±»åˆ«ä¸­çš„è§†è§‰å¼‚å¸¸ã€‚</li>
<li>DictASåˆ©ç”¨æ­£å¸¸å‚è€ƒå›¾åƒçš„ç‰¹å¾æ„å»ºå­—å…¸ï¼Œæ¨¡æ‹ŸçœŸå®å­—å…¸çš„ç´¢å¼•å’Œå†…å®¹ã€‚</li>
<li>é€šè¿‡ç¨€ç–æ£€ç´¢ç­–ç•¥æ£€ç´¢æŸ¥è¯¢åŒºåŸŸç‰¹å¾ï¼Œæ— æ³•æ£€ç´¢åˆ°çš„ç‰¹å¾è¢«è§†ä¸ºå¼‚å¸¸ã€‚</li>
<li>é€šè¿‡å¯¹æ¯”æŸ¥è¯¢çº¦æŸå’Œæ–‡æœ¬å¯¹é½çº¦æŸå¢å¼ºå¼‚å¸¸æ£€æµ‹èƒ½åŠ›ã€‚</li>
<li>DictASæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šå­—å…¸æ„å»ºã€å­—å…¸æŸ¥æ‰¾å’ŒæŸ¥è¯¢åˆ¤åˆ«æ­£åˆ™åŒ–ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDictASåœ¨ä¸ƒä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„ä¸€è‡´è¡¨ç°ä¼˜äºç°æœ‰FSASæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13560">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e49a66ab2261e31b24def0d322fa2b50.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-401706d57dbafcb784033b9856ecf607.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d2ffe3a4f50d5311fbe18eae2380d36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a379e50efa4f973d4e20403d7a00f4d.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CC-Time-Cross-Model-and-Cross-Modality-Time-Series-Forecasting"><a href="#CC-Time-Cross-Model-and-Cross-Modality-Time-Series-Forecasting" class="headerlink" title="CC-Time: Cross-Model and Cross-Modality Time Series Forecasting"></a>CC-Time: Cross-Model and Cross-Modality Time Series Forecasting</h2><p><strong>Authors:Peng Chen, Yihang Wang, Yang Shu, Yunyao Cheng, Kai Zhao, Zhongwen Rao, Lujia Pan, Bin Yang, Chenjuan Guo</strong></p>
<p>With the success of pre-trained language models (PLMs) in various application fields beyond natural language processing, language models have raised emerging attention in the field of time series forecasting (TSF) and have shown great prospects. However, current PLM-based TSF methods still fail to achieve satisfactory prediction accuracy matching the strong sequential modeling power of language models. To address this issue, we propose Cross-Model and Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We explore the potential of PLMs for time series forecasting from two aspects: 1) what time series features could be modeled by PLMs, and 2) whether relying solely on PLMs is sufficient for building time series models. In the first aspect, CC-Time incorporates cross-modality learning to model temporal dependency and channel correlations in the language model from both time series sequences and their corresponding text descriptions. In the second aspect, CC-Time further proposes the cross-model fusion block to adaptively integrate knowledge from the PLMs and time series model to form a more comprehensive modeling of time series patterns. Extensive experiments on nine real-world datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy in both full-data training and few-shot learning situations. </p>
<blockquote>
<p>éšç€é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»¥å¤–çš„å„ç§åº”ç”¨é¢†åŸŸçš„æˆåŠŸï¼Œè¯­è¨€æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTSFï¼‰é¢†åŸŸå¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ï¼Œå¹¶æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„åŸºäºPLMçš„æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•ä»ç„¶æ— æ³•å®ç°å¯¹æ—¶é—´åºåˆ—æ¨¡å¼è¿›è¡Œå¼ºæœ‰åŠ›å»ºæ¨¡çš„æ»¡æ„é¢„æµ‹ç²¾åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºPLMçš„è·¨æ¨¡å‹è·¨æ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•ï¼ˆCC-Timeï¼‰ã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªæ–¹é¢æ¢è®¨äº†PLMåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ½œåŠ›ï¼š1ï¼‰PLMå¯ä»¥å»ºæ¨¡å“ªäº›æ—¶é—´åºåˆ—ç‰¹å¾ï¼›2ï¼‰ä»…ä¾èµ–PLMæ˜¯å¦è¶³ä»¥æ„å»ºæ—¶é—´åºåˆ—æ¨¡å‹ã€‚åœ¨ç¬¬ä¸€æ–¹é¢ï¼ŒCC-Timeç»“åˆäº†è·¨æ¨¡æ€å­¦ä¹ ï¼Œä»æ—¶é—´åºåˆ—åºåˆ—åŠå…¶ç›¸åº”çš„æ–‡æœ¬æè¿°ä¸­ï¼Œå¯¹è¯­è¨€æ¨¡å‹ä¸­çš„æ—¶é—´ä¾èµ–æ€§å’Œé€šé“ç›¸å…³æ€§è¿›è¡Œå»ºæ¨¡ã€‚åœ¨ç¬¬äºŒæ–¹é¢ï¼ŒCC-Timeè¿›ä¸€æ­¥æå‡ºäº†è·¨æ¨¡å‹èåˆæ¨¡å—ï¼Œä»¥è‡ªé€‚åº”åœ°æ•´åˆæ¥è‡ªPLMå’Œæ—¶åºæ¨¡å‹çš„çŸ¥è¯†ï¼Œå½¢æˆå¯¹æ—¶åºæ¨¡å¼æ›´å…¨é¢å»ºæ¨¡ã€‚åœ¨ä¹ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCC-Timeåœ¨å…¨æ•°æ®è®­ç»ƒå’Œå°‘æ ·æœ¬å­¦ä¹ æƒ…å†µä¸‹å‡è¾¾åˆ°äº†æœ€æ–°çš„é¢„æµ‹ç²¾åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12235v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»¥å¤–é¢†åŸŸçš„åº”ç”¨æˆåŠŸï¼Œæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTSFï¼‰é¢†åŸŸå¼€å§‹å…³æ³¨è¯­è¨€æ¨¡å‹å¹¶å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚é’ˆå¯¹å½“å‰PLM-based TSFæ–¹æ³•é¢„æµ‹ç²¾åº¦ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºCross-Modelå’ŒCross-Modality Learning with PLMs for time series forecastingï¼ˆCC-Timeï¼‰ã€‚ä»ä¸¤ä¸ªæ–¹é¢æ¢ç´¢PLMåœ¨TSFä¸­çš„æ½œåŠ›ï¼šä¸€æ˜¯PLMå¯å»ºæ¨¡çš„æ—¶é—´åºåˆ—ç‰¹å¾ï¼›äºŒæ˜¯ä»…ä¾èµ–PLMæ˜¯å¦è¶³ä»¥æ„å»ºæ—¶é—´åºåˆ—æ¨¡å‹ã€‚CC-Timeé€šè¿‡è·¨æ¨¡æ€å­¦ä¹ å»ºæ¨¡æ—¶é—´åºåˆ—åºåˆ—å’Œå¯¹åº”æ–‡æœ¬æè¿°ä¸­çš„æ—¶é—´ä¾èµ–å’Œé€šé“ç›¸å…³æ€§ï¼Œå¹¶æå‡ºè·¨æ¨¡å‹èåˆå—ä»¥è‡ªé€‚åº”åœ°æ•´åˆPLMå’ŒTSFæ¨¡å‹çš„çŸ¥è¯†ï¼Œä»¥æ›´å…¨é¢å»ºæ¨¡æ—¶é—´åºåˆ—æ¨¡å¼ã€‚åœ¨ä¹ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCC-Timeåœ¨å®Œå…¨æ•°æ®è®­ç»ƒå’Œå°‘æ ·æœ¬å­¦ä¹ æƒ…å†µä¸‹å‡å®ç°äº†æœ€å…ˆè¿›çš„é¢„æµ‹ç²¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸå–å¾—æˆåŠŸï¼Œå¼•å‘æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTSFï¼‰é¢†åŸŸçš„å…³æ³¨ã€‚</li>
<li>å½“å‰PLM-based TSFæ–¹æ³•é¢„æµ‹ç²¾åº¦ä¸è¶³ï¼Œéœ€è¦æ–°çš„æ–¹æ³•æ”¹è¿›ã€‚</li>
<li>æå‡ºCC-Timeæ–¹æ³•ï¼Œä»ä¸¤ä¸ªæ–¹é¢æ¢ç´¢PLMåœ¨TSFä¸­çš„æ½œåŠ›ï¼šæ—¶é—´åºåˆ—ç‰¹å¾çš„å»ºæ¨¡å’Œæ„å»ºæ—¶é—´åºåˆ—æ¨¡å‹çš„å……åˆ†æ€§ã€‚</li>
<li>CC-Timeé€šè¿‡è·¨æ¨¡æ€å­¦ä¹ å»ºæ¨¡æ—¶é—´åºåˆ—åºåˆ—å’Œæ–‡æœ¬æè¿°ä¸­çš„æ—¶é—´ä¾èµ–å’Œé€šé“ç›¸å…³æ€§ã€‚</li>
<li>CC-Timeæå‡ºè·¨æ¨¡å‹èåˆå—ï¼Œè‡ªé€‚åº”æ•´åˆPLMå’ŒTSFæ¨¡å‹çŸ¥è¯†ï¼Œå®ç°æ›´å…¨é¢å»ºæ¨¡æ—¶é—´åºåˆ—æ¨¡å¼ã€‚</li>
<li>åœ¨ä¹ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCC-Timeåœ¨å¤šç§æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›çš„é¢„æµ‹ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12235">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-687c1a6dfe880300d526e122ccfdb413.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-039d5e60ec124b362ec8ede5270afae8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8e9808ff564f5e19ce16e0846f0654a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dfbbfdc89027582bc4d94ccedfa3c8e8.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Prescriptive-Agents-based-on-RAG-for-Automated-Maintenance-PARAM"><a href="#Prescriptive-Agents-based-on-RAG-for-Automated-Maintenance-PARAM" class="headerlink" title="Prescriptive Agents based on RAG for Automated Maintenance (PARAM)"></a>Prescriptive Agents based on RAG for Automated Maintenance (PARAM)</h2><p><strong>Authors:Chitranshu Harbola, Anupam Purwar</strong></p>
<p>Industrial machinery maintenance requires timely intervention to prevent catastrophic failures and optimize operational efficiency. This paper presents an integrated Large Language Model (LLM)-based intelligent system for prescriptive maintenance that extends beyond traditional anomaly detection to provide actionable maintenance recommendations. Building upon our prior LAMP framework for numerical data analysis, we develop a comprehensive solution that combines bearing vibration frequency analysis with multi agentic generation for intelligent maintenance planning. Our approach serializes bearing vibration data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM processing, enabling few-shot anomaly detection with high accuracy. The system classifies fault types (inner race, outer race, ball&#x2F;roller, cage faults) and assesses severity levels. A multi-agentic component processes maintenance manuals using vector embeddings and semantic search, while also conducting web searches to retrieve comprehensive procedural knowledge and access up-to-date maintenance practices for more accurate and in-depth recommendations. The Gemini model then generates structured maintenance recommendations includes immediate actions, inspection checklists, corrective measures, parts requirements, and timeline specifications. Experimental validation in bearing vibration datasets demonstrates effective anomaly detection and contextually relevant maintenance guidance. The system successfully bridges the gap between condition monitoring and actionable maintenance planning, providing industrial practitioners with intelligent decision support. This work advances the application of LLMs in industrial maintenance, offering a scalable framework for prescriptive maintenance across machinery components and industrial sectors. </p>
<blockquote>
<p>å·¥ä¸šæœºæ¢°ç»´æŠ¤éœ€è¦åŠæ—¶çš„å¹²é¢„æ¥é¢„é˜²ç¾éš¾æ€§æ•…éšœå¹¶ä¼˜åŒ–è¿è¥æ•ˆç‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é›†æˆæ™ºèƒ½ç³»ç»Ÿï¼Œç”¨äºé¢„é˜²æ€§ç»´æŠ¤ï¼Œè¯¥ç³»ç»Ÿè¶…è¶Šäº†ä¼ ç»Ÿçš„å¼‚å¸¸æ£€æµ‹ï¼Œæä¾›äº†å¯è¡Œçš„ç»´æŠ¤å»ºè®®ã€‚åœ¨å…ˆå‰ç”¨äºæ•°å€¼æ•°æ®åˆ†æçš„LAMPæ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç»¼åˆè§£å†³æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆå°†è½´æ‰¿æŒ¯åŠ¨é¢‘ç‡åˆ†æä¸å¤šæ™ºèƒ½ä½“ç”Ÿæˆç›¸ç»“åˆï¼Œç”¨äºæ™ºèƒ½ç»´æŠ¤è§„åˆ’ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†è½´æ‰¿æŒ¯åŠ¨æ•°æ®ï¼ˆBPFOã€BPFIã€BSFã€FTFé¢‘ç‡ï¼‰åºåˆ—åŒ–ä¸ºè‡ªç„¶è¯­è¨€ä»¥ä¾›LLMå¤„ç†ï¼Œä»è€Œå®ç°é«˜å‡†ç¡®åº¦çš„å°‘é‡å¼‚å¸¸æ£€æµ‹ã€‚è¯¥ç³»ç»Ÿå¯¹æ•…éšœç±»å‹ï¼ˆå†…åœˆã€å¤–åœˆã€çƒ&#x2F;æ»šç ã€ç¬¼æ•…éšœï¼‰è¿›è¡Œåˆ†ç±»å¹¶è¯„ä¼°ä¸¥é‡ç¨‹åº¦ã€‚å¤šæ™ºèƒ½ä½“ç»„ä»¶ä½¿ç”¨å‘é‡åµŒå…¥å’Œè¯­ä¹‰æœç´¢å¤„ç†ç»´æŠ¤æ‰‹å†Œï¼ŒåŒæ—¶è¿›è¡Œç½‘ç»œæœç´¢ä»¥æ£€ç´¢å…¨é¢çš„ç¨‹åºçŸ¥è¯†å¹¶è·å–æœ€æ–°ç»´æŠ¤å®è·µï¼Œä»¥æä¾›æ›´å‡†ç¡®å’Œæ·±å…¥çš„æ¨èã€‚ç„¶åï¼ŒGeminiæ¨¡å‹ç”Ÿæˆç»“æ„åŒ–ç»´æŠ¤å»ºè®®ï¼ŒåŒ…æ‹¬ç«‹å³è¡ŒåŠ¨ã€æ£€æŸ¥æ¸…å•ã€çº æ­£æªæ–½ã€é›¶ä»¶è¦æ±‚å’Œæ—¶é—´è¡¨è§„èŒƒã€‚åœ¨è½´æ‰¿æŒ¯åŠ¨æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯è¡¨æ˜ï¼Œç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆåœ°æ£€æµ‹å¼‚å¸¸å¹¶æä¾›ä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„ç»´æŠ¤æŒ‡å¯¼ã€‚è¯¥ç³»ç»ŸæˆåŠŸåœ°å¼¥åˆäº†çŠ¶å†µç›‘æµ‹å’Œå¯æ“ä½œç»´æŠ¤è§„åˆ’ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºå·¥ä¸šä»ä¸šè€…æä¾›æ™ºèƒ½å†³ç­–æ”¯æŒã€‚è¿™é¡¹å·¥ä½œæ¨åŠ¨äº†LLMåœ¨å·¥ä¸šç»´æŠ¤é¢†åŸŸçš„åº”ç”¨ï¼Œä¸ºæœºæ¢°éƒ¨ä»¶å’Œå·¥ä¸šéƒ¨é—¨çš„é¢„é˜²æ€§ç»´æŠ¤æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04714v2">PDF</a> </p>
<p><strong>Summary</strong>:<br>å·¥ä¸šæœºæ¢°ç»´æŠ¤éœ€è¦åŠæ—¶çš„å¹²é¢„æ¥é¢„é˜²ç¾éš¾æ€§æ•…éšœå¹¶ä¼˜åŒ–è¿è¥æ•ˆç‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é›†æˆæ™ºèƒ½ç³»ç»Ÿï¼Œç”¨äºé¢„é˜²æ€§ç»´æŠ¤ï¼Œè¯¥ç³»ç»Ÿä¸ä»…è¶…è¶Šäº†ä¼ ç»Ÿçš„å¼‚å¸¸æ£€æµ‹ï¼Œè€Œä¸”æä¾›äº†å¯æ“ä½œçš„ç»´æŠ¤å»ºè®®ã€‚è¯¥ç³»ç»Ÿç»“åˆè½´æ‰¿æŒ¯åŠ¨é¢‘ç‡åˆ†æå’Œå¤šæ™ºèƒ½ä½“ç”Ÿæˆï¼Œå®ç°äº†æ™ºèƒ½åŒ–çš„ç»´æŠ¤è®¡åˆ’ã€‚é€šè¿‡åºåˆ—åŒ–è½´æ‰¿æŒ¯åŠ¨æ•°æ®å¹¶è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œå®ç°äº†é«˜å‡†ç¡®åº¦çš„å°‘æ•°å¼‚å¸¸æ£€æµ‹ã€‚ç³»ç»Ÿå¯ä»¥åˆ†ç±»æ•…éšœç±»å‹å¹¶è¯„ä¼°ä¸¥é‡ç¨‹åº¦ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿè¿˜é€šè¿‡å‘é‡åµŒå…¥å’Œè¯­ä¹‰æœç´¢å¤„ç†ç»´æŠ¤æ‰‹å†Œï¼Œè¿›è¡Œç½‘ç»œæœç´¢ä»¥è·å–å…¨é¢çš„ç¨‹åºæ€§çŸ¥è¯†å’Œæœ€æ–°çš„ç»´æŠ¤å®è·µï¼Œä»¥æä¾›æ›´å‡†ç¡®å’Œæ·±å…¥çš„æ¨èã€‚é€šè¿‡è½´æ‰¿æŒ¯åŠ¨æ•°æ®é›†çš„å®éªŒéªŒè¯ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†æœ‰æ•ˆçš„å¼‚å¸¸æ£€æµ‹å’Œä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„ç»´æŠ¤æŒ‡å¯¼ã€‚è¿™é¡¹å·¥ä½œæ¨åŠ¨äº†LLMåœ¨å·¥ä¸šç»´æŠ¤é¢†åŸŸçš„åº”ç”¨ï¼Œä¸ºæœºæ¢°éƒ¨ä»¶å’Œå·¥ä¸šéƒ¨é—¨æä¾›äº†å¯æ‰©å±•çš„é¢„é˜²æ€§ç»´æŠ¤æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”¨äºå·¥ä¸šæœºæ¢°çš„æ™ºèƒ½ç»´æŠ¤ç³»ç»Ÿã€‚</li>
<li>ç³»ç»Ÿç»“åˆè½´æ‰¿æŒ¯åŠ¨é¢‘ç‡åˆ†æä¸å¤šæ™ºèƒ½ä½“ç”Ÿæˆï¼Œæä¾›ç»´æŠ¤å»ºè®®ã€‚</li>
<li>é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å®ç°å°‘æ•°å¼‚å¸¸æ£€æµ‹çš„é«˜å‡†ç¡®æ€§ã€‚</li>
<li>ç³»ç»Ÿèƒ½åˆ†ç±»æ•…éšœç±»å‹å’Œè¯„ä¼°ä¸¥é‡ç¨‹åº¦ã€‚</li>
<li>é€šè¿‡å¤„ç†ç»´æŠ¤æ‰‹å†Œå’Œç½‘ç»œæœç´¢ï¼Œç³»ç»Ÿæä¾›æ›´å‡†ç¡®å’Œæ·±å…¥çš„ç»´æŠ¤å»ºè®®ã€‚</li>
<li>å®éªŒéªŒè¯è¡¨æ˜ï¼Œç³»ç»Ÿå®ç°äº†æœ‰æ•ˆçš„å¼‚å¸¸æ£€æµ‹å’Œä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„ç»´æŠ¤æŒ‡å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04714">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-99f24ef02a7e7288b085b18a70597849.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-833d53ccf48f02fd0f28e242433f157a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-659d4eb6d0e68fcd3a48ee5cc5b2568d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e444f740ceaeb9b313bbe1260e335924.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97150f109527f773126066ce74a320b0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AraReasoner-Evaluating-Reasoning-Based-LLMs-for-Arabic-NLP"><a href="#AraReasoner-Evaluating-Reasoning-Based-LLMs-for-Arabic-NLP" class="headerlink" title="AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP"></a>AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP</h2><p><strong>Authors:Ahmed Hasanaath, Aisha Alansari, Ahmed Ashraf, Chafik Salmane, Hamzah Luqman, Saad Ezzini</strong></p>
<p>Large language models (LLMs) have shown remarkable progress in reasoning abilities and general natural language processing (NLP) tasks, yet their performance on Arabic data, characterized by rich morphology, diverse dialects, and complex script, remains underexplored. This paper presents a comprehensive benchmarking study of multiple reasoning-focused LLMs, with a special emphasis on the newly introduced DeepSeek models, across a suite of fifteen Arabic NLP tasks. We experiment with various strategies, including zero-shot, few-shot, and fine-tuning. This allows us to systematically evaluate performance on datasets covering a range of applications to examine their capacity for linguistic reasoning under different levels of complexity. Our experiments reveal several key findings. First, carefully selecting just three in-context examples delivers an average uplift of over 13 F1 points on classification tasks-boosting sentiment analysis from 35.3% to 87.5% and paraphrase detection from 56.1% to 87.0%. Second, reasoning-focused DeepSeek architectures outperform a strong GPT o4-mini baseline by an average of 12 F1 points on complex inference tasks in the zero-shot setting. Third, LoRA-based fine-tuning yields up to an additional 8 points in F1 and BLEU compared to equivalent increases in model scale. The code is available at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AraReasoner41299">https://anonymous.4open.science/r/AraReasoner41299</a> </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†èƒ½åŠ›å’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„ä¸€èˆ¬ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œç„¶è€Œï¼Œå®ƒä»¬åœ¨å¤„ç†é˜¿æ‹‰ä¼¯æ•°æ®æ–¹é¢çš„è¡¨ç°ï¼Œè¿™äº›é˜¿æ‹‰ä¼¯æ•°æ®ä»¥ä¸°å¯Œçš„å½¢æ€ã€å¤šæ ·çš„æ–¹è¨€å’Œå¤æ‚çš„è„šæœ¬ä¸ºç‰¹å¾ï¼Œä»è¢«ç ”ç©¶å¾—ä¸å¤Ÿé€å½»ã€‚æœ¬æ–‡å…¨é¢è¯„ä¼°äº†å¤šä¸ªæ³¨é‡æ¨ç†çš„LLMæ¨¡å‹ï¼Œç‰¹åˆ«å¼ºè°ƒæ–°æ¨å‡ºçš„DeepSeekæ¨¡å‹ï¼Œæ¶µç›–åäº”é¡¹é˜¿æ‹‰ä¼¯è¯­NLPä»»åŠ¡ã€‚æˆ‘ä»¬å°è¯•äº†å¤šç§ç­–ç•¥ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿç³»ç»Ÿåœ°è¯„ä¼°æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œæ¶µç›–å„ç§åº”ç”¨ç¨‹åºï¼Œä»¥æ£€æŸ¥å®ƒä»¬åœ¨ä¸åŒå¤æ‚ç¨‹åº¦ä¸‹çš„è¯­è¨€æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒæ­ç¤ºäº†å‡ ä¸ªå…³é”®å‘ç°ã€‚é¦–å…ˆï¼Œåªéœ€ç²¾å¿ƒé€‰æ‹©ä¸‰ä¸ªä¸Šä¸‹æ–‡å®ä¾‹ï¼Œå°±å¯ä»¥åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šå¹³å‡æé«˜è¶…è¿‡13ä¸ªF1ç‚¹â€”â€”æƒ…æ„Ÿåˆ†æä»35.3%æé«˜åˆ°87.5%ï¼Œè€Œæ”¹è¿°æ£€æµ‹ä»56.1%æé«˜åˆ°87.0%ã€‚å…¶æ¬¡ï¼Œæ³¨é‡æ¨ç†çš„DeepSeekæ¶æ„åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹çš„å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå¹³å‡æ¯”å¼ºå¤§çš„GPT o4-miniåŸºçº¿é«˜å‡º12ä¸ªF1ç‚¹ã€‚ç¬¬ä¸‰ï¼ŒåŸºäºLoRAçš„å¾®è°ƒä¸æ¨¡å‹è§„æ¨¡çš„ç­‰æ•ˆå¢é•¿ç›¸æ¯”ï¼Œé¢å¤–æé«˜äº†é«˜è¾¾8ä¸ªF1ç‚¹å’ŒBLEUå€¼ã€‚ä»£ç å¯ç”¨<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AraReasoner41299%E6%9F%A5%E8%AF%A2%E3%80%82">https://anonymous.4open.science/r/AraReasoner41299æŸ¥è¯¢ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08768v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å…·æœ‰ä¸°å¯Œå½¢æ€ã€å¤šæ ·æ–¹è¨€å’Œå¤æ‚è„šæœ¬çš„é˜¿æ‹‰ä¼¯è¯­æ•°æ®ä¸Šæ€§èƒ½å°šå¾…æ¢ç´¢ã€‚æœ¬æ–‡é€šè¿‡ä¸€ç³»åˆ—é˜¿æ‹‰ä¼¯NLPä»»åŠ¡å…¨é¢è¯„ä¼°å¤šä¸ªæ³¨é‡æ¨ç†çš„LLMsï¼Œå°¤å…¶æ˜¯æ–°æ¨å‡ºçš„DeepSeekæ¨¡å‹ã€‚ç ”ç©¶å‘ç°ï¼Œç²¾é€‰ä¸‰ä¸ªå®ä¾‹çš„few-shotæ–¹å¼èƒ½æé«˜åˆ†ç±»ä»»åŠ¡çš„å¹³å‡F1åˆ†æ•°è¶…è¿‡13ç‚¹ï¼›DeepSeekæ¶æ„åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹æ¯”GPT o4-miniåŸºçº¿å¹³å‡é«˜å‡º12 F1ç‚¹ï¼›åŸºäºLoRAçš„å¾®è°ƒæŠ€æœ¯ç›¸æ¯”æ¨¡å‹è§„æ¨¡çš„å¢åŠ å¯æé«˜æœ€å¤š8ç‚¹çš„F1å’ŒBLEUåˆ†æ•°ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€åˆ†äº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ¨é˜¿æ‹‰ä¼¯è¯­NLPä»»åŠ¡ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ä»æœ‰å¾…å……åˆ†æ¢ç´¢ã€‚</li>
<li>é€šè¿‡ä¸€ç³»åˆ—å®éªŒè¯„ä¼°äº†å¤šç§æ¨ç†å‹LLMsï¼Œå°¤å…¶æ˜¯æ–°å‡ºç°çš„DeepSeekæ¨¡å‹ã€‚</li>
<li>ç²¾é€‰ä¸‰ä¸ªå®ä¾‹çš„few-shotæ–¹å¼æ˜¾è‘—æé«˜åˆ†ç±»ä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>DeepSeekæ¶æ„åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>LoRAå¾®è°ƒæŠ€æœ¯èƒ½æœ‰æ•ˆæå‡æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¯¦ç»†è¯´æ˜äº†ä¸åŒç­–ç•¥å¯¹é˜¿æ‹‰ä¼¯è¯­NLPä»»åŠ¡æ€§èƒ½çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08768">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-85909eb455fa75a12e4c53f27797c2cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98eb100cc13fdad5032bac7377f6403e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49480addd61a026709ac53c33ba9859f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Embodied-Long-Horizon-Manipulation-with-Closed-loop-Code-Generation-and-Incremental-Few-shot-Adaptation"><a href="#Embodied-Long-Horizon-Manipulation-with-Closed-loop-Code-Generation-and-Incremental-Few-shot-Adaptation" class="headerlink" title="Embodied Long Horizon Manipulation with Closed-loop Code Generation and   Incremental Few-shot Adaptation"></a>Embodied Long Horizon Manipulation with Closed-loop Code Generation and   Incremental Few-shot Adaptation</h2><p><strong>Authors:Yuan Meng, Xiangtong Yao, Haihui Ye, Yirui Zhou, Shengqiang Zhang, Zhenguo Sun, Xukun Li, Zhenshan Bing, Alois Knoll</strong></p>
<p>Embodied long-horizon manipulation requires robotic systems to process multimodal inputs-such as vision and natural language-and translate them into executable actions. However, existing learning-based approaches often depend on large, task-specific datasets and struggle to generalize to unseen scenarios. Recent methods have explored using large language models (LLMs) as high-level planners that decompose tasks into subtasks using natural language and guide pretrained low-level controllers. Yet, these approaches assume perfect execution from low-level policies, which is unrealistic in real-world environments with noise or suboptimal behaviors. To overcome this, we fully discard the pretrained low-level policy and instead use the LLM to directly generate executable code plans within a closed-loop framework. Our planner employs chain-of-thought (CoT)-guided few-shot learning with incrementally structured examples to produce robust and generalizable task plans. Complementing this, a reporter evaluates outcomes using RGB-D and delivers structured feedback, enabling recovery from misalignment and replanning under partial observability. This design eliminates per-step inference, reduces computational overhead, and limits error accumulation that was observed in previous methods. Our framework achieves state-of-the-art performance on 30+ diverse seen and unseen long-horizon tasks across LoHoRavens, CALVIN, Franka Kitchen, and cluttered real-world settings. </p>
<blockquote>
<p>å®ç°å…·æœ‰é•¿æœŸè§†è§’çš„æ“ä½œéœ€è¦æœºå™¨äººç³»ç»Ÿå¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼Œå¦‚è§†è§‰å’Œè‡ªç„¶è¯­è¨€ï¼Œå¹¶å°†å…¶ç¿»è¯‘æˆå¯æ‰§è¡Œçš„è¡ŒåŠ¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºå­¦ä¹ çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤§å‹ã€ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ï¼Œå¹¶ä¸”åœ¨æœªè§åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚æœ€è¿‘çš„æ–¹æ³•å·²ç»å°è¯•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºé«˜çº§è§„åˆ’å™¨ï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€å°†ä»»åŠ¡åˆ†è§£æˆå­ä»»åŠ¡ï¼Œå¹¶å¼•å¯¼é¢„è®­ç»ƒçš„ä½çº§æ§åˆ¶å™¨ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å‡è®¾ä½çº§ç­–ç•¥å¯ä»¥å®Œç¾æ‰§è¡Œï¼Œè¿™åœ¨ç°å®ä¸–ç•Œä¸­å­˜åœ¨å™ªå£°æˆ–éæœ€ä¼˜è¡Œä¸ºçš„æƒ…å†µä¸‹æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å®Œå…¨æŠ›å¼ƒäº†é¢„è®­ç»ƒçš„ä½çº§ç­–ç•¥ï¼Œè€Œæ˜¯ä½¿ç”¨LLMç›´æ¥åœ¨é—­ç¯æ¡†æ¶å†…ç”Ÿæˆå¯æ‰§è¡Œçš„ä»£ç è®¡åˆ’ã€‚æˆ‘ä»¬çš„è§„åˆ’å™¨é‡‡ç”¨åŸºäºæ€ç»´é“¾ï¼ˆCoTï¼‰å¼•å¯¼çš„å°æ ·æœ¬å­¦ä¹ ï¼Œé€šè¿‡å¢é‡ç»“æ„åŒ–ç¤ºä¾‹æ¥äº§ç”Ÿç¨³å¥ä¸”å¯æ³›åŒ–çš„ä»»åŠ¡è®¡åˆ’ã€‚ä½œä¸ºè¡¥å……ï¼Œä¸€ä¸ªæŠ¥å‘Šè€…ä½¿ç”¨RGB-Dè¯„ä¼°ç»“æœå¹¶æä¾›ç»“æ„åŒ–åé¦ˆï¼Œä»è€Œå®ç°éƒ¨åˆ†è§‚æµ‹ä¸‹çš„è¯¯å¯¹é½æ¢å¤å’Œé‡æ–°è§„åˆ’ã€‚è¿™ç§è®¾è®¡æ¶ˆé™¤äº†é€æ­¥æ¨ç†ï¼Œå‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œå¹¶é™åˆ¶äº†ä¹‹å‰åœ¨å…¶å®ƒæ–¹æ³•ä¸­è§‚å¯Ÿåˆ°çš„è¯¯å·®ç´¯ç§¯ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨LoHoRavensã€CALVINã€Frankaå¨æˆ¿å’Œæ‚ä¹±çš„çœŸå®ä¸–ç•Œç¯å¢ƒä¸­ï¼Œå®ç°äº†30å¤šä¸ªä¸åŒå·²è§å’Œæœªè§é•¿æœŸä»»åŠ¡çš„æœ€ä½³æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.21969v3">PDF</a> update ICRA 6 page</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šæ¨¡æ€è¾“å…¥çš„é•¿æœŸè§„åˆ’æ“æ§éœ€è¦æœºå™¨äººç³»ç»Ÿå¤„ç†è§†è§‰å’Œè‡ªç„¶è¯­è¨€ç­‰å¤šç§æ¨¡å¼è¾“å…¥ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯æ‰§è¡ŒåŠ¨ä½œã€‚ç°æœ‰å­¦ä¹ æ³•ä¾èµ–äºç‰¹å®šä»»åŠ¡çš„å¤§é‡æ•°æ®é›†ï¼Œéš¾ä»¥æ¨å¹¿åˆ°æœªè§åœºæ™¯ã€‚è¿‘æœŸæ–¹æ³•å°è¯•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºé«˜çº§è§„åˆ’å™¨ï¼Œä½†å‡è®¾ä½çº§ç­–ç•¥çš„å®Œç¾æ‰§è¡Œå¹¶ä¸ç°å®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æŠ›å¼ƒé¢„è®­ç»ƒçš„ä½çº§ç­–ç•¥ï¼Œæ”¹ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç›´æ¥ç”Ÿæˆå°é—­å¾ªç¯æ¡†æ¶å†…çš„å¯æ‰§è¡Œä»£ç è®¡åˆ’ã€‚æ­¤å¤–ï¼Œç»“åˆä½¿ç”¨RGB-Dè¿›è¡Œç»“æœè¯„ä¼°å¹¶æä¾›ç»“æ„åŒ–åé¦ˆï¼Œä¿ƒè¿›è¯¯å¯¹é½æƒ…å†µä¸‹çš„æ¢å¤ä¸éƒ¨åˆ†è§‚å¯Ÿä¸‹çš„é‡æ–°è§„åˆ’ã€‚æ­¤è®¾è®¡æ¶ˆé™¤äº†é€æ­¥æ¨ç†ï¼Œå‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œå¹¶é™åˆ¶äº†å…ˆå‰æ–¹æ³•è§‚å¯Ÿåˆ°çš„è¯¯å·®ç´¯ç§¯ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨å¤šä¸ªé•¿å‘¨æœŸä»»åŠ¡ä¸Šå®ç°äº†å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœºå™¨äººç³»ç»Ÿéœ€è¦å¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼Œå¦‚è§†è§‰å’Œè‡ªç„¶è¯­è¨€ï¼Œè½¬åŒ–ä¸ºå¯æ‰§è¡ŒåŠ¨ä½œã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§é‡ç‰¹å®šä»»åŠ¡æ•°æ®é›†ï¼Œéš¾ä»¥é€‚åº”æ–°åœºæ™¯ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ç”¨äºé«˜çº§ä»»åŠ¡è§„åˆ’ï¼Œä½†å®Œç¾æ‰§è¡Œå‡è®¾ä¸ç°å®ã€‚</li>
<li>æŠ›å¼ƒé¢„è®­ç»ƒçš„ä½çº§ç­–ç•¥ï¼Œç›´æ¥ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆä»£ç è®¡åˆ’ã€‚</li>
<li>ç»“åˆRGB-Dè¿›è¡Œç»“æœè¯„ä¼°å¹¶æä¾›ç»“æ„åŒ–åé¦ˆã€‚</li>
<li>è¯¥è®¾è®¡å‡å°‘è®¡ç®—å¼€é”€å’Œè¯¯å·®ç´¯ç§¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.21969">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-477e5b2528e669fb1d9aaa17210cad7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d34edef9b411ac4c1c28be81f232fe2e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de8b11308af9cce233e856bbc878d26f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-506702e2a4341bcdd7004138af3c3667.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88d516f7bc4a2ca9c12ad57a136bebea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5a6b9f2350360c95e1ce5bfd4a7db9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77846ad7794efa874f08b1c4773e28f0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Revisiting-Out-of-Distribution-Detection-in-Real-time-Object-Detection-From-Benchmark-Pitfalls-to-a-New-Mitigation-Paradigm"><a href="#Revisiting-Out-of-Distribution-Detection-in-Real-time-Object-Detection-From-Benchmark-Pitfalls-to-a-New-Mitigation-Paradigm" class="headerlink" title="Revisiting Out-of-Distribution Detection in Real-time Object Detection:   From Benchmark Pitfalls to a New Mitigation Paradigm"></a>Revisiting Out-of-Distribution Detection in Real-time Object Detection:   From Benchmark Pitfalls to a New Mitigation Paradigm</h2><p><strong>Authors:Changshun Wu, Weicheng He, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem</strong></p>
<p>Out-of-distribution (OoD) inputs pose a persistent challenge to deep learning models, often triggering overconfident predictions on non-target objects. While prior work has primarily focused on refining scoring functions and adjusting test-time thresholds, such algorithmic improvements offer only incremental gains. We argue that a rethinking of the entire development lifecycle is needed to mitigate these risks effectively. This work addresses two overlooked dimensions of OoD detection in object detection. First, we reveal fundamental flaws in widely used evaluation benchmarks: contrary to their design intent, up to 13% of objects in the OoD test sets actually belong to in-distribution classes, and vice versa. These quality issues severely distort the reported performance of existing methods and contribute to their high false positive rates. Second, we introduce a novel training-time mitigation paradigm that operates independently of external OoD detectors. Instead of relying solely on post-hoc scoring, we fine-tune the detector using a carefully synthesized OoD dataset that semantically resembles in-distribution objects. This process shapes a defensive decision boundary by suppressing objectness on OoD objects, leading to a 91% reduction in hallucination error of a YOLO model on BDD-100K. Our methodology generalizes across detection paradigms such as YOLO, Faster R-CNN, and RT-DETR, and supports few-shot adaptation. Together, these contributions offer a principled and effective way to reduce OoD-induced hallucination in object detectors. Code and data are available at: <a target="_blank" rel="noopener" href="https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood">https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood</a>. </p>
<blockquote>
<p>åˆ†å¸ƒå¤–ï¼ˆOut-of-distributionï¼ŒOoDï¼‰è¾“å…¥å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹æ„æˆæŒç»­æŒ‘æˆ˜ï¼Œé€šå¸¸ä¼šå¯¹éç›®æ ‡å¯¹è±¡åšå‡ºè¿‡äºè‡ªä¿¡çš„é¢„æµ‹ã€‚è™½ç„¶å…ˆå‰çš„å·¥ä½œä¸»è¦é›†ä¸­äºæ”¹è¿›è¯„åˆ†åŠŸèƒ½å’Œè°ƒæ•´æµ‹è¯•æ—¶é—´é˜ˆå€¼ï¼Œä½†æ­¤ç±»ç®—æ³•æ”¹è¿›åªèƒ½å¸¦æ¥å¢é‡æ”¶ç›Šã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œä¸ºäº†æœ‰æ•ˆå‡è½»è¿™äº›é£é™©ï¼Œéœ€è¦é‡æ–°æ€è€ƒæ•´ä¸ªå¼€å‘ç”Ÿå‘½å‘¨æœŸã€‚è¿™é¡¹å·¥ä½œè§£å†³äº†å¯¹è±¡æ£€æµ‹ä¸­åˆ†å¸ƒå¤–æ£€æµ‹ï¼ˆOoDæ£€æµ‹ï¼‰è¢«å¿½ç•¥çš„ä¸¤ä¸ªç»´åº¦ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ­ç¤ºäº†å¹¿æ³›ä½¿ç”¨çš„è¯„ä¼°åŸºå‡†ä¸­å­˜åœ¨çš„æ ¹æœ¬é—®é¢˜ï¼šä¸ä»–ä»¬çš„è®¾è®¡åˆè¡·ç›¸åï¼Œé«˜è¾¾13%çš„å¯¹è±¡å±äºåˆ†å¸ƒå†…ç±»åˆ«ï¼Œåä¹‹äº¦ç„¶ã€‚è¿™äº›é—®é¢˜ä¸¥é‡å½±å“äº†ç°æœ‰æ–¹æ³•çš„æŠ¥å‘Šæ€§èƒ½ï¼Œå¹¶å¯¼è‡´äº†è¾ƒé«˜çš„è¯¯æŠ¥ç‡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„è®­ç»ƒæ—¶é—´ç¼“è§£æ¨¡å¼ï¼Œè¯¥æ¨¡å¼ç‹¬ç«‹äºå¤–éƒ¨åˆ†å¸ƒå¤–æ£€æµ‹å™¨è¿è¡Œã€‚æˆ‘ä»¬ä¸æ˜¯ä¾èµ–äº‹åè¯„åˆ†ï¼Œè€Œæ˜¯ä½¿ç”¨ç²¾å¿ƒåˆæˆçš„åˆ†å¸ƒå¤–æ•°æ®é›†å¯¹æ£€æµ‹å™¨è¿›è¡Œå¾®è°ƒï¼Œè¯¥æ•°æ®é›†åœ¨è¯­ä¹‰ä¸Šç±»ä¼¼äºåˆ†å¸ƒå†…å¯¹è±¡ã€‚è¿™ä¸€è¿‡ç¨‹é€šè¿‡æŠ‘åˆ¶åˆ†å¸ƒå¤–å¯¹è±¡ä¸Šçš„å¯¹è±¡æ€§æ¥å½¢æˆé˜²å¾¡å†³ç­–è¾¹ç•Œï¼Œå¯¼è‡´YOLOæ¨¡å‹åœ¨BDD-100Kä¸Šçš„å¹»è§‰è¯¯å·®é™ä½äº†91%ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºYOLOã€Faster R-CNNå’ŒRT-DETRç­‰æ£€æµ‹èŒƒå¼ï¼Œå¹¶æ”¯æŒå°‘é‡é•œå¤´é€‚åº”ã€‚è¿™äº›è´¡çŒ®å…±åŒæä¾›äº†ä¸€ç§æœ‰åŸåˆ™ä¸”æœ‰æ•ˆçš„å‡å°‘å¯¹è±¡æ£€æµ‹å™¨ä¸­çš„åˆ†å¸ƒå¤–è¾“å…¥å¼•èµ·çš„å¹»è§‰çš„æ–¹æ³•ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood%E3%80%82">https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hoodã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.07330v3">PDF</a> Expanded journal version of our IROS 2025 paper, adding automated OoD   benchmarking, generalization to multiple object detectors, few-shot   fine-tuning, and in-depth analysis</p>
<p><strong>æ‘˜è¦</strong><br>æ·±åº¦å­¦ä¹ æ–¹æ³•é¢ä¸´æ¥è‡ªåˆ†å¸ƒå¤–ï¼ˆOut-of-Distributionï¼ŒOoDï¼‰è¾“å…¥çš„æŒç»­æŒ‘æˆ˜ï¼Œå®¹æ˜“åœ¨éç›®æ ‡å¯¹è±¡ä¸Šäº§ç”Ÿè¿‡åº¦è‡ªä¿¡çš„é¢„æµ‹ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨è¯„åˆ†å‡½æ•°çš„æ”¹è¿›å’Œæµ‹è¯•æ—¶é˜ˆå€¼çš„è°ƒæ•´ï¼Œä½†è¿™äº›ç®—æ³•ä¸Šçš„æ”¹è¿›åªå¸¦æ¥äº†æœ‰é™çš„æå‡ã€‚æœ¬æ–‡é‡æ–°æ€è€ƒäº†å¼€å‘å‘¨æœŸä¸­çš„ä¸¤ä¸ªè¢«å¿½è§†æ–¹é¢ï¼Œä»¥è§£å†³OoDæ£€æµ‹ä¸­çš„å…³é”®é—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å‘ç°å¸¸ç”¨çš„è¯„ä¼°åŸºå‡†å­˜åœ¨æ ¹æœ¬é—®é¢˜ï¼šæµ‹è¯•é›†ä¸­æœ‰é«˜è¾¾13%çš„å¯¹è±¡å®é™…ä¸Šæ˜¯åˆ†å¸ƒå†…çš„ç±»åˆ«ï¼Œè¿™ä¸è®¾è®¡åˆè¡·ç›¸åã€‚è¿™äº›é—®é¢˜ä¸¥é‡å½±å“äº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½æŠ¥å‘Šå¹¶å¯¼è‡´äº†é«˜è¯¯æŠ¥ç‡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åœ¨çº¿ç¼“è§£èŒƒå¼ï¼Œç‹¬ç«‹äºå¤–éƒ¨OoDæ£€æµ‹å™¨è¿è¡Œã€‚æˆ‘ä»¬ä¸å†ä¾èµ–äº‹åè¯„åˆ†ï¼Œè€Œæ˜¯ä½¿ç”¨ç²¾å¿ƒåˆæˆçš„ç±»ä¼¼äºåˆ†å¸ƒå†…å¯¹è±¡çš„OoDæ•°æ®é›†å¾®è°ƒæ£€æµ‹å™¨ã€‚é€šè¿‡å‹åˆ¶OoDå¯¹è±¡ä¸Šçš„å¯¹è±¡æ€§ï¼Œå¡‘é€ é˜²å¾¡å†³ç­–è¾¹ç•Œï¼ŒYOLOæ¨¡å‹çš„å¹»è§‰é”™è¯¯å‡å°‘äº†91%ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºYOLOã€Faster R-CNNå’ŒRT-DETRç­‰æ£€æµ‹èŒƒå¼ï¼Œå¹¶æ”¯æŒå°‘é‡æ ·æœ¬é€‚åº”ã€‚è¿™äº›è´¡çŒ®ä¸ºè§£å†³æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å¯¹è±¡æ£€æµ‹ä¸­çš„åˆ†å¸ƒå¤–è¾“å…¥é—®é¢˜æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚æ›´å¤šä¿¡æ¯å’Œèµ„æºå¯åœ¨é“¾æ¥ä¸­æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood">https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood</a>ã€‚</p>
<p><strong>è¦ç‚¹å½’çº³</strong></p>
<p>ä¸€ã€ç°æœ‰çš„å¯¹è±¡æ£€æµ‹æ¨¡å‹é¢ä¸´æ¥è‡ªåˆ†å¸ƒå¤–çš„è¾“å…¥æŒ‘æˆ˜ï¼Œä¼šå¯¼è‡´å¯¹éç›®æ ‡å¯¹è±¡çš„è¿‡åº¦è‡ªä¿¡é¢„æµ‹ã€‚è¿™å¸¦æ¥äº†å¯¹æ–°æ–¹æ³•çš„è¿«åˆ‡éœ€æ±‚ã€‚</p>
<p>äºŒã€ä¼ ç»Ÿçš„è¯„ä¼°åŸºå‡†å­˜åœ¨è´¨é‡ç¼ºé™·ï¼šè®¾è®¡åˆè¡·ä¸å®é™…å­˜åœ¨å·®å¼‚ï¼Œå¯èƒ½å¯¼è‡´é«˜è¾¾13%çš„å¯¹è±¡ç±»åˆ«è¢«è¯¯æŠ¥ä¸ºåˆ†å¸ƒå†…æˆ–åˆ†å¸ƒå¤–ã€‚è¿™å¯¹è¯„ä¼°æ¨¡å‹æ€§èƒ½é€ æˆäº†ä¸¥é‡æ‰­æ›²ã€‚æˆ‘ä»¬æå‡ºäº†ç›¸åº”çš„è§£å†³æ–¹æ³•æ¥æ”¹å–„è¿™ä¸ªé—®é¢˜ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.07330">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c6c4c66eb6766776627010ba4e243a49.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f657f2faea724bd7f1d739deef4ee9c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f0e15772a987df8ec33a28eae01a7dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20b1c1a4e1e4e4be5e39eaaf7f3a59e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b4af4548204b148ca3e5d717348f18b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-731a8fc9e488b35a920a95578f9ada87.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3d654934ef966007a679f6377ad964f2.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Label-Anything-Multi-Class-Few-Shot-Semantic-Segmentation-with-Visual-Prompts"><a href="#Label-Anything-Multi-Class-Few-Shot-Semantic-Segmentation-with-Visual-Prompts" class="headerlink" title="Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual   Prompts"></a>Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual   Prompts</h2><p><strong>Authors:Pasquale De Marinis, Nicola Fanelli, Raffaele Scaringi, Emanuele Colonna, Giuseppe Fiameni, Gennaro Vessio, Giovanna Castellano</strong></p>
<p>Few-shot semantic segmentation aims to segment objects from previously unseen classes using only a limited number of labeled examples. In this paper, we introduce Label Anything, a novel transformer-based architecture designed for multi-prompt, multi-way few-shot semantic segmentation. Our approach leverages diverse visual prompts â€“ points, bounding boxes, and masks â€“ to create a highly flexible and generalizable framework that significantly reduces annotation burden while maintaining high accuracy. Label Anything makes three key contributions: ($\textit{i}$) we introduce a new task formulation that relaxes conventional few-shot segmentation constraints by supporting various types of prompts, multi-class classification, and enabling multiple prompts within a single image; ($\textit{ii}$) we propose a novel architecture based on transformers and attention mechanisms; and ($\textit{iii}$) we design a versatile training procedure allowing our model to operate seamlessly across different $N$-way $K$-shot and prompt-type configurations with a single trained model. Our extensive experimental evaluation on the widely used COCO-$20^i$ benchmark demonstrates that Label Anything achieves state-of-the-art performance among existing multi-way few-shot segmentation methods, while significantly outperforming leading single-class models when evaluated in multi-class settings. Code and trained models are available at <a target="_blank" rel="noopener" href="https://github.com/pasqualedem/LabelAnything">https://github.com/pasqualedem/LabelAnything</a>. </p>
<blockquote>
<p>å°‘é‡æ ·æœ¬è¯­ä¹‰åˆ†å‰²æ—¨åœ¨ä½¿ç”¨æœ‰é™çš„æ ‡æ³¨æ ·æœ¬å¯¹ä¹‹å‰æœªè§è¿‡çš„ç±»åˆ«è¿›è¡Œå¯¹è±¡åˆ†å‰²ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Label Anythingï¼Œè¿™æ˜¯ä¸€ç§åŸºäºtransformerçš„æ–°å‹æ¶æ„ï¼Œä¸“ä¸ºå¤šæç¤ºã€å¤šç±»åˆ«å°‘é‡æ ·æœ¬è¯­ä¹‰åˆ†å‰²è®¾è®¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å¤šæ ·åŒ–çš„è§†è§‰æç¤ºâ€”â€”ç‚¹ã€è¾¹ç•Œæ¡†å’Œè’™ç‰ˆï¼Œåˆ›å»ºä¸€ä¸ªé«˜åº¦çµæ´»å’Œå¯æ¨å¹¿çš„æ¡†æ¶ï¼Œåœ¨ä¿æŒé«˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå¤§å¤§é™ä½äº†æ ‡æ³¨è´Ÿæ‹…ã€‚Label Anythingåšå‡ºäº†ä¸‰ä¸ªä¸»è¦è´¡çŒ®ï¼šï¼ˆiï¼‰æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„ä»»åŠ¡å½¢å¼åŒ–æ–¹æ³•ï¼Œé€šè¿‡æ”¯æŒå„ç§æç¤ºç±»å‹ã€å¤šç±»åˆ†ç±»ï¼Œå¹¶åœ¨å•ä¸ªå›¾åƒå†…æ”¯æŒå¤šä¸ªæç¤ºï¼Œæ”¾å®½äº†ä¼ ç»Ÿçš„å°‘é‡æ ·æœ¬åˆ†å‰²çº¦æŸï¼›ï¼ˆiiï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºtransformerå’Œæ³¨æ„åŠ›æœºåˆ¶çš„æ–°å‹æ¶æ„ï¼›ï¼ˆiiiï¼‰æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§é€šç”¨è®­ç»ƒç¨‹åºï¼Œä½¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„Nè·¯Kæ ·æœ¬å’Œæç¤ºç±»å‹é…ç½®ä¸­ä½¿ç”¨å•ä¸ªè®­ç»ƒæ¨¡å‹æ— ç¼è¿è¡Œã€‚æˆ‘ä»¬åœ¨å¹¿æ³›ä½¿ç”¨çš„COCO-20iåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒLabel Anythingåœ¨ç°æœ‰çš„å¤šç±»åˆ«å°‘é‡æ ·æœ¬åˆ†å‰²æ–¹æ³•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å¤šç±»åˆ«è®¾ç½®ä¸­æ˜¾è‘—ä¼˜äºé¢†å…ˆçš„å•ç±»æ¨¡å‹ã€‚ç›¸å…³ä»£ç å’Œè®­ç»ƒå¥½çš„æ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/pasqualedem/LabelAnything%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pasqualedem/LabelAnythingæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.02075v4">PDF</a> ECAI 2025 - 28th European Conference on Artificial Intelligence</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºTransformeræ¶æ„çš„Label Anythingæ¨¡å‹ï¼Œç”¨äºå¤šæç¤ºã€å¤šç±»åˆ«å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å¤šæ ·åŒ–çš„è§†è§‰æç¤ºï¼ˆç‚¹ã€è¾¹ç•Œæ¡†å’Œæ©ç ï¼‰åˆ›å»ºäº†ä¸€ä¸ªçµæ´»ä¸”å¯æ¨å¹¿çš„æ¡†æ¶ï¼Œæ˜¾è‘—å‡å°‘äº†æ ‡æ³¨è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚Label Anythingå¯¹å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²é¢†åŸŸåšå‡ºäº†ä¸‰é¡¹å…³é”®è´¡çŒ®ï¼šå¼•å…¥æ”¯æŒå¤šç§æç¤ºã€å¤šç±»åˆ«åˆ†ç±»çš„æ–°ä»»åŠ¡å½¢å¼ï¼›æå‡ºåŸºäºTransformerå’Œæ³¨æ„åŠ›æœºåˆ¶çš„æ–°æ¶æ„ï¼›è®¾è®¡äº†ä¸€ç§é€šç”¨è®­ç»ƒç¨‹åºï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„N-way K-shotå’Œæç¤ºç±»å‹é…ç½®ä¸­æ— ç¼è¿è¡Œã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„COCO-20iåŸºå‡†æµ‹è¯•ä¸­ï¼ŒLabel Anythingåœ¨ç°æœ‰çš„å¤šç±»åˆ«å°‘æ ·æœ¬åˆ†å‰²æ–¹æ³•ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Label Anythingæ˜¯ä¸€ä¸ªåŸºäºTransformerçš„å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼Œæ”¯æŒå¤šæç¤ºå’Œå¤šç±»åˆ«åˆ†ç±»ã€‚</li>
<li>è¯¥æ¨¡å‹åˆ©ç”¨ç‚¹ã€è¾¹ç•Œæ¡†å’Œæ©ç ç­‰å¤šæ ·åŒ–çš„è§†è§‰æç¤ºï¼Œåˆ›å»ºäº†ä¸€ä¸ªçµæ´»ä¸”å¯æ¨å¹¿çš„æ¡†æ¶ã€‚</li>
<li>Label Anythingæ˜¾è‘—å‡å°‘äº†æ ‡æ³¨è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ¨¡å‹åšå‡ºäº†ä¸‰é¡¹å…³é”®è´¡çŒ®ï¼šå¼•å…¥æ–°çš„ä»»åŠ¡å½¢å¼ã€æ–°çš„æ¶æ„è®¾è®¡å’Œé€šç”¨è®­ç»ƒç¨‹åºã€‚</li>
<li>Label Anythingåœ¨COCO-20iåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>æ¨¡å‹æ”¯æŒä¸åŒçš„N-way K-shotå’Œæç¤ºç±»å‹é…ç½®ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.02075">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-943de758e838f749339981471007a3c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e32b2483843529dfb32bb4f52c67317.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de0a205bdd88658ebc95bfca2df6d6fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a6b5232cb693b7b99e2bfc6e8617a49.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-23/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-23/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-23/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-26cbea695aa2d6f406a4930a75641d36.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-23  Are Virtual DES Images a Valid Alternative to the Real Ones?
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-23/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-20b6292f2fd919823d826d9270025daf.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-23  Distributed Detection of Adversarial Attacks in Multi-Agent   Reinforcement Learning with Continuous Action Space
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
