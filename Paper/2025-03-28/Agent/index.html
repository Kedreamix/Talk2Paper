<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-28  Feature4X Bridging Any Monocular Video to 4D Agentic AI with Versatile   Gaussian Feature Fields">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-ab30b0eba029d65e0ca1119bd6e746ce.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    52 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-28-æ›´æ–°"><a href="#2025-03-28-æ›´æ–°" class="headerlink" title="2025-03-28 æ›´æ–°"></a>2025-03-28 æ›´æ–°</h1><h2 id="Feature4X-Bridging-Any-Monocular-Video-to-4D-Agentic-AI-with-Versatile-Gaussian-Feature-Fields"><a href="#Feature4X-Bridging-Any-Monocular-Video-to-4D-Agentic-AI-with-Versatile-Gaussian-Feature-Fields" class="headerlink" title="Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile   Gaussian Feature Fields"></a>Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile   Gaussian Feature Fields</h2><p><strong>Authors:Shijie Zhou, Hui Ren, Yijia Weng, Shuwang Zhang, Zhen Wang, Dejia Xu, Zhiwen Fan, Suya You, Zhangyang Wang, Leonidas Guibas, Achuta Kadambi</strong></p>
<p>Recent advancements in 2D and multimodal models have achieved remarkable success by leveraging large-scale training on extensive datasets. However, extending these achievements to enable free-form interactions and high-level semantic operations with complex 3D&#x2F;4D scenes remains challenging. This difficulty stems from the limited availability of large-scale, annotated 3D&#x2F;4D or multi-view datasets, which are crucial for generalizable vision and language tasks such as open-vocabulary and prompt-based segmentation, language-guided editing, and visual question answering (VQA). In this paper, we introduce Feature4X, a universal framework designed to extend any functionality from 2D vision foundation model into the 4D realm, using only monocular video input, which is widely available from user-generated content. The â€œXâ€ in Feature4X represents its versatility, enabling any task through adaptable, model-conditioned 4D feature field distillation. At the core of our framework is a dynamic optimization strategy that unifies multiple model capabilities into a single representation. Additionally, to the best of our knowledge, Feature4X is the first method to distill and lift the features of video foundation models (e.g. SAM2, InternVideo2) into an explicit 4D feature field using Gaussian Splatting. Our experiments showcase novel view segment anything, geometric and appearance scene editing, and free-form VQA across all time steps, empowered by LLMs in feedback loops. These advancements broaden the scope of agentic AI applications by providing a foundation for scalable, contextually and spatiotemporally aware systems capable of immersive dynamic 4D scene interaction. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼ŒäºŒç»´å’Œå¤šæ¨¡æ€æ¨¡å‹çš„è¿›æ­¥é€šè¿‡å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„è®­ç»ƒå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œå°†è¿™äº›æˆå°±æ‰©å±•åˆ°ä¸å¤æ‚çš„ä¸‰ç»´&#x2F;å››ç»´åœºæ™¯è¿›è¡Œè‡ªç”±å½¢å¼çš„äº¤äº’å’Œé«˜å±‚æ¬¡è¯­ä¹‰æ“ä½œä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™ä¸€å›°éš¾æºäºå¤§è§„æ¨¡ã€æ³¨é‡Šçš„3D&#x2F;4Dæˆ–å¤šè§†å›¾æ•°æ®é›†çš„æœ‰é™å¯ç”¨æ€§ï¼Œè¿™äº›æ•°æ®é›†å¯¹äºé€šç”¨è§†è§‰å’Œè¯­è¨€ä»»åŠ¡ï¼ˆå¦‚å¼€æ”¾è¯æ±‡è¡¨å’ŒåŸºäºæç¤ºçš„åˆ†å‰²ã€è¯­è¨€æŒ‡å¯¼ç¼–è¾‘ä»¥åŠè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ï¼‰è‡³å…³é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Feature4Xï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨å°†ä»»ä½•äºŒç»´è§†è§‰åŸºç¡€æ¨¡å‹çš„åŠŸèƒ½æ‰©å±•åˆ°å››ç»´é¢†åŸŸï¼Œä»…ä½¿ç”¨æ¥è‡ªç”¨æˆ·ç”Ÿæˆå†…å®¹çš„å•ç›®è§†é¢‘è¾“å…¥ã€‚â€œXâ€åœ¨Feature4Xä¸­ä»£è¡¨äº†å…¶é€šç”¨æ€§ï¼Œå¯é€šè¿‡å¯é€‚åº”çš„ã€æ¨¡å‹æ§åˆ¶çš„å››ç»´ç‰¹å¾åœºè’¸é¦æ¥å¯ç”¨ä»»ä½•ä»»åŠ¡ã€‚æˆ‘ä»¬æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€ç§åŠ¨æ€ä¼˜åŒ–ç­–ç•¥ï¼Œå®ƒå°†å¤šç§æ¨¡å‹èƒ½åŠ›æ•´åˆåˆ°å•ä¸€è¡¨ç¤ºä¸­ã€‚æ­¤å¤–ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒFeature4Xæ˜¯ç¬¬ä¸€ç§é€šè¿‡é«˜æ–¯å–·ç»˜å°†è§†é¢‘åŸºç¡€æ¨¡å‹ï¼ˆå¦‚SAM2ã€InternVideo2ï¼‰çš„ç‰¹å¾æç‚¼å¹¶æå‡åˆ°æ˜ç¡®çš„å››ç»´ç‰¹å¾åœºçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„å®éªŒå±•ç¤ºäº†åœ¨æ‰€æœ‰è¿™äº›æ—¶é—´æ­¥é•¿ä¸­çš„æ–°é¢–è§†å›¾åˆ†å‰²ã€å‡ ä½•å’Œå¤–è§‚åœºæ™¯ç¼–è¾‘ä»¥åŠè‡ªç”±å½¢å¼çš„VQAï¼Œè¿™äº›è¿›æ­¥é€šè¿‡åé¦ˆå¾ªç¯ä¸­çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¾—ä»¥å¢å¼ºã€‚è¿™äº›è¿›å±•ä¸ºæ„å»ºå¯æ‰©å±•çš„ã€ä¸Šä¸‹æ–‡å’Œæ—¶ç©ºæ„ŸçŸ¥ç³»ç»Ÿæä¾›äº†åŸºç¡€ï¼Œè¿™äº›ç³»ç»Ÿèƒ½å¤Ÿè¿›è¡Œæ²‰æµ¸å¼åŠ¨æ€å››ç»´åœºæ™¯äº¤äº’ï¼Œä»è€Œæ‹“å®½äº†æ™ºèƒ½ä½“AIåº”ç”¨çš„èŒƒå›´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20776v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Feature4Xæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯å°†ä»»ä½•äºŒç»´è§†è§‰åŸºç¡€æ¨¡å‹çš„åŠŸèƒ½æ‰©å±•åˆ°å››ç»´é¢†åŸŸï¼Œä»…ä½¿ç”¨å•ç›®è§†é¢‘è¾“å…¥ã€‚è¯¥æ¡†æ¶å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€šè¿‡å¯é€‚åº”çš„ã€æ¨¡å‹æ¡ä»¶åŒ–çš„å››ç»´ç‰¹å¾åœºè’¸é¦å®ç°ä»»ä½•ä»»åŠ¡ã€‚å…¶æ ¸å¿ƒæ˜¯åŠ¨æ€ä¼˜åŒ–ç­–ç•¥ï¼Œèƒ½å¤Ÿç»Ÿä¸€å¤šç§æ¨¡å‹èƒ½åŠ›åˆ°å•ä¸€è¡¨ç¤ºä¸­ã€‚æ­¤å¤–ï¼ŒFeature4Xæ˜¯é¦–ä¸ªä½¿ç”¨é«˜æ–¯æ‹¼è´´æ³•æç‚¼å’Œæå‡è§†é¢‘åŸºç¡€æ¨¡å‹ç‰¹å¾åˆ°æ˜ç¡®å››ç»´ç‰¹å¾åœºçš„æ–¹æ³•ã€‚å®éªŒå±•ç¤ºäº†å…¨æ™¯åˆ†æ®µã€å‡ ä½•å’Œå¤–è§‚åœºæ™¯ç¼–è¾‘ä»¥åŠè‡ªç”±å½¢å¼çš„è·¨æ—¶é—´æ­¥éª¤çš„è§†è§‰é—®ç­”ï¼Œè¿™äº›è¿›æ­¥é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹åé¦ˆå¾ªç¯èµ‹èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Feature4Xæ¡†æ¶æˆåŠŸå°†äºŒç»´å’Œå¤šåŠŸèƒ½æ¨¡å‹çš„æˆå°±æ‰©å±•åˆ°å››ç»´é¢†åŸŸï¼Œåº”å¯¹å¤æ‚å››ç»´åœºæ™¯çš„è‡ªç”±å½¢å¼äº¤äº’å’Œé«˜å±‚æ¬¡è¯­ä¹‰æ“ä½œæŒ‘æˆ˜ã€‚</li>
<li>è¯¥æ¡†æ¶è®¾è®¡ç”¨äºä½¿ç”¨å¹¿æ³›å¯ç”¨çš„å•ç›®è§†é¢‘è¾“å…¥ï¼Œå…·æœ‰é€šç”¨æ€§ï¼Œèƒ½å¤Ÿé€‚åº”å„ç§ä»»åŠ¡ã€‚</li>
<li>æ ¸å¿ƒçš„åŠ¨æ€ä¼˜åŒ–ç­–ç•¥èƒ½å¤Ÿç»Ÿä¸€å¤šç§æ¨¡å‹èƒ½åŠ›åˆ°å•ä¸€è¡¨ç¤ºä¸­ã€‚</li>
<li>Feature4Xä½¿ç”¨äº†é«˜æ–¯æ‹¼è´´æ³•ï¼Œæ˜¯é¦–ä¸ªå°†è§†é¢‘åŸºç¡€æ¨¡å‹ç‰¹å¾æç‚¼å¹¶æå‡åˆ°æ˜ç¡®å››ç»´ç‰¹å¾åœºçš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ¡†æ¶æ”¯æŒå…¨æ™¯åˆ†æ®µã€å‡ ä½•å’Œå¤–è§‚åœºæ™¯ç¼–è¾‘ç­‰åŠŸèƒ½ã€‚</li>
<li>é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹åé¦ˆå¾ªç¯ï¼Œå®ç°äº†è·¨æ—¶é—´æ­¥éª¤çš„è‡ªç”±å½¢å¼è§†è§‰é—®ç­”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20776">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c096a239a8c557c396aeb6498ced8fe1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d38d8fc90019b0e50ed506b98730cd2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e9c83554d5da972b7a4eac7463a35b0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4bda7cc05c9d32c7f1cc9cea2135f6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab43db0ee7d2b3b0079489ed831a07ef.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="TAMA-A-Human-AI-Collaborative-Thematic-Analysis-Framework-Using-Multi-Agent-LLMs-for-Clinical-Interviews"><a href="#TAMA-A-Human-AI-Collaborative-Thematic-Analysis-Framework-Using-Multi-Agent-LLMs-for-Clinical-Interviews" class="headerlink" title="TAMA: A Human-AI Collaborative Thematic Analysis Framework Using   Multi-Agent LLMs for Clinical Interviews"></a>TAMA: A Human-AI Collaborative Thematic Analysis Framework Using   Multi-Agent LLMs for Clinical Interviews</h2><p><strong>Authors:Huimin Xu, Seungjun Yi, Terence Lim, Jiawei Xu, Andrew Well, Carlos Mery, Aidong Zhang, Yuji Zhang, Heng Ji, Keshav Pingali, Yan Leng, Ying Ding</strong></p>
<p>Thematic analysis (TA) is a widely used qualitative approach for uncovering latent meanings in unstructured text data. TA provides valuable insights in healthcare but is resource-intensive. Large Language Models (LLMs) have been introduced to perform TA, yet their applications in healthcare remain unexplored. Here, we propose TAMA: A Human-AI Collaborative Thematic Analysis framework using Multi-Agent LLMs for clinical interviews. We leverage the scalability and coherence of multi-agent systems through structured conversations between agents and coordinate the expertise of cardiac experts in TA. Using interview transcripts from parents of children with Anomalous Aortic Origin of a Coronary Artery (AAOCA), a rare congenital heart disease, we demonstrate that TAMA outperforms existing LLM-assisted TA approaches, achieving higher thematic hit rate, coverage, and distinctiveness. TAMA demonstrates strong potential for automated TA in clinical settings by leveraging multi-agent LLM systems with human-in-the-loop integration by enhancing quality while significantly reducing manual workload. </p>
<blockquote>
<p>ä¸»é¢˜åˆ†æï¼ˆTAï¼‰æ˜¯ä¸€ç§å¹¿æ³›åº”ç”¨äºæ— ç»“æ„æ–‡æœ¬æ•°æ®ä¸­æŒ–æ˜æ½œåœ¨å«ä¹‰çš„å®šæ€§æ–¹æ³•ã€‚TAåœ¨åŒ»ç–—ä¿å¥é¢†åŸŸæä¾›äº†å®è´µçš„è§è§£ï¼Œä½†èµ„æºå¯†é›†ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»è¢«å¼•å…¥æ¥è¿›è¡ŒTAï¼Œä½†å®ƒä»¬åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸçš„åº”ç”¨ä»ç„¶æœªè¢«æ¢ç´¢ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†ä½¿ç”¨å¤šæ™ºèƒ½ä½“çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä¸´åºŠè®¿è°ˆçš„ä¸»é¢˜åˆ†ææ¡†æ¶TAMAï¼šäººæœºååŒä¸»é¢˜åˆ†ææ¡†æ¶ã€‚æˆ‘ä»¬é€šè¿‡æ™ºèƒ½ä½“ä¹‹é—´çš„ç»“æ„åŒ–å¯¹è¯ï¼Œåˆ©ç”¨å¤šæ™ºèƒ½ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œè¿è´¯æ€§ï¼Œå¹¶åè°ƒå¿ƒè„ç—…ä¸“å®¶åœ¨ä¸»é¢˜åˆ†ææ–¹é¢çš„ä¸“ä¸šçŸ¥è¯†ã€‚æˆ‘ä»¬ä½¿ç”¨æ‚£æœ‰ç½•è§å…ˆå¤©æ€§å¿ƒè„ç–¾ç—…å¼‚å¸¸ä¸»åŠ¨è„‰å† çŠ¶åŠ¨è„‰èµ·æºç—‡ï¼ˆAAOCAï¼‰çš„å„¿ç«¥çš„çˆ¶æ¯è®¿è°ˆè®°å½•ï¼Œè¯æ˜TAMAåœ¨ä¸»é¢˜å‘½ä¸­ç‡ã€è¦†ç›–ç‡å’Œç‹¬ç‰¹æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©TAæ–¹æ³•ã€‚TAMAé€šè¿‡åˆ©ç”¨å¤šæ™ºèƒ½å¤§å‹è¯­è¨€ç³»ç»Ÿï¼ŒåŒæ—¶é€šè¿‡äººæœºé›†æˆç¯å¢å¼ºè´¨é‡å¹¶æ˜¾è‘—å‡å°‘æ‰‹åŠ¨å·¥ä½œé‡ï¼Œåœ¨è¯Šæ‰€ç¯å¢ƒä¸­è¿›è¡Œè‡ªåŠ¨åŒ–ä¸»é¢˜åˆ†ææ–¹é¢æ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20666v1">PDF</a> Submitted to the American Medical Informatics Association (AMIA) 2025   Annual Symposium, 10 pages</p>
<p><strong>Summary</strong><br>ä¸»é¢˜åˆ†æï¼ˆTAï¼‰æ˜¯æŒ–æ˜æ— ç»“æ„æ–‡æœ¬æ•°æ®ä¸­æ½œåœ¨å«ä¹‰çš„å¸¸ç”¨å®šæ€§æ–¹æ³•ã€‚å®ƒå¯¹äºåŒ»ç–—é¢†åŸŸå…·æœ‰æé«˜çš„ä»·å€¼ï¼Œä½†èµ„æºæ¶ˆè€—å¤§ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²è¢«å¼•å…¥è¿›è¡Œä¸»é¢˜åˆ†æï¼Œä½†åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä»å¾…æ¢ç´¢ã€‚æœ¬æ–‡æå‡ºä½¿ç”¨åŸºäºå¤šæ™ºèƒ½ä½“çš„è¯­è¨€æ¨¡å‹çš„å¤§å‹ä¸»é¢˜åˆ†ææ¡†æ¶TAMAï¼Œç»“åˆäººæœºååŒè¿›è¡Œä¸´åºŠè®¿è°ˆçš„ä¸»é¢˜åˆ†æã€‚é€šè¿‡æ™ºèƒ½ä½“é—´çš„ç»“æ„åŒ–å¯¹è¯ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤šæ™ºèƒ½ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œä¸€è‡´æ€§ï¼Œå¹¶åè°ƒå¿ƒè„ç—…å­¦ä¸“å®¶è¿›è¡Œä¸»é¢˜åˆ†æã€‚ä½¿ç”¨æ‚£æœ‰ç½•è§å…ˆå¤©æ€§å¿ƒè„ç–¾ç—…â€”â€”å¼‚å¸¸ä¸»åŠ¨è„‰èµ·æºå† çŠ¶åŠ¨è„‰ï¼ˆAAOCAï¼‰çš„å„¿ç«¥çš„çˆ¶æ¯è®¿è°ˆè®°å½•è¿›è¡Œæ¼”ç¤ºï¼Œè¯æ˜TAMAä¼˜äºç°æœ‰çš„LLMè¾…åŠ©ä¸»é¢˜åˆ†ææ–¹æ³•ï¼Œå…·æœ‰æ›´é«˜çš„ä¸»é¢˜å‘½ä¸­ç‡ã€è¦†ç›–ç‡å’Œç‹¬ç‰¹æ€§ã€‚é€šè¿‡åˆ©ç”¨äººæœºå¾ªç¯é›†æˆçš„å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿï¼ŒTAMAåœ¨å‡è½»äººå·¥å·¥ä½œé‡çš„åŒæ—¶æé«˜è´¨é‡ï¼Œåœ¨ä¸´åºŠåŒ»å­¦è‡ªåŠ¨åŒ–ä¸»é¢˜åˆ†æä¸­å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸»é¢˜åˆ†æï¼ˆTAï¼‰æ˜¯ä¸€ç§æŒ–æ˜æ— ç»“æ„æ–‡æœ¬æ•°æ®ä¸­æ½œåœ¨å«ä¹‰çš„å®šæ€§æ–¹æ³•ï¼Œå¹¿æ³›åº”ç”¨äºåŒ»ç–—é¢†åŸŸã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸»é¢˜åˆ†æä¸­çš„åº”ç”¨å°šæœªåœ¨åŒ»ç–—é¢†åŸŸå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>TAMAæ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“çš„è¯­è¨€æ¨¡å‹çš„å¤§å‹ä¸»é¢˜åˆ†ææ¡†æ¶ï¼Œç»“åˆäº†äººæœºååŒè¿›è¡Œä¸´åºŠè®¿è°ˆçš„ä¸»é¢˜åˆ†æã€‚</li>
<li>TAMAåˆ©ç”¨å¤šæ™ºèƒ½ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œä¸€è‡´æ€§ï¼Œé€šè¿‡æ™ºèƒ½ä½“é—´çš„ç»“æ„åŒ–å¯¹è¯å®ç°é«˜æ•ˆçš„ä¸»é¢˜åˆ†æã€‚</li>
<li>TAMAåœ¨å¿ƒè„ç—…é¢†åŸŸçš„åº”ç”¨ä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•å…·æœ‰æ›´é«˜çš„ä¸»é¢˜å‘½ä¸­ç‡ã€è¦†ç›–ç‡å’Œç‹¬ç‰¹æ€§ã€‚</li>
<li>TAMAé€šè¿‡äººæœºå¾ªç¯é›†æˆæé«˜åˆ†æè´¨é‡ï¼ŒåŒæ—¶æ˜¾è‘—å‡è½»äººå·¥å·¥ä½œé‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20666">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0814ff304d27c6f1078e672d98ff3a77.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2cd7db83cef869a9e9dbb7a653df0175.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55ce015910d46b535989b93ea600450d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aec749ce90f742210189342b1b61952f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45df6e64deb1d85b3f5759c3d8ceee22.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Harmonia-A-Multi-Agent-Reinforcement-Learning-Approach-to-Data-Placement-and-Migration-in-Hybrid-Storage-Systems"><a href="#Harmonia-A-Multi-Agent-Reinforcement-Learning-Approach-to-Data-Placement-and-Migration-in-Hybrid-Storage-Systems" class="headerlink" title="Harmonia: A Multi-Agent Reinforcement Learning Approach to Data   Placement and Migration in Hybrid Storage Systems"></a>Harmonia: A Multi-Agent Reinforcement Learning Approach to Data   Placement and Migration in Hybrid Storage Systems</h2><p><strong>Authors:Rakesh Nadig, Vamanan Arulchelvan, Rahul Bera, Taha Shahroodi, Gagandeep Singh, Mohammad Sadrosadati, Jisung Park, Onur Mutlu</strong></p>
<p>Hybrid storage systems (HSS) combine multiple storage devices with diverse characteristics to achieve high performance and capacity at low cost. The performance of an HSS highly depends on the effectiveness of two key policies: (1) the data-placement policy, which determines the best-fit storage device for incoming data, and (2) the data-migration policy, which rearranges stored data across the devices to sustain high HSS performance. Prior works focus on improving only data placement or only data migration in HSS, which leads to sub-optimal HSS performance. Unfortunately, no prior work tries to optimize both policies together. Our goal is to design a holistic data-management technique for HSS that optimizes both data-placement and data-migration policies to fully exploit the potential of an HSS. We propose Harmonia, a multi-agent reinforcement learning (RL)-based data-management technique that employs two light-weight autonomous RL agents, a data-placement agent and a data-migration agent, which adapt their policies for the current workload and HSS configuration, and coordinate with each other to improve overall HSS performance. We evaluate Harmonia on a real HSS with up to four heterogeneous storage devices with diverse characteristics. Our evaluation using 17 data-intensive workloads on performance-optimized (cost-optimized) HSS with two storage devices shows that, on average, Harmonia (1) outperforms the best-performing prior approach by 49.5% (31.7%), (2) bridges the performance gap between the best-performing prior work and Oracle by 64.2% (64.3%). On an HSS with three (four) devices, Harmonia outperforms the best-performing prior work by 37.0% (42.0%). Harmoniaâ€™s performance benefits come with low latency (240ns for inference) and storage overheads (206 KiB for both RL agents together). We plan to open-source Harmoniaâ€™s implementation to aid future research on HSS. </p>
<blockquote>
<p>æ··åˆå­˜å‚¨ç³»ç»Ÿï¼ˆHSSï¼‰ç»“åˆäº†å¤šç§ä¸åŒç‰¹æ€§çš„å­˜å‚¨è®¾å¤‡ï¼Œä»¥ä½æˆæœ¬å®ç°é«˜æ€§èƒ½å’Œé«˜å®¹é‡ã€‚HSSçš„æ€§èƒ½é«˜åº¦å–å†³äºä¸¤ä¸ªå…³é”®ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼šï¼ˆ1ï¼‰æ•°æ®æ”¾ç½®ç­–ç•¥ï¼Œå®ƒå†³å®šäº†ä¼ å…¥æ•°æ®çš„æœ€ä½³å­˜å‚¨è®¾å¤‡ï¼›ï¼ˆ2ï¼‰æ•°æ®è¿ç§»ç­–ç•¥ï¼Œå®ƒé‡æ–°æ’åˆ—å­˜å‚¨åœ¨å„è®¾å¤‡ä¸Šçš„æ•°æ®ä»¥ç»´æŒé«˜HSSæ€§èƒ½ã€‚æ—©æœŸçš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æ”¹è¿›HSSä¸­çš„ä»…æ•°æ®æ”¾ç½®æˆ–ä»…æ•°æ®è¿ç§»ï¼Œè¿™å¯¼è‡´HSSæ€§èƒ½ä¸ä½³ã€‚ç„¶è€Œï¼Œé—æ†¾çš„æ˜¯ï¼Œæ²¡æœ‰æ—©æœŸçš„å·¥ä½œå°è¯•åŒæ—¶ä¼˜åŒ–è¿™ä¸¤ç§ç­–ç•¥ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®¾è®¡ä¸€ç§å…¨é¢çš„æ•°æ®ç®¡ç†æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å¯é’ˆå¯¹HSSåŒæ—¶ä¼˜åŒ–æ•°æ®æ”¾ç½®å’Œæ•°æ®è¿ç§»ç­–ç•¥ï¼Œä»¥å……åˆ†åˆ©ç”¨HSSçš„æ½œåŠ›ã€‚æˆ‘ä»¬æå‡ºäº†Harmoniaï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ•°æ®ç®¡ç†æŠ€æœ¯ï¼Œå®ƒé‡‡ç”¨ä¸¤ä¸ªè½»é‡çº§çš„è‡ªä¸»RLæ™ºèƒ½ä½“ï¼Œå³æ•°æ®æ”¾ç½®æ™ºèƒ½ä½“å’Œæ•°æ®è¿ç§»æ™ºèƒ½ä½“ï¼Œè¿™ä¸¤ä¸ªæ™ºèƒ½ä½“èƒ½é€‚åº”å½“å‰çš„å·¥ä½œè´Ÿè½½å’ŒHSSé…ç½®ï¼Œå¹¶ç›¸äº’åè°ƒä»¥æé«˜HSSçš„æ•´ä½“æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨å…·æœ‰å¤šè¾¾å››ç§ä¸åŒç‰¹æ€§çš„å¼‚æ„å­˜å‚¨è®¾å¤‡çš„çœŸå®HSSä¸Šè¯„ä¼°äº†Harmoniaã€‚æˆ‘ä»¬å¯¹æ€§èƒ½ä¼˜åŒ–ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰çš„HSSä½¿ç”¨17ä¸ªæ•°æ®å¯†é›†å‹å·¥ä½œè´Ÿè½½è¿›è¡Œçš„è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºï¼Œåœ¨å¹³å‡æƒ…å†µä¸‹ï¼ŒHarmoniaï¼ˆ1ï¼‰æ¯”æœ€ä½³çš„å‰æœŸæ–¹æ³•é«˜å‡º49.5%ï¼ˆ31.7%ï¼‰ï¼Œï¼ˆ2ï¼‰ç¼©å°äº†æœ€ä½³å‰æœŸå·¥ä½œä¸Oracleä¹‹é—´çš„æ€§èƒ½å·®è·64.2%ï¼ˆ64.3%ï¼‰ã€‚åœ¨å…·æœ‰ä¸‰ä¸ªï¼ˆå››ä¸ªï¼‰è®¾å¤‡çš„HSSä¸Šï¼ŒHarmoniaæ¯”æœ€ä½³çš„å‰æœŸæ–¹æ³•é«˜å‡º37.0%ï¼ˆ42.0%ï¼‰ã€‚Harmoniaçš„æ€§èƒ½ä¼˜åŠ¿å…·æœ‰ä½å»¶è¿Ÿï¼ˆæ¨ç†å»¶è¿Ÿä¸º240nsï¼‰å’Œä½çš„å­˜å‚¨å¼€é”€ï¼ˆä¸¤ä¸ªRLæ™ºèƒ½ä½“çš„æ€»å¤§å°ä¸º206KiBï¼‰ã€‚æˆ‘ä»¬è®¡åˆ’å…¬å¼€Harmoniaçš„å®ç°æºä»£ç ï¼Œä»¥å¸®åŠ©æœªæ¥çš„HSSç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20507v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ··åˆå­˜å‚¨ç³»ç»Ÿï¼ˆHSSï¼‰é€šè¿‡ç»“åˆå¤šç§å…·æœ‰ä¸åŒç‰¹æ€§çš„å­˜å‚¨è®¾å¤‡ï¼Œä»¥å®ç°é«˜æ€§èƒ½å’Œä½æˆæœ¬å¤§å®¹é‡ã€‚HSSçš„æ€§èƒ½å–å†³äºæ•°æ®æ”¾ç½®ç­–ç•¥å’Œæ•°æ®è¿ç§»ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦å…³æ³¨æ”¹è¿›HSSä¸­çš„æ•°æ®æ”¾ç½®æˆ–æ•°æ®è¿ç§»ï¼Œè¿™å¯¼è‡´HSSæ€§èƒ½ä¸ä½³ã€‚ç„¶è€Œï¼Œæ²¡æœ‰ç ”ç©¶å°è¯•åŒæ—¶ä¼˜åŒ–è¿™ä¸¤ç§ç­–ç•¥ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®¾è®¡ä¸€ç§å…¨é¢çš„HSSæ•°æ®ç®¡ç†æŠ€æœ¯ï¼Œä¼˜åŒ–æ•°æ®æ”¾ç½®å’Œæ•°æ®è¿ç§»ç­–ç•¥ï¼Œä»¥å……åˆ†åˆ©ç”¨HSSçš„æ½œåŠ›ã€‚æˆ‘ä»¬æå‡ºHarmonyï¼Œä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ•°æ®ç®¡ç†æŠ€æœ¯ï¼Œé‡‡ç”¨ä¸¤ä¸ªè½»é‡çº§çš„è‡ªä¸»RLæ™ºèƒ½ä½“ï¼Œæ•°æ®æ”¾ç½®æ™ºèƒ½ä½“å’Œæ•°æ®è¿ç§»æ™ºèƒ½ä½“ï¼Œå®ƒä»¬æ ¹æ®å½“å‰å·¥ä½œè´Ÿè½½å’ŒHSSé…ç½®è‡ªé€‚åº”è°ƒæ•´ç­–ç•¥ï¼Œå¹¶ç›¸äº’åè°ƒï¼Œä»¥æé«˜HSSçš„æ•´ä½“æ€§èƒ½ã€‚åœ¨å…·æœ‰å¤šè¾¾å››ä¸ªå¼‚æ„å­˜å‚¨è®¾å¤‡çš„çœŸå®HSSä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒHarmonyåœ¨æ€§èƒ½ä¼˜åŒ–å’Œæˆæœ¬ä¼˜åŒ–çš„HSSä¸Šå¹³å‡ä¼˜äºæœ€ä½³å…ˆå‰æ–¹æ³•49.5%å’Œ31.7%ï¼Œå¹¶ç¼©å°äº†ä¸Oracleçš„æœ€ä½³å…ˆå‰å·¥ä½œå’ŒOracleä¹‹é—´çš„æ€§èƒ½å·®è·64.2%å’Œ64.3%ã€‚åœ¨å…·æœ‰ä¸‰ä¸ªæˆ–å››ä¸ªè®¾å¤‡çš„HSSä¸Šï¼ŒHarmonyä¼˜äºæœ€ä½³å…ˆå‰æ–¹æ³•37.0%å’Œ42.0%ã€‚Harmonyçš„æ€§èƒ½ä¼˜åŠ¿å…·æœ‰ä½å»¶è¿Ÿï¼ˆæ¨ç†å»¶è¿Ÿä¸º240nsï¼‰å’Œè¾ƒä½çš„å­˜å‚¨å¼€é”€ï¼ˆä¸¤ä¸ªRLæ™ºèƒ½ä½“çš„æ€»å­˜å‚¨å¼€é”€ä¸º206KiBï¼‰ã€‚æˆ‘ä»¬è®¡åˆ’å¼€æºHarmonyçš„å®ç°ï¼Œä»¥åŠ©åŠ›æœªæ¥å…³äºHSSçš„ç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ··åˆå­˜å‚¨ç³»ç»Ÿï¼ˆHSSï¼‰ç»“åˆå¤šç§å­˜å‚¨è®¾å¤‡ä»¥æé«˜æ€§èƒ½å’Œé™ä½æˆæœ¬ã€‚</li>
<li>HSSæ€§èƒ½å–å†³äºæ•°æ®æ”¾ç½®å’Œæ•°æ®è¿ç§»ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ç°æœ‰ç ”ç©¶æœªåŒæ—¶ä¼˜åŒ–æ•°æ®æ”¾ç½®å’Œæ•°æ®è¿ç§»ç­–ç•¥ã€‚</li>
<li>æå‡ºHarmonyæ•°æ®ç®¡ç†æŠ€æœ¯ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ•°æ®æ”¾ç½®å’Œæ•°æ®è¿ç§»ç­–ç•¥ã€‚</li>
<li>Harmonyåœ¨å…·æœ‰ä¸åŒè®¾å¤‡æ•°é‡çš„HSSä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¼˜äºå…¶ä»–æœ€ä½³æ–¹æ³•ã€‚</li>
<li>Harmonyå…·æœ‰ä½å»¶è¿Ÿå’Œè¾ƒä½çš„å­˜å‚¨å¼€é”€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20507">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4ec53857d3b5ae2f4c9fbae8832f4867.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ebc9a4f383cf321a76092880a74fdf3f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ccf804bee975776b077247bfbaaa063.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de9bdfdf48affb05109a88d12d8c9f68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6d2a1fbbf9cc405af6085baf9429668.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6812d97dfba63ab95900689c31e3a0b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f1ff000676ffe267ba5f945fa3079ba.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multi-agent-Uncertainty-Aware-Pessimistic-Model-Based-Reinforcement-Learning-for-Connected-Autonomous-Vehicles"><a href="#Multi-agent-Uncertainty-Aware-Pessimistic-Model-Based-Reinforcement-Learning-for-Connected-Autonomous-Vehicles" class="headerlink" title="Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement   Learning for Connected Autonomous Vehicles"></a>Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement   Learning for Connected Autonomous Vehicles</h2><p><strong>Authors:Ruoqi Wen, Rongpeng Li, Xing Xu, Zhifeng Zhao</strong></p>
<p>Deep Reinforcement Learning (DRL) holds significant promise for achieving human-like Autonomous Vehicle (AV) capabilities, but suffers from low sample efficiency and challenges in reward design. Model-Based Reinforcement Learning (MBRL) offers improved sample efficiency and generalizability compared to Model-Free Reinforcement Learning (MFRL) in various multi-agent decision-making scenarios. Nevertheless, MBRL faces critical difficulties in estimating uncertainty during the model learning phase, thereby limiting its scalability and applicability in real-world scenarios. Additionally, most Connected Autonomous Vehicle (CAV) studies focus on single-agent decision-making, while existing multi-agent MBRL solutions lack computationally tractable algorithms with Probably Approximately Correct (PAC) guarantees, an essential factor for ensuring policy reliability with limited training data. To address these challenges, we propose MA-PMBRL, a novel Multi-Agent Pessimistic Model-Based Reinforcement Learning framework for CAVs, incorporating a max-min optimization approach to enhance robustness and decision-making. To mitigate the inherent subjectivity of uncertainty estimation in MBRL and avoid incurring catastrophic failures in AV, MA-PMBRL employs a pessimistic optimization framework combined with Projected Gradient Descent (PGD) for both model and policy learning. MA-PMBRL also employs general function approximations under partial dataset coverage to enhance learning efficiency and system-level performance. By bounding the suboptimality of the resulting policy under mild theoretical assumptions, we successfully establish PAC guarantees for MA-PMBRL, demonstrating that the proposed framework represents a significant step toward scalable, efficient, and reliable multi-agent decision-making for CAVs. </p>
<blockquote>
<p>æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰åœ¨å®ç°äººç±»çº§åˆ«çš„è‡ªåŠ¨é©¾é©¶ï¼ˆAVï¼‰èƒ½åŠ›æ–¹é¢æœ‰ç€å·¨å¤§çš„æ½œåŠ›ï¼Œä½†å­˜åœ¨ç€æ ·æœ¬æ•ˆç‡ä½ä¸‹å’Œå¥–åŠ±è®¾è®¡æ–¹é¢çš„æŒ‘æˆ˜ã€‚åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼ˆMBRLï¼‰åœ¨å„ç§å¤šæ™ºèƒ½ä½“å†³ç­–åœºæ™¯ä¸­ä¸æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼ˆMFRLï¼‰ç›¸æ¯”ï¼Œå…·æœ‰æ”¹è¿›çš„æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒMBRLåœ¨æ¨¡å‹å­¦ä¹ é˜¶æ®µä¼°è®¡ä¸ç¡®å®šæ€§æ—¶é¢ä¸´å…³é”®å›°éš¾ï¼Œä»è€Œé™åˆ¶äº†å…¶åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„å¯æ‰©å±•æ€§å’Œé€‚ç”¨æ€§ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°å…³äºæ™ºèƒ½ç½‘è”æ±½è½¦ï¼ˆCAVï¼‰çš„ç ”ç©¶éƒ½é›†ä¸­åœ¨å•æ™ºèƒ½ä½“å†³ç­–ä¸Šï¼Œè€Œç°æœ‰çš„å¤šæ™ºèƒ½ä½“MBRLè§£å†³æ–¹æ¡ˆç¼ºä¹å…·æœ‰æ¦‚ç‡è¿‘ä¼¼æ­£ç¡®ï¼ˆPACï¼‰ä¿è¯çš„è®¡ç®—å¯è¡Œç®—æ³•ï¼Œè¿™æ˜¯ç¡®ä¿åœ¨æœ‰é™è®­ç»ƒæ•°æ®ä¸‹ç­–ç•¥å¯é æ€§çš„å…³é”®å› ç´ ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MA-PMBRLï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ™ºèƒ½ç½‘è”æ±½è½¦çš„æ–°å‹å¤šæ™ºèƒ½ä½“æ‚²è§‚æ¨¡å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå®ƒé‡‡ç”¨æœ€å¤§æœ€å°ä¼˜åŒ–æ–¹æ³•æ¥å¢å¼ºç¨³å¥æ€§å’Œå†³ç­–èƒ½åŠ›ã€‚ä¸ºäº†ç¼“è§£MBRLä¸­ä¸ç¡®å®šæ€§ä¼°è®¡çš„å†…åœ¨ä¸»è§‚æ€§ï¼Œé¿å…è‡ªåŠ¨é©¾é©¶è½¦è¾†å‘ç”Ÿç¾éš¾æ€§æ•…éšœï¼ŒMA-PMBRLé‡‡ç”¨æ‚²è§‚ä¼˜åŒ–æ¡†æ¶ä¸æŠ•å½±æ¢¯åº¦ä¸‹é™æ³•ï¼ˆPGDï¼‰ç›¸ç»“åˆè¿›è¡Œæ¨¡å‹å’Œç­–ç•¥å­¦ä¹ ã€‚MA-PMBRLè¿˜åœ¨éƒ¨åˆ†æ•°æ®é›†è¦†ç›–ä¸‹é‡‡ç”¨é€šç”¨å‡½æ•°è¿‘ä¼¼æŠ€æœ¯æ¥æé«˜å­¦ä¹ æ•ˆç‡å’Œç³»ç»Ÿçº§æ€§èƒ½ã€‚é€šè¿‡åœ¨ä¸€å®šç†è®ºå‡è®¾ä¸‹ç•Œå®šæ‰€å¾—ç­–ç•¥çš„æ¬¡ä¼˜æ€§ï¼Œæˆ‘ä»¬æˆåŠŸä¸ºMA-PMBRLå»ºç«‹äº†PACä¿è¯ï¼Œè¡¨æ˜è¯¥æ¡†æ¶æ˜¯æœç€å¯æ‰©å±•ã€é«˜æ•ˆã€å¯é çš„æ™ºèƒ½ç½‘è”æ±½è½¦å¤šæ™ºèƒ½ä½“å†³ç­–è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20462v1">PDF</a> 17 pages, 7 figures</p>
<p><strong>Summary</strong><br>     æ·±åº¦å­¦ä¹ å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰åœ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†ï¼ˆAVï¼‰æŠ€æœ¯ä¸Šæ½œåŠ›å·¨å¤§ï¼Œä½†åœ¨æ ·æœ¬æ•ˆç‡å’Œå¥–åŠ±è®¾è®¡æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚æ¨¡å‹åŸºç¡€å¼ºåŒ–å­¦ä¹ ï¼ˆMBRLï¼‰åœ¨å¤šç§å¤šæ™ºèƒ½ä½“å†³ç­–åœºæ™¯ä¸­ï¼Œç›¸è¾ƒäºæ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼ˆMFRLï¼‰å…·æœ‰æ›´é«˜çš„æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒMBRLåœ¨æ¨¡å‹å­¦ä¹ é˜¶æ®µé¢ä¸´ä¼°ç®—ä¸ç¡®å®šæ€§çš„å›°éš¾ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„å¯æ‰©å±•æ€§å’Œé€‚ç”¨æ€§ã€‚é’ˆå¯¹æ­¤ï¼Œæˆ‘ä»¬æå‡ºMA-PMBRLï¼Œè¿™æ˜¯ä¸€ç§ä¸ºè¿æ¥è‡ªåŠ¨é©¾é©¶è½¦è¾†ï¼ˆCAVï¼‰è®¾è®¡çš„æ–°å‹å¤šæ™ºèƒ½ä½“æ‚²è§‚æ¨¡å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé‡‡ç”¨æœ€å¤§æœ€å°ä¼˜åŒ–æ–¹æ³•æé«˜ç¨³å¥æ€§å’Œå†³ç­–èƒ½åŠ›ã€‚ç»“åˆæŠ•å½±æ¢¯åº¦ä¸‹é™ï¼ˆPGDï¼‰è¿›è¡Œæ¨¡å‹å’Œç­–ç•¥å­¦ä¹ ï¼Œä»¥ç¼“è§£MBRLä¸­ä¸ç¡®å®šæ€§ä¼°è®¡çš„å†…åœ¨ä¸»è§‚æ€§ï¼Œé¿å…è‡ªåŠ¨é©¾é©¶ä¸­çš„ç¾éš¾æ€§æ•…éšœã€‚MA-PMBRLè¿˜é‡‡ç”¨é€šç”¨å‡½æ•°è¿‘ä¼¼æ–¹æ³•æé«˜å­¦ä¹ æ•ˆç‡å’Œç³»ç»Ÿæ€§èƒ½ã€‚æˆ‘ä»¬æˆåŠŸå»ºç«‹äº†MA-PMBRLçš„ç†è®ºä¿è¯ï¼Œè¯æ˜è¯¥æ¡†æ¶æ˜¯æœç€å¯æ‰©å±•ã€é«˜æ•ˆå’Œå¯é çš„è‡ªåŠ¨é©¾é©¶å¤šæ™ºèƒ½ä½“å†³ç­–çš„é‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DRLåœ¨è‡ªåŠ¨é©¾é©¶æŠ€æœ¯ä¸­æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†é¢ä¸´æ ·æœ¬æ•ˆç‡å’Œå¥–åŠ±è®¾è®¡æŒ‘æˆ˜ã€‚</li>
<li>MBRLç›¸è¾ƒäºMFRLåœ¨æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ä¸Šæœ‰ä¼˜åŠ¿ã€‚</li>
<li>MBRLåœ¨æ¨¡å‹å­¦ä¹ é˜¶æ®µé¢ä¸´ä¼°ç®—ä¸ç¡®å®šæ€§çš„å›°éš¾ã€‚</li>
<li>MA-PMBRLæ¡†æ¶é€šè¿‡æœ€å¤§æœ€å°ä¼˜åŒ–æ–¹æ³•æé«˜ç¨³å¥æ€§å’Œå†³ç­–èƒ½åŠ›ã€‚</li>
<li>MA-PMBRLç»“åˆæŠ•å½±æ¢¯åº¦ä¸‹é™ï¼ˆPGDï¼‰è¿›è¡Œæ¨¡å‹å’Œç­–ç•¥å­¦ä¹ ï¼Œä»¥ç¼“è§£ä¸ç¡®å®šæ€§ä¼°è®¡çš„ä¸»è§‚æ€§ã€‚</li>
<li>MA-PMBRLé‡‡ç”¨é€šç”¨å‡½æ•°è¿‘ä¼¼æ–¹æ³•æé«˜å­¦ä¹ æ•ˆç‡å’Œç³»ç»Ÿæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20462">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6524dcef13b8092aeb79c1a895802b9d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-491fa552d053f11d85999f3fed202843.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-acc5ded0f2500a66f4f32d77991df2fa.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Open-Deep-Search-Democratizing-Search-with-Open-source-Reasoning-Agents"><a href="#Open-Deep-Search-Democratizing-Search-with-Open-source-Reasoning-Agents" class="headerlink" title="Open Deep Search: Democratizing Search with Open-source Reasoning Agents"></a>Open Deep Search: Democratizing Search with Open-source Reasoning Agents</h2><p><strong>Authors:Salaheddin Alzubi, Creston Brooks, Purva Chiniya, Edoardo Contente, Chiara von Gerlach, Lucas Irwin, Yihan Jiang, Arda Kaz, Windsor Nguyen, Sewoong Oh, Himanshu Tyagi, Pramod Viswanath</strong></p>
<p>We introduce Open Deep Search (ODS) to close the increasing gap between the proprietary search AI solutions, such as Perplexityâ€™s Sonar Reasoning Pro and OpenAIâ€™s GPT-4o Search Preview, and their open-source counterparts. The main innovation introduced in ODS is to augment the reasoning capabilities of the latest open-source LLMs with reasoning agents that can judiciously use web search tools to answer queries. Concretely, ODS consists of two components that work with a base LLM chosen by the user: Open Search Tool and Open Reasoning Agent. Open Reasoning Agent interprets the given task and completes it by orchestrating a sequence of actions that includes calling tools, one of which is the Open Search Tool. Open Search Tool is a novel web search tool that outperforms proprietary counterparts. Together with powerful open-source reasoning LLMs, such as DeepSeek-R1, ODS nearly matches and sometimes surpasses the existing state-of-the-art baselines on two benchmarks: SimpleQA and FRAMES. For example, on the FRAMES evaluation benchmark, ODS improves the best existing baseline of the recently released GPT-4o Search Preview by 9.7% in accuracy. ODS is a general framework for seamlessly augmenting any LLMs â€“ for example, DeepSeek-R1 that achieves 82.4% on SimpleQA and 30.1% on FRAMES â€“ with search and reasoning capabilities to achieve state-of-the-art performance: 88.3% on SimpleQA and 75.3% on FRAMES. </p>
<blockquote>
<p>æˆ‘ä»¬å¼•å…¥Open Deep Searchï¼ˆODSï¼‰ï¼Œä»¥ç¼©å°ä¸“æœ‰æœç´¢AIè§£å†³æ–¹æ¡ˆï¼ˆå¦‚Perplexityçš„Sonar Reasoning Proå’ŒOpenAIçš„GPT-4o Search Previewï¼‰ä¸å…¶å¼€æºå¯¹åº”äº§å“ä¹‹é—´æ—¥ç›Šå¢é•¿çš„å·®è·ã€‚ODSçš„ä¸»è¦åˆ›æ–°ä¹‹å¤„åœ¨äºï¼Œé€šè¿‡æ¨ç†ä»£ç†å¢å¼ºæœ€æ–°å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè¿™äº›æ¨ç†ä»£ç†å¯ä»¥è°¨æ…åœ°ä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼ŒODSåŒ…å«ä¸¤ä¸ªä¸ç”¨æˆ·é€‰æ‹©çš„åŸºç¡€å¤§å‹è¯­è¨€æ¨¡å‹ä¸€èµ·å·¥ä½œçš„ç»„ä»¶ï¼šOpen Search Toolå’ŒOpen Reasoning Agentã€‚Open Reasoning Agentè§£é‡Šç»™å®šä»»åŠ¡å¹¶å®Œæˆä»»åŠ¡ï¼Œé€šè¿‡åè°ƒä¸€ç³»åˆ—åŠ¨ä½œæ¥å®Œæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬è°ƒç”¨å·¥å…·ï¼Œå…¶ä¸­ä¹‹ä¸€æ˜¯Open Search Toolã€‚Open Search Toolæ˜¯ä¸€ç§æ–°å‹ç½‘ç»œæœç´¢å·¥å…·ï¼Œå…¶æ€§èƒ½è¶…è¿‡äº†ä¸“æœ‰å·¥å…·ã€‚ä¸å¼ºå¤§çš„å¼€æºæ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚DeepSeek-R1ï¼‰ä¸€èµ·ï¼ŒODSåœ¨SimpleQAå’ŒFRAMESä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡ ä¹è¾¾åˆ°æˆ–æœ‰æ—¶è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯çš„æœ€æ–°æ°´å¹³ã€‚ä¾‹å¦‚ï¼Œåœ¨FRAMESè¯„ä¼°åŸºå‡†æµ‹è¯•ä¸­ï¼ŒODSæé«˜äº†æœ€è¿‘å‘å¸ƒçš„GPT-4o Search Previewçš„æœ€ä½³ç°æœ‰åŸºå‡†çš„å‡†ç¡®åº¦ï¼Œæé«˜äº†9.7%ã€‚ODSæ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥æ— ç¼åœ°å¢å¼ºä»»ä½•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚DeepSeek-R1ï¼‰ï¼Œåœ¨SimpleQAä¸Šè¾¾åˆ°82.4%çš„å‡†ç¡®ç‡å’ŒFRAMESä¸Šçš„30.1%çš„å‡†ç¡®ç‡ï¼‰ï¼Œé€šè¿‡æœç´¢å’Œæ¨ç†èƒ½åŠ›å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼šåœ¨SimpleQAä¸Šè¾¾åˆ°88.3%çš„å‡†ç¡®ç‡å’ŒFRAMESä¸Šçš„75.3%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20201v1">PDF</a> 27 pages, 8 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>åœ¨æ–‡æœ¬ä¸­ï¼Œä»‹ç»äº†Open Deep Searchï¼ˆODSï¼‰æ—¨åœ¨ç¼©å°ä¸“æœ‰æœç´¢AIè§£å†³æ–¹æ¡ˆå’Œå…¶å¼€æºå¯¹åº”æ–¹æ¡ˆä¹‹é—´çš„å·®è·ã€‚ODSçš„ä¸»è¦åˆ›æ–°ä¹‹å¤„åœ¨äºå¢å¼ºæœ€æ–°å¼€æºLLMçš„æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡æ¨ç†ä»£ç†èƒ½å¤Ÿå®¡æ…åœ°ä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚ODSåŒ…å«ä¸¤ä¸ªç»„ä»¶ï¼šOpen Search Toolå’ŒOpen Reasoning Agentï¼Œå®ƒä»¬ä¸ç”¨æˆ·é€‰æ‹©çš„åŸºå‡†LLMä¸€èµ·å·¥ä½œã€‚Open Search Toolæ˜¯ä¸€ç§æ–°å‹çš„ç½‘é¡µæœç´¢å·¥å…·ï¼Œå…¶æ€§èƒ½è¶…è¿‡äº†ä¸“æœ‰æœç´¢å·¥å…·ã€‚é…åˆå¼ºå¤§çš„å¼€æºæ¨ç†LLMï¼Œå¦‚DeepSeek-R1ï¼ŒODSåœ¨SimpleQAå’ŒFRAMESä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°æ¥è¿‘æˆ–è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æ°´å¹³çš„åŸºå‡†çº¿ã€‚ä¾‹å¦‚ï¼Œåœ¨FRAMESè¯„ä¼°åŸºå‡†æµ‹è¯•ä¸­ï¼ŒODSæé«˜äº†æœ€è¿‘å‘å¸ƒçš„GPT-4o Search Previewçš„æœ€ä½³ç°æœ‰åŸºå‡†çº¿çš„å‡†ç¡®æ€§9.7%ã€‚ODSæ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥æ— ç¼åœ°å¢å¼ºä»»ä½•LLMï¼ˆå¦‚DeepSeek-R1ï¼‰çš„æœç´¢å’Œæ¨ç†èƒ½åŠ›ï¼Œä»¥å®ç°æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ODSæ—¨åœ¨ç¼©å°ä¸“æœ‰æœç´¢AIè§£å†³æ–¹æ¡ˆå’Œå¼€æºè§£å†³æ–¹æ¡ˆä¹‹é—´çš„å·®è·ã€‚</li>
<li>ODSé€šè¿‡å¼•å…¥æ¨ç†ä»£ç†ï¼Œå¢å¼ºäº†æœ€æ–°å¼€æºLLMçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ODSåŒ…å«ä¸¤ä¸ªç»„ä»¶ï¼šOpen Search Toolå’ŒOpen Reasoning Agentï¼Œå®ƒä»¬ä¸LLMä¸€èµ·å·¥ä½œä»¥å®Œæˆä»»åŠ¡ã€‚</li>
<li>Open Search Toolæ˜¯ä¸€ç§æ–°å‹çš„ç½‘é¡µæœç´¢å·¥å…·ï¼Œå…¶æ€§èƒ½è¶…è¿‡äº†ä¸“æœ‰æœç´¢å·¥å…·çš„æ€§èƒ½ã€‚</li>
<li>åœ¨SimpleQAå’ŒFRAMESåŸºå‡†æµ‹è¯•ä¸­ï¼ŒODSçš„è¡¨ç°æ¥è¿‘æˆ–è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æ°´å¹³çš„åŸºå‡†çº¿ã€‚</li>
<li>åœ¨FRAMESè¯„ä¼°åŸºå‡†æµ‹è¯•ä¸­ï¼ŒODSæé«˜äº†GPT-4o Search Previewçš„å‡†ç¡®æ€§9.7%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20201">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9061116c74cb80a4bad85414dafeb7b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-87f80bd75d02ee70f8ab80688e2d8493.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ddf9d855f51b54d4bfe29201f11866b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98887c303b6fbdc9355ef1f80e3a4341.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab30b0eba029d65e0ca1119bd6e746ce.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Direct-Post-Training-Preference-Alignment-for-Multi-Agent-Motion-Generation-Models-Using-Implicit-Feedback-from-Pre-training-Demonstrations"><a href="#Direct-Post-Training-Preference-Alignment-for-Multi-Agent-Motion-Generation-Models-Using-Implicit-Feedback-from-Pre-training-Demonstrations" class="headerlink" title="Direct Post-Training Preference Alignment for Multi-Agent Motion   Generation Models Using Implicit Feedback from Pre-training Demonstrations"></a>Direct Post-Training Preference Alignment for Multi-Agent Motion   Generation Models Using Implicit Feedback from Pre-training Demonstrations</h2><p><strong>Authors:Ran Tian, Kratarth Goel</strong></p>
<p>Recent advancements in LLMs have revolutionized motion generation models in embodied applications. While LLM-type auto-regressive motion generation models benefit from training scalability, there remains a discrepancy between their token prediction objectives and human preferences. As a result, models pre-trained solely with token-prediction objectives often generate behaviors that deviate from what humans would prefer, making post-training preference alignment crucial for producing human-preferred motions. Unfortunately, post-training alignment requires extensive preference rankings of motions generated by the pre-trained model, which are costly to annotate, especially in multi-agent settings. Recently, there has been growing interest in leveraging pre-training demonstrations to scalably generate preference data for post-training alignment. However, these methods often adopt an adversarial assumption, treating all pre-trained model-generated samples as unpreferred examples. This adversarial approach overlooks the valuable signal provided by preference rankings among the modelâ€™s own generations, ultimately reducing alignment effectiveness and potentially leading to misaligned behaviors. In this work, instead of treating all generated samples as equally bad, we leverage implicit preferences encoded in pre-training demonstrations to construct preference rankings among the pre-trained modelâ€™s generations, offering more nuanced preference alignment guidance with zero human cost. We apply our approach to large-scale traffic simulation and demonstrate its effectiveness in improving the realism of pre-trained modelâ€™s generated behaviors, making a lightweight 1M motion generation model comparable to SOTA large imitation-based models by relying solely on implicit feedback from pre-training demonstrations, without additional post-training human preference annotations or high computational costs. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›å±•ä¸ºå®ä½“åº”ç”¨ä¸­çš„è¿åŠ¨ç”Ÿæˆæ¨¡å‹å¸¦æ¥äº†é©å‘½æ€§çš„å˜é©ã€‚è™½ç„¶LLMç±»å‹çš„è‡ªå›å½’è¿åŠ¨ç”Ÿæˆæ¨¡å‹å—ç›Šäºè®­ç»ƒçš„å¯æ‰©å±•æ€§ï¼Œä½†å®ƒä»¬çš„ä»¤ç‰Œé¢„æµ‹ç›®æ ‡ä¸äººç±»åå¥½ä¹‹é—´ä»å­˜åœ¨å·®å¼‚ã€‚å› æ­¤ï¼Œä»…ä½¿ç”¨ä»¤ç‰Œé¢„æµ‹ç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒçš„æ¨¡å‹å¾€å¾€ä¼šç”Ÿæˆä¸äººç±»åå¥½ç›¸åç¦»çš„è¡Œä¸ºï¼Œè¿™ä½¿å¾—è®­ç»ƒåçš„åå¥½å¯¹é½å¯¹äºç”Ÿæˆäººç±»åå¥½çš„è¿åŠ¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè®­ç»ƒåçš„å¯¹é½éœ€è¦é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¿åŠ¨çš„åå¥½æ’åçš„å¹¿æ³›æ ‡æ³¨ï¼Œè¿™åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å°¤å…¶æˆæœ¬é«˜æ˜‚ã€‚æœ€è¿‘ï¼Œäººä»¬è¶Šæ¥è¶Šæ„Ÿå…´è¶£åˆ©ç”¨é¢„è®­ç»ƒæ¼”ç¤ºæ¥å¤§è§„æ¨¡ç”Ÿæˆç”¨äºè®­ç»ƒåå¯¹é½çš„åå¥½æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸é‡‡ç”¨å¯¹æŠ—æ€§å‡è®¾ï¼Œå°†æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬è§†ä¸ºä¸å—æ¬¢è¿çš„ä¾‹å­ã€‚è¿™ç§å¯¹æŠ—æ€§æ–¹æ³•å¿½ç•¥äº†æ¨¡å‹è‡ªèº«ç”Ÿæˆç‰©ä¹‹é—´çš„åå¥½æ’åæ‰€æä¾›çš„å®è´µä¿¡å·ï¼Œæœ€ç»ˆé™ä½äº†å¯¹é½æ•ˆæœå¹¶å¯èƒ½å¯¼è‡´è¡Œä¸ºå¤±å‡†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä¸æ˜¯å°†æ‰€æœ‰ç”Ÿæˆçš„æ ·æœ¬è§†ä¸ºåŒæ ·ç³Ÿç³•ï¼Œè€Œæ˜¯åˆ©ç”¨é¢„è®­ç»ƒæ¼”ç¤ºä¸­éšå«çš„åå¥½æ¥æ„å»ºé¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆç‰©ä¹‹é—´çš„åå¥½æ’åï¼Œæä¾›å…·æœ‰é›¶äººåŠ›æˆæœ¬çš„æ›´ç²¾ç»†çš„åå¥½å¯¹é½æŒ‡å¯¼ã€‚æˆ‘ä»¬å°†è¯¥æ–¹æ³•åº”ç”¨äºå¤§è§„æ¨¡äº¤é€šä»¿çœŸï¼Œå¹¶è¯æ˜äº†å…¶åœ¨æé«˜é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¡Œä¸ºçœŸå®æ„Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬ä¾é ä»…æ¥è‡ªé¢„è®­ç»ƒæ¼”ç¤ºçš„éšæ€§åé¦ˆï¼Œä½¿è½»é‡çº§çš„1Mè¿åŠ¨ç”Ÿæˆæ¨¡å‹ä¸åŸºäºæ¨¡ä»¿çš„å…ˆè¿›å¤§å‹æ¨¡å‹ç›¸åª²ç¾ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒåäººç±»åå¥½æ³¨é‡Šæˆ–é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20105v1">PDF</a> ICLR 2025 Spotlight</p>
<p><strong>Summary</strong></p>
<p>LLMsåœ¨åŠ¨ä½œç”Ÿæˆæ¨¡å‹ä¸­çš„è¿›å±•å·²ç»å¼•èµ·äº†é©å‘½æ€§çš„å˜é©ï¼Œä½†åœ¨ä½¿ç”¨åŸºäºtokené¢„æµ‹ç›®æ ‡çš„é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œç”Ÿæˆçš„è¡ŒåŠ¨å¾€å¾€ä¸äººç±»åå¥½å­˜åœ¨åå·®ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†åˆ©ç”¨é¢„è®­ç»ƒæ¼”ç¤ºæ¥ç”Ÿæˆåå¥½æ•°æ®çš„æ–¹æ³•ï¼Œä½†ç°æœ‰æ–¹æ³•é‡‡ç”¨å¯¹æŠ—æ€§å‡è®¾ï¼Œå°†æ‰€æœ‰ç”±é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬è§†ä¸ºä¸å—æ¬¢è¿çš„ä¾‹å­ã€‚è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹åœ¨äºå¿½è§†äº†åå¥½æ’åä¸­åŒ…å«çš„ä¿¡æ¯ä¿¡å·ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé¢„è®­ç»ƒæ¼”ç¤ºä¸­çš„éšå«åå¥½æ„å»ºæ¨¡å‹ç”Ÿæˆæ ·æœ¬çš„åå¥½æ’åçš„æ–¹æ³•ï¼Œä¸ºæ¨¡å‹æä¾›äº†æ›´ç²¾ç»†çš„åå¥½å¯¹é½æŒ‡å¯¼ï¼Œä¸”æ— éœ€é¢å¤–çš„äººåŠ›æˆæœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤§è§„æ¨¡äº¤é€šæ¨¡æ‹Ÿä¸­å¾—åˆ°äº†åº”ç”¨ï¼Œè¯æ˜äº†å…¶åœ¨æé«˜é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¡Œä¸ºçœŸå®æ„Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬ä¾é ä»…æ¥è‡ªé¢„è®­ç»ƒæ¼”ç¤ºçš„éšå«åé¦ˆï¼Œåœ¨ä¸å¢åŠ é¢å¤–çš„äººåŠ›åå¥½æ³¨é‡Šæˆ–é«˜è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œä½¿å¾—è½»é‡çº§çš„ç™¾ä¸‡åŠ¨ä½œç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿä¸åŸºäºæ¨¡ä»¿çš„æœ€å…ˆè¿›æ¨¡å‹ç›¸åª²ç¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨è¿åŠ¨ç”Ÿæˆæ¨¡å‹ä¸­å–å¾—äº†è¿›å±•ï¼Œä½†å­˜åœ¨ä¸äººç±»åå¥½ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>ä»…ä½¿ç”¨åŸºäºtokené¢„æµ‹ç›®æ ‡çš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„è¡ŒåŠ¨å¾€å¾€åç¦»äººç±»åå¥½ã€‚</li>
<li>å¯¹æŠ—æ€§æ–¹æ³•å°†æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬è§†ä¸ºä¸å—æ¬¢è¿çš„ä¾‹å­ï¼Œå¿½ç•¥äº†æœ‰ä»·å€¼çš„ä¿¡å·ã€‚</li>
<li>æœ¬ç ”ç©¶åˆ©ç”¨é¢„è®­ç»ƒæ¼”ç¤ºä¸­çš„éšå«åå¥½æ„å»ºæ¨¡å‹ç”Ÿæˆæ ·æœ¬çš„åå¥½æ’åã€‚</li>
<li>è¯¥æ–¹æ³•æé«˜äº†é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¡Œä¸ºçš„çœŸå®æ„Ÿï¼Œå¹¶æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>ä¸å…¶ä»–å¤§å‹æ¨¡ä»¿æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸å¢åŠ é¢å¤–çš„äººåŠ›åå¥½æ³¨é‡Šæˆ–é«˜è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹è¡¨ç°å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20105">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a83fee43596c8d2edce0aa982f7d16cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75765831c4f4e92db643e7a05eb03d00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-127151a5d0b16e52043c4b8e3a8b1592.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="BugCraft-End-to-End-Crash-Bug-Reproduction-Using-LLM-Agents-in-Minecraft"><a href="#BugCraft-End-to-End-Crash-Bug-Reproduction-Using-LLM-Agents-in-Minecraft" class="headerlink" title="BugCraft: End-to-End Crash Bug Reproduction Using LLM Agents in   Minecraft"></a>BugCraft: End-to-End Crash Bug Reproduction Using LLM Agents in   Minecraft</h2><p><strong>Authors:Eray YapaÄŸcÄ±, Yavuz Alp Sencer Ã–ztÃ¼rk, Eray TÃ¼zÃ¼n</strong></p>
<p>Reproducing game bugs, in our case crash bugs in continuously evolving games like Minecraft, is a notoriously manual, time-consuming, and challenging process to automate. Despite the success of LLM-driven bug reproduction in other software domains, games, with their complex interactive environments, remain largely unaddressed. This paper introduces BugCraft, a novel end-to-end framework designed to automate the reproduction of crash bugs in Minecraft directly from user-submitted bug reports, addressing the critical gap in automated game bug reproduction. BugCraft employs a two-stage approach: first, a Step Synthesizer leverages LLMs and Minecraft Wiki knowledge to transform bug reports into high-quality, structured steps to reproduce (S2R). Second, an Action Model, powered by a vision-based LLM agent (GPT-4o) and a custom macro API, executes these S2R steps within Minecraft to trigger the reported crash. To facilitate evaluation, we introduce BugCraft-Bench, a curated dataset of Minecraft crash bug reports. Evaluated on BugCraft-Bench, our framework successfully reproduced 30.23% of crash bugs end-to-end. The Step Synthesizer demonstrated a 66.28% accuracy in generating correct bug reproduction plans, highlighting its effectiveness in interpreting and structuring bug report information. BugCraft demonstrates the feasibility of automated reproduction of crash bugs in complex game environments using LLMs, opening promising avenues for game testing and development. The framework and the BugCraft-Bench dataset pave the way for future research in automated game bug analysis and hold potential for generalization to other interactive game platforms. Finally, we make our code open at <a target="_blank" rel="noopener" href="https://bugcraft2025.github.io/">https://bugcraft2025.github.io/</a> </p>
<blockquote>
<p>å¤ç°æ¸¸æˆæ¼æ´ï¼ˆå¦‚Minecraftç­‰æŒç»­è¿›åŒ–æ¸¸æˆä¸­çš„å´©æºƒæ¼æ´ï¼‰æ˜¯ä¸€ä¸ªä¼—æ‰€å‘¨çŸ¥çš„æ‰‹åŠ¨ã€è€—æ—¶ä¸”éš¾ä»¥è‡ªåŠ¨åŒ–çš„è¿‡ç¨‹ã€‚å°½ç®¡LLMé©±åŠ¨çš„æ¼æ´å¤ç°æŠ€æœ¯åœ¨å…¶ä»–è½¯ä»¶é¢†åŸŸå–å¾—äº†æˆåŠŸï¼Œä½†æ¸¸æˆç”±äºå…¶å¤æ‚çš„äº¤äº’ç¯å¢ƒï¼Œä»å¤§éƒ¨åˆ†æœªè¢«è§£å†³ã€‚æœ¬æ–‡ä»‹ç»äº†BugCraftï¼Œä¸€ä¸ªä¸“ä¸ºè‡ªåŠ¨åŒ–å¤ç°Minecraftä¸­çš„å´©æºƒæ¼æ´è€Œè®¾è®¡çš„æ–°å‹ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œè§£å†³äº†è‡ªåŠ¨åŒ–æ¸¸æˆæ¼æ´å¤ç°ä¸­çš„å…³é”®ç©ºç™½ã€‚BugCrafté‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•ï¼šé¦–å…ˆï¼Œæ­¥éª¤åˆæˆå™¨åˆ©ç”¨LLMå’ŒMinecraftç»´åŸºçŸ¥è¯†å°†æ¼æ´æŠ¥å‘Šè½¬åŒ–ä¸ºé«˜è´¨é‡çš„ç»“æ„åŒ–å¤ç°æ­¥éª¤ï¼ˆS2Rï¼‰ï¼›å…¶æ¬¡ï¼ŒåŠ¨ä½œæ¨¡å‹ç”±åŸºäºè§†è§‰çš„LLMä»£ç†ï¼ˆGPT-4oï¼‰å’Œè‡ªå®šä¹‰å®APIç»„æˆï¼Œè¿™äº›ä»£ç†åœ¨Minecraftä¸­æ‰§è¡ŒS2Ræ­¥éª¤ä»¥è§¦å‘æŠ¥å‘Šçš„å´©æºƒã€‚ä¸ºäº†ä¿ƒè¿›è¯„ä¼°ï¼Œæˆ‘ä»¬æ¨å‡ºäº†BugCraft-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„Minecraftå´©æºƒæ¼æ´æŠ¥å‘Šæ•°æ®é›†ã€‚åœ¨BugCraft-Benchä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æˆåŠŸç«¯åˆ°ç«¯å¤ç°äº†30.23%çš„å´©æºƒæ¼æ´ã€‚æ­¥éª¤åˆæˆå™¨åœ¨ç”Ÿæˆæ­£ç¡®çš„æ¼æ´å¤ç°è®¡åˆ’æ–¹é¢è¾¾åˆ°äº†66.28%çš„å‡†ç¡®ç‡ï¼Œè¿™å‡¸æ˜¾äº†å…¶åœ¨è§£é‡Šå’Œç»“æ„æ¼æ´æŠ¥å‘Šä¿¡æ¯æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚BugCraftåˆ©ç”¨LLMæ¼”ç¤ºäº†åœ¨å¤æ‚çš„æ¸¸æˆç¯å¢ƒä¸­è‡ªåŠ¨å¤ç°å´©æºƒæ¼æ´çš„å¯è¡Œæ€§ï¼Œä¸ºæ¸¸æˆæµ‹è¯•å’Œå¼€å‘å¼€è¾Ÿäº†å¯Œæœ‰å¸Œæœ›çš„é“è·¯ã€‚è¯¥æ¡†æ¶å’ŒBugCraft-Benchæ•°æ®é›†ä¸ºæœªæ¥çš„è‡ªåŠ¨åŒ–æ¸¸æˆæ¼æ´åˆ†æé“ºå¹³äº†é“è·¯ï¼Œå¹¶æœ‰æ½œåŠ›æ¨å¹¿åˆ°å…¶ä»–äº¤äº’å¼æ¸¸æˆå¹³å°ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ <a target="_blank" rel="noopener" href="https://bugcraft2025.github.io/">https://bugcraft2025.github.io/</a> å…¬å¼€æˆ‘ä»¬çš„ä»£ç ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20036v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåä¸ºBugCraftçš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨å†ç°Minecraftæ¸¸æˆä¸­çš„å´©æºƒé”™è¯¯ï¼ˆå³Bugï¼‰ã€‚æ­¤æ¡†æ¶é¦–å…ˆä½¿ç”¨LLMsï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ä¸Minecraft WikiçŸ¥è¯†ï¼Œå°†ç”¨æˆ·æäº¤çš„BugæŠ¥å‘Šè½¬åŒ–ä¸ºé«˜è´¨é‡çš„ç»“æ„åŒ–é‡ç°æ­¥éª¤ï¼ˆS2Rï¼‰ã€‚ç„¶åï¼Œåˆ©ç”¨åŸºäºè§†è§‰çš„LLMä»£ç†ï¼ˆGPT-4oï¼‰å’Œè‡ªå®šä¹‰å®APIæ‰§è¡Œè¿™äº›æ­¥éª¤ï¼Œåœ¨Minecraftä¸­è§¦å‘æŠ¥å‘Šçš„å´©æºƒã€‚å®éªŒè¡¨æ˜ï¼ŒBugCraftæ¡†æ¶æˆåŠŸåœ°åœ¨Minecraftä¸­è‡ªåŠ¨å†ç°äº†30.23%çš„å´©æºƒBugã€‚è¯¥æ¡†æ¶ä¸ºæ¸¸æˆæµ‹è¯•å’Œå¼€å‘é¢†åŸŸå¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>BugCraftæ˜¯ä¸€ä¸ªæ—¨åœ¨è‡ªåŠ¨åŒ–å†ç°Minecraftæ¸¸æˆä¸­å´©æºƒBugçš„æ¡†æ¶ã€‚</li>
<li>å®ƒä½¿ç”¨LLMså’ŒMinecraft WikiçŸ¥è¯†è½¬åŒ–BugæŠ¥å‘Šä¸ºç»“æ„åŒ–é‡ç°æ­¥éª¤ï¼ˆS2Rï¼‰ã€‚</li>
<li>åˆ©ç”¨åŸºäºè§†è§‰çš„LLMä»£ç†å’Œè‡ªå®šä¹‰å®APIåœ¨Minecraftä¸­æ‰§è¡Œè¿™äº›æ­¥éª¤ã€‚</li>
<li>åœ¨BugCraft-Benchæ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶æˆåŠŸå†ç°çš„å´©æºƒBugå æ€»ä½“çš„æ¯”ä¾‹è¾¾åˆ°äº†çº¦30%ã€‚è€Œç”ŸæˆBugå¤ç°è®¡åˆ’çš„å‡†ç¡®åº¦è¾¾åˆ°äº†çº¦66%ã€‚</li>
<li>BugCraftå±•ç¤ºäº†åœ¨å¤æ‚çš„æ¸¸æˆç¯å¢ƒä¸­ä½¿ç”¨LLMsè‡ªåŠ¨åŒ–é‡ç°å´©æºƒBugçš„å¯è¡Œæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20036">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d46f2f4922dc8f530f42f183c285b952.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd6a3fa8bb4740836e19cd3ebf98debf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f32832bbc78c9c9c9c4950d5d136aa6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42e63bc1d7e3c3de849d752afc168cfc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b9faab886bec7d4fb94e1e5a8a4a8ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dcf43c46071bce1db34c7927c1150e12.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e7ef4055e8decee91021af99b96e34e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="OmniNova-A-General-Multimodal-Agent-Framework"><a href="#OmniNova-A-General-Multimodal-Agent-Framework" class="headerlink" title="OmniNova:A General Multimodal Agent Framework"></a>OmniNova:A General Multimodal Agent Framework</h2><p><strong>Authors:Pengfei Du</strong></p>
<p>The integration of Large Language Models (LLMs) with specialized tools presents new opportunities for intelligent automation systems. However, orchestrating multiple LLM-driven agents to tackle complex tasks remains challenging due to coordination difficulties, inefficient resource utilization, and inconsistent information flow. We present OmniNova, a modular multi-agent automation framework that combines language models with specialized tools such as web search, crawling, and code execution capabilities. OmniNova introduces three key innovations: (1) a hierarchical multi-agent architecture with distinct coordinator, planner, supervisor, and specialist agents; (2) a dynamic task routing mechanism that optimizes agent deployment based on task complexity; and (3) a multi-layered LLM integration system that allocates appropriate models to different cognitive requirements. Our evaluations across 50 complex tasks in research, data analysis, and web interaction domains demonstrate that OmniNova outperforms existing frameworks in task completion rate (87% vs. baseline 62%), efficiency (41% reduced token usage), and result quality (human evaluation score of 4.2&#x2F;5 vs. baseline 3.1&#x2F;5). We contribute both a theoretical framework for multi-agent system design and an open-source implementation that advances the state-of-the-art in LLM-based automation systems. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ä¸“ç”¨å·¥å…·ç›¸ç»“åˆä¸ºæ™ºèƒ½è‡ªåŠ¨åŒ–ç³»ç»Ÿå¸¦æ¥äº†æ–°çš„æœºé‡ã€‚ç„¶è€Œï¼Œç”±äºåè°ƒå›°éš¾ã€èµ„æºåˆ©ç”¨ä¸è¶³ä»¥åŠä¿¡æ¯æµåŠ¨ä¸ä¸€è‡´ç­‰é—®é¢˜ï¼Œåè°ƒå¤šä¸ªLLMé©±åŠ¨çš„æ™ºèƒ½ä½“ä»¥åº”å¯¹å¤æ‚ä»»åŠ¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æå‡ºäº†OmniNovaï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œå®ƒå°†è¯­è¨€æ¨¡å‹ä¸ä¸“ç”¨å·¥å…·ï¼ˆå¦‚ç½‘ç»œæœç´¢ã€çˆ¬è™«å’Œä»£ç æ‰§è¡ŒåŠŸèƒ½ï¼‰ç›¸ç»“åˆã€‚OmniNovaå¼•å…¥äº†ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰å…·æœ‰ä¸åŒåè°ƒå™¨ã€è§„åˆ’å™¨ã€ç›‘ç£è€…å’Œä¸“ä¸šæ™ºèƒ½ä½“çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“æ¶æ„ï¼›ï¼ˆ2ï¼‰æ ¹æ®ä»»åŠ¡å¤æ‚æ€§ä¼˜åŒ–æ™ºèƒ½ä½“éƒ¨ç½²çš„åŠ¨æ€ä»»åŠ¡è·¯ç”±æœºåˆ¶ï¼›ï¼ˆ3ï¼‰å¤šå±‚LLMé›†æˆç³»ç»Ÿï¼Œä¸ºä¸åŒçš„è®¤çŸ¥éœ€æ±‚åˆ†é…é€‚å½“çš„æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ç ”ç©¶ã€æ•°æ®åˆ†æå’Œç½‘ç»œäº¤äº’é¢†åŸŸçš„50ä¸ªå¤æ‚ä»»åŠ¡ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒOmniNovaåœ¨ä»»åŠ¡å®Œæˆç‡ï¼ˆ87%å¯¹æ¯”åŸºçº¿62%ï¼‰ã€æ•ˆç‡ï¼ˆå‡å°‘41%çš„ä»¤ç‰Œä½¿ç”¨é‡ï¼‰å’Œç»“æœè´¨é‡ï¼ˆäººç±»è¯„ä»·å¾—åˆ†4.2&#x2F;5å¯¹æ¯”åŸºçº¿3.1&#x2F;5ï¼‰æ–¹é¢å‡ä¼˜äºç°æœ‰æ¡†æ¶ã€‚æˆ‘ä»¬ä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè®¾è®¡æä¾›äº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œå¹¶æ¨å‡ºäº†ä¸€ä¸ªå¼€æºå®ç°ï¼Œè¿™æ¨åŠ¨äº†åŸºäºLLMçš„è‡ªåŠ¨åŒ–ç³»ç»Ÿé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20028v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ä¸“ä¸šåŒ–å·¥å…·ä¸ºæ™ºèƒ½è‡ªåŠ¨åŒ–ç³»ç»Ÿå¸¦æ¥äº†æ–°çš„æœºé‡ã€‚ç„¶è€Œï¼Œç”±äºåè°ƒå›°éš¾ã€èµ„æºåˆ©ç”¨ä¸è¶³å’Œä¿¡æ¯æµä¸ä¸€è‡´ç­‰é—®é¢˜ï¼Œä½¿ç”¨å¤šä¸ªLLMé©±åŠ¨çš„æ™ºèƒ½ä»£ç†æ¥æ‰§è¡Œå¤æ‚ä»»åŠ¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æå‡ºäº†OmniNovaï¼Œä¸€ä¸ªç»“åˆäº†è¯­è¨€æ¨¡å‹ä¸è¯¸å¦‚ç½‘ç»œæœç´¢ã€çˆ¬è™«å’Œä»£ç æ‰§è¡Œç­‰ä¸“ä¸šåŒ–å·¥å…·çš„æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚OmniNovaé€šè¿‡ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹æ¥åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼šå±‚æ¬¡åŒ–çš„å¤šæ™ºèƒ½ä½“æ¶æ„ã€åŠ¨æ€çš„ä»»åŠ¡è·¯ç”±æœºåˆ¶å’Œåˆ†å±‚çš„å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆç³»ç»Ÿã€‚åœ¨ç ”ç©¶å’Œè¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬å‘ç°OmniNovaåœ¨ä»»åŠ¡å®Œæˆç‡ã€æ•ˆç‡å’Œç»“æœè´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LLMä¸ä¸“ä¸šåŒ–å·¥å…·çš„ç»“åˆä¸ºæ™ºèƒ½è‡ªåŠ¨åŒ–ç³»ç»Ÿå¸¦æ¥äº†æ–°çš„æœºé‡ã€‚</li>
<li>æ•´åˆå¤šä¸ªLLMé©±åŠ¨çš„æ™ºèƒ½ä»£ç†ä»¥æ‰§è¡Œå¤æ‚ä»»åŠ¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä¸»è¦åŸå› æ˜¯åè°ƒå›°éš¾ã€èµ„æºåˆ©ç”¨ä¸è¶³å’Œä¿¡æ¯æµä¸ä¸€è‡´ã€‚</li>
<li>OmniNovaæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œç»“åˆäº†è¯­è¨€æ¨¡å‹å’Œä¸“ä¸šåŒ–å·¥å…·ã€‚</li>
<li>OmniNovaå…·æœ‰ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šå±‚æ¬¡åŒ–çš„å¤šæ™ºèƒ½ä½“æ¶æ„ã€åŠ¨æ€çš„ä»»åŠ¡è·¯ç”±æœºåˆ¶å’Œåˆ†å±‚çš„å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆç³»ç»Ÿã€‚</li>
<li>OmniNovaåœ¨ä»»åŠ¡å®Œæˆç‡ã€æ•ˆç‡å’Œç»“æœè´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ¡†æ¶ï¼Œä»»åŠ¡å®Œæˆç‡ä¸º87%ï¼Œè€ŒåŸºçº¿ä¸º62%ã€‚</li>
<li>OmniNovaçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œå…¶åœ¨ç ”ç©¶ã€æ•°æ®åˆ†æå’Œç½‘ç»œäº¤äº’é¢†åŸŸçš„å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20028">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5c309fe759c24bf04de58a592b2978db.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a95bab7cbc11ebaf46b15c18a6843100.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-772ff1d26ca4f12320437182ab0861ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d94500ce1bc5203fd400d27ed08dff5e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Multi-agent-Application-System-in-Office-Collaboration-Scenarios"><a href="#Multi-agent-Application-System-in-Office-Collaboration-Scenarios" class="headerlink" title="Multi-agent Application System in Office Collaboration Scenarios"></a>Multi-agent Application System in Office Collaboration Scenarios</h2><p><strong>Authors:Songtao Sun, Jingyi Li, Yuanfei Dong, Haoguang Liu, Chenxin Xu, Fuyang Li, Qiang Liu</strong></p>
<p>This paper introduces a multi-agent application system designed to enhance office collaboration efficiency and work quality. The system integrates artificial intelligence, machine learning, and natural language processing technologies, achieving functionalities such as task allocation, progress monitoring, and information sharing. The agents within the system are capable of providing personalized collaboration support based on team membersâ€™ needs and incorporate data analysis tools to improve decision-making quality. The paper also proposes an intelligent agent architecture that separates Plan and Solver, and through techniques such as multi-turn query rewriting and business tool retrieval, it enhances the agentâ€™s multi-intent and multi-turn dialogue capabilities. Furthermore, the paper details the design of tools and multi-turn dialogue in the context of office collaboration scenarios, and validates the systemâ€™s effectiveness through experiments and evaluations. Ultimately, the system has demonstrated outstanding performance in real business applications, particularly in query understanding, task planning, and tool calling. Looking forward, the system is expected to play a more significant role in addressing complex interaction issues within dynamic environments and large-scale multi-agent systems. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ—¨åœ¨æé«˜åŠå…¬å®¤åä½œæ•ˆç‡å’Œå·¥ä½œè´¨é‡çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿèåˆäº†äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå®ç°äº†ä»»åŠ¡åˆ†é…ã€è¿›åº¦ç›‘æ§å’Œä¿¡æ¯å…±äº«ç­‰åŠŸèƒ½ã€‚ç³»ç»Ÿå†…çš„æ™ºèƒ½ä½“èƒ½æ ¹æ®å›¢é˜Ÿæˆå‘˜çš„éœ€æ±‚æä¾›ä¸ªæ€§åŒ–çš„åä½œæ”¯æŒï¼Œå¹¶èåˆæ•°æ®åˆ†æå·¥å…·æ¥æé«˜å†³ç­–è´¨é‡ã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ™ºèƒ½ä½“æ¶æ„ï¼Œè¯¥æ¶æ„å°†è®¡åˆ’å’Œæ±‚è§£å™¨åˆ†ç¦»ï¼Œå¹¶é€šè¿‡å¤šè½®æŸ¥è¯¢é‡å†™å’Œä¸šåŠ¡å·¥å…·æ£€ç´¢ç­‰æŠ€æœ¯ï¼Œæé«˜äº†æ™ºèƒ½ä½“çš„å¤šæ„å›¾å’Œå¤šè½®å¯¹è¯èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¯¦ç»†æè¿°äº†åŠå…¬å®¤åä½œåœºæ™¯ä¸‹å·¥å…·å’Œå¤šè½®å¯¹è¯çš„è®¾è®¡ï¼Œå¹¶é€šè¿‡å®éªŒå’Œè¯„ä¼°éªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚æœ€ç»ˆï¼Œè¯¥ç³»ç»Ÿåœ¨çœŸå®ä¸šåŠ¡åº”ç”¨ä¸­è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æŸ¥è¯¢ç†è§£ã€ä»»åŠ¡è§„åˆ’å’Œå·¥å…·è°ƒç”¨æ–¹é¢ã€‚å±•æœ›æœªæ¥ï¼Œè¯¥ç³»ç»Ÿæœ‰æœ›åœ¨è§£å†³åŠ¨æ€ç¯å¢ƒå’Œå¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå†…çš„å¤æ‚äº¤äº’é—®é¢˜æ–¹é¢å‘æŒ¥æ›´é‡è¦çš„ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19584v2">PDF</a> Technical report</p>
<p><strong>Summary</strong><br>ç³»ç»Ÿé€šè¿‡é›†æˆäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œè®¾è®¡äº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“åº”ç”¨ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜åŠå…¬åä½œæ•ˆç‡å’Œå·¥ä½œè´¨é‡ã€‚è¯¥ç³»ç»Ÿå…·å¤‡ä»»åŠ¡åˆ†é…ã€è¿›åº¦ç›‘æ§ã€ä¿¡æ¯å…±äº«ç­‰åŠŸèƒ½ï¼Œæ™ºèƒ½ä½“å¯æ ¹æ®å›¢é˜Ÿæˆå‘˜éœ€æ±‚æä¾›ä¸ªæ€§åŒ–åä½œæ”¯æŒï¼Œå¹¶å¯é€šè¿‡æ•°æ®åˆ†æå·¥å…·æé«˜å†³ç­–è´¨é‡ã€‚ç³»ç»Ÿé‡‡ç”¨æ™ºèƒ½ä½“æ¶æ„ï¼Œåˆ†ç¦»è®¡åˆ’å’Œæ±‚è§£å™¨ï¼Œå¢å¼ºå¤šæ„å›¾å’Œå¤šè½®å¯¹è¯èƒ½åŠ›ã€‚é€šè¿‡å®éªŒå’Œè¯„ä¼°éªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æŸ¥è¯¢ç†è§£ã€ä»»åŠ¡è§„åˆ’å’Œå·¥å…·è°ƒç”¨æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥ç³»ç»Ÿå°†åœ¨è§£å†³åŠ¨æ€ç¯å¢ƒå’Œå¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„å¤æ‚äº¤äº’é—®é¢˜æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥ç³»ç»Ÿæ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“åº”ç”¨ç³»ç»Ÿè®¾è®¡ç”¨äºæé«˜åŠå…¬åä½œæ•ˆç‡å’Œå·¥ä½œè´¨é‡ã€‚</li>
<li>é›†æˆäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å®ç°ä»»åŠ¡åˆ†é…ã€è¿›åº¦ç›‘æ§å’Œä¿¡æ¯å…±äº«ç­‰åŠŸèƒ½ã€‚</li>
<li>æ™ºèƒ½ä½“æ ¹æ®å›¢é˜Ÿæˆå‘˜éœ€æ±‚æä¾›ä¸ªæ€§åŒ–åä½œæ”¯æŒå¹¶ä½¿ç”¨æ•°æ®åˆ†æå·¥å…·æé«˜å†³ç­–è´¨é‡ã€‚</li>
<li>é‡‡ç”¨æ™ºèƒ½ä½“æ¶æ„åˆ†ç¦»è®¡åˆ’å’Œæ±‚è§£å™¨ï¼Œå¢å¼ºå¤šæ„å›¾å’Œå¤šè½®å¯¹è¯èƒ½åŠ›ã€‚</li>
<li>ç³»ç»Ÿé€šè¿‡æ™ºèƒ½æŠ€æœ¯å®ç°æŸ¥è¯¢ç†è§£ã€ä»»åŠ¡è§„åˆ’å’Œå·¥å…·è°ƒç”¨çš„é«˜æ•ˆæ€§èƒ½ã€‚</li>
<li>ç»è¿‡å®éªŒå’Œè¯„ä¼°éªŒè¯ç³»ç»Ÿæœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19584">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3bdfb920c9ee9b839e5bc5f8cd54ab7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfc50d6dc5757d9b2cea4fd1e6ae87dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e9d4942349846814347d41b8cba37ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f18c220aea68345c1aad1bd06723a525.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3eeac6fd844947a7699f20d708e82a4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ad9affbc7c026e5fb3b2cd540c50acd.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Agentic-AI-Software-Engineer-Programming-with-Trust"><a href="#Agentic-AI-Software-Engineer-Programming-with-Trust" class="headerlink" title="Agentic AI Software Engineer: Programming with Trust"></a>Agentic AI Software Engineer: Programming with Trust</h2><p><strong>Authors:Abhik Roychoudhury, Corina Pasareanu, Michael Pradel, Baishakhi Ray</strong></p>
<p>Large Language Models (LLMs) have shown surprising proficiency in generating code snippets, promising to automate large parts of software engineering via artificial intelligence (AI). We argue that successfully deploying AI software engineers requires a level of trust equal to or even greater than the trust established by human-driven software engineering practices. The recent trend toward LLM agents offers a path toward integrating the power of LLMs to create new code with the power of analysis tools to increase trust in the code. This opinion piece comments on whether LLM agents could dominate software engineering workflows in the future and whether the focus of programming will shift from programming at scale to programming with trust. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆä»£ç ç‰‡æ®µæ–¹é¢è¡¨ç°å‡ºäº†æƒŠäººçš„ç†Ÿç»ƒç¨‹åº¦ï¼Œæœ‰æœ›é€šè¿‡äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰è‡ªåŠ¨åŒ–è½¯ä»¶å·¥ç¨‹çš„å¾ˆå¤§ä¸€éƒ¨åˆ†å·¥ä½œã€‚æˆ‘ä»¬è®¤ä¸ºï¼ŒæˆåŠŸéƒ¨ç½²AIè½¯ä»¶å·¥ç¨‹å¸ˆéœ€è¦å»ºç«‹ä¸äººç±»é©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹å®è·µç›¸å½“çš„ä¿¡ä»»ï¼Œç”šè‡³éœ€è¦æ›´é«˜çš„ä¿¡ä»»åº¦ã€‚è¿‘æœŸæµè¡Œçš„LLMä»£ç†è¶‹åŠ¿ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€æ¡é“è·¯ï¼Œå³æ•´åˆLLMsç”Ÿæˆæ–°ä»£ç çš„èƒ½åŠ›ä¸åˆ†æå·¥å…·çš„åŠ›é‡ï¼Œä»¥å¢åŠ å¯¹ä»£ç çš„ä¿¡ä»»ã€‚æœ¬æ–‡ç€é‡è®¨è®ºLLMä»£ç†æ˜¯å¦ä¼šåœ¨æœªæ¥ä¸»å¯¼è½¯ä»¶å·¥ç¨‹å·¥ä½œæµç¨‹ï¼Œä»¥åŠç¼–ç¨‹çš„é‡ç‚¹æ˜¯å¦ä¼šä»è§„æ¨¡åŒ–ç¼–ç¨‹è½¬å‘å¯ä¿¡ç¼–ç¨‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13767v2">PDF</a> 5 pages</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆä»£ç ç‰‡æ®µæ–¹é¢å±•ç°å‡ºæƒŠäººçš„èƒ½åŠ›ï¼Œæœ‰æœ›é€šè¿‡äººå·¥æ™ºèƒ½è‡ªåŠ¨åŒ–è½¯ä»¶å·¥ç¨‹çš„å¾ˆå¤§ä¸€éƒ¨åˆ†å·¥ä½œã€‚æˆåŠŸéƒ¨ç½²AIè½¯ä»¶å·¥ç¨‹å¸ˆéœ€è¦å»ºç«‹ä¸äººç±»é©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹å®è·µç›¸å½“çš„ç”šè‡³æ›´é«˜çš„ä¿¡ä»»åº¦ã€‚æœ€è¿‘çš„LLMä»£ç†è¶‹åŠ¿ä¸ºæ•´åˆLLMsç”Ÿæˆæ–°ä»£ç çš„èƒ½åŠ›ä¸åˆ†æå·¥å…·å¢åŠ ä»£ç ä¿¡ä»»çš„èƒ½åŠ›æä¾›äº†é€”å¾„ã€‚æœ¬æ–‡æ„è§è®¤ä¸ºLLMä»£ç†æœªæ¥æ˜¯å¦ä¼šä¸»å¯¼è½¯ä»¶å·¥ç¨‹çš„å·¥ä½œæµç¨‹ï¼Œä»¥åŠç¼–ç¨‹çš„å…³æ³¨ç‚¹æ˜¯å¦ä¼šä»è§„æ¨¡åŒ–ç¼–ç¨‹è½¬å‘å…·æœ‰ä¿¡ä»»åº¦çš„ç¼–ç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½ç”Ÿæˆä»£ç ç‰‡æ®µï¼Œå¹¶æœ‰æœ›é€šè¿‡äººå·¥æ™ºèƒ½è‡ªåŠ¨åŒ–è½¯ä»¶å·¥ç¨‹çš„è®¸å¤šä»»åŠ¡ã€‚</li>
<li>æˆåŠŸéƒ¨ç½²AIè½¯ä»¶å·¥ç¨‹å¸ˆéœ€è¦å»ºç«‹è¾ƒé«˜çš„ä¿¡ä»»åº¦ï¼Œç±»ä¼¼äºäººç±»é©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹å®è·µã€‚</li>
<li>LLMä»£ç†çš„è¶‹åŠ¿ä¸ºæ•´åˆLLMsçš„èƒ½åŠ›ä¸åˆ†æå·¥å…·æ¥å¢å¼ºä»£ç çš„ä¿¡ä»»åº¦æä¾›äº†å¯èƒ½ã€‚</li>
<li>æœªæ¥LLMä»£ç†å¯èƒ½åœ¨è½¯ä»¶å·¥ç¨‹ä¸­èµ·ä¸»å¯¼ä½œç”¨ã€‚</li>
<li>ç¼–ç¨‹çš„å…³æ³¨ç‚¹å¯èƒ½ä¼šä»è§„æ¨¡åŒ–ç¼–ç¨‹è½¬å‘å…·æœ‰ä¿¡ä»»åº¦çš„ç¼–ç¨‹ã€‚</li>
<li>LLMsçš„æ½œåŠ›åœ¨äºå®ƒä»¬èƒ½å¤Ÿç»“åˆäººå·¥æ™ºèƒ½å’Œä»£ç ç”Ÿæˆï¼Œä»¥æé«˜è½¯ä»¶å¼€å‘çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2f0b59ecedd0e1cc701877bd7565bc6b.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="CoDiNG-â€“-Naming-Game-with-Continuous-Latent-Opinions-of-Individual-Agents"><a href="#CoDiNG-â€“-Naming-Game-with-Continuous-Latent-Opinions-of-Individual-Agents" class="headerlink" title="CoDiNG â€“ Naming Game with Continuous Latent Opinions of Individual   Agents"></a>CoDiNG â€“ Naming Game with Continuous Latent Opinions of Individual   Agents</h2><p><strong>Authors:Mateusz Nurek, Joanna KoÅ‚aczek, RadosÅ‚aw Michalski, BolesÅ‚aw K. SzymaÅ„ski, Omar Lizardo</strong></p>
<p>Understanding the mechanisms behind opinion formation is crucial for gaining insight into the processes that shape political beliefs, cultural attitudes, consumer choices, and social movements. This work aims to explore a nuanced model that captures the intricacies of real-world opinion dynamics by synthesizing principles from cognitive science and employing social network analysis. The proposed model is a hybrid continuous-discrete extension of the well-known Naming Game opinion model. The added latent continuous layer of opinion strength follows cognitive processes in the human brain, akin to memory imprints. The discrete layer allows for the conversion of intrinsic continuous opinion into discrete form, which often occurs when we publicly verbalize our opinions. We evaluated our model using real data as ground truth and demonstrated that the proposed mechanism outperforms the classic Naming Game model in many cases, reflecting that our model is closer to the real process of opinion formation. </p>
<blockquote>
<p>äº†è§£æ„è§å½¢æˆçš„æœºåˆ¶å¯¹äºæ´å¯Ÿå¡‘é€ æ”¿æ²»ä¿¡ä»°ã€æ–‡åŒ–æ€åº¦ã€æ¶ˆè´¹é€‰æ‹©å’Œç¤¾ä¼šè¿åŠ¨çš„è¿‡ç¨‹è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ¢ç´¢ä¸€ä¸ªå¾®å¦™çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡èåˆè®¤çŸ¥ç§‘å­¦çš„åŸç†å¹¶é‡‡ç”¨ç¤¾ä¼šç½‘ç»œåˆ†æï¼Œæ•æ‰ç°å®ä¸–ç•Œä¸­æ„è§åŠ¨æ€çš„å¤æ‚æ€§ã€‚æ‰€æå‡ºçš„æ¨¡å‹æ˜¯è‘—åçš„å‘½åæ¸¸æˆæ„è§æ¨¡å‹çš„è¿ç»­ç¦»æ•£æ··åˆæ‰©å±•ã€‚å¢åŠ çš„æ½œåœ¨è¿ç»­æ„è§å±‚éµå¾ªäººç±»å¤§è„‘çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œç±»ä¼¼äºè®°å¿†å°è®°ã€‚ç¦»æ•£å±‚å…è®¸å°†å†…åœ¨è¿ç»­æ„è§è½¬åŒ–ä¸ºç¦»æ•£å½¢å¼ï¼Œè¿™ç§æƒ…å†µç»å¸¸å‘ç”Ÿåœ¨æˆ‘ä»¬å…¬å¼€è¡¨è¾¾æ„è§æ—¶ã€‚æˆ‘ä»¬ä½¿ç”¨çœŸå®æ•°æ®ä½œä¸ºåŸºå‡†è¯„ä¼°äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶è¯æ˜æ‰€æå‡ºçš„æœºåˆ¶åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½ä¼˜äºç»å…¸çš„å‘½åæ¸¸æˆæ¨¡å‹ï¼Œåæ˜ äº†æˆ‘ä»¬çš„æ¨¡å‹æ›´æ¥è¿‘çœŸå®çš„æ„è§å½¢æˆè¿‡ç¨‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.19204v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä¸€ä¸ªå…³äºæ„è§å½¢æˆæœºåˆ¶çš„ç²¾ç»†æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†è®¤çŸ¥ç§‘å­¦çš„åŸç†å¹¶é‡‡ç”¨äº†ç¤¾ä¼šç½‘ç»œåˆ†æã€‚æ¨¡å‹æ˜¯è‘—åçš„å‘½åæ¸¸æˆæ„è§æ¨¡å‹çš„è¿ç»­ç¦»æ•£æ··åˆæ‰©å±•ï¼Œå…¶ä¸­å¢åŠ çš„æ½œåœ¨è¿ç»­æ„è§å±‚éµå¾ªäººç±»å¤§è„‘çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œç±»ä¼¼äºè®°å¿†å°è®°ã€‚ç¦»æ•£å±‚ä½¿å†…åœ¨è¿ç»­æ„è§èƒ½å¤Ÿè½¬åŒ–ä¸ºç¦»æ•£å½¢å¼ï¼Œè¿™åœ¨æˆ‘ä»¬å…¬å¼€è¡¨è¾¾æ„è§æ—¶ç»å¸¸å‘ç”Ÿã€‚ä½¿ç”¨çœŸå®æ•°æ®ä½œä¸ºåŸºå‡†æµ‹è¯•è¯„ä¼°äº†è¯¥æ¨¡å‹ï¼Œè¯æ˜è¯¥æœºåˆ¶åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½ä¼˜äºç»å…¸çš„å‘½åæ¸¸æˆæ¨¡å‹ï¼Œè¡¨æ˜è¯¥æ¨¡å‹æ›´æ¥è¿‘çœŸå®çš„æ„è§å½¢æˆè¿‡ç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨¡å‹æ—¨åœ¨æ·±å…¥ç†è§£æ„è§å½¢æˆæœºåˆ¶ï¼Œæ¶‰åŠæ”¿æ²»ä¿¡ä»°ã€æ–‡åŒ–æ€åº¦ã€æ¶ˆè´¹é€‰æ‹©å’Œç¤¾ä¼šè¿åŠ¨çš„è¿‡ç¨‹ã€‚</li>
<li>æ¨¡å‹æ˜¯å‘½åæ¸¸æˆæ„è§æ¨¡å‹çš„æ‰©å±•ï¼ŒåŒ…å«è¿ç»­å’Œç¦»æ•£ä¸¤å±‚ï¼Œä»¥æ•æ‰ç°å®ä¸–ç•Œä¸­æ„è§åŠ¨æ€çš„ç»†å¾®å·®åˆ«ã€‚</li>
<li>æ½œåœ¨è¿ç»­å±‚ä»£è¡¨æ„è§å¼ºåº¦ï¼Œéµå¾ªäººç±»å¤§è„‘çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œç±»ä¼¼äºè®°å¿†å°è®°ã€‚</li>
<li>ç¦»æ•£å±‚ä½¿å†…åœ¨è¿ç»­æ„è§èƒ½å¤Ÿè½¬åŒ–ä¸ºå…¬ä¼—è¡¨è¾¾çš„ç¦»æ•£å½¢å¼ã€‚</li>
<li>ä½¿ç”¨çœŸå®æ•°æ®è¯„ä¼°äº†æ¨¡å‹ï¼Œè¯æ˜å…¶åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½æ¯”ä¼ ç»Ÿæ¨¡å‹è¡¨ç°æ›´å¥½ã€‚</li>
<li>æ¨¡å‹åæ˜ äº†çœŸå®çš„æ„è§å½¢æˆè¿‡ç¨‹ï¼Œæ¯”ä¼ ç»Ÿæ¨¡å‹æ›´è´´è¿‘ç°å®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.19204">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-01bd58189422580d37182ef9de93e64c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fddfef8c48c2fb24cd781c35df7bec2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-962d81eebf02255762945aa4db1276c9.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="TwoStep-Multi-agent-Task-Planning-using-Classical-Planners-and-Large-Language-Models"><a href="#TwoStep-Multi-agent-Task-Planning-using-Classical-Planners-and-Large-Language-Models" class="headerlink" title="TwoStep: Multi-agent Task Planning using Classical Planners and Large   Language Models"></a>TwoStep: Multi-agent Task Planning using Classical Planners and Large   Language Models</h2><p><strong>Authors:David Bai, Ishika Singh, David Traum, Jesse Thomason</strong></p>
<p>Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible. However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, such as concurrent actions between two agents when there are no conflicting conditions, without significant modification and definition to existing PDDL domains. A human expert aware of such constraints can decompose a goal into subgoals, each reachable through single agent planning, to take advantage of simultaneous actions. In contrast to classical planning, large language models (LLMs) directly used for inferring plan steps rarely guarantee execution success, but are capable of leveraging commonsense reasoning to assemble action sequences. We combine the strengths of both classical planning and LLMs by approximating human intuitions for multi-agent planning goal decomposition. We demonstrate that LLM-based goal decomposition leads to faster planning times than solving multi-agent PDDL problems directly while simultaneously achieving fewer plan execution steps than a single agent plan alone, as well as most multiagent plans, while guaranteeing execution success. Additionally, we find that LLM-based approximations of subgoals result in similar multi-agent execution lengths to those specified by human experts. Website and resources at <a target="_blank" rel="noopener" href="https://glamor-usc.github.io/twostep">https://glamor-usc.github.io/twostep</a> </p>
<blockquote>
<p>å¤å…¸è§„åˆ’å…¬å¼ï¼ˆå¦‚è§„åˆ’é¢†åŸŸå®šä¹‰è¯­è¨€PDDLï¼‰æ‰¿è®¤å¦‚æœå­˜åœ¨å¯èƒ½çš„è¡ŒåŠ¨åºåˆ—ï¼Œé‚£ä¹ˆç»™å®šåˆå§‹çŠ¶æ€å°±èƒ½è¾¾åˆ°ç›®æ ‡çŠ¶æ€ã€‚ç„¶è€Œï¼Œåœ¨PDDLä¸­å®šä¹‰çš„é—®é¢˜å¹¶ä¸èƒ½æ•æ‰åˆ°è¡ŒåŠ¨çš„æ—¶é—´æ–¹é¢ï¼Œä¾‹å¦‚åœ¨ä¸¤ä¸ªä»£ç†ä¹‹é—´ä¸å­˜åœ¨å†²çªæ¡ä»¶æ—¶çš„å¹¶è¡Œè¡ŒåŠ¨ï¼Œé™¤éå¯¹ç°æœ‰PDDLé¢†åŸŸè¿›è¡Œé‡å¤§ä¿®æ”¹å’Œå®šä¹‰ã€‚äº†è§£è¿™äº›çº¦æŸçš„äººç±»ä¸“å®¶å¯ä»¥å°†ç›®æ ‡åˆ†è§£ä¸ºå­ç›®æ ‡ï¼Œæ¯ä¸ªå­ç›®æ ‡éƒ½å¯ä»¥é€šè¿‡å•ä¸€ä»£ç†è§„åˆ’æ¥å®ç°ï¼Œä»¥åˆ©ç”¨å¹¶è¡Œè¡ŒåŠ¨çš„ä¼˜åŠ¿ã€‚ä¸å¤å…¸è§„åˆ’ä¸åŒï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç›´æ¥ç”¨äºæ¨æ–­è§„åˆ’æ­¥éª¤å¾ˆå°‘èƒ½ä¿è¯æ‰§è¡ŒæˆåŠŸï¼Œä½†å®ƒä»¬èƒ½å¤Ÿåˆ©ç”¨å¸¸è¯†æ¨ç†æ¥ç»„åˆè¡ŒåŠ¨åºåˆ—ã€‚æˆ‘ä»¬é€šè¿‡è¿‘ä¼¼äººç±»çš„å¤šä»£ç†è§„åˆ’ç›®æ ‡åˆ†è§£ç›´è§‰æ¥ç»“åˆå¤å…¸è§„åˆ’å’ŒLLMçš„ä¼˜ç‚¹ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒåŸºäºLLMçš„ç›®æ ‡åˆ†è§£å¯¼è‡´æ›´å¿«çš„è§„åˆ’æ—¶é—´ï¼Œè€Œä¸”ä¸ç›´æ¥è§£å†³å¤šä»£ç†PDDLé—®é¢˜ç›¸æ¯”ï¼Œåœ¨åŒæ—¶å®ç°è¾ƒå°‘çš„è®¡åˆ’æ‰§è¡Œæ­¥éª¤çš„åŒæ—¶ä¿è¯æ‰§è¡ŒæˆåŠŸã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°åŸºäºLLMçš„è¿‘ä¼¼å­ç›®æ ‡å¯¼è‡´ä¸ä¸“å®¶æŒ‡å®šçš„å¤šä»£ç†æ‰§è¡Œé•¿åº¦ç›¸ä¼¼ã€‚ç›¸å…³ç½‘ç«™å’Œèµ„æºè¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://glamor-usc.github.io/twostep">https://glamor-usc.github.io/twostep</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17246v2">PDF</a> 14 pages</p>
<p><strong>Summary</strong>ï¼šå¤å…¸è§„åˆ’è¯­è¨€å¦‚PDDLè§„åˆ’ä¸»è¦é’ˆå¯¹å•ç›®æ ‡å®Œæˆçš„é—®é¢˜åœºæ™¯è®¾è®¡ï¼Œå¯ä»¥ä¿è¯å®Œæˆç‰¹å®šç›®æ ‡çš„è¡ŒåŠ¨åºåˆ—æˆåŠŸè¾¾æˆï¼Œä½†å¯¹å¤šä¸ªä¸»ä½“ä¹‹é—´çš„å¹¶å‘åŠ¨ä½œä¸­åŠ¨ä½œçš„æ—¶æ•ˆæ€§åŠé¡ºåºé—®é¢˜å¤„ç†å­˜åœ¨å±€é™ã€‚äººç±»ä¸“å®¶å¯ä»¥é€šè¿‡åˆ†è§£ç›®æ ‡ä¸ºå­ç›®æ ‡ï¼Œåˆ©ç”¨å•ä¸»ä½“è§„åˆ’çš„ä¼˜åŠ¿å®ç°å¹¶å‘åŠ¨ä½œã€‚æœ¬ç ”ç©¶ç»“åˆäº†å¤å…¸è§„åˆ’å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹æ¥æ¨¡æ‹Ÿåˆ†è§£å¤šä¸»ä½“è§„åˆ’çš„ç›®æ ‡ã€‚è¯¥ç ”ç©¶å±•ç°å‡ºè¾ƒå¿«çš„è§„åˆ’æ—¶é—´å’Œè¾ƒå°‘çš„æ‰§è¡Œæ­¥éª¤ï¼Œä¸”ä¿è¯äº†æ‰§è¡ŒæˆåŠŸã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶å‘ç°åŸºäºè¯­è¨€æ¨¡å‹çš„å­ç›®æ ‡åˆ†è§£ä¸ä¸“å®¶æŒ‡å®šçš„å­ç›®æ ‡æ‰§è¡Œé•¿åº¦ç›¸ä¼¼ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤å…¸è§„åˆ’è¯­è¨€å¦‚PDDLè§„åˆ’èƒ½ä¿è¯ç›®æ ‡è¾¾æˆçš„è¡ŒåŠ¨åºåˆ—æˆåŠŸï¼Œä½†å¤„ç†å¤šä¸»ä½“å¹¶å‘åŠ¨ä½œçš„æ—¶æ•ˆæ€§å­˜åœ¨é—®é¢˜ã€‚</li>
<li>äººç±»ä¸“å®¶å¯é€šè¿‡åˆ†è§£ç›®æ ‡ä¸ºå­ç›®æ ‡åˆ©ç”¨å•ä¸»ä½“è§„åˆ’çš„ä¼˜åŠ¿æ¥å®ç°å¹¶å‘åŠ¨ä½œã€‚</li>
<li>ç ”ç©¶ç»“åˆäº†å¤å…¸è§„åˆ’å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼˜åŠ¿è¿›è¡Œå¤šä¸»ä½“è§„åˆ’ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½åŠ å¿«è§„åˆ’æ—¶é—´å¹¶å‡å°‘æ‰§è¡Œæ­¥éª¤ï¼ŒåŒæ—¶ä¿è¯æ‰§è¡ŒæˆåŠŸã€‚</li>
<li>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å­ç›®æ ‡åˆ†è§£èƒ½æœ‰æ•ˆå®ç°ç±»ä¼¼ä¸“å®¶çº§åˆ«çš„æ‰§è¡Œé•¿åº¦ã€‚</li>
<li>è¯¥ç ”ç©¶æä¾›äº†ä¸€ä¸ªç½‘ç«™åŠç›¸å…³èµ„æºä¾›å…¬ä¼—æŸ¥é˜…å’Œå‚è€ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.17246">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-84383ba93162a596efc1009559d4468f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9dd729d71b20b4737c50e871e64aba76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ca2c0152544539a8c3375c3c00aab3b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd48724d8fb15196a99e57b7a5ea5481.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-566ceeb0b748e7fbe266f5213bdeeb83.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f0c2b22349cf18cc4390f946b35cdde1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a359e0e0903eaf1ea0b512edc6517226.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-28/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-28/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-28/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-b676d91c12009bfda247722bff30df3e.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-28  Reason-RFT Reinforcement Fine-Tuning for Visual Reasoning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-28/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-dd109bd7323dd466451e40f008ab6c81.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-28  Mobile-MMLU A Mobile Intelligence Language Understanding Benchmark
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32127.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
