<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-28  SaViD Spectravista Aesthetic Vision Integration for Robust and   Discerning 3D Object Detection in Challenging Environments">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-0f20ab4e75de3c994d67d2f6effa4f36.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    28 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-28-æ›´æ–°"><a href="#2025-03-28-æ›´æ–°" class="headerlink" title="2025-03-28 æ›´æ–°"></a>2025-03-28 æ›´æ–°</h1><h2 id="SaViD-Spectravista-Aesthetic-Vision-Integration-for-Robust-and-Discerning-3D-Object-Detection-in-Challenging-Environments"><a href="#SaViD-Spectravista-Aesthetic-Vision-Integration-for-Robust-and-Discerning-3D-Object-Detection-in-Challenging-Environments" class="headerlink" title="SaViD: Spectravista Aesthetic Vision Integration for Robust and   Discerning 3D Object Detection in Challenging Environments"></a>SaViD: Spectravista Aesthetic Vision Integration for Robust and   Discerning 3D Object Detection in Challenging Environments</h2><p><strong>Authors:Tanmoy Dam, Sanjay Bhargav Dharavath, Sameer Alam, Nimrod Lilith, Aniruddha Maiti, Supriyo Chakraborty, Mir Feroskhan</strong></p>
<p>The fusion of LiDAR and camera sensors has demonstrated significant effectiveness in achieving accurate detection for short-range tasks in autonomous driving. However, this fusion approach could face challenges when dealing with long-range detection scenarios due to disparity between sparsity of LiDAR and high-resolution camera data. Moreover, sensor corruption introduces complexities that affect the ability to maintain robustness, despite the growing adoption of sensor fusion in this domain. We present SaViD, a novel framework comprised of a three-stage fusion alignment mechanism designed to address long-range detection challenges in the presence of natural corruption. The SaViD framework consists of three key elements: the Global Memory Attention Network (GMAN), which enhances the extraction of image features through offering a deeper understanding of global patterns; the Attentional Sparse Memory Network (ASMN), which enhances the integration of LiDAR and image features; and the KNNnectivity Graph Fusion (KGF), which enables the entire fusion of spatial information. SaViD achieves superior performance on the long-range detection Argoverse-2 (AV2) dataset with a performance improvement of 9.87% in AP value and an improvement of 2.39% in mAPH for L2 difficulties on the Waymo Open dataset (WOD). Comprehensive experiments are carried out to showcase its robustness against 14 natural sensor corruptions. SaViD exhibits a robust performance improvement of 31.43% for AV2 and 16.13% for WOD in RCE value compared to other existing fusion-based methods while considering all the corruptions for both datasets. Our code is available at \href{<a target="_blank" rel="noopener" href="https://github.com/sanjay-810/SAVID%7D">https://github.com/sanjay-810/SAVID}</a> </p>
<blockquote>
<p>æ¿€å…‰é›·è¾¾å’Œç›¸æœºä¼ æ„Ÿå™¨çš„èåˆåœ¨è‡ªåŠ¨é©¾é©¶çš„çŸ­ç¨‹ä»»åŠ¡ä¸­å®ç°äº†å‡†ç¡®çš„æ£€æµ‹ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œå½“å¤„ç†è¿œç¨‹æ£€æµ‹åœºæ™¯æ—¶ï¼Œç”±äºæ¿€å…‰é›·è¾¾æ•°æ®çš„ç¨€ç–æ€§ä¸é«˜åˆ†è¾¨ç‡ç›¸æœºæ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œè¿™ç§èåˆæ–¹æ³•å¯èƒ½ä¼šé¢ä¸´æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œä¼ æ„Ÿå™¨æŸåå¼•å…¥äº†å¤æ‚æ€§ï¼Œå°½ç®¡è¯¥é¢†åŸŸè¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨ä¼ æ„Ÿå™¨èåˆï¼Œä½†ä»ç„¶ä¼šå½±å“ä¿æŒç¨³å¥æ€§çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†SaViDï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå®ƒåŒ…å«äº†ä¸€ä¸ªä¸‰é˜¶æ®µèåˆå¯¹é½æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³å­˜åœ¨è‡ªç„¶æŸåçš„è¿œç¨‹æ£€æµ‹æŒ‘æˆ˜ã€‚SaViDæ¡†æ¶ç”±ä¸‰ä¸ªå…³é”®å…ƒç´ ç»„æˆï¼šå…¨å±€è®°å¿†æ³¨æ„åŠ›ç½‘ç»œï¼ˆGMANï¼‰ï¼Œå®ƒé€šè¿‡æä¾›å¯¹å…¨å±€æ¨¡å¼çš„æ·±å…¥ç†è§£æ¥å¢å¼ºå›¾åƒç‰¹å¾çš„æå–ï¼›æ³¨æ„åŠ›ç¨€ç–è®°å¿†ç½‘ç»œï¼ˆASMNï¼‰ï¼Œå®ƒå¢å¼ºäº†æ¿€å…‰é›·è¾¾å’Œå›¾åƒç‰¹å¾çš„é›†æˆï¼›ä»¥åŠKNNè¿æ¥å›¾èåˆï¼ˆKGFï¼‰ï¼Œå®ƒå®ç°äº†ç©ºé—´ä¿¡æ¯çš„æ•´ä½“èåˆã€‚SaViDåœ¨Argoverse-2ï¼ˆAV2ï¼‰æ•°æ®é›†ä¸Šçš„è¿œç¨‹æ£€æµ‹è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œåœ¨APå€¼ä¸Šæé«˜äº†9.87%ï¼Œåœ¨Waymo Openæ•°æ®é›†ï¼ˆWODï¼‰çš„L2éš¾åº¦ä¸ŠmAPHæé«˜äº†2.39%ã€‚è¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œå±•ç¤ºäº†å…¶åœ¨14ç§è‡ªç„¶ä¼ æ„Ÿå™¨æŸåæƒ…å†µä¸‹çš„ç¨³å¥æ€§ã€‚ä¸å…¶ä»–ç°æœ‰çš„èåˆæ–¹æ³•ç›¸æ¯”ï¼Œåœ¨è€ƒè™‘æ‰€æœ‰æŸåå› ç´ çš„æƒ…å†µä¸‹ï¼ŒSaViDåœ¨AV2å’ŒWODçš„RCEå€¼ä¸Šåˆ†åˆ«æé«˜äº†31.43%å’Œ16.13%ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sanjay-810/SAVID%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sanjay-810/SAVIDä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20614v1">PDF</a> This paper has been accepted for ICRA 2025, and copyright will   automatically transfer to IEEE upon its availability on the IEEE portal</p>
<p><strong>Summary</strong><br>    æ¿€å…‰é›·è¾¾ä¸ç›¸æœºä¼ æ„Ÿå™¨çš„èåˆåœ¨è‡ªåŠ¨é©¾é©¶çš„çŸ­ç¨‹ä»»åŠ¡æ£€æµ‹ä¸­è¡¨ç°å“è¶Šã€‚ä½†é¢å¯¹é•¿ç¨‹æ£€æµ‹åœºæ™¯æ—¶ï¼Œç”±äºæ¿€å…‰é›·è¾¾æ•°æ®çš„ç¨€ç–æ€§ä¸é«˜åˆ†è¾¨ç‡ç›¸æœºæ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œè¿™ä¸€èåˆæ–¹æ³•å¯èƒ½é¢ä¸´æŒ‘æˆ˜ã€‚é’ˆå¯¹ä¼ æ„Ÿå™¨å¤±æ•ˆå¼•å…¥çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†SaViDæ¡†æ¶ï¼Œå®ƒåŒ…å«ä¸‰é˜¶æ®µèåˆå¯¹é½æœºåˆ¶ï¼Œæ—¨åœ¨åœ¨è‡ªç„¶å¤±æ•ˆæƒ…å†µä¸‹è§£å†³é•¿ç¨‹æ£€æµ‹æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªå…³é”®å…ƒç´ ç»„æˆï¼šå…¨çƒè®°å¿†æ³¨æ„åŠ›ç½‘ç»œï¼ˆGMANï¼‰ï¼Œå¢å¼ºå›¾åƒç‰¹å¾æå–å¹¶æ·±å…¥ç†è§£å…¨å±€æ¨¡å¼ï¼›æ³¨æ„åŠ›ç¨€ç–è®°å¿†ç½‘ç»œï¼ˆASMNï¼‰ï¼Œå¢å¼ºæ¿€å…‰é›·è¾¾å’Œå›¾åƒç‰¹å¾çš„èåˆï¼›ä»¥åŠKNNè¿æ¥å›¾èåˆï¼ˆKGFï¼‰ï¼Œå®ç°ç©ºé—´ä¿¡æ¯çš„å…¨é¢èåˆã€‚SaViDåœ¨Argoverse-2æ•°æ®é›†ä¸Šé•¿ç¨‹æ£€æµ‹è¡¨ç°ä¼˜å¼‚ï¼Œåœ¨Waymo Openæ•°æ®é›†ä¸Šäº¦æœ‰æ˜¾è‘—æå‡ã€‚è¯¥æ¡†æ¶å¯¹14ç§è‡ªç„¶ä¼ æ„Ÿå™¨å¤±æ•ˆè¡¨ç°å‡ºç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LiDARä¸ç›¸æœºä¼ æ„Ÿå™¨çš„èåˆåœ¨è‡ªåŠ¨é©¾é©¶çŸ­ç¨‹ä»»åŠ¡æ£€æµ‹ä¸­æ•ˆæœæ˜¾è‘—ã€‚</li>
<li>åœ¨å¤„ç†é•¿ç¨‹æ£€æµ‹åœºæ™¯æ—¶ï¼Œèåˆæ–¹æ³•å¯èƒ½å› æ•°æ®ç¨€ç–æ€§å’Œå·®å¼‚é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>SaViDæ¡†æ¶åŒ…å«ä¸‰é˜¶æ®µèåˆå¯¹é½æœºåˆ¶ï¼Œåº”å¯¹é•¿ç¨‹æ£€æµ‹æŒ‘æˆ˜åŠä¼ æ„Ÿå™¨å¤±æ•ˆé—®é¢˜ã€‚</li>
<li>SaViDæ¡†æ¶ç”±GMANã€ASMNå’ŒKGFä¸‰ä¸ªå…³é”®å…ƒç´ ç»„æˆï¼Œåˆ†åˆ«å¢å¼ºå›¾åƒç‰¹å¾æå–ã€ç‰¹å¾èåˆåŠç©ºé—´ä¿¡æ¯èåˆã€‚</li>
<li>SaViDåœ¨Argoverse-2å’ŒWaymo Openæ•°æ®é›†ä¸Šé•¿ç¨‹æ£€æµ‹è¡¨ç°ä¼˜å¼‚ï¼Œç›¸æ¯”å…¶ä»–èåˆæ–¹æ³•æœ‰æ˜æ˜¾æå‡ã€‚</li>
<li>SaViDå¯¹å¤šç§è‡ªç„¶ä¼ æ„Ÿå™¨å¤±æ•ˆè¡¨ç°å‡ºç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20614">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-36b9741a71daf83fc7387212583ac30f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98e745994194bee179ace81ca328e455.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6457707f9e154b74a05d6ff4b36baf1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7db85549301fbc66b857fdb16f837983.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9cdd355792801e87dc03193b090578d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a58494356136e213101b344bcaffbe94.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Small-Object-Detection-A-Comprehensive-Survey-on-Challenges-Techniques-and-Real-World-Applications"><a href="#Small-Object-Detection-A-Comprehensive-Survey-on-Challenges-Techniques-and-Real-World-Applications" class="headerlink" title="Small Object Detection: A Comprehensive Survey on Challenges, Techniques   and Real-World Applications"></a>Small Object Detection: A Comprehensive Survey on Challenges, Techniques   and Real-World Applications</h2><p><strong>Authors:Mahya Nikouei, Bita Baroutian, Shahabedin Nabavi, Fateme Taraghi, Atefe Aghaei, Ayoob Sajedi, Mohsen Ebrahimi Moghaddam</strong></p>
<p>Small object detection (SOD) is a critical yet challenging task in computer vision, with applications like spanning surveillance, autonomous systems, medical imaging, and remote sensing. Unlike larger objects, small objects contain limited spatial and contextual information, making accurate detection difficult. Challenges such as low resolution, occlusion, background interference, and class imbalance further complicate the problem. This survey provides a comprehensive review of recent advancements in SOD using deep learning, focusing on articles published in Q1 journals during 2024-2025. We analyzed challenges, state-of-the-art techniques, datasets, evaluation metrics, and real-world applications. Recent advancements in deep learning have introduced innovative solutions, including multi-scale feature extraction, Super-Resolution (SR) techniques, attention mechanisms, and transformer-based architectures. Additionally, improvements in data augmentation, synthetic data generation, and transfer learning have addressed data scarcity and domain adaptation issues. Furthermore, emerging trends such as lightweight neural networks, knowledge distillation (KD), and self-supervised learning offer promising directions for improving detection efficiency, particularly in resource-constrained environments like Unmanned Aerial Vehicles (UAV)-based surveillance and edge computing. We also review widely used datasets, along with standard evaluation metrics such as mean Average Precision (mAP) and size-specific AP scores. The survey highlights real-world applications, including traffic monitoring, maritime surveillance, industrial defect detection, and precision agriculture. Finally, we discuss open research challenges and future directions, emphasizing the need for robust domain adaptation techniques, better feature fusion strategies, and real-time performance optimization. </p>
<blockquote>
<p>å°ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰æ˜¯è®¡ç®—æœºè§†è§‰ä¸­ä¸€é¡¹è‡³å…³é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå…¶åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç›‘æ§ã€è‡ªä¸»ç³»ç»Ÿã€åŒ»å­¦æˆåƒå’Œé¥æ„Ÿç­‰ã€‚ä¸å¤§å‹ç‰©ä½“ä¸åŒï¼Œå°ç›®æ ‡åŒ…å«æœ‰é™çš„ç©ºé—´å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä½¿å¾—å‡†ç¡®æ£€æµ‹å˜å¾—å›°éš¾ã€‚ä½åˆ†è¾¨ç‡ã€é®æŒ¡ã€èƒŒæ™¯å¹²æ‰°å’Œç±»åˆ«ä¸å¹³è¡¡ç­‰æŒ‘æˆ˜è¿›ä¸€æ­¥åŠ å‰§äº†é—®é¢˜ã€‚æœ¬æ–‡å…¨é¢å›é¡¾äº†æœ€è¿‘ä½¿ç”¨æ·±åº¦å­¦ä¹ åœ¨SODæ–¹é¢çš„è¿›å±•ï¼Œé‡ç‚¹å…³æ³¨2024-2025å¹´æœŸé—´åœ¨Q1æœŸåˆŠä¸Šå‘è¡¨çš„æ–‡ç« ã€‚æˆ‘ä»¬åˆ†æäº†æŒ‘æˆ˜ã€æœ€æ–°æŠ€æœ¯ã€æ•°æ®é›†ã€è¯„ä¼°æŒ‡æ ‡å’Œå®é™…åº”ç”¨ã€‚æ·±åº¦å­¦ä¹ çš„æœ€æ–°è¿›å±•å¼•å…¥äº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å¤šå°ºåº¦ç‰¹å¾æå–ã€è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æŠ€æœ¯ã€æ³¨æ„åŠ›æœºåˆ¶å’ŒåŸºäºtransformerçš„æ¶æ„ã€‚æ­¤å¤–ï¼Œæ•°æ®å¢å¼ºã€åˆæˆæ•°æ®ç”Ÿæˆå’Œè¿ç§»å­¦ä¹ çš„æ”¹è¿›è§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œé¢†åŸŸé€‚åº”æ€§é—®é¢˜ã€‚å¦å¤–ï¼Œæ–°å…´è¶‹åŠ¿å¦‚è½»é‡çº§ç¥ç»ç½‘ç»œã€çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰å’Œè‡ªæˆ‘ç›‘ç£å­¦ä¹ ä¸ºæé«˜æ£€æµ‹æ•ˆç‡æä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ï¼Œç‰¹åˆ«æ˜¯åœ¨æ— äººæœºï¼ˆUAVï¼‰ç›‘æ§å’Œè¾¹ç¼˜è®¡ç®—ç­‰èµ„æºå—é™çš„ç¯å¢ƒä¸­ã€‚æˆ‘ä»¬è¿˜å›é¡¾äº†å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä»¥åŠå¦‚å¹³å‡ç²¾åº¦ï¼ˆmAPï¼‰å’Œå°ºå¯¸ç‰¹å®šAPåˆ†æ•°ç­‰æ ‡å‡†è¯„ä¼°æŒ‡æ ‡ã€‚è¯¥è°ƒæŸ¥å¼ºè°ƒäº†å®é™…åº”ç”¨ï¼ŒåŒ…æ‹¬äº¤é€šç›‘æ§ã€æµ·äº‹ç›‘æ§ã€å·¥ä¸šç¼ºé™·æ£€æµ‹å’Œç²¾å‡†å†œä¸šã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å¼€æ”¾çš„ç ”ç©¶æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ï¼Œå¼ºè°ƒéœ€è¦å¼ºå¤§çš„é¢†åŸŸé€‚åº”æŠ€æœ¯ã€æ›´å¥½çš„ç‰¹å¾èåˆç­–ç•¥å’Œå®æ—¶æ€§èƒ½ä¼˜åŒ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20516v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæœ¬æ–‡ç»¼è¿°äº†è¿‘æœŸåˆ©ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œå°ç›®æ ‡æ£€æµ‹çš„è¿›å±•ï¼Œæ¢è®¨äº†æ‰€é¢ä¸´çš„æŒ‘æˆ˜å’Œæœ€æ–°æŠ€æœ¯ï¼Œå¦‚å¤šå°ºåº¦ç‰¹å¾æå–ã€è¶…åˆ†è¾¨ç‡æŠ€æœ¯ã€æ³¨æ„åŠ›æœºåˆ¶å’ŒåŸºäºtransformerçš„æ¶æ„ç­‰ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜ä»‹ç»äº†æ”¹è¿›çš„æ•°æ®å¢å¼ºã€åˆæˆæ•°æ®ç”Ÿæˆå’Œè¿ç§»å­¦ä¹ ç­‰æ–¹æ³•ï¼Œä»¥è§£å†³æ•°æ®ç¨€ç¼ºå’Œé¢†åŸŸé€‚åº”æ€§é—®é¢˜ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†è½»é‡çº§ç¥ç»ç½‘ç»œã€çŸ¥è¯†è’¸é¦å’Œè‡ªç›‘ç£å­¦ä¹ ç­‰æ–°å…´è¶‹åŠ¿åœ¨æé«˜æ£€æµ‹æ•ˆç‡æ–¹é¢çš„å‰æ™¯ã€‚æ–‡ç« è¿˜è®¨è®ºäº†çœŸå®åº”ç”¨ï¼Œå¦‚äº¤é€šç›‘æ§ã€æµ·äº‹ç›‘æ§ç­‰ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å°ç›®æ ‡æ£€æµ‹åœ¨è®¡ç®—æœºè§†è§‰ä¸­æ˜¯å…³é”®ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæ¶‰åŠå¤šä¸ªåº”ç”¨é¢†åŸŸï¼Œå¦‚ç›‘æ§ã€è‡ªä¸»ç³»ç»Ÿç­‰ã€‚</li>
<li>å°ç›®æ ‡æ£€æµ‹é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚ä½åˆ†è¾¨ç‡ã€é®æŒ¡ã€èƒŒæ™¯å¹²æ‰°å’Œç±»åˆ«ä¸å¹³è¡¡ç­‰ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨è§£å†³å°ç›®æ ‡æ£€æµ‹æ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ï¼ŒåŒ…æ‹¬å¤šå°ºåº¦ç‰¹å¾æå–ã€è¶…åˆ†è¾¨ç‡æŠ€æœ¯ç­‰æ–¹æ³•ã€‚</li>
<li>æ”¹è¿›çš„æ•°æ®å¢å¼ºå’Œè¿ç§»å­¦ä¹ ç­‰æŠ€æœ¯è§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œé¢†åŸŸé€‚åº”æ€§é—®é¢˜ã€‚</li>
<li>æ–°å…´è¶‹åŠ¿å¦‚è½»é‡çº§ç¥ç»ç½‘ç»œã€çŸ¥è¯†è’¸é¦å’Œè‡ªç›‘ç£å­¦ä¹ æœ‰æœ›æé«˜æ£€æµ‹æ•ˆç‡ã€‚</li>
<li>æ–‡ç« æ¶µç›–çš„å®é™…åº”ç”¨é¢†åŸŸå¹¿æ³›ï¼ŒåŒ…æ‹¬äº¤é€šç›‘æ§ã€æµ·äº‹ç›‘æ§ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20516">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f92395b5510f497df9c03cb18bdf28e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef410e8020bc5d0fd7f216d66c701d5b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EVT-Efficient-View-Transformation-for-Multi-Modal-3D-Object-Detection"><a href="#EVT-Efficient-View-Transformation-for-Multi-Modal-3D-Object-Detection" class="headerlink" title="EVT: Efficient View Transformation for Multi-Modal 3D Object Detection"></a>EVT: Efficient View Transformation for Multi-Modal 3D Object Detection</h2><p><strong>Authors:Yongjin Lee, Hyeon-Mun Jeong, Yurim Jeon, Sanghyun Kim</strong></p>
<p>Multi-modal sensor fusion in Birdâ€™s Eye View (BEV) representation has become the leading approach for 3D object detection. However, existing methods often rely on depth estimators or transformer encoders to transform image features into BEV space, which reduces robustness or introduces significant computational overhead. Moreover, the insufficient geometric guidance in view transformation results in ray-directional misalignments, limiting the effectiveness of BEV representations. To address these challenges, we propose Efficient View Transformation (EVT), a novel 3D object detection framework that constructs a well-structured BEV representation, improving both accuracy and efficiency. Our approach focuses on two key aspects. First, Adaptive Sampling and Adaptive Projection (ASAP), which utilizes LiDAR guidance to generate 3D sampling points and adaptive kernels, enables more effective transformation of image features into BEV space and a refined BEV representation. Second, an improved query-based detection framework, incorporating group-wise mixed query selection and geometry-aware cross-attention, effectively captures both the common properties and the geometric structure of objects in the transformer decoder. On the nuScenes test set, EVT achieves state-of-the-art performance of 75.3% NDS with real-time inference speed. </p>
<blockquote>
<p>å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆåœ¨é¸Ÿç°å›¾ï¼ˆBEVï¼‰è¡¨ç¤ºå·²æˆä¸º3Då¯¹è±¡æ£€æµ‹çš„ä¸»æµæ–¹æ³•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ·±åº¦ä¼°è®¡å™¨æˆ–å˜å‹å™¨ç¼–ç å™¨å°†å›¾åƒç‰¹å¾è½¬æ¢ä¸ºBEVç©ºé—´ï¼Œè¿™é™ä½äº†é²æ£’æ€§æˆ–å¼•å…¥äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œè§†å›¾å˜æ¢ä¸­å‡ ä½•æŒ‡å¯¼çš„ä¸è¶³å¯¼è‡´å°„çº¿æ–¹å‘é”™ä½ï¼Œé™åˆ¶äº†BEVè¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Efficient View Transformationï¼ˆEVTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹3Då¯¹è±¡æ£€æµ‹æ¡†æ¶ï¼Œæ„å»ºäº†ç»“æ„è‰¯å¥½çš„BEVè¡¨ç¤ºï¼Œæé«˜äº†å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¾§é‡äºä¸¤ä¸ªå…³é”®æ–¹é¢ã€‚é¦–å…ˆï¼Œè‡ªé€‚åº”é‡‡æ ·å’Œè‡ªé€‚åº”æŠ•å½±ï¼ˆASAPï¼‰åˆ©ç”¨æ¿€å…‰é›·è¾¾æŒ‡å¯¼ç”Ÿæˆ3Dé‡‡æ ·ç‚¹å’Œè‡ªé€‚åº”å†…æ ¸ï¼Œå®ç°äº†æ›´æœ‰æ•ˆçš„å›¾åƒç‰¹å¾åˆ°BEVç©ºé—´çš„è½¬æ¢å’Œæ›´ç²¾ç»†çš„BEVè¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œæ”¹è¿›çš„åŸºäºæŸ¥è¯¢çš„æ£€æµ‹æ¡†æ¶ï¼Œç»“åˆåˆ†ç»„æ··åˆæŸ¥è¯¢é€‰æ‹©å’Œå‡ ä½•æ„ŸçŸ¥äº¤å‰æ³¨æ„åŠ›ï¼Œæœ‰æ•ˆåœ°æ•è·äº†å˜å‹å™¨è§£ç å™¨ä¸­å¯¹è±¡çš„å…±åŒå±æ€§å’Œå‡ ä½•ç»“æ„ã€‚åœ¨nuscenesæµ‹è¯•é›†ä¸Šï¼ŒEVTå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå®æ—¶æ¨ç†é€Ÿåº¦ä¸º75.3%NDSã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.10715v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆåœ¨é¸Ÿç°å›¾ï¼ˆBEVï¼‰è¡¨ç¤ºå·²æˆä¸º3Då¯¹è±¡æ£€æµ‹çš„ä¸»æµæ–¹æ³•ã€‚ä½†ç°æœ‰æ–¹æ³•å¸¸ä¾èµ–æ·±åº¦ä¼°è®¡å™¨æˆ–è½¬æ¢å™¨ç¼–ç å™¨å°†å›¾åƒç‰¹å¾è½¬æ¢ä¸ºBEVç©ºé—´ï¼Œè¿™é™ä½äº†ç¨³å¥æ€§æˆ–å¼•å…¥äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œè§†å›¾å˜æ¢ä¸­å‡ ä½•æŒ‡å¯¼çš„ä¸è¶³å¯¼è‡´å°„çº¿æ–¹å‘çš„è¯¯å¯¹é½ï¼Œé™åˆ¶äº†BEVè¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†é«˜æ•ˆè§†å›¾å˜æ¢ï¼ˆEVTï¼‰æ¡†æ¶ï¼Œæ„å»ºç»“æ„è‰¯å¥½çš„BEVè¡¨ç¤ºï¼Œæé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¯¥æ¡†æ¶å…³æ³¨è‡ªé€‚åº”é‡‡æ ·å’Œè‡ªé€‚åº”æŠ•å½±ï¼ˆASAPï¼‰å’Œåˆ©ç”¨æ¿€å…‰é›·è¾¾æŒ‡å¯¼ç”Ÿæˆ3Dé‡‡æ ·ç‚¹å’Œè‡ªé€‚åº”å†…æ ¸ï¼Œä»¥åŠæ”¹è¿›åŸºäºæŸ¥è¯¢çš„æ£€æµ‹æ¡†æ¶ï¼Œç»“åˆåˆ†ç»„æ··åˆæŸ¥è¯¢é€‰æ‹©å’Œå‡ ä½•æ„ŸçŸ¥äº¤å‰æ³¨æ„åŠ›ï¼Œæœ‰æ•ˆæ•æ‰å¯¹è±¡çš„å…±åŒå±æ€§å’Œå‡ ä½•ç»“æ„ã€‚åœ¨nuScenesæµ‹è¯•é›†ä¸Šï¼ŒEVTå®ç°äº†å…·æœ‰å®æ—¶æ¨ç†é€Ÿåº¦çš„æœ€æ–°æ€§èƒ½ï¼ŒNDSè¾¾åˆ°75.3%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆåœ¨é¸Ÿç°å›¾è¡¨ç¤ºæ˜¯3Då¯¹è±¡æ£€æµ‹çš„ä¸»æµæ–¹æ³•ã€‚</li>
<li>å½“å‰æ–¹æ³•å­˜åœ¨ç¨³å¥æ€§é™ä½å’Œè®¡ç®—å¼€é”€å¤§çš„é—®é¢˜ã€‚</li>
<li>è§†å›¾å˜æ¢ä¸­çš„å‡ ä½•æŒ‡å¯¼ä¸è¶³å¯¼è‡´å°„çº¿æ–¹å‘çš„è¯¯å¯¹é½ã€‚</li>
<li>æå‡ºEfficient View Transformation (EVT)æ¡†æ¶ï¼Œæ„å»ºç»“æ„è‰¯å¥½çš„BEVè¡¨ç¤ºæé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>EVTæ¡†æ¶åŒ…æ‹¬è‡ªé€‚åº”é‡‡æ ·å’Œè‡ªé€‚åº”æŠ•å½±ï¼ˆASAPï¼‰ï¼Œåˆ©ç”¨LiDARæŒ‡å¯¼ç”Ÿæˆ3Dé‡‡æ ·ç‚¹å’Œè‡ªé€‚åº”å†…æ ¸ã€‚</li>
<li>æ”¹è¿›äº†åŸºäºæŸ¥è¯¢çš„æ£€æµ‹æ¡†æ¶ï¼Œç»“åˆåˆ†ç»„æ··åˆæŸ¥è¯¢é€‰æ‹©å’Œå‡ ä½•æ„ŸçŸ¥äº¤å‰æ³¨æ„åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.10715">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5a85787a835b31b39399d85464d37d23.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee6a4576cddd4c3c719e05a8f357f279.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c773087bdcb5373cd78501bf370dcc13.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f05e67203f09b8fad7dd4ff587702528.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Fractal-Calibration-for-long-tailed-object-detection"><a href="#Fractal-Calibration-for-long-tailed-object-detection" class="headerlink" title="Fractal Calibration for long-tailed object detection"></a>Fractal Calibration for long-tailed object detection</h2><p><strong>Authors:Konstantinos Panagiotis Alexandridis, Ismail Elezi, Jiankang Deng, Anh Nguyen, Shan Luo</strong></p>
<p>Real-world datasets follow an imbalanced distribution, which poses significant challenges in rare-category object detection. Recent studies tackle this problem by developing re-weighting and re-sampling methods, that utilise the class frequencies of the dataset. However, these techniques focus solely on the frequency statistics and ignore the distribution of the classes in image space, missing important information. In contrast to them, we propose FRActal CALibration (FRACAL): a novel post-calibration method for long-tailed object detection. FRACAL devises a logit adjustment method that utilises the fractal dimension to estimate how uniformly classes are distributed in image space. During inference, it uses the fractal dimension to inversely downweight the probabilities of uniformly spaced class predictions achieving balance in two axes: between frequent and rare categories, and between uniformly spaced and sparsely spaced classes. FRACAL is a post-processing method and it does not require any training, also it can be combined with many off-the-shelf models such as one-stage sigmoid detectors and two-stage instance segmentation models. FRACAL boosts the rare class performance by up to 8.6% and surpasses all previous methods on LVIS dataset, while showing good generalisation to other datasets such as COCO, V3Det and OpenImages. We provide the code at <a target="_blank" rel="noopener" href="https://github.com/kostas1515/FRACAL">https://github.com/kostas1515/FRACAL</a>. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œçš„æ•°æ®é›†å‘ˆç°å‡ºä¸å‡è¡¡çš„åˆ†å¸ƒï¼Œè¿™ç»™ç½•è§ç±»åˆ«å¯¹è±¡æ£€æµ‹å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡å¼€å‘é‡æ–°åŠ æƒå’Œé‡æ–°é‡‡æ ·æ–¹æ³•æ¥è§£å†³æ­¤é—®é¢˜ï¼Œè¿™äº›æ–¹æ³•åˆ©ç”¨æ•°æ®é›†çš„ç±»åˆ«é¢‘ç‡ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯åªå…³æ³¨é¢‘ç‡ç»Ÿè®¡ï¼Œè€Œå¿½ç•¥äº†ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒï¼Œä»è€Œä¸¢å¤±äº†é‡è¦ä¿¡æ¯ã€‚ä¸ä¹‹ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†FRACtal CALibrationï¼ˆFRACALï¼‰ï¼šä¸€ç§æ–°å‹çš„é’ˆå¯¹é•¿å°¾å¯¹è±¡æ£€æµ‹çš„åæ ¡å‡†æ–¹æ³•ã€‚FRACALè®¾è®¡äº†ä¸€ç§å¯¹æ•°å‡ ç‡è°ƒæ•´æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å½¢ç»´åº¦æ¥ä¼°è®¡ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒæœ‰å¤šå‡åŒ€ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå®ƒä½¿ç”¨åˆ†å½¢ç»´åº¦æ¥é€†å‘ä¸‹è°ƒæ•´å‡åŒ€é—´éš”çš„ç±»åˆ«é¢„æµ‹çš„æ¦‚ç‡ï¼Œä»è€Œåœ¨ä¸¤ä¸ªè½´ï¼ˆå¸¸è§ç±»åˆ«ä¸ç½•è§ç±»åˆ«ä¹‹é—´ï¼Œä»¥åŠå‡åŒ€é—´éš”çš„ç±»åˆ«ä¸ç¨€ç–é—´éš”çš„ç±»åˆ«ä¹‹é—´ï¼‰ä¸Šå®ç°å¹³è¡¡ã€‚FRACALæ˜¯ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼Œå®ƒå¯ä»¥ä¸è®¸å¤šç°æˆçš„æ¨¡å‹ï¼ˆå¦‚å•é˜¶æ®µSigmoidæ£€æµ‹å™¨å’Œä¸¤é˜¶æ®µå®ä¾‹åˆ†å‰²æ¨¡å‹ï¼‰ç›¸ç»“åˆã€‚FRACALæé«˜äº†ç½•è§ç±»åˆ«çš„æ€§èƒ½ï¼Œæé«˜äº†é«˜è¾¾8.6%ï¼Œå¹¶åœ¨LVISæ•°æ®é›†ä¸Šè¶…è¶Šäº†æ‰€æœ‰ä»¥å‰çš„æ–¹æ³•ï¼ŒåŒæ—¶è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºå…¶ä»–æ•°æ®é›†å¦‚COCOã€V3Detå’ŒOpenImagesã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/kostas1515/FRACAL">https://github.com/kostas1515/FRACAL</a>æä¾›ä»£ç ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.11774v3">PDF</a> CVPR2025 (camera-ready)</p>
<p><strong>Summary</strong><br>å®æ—¶ä¸–ç•Œçš„çœŸå®æ•°æ®é›†å‘ˆç°å‡ºä¸å‡è¡¡çš„åˆ†å¸ƒï¼Œå¯¼è‡´ç½•è§ç±»åˆ«çš„ç›®æ ‡æ£€æµ‹é¢ä¸´æŒ‘æˆ˜ã€‚æœ€æ–°ç ”ç©¶é€šè¿‡å¼€å‘å†åŠ æƒå’Œå†é‡‡æ ·æ–¹æ³•è§£å†³è¿™ä¸€é—®é¢˜ï¼Œåˆ©ç”¨æ•°æ®é›†ä¸­çš„ç±»åˆ«é¢‘ç‡ç»Ÿè®¡ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä»…å…³æ³¨é¢‘ç‡ç»Ÿè®¡è€Œå¿½ç•¥äº†ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒï¼Œä¸¢å¤±äº†é‡è¦ä¿¡æ¯ã€‚ç›¸åï¼Œæˆ‘ä»¬æå‡ºFRActal CALibrationï¼ˆFRACALï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„åæ ¡å‡†æ–¹æ³•ç”¨äºé•¿å°¾ç›®æ ‡æ£€æµ‹ã€‚FRACALè®¾è®¡äº†ä¸€ç§å¯¹æ•°å‡ ç‡è°ƒæ•´æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å½¢ç»´åº¦ä¼°è®¡ç±»åˆ«åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒå‡åŒ€æ€§ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå®ƒä½¿ç”¨åˆ†å½¢ç»´åº¦é€†å‘è°ƒæ•´å‡åŒ€åˆ†å¸ƒç±»åˆ«é¢„æµ‹çš„æ¦‚ç‡ï¼Œåœ¨é¢‘ç¹å’Œç½•è§ç±»åˆ«ä¹‹é—´ä»¥åŠå‡åŒ€åˆ†å¸ƒå’Œç¨€ç–åˆ†å¸ƒç±»åˆ«ä¹‹é—´å®ç°å¹³è¡¡ã€‚FRACALæ˜¯ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒè¿‡ç¨‹ï¼Œå¯ä»¥ä¸è®¸å¤šç°æˆçš„æ¨¡å‹ï¼ˆå¦‚å•é˜¶æ®µSigmoidæ£€æµ‹å™¨å’Œä¸¤é˜¶æ®µå®ä¾‹åˆ†å‰²æ¨¡å‹ï¼‰ç›¸ç»“åˆä½¿ç”¨ã€‚å®ƒé€šè¿‡æé«˜ç½•è§ç±»åˆ«çš„æ€§èƒ½è‡³é«˜è¾¾8.6%ï¼Œåœ¨LVISæ•°æ®é›†ä¸Šè¶…è¶Šæ‰€æœ‰å…ˆå‰çš„æ–¹æ³•ï¼Œå¹¶åœ¨å…¶ä»–æ•°æ®é›†å¦‚COCOã€V3Detå’ŒOpenImagesä¸Šå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚ä»£ç å…¬å¼€äºï¼š<a target="_blank" rel="noopener" href="https://github.com/kostas1515/FRACAL%E3%80%82">https://github.com/kostas1515/FRACALã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>çœŸå®ä¸–ç•Œæ•°æ®é›†å­˜åœ¨ç±»åˆ«ä¸å‡è¡¡é—®é¢˜ï¼Œå½±å“ç½•è§ç±»åˆ«ç›®æ ‡æ£€æµ‹ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨ç±»åˆ«é¢‘ç‡ç»Ÿè®¡ï¼Œå¿½ç•¥äº†å…¶åœ¨å›¾åƒç©ºé—´ä¸­çš„åˆ†å¸ƒã€‚</li>
<li>FRACALæ˜¯ä¸€ç§åæ ¡å‡†æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å½¢ç»´åº¦æ¥ä¼°è®¡ç±»åˆ«åˆ†å¸ƒçš„å‡åŒ€æ€§ï¼Œå¹¶è°ƒæ•´å¯¹æ•°å‡ ç‡ã€‚</li>
<li>FRACALåœ¨æ¨ç†è¿‡ç¨‹ä¸­å®ç°ç±»åˆ«å¹³è¡¡ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚</li>
<li>FRACALå¯ä¸å…¶ä»–æ£€æµ‹æ¨¡å‹ç»“åˆä½¿ç”¨ï¼Œæé«˜ç½•è§ç±»åˆ«çš„æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>FRACALåœ¨LVISæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºå…¶ä»–æ•°æ®é›†å¦‚COCOã€V3Detå’ŒOpenImagesã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.11774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-61705bbd6d4503976d5e6bc732f2898d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e509b4c0c7665d0d3cd95f0a3e90f6d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2ce19e79997329618fd498c1981297cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f959787b2132de32e9c10ebece77f1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f20ab4e75de3c994d67d2f6effa4f36.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Believing-is-Seeing-Unobserved-Object-Detection-using-Generative-Models"><a href="#Believing-is-Seeing-Unobserved-Object-Detection-using-Generative-Models" class="headerlink" title="Believing is Seeing: Unobserved Object Detection using Generative Models"></a>Believing is Seeing: Unobserved Object Detection using Generative Models</h2><p><strong>Authors:Subhransu S. Bhattacharjee, Dylan Campbell, Rahul Shome</strong></p>
<p>Can objects that are not visible in an image â€“ but are in the vicinity of the camera â€“ be detected? This study introduces the novel tasks of 2D, 2.5D and 3D unobserved object detection for predicting the location of nearby objects that are occluded or lie outside the image frame. We adapt several state-of-the-art pre-trained generative models to address this task, including 2D and 3D diffusion models and vision-language models, and show that they can be used to infer the presence of objects that are not directly observed. To benchmark this task, we propose a suite of metrics that capture different aspects of performance. Our empirical evaluation on indoor scenes from the RealEstate10k and NYU Depth v2 datasets demonstrate results that motivate the use of generative models for the unobserved object detection task. </p>
<blockquote>
<p>åœ¨å›¾åƒä¸­ä¸å¯è§ä½†ä½äºç›¸æœºé™„è¿‘çš„å¯¹è±¡èƒ½å¦è¢«æ£€æµ‹å‡ºæ¥ï¼Ÿæœ¬ç ”ç©¶å¼•å…¥äº†ç”¨äºé¢„æµ‹è¢«é®æŒ¡æˆ–ä½äºå›¾åƒå¸§ä¹‹å¤–çš„é™„è¿‘å¯¹è±¡ä½ç½®çš„äºŒç»´ã€2.5ç»´å’Œä¸‰ç»´æœªè§‚æµ‹å¯¹è±¡æ£€æµ‹çš„æ–°ä»»åŠ¡ã€‚æˆ‘ä»¬é€‚åº”äº†å‡ ç§æœ€æ–°çš„é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹æ¥è§£å†³æ­¤ä»»åŠ¡ï¼ŒåŒ…æ‹¬äºŒç»´å’Œä¸‰ç»´æ‰©æ•£æ¨¡å‹ä»¥åŠè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶å±•ç¤ºäº†å®ƒä»¬å¯ç”¨äºæ¨æ–­æœªç›´æ¥è§‚å¯Ÿåˆ°çš„å¯¹è±¡çš„å­˜åœ¨ã€‚ä¸ºäº†å¯¹è¿™é¡¹ä»»åŠ¡è¿›è¡Œè¯„ä¼°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€å¥—æ¶µç›–æ€§èƒ½ä¸åŒæ–¹é¢çš„åº¦é‡æŒ‡æ ‡ã€‚æˆ‘ä»¬åœ¨RealEstate10kå’ŒNYU Depth v2æ•°æ®é›†ä¸Šçš„å®¤å†…åœºæ™¯è¿›è¡Œçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œä½¿ç”¨ç”Ÿæˆæ¨¡å‹è¿›è¡Œæœªè§‚æµ‹å¯¹è±¡æ£€æµ‹ä»»åŠ¡çš„ç»“æœå…·æœ‰æ¿€åŠ±ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.05869v4">PDF</a> IEEE&#x2F;CVF Computer Vision and Pattern Recognition 2025; 22 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶çš„æ˜¯ä¸å¯è§ç‰©ä½“çš„æ£€æµ‹é—®é¢˜ï¼Œå³åœ¨å›¾åƒä¸­ä¸å¯è§ä½†åœ¨ç›¸æœºé™„è¿‘å­˜åœ¨çš„ç‰©ä½“çš„æ£€æµ‹ã€‚è¯¥ç ”ç©¶æå‡ºäº†2Dã€2.5Då’Œ3Dæœªè§‚æµ‹ç‰©ä½“æ£€æµ‹çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨é¢„æµ‹è¢«é®æŒ¡æˆ–ä½äºå›¾åƒå¸§å¤–çš„é™„è¿‘ç‰©ä½“çš„ä½ç½®ã€‚æ–‡ç« é€‚åº”äº†å…ˆè¿›çš„é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹æ¥å®Œæˆæ­¤ä»»åŠ¡ï¼ŒåŒ…æ‹¬2Då’Œ3Dæ‰©æ•£æ¨¡å‹ä»¥åŠè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶å±•ç¤ºäº†è¿™äº›æ¨¡å‹å¯æ¨çŸ¥æœªç›´æ¥è§‚å¯Ÿåˆ°çš„ç‰©ä½“çš„å­˜åœ¨ã€‚è¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€å¥—è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡æ€§èƒ½çš„ä¸åŒæ–¹é¢ï¼Œå¹¶é€šè¿‡RealEstate10kå’ŒNYU Depth v2æ•°æ®é›†çš„å®éªŒè¯„ä¼°éªŒè¯äº†ç”Ÿæˆæ¨¡å‹åœ¨æœªè§‚æµ‹ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸­çš„å®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å…³æ³¨äºåœ¨å›¾åƒä¸­ä¸å¯è§ä½†åœ¨ç›¸æœºé™„è¿‘å­˜åœ¨çš„ç‰©ä½“çš„æ£€æµ‹é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†2Dã€2.5Då’Œ3Dæœªè§‚æµ‹ç‰©ä½“æ£€æµ‹çš„æ–°ä»»åŠ¡ã€‚</li>
<li>ç ”ç©¶é€‚åº”å¹¶ä½¿ç”¨äº†å…ˆè¿›çš„é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬æ‰©æ•£æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ã€‚</li>
<li>è¿™äº›æ¨¡å‹èƒ½å¤Ÿæ¨çŸ¥æœªç›´æ¥è§‚å¯Ÿåˆ°çš„ç‰©ä½“çš„å­˜åœ¨ã€‚</li>
<li>æå‡ºäº†ä¸€å¥—è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡æœªè§‚æµ‹ç‰©ä½“æ£€æµ‹ä»»åŠ¡çš„ä¸åŒæ€§èƒ½ã€‚</li>
<li>é€šè¿‡RealEstate10kå’ŒNYU Depth v2æ•°æ®é›†çš„å®éªŒè¯„ä¼°éªŒè¯äº†ç”Ÿæˆæ¨¡å‹çš„å®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.05869">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-eae9f439848267a4357beb0b1379a950.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6eff8ced9348e87b7694e15f4077cad.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a85ca8415f5e032cf76849d28e8c5b40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e3f4f85b9de671f8231fd675f9522b5.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MonoTAKD-Teaching-Assistant-Knowledge-Distillation-for-Monocular-3D-Object-Detection"><a href="#MonoTAKD-Teaching-Assistant-Knowledge-Distillation-for-Monocular-3D-Object-Detection" class="headerlink" title="MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D   Object Detection"></a>MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D   Object Detection</h2><p><strong>Authors:Hou-I Liu, Christine Wu, Jen-Hao Cheng, Wenhao Chai, Shian-Yun Wang, Gaowen Liu, Hugo Latapie, Jhih-Ciang Wu, Jenq-Neng Hwang, Hong-Han Shuai, Wen-Huang Cheng</strong></p>
<p>Monocular 3D object detection (Mono3D) holds noteworthy promise for autonomous driving applications owing to the cost-effectiveness and rich visual context of monocular camera sensors. However, depth ambiguity poses a significant challenge, as it requires extracting precise 3D scene geometry from a single image, resulting in suboptimal performance when transferring knowledge from a LiDAR-based teacher model to a camera-based student model. To facilitate effective distillation, we introduce Monocular Teaching Assistant Knowledge Distillation (MonoTAKD), which proposes a camera-based teaching assistant (TA) model to transfer robust 3D visual knowledge to the student model, leveraging the smaller feature representation gap. Additionally, we define 3D spatial cues as residual features that capture the differences between the teacher and the TA models. We then leverage these cues to improve the student modelâ€™s 3D perception capabilities. Experimental results show that our MonoTAKD achieves state-of-the-art performance on the KITTI3D dataset. Furthermore, we evaluate the performance on nuScenes and KITTI raw datasets to demonstrate the generalization of our model to multi-view 3D and unsupervised data settings. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/hoiliu-0801/MonoTAKD">https://github.com/hoiliu-0801/MonoTAKD</a>. </p>
<blockquote>
<p>å•ç›®3Dç›®æ ‡æ£€æµ‹ï¼ˆMono3Dï¼‰å› å•ç›®ç›¸æœºä¼ æ„Ÿå™¨çš„æˆæœ¬æ•ˆç›Šå’Œä¸°å¯Œçš„è§†è§‰ä¸Šä¸‹æ–‡è€Œåœ¨è‡ªåŠ¨é©¾é©¶åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œæ·±åº¦æ­§ä¹‰æ€§æ„æˆäº†ä¸€å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒéœ€è¦ä»å•å¼ å›¾åƒä¸­æå–ç²¾ç¡®çš„3Dåœºæ™¯å‡ ä½•ç»“æ„ï¼Œå¯¼è‡´ä»æ¿€å…‰é›·è¾¾åŸºç¡€æ•™å¸ˆæ¨¡å‹å‘ç›¸æœºåŸºç¡€å­¦ç”Ÿæ¨¡å‹è½¬ç§»çŸ¥è¯†æ—¶æ€§èƒ½ä¸ä½³ã€‚ä¸ºäº†ä¿ƒè¿›æœ‰æ•ˆçš„è’¸é¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†å•ç›®æ•™å­¦åŠ©ç†çŸ¥è¯†è’¸é¦ï¼ˆMonoTAKDï¼‰ï¼Œå…¶ä¸­æå‡ºäº†ä¸€ä¸ªåŸºäºç›¸æœºçš„æ•™å­¦åŠ©ç†ï¼ˆTAï¼‰æ¨¡å‹ï¼Œä»¥ç¼©å°ç‰¹å¾è¡¨ç¤ºå·®è·çš„æ–¹å¼å‘å­¦ç”Ÿæ¨¡å‹è½¬ç§»ç¨³å¥çš„3Dè§†è§‰çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†3Dç©ºé—´çº¿ç´¢å®šä¹‰ä¸ºæ®‹å·®ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾æ•æ‰äº†æ•™å¸ˆæ¨¡å‹å’ŒåŠ©æ•™æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨è¿™äº›çº¿ç´¢æ¥æé«˜å­¦ç”Ÿæ¨¡å‹çš„3Dæ„ŸçŸ¥èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MonoTAKDåœ¨KITTI3Dæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨nuSceneså’ŒKITTIåŸå§‹æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ€§èƒ½ï¼Œä»¥è¯æ˜æˆ‘ä»¬çš„æ¨¡å‹åœ¨å¤šè§†å›¾3Då’Œæ— ç›‘ç£æ•°æ®è®¾ç½®ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/hoiliu-0">https://github.com/hoiliu-0</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.04910v3">PDF</a> Accepted by CVPR 2025. Our code is available at   <a target="_blank" rel="noopener" href="https://github.com/hoiliu-0801/MonoTAKD">https://github.com/hoiliu-0801/MonoTAKD</a></p>
<p><strong>Summary</strong>ï¼š</p>
<p>å•ç›®ä¸‰ç»´ç›®æ ‡æ£€æµ‹ï¼ˆMono3Dï¼‰åœ¨è‡ªåŠ¨é©¾é©¶åº”ç”¨ä¸­å…·æœ‰æˆæœ¬æ•ˆç›Šå’Œä¸°å¯Œçš„è§†è§‰ä¸Šä¸‹æ–‡ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œæ·±åº¦æ­§ä¹‰æ˜¯ä¸€å¤§æŒ‘æˆ˜ï¼Œéœ€è¦ä»å•å¼ å›¾åƒä¸­æå–ç²¾ç¡®çš„ä¸‰ç»´åœºæ™¯å‡ ä½•ä¿¡æ¯ã€‚ä¸ºäº†ä¿ƒè¿›æœ‰æ•ˆçš„çŸ¥è¯†è’¸é¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºå•ç›®ç›¸æœºçš„åŠ©æ•™çŸ¥è¯†è’¸é¦ï¼ˆMonoTAKDï¼‰ï¼Œé€šè¿‡åˆ©ç”¨è¾ƒå°çš„ç‰¹å¾è¡¨ç¤ºå·®è·ï¼Œæå‡ºä¸€ä¸ªåŸºäºç›¸æœºçš„åŠ©æ•™æ¨¡å‹æ¥å‘å­¦ç”Ÿæ¨¡å‹ä¼ é€’ç¨³å¥çš„ä¸‰ç»´è§†è§‰çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å®šä¹‰äº†ä¸‰ç»´ç©ºé—´çº¿ç´¢ä½œä¸ºæ®‹å·®ç‰¹å¾ï¼Œæ•æ‰æ•™å¸ˆæ¨¡å‹å’ŒåŠ©æ•™æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶åˆ©ç”¨è¿™äº›çº¿ç´¢æ¥æé«˜å­¦ç”Ÿæ¨¡å‹çš„ä¸‰ç»´æ„ŸçŸ¥èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MonoTAKDåœ¨KITTI3Dæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬åœ¨nuSceneså’ŒKITTIåŸå§‹æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤šè§†è§’ä¸‰ç»´å’Œæ— ç›‘ç£æ•°æ®è®¾ç½®ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Mono3Dåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œä¸»è¦å¾—ç›Šäºå•ç›®ç›¸æœºçš„æˆæœ¬æ•ˆç›Šå’Œä¸°å¯Œçš„è§†è§‰ä¸Šä¸‹æ–‡ã€‚</li>
<li>æ·±åº¦æ­§ä¹‰æ˜¯Mono3Dé¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ï¼Œéœ€è¦ä»å•å¼ å›¾åƒä¸­æå–ç²¾ç¡®çš„ä¸‰ç»´åœºæ™¯å‡ ä½•ä¿¡æ¯ã€‚</li>
<li>å¼•å…¥MonoTAKDæ–¹æ³•ï¼Œé€šè¿‡åŠ©æ•™æ¨¡å‹æœ‰æ•ˆä¼ é€’ä¸‰ç»´è§†è§‰çŸ¥è¯†ï¼Œç¼©å°äº†ç‰¹å¾è¡¨ç¤ºå·®è·ã€‚</li>
<li>å®šä¹‰ä¸‰ç»´ç©ºé—´çº¿ç´¢ä½œä¸ºæ®‹å·®ç‰¹å¾ï¼Œä»¥æ•æ‰æ•™å¸ˆæ¨¡å‹å’ŒåŠ©æ•™æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ã€‚</li>
<li>åˆ©ç”¨ä¸‰ç»´ç©ºé—´çº¿ç´¢æé«˜å­¦ç”Ÿæ¨¡å‹çš„ä¸‰ç»´æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>MonoTAKDåœ¨KITTI3Dæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.04910">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bf807a121ffc7c3074f42c0cd6f028c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-188157f678d63cc846c68285642e253c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3be2319ec9f876d4f1de241199f65290.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c227bc87e92da2453a4e7813ff88c749.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Referring-Camouflaged-Object-Detection"><a href="#Referring-Camouflaged-Object-Detection" class="headerlink" title="Referring Camouflaged Object Detection"></a>Referring Camouflaged Object Detection</h2><p><strong>Authors:Xuying Zhang, Bowen Yin, Zheng Lin, Qibin Hou, Deng-Ping Fan, Ming-Ming Cheng</strong></p>
<p>We consider the problem of referring camouflaged object detection (Ref-COD), a new task that aims to segment specified camouflaged objects based on a small set of referring images with salient target objects. We first assemble a large-scale dataset, called R2C7K, which consists of 7K images covering 64 object categories in real-world scenarios. Then, we develop a simple but strong dual-branch framework, dubbed R2CNet, with a reference branch embedding the common representations of target objects from referring images and a segmentation branch identifying and segmenting camouflaged objects under the guidance of the common representations. In particular, we design a Referring Mask Generation module to generate pixel-level prior mask and a Referring Feature Enrichment module to enhance the capability of identifying specified camouflaged objects. Extensive experiments show the superiority of our Ref-COD methods over their COD counterparts in segmenting specified camouflaged objects and identifying the main body of target objects. Our code and dataset are publicly available at <a target="_blank" rel="noopener" href="https://github.com/zhangxuying1004/RefCOD">https://github.com/zhangxuying1004/RefCOD</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†ä¼ªè£…ç›®æ ‡æ£€æµ‹ï¼ˆRef-CODï¼‰é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°ä»»åŠ¡ï¼Œæ—¨åœ¨åŸºäºåŒ…å«æ˜¾è‘—ç›®æ ‡å¯¹è±¡çš„ä¸€ç»„å°‘é‡å‚è€ƒå›¾åƒæ¥åˆ†å‰²æŒ‡å®šçš„ä¼ªè£…å¯¹è±¡ã€‚æˆ‘ä»¬é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†R2C7Kï¼ŒåŒ…å«7Kå¼ å›¾åƒï¼Œè¦†ç›–ç°å®åœºæ™¯ä¸­çš„64ä¸ªå¯¹è±¡ç±»åˆ«ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„åŒåˆ†æ”¯æ¡†æ¶R2CNetï¼Œå…¶ä¸­å‚è€ƒåˆ†æ”¯åµŒå…¥æ¥è‡ªå‚è€ƒå›¾åƒçš„ç›® æ ‡å¯¹è±¡çš„é€šç”¨è¡¨ç¤ºï¼Œè€Œåˆ†å‰²åˆ†æ”¯åˆ™åœ¨é€šç”¨è¡¨ç¤ºçš„æŒ‡å¯¼ä¸‹è¯†åˆ«å’Œåˆ†å‰²ä¼ªè£…å¯¹è±¡ã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå‚è€ƒæ©æ¨¡ç”Ÿæˆæ¨¡å—æ¥ç”Ÿæˆåƒç´ çº§å…ˆéªŒæ©æ¨¡å’Œä¸€ä¸ªå‚è€ƒç‰¹å¾å¢å¼ºæ¨¡å—æ¥æé«˜è¯†åˆ«æŒ‡å®šä¼ªè£…å¯¹è±¡çš„èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„Ref-CODæ–¹æ³•åœ¨åˆ†å‰²æŒ‡å®šä¼ªè£…å¯¹è±¡å’Œè¯†åˆ«ç›®æ ‡å¯¹è±¡ä¸»ä½“æ–¹é¢ä¼˜äºå…¶CODå¯¹åº”æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zhangxuying1004/RefCOD%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/zhangxuying1004/RefCODå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.07532v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é’ˆå¯¹æŒ‡ä»£ä¼ªè£…ç›®æ ‡æ£€æµ‹ï¼ˆRef-CODï¼‰è¿™ä¸€æ–°ä»»åŠ¡ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†R2C7Kï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„åŒåˆ†æ”¯æ¡†æ¶R2CNetã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªå‚è€ƒåˆ†æ”¯å’Œä¸€ä¸ªåˆ†å‰²åˆ†æ”¯ï¼Œå‰è€…ä»å‚ç…§å›¾åƒä¸­æå–ç›®æ ‡å¯¹è±¡çš„é€šç”¨è¡¨ç¤ºï¼Œåè€…åœ¨é€šç”¨è¡¨ç¤ºçš„å¼•å¯¼ä¸‹è¯†åˆ«å’Œåˆ†å‰²ä¼ªè£…å¯¹è±¡ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜è®¾è®¡äº†æŒ‡ä»£æ©è†œç”Ÿæˆæ¨¡å—å’ŒæŒ‡ä»£ç‰¹å¾å¢å¼ºæ¨¡å—ï¼Œä»¥æé«˜è¯†åˆ«æŒ‡å®šä¼ªè£…ç›®æ ‡çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒRef-CODæ–¹æ³•åœ¨åˆ†å‰²æŒ‡å®šä¼ªè£…ç›®æ ‡å’Œè¯†åˆ«ç›®æ ‡ä¸»ä½“æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„CODæ–¹æ³•ã€‚æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å›¢é˜Ÿæå‡ºäº†æŒ‡ä»£ä¼ªè£…ç›®æ ‡æ£€æµ‹ï¼ˆRef-CODï¼‰çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨åŸºäºä¸€ç»„å‚ç…§å›¾åƒå¯¹æŒ‡å®šçš„ä¼ªè£…ç›®æ ‡è¿›è¡Œåˆ†å‰²ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†R2C7Kï¼ŒåŒ…å«7000å¼ å›¾åƒå’Œ64ä¸ªå¯¹è±¡ç±»åˆ«ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŒåˆ†æ”¯æ¡†æ¶R2CNetï¼ŒåŒ…å«å‚è€ƒåˆ†æ”¯å’Œåˆ†å‰²åˆ†æ”¯ã€‚</li>
<li>è®¾è®¡äº†æŒ‡ä»£æ©è†œç”Ÿæˆæ¨¡å—ï¼Œç”¨äºç”Ÿæˆåƒç´ çº§å…ˆéªŒæ©è†œã€‚</li>
<li>å¼€å‘äº†æŒ‡ä»£ç‰¹å¾å¢å¼ºæ¨¡å—ï¼Œæé«˜äº†è¯†åˆ«æŒ‡å®šä¼ªè£…ç›®æ ‡çš„èƒ½åŠ›ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒRef-CODæ–¹æ³•åœ¨åˆ†å‰²æŒ‡å®šä¼ªè£…å¯¹è±¡å’Œè¯†åˆ«ç›®æ ‡ä¸»ä½“æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„CODæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2306.07532">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8eae6aef8d827f56b1ddc302f94c6e17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-def3f14b089262d67db634240c05e393.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bed26d52cd9469274b70d1bdce86dc1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0691dc5ba267ac1c97fa6a1b781163f0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4de85de2dd6016959a5a8e80386fa464.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-28/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-28/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-28/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-68a7121e23409fdf65737a97e08e3212.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-28  Cross-Modal Prototype Allocation Unsupervised Slide Representation   Learning via Patch-Text Contrast in Computational Pathology
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-28/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cb171a6d94a0b73bcb41f5d4c8eb8c32.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-28  Vision as LoRA
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19758k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
