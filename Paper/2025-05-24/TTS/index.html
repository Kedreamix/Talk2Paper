<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS 方向最新论文已更新，请持续关注 Update in 2025-05-24  Audio Jailbreak An Open Comprehensive Benchmark for Jailbreaking Large   Audio-Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-3862ab512a1a7d47697956085cfdeaf5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-31
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    36 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-24-更新"><a href="#2025-05-24-更新" class="headerlink" title="2025-05-24 更新"></a>2025-05-24 更新</h1><h2 id="Audio-Jailbreak-An-Open-Comprehensive-Benchmark-for-Jailbreaking-Large-Audio-Language-Models"><a href="#Audio-Jailbreak-An-Open-Comprehensive-Benchmark-for-Jailbreaking-Large-Audio-Language-Models" class="headerlink" title="Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large   Audio-Language Models"></a>Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large   Audio-Language Models</h2><p><strong>Authors:Zirui Song, Qian Jiang, Mingxuan Cui, Mingzhe Li, Lang Gao, Zeyu Zhang, Zixiang Xu, Yanbo Wang, Chenxi Wang, Guangxian Ouyang, Zhenhao Chen, Xiuying Chen</strong></p>
<p>The rise of Large Audio Language Models (LAMs) brings both potential and risks, as their audio outputs may contain harmful or unethical content. However, current research lacks a systematic, quantitative evaluation of LAM safety especially against jailbreak attacks, which are challenging due to the temporal and semantic nature of speech. To bridge this gap, we introduce AJailBench, the first benchmark specifically designed to evaluate jailbreak vulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of 1,495 adversarial audio prompts spanning 10 policy-violating categories, converted from textual jailbreak attacks using realistic text to speech synthesis. Using this dataset, we evaluate several state-of-the-art LAMs and reveal that none exhibit consistent robustness across attacks. To further strengthen jailbreak testing and simulate more realistic attack conditions, we propose a method to generate dynamic adversarial variants. Our Audio Perturbation Toolkit (APT) applies targeted distortions across time, frequency, and amplitude domains. To preserve the original jailbreak intent, we enforce a semantic consistency constraint and employ Bayesian optimization to efficiently search for perturbations that are both subtle and highly effective. This results in AJailBench-APT, an extended dataset of optimized adversarial audio samples. Our findings demonstrate that even small, semantically preserved perturbations can significantly reduce the safety performance of leading LAMs, underscoring the need for more robust and semantically aware defense mechanisms. </p>
<blockquote>
<p>大规模音频语言模型（LAMs）的兴起带来了潜力和风险，因为它们的音频输出可能包含有害或不道德的内容。然而，当前的研究缺乏系统、定量地评估LAM安全性的方法，特别是对于越狱攻击（jailbreak attacks）的评估，这种评估颇具挑战性，原因在于语音的时效性和语义性。为了填补这一空白，我们推出了AJailBench，这是专门用于评估LAMs中越狱漏洞的第一个基准测试。</p>
</blockquote>
<p>我们首先构建AJailBench-Base数据集，包含1495个跨10类违规政策的对抗性音频提示，这些提示是通过现实文本到语音合成技术，从文本越狱攻击转换而来的。使用该数据集，我们评估了几种最新前沿的LAMs，发现它们在各种攻击中均没有表现出一致的稳健性。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15406v1">PDF</a> We release AJailBench, including both static and optimized   adversarial data, to facilitate future research:   <a target="_blank" rel="noopener" href="https://github.com/mbzuai-nlp/AudioJailbreak">https://github.com/mbzuai-nlp/AudioJailbreak</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了大型音频语言模型（LAMs）的兴起带来的潜在风险和机遇。针对LAMs的安全性问题，尤其是针对语音的临时和语义特性的越狱攻击，提出了一种新的评估方法。文章建立了AJailBench基准测试，用于评估LAMs的越狱漏洞，并引入了AJailBench-Base数据集和Audio Perturbation Toolkit（APT）来生成动态对抗样本。研究结果表明，即使是微小且语义上保持一致的扰动，也能显著降低领先LAMs的安全性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型音频语言模型（LAMs）的音频输出可能包含有害或不道德的内容，存在潜在风险。</li>
<li>目前针对LAMs的安全评估缺乏系统、定量的评价，尤其是针对越狱攻击。</li>
<li>建立了AJailBench基准测试来评估LAMs的越狱漏洞。</li>
<li>AJailBench-Base数据集由1495个对抗性音频提示组成，这些提示是从文本越狱攻击转换而来，用于评估LAMs。</li>
<li>现有的先进LAMs在攻击方面缺乏一致的稳健性。</li>
<li>Audio Perturbation Toolkit（APT）用于生成动态对抗样本，通过时间、频率和振幅域的目标失真进行模拟更现实的攻击条件。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15406">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9aea5148eb16a514cb929d60f9f9e8e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c424fbc78398328403f5617a873222be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61fe979964da9bf901b177dc8a991e94.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1a4bb0c1c8c0e1dd66c2e0318130405b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Prosody-Adaptable-Audio-Codecs-for-Zero-Shot-Voice-Conversion-via-In-Context-Learning"><a href="#Prosody-Adaptable-Audio-Codecs-for-Zero-Shot-Voice-Conversion-via-In-Context-Learning" class="headerlink" title="Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via   In-Context Learning"></a>Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via   In-Context Learning</h2><p><strong>Authors:Junchuan Zhao, Xintong Wang, Ye Wang</strong></p>
<p>Recent advances in discrete audio codecs have significantly improved speech representation modeling, while codec language models have enabled in-context learning for zero-shot speech synthesis. Inspired by this, we propose a voice conversion (VC) model within the VALLE-X framework, leveraging its strong in-context learning capabilities for speaker adaptation. To enhance prosody control, we introduce a prosody-aware audio codec encoder (PACE) module, which isolates and refines prosody from other sources, improving expressiveness and control. By integrating PACE into our VC model, we achieve greater flexibility in prosody manipulation while preserving speaker timbre. Experimental evaluation results demonstrate that our approach outperforms baseline VC systems in prosody preservation, timbre consistency, and overall naturalness, surpassing baseline VC systems. </p>
<blockquote>
<p>近期离散音频编码器的进展极大地改进了语音表示建模，而编码器语言模型已经实现了零样本语音合成的上下文学习。受其启发，我们在VALLE-X框架内提出了一个语音转换（VC）模型，利用其强大的上下文学习能力进行说话人适配。为了增强韵律控制，我们引入了一个韵律感知音频编码器（PACE）模块，该模块可以隔离并优化韵律的来源，提高表达力和控制力。通过将PACE集成到我们的VC模型中，我们在韵律操纵方面实现了更大的灵活性，同时保留了说话人的音色。实验评估结果表明，我们的方法在韵律保持、音色一致性和整体自然度方面超越了基线VC系统。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15402v1">PDF</a> 5 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>近期离散音频编码器的进展极大地改进了语音表示建模，而编码器语言模型则为零样本语音合成提供了上下文学习环境。受此启发，我们在VALLE-X框架内提出了语音转换（VC）模型，利用其强大的上下文学习能力进行语音者适应。为提升语调控制，我们引入了语调感知音频编码器（PACE）模块，该模块能隔离并优化语调来源，提升表达的生动性和控制力。将PACE整合至VC模型中，我们在语调操控上获得更大的灵活性，同时保留说话者的音色。实验评估结果显示，我们的方法在语调保留、音色一致性和整体自然度上超越了基线VC系统。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>离散音频编码器的最新进展显著改进了语音表示建模。</li>
<li>编码器语言模型支持零样本语音合成的上下文学习。</li>
<li>提出了在VALLE-X框架内的语音转换（VC）模型，利用上下文学习能力进行语音者适应。</li>
<li>引入PACE模块以强化语调控制，并隔离和优化语调来源。</li>
<li>PACE与VC模型的结合实现了灵活的语调操控，同时保留音色。</li>
<li>实验结果证明，该方法在语调保留、音色一致性和自然度上超越了基线VC系统。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15402">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ba1cba21ed3de6bc44389948aa5b00e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1e4201e7de303229190d1eea635ba23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3646ee87f32d11323a55446a1552483.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-32184b8a627ad4363f6d6f2252a3a6df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1880b7f97a55df6b9a2c14ad26fa717f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f38d0b65c8dfaeb9c81bb1e530eac4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c2b129d197257c131aeb99eebbd2fd2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Saten-Sparse-Augmented-Tensor-Networks-for-Post-Training-Compression-of-Large-Language-Models"><a href="#Saten-Sparse-Augmented-Tensor-Networks-for-Post-Training-Compression-of-Large-Language-Models" class="headerlink" title="Saten: Sparse Augmented Tensor Networks for Post-Training Compression of   Large Language Models"></a>Saten: Sparse Augmented Tensor Networks for Post-Training Compression of   Large Language Models</h2><p><strong>Authors:Ryan Solgi, Kai Zhen, Rupak Vignesh Swaminathan, Nathan Susanj, Athanasios Mouchtaris, Siegfried Kunzmann, Zheng Zhang</strong></p>
<p>The efficient implementation of large language models (LLMs) is crucial for deployment on resource-constrained devices. Low-rank tensor compression techniques, such as tensor-train (TT) networks, have been widely studied for over-parameterized neural networks. However, their applications to compress pre-trained large language models (LLMs) for downstream tasks (post-training) remains challenging due to the high-rank nature of pre-trained LLMs and the lack of access to pretraining data. In this study, we investigate low-rank tensorized LLMs during fine-tuning and propose sparse augmented tensor networks (Saten) to enhance their performance. The proposed Saten framework enables full model compression. Experimental results demonstrate that Saten enhances both accuracy and compression efficiency in tensorized language models, achieving state-of-the-art performance. </p>
<blockquote>
<p>大型语言模型（LLM）的有效实现对于在资源受限设备上的部署至关重要。张量分解技术，如张量列车（TT）网络，已被广泛应用于过参数化的神经网络。然而，由于其高维特性和无法访问预训练数据，将预训练的大型语言模型（LLM）应用于下游任务（后训练）时，使用这些技术进行压缩仍然具有挑战性。在这项研究中，我们调查了在微调期间使用低阶张量的大型语言模型，并提出了稀疏增强张量网络（Saten）以提高其性能。所提出的Saten框架能够实现全模型压缩。实验结果表明，Saten在提高了张量化语言模型的准确性和压缩效率的同时，实现了最先进的性能表现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14871v1">PDF</a> </p>
<p><strong>总结</strong></p>
<p>对于资源受限设备来说，大型语言模型（LLMs）的有效实施至关重要。张量训练网络等低秩张量压缩技术已广泛应用于过参数化的神经网络。然而，由于其高秩特性和无法访问预训练数据，这些技术应用于压缩预训练的大型语言模型（LLMs）以适应下游任务仍面临挑战。本研究在微调过程中调查了低秩张量化LLMs，并提出稀疏增强张量网络（Saten）以提高其性能。所提出的Saten框架能够实现全模型压缩。实验结果表明，Saten在提高了张量化语言模型的准确性和压缩效率的同时，达到了业界最佳性能。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>大型语言模型（LLMs）在资源受限设备上的有效实施非常重要。</li>
<li>低秩张量压缩技术如张量训练网络已广泛应用于过参数化神经网络。</li>
<li>将这些技术应用于预训练的大型语言模型（LLMs）以适应下游任务面临挑战，主要由于高秩特性和无法访问预训练数据。</li>
<li>研究人员在微调过程中调查了低秩张量化LLMs。</li>
<li>提出了一种新的框架——稀疏增强张量网络（Saten），旨在提高语言模型的性能。</li>
<li>Saten框架能够实现全模型压缩。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14871">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-a386f70702e171c6aed1ad4e6637ec25.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3862ab512a1a7d47697956085cfdeaf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb2a2608d3a7a2af45c020fd6fa58f08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21a7647f0d184f7d97bd83d6f4d9e98c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e29e934e9664c13549f8e399a5588ad.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AudioJailbreak-Jailbreak-Attacks-against-End-to-End-Large-Audio-Language-Models"><a href="#AudioJailbreak-Jailbreak-Attacks-against-End-to-End-Large-Audio-Language-Models" class="headerlink" title="AudioJailbreak: Jailbreak Attacks against End-to-End Large   Audio-Language Models"></a>AudioJailbreak: Jailbreak Attacks against End-to-End Large   Audio-Language Models</h2><p><strong>Authors:Guangke Chen, Fu Song, Zhe Zhao, Xiaojun Jia, Yang Liu, Yanchen Qiao, Weizhe Zhang</strong></p>
<p>Jailbreak attacks to Large audio-language models (LALMs) are studied recently, but they achieve suboptimal effectiveness, applicability, and practicability, particularly, assuming that the adversary can fully manipulate user prompts. In this work, we first conduct an extensive experiment showing that advanced text jailbreak attacks cannot be easily ported to end-to-end LALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a novel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio does not need to align with user prompts in the time axis by crafting suffixal jailbreak audios; (2) universality: a single jailbreak perturbation is effective for different prompts by incorporating multiple prompts into perturbation generation; (3) stealthiness: the malicious intent of jailbreak audios will not raise the awareness of victims by proposing various intent concealment strategies; and (4) over-the-air robustness: the jailbreak audios remain effective when being played over the air by incorporating the reverberation distortion effect with room impulse response into the generation of the perturbations. In contrast, all prior audio jailbreak attacks cannot offer asynchrony, universality, stealthiness, or over-the-air robustness. Moreover, AudioJailbreak is also applicable to the adversary who cannot fully manipulate user prompts, thus has a much broader attack scenario. Extensive experiments with thus far the most LALMs demonstrate the high effectiveness of AudioJailbreak. We highlight that our work peeks into the security implications of audio jailbreak attacks against LALMs, and realistically fosters improving their security robustness. The implementation and audio samples are available at our website <a target="_blank" rel="noopener" href="https://audiojailbreak.github.io/AudioJailbreak">https://audiojailbreak.github.io/AudioJailbreak</a>. </p>
<blockquote>
<p>近年来，针对大型音频语言模型（LALM）的越狱攻击已受到研究，但其在效能、适用性和实用性方面尚未达到最佳，尤其是假设攻击者可以完全操控用户提示的情况下。在这项工作中，我们首先进行了大量实验，表明先进的文本越狱攻击无法轻易通过文本到语音（TTS）技术转移到端到端的LALM上。然后，我们提出了AudioJailbreak，这是一种新型音频越狱攻击，具有以下特点：</p>
</blockquote>
<ol>
<li>异步性：越狱音频无需通过制作后缀越狱音频与用户提示在时间轴上进行对齐；</li>
<li>通用性：通过合并多个提示来生成扰动，单个越狱扰动对不同的提示都有效；</li>
<li>隐蔽性：通过提出各种意图隐藏策略，越狱音频的恶意意图不会让受害者提高警惕；</li>
<li>空中传播的稳健性：通过将混响失真效应与房间冲击响应结合到扰动生成中，越狱音频在在空中播放时仍能保持有效。</li>
</ol>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14103v2">PDF</a> </p>
<p><strong>Summary</strong><br>     针对大型音频语言模型（LALM）的越狱攻击研究存在局限性，近期提出的文本越狱攻击无法轻易应用于端到端的LALM模型。本研究提出一种新型音频越狱攻击方法——AudioJailbreak，具有异步性、普遍性、隐蔽性及空中传播稳健性等特点，对现有攻击场景有更广泛的适用性。实验证明，AudioJailbreak对目前大多数LALM模型具有高效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有针对LALM的越狱攻击存在效果、适用性和实用性方面的不足。</li>
<li>文本越狱攻击无法轻易应用于端到端的LALM模型。</li>
<li>AudioJailbreak是一种新型音频越狱攻击，具有异步性、普遍性、隐蔽性和空中传播稳健性。</li>
<li>AudioJailbreak对目前大多数LALM模型具有高效性。</li>
<li>AudioJailbreak适用于无法完全操纵用户提示的对手，具有更广泛的攻击场景。</li>
<li>AudioJailbreak通过融入混响失真效应与房间脉冲响应来提升空中传播稳健性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14103">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fde7517063fbf998e01e91025551f181.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88755946603f8cbe258b2fe3cb0bb019.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe8d54d42c0ffd4affae82ca1a116e94.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Improving-Noise-Robustness-of-LLM-based-Zero-shot-TTS-via-Discrete-Acoustic-Token-Denoising"><a href="#Improving-Noise-Robustness-of-LLM-based-Zero-shot-TTS-via-Discrete-Acoustic-Token-Denoising" class="headerlink" title="Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete   Acoustic Token Denoising"></a>Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete   Acoustic Token Denoising</h2><p><strong>Authors:Ye-Xin Lu, Hui-Peng Du, Fei Liu, Yang Ai, Zhen-Hua Ling</strong></p>
<p>Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend to preserve the acoustic environment of the audio prompt, leading to degradation in synthesized speech quality when the audio prompt contains noise. In this paper, we propose a novel neural codec-based speech denoiser and integrate it with the advanced LLM-based TTS model, LauraTTS, to achieve noise-robust zero-shot TTS. The proposed codec denoiser consists of an audio codec, a token denoiser, and an embedding refiner. The token denoiser predicts the first two groups of clean acoustic tokens from the noisy ones, which can serve as the acoustic prompt for LauraTTS to synthesize high-quality personalized speech or be converted to clean speech waveforms through the embedding refiner and codec decoder. Experimental results show that our proposed codec denoiser outperforms state-of-the-art speech enhancement (SE) methods, and the proposed noise-robust LauraTTS surpasses the approach using additional SE models. </p>
<blockquote>
<p>基于大型语言模型（LLM）的零样本文本到语音（TTS）方法往往会保留音频提示的声学环境，但当音频提示包含噪声时，会导致合成语音质量下降。在本文中，我们提出了一种新型的基于神经网络编解码器的语音去噪器，并将其与先进的基于LLM的TTS模型LauraTTS相结合，实现了噪声鲁棒的零样本TTS。所提出的编解码器去噪器由音频编解码器、令牌去噪器和嵌入精炼器组成。令牌去噪器从噪声令牌中预测前两个组的干净声学令牌，这可以作为LauraTTS合成高质量个性化语音的声学提示，或者通过嵌入精炼器和编解码器解码器转换为干净的语音波形。实验结果表明，我们提出的编解码器去噪器优于现有的语音增强（SE）方法，并且所提出的噪声鲁棒LauraTTS超越了使用附加SE模型的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13830v2">PDF</a> Accepted by Interspeech 2025</p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型（LLM）的零样本文本到语音（TTS）方法会保留音频提示的声学环境，当音频提示包含噪声时，会导致合成语音质量下降。本文提出了一种新颖的基于神经网络编解码器的语音去噪器，并将其与先进的LLM-based TTS模型LauraTTS相结合，实现了噪声鲁棒的零样本TTS。编解码器去噪器由音频编解码器、令牌去噪器和嵌入精炼器组成。令牌去噪器从嘈杂的令牌预测前两组干净的声学令牌，可以作为LauraTTS合成高质量个性化语音的声学提示，或通过嵌入精炼器和编解码器解码器转换为干净的语音波形。实验结果表明，本文提出的编解码器去噪器优于现有的语音增强（SE）方法，而提出的噪声鲁棒性LauraTTS则超越了使用附加SE模型的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based zero-shot TTS方法在保留音频提示的声学环境方面表现良好，但在含有噪声的音频提示下会导致语音质量下降。</li>
<li>论文提出了一种新颖的神经网络编解码器语音去噪器，用于处理音频中的噪声问题。</li>
<li>编解码器去噪器包括音频编解码器、令牌去噪器和嵌入精炼器三个关键组件。</li>
<li>令牌去噪器能够从含噪声的令牌中预测出干净的声学令牌，为LauraTTS提供高质量的声学提示。</li>
<li>整合编解码器去噪器和LauraTTS模型可实现噪声鲁棒的零样本TTS。</li>
<li>实验结果显示，论文提出的编解码器去噪器在性能上超越了现有的语音增强方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13830">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4aa79b6eb807d311ebdea7380b9395ad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ba58973ea83532ce32150a761118e124.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-582a9fe21eabd309d2c2f7fd1e78776e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-02c233800f084b2074fac3697b931790.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TTRL-Test-Time-Reinforcement-Learning"><a href="#TTRL-Test-Time-Reinforcement-Learning" class="headerlink" title="TTRL: Test-Time Reinforcement Learning"></a>TTRL: Test-Time Reinforcement Learning</h2><p><strong>Authors:Yuxin Zuo, Kaiyan Zhang, Li Sheng, Shang Qu, Ganqu Cui, Xuekai Zhu, Haozhan Li, Yuchen Zhang, Xinwei Long, Ermo Hua, Biqing Qi, Youbang Sun, Zhiyuan Ma, Lifan Yuan, Ning Ding, Bowen Zhou</strong></p>
<p>This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 211% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the maj@n metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model maj@n, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks and highlight TTRL’s potential for broader tasks and domains. GitHub: <a target="_blank" rel="noopener" href="https://github.com/PRIME-RL/TTRL">https://github.com/PRIME-RL/TTRL</a> </p>
<blockquote>
<p>本文探讨了在大语言模型（LLM）的推理任务中，在无明确标签数据上应用强化学习（RL）的情况。该问题的核心挑战在于在推理过程中进行奖励估计，同时无法获得真实信息的支持。尽管这个设置似乎很模糊，但我们发现测试时间缩放（TTS）中的常见做法，如多数投票，会产生令人惊讶的有效奖励，适用于驱动RL训练。在这项工作中，我们引入了测试时间强化学习（TTRL），这是一种使用无标签数据上的RL训练LLM的新方法。TTRL利用预训练模型中的先验知识，实现了LLM的自我进化。我们的实验表明，TTRL在各种任务和模型上的性能持续提高。值得注意的是，在AIME 2024上，TTRL将Qwen-2.5-Math-7B的pass@1性能提高了大约211%，而且仅使用无标签的测试数据。此外，尽管TTRL只受到maj@n指标的监督，但其性能已经超越了初始模型的maj@n上限，并接近直接在带有真实标签的测试数据上训练的模型性能。我们的实验结果表明TTRL在多种任务中的普遍有效性，并突出了其在更广泛的任务和领域中的潜力。GitHub地址：<a target="_blank" rel="noopener" href="https://github.com/PRIME-RL/TTRL">https://github.com/PRIME-RL/TTRL</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16084v2">PDF</a> </p>
<p><strong>Summary</strong><br>本文探索了无需标签数据的大型语言模型（LLM）在推理任务中的强化学习（RL）应用。主要挑战在于在推理过程中进行奖励估算，同时无法获取真实信息。尽管这种情况看似难以解决，但测试时间缩放（TTS）的常见实践，如多数投票，产生了令人惊讶的有效奖励，适用于驱动RL训练。本文提出了Test-Time Reinforcement Learning（TTRL）这一新方法，用于在无需标签的数据上训练LLM。TTRL通过利用预训练模型中的先验知识，实现了LLM的自我进化。实验表明，TTRL在各种任务和模型上的性能持续提升。特别是，在AIME 2024比赛中，TTRL使Qwen-2.5-Math-7B的pass@1性能提高了约211%，且仅使用无标签的测试数据。尽管TTRL仅受maj@n指标的监督，但其性能始终超过初始模型的maj@n上限，并接近直接在带有真实标签的测试数据上训练的模型性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究采用强化学习（RL）对大型语言模型（LLM）进行训练，且无需数据标签。</li>
<li>面临的核心挑战在于在缺乏真实信息的情况下进行奖励估算。</li>
<li>测试时间缩放（TTS）的常见实践如多数投票在RL训练中表现有效。</li>
<li>引入Test-Time Reinforcement Learning（TTRL）方法，利用预训练模型中的先验知识实现LLM的自我进化。</li>
<li>TTRL在各种任务上的性能持续提升，且在特定比赛中显著提高模型性能。</li>
<li>TTRL的性能超越初始模型的指标，并接近使用真实标签数据训练的模型性能。</li>
<li>TTRL的潜在应用范围广泛，可应用于更广泛的任务和领域。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16084">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-442a16b924283ccbcc6ffe9c7f5d2182.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a0866297a9a1a714a997857dcaeaca7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-faf500453f74bac763af5e8c2b094e98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68fbde7f77107f409fa781b1f59abc3f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ShiftySpeech-A-Large-Scale-Synthetic-Speech-Dataset-with-Distribution-Shifts"><a href="#ShiftySpeech-A-Large-Scale-Synthetic-Speech-Dataset-with-Distribution-Shifts" class="headerlink" title="ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution   Shifts"></a>ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution   Shifts</h2><p><strong>Authors:Ashi Garg, Zexin Cai, Lin Zhang, Henry Li Xinyuan, Leibny Paola García-Perera, Kevin Duh, Sanjeev Khudanpur, Matthew Wiesner, Nicholas Andrews</strong></p>
<p>The problem of synthetic speech detection has enjoyed considerable attention, with recent methods achieving low error rates across several established benchmarks. However, to what extent can low error rates on academic benchmarks translate to more realistic conditions? In practice, while the training set is fixed at one point in time, test-time conditions may exhibit distribution shifts relative to the training conditions, such as changes in speaker characteristics, emotional expressiveness, language and acoustic conditions, and the emergence of novel synthesis methods. Although some existing datasets target subsets of these distribution shifts, systematic analysis remains difficult due to inconsistencies between source data and synthesis systems across datasets. This difficulty is further exacerbated by the rapid development of new text-to-speech (TTS) and vocoder systems, which continually expand the diversity of synthetic speech. To enable systematic benchmarking of model performance under distribution shifts, we introduce ShiftySpeech, a large-scale benchmark comprising over 3,000 hours of synthetic speech across 7 source domains, 6 TTS systems, 12 vocoders, and 3 languages. ShiftySpeech is specifically designed to evaluate model generalization under controlled distribution shifts while ensuring broad coverage of modern synthetic speech generation techniques. It fills a key gap in current benchmarks by supporting fine-grained, controlled analysis of generalization robustness. All tested distribution shifts significantly degrade detection performance of state-of-the-art detection approaches based on self-supervised features. Overall, our findings suggest that reliance on synthetic speech detection methods in production environments should be carefully evaluated based on anticipated distribution shifts. </p>
<blockquote>
<p>语音合成检测问题已引起广泛关注，最近的方法在多个既定基准测试上的错误率较低。然而，低错误率在学术基准上能在多大程度上转化为更现实的条件？实际上，虽然训练集是固定在一个时间点的，但测试时的条件可能会相对于训练条件出现分布偏移，例如发言人特征、情感表达、语言和声学条件的改变，以及新型合成方法的出现。虽然一些现有数据集针对这些分布偏移的子集，但由于数据集之间源数据和合成系统的不一致性，系统分析仍然困难。这一困难因新型文本到语音（TTS）和振动系统的高速发展而进一步加剧，它们不断扩大了合成语音的多样性。为了能够对模型在分布偏移下的性能进行系统的基准测试，我们引入了ShiftySpeech，这是一个大规模的基准测试，包括超过3000小时的合成语音，涵盖7个源域、6个TTS系统、12个振动器和3种语言。ShiftySpeech专门设计用于评估模型在受控分布偏移下的泛化能力，同时确保广泛覆盖现代合成语音生成技术。它填补了当前基准测试的空白，支持精细的、受控的泛化稳健性分析。所有测试的分布偏移都会显著降级基于自我监督特征的最新检测方法的检测性能。总体而言，我们的研究结果表明，在生产环境中依赖合成语音检测方法应谨慎评估预期的分布偏移。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05674v4">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>这篇论文关注了合成语音检测的问题，尽管在几个既定的基准测试上取得了较低的误差率，但在更现实的条件下，这些低误差率能否得到实际应用仍存在疑问。训练集是固定不变的，但测试时的条件可能与训练条件存在分布偏移，如说话人特征、情感表达、语言和声学条件的改变，以及新合成方法的出现。为了对模型在分布偏移下的性能进行系统性评估，引入了ShiftySpeech基准测试，包含超过3000小时的合成语音数据，涵盖7个源域、6个文本到语音系统、12个vocoder和3种语言。ShiftySpeech专门设计用于评估模型在受控分布偏移下的泛化能力，同时确保覆盖现代合成语音生成技术的广泛范围。它填补了当前基准测试的空白，支持对泛化稳健性的精细控制分析。所有测试的分布偏移都会显著地降低基于自监督特征的最新检测方法的性能。总体而言，我们的研究结果表明，在预期存在分布偏移的生产环境中使用合成语音检测方法应谨慎评估。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>合成语音检测面临从学术基准测试到现实条件的应用转化问题。</li>
<li>训练集固定，但测试条件可能存在与训练条件的分布偏移。</li>
<li>分布偏移包括说话人特征、情感表达、语言和声学条件的改变，以及新合成方法的出现。</li>
<li>现有数据集只针对分布偏移的部分方面，缺乏系统性分析。</li>
<li>介绍了ShiftySpeech基准测试，包含大规模合成语音数据，支持精细控制的泛化分析。</li>
<li>测试分布偏移显著降低了最新检测方法的性能。</li>
<li>在预期存在分布偏移的生产环境中使用合成语音检测方法应谨慎评估。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05674">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-de536c413b6b40a76d35f2a5eefd33ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e9e34e0d166ffd0138fe166b50f0417.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18c3fbbbeafbe7e17d230de015d237bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b8517e4b05ea16925a053da4da9d013.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c7becb3bbe670bed6ec7e323c80835e4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6de38e73018950a33fb698c0a4840a47.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-30846d0b2275b7b64c1b9f00ab81295d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SmoothCache-A-Universal-Inference-Acceleration-Technique-for-Diffusion-Transformers"><a href="#SmoothCache-A-Universal-Inference-Acceleration-Technique-for-Diffusion-Transformers" class="headerlink" title="SmoothCache: A Universal Inference Acceleration Technique for Diffusion   Transformers"></a>SmoothCache: A Universal Inference Acceleration Technique for Diffusion   Transformers</h2><p><strong>Authors:Joseph Liu, Joshua Geddes, Ziyu Guo, Haomiao Jiang, Mahesh Kumar Nandwana</strong></p>
<p>Diffusion Transformers (DiT) have emerged as powerful generative models for various tasks, including image, video, and speech synthesis. However, their inference process remains computationally expensive due to the repeated evaluation of resource-intensive attention and feed-forward modules. To address this, we introduce SmoothCache, a model-agnostic inference acceleration technique for DiT architectures. SmoothCache leverages the observed high similarity between layer outputs across adjacent diffusion timesteps. By analyzing layer-wise representation errors from a small calibration set, SmoothCache adaptively caches and reuses key features during inference. Our experiments demonstrate that SmoothCache achieves 8% to 71% speed up while maintaining or even improving generation quality across diverse modalities. We showcase its effectiveness on DiT-XL for image generation, Open-Sora for text-to-video, and Stable Audio Open for text-to-audio, highlighting its potential to enable real-time applications and broaden the accessibility of powerful DiT models. </p>
<blockquote>
<p>扩散Transformer（DiT）已经成为包括图像、视频和语音合成在内的各种任务的强大生成模型。然而，由于需要重复评估资源密集型的注意力和前馈模块，它们的推理过程计算成本仍然很高。为了解决这一问题，我们引入了SmoothCache，这是一种适用于DiT架构的模型无关推理加速技术。SmoothCache利用相邻扩散时间步长之间层输出的高相似性。通过分析来自小型校准集的逐层表示误差，SmoothCache在推理过程中自适应地缓存和重复使用关键特征。我们的实验表明，SmoothCache在保持或甚至提高生成质量的同时，实现了8%到71%的提速，涉及多种模态。我们在图像生成的DiT-XL、文本到视频的Open-Sora以及文本到音频的Stable Audio Open上展示了其有效性，突出了其实现实时应用和扩大强大DiT模型可及性的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.10510v2">PDF</a> Code can be found at <a target="_blank" rel="noopener" href="https://github.com/Roblox/SmoothCache">https://github.com/Roblox/SmoothCache</a>. Accepted   at CVPR eLVM workshop</p>
<p><strong>摘要</strong></p>
<p>扩散转换器（DiT）已作为图像、视频和语音合成等任务的强大生成模型出现。然而，由于其重复的注意力评估和正向传播模块的计算资源密集性，其推理过程计算成本仍然很高。为解决这一问题，我们推出了SmoothCache，这是一种适用于DiT架构的模型无关推理加速技术。SmoothCache利用相邻扩散时间步长之间层输出之间的高相似性。通过分析来自小校准集的层表示误差，SmoothCache自适应地缓存和重用关键特征来进行推理。实验表明，SmoothCache在保持或甚至提高生成质量的同时，实现了8%至71%的提速。我们在DiT-XL图像生成、Open-Sora文本到视频以及Stable Audio Open文本到音频的应用中展示了其有效性，突显其实现实时应用和扩大强大DiT模型可及性的潜力。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>扩散转换器（DiT）是图像、视频和语音合成等领域的强大生成模型。</li>
<li>推理过程中，由于资源密集型模块的重复评估，DiT的计算成本仍然较高。</li>
<li>SmoothCache是一种适用于DiT架构的模型无关推理加速技术。</li>
<li>SmoothCache利用相邻扩散时间步长间层输出的高相似性。</li>
<li>通过分析来自小校准集的层表示误差，SmoothCache能够自适应地缓存和重用关键特征。</li>
<li>实验显示，SmoothCache实现了显著的推理速度提升，同时保持或提高了生成质量。</li>
<li>SmoothCache在多种模态（如图像生成、文本到视频、文本到音频）中均表现出有效性，具有实现实时应用和扩大DiT模型潜力的潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.10510">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7350587bef2e6f4e436c3513c37f4c8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34a0fd48013b551412d2aba8ff901f76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-08be4be0b33adc1f48adf8ad93acd387.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c79fd6961bc94b4811a79e02191cf1b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ade5bccd213ed646382cb5515626815.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c1e854fd7e98804a9b6705d4c9f18c67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9871a92156aa1b646f2dbb597eb1c7f9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="On-the-contributions-of-extragalactic-CO-emission-lines-to-ground-based-CMB-observations"><a href="#On-the-contributions-of-extragalactic-CO-emission-lines-to-ground-based-CMB-observations" class="headerlink" title="On the contributions of extragalactic CO emission lines to ground-based   CMB observations"></a>On the contributions of extragalactic CO emission lines to ground-based   CMB observations</h2><p><strong>Authors:Nickolas Kokron, José Luis Bernal, Jo Dunkley</strong></p>
<p>We investigate the potential of CO rotational lines at redshifts $z\sim 0-6$ being an appreciable source of extragalactic foreground anisotropies in the cosmic microwave background. Motivated by previous investigations, we specifically focus on the frequency bands and small scales probed by ground-based surveys. Using an empirical parameterization for the relation between the infrared luminosity of galaxies and their CO line luminosity, conditioned on sub-mm observations of CO luminosity functions from $J&#x3D;1$ to $J&#x3D;7$ at $\nu &#x3D; {100,250}$ GHz, we explore how uncertainty in the CO luminosity function translates into uncertainty in the signature of CO emission in the CMB. We find that at $\ell &#x3D; 3000$ the amplitude of the CO cross-correlation with the CIB could be detectable in an ACT-like experiment with 90, 150 and 220 GHz bands, even in the scenarios with the lowest amplitude consistent with sub-mm data. We also investigate, for the first time, the amplitude of the CO$\times$CIB correlation between different frequency bands and find that our model predicts that this signal could be the second-largest extragalactic foreground at certain wavelengths, behind the CIB cross-frequency spectrum. This implies current observations can potentially be used to constrain the bright end of CO luminosity functions, which are difficult to probe with current sub-mm telescopes due to the small volumes they survey. Our findings corroborate past results and have significant implications in template-based searches for CMB secondaries, such as the kinetic Sunyaev Zel’dovich effect, using the frequency-dependent high-$\ell$ TT power spectrum. </p>
<blockquote>
<p>我们研究了在红移$z\sim 0-6$的CO转动线作为宇宙微波背景中可观测的星系前景各向异性来源的潜力。受之前研究的启发，我们特别关注地面勘测所探测的频率波段和小尺度范围。我们利用星系红外光度和其CO线光度之间的经验参数化关系，基于对$\nu &#x3D; {100, 250}$ GHz频率下$J&#x3D;1$至$J&#x3D;7$的亚毫米CO光度函数的观测，探讨了CO光度函数的不确定性如何转化为对CMB中CO发射特征的不确定性。我们发现，在$\ell &#x3D; 3000$时，CO与CIB的互相关幅度可能在ACT类似的实验中检测到，该实验具有90、150和220 GHz的波段，即使在与亚毫米数据一致的最低幅度情景下也是如此。我们还首次调查了不同频率波段之间CO×CIB关联的幅度，发现我们的模型预测，在某些波长上，这一信号可能是仅次于跨频CIB谱的第二大外星系前景。这意味着当前观测结果可用于约束明亮的CO光度函数末端，由于当前亚毫米望远镜所调查的体积较小，这使得这一末端难以探测。我们的研究结果证实了以往的结果，并在基于模板的寻找宇宙微波背景次要成分（如动态Sunyaev Zel’dovich效应）的研究中具有重要含义，尤其是在频率依赖的高$\ell$ TT功率谱分析中。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.20369v2">PDF</a> 14+3 pages, 8+2 figures. Reflects published version, with an   additional post-publication revision which corrects a normalization error in   the original work. Results have changed quantitatively</p>
<p><strong>摘要</strong></p>
<p>本文探讨了CO转动线在红移$z\sim 0-6$范围内作为宇宙微波背景中可观测的宇宙外前景各向异性来源的潜力。基于先前的调查，我们特别关注地面调查所探测的频率波段和小尺度范围。利用星系红外光度与其CO线光度之间的经验参数化关系，并结合亚毫米波段的CO光度函数观测数据，我们研究了CO光度函数的不确定性如何转化为对CMB中CO发射特征的不确定性。我们发现，在$\ell &#x3D; 3000$时，CO与CIB的互相关可能在ACT类似实验中的90、150和220 GHz波段内检测到，即使在与亚毫米数据一致的最低振幅情景下。我们还首次探究了不同频率波段间CO×CIB关联的振幅，我们的模型预测，在某些波长下，这一信号可能是仅次于宇宙红外背景跨频谱的第二大外宇宙前景信号。这意味着当前观测结果可能用于约束CO光度函数的明亮端，由于当前亚毫米望远镜所调查的样本量较小，难以探测这部分信息。我们的研究结果验证了过去的发现，并对基于模板的CMB次级效应搜索（如动学Sunyaev Zel’dovich效应）具有重要影响，可通过频率依赖的高$\ell$ TT功率谱进行研究。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>CO转动线在红移$z\sim 0-6$范围可成为宇宙微波背景中重要的前景各向异性来源。</li>
<li>CO光度函数的不确定性会影响其在宇宙微波背景中的特征表现。</li>
<li>在一定条件下，CO与宇宙红外背景的互相关可能显著，成为第二大外宇宙前景信号。</li>
<li>当前观测可用于约束CO光度函数的明亮端，这部分信息由于亚毫米望远镜样本量小而难以通过现有手段探测。</li>
<li>研究结果验证了过去的发现，对基于模板的次级效应搜索有重要影响。</li>
<li>通过频率依赖的高$\ell$ TT功率谱，可以更好地研究宇宙微波背景的次级效应。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.20369">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-55ee6fb397e63f980ebf8ba581996706.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dbfc04f1973669350bf58e4a0f10f2a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-542e9fe6a9063844f673c6a870a4b5bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b69369481cd36ed39f8b26770c4eaf93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8c5f86fa0020c4135309a70713d9564.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-24/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-24/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-24/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-07875fe1c57e6f78534591239d408f54.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive 方向最新论文已更新，请持续关注 Update in 2025-05-24  Meta-PerSER Few-Shot Listener Personalized Speech Emotion Recognition   via Meta-learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-4686fad44d4ed9b29375e021d84df535.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-05-24  Tracking the Flight Exploring a Computational Framework for Analyzing   Escape Responses in Plains Zebra (Equus quagga)
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19710k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
