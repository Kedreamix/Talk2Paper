<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-24  Audio Jailbreak An Open Comprehensive Benchmark for Jailbreaking Large   Audio-Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-3862ab512a1a7d47697956085cfdeaf5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-31
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    36 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-24-æ›´æ–°"><a href="#2025-05-24-æ›´æ–°" class="headerlink" title="2025-05-24 æ›´æ–°"></a>2025-05-24 æ›´æ–°</h1><h2 id="Audio-Jailbreak-An-Open-Comprehensive-Benchmark-for-Jailbreaking-Large-Audio-Language-Models"><a href="#Audio-Jailbreak-An-Open-Comprehensive-Benchmark-for-Jailbreaking-Large-Audio-Language-Models" class="headerlink" title="Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large   Audio-Language Models"></a>Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large   Audio-Language Models</h2><p><strong>Authors:Zirui Song, Qian Jiang, Mingxuan Cui, Mingzhe Li, Lang Gao, Zeyu Zhang, Zixiang Xu, Yanbo Wang, Chenxi Wang, Guangxian Ouyang, Zhenhao Chen, Xiuying Chen</strong></p>
<p>The rise of Large Audio Language Models (LAMs) brings both potential and risks, as their audio outputs may contain harmful or unethical content. However, current research lacks a systematic, quantitative evaluation of LAM safety especially against jailbreak attacks, which are challenging due to the temporal and semantic nature of speech. To bridge this gap, we introduce AJailBench, the first benchmark specifically designed to evaluate jailbreak vulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of 1,495 adversarial audio prompts spanning 10 policy-violating categories, converted from textual jailbreak attacks using realistic text to speech synthesis. Using this dataset, we evaluate several state-of-the-art LAMs and reveal that none exhibit consistent robustness across attacks. To further strengthen jailbreak testing and simulate more realistic attack conditions, we propose a method to generate dynamic adversarial variants. Our Audio Perturbation Toolkit (APT) applies targeted distortions across time, frequency, and amplitude domains. To preserve the original jailbreak intent, we enforce a semantic consistency constraint and employ Bayesian optimization to efficiently search for perturbations that are both subtle and highly effective. This results in AJailBench-APT, an extended dataset of optimized adversarial audio samples. Our findings demonstrate that even small, semantically preserved perturbations can significantly reduce the safety performance of leading LAMs, underscoring the need for more robust and semantically aware defense mechanisms. </p>
<blockquote>
<p>å¤§è§„æ¨¡éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLAMsï¼‰çš„å…´èµ·å¸¦æ¥äº†æ½œåŠ›å’Œé£é™©ï¼Œå› ä¸ºå®ƒä»¬çš„éŸ³é¢‘è¾“å‡ºå¯èƒ½åŒ…å«æœ‰å®³æˆ–ä¸é“å¾·çš„å†…å®¹ã€‚ç„¶è€Œï¼Œå½“å‰çš„ç ”ç©¶ç¼ºä¹ç³»ç»Ÿã€å®šé‡åœ°è¯„ä¼°LAMå®‰å…¨æ€§çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºè¶Šç‹±æ”»å‡»ï¼ˆjailbreak attacksï¼‰çš„è¯„ä¼°ï¼Œè¿™ç§è¯„ä¼°é¢‡å…·æŒ‘æˆ˜æ€§ï¼ŒåŸå› åœ¨äºè¯­éŸ³çš„æ—¶æ•ˆæ€§å’Œè¯­ä¹‰æ€§ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†AJailBenchï¼Œè¿™æ˜¯ä¸“é—¨ç”¨äºè¯„ä¼°LAMsä¸­è¶Šç‹±æ¼æ´çš„ç¬¬ä¸€ä¸ªåŸºå‡†æµ‹è¯•ã€‚</p>
</blockquote>
<p>æˆ‘ä»¬é¦–å…ˆæ„å»ºAJailBench-Baseæ•°æ®é›†ï¼ŒåŒ…å«1495ä¸ªè·¨10ç±»è¿è§„æ”¿ç­–çš„å¯¹æŠ—æ€§éŸ³é¢‘æç¤ºï¼Œè¿™äº›æç¤ºæ˜¯é€šè¿‡ç°å®æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆæŠ€æœ¯ï¼Œä»æ–‡æœ¬è¶Šç‹±æ”»å‡»è½¬æ¢è€Œæ¥çš„ã€‚ä½¿ç”¨è¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å‡ ç§æœ€æ–°å‰æ²¿çš„LAMsï¼Œå‘ç°å®ƒä»¬åœ¨å„ç§æ”»å‡»ä¸­å‡æ²¡æœ‰è¡¨ç°å‡ºä¸€è‡´çš„ç¨³å¥æ€§ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15406v1">PDF</a> We release AJailBench, including both static and optimized   adversarial data, to facilitate future research:   <a target="_blank" rel="noopener" href="https://github.com/mbzuai-nlp/AudioJailbreak">https://github.com/mbzuai-nlp/AudioJailbreak</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLAMsï¼‰çš„å…´èµ·å¸¦æ¥çš„æ½œåœ¨é£é™©å’Œæœºé‡ã€‚é’ˆå¯¹LAMsçš„å®‰å…¨æ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹è¯­éŸ³çš„ä¸´æ—¶å’Œè¯­ä¹‰ç‰¹æ€§çš„è¶Šç‹±æ”»å‡»ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ã€‚æ–‡ç« å»ºç«‹äº†AJailBenchåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°LAMsçš„è¶Šç‹±æ¼æ´ï¼Œå¹¶å¼•å…¥äº†AJailBench-Baseæ•°æ®é›†å’ŒAudio Perturbation Toolkitï¼ˆAPTï¼‰æ¥ç”ŸæˆåŠ¨æ€å¯¹æŠ—æ ·æœ¬ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯å¾®å°ä¸”è¯­ä¹‰ä¸Šä¿æŒä¸€è‡´çš„æ‰°åŠ¨ï¼Œä¹Ÿèƒ½æ˜¾è‘—é™ä½é¢†å…ˆLAMsçš„å®‰å…¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLAMsï¼‰çš„éŸ³é¢‘è¾“å‡ºå¯èƒ½åŒ…å«æœ‰å®³æˆ–ä¸é“å¾·çš„å†…å®¹ï¼Œå­˜åœ¨æ½œåœ¨é£é™©ã€‚</li>
<li>ç›®å‰é’ˆå¯¹LAMsçš„å®‰å…¨è¯„ä¼°ç¼ºä¹ç³»ç»Ÿã€å®šé‡çš„è¯„ä»·ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹è¶Šç‹±æ”»å‡»ã€‚</li>
<li>å»ºç«‹äº†AJailBenchåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°LAMsçš„è¶Šç‹±æ¼æ´ã€‚</li>
<li>AJailBench-Baseæ•°æ®é›†ç”±1495ä¸ªå¯¹æŠ—æ€§éŸ³é¢‘æç¤ºç»„æˆï¼Œè¿™äº›æç¤ºæ˜¯ä»æ–‡æœ¬è¶Šç‹±æ”»å‡»è½¬æ¢è€Œæ¥ï¼Œç”¨äºè¯„ä¼°LAMsã€‚</li>
<li>ç°æœ‰çš„å…ˆè¿›LAMsåœ¨æ”»å‡»æ–¹é¢ç¼ºä¹ä¸€è‡´çš„ç¨³å¥æ€§ã€‚</li>
<li>Audio Perturbation Toolkitï¼ˆAPTï¼‰ç”¨äºç”ŸæˆåŠ¨æ€å¯¹æŠ—æ ·æœ¬ï¼Œé€šè¿‡æ—¶é—´ã€é¢‘ç‡å’ŒæŒ¯å¹…åŸŸçš„ç›®æ ‡å¤±çœŸè¿›è¡Œæ¨¡æ‹Ÿæ›´ç°å®çš„æ”»å‡»æ¡ä»¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15406">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9aea5148eb16a514cb929d60f9f9e8e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c424fbc78398328403f5617a873222be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61fe979964da9bf901b177dc8a991e94.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1a4bb0c1c8c0e1dd66c2e0318130405b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Prosody-Adaptable-Audio-Codecs-for-Zero-Shot-Voice-Conversion-via-In-Context-Learning"><a href="#Prosody-Adaptable-Audio-Codecs-for-Zero-Shot-Voice-Conversion-via-In-Context-Learning" class="headerlink" title="Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via   In-Context Learning"></a>Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via   In-Context Learning</h2><p><strong>Authors:Junchuan Zhao, Xintong Wang, Ye Wang</strong></p>
<p>Recent advances in discrete audio codecs have significantly improved speech representation modeling, while codec language models have enabled in-context learning for zero-shot speech synthesis. Inspired by this, we propose a voice conversion (VC) model within the VALLE-X framework, leveraging its strong in-context learning capabilities for speaker adaptation. To enhance prosody control, we introduce a prosody-aware audio codec encoder (PACE) module, which isolates and refines prosody from other sources, improving expressiveness and control. By integrating PACE into our VC model, we achieve greater flexibility in prosody manipulation while preserving speaker timbre. Experimental evaluation results demonstrate that our approach outperforms baseline VC systems in prosody preservation, timbre consistency, and overall naturalness, surpassing baseline VC systems. </p>
<blockquote>
<p>è¿‘æœŸç¦»æ•£éŸ³é¢‘ç¼–ç å™¨çš„è¿›å±•æå¤§åœ°æ”¹è¿›äº†è¯­éŸ³è¡¨ç¤ºå»ºæ¨¡ï¼Œè€Œç¼–ç å™¨è¯­è¨€æ¨¡å‹å·²ç»å®ç°äº†é›¶æ ·æœ¬è¯­éŸ³åˆæˆçš„ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚å—å…¶å¯å‘ï¼Œæˆ‘ä»¬åœ¨VALLE-Xæ¡†æ¶å†…æå‡ºäº†ä¸€ä¸ªè¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰æ¨¡å‹ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›è¿›è¡Œè¯´è¯äººé€‚é…ã€‚ä¸ºäº†å¢å¼ºéŸµå¾‹æ§åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªéŸµå¾‹æ„ŸçŸ¥éŸ³é¢‘ç¼–ç å™¨ï¼ˆPACEï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥éš”ç¦»å¹¶ä¼˜åŒ–éŸµå¾‹çš„æ¥æºï¼Œæé«˜è¡¨è¾¾åŠ›å’Œæ§åˆ¶åŠ›ã€‚é€šè¿‡å°†PACEé›†æˆåˆ°æˆ‘ä»¬çš„VCæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬åœ¨éŸµå¾‹æ“çºµæ–¹é¢å®ç°äº†æ›´å¤§çš„çµæ´»æ€§ï¼ŒåŒæ—¶ä¿ç•™äº†è¯´è¯äººçš„éŸ³è‰²ã€‚å®éªŒè¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨éŸµå¾‹ä¿æŒã€éŸ³è‰²ä¸€è‡´æ€§å’Œæ•´ä½“è‡ªç„¶åº¦æ–¹é¢è¶…è¶Šäº†åŸºçº¿VCç³»ç»Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15402v1">PDF</a> 5 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸç¦»æ•£éŸ³é¢‘ç¼–ç å™¨çš„è¿›å±•æå¤§åœ°æ”¹è¿›äº†è¯­éŸ³è¡¨ç¤ºå»ºæ¨¡ï¼Œè€Œç¼–ç å™¨è¯­è¨€æ¨¡å‹åˆ™ä¸ºé›¶æ ·æœ¬è¯­éŸ³åˆæˆæä¾›äº†ä¸Šä¸‹æ–‡å­¦ä¹ ç¯å¢ƒã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬åœ¨VALLE-Xæ¡†æ¶å†…æå‡ºäº†è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰æ¨¡å‹ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›è¿›è¡Œè¯­éŸ³è€…é€‚åº”ã€‚ä¸ºæå‡è¯­è°ƒæ§åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­è°ƒæ„ŸçŸ¥éŸ³é¢‘ç¼–ç å™¨ï¼ˆPACEï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½éš”ç¦»å¹¶ä¼˜åŒ–è¯­è°ƒæ¥æºï¼Œæå‡è¡¨è¾¾çš„ç”ŸåŠ¨æ€§å’Œæ§åˆ¶åŠ›ã€‚å°†PACEæ•´åˆè‡³VCæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬åœ¨è¯­è°ƒæ“æ§ä¸Šè·å¾—æ›´å¤§çš„çµæ´»æ€§ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯è€…çš„éŸ³è‰²ã€‚å®éªŒè¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¯­è°ƒä¿ç•™ã€éŸ³è‰²ä¸€è‡´æ€§å’Œæ•´ä½“è‡ªç„¶åº¦ä¸Šè¶…è¶Šäº†åŸºçº¿VCç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¦»æ•£éŸ³é¢‘ç¼–ç å™¨çš„æœ€æ–°è¿›å±•æ˜¾è‘—æ”¹è¿›äº†è¯­éŸ³è¡¨ç¤ºå»ºæ¨¡ã€‚</li>
<li>ç¼–ç å™¨è¯­è¨€æ¨¡å‹æ”¯æŒé›¶æ ·æœ¬è¯­éŸ³åˆæˆçš„ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚</li>
<li>æå‡ºäº†åœ¨VALLE-Xæ¡†æ¶å†…çš„è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰æ¨¡å‹ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›è¿›è¡Œè¯­éŸ³è€…é€‚åº”ã€‚</li>
<li>å¼•å…¥PACEæ¨¡å—ä»¥å¼ºåŒ–è¯­è°ƒæ§åˆ¶ï¼Œå¹¶éš”ç¦»å’Œä¼˜åŒ–è¯­è°ƒæ¥æºã€‚</li>
<li>PACEä¸VCæ¨¡å‹çš„ç»“åˆå®ç°äº†çµæ´»çš„è¯­è°ƒæ“æ§ï¼ŒåŒæ—¶ä¿ç•™éŸ³è‰²ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯­è°ƒä¿ç•™ã€éŸ³è‰²ä¸€è‡´æ€§å’Œè‡ªç„¶åº¦ä¸Šè¶…è¶Šäº†åŸºçº¿VCç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15402">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ba1cba21ed3de6bc44389948aa5b00e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1e4201e7de303229190d1eea635ba23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3646ee87f32d11323a55446a1552483.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-32184b8a627ad4363f6d6f2252a3a6df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1880b7f97a55df6b9a2c14ad26fa717f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f38d0b65c8dfaeb9c81bb1e530eac4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c2b129d197257c131aeb99eebbd2fd2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Saten-Sparse-Augmented-Tensor-Networks-for-Post-Training-Compression-of-Large-Language-Models"><a href="#Saten-Sparse-Augmented-Tensor-Networks-for-Post-Training-Compression-of-Large-Language-Models" class="headerlink" title="Saten: Sparse Augmented Tensor Networks for Post-Training Compression of   Large Language Models"></a>Saten: Sparse Augmented Tensor Networks for Post-Training Compression of   Large Language Models</h2><p><strong>Authors:Ryan Solgi, Kai Zhen, Rupak Vignesh Swaminathan, Nathan Susanj, Athanasios Mouchtaris, Siegfried Kunzmann, Zheng Zhang</strong></p>
<p>The efficient implementation of large language models (LLMs) is crucial for deployment on resource-constrained devices. Low-rank tensor compression techniques, such as tensor-train (TT) networks, have been widely studied for over-parameterized neural networks. However, their applications to compress pre-trained large language models (LLMs) for downstream tasks (post-training) remains challenging due to the high-rank nature of pre-trained LLMs and the lack of access to pretraining data. In this study, we investigate low-rank tensorized LLMs during fine-tuning and propose sparse augmented tensor networks (Saten) to enhance their performance. The proposed Saten framework enables full model compression. Experimental results demonstrate that Saten enhances both accuracy and compression efficiency in tensorized language models, achieving state-of-the-art performance. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ‰æ•ˆå®ç°å¯¹äºåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²è‡³å…³é‡è¦ã€‚å¼ é‡åˆ†è§£æŠ€æœ¯ï¼Œå¦‚å¼ é‡åˆ—è½¦ï¼ˆTTï¼‰ç½‘ç»œï¼Œå·²è¢«å¹¿æ³›åº”ç”¨äºè¿‡å‚æ•°åŒ–çš„ç¥ç»ç½‘ç»œã€‚ç„¶è€Œï¼Œç”±äºå…¶é«˜ç»´ç‰¹æ€§å’Œæ— æ³•è®¿é—®é¢„è®­ç»ƒæ•°æ®ï¼Œå°†é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼ˆåè®­ç»ƒï¼‰æ—¶ï¼Œä½¿ç”¨è¿™äº›æŠ€æœ¯è¿›è¡Œå‹ç¼©ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è°ƒæŸ¥äº†åœ¨å¾®è°ƒæœŸé—´ä½¿ç”¨ä½é˜¶å¼ é‡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶æå‡ºäº†ç¨€ç–å¢å¼ºå¼ é‡ç½‘ç»œï¼ˆSatenï¼‰ä»¥æé«˜å…¶æ€§èƒ½ã€‚æ‰€æå‡ºçš„Satenæ¡†æ¶èƒ½å¤Ÿå®ç°å…¨æ¨¡å‹å‹ç¼©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSatenåœ¨æé«˜äº†å¼ é‡åŒ–è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå‹ç¼©æ•ˆç‡çš„åŒæ—¶ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14871v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>å¯¹äºèµ„æºå—é™è®¾å¤‡æ¥è¯´ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœ‰æ•ˆå®æ–½è‡³å…³é‡è¦ã€‚å¼ é‡è®­ç»ƒç½‘ç»œç­‰ä½ç§©å¼ é‡å‹ç¼©æŠ€æœ¯å·²å¹¿æ³›åº”ç”¨äºè¿‡å‚æ•°åŒ–çš„ç¥ç»ç½‘ç»œã€‚ç„¶è€Œï¼Œç”±äºå…¶é«˜ç§©ç‰¹æ€§å’Œæ— æ³•è®¿é—®é¢„è®­ç»ƒæ•°æ®ï¼Œè¿™äº›æŠ€æœ¯åº”ç”¨äºå‹ç¼©é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥é€‚åº”ä¸‹æ¸¸ä»»åŠ¡ä»é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­è°ƒæŸ¥äº†ä½ç§©å¼ é‡åŒ–LLMsï¼Œå¹¶æå‡ºç¨€ç–å¢å¼ºå¼ é‡ç½‘ç»œï¼ˆSatenï¼‰ä»¥æé«˜å…¶æ€§èƒ½ã€‚æ‰€æå‡ºçš„Satenæ¡†æ¶èƒ½å¤Ÿå®ç°å…¨æ¨¡å‹å‹ç¼©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSatenåœ¨æé«˜äº†å¼ é‡åŒ–è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå‹ç¼©æ•ˆç‡çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†ä¸šç•Œæœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„æœ‰æ•ˆå®æ–½éå¸¸é‡è¦ã€‚</li>
<li>ä½ç§©å¼ é‡å‹ç¼©æŠ€æœ¯å¦‚å¼ é‡è®­ç»ƒç½‘ç»œå·²å¹¿æ³›åº”ç”¨äºè¿‡å‚æ•°åŒ–ç¥ç»ç½‘ç»œã€‚</li>
<li>å°†è¿™äº›æŠ€æœ¯åº”ç”¨äºé¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥é€‚åº”ä¸‹æ¸¸ä»»åŠ¡é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºé«˜ç§©ç‰¹æ€§å’Œæ— æ³•è®¿é—®é¢„è®­ç»ƒæ•°æ®ã€‚</li>
<li>ç ”ç©¶äººå‘˜åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­è°ƒæŸ¥äº†ä½ç§©å¼ é‡åŒ–LLMsã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”ç¨€ç–å¢å¼ºå¼ é‡ç½‘ç»œï¼ˆSatenï¼‰ï¼Œæ—¨åœ¨æé«˜è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>Satenæ¡†æ¶èƒ½å¤Ÿå®ç°å…¨æ¨¡å‹å‹ç¼©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14871">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a386f70702e171c6aed1ad4e6637ec25.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3862ab512a1a7d47697956085cfdeaf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb2a2608d3a7a2af45c020fd6fa58f08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21a7647f0d184f7d97bd83d6f4d9e98c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e29e934e9664c13549f8e399a5588ad.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AudioJailbreak-Jailbreak-Attacks-against-End-to-End-Large-Audio-Language-Models"><a href="#AudioJailbreak-Jailbreak-Attacks-against-End-to-End-Large-Audio-Language-Models" class="headerlink" title="AudioJailbreak: Jailbreak Attacks against End-to-End Large   Audio-Language Models"></a>AudioJailbreak: Jailbreak Attacks against End-to-End Large   Audio-Language Models</h2><p><strong>Authors:Guangke Chen, Fu Song, Zhe Zhao, Xiaojun Jia, Yang Liu, Yanchen Qiao, Weizhe Zhang</strong></p>
<p>Jailbreak attacks to Large audio-language models (LALMs) are studied recently, but they achieve suboptimal effectiveness, applicability, and practicability, particularly, assuming that the adversary can fully manipulate user prompts. In this work, we first conduct an extensive experiment showing that advanced text jailbreak attacks cannot be easily ported to end-to-end LALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a novel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio does not need to align with user prompts in the time axis by crafting suffixal jailbreak audios; (2) universality: a single jailbreak perturbation is effective for different prompts by incorporating multiple prompts into perturbation generation; (3) stealthiness: the malicious intent of jailbreak audios will not raise the awareness of victims by proposing various intent concealment strategies; and (4) over-the-air robustness: the jailbreak audios remain effective when being played over the air by incorporating the reverberation distortion effect with room impulse response into the generation of the perturbations. In contrast, all prior audio jailbreak attacks cannot offer asynchrony, universality, stealthiness, or over-the-air robustness. Moreover, AudioJailbreak is also applicable to the adversary who cannot fully manipulate user prompts, thus has a much broader attack scenario. Extensive experiments with thus far the most LALMs demonstrate the high effectiveness of AudioJailbreak. We highlight that our work peeks into the security implications of audio jailbreak attacks against LALMs, and realistically fosters improving their security robustness. The implementation and audio samples are available at our website <a target="_blank" rel="noopener" href="https://audiojailbreak.github.io/AudioJailbreak">https://audiojailbreak.github.io/AudioJailbreak</a>. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œé’ˆå¯¹å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰çš„è¶Šç‹±æ”»å‡»å·²å—åˆ°ç ”ç©¶ï¼Œä½†å…¶åœ¨æ•ˆèƒ½ã€é€‚ç”¨æ€§å’Œå®ç”¨æ€§æ–¹é¢å°šæœªè¾¾åˆ°æœ€ä½³ï¼Œå°¤å…¶æ˜¯å‡è®¾æ”»å‡»è€…å¯ä»¥å®Œå…¨æ“æ§ç”¨æˆ·æç¤ºçš„æƒ…å†µä¸‹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œè¡¨æ˜å…ˆè¿›çš„æ–‡æœ¬è¶Šç‹±æ”»å‡»æ— æ³•è½»æ˜“é€šè¿‡æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯è½¬ç§»åˆ°ç«¯åˆ°ç«¯çš„LALMä¸Šã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†AudioJailbreakï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹éŸ³é¢‘è¶Šç‹±æ”»å‡»ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p>
</blockquote>
<ol>
<li>å¼‚æ­¥æ€§ï¼šè¶Šç‹±éŸ³é¢‘æ— éœ€é€šè¿‡åˆ¶ä½œåç¼€è¶Šç‹±éŸ³é¢‘ä¸ç”¨æˆ·æç¤ºåœ¨æ—¶é—´è½´ä¸Šè¿›è¡Œå¯¹é½ï¼›</li>
<li>é€šç”¨æ€§ï¼šé€šè¿‡åˆå¹¶å¤šä¸ªæç¤ºæ¥ç”Ÿæˆæ‰°åŠ¨ï¼Œå•ä¸ªè¶Šç‹±æ‰°åŠ¨å¯¹ä¸åŒçš„æç¤ºéƒ½æœ‰æ•ˆï¼›</li>
<li>éšè”½æ€§ï¼šé€šè¿‡æå‡ºå„ç§æ„å›¾éšè—ç­–ç•¥ï¼Œè¶Šç‹±éŸ³é¢‘çš„æ¶æ„æ„å›¾ä¸ä¼šè®©å—å®³è€…æé«˜è­¦æƒ•ï¼›</li>
<li>ç©ºä¸­ä¼ æ’­çš„ç¨³å¥æ€§ï¼šé€šè¿‡å°†æ··å“å¤±çœŸæ•ˆåº”ä¸æˆ¿é—´å†²å‡»å“åº”ç»“åˆåˆ°æ‰°åŠ¨ç”Ÿæˆä¸­ï¼Œè¶Šç‹±éŸ³é¢‘åœ¨åœ¨ç©ºä¸­æ’­æ”¾æ—¶ä»èƒ½ä¿æŒæœ‰æ•ˆã€‚</li>
</ol>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14103v2">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰çš„è¶Šç‹±æ”»å‡»ç ”ç©¶å­˜åœ¨å±€é™æ€§ï¼Œè¿‘æœŸæå‡ºçš„æ–‡æœ¬è¶Šç‹±æ”»å‡»æ— æ³•è½»æ˜“åº”ç”¨äºç«¯åˆ°ç«¯çš„LALMæ¨¡å‹ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ–°å‹éŸ³é¢‘è¶Šç‹±æ”»å‡»æ–¹æ³•â€”â€”AudioJailbreakï¼Œå…·æœ‰å¼‚æ­¥æ€§ã€æ™®éæ€§ã€éšè”½æ€§åŠç©ºä¸­ä¼ æ’­ç¨³å¥æ€§ç­‰ç‰¹ç‚¹ï¼Œå¯¹ç°æœ‰æ”»å‡»åœºæ™¯æœ‰æ›´å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚å®éªŒè¯æ˜ï¼ŒAudioJailbreakå¯¹ç›®å‰å¤§å¤šæ•°LALMæ¨¡å‹å…·æœ‰é«˜æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰é’ˆå¯¹LALMçš„è¶Šç‹±æ”»å‡»å­˜åœ¨æ•ˆæœã€é€‚ç”¨æ€§å’Œå®ç”¨æ€§æ–¹é¢çš„ä¸è¶³ã€‚</li>
<li>æ–‡æœ¬è¶Šç‹±æ”»å‡»æ— æ³•è½»æ˜“åº”ç”¨äºç«¯åˆ°ç«¯çš„LALMæ¨¡å‹ã€‚</li>
<li>AudioJailbreakæ˜¯ä¸€ç§æ–°å‹éŸ³é¢‘è¶Šç‹±æ”»å‡»ï¼Œå…·æœ‰å¼‚æ­¥æ€§ã€æ™®éæ€§ã€éšè”½æ€§å’Œç©ºä¸­ä¼ æ’­ç¨³å¥æ€§ã€‚</li>
<li>AudioJailbreakå¯¹ç›®å‰å¤§å¤šæ•°LALMæ¨¡å‹å…·æœ‰é«˜æ•ˆæ€§ã€‚</li>
<li>AudioJailbreaké€‚ç”¨äºæ— æ³•å®Œå…¨æ“çºµç”¨æˆ·æç¤ºçš„å¯¹æ‰‹ï¼Œå…·æœ‰æ›´å¹¿æ³›çš„æ”»å‡»åœºæ™¯ã€‚</li>
<li>AudioJailbreaké€šè¿‡èå…¥æ··å“å¤±çœŸæ•ˆåº”ä¸æˆ¿é—´è„‰å†²å“åº”æ¥æå‡ç©ºä¸­ä¼ æ’­ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14103">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fde7517063fbf998e01e91025551f181.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88755946603f8cbe258b2fe3cb0bb019.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe8d54d42c0ffd4affae82ca1a116e94.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Improving-Noise-Robustness-of-LLM-based-Zero-shot-TTS-via-Discrete-Acoustic-Token-Denoising"><a href="#Improving-Noise-Robustness-of-LLM-based-Zero-shot-TTS-via-Discrete-Acoustic-Token-Denoising" class="headerlink" title="Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete   Acoustic Token Denoising"></a>Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete   Acoustic Token Denoising</h2><p><strong>Authors:Ye-Xin Lu, Hui-Peng Du, Fei Liu, Yang Ai, Zhen-Hua Ling</strong></p>
<p>Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend to preserve the acoustic environment of the audio prompt, leading to degradation in synthesized speech quality when the audio prompt contains noise. In this paper, we propose a novel neural codec-based speech denoiser and integrate it with the advanced LLM-based TTS model, LauraTTS, to achieve noise-robust zero-shot TTS. The proposed codec denoiser consists of an audio codec, a token denoiser, and an embedding refiner. The token denoiser predicts the first two groups of clean acoustic tokens from the noisy ones, which can serve as the acoustic prompt for LauraTTS to synthesize high-quality personalized speech or be converted to clean speech waveforms through the embedding refiner and codec decoder. Experimental results show that our proposed codec denoiser outperforms state-of-the-art speech enhancement (SE) methods, and the proposed noise-robust LauraTTS surpasses the approach using additional SE models. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ–¹æ³•å¾€å¾€ä¼šä¿ç•™éŸ³é¢‘æç¤ºçš„å£°å­¦ç¯å¢ƒï¼Œä½†å½“éŸ³é¢‘æç¤ºåŒ…å«å™ªå£°æ—¶ï¼Œä¼šå¯¼è‡´åˆæˆè¯­éŸ³è´¨é‡ä¸‹é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºç¥ç»ç½‘ç»œç¼–è§£ç å™¨çš„è¯­éŸ³å»å™ªå™¨ï¼Œå¹¶å°†å…¶ä¸å…ˆè¿›çš„åŸºäºLLMçš„TTSæ¨¡å‹LauraTTSç›¸ç»“åˆï¼Œå®ç°äº†å™ªå£°é²æ£’çš„é›¶æ ·æœ¬TTSã€‚æ‰€æå‡ºçš„ç¼–è§£ç å™¨å»å™ªå™¨ç”±éŸ³é¢‘ç¼–è§£ç å™¨ã€ä»¤ç‰Œå»å™ªå™¨å’ŒåµŒå…¥ç²¾ç‚¼å™¨ç»„æˆã€‚ä»¤ç‰Œå»å™ªå™¨ä»å™ªå£°ä»¤ç‰Œä¸­é¢„æµ‹å‰ä¸¤ä¸ªç»„çš„å¹²å‡€å£°å­¦ä»¤ç‰Œï¼Œè¿™å¯ä»¥ä½œä¸ºLauraTTSåˆæˆé«˜è´¨é‡ä¸ªæ€§åŒ–è¯­éŸ³çš„å£°å­¦æç¤ºï¼Œæˆ–è€…é€šè¿‡åµŒå…¥ç²¾ç‚¼å™¨å’Œç¼–è§£ç å™¨è§£ç å™¨è½¬æ¢ä¸ºå¹²å‡€çš„è¯­éŸ³æ³¢å½¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„ç¼–è§£ç å™¨å»å™ªå™¨ä¼˜äºç°æœ‰çš„è¯­éŸ³å¢å¼ºï¼ˆSEï¼‰æ–¹æ³•ï¼Œå¹¶ä¸”æ‰€æå‡ºçš„å™ªå£°é²æ£’LauraTTSè¶…è¶Šäº†ä½¿ç”¨é™„åŠ SEæ¨¡å‹çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13830v2">PDF</a> Accepted by Interspeech 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ–¹æ³•ä¼šä¿ç•™éŸ³é¢‘æç¤ºçš„å£°å­¦ç¯å¢ƒï¼Œå½“éŸ³é¢‘æç¤ºåŒ…å«å™ªå£°æ—¶ï¼Œä¼šå¯¼è‡´åˆæˆè¯­éŸ³è´¨é‡ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºç¥ç»ç½‘ç»œç¼–è§£ç å™¨çš„è¯­éŸ³å»å™ªå™¨ï¼Œå¹¶å°†å…¶ä¸å…ˆè¿›çš„LLM-based TTSæ¨¡å‹LauraTTSç›¸ç»“åˆï¼Œå®ç°äº†å™ªå£°é²æ£’çš„é›¶æ ·æœ¬TTSã€‚ç¼–è§£ç å™¨å»å™ªå™¨ç”±éŸ³é¢‘ç¼–è§£ç å™¨ã€ä»¤ç‰Œå»å™ªå™¨å’ŒåµŒå…¥ç²¾ç‚¼å™¨ç»„æˆã€‚ä»¤ç‰Œå»å™ªå™¨ä»å˜ˆæ‚çš„ä»¤ç‰Œé¢„æµ‹å‰ä¸¤ç»„å¹²å‡€çš„å£°å­¦ä»¤ç‰Œï¼Œå¯ä»¥ä½œä¸ºLauraTTSåˆæˆé«˜è´¨é‡ä¸ªæ€§åŒ–è¯­éŸ³çš„å£°å­¦æç¤ºï¼Œæˆ–é€šè¿‡åµŒå…¥ç²¾ç‚¼å™¨å’Œç¼–è§£ç å™¨è§£ç å™¨è½¬æ¢ä¸ºå¹²å‡€çš„è¯­éŸ³æ³¢å½¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„ç¼–è§£ç å™¨å»å™ªå™¨ä¼˜äºç°æœ‰çš„è¯­éŸ³å¢å¼ºï¼ˆSEï¼‰æ–¹æ³•ï¼Œè€Œæå‡ºçš„å™ªå£°é²æ£’æ€§LauraTTSåˆ™è¶…è¶Šäº†ä½¿ç”¨é™„åŠ SEæ¨¡å‹çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based zero-shot TTSæ–¹æ³•åœ¨ä¿ç•™éŸ³é¢‘æç¤ºçš„å£°å­¦ç¯å¢ƒæ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å«æœ‰å™ªå£°çš„éŸ³é¢‘æç¤ºä¸‹ä¼šå¯¼è‡´è¯­éŸ³è´¨é‡ä¸‹é™ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¥ç»ç½‘ç»œç¼–è§£ç å™¨è¯­éŸ³å»å™ªå™¨ï¼Œç”¨äºå¤„ç†éŸ³é¢‘ä¸­çš„å™ªå£°é—®é¢˜ã€‚</li>
<li>ç¼–è§£ç å™¨å»å™ªå™¨åŒ…æ‹¬éŸ³é¢‘ç¼–è§£ç å™¨ã€ä»¤ç‰Œå»å™ªå™¨å’ŒåµŒå…¥ç²¾ç‚¼å™¨ä¸‰ä¸ªå…³é”®ç»„ä»¶ã€‚</li>
<li>ä»¤ç‰Œå»å™ªå™¨èƒ½å¤Ÿä»å«å™ªå£°çš„ä»¤ç‰Œä¸­é¢„æµ‹å‡ºå¹²å‡€çš„å£°å­¦ä»¤ç‰Œï¼Œä¸ºLauraTTSæä¾›é«˜è´¨é‡çš„å£°å­¦æç¤ºã€‚</li>
<li>æ•´åˆç¼–è§£ç å™¨å»å™ªå™¨å’ŒLauraTTSæ¨¡å‹å¯å®ç°å™ªå£°é²æ£’çš„é›¶æ ·æœ¬TTSã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè®ºæ–‡æå‡ºçš„ç¼–è§£ç å™¨å»å™ªå™¨åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰çš„è¯­éŸ³å¢å¼ºæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13830">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4aa79b6eb807d311ebdea7380b9395ad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ba58973ea83532ce32150a761118e124.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-582a9fe21eabd309d2c2f7fd1e78776e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-02c233800f084b2074fac3697b931790.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TTRL-Test-Time-Reinforcement-Learning"><a href="#TTRL-Test-Time-Reinforcement-Learning" class="headerlink" title="TTRL: Test-Time Reinforcement Learning"></a>TTRL: Test-Time Reinforcement Learning</h2><p><strong>Authors:Yuxin Zuo, Kaiyan Zhang, Li Sheng, Shang Qu, Ganqu Cui, Xuekai Zhu, Haozhan Li, Yuchen Zhang, Xinwei Long, Ermo Hua, Biqing Qi, Youbang Sun, Zhiyuan Ma, Lifan Yuan, Ning Ding, Bowen Zhou</strong></p>
<p>This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 211% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the maj@n metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model maj@n, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks and highlight TTRLâ€™s potential for broader tasks and domains. GitHub: <a target="_blank" rel="noopener" href="https://github.com/PRIME-RL/TTRL">https://github.com/PRIME-RL/TTRL</a> </p>
<blockquote>
<p>æœ¬æ–‡æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†ä»»åŠ¡ä¸­ï¼Œåœ¨æ— æ˜ç¡®æ ‡ç­¾æ•°æ®ä¸Šåº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æƒ…å†µã€‚è¯¥é—®é¢˜çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºåœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œå¥–åŠ±ä¼°è®¡ï¼ŒåŒæ—¶æ— æ³•è·å¾—çœŸå®ä¿¡æ¯çš„æ”¯æŒã€‚å°½ç®¡è¿™ä¸ªè®¾ç½®ä¼¼ä¹å¾ˆæ¨¡ç³Šï¼Œä½†æˆ‘ä»¬å‘ç°æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰ä¸­çš„å¸¸è§åšæ³•ï¼Œå¦‚å¤šæ•°æŠ•ç¥¨ï¼Œä¼šäº§ç”Ÿä»¤äººæƒŠè®¶çš„æœ‰æ•ˆå¥–åŠ±ï¼Œé€‚ç”¨äºé©±åŠ¨RLè®­ç»ƒã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†æµ‹è¯•æ—¶é—´å¼ºåŒ–å­¦ä¹ ï¼ˆTTRLï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨æ— æ ‡ç­¾æ•°æ®ä¸Šçš„RLè®­ç»ƒLLMçš„æ–°æ–¹æ³•ã€‚TTRLåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„å…ˆéªŒçŸ¥è¯†ï¼Œå®ç°äº†LLMçš„è‡ªæˆ‘è¿›åŒ–ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒTTRLåœ¨å„ç§ä»»åŠ¡å’Œæ¨¡å‹ä¸Šçš„æ€§èƒ½æŒç»­æé«˜ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨AIME 2024ä¸Šï¼ŒTTRLå°†Qwen-2.5-Math-7Bçš„pass@1æ€§èƒ½æé«˜äº†å¤§çº¦211%ï¼Œè€Œä¸”ä»…ä½¿ç”¨æ— æ ‡ç­¾çš„æµ‹è¯•æ•°æ®ã€‚æ­¤å¤–ï¼Œå°½ç®¡TTRLåªå—åˆ°maj@næŒ‡æ ‡çš„ç›‘ç£ï¼Œä½†å…¶æ€§èƒ½å·²ç»è¶…è¶Šäº†åˆå§‹æ¨¡å‹çš„maj@nä¸Šé™ï¼Œå¹¶æ¥è¿‘ç›´æ¥åœ¨å¸¦æœ‰çœŸå®æ ‡ç­¾çš„æµ‹è¯•æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜TTRLåœ¨å¤šç§ä»»åŠ¡ä¸­çš„æ™®éæœ‰æ•ˆæ€§ï¼Œå¹¶çªå‡ºäº†å…¶åœ¨æ›´å¹¿æ³›çš„ä»»åŠ¡å’Œé¢†åŸŸä¸­çš„æ½œåŠ›ã€‚GitHubåœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/PRIME-RL/TTRL">https://github.com/PRIME-RL/TTRL</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16084v2">PDF</a> </p>
<p><strong>Summary</strong><br>æœ¬æ–‡æ¢ç´¢äº†æ— éœ€æ ‡ç­¾æ•°æ®çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åº”ç”¨ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºåœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œå¥–åŠ±ä¼°ç®—ï¼ŒåŒæ—¶æ— æ³•è·å–çœŸå®ä¿¡æ¯ã€‚å°½ç®¡è¿™ç§æƒ…å†µçœ‹ä¼¼éš¾ä»¥è§£å†³ï¼Œä½†æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰çš„å¸¸è§å®è·µï¼Œå¦‚å¤šæ•°æŠ•ç¥¨ï¼Œäº§ç”Ÿäº†ä»¤äººæƒŠè®¶çš„æœ‰æ•ˆå¥–åŠ±ï¼Œé€‚ç”¨äºé©±åŠ¨RLè®­ç»ƒã€‚æœ¬æ–‡æå‡ºäº†Test-Time Reinforcement Learningï¼ˆTTRLï¼‰è¿™ä¸€æ–°æ–¹æ³•ï¼Œç”¨äºåœ¨æ— éœ€æ ‡ç­¾çš„æ•°æ®ä¸Šè®­ç»ƒLLMã€‚TTRLé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„å…ˆéªŒçŸ¥è¯†ï¼Œå®ç°äº†LLMçš„è‡ªæˆ‘è¿›åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒTTRLåœ¨å„ç§ä»»åŠ¡å’Œæ¨¡å‹ä¸Šçš„æ€§èƒ½æŒç»­æå‡ã€‚ç‰¹åˆ«æ˜¯ï¼Œåœ¨AIME 2024æ¯”èµ›ä¸­ï¼ŒTTRLä½¿Qwen-2.5-Math-7Bçš„pass@1æ€§èƒ½æé«˜äº†çº¦211%ï¼Œä¸”ä»…ä½¿ç”¨æ— æ ‡ç­¾çš„æµ‹è¯•æ•°æ®ã€‚å°½ç®¡TTRLä»…å—maj@næŒ‡æ ‡çš„ç›‘ç£ï¼Œä½†å…¶æ€§èƒ½å§‹ç»ˆè¶…è¿‡åˆå§‹æ¨¡å‹çš„maj@nä¸Šé™ï¼Œå¹¶æ¥è¿‘ç›´æ¥åœ¨å¸¦æœ‰çœŸå®æ ‡ç­¾çš„æµ‹è¯•æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè®­ç»ƒï¼Œä¸”æ— éœ€æ•°æ®æ ‡ç­¾ã€‚</li>
<li>é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºåœ¨ç¼ºä¹çœŸå®ä¿¡æ¯çš„æƒ…å†µä¸‹è¿›è¡Œå¥–åŠ±ä¼°ç®—ã€‚</li>
<li>æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰çš„å¸¸è§å®è·µå¦‚å¤šæ•°æŠ•ç¥¨åœ¨RLè®­ç»ƒä¸­è¡¨ç°æœ‰æ•ˆã€‚</li>
<li>å¼•å…¥Test-Time Reinforcement Learningï¼ˆTTRLï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„å…ˆéªŒçŸ¥è¯†å®ç°LLMçš„è‡ªæˆ‘è¿›åŒ–ã€‚</li>
<li>TTRLåœ¨å„ç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½æŒç»­æå‡ï¼Œä¸”åœ¨ç‰¹å®šæ¯”èµ›ä¸­æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>TTRLçš„æ€§èƒ½è¶…è¶Šåˆå§‹æ¨¡å‹çš„æŒ‡æ ‡ï¼Œå¹¶æ¥è¿‘ä½¿ç”¨çœŸå®æ ‡ç­¾æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>TTRLçš„æ½œåœ¨åº”ç”¨èŒƒå›´å¹¿æ³›ï¼Œå¯åº”ç”¨äºæ›´å¹¿æ³›çš„ä»»åŠ¡å’Œé¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16084">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-442a16b924283ccbcc6ffe9c7f5d2182.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a0866297a9a1a714a997857dcaeaca7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-faf500453f74bac763af5e8c2b094e98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68fbde7f77107f409fa781b1f59abc3f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ShiftySpeech-A-Large-Scale-Synthetic-Speech-Dataset-with-Distribution-Shifts"><a href="#ShiftySpeech-A-Large-Scale-Synthetic-Speech-Dataset-with-Distribution-Shifts" class="headerlink" title="ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution   Shifts"></a>ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution   Shifts</h2><p><strong>Authors:Ashi Garg, Zexin Cai, Lin Zhang, Henry Li Xinyuan, Leibny Paola GarcÃ­a-Perera, Kevin Duh, Sanjeev Khudanpur, Matthew Wiesner, Nicholas Andrews</strong></p>
<p>The problem of synthetic speech detection has enjoyed considerable attention, with recent methods achieving low error rates across several established benchmarks. However, to what extent can low error rates on academic benchmarks translate to more realistic conditions? In practice, while the training set is fixed at one point in time, test-time conditions may exhibit distribution shifts relative to the training conditions, such as changes in speaker characteristics, emotional expressiveness, language and acoustic conditions, and the emergence of novel synthesis methods. Although some existing datasets target subsets of these distribution shifts, systematic analysis remains difficult due to inconsistencies between source data and synthesis systems across datasets. This difficulty is further exacerbated by the rapid development of new text-to-speech (TTS) and vocoder systems, which continually expand the diversity of synthetic speech. To enable systematic benchmarking of model performance under distribution shifts, we introduce ShiftySpeech, a large-scale benchmark comprising over 3,000 hours of synthetic speech across 7 source domains, 6 TTS systems, 12 vocoders, and 3 languages. ShiftySpeech is specifically designed to evaluate model generalization under controlled distribution shifts while ensuring broad coverage of modern synthetic speech generation techniques. It fills a key gap in current benchmarks by supporting fine-grained, controlled analysis of generalization robustness. All tested distribution shifts significantly degrade detection performance of state-of-the-art detection approaches based on self-supervised features. Overall, our findings suggest that reliance on synthetic speech detection methods in production environments should be carefully evaluated based on anticipated distribution shifts. </p>
<blockquote>
<p>è¯­éŸ³åˆæˆæ£€æµ‹é—®é¢˜å·²å¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œæœ€è¿‘çš„æ–¹æ³•åœ¨å¤šä¸ªæ—¢å®šåŸºå‡†æµ‹è¯•ä¸Šçš„é”™è¯¯ç‡è¾ƒä½ã€‚ç„¶è€Œï¼Œä½é”™è¯¯ç‡åœ¨å­¦æœ¯åŸºå‡†ä¸Šèƒ½åœ¨å¤šå¤§ç¨‹åº¦ä¸Šè½¬åŒ–ä¸ºæ›´ç°å®çš„æ¡ä»¶ï¼Ÿå®é™…ä¸Šï¼Œè™½ç„¶è®­ç»ƒé›†æ˜¯å›ºå®šåœ¨ä¸€ä¸ªæ—¶é—´ç‚¹çš„ï¼Œä½†æµ‹è¯•æ—¶çš„æ¡ä»¶å¯èƒ½ä¼šç›¸å¯¹äºè®­ç»ƒæ¡ä»¶å‡ºç°åˆ†å¸ƒåç§»ï¼Œä¾‹å¦‚å‘è¨€äººç‰¹å¾ã€æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è¨€å’Œå£°å­¦æ¡ä»¶çš„æ”¹å˜ï¼Œä»¥åŠæ–°å‹åˆæˆæ–¹æ³•çš„å‡ºç°ã€‚è™½ç„¶ä¸€äº›ç°æœ‰æ•°æ®é›†é’ˆå¯¹è¿™äº›åˆ†å¸ƒåç§»çš„å­é›†ï¼Œä½†ç”±äºæ•°æ®é›†ä¹‹é—´æºæ•°æ®å’Œåˆæˆç³»ç»Ÿçš„ä¸ä¸€è‡´æ€§ï¼Œç³»ç»Ÿåˆ†æä»ç„¶å›°éš¾ã€‚è¿™ä¸€å›°éš¾å› æ–°å‹æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å’ŒæŒ¯åŠ¨ç³»ç»Ÿçš„é«˜é€Ÿå‘å±•è€Œè¿›ä¸€æ­¥åŠ å‰§ï¼Œå®ƒä»¬ä¸æ–­æ‰©å¤§äº†åˆæˆè¯­éŸ³çš„å¤šæ ·æ€§ã€‚ä¸ºäº†èƒ½å¤Ÿå¯¹æ¨¡å‹åœ¨åˆ†å¸ƒåç§»ä¸‹çš„æ€§èƒ½è¿›è¡Œç³»ç»Ÿçš„åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬å¼•å…¥äº†ShiftySpeechï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬è¶…è¿‡3000å°æ—¶çš„åˆæˆè¯­éŸ³ï¼Œæ¶µç›–7ä¸ªæºåŸŸã€6ä¸ªTTSç³»ç»Ÿã€12ä¸ªæŒ¯åŠ¨å™¨å’Œ3ç§è¯­è¨€ã€‚ShiftySpeechä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å—æ§åˆ†å¸ƒåç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ç¡®ä¿å¹¿æ³›è¦†ç›–ç°ä»£åˆæˆè¯­éŸ³ç”ŸæˆæŠ€æœ¯ã€‚å®ƒå¡«è¡¥äº†å½“å‰åŸºå‡†æµ‹è¯•çš„ç©ºç™½ï¼Œæ”¯æŒç²¾ç»†çš„ã€å—æ§çš„æ³›åŒ–ç¨³å¥æ€§åˆ†æã€‚æ‰€æœ‰æµ‹è¯•çš„åˆ†å¸ƒåç§»éƒ½ä¼šæ˜¾è‘—é™çº§åŸºäºè‡ªæˆ‘ç›‘ç£ç‰¹å¾çš„æœ€æ–°æ£€æµ‹æ–¹æ³•çš„æ£€æµ‹æ€§èƒ½ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¾èµ–åˆæˆè¯­éŸ³æ£€æµ‹æ–¹æ³•åº”è°¨æ…è¯„ä¼°é¢„æœŸçš„åˆ†å¸ƒåç§»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05674v4">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿™ç¯‡è®ºæ–‡å…³æ³¨äº†åˆæˆè¯­éŸ³æ£€æµ‹çš„é—®é¢˜ï¼Œå°½ç®¡åœ¨å‡ ä¸ªæ—¢å®šçš„åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†è¾ƒä½çš„è¯¯å·®ç‡ï¼Œä½†åœ¨æ›´ç°å®çš„æ¡ä»¶ä¸‹ï¼Œè¿™äº›ä½è¯¯å·®ç‡èƒ½å¦å¾—åˆ°å®é™…åº”ç”¨ä»å­˜åœ¨ç–‘é—®ã€‚è®­ç»ƒé›†æ˜¯å›ºå®šä¸å˜çš„ï¼Œä½†æµ‹è¯•æ—¶çš„æ¡ä»¶å¯èƒ½ä¸è®­ç»ƒæ¡ä»¶å­˜åœ¨åˆ†å¸ƒåç§»ï¼Œå¦‚è¯´è¯äººç‰¹å¾ã€æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è¨€å’Œå£°å­¦æ¡ä»¶çš„æ”¹å˜ï¼Œä»¥åŠæ–°åˆæˆæ–¹æ³•çš„å‡ºç°ã€‚ä¸ºäº†å¯¹æ¨¡å‹åœ¨åˆ†å¸ƒåç§»ä¸‹çš„æ€§èƒ½è¿›è¡Œç³»ç»Ÿæ€§è¯„ä¼°ï¼Œå¼•å…¥äº†ShiftySpeechåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«è¶…è¿‡3000å°æ—¶çš„åˆæˆè¯­éŸ³æ•°æ®ï¼Œæ¶µç›–7ä¸ªæºåŸŸã€6ä¸ªæ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿã€12ä¸ªvocoderå’Œ3ç§è¯­è¨€ã€‚ShiftySpeechä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å—æ§åˆ†å¸ƒåç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ç¡®ä¿è¦†ç›–ç°ä»£åˆæˆè¯­éŸ³ç”ŸæˆæŠ€æœ¯çš„å¹¿æ³›èŒƒå›´ã€‚å®ƒå¡«è¡¥äº†å½“å‰åŸºå‡†æµ‹è¯•çš„ç©ºç™½ï¼Œæ”¯æŒå¯¹æ³›åŒ–ç¨³å¥æ€§çš„ç²¾ç»†æ§åˆ¶åˆ†æã€‚æ‰€æœ‰æµ‹è¯•çš„åˆ†å¸ƒåç§»éƒ½ä¼šæ˜¾è‘—åœ°é™ä½åŸºäºè‡ªç›‘ç£ç‰¹å¾çš„æœ€æ–°æ£€æµ‹æ–¹æ³•çš„æ€§èƒ½ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨é¢„æœŸå­˜åœ¨åˆ†å¸ƒåç§»çš„ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨åˆæˆè¯­éŸ³æ£€æµ‹æ–¹æ³•åº”è°¨æ…è¯„ä¼°ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åˆæˆè¯­éŸ³æ£€æµ‹é¢ä¸´ä»å­¦æœ¯åŸºå‡†æµ‹è¯•åˆ°ç°å®æ¡ä»¶çš„åº”ç”¨è½¬åŒ–é—®é¢˜ã€‚</li>
<li>è®­ç»ƒé›†å›ºå®šï¼Œä½†æµ‹è¯•æ¡ä»¶å¯èƒ½å­˜åœ¨ä¸è®­ç»ƒæ¡ä»¶çš„åˆ†å¸ƒåç§»ã€‚</li>
<li>åˆ†å¸ƒåç§»åŒ…æ‹¬è¯´è¯äººç‰¹å¾ã€æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è¨€å’Œå£°å­¦æ¡ä»¶çš„æ”¹å˜ï¼Œä»¥åŠæ–°åˆæˆæ–¹æ³•çš„å‡ºç°ã€‚</li>
<li>ç°æœ‰æ•°æ®é›†åªé’ˆå¯¹åˆ†å¸ƒåç§»çš„éƒ¨åˆ†æ–¹é¢ï¼Œç¼ºä¹ç³»ç»Ÿæ€§åˆ†æã€‚</li>
<li>ä»‹ç»äº†ShiftySpeechåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å¤§è§„æ¨¡åˆæˆè¯­éŸ³æ•°æ®ï¼Œæ”¯æŒç²¾ç»†æ§åˆ¶çš„æ³›åŒ–åˆ†æã€‚</li>
<li>æµ‹è¯•åˆ†å¸ƒåç§»æ˜¾è‘—é™ä½äº†æœ€æ–°æ£€æµ‹æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
<li>åœ¨é¢„æœŸå­˜åœ¨åˆ†å¸ƒåç§»çš„ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨åˆæˆè¯­éŸ³æ£€æµ‹æ–¹æ³•åº”è°¨æ…è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05674">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-de536c413b6b40a76d35f2a5eefd33ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e9e34e0d166ffd0138fe166b50f0417.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18c3fbbbeafbe7e17d230de015d237bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b8517e4b05ea16925a053da4da9d013.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c7becb3bbe670bed6ec7e323c80835e4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6de38e73018950a33fb698c0a4840a47.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-30846d0b2275b7b64c1b9f00ab81295d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SmoothCache-A-Universal-Inference-Acceleration-Technique-for-Diffusion-Transformers"><a href="#SmoothCache-A-Universal-Inference-Acceleration-Technique-for-Diffusion-Transformers" class="headerlink" title="SmoothCache: A Universal Inference Acceleration Technique for Diffusion   Transformers"></a>SmoothCache: A Universal Inference Acceleration Technique for Diffusion   Transformers</h2><p><strong>Authors:Joseph Liu, Joshua Geddes, Ziyu Guo, Haomiao Jiang, Mahesh Kumar Nandwana</strong></p>
<p>Diffusion Transformers (DiT) have emerged as powerful generative models for various tasks, including image, video, and speech synthesis. However, their inference process remains computationally expensive due to the repeated evaluation of resource-intensive attention and feed-forward modules. To address this, we introduce SmoothCache, a model-agnostic inference acceleration technique for DiT architectures. SmoothCache leverages the observed high similarity between layer outputs across adjacent diffusion timesteps. By analyzing layer-wise representation errors from a small calibration set, SmoothCache adaptively caches and reuses key features during inference. Our experiments demonstrate that SmoothCache achieves 8% to 71% speed up while maintaining or even improving generation quality across diverse modalities. We showcase its effectiveness on DiT-XL for image generation, Open-Sora for text-to-video, and Stable Audio Open for text-to-audio, highlighting its potential to enable real-time applications and broaden the accessibility of powerful DiT models. </p>
<blockquote>
<p>æ‰©æ•£Transformerï¼ˆDiTï¼‰å·²ç»æˆä¸ºåŒ…æ‹¬å›¾åƒã€è§†é¢‘å’Œè¯­éŸ³åˆæˆåœ¨å†…çš„å„ç§ä»»åŠ¡çš„å¼ºå¤§ç”Ÿæˆæ¨¡å‹ã€‚ç„¶è€Œï¼Œç”±äºéœ€è¦é‡å¤è¯„ä¼°èµ„æºå¯†é›†å‹çš„æ³¨æ„åŠ›å’Œå‰é¦ˆæ¨¡å—ï¼Œå®ƒä»¬çš„æ¨ç†è¿‡ç¨‹è®¡ç®—æˆæœ¬ä»ç„¶å¾ˆé«˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SmoothCacheï¼Œè¿™æ˜¯ä¸€ç§é€‚ç”¨äºDiTæ¶æ„çš„æ¨¡å‹æ— å…³æ¨ç†åŠ é€ŸæŠ€æœ¯ã€‚SmoothCacheåˆ©ç”¨ç›¸é‚»æ‰©æ•£æ—¶é—´æ­¥é•¿ä¹‹é—´å±‚è¾“å‡ºçš„é«˜ç›¸ä¼¼æ€§ã€‚é€šè¿‡åˆ†ææ¥è‡ªå°å‹æ ¡å‡†é›†çš„é€å±‚è¡¨ç¤ºè¯¯å·®ï¼ŒSmoothCacheåœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°ç¼“å­˜å’Œé‡å¤ä½¿ç”¨å…³é”®ç‰¹å¾ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒSmoothCacheåœ¨ä¿æŒæˆ–ç”šè‡³æé«˜ç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†8%åˆ°71%çš„æé€Ÿï¼Œæ¶‰åŠå¤šç§æ¨¡æ€ã€‚æˆ‘ä»¬åœ¨å›¾åƒç”Ÿæˆçš„DiT-XLã€æ–‡æœ¬åˆ°è§†é¢‘çš„Open-Soraä»¥åŠæ–‡æœ¬åˆ°éŸ³é¢‘çš„Stable Audio Openä¸Šå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†å…¶å®ç°å®æ—¶åº”ç”¨å’Œæ‰©å¤§å¼ºå¤§DiTæ¨¡å‹å¯åŠæ€§çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.10510v2">PDF</a> Code can be found at <a target="_blank" rel="noopener" href="https://github.com/Roblox/SmoothCache">https://github.com/Roblox/SmoothCache</a>. Accepted   at CVPR eLVM workshop</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰å·²ä½œä¸ºå›¾åƒã€è§†é¢‘å’Œè¯­éŸ³åˆæˆç­‰ä»»åŠ¡çš„å¼ºå¤§ç”Ÿæˆæ¨¡å‹å‡ºç°ã€‚ç„¶è€Œï¼Œç”±äºå…¶é‡å¤çš„æ³¨æ„åŠ›è¯„ä¼°å’Œæ­£å‘ä¼ æ’­æ¨¡å—çš„è®¡ç®—èµ„æºå¯†é›†æ€§ï¼Œå…¶æ¨ç†è¿‡ç¨‹è®¡ç®—æˆæœ¬ä»ç„¶å¾ˆé«˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†SmoothCacheï¼Œè¿™æ˜¯ä¸€ç§é€‚ç”¨äºDiTæ¶æ„çš„æ¨¡å‹æ— å…³æ¨ç†åŠ é€ŸæŠ€æœ¯ã€‚SmoothCacheåˆ©ç”¨ç›¸é‚»æ‰©æ•£æ—¶é—´æ­¥é•¿ä¹‹é—´å±‚è¾“å‡ºä¹‹é—´çš„é«˜ç›¸ä¼¼æ€§ã€‚é€šè¿‡åˆ†ææ¥è‡ªå°æ ¡å‡†é›†çš„å±‚è¡¨ç¤ºè¯¯å·®ï¼ŒSmoothCacheè‡ªé€‚åº”åœ°ç¼“å­˜å’Œé‡ç”¨å…³é”®ç‰¹å¾æ¥è¿›è¡Œæ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼ŒSmoothCacheåœ¨ä¿æŒæˆ–ç”šè‡³æé«˜ç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†8%è‡³71%çš„æé€Ÿã€‚æˆ‘ä»¬åœ¨DiT-XLå›¾åƒç”Ÿæˆã€Open-Soraæ–‡æœ¬åˆ°è§†é¢‘ä»¥åŠStable Audio Openæ–‡æœ¬åˆ°éŸ³é¢‘çš„åº”ç”¨ä¸­å±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ï¼Œçªæ˜¾å…¶å®ç°å®æ—¶åº”ç”¨å’Œæ‰©å¤§å¼ºå¤§DiTæ¨¡å‹å¯åŠæ€§çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰æ˜¯å›¾åƒã€è§†é¢‘å’Œè¯­éŸ³åˆæˆç­‰é¢†åŸŸçš„å¼ºå¤§ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç”±äºèµ„æºå¯†é›†å‹æ¨¡å—çš„é‡å¤è¯„ä¼°ï¼ŒDiTçš„è®¡ç®—æˆæœ¬ä»ç„¶è¾ƒé«˜ã€‚</li>
<li>SmoothCacheæ˜¯ä¸€ç§é€‚ç”¨äºDiTæ¶æ„çš„æ¨¡å‹æ— å…³æ¨ç†åŠ é€ŸæŠ€æœ¯ã€‚</li>
<li>SmoothCacheåˆ©ç”¨ç›¸é‚»æ‰©æ•£æ—¶é—´æ­¥é•¿é—´å±‚è¾“å‡ºçš„é«˜ç›¸ä¼¼æ€§ã€‚</li>
<li>é€šè¿‡åˆ†ææ¥è‡ªå°æ ¡å‡†é›†çš„å±‚è¡¨ç¤ºè¯¯å·®ï¼ŒSmoothCacheèƒ½å¤Ÿè‡ªé€‚åº”åœ°ç¼“å­˜å’Œé‡ç”¨å…³é”®ç‰¹å¾ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼ŒSmoothCacheå®ç°äº†æ˜¾è‘—çš„æ¨ç†é€Ÿåº¦æå‡ï¼ŒåŒæ—¶ä¿æŒæˆ–æé«˜äº†ç”Ÿæˆè´¨é‡ã€‚</li>
<li>SmoothCacheåœ¨å¤šç§æ¨¡æ€ï¼ˆå¦‚å›¾åƒç”Ÿæˆã€æ–‡æœ¬åˆ°è§†é¢‘ã€æ–‡æœ¬åˆ°éŸ³é¢‘ï¼‰ä¸­å‡è¡¨ç°å‡ºæœ‰æ•ˆæ€§ï¼Œå…·æœ‰å®ç°å®æ—¶åº”ç”¨å’Œæ‰©å¤§DiTæ¨¡å‹æ½œåŠ›çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.10510">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7350587bef2e6f4e436c3513c37f4c8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34a0fd48013b551412d2aba8ff901f76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-08be4be0b33adc1f48adf8ad93acd387.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c79fd6961bc94b4811a79e02191cf1b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ade5bccd213ed646382cb5515626815.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c1e854fd7e98804a9b6705d4c9f18c67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9871a92156aa1b646f2dbb597eb1c7f9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="On-the-contributions-of-extragalactic-CO-emission-lines-to-ground-based-CMB-observations"><a href="#On-the-contributions-of-extragalactic-CO-emission-lines-to-ground-based-CMB-observations" class="headerlink" title="On the contributions of extragalactic CO emission lines to ground-based   CMB observations"></a>On the contributions of extragalactic CO emission lines to ground-based   CMB observations</h2><p><strong>Authors:Nickolas Kokron, JosÃ© Luis Bernal, Jo Dunkley</strong></p>
<p>We investigate the potential of CO rotational lines at redshifts $z\sim 0-6$ being an appreciable source of extragalactic foreground anisotropies in the cosmic microwave background. Motivated by previous investigations, we specifically focus on the frequency bands and small scales probed by ground-based surveys. Using an empirical parameterization for the relation between the infrared luminosity of galaxies and their CO line luminosity, conditioned on sub-mm observations of CO luminosity functions from $J&#x3D;1$ to $J&#x3D;7$ at $\nu &#x3D; {100,250}$ GHz, we explore how uncertainty in the CO luminosity function translates into uncertainty in the signature of CO emission in the CMB. We find that at $\ell &#x3D; 3000$ the amplitude of the CO cross-correlation with the CIB could be detectable in an ACT-like experiment with 90, 150 and 220 GHz bands, even in the scenarios with the lowest amplitude consistent with sub-mm data. We also investigate, for the first time, the amplitude of the CO$\times$CIB correlation between different frequency bands and find that our model predicts that this signal could be the second-largest extragalactic foreground at certain wavelengths, behind the CIB cross-frequency spectrum. This implies current observations can potentially be used to constrain the bright end of CO luminosity functions, which are difficult to probe with current sub-mm telescopes due to the small volumes they survey. Our findings corroborate past results and have significant implications in template-based searches for CMB secondaries, such as the kinetic Sunyaev Zelâ€™dovich effect, using the frequency-dependent high-$\ell$ TT power spectrum. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†åœ¨çº¢ç§»$z\sim 0-6$çš„COè½¬åŠ¨çº¿ä½œä¸ºå®‡å®™å¾®æ³¢èƒŒæ™¯ä¸­å¯è§‚æµ‹çš„æ˜Ÿç³»å‰æ™¯å„å‘å¼‚æ€§æ¥æºçš„æ½œåŠ›ã€‚å—ä¹‹å‰ç ”ç©¶çš„å¯å‘ï¼Œæˆ‘ä»¬ç‰¹åˆ«å…³æ³¨åœ°é¢å‹˜æµ‹æ‰€æ¢æµ‹çš„é¢‘ç‡æ³¢æ®µå’Œå°å°ºåº¦èŒƒå›´ã€‚æˆ‘ä»¬åˆ©ç”¨æ˜Ÿç³»çº¢å¤–å…‰åº¦å’Œå…¶COçº¿å…‰åº¦ä¹‹é—´çš„ç»éªŒå‚æ•°åŒ–å…³ç³»ï¼ŒåŸºäºå¯¹$\nu &#x3D; {100, 250}$ GHzé¢‘ç‡ä¸‹$J&#x3D;1$è‡³$J&#x3D;7$çš„äºšæ¯«ç±³COå…‰åº¦å‡½æ•°çš„è§‚æµ‹ï¼Œæ¢è®¨äº†COå…‰åº¦å‡½æ•°çš„ä¸ç¡®å®šæ€§å¦‚ä½•è½¬åŒ–ä¸ºå¯¹CMBä¸­COå‘å°„ç‰¹å¾çš„ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å‘ç°ï¼Œåœ¨$\ell &#x3D; 3000$æ—¶ï¼ŒCOä¸CIBçš„äº’ç›¸å…³å¹…åº¦å¯èƒ½åœ¨ACTç±»ä¼¼çš„å®éªŒä¸­æ£€æµ‹åˆ°ï¼Œè¯¥å®éªŒå…·æœ‰90ã€150å’Œ220 GHzçš„æ³¢æ®µï¼Œå³ä½¿åœ¨ä¸äºšæ¯«ç±³æ•°æ®ä¸€è‡´çš„æœ€ä½å¹…åº¦æƒ…æ™¯ä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬è¿˜é¦–æ¬¡è°ƒæŸ¥äº†ä¸åŒé¢‘ç‡æ³¢æ®µä¹‹é—´COÃ—CIBå…³è”çš„å¹…åº¦ï¼Œå‘ç°æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹ï¼Œåœ¨æŸäº›æ³¢é•¿ä¸Šï¼Œè¿™ä¸€ä¿¡å·å¯èƒ½æ˜¯ä»…æ¬¡äºè·¨é¢‘CIBè°±çš„ç¬¬äºŒå¤§å¤–æ˜Ÿç³»å‰æ™¯ã€‚è¿™æ„å‘³ç€å½“å‰è§‚æµ‹ç»“æœå¯ç”¨äºçº¦æŸæ˜äº®çš„COå…‰åº¦å‡½æ•°æœ«ç«¯ï¼Œç”±äºå½“å‰äºšæ¯«ç±³æœ›è¿œé•œæ‰€è°ƒæŸ¥çš„ä½“ç§¯è¾ƒå°ï¼Œè¿™ä½¿å¾—è¿™ä¸€æœ«ç«¯éš¾ä»¥æ¢æµ‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¯å®äº†ä»¥å¾€çš„ç»“æœï¼Œå¹¶åœ¨åŸºäºæ¨¡æ¿çš„å¯»æ‰¾å®‡å®™å¾®æ³¢èƒŒæ™¯æ¬¡è¦æˆåˆ†ï¼ˆå¦‚åŠ¨æ€Sunyaev Zelâ€™dovichæ•ˆåº”ï¼‰çš„ç ”ç©¶ä¸­å…·æœ‰é‡è¦å«ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨é¢‘ç‡ä¾èµ–çš„é«˜$\ell$ TTåŠŸç‡è°±åˆ†æä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.20369v2">PDF</a> 14+3 pages, 8+2 figures. Reflects published version, with an   additional post-publication revision which corrects a normalization error in   the original work. Results have changed quantitatively</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†COè½¬åŠ¨çº¿åœ¨çº¢ç§»$z\sim 0-6$èŒƒå›´å†…ä½œä¸ºå®‡å®™å¾®æ³¢èƒŒæ™¯ä¸­å¯è§‚æµ‹çš„å®‡å®™å¤–å‰æ™¯å„å‘å¼‚æ€§æ¥æºçš„æ½œåŠ›ã€‚åŸºäºå…ˆå‰çš„è°ƒæŸ¥ï¼Œæˆ‘ä»¬ç‰¹åˆ«å…³æ³¨åœ°é¢è°ƒæŸ¥æ‰€æ¢æµ‹çš„é¢‘ç‡æ³¢æ®µå’Œå°å°ºåº¦èŒƒå›´ã€‚åˆ©ç”¨æ˜Ÿç³»çº¢å¤–å…‰åº¦ä¸å…¶COçº¿å…‰åº¦ä¹‹é—´çš„ç»éªŒå‚æ•°åŒ–å…³ç³»ï¼Œå¹¶ç»“åˆäºšæ¯«ç±³æ³¢æ®µçš„COå…‰åº¦å‡½æ•°è§‚æµ‹æ•°æ®ï¼Œæˆ‘ä»¬ç ”ç©¶äº†COå…‰åº¦å‡½æ•°çš„ä¸ç¡®å®šæ€§å¦‚ä½•è½¬åŒ–ä¸ºå¯¹CMBä¸­COå‘å°„ç‰¹å¾çš„ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å‘ç°ï¼Œåœ¨$\ell &#x3D; 3000$æ—¶ï¼ŒCOä¸CIBçš„äº’ç›¸å…³å¯èƒ½åœ¨ACTç±»ä¼¼å®éªŒä¸­çš„90ã€150å’Œ220 GHzæ³¢æ®µå†…æ£€æµ‹åˆ°ï¼Œå³ä½¿åœ¨ä¸äºšæ¯«ç±³æ•°æ®ä¸€è‡´çš„æœ€ä½æŒ¯å¹…æƒ…æ™¯ä¸‹ã€‚æˆ‘ä»¬è¿˜é¦–æ¬¡æ¢ç©¶äº†ä¸åŒé¢‘ç‡æ³¢æ®µé—´COÃ—CIBå…³è”çš„æŒ¯å¹…ï¼Œæˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹ï¼Œåœ¨æŸäº›æ³¢é•¿ä¸‹ï¼Œè¿™ä¸€ä¿¡å·å¯èƒ½æ˜¯ä»…æ¬¡äºå®‡å®™çº¢å¤–èƒŒæ™¯è·¨é¢‘è°±çš„ç¬¬äºŒå¤§å¤–å®‡å®™å‰æ™¯ä¿¡å·ã€‚è¿™æ„å‘³ç€å½“å‰è§‚æµ‹ç»“æœå¯èƒ½ç”¨äºçº¦æŸCOå…‰åº¦å‡½æ•°çš„æ˜äº®ç«¯ï¼Œç”±äºå½“å‰äºšæ¯«ç±³æœ›è¿œé•œæ‰€è°ƒæŸ¥çš„æ ·æœ¬é‡è¾ƒå°ï¼Œéš¾ä»¥æ¢æµ‹è¿™éƒ¨åˆ†ä¿¡æ¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœéªŒè¯äº†è¿‡å»çš„å‘ç°ï¼Œå¹¶å¯¹åŸºäºæ¨¡æ¿çš„CMBæ¬¡çº§æ•ˆåº”æœç´¢ï¼ˆå¦‚åŠ¨å­¦Sunyaev Zelâ€™dovichæ•ˆåº”ï¼‰å…·æœ‰é‡è¦å½±å“ï¼Œå¯é€šè¿‡é¢‘ç‡ä¾èµ–çš„é«˜$\ell$ TTåŠŸç‡è°±è¿›è¡Œç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>COè½¬åŠ¨çº¿åœ¨çº¢ç§»$z\sim 0-6$èŒƒå›´å¯æˆä¸ºå®‡å®™å¾®æ³¢èƒŒæ™¯ä¸­é‡è¦çš„å‰æ™¯å„å‘å¼‚æ€§æ¥æºã€‚</li>
<li>COå…‰åº¦å‡½æ•°çš„ä¸ç¡®å®šæ€§ä¼šå½±å“å…¶åœ¨å®‡å®™å¾®æ³¢èƒŒæ™¯ä¸­çš„ç‰¹å¾è¡¨ç°ã€‚</li>
<li>åœ¨ä¸€å®šæ¡ä»¶ä¸‹ï¼ŒCOä¸å®‡å®™çº¢å¤–èƒŒæ™¯çš„äº’ç›¸å…³å¯èƒ½æ˜¾è‘—ï¼Œæˆä¸ºç¬¬äºŒå¤§å¤–å®‡å®™å‰æ™¯ä¿¡å·ã€‚</li>
<li>å½“å‰è§‚æµ‹å¯ç”¨äºçº¦æŸCOå…‰åº¦å‡½æ•°çš„æ˜äº®ç«¯ï¼Œè¿™éƒ¨åˆ†ä¿¡æ¯ç”±äºäºšæ¯«ç±³æœ›è¿œé•œæ ·æœ¬é‡å°è€Œéš¾ä»¥é€šè¿‡ç°æœ‰æ‰‹æ®µæ¢æµ‹ã€‚</li>
<li>ç ”ç©¶ç»“æœéªŒè¯äº†è¿‡å»çš„å‘ç°ï¼Œå¯¹åŸºäºæ¨¡æ¿çš„æ¬¡çº§æ•ˆåº”æœç´¢æœ‰é‡è¦å½±å“ã€‚</li>
<li>é€šè¿‡é¢‘ç‡ä¾èµ–çš„é«˜$\ell$ TTåŠŸç‡è°±ï¼Œå¯ä»¥æ›´å¥½åœ°ç ”ç©¶å®‡å®™å¾®æ³¢èƒŒæ™¯çš„æ¬¡çº§æ•ˆåº”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.20369">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-55ee6fb397e63f980ebf8ba581996706.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dbfc04f1973669350bf58e4a0f10f2a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-542e9fe6a9063844f673c6a870a4b5bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b69369481cd36ed39f8b26770c4eaf93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8c5f86fa0020c4135309a70713d9564.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-24/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-24/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-24/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-07875fe1c57e6f78534591239d408f54.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-24  Meta-PerSER Few-Shot Listener Personalized Speech Emotion Recognition   via Meta-learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-4686fad44d4ed9b29375e021d84df535.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-24  Tracking the Flight Exploring a Computational Framework for Analyzing   Escape Responses in Plains Zebra (Equus quagga)
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19710k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
