<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-24  SHaDe Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane   Deformation and Latent Diffusion">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-5d2078e5afc415869e09090a1b2beb05.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    60 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-24-æ›´æ–°"><a href="#2025-05-24-æ›´æ–°" class="headerlink" title="2025-05-24 æ›´æ–°"></a>2025-05-24 æ›´æ–°</h1><h2 id="SHaDe-Compact-and-Consistent-Dynamic-3D-Reconstruction-via-Tri-Plane-Deformation-and-Latent-Diffusion"><a href="#SHaDe-Compact-and-Consistent-Dynamic-3D-Reconstruction-via-Tri-Plane-Deformation-and-Latent-Diffusion" class="headerlink" title="SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane   Deformation and Latent Diffusion"></a>SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane   Deformation and Latent Diffusion</h2><p><strong>Authors:Asrar Alruwayqi</strong></p>
<p>We present a novel framework for dynamic 3D scene reconstruction that integrates three key components: an explicit tri-plane deformation field, a view-conditioned canonical radiance field with spherical harmonics (SH) attention, and a temporally-aware latent diffusion prior. Our method encodes 4D scenes using three orthogonal 2D feature planes that evolve over time, enabling efficient and compact spatiotemporal representation. These features are explicitly warped into a canonical space via a deformation offset field, eliminating the need for MLP-based motion modeling.   In canonical space, we replace traditional MLP decoders with a structured SH-based rendering head that synthesizes view-dependent color via attention over learned frequency bands improving both interpretability and rendering efficiency. To further enhance fidelity and temporal consistency, we introduce a transformer-guided latent diffusion module that refines the tri-plane and deformation features in a compressed latent space. This generative module denoises scene representations under ambiguous or out-of-distribution (OOD) motion, improving generalization.   Our model is trained in two stages: the diffusion module is first pre-trained independently, and then fine-tuned jointly with the full pipeline using a combination of image reconstruction, diffusion denoising, and temporal consistency losses. We demonstrate state-of-the-art results on synthetic benchmarks, surpassing recent methods such as HexPlane and 4D Gaussian Splatting in visual quality, temporal coherence, and robustness to sparse-view dynamic inputs. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€3Dåœºæ™¯é‡å»ºæ¡†æ¶ï¼Œå®ƒé›†æˆäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæ˜¾å¼ä¸‰å¹³é¢å˜å½¢åœºã€å¸¦æœ‰çƒé¢è°æ³¢ï¼ˆSHï¼‰æ³¨æ„åŠ›çš„è§†åœºæ¡ä»¶è§„èŒƒè¾å°„åœºä»¥åŠæ—¶é—´æ„ŸçŸ¥æ½œåœ¨æ‰©æ•£å…ˆéªŒã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨éšæ—¶é—´å˜åŒ–çš„ä¸‰ä¸ªæ­£äº¤2Dç‰¹å¾å¹³é¢å¯¹4Dåœºæ™¯è¿›è¡Œç¼–ç ï¼Œä»è€Œå®ç°é«˜æ•ˆä¸”ç´§å‡‘çš„æ—¶ç©ºè¡¨ç¤ºã€‚è¿™äº›ç‰¹å¾é€šè¿‡å˜å½¢åç§»åœºæ˜ç¡®å˜å½¢åˆ°è§„èŒƒç©ºé—´ï¼Œæ— éœ€åŸºäºMLPçš„è¿åŠ¨å»ºæ¨¡ã€‚åœ¨è§„èŒƒç©ºé—´ä¸­ï¼Œæˆ‘ä»¬ç”¨ç»“æ„åŒ–çš„SHåŸºäºæ¸²æŸ“å¤´æ›¿æ¢ä¼ ç»Ÿçš„MLPè§£ç å™¨ï¼Œé€šè¿‡å…³æ³¨å­¦ä¹ é¢‘ç‡æ³¢æ®µæ¥åˆæˆè§†è§‰ç›¸å…³çš„é¢œè‰²ï¼Œä»è€Œæé«˜å¯è§£é‡Šæ€§å’Œæ¸²æŸ“æ•ˆç‡ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ä¿çœŸåº¦å’Œæ—¶é—´ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå—å˜å‹å™¨å¼•å¯¼çš„æ½œåœ¨æ‰©æ•£æ¨¡å—ï¼Œè¯¥æ¨¡å—åœ¨å‹ç¼©çš„æ½œåœ¨ç©ºé—´ä¸­ç»†åŒ–äº†ä¸‰å¹³é¢å’Œå˜å½¢ç‰¹å¾ã€‚è¿™ä¸ªç”Ÿæˆæ¨¡å—å‡å°‘äº†æ¨¡ç³Šæˆ–è¶…å‡ºåˆ†å¸ƒï¼ˆOODï¼‰è¿åŠ¨ä¸‹çš„åœºæ™¯è¡¨ç¤ºå™ªå£°ï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µè¿›è¡Œè®­ç»ƒï¼šé¦–å…ˆç‹¬ç«‹åœ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å—ï¼Œç„¶åä½¿ç”¨å›¾åƒé‡å»ºã€æ‰©æ•£å»å™ªå’Œæ—¶é—´ä¸€è‡´æ€§æŸå¤±çš„ç»„åˆä¸å…¨ç®¡é“è”åˆå¾®è°ƒã€‚æˆ‘ä»¬åœ¨åˆæˆåŸºå‡†æµ‹è¯•ä¸Šå±•ç¤ºäº†å“è¶Šçš„ç»“æœï¼Œåœ¨è§†è§‰è´¨é‡ã€æ—¶é—´è¿è´¯æ€§å’Œå¯¹ç¨€ç–è§†å›¾åŠ¨æ€è¾“å…¥çš„é²æ£’æ€§æ–¹é¢è¶…è¶Šäº†æœ€è¿‘çš„HexPlaneå’Œ4Dé«˜æ–¯æ‹¼è´´ç­‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16535v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€ä¸‰ç»´åœºæ™¯é‡å»ºæ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæ˜¾å¼ä¸‰å¹³é¢å˜å½¢åœºã€åŸºäºè§†å›¾çš„å…¸å‹è¾å°„åœºä¸çƒé¢è°æ³¢ï¼ˆSHï¼‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥åŠæ—¶é—´æ„ŸçŸ¥æ½œåœ¨æ‰©æ•£å…ˆéªŒã€‚è¯¥æ–¹æ³•é‡‡ç”¨éšæ—¶é—´å˜åŒ–çš„ä¸‰æ­£äº¤äºŒç»´ç‰¹å¾å¹³é¢ç¼–ç å››ç»´åœºæ™¯ï¼Œé€šè¿‡å˜å½¢åç§»åœºå°†è¿™äº›ç‰¹å¾æ˜¾å¼åœ°å˜æ¢åˆ°å…¸å‹ç©ºé—´ï¼Œæ— éœ€ä½¿ç”¨MLPåŸºè¿åŠ¨å»ºæ¨¡ã€‚å…¸å‹ç©ºé—´ä¸­ï¼Œä½¿ç”¨ç»“æ„åŒ–SHæ¸²æŸ“å¤´åˆæˆè§†ç›¸å…³è‰²å½©ï¼Œé€šè¿‡å…³æ³¨å­¦ä¹ é¢‘ç‡å¸¦æé«˜è§£é‡Šæ€§å’Œæ¸²æŸ“æ•ˆç‡ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜ä¿çœŸåº¦å’Œæ—¶é—´ä¸€è‡´æ€§ï¼Œå¼•å…¥äº†åŸºäºå˜å‹å™¨çš„æ½œåœ¨æ‰©æ•£æ¨¡å—ï¼Œåœ¨å‹ç¼©æ½œåœ¨ç©ºé—´ä¸­ä¼˜åŒ–ä¸‰å¹³é¢å’Œå˜å½¢ç‰¹å¾ã€‚è¯¥ç”Ÿæˆæ¨¡å—åœ¨æ¨¡ç³Šæˆ–åˆ†å¸ƒå¤–ï¼ˆOODï¼‰è¿åŠ¨æƒ…å†µä¸‹é™ä½åœºæ™¯è¡¨ç¤ºçš„å™ªå£°ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ¨¡å‹åˆ†ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒï¼šé¦–å…ˆç‹¬ç«‹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å—ï¼Œç„¶åä½¿ç”¨å›¾åƒé‡å»ºã€æ‰©æ•£å»å™ªå’Œæ—¶é—´ä¸€è‡´æ€§æŸå¤±è”åˆå¾®è°ƒæ•´ä¸ªç®¡é“ã€‚åœ¨åˆæˆåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å“è¶Šï¼Œè¶…è¶ŠHexPlaneå’Œ4Dé«˜æ–¯è´´ç‰‡ç­‰æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€æ—¶é—´è¿è´¯æ€§å’Œå¯¹ç¨€ç–åŠ¨æ€è¾“å…¥é²æ£’æ€§æ–¹é¢çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°å‹åŠ¨æ€ä¸‰ç»´åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œé›†æˆäº†æ˜¾å¼ä¸‰å¹³é¢å˜å½¢åœºã€åŸºäºè§†å›¾çš„å…¸å‹è¾å°„åœºä¸SHæ³¨æ„åŠ›æœºåˆ¶ä»¥åŠæ—¶é—´æ„ŸçŸ¥æ½œåœ¨æ‰©æ•£å…ˆéªŒã€‚</li>
<li>é€šè¿‡å˜å½¢åç§»åœºå°†ç‰¹å¾æ˜¾å¼å˜æ¢åˆ°å…¸å‹ç©ºé—´ï¼Œæé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>é‡‡ç”¨ç»“æ„åŒ–SHæ¸²æŸ“å¤´åˆæˆè§†ç›¸å…³è‰²å½©ï¼Œæå‡äº†æ¸²æŸ“æ•ˆç‡å’Œè§£é‡Šæ€§ã€‚</li>
<li>å¼•å…¥åŸºäºå˜å‹å™¨çš„æ½œåœ¨æ‰©æ•£æ¨¡å—ï¼Œä¼˜åŒ–äº†åœºæ™¯è¡¨ç¤ºï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ³•ï¼Œå…ˆç‹¬ç«‹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å—ï¼Œå†è”åˆå¾®è°ƒæ•´ä¸ªç®¡é“ã€‚</li>
<li>åœ¨å›¾åƒé‡å»ºã€æ‰©æ•£å»å™ªå’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä½¿ç”¨æŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16535">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5d2078e5afc415869e09090a1b2beb05.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fd5696dd58fff4cd2fbdf20329e853a3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53ca7679e0829cfeabc3d94ab477210b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0408e7eafc56b86ef5e3e641eea9d11e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-810bd2dee7512748b03541103c339eff.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Motion-Matters-Compact-Gaussian-Streaming-for-Free-Viewpoint-Video-Reconstruction"><a href="#Motion-Matters-Compact-Gaussian-Streaming-for-Free-Viewpoint-Video-Reconstruction" class="headerlink" title="Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video   Reconstruction"></a>Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video   Reconstruction</h2><p><strong>Authors:Jiacong Chen, Qingyu Mao, Youneng Bao, Xiandong Meng, Fanyang Meng, Ronggang Wang, Yongsheng Liang</strong></p>
<p>3D Gaussian Splatting (3DGS) has emerged as a high-fidelity and efficient paradigm for online free-viewpoint video (FVV) reconstruction, offering viewers rapid responsiveness and immersive experiences. However, existing online methods face challenge in prohibitive storage requirements primarily due to point-wise modeling that fails to exploit the motion properties. To address this limitation, we propose a novel Compact Gaussian Streaming (ComGS) framework, leveraging the locality and consistency of motion in dynamic scene, that models object-consistent Gaussian point motion through keypoint-driven motion representation. By transmitting only the keypoint attributes, this framework provides a more storage-efficient solution. Specifically, we first identify a sparse set of motion-sensitive keypoints localized within motion regions using a viewspace gradient difference strategy. Equipped with these keypoints, we propose an adaptive motion-driven mechanism that predicts a spatial influence field for propagating keypoint motion to neighboring Gaussian points with similar motion. Moreover, ComGS adopts an error-aware correction strategy for key frame reconstruction that selectively refines erroneous regions and mitigates error accumulation without unnecessary overhead. Overall, ComGS achieves a remarkable storage reduction of over 159 X compared to 3DGStream and 14 X compared to the SOTA method QUEEN, while maintaining competitive visual fidelity and rendering speed. Our code will be released. </p>
<blockquote>
<p>3Dé«˜æ–¯æ˜ å°„ï¼ˆ3DGSï¼‰å·²ç»æˆä¸ºä¸€ç§ç”¨äºåœ¨çº¿è‡ªç”±è§†ç‚¹è§†é¢‘ï¼ˆFVVï¼‰é‡å»ºçš„é«˜ä¿çœŸå’Œé«˜æ•ˆèŒƒå¼ï¼Œä¸ºè§‚ä¼—æä¾›å¿«é€Ÿå“åº”å’Œæ²‰æµ¸å¼ä½“éªŒã€‚ç„¶è€Œï¼Œç°æœ‰çš„åœ¨çº¿æ–¹æ³•é¢ä¸´å­˜å‚¨è¦æ±‚è¿‡é«˜çš„æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºç‚¹å¯¹å»ºæ¨¡æœªèƒ½å……åˆ†åˆ©ç”¨è¿åŠ¨å±æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„ç´§å‡‘é«˜æ–¯æµï¼ˆComGSï¼‰æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨åŠ¨æ€åœºæ™¯ä¸­çš„è¿åŠ¨å±€éƒ¨æ€§å’Œä¸€è‡´æ€§ï¼Œé€šè¿‡å…³é”®å¸§é©±åŠ¨çš„è¿åŠ¨è¡¨ç¤ºå¯¹ç‰©ä½“ä¸€è‡´çš„é«˜æ–¯ç‚¹è¿åŠ¨è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡ä»…ä¼ è¾“å…³é”®ç‚¹çš„å±æ€§ï¼Œè¯¥æ¡†æ¶æä¾›äº†æ›´é«˜æ•ˆçš„å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨è§†å›¾ç©ºé—´æ¢¯åº¦å·®å¼‚ç­–ç•¥ï¼Œåœ¨è¿åŠ¨åŒºåŸŸå†…è¯†åˆ«ä¸€ç»„ç¨€ç–çš„è¿åŠ¨æ•æ„Ÿå…³é”®ç‚¹ã€‚æœ‰äº†è¿™äº›å…³é”®ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªé€‚åº”çš„è¿åŠ¨é©±åŠ¨æœºåˆ¶ï¼Œé¢„æµ‹ä¸€ä¸ªç©ºé—´å½±å“åœºï¼Œå°†å…³é”®ç‚¹çš„è¿åŠ¨ä¼ æ’­åˆ°å…·æœ‰ç›¸ä¼¼è¿åŠ¨çš„ç›¸é‚»é«˜æ–¯ç‚¹ã€‚æ­¤å¤–ï¼ŒComGSé‡‡ç”¨äº†ä¸€ç§é”™è¯¯æ„ŸçŸ¥æ ¡æ­£ç­–ç•¥ï¼Œå¯¹å…³é”®å¸§é‡å»ºè¿›è¡Œé€‰æ‹©æ€§ç»†åŒ–ï¼Œç¼“è§£é”™è¯¯ç§¯ç´¯ï¼ŒåŒæ—¶é¿å…ä¸å¿…è¦çš„å¼€é”€ã€‚æ€»ä½“è€Œè¨€ï¼ŒComGSä¸3DGStreamç›¸æ¯”å®ç°äº†é«˜è¾¾159å€çš„å­˜å‚¨ç¼©å‡ï¼Œä¸å½“å‰æœ€ä½³æ–¹æ³•QUEENç›¸æ¯”å®ç°äº†14å€çš„å­˜å‚¨ç¼©å‡ï¼ŒåŒæ—¶ä¿æŒäº†æœ‰ç«äº‰åŠ›çš„è§†è§‰ä¿çœŸåº¦å’Œæ¸²æŸ“é€Ÿåº¦ã€‚æˆ‘ä»¬çš„ä»£ç å°†ä¼šå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16533v1">PDF</a> 17 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>3DGSæ–¹æ³•ä»¥å…¶é«˜ä¿çœŸåº¦å’Œé«˜æ•ˆç‡æˆä¸ºäº†åœ¨çº¿è‡ªç”±è§†ç‚¹è§†é¢‘é‡å»ºé¢†åŸŸçš„æµè¡Œæ–¹æ³•ï¼Œä¸ºç”¨æˆ·æä¾›å¿«é€Ÿå“åº”å’Œæ²‰æµ¸å¼ä½“éªŒã€‚ä½†æ˜¯ç°æœ‰åœ¨çº¿æ–¹æ³•å­˜å‚¨è¦æ±‚å¾ˆé«˜ï¼Œä¸»è¦æ˜¯å› äº†ç‚¹æ¨¡å‹æ²¡æœ‰å……åˆ†åˆ©ç”¨è¿åŠ¨ç‰¹æ€§ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Compact Gaussian Streamingï¼ˆComGSï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨åŠ¨æ€åœºæ™¯çš„è¿åŠ¨å±€éƒ¨æ€§å’Œä¸€è‡´æ€§ï¼Œé€šè¿‡å…³é”®ç‚¹çš„è¿åŠ¨è¡¨ç¤ºæ¥æ¨¡æ‹Ÿå¯¹è±¡ä¸€è‡´çš„Gaussianç‚¹è¿åŠ¨ã€‚å®ƒä»…ä¼ è¾“å…³é”®ç‚¹çš„å±æ€§ï¼Œä»è€Œæ›´èŠ‚çœå­˜å‚¨ç©ºé—´ã€‚é€šè¿‡è¿åŠ¨æ•æ„Ÿçš„å…³é”®ç‚¹è‡ªé€‚åº”é¢„æµ‹ç©ºé—´å½±å“åœºæ¥å°†è¿åŠ¨ä¼ æ’­åˆ°ç›¸é‚»çš„Gaussianç‚¹ã€‚æ­¤å¤–ï¼ŒComGSé‡‡ç”¨äº†ä¸€ç§é”™è¯¯æ„ŸçŸ¥æ ¡æ­£ç­–ç•¥è¿›è¡Œå…³é”®å¸§é‡å»ºï¼Œé€‰æ‹©æ€§ä¼˜åŒ–é”™è¯¯åŒºåŸŸå¹¶å‡è½»é”™è¯¯ç´¯ç§¯è´Ÿæ‹…ã€‚ç›¸è¾ƒäºå…¶ä»–æ–¹æ³•ï¼ŒComGSå®ç°äº†æ˜¾è‘—çš„å­˜å‚¨é™ä½ï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰æ€§çš„è§†è§‰ä¿çœŸåº¦å’Œæ¸²æŸ“é€Ÿåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯å…³äºæ–‡æœ¬çš„å…³é”®è§è§£ï¼š</p>
<ul>
<li>ç°æœ‰åœ¨çº¿æ–¹æ³•çš„å­˜å‚¨è¦æ±‚è¾ƒé«˜æ˜¯å› ä¸ºæœªå……åˆ†åˆ©ç”¨è¿åŠ¨ç‰¹æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç‚¹å¯¹æ¨¡å‹å¤„ç†æ–¹é¢å­˜åœ¨é—®é¢˜ã€‚å¯¹æ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ComGSæ¡†æ¶æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨åŠ¨æ€åœºæ™¯çš„è¿åŠ¨å±€éƒ¨æ€§å’Œä¸€è‡´æ€§æ¥å®ç°é«˜æ•ˆå­˜å‚¨ã€‚</li>
<li>ComGSæ¡†æ¶åˆ©ç”¨å…³é”®ç‚¹çš„è¿åŠ¨è¡¨ç¤ºæ¥æ¨¡æ‹Ÿå¯¹è±¡ä¸€è‡´çš„Gaussianç‚¹è¿åŠ¨ï¼Œä»…ä¼ è¾“å…³é”®ç‚¹çš„å±æ€§ï¼Œä»è€Œæ˜¾è‘—å‡å°‘å­˜å‚¨éœ€æ±‚ã€‚è¿™æ˜¯é€šè¿‡è¯†åˆ«è¿åŠ¨æ•æ„Ÿçš„å…³é”®ç‚¹å¹¶é¢„æµ‹ç©ºé—´å½±å“åœºå®ç°çš„ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå…³é”®ç‚¹çš„è¿åŠ¨èƒ½å¤Ÿä¼ æ’­åˆ°å…·æœ‰ç›¸ä¼¼è¿åŠ¨çš„ç›¸é‚»Gaussianç‚¹ã€‚è¿™æ˜¯ä¸€ç§ç»“åˆå…³é”®ç‚¹å’Œè¿åŠ¨é¢„æµ‹çš„ç­–ç•¥ï¼Œä½¿å¾—å­˜å‚¨æ•ˆç‡å¤§å¤§æé«˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16533">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c3eb68f7037794b08679271c3b4ec12b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8702188b9dec2c0cc286562015c741ea.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MAGIC-Motion-Aware-Generative-Inference-via-Confidence-Guided-LLM"><a href="#MAGIC-Motion-Aware-Generative-Inference-via-Confidence-Guided-LLM" class="headerlink" title="MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM"></a>MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM</h2><p><strong>Authors:Siwei Meng, Yawei Luo, Ping Liu</strong></p>
<p>Recent advances in static 3D generation have intensified the demand for physically consistent dynamic 3D content. However, existing video generation models, including diffusion-based methods, often prioritize visual realism while neglecting physical plausibility, resulting in implausible object dynamics. Prior approaches for physics-aware dynamic generation typically rely on large-scale annotated datasets or extensive model fine-tuning, which imposes significant computational and data collection burdens and limits scalability across scenarios. To address these challenges, we present MAGIC, a training-free framework for single-image physical property inference and dynamic generation, integrating pretrained image-to-video diffusion models with iterative LLM-based reasoning. Our framework generates motion-rich videos from a static image and closes the visual-to-physical gap through a confidence-driven LLM feedback loop that adaptively steers the diffusion model toward physics-relevant motion. To translate visual dynamics into controllable physical behavior, we further introduce a differentiable MPM simulator operating directly on 3D Gaussians reconstructed from the single image, enabling physically grounded, simulation-ready outputs without any supervision or model tuning. Experiments show that MAGIC outperforms existing physics-aware generative methods in inference accuracy and achieves greater temporal coherence than state-of-the-art video diffusion models. </p>
<blockquote>
<p>è¿‘å¹´æ¥é™æ€ä¸‰ç»´ç”ŸæˆæŠ€æœ¯çš„è¿›å±•åŠ å‰§äº†å¯¹ç‰©ç†ä¸€è‡´æ€§åŠ¨æ€ä¸‰ç»´å†…å®¹çš„éœ€æ±‚ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬åŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œé€šå¸¸ä¼˜å…ˆè¿½æ±‚è§†è§‰çœŸå®æ€§ï¼Œè€Œå¿½è§†ç‰©ç†åˆç†æ€§ï¼Œå¯¼è‡´ç‰©ä½“åŠ¨æ€ä¸çœŸå®ã€‚ä»¥å‰çš„æ–¹æ³•å¯¹äºç‰©ç†æ„ŸçŸ¥çš„åŠ¨æ€ç”Ÿæˆé€šå¸¸ä¾èµ–äºå¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†æˆ–æ¨¡å‹ç²¾ç»†è°ƒæ•´ï¼Œè¿™å¸¦æ¥äº†æ˜¾è‘—çš„è®¡ç®—å’Œæ•°æ®æ”¶é›†è´Ÿæ‹…ï¼Œå¹¶é™åˆ¶äº†è·¨åœºæ™¯çš„æ‰©å±•æ€§ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MAGICï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„å•å›¾åƒç‰©ç†å±æ€§æ¨æ–­å’ŒåŠ¨æ€ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒç»“åˆäº†é¢„è®­ç»ƒçš„å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹ä¸åŸºäºè¿­ä»£çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä»é™æ€å›¾åƒç”Ÿæˆè¿åŠ¨ä¸°å¯Œçš„è§†é¢‘ï¼Œå¹¶é€šè¿‡ä¿¡å¿ƒé©±åŠ¨çš„LLMåé¦ˆå¾ªç¯æ¥ç¼©å°è§†è§‰åˆ°ç‰©ç†çš„å·®è·ï¼Œè¯¥å¾ªç¯è‡ªé€‚åº”åœ°å¼•å¯¼æ‰©æ•£æ¨¡å‹å‘ç‰©ç†ç›¸å…³çš„è¿åŠ¨æ–¹å‘è¿›è¡Œã€‚ä¸ºäº†å°†è§†è§‰åŠ¨æ€è½¬åŒ–ä¸ºå¯æ§çš„ç‰©ç†è¡Œä¸ºï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ä¸ªå¯å¾®åˆ†çš„MPMæ¨¡æ‹Ÿå™¨ï¼Œè¯¥æ¨¡æ‹Ÿå™¨ç›´æ¥åœ¨ç”±å•å›¾åƒé‡å»ºçš„3Dé«˜æ–¯åˆ†å¸ƒä¸Šè¿è¡Œï¼Œæ— éœ€ç›‘ç£æˆ–æ¨¡å‹è°ƒæ•´å³å¯å®ç°ç‰©ç†åŸºç¡€ã€æ¨¡æ‹Ÿå°±ç»ªçš„è¾“å‡ºã€‚å®éªŒè¡¨æ˜ï¼ŒMAGICåœ¨æ¨ç†å‡†ç¡®æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„ç‰©ç†æ„ŸçŸ¥ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æ—¶é—´è¿è´¯æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16456v1">PDF</a> </p>
<p><strong>Summary</strong><br>æœ¬æ–‡ä»‹ç»äº†MAGICæ¡†æ¶ï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„å•å›¾åƒç‰©ç†å±æ€§æ¨æ–­å’ŒåŠ¨æ€ç”Ÿæˆæ¡†æ¶ã€‚å®ƒç»“åˆäº†é¢„è®­ç»ƒçš„å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹å’ŒåŸºäºè¿­ä»£çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ï¼Œèƒ½å¤Ÿç”Ÿæˆè¿åŠ¨ä¸°å¯Œçš„è§†é¢‘å¹¶å¼¥åˆè§†è§‰åˆ°ç‰©ç†ä¹‹é—´çš„å·®è·ã€‚æ¡†æ¶é€šè¿‡ç½®ä¿¡åº¦é©±åŠ¨çš„LLMåé¦ˆå¾ªç¯è‡ªé€‚åº”åœ°å¼•å¯¼æ‰©æ•£æ¨¡å‹è¿›è¡Œç‰©ç†ç›¸å…³çš„è¿åŠ¨ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†å¯å¾®åˆ†çš„MPMæ¨¡æ‹Ÿå™¨ï¼Œç›´æ¥åœ¨ä»å•å¼ å›¾åƒé‡å»ºçš„3Dé«˜æ–¯ä¸Šæ“ä½œï¼Œå®ç°ç‰©ç†åŸºç¡€ä¸”æ¨¡æ‹Ÿå°±ç»ªçš„è¾“å‡ºï¼Œæ— éœ€ç›‘ç£æˆ–æ¨¡å‹è°ƒæ•´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MAGICæ¡†æ¶æ˜¯é¦–ä¸ªæ— éœ€è®­ç»ƒå°±èƒ½è¿›è¡Œç‰©ç†å±æ€§æ¨æ–­å’ŒåŠ¨æ€ç”Ÿæˆçš„æ–¹æ³•ã€‚</li>
<li>ç»“åˆäº†å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹å’ŒLLMæ¨ç†ï¼Œç”Ÿæˆè¿åŠ¨ä¸°å¯Œçš„è§†é¢‘ã€‚</li>
<li>é€šè¿‡ç½®ä¿¡åº¦é©±åŠ¨çš„LLMåé¦ˆå¾ªç¯ï¼Œä½¿æ¨¡å‹èƒ½è‡ªé€‚åº”åœ°æ¨¡æ‹Ÿç‰©ç†ç›¸å…³çš„è¿åŠ¨ã€‚</li>
<li>å¼•å…¥äº†å¯å¾®åˆ†çš„MPMæ¨¡æ‹Ÿå™¨ï¼Œç›´æ¥åœ¨3Dé«˜æ–¯ä¸Šè¿›è¡Œæ“ä½œï¼Œå®ç°ç‰©ç†åŸºç¡€çš„æ¨¡æ‹Ÿã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„ç›‘ç£æˆ–æ¨¡å‹è°ƒæ•´ï¼Œå…·æœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼ŒMAGICåœ¨æ¨ç†å‡†ç¡®æ€§å’Œæ—¶é—´è¿è´¯æ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„ç‰©ç†æ„ŸçŸ¥ç”Ÿæˆæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16456">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dca90b978eb12c54278e945f8392df79.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e05670f0400652cee38bd0d733e0648d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20e9e24d2e0a0db7dcb33948ed816fa1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-488a64befa1216189a3cae36eb973c80.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43eded7d51517ad257d1da2db9033f82.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="RUSplatting-Robust-3D-Gaussian-Splatting-for-Sparse-View-Underwater-Scene-Reconstruction"><a href="#RUSplatting-Robust-3D-Gaussian-Splatting-for-Sparse-View-Underwater-Scene-Reconstruction" class="headerlink" title="RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater   Scene Reconstruction"></a>RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater   Scene Reconstruction</h2><p><strong>Authors:Zhuodong Jiang, Haoran Wang, Guoxi Huang, Brett Seymour, Nantheera Anantrasirichai</strong></p>
<p>Reconstructing high-fidelity underwater scenes remains a challenging task due to light absorption, scattering, and limited visibility inherent in aquatic environments. This paper presents an enhanced Gaussian Splatting-based framework that improves both the visual quality and geometric accuracy of deep underwater rendering. We propose decoupled learning for RGB channels, guided by the physics of underwater attenuation, to enable more accurate colour restoration. To address sparse-view limitations and improve view consistency, we introduce a frame interpolation strategy with a novel adaptive weighting scheme. Additionally, we introduce a new loss function aimed at reducing noise while preserving edges, which is essential for deep-sea content. We also release a newly collected dataset, Submerged3D, captured specifically in deep-sea environments. Experimental results demonstrate that our framework consistently outperforms state-of-the-art methods with PSNR gains up to 1.90dB, delivering superior perceptual quality and robustness, and offering promising directions for marine robotics and underwater visual analytics. </p>
<blockquote>
<p>é‡å»ºé«˜ä¿çœŸæ°´ä¸‹åœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œç”±äºæ°´ä¸‹ç¯å¢ƒä¸­çš„å…‰å¸æ”¶ã€æ•£å°„å’Œæœ‰é™çš„å¯è§åº¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¢å¼ºé«˜æ–¯Splattingçš„æ¡†æ¶ï¼Œæé«˜äº†æ·±æµ·æ¸²æŸ“çš„è§†è§‰è´¨é‡å’Œå‡ ä½•ç²¾åº¦ã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºæ°´ä¸‹è¡°å‡ç‰©ç†åŸç†çš„RGBé€šé“è§£è€¦å­¦ä¹ ï¼Œä»¥å®ç°æ›´å‡†ç¡®çš„é¢œè‰²æ¢å¤ã€‚ä¸ºäº†è§£å†³ç¨€ç–è§†è§’çš„é™åˆ¶å¹¶æé«˜è§†è§’ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¸¦æœ‰æ–°å‹è‡ªé€‚åº”åŠ æƒæ–¹æ¡ˆçš„æ–°å¸§æ’å€¼ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨å‡å°‘å™ªå£°çš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ï¼Œè¿™å¯¹äºæ·±æµ·å†…å®¹è‡³å…³é‡è¦ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†ä¸€ä¸ªæ–°æ”¶é›†çš„ç‰¹å®šåœ¨æ·±æµ·ç¯å¢ƒä¸­æ•è·çš„æ•°æ®é›†Submerged3Dã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å§‹ç»ˆä¼˜äºæœ€æ–°æŠ€æœ¯çš„æ–¹æ³•ï¼ŒPSNRå¢ç›Šé«˜è¾¾1.90dBï¼Œå…·æœ‰å‡ºè‰²çš„æ„ŸçŸ¥è´¨é‡å’Œç¨³å¥æ€§ï¼Œå¹¶ä¸ºæµ·æ´‹æœºå™¨äººæŠ€æœ¯å’Œæ°´ä¸‹è§†è§‰åˆ†ææä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15737v1">PDF</a> 10 pages, 3 figures. Submitted to BMVC 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯Splattingçš„å¢å¼ºæ¡†æ¶ï¼Œç”¨äºæé«˜æ°´ä¸‹åœºæ™¯çš„è§†è§‰è´¨é‡å’Œå‡ ä½•æ¸²æŸ“ç²¾åº¦ã€‚è¯¥ç ”ç©¶é€šè¿‡è§£è€¦RGBé€šé“å­¦ä¹ ã€å¼•å…¥å¸§æ’å€¼ç­–ç•¥å’Œè‡ªé€‚åº”æƒé‡æ–¹æ¡ˆï¼Œä»¥åŠè®¾è®¡æ–°çš„æŸå¤±å‡½æ•°ï¼Œæœ‰æ•ˆåº”å¯¹æ°´ä¸‹ç¯å¢ƒä¸­çš„å…‰å¸æ”¶ã€æ•£å°„å’Œæœ‰é™å¯è§åº¦ç­‰æŒ‘æˆ˜ï¼Œå®ç°äº†æ›´å‡†ç¡®çš„é¢œè‰²æ¢å¤ã€è§†å›¾ä¸€è‡´æ€§å’Œè¾¹ç¼˜ä¿æŠ¤ã€‚åŒæ—¶ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å…¬å¼€äº†ä¸€ä¸ªä¸“é—¨åœ¨æ·±æµ·ç¯å¢ƒä¸­é‡‡é›†çš„æ–°æ•°æ®é›†Submerged3Dã€‚ç ”ç©¶æˆæœåœ¨å®éªŒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¾ƒç°æœ‰æ–¹æ³•å¹³å‡å³°å€¼ä¿¡å™ªæ¯”æé«˜è¾¾1.90dBï¼Œä¸ºæµ·æ´‹æœºå™¨äººå’Œæ°´ä¸‹è§†è§‰åˆ†ææä¾›äº†æœ‰åŠ›æ”¯æŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡‡ç”¨å¢å¼ºé«˜æ–¯Splattingæ¡†æ¶ï¼Œæé«˜æ°´ä¸‹åœºæ™¯è§†è§‰è´¨é‡å’Œå‡ ä½•æ¸²æŸ“ç²¾åº¦ã€‚</li>
<li>è§£è€¦RGBé€šé“å­¦ä¹ ï¼Œæ ¹æ®æ°´ä¸‹è¡°å‡ç‰©ç†ç‰¹æ€§æŒ‡å¯¼æ›´å‡†ç¡®çš„é¢œè‰²æ¢å¤ã€‚</li>
<li>å¼•å…¥å¸§æ’å€¼ç­–ç•¥åŠè‡ªé€‚åº”æƒé‡æ–¹æ¡ˆï¼Œè§£å†³ç¨€ç–è§†å›¾é—®é¢˜å¹¶æ”¹å–„è§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>è®¾è®¡æ–°æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨é™ä½å™ªå£°åŒæ—¶ä¿ç•™è¾¹ç¼˜ï¼Œå¯¹æ·±æµ·å†…å®¹è‡³å…³é‡è¦ã€‚</li>
<li>å…¬å¼€æ–°æ•°æ®é›†Submerged3Dï¼Œä¸“æ³¨äºæ·±æµ·ç¯å¢ƒé‡‡é›†ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶è¾ƒç°æœ‰æŠ€æœ¯æœ‰æ˜¾è‘—æå‡ï¼Œå³°å€¼ä¿¡å™ªæ¯”æé«˜è¾¾1.90dBã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15737">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-578f5643f1b2cdd35ae063cecf7dcd2c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-684dcc6928c25e245169e45e01e6abd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6528c2d6dd13fa6985f9bc72715fe025.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PlantDreamer-Achieving-Realistic-3D-Plant-Models-with-Diffusion-Guided-Gaussian-Splatting"><a href="#PlantDreamer-Achieving-Realistic-3D-Plant-Models-with-Diffusion-Guided-Gaussian-Splatting" class="headerlink" title="PlantDreamer: Achieving Realistic 3D Plant Models with Diffusion-Guided   Gaussian Splatting"></a>PlantDreamer: Achieving Realistic 3D Plant Models with Diffusion-Guided   Gaussian Splatting</h2><p><strong>Authors:Zane K J Hartley, Lewis A G Stuart, Andrew P French, Michael P Pound</strong></p>
<p>Recent years have seen substantial improvements in the ability to generate synthetic 3D objects using AI. However, generating complex 3D objects, such as plants, remains a considerable challenge. Current generative 3D models struggle with plant generation compared to general objects, limiting their usability in plant analysis tools, which require fine detail and accurate geometry. We introduce PlantDreamer, a novel approach to 3D synthetic plant generation, which can achieve greater levels of realism for complex plant geometry and textures than available text-to-3D models. To achieve this, our new generation pipeline leverages a depth ControlNet, fine-tuned Low-Rank Adaptation and an adaptable Gaussian culling algorithm, which directly improve textural realism and geometric integrity of generated 3D plant models. Additionally, PlantDreamer enables both purely synthetic plant generation, by leveraging L-System-generated meshes, and the enhancement of real-world plant point clouds by converting them into 3D Gaussian Splats. We evaluate our approach by comparing its outputs with state-of-the-art text-to-3D models, demonstrating that PlantDreamer outperforms existing methods in producing high-fidelity synthetic plants. Our results indicate that our approach not only advances synthetic plant generation, but also facilitates the upgrading of legacy point cloud datasets, making it a valuable tool for 3D phenotyping applications. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œåˆ©ç”¨äººå·¥æ™ºèƒ½ç”Ÿæˆåˆæˆ3Dç‰©ä½“çš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚ç„¶è€Œï¼Œç”Ÿæˆå¤æ‚çš„3Dç‰©ä½“ï¼Œå¦‚æ¤ç‰©ï¼Œä»ç„¶æ˜¯ä¸€é¡¹å·¨å¤§çš„æŒ‘æˆ˜ã€‚ä¸é€šç”¨ç‰©ä½“ç›¸æ¯”ï¼Œå½“å‰çš„3Dç”Ÿæˆæ¨¡å‹åœ¨æ¤ç‰©ç”Ÿæˆæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦ç²¾ç»†ç»†èŠ‚å’Œç²¾ç¡®å‡ ä½•å½¢çŠ¶çš„æ¤ç‰©åˆ†æå·¥å…·ä¸­çš„å¯ç”¨æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†PlantDreamerï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„3Dåˆæˆæ¤ç‰©ç”Ÿæˆæ–¹æ³•ï¼Œä¸ç°æœ‰çš„æ–‡æœ¬åˆ°3Dæ¨¡å‹ç›¸æ¯”ï¼Œå®ƒå¯ä»¥åœ¨å¤æ‚çš„æ¤ç‰©å‡ ä½•å’Œçº¹ç†æ–¹é¢å®ç°æ›´é«˜æ°´å¹³çš„é€¼çœŸåº¦ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬çš„æ–°ä¸€ä»£æµæ°´çº¿åˆ©ç”¨æ·±åº¦ControlNetï¼Œç²¾ç»†è°ƒæ•´çš„ä½ç§©é€‚åº”æ€§å’Œå¯é€‚åº”çš„é«˜æ–¯å‰”é™¤ç®—æ³•ï¼Œç›´æ¥æé«˜äº†ç”Ÿæˆ3Dæ¤ç‰©æ¨¡å‹çš„çœŸå®æ„Ÿå’Œå‡ ä½•å®Œæ•´æ€§ã€‚æ­¤å¤–ï¼ŒPlantDreamerèƒ½å¤Ÿé€šè¿‡åˆ©ç”¨Lç³»ç»Ÿç”Ÿæˆçš„ç½‘æ ¼è¿›è¡Œçº¯ç²¹çš„åˆæˆæ¤ç‰©ç”Ÿæˆï¼Œå¹¶ä¸”èƒ½å¤Ÿé€šè¿‡å°†ç°å®ä¸–ç•Œä¸­çš„æ¤ç‰©ç‚¹äº‘è½¬æ¢ä¸º3Dé«˜æ–¯æ–‘å—æ¥å¢å¼ºå®ƒä»¬ã€‚æˆ‘ä»¬é€šè¿‡å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›æ–‡æœ¬åˆ°3Dæ¨¡å‹è¾“å‡ºè¿›è¡Œæ¯”è¾ƒæ¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜PlantDreameråœ¨ç”Ÿæˆé«˜ä¿çœŸåˆæˆæ¤ç‰©æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…æ¨åŠ¨äº†åˆæˆæ¤ç‰©çš„ç”Ÿæˆï¼Œè€Œä¸”è¿˜ä¿ƒè¿›äº†æ—§æœ‰ç‚¹äº‘æ•°æ®é›†å‡çº§ï¼Œä½¿å…¶æˆä¸º3Dè¡¨å‹åº”ç”¨çš„æœ‰ä»·å€¼çš„å·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15528v1">PDF</a> 13 pages, 5 figures, 4 tables</p>
<p><strong>Summary</strong><br>     è¿‘å¹´æ¥AIç”Ÿæˆåˆæˆ3Dç‰©ä½“çš„èƒ½åŠ›æ˜¾è‘—æé«˜ï¼Œä½†åœ¨ç”Ÿæˆå¤æ‚çš„æ¤ç‰©æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æ¨å‡ºPlantDreamerï¼Œä¸€ç§æ–°å‹çš„3Dåˆæˆæ¤ç‰©ç”Ÿæˆæ–¹æ³•ï¼Œå¯å®ç°æ›´é«˜çº§çš„é€¼çœŸåº¦ã€‚æ­¤æ–¹æ³•åˆ©ç”¨æ·±åº¦æ§åˆ¶ç½‘ç»œã€ç²¾ç»†çš„ä½é˜¶é€‚åº”æ€§å’Œçµæ´»çš„é«˜æ–¯å‰”é™¤ç®—æ³•ç­‰æŠ€æœ¯æå‡çº¹ç†çœŸå®æ„Ÿå’Œå‡ ä½•å®Œæ•´æ€§ã€‚æ­¤å¤–ï¼Œå®ƒä¸ä»…èƒ½å¤Ÿç”Ÿæˆçº¯åˆæˆçš„æ¤ç‰©ï¼Œè¿˜å¯ä»¥æé«˜ç°å®ä¸–ç•Œæ¤ç‰©ç‚¹äº‘çš„è½¬æ¢ä¸ºé«˜è´¨é‡çš„æ¤ç‰©æ¨¡å‹çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç›®å‰ä¸»æµçš„æ–‡æœ¬åˆ°3Dæ¨¡å‹ç›¸æ¯”ï¼ŒPlantDreameråœ¨ç”Ÿæˆé«˜è´¨é‡åˆæˆæ¤ç‰©æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚å®ƒä¸ä»…æ¨åŠ¨äº†åˆæˆæ¤ç‰©çš„ç”ŸæˆæŠ€æœ¯ï¼Œè¿˜æœ‰åŠ©äºæå‡ç°æœ‰çš„ç‚¹äº‘æ•°æ®é›†ï¼Œå¯¹æ¤ç‰©è¡¨å‹åˆ†æåº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIåœ¨ç”Ÿæˆå¤æ‚æ¤ç‰©æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚ç›®å‰ä¸»æµçš„ç”Ÿæˆæ¨¡å‹åœ¨è¿™æ–¹é¢éš¾ä»¥ä¸ä¸€èˆ¬çš„ç‰©ä½“ç›¸æå¹¶è®ºï¼Œå¯¼è‡´å®ƒä»¬åœ¨ç²¾ç»†ç»†èŠ‚å’Œç²¾ç¡®å‡ ä½•ä¸Šçš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚è¿™å½±å“æ¤ç‰©åˆ†æå·¥å…·çš„å®ç”¨æ€§å’Œå¯é æ€§ã€‚å°½ç®¡å¦‚æ­¤ï¼Œè¿‘æœŸçš„æŠ€æœ¯å‘å±•å±•ç°äº†äººå·¥æ™ºèƒ½åœ¨æ­¤æ–¹é¢çš„è¿›æ­¥ç©ºé—´å’Œå‘å±•æ½œåŠ›ã€‚</li>
<li>PlantDreamerä½œä¸ºä¸€ç§æ–°å‹çš„åˆæˆæ¤ç‰©ç”Ÿæˆæ–¹æ³•å¼•å…¥äº†ä¸€ç³»åˆ—æŠ€æœ¯æ”¹è¿›ä»¥æå‡æ¤ç‰©ç”Ÿæˆçš„é€¼çœŸåº¦ã€‚å®ƒåˆ©ç”¨æ·±åº¦æ§åˆ¶ç½‘ç»œã€ä½é˜¶é€‚åº”æ€§è°ƒæ•´å’Œé«˜æ–¯å‰”é™¤ç®—æ³•ç­‰æŠ€æœ¯æ¥ä¼˜åŒ–ç”Ÿæˆçš„æ¤ç‰©æ¨¡å‹çš„çº¹ç†å’Œå‡ ä½•å®Œæ•´æ€§ã€‚è¿™ä¸€æ–¹æ³•åœ¨ä¼˜åŒ–æ¨¡æ‹Ÿæ¤ç‰©ä¸Šå±•ç¤ºäº†ä¼˜åŠ¿ï¼Œå¹¶èƒ½å¤ŸåŒæ—¶å¢å¼ºç°å®æ¤ç‰©çš„ç‚¹äº‘æ•°æ®è´¨é‡ã€‚è¿™ä¸ºæ¤ç‰©ç§‘å­¦ç ”ç©¶å’Œå¯è§†åŒ–æä¾›äº†æœ‰åŠ›çš„å·¥å…·ã€‚</li>
<li>PlantDreamerä¸ä»…èƒ½ç”Ÿæˆçº¯åˆæˆçš„æ¤ç‰©æ¨¡å‹ï¼Œè¿˜èƒ½å°†ç°å®ä¸–ç•Œä¸­çš„æ¤ç‰©ç‚¹äº‘è½¬æ¢ä¸ºé«˜è´¨é‡çš„æ¨¡å‹ï¼Œè¿™å¯¹äºå‡çº§ç°æœ‰çš„ç‚¹äº‘æ•°æ®é›†å…·æœ‰å…³é”®ä½œç”¨ã€‚è¿™å¯¹äºæ¤ç‰©è¡¨å‹åˆ†æåº”ç”¨æ¥è¯´è‡³å…³é‡è¦ï¼Œæœ‰åŠ©äºæé«˜å†œä¸šå’Œç”Ÿæ€ç ”ç©¶çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¿™æœ‰åŠ©äºå¡«è¡¥ç°å®ä¸–ç•Œä¸­æ¤ç‰©æ•°æ®çš„ç©ºç™½ï¼Œæé«˜æ¨¡å‹çš„å¤šæ ·æ€§å’Œå‡†ç¡®æ€§ã€‚è¿™ä¸€æŠ€æœ¯ä¸ºæ„å»ºæ›´å…¨é¢çš„æ¤ç‰©æ•°æ®åº“æä¾›äº†å¯èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15528">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3e8fe810ba9a3f6e7b242a3a53df5835.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e5adad00bf3e14febb16db304b5ddc65.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e16947612c822874d6652ccefc199dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27108270eac8905588576faf7f7ab84c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-13d6a42597f1a008cce29441ae7ef3b4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="EVA-Expressive-Virtual-Avatars-from-Multi-view-Videos"><a href="#EVA-Expressive-Virtual-Avatars-from-Multi-view-Videos" class="headerlink" title="EVA: Expressive Virtual Avatars from Multi-view Videos"></a>EVA: Expressive Virtual Avatars from Multi-view Videos</h2><p><strong>Authors:Hendrik Junkawitsch, Guoxing Sun, Heming Zhu, Christian Theobalt, Marc Habermann</strong></p>
<p>With recent advancements in neural rendering and motion capture algorithms, remarkable progress has been made in photorealistic human avatar modeling, unlocking immense potential for applications in virtual reality, augmented reality, remote communication, and industries such as gaming, film, and medicine. However, existing methods fail to provide complete, faithful, and expressive control over human avatars due to their entangled representation of facial expressions and body movements. In this work, we introduce Expressive Virtual Avatars (EVA), an actor-specific, fully controllable, and expressive human avatar framework that achieves high-fidelity, lifelike renderings in real time while enabling independent control of facial expressions, body movements, and hand gestures. Specifically, our approach designs the human avatar as a two-layer model: an expressive template geometry layer and a 3D Gaussian appearance layer. First, we present an expressive template tracking algorithm that leverages coarse-to-fine optimization to accurately recover body motions, facial expressions, and non-rigid deformation parameters from multi-view videos. Next, we propose a novel decoupled 3D Gaussian appearance model designed to effectively disentangle body and facial appearance. Unlike unified Gaussian estimation approaches, our method employs two specialized and independent modules to model the body and face separately. Experimental results demonstrate that EVA surpasses state-of-the-art methods in terms of rendering quality and expressiveness, validating its effectiveness in creating full-body avatars. This work represents a significant advancement towards fully drivable digital human models, enabling the creation of lifelike digital avatars that faithfully replicate human geometry and appearance. </p>
<blockquote>
<p>éšç€ç¥ç»ç½‘ç»œæ¸²æŸ“å’Œè¿åŠ¨æ•æ‰ç®—æ³•çš„æœ€æ–°è¿›å±•ï¼Œå…‰çœŸäººåŒ–çš„äººç±»åŒ–èº«å»ºæ¨¡å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸ºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è¿œç¨‹é€šä¿¡ä»¥åŠæ¸¸æˆã€ç”µå½±å’ŒåŒ»å­¦ç­‰è¡Œä¸šçš„åº”ç”¨è§£é”äº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ç”±äºé¢éƒ¨è¡¨æƒ…å’Œèº«ä½“è¿åŠ¨çš„çº ç¼ è¡¨ç¤ºï¼Œæ— æ³•æä¾›å®Œæ•´ã€å¿ å®å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„åŒ–èº«æ§åˆ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†â€œè¡¨æƒ…è™šæ‹ŸåŒ–èº«ï¼ˆEVAï¼‰â€ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ç‰¹å®šæ¼”å‘˜ã€å¯å®Œå…¨æ§åˆ¶å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„åŒ–èº«æ¡†æ¶ï¼Œå¯åœ¨å®æ—¶å®ç°é«˜ä¿çœŸã€é€¼çœŸçš„æ¸²æŸ“ï¼ŒåŒæ—¶å®ç°å¯¹é¢éƒ¨è¡¨æƒ…ã€èº«ä½“è¿åŠ¨å’Œæ‰‹åŠ¿çš„ç‹¬ç«‹æ§åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†äººç±»åŒ–èº«è®¾è®¡ä¸ºä¸¤å±‚æ¨¡å‹ï¼šä¸€ä¸ªè¡¨æƒ…æ¨¡æ¿å‡ ä½•å±‚å’Œä¸€ä¸ª3Dé«˜æ–¯å¤–è§‚å±‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¡¨æƒ…æ¨¡æ¿è·Ÿè¸ªç®—æ³•ï¼Œè¯¥ç®—æ³•åˆ©ç”¨ä»ç²—åˆ°ç»†çš„ä¼˜åŒ–ï¼Œå¯ä»¥ä»å¤šè§’åº¦è§†é¢‘ä¸­å‡†ç¡®æ¢å¤èº«ä½“è¿åŠ¨ã€é¢éƒ¨è¡¨æƒ…å’Œéåˆšæ€§å˜å½¢å‚æ•°ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è§£è€¦3Dé«˜æ–¯å¤–è§‚æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æœ‰æ•ˆåœ°åˆ†ç¦»äº†èº«ä½“å’Œé¢éƒ¨å¤–è§‚ã€‚ä¸åŒäºç»Ÿä¸€çš„é«˜æ–¯ä¼°è®¡æ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤ä¸ªä¸“é—¨ç‹¬ç«‹çš„æ¨¡å—æ¥åˆ†åˆ«å»ºæ¨¡èº«ä½“å’Œé¢éƒ¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEVAåœ¨æ¸²æŸ“è´¨é‡å’Œè¡¨ç°åŠ›æ–¹é¢è¶…è¿‡äº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨åˆ›å»ºå…¨èº«åŒ–èº«æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œåœ¨æœç€å®Œå…¨å¯é©±åŠ¨çš„æ•°å­—åŒ–äººç‰©æ¨¡å‹æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œèƒ½å¤Ÿå®ç°é€¼çœŸå¤åˆ¶äººç±»å‡ ä½•å’Œå¤–è§‚çš„æ•°å­—åŒ–èº«ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15385v1">PDF</a> Accepted at SIGGRAPH 2025 Conference Track, Project page:   <a target="_blank" rel="noopener" href="https://vcai.mpi-inf.mpg.de/projects/EVA/">https://vcai.mpi-inf.mpg.de/projects/EVA/</a></p>
<p><strong>æ‘˜è¦</strong><br>     éšç€ç¥ç»ç½‘ç»œæ¸²æŸ“å’Œè¿åŠ¨æ•æ‰ç®—æ³•çš„æœ€æ–°è¿›å±•ï¼Œåœ¨å…‰æ …åŒ–äººç±»åŒ–èº«å»ºæ¨¡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸ºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è¿œç¨‹é€šä¿¡ä»¥åŠæ¸¸æˆã€ç”µå½±å’ŒåŒ»å­¦ç­‰è¡Œä¸šå¸¦æ¥äº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ç”±äºé¢éƒ¨è¡¨æƒ…å’Œèº¯ä½“è¿åŠ¨çš„çº ç¼ è¡¨ç¤ºï¼Œæ— æ³•æä¾›å®Œæ•´ã€å¿ è¯šå’Œå¯Œæœ‰è¡¨ç°åŠ›çš„åŒ–èº«æ§åˆ¶ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¡¨ç°æ€§è™šæ‹ŸåŒ–èº«ï¼ˆEVAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç‰¹å®šæ¼”å‘˜ã€å¯å®Œå…¨æ§åˆ¶å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„åŒ–èº«æ¡†æ¶ï¼Œå¯åœ¨å®æ—¶æƒ…å†µä¸‹å®ç°é«˜ä¿çœŸã€é€¼çœŸçš„æ¸²æŸ“ï¼ŒåŒæ—¶å®ç°å¯¹é¢éƒ¨è¡¨æƒ…ã€èº¯ä½“è¿åŠ¨å’Œæ‰‹åŠ¿çš„ç‹¬ç«‹æ§åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†äººç±»åŒ–èº«è®¾è®¡ä¸ºä¸€ä¸ªä¸¤å±‚æ¨¡å‹ï¼šè¡¨ç°æ¨¡æ¿å‡ ä½•å±‚å’Œ3Dé«˜æ–¯å¤–è§‚å±‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¡¨ç°æ¨¡æ¿è·Ÿè¸ªç®—æ³•ï¼Œè¯¥ç®—æ³•åˆ©ç”¨ä»ç²—åˆ°ç»†çš„ä¼˜åŒ–æŠ€æœ¯ï¼Œä»å¤šè§’åº¦è§†é¢‘ä¸­å‡†ç¡®æ¢å¤èº«ä½“è¿åŠ¨ã€é¢éƒ¨è¡¨æƒ…å’Œéåˆšæ€§å˜å½¢å‚æ•°ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è§£è€¦3Dé«˜æ–¯å¤–è§‚æ¨¡å‹ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°åˆ†ç¦»èº«ä½“å’Œé¢éƒ¨å¤–è§‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤ä¸ªä¸“ä¸šå’Œç‹¬ç«‹çš„æ¨¡å—æ¥åˆ†åˆ«å»ºæ¨¡èº«ä½“å’Œé¢éƒ¨ï¼Œä¸åŒäºç»Ÿä¸€çš„é«˜æ–¯ä¼°è®¡æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEVAåœ¨æ¸²æŸ“è´¨é‡å’Œè¡¨ç°åŠ›æ–¹é¢è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨åˆ›å»ºå…¨èº«åŒ–èº«æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨ç€é€šå‘å®Œå…¨å¯é©±åŠ¨çš„æ•°å­—åŒ–äººç±»æ¨¡å‹çš„é‡å¤§è¿›å±•ï¼Œèƒ½å¤Ÿåˆ›å»ºå‡ºé€¼çœŸã€å¿ è¯šåœ°å¤åˆ¶äººç±»å‡ ä½•å’Œå¤–è§‚çš„æ•°å­—åŒ–èº«ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æœ€è¿‘çš„ç¥ç»è¿‡ç¨‹å’Œè¿åŠ¨æ•æ‰ç®—æ³•è¿›å±•åœ¨å…‰æ …åŒ–äººç±»åŒ–èº«å»ºæ¨¡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨æ§åˆ¶äººç±»åŒ–èº«æ–¹é¢å­˜åœ¨ç¼ºé™·ï¼Œæ— æ³•æä¾›å®Œæ•´ã€å¿ è¯šå’Œå¯Œæœ‰è¡¨ç°åŠ›çš„æ§åˆ¶ã€‚</li>
<li>Expressive Virtual Avatars (EVA)æ¡†æ¶è¢«å¼•å…¥ï¼Œå®ç°é«˜ä¿çœŸã€é€¼çœŸçš„å®æ—¶æ¸²æŸ“ï¼ŒåŒæ—¶ç‹¬ç«‹æ§åˆ¶é¢éƒ¨è¡¨æƒ…ã€èº«ä½“è¿åŠ¨å’Œæ‰‹åŠ¿ã€‚</li>
<li>EVAé‡‡ç”¨ä¸¤å±‚æ¨¡å‹è®¾è®¡ï¼šè¡¨ç°æ¨¡æ¿å‡ ä½•å±‚å’Œ3Dé«˜æ–¯å¤–è§‚å±‚ã€‚</li>
<li>æå‡ºäº†è¡¨ç°æ¨¡æ¿è·Ÿè¸ªç®—æ³•ï¼Œåˆ©ç”¨ä»ç²—åˆ°ç»†çš„ä¼˜åŒ–æŠ€æœ¯ä»å¤šè§’åº¦è§†é¢‘ä¸­æ¢å¤èº«ä½“è¿åŠ¨å’Œé¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>åˆ›æ–°çš„è§£è€¦3Dé«˜æ–¯å¤–è§‚æ¨¡å‹æœ‰æ•ˆåœ°åˆ†ç¦»äº†èº«ä½“å’Œé¢éƒ¨å¤–è§‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15385">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fcc274326a03eed48b70734a3a70bc11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e90425be9385ad443d7e07844a98ace7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb5a5652c328b29c78cda766f10c6ca5.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="R3GS-Gaussian-Splatting-for-Robust-Reconstruction-and-Relocalization-in-Unconstrained-Image-Collections"><a href="#R3GS-Gaussian-Splatting-for-Robust-Reconstruction-and-Relocalization-in-Unconstrained-Image-Collections" class="headerlink" title="R3GS: Gaussian Splatting for Robust Reconstruction and Relocalization in   Unconstrained Image Collections"></a>R3GS: Gaussian Splatting for Robust Reconstruction and Relocalization in   Unconstrained Image Collections</h2><p><strong>Authors:Xu yan, Zhaohui Wang, Rong Wei, Jingbo Yu, Dong Li, Xiangde Liu</strong></p>
<p>We propose R3GS, a robust reconstruction and relocalization framework tailored for unconstrained datasets. Our method uses a hybrid representation during training. Each anchor combines a global feature from a convolutional neural network (CNN) with a local feature encoded by the multiresolution hash grids [2]. Subsequently, several shallow multi-layer perceptrons (MLPs) predict the attributes of each Gaussians, including color, opacity, and covariance. To mitigate the adverse effects of transient objects on the reconstruction process, we ffne-tune a lightweight human detection network. Once ffne-tuned, this network generates a visibility map that efffciently generalizes to other transient objects (such as posters, banners, and cars) with minimal need for further adaptation. Additionally, to address the challenges posed by sky regions in outdoor scenes, we propose an effective sky-handling technique that incorporates a depth prior as a constraint. This allows the inffnitely distant sky to be represented on the surface of a large-radius sky sphere, signiffcantly reducing ffoaters caused by errors in sky reconstruction. Furthermore, we introduce a novel relocalization method that remains robust to changes in lighting conditions while estimating the camera pose of a given image within the reconstructed 3DGS scene. As a result, R3GS significantly enhances rendering ffdelity, improves both training and rendering efffciency, and reduces storage requirements. Our method achieves state-of-the-art performance compared to baseline methods on in-the-wild datasets. The code will be made open-source following the acceptance of the paper. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†R3GSï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹æ— çº¦æŸæ•°æ®é›†çš„ç¨³å¥é‡å»ºå’Œé‡æ–°å®šä½æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ··åˆè¡¨ç¤ºè¿›è¡Œè®­ç»ƒã€‚æ¯ä¸ªé”šç‚¹ç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„å…¨å±€ç‰¹å¾å’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼[2]ç¼–ç çš„å±€éƒ¨ç‰¹å¾ã€‚éšåï¼Œå‡ ä¸ªæµ…å±‚çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰é¢„æµ‹æ¯ä¸ªé«˜æ–¯å±æ€§çš„å€¼ï¼ŒåŒ…æ‹¬é¢œè‰²ã€ä¸é€æ˜åº¦å’Œåæ–¹å·®ã€‚ä¸ºäº†å‡è½»ç¬æ€ç‰©ä½“å¯¹é‡å»ºè¿‡ç¨‹çš„ä¸åˆ©å½±å“ï¼Œæˆ‘ä»¬å¯¹è½»é‡çº§çš„äººè„¸æ£€æµ‹ç½‘ç»œè¿›è¡Œäº†å¾®è°ƒã€‚ä¸€æ—¦å¾®è°ƒå®Œæˆï¼Œè¯¥ç½‘ç»œå¯ä»¥ç”Ÿæˆä¸€ä¸ªå¯è§æ€§æ˜ å°„ï¼Œè¯¥æ˜ å°„èƒ½å¤Ÿé«˜æ•ˆæ¨å¹¿åˆ°å…¶å®ƒç¬æ€å¯¹è±¡ï¼ˆå¦‚æµ·æŠ¥ã€æ¨ªå¹…å’Œæ±½è½¦ç­‰ï¼‰ï¼Œå¹¶ä¸”å‡ ä¹ä¸éœ€è¦è¿›ä¸€æ­¥çš„é€‚åº”ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³æˆ·å¤–åœºæ™¯ä¸­çš„å¤©ç©ºåŒºåŸŸå¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å¤©ç©ºå¤„ç†æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯é‡‡ç”¨æ·±åº¦å…ˆéªŒä½œä¸ºçº¦æŸã€‚è¿™ä½¿å¾—æ— é™è¿œçš„å¤©ç©ºå¯ä»¥åœ¨å¤§åŠå¾„å¤©ç©ºçƒé¢ä¸Šè¡¨ç¤ºå‡ºæ¥ï¼Œä»è€Œæ˜¾è‘—å‡å°‘å› å¤©ç©ºé‡å»ºé”™è¯¯å¼•èµ·çš„æµ®æ²«ç°è±¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é‡æ–°å®šä½æ–¹æ³•ï¼Œå®ƒåœ¨ä¼°è®¡ç»™å®šå›¾åƒåœ¨é‡å»ºçš„3DGSåœºæ™¯ä¸­çš„ç›¸æœºå§¿æ€æ—¶ä¿æŒå¯¹å…‰ç…§å˜åŒ–çš„ç¨³å¥æ€§ã€‚å› æ­¤ï¼ŒR3GSæ˜¾è‘—æé«˜äº†æ¸²æŸ“çš„ä¿çœŸåº¦ï¼Œæé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“çš„æ•ˆç‡ï¼Œå¹¶é™ä½äº†å­˜å‚¨éœ€æ±‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸åŸºå‡†æ•°æ®é›†ä¸Šçš„åŸºçº¿æ–¹æ³•ç›¸æ¯”è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è®ºæ–‡è¢«æ¥å—åï¼Œä»£ç å°†ä½œä¸ºå¼€æºå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15294v1">PDF</a> 7 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹æ— çº¦æŸæ•°æ®é›†çš„ç¨³å¥é‡å»ºä¸é‡æ–°å®šä½æ¡†æ¶R3GSã€‚å®ƒé‡‡ç”¨æ··åˆè¡¨ç¤ºè¿›è¡Œè®­ç»ƒï¼Œç»“åˆå·ç§¯ç¥ç»ç½‘ç»œçš„å…¨å±€ç‰¹å¾ä¸å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç çš„å±€éƒ¨ç‰¹å¾ã€‚é€šè¿‡æµ…å±‚å¤šå±‚æ„ŸçŸ¥å™¨é¢„æµ‹é«˜æ–¯å±æ€§çš„å±æ€§ï¼ŒåŒ…æ‹¬é¢œè‰²ã€ä¸é€æ˜åº¦å’Œåæ–¹å·®ã€‚é€šè¿‡å¾®è°ƒè½»é‡çº§äººä½“æ£€æµ‹ç½‘ç»œæ¥å‡è½»ç¬æ—¶å¯¹è±¡å¯¹é‡å»ºè¿‡ç¨‹çš„ä¸åˆ©å½±å“ï¼Œç”Ÿæˆå¯è§†åŒ–åœ°å›¾ï¼Œæœ‰æ•ˆåœ°æ³›åŒ–åˆ°å…¶ä»–ç¬æ—¶å¯¹è±¡ã€‚é’ˆå¯¹æˆ·å¤–åœºæ™¯çš„å¤©ç©ºåŒºåŸŸæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å¤©ç©ºå¤„ç†æŠ€æœ¯ï¼Œé‡‡ç”¨æ·±åº¦å…ˆéªŒä½œä¸ºçº¦æŸã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„é‡æ–°å®šä½æ–¹æ³•ï¼Œåœ¨å…‰ç…§æ¡ä»¶å˜åŒ–æ—¶ä¿æŒç¨³å¥ï¼Œä¼°è®¡ç»™å®šå›¾åƒåœ¨é‡å»ºçš„3DGSåœºæ™¯ä¸­çš„ç›¸æœºå§¿æ€ã€‚R3GSæé«˜äº†æ¸²æŸ“çš„ä¿çœŸåº¦ï¼Œæé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“çš„æ•ˆç‡ï¼Œå¹¶é™ä½äº†å­˜å‚¨éœ€æ±‚ï¼Œåœ¨é‡ç”Ÿæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>R3GSæ˜¯ä¸€ä¸ªé’ˆå¯¹æ— çº¦æŸæ•°æ®é›†çš„é‡å»ºå’Œé‡æ–°å®šä½æ¡†æ¶ã€‚</li>
<li>èåˆå·ç§¯ç¥ç»ç½‘ç»œçš„å…¨å±€ç‰¹å¾ä¸å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼çš„å±€éƒ¨ç‰¹å¾è¿›è¡Œè®­ç»ƒã€‚</li>
<li>é€šè¿‡æµ…å±‚å¤šå±‚æ„ŸçŸ¥å™¨é¢„æµ‹é«˜æ–¯å±æ€§çš„å±æ€§ï¼ŒåŒ…æ‹¬é¢œè‰²ã€ä¸é€æ˜åº¦å’Œåæ–¹å·®ã€‚</li>
<li>é€šè¿‡å¾®è°ƒè½»é‡çº§äººä½“æ£€æµ‹ç½‘ç»œæ¥åº”å¯¹ç¬æ—¶å¯¹è±¡çš„å½±å“ï¼Œç”Ÿæˆå¯è§†åŒ–åœ°å›¾ã€‚</li>
<li>å¼•å…¥å¤©ç©ºå¤„ç†æŠ€æœ¯ï¼Œé‡‡ç”¨æ·±åº¦å…ˆéªŒä½œä¸ºçº¦æŸï¼Œå¤„ç†å¤©ç©ºåŒºåŸŸçš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹çš„é‡æ–°å®šä½æ–¹æ³•ï¼Œèƒ½åœ¨å…‰ç…§æ¡ä»¶å˜åŒ–æ—¶ä¿æŒç¨³å¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15294">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-571ae2932bd6b3d75a5e82d2b40daf82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5061485433530f68434669d4779b602.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8624831b6e61a5b74e1d510472a41284.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b6e0fdb12ead36eed8f46551b279099.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94185f5e4d39add9ecb231640703842d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-93fd5d3eadb24d0dd1630c2f88ccfa82.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-96ddd3c6fb75de0d0c2de9d2d8a92577.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="X-GRM-Large-Gaussian-Reconstruction-Model-for-Sparse-view-X-rays-to-Computed-Tomography"><a href="#X-GRM-Large-Gaussian-Reconstruction-Model-for-Sparse-view-X-rays-to-Computed-Tomography" class="headerlink" title="X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to   Computed Tomography"></a>X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to   Computed Tomography</h2><p><strong>Authors:Yifan Liu, Wuyang Li, Weihao Yu, Chenxin Li, Alexandre Alahi, Max Meng, Yixuan Yuan</strong></p>
<p>Computed Tomography serves as an indispensable tool in clinical workflows, providing non-invasive visualization of internal anatomical structures. Existing CT reconstruction works are limited to small-capacity model architecture, inflexible volume representation, and small-scale training data. In this paper, we present X-GRM (X-ray Gaussian Reconstruction Model), a large feedforward model for reconstructing 3D CT from sparse-view 2D X-ray projections. X-GRM employs a scalable transformer-based architecture to encode an arbitrary number of sparse X-ray inputs, where tokens from different views are integrated efficiently. Then, tokens are decoded into a new volume representation, named Voxel-based Gaussian Splatting (VoxGS), which enables efficient CT volume extraction and differentiable X-ray rendering. To support the training of X-GRM, we collect ReconX-15K, a large-scale CT reconstruction dataset containing around 15,000 CT&#x2F;X-ray pairs across diverse organs, including the chest, abdomen, pelvis, and tooth etc. This combination of a high-capacity model, flexible volume representation, and large-scale training data empowers our model to produce high-quality reconstructions from various testing inputs, including in-domain and out-domain X-ray projections. Project Page: <a target="_blank" rel="noopener" href="https://github.com/CUHK-AIM-Group/X-GRM">https://github.com/CUHK-AIM-Group/X-GRM</a>. </p>
<blockquote>
<p>è®¡ç®—æœºæ–­å±‚æ‰«æåœ¨ä¸´åºŠå·¥ä½œæµç¨‹ä¸­æ‰®æ¼”ç€ä¸å¯æˆ–ç¼ºçš„è§’è‰²ï¼Œèƒ½å¤Ÿéä¾µå…¥æ€§åœ°å‘ˆç°å†…éƒ¨ç»“æ„ã€‚ç°æœ‰çš„CTé‡å»ºå·¥ä½œå—é™äºå°å®¹é‡æ¨¡å‹ç»“æ„ã€ä¸çµæ´»çš„ä½“ç§¯è¡¨ç¤ºå’Œå°è§„æ¨¡è®­ç»ƒæ•°æ®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†X-GRMï¼ˆXå°„çº¿é«˜æ–¯é‡å»ºæ¨¡å‹ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»ç¨€ç–äºŒç»´Xå°„çº¿æŠ•å½±é‡å»ºä¸‰ç»´CTçš„å¤§å‹å‰é¦ˆæ¨¡å‹ã€‚X-GRMé‡‡ç”¨å¯æ‰©å±•çš„åŸºäºtransformerçš„æ¶æ„æ¥ç¼–ç ä»»æ„æ•°é‡çš„ç¨€ç–Xå°„çº¿è¾“å…¥ï¼Œå…¶ä¸­ä¸åŒè§†è§’çš„æ ‡è®°è¢«é«˜æ•ˆé›†æˆã€‚ç„¶åï¼Œæ ‡è®°è¢«è§£ç æˆä¸€ç§æ–°çš„ä½“ç§¯è¡¨ç¤ºï¼Œç§°ä¸ºåŸºäºä½“ç´ çš„é«˜æ–¯æº…å°„ï¼ˆVoxGSï¼‰ï¼Œè¿™èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„CTä½“ç§¯æå–å’Œå¯å¾®åˆ†Xå°„çº¿æ¸²æŸ“ã€‚ä¸ºäº†æ”¯æŒX-GRMçš„è®­ç»ƒï¼Œæˆ‘ä»¬æ”¶é›†äº†ReconX-15Kå¤§è§„æ¨¡CTé‡å»ºæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¤§çº¦15000ä¸ªæ¶µç›–å¤šä¸ªå™¨å®˜çš„CT&#x2F;Xå°„çº¿å¯¹ï¼ŒåŒ…æ‹¬èƒ¸éƒ¨ã€è…¹éƒ¨ã€éª¨ç›†å’Œç‰™é½¿ç­‰ã€‚å¤§å®¹é‡æ¨¡å‹ã€çµæ´»çš„ä½“ç§¯è¡¨ç¤ºå’Œå¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„ç»“åˆä½¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿä»å„ç§æµ‹è¯•è¾“å…¥ä¸­äº§ç”Ÿé«˜è´¨é‡çš„é‡æ„ï¼ŒåŒ…æ‹¬é¢†åŸŸå†…çš„å’Œè·¨é¢†åŸŸçš„Xå°„çº¿æŠ•å½±ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://github.com/CUHK-AIM-Group/X-GRM%E3%80%82">https://github.com/CUHK-AIM-Group/X-GRMã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15235v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰åœ¨ä¸´åºŠå·¥ä½œæµä¸­çš„é‡è¦æ€§ï¼Œä»¥åŠç°æœ‰çš„CTé‡å»ºæŠ€æœ¯çš„å±€é™æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†X-GRMæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»ç¨€ç–è§†è§’çš„äºŒç»´Xå°„çº¿æŠ•å½±é‡å»ºä¸‰ç»´CTçš„å¤§å‹å‰é¦ˆæ¨¡å‹ã€‚X-GRMé‡‡ç”¨å¯æ‰©å±•çš„åŸºäºå˜å‹å™¨çš„æ¶æ„ï¼Œèƒ½å¤Ÿç¼–ç ä»»æ„æ•°é‡çš„ç¨€ç–Xå°„çº¿è¾“å…¥ï¼Œå¹¶æœ‰æ•ˆåœ°æ•´åˆä¸åŒè§†è§’çš„æ ‡è®°ã€‚ç„¶åï¼Œè¿™äº›æ ‡è®°è¢«è§£ç æˆä¸€ç§æ–°çš„ä½“ç§¯è¡¨ç¤ºâ€”â€”åŸºäºä½“ç´ çš„é«˜æ–¯å–·æº…ï¼ˆVoxGSï¼‰ï¼Œè¿™æœ‰åŠ©äºé«˜æ•ˆåœ°è¿›è¡ŒCTä½“ç§¯æå–å’Œå¯å¾®åˆ†Xå°„çº¿æ¸²æŸ“ã€‚ä¸ºäº†æ”¯æŒX-GRMçš„è®­ç»ƒï¼Œç ”ç©¶è€…è¿˜æ”¶é›†äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„CTé‡å»ºæ•°æ®é›†ReconX-15Kï¼ŒåŒ…å«å¤§çº¦1.5ä¸‡ä¸ªCT&#x2F;Xå°„çº¿é…å¯¹ï¼Œæ¶µç›–äº†å¤šä¸ªå™¨å®˜ç±»å‹ã€‚æ¨¡å‹èƒ½å¤Ÿä»å¤šç§æµ‹è¯•è¾“å…¥ä¸­äº§ç”Ÿé«˜è´¨é‡çš„é‡æ„ç»“æœï¼ŒåŒ…æ‹¬é¢†åŸŸå†…çš„å’Œè·¨é¢†åŸŸçš„Xå°„çº¿æŠ•å½±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰åœ¨ä¸´åºŠå·¥ä½œæµä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†ç°æœ‰çš„CTé‡å»ºæŠ€æœ¯å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>X-GRMæ¨¡å‹æ˜¯ä¸€ä¸ªç”¨äºä»ç¨€ç–è§†è§’çš„äºŒç»´Xå°„çº¿æŠ•å½±é‡å»ºä¸‰ç»´CTçš„å¤§å‹å‰é¦ˆæ¨¡å‹ã€‚</li>
<li>X-GRMé‡‡ç”¨åŸºäºå˜å‹å™¨çš„å¯æ‰©å±•æ¶æ„è¿›è¡Œç¼–ç å’Œæ•´åˆä¸åŒè§†è§’çš„æ ‡è®°ã€‚</li>
<li>X-GRMé‡‡ç”¨æ–°çš„ä½“ç§¯è¡¨ç¤ºæ–¹æ³•â€”â€”åŸºäºä½“ç´ çš„é«˜æ–¯å–·æº…ï¼ˆVoxGSï¼‰ã€‚</li>
<li>VoxGSæœ‰åŠ©äºé«˜æ•ˆCTä½“ç§¯æå–å’Œå¯å¾®åˆ†Xå°„çº¿æ¸²æŸ“ã€‚</li>
<li>æ”¯æŒX-GRMè®­ç»ƒçš„å¤§å‹CTé‡å»ºæ•°æ®é›†ReconX-15KåŒ…å«å¤šç§å™¨å®˜ç±»å‹çš„1.5ä¸‡ä¸ªCT&#x2F;Xå°„çº¿é…å¯¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15235">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db094be52d587e70669e1fbcd90e6900.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3b6bcf6250d03a7172ed10c9447d681.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03db5e24ab0081795990b96e9d95ec5a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="GT-2-GS-Geometry-aware-Texture-Transfer-for-Gaussian-Splatting"><a href="#GT-2-GS-Geometry-aware-Texture-Transfer-for-Gaussian-Splatting" class="headerlink" title="GT^2-GS: Geometry-aware Texture Transfer for Gaussian Splatting"></a>GT^2-GS: Geometry-aware Texture Transfer for Gaussian Splatting</h2><p><strong>Authors:Wenjie Liu, Zhongliang Liu, Junwei Shu, Changbo Wang, Yang Li</strong></p>
<p>Transferring 2D textures to 3D modalities is of great significance for improving the efficiency of multimedia content creation. Existing approaches have rarely focused on transferring image textures onto 3D representations. 3D style transfer methods are capable of transferring abstract artistic styles to 3D scenes. However, these methods often overlook the geometric information of the scene, which makes it challenging to achieve high-quality 3D texture transfer results. In this paper, we present GT^2-GS, a geometry-aware texture transfer framework for gaussian splitting. From the perspective of matching texture features with geometric information in rendered views, we identify the issue of insufficient texture features and propose a geometry-aware texture augmentation module to expand the texture feature set. Moreover, a geometry-consistent texture loss is proposed to optimize texture features into the scene representation. This loss function incorporates both camera pose and 3D geometric information of the scene, enabling controllable texture-oriented appearance editing. Finally, a geometry preservation strategy is introduced. By alternating between the texture transfer and geometry correction stages over multiple iterations, this strategy achieves a balance between learning texture features and preserving geometric integrity. Extensive experiments demonstrate the effectiveness and controllability of our method. Through geometric awareness, our approach achieves texture transfer results that better align with human visual perception. Our homepage is available at <a target="_blank" rel="noopener" href="https://vpx-ecnu.github.io/GT2-GS-website">https://vpx-ecnu.github.io/GT2-GS-website</a>. </p>
<blockquote>
<p>å°†äºŒç»´çº¹ç†è½¬ç§»åˆ°ä¸‰ç»´æ¨¡æ€å¯¹äºæé«˜å¤šåª’ä½“å†…å®¹åˆ›å»ºæ•ˆç‡å…·æœ‰é‡è¦æ„ä¹‰ã€‚ç°æœ‰æ–¹æ³•å¾ˆå°‘å…³æ³¨å°†å›¾åƒçº¹ç†è½¬ç§»åˆ°ä¸‰ç»´è¡¨ç¤ºä¸Šã€‚ä¸‰ç»´é£æ ¼è½¬ç§»æ–¹æ³•èƒ½å¤Ÿå°†æŠ½è±¡çš„è‰ºæœ¯é£æ ¼è½¬ç§»åˆ°ä¸‰ç»´åœºæ™¯ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å¿½ç•¥äº†åœºæ™¯çš„ä¸‰ç»´å‡ ä½•ä¿¡æ¯ï¼Œä½¿å¾—å®ç°é«˜è´¨é‡çš„ä¸‰ç»´çº¹ç†è½¬ç§»ç»“æœå…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GT^2-GSï¼Œä¸€ä¸ªç”¨äºé«˜æ–¯åˆ†å‰²çš„å‡ ä½•æ„ŸçŸ¥çº¹ç†è½¬ç§»æ¡†æ¶ã€‚ä»åŒ¹é…æ¸²æŸ“è§†å›¾ä¸­çš„çº¹ç†ç‰¹å¾å’Œå‡ ä½•ä¿¡æ¯çš„è§’åº¦ï¼Œæˆ‘ä»¬å‘ç°äº†çº¹ç†ç‰¹å¾ä¸è¶³çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå‡ ä½•æ„ŸçŸ¥çº¹ç†å¢å¼ºæ¨¡å—æ¥æ‰©å±•çº¹ç†ç‰¹å¾é›†ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§å‡ ä½•ä¸€è‡´çš„çº¹ç†æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºä¸­çš„çº¹ç†ç‰¹å¾ã€‚è¯¥æŸå¤±å‡½æ•°ç»“åˆäº†åœºæ™¯çš„ç›¸æœºå§¿æ€å’Œä¸‰ç»´å‡ ä½•ä¿¡æ¯ï¼Œå®ç°äº†å¯æ§çš„çº¹ç†å¯¼å‘çš„å¤–è§‚ç¼–è¾‘ã€‚æœ€åï¼Œå¼•å…¥äº†ä¸€ç§å‡ ä½•ä¿ç•™ç­–ç•¥ã€‚é€šè¿‡å¤šæ¬¡è¿­ä»£åœ¨çº¹ç†è½¬ç§»å’Œå‡ ä½•æ ¡æ­£é˜¶æ®µä¹‹é—´äº¤æ›¿è¿›è¡Œï¼Œè¯¥ç­–ç•¥å®ç°äº†å­¦ä¹ çº¹ç†ç‰¹å¾å’Œä¿æŒå‡ ä½•å®Œæ•´æ€§ä¹‹é—´çš„å¹³è¡¡ã€‚å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå¯æ§æ€§ã€‚é€šè¿‡å‡ ä½•æ„ŸçŸ¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†æ›´ç¬¦åˆäººç±»è§†è§‰æ„ŸçŸ¥çš„çº¹ç†è½¬ç§»ç»“æœã€‚æˆ‘ä»¬çš„ç½‘ç«™å¯åœ¨<a target="_blank" rel="noopener" href="https://vpx-ecnu.github.io/GT2-GS-website">ç½‘ç«™é“¾æ¥</a>è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15208v1">PDF</a> 15 pages, 16 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å‡ ä½•æ„ŸçŸ¥çš„çº¹ç†è½¬ç§»æ¡†æ¶GT^2-GSï¼Œç”¨äºé«˜æ–¯åˆ†å‰²çš„çº¹ç†è½¬ç§»ã€‚è¯¥æ¡†æ¶ä»åŒ¹é…æ¸²æŸ“è§†å›¾ä¸­çš„çº¹ç†ç‰¹å¾å’Œå‡ ä½•ä¿¡æ¯å‡ºå‘ï¼Œé€šè¿‡å‡ ä½•æ„ŸçŸ¥çº¹ç†å¢å¼ºæ¨¡å—æ‰©å±•çº¹ç†ç‰¹å¾é›†ï¼Œå¹¶æå‡ºå‡ ä½•ä¸€è‡´æ€§çº¹ç†æŸå¤±å‡½æ•°ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºçš„çº¹ç†ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†å‡ ä½•ä¿ç•™ç­–ç•¥ï¼Œé€šè¿‡è¿­ä»£çº¹ç†è½¬ç§»å’Œå‡ ä½•æ ¡æ­£é˜¶æ®µï¼Œå®ç°çº¹ç†ç‰¹å¾å’Œå‡ ä½•å®Œæ•´æ€§çš„å¹³è¡¡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆä¸”å¯æ§ï¼Œé€šè¿‡å‡ ä½•æ„ŸçŸ¥ï¼Œå®ç°äº†æ›´ç¬¦åˆäººç±»è§†è§‰æ„ŸçŸ¥çš„çº¹ç†è½¬ç§»ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å‡ ä½•æ„ŸçŸ¥çº¹ç†è½¬ç§»æ¡†æ¶GT^2-GSï¼Œæ—¨åœ¨æé«˜å¤šåª’ä½“å†…å®¹åˆ›å»ºçš„æ•ˆç‡ã€‚</li>
<li>æ¡†æ¶é€šè¿‡åŒ¹é…æ¸²æŸ“è§†å›¾ä¸­çš„çº¹ç†ç‰¹å¾å’Œå‡ ä½•ä¿¡æ¯ï¼Œè§£å†³äº†ç°æœ‰çº¹ç†è½¬ç§»æ–¹æ³•å¿½ç•¥å‡ ä½•ä¿¡æ¯çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†å‡ ä½•æ„ŸçŸ¥çº¹ç†å¢å¼ºæ¨¡å—ï¼Œä»¥æ‰©å±•çº¹ç†ç‰¹å¾é›†ï¼Œæé«˜çº¹ç†è½¬ç§»çš„è´¨æ„Ÿã€‚</li>
<li>æå‡ºäº†å‡ ä½•ä¸€è‡´æ€§çº¹ç†æŸå¤±å‡½æ•°ï¼Œç»“åˆç›¸æœºå§¿æ€å’Œåœºæ™¯çš„ä¸‰ç»´å‡ ä½•ä¿¡æ¯ï¼Œå®ç°å¯æ§çš„çº¹ç†å¯¼å‘å¤–è§‚ç¼–è¾‘ã€‚</li>
<li>ä»‹ç»äº†å‡ ä½•ä¿ç•™ç­–ç•¥ï¼Œé€šè¿‡è¿­ä»£çº¹ç†è½¬ç§»å’Œå‡ ä½•æ ¡æ­£é˜¶æ®µï¼Œå¹³è¡¡äº†å­¦ä¹ çº¹ç†ç‰¹å¾å’Œä¿æŒå‡ ä½•å®Œæ•´æ€§çš„éœ€æ±‚ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆä¸”å¯æ§ï¼Œèƒ½å¤Ÿå®ç°é«˜è´¨é‡çš„3Dçº¹ç†è½¬ç§»ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15208">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3bfc0945b49dc3bdaa1a96590c7bc01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-401834dfe70fd0817666a5aa77d1a3a1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-10bbd9c0064fed1a506c349cff08c8f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-18285079b410f788adf627f89838ebb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54f3d7f42807bb2c9d857f3565a87b05.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="MonoSplat-Generalizable-3D-Gaussian-Splatting-from-Monocular-Depth-Foundation-Models"><a href="#MonoSplat-Generalizable-3D-Gaussian-Splatting-from-Monocular-Depth-Foundation-Models" class="headerlink" title="MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth   Foundation Models"></a>MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth   Foundation Models</h2><p><strong>Authors:Yifan Liu, Keyu Fan, Weihao Yu, Chenxin Li, Hao Lu, Yixuan Yuan</strong></p>
<p>Recent advances in generalizable 3D Gaussian Splatting have demonstrated promising results in real-time high-fidelity rendering without per-scene optimization, yet existing approaches still struggle to handle unfamiliar visual content during inference on novel scenes due to limited generalizability. To address this challenge, we introduce MonoSplat, a novel framework that leverages rich visual priors from pre-trained monocular depth foundation models for robust Gaussian reconstruction. Our approach consists of two key components: a Mono-Multi Feature Adapter that transforms monocular features into multi-view representations, coupled with an Integrated Gaussian Prediction module that effectively fuses both feature types for precise Gaussian generation. Through the Adapterâ€™s lightweight attention mechanism, features are seamlessly aligned and aggregated across views while preserving valuable monocular priors, enabling the Prediction module to generate Gaussian primitives with accurate geometry and appearance. Through extensive experiments on diverse real-world datasets, we convincingly demonstrate that MonoSplat achieves superior reconstruction quality and generalization capability compared to existing methods while maintaining computational efficiency with minimal trainable parameters. Codes are available at <a target="_blank" rel="noopener" href="https://github.com/CUHK-AIM-Group/MonoSplat">https://github.com/CUHK-AIM-Group/MonoSplat</a>. </p>
<blockquote>
<p>è¿‘æœŸé€šç”¨3Dé«˜æ–¯èåˆæŠ€æœ¯çš„è¿›å±•ï¼Œåœ¨æ— éœ€é’ˆå¯¹åœºæ™¯ä¼˜åŒ–çš„æƒ…å†µä¸‹ï¼Œå·²ç»æ˜¾ç¤ºå‡ºåœ¨å®æ—¶é«˜ä¿çœŸæ¸²æŸ“æ–¹é¢çš„å‰æ™¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä»ç„¶éš¾ä»¥åœ¨æ–°å‹åœºæ™¯æ¨ç†æ—¶å¤„ç†ä¸ç†Ÿæ‚‰çš„è§†è§‰å†…å®¹ï¼Œå…¶æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†MonoSplatè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦åŸºç¡€æ¨¡å‹ä¸­çš„ä¸°å¯Œè§†è§‰å…ˆéªŒæ¥è¿›è¡Œç¨³å¥çš„é«˜æ–¯é‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šMono-Multiç‰¹å¾é€‚é…å™¨ï¼Œå°†å•ç›®ç‰¹å¾è½¬æ¢ä¸ºå¤šè§†è§’è¡¨ç¤ºï¼Œä»¥åŠä¸é›†æˆé«˜æ–¯é¢„æµ‹æ¨¡å—ç›¸ç»“åˆï¼Œæœ‰æ•ˆåœ°èåˆè¿™ä¸¤ç§ç‰¹å¾ç±»å‹ï¼Œä»¥å®ç°ç²¾ç¡®çš„é«˜æ–¯ç”Ÿæˆã€‚é€šè¿‡é€‚é…å™¨çš„è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶ï¼Œç‰¹å¾åœ¨ä¸åŒè§†è§’ä¹‹é—´æ— ç¼å¯¹é½å’Œèšåˆï¼ŒåŒæ—¶ä¿ç•™æœ‰ä»·å€¼çš„å•ç›®å…ˆéªŒï¼Œä½¿é¢„æµ‹æ¨¡å—èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç²¾ç¡®å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚çš„é«˜æ–¯åŸºæœ¬ä½“ã€‚åœ¨å¤šç§çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMonoSplatä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨é‡å»ºè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡å¹¶å…·æœ‰æœ€å°‘çš„å¯è®­ç»ƒå‚æ•°ã€‚ä»£ç å¯ä»<a target="_blank" rel="noopener" href="https://github.com/CUHK-AIM-Group/MonoSplat%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/CUHK-AIM-Group/MonoSplatè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15185v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æ–°ä¸€ä»£é€šç”¨åŒ–3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯æ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œå³å¯å®ç°å®æ—¶é«˜ä¿çœŸæ¸²æŸ“ï¼Œå±•ç°å‡ºè‰¯å¥½å‰æ™¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æ¨ç†é˜¶æ®µé‡åˆ°çš„æ–°åœºæ™¯ä¸­çš„æœªçŸ¥è§†è§‰å†…å®¹æ—¶ï¼Œä»é¢ä¸´æ³›åŒ–æ€§æœ‰é™çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºMonoSplatæ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒå•ç›®æ·±åº¦åŸºç¡€æ¨¡å‹ä¸­çš„ä¸°å¯Œè§†è§‰å…ˆéªŒä¿¡æ¯ï¼Œè¿›è¡Œç¨³å¥çš„é«˜æ–¯é‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šMono-Multiç‰¹å¾é€‚é…å™¨ï¼Œå°†å•ç›®ç‰¹å¾è½¬æ¢ä¸ºå¤šè§†è§’è¡¨ç¤ºï¼Œä»¥åŠä¸é›†æˆé«˜æ–¯é¢„æµ‹æ¨¡å—ç›¸ç»“åˆï¼Œæœ‰æ•ˆèåˆè¿™ä¸¤ç§ç‰¹å¾ç±»å‹ï¼Œè¿›è¡Œç²¾ç¡®çš„é«˜æ–¯ç”Ÿæˆã€‚é€šè¿‡é€‚é…å™¨çš„è½»é‡åŒ–æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸åŒè§†è§’çš„ç‰¹å¾èƒ½å¤Ÿæ— ç¼å¯¹é½å’Œèšåˆï¼ŒåŒæ—¶ä¿ç•™å®è´µçš„å•ç›®å…ˆéªŒä¿¡æ¯ï¼Œä½¿é¢„æµ‹æ¨¡å—èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç²¾ç¡®å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚çš„é«˜æ–¯åŸºæœ¬ä½“ã€‚åœ¨å¤šç§çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMonoSplatç›¸è¾ƒäºç°æœ‰æ–¹æ³•å®ç°äº†æ›´é«˜çš„é‡å»ºè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡ä¸”å¯è®­ç»ƒå‚æ•°æœ€å°‘ã€‚ç›¸å…³ä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/CUHK-AIM-Group/MonoSplat">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å¼•å…¥MonoSplatæ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦åŸºç¡€æ¨¡å‹ä¸­çš„è§†è§‰å…ˆéªŒä¿¡æ¯ï¼Œå¢å¼ºé«˜æ–¯é‡å»ºçš„ç¨³å¥æ€§ã€‚</li>
<li>æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šMono-Multiç‰¹å¾é€‚é…å™¨ä¸é›†æˆé«˜æ–¯é¢„æµ‹æ¨¡å—ï¼Œå®ç°ç‰¹å¾çš„ç±»å‹è½¬æ¢å’Œç²¾ç¡®é«˜æ–¯ç”Ÿæˆã€‚</li>
<li>é€‚é…å™¨é€šè¿‡è½»é‡åŒ–æ³¨æ„åŠ›æœºåˆ¶æ— ç¼å¯¹é½å’Œèšåˆä¸åŒè§†è§’çš„ç‰¹å¾ï¼ŒåŒæ—¶ä¿ç•™å•ç›®å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>MonoSplatåœ¨å¤šç§çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†è¾ƒé«˜çš„é‡å»ºè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•ä¿æŒè®¡ç®—æ•ˆç‡ä¸”å¯è®­ç»ƒå‚æ•°æœ€å°‘ã€‚</li>
<li>ç›¸å…³ä»£ç å·²å…¬å¼€ï¼Œæ–¹ä¾¿ç ”ç©¶è€…å’Œå¼€å‘è€…è¿›ä¸€æ­¥æ¢ç´¢å’Œæ”¹è¿›ã€‚</li>
<li>MonoSplatä¸ºå¤„ç†æ–°åœºæ™¯ä¸­çš„æœªçŸ¥è§†è§‰å†…å®¹æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15185">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dc12ffecb6cdaac593875b159d8990a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e9dca4a15b577499031d9413764bf72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8388c6b583cb7a5ac5cb1a2ca0ded7c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a4ccb001821fc97e67391527141e989.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Consistent-Quantity-Quality-Control-across-Scenes-for-Deployment-Aware-Gaussian-Splatting"><a href="#Consistent-Quantity-Quality-Control-across-Scenes-for-Deployment-Aware-Gaussian-Splatting" class="headerlink" title="Consistent Quantity-Quality Control across Scenes for Deployment-Aware   Gaussian Splatting"></a>Consistent Quantity-Quality Control across Scenes for Deployment-Aware   Gaussian Splatting</h2><p><strong>Authors:Fengdi Zhang, Hongkun Cao, Ruqi Huang</strong></p>
<p>To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks to minimize the number of Gaussians used while preserving high rendering quality, introducing an inherent trade-off between Gaussian quantity and rendering quality. Existing methods strive for better quantity-quality performance, but lack the ability for users to intuitively adjust this trade-off to suit practical needs such as model deployment under diverse hardware and communication constraints. Here, we present ControlGS, a 3DGS optimization method that achieves semantically meaningful and cross-scene consistent quantity-quality control. Through a single training run using a fixed setup and a user-specified hyperparameter reflecting quantity-quality preference, ControlGS can automatically find desirable quantity-quality trade-off points across diverse scenes, from compact objects to large outdoor scenes. It also outperforms baselines by achieving higher rendering quality with fewer Gaussians, and supports a broad adjustment range with stepless control over the trade-off. Project page: <a target="_blank" rel="noopener" href="https://zhang-fengdi.github.io/ControlGS/">https://zhang-fengdi.github.io/ControlGS/</a> </p>
<blockquote>
<p>ä¸ºäº†å‡å°‘å­˜å‚¨å’Œè®¡ç®—æˆæœ¬ï¼Œ3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰æ—¨åœ¨å‡å°‘ä½¿ç”¨çš„é«˜æ–¯æ•°é‡ï¼ŒåŒæ—¶ä¿æŒé«˜æ¸²æŸ“è´¨é‡ï¼Œä»è€Œåœ¨é«˜æ–¯æ•°é‡å’Œæ¸²æŸ“è´¨é‡ä¹‹é—´å¼•å…¥å›ºæœ‰çš„æƒè¡¡ã€‚ç°æœ‰æ–¹æ³•åŠªåŠ›æå‡æ•°é‡ä¸è´¨é‡çš„æ€§èƒ½ï¼Œä½†ç¼ºä¹è®©ç”¨æˆ·èƒ½å¤Ÿç›´è§‚åœ°è°ƒæ•´è¿™ç§æƒè¡¡ä»¥é€‚åº”å®é™…éœ€æ±‚çš„èƒ½åŠ›ï¼Œä¾‹å¦‚åœ¨å„ç§ç¡¬ä»¶å’Œé€šä¿¡çº¦æŸä¸‹è¿›è¡Œæ¨¡å‹éƒ¨ç½²ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†ControlGSï¼Œè¿™æ˜¯ä¸€ç§3DGSä¼˜åŒ–æ–¹æ³•ï¼Œå®ç°äº†è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰å’Œè·¨åœºæ™¯ä¸€è‡´çš„æ•°é‡ä¸è´¨é‡æ§åˆ¶ã€‚é€šè¿‡ä¸€æ¬¡å›ºå®šçš„è®¾ç½®å’Œç”¨æˆ·æŒ‡å®šçš„åæ˜ æ•°é‡ä¸è´¨é‡åå¥½çš„è¶…å‚æ•°è®­ç»ƒè¿è¡Œï¼ŒControlGSå¯ä»¥åœ¨å„ç§åœºæ™¯ä¸­è‡ªåŠ¨æ‰¾åˆ°ç†æƒ³çš„è´¨é‡ä¸æ•°é‡æƒè¡¡ç‚¹ï¼Œä»ç´§å‡‘çš„å¯¹è±¡åˆ°å¤§å‹å®¤å¤–åœºæ™¯ã€‚å®ƒè¿˜é€šè¿‡ç”¨æ›´å°‘çš„é«˜æ–¯å®ç°æ›´é«˜çš„æ¸²æŸ“è´¨é‡è¶…è¶Šäº†åŸºçº¿ï¼Œå¹¶æ”¯æŒå¹¿æ³›çš„è°ƒæ•´èŒƒå›´å’Œæ— ç¼æ§åˆ¶æƒè¡¡ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://zhang-fengdi.github.io/ControlGS/">https://zhang-fengdi.github.io/ControlGS/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10473v2">PDF</a> 16 pages, 7 figures, 7 tables. Project page available at   <a target="_blank" rel="noopener" href="https://zhang-fengdi.github.io/ControlGS/">https://zhang-fengdi.github.io/ControlGS/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†æ§åˆ¶3Dé«˜æ–¯æ‹¼æ¥ï¼ˆControlGSï¼‰æ–¹æ³•ï¼Œæ­¤æ–¹æ³•æ—¨åœ¨ä¼˜åŒ–æ¸²æŸ“è´¨é‡å’Œä½¿ç”¨çš„é«˜æ–¯æ•°é‡ä¹‹é—´çš„æƒè¡¡ã€‚ControlGSèƒ½å¤Ÿåœ¨ä¸€æ¬¡è®­ç»ƒè¿è¡Œä¸­è‡ªåŠ¨æ‰¾åˆ°åœºæ™¯é—´çš„æœ€ä½³å¹³è¡¡ï¼Œå¹¶æä¾›ç”¨æˆ·å¯è°ƒèŠ‚çš„åå¥½å‚æ•°ï¼Œä»¥å®ç°çµæ´»çš„é«˜æ–¯æ•°é‡ä¸æ¸²æŸ“è´¨é‡ä¹‹é—´çš„å¹³è¡¡ã€‚åŒæ—¶ï¼ŒControlGSå®ç°äº†æ›´é«˜è´¨é‡çš„æ¸²æŸ“ï¼Œä½¿ç”¨äº†æ›´å°‘çš„é«˜æ–¯æ•°é‡ï¼Œå¹¶ä¸”æä¾›äº†å¹¿æ³›çš„è°ƒæ•´èŒƒå›´å’Œè¿ç»­çš„æ§åˆ¶æƒè¡¡èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ControlGSæ˜¯ä¸€ç§ä¼˜åŒ–æ–¹æ³•ï¼Œç”¨äºæ§åˆ¶ä¸‰ç»´é«˜æ–¯æ‹¼æ¥ä¸­çš„é«˜æ–¯æ•°é‡å’Œæ¸²æŸ“è´¨é‡ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>ç”¨æˆ·å¯ä»¥é€šè¿‡æŒ‡å®šçš„è¶…å‚æ•°åæ˜ å…¶å¯¹æ•°é‡ä¸è´¨é‡çš„åå¥½ã€‚</li>
<li>ControlGSèƒ½å¤Ÿåœ¨ä¸åŒåœºæ™¯ä¹‹é—´è‡ªåŠ¨æ‰¾åˆ°æœ€ä½³æ•°é‡ä¸è´¨é‡ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å•æ¬¡è®­ç»ƒå³å¯å®ç°è¿™ä¸€ç›®æ ‡ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ç´§å‡‘ç‰©ä½“å’Œå¤§å‹å®¤å¤–åœºæ™¯ç­‰ä¸åŒåœºæ™¯ä¸‹åº”ç”¨ã€‚</li>
<li>ControlGSåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºåŸºå‡†æ–¹æ³•ï¼ŒåŒæ—¶ä½¿ç”¨äº†æ›´å°‘çš„é«˜æ–¯æ•°é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10473">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-830b666bd569e79498eb1e0f782cb1ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34a8e0c630fbc54a0eb59f7488aa85d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b8aca5f8cdf0656dea72f0d3243bce9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cce0b8b69f3ee09ba3ca812cca8f8e92.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="OpenFly-A-Comprehensive-Platform-for-Aerial-Vision-Language-Navigation"><a href="#OpenFly-A-Comprehensive-Platform-for-Aerial-Vision-Language-Navigation" class="headerlink" title="OpenFly: A Comprehensive Platform for Aerial Vision-Language Navigation"></a>OpenFly: A Comprehensive Platform for Aerial Vision-Language Navigation</h2><p><strong>Authors:Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang, Liansheng Wang, Penghui Yang, Yiwen Tang, Yuhang Tang, Shuai Liang, Songyi Zhu, Ziqin Xiong, Yifei Su, Xinyi Ye, Jianan Li, Yan Ding, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li</strong></p>
<p>Vision-Language Navigation (VLN) aims to guide agents by leveraging language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose OpenFly, a platform comprising various rendering engines, a versatile toolchain, and a large-scale benchmark for aerial VLN. Firstly, we integrate diverse rendering engines and advanced techniques for environment simulation, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of our environments. Secondly, we develop a highly automated toolchain for aerial VLN data collection, streamlining point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Thirdly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. Moreover, we propose OpenFly-Agent, a keyframe-aware VLN model emphasizing key observations during flight. For benchmarking, extensive experiments and analyses are conducted, evaluating several recent VLN methods and showcasing the superiority of our OpenFly platform and agent. The toolchain, dataset, and codes will be open-sourced. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ—¨åœ¨é€šè¿‡è¯­è¨€æŒ‡ä»¤å’Œè§†è§‰çº¿ç´¢æ¥å¼•å¯¼ä»£ç†ï¼Œåœ¨åµŒå…¥å¼äººå·¥æ™ºèƒ½ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚å®¤å†…VLNå·²ç»å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶ï¼Œè€Œæˆ·å¤–ç©ºä¸­VLNä»ç„¶è¢«è¾ƒå°‘æ¢ç´¢ã€‚å¯èƒ½çš„åŸå› æ˜¯æˆ·å¤–ç©ºä¸­è§†è§’æ¶‰åŠå¤§ç‰‡åŒºåŸŸï¼Œä½¿å¾—æ•°æ®æ”¶é›†æ›´å…·æŒ‘æˆ˜æ€§ï¼Œä»è€Œå¯¼è‡´ç¼ºä¹åŸºå‡†æµ‹è¯•ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†OpenFlyå¹³å°ï¼Œè¯¥å¹³å°åŒ…æ‹¬å„ç§æ¸²æŸ“å¼•æ“ã€é€šç”¨å·¥å…·é“¾å’Œç”¨äºç©ºä¸­VLNçš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é›†æˆäº†å¤šç§æ¸²æŸ“å¼•æ“å’Œå…ˆè¿›çš„ç¯å¢ƒæ¨¡æ‹ŸæŠ€æœ¯ï¼ŒåŒ…æ‹¬Unreal Engineã€GTA Vã€Google Earthå’Œ3Dé«˜æ–¯å¹³æ¿å°åˆ·æœ¯ï¼ˆ3D GSï¼‰ã€‚ç‰¹åˆ«æ˜¯ï¼Œ3D GSæ”¯æŒçœŸå®åˆ°æ¨¡æ‹Ÿæ¸²æŸ“ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†æˆ‘ä»¬çš„ç¯å¢ƒçœŸå®æ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªé«˜åº¦è‡ªåŠ¨åŒ–çš„ç©ºä¸­VLNæ•°æ®æ”¶é›†å·¥å…·é“¾ï¼Œç”¨äºç‚¹äº‘é‡‡é›†ã€åœºæ™¯è¯­ä¹‰åˆ†å‰²ã€é£è¡Œè½¨è¿¹åˆ›å»ºå’ŒæŒ‡ä»¤ç”Ÿæˆã€‚ç¬¬ä¸‰ï¼ŒåŸºäºå·¥å…·é“¾ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„ç©ºä¸­VLNæ•°æ®é›†ï¼ŒåŒ…å«10ä¸‡æ¡è½¨è¿¹ï¼Œè¦†ç›–18ä¸ªåœºæ™¯çš„å¤šç§é«˜åº¦å’Œé•¿åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†OpenFly-Agentï¼Œä¸€ä¸ªå…³é”®å¸§æ„ŸçŸ¥çš„VLNæ¨¡å‹ï¼Œå¼ºè°ƒé£è¡Œè¿‡ç¨‹ä¸­çš„å…³é”®è§‚å¯Ÿã€‚ä¸ºäº†è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒå’Œåˆ†æï¼Œè¯„ä¼°äº†å‡ ç§æœ€æ–°çš„VLNæ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†æˆ‘ä»¬çš„OpenFlyå¹³å°å’Œä»£ç†çš„ä¼˜åŠ¿ã€‚å·¥å…·é“¾ã€æ•°æ®é›†å’Œä»£ç å°†å¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18041v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰çš„ç ”ç©¶ï¼Œç‰¹åˆ«å¼ºè°ƒäº†æˆ·å¤–é«˜ç©ºè§†è§’å¯¼èˆªçš„æ½œåœ¨ä»·å€¼åŠå…¶æŒ‘æˆ˜ã€‚æ–‡ç« æå‡ºä¸€ä¸ªåä¸ºOpenFlyçš„å¹³å°ï¼Œé›†æˆå¤šç§æ¸²æŸ“å¼•æ“ã€å…ˆè¿›ä»¿çœŸæŠ€æœ¯å’Œä¸€ä¸ªå¤§è§„æ¨¡çš„ç©ºä¸­VLNæ•°æ®é›†ï¼Œä¸ºæ•°æ®æ”¶é›†å’Œç¯å¢ƒæ¨¡æ‹Ÿæä¾›ä¾¿æ·çš„å·¥å…·é“¾ã€‚è¯¥å¹³å°åŒ…å«ä¸€ä¸ªé’ˆå¯¹é«˜ç©ºè§†è§’å¯¼èˆªè®¾è®¡çš„å¯¼èˆªæ¨¡å‹ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶ä¼˜è¶Šæ€§ã€‚æ–‡ç« æ—¨åœ¨æ¨åŠ¨ç©ºä¸­VLNçš„ç ”ç©¶è¿›å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLNç»“åˆäº†è¯­è¨€æŒ‡ä»¤å’Œè§†è§‰çº¿ç´¢ï¼Œå¯¹äºå®é™…æœºå™¨äººçš„è¡Œä¸ºå…·æœ‰é‡è¦æ„ä¹‰ã€‚å®¤å†…ç ”ç©¶å……åˆ†ï¼Œè€Œé«˜ç©ºè§†è§’ä¸‹çš„ç ”ç©¶ä¸è¶³æ˜¯ç”±äºé«˜ç©ºæ•°æ®æ”¶é›†çš„å¤æ‚æ€§æ‰€è‡´ã€‚æå‡ºä¸€ä¸ªæ–°çš„OpenFlyå¹³å°ï¼Œè§£å†³æ•°æ®æ”¶é›†çš„é—®é¢˜ã€‚</li>
<li>OpenFlyå¹³å°åŒ…å«å¤šç§æ¸²æŸ“å¼•æ“å’Œä»¿çœŸæŠ€æœ¯ï¼ŒåŒ…æ‹¬Unreal Engineã€GTA Vç­‰å…ˆè¿›å¼•æ“ä»¥åŠä¸“ä¸ºé«˜ç©ºè§†è§’è®¾è®¡çš„å®æ—¶æ¨¡æ‹Ÿæ¸²æŸ“æŠ€æœ¯ï¼ˆå¦‚3D GSï¼‰ã€‚è¿™äº›æŠ€æœ¯å¢å¼ºäº†ç¯å¢ƒçš„çœŸå®æ„Ÿã€‚</li>
<li>OpenFlyå¼€å‘äº†ä¸€ä¸ªé«˜åº¦è‡ªåŠ¨åŒ–çš„å·¥å…·é“¾ï¼Œç”¨äºé«˜ç©ºVLNæ•°æ®æ”¶é›†ï¼ŒåŒ…æ‹¬ç‚¹äº‘è·å–ã€åœºæ™¯è¯­ä¹‰åˆ†å‰²ã€é£è¡Œè½¨è¿¹åˆ›å»ºå’ŒæŒ‡ä»¤ç”Ÿæˆç­‰ç¯èŠ‚ã€‚è¿™ä½¿å¾—æ„å»ºå¤§è§„æ¨¡é«˜ç©ºVLNæ•°æ®é›†å˜å¾—é«˜æ•ˆä¸”å¯èƒ½ã€‚OpenFlyåŸºäºè¿™ä¸ªå·¥å…·é“¾åˆ›å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„é«˜ç©ºVLNæ•°æ®é›†ï¼ŒåŒ…å«è¦†ç›–ä¸åŒé«˜åº¦å’Œé•¿åº¦çš„åœºæ™¯è¾¾åˆ°1ä¸‡æ¡è½¨è¿¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18041">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-86c28bef348c9cbd2db269c3e00b881d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18eba59ba848bcf8eb8794610cb96533.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-15860a1fe81b72557546445e8b331ba0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c923fc96bb4894bcbdbfe34600689443.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Volumetrically-Consistent-3D-Gaussian-Rasterization"><a href="#Volumetrically-Consistent-3D-Gaussian-Rasterization" class="headerlink" title="Volumetrically Consistent 3D Gaussian Rasterization"></a>Volumetrically Consistent 3D Gaussian Rasterization</h2><p><strong>Authors:Chinmay Talegaonkar, Yash Belhe, Ravi Ramamoorthi, Nicholas Antipa</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS) has enabled photorealistic view synthesis at high inference speeds. However, its splatting-based rendering model makes several approximations to the rendering equation, reducing physical accuracy. We show that the core approximations in splatting are unnecessary, even within a rasterizer; We instead volumetrically integrate 3D Gaussians directly to compute the transmittance across them analytically. We use this analytic transmittance to derive more physically-accurate alpha values than 3DGS, which can directly be used within their framework. The result is a method that more closely follows the volume rendering equation (similar to ray-tracing) while enjoying the speed benefits of rasterization. Our method represents opaque surfaces with higher accuracy and fewer points than 3DGS. This enables it to outperform 3DGS for view synthesis (measured in SSIM and LPIPS). Being volumetrically consistent also enables our method to work out of the box for tomography. We match the state-of-the-art 3DGS-based tomography method with fewer points. Our code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/chinmay0301ucsd/Vol3DGS">https://github.com/chinmay0301ucsd/Vol3DGS</a> </p>
<blockquote>
<p>æœ€è¿‘ï¼Œ3Dé«˜æ–¯Splattingï¼ˆ3DGSï¼‰å·²ç»å®ç°äº†å¿«é€Ÿæ¨ç†ä¸‹çš„é€¼çœŸè§†å›¾åˆæˆã€‚ç„¶è€Œï¼Œå…¶åŸºäºSplattingçš„æ¸²æŸ“æ¨¡å‹å¯¹æ¸²æŸ“æ–¹ç¨‹è¿›è¡Œäº†å¤šä¸ªè¿‘ä¼¼å¤„ç†ï¼Œé™ä½äº†ç‰©ç†å‡†ç¡®æ€§ã€‚æˆ‘ä»¬æ˜¾ç¤ºï¼ŒSplattingä¸­çš„æ ¸å¿ƒè¿‘ä¼¼å€¼åœ¨å…‰æ …åŒ–å™¨ä¸­æ˜¯ä¸å¿…è¦çš„ï¼›ç›¸åï¼Œæˆ‘ä»¬ç›´æ¥åœ¨ä½“ç§¯å†…ç§¯åˆ†3Dé«˜æ–¯å€¼ï¼Œä»¥åˆ†æè®¡ç®—å…¶é€å°„ç‡ã€‚æˆ‘ä»¬ä½¿ç”¨è¿™ç§åˆ†æé€å°„ç‡æ¥å¾—å‡ºæ¯”3DGSæ›´å‡†ç¡®çš„alphaå€¼ï¼Œå¹¶å¯åœ¨å…¶æ¡†æ¶å†…ç›´æ¥ä½¿ç”¨ã€‚ç»“æœæ˜¯ä¸€ç§æ›´ç´§å¯†åœ°éµå¾ªä½“ç§¯æ¸²æŸ“æ–¹ç¨‹ï¼ˆç±»ä¼¼äºå…‰çº¿è¿½è¸ªï¼‰çš„æ–¹æ³•ï¼ŒåŒæ—¶äº«å—å…‰æ …åŒ–çš„é€Ÿåº¦ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä»¥æ›´é«˜çš„ç²¾åº¦å’Œæ›´å°‘çš„ç‚¹æ•°ä»£è¡¨ä¸é€æ˜è¡¨é¢ï¼Œè¶…è¿‡äº†ç”¨äºè§†å›¾åˆæˆçš„3DGSï¼ˆåœ¨SSIMå’ŒLPIPSä¸­æµ‹é‡ï¼‰ã€‚å…¶ä½“ç§¯ä¸€è‡´æ€§è¿˜ä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿè½»æ¾åº”ç”¨äºæ–­å±‚æ‰«æã€‚æˆ‘ä»¬ä½¿ç”¨è¾ƒå°‘çš„ç‚¹ä¸æœ€å…ˆè¿›çš„åŸºäº3DGSçš„æ–­å±‚æ‰«ææ–¹æ³•ç›¸åŒ¹é…ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€å…¬å¼€è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/chinmay0301ucsd/Vol3DGS">https://github.com/chinmay0301ucsd/Vol3DGS</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.03378v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºé«˜æ–¯çš„3Dæ¸²æŸ“æ–¹æ³•è¿‘æœŸè¢«æå‡ºï¼Œè™½ç„¶èƒ½å¤Ÿå®ç°é€¼çœŸçš„åœºæ™¯åˆæˆå¹¶æ‹¥æœ‰é«˜æ•ˆçš„æ¨ç†é€Ÿåº¦ï¼Œä½†åœ¨æ¸²æŸ“æ–¹ç¨‹çš„å¤„ç†è¿‡ç¨‹ä¸­å­˜åœ¨ä¸€å®šç¨‹åº¦çš„è¿‘ä¼¼å¤„ç†ï¼Œä»è€Œå½±å“å…¶ç‰©ç†å‡†ç¡®æ€§ã€‚æœ¬ç ”ç©¶ç›´æ¥å¯¹ä¸‰ç»´é«˜æ–¯è¿›è¡Œä½“ç§¯ç§¯åˆ†ï¼Œè§£æè®¡ç®—å…¶é€å°„ç‡ï¼Œæ—¨åœ¨æä¾›æ›´ç²¾ç¡®çš„ç‰©ç†æ¨¡å‹ã€‚è¯¥æ–¹æ³•çš„æå‡ºç»“åˆäº†é«˜å‡†ç¡®æ€§çš„å…‰çº¿è¿½è¸ªæŠ€æœ¯åŒæ—¶æ‹¥æœ‰é«˜æ•ˆæ¸²æŸ“çš„é€Ÿåº¦ä¼˜åŠ¿ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºç‚¹è¿‘ä¼¼çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹äºä¸é€æ˜è¡¨é¢çš„è¡¨ç¤ºæ›´ä¸ºå‡†ç¡®ä¸”ä½¿ç”¨æ›´å°‘çš„ç‚¹ã€‚æ­¤å¤–ï¼Œå…¶ä½“ç§¯ä¸€è‡´æ€§è¿˜ä½¿å…¶èƒ½åº”ç”¨äºå±‚ææˆåƒæŠ€æœ¯å¹¶è¾¾åˆ°ä¼˜ç§€çš„æ€§èƒ½è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSèƒ½å¤Ÿå®ç°é€¼çœŸçš„åœºæ™¯åˆæˆå¹¶æ‹¥æœ‰é«˜æ•ˆçš„æ¨ç†é€Ÿåº¦ï¼Œä½†åœ¨ç‰©ç†å‡†ç¡®æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>ç ”ç©¶é€šè¿‡ç›´æ¥å¯¹ä¸‰ç»´é«˜æ–¯è¿›è¡Œä½“ç§¯ç§¯åˆ†è®¡ç®—é€å°„ç‡æ¥æé«˜ç‰©ç†å‡†ç¡®æ€§ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†å…‰çº¿è¿½è¸ªçš„é«˜å‡†ç¡®æ€§ä»¥åŠé«˜æ•ˆæ¸²æŸ“çš„é€Ÿåº¦ä¼˜åŠ¿ã€‚</li>
<li>å¯¹äºä¸é€æ˜è¡¨é¢çš„è¡¨ç¤ºç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æ›´ä¸ºå‡†ç¡®ä¸”ä½¿ç”¨æ›´å°‘çš„ç‚¹ã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä½“ç§¯ä¸€è‡´æ€§ä½¿å…¶èƒ½é€‚ç”¨äºå±‚ææˆåƒæŠ€æœ¯å¹¶å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.03378">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-523363565277eccadd0024128844845f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-025e3fd668ea9795946199c03591fac2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8246de84fb8bb02305e59c3604e6ce5d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e05f14fe6836dd798b9db0c9802ee2a.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="VisionPAD-A-Vision-Centric-Pre-training-Paradigm-for-Autonomous-Driving"><a href="#VisionPAD-A-Vision-Centric-Pre-training-Paradigm-for-Autonomous-Driving" class="headerlink" title="VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving"></a>VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving</h2><p><strong>Authors:Haiming Zhang, Wending Zhou, Yiyao Zhu, Xu Yan, Jiantao Gao, Dongfeng Bai, Yingjie Cai, Bingbing Liu, Shuguang Cui, Zhen Li</strong></p>
<p>This paper introduces VisionPAD, a novel self-supervised pre-training paradigm designed for vision-centric algorithms in autonomous driving. In contrast to previous approaches that employ neural rendering with explicit depth supervision, VisionPAD utilizes more efficient 3D Gaussian Splatting to reconstruct multi-view representations using only images as supervision. Specifically, we introduce a self-supervised method for voxel velocity estimation. By warping voxels to adjacent frames and supervising the rendered outputs, the model effectively learns motion cues in the sequential data. Furthermore, we adopt a multi-frame photometric consistency approach to enhance geometric perception. It projects adjacent frames to the current frame based on rendered depths and relative poses, boosting the 3D geometric representation through pure image supervision. Extensive experiments on autonomous driving datasets demonstrate that VisionPAD significantly improves performance in 3D object detection, occupancy prediction and map segmentation, surpassing state-of-the-art pre-training strategies by a considerable margin. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†VisionPADï¼Œè¿™æ˜¯ä¸€ç§ä¸ºè‡ªåŠ¨é©¾é©¶ä¸­çš„ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„ç®—æ³•è®¾è®¡çš„æ–°å‹è‡ªç›‘ç£é¢„è®­ç»ƒèŒƒå¼ã€‚ä¸ä¹‹å‰é‡‡ç”¨å…·æœ‰æ˜ç¡®æ·±åº¦ç›‘ç£çš„ç¥ç»æ¸²æŸ“æ–¹æ³•ä¸åŒï¼ŒVisionPADåˆ©ç”¨æ›´æœ‰æ•ˆçš„3Dé«˜æ–¯SplattingæŠ€æœ¯ï¼Œä»…ä½¿ç”¨å›¾åƒä½œä¸ºç›‘ç£æ¥é‡å»ºå¤šè§†å›¾è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ºä½“ç´ é€Ÿåº¦ä¼°è®¡æå‡ºäº†ä¸€ç§è‡ªç›‘ç£æ–¹æ³•ã€‚é€šè¿‡å°†ä½“ç´ å˜å½¢åˆ°ç›¸é‚»å¸§å¹¶å¯¹æ¸²æŸ“è¾“å‡ºè¿›è¡Œç›‘ç£ï¼Œæ¨¡å‹æœ‰æ•ˆåœ°å­¦ä¹ äº†åºåˆ—æ•°æ®ä¸­çš„è¿åŠ¨çº¿ç´¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨å¤šå¸§å…‰åº¦ä¸€è‡´æ€§æ–¹æ³•æ¥å¢å¼ºå‡ ä½•æ„ŸçŸ¥ã€‚å®ƒæ ¹æ®æ¸²æŸ“æ·±åº¦å’Œç›¸å¯¹å§¿æ€å°†ç›¸é‚»å¸§æŠ•å½±åˆ°å½“å‰å¸§ï¼Œé€šè¿‡çº¯å›¾åƒç›‘ç£å¢å¼º3Då‡ ä½•è¡¨ç¤ºã€‚åœ¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒVisionPADåœ¨3Dç›®æ ‡æ£€æµ‹ã€å ç”¨é¢„æµ‹å’Œåœ°å›¾åˆ†å‰²æ–¹é¢çš„æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æé«˜ï¼Œæ˜¾è‘—è¶…è¶Šäº†æœ€å…ˆè¿›çš„é¢„è®­ç»ƒç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.14716v2">PDF</a> Accepted at CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†VisionPADï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­è§†è§‰ç®—æ³•çš„æ–°å‹è‡ªç›‘ç£é¢„è®­ç»ƒèŒƒå¼ã€‚ä¸ä»¥å¾€é‡‡ç”¨æ˜ç¡®æ·±åº¦ç›‘ç£çš„ç¥ç»æ¸²æŸ“æ–¹æ³•ä¸åŒï¼ŒVisionPADåˆ©ç”¨æ›´æœ‰æ•ˆçš„3Dé«˜æ–¯SplattingæŠ€æœ¯ï¼Œä»…ä½¿ç”¨å›¾åƒä½œä¸ºç›‘ç£æ¥é‡å»ºå¤šè§†è§’è¡¨ç¤ºã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªç›‘ç£çš„ä½“ç´ é€Ÿåº¦ä¼°è®¡æ–¹æ³•ã€‚é€šè¿‡é‚»å¸§å˜å½¢å’Œç›‘ç£æ¸²æŸ“è¾“å‡ºï¼Œæ¨¡å‹æœ‰æ•ˆåœ°å­¦ä¹ äº†åºåˆ—æ•°æ®ä¸­çš„è¿åŠ¨çº¿ç´¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨å¤šå¸§å…‰åº¦ä¸€è‡´æ€§æ–¹æ³•ï¼Œä»¥æé«˜å‡ ä½•æ„ŸçŸ¥èƒ½åŠ›ã€‚å®ƒå°†ç›¸é‚»å¸§æŠ•å½±åˆ°å½“å‰å¸§ä¸Šï¼ŒåŸºäºæ¸²æŸ“æ·±åº¦å’Œç›¸å¯¹å§¿æ€ï¼Œé€šè¿‡çº¯å›¾åƒç›‘ç£å¢å¼º3Då‡ ä½•è¡¨ç¤ºã€‚åœ¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒVisionPADåœ¨3Dç›®æ ‡æ£€æµ‹ã€å ç”¨é¢„æµ‹å’Œåœ°å›¾åˆ†å‰²æ–¹é¢çš„æ€§èƒ½å¾—åˆ°æ˜¾è‘—æå‡ï¼Œä¼˜äºå…¶ä»–å…ˆè¿›çš„é¢„è®­ç»ƒç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VisionPADæ˜¯ä¸€ç§é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è§†è§‰ç®—æ³•çš„è‡ªç›‘ç£é¢„è®­ç»ƒèŒƒå¼ã€‚</li>
<li>ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒVisionPADé‡‡ç”¨3Dé«˜æ–¯SplattingæŠ€æœ¯é‡å»ºå¤šè§†è§’è¡¨ç¤ºã€‚</li>
<li>VisionPADåˆ©ç”¨è‡ªç›‘ç£æ–¹æ³•ä¼°è®¡ä½“ç´ é€Ÿåº¦ï¼Œå­¦ä¹ åºåˆ—æ•°æ®ä¸­çš„è¿åŠ¨çº¿ç´¢ã€‚</li>
<li>é€šè¿‡å¤šå¸§å…‰åº¦ä¸€è‡´æ€§æ–¹æ³•å¢å¼ºå‡ ä½•æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>VisionPADé€šè¿‡æŠ•å½±ç›¸é‚»å¸§åˆ°å½“å‰å¸§æ¥æé«˜3Då‡ ä½•è¡¨ç¤ºã€‚</li>
<li>åœ¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸Šï¼ŒVisionPADæ˜¾è‘—æé«˜äº†3Dç›®æ ‡æ£€æµ‹ã€å ç”¨é¢„æµ‹å’Œåœ°å›¾åˆ†å‰²çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.14716">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cd1b646db3b9ceb6dd96470313d69f72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac354524907b734ddec680a60fd5efcb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c019efddfbad4b028125325e3d6e14c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2985ac443c7217d98c42ce9b4d57a16c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aa1dc94103d0c6f9aef97d79de06a1e7.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-24/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-24/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-24/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d3126b4d9896e174493289f273f89f37.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-24  Seeing through Satellite Images at Street Views
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-24/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fcc274326a03eed48b70734a3a70bc11.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-24  EVA Expressive Virtual Avatars from Multi-view Videos
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24801.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
