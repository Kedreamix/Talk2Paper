<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-10  Hidden Entity Detection from GitHub Leveraging Large Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fab9ca2636ad6eac80ec4eabed11f4e0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    36 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-10-æ›´æ–°"><a href="#2025-01-10-æ›´æ–°" class="headerlink" title="2025-01-10 æ›´æ–°"></a>2025-01-10 æ›´æ–°</h1><h2 id="Hidden-Entity-Detection-from-GitHub-Leveraging-Large-Language-Models"><a href="#Hidden-Entity-Detection-from-GitHub-Leveraging-Large-Language-Models" class="headerlink" title="Hidden Entity Detection from GitHub Leveraging Large Language Models"></a>Hidden Entity Detection from GitHub Leveraging Large Language Models</h2><p><strong>Authors:Lu Gan, Martin Blum, Danilo Dessi, Brigitte Mathiak, Ralf Schenkel, Stefan Dietze</strong></p>
<p>Named entity recognition is an important task when constructing knowledge bases from unstructured data sources. Whereas entity detection methods mostly rely on extensive training data, Large Language Models (LLMs) have paved the way towards approaches that rely on zero-shot learning (ZSL) or few-shot learning (FSL) by taking advantage of the capabilities LLMs acquired during pretraining. Specifically, in very specialized scenarios where large-scale training data is not available, ZSL &#x2F; FSL opens new opportunities. This paper follows this recent trend and investigates the potential of leveraging Large Language Models (LLMs) in such scenarios to automatically detect datasets and software within textual content from GitHub repositories. While existing methods focused solely on named entities, this study aims to broaden the scope by incorporating resources such as repositories and online hubs where entities are also represented by URLs. The study explores different FSL prompt learning approaches to enhance the LLMsâ€™ ability to identify dataset and software mentions within repository texts. Through analyses of LLM effectiveness and learning strategies, this paper offers insights into the potential of advanced language models for automated entity detection. </p>
<blockquote>
<p>ä»éç»“æ„åŒ–æ•°æ®æºæ„å»ºçŸ¥è¯†åº“æ—¶ï¼Œå‘½åå®ä½“è¯†åˆ«æ˜¯ä¸€é¡¹é‡è¦ä»»åŠ¡ã€‚å®ä½“æ£€æµ‹æ–¹æ³•å¤§å¤šä¾èµ–äºå¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ä¸ºä¾èµ–äºé›¶æ ·æœ¬å­¦ä¹ ï¼ˆZSLï¼‰æˆ–å°‘æ ·æœ¬å­¦ä¹ ï¼ˆFSLï¼‰çš„æ–¹æ³•é“ºå¹³äº†é“è·¯ã€‚å®ƒä»¬é€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢„è®­ç»ƒæœŸé—´è·å¾—çš„èƒ½åŠ›æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ç‰¹åˆ«åœ°ï¼Œåœ¨æ— æ³•ä½¿ç”¨å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„é«˜åº¦ä¸“ä¸šåŒ–åœºæ™¯ä¸­ï¼ŒZSL&#x2F;FSLå¸¦æ¥äº†æ–°çš„æœºä¼šã€‚æœ¬æ–‡éµå¾ªè¿™ä¸€æœ€æ–°è¶‹åŠ¿ï¼Œæ¢è®¨äº†åœ¨è¿™ç§åœºæ™¯ä¸­åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨æ£€æµ‹GitHubå­˜å‚¨åº“ä¸­çš„æ•°æ®é›†å’Œè½¯ä»¶èµ„æºçš„æ½œåŠ›ã€‚ç°æœ‰çš„æ–¹æ³•åªä¸“æ³¨äºå‘½åå®ä½“ï¼Œè€Œæœ¬ç ”ç©¶æ—¨åœ¨é€šè¿‡æ•´åˆå­˜å‚¨åº“å’Œåœ¨çº¿ä¸­å¿ƒç­‰èµ„æºï¼ˆå…¶ä¸­å®ä½“ä¹Ÿä»¥URLå½¢å¼è¡¨ç¤ºï¼‰æ¥æ‰©å¤§èŒƒå›´ã€‚è¯¥ç ”ç©¶æ¢ç´¢äº†ä¸åŒçš„FSLæç¤ºå­¦ä¹ æ–¹æ³•æ¥æé«˜LLMåœ¨å­˜å‚¨åº“æ–‡æœ¬ä¸­è¯†åˆ«æ•°æ®é›†å’Œè½¯ä»¶æåŠçš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹LLMçš„æœ‰æ•ˆæ€§å’Œå­¦ä¹ ç­–ç•¥çš„åˆ†æï¼Œæœ¬æ–‡æä¾›äº†å¯¹é«˜çº§è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨å®ä½“æ£€æµ‹æ–¹é¢çš„æ½œåŠ›çš„æ·±åˆ»è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04455v1">PDF</a> accepted by KDD2024 workshop DL4KG</p>
<p><strong>Summary</strong>ï¼š</p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯åœ¨ç¼ºä¹å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨é›¶æ ·æœ¬å­¦ä¹ ï¼ˆZSLï¼‰æˆ–å°‘æ ·æœ¬å­¦ä¹ ï¼ˆFSLï¼‰æŠ€æœ¯åœ¨æ„å»ºçŸ¥è¯†åº“æ—¶è‡ªåŠ¨æ£€æµ‹GitHubå­˜å‚¨åº“ä¸­çš„æ•°æ®é›†å’Œè½¯ä»¶ã€‚æœ¬æ–‡ä¸»è¦æ¢ç´¢ä½¿ç”¨LLMæ¥è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬å†…å®¹ä¸­çš„æ•°æ®é›†å’Œè½¯ä»¶ï¼Œä¸ä»…å…³æ³¨å‘½åå®ä½“è¯†åˆ«ï¼Œè¿˜èå…¥èµ„æºå¦‚å­˜å‚¨åº“å’Œåœ¨çº¿ä¸­å¿ƒï¼Œå…¶ä¸­å®ä½“é€šè¿‡URLè¡¨ç¤ºã€‚é€šè¿‡æ¢ç´¢ä¸åŒçš„FSLæç¤ºå­¦ä¹ æ–¹æ³•ï¼Œå¢å¼ºLLMåœ¨å­˜å‚¨åº“æ–‡æœ¬ä¸­è¯†åˆ«æ•°æ®é›†å’Œè½¯ä»¶çš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹LLMçš„æ•ˆæœå’Œå­¦ä¹ ç­–ç•¥çš„åˆ†æï¼Œä¸ºè‡ªåŠ¨åŒ–å®ä½“æ£€æµ‹æä¾›æ·±å…¥è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿåœ¨ç¼ºä¹å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨é›¶æ ·æœ¬å­¦ä¹ ï¼ˆZSLï¼‰æˆ–å°‘æ ·æœ¬å­¦ä¹ ï¼ˆFSLï¼‰æŠ€æœ¯è¯†åˆ«GitHubå­˜å‚¨åº“ä¸­çš„å®ä½“ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å‘½åå®ä½“è¯†åˆ«ï¼Œè€Œæœ¬æ–‡ç ”ç©¶æ‰©å¤§äº†èŒƒå›´ï¼Œçº³å…¥å¦‚å­˜å‚¨åº“å’Œåœ¨çº¿ä¸­å¿ƒç­‰èµ„æºçš„è€ƒè™‘ã€‚</li>
<li>ç ”ç©¶æ¢ç´¢äº†ä¸åŒçš„FSLæç¤ºå­¦ä¹ æ–¹æ³•æ¥å¢å¼ºLLMåœ¨å­˜å‚¨åº“æ–‡æœ¬ä¸­è¯†åˆ«æ•°æ®é›†å’Œè½¯ä»¶çš„èƒ½åŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶é€šè¿‡å¯¹LLMçš„æœ‰æ•ˆæ€§å’Œå­¦ä¹ ç­–ç•¥çš„åˆ†æï¼Œä¸ºè‡ªåŠ¨åŒ–å®ä½“æ£€æµ‹æä¾›äº†è§è§£ã€‚</li>
<li>å€ŸåŠ©LLMçš„æŠ€æœ¯å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç®€åŒ–å¹¶æ”¹è¿›æ•°æ®é›†åˆå’Œè½¯ä»¶åŒ…çš„æ£€æµ‹ä¸è¯†åˆ«ã€‚</li>
<li>URLçš„å¼•å…¥å¢å¼ºäº†å®ä½“è¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå› ä¸ºè®¸å¤šæ•°æ®é›†å’Œè½¯ä»¶çš„å¼•ç”¨éƒ½åŒ…å«URLé“¾æ¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04455">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6a41a168e56612e8792b77d690cdb1ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c89543b75437b3d3f9c82ddbb0b5b10b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1f18f7fff3c7cd82076faed0eb309aa.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DispFormer-Pretrained-Transformer-for-Flexible-Dispersion-Curve-Inversion-from-Global-Synthesis-to-Regional-Applications"><a href="#DispFormer-Pretrained-Transformer-for-Flexible-Dispersion-Curve-Inversion-from-Global-Synthesis-to-Regional-Applications" class="headerlink" title="DispFormer: Pretrained Transformer for Flexible Dispersion Curve   Inversion from Global Synthesis to Regional Applications"></a>DispFormer: Pretrained Transformer for Flexible Dispersion Curve   Inversion from Global Synthesis to Regional Applications</h2><p><strong>Authors:Feng Liu, Bao Deng, Rui Su, Lei Bai, Wanli Ouyang</strong></p>
<p>Surface wave dispersion curve inversion is essential for estimating subsurface Shear-wave velocity ($v_s$), yet traditional methods often struggle to balance computational efficiency with inversion accuracy. While deep learning approaches show promise, previous studies typically require large amounts of labeled data and struggle with real-world datasets that have varying period ranges, missing data, and low signal-to-noise ratios. This study proposes DispFormer, a transformer-based neural network for inverting the $v_s$ profile from Rayleigh-wave phase and group dispersion curves. DispFormer processes dispersion data at each period independently, thereby allowing it to handle data of varying lengths without requiring network modifications or alignment between training and testing data. The performance is demonstrated by pre-training it on a global synthetic dataset and testing it on two regional synthetic datasets using zero-shot and few-shot strategies. Results indicate that zero-shot DispFormer, even without any labeled data, produces inversion profiles that match well with the ground truth, providing a deployable initial model generator to assist traditional methods. When labeled data is available, few-shot DispFormer outperforms traditional methods with only a small number of labels. Furthermore, real-world tests indicate that DispFormer effectively handles varying length data, and yields lower data residuals than reference models. These findings demonstrate that DispFormer provides a robust foundation model for dispersion curve inversion and is a promising approach for broader applications. </p>
<blockquote>
<p>è¡¨é¢æ³¢å¼¥æ•£æ›²çº¿åæ¼”å¯¹äºä¼°è®¡åœ°ä¸‹å‰ªåˆ‡æ³¢é€Ÿåº¦ï¼ˆv_sï¼‰è‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•å¾€å¾€åœ¨è®¡ç®—æ•ˆç‡å’Œåæ¼”ç²¾åº¦ä¹‹é—´éš¾ä»¥å–å¾—å¹³è¡¡ã€‚è™½ç„¶æ·±åº¦å­¦ä¹ æ–¹æ³•æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ä¹‹å‰çš„ç ”ç©¶é€šå¸¸éœ€è¦å¤§é‡æ ‡è®°æ•°æ®ï¼Œå¹¶ä¸”åœ¨å¤„ç†å…·æœ‰ä¸åŒå‘¨æœŸèŒƒå›´ã€ç¼ºå¤±æ•°æ®å’Œä½ä¿¡å™ªæ¯”çš„çœŸå®ä¸–ç•Œæ•°æ®é›†æ—¶é¢ä¸´å›°éš¾ã€‚æœ¬ç ”ç©¶æå‡ºäº†DispFormerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè½¬æ¢å™¨çš„ç¥ç»ç½‘ç»œï¼Œç”¨äºä»ç‘åˆ©æ³¢ç›¸ä½å’Œç¾¤å¼¥æ•£æ›²çº¿åæ¼”v_så‰–é¢ã€‚DispFormerç‹¬ç«‹å¤„ç†æ¯ä¸ªå‘¨æœŸçš„å¼¥æ•£æ•°æ®ï¼Œå› æ­¤èƒ½å¤Ÿå¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®ï¼Œè€Œæ— éœ€å¯¹ç½‘ç»œå’Œè®­ç»ƒå’Œæµ‹è¯•æ•°æ®è¿›è¡Œä¿®æ”¹æˆ–å¯¹é½ã€‚é€šè¿‡åœ¨å…¨çƒåˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨ä¸¤ä¸ªåŒºåŸŸåˆæˆæ•°æ®é›†ä¸Šä½¿ç”¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ç­–ç•¥è¿›è¡Œæµ‹è¯•ï¼ŒéªŒè¯äº†å…¶æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œé›¶æ ·æœ¬DispFormerå³ä½¿æ²¡æœ‰æ ‡è®°æ•°æ®ä¹Ÿèƒ½äº§ç”Ÿä¸çœŸå®æƒ…å†µåŒ¹é…è‰¯å¥½çš„åæ¼”å‰–é¢ï¼Œä¸ºä¼ ç»Ÿæ–¹æ³•æä¾›äº†ä¸€ä¸ªå¯éƒ¨ç½²çš„åˆå§‹æ¨¡å‹ç”Ÿæˆå™¨ã€‚å½“æœ‰æ ‡è®°æ•°æ®æ—¶ï¼Œå°‘æ ·æœ¬DispFormerä»…éœ€å°‘é‡æ ‡ç­¾å°±èƒ½è¶…è¶Šä¼ ç»Ÿæ–¹æ³•ã€‚æ­¤å¤–ï¼ŒçœŸå®ä¸–ç•Œæµ‹è¯•è¡¨æ˜ï¼ŒDispFormeræœ‰æ•ˆå¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®ï¼Œå¹¶ä¸”äº§ç”Ÿçš„æ•°æ®æ®‹å·®ä½äºå‚è€ƒæ¨¡å‹ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒDispFormerä¸ºå¼¥æ•£æ›²çº¿åæ¼”æä¾›äº†ç¨³å¥çš„åŸºç¡€æ¨¡å‹ï¼Œæ˜¯æ›´å¹¿æ³›åº”ç”¨çš„æœ‰å‰é€”çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04366v1">PDF</a> 11 pages, 11 figures, related codes and data are available at   <a target="_blank" rel="noopener" href="https://github.com/liufeng2317/DispFormer">https://github.com/liufeng2317/DispFormer</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå˜å‹å™¨çš„ç¥ç»ç½‘ç»œDispFormerï¼Œç”¨äºä»Rayleighæ³¢ç›¸ä½å’Œç¾¤é€Ÿåº¦è‰²æ•£æ›²çº¿åæ¼”åœ°ä¸‹å‰ªåˆ‡æ³¢é€Ÿåº¦ï¼ˆ$v_s$ï¼‰åˆ†å¸ƒã€‚DispFormerèƒ½å¤Ÿå¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®ï¼Œä¸”æ— éœ€ä¿®æ”¹ç½‘ç»œç»“æ„æˆ–è®­ç»ƒä¸æµ‹è¯•æ•°æ®å¯¹é½ã€‚é€šè¿‡å…¨çƒåˆæˆæ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨ä¸¤ä¸ªåŒºåŸŸåˆæˆæ•°æ®é›†ä¸Šé‡‡ç”¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ç­–ç•¥è¿›è¡Œæµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºé›¶æ ·æœ¬DispFormerå³ä½¿æ²¡æœ‰æ ‡è®°æ•°æ®ä¹Ÿèƒ½ç”Ÿæˆä¸çœŸå®æƒ…å†µåŒ¹é…çš„åæ¼”å‰–é¢ï¼Œä¸ºä¼ ç»Ÿæ–¹æ³•æä¾›äº†å¯éƒ¨ç½²çš„åˆå§‹æ¨¡å‹ç”Ÿæˆå™¨ã€‚å½“ä½¿ç”¨å°‘é‡æ ‡è®°æ•°æ®æ—¶ï¼Œå°‘æ ·æœ¬DispFormerè¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚æ­¤å¤–ï¼Œå®é™…æµ‹è¯•è¡¨æ˜ï¼ŒDispFormerèƒ½æœ‰æ•ˆå¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®ï¼Œå¹¶äº§ç”Ÿè¾ƒä½çš„æ•°æ®æ®‹å·®ã€‚æ€»ä¹‹ï¼ŒDispFormerä¸ºè‰²æ•£æ›²çº¿åæ¼”æä¾›äº†ç¨³å¥çš„åŸºç¡€æ¨¡å‹ï¼Œåœ¨æ›´å¹¿é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DispFormeræ˜¯ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„å˜å‹å™¨æ¶æ„ï¼Œç”¨äºåæ¼”åœ°ä¸‹å‰ªåˆ‡æ³¢é€Ÿåº¦ï¼ˆ$v_s$ï¼‰ã€‚</li>
<li>DispFormerèƒ½å¤Ÿå¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®ï¼Œæ— éœ€è°ƒæ•´ç½‘ç»œç»“æ„æˆ–æ•°æ®å¯¹é½ã€‚</li>
<li>é€šè¿‡å…¨çƒåˆæˆæ•°æ®é›†é¢„è®­ç»ƒçš„DispFormerï¼Œåœ¨é›¶æ ·æœ¬çŠ¶æ€ä¸‹è¡¨ç°å‡ºè‰¯å¥½çš„åæ¼”æ€§èƒ½ã€‚</li>
<li>å½“ä½¿ç”¨å°‘é‡æ ‡è®°æ•°æ®æ—¶ï¼Œå°‘æ ·æœ¬DispFormerä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</li>
<li>DispFormeråœ¨å®é™…æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½æœ‰æ•ˆå¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®å¹¶äº§ç”Ÿè¾ƒä½çš„æ•°æ®æ®‹å·®ã€‚</li>
<li>DispFormerä¸ºè‰²æ•£æ›²çº¿åæ¼”æä¾›äº†ç¨³å¥çš„åŸºç¡€æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04366">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-81d112b711c101e6023573b9369ab351.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e1330185bd5a9bb3da2f82d6a3fe9933.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-408147874b81da5e369f1dbf4545e743.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2b598e0bea196a2ab18a7d1fba6e9d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-521e3099d1d6715728b0393d0124c0fc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4054ffd55fdd710bf9abf18189de8dff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0833568912e078a34d4634f3236334fc.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Online-Gaussian-Test-Time-Adaptation-of-Vision-Language-Models"><a href="#Online-Gaussian-Test-Time-Adaptation-of-Vision-Language-Models" class="headerlink" title="Online Gaussian Test-Time Adaptation of Vision-Language Models"></a>Online Gaussian Test-Time Adaptation of Vision-Language Models</h2><p><strong>Authors:ClÃ©ment Fuchs, Maxime Zanella, Christophe De Vleeschouwer</strong></p>
<p>Online test-time adaptation (OTTA) of vision-language models (VLMs) has recently garnered increased attention to take advantage of data observed along a stream to improve future predictions. Unfortunately, existing methods rely on dataset-specific hyperparameters, significantly limiting their adaptability to unseen tasks. In response, we propose Online Gaussian Adaptation (OGA), a novel method that models the likelihoods of visual features using Gaussian distributions and incorporates zero-shot priors into an interpretable Maximum A Posteriori (MAP) estimation framework with fixed hyper-parameters across all datasets. We demonstrate that OGA outperforms state-of-the-art methods on most datasets and runs. Additionally, we show that combining OTTA with popular few-shot techniques (a practical yet overlooked setting in prior research) is highly beneficial. Furthermore, our experimental study reveals that common OTTA evaluation protocols, which average performance over at most three runs per dataset, are inadequate due to the substantial variability observed across runs for all OTTA methods. Therefore, we advocate for more rigorous evaluation practices, including increasing the number of runs and considering additional quantitative metrics, such as our proposed Expected Tail Accuracy (ETA), calculated as the average accuracy in the worst 10% of runs. We hope these contributions will encourage more rigorous and diverse evaluation practices in the OTTA community. Code is available at <a target="_blank" rel="noopener" href="https://github.com/cfuchs2023/OGA">https://github.com/cfuchs2023/OGA</a> . </p>
<blockquote>
<p>åœ¨çº¿æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆOTTAï¼‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æœ€è¿‘å¼•èµ·äº†äººä»¬çš„å¹¿æ³›å…³æ³¨ï¼Œåˆ©ç”¨è§‚å¯Ÿåˆ°çš„æ•°æ®æµæ¥æ”¹å–„æœªæ¥çš„é¢„æµ‹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºç‰¹å®šæ•°æ®é›†çš„è¶…å‚æ•°ï¼Œæå¤§åœ°é™åˆ¶äº†å®ƒä»¬å¯¹æœªè§ä»»åŠ¡çš„é€‚åº”èƒ½åŠ›ã€‚ä½œä¸ºå›åº”ï¼Œæˆ‘ä»¬æå‡ºäº†åœ¨çº¿é«˜æ–¯é€‚åº”ï¼ˆOGAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œåˆ©ç”¨é«˜æ–¯åˆ†å¸ƒå¯¹è§†è§‰ç‰¹å¾çš„æ¦‚ç‡è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†é›¶æ ·æœ¬å…ˆéªŒèå…¥å¯è§£é‡Šçš„æœ€å¤§åéªŒï¼ˆMAPï¼‰ä¼°è®¡æ¡†æ¶ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½å…·æœ‰å›ºå®šçš„è¶…å‚æ•°ã€‚æˆ‘ä»¬è¯æ˜OGAåœ¨å¤§å¤šæ•°æ•°æ®é›†å’Œè¿è¡Œä¸­çš„è¡¨ç°éƒ½ä¼˜äºæœ€æ–°æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†å°†OTTAä¸æµè¡Œçš„å°‘é‡é•œå¤´æŠ€æœ¯ç›¸ç»“åˆï¼ˆè¿™åœ¨å…ˆå‰çš„ç ”ç©¶ä¸­æ˜¯ä¸€ä¸ªå®ç”¨ä½†è¢«å¿½è§†çš„è®¾ç½®ï¼‰æ˜¯éå¸¸æœ‰ç›Šçš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„å®éªŒç ”ç©¶è¡¨æ˜ï¼Œå¸¸è§çš„OTTAè¯„ä¼°åè®®ï¼ˆåœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šå¹³å‡è¿è¡Œæœ€å¤šä¸‰æ¬¡çš„æ€§èƒ½ï¼‰æ˜¯ä¸å……åˆ†çš„ï¼Œå› ä¸ºæ‰€æœ‰OTTAæ–¹æ³•åœ¨è¿è¡Œä¹‹é—´çš„è§‚å¯Ÿå€¼éƒ½æœ‰å¾ˆå¤§å·®å¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå€¡æ›´ä¸¥æ ¼çš„è¯„ä¼°å®è·µï¼ŒåŒ…æ‹¬å¢åŠ è¿è¡Œæ¬¡æ•°å¹¶è€ƒè™‘é¢å¤–çš„å®šé‡æŒ‡æ ‡ï¼Œå¦‚æˆ‘ä»¬æå‡ºçš„é¢„æœŸå°¾éƒ¨ç²¾åº¦ï¼ˆETAï¼‰ï¼Œè®¡ç®—ä¸ºåœ¨æœ€å·®çš„10%è¿è¡Œä¸­å¹³å‡ç²¾åº¦çš„å€¼ã€‚æˆ‘ä»¬å¸Œæœ›è¿™äº›è´¡çŒ®å°†é¼“åŠ±OTTAç¤¾åŒºé‡‡ç”¨æ›´ä¸¥æ ¼å’Œå¤šæ ·åŒ–çš„è¯„ä¼°å®è·µã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/cfuchs2023/OGA%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/cfuchs2023/OGAæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04352v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åœ¨çº¿é«˜æ–¯é€‚åº”ï¼ˆOGAï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é«˜æ–¯åˆ†å¸ƒå¯¹è§†è§‰ç‰¹å¾è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†é›¶æ ·æœ¬å…ˆéªŒçº³å…¥å¯è§£é‡Šçš„æœ€å¤§åéªŒä¼°è®¡æ¡†æ¶ä¸­ã€‚æ­¤æ–¹æ³•åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½ä½¿ç”¨å›ºå®šçš„è¶…å‚æ•°ï¼Œæé«˜äº†å¯¹ä¸åŒä»»åŠ¡çš„é€‚åº”æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒOGAåœ¨å¤§å¤šæ•°æ•°æ®é›†å’Œè¿è¡Œä¸­çš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç»“åˆåœ¨çº¿æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆOTTAï¼‰å’Œæµè¡Œçš„å°‘æ ·æœ¬æŠ€æœ¯ï¼Œæ•ˆæœæ›´ä½³ã€‚ä½œè€…å¯¹ç°æœ‰çš„OTTAè¯„ä¼°åè®®æå‡ºè´¨ç–‘ï¼Œè®¤ä¸ºç°æœ‰çš„è¯„ä¼°åè®®ä¸è¶³å¤Ÿå…¨é¢å’Œå¯é ï¼Œå»ºè®®é‡‡ç”¨æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹æ³•å’Œæ›´å¤šå®šé‡æŒ‡æ ‡æ¥è¯„ä»·æ¨¡å‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OGAæ–¹æ³•åˆ©ç”¨é«˜æ–¯åˆ†å¸ƒå»ºæ¨¡è§†è§‰ç‰¹å¾ï¼Œæé«˜äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œé¢„æµ‹æ€§èƒ½ã€‚</li>
<li>OGAåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šä½¿ç”¨å›ºå®šè¶…å‚æ•°ï¼Œå¢å¼ºäº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>OGAåœ¨å¤§å¤šæ•°æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>ç»“åˆOTTAå’Œå°‘æ ·æœ¬æŠ€æœ¯èƒ½è¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>ç°æœ‰çš„OTTAè¯„ä¼°åè®®å­˜åœ¨ä¸è¶³ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹æ³•å’Œæ›´å¤šå®šé‡æŒ‡æ ‡æ¥å…¨é¢è¯„ä»·æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡â€”â€”é¢„æœŸå°¾éƒ¨å‡†ç¡®ç‡ï¼ˆETAï¼‰ï¼Œç”¨äºæ›´å‡†ç¡®åœ°è¡¡é‡æ¨¡å‹åœ¨ä¸åŒè¿è¡Œä¸­çš„æ€§èƒ½ç¨³å®šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04352">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a49980565a258988916ade760b1c55aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fab9ca2636ad6eac80ec4eabed11f4e0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-79ebc13543f85ba004230bbe041d0ca8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="More-is-not-always-better-Enhancing-Many-Shot-In-Context-Learning-with-Differentiated-and-Reweighting-Objectives"><a href="#More-is-not-always-better-Enhancing-Many-Shot-In-Context-Learning-with-Differentiated-and-Reweighting-Objectives" class="headerlink" title="More is not always better? Enhancing Many-Shot In-Context Learning with   Differentiated and Reweighting Objectives"></a>More is not always better? Enhancing Many-Shot In-Context Learning with   Differentiated and Reweighting Objectives</h2><p><strong>Authors:Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Shuo Shang, Xiuying Chen, Rui Yan</strong></p>
<p>Large language models (LLMs) excel at few-shot in-context learning (ICL) without requiring parameter updates. However, as the number of ICL demonstrations increases from a few to many, performance tends to plateau and eventually decline. We identify two primary causes for this trend: the suboptimal negative log-likelihood (NLL) optimization objective and the incremental data noise. To address these issues, we introduce DR-ICL, a novel optimization method that enhances model performance through Differentiated Learning and advantage-based Reweighting objectives. Globally, DR-ICL utilizes differentiated learning to optimize the NLL objective, ensuring that many-shot performance surpasses zero-shot levels. Locally, it dynamically adjusts the weighting of many-shot demonstrations by leveraging cumulative advantages inspired by reinforcement learning, thereby improving generalization. This approach allows the model to handle varying numbers of shots effectively, mitigating the impact of noisy data. Recognizing the lack of multi-task datasets with diverse many-shot distributions, we develop the Many-Shot ICL Benchmark (MICLB)-a large-scale benchmark covering shot numbers from 1 to 350 within sequences of up to 8,000 tokens-for fine-tuning purposes. MICLB facilitates the evaluation of many-shot ICL strategies across seven prominent NLP tasks and 50 distinct datasets. Experimental results demonstrate that LLMs enhanced with DR-ICL achieve significant improvements in many-shot setups across various tasks, including both in-domain and out-of-domain scenarios. We release the code and benchmark dataset hoping to facilitate further research in many-shot ICL. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸éœ€æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹ï¼Œæ“…é•¿è¿›è¡Œå°‘é‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ã€‚ç„¶è€Œï¼Œéšç€ICLæ¼”ç¤ºçš„æ•°é‡ä»å‡ ä¸ªå¢åŠ åˆ°è®¸å¤šï¼Œæ€§èƒ½å¾€å¾€è¾¾åˆ°å³°å€¼å¹¶æœ€ç»ˆä¸‹é™ã€‚æˆ‘ä»¬ç¡®å®šäº†è¿™ä¸€è¶‹åŠ¿çš„ä¸¤ä¸ªä¸»è¦åŸå› ï¼šæ¬¡ä¼˜çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNLLï¼‰ä¼˜åŒ–ç›®æ ‡å’Œå¢é‡æ•°æ®å™ªå£°ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†DR-ICLè¿™ä¸€æ–°å‹ä¼˜åŒ–æ–¹æ³•ï¼Œå®ƒé€šè¿‡å·®å¼‚åŒ–å­¦ä¹ å’ŒåŸºäºä¼˜åŠ¿çš„é‡åŠ æƒç›®æ ‡æ¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚ä»å…¨å±€è§’åº¦çœ‹ï¼ŒDR-ICLé€šè¿‡ä¼˜åŒ–NLLç›®æ ‡è¿›è¡Œå·®å¼‚åŒ–å­¦ä¹ ï¼Œç¡®ä¿å¤šé•œå¤´æ€§èƒ½è¶…è¶Šé›¶é•œå¤´æ°´å¹³ã€‚ä»å±€éƒ¨è§’åº¦çœ‹ï¼Œå®ƒåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å¾—åˆ°çš„ç´¯ç§¯ä¼˜åŠ¿åŠ¨æ€è°ƒæ•´å¤šé•œå¤´æ¼”ç¤ºçš„æƒé‡ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•ä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†ä¸åŒæ•°é‡çš„é•œå¤´ï¼Œå‡è½»å™ªå£°æ•°æ®çš„å½±å“ã€‚ç”±äºç¼ºå°‘å…·æœ‰å¤šç§å¤šé•œå¤´åˆ†å¸ƒçš„å¤šä»»åŠ¡æ•°æ®é›†ï¼Œæˆ‘ä»¬å¼€å‘äº†å¤šé•œå¤´ICLåŸºå‡†æµ‹è¯•ï¼ˆMICLBï¼‰â€”â€”ä¸€ä¸ªå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–ä»1åˆ°350çš„å°„å‡»æ¬¡æ•°ï¼Œåºåˆ—ä¸­çš„ä»¤ç‰Œæ•°é«˜è¾¾8000ä¸ªâ€”â€”ç”¨äºå¾®è°ƒç›®çš„ã€‚MICLBä¾¿äºåœ¨ä¸ƒä¸ªä¸»è¦NLPä»»åŠ¡å’Œäº”åä¸ªä¸åŒæ•°æ®é›†ä¸Šè¯„ä¼°å¤šé•œå¤´ICLç­–ç•¥çš„æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨DR-ICLå¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡çš„å¤šé•œå¤´è®¾ç½®ä¸­å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒ…æ‹¬åŸŸå†…å’ŒåŸŸå¤–åœºæ™¯ã€‚æˆ‘ä»¬å‘å¸ƒä»£ç å’ŒåŸºå‡†æ•°æ®é›†ï¼Œå¸Œæœ›èƒ½è¿›ä¸€æ­¥æ¨åŠ¨å¤šé•œå¤´ICLçš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04070v1">PDF</a> 13 pages, 8 figures, 11 tables</p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸éœ€è¦å‚æ•°æ›´æ–°çš„å°‘é‡ä¸Šä¸‹æ–‡å­¦ä¹ åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†éšç€ä¸Šä¸‹æ–‡å­¦ä¹ ç¤ºä¾‹ä»å‡ ä¸ªå¢åŠ åˆ°å¤šä¸ªï¼Œæ€§èƒ½å¾€å¾€ä¼šè¾¾åˆ°å³°å€¼å¹¶æœ€ç»ˆä¸‹é™ã€‚ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹è¿™ä¸€é—®é¢˜æå‡ºäº†DR-ICLè¿™ä¸€æ–°å‹ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡å·®å¼‚åŒ–å­¦ä¹ å’ŒåŸºäºä¼˜åŠ¿çš„åŠ æƒä¼˜åŒ–ç›®æ ‡æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡å·®å¼‚åŒ–å­¦ä¹ ä¼˜åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ç›®æ ‡ï¼Œç¡®ä¿å¤šç¤ºä¾‹æ€§èƒ½è¶…è¶Šé›¶ç¤ºä¾‹æ°´å¹³ã€‚åŒæ—¶ï¼Œå®ƒè¿˜ä¼šæ ¹æ®å¼ºåŒ–å­¦ä¹ çš„ç´¯ç§¯ä¼˜åŠ¿åŠ¨æ€è°ƒæ•´å¤šç¤ºä¾‹æ¼”ç¤ºçš„æƒé‡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†ä¸åŒæ•°é‡çš„ç¤ºä¾‹ï¼Œå‡è½»å™ªå£°æ•°æ®çš„å½±å“ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³å¤šä»»åŠ¡æ•°æ®é›†ç¼ºä¹å¤šæ ·å¤šå˜çš„å¤šç¤ºä¾‹åˆ†å¸ƒé—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•å¹³å°â€”â€”å¤šç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ åŸºå‡†ï¼ˆMICLBï¼‰ï¼Œæ¶µç›–äº†ä»1åˆ°350ä¸ªç¤ºä¾‹ï¼Œåºåˆ—é•¿åº¦é«˜è¾¾8000ä¸ªæ ‡è®°çš„å¤šç§åœºæ™¯ï¼Œç”¨äºç²¾ç»†è°ƒæ•´ç›®çš„ã€‚MICLBèƒ½å¤Ÿåœ¨ä¸ƒä¸ªä¸»è¦NLPä»»åŠ¡å’Œäº”åä¸ªä¸åŒæ•°æ®é›†ä¸Šè¯„ä¼°å¤šç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨DR-ICLå¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡çš„å¤šç¤ºä¾‹è®¾ç½®ä¸­éƒ½å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒ…æ‹¬åŸŸå†…å’ŒåŸŸå¤–åœºæ™¯ã€‚æˆ‘ä»¬å…¬å¼€äº†ä»£ç å’ŒåŸºå‡†æ•°æ®é›†ï¼Œå¸Œæœ›è¿›ä¸€æ­¥æ¨åŠ¨å¤šç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ é¢†åŸŸçš„ç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸éœ€è¦å‚æ•°æ›´æ–°çš„å°‘é‡ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†éšç€ç¤ºä¾‹æ•°é‡å¢åŠ ï¼Œæ€§èƒ½ä¼šä¸‹é™ã€‚</li>
<li>æ€§èƒ½ä¸‹é™çš„ä¸»è¦åŸå› åŒ…æ‹¬æ¬¡ä¼˜çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ä¼˜åŒ–ç›®æ ‡å’Œå¢åŠ çš„æ•°æ®å™ªå£°ã€‚</li>
<li>DR-ICLæ˜¯ä¸€ç§æ–°å‹ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡å·®å¼‚åŒ–å­¦ä¹ å’ŒåŸºäºä¼˜åŠ¿çš„åŠ æƒæ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>DR-ICLèƒ½å¤Ÿåœ¨å…¨çƒèŒƒå›´å†…ä¼˜åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ç›®æ ‡ï¼Œå¹¶åœ¨å±€éƒ¨é€šè¿‡å€Ÿé‰´å¼ºåŒ–å­¦ä¹ çš„ç´¯ç§¯ä¼˜åŠ¿åŠ¨æ€è°ƒæ•´å¤šç¤ºä¾‹æ¼”ç¤ºçš„æƒé‡ã€‚</li>
<li>DR-ICLå…è®¸æ¨¡å‹æœ‰æ•ˆå¤„ç†ä¸åŒæ•°é‡çš„ç¤ºä¾‹ï¼Œå¹¶å‡è½»å™ªå£°æ•°æ®çš„å½±å“ã€‚</li>
<li>ä¸ºäº†ä¿ƒè¿›å¤šç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ ç ”ç©¶ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•å¹³å°â€”â€”å¤šç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ åŸºå‡†ï¼ˆMICLBï¼‰ï¼Œæ¶µç›–å¤šç§NLPä»»åŠ¡å’Œæ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04070">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-36b0009946a6ceda17564a2d63590a78.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-02a20821473a9e1da132110f06e999ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-121b4f1da0318451f08f703376339193.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ebb477671929c42bd2861cd8a4b49ed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-166d78d39b98ac5c931d706a5390b2db.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Soft-Sensor-Method-with-Uncertainty-Awareness-and-Self-Explanation-Based-on-Large-Language-Models-Enhanced-by-Domain-Knowledge-Retrieval"><a href="#A-Soft-Sensor-Method-with-Uncertainty-Awareness-and-Self-Explanation-Based-on-Large-Language-Models-Enhanced-by-Domain-Knowledge-Retrieval" class="headerlink" title="A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation   Based on Large Language Models Enhanced by Domain Knowledge Retrieval"></a>A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation   Based on Large Language Models Enhanced by Domain Knowledge Retrieval</h2><p><strong>Authors:Shuo Tong, Han Liu, Runyuan Guo, Wenqing Wang, Xueqiong Tian, Lingyun Wei, Lin Zhang, Huayong Wu, Ding Liu, Youmin Zhang</strong></p>
<p>Data-driven soft sensors are crucial in predicting key performance indicators in industrial systems. However, current methods predominantly rely on the supervised learning paradigms of parameter updating, which inherently faces challenges such as high development costs, poor robustness, training instability, and lack of interpretability. Recently, large language models (LLMs) have demonstrated significant potential across various domains, notably through In-Context Learning (ICL), which enables high-performance task execution with minimal input-label demonstrations and no prior training. This paper aims to replace supervised learning with the emerging ICL paradigm for soft sensor modeling to address existing challenges and explore new avenues for advancement. To achieve this, we propose a novel framework called the Few-shot Uncertainty-aware and self-Explaining Soft Sensor (LLM-FUESS), which includes the Zero-shot Auxiliary Variable Selector (LLM-ZAVS) and the Uncertainty-aware Few-shot Soft Sensor (LLM-UFSS). The LLM-ZAVS retrieves from the Industrial Knowledge Vector Storage to enhance LLMsâ€™ domain-specific knowledge, enabling zero-shot auxiliary variable selection. In the LLM-UFSS, we utilize text-based context demonstrations of structured data to prompt LLMs to execute ICL for predicting and propose a context sample retrieval augmentation strategy to improve performance. Additionally, we explored LLMsâ€™ AIGC and probabilistic characteristics to propose self-explanation and uncertainty quantification methods for constructing a trustworthy soft sensor. Extensive experiments demonstrate that our method achieved state-of-the-art predictive performance, strong robustness, and flexibility, effectively mitigates training instability found in traditional methods. To the best of our knowledge, this is the first work to establish soft sensor utilizing LLMs. </p>
<blockquote>
<p>æ•°æ®é©±åŠ¨è½¯ä¼ æ„Ÿå™¨åœ¨å·¥ä¸šç³»ç»Ÿä¸­é¢„æµ‹å…³é”®æ€§èƒ½æŒ‡æ ‡æ–¹é¢å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºå‚æ•°æ›´æ–°çš„ç›‘ç£å­¦ä¹ æ¨¡å¼ï¼Œè¿™å›ºæœ‰åœ°é¢ä¸´ç€é«˜å¼€å‘æˆæœ¬ã€é²æ£’æ€§å·®ã€è®­ç»ƒä¸ç¨³å®šå’Œç¼ºä¹å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ä¸ªé¢†åŸŸè¡¨ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Œå®ƒèƒ½å¤Ÿåœ¨å°‘é‡è¾“å…¥æ ‡ç­¾æ¼”ç¤ºçš„æƒ…å†µä¸‹å®ç°é«˜æ€§èƒ½çš„ä»»åŠ¡æ‰§è¡Œï¼Œæ— éœ€é¢„å…ˆè®­ç»ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03295v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ•°æ®é©±åŠ¨å‹è½¯ä¼ æ„Ÿå™¨å¯¹é¢„æµ‹å·¥ä¸šç³»ç»Ÿå…³é”®æ€§èƒ½æŒ‡æ ‡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•ä¸»è¦ä¾èµ–å‚æ•°æ›´æ–°çš„ç›‘ç£å­¦ä¹ æ¨¡å¼ï¼Œè¿™å›ºæœ‰åœ°é¢ä¸´é«˜å¼€å‘æˆæœ¬ã€é²æ£’æ€§å·®ã€è®­ç»ƒä¸ç¨³å®šå’Œç¼ºä¹å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚è¿‘æœŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ä¸ªé¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ— éœ€äº‹å…ˆè®­ç»ƒçš„æƒ…å¢ƒå­¦ä¹ ï¼ˆICLï¼‰æ–¹é¢ã€‚æœ¬æ–‡æ—¨åœ¨å°†æ–°å…´çš„ICLèŒƒå¼åº”ç”¨äºè½¯ä¼ æ„Ÿå™¨å»ºæ¨¡ï¼Œä»¥åº”å¯¹ç°æœ‰æŒ‘æˆ˜å¹¶æ¢ç´¢æ–°çš„è¿›æ­¥é€”å¾„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºFew-shot Uncertainty-aware and self-Explaining Soft Sensorï¼ˆLLM-FUESSï¼‰çš„æ–°æ¡†æ¶ï¼ŒåŒ…æ‹¬Zero-shot Auxiliary Variable Selectorï¼ˆLLM-ZAVSï¼‰å’ŒUncertainty-aware Few-shot Soft Sensorï¼ˆLLM-UFSSï¼‰ã€‚LLM-ZAVSä»å·¥ä¸šçŸ¥è¯†å‘é‡å­˜å‚¨ä¸­æ£€ç´¢ä»¥å¢å¼ºLLMçš„é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œå®ç°é›¶è¾…åŠ©å˜é‡é€‰æ‹©ã€‚åœ¨LLM-UFSSä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨ç»“æ„åŒ–æ•°æ®çš„æ–‡æœ¬ä¸Šä¸‹æ–‡æ¼”ç¤ºæ¥æç¤ºLLMæ‰§è¡ŒICLè¿›è¡Œé¢„æµ‹ï¼Œå¹¶æå‡ºä¸€ç§ä¸Šä¸‹æ–‡æ ·æœ¬æ£€ç´¢å¢å¼ºç­–ç•¥æ¥æé«˜æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢äº†LLMçš„è‡ªè§£é‡Šå’Œä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œä»¥æ„å»ºå¯ä¿¡èµ–çš„è½¯ä¼ æ„Ÿå™¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†å…ˆè¿›çš„é¢„æµ‹æ€§èƒ½ã€å¼ºå¤§çš„é²æ£’æ€§å’Œçµæ´»æ€§ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡åˆ©ç”¨LLMå»ºç«‹è½¯ä¼ æ„Ÿå™¨çš„å·¥ä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°æ®é©±åŠ¨å‹è½¯ä¼ æ„Ÿå™¨åœ¨é¢„æµ‹å·¥ä¸šç³»ç»Ÿå…³é”®æ€§èƒ½æŒ‡æ ‡æ–¹é¢æ‰®æ¼”é‡è¦è§’è‰²ã€‚</li>
<li>å½“å‰è½¯ä¼ æ„Ÿå™¨æ–¹æ³•ä¸»è¦åŸºäºç›‘ç£å­¦ä¹ ï¼Œå­˜åœ¨é«˜æˆæœ¬ã€ç¼ºä¹é²æ£’æ€§ã€è®­ç»ƒä¸ç¨³å®šå’Œç¼ºä¹å¯è§£é‡Šæ€§é—®é¢˜ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œæƒ…å¢ƒå­¦ä¹ ï¼ˆICLï¼‰åœ¨è½¯ä¼ æ„Ÿå™¨å»ºæ¨¡ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†Few-shot Uncertainty-aware and self-Explaining Soft Sensorï¼ˆLLM-FUESSï¼‰æ¡†æ¶ï¼Œç»“åˆLLM-ZAVSå’ŒLLM-UFSSï¼Œä»¥æ”¹è¿›è½¯ä¼ æ„Ÿå™¨æ€§èƒ½ã€‚</li>
<li>LLM-ZAVSåˆ©ç”¨å·¥ä¸šçŸ¥è¯†å‘é‡å­˜å‚¨å¢å¼ºLLMçš„é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œå®ç°é›¶è¾…åŠ©å˜é‡é€‰æ‹©ã€‚</li>
<li>LLM-UFSSåˆ©ç”¨æ–‡æœ¬ä¸Šä¸‹æ–‡æ¼”ç¤ºå’Œä¸Šä¸‹æ–‡æ ·æœ¬æ£€ç´¢å¢å¼ºç­–ç•¥ï¼Œæé«˜é¢„æµ‹æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03295">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1515b84ef3499546e99e8bfc563a0f9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5292ad4f5db3e3c5216dbb908b21d3c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0ad17a519770ec26387bd518940eb60.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CaT-BENCH-Benchmarking-Language-Model-Understanding-of-Causal-and-Temporal-Dependencies-in-Plans"><a href="#CaT-BENCH-Benchmarking-Language-Model-Understanding-of-Causal-and-Temporal-Dependencies-in-Plans" class="headerlink" title="CaT-BENCH: Benchmarking Language Model Understanding of Causal and   Temporal Dependencies in Plans"></a>CaT-BENCH: Benchmarking Language Model Understanding of Causal and   Temporal Dependencies in Plans</h2><p><strong>Authors:Yash Kumar Lal, Vanya Cohen, Nathanael Chambers, Niranjan Balasubramanian, Raymond Mooney</strong></p>
<p>Understanding the abilities of LLMs to reason about natural language plans, such as instructional text and recipes, is critical to reliably using them in decision-making systems. A fundamental aspect of plans is the temporal order in which their steps needs to be executed, which reflects the underlying causal dependencies between them. We introduce CaT-Bench, a benchmark of Step Order Prediction questions, which test whether a step must necessarily occur before or after another in cooking recipe plans. We use this to evaluate how well frontier LLMs understand causal and temporal dependencies. We find that SOTA LLMs are underwhelming (best zero-shot is only 0.59 in F1), and are biased towards predicting dependence more often, perhaps relying on temporal order of steps as a heuristic. While prompting for explanations and using few-shot examples improve performance, the best F1 result is only 0.73. Further, human evaluation of explanations along with answer correctness show that, on average, humans do not agree with model reasoning. Surprisingly, we also find that explaining after answering leads to better performance than normal chain-of-thought prompting, and LLM answers are not consistent across questions about the same step pairs. Overall, results show that LLMsâ€™ ability to detect dependence between steps has significant room for improvement. </p>
<blockquote>
<p>ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å†³ç­–ç³»ç»Ÿæ¨ç†ä¸­é’ˆå¯¹è‡ªç„¶è¯­è¨€è®¡åˆ’ï¼ˆå¦‚è¯´æ˜æ€§æ–‡æœ¬å’Œé£Ÿè°±ï¼‰çš„èƒ½åŠ›å¯¹äºå¯é åœ°ä½¿ç”¨å®ƒä»¬è‡³å…³é‡è¦ã€‚è®¡åˆ’çš„ä¸€ä¸ªåŸºæœ¬æ–¹é¢æ˜¯æŒ‰ç…§å…¶æ­¥éª¤éœ€è¦æ‰§è¡Œçš„æ—¶åºé¡ºåºï¼Œè¿™åæ˜ äº†å®ƒä»¬ä¹‹é—´çš„æ½œåœ¨å› æœä¾èµ–å…³ç³»ã€‚æˆ‘ä»¬å¼•å…¥äº†CaT-Benchï¼Œä¸€ä¸ªæ­¥éª¤é¡ºåºé¢„æµ‹é—®é¢˜çš„åŸºå‡†æµ‹è¯•ï¼Œæµ‹è¯•çƒ¹é¥ªé£Ÿè°±è®¡åˆ’ä¸­æŸä¸ªæ­¥éª¤æ˜¯å¦å¿…é¡»åœ¨å¦ä¸€ä¸ªæ­¥éª¤ä¹‹å‰æˆ–ä¹‹åå‘ç”Ÿã€‚æˆ‘ä»¬ä½¿ç”¨å®ƒæ¥è¯„ä¼°å‰æ²¿LLMå¯¹å› æœå’Œæ—¶é—´ä¾èµ–å…³ç³»çš„ç†è§£ç¨‹åº¦ã€‚æˆ‘ä»¬å‘ç°ï¼Œæœ€å…ˆè¿›çš„LLMè¡¨ç°ä»¤äººå¤±æœ›ï¼ˆæœ€ä½³é›¶æ ·æœ¬çš„F1åˆ†æ•°ä»…ä¸º0.59ï¼‰ï¼Œå¹¶ä¸”åå‘äºæ›´é¢‘ç¹åœ°é¢„æµ‹ä¾èµ–æ€§ï¼Œæˆ–è®¸ä¾èµ–æ­¥éª¤çš„æ—¶é—´é¡ºåºä½œä¸ºå¯å‘å¼æ–¹æ³•ã€‚è™½ç„¶æç¤ºè§£é‡Šå’Œä½¿ç”¨å°‘é‡ç¤ºä¾‹å¯ä»¥æé«˜æ€§èƒ½ï¼Œä½†æœ€ä½³F1ç»“æœä»…ä¸º0.73ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯¹è§£é‡Šå’Œç­”æ¡ˆæ­£ç¡®æ€§çš„äººç±»è¯„ä¼°æ˜¾ç¤ºï¼Œå¹³å‡è€Œè¨€ï¼Œäººç±»å¹¶ä¸è®¤åŒæ¨¡å‹çš„æ¨ç†ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬è¿˜å‘ç°ï¼Œåœ¨å›ç­”é—®é¢˜åè§£é‡Šæ¯”æ­£å¸¸æ€ç»´é“¾æç¤ºå¯¼è‡´æ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”LLMå¯¹åŒä¸€æ­¥éª¤å¯¹çš„ç­”æ¡ˆå¹¶ä¸ä¸€è‡´ã€‚æ€»ä½“è€Œè¨€ï¼Œç»“æœè¡¨æ˜LLMæ£€æµ‹æ­¥éª¤ä¹‹é—´ä¾èµ–æ€§çš„èƒ½åŠ›ä»æœ‰å¾ˆå¤§æå‡ç©ºé—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.15823v3">PDF</a> Accepted to EMNLP 2024 Main Conference</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç†è§£å’Œå¤„ç†è‡ªç„¶è¯­è¨€è®¡åˆ’ï¼ˆå¦‚æŒ‡ä»¤æ–‡æœ¬å’Œé£Ÿè°±ï¼‰çš„èƒ½åŠ›å¯¹äºåœ¨å†³ç­–ç³»ç»Ÿä¸­å¯é ä½¿ç”¨å®ƒä»¬è‡³å…³é‡è¦ã€‚è®¡åˆ’çš„ä¸€ä¸ªåŸºæœ¬æ–¹é¢æ˜¯æ­¥éª¤æ‰§è¡Œçš„æ—¶åºé¡ºåºï¼Œè¿™åæ˜ äº†å®ƒä»¬ä¹‹é—´çš„æ½œåœ¨å› æœä¾èµ–å…³ç³»ã€‚æœ¬æ–‡ä»‹ç»äº†CaT-Benchï¼Œä¸€ä¸ªæ­¥éª¤é¡ºåºé¢„æµ‹é—®é¢˜çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºæµ‹è¯•LLMsåœ¨çƒ¹é¥ªé£Ÿè°±è®¡åˆ’ä¸­ç†è§£å› æœå’Œæ—¶é—´ä¾èµ–å…³ç³»çš„èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰æœ€å‰æ²¿çš„LLMsè¡¨ç°ä»¤äººå¤±æœ›ï¼ˆæœ€ä½³é›¶æ ·æœ¬F1åˆ†æ•°ä»…ä¸º0.59ï¼‰ï¼Œä¸”å€¾å‘äºè¿‡åº¦é¢„æµ‹ä¾èµ–æ€§ï¼Œå¯èƒ½ä¾èµ–æ­¥éª¤çš„æ—¶åºé¡ºåºä½œä¸ºå¯å‘å¼ã€‚è™½ç„¶æç¤ºè§£é‡Šå’Œä½¿ç”¨å°‘é‡æ ·æœ¬å¯ä»¥æé«˜æ€§èƒ½ï¼Œä½†æœ€ä½³F1ç»“æœä»…ä¸º0.73ã€‚æ­¤å¤–ï¼Œå¯¹è§£é‡Šå’Œç­”æ¡ˆæ­£ç¡®æ€§çš„äººç±»è¯„ä¼°æ˜¾ç¤ºï¼ŒLLMsçš„æ¨ç†å¹³å‡è€Œè¨€å¹¶ä¸ç¬¦åˆäººç±»çš„ç†è§£ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬è¿˜å‘ç°å…ˆç­”é¢˜å†è§£é‡Šçš„æ¨¡å¼æ¯”ä¼ ç»Ÿçš„æ€è€ƒé“¾æç¤ºæ›´æœ‰æ•ˆï¼Œå¹¶ä¸”å¯¹äºåŒä¸€æ­¥éª¤å¯¹çš„å„ç§é—®é¢˜ï¼ŒLLMçš„ç­”æ¡ˆå¹¶ä¸ä¸€è‡´ã€‚æ€»ä½“è€Œè¨€ï¼ŒLLMsåœ¨æ£€æµ‹æ­¥éª¤é—´ä¾èµ–å…³ç³»çš„èƒ½åŠ›æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨å¤„ç†è‡ªç„¶è¯­è¨€è®¡åˆ’æ–¹é¢çš„èƒ½åŠ›å¯¹äºåœ¨å†³ç­–ç³»ç»Ÿä¸­çš„ä½¿ç”¨è‡³å…³é‡è¦ã€‚</li>
<li>CaT-BenchåŸºå‡†æµ‹è¯•ç”¨äºè¯„ä¼°LLMsåœ¨ç†è§£çƒ¹é¥ªé£Ÿè°±è®¡åˆ’ä¸­çš„å› æœå’Œæ—¶é—´ä¾èµ–å…³ç³»ã€‚</li>
<li>å½“å‰LLMsåœ¨æ­¥éª¤é¡ºåºé¢„æµ‹æ–¹é¢çš„è¡¨ç°ä¸ä½³ï¼Œæœ€ä½³F1åˆ†æ•°ä»…ä¸º0.73ã€‚</li>
<li>LLMså€¾å‘äºè¿‡åº¦é¢„æµ‹æ­¥éª¤ä¹‹é—´çš„ä¾èµ–æ€§ï¼Œå¯èƒ½ä¾èµ–æ—¶åºå¯å‘å¼ã€‚</li>
<li>æç¤ºè§£é‡Šå’Œä½¿ç”¨å°‘é‡æ ·æœ¬å¯ä»¥æé«˜LLMsçš„æ€§èƒ½ï¼Œä½†ä»å­˜åœ¨æ”¹è¿›ç©ºé—´ã€‚</li>
<li>äººç±»è¯„ä¼°æ˜¾ç¤ºLLMsçš„æ¨ç†å¹¶ä¸ç¬¦åˆäººç±»çš„ç†è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.15823">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4f03311eb9726ef6474c0bd5aa5059da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-35e91675950f334a2021ff36da4e96ee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6e6044741ccbf4f5ea1a9cb8e5fa09a0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Rho-1-Not-All-Tokens-Are-What-You-Need"><a href="#Rho-1-Not-All-Tokens-Are-What-You-Need" class="headerlink" title="Rho-1: Not All Tokens Are What You Need"></a>Rho-1: Not All Tokens Are What You Need</h2><p><strong>Authors:Zhenghao Lin, Zhibin Gou, Yeyun Gong, Xiao Liu, Yelong Shen, Ruochen Xu, Chen Lin, Yujiu Yang, Jian Jiao, Nan Duan, Weizhu Chen</strong></p>
<p>Previous language model pre-training methods have uniformly applied a next-token prediction loss to all training tokens. Challenging this norm, we posit that â€œ9l trainingâ€. Our initial analysis examines token-level training dynamics of language model, revealing distinct loss patterns for different tokens. Leveraging these insights, we introduce a new language model called Rho-1. Unlike traditional LMs that learn to predict every next token in a corpus, Rho-1 employs Selective Language Modeling (SLM), which selectively trains on useful tokens that aligned with the desired distribution. This approach involves scoring pretraining tokens using a reference model, and then training the language model with a focused loss on tokens with higher scores. When continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute improvement in few-shot accuracy of up to 30% in 9 math tasks. After fine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and 51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the pretraining tokens. Furthermore, when continual pretraining on 80B general tokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks, increasing both efficiency and performance of the language model pre-training. </p>
<blockquote>
<p>ä¹‹å‰çš„è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ–¹æ³•éƒ½æ˜¯å°†æ‰€æœ‰è®­ç»ƒä»¤ç‰Œç»Ÿä¸€åº”ç”¨ä¸‹ä¸€ä¸ªä»¤ç‰Œé¢„æµ‹æŸå¤±ã€‚æˆ‘ä»¬æŒ‘æˆ˜è¿™ä¸€å¸¸è§„ï¼Œæå‡ºâ€œ9lè®­ç»ƒâ€æ–¹æ³•ã€‚æˆ‘ä»¬çš„åˆæ­¥åˆ†æç ”ç©¶äº†è¯­è¨€æ¨¡å‹çš„ä»¤ç‰Œçº§è®­ç»ƒåŠ¨æ€ï¼Œæ­ç¤ºäº†ä¸åŒä»¤ç‰Œçš„ä¸åŒæŸå¤±æ¨¡å¼ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åä¸ºRho-1çš„æ–°è¯­è¨€æ¨¡å‹ã€‚ä¸åŒäºä¼ ç»ŸLMså­¦ä¹ é¢„æµ‹è¯­æ–™åº“ä¸­çš„æ¯ä¸ªä¸‹ä¸€ä¸ªä»¤ç‰Œï¼ŒRho-1é‡‡ç”¨é€‰æ‹©æ€§è¯­è¨€å»ºæ¨¡ï¼ˆSelective Language Modelingï¼ŒSLMï¼‰ï¼Œåªé’ˆå¯¹ä¸æ‰€éœ€åˆ†å¸ƒå¯¹é½çš„æœ‰ç”¨ä»¤ç‰Œè¿›è¡Œé€‰æ‹©æ€§è®­ç»ƒã€‚è¿™ç§æ–¹æ³•æ¶‰åŠä½¿ç”¨å‚è€ƒæ¨¡å‹ä¸ºé¢„è®­ç»ƒä»¤ç‰Œæ‰“åˆ†ï¼Œç„¶åé’ˆå¯¹å¾—åˆ†è¾ƒé«˜çš„ä»¤ç‰Œä½¿ç”¨æœ‰é’ˆå¯¹æ€§çš„æŸå¤±æ¥è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚åœ¨è¿ç»­é¢„è®­ç»ƒ15B OpenWebMathè¯­æ–™åº“æ—¶ï¼ŒRho-1åœ¨9ä¸ªæ•°å­¦ä»»åŠ¡ä¸­çš„å°æ ·æœ¬ç²¾åº¦æé«˜äº†é«˜è¾¾30%ã€‚ç»è¿‡å¾®è°ƒåï¼ŒRho-1-1Bå’Œ7Båœ¨MATHæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€æ–°çš„æœ€å¥½æˆç»©ï¼Œåˆ†åˆ«ä¸º40.6%å’Œ51.8%ï¼Œåˆ†åˆ«åŒ¹é…äº†DeepSeekMathåªæœ‰å…¶é¢„è®­ç»ƒä»¤ç‰Œçš„3%ã€‚æ­¤å¤–ï¼Œåœ¨å¯¹80Bé€šç”¨ä»¤ç‰Œè¿›è¡Œè¿ç»­é¢„è®­ç»ƒæ—¶ï¼ŒRho-1åœ¨15ä¸ªä¸åŒä»»åŠ¡ä¸Šå¹³å‡æé«˜äº†6.8%çš„æ€§èƒ½ï¼Œæé«˜äº†è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„æ•ˆç‡ä¸æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.07965v4">PDF</a> First two authors equal contribution</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æŒ‘æˆ˜äº†ä¼ ç»Ÿè¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„æ–¹å¼ï¼Œæå‡ºä¸€ç§åä¸ºRho-1çš„æ–°å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨é€‰æ‹©æ€§è¯­è¨€å»ºæ¨¡ï¼ˆSLMï¼‰æ–¹æ³•ï¼Œåªé’ˆå¯¹æœ‰ç”¨ä¸”ç¬¦åˆæœŸæœ›åˆ†å¸ƒçš„ä»¤ç‰Œè¿›è¡Œè®­ç»ƒã€‚é€šè¿‡è¯„åˆ†é¢„è®­ç»ƒä»¤ç‰Œå¹¶ä½¿ç”¨æœ‰é’ˆå¯¹æ€§çš„æŸå¤±å‡½æ•°å¯¹é«˜åˆ†ä»¤ç‰Œè¿›è¡Œè®­ç»ƒï¼Œåœ¨æŒç»­é¢„è®­ç»ƒæ—¶æé«˜äº†æ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚åœ¨å¤šä¸ªä»»åŠ¡ä¸­ï¼ŒRho-1çš„é¢„è®­ç»ƒä»¤ç‰Œæ•°é‡ç›¸è¾ƒäºå…¶ä»–æ¨¡å‹å¤§å¤§å‡å°‘ï¼Œä½†ä»å–å¾—äº†æ˜¾è‘—çš„å‡†ç¡®æ€§æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿè¯­è¨€æ¨¡å‹é¢„è®­ç»ƒé‡‡ç”¨å¯¹æ‰€æœ‰ä»¤ç‰Œåº”ç”¨ä¸‹ä¸€ä¸ªä»¤ç‰Œé¢„æµ‹æŸå¤±çš„æ–¹æ³•ï¼Œè€Œæœ¬æ–‡æå‡ºæŒ‘æˆ˜å¹¶å¼•å…¥é€‰æ‹©æ€§è¯­è¨€å»ºæ¨¡ï¼ˆSLMï¼‰ã€‚</li>
<li>Rho-1æ¨¡å‹ä½¿ç”¨å‚è€ƒæ¨¡å‹å¯¹é¢„è®­ç»ƒä»¤ç‰Œè¿›è¡Œè¯„åˆ†ï¼Œåªé’ˆå¯¹é«˜åˆ†ä»¤ç‰Œè¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æŸå¤±è®­ç»ƒã€‚</li>
<li>Rho-1æ¨¡å‹åœ¨æŒç»­é¢„è®­ç»ƒæ—¶ï¼Œç›¸è¾ƒäºå…¶ä»–æ¨¡å‹ä½¿ç”¨æ›´å°‘çš„é¢„è®­ç»ƒä»¤ç‰Œæ•°é‡ã€‚</li>
<li>Rho-1åœ¨å¤šä¸ªæ•°å­¦ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾30%çš„å°‘æ ·æœ¬å‡†ç¡®æ€§æå‡ã€‚</li>
<li>Rho-1åœ¨MATHæ•°æ®é›†ä¸Šçš„è¡¨ç°è¾¾åˆ°æˆ–è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œå³ä½¿åªä½¿ç”¨å°‘é‡é¢„è®­ç»ƒä»¤ç‰Œã€‚</li>
<li>Rho-1åœ¨å¤šç§ä»»åŠ¡ä¸Šå¹³å‡æé«˜äº†æ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ï¼Œå¹³å‡æå‡å¹…åº¦è¾¾åˆ°6.8%ã€‚</li>
<li>Rho-1æ¨¡å‹çš„å¼•å…¥ä¸ºè¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒæä¾›äº†æ–°çš„è§†è§’å’Œæ–¹æ³•è®ºåŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.07965">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-905554d8f282d5b54c986cb69db390c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62cbd37a55128d00a6c0c4d4d6b3db36.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e67d84554c46160b55ad3faaf302fd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8715239cda5adcb6370b69c2d9b3e8a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6251b7c2d0a642fd2c586c2ba121eb29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2952de91398a6a427d8c70821e213c0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="FILP-3D-Enhancing-3D-Few-shot-Class-incremental-Learning-with-Pre-trained-Vision-Language-Models"><a href="#FILP-3D-Enhancing-3D-Few-shot-Class-incremental-Learning-with-Pre-trained-Vision-Language-Models" class="headerlink" title="FILP-3D: Enhancing 3D Few-shot Class-incremental Learning with   Pre-trained Vision-Language Models"></a>FILP-3D: Enhancing 3D Few-shot Class-incremental Learning with   Pre-trained Vision-Language Models</h2><p><strong>Authors:Wan Xu, Tianyu Huang, Tianyu Qu, Guanglei Yang, Yiwen Guo, Wangmeng Zuo</strong></p>
<p>Few-shot class-incremental learning (FSCIL) aims to mitigate the catastrophic forgetting issue when a model is incrementally trained on limited data. However, many of these works lack effective exploration of prior knowledge, rendering them unable to effectively address the domain gap issue in the context of 3D FSCIL, thereby leading to catastrophic forgetting. The Contrastive Vision-Language Pre-Training (CLIP) model serves as a highly suitable backbone for addressing the challenges of 3D FSCIL due to its abundant shape-related prior knowledge. Unfortunately, its direct application to 3D FSCIL still faces the incompatibility between 3D data representation and the 2D features, primarily manifested as feature space misalignment and significant noise. To address the above challenges, we introduce the FILP-3D framework with two novel components: the Redundant Feature Eliminator (RFE) for feature space misalignment and the Spatial Noise Compensator (SNC) for significant noise. RFE aligns the feature spaces of input point clouds and their embeddings by performing a unique dimensionality reduction on the feature space of pre-trained models (PTMs), effectively eliminating redundant information without compromising semantic integrity. On the other hand, SNC is a graph-based 3D model designed to capture robust geometric information within point clouds, thereby augmenting the knowledge lost due to projection, particularly when processing real-world scanned data. Moreover, traditional accuracy metrics are proven to be biased due to the imbalance in existing 3D datasets. Therefore we propose 3D FSCIL benchmark FSCIL3D-XL and novel evaluation metrics that offer a more nuanced assessment of a 3D FSCIL model. Experimental results on both established and our proposed benchmarks demonstrate that our approach significantly outperforms existing state-of-the-art methods. </p>
<blockquote>
<p>å°‘é‡ç±»åˆ«å¢é‡å­¦ä¹ ï¼ˆFSCILï¼‰æ—¨åœ¨è§£å†³æ¨¡å‹åœ¨æœ‰é™æ•°æ®ä¸Šé€æ­¥è®­ç»ƒæ—¶å‡ºç°çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›å·¥ä½œä¸­çš„è®¸å¤šç¼ºä¹å¯¹å…ˆéªŒçŸ¥è¯†çš„æœ‰æ•ˆæ¢ç´¢ï¼Œå¯¼è‡´å®ƒä»¬æ— æ³•æœ‰æ•ˆè§£å†³3D FSCILä¸­çš„é¢†åŸŸå·®è·é—®é¢˜ï¼Œä»è€Œå¯¼è‡´ç¾éš¾æ€§é—å¿˜ã€‚å¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¨¡å‹ç”±äºå…¶ä¸°å¯Œçš„å½¢çŠ¶ç›¸å…³å…ˆéªŒçŸ¥è¯†ï¼Œæˆä¸ºåº”å¯¹3D FSCILæŒ‘æˆ˜çš„ç†æƒ³éª¨å¹²ç½‘ã€‚ç„¶è€Œï¼Œå…¶ç›´æ¥åº”ç”¨äº3D FSCILä»ç„¶é¢ä¸´3Dæ•°æ®è¡¨ç¤ºä¸2Dç‰¹å¾ä¹‹é—´çš„ä¸å…¼å®¹é—®é¢˜ï¼Œä¸»è¦è¡¨ç°ä¸ºç‰¹å¾ç©ºé—´ä¸å¯¹é½å’Œæ˜¾è‘—å™ªå£°ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†FILP-3Dæ¡†æ¶ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸¤ä¸ªæ–°ç»„ä»¶ï¼šç”¨äºç‰¹å¾ç©ºé—´ä¸å¯¹é½çš„å†—ä½™ç‰¹å¾æ¶ˆé™¤å™¨ï¼ˆRFEï¼‰å’Œç”¨äºæ˜¾è‘—å™ªå£°çš„ç©ºé—´å™ªå£°è¡¥å¿å™¨ï¼ˆSNCï¼‰ã€‚RFEé€šè¿‡å¯¹é¢„è®­ç»ƒæ¨¡å‹ï¼ˆPTMï¼‰çš„ç‰¹å¾ç©ºé—´è¿›è¡Œç‹¬ç‰¹çš„é™ç»´æ“ä½œï¼Œå¯¹é½è¾“å…¥ç‚¹äº‘åŠå…¶åµŒå…¥çš„ç‰¹å¾ç©ºé—´ï¼Œæœ‰æ•ˆåœ°æ¶ˆé™¤äº†å†—ä½™ä¿¡æ¯ï¼ŒåŒæ—¶ä¸æŸå®³è¯­ä¹‰å®Œæ•´æ€§ã€‚å¦ä¸€æ–¹é¢ï¼ŒSNCæ˜¯ä¸€ä¸ªåŸºäºå›¾çš„3Dæ¨¡å‹ï¼Œæ—¨åœ¨æ•è·ç‚¹äº‘ä¸­çš„ç¨³å¥å‡ ä½•ä¿¡æ¯ï¼Œä»è€Œå¼¥è¡¥å› æŠ•å½±è€Œä¸¢å¤±çš„çŸ¥è¯†ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ç°å®ä¸–ç•Œæ‰«ææ•°æ®æ—¶ã€‚æ­¤å¤–ï¼Œç”±äºç°æœ‰3Dæ•°æ®é›†çš„ä¸å¹³è¡¡ï¼Œä¼ ç»Ÿå‡†ç¡®æ€§æŒ‡æ ‡è¢«è¯æ˜æ˜¯æœ‰åè§çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†3D FSCILåŸºå‡†æµ‹è¯•FSCIL3D-XLå’Œæ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¸º3D FSCILæ¨¡å‹æä¾›æ›´å¾®å¦™çš„è¯„ä¼°ã€‚åœ¨æ—¢å®šåŸºå‡†æµ‹è¯•å’Œæˆ‘ä»¬æå‡ºçš„åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœéƒ½è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.17051v2">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹few-shotç±»å¢é‡å­¦ä¹ ï¼ˆFSCILï¼‰ä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä½¿ç”¨å¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¨¡å‹çš„FILP-3Dæ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤ä¸ªæ–°ç»„ä»¶ï¼šç”¨äºç‰¹å¾ç©ºé—´ä¸å¯¹é½çš„å†—ä½™ç‰¹å¾æ¶ˆé™¤å™¨ï¼ˆRFEï¼‰å’Œç”¨äºæ˜¾è‘—å™ªå£°çš„ç©ºé—´å™ªå£°è¡¥å¿å™¨ï¼ˆSNCï¼‰ã€‚åŒæ—¶ï¼Œä¸ºè§£å†³ä¼ ç»Ÿå‡†ç¡®ç‡åº¦é‡åœ¨3Dæ•°æ®é›†ä¸Šçš„åè§é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†FSCIL3D-XLåŸºå‡†æµ‹è¯•å’Œæ–°å‹è¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°æœ‰å’Œä¼ ç»ŸåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-shotç±»å¢é‡å­¦ä¹ ï¼ˆFSCILï¼‰é¢ä¸´ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œéœ€è¦æ¢ç´¢å…ˆå‰çŸ¥è¯†æ¥è§£å†³ã€‚</li>
<li>å¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¨¡å‹å› å…¶ä¸°å¯Œçš„å½¢çŠ¶ç›¸å…³å…ˆéªŒçŸ¥è¯†ï¼Œé€‚åˆè§£å†³3D FSCILçš„æŒ‘æˆ˜ã€‚</li>
<li>FILP-3Dæ¡†æ¶é€šè¿‡å¼•å…¥å†—ä½™ç‰¹å¾æ¶ˆé™¤å™¨ï¼ˆRFEï¼‰å’Œç©ºé—´å™ªå£°è¡¥å¿å™¨ï¼ˆSNCï¼‰æ¥è§£å†³3Dæ•°æ®è¡¨ç¤ºä¸2Dç‰¹å¾ä¹‹é—´çš„ä¸å…¼å®¹é—®é¢˜ã€‚</li>
<li>RFEé€šè¿‡å¯¹é¢„è®­ç»ƒæ¨¡å‹çš„ç‰¹å¾ç©ºé—´è¿›è¡Œç‹¬ç‰¹çš„é™ç»´æ“ä½œï¼Œæ¶ˆé™¤äº†å†—ä½™ä¿¡æ¯ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ã€‚</li>
<li>SNCæ˜¯ä¸€ä¸ªåŸºäºå›¾çš„3Dæ¨¡å‹ï¼Œæ—¨åœ¨æ•æ‰ç‚¹äº‘ä¸­çš„ç¨³å¥å‡ ä½•ä¿¡æ¯ï¼Œä»è€Œå¼¥è¡¥å› æŠ•å½±è€Œä¸¢å¤±çš„çŸ¥è¯†ã€‚</li>
<li>ä¼ ç»Ÿå‡†ç¡®ç‡åº¦é‡åœ¨3Dæ•°æ®é›†ä¸Šå­˜åœ¨åè§ï¼Œå› æ­¤æå‡ºäº†FSCIL3D-XLåŸºå‡†æµ‹è¯•å’Œæ–°å‹è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æä¾›æ›´ç»†è‡´çš„è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.17051">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bbc141e2deb1da69f532de88383d6f9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afc19195904a063af8bd12e5a52b86e4.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-10/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-10/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-10/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-20bae26bab7d77089dc1955b48b4174f.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-10  MultiMax Sparse and Multi-Modal Attention Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-10/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6f397f7d2e8cb3133ad298a905f61c9b.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-10  MultiMax Sparse and Multi-Modal Attention Learning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">13597.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
