<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-02-20  Magma A Foundation Model for Multimodal AI Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-509a10fdf6c6b07c4d0432e6ded7d510.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-02-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    47 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-20-更新"><a href="#2025-02-20-更新" class="headerlink" title="2025-02-20 更新"></a>2025-02-20 更新</h1><h2 id="Magma-A-Foundation-Model-for-Multimodal-AI-Agents"><a href="#Magma-A-Foundation-Model-for-Multimodal-AI-Agents" class="headerlink" title="Magma: A Foundation Model for Multimodal AI Agents"></a>Magma: A Foundation Model for Multimodal AI Agents</h2><p><strong>Authors:Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao</strong></p>
<p>We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds. Magma is a significant extension of vision-language (VL) models in that it not only retains the VL understanding ability (verbal intelligence) of the latter, but is also equipped with the ability to plan and act in the visual-spatial world (spatial-temporal intelligence) and complete agentic tasks ranging from UI navigation to robot manipulation. To endow the agentic capabilities, Magma is pretrained on large amounts of heterogeneous datasets spanning from images, videos to robotics data, where the actionable visual objects (e.g., clickable buttons in GUI) in images are labeled by Set-of-Mark (SoM) for action grounding, and the object movements (e.g., the trace of human hands or robotic arms) in videos are labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show that SoM and ToM reach great synergy and facilitate the acquisition of spatial-temporal intelligence for our Magma model, which is fundamental to a wide range of tasks as shown in Fig.1. In particular, Magma creates new state-of-the-art results on UI navigation and robotic manipulation tasks, outperforming previous models that are specifically tailored to these tasks. On image and video-related multimodal tasks, Magma also compares favorably to popular large multimodal models that are trained on much larger datasets. We make our model and code public for reproducibility at <a target="_blank" rel="noopener" href="https://microsoft.github.io/Magma">https://microsoft.github.io/Magma</a>. </p>
<blockquote>
<p>我们推出了Magma，这是一个服务于数字和物理世界多模态人工智能任务的基础模型。Magma是视觉语言（VL）模型的重大扩展，它不仅保留了后者的视觉语言理解能力（语言智能），还具备了视觉空间世界的规划和行动能力（时空智能），能够完成从用户界面导航到机器人操作的各种任务。为了赋予这些智能能力，Magma在大量异构数据集上进行预训练，涵盖了图像、视频和机器人数据。在图像中，可操作视觉对象（例如GUI中的可点击按钮）通过Set-of-Mark（SoM）进行动作标注，而在视频中的对象运动（例如人手或机械臂的运动轨迹）则通过Trace-of-Mark（ToM）进行动作规划标注。大量实验表明，SoM和ToM之间实现了良好的协同作用，促进了我们Magma模型获得时空智能，这对如图一所示的各种任务至关重要。特别是，Magma在用户界面导航和机器人操作任务上创造了新的最佳结果，超越了专门为这些任务设计的先前模型。在图像和与视频相关的多模态任务上，Magma也与训练在更大数据集上的流行大型多模态模型相比表现良好。我们在<a target="_blank" rel="noopener" href="https://microsoft.github.io/Magma%E5%85%AC%E5%BC%80%E4%BA%86%E6%88%91%E4%BB%AC%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E4%BB%A3%E7%A0%81%EF%BC%8C%E4%BB%A5%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%87%8D%E5%A4%8D%E6%80%A7%E3%80%82">https://microsoft.github.io/Magma公开了我们的模型和代码，以实现可重复性。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13130v1">PDF</a> 29 pages, 16 figures, technical report from MSR</p>
<p><strong>Summary</strong></p>
<p>Magma是一个服务于数字与物理世界多模态AI任务的预训练模型。它扩展了视觉语言模型的潜力，不仅保留了理解视觉语言的能力，还具备在视觉空间世界中进行规划和行动的能力，能够完成从UI导航到机器人操作等任务。Magma通过预训练大量包含图像、视频和机器人数据的异构数据集来赋予其代理能力，采用Set-of-Mark（SoM）进行动作定位，Trace-of-Mark（ToM）进行动作规划。实验表明，SoM和ToM的协同作用有助于获取空间时间智能，对一系列任务至关重要。Magma在UI导航和机器人操作任务上创造了新的最佳结果，与其他专门为这些任务设计的模型相比具有优势。此外，Magma在图像和视频相关的多模态任务上也表现出良好的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Magma是一个多模态AI的预训练模型，适用于数字和物理世界的任务。</li>
<li>Magma扩展了视觉语言模型的潜力，具备空间时间智能。</li>
<li>Magma能够完成从UI导航到机器人操作等多种任务。</li>
<li>SoM和ToM的协同作用对Magma的空间时间智能获取至关重要。</li>
<li>Magma在UI导航和机器人操作任务上表现优异，与其他模型相比具有优势。</li>
<li>Magma在图像和视频相关的多模态任务上也有良好的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13130">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-94c368b2b427f6afa31e8803d090e3be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c7a0e25c17506bdd7ef96df30d5b498.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-12762a006329c5b418f25034e173c5fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53e1fef77c343882a16e94bf3abff44f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4b3c0714dceed32a8a42ee16baf4b23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7b070c23c18b9ce5b539917ad60e0119.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Interactive-Agents-to-Overcome-Ambiguity-in-Software-Engineering"><a href="#Interactive-Agents-to-Overcome-Ambiguity-in-Software-Engineering" class="headerlink" title="Interactive Agents to Overcome Ambiguity in Software Engineering"></a>Interactive Agents to Overcome Ambiguity in Software Engineering</h2><p><strong>Authors:Sanidhya Vijayvargiya, Xuhui Zhou, Akhila Yerukola, Maarten Sap, Graham Neubig</strong></p>
<p>AI agents are increasingly being deployed to automate tasks, often based on ambiguous and underspecified user instructions. Making unwarranted assumptions and failing to ask clarifying questions can lead to suboptimal outcomes, safety risks due to tool misuse, and wasted computational resources. In this work, we study the ability of LLM agents to handle ambiguous instructions in interactive code generation settings by evaluating proprietary and open-weight models on their performance across three key steps: (a) leveraging interactivity to improve performance in ambiguous scenarios, (b) detecting ambiguity, and (c) asking targeted questions. Our findings reveal that models struggle to distinguish between well-specified and underspecified instructions. However, when models interact for underspecified inputs, they effectively obtain vital information from the user, leading to significant improvements in performance and underscoring the value of effective interaction. Our study highlights critical gaps in how current state-of-the-art models handle ambiguity in complex software engineering tasks and structures the evaluation into distinct steps to enable targeted improvements. </p>
<blockquote>
<p>人工智能代理正越来越多地被部署用于自动化任务，通常基于模糊和未明确指定的用户指令。做出不合理的假设和未能提出明确的问题可能导致结果不理想、工具误用带来的安全风险以及计算资源的浪费。在这项工作中，我们通过评估专有和公开权重模型在三个关键步骤中的表现，研究大型语言模型代理在交互式代码生成环境中处理模糊指令的能力：（a）利用交互性提高在模糊场景中的性能，（b）检测歧义，（c）提出有针对性的问题。我们的研究发现，模型很难区分明确指定和未明确指定的指令。然而，当模型为未明确指定的输入进行交互时，它们可以有效地从用户那里获得重要信息，从而在性能和改善方面取得显著进步，这突显了有效交互的价值。我们的研究指出了当前最先进模型在处理复杂软件工程任务中的歧义时的关键差距，并将评估分解为不同的步骤以实现有针对性的改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13069v1">PDF</a> 15 pages, 5 figures</p>
<p><strong>Summary</strong><br>AI代理在处理模糊指令时面临挑战，但利用交互性、检测模糊性并提出针对性问题，可有效改善其在交互式代码生成环境中的表现。研究指出，当前最先进的模型在处理复杂软件工程任务的模糊性方面存在关键差距。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI代理在处理模糊和未明确指定的用户指令时可能会遇到挑战。</li>
<li>在交互式代码生成环境中，AI代理需要利用交互性来改善其在处理模糊场景中的表现。</li>
<li>检测模糊性是AI代理处理复杂任务的关键步骤之一。</li>
<li>AI代理通过提出有针对性的问题，可以有效地获取用户的关键信息。</li>
<li>当前最先进的模型在区分明确和未明确指定的指令方面存在困难。</li>
<li>在处理复杂软件工程任务的模糊性方面，当前模型存在关键差距。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13069">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-464d0e221e1b52d7eb0bd24d0a8ac2d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-200b3cf4a68fd3fb4c7d5b1553f0a4ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-845cee804fe9860b671bc7b3544892f8.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-20\./crop_Agent/2502.13069v1/page_3_1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-618e2d9b4efac57721fd245819a523e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f952112295e0487ace479e61211b6116.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="An-LLM-Powered-Agent-for-Physiological-Data-Analysis-A-Case-Study-on-PPG-based-Heart-Rate-Estimation"><a href="#An-LLM-Powered-Agent-for-Physiological-Data-Analysis-A-Case-Study-on-PPG-based-Heart-Rate-Estimation" class="headerlink" title="An LLM-Powered Agent for Physiological Data Analysis: A Case Study on   PPG-based Heart Rate Estimation"></a>An LLM-Powered Agent for Physiological Data Analysis: A Case Study on   PPG-based Heart Rate Estimation</h2><p><strong>Authors:Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M. Rahmani</strong></p>
<p>Large language models (LLMs) are revolutionizing healthcare by improving diagnosis, patient care, and decision support through interactive communication. More recently, they have been applied to analyzing physiological time-series like wearable data for health insight extraction. Existing methods embed raw numerical sequences directly into prompts, which exceeds token limits and increases computational costs. Additionally, some studies integrated features extracted from time-series in textual prompts or applied multimodal approaches. However, these methods often produce generic and unreliable outputs due to LLMs’ limited analytical rigor and inefficiency in interpreting continuous waveforms. In this paper, we develop an LLM-powered agent for physiological time-series analysis aimed to bridge the gap in integrating LLMs with well-established analytical tools. Built on the OpenCHA, an open-source LLM-powered framework, our agent features an orchestrator that integrates user interaction, data sources, and analytical tools to generate accurate health insights. To evaluate its effectiveness, we implement a case study on heart rate (HR) estimation from Photoplethysmogram (PPG) signals using a dataset of PPG and Electrocardiogram (ECG) recordings in a remote health monitoring study. The agent’s performance is benchmarked against OpenAI GPT-4o-mini and GPT-4o, with ECG serving as the gold standard for HR estimation. Results demonstrate that our agent significantly outperforms benchmark models by achieving lower error rates and more reliable HR estimations. The agent implementation is publicly available on GitHub. </p>
<blockquote>
<p>大规模语言模型（LLM）正通过交互通信改善诊断、患者护理和决策支持，从而引发医疗保健领域的革命。最近，它们被应用于分析生理时间序列，如可穿戴设备数据，以提取健康洞察力。现有方法直接将原始数字序列嵌入提示中，这超出了令牌限制并增加了计算成本。此外，一些研究将时间序列提取的特征融入到文本提示中，或采用多模式方法。然而，由于LLM在连续波形解析方面的分析严谨性和效率有限，这些方法往往产生通用且不可靠的输出。在本文中，我们开发了一个由LLM驱动的生理时间序列分析代理，旨在弥合LLM与成熟的分析工具之间的鸿沟。基于开源LLM驱动框架OpenCHA，我们的代理具有一个协调器，可整合用户交互、数据源和分析工具，以生成准确的健康洞察力。为了评估其有效性，我们在远程健康监测研究的数据集上实施了一个案例研究，从光体积描记仪（PPG）信号估计心率（HR）。该代理的性能以OpenAI GPT-4o-mini和GPT-4o为基准进行测试，心电图（ECG）作为心率估计的金标准。结果表明，我们的代理显著优于基准模型，实现了更低的错误率和更可靠的心率估计。该代理的实现已在GitHub上公开可用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12836v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）正在通过交互式通信改变医疗保健领域，包括改进诊断、患者护理和决策支持。本文开发了一个基于LLM的代理，用于生理时间序列分析，旨在弥合将LLM与成熟的分析工具相结合的差距。该代理基于开源LLM框架OpenCHA构建，具有协调器功能，可整合用户交互、数据源和分析工具以生成准确的健康见解。通过心率估算的案例研究验证了其有效性，表现优于OpenAI GPT-4o-mini和GPT-4o等基准模型，误差率更低，心率估算更可靠。该代理实现已公开在GitHub上提供。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在医疗保健领域的应用正在改变诊断、患者护理和决策支持的方式。</li>
<li>生理时间序列分析是LLM在医疗保健领域的新应用方向。</li>
<li>直接将原始数值序列嵌入提示中会超过令牌限制并增加计算成本。</li>
<li>现有方法因LLM的分析严谨性有限和解释连续波形的能力不足，常常产生通用且不可靠的输出。</li>
<li>本文开发的基于LLM的代理旨在整合用户交互、数据源和分析工具，以生成准确的健康见解。</li>
<li>代理在心率估算的案例研究中表现优异，相比基准模型有更低的误差率和更可靠的估算。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12836">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5922be8103c3068aff38129135423d3e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f8a3e29491fd72b77a3f0f367aa0012b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-46510622a4a3d18763b1b8ccc9e3b558.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2c38dacbd06e4cf02620b7f6b41bcb7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07dfff1284d3d292422b3547ce304008.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="R2-KG-General-Purpose-Dual-Agent-Framework-for-Reliable-Reasoning-on-Knowledge-Graphs"><a href="#R2-KG-General-Purpose-Dual-Agent-Framework-for-Reliable-Reasoning-on-Knowledge-Graphs" class="headerlink" title="R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on   Knowledge Graphs"></a>R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on   Knowledge Graphs</h2><p><strong>Authors:Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi</strong></p>
<p>Recent studies have combined Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance reasoning, improving inference accuracy without additional training while mitigating hallucination. However, existing frameworks are often rigid, struggling to adapt to KG or task changes. They also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning. To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that separates reasoning into two roles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor (a high-capacity LLM) that makes final judgments. This design is cost-efficient for LLM inference while still maintaining strong reasoning accuracy. Additionally, R2-KG employs an Abstention mechanism, generating answers only when sufficient evidence is collected from KG, which significantly enhances reliability. Experiments across multiple KG-based reasoning tasks show that R2-KG consistently outperforms baselines in both accuracy and reliability, regardless of the inherent capability of LLMs used as the Operator. Further experiments reveal that the single-agent version of R2-KG, equipped with a strict self-consistency strategy, achieves significantly higher-than-baseline reliability while reducing inference cost. However, it also leads to a higher abstention rate in complex KGs. Our findings establish R2-KG as a flexible and cost-effective solution for KG-based reasoning. It reduces reliance on high-capacity LLMs while ensuring trustworthy inference. </p>
<blockquote>
<p>最近的研究结合了大型语言模型（LLM）和知识图谱（KG），以提高推理能力，可以在不进行额外训练的情况下提高推理准确性，同时减轻虚构现象。然而，现有的框架通常很僵化，难以适应知识图谱或任务变化。它们还严重依赖于功能强大的LLM进行可靠（即值得信赖）的推理。为了解决这一问题，我们引入了R2-KG，这是一个即插即用的双代理框架，将推理分为两个角色：一个负责收集证据的Operator（低容量LLM）和一个负责做出最终判断的Supervisor（高容量LLM）。这种设计在LLM推理方面是成本效益的，同时仍能保持强大的推理准确性。此外，R2-KG采用了一种弃权机制，只在从知识图谱收集到足够证据时才生成答案，这显著提高了可靠性。在多个基于知识图谱的推理任务上的实验表明，R2-KG在准确性和可靠性方面始终优于基准线，无论使用的Operator的LLM能力如何。进一步的实验表明，配备严格自我一致性策略的R2-KG的单代理版本在达到基线以上的可靠性的同时降低了推理成本。然而，这在复杂的KG中也导致了更高的弃权率。我们的研究结果表明，R2-KG是一个灵活且成本效益高的解决基于KG的推理问题的方案。它降低了对高容量LLM的依赖，同时确保可信的推理。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12767v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>最近的研究结合了大型语言模型（LLMs）和知识图谱（KGs）以提高推理能力，从而提高推理准确性，同时减少训练负担并抑制虚构。然而，现有框架通常刚性且难以适应知识图谱或任务变化。它们还依赖于强大的LLMs进行可靠推理。为解决这一问题，我们推出了R2-KG，一个即插即用的双代理框架，将推理分为两个角色：收集证据的操作者（低容量LLM）和做出最终判断的监督者（高容量LLM）。这种设计在LLM推理方面成本效益高，同时保持强大的推理准确性。此外，R2-KG采用拒绝机制，仅在从知识图谱收集到足够证据时才生成答案，这显著提高了可靠性。在多个基于知识图谱的推理任务上的实验表明，R2-KG在准确性和可靠性方面始终优于基线，无论使用的操作者LLMs的能力如何。进一步实验表明，配备严格自我一致性策略的R2-KG单代理版本在可靠性方面实现了显著高于基线的表现，同时降低了推理成本。然而，这在复杂知识图谱中的拒绝率也较高。我们的研究结果表明，R2-KG是一个灵活且成本效益高的解决知识图谱基于推理的方案。它降低了对高容量LLMs的依赖，同时确保可靠的推理。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>R2-KG结合LLMs和KGs提高推理能力，增强准确性和可靠性。</li>
<li>现有框架缺乏灵活性和适应性，R2-KG通过分离推理角色解决这一问题。</li>
<li>R2-KG采用双代理设计，包括收集证据的操作者和做出判断的监督者。</li>
<li>R2-KG采用拒绝机制，提高答案的可靠性。</li>
<li>R2-KG在多个KG-based推理任务上表现优异，无论LLM能力如何。</li>
<li>单代理版本的R2-KG在复杂知识图谱中表现出较高的可靠性，但拒绝率也较高。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12767">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-2d0bff1494453dd87fb99d78b6627fc4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0eb1e1386042b2c75fc771ce339e52f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-393642f767d54684c51feb71db96f357.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Hypernetwork-based-approach-for-optimal-composition-design-in-partially-controlled-multi-agent-systems"><a href="#Hypernetwork-based-approach-for-optimal-composition-design-in-partially-controlled-multi-agent-systems" class="headerlink" title="Hypernetwork-based approach for optimal composition design in partially   controlled multi-agent systems"></a>Hypernetwork-based approach for optimal composition design in partially   controlled multi-agent systems</h2><p><strong>Authors:Kyeonghyeon Park, David Molina Concha, Hyun-Rok Lee, Chi-Guhn Lee, Taesik Lee</strong></p>
<p>Partially Controlled Multi-Agent Systems (PCMAS) are comprised of controllable agents, managed by a system designer, and uncontrollable agents, operating autonomously. This study addresses an optimal composition design problem in PCMAS, which involves the system designer’s problem, determining the optimal number and policies of controllable agents, and the uncontrollable agents’ problem, identifying their best-response policies. Solving this bi-level optimization problem is computationally intensive, as it requires repeatedly solving multi-agent reinforcement learning problems under various compositions for both types of agents. To address these challenges, we propose a novel hypernetwork-based framework that jointly optimizes the system’s composition and agent policies. Unlike traditional methods that train separate policy networks for each composition, the proposed framework generates policies for both controllable and uncontrollable agents through a unified hypernetwork. This approach enables efficient information sharing across similar configurations, thereby reducing computational overhead. Additional improvements are achieved by incorporating reward parameter optimization and mean action networks. Using real-world New York City taxi data, we demonstrate that our framework outperforms existing methods in approximating equilibrium policies. Our experimental results show significant improvements in key performance metrics, such as order response rate and served demand, highlighting the practical utility of controlling agents and their potential to enhance decision-making in PCMAS. </p>
<blockquote>
<p>部分控制多智能体系统（PCMAS）由系统设计师管理的可控智能体和自主运行的不可控智能体组成。本研究解决了PCMAS中的最优组合设计问题，这涉及到系统设计师的问题，即确定可控智能体的最优数量和策略，以及不可控智能体的问题，即确定其最佳响应策略。解决这个两级优化问题是计算密集型的，因为它需要针对两种类型的智能体在各种组合下反复解决多智能体强化学习问题。为了解决这些挑战，我们提出了一种基于超网络的新型框架，该框架可以联合优化系统的组合和智能体策略。不同于传统方法为每种组合分别训练策略网络，所提出的框架通过统一的超网络为可控和不可控智能体生成策略。这种方法使得在类似配置之间能够有效地共享信息，从而减少了计算开销。通过整合奖励参数优化和平均行动网络，实现了进一步的改进。我们使用纽约市出租车真实数据证明，我们的框架在逼近均衡策略方面优于现有方法。我们的实验结果显示关键性能指标，如订单响应率和需求服务率有显著改善，突出了控制智能体的实用性以及它们在PCMAS中提高决策制定的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12605v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>多代理系统包含可控代理和自主操作的不可控代理。本研究针对其中的最优构成设计问题，涉及系统设计师确定可控代理的最优数量和策略，以及不可控代理的最佳响应策略。解决这个双层优化问题是计算密集型的，需要为两种类型的代理在各种构成下重复解决多代理强化学习问题。为此，我们提出了基于超网络的新框架，该框架可以联合优化系统的构成和代理策略。不同于传统方法为每种构成训练单独的策略网络，我们的框架通过统一的超网络为可控和不可控代理生成策略。这减少了计算开销并提高了效率。通过引入奖励参数优化和平均动作网络进一步提高了性能。使用纽约市出租车数据的实验表明，我们的框架在近似均衡策略方面优于现有方法。关键性能指标如订单响应率和需求服务率得到显著提高，凸显了控制代理的实际效用及其在增强多代理系统决策潜力方面的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>部分控制多代理系统包含可控和不可控两种代理。</li>
<li>最优构成设计问题涉及系统设计师确定可控代理的数量和策略，以及不可控代理的最佳响应策略。</li>
<li>解决这个问题的双层优化是计算密集型的。</li>
<li>提出了基于超网络的新框架，联合优化系统构成和代理策略。</li>
<li>该框架通过统一的超网络生成可控和不可控代理的策略，提高计算效率。</li>
<li>通过奖励参数优化和平均动作网络的引入进一步提升了框架性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12605">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-70ec96f5689d83f89f26e9e8027b4e77.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a21501078d095c8338598bbe8a966ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-94c2e21437c50e2ae5b878863560eedc.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DemonAgent-Dynamically-Encrypted-Multi-Backdoor-Implantation-Attack-on-LLM-based-Agent"><a href="#DemonAgent-Dynamically-Encrypted-Multi-Backdoor-Implantation-Attack-on-LLM-based-Agent" class="headerlink" title="DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on   LLM-based Agent"></a>DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on   LLM-based Agent</h2><p><strong>Authors:Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su</strong></p>
<p>As LLM-based agents become increasingly prevalent, backdoors can be implanted into agents through user queries or environment feedback, raising critical concerns regarding safety vulnerabilities. However, backdoor attacks are typically detectable by safety audits that analyze the reasoning process of agents. To this end, we propose a novel backdoor implantation strategy called \textbf{Dynamically Encrypted Multi-Backdoor Implantation Attack}. Specifically, we introduce dynamic encryption, which maps the backdoor into benign content, effectively circumventing safety audits. To enhance stealthiness, we further decompose the backdoor into multiple sub-backdoor fragments. Based on these advancements, backdoors are allowed to bypass safety audits significantly. Additionally, we present AgentBackdoorEval, a dataset designed for the comprehensive evaluation of agent backdoor attacks. Experimental results across multiple datasets demonstrate that our method achieves an attack success rate nearing 100% while maintaining a detection rate of 0%, illustrating its effectiveness in evading safety audits. Our findings highlight the limitations of existing safety mechanisms in detecting advanced attacks, underscoring the urgent need for more robust defenses against backdoor threats. Code and data are available at <a target="_blank" rel="noopener" href="https://github.com/whfeLingYu/DemonAgent">https://github.com/whfeLingYu/DemonAgent</a>. </p>
<blockquote>
<p>随着基于大型语言模型的代理日益普及，可以通过用户查询或环境反馈将后门植入代理，这引发了人们对安全漏洞的关键担忧。然而，后门攻击通常可以通过分析代理的推理过程来进行安全审计检测。为此，我们提出了一种新的后门植入策略，称为“动态加密多后门植入攻击”。具体来说，我们引入了动态加密技术，将后门映射到良性内容中，从而有效地绕过安全审计。为了提高隐蔽性，我们将后门进一步分解为多个子后门片段。基于这些进展，后门能够显著绕过安全审计。此外，我们还推出了AgentBackdoorEval数据集，用于全面评估代理后门攻击。跨多个数据集的实验结果表明，我们的方法攻击成功率接近100%，同时保持0%的检测率，证明了其在躲避安全审计方面的有效性。我们的研究凸显了现有安全机制在应对高级攻击方面的局限性，并强调了应对后门威胁的更强大防御手段的迫切需求。代码和数据集可在<a target="_blank" rel="noopener" href="https://github.com/whfeLingYu/DemonAgent%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/whfeLingYu/DemonAgent找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12575v1">PDF</a> </p>
<p><strong>Summary</strong><br>大型语言模型（LLM）为基础构建的代理日渐普及，引发安全隐患。新策略动态加密多后门植入攻击将后门嵌入用户查询或环境反馈中，并映射至良性内容以规避安全审计检测。利用该策略将后门分解为多个子片段增强隐匿性。数据集AgentBackdoorEval旨在全面评估代理后门攻击。实验结果表明新方法攻击成功率近百分之百同时检测率为零，突显现有安全机制对高级攻击的局限性，强调应对后门威胁的迫切需求。更多代码和数据可通过相关链接获取。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型代理普及带来安全隐患。</li>
<li>提出动态加密多后门植入攻击策略，规避安全审计检测。</li>
<li>将后门分解为子片段以增强隐匿性。</li>
<li>介绍用于全面评估代理后门攻击的数据集AgentBackdoorEval。</li>
<li>实验显示新攻击方法成功率高且检测率为零。</li>
<li>现有安全机制对高级攻击的局限性被突显。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12575">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-5db3a3cf6976bca602262eed3db0d65f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1b13b27d68c64a1ddf44b81f7c1af827.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cea51fe19a7e4608a8d2c02e04b93a0d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ecba4bd9ca7b2bb5358e05144f03bdd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d364d853395be11fc76c01ccf91f194.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="AutoAgent-A-Fully-Automated-and-Zero-Code-Framework-for-LLM-Agents"><a href="#AutoAgent-A-Fully-Automated-and-Zero-Code-Framework-for-LLM-Agents" class="headerlink" title="AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents"></a>AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents</h2><p><strong>Authors:Jiabin Tang, Tianyu Fan, Chao Huang</strong></p>
<p>Large Language Model (LLM) Agents have demonstrated remarkable capabilities in task automation and intelligent decision-making, driving the widespread adoption of agent development frameworks such as LangChain and AutoGen. However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills. This stark accessibility gap raises a fundamental question: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone? To address this challenge, we introduce AutoAgent-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone. Operating as an autonomous Agent Operating System, AutoAgent comprises four key components: i) Agentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing File System, and iv) Self-Play Agent Customization module. This lightweight yet powerful system enables efficient and dynamic creation and modification of tools, agents, and workflows without coding requirements or manual intervention. Beyond its code-free agent development capabilities, AutoAgent also serves as a versatile multi-agent system for General AI Assistants. Comprehensive evaluations on the GAIA benchmark demonstrate AutoAgent’s effectiveness in generalist multi-agent tasks, surpassing existing state-of-the-art methods. Furthermore, AutoAgent’s Retrieval-Augmented Generation (RAG)-related capabilities have shown consistently superior performance compared to many alternative LLM-based solutions. </p>
<blockquote>
<p>大型语言模型（LLM）代理在任务自动化和智能决策方面展示了卓越的能力，推动了诸如LangChain和AutoGen等代理开发框架的广泛采用。然而，这些框架主要服务于具有丰富技术专长的开发者——考虑到全球只有0.03%的人口具备必要的编程技能，这是一个重要的局限性。这一严峻的可访问性差距提出了一个根本性的问题：我们能否让每个人仅凭自然语言就能构建自己的LLM代理，而不考虑他们的技术背景？为了解决这一挑战，我们推出了AutoAgent——一个全自动、高度自我发展的框架，使用户能够仅凭自然语言创建和部署LLM代理。AutoAgent作为一个自主代理操作系统运行，包含四个关键组件：i)代理系统实用程序、ii)LLM驱动的可行引擎、iii)自我管理的文件系统、iv)自我玩耍代理自定义模块。这个轻便而强大的系统能够高效、动态地创建和修改工具、代理和工作流程，无需编码或人工干预。除了无代码代理开发能力之外，AutoAgent还作为通用人工智能助理的多代理系统。在GAIA基准测试上的综合评估表明，AutoAgent在通用多代理任务中的有效性超过了现有最先进的方法。此外，AutoAgent的检索增强生成（RAG）相关功能在许多替代的LLM解决方案中表现出了一贯的卓越性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05957v2">PDF</a> Code: <a target="_blank" rel="noopener" href="https://github.com/HKUDS/AutoAgent">https://github.com/HKUDS/AutoAgent</a></p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理在任务自动化和智能决策方面表现出卓越的能力，推动了诸如LangChain和AutoGen等代理开发框架的广泛应用。然而，这些框架主要服务于拥有深厚技术专长开发人员，考虑全球只有0.03%的人具备必要的编程技能，因此存在显著的可访问性差距。为解决这一挑战，我们推出了AutoAgent——一个全自动化、高度自我发展的框架，用户只需通过自然语言即可创建和部署LLM代理。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM代理在任务自动化和智能决策方面表现出卓越的能力。</li>
<li>目前框架主要服务于具有深厚技术背景的开发人员，存在可访问性差距。</li>
<li>AutoAgent框架旨在解决这一差距，使所有人都可以通过自然语言创建和部署LLM代理。</li>
<li>AutoAgent作为一个自主代理操作系统，具备四个关键组件。</li>
<li>该系统无需编码要求或手动干预，能够高效、动态地创建和修改工具、代理和工作流程。</li>
<li>AutoAgent不仅具备无代码代理开发能力，还作为一个通用的多代理系统为通用AI助理服务。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05957">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-b6ca207e83daf0a8ca254de333f0c53a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a2bc333ba0739771e6604a28bf5adff6.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A3-Android-Agent-Arena-for-Mobile-GUI-Agents"><a href="#A3-Android-Agent-Arena-for-Mobile-GUI-Agents" class="headerlink" title="A3: Android Agent Arena for Mobile GUI Agents"></a>A3: Android Agent Arena for Mobile GUI Agents</h2><p><strong>Authors:Yuxiang Chai, Hanhao Li, Jiayu Zhang, Liang Liu, Guangyi Liu, Guozhi Wang, Shuai Ren, Siyuan Huang, Hongsheng Li</strong></p>
<p>AI agents have become increasingly prevalent in recent years, driven by significant advancements in the field of large language models (LLMs). Mobile GUI agents, a subset of AI agents, are designed to autonomously perform tasks on mobile devices. While numerous studies have introduced agents, datasets, and benchmarks to advance mobile GUI agent research, many existing datasets focus on static frame evaluations and fail to provide a comprehensive platform for assessing performance on real-world, in-the-wild tasks. To address this gap, we present Android Agent Arena (A3), a novel evaluation platform. Unlike existing in-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as real-time online information retrieval and operational instructions; (2) a larger, more flexible action space, enabling compatibility with agents trained on any dataset; and (3) automated business-level LLM-based evaluation process. A3 includes 21 widely used general third-party apps and 201 tasks representative of common user scenarios, providing a robust foundation for evaluating mobile GUI agents in real-world situations and a new autonomous evaluation process for less human labor and coding expertise. The project is available at <a target="_blank" rel="noopener" href="https://yuxiangchai.github.io/Android-Agent-Arena/">https://yuxiangchai.github.io/Android-Agent-Arena/</a>. </p>
<blockquote>
<p>近年来，随着自然语言模型（LLM）领域的重大进展，人工智能代理（AI agents）变得越来越普遍。移动图形用户界面代理（Mobile GUI agents）是人工智能代理的一个子集，旨在自主执行移动设备上的任务。尽管许多研究已经引入了代理、数据集和基准测试来推动移动GUI代理的研究，但许多现有数据集侧重于静态框架评估，未能为现实世界中的任务提供一个全面的评估平台。为了解决这一空白，我们推出了Android Agent Arena（A3）这一新型评估平台。与现有的野外系统不同，A3提供了：（1）有意义且实用的任务，如实时在线信息检索和操作规程；（2）更大的灵活动作空间，可与任何数据集训练的代理兼容；（3）自动化的业务级LLM评估流程。A3包括21个广泛使用的第三方通用应用程序和201个代表常见用户场景的任务，为评估移动GUI代理在现实世界中的情况提供了一个坚实的基础，并为减少人工劳动和编码专业知识提供了一个新的自主评估流程。该项目可在<a target="_blank" rel="noopener" href="https://yuxiangchai.github.io/Android-Agent-Arena/%E6%89%BE%E5%88%B0%E3%80%82">https://yuxiangchai.github.io/Android-Agent-Arena/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01149v2">PDF</a> </p>
<p><strong>Summary</strong><br>     随着自然语言模型领域的重大进展，AI代理日益普及。移动GUI代理作为AI代理的一个子集，旨在在移动设备上自主执行任务。为评估移动GUI代理性能，存在众多数据集和研究，但许多数据集侧重于静态框架评估，未能为评估真实世界任务性能提供全面平台。为解决此问题，推出Android Agent Arena（A3）这一新型评估平台，该平台具有实用任务、更大的灵活动作空间并采用自动化业务级LLM评估流程等优点。A3包含21个通用第三方应用和201个代表常见用户场景的任务，为评估移动GUI代理在真实世界中的表现提供坚实基础，并减少人工和编码专业知识需求。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI代理近年来日益普及，得益于自然语言模型领域的进步。</li>
<li>移动GUI代理是AI代理的一个子集，旨在在移动设备上自主执行任务。</li>
<li>现有数据集在评估移动GUI代理性能时存在局限性，主要侧重于静态框架评估。</li>
<li>Android Agent Arena（A3）是一个新型评估平台，旨在解决现有数据集的问题。</li>
<li>A3提供实用任务，如实时在线信息检索和操作指南。</li>
<li>A3具有更大的灵活动作空间，可与任何数据集上训练的代理兼容。</li>
<li>A3采用自动化业务级LLM评估流程，减少人工和编码专业知识需求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01149">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-509a10fdf6c6b07c4d0432e6ded7d510.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b2d3de028a4f092174e9b0257e66f47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2efc1b81d5fb0ce88cb8affe3e22525.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77531e657315e489bd5ecb71c45fe3ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e63d4ebb488e90a22ae43ca07d4fba01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed22bb221d2f75794e629a5ce0e3d855.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="SmartAgent-Chain-of-User-Thought-for-Embodied-Personalized-Agent-in-Cyber-World"><a href="#SmartAgent-Chain-of-User-Thought-for-Embodied-Personalized-Agent-in-Cyber-World" class="headerlink" title="SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in   Cyber World"></a>SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in   Cyber World</h2><p><strong>Authors:Jiaqi Zhang, Chen Gao, Liyuan Zhang, Yong Li, Hongzhi Yin</strong></p>
<p>Recent advances in embodied agents with multimodal perception and reasoning capabilities based on large vision-language models (LVLMs), excel in autonomously interacting either real or cyber worlds, helping people make intelligent decisions in complex environments. However, the current works are normally optimized by golden action trajectories or ideal task-oriented solutions toward a definitive goal. This paradigm considers limited user-oriented factors, which could be the reason for their performance reduction in a wide range of personal assistant applications. To address this, we propose Chain-of-User-Thought (COUT), a novel embodied reasoning paradigm that takes a chain of thought from basic action thinking to explicit and implicit personalized preference thought to incorporate personalized factors into autonomous agent learning. To target COUT, we introduce SmartAgent, an agent framework perceiving cyber environments and reasoning personalized requirements as 1) interacting with GUI to access an item pool, 2) generating users’ explicit requirements implied by previous actions, and 3) recommending items to fulfill users’ implicit requirements. To demonstrate SmartAgent’s capabilities, we also create a brand-new dataset SmartSpot that offers a full-stage personalized action-involved environment. To our best knowledge, our work is the first to formulate the COUT process, serving as a preliminary attempt towards embodied personalized agent learning. Our extensive experiments on SmartSpot illuminate SmartAgent’s functionality among a series of embodied and personalized sub-tasks. We will release code and data upon paper notification at <a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/SmartAgent">https://github.com/tsinghua-fib-lab/SmartAgent</a>. </p>
<blockquote>
<p>基于大型视觉语言模型（LVLMs）的多模态感知和推理能力的实体代理最近取得了进展，它们擅长在真实或网络世界中进行自主交互，帮助人们在复杂环境中做出智能决策。然而，当前的工作通常是通过最佳行动轨迹或面向目标的理想解决方案来进行优化的，以达到明确的目标。这种范式考虑的用户导向因素有限，可能是其在个人助理应用程序的广泛性能下降的原因。为了解决这一问题，我们提出了用户思维链（COUT）这一新型实体推理范式，它可以从基本行动思维到明确和隐性的个性化偏好思维，将个性化因素融入自主代理学习中。为了瞄准COUT，我们引入了SmartAgent，这是一个感知网络环境的代理框架，并推理出个性化需求，包括1）与GUI交互以访问项目池，2）根据之前的行动生成用户的明确需求，以及3）推荐满足用户隐性需求的物品。为了展示SmartAgent的功能，我们还创建了一个全新的数据集SmartSpot，它提供了一个完整的个性化行动环境阶段。据我们所知，我们的工作是首次制定COUT流程，是朝着实体个性化代理学习迈出的初步尝试。我们在SmartSpot上的大量实验证明了SmartAgent在一系列实体和个性化子任务中的功能。论文通知发布后，我们将在<a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/SmartAgent">https://github.com/tsinghua-fib-lab/SmartAgent</a>上发布代码和数据。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07472v3">PDF</a> </p>
<p><strong>Summary</strong><br>    本文介绍了一种新的嵌入式智能体推理范式——Chain-of-User-Thought（COUT），旨在将用户的基本行动思考融入自主代理学习。为此，文章提出了SmartAgent框架，该框架可以感知网络环境并进行个性化推理。为实现SmartAgent的功能，文章创建了一个全新数据集SmartSpot，用于模拟个性化的行动环境。本文强调嵌入用户的行动思考对于自主代理学习的重要性，并展示了其在多个嵌入式和个性化子任务中的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>介绍了基于大型视觉语言模型（LVLMs）的多模态感知和推理能力的嵌入式代理的最新进展。</li>
<li>当前优化工作主要通过预定的行动轨迹或面向任务的目标解决方案进行，但这种方法忽略了用户的个性化因素，导致在多种个人助理应用中的性能下降。</li>
<li>提出了Chain-of-User-Thought（COUT）的新概念，这是一种将用户从基本行动思考到明确的和隐性的个性化偏好思考的思考链融入自主代理学习的理念。</li>
<li>介绍了SmartAgent框架，该框架可以感知网络环境并对个性化需求进行推理，包括与GUI交互访问项目池、生成用户由先前操作隐含的明确需求以及推荐满足用户隐性需求的项目。</li>
<li>创建了一个新的数据集SmartSpot，用于模拟个性化的行动环境，并展示了SmartAgent的功能。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07472">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-c9223f99c248eabbdf355550c58e596a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd3e4d53b0d959028cf1cbde2f56fcd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc574c085081f7f3a77a23d87369dfbf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f87d4aacd818018bcf55e626ec472276.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Optima-Optimizing-Effectiveness-and-Efficiency-for-LLM-Based-Multi-Agent-System"><a href="#Optima-Optimizing-Effectiveness-and-Efficiency-for-LLM-Based-Multi-Agent-System" class="headerlink" title="Optima: Optimizing Effectiveness and Efficiency for LLM-Based   Multi-Agent System"></a>Optima: Optimizing Effectiveness and Efficiency for LLM-Based   Multi-Agent System</h2><p><strong>Authors:Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun</strong></p>
<p>Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel framework that addresses these issues by significantly enhancing both communication efficiency and task effectiveness in LLM-based MAS through LLM training. Optima employs an iterative generate, rank, select, and train paradigm with a reward function balancing task performance, token efficiency, and communication readability. We explore various RL algorithms, including Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid approaches, providing insights into their effectiveness-efficiency trade-offs. We integrate Monte Carlo Tree Search-inspired techniques for DPO data generation, treating conversation turns as tree nodes to explore diverse interaction paths. Evaluated on common multi-agent tasks, including information-asymmetric question answering and complex reasoning, Optima shows consistent and substantial improvements over single-agent baselines and vanilla MAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than 10% tokens on tasks requiring heavy information exchange. Moreover, Optima’s efficiency gains open new possibilities for leveraging inference-compute more effectively, leading to improved inference-time scaling laws. By addressing fundamental challenges in LLM-based MAS, Optima shows the potential towards scalable, efficient, and effective MAS (<a target="_blank" rel="noopener" href="https://chenweize1998.github.io/optima-project-page">https://chenweize1998.github.io/optima-project-page</a>). </p>
<blockquote>
<p>基于大型语言模型（LLM）的多智能体系统（MAS）在协同解决问题方面显示出显著潜力，但它们仍面临关键挑战：通信效率低下、可扩展性差以及缺乏有效的参数更新优化方法。我们提出了Optima，这是一个通过LLM训练显著提高了基于LLM的MAS的通信效率和任务效率的新型框架。Optima采用了一种迭代生成、排名、选择和训练的模式，使用奖励函数来平衡任务性能、令牌效率和通信可读性。我们探索了各种强化学习算法，包括有监督微调、直接偏好优化及其混合方法，深入了解它们的有效性与效率之间的权衡。我们集成了受蒙特卡洛树搜索启发的技术，用于DPO数据生成，将对话回合视为树节点，以探索各种交互路径。在包括信息不对称问题回答和复杂推理等常见多智能体任务上，Optima相较于单智能体基准线和基于Llama 3 8B的原始MAS，表现出一致且实质性的改进，在需要重信息交换的任务上，仅用不到10%的令牌就实现了高达2.8倍的性能提升。此外，Optima的效率提升为实现更有效的推理计算利用打开了新途径，从而改善了推理时间缩放定律。通过解决基于LLM的MAS的根本挑战，Optima展示了向可扩展、高效和有成效的MAS发展的潜力（<a target="_blank" rel="noopener" href="https://chenweize1998.github.io/optima-project-page%EF%BC%89%E3%80%82">https://chenweize1998.github.io/optima-project-page）。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.08115v2">PDF</a> Under review</p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型（LLM）的多智能体系统（MAS）在协作问题解决方面展现出显著潜力，但仍面临沟通效率低下、缺乏可扩展性以及参数更新优化方法不足等挑战。我们提出Optima框架，通过LLM训练显著提高了LLM-based MAS的沟通效率和任务效率。Optima采用迭代生成、排名、选择和训练的模式，以平衡任务性能、令牌效率和沟通可读性的奖励函数。我们探索了各种强化学习算法，包括监督微调、直接偏好优化及其混合方法，以了解它们的有效性与效率之间的权衡。在常见的多任务环境下，Optima相较于单智能体基准测试和基于Llama 3 8B的传统MAS，表现出持续且显著的改进，在需要重信息交换的任务上实现了高达2.8倍的性能提升，并使用不到10%的令牌。此外，Optima的效率提升使得更有效地利用推理计算成为可能，并改善了推理时间的扩展定律。通过解决LLM-based MAS的基本挑战，Optima展现了可扩展、高效和有潜力的MAS。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based MAS在协作问题解决中有显著潜力，但仍面临沟通效率低下、缺乏可扩展性和优化方法不足等挑战。</li>
<li>Optima框架通过LLM训练提高了LLM-based MAS的沟通效率和任务效率。</li>
<li>Optima采用生成、排名、选择和训练的迭代模式，并平衡任务性能、令牌效率和沟通可读性的奖励函数。</li>
<li>强化了学习算法包括监督微调、直接偏好优化及其混合方法，以优化效率与效果之间的权衡。</li>
<li>Optima在多项任务中表现出优异性能，相较于基准测试和传统MAS有显著改进。</li>
<li>Optima实现了高效利用推理计算，改善了推理时间的扩展定律。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.08115">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-75946c2668f50684ab5a43d587dd6e38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be37e5b52a7bbef2d2c63addcd114e40.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-133eacc248ccbd3d29e0eb80e69a969e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GPUDrive-Data-driven-multi-agent-driving-simulation-at-1-million-FPS"><a href="#GPUDrive-Data-driven-multi-agent-driving-simulation-at-1-million-FPS" class="headerlink" title="GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS"></a>GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS</h2><p><strong>Authors:Saman Kazemkhani, Aarav Pandya, Daphne Cornelisse, Brennan Shacklett, Eugene Vinitsky</strong></p>
<p>Multi-agent learning algorithms have been successful at generating superhuman planning in various games but have had limited impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at scale, we present GPUDrive. GPUDrive is a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine capable of generating over a million simulation steps per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. Despite these low-level optimizations, GPUDrive is fully accessible through Python, offering a seamless and efficient workflow for multi-agent, closed-loop simulation. Using GPUDrive, we train reinforcement learning agents on the Waymo Open Motion Dataset, achieving efficient goal-reaching in minutes and scaling to thousands of scenarios in hours. We open-source the code and pre-trained agents at <a target="_blank" rel="noopener" href="https://github.com/Emerge-Lab/gpudrive">https://github.com/Emerge-Lab/gpudrive</a>. </p>
<blockquote>
<p>多智能体学习算法在各种游戏中已经成功生成了超人规划，但对已部署的多智能体规划的设计影响有限。将这些技术应用于多智能体规划的关键瓶颈在于它们需要数十亿步的经验。为了实现在大规模上的多智能体规划研究，我们推出了GPUDrive。GPUDrive是一款基于Madrona游戏引擎的GPU加速多智能体模拟器，每秒能生成超过一百万步的模拟。观察、奖励和动态函数直接用C++编写，允许用户定义复杂、异构的智能体行为，降低为高性能CUDA。尽管有这些底层优化，GPUDrive完全可以通过Python访问，为多智能体闭环模拟提供了无缝、高效的工作流程。我们使用GPUDrive在Waymo Open Motion数据集上训练强化学习智能体，能在几分钟内实现有效的目标达成，并在数小时内扩展到数千个场景。我们在<a target="_blank" rel="noopener" href="https://github.com/Emerge-Lab/gpudrive%E5%85%AC%E5%BC%80%E4%BA%86%E4%BB%A3%E7%A0%81%E5%92%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E6%99%BA%E8%83%BD%E4%BD%93%E3%80%82">https://github.com/Emerge-Lab/gpudrive公开了代码和预训练智能体。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.01584v3">PDF</a> ICLR 2025 camera-ready version</p>
<p><strong>Summary</strong></p>
<p>GPU加速的多智能体模拟器GPUDrive可生成每秒超百万步的智能体模拟，适用于大规模的多智能体规划研究。GPUDrive基于Madrona游戏引擎构建，可直接在C++中编写观察、奖励和动态函数，以定义复杂、异构的智能体行为。通过Python访问GPUDrive可实现无缝高效的多智能体闭环模拟。利用GPUDrive训练强化学习智能体可达到高效的实时目标达成并可在数小时内扩展到数千个场景。我们公开的代码和预训练智能体可在<a target="_blank" rel="noopener" href="https://github.com/Emerge-Lab/gpudrive%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Emerge-Lab/gpudrive获取。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GPU加速的多智能体模拟器GPUDrive可以实现大规模的多智能体规划研究，具有快速模拟能力。</li>
<li>GPUDrive基于Madrona游戏引擎构建，支持复杂的异构智能体行为定义。</li>
<li>GPUDrive通过Python接口提供无缝高效的多智能体闭环模拟。</li>
<li>GPUDrive能够利用强化学习在Waymo Open Motion数据集上训练智能体。</li>
<li>GPUDrive能够在短时间内实现高效的实时目标达成，并能快速扩展到数千个场景。</li>
<li>GPUDrive已在<a target="_blank" rel="noopener" href="https://github.com/Emerge-Lab/gpudrive%E4%B8%8A%E5%BC%80%E6%BA%90%E6%8F%90%E4%BE%9B%E4%BB%A3%E7%A0%81%E5%92%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E6%99%BA%E8%83%BD%E4%BD%93%E4%BE%9B%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E5%92%8C%E7%A0%94%E7%A9%B6%E3%80%82">https://github.com/Emerge-Lab/gpudrive上开源提供代码和预训练智能体供用户使用和研究。</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.01584">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fb70ae6d743de373b7b0cdfe83041e40.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6bbd6882ee3b18699e2c443565ab4177.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-216f8505c6232af1ce069c69ba7d8f3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98353af60dcf1db63c3bd30ba35d77eb.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-20/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-20/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-20/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f39c32afa7bb8bdf0e3667a1ff29a511.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-02-20  Do we still need Human Annotators? Prompting Large Language Models for   Aspect Sentiment Quad Prediction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-20/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-774efd57a46de594c5180bbbcdb3454a.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-02-20  Re-Align Aligning Vision Language Models via Retrieval-Augmented Direct   Preference Optimization
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">11538.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
