<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2024-04-22  Learn2Talk 3D Talking Face Learns from 2D Talking Face">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-c36e0e4bd338738e2a5420e68cd6ab5d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-04-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    19 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-04-22-更新"><a href="#2024-04-22-更新" class="headerlink" title="2024-04-22 更新"></a>2024-04-22 更新</h1><h2 id="Learn2Talk-3D-Talking-Face-Learns-from-2D-Talking-Face"><a href="#Learn2Talk-3D-Talking-Face-Learns-from-2D-Talking-Face" class="headerlink" title="Learn2Talk: 3D Talking Face Learns from 2D Talking Face"></a>Learn2Talk: 3D Talking Face Learns from 2D Talking Face</h2><p><strong>Authors:Yixiang Zhuang, Baoping Cheng, Yao Cheng, Yuntao Jin, Renshuai Liu, Chengyang Li, Xuan Cheng, Jing Liao, Juncong Lin</strong></p>
<p>Speech-driven facial animation methods usually contain two main classes, 3D and 2D talking face, both of which attract considerable research attention in recent years. However, to the best of our knowledge, the research on 3D talking face does not go deeper as 2D talking face, in the aspect of lip-synchronization (lip-sync) and speech perception. To mind the gap between the two sub-fields, we propose a learning framework named Learn2Talk, which can construct a better 3D talking face network by exploiting two expertise points from the field of 2D talking face. Firstly, inspired by the audio-video sync network, a 3D sync-lip expert model is devised for the pursuit of lip-sync between audio and 3D facial motion. Secondly, a teacher model selected from 2D talking face methods is used to guide the training of the audio-to-3D motions regression network to yield more 3D vertex accuracy. Extensive experiments show the advantages of the proposed framework in terms of lip-sync, vertex accuracy and speech perception, compared with state-of-the-arts. Finally, we show two applications of the proposed framework: audio-visual speech recognition and speech-driven 3D Gaussian Splatting based avatar animation. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12888v1">PDF</a> </p>
<p><strong>Summary</strong><br>通过借鉴2D说话人面部的唇形同步和言语感知领域的专业知识，提出了一种学习框架，可以构建更好的3D说话人面部网络。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D说话人面部研究在唇形同步和言语感知方面不如2D说话人面部研究深入。</li>
<li>Learn2Talk框架利用2D说话人面部领域的两个专业知识点来构建更好的3D说话人面部网络。</li>
<li>3D同步唇专家模型旨在实现音频和3D面部运动之间的唇形同步。</li>
<li>2D说话人面部方法中选择的教师模型用于指导音频到3D运动回归网络的训练，以提高3D顶点精度。</li>
<li>广泛的实验表明，该框架在唇形同步、顶点精度和言语感知方面优于现有技术。</li>
<li>该框架有语音-视觉语音识别和语音驱动3D高斯飞溅基于头像动画两个应用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>标题：Learn2Talk：3D 说话人脸从 2D 说话人脸学习</p>
</li>
<li>
<p>作者：Yixiang Zhuang, Baoping Cheng, Yao Cheng, Yuntao Jin, Renshuai Liu, Chengyang Li, Xuan
Cheng, Jing Liao, Juncong Lin</p>
</li>
<li>
<p>单位：暂缺</p>
</li>
<li>
<p>关键词：Speech-driven, 3D Facial Animation, 2D Talking face, Transformer, 3D Gaussian Splatting</p>
</li>
<li>
<p>论文链接：https://arxiv.org/abs/2404.12888v1
Github：None</p>
</li>
<li>
<p>摘要：</p>
</li>
</ol>
<p>（1）：研究背景：说话人脸动画方法通常包含 3D 和 2D 说话人脸两大类，近年来两者都备受研究关注。然而，据我们所知，3D 说话人脸的研究在唇形同步（lip-sync）和语音感知方面并未像 2D 说话人脸那样深入。</p>
<p>（2）：过去的方法及其问题：本文方法动机充分。</p>
<p>（3）：本文提出的研究方法：提出一个名为 Learn2Talk 的学习框架，该框架通过利用 2D 说话人脸领域的两个专业知识点来构建一个更好的 3D 说话人脸网络。首先，受音频视频同步网络的启发，设计了一个 3D 同步唇形专家模型，以追求音频和 3D 面部动作之间的唇形同步。其次，选择一个来自 2D 说话人脸方法的教师模型来指导音频到 3D 运动回归网络的训练，以产生更高的 3D 顶点精度。</p>
<p>（4）：方法性能：本文方法在唇形同步、顶点精度和语音感知方面均优于现有技术。这些性能可以支持其目标。</p>
<ol>
<li>方法：</li>
</ol>
<p>（1）：提出一个名为 Learn2Talk 的学习框架，该框架通过利用 2D 说话人脸领域的两个专业知识点来构建一个更好的 3D 说话人脸网络。</p>
<p>（2）：设计了一个 3D 同步唇形专家模型，以追求音频和 3D 面部动作之间的唇形同步。</p>
<p>（3）：选择一个来自 2D 说话人脸方法的教师模型来指导音频到 3D 运动回归网络的训练，以产生更高的 3D 顶点精度。</p>
<ol>
<li>结论：</li>
</ol>
<p>（1）：本文提出了一种名为 Learn2Talk 的学习框架，该框架通过利用 2D 说话人脸领域的两个专业知识点来构建一个更好的 3D 说话人脸网络，在唇形同步、顶点精度和语音感知方面均优于现有技术。</p>
<p>（2）：创新点：提出了一种新的 3D 说话人脸动画方法，该方法利用了 2D 说话人脸领域的专业知识；性能：在唇形同步、顶点精度和语音感知方面均优于现有技术；工作量：需要收集和标注大量的数据。</p>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c2e8566372db83537dc565617387f4cf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c36e0e4bd338738e2a5420e68cd6ab5d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-3fe7530e7260eff001a6736622671663.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-3f8c50de092534c8ec8b833626c35e42.jpg" align="middle">
</details>




<h2 id="Contrastive-Gaussian-Clustering-Weakly-Supervised-3D-Scene-Segmentation"><a href="#Contrastive-Gaussian-Clustering-Weakly-Supervised-3D-Scene-Segmentation" class="headerlink" title="Contrastive Gaussian Clustering: Weakly Supervised 3D Scene Segmentation"></a>Contrastive Gaussian Clustering: Weakly Supervised 3D Scene Segmentation</h2><p><strong>Authors:Myrna C. Silva, Mahtab Dahaghin, Matteo Toso, Alessio Del Bue</strong></p>
<p>We introduce Contrastive Gaussian Clustering, a novel approach capable of provide segmentation masks from any viewpoint and of enabling 3D segmentation of the scene. Recent works in novel-view synthesis have shown how to model the appearance of a scene via a cloud of 3D Gaussians, and how to generate accurate images from a given viewpoint by projecting on it the Gaussians before $\alpha$ blending their color. Following this example, we train a model to include also a segmentation feature vector for each Gaussian. These can then be used for 3D scene segmentation, by clustering Gaussians according to their feature vectors; and to generate 2D segmentation masks, by projecting the Gaussians on a plane and $\alpha$ blending over their segmentation features. Using a combination of contrastive learning and spatial regularization, our method can be trained on inconsistent 2D segmentation masks, and still learn to generate segmentation masks consistent across all views. Moreover, the resulting model is extremely accurate, improving the IoU accuracy of the predicted masks by $+8%$ over the state of the art. Code and trained models will be released soon. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12784v1">PDF</a> </p>
<p><strong>Summary</strong><br>使用来自不同视角的对比高斯聚类实现 3D 场景分割。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>提出一种新的对比高斯聚类方法，能够从任何视角提供分割掩模，并实现场景的 3D 分割。</li>
<li>受新视角合成领域研究的启发，使用 3D 高斯云建模场景的外观。</li>
<li>通过将高斯投影到给定视点并对其颜色进行α混合，从给定视点生成准确的图像。</li>
<li>训练模型，使每个高斯都包含一个分割特征向量。</li>
<li>通过根据其特征向量对高斯进行聚类，可用于 3D 场景分割；通过将高斯投影到平面上并对其分割特征进行 α 混合，可生成 2D 分割掩模。</li>
<li>使用对比学习和空间正则化的组合，可以在不一致的 2D 分割掩模上训练我们的方法，并学习生成在所有视图中都一致的分割掩模。</li>
<li>所提出的方法非常准确，与现有技术相比，预测掩模的 IoU 准确度提高了 8%。</li>
<li>代码和训练好的模型即将发布。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>标题：对比高斯聚类：弱监督 3D 场景分割</p>
</li>
<li>
<p>作者：Myrna C. Silva、Mahtab Dahaghin、Matteo Toso、Alessio Del Bue</p>
</li>
<li>
<p>单位：意大利理工学院模式分析与计算机视觉（PAVIS）</p>
</li>
<li>
<p>关键词：3D 高斯散射、3D 分割、对比学习</p>
</li>
<li>
<p>论文链接：arXiv:2404.12784v1 [cs.CV]
   Github 链接：无</p>
</li>
<li>
<p>摘要：</p>
</li>
</ol>
<p>（1）：研究背景：近年来，新视角合成领域的研究表明，可以通过 3D 高斯云对场景的外观进行建模，并通过在给定视角上投影高斯并 α 混合其颜色来生成准确的图像。</p>
<p>（2）：过去方法与问题：高斯分组和 LangSplat 等方法存在以下问题：
   - 训练和评估需要大量 GPU 内存，导致某些场景无法处理。
   - 无法从任意视角提供分割掩码，也无法实现场景的 3D 分割。</p>
<p>（3）：研究方法：本文提出对比高斯聚类方法，该方法通过以下步骤实现 3D 场景分割和 2D 分割掩码预测：
   - 训练模型为每个高斯体添加分割特征向量。
   - 根据特征向量对高斯体进行聚类，实现 3D 场景分割。
   - 将高斯体投影到平面上并 α 混合其分割特征，生成 2D 分割掩码。
   - 使用对比学习和空间正则化，在不一致的 2D 分割掩码上训练模型，生成跨所有视角一致的分割掩码。</p>
<p>（4）：性能与目标：
   - 任务：3D 场景分割和 2D 分割掩码预测。
   - 性能：IoU 准确率比现有技术提高 +8%，表明该方法能够有效实现其目标。</p>
<ol>
<li>方法：</li>
</ol>
<p>（1）：将场景表示为 3D 高斯体集合，编码几何、外观和实例分割信息；</p>
<p>（2）：使用基础模型生成 2D 分割掩码；</p>
<p>（3）：优化 3D 高斯体，最小化渲染图像和真实图像之间的差异；</p>
<p>（4）：使用对比分割损失监督 3D 特征场；</p>
<p>（5）：引入正则化项，强制高斯体在欧几里得和分割特征空间中的距离相关；</p>
<p>（6）：渲染 2D 特征图，根据对应的 2D 分割掩码对渲染特征进行聚类，计算对比聚类损失；</p>
<p>（7）：最大化同一分割内特征之间的相似度，最小化不同分割内的特征相似度。</p>
<p><strong>8. 结论</strong></p>
<p><strong>(1)</strong> 本工作的主要意义在于：</p>
<p>提出了对比高斯聚类方法，实现了 3D 场景分割和 2D 分割掩码预测，有效提高了分割精度。</p>
<p><strong>(2)</strong> 本文优缺点总结（创新点、性能、工作量）：</p>
<p><strong>创新点：</strong></p>
<ul>
<li>引入对比学习和空间正则化，提高了分割掩码的一致性。</li>
<li>使用 3D 高斯体表示场景，编码几何、外观和实例分割信息。</li>
</ul>
<p><strong>性能：</strong></p>
<ul>
<li>IoU 准确率比现有技术提高 +8%，分割精度高。</li>
</ul>
<p><strong>工作量：</strong></p>
<ul>
<li>训练和评估需要大量 GPU 内存，大场景处理困难。</li>
<li>无法从任意视角提供分割掩码，无法实现场景的完整 3D 分割。</li>
</ul>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-252e679c7e0a5cfc8056b41c43d99b59.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-668e640c91611b7b91220b00abd05f4e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-03dada656b628530891ef19dcbebedba.jpg" align="middle">
</details>




<h2 id="RainyScape-Unsupervised-Rainy-Scene-Reconstruction-using-Decoupled-Neural-Rendering"><a href="#RainyScape-Unsupervised-Rainy-Scene-Reconstruction-using-Decoupled-Neural-Rendering" class="headerlink" title="RainyScape: Unsupervised Rainy Scene Reconstruction using Decoupled   Neural Rendering"></a>RainyScape: Unsupervised Rainy Scene Reconstruction using Decoupled   Neural Rendering</h2><p><strong>Authors:Xianqiang Lyu, Hui Liu, Junhui Hou</strong></p>
<p>We propose RainyScape, an unsupervised framework for reconstructing clean scenes from a collection of multi-view rainy images. RainyScape consists of two main modules: a neural rendering module and a rain-prediction module that incorporates a predictor network and a learnable latent embedding that captures the rain characteristics of the scene. Specifically, based on the spectral bias property of neural networks, we first optimize the neural rendering pipeline to obtain a low-frequency scene representation. Subsequently, we jointly optimize the two modules, driven by the proposed adaptive direction-sensitive gradient-based reconstruction loss, which encourages the network to distinguish between scene details and rain streaks, facilitating the propagation of gradients to the relevant components. Extensive experiments on both the classic neural radiance field and the recently proposed 3D Gaussian splatting demonstrate the superiority of our method in effectively eliminating rain streaks and rendering clean images, achieving state-of-the-art performance. The constructed high-quality dataset and source code will be publicly available. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.11401v1">PDF</a> </p>
<p><strong>Summary</strong><br>雨景重建：无监督地从多视角雨景图重建干净场景。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>提出无监督框架 RainyScape，重建干净场景。</li>
<li>RainyScape 由神经渲染和降雨预测模块组成。</li>
<li>降雨预测模块包含预测网络和可学习潜嵌入，捕捉场景的降雨特征。</li>
<li>基于神经网络的光谱偏差属性，优化神经渲染管道，获得低频场景表示。</li>
<li>利用自适应方向敏感梯度重建损失，优化两个模块，区分场景细节和雨痕。</li>
<li>在神经辐射场和 3D 高斯喷溅中进行的实验表明，该方法能有效消除雨痕、渲染干净图像，达到最先进性能。</li>
<li>将公开构建高质量数据集和源代码。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>标题：RainyScape：基于解耦神经渲染的无监督雨景重建</p>
</li>
<li>
<p>作者：Xianqiang Lyu, Hui Liu, Junhui Hou</p>
</li>
<li>
<p>单位：香港城市大学计算机科学系</p>
</li>
<li>
<p>关键词：雨景重建、神经渲染、无监督损失</p>
</li>
<li>
<p>论文链接：xxx，Github 链接：None</p>
</li>
<li>
<p>摘要：</p>
</li>
</ol>
<p>（1）：研究背景：神经辐射场（NeRF）在学习场景的连续体积表示方面取得了突破性进展，但当输入图像因模糊、噪声或雨水等因素而退化时，渲染结果不可避免地会出现明显伪影。</p>
<p>（2）：过去方法：现有方法针对不同的退化因素提出了特定任务的解决方案，但针对雨景重建任务的方法较少，且难以通过附加神经渲染场来表示雨水。</p>
<p>（3）：研究方法：本文提出 RainyScape，一个解耦的神经渲染框架，能够从雨景图像中无监督地重建无雨场景。该框架包括一个神经渲染模块和一个雨滴预测模块，通过学习雨滴嵌入和使用预测器来预测雨滴条纹，并提出自适应角度估计策略和梯度旋转损失来解耦场景高频细节和雨滴条纹。</p>
<p>（4）：方法性能：在经典神经辐射场和最近提出的 3D 高斯 splatting 上的广泛实验表明，该方法在有效消除雨滴条纹和渲染清晰图像方面优于现有方法，达到最先进的性能。</p>
<ol>
<li>方法：</li>
</ol>
<p>（1）：提出 RainyScape，一个解耦的神经渲染框架，能够从雨景图像中无监督地重建无雨场景。</p>
<p>（2）：该框架包括一个神经渲染模块和一个雨滴预测模块，通过学习雨滴嵌入和使用预测器来预测雨滴条纹。</p>
<p>（3）：提出自适应角度估计策略和梯度旋转损失来解耦场景高频细节和雨滴条纹。</p>
<ol>
<li>结论：<pre><code>            （1）：RainyScape 在雨景重建领域具有重要意义，它首次提出了一个解耦神经渲染框架，能够从雨景图像中无监督地重建无雨场景。 该框架通过将场景高频细节和雨滴条纹解耦，有效地消除了雨滴条纹，并渲染出清晰的图像。

<pre><code>        （2）：创新点：RainyScape 创新性地提出了一个解耦神经渲染框架，将场景高频细节和雨滴条纹解耦，有效地消除了雨滴条纹，并渲染出清晰的图像。

        性能：RainyScape 在经典神经辐射场和最近提出的 3D 高斯 splatting 上的广泛实验表明，该方法在有效消除雨滴条纹和渲染清晰图像方面优于现有方法，达到最先进的性能。

        工作量：RainyScape 的工作量中等，需要训练神经渲染模块和雨滴预测模块，并提出自适应角度估计策略和梯度旋转损失来解耦场景高频细节和雨滴条纹。
</code></pre>
<p></code></pre></p>
</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-789763f7ebb6ec7a923539611ab1fe24.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-89f176b1378008d1c0b63c9241adfdb2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5f7fb8305c36c1fe2572adfd98b584f7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-76be36036e15658d754b57c4864b0abf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-3765b699865b1d89cc9f5f13f9843a0e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-34d10a80ece07ba92081dfc066d00427.jpg" align="middle">
</details>




<h2 id="DeblurGS-Gaussian-Splatting-for-Camera-Motion-Blur"><a href="#DeblurGS-Gaussian-Splatting-for-Camera-Motion-Blur" class="headerlink" title="DeblurGS: Gaussian Splatting for Camera Motion Blur"></a>DeblurGS: Gaussian Splatting for Camera Motion Blur</h2><p><strong>Authors:Jeongtaek Oh, Jaeyoung Chung, Dongwoo Lee, Kyoung Mu Lee</strong></p>
<p>Although significant progress has been made in reconstructing sharp 3D scenes from motion-blurred images, a transition to real-world applications remains challenging. The primary obstacle stems from the severe blur which leads to inaccuracies in the acquisition of initial camera poses through Structure-from-Motion, a critical aspect often overlooked by previous approaches. To address this challenge, we propose DeblurGS, a method to optimize sharp 3D Gaussian Splatting from motion-blurred images, even with the noisy camera pose initialization. We restore a fine-grained sharp scene by leveraging the remarkable reconstruction capability of 3D Gaussian Splatting. Our approach estimates the 6-Degree-of-Freedom camera motion for each blurry observation and synthesizes corresponding blurry renderings for the optimization process. Furthermore, we propose Gaussian Densification Annealing strategy to prevent the generation of inaccurate Gaussians at erroneous locations during the early training stages when camera motion is still imprecise. Comprehensive experiments demonstrate that our DeblurGS achieves state-of-the-art performance in deblurring and novel view synthesis for real-world and synthetic benchmark datasets, as well as field-captured blurry smartphone videos. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.11358v2">PDF</a> </p>
<p><strong>Summary</strong><br>从模糊运动图像重建清晰 3D 场景方法，优化 3D 高斯投射，实现精确摄像机位姿初始化。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DeblurGS 优化高斯投射，提高运动模糊图像 3D 重建精度。</li>
<li>利用高斯投射的重建能力，还原精细锐利场景。</li>
<li>估计每幅模糊图像的 6 自由度摄像机运动，生成模糊渲染用于优化。</li>
<li>高斯密度退火策略防止错误位置生成不准确的高斯。</li>
<li>DeblurGS 在去模糊和合成新视角方面取得了最先进的性能。</li>
<li>适用于真实世界和合成基准数据集，以及现场拍摄的模糊智能手机视频。</li>
<li>DeblurGS 极大地扩展了运动模糊图像的 3D 重建的实际应用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: DeblurGS: 高斯溅射相机运动模糊 (DeblurGS: Gaussian Splatting for Camera Motion Blur)</p>
</li>
<li>
<p>Authors: Jeongtaek Oh, Jaeyoung Chung, Dongwoo Lee, and Kyoung Mu Lee</p>
</li>
<li>
<p>Affiliation: 首尔国立大学人工智能与信息处理研究所 (IPAI, Seoul National University)</p>
</li>
<li>
<p>Keywords: 3D Gaussian Splatting · Camera Motion Deblurring</p>
</li>
<li>
<p>Urls: None, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): 尽管从运动模糊图像重建清晰的 3D 场景方面取得了重大进展，但向实际应用的过渡仍然具有挑战性。主要障碍源于严重的模糊，这会导致通过 Structure-from-Motion 获取初始相机姿态的不准确，而这往往是以前的方法所忽视的关键方面。</p>
<p>(2): 过去的方法主要集中于模糊图像的去模糊处理，但对于初始相机姿态的噪声初始化不鲁棒。</p>
<p>(3): 本文提出 DeblurGS，这是一种从运动模糊图像优化清晰的 3D 高斯溅射的方法，即使在噪声相机姿态初始化的情况下也是如此。我们利用 3D 高斯溅射的出色重建能力来恢复细粒度的清晰场景。我们的方法估计每个模糊观测的 6 自由度相机运动，并为优化过程合成相应的模糊渲染。此外，我们提出了高斯致密化退火策略，以防止在相机运动仍然不精确的早期训练阶段在错误的位置生成不准确的高斯。</p>
<p>(4): 综合实验表明，我们的 DeblurGS 在真实世界和合成基准数据集以及现场捕获的模糊智能手机视频的去模糊和新视图合成方面实现了最先进的性能。</p>
<ol>
<li>方法：</li>
</ol>
<p>（1）：提出 DeblurGS，一种从运动模糊图像优化清晰的 3D 高斯溅射的方法；</p>
<p>（2）：利用 3D 高斯溅射的重建能力恢复细粒度的清晰场景；</p>
<p>（3）：估计每个模糊观测的 6 自由度相机运动，并合成相应的模糊渲染；</p>
<p>（4）：提出高斯致密化退火策略，防止在相机运动不精确的早期训练阶段生成不准确的高斯。</p>
<ol>
<li>结论：</li>
</ol>
<p>（1）：本文提出了一种从运动模糊图像优化清晰的 3D 高斯溅射的方法，即使在噪声相机姿态初始化的情况下也是如此。该方法利用 3D 高斯溅射的出色重建能力来恢复细粒度的清晰场景，估计每个模糊观测的 6 自由度相机运动，并为优化过程合成相应的模糊渲染。此外，该方法提出了高斯致密化退火策略，以防止在相机运动仍然不精确的早期训练阶段在错误的位置生成不准确的高斯。综合实验表明，该方法在真实世界和合成基准数据集以及现场捕获的模糊智能手机视频的去模糊和新视图合成方面实现了最先进的性能。</p>
<p>（2）：创新点：利用 3D 高斯溅射的重建能力恢复细粒度的清晰场景，即使在噪声相机姿态初始化的情况下也是如此；</p>
<p>性能：在真实世界和合成基准数据集以及现场捕获的模糊智能手机视频的去模糊和新视图合成方面实现了最先进的性能；</p>
<p>工作量：该方法需要估计每个模糊观测的 6 自由度相机运动，并为优化过程合成相应的模糊渲染，这可能会增加计算成本。</p>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d1b62fa212aabdf515b9baf8fdc306be.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-32c4f56eaf456fe86ff5f42abfbd6ffb.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-50b9e9cff40ee36449b6b3559539186a.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-04-22/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2024-04-22/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-04-22/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5f7fb8305c36c1fe2572adfd98b584f7.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2024-04-22  AG-NeRF Attention-guided Neural Radiance Fields for Multi-height   Large-scale Outdoor Scene Rendering
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-04-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-04-22/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3fe7530e7260eff001a6736622671663.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-04-22  Learn2Talk 3D Talking Face Learns from 2D Talking Face
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-04-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">7652.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    


        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script><script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
