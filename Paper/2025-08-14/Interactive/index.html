<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Interactive">
    <meta name="description" content="Interactive 方向最新论文已更新，请持续关注 Update in 2025-08-14  Explore, Listen, Inspect Supporting Multimodal Interaction with 3D   Surface and Point Data Visualizations">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Interactive | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2504.16858v2/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Interactive</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Interactive/">
                                <span class="chip bg-color">Interactive</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                Interactive
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    31 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-14-更新"><a href="#2025-08-14-更新" class="headerlink" title="2025-08-14 更新"></a>2025-08-14 更新</h1><h2 id="Explore-Listen-Inspect-Supporting-Multimodal-Interaction-with-3D-Surface-and-Point-Data-Visualizations"><a href="#Explore-Listen-Inspect-Supporting-Multimodal-Interaction-with-3D-Surface-and-Point-Data-Visualizations" class="headerlink" title="Explore, Listen, Inspect: Supporting Multimodal Interaction with 3D   Surface and Point Data Visualizations"></a>Explore, Listen, Inspect: Supporting Multimodal Interaction with 3D   Surface and Point Data Visualizations</h2><p><strong>Authors:Sanchita S. Kamath, Aziz N. Zeidieh, JooYoung Seo</strong></p>
<p>Blind and low-vision (BLV) users remain largely excluded from three-dimensional (3D) surface and point data visualizations due to the reliance on visual interaction. Existing approaches inadequately support non-visual access, especially in browser-based environments. This study introduces DIXTRAL, a hosted web-native system, co-designed with BLV researchers to address these gaps through multimodal interaction. Conducted with two blind and one sighted researcher, this study took place over sustained design sessions. Data were gathered through iterative testing of the prototype, collecting feedback on spatial navigation, sonification, and usability. Co-design observations demonstrate that synchronized auditory, visual, and textual feedback, combined with keyboard and gamepad navigation, enhances both structure discovery and orientation. DIXTRAL aims to improve access to 3D continuous scalar fields for BLV users and inform best practices for creating inclusive 3D visualizations. </p>
<blockquote>
<p>盲人和视力障碍（BLV）用户由于依赖于视觉交互，在很大程度上被排除在三维（3D）曲面和点数据可视化之外。现有的方法在非视觉访问方面的支持不足，特别是在基于浏览器的环境中。本研究介绍了DIXTRAL，这是一个托管的本地网络系统，与BLV研究者共同设计，通过多模式交互来解决这些差距。本研究持续进行的设计会话中，有两名盲人和一名视力正常的研究者参与。数据是通过原型的迭代测试收集的，收集了关于空间导航、声音反馈和可用性的反馈。共同设计的观察结果表明，同步的听觉、视觉和文本反馈，结合键盘和游戏手柄导航，可以增强结构的发现和方向感。DIXTRAL旨在提高BLV用户对三维连续标量场的访问能力，并为创建包容性三维可视化提供最佳实践信息。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08554v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本研究的目的是解决盲人和低视力用户无法参与三维表面和点数据可视化的问题。通过引入DIXTRAL系统，该系统采用多模式交互方式，为这类用户提供浏览器环境下的非视觉访问支持。研究过程中与盲人和有视力研究者共同设计，通过持续的设计会议和原型迭代测试收集数据，包括空间导航、声音反馈和可用性等方面的反馈。研究结果表明，结合听觉、视觉、文本反馈以及键盘和游戏手柄导航，能有效提升结构和方向的感知。DIXTRAL旨在改善盲人和低视力用户对三维连续标量场的访问体验，并为创建包容性三维可视化提供最佳实践指导。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DIXTRAL系统是为解决盲人和低视力用户无法参与三维数据可视化的问题而设计的。</li>
<li>该系统采用多模式交互方式，支持非视觉访问，特别是在浏览器环境下。</li>
<li>研究过程中与盲人和有视力研究者共同设计，强调用户参与的重要性。</li>
<li>通过持续的设计会议和原型迭代测试收集数据，包括空间导航、声音反馈和可用性等方面的反馈。</li>
<li>研究发现结合听觉、视觉和文本反馈以及键盘和游戏手柄导航能有效提升结构和方向的感知。</li>
<li>DIXTRAL旨在改善盲人和低视力用户对三维连续标量场的访问体验。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08554">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08554v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08554v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08554v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08554v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08554v1/page_3_1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="First-Ask-Then-Answer-A-Framework-Design-for-AI-Dialogue-Based-on-Supplementary-Questioning-with-Large-Language-Models"><a href="#First-Ask-Then-Answer-A-Framework-Design-for-AI-Dialogue-Based-on-Supplementary-Questioning-with-Large-Language-Models" class="headerlink" title="First Ask Then Answer: A Framework Design for AI Dialogue Based on   Supplementary Questioning with Large Language Models"></a>First Ask Then Answer: A Framework Design for AI Dialogue Based on   Supplementary Questioning with Large Language Models</h2><p><strong>Authors:Chuanruo Fu, Yuncheng Du</strong></p>
<p>Large Language Models (LLMs) often struggle to deliver accurate and actionable answers when user-provided information is incomplete or ill-specified. We propose a new interaction paradigm, First Ask Then Answer (FATA), in which, through prompt words, LLMs are guided to proactively generate multidimensional supplementary questions for users prior to response generation. Subsequently, by integrating user-provided supplementary information with the original query through sophisticated prompting techniques, we achieve substantially improved response quality and relevance. In contrast to existing clarification approaches – such as the CLAM framework oriented to ambiguity and the self-interrogation Self-Ask method – FATA emphasizes completeness (beyond mere disambiguation) and user participation (inviting human input instead of relying solely on model-internal reasoning). It also adopts a single-turn strategy: all clarifying questions are produced at once, thereby reducing dialogue length and improving efficiency. Conceptually, FATA uses the reasoning power of LLMs to scaffold user expression, enabling non-expert users to formulate more comprehensive and contextually relevant queries. To evaluate FATA, we constructed a multi-domain benchmark and compared it with two controls: a baseline prompt (B-Prompt) and a context-enhanced expert prompt (C-Prompt). Experimental results show that FATA outperforms B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient of variation 8% lower than C-Prompt, indicating superior stability. </p>
<blockquote>
<p>大型语言模型（LLM）在用户提供的资讯不完整或不明确时，往往难以提供准确和可操作的答案。我们提出了一种新的交互模式——先问后答（FATA），通过提示词引导LLM在生成答案前主动生成多维补充问题。随后，通过先进的提示技术整合用户提供的补充资讯和原始查询，我们实现了显著增强的响应质量和相关性。与现有的澄清方法不同，如面向模糊性的CLAM框架和自我反问的Self-Ask方法，FATA强调完整性（超越单纯的消歧）和用户参与（邀请人类输入而不是仅依赖模型内部推理）。它还采用单轮策略：所有澄清问题一次性提出，从而减少对话长度并提高效率。在概念上，FATA利用LLM的推理能力来支撑用户表达，使非专业用户能够制定更全面和上下文相关的查询。为了评估FATA，我们构建了一个多域基准并进行比较的两个控制组：基线提示（B-Prompt）和上下文增强专家提示（C-Prompt）。实验结果表明，FATA在总体指标上较基线提示高出约40%，并且变异系数较专家提示低8%，显示出更高的稳定性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08308v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型在用户信息不完整或不明确时，难以提供准确和可操作的答案。为此，本文提出了一种新的交互范式——先问后答（FATA），通过提示词引导LLM主动生成多维补充问题，再整合用户提供的补充信息与原始查询，实现响应质量和相关性的显著提高。与现有的澄清方法相比，FATA不仅强调消除歧义，更重视完整性，并强调用户参与。它采用单轮策略，一次性提出所有澄清问题，缩短对话长度，提高效率。实验结果表明，与基线提示相比，FATA的聚合指标提高了约40%，并且稳定性也较高。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM在用户信息不完整或不明确时面临挑战。</li>
<li>FATA范式通过生成多维补充问题来改善LLM的响应。</li>
<li>FATA结合用户补充信息和原始查询，提高响应质量和相关性。</li>
<li>FATA强调完整性和用户参与，不同于仅注重消除歧义的澄清方法。</li>
<li>FATA采用单轮策略，缩短对话长度，提高效率。</li>
<li>FATA在实验中表现出较高的性能和稳定性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08308">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08308v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08308v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Exploring-Safety-Alignment-Evaluation-of-LLMs-in-Chinese-Mental-Health-Dialogues-via-LLM-as-Judge"><a href="#Exploring-Safety-Alignment-Evaluation-of-LLMs-in-Chinese-Mental-Health-Dialogues-via-LLM-as-Judge" class="headerlink" title="Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health   Dialogues via LLM-as-Judge"></a>Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health   Dialogues via LLM-as-Judge</h2><p><strong>Authors:Yunna Cai, Fan Wang, Haowei Wang, Kun Wang, Kailai Yang, Sophia Ananiadou, Moyan Li, Mingming Fan</strong></p>
<p>Evaluating the safety alignment of LLM responses in high-risk mental health dialogues is particularly difficult due to missing gold-standard answers and the ethically sensitive nature of these interactions. To address this challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark based on real-world Chinese mental health dialogues. It evaluates whether the model responses align with the safety principles defined by experts. Specifically designed for settings without standard references, our method adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation using expert-defined reasoning chains grounded in psychological intervention principles. We employ binary point-wise scoring across multiple safety dimensions to enhance the explainability and traceability of the evaluation. Additionally, we present a manually curated, high-quality Chinese-language dataset covering self-harm, suicidal ideation, and existential distress, derived from real-world online discourse. Experiments on 3600 judgments show that our method achieves the highest agreement with expert assessments and produces more interpretable evaluation rationales compared to existing approaches. Our dataset and evaluation tool are publicly available to facilitate further research. </p>
<blockquote>
<p>评估高风险心理健康对话中LLM回答的安全一致性非常困难，原因在于缺乏黄金标准的答案以及这些互动的伦理敏感性。为了应对这一挑战，我们提出了PsyCrisis-Bench，这是一个基于真实世界中文心理健康对话的无参考评估基准。它评估模型回答是否与专家定义的安全原则相符。我们专为没有标准参考的设置设计此方法，采用基于提示的LLM-as-Judge方法，使用专家定义的基于心理干预原则的推理链进行上下文评估。我们在多个安全维度上采用二元点评分，以提高评估的可解释性和可追溯性。此外，我们还提供了一个手动整理的高质量中文数据集，涵盖自伤、自杀意念和存在性焦虑，来源于真实世界的在线对话。对3600次判断的实验表明，我们的方法与专家评估的契合度最高，与现有方法相比，产生的评估理由更具解释性。我们的数据集和评估工具已公开提供，以促进进一步的研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08236v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文本介绍了针对高风险心理健康对话中LLM响应的安全对齐评估的挑战性，并提出了一个基于真实世界中文心理健康对话的无参考评估基准——PsyCrisis-Bench。该方法采用基于提示的LLM-as-Judge方式进行上下文评估，以专家定义的心理干预原则为依据构建推理链。采用跨多个安全维度的二进制点计分方式，以提高评价的解性和可追溯性。此外，该论文还提供了一个覆盖自残、自杀意念和存在性焦虑的中文高质量数据集，这些数据集来自真实的在线对话。实验结果显示，该方法与专家评估的一致性最高，且相比现有方法能产生更可解释的评价依据。该数据集和评估工具已公开供进一步研究使用。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>评估LLM在高风险心理健康对话中的响应安全对齐是一项挑战，因为缺乏金标准答案和伦理敏感性。</li>
<li>PsyCrisis-Bench是一个基于真实世界中文心理健康对话的无参考评估基准，用于评价模型响应是否符合安全原则。</li>
<li>采用基于提示的LLM-as-Judge方式进行上下文评估，依据专家定义的心理干预原则构建推理链。</li>
<li>使用二进制点计分方式跨多个安全维度进行评估，增强评价的解性和可追溯性。</li>
<li>论文提供了一个覆盖自残、自杀意念和存在性焦虑的中文高质量数据集，来源于真实的在线对话。</li>
<li>实验结果显示，该方法与专家评估一致性高，能产生更可解释的评价依据。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08236">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.08236v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ShoulderShot-Generating-Over-the-Shoulder-Dialogue-Videos"><a href="#ShoulderShot-Generating-Over-the-Shoulder-Dialogue-Videos" class="headerlink" title="ShoulderShot: Generating Over-the-Shoulder Dialogue Videos"></a>ShoulderShot: Generating Over-the-Shoulder Dialogue Videos</h2><p><strong>Authors:Yuang Zhang, Junqi Cheng, Haoyu Zhao, Jiaxi Gu, Fangyuan Zou, Zenghui Lu, Peng Shu</strong></p>
<p>Over-the-shoulder dialogue videos are essential in films, short dramas, and advertisements, providing visual variety and enhancing viewers’ emotional connection. Despite their importance, such dialogue scenes remain largely underexplored in video generation research. The main challenges include maintaining character consistency across different shots, creating a sense of spatial continuity, and generating long, multi-turn dialogues within limited computational budgets. Here, we present ShoulderShot, a framework that combines dual-shot generation with looping video, enabling extended dialogues while preserving character consistency. Our results demonstrate capabilities that surpass existing methods in terms of shot-reverse-shot layout, spatial continuity, and flexibility in dialogue length, thereby opening up new possibilities for practical dialogue video generation. Videos and comparisons are available at <a target="_blank" rel="noopener" href="https://shouldershot.github.io/">https://shouldershot.github.io</a>. </p>
<blockquote>
<p>肩部对话视频在影片、短片及广告中扮演着至关重要的角色，为观众带来了视觉上的多样性和情感上的连接。尽管其重要性不言而喻，但在视频生成研究中，这类对话场景的研究仍远远不足。主要挑战包括在不同镜头中保持角色一致性、创造空间连贯性以及有限计算预算下生成长篇多轮对话。在这里，我们推出ShoulderShot框架，它将双镜头生成与循环视频相结合，能够在保持角色一致性的同时，生成更长的对话。我们的结果表明，在镜头反转镜头布局、空间连贯性和对话长度灵活性方面，我们的能力超过了现有方法，从而为实际对话视频生成打开了新的可能性。相关视频和对比视频可在<a target="_blank" rel="noopener" href="https://shouldershot.github.io查看./">https://shouldershot.github.io查看。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07597v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>对话场景在影片、短片及广告中极为重要，能增加视觉多样性并加深观众的情感连接。尽管其重要性显著，但在视频生成研究中，对话场景的研究仍被大大忽视。主要挑战包括在不同镜头中保持角色一致性、创造空间连贯性以及有限计算预算下生成长篇多轮对话。为此，我们推出ShoulderShot框架，结合双镜头生成与循环视频技术，实现扩展对话的同时保持角色一致性。我们的研究成果在镜头反转布局、空间连贯性及对话长度灵活性方面超越现有方法，为实用对话视频生成开辟新的可能性。更多视频及对比可访问：<a target="_blank" rel="noopener" href="https://shouldershot.github.io./">https://shouldershot.github.io。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>对话场景在影视、短片及广告中占据重要地位，能增强观众的情感连接。</li>
<li>对话场景在视频生成研究中被忽视，存在诸多挑战，如角色一致性、空间连贯性和对话长度。</li>
<li>ShoulderShot框架结合双镜头生成与循环视频技术，实现扩展对话的同时保持角色一致性。</li>
<li>ShoulderShot在镜头反转布局、空间连贯性和对话长度灵活性方面超越现有方法。</li>
<li>该框架有助于为实用对话视频生成开辟新的可能性。</li>
<li>更多详细信息和视频对比可访问特定网站。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07597">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07597v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07597v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07597v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07597v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07597v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07597v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Think-Before-You-Talk-Enhancing-Meaningful-Dialogue-Generation-in-Full-Duplex-Speech-Language-Models-with-Planning-Inspired-Text-Guidance"><a href="#Think-Before-You-Talk-Enhancing-Meaningful-Dialogue-Generation-in-Full-Duplex-Speech-Language-Models-with-Planning-Inspired-Text-Guidance" class="headerlink" title="Think Before You Talk: Enhancing Meaningful Dialogue Generation in   Full-Duplex Speech Language Models with Planning-Inspired Text Guidance"></a>Think Before You Talk: Enhancing Meaningful Dialogue Generation in   Full-Duplex Speech Language Models with Planning-Inspired Text Guidance</h2><p><strong>Authors:Wenqian Cui, Lei Zhu, Xiaohui Li, Zhihan Guo, Haoli Bai, Lu Hou, Irwin King</strong></p>
<p>Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation models designed to enable natural, real-time spoken interactions by modeling complex conversational dynamics such as interruptions, backchannels, and overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world double-channel conversational data to capture nuanced two-speaker dialogue patterns for human-like interactions. However, they face a critical challenge – their conversational abilities often degrade compared to pure-text conversation due to prolonged speech sequences and limited high-quality spoken dialogue data. While text-guided speech generation could mitigate these issues, it suffers from timing and length issues when integrating textual guidance into double-channel audio streams, disrupting the precise time alignment essential for natural interactions. To address these challenges, we propose TurnGuide, a novel planning-inspired approach that mimics human conversational planning by dynamically segmenting assistant speech into dialogue turns and generating turn-level text guidance before speech output, which effectively resolves both insertion timing and length challenges. Extensive experiments demonstrate our approach significantly improves e2e FD-SLMs’ conversational abilities, enabling them to generate semantically meaningful and coherent speech while maintaining natural conversational flow. Demos are available at <a target="_blank" rel="noopener" href="https://dreamtheater123.github.io/TurnGuide-Demo/">https://dreamtheater123.github.io/TurnGuide-Demo/</a>. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/dreamtheater123/TurnGuide">https://github.com/dreamtheater123/TurnGuide</a>. </p>
<blockquote>
<p>全双工语音语言模型（FD-SLMs）是专门设计的基础模型，能够模拟复杂对话动态，如中断、反馈通道和重叠语音，从而实现自然、实时的口语交互。端到端（e2e）FD-SLMs则利用现实世界的双通道对话数据，捕捉微妙的两说话人对话模式，用于实现类似人类的交互。然而，它们面临一个关键挑战：由于语音序列的延长和高质量口语对话数据的有限，它们的对话能力往往较纯文本对话有所下降。虽然文本指导的语音生成可以缓解这些问题，但在将文本指导集成到双通道音频流中时，它面临着时间和长度的问题，破坏了自然交互所必需的时间精确对齐。为了解决这些挑战，我们提出了TurnGuide这一新型规划启发方法。它通过动态分割助理语音为对话回合并生成回合级别的文本指导来模仿人类对话规划，在语音输出之前生成指导，有效地解决了插入时间和长度挑战。大量实验表明，我们的方法显著提高了端到端FD-SLMs的对话能力，使它们能够生成语义上连贯的语音并保持自然的对话流程。演示网站为：[<a target="_blank" rel="noopener" href="https://dreamtheater123.github.io/TurnGuide-Demo/%E3%80%82%E4%BB%A3%E7%A0%81%E5%B0%86%E5%8F%91%E5%B8%83%E5%9C%A8]">https://dreamtheater123.github.io/TurnGuide-Demo/。代码将发布在]</a>(<a target="_blank" rel="noopener" href="https://dreamtheater123.github.io/TurnGuide-Demo/%E3%80%82%E4%BB%A3%E7%A0%81%E5%B0%86%E5%8F%91%E5%B8%AE%E5%9C%B0%E9%AB%98%E6%B8%A9%E5%AE%B6%E7%AC%AC%E5%BD%A%E9%87%8D%E5%8F%A0%E3%80%82%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F%EF%BC%9A">https://dreamtheater123.github.io/TurnGuide-Demo/%E3%80%82%E4%BB%A3%E7%A0%81%E5%B0%86%E5%8F%91%E5%B8%AE%E5%9C%B0%E9%AB%98%E6%B8%A9%E5%AE%B6%E7%AC%AC%E5%BD%A重叠。联系方式：</a><a target="_blank" rel="noopener" href="https://github.com/dreamtheater123/TurnGuide">https://github.com/dreamtheater123/TurnGuide</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07375v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>本文介绍了针对全双工语音语言模型（FD-SLMs）的挑战，提出了一种名为TurnGuide的新型规划驱动方法。该方法通过动态分割助理语音为对话轮次并生成轮次级别的文本指导来模拟人类对话规划，解决了在双频道音频流中插入文本指导时出现的时序和长度问题。实验证明，该方法显著提高了端到端FD-SLMs的会话能力，能够生成语义上有意义和连贯的语音，同时保持自然对话流程。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>全双工语音语言模型（FD-SLMs）是为了实现自然、实时的口语交互而设计的专用基础模型。</li>
<li>端到端（e2e）FD-SLMs利用现实世界的双频道对话数据来捕捉微妙的双人对话模式，以实现人类般的交互。</li>
<li>FD-SLMs面临的关键挑战是，由于长时间的语音序列和高质量口语对话数据的有限性，其会话能力往往会下降。</li>
<li>虽然文本指导的语音生成可以缓解这些问题，但在将文本指导集成到双频道音频流时存在时间和长度问题，这破坏了自然交互所需的时间精确对齐。</li>
<li>TurnGuide是一种新的规划驱动方法，通过动态分割助理语音为对话轮次并生成轮次级别的文本指导来解决上述问题。</li>
<li>TurnGuide能有效解决插入时机和长度问题，显著提高了端到端FD-SLMs的会话能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07375">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.07375v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Score-Before-You-Speak-Improving-Persona-Consistency-in-Dialogue-Generation-using-Response-Quality-Scores"><a href="#Score-Before-You-Speak-Improving-Persona-Consistency-in-Dialogue-Generation-using-Response-Quality-Scores" class="headerlink" title="Score Before You Speak: Improving Persona Consistency in Dialogue   Generation using Response Quality Scores"></a>Score Before You Speak: Improving Persona Consistency in Dialogue   Generation using Response Quality Scores</h2><p><strong>Authors:Arpita Saggar, Jonathan C. Darling, Vania Dimitrova, Duygu Sarikaya, David C. Hogg</strong></p>
<p>Persona-based dialogue generation is an important milestone towards building conversational artificial intelligence. Despite the ever-improving capabilities of large language models (LLMs), effectively integrating persona fidelity in conversations remains challenging due to the limited diversity in existing dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which outperforms previous methods and yields improvements for both million and billion-parameter models. Unlike previous methods, SBS unifies the learning of responses and their relative quality into a single step. The key innovation is to train a dialogue model to correlate augmented responses with a quality score during training and then leverage this knowledge at inference. We use noun-based substitution for augmentation and semantic similarity-based scores as a proxy for response quality. Through extensive experiments with benchmark datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training allows existing models to better capture a spectrum of persona-consistent dialogues. Our ablation studies also demonstrate that including scores in the input prompt during training is superior to conventional training setups. Code and further details are available at <a target="_blank" rel="noopener" href="https://arpita2512.github.io/score_before_you_speak">https://arpita2512.github.io/score_before_you_speak</a> </p>
<blockquote>
<p>基于角色的对话生成是构建对话式人工智能的一个重要里程碑。尽管大型语言模型（LLM）的能力不断提高，但由于现有对话数据的多样性有限，有效整合角色真实性在对话中仍然具有挑战性。我们提出了一种新型框架SBS（先评分再说话），该框架超越了以前的方法，并改善了百万和亿参数模型的性能。与以前的方法不同，SBS将响应的学习和它们的相对质量合并到单一步骤中。关键的创新点是在训练期间训练对话模型，使增强的响应与质量分数相关联，然后在推理时使用此知识。我们使用名词替换增强数据，并使用语义相似性分数作为响应质量的代理。通过基准数据集（PERSONA-CHAT和ConvAI2）的大量实验，我们证明评分条件训练允许现有模型更好地捕捉一系列角色一致的对话。我们的消融研究也表明，在训练过程中将分数包含在输入提示中优于传统训练设置。更多详情和代码可访问：<a target="_blank" rel="noopener" href="https://arpita2512.github.io/score_before_you_speak">https://arpita2512.github.io/score_before_you_speak</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.06886v1">PDF</a> Camera-Ready version for ECAI 2025. 8 pages</p>
<p><strong>Summary</strong></p>
<p>基于人格的对话生成是构建对话式人工智能的重要里程碑。尽管大型语言模型（LLMs）的能力不断提高，但由于现有对话数据的多样性有限，有效整合人格一致性对话仍然具有挑战性。我们提出了一种新型框架SBS（Score-Before-Speaking），该框架优于以前的方法，并改善了百万和十亿参数模型的性能。不同于以往的方法，SBS将学习回应及其相对质量合并到一步中。关键创新点是在训练期间训练对话模型，以在增强响应与质量分数之间建立关联，然后在推理时利用这些知识。我们使用名词替代增强现实和基于语义相似性的分数作为响应质量的代理。通过基准数据集（PERSONA-CHAT和ConvAI2）的广泛实验，我们证明分数条件训练允许现有模型更好地捕捉一系列人格一致的对话。我们的消融研究还表明，在训练过程中包含输入提示中的分数优于传统训练设置。更多细节和代码可在<a target="_blank" rel="noopener" href="https://arpita2512.github.io/score_before_you_speak%E6%89%BE%E5%88%B0%E3%80%82">https://arpita2512.github.io/score_before_you_speak找到。</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>人格对话生成是构建对话式人工智能的重要部分，但整合人格一致性对话具有挑战性。</li>
<li>提出了SBS框架，通过训练模型在回应与质量分数之间建立关联，提高对话质量。</li>
<li>使用名词替代增强现实和基于语义相似性的分数来评估回应质量。</li>
<li>通过实验证明SBS框架能有效改善模型在人格一致对话上的表现。</li>
<li>消融研究显示，在训练过程中包含输入提示中的分数效果更佳。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.06886">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.06886v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Uni-Mol3-A-Multi-Molecular-Foundation-Model-for-Advancing-Organic-Reaction-Modeling"><a href="#Uni-Mol3-A-Multi-Molecular-Foundation-Model-for-Advancing-Organic-Reaction-Modeling" class="headerlink" title="Uni-Mol3: A Multi-Molecular Foundation Model for Advancing Organic   Reaction Modeling"></a>Uni-Mol3: A Multi-Molecular Foundation Model for Advancing Organic   Reaction Modeling</h2><p><strong>Authors:Lirong Wu, Junjie Wang, Zhifeng Gao, Xiaohong Ji, Rong Zhu, Xinyu Li, Linfeng Zhang, Guolin Ke, Weinan E</strong></p>
<p>Organic reaction, the foundation of modern chemical industry, is crucial for new material development and drug discovery. However, deciphering reaction mechanisms and modeling multi-molecular relationships remain formidable challenges due to the complexity of molecular dynamics. While several state-of-the-art models like Uni-Mol2 have revolutionized single-molecular representation learning, their extension to multi-molecular systems, where chemical reactions inherently occur, has been underexplored. This paper introduces Uni-Mol3, a novel deep learning framework that employs a hierarchical pipeline for multi-molecular reaction modeling. At its core, Uni-Mol3 adopts a multi-scale molecular tokenizer (Mol-Tokenizer) that encodes 3D structures of molecules and other features into discrete tokens, creating a 3D-aware molecular language. The framework innovatively combines two pre-training stages: molecular pre-training to learn the molecular grammars and reaction pre-training to capture fundamental reaction principles, forming a progressive learning paradigm from single- to multi-molecular systems. With prompt-aware downstream fine-tuning, Uni-Mol3 demonstrates exceptional performance in diverse organic reaction tasks and supports multi-task prediction with strong generalizability. Experimental results across 10 datasets spanning 4 downstream tasks show that Uni-Mol3 outperforms existing methods, validating its effectiveness in modeling complex organic reactions. This work not only ushers in an alternative paradigm for multi-molecular computational modeling but also charts a course for intelligent organic reaction by bridging molecular representation with reaction mechanism understanding. </p>
<blockquote>
<p>有机反应是现代化学工业的基础，对于新材料开发和药物发现至关重要。然而，由于分子动力学的复杂性，解析反应机制和模拟多分子关系仍然是巨大的挑战。虽然最先进的模型如Uni-Mol2已经实现了单分子表示学习革命，但其在多分子系统（化学反应固有的发生场所）的应用却鲜有研究。本文介绍了Uni-Mol3，这是一个采用多层次管道进行多分子反应建模的新型深度学习框架。其核心是采用多尺度分子令牌化器（Mol-Tokenizer），该令牌化器将分子的三维结构和其他特征编码为离散令牌，创建了一种三维感知分子语言。该框架创新地结合了两种预训练阶段：分子预训练学习分子语法和反应预训练捕获基本反应原理，形成了从单分子系统到多分子系统的渐进学习范式。通过提示感知下游微调，Uni-Mol3在多种有机反应任务中表现出卓越性能，支持多任务预测并具有强大的泛化能力。跨越10个数据集和4个下游任务的实验结果证明，Uni-Mol3优于现有方法，验证了其在模拟复杂有机反应中的有效性。这项工作不仅为计算多分子建模提供了替代范式，而且通过连接分子表示和反应机制理解，为智能有机反应指明了方向。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00920v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种新型深度学习框架Uni-Mol3，用于多分子反应建模。该框架采用多层次管道，通过多尺度分子标记器（Mol-Tokenizer）对分子进行编码，并创新地结合分子预训练和反应预训练两个阶段，形成从单分子系统到多分子系统的渐进学习范式。Uni-Mol3在多种有机反应任务中表现出卓越性能，并支持多任务预测，具有强大的泛化能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Uni-Mol3是首个针对多分子系统反应建模的深度学习框架。</li>
<li>采用多层次管道设计，实现复杂反应机制的精准建模。</li>
<li>引入多尺度分子标记器（Mol-Tokenizer），编码分子3D结构和特征。</li>
<li>结合分子预训练和反应预训练，形成渐进学习范式。</li>
<li>通过提示感知下游微调，实现强泛化能力和多任务预测。</li>
<li>在10个数据集上的实验结果表明，Uni-Mol3在建模复杂有机反应方面优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00920">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.00920v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.00920v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.00920v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2508.00920v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Planning-with-Diffusion-Models-for-Target-Oriented-Dialogue-Systems"><a href="#Planning-with-Diffusion-Models-for-Target-Oriented-Dialogue-Systems" class="headerlink" title="Planning with Diffusion Models for Target-Oriented Dialogue Systems"></a>Planning with Diffusion Models for Target-Oriented Dialogue Systems</h2><p><strong>Authors:Hanwen Du, Bo Peng, Xia Ning</strong></p>
<p>Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM era, where strategic dialogue planning is crucial for directing conversations toward specific targets. However, existing dialogue planning methods generate dialogue plans in a step-by-step sequential manner, and may suffer from compounding errors and myopic actions. To address these limitations, we introduce a novel dialogue planning framework, DiffTOD, which leverages diffusion models to enable non-sequential dialogue planning. DiffTOD formulates dialogue planning as a trajectory generation problem with conditional guidance, and leverages a diffusion language model to estimate the likelihood of the dialogue trajectory. To optimize the dialogue action strategies, DiffTOD introduces three tailored guidance mechanisms for different target types, offering flexible guidance toward diverse TOD targets at test time. Extensive experiments across three diverse TOD settings show that DiffTOD can effectively perform non-myopic lookahead exploration and optimize action strategies over a long horizon through non-sequential dialogue planning, and demonstrates strong flexibility across complex and diverse dialogue scenarios. Our code and data are accessible through <a target="_blank" rel="noopener" href="https://github.com/ninglab/DiffTOD">https://github.com/ninglab/DiffTOD</a>. </p>
<blockquote>
<p>面向目标的对话（TOD）在LLM时代仍然是一个巨大的挑战，在这个时代，战略性的对话规划对于引导对话朝着特定目标进行至关重要。然而，现有的对话规划方法以逐步顺序的方式生成对话计划，并可能遭受累积误差和短视行为的影响。为了解决这些局限性，我们引入了一种新型的对话规划框架DiffTOD，它利用扩散模型实现了非序贯对话规划。DiffTOD将对话规划制定为具有条件指导的轨迹生成问题，并利用扩散语言模型来估计对话轨迹的可能性。为了优化对话行动策略，DiffTOD针对不同目标类型引入了三种定制的指导机制，在测试时为不同的TOD目标提供了灵活指导。在三种不同的TOD设置上的广泛实验表明，DiffTOD可以通过非序贯对话规划有效地执行非短视的前瞻性探索，并在长期范围内优化行动策略，同时在复杂的多样化对话场景中表现出强大的灵活性。我们的代码和数据可通过<a target="_blank" rel="noopener" href="https://github.com/ninglab/DiffTOD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ninglab/DiffTOD获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16858v2">PDF</a> Accepted to ACL 2025 Main Conference</p>
<p><strong>Summary</strong></p>
<p>面向目标的对话（TOD）仍是大型语言模型时代的一个挑战。现有的对话规划方法采用逐步顺序方式生成对话计划，并可能受到累积误差和近视行为的影响。为解决这些问题，我们引入了新型的对话规划框架DiffTOD，利用扩散模型实现非序列对话规划。DiffTOD将对话规划制定为带有条件指导的轨迹生成问题，并利用扩散语言模型估计对话轨迹的可能性。为优化对话行动策略，DiffTOD针对不同目标类型引入了三种定制指导机制，在测试时提供灵活指导以达成不同的TOD目标。实验表明，DiffTOD能有效进行非近视前瞻探索，并通过非序列对话规划在长期内优化行动策略，在复杂多变的对话场景中表现出强大的灵活性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>面向目标的对话（TOD）仍然是一个挑战，需要战略性的对话规划来引导对话达到特定目标。</li>
<li>现有的对话规划方法采用逐步顺序方式，存在累积误差和近视行为的问题。</li>
<li>DiffTOD是一个新型的对话规划框架，利用扩散模型实现非序列对话规划。</li>
<li>DiffTOD将对话规划制定为带有条件指导的轨迹生成问题。</li>
<li>DiffTOD通过引入三种定制指导机制来优化对话行动策略，以适应不同的目标类型。</li>
<li>DiffTOD能在非近视前瞻探索和非序列对话规划的长期内优化行动策略。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16858">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2504.16858v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2504.16858v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Interactive/2504.16858v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-14/Interactive/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-14/Interactive/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Interactive/">
                                    <span class="chip bg-color">Interactive</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-14/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_Text-to-Motion/2508.08588v1/page_2_0.jpg" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion 方向最新论文已更新，请持续关注 Update in 2025-08-14  RealisMotion Decomposed Human Motion Control and Video Generation in   the World Space
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-14/TTS/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-08-14\./crop_TTS/2508.07426v1/page_2_0.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-08-14  Scalable Controllable Accented TTS
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25691.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
