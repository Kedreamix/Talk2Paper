<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-08-14  A new dataset and comparison for multi-camera frame synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-3c20060bebec3fdeba18fc70ec034e88.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-14-更新"><a href="#2025-08-14-更新" class="headerlink" title="2025-08-14 更新"></a>2025-08-14 更新</h1><h2 id="A-new-dataset-and-comparison-for-multi-camera-frame-synthesis"><a href="#A-new-dataset-and-comparison-for-multi-camera-frame-synthesis" class="headerlink" title="A new dataset and comparison for multi-camera frame synthesis"></a>A new dataset and comparison for multi-camera frame synthesis</h2><p><strong>Authors:Conall Daly, Anil Kokaram</strong></p>
<p>Many methods exist for frame synthesis in image sequences but can be broadly categorised into frame interpolation and view synthesis techniques. Fundamentally, both frame interpolation and view synthesis tackle the same task, interpolating a frame given surrounding frames in time or space. However, most frame interpolation datasets focus on temporal aspects with single cameras moving through time and space, while view synthesis datasets are typically biased toward stereoscopic depth estimation use cases. This makes direct comparison between view synthesis and frame interpolation methods challenging. In this paper, we develop a novel multi-camera dataset using a custom-built dense linear camera array to enable fair comparison between these approaches. We evaluate classical and deep learning frame interpolators against a view synthesis method (3D Gaussian Splatting) for the task of view in-betweening. Our results reveal that deep learning methods do not significantly outperform classical methods on real image data, with 3D Gaussian Splatting actually underperforming frame interpolators by as much as 3.5 dB PSNR. However, in synthetic scenes, the situation reverses – 3D Gaussian Splatting outperforms frame interpolation algorithms by almost 5 dB PSNR at a 95% confidence level. </p>
<blockquote>
<p>关于图像序列中的帧合成方法存在许多，但大体上可归纳为帧插值和视图合成技术。从本质上讲，帧插值和视图合成解决的是同一任务，即在时间或空间上根据周围帧进行帧插值。然而，大多数帧插值数据集侧重于单个相机随时间在空间中的运动方面，而视图合成数据集通常偏向于立体深度估计的使用情况。这使得视图合成和帧插值方法之间的直接比较具有挑战性。在本文中，我们使用自定义的密集线性相机阵列开发了一个新型多相机数据集，以实现这些方法之间的公平比较。我们评估了经典和深度学习的帧插值器与视图合成方法（3D高斯拼贴）在视图中间任务上的表现。我们的结果表明，在真实图像数据上，深度学习方法并没有显著优于经典方法，3D高斯拼贴的实际表现甚至比帧插值器差3.5 dB PSNR。然而，在合成场景中情况恰恰相反——在95%的置信水平下，3D高斯拼贴比帧插值算法高出近5 dB PSNR。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09068v1">PDF</a> SPIE2025 - Applications of Digital Image Processing XLVIII accepted   manuscript</p>
<p><strong>Summary</strong></p>
<p>本文介绍了图像序列中帧合成的两种方法：帧插值与视图合成。虽然两者都解决在给定周围帧的情况下内插帧的任务，但现有数据集大多侧重于时间方面的帧插值，而视图合成数据集则偏向于立体深度估计用例。为此，本文开发了一种使用自定义的密集线性相机阵列的多相机数据集，以便在这两种方法之间进行公平比较。评估结果显示，在真实图像数据上，深度学习方法并未显著优于经典方法，而3D高斯喷涂技术甚至比帧插值器性能差3.5 dB PSNR。但在合成场景中，情况逆转，3D高斯喷涂技术在95%的置信水平下比帧插补算法高出近5 dB PSNR。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>帧插值和视图合成是图像序列中帧合成的两种主要方法，但现有数据集存在偏向，导致直接比较具有挑战性。</li>
<li>本文开发了一种新型多相机数据集，使用自定义密集线性相机阵列，以公平比较这两种方法。</li>
<li>在真实图像数据上，深度学习方法与经典方法的性能差异不大。</li>
<li>3D高斯喷涂技术在真实图像数据上的性能较差，与帧插值器相比可能低达3.5 dB PSNR。</li>
<li>在合成场景中，3D高斯喷涂技术的性能显著优于帧插补算法，差异近5 dB PSNR。</li>
<li>这种差异在95%的置信水平上是显著的。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09068">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2610a3ded9dc8ee9fbc71ff861bfbd52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5712093207615a13a1bf1a630da9246a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1df09dab1de5f1df711f7d7305d81fa3.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GaussianUpdate-Continual-3D-Gaussian-Splatting-Update-for-Changing-Environments"><a href="#GaussianUpdate-Continual-3D-Gaussian-Splatting-Update-for-Changing-Environments" class="headerlink" title="GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing   Environments"></a>GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing   Environments</h2><p><strong>Authors:Lin Zeng, Boming Zhao, Jiarui Hu, Xujie Shen, Ziqiang Dang, Hujun Bao, Zhaopeng Cui</strong></p>
<p>Novel view synthesis with neural models has advanced rapidly in recent years, yet adapting these models to scene changes remains an open problem. Existing methods are either labor-intensive, requiring extensive model retraining, or fail to capture detailed types of changes over time. In this paper, we present GaussianUpdate, a novel approach that combines 3D Gaussian representation with continual learning to address these challenges. Our method effectively updates the Gaussian radiance fields with current data while preserving information from past scenes. Unlike existing methods, GaussianUpdate explicitly models different types of changes through a novel multi-stage update strategy. Additionally, we introduce a visibility-aware continual learning approach with generative replay, enabling self-aware updating without the need to store images. The experiments on the benchmark dataset demonstrate our method achieves superior and real-time rendering with the capability of visualizing changes over different times </p>
<blockquote>
<p>近年来，利用神经网络模型进行新型视图合成的研究进展迅速，然而，如何适应场景变化仍是亟待解决的问题。现有方法要么需要大量的人工进行模型重新训练，要么无法捕捉随时间变化的细节变化。在本文中，我们提出了GaussianUpdate，这是一种结合三维高斯表示和持续学习来解决这些挑战的新型方法。我们的方法可以有效地使用当前数据更新高斯辐射场，同时保留过去场景的信息。与现有方法不同，GaussianUpdate通过一种新型的多阶段更新策略来显式地模拟不同类型的场景变化。此外，我们引入了一种具有生成回放功能的可见性感知持续学习方法，实现了自我感知更新，无需存储图像。在基准数据集上的实验表明，我们的方法实现了具有实时渲染能力的卓越性能，能够可视化不同时间的变化。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08867v1">PDF</a> Accepted to ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>神经网络模型在视图合成方面的应用近年来发展迅速，但在场景变化方面的适应性仍然是一个待解决的问题。现有方法要么需要大量的人工参与和模型重新训练，要么无法捕捉随时间变化的细节变化。本文提出了GaussianUpdate方法，它结合了三维高斯表示和持续学习技术，以应对这些挑战。该方法可以有效地更新当前数据的高斯辐射场，同时保留过去场景的信息。不同于现有方法，GaussianUpdate通过一种新的多阶段更新策略来显式地模拟不同类型的变化。此外，我们还引入了一种具有生成回放功能的可见性感知持续学习方法，实现了自我感知更新，无需存储图像。在基准数据集上的实验表明，该方法可实现先进且实时的渲染，能够可视化不同时间的变化。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>神经网络模型在视图合成领域发展迅速，但场景变化的适应性仍是问题。</li>
<li>现有方法存在劳动密集或无法捕捉细节变化的问题。</li>
<li>GaussianUpdate方法结合了三维高斯表示和持续学习技术。</li>
<li>GaussianUpdate可以有效地更新当前数据的高斯辐射场并保留过去场景的信息。</li>
<li>多阶段更新策略显式地模拟不同类型的场景变化。</li>
<li>引入可见性感知持续学习方法，实现自我感知更新，无需存储图像。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08867">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-a109400a07d73fdcaab6fc78f03b8076.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d66d84174724c84b545847e4d890de62.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e8c958fa996695aa64e782cf110a2175.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Communication-Efficient-Robotic-Mixed-Reality-with-Gaussian-Splatting-Cross-Layer-Optimization"><a href="#Communication-Efficient-Robotic-Mixed-Reality-with-Gaussian-Splatting-Cross-Layer-Optimization" class="headerlink" title="Communication Efficient Robotic Mixed Reality with Gaussian Splatting   Cross-Layer Optimization"></a>Communication Efficient Robotic Mixed Reality with Gaussian Splatting   Cross-Layer Optimization</h2><p><strong>Authors:Chenxuan Liu, He Li, Zongze Li, Shuai Wang, Wei Xu, Kejiang Ye, Derrick Wing Kwan Ng, Chengzhong Xu</strong></p>
<p>Realizing low-cost communication in robotic mixed reality (RoboMR) systems presents a challenge, due to the necessity of uploading high-resolution images through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSMR), which enables the simulator to opportunistically render a photo-realistic view from the robot’s pose by calling &#96;&#96;memory’’ from a GS model, thus reducing the need for excessive image uploads. However, the GS model may involve discrepancies compared to the actual environments. To this end, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation (i.e., adjusting to content profiles) across different frames by minimizing a newly derived GSMR loss function. The GSCLO problem is addressed by an accelerated penalty optimization (APO) algorithm that reduces computational complexity by over $10$x compared to traditional branch-and-bound and search algorithms. Moreover, variants of GSCLO are presented to achieve robust, low-power, and multi-robot GSMR. Extensive experiments demonstrate that the proposed GSMR paradigm and GSCLO method achieve significant improvements over existing benchmarks on both wheeled and legged robots in terms of diverse metrics in various scenarios. For the first time, it is found that RoboMR can be achieved with ultra-low communication costs, and mixture of data is useful for enhancing GS performance in dynamic scenarios. </p>
<blockquote>
<p>在机器人混合现实（RoboMR）系统中实现低成本通信是一个挑战，因为需要通过无线信道上传高分辨率图像。本文提出了高斯斑点（GS）RoboMR（GSMR），它允许模拟器通过从GS模型中调用“内存”来随机呈现机器人的逼真视图，从而减少了过度图像上传的需求。然而，与实际情况相比，GS模型可能存在差异。为此，进一步提出了GS跨层优化（GSCLO）框架，该框架通过最小化新推导的GSMR损失函数来联合优化内容切换（即决定是否需要上传图像）和功率分配（即适应内容配置文件）。不同帧之间的GSCLO问题通过加速惩罚优化（APO）算法来解决，与传统的分支界定和搜索算法相比，该算法的计算复杂度降低了超过10倍。此外，还提出了GSCLO的变体，以实现稳健、低功耗和多机器人的GSMR。大量实验表明，在轮式机器人和步行机器人上，所提出的GSMR范式和GSCLO方法在多种场景下的各种指标方面均显著优于现有基准测试。首次发现RoboMR可以使用超低的通信成本来实现，并且数据的混合对于增强动态场景中的GS性能很有用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08624v1">PDF</a> 14 pages, 18 figures, to appear in IEEE Transactions on Cognitive   Communications and Networking</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于高斯点云技术（GS）的机器人混合现实（RoboMR）系统，实现了低成本通信。该系统通过调用GS模型的“内存”来模拟渲染机器人姿态的逼真视图，减少了对大量图像上传的需求。为进一步减小与真实环境的差异，文章提出了GS跨层优化（GSLO）框架，联合优化内容切换和功率分配。通过加速惩罚优化算法解决GSLO问题，计算复杂度较传统方法降低了超过十倍。实验证明，该框架和方法在轮式和步行机器人上均显著优于现有基准测试，实现了超低通信成本的RoboMR，且混合数据在动态场景中有助于提升GS性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>该论文提出了基于高斯点云技术（GS）的机器人混合现实（RoboMR）系统，实现了低成本通信。</li>
<li>系统通过调用GS模型的“内存”模拟渲染机器人姿态的视图，减少了图像上传的需求。</li>
<li>论文提出了GS跨层优化（GSLO）框架以减小与真实环境的差异，联合优化内容切换和功率分配。</li>
<li>采用加速惩罚优化算法解决GSLO问题，计算复杂度大幅降低。</li>
<li>实验证明，该框架和方法在多种机器人和场景下均显著优于现有技术。</li>
<li>RobomR可以实现超低通信成本。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08624">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-2175a49b81a29b3bbfbd6d3ef6b8a767.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-252e52d8730fbbadf96527fa63820018.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf05c64c09bde372a1a001d47c6d0f13.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d2ed4eb9b5e0eae7b48eda4ef179a118.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3c20060bebec3fdeba18fc70ec034e88.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GaussianFlowOcc-Sparse-and-Weakly-Supervised-Occupancy-Estimation-using-Gaussian-Splatting-and-Temporal-Flow"><a href="#GaussianFlowOcc-Sparse-and-Weakly-Supervised-Occupancy-Estimation-using-Gaussian-Splatting-and-Temporal-Flow" class="headerlink" title="GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using   Gaussian Splatting and Temporal Flow"></a>GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using   Gaussian Splatting and Temporal Flow</h2><p><strong>Authors:Simon Boeder, Fabian Gigengack, Benjamin Risse</strong></p>
<p>Occupancy estimation has become a prominent task in 3D computer vision, particularly within the autonomous driving community. In this paper, we present a novel approach to occupancy estimation, termed GaussianFlowOcc, which is inspired by Gaussian Splatting and replaces traditional dense voxel grids with a sparse 3D Gaussian representation. Our efficient model architecture based on a Gaussian Transformer significantly reduces computational and memory requirements by eliminating the need for expensive 3D convolutions used with inefficient voxel-based representations that predominantly represent empty 3D spaces. GaussianFlowOcc effectively captures scene dynamics by estimating temporal flow for each Gaussian during the overall network training process, offering a straightforward solution to a complex problem that is often neglected by existing methods. Moreover, GaussianFlowOcc is designed for scalability, as it employs weak supervision and does not require costly dense 3D voxel annotations based on additional data (e.g., LiDAR). Through extensive experimentation, we demonstrate that GaussianFlowOcc significantly outperforms all previous methods for weakly supervised occupancy estimation on the nuScenes dataset while featuring an inference speed that is 50 times faster than current SOTA. </p>
<blockquote>
<p>场景中的物体占有率估计在三维计算机视觉中已经成为一项重要任务，特别是在自动驾驶领域。在本文中，我们提出了一种新颖的占有率估计方法，称为GaussianFlowOcc。该方法受到高斯涂抹（Gaussian Splatting）的启发，用稀疏的三维高斯表示替换了传统的密集体素网格。我们基于高斯变换器的有效模型架构，通过消除主要代表空三维空间的低效体素表示所需的高昂的三维卷积，大大减少了计算和内存需求。GaussianFlowOcc通过在整个网络训练过程中估计每个高斯的时间流来有效地捕捉场景动态，为解决现有方法经常忽略的复杂问题提供了直接解决方案。此外，GaussianFlowOcc具有可扩展性设计，因为它采用弱监督，无需基于其他数据（如激光雷达）的昂贵密集三维体素注释。通过广泛的实验，我们证明GaussianFlowOcc在nuScenes数据集上的弱监督占有率估计方面大大优于所有之前的方法，同时其推理速度比当前最佳方法快50倍。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17288v3">PDF</a> Accepted to ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新颖的占用率估计方法，称为GaussianFlowOcc。该方法受到高斯涂抹技术的启发，采用稀疏的3D高斯表示替代传统的密集体素网格。基于高斯变换器的有效模型架构大大减少了计算和内存需求，因为它消除了需要使用昂贵的3D卷积和基于体素的表示方法，后者主要代表空的3D空间。GaussianFlowOcc通过在网络训练过程中估计每个高斯的时间流来有效地捕捉场景动态，为常被现有方法忽视的一个复杂问题提供了简单的解决方案。此外，GaussianFlowOcc设计用于可扩展性，它采用弱监督，无需基于额外数据（如激光雷达）的昂贵密集3D体素注释。通过广泛的实验，我们证明GaussianFlowOcc在nuScenes数据集上的弱监督占用率估计方面显著优于所有之前的方法，同时其推理速度比当前的最佳方法快50倍。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GaussianFlowOcc是一种用于占用率估计的新型方法，基于稀疏的3D高斯表示。</li>
<li>该方法受到高斯涂抹技术的启发，并采用了基于高斯变换器的有效模型架构。</li>
<li>GaussianFlowOcc通过估计场景动态的时间流来解决复杂问题。</li>
<li>与传统方法相比，GaussianFlowOcc大大减少了计算和内存需求。</li>
<li>GaussianFlowOcc采用弱监督，无需昂贵的密集3D体素注释。</li>
<li>在nuScenes数据集上，GaussianFlowOcc在弱监督占用率估计方面表现出显著的优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17288">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-f2016a96afc1b27c424adb5d9d2ced3c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14ff8e716d646c9f2824047b16879346.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b72b93153153bb2b30b5950aa7990409.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-18965c9e2cd33aa2244b9e5e08a81fb3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Deblur4DGS-4D-Gaussian-Splatting-from-Blurry-Monocular-Video"><a href="#Deblur4DGS-4D-Gaussian-Splatting-from-Blurry-Monocular-Video" class="headerlink" title="Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video"></a>Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video</h2><p><strong>Authors:Renlong Wu, Zhilu Zhang, Mingyang Chen, Zifei Yan, Wangmeng Zuo</strong></p>
<p>Recent 4D reconstruction methods have yielded impressive results but rely on sharp videos as supervision. However, motion blur often occurs in videos due to camera shake and object movement, while existing methods render blurry results when using such videos for reconstructing 4D models. Although a few approaches attempted to address the problem, they struggled to produce high-quality results, due to the inaccuracy in estimating continuous dynamic representations within the exposure time. Encouraged by recent works in 3D motion trajectory modeling using 3D Gaussian Splatting (3DGS), we take 3DGS as the scene representation manner, and propose Deblur4DGS to reconstruct a high-quality 4D model from blurry monocular video. Specifically, we transform continuous dynamic representations estimation within an exposure time into the exposure time estimation. Moreover, we introduce the exposure regularization term, multi-frame, and multi-resolution consistency regularization term to avoid trivial solutions. Furthermore, to better represent objects with large motion, we suggest blur-aware variable canonical Gaussians. Beyond novel-view synthesis, Deblur4DGS can be applied to improve blurry video from multiple perspectives, including deblurring, frame interpolation, and video stabilization. Extensive experiments in both synthetic and real-world data on the above four tasks show that Deblur4DGS outperforms state-of-the-art 4D reconstruction methods. The codes are available at <a target="_blank" rel="noopener" href="https://github.com/ZcsrenlongZ/Deblur4DGS">https://github.com/ZcsrenlongZ/Deblur4DGS</a>. </p>
<blockquote>
<p>虽然最近的4D重建方法取得了令人印象深刻的结果，但它们依赖于清晰视频作为监督。然而，由于相机抖动和物体移动，视频中的运动模糊经常发生，而现有方法在利用此类视频进行4D模型重建时会产生模糊的结果。尽管有一些方法试图解决这个问题，但由于在曝光时间内估计连续动态表示的不准确性，它们很难产生高质量的结果。受最近使用3D高斯描画（3DGS）进行3D运动轨迹建模的工作的启发，我们以3DGS作为场景表示方式，并提出Deblur4DGS从模糊的单目视频中重建高质量的4D模型。具体来说，我们将曝光时间内连续动态表示的估计转化为曝光时间估计。此外，我们引入了曝光正则化项、多帧和多分辨率一致性正则化项，以避免平凡解。为了进一步更好地表示大运动物体，我们建议使用模糊感知的可变规范高斯。除了新型视图合成，Deblur4DGS可以从多个角度提高模糊视频，包括去模糊、帧内插和视频稳定。在合成和真实数据对上述四个任务的广泛实验表明，Deblur4DGS优于最新的4D重建方法。相关代码可访问 <a target="_blank" rel="noopener" href="https://github.com/ZcsrenlongZ/Deblur4DGS">https://github.com/ZcsrenlongZ/Deblur4DGS</a> 了解更多。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06424v2">PDF</a> 16 pages</p>
<p><strong>摘要</strong><br>视频中的运动模糊问题在4D重建中是一大挑战。传统方法依赖清晰视频进行重建，但面对运动模糊时效果不佳。本研究利用3D高斯点云技术（3DGS）进行场景表示，提出Deblur4DGS方法，可从模糊的单视角视频重建高质量4D模型。通过估算曝光时间内的连续动态表示，结合曝光正则化项、多帧多分辨率一致性正则化项等，实现更佳结果。对于运动幅度较大的对象，我们引入了模糊感知的可变规范高斯。除了新颖视图合成外，Deblur4DGS还可应用于多种模糊视频改进任务，如去模糊、帧插值和视频稳定等。实验证明，Deblur4DGS在合成和真实数据上的效果优于现有主流方法。相关代码可通过<a target="_blank" rel="noopener" href="https://github.com/ZcsrenlongZ/Deblur4DGS%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ZcsrenlongZ/Deblur4DGS获取。</a></p>
<p><strong>关键见解</strong></p>
<ol>
<li>4D重建方法在面对视频中的运动模糊问题时存在挑战。</li>
<li>本研究采用3D高斯点云技术（3DGS）作为场景表示方式。</li>
<li>提出Deblur4DGS方法，能够从模糊的单视角视频重建高质量的4D模型。</li>
<li>通过估算曝光时间内的连续动态表示来解决模糊问题。</li>
<li>引入曝光正则化项和多帧多分辨率一致性正则化项，进一步优化结果。</li>
<li>对于运动幅度大的对象，采用模糊感知的可变规范高斯进行更好表示。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06424">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ba09f1e07b20a9d7f2920b6bfa16eaff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15d75ace71ae92c14d2aac1171d46197.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24c58ea09de1fd635fd09e4a7767217c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0cac8786d8134f5d3e814d5a4540fd03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54c7b3b5d65c8cffbb2d4d08a3bb3780.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ddec565978d0ebd5617fdc5912998f27.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Quadratic-Gaussian-Splatting-High-Quality-Surface-Reconstruction-with-Second-order-Geometric-Primitives"><a href="#Quadratic-Gaussian-Splatting-High-Quality-Surface-Reconstruction-with-Second-order-Geometric-Primitives" class="headerlink" title="Quadratic Gaussian Splatting: High Quality Surface Reconstruction with   Second-order Geometric Primitives"></a>Quadratic Gaussian Splatting: High Quality Surface Reconstruction with   Second-order Geometric Primitives</h2><p><strong>Authors:Ziyu Zhang, Binbin Huang, Hanqing Jiang, Liyang Zhou, Xiaojun Xiang, Shunhan Shen</strong></p>
<p>We propose Quadratic Gaussian Splatting (QGS), a novel representation that replaces static primitives with deformable quadric surfaces (e.g., ellipse, paraboloids) to capture intricate geometry. Unlike prior works that rely on Euclidean distance for primitive density modeling–a metric misaligned with surface geometry under deformation–QGS introduces geodesic distance-based density distributions. This innovation ensures that density weights adapt intrinsically to the primitive curvature, preserving consistency during shape changes (e.g., from planar disks to curved paraboloids). By solving geodesic distances in closed form on quadric surfaces, QGS enables surface-aware splatting, where a single primitive can represent complex curvature that previously required dozens of planar surfels, potentially reducing memory usage while maintaining efficient rendering via fast ray-quadric intersection. Experiments on DTU, Tanks and Temples, and MipNeRF360 datasets demonstrate state-of-the-art surface reconstruction, with QGS reducing geometric error (chamfer distance) by 33% over 2DGS and 27% over GOF on the DTU dataset. Crucially, QGS retains competitive appearance quality, bridging the gap between geometric precision and visual fidelity for applications like robotics and immersive reality. </p>
<blockquote>
<p>我们提出了二次高斯摊铺（Quadratic Gaussian Splatting，简称QGS）这一新型表示方法，它用可变形的二次曲面（如椭圆、抛物线等）替代静态基本体素，以捕捉复杂的几何形状。不同于以往依赖欧几里得距离进行基本体素密度建模的工作——这一度量方式与变形下的表面几何结构不符——QGS引入了基于测地距离（geodesic distance）的密度分布。这一创新确保了密度权重能够内在地适应原始曲率，在形状变化（例如从平面圆盘到弯曲的抛物线）过程中保持一致性。通过在二次曲面上解决闭合形式的测地距离问题，QGS实现了表面感知摊铺，其中单个基本体素就能代表以前需要数十个平面surfels的复杂曲率，这在可能降低内存使用的同时，通过快速的射线与二次曲面求交算法，维持了高效的渲染效率。在DTU、Tanks and Temples以及MipNeRF360数据集上的实验证明了其最先进的三维重建能力，相较于二维GS，QGS在DTU数据集上将几何误差减少了33%，相较于GOF减少了27%。最重要的是，QGS保持了出色的外观质量，在机器人和沉浸式现实等应用中缩小了几何精度和视觉保真度之间的差距。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16392v3">PDF</a> 16pages,18figures</p>
<p><strong>Summary</strong></p>
<p>二次高斯融合（Quadratic Gaussian Splatting，简称QGS）是一种新型几何表示方法，它采用可变形二次曲面（如椭圆、抛物线等）替代静态基本体素，以捕捉复杂几何结构。与依赖欧几里得距离进行基本密度建模的先前方法不同，QGS引入基于测地距离（geodesic distance）的密度分布。这一创新确保密度权重能够自适应基本曲面的曲率变化，从而在形状变化时保持一致性。通过解决二次曲面上的测地距离问题，QGS实现了表面感知融合（surface-aware splatting），单个基本体能代表复杂的曲面，从而可能减少内存使用并维持高效的渲染效率。实验结果表明，QGS在表面重建方面具有最佳性能，与二维高斯融合相比减少了33%的几何误差（使用测地距离作为评价指标），并且在机器人和沉浸式现实等应用中实现了几何精度与视觉逼真度之间的平衡。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QGS使用可变形二次曲面替代静态基本体素，捕捉复杂几何结构。</li>
<li>QGS引入基于测地距离的密度分布，确保密度权重适应基本曲面的曲率变化。</li>
<li>QGS实现表面感知融合，单个基本体能代表复杂曲面，降低内存使用并提高渲染效率。</li>
<li>QGS在表面重建方面表现最佳，与现有方法相比显著减少几何误差。</li>
<li>QGS在机器人和沉浸式现实等应用中实现了几何精度与视觉逼真度之间的平衡。</li>
<li>QGS方法解决了传统方法中欧式距离与曲面几何变形不匹配的问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16392">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-89466ca2e1b612c1dda282c4e63d752d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ede5b9c089abb208a02ee275b01e52e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55e6fc5608092b0b34200ce0e8040ff5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11054e273d5c29a6bad15193edac95b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-137b819c6fa0fba8a41ab5e17cbd3073.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfc003dc297cee101b45241bb357f823.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-14/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-14/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-14/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-30a868c4bb872291800eb6fa60ffb12f.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-08-14  MonoPartNeRFHuman Reconstruction from Monocular Video via Part-Based   Neural Radiance Fields
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-14/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-170c7d268e3cd03cc73d12c595b86a87.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-08-14  Preview WB-DH Towards Whole Body Digital Human Bench for the Generation   of Whole-body Talking Avatar Videos
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30166.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
