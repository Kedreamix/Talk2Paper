<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-07  Decoupling Augmentation Bias in Prompt Learning for Vision-Language   Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ea16d27e71f830322bac153f0b146c81')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    37 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-07-æ›´æ–°"><a href="#2025-11-07-æ›´æ–°" class="headerlink" title="2025-11-07 æ›´æ–°"></a>2025-11-07 æ›´æ–°</h1><h2 id="Decoupling-Augmentation-Bias-in-Prompt-Learning-for-Vision-Language-Models"><a href="#Decoupling-Augmentation-Bias-in-Prompt-Learning-for-Vision-Language-Models" class="headerlink" title="Decoupling Augmentation Bias in Prompt Learning for Vision-Language   Models"></a>Decoupling Augmentation Bias in Prompt Learning for Vision-Language   Models</h2><p><strong>Authors:Gahyeon Kim, Sohee Kim, Seokju Lee</strong></p>
<p>Recent advances in large-scale vision and language models have led to significant progress in zero-shot learning tasks. Methods such as CoOp and CoCoOp have shown that replacing handcrafted prompts with learnable vectors, known as prompt learning, can result in improved performance. However, these models often struggle to generalize to entirely unseen categories. While traditional zero-shot learning techniques benefit from various data augmentation strategies, prompt learning has primarily focused on text-based modifications, leaving the potential of image-based augmentation largely unexplored. In this work, we explore how image-level augmentations, particularly those that introduce attribute-specific variations, can support and enhance prompt learning. Our analysis examines the interaction between these augmentations and soft prompt frameworks, revealing their potential to improve generalization. We also identify a limitation in existing methods, such as CoCoOp, which do not provide explicit guidance for learning prompts that focus on semantically meaningful visual features. To address this, we propose Adding Attributes to Prompt Learning, AAPL, a novel method that introduces adversarial token embeddings to decouple superficial visual variations introduced by augmentation from class-relevant semantic representations. This decoupling enables the learned prompts to concentrate on visually discriminative features that align with the target categories. We conduct comprehensive experiments on eleven benchmark datasets, and AAPL consistently outperforms existing methods across few-shot, zero-shot, cross-dataset, and domain generalization settings. Our source code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Gahyeonkim09/AAPL">https://github.com/Gahyeonkim09/AAPL</a> </p>
<blockquote>
<p>æœ€è¿‘å¤§è§„æ¨¡è§†è§‰å’Œè¯­è¨€æ¨¡å‹çš„è¿›å±•ä¸ºé›¶æ ·æœ¬å­¦ä¹ ä»»åŠ¡å¸¦æ¥äº†é‡å¤§çªç ´ã€‚CoOpå’ŒCoCoOpç­‰æ–¹æ³•è¡¨æ˜ï¼Œç”¨å¯å­¦ä¹ å‘é‡æ›¿ä»£æ‰‹å·¥æç¤ºï¼Œå³æ‰€è°“çš„æç¤ºå­¦ä¹ ï¼Œå¯ä»¥æé«˜æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸åœ¨æ¨å¹¿åˆ°æœªè§è¿‡çš„ç±»åˆ«æ—¶é‡åˆ°æŒ‘æˆ˜ã€‚è™½ç„¶ä¼ ç»Ÿé›¶æ ·æœ¬å­¦ä¹ æŠ€æœ¯å—ç›Šäºå„ç§æ•°æ®å¢å¼ºç­–ç•¥ï¼Œä½†æç¤ºå­¦ä¹ ä¸»è¦å…³æ³¨æ–‡æœ¬ä¿®æ”¹ï¼Œå¾ˆå°‘æ¢ç´¢å›¾åƒå¢å¼ºæ–¹æ³•çš„æ½œåŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å›¾åƒçº§å¢å¼ºï¼ˆç‰¹åˆ«æ˜¯å¼•å…¥ç‰¹å®šå±æ€§å˜åŒ–çš„å¢å¼ºï¼‰å¦‚ä½•æ”¯æŒå’Œå¢å¼ºæç¤ºå­¦ä¹ ã€‚æˆ‘ä»¬çš„åˆ†æç ”ç©¶äº†è¿™äº›å¢å¼ºä¸è½¯æç¤ºæ¡†æ¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œæ­ç¤ºäº†å®ƒä»¬æé«˜æ³›åŒ–çš„æ½œåŠ›ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†ç°æœ‰æ–¹æ³•ï¼ˆå¦‚CoCoOpï¼‰çš„ä¸€ä¸ªå±€é™æ€§ï¼Œå³å®ƒä»¬æ²¡æœ‰ä¸ºå­¦ä¹ ä¸“æ³¨äºè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„è§†è§‰ç‰¹å¾çš„æç¤ºæä¾›æ˜ç¡®æŒ‡å¯¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†â€œæ·»åŠ å±æ€§æç¤ºå­¦ä¹ â€ï¼ˆAAPLï¼‰è¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒå¼•å…¥å¯¹æŠ—æ€§ä»¤ç‰ŒåµŒå…¥æ¥è§£è€¦ç”±å¢å¼ºå¼•å…¥çš„è¡¨é¢è§†è§‰å˜åŒ–ä¸ç±»ç›¸å…³çš„è¯­ä¹‰è¡¨ç¤ºã€‚è¿™ç§è§£è€¦ä½¿å¾—å­¦ä¹ åˆ°çš„æç¤ºèƒ½å¤Ÿé›†ä¸­åœ¨ä¸ç›®æ ‡ç±»åˆ«å¯¹é½çš„è§†è§‰åŒºåˆ†ç‰¹å¾ä¸Šã€‚æˆ‘ä»¬åœ¨11ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼ŒAAPLåœ¨å°‘æ ·æœ¬ã€é›¶æ ·æœ¬ã€è·¨æ•°æ®é›†å’Œé¢†åŸŸæ³›åŒ–è®¾ç½®ä¸Šå‡è¡¨ç°å‡ºè¶…è¶Šç°æœ‰æ–¹æ³•çš„æ•ˆæœã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€å…¬å¼€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/Gahyeonkim09/AAPL">https://github.com/Gahyeonkim09/AAPL</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.03367v1">PDF</a> Accepted in Pattern Recognition</p>
<p><strong>Summary</strong><br>å¤§å‹è§†è§‰ä¸è¯­è¨€æ¨¡å‹çš„æœ€æ–°è¿›å±•æ¨åŠ¨äº†é›¶æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„æ˜¾è‘—è¿›æ­¥ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å›¾åƒçº§åˆ«çš„å¢å¼ºï¼Œç‰¹åˆ«æ˜¯å¼•å…¥å±æ€§ç‰¹å®šå˜åŒ–çš„å¢å¼ºå¦‚ä½•æ”¯æŒå’Œå¢å¼ºæç¤ºå­¦ä¹ ã€‚åˆ†æè¡¨æ˜ï¼Œè¿™äº›å¢å¼ºä¸è½¯æç¤ºæ¡†æ¶ä¹‹é—´çš„äº¤äº’å…·æœ‰æ”¹å–„æ³›åŒ–çš„æ½œåŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æŒ‡å‡ºäº†ç°æœ‰æ–¹æ³•ï¼ˆå¦‚CoCoOpï¼‰çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†åä¸ºAAPLçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥å¯¹æŠ—æ€§ä»¤ç‰ŒåµŒå…¥æ¥è§£è€¦ç”±å¢å¼ºå¼•å…¥çš„è¡¨é¢è§†è§‰å˜åŒ–ä¸ç±»ç›¸å…³çš„è¯­ä¹‰è¡¨ç¤ºã€‚åœ¨åä¸€ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAAPLåœ¨å°‘æ ·æœ¬ã€é›¶æ ·æœ¬ã€è·¨æ•°æ®é›†å’ŒåŸŸæ³›åŒ–è®¾ç½®ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è§†è§‰ä¸è¯­è¨€æ¨¡å‹çš„æœ€æ–°è¿›å±•æ¨åŠ¨äº†é›¶æ ·æœ¬å­¦ä¹ çš„å‘å±•ã€‚</li>
<li>æç¤ºå­¦ä¹ åœ¨é›¶æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸­å±•ç°äº†æ”¹å–„æ€§èƒ½çš„å¯èƒ½æ€§ã€‚</li>
<li>å›¾åƒçº§åˆ«çš„å¢å¼ºï¼Œç‰¹åˆ«æ˜¯å±æ€§ç‰¹å®šå˜åŒ–çš„å¢å¼ºï¼Œå¯¹äºæ”¯æŒå¹¶å¢å¼ºæç¤ºå­¦ä¹ å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>è½¯æç¤ºæ¡†æ¶ä¸å›¾åƒå¢å¼ºçš„äº¤äº’æœ‰åŠ©äºæ”¹å–„æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ï¼ˆå¦‚CoCoOpï¼‰åœ¨å­¦ä¹ æç¤ºæ—¶ç¼ºä¹é’ˆå¯¹è¯­ä¹‰ç›¸å…³è§†è§‰ç‰¹å¾çš„æ˜ç¡®æŒ‡å¯¼ã€‚</li>
<li>AAPLæ–¹æ³•é€šè¿‡å¼•å…¥å¯¹æŠ—æ€§ä»¤ç‰ŒåµŒå…¥æ¥è§£è€¦è¡¨é¢è§†è§‰å˜åŒ–å’Œç±»ç›¸å…³è¯­ä¹‰è¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.03367">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ec3ed47ef9f3fbc8632593233d6c2104" align="middle">
<img src="https://picx.zhimg.com/v2-0241b60fe6161a7b3657e17224abf965" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SLIP-Structural-aware-Language-Image-Pretraining-for-Vision-Language-Alignment"><a href="#SLIP-Structural-aware-Language-Image-Pretraining-for-Vision-Language-Alignment" class="headerlink" title="SLIP: Structural-aware Language-Image Pretraining for Vision-Language   Alignment"></a>SLIP: Structural-aware Language-Image Pretraining for Vision-Language   Alignment</h2><p><strong>Authors:Wenbo Lu</strong></p>
<p>Vision-Language Pretraining (VLP) has achieved remarkable success across various downstream tasks, but such gains are largely driven by scaling up on training data. Yet, literature methods treat image-text pairs as isolated training examples; this neglects the rich relational structure naturally present in many domains, such as e-commerce product co-purchase graphs and social recommendation networks. Inspired by neuroscientific evidence that human encodes knowledge as relationship cognitive maps, we introduce Structure-aware Language-Image Pretraining (SLIP). SLIP integrates a structural contrastive loss to align modalities while also modeling relationships between neighboring entities in a structured graph. To support this paradigm, we construct a large-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling structured cross-modality supervision at scale. Experiment results show that SLIP consistently outperforms CLIP on cross-modal retrieval and classification tasks in both zero-shot and few-shot settings, showing the value of relational supervision for cross-modal alignment. </p>
<blockquote>
<p>è§†è§‰-è¯­è¨€é¢„è®­ç»ƒï¼ˆVLPï¼‰åœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†è¿™äº›æˆæœä¸»è¦å¾—ç›Šäºè®­ç»ƒæ•°æ®çš„è§„æ¨¡åŒ–ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å°†å›¾åƒæ–‡æœ¬å¯¹ä½œä¸ºå­¤ç«‹çš„è®­ç»ƒç¤ºä¾‹è¿›è¡Œå¤„ç†ï¼Œè¿™å¿½ç•¥äº†å¤šä¸ªé¢†åŸŸä¸­è‡ªç„¶å­˜åœ¨çš„ä¸°å¯Œå…³ç³»ç»“æ„ï¼Œå¦‚ç”µå­å•†åŠ¡äº§å“å…±è´­å›¾å’Œç¤¾äº¤æ¨èç½‘ç»œã€‚å—ç¥ç»ç§‘å­¦è¯æ®è¡¨æ˜äººç±»å°†çŸ¥è¯†ç¼–ç ä¸ºå…³ç³»è®¤çŸ¥åœ°å›¾çš„å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç»“æ„æ„ŸçŸ¥è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆSLIPï¼‰ã€‚SLIPé›†æˆäº†ä¸€ä¸ªç»“æ„å¯¹æ¯”æŸå¤±ï¼Œä»¥åœ¨å¯¹é½æ¨¡å¼çš„åŒæ—¶å¯¹ç»“æ„åŒ–å›¾ä¸­çš„ç›¸é‚»å®ä½“ä¹‹é—´çš„å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€èŒƒå¼ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„äºšé©¬é€Šäº§å“å…±è´­å¤šæ¨¡æ€å›¾æ•°æ®é›†ï¼Œä»¥å®ç°å¤§è§„æ¨¡çš„ç»“æ„åŒ–è·¨æ¨¡æ€ç›‘ç£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSLIPåœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®çš„è·¨æ¨¡æ€æ£€ç´¢å’Œåˆ†ç±»ä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºCLIPï¼Œè¿™æ˜¾ç¤ºäº†å…³ç³»ç›‘ç£å¯¹è·¨æ¨¡æ€å¯¹é½çš„ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.03019v1">PDF</a> Capstone Paper</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Vision-Language Pretrainingï¼ˆVLPï¼‰åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—çš„æ˜¾è‘—æˆåŠŸï¼Œä½†å…¶ä¸»è¦å¾—ç›Šäºè®­ç»ƒæ•°æ®çš„è§„æ¨¡åŒ–ã€‚ç°æœ‰çš„æ–¹æ³•å°†å›¾åƒæ–‡æœ¬å¯¹è§†ä¸ºå­¤ç«‹è®­ç»ƒæ ·æœ¬ï¼Œå¿½ç•¥äº†å¤šä¸ªé¢†åŸŸè‡ªç„¶å­˜åœ¨çš„ä¸°å¯Œå…³ç³»ç»“æ„ï¼Œå¦‚ç”µå­å•†åŠ¡äº§å“å…±è´­å›¾å’Œç¤¾äº¤æ¨èç½‘ç»œã€‚å—ç¥ç»ç§‘å­¦è¯æ®è¡¨æ˜äººç±»å°†çŸ¥è¯†ç¼–ç ä¸ºå…³ç³»è®¤çŸ¥å›¾çš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†Structure-aware Language-Image Pretrainingï¼ˆSLIPï¼‰ã€‚SLIPé€šè¿‡é›†æˆç»“æ„å¯¹æ¯”æŸå¤±æ¥å¯¹é½ä¸åŒæ¨¡æ€ï¼ŒåŒæ—¶å»ºæ¨¡ç»“æ„åŒ–å›¾ä¸­ç›¸é‚»å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€ç†å¿µï¼Œæ„å»ºäº†å¤§è§„æ¨¡çš„äºšé©¬é€Šäº§å“å…±è´­å¤šæ¨¡æ€å›¾æ•°æ®é›†ï¼Œå®ç°äº†ç»“æ„åŒ–è·¨æ¨¡æ€ç›‘ç£çš„å¤§è§„æ¨¡åº”ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSLIPåœ¨è·¨æ¨¡æ€æ£€ç´¢å’Œåˆ†ç±»ä»»åŠ¡ä¸Šçš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸­å‡ä¼˜äºCLIPï¼Œè¯æ˜äº†å…³ç³»ç›‘ç£å¯¹äºè·¨æ¨¡æ€å¯¹é½çš„ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Vision-Language Pretraining (VLP) åœ¨ä¸åŒä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä¸»è¦å¾—ç›Šäºè®­ç»ƒæ•°æ®çš„è§„æ¨¡åŒ–ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¿½ç•¥äº†å›¾åƒæ–‡æœ¬å¯¹ä¹‹é—´çš„ä¸°å¯Œå…³ç³»ç»“æ„ã€‚</li>
<li>SLIP é€šè¿‡å¼•å…¥ç»“æ„å¯¹æ¯”æŸå¤±æ¥å»ºæ¨¡å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„å…³ç³»ç»“æ„ã€‚</li>
<li>SLIP åœ¨è·¨æ¨¡æ€æ£€ç´¢å’Œåˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äº CLIPã€‚</li>
<li>SLIP åˆ©ç”¨å¤§è§„æ¨¡äºšé©¬é€Šäº§å“å…±è´­å¤šæ¨¡æ€å›¾æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚</li>
<li>å…³ç³»ç›‘ç£å¯¹äºè·¨æ¨¡æ€å¯¹é½å…·æœ‰é‡è¦ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.03019">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2bf900f785c554f3aa2c34e41b39fb55" align="middle">
<img src="https://picx.zhimg.com/v2-921df0b7684f1dfe6f66f29118576209" align="middle">
<img src="https://picx.zhimg.com/v2-14dd6d5c2a0acd843622c9e1ed0bf409" align="middle">
<img src="https://picx.zhimg.com/v2-bf05b7502c5c64410e66c860392ee3c1" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="NABench-Large-Scale-Benchmarks-of-Nucleotide-Foundation-Models-for-Fitness-Prediction"><a href="#NABench-Large-Scale-Benchmarks-of-Nucleotide-Foundation-Models-for-Fitness-Prediction" class="headerlink" title="NABench: Large-Scale Benchmarks of Nucleotide Foundation Models for   Fitness Prediction"></a>NABench: Large-Scale Benchmarks of Nucleotide Foundation Models for   Fitness Prediction</h2><p><strong>Authors:Zhongmin Li, Runze Ma, Jiahao Tan, Chengzi Tan, Shuangjia Zheng</strong></p>
<p>Nucleotide sequence variation can induce significant shifts in functional fitness. Recent nucleotide foundation models promise to predict such fitness effects directly from sequence, yet heterogeneous datasets and inconsistent preprocessing make it difficult to compare methods fairly across DNA and RNA families. Here we introduce NABench, a large-scale, systematic benchmark for nucleic acid fitness prediction. NABench aggregates 162 high-throughput assays and curates 2.6 million mutated sequences spanning diverse DNA and RNA families, with standardized splits and rich metadata. We show that NABench surpasses prior nucleotide fitness benchmarks in scale, diversity, and data quality. Under a unified evaluation suite, we rigorously assess 29 representative foundation models across zero-shot, few-shot prediction, transfer learning, and supervised settings. The results quantify performance heterogeneity across tasks and nucleic-acid types, demonstrating clear strengths and failure modes for different modeling choices and establishing strong, reproducible baselines. We release NABench to advance nucleic acid modeling, supporting downstream applications in RNA&#x2F;DNA design, synthetic biology, and biochemistry. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/mrzzmrzz/NABench">https://github.com/mrzzmrzz/NABench</a>. </p>
<blockquote>
<p>æ ¸è‹·é…¸åºåˆ—å˜å¼‚ä¼šå¯¼è‡´åŠŸèƒ½é€‚åº”æ€§çš„æ˜¾è‘—å˜åŒ–ã€‚æœ€è¿‘çš„æ ¸è‹·é…¸åŸºç¡€æ¨¡å‹æ‰¿è¯ºç›´æ¥ä»åºåˆ—é¢„æµ‹é€‚åº”æ€§æ•ˆåº”ï¼Œä½†å¼‚è´¨çš„æ•°æ®é›†å’Œä¸ä¸€è‡´çš„é¢„å¤„ç†ä½¿å¾—åœ¨DNAå’ŒRNAå®¶æ—ä¹‹é—´å…¬å¹³æ¯”è¾ƒæ–¹æ³•å˜å¾—å›°éš¾ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†NABenchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ ¸é…¸é€‚åº”æ€§é¢„æµ‹çš„å¤§è§„æ¨¡ç³»ç»ŸåŸºå‡†æµ‹è¯•ã€‚NABenchæ±‡é›†äº†162ä¸ªé«˜é€šé‡æµ‹å®šæ³•ï¼Œå¹¶æ•´ç†äº†è·¨è¶Šå¤šç§DNAå’ŒRNAå®¶æ—çš„260ä¸‡çªå˜åºåˆ—ï¼Œå…·æœ‰æ ‡å‡†åŒ–çš„åˆ†å‰²å’Œä¸°å¯Œçš„å…ƒæ•°æ®ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œåœ¨è§„æ¨¡ã€å¤šæ ·æ€§å’Œæ•°æ®è´¨é‡æ–¹é¢ï¼ŒNABenchè¶…è¶Šäº†å…ˆå‰çš„æ ¸è‹·é…¸é€‚åº”æ€§åŸºå‡†æµ‹è¯•ã€‚åœ¨ç»Ÿä¸€çš„è¯„ä¼°å¥—ä»¶ä¸‹ï¼Œæˆ‘ä»¬å¯¹é›¶æ ·æœ¬ã€å°‘æ ·æœ¬é¢„æµ‹ã€è¿ç§»å­¦ä¹ å’Œç›‘ç£ç¯å¢ƒä¸‹çš„29ä¸ªä»£è¡¨æ€§åŸºç¡€æ¨¡å‹è¿›è¡Œäº†ä¸¥æ ¼è¯„ä¼°ã€‚ç»“æœé‡åŒ–äº†ä¸åŒä»»åŠ¡å’Œæ ¸é…¸ç±»å‹ä¹‹é—´çš„æ€§èƒ½å¼‚è´¨æ€§ï¼Œå±•ç¤ºäº†ä¸åŒå»ºæ¨¡é€‰æ‹©çš„æ˜æ˜¾ä¼˜åŠ¿å’Œå¤±è´¥æ¨¡å¼ï¼Œå¹¶å»ºç«‹äº†å¼ºå¤§ä¸”å¯é‡ç°çš„åŸºå‡†ã€‚æˆ‘ä»¬å‘å¸ƒNABenchä»¥ä¿ƒè¿›æ ¸é…¸å»ºæ¨¡ï¼Œæ”¯æŒRNA&#x2F;DNAè®¾è®¡ã€åˆæˆç”Ÿç‰©å­¦å’Œç”Ÿç‰©åŒ–å­¦ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/mrzzmrzz/NABench%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mrzzmrzz/NABenchè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02888v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†NABenchï¼Œä¸€ä¸ªç”¨äºæ ¸é…¸é€‚åº”æ€§é¢„æµ‹çš„å¤§è§„æ¨¡ã€ç³»ç»Ÿæ€§åŸºå‡†æµ‹è¯•å¹³å°ã€‚è¯¥å¹³å°æ±‡èšäº†162ä¸ªé«˜é€šé‡å®éªŒï¼Œæ•´ç†å‡ºæ¶µç›–å¤šç§DNAå’ŒRNAå®¶æ—çš„260ä¸‡çªå˜åºåˆ—ï¼Œå…·æœ‰æ ‡å‡†åŒ–åˆ†å‰²å’Œä¸°å¯Œçš„å…ƒæ•°æ®ã€‚é€šè¿‡å¯¹29ä¸ªä»£è¡¨æ€§åŸºç¡€æ¨¡å‹è¿›è¡Œç»Ÿä¸€è¯„ä¼°å¥—ä»¶ä¸‹çš„ä¸¥æ ¼è¯„ä¼°ï¼ŒNABenchåœ¨è§„æ¨¡ã€å¤šæ ·æ€§å’Œæ•°æ®è´¨é‡ä¸Šè¶…è¶Šäº†å…ˆå‰çš„æ ¸è‹·é…¸é€‚åº”æ€§åŸºå‡†æµ‹è¯•ã€‚è¯„ä¼°ç»“æœé‡åŒ–äº†ä¸åŒä»»åŠ¡å’Œæ ¸é…¸ç±»å‹ä¹‹é—´æ€§èƒ½çš„å·®å¼‚ï¼Œå±•ç¤ºäº†ä¸åŒå»ºæ¨¡é€‰æ‹©çš„æ˜æ˜¾ä¼˜åŠ¿å’Œå¤±è´¥æ¨¡å¼ï¼Œä¸ºRNA&#x2F;DNAè®¾è®¡ã€åˆæˆç”Ÿç‰©å­¦å’Œç”Ÿç‰©åŒ–å­¦ç­‰ä¸‹æ¸¸åº”ç”¨æä¾›äº†æ¨åŠ¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NABenchæ˜¯ä¸€ä¸ªç”¨äºæ ¸é…¸é€‚åº”æ€§é¢„æµ‹çš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>å¹³å°æ¶µç›–äº†å¤šç§DNAå’ŒRNAå®¶æ—çš„çªå˜åºåˆ—æ•°æ®ã€‚</li>
<li>NABenchå…·æœ‰æ ‡å‡†åŒ–åˆ†å‰²å’Œä¸°å¯Œçš„å…ƒæ•°æ®ï¼Œæé«˜äº†æ•°æ®è´¨é‡ã€‚</li>
<li>é€šè¿‡å¯¹å¤šç§åŸºç¡€æ¨¡å‹çš„è¯„ä¼°ï¼ŒNABenchåœ¨è§„æ¨¡å’Œå¤šæ ·æ€§ä¸Šè¶…è¶Šäº†å…ˆå‰åŸºå‡†æµ‹è¯•ã€‚</li>
<li>è¯„ä¼°ç»“æœæ­ç¤ºäº†ä¸åŒå»ºæ¨¡é€‰æ‹©åœ¨ä¸åŒä»»åŠ¡å’Œæ ¸é…¸ç±»å‹ä¸Šçš„æ€§èƒ½å·®å¼‚ã€‚</li>
<li>NABenchä¸ºæ ¸é…¸å»ºæ¨¡æä¾›äº†æ¨åŠ¨ï¼Œæ”¯æŒRNA&#x2F;DNAè®¾è®¡ã€åˆæˆç”Ÿç‰©å­¦å’Œç”Ÿç‰©åŒ–å­¦ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02888">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b3bc0e0a5c003768a3de7277c59a8c1b" align="middle">
<img src="https://picx.zhimg.com/v2-d8b275c8b119c3a1c924b46f2d2d3ee9" align="middle">
<img src="https://picx.zhimg.com/v2-189ae1de65274a1278a180784d962670" align="middle">
<img src="https://picx.zhimg.com/v2-ea16d27e71f830322bac153f0b146c81" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Enabling-Robust-In-Context-Memory-and-Rapid-Task-Adaptation-in-Transformers-with-Hebbian-and-Gradient-Based-Plasticity"><a href="#Enabling-Robust-In-Context-Memory-and-Rapid-Task-Adaptation-in-Transformers-with-Hebbian-and-Gradient-Based-Plasticity" class="headerlink" title="Enabling Robust In-Context Memory and Rapid Task Adaptation in   Transformers with Hebbian and Gradient-Based Plasticity"></a>Enabling Robust In-Context Memory and Rapid Task Adaptation in   Transformers with Hebbian and Gradient-Based Plasticity</h2><p><strong>Authors:Siddharth Chaudhary</strong></p>
<p>Large language models display in-context learning as an emergent effect of scale, but they rely on static weights during inference. In contrast, biological systems continually adapt via synaptic plasticity. We investigate whether explicit, biologically inspired plasticity can endow Transformers with faster in-sequence adaptation. To this end, we augment decoder-only Transformers with fast-weight modules updated either by (i) a neuromodulated Hebbian rule or (ii) the gradient-based plasticity mechanism of Duan et al. (2023). Across copying, regression, and few-shot classification tasks (CIFAR-FS, Omniglot), Hebbian plasticity consistently achieves lower loss and stronger few-shot generalization, while gradient-based updates perform best on long-horizon credit assignment. When associations are short and linearly separable, static weights suffice, defining a clear boundary condition for when plasticity helps. Analysis of learned modulatory signals reveals that gradient-based rules maintain large, persistent updates, whereas Hebbian plasticity is sharply gated around salient events. Together, these results show that explicit plasticity complements attention by enabling rapid, task-specific adaptation, and clarify when different plasticity mechanisms are most effective. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºä¸Šä¸‹æ–‡å­¦ä¹ ä½œä¸ºè§„æ¨¡çš„ä¸€ç§æ¶Œç°æ•ˆåº”ï¼Œä½†å®ƒä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¾èµ–äºé™æ€æƒé‡ã€‚ä¸ä¹‹ç›¸åï¼Œç”Ÿç‰©ç³»ç»Ÿé€šè¿‡çªè§¦å¯å¡‘æ€§æŒç»­é€‚åº”ã€‚æˆ‘ä»¬ç ”ç©¶æ˜¯å¦æ˜ç¡®çš„ã€å—ç”Ÿç‰©å¯å‘çš„å¯å¡‘æ€§å¯ä»¥èµ‹äºˆTransformeræ›´å¿«çš„åºåˆ—å†…é€‚åº”ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¢åŠ äº†ä»…è§£ç çš„Transformerï¼Œé€šè¿‡ï¼ˆiï¼‰ç¥ç»è°ƒèŠ‚çš„èµ«å¸ƒè§„åˆ™æˆ–ï¼ˆiiï¼‰æ®µç­‰äººæå‡ºçš„åŸºäºæ¢¯åº¦çš„å¯å¡‘æ€§æœºåˆ¶è¿›è¡Œå¿«é€Ÿæƒé‡æ¨¡å—æ›´æ–°ï¼ˆ2023å¹´ï¼‰ã€‚åœ¨å¤åˆ¶ã€å›å½’å’Œå°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼ˆCIFAR-FSã€Omniglotï¼‰ä¸­ï¼Œèµ«å¸ƒå¯å¡‘æ€§å§‹ç»ˆå®ç°æ›´ä½çš„æŸå¤±å’Œæ›´å¼ºçš„å°‘æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œè€ŒåŸºäºæ¢¯åº¦çš„æ›´æ–°åœ¨é•¿è¿œè§†é‡ä¿¡ç”¨åˆ†é…æ–¹é¢è¡¨ç°æœ€ä½³ã€‚å½“å…³è”çŸ­æš‚ä¸”çº¿æ€§å¯åˆ†æ—¶ï¼Œé™æ€æƒé‡å°±è¶³å¤Ÿäº†ï¼Œè¿™ä¸ºå¯å¡‘æ€§ä½•æ—¶æœ‰å¸®åŠ©è®¾å®šäº†æ˜ç¡®çš„è¾¹ç•Œæ¡ä»¶ã€‚å¯¹å­¦åˆ°çš„è°ƒåˆ¶ä¿¡å·çš„åˆ†æè¡¨æ˜ï¼ŒåŸºäºæ¢¯åº¦çš„è§„åˆ™ç»´æŒäº†å¤§è€ŒæŒä¹…çš„æ›´æ–°ï¼Œè€Œèµ«å¸ƒå¯å¡‘æ€§åˆ™å›´ç»•æ˜¾è‘—äº‹ä»¶è¿›è¡Œå°–é”çš„é—¸é—¨æ§åˆ¶ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœå±•ç¤ºäº†æ˜ç¡®çš„å¯å¡‘æ€§å¦‚ä½•é€šè¿‡å®ç°å¿«é€Ÿã€ç‰¹å®šä»»åŠ¡çš„é€‚åº”æ¥è¡¥å……æ³¨æ„åŠ›ï¼Œå¹¶æ˜ç¡®äº†ä¸åŒå¯å¡‘æ€§æœºåˆ¶ä½•æ—¶æœ€ä¸ºæœ‰æ•ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.21908v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºä¸Šä¸‹æ–‡å­¦ä¹ çš„èƒ½åŠ›ï¼Œè¿™å½’åŠŸäºå…¶è§„æ¨¡æ•ˆåº”ï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¾èµ–é™æ€æƒé‡ã€‚ä¸æ­¤ç›¸åï¼Œç”Ÿç‰©ç³»ç»Ÿåˆ™é€šè¿‡çªè§¦å¯å¡‘æ€§è¿›è¡ŒæŒç»­çš„é€‚åº”ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ¢è®¨æ˜ç¡®çš„ã€å—ç”Ÿç‰©å¯å‘çš„å¯å¡‘æ€§æ˜¯å¦èƒ½å¤Ÿèµ‹äºˆTransformeræ›´å¿«çš„åºåˆ—é€‚åº”åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä¸ºä»…è§£ç çš„Transformerå¢åŠ äº†é€šè¿‡ï¼ˆiï¼‰ç¥ç»è°ƒèŠ‚çš„èµ«å¸ƒè§„åˆ™æˆ–ï¼ˆiiï¼‰æ®µç­‰äººæå‡ºçš„åŸºäºæ¢¯åº¦çš„å¯å¡‘æ€§æœºåˆ¶æ›´æ–°çš„å¿«é€Ÿæƒé‡æ¨¡å—ã€‚ï¼ˆåœ¨æ‹·è´ä»»åŠ¡ã€å›å½’ä»»åŠ¡å’Œå°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚CIFAR-FSå’ŒOmniglotï¼‰ä¸Šï¼Œèµ«å¸ƒå¯å¡‘æ€§è¾¾åˆ°äº†æ›´ä½çš„æŸå¤±å’Œæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œè€ŒåŸºäºæ¢¯åº¦çš„æ›´æ–°åœ¨é•¿æ—¶é—´åºåˆ—ä¸Šè¡¨ç°æœ€ä½³ã€‚å½“å…³è”çŸ­æš‚ä¸”çº¿æ€§å¯åˆ†æ—¶ï¼Œé™æ€æƒé‡è¶³å¤Ÿä½¿ç”¨ï¼Œè¿™ä¸ºå¯å¡‘æ€§å‘æŒ¥ä½œç”¨è®¾å®šäº†æ˜ç¡®çš„è¾¹ç•Œæ¡ä»¶ã€‚å¯¹å­¦åˆ°çš„è°ƒåˆ¶ä¿¡å·çš„åˆ†ææ˜¾ç¤ºï¼ŒåŸºäºæ¢¯åº¦çš„è§„åˆ™ç»´æŒäº†å¤§è€ŒæŒä¹…çš„æ›´æ–°ï¼Œè€Œèµ«å¸ƒå¯å¡‘æ€§åˆ™å›´ç»•é‡è¦äº‹ä»¶è¿›è¡Œå°–é”çš„è°ƒèŠ‚ã€‚æ€»ä½“è€Œè¨€ï¼Œæ˜ç¡®çš„å¯å¡‘æ€§è¡¥å……äº†æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°äº†å¿«é€Ÿã€é’ˆå¯¹ä»»åŠ¡çš„é€‚åº”ï¼Œå¹¶æ˜ç¡®äº†ä¸åŒå¯å¡‘æ€§æœºåˆ¶ä½•æ—¶æœ€ä¸ºæœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºä¸Šä¸‹æ–‡å­¦ä¹ çš„èƒ½åŠ›ï¼Œä½†æ¨ç†æ—¶ä¾èµ–é™æ€æƒé‡ã€‚</li>
<li>ç”Ÿç‰©ç³»ç»Ÿé€šè¿‡çªè§¦å¯å¡‘æ€§è¿›è¡ŒæŒç»­é€‚åº”ã€‚</li>
<li>æ˜¾å¼ã€å—ç”Ÿç‰©å¯å‘çš„å¯å¡‘æ€§å¯ä»¥ä½¿Transformerå…·å¤‡æ›´å¿«çš„åºåˆ—é€‚åº”åŠ›ã€‚</li>
<li>é€šè¿‡èµ«å¸ƒå¯å¡‘æ€§å’ŒåŸºäºæ¢¯åº¦çš„æ›´æ–°æœºåˆ¶å¢å¼ºäº†Transformerçš„æ€§èƒ½ã€‚</li>
<li>åœ¨ä¸åŒä»»åŠ¡åœºæ™¯ä¸‹ï¼Œèµ«å¸ƒå¯å¡‘æ€§å’ŒåŸºäºæ¢¯åº¦çš„æ›´æ–°æœºåˆ¶å„æœ‰ä¼˜åŠ¿ã€‚</li>
<li>å½“å…³è”çŸ­æš‚ä¸”çº¿æ€§å¯åˆ†æ—¶ï¼Œé™æ€æƒé‡è¶³å¤Ÿä½¿ç”¨ï¼Œè¿™æ˜¯å¯å¡‘æ€§çš„è¾¹ç•Œæ¡ä»¶ä¹‹ä¸€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.21908">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9c915953067f462fbe1df8cf6f875657" align="middle">
<img src="https://picx.zhimg.com/v2-23e9691191530aa4509a1d49e3c5e0ab" align="middle">
<img src="https://picx.zhimg.com/v2-c6920bbe63807ef9943a847fa13922ed" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Navigating-High-Dimensional-Concept-Space-with-Metalearning"><a href="#Navigating-High-Dimensional-Concept-Space-with-Metalearning" class="headerlink" title="Navigating High Dimensional Concept Space with Metalearning"></a>Navigating High Dimensional Concept Space with Metalearning</h2><p><strong>Authors:Max Gupta</strong></p>
<p>Rapidly learning abstract concepts from limited examples is a hallmark of human intelligence. This work investigates whether gradient-based meta-learning can equip neural networks with inductive biases for efficient few-shot acquisition of discrete concepts. I compare meta-learning methods against a supervised learning baseline on Boolean concepts (logical statements) generated by a probabilistic context-free grammar (PCFG). By systematically varying concept dimensionality (number of features) and recursive compositionality (depth of grammar recursion), I delineate between complexity regimes in which meta-learning robustly improves few-shot concept learning and regimes in which it does not. Meta-learners are much better able to handle compositional complexity than featural complexity. I highlight some reasons for this with a representational analysis of the weights of meta-learners and a loss landscape analysis demonstrating how featural complexity increases the roughness of loss trajectories, allowing curvature-aware optimization to be more effective than first-order methods. I find improvements in out-of-distribution generalization on complex concepts by increasing the number of adaptation steps in meta-SGD, where adaptation acts as a way of encouraging exploration of rougher loss basins. Overall, this work highlights the intricacies of learning compositional versus featural complexity in high dimensional concept spaces and provides a road to understanding the role of 2nd order methods and extended gradient adaptation in few-shot concept learning. </p>
<blockquote>
<p>ä»æœ‰é™ä¾‹å­ä¸­å¿«é€Ÿå­¦ä¹ æŠ½è±¡æ¦‚å¿µæ˜¯äººç±»æ™ºèƒ½çš„æ ‡å¿—ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ¢ç©¶åŸºäºæ¢¯åº¦çš„å…ƒå­¦ä¹ æ˜¯å¦èƒ½ä¸ºç¥ç»ç½‘ç»œé…å¤‡å½’çº³åç½®ï¼Œä»¥é«˜æ•ˆåœ°è¿›è¡Œç¦»æ•£æ¦‚å¿µçš„å°‘é‡æ ·æœ¬è·å–ã€‚æˆ‘åœ¨æ¦‚ç‡ä¸Šä¸‹æ–‡æ— å…³è¯­æ³•ï¼ˆPCFGï¼‰ç”Ÿæˆçš„å¸ƒå°”æ¦‚å¿µï¼ˆé€»è¾‘é™ˆè¿°ï¼‰ä¸Šï¼Œå°†å…ƒå­¦ä¹ æ–¹æ³•ä¸ç›‘ç£å­¦ä¹ åŸºçº¿è¿›è¡Œäº†æ¯”è¾ƒã€‚é€šè¿‡ç³»ç»Ÿåœ°æ”¹å˜æ¦‚å¿µçš„ç»´åº¦ï¼ˆç‰¹å¾æ•°é‡ï¼‰å’Œé€’å½’ç»„åˆæ€§ï¼ˆè¯­æ³•é€’å½’æ·±åº¦ï¼‰ï¼Œæˆ‘åˆ’å®šäº†å…ƒå­¦ä¹ åœ¨å“ªäº›å¤æ‚æ€§ç¯å¢ƒä¸­èƒ½å¤Ÿå¯é åœ°æ”¹å–„å°‘é‡æ ·æœ¬çš„æ¦‚å¿µå­¦ä¹ ï¼Œä»¥åŠåœ¨å“ªäº›ç¯å¢ƒä¸­åˆ™ä¸èƒ½ã€‚å…ƒå­¦ä¹ è€…æ¯”ç‰¹å¾å¤æ‚æ€§æ›´èƒ½å¤„ç†ç»„åˆå¤æ‚æ€§ã€‚é€šè¿‡å¯¹å…ƒå­¦ä¹ è€…çš„æƒé‡è¡¨ç¤ºè¿›è¡Œåˆ†æï¼Œä»¥åŠé€šè¿‡æŸå¤±æ™¯è§‚åˆ†æå±•ç¤ºç‰¹å¾å¤æ‚æ€§å¦‚ä½•å¢åŠ æŸå¤±è½¨è¿¹çš„ç²—ç³™åº¦ï¼Œä»è€Œä½¿æ›²ç‡æ„ŸçŸ¥ä¼˜åŒ–æ¯”ä¸€é˜¶æ–¹æ³•æ›´æœ‰æ•ˆï¼Œæˆ‘å¼ºè°ƒäº†è¿™ä¸€ç‚¹çš„ä¸€äº›åŸå› ã€‚æˆ‘å‘ç°é€šè¿‡å¢åŠ å…ƒSGDä¸­çš„é€‚åº”æ­¥éª¤æ•°é‡ï¼Œå¯ä»¥æé«˜å¤æ‚æ¦‚å¿µä¸Šçš„ç¦»ç¾¤åˆ†å¸ƒæ³›åŒ–èƒ½åŠ›ï¼Œå…¶ä¸­é€‚åº”ä½œä¸ºä¸€ç§æ–¹å¼é¼“åŠ±æ¢ç´¢æ›´ç²—ç³™çš„æŸå¤±ç›†åœ°ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹å·¥ä½œçªå‡ºäº†åœ¨é«˜ç»´æ¦‚å¿µç©ºé—´ä¸­å­¦ä¹ ç»„åˆä¸ç‰¹å¾å¤æ‚æ€§çš„ç»†å¾®å·®åˆ«ï¼Œå¹¶ä¸ºç†è§£äºŒé˜¶æ–¹æ³•å’Œæ‰©å±•æ¢¯åº¦é€‚åº”åœ¨å°‘é‡æ ·æœ¬æ¦‚å¿µå­¦ä¹ ä¸­çš„ä½œç”¨æä¾›äº†é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01948v3">PDF</a> 7 pages, 3 figures. Presented at the ICML 2025 HiLD Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºæ¢¯åº¦çš„å…ƒå­¦ä¹ æ˜¯å¦èƒ½è®©ç¥ç»ç½‘ç»œå…·å¤‡å½’çº³åè§ï¼Œä»¥æœ‰æ•ˆåœ°ä»æœ‰é™æ ·æœ¬ä¸­å­¦ä¹ æŠ½è±¡æ¦‚å¿µã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯”å…ƒå­¦ä¹ æ–¹æ³•ä¸ç›‘ç£å­¦ä¹ åŸºçº¿ï¼Œåœ¨ç”±æ¦‚ç‡ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ç”Ÿæˆçš„å¸ƒå°”æ¦‚å¿µä¸Šè¿›è¡Œå®éªŒã€‚é€šè¿‡ç³»ç»Ÿåœ°æ”¹å˜æ¦‚å¿µçš„ç»´åº¦å’Œé€’å½’ç»„åˆæ€§ï¼Œç ”ç©¶åˆ†æäº†å…ƒå­¦ä¹ åœ¨å“ªäº›å¤æ‚åº¦æƒ…å†µä¸‹èƒ½ç¨³å¥åœ°æé«˜å°‘æ ·æœ¬æ¦‚å¿µå­¦ä¹ ï¼Œä»¥åŠåœ¨å“ªäº›æƒ…å†µä¸‹æ— æ³•æé«˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡å…ƒå­¦ä¹ å™¨çš„æƒé‡è¡¨ç¤ºåˆ†æå’ŒæŸå¤±è½¨è¿¹çš„ç²—ç³™æ€§åˆ†æï¼Œæ­ç¤ºäº†å…ƒå­¦ä¹ å™¨å¤„ç†ç»„åˆå¤æ‚æ€§å’Œç‰¹å¾å¤æ‚æ€§çš„å·®å¼‚ã€‚é€šè¿‡å¢åŠ å…ƒSGDä¸­çš„é€‚åº”æ­¥éª¤æ•°é‡ï¼Œå‘ç°å¯¹å¤æ‚æ¦‚å¿µçš„æ³›åŒ–èƒ½åŠ›æœ‰æ‰€æé«˜ï¼Œå…¶ä¸­é€‚åº”ä½œä¸ºä¸€ç§é¼“åŠ±æ¢ç´¢ç²—ç³™æŸå¤±ç›†åœ°çš„æ–¹å¼ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–‡æ­ç¤ºäº†é«˜ç»´æ¦‚å¿µç©ºé—´ä¸­å­¦ä¹ ç»„åˆä¸ç‰¹å¾å¤æ‚æ€§çš„ç»†å¾®å·®åˆ«ï¼Œå¹¶ä¸ºç†è§£äºŒé˜¶æ–¹æ³•å’Œæ‰©å±•æ¢¯åº¦é€‚åº”åœ¨å°‘æ ·æœ¬æ¦‚å¿µå­¦ä¹ ä¸­çš„ä½œç”¨æä¾›äº†æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡æ¢è®¨äº†å…ƒå­¦ä¹ åœ¨å°‘æ ·æœ¬æ¦‚å¿µå­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œå…³æ³¨å…¶åœ¨å¤„ç†æŠ½è±¡æ¦‚å¿µæ—¶çš„æ•ˆç‡ã€‚</li>
<li>é€šè¿‡å¯¹æ¯”å®éªŒï¼Œç ”ç©¶äº†å…ƒå­¦ä¹ åœ¨å¤„ç†ä¸åŒç»´åº¦å’Œç»„åˆæ€§çš„æ¦‚å¿µæ—¶çš„è¡¨ç°ã€‚</li>
<li>å‘ç°å…ƒå­¦ä¹ åœ¨å¤„ç†ç»„åˆå¤æ‚æ€§æ–¹é¢ä¼˜äºç‰¹å¾å¤æ‚æ€§ã€‚</li>
<li>é€šè¿‡åˆ†æå…ƒå­¦ä¹ å™¨çš„æƒé‡å’ŒæŸå¤±è½¨è¿¹ï¼Œæ­ç¤ºäº†å…¶å¤„ç†å¤æ‚æ€§çš„æœºåˆ¶ã€‚</li>
<li>å¢åŠ é€‚åº”æ­¥éª¤æ•°é‡å¯æé«˜åœ¨å¤æ‚æ¦‚å¿µä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>é€‚åº”è¿‡ç¨‹æœ‰åŠ©äºæ¢ç´¢ç²—ç³™çš„æŸå¤±ç›†åœ°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01948">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ba057c1b1385c714fae7f9140356e2e" align="middle">
<img src="https://picx.zhimg.com/v2-535e410b2921f9bc57afecc6c02d1d0b" align="middle">
<img src="https://picx.zhimg.com/v2-67f0cde460da4b7b824c09270f22cd62" align="middle">
<img src="https://picx.zhimg.com/v2-c62a2aaaefcdfe0671417c7cbf7be9da" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Scalable-Medication-Extraction-and-Discontinuation-Identification-from-Electronic-Health-Records-Using-Large-Language-Models"><a href="#Scalable-Medication-Extraction-and-Discontinuation-Identification-from-Electronic-Health-Records-Using-Large-Language-Models" class="headerlink" title="Scalable Medication Extraction and Discontinuation Identification from   Electronic Health Records Using Large Language Models"></a>Scalable Medication Extraction and Discontinuation Identification from   Electronic Health Records Using Large Language Models</h2><p><strong>Authors:Chong Shao, Douglas Snyder, Chiran Li, Bowen Gu, Kerry Ngan, Chun-Ting Yang, Jiageng Wu, Richard Wyss, Kueiyu Joshua Lin, Jie Yang</strong></p>
<p>Identifying medication discontinuations in electronic health records (EHRs) is vital for patient safety but is often hindered by information being buried in unstructured notes. This study aims to evaluate the capabilities of advanced open-sourced and proprietary large language models (LLMs) in extracting medications and classifying their medication status from EHR notes, focusing on their scalability on medication information extraction without human annotation. We collected three EHR datasets from diverse sources to build the evaluation benchmark. We evaluated 12 advanced LLMs and explored multiple LLM prompting strategies. Performance on medication extraction, medication status classification, and their joint task (extraction then classification) was systematically compared across all experiments. We found that LLMs showed promising performance on the medication extraction and discontinuation classification from EHR notes. GPT-4o consistently achieved the highest average F1 scores in all tasks under zero-shot setting - 94.0% for medication extraction, 78.1% for discontinuation classification, and 72.7% for the joint task. Open-sourced models followed closely, Llama-3.1-70B-Instruct achieved the highest performance in medication status classification on the MIV-Med dataset (68.7%) and in the joint task on both the Re-CASI (76.2%) and MIV-Med (60.2%) datasets. Medical-specific LLMs demonstrated lower performance compared to advanced general-domain LLMs. Few-shot learning generally improved performance, while CoT reasoning showed inconsistent gains. LLMs demonstrate strong potential for medication extraction and discontinuation identification on EHR notes, with open-sourced models offering scalable alternatives to proprietary systems and few-shot can further improve LLMsâ€™ capability. </p>
<blockquote>
<p>è¯†åˆ«ç”µå­å¥åº·è®°å½•ï¼ˆEHRsï¼‰ä¸­çš„è¯ç‰©åœç”¨å¯¹äºæ‚£è€…å®‰å…¨è‡³å…³é‡è¦ï¼Œä½†å¾€å¾€å› ä¿¡æ¯éšè—åœ¨éç»“æ„åŒ–ç¬”è®°ä¸­è€Œå—åˆ°é˜»ç¢ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°å…ˆè¿›çš„å¼€æºå’Œä¸“æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»EHRç¬”è®°ä¸­æå–è¯ç‰©å’Œåˆ†ç±»å…¶ç”¨è¯çŠ¶æ€çš„èƒ½åŠ›ï¼Œé‡ç‚¹å…³æ³¨å…¶åœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„è¯ç‰©ä¿¡æ¯æå–ä¸Šçš„å¯æ‰©å±•æ€§ã€‚æˆ‘ä»¬ä»å¤šç§æ¥æºæ”¶é›†äº†ä¸‰ä¸ªEHRæ•°æ®é›†æ¥å»ºç«‹è¯„ä¼°åŸºå‡†ã€‚æˆ‘ä»¬è¯„ä¼°äº†12ä¸ªå…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶æ¢ç´¢äº†å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹æç¤ºç­–ç•¥ã€‚ç³»ç»Ÿåœ°æ¯”è¾ƒäº†æ‰€æœ‰å®éªŒä¸­è¯ç‰©æå–ã€ç”¨è¯çŠ¶æ€åˆ†ç±»åŠå…¶è”åˆä»»åŠ¡ï¼ˆå…ˆæå–ååˆ†ç±»ï¼‰çš„æ€§èƒ½ã€‚æˆ‘ä»¬å‘ç°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨EHRç¬”è®°ä¸­çš„è¯ç‰©æå–å’Œåœè¯åˆ†ç±»æ–¹é¢è¡¨ç°å‡ºæœ‰å¸Œæœ›çš„æ€§èƒ½ã€‚GPT-4oåœ¨æ‰€æœ‰ä»»åŠ¡ä¸­çš„å¹³å‡F1å¾—åˆ†å§‹ç»ˆæœ€é«˜ï¼Œé›¶æ ·æœ¬è®¾ç½®ä¸‹çš„å¾—åˆ†åˆ†åˆ«ä¸ºï¼šè¯ç‰©æå–94.0%ï¼Œåœè¯åˆ†ç±»78.1%ï¼Œè”åˆä»»åŠ¡72.7%ã€‚å¼€æºæ¨¡å‹ç´§éšå…¶åï¼ŒLlama-3.1-70B-Instructåœ¨MIV-Medæ•°æ®é›†ä¸Šçš„ç”¨è¯çŠ¶æ€åˆ†ç±»åŠRe-CASIå’ŒMIV-Medæ•°æ®é›†çš„è”åˆä»»åŠ¡ä¸­å‡å–å¾—äº†æœ€é«˜æ€§èƒ½ï¼ˆåˆ†åˆ«ä¸º68.7%ã€76.2%å’Œ60.2%ï¼‰ã€‚ç‰¹å®šåŒ»ç–—é¢†åŸŸçš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸å…ˆè¿›é€šç”¨é¢†åŸŸçš„å¤§å‹è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼Œè¡¨ç°è¾ƒå·®ã€‚å°‘æ ·æœ¬å­¦ä¹ é€šå¸¸å¯ä»¥æé«˜æ€§èƒ½ï¼Œè€ŒCoTæ¨ç†æ˜¾ç¤ºå‡ºä¸ä¸€è‡´çš„æ”¶ç›Šã€‚å¤§å‹è¯­è¨€æ¨¡å‹åœ¨EHRç¬”è®°ä¸­çš„è¯ç‰©æå–å’Œåœè¯è¯†åˆ«æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ½œåŠ›ï¼Œå¼€æºæ¨¡å‹ä¸ºä¸“æœ‰ç³»ç»Ÿæä¾›äº†å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè€Œå°‘æ ·æœ¬å­¦ä¹ å¯ä»¥è¿›ä¸€æ­¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.11137v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åˆ©ç”¨å…ˆè¿›çš„å¼€æºå’Œä¸“æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»ç”µå­å¥åº·è®°å½•ï¼ˆEHRsï¼‰ä¸­æå–è¯ç‰©ä¿¡æ¯å¹¶åˆ†ç±»å…¶ç”¨è¯çŠ¶æ€çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒLLMsåœ¨è¯ç‰©æå–å’Œåœè¯åˆ†ç±»æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½æ€§èƒ½ï¼ŒGPT-4oåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¡¨ç°æœ€ä½³ã€‚æ­¤å¤–ï¼Œå¼€æºæ¨¡å‹å¦‚Llama-3.1-70B-Instructä¹Ÿæœ‰å‡ºè‰²è¡¨ç°ï¼Œè€Œé’ˆå¯¹åŒ»ç–—é¢†åŸŸçš„LLMsæ€§èƒ½è¾ƒä½ã€‚å°‘é‡æ ·æœ¬å­¦ä¹ èƒ½æé«˜æ€§èƒ½ï¼Œè€ŒCoTæ¨ç†åˆ™è¡¨ç°å‡ºä¸ä¸€è‡´çš„æ•ˆæœã€‚LLMsåœ¨EHRsä¸­çš„è¯ç‰©æå–å’Œåœè¯è¯†åˆ«æ–¹é¢å…·æœ‰å¼ºå¤§æ½œåŠ›ï¼Œå¼€æºæ¨¡å‹å¯æä¾›å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…ˆè¿›çš„LLMsåœ¨è¯ç‰©æå–å’Œåœè¯åˆ†ç±»æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½æ€§èƒ½ã€‚</li>
<li>GPT-4oåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¡¨ç°æœ€ä½³ï¼Œå¹³å‡F1åˆ†æ•°é«˜ã€‚</li>
<li>å¼€æºæ¨¡å‹å¦‚Llama-3.1-70B-Instructåœ¨è¯ç‰©çŠ¶æ€åˆ†ç±»æ–¹é¢è¡¨ç°ä¼˜ç§€ã€‚</li>
<li>åŒ»ç–—é¢†åŸŸçš„LLMsæ€§èƒ½è¾ƒä½ã€‚</li>
<li>å°‘é‡æ ·æœ¬å­¦ä¹ èƒ½æé«˜LLMsçš„æ€§èƒ½ã€‚</li>
<li>CoTæ¨ç†çš„æ•ˆæœè¡¨ç°ä¸ä¸€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.11137">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-272fb19a82998827eb3fc723b14ee256" align="middle">
<img src="https://picx.zhimg.com/v2-ed66eda0752f51e76bee65c24db25b8c" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="UniFault-A-Fault-Diagnosis-Foundation-Model-from-Bearing-Data"><a href="#UniFault-A-Fault-Diagnosis-Foundation-Model-from-Bearing-Data" class="headerlink" title="UniFault: A Fault Diagnosis Foundation Model from Bearing Data"></a>UniFault: A Fault Diagnosis Foundation Model from Bearing Data</h2><p><strong>Authors:Emadeldeen Eldele, Mohamed Ragab, Xu Qing,  Edward, Zhenghua Chen, Min Wu, Xiaoli Li, Jay Lee</strong></p>
<p>Machine fault diagnosis (FD) is a critical task for predictive maintenance, enabling early fault detection and preventing unexpected failures. Despite its importance, existing FD models are operation-specific with limited generalization across diverse datasets. Foundation models (FM) have demonstrated remarkable potential in both visual and language domains, achieving impressive generalization capabilities even with minimal data through few-shot or zero-shot learning. However, translating these advances to FD presents unique hurdles. Unlike the large-scale, cohesive datasets available for images and text, FD datasets are typically smaller and more heterogeneous, with significant variations in sampling frequencies and the number of channels across different systems and applications. This heterogeneity complicates the design of a universal architecture capable of effectively processing such diverse data while maintaining robust feature extraction and learning capabilities. In this paper, we introduce UniFault, a foundation model for fault diagnosis that systematically addresses these issues. Specifically, the model incorporates a comprehensive data harmonization pipeline featuring two key innovations. First, a unification scheme transforms multivariate inputs into standardized univariate sequences. Second, a novel cross-domain temporal fusion strategy mitigates distribution shifts and enriches sample diversity and count, improving the model generalization across varying conditions. UniFault is pretrained on over 6.9 million samples spanning diverse FD datasets, enabling superior few-shot performance. Extensive experiments on real-world FD datasets demonstrate that UniFault achieves state-of-the-art performance, setting a new benchmark for fault diagnosis models and paving the way for more scalable and robust predictive maintenance solutions. </p>
<blockquote>
<p>æœºå™¨æ•…éšœè¯Šæ–­ï¼ˆFDï¼‰æ˜¯é¢„æµ‹æ€§ç»´æŠ¤ä¸­çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ï¼Œèƒ½å¤Ÿå®ç°æ—©æœŸæ•…éšœæ£€æµ‹å¹¶é˜²æ­¢æ„å¤–æ•…éšœçš„å‘ç”Ÿã€‚å°½ç®¡å…¶é‡è¦æ€§æ˜¾è‘—ï¼Œä½†ç°æœ‰çš„FDæ¨¡å‹é€šå¸¸å…·æœ‰æ“ä½œç‰¹å¼‚æ€§ï¼Œåœ¨å¤šç§æ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚åŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰åœ¨è§†è§‰å’Œè¯­è¨€é¢†åŸŸè¡¨ç°å‡ºäº†æƒŠäººçš„æ½œåŠ›ï¼Œå³ä½¿åœ¨å°‘é‡æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½é€šè¿‡å°æ ·æœ¬å­¦ä¹ å®ç°ä»¤äººå°è±¡æ·±åˆ»çš„æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå°†è¿™äº›è¿›å±•è½¬åŒ–ä¸ºFDé¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ä¸å¯ç”¨äºå›¾åƒå’Œæ–‡æœ¬çš„å¤§è§„æ¨¡è¿è´¯æ•°æ®é›†ç›¸æ¯”ï¼ŒFDæ•°æ®é›†é€šå¸¸æ›´å°ã€æ›´å¼‚æ„ï¼Œä¸åŒç³»ç»Ÿå’Œåº”ç”¨çš„é‡‡æ ·é¢‘ç‡å’Œæ•°æ®é€šé“æ•°é‡å­˜åœ¨é‡å¤§å·®å¼‚ã€‚è¿™ç§å¼‚è´¨æ€§ä½¿å¾—è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†å¦‚æ­¤å¤šæ ·æ•°æ®çš„åŒæ—¶ä¿æŒç¨³å¥çš„ç‰¹å¾æå–å’Œå­¦ä¹ èƒ½åŠ›çš„é€šç”¨æ¶æ„å˜å¾—å¤æ‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†UniFaultï¼Œä¸€ä¸ªç”¨äºæ•…éšœè¯Šæ–­çš„åŸºç¡€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç³»ç»Ÿåœ°è§£å†³äº†è¿™äº›é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨å…¨é¢çš„æ•°æ®åè°ƒç®¡é“ï¼Œå…·æœ‰ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ã€‚é¦–å…ˆï¼Œç»Ÿä¸€æ–¹æ¡ˆå°†å¤šå…ƒè¾“å…¥è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„å•å˜é‡åºåˆ—ã€‚å…¶æ¬¡ï¼Œä¸€ç§æ–°çš„è·¨åŸŸæ—¶é—´èåˆç­–ç•¥ç¼“è§£äº†åˆ†å¸ƒåç§»é—®é¢˜å¹¶ä¸°å¯Œäº†æ ·æœ¬å¤šæ ·æ€§å’Œæ•°é‡ï¼Œæé«˜äº†æ¨¡å‹åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚UniFaultåœ¨æ¶µç›–å¤šç§FDæ•°æ®é›†çš„è¶…690ä¸‡ä¸ªæ ·æœ¬ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¯å®ç°å‡ºè‰²çš„å°æ ·æœ¬æ€§èƒ½ã€‚åœ¨çœŸå®ä¸–ç•Œçš„FDæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒUniFaultè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼Œä¸ºæ•…éšœè¯Šæ–­æ¨¡å‹è®¾å®šäº†æ–°çš„åŸºå‡†ï¼Œå¹¶ä¸ºæ›´å¯æ‰©å±•å’Œç¨³å¥çš„é¢„æµ‹æ€§ç»´æŠ¤è§£å†³æ–¹æ¡ˆé“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01373v2">PDF</a> </p>
<p><strong>Summary</strong><br>å·¥ä¸šæ•…éšœè¯Šæ–­æ˜¯é¢„æµ‹æ€§ç»´æŠ¤çš„å…³é”®ä»»åŠ¡ï¼Œå¯¹äºé˜²æ­¢æ„å¤–æ•…éšœæœ‰ç€é‡è¦ä½œç”¨ã€‚å½“å‰æ•…éšœè¯Šæ–­æ¨¡å‹çš„æ“ä½œå…·æœ‰ç‰¹å¼‚æ€§ï¼Œå¯¹å¤šæ ·æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›å—é™ã€‚åŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰åœ¨è§†è§‰å’Œè¯­è¨€é¢†åŸŸå±•ç°äº†å‡ºè‰²çš„æ½œåŠ›ï¼Œèƒ½é€šè¿‡å°æ ·æœ¬å­¦ä¹ å®ç°ä»¤äººå°è±¡æ·±åˆ»çš„æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå°†è¿™ä¸€è¿›å±•åº”ç”¨äºæ•…éšœè¯Šæ–­é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æ•°æ®é›†å°ä¸”å¤šæ ·ã€é‡‡æ ·é¢‘ç‡å·®å¼‚å¤§ç­‰å¯¼è‡´è®¾è®¡èƒ½å¤Ÿå¤„ç†æ­¤ç±»æ•°æ®çš„é€šç”¨æ¶æ„å˜å¾—å¤æ‚ã€‚æœ¬æ–‡æå‡ºUniFaultæ¨¡å‹ï¼Œç³»ç»Ÿè§£å†³è¿™äº›é—®é¢˜ã€‚æ¨¡å‹åŒ…å«å…¨é¢çš„æ•°æ®è°ƒå’Œç®¡é“ï¼Œé€šè¿‡ç»Ÿä¸€æ–¹æ¡ˆå°†å¤šå…ƒè¾“å…¥è½¬åŒ–ä¸ºæ ‡å‡†åŒ–ä¸€å…ƒåºåˆ—ï¼Œå¹¶é€šè¿‡æ–°å‹è·¨åŸŸæ—¶é—´èåˆç­–ç•¥è§£å†³åˆ†å¸ƒè½¬ç§»é—®é¢˜ï¼Œæé«˜æ ·æœ¬å¤šæ ·æ€§å’Œæ•°é‡ï¼Œæ”¹å–„æ¨¡å‹åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚UniFaultåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•…éšœè¯Šæ–­æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå±•ç°å‡ºå“è¶Šçš„å°æ ·æœ¬æ€§èƒ½ï¼Œä¸ºæ•…éšœè¯Šæ–­æ¨¡å‹æ ‘ç«‹æ–°æ ‡æ†ï¼Œä¸ºæ›´å¯æ‰©å±•å’Œç¨³å¥çš„é¢„æµ‹æ€§ç»´æŠ¤è§£å†³æ–¹æ¡ˆé“ºå¹³é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœºå™¨æ•…éšœè¯Šæ–­ï¼ˆFDï¼‰æ˜¯é¢„æµ‹æ€§ç»´æŠ¤çš„å…³é”®ä»»åŠ¡ï¼Œè¦æ±‚æ—©æœŸæ•…éšœæ£€æµ‹ã€‚</li>
<li>å½“å‰FDæ¨¡å‹æ“ä½œç‰¹å¼‚æ€§é«˜ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚</li>
<li>åŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰åœ¨è§†è§‰å’Œè¯­è¨€é¢†åŸŸå…·æœ‰å‡ºè‰²æ³›åŒ–æ½œåŠ›ã€‚</li>
<li>å°†FMåº”ç”¨äºFDé¢ä¸´æ•°æ®å°ã€å¤šæ ·æ€§å’Œé‡‡æ ·é¢‘ç‡å·®å¼‚ç­‰æŒ‘æˆ˜ã€‚</li>
<li>UniFaultæ¨¡å‹é€šè¿‡æ•°æ®è°ƒå’Œç®¡é“è§£å†³è¿™äº›é—®é¢˜ï¼ŒåŒ…å«ç»Ÿä¸€æ–¹æ¡ˆå’Œè·¨åŸŸæ—¶é—´èåˆç­–ç•¥ã€‚</li>
<li>UniFaulté€šè¿‡é¢„è®­ç»ƒåœ¨å¤šä¸ªFDæ•°æ®é›†ä¸Šå®ç°ä¼˜è¶Šçš„å°æ ·æœ¬æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01373">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-732c55200c60666b5e5f30b1b16c6e39" align="middle">
<img src="https://picx.zhimg.com/v2-4a6ecd323e8ff4eb69389bbd25d83236" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Sundial-A-Family-of-Highly-Capable-Time-Series-Foundation-Models"><a href="#Sundial-A-Family-of-Highly-Capable-Time-Series-Foundation-Models" class="headerlink" title="Sundial: A Family of Highly Capable Time Series Foundation Models"></a>Sundial: A Family of Highly Capable Time Series Foundation Models</h2><p><strong>Authors:Yong Liu, Guo Qin, Zhiyuan Shi, Zhi Chen, Caiyin Yang, Xiangdong Huang, Jianmin Wang, Mingsheng Long</strong></p>
<p>We introduce Sundial, a family of native, flexible, and scalable time series foundation models. To predict the next-patchâ€™s distribution, we propose a TimeFlow Loss based on flow-matching, which facilitates native pre-training of Transformers on continuous-valued time series without discrete tokenization. Conditioned on arbitrary-length time series, our models are pre-trained without specifying any prior distribution and can generate multiple probable predictions, achieving more flexibility in representation learning than using parametric densities. Towards time series foundation models, we leverage minimal but crucial adaptations of Transformers and curate TimeBench with one trillion time points, comprising mostly real-world datasets and synthetic data. By mitigating mode collapse via TimeFlow Loss, we pre-train a family of Sundial models on TimeBench, which achieve unprecedented model capacity and generalization performance. In addition to excellent scalability, Sundial achieves state-of-the-art results on both point and probabilistic forecasting benchmarks with a just-in-time inference speed, i.e., making zero-shot predictions within a few milliseconds. We believe that Sundialâ€™s pioneering generative forecasting capability can improve model reliability in real-world decision-making. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/thuml/Sundial">https://github.com/thuml/Sundial</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Sundialï¼Œè¿™æ˜¯ä¸€ç³»åˆ—åŸç”Ÿã€çµæ´»ä¸”å¯æ‰©å±•çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ã€‚ä¸ºäº†é¢„æµ‹ä¸‹ä¸€ä¸ªç‰‡æ®µçš„åˆ†å¸ƒï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæµåŒ¹é…çš„TimeFlow Lossï¼Œå®ƒä¿ƒè¿›äº†Transformeråœ¨è¿ç»­å€¼æ—¶é—´åºåˆ—ä¸Šçš„åŸç”Ÿé¢„è®­ç»ƒï¼Œæ— éœ€è¿›è¡Œç¦»æ•£ä»¤ç‰ŒåŒ–ã€‚æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥å¯¹ä»»æ„é•¿åº¦çš„æ—¶é—´åºåˆ—è¿›è¡Œé¢„è®­ç»ƒï¼Œæ— éœ€æŒ‡å®šä»»ä½•å…ˆéªŒåˆ†å¸ƒï¼Œå¹¶ä¸”å¯ä»¥ç”Ÿæˆå¤šä¸ªå¯èƒ½çš„é¢„æµ‹ï¼Œä¸å‚æ•°å¯†åº¦æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨è¡¨ç¤ºå­¦ä¹ ä¸­å®ç°äº†æ›´å¤§çš„çµæ´»æ€§ã€‚åœ¨æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹æ–¹é¢ï¼Œæˆ‘ä»¬å¯¹Transformerè¿›è¡Œäº†å¾®å°ä½†å…³é”®æ€§çš„è°ƒæ•´ï¼Œå¹¶ç²¾å¿ƒåˆ¶ä½œäº†åŒ…å«å¤§å¤šæ•°ç°å®ä¸–ç•Œæ•°æ®é›†å’Œåˆæˆæ•°æ®çš„TimeBenchæ•°æ®é›†ï¼ŒåŒ…å«ä¸‡äº¿ä¸ªæ—¶é—´ç‚¹ã€‚é€šè¿‡TimeFlow Losså‡è½»æ¨¡å¼å´©æºƒé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨TimeBenchä¸Šé¢„è®­ç»ƒäº†ä¸€ç³»åˆ—Sundialæ¨¡å‹ï¼Œå®ç°äº†å‰æ‰€æœªæœ‰çš„æ¨¡å‹å®¹é‡å’Œæ³›åŒ–æ€§èƒ½ã€‚é™¤äº†å‡ºè‰²çš„å¯æ‰©å±•æ€§å¤–ï¼ŒSundialåœ¨ç‚¹é¢„æµ‹å’Œæ¦‚ç‡é¢„æµ‹åŸºå‡†æµ‹è¯•ä¸Šéƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œå³æ—¶æ¨ç†é€Ÿåº¦æå¿«ï¼Œå³é›¶æ ·æœ¬é¢„æµ‹ä»…éœ€å‡ æ¯«ç§’ã€‚æˆ‘ä»¬ç›¸ä¿¡Sundialå¼€åˆ›æ€§çš„ç”Ÿæˆé¢„æµ‹èƒ½åŠ›å¯ä»¥æé«˜çœŸå®ä¸–ç•Œå†³ç­–ä¸­çš„æ¨¡å‹å¯é æ€§ã€‚ä»£ç å¯ä»ä»¥ä¸‹ç½‘ç«™è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/thuml/Sundial">https://github.com/thuml/Sundial</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.00816v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Sundialç³»åˆ—åŸç”Ÿã€çµæ´»ä¸”å¯æ‰©å±•çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ã€‚æå‡ºåŸºäºæµåŒ¹é…çš„TimeFlow Lossï¼Œç”¨äºåœ¨æ— éœ€ç¦»æ•£æ ‡è®°çš„æƒ…å†µä¸‹å¯¹è¿ç»­å€¼æ—¶é—´åºåˆ—è¿›è¡ŒåŸç”Ÿé¢„è®­ç»ƒã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨æœªæŒ‡å®šå…ˆéªŒåˆ†å¸ƒçš„æƒ…å†µä¸‹è¿›è¡Œé¢„è®­ç»ƒï¼Œç”Ÿæˆå¤šç§å¯èƒ½çš„é¢„æµ‹ç»“æœï¼Œä»è€Œå®ç°è¡¨ç¤ºå­¦ä¹ ä¸Šçš„æ›´å¤§çµæ´»æ€§ã€‚æ¨¡å‹è¿˜åˆ©ç”¨æœ€å°ä½†å…³é”®çš„Transformeræ”¹è¿›ï¼Œç²¾å¿ƒæ‰“é€ äº†TimeBenchæ•°æ®é›†ï¼ŒåŒ…å«ä¸‡äº¿ä¸ªæ—¶é—´ç‚¹ï¼Œä»¥æ¶µç›–ç°å®æ•°æ®å’Œåˆæˆæ•°æ®ä¸ºä¸»ã€‚ç»è¿‡TimeFlow Lossé˜²æ­¢æ¨¡å¼å´©æºƒçš„æ–¹æ³•ï¼Œåœ¨TimeBenchä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„Sundialç³»åˆ—æ¨¡å‹è¡¨ç°å‡ºå‰æ‰€æœªæœ‰çš„å®¹é‡å’Œæ³›åŒ–æ€§èƒ½ï¼Œä¸ä»…åœ¨ç‚¹å’Œæ¦‚ç‡é¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœï¼Œè¿˜å…·æœ‰å³æ—¶æ¨ç†é€Ÿåº¦ï¼Œèƒ½å¤Ÿåœ¨å‡ æ¯«ç§’å†…å®Œæˆé›¶æ ·æœ¬é¢„æµ‹ã€‚ç›¸ä¿¡Sundialå¼€åˆ›æ€§çš„ç”Ÿæˆé¢„æµ‹èƒ½åŠ›å¯ä»¥æé«˜ç°å®å†³ç­–ä¸­çš„æ¨¡å‹å¯é æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Sundialæ˜¯åŸç”Ÿã€çµæ´»ä¸”å¯æ‰©å±•çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ã€‚</li>
<li>æå‡ºTimeFlow Lossï¼ŒåŸºäºæµåŒ¹é…è¿›è¡Œé¢„è®­ç»ƒï¼Œæ— éœ€ç¦»æ•£æ ‡è®°å¤„ç†è¿ç»­å€¼æ—¶é—´åºåˆ—ã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå¤šç§é¢„æµ‹ç»“æœï¼Œå®ç°è¡¨ç¤ºå­¦ä¹ ä¸Šçš„çµæ´»æ€§ã€‚</li>
<li>åˆ©ç”¨æœ€å°ä½†å…³é”®çš„Transformeræ”¹è¿›ï¼Œåˆ›å»ºTimeBenchæ•°æ®é›†ã€‚</li>
<li>TimeBenchåŒ…å«å¤§é‡ç°å®å’Œåˆæˆæ•°æ®ï¼Œæ¶µç›–å¤šç§æ—¶é—´åºåˆ—åœºæ™¯ã€‚</li>
<li>é€šè¿‡TimeFlow Lossé˜²æ­¢æ¨¡å¼å´©æºƒï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½å’Œå®¹é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.00816">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-32ebe23c76f0eb34a5475fe0d2546602" align="middle">
<img src="https://picx.zhimg.com/v2-34a4e7b61c5d3ce97e00dc715ce529cf" align="middle">
<img src="https://picx.zhimg.com/v2-626e7450f4bf0496fb315c173dd1c8f5" align="middle">
<img src="https://picx.zhimg.com/v2-f42c9b8cff206deed391f518eae3a0a6" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MSDNet-Multi-Scale-Decoder-for-Few-Shot-Semantic-Segmentation-via-Transformer-Guided-Prototyping"><a href="#MSDNet-Multi-Scale-Decoder-for-Few-Shot-Semantic-Segmentation-via-Transformer-Guided-Prototyping" class="headerlink" title="MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via   Transformer-Guided Prototyping"></a>MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via   Transformer-Guided Prototyping</h2><p><strong>Authors:Amirreza Fateh, Mohammad Reza Mohammadi, Mohammad Reza Jahed Motlagh</strong></p>
<p>Few-shot Semantic Segmentation addresses the challenge of segmenting objects in query images with only a handful of annotated examples. However, many previous state-of-the-art methods either have to discard intricate local semantic features or suffer from high computational complexity. To address these challenges, we propose a new Few-shot Semantic Segmentation framework based on the Transformer architecture. Our approach introduces the spatial transformer decoder and the contextual mask generation module to improve the relational understanding between support and query images. Moreover, we introduce a multi scale decoder to refine the segmentation mask by incorporating features from different resolutions in a hierarchical manner. Additionally, our approach integrates global features from intermediate encoder stages to improve contextual understanding, while maintaining a lightweight structure to reduce complexity. This balance between performance and efficiency enables our method to achieve competitive results on benchmark datasets such as PASCAL-5^i and COCO-20^i in both 1-shot and 5-shot settings. Notably, our model with only 1.5 million parameters demonstrates competitive performance while overcoming limitations of existing methodologies. <a target="_blank" rel="noopener" href="https://github.com/amirrezafateh/MSDNet">https://github.com/amirrezafateh/MSDNet</a> </p>
<blockquote>
<p>å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆFew-shot Semantic Segmentationï¼‰æ—¨åœ¨è§£å†³ä»…ä½¿ç”¨å°‘é‡æ ‡æ³¨ç¤ºä¾‹æ¥å¯¹æŸ¥è¯¢å›¾åƒä¸­çš„å¯¹è±¡è¿›è¡Œåˆ†å‰²çš„æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œè®¸å¤šç°æœ‰çš„æœ€å…ˆè¿›çš„æ–¹æ³•è¦ä¹ˆä¸å¾—ä¸ä¸¢å¼ƒå¤æ‚çš„å±€éƒ¨è¯­ä¹‰ç‰¹å¾ï¼Œè¦ä¹ˆé¢ä¸´è®¡ç®—å¤æ‚åº¦é«˜çš„å›°æ‰°ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºTransformeræ¶æ„çš„å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ç©ºé—´å˜æ¢è§£ç å™¨å’Œä¸Šä¸‹æ–‡æ©æ¨¡ç”Ÿæˆæ¨¡å—ï¼Œä»¥æé«˜æ”¯æŒå›¾åƒå’ŒæŸ¥è¯¢å›¾åƒä¹‹é—´çš„å…³ç³»ç†è§£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šå°ºåº¦è§£ç å™¨ï¼Œä»¥å±‚æ¬¡çš„æ–¹å¼èå…¥ä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾æ¥ä¼˜åŒ–åˆ†å‰²æ©æ¨¡ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸­é—´ç¼–ç å™¨é˜¶æ®µçš„å…¨å±€ç‰¹å¾ä»¥æé«˜ä¸Šä¸‹æ–‡ç†è§£ï¼ŒåŒæ—¶ä¿æŒè½»é‡çº§ç»“æ„ä»¥é™ä½å¤æ‚åº¦ã€‚æ€§èƒ½ä¸æ•ˆç‡ä¹‹é—´çš„è¿™ç§å¹³è¡¡ä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨PASCAL-5^iå’ŒCOCO-20^iç­‰åŸºå‡†æ•°æ®é›†ä¸Šå®ç°å…·æœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œæ— è®ºæ˜¯åœ¨å•æ¬¡å°„å‡»è¿˜æ˜¯äº”æ¬¡å°„å‡»çš„ç¯å¢ƒä¸­ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»…æœ‰150ä¸‡ä¸ªå‚æ•°ï¼Œå±•ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶å…‹æœäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚è¯¦æƒ…è¯·å‚è§<a target="_blank" rel="noopener" href="https://github.com/amirrezafateh/MSDNet%E3%80%82">https://github.com/amirrezafateh/MSDNetã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.11316v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºåŸºäºTransformeræ¶æ„çš„Few-shotè¯­ä¹‰åˆ†å‰²æ–°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ç©ºé—´å˜æ¢è§£ç å™¨ã€ä¸Šä¸‹æ–‡æ©è†œç”Ÿæˆæ¨¡å—å’Œå¤šå°ºåº¦è§£ç å™¨ï¼Œæé«˜äº†å¯¹æ”¯æŒå›¾åƒå’ŒæŸ¥è¯¢å›¾åƒä¹‹é—´å…³ç³»çš„ç†è§£ï¼Œå®ç°äº†å¯¹å°‘é‡æ ‡æ³¨æ ·æœ¬çš„å›¾åƒåˆ†å‰²ã€‚è¯¥æ¨¡å‹åœ¨PASCAL-5^iå’ŒCOCO-20^iç­‰åŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ä¸æ•ˆç‡å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥åŸºäºTransformeræ¶æ„çš„Few-shotè¯­ä¹‰åˆ†å‰²æ–°æ¡†æ¶ã€‚</li>
<li>é€šè¿‡ç©ºé—´å˜æ¢è§£ç å™¨å’Œä¸Šä¸‹æ–‡æ©è†œç”Ÿæˆæ¨¡å—æé«˜å…³ç³»ç†è§£ã€‚</li>
<li>é‡‡ç”¨å¤šå°ºåº¦è§£ç å™¨ï¼Œé€šè¿‡åˆ†å±‚æ–¹å¼èå…¥ä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾ï¼Œä¼˜åŒ–åˆ†å‰²æ©è†œã€‚</li>
<li>é›†æˆä¸­é—´ç¼–ç å™¨é˜¶æ®µçš„å…¨å±€ç‰¹å¾ï¼Œæå‡ä¸Šä¸‹æ–‡ç†è§£ã€‚</li>
<li>ä¿æŒæ¨¡å‹ç»“æ„è½»é‡åŒ–ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚</li>
<li>åœ¨åŸºå‡†æ•°æ®é›†å¦‚PASCAL-5^iå’ŒCOCO-20^iä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.11316">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a467c24feedf139e997c5728ca4fc71b" align="middle">
<img src="https://picx.zhimg.com/v2-1c6e719d0a34e103475f80a5b03bc20f" align="middle">
<img src="https://picx.zhimg.com/v2-b1232d75de621baac9ac76c250665a86" align="middle">
<img src="https://picx.zhimg.com/v2-43b280a5d0cd66845ec22d0186712420" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-07/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-07/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-07/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1dc5af37412971d3a4929fcbb19af10a" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-07  PLUTO-4 Frontier Pathology Foundation Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-07/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c0e0da729ae65cd12dcf37a2918d3aa3" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-07  Manifold-constrained Hamilton-Jacobi Reachability Learning for   Decentralized Multi-Agent Motion Planning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33446.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
