<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-21  DiffStereo High-Frequency Aware Diffusion Model for Stereo Image   Restoration">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-70485c60bb15224906c1dd79f5cacbd7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    39 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-21-æ›´æ–°"><a href="#2025-01-21-æ›´æ–°" class="headerlink" title="2025-01-21 æ›´æ–°"></a>2025-01-21 æ›´æ–°</h1><h2 id="DiffStereo-High-Frequency-Aware-Diffusion-Model-for-Stereo-Image-Restoration"><a href="#DiffStereo-High-Frequency-Aware-Diffusion-Model-for-Stereo-Image-Restoration" class="headerlink" title="DiffStereo: High-Frequency Aware Diffusion Model for Stereo Image   Restoration"></a>DiffStereo: High-Frequency Aware Diffusion Model for Stereo Image   Restoration</h2><p><strong>Authors:Huiyun Cao, Yuan Shi, Bin Xia, Xiaoyu Jin, Wenming Yang</strong></p>
<p>Diffusion models (DMs) have achieved promising performance in image restoration but havenâ€™t been explored for stereo images. The application of DM in stereo image restoration is confronted with a series of challenges. The need to reconstruct two images exacerbates DMâ€™s computational cost. Additionally, existing latent DMs usually focus on semantic information and remove high-frequency details as redundancy during latent compression, which is precisely what matters for image restoration. To address the above problems, we propose a high-frequency aware diffusion model, DiffStereo for stereo image restoration as the first attempt at DM in this domain. Specifically, DiffStereo first learns latent high-frequency representations (LHFR) of HQ images. DM is then trained in the learned space to estimate LHFR for stereo images, which are fused into a transformer-based stereo image restoration network providing beneficial high-frequency information of corresponding HQ images. The resolution of LHFR is kept the same as input images, which preserves the inherent texture from distortion. And the compression in channels alleviates the computational burden of DM. Furthermore, we devise a position encoding scheme when integrating the LHFR into the restoration network, enabling distinctive guidance in different depths of the restoration network. Comprehensive experiments verify that by combining generative DM and transformer, DiffStereo achieves both higher reconstruction accuracy and better perceptual quality on stereo super-resolution, deblurring, and low-light enhancement compared with state-of-the-art methods. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰åœ¨å›¾åƒä¿®å¤æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ç«‹ä½“å›¾åƒä¿®å¤é¢†åŸŸå°šæœªå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚æ‰©æ•£æ¨¡å‹åº”ç”¨äºç«‹ä½“å›¾åƒä¿®å¤é¢ä¸´ä¸€ç³»åˆ—æŒ‘æˆ˜ã€‚é‡å»ºä¸¤ä¸ªå›¾åƒçš„éœ€æ±‚åŠ å‰§äº†æ‰©æ•£æ¨¡å‹çš„è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹é€šå¸¸å…³æ³¨è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶åœ¨æ½œåœ¨å‹ç¼©è¿‡ç¨‹ä¸­å»é™¤é«˜é¢‘ç»†èŠ‚ï¼Œè€Œè¿™æ­£æ˜¯å›¾åƒä¿®å¤æ‰€é‡è§†çš„ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬é¦–æ¬¡å°è¯•åœ¨ç«‹ä½“å›¾åƒä¿®å¤é¢†åŸŸå¼•å…¥æ‰©æ•£æ¨¡å‹ï¼Œæå‡ºä¸€ç§é«˜é¢‘æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹â€”â€”DiffStereoã€‚å…·ä½“æ¥è¯´ï¼ŒDiffStereoé¦–å…ˆå­¦ä¹ é«˜è´¨é‡å›¾åƒï¼ˆHQï¼‰çš„æ½œåœ¨é«˜é¢‘è¡¨ç¤ºï¼ˆLHFRï¼‰ã€‚ç„¶åï¼Œåœ¨æ‰€å­¦ç©ºé—´å†…è®­ç»ƒæ‰©æ•£æ¨¡å‹ä»¥ä¼°è®¡ç«‹ä½“å›¾åƒçš„LHFRï¼Œå¹¶å°†å…¶èåˆåˆ°åŸºäºå˜å‹å™¨çš„ç«‹ä½“å›¾åƒä¿®å¤ç½‘ç»œä¸­ï¼Œä¸ºå¯¹åº”çš„é«˜è´¨é‡å›¾åƒæä¾›æœ‰ç›Šçš„é«˜é¢‘ä¿¡æ¯ã€‚LHFRçš„åˆ†è¾¨ç‡ä¿æŒä¸è¾“å…¥å›¾åƒç›¸åŒï¼Œä¿ç•™äº†åŸå§‹çº¹ç†æ— å¤±çœŸã€‚åŒæ—¶é€šé“å‹ç¼©å‡è½»äº†æ‰©æ•£æ¨¡å‹çš„è®¡ç®—è´Ÿæ‹…ã€‚æ­¤å¤–ï¼Œå½“å°†LHFRé›†æˆåˆ°ä¿®å¤ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½ç½®ç¼–ç æ–¹æ¡ˆï¼Œåœ¨ä¿®å¤ç½‘ç»œçš„ä¸åŒæ·±åº¦æä¾›ç‹¬ç‰¹çš„æŒ‡å¯¼ã€‚ç»¼åˆå®éªŒè¯æ˜ï¼Œé€šè¿‡ç»“åˆç”Ÿæˆæ€§æ‰©æ•£æ¨¡å‹å’Œå˜å‹å™¨ï¼ŒDiffStereoåœ¨ç«‹ä½“è¶…åˆ†è¾¨ç‡ã€å»æ¨¡ç³Šå’Œä½å…‰å¢å¼ºæ–¹é¢å®ç°äº†æ›´é«˜çš„é‡å»ºç²¾åº¦å’Œæ›´å¥½çš„æ„ŸçŸ¥è´¨é‡ï¼Œç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ–¹æ³•å…·æœ‰ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10325v1">PDF</a> 9 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºDiffStereoçš„é«˜é¢‘æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºç«‹ä½“å›¾åƒæ¢å¤ã€‚è¯¥æ¨¡å‹é¦–æ¬¡å°è¯•å°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºè¯¥é¢†åŸŸï¼Œè§£å†³äº†ç«‹ä½“å›¾åƒæ¢å¤ä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚é€šè¿‡å­¦ä¹ é«˜è´¨é‡å›¾åƒçš„é«˜é¢‘è¡¨ç¤ºï¼ŒDiffStereoè®­ç»ƒæ‰©æ•£æ¨¡å‹ä¼°è®¡ç«‹ä½“å›¾åƒçš„é«˜é¢‘è¡¨ç¤ºï¼Œç„¶åå°†å…¶èåˆåˆ°åŸºäºå˜æ¢çš„å›¾åƒæ¢å¤ç½‘ç»œä¸­ï¼Œä»è€Œæä¾›é«˜è´¨é‡å›¾åƒçš„æœ‰ç›Šé«˜é¢‘ä¿¡æ¯ã€‚è¯¥æ¨¡å‹é€šè¿‡ä¿æŒé«˜é¢‘è¡¨ç¤ºçš„åˆ†è¾¨ç‡ä¸è¾“å…¥å›¾åƒç›¸åŒï¼Œä¿ç•™äº†å›ºæœ‰çš„çº¹ç†ï¼Œå¹¶é€šè¿‡å‡å°‘é€šé“å‹ç¼©å‡è½»äº†æ‰©æ•£æ¨¡å‹çš„è®¡ç®—è´Ÿæ‹…ã€‚å®éªŒè¯æ˜ï¼Œç»“åˆç”Ÿæˆæ‰©æ•£æ¨¡å‹å’Œå˜æ¢å™¨ï¼ŒDiffStereoåœ¨ç«‹ä½“è¶…åˆ†è¾¨ç‡ã€å»æ¨¡ç³Šå’Œä½å…‰å¢å¼ºæ–¹é¢å®ç°äº†è¾ƒé«˜çš„é‡å»ºç²¾åº¦å’Œæ›´å¥½çš„æ„ŸçŸ¥è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒæ¢å¤é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›å±•ï¼Œä½†å°šæœªåœ¨ç«‹ä½“å›¾åƒæ¢å¤ä¸­å¾—åˆ°åº”ç”¨ã€‚</li>
<li>é¦–æ¬¡æå‡ºåä¸ºDiffStereoçš„é«˜é¢‘æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œåº”ç”¨äºç«‹ä½“å›¾åƒæ¢å¤ã€‚</li>
<li>DiffStereoå­¦ä¹ é«˜è´¨é‡å›¾åƒçš„é«˜é¢‘è¡¨ç¤ºå¹¶å°†å…¶åº”ç”¨äºä¼°è®¡ç«‹ä½“å›¾åƒçš„é«˜é¢‘ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡å°†é«˜é¢‘è¡¨ç¤ºèåˆåˆ°åŸºäºå˜æ¢çš„å›¾åƒæ¢å¤ç½‘ç»œä¸­ï¼ŒDiffStereoæé«˜äº†å›¾åƒçš„æ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>DiffStereoé€šè¿‡ä¿æŒé«˜é¢‘è¡¨ç¤ºçš„åˆ†è¾¨ç‡ä¸è¾“å…¥å›¾åƒç›¸åŒï¼Œä¿ç•™äº†çº¹ç†ç»†èŠ‚ï¼ŒåŒæ—¶é™ä½äº†è®¡ç®—æˆæœ¬ã€‚</li>
<li>ç»“åˆç”Ÿæˆæ‰©æ•£æ¨¡å‹å’Œå˜æ¢å™¨æŠ€æœ¯ï¼ŒDiffStereoåœ¨ç«‹ä½“å›¾åƒæ¢å¤çš„å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10325">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-204a185289149b31ce55aa82b46a048d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cb96af87d3c5b0b98d762963f4b34f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54cf617c316da025430a7147c85397c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75f113edca4fbb809a14110e31bba6a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-12f1c11fe9608dac67a278fba267761f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2b0b6f7b2ffcb9806af933a93577086e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DiffuEraser-A-Diffusion-Model-for-Video-Inpainting"><a href="#DiffuEraser-A-Diffusion-Model-for-Video-Inpainting" class="headerlink" title="DiffuEraser: A Diffusion Model for Video Inpainting"></a>DiffuEraser: A Diffusion Model for Video Inpainting</h2><p><strong>Authors:Xiaowen Li, Haolan Xue, Peiran Ren, Liefeng Bo</strong></p>
<p>Recent video inpainting algorithms integrate flow-based pixel propagation with transformer-based generation to leverage optical flow for restoring textures and objects using information from neighboring frames, while completing masked regions through visual Transformers. However, these approaches often encounter blurring and temporal inconsistencies when dealing with large masks, highlighting the need for models with enhanced generative capabilities. Recently, diffusion models have emerged as a prominent technique in image and video generation due to their impressive performance. In this paper, we introduce DiffuEraser, a video inpainting model based on stable diffusion, designed to fill masked regions with greater details and more coherent structures. We incorporate prior information to provide initialization and weak conditioning,which helps mitigate noisy artifacts and suppress hallucinations. Additionally, to improve temporal consistency during long-sequence inference, we expand the temporal receptive fields of both the prior model and DiffuEraser, and further enhance consistency by leveraging the temporal smoothing property of Video Diffusion Models. Experimental results demonstrate that our proposed method outperforms state-of-the-art techniques in both content completeness and temporal consistency while maintaining acceptable efficiency. </p>
<blockquote>
<p>æœ€è¿‘çš„è§†é¢‘è¡¥å…¨ç®—æ³•ç»“åˆäº†åŸºäºæµçš„åƒç´ ä¼ æ’­å’ŒåŸºäºè½¬æ¢å™¨çš„ç”Ÿæˆï¼Œåˆ©ç”¨å…‰å­¦æµæ¢å¤çº¹ç†å’Œå¯¹è±¡ï¼ŒåŒæ—¶ä½¿ç”¨æ¥è‡ªç›¸é‚»å¸§çš„ä¿¡æ¯ï¼ŒåŒæ—¶é€šè¿‡è§†è§‰è½¬æ¢å™¨å®Œæˆé®ç½©åŒºåŸŸã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨å¤„ç†å¤§é®ç½©æ—¶ç»å¸¸é‡åˆ°æ¨¡ç³Šå’Œæ—¶é—´ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œè¿™çªæ˜¾äº†éœ€è¦å…·æœ‰å¢å¼ºç”Ÿæˆèƒ½åŠ›çš„æ¨¡å‹ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹å› å…¶ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½è€Œæˆä¸ºå›¾åƒå’Œè§†é¢‘ç”Ÿæˆä¸­çš„ä¸€é¡¹é‡è¦æŠ€æœ¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†åŸºäºç¨³å®šæ‰©æ•£çš„DiffuEraserè§†é¢‘è¡¥å…¨æ¨¡å‹ï¼Œæ—¨åœ¨ä»¥æ›´é«˜çš„ç»†èŠ‚å’Œæ›´è¿è´¯çš„ç»“æ„å¡«å……é®ç½©åŒºåŸŸã€‚æˆ‘ä»¬ç»“åˆå…ˆéªŒä¿¡æ¯æä¾›åˆå§‹åŒ–å’Œå¼±æ¡ä»¶è®¾ç½®ï¼Œè¿™æœ‰åŠ©äºå‡å°‘å™ªå£°ä¼ªå½±å¹¶æŠ‘åˆ¶å¹»è§‰ã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜é•¿åºåˆ—æ¨ç†æœŸé—´çš„æ—¶åºä¸€è‡´æ€§ï¼Œæˆ‘ä»¬æ‰©å¤§äº†å…ˆéªŒæ¨¡å‹å’ŒDiffuEraserçš„æ—¶é—´æ„Ÿå—é‡ï¼Œå¹¶å€ŸåŠ©è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶åºå¹³æ»‘å±æ€§è¿›ä¸€æ­¥æé«˜äº†ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å†…å®¹å®Œæ•´æ€§å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒå¯æ¥å—çš„æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10018v1">PDF</a> 11pages, 13figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¨³å®šæ‰©æ•£çš„DiffuEraserè§†é¢‘ä¿®å¤æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¡«è¡¥é®æŒ¡åŒºåŸŸï¼Œç»†èŠ‚æ›´ä¸°å¯Œä¸”ç»“æ„æ›´è¿è´¯ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å…ˆéªŒä¿¡æ¯åˆå§‹åŒ–å¹¶æä¾›å¼±æ¡ä»¶ï¼Œå‡å°‘å™ªå£°ä¼ªå½±å¹¶æŠ‘åˆ¶å¹»è§‰ã€‚åŒæ—¶ï¼Œé€šè¿‡æ‰©å¤§æ—¶é—´æ¥æ”¶åŸŸå¹¶åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶åºå¹³æ»‘ç‰¹æ€§ï¼Œæé«˜äº†é•¿åºåˆ—æ¨ç†çš„æ—¶ç©ºä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å†…å®¹å®Œæ•´æ€§å’Œæ—¶åºä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¥å—çš„æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DiffuEraserç»“åˆæµä¼ æ’­çš„åƒç´ å’ŒåŸºäºè½¬æ¢å™¨çš„ç”Ÿæˆæ–¹æ³•æ¢å¤çº¹ç†å’Œå¯¹è±¡ã€‚</li>
<li>å½“å‰æ–¹æ³•åœ¨é‡åˆ°å¤§é®ç½©æ—¶å¯èƒ½å‡ºç°æ¨¡ç³Šå’Œæ—¶åºä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ–¹é¢çš„çªå‡ºè¡¨ç°ä½¿å…¶æˆä¸ºç†æƒ³é€‰æ‹©ã€‚</li>
<li>DiffuEraseråˆ©ç”¨å…ˆéªŒä¿¡æ¯è¿›è¡Œåˆå§‹åŒ–å’Œå¼±æ¡ä»¶åŒ–ï¼Œå‡å°‘å™ªå£°ä¼ªå½±å’ŒæŠ‘åˆ¶å¹»è§‰ã€‚</li>
<li>é€šè¿‡æ‰©å¤§æ—¶é—´æ¥æ”¶åŸŸæé«˜æ—¶åºä¸€è‡´æ€§ã€‚</li>
<li>åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶åºå¹³æ»‘ç‰¹æ€§è¿›ä¸€æ­¥å¢å¼ºä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10018">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b340379526b79bd4080d097ad54f09d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-672de16b31c2804b2e9322250c1ef29d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ec5b7fa3445f5a6f4eb0ebc4ac2c698f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-70485c60bb15224906c1dd79f5cacbd7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b24b2709eca619ee64f2177b71130e49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d037c9940ec01be7aba07cffdaa4d5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59e37c094fd48ce711a763b2b3224280.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Physics-informed-DeepCT-Sinogram-Wavelet-Decomposition-Meets-Masked-Diffusion"><a href="#Physics-informed-DeepCT-Sinogram-Wavelet-Decomposition-Meets-Masked-Diffusion" class="headerlink" title="Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked   Diffusion"></a>Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked   Diffusion</h2><p><strong>Authors:Zekun Zhou, Tan Liu, Bing Yu, Yanru Gong, Liu Shi, Qiegen Liu</strong></p>
<p>Diffusion model shows remarkable potential on sparse-view computed tomography (SVCT) reconstruction. However, when a network is trained on a limited sample space, its generalization capability may be constrained, which degrades performance on unfamiliar data. For image generation tasks, this can lead to issues such as blurry details and inconsistencies between regions. To alleviate this problem, we propose a Sinogram-based Wavelet random decomposition And Random mask diffusion Model (SWARM) for SVCT reconstruction. Specifically, introducing a random mask strategy in the sinogram effectively expands the limited training sample space. This enables the model to learn a broader range of data distributions, enhancing its understanding and generalization of data uncertainty. In addition, applying a random training strategy to the high-frequency components of the sinogram wavelet enhances feature representation and improves the ability to capture details in different frequency bands, thereby improving performance and robustness. Two-stage iterative reconstruction method is adopted to ensure the global consistency of the reconstructed image while refining its details. Experimental results demonstrate that SWARM outperforms competing approaches in both quantitative and qualitative performance across various datasets. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹åœ¨ç¨€ç–è§†å›¾è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆSVCTï¼‰é‡å»ºä¸­æ˜¾ç¤ºå‡ºæ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“ç½‘ç»œåœ¨æœ‰é™çš„æ ·æœ¬ç©ºé—´ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ï¼Œå…¶æ³›åŒ–èƒ½åŠ›å¯èƒ½ä¼šå—åˆ°é™åˆ¶ï¼Œå¯¼è‡´åœ¨é™Œç”Ÿæ•°æ®ä¸Šçš„æ€§èƒ½ä¸‹é™ã€‚å¯¹äºå›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ç»†èŠ‚æ¨¡ç³Šä»¥åŠåŒºåŸŸé—´çš„ä¸ä¸€è‡´æ€§ç­‰é—®é¢˜ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè¾›æ°å›¾çš„å°æ³¢éšæœºåˆ†è§£å’Œéšæœºæ©è†œæ‰©æ•£æ¨¡å‹ï¼ˆSWARMï¼‰ï¼Œç”¨äºSVCTé‡å»ºã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨è¾›æ°å›¾ä¸­å¼•å…¥éšæœºæ©è†œç­–ç•¥ï¼Œæœ‰æ•ˆåœ°æ‰©å¤§äº†æœ‰é™çš„è®­ç»ƒæ ·æœ¬ç©ºé—´ã€‚è¿™ä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´å¹¿æ³›çš„æ•°æ®åˆ†å¸ƒï¼Œå¢å¼ºäº†å¯¹æ•°æ®ä¸ç¡®å®šæ€§çš„ç†è§£å’Œæ³›åŒ–ã€‚æ­¤å¤–ï¼Œå¯¹è¾›æ°å›¾å°æ³¢çš„é«˜é¢‘æˆåˆ†åº”ç”¨éšæœºè®­ç»ƒç­–ç•¥ï¼Œå¢å¼ºäº†ç‰¹å¾è¡¨ç¤ºï¼Œæé«˜äº†æ•è·ä¸åŒé¢‘æ®µç»†èŠ‚çš„èƒ½åŠ›ï¼Œä»è€Œæé«˜äº†æ€§èƒ½å’Œç¨³å¥æ€§ã€‚é‡‡ç”¨ä¸¤é˜¶æ®µè¿­ä»£é‡å»ºæ–¹æ³•ï¼Œç¡®ä¿é‡å»ºå›¾åƒçš„æ•´ä½“ä¸€è‡´æ€§ï¼ŒåŒæ—¶ç»†åŒ–å…¶ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSWARMåœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§æ€§èƒ½å‡ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09935v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæ‰©æ•£æ¨¡å‹åœ¨ç¨€ç–è§†è§’è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆSVCTï¼‰é‡å»ºä¸­æ˜¾ç¤ºå‡ºæ˜¾è‘—æ½œåŠ›ï¼Œä½†åœ¨æœ‰é™æ ·æœ¬ç©ºé—´è®­ç»ƒçš„ç½‘ç»œåœ¨é™Œç”Ÿæ•°æ®ä¸Šçš„è¡¨ç°å¯èƒ½ä¼šå—åˆ°é™åˆ¶ã€‚ä¸ºè§£å†³å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ç»†èŠ‚æ¨¡ç³Šå’ŒåŒºåŸŸé—´ä¸ä¸€è‡´ç­‰é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè¾›æ°å›¾å°æ³¢éšæœºåˆ†è§£å’Œéšæœºæ©è†œæ‰©æ•£æ¨¡å‹ï¼ˆSWARMï¼‰çš„SVCTé‡å»ºæ–¹æ³•ã€‚é€šè¿‡è¾›æ°å›¾ä¸­å¼•å…¥éšæœºæ©è†œç­–ç•¥æœ‰æ•ˆæ‰©å±•äº†æœ‰é™çš„è®­ç»ƒæ ·æœ¬ç©ºé—´ï¼Œæé«˜äº†æ¨¡å‹å¯¹æ•°æ®ä¸ç¡®å®šæ€§çš„ç†è§£å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå¯¹è¾›æ°å›¾å°æ³¢é«˜é¢‘æˆåˆ†é‡‡ç”¨éšæœºè®­ç»ƒç­–ç•¥ï¼Œå¢å¼ºäº†ç‰¹å¾è¡¨ç¤ºå’Œæ•æ‰ä¸åŒé¢‘æ®µç»†èŠ‚çš„èƒ½åŠ›ï¼Œæé«˜äº†æ€§èƒ½å’Œé²æ£’æ€§ã€‚é‡‡ç”¨ä¸¤é˜¶æ®µè¿­ä»£é‡å»ºæ–¹æ³•ï¼Œç¡®ä¿é‡å»ºå›¾åƒçš„æ•´ä½“ä¸€è‡´æ€§å¹¶ä¼˜åŒ–ç»†èŠ‚ã€‚å®éªŒç»“æœè¯æ˜SWARMåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®šé‡å’Œå®šæ€§æ€§èƒ½å‡ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨SVCTé‡å»ºä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚</li>
<li>åœ¨æœ‰é™æ ·æœ¬ç©ºé—´è®­ç»ƒçš„ç½‘ç»œå¯èƒ½é™åˆ¶äº†å…¶åœ¨é™Œç”Ÿæ•°æ®ä¸Šçš„è¡¨ç°ã€‚</li>
<li>SWARMæ¨¡å‹é€šè¿‡å¼•å…¥éšæœºæ©è†œç­–ç•¥æ‰©å±•äº†è®­ç»ƒæ ·æœ¬ç©ºé—´ã€‚</li>
<li>éšæœºè®­ç»ƒç­–ç•¥æé«˜äº†æ¨¡å‹å¯¹æ•°æ®ä¸ç¡®å®šæ€§çš„ç†è§£å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¯¹è¾›æ°å›¾å°æ³¢é«˜é¢‘æˆåˆ†é‡‡ç”¨éšæœºè®­ç»ƒç­–ç•¥ï¼Œå¢å¼ºäº†ç‰¹å¾è¡¨ç¤ºå’Œæ•æ‰ç»†èŠ‚çš„èƒ½åŠ›ã€‚</li>
<li>é‡‡ç”¨ä¸¤é˜¶æ®µè¿­ä»£é‡å»ºæ–¹æ³•ç¡®ä¿å›¾åƒå…¨å±€ä¸€è‡´æ€§å¹¶ä¼˜åŒ–ç»†èŠ‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09935">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-20e5a97bfa79dc52917b15637a7639bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-da058ff37c45bb0744f02c5a73c46f2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49326a45f585853ac31768aae7ba2fa2.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CrossModalityDiffusion-Multi-Modal-Novel-View-Synthesis-with-Unified-Intermediate-Representation"><a href="#CrossModalityDiffusion-Multi-Modal-Novel-View-Synthesis-with-Unified-Intermediate-Representation" class="headerlink" title="CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified   Intermediate Representation"></a>CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified   Intermediate Representation</h2><p><strong>Authors:Alex Berian, Daniel Brignac, JhihYang Wu, Natnael Daba, Abhijit Mahalanobis</strong></p>
<p>Geospatial imaging leverages data from diverse sensing modalities-such as EO, SAR, and LiDAR, ranging from ground-level drones to satellite views. These heterogeneous inputs offer significant opportunities for scene understanding but present challenges in interpreting geometry accurately, particularly in the absence of precise ground truth data. To address this, we propose CrossModalityDiffusion, a modular framework designed to generate images across different modalities and viewpoints without prior knowledge of scene geometry. CrossModalityDiffusion employs modality-specific encoders that take multiple input images and produce geometry-aware feature volumes that encode scene structure relative to their input camera positions. The space where the feature volumes are placed acts as a common ground for unifying input modalities. These feature volumes are overlapped and rendered into feature images from novel perspectives using volumetric rendering techniques. The rendered feature images are used as conditioning inputs for a modality-specific diffusion model, enabling the synthesis of novel images for the desired output modality. In this paper, we show that jointly training different modules ensures consistent geometric understanding across all modalities within the framework. We validate CrossModalityDiffusionâ€™s capabilities on the synthetic ShapeNet cars dataset, demonstrating its effectiveness in generating accurate and consistent novel views across multiple imaging modalities and perspectives. </p>
<blockquote>
<p>åœ°ç†ç©ºé—´æˆåƒåˆ©ç”¨æ¥è‡ªä¸åŒæ„ŸçŸ¥æ¨¡å¼çš„æ•°æ®ï¼Œå¦‚EOã€SARå’ŒLiDARï¼Œä»åœ°é¢æ— äººæœºåˆ°å«æ˜Ÿè§†å›¾çš„å„ç§æ•°æ®ã€‚è¿™äº›å¼‚æ„è¾“å…¥ä¸ºåœºæ™¯ç†è§£æä¾›äº†é‡å¤§æœºä¼šï¼Œä½†åœ¨æ²¡æœ‰ç²¾ç¡®åœ°é¢çœŸå®æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¯¹å‡ ä½•çš„å‡†ç¡®è§£é‡Šå´å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†CrossModalityDiffusionï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨åœ¨ä¸åŒæ¨¡æ€å’Œè§†è§’ç”Ÿæˆå›¾åƒï¼Œè€Œæ— éœ€äº‹å…ˆäº†è§£åœºæ™¯å‡ ä½•ã€‚CrossModalityDiffusioné‡‡ç”¨ç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨ï¼Œè¿™äº›ç¼–ç å™¨æ¥å—å¤šä¸ªè¾“å…¥å›¾åƒå¹¶äº§ç”Ÿæ„ŸçŸ¥å‡ ä½•ç‰¹å¾çš„ä½“ç§¯ï¼Œè¿™äº›ä½“ç§¯ç¼–ç äº†ç›¸å¯¹äºå…¶è¾“å…¥ç›¸æœºä½ç½®çš„åœºæ™¯ç»“æ„ã€‚ç‰¹å¾ä½“ç§¯æ‰€å¤„çš„ç©ºé—´æˆä¸ºç»Ÿä¸€è¾“å…¥æ¨¡æ€çš„å…±åŒåŸºç¡€ã€‚è¿™äº›ç‰¹å¾ä½“ç§¯è¢«é‡å å¹¶ä½¿ç”¨ä½“ç§¯æ¸²æŸ“æŠ€æœ¯ä»æ–°çš„è§†è§’æ¸²æŸ“æˆç‰¹å¾å›¾åƒã€‚æ¸²æŸ“çš„ç‰¹å¾å›¾åƒç”¨ä½œç‰¹å®šæ¨¡æ€æ‰©æ•£æ¨¡å‹çš„è°ƒèŠ‚è¾“å…¥ï¼Œä»è€Œåˆæˆæ‰€éœ€è¾“å‡ºæ¨¡æ€çš„æ–°å›¾åƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è”åˆè®­ç»ƒä¸åŒçš„æ¨¡å—å¯ä»¥ç¡®ä¿æ¡†æ¶å†…æ‰€æœ‰æ¨¡æ€çš„å‡ ä½•ç†è§£çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬åœ¨åˆæˆçš„ShapeNetæ±½è½¦æ•°æ®é›†ä¸ŠéªŒè¯äº†CrossModalityDiffusionçš„èƒ½åŠ›ï¼Œè¯æ˜äº†å®ƒåœ¨ç”Ÿæˆå¤šä¸ªæˆåƒæ¨¡æ€å’Œè§†è§’çš„æ–°é¢–ä¸”å‡†ç¡®çš„è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09838v1">PDF</a> Accepted in the 2025 WACV workshop GeoCV</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè·¨æ¨¡æ€æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼ˆCrossModalityDiffusionï¼‰ï¼Œè¯¥æ¡†æ¶å¯åœ¨ä¸åŒæ¨¡æ€å’Œè§†è§’ç”Ÿæˆå›¾åƒï¼Œæ— éœ€å¯¹åœºæ™¯å‡ ä½•çš„å…ˆéªŒçŸ¥è¯†ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ¨¡æ€ç‰¹å®šç¼–ç å™¨å¤„ç†å¤šç§è¾“å…¥å›¾åƒï¼Œç”ŸæˆåŒ…å«åœºæ™¯ç»“æ„çš„ç‰¹å¾ä½“ç§¯ï¼Œå¹¶é€šè¿‡ä½“ç§¯æ¸²æŸ“æŠ€æœ¯ä»æ–°é¢–è§†è§’å‘ˆç°ç‰¹å¾å›¾åƒã€‚è¿™äº›ç‰¹å¾å›¾åƒä¸ºç‰¹å®šæ¨¡æ€çš„æ‰©æ•£æ¨¡å‹æä¾›æ¡ä»¶è¾“å…¥ï¼Œä»è€Œåˆæˆç›®æ ‡æ¨¡æ€çš„æ–°é¢–å›¾åƒã€‚æœ¬æ–‡éªŒè¯äº†åœ¨ä¸åŒæ¨¡å—è”åˆè®­ç»ƒä¸‹ï¼Œè¯¥æ¡†æ¶åœ¨å¤šæ¨¡æ€å’Œé€è§†åœºæ™¯ä¸­çš„å‡ ä½•ä¸€è‡´æ€§ç†è§£èƒ½åŠ›ã€‚åœ¨ShapeNetæ±½è½¦æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½ç”Ÿæˆå‡†ç¡®ä¸”ä¸€è‡´çš„æ–°è§†è§’è·¨æ¨¡æ€å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Geospatialæˆåƒåˆ©ç”¨å¤šç§ä¼ æ„Ÿå™¨æ¨¡æ€çš„æ•°æ®ï¼Œå¦‚EOã€SARå’ŒLiDARï¼Œä»åœ°é¢æ— äººæœºåˆ°å«æ˜Ÿè§†å›¾ä¸ç­‰ã€‚</li>
<li>è·¨æ¨¡æ€æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼ˆCrossModalityDiffusionï¼‰è®¾è®¡ç”¨äºä¸åŒæ¨¡æ€å’Œè§†è§’ç”Ÿæˆå›¾åƒï¼Œæ— éœ€å¯¹åœºæ™¯å‡ ä½•å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>CrossModalityDiffusioné‡‡ç”¨æ¨¡æ€ç‰¹å®šç¼–ç å™¨ç”ŸæˆåŒ…å«åœºæ™¯ç»“æ„çš„ç‰¹å¾ä½“ç§¯ï¼Œå¹¶å°†å®ƒä»¬æ”¾ç½®åœ¨ç»Ÿä¸€çš„ç©ºé—´ä¸­ä»¥èåˆä¸åŒæ¨¡æ€ã€‚</li>
<li>é€šè¿‡ä½“ç§¯æ¸²æŸ“æŠ€æœ¯ä»æ–°é¢–è§†è§’å‘ˆç°ç‰¹å¾å›¾åƒã€‚</li>
<li>ç‰¹å¾å›¾åƒä¸ºç‰¹å®šæ¨¡æ€çš„æ‰©æ•£æ¨¡å‹æä¾›æ¡ä»¶è¾“å…¥ï¼Œåˆæˆç›®æ ‡æ¨¡æ€çš„æ–°é¢–å›¾åƒã€‚</li>
<li>è”åˆè®­ç»ƒä¸åŒæ¨¡å—ç¡®ä¿äº†è·¨æ‰€æœ‰æ¨¡æ€çš„å‡ ä½•ä¸€è‡´æ€§ç†è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09838">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dab66cc4fcc22dedac17aa202d374f51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa4bb217507f8e09611f3864152a2a51.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6f602960b503c4f95a8f4391b18af317.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d47d370da81fc5d59eb6287cb1e5cccb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6a9921106fe7a2e939f4fd8f02bc27c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Lossy-Compression-with-Pretrained-Diffusion-Models"><a href="#Lossy-Compression-with-Pretrained-Diffusion-Models" class="headerlink" title="Lossy Compression with Pretrained Diffusion Models"></a>Lossy Compression with Pretrained Diffusion Models</h2><p><strong>Authors:Jeremy Vonderfecht, Feng Liu</strong></p>
<p>We apply the DiffC algorithm (Theis et al. 2022) to Stable Diffusion 1.5, 2.1, XL, and Flux-dev, and demonstrate that these pretrained models are remarkably capable lossy image compressors. A principled algorithm for lossy compression using pretrained diffusion models has been understood since at least Ho et al. 2020, but challenges in reverse-channel coding have prevented such algorithms from ever being fully implemented. We introduce simple workarounds that lead to the first complete implementation of DiffC, which is capable of compressing and decompressing images using Stable Diffusion in under 10 seconds. Despite requiring no additional training, our method is competitive with other state-of-the-art generative compression methods at low ultra-low bitrates. </p>
<blockquote>
<p>æˆ‘ä»¬å°†DiffCç®—æ³•ï¼ˆTheisç­‰äººï¼Œ2022å¹´ï¼‰åº”ç”¨äºStable Diffusion 1.5ã€2.1ã€XLå’ŒFlux-devï¼Œå¹¶è¯æ˜è¿™äº›é¢„è®­ç»ƒæ¨¡å‹æ˜¯å‡ºè‰²çš„æœ‰æŸå›¾åƒå‹ç¼©å™¨ã€‚è‡³å°‘è‡ªHoç­‰äººï¼ˆ2020å¹´ï¼‰ä»¥æ¥ï¼Œå·²ç»äº†è§£ä½¿ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œæœ‰æŸå‹ç¼©çš„åŸç†ç®—æ³•ï¼Œä½†åå‘ä¿¡é“ç¼–ç çš„æŒ‘æˆ˜ä½¿å¾—æ­¤ç±»ç®—æ³•ä»æœªå¾—åˆ°å…¨é¢å®æ–½ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸€äº›ç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œé¦–æ¬¡å®ç°äº†å®Œæ•´çš„DiffCå®ç°ï¼Œèƒ½å¤Ÿåœ¨ä¸åˆ°10ç§’å†…ä½¿ç”¨Stable Diffusionå¯¹å›¾åƒè¿›è¡Œå‹ç¼©å’Œè§£å‹ç¼©ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒï¼Œåœ¨ä½è¶…ä½æ¯”ç‰¹ç‡ä¸‹ä¸å…¶ä»–æœ€å…ˆè¿›çš„ç”Ÿæˆå‹ç¼©æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09815v1">PDF</a> </p>
<p><strong>Summary</strong><br>     å°†DiffCç®—æ³•åº”ç”¨äºStable Diffusion 1.5ã€2.1ã€XLå’ŒFlux-devç­‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯æ˜è¿™äº›æ¨¡å‹å…·æœ‰å‡ºè‰²çš„æœ‰æŸå›¾åƒå‹ç¼©èƒ½åŠ›ã€‚è™½ç„¶æ—©åœ¨Hoç­‰äººåœ¨2020å¹´å°±å·²ç»äº†è§£äº†åˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œæœ‰æŸå‹ç¼©çš„åŸç†ï¼Œä½†ç”±äºåå‘ä¿¡é“ç¼–ç çš„æŒ‘æˆ˜ï¼Œç›¸å…³ç®—æ³•ä¸€ç›´æ²¡æœ‰å®Œå…¨å®ç°ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ç®€å•å¯¹ç­–ï¼Œé¦–æ¬¡å®Œæˆäº†DiffCçš„å®Œæ•´å®ç°ï¼Œèƒ½åœ¨ä¸åˆ°10ç§’å†…ä½¿ç”¨Stable Diffusionå¯¹å›¾åƒè¿›è¡Œå‹ç¼©å’Œè§£å‹ç¼©ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œåœ¨ä½è¶…ä½æ¯”ç‰¹ç‡ä¸‹ä¸å…¶ä»–å…ˆè¿›çš„ç”Ÿæˆå‹ç¼©æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DiffCç®—æ³•æˆåŠŸåº”ç”¨äºå¤šç§é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬Stable Diffusion 1.5ã€2.1ã€XLå’ŒFlux-devï¼Œå±•ç¤ºå‡ºè‰²çš„æœ‰æŸå›¾åƒå‹ç¼©èƒ½åŠ›ã€‚</li>
<li>å°½ç®¡è‡ªHoç­‰äººåœ¨2020å¹´æå‡ºåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œæœ‰æŸå‹ç¼©çš„åŸç†ä»¥æ¥ï¼Œç›¸å…³ç®—æ³•ä¸€ç›´é¢ä¸´åå‘ä¿¡é“ç¼–ç çš„æŒ‘æˆ˜ï¼Œä½†ç ”ç©¶å›¢é˜ŸæˆåŠŸè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿé¦–æ¬¡å®ç°äº†DiffCçš„å®Œæ•´ç‰ˆæœ¬ï¼Œèƒ½å¤Ÿåœ¨çŸ­æ—¶é—´å†…ï¼ˆä¸åˆ°10ç§’ï¼‰å®Œæˆå›¾åƒçš„å‹ç¼©å’Œè§£å‹ç¼©è¿‡ç¨‹ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€å¯¹æ¨¡å‹è¿›è¡Œé¢å¤–è®­ç»ƒï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚</li>
<li>ä¸å…¶ä»–å…ˆè¿›çš„ç”Ÿæˆå‹ç¼©æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨è¶…ä½æ¯”ç‰¹ç‡ä¸‹è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</li>
<li>è¿™ä¸€è¿›å±•ä¸ºåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒå‹ç¼©æä¾›äº†æ–°çš„å¯èƒ½æ€§å’Œå®é™…åº”ç”¨åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09815">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e6e73f06ece4fda86ec3ee710f26f531.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ddf9add97d5adc85c6974954ac0ac396.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1930235d1ff3d7e595968f5872637829.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4a76203b00b637804cee47e1d7fa42a3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="NeurOp-Diff-Continuous-Remote-Sensing-Image-Super-Resolution-via-Neural-Operator-Diffusion"><a href="#NeurOp-Diff-Continuous-Remote-Sensing-Image-Super-Resolution-via-Neural-Operator-Diffusion" class="headerlink" title="NeurOp-Diff:Continuous Remote Sensing Image Super-Resolution via Neural   Operator Diffusion"></a>NeurOp-Diff:Continuous Remote Sensing Image Super-Resolution via Neural   Operator Diffusion</h2><p><strong>Authors:Zihao Xu, Yuzhi Tang, Bowen Xu, Qingquan Li</strong></p>
<p>Most publicly accessible remote sensing data suffer from low resolution, limiting their practical applications. To address this, we propose a diffusion model guided by neural operators for continuous remote sensing image super-resolution (NeurOp-Diff). Neural operators are used to learn resolution representations at arbitrary scales, encoding low-resolution (LR) images into high-dimensional features, which are then used as prior conditions to guide the diffusion model for denoising. This effectively addresses the artifacts and excessive smoothing issues present in existing super-resolution (SR) methods, enabling the generation of high-quality, continuous super-resolution images. Specifically, we adjust the super-resolution scale by a scaling factor s, allowing the model to adapt to different super-resolution magnifications. Furthermore, experiments on multiple datasets demonstrate the effectiveness of NeurOp-Diff. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/zerono000/NeurOp-Diff">https://github.com/zerono000/NeurOp-Diff</a>. </p>
<blockquote>
<p>å¤§éƒ¨åˆ†å…¬å¼€å¯è®¿é—®çš„é¥æ„Ÿæ•°æ®å­˜åœ¨åˆ†è¾¨ç‡ä½çš„é—®é¢˜ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±ç¥ç»ç®—å­å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºè¿ç»­é¥æ„Ÿå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆNeurOp-Diffï¼‰ã€‚ç¥ç»ç®—å­ç”¨äºå­¦ä¹ ä»»æ„å°ºåº¦çš„åˆ†è¾¨ç‡è¡¨ç¤ºï¼Œå°†ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒç¼–ç ä¸ºé«˜ç»´ç‰¹å¾ï¼Œç„¶åå°†å…¶ä½œä¸ºå…ˆéªŒæ¡ä»¶ï¼Œå¼•å¯¼æ‰©æ•£æ¨¡å‹è¿›è¡Œå»å™ªã€‚è¿™æœ‰æ•ˆåœ°è§£å†³äº†ç°æœ‰è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æ–¹æ³•ä¸­å‡ºç°çš„ä¼ªå½±å’Œè¿‡åº¦å¹³æ»‘é—®é¢˜ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€è¿ç»­çš„è¶…é«˜åˆ†è¾¨ç‡å›¾åƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡ç¼©æ”¾å› å­sè°ƒæ•´è¶…åˆ†è¾¨ç‡å°ºåº¦ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä¸åŒçš„è¶…åˆ†è¾¨ç‡æ”¾å¤§å€æ•°ã€‚æ­¤å¤–ï¼Œå¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†NeurOp-Diffçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zerono000/NeurOp-Diff%E4%B8%8A%E8%8E%B7%E3%80%82">https://github.com/zerono000/NeurOp-Diffä¸Šè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09054v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é’ˆå¯¹ç°æœ‰é¥æ„Ÿæ•°æ®åˆ†è¾¨ç‡ä½çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç®—å­å’Œæ‰©æ•£æ¨¡å‹çš„è¿ç»­é¥æ„Ÿå›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼ˆNeurOp-Diffï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç¥ç»ç®—å­å­¦ä¹ ä»»æ„å°ºåº¦çš„åˆ†è¾¨ç‡è¡¨ç¤ºï¼Œå°†ä½åˆ†è¾¨ç‡å›¾åƒç¼–ç ä¸ºé«˜ç»´ç‰¹å¾ï¼Œå¹¶ä½œä¸ºå…ˆéªŒæ¡ä»¶å¼•å¯¼æ‰©æ•£æ¨¡å‹è¿›è¡Œå»å™ªã€‚è¿™è§£å†³äº†ç°æœ‰è¶…åˆ†è¾¨ç‡æ–¹æ³•ä¸­çš„ä¼ªå½±å’Œè¿‡åº¦å¹³æ»‘é—®é¢˜ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€è¿ç»­çš„è¶…çº§åˆ†è¾¨ç‡å›¾åƒã€‚é€šè¿‡è°ƒæ•´è¶…åˆ†è¾¨ç‡å°ºåº¦ç¼©æ”¾å› å­sï¼Œè¯¥æ¨¡å‹å¯é€‚åº”ä¸åŒçš„è¶…åˆ†è¾¨ç‡æ”¾å¤§å€æ•°ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†NeurOp-Diffçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç®—å­å’Œæ‰©æ•£æ¨¡å‹çš„é¥æ„Ÿå›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•NeurOp-Diffã€‚</li>
<li>ç¥ç»ç®—å­ç”¨äºå­¦ä¹ ä»»æ„å°ºåº¦çš„åˆ†è¾¨ç‡è¡¨ç¤ºï¼Œå¹¶å°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬åŒ–ä¸ºé«˜ç»´ç‰¹å¾ã€‚</li>
<li>é«˜ç»´ç‰¹å¾ä½œä¸ºå…ˆéªŒæ¡ä»¶å¼•å¯¼æ‰©æ•£æ¨¡å‹è¿›è¡Œå»å™ªï¼Œè§£å†³äº†ä¼ªå½±å’Œè¿‡åº¦å¹³æ»‘é—®é¢˜ã€‚</li>
<li>é€šè¿‡è°ƒæ•´ç¼©æ”¾å› å­sï¼Œæ¨¡å‹å¯é€‚åº”ä¸åŒçš„è¶…åˆ†è¾¨ç‡æ”¾å¤§éœ€æ±‚ã€‚</li>
<li>NeurOp-Diffåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ¨¡å‹çš„ä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¿ç»­è¶…çº§åˆ†è¾¨ç‡å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09054">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-833ba1113001237d1e27042dedece5b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-adf8859f49f6285166d1153044e49051.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-640889ab9d48cde97890705c2044351c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DPCL-Diff-The-Temporal-Knowledge-Graph-Reasoning-Based-on-Graph-Node-Diffusion-Model-with-Dual-Domain-Periodic-Contrastive-Learning"><a href="#DPCL-Diff-The-Temporal-Knowledge-Graph-Reasoning-Based-on-Graph-Node-Diffusion-Model-with-Dual-Domain-Periodic-Contrastive-Learning" class="headerlink" title="DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node   Diffusion Model with Dual-Domain Periodic Contrastive Learning"></a>DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node   Diffusion Model with Dual-Domain Periodic Contrastive Learning</h2><p><strong>Authors:Yukun Cao, Lisheng Wang, Luobin Huang</strong></p>
<p>Temporal knowledge graph (TKG) reasoning that infers future missing facts is an essential and challenging task. Predicting future events typically relies on closely related historical facts, yielding more accurate results for repetitive or periodic events. However, for future events with sparse historical interactions, the effectiveness of this method, which focuses on leveraging high-frequency historical information, diminishes. Recently, the capabilities of diffusion models in image generation have opened new opportunities for TKG reasoning. Therefore, we propose a graph node diffusion model with dual-domain periodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff) introduces noise into sparsely related events to simulate new events, generating high-quality data that better conforms to the actual distribution. This generative mechanism significantly enhances the modelâ€™s ability to reason about new events. Additionally, the dual-domain periodic contrastive learning (DPCL) maps periodic and non-periodic event entities to Poincar&#39;e and Euclidean spaces, leveraging their characteristics to distinguish similar periodic events effectively. Experimental results on four public datasets demonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG models in event prediction, demonstrating our approachâ€™s effectiveness. This study also investigates the combined effectiveness of GNDiff and DPCL in TKG tasks. </p>
<blockquote>
<p>æ—¶åºçŸ¥è¯†å›¾è°±ï¼ˆTKGï¼‰æ¨ç†ï¼Œæ¨æ–­æœªæ¥ç¼ºå¤±çš„äº‹å®ï¼Œæ˜¯ä¸€é¡¹é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚é¢„æµ‹æœªæ¥äº‹ä»¶é€šå¸¸ä¾èµ–äºå¯†åˆ‡ç›¸å…³çš„å†å²äº‹å®ï¼Œå¯¹äºé‡å¤æ€§æˆ–å‘¨æœŸæ€§äº‹ä»¶ï¼Œèƒ½å¸¦æ¥æ›´å‡†ç¡®çš„ç»“æœã€‚ç„¶è€Œï¼Œå¯¹äºå†å²äº¤äº’ç¨€ç–çš„æœªæ¥äº‹ä»¶ï¼Œè¿™ç§æ–¹æ³•çš„æœ‰æ•ˆæ€§ä¼šé™ä½ï¼Œå› ä¸ºå®ƒä¸»è¦ä¾§é‡äºåˆ©ç”¨é«˜é¢‘å†å²ä¿¡æ¯ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›ä¸ºTKGæ¨ç†æä¾›äº†æ–°çš„æœºä¼šã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å…·æœ‰åŒåŸŸå‘¨æœŸæ€§å¯¹æ¯”å­¦ä¹ ï¼ˆDPCLï¼‰çš„å›¾èŠ‚ç‚¹æ‰©æ•£æ¨¡å‹ï¼ˆDPCL-Diffï¼‰ã€‚å›¾èŠ‚ç‚¹æ‰©æ•£æ¨¡å‹ï¼ˆGNDiffï¼‰å°†å™ªå£°å¼•å…¥ç¨€ç–ç›¸å…³çš„äº‹ä»¶ä¸­ï¼Œä»¥æ¨¡æ‹Ÿæ–°äº‹ä»¶ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æ•°æ®ï¼Œæ›´å¥½åœ°ç¬¦åˆå®é™…åˆ†å¸ƒã€‚è¿™ç§ç”Ÿæˆæœºåˆ¶æ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹æ–°äº‹ä»¶çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒåŒåŸŸå‘¨æœŸæ€§å¯¹æ¯”å­¦ä¹ ï¼ˆDPCLï¼‰å°†å‘¨æœŸæ€§å’Œéå‘¨æœŸæ€§äº‹ä»¶å®ä½“æ˜ å°„åˆ°PoincarÃ©å’Œæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼Œåˆ©ç”¨å…¶ç‰¹æ€§æ¥æœ‰æ•ˆåœ°åŒºåˆ†ç›¸ä¼¼çš„å‘¨æœŸæ€§äº‹ä»¶ã€‚åœ¨å››ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDPCL-Diffåœ¨äº‹ä»¶é¢„æµ‹æ–¹é¢æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„TKGæ¨¡å‹ï¼Œè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æœ¬ç ”ç©¶è¿˜æ¢è®¨äº†GNDiffå’ŒDPCLåœ¨TKGä»»åŠ¡ä¸­çš„ç»„åˆæ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.01477v2">PDF</a> 11 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ—¶åºçŸ¥è¯†å›¾è°±ï¼ˆTKGï¼‰æ¨ç†é¢„æµ‹æœªæ¥ç¼ºå¤±äº‹å®æ˜¯ä¸€é¡¹é‡è¦ä¸”å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å†å²äº‹å®è¿›è¡Œæœªæ¥äº‹ä»¶é¢„æµ‹ï¼Œå¯¹äºé‡å¤æˆ–å‘¨æœŸæ€§äº‹ä»¶æ•ˆæœè¾ƒå¥½ï¼Œä½†å¯¹äºå†å²äº¤äº’ç¨€ç–çš„æœªæ¥äº‹ä»¶åˆ™è¡¨ç°ä¸è¶³ã€‚æœ¬æ–‡æå‡ºäº†ç»“åˆå›¾èŠ‚ç‚¹æ‰©æ•£æ¨¡å‹å’ŒåŒåŸŸå‘¨æœŸæ€§å¯¹æ¯”å­¦ä¹ ï¼ˆDPCL-Diffï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥å™ªå£°æ¨¡æ‹Ÿæ–°äº‹ä»¶ï¼Œæé«˜æ¨¡å‹å¯¹æ–°äº‹ä»¶çš„æ¨ç†èƒ½åŠ›ã€‚åŒæ—¶ï¼ŒDPCLå°†å‘¨æœŸæ€§å’Œéå‘¨æœŸæ€§äº‹ä»¶å®ä½“æ˜ å°„åˆ°ä¸åŒçš„ç©ºé—´ï¼Œä»¥åŒºåˆ†ç›¸ä¼¼çš„å‘¨æœŸæ€§äº‹ä»¶ã€‚åœ¨å››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDPCL-Diffåœ¨äº‹ä»¶é¢„æµ‹æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰TKGæ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ—¶åºçŸ¥è¯†å›¾è°±ï¼ˆTKGï¼‰æ¨ç†é¢„æµ‹æœªæ¥ç¼ºå¤±äº‹å®å¾ˆé‡è¦ä¸”å…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å†å²äº‹å®è¿›è¡Œé¢„æµ‹ï¼Œå¯¹ç¨€ç–å†å²äº¤äº’çš„æœªæ¥äº‹ä»¶æ•ˆæœæœ‰é™ã€‚</li>
<li>æå‡ºçš„å›¾èŠ‚ç‚¹æ‰©æ•£æ¨¡å‹ï¼ˆGNDiffï¼‰é€šè¿‡å¼•å…¥å™ªå£°æ¨¡æ‹Ÿæ–°äº‹ä»¶ï¼Œæé«˜æ¨¡å‹å¯¹æ–°äº‹ä»¶çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>åŒåŸŸå‘¨æœŸæ€§å¯¹æ¯”å­¦ä¹ ï¼ˆDPCLï¼‰èƒ½æœ‰æ•ˆåŒºåˆ†å‘¨æœŸæ€§äº‹ä»¶å’Œéå‘¨æœŸæ€§äº‹ä»¶å®ä½“ã€‚</li>
<li>DPCL-Diffæ–¹æ³•ç»“åˆäº†GNDiffå’ŒDPCLï¼Œæ˜¾è‘—æé«˜äº†åœ¨å››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„äº‹ä»¶é¢„æµ‹æ€§èƒ½ã€‚</li>
<li>GNDiffå’ŒDPCLçš„è”åˆæ•ˆæœåœ¨TKGä»»åŠ¡ä¸­å¾—åˆ°äº†è°ƒæŸ¥éªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.01477">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8b96902c8bbb7e73d5a199b2d3e51fc8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3545eb03cdcd5a2171d88b744e71688f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d04e77e60f4898d5b3edde8c967d2819.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-71265a8141a1db97fec5668fc7ce0269.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42aa5ab06b72e19369f0097a2be98afe.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DX2CT-Diffusion-Model-for-3D-CT-Reconstruction-from-Bi-or-Mono-planar-2D-X-ray-s"><a href="#DX2CT-Diffusion-Model-for-3D-CT-Reconstruction-from-Bi-or-Mono-planar-2D-X-ray-s" class="headerlink" title="DX2CT: Diffusion Model for 3D CT Reconstruction from Bi or Mono-planar   2D X-ray(s)"></a>DX2CT: Diffusion Model for 3D CT Reconstruction from Bi or Mono-planar   2D X-ray(s)</h2><p><strong>Authors:Yun Su Jeong, Hye Bin Yoo, Il Yong Chun</strong></p>
<p>Computational tomography (CT) provides high-resolution medical imaging, but it can expose patients to high radiation. X-ray scanners have low radiation exposure, but their resolutions are low. This paper proposes a new conditional diffusion model, DX2CT, that reconstructs three-dimensional (3D) CT volumes from bi or mono-planar X-ray image(s). Proposed DX2CT consists of two key components: 1) modulating feature maps extracted from two-dimensional (2D) X-ray(s) with 3D positions of CT volume using a new transformer and 2) effectively using the modulated 3D position-aware feature maps as conditions of DX2CT. In particular, the proposed transformer can provide conditions with rich information of a target CT slice to the conditional diffusion model, enabling high-quality CT reconstruction. Our experiments with the bi or mono-planar X-ray(s) benchmark datasets show that proposed DX2CT outperforms several state-of-the-art methods. Our codes and model will be available at: <a target="_blank" rel="noopener" href="https://www.github.com/intyeger/DX2CT">https://www.github.com/intyeger/DX2CT</a>. </p>
<blockquote>
<p>è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰æä¾›é«˜åˆ†è¾¨ç‡åŒ»å­¦æˆåƒï¼Œä½†å®ƒä¼šä½¿æ‚£è€…æš´éœ²åœ¨è¾ƒé«˜çš„è¾å°„ä¹‹ä¸‹ã€‚Xå°„çº¿æ‰«æä»ªçš„è¾å°„æš´éœ²è¾ƒä½ï¼Œä½†å…¶åˆ†è¾¨ç‡ä¹Ÿè¾ƒä½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹DX2CTï¼Œèƒ½å¤Ÿä»åŒå¹³é¢æˆ–å•å¹³é¢Xå°„çº¿å›¾åƒé‡å»ºä¸‰ç»´ï¼ˆ3Dï¼‰CTä½“ç§¯ã€‚æå‡ºçš„DX2CTç”±ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ç»„æˆï¼š1ï¼‰ä½¿ç”¨æ–°å˜å‹å™¨å°†äºŒç»´ï¼ˆ2Dï¼‰Xå°„çº¿ç‰¹å¾å›¾ä¸CTä½“ç§¯çš„ä¸‰ç»´ä½ç½®è¿›è¡Œè°ƒåˆ¶ï¼Œä»¥åŠ2ï¼‰æœ‰æ•ˆåœ°åˆ©ç”¨è°ƒåˆ¶åçš„ä¸‰ç»´ä½ç½®æ„ŸçŸ¥ç‰¹å¾å›¾ä½œä¸ºDX2CTçš„æ¡ä»¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæ‰€æå‡ºçš„å˜å‹å™¨å¯ä»¥ä¸ºæ¡ä»¶æ‰©æ•£æ¨¡å‹æä¾›ç›®æ ‡CTåˆ‡ç‰‡çš„ä¸°å¯Œä¿¡æ¯ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„CTé‡å»ºã€‚æˆ‘ä»¬åœ¨åŒå¹³é¢æˆ–å•å¹³é¢Xå°„çº¿åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„DX2CTä¼˜äºå‡ ç§æœ€æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://www.github.com/intyeger/DX2CT">https://www.github.com/intyeger/DX2CT</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08850v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹DX2CTï¼Œå¯ä»äºŒç»´X-rayå›¾åƒé‡å»ºå‡ºä¸‰ç»´CTä½“ç§¯ã€‚è¯¥æ¨¡å‹ç”±ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ç»„æˆï¼šä¸€æ˜¯ä½¿ç”¨æ–°å˜å‹å™¨è°ƒåˆ¶æ¥è‡ªäºŒç»´X-rayçš„ç‰¹å¾å›¾ï¼Œå¹¶ç»“åˆCTä½“ç§¯çš„ä¸‰ç»´ä½ç½®ï¼›äºŒæ˜¯æœ‰æ•ˆåœ°åˆ©ç”¨è°ƒåˆ¶åçš„ä¸‰ç»´ä½ç½®æ„ŸçŸ¥ç‰¹å¾å›¾ä½œä¸ºDX2CTçš„æ¡ä»¶ã€‚å®éªŒè¡¨æ˜ï¼ŒDX2CTåœ¨äºŒç»´X-rayåŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ¡ä»¶æ‰©æ•£æ¨¡å‹DX2CTï¼Œå¯ä»äºŒç»´X-rayå›¾åƒé‡å»ºå‡ºé«˜è´¨é‡çš„ä¸‰ç»´CTä½“ç§¯ã€‚</li>
<li>DX2CTåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šè°ƒåˆ¶ç‰¹å¾å›¾çš„å˜å‹å™¨å’Œç”¨äºæ¡ä»¶æ‰©æ•£æ¨¡å‹çš„ä¸‰ç»´ä½ç½®æ„ŸçŸ¥ç‰¹å¾å›¾ã€‚</li>
<li>å˜å‹å™¨èƒ½å¤Ÿä»äºŒç»´X-rayå›¾åƒä¸­æå–ç‰¹å¾å›¾ï¼Œå¹¶ç»“åˆCTä½“ç§¯çš„ä¸‰ç»´ä½ç½®è¿›è¡Œè°ƒåˆ¶ã€‚</li>
<li>è°ƒåˆ¶åçš„ä¸‰ç»´ä½ç½®æ„ŸçŸ¥ç‰¹å¾å›¾è¢«ç”¨ä½œDX2CTçš„æ¡ä»¶ï¼Œä»¥æé«˜é‡å»ºè´¨é‡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDX2CTåœ¨äºŒç»´X-rayå›¾åƒåŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ¨¡å‹çš„ä»£ç å’Œå°†å…¬å¼€åœ¨GitHubä¸Šä¾›å…¬ä¼—ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08850">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-12f602f173596666d0068e8a2c61d1e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbe0ac2a77fab04a7719910d8d7a5373.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec517e7397fa2ae0fd334c3b9a5c4a32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7469f87dce8054a4d1291573224c7ef4.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Isolated-Diffusion-Optimizing-Multi-Concept-Text-to-Image-Generation-Training-Freely-with-Isolated-Diffusion-Guidance"><a href="#Isolated-Diffusion-Optimizing-Multi-Concept-Text-to-Image-Generation-Training-Freely-with-Isolated-Diffusion-Guidance" class="headerlink" title="Isolated Diffusion: Optimizing Multi-Concept Text-to-Image Generation   Training-Freely with Isolated Diffusion Guidance"></a>Isolated Diffusion: Optimizing Multi-Concept Text-to-Image Generation   Training-Freely with Isolated Diffusion Guidance</h2><p><strong>Authors:Jingyuan Zhu, Huimin Ma, Jiansheng Chen, Jian Yuan</strong></p>
<p>Large-scale text-to-image diffusion models have achieved great success in synthesizing high-quality and diverse images given target text prompts. Despite the revolutionary image generation ability, current state-of-the-art models still struggle to deal with multi-concept generation accurately in many cases. This phenomenon is known as &#96;&#96;concept bleedingâ€ and displays as the unexpected overlapping or merging of various concepts. This paper presents a general approach for text-to-image diffusion models to address the mutual interference between different subjects and their attachments in complex scenes, pursuing better text-image consistency. The core idea is to isolate the synthesizing processes of different concepts. We propose to bind each attachment to corresponding subjects separately with split text prompts. Besides, we introduce a revision method to fix the concept bleeding problem in multi-subject synthesis. We first depend on pre-trained object detection and segmentation models to obtain the layouts of subjects. Then we isolate and resynthesize each subject individually with corresponding text prompts to avoid mutual interference. Overall, we achieve a training-free strategy, named Isolated Diffusion, to optimize multi-concept text-to-image synthesis. It is compatible with the latest Stable Diffusion XL (SDXL) and prior Stable Diffusion (SD) models. We compare our approach with alternative methods using a variety of multi-concept text prompts and demonstrate its effectiveness with clear advantages in text-image consistency and user study. </p>
<blockquote>
<p>å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨ç»™å®šç›®æ ‡æ–‡æœ¬æç¤ºçš„æƒ…å†µä¸‹ï¼Œå·²æˆåŠŸåˆæˆé«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„å›¾åƒã€‚å°½ç®¡è¿™äº›é©å‘½æ€§çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†å½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹ä»ç„¶åœ¨è®¸å¤šæƒ…å†µä¸‹éš¾ä»¥å‡†ç¡®å¤„ç†å¤šæ¦‚å¿µç”Ÿæˆã€‚è¿™ç§ç°è±¡è¢«ç§°ä¸ºâ€œæ¦‚å¿µå‡ºè¡€â€ï¼Œè¡¨ç°ä¸ºå„ç§æ¦‚å¿µçš„æ„å¤–é‡å æˆ–åˆå¹¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šç”¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ–¹æ³•ï¼Œä»¥è§£å†³å¤æ‚åœºæ™¯ä¸­ä¸åŒä¸»é¢˜åŠå…¶é™„ä»¶ä¹‹é—´çš„ç›¸äº’å¹²æ‰°ï¼Œä»¥è¿½æ±‚æ›´å¥½çš„æ–‡æœ¬-å›¾åƒä¸€è‡´æ€§ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯éš”ç¦»ä¸åŒæ¦‚å¿µçš„åˆæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬æå‡ºé€šè¿‡æ‹†åˆ†æ–‡æœ¬æç¤ºæ¥å°†æ¯ä¸ªé™„ä»¶ä¸ç›¸åº”çš„ä¸»é¢˜åˆ†åˆ«ç»‘å®šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¿®æ­£æ–¹æ³•æ¥è§£å†³å¤šä¸»é¢˜åˆæˆä¸­çš„æ¦‚å¿µå‡ºè¡€é—®é¢˜ã€‚æˆ‘ä»¬é¦–å…ˆä¾èµ–äºé¢„è®­ç»ƒçš„ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²æ¨¡å‹æ¥è·å¾—ä¸»é¢˜å¸ƒå±€ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨ç›¸åº”çš„æ–‡æœ¬æç¤ºæ¥éš”ç¦»å¹¶é‡æ–°åˆæˆæ¯ä¸ªä¸»é¢˜ï¼Œä»¥é¿å…ç›¸äº’å¹²æ‰°ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç§åä¸ºâ€œå­¤ç«‹æ‰©æ•£â€çš„éè®­ç»ƒç­–ç•¥ï¼Œä»¥ä¼˜åŒ–å¤šæ¦‚å¿µæ–‡æœ¬åˆ°å›¾åƒçš„åˆæˆã€‚å®ƒä¸æœ€æ–°çš„Stable Diffusion XLï¼ˆSDXLï¼‰å’Œä¹‹å‰çš„Stable Diffusionï¼ˆSDï¼‰æ¨¡å‹å…¼å®¹ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨å¤šç§å¤šæ¦‚å¿µæ–‡æœ¬æç¤ºå°†æˆ‘ä»¬çš„æ–¹æ³•ä¸æ›¿ä»£æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶åœ¨æ–‡æœ¬-å›¾åƒä¸€è‡´æ€§å’Œç”¨æˆ·ç ”ç©¶æ–¹é¢æ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§åŠæ˜æ˜¾ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.16954v2">PDF</a> Accepted by IEEE Transactions on Visualization and Computer Graphics</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œç”¨äºè§£å†³å¤æ‚åœºæ™¯ä¸­ä¸åŒä¸»é¢˜åŠå…¶é™„ä»¶ä¹‹é—´çš„ç›¸äº’å¹²æ‰°é—®é¢˜ï¼Œä»è€Œæé«˜æ–‡æœ¬ä¸å›¾åƒçš„ä¸€è‡´æ€§ã€‚é€šè¿‡åˆ†ç¦»ä¸åŒæ¦‚å¿µçš„åˆæˆè¿‡ç¨‹ï¼Œé‡‡ç”¨åˆ†å‰²æ–‡æœ¬æç¤ºå°†æ¯ä¸ªé™„ä»¶ç»‘å®šåˆ°ç›¸åº”çš„ä¸»é¢˜ä¸Šã€‚åŒæ—¶ï¼Œå¼•å…¥äº†ä¸€ç§ä¿®æ­£æ–¹æ³•æ¥è§£å†³å¤šä¸»é¢˜åˆæˆä¸­çš„æ¦‚å¿µæ··æ·†é—®é¢˜ã€‚é€šè¿‡ä¾èµ–äºé¢„è®­ç»ƒçš„ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²æ¨¡å‹æ¥è·å–ä¸»é¢˜å¸ƒå±€ï¼Œç„¶åå­¤ç«‹å¹¶é‡æ–°åˆæˆæ¯ä¸ªä¸»é¢˜ï¼Œä»¥æé«˜æ–‡æœ¬ä¸å›¾åƒçš„ä¸€è‡´æ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™æ˜¯ä¸€ç§åä¸ºâ€œå­¤ç«‹æ‰©æ•£â€çš„æ— è®­ç»ƒç­–ç•¥ï¼Œå¯ä¼˜åŒ–å¤šæ¦‚å¿µæ–‡æœ¬åˆ°å›¾åƒçš„ç»¼åˆç”Ÿæˆï¼Œä¸æœ€æ–°çš„Stable Diffusion XLå’Œä¹‹å‰çš„Stable Diffusionæ¨¡å‹å…¼å®¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨åˆæˆé«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„å›¾åƒæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†åœ¨å¤šæ¦‚å¿µç”Ÿæˆæ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰æ¨¡å‹é¢ä¸´çš„æ¦‚å¿µæ··æ·†é—®é¢˜è¢«ç§°ä¸ºâ€œæ¦‚å¿µå‡ºè¡€â€ï¼Œè¡¨ç°ä¸ºå„ç§æ¦‚å¿µçš„æ„å¤–é‡å æˆ–åˆå¹¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³å¤æ‚åœºæ™¯ä¸­ä¸åŒä¸»é¢˜åŠå…¶é™„ä»¶ä¹‹é—´çš„å¹²æ‰°é—®é¢˜ï¼Œä»¥æé«˜æ–‡æœ¬ä¸å›¾åƒçš„ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡åˆ†ç¦»ä¸åŒæ¦‚å¿µçš„åˆæˆè¿‡ç¨‹å¹¶é‡‡ç”¨åˆ†å‰²æ–‡æœ¬æç¤ºæ¥ç»‘å®šæ¯ä¸ªé™„ä»¶åˆ°ç›¸åº”çš„ä¸»é¢˜ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§ä¿®æ­£æ–¹æ³•æ¥å¤„ç†å¤šä¸»é¢˜åˆæˆä¸­çš„æ¦‚å¿µæ··æ·†é—®é¢˜ï¼Œä¾èµ–äºé¢„è®­ç»ƒçš„ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²æ¨¡å‹æ¥è·å–ä¸»é¢˜å¸ƒå±€ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºâ€œå­¤ç«‹æ‰©æ•£â€çš„æ— è®­ç»ƒç­–ç•¥ï¼Œä¼˜åŒ–äº†å¤šæ¦‚å¿µæ–‡æœ¬åˆ°å›¾åƒçš„ç»¼åˆç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.16954">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-85f7a5d9da68054b841d6e82e946721c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59142d846d4e359688805be6f3e9531f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1588650e8316fc8560462f8d745bdd8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e8ba5c7568a73643d725e4fa9b60a09.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-564b5c14c225f074d1158ed624da5632.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Generate-E-commerce-Product-Background-by-Integrating-Category-Commonality-and-Personalized-Style"><a href="#Generate-E-commerce-Product-Background-by-Integrating-Category-Commonality-and-Personalized-Style" class="headerlink" title="Generate E-commerce Product Background by Integrating Category   Commonality and Personalized Style"></a>Generate E-commerce Product Background by Integrating Category   Commonality and Personalized Style</h2><p><strong>Authors:Haohan Wang, Wei Feng, Yaoyu Li, Zheng Zhang, Jingjing Lv, Junjie Shen, Zhangang Lin, Jingping Shao</strong></p>
<p>The state-of-the-art methods for e-commerce product background generation suffer from the inefficiency of designing product-wise prompts when scaling up the production, as well as the ineffectiveness of describing fine-grained styles when customizing personalized backgrounds for some specific brands. To address these obstacles, we integrate the category commonality and personalized style into diffusion models. Concretely, we propose a Category-Wise Generator to enable large-scale background generation with only one model for the first time. A unique identifier in the prompt is assigned to each category, whose attention is located on the background by a mask-guided cross attention layer to learn the category-wise style. Furthermore, for products with specific and fine-grained requirements in layout, elements, etc, a Personality-Wise Generator is devised to learn such personalized style directly from a reference image to resolve textual ambiguities, and is trained in a self-supervised manner for more efficient training data usage. To advance research in this field, the first large-scale e-commerce product background generation dataset BG60k is constructed, which covers more than 60k product images from over 2k categories. Experiments demonstrate that our method could generate high-quality backgrounds for different categories, and maintain the personalized background style of reference images. BG60k will be available at \url{<a target="_blank" rel="noopener" href="https://github.com/Whileherham/BG60k%7D">https://github.com/Whileherham/BG60k}</a>. </p>
<blockquote>
<p>å½“å‰ç”µå­å•†åŠ¡äº§å“èƒŒæ™¯ç”Ÿæˆçš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œåœ¨æ‰©å¤§ç”Ÿäº§è§„æ¨¡æ—¶é¢ä¸´ç€äº§å“è®¾è®¡æç¤ºæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œä»¥åŠåœ¨ä¸ºæŸäº›ç‰¹å®šå“ç‰Œå®šåˆ¶ä¸ªæ€§åŒ–èƒŒæ™¯æ—¶æè¿°ç»†å¾®é£æ ¼çš„ä¸æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›éšœç¢ï¼Œæˆ‘ä»¬å°†ç±»åˆ«å…±æ€§ä¸ä¸ªæ€§åŒ–é£æ ¼èå…¥æ‰©æ•£æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–æ¬¡æå‡ºä¸€ç§ç±»åˆ«ç”Ÿæˆå™¨ï¼Œåªéœ€ä¸€ä¸ªæ¨¡å‹å³å¯å®ç°å¤§è§„æ¨¡çš„èƒŒæ™¯ç”Ÿæˆã€‚æ¯ä¸ªç±»åˆ«åœ¨æç¤ºä¸­éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œé€šè¿‡ä¸€ä¸ªæ©è†œå¼•å¯¼äº¤å‰æ³¨æ„åŠ›å±‚å°†æ³¨æ„åŠ›é›†ä¸­åœ¨èƒŒæ™¯ä¸Šï¼Œä»¥å­¦ä¹ ç±»åˆ«é£æ ¼ã€‚æ­¤å¤–ï¼Œå¯¹äºåœ¨å¸ƒå±€ã€å…ƒç´ ç­‰æ–¹é¢æœ‰ç‰¹å®šå’Œç»†å¾®è¦æ±‚çš„äº§å“ï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸ªæ€§åŒ–ç”Ÿæˆå™¨ï¼Œç›´æ¥ä»å‚è€ƒå›¾åƒå­¦ä¹ ä¸ªæ€§åŒ–é£æ ¼ï¼Œä»¥è§£å†³æ–‡æœ¬æ­§ä¹‰é—®é¢˜ï¼Œå¹¶ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨è®­ç»ƒæ•°æ®ã€‚ä¸ºäº†æ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡ç”µå­å•†åŠ¡äº§å“èƒŒæ™¯ç”Ÿæˆæ•°æ®é›†BG60kï¼Œè¯¥æ•°æ®é›†æ¶µç›–äº†æ¥è‡ª2kå¤šä¸ªç±»åˆ«çš„è¶…è¿‡6ä¸‡å¼ äº§å“å›¾åƒã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä¸ºä¸åŒçš„ç±»åˆ«ç”Ÿæˆé«˜è´¨é‡çš„èƒŒæ™¯ï¼Œå¹¶ä¿æŒå‚è€ƒå›¾åƒçš„ä¸ªæ€§åŒ–èƒŒæ™¯é£æ ¼ã€‚BG60kæ•°æ®é›†å°†åœ¨\url{<a target="_blank" rel="noopener" href="https://github.com/Whileherham/BG60k%7D%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/Whileherham/BG60k}ä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.13309v2">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>åœ¨å½“å‰çš„ç”µå•†äº§å“èƒŒæ™¯ç”Ÿæˆæ–¹æ³•ä¸­ï¼Œéšç€äº§å“æ•°é‡çš„å¢é•¿ï¼Œä¸ºæ¯ä¸€ä¸ªäº§å“è®¾è®¡ä¸“å±æç¤ºè¯­æ˜¯éå¸¸ä½æ•ˆçš„ï¼›åŒæ—¶ä¸ºæŸäº›ç‰¹å®šå“ç‰Œå®šåˆ¶ç²¾ç»†é£æ ¼èƒŒæ™¯æ—¶ä¹Ÿå­˜åœ¨æè¿°ä¸å¤Ÿç²¾ç¡®çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿç»“åˆæ‰©æ•£æ¨¡å‹ä¸­çš„ç±»åˆ«å…±æ€§åŠä¸ªæ€§åŒ–é£æ ¼æå‡ºäº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚é¦–å…ˆï¼Œä»–ä»¬é¦–æ¬¡æå‡ºäº†ä¸€ä¸ªç±»åˆ«å¯¼å‘ç”Ÿæˆå™¨ï¼Œåªéœ€ä¸€ä¸ªæ¨¡å‹å°±èƒ½å®ç°å¤§è§„æ¨¡çš„èƒŒæ™¯ç”Ÿæˆã€‚æ¯ä¸ªç±»åˆ«éƒ½æœ‰ä¸€ä¸ªç‹¬ç‰¹çš„æ ‡è¯†ç¬¦ä½œä¸ºæç¤ºè¯­ï¼Œé€šè¿‡é®ç½©å¼•å¯¼çš„äº¤å‰æ³¨æ„åŠ›å±‚å°†å…¶èšç„¦åœ¨èƒŒæ™¯ä¸Šï¼Œä»¥å­¦ä¹ ç±»åˆ«çš„é£æ ¼ç‰¹å¾ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ»¡è¶³å…·æœ‰ç‰¹å®šç»†èŠ‚è¦æ±‚çš„äº§å“çš„å¸ƒå±€å’Œå…ƒç´ ç­‰éœ€æ±‚ï¼Œä»–ä»¬è¿˜è®¾è®¡äº†ä¸€ä¸ªä¸ªæ€§åŒ–ç”Ÿæˆå™¨ï¼Œå¯ä»¥ä»å‚è€ƒå›¾åƒä¸­å­¦ä¹ ä¸ªæ€§åŒ–é£æ ¼ä»¥è§£å†³æ–‡æœ¬æ­§ä¹‰é—®é¢˜ï¼Œå¹¶é‡‡ç”¨è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒä»¥æ›´æœ‰æ•ˆåœ°ä½¿ç”¨è®­ç»ƒæ•°æ®ã€‚ä¸ºäº†æ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•ï¼Œä»–ä»¬è¿˜æ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡çš„ç”µå•†äº§å“èƒŒæ™¯ç”Ÿæˆæ•°æ®é›†BG60kï¼ŒåŒ…å«è¶…è¿‡6ä¸‡å¼ æ¥è‡ªè¶…è¿‡ä¸¤åƒä¸ªç±»åˆ«çš„äº§å“å›¾åƒã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä¸ºä¸åŒç±»åˆ«çš„äº§å“ç”Ÿæˆé«˜è´¨é‡èƒŒæ™¯ï¼Œå¹¶ä¿ç•™å‚è€ƒå›¾åƒçš„ä¸ªæ€§åŒ–èƒŒæ™¯é£æ ¼ã€‚è¯¥æ•°æ®é›†ç°å·²å¯åœ¨æŒ‡å®šç½‘ç«™è·å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰ç”µå•†äº§å“èƒŒæ™¯ç”Ÿæˆé¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬è®¾è®¡äº§å“æç¤ºçš„ä½æ•ˆæ€§å’Œæè¿°ç²¾ç»†é£æ ¼çš„å›°éš¾æ€§ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿé€šè¿‡ç»“åˆæ‰©æ•£æ¨¡å‹ä¸­çš„ç±»åˆ«å…±æ€§åŠä¸ªæ€§åŒ–é£æ ¼æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>æå‡ºç±»åˆ«å¯¼å‘ç”Ÿæˆå™¨ï¼Œå®ç°å¤§è§„æ¨¡èƒŒæ™¯ç”Ÿæˆåªéœ€ä¸€ä¸ªæ¨¡å‹ã€‚æ¯ä¸ªç±»åˆ«æœ‰ç‹¬ç‰¹çš„æ ‡è¯†ç¬¦ä½œä¸ºæç¤ºè¯­ã€‚</li>
<li>è®¾è®¡ä¸ªæ€§åŒ–ç”Ÿæˆå™¨ä»¥æ»¡è¶³å…·æœ‰ç‰¹å®šç»†èŠ‚è¦æ±‚çš„äº§å“çš„éœ€æ±‚ï¼Œä»å‚è€ƒå›¾åƒä¸­å­¦ä¹ ä¸ªæ€§åŒ–é£æ ¼å¹¶è§£å†³æ–‡æœ¬æ­§ä¹‰é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨è‡ªæˆ‘ç›‘ç£è®­ç»ƒä»¥æé«˜è®­ç»ƒæ•°æ®ä½¿ç”¨æ•ˆç‡ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡çš„ç”µå•†äº§å“èƒŒæ™¯ç”Ÿæˆæ•°æ®é›†BG60kï¼ŒåŒ…å«è¶…è¿‡6ä¸‡å¼ æ¥è‡ªä¸¤åƒä¸ªç±»åˆ«çš„äº§å“å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.13309">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6862b1022331c75bdfb5c92da78d23ad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0cb1f7179677475ed0a9af8ae9e9aaac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c0a7827a15cbbd0bcf8dc09a9c0ac4e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5c926d21c5639b073975b0c8209248c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b36c366ed9a66cb6c2b8d822b2f6fbd.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-21/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-21/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-21/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-7e2835baee1b0b1d105266f164f847db.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-21  Region-wise stacking ensembles for estimating brain-age using MRI
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-21/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-02482c9381dc27eea9ef006577460386.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-21  Surface-SOS Self-Supervised Object Segmentation via Neural Surface   Representation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29474.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
