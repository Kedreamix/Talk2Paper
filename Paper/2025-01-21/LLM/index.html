<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-21  FaceXBench Evaluating Multimodal LLMs on Face Understanding">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-a9b3929f400dd861e57bad3fed550363.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    82 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-21-æ›´æ–°"><a href="#2025-01-21-æ›´æ–°" class="headerlink" title="2025-01-21 æ›´æ–°"></a>2025-01-21 æ›´æ–°</h1><h2 id="FaceXBench-Evaluating-Multimodal-LLMs-on-Face-Understanding"><a href="#FaceXBench-Evaluating-Multimodal-LLMs-on-Face-Understanding" class="headerlink" title="FaceXBench: Evaluating Multimodal LLMs on Face Understanding"></a>FaceXBench: Evaluating Multimodal LLMs on Face Understanding</h2><p><strong>Authors:Kartik Narayan, Vibashan VS, Vishal M. Patel</strong></p>
<p>Multimodal Large Language Models (MLLMs) demonstrate impressive problem-solving abilities across a wide range of tasks and domains. However, their capacity for face understanding has not been systematically studied. To address this gap, we introduce FaceXBench, a comprehensive benchmark designed to evaluate MLLMs on complex face understanding tasks. FaceXBench includes 5,000 multimodal multiple-choice questions derived from 25 public datasets and a newly created dataset, FaceXAPI. These questions cover 14 tasks across 6 broad categories, assessing MLLMsâ€™ face understanding abilities in bias and fairness, face authentication, recognition, analysis, localization and tool retrieval. Using FaceXBench, we conduct an extensive evaluation of 26 open-source MLLMs alongside 2 proprietary models, revealing the unique challenges in complex face understanding tasks. We analyze the models across three evaluation settings: zero-shot, in-context task description, and chain-of-thought prompting. Our detailed analysis reveals that current MLLMs, including advanced models like GPT-4o, and GeminiPro 1.5, show significant room for improvement. We believe FaceXBench will be a crucial resource for developing MLLMs equipped to perform sophisticated face understanding. Code: <a target="_blank" rel="noopener" href="https://github.com/Kartik-3004/facexbench">https://github.com/Kartik-3004/facexbench</a> </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¹¿æ³›çš„ä»»åŠ¡å’Œé¢†åŸŸä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹é¢éƒ¨ç†è§£çš„èƒ½åŠ›å°šæœªå¾—åˆ°ç³»ç»Ÿçš„ç ”ç©¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†FaceXBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°MLLMsåœ¨å¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡ä¸Šçš„ç»¼åˆåŸºå‡†æµ‹è¯•ã€‚FaceXBenchåŒ…æ‹¬ä»25ä¸ªå…¬å…±æ•°æ®é›†å’Œæ–°åˆ›å»ºçš„æ•°æ®é›†FaceXAPIä¸­æ´¾ç”Ÿçš„5000ä¸ªå¤šæ¨¡æ€å¤šé¡¹é€‰æ‹©é¢˜ã€‚è¿™äº›é—®é¢˜æ¶µç›–äº†6å¤§ç±»ä¸­çš„14é¡¹ä»»åŠ¡ï¼Œè¯„ä¼°MLLMsåœ¨åè§å’Œå…¬å¹³æ€§ã€é¢éƒ¨è®¤è¯ã€è¯†åˆ«ã€åˆ†æã€å®šä½å’Œå·¥å…·æ£€ç´¢æ–¹é¢çš„é¢éƒ¨ç†è§£èƒ½åŠ›ã€‚ä½¿ç”¨FaceXBenchï¼Œæˆ‘ä»¬å¯¹26ä¸ªå¼€æºMLLMså’Œ2ä¸ªä¸“æœ‰æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œæ­ç¤ºäº†å¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡çš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æˆ‘ä»¬åˆ†æäº†ä¸‰ç§è¯„ä¼°ç¯å¢ƒä¸‹çš„æ¨¡å‹ï¼šé›¶æ ·æœ¬ã€ä¸Šä¸‹æ–‡ä»»åŠ¡æè¿°å’Œæ€ç»´é“¾æç¤ºã€‚æˆ‘ä»¬çš„è¯¦ç»†åˆ†æè¡¨æ˜ï¼ŒåŒ…æ‹¬GPT-4oå’ŒGeminiPro 1.5ç­‰å…ˆè¿›æ¨¡å‹åœ¨å†…çš„å½“å‰MLLMsä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚æˆ‘ä»¬ç›¸ä¿¡FaceXBenchå°†æˆä¸ºå¼€å‘èƒ½å¤Ÿæ‰§è¡Œå¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡çš„å…³é”®èµ„æºçš„é‡è¦å·¥å…·ã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/Kartik-3004/facexbench">https://github.com/Kartik-3004/facexbench</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10360v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://kartik-3004.github.io/facexbench/">https://kartik-3004.github.io/facexbench/</a></p>
<p><strong>Summary</strong>ï¼š</p>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¹¿æ³›çš„ä»»åŠ¡å’Œé¢†åŸŸä¸­å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹é¢éƒ¨ç†è§£çš„èƒ½åŠ›å°šæœªè¿›è¡Œç³»ç»Ÿæ€§çš„ç ”ç©¶ã€‚ä¸ºè§£å†³è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†FaceXBenchï¼Œè¿™æ˜¯ä¸€å¥—å…¨é¢è¯„ä¼°MLLMsåœ¨å¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡ä¸Šçš„è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚FaceXBenchåŒ…å«ä»25ä¸ªå…¬å¼€æ•°æ®é›†å’Œæ–°åˆ›å»ºçš„FaceXAPIæ•°æ®é›†ä¸­è¡ç”Ÿçš„5000ä¸ªå¤šæ¨¡æ€é€‰æ‹©é¢˜ã€‚è¿™äº›é—®é¢˜æ¶µç›–äº†6å¤§ç±»åˆ«çš„14é¡¹ä»»åŠ¡ï¼Œè¯„ä¼°MLLMsåœ¨åè§ä¸å…¬æ­£ã€é¢éƒ¨è®¤è¯ã€è¯†åˆ«ã€åˆ†æã€å®šä½å’Œå·¥å…·æ£€ç´¢æ–¹é¢çš„é¢éƒ¨ç†è§£èƒ½åŠ›ã€‚é€šè¿‡ä½¿ç”¨FaceXBenchï¼Œæˆ‘ä»¬å¯¹26ä¸ªå¼€æºMLLMså’Œ2ä¸ªä¸“æœ‰æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œæ­ç¤ºäº†å¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡çš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼ŒåŒ…æ‹¬GPT-4oå’ŒGeminiPro 1.5ç­‰å…ˆè¿›æ¨¡å‹åœ¨å†…çš„å½“å‰MLLMsä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚æˆ‘ä»¬ç›¸ä¿¡FaceXBenchå°†æˆä¸ºå¼€å‘å…·å¤‡é«˜çº§é¢éƒ¨ç†è§£èƒ½åŠ›çš„MLLMsçš„å…³é”®èµ„æºã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>FaceXBenchæ˜¯é¦–ä¸ªå…¨é¢è¯„ä¼°MLLMsåœ¨å¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡ä¸Šè¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>FaceXBenchåŒ…å«5000ä¸ªå¤šæ¨¡æ€é€‰æ‹©é¢˜ï¼Œæ¶µç›–14é¡¹ä»»åŠ¡ï¼Œ6å¤§ç±»åˆ«ï¼Œå…¨é¢è¯„ä¼°MLLMsçš„é¢éƒ¨ç†è§£èƒ½åŠ›ã€‚</li>
<li>FaceXBenchæ¥æºäº25ä¸ªå…¬å¼€æ•°æ®é›†å’Œæ–°åˆ›å»ºçš„FaceXAPIæ•°æ®é›†ã€‚</li>
<li>é€šè¿‡FaceXBenchå¯¹å¤šä¸ªMLLMsæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬å¼€æºæ¨¡å‹å’Œä¸“æœ‰æ¨¡å‹ã€‚</li>
<li>å¤æ‚é¢éƒ¨ç†è§£ä»»åŠ¡å­˜åœ¨ç‹¬ç‰¹æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰MLLMsï¼ŒåŒ…æ‹¬å…ˆè¿›æ¨¡å‹ï¼Œåœ¨é¢éƒ¨ç†è§£æ–¹é¢ä»æœ‰æ˜¾è‘—æ”¹è¿›ç©ºé—´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10360">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bc43479ca2a6cba4a63db3c97460540e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a396dfbc341c6343e54cae812ee51554.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2d734150feb840cfdac38e8b96df01c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9bf14c7b56d3e8ac1d05d7cf37b2d28.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Agent4Edu-Generating-Learner-Response-Data-by-Generative-Agents-for-Intelligent-Education-Systems"><a href="#Agent4Edu-Generating-Learner-Response-Data-by-Generative-Agents-for-Intelligent-Education-Systems" class="headerlink" title="Agent4Edu: Generating Learner Response Data by Generative Agents for   Intelligent Education Systems"></a>Agent4Edu: Generating Learner Response Data by Generative Agents for   Intelligent Education Systems</h2><p><strong>Authors:Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Rui Lv, Zheng Zhang, Hao Wang, Zhenya Huang</strong></p>
<p>Personalized learning represents a promising educational strategy within intelligent educational systems, aiming to enhance learnersâ€™ practice efficiency. However, the discrepancy between offline metrics and online performance significantly impedes their progress. To address this challenge, we introduce Agent4Edu, a novel personalized learning simulator leveraging recent advancements in human intelligence through large language models (LLMs). Agent4Edu features LLM-powered generative agents equipped with learner profile, memory, and action modules tailored to personalized learning algorithms. The learner profiles are initialized using real-world response data, capturing practice styles and cognitive factors. Inspired by human psychology theory, the memory module records practice facts and high-level summaries, integrating reflection mechanisms. The action module supports various behaviors, including exercise understanding, analysis, and response generation. Each agent can interact with personalized learning algorithms, such as computerized adaptive testing, enabling a multifaceted evaluation and enhancement of customized services. Through a comprehensive assessment, we explore the strengths and weaknesses of Agent4Edu, emphasizing the consistency and discrepancies in responses between agents and human learners. The code, data, and appendix are publicly available at <a target="_blank" rel="noopener" href="https://github.com/bigdata-ustc/Agent4Edu">https://github.com/bigdata-ustc/Agent4Edu</a>. </p>
<blockquote>
<p>ä¸ªæ€§åŒ–å­¦ä¹ ä»£è¡¨äº†ä¸€ç§åœ¨æ™ºèƒ½æ•™è‚²ç³»ç»Ÿä¸­å…·æœ‰å‰æ™¯çš„æ•™è‚²ç­–ç•¥ï¼Œæ—¨åœ¨æé«˜å­¦ä¹ è€…çš„å®è·µæ•ˆç‡ã€‚ç„¶è€Œï¼Œç¦»çº¿æŒ‡æ ‡ä¸åœ¨çº¿è¡¨ç°ä¹‹é—´çš„å·®å¼‚æ˜¾è‘—é˜»ç¢äº†å…¶è¿›å±•ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Agent4Eduï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•çš„æ–°å‹ä¸ªæ€§åŒ–å­¦ä¹ æ¨¡æ‹Ÿå™¨ã€‚Agent4Eduçš„ç‰¹ç‚¹æ˜¯æ‹¥æœ‰LLMé©±åŠ¨çš„ç”Ÿæˆä»£ç†ï¼Œé…å¤‡äº†å­¦ä¹ è€…æ¦‚å†µã€è®°å¿†å’Œè¡ŒåŠ¨æ¨¡å—ï¼Œè¿™äº›æ¨¡å—éƒ½é’ˆå¯¹ä¸ªæ€§åŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œäº†å®šåˆ¶ã€‚å­¦ä¹ è€…æ¦‚å†µä½¿ç”¨ç°å®ä¸–ç•Œçš„å“åº”æ•°æ®è¿›è¡Œåˆå§‹åŒ–ï¼Œæ•è·å®è·µé£æ ¼å’Œè®¤çŸ¥å› ç´ ã€‚å—äººç±»å¿ƒç†å­¦ç†è®ºçš„å¯å‘ï¼Œè®°å¿†æ¨¡å—è®°å½•å®è·µäº‹å®å’Œé«˜å±‚æ¬¡æ‘˜è¦ï¼Œé›†æˆäº†åæ€æœºåˆ¶ã€‚è¡ŒåŠ¨æ¨¡å—æ”¯æŒå„ç§è¡Œä¸ºï¼ŒåŒ…æ‹¬ç†è§£ç»ƒä¹ ã€åˆ†æå’Œç”Ÿæˆå“åº”ã€‚æ¯ä¸ªä»£ç†éƒ½å¯ä»¥ä¸ä¸ªæ€§åŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œäº¤äº’ï¼Œå¦‚è®¡ç®—æœºåŒ–è‡ªé€‚åº”æµ‹è¯•ï¼Œä»è€Œå®ç°å¤šæ–¹é¢çš„è¯„ä¼°å’Œå®šåˆ¶æœåŠ¡çš„å¢å¼ºã€‚é€šè¿‡å…¨é¢è¯„ä¼°ï¼Œæˆ‘ä»¬æ¢è®¨äº†Agent4Eduçš„ä¼˜ç¼ºç‚¹ï¼Œé‡ç‚¹å¼ºè°ƒäº†ä»£ç†å’Œäººç±»å­¦ä¹ è€…ä¹‹é—´å“åº”çš„ä¸€è‡´æ€§å’Œå·®å¼‚ã€‚ä»£ç ã€æ•°æ®å’Œé™„å½•å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bigdata-ustc/Agent4Edu%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/bigdata-ustc/Agent4Eduä¸Šå…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10332v1">PDF</a> Accepted by AAAI2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ™ºèƒ½æ•™è‚²ç³»ç»Ÿå†…çš„ä¸ªæ€§åŒ–å­¦ä¹ ç­–ç•¥å…·æœ‰å¹¿é˜”çš„å‘å±•å‰æ™¯ï¼Œæ—¨åœ¨æé«˜å­¦ä¹ è€…çš„å®è·µæ•ˆç‡ã€‚ç„¶è€Œï¼Œç¦»çº¿æŒ‡æ ‡ä¸åœ¨çº¿è¡¨ç°ä¹‹é—´çš„å·®å¼‚æ˜¾è‘—é˜»ç¢äº†ä¸ªæ€§åŒ–å­¦ä¹ çš„è¿›æ­¥ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Agent4Eduâ€”â€”ä¸€æ¬¾åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ€æ–°è¿›å±•çš„æ–°å‹ä¸ªæ€§åŒ–å­¦ä¹ æ¨¡æ‹Ÿå™¨ã€‚Agent4Edué…å¤‡äº†ä¸ªæ€§åŒ–å­¦ä¹ ç®—æ³•ï¼Œå…¶ç”Ÿæˆå¼ä»£ç†æ‹¥æœ‰å­¦ä¹ è€…ç‰¹æ€§ã€è®°å¿†åŠè¡ŒåŠ¨æ¨¡å—ã€‚å­¦ä¹ è€…ç‰¹æ€§é‡‡ç”¨ç°å®ä¸–ç•Œå“åº”æ•°æ®è¿›è¡Œåˆå§‹åŒ–ï¼Œä»¥æ•æ‰å®è·µé£æ ¼å’Œè®¤çŸ¥å› ç´ ã€‚è®°å¿†æ¨¡å—é‡‡ç”¨å¿ƒç†å­¦ç†è®ºï¼Œè®°å½•å®è·µäº‹å®å’Œé«˜çº§æ‘˜è¦å¹¶é›†æˆåæ€æœºåˆ¶ã€‚è¡ŒåŠ¨æ¨¡å—æ”¯æŒç»ƒä¹ ç†è§£ã€åˆ†æå’Œå“åº”ç”Ÿæˆç­‰è¡Œä¸ºã€‚æ¯ä¸ªä»£ç†éƒ½èƒ½ä¸è¯¸å¦‚è®¡ç®—æœºè‡ªé€‚åº”æµ‹è¯•ç­‰ä¸ªæ€§åŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œäº¤äº’ï¼Œå®ç°å¤šå…ƒåŒ–è¯„ä¼°å’Œå®šåˆ¶åŒ–æœåŠ¡çš„æå‡ã€‚æˆ‘ä»¬å¯¹Agent4Eduè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨äº†ä»£ç†å“åº”ä¸äººç±»å­¦ä¹ è€…ä¹‹é—´çš„ä¸€è‡´æ€§å·®å¼‚å’Œå¼ºå¼±é¡¹ã€‚ç›¸å…³ä»£ç ã€æ•°æ®å’Œé™„å½•å¯è®¿é—® <a target="_blank" rel="noopener" href="https://github.com/bigdata-ustc/Agent4Edu">https://github.com/bigdata-ustc/Agent4Edu</a> è·å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸ªæ€§åŒ–å­¦ä¹ æ˜¯æ™ºèƒ½æ•™è‚²ç³»ç»Ÿä¸­ä¸€ç§æœ‰å‰é€”çš„æ•™è‚²ç­–ç•¥ï¼Œæ—¨åœ¨æé«˜å­¦ä¹ è€…çš„å®è·µæ•ˆç‡ã€‚</li>
<li>Agent4Eduæ˜¯ä¸€æ¬¾æ–°å‹ä¸ªæ€§åŒ–å­¦ä¹ æ¨¡æ‹Ÿå™¨ï¼Œé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯ã€‚</li>
<li>Agent4Edué…å¤‡å­¦ä¹ è€…ç‰¹æ€§ã€è®°å¿†å’Œè¡ŒåŠ¨æ¨¡å—ï¼Œæ¨¡æ‹ŸçœŸå®å­¦ä¹ è€…çš„ç‰¹æ€§å’Œè¡Œä¸ºã€‚</li>
<li>å­¦ä¹ è€…ç‰¹æ€§é€šè¿‡ç°å®ä¸–ç•Œçš„å“åº”æ•°æ®è¿›è¡Œåˆå§‹åŒ–ï¼Œä»¥åæ˜ å®è·µé£æ ¼å’Œè®¤çŸ¥å› ç´ ã€‚</li>
<li>Agent4Eduçš„è®°å¿†æ¨¡å—åŸºäºå¿ƒç†å­¦ç†è®ºè®¾è®¡ï¼Œè®°å½•å®è·µäº‹å®ã€é«˜çº§æ‘˜è¦ï¼Œå¹¶é›†æˆåæ€æœºåˆ¶ã€‚</li>
<li>Agent4Edué€šè¿‡å…¨é¢çš„è¯„ä¼°ï¼Œåœ¨ä¸ªæ€§åŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚è®¡ç®—æœºè‡ªé€‚åº”æµ‹è¯•ï¼‰çš„äº¤äº’ä¸­è¡¨ç°å‡ºä¸€è‡´æ€§å·®å¼‚å’Œæ€§èƒ½å¼ºå¼±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d182b0f8642d70c5ad9f0c000fc53028.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ec3d5e92938c6f9eb58305a79f2e3e1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d86bf1672931fca61d398cca51fcf06c.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Towards-Human-Guided-Data-Centric-LLM-Co-Pilots"><a href="#Towards-Human-Guided-Data-Centric-LLM-Co-Pilots" class="headerlink" title="Towards Human-Guided, Data-Centric LLM Co-Pilots"></a>Towards Human-Guided, Data-Centric LLM Co-Pilots</h2><p><strong>Authors:Evgeny Saveliev, Jiashuo Liu, Nabeel Seedat, Anders Boyd, Mihaela van der Schaar</strong></p>
<p>Machine learning (ML) has the potential to revolutionize healthcare, but its adoption is often hindered by the disconnect between the needs of domain experts and translating these needs into robust and valid ML tools. Despite recent advances in LLM-based co-pilots to democratize ML for non-technical domain experts, these systems remain predominantly focused on model-centric aspects while overlooking critical data-centric challenges. This limitation is problematic in complex real-world settings where raw data often contains complex issues, such as missing values, label noise, and domain-specific nuances requiring tailored handling. To address this we introduce CliMB-DC, a human-guided, data-centric framework for LLM co-pilots that combines advanced data-centric tools with LLM-driven reasoning to enable robust, context-aware data processing. At its core, CliMB-DC introduces a novel, multi-agent reasoning system that combines a strategic coordinator for dynamic planning and adaptation with a specialized worker agent for precise execution. Domain expertise is then systematically incorporated to guide the reasoning process using a human-in-the-loop approach. To guide development, we formalize a taxonomy of key data-centric challenges that co-pilots must address. Thereafter, to address the dimensions of the taxonomy, we integrate state-of-the-art data-centric tools into an extensible, open-source architecture, facilitating the addition of new tools from the research community. Empirically, using real-world healthcare datasets we demonstrate CliMB-DCâ€™s ability to transform uncurated datasets into ML-ready formats, significantly outperforming existing co-pilot baselines for handling data-centric challenges. CliMB-DC promises to empower domain experts from diverse domains â€“ healthcare, finance, social sciences and more â€“ to actively participate in driving real-world impact using ML. </p>
<blockquote>
<p>æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æœ‰æ½œåŠ›å½»åº•æ”¹å˜åŒ»ç–—ä¿å¥é¢†åŸŸï¼Œä½†å…¶åº”ç”¨å¾€å¾€å—åˆ°é¢†åŸŸä¸“å®¶éœ€æ±‚ä¸å°†è¿™äº›éœ€æ±‚è½¬åŒ–ä¸ºç¨³å¥æœ‰æ•ˆçš„MLå·¥å…·ä¹‹é—´çš„è„±èŠ‚é˜»ç¢ã€‚å°½ç®¡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‰¯é©¾é©¶ç³»ç»Ÿåœ¨æ°‘ä¸»åŒ–MLæ–¹é¢ä¸ºéæŠ€æœ¯ä¸“å®¶åšå‡ºäº†æœ€æ–°çš„è¿›å±•ï¼Œä½†è¿™äº›ç³»ç»Ÿä¸»è¦å…³æ³¨æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ–¹é¢ï¼Œå´å¿½è§†äº†å…³é”®çš„æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜ã€‚åœ¨å¤æ‚çš„ç°å®ä¸–ç•Œä¸­ï¼ŒåŸå§‹æ•°æ®å¸¸å¸¸å­˜åœ¨å¤æ‚çš„é—®é¢˜ï¼Œå¦‚ç¼ºå¤±å€¼ã€æ ‡ç­¾å™ªå£°å’Œéœ€è¦å®šåˆ¶å¤„ç†çš„é¢†åŸŸç‰¹å®šç»†å¾®å·®åˆ«ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CliMB-DCï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥äººä¸ºæŒ‡å¯¼ã€ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹å‰¯é©¾é©¶æ¡†æ¶ï¼Œå®ƒç»“åˆäº†å…ˆè¿›çš„æ•°æ®ä¸­å¿ƒå·¥å…·å’Œå¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ¨ç†ï¼Œä»¥å®ç°ç¨³å¥ã€é¢å‘ä¸Šä¸‹æ–‡çš„æ•°æ®å¤„ç†ã€‚å…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ–°å‹çš„å¤šæ™ºèƒ½ä½“æ¨ç†ç³»ç»Ÿï¼Œç»“åˆäº†ç”¨äºåŠ¨æ€è§„åˆ’å’Œé€‚åº”çš„æˆ˜ç•¥åè°ƒå™¨ä»¥åŠç”¨äºç²¾ç¡®æ‰§è¡Œçš„ä¸“èŒå·¥ä½œè€…æ™ºèƒ½ä½“ã€‚æ­¤åï¼Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†è¢«ç³»ç»Ÿåœ°çº³å…¥ä»¥æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ï¼Œé‡‡ç”¨äººç±»å‚ä¸å¾ªç¯çš„æ–¹æ³•ã€‚ä¸ºäº†æŒ‡å¯¼å¼€å‘ï¼Œæˆ‘ä»¬å¯¹å…³é”®çš„æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜è¿›è¡Œäº†åˆ†ç±»ï¼Œå‰¯é©¾é©¶å¿…é¡»è§£å†³è¿™äº›é—®é¢˜ã€‚ä¹‹åï¼Œä¸ºäº†åº”å¯¹åˆ†ç±»çš„å„ä¸ªæ–¹é¢ï¼Œæˆ‘ä»¬å°†å…ˆè¿›çš„æ•°æ®ä¸ºä¸­å¿ƒçš„å·¥å…·é›†æˆåˆ°ä¸€ä¸ªå¯æ‰©å±•çš„å¼€æºæ¶æ„ä¸­ï¼Œä¾¿äºç ”ç©¶ç¤¾åŒºæ·»åŠ æ–°å·¥å…·ã€‚åœ¨å®è¯æ–¹é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨çœŸå®çš„åŒ»ç–—æ•°æ®é›†è¯æ˜äº†CliMB-DCå°†éç­–åˆ’æ•°æ®é›†è½¬åŒ–ä¸ºé€‚åˆæœºå™¨å­¦ä¹ æ ¼å¼çš„èƒ½åŠ›ï¼Œåœ¨å¤„ç†æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„å‰¯é©¾é©¶åŸºçº¿ã€‚CliMB-DCæœ‰æœ›èµ‹èƒ½æ¥è‡ªä¸åŒé¢†åŸŸçš„é¢†åŸŸä¸“å®¶â€”â€”åŒ»ç–—ä¿å¥ã€é‡‘èã€ç¤¾ä¼šç§‘å­¦ç­‰â€”â€”ç§¯æå‚ä¸åˆ©ç”¨æœºå™¨å­¦ä¹ æ¨åŠ¨ç°å®ä¸–ç•Œçš„å˜é©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10321v1">PDF</a> Saveliev, Liu &amp; Seedat contributed equally</p>
<p><strong>Summary</strong></p>
<p>æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰åœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œä½†å…¶å®é™…åº”ç”¨å¸¸å¸¸å—åˆ°é¢†åŸŸä¸“å®¶éœ€æ±‚ä¸å°†è¿™äº›éœ€æ±‚è½¬åŒ–ä¸ºç¨³å¥æœ‰æ•ˆçš„MLå·¥å…·ä¹‹é—´çš„é¸¿æ²Ÿçš„é˜»ç¢ã€‚å°½ç®¡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¾…åŠ©ç³»ç»Ÿåœ¨æ°‘ä¸»åŒ–MLæ–¹é¢å–å¾—è¿›å±•ï¼Œä½†å®ƒä»¬ä¸»è¦å…³æ³¨æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ–¹æ³•è€Œå¿½è§†æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡ä»‹ç»äº†CliMB-DCï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆé«˜çº§æ•°æ®å·¥å…·ä¸LLMé©±åŠ¨çš„æ¨ç†çš„äººä¸ºå¼•å¯¼ã€ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©ç³»ç»Ÿæ¡†æ¶ã€‚å®ƒå¼•å…¥äº†å¤šæ™ºèƒ½ä½“æ¨ç†ç³»ç»Ÿï¼Œç»“åˆæˆ˜ç•¥åè°ƒå‘˜è¿›è¡ŒåŠ¨æ€è§„åˆ’å’Œé€‚åº”æ€§ä¸ä¸“èŒå·¥ä½œä»£ç†è¿›è¡Œç²¾ç¡®æ‰§è¡Œã€‚é€šè¿‡äººä¸ºå¼•å¯¼çš„æ–¹å¼ç³»ç»Ÿåœ°èå…¥é¢†åŸŸä¸“ä¸šçŸ¥è¯†ä»¥æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡å®è¯ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨çœŸå®åŒ»ç–—æ•°æ®é›†æ—¶ï¼ŒCliMB-DCèƒ½å°†æœªæ•´ç†çš„æ•°é›†è½¬åŒ–ä¸ºMLå°±ç»ªæ ¼å¼ï¼Œåœ¨å¤„ç†æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜æ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰è¾…åŠ©ç³»ç»ŸåŸºçº¿ã€‚CliMB-DCæœ‰æœ›åœ¨åŒ»ç–—ã€é‡‘èã€ç¤¾ä¼šç§‘å­¦ç­‰å„ä¸ªé¢†åŸŸä¸ºé¢†åŸŸä¸“å®¶èµ‹èƒ½ï¼Œç§¯æå‚ä¸æ¨åŠ¨æœºå™¨å­¦ä¹ åœ¨ç°å®ä¸–ç•Œçš„å®é™…åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœºå™¨å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰æ½œåŠ›ï¼Œä½†å®é™…åº”ç”¨å—åˆ°é¢†åŸŸä¸“å®¶ä¸å·¥å…·è½¬åŒ–éœ€æ±‚ä¹‹é—´çš„é¸¿æ²Ÿçš„é˜»ç¢ã€‚</li>
<li>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©ç³»ç»Ÿä¸»è¦å…³æ³¨æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ–¹æ³•è€Œå¿½è§†æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜ã€‚</li>
<li>CliMB-DCæ˜¯ä¸€ä¸ªç»“åˆé«˜çº§æ•°æ®å·¥å…·ä¸LLMçš„å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©ç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>CliMB-DCå¼•å…¥å¤šæ™ºèƒ½ä½“æ¨ç†ç³»ç»Ÿï¼ŒåŒ…æ‹¬æˆ˜ç•¥åè°ƒå‘˜å’Œå·¥ä½œä»£ç†æ¥ç¡®ä¿ç¨³å¥ä¸”ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ•°æ®å¤„ç†ã€‚</li>
<li>é€šè¿‡äººä¸ºå¼•å¯¼çš„æ–¹å¼èå…¥é¢†åŸŸä¸“ä¸šçŸ¥è¯†ä»¥æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ã€‚</li>
<li>CliMB-DCèƒ½æˆåŠŸè½¬åŒ–æœªæ•´ç†æ•°æ®é›†ä¸ºMLå°±ç»ªæ ¼å¼ï¼Œå¹¶å¤„ç†æ•°æ®ä¸ºä¸­å¿ƒçš„æŒ‘æˆ˜æ–¹é¢ä¼˜äºç°æœ‰è¾…åŠ©ç³»ç»ŸåŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10321">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a8b0cca60e4d4698d3c9c48f9e9b84d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-522865d56fe364222cdc073f4616567f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ca7d25357d0d20791133607bac5564b.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="HiMix-Reducing-Computational-Complexity-in-Large-Vision-Language-Models"><a href="#HiMix-Reducing-Computational-Complexity-in-Large-Vision-Language-Models" class="headerlink" title="HiMix: Reducing Computational Complexity in Large Vision-Language Models"></a>HiMix: Reducing Computational Complexity in Large Vision-Language Models</h2><p><strong>Authors:Xuange Zhang, Dengjie Li, Bo Liu, Zenghao Bao, Yao Zhou, Baisong Yang, Zhongying Liu, Yujie Zhong, Zheng Zhao, Tongtong Yuan</strong></p>
<p>Benefiting from recent advancements in large language models and modality alignment techniques, existing Large Vision-Language Models(LVLMs) have achieved prominent performance across a wide range of scenarios. However, the excessive computational complexity limits the widespread use of these models in practical applications. We argue that one main bottleneck in computational complexity is caused by the involvement of redundant vision sequences in model computation. This is inspired by a reassessment of the efficiency of vision and language information transmission in the language decoder of LVLMs. Then, we propose a novel hierarchical vision-language interaction mechanism called Hierarchical Vision injection for Mixture Attention (HiMix). In HiMix, only the language sequence undergoes full forward propagation, while the vision sequence interacts with the language at specific stages within each language decoder layer. It is striking that our approach significantly reduces computational complexity with minimal performance loss. Specifically, HiMix achieves a 10x reduction in the computational cost of the language decoder across multiple LVLM models while maintaining comparable performance. This highlights the advantages of our method, and we hope our research brings new perspectives to the field of vision-language understanding. Project Page: <a target="_blank" rel="noopener" href="https://xuange923.github.io/HiMix">https://xuange923.github.io/HiMix</a> </p>
<blockquote>
<p>å¾—ç›Šäºå¤§å‹è¯­è¨€æ¨¡å‹å’Œæ¨¡æ€å¯¹é½æŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œç°æœ‰çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨å¤šç§åœºæ™¯ä¸­å‡å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿‡é«˜çš„è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†è¿™äº›æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›ä½¿ç”¨ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè®¡ç®—å¤æ‚åº¦çš„ä¸€ä¸ªä¸»è¦ç“¶é¢ˆæ˜¯ç”±æ¨¡å‹è®¡ç®—ä¸­å†—ä½™çš„è§†è§‰åºåˆ—çš„å‚ä¸æ‰€å¼•èµ·çš„ã€‚è¿™æºäºæˆ‘ä»¬å¯¹LVLMsè¯­è¨€è§£ç å™¨ä¸­è§†è§‰å’Œè¯­è¨€ä¿¡æ¯ä¼ è¾“æ•ˆç‡çš„é‡æ–°è¯„ä¼°ã€‚éšåï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åˆ†å±‚è§†è§‰è¯­è¨€äº¤äº’æœºåˆ¶ï¼Œç§°ä¸ºæ··åˆæ³¨æ„åŠ›åˆ†å±‚è§†è§‰æ³¨å…¥ï¼ˆHiMixï¼‰ã€‚åœ¨HiMixä¸­ï¼Œåªæœ‰è¯­è¨€åºåˆ—è¿›è¡Œå…¨å‰å‘ä¼ æ’­ï¼Œè€Œè§†è§‰åºåˆ—åˆ™åœ¨æ¯ä¸ªè¯­è¨€è§£ç å™¨å±‚çš„ç‰¹å®šé˜¶æ®µä¸è¯­è¨€è¿›è¡Œäº¤äº’ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½åœ¨ä¿æŒæå°æ€§èƒ½æŸå¤±çš„åŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ã€‚å…·ä½“æ¥è¯´ï¼ŒHiMixåœ¨å¤šä¸ªLVLMæ¨¡å‹çš„è¯­è¨€è§£ç å™¨ä¸Šå®ç°äº†è®¡ç®—æˆæœ¬çš„10å€ç¼©å‡ï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„æ€§èƒ½ã€‚è¿™å‡¸æ˜¾äº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œæˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶èƒ½ä¸ºè§†è§‰è¯­è¨€ç†è§£é¢†åŸŸå¸¦æ¥æ–°çš„è§†è§’ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://xuange923.github.io/HiMix">https://xuange923.github.io/HiMix</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10318v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹å’Œæ¨¡æ€å¯¹é½æŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å·²åœ¨å„ç§åœºæ™¯ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ç„¶è€Œï¼Œè¿‡é«˜çš„è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†è¿™äº›æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚æœ¬ç ”ç©¶è®¤ä¸ºå†—ä½™çš„è§†è§‰åºåˆ—å‚ä¸æ¨¡å‹è®¡ç®—æ˜¯å¯¼è‡´è®¡ç®—å¤æ‚åº¦è¿‡é«˜çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åˆ†å±‚è§†è§‰è¯­è¨€äº¤äº’æœºåˆ¶ï¼Œç§°ä¸ºåˆ†å±‚è§†è§‰æ³¨å…¥æ··åˆæ³¨æ„åŠ›ï¼ˆHiMixï¼‰ã€‚åœ¨HiMixä¸­ï¼Œåªæœ‰è¯­è¨€åºåˆ—è¿›è¡Œå…¨å‰å‘ä¼ æ’­ï¼Œè€Œè§†è§‰åºåˆ—åˆ™åœ¨æ¯ä¸ªè¯­è¨€è§£ç å™¨å±‚çš„ç‰¹å®šé˜¶æ®µä¸è¯­è¨€è¿›è¡Œäº¤äº’ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿è¯æ€§èƒ½æŸå¤±æœ€å°çš„æƒ…å†µä¸‹æ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚å…·ä½“æ¥è¯´ï¼ŒHiMixåœ¨å¤šä¸ªLVLMæ¨¡å‹ä¸­å®ç°äº†è¯­è¨€è§£ç å™¨è®¡ç®—æˆæœ¬çš„10å€ç¼©å‡ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨å¤šç§åœºæ™¯ä¸­çš„æ€§èƒ½çªå‡ºï¼Œä½†è®¡ç®—å¤æ‚åº¦è¿‡é«˜é™åˆ¶äº†å®é™…åº”ç”¨ã€‚</li>
<li>å†—ä½™çš„è§†è§‰åºåˆ—å‚ä¸æ¨¡å‹è®¡ç®—æ˜¯å¯¼è‡´è®¡ç®—å¤æ‚åº¦é«˜çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚</li>
<li>æå‡ºäº†æ–°å‹çš„åˆ†å±‚è§†è§‰è¯­è¨€äº¤äº’æœºåˆ¶â€”â€”åˆ†å±‚è§†è§‰æ³¨å…¥æ··åˆæ³¨æ„åŠ›ï¼ˆHiMixï¼‰ã€‚</li>
<li>åœ¨HiMixä¸­ï¼Œåªæœ‰è¯­è¨€åºåˆ—è¿›è¡Œå…¨å‰å‘ä¼ æ’­ï¼Œè§†è§‰åºåˆ—åˆ™åœ¨ç‰¹å®šé˜¶æ®µä¸è¯­è¨€äº¤äº’ã€‚</li>
<li>HiMixæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå®ç°äº†è¯­è¨€è§£ç å™¨è®¡ç®—æˆæœ¬çš„10å€ç¼©å‡ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ç›¸å½“ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10318">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ab98bafc0f62ea091954ef242754c419.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1c08802412e896867f4ca5efe9b15cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f69725e932a6bc774637f873a980520b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-283455534c9ee4426cdb89a80192a84b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c16449b4cc6ef69f358ded9f621de95e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d2866620bb060c58867ebc4f8607799a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a240108800143b400ba5eb445c479b86.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Addressing-Popularity-Bias-in-Third-Party-Library-Recommendations-Using-LLMs"><a href="#Addressing-Popularity-Bias-in-Third-Party-Library-Recommendations-Using-LLMs" class="headerlink" title="Addressing Popularity Bias in Third-Party Library Recommendations Using   LLMs"></a>Addressing Popularity Bias in Third-Party Library Recommendations Using   LLMs</h2><p><strong>Authors:Claudio Di Sipio, Juri Di Rocco, Davide Di Ruscio, Vladyslav Bulhakov</strong></p>
<p>Recommender systems for software engineering (RSSE) play a crucial role in automating development tasks by providing relevant suggestions according to the developerâ€™s context. However, they suffer from the so-called popularity bias, i.e., the phenomenon of recommending popular items that might be irrelevant to the current task. In particular, the long-tail effect can hamper the systemâ€™s performance in terms of accuracy, thus leading to false positives in the provided recommendations. Foundation models are the most advanced generative AI-based models that achieve relevant results in several SE tasks.   This paper aims to investigate the capability of large language models (LLMs) to address the popularity bias in recommender systems of third-party libraries (TPLs). We conduct an ablation study experimenting with state-of-the-art techniques to mitigate the popularity bias, including fine-tuning and popularity penalty mechanisms. Our findings reveal that the considered LLMs cannot address the popularity bias in TPL recommenders, even though fine-tuning and post-processing penalty mechanism contributes to increasing the overall diversity of the provided recommendations. In addition, we discuss the limitations of LLMs in this context and suggest potential improvements to address the popularity bias in TPL recommenders, thus paving the way for additional experiments in this direction. </p>
<blockquote>
<p>è½¯ä»¶å·¥ç¨‹çš„æ¨èç³»ç»Ÿï¼ˆRSSEï¼‰æ ¹æ®å¼€å‘è€…çš„ä¸Šä¸‹æ–‡æä¾›ç›¸å…³çš„å»ºè®®ï¼Œåœ¨è‡ªåŠ¨åŒ–å¼€å‘ä»»åŠ¡ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œå®ƒä»¬å­˜åœ¨æ‰€è°“çš„æµè¡Œåè§ï¼Œå³æ¨èæµè¡Œé¡¹ç›®ï¼Œè€Œè¿™äº›é¡¹ç›®å¯èƒ½ä¸å½“å‰ä»»åŠ¡æ— å…³çš„ç°è±¡ã€‚ç‰¹åˆ«æ˜¯ï¼Œé•¿å°¾æ•ˆåº”å¯èƒ½ä¼šé˜»ç¢ç³»ç»Ÿåœ¨å‡†ç¡®æ€§æ–¹é¢çš„æ€§èƒ½ï¼Œä»è€Œå¯¼è‡´æä¾›çš„æ¨èä¸­å‡ºç°è¯¯æŠ¥ã€‚åŸºç¡€æ¨¡å‹æ˜¯æœ€å…ˆè¿›çš„åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æ¨¡å‹ï¼Œåœ¨å¤šä¸ªè½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­å–å¾—äº†ç›¸å…³çš„ç»“æœã€‚æœ¬æ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§£å†³ç¬¬ä¸‰æ–¹åº“ï¼ˆTPLï¼‰æ¨èç³»ç»Ÿä¸­æµè¡Œåè§çš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹æ¶ˆèç ”ç©¶ï¼Œå°è¯•ä½¿ç”¨æœ€å…ˆè¿›çš„æŠ€æœ¯æ¥å‡è½»æµè¡Œåè§ï¼ŒåŒ…æ‹¬å¾®è°ƒå’Œåå¤„ç†æƒ©ç½šæœºåˆ¶ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œæ‰€è€ƒè™‘çš„LLMæ— æ³•è§£å†³TPLæ¨èç³»ç»Ÿä¸­çš„æµè¡Œåè§é—®é¢˜ï¼Œå°½ç®¡å¾®è°ƒå’Œåå¤„ç†æƒ©ç½šæœºåˆ¶æœ‰åŠ©äºæé«˜æ‰€æä¾›å»ºè®®çš„æ€»ä½“å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¨è®ºäº†åœ¨è¿™ç§æƒ…å†µä¸‹LLMçš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†è§£å†³TPLæ¨èç³»ç»Ÿä¸­æµè¡Œåè§é—®é¢˜çš„æ½œåœ¨æ”¹è¿›æ–¹æ³•ï¼Œä»è€Œä¸ºä»Šåçš„å®éªŒæŒ‡æ˜äº†æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10313v1">PDF</a> Accepted at the 1st International Workshop on Fairness in Software   Systems, co-located with SANER2025</p>
<p><strong>Summary</strong><br>æ¨èç³»ç»Ÿå¯¹äºè½¯ä»¶å·¥ç¨‹æ¥è¯´éå¸¸é‡è¦ï¼Œèƒ½å¤Ÿæ ¹æ®å¼€å‘è€…çš„ä¸Šä¸‹æ–‡æä¾›ç›¸å…³çš„å»ºè®®ï¼Œè‡ªåŠ¨åŒ–å¼€å‘ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå®ƒä»¬å—åˆ°æ‰€è°“çš„æµè¡Œåº¦åå·®çš„å½±å“ï¼Œæ¨èæµè¡Œé¡¹ç›®å¯èƒ½ä¸å½“å‰ä»»åŠ¡æ— å…³ã€‚æœ¬æ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§£å†³ç¬¬ä¸‰æ–¹åº“æ¨èç³»ç»Ÿä¸­çš„æµè¡Œåº¦åå·®çš„èƒ½åŠ›ã€‚é€šè¿‡é‡‡ç”¨å…ˆè¿›æŠ€æœ¯æ¥å‡è½»æµè¡Œåº¦åå·®ï¼ŒåŒ…æ‹¬å¾®è°ƒå’Œåå¤„ç†æƒ©ç½šæœºåˆ¶ï¼Œå‘ç°LLMæ— æ³•è§£å†³TPLæ¨èç³»ç»Ÿä¸­çš„æµè¡Œåº¦åå·®é—®é¢˜ã€‚å°½ç®¡å¾®è°ƒå’Œåå¤„ç†æƒ©ç½šæœºåˆ¶æœ‰åŠ©äºæé«˜æ¨èçš„æ€»ä½“å¤šæ ·æ€§ï¼Œä½†ä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨èç³»ç»Ÿå¯¹è½¯ä»¶å·¥ç¨‹è‡³å…³é‡è¦ï¼Œå¯è‡ªåŠ¨åŒ–å¼€å‘ä»»åŠ¡å¹¶æä¾›ç›¸å…³å»ºè®®ã€‚</li>
<li>æ¨èç³»ç»Ÿå­˜åœ¨æµè¡Œåº¦åå·®é—®é¢˜ï¼Œå³æ¨èæµè¡Œé¡¹ç›®å¯èƒ½ä¸å½“å‰ä»»åŠ¡æ— å…³ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¢«ç ”ç©¶ç”¨äºè§£å†³ç¬¬ä¸‰æ–¹åº“æ¨èç³»ç»Ÿä¸­çš„æµè¡Œåº¦åå·®é—®é¢˜ã€‚</li>
<li>é€šè¿‡é‡‡ç”¨å…ˆè¿›æŠ€æœ¯æ¥å‡è½»æµè¡Œåº¦åå·®ï¼ŒåŒ…æ‹¬å¾®è°ƒå’Œåå¤„ç†æƒ©ç½šæœºåˆ¶ã€‚</li>
<li>LLMæ— æ³•è§£å†³TPLæ¨èç³»ç»Ÿä¸­çš„æµè¡Œåº¦åå·®é—®é¢˜ã€‚</li>
<li>å³ä½¿æœ‰è¡¥æ•‘æªæ–½ï¼Œæ¨èç³»ç»Ÿä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10313">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ba41fbcdc24b35d81292b7bc3e59022e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-963a1d255447ace9d429f5d554da8ab3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8b90b86432a292253c48dc003b7bbde1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a268f7c1f002d4d465b645ce1e3b95ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ec41332145feaafc31430a7c929ffef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ecbb8c6d9a1dc97060913e5b6eb3dce3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fe8e97c43879adf487bc92111450b00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8716599235a251bd39f5bfca193798bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-88b8234a29cc132cc4ec8e737481c341.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Test-Wars-A-Comparative-Study-of-SBST-Symbolic-Execution-and-LLM-Based-Approaches-to-Unit-Test-Generation"><a href="#Test-Wars-A-Comparative-Study-of-SBST-Symbolic-Execution-and-LLM-Based-Approaches-to-Unit-Test-Generation" class="headerlink" title="Test Wars: A Comparative Study of SBST, Symbolic Execution, and   LLM-Based Approaches to Unit Test Generation"></a>Test Wars: A Comparative Study of SBST, Symbolic Execution, and   LLM-Based Approaches to Unit Test Generation</h2><p><strong>Authors:Azat Abdullin, Pouria Derakhshanfar, Annibale Panichella</strong></p>
<p>Generating tests automatically is a key and ongoing area of focus in software engineering research. The emergence of Large Language Models (LLMs) has opened up new opportunities, given their ability to perform a wide spectrum of tasks. However, the effectiveness of LLM-based approaches compared to traditional techniques such as search-based software testing (SBST) and symbolic execution remains uncertain. In this paper, we perform an extensive study of automatic test generation approaches based on three tools: EvoSuite for SBST, Kex for symbolic execution, and TestSpark for LLM-based test generation. We evaluate tools performance on the GitBug Java dataset and compare them using various execution-based and feature-based metrics. Our results show that while LLM-based test generation is promising, it falls behind traditional methods in terms of coverage. However, it significantly outperforms them in mutation scores, suggesting that LLMs provide a deeper semantic understanding of code. LLM-based approach also performed worse than SBST and symbolic execution-based approaches w.r.t. fault detection capabilities. Additionally, our feature-based analysis shows that all tools are primarily affected by the complexity and internal dependencies of the class under test (CUT), with LLM-based approaches being especially sensitive to the CUT size. </p>
<blockquote>
<p>è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ˜¯è½¯ä»¶å·¥ç¨‹ç ”ç©¶çš„å…³é”®å’ŒæŒç»­å…³æ³¨çš„é¢†åŸŸã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ä¸ºå…¶æä¾›äº†æ–°çš„æœºé‡ï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿæ‰§è¡Œå„ç§ä»»åŠ¡ã€‚ç„¶è€Œï¼Œä¸åŸºäºæœç´¢çš„è½¯ä»¶æµ‹è¯•ï¼ˆSBSTï¼‰å’Œç¬¦å·æ‰§è¡Œç­‰ä¼ ç»ŸæŠ€æœ¯ç›¸æ¯”ï¼ŒLLMæ–¹æ³•çš„æœ‰æ•ˆæ€§ä»ç„¶ä¸ç¡®å®šã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹åŸºäºä¸‰ç§å·¥å…·çš„è‡ªåŠ¨æµ‹è¯•ç”Ÿæˆæ–¹æ³•è¿›è¡Œäº†å¹¿æ³›çš„ç ”ç©¶ï¼šç”¨äºSBSTçš„EvoSuiteï¼Œç”¨äºç¬¦å·æ‰§è¡Œçš„Kexï¼Œä»¥åŠç”¨äºLLMæµ‹è¯•ç”Ÿæˆçš„TestSparkã€‚æˆ‘ä»¬åœ¨GitBug Javaæ•°æ®é›†ä¸Šè¯„ä¼°äº†è¿™äº›å·¥å…·çš„æ€§èƒ½ï¼Œå¹¶ä½¿ç”¨å„ç§åŸºäºæ‰§è¡Œå’ŒåŸºäºç‰¹å¾çš„æ€§èƒ½æŒ‡æ ‡è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè™½ç„¶åŸºäºLLMçš„æµ‹è¯•ç”Ÿæˆå…·æœ‰å‰æ™¯ï¼Œä½†åœ¨è¦†ç›–ç‡æ–¹é¢è½åäºä¼ ç»Ÿæ–¹æ³•ã€‚ç„¶è€Œï¼Œå®ƒåœ¨çªå˜å¾—åˆ†æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œè¿™è¡¨æ˜LLMå¯¹ä»£ç å…·æœ‰æ›´æ·±è¯­ä¹‰ç†è§£ã€‚å°±æ•…éšœæ£€æµ‹èƒ½åŠ›è€Œè¨€ï¼ŒåŸºäºLLMçš„æ–¹æ³•ä¹Ÿè¡¨ç°è¾ƒå·®é€ŠäºSBSTå’Œç¬¦å·æ‰§è¡Œæ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„åŸºäºç‰¹å¾çš„åˆ†æè¡¨æ˜ï¼Œæ‰€æœ‰å·¥å…·ä¸»è¦å—åˆ°æµ‹è¯•ç±»ï¼ˆCUTï¼‰çš„å¤æ‚æ€§åŠå…¶å†…éƒ¨ä¾èµ–æ€§çš„å½±å“ï¼Œè€ŒåŸºäºLLMçš„æ–¹æ³•å°¤å…¶å—åˆ°CUTå¤§å°çš„å½±å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10200v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LLMåœ¨è‡ªåŠ¨æµ‹è¯•ç”Ÿæˆé¢†åŸŸå…·æœ‰æ½œåŠ›ï¼Œä½†ä¸ä¼ ç»Ÿçš„åŸºäºæœç´¢çš„è½¯ä»¶æµ‹è¯•ï¼ˆSBSTï¼‰å’Œç¬¦å·æ‰§è¡ŒæŠ€æœ¯ç›¸æ¯”ï¼Œå…¶æ•ˆæœå°šä¸ç¡®å®šã€‚ä¸€é¡¹æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œåœ¨åŸºäºä¸‰ç§å·¥å…·çš„è‡ªåŠ¨æµ‹è¯•ç”Ÿæˆæ–¹æ³•ï¼ˆEvoSuite for SBSTï¼ŒKex forç¬¦å·æ‰§è¡Œï¼ŒTestSpark for LLMï¼‰çš„å¯¹æ¯”è¯„ä¼°ä¸­ï¼ŒLLMè™½ç„¶åœ¨è¦†ç›–ç‡æ–¹é¢è¡¨ç°è¾ƒå¼±ï¼Œä½†åœ¨çªå˜å¾—åˆ†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾ç¤ºå‡ºå¯¹ä»£ç æ›´æ·±å±‚çš„è¯­ä¹‰ç†è§£ã€‚ç„¶è€Œï¼Œåœ¨æ•…éšœæ£€æµ‹èƒ½åŠ›æ–¹é¢ï¼ŒLLMä»è½åäºSBSTå’Œç¬¦å·æ‰§è¡Œã€‚æ­¤å¤–ï¼Œç‰¹å¾åˆ†æè¡¨æ˜ï¼Œæ‰€æœ‰å·¥å…·ä¸»è¦å—æµ‹è¯•ç±»ï¼ˆCUTï¼‰çš„å¤æ‚æ€§å’Œå†…éƒ¨ä¾èµ–æ€§çš„å½±å“ï¼Œå…¶ä¸­LLMå¯¹CUTå¤§å°å°¤ä¸ºæ•æ„Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨è‡ªåŠ¨æµ‹è¯•ç”Ÿæˆä¸­å…·æœ‰æ½œåŠ›ï¼Œä½†ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ•ˆæœå¯¹æ¯”å°šä¸ç¡®å®šã€‚</li>
<li>LLMåœ¨çªå˜å¾—åˆ†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾ç¤ºå‡ºå¯¹ä»£ç æ·±å±‚çš„è¯­ä¹‰ç†è§£ã€‚</li>
<li>åœ¨è¦†ç›–ç‡æ–¹é¢ï¼ŒLLMè¡¨ç°è¾ƒå¼±ï¼Œè½åäºä¼ ç»Ÿçš„SBSTå’Œç¬¦å·æ‰§è¡ŒæŠ€æœ¯ã€‚</li>
<li>LLMåœ¨æ•…éšœæ£€æµ‹èƒ½åŠ›æ–¹é¢ä»è½åäºSBSTå’Œç¬¦å·æ‰§è¡Œã€‚</li>
<li>æ‰€æœ‰æµ‹è¯•å·¥å…·éƒ½å—æµ‹è¯•ç±»ï¼ˆCUTï¼‰çš„å¤æ‚æ€§å’Œå†…éƒ¨ä¾èµ–æ€§çš„å½±å“ã€‚</li>
<li>LLMå¯¹CUTå¤§å°å°¤ä¸ºæ•æ„Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10200">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c74940af13ab3114a73b9666ae0e39f3.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-21\./crop_LLM/2501.10200v1/page_2_0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c26454058be1f8d50d2f480ccbd6b991.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e2f5481d98d7ddcdb5ab4860637cd4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-747e6c4b9a544c2c8269d64089783ddd.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Generative-Artificial-Intelligence-Implications-for-Biomedical-and-Health-Professions-Education"><a href="#Generative-Artificial-Intelligence-Implications-for-Biomedical-and-Health-Professions-Education" class="headerlink" title="Generative Artificial Intelligence: Implications for Biomedical and   Health Professions Education"></a>Generative Artificial Intelligence: Implications for Biomedical and   Health Professions Education</h2><p><strong>Authors:William Hersh</strong></p>
<p>Generative AI has had a profound impact on biomedicine and health, both in professional work and in education. Based on large language models (LLMs), generative AI has been found to perform as well as humans in simulated situations taking medical board exams, answering clinical questions, solving clinical cases, applying clinical reasoning, and summarizing information. Generative AI is also being used widely in education, performing well in academic courses and their assessments. This review summarizes the successes of LLMs and highlights some of their challenges in the context of education, most notably aspects that may undermines the acquisition of knowledge and skills for professional work. It then provides recommendations for best practices overcoming shortcomings for LLM use in education. Although there are challenges for use of generative AI in education, all students and faculty, in biomedicine and health and beyond, must have understanding and be competent in its use. </p>
<blockquote>
<p>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨ç”Ÿç‰©åŒ»å­¦å’Œå¥åº·é¢†åŸŸäº§ç”Ÿäº†æ·±è¿œå½±å“ï¼Œæ— è®ºæ˜¯åœ¨ä¸“ä¸šå·¥ä½œè¿˜æ˜¯åœ¨æ•™è‚²ä¸­éƒ½æ˜¯å¦‚æ­¤ã€‚åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨æ¨¡æ‹Ÿçš„åŒ»ç–—è€ƒè¯•ã€å›ç­”ä¸´åºŠé—®é¢˜ã€è§£å†³ä¸´åºŠç—…ä¾‹ã€åº”ç”¨ä¸´åºŠæ¨ç†å’Œä¿¡æ¯æ€»ç»“ç­‰æƒ…å¢ƒä¸­ï¼Œè¢«å‘ç°çš„è¡¨ç°ä¸äººç±»ç›¸å½“ã€‚ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¹Ÿåœ¨æ•™è‚²ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œåœ¨å­¦æœ¯è¯¾ç¨‹å’Œè¯„ä¼°ä¸­è¡¨ç°è‰¯å¥½ã€‚è¿™ç¯‡ç»¼è¿°æ€»ç»“äº†LLMçš„æˆåŠŸä¹‹å¤„ï¼Œå¹¶å¼ºè°ƒäº†å®ƒä»¬åœ¨æ•™è‚²ç¯å¢ƒä¸­çš„ä¸€äº›æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯é‚£äº›å¯èƒ½ä¼šç ´åä¸“ä¸šå·¥ä½œçš„çŸ¥è¯†å’ŒæŠ€èƒ½è·å–æ–¹é¢ã€‚ç„¶åï¼Œå®ƒä¸ºå…‹æœåœ¨æ•™è‚²ä¸­ä½¿ç”¨LLMçš„ç¼ºé™·çš„æœ€ä½³å®è·µæä¾›äº†å»ºè®®ã€‚å°½ç®¡åœ¨æ•™è‚²é¢†åŸŸä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å­˜åœ¨æŒ‘æˆ˜ï¼Œä½†ç”Ÿç‰©åŒ»å­¦å’Œå¥åº·é¢†åŸŸä»¥åŠæ›´å¹¿æ³›çš„å­¦ç”Ÿå’Œæ•™å¸ˆéƒ½å¿…é¡»ç†è§£å¹¶ç†Ÿç»ƒä½¿ç”¨å®ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10186v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç”Ÿæˆæ€§äººå·¥æ™ºèƒ½åœ¨ç”Ÿç‰©åŒ»å­¦å’Œå¥åº·é¢†åŸŸäº§ç”Ÿäº†æ·±è¿œå½±å“ï¼Œä¸ä»…åœ¨ä¸“ä¸šå·¥ä½œä¸­è¡¨ç°å‡ºè‰²ï¼Œä¹Ÿåœ¨æ•™è‚²ä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚åœ¨æ¨¡æ‹ŸåŒ»å­¦è€ƒè¯•ã€å›ç­”ä¸´åºŠé—®é¢˜ã€è§£å†³ä¸´åºŠç—…ä¾‹ã€åº”ç”¨ä¸´åºŠæ¨ç†å’Œä¿¡æ¯æ€»ç»“ç­‰æ–¹é¢ï¼Œç”Ÿæˆæ€§äººå·¥æ™ºèƒ½çš„è¡¨ç°ä¸äººç±»ç›¸å½“ã€‚ç„¶è€Œï¼Œåœ¨æ•™è‚²ç¯å¢ƒä¸­ï¼Œå®ƒä¹Ÿé¢ä¸´ç€ä¸€äº›æŒ‘æˆ˜ï¼Œå¯èƒ½ä¼šå½±å“åˆ°ä¸“ä¸šå·¥ä½œä¸­çŸ¥è¯†å’ŒæŠ€èƒ½çš„åŸ¹å…»ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ€»ç»“äº†LLMçš„æˆåŠŸåº”ç”¨ï¼Œå¼ºè°ƒäº†å…¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æä¾›äº†å…‹æœè¿™äº›æŒ‘æˆ˜çš„æœ€ä½³å®è·µå»ºè®®ã€‚å°½ç®¡å­˜åœ¨æŒ‘æˆ˜ï¼Œä½†æ‰€æœ‰ç”Ÿç‰©åŒ»å­¦å’Œå¥åº·é¢†åŸŸçš„å­¦ç”Ÿå’Œæ•™å¸ˆéƒ½éœ€è¦äº†è§£å¹¶ç†Ÿç»ƒä½¿ç”¨ç”Ÿæˆæ€§äººå·¥æ™ºèƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç”Ÿæˆæ€§AIåœ¨ç”Ÿç‰©åŒ»å­¦å’Œå¥åº·é¢†åŸŸæœ‰æ·±è¿œå½±å“ï¼Œåœ¨ä¸“ä¸šå·¥ä½œå’Œæ•™è‚²ä¸­éƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>åœ¨æ¨¡æ‹ŸåŒ»å­¦è€ƒè¯•ã€å›ç­”ä¸´åºŠé—®é¢˜ç­‰æ–¹é¢ï¼Œç”Ÿæˆæ€§AIçš„è¡¨ç°ä¸äººç±»ç›¸å½“ã€‚</li>
<li>ç”Ÿæˆæ€§AIåœ¨æ•™è‚²ç¯å¢ƒä¸­å­˜åœ¨ä¸€äº›æŒ‘æˆ˜ï¼Œå¯èƒ½å½±å“çŸ¥è¯†åŠæŠ€èƒ½çš„ä¹ å¾—ã€‚</li>
<li>LLMçš„æˆåŠŸåº”ç”¨éœ€è¦å…‹æœä¸€äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æä¾›äº†å…‹æœæŒ‘æˆ˜çš„æœ€ä½³å®è·µå»ºè®®ã€‚</li>
<li>ç”Ÿæˆæ€§AIåœ¨æ•™è‚²ä¸­å­˜åœ¨æŒ‘æˆ˜ï¼Œä½†å­¦ç”Ÿä¸æ•™å¸ˆä»éœ€æŒæ¡å…¶ä½¿ç”¨ã€‚</li>
<li>ç”Ÿæˆæ€§AIçš„æ½œåŠ›åœ¨äºå…¶èƒ½å¤Ÿå¤„ç†å¤§é‡æ•°æ®å’Œå¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>åœ¨æ•™è‚²ç¯å¢ƒä¸­ä½¿ç”¨ç”Ÿæˆæ€§AIæ—¶éœ€è¦æ³¨æ„ä¿æŠ¤å­¦ç”Ÿéšç§å’Œæ•°æ®å®‰å…¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10186">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a86bcf3a5473a32ec0fb947e788d402f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0fa44218f4684fce6611c20912d5e330.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ac06db05bb6f51f9ed41a02d4518a11a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9906e20b26302570256825896bdc243d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="ComplexFuncBench-Exploring-Multi-Step-and-Constrained-Function-Calling-under-Long-Context-Scenario"><a href="#ComplexFuncBench-Exploring-Multi-Step-and-Constrained-Function-Calling-under-Long-Context-Scenario" class="headerlink" title="ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling   under Long-Context Scenario"></a>ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling   under Long-Context Scenario</h2><p><strong>Authors:Lucen Zhong, Zhengxiao Du, Xiaohan Zhang, Haiyi Hu, Jie Tang</strong></p>
<p>Enhancing large language models (LLMs) with real-time APIs can help generate more accurate and up-to-date responses. However, evaluating the function calling abilities of LLMs in real-world scenarios remains under-explored due to the complexity of data collection and evaluation. In this work, we introduce ComplexFuncBench, a benchmark for complex function calling across five real-world scenarios. Compared to existing benchmarks, ComplexFuncBench encompasses multi-step and constrained function calling, which requires long-parameter filing, parameter value reasoning, and 128k long context. Additionally, we propose an automatic framework, ComplexEval, for quantitatively evaluating complex function calling tasks. Through comprehensive experiments, we demonstrate the deficiencies of state-of-the-art LLMs in function calling and suggest future directions for optimizing these capabilities. The data and code are available at \url{<a target="_blank" rel="noopener" href="https://github.com/THUDM/ComplexFuncBench%7D">https://github.com/THUDM/ComplexFuncBench}</a>. </p>
<blockquote>
<p>å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®æ—¶APIå¯ä»¥å¸®åŠ©ç”Ÿæˆæ›´å‡†ç¡®å’Œæœ€æ–°çš„å“åº”ã€‚ç„¶è€Œï¼Œç”±äºæ•°æ®æ”¶é›†å’Œè¯„ä¼°çš„å¤æ‚æ€§ï¼Œåœ¨çœŸå®åœºæ™¯ä¸­è¯„ä¼°LLMçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ä»ç„¶è¢«ä½ä¼°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ComplexFuncBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–äº”ç§çœŸå®åœºæ™¯å¤æ‚å‡½æ•°è°ƒç”¨çš„åŸºå‡†æµ‹è¯•ã€‚ä¸ç°æœ‰åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒComplexFuncBenchåŒ…æ‹¬å¤šæ­¥éª¤å’Œå—çº¦æŸçš„å‡½æ•°è°ƒç”¨ï¼Œè¿™éœ€è¦é•¿å‚æ•°æ–‡ä»¶ã€å‚æ•°å€¼æ¨ç†å’Œ128ké•¿ä¸Šä¸‹æ–‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè‡ªåŠ¨æ¡†æ¶ComplexEvalï¼Œç”¨äºå®šé‡è¯„ä¼°å¤æ‚çš„å‡½æ•°è°ƒç”¨ä»»åŠ¡ã€‚é€šè¿‡å…¨é¢çš„å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†å½“å‰LLMåœ¨å‡½æ•°è°ƒç”¨æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶æŒ‡å‡ºäº†ä¼˜åŒ–è¿™äº›èƒ½åŠ›çš„æœªæ¥æ–¹å‘ã€‚æ•°æ®å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/THUDM/ComplexFuncBench%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/THUDM/ComplexFuncBenchæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10132v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å®æ—¶APIå¯ä»¥ç”Ÿæˆæ›´å‡†ç¡®å’Œæœ€æ–°çš„å“åº”ã€‚ç„¶è€Œï¼Œç”±äºæ•°æ®æ”¶é›†å’Œè¯„ä¼°çš„å¤æ‚æ€§ï¼Œåœ¨çœŸå®åœºæ™¯ä¸­è¯„ä¼°LLMçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ä»å¤„äºæ¢ç´¢é˜¶æ®µã€‚æœ¬å·¥ä½œå¼•å…¥äº†ä¸€ä¸ªå¤æ‚å‡½æ•°è°ƒç”¨åŸºå‡†æµ‹è¯•ï¼ˆComplexFuncBenchï¼‰ï¼Œæ¶µç›–äº”ç§çœŸå®åœºæ™¯ä¸‹çš„å¤æ‚å‡½æ•°è°ƒç”¨ã€‚ç›¸è¾ƒäºç°æœ‰åŸºå‡†æµ‹è¯•ï¼ŒComplexFuncBenchåŒ…å«å¤šæ­¥éª¤å’Œå—çº¦æŸçš„å‡½æ•°è°ƒç”¨ï¼Œè¿™éœ€è¦é•¿å‚æ•°æ–‡ä»¶ã€å‚æ•°å€¼æ¨ç†å’Œ128ké•¿ä¸Šä¸‹æ–‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªè‡ªåŠ¨è¯„ä¼°æ¡†æ¶ï¼ˆComplexEvalï¼‰ï¼Œç”¨äºå®šé‡è¯„ä¼°å¤æ‚å‡½æ•°è°ƒç”¨ä»»åŠ¡ã€‚é€šè¿‡å…¨é¢çš„å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†å½“å‰LLMåœ¨å‡½æ•°è°ƒç”¨æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶æŒ‡å‡ºäº†ä¼˜åŒ–è¿™äº›èƒ½åŠ›çš„æœªæ¥æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMé€šè¿‡å®æ—¶APIå¯æå‡ç”Ÿæˆå“åº”çš„å‡†ç¡®æ€§å’Œå®æ—¶æ€§ã€‚</li>
<li>è¯„ä¼°LLMçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›åœ¨çœŸå®åœºæ™¯ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªè¢«å¿½è§†çš„é¢†åŸŸã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å¤æ‚å‡½æ•°è°ƒç”¨åŸºå‡†æµ‹è¯•ï¼ˆComplexFuncBenchï¼‰ï¼Œæ¶µç›–äº”ç§çœŸå®åœºæ™¯ã€‚</li>
<li>ComplexFuncBenchåŒ…æ‹¬å¤šæ­¥éª¤å’Œå—çº¦æŸçš„å‡½æ•°è°ƒç”¨ï¼Œè¦æ±‚é«˜çº§å‚æ•°å¤„ç†å’Œä¸Šä¸‹æ–‡ç†è§£ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªè‡ªåŠ¨è¯„ä¼°æ¡†æ¶ï¼ˆComplexEvalï¼‰æ¥å®šé‡è¯„ä¼°å¤æ‚å‡½æ•°è°ƒç”¨ä»»åŠ¡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œå½“å‰LLMåœ¨å‡½æ•°è°ƒç”¨æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10132">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c36593a4333a5e8adf37667697072132.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7cf60c59091aad72dc693ab1a0a6431.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-76159489d0e2c7d08723fd6d95a47976.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-421fb73d7c90325d487f51b240002992.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="PaSa-An-LLM-Agent-for-Comprehensive-Academic-Paper-Search"><a href="#PaSa-An-LLM-Agent-for-Comprehensive-Academic-Paper-Search" class="headerlink" title="PaSa: An LLM Agent for Comprehensive Academic Paper Search"></a>PaSa: An LLM Agent for Comprehensive Academic Paper Search</h2><p><strong>Authors:Yichen He, Guanhua Huang, Peiyuan Feng, Yuan Lin, Yuchen Zhang, Hang Li, Weinan E</strong></p>
<p>We introduce PaSa, an advanced Paper Search agent powered by large language models. PaSa can autonomously make a series of decisions, including invoking search tools, reading papers, and selecting relevant references, to ultimately obtain comprehensive and accurate results for complex scholarly queries. We optimize PaSa using reinforcement learning with a synthetic dataset, AutoScholarQuery, which includes 35k fine-grained academic queries and corresponding papers sourced from top-tier AI conference publications. Additionally, we develop RealScholarQuery, a benchmark collecting real-world academic queries to assess PaSa performance in more realistic scenarios. Despite being trained on synthetic data, PaSa significantly outperforms existing baselines on RealScholarQuery, including Google, Google Scholar, Google with GPT-4 for paraphrased queries, chatGPT (search-enabled GPT-4o), GPT-o1, and PaSa-GPT-4o (PaSa implemented by prompting GPT-4o). Notably, PaSa-7B surpasses the best Google-based baseline, Google with GPT-4o, by 37.78% in recall@20 and 39.90% in recall@50. It also exceeds PaSa-GPT-4o by 30.36% in recall and 4.25% in precision. Model, datasets, and code are available at <a target="_blank" rel="noopener" href="https://github.com/bytedance/pasa">https://github.com/bytedance/pasa</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†PaSaï¼Œè¿™æ˜¯ä¸€æ¬¾ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é«˜çº§è®ºæ–‡æœç´¢ä»£ç†ã€‚PaSaå¯ä»¥è‡ªä¸»åšå‡ºä¸€ç³»åˆ—å†³ç­–ï¼ŒåŒ…æ‹¬è°ƒç”¨æœç´¢å·¥å…·ã€é˜…è¯»è®ºæ–‡å’Œé€‰æ‹©ç›¸å…³å‚è€ƒæ–‡çŒ®ï¼Œä»¥è·å–é’ˆå¯¹å¤æ‚å­¦æœ¯æŸ¥è¯¢çš„å…¨é¢å’Œå‡†ç¡®ç»“æœã€‚æˆ‘ä»¬ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å’Œåˆæˆæ•°æ®é›†AutoScholarQueryå¯¹PaSaè¿›è¡Œäº†ä¼˜åŒ–ï¼Œè¯¥æ•°æ®é›†åŒ…å«3.5ä¸‡æ¡ç²¾ç»†çš„å­¦æœ¯æŸ¥è¯¢å’Œç›¸åº”è®ºæ–‡ï¼Œæ¥æºäºé¡¶çº§äººå·¥æ™ºèƒ½ä¼šè®®å‡ºç‰ˆç‰©ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†RealScholarQueryåŸºå‡†æµ‹è¯•ï¼Œæ”¶é›†çœŸå®ä¸–ç•Œçš„å­¦æœ¯æŸ¥è¯¢ï¼Œä»¥è¯„ä¼°PaSaåœ¨æ›´ç°å®åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚å°½ç®¡æ˜¯åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œä½†PaSaåœ¨RealScholarQueryä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼ŒåŒ…æ‹¬Googleã€Google Scholarã€é’ˆå¯¹æ”¹è¿°æŸ¥è¯¢çš„GPT-4ç»“åˆçš„Googleæœç´¢ã€chatGPTï¼ˆå¯ç”¨æœç´¢åŠŸèƒ½çš„GPT-4oï¼‰ã€GPT-o1ä»¥åŠé€šè¿‡æç¤ºGPT-4oå®ç°çš„PaSa-GPT-4oã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒPaSa-7Båœ¨å¬å›ç‡@20å’Œå¬å›ç‡@50æ–¹é¢åˆ†åˆ«è¶…è¿‡äº†æœ€ä½³GoogleåŸºçº¿â€”â€”GPT-4ç»“åˆçš„Googleæœç´¢è¾¾37.78%å’Œ39.90%ã€‚åŒæ—¶ï¼Œå®ƒçš„å¬å›ç‡ä¹Ÿè¶…è¿‡äº†PaSa-GPT-4oè¾¾30.36%ï¼Œç²¾ç¡®åº¦æé«˜äº†4.25%ã€‚æ¨¡å‹ã€æ•°æ®é›†å’Œä»£ç å‡å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bytedance/pasa%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/bytedance/pasaæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10120v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¸•è¨æ˜¯ä¸€ä¸ªå¼ºå¤§çš„è®ºæ–‡æœç´¢æ™ºèƒ½ä»£ç†ï¼Œå¯ä»¥è‡ªä¸»åšå‡ºåŒ…æ‹¬è°ƒç”¨æœç´¢å·¥å…·ã€é˜…è¯»è®ºæ–‡å’Œç­›é€‰ç›¸å…³æ–‡çŒ®ç­‰å†³ç­–ï¼Œä»¥è·å–é’ˆå¯¹å¤æ‚å­¦æœ¯æŸ¥è¯¢çš„å…¨é¢å‡†ç¡®ç»“æœã€‚å¸•è¨çš„ä¼˜åŒ–é€šè¿‡ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¸åˆæˆæ•°æ®é›†AutoScholarQueryè¿›è¡Œï¼Œè¯¥æ•°æ®é›†åŒ…å«3.5ä¸‡ç²¾ç»†çš„å­¦æœ¯æŸ¥è¯¢å’Œç›¸åº”è®ºæ–‡ï¼Œæ¥æºäºé¡¶çº§äººå·¥æ™ºèƒ½ä¼šè®®å‡ºç‰ˆç‰©ã€‚æ­¤å¤–ï¼Œä¸ºäº†è¯„ä¼°å¸•è¨åœ¨æ›´çœŸå®åœºæ™¯ä¸­çš„æ€§èƒ½ï¼Œå¼€å‘äº†RealScholarQueryåŸºå‡†æµ‹è¯•ã€‚å°½ç®¡æ˜¯åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œä½†å¸•è¨åœ¨RealScholarQueryä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼ŒåŒ…æ‹¬è°·æ­Œã€è°·æ­Œå­¦æœ¯ã€è°·æ­Œä¸GPT-4ç»“åˆçš„æŸ¥è¯¢ã€ChatGPTï¼ˆæœç´¢å¯ç”¨çš„GPT-4oï¼‰ã€GPT-o1ä»¥åŠç”±GPT-4oå®ç°çš„å¸•è¨ã€‚ç‰¹åˆ«æ˜¯å¸•è¨-7Båœ¨å¬å›ç‡@20å’Œå¬å›ç‡@50æ–¹é¢åˆ†åˆ«è¶…è¶Šäº†æœ€ä½³è°·æ­ŒåŸºçº¿Google with GPT-4o 37.78%å’Œ39.90%ã€‚æ¨¡å‹ã€æ•°æ®é›†å’Œä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/bytedance/pasa%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/bytedance/pasaè·å–ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¸•è¨æ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å…ˆè¿›è®ºæ–‡æœç´¢ä»£ç†ï¼Œå¯è‡ªä¸»è¿›è¡Œä¸€ç³»åˆ—å†³ç­–ä»¥è·å–å…¨é¢å‡†ç¡®çš„å­¦æœ¯æŸ¥è¯¢ç»“æœã€‚</li>
<li>ä½¿ç”¨åˆæˆæ•°æ®é›†AutoScholarQueryè¿›è¡Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ã€‚</li>
<li>å¼€å‘RealScholarQueryåŸºå‡†æµ‹è¯•ä»¥è¯„ä¼°å¸•è¨åœ¨æ›´çœŸå®åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚</li>
<li>å¸•è¨åœ¨RealScholarQueryä¸Šçš„è¡¨ç°ä¼˜äºå¤šä¸ªåŸºçº¿ï¼ŒåŒ…æ‹¬è°·æ­ŒåŠå…¶ä¸GPT-4ç»“åˆçš„ç‰ˆæœ¬ã€‚</li>
<li>å¸•è¨-7Båœ¨å¬å›ç‡æ–¹é¢æ˜¾è‘—è¶…è¶Šäº†æœ€ä½³è°·æ­ŒåŸºçº¿ã€‚</li>
<li>å¸•è¨æ¨¡å‹ã€æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å‘å¸ƒåœ¨GitHubä¸Šã€‚</li>
<li>å¸•è¨æœ‰æœ›ä¸ºå¤æ‚çš„å­¦æœ¯æŸ¥è¯¢æä¾›é«˜æ•ˆä¸”å‡†ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10120">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c28ad991b12190da0ee12473efc65a10.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2e2f47dfee4f53354937aaed3c61cfc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5ca2459afc77830fe8fdf70248257e4f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0171d07dbfa0adcd2de7c56610d444cc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e42fefdbaf384622dbb01f15ab9cd02.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="A-Survey-on-LLM-Test-Time-Compute-via-Search-Tasks-LLM-Profiling-Search-Algorithms-and-Relevant-Frameworks"><a href="#A-Survey-on-LLM-Test-Time-Compute-via-Search-Tasks-LLM-Profiling-Search-Algorithms-and-Relevant-Frameworks" class="headerlink" title="A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling,   Search Algorithms, and Relevant Frameworks"></a>A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling,   Search Algorithms, and Relevant Frameworks</h2><p><strong>Authors:Xinzhe Li</strong></p>
<p>LLM test-time compute (or LLM inference) via search has emerged as a promising research area with rapid developments. However, current frameworks often adopt distinct perspectives on three key aspects (task definition, LLM profiling, and search procedures), making direct comparisons challenging. Moreover, the search algorithms employed often diverge from standard implementations, and their specific characteristics are not thoroughly specified. In this survey, we provide a comprehensive technical review that unifies task definitions and provides modular definitions of LLM profiling and search procedures. The definitions enable precise comparisons of various LLM inference frameworks while highlighting their departures from conventional search algorithms. We also discuss the applicability, performance, and efficiency of these methods. For further details and ongoing updates, please refer to our GitHub repository: <a target="_blank" rel="noopener" href="https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md">https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md</a> </p>
<blockquote>
<p>LLMæµ‹è¯•æ—¶é—´è®¡ç®—ï¼ˆæˆ–LLMæ¨ç†ï¼‰é€šè¿‡æœç´¢å·²ç»æˆä¸ºä¸€ä¸ªæœ‰å‰æ™¯çš„ç ”ç©¶é¢†åŸŸï¼Œå‘å±•è¿…é€Ÿã€‚ç„¶è€Œï¼Œå½“å‰æ¡†æ¶å¾€å¾€ä»ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼ˆä»»åŠ¡å®šä¹‰ã€LLMåˆ†æä»¥åŠæœç´¢ç¨‹åºï¼‰é‡‡ç”¨ä¸åŒçš„è§‚ç‚¹ï¼Œä½¿å¾—ç›´æ¥æ¯”è¾ƒå˜å¾—å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œæ‰€ä½¿ç”¨çš„æœç´¢ç®—æ³•ç»å¸¸åç¦»æ ‡å‡†å®ç°ï¼Œå¹¶ä¸”å®ƒä»¬çš„ç‰¹å®šç‰¹æ€§å¹¶æœªå¾—åˆ°å½»åº•è¯´æ˜ã€‚åœ¨æœ¬æ¬¡è°ƒæŸ¥ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€é¡¹å…¨é¢çš„æŠ€æœ¯å›é¡¾ï¼Œç»Ÿä¸€äº†ä»»åŠ¡å®šä¹‰ï¼Œå¹¶æä¾›äº†æ¨¡å—åŒ–å®šä¹‰çš„LLMåˆ†æå’Œæœç´¢ç¨‹åºã€‚è¿™äº›å®šä¹‰èƒ½å¤Ÿç²¾ç¡®æ¯”è¾ƒå„ç§LLMæ¨ç†æ¡†æ¶ï¼ŒåŒæ—¶çªå‡ºå…¶ä¸å¸¸è§„æœç´¢ç®—æ³•çš„åç¦»ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†è¿™äº›æ–¹æ³•çš„åº”ç”¨æ€§ã€æ€§èƒ½å’Œæ•ˆç‡ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œæœ€æ–°æ›´æ–°ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„GitHubä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md">https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10069v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LLMæµ‹è¯•æ—¶çš„è®¡ç®—ï¼ˆæˆ–LLMæ¨ç†ï¼‰é€šè¿‡æœç´¢å·²æˆä¸ºå…·æœ‰å‘å±•å‰æ™¯çš„ç ”ç©¶é¢†åŸŸï¼Œå‘å±•è¿…é€Ÿã€‚ç„¶è€Œï¼Œå½“å‰çš„ç ”ç©¶æ¡†æ¶åœ¨ä»»åŠ¡å®šä¹‰ã€LLMæ€§èƒ½åˆ†æå’Œæœç´¢ç¨‹åºæ–¹é¢å¾€å¾€é‡‡ç”¨ä¸åŒè§‚ç‚¹ï¼Œä½¿å¾—ç›´æ¥æ¯”è¾ƒå…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æä¾›å…¨é¢çš„æŠ€æœ¯å›é¡¾ï¼Œç»Ÿä¸€ä»»åŠ¡å®šä¹‰ï¼Œæ¨¡å—åŒ–å®šä¹‰LLMæ€§èƒ½åˆ†æå’Œæœç´¢ç¨‹åºï¼Œä½¿ä¸åŒLLMæ¨ç†æ¡†æ¶ä¹‹é—´çš„ç²¾ç¡®æ¯”è¾ƒæˆä¸ºå¯èƒ½ï¼ŒåŒæ—¶çªå‡ºå…¶ä¸å¸¸è§„æœç´¢ç®—æ³•çš„å·®å¼‚æ€§ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†è¿™äº›æ–¹æ³•çš„åº”ç”¨æ€§ã€æ€§èƒ½å’Œæ•ˆç‡ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯åŠæœ€æ–°æ›´æ–°ï¼Œè¯·æŸ¥é˜…æˆ‘ä»¬çš„GitHubä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md">GitHubé“¾æ¥</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMæµ‹è¯•æ—¶é—´è®¡ç®—å·²æˆä¸ºçƒ­é—¨ç ”ç©¶é¢†åŸŸã€‚</li>
<li>å½“å‰æ¡†æ¶åœ¨ä»»åŠ¡å®šä¹‰ã€LLMæ€§èƒ½åˆ†æå’Œæœç´¢ç¨‹åºæ–¹é¢å­˜åœ¨å¤šæ ·æ€§ã€‚</li>
<li>ç¼ºä¹ç›´æ¥æ¯”è¾ƒä¸åŒLLMæ¨ç†æ¡†æ¶çš„æ ‡å‡†ã€‚</li>
<li>æœ¬æ–‡æä¾›å…¨é¢çš„æŠ€æœ¯å›é¡¾ï¼Œç»Ÿä¸€ä»»åŠ¡å®šä¹‰ï¼Œæ¨¡å—åŒ–å®šä¹‰LLMæ€§èƒ½åˆ†æå’Œæœç´¢ç¨‹åºã€‚</li>
<li>æ¡†æ¶ä¹‹é—´çš„ç²¾ç¡®æ¯”è¾ƒæˆä¸ºå¯èƒ½ã€‚</li>
<li>çªå‡ºå¸¸è§„æœç´¢ç®—æ³•ä¸LLMæ¨ç†æ¡†æ¶ä¹‹é—´çš„å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10069">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-84a73065d9cb0d960bbc3f2525f4f6ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b293b407073da014db4609ec9484c608.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f96f27009ce2068143a24f4076f5783c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a44bd8273705737240dca3a96fa6bd6.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="FiLo-Zero-Few-Shot-Anomaly-Detection-by-Fused-Fine-Grained-Descriptions-and-Deformable-Localization"><a href="#FiLo-Zero-Few-Shot-Anomaly-Detection-by-Fused-Fine-Grained-Descriptions-and-Deformable-Localization" class="headerlink" title="FiLo++: Zero-&#x2F;Few-Shot Anomaly Detection by Fused Fine-Grained   Descriptions and Deformable Localization"></a>FiLo++: Zero-&#x2F;Few-Shot Anomaly Detection by Fused Fine-Grained   Descriptions and Deformable Localization</h2><p><strong>Authors:Zhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen, Ming Tang, Jinqiao Wang</strong></p>
<p>Anomaly detection methods typically require extensive normal samples from the target class for training, limiting their applicability in scenarios that require rapid adaptation, such as cold start. Zero-shot and few-shot anomaly detection do not require labeled samples from the target class in advance, making them a promising research direction. Existing zero-shot and few-shot approaches often leverage powerful multimodal models to detect and localize anomalies by comparing image-text similarity. However, their handcrafted generic descriptions fail to capture the diverse range of anomalies that may emerge in different objects, and simple patch-level image-text matching often struggles to localize anomalous regions of varying shapes and sizes. To address these issues, this paper proposes the FiLo++ method, which consists of two key components. The first component, Fused Fine-Grained Descriptions (FusDes), utilizes large language models to generate anomaly descriptions for each object category, combines both fixed and learnable prompt templates and applies a runtime prompt filtering method, producing more accurate and task-specific textual descriptions. The second component, Deformable Localization (DefLoc), integrates the vision foundation model Grounding DINO with position-enhanced text descriptions and a Multi-scale Deformable Cross-modal Interaction (MDCI) module, enabling accurate localization of anomalies with various shapes and sizes. In addition, we design a position-enhanced patch matching approach to improve few-shot anomaly detection performance. Experiments on multiple datasets demonstrate that FiLo++ achieves significant performance improvements compared with existing methods. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/CASIA-IVA-Lab/FiLo">https://github.com/CASIA-IVA-Lab/FiLo</a>. </p>
<blockquote>
<p>å¼‚å¸¸æ£€æµ‹æ–¹æ³•é€šå¸¸éœ€è¦ç›®æ ‡ç±»åˆ«çš„å¤§é‡æ­£å¸¸æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨éœ€è¦å¿«é€Ÿé€‚åº”çš„åœºæ™¯ï¼ˆå¦‚å†·å¯åŠ¨ï¼‰ä¸­é™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å¼‚å¸¸æ£€æµ‹ä¸éœ€è¦æå‰è·å–ç›®æ ‡ç±»åˆ«çš„æ ‡è®°æ ·æœ¬ï¼Œå› æ­¤æˆä¸ºäº†ä¸€ä¸ªæœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚ç°æœ‰çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ–¹æ³•å¸¸å¸¸åˆ©ç”¨å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œé€šè¿‡æ¯”è¾ƒå›¾åƒæ–‡æœ¬ç›¸ä¼¼æ€§æ¥æ£€æµ‹å’Œå®šä½å¼‚å¸¸ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æ‰‹å·¥é€šç”¨æè¿°æ— æ³•æ•æ‰ä¸åŒå¯¹è±¡ä¸­å¯èƒ½å‡ºç°çš„å„ç§å¼‚å¸¸ï¼Œè€Œç®€å•çš„è¡¥ä¸çº§åˆ«çš„å›¾åƒæ–‡æœ¬åŒ¹é…å¾€å¾€éš¾ä»¥å®šä½å½¢çŠ¶å’Œå¤§å°å„å¼‚çš„å¼‚å¸¸åŒºåŸŸã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†FiLo++æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶ç»„æˆã€‚ç¬¬ä¸€ä¸ªç»„ä»¶Fused Fine-Grained Descriptionsï¼ˆFusDesï¼‰åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºæ¯ä¸ªå¯¹è±¡ç±»åˆ«ç”Ÿæˆå¼‚å¸¸æè¿°ï¼Œç»“åˆäº†å›ºå®šå’Œå¯å­¦ä¹ çš„æç¤ºæ¨¡æ¿ï¼Œå¹¶åº”ç”¨äº†è¿è¡Œæ—¶æç¤ºè¿‡æ»¤æ–¹æ³•ï¼Œäº§ç”Ÿæ›´å‡†ç¡®å’Œä»»åŠ¡ç‰¹å®šçš„æ–‡æœ¬æè¿°ã€‚ç¬¬äºŒä¸ªç»„ä»¶Deformable Localizationï¼ˆDefLocï¼‰å°†è§†è§‰åŸºç¡€æ¨¡å‹Grounding DINOä¸ä½ç½®å¢å¼ºçš„æ–‡æœ¬æè¿°å’Œå¤šå°ºåº¦å¯å˜å½¢è·¨æ¨¡æ€äº¤äº’ï¼ˆMDCIï¼‰æ¨¡å—é›†æˆï¼Œèƒ½å¤Ÿå®ç°å„ç§å½¢çŠ¶å’Œå¤§å°çš„å¼‚å¸¸å‡†ç¡®å®šä½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½ç½®å¢å¼ºçš„è¡¥ä¸åŒ¹é…æ–¹æ³•ï¼Œä»¥æé«˜å°‘æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„æ€§èƒ½ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFiLo++å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/CASIA-IVA-Lab/FiLo%E4%B8%8A%E6%8F%9B%E4%BA%8B%E3%80%82">https://github.com/CASIA-IVA-Lab/FiLoä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10067v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡é’ˆå¯¹é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„é—®é¢˜ï¼Œæå‡ºäº†FiLo++æ–¹æ³•ï¼ŒåŒ…æ‹¬Fused Fine-Grained Descriptionsï¼ˆFusDesï¼‰å’ŒDeformable Localizationï¼ˆDefLocï¼‰ä¸¤ä¸ªå…³é”®ç»„ä»¶ã€‚å‰è€…åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¼‚å¸¸æè¿°ï¼Œç»“åˆå›ºå®šå’Œå¯å­¦ä¹ çš„æç¤ºæ¨¡æ¿ï¼Œå¹¶åº”ç”¨è¿è¡Œæ—¶æç¤ºè¿‡æ»¤æ–¹æ³•ï¼Œç”Ÿæˆæ›´å‡†ç¡®çš„ä»»åŠ¡ç‰¹å®šæ–‡æœ¬æè¿°ã€‚åè€…ç»“åˆäº†è§†è§‰åŸºç¡€æ¨¡å‹Grounding DINOä¸ä½ç½®å¢å¼ºçš„æ–‡æœ¬æè¿°å’Œå¤šå°ºåº¦å¯å˜å½¢è·¨æ¨¡æ€äº¤äº’ï¼ˆMDCIï¼‰æ¨¡å—ï¼Œèƒ½å‡†ç¡®å®šä½å„ç§å½¢çŠ¶å’Œå¤§å°çš„å¼‚å¸¸ã€‚å®éªŒè¯æ˜ï¼ŒFiLo++ç›¸è¾ƒäºç°æœ‰æ–¹æ³•å…·æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼‚å¸¸æ£€æµ‹æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡ç›®æ ‡ç±»åˆ«çš„æ­£å¸¸æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨éœ€è¦å¿«é€Ÿé€‚åº”çš„åœºæ™¯ï¼ˆå¦‚å†·å¯åŠ¨ï¼‰ä¸­é™åˆ¶äº†å…¶åº”ç”¨ã€‚</li>
<li>é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å¼‚å¸¸æ£€æµ‹ä¸éœ€è¦æå‰è·å¾—ç›®æ ‡ç±»åˆ«çš„æ ‡ç­¾æ ·æœ¬ï¼Œæˆä¸ºæœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹é€šè¿‡å›¾åƒæ–‡æœ¬ç›¸ä¼¼æ€§æ£€æµ‹ä¸å®šä½å¼‚å¸¸ï¼Œä½†é€šç”¨æè¿°æ— æ³•æ•æ‰ä¸åŒå¯¹è±¡ä¸­å¤šæ ·çš„å¼‚å¸¸ã€‚</li>
<li>FiLo++æ–¹æ³•åŒ…æ‹¬Fused Fine-Grained Descriptionsï¼ˆFusDesï¼‰å’ŒDeformable Localizationï¼ˆDefLocï¼‰ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼Œåˆ†åˆ«ç”¨äºç”Ÿæˆæ›´å‡†ç¡®çš„å¼‚å¸¸æè¿°å’Œå‡†ç¡®å®šä½å¼‚å¸¸ã€‚</li>
<li>FusDesåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¼‚å¸¸æè¿°ï¼Œå¹¶ç»“åˆå›ºå®šå’Œå¯å­¦ä¹ æç¤ºæ¨¡æ¿ï¼Œæé«˜æè¿°çš„å‡†ç¡®æ€§ã€‚</li>
<li>DefLocç»“åˆäº†è§†è§‰åŸºç¡€æ¨¡å‹ä¸ä½ç½®å¢å¼ºçš„æ–‡æœ¬æè¿°ï¼Œä»¥åŠå¤šå°ºåº¦å¯å˜å½¢è·¨æ¨¡æ€äº¤äº’æ¨¡å—ï¼Œå®ç°å¼‚å¸¸ç²¾å‡†å®šä½ã€‚</li>
<li>å®éªŒè¯æ˜FiLo++åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾ƒç°æœ‰æ–¹æ³•å…·æœ‰æ˜¾è‘—æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10067">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a9b3929f400dd861e57bad3fed550363.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d2dbd358010dc6a76ae4702e1d04d57.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LLM-Based-Routing-in-Mixture-of-Experts-A-Novel-Framework-for-Trading"><a href="#LLM-Based-Routing-in-Mixture-of-Experts-A-Novel-Framework-for-Trading" class="headerlink" title="LLM-Based Routing in Mixture of Experts: A Novel Framework for Trading"></a>LLM-Based Routing in Mixture of Experts: A Novel Framework for Trading</h2><p><strong>Authors:Kuan-Ming Liu, Ming-Chih Lo</strong></p>
<p>Recent advances in deep learning and large language models (LLMs) have facilitated the deployment of the mixture-of-experts (MoE) mechanism in the stock investment domain. While these models have demonstrated promising trading performance, they are often unimodal, neglecting the wealth of information available in other modalities, such as textual data. Moreover, the traditional neural network-based router selection mechanism fails to consider contextual and real-world nuances, resulting in suboptimal expert selection. To address these limitations, we propose LLMoE, a novel framework that employs LLMs as the router within the MoE architecture. Specifically, we replace the conventional neural network-based router with LLMs, leveraging their extensive world knowledge and reasoning capabilities to select experts based on historical price data and stock news. This approach provides a more effective and interpretable selection mechanism. Our experiments on multimodal real-world stock datasets demonstrate that LLMoE outperforms state-of-the-art MoE models and other deep neural network approaches. Additionally, the flexible architecture of LLMoE allows for easy adaptation to various downstream tasks. </p>
<blockquote>
<p>æœ€è¿‘æ·±åº¦å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ä¿ƒè¿›äº†ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æœºåˆ¶åœ¨è‚¡ç¥¨æŠ•èµ„é¢†åŸŸçš„åº”ç”¨ã€‚è™½ç„¶è¿™äº›æ¨¡å‹å·²ç»è¡¨ç°å‡ºäº†æœ‰å‰æ™¯çš„äº¤æ˜“æ€§èƒ½ï¼Œä½†å®ƒä»¬é€šå¸¸æ˜¯å•æ¨¡æ€çš„ï¼Œå¿½ç•¥äº†å…¶ä»–æ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬æ•°æ®ï¼‰ä¸­ä¸°å¯Œçš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒåŸºäºä¼ ç»Ÿç¥ç»ç½‘ç»œçš„è·¯ç”±å™¨é€‰æ‹©æœºåˆ¶æœªèƒ½è€ƒè™‘ä¸Šä¸‹æ–‡å’Œç°å®ä¸–ç•Œç»†å¾®å·®åˆ«ï¼Œå¯¼è‡´ä¸“å®¶é€‰æ‹©ä¸ç†æƒ³ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†LLMoEè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨LLMä½œä¸ºMoEæ¶æ„ä¸­çš„è·¯ç”±å™¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç”¨LLMæ›¿ä»£äº†åŸºäºå¸¸è§„ç¥ç»ç½‘ç»œçš„è·¯ç”±å™¨ï¼Œåˆ©ç”¨å…¶ä¸°å¯Œçš„ä¸–ç•ŒçŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œæ ¹æ®å†å²ä»·æ ¼æ•°æ®å’Œè‚¡ç¥¨æ–°é—»é€‰æ‹©ä¸“å®¶ã€‚è¿™ç§æ–¹æ³•æä¾›äº†æ›´æœ‰æ•ˆå’Œå¯è§£é‡Šçš„é€‰æ‹©æœºåˆ¶ã€‚æˆ‘ä»¬åœ¨å¤šæ¨¡æ€ç°å®ä¸–ç•Œè‚¡ç¥¨æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLLMoEçš„è¡¨ç°ä¼˜äºæœ€æ–°çš„MoEæ¨¡å‹å’Œå…¶ä»–æ·±åº¦ç¥ç»ç½‘ç»œæ–¹æ³•ã€‚æ­¤å¤–ï¼ŒLLMoEçµæ´»çš„æ¶æ„å¯è½»æ¾é€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09636v2">PDF</a> Accepted by AAAI 2025 Workshop on AI for Social Impact - Bridging   Innovations in Finance, Social Media, and Crime Prevention</p>
<p><strong>Summary</strong><br>     æ·±åº¦å­¦ä¹ ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä¿ƒè¿›äº†æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æœºåˆ¶åœ¨è‚¡ç¥¨æŠ•èµ„é¢†åŸŸçš„åº”ç”¨ã€‚é’ˆå¯¹ä¼ ç»Ÿç¥ç»ç½‘ç»œè·¯ç”±å™¨é€‰æ‹©æœºåˆ¶å¿½è§†ä¸Šä¸‹æ–‡å’Œç°å®ä¸–ç•Œç»†å¾®å·®åˆ«çš„å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºLLMoEæ¡†æ¶ï¼Œé‡‡ç”¨LLMä½œä¸ºMoEæ¶æ„ä¸­çš„è·¯ç”±å™¨ï¼ŒåŸºäºå†å²ä»·æ ¼æ•°æ®å’Œè‚¡ç¥¨æ–°é—»é€‰æ‹©ä¸“å®¶ã€‚å®éªŒè¯æ˜ï¼ŒLLMoEåœ¨æ¨¡æ€ç°å®è‚¡ç¥¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºæœ€å…ˆè¿›MoEæ¨¡å‹å’Œå…¶ä»–æ·±åº¦ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œä¸”æ¶æ„çµæ´»ï¼Œæ˜“äºé€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°å‘å±•ä¿ƒè¿›äº†æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æœºåˆ¶åœ¨è‚¡ç¥¨æŠ•èµ„ä¸­çš„åº”ç”¨ã€‚</li>
<li>ä¼ ç»Ÿç¥ç»ç½‘ç»œè·¯ç”±å™¨é€‰æ‹©æœºåˆ¶å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å……åˆ†è€ƒè™‘ä¸Šä¸‹æ–‡å’Œç°å®ä¸–ç•Œç»†å¾®å·®åˆ«ã€‚</li>
<li>LLMoEæ¡†æ¶é‡‡ç”¨LLMä½œä¸ºMoEæ¶æ„ä¸­çš„è·¯ç”±å™¨ï¼ŒåŸºäºå†å²ä»·æ ¼æ•°æ®å’Œè‚¡ç¥¨æ–°é—»é€‰æ‹©ä¸“å®¶ã€‚</li>
<li>LLMoEåœ¨æ¨¡æ€ç°å®è‚¡ç¥¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>LLMoEæ¶æ„çµæ´»ï¼Œæ˜“äºé€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚</li>
<li>LLMçš„å¹¿æ³›åº”ç”¨çŸ¥è¯†åŠå…¶æ¨ç†èƒ½åŠ›åœ¨è‚¡ç¥¨æŠ•èµ„é¢†åŸŸå…·æœ‰æ½œåœ¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09636">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2a8b5e149ad8bd18b0595d298238f325.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3a42e88b738b756ac1e6357b982a80a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70c476004962a7c3351e42d261325042.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e532199298767c7cd68ed582970b40fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-237f0e21d645cca6f05c865b282dd8ce.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MVTamperBench-Evaluating-Robustness-of-Vision-Language-Models"><a href="#MVTamperBench-Evaluating-Robustness-of-Vision-Language-Models" class="headerlink" title="MVTamperBench: Evaluating Robustness of Vision-Language Models"></a>MVTamperBench: Evaluating Robustness of Vision-Language Models</h2><p><strong>Authors:Amit Agarwal, Srikant Panda, Angeline Charles, Bhargava Kumar, Hitesh Patel, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Dong-Kyu Chae</strong></p>
<p>Multimodal Large Language Models (MLLMs) have driven major advances in video understanding, yet their vulnerability to adversarial tampering and manipulations remains underexplored. To address this gap, we introduce MVTamperBench, a benchmark that systematically evaluates MLLM robustness against five prevalent tampering techniques: rotation, masking, substitution, repetition, and dropping. Built from 3.4K original videos-expanded to over 17K tampered clips spanning 19 video tasks.   MVTamperBench challenges models to detect manipulations in spatial and temporal coherence. We evaluate 45 recent MLLMs from 15+ model families, revealing substantial variability in resilience across tampering types and showing that larger parameter counts do not necessarily guarantee robustness. MVTamperBench sets a new benchmark for developing tamper-resilient MLLM in safety-critical applications, including detecting clickbait, preventing harmful content distribution, and enforcing policies on media platforms. We release all code and data to foster open research in trustworthy video understanding.   Code: <a target="_blank" rel="noopener" href="https://amitbcp.github.io/MVTamperBench/">https://amitbcp.github.io/MVTamperBench/</a> Data: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/Srikant86/MVTamperBench">https://huggingface.co/datasets/Srikant86/MVTamperBench</a> </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†å…¶åœ¨é¢ä¸´å¯¹æŠ—æ€§å¹²æ‰°å’Œæ“çºµæ—¶çš„è„†å¼±æ€§ä»ç„¶é²œæœ‰ç ”ç©¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†MVTamperBenchåŸºå‡†æµ‹è¯•å¹³å°ï¼Œè¯¥å¹³å°ç³»ç»Ÿåœ°è¯„ä¼°äº†MLLMå¯¹äº”ç§å¸¸è§å¹²æ‰°æŠ€æœ¯çš„é²æ£’æ€§ï¼šæ—‹è½¬ã€é®æŒ¡ã€æ›¿æ¢ã€é‡å¤å’Œä¸¢å¼ƒã€‚å®ƒå»ºç«‹åœ¨åŸå§‹è§†é¢‘çš„æ‰©å¼ é›†ä¸Šï¼Œè¶…è¿‡æœ‰æ”»å‡»è¡Œä¸ºçš„è§†é¢‘å‰ªè¾‘æœ‰ä¸‰åƒå››ç™¾ä¸‡æ¡è§†é¢‘è·¨è¶Šåä¹ç§è§†é¢‘ä»»åŠ¡ã€‚MVTamperBenchæŒ‘æˆ˜æ¨¡å‹æ£€æµ‹ç©ºé—´å’Œæ—¶é—´è¿è´¯æ€§çš„æ“çºµè¡Œä¸ºã€‚æˆ‘ä»¬è¯„ä¼°äº†æ¥è‡ªåäº”ä¸ªä»¥ä¸Šçš„æ¨¡å‹çš„å››åäº”ä¸ªè¿‘æœŸçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå‘ç°ä¸åŒç±»å‹å¹²æ‰°ä¸‹æ¨¡å‹çš„éŸ§æ€§å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œè€Œä¸”æ›´å¤§çš„å‚æ•°æ•°é‡å¹¶ä¸ä¸€å®šä¿è¯æ¨¡å‹çš„é²æ£’æ€§ã€‚MVTamperBenchä¸ºåœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­å¼€å‘é˜²å¹²æ‰°å¤§å‹è¯­è¨€æ¨¡å‹è®¾ç«‹äº†æ–°çš„åŸºå‡†çº¿ï¼ŒåŒ…æ‹¬æ£€æµ‹æ ‡é¢˜æ¬ºè¯ˆã€é˜²æ­¢æœ‰å®³å†…å®¹ä¼ æ’­ä»¥åŠåœ¨åª’ä½“å¹³å°ä¸Šæ‰§è¡Œæ”¿ç­–ç­‰ã€‚æˆ‘ä»¬å…¬å¼€æ‰€æœ‰ä»£ç å’Œæ•°æ®ä»¥ä¿ƒè¿›å¯ä¿¡è§†é¢‘ç†è§£çš„å¼€æ”¾ç ”ç©¶ã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://amitbcp.github.io/MVTamperBench/">https://amitbcp.github.io/MVTamperBench/</a> æ•°æ®é›†ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/Srikant86/MVTamperBench">https://huggingface.co/datasets/Srikant86/MVTamperBench</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19794v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>MLLMsåœ¨è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†å…¶å¯¹æ•Œå¯¹å¹²æ‰°å’Œæ“ä½œçš„è„†å¼±æ€§ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MVTamperBenchåŸºå‡†æµ‹è¯•ï¼Œè¯¥æµ‹è¯•ç³»ç»Ÿåœ°è¯„ä¼°äº†MLLMå¯¹äº”ç§å¸¸è§å¹²æ‰°æŠ€æœ¯çš„ç¨³å¥æ€§ï¼šæ—‹è½¬ã€é®æŒ¡ã€æ›¿æ¢ã€é‡å¤å’Œä¸¢å¼ƒã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«æ¥è‡ªåŸå§‹è§†é¢‘çš„è¶…è¿‡17Kä¸ªå¹²æ‰°ç‰‡æ®µï¼Œæ¶µç›–äº†æ¶µç›–è§†é¢‘ä»»åŠ¡çš„è¶…è¿‡å†…å®¹è¯„ä¼°è¶…è¿‡æ‹“å±•äº†å¯¹äºåº”å¯¹å„ç§æ—¶ç©ºå¹²æ‰°è§†é¢‘å†…å®¹å¹¿æ³›çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¯¹åŒ…æ‹¬è¶…è¿‡æ¨¡å‹å®¶æ—åœ¨å†…çš„è¿‘æœŸMLLMè¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°ä¸åŒå¹²æ‰°ç±»å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸”å‚æ•°æ•°é‡å¤šçš„æ¨¡å‹ä¸ä¸€å®šå…·å¤‡æ›´å¥½çš„ç¨³å¥æ€§ã€‚MVTamperBenchä¸ºå¼€å‘ç¨³å¥çš„MLLMè®¾å®šäº†æ–°çš„åŸºå‡†çº¿ï¼Œé€‚ç”¨äºå®‰å…¨å…³é”®å‹åº”ç”¨ï¼Œå¦‚æ£€æµ‹æ ‡é¢˜æ¬ºè¯ˆã€é˜²æ­¢æœ‰å®³å†…å®¹ä¼ æ’­ä»¥åŠåœ¨åª’ä½“å¹³å°ä¸Šæ‰§è¡Œæ”¿ç­–ç­‰ã€‚æˆ‘ä»¬å…¬å¼€äº†æ‰€æœ‰ä»£ç å’Œæ•°æ®ï¼Œä»¥ä¿ƒè¿›åœ¨å¯ä¿¡è§†é¢‘ç†è§£æ–¹é¢çš„å¼€æ”¾ç ”ç©¶ã€‚ä¸ºæ”¹å–„æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯é æ€§ï¼Œè¿›ä¸€æ­¥æå‡äº†é¢†åŸŸçš„åº”ç”¨å‰æ™¯å’Œä»·å€¼ã€‚å¸Œæœ›å…¶ä¿ƒè¿›å¤šåª’ä½“æŠ€æœ¯çš„å¯æŒç»­æ€§å‘å±•ï¼Œä¸ºæœªæ¥å¸¦æ¥æ›´å¥½çš„å¤šåª’ä½“å†…å®¹åº”ç”¨å‰æ™¯ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™ä¸€å·¥å…·å°†ä¿ƒè¿›ç ”ç©¶ç¤¾åŒºçš„å‘å±•å¹¶æ¨åŠ¨å¤šåª’ä½“é¢†åŸŸçš„è¿›æ­¥ã€‚æ¬¢è¿æ›´å¤šç ”ç©¶è€…å‚ä¸åˆä½œå’Œè®¨è®ºã€‚æ„Ÿå…´è¶£çš„ç ”ç©¶è€…å¯é€šè¿‡è®¿é—®ä»¥ä¸‹é“¾æ¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚æ„Ÿå…´è¶£çš„ç§‘ç ”è€…å¯ä»¥é€šè¿‡<a target="_blank" rel="noopener" href="https://amitbcp.github.io/MVTamperBench/%E8%BF%9B%E8%A1%8C%E8%AE%BF%E9%97%AE%E4%BA%86%E8%A7%A3%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF%E4%BB%A3%E7%A0%81%E8%8E%B7%E5%8F%96%E5%8F%AF%E9%80%9A%E8%BF%87">https://amitbcp.github.io/MVTamperBench/è¿›è¡Œè®¿é—®äº†è§£è¯¦ç»†ä¿¡æ¯ä»£ç è·å–å¯é€šè¿‡</a> <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/Srikant86/MVTamperBench%E8%BF%9B%E8%A1%8C%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BF%A1%E6%81%AF%E5%B9%B6%E5%8F%82%E4%B8%8E%E5%90%88%E4%BD%9C%E7%A0%94%E7%A9%B6%E5%85%B1%E5%90%8C%E6%8E%A8%E5%8A%A8%E5%A4%9A%E5%AA%92%E4%BD%93%E9%A2%86%E5%9F%9F%E7%9A%84%E7%A8%B3%E5%81%A5%E6%80%A7%E5%8F%91%E5%B1%95%E5%B9%B6%E5%88%9B%E9%80%A0%E6%9B%B4%E5%AE%89%E5%85%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E3%80%82%E3%80%82MVTamperBench%E5%B0%86%E4%B8%BA%E5%A4%9A%E5%AA%92%E4%BD%93%E9%A2%86%E5%9F%9F%E7%9A%84%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95%E6%B3%A8%E5%85%A5%E6%96%B0%E7%9A%84%E6%B4%BB%E5%8A%9B%EF%BC%8C%E4%BF%83%E8%BF%9B%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%A4%8D%E6%9D%82%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E7%9A%84%E7%A8%B3%E5%81%A5%E6%80%A7%E8%BF%9B%E6%AD%A5%E5%B9%B6%E5%8A%A9%E5%8A%9B%E5%88%9B%E9%80%A0%E6%9B%B4%E5%AE%89%E5%85%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E3%80%82%E6%AD%A4%E5%A4%96%E5%AE%83%E7%9A%84%E5%BC%95%E5%85%A5%E8%BF%98%E5%B0%86%E6%9E%81%E5%A4%A7%E5%9C%B0%E4%BF%83%E8%BF%9B%E8%AF%A5%E9%A2%86%E5%9F%9F%E7%9A%84%E5%8F%91%E5%B1%95%E6%8E%A8%E5%8A%A8%E5%A4%9A%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF%E7%9A%84%E5%88%9B%E6%96%B0%E5%B9%B6%E6%8E%A8%E5%8A%A8%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%BF%9B%E6%AD%A5%E3%80%82%E6%88%91%E4%BB%AC%E7%9B%B8%E4%BF%A1%E8%AF%A5%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B0%86%E6%88%90%E4%B8%BA%E5%A4%9A%E5%AA%92%E4%BD%93%E9%A2%86%E5%9F%9F%E7%9A%84%E9%87%8D%E8%A6%81%E9%87%8C%E7%A8%8B%E7%A2%91%E4%B9%8B%E4%B8%80%E6%8E%A8%E5%8A%A8%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E7%9A%84%E6%8C%81%E7%BB%AD%E5%8F%91%E5%B1%95%E5%92%8C%E5%88%9B%E6%96%B0%E3%80%82">https://huggingface.co/datasets/Srikant86/MVTamperBenchè¿›è¡Œè·å–æ•°æ®é›†ä¿¡æ¯å¹¶å‚ä¸åˆä½œç ”ç©¶å…±åŒæ¨åŠ¨å¤šåª’ä½“é¢†åŸŸçš„ç¨³å¥æ€§å‘å±•å¹¶åˆ›é€ æ›´å®‰å…¨çš„ç½‘ç»œç¯å¢ƒã€‚ã€‚MVTamperBenchå°†ä¸ºå¤šåª’ä½“é¢†åŸŸçš„æœªæ¥å‘å±•æ³¨å…¥æ–°çš„æ´»åŠ›ï¼Œä¿ƒè¿›æ¨¡å‹å¯¹å¤æ‚è§†é¢‘å†…å®¹çš„ç¨³å¥æ€§è¿›æ­¥å¹¶åŠ©åŠ›åˆ›é€ æ›´å®‰å…¨çš„ç½‘ç»œç¯å¢ƒã€‚æ­¤å¤–å®ƒçš„å¼•å…¥è¿˜å°†æå¤§åœ°ä¿ƒè¿›è¯¥é¢†åŸŸçš„å‘å±•æ¨åŠ¨å¤šåª’ä½“æŠ€æœ¯çš„åˆ›æ–°å¹¶æ¨åŠ¨è§†é¢‘ç†è§£çš„å¯é æ€§è¿›æ­¥ã€‚æˆ‘ä»¬ç›¸ä¿¡è¯¥åŸºå‡†æµ‹è¯•å°†æˆä¸ºå¤šåª’ä½“é¢†åŸŸçš„é‡è¦é‡Œç¨‹ç¢‘ä¹‹ä¸€æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„æŒç»­å‘å±•å’Œåˆ›æ–°ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<p>ä¸€ã€MLLMsåœ¨è§†é¢‘ç†è§£æ–¹é¢å­˜åœ¨è„†å¼±æ€§ï¼Œéœ€è¦è¯„ä¼°å…¶å¯¹æŠ—å¹²æ‰°çš„ç¨³å¥æ€§ã€‚ä¸ºæ­¤å¼•å…¥MVTamperBenchåŸºå‡†æµ‹è¯•è¯„ä¼°ç¨³å¥æ€§å¾ˆé‡è¦å…·æœ‰äº”å¤§é‡ç‚¹ï¼šæ£€æµ‹å„ç§è§†é¢‘å¹²æ‰°çš„èƒ½åŠ›æ¶‰åŠå¯¹å¤§é‡æ•°æ®é›†çš„åº”ç”¨é‡‡ç”¨æ—¶ç©ºé²æ£’æŠ€æœ¯è¿›è¡Œæ·±å…¥æ¢è®¨æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½å’Œç»“æ„ç‰¹æ€§åŒ…æ‹¬ä¸åŒæ¨¡å‹å®¶æ—çš„å·®å¼‚å¯¹å¹²æ‰°ç±»å‹çš„å“åº”ç­‰ï¼Œå¯é’ˆå¯¹æ¨¡å‹çš„å®é™…åº”ç”¨æ•ˆæœè¿›è¡Œåˆ†æä¸æ”¹è¿›ä¸ºå¤šåª’ä½“é¢†åŸŸçš„æœªæ¥å‘å±•æ³¨å…¥æ–°çš„æ´»åŠ›è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹ä¸åŒå¹²æ‰°æŠ€æœ¯çš„åº”å¯¹èƒ½åŠ›ä¸ºåç»­æ¨¡å‹çš„æ”¹è¿›æ–¹å‘æä¾›ä¾æ®å‚è€ƒå’Œæ”¯æŒå¹¶ä¸”èƒ½å¤Ÿä¸ºå¼€å‘å®‰å…¨å…³é”®çš„MLLMæä¾›åŸºå‡†çº¿æŒ‡å¯¼æ–¹å‘å¹¶ä¿ƒè¿›ç›¸å…³ç ”ç©¶çš„è¿›å±•å’Œåˆä½œç ”ç©¶å…±åŒæ¨åŠ¨å¤šåª’ä½“é¢†åŸŸçš„ç¨³å¥æ€§å‘å±•ã€‚åŒæ—¶è¯„ä¼°å¤šç§æ¨¡å‹å¯¹äºå„ç§å¹²æ‰°çš„æŠµæŠ—èƒ½åŠ›å¯ä¸ºå¼€å‘æ›´åŠ é²æ£’çš„æ¨¡å‹æä¾›æ€è·¯å’ŒæŒ‡å¯¼å¸®åŠ©ä¿ƒè¿›æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•å’Œæå‡åº”ç”¨åœºæ™¯çš„ä¸æ–­æ‹“å±•ä¹Ÿä¸ºåç»­çš„ç®—æ³•è®¾è®¡å’Œæ”¹è¿›æä¾›äº†å®è´µçš„ç»éªŒå’Œå‚è€ƒå€Ÿé‰´å…¶æ˜¯è§†é¢‘å†…å®¹ç†è§£çš„å¯é æ€§çš„é‡è¦è¡¡é‡æ ‡å‡†ä¹‹ä¸€å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œæ½œåŠ›ä»·å€¼ï¼›åŒæ—¶å®ƒçš„å¼•å…¥ä¹Ÿå°†æå¤§åœ°ä¿ƒè¿›å¤šåª’ä½“é¢†åŸŸçš„å¯æŒç»­æ€§å‘å±•æ¨è¿›æŠ€æœ¯åˆ›æ–°å¹¶åœ¨å¤šåª’ä½“æŠ€æœ¯é¢†åŸŸä¸æ–­å‘æŒ¥é‡è¦ä½œç”¨å¹¶ä¸ºå…¶ä»–é¢†åŸŸå¸¦æ¥æœ‰ç›Šå½±å“é€šè¿‡æå‡ºåŸºäºè§†è§‰çš„è¯­è¨€æ„ŸçŸ¥é²æ£’æ€§è¯„ä»·çš„æ–¹æ³•å¤§å¤§å¢å¼ºäº†æ„ŸçŸ¥ä¸€è‡´æ€§å…·æœ‰ç¨³å¥çš„æŠ€æœ¯æ•ˆæœå’Œä¸°å¯Œçš„ç¤¾ä¼šä»·å€¼å°†ä¼šåº”ç”¨äºåª’ä½“ä¿¡æ¯çš„æœ‰æ•ˆç­›é€‰é¢†åŸŸåˆ›é€ æ›´å¤šçš„å®é™…ä»·å€¼æ¨è¿›è¡Œä¸šå¯æŒç»­å‘å±•ä¸åˆ›æ–°çš„åº”ç”¨æ½œåŠ›ä½“ç°ç ”ç©¶æ„ä¹‰åœ¨å¤šç§è¡Œä¸šé¢†åŸŸå†…è¿›è¡Œå¹¿æ³›å®è·µæ¢ç´¢åŠæ·±åº¦åˆ†æå‘æŒ¥é¢†åŸŸæ ¸å¿ƒç ”ç©¶ä»·å€¼çš„å±•ç°æ›´å¤šæ·±å…¥ä¸”å…¨é¢æ›´ç»†è‡´å…¨é¢æŒ–æ˜è¡Œä¸šå‘å±•æ–¹å‘åšå‡ºåšå®æœ‰åŠ›è´¡çŒ®ä»æ£€æµ‹æ¨¡å‹çš„ä»¿çœŸæ€§èƒ½æå‡åˆ°ç»¼åˆå®é™…è¿ç”¨å†åˆ°ç§‘ç ”å¹³å°ä¸æ–­å®Œå–„æŠ€æœ¯åˆ›æ–°ä½“ç°åœ¨ç ”ç©¶ä¸­çš„æ¯ä¸€ä¸ªç¯èŠ‚å½“ä¸­å¹¶åœ¨å¤šä¸ªè¡Œä¸šé¢†åŸŸå†…å‘æŒ¥ç€é‡è¦çš„ä½œç”¨æå‡ç§‘ç ”å›¢é˜Ÿçš„æˆæœäº§å‡ºçš„åŒæ—¶ä¹Ÿèƒ½åˆ‡å®æœ‰æ•ˆèµ‹èƒ½å¤šä¸ªäº§ä¸šå®é™…åº”ç”¨å‘æŒ¥äº§ä¸šæ•°å­—åŒ–è½¬å‹çš„æ™ºèƒ½æ¨åŠ¨åŠ›ç»¼åˆä½¿ç”¨å…¨é¢æ‰å®æœ‰åŠ›æ¨åŠ¨è¡Œä¸šæŠ€æœ¯é©æ–°ä¸å‘å±•è¿›æ­¥ä¸ºè¡Œä¸šå¸¦æ¥æ›´åŠ å¹¿é˜”çš„å‰æ™¯å’Œå‘å±•ç©ºé—´ã€‚å…·ä½“æ¥è¯´åŒ…æ‹¬ä»¥ä¸‹å‡ ç‚¹ï¼š</p>
<p>äºŒã€MLLMså¯¹å„ç§è§†é¢‘å¹²æ‰°æŠ€æœ¯çš„å“åº”å­˜åœ¨å·®å¼‚ä¸”è¿™ç§å·®å¼‚å¯èƒ½å½±å“åˆ°å…¶å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½ä¸å®‰å…¨æ€§é’ˆå¯¹å„ç§å¹²æ‰°æŠ€æœ¯è¿›è¡Œåˆ†æè¯„ä¼°ä»¥æ­ç¤ºæ¨¡å‹çš„å¼±ç‚¹å¹¶æä¾›æ”¹è¿›æ–¹å‘æˆä¸ºç ”ç©¶çš„é‡ç‚¹ã€‚é€šè¿‡å¯¹æ¨¡å‹è¿›è¡Œå¯¹æŠ—æ ·æœ¬æ”»å‡»ä¸è®­ç»ƒä»è€ŒåŠ å¼ºæ¨¡å‹çš„æŠ—å¹²æ‰°èƒ½åŠ›æå‡ºé’ˆå¯¹æ€§æ›´å¼ºçš„è®­ç»ƒæ–¹æ¡ˆä¸ºè¡Œä¸šåŸ¹å…»é«˜è´¨é‡é«˜æ°´å¹³çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯äººå‘˜è€Œå¼ºæœ‰åŠ›çš„è§£å†³æ–¹æ¡ˆæ˜¯ç ”ç©¶æœªæ¥äº§ä¸šå‘å±•æŠ€æœ¯æ”¯æ’‘çš„é‡è¦æ–¹å‘ä¹‹ä¸€æå‡ç ”ç©¶è´¨é‡å’ŒæŠ€æœ¯æ°´å¹³è¿›è€Œæå‡è¡Œä¸šçš„æ ¸å¿ƒç«äº‰åŠ›å¯¹äºè¡Œä¸šçš„é•¿è¿œå‘å±•å…·æœ‰é‡è¦æ„ä¹‰å’Œå¹¿é˜”å‰æ™¯æå‡è§†é¢‘ç†è§£æ¨¡å‹çš„æŠ—å¹²æ‰°èƒ½åŠ›æé«˜å…¶åœ¨å„ç§åº”ç”¨åœºæ™¯ä¸‹çš„æ€§èƒ½ä¸å¯é æ€§åŒæ—¶é™ä½å› æ¨¡å‹è„†å¼±æ€§å¸¦æ¥çš„é£é™©ä¸æŸå¤±å¯¹äºå¤šåª’ä½“é¢†åŸŸçš„å‘å±•è‡³å…³é‡è¦å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œæ½œåœ¨ç»æµä»·å€¼ä¸ºæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œäº§ä¸šå‡çº§æä¾›é‡è¦çš„æ”¯æŒå’ŒæŒ‡å¯¼æå‡ºå…³é”®æ€è·¯å¹¶åŠ ä»¥å®æ–½å¼€å±•æ›´é«˜æ°´å¹³çš„ç›¸å…³æŠ€æœ¯åº”ç”¨åšå‡ºæ›´ä¸ºå‡ºè‰²çš„å·¥ä½œä¸ºæ¨åŠ¨æ•´ä¸ªè¡Œä¸šçš„è¿›æ­¥å’Œå‘å±•è´¡çŒ®è‡ªå·±çš„åŠ›é‡å®ç°æŠ€æœ¯åˆ›æ–°çš„è·¨è¶Šå¼å‘å±•åŒæ—¶å¯¹äºæé«˜å…¬ä¼—ä¿¡æ¯çš„å®‰å…¨æ€§å’Œå¯ä¿¡åº¦ä¹Ÿæœ‰ç€é‡è¦çš„ç°å®æ„ä¹‰å’Œåº”ç”¨ä»·å€¼å¢å¼ºç¤¾ä¼šå…¬ä¼—å¯¹ç½‘ç»œä¿¡æ¯çš„ä¿¡ä»»åº¦å’Œå®‰å…¨æ„Ÿä»è€Œä¿ƒè¿›æ•´ä¸ªç¤¾ä¼šçš„å’Œè°ç¨³å®šå‘å±•æ¨åŠ¨è¡Œä¸šæŠ€æœ¯è¿›æ­¥å’Œåˆ›æ–°å‘å±•å¢å¼ºç¤¾ä¼šå…¬ä¼—å¯¹ç½‘ç»œä¿¡æ¯çš„ä¿¡ä»»åº¦å’Œå®‰å…¨æ„Ÿæˆä¸ºæ¨åŠ¨ç¤¾ä¼šå’Œè°ç¨³å®šå‘å±•çš„é‡è¦å› ç´ ä¹‹ä¸€ä¸ºè§£å†³å¤šåª’ä½“æ•°æ®å®‰å…¨å’Œè™šå‡ä¿¡æ¯æ³›æ»¥ç­‰é—®é¢˜æä¾›æœ‰åŠ›æ”¯æŒå¹¶ä¸ºè¡Œä¸šçš„æŒç»­å¥åº·å‘å±•æä¾›åšå®çš„ä¿éšœå¯¹ç†è§£è®¡ç®—æœºæŠ€æœ¯å®é™…åº”ç”¨ä¸ç³»ç»Ÿæ§åˆ¶ä¸‹çš„åº”ç”¨é¢†åŸŸæ›´å¸¦æ¥å¯é é«˜æ•ˆçš„è·¯å¾„ä»ä»¿çœŸè½¬å‘è½åœ°çš„ä¸€ä¸ªè¿‡ç¨‹å…·æœ‰é‡è¦æ„ä¹‰å’Œåº”ç”¨ä»·å€¼æå‡ç¤¾ä¼šå…¬ä¼—å¯¹ç½‘ç»œä¿¡æ¯çš„ä¿¡ä»»åº¦å’Œå®‰å…¨æ„Ÿä¹Ÿæ˜¯äº’è”ç½‘åº”ç”¨ä¸­çš„é‡è¦ç›®æ ‡ä¹‹ä¸€å¢å¼ºç½‘ç»œä¿¡æ¯çš„çœŸå®æ€§å’Œå¯ä¿¡åº¦å¯¹äºç»´æŠ¤ç¤¾ä¼šç¨³å®šå’Œä¿ƒè¿›ç»æµå‘å±•å…·æœ‰ååˆ†é‡è¦çš„ä½œç”¨å’Œæ„ä¹‰ã€‚å…·ä½“æ¥è¯´åŒ…æ‹¬ä»¥ä¸‹å‡ ç‚¹ï¼š</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19794">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-00a1e059fb63db499875827f1849fe6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bebe182346f8d190ceb4a609303d5f5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-867478dc7e6d115b5af9759f5fe1b434.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37c69ffbba9ff7c246f2a9e133ba05e4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f5fb4ff128881240eae0c68c5e03fe4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcdca311c659e4a39a41cab1d35da740.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AceMath-Advancing-Frontier-Math-Reasoning-with-Post-Training-and-Reward-Modeling"><a href="#AceMath-Advancing-Frontier-Math-Reasoning-with-Post-Training-and-Reward-Modeling" class="headerlink" title="AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward   Modeling"></a>AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward   Modeling</h2><p><strong>Authors:Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping</strong></p>
<p>In this paper, we introduce AceMath, a suite of frontier math models that excel in solving complex math problems, along with highly effective reward models capable of evaluating generated solutions and reliably identifying the correct ones. To develop the instruction-tuned math models, we propose a supervised fine-tuning (SFT) process that first achieves competitive performance across general domains, followed by targeted fine-tuning for the math domain using a carefully curated set of prompts and synthetically generated responses. The resulting model, AceMath-72B-Instruct greatly outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop math-specialized reward model, we first construct AceMath-RewardBench, a comprehensive and robust benchmark for evaluating math reward models across diverse problems and difficulty levels. After that, we present a systematic approach to build our math reward models. The resulting model, AceMath-72B-RM, consistently outperforms state-of-the-art reward models. Furthermore, when combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest average rm@8 score across the math reasoning benchmarks. We release model weights, training data, and evaluation benchmarks at: <a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/adlr/acemath">https://research.nvidia.com/labs/adlr/acemath</a> </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†AceMathï¼Œè¿™æ˜¯ä¸€ç³»åˆ—å‰æ²¿çš„æ•°å­¦æ¨¡å‹ï¼Œæ“…é•¿è§£å†³å¤æ‚çš„æ•°å­¦é—®é¢˜ï¼Œä»¥åŠé«˜æ•ˆçš„å¥–åŠ±æ¨¡å‹ï¼Œèƒ½å¤Ÿè¯„ä¼°ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆå¹¶å¯é åœ°è¯†åˆ«æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†å¼€å‘æŒ‡ä»¤è°ƒä¼˜çš„æ•°å­¦æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹ï¼Œé¦–å…ˆåœ¨å„ç§é€šç”¨é¢†åŸŸå®ç°å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œç„¶åä½¿ç”¨ç²¾å¿ƒæŒ‘é€‰çš„æç¤ºå’Œåˆæˆç”Ÿæˆçš„å“åº”è¿›è¡Œæ•°å­¦é¢†åŸŸçš„ç›®æ ‡å¾®è°ƒã€‚AceMath-72B-Instructæ¨¡å‹åœ¨æ€§èƒ½ä¸Šå¤§å¤§è¶…è¿‡äº†Qwen2.5-Math-72B-Instructã€GPT-4oå’ŒClaude-3.5 Sonnetã€‚ä¸ºäº†å¼€å‘ä¸“ä¸šåŒ–çš„æ•°å­¦å¥–åŠ±æ¨¡å‹ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºäº†AceMath-RewardBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢ä¸”ç¨³å¥çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°ä¸åŒé—®é¢˜å’Œéš¾åº¦çº§åˆ«çš„æ•°å­¦å¥–åŠ±æ¨¡å‹ã€‚ä¹‹åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ„å»ºæ•°å­¦å¥–åŠ±æ¨¡å‹çš„ç³»ç»Ÿçš„æ–¹æ³•ã€‚AceMath-72B-RMæ¨¡å‹ä¸€ç›´ä¼˜äºæœ€æ–°çš„å¥–åŠ±æ¨¡å‹ã€‚æ­¤å¤–ï¼Œå½“å°†AceMath-72B-Instructä¸AceMath-72B-RMç›¸ç»“åˆæ—¶ï¼Œæˆ‘ä»¬åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è·å¾—äº†æœ€é«˜çš„å¹³å‡rm@8åˆ†æ•°ã€‚æˆ‘ä»¬å‘å¸ƒçš„æ¨¡å‹æƒé‡ã€è®­ç»ƒæ•°æ®å’Œè¯„ä¼°åŸºå‡†æµ‹è¯•å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/adlr/acemath">https://research.nvidia.com/labs/adlr/acemath</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15084v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>AceMathæ˜¯ä¸€å¥—å‰æ²¿çš„æ•°å­¦æ¨¡å‹ï¼Œæ“…é•¿è§£å†³å¤æ‚çš„æ•°å­¦é—®é¢˜ï¼Œå¹¶é…å¤‡äº†é«˜æ•ˆçš„å¥–åŠ±æ¨¡å‹ï¼Œèƒ½è¯„ä¼°ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆå¹¶å‡†ç¡®è¯†åˆ«æ­£ç¡®çš„ç­”æ¡ˆã€‚è¯¥ç ”ç©¶é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹å¼€å‘äº†æŒ‡ä»¤è°ƒä¼˜çš„æ•°å­¦æ¨¡å‹ï¼Œé¦–å…ˆåœ¨å…¨åŸŸå®ç°ç«äº‰åŠ›æ€§èƒ½ï¼Œç„¶åé’ˆå¯¹æ•°å­¦é¢†åŸŸè¿›è¡Œå®šå‘å¾®è°ƒã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ„å»ºäº†AceMath-RewardBenchåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ•°å­¦å¥–åŠ±æ¨¡å‹ï¼Œå¹¶ç³»ç»Ÿæ„å»ºäº†æ•°å­¦å¥–åŠ±æ¨¡å‹ã€‚å°†æ•°å­¦æ¨¡å‹ä¸å¥–åŠ±æ¨¡å‹ç»“åˆï¼Œå®ç°äº†é«˜å¹³å‡rm@8åˆ†æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AceMathæ˜¯ä¸€ç³»åˆ—ä¼˜ç§€çš„æ•°å­¦æ¨¡å‹ï¼Œæ“…é•¿è§£å†³å¤æ‚çš„æ•°å­¦é—®é¢˜ã€‚</li>
<li>AceMathé…å¤‡äº†é«˜æ•ˆçš„å¥–åŠ±æ¨¡å‹ï¼Œèƒ½å¤Ÿè¯„ä¼°ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆå¹¶å‡†ç¡®è¯†åˆ«æ­£ç¡®ç­”æ¡ˆã€‚</li>
<li>ç ”ç©¶äººå‘˜é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹ï¼Œæé«˜äº†æ•°å­¦æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>AceMath-72B-Instructæ¨¡å‹åœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>æ„å»ºäº†AceMath-RewardBenchåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ•°å­¦å¥–åŠ±æ¨¡å‹ã€‚</li>
<li>ç³»ç»Ÿæ„å»ºäº†æ•°å­¦å¥–åŠ±æ¨¡å‹AceMath-72B-RMï¼Œå…¶æ€§èƒ½è¶…è¿‡ç°æœ‰å¥–åŠ±æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15084">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aafb33ce1da2b660008c91e998691d0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5da6e8dd4dc08530b69156c91cc49017.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e9493377d543f27458a2006d4b41e183.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ad5e8004600d7e99a771c8211935a86.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Automatic-Database-Configuration-Debugging-using-Retrieval-Augmented-Language-Models"><a href="#Automatic-Database-Configuration-Debugging-using-Retrieval-Augmented-Language-Models" class="headerlink" title="Automatic Database Configuration Debugging using Retrieval-Augmented   Language Models"></a>Automatic Database Configuration Debugging using Retrieval-Augmented   Language Models</h2><p><strong>Authors:Sibei Chen, Ju Fan, Bin Wu, Nan Tang, Chao Deng, Pengyi Wang, Ye Li, Jian Tan, Feifei Li, Jingren Zhou, Xiaoyong Du</strong></p>
<p>Database management system (DBMS) configuration debugging, e.g., diagnosing poorly configured DBMS knobs and generating troubleshooting recommendations, is crucial in optimizing DBMS performance. However, the configuration debugging process is tedious and, sometimes challenging, even for seasoned database administrators (DBAs) with sufficient experience in DBMS configurations and good understandings of the DBMS internals (e.g., MySQL or Oracle). To address this difficulty, we propose Andromeda, a framework that utilizes large language models (LLMs) to enable automatic DBMS configuration debugging. Andromeda serves as a natural surrogate of DBAs to answer a wide range of natural language (NL) questions on DBMS configuration issues, and to generate diagnostic suggestions to fix these issues. Nevertheless, directly prompting LLMs with these professional questions may result in overly generic and often unsatisfying answers. To this end, we propose a retrieval-augmented generation (RAG) strategy that effectively provides matched domain-specific contexts for the question from multiple sources. They come from related historical questions, troubleshooting manuals and DBMS telemetries, which significantly improve the performance of configuration debugging. To support the RAG strategy, we develop a document retrieval mechanism addressing heterogeneous documents and design an effective method for telemetry analysis. Extensive experiments on real-world DBMS configuration debugging datasets show that Andromeda significantly outperforms existing solutions. </p>
<blockquote>
<p>æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆDBMSï¼‰é…ç½®è°ƒè¯•å¯¹äºä¼˜åŒ–DBMSæ€§èƒ½è‡³å…³é‡è¦ï¼Œä¾‹å¦‚è¯Šæ–­é…ç½®ä¸å½“çš„DBMSæ—‹é’®å¹¶ç”Ÿæˆæ•…éšœæ’é™¤å»ºè®®ã€‚ç„¶è€Œï¼Œé…ç½®è°ƒè¯•è¿‡ç¨‹æ—¢ç¹çåˆæœ‰æ—¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå³ä½¿æ˜¯ç»éªŒä¸°å¯Œçš„æ•°æ®åº“ç®¡ç†å‘˜ï¼ˆDBAï¼‰åœ¨DBMSé…ç½®æ–¹é¢æ‹¥æœ‰è¶³å¤Ÿçš„ç»éªŒå¹¶å¯¹DBMSå†…éƒ¨æœ‰è‰¯å¥½ç†è§£ï¼ˆä¾‹å¦‚MySQLæˆ–Oracleï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€éš¾é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨è¿›è¡ŒDBMSé…ç½®è°ƒè¯•çš„æ¡†æ¶Andromedaã€‚Andromedaå¯ä»¥ä½œä¸ºDBAçš„è‡ªç„¶æ›¿ä»£è€…ï¼Œå›ç­”æœ‰å…³DBMSé…ç½®é—®é¢˜çš„å¹¿æ³›è‡ªç„¶è¯­è¨€ï¼ˆNLï¼‰é—®é¢˜ï¼Œå¹¶ç”Ÿæˆè§£å†³è¿™äº›é—®é¢˜çš„è¯Šæ–­å»ºè®®ã€‚ç„¶è€Œï¼Œç›´æ¥ä½¿ç”¨è¿™äº›é—®é¢˜æç¤ºLLMå¯èƒ½ä¼šå¾—åˆ°è¿‡äºé€šç”¨ä¸”å¾€å¾€ä»¤äººä¸æ»¡æ„çš„ç­”æ¡ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼‰ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°ä»å¤šä¸ªæ¥æºä¸ºé—®é¢˜æä¾›åŒ¹é…çš„ç‰¹å®šé¢†åŸŸä¸Šä¸‹æ–‡ã€‚è¿™äº›æ¥æºåŒ…æ‹¬ç›¸å…³çš„å†å²é—®é¢˜ã€æ•…éšœæ’é™¤æ‰‹å†Œå’ŒDBMSé¥æµ‹æ•°æ®ï¼Œä»è€Œå¤§å¤§æé«˜äº†é…ç½®è°ƒè¯•çš„æ€§èƒ½ã€‚ä¸ºäº†æ”¯æŒRAGç­–ç•¥ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è§£å†³å¼‚æ„æ–‡æ¡£çš„æ–‡ä»¶æ£€ç´¢æœºåˆ¶ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æœ‰æ•ˆçš„é¥æµ‹åˆ†ææ–¹æ³•ã€‚åœ¨çœŸå®ä¸–ç•Œçš„DBMSé…ç½®è°ƒè¯•æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAndromedaæ˜¾è‘—ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07548v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆDBMSï¼‰é…ç½®è°ƒè¯•å¯¹äºä¼˜åŒ–DBMSæ€§èƒ½è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œé…ç½®è°ƒè¯•è¿‡ç¨‹ç¹çä¸”æœ‰æ—¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå³ä½¿å¯¹äºç»éªŒä¸°å¯Œçš„æ•°æ®åº“ç®¡ç†å‘˜ï¼ˆDBAï¼‰ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Andromedaæ¡†æ¶ï¼Œå®ç°DBMSé…ç½®çš„è‡ªåŠ¨è°ƒè¯•ã€‚Andromedaå¯æ›¿ä»£DBAå›ç­”æœ‰å…³DBMSé…ç½®çš„å„ç±»è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œå¹¶ç”Ÿæˆè¯Šæ–­å»ºè®®ä»¥è§£å†³é—®é¢˜ã€‚ä½†æ˜¯ï¼Œç›´æ¥ä½¿ç”¨è¿™äº›é—®é¢˜æç¤ºLLMå¯èƒ½ä¼šå¾—åˆ°è¿‡äºç¬¼ç»Ÿä¸”å¸¸å¸¸ä¸ä»¤äººæ»¡æ„çš„ç­”æ¡ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­–ç•¥ï¼Œè¯¥ç­–ç•¥é€šè¿‡ä»å¤šä¸ªæ¥æºä¸ºé—®é¢˜æä¾›åŒ¹é…çš„ç‰¹å®šé¢†åŸŸä¸Šä¸‹æ–‡ï¼Œæ˜¾è‘—æé«˜äº†é…ç½®è°ƒè¯•çš„æ€§èƒ½ã€‚è¿™äº›æ¥æºåŒ…æ‹¬ç›¸å…³å†å²é—®é¢˜ã€æ•…éšœæ’é™¤æ‰‹å†Œå’ŒDBMSé¥æµ‹æ•°æ®ã€‚ä¸ºæ”¯æŒRAGç­–ç•¥ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¤„ç†å¼‚æ„æ–‡æ¡£çš„æ–‡æ¡£æ£€ç´¢æœºåˆ¶ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æœ‰æ•ˆçš„é¥æµ‹åˆ†ææ–¹æ³•ã€‚åœ¨çœŸå®ä¸–ç•Œçš„DBMSé…ç½®è°ƒè¯•æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒAndromedaæ˜¾è‘—ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆDBMSï¼‰é…ç½®è°ƒè¯•å¯¹äºæ€§èƒ½ä¼˜åŒ–è‡³å…³é‡è¦ï¼Œä½†è¿‡ç¨‹ç¹çä¸”å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>æå‡ºä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Andromedaæ¡†æ¶è¿›è¡Œè‡ªåŠ¨DBMSé…ç½®è°ƒè¯•ã€‚</li>
<li>Andromedaèƒ½å¤Ÿå›ç­”æœ‰å…³DBMSé…ç½®çš„å„ç±»è‡ªç„¶è¯­è¨€é—®é¢˜å¹¶ç”Ÿæˆè¯Šæ–­å»ºè®®ã€‚</li>
<li>ç›´æ¥æç¤ºLLMå¯èƒ½ä¼šå¾—åˆ°ä¸æ»¡æ„çš„ç­”æ¡ˆï¼Œå› æ­¤æå‡ºä¸€ç§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­–ç•¥ã€‚</li>
<li>RAGç­–ç•¥é€šè¿‡ä»å¤šä¸ªæ¥æºæä¾›åŒ¹é…çš„ç‰¹å®šé¢†åŸŸä¸Šä¸‹æ–‡æ¥æé«˜é…ç½®è°ƒè¯•çš„æ€§èƒ½ã€‚</li>
<li>Andromedaæ”¯æŒå¤„ç†å¼‚æ„æ–‡æ¡£çš„æ–‡æ¡£æ£€ç´¢æœºåˆ¶ä»¥åŠæœ‰æ•ˆçš„é¥æµ‹åˆ†ææ–¹æ³•ã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAndromedaåœ¨DBMSé…ç½®è°ƒè¯•æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07548">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-26d417a50447e3039c7f011e3a15f303.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-581018f4e166f314b7fc8f9bc0a61682.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-722cd91f2ccb543f5814105e5e8d0940.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-357f9e71814c9df52a3362ee38242afd.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="BatchLLM-Optimizing-Large-Batched-LLM-Inference-with-Global-Prefix-Sharing-and-Throughput-oriented-Token-Batching"><a href="#BatchLLM-Optimizing-Large-Batched-LLM-Inference-with-Global-Prefix-Sharing-and-Throughput-oriented-Token-Batching" class="headerlink" title="BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix   Sharing and Throughput-oriented Token Batching"></a>BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix   Sharing and Throughput-oriented Token Batching</h2><p><strong>Authors:Zhen Zheng, Xin Ji, Taosong Fang, Fanghao Zhou, Chuanjie Liu, Gang Peng</strong></p>
<p>Large language models (LLMs) increasingly play an important role in a wide range of information processing and management tasks. Many of these tasks are performed in large batches or even offline, and the performance indictor for which is throughput. These tasks usually show the characteristic of prefix sharing, where different prompt input can partially show the common prefix. However, the existing LLM inference engines tend to optimize the streaming requests and show limitations of supporting the large batched tasks with the prefix sharing characteristic. The existing solutions use the LRU-based cache to reuse the KV context of common prefix between requests. The KV context that are about to be reused may prematurely evicted with the implicit cache management. Besides, the streaming oriented systems do not leverage the request-batch information and can not mix the decoding tokens with the prefill chunks to the best for the batched scenarios, and thus fails to saturate the GPU. We propose BatchLLM to address the above problems. BatchLLM explicitly identifies the common prefixes globally. The requests sharing the same prefix will be scheduled together to reuse the KV context the best. BatchLLM reorders the requests and schedules the requests with larger ratio of decoding first to better mix the decoding tokens with the latter prefill chunks, and applies memory-centric token batching to enlarge the token-batch sizes, which helps to increase the GPU utilization. Finally, BatchLLM optimizes the prefix-shared Attention kernel with horizontal fusion to reduce tail effect and kernel launch overhead. Extensive evaluation shows that BatchLLM outperforms vLLM and SGLang by 1.3$\times$ to 10.8$\times$ on a set of microbenchmarks and a typical industry workload under different hardware environments. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¹¿æ³›çš„ä¿¡æ¯å¤„ç†å’Œç®¡ç†ä»»åŠ¡ä¸­å‘æŒ¥ç€è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚è¿™äº›ä»»åŠ¡ä¸­çš„è®¸å¤šéƒ½æ˜¯æ‰¹é‡å¤„ç†ç”šè‡³ç¦»çº¿å¤„ç†çš„ï¼Œå…¶æ€§èƒ½æŒ‡æ ‡æ˜¯ååé‡ã€‚è¿™äº›ä»»åŠ¡é€šå¸¸è¡¨ç°å‡ºå‰ç¼€å…±äº«çš„ç‰¹å¾ï¼Œä¸åŒçš„æç¤ºè¾“å…¥å¯ä»¥éƒ¨åˆ†æ˜¾ç¤ºå…±åŒçš„å‰ç¼€ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMæ¨ç†å¼•æ“å€¾å‘äºä¼˜åŒ–æµå¼è¯·æ±‚ï¼Œå¹¶åœ¨æ”¯æŒå…·æœ‰å‰ç¼€å…±äº«ç‰¹å¾çš„å¤§æ‰¹é‡ä»»åŠ¡æ—¶æ˜¾ç¤ºå‡ºå±€é™æ€§ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆä½¿ç”¨åŸºäºLRUçš„ç¼“å­˜æ¥é‡ç”¨è¯·æ±‚ä¹‹é—´çš„å¸¸è§å‰ç¼€çš„KVä¸Šä¸‹æ–‡ã€‚å³å°†è¢«é‡ç”¨çš„KVä¸Šä¸‹æ–‡å¯èƒ½ä¼šå› éšå¼ç¼“å­˜ç®¡ç†è€Œæå‰è¢«é€å‡ºã€‚æ­¤å¤–ï¼Œæµå¼å®šå‘ç³»ç»Ÿæ²¡æœ‰åˆ©ç”¨è¯·æ±‚æ‰¹å¤„ç†ä¿¡æ¯ï¼Œæ— æ³•å°†è§£ç ä»¤ç‰Œä¸é¢„å¡«å……å—æ··åˆåˆ°æœ€ä½³çŠ¶æ€ï¼Œä»è€Œæ— æ³•æ»¡è¶³GPUçš„éœ€æ±‚ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†BatchLLMã€‚BatchLLMæ˜¾å¼åœ°å…¨å±€è¯†åˆ«å…¬å…±å‰ç¼€ã€‚å…±äº«ç›¸åŒå‰ç¼€çš„è¯·æ±‚å°†ä¸€èµ·è°ƒåº¦ï¼Œä»¥æœ€ä½³æ–¹å¼é‡ç”¨KVä¸Šä¸‹æ–‡ã€‚BatchLLMé‡æ–°æ’åºè¯·æ±‚ï¼Œå¹¶ä¼˜å…ˆè°ƒåº¦è§£ç æ¯”ä¾‹è¾ƒå¤§çš„è¯·æ±‚ï¼Œä»¥ä¾¿æ›´å¥½åœ°å°†è§£ç ä»¤ç‰Œä¸åç»­çš„é¢„å¡«å……å—æ··åˆï¼Œå¹¶é‡‡ç”¨ä»¥å†…å­˜ä¸ºä¸­å¿ƒçš„ä»¤ç‰Œæ‰¹å¤„ç†æ¥æ‰©å¤§ä»¤ç‰Œæ‰¹å¤„ç†å¤§å°ï¼Œæœ‰åŠ©äºæé«˜GPUåˆ©ç”¨ç‡ã€‚æœ€åï¼ŒBatchLLMé€šè¿‡æ°´å¹³èåˆä¼˜åŒ–äº†å…±äº«å‰ç¼€çš„æ³¨æ„åŠ›å†…æ ¸ï¼Œä»¥å‡å°‘å°¾éƒ¨æ•ˆåº”å’Œå†…æ ¸å¯åŠ¨å¼€é”€ã€‚è¯„ä¼°æ˜¾ç¤ºï¼ŒBatchLLMåœ¨ä¸€ç»„å¾®åŸºå‡†æµ‹è¯•å’Œå…¸å‹è¡Œä¸šå·¥ä½œè´Ÿè½½çš„ä¸åŒç¡¬ä»¶ç¯å¢ƒä¸‹ï¼Œæ€§èƒ½ä¼˜äºvLLMå’ŒSGLangï¼ŒåŠ é€Ÿæ¯”ä¸º1.3å€è‡³10.8å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.03594v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†ä¿¡æ¯ç®¡ç†ä»»åŠ¡æ—¶è¡¨ç°å‡ºæ—¥ç›Šé‡è¦çš„ä½œç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨æ‰¹é‡å’Œç¦»çº¿ä»»åŠ¡ä¸­ã€‚é’ˆå¯¹ç°æœ‰LLMæ¨ç†å¼•æ“åœ¨å¤„ç†å…·æœ‰å‰ç¼€å…±äº«ç‰¹æ€§çš„å¤§æ‰¹é‡ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†BatchLLMæ–¹æ¡ˆã€‚BatchLLMé€šè¿‡å…¨å±€è¯†åˆ«å…±åŒå‰ç¼€ã€é‡æ–°æ’åºè¯·æ±‚ã€ä¼˜åŒ–å†…å­˜ä¸ºä¸­å¿ƒçš„ä»¤ç‰Œæ‰¹å¤„ç†ä»¥åŠä¼˜åŒ–å‰ç¼€å…±äº«çš„å…³æ³¨æ ¸æ¥æ”¹è¿›ç°æœ‰è§£å†³æ–¹æ¡ˆã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒBatchLLMåœ¨å¾®åŸºå‡†æµ‹è¯•å’Œå…¸å‹å·¥ä¸šå·¥ä½œè´Ÿè½½ä¸Šåˆ†åˆ«è¶…è¶Šäº†vLLMå’ŒSGLang 1.3è‡³10.8å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMs å·²åœ¨ä¿¡æ¯å¤„ç†å’Œ management ä»»åŠ¡ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨æ‰¹é‡å’Œç¦»çº¿ä»»åŠ¡ä¸­ã€‚</li>
<li>ç°æœ‰LLMæ¨ç†å¼•æ“åœ¨å¤„ç†å…·æœ‰å‰ç¼€å…±äº«ç‰¹æ€§çš„å¤§æ‰¹é‡ä»»åŠ¡æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>BatchLLM é€šè¿‡è¯†åˆ«å…±åŒå‰ç¼€ã€é‡æ–°æ’åºè¯·æ±‚ã€ä¼˜åŒ–å†…å­˜ä»¤ç‰Œæ‰¹å¤„ç†ä»¥åŠä¼˜åŒ–å…³æ³¨æ ¸æ¥æ”¹è¿›ç°æœ‰è§£å†³æ–¹æ¡ˆã€‚</li>
<li>BatchLLM æé«˜äº† GPU çš„åˆ©ç”¨ç‡ã€‚</li>
<li>BatchLLM åœ¨å¾®åŸºå‡†æµ‹è¯•å’Œå…¸å‹å·¥ä¸šå·¥ä½œè´Ÿè½½ä¸Šçš„æ€§èƒ½è¶…è¶Šäº†å…¶ä»–æ¨¡å‹ã€‚</li>
<li>BatchLLM é€šè¿‡å…¨å±€è¯†åˆ«å…±åŒå‰ç¼€æ¥æœ€å¤§åŒ– KV ä¸Šä¸‹æ–‡çš„é‡å¤ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.03594">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7f3b38897cfefdd982abb5ff6b224170.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f25ee743df247ccc8d0415efcc71b9b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e74f15af924c064d7c5952565e64d28c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-048f14c08acf9cdb851834e83758a4bc.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="VLSBench-Unveiling-Visual-Leakage-in-Multimodal-Safety"><a href="#VLSBench-Unveiling-Visual-Leakage-in-Multimodal-Safety" class="headerlink" title="VLSBench: Unveiling Visual Leakage in Multimodal Safety"></a>VLSBench: Unveiling Visual Leakage in Multimodal Safety</h2><p><strong>Authors:Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao</strong></p>
<p>Safety concerns of Multimodal large language models (MLLMs) have gradually become an important problem in various applications. Surprisingly, previous works indicate a counter-intuitive phenomenon that using textual unlearning to align MLLMs achieves comparable safety performances with MLLMs trained with image-text pairs. To explain such a counter-intuitive phenomenon, we discover a visual safety information leakage (VSIL) problem in existing multimodal safety benchmarks, i.e., the potentially risky and sensitive content in the image has been revealed in the textual query. In this way, MLLMs can easily refuse these sensitive text-image queries according to textual queries. However, image-text pairs without VSIL are common in real-world scenarios and are overlooked by existing multimodal safety benchmarks. To this end, we construct multimodal visual leakless safety benchmark (VLSBench) preventing visual safety leakage from image to textual query with 2.4k image-text pairs. Experimental results indicate that VLSBench poses a significant challenge to both open-source and close-source MLLMs, including LLaVA, Qwen2-VL, Llama3.2-Vision, and GPT-4o. This study demonstrates that textual alignment is enough for multimodal safety scenarios with VSIL, while multimodal alignment is a more promising solution for multimodal safety scenarios without VSIL. Please see our code and data at: <a target="_blank" rel="noopener" href="https://hxhcreate.github.io/vlsbench.github.io/">https://hxhcreate.github.io/vlsbench.github.io/</a> </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å®‰å…¨é—®é¢˜åœ¨å„ç§åº”ç”¨ä¸­é€æ¸æˆä¸ºä¸€ä¸ªé‡è¦çš„é—®é¢˜ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä¹‹å‰çš„ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨æ–‡æœ¬é—å¿˜æ¥å¯¹MLLMsè¿›è¡Œå¯¹é½è®­ç»ƒï¼Œå…¶å®‰å…¨æ€§èƒ½ä¸ç”¨å›¾åƒ-æ–‡æœ¬å¯¹è®­ç»ƒçš„MLLMsç›¸å½“ã€‚ä¸ºäº†è§£é‡Šè¿™ç§åç›´è§‰çš„ç°è±¡ï¼Œæˆ‘ä»¬å‘ç°ç°æœ‰å¤šæ¨¡æ€å®‰å…¨åŸºå‡†ä¸­å­˜åœ¨è§†è§‰å®‰å…¨ä¿¡æ¯æ³„éœ²ï¼ˆVSILï¼‰é—®é¢˜ï¼Œå³å›¾åƒä¸­çš„æ½œåœ¨å±é™©å’Œæ•æ„Ÿå†…å®¹å·²åœ¨æ–‡æœ¬æŸ¥è¯¢ä¸­æ³„éœ²ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒMLLMså¯ä»¥æ ¹æ®æ–‡æœ¬æŸ¥è¯¢è½»æ¾æ‹’ç»è¿™äº›æ•æ„Ÿçš„æ–‡æœ¬-å›¾åƒæŸ¥è¯¢ã€‚ç„¶è€Œï¼Œåœ¨ç°å®åœºæ™¯ä¸­ï¼Œæ²¡æœ‰VSILçš„å›¾åƒ-æ–‡æœ¬å¯¹æ˜¯å¸¸è§çš„ï¼Œä½†è¢«ç°æœ‰å¤šæ¨¡æ€å®‰å…¨åŸºå‡†æ‰€å¿½è§†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº†é˜²æ­¢å›¾åƒåˆ°æ–‡æœ¬æŸ¥è¯¢çš„è§†è§‰å®‰å…¨æ³„éœ²çš„å¤šæ¨¡æ€è§†è§‰æ— æ³„æ¼å®‰å…¨åŸºå‡†ï¼ˆVLSBenchï¼‰ï¼ŒåŒ…å«2. å€¼å¾—æ³¨æ„çš„æ˜¯è¿™ä¸€ç ”ç©¶æˆæœå¹¶éç©ºä¸­æ¥¼é˜æˆ–çº¯ç†è®ºæ„æƒ³ã€‚åœ¨æˆ‘ä»¬æä¾›çš„é“¾æ¥åœ°å€ä¸Šï¼Œ[ç½‘å€é“¾æ¥]ï¼Œä½ å¯ä»¥æŸ¥é˜…åˆ°æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®ã€‚è¯¥ç ”ç©¶å‘ç°å¯¹äºæœ‰è§†è§‰å®‰å…¨ä¿¡æ¯æ³„éœ²çš„å¤šæ¨¡æ€å®‰å…¨åœºæ™¯è€Œè¨€ï¼Œæ–‡æœ¬å¯¹é½å·²è¶³å¤Ÿåº”å¯¹ï¼›è€Œå¯¹äºæ²¡æœ‰è§†è§‰å®‰å…¨ä¿¡æ¯æ³„éœ²çš„å¤šæ¨¡æ€å®‰å…¨åœºæ™¯è€Œè¨€ï¼Œå¤šæ¨¡æ€å¯¹é½åˆ™æ˜¯ä¸€ä¸ªæ›´æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.19939v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å®‰å…¨æ€§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å„ç§åº”ç”¨ä¸­çš„é‡è¦æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨æ–‡æœ¬é—å¿˜å¯¹é½MLLMsçš„æ–¹æ³•åœ¨å®‰å…¨æ€§èƒ½ä¸Šå¯ä¸ä½¿ç”¨å›¾åƒ-æ–‡æœ¬å¯¹è®­ç»ƒçš„MLLMsç›¸åª²ç¾ã€‚é’ˆå¯¹è¿™ä¸€åå¸¸ç°è±¡ï¼Œå‘ç°äº†ç°æœ‰å¤šæ¨¡æ€å®‰å…¨åŸºå‡†ä¸­å­˜åœ¨çš„è§†è§‰å®‰å…¨ä¿¡æ¯æ³„éœ²ï¼ˆVSILï¼‰é—®é¢˜ã€‚å› æ­¤ï¼Œæ„å»ºäº†é˜²æ­¢å›¾åƒåˆ°æ–‡æœ¬æŸ¥è¯¢çš„è§†è§‰å®‰å…¨æ³„éœ²çš„å¤šæ¨¡æ€è§†è§‰æ— æ³„æ¼å®‰å…¨åŸºå‡†ï¼ˆVLSBenchï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVLSBenchå¯¹å¼€æºå’Œé—­æºMLLMsæ„æˆé‡å¤§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬LLaVAã€Qwen2-VLç­‰æ¨¡å‹ã€‚æœ¬æ–‡è¡¨æ˜ï¼Œåœ¨æœ‰VSILçš„å¤šæ¨¡æ€å®‰å…¨åœºæ™¯ä¸­ï¼Œæ–‡æœ¬å¯¹é½è¶³å¤Ÿï¼Œè€Œæ— VSILçš„å¤šæ¨¡æ€å®‰å…¨åœºæ™¯ä¸­ï¼Œå¤šæ¨¡æ€å¯¹é½æ›´æœ‰å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å®‰å…¨é—®é¢˜åœ¨å„ç±»åº”ç”¨ä¸­é€æ¸å‡¸æ˜¾ã€‚</li>
<li>æ–‡æœ¬é—å¿˜ä¸å¯¹é½æ–¹æ³•åœ¨MLLMå®‰å…¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºä¸å›¾åƒ-æ–‡æœ¬å¯¹è®­ç»ƒç›¸å½“çš„æ•ˆèƒ½ã€‚</li>
<li>å­˜åœ¨è§†è§‰å®‰å…¨ä¿¡æ¯æ³„éœ²ï¼ˆVSILï¼‰é—®é¢˜åœ¨å¤šæ¨¡æ€å®‰å…¨åŸºå‡†ä¸­ã€‚</li>
<li>VLSBenchåŸºå‡†æ„å»ºæˆåŠŸï¼Œé˜²æ­¢äº†å›¾åƒåˆ°æ–‡æœ¬æŸ¥è¯¢çš„è§†è§‰å®‰å…¨æ³„éœ²ã€‚</li>
<li>VLSBenchå¯¹å¤šç§MLLMsæ„æˆæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¼€æºå’Œé—­æºæ¨¡å‹ã€‚</li>
<li>åœ¨å­˜åœ¨VSILçš„å¤šæ¨¡æ€å®‰å…¨åœºæ™¯ä¸­ï¼Œæ–‡æœ¬å¯¹é½æ–¹æ³•è¶³å¤Ÿæœ‰æ•ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.19939">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3f3d3f6859b931c630c7dba40af4a883.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a229ce8c1c89328a9fd8cfb48e37d07e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0f415583dccb67d5caa5ab791743bfb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6c1c8d17114a7f60bdd5bc658658bc0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd990e44b494512c0d157bce9665943b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-917820fa872d3502b8fa65600d4795fb.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Mitigating-Sycophancy-in-Decoder-Only-Transformer-Architectures-Synthetic-Data-Intervention"><a href="#Mitigating-Sycophancy-in-Decoder-Only-Transformer-Architectures-Synthetic-Data-Intervention" class="headerlink" title="Mitigating Sycophancy in Decoder-Only Transformer Architectures:   Synthetic Data Intervention"></a>Mitigating Sycophancy in Decoder-Only Transformer Architectures:   Synthetic Data Intervention</h2><p><strong>Authors:Libo Wang</strong></p>
<p>To address the sycophancy problem caused by reinforcement learning from human feedback in large language models, this research applies synthetic data intervention technology to the decoder-only transformer architecture. Based on the research gaps in the existing literature, the researcher designed an experimental process to reduce the tendency of models to cater by generating diversified data, and used GPT4o as an experimental tool for verification. The experiment used 100 true and false questions, and compared the performance of the model trained with synthetic data intervention and the original untrained model on multiple indicators. The results show that the SDI training model supports the technology in terms of accuracy rate and sycophancy rate and has significant effectiveness in reducing sycophancy phenomena. Notably, the data set, experimental process, code and data results have been uploaded to Github, the link is <a target="_blank" rel="noopener" href="https://github.com/brucewang123456789/GeniusTrail.git">https://github.com/brucewang123456789/GeniusTrail.git</a>. </p>
<blockquote>
<p>é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç”±äººç±»åé¦ˆå¼•èµ·çš„é€¢è¿é—®é¢˜ï¼Œæœ¬ç ”ç©¶å°†åˆæˆæ•°æ®å¹²é¢„æŠ€æœ¯åº”ç”¨äºä»…è§£ç å™¨å˜æ¢å™¨æ¶æ„ã€‚åŸºäºç°æœ‰æ–‡çŒ®çš„ç ”ç©¶ç©ºç™½ï¼Œç ”ç©¶è€…è®¾è®¡äº†ä¸€ä¸ªå®éªŒè¿‡ç¨‹ï¼Œä»¥å‡å°‘æ¨¡å‹äº§ç”Ÿå¤šæ ·åŒ–æ•°æ®ä»¥è¿åˆçš„å€¾å‘ï¼Œå¹¶ä½¿ç”¨GPT4oä½œä¸ºéªŒè¯çš„å®éªŒå·¥å…·ã€‚å®éªŒé‡‡ç”¨100ä¸ªçœŸå®å’Œè™šå‡é—®é¢˜ï¼Œæ¯”è¾ƒç»è¿‡åˆæˆæ•°æ®å¹²é¢„è®­ç»ƒå’Œæœªç»è®­ç»ƒçš„åŸå§‹æ¨¡å‹åœ¨å¤šæŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼ŒSDIè®­ç»ƒæ¨¡å‹åœ¨å‡†ç¡®ç‡å’Œå¥‰æ‰¿ç‡æ–¹é¢æ”¯æŒè¯¥æŠ€æœ¯ï¼Œå¹¶èƒ½æœ‰æ•ˆå‡å°‘å¥‰æ‰¿ç°è±¡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ•°æ®é›†ã€å®éªŒè¿‡ç¨‹ã€ä»£ç å’Œæ•°æ®ç»“æœå·²ä¸Šä¼ åˆ°Githubï¼Œé“¾æ¥ä¸º<a target="_blank" rel="noopener" href="https://github.com/brucewang123456789/GeniusTrail.git%E3%80%82">https://github.com/brucewang123456789/GeniusTrail.gitã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.10156v3">PDF</a> This research is also submitted to OpenReview. The main text is 9   pages (excluding citations), 7 figures, and 1 table</p>
<p><strong>Summary</strong></p>
<p>ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç”±äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ å¯¼è‡´çš„åªšä¿—é—®é¢˜ï¼Œé‡‡ç”¨åˆæˆæ•°æ®å¹²é¢„æŠ€æœ¯åº”ç”¨äºä»…è§£ç çš„è½¬æ¢å™¨æ¶æ„æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚è¯¥ç ”ç©¶å¡«è¡¥äº†ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ï¼Œé€šè¿‡ç”Ÿæˆå¤šæ ·åŒ–æ•°æ®æ¥å‡å°‘æ¨¡å‹è¿åˆå€¾å‘çš„å®éªŒè®¾è®¡ï¼Œå¹¶åˆ©ç”¨GPT4oä½œä¸ºéªŒè¯å®éªŒå·¥å…·ã€‚å®éªŒé‡‡ç”¨100ä¸ªçœŸå®ä¸è™šå‡é—®é¢˜ï¼Œæ¯”è¾ƒåˆæˆæ•°æ®å¹²é¢„è®­ç»ƒæ¨¡å‹ä¸åŸå§‹æœªè®­ç»ƒæ¨¡å‹åœ¨å¤šæŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºï¼ŒSDIè®­ç»ƒæ¨¡å‹åœ¨å‡†ç¡®ç‡å’Œåªšä¿—ç‡æ–¹é¢æ”¯æŒè¯¥æŠ€æœ¯ï¼Œå¹¶åœ¨å‡å°‘åªšä¿—ç°è±¡æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚ç›¸å…³æ•°æ®é›†ã€å®éªŒè¿‡ç¨‹ã€ä»£ç åŠæ•°æ®ç»“æœå·²ä¸Šä¼ è‡³Githubå¹³å°ï¼Œé“¾æ¥ä¸º[é“¾æ¥åœ°å€]ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥ç ”ç©¶ä½¿ç”¨åˆæˆæ•°æ®å¹²é¢„æŠ€æœ¯æ¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å› å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆå¯¼è‡´çš„åªšä¿—é—®é¢˜ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿé’ˆå¯¹ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ï¼Œè®¾è®¡äº†ç”Ÿæˆå¤šæ ·åŒ–æ•°æ®çš„å®éªŒæ¥å‡å°‘æ¨¡å‹çš„è¿åˆå€¾å‘ã€‚</li>
<li>GPT4oè¢«ç”¨ä½œéªŒè¯å®éªŒå·¥å…·ï¼Œå®éªŒæ¶‰åŠ100ä¸ªçœŸå®ä¸è™šå‡é—®é¢˜ã€‚</li>
<li>å¯¹æ¯”äº†åˆæˆæ•°æ®å¹²é¢„è®­ç»ƒæ¨¡å‹ä¸åŸå§‹æœªè®­ç»ƒæ¨¡å‹åœ¨å¤šæŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œåˆæˆæ•°æ®å¹²é¢„è®­ç»ƒæ¨¡å‹åœ¨å‡†ç¡®ç‡å’Œåªšä¿—ç‡æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ•ˆæœã€‚</li>
<li>æ•°æ®é›†ã€å®éªŒè¿‡ç¨‹ã€ä»£ç åŠæ•°æ®ç»“æœå·²å…¬å¼€åœ¨Githubå¹³å°ä¸Šã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.10156">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-18ca115bff1da38e032a8854a9af1046.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60340bf3d30c022ae26590c05084a159.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8dca582572308909a595b858d4a830aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e717fbcd223039c7fe7ce5abddad713f.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Jailbreaking-as-a-Reward-Misspecification-Problem"><a href="#Jailbreaking-as-a-Reward-Misspecification-Problem" class="headerlink" title="Jailbreaking as a Reward Misspecification Problem"></a>Jailbreaking as a Reward Misspecification Problem</h2><p><strong>Authors:Zhihui Xie, Jiahui Gao, Lei Li, Zhenguo Li, Qi Liu, Lingpeng Kong</strong></p>
<p>The widespread adoption of large language models (LLMs) has raised concerns about their safety and reliability, particularly regarding their vulnerability to adversarial attacks. In this paper, we propose a novel perspective that attributes this vulnerability to reward misspecification during the alignment process. This misspecification occurs when the reward function fails to accurately capture the intended behavior, leading to misaligned model outputs. We introduce a metric ReGap to quantify the extent of reward misspecification and demonstrate its effectiveness and robustness in detecting harmful backdoor prompts. Building upon these insights, we present ReMiss, a system for automated red teaming that generates adversarial prompts in a reward-misspecified space. ReMiss achieves state-of-the-art attack success rates on the AdvBench benchmark against various target aligned LLMs while preserving the human readability of the generated prompts. Furthermore, these attacks on open-source models demonstrate high transferability to closed-source models like GPT-4o and out-of-distribution tasks from HarmBench. Detailed analysis highlights the unique advantages of the proposed reward misspecification objective compared to previous methods, offering new insights for improving LLM safety and robustness. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹¿æ³›åº”ç”¨å¼•å‘äº†äººä»¬å¯¹å…¶å®‰å…¨æ€§å’Œå¯é æ€§çš„æ‹…å¿§ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬æ˜¯å¦å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„è„†å¼±æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªæ–°çš„è§’åº¦æå‡ºï¼Œå°†è¿™ç§è„†å¼±æ€§å½’å› äºå¯¹é½è¿‡ç¨‹ä¸­çš„å¥–åŠ±è¯¯æŒ‡å®šã€‚å½“å¥–åŠ±å‡½æ•°æ— æ³•å‡†ç¡®æ•æ‰é¢„æœŸè¡Œä¸ºæ—¶ï¼Œå°±ä¼šå‡ºç°è¿™ç§è¯¯æŒ‡å®šï¼Œä»è€Œå¯¼è‡´æ¨¡å‹è¾“å‡ºå¤±å‡†ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåº¦é‡æ ‡å‡†ReGapæ¥é‡åŒ–å¥–åŠ±è¯¯æŒ‡å®šçš„ç¨‹åº¦ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨æ£€æµ‹æœ‰å®³åé—¨æç¤ºæ—¶çš„æœ‰æ•ˆæ€§å’Œç¨³å¥æ€§ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ReMissç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè‡ªåŠ¨ç”Ÿæˆå¯¹æŠ—æ€§æç¤ºçš„è‡ªåŠ¨åŒ–çº¢é˜Ÿç³»ç»Ÿï¼Œåœ¨å¥–åŠ±è¯¯æŒ‡å®šçš„ç©ºé—´ä¸­å·¥ä½œã€‚ReMissåœ¨AdvBenchåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†é’ˆå¯¹å„ç§ç›®æ ‡å¯¹é½LLMçš„æœ€æ–°æ”»å‡»æˆåŠŸç‡ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆæç¤ºçš„å¯è¯»æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›å¯¹å¼€æºæ¨¡å‹çš„æ”»å‡»è¡¨ç°å‡ºå¯¹å°é—­æºæ¨¡å‹ï¼ˆå¦‚GPT-4oï¼‰å’Œä»»åŠ¡å¤–çš„é«˜å¯è½¬ç§»æ€§ã€‚è¯¦ç»†çš„åˆ†æçªå‡ºäº†ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„å¥–åŠ±è¯¯æŒ‡å®šç›®æ ‡çš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œä¸ºæ”¹è¿›LLMçš„å®‰å…¨æ€§å’Œç¨³å¥æ€§æä¾›äº†æ–°çš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.14393v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹¿æ³›åº”ç”¨å¼•å‘äº†å…³äºå…¶å®‰å…¨æ€§å’Œå¯é æ€§çš„æ‹…å¿§ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºä¸€ä¸ªæ–°è§†è§’ï¼Œå°†è¿™ä¸€æ¼æ´å½’å› äºå¯¹é½è¿‡ç¨‹ä¸­çš„å¥–åŠ±è¯¯æŒ‡å®šã€‚å¥–åŠ±è¯¯æŒ‡å®šå‘ç”Ÿåœ¨å¥–åŠ±å‡½æ•°æœªèƒ½å‡†ç¡®æ•æ‰é¢„æœŸè¡Œä¸ºæ—¶ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºé”™ä½ã€‚æœ¬æ–‡å¼•å…¥ReGapæŒ‡æ ‡æ¥é‡åŒ–å¥–åŠ±è¯¯æŒ‡å®šçš„ç¨‹åº¦ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨æ£€æµ‹æœ‰å®³åé—¨æç¤ºä¸­çš„æœ‰æ•ˆæ€§å’Œç¨³å¥æ€§ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæœ¬æ–‡æå‡ºäº†ReMissç³»ç»Ÿï¼Œä¸€ä¸ªç”¨äºè‡ªåŠ¨åŒ–çº¢é˜Ÿå¯¹æŠ—çš„è‡ªåŠ¨ç³»ç»Ÿï¼Œåœ¨å¥–åŠ±è¯¯æŒ‡å®šçš„ç©ºé—´ä¸­ç”Ÿæˆå¯¹æŠ—æ€§æç¤ºã€‚ReMissåœ¨AdvBenchåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†é’ˆå¯¹å„ç§ç›®æ ‡å¯¹é½LLMçš„æœ€ä½³æ”»å‡»æˆåŠŸç‡ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆæç¤ºçš„å¯è¯»æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›å¯¹å¼€æºæ¨¡å‹çš„æ”»å‡»æ˜¾ç¤ºå‡ºå¯¹é—­æºæ¨¡å‹å¦‚GPT-4oå’Œé«˜å¯è¿ç§»æ€§çš„ä¼˜åŠ¿ï¼Œä»¥åŠè·¨åˆ†å¸ƒä»»åŠ¡çš„ä¼˜åŠ¿ã€‚è¿™äº›è§è§£ä¸ºæ”¹è¿›LLMçš„å®‰å…¨æ€§å’Œç¨³å¥æ€§æä¾›äº†æ–°çš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´å®‰å…¨æ€§å’Œå¯é æ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„é—®é¢˜ã€‚</li>
<li>è®ºæ–‡æå‡ºå°†LLMçš„æ¼æ´å½’å› äºå¯¹é½è¿‡ç¨‹ä¸­çš„å¥–åŠ±è¯¯æŒ‡å®šã€‚</li>
<li>å¼•å…¥ReGapæŒ‡æ ‡æ¥é‡åŒ–å¥–åŠ±è¯¯æŒ‡å®šçš„ç¨‹åº¦ï¼Œæœ‰æ•ˆæ£€æµ‹æœ‰å®³åé—¨æç¤ºã€‚</li>
<li>æå‡ºReMissç³»ç»Ÿï¼Œç”¨äºç”Ÿæˆå¯¹æŠ—æ€§æç¤ºï¼Œåœ¨å¥–åŠ±è¯¯æŒ‡å®šçš„ç©ºé—´ä¸­å®ç°è‡ªåŠ¨åŒ–çº¢é˜Ÿå¯¹æŠ—ã€‚</li>
<li>ReMissç³»ç»Ÿåœ¨AdvBenchåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°æœ€ä½³æ”»å‡»æˆåŠŸç‡ï¼Œç”Ÿæˆæç¤ºä¿æŒå¯è¯»æ€§ã€‚</li>
<li>å¯¹å¼€æºæ¨¡å‹çš„æ”»å‡»è¡¨ç°å‡ºå¯¹é—­æºæ¨¡å‹å’Œè·¨åˆ†å¸ƒä»»åŠ¡çš„é«˜è¿ç§»æ€§ä¼˜åŠ¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.14393">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8ca6a0efd351065ebcf0fd326a4b89d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc3a551a372afd8ba9d416b418f8040f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e02cbfbd6775844ef50f164d5b5a99ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-95e2e7a40d668b0422f0e8ba47a2a58a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ed49601dd729f2aa8fa4476a8b78af6.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-21/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-21/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-21/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-4cdb2cc713c8f8dc13ce18ea7733c544.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-21  Agent4Edu Generating Learner Response Data by Generative Agents for   Intelligent Education Systems
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3f7d1e18027fbbee053a2f950228f8c5.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-19  On the optimal prediction of extreme events in heavy-tailed time series   with applications to solar flare forecasting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">17204.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
