<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS 方向最新论文已更新，请持续关注 Update in 2025-04-16  Pseudo-Autoregressive Neural Codec Language Models for Efficient   Zero-Shot Text-to-Speech Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-ef8b1fbfa1129e284894ac2aba253f01.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    20 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-16-更新"><a href="#2025-04-16-更新" class="headerlink" title="2025-04-16 更新"></a>2025-04-16 更新</h1><h2 id="Pseudo-Autoregressive-Neural-Codec-Language-Models-for-Efficient-Zero-Shot-Text-to-Speech-Synthesis"><a href="#Pseudo-Autoregressive-Neural-Codec-Language-Models-for-Efficient-Zero-Shot-Text-to-Speech-Synthesis" class="headerlink" title="Pseudo-Autoregressive Neural Codec Language Models for Efficient   Zero-Shot Text-to-Speech Synthesis"></a>Pseudo-Autoregressive Neural Codec Language Models for Efficient   Zero-Shot Text-to-Speech Synthesis</h2><p><strong>Authors:Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen</strong></p>
<p>Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and typically require complex designs. In this paper, we introduce a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies AR and NAR modeling. Combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Building on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at <a target="_blank" rel="noopener" href="https://anonymous-palle.github.io/">https://anonymous-palle.github.io</a>. </p>
<blockquote>
<p>最近，零样本文本转语音（TTS）系统面临一个共同的问题：自回归（AR）模型存在生成速度慢和缺乏持续时间控制性的缺点，而非自回归（NAR）模型则缺乏时间建模并且通常需要复杂的设计。在本文中，我们介绍了一种新型伪自回归（PAR）编码解码语言建模方法，它将AR和NAR建模统一起来。通过将AR的显式时间建模与NAR的并行生成相结合，PAR在固定时间步长上生成动态长度的跨度。基于PAR，我们提出了PALLE，一个两阶段的TTS系统，它利用PAR进行初步生成，然后用NAR进行细化。在第一阶段，PAR沿着时间维度逐步生成语音标记，每一步都预测所有位置并并行处理，但只保留最左边的跨度。在第二阶段，对低置信度的标记进行并行细化，利用全局上下文信息。实验表明，在LibriSpeech测试集上，PALLE在语音质量、说话人相似度和清晰度方面优于在大型数据上训练的最新系统，包括F5-TTS、E2-TTS和MaskGCT等系统，同时实现了高达十倍的推理速度提升。音频样本可在<a target="_blank" rel="noopener" href="https://anonymous-palle.github.io找到./">https://anonymous-palle.github.io找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10352v1">PDF</a> Submitted to ACM MM 2025</p>
<p><strong>Summary</strong></p>
<p>本文主要介绍了一种新型的伪自回归（PAR）编码解码语言建模方法，它结合了自回归（AR）和非自回归（NAR）建模的优点。在此基础上，提出了一种两阶段的文本转语音（TTS）系统PALLE。第一阶段使用PAR逐步生成语音标记，第二阶段利用NAR对低置信度的标记进行并行精细校正。实验表明，在LibriSpeech测试集上，PALLE在语音质量、说话人相似性和清晰度方面优于其他先进系统，同时推理速度提高十倍。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本文提出了一种新颖的伪自回归（PAR）编码解码语言建模方法，结合了自回归和非自回归建模的优势。</li>
<li>PAR建模能够在固定时间步长内生成动态长度的语音标记。</li>
<li>PALLE是一种基于PAR的两阶段TTS系统，第一阶段使用PAR逐步生成语音，第二阶段利用非自回归模型对低置信度的标记进行精细校正。</li>
<li>实验结果表明，PALLE在语音质量、说话人相似性和清晰度方面优于其他先进系统。</li>
<li>PALLE系统实现了高达十倍的推理速度提升。</li>
<li>音频样本可通过[链接]进行访问。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10352">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-af63fdcbb4b03526d16721ae8bd73875.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0945ac8982f9644a5514183d12726db2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b761fc4862b17de35c75cfc1c8b88edd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22db01804714e80cec5418262fbc2bbc.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="AutoStyle-TTS-Retrieval-Augmented-Generation-based-Automatic-Style-Matching-Text-to-Speech-Synthesis"><a href="#AutoStyle-TTS-Retrieval-Augmented-Generation-based-Automatic-Style-Matching-Text-to-Speech-Synthesis" class="headerlink" title="AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style   Matching Text-to-Speech Synthesis"></a>AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style   Matching Text-to-Speech Synthesis</h2><p><strong>Authors:Dan Luo, Chengyuan Ma, Weiqin Li, Jun Wang, Wei Chen, Zhiyong Wu</strong></p>
<p>With the advancement of speech synthesis technology, users have higher expectations for the naturalness and expressiveness of synthesized speech. But previous research ignores the importance of prompt selection. This study proposes a text-to-speech (TTS) framework based on Retrieval-Augmented Generation (RAG) technology, which can dynamically adjust the speech style according to the text content to achieve more natural and vivid communication effects. We have constructed a speech style knowledge database containing high-quality speech samples in various contexts and developed a style matching scheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and Moka, to match with samples in the knowledge database, selecting the most appropriate speech style for synthesis. Furthermore, our empirical research validates the effectiveness of the proposed method. Our demo can be viewed at: <a target="_blank" rel="noopener" href="https://thuhcsi.github.io/icme2025-AutoStyle-TTS">https://thuhcsi.github.io/icme2025-AutoStyle-TTS</a> </p>
<blockquote>
<p>随着语音合成技术的进步，用户对合成语音的自然性和表达性有了更高的期望。然而，之前的研究忽略了提示选择的重要性。本研究提出了一种基于检索增强生成（RAG）技术的文本到语音（TTS）框架，该框架可以根据文本内容动态调整语音风格，以实现更自然、生动的交流效果。我们构建了一个包含各种上下文高质量语音样本的语音风格知识数据库，并开发了一种风格匹配方案。该方案使用Llama、PER-LLM-Embedder和Moka提取的嵌入来与知识数据库中的样本进行匹配，选择最合适的语音风格进行合成。此外，我们的实证研究验证了该方法的有效性。我们的演示视频可以在：<a target="_blank" rel="noopener" href="https://thuhcsi.github.io/icme2025-AutoStyle-TTS">https://thuhcsi.github.io/icme2025-AutoStyle-TTS</a> 查看。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10309v1">PDF</a> accepted by ICME25</p>
<p><strong>Summary</strong><br>随着语音合成技术的进步，用户对合成语音的自然度和表现力有更高的要求。本研究提出了一种基于检索增强生成（RAG）技术的文本到语音（TTS）框架，该框架可根据文本内容动态调整语音风格，以实现更自然、更生动的沟通效果。构建了包含多种语境高质量语音样本的语音风格知识库，并开发了风格匹配方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文本到语音（TTS）技术需要满足用户对自然度和表现力的更高期望。</li>
<li>提出了一种基于检索增强生成（RAG）技术的TTS框架。</li>
<li>框架能依据文本内容动态调整语音风格。</li>
<li>构建了包含多种语境下高质量语音样本的语音风格知识库。</li>
<li>开发了利用嵌入技术匹配语音风格的知识库样本的风格匹配方案。</li>
<li>所提方法经过实证研究验证其有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10309">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7f9b9197d648a4344e5edb6649561cf9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3029fd8b093500d01cdd097fec550c73.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d47ba0a78b0bc683f64543b2af307f4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef8b1fbfa1129e284894ac2aba253f01.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0cba9262c2cb9b15f133a7d2f221c0cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a83e794cbe4ea9a3a9d9edc59b8ef199.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9149d29fdc0ad12021a1342901a72b26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-753c94577a25756060cfbb0c9c53307c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb691bf0757cb40cbb7afb516a77635a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SafeSpeech-Robust-and-Universal-Voice-Protection-Against-Malicious-Speech-Synthesis"><a href="#SafeSpeech-Robust-and-Universal-Voice-Protection-Against-Malicious-Speech-Synthesis" class="headerlink" title="SafeSpeech: Robust and Universal Voice Protection Against Malicious   Speech Synthesis"></a>SafeSpeech: Robust and Universal Voice Protection Against Malicious   Speech Synthesis</h2><p><strong>Authors:Zhisheng Zhang, Derui Wang, Qianyi Yang, Pengyang Huang, Junhan Pu, Yuxin Cao, Kai Ye, Jie Hao, Yixian Yang</strong></p>
<p>Speech synthesis technology has brought great convenience, while the widespread usage of realistic deepfake audio has triggered hazards. Malicious adversaries may unauthorizedly collect victims’ speeches and clone a similar voice for illegal exploitation (\textit{e.g.}, telecom fraud). However, the existing defense methods cannot effectively prevent deepfake exploitation and are vulnerable to robust training techniques. Therefore, a more effective and robust data protection method is urgently needed. In response, we propose a defensive framework, \textit{\textbf{SafeSpeech}}, which protects the users’ audio before uploading by embedding imperceptible perturbations on original speeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a robust and universal proactive protection technique, \textbf{S}peech \textbf{PE}rturbative \textbf{C}oncealment (\textbf{SPEC}), that leverages a surrogate model to generate universally applicable perturbation for generative synthetic models. Moreover, we optimize the human perception of embedded perturbation in terms of time and frequency domains. To evaluate our method comprehensively, we conduct extensive experiments across advanced models and datasets, both subjectively and objectively. Our experimental results demonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection effectiveness and transferability and is highly robust against advanced adaptive adversaries. Moreover, SafeSpeech has real-time capability in real-world tests. The source code is available at \href{<a target="_blank" rel="noopener" href="https://github.com/wxzyd123/SafeSpeech%7D%7Bhttps://github.com/wxzyd123/SafeSpeech%7D">https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}</a>. </p>
<blockquote>
<p>语音合成技术带来了极大的便利，而真实深度伪造音频的广泛使用也引发了风险。恶意对手可能会未经授权地收集受害者的演讲并克隆类似的声音进行非法利用（例如电信欺诈）。然而，现有的防御方法无法有效地防止深度伪造攻击，并容易受到强大的训练技术的影响。因此，急需一种更有效和稳健的数据保护方法。作为回应，我们提出了一种防御框架，名为“SafeSpeech”，通过在原始演讲上嵌入几乎无法察觉的扰动来保护用户音频，防止高质量合成语音。在SafeSpeech中，我们设计了一种强大且通用的主动保护技术——语音扰动掩盖（SPEC），该技术利用替代模型生成适用于所有生成合成模型的通用扰动。此外，我们优化了嵌入扰动在时间和频率域中的人类感知。为了全面评估我们的方法，我们在先进的模型和数据集上进行了大量实验，包括主观和客观评估。我们的实验结果表明，SafeSpeech达到了最先进的语音保护效果和可转移性，并对高级自适应对手具有高度鲁棒性。此外，SafeSpeech在真实世界测试中具有实时能力。源代码可在<a target="_blank" rel="noopener" href="https://github.com/wxzyd123/SafeSpeech">https://github.com/wxzyd123/SafeSpeech</a>获得。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09839v1">PDF</a> Accepted to USENIX Security 2025</p>
<p><strong>Summary</strong></p>
<p>文本主要讨论语音合成技术带来的便利性和深度伪造音频的广泛运用所带来的风险。现有的防御方法无法有效防止深度伪造技术的滥用，因此急需一种更有效和稳健的数据保护方法。针对这一问题，本文提出了一种名为SafeSpeech的防御框架，通过在用户上传音频前嵌入几乎无法察觉的扰动来保护用户语音，防止高质量合成语音。SafeSpeech采用一种名为SPEC的稳健且通用的主动保护技术，利用替代模型生成适用于所有生成式合成模型的通用扰动。同时，优化了嵌入扰动在时间和频率域的人类感知。经过广泛的实验验证，SafeSpeech达到了当前最佳的声音保护效果和可转移性，对高级自适应对手具有高度的稳健性，并且在真实场景测试中具备实时能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语音合成技术带来了便利，但深度伪造音频的滥用引发了风险。</li>
<li>现有防御方法无法有效防止深度伪造技术的滥用，需要更有效和稳健的数据保护方法。</li>
<li>SafeSpeech框架通过嵌入几乎无法察觉的扰动保护用户语音。</li>
<li>SafeSpeech采用名为SPEC的主动保护技术，对生成式合成模型具有通用性。</li>
<li>SafeSpeech优化了嵌入扰动在时间和频率域的人类感知。</li>
<li>SafeSpeech达到了当前最佳的声音保护效果和可转移性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09839">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8ca6a1fc84a55a8c570e0010cda18df3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27c6759b658f727c4dc887c4e5094dbc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a02bb809a5375f78e2bd9088a10c683.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Two-Heads-are-Better-Than-One-Test-time-Scaling-of-Multi-agent-Collaborative-Reasoning"><a href="#Two-Heads-are-Better-Than-One-Test-time-Scaling-of-Multi-agent-Collaborative-Reasoning" class="headerlink" title="Two Heads are Better Than One: Test-time Scaling of Multi-agent   Collaborative Reasoning"></a>Two Heads are Better Than One: Test-time Scaling of Multi-agent   Collaborative Reasoning</h2><p><strong>Authors:Can Jin, Hongwu Peng, Qixin Zhang, Yujin Tang, Dimitris N. Metaxas, Tong Che</strong></p>
<p>Multi-agent systems (MAS) built on large language models (LLMs) offer a promising path toward solving complex, real-world tasks that single-agent systems often struggle to manage. While recent advancements in test-time scaling (TTS) have significantly improved single-agent performance on challenging reasoning tasks, how to effectively scale collaboration and reasoning in MAS remains an open question. In this work, we introduce an adaptive multi-agent framework designed to enhance collaborative reasoning through both model-level training and system-level coordination. We construct M500, a high-quality dataset containing 500 multi-agent collaborative reasoning traces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a model optimized for multi-agent collaboration. To further enable adaptive reasoning, we propose a novel CEO agent that dynamically manages the discussion process, guiding agent collaboration and adjusting reasoning depth for more effective problem-solving. Evaluated in an open-source MAS across a range of tasks-including general understanding, mathematical reasoning, and coding-our system significantly outperforms strong baselines. For instance, M1-32B achieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on MBPP-Sanitized, matching the performance of state-of-the-art models like DeepSeek-R1 on some tasks. These results highlight the importance of both learned collaboration and adaptive coordination in scaling multi-agent reasoning. Code is available at <a target="_blank" rel="noopener" href="https://github.com/jincan333/MAS-TTS">https://github.com/jincan333/MAS-TTS</a> </p>
<blockquote>
<p>基于大规模语言模型（LLM）的多智能体系统（MAS）为解决复杂现实世界任务提供了一条充满希望的道路，这些任务通常是单一智能体系统难以应对的。虽然最近在测试时间缩放（TTS）方面的进展大大提高了单一智能体在具有挑战性的推理任务上的性能，但如何在MAS中有效地扩展协作和推理仍然是一个悬而未决的问题。在这项工作中，我们引入了一个自适应多智能体框架，旨在通过模型级别的训练和系统级别的协调来提高协作推理能力。我们构建了M500，这是一个包含500个多智能体协作推理轨迹的高质量数据集，并在此基础上对Qwen2.5-32B-Instruct进行了微调，产生了针对多智能体协作优化的M1-32B模型。为了进一步实现自适应推理，我们提出了一种新型的首席执行官智能体，它能动态管理讨论过程，引导智能体协作，并根据需要调整推理深度，以更有效地解决问题。我们在开源MAS上对各种任务进行了评估，包括一般理解、数学推理和编码任务。我们的系统在GPQA-Diamond上实现了12%的改进，在AIME2024上实现了41%的改进，在MBPP-Sanitized上实现了10%的改进。在某些任务上，我们的性能与最新模型（如DeepSeek-R1）相匹配。这些结果凸显了学习到的协作和自适应协调在多智能体推理扩展中的重要性。相关代码可通过<a target="_blank" rel="noopener" href="https://github.com/jincan333/MAS-TTS%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/jincan333/MAS-TTS获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09772v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>基于大型语言模型的多智能体系统为解决复杂现实世界任务提供了有效途径，这些任务是单智能体系统难以应对的。虽然测试时缩放技术（TTS）的近期进展显著提高了单智能体在挑战性推理任务上的性能，但如何有效扩展多智能体系统的协作和推理仍是开放问题。本研究引入了一种自适应多智能体框架，旨在通过模型级训练和系统级协调增强协作推理能力。构建了M500数据集，包含500个多智能体协作推理轨迹，并在该数据集上微调Qwen2.5-32B-Instruct模型，生成针对多智能体协作优化的M1-32B模型。为了进一步优化自适应推理，我们提出了一种新型的CEO智能体，能够动态管理讨论过程，引导智能体协作并调整推理深度以更有效地解决问题。在开源多智能体系统上进行了一系列任务评估，包括通用理解、数学推理和编码任务，我们的系统显著优于强大的基线模型。例如，M1-32B在GPQA-Diamond上提高了12%，在AIME2024上提高了41%，在MBPP-Sanitized上提高了10%，在某些任务上的性能与DeepSeek-R1等先进模型相匹配。这些结果凸显了学习协作和自适应协调在扩展多智能体推理中的重要性。</p>
<p><strong>要点提炼</strong></p>
<ol>
<li>多智能体系统(MAS)基于大型语言模型(LLM)为解决复杂现实世界任务提供了有效途径。</li>
<li>测试时缩放技术（TTS）对单智能体的性能提升显著，但在多智能体系统中的协作和推理扩展仍然面临挑战。</li>
<li>研究引入了一种自适应多智能体框架，通过模型级训练和系统级协调增强协作推理能力。</li>
<li>构建了一个高质量的多智能体协作数据集M500，并基于此微调了针对多智能体协作优化的模型M1-32B。</li>
<li>提出了一种新型的CEO智能体，能够动态管理讨论过程，引导智能体协作并调整推理深度。</li>
<li>在多个任务上评估了系统的性能，包括通用理解、数学推理和编码任务，显著优于基线模型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09772">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-693140b05a1e6d90c7f89506b4c037db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b724f8e0a184b134038e0238156c13ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-921f9debfca08b7e99b2ad47b42eb2bf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-190a3911116430d7632d3dacf135f162.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="AMNet-An-Acoustic-Model-Network-for-Enhanced-Mandarin-Speech-Synthesis"><a href="#AMNet-An-Acoustic-Model-Network-for-Enhanced-Mandarin-Speech-Synthesis" class="headerlink" title="AMNet: An Acoustic Model Network for Enhanced Mandarin Speech Synthesis"></a>AMNet: An Acoustic Model Network for Enhanced Mandarin Speech Synthesis</h2><p><strong>Authors:Yubing Cao, Yinfeng Yu, Yongming Li, Liejun Wang</strong></p>
<p>This paper presents AMNet, an Acoustic Model Network designed to improve the performance of Mandarin speech synthesis by incorporating phrase structure annotation and local convolution modules. AMNet builds upon the FastSpeech 2 architecture while addressing the challenge of local context modeling, which is crucial for capturing intricate speech features such as pauses, stress, and intonation. By embedding a phrase structure parser into the model and introducing a local convolution module, AMNet enhances the model’s sensitivity to local information. Additionally, AMNet decouples tonal characteristics from phonemes, providing explicit guidance for tone modeling, which improves tone accuracy and pronunciation. Experimental results demonstrate that AMNet outperforms baseline models in subjective and objective evaluations. The proposed model achieves superior Mean Opinion Scores (MOS), lower Mel Cepstral Distortion (MCD), and improved fundamental frequency fitting $F0 (R^2)$, confirming its ability to generate high-quality, natural, and expressive Mandarin speech. </p>
<blockquote>
<p>本文介绍了AMNet，这是一种声学模型网络，旨在通过融入短语结构标注和局部卷积模块，提高普通话语音合成的性能。AMNet以FastSpeech 2架构为基础，解决了局部上下文建模的挑战，这对于捕捉复杂的语音特征（如停顿、重音和语调）至关重要。通过在模型中加入短语结构解析器和引入局部卷积模块，AMNet提高了模型对局部信息的敏感性。此外，AMNet将音调特征从音素中分离出来，为音调建模提供了明确的指导，从而提高了音调的准确性和发音。实验结果表明，在主观和客观评估中，AMNet的性能优于基准模型。所提出模型的平均意见得分（MOS）更高，梅尔倒谱失真（MCD）更低，基频拟合$F0 (R^2)$有所改善，证明其能够生成高质量、自然、富有表现力的普通话语音。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09225v1">PDF</a> Main paper (8 pages). Accepted for publication by IJCNN 2025</p>
<p><strong>摘要</strong></p>
<p>本文介绍了AMNet，这是一种声学模型网络，通过融入短语结构标注和局部卷积模块，旨在提高普通话语音合成的性能。AMNet基于FastSpeech 2架构，解决了局部上下文建模的挑战，这对于捕捉语音的停顿、重读和语调等复杂特征至关重要。通过将短语结构解析器嵌入模型并引入局部卷积模块，AMNet提高了对局部信息的敏感性。此外，AMNet将音调的特性与音素分离，为音调建模提供了明确的指导，提高了音调的准确性和发音。实验结果表明，AMNet在主观和客观评估中均优于基准模型。所提出的模型获得了较高的平均意见得分（MOS），降低了梅尔倒谱失真（MCD），并改善了基频拟合$F0 (R^2)$，证明了其生成高质量、自然、表达流畅的普通话语音的能力。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>AMNet是一种基于FastSpeech 2架构的声学模型网络，旨在提高普通话语音合成的性能。</li>
<li>AMNet通过融入短语结构标注和局部卷积模块，解决了局部上下文建模的挑战。</li>
<li>AMNet提高了模型对语音的停顿、重读和语调等复杂特征的捕捉能力。</li>
<li>短语结构解析器嵌入模型，增强了AMNet对局部信息的敏感性。</li>
<li>AMNet将音调的特性与音素分离，优化了音调建模，提高了发音准确性。</li>
<li>实验结果表明，AMNet在主观和客观评估中均优于其他模型，显示出生成高质量普通话语音的能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09225">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-68c287d072134a83fd96197d17ef4c96.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe356c0d5b511c27c5b56adecff15ab1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54a6d570fe47403c4d6a4b4ba4ae01d6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-baa4e48ecc39e51b302d6ae36e3d35cd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a723476b702f4f21070218b4e4d65e3f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-74e3bb2dd3b120b4db990cbc27c78109.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-16/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-16/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-16/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-7c0d47a914a1405cf4a935e1fac40e0e.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive 方向最新论文已更新，请持续关注 Update in 2025-04-16  CliniChat A Multi-Source Knowledge-Driven Framework for Clinical   Interview Dialogue Reconstruction and Evaluation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-16/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c998c6c2c2bbe666cf899972d93cfe57.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-04-16  Giant and anisotropic magnetostriction in $β$-O$_{2}$ at 110 T
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">17548.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
