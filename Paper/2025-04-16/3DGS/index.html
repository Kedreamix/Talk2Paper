<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-16  LL-Gaussian Low-Light Scene Reconstruction and Enhancement via Gaussian   Splatting for Novel View Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-97123eb78e3a48e07c13c6f9a8a02a64.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    58 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-16-æ›´æ–°"><a href="#2025-04-16-æ›´æ–°" class="headerlink" title="2025-04-16 æ›´æ–°"></a>2025-04-16 æ›´æ–°</h1><h2 id="LL-Gaussian-Low-Light-Scene-Reconstruction-and-Enhancement-via-Gaussian-Splatting-for-Novel-View-Synthesis"><a href="#LL-Gaussian-Low-Light-Scene-Reconstruction-and-Enhancement-via-Gaussian-Splatting-for-Novel-View-Synthesis" class="headerlink" title="LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian   Splatting for Novel View Synthesis"></a>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian   Splatting for Novel View Synthesis</h2><p><strong>Authors:Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou</strong></p>
<p>Novel view synthesis (NVS) in low-light scenes remains a significant challenge due to degraded inputs characterized by severe noise, low dynamic range (LDR) and unreliable initialization. While recent NeRF-based approaches have shown promising results, most suffer from high computational costs, and some rely on carefully captured or pre-processed dataâ€“such as RAW sensor inputs or multi-exposure sequencesâ€“which severely limits their practicality. In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with competitive visual fidelity; however, existing 3DGS-based methods struggle with low-light sRGB inputs, resulting in unstable Gaussian initialization and ineffective noise suppression. To address these challenges, we propose LL-Gaussian, a novel framework for 3D reconstruction and enhancement from low-light sRGB images, enabling pseudo normal-light novel view synthesis. Our method introduces three key innovations: 1) an end-to-end Low-Light Gaussian Initialization Module (LLGIM) that leverages dense priors from learning-based MVS approach to generate high-quality initial point clouds; 2) a dual-branch Gaussian decomposition model that disentangles intrinsic scene properties (reflectance and illumination) from transient interference, enabling stable and interpretable optimization; 3) an unsupervised optimization strategy guided by both physical constrains and diffusion prior to jointly steer decomposition and enhancement. Additionally, we contribute a challenging dataset collected in extreme low-light environments and demonstrate the effectiveness of LL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian achieves up to 2,000 times faster inference and reduces training time to just 2%, while delivering superior reconstruction and rendering quality. </p>
<blockquote>
<p>åœ¨ä½å…‰ç…§åœºæ™¯ä¸­çš„æ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºé€€åŒ–è¾“å…¥çš„ç‰¹å¾åŒ…æ‹¬ä¸¥é‡å™ªå£°ã€ä½åŠ¨æ€èŒƒå›´ï¼ˆLDRï¼‰å’Œä¸å¯é çš„åˆå§‹åŒ–ã€‚è™½ç„¶æœ€è¿‘çš„åŸºäºNeRFçš„æ–¹æ³•å·²ç»æ˜¾ç¤ºå‡ºæœ‰å¸Œæœ›çš„ç»“æœï¼Œä½†å¤§å¤šæ•°æ–¹æ³•çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œæœ‰äº›æ–¹æ³•ä¾èµ–äºç²¾å¿ƒæ•è·æˆ–é¢„å¤„ç†çš„æ•°æ®ï¼Œå¦‚RAWä¼ æ„Ÿå™¨è¾“å…¥æˆ–å¤šæ›å…‰åºåˆ—ï¼Œè¿™ä¸¥é‡é™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰èƒ½å¤Ÿå®ç°å…·æœ‰ç«äº‰è§†è§‰ä¿çœŸåº¦çš„å®æ—¶æ¸²æŸ“ï¼›ç„¶è€Œï¼Œç°æœ‰çš„åŸºäº3DGSçš„æ–¹æ³•åœ¨å¤„ç†ä½å…‰sRGBè¾“å…¥æ—¶é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´é«˜æ–¯åˆå§‹åŒ–ä¸ç¨³å®šä¸”å™ªå£°æŠ‘åˆ¶æ— æ•ˆã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†LL-Gaussianï¼Œè¿™æ˜¯ä¸€ä¸ªä»ä½å…‰sRGBå›¾åƒè¿›è¡Œ3Dé‡å»ºå’Œå¢å¼ºçš„æ–°å‹æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°ä¼ªæ­£å¸¸å…‰æ–°å‹è§†å›¾åˆæˆã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼š1ï¼‰ç«¯åˆ°ç«¯çš„ä½å…‰é«˜æ–¯åˆå§‹åŒ–æ¨¡å—ï¼ˆLLGIMï¼‰ï¼Œå®ƒåˆ©ç”¨åŸºäºå­¦ä¹ çš„MVSæ–¹æ³•çš„å¯†é›†å…ˆéªŒæ¥ç”Ÿæˆé«˜è´¨é‡åˆå§‹ç‚¹äº‘ï¼›2ï¼‰åŒåˆ†æ”¯é«˜æ–¯åˆ†è§£æ¨¡å‹ï¼Œå°†åœºæ™¯çš„å†…åœ¨å±æ€§ï¼ˆåå°„ç‡å’Œç…§æ˜ï¼‰ä»ç¬æ€å¹²æ‰°ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå®ç°ç¨³å®šå’Œå¯è§£é‡Šçš„ä¼˜åŒ–ï¼›3ï¼‰ä¸€ç§æ— ç›‘ç£ä¼˜åŒ–ç­–ç•¥ï¼Œç”±ç‰©ç†çº¦æŸå’Œæ‰©æ•£å…ˆéªŒå…±åŒå¼•å¯¼åˆ†è§£å’Œå¢å¼ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è´¡çŒ®äº†ä¸€ä¸ªåœ¨æç«¯ä½å…‰ç¯å¢ƒä¸­æ”¶é›†çš„æŒ‘æˆ˜æ€§æ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†LL-Gaussiançš„æœ‰æ•ˆæ€§ã€‚ä¸æœ€å…ˆè¿›çš„åŸºäºNeRFçš„æ–¹æ³•ç›¸æ¯”ï¼ŒLL-Gaussianå®ç°äº†é«˜è¾¾2000å€æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œå¹¶å°†è®­ç»ƒæ—¶é—´å‡å°‘åˆ°ä»…2%ï¼ŒåŒæ—¶æä¾›å“è¶Šçš„é‡å»ºå’Œæ¸²æŸ“è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10331v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é’ˆå¯¹ä½å…‰åœºæ™¯ä¸­çš„æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´å™ªå£°ä¸¥é‡ã€åŠ¨æ€èŒƒå›´ä½åŠåˆå§‹åŒ–ä¸ç¨³å®šç­‰é—®é¢˜ã€‚å°½ç®¡åŸºäºNeRFçš„æ–¹æ³•å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬è®¡ç®—æˆæœ¬é«˜ä¸”ä¾èµ–ç²¾ç»†æ•æ‰æˆ–é¢„å¤„ç†çš„æ•°æ®ï¼Œé™åˆ¶äº†å®ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰å¯å®ç°å®æ—¶æ¸²æŸ“å¹¶å…·å¤‡ç«äº‰æ€§çš„è§†è§‰ä¿çœŸåº¦ï¼Œä½†å¤„ç†ä½å…‰sRGBè¾“å…¥æ—¶è¡¨ç°ä¸ç¨³å®šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºLL-Gaussianæ¡†æ¶ï¼Œç”¨äºä»ä½å…‰sRGBå›¾åƒè¿›è¡Œ3Dé‡å»ºå’Œå¢å¼ºï¼Œå®ç°ä¼ªæ­£å¸¸å…‰æ–°è§†è§’åˆæˆã€‚è¯¥æ–¹æ³•å¼•å…¥ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼š1ï¼‰ç«¯åˆ°ç«¯çš„ä½å…‰é«˜æ–¯åˆå§‹åŒ–æ¨¡å—ï¼ˆLLGIMï¼‰ï¼Œåˆ©ç”¨åŸºäºå­¦ä¹ çš„MVSæ–¹æ³•çš„å¯†é›†å…ˆéªŒç”Ÿæˆé«˜è´¨é‡åˆå§‹ç‚¹äº‘ï¼›2ï¼‰åŒåˆ†æ”¯é«˜æ–¯åˆ†è§£æ¨¡å‹ï¼Œå°†åœºæ™¯å›ºæœ‰å±æ€§ï¼ˆåå°„å’Œç…§æ˜ï¼‰ä¸ç¬æ€å¹²æ‰°åˆ†ç¦»ï¼Œå®ç°ç¨³å®šå’Œå¯è§£é‡Šçš„ä¼˜åŒ–ï¼›3ï¼‰ç”±ç‰©ç†çº¦æŸå’Œæ‰©æ•£å…ˆéªŒå¼•å¯¼çš„æ— ç›‘ç£ä¼˜åŒ–ç­–ç•¥ï¼Œå…±åŒå¼•å¯¼åˆ†è§£å’Œå¢å¼ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è´¡çŒ®äº†åœ¨æç«¯ä½å…‰ç¯å¢ƒä¸­æ”¶é›†çš„æŒ‘æˆ˜æ€§æ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†LL-Gaussiançš„æœ‰æ•ˆæ€§ã€‚ä¸å…ˆè¿›çš„NeRFæ–¹æ³•ç›¸æ¯”ï¼ŒLL-Gaussianæ¨ç†é€Ÿåº¦æœ€å¿«å¯è¾¾2000å€ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘è‡³ä»…2%ï¼ŒåŒæ—¶æä¾›ä¼˜è¶Šçš„é‡æ„å’Œæ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>ä½å…‰åœºæ™¯ä¸­çš„æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å™ªå£°ã€åŠ¨æ€èŒƒå›´å’Œåˆå§‹åŒ–é—®é¢˜ã€‚</li>
<li>åŸºäºNeRFçš„æ–¹æ³•è™½å…·æœ‰æ½œåŠ›ï¼Œä½†è®¡ç®—æˆæœ¬é«˜ä¸”ä¾èµ–ç‰¹å®šæ•°æ®ï¼Œå®ç”¨æ€§å—é™ã€‚</li>
<li>3DGSæ–¹æ³•å¯å®ç°å®æ—¶æ¸²æŸ“ï¼Œä½†åœ¨å¤„ç†ä½å…‰sRGBè¾“å…¥æ—¶è¡¨ç°ä¸ç¨³å®šã€‚</li>
<li>LL-Gaussianæ¡†æ¶é€šè¿‡ä¸‰é¡¹å…³é”®åˆ›æ–°è§£å†³è¿™äº›é—®é¢˜ï¼šä½å…‰é«˜æ–¯åˆå§‹åŒ–æ¨¡å—ã€åŒåˆ†æ”¯é«˜æ–¯åˆ†è§£æ¨¡å‹å’Œæ— ç›‘ç£ä¼˜åŒ–ç­–ç•¥ã€‚</li>
<li>LL-Gaussianåœ¨æç«¯ä½å…‰ç¯å¢ƒä¸­æ”¶é›†çš„æŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒLL-Gaussianå…·æœ‰æ›´å¿«çš„æ¨ç†é€Ÿåº¦å’Œå‡å°‘çš„è®­ç»ƒæ—¶é—´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10331">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f4f09fc0fea5d58635768bd99332acc6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa6dbd3823e337d4c4527cfe396fdf2c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de11ea7140d240861a6ee879dd40aea2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e9b78a90cb6210c12dffc9e19c56fe2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MCBlock-Boosting-Neural-Radiance-Field-Training-Speed-by-MCTS-based-Dynamic-Resolution-Ray-Sampling"><a href="#MCBlock-Boosting-Neural-Radiance-Field-Training-Speed-by-MCTS-based-Dynamic-Resolution-Ray-Sampling" class="headerlink" title="MCBlock: Boosting Neural Radiance Field Training Speed by MCTS-based   Dynamic-Resolution Ray Sampling"></a>MCBlock: Boosting Neural Radiance Field Training Speed by MCTS-based   Dynamic-Resolution Ray Sampling</h2><p><strong>Authors:Yunpeng Tan, Junlin Hao, Jiangkai Wu, Liming Liu, Qingyang Li, Xinggong Zhang</strong></p>
<p>Neural Radiance Field (NeRF) is widely known for high-fidelity novel view synthesis. However, even the state-of-the-art NeRF model, Gaussian Splatting, requires minutes for training, far from the real-time performance required by multimedia scenarios like telemedicine. One of the obstacles is its inefficient sampling, which is only partially addressed by existing works. Existing point-sampling algorithms uniformly sample simple-texture regions (easy to fit) and complex-texture regions (hard to fit), while existing ray-sampling algorithms sample these regions all in the finest granularity (i.e. the pixel level), both wasting GPU training resources. Actually, regions with different texture intensities require different sampling granularities. To this end, we propose a novel dynamic-resolution ray-sampling algorithm, MCBlock, which employs Monte Carlo Tree Search (MCTS) to partition each training image into pixel blocks with different sizes for active block-wise training. Specifically, the trees are initialized according to the texture of training images to boost the initialization speed, and an expansion&#x2F;pruning module dynamically optimizes the block partition. MCBlock is implemented in Nerfstudio, an open-source toolset, and achieves a training acceleration of up to 2.33x, surpassing other ray-sampling algorithms. We believe MCBlock can apply to any cone-tracing NeRF model and contribute to the multimedia community. </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä»¥å…¶é«˜ä¿çœŸåº¦çš„æ–°å‹è§†å›¾åˆæˆè€Œå¹¿ä¸ºäººçŸ¥ã€‚ç„¶è€Œï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„NeRFæ¨¡å‹â€”â€”é«˜æ–¯æ‹¼è´´ï¼ˆGaussian Splattingï¼‰ï¼Œå…¶è®­ç»ƒä¹Ÿéœ€è¦æ•°åˆ†é’Ÿæ—¶é—´ï¼Œè¿œè¿œä¸èƒ½æ»¡è¶³è¿œç¨‹åŒ»ç–—ç­‰å¤šåª’ä½“åœºæ™¯å¯¹å®æ—¶æ€§èƒ½çš„è¦æ±‚ã€‚å…¶ä¸­ä¸€ä¸ªéšœç¢æ˜¯å…¶ä½æ•ˆçš„é‡‡æ ·æ–¹å¼ï¼Œç°æœ‰ç ”ç©¶å¯¹æ­¤åªè¿›è¡Œäº†éƒ¨åˆ†è§£å†³ã€‚ç°æœ‰çš„ç‚¹é‡‡æ ·ç®—æ³•å¯¹ç®€å•çº¹ç†åŒºåŸŸï¼ˆæ˜“äºæ‹Ÿåˆï¼‰å’Œå¤æ‚çº¹ç†åŒºåŸŸï¼ˆéš¾ä»¥æ‹Ÿåˆï¼‰è¿›è¡Œç»Ÿä¸€é‡‡æ ·ï¼Œè€Œç°æœ‰çš„å°„çº¿é‡‡æ ·ç®—æ³•åˆ™åœ¨è¿™äº›åŒºåŸŸä¸­ä»¥æœ€ç²¾ç»†çš„ç²’åº¦ï¼ˆå³åƒç´ çº§åˆ«ï¼‰è¿›è¡Œé‡‡æ ·ï¼Œä¸¤è€…éƒ½æµªè´¹äº†GPUè®­ç»ƒèµ„æºã€‚å®é™…ä¸Šï¼Œä¸åŒçº¹ç†å¼ºåº¦çš„åŒºåŸŸéœ€è¦ä¸åŒçš„é‡‡æ ·ç²’åº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹åŠ¨æ€åˆ†è¾¨ç‡å°„çº¿é‡‡æ ·ç®—æ³•MCBlockï¼Œè¯¥ç®—æ³•é‡‡ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å°†æ¯ä¸€å¼ è®­ç»ƒå›¾åƒåˆ†å‰²æˆä¸åŒå¤§å°çš„åƒç´ å—è¿›è¡Œæ´»åŠ¨å—çº§è®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œæ ‘æ ¹æ®è®­ç»ƒå›¾åƒçš„çº¹ç†è¿›è¡Œåˆå§‹åŒ–ä»¥åŠ é€Ÿåˆå§‹åŒ–é€Ÿåº¦ï¼Œä¸€ä¸ªæ‰©å±•&#x2F;ä¿®å‰ªæ¨¡å—åŠ¨æ€ä¼˜åŒ–å—åˆ†å‰²ã€‚MCBlockåœ¨Nerfstudioè¿™ä¸ªå¼€æºå·¥å…·åŒ…ä¸­å®ç°ï¼Œå®ç°äº†é«˜è¾¾2.33å€çš„è®­ç»ƒåŠ é€Ÿï¼Œè¶…è¶Šäº†å…¶ä»–å°„çº¿é‡‡æ ·ç®—æ³•ã€‚æˆ‘ä»¬ç›¸ä¿¡MCBlockå¯ä»¥åº”ç”¨äºä»»ä½•é”¥è¿½è¸ªNeRFæ¨¡å‹ï¼Œå¹¶ä¸ºå¤šåª’ä½“é¢†åŸŸåšå‡ºè´¡çŒ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09878v1">PDF</a> </p>
<p><strong>Summary</strong><br>     ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰ä»¥é«˜ä¿çœŸåº¦æ–°é¢–è§†å›¾åˆæˆä¸ºäººæ‰€ç†ŸçŸ¥ï¼Œä½†å…¶ç°æœ‰æŠ€æœ¯å¦‚é«˜æ–¯æ‹¼æ¥ä»å­˜åœ¨è®­ç»ƒæ—¶é—´é•¿çš„é—®é¢˜ï¼Œéš¾ä»¥æ»¡è¶³å¤šåª’ä½“åœºæ™¯å¦‚è¿œç¨‹åŒ»ç–—çš„å®æ—¶æ€§èƒ½è¦æ±‚ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŠ¨æ€åˆ†è¾¨ç‡å°„çº¿é‡‡æ ·ç®—æ³•MCBlockï¼Œé‡‡ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å¯¹è®­ç»ƒå›¾åƒè¿›è¡Œä¸åŒå¤§å°çš„åƒç´ å—åˆ†å‰²ï¼Œå®ç°æ´»åŠ¨å—çº§è®­ç»ƒã€‚æ­¤ç®—æ³•å¯åŠ é€Ÿè®­ç»ƒï¼Œè¾¾åˆ°2.33å€ï¼Œå¹¶é€‚ç”¨äºä»»ä½•é”¥è¿½è¸ªNeRFæ¨¡å‹ï¼Œå¯¹å¤šåª’ä½“é¢†åŸŸæœ‰æ‰€è´¡çŒ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRFåœ¨é«˜ä¿çœŸæ–°é¢–è§†å›¾åˆæˆæ–¹é¢çš„ä¼˜åŠ¿åŠå…¶é¢ä¸´çš„å®æ—¶æ€§èƒ½æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰é‡‡æ ·æ–¹æ³•ï¼ˆåŒ…æ‹¬ç‚¹é‡‡æ ·å’Œå°„çº¿é‡‡æ ·ï¼‰åœ¨GPUèµ„æºåˆ©ç”¨æ–¹é¢å­˜åœ¨çš„é—®é¢˜ã€‚</li>
<li>MCBlockç®—æ³•é‡‡ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œåƒç´ å—åˆ†å‰²ï¼Œå®ç°åŠ¨æ€åˆ†è¾¨ç‡å°„çº¿é‡‡æ ·ã€‚</li>
<li>MCBlockç®—æ³•èƒ½å¤Ÿåœ¨è®­ç»ƒå›¾åƒä¸Šå®ç°æ´»åŠ¨å—çº§è®­ç»ƒã€‚</li>
<li>MCBlockç®—æ³•åœ¨è®­ç»ƒåŠ é€Ÿæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœï¼Œè¾¾åˆ°2.33å€ã€‚</li>
<li>MCBlockç®—æ³•é€‚ç”¨äºä»»ä½•é”¥è¿½è¸ªNeRFæ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09878">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-28c187f3fb5ec6510f4dcf687d8fec78.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3bc5bc282c46a26273fdad42ec8a653f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6565f8ed9c94f02f87f20d93785720e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f76bb8ae4e1096baaf2588e5b66a774a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85c75c8de7ab382f6f9fc34b92cdda43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75f538d1bb9511876247d59d56bcaf8e.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DropoutGS-Dropping-Out-Gaussians-for-Better-Sparse-view-Rendering"><a href="#DropoutGS-Dropping-Out-Gaussians-for-Better-Sparse-view-Rendering" class="headerlink" title="DropoutGS: Dropping Out Gaussians for Better Sparse-view Rendering"></a>DropoutGS: Dropping Out Gaussians for Better Sparse-view Rendering</h2><p><strong>Authors:Yexing Xu, Longguang Wang, Minglin Chen, Sheng Ao, Li Li, Yulan Guo</strong></p>
<p>Although 3D Gaussian Splatting (3DGS) has demonstrated promising results in novel view synthesis, its performance degrades dramatically with sparse inputs and generates undesirable artifacts. As the number of training views decreases, the novel view synthesis task degrades to a highly under-determined problem such that existing methods suffer from the notorious overfitting issue. Interestingly, we observe that models with fewer Gaussian primitives exhibit less overfitting under sparse inputs. Inspired by this observation, we propose a Random Dropout Regularization (RDR) to exploit the advantages of low-complexity models to alleviate overfitting. In addition, to remedy the lack of high-frequency details for these models, an Edge-guided Splitting Strategy (ESS) is developed. With these two techniques, our method (termed DropoutGS) provides a simple yet effective plug-in approach to improve the generalization performance of existing 3DGS methods. Extensive experiments show that our DropoutGS produces state-of-the-art performance under sparse views on benchmark datasets including Blender, LLFF, and DTU. The project page is at: <a target="_blank" rel="noopener" href="https://xuyx55.github.io/DropoutGS/">https://xuyx55.github.io/DropoutGS/</a>. </p>
<blockquote>
<p>å°½ç®¡ä¸‰ç»´é«˜æ–¯æ¨¡ç³ŠæŠ€æœ¯ï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†å›¾åˆæˆé¢†åŸŸå–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœï¼Œä½†åœ¨ç¨€ç–è¾“å…¥æƒ…å†µä¸‹å…¶æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå¹¶äº§ç”Ÿä¸è‰¯ä¼ªå½±ã€‚éšç€è®­ç»ƒè§†å›¾æ•°é‡çš„å‡å°‘ï¼Œæ–°å‹è§†å›¾åˆæˆä»»åŠ¡é™çº§ä¸ºä¸€ä¸ªé«˜åº¦æ¬ å®šé—®é¢˜ï¼Œå¯¼è‡´ç°æœ‰æ–¹æ³•å—åˆ°ä¸¥é‡çš„è¿‡æ‹Ÿåˆé—®é¢˜å½±å“ã€‚æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å…·æœ‰æ›´å°‘é«˜æ–¯åŸºå…ƒçš„æ¨¡å‹åœ¨ç¨€ç–è¾“å…¥æƒ…å†µä¸‹è¡¨ç°å‡ºè¾ƒå°‘çš„è¿‡æ‹Ÿåˆç°è±¡ã€‚å—æ­¤è§‚å¯Ÿå¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§éšæœºå¤±æ´»æ­£åˆ™åŒ–ï¼ˆRDRï¼‰æ–¹æ³•ï¼Œä»¥åˆ©ç”¨ä½å¤æ‚åº¦æ¨¡å‹çš„ä¼˜åŠ¿æ¥ç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ã€‚æ­¤å¤–ï¼Œä¸ºäº†å¼¥è¡¥è¿™äº›æ¨¡å‹ç¼ºä¹é«˜é¢‘ç»†èŠ‚çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è¾¹ç¼˜å¼•å¯¼åˆ†è£‚ç­–ç•¥ï¼ˆESSï¼‰ã€‚é€šè¿‡è¿™ä¸¤ç§æŠ€æœ¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ï¼ˆç§°ä¸ºDropoutGSï¼‰æä¾›äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ’ä»¶æ–¹æ³•ï¼Œä»¥æé«˜ç°æœ‰3DGSæ–¹æ³•çš„æ³›åŒ–æ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„DropoutGSåœ¨åŒ…æ‹¬Blenderã€LLFFå’ŒDTUåœ¨å†…çš„åŸºå‡†æ•°æ®é›†ä¸Šï¼Œç¨€ç–è§†å›¾ä¸‹çš„æ€§èƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚é¡¹ç›®é¡µé¢ä¸ºï¼š<a target="_blank" rel="noopener" href="https://xuyx55.github.io/DropoutGS/%E3%80%82">https://xuyx55.github.io/DropoutGS/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09491v1">PDF</a> Accepted by CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>åœ¨åŸºäºé«˜æ–¯å–·ç»˜æŠ€æœ¯çš„ä¸‰ç»´æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå°½ç®¡ç¨€ç–è¾“å…¥å¯èƒ½ä¼šå¯¼è‡´ç®—æ³•æ€§èƒ½æ˜¾è‘—ä¸‹é™å¹¶äº§ç”Ÿä¸è‰¯ä¼ªå½±ï¼Œä½†å‡å°‘é«˜æ–¯åŸå§‹æ¨¡å‹æ•°é‡å¯ä»¥é™ä½è¿‡æ‹Ÿåˆç°è±¡ã€‚ä¸ºæ­¤ï¼Œæœ¬ç ”ç©¶æå‡ºäº†éšæœºä¸¢å¼ƒæ­£åˆ™åŒ–ï¼ˆRDRï¼‰æ–¹æ³•ï¼Œå¹¶ç»“åˆè¾¹ç¼˜å¼•å¯¼åˆ†å‰²ç­–ç•¥ï¼ˆESSï¼‰ï¼Œä»¥æå‡ç°æœ‰æŠ€æœ¯çš„æ³›åŒ–æ€§èƒ½ã€‚DropoutGSä½œä¸ºä¸€ç§ç®€å•æœ‰æ•ˆçš„æ’ä»¶æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ç¨€ç–è§†å›¾ä¸‹å®ç°å…ˆè¿›æ€§èƒ½ã€‚è¯¥é¡¹ç›®å·²åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒéªŒè¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¨€ç–è¾“å…¥å¯¼è‡´ç°æœ‰ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯æ€§èƒ½ä¸‹é™å¹¶äº§ç”Ÿä¼ªå½±ã€‚</li>
<li>å‡å°‘æ¨¡å‹ä¸­çš„é«˜æ–¯åŸå§‹æ•°é‡å¯é™ä½è¿‡æ‹Ÿåˆç°è±¡ã€‚</li>
<li>éšæœºä¸¢å¼ƒæ­£åˆ™åŒ–ï¼ˆRDRï¼‰æ–¹æ³•ç”¨äºåˆ©ç”¨ä½å¤æ‚åº¦æ¨¡å‹çš„ä¼˜åŠ¿ç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>ä¸ºå¼¥è¡¥æ¨¡å‹ç¼ºä¹é«˜é¢‘ç»†èŠ‚çš„é—®é¢˜ï¼Œå¼€å‘äº†è¾¹ç¼˜å¼•å¯¼åˆ†å‰²ç­–ç•¥ï¼ˆESSï¼‰ã€‚</li>
<li>DropoutGSæ–¹æ³•ç»“åˆäº†RDRå’ŒESSæŠ€æœ¯ï¼Œæé«˜äº†ç°æœ‰ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯çš„æ³›åŒ–æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09491">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3acfbb6908b12e36e9451a9a5ceeb705.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-580c523b4a024135b12aaad440d85510.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1de068dc74b897d99afc5160b3cb2c59.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e8c55119b163f01064f7536df90500d0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-851a7d23035563e533c6959226199e73.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-Constrained-Optimization-Approach-for-Gaussian-Splatting-from-Coarsely-posed-Images-and-Noisy-Lidar-Point-Clouds"><a href="#A-Constrained-Optimization-Approach-for-Gaussian-Splatting-from-Coarsely-posed-Images-and-Noisy-Lidar-Point-Clouds" class="headerlink" title="A Constrained Optimization Approach for Gaussian Splatting from   Coarsely-posed Images and Noisy Lidar Point Clouds"></a>A Constrained Optimization Approach for Gaussian Splatting from   Coarsely-posed Images and Noisy Lidar Point Clouds</h2><p><strong>Authors:Jizong Peng, Tze Ho Elden Tse, Kai Xu, Wenchao Gao, Angela Yao</strong></p>
<p>3D Gaussian Splatting (3DGS) is a powerful reconstruction technique, but it needs to be initialized from accurate camera poses and high-fidelity point clouds. Typically, the initialization is taken from Structure-from-Motion (SfM) algorithms; however, SfM is time-consuming and restricts the application of 3DGS in real-world scenarios and large-scale scene reconstruction. We introduce a constrained optimization method for simultaneous camera pose estimation and 3D reconstruction that does not require SfM support. Core to our approach is decomposing a camera pose into a sequence of camera-to-(device-)center and (device-)center-to-world optimizations. To facilitate, we propose two optimization constraints conditioned to the sensitivity of each parameter group and restricts each parameterâ€™s search space. In addition, as we learn the scene geometry directly from the noisy point clouds, we propose geometric constraints to improve the reconstruction quality. Experiments demonstrate that the proposed method significantly outperforms the existing (multi-modal) 3DGS baseline and methods supplemented by COLMAP on both our collected dataset and two public benchmarks. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„é‡å»ºæŠ€æœ¯ï¼Œä½†å®ƒéœ€è¦ä»¥ç²¾ç¡®çš„ç›¸æœºå§¿æ€å’Œé«˜ä¿çœŸç‚¹äº‘ä½œä¸ºåˆå§‹å€¼ã€‚é€šå¸¸ï¼Œåˆå§‹åŒ–æ˜¯ä»è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰ç®—æ³•ä¸­æå–çš„ï¼›ç„¶è€Œï¼ŒSfMè€—æ—¶è¾ƒé•¿ï¼Œé™åˆ¶äº†3DGSåœ¨çœŸå®åœºæ™¯å’Œå¤§è§„æ¨¡åœºæ™¯é‡å»ºä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç”¨äºåŒæ—¶ä¼°è®¡ç›¸æœºå§¿æ€å’Œè¿›è¡Œä¸‰ç»´é‡å»ºçš„çº¦æŸä¼˜åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦SfMçš„æ”¯æŒã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯å°†ç›¸æœºå§¿æ€åˆ†è§£æˆä¸€ç³»åˆ—ç›¸æœºåˆ°ï¼ˆè®¾å¤‡ï¼‰ä¸­å¿ƒå’Œï¼ˆè®¾å¤‡ï¼‰ä¸­å¿ƒåˆ°ä¸–ç•Œçš„ä¼˜åŒ–ã€‚ä¸ºäº†ç®€åŒ–æ“ä½œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§é’ˆå¯¹æ¯ä¸ªå‚æ•°ç»„æ•æ„Ÿæ€§çš„ä¼˜åŒ–çº¦æŸï¼Œå¹¶é™åˆ¶äº†æ¯ä¸ªå‚æ•°çš„æœç´¢ç©ºé—´ã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬ç›´æ¥ä»å™ªå£°ç‚¹äº‘å­¦ä¹ åœºæ™¯å‡ ä½•ï¼Œå› æ­¤æå‡ºäº†å‡ ä½•çº¦æŸä»¥æé«˜é‡å»ºè´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ”¶é›†çš„æ•°æ®é›†å’Œä¸¤ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„ï¼ˆå¤šæ¨¡æ€ï¼‰3DGSåŸºå‡†æ–¹æ³•å’Œç”±COLMAPè¾…åŠ©çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09129v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>3DGSæŠ€æœ¯éœ€ä¾èµ–å‡†ç¡®çš„ç›¸æœºå§¿æ€ä¸é«˜ä¿çœŸç‚¹äº‘è¿›è¡Œåˆå§‹åŒ–ï¼Œé€šå¸¸ä¾èµ–äºä»è¿åŠ¨æ¢å¤ç»“æ„ï¼ˆSfMï¼‰ç®—æ³•å®ç°ã€‚ä½†SfMè€—æ—¶è¾ƒé•¿ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®åœºæ™¯å’Œå¤§è§„æ¨¡åœºæ™¯é‡å»ºä¸­çš„åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºä¸€ç§çº¦æŸä¼˜åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶ä¼°è®¡ç›¸æœºå§¿æ€å¹¶è¿›è¡Œä¸‰ç»´é‡å»ºï¼Œæ— éœ€SfMæ”¯æŒã€‚å…¶æ ¸å¿ƒæ˜¯å°†ç›¸æœºå§¿æ€åˆ†è§£ä¸ºä¸€ç³»åˆ—ç›¸æœºåˆ°è®¾å¤‡ä¸­å¿ƒå’Œè®¾å¤‡ä¸­å¿ƒåˆ°ä¸–ç•Œçš„ä¼˜åŒ–åºåˆ—ï¼Œæå‡ºä¸¤ç§é’ˆå¯¹æ¯ç§å‚æ•°ç»„æ•æ„Ÿæ€§çš„ä¼˜åŒ–çº¦æŸï¼Œå¹¶é™åˆ¶æ¯ä¸ªå‚æ•°çš„æœç´¢ç©ºé—´ã€‚æ­¤å¤–ï¼Œç›´æ¥ä»å™ªå£°ç‚¹äº‘å­¦ä¹ åœºæ™¯å‡ ä½•ï¼Œæå‡ºå‡ ä½•çº¦æŸä»¥æé«˜é‡å»ºè´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ”¶é›†çš„æ•°æ®é›†å’Œä¸¤ä¸ªå…¬å¼€åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šæ¨¡æ€3DGSæ–¹æ³•å’Œè¡¥å……COLMAPçš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSæŠ€æœ¯éœ€è¦åˆå§‹åŒ–ç›¸æœºå§¿æ€å’Œé«˜ä¿çœŸç‚¹äº‘ã€‚</li>
<li>é€šå¸¸ä½¿ç”¨SfMç®—æ³•è¿›è¡Œåˆå§‹åŒ–ï¼Œä½†è¿™ç§æ–¹æ³•è€—æ—¶è¾ƒé•¿ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®åœºæ™¯å’Œå¤§è§„æ¨¡åœºæ™¯é‡å»ºä¸­çš„åº”ç”¨ã€‚</li>
<li>ç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°çš„çº¦æŸä¼˜åŒ–æ–¹æ³•ï¼Œå¯åŒæ—¶ä¼°è®¡ç›¸æœºå§¿æ€å¹¶è¿›è¡Œä¸‰ç»´é‡å»ºï¼Œæ— éœ€SfMæ”¯æŒã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åˆ†è§£ç›¸æœºå§¿æ€ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶å¼•å…¥é’ˆå¯¹å‚æ•°ç»„çš„æ•æ„Ÿæ€§ä¼˜åŒ–çº¦æŸã€‚</li>
<li>ä¸ºäº†æé«˜ä»å™ªå£°ç‚¹äº‘ä¸­çš„é‡å»ºè´¨é‡ï¼Œå¼•å…¥äº†å‡ ä½•çº¦æŸã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°æ®é›†çš„å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09129">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4dd8b7ec2e43d67daaba2eddc4993395.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8d01a1fe1f5c13a6cbac6a6283cc767.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c196266fc91d7f2da79dcdf3762f516.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31400eb38a9a7e23ae03934855e2cb74.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-90e474faee74f0872faae0692ff4cae5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-df2b240a1e3e78398fb5df57cc8b111b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BIGS-Bimanual-Category-agnostic-Interaction-Reconstruction-from-Monocular-Videos-via-3D-Gaussian-Splatting"><a href="#BIGS-Bimanual-Category-agnostic-Interaction-Reconstruction-from-Monocular-Videos-via-3D-Gaussian-Splatting" class="headerlink" title="BIGS: Bimanual Category-agnostic Interaction Reconstruction from   Monocular Videos via 3D Gaussian Splatting"></a>BIGS: Bimanual Category-agnostic Interaction Reconstruction from   Monocular Videos via 3D Gaussian Splatting</h2><p><strong>Authors:Jeongwan On, Kyeonghwan Gwak, Gunyoung Kang, Junuk Cha, Soohyun Hwang, Hyein Hwang, Seungryul Baek</strong></p>
<p>Reconstructing 3Ds of hand-object interaction (HOI) is a fundamental problem that can find numerous applications. Despite recent advances, there is no comprehensive pipeline yet for bimanual class-agnostic interaction reconstruction from a monocular RGB video, where two hands and an unknown object are interacting with each other. Previous works tackled the limited hand-object interaction case, where object templates are pre-known or only one hand is involved in the interaction. The bimanual interaction reconstruction exhibits severe occlusions introduced by complex interactions between two hands and an object. To solve this, we first introduce BIGS (Bimanual Interaction 3D Gaussian Splatting), a method that reconstructs 3D Gaussians of hands and an unknown object from a monocular video. To robustly obtain object Gaussians avoiding severe occlusions, we leverage prior knowledge of pre-trained diffusion model with score distillation sampling (SDS) loss, to reconstruct unseen object parts. For hand Gaussians, we exploit the 3D priors of hand model (i.e., MANO) and share a single Gaussian for two hands to effectively accumulate hand 3D information, given limited views. To further consider the 3D alignment between hands and objects, we include the interacting-subjects optimization step during Gaussian optimization. Our method achieves the state-of-the-art accuracy on two challenging datasets, in terms of 3D hand pose estimation (MPJPE), 3D object reconstruction (CDh, CDo, F10), and rendering quality (PSNR, SSIM, LPIPS), respectively. </p>
<blockquote>
<p>é‡å»ºæ‰‹ç‰©äº¤äº’ï¼ˆHOIï¼‰çš„3Dæ¨¡å‹æ˜¯ä¸€ä¸ªå…·æœ‰è®¸å¤šåº”ç”¨åŸºç¡€æ€§é—®é¢˜ã€‚å°½ç®¡æœ€è¿‘æœ‰æ‰€è¿›å±•ï¼Œä½†ç›®å‰è¿˜æ²¡æœ‰ä»å•ç›®RGBè§†é¢‘ä¸­å®ç°åŒæ‰‹æ— å…³ç±»åˆ«çš„äº¤äº’é‡å»ºçš„å…¨é¢æµç¨‹ï¼Œå…¶ä¸­ä¸¤åªæ‰‹å’Œä¸€ä¸ªæœªçŸ¥å¯¹è±¡åœ¨ç›¸äº’äº¤äº’ã€‚ä¹‹å‰çš„å·¥ä½œè§£å†³äº†æœ‰é™çš„æ‰‹ç‰©äº¤äº’æƒ…å†µï¼Œå…¶ä¸­å¯¹è±¡æ¨¡æ¿æ˜¯é¢„å…ˆå·²çŸ¥çš„ï¼Œæˆ–è€…åªæ¶‰åŠä¸€åªæ‰‹è¿›è¡Œäº¤äº’ã€‚åŒæ‰‹äº¤äº’é‡å»ºä¼šå‡ºç°ä¸¥é‡çš„é®æŒ¡é—®é¢˜ï¼Œè¿™æ˜¯ç”±äºä¸¤åªæ‰‹å’Œä¸€ä¸ªå¯¹è±¡ä¹‹é—´çš„å¤æ‚äº¤äº’é€ æˆçš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæ¨å‡ºäº†BIGSï¼ˆåŒæ‰‹äº¤äº’3Dé«˜æ–¯æ¨¡æ¿ï¼‰ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥ä»å•ç›®è§†é¢‘ä¸­é‡å»ºæ‰‹å’ŒæœªçŸ¥å¯¹è±¡çš„3Dé«˜æ–¯æ¨¡å‹ã€‚ä¸ºäº†ç¨³å¥åœ°è·å–å¯¹è±¡çš„é«˜æ–¯æ¨¡å‹ï¼Œé¿å…ä¸¥é‡çš„é®æŒ¡é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œç»“åˆå¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±ï¼Œæ¥é‡å»ºæœªè§åˆ°çš„å¯¹è±¡éƒ¨åˆ†ã€‚å¯¹äºæ‰‹çš„é«˜æ–¯æ¨¡å‹ï¼Œæˆ‘ä»¬åˆ©ç”¨æ‰‹çš„3Då…ˆéªŒçŸ¥è¯†ï¼ˆå³MANOæ¨¡å‹ï¼‰ï¼Œå¹¶ä¸ºä¸¤åªæ‰‹å…±äº«ä¸€ä¸ªå•ä¸€çš„é«˜æ–¯æ¨¡å‹ï¼Œä»¥åœ¨æœ‰é™çš„è§†è§’å†…æœ‰æ•ˆåœ°ç´¯ç§¯æ‰‹çš„3Dä¿¡æ¯ã€‚ä¸ºäº†è¿›ä¸€æ­¥è€ƒè™‘æ‰‹å’Œç‰©ä½“ä¹‹é—´çš„3Då¯¹é½ï¼Œæˆ‘ä»¬åœ¨é«˜æ–¯ä¼˜åŒ–è¿‡ç¨‹ä¸­åŒ…å«äº†äº¤äº’ä¸»ä½“çš„ä¼˜åŒ–æ­¥éª¤ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä¸¤ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œåœ¨ä¸‰ç»´æ‰‹å§¿æ€ä¼°è®¡ï¼ˆMPJPEï¼‰ã€ä¸‰ç»´ç‰©ä½“é‡å»ºï¼ˆCDhã€CDoã€F10ï¼‰å’Œæ¸²æŸ“è´¨é‡ï¼ˆPSNRã€SSIMã€LPIPSï¼‰ç­‰æ–¹é¢å‡å–å¾—äº†ä¼˜å¼‚æˆç»©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09097v1">PDF</a> Accepted to CVPR 2025</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹æ‰‹-å¯¹è±¡äº¤äº’ï¼ˆHOIï¼‰çš„ä¸‰ç»´é‡å»ºæ˜¯ä¸€ä¸ªå…·æœ‰ä¼—å¤šåº”ç”¨å‰æ™¯çš„åŸºç¡€é—®é¢˜ã€‚é’ˆå¯¹åŒç›®æ‰‹ä¸æœªçŸ¥å¯¹è±¡äº¤äº’çš„å¤æ‚æƒ…å†µï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºBIGSï¼ˆåŒæ‰‹äº¤äº’ä¸‰ç»´é«˜æ–¯å–·å°„ï¼‰çš„æ–¹æ³•ï¼Œå®ç°äº†ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŒæ‰‹ä¸æœªçŸ¥å¯¹è±¡çš„ä¸‰ç»´é«˜æ–¯æ¨¡å‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œç»“åˆè¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±ï¼Œæœ‰æ•ˆé‡å»ºäº†è¢«é®æŒ¡çš„å¯¹è±¡éƒ¨åˆ†ï¼›åŒæ—¶åˆ©ç”¨æ‰‹æ¨¡å‹çš„3Då…ˆéªŒä¿¡æ¯ï¼Œä¸ºåŒæ‰‹å…±äº«å•ä¸€é«˜æ–¯æ¨¡å‹ä»¥ç´¯ç§¯æœ‰é™è§†è§’ä¸‹çš„æ‰‹éƒ¨ä¸‰ç»´ä¿¡æ¯ã€‚æœ¬ç ”ç©¶åœ¨ä¸¤é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¾¾åˆ°äº†é¢†å…ˆçš„å‡†ç¡®åº¦ï¼Œåœ¨æ‰‹éƒ¨å§¿æ€ä¼°è®¡å’Œå¯¹è±¡é‡å»ºç­‰å¤šä¸ªæ–¹é¢è¡¨ç°ä¼˜ç§€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é’ˆå¯¹æ‰‹ä¸æœªçŸ¥å¯¹è±¡äº¤äº’çš„ä¸‰ç»´é‡å»ºé—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„æ–¹æ³•BIGSã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŒæ‰‹ä¸æœªçŸ¥å¯¹è±¡çš„ä¸‰ç»´é«˜æ–¯æ¨¡å‹ã€‚</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†å’Œè¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±æŠ€æœ¯è§£å†³äº†å› æ‰‹éƒ¨äº¤äº’å¯¼è‡´çš„ä¸¥é‡é®æŒ¡é—®é¢˜ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨æ‰‹éƒ¨æ¨¡å‹çš„3Då…ˆéªŒä¿¡æ¯ï¼Œä¸ºåŒæ‰‹å…±äº«å•ä¸€é«˜æ–¯æ¨¡å‹ä»¥ä¼˜åŒ–ä¿¡æ¯ç´¯ç§¯ã€‚</li>
<li>åœ¨ä¼˜åŒ–é«˜æ–¯æ¨¡å‹æ—¶è€ƒè™‘äº†æ‰‹å’Œå¯¹è±¡ä¹‹é—´çš„ä¸‰ç»´å¯¹é½å…³ç³»ã€‚</li>
<li>åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå®ç°äº†å“è¶Šçš„å‡†ç¡®æ€§ï¼ŒåŒ…æ‹¬æ‰‹éƒ¨å§¿æ€ä¼°è®¡å’Œå¯¹è±¡é‡å»ºç­‰æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09097">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8b82ea18ffc7d3f7e52b4b0907c1af36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d318cb48709dce042faf75b7bcb0033e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-462ce779f42ac4ab2736ca11e06fe78e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d63a180bb3a8bb40936af62f34c3616.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="You-Need-a-Transition-Plane-Bridging-Continuous-Panoramic-3D-Reconstruction-with-Perspective-Gaussian-Splatting"><a href="#You-Need-a-Transition-Plane-Bridging-Continuous-Panoramic-3D-Reconstruction-with-Perspective-Gaussian-Splatting" class="headerlink" title="You Need a Transition Plane: Bridging Continuous Panoramic 3D   Reconstruction with Perspective Gaussian Splatting"></a>You Need a Transition Plane: Bridging Continuous Panoramic 3D   Reconstruction with Perspective Gaussian Splatting</h2><p><strong>Authors:Zhijie Shen, Chunyu Lin, Shujuan Huang, Lang Nie, Kang Liao, Yao Zhao</strong></p>
<p>Recently, reconstructing scenes from a single panoramic image using advanced 3D Gaussian Splatting (3DGS) techniques has attracted growing interest. Panoramic images offer a 360$\times$ 180 field of view (FoV), capturing the entire scene in a single shot. However, panoramic images introduce severe distortion, making it challenging to render 3D Gaussians into 2D distorted equirectangular space directly. Converting equirectangular images to cubemap projections partially alleviates this problem but introduces new challenges, such as projection distortion and discontinuities across cube-face boundaries. To address these limitations, we present a novel framework, named TPGS, to bridge continuous panoramic 3D scene reconstruction with perspective Gaussian splatting. Firstly, we introduce a Transition Plane between adjacent cube faces to enable smoother transitions in splatting directions and mitigate optimization ambiguity in the boundary region. Moreover, an intra-to-inter face optimization strategy is proposed to enhance local details and restore visual consistency across cube-face boundaries. Specifically, we optimize 3D Gaussians within individual cube faces and then fine-tune them in the stitched panoramic space. Additionally, we introduce a spherical sampling technique to eliminate visible stitching seams. Extensive experiments on indoor and outdoor, egocentric, and roaming benchmark datasets demonstrate that our approach outperforms existing state-of-the-art methods. Code and models will be available at <a target="_blank" rel="noopener" href="https://github.com/zhijieshen-bjtu/TPGS">https://github.com/zhijieshen-bjtu/TPGS</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œåˆ©ç”¨å…ˆè¿›çš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯ä»å•ä¸ªå…¨æ™¯å›¾åƒé‡å»ºåœºæ™¯å·²ç»å¼•èµ·äº†äººä»¬çš„æå¤§å…´è¶£ã€‚å…¨æ™¯å›¾åƒæä¾›äº†360Â°Ã—180Â°çš„è§†é‡ï¼ˆFoVï¼‰ï¼Œèƒ½å¤Ÿå•æ¬¡æ‹æ‘„æ•æ‰æ•´ä¸ªåœºæ™¯ã€‚ç„¶è€Œï¼Œå…¨æ™¯å›¾åƒå¼•å…¥äº†ä¸¥é‡çš„å¤±çœŸï¼Œä½¿å¾—ç›´æ¥å°†3Dé«˜æ–¯æ¸²æŸ“åˆ°2Dæ‰­æ›²çš„ç­‰è·ç©ºé—´å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å°†ç­‰è·å›¾åƒè½¬æ¢ä¸ºç«‹æ–¹ä½“æ˜ å°„æŠ•å½±éƒ¨åˆ†ç¼“è§£äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†å¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚æŠ•å½±å¤±çœŸå’Œç«‹æ–¹ä½“é¢éƒ¨è¾¹ç•Œå¤„çš„é—´æ–­ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºTPGSçš„æ–°å‹æ¡†æ¶ï¼Œä»¥å»ºç«‹è¿ç»­å…¨æ™¯3Dåœºæ™¯é‡å»ºä¸é€è§†é«˜æ–¯æ‹¼è´´ä¹‹é—´çš„æ¡¥æ¢ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åœ¨ç›¸é‚»çš„ç«‹æ–¹ä½“é¢éƒ¨ä¹‹é—´å¼•å…¥äº†ä¸€ä¸ªè¿‡æ¸¡å¹³é¢ï¼Œä»¥å®ç°åœ¨æ‹¼è´´æ–¹å‘ä¸Šçš„å¹³æ»‘è¿‡æ¸¡ï¼Œå¹¶å‡è½»è¾¹ç•ŒåŒºåŸŸçš„ä¼˜åŒ–æ¨¡ç³Šæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»å†…éƒ¨åˆ°å¤–éƒ¨é¢éƒ¨ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥å¢å¼ºå±€éƒ¨ç»†èŠ‚å¹¶æ¢å¤ç«‹æ–¹ä½“é¢éƒ¨è¾¹ç•Œå¤„çš„è§†è§‰ä¸€è‡´æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¼˜åŒ–å•ä¸ªç«‹æ–¹ä½“é¢éƒ¨å†…çš„3Dé«˜æ–¯ï¼Œç„¶ååœ¨æ‹¼æ¥çš„å…¨æ™¯ç©ºé—´ä¸­è¿›è¡Œå¾®è°ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§çƒå½¢é‡‡æ ·æŠ€æœ¯ä»¥æ¶ˆé™¤å¯è§çš„æ¥ç¼ã€‚åœ¨å®¤å†…å’Œå®¤å¤–ã€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„ä»¥åŠæ¼«æ¸¸åŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/zhijieshen-bjtu/TPGS">https://github.com/zhijieshen-bjtu/TPGS</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09062v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå…ˆè¿›çš„3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œä»å•ä¸€å…¨æ™¯å›¾åƒé‡å»ºåœºæ™¯å·²å¼•èµ·å¹¿æ³›å…³æ³¨ã€‚å…¨æ™¯å›¾åƒå¼•å…¥çš„å¤±çœŸä½¿å¾—å°†3Dé«˜æ–¯æ¸²æŸ“åˆ°2Dç­‰è·ç©ºé—´å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹æ¡†æ¶TPGSï¼Œé€šè¿‡é€è§†é«˜æ–¯å±•å¼€æ¡¥æ¥è¿ç»­å…¨æ™¯3Dåœºæ™¯é‡å»ºï¼Œå¼•å…¥è¿‡æ¸¡å¹³é¢ä¼˜åŒ–ç›¸é‚»ç«‹æ–¹ä½“é¢éƒ¨ä¹‹é—´çš„è¿‡æ¸¡ï¼Œå¹¶æå‡ºé¢å†…è‡³é¢é—´ä¼˜åŒ–ç­–ç•¥ï¼Œå¢å¼ºå±€éƒ¨ç»†èŠ‚å¹¶æ¢å¤ç«‹æ–¹ä½“é¢éƒ¨è¾¹ç•Œå¤„çš„è§†è§‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨çƒå½¢é‡‡æ ·æŠ€æœ¯æ¶ˆé™¤å¯è§æ¥ç¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSæŠ€æœ¯åœ¨ä»å•ä¸€å…¨æ™¯å›¾åƒé‡å»ºåœºæ™¯ä¸­çš„åº”ç”¨å—åˆ°å…³æ³¨ã€‚</li>
<li>å…¨æ™¯å›¾åƒå¼•å…¥çš„ä¸¥é‡å¤±çœŸä½¿å¾—æ¸²æŸ“å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>TPGSæ¡†æ¶é€šè¿‡é€è§†é«˜æ–¯å±•å¼€è§£å†³è¿ç»­å…¨æ™¯3Dåœºæ™¯é‡å»ºé—®é¢˜ã€‚</li>
<li>å¼•å…¥è¿‡æ¸¡å¹³é¢ä»¥ä¼˜åŒ–ç›¸é‚»ç«‹æ–¹ä½“é¢éƒ¨ä¹‹é—´çš„è¿‡æ¸¡ã€‚</li>
<li>æå‡ºé¢å†…è‡³é¢é—´çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå¢å¼ºå±€éƒ¨ç»†èŠ‚å’Œè§†è§‰ä¸€è‡´æ€§ã€‚</li>
<li>çƒå½¢é‡‡æ ·æŠ€æœ¯ç”¨äºæ¶ˆé™¤å¯è§æ¥ç¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09062">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-03cafb913a2d7a51f7a012a59ca93fac.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-148ae3a0ea12c520851c21aa2aea0afd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e56e44ebee0d874d9deac263508bef8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c36407b767dd0e2f752b5b7161bf059.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dcf9d7b1bb505538ad6b62899822607b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a59bb74a7fb8881baa91f604e06e531c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="BlockGaussian-Efficient-Large-Scale-Scene-NovelView-Synthesis-via-Adaptive-Block-Based-Gaussian-Splatting"><a href="#BlockGaussian-Efficient-Large-Scale-Scene-NovelView-Synthesis-via-Adaptive-Block-Based-Gaussian-Splatting" class="headerlink" title="BlockGaussian: Efficient Large-Scale Scene NovelView Synthesis via   Adaptive Block-Based Gaussian Splatting"></a>BlockGaussian: Efficient Large-Scale Scene NovelView Synthesis via   Adaptive Block-Based Gaussian Splatting</h2><p><strong>Authors:Yongchang Wu, Zipeng Qi, Zhenwei Shi, Zhengxia Zou</strong></p>
<p>The recent advancements in 3D Gaussian Splatting (3DGS) have demonstrated remarkable potential in novel view synthesis tasks. The divide-and-conquer paradigm has enabled large-scale scene reconstruction, but significant challenges remain in scene partitioning, optimization, and merging processes. This paper introduces BlockGaussian, a novel framework incorporating a content-aware scene partition strategy and visibility-aware block optimization to achieve efficient and high-quality large-scale scene reconstruction. Specifically, our approach considers the content-complexity variation across different regions and balances computational load during scene partitioning, enabling efficient scene reconstruction. To tackle the supervision mismatch issue during independent block optimization, we introduce auxiliary points during individual block optimization to align the ground-truth supervision, which enhances the reconstruction quality. Furthermore, we propose a pseudo-view geometry constraint that effectively mitigates rendering degradation caused by airspace floaters during block merging. Extensive experiments on large-scale scenes demonstrate that our approach achieves state-of-the-art performance in both reconstruction efficiency and rendering quality, with a 5x speedup in optimization and an average PSNR improvement of 1.21 dB on multiple benchmarks. Notably, BlockGaussian significantly reduces computational requirements, enabling large-scale scene reconstruction on a single 24GB VRAM device. The project page is available at <a target="_blank" rel="noopener" href="https://github.com/SunshineWYC/BlockGaussian">https://github.com/SunshineWYC/BlockGaussian</a> </p>
<blockquote>
<p>è¿‘æœŸåœ¨ä¸‰ç»´é«˜æ–¯å»¶å±•ï¼ˆ3DGSï¼‰æ–¹é¢çš„è¿›å±•è¡¨æ˜ï¼Œå®ƒåœ¨æ–°å‹è§†å›¾åˆæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—æ½œåŠ›ã€‚åˆ†è€Œæ²»ä¹‹çš„æ¨¡å¼ä½¿å¤§è§„æ¨¡åœºæ™¯é‡å»ºæˆä¸ºå¯èƒ½ï¼Œä½†åœ¨åœºæ™¯åˆ†å‰²ã€ä¼˜åŒ–å’Œåˆå¹¶è¿‡ç¨‹ä¸­ä»å­˜åœ¨é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†BlockGaussianï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆå†…å®¹æ„ŸçŸ¥åœºæ™¯åˆ†å‰²ç­–ç•¥å’Œå¯è§æ€§æ„ŸçŸ¥å—ä¼˜åŒ–çš„æ–°å‹æ¡†æ¶ï¼Œä»¥å®ç°é«˜æ•ˆé«˜è´¨é‡çš„å¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è€ƒè™‘äº†ä¸åŒåŒºåŸŸçš„å†…å®¹å¤æ‚æ€§å˜åŒ–ï¼Œå¹¶åœ¨åœºæ™¯åˆ†å‰²è¿‡ç¨‹ä¸­å¹³è¡¡è®¡ç®—è´Ÿè½½ï¼Œä»¥å®ç°é«˜æ•ˆçš„åœºæ™¯é‡å»ºã€‚ä¸ºäº†è§£å†³ç‹¬ç«‹å—ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„ç›‘ç£ä¸åŒ¹é…é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨å•ä¸ªå—ä¼˜åŒ–è¿‡ç¨‹ä¸­å¼•å…¥äº†è¾…åŠ©ç‚¹æ¥å¯¹é½åœ°é¢çœŸå®ç›‘ç£ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¼ªè§†å›¾å‡ ä½•çº¦æŸï¼Œæœ‰æ•ˆå‡è½»äº†å—åˆå¹¶è¿‡ç¨‹ä¸­å› ç©ºä¸­æ¼‚æµ®ç‰©é€ æˆçš„æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚å¤§è§„æ¨¡åœºæ™¯ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºæ•ˆç‡å’Œæ¸²æŸ“è´¨é‡æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œä¼˜åŒ–é€Ÿåº¦æé«˜äº†5å€ï¼Œå¤šä¸ªåŸºå‡†æµ‹è¯•çš„å¹³å‡PSNRæé«˜äº†1.21åˆ†è´ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒBlockGaussianæ˜¾è‘—é™ä½äº†è®¡ç®—è¦æ±‚ï¼Œèƒ½å¤Ÿåœ¨å•ä¸ª24GB VRAMè®¾å¤‡ä¸Šå®ç°å¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚é¡¹ç›®é¡µé¢å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/SunshineWYC/BlockGaussian%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/SunshineWYC/BlockGaussianè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09048v1">PDF</a> <a target="_blank" rel="noopener" href="https://github.com/SunshineWYC/BlockGaussian">https://github.com/SunshineWYC/BlockGaussian</a></p>
<p><strong>Summary</strong></p>
<p>3DGSæŠ€æœ¯çš„æ–°è¿›å±•åœ¨æ–°å‹è§†å›¾åˆæˆä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚BlockGaussianæ¡†æ¶é‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥å®ç°å¤§è§„æ¨¡åœºæ™¯é‡å»ºï¼Œå¼•å…¥å†…å®¹æ„ŸçŸ¥çš„åœºæ™¯åˆ†å‰²ç­–ç•¥å’Œå¯è§æ€§æ„ŸçŸ¥çš„å—ä¼˜åŒ–æŠ€æœ¯ï¼Œæé«˜äº†åœºæ™¯é‡å»ºçš„æ•ˆç‡å’Œå“è´¨ã€‚è¯¥æ¡†æ¶è¿˜è§£å†³äº†ç‹¬ç«‹å—ä¼˜åŒ–ä¸­çš„ç›‘ç£ä¸åŒ¹é…é—®é¢˜ï¼Œå¹¶æå‡ºä¼ªè§†å›¾å‡ ä½•çº¦æŸä»¥ç¼“è§£å—åˆå¹¶è¿‡ç¨‹ä¸­å› ç©ºä¸­æ¼‚æµ®ç‰©å¯¼è‡´çš„æ¸²æŸ“é€€åŒ–é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨é‡å»ºæ•ˆç‡å’Œæ¸²æŸ“è´¨é‡æ–¹é¢è¾¾åˆ°é¢†å…ˆæ°´å¹³ï¼Œä¼˜åŒ–é€Ÿåº¦æå‡5å€ï¼Œå¤šé¡¹åŸºå‡†æµ‹è¯•çš„å¹³å‡PSNRå€¼æé«˜1.21 dBã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>BlockGaussianæ¡†æ¶åˆ©ç”¨åˆ†è€Œæ²»ä¹‹ç­–ç•¥å®ç°å¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚</li>
<li>å¼•å…¥å†…å®¹æ„ŸçŸ¥çš„åœºæ™¯åˆ†å‰²ç­–ç•¥ï¼Œè€ƒè™‘å†…å®¹å¤æ‚åº¦çš„å˜åŒ–ï¼Œå¹³è¡¡è®¡ç®—è´Ÿè½½ã€‚</li>
<li>é‡‡ç”¨å¯è§æ€§æ„ŸçŸ¥çš„å—ä¼˜åŒ–æŠ€æœ¯ï¼Œè§£å†³ç‹¬ç«‹å—ä¼˜åŒ–ä¸­çš„ç›‘ç£ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>å¼•å…¥è¾…åŠ©ç‚¹è¿›è¡Œä¸ªä½“å—ä¼˜åŒ–ï¼Œæé«˜é‡å»ºè´¨é‡ã€‚</li>
<li>æå‡ºä¼ªè§†å›¾å‡ ä½•çº¦æŸï¼Œæœ‰æ•ˆç¼“è§£å› ç©ºä¸­æ¼‚æµ®ç‰©å¯¼è‡´çš„æ¸²æŸ“é€€åŒ–é—®é¢˜ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒBlockGaussianæ¡†æ¶åœ¨é‡å»ºæ•ˆç‡å’Œæ¸²æŸ“è´¨é‡æ–¹é¢è¡¨ç°å“è¶Šã€‚</li>
<li>è¯¥æ¡†æ¶ä¼˜åŒ–é€Ÿåº¦æå‡5å€ï¼Œå¤šé¡¹åŸºå‡†æµ‹è¯•çš„å¹³å‡PSNRå€¼æé«˜1.21 dBã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09048">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c92c9307dd92c9e02362cdc3def177c2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c5eded602b6dcc30b60bd4b0e200b0ba.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-496815366bb2fa2d8f4b803b1a2be14c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HOMER-Homography-Based-Efficient-Multi-view-3D-Object-Removal"><a href="#HOMER-Homography-Based-Efficient-Multi-view-3D-Object-Removal" class="headerlink" title="HOMER: Homography-Based Efficient Multi-view 3D Object Removal"></a>HOMER: Homography-Based Efficient Multi-view 3D Object Removal</h2><p><strong>Authors:Jingcheng Ni, Weiguang Zhao, Daniel Wang, Ziyao Zeng, Chenyu You, Alex Wong, Kaizhu Huang</strong></p>
<p>3D object removal is an important sub-task in 3D scene editing, with broad applications in scene understanding, augmented reality, and robotics. However, existing methods struggle to achieve a desirable balance among consistency, usability, and computational efficiency in multi-view settings. These limitations are primarily due to unintuitive user interaction in the source view, inefficient multi-view object mask generation, computationally expensive inpainting procedures, and a lack of applicability across different radiance field representations. To address these challenges, we propose a novel pipeline that improves the quality and efficiency of multi-view object mask generation and inpainting. Our method introduces an intuitive region-based interaction mechanism in the source view and eliminates the need for camera poses or extra model training. Our lightweight HoMM module is employed to achieve high-quality multi-view mask propagation with enhanced efficiency. In the inpainting stage, we further reduce computational costs by performing inpainting only on selected key views and propagating the results to other views via homography-based mapping. Our pipeline is compatible with a variety of radiance field frameworks, including NeRF and 3D Gaussian Splatting, demonstrating improved generalizability and practicality in real-world scenarios. Additionally, we present a new 3D multi-object removal dataset with greater object diversity and viewpoint variation than existing datasets. Experiments on public benchmarks and our proposed dataset show that our method achieves state-of-the-art performance while reducing runtime to one-fifth of that required by leading baselines. </p>
<blockquote>
<p>3Dç‰©ä½“ç§»é™¤æ˜¯3Dåœºæ™¯ç¼–è¾‘ä¸­çš„ä¸€ä¸ªé‡è¦å­ä»»åŠ¡ï¼Œå¹¿æ³›åº”ç”¨äºåœºæ™¯ç†è§£ã€å¢å¼ºç°å®å’Œæœºå™¨äººæŠ€æœ¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¤šè§’åº¦è®¾ç½®ä¸­çš„ä¸€è‡´æ€§ã€å¯ç”¨æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å¾ˆéš¾è¾¾åˆ°ç†æƒ³å¹³è¡¡ã€‚è¿™äº›å±€é™æ€§ä¸»è¦æ˜¯ç”±äºæºè§†å›¾ä¸­çš„ç”¨æˆ·äº¤äº’ä¸å¤Ÿç›´è§‚ã€å¤šè§†å›¾å¯¹è±¡è’™ç‰ˆç”Ÿæˆæ•ˆç‡ä½ä¸‹ã€æ˜‚è´µçš„ä¿®å¤ç¨‹åºè®¡ç®—ä»¥åŠç¼ºä¹è·¨ä¸åŒè¾å°„åœºè¡¨ç¤ºçš„åº”ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ”¹è¿›å¤šè§†å›¾å¯¹è±¡è’™ç‰ˆç”Ÿæˆå’Œä¿®å¤è´¨é‡åŠæ•ˆç‡çš„æ–°æµç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æºè§†å›¾ä¸­å¼•å…¥äº†ä¸€ç§ç›´è§‚çš„åŸºäºåŒºåŸŸçš„äº¤äº’æœºåˆ¶ï¼Œæ— éœ€ç›¸æœºå§¿æ€æˆ–é¢å¤–çš„æ¨¡å‹è®­ç»ƒã€‚æˆ‘ä»¬é‡‡ç”¨è½»é‡çº§çš„HoMMæ¨¡å—å®ç°é«˜æ•ˆçš„é«˜è´¨é‡å¤šè§†å›¾è’™ç‰ˆä¼ æ’­ã€‚åœ¨ä¿®å¤é˜¶æ®µï¼Œæˆ‘ä»¬é€šè¿‡åœ¨é€‰å®šçš„å…³é”®è§†å›¾ä¸Šè¿›è¡Œä¿®å¤ï¼Œå¹¶é€šè¿‡åŸºäºå‡ ä½•æ˜ å°„çš„ä¼ æ’­å°†ç»“æœä¼ æ’­åˆ°å…¶ä»–è§†å›¾ï¼Œä»è€Œè¿›ä¸€æ­¥é™ä½è®¡ç®—æˆæœ¬ã€‚æˆ‘ä»¬çš„æµç¨‹ä¸å„ç§è¾å°„åœºæ¡†æ¶å…¼å®¹ï¼ŒåŒ…æ‹¬NeRFå’Œ3Dé«˜æ–¯å¹³é“ºï¼Œæ˜¾ç¤ºå‡ºåœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„æ”¹è¿›é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„3Då¤šç‰©ä½“ç§»é™¤æ•°æ®é›†ï¼Œä¸ç°æœ‰æ•°æ®é›†ç›¸æ¯”ï¼Œè¯¥æ•°æ®é›†å…·æœ‰æ›´å¤§çš„ç‰©ä½“å¤šæ ·æ€§å’Œè§†è§’å˜åŒ–ã€‚åœ¨å…¬å…±åŸºå‡†æµ‹è¯•å’Œæˆ‘ä»¬æå‡ºçš„æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶å°†è¿è¡Œæ—¶é—´å‡å°‘åˆ°ç°æœ‰åŸºçº¿æ‰€éœ€æ—¶é—´çš„äº”åˆ†ä¹‹ä¸€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17636v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œæ—¨åœ¨æ”¹è¿›å¤šè§†è§’ç‰©ä½“ç§»é™¤çš„è´¨é‡å’Œæ•ˆç‡ã€‚é€šè¿‡å¼•å…¥åŸºäºåŒºåŸŸçš„äº¤äº’æœºåˆ¶å’Œé«˜æ•ˆçš„å¤šè§†è§’æ©è†œç”ŸæˆæŠ€æœ¯ï¼Œè¯¥æ–¹æ³•æ— éœ€ç›¸æœºå§¿æ€å’Œé¢å¤–æ¨¡å‹è®­ç»ƒã€‚åŒæ—¶ï¼Œé‡‡ç”¨è½»é‡çº§çš„HoMMæ¨¡å—å®ç°é«˜è´¨é‡çš„å¤šè§†è§’æ©è†œä¼ æ’­ï¼Œå¹¶åœ¨é€‰å®šçš„å…³é”®è§†å›¾ä¸Šæ‰§è¡Œå¡«å……æ“ä½œï¼Œé€šè¿‡åŸºäºåŒæ„æ€§çš„æ˜ å°„å°†ç»“æœä¼ æ’­åˆ°å…¶ä»–è§†å›¾ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…¼å®¹å¤šç§è¾å°„åœºæ¡†æ¶ï¼ŒåŒ…æ‹¬NeRFå’Œ3Dé«˜æ–¯æ–‘ç‰‡æŠ€æœ¯ï¼Œå¹¶åœ¨ç°å®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¬å…±åŸºå‡†æµ‹è¯•é›†å’Œæå‡ºçš„æ–°æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å°†è¿è¡Œæ—¶é—´ç¼©çŸ­åˆ°ç°æœ‰åŸºçº¿æŠ€æœ¯çš„äº”åˆ†ä¹‹ä¸€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†åœ¨å¤šè§†è§’åœºæ™¯ä¸­ç‰©ä½“ç§»é™¤çš„é‡è¦æ€§å’Œåº”ç”¨ã€‚</li>
<li>æŒ‡å‡ºäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§å’Œé¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚ç”¨æˆ·äº¤äº’ä¸ç›´è§‚ã€å¤šè§†è§’ç‰©ä½“æ©è†œç”Ÿæˆæ•ˆç‡ä½ç­‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼ŒåŒ…æ‹¬åŸºäºåŒºåŸŸçš„äº¤äº’æœºåˆ¶ã€é«˜æ•ˆçš„å¤šè§†è§’æ©è†œç”Ÿæˆå’Œå¡«å……æŠ€æœ¯ã€‚</li>
<li>å¼•å…¥äº†è½»é‡çº§çš„HoMMæ¨¡å—ï¼Œå®ç°äº†é«˜è´¨é‡çš„å¤šè§†è§’æ©è†œä¼ æ’­å’Œé«˜æ•ˆçš„å¡«å……æ“ä½œã€‚</li>
<li>æ–¹æ³•å…¼å®¹å¤šç§è¾å°„åœºæ¡†æ¶ï¼ŒåŒ…æ‹¬NeRFå’Œ3Dé«˜æ–¯æ–‘ç‰‡æŠ€æœ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å¤šè§†è§’ç‰©ä½“ç§»é™¤æ•°æ®é›†ï¼Œå…·æœ‰æ›´å¤§çš„ç‰©ä½“å¤šæ ·æ€§å’Œè§†è§’å˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17636">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ac12c9621662c687b0edad4616abd37b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb5195a4daf469db40c8e5775af388e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d09095d4dfa0ddc0abae8fe39ebfec6f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="SplatMAP-Online-Dense-Monocular-SLAM-with-3D-Gaussian-Splatting"><a href="#SplatMAP-Online-Dense-Monocular-SLAM-with-3D-Gaussian-Splatting" class="headerlink" title="SplatMAP: Online Dense Monocular SLAM with 3D Gaussian Splatting"></a>SplatMAP: Online Dense Monocular SLAM with 3D Gaussian Splatting</h2><p><strong>Authors:Yue Hu, Rong Liu, Meida Chen, Peter Beerel, Andrew Feng</strong></p>
<p>Achieving high-fidelity 3D reconstruction from monocular video remains challenging due to the inherent limitations of traditional methods like Structure-from-Motion (SfM) and monocular SLAM in accurately capturing scene details. While differentiable rendering techniques such as Neural Radiance Fields (NeRF) address some of these challenges, their high computational costs make them unsuitable for real-time applications. Additionally, existing 3D Gaussian Splatting (3DGS) methods often focus on photometric consistency, neglecting geometric accuracy and failing to exploit SLAMâ€™s dynamic depth and pose updates for scene refinement. We propose a framework integrating dense SLAM with 3DGS for real-time, high-fidelity dense reconstruction. Our approach introduces SLAM-Informed Adaptive Densification, which dynamically updates and densifies the Gaussian model by leveraging dense point clouds from SLAM. Additionally, we incorporate Geometry-Guided Optimization, which combines edge-aware geometric constraints and photometric consistency to jointly optimize the appearance and geometry of the 3DGS scene representation, enabling detailed and accurate SLAM mapping reconstruction. Experiments on the Replica and TUM-RGBD datasets demonstrate the effectiveness of our approach, achieving state-of-the-art results among monocular systems. Specifically, our method achieves a PSNR of 36.864, SSIM of 0.985, and LPIPS of 0.040 on Replica, representing improvements of 10.7%, 6.4%, and 49.4%, respectively, over the previous SOTA. On TUM-RGBD, our method outperforms the closest baseline by 10.2%, 6.6%, and 34.7% in the same metrics. These results highlight the potential of our framework in bridging the gap between photometric and geometric dense 3D scene representations, paving the way for practical and efficient monocular dense reconstruction. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­å®ç°é«˜ä¿çœŸ3Dé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰å’Œå•ç›®SLAMï¼‰åœ¨å‡†ç¡®æ•æ‰åœºæ™¯ç»†èŠ‚æ–¹é¢çš„å›ºæœ‰å±€é™æ€§ã€‚è™½ç„¶åƒç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰è¿™æ ·çš„å¯å¾®åˆ†æ¸²æŸ“æŠ€æœ¯è§£å†³äº†ä¸€äº›è¿™äº›æŒ‘æˆ˜ï¼Œä½†å®ƒä»¬çš„é«˜è®¡ç®—æˆæœ¬ä½¿å®ƒä»¬ä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„3Dé«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰æ–¹æ³•é€šå¸¸ä¾§é‡äºå…‰åº¦ä¸€è‡´æ€§ï¼Œå¿½è§†äº†å‡ ä½•ç²¾åº¦ï¼Œå¹¶ä¸”æœªèƒ½åˆ©ç”¨SLAMçš„åŠ¨æ€æ·±åº¦å’Œå§¿æ€æ›´æ–°æ¥è¿›è¡Œåœºæ™¯ç»†åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ•´åˆå¯†é›†SLAMä¸3DGSçš„æ¡†æ¶ï¼Œç”¨äºå®æ—¶é«˜ä¿çœŸå¯†é›†é‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†SLAMä¿¡æ¯è‡ªé€‚åº”è‡´å¯†åŒ–ï¼Œåˆ©ç”¨SLAMçš„å¯†é›†ç‚¹äº‘åŠ¨æ€æ›´æ–°å’Œè‡´å¯†åŒ–é«˜æ–¯æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†å‡ ä½•å¼•å¯¼ä¼˜åŒ–ï¼Œå®ƒå°†è¾¹ç¼˜æ„ŸçŸ¥å‡ ä½•çº¦æŸå’Œå…‰åº¦ä¸€è‡´æ€§ç›¸ç»“åˆï¼Œä»¥è”åˆä¼˜åŒ–3DGSåœºæ™¯è¡¨ç¤ºçš„å¤–è§‚å’Œå‡ ä½•å½¢çŠ¶ï¼Œä»è€Œå®ç°è¯¦ç»†è€Œå‡†ç¡®çš„SLAMæ˜ å°„é‡å»ºã€‚åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å•ç›®ç³»ç»Ÿä¸­å®ç°äº†æœ€å…ˆè¿›çš„æˆæœã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Replicaä¸Šå®ç°äº†PSNRä¸º36.864ï¼ŒSSIMä¸º0.985ï¼ŒLPIPSä¸º0.040çš„æŒ‡æ ‡ï¼Œåˆ†åˆ«æ¯”ä¹‹å‰çš„æœ€ä½³æˆæœæé«˜äº†10.7%ï¼Œ6.4%å’Œ49.4%ã€‚åœ¨TUM-RGBDä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç›¸åŒçš„æŒ‡æ ‡ä¸Šæ¯”æœ€æ¥è¿‘çš„åŸºçº¿é«˜å‡º10.2%ï¼Œ6.6%å’Œ34.7%ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†æˆ‘ä»¬æ¡†æ¶åœ¨æ¡¥æ¥å…‰åº¦è¡¨ç¤ºå’Œå‡ ä½•å¯†é›†3Dåœºæ™¯è¡¨ç¤ºä¹‹é—´çš„æ½œåŠ›ï¼Œä¸ºå®ç”¨å’Œé«˜æ•ˆçš„å•ç›®å¯†é›†é‡å»ºé“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07015v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªèåˆå¯†é›†SLAMä¸3DGSçš„æ–°æ¡†æ¶ï¼Œç”¨äºå®æ—¶é«˜ç²¾åº¦ä¸‰ç»´é‡å»ºã€‚è¯¥æ¡†æ¶å¼•å…¥SLAMä¿¡æ¯è‡ªé€‚åº”å¯†é›†åŒ–æŠ€æœ¯ï¼Œç»“åˆè¾¹ç¼˜æ„ŸçŸ¥å‡ ä½•çº¦æŸå’Œå…‰åº¦ä¸€è‡´æ€§ä¼˜åŒ–ï¼Œå®ç°äº†é«˜ç²¾åº¦çš„SLAMæ˜ å°„é‡å»ºã€‚åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å•ç›®ç³»ç»Ÿä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¼ ç»Ÿæ–¹æ³•å¦‚SfMå’Œå•ç›®SLAMåœ¨æ•æ‰åœºæ™¯ç»†èŠ‚æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>å¯å¾®æ¸²æŸ“æŠ€æœ¯å¦‚NeRFè™½èƒ½è§£å†³éƒ¨åˆ†æŒ‘æˆ˜ï¼Œä½†è®¡ç®—æˆæœ¬é«˜ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚</li>
<li>ç°æœ‰3DGSæ–¹æ³•ä¸»è¦å…³æ³¨å…‰åº¦ä¸€è‡´æ€§ï¼Œå¿½è§†å‡ ä½•ç²¾åº¦ï¼Œæœªèƒ½åˆ©ç”¨SLAMçš„åŠ¨æ€æ·±åº¦å’Œå§¿æ€æ›´æ–°è¿›è¡Œåœºæ™¯ä¼˜åŒ–ã€‚</li>
<li>æå‡ºèåˆå¯†é›†SLAMä¸3DGSçš„æ–°æ¡†æ¶ï¼Œå®ç°å®æ—¶é«˜ç²¾åº¦ä¸‰ç»´é‡å»ºã€‚</li>
<li>å¼•å…¥SLAMä¿¡æ¯è‡ªé€‚åº”å¯†é›†åŒ–æŠ€æœ¯ï¼Œåˆ©ç”¨å¯†é›†ç‚¹äº‘åŠ¨æ€æ›´æ–°å’ŒåŠ å¯†é«˜æ–¯æ¨¡å‹ã€‚</li>
<li>ç»“åˆè¾¹ç¼˜æ„ŸçŸ¥å‡ ä½•çº¦æŸå’Œå…‰åº¦ä¸€è‡´æ€§ä¼˜åŒ–ï¼Œå®ç°åœºæ™¯è¡¨ç¤ºçš„å‡ ä½•å’Œå¤–è§‚è”åˆä¼˜åŒ–ã€‚</li>
<li>åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å–å¾—äº†æ˜¾è‘—æˆæœï¼Œå®ç°äº†ä¸å•ç›®ç³»ç»Ÿçš„æœ€å…ˆè¿›çš„æˆæœã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07015">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f91bf9818daa3973064822dc95e52395.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eeb1f7bb332542eb9550486e9c643885.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2115178af1283bf30600924cebbf7c4d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Real-time-Free-view-Human-Rendering-from-Sparse-view-RGB-Videos-using-Double-Unprojected-Textures"><a href="#Real-time-Free-view-Human-Rendering-from-Sparse-view-RGB-Videos-using-Double-Unprojected-Textures" class="headerlink" title="Real-time Free-view Human Rendering from Sparse-view RGB Videos using   Double Unprojected Textures"></a>Real-time Free-view Human Rendering from Sparse-view RGB Videos using   Double Unprojected Textures</h2><p><strong>Authors:Guoxing Sun, Rishabh Dabral, Heming Zhu, Pascal Fua, Christian Theobalt, Marc Habermann</strong></p>
<p>Real-time free-view human rendering from sparse-view RGB inputs is a challenging task due to the sensor scarcity and the tight time budget. To ensure efficiency, recent methods leverage 2D CNNs operating in texture space to learn rendering primitives. However, they either jointly learn geometry and appearance, or completely ignore sparse image information for geometry estimation, significantly harming visual quality and robustness to unseen body poses. To address these issues, we present Double Unprojected Textures, which at the core disentangles coarse geometric deformation estimation from appearance synthesis, enabling robust and photorealistic 4K rendering in real-time. Specifically, we first introduce a novel image-conditioned template deformation network, which estimates the coarse deformation of the human template from a first unprojected texture. This updated geometry is then used to apply a second and more accurate texture unprojection. The resulting texture map has fewer artifacts and better alignment with input views, which benefits our learning of finer-level geometry and appearance represented by Gaussian splats. We validate the effectiveness and efficiency of the proposed method in quantitative and qualitative experiments, which significantly surpasses other state-of-the-art methods. Project page: <a target="_blank" rel="noopener" href="https://vcai.mpi-inf.mpg.de/projects/DUT/">https://vcai.mpi-inf.mpg.de/projects/DUT/</a> </p>
<blockquote>
<p>ä»ç¨€ç–è§†è§’çš„RGBè¾“å…¥è¿›è¡Œå®æ—¶è‡ªç”±è§†è§’çš„äººä½“æ¸²æŸ“æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºä¼ æ„Ÿå™¨ç¨€ç–å’Œä¸¥æ ¼çš„æ—¶é—´é¢„ç®—é™åˆ¶ã€‚ä¸ºäº†ä¿è¯æ•ˆç‡ï¼Œæœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨åœ¨çº¹ç†ç©ºé—´æ“ä½œçš„äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ¸²æŸ“åŸå§‹æ•°æ®ã€‚ç„¶è€Œï¼Œå®ƒä»¬è¦ä¹ˆè”åˆå­¦ä¹ å‡ ä½•å’Œå¤–è§‚ï¼Œè¦ä¹ˆå®Œå…¨å¿½ç•¥ç¨€ç–å›¾åƒçš„å‡ ä½•ä¼°è®¡ä¿¡æ¯ï¼Œè¿™ä¸¥é‡æŸå®³äº†è§†è§‰è´¨é‡å’Œå¯¹æœªè§è¿‡çš„èº«ä½“å§¿æ€çš„é²æ£’æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŒæœªæŠ•å½±çº¹ç†ï¼ˆDouble Unprojected Texturesï¼‰æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ˜¯å°†ç²—ç•¥çš„å‡ ä½•å˜å½¢ä¼°è®¡ä»å¤–è§‚åˆæˆä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä»è€Œå®ç°å®æ—¶é²æ£’ä¸”é€¼çœŸçš„4Kæ¸²æŸ“ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥äº†ä¸€ç§æ–°å‹å›¾åƒæ¡ä»¶æ¨¡æ¿å˜å½¢ç½‘ç»œï¼Œä»ç¬¬ä¸€ä¸ªæœªæŠ•å½±çº¹ç†ä¼°è®¡äººä½“æ¨¡æ¿çš„ç²—ç•¥å˜å½¢ã€‚ç„¶åï¼Œä½¿ç”¨è¿™ä¸ªæ›´æ–°çš„å‡ ä½•ä½“æ¥è¿›è¡Œç¬¬äºŒæ¬¡æ›´å‡†ç¡®çš„çº¹ç†åæŠ•å½±ã€‚å¾—åˆ°çš„çº¹ç†æ˜ å°„å…·æœ‰è¾ƒå°‘çš„ä¼ªå½±ï¼Œä¸è¾“å…¥è§†è§’å¯¹é½æ›´å¥½ï¼Œè¿™æœ‰åˆ©äºæˆ‘ä»¬å­¦ä¹ ç”±é«˜æ–¯ç‚¹è¡¨ç¤ºçš„æ›´ç²¾ç»†çº§åˆ«çš„å‡ ä½•å’Œå¤–è§‚ã€‚æˆ‘ä»¬é€šè¿‡å®šé‡å’Œå®šæ€§å®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ï¼Œæ˜¾è‘—è¶…è¶Šäº†å…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://vcai.mpi-inf.mpg.de/projects/DUT/">https://vcai.mpi-inf.mpg.de/projects/DUT/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13183v2">PDF</a> Accepted at CVPR 2025, Project page:   <a target="_blank" rel="noopener" href="https://vcai.mpi-inf.mpg.de/projects/DUT/">https://vcai.mpi-inf.mpg.de/projects/DUT/</a></p>
<p><strong>Summary</strong></p>
<p>å®æ—¶ä»ç¨€ç–RGBè¾“å…¥è¿›è¡Œè‡ªç”±è§†è§’äººç±»æ¸²æŸ“æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œç”±äºä¼ æ„Ÿå™¨ç¨€ç–å’Œæ—¶é—´é™åˆ¶ã€‚æœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œåœ¨çº¹ç†ç©ºé—´å­¦ä¹ æ¸²æŸ“åŸç†ï¼Œä½†å­˜åœ¨è”åˆå­¦ä¹ å‡ ä½•å’Œå¤–è§‚æˆ–å¿½ç•¥ç¨€ç–å›¾åƒä¿¡æ¯ä¼°è®¡å‡ ä½•çš„é—®é¢˜ï¼Œä¸¥é‡å½±å“äº†è§†è§‰è´¨é‡å’Œå¯¹æœªè§å§¿æ€çš„é²æ£’æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåŒé‡æœªæŠ•å½±çº¹ç†ï¼ˆDouble Unprojected Texturesï¼‰æ–¹æ³•ï¼Œæ ¸å¿ƒåœ¨äºå°†ç²—ç•¥çš„å‡ ä½•å˜å½¢ä¼°è®¡ä¸å¤–è§‚åˆæˆè§£è€¦ï¼Œå®ç°å®æ—¶é²æ£’çš„å…‰å­çº§æ¸²æŸ“ã€‚æˆ‘ä»¬å¼•å…¥å›¾åƒæ¡ä»¶æ¨¡æ¿å˜å½¢ç½‘ç»œï¼Œä»ç¬¬ä¸€ä¸ªæœªæŠ•å½±çº¹ç†ä¼°è®¡äººä½“æ¨¡æ¿çš„ç²—ç•¥å˜å½¢ã€‚æ›´æ–°çš„å‡ ä½•ç”¨äºåº”ç”¨ç¬¬äºŒæ¬¡æ›´å‡†ç¡®çš„çº¹ç†æœªæŠ•å½±ã€‚ç»“æœçº¹ç†å›¾å…·æœ‰è¾ƒå°‘çš„ä¼ªå½±ï¼Œä¸è¾“å…¥è§†å›¾å¯¹é½æ›´å¥½ï¼Œæœ‰åˆ©äºæˆ‘ä»¬å­¦ä¹ ç”±é«˜æ–¯ç‚¹è¡¨ç¤ºçš„ç²¾ç»†çº§åˆ«çš„å‡ ä½•å’Œå¤–è§‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®æ—¶è‡ªç”±è§†è§’äººç±»æ¸²æŸ“æ˜¯é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦ç”±äºä¼ æ„Ÿå™¨ç¨€ç–å’Œæ—¶é—´é™åˆ¶ã€‚</li>
<li>æœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œåœ¨çº¹ç†ç©ºé—´å­¦ä¹ æ¸²æŸ“åŸç†ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨è”åˆå­¦ä¹ å‡ ä½•å’Œå¤–è§‚æˆ–å¿½ç•¥ç¨€ç–å›¾åƒä¿¡æ¯çš„é—®é¢˜ï¼Œå½±å“è§†è§‰è´¨é‡å’Œé²æ£’æ€§ã€‚</li>
<li>æå‡ºåŒé‡æœªæŠ•å½±çº¹ç†æ–¹æ³•ï¼Œæ ¸å¿ƒåœ¨äºå°†å‡ ä½•å˜å½¢ä¼°è®¡ä¸å¤–è§‚åˆæˆè§£è€¦ã€‚</li>
<li>å¼•å…¥å›¾åƒæ¡ä»¶æ¨¡æ¿å˜å½¢ç½‘ç»œï¼Œä»ç¬¬ä¸€ä¸ªæœªæŠ•å½±çº¹ç†ä¼°è®¡äººä½“æ¨¡æ¿çš„å˜å½¢ã€‚</li>
<li>æ›´æ–°åçš„å‡ ä½•ç”¨äºæ›´å‡†ç¡®çš„çº¹ç†äºŒæ¬¡æœªæŠ•å½±ï¼Œå‡å°‘ä¼ªå½±ï¼Œæé«˜ä¸è¾“å…¥è§†å›¾çš„å¯¹é½ã€‚</li>
<li>æ–¹æ³•æœ‰åˆ©äºæé«˜å¯¹ç²¾ç»†çº§åˆ«å‡ ä½•å’Œå¤–è§‚çš„å­¦ä¹ ï¼Œæ˜¾è‘—è¶…è¶Šå…¶ä»–å…ˆè¿›æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13183">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-037b745bb00439c9890156f1477dfe5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cf6880842700fa6bffabbf3ec9df53a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8f8700c8e2b70bbf1e2e9a237cf709c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f32fa519ffcb32d35443bdb2e79defc6.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GAF-Gaussian-Avatar-Reconstruction-from-Monocular-Videos-via-Multi-view-Diffusion"><a href="#GAF-Gaussian-Avatar-Reconstruction-from-Monocular-Videos-via-Multi-view-Diffusion" class="headerlink" title="GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view   Diffusion"></a>GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view   Diffusion</h2><p><strong>Authors:Jiapeng Tang, Davide Davoli, Tobias Kirschstein, Liam Schoneveld, Matthias Niessner</strong></p>
<p>We propose a novel approach for reconstructing animatable 3D Gaussian avatars from monocular videos captured by commodity devices like smartphones. Photorealistic 3D head avatar reconstruction from such recordings is challenging due to limited observations, which leaves unobserved regions under-constrained and can lead to artifacts in novel views. To address this problem, we introduce a multi-view head diffusion model, leveraging its priors to fill in missing regions and ensure view consistency in Gaussian splatting renderings. To enable precise viewpoint control, we use normal maps rendered from FLAME-based head reconstruction, which provides pixel-aligned inductive biases. We also condition the diffusion model on VAE features extracted from the input image to preserve facial identity and appearance details. For Gaussian avatar reconstruction, we distill multi-view diffusion priors by using iteratively denoised images as pseudo-ground truths, effectively mitigating over-saturation issues. To further improve photorealism, we apply latent upsampling priors to refine the denoised latent before decoding it into an image. We evaluate our method on the NeRSemble dataset, showing that GAF outperforms previous state-of-the-art methods in novel view synthesis. Furthermore, we demonstrate higher-fidelity avatar reconstructions from monocular videos captured on commodity devices. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥ä»æ™®é€šè®¾å¤‡ï¼ˆå¦‚æ™ºèƒ½æ‰‹æœºï¼‰æ‹æ‘„çš„å•ç›®è§†é¢‘ä¸­é‡å»ºå¯åŠ¨ç”»çš„3Dé«˜æ–¯åŒ–èº«ã€‚ä»è¿™ç§å½•åˆ¶ä¸­é‡å»ºé€¼çœŸçš„3Då¤´éƒ¨åŒ–èº«æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºè§‚å¯Ÿæœ‰é™ï¼Œè¿™ä½¿å¾—æœªè§‚å¯Ÿåˆ°çš„åŒºåŸŸçº¦æŸä¸è¶³ï¼Œå¯èƒ½å¯¼è‡´æ–°è§†è§’å‡ºç°ä¼ªå½±ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤šè§†è§’å¤´éƒ¨æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨å…ˆéªŒçŸ¥è¯†æ¥å¡«å……ç¼ºå¤±åŒºåŸŸï¼Œå¹¶ç¡®ä¿åœ¨é«˜æ–¯å¹³é“ºæ¸²æŸ“ä¸­çš„è§†è§’ä¸€è‡´æ€§ã€‚ä¸ºäº†å®ç°ç²¾ç¡®çš„è§‚ç‚¹æ§åˆ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºFLAMEçš„å¤´éƒ¨é‡å»ºæ¸²æŸ“çš„æ³•çº¿å›¾ï¼Œè¿™æä¾›äº†åƒç´ å¯¹é½çš„å½’çº³åè§ã€‚æˆ‘ä»¬è¿˜æ ¹æ®ä»è¾“å…¥å›¾åƒä¸­æå–çš„VAEç‰¹å¾å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œä»¥ä¿ç•™é¢éƒ¨èº«ä»½å’Œå¤–è§‚ç»†èŠ‚ã€‚å¯¹äºé«˜æ–¯åŒ–èº«é‡å»ºï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨è¿­ä»£å»å™ªå›¾åƒä½œä¸ºä¼ªçœŸå®å€¼æ¥æç‚¼å¤šè§†è§’æ‰©æ•£å…ˆéªŒï¼Œæœ‰æ•ˆåœ°å‡è½»è¿‡é¥±å’Œé—®é¢˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜é€¼çœŸåº¦ï¼Œæˆ‘ä»¬åº”ç”¨æ½œåœ¨ä¸Šé‡‡æ ·å…ˆéªŒæ¥ç²¾ç»†åŒ–å»å™ªæ½œåœ¨ç ï¼Œç„¶åå†å°†å…¶è§£ç ä¸ºå›¾åƒã€‚æˆ‘ä»¬åœ¨NeRSembleæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç»“æœè¡¨æ˜GAFåœ¨æ–°å‹è§†è§’åˆæˆæ–¹é¢ä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†ä»æ™®é€šè®¾å¤‡æ‹æ‘„çš„å•ç›®è§†é¢‘ä¸­è¿›è¡Œçš„é«˜ä¿çœŸåŒ–èº«é‡å»ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10209v2">PDF</a> Paper Video: <a target="_blank" rel="noopener" href="https://youtu.be/QuIYTljvhyg">https://youtu.be/QuIYTljvhyg</a> Project Page:   <a target="_blank" rel="noopener" href="https://tangjiapeng.github.io/projects/GAF">https://tangjiapeng.github.io/projects/GAF</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ¨ç”»åŒ–ä¸‰ç»´é«˜æ–¯åŒ–èº«é‡å»ºæ–¹æ³•ï¼Œå¯ä»å•ç›®è§†é¢‘é‡å»ºé€¼çœŸçš„ä¸‰ç»´å¤´éƒ¨åŒ–èº«ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤šè§†è§’å¤´éƒ¨æ‰©æ•£æ¨¡å‹å¡«å……ç¼ºå¤±åŒºåŸŸå¹¶ä¼˜åŒ–æ¸²æŸ“çš„è§†ç‚¹å’Œç»†èŠ‚è´¨é‡ï¼Œæé«˜äº†é«˜è´¨é‡åˆæˆçš„é€¼çœŸåº¦å’Œæ•ˆæœã€‚å€ŸåŠ©ç”±åŸºäºFLAMEçš„å¤´éƒ¨é‡å»ºæ¸²æŸ“å¾—åˆ°çš„æ³•çº¿å›¾ï¼Œå®ç°äº†ç²¾ç¡®çš„è§†ç‚¹æ§åˆ¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡æå–è¾“å…¥å›¾åƒçš„VAEç‰¹å¾è¿›è¡Œè®­ç»ƒæ¡ä»¶ï¼Œä»¥ä¿è¯é¢éƒ¨èº«ä»½å’Œå¤–è§‚ç»†èŠ‚çš„ä¿ç•™ã€‚åœ¨é«˜æ–¯åŒ–èº«é‡å»ºä¸­é‡‡ç”¨å»å™ªå›¾åƒè¿­ä»£ä½œä¸ºä¼ªçœŸå®å€¼ï¼Œæœ‰æ•ˆè§£å†³äº†è¿‡åº¦é¥±å’Œé—®é¢˜ã€‚é€šè¿‡æ½œåœ¨ä¸Šé‡‡æ ·å…ˆéªŒå¯¹å»å™ªæ½œåœ¨è¿›è¡Œç²¾ç‚¼ï¼Œè¿›ä¸€æ­¥æé«˜äº†å›¾åƒçš„å…‰ç…§è´¨é‡å’Œçº¹ç†ç»†èŠ‚ã€‚ç»è¿‡åœ¨NeRSembleæ•°æ®é›†ä¸Šçš„è¯„ä¼°ï¼Œè¯æ˜äº†GAFåœ¨åˆæˆæ–°è§†è§’ä¸‹çš„æ€§èƒ½ä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„é‡å»ºæ–¹æ³•ã€‚æœ¬æ–‡æˆåŠŸåœ°å®ç°äº†ä½¿ç”¨æ™®é€šè®¾å¤‡æ•è·çš„å•ç›®è§†é¢‘ç”Ÿæˆé«˜ä¿çœŸåº¦çš„ä¸‰ç»´å¤´éƒ¨åŒ–èº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ¨ç”»åŒ–ä¸‰ç»´é«˜æ–¯åŒ–èº«é‡å»ºæ–¹æ³•ã€‚</li>
<li>é€šè¿‡å¼•å…¥å¤šè§†è§’å¤´éƒ¨æ‰©æ•£æ¨¡å‹ï¼Œè§£å†³å› ç¼ºä¹è§‚å¯Ÿè€Œå¯¼è‡´çš„ä¸è¶³å’Œè§†è§‰ç¼ºé™·é—®é¢˜ã€‚</li>
<li>åˆ©ç”¨FLAMEç”Ÿæˆçš„æ³•çº¿å›¾è¿›è¡Œè§†ç‚¹æ§åˆ¶ï¼Œå¢å¼ºäº†è§†è§‰æ•ˆæœã€‚</li>
<li>åˆ©ç”¨è¾“å…¥å›¾åƒçš„VAEç‰¹å¾ä½œä¸ºè®­ç»ƒæ¡ä»¶ï¼Œä¿ç•™äº†é¢éƒ¨èº«ä»½å’Œå¤–è§‚ç»†èŠ‚ã€‚</li>
<li>é€šè¿‡è¿­ä»£å»å™ªå›¾åƒä½œä¸ºä¼ªçœŸå®å€¼ï¼Œè§£å†³äº†è¿‡åº¦é¥±å’Œé—®é¢˜ã€‚</li>
<li>é€šè¿‡æ½œåœ¨ä¸Šé‡‡æ ·å…ˆéªŒæé«˜å›¾åƒçš„å…‰ç…§è´¨é‡å’Œçº¹ç†ç»†èŠ‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10209">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a84f7e9e47425e042b2c5497db496304.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60f0fc2007b008c3ee32c93478fbd1cf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e6f4cbd72dfce29c3660a4214a132a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2fe1ac51560723367b066f9d3c914b58.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Ref-GS-Directional-Factorization-for-2D-Gaussian-Splatting"><a href="#Ref-GS-Directional-Factorization-for-2D-Gaussian-Splatting" class="headerlink" title="Ref-GS: Directional Factorization for 2D Gaussian Splatting"></a>Ref-GS: Directional Factorization for 2D Gaussian Splatting</h2><p><strong>Authors:Youjia Zhang, Anpei Chen, Yumin Wan, Zikai Song, Junqing Yu, Yawei Luo, Wei Yang</strong></p>
<p>In this paper, we introduce Ref-GS, a novel approach for directional light factorization in 2D Gaussian splatting, which enables photorealistic view-dependent appearance rendering and precise geometry recovery. Ref-GS builds upon the deferred rendering of Gaussian splatting and applies directional encoding to the deferred-rendered surface, effectively reducing the ambiguity between orientation and viewing angle. Next, we introduce a spherical Mip-grid to capture varying levels of surface roughness, enabling roughness-aware Gaussian shading. Additionally, we propose a simple yet efficient geometry-lighting factorization that connects geometry and lighting via the vector outer product, significantly reducing renderer overhead when integrating volumetric attributes. Our method achieves superior photorealistic rendering for a range of open-world scenes while also accurately recovering geometry. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºRef-GSçš„æ–°å‹æ–¹æ³•ï¼Œç”¨äºåœ¨äºŒç»´é«˜æ–¯æ··æŸ“ä¸­è¿›è¡Œæ–¹å‘æ€§å…‰ç…§åˆ†è§£ï¼Œä»è€Œå®ç°ä¸è§†å›¾ç›¸å…³çš„é€¼çœŸå¤–è§‚æ¸²æŸ“å’Œç²¾ç¡®å‡ ä½•æ¢å¤ã€‚Ref-GSåŸºäºé«˜æ–¯æ··æŸ“çš„å»¶è¿Ÿæ¸²æŸ“ï¼Œå¯¹å»¶è¿Ÿæ¸²æŸ“è¡¨é¢åº”ç”¨æ–¹å‘ç¼–ç ï¼Œæœ‰æ•ˆå‡å°‘äº†æ–¹å‘å’Œè§†è§’ä¹‹é—´çš„æ­§ä¹‰ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªçƒå½¢Mipç½‘æ ¼æ¥æ•æ‰ä¸åŒçº§åˆ«çš„è¡¨é¢ç²—ç³™åº¦ï¼Œä»è€Œå®ç°ç²—ç³™åº¦æ„ŸçŸ¥çš„é«˜æ–¯ç€è‰²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•é«˜æ•ˆçš„åœ°å½¢-å…‰ç…§åˆ†è§£æ–¹æ³•ï¼Œé€šè¿‡å‘é‡å¤–ç§¯å°†åœ°å½¢å’Œå…‰ç…§è¿æ¥èµ·æ¥ï¼Œåœ¨é›†æˆä½“ç§¯å±æ€§æ—¶å¤§å¤§é™ä½äº†æ¸²æŸ“å™¨å¼€é”€ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸ºä¸€ç³»åˆ—å¼€æ”¾ä¸–ç•Œåœºæ™¯å®ç°é€¼çœŸçš„æ¸²æŸ“çš„åŒæ—¶ï¼Œè¿˜èƒ½å‡†ç¡®åœ°æ¢å¤åœ°å½¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.00905v2">PDF</a> CVPR 2025. Project page: <a target="_blank" rel="noopener" href="https://ref-gs.github.io/">https://ref-gs.github.io/</a></p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†Ref-GSæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºäºŒç»´é«˜æ–¯å¹³é“ºä¸­çš„æ–¹å‘å…‰å› å­åŒ–çš„æ–°æ–¹æ³•ï¼Œå¯å®ç°ä¸è§†å›¾ç›¸å…³çš„é€¼çœŸå¤–è§‚æ¸²æŸ“å’Œç²¾ç¡®å‡ ä½•æ¢å¤ã€‚Ref-GSåŸºäºé«˜æ–¯å¹³é“ºçš„å»¶è¿Ÿæ¸²æŸ“ï¼Œå¹¶å°†æ–¹å‘ç¼–ç åº”ç”¨äºå»¶è¿Ÿæ¸²æŸ“çš„è¡¨é¢ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†æ–¹å‘å’Œè§‚çœ‹è§’åº¦ä¹‹é—´çš„æ­§ä¹‰ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†çƒå½¢Mipç½‘æ ¼æ¥æ•æ‰ä¸åŒçº§åˆ«çš„è¡¨é¢ç²—ç³™åº¦ï¼Œå®ç°äº†ç²—ç³™åº¦æ„ŸçŸ¥çš„é«˜æ–¯ç€è‰²ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§ç®€å•è€Œé«˜æ•ˆçš„åœ°å½¢å…‰ç…§å› å­åŒ–æ–¹æ³•ï¼Œé€šè¿‡å‘é‡å¤–ç§¯è¿æ¥åœ°å½¢å’Œå…‰ç…§ï¼Œå¤§å¤§å‡å°‘äº†é›†æˆä½“ç§¯å±æ€§æ—¶çš„æ¸²æŸ“å™¨å¼€é”€ã€‚è¯¥æ–¹æ³•ä¸ºå¼€æ”¾ä¸–ç•Œåœºæ™¯å®ç°äº†é€¼çœŸçš„æ¸²æŸ“ï¼Œå¹¶å‡†ç¡®æ¢å¤äº†åœ°å½¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Ref-GSæ–¹æ³•æ˜¯ä¸€ç§ç”¨äºäºŒç»´é«˜æ–¯å¹³é“ºä¸­çš„æ–¹å‘å…‰å› å­åŒ–æ–°æŠ€æœ¯ã€‚</li>
<li>Ref-GSå®ç°äº†ä¸è§†å›¾ç›¸å…³çš„é€¼çœŸå¤–è§‚æ¸²æŸ“å’Œç²¾ç¡®å‡ ä½•æ¢å¤ã€‚</li>
<li>è¯¥æ–¹æ³•åŸºäºé«˜æ–¯å¹³é“ºçš„å»¶è¿Ÿæ¸²æŸ“ï¼Œåˆ©ç”¨æ–¹å‘ç¼–ç å‡å°‘æ–¹å‘å’Œè§‚çœ‹è§’åº¦çš„æ­§ä¹‰ã€‚</li>
<li>å¼•å…¥äº†çƒå½¢Mipç½‘æ ¼æ¥æ•æ‰ä¸åŒçº§åˆ«çš„è¡¨é¢ç²—ç³™åº¦ï¼Œå®ç°ç²—ç³™åº¦æ„ŸçŸ¥çš„é«˜æ–¯ç€è‰²ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç®€å•è€Œé«˜æ•ˆçš„åœ°å½¢å…‰ç…§å› å­åŒ–æ–¹æ³•ï¼Œè¿æ¥åœ°å½¢å’Œå…‰ç…§ã€‚</li>
<li>è¯¥æ–¹æ³•å¤§å¤§å‡å°‘äº†é›†æˆä½“ç§¯å±æ€§æ—¶çš„æ¸²æŸ“å™¨å¼€é”€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.00905">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a7b5229a3fb283eecd2877c5e6874876.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8183a5ada2a1797b00983b3f21884e94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-695e9245e4ab5036db4e8e703afa0d93.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-74b5269cea02c6efe7948c0f48e51ce6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b076ee594809142b18aa32647aed386.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Reconstructing-Satellites-in-3D-from-Amateur-Telescope-Images"><a href="#Reconstructing-Satellites-in-3D-from-Amateur-Telescope-Images" class="headerlink" title="Reconstructing Satellites in 3D from Amateur Telescope Images"></a>Reconstructing Satellites in 3D from Amateur Telescope Images</h2><p><strong>Authors:Zhiming Chang, Boyang Liu, Yifei Xia, Youming Guo, Boxin Shi, He Sun</strong></p>
<p>Monitoring space objects is crucial for space situational awareness, yet reconstructing 3D satellite models from ground-based telescope images is challenging due to atmospheric turbulence, long observation distances, limited viewpoints, and low signal-to-noise ratios. In this paper, we propose a novel computational imaging framework that overcomes these obstacles by integrating a hybrid image pre-processing pipeline with a joint pose estimation and 3D reconstruction module based on controlled Gaussian Splatting (GS) and Branch-and-Bound (BnB) search. We validate our approach on both synthetic satellite datasets and on-sky observations of Chinaâ€™s Tiangong Space Station and the International Space Station, achieving robust 3D reconstructions of low-Earth orbit satellites from ground-based data. Quantitative evaluations using SSIM, PSNR, LPIPS, and Chamfer Distance demonstrate that our method outperforms state-of-the-art NeRF-based approaches, and ablation studies confirm the critical role of each component. Our framework enables high-fidelity 3D satellite monitoring from Earth, offering a cost-effective alternative for space situational awareness. Project page: <a target="_blank" rel="noopener" href="https://ai4scientificimaging.org/ReconstructingSatellites">https://ai4scientificimaging.org/ReconstructingSatellites</a> </p>
<blockquote>
<p>å¯¹ç©ºé—´ç›®æ ‡è¿›è¡Œç›‘æµ‹å¯¹äºç©ºé—´æ€åŠ¿æ„ŸçŸ¥è‡³å…³é‡è¦ï¼Œç„¶è€Œï¼Œä»åœ°é¢æœ›è¿œé•œå›¾åƒé‡å»º3Då«æ˜Ÿæ¨¡å‹æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œé¢ä¸´ç€å¤§æ°”æ‰°åŠ¨ã€é•¿è§‚æµ‹è·ç¦»ã€è§‚æµ‹è§†è§’æœ‰é™å’Œä¿¡å™ªæ¯”ä½ç­‰é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è®¡ç®—æˆåƒæ¡†æ¶ï¼Œé€šè¿‡èåˆæ··åˆå›¾åƒé¢„å¤„ç†ç®¡é“ä¸åŸºäºå—æ§çš„é«˜æ–¯æ¶‚æ–‘ï¼ˆGSï¼‰å’Œåˆ†å½¢ç•Œå®šï¼ˆBnBï¼‰æœç´¢çš„è”åˆå§¿æ€ä¼°è®¡å’Œ3Dé‡å»ºæ¨¡å—ï¼Œå…‹æœäº†è¿™äº›éšœç¢ã€‚æˆ‘ä»¬é€šè¿‡å¯¹åˆæˆå«æ˜Ÿæ•°æ®é›†å’Œä¸­å›½å¤©å®«ç©ºé—´ç«™ä»¥åŠå›½é™…ç©ºé—´ç«™çš„å¤©æ–‡è§‚æµ‹è¿›è¡Œäº†éªŒè¯ï¼Œå®ç°äº†ä»åœ°é¢æ•°æ®å¯¹ä½åœ°çƒè½¨é“å«æ˜Ÿçš„ç¨³å¥3Dé‡å»ºã€‚ä½¿ç”¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰ã€å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€å±€éƒ¨æ„ŸçŸ¥å›¾åƒç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰å’ŒChamferè·ç¦»è¿›è¡Œçš„å®šé‡è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€æ–°çš„åŸºäºNeRFçš„æ–¹æ³•ï¼Œæ¶ˆèç ”ç©¶è¯å®äº†æ¯ä¸ªç»„ä»¶çš„å…³é”®ä½œç”¨ã€‚æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿå®ç°ä»åœ°çƒè¿›è¡Œçš„é«˜ä¿çœŸ3Då«æ˜Ÿç›‘æµ‹ï¼Œä¸ºç©ºé—´æ€åŠ¿æ„ŸçŸ¥æä¾›äº†ç»æµé«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://ai4scientificimaging.org/ReconstructingSatellites">ç½‘ç«™é“¾æ¥</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.18394v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„è®¡ç®—æˆåƒæ¡†æ¶ï¼Œé€šè¿‡æ•´åˆæ··åˆå›¾åƒé¢„å¤„ç†ç®¡é“ä¸åŸºäºå—æ§é«˜æ–¯Splattingå’Œåˆ†æ”¯å®šç•Œæœç´¢çš„è”åˆå§¿æ€ä¼°è®¡å’Œ3Dé‡å»ºæ¨¡å—ï¼Œå…‹æœäº†å¤§æ°”æ‰°åŠ¨ã€é•¿è§‚æµ‹è·ç¦»ã€æœ‰é™è§‚æµ‹è§†è§’ä»¥åŠä½ä¿¡å™ªæ¯”ç­‰é—®é¢˜ï¼Œå®ç°äº†å¯¹ä½è½¨é“å«æ˜Ÿçš„ç¨³å¥3Dé‡å»ºã€‚è¯¥æ–¹æ³•å·²åœ¨åˆæˆå«æ˜Ÿæ•°æ®é›†å’Œä¸­å›½å¤©å®«ç©ºé—´ç«™åŠå›½é™…ç©ºé—´ç«™çš„æ˜Ÿç©ºè§‚æµ‹ä¸Šå¾—åˆ°éªŒè¯ï¼Œè¡¨ç°å‡ºä¼˜äºç°æœ‰NeRFæ–¹æ³•çš„æ•ˆæœã€‚æ­¤æ¡†æ¶ä¸ºä»åœ°çƒè¿›è¡Œçš„é«˜ä¿çœŸå«æ˜Ÿç›‘æµ‹æä¾›äº†æˆæœ¬æ•ˆç›Šé«˜çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ–‡ä¸­å¼ºè°ƒäº†ç›‘æµ‹å¤ªç©ºç‰©ä½“å¯¹äºå¤ªç©ºæ€åŠ¿æ„ŸçŸ¥çš„é‡è¦æ€§ã€‚</li>
<li>é‡å»º3Då«æ˜Ÿæ¨¡å‹ä»åœ°é¢æœ›è¿œé•œå›¾åƒæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå­˜åœ¨å¤šä¸ªéš¾ç‚¹ï¼Œå¦‚å¤§æ°”æ‰°åŠ¨ã€è§‚æµ‹è·ç¦»ç­‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹è®¡ç®—æˆåƒæ¡†æ¶ï¼Œæ•´åˆäº†å›¾åƒé¢„å¤„ç†ç®¡é“å’Œ3Dé‡å»ºæ¨¡å—ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨å—æ§é«˜æ–¯Splattingå’Œåˆ†æ”¯å®šç•Œæœç´¢æŠ€æœ¯ï¼Œå®ç°äº†ç¨³å¥çš„3Då«æ˜Ÿé‡å»ºã€‚</li>
<li>åœ¨åˆæˆå«æ˜Ÿæ•°æ®é›†åŠå®é™…æ˜Ÿç©ºè§‚æµ‹ä¸­éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ä¸ç°æœ‰NeRFæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæ›´å¥½çš„æ•ˆæœã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.18394">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b103f21c0848ff49da5a47ea311a4ff4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a11b0ee8fe6b8187fe0a7781fb4272ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05fa33db2c1d15642dc495b4336468e9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97123eb78e3a48e07c13c6f9a8a02a64.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="SplatMesh-Interactive-3D-Segmentation-and-Editing-Using-Mesh-Based-Gaussian-Splatting"><a href="#SplatMesh-Interactive-3D-Segmentation-and-Editing-Using-Mesh-Based-Gaussian-Splatting" class="headerlink" title="SplatMesh: Interactive 3D Segmentation and Editing Using Mesh-Based   Gaussian Splatting"></a>SplatMesh: Interactive 3D Segmentation and Editing Using Mesh-Based   Gaussian Splatting</h2><p><strong>Authors:Kaichen Zhou, Lanqing Hong, Xinhai Chang, Yingji Zhong, Enze Xie, Hao Dong, Zhihao Li, Yongxin Yang, Zhenguo Li, Wei Zhang</strong></p>
<p>A key challenge in fine-grained 3D-based interactive editing is the absence of an efficient representation that balances diverse modifications with high-quality view synthesis under a given memory constraint. While 3D meshes provide robustness for various modifications, they often yield lower-quality view synthesis compared to 3D Gaussian Splatting, which, in turn, suffers from instability during extensive editing. A straightforward combination of these two representations results in suboptimal performance and fails to meet memory constraints. In this paper, we introduce SplatMesh, a novel fine-grained interactive 3D segmentation and editing algorithm that integrates 3D Gaussian Splat with a precomputed mesh and could adjust the memory request based on the requirement. Specifically, given a mesh, \method simplifies it while considering both color and shape, ensuring it meets memory constraints. Then, SplatMesh aligns Gaussian splats with the simplified mesh by treating each triangle as a new reference point. By segmenting and editing the simplified mesh, we can effectively edit the Gaussian splats as well, which will lead to extensive experiments on real and synthetic datasets, coupled with illustrative visual examples, highlighting the superiority of our approach in terms of representation quality and editing performance. Code of our paper can be found here: <a target="_blank" rel="noopener" href="https://github.com/kaichen-z/SplatMesh">https://github.com/kaichen-z/SplatMesh</a>. </p>
<blockquote>
<p>åœ¨åŸºäºç²¾ç»†ç²’åº¦çš„3Däº¤äº’å¼ç¼–è¾‘ä¸­ï¼Œä¸»è¦æŒ‘æˆ˜åœ¨äºç¼ºä¹ä¸€ç§æœ‰æ•ˆçš„è¡¨ç¤ºæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ç»™å®šçš„å†…å­˜çº¦æŸä¸‹å¹³è¡¡å¤šç§ä¿®æ”¹ä¸é«˜è´¨é‡è§†å›¾åˆæˆã€‚è™½ç„¶3Dç½‘æ ¼å¯¹å„ç§ä¿®æ”¹æä¾›äº†ç¨³å¥æ€§ï¼Œä½†å®ƒä»¬é€šå¸¸äº§ç”Ÿçš„è§†å›¾åˆæˆè´¨é‡è¾ƒä½ï¼Œä¸3Dé«˜æ–¯å¹³é“ºç›¸æ¯”å°¤å…¶å¦‚æ­¤ï¼Œè€Œåè€…åœ¨å¤§é‡ç¼–è¾‘æ—¶åˆä¼šå‡ºç°ä¸ç¨³å®šã€‚è¿™ä¸¤ç§è¡¨ç¤ºçš„ç›´æ¥ç»“åˆä¼šå¯¼è‡´æ€§èƒ½ä¸ä½³ï¼Œæ— æ³•æ»¡è¶³å†…å­˜çº¦æŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SplatMeshï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ç²¾ç»†ç²’åº¦äº¤äº’å¼3Dåˆ†å‰²å’Œç¼–è¾‘ç®—æ³•ï¼Œå®ƒç»“åˆäº†3Dé«˜æ–¯å¹³é“ºå’Œé¢„è®¡ç®—ç½‘æ ¼ï¼Œå¹¶å¯ä»¥æ ¹æ®éœ€æ±‚è°ƒæ•´å†…å­˜è¯·æ±‚ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªç½‘æ ¼ï¼Œè¯¥æ–¹æ³•åœ¨è€ƒè™‘é¢œè‰²å’Œå½¢çŠ¶çš„åŒæ—¶å¯¹å…¶è¿›è¡Œç®€åŒ–ï¼Œç¡®ä¿å…¶æ»¡è¶³å†…å­˜çº¦æŸã€‚ç„¶åï¼ŒSplatMeshé€šè¿‡å°†æ¯ä¸ªä¸‰è§’å½¢è§†ä¸ºæ–°çš„å‚è€ƒç‚¹ï¼Œå°†é«˜æ–¯å¹³é“ºä¸ç®€åŒ–çš„ç½‘æ ¼å¯¹é½ã€‚é€šè¿‡åˆ†å‰²å’Œç¼–è¾‘ç®€åŒ–çš„ç½‘æ ¼ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°ç¼–è¾‘é«˜æ–¯å¹³é“ºï¼Œè¿™å°†å¯¼è‡´åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œå¤§é‡å®éªŒï¼ŒåŒæ—¶é…ä»¥è¯´æ˜æ€§çš„è§†è§‰ç¤ºä¾‹ï¼Œçªå‡ºæˆ‘ä»¬åœ¨è¡¨ç¤ºè´¨é‡å’Œç¼–è¾‘æ€§èƒ½æ–¹é¢çš„æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬çš„è®ºæ–‡ä»£ç å¯ä»¥åœ¨æ­¤æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/kaichen-z/SplatMesh">https://github.com/kaichen-z/SplatMesh</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.15856v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SplatMeshï¼Œä¸€ç§æ–°å‹çš„åŸºäºç²¾ç»†äº¤äº’çš„3Dåˆ†å‰²å’Œç¼–è¾‘ç®—æ³•ã€‚è¯¥ç®—æ³•ç»“åˆäº†3Dé«˜æ–¯Splatå’Œé¢„è®¡ç®—ç½‘æ ¼ï¼Œèƒ½å¤Ÿåœ¨å†…å­˜éœ€æ±‚æ–¹é¢è¿›è¡Œè°ƒæ•´ã€‚SplatMeshé€šè¿‡ç®€åŒ–ç½‘æ ¼å¹¶è€ƒè™‘é¢œè‰²å’Œå½¢çŠ¶ï¼Œç¡®ä¿æ»¡è¶³å†…å­˜çº¦æŸï¼Œç„¶åé€šè¿‡å°†é«˜æ–¯splatsä¸ç®€åŒ–ç½‘æ ¼å¯¹é½ï¼Œå®ç°å¯¹ç½‘æ ¼çš„ç²¾ç»†åˆ†å‰²å’Œç¼–è¾‘ï¼Œä»è€Œè¾¾åˆ°é«˜è´¨é‡çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SplatMeshæ˜¯ä¸€ç§æ–°å‹çš„äº¤äº’å¼3Dåˆ†å‰²å’Œç¼–è¾‘ç®—æ³•ï¼Œèåˆäº†3Dé«˜æ–¯Splatå’Œé¢„è®¡ç®—ç½‘æ ¼æŠ€æœ¯ã€‚</li>
<li>è¯¥ç®—æ³•èƒ½å¤Ÿåœ¨å†…å­˜éœ€æ±‚æ–¹é¢è¿›è¡Œè°ƒæ•´ï¼Œä»¥é€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ã€‚</li>
<li>SplatMeshé€šè¿‡ç®€åŒ–ç½‘æ ¼å¹¶è€ƒè™‘é¢œè‰²å’Œå½¢çŠ¶ï¼Œç¡®ä¿æ»¡è¶³å†…å­˜çº¦æŸï¼Œå®ç°é«˜æ•ˆçš„è¡¨ç¤ºã€‚</li>
<li>è¯¥ç®—æ³•é€šè¿‡å°†é«˜æ–¯splatsä¸ç®€åŒ–ç½‘æ ¼å¯¹é½ï¼Œå®ç°å¯¹ç½‘æ ¼çš„ç²¾ç»†åˆ†å‰²å’Œç¼–è¾‘ã€‚</li>
<li>SplatMeshç®—æ³•åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒéªŒè¯ã€‚</li>
<li>å®éªŒç»“æœçªå‡ºäº†SplatMeshåœ¨è¡¨ç¤ºè´¨é‡å’Œç¼–è¾‘æ€§èƒ½æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.15856">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2fbe1e26e37f64ea5859cd344d2aaca9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-379bb1f8212b9cf3fb44578c652d02e9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0a3a4fe69ddb8019fdd095847992db06.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-16/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-16/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-16/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-8255d31c849d39aab17844f4b62711d8.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-16  LL-Gaussian Low-Light Scene Reconstruction and Enhancement via Gaussian   Splatting for Novel View Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-16/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2fe1ac51560723367b066f9d3c914b58.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-16  GAF Gaussian Avatar Reconstruction from Monocular Videos via Multi-view   Diffusion
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26633.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
