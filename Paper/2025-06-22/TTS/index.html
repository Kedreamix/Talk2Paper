<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-22  TTSOps A Closed-Loop Corpus Optimization Framework for Training   Multi-Speaker TTS Models from Dark Data">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ae5ea89989805d02f0cf79d2c2aa9f32.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    39 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-22-æ›´æ–°"><a href="#2025-06-22-æ›´æ–°" class="headerlink" title="2025-06-22 æ›´æ–°"></a>2025-06-22 æ›´æ–°</h1><h2 id="TTSOps-A-Closed-Loop-Corpus-Optimization-Framework-for-Training-Multi-Speaker-TTS-Models-from-Dark-Data"><a href="#TTSOps-A-Closed-Loop-Corpus-Optimization-Framework-for-Training-Multi-Speaker-TTS-Models-from-Dark-Data" class="headerlink" title="TTSOps: A Closed-Loop Corpus Optimization Framework for Training   Multi-Speaker TTS Models from Dark Data"></a>TTSOps: A Closed-Loop Corpus Optimization Framework for Training   Multi-Speaker TTS Models from Dark Data</h2><p><strong>Authors:Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki, Hiroshi Saruwatari</strong></p>
<p>This paper presents TTSOps, a fully automated closed-loop framework for constructing multi-speaker text-to-speech (TTS) systems from noisy, uncurated web-scale speech data, often referred to as &#96;&#96;dark data,â€™â€™ such as online videos. Conventional TTS training pipelines require well-curated corpora with high acoustic quality and accurate text-speech alignment, which severely limits scalability, speaker diversity, and real-world applicability. While recent studies have proposed acoustic-quality-based data selection techniques, they often overlook two critical aspects: (1) the inherent robustness of modern TTS models to noise, and (2) the potential contribution of perceptually low-quality yet informative samples. To address these issues, TTSOps introduces a data-centric training pipeline that integrates three core components: (1) automated data collection from dark data sources, (2) utterance-level dynamic selection of data cleansing methods based on training data quality, and (3) evaluation-in-the-loop data selection using automatically predicted mean opinion scores (MOS) to estimate each utteranceâ€™s impact on model performance. Furthermore, TTSOps jointly optimizes the corpus and the TTS model in a closed-loop framework by dynamically adapting both data selection and data cleansing processes to the characteristics of the target TTS model. Extensive experiments on Japanese YouTube data demonstrate that TTSOps outperforms conventional acoustic-quality-based baselines in both the naturalness and speaker diversity of synthesized speech. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†TTSOpsï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨è‡ªåŠ¨çš„é—­ç¯æ¡†æ¶ï¼Œç”¨äºä»å˜ˆæ‚çš„ã€æœªæ•´ç†çš„ç½‘é¡µè§„æ¨¡è¯­éŸ³æ•°æ®ä¸­æ„å»ºå¤šè¯´è¯äººæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿï¼Œè¿™ç§æ•°æ®é€šå¸¸è¢«ç§°ä¸ºâ€œæš—æ•°æ®â€ï¼Œå¦‚åœ¨çº¿è§†é¢‘ã€‚ä¼ ç»Ÿçš„TTSè®­ç»ƒç®¡é“éœ€è¦é«˜è´¨é‡çš„å£°éŸ³å’Œå‡†ç¡®çš„æ–‡æœ¬-è¯­éŸ³å¯¹é½çš„ç²¾å¿ƒæ•´ç†è¯­æ–™åº“ï¼Œè¿™ä¸¥é‡é™åˆ¶äº†å¯æ‰©å±•æ€§ã€è¯´è¯äººå¤šæ ·æ€§å’Œç°å®ä¸–ç•Œçš„é€‚ç”¨æ€§ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶å·²ç»æå‡ºäº†åŸºäºå£°éŸ³è´¨é‡çš„æ•°æ®é€‰æ‹©æŠ€æœ¯ï¼Œä½†ä»–ä»¬å¾€å¾€å¿½ç•¥äº†ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šï¼ˆ1ï¼‰ç°ä»£TTSæ¨¡å‹å¯¹å™ªå£°çš„å›ºæœ‰é²æ£’æ€§ï¼›ï¼ˆ2ï¼‰æ„ŸçŸ¥è´¨é‡è¾ƒä½ä½†ä¿¡æ¯ä¸°å¯Œçš„æ ·æœ¬çš„æ½œåœ¨è´¡çŒ®ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒTTSOpså¼•å…¥äº†ä¸€ä¸ªä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è®­ç»ƒç®¡é“ï¼Œè¯¥ç®¡é“é›†æˆäº†ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šï¼ˆ1ï¼‰ä»æš—æ•°æ®æºè‡ªåŠ¨æ”¶é›†æ•°æ®ï¼Œï¼ˆ2ï¼‰åŸºäºè®­ç»ƒæ•°æ®è´¨é‡çš„è¯­å¥çº§åŠ¨æ€é€‰æ‹©æ•°æ®æ¸…æ´—æ–¹æ³•ï¼Œï¼ˆ3ï¼‰ä½¿ç”¨è‡ªåŠ¨é¢„æµ‹çš„å¹³å‡æ„è§åˆ†æ•°ï¼ˆMOSï¼‰è¿›è¡Œé—­ç¯æ•°æ®é€‰æ‹©ï¼Œä»¥ä¼°è®¡æ¯ä¸ªè¯­å¥å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚æ­¤å¤–ï¼ŒTTSOpsåœ¨ä¸€ä¸ªé—­ç¯æ¡†æ¶ä¸­è”åˆä¼˜åŒ–è¯­æ–™åº“å’ŒTTSæ¨¡å‹ï¼Œé€šè¿‡åŠ¨æ€é€‚åº”æ•°æ®é€‰æ‹©å’Œæ¸…æ´—è¿‡ç¨‹æ¥é€‚åº”ç›®æ ‡TTSæ¨¡å‹çš„ç‰¹å¾ã€‚åœ¨æ—¥è¯­YouTubeæ•°æ®ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTTSOpsåœ¨è‡ªç„¶åº¦å’Œè¯´è¯äººå¤šæ ·æ€§æ–¹é¢è¶…è¶Šäº†åŸºäºä¼ ç»Ÿå£°éŸ³è´¨é‡çš„åŸºå‡†çº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.15614v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†TTSOpsï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨è‡ªåŠ¨çš„é—­ç¯æ¡†æ¶ï¼Œç”¨äºä»å˜ˆæ‚çš„ã€æœªæ•´ç†çš„ç½‘é¡µè§„æ¨¡è¯­éŸ³æ•°æ®ä¸­æ„å»ºå¤šè¯´è¯è€…æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿã€‚è¯¥æ¡†æ¶è§£å†³äº†ä¼ ç»ŸTTSè®­ç»ƒç®¡é“åœ¨å¯æ‰©å±•æ€§ã€è¯´è¯è€…å¤šæ ·æ€§å’Œç°å®ä¸–ç•Œåº”ç”¨æ–¹é¢çš„é™åˆ¶ã€‚TTSOpsé€šè¿‡æ•´åˆè‡ªåŠ¨åŒ–æ•°æ®é‡‡é›†ã€åŸºäºè®­ç»ƒæ•°æ®è´¨é‡çš„åŠ¨æ€é€‰æ‹©æ•°æ®æ¸…æ´—æ–¹æ³•å’ŒåŸºäºè‡ªåŠ¨é¢„æµ‹å¹³å‡æ„è§åˆ†æ•°ï¼ˆMOSï¼‰çš„é—­ç¯æ•°æ®é€‰æ‹©ï¼Œå½¢æˆäº†ä¸€ä¸ªæ•°æ®ä¸­å¿ƒçš„è®­ç»ƒç®¡é“ã€‚æ­¤å¤–ï¼ŒTTSOpsåœ¨ä¸€ä¸ªé—­ç¯æ¡†æ¶ä¸­è”åˆä¼˜åŒ–è¯­æ–™åº“å’ŒTTSæ¨¡å‹ï¼ŒåŠ¨æ€é€‚åº”æ•°æ®é€‰æ‹©å’Œæ¸…æ´—è¿‡ç¨‹ä»¥é€‚åº”ç›®æ ‡TTSæ¨¡å‹çš„ç‰¹æ€§ã€‚åœ¨æ—¥è¯­YouTubeæ•°æ®ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTTSOpsåœ¨è‡ªç„¶æ€§å’Œè¯´è¯è€…å¤šæ ·æ€§æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„åŸºäºå£°éŸ³è´¨é‡çš„åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TTSOpsæ˜¯ä¸€ä¸ªå…¨è‡ªåŠ¨çš„é—­ç¯æ¡†æ¶ï¼Œç”¨äºæ„å»ºå¤šè¯´è¯è€…æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿã€‚</li>
<li>å®ƒè§£å†³äº†ä¼ ç»ŸTTSè®­ç»ƒç®¡é“åœ¨å¯æ‰©å±•æ€§ã€è¯´è¯è€…å¤šæ ·æ€§å’Œç°å®åº”ç”¨æ–¹é¢çš„é™åˆ¶ã€‚</li>
<li>TTSOpsæ•´åˆäº†è‡ªåŠ¨åŒ–æ•°æ®é‡‡é›†ã€åŠ¨æ€é€‰æ‹©æ•°æ®æ¸…æ´—æ–¹æ³•å’ŒåŸºäºè‡ªåŠ¨é¢„æµ‹å¹³å‡æ„è§åˆ†æ•°ï¼ˆMOSï¼‰çš„é—­ç¯æ•°æ®é€‰æ‹©ã€‚</li>
<li>TTSOpsè€ƒè™‘äº†ç°ä»£TTSæ¨¡å‹å¯¹å™ªå£°çš„å›ºæœ‰é²æ£’æ€§å’Œæ„ŸçŸ¥ä½è´¨é‡ä½†ä¿¡æ¯ä¸°å¯Œçš„æ ·æœ¬çš„æ½œåœ¨è´¡çŒ®ã€‚</li>
<li>æ¡†æ¶ä¸­çš„åŠ¨æ€é€‚åº”æœºåˆ¶å…è®¸æ ¹æ®ç›®æ ‡TTSæ¨¡å‹çš„ç‰¹æ€§è°ƒæ•´æ•°æ®é€‰æ‹©å’Œæ¸…æ´—è¿‡ç¨‹ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒTTSOpsåœ¨è‡ªç„¶æ€§å’Œè¯´è¯è€…å¤šæ ·æ€§æ–¹é¢ä¼˜äºåŸºäºå£°éŸ³è´¨é‡çš„ä¼ ç»Ÿæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.15614">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ffdaff99a23d2b2c23d6d014b686ab15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15cbec87c7dc904033ad3a65f63f3908.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-29e5d449514c7229a296f8b1d81186c3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-26c8f96aff7ec9ca38ab135f986fea2c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b7cc192e0a73e16242810fb4cf4be496.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a77f1ec8ea0d9e6981b18326f74f7165.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Investigation-of-Zero-shot-Text-to-Speech-Models-for-Enhancing-Short-Utterance-Speaker-Verification"><a href="#Investigation-of-Zero-shot-Text-to-Speech-Models-for-Enhancing-Short-Utterance-Speaker-Verification" class="headerlink" title="Investigation of Zero-shot Text-to-Speech Models for Enhancing   Short-Utterance Speaker Verification"></a>Investigation of Zero-shot Text-to-Speech Models for Enhancing   Short-Utterance Speaker Verification</h2><p><strong>Authors:Yiyang Zhao, Shuai Wang, Guangzhi Sun, Zehua Chen, Chao Zhang, Mingxing Xu, Thomas Fang Zheng</strong></p>
<p>Short-utterance speaker verification presents significant challenges due to the limited information in brief speech segments, which can undermine accuracy and reliability. Recently, zero-shot text-to-speech (ZS-TTS) systems have made considerable progress in preserving speaker identity. In this study, we explore, for the first time, the use of ZS-TTS systems for test-time data augmentation for speaker verification. We evaluate three state-of-the-art pre-trained ZS-TTS systems, NatureSpeech 3, CosyVoice, and MaskGCT, on the VoxCeleb 1 dataset. Our experimental results show that combining real and synthetic speech samples leads to 10%-16% relative equal error rate (EER) reductions across all durations, with particularly notable improvements for short utterances, all without retraining any existing systems. However, our analysis reveals that longer synthetic speech does not yield the same benefits as longer real speech in reducing EERs. These findings highlight the potential and challenges of using ZS-TTS for test-time speaker verification, offering insights for future research. </p>
<blockquote>
<p>çŸ­æ—¶æ®µè¯­éŸ³è¯´è¯è€…éªŒè¯ç”±äºç®€çŸ­è¯­éŸ³ç‰‡æ®µä¸­çš„ä¿¡æ¯æœ‰é™è€Œé¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œè¿™å¯èƒ½ä¼šæŸå®³å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚æœ€è¿‘ï¼Œé›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆZS-TTSï¼‰ç³»ç»Ÿåœ¨ä¿æŒè¯´è¯è€…èº«ä»½æ–¹é¢å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡æ¢ç´¢äº†ZS-TTSç³»ç»Ÿåœ¨æµ‹è¯•æ—¶é—´æ•°æ®å¢å¼ºï¼ˆtest-time data augmentationï¼‰åœ¨è¯´è¯è€…éªŒè¯ä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬åœ¨VoxCeleb 1æ•°æ®é›†ä¸Šè¯„ä¼°äº†ä¸‰ç§æœ€å…ˆè¿›çš„é¢„è®­ç»ƒZS-TTSç³»ç»Ÿï¼Œåˆ†åˆ«æ˜¯NatureSpeech 3ã€CosyVoiceå’ŒMaskGCTã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆçœŸå®å’Œåˆæˆè¯­éŸ³æ ·æœ¬åœ¨æ‰€æœ‰æ—¶é—´æ®µå†…å¯¼è‡´ç›¸å¯¹ç­‰é”™è¯¯ç‡ï¼ˆEERï¼‰é™ä½äº†10%-16%ï¼Œç‰¹åˆ«æ˜¯å¯¹äºçŸ­æ—¶æ®µè¯­éŸ³ï¼Œè€Œä¸”æ— éœ€å¯¹ä»»ä½•ç°æœ‰ç³»ç»Ÿè¿›è¡Œå†è®­ç»ƒã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œè¾ƒé•¿çš„åˆæˆè¯­éŸ³åœ¨é™ä½EERæ–¹é¢å¹¶ä¸äº§ç”Ÿä¸è¾ƒé•¿çœŸå®è¯­éŸ³ç›¸åŒçš„æ•ˆç›Šã€‚è¿™äº›å‘ç°çªæ˜¾äº†ä½¿ç”¨ZS-TTSè¿›è¡Œæµ‹è¯•æ—¶é—´è¯´è¯è€…éªŒè¯çš„æ½œåŠ›å’ŒæŒ‘æˆ˜ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.14226v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶é¦–æ¬¡æ¢ç´¢äº†ä½¿ç”¨é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆZS-TTSï¼‰ç³»ç»Ÿè¿›è¡Œæµ‹è¯•æ—¶æ•°æ®å¢å¼ºåœ¨è¯´è¯äººéªŒè¯ä¸­çš„åº”ç”¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆçœŸå®å’Œåˆæˆè¯­éŸ³æ ·æœ¬ç›¸å¯¹äºåªç”¨çœŸå®æ ·æœ¬åœ¨çŸ­è¯è¯­ä¸Šçš„ç­‰é”™è¯¯ç‡ï¼ˆEERï¼‰é™ä½äº†10%-16%ï¼Œå¹¶ä¸”ä¸éœ€è¦å¯¹ç°æœ‰ç³»ç»Ÿè¿›è¡Œä»»ä½•é‡æ–°è®­ç»ƒã€‚ä½†åˆ†æè¡¨æ˜ï¼Œåˆæˆè¯­éŸ³ä¸çœŸå®è¯­éŸ³åœ¨é™ä½EERæ–¹é¢çš„æ•ˆæœå¹¶ä¸ç­‰åŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ZS-TTSç³»ç»Ÿåœ¨æµ‹è¯•æ—¶é—´æ•°æ®å¢å¼ºåœ¨è¯´è¯äººéªŒè¯ä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>ç»“åˆçœŸå®å’Œåˆæˆè¯­éŸ³æ ·æœ¬å¯ä»¥æé«˜è¯´è¯äººéªŒè¯çš„å‡†ç¡®æ€§ã€‚</li>
<li>ä½¿ç”¨ZS-TTSç³»ç»Ÿå¯ä»¥åœ¨ä¸é‡æ–°è®­ç»ƒç°æœ‰ç³»ç»Ÿçš„æƒ…å†µä¸‹æé«˜æ€§èƒ½ã€‚</li>
<li>çŸ­ç‰‡æ®µè¯­éŸ³é€šè¿‡æ•°æ®å¢å¼ºå¯è·å¾—æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>è¾ƒé•¿çš„åˆæˆè¯­éŸ³åœ¨é™ä½ç­‰é”™è¯¯ç‡æ–¹é¢ä¸å¦‚è¾ƒé•¿çš„çœŸå®è¯­éŸ³æœ‰æ•ˆã€‚</li>
<li>åœ¨ä½¿ç”¨ZS-TTSç³»ç»Ÿæ—¶å­˜åœ¨æŒ‘æˆ˜å’Œå±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.14226">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bf630bdfad1b39c38b5704284feaf182.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0256bd1c03b59d535cb3b3a488529cf0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47e17273cb8b2824416b560dc49e469e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40c944d44b370ec97fbe32fd18147d94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5785249a9d34d296c0bd728b4543513.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EmoNews-A-Spoken-Dialogue-System-for-Expressive-News-Conversations"><a href="#EmoNews-A-Spoken-Dialogue-System-for-Expressive-News-Conversations" class="headerlink" title="EmoNews: A Spoken Dialogue System for Expressive News Conversations"></a>EmoNews: A Spoken Dialogue System for Expressive News Conversations</h2><p><strong>Authors:Ryuki Matsuura, Shikhar Bharadwaj, Jiarui Liu, Dhatchi Kunde Govindarajan</strong></p>
<p>We develop a task-oriented spoken dialogue system (SDS) that regulates emotional speech based on contextual cues to enable more empathetic news conversations. Despite advancements in emotional text-to-speech (TTS) techniques, task-oriented emotional SDSs remain underexplored due to the compartmentalized nature of SDS and emotional TTS research, as well as the lack of standardized evaluation metrics for social goals. We address these challenges by developing an emotional SDS for news conversations that utilizes a large language model (LLM)-based sentiment analyzer to identify appropriate emotions and PromptTTS to synthesize context-appropriate emotional speech. We also propose subjective evaluation scale for emotional SDSs and judge the emotion regulation performance of the proposed and baseline systems. Experiments showed that our emotional SDS outperformed a baseline system in terms of the emotion regulation and engagement. These results suggest the critical role of speech emotion for more engaging conversations. All our source code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1">https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1</a> </p>
<blockquote>
<p>æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªé¢å‘ä»»åŠ¡çš„å£è¯­å¯¹è¯ç³»ç»Ÿï¼ˆSDSï¼‰ï¼Œè¯¥ç³»ç»ŸåŸºäºä¸Šä¸‹æ–‡çº¿ç´¢è°ƒèŠ‚æƒ…æ„Ÿè¯­éŸ³ï¼Œä»¥å®ç°æ›´å…·åŒç†å¿ƒçš„æ–°é—»å¯¹è¯ã€‚å°½ç®¡æƒ…æ„Ÿæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æŠ€æœ¯å–å¾—äº†è¿›å±•ï¼Œä½†ç”±äºSDSå’Œæƒ…æ„ŸTTSç ”ç©¶çš„åˆ†éš”æ€§è´¨ï¼Œä»¥åŠç¼ºä¹å¯¹ç¤¾ä¼šç›®æ ‡çš„æ ‡å‡†åŒ–è¯„ä¼°æŒ‡æ ‡ï¼Œé¢å‘ä»»åŠ¡çš„æƒ…æ„ŸSDSä»è¢«è¾ƒå°‘æ¢ç´¢ã€‚æˆ‘ä»¬é€šè¿‡å¼€å‘ç”¨äºæ–°é—»å¯¹è¯çš„æƒ…æ„ŸSDSæ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æå™¨æ¥è¯†åˆ«é€‚å½“çš„æƒ…æ„Ÿï¼Œå¹¶åˆ©ç”¨PromptTTSåˆæˆé€‚åˆä¸Šä¸‹æ–‡çš„æƒ…æ„Ÿè¯­éŸ³ã€‚æˆ‘ä»¬è¿˜ä¸ºæƒ…æ„ŸSDSæå‡ºäº†ä¸»è§‚è¯„ä»·å°ºåº¦ï¼Œå¹¶åˆ¤æ–­æ‰€æå‡ºç³»ç»Ÿå’ŒåŸºçº¿ç³»ç»Ÿçš„æƒ…æ„Ÿè°ƒèŠ‚æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æƒ…æ„ŸSDSåœ¨æƒ…æ„Ÿè°ƒèŠ‚å’Œå‚ä¸åº¦æ–¹é¢ä¼˜äºåŸºçº¿ç³»ç»Ÿã€‚è¿™äº›ç»“æœçªæ˜¾äº†è¯­éŸ³æƒ…æ„Ÿå¯¹äºæ›´å¼•äººå…¥èƒœçš„å¯¹è¯çš„å…³é”®ä½œç”¨ã€‚æˆ‘ä»¬çš„æ‰€æœ‰æºä»£ç å‡å·²å¼€æºï¼Œå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds&#x2F;sds1æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.13894v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¼€å‘äº†ä¸€ç§é¢å‘ä»»åŠ¡çš„æƒ…æ„Ÿå¯¹è¯ç³»ç»Ÿï¼ˆSDSï¼‰ï¼Œè¯¥ç³»ç»ŸåŸºäºä¸Šä¸‹æ–‡çº¿ç´¢è°ƒèŠ‚æƒ…æ„Ÿè¯­éŸ³ï¼Œä»¥å®ç°æ›´å…·åŒç†å¿ƒçš„æ–°é—»å¯¹è¯ã€‚é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æƒ…æ„Ÿåˆ†æå™¨è¯†åˆ«é€‚å½“æƒ…æ„Ÿï¼Œå¹¶åˆ©ç”¨PromptTTSåˆæˆç¬¦åˆä¸Šä¸‹æ–‡çš„æƒ…æ„Ÿè¯­éŸ³ã€‚åŒæ—¶ï¼Œæœ¬æ–‡æå‡ºäº†é’ˆå¯¹æƒ…æ„ŸSDSçš„ä¸»è§‚è¯„ä»·å°ºåº¦ï¼Œå¹¶è¯„ä¼°äº†æ‰€æå‡ºç³»ç»Ÿå’ŒåŸºçº¿ç³»ç»Ÿçš„æƒ…æ„Ÿè°ƒèŠ‚æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æƒ…æ„Ÿè°ƒèŠ‚å’Œå‚ä¸åº¦æ–¹é¢ï¼Œæ‰€æå‡ºæƒ…æ„ŸSDSä¼˜äºåŸºçº¿ç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼€å‘äº†ä¸€ç§é¢å‘ä»»åŠ¡çš„æƒ…æ„Ÿå¯¹è¯ç³»ç»Ÿï¼ˆSDSï¼‰ï¼Œèƒ½å¤ŸåŸºäºä¸Šä¸‹æ–‡è°ƒèŠ‚æƒ…æ„Ÿè¯­éŸ³ï¼Œç”¨äºæ–°é—»å¯¹è¯ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æƒ…æ„Ÿåˆ†æå™¨è¯†åˆ«é€‚å½“çš„æƒ…æ„Ÿã€‚</li>
<li>ä½¿ç”¨PromptTTSæŠ€æœ¯åˆæˆä¸ä¸Šä¸‹æ–‡ç›¸é€‚åº”çš„æƒ…æ„Ÿè¯­éŸ³ã€‚</li>
<li>æå‡ºäº†é’ˆå¯¹æƒ…æ„ŸSDSçš„ä¸»è§‚è¯„ä»·å°ºåº¦ã€‚</li>
<li>æ‰€å¼€å‘æƒ…æ„ŸSDSåœ¨æƒ…æ„Ÿè°ƒèŠ‚å’Œå‚ä¸åº¦æ–¹é¢è¡¨ç°å‡ºä¼˜äºåŸºçº¿ç³»ç»Ÿçš„æ€§èƒ½ã€‚</li>
<li>è¯¥ç ”ç©¶æœ‰åŠ©äºå®ç°æ›´å…·åŒç†å¿ƒçš„æ–°é—»å¯¹è¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.13894">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9b32d715486f43bd1f56b213087dfc8c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-205a38672d1f24e498b2e0b817378d1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65cd3b88440a4865fd6b358f852c4c53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1234a218a5bb8cccf85aeed90bcfb37d.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ZipVoice-Fast-and-High-Quality-Zero-Shot-Text-to-Speech-with-Flow-Matching"><a href="#ZipVoice-Fast-and-High-Quality-Zero-Shot-Text-to-Speech-with-Flow-Matching" class="headerlink" title="ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow   Matching"></a>ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow   Matching</h2><p><strong>Authors:Han Zhu, Wei Kang, Zengwei Yao, Liyong Guo, Fangjun Kuang, Zhaoqing Li, Weiji Zhuang, Long Lin, Daniel Povey</strong></p>
<p>Existing large-scale zero-shot text-to-speech (TTS) models deliver high speech quality but suffer from slow inference speeds due to massive parameters. To address this issue, this paper introduces ZipVoice, a high-quality flow-matching-based zero-shot TTS model with a compact model size and fast inference speed. Key designs include: 1) a Zipformer-based flow-matching decoder to maintain adequate modeling capabilities under constrained size; 2) Average upsampling-based initial speech-text alignment and Zipformer-based text encoder to improve speech intelligibility; 3) A flow distillation method to reduce sampling steps and eliminate the inference overhead associated with classifier-free guidance. Experiments on 100k hours multilingual datasets show that ZipVoice matches state-of-the-art models in speech quality, while being 3 times smaller and up to 30 times faster than a DiT-based flow-matching baseline. Codes, model checkpoints and demo samples are publicly available. </p>
<blockquote>
<p>ç°æœ‰çš„å¤§è§„æ¨¡é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹è™½ç„¶èƒ½å¤Ÿæä¾›é«˜è´¨é‡çš„è¯­éŸ³ï¼Œä½†ç”±äºå‚æ•°ä¼—å¤šï¼Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†ZipVoiceï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé«˜è´¨é‡æµåŒ¹é…çš„é›¶æ ·æœ¬TTSæ¨¡å‹ï¼Œå…·æœ‰æ¨¡å‹ä½“ç§¯å°ã€æ¨ç†é€Ÿåº¦å¿«çš„ç‰¹ç‚¹ã€‚ä¸»è¦è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰åŸºäºZipformerçš„æµåŒ¹é…è§£ç å™¨ï¼Œåœ¨å—é™çš„æ¨¡å‹å¤§å°ä¸‹ä¿æŒè¶³å¤Ÿçš„å»ºæ¨¡èƒ½åŠ›ï¼›2ï¼‰åŸºäºå¹³å‡ä¸Šé‡‡æ ·çš„åˆå§‹è¯­éŸ³-æ–‡æœ¬å¯¹é½å’ŒåŸºäºZipformerçš„æ–‡æœ¬ç¼–ç å™¨ï¼Œä»¥æé«˜è¯­éŸ³çš„å¯æ‡‚åº¦ï¼›3ï¼‰æµè’¸é¦æ–¹æ³•ç”¨äºå‡å°‘é‡‡æ ·æ­¥éª¤ï¼Œæ¶ˆé™¤ä¸æ— åˆ†ç±»å™¨å¼•å¯¼ç›¸å…³çš„æ¨ç†å¼€é”€ã€‚åœ¨100kå°æ—¶çš„å¤šè¯­ç§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒZipVoiceåœ¨è¯­éŸ³è´¨é‡æ–¹é¢ä¸æœ€æ–°æ¨¡å‹ç›¸åŒ¹é…ï¼ŒåŒæ—¶æ¯”åŸºäºDiTçš„æµåŒ¹é…åŸºå‡†æ¨¡å‹å°3å€ï¼Œé€Ÿåº¦å¿«è¾¾30å€ã€‚ä»£ç ã€æ¨¡å‹æ£€æŸ¥ç‚¹å’Œæ¼”ç¤ºæ ·æœ¬å·²å…¬å¼€å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.13053v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæµåŒ¹é…çš„é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ZipVoiceï¼Œå…·æœ‰æ¨¡å‹ä½“ç§¯å°ã€æ¨ç†é€Ÿåº¦å¿«çš„ç‰¹ç‚¹ã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥ZipformeræµåŒ¹é…è§£ç å™¨ã€åŸºäºå¹³å‡ä¸Šé‡‡æ ·çš„è¯­éŸ³æ–‡æœ¬å¯¹é½æ–¹æ³•å’Œæµè’¸é¦æŠ€æœ¯ï¼Œå®ç°äº†åœ¨æœ‰é™æ¨¡å‹å¤§å°ä¸‹çš„é«˜è´¨é‡è¯­éŸ³åˆæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒZipVoiceåœ¨è¯­éŸ³è´¨é‡æ–¹é¢ä¸å½“å‰æœ€ä½³æ¨¡å‹ç›¸å½“ï¼Œæ¨¡å‹ä½“ç§¯å‡å°äº†3å€ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†é«˜è¾¾30å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ZipVoiceæ˜¯ä¸€ä¸ªåŸºäºæµåŒ¹é…çš„é›¶æ ·æœ¬TTSæ¨¡å‹ï¼Œè§£å†³äº†ç°æœ‰å¤§è§„æ¨¡æ¨¡å‹å‚æ•°åºå¤§ã€æ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨ZipformeræµåŒ¹é…è§£ç å™¨ï¼Œåœ¨æœ‰é™æ¨¡å‹å¤§å°ä¸‹ä¿æŒè¶³å¤Ÿçš„å»ºæ¨¡èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡åŸºäºå¹³å‡ä¸Šé‡‡æ ·çš„åˆå§‹è¯­éŸ³æ–‡æœ¬å¯¹é½å’ŒZipformeræ–‡æœ¬ç¼–ç å™¨ï¼Œæé«˜äº†è¯­éŸ³æ¸…æ™°åº¦ã€‚</li>
<li>å¼•å…¥æµè’¸é¦æŠ€æœ¯ï¼Œå‡å°‘é‡‡æ ·æ­¥éª¤ï¼Œæ¶ˆé™¤ä¸æ— åˆ†ç±»å¼•å¯¼ç›¸å…³çš„æ¨ç†å¼€é”€ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒZipVoiceåœ¨è¯­éŸ³è´¨é‡æ–¹é¢ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“ã€‚</li>
<li>ZipVoiceæ¨¡å‹ä½“ç§¯è¾ƒå°ï¼Œä»…ä¸ºå…¶ä»–æ¨¡å‹çš„3å€å¤§å°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.13053">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-699d4c4c638cfdab17d01c02eb4616fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b95442658d63b75a0261323235370b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4781955976ebd17ab6bf8e7b661543bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60581c5031091ac95e4d7fb0783be078.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a3ba3339606bea8eb72c2185f0f49e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-685098491ef52c668f41a230b28ae69c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-684363c637d82741c6c5d19470eab31e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4fd4ce1327c075b254a339d25ecef6d4.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="StreamMel-Real-Time-Zero-shot-Text-to-Speech-via-Interleaved-Continuous-Autoregressive-Modeling"><a href="#StreamMel-Real-Time-Zero-shot-Text-to-Speech-via-Interleaved-Continuous-Autoregressive-Modeling" class="headerlink" title="StreamMel: Real-Time Zero-shot Text-to-Speech via Interleaved Continuous   Autoregressive Modeling"></a>StreamMel: Real-Time Zero-shot Text-to-Speech via Interleaved Continuous   Autoregressive Modeling</h2><p><strong>Authors:Hui Wang, Yifan Yang, Shujie Liu, Jinyu Li, Lingwei Meng, Yanqing Liu, Jiaming Zhou, Haoqin Sun, Yan Lu, Yong Qin</strong></p>
<p>Recent advances in zero-shot text-to-speech (TTS) synthesis have achieved high-quality speech generation for unseen speakers, but most systems remain unsuitable for real-time applications because of their offline design. Current streaming TTS paradigms often rely on multi-stage pipelines and discrete representations, leading to increased computational cost and suboptimal system performance. In this work, we propose StreamMel, a pioneering single-stage streaming TTS framework that models continuous mel-spectrograms. By interleaving text tokens with acoustic frames, StreamMel enables low-latency, autoregressive synthesis while preserving high speaker similarity and naturalness. Experiments on LibriSpeech demonstrate that StreamMel outperforms existing streaming TTS baselines in both quality and latency. It even achieves performance comparable to offline systems while supporting efficient real-time generation, showcasing broad prospects for integration with real-time speech large language models. Audio samples are available at: <a target="_blank" rel="noopener" href="https://aka.ms/StreamMel">https://aka.ms/StreamMel</a>. </p>
<blockquote>
<p>è¿‘æœŸé›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆæŠ€æœ¯çš„è¿›å±•ä¸ºæœªè§è¿‡çš„è¯´è¯è€…å®ç°äº†é«˜è´¨é‡è¯­éŸ³ç”Ÿæˆï¼Œä½†å¤§å¤šæ•°ç³»ç»Ÿç”±äºå…¶ç¦»çº¿è®¾è®¡ä»ä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚å½“å‰çš„æµå¼TTSèŒƒå¼é€šå¸¸ä¾èµ–äºå¤šé˜¶æ®µç®¡é“å’Œç¦»æ•£è¡¨ç¤ºï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ å’Œç³»ç»Ÿæ€§èƒ½ä¸ä½³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†StreamMelï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€åˆ›æ€§çš„å•é˜¶æ®µæµå¼TTSæ¡†æ¶ï¼Œç”¨äºå¯¹è¿ç»­çš„æ¢…å°”é¢‘è°±è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡æ–‡æœ¬æ ‡è®°ä¸å£°å­¦å¸§çš„äº¤é”™ï¼ŒStreamMelå¯å®ç°ä½å»¶è¿Ÿçš„è‡ªåŠ¨å›å½’åˆæˆï¼ŒåŒæ—¶ä¿æŒé«˜è¯´è¯è€…ç›¸ä¼¼æ€§å’Œè‡ªç„¶åº¦ã€‚åœ¨LibriSpeechä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒStreamMelåœ¨è´¨é‡å’Œå»¶è¿Ÿæ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æµå¼TTSåŸºçº¿ã€‚å®ƒç”šè‡³åœ¨æ”¯æŒé«˜æ•ˆå®æ—¶ç”Ÿæˆçš„åŒæ—¶ï¼Œå®ç°äº†ä¸ç¦»çº¿ç³»ç»Ÿç›¸å½“çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†ä¸å®æ—¶è¯­éŸ³å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆçš„å¹¿é˜”å‰æ™¯ã€‚éŸ³é¢‘æ ·æœ¬å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://aka.ms/StreamMel">https://aka.ms/StreamMel</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.12570v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ€æ–°é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆæŠ€æœ¯å·²å®ç°äº†æœªè§è¿‡çš„è¯´è¯è€…çš„é«˜è´¨é‡è¯­éŸ³ç”Ÿæˆï¼Œä½†ç”±äºå…¶ç¦»çº¿è®¾è®¡ï¼Œå¤§å¤šæ•°ç³»ç»Ÿä»ä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚å½“å‰æµå¼TTSèŒƒå¼é€šå¸¸ä¾èµ–äºå¤šé˜¶æ®µç®¡é“å’Œç¦»æ•£è¡¨ç¤ºï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ å’Œç³»ç»Ÿæ€§èƒ½ä¸‹é™ã€‚åœ¨æ­¤ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†StreamMelï¼Œä¸€ä¸ªå¼€åˆ›æ€§çš„å•é˜¶æ®µæµå¼TTSæ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡è¿ç»­æ¢…å°”é¢‘è°±å›¾ã€‚é€šè¿‡å°†æ–‡æœ¬æ ‡è®°ä¸å£°éŸ³å¸§äº¤ç»‡ï¼ŒStreamMelå¯å®ç°ä½å»¶è¿Ÿçš„è‡ªåŠ¨å›å½’åˆæˆï¼ŒåŒæ—¶ä¿æŒé«˜è¯´è¯è€…ç›¸ä¼¼æ€§å’Œè‡ªç„¶åº¦ã€‚åœ¨LibriSpeechä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒStreamMelåœ¨è´¨é‡å’Œå»¶è¿Ÿæ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æµå¼TTSåŸºçº¿ã€‚å®ƒç”šè‡³å®ç°äº†ä¸ç¦»çº¿ç³»ç»Ÿç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ”¯æŒé«˜æ•ˆçš„å®æ—¶ç”Ÿæˆï¼Œæ˜¾ç¤ºå‡ºä¸å®æ—¶è¯­éŸ³å¤§å‹è¯­è¨€æ¨¡å‹ç»“åˆçš„å¹¿é˜”å‰æ™¯ã€‚éŸ³é¢‘æ ·æœ¬å¯åœ¨aka.ms&#x2F;StreamMelå¤„è·å–ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æœ€æ–°é›¶æ ·æœ¬TTSæŠ€æœ¯å®ç°äº†é«˜è´¨é‡è¯­éŸ³ç”Ÿæˆã€‚</li>
<li>å¤§å¤šæ•°TTSç³»ç»Ÿä¸ºç¦»çº¿è®¾è®¡ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚</li>
<li>æµå¼TTSèŒƒå¼é€šå¸¸è®¡ç®—æˆæœ¬é«˜ä¸”æ€§èƒ½ä¸‹é™ã€‚</li>
<li>StreamMelæ˜¯ä¸€ä¸ªå•é˜¶æ®µæµå¼TTSæ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡è¿ç»­æ¢…å°”é¢‘è°±å›¾ã€‚</li>
<li>StreamMelé€šè¿‡äº¤ç»‡æ–‡æœ¬æ ‡è®°å’Œå£°éŸ³å¸§å®ç°ä½å»¶è¿Ÿçš„è‡ªåŠ¨å›å½’åˆæˆã€‚</li>
<li>StreamMelåœ¨è´¨é‡å’Œå»¶è¿Ÿæ–¹é¢ä¼˜äºç°æœ‰æµå¼TTSç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.12570">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a9c0ea554cb063b5946ea387a09f6b0d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d35413b56675cc00fae5866696c7494e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-978c6c3b337eae4abde2b48158212af3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3dc95a38645e362b825208de59505ec.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Phonikud-Hebrew-Grapheme-to-Phoneme-Conversion-for-Real-Time-Text-to-Speech"><a href="#Phonikud-Hebrew-Grapheme-to-Phoneme-Conversion-for-Real-Time-Text-to-Speech" class="headerlink" title="Phonikud: Hebrew Grapheme-to-Phoneme Conversion for Real-Time   Text-to-Speech"></a>Phonikud: Hebrew Grapheme-to-Phoneme Conversion for Real-Time   Text-to-Speech</h2><p><strong>Authors:Yakov Kolani, Maxim Melichov, Cobi Calev, Morris Alper</strong></p>
<p>Real-time text-to-speech (TTS) for Modern Hebrew is challenging due to the languageâ€™s orthographic complexity. Existing solutions ignore crucial phonetic features such as stress that remain underspecified even when vowel marks are added. To address these limitations, we introduce Phonikud, a lightweight, open-source Hebrew grapheme-to-phoneme (G2P) system that outputs fully-specified IPA transcriptions. Our approach adapts an existing diacritization model with lightweight adaptors, incurring negligible additional latency. We also contribute the ILSpeech dataset of transcribed Hebrew speech with IPA annotations, serving as a benchmark for Hebrew G2P and as training data for TTS systems. Our results demonstrate that Phonikud G2P conversion more accurately predicts phonemes from Hebrew text compared to prior methods, and that this enables training of effective real-time Hebrew TTS models with superior speed-accuracy trade-offs. We release our code, data, and models at <a target="_blank" rel="noopener" href="https://phonikud.github.io/">https://phonikud.github.io</a>. </p>
<blockquote>
<p>ç°ä»£å¸Œä¼¯æ¥è¯­çš„å®æ—¶æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºè¯¥è¯­è¨€çš„æ­£å­—æ³•å¤æ‚ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆå¿½ç•¥äº†å…³é”®çš„è¯­éŸ³ç‰¹å¾ï¼Œä¾‹å¦‚å³ä½¿æ·»åŠ å…ƒéŸ³æ ‡è®°ä¹Ÿä»æœªæ˜ç¡®æŒ‡å®šçš„é‡éŸ³ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†Phonikudï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„å¼€æºå¸Œä¼¯æ¥å­—æ¯åˆ°éŸ³ç´ ï¼ˆG2Pï¼‰ç³»ç»Ÿï¼Œå¯ä»¥è¾“å‡ºå®Œå…¨æŒ‡å®šçš„å›½é™…éŸ³æ ‡ï¼ˆIPAï¼‰è½¬å½•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡è½»é‡çº§é€‚é…å™¨é€‚åº”ç°æœ‰çš„æ ‡è°ƒæ¨¡å‹ï¼Œå‡ ä¹ä¸ä¼šå¢åŠ é¢å¤–çš„å»¶è¿Ÿã€‚æˆ‘ä»¬è¿˜æä¾›äº†å¸¦æœ‰å›½é™…éŸ³æ ‡æ³¨é‡Šçš„ILSpeechå¸Œä¼¯æ¥è¯­è¯­éŸ³è½¬å½•æ•°æ®é›†ï¼Œä½œä¸ºå¸Œä¼¯æ¥å­—æ¯åˆ°éŸ³ç´ çš„åŸºå‡†æµ‹è¯•æ•°æ®ï¼Œå¹¶ä¸ºTTSç³»ç»Ÿæä¾›è®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä¸å…ˆå‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPhonikudçš„G2Pè½¬æ¢æ›´èƒ½å‡†ç¡®åœ°ä»å¸Œä¼¯æ¥è¯­æ–‡æœ¬é¢„æµ‹éŸ³ç´ ï¼Œå¹¶ä¸”è¿™èƒ½å¤Ÿè®­ç»ƒå‡ºæœ‰æ•ˆçš„å®æ—¶å¸Œä¼¯æ¥è¯­TTSæ¨¡å‹ï¼Œåœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢è¾¾åˆ°æ›´å¥½çš„æƒè¡¡ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://phonikud.github.ioå‘å¸ƒæˆ‘ä»¬çš„ä»£ç ã€æ•°æ®å’Œæ¨¡å‹./">https://phonikud.github.ioå‘å¸ƒæˆ‘ä»¬çš„ä»£ç ã€æ•°æ®å’Œæ¨¡å‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.12311v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://phonikud.github.io/">https://phonikud.github.io</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>é’ˆå¯¹ç°ä»£å¸Œä¼¯æ¥è¯­çš„å®æ—¶æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰å­˜åœ¨æŒ‘æˆ˜ï¼Œå› å¸Œä¼¯æ¥è¯­çš„å­—å½¢å¤æ‚ï¼Œç°æœ‰è§£å†³æ–¹æ¡ˆå¿½ç•¥äº†é‡è¦çš„è¯­éŸ³ç‰¹å¾ï¼Œå¦‚å³ä½¿æ·»åŠ å…ƒéŸ³ç¬¦å·ä¹Ÿä»ç„¶æœªæŒ‡å®šçš„éŸ³å¼ºã€‚ä¸ºè§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†Phonikudï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„å¼€æºå¸Œä¼¯æ¥å­—æ¯åˆ°éŸ³ç´ ï¼ˆG2Pï¼‰ç³»ç»Ÿï¼Œå¯è¾“å‡ºå®Œå…¨æŒ‡å®šçš„å›½é™…éŸ³æ ‡ï¼ˆIPAï¼‰è½¬å½•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡è½»é‡çº§é€‚é…å™¨é€‚åº”ç°æœ‰çš„æ ‡éŸ³æ¨¡å‹ï¼Œå‡ ä¹ä¸ä¼šå¢åŠ é¢å¤–çš„å»¶è¿Ÿã€‚æˆ‘ä»¬è¿˜è´¡çŒ®äº†å¸¦æœ‰IPAæ³¨é‡Šçš„ILSpeechå¸Œä¼¯æ¥è¯­è¯­éŸ³æ•°æ®é›†ï¼Œä½œä¸ºå¸Œä¼¯æ¥è¯­G2Pçš„åŸºå‡†æµ‹è¯•å’ŒåŸ¹è®­TTSç³»ç»Ÿçš„æ•°æ®ã€‚ç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºå‰äººçš„æ–¹æ³•ï¼ŒPhonikudçš„G2Pè½¬æ¢èƒ½æ›´å‡†ç¡®åœ°ä»å¸Œä¼¯æ¥è¯­æ–‡æœ¬é¢„æµ‹éŸ³ç´ ï¼Œå¹¶ä¸”èƒ½è®­ç»ƒå‡ºæœ‰æ•ˆã€å®æ—¶çš„å¸Œä¼¯æ¥è¯­TTSæ¨¡å‹ï¼Œåœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢éƒ½æœ‰æ›´ä¼˜çš„æƒè¡¡ã€‚æˆ‘ä»¬çš„ä»£ç ã€æ•°æ®å’Œæ¨¡å‹å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://phonikud.github.ioä¸Š./">https://phonikud.github.ioä¸Šã€‚</a></p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å¸Œä¼¯æ¥è¯­å®æ—¶æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰é¢ä¸´æŒ‘æˆ˜ï¼Œå› å­—å½¢å¤æ‚å’Œç¼ºä¹è¶³å¤Ÿçš„è¯­éŸ³ç‰¹å¾ã€‚</li>
<li>Phonikudæ˜¯ä¸€ä¸ªè½»é‡çº§çš„å¸Œä¼¯æ¥è¯­å­—æ¯åˆ°éŸ³ç´ ï¼ˆG2Pï¼‰ç³»ç»Ÿï¼Œèƒ½è¾“å‡ºå®Œå…¨æŒ‡å®šçš„å›½é™…éŸ³æ ‡ï¼ˆIPAï¼‰è½¬å½•ã€‚</li>
<li>Phonikudé€šè¿‡è½»é‡çº§é€‚é…å™¨æ”¹è¿›äº†ç°æœ‰æ ‡éŸ³æ¨¡å‹ï¼Œå‡ ä¹ä¸å¢åŠ é¢å¤–å»¶è¿Ÿã€‚</li>
<li>ILSpeechæ•°æ®é›†ä¸ºå¸Œä¼¯æ¥è¯­G2Pæä¾›äº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶ä½œä¸ºTTSç³»ç»Ÿçš„è®­ç»ƒæ•°æ®ã€‚</li>
<li>Phonikudçš„G2Pè½¬æ¢èƒ½æ›´å‡†ç¡®åœ°é¢„æµ‹å¸Œä¼¯æ¥è¯­ä¸­çš„éŸ³ç´ ã€‚</li>
<li>Phonikudä½¿è®­ç»ƒå®æ—¶å¸Œä¼¯æ¥è¯­TTSæ¨¡å‹æˆä¸ºå¯èƒ½ï¼Œä¸”åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢æœ‰æ›´ä¼˜çš„æƒè¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.12311">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cc74671b3405ea7bc787ebdd349ac9e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6653056e94fb5ed6017a351853ddbb54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04da13a1c1dd7de622c2b50e670a7fe4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f9ddfa45e00791381e8aac15aa28aeb.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="S2ST-Omni-An-Efficient-and-Scalable-Multilingual-Speech-to-Speech-Translation-Framework-via-Seamlessly-Speech-Text-Alignment-and-Streaming-Speech-Decoder"><a href="#S2ST-Omni-An-Efficient-and-Scalable-Multilingual-Speech-to-Speech-Translation-Framework-via-Seamlessly-Speech-Text-Alignment-and-Streaming-Speech-Decoder" class="headerlink" title="S2ST-Omni: An Efficient and Scalable Multilingual Speech-to-Speech   Translation Framework via Seamlessly Speech-Text Alignment and Streaming   Speech Decoder"></a>S2ST-Omni: An Efficient and Scalable Multilingual Speech-to-Speech   Translation Framework via Seamlessly Speech-Text Alignment and Streaming   Speech Decoder</h2><p><strong>Authors:Yu Pan, Yuguang Yang, Yanni Hu, Jianhao Ye, Xiang Zhang, Hongbin Zhou, Lei Ma, Jianjun Zhao</strong></p>
<p>Multilingual speech-to-speech translation (S2ST) aims to directly convert spoken utterances from multiple source languages into fluent and intelligible speech in a target language. Despite recent progress, several critical challenges persist: 1) achieving high-quality and low-latency S2ST remains a significant obstacle; 2) most existing S2ST methods rely heavily on large-scale parallel speech corpora, which are difficult and resource-intensive to obtain. To tackle these challenges, we introduce S2ST-Omni, a novel, efficient, and scalable framework tailored for multilingual speech-to-speech translation. To enable high-quality S2TT while mitigating reliance on large-scale parallel speech corpora, we leverage powerful pretrained models: Whisper for robust audio understanding and Qwen 3.0 for advanced text comprehension. A lightweight speech adapter is introduced to bridge the modality gap between speech and text representations, facilitating effective utilization of pretrained multimodal knowledge. To ensure both translation accuracy and real-time responsiveness, we adopt a streaming speech decoder in the TTS stage, which generates the target speech in an autoregressive manner. Extensive experiments conducted on the CVSS benchmark demonstrate that S2ST-Omni consistently surpasses several state-of-the-art S2ST baselines in translation quality, highlighting its effectiveness and superiority. </p>
<blockquote>
<p>å¤šè¯­ç§è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ï¼ˆS2STï¼‰æ—¨åœ¨å°†å¤šç§æºè¯­è¨€çš„å£å¤´è¡¨è¾¾ç›´æ¥ç¿»è¯‘æˆç›®æ ‡è¯­è¨€ä¸­çš„æµç•…å’Œå¯ç†è§£çš„è¯­éŸ³ã€‚å°½ç®¡æœ€è¿‘æœ‰è¿›å±•ï¼Œä½†ä»å­˜åœ¨å‡ ä¸ªå…³é”®æŒ‘æˆ˜ï¼š1ï¼‰å®ç°é«˜è´¨é‡ã€ä½å»¶è¿Ÿçš„S2STä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§éšœç¢ï¼›2ï¼‰å¤§å¤šæ•°ç°æœ‰çš„S2STæ–¹æ³•ä¸¥é‡ä¾èµ–äºå¤§è§„æ¨¡å¹¶è¡Œè¯­éŸ³è¯­æ–™åº“ï¼Œè¿™äº›è¯­æ–™åº“çš„è·å–å›°éš¾å’Œèµ„æºå¯†é›†ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†S2ST-Omniï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–ã€é«˜æ•ˆã€å¯æ‰©å±•çš„å¤šè¯­ç§è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘æ¡†æ¶ã€‚ä¸ºäº†å®ç°é«˜è´¨é‡çš„S2TTï¼ŒåŒæ—¶å‡å°‘å¤§è§„æ¨¡å¹¶è¡Œè¯­éŸ³è¯­æ–™åº“çš„ä¾èµ–ï¼Œæˆ‘ä»¬åˆ©ç”¨å¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ï¼šWhisperè¿›è¡Œç¨³å¥çš„éŸ³é¢‘ç†è§£ï¼ŒQwen 3.0è¿›è¡Œé«˜çº§æ–‡æœ¬ç†è§£ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„è¯­éŸ³é€‚é…å™¨æ¥å¼¥åˆè¯­éŸ³å’Œæ–‡æœ¬è¡¨ç¤ºä¹‹é—´çš„æ¨¡æ€å·®è·ï¼Œä¿ƒè¿›é¢„è®­ç»ƒå¤šæ¨¡æ€çŸ¥è¯†çš„æœ‰æ•ˆåˆ©ç”¨ã€‚ä¸ºäº†ç¡®ä¿ç¿»è¯‘å‡†ç¡®æ€§å’Œå®æ—¶å“åº”æ€§ï¼Œæˆ‘ä»¬åœ¨TTSé˜¶æ®µé‡‡ç”¨æµå¼è¯­éŸ³è§£ç å™¨ï¼Œä»¥è‡ªå›å½’çš„æ–¹å¼ç”Ÿæˆç›®æ ‡è¯­éŸ³ã€‚åœ¨CVSSåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒS2ST-Omniåœ¨ç¿»è¯‘è´¨é‡ä¸Šå§‹ç»ˆè¶…è¶Šäº†å‡ ç§æœ€å…ˆè¿›çš„S2STåŸºå‡†æµ‹è¯•ï¼Œå‡¸æ˜¾äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.11160v2">PDF</a> Working in progress</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹å¤šè¯­è¨€è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ï¼ˆS2STï¼‰çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„é«˜æ•ˆã€å¯æ‰©å±•çš„æ¡†æ¶S2ST-Omniã€‚è¯¥æ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å®ç°é«˜è´¨é‡S2STï¼Œå‡å°‘å¯¹å¤§è§„æ¨¡å¹³è¡Œè¯­éŸ³è¯­æ–™åº“çš„ä¾èµ–ã€‚é€šè¿‡å¼•å…¥è½»é‡çº§è¯­éŸ³é€‚é…å™¨ï¼Œæœ‰æ•ˆèåˆè¯­éŸ³å’Œæ–‡æœ¬è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€çŸ¥è¯†ã€‚é‡‡ç”¨æµå¼è¯­éŸ³è§£ç å™¨ï¼Œç¡®ä¿ç¿»è¯‘å‡†ç¡®æ€§å’Œå®æ—¶å“åº”æ€§ã€‚åœ¨CVSSåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒS2ST-Omniåœ¨ç¿»è¯‘è´¨é‡ä¸Šè¶…è¶Šäº†å¤šä¸ªæœ€æ–°S2STåŸºçº¿ï¼Œå‡¸æ˜¾å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šè¯­è¨€è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ï¼ˆS2STï¼‰çš„ç›®æ ‡æ˜¯ç›´æ¥å°†å¤šç§æºè¯­è¨€çš„å£è¯­è¡¨è¾¾è½¬åŒ–ä¸ºç›®æ ‡è¯­è¨€çš„æµç•…ã€å¯ç†è§£çš„è¯­éŸ³ã€‚</li>
<li>ç°æœ‰S2STæ–¹æ³•é¢ä¸´é«˜è´¨é‡ã€ä½å»¶è¿Ÿç¿»è¯‘ä»¥åŠä¾èµ–å¤§è§„æ¨¡å¹³è¡Œè¯­éŸ³è¯­æ–™åº“çš„æŒ‘æˆ˜ã€‚</li>
<li>S2ST-Omniæ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å®ç°é«˜è´¨é‡S2STï¼ŒåŒæ—¶å‡å°‘å¤§è§„æ¨¡å¹³è¡Œè¯­éŸ³è¯­æ–™åº“çš„ä¾èµ–ã€‚</li>
<li>å¼•å…¥è½»é‡çº§è¯­éŸ³é€‚é…å™¨ï¼Œæœ‰æ•ˆèåˆè¯­éŸ³å’Œæ–‡æœ¬è¡¨ç¤ºï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€çŸ¥è¯†ã€‚</li>
<li>é‡‡ç”¨æµå¼è¯­éŸ³è§£ç å™¨ï¼Œç¡®ä¿ç¿»è¯‘å‡†ç¡®æ€§å’Œå®æ—¶å“åº”æ€§ã€‚</li>
<li>S2ST-Omniåœ¨CVSSåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°è¶…è¶Šäº†å¤šä¸ªæœ€æ–°S2STåŸºçº¿ï¼Œå‡¸æ˜¾å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</li>
<li>S2ST-Omniæ¡†æ¶å¯¹äºå¤šè¯­è¨€è¯­éŸ³ç¿»è¯‘å…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.11160">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3cc2cddc18be94463e136ebbdd5006dd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bf22ab268bbbf84bd98efbdd95a7184e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62d98ddcbe56060abd1c14891c176992.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="EmoNet-Voice-A-Fine-Grained-Expert-Verified-Benchmark-for-Speech-Emotion-Detection"><a href="#EmoNet-Voice-A-Fine-Grained-Expert-Verified-Benchmark-for-Speech-Emotion-Detection" class="headerlink" title="EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech   Emotion Detection"></a>EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech   Emotion Detection</h2><p><strong>Authors:Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Felix Friedrich, Maurice Kraus, Kourosh Nadi, Huu Nguyen, Kristian Kersting, SÃ¶ren Auer</strong></p>
<p>The advancement of text-to-speech and audio generation models necessitates robust benchmarks for evaluating the emotional understanding capabilities of AI systems. Current speech emotion recognition (SER) datasets often exhibit limitations in emotional granularity, privacy concerns, or reliance on acted portrayals. This paper introduces EmoNet-Voice, a new resource for speech emotion detection, which includes EmoNet-Voice Big, a large-scale pre-training dataset (featuring over 4,500 hours of speech across 11 voices, 40 emotions, and 4 languages), and EmoNet-Voice Bench, a novel benchmark dataset with human expert annotations. EmoNet-Voice is designed to evaluate SER models on a fine-grained spectrum of 40 emotion categories with different levels of intensities. Leveraging state-of-the-art voice generation, we curated synthetic audio snippets simulating actors portraying scenes designed to evoke specific emotions. Crucially, we conducted rigorous validation by psychology experts who assigned perceived intensity labels. This synthetic, privacy-preserving approach allows for the inclusion of sensitive emotional states often absent in existing datasets. Lastly, we introduce Empathic Insight Voice models that set a new standard in speech emotion recognition with high agreement with human experts. Our evaluations across the current model landscape exhibit valuable findings, such as high-arousal emotions like anger being much easier to detect than low-arousal states like concentration. </p>
<blockquote>
<p>æ–‡æœ¬è½¬è¯­éŸ³å’ŒéŸ³é¢‘ç”Ÿæˆæ¨¡å‹çš„è¿›æ­¥ä¸ºè¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æƒ…æ„Ÿç†è§£èƒ½åŠ›æä¾›äº†å¼ºå¤§çš„åŸºå‡†ã€‚ç°æœ‰çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰æ•°æ®é›†åœ¨æƒ…æ„Ÿç²¾ç»†åº¦ã€éšç§æ‹…å¿§æˆ–ä¾èµ–äºè¡¨ç°è¡¨ç°æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†ç”¨äºè¯­éŸ³æƒ…æ„Ÿæ£€æµ‹çš„EmoNet-Voiceæ–°èµ„æºï¼Œå…¶ä¸­åŒ…æ‹¬EmoNet-Voice Bigå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†ï¼ˆåŒ…å«è¶…è¿‡4500å°æ—¶çš„è¯­éŸ³æ•°æ®ï¼Œæ¶µç›–11ç§å£°éŸ³ã€40ç§æƒ…æ„Ÿå’Œå››ç§è¯­è¨€ï¼‰ï¼Œä»¥åŠå¸¦æœ‰ä¸“å®¶æ³¨é‡Šçš„æ–°å‹åŸºå‡†æ•°æ®é›†EmoNet-Voice Benchã€‚EmoNet-Voiceæ—¨åœ¨é’ˆå¯¹ä¸€ä¸ªæƒ…æ„Ÿåˆ†ç±»ç²¾ç»†åº¦é«˜è¾¾40ä¸ªç±»åˆ«çš„å…‰è°±è¯„ä¼°SERæ¨¡å‹ï¼Œä¸åŒçº§åˆ«çš„å¼ºåº¦ã€‚å€ŸåŠ©æœ€å…ˆè¿›çš„è¯­éŸ³ç”ŸæˆæŠ€æœ¯ï¼Œæˆ‘ä»¬ç²¾å¿ƒåˆ¶ä½œäº†æ¨¡æ‹Ÿæ¼”å‘˜æ‰®æ¼”åœºæ™¯åˆæˆéŸ³é¢‘ç‰‡æ®µï¼Œæ—¨åœ¨å”¤èµ·ç‰¹å®šæƒ…æ„Ÿã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡å¿ƒç†å­¦ä¸“å®¶è¿›è¡Œäº†ä¸¥æ ¼éªŒè¯ï¼Œä»–ä»¬èµ‹äºˆäº†æ„ŸçŸ¥å¼ºåº¦æ ‡ç­¾ã€‚è¿™ç§åˆæˆçš„æ–¹æ³•å¯ä¿æŠ¤éšç§ï¼Œå…è®¸åŠ å…¥ç°æœ‰æ•°æ®é›†ä¸­é€šå¸¸ç¼ºå°‘çš„æ•æ„Ÿæƒ…æ„ŸçŠ¶æ€ã€‚æœ€åï¼Œæˆ‘ä»¬æ¨å‡ºäº†Empathic Insight Voiceæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ–¹é¢æ ‘ç«‹äº†æ–°çš„æ ‡å‡†ï¼Œä¸äººç±»ä¸“å®¶çš„è®¤å¯åº¦å¾ˆé«˜ã€‚æˆ‘ä»¬åœ¨å½“å‰æ¨¡å‹æ™¯è§‚ä¸­çš„è¯„ä¼°å±•ç°äº†æœ‰ä»·å€¼çš„å‘ç°ï¼Œä¾‹å¦‚æ„¤æ€’ç­‰é«˜å”¤èµ·æƒ…æ„Ÿæ¯”é›†ä¸­ç­‰ä½å”¤èµ·çŠ¶æ€æ›´å®¹æ˜“æ£€æµ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09827v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„è¯­éŸ³æƒ…æ„Ÿæ£€æµ‹èµ„æºâ€”â€”EmoNet-Voiceã€‚å®ƒåŒ…æ‹¬ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šå¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®é›†EmoNet-Voice Bigå’Œæ–°å‹åŸºå‡†æ•°æ®é›†EmoNet-Voice Benchã€‚EmoNet-Voiceæ—¨åœ¨è¯„ä¼°è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹åœ¨ç²¾ç»†ç²’åº¦çš„æƒ…æ„Ÿç±»åˆ«ä¸Šçš„è¡¨ç°ï¼Œå¹¶å¼•å…¥äº†åˆæˆéŸ³é¢‘ç‰‡æ®µå’Œå¿ƒç†å­¦ä¸“å®¶éªŒè¯çš„æµç¨‹ã€‚å…¶é‡‡ç”¨å…ˆè¿›çš„è¯­éŸ³ç”ŸæˆæŠ€æœ¯ï¼Œæ¨¡æ‹Ÿæ¼”å‘˜åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æƒ…æ„Ÿè¡¨ç°ã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†Empathic Insight Voiceæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ–¹é¢è®¾å®šäº†æ–°çš„æ ‡å‡†ï¼Œå¹¶å±•ç¤ºäº†ä¸€äº›æœ‰è¶£çš„å‘ç°ï¼Œå¦‚æ„¤æ€’ç­‰é«˜å”¤èµ·æƒ…æ„Ÿæ›´å®¹æ˜“è¢«æ£€æµ‹ï¼Œè€Œä½å”¤èµ·çŠ¶æ€å¦‚ä¸“æ³¨åˆ™è¾ƒéš¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹çš„è¯­éŸ³æƒ…æ„Ÿæ£€æµ‹èµ„æºâ€”â€”EmoNet-Voiceï¼Œç”¨äºè¯„ä¼°AIç³»ç»Ÿçš„æƒ…æ„Ÿç†è§£èƒ½åŠ›ã€‚</li>
<li>åŒ…å«äº†å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®é›†EmoNet-Voice Bigï¼Œæ¶µç›–å¤šç§è¯­è¨€ã€æƒ…æ„Ÿå’Œå£°éŸ³ã€‚</li>
<li>æä¾›äº†æ–°å‹åŸºå‡†æ•°æ®é›†EmoNet-Voice Benchï¼Œå…·æœ‰äººç±»ä¸“å®¶æ³¨é‡Šï¼Œç”¨äºç²¾ç»†ç²’åº¦çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ã€‚</li>
<li>é€šè¿‡åˆæˆéŸ³é¢‘ç‰‡æ®µæ¨¡æ‹Ÿæ¼”å‘˜çš„æƒ…æ„Ÿè¡¨ç°ï¼Œè§£å†³äº†ç°æœ‰æ•°æ®é›†åœ¨æƒ…æ„Ÿç²’åº¦ã€éšç§å…³æ³¨æˆ–è¡¨æ¼”ä¾èµ–æ–¹é¢çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†å¿ƒç†å­¦ä¸“å®¶éªŒè¯æµç¨‹ï¼Œç¡®ä¿æƒ…æ„Ÿæ ‡æ³¨çš„å‡†ç¡®æ€§ã€‚</li>
<li>é‡‡ç”¨äº†éšç§ä¿æŠ¤çš„åˆæˆæ–¹æ³•ï¼Œèƒ½å¤ŸåŒ…å«ç°æœ‰æ•°æ®é›†ä¸­å¸¸ç¼ºå¤±çš„æ•æ„Ÿæƒ…æ„ŸçŠ¶æ€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09827">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5826b7a29f41fe24f9d3145cda5eeda7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-89e5c3e69192ee6e28a9481fc91b6d1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f3ad4742d3f56ecf7b1adf9445f1db9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ead12f776165c52d3bd1fc04d82aeaba.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="LEP3-A-High-Luminosity-e-e-Higgs-and-ElectroweakFactory-in-the-LHC-Tunnel"><a href="#LEP3-A-High-Luminosity-e-e-Higgs-and-ElectroweakFactory-in-the-LHC-Tunnel" class="headerlink" title="LEP3: A High-Luminosity e+e- Higgs and ElectroweakFactory in the LHC   Tunnel"></a>LEP3: A High-Luminosity e+e- Higgs and ElectroweakFactory in the LHC   Tunnel</h2><p><strong>Authors:C. Anastopoulos, R. Assmann, A. Ball, O. Bruning, O. Buchmueller, T. Camporesi, P. Collier, J Dainton, G. Davies, J. R. Ellis, B. Goddard, L. Gouskos, M. Klute, M. Koratzinos, G. Landsberg, K. Long, L. Malgeri, F. Maltoni, F. Moortgat, C. Mariotti, S. Myers, J. A. Osborne, M. Pierini, D. R. Tovey, D. Treille, T. S. Virdee, N. Wardle, M. Zanetti</strong></p>
<p>As stated in the 2019 European Strategy for Particle Physics (ESPP), it is of the utmost importance that the HL-LHC upgrade of the accelerator and the experiments be successfully completed in a timely manner. All necessary efforts should be devoted to achieving this goal. We also recall two of the principal recommendations of the 2019 ESPP for future accelerator initiatives, namely that 1) An electron-positron Higgs factory is the highest priority for the next collider (Rec. c). 2) Europe, together with its international partners, should investigate the technical and financial feasibility of a future hadron collider at CERN with a centre-of-mass energy of at least 100 TeV and with an electron-positron Higgs and electroweak factory as a possible first stage (Rec. e). A major objective in particle physics is always to operate an accelerator that allows a leap of an order of magnitude in the constituent centre-of-mass energy with respect to the previous one. We support FCC-ee and FCC-hh as the preferred option for CERN future, as it addresses both of the above recommendations.   The guidance for the 2025 ESPP requests, in addition to the preferred option, the inclusion of &#96;&#96;prioritised alternatives to be pursued if the chosen preferred option turns out not to be feasible or competitiveâ€™â€™. Proposed alternatives to the preferred FCC option include linear, muon colliders and LHeC accelerators. In response to this request we propose reusing the existing LHC tunnel for an electron-positron collider, called LEP3, as a back-up alternative if the FCC cannot proceed. LEP3 leverages much of the R&amp;D conducted for FCC-ee, offers high-precision studies of Z, W, and Higgs bosons below the tt threshold, and offers potential physics performance comparable or superior to other fallback options at a lower cost while supporting continued R&amp;D towards a next-generation energy frontier machine. </p>
<blockquote>
<p>å¦‚2019å¹´æ¬§æ´²ç²’å­ç‰©ç†ç­–ç•¥ï¼ˆESPPï¼‰æ‰€è¿°ï¼ŒåŠæ—¶æˆåŠŸå®ŒæˆHL-LHCåŠ é€Ÿå™¨åŠå®éªŒçš„å‡çº§è‡³å…³é‡è¦ã€‚æˆ‘ä»¬åº”è¯¥ä»˜å‡ºä¸€åˆ‡åŠªåŠ›æ¥å®ç°è¿™ä¸ªç›®æ ‡ã€‚æˆ‘ä»¬è¿˜å›é¡¾äº†2019å¹´ESPPå…³äºæœªæ¥åŠ é€Ÿå™¨å€¡è®®çš„ä¸¤ä¸ªä¸»è¦å»ºè®®ï¼Œå³ï¼š1) ç”µå­æ­£ç”µå­å¸Œæ ¼æ–¯å·¥å‚æ˜¯ä¸‹ä¸€ä¸ªå¯¹æ’æœºçš„é¦–è¦é€‰æ‹©ï¼ˆå»ºè®®cï¼‰ã€‚2) æ¬§æ´²åº”ä¸å…¶å›½é™…åˆä½œä¼™ä¼´å…±åŒç ”ç©¶åœ¨CERNå»ºé€ ä¸€ä¸ªè‡³å°‘å…·æœ‰100TeVè´¨å¿ƒèƒ½é‡çš„æœªæ¥å¼ºå­å¯¹æ’æœºçš„æŠ€æœ¯å’Œè´¢åŠ¡å¯è¡Œæ€§ï¼Œå¹¶å°†ç”µå­æ­£ç”µå­å¸Œæ ¼æ–¯å·¥å‚å’Œç”µå¼±å·¥å‚ä½œä¸ºå¯èƒ½çš„ç¬¬ä¸€é˜¶æ®µï¼ˆå»ºè®®eï¼‰ã€‚ç²’å­ç‰©ç†å­¦çš„ä¸€ä¸ªä¸»è¦ç›®æ ‡å§‹ç»ˆæ˜¯è¿è¡Œä¸€ç§åŠ é€Ÿå™¨ï¼Œè¿™ç§åŠ é€Ÿå™¨èƒ½å¤Ÿä½¿è´¨å¿ƒèƒ½é‡ç›¸å¯¹äºå‰ä¸€ä¸ªå®ç°æ•°é‡çº§çš„é£è·ƒã€‚æˆ‘ä»¬æ”¯æŒFCC-eeå’ŒFCC-hhä½œä¸ºCERNæœªæ¥çš„é¦–é€‰æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒæ¶µç›–äº†ä¸Šè¿°ä¸¤ä¸ªå»ºè®®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00541v2">PDF</a> 11 pages, 3 tables</p>
<p><strong>Summary</strong><br>     æ¬§æ´²ç²’å­ç‰©ç†æˆ˜ç•¥å¼ºè°ƒHL-LHCåŠ é€Ÿå™¨åŠå…¶å®éªŒçš„å‡çº§è‡³å…³é‡è¦ï¼Œéœ€åŠæ—¶å®Œæˆã€‚ä¸»è¦æ¨èæœªæ¥åŠ é€Ÿå™¨è®¡åˆ’ä¸ºç”µå­æ­£è´Ÿç²’å­å¸Œæ ¼æ–¯å·¥å‚åŠåœ¨è‡³å°‘ç™¾TeVçº§çš„å¤§å‹å¼ºå­å¯¹æ’æœºä¸Šè¿›è¡Œçš„æŠ€æœ¯å’Œè´¢åŠ¡å¯è¡Œæ€§ç ”ç©¶ã€‚æ”¯æŒFCCä½œä¸ºCERNçš„ä¼˜é€‰æ–¹æ¡ˆã€‚åŒæ—¶è€ƒè™‘å¤‡é€‰æ–¹æ¡ˆï¼Œå¦‚çº¿æ€§åŠ é€Ÿå™¨ã€Î¼å­å¯¹æ’æœºå’ŒLHeCåŠ é€Ÿå™¨ç­‰ã€‚å¹¶æå‡ºè‹¥FCCæ— æ³•å®æ–½åˆ™åˆ©ç”¨ç°æœ‰LHCéš§é“å»ºç«‹LEP3ä½œä¸ºå¤‡ç”¨é€‰é¡¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HL-LHCåŠ é€Ÿå™¨åŠå…¶å®éªŒçš„å‡çº§è‡³å…³é‡è¦ï¼Œéœ€åŠªåŠ›å®Œæˆä»¥è¾¾æˆæœªæ¥ç²’å­ç‰©ç†ç ”ç©¶ç›®æ ‡ã€‚</li>
<li>ç”µå­æ­£è´Ÿç²’å­å¸Œæ ¼æ–¯å·¥å‚æ˜¯æœªæ¥åŠ é€Ÿå™¨çš„é¦–è¦è®¡åˆ’ã€‚</li>
<li>æ¬§æ´²ä¸å…¶å›½é™…ä¼™ä¼´æ­£åœ¨ç ”ç©¶åœ¨CERNå»ºç«‹ä¸€ä¸ªè‡³å°‘ç™¾TeVçº§çš„å¤§å‹å¼ºå­å¯¹æ’æœºçš„æŠ€æœ¯å’Œè´¢åŠ¡å¯è¡Œæ€§ã€‚</li>
<li>FCCè¢«è§†ä½œCERNçš„é¦–é€‰æ–¹æ¡ˆï¼Œå®ƒç»“åˆäº†ä»¥ä¸Šä¸¤é¡¹å»ºè®®çš„ç›®æ ‡ã€‚</li>
<li>æå‡ºäº†æ›¿ä»£æ–¹æ¡ˆå¦‚çº¿æ€§åŠ é€Ÿå™¨ã€Î¼å­å¯¹æ’æœºå’ŒLHeCåŠ é€Ÿå™¨ç­‰ä»¥åº”å¯¹å¯èƒ½çš„ä¸ç¡®å®šæ€§ã€‚</li>
<li>å¦‚æœé¦–é€‰æ–¹æ¡ˆæ— æ³•å®ç°ï¼Œå¯ä»¥è€ƒè™‘åˆ©ç”¨ç°æœ‰çš„LHCéš§é“å»ºç«‹ä¸€ä¸ªç”µå­æ­£è´Ÿç²’å­å¯¹æ’æœºLEP3ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00541">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-65da9c8f38f5ed7455883653392fdc71.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-caaac85e3381ec883503d3682f5a4da2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae5ea89989805d02f0cf79d2c2aa9f32.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="On-the-Feasibility-of-Fully-AI-automated-Vishing-Attacks"><a href="#On-the-Feasibility-of-Fully-AI-automated-Vishing-Attacks" class="headerlink" title="On the Feasibility of Fully AI-automated Vishing Attacks"></a>On the Feasibility of Fully AI-automated Vishing Attacks</h2><p><strong>Authors:JoÃ£o Figueiredo, Afonso Carvalho, Daniel Castro, Daniel GonÃ§alves, Nuno Santos</strong></p>
<p>A vishing attack is a form of social engineering where attackers use phone calls to deceive individuals into disclosing sensitive information, such as personal data, financial information, or security credentials. Attackers exploit the perceived urgency and authenticity of voice communication to manipulate victims, often posing as legitimate entities like banks or tech support. Vishing is a particularly serious threat as it bypasses security controls designed to protect information. In this work, we study the potential for vishing attacks to escalate with the advent of AI. In theory, AI-powered software bots may have the ability to automate these attacks by initiating conversations with potential victims via phone calls and deceiving them into disclosing sensitive information. To validate this thesis, we introduce ViKing, an AI-powered vishing system developed using publicly available AI technology. It relies on a Large Language Model (LLM) as its core cognitive processor to steer conversations with victims, complemented by a pipeline of speech-to-text and text-to-speech modules that facilitate audio-text conversion in phone calls. Through a controlled social experiment involving 240 participants, we discovered that ViKing has successfully persuaded many participants to reveal sensitive information, even those who had been explicitly warned about the risk of vishing campaigns. Interactions with ViKingâ€™s bots were generally considered realistic. From these findings, we conclude that tools like ViKing may already be accessible to potential malicious actors, while also serving as an invaluable resource for cyber awareness programs. </p>
<blockquote>
<p>é’“é±¼æ”»å‡»æ˜¯ä¸€ç§ç¤¾ä¼šå·¥ç¨‹å­¦æ‰‹æ®µï¼Œæ”»å‡»è€…é€šè¿‡æ‹¨æ‰“ç”µè¯æ¬ºéª—ä¸ªäººæ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼Œå¦‚ä¸ªäººæ•°æ®ã€è´¢åŠ¡ä¿¡æ¯æˆ–å®‰å…¨å‡­æ®ã€‚æ”»å‡»è€…åˆ©ç”¨è¯­éŸ³é€šä¿¡çš„ç´§è¿«æ„Ÿå’ŒçœŸå®æ€§æ¥æ“çºµå—å®³è€…ï¼Œç»å¸¸ä¼ªè£…æˆåˆæ³•å®ä½“ï¼Œå¦‚é“¶è¡Œæˆ–æŠ€æœ¯æ”¯æŒã€‚é’“é±¼æ”»å‡»æ˜¯ä¸€ç§ç‰¹åˆ«ä¸¥é‡çš„å¨èƒï¼Œå› ä¸ºå®ƒç»•è¿‡äº†ä¸ºä¿æŠ¤ä¿¡æ¯è€Œè®¾è®¡çš„å®‰å…¨æ§åˆ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†éšç€äººå·¥æ™ºèƒ½çš„å‡ºç°ï¼Œé’“é±¼æ”»å‡»æ¶åŒ–çš„æ½œåŠ›ã€‚ç†è®ºä¸Šï¼Œäººå·¥æ™ºèƒ½è½¯ä»¶æœºå™¨äººæœ‰èƒ½åŠ›é€šè¿‡æ‹¨æ‰“ä¸æ½œåœ¨å—å®³è€…è¿›è¡Œå¯¹è¯çš„ç”µè¯è‡ªåŠ¨æ‰§è¡Œè¿™äº›æ”»å‡»ï¼Œå¹¶æ¬ºéª—ä»–ä»¬æ³„éœ²æ•æ„Ÿä¿¡æ¯ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€è§‚ç‚¹ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä½¿ç”¨å…¬å¼€å¯ç”¨çš„äººå·¥æ™ºèƒ½æŠ€æœ¯å¼€å‘çš„åä¸ºViKingçš„äººå·¥æ™ºèƒ½é’“é±¼ç³»ç»Ÿã€‚å®ƒä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºå…¶æ ¸å¿ƒçš„å¯¹è¯å¤„ç†å™¨æ¥å¼•å¯¼ä¸å—å®³è€…çš„å¯¹è¯ï¼Œè¾…ä»¥è¯­éŸ³åˆ°æ–‡æœ¬å’Œæ–‡æœ¬åˆ°è¯­éŸ³çš„æ¨¡å—ç®¡é“ï¼Œä¾¿äºç”µè¯ä¸­çš„éŸ³é¢‘æ–‡æœ¬è½¬æ¢ã€‚é€šè¿‡ä¸€é¡¹æ¶‰åŠ240åå‚ä¸è€…çš„å—æ§ç¤¾ä¼šå®éªŒï¼Œæˆ‘ä»¬å‘ç°ViKingå·²æˆåŠŸè¯´æœè®¸å¤šå‚ä¸è€…é€éœ²æ•æ„Ÿä¿¡æ¯ï¼Œå³ä½¿é‚£äº›å·²ç»æ˜ç¡®è­¦å‘Šè¿‡é¢ä¸´é’“é±¼æ”»å‡»é£é™©çš„äººã€‚ä¸ViKingæœºå™¨äººçš„äº’åŠ¨é€šå¸¸è¢«è®¤ä¸ºæ˜¯çœŸå®çš„ã€‚æ ¹æ®è¿™äº›å‘ç°ï¼Œæˆ‘ä»¬å¾—å‡ºç»“è®ºï¼šåƒViKingè¿™æ ·çš„å·¥å…·å¯èƒ½å·²ç»è¢«æ½œåœ¨çš„æ¶æ„è¡Œä¸ºè€…æ‰€æŒæ¡ï¼ŒåŒæ—¶ä¹Ÿä¸ºç½‘ç»œå®‰å…¨æ„è¯†è®¡åˆ’æä¾›äº†å®è´µçš„èµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.13793v2">PDF</a> To appear in AsiaCCS 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬æ¢è®¨äº†AIçš„å…´èµ·å¯¹äºç½‘ç»œæ”»å‡»äº§ç”Ÿçš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åŸºäºAIæŠ€æœ¯çš„ç»´å¸Œæ”»å‡»ã€‚æ–‡æœ¬ä¸­è¯¦ç»†ä»‹ç»äº†ç»´å¸Œæ”»å‡»çš„å½¢å¼å’ŒåŸç†ï¼Œä»¥åŠAIå¦‚ä½•è¢«ç”¨äºè‡ªåŠ¨åŒ–æ­¤ç±»æ”»å‡»ã€‚é€šè¿‡å¼•å…¥åä¸ºViKingçš„AIç»´å¸Œç³»ç»Ÿï¼Œå±•ç¤ºäº†AIæŠ€æœ¯åœ¨ç½‘ç»œæ”»å‡»ä¸­çš„åº”ç”¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿçš„ç¡®èƒ½å¤Ÿæ¬ºéª—å‚ä¸è€…å¹¶è·å–æ•æ„Ÿä¿¡æ¯ã€‚è¿™è¡¨æ˜è¿™ç±»å·¥å…·å¯èƒ½ä¼šè¢«æ½œåœ¨çš„ç½‘ç»œçŠ¯ç½ªåˆ†å­æ‰€åˆ©ç”¨ï¼Œå¹¶æˆä¸ºä¸€ç§æå…·å¨èƒçš„ç½‘ç»œæ”»å‡»æ‰‹æ®µã€‚ä½†ä¹Ÿå¯ä»¥å°†å…¶ä½œä¸ºç½‘ç»œå®‰å…¨æ„è¯†åŸ¹è®­çš„èµ„æºã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç»´å¸Œæ”»å‡»æ˜¯ä¸€ç§åˆ©ç”¨ç”µè¯é€šè¯æ¬ºéª—ä¸ªäººä¿¡æ¯çš„ç¤¾äº¤å·¥ç¨‹å½¢å¼ã€‚æ”»å‡»è€…ä¼šä¼ªè£…æˆåˆæ³•å®ä½“ä»¥è·å–ä¸ªäººæ•°æ®ã€è´¢åŠ¡ä¿¡æ¯æˆ–å®‰å…¨å‡­æ®ç­‰æ•æ„Ÿä¿¡æ¯ã€‚è¿™ç§æ”»å‡»æ–¹å¼å¯¹ä¿æŠ¤ä¿¡æ¯çš„ä¼ ç»Ÿå®‰å…¨æªæ–½å…·æœ‰å¼ºå¤§çš„è§„é¿èƒ½åŠ›ã€‚</li>
<li>AIçš„å‘å±•ç»™è¿™äº›æ”»å‡»å¸¦æ¥äº†æ›´å¤§çš„æ½œåŠ›ï¼Œé€šè¿‡ä½¿ç”¨AIè½¯ä»¶æœºå™¨äººå‘èµ·è‡ªåŠ¨åŒ–ç”µè¯å¯¹è¯æ¥å®ç°æ›´é«˜çš„æ”»å‡»æ•ˆç‡ã€‚è€ŒAIæŠ€æœ¯åœ¨æ¨¡æ‹ŸçœŸå®å¯¹è¯æ–¹é¢è¡¨ç°å‡ºè¾ƒé«˜çš„å‡†ç¡®æ€§ï¼Œå¢åŠ äº†æ­¤ç±»æ”»å‡»çš„æ¬ºéª—æ€§ã€‚ä¾‹å¦‚ï¼ŒViKingç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæ ¸å¿ƒè®¤çŸ¥å¤„ç†å™¨æ¥å¼•å¯¼ä¸å—å®³è€…çš„å¯¹è¯ï¼ŒåŒæ—¶é€šè¿‡è¯­éŸ³åˆ°æ–‡æœ¬å’Œæ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å—è¿›è¡ŒéŸ³é¢‘æ–‡æœ¬è½¬æ¢ï¼Œä½¿å…¶ç”µè¯é€šè¯æ›´é€¼çœŸã€‚è¿™ä¸€æŠ€æœ¯è¢«å¹¿æ³›è¿ç”¨å¯èƒ½å¯¼è‡´å®‰å…¨å¨èƒçš„å‡çº§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.13793">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ced65d3ce6435f36a9787756bf32ec87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a4a9c0c2be624e32c7c3997ebdb6729.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-22/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-22/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-22/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4cc5d658d3532f020dd903f92a371c53.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-22  Improving Dialogue Discourse Parsing through Discourse-aware Utterance   Clarification
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-22/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a64112893cb38c03306e6d6cd7e48c88.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-22  Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image   Registration
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26384.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
