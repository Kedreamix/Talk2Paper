<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Interactive">
    <meta name="description" content="Interactive 方向最新论文已更新，请持续关注 Update in 2025-06-22  Improving Dialogue Discourse Parsing through Discourse-aware Utterance   Clarification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Interactive | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4cc5d658d3532f020dd903f92a371c53.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Interactive</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Interactive/">
                                <span class="chip bg-color">Interactive</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                Interactive
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    27 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-06-22-更新"><a href="#2025-06-22-更新" class="headerlink" title="2025-06-22 更新"></a>2025-06-22 更新</h1><h2 id="Improving-Dialogue-Discourse-Parsing-through-Discourse-aware-Utterance-Clarification"><a href="#Improving-Dialogue-Discourse-Parsing-through-Discourse-aware-Utterance-Clarification" class="headerlink" title="Improving Dialogue Discourse Parsing through Discourse-aware Utterance   Clarification"></a>Improving Dialogue Discourse Parsing through Discourse-aware Utterance   Clarification</h2><p><strong>Authors:Yaxin Fan, Peifeng Li, Qiaoming Zhu</strong></p>
<p>Dialogue discourse parsing aims to identify and analyze discourse relations between the utterances within dialogues. However, linguistic features in dialogues, such as omission and idiom, frequently introduce ambiguities that obscure the intended discourse relations, posing significant challenges for parsers. To address this issue, we propose a Discourse-aware Clarification Module (DCM) to enhance the performance of the dialogue discourse parser. DCM employs two distinct reasoning processes: clarification type reasoning and discourse goal reasoning. The former analyzes linguistic features, while the latter distinguishes the intended relation from the ambiguous one. Furthermore, we introduce Contribution-aware Preference Optimization (CPO) to mitigate the risk of erroneous clarifications, thereby reducing cascading errors. CPO enables the parser to assess the contributions of the clarifications from DCM and provide feedback to optimize the DCM, enhancing its adaptability and alignment with the parser’s requirements. Extensive experiments on the STAC and Molweni datasets demonstrate that our approach effectively resolves ambiguities and significantly outperforms the state-of-the-art (SOTA) baselines. </p>
<blockquote>
<p>对话文本解析旨在识别和分析对话中语句之间的文本关系。然而，对话中的语言特征，如省略和习惯用语，经常引入歧义，模糊了预期的文本关系，给解析器带来了重大挑战。为了解决这个问题，我们提出了一种基于文本感知的澄清模块（DCM）来提高对话文本解析器的性能。DCM采用两种不同的推理过程：澄清类型推理和文本目标推理。前者分析语言特征，后者区分预期的文本关系和模糊的文本关系。此外，我们引入了基于贡献的偏好优化（CPO）来降低错误澄清的风险，从而减少级联错误。CPO使解析器能够评估DCM的澄清贡献并提供反馈以优化DCM，提高其适应性和与解析器的要求相匹配。在STAC和Molweni数据集上的大量实验表明，我们的方法有效地解决了歧义问题，并显著优于当前最佳基线模型。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.15081v1">PDF</a> Accepted by ACL2025(main conference)</p>
<p><strong>Summary</strong></p>
<p>对话文本解析旨在识别和解析对话中话语间的语段关系。然而，对话中的语言特征，如省略和习惯用语，经常引入歧义，掩盖了预期的语段关系，给解析器带来重大挑战。为解决此问题，我们提出了一个话语感知澄清模块（DCM）来提高对话文本解析器的性能。DCM采用两种独特的推理过程：澄清类型推理和话语目标推理。前者分析语言特征，后者区分预期关系与模糊关系。此外，我们引入了贡献感知偏好优化（CPO）来降低错误澄清的风险，从而减少级联错误。CPO使解析器能够评估DCM的澄清贡献并提供反馈以优化DCM，提高其适应性并与解析器的需求保持一致。在STAC和Molweni数据集上的广泛实验表明，我们的方法有效地解决了歧义问题，并显著优于现有技术（SOTA）基线。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>对话文本解析的目标是识别和解析对话中的语段关系。</li>
<li>语言特征如省略和习惯用语可能引入歧义，影响语段关系的识别。</li>
<li>话语感知澄清模块（DCM）用于提高对话文本解析性能。</li>
<li>DCM通过澄清类型推理和话语目标推理两种推理过程来工作。</li>
<li>贡献感知偏好优化（CPO）用于降低错误澄清的风险，减少级联错误。</li>
<li>CPO使解析器能够评估DCM的澄清贡献并提供反馈以优化其性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.15081">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-013eed566701598622827a08d60fa6d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93b5fd51358ce75213b2772766cbffaa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb8d3b18f3e8b77ddbcfd1e2766e4d3e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="From-What-to-Respond-to-When-to-Respond-Timely-Response-Generation-for-Open-domain-Dialogue-Agents"><a href="#From-What-to-Respond-to-When-to-Respond-Timely-Response-Generation-for-Open-domain-Dialogue-Agents" class="headerlink" title="From What to Respond to When to Respond: Timely Response Generation for   Open-domain Dialogue Agents"></a>From What to Respond to When to Respond: Timely Response Generation for   Open-domain Dialogue Agents</h2><p><strong>Authors:Seongbo Jang, Minjin Jeon, Jaehoon Lee, Seonghyeon Lee, Dongha Lee, Hwanjo Yu</strong></p>
<p>While research on dialogue response generation has primarily focused on generating coherent responses conditioning on textual context, the critical question of when to respond grounded on the temporal context remains underexplored. To bridge this gap, we propose a novel task called timely dialogue response generation and introduce the TimelyChat benchmark, which evaluates the capabilities of language models to predict appropriate time intervals and generate time-conditioned responses. Additionally, we construct a large-scale training dataset by leveraging unlabeled event knowledge from a temporal commonsense knowledge graph and employing a large language model (LLM) to synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent designed to proactively predict time intervals and generate timely responses that align with those intervals. Experimental results show that Timer outperforms prompting-based LLMs and other fine-tuned baselines in both turn-level and dialogue-level evaluations. We publicly release our data, model, and code. </p>
<blockquote>
<p>对话应答生成的研究主要聚焦于基于文本语境生成连贯的应答，而基于时间语境的应答时机这一关键问题仍未得到充分探索。为了填补这一空白，我们提出了一个名为“及时对话应答生成”的新任务，并引入了TimelyChat基准测试，该测试评估语言模型预测合适的时间间隔和生成时间条件应答的能力。此外，我们利用时间常识知识图谱中的未标注事件知识，采用大型语言模型（LLM）合成了5.5万条事件驱动对话，构建了一个大规模训练数据集。然后，我们训练了Timer对话机器人，该机器人能够主动预测时间间隔并生成与这些间隔相符的及时响应。实验结果表明，Timer在回合级和对话级的评估中都优于基于提示的LLM和其他微调基准测试。我们公开发布了我们的数据、模型和代码。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.14285v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>本文主要研究了对话响应生成中的一个新任务——及时对话响应生成，并为此建立了TimelyChat基准测试平台。该研究旨在评估语言模型预测合适时间间隔和生成时间条件响应的能力。为弥补现有研究的不足，研究者利用时间常识知识图谱的无标签事件知识，通过大型语言模型（LLM）合成55K事件驱动对话，构建大规模训练数据集。实验结果表明，Timer对话代理在回合和对话级别评估中均优于基于提示的LLM和其他微调基线。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出及时对话响应生成的新任务，强调语言模型在预测合适时间间隔和生成与时间相关的响应方面的能力的重要性。</li>
<li>建立TimelyChat基准测试平台，用于评估语言模型在及时对话响应生成方面的性能。</li>
<li>通过利用时间常识知识图谱的无标签事件知识，结合大型语言模型（LLM），合成大规模事件驱动对话训练数据集。</li>
<li>介绍对话代理“Timer”，该代理可预测时间间隔并生成与这些间隔相符的及时响应。</li>
<li>Timer在回合和对话级别的评估中表现出优于基于提示的LLM和其他微调基线的性能。</li>
<li>研究结果填补了现有对话响应生成研究在基于时间上下文方面的不足。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.14285">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-f33c9f82d8d37eddf7571f0bfe3efeb7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-38e08b9391e5ca7bf52baea35b72b8d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15bdccb5d7993e3aea33c7a851ccdec4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-985e365468f2a8eaf92ef5175b7afd2f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EmoNews-A-Spoken-Dialogue-System-for-Expressive-News-Conversations"><a href="#EmoNews-A-Spoken-Dialogue-System-for-Expressive-News-Conversations" class="headerlink" title="EmoNews: A Spoken Dialogue System for Expressive News Conversations"></a>EmoNews: A Spoken Dialogue System for Expressive News Conversations</h2><p><strong>Authors:Ryuki Matsuura, Shikhar Bharadwaj, Jiarui Liu, Dhatchi Kunde Govindarajan</strong></p>
<p>We develop a task-oriented spoken dialogue system (SDS) that regulates emotional speech based on contextual cues to enable more empathetic news conversations. Despite advancements in emotional text-to-speech (TTS) techniques, task-oriented emotional SDSs remain underexplored due to the compartmentalized nature of SDS and emotional TTS research, as well as the lack of standardized evaluation metrics for social goals. We address these challenges by developing an emotional SDS for news conversations that utilizes a large language model (LLM)-based sentiment analyzer to identify appropriate emotions and PromptTTS to synthesize context-appropriate emotional speech. We also propose subjective evaluation scale for emotional SDSs and judge the emotion regulation performance of the proposed and baseline systems. Experiments showed that our emotional SDS outperformed a baseline system in terms of the emotion regulation and engagement. These results suggest the critical role of speech emotion for more engaging conversations. All our source code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1">https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1</a> </p>
<blockquote>
<p>我们开发了一个面向任务的口语对话系统（SDS），该系统基于上下文线索调控情感语音，以实现更具同理心的新闻对话。尽管情感文本到语音（TTS）技术取得了进展，但由于SDS和情绪TTS研究的分隔性质以及缺乏对社会目标的标准化评估指标，面向任务的情感SDS仍然被较少探索。我们通过开发用于新闻对话的情感SDS来解决这些挑战，该系统利用基于大型语言模型（LLM）的情感分析器来识别适当的情感，并使用PromptTTS合成适当的上下文情感语音。我们还为情感SDS提出了主观评价量表，并判断所提出系统和基线系统的情感调节性能。实验表明，我们的情感SDS在情感调节和参与度方面优于基线系统。这些结果突显了语音情感对于更引人入胜的对话的关键作用。我们的所有源代码均已开源，可在[<a target="_blank" rel="noopener" href="https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.13894v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文开发了一种面向任务的对话系统（SDS），该系统基于上下文线索调节情感语音，以实现更具同理心的新闻对话。作者针对当前情绪文本到语音（TTS）技术的挑战，提出了一个情感SDS，该SDS采用基于大型语言模型的情感分析器来识别适当情绪和PromptTTS技术合成适合上下文的情感语音。此外，作者还提出了一种针对情感SDS的主观评价体系，并对所提出的系统进行了情感调节性能评估。实验结果表明，该情感SDS在情感调节和参与度方面优于基线系统。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>开发了一种面向任务的对话系统（SDS），该系统能够基于上下文线索调节情感语音，促进更具同理心的新闻对话。</li>
<li>利用大型语言模型（LLM）的情感分析器识别适当的情绪。</li>
<li>采用PromptTTS技术合成与上下文相适应的情感语音。</li>
<li>提出了一种针对情感SDS的主观评价体系。</li>
<li>实验证明，该情感SDS在情感调节和参与度方面优于基线系统。</li>
<li>开放源代码，便于他人在此基础上进行研究和改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.13894">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9b32d715486f43bd1f56b213087dfc8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-205a38672d1f24e498b2e0b817378d1e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-65cd3b88440a4865fd6b358f852c4c53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1234a218a5bb8cccf85aeed90bcfb37d.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CliniDial-A-Naturally-Occurring-Multimodal-Dialogue-Dataset-for-Team-Reflection-in-Action-During-Clinical-Operation"><a href="#CliniDial-A-Naturally-Occurring-Multimodal-Dialogue-Dataset-for-Team-Reflection-in-Action-During-Clinical-Operation" class="headerlink" title="CliniDial: A Naturally Occurring Multimodal Dialogue Dataset for Team   Reflection in Action During Clinical Operation"></a>CliniDial: A Naturally Occurring Multimodal Dialogue Dataset for Team   Reflection in Action During Clinical Operation</h2><p><strong>Authors:Naihao Deng, Kapotaksha Das, Rada Mihalcea, Vitaliy Popov, Mohamed Abouelenien</strong></p>
<p>In clinical operations, teamwork can be the crucial factor that determines the final outcome. Prior studies have shown that sufficient collaboration is the key factor that determines the outcome of an operation. To understand how the team practices teamwork during the operation, we collected CliniDial from simulations of medical operations. CliniDial includes the audio data and its transcriptions, the simulated physiology signals of the patient manikins, and how the team operates from two camera angles. We annotate behavior codes following an existing framework to understand the teamwork process for CliniDial. We pinpoint three main characteristics of our dataset, including its label imbalances, rich and natural interactions, and multiple modalities, and conduct experiments to test existing LLMs’ capabilities on handling data with these characteristics. Experimental results show that CliniDial poses significant challenges to the existing models, inviting future effort on developing methods that can deal with real-world clinical data. We open-source the codebase at <a target="_blank" rel="noopener" href="https://github.com/MichiganNLP/CliniDial">https://github.com/MichiganNLP/CliniDial</a> </p>
<blockquote>
<p>在临床试验中，团队合作可能是决定最终结果的至关重要的因素。早期的研究已经表明，充分的协作是决定手术结果的关键因素。为了了解团队在手术过程中如何进行团队合作，我们从模拟的医学手术中收集了CliniDial数据。CliniDial包括音频数据和其转录记录、模拟的病人模拟生理信号以及两个相机角度下团队的手术操作过程。我们使用现有框架对行为代码进行标注，以理解CliniDial中的团队合作过程。我们确定了数据集三个主要特点，包括标签不平衡、丰富自然的交互以及多种模态，并进行了实验来测试现有大型语言模型处理这些特点数据的能力。实验结果表明，CliniDial对现有模型构成了重大挑战，需要未来开发能够处理现实世界临床数据的方法。我们在<a target="_blank" rel="noopener" href="https://github.com/MichiganNLP/CliniDial%E4%B8%8A%E5%85%AC%E5%BC%80%E4%BA%86%E4%BB%A3%E7%A0%81%E5%BA%93%E3%80%82">https://github.com/MichiganNLP/CliniDial上公开了代码库。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.12936v1">PDF</a> Accepted to ACL 2025 Findings</p>
<p><strong>Summary</strong></p>
<p>本文介绍了在医疗操作中的团队合作的重要性，并引入了CliniDial数据集，该数据集通过模拟医疗操作收集音频数据及其转录、患者模拟生理信号以及两个角度的摄像数据，以理解团队合作过程。文章强调了数据集的三个主要特点，包括标签不平衡、丰富的自然交互和多种模态，并进行了实验以测试现有大型语言模型处理此类数据的能力。实验结果表明，CliniDial对现有模型构成挑战，并鼓励未来开发能够处理真实临床数据的方法。数据集已在GitHub上开源。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>团队合作在医疗操作中至关重要，可决定最终手术结果。</li>
<li>引入CliniDial数据集，该数据集包含医疗操作中的音频、转录、患者生理信号及团队行为影像数据。</li>
<li>数据集具有三个主要特点：标签不平衡、丰富的自然交互和多种模态。</li>
<li>通过实验发现CliniDial对现有模型构成挑战。</li>
<li>开源数据集以促进对处理真实临床数据方法的研究。</li>
<li>数据集可用于研究和提高医疗团队的合作效率和沟通能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.12936">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1e3932c47e5fe15100af8b904b2a896b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e687f78dda3478f13b79259e8013a7cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-709f5429e71bc59c0a004c61a3f93f7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75c8fbc9206945d0e02d5d838d66fe92.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f48fb69b0ba57c5e69f23702dfe06e86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4cc5d658d3532f020dd903f92a371c53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6761330b7521febef322f366b543bbc9.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Improving-Factuality-for-Dialogue-Response-Generation-via-Graph-Based-Knowledge-Augmentation"><a href="#Improving-Factuality-for-Dialogue-Response-Generation-via-Graph-Based-Knowledge-Augmentation" class="headerlink" title="Improving Factuality for Dialogue Response Generation via Graph-Based   Knowledge Augmentation"></a>Improving Factuality for Dialogue Response Generation via Graph-Based   Knowledge Augmentation</h2><p><strong>Authors:Xiangyan Chen, Yujian Gan, Matthew Purver</strong></p>
<p>Large Language Models (LLMs) succeed in many natural language processing tasks. However, their tendency to hallucinate - generate plausible but inconsistent or factually incorrect text - can cause problems in certain tasks, including response generation in dialogue. To mitigate this issue, knowledge-augmented methods have shown promise in reducing hallucinations. Here, we introduce a novel framework designed to enhance the factuality of dialogue response generation, as well as an approach to evaluate dialogue factual accuracy. Our framework combines a knowledge triple retriever, a dialogue rewrite, and knowledge-enhanced response generation to produce more accurate and grounded dialogue responses. To further evaluate generated responses, we propose a revised fact score that addresses the limitations of existing fact-score methods in dialogue settings, providing a more reliable assessment of factual consistency. We evaluate our methods using different baselines on the OpendialKG and HybriDialogue datasets. Our methods significantly improve factuality compared to other graph knowledge-augmentation baselines, including the state-of-the-art G-retriever. The code will be released on GitHub. </p>
<blockquote>
<p>大型语言模型（LLMs）在许多自然语言处理任务中取得了成功。然而，它们倾向于产生合理但自相矛盾或事实错误的文本，这在某些任务中（包括对对话中的回答生成）可能会引发问题。为了缓解这一问题，知识增强方法在减少幻觉方面显示出希望。在这里，我们介绍了一个旨在提高对话回答生成的事实性的新型框架，以及一种评估对话事实准确性的方法。我们的框架结合了知识三元组检索器、对话重写和知识增强回答生成，以产生更准确、更切实的对话回答。为了对生成的回答进行进一步评估，我们提出了修订的事实得分，解决了现有事实得分方法在对话环境中的局限性，提供了更可靠的现实一致性评估。我们在OpendialKG和HybriDialogue数据集上使用不同的基线评估了我们的方法。我们的方法在事实性方面显著改进了与其他图形知识增强基线的比较，包括最先进的G-检索器。代码将在GitHub上发布。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.12496v1">PDF</a> </p>
<p><strong>Summary</strong><br>大型语言模型在自然语言处理任务中取得了巨大成功，但其产生的文本往往具有幻想性，导致某些任务出现问题，如对话生成响应。为缓解这一问题，知识增强方法显示出减少幻想的潜力。本文介绍了一种旨在提高对话响应生成的事实性的新型框架，以及一种评估对话事实准确性的方法。该框架结合了知识三元组检索器、对话重写和知识增强响应生成，以产生更准确、更实际的对话响应。为了评估生成的响应，我们提出了一种改进的事实得分，该得分解决了现有事实得分方法在对话设置中的局限性，提供更可靠的实质性一致性评估。我们的方法在OpendialKG和HybriDialogue数据集上进行评估，与包括当前先进技术G-retriever在内的其他图形知识增强基线相比，显著提高了事实性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在自然语言处理任务中表现出色，但在对话生成响应方面存在幻想性问题。</li>
<li>知识增强方法有助于减少大型语言模型的幻想问题。</li>
<li>新型框架结合了知识三元组检索器、对话重写和知识增强响应生成，旨在提高对话响应的事实性。</li>
<li>提出了一种改进的对话事实评估方法，以更可靠地评估生成的对话响应的事实一致性。</li>
<li>该方法在OpendialKG和HybriDialogue数据集上进行了评估，显著提高了事实性，优于其他知识增强方法。</li>
<li>该方法将有助于增强对话系统的可靠性，减少由于幻想导致的误解和问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.12496">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-38d0610ba52c6544de8c95e7a8b61a1c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f45fb715835e2b73870d51a823fae23c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3c80a3dc77f1d4c96e43eddefdfb3bb8.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MORTAR-Multi-turn-Metamorphic-Testing-for-LLM-based-Dialogue-Systems"><a href="#MORTAR-Multi-turn-Metamorphic-Testing-for-LLM-based-Dialogue-Systems" class="headerlink" title="MORTAR: Multi-turn Metamorphic Testing for LLM-based Dialogue Systems"></a>MORTAR: Multi-turn Metamorphic Testing for LLM-based Dialogue Systems</h2><p><strong>Authors:Guoxiang Guo, Aldeida Aleti, Neelofar Neelofar, Chakkrit Tantithamthavorn, Yuanyuan Qi, Tsong Yueh Chen</strong></p>
<p>With the widespread application of LLM-based dialogue systems in daily life, quality assurance has become more important than ever. Recent research has successfully introduced methods to identify unexpected behaviour in single-turn testing scenarios. However, multi-turn interaction is the common real-world usage of dialogue systems, yet testing methods for such interactions remain underexplored. This is largely due to the oracle problem in multi-turn testing, which continues to pose a significant challenge for dialogue system developers and researchers. In this paper, we propose MORTAR, a metamorphic multi-turn dialogue testing approach, which mitigates the test oracle problem in testing LLM-based dialogue systems. MORTAR formalises the multi-turn testing for dialogue systems, and automates the generation of question-answer dialogue test cases with multiple dialogue-level perturbations and metamorphic relations (MRs). The automated perturbation-MR matching mechanism allows MORTAR more flexibility and efficiency in metamorphic testing. The proposed approach is fully automated without reliance on potentially biased LLMs as test oracles. In testing six popular LLM-based dialogue systems, MORTAR reaches significantly better effectiveness with over 150% more bugs revealed per test case when compared to the single-turn metamorphic testing baseline. On the quality of bugs, MORTAR reveals higher-quality bugs in terms of diversity, precision and uniqueness. MORTAR is expected to inspire more multi-turn testing approaches without LLM judges, and assist developers to evaluate the dialogue system performance more comprehensively with constrained test resources and budget. </p>
<blockquote>
<p>随着基于LLM的对话系统在日常生活中的应用日益广泛，质量保障变得尤为重要。最近的研究已经成功引入了在单轮测试场景中识别意外行为的方法。然而，多轮交互是对话系统在现实世界中的常见用法，但针对此类交互的测试方法仍然研究不足。这主要是由于多轮测试中的“金标准”问题，它继续给对话系统开发人员和研究人员带来重大挑战。在本文中，我们提出了MORTAR，一种用于测试基于LLM的对话系统的多轮变异测试方法，它减轻了测试金标准问题。MORTAR为对话系统的多轮测试制定了规范，并自动生成具有多个对话级别扰动和变异关系（MRs）的问题答案测试用例。自动化的扰动-MR匹配机制使MORTAR在变异测试中更具灵活性和效率。该方法完全自动化，不依赖于可能带有偏见的LLMs作为测试金标准。在测试六个流行的基于LLM的对话系统时，与单轮变异测试基线相比，MORTAR在有效性方面达到了更高的水平，每个测试用例发现的错误数量增加了超过150％。在错误质量方面，MORTAR在多样性、精确度和唯一性方面揭示了更高质量的错误。预计MORTAR将激发更多不需要LLM法官的多轮测试方法，并帮助开发人员在有限的测试资源和预算下更全面地评估对话系统性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15557v2">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>随着大语言模型（LLM）为基础的对话系统在日常生活中的应用日益广泛，质量保障显得尤为重要。针对单轮测试场景中的意外行为识别方法已经取得进展，但多轮交互作为对话系统在现实生活中的常见用法，其测试方法仍然缺乏研究。这主要是由于多轮测试中的“金标准”问题仍为对话系统开发者与研究人员带来重大挑战。本文提出一种名为MORTAR的变异多轮对话测试方法，该方法旨在缓解测试LLM基础对话系统时的测试金标准问题。MORTAR对对话系统的多轮测试进行了形式化，并自动化生成具有多种对话级别扰动和变异关系（MRs）的问题答案测试用例。自动扰动-MR匹配机制为MORTAR在变异测试中提供了更大的灵活性和效率。该方法完全自动化运行，无需依赖可能存在偏见的LLM作为测试金标准。在对六个流行的LLM基础对话系统进行测试时，与单轮变异测试基线相比，MORTAR在效果上达到了显著的提升，每个测试用例发现的错误数量增加了超过150％。在错误质量方面，MORTAR在多样性、精确度和唯一性方面揭示了更高质量的错误。预计MORTAR将激发更多无需LLM判断的多轮测试方法，并帮助开发者在有限的测试资源和预算下更全面地评估对话系统性能。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>多轮对话测试在对话系统质量保障中至关重要，但相关研究仍然不足。</li>
<li>MORTAR是一种针对LLM基础对话系统的变异多轮测试方法，旨在解决多轮测试中的“金标准”问题。</li>
<li>MORTAR通过自动化生成具有多种对话级别扰动和变异关系的测试用例，提高了测试的灵活性和效率。</li>
<li>MORTAR完全自动化运行，不依赖可能存在偏见的LLM。</li>
<li>对比单轮测试基线，MORTAR在测试中表现出更高的有效性，每个测试用例发现的错误数量增加了超过150％。</li>
<li>MORTAR揭示了更高质量的错误，表现在多样性、精确度和唯一性方面。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15557">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ae88f3a58678ab9f24e039f9b4cd285b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-990f7a5412334b43ef95cb256660321b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6c7b9c57c177ef351ec523224e64aec0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5729ec11879872bb9f25ccff71208444.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="EmoDynamiX-Emotional-Support-Dialogue-Strategy-Prediction-by-Modelling-MiXed-Emotions-and-Discourse-Dynamics"><a href="#EmoDynamiX-Emotional-Support-Dialogue-Strategy-Prediction-by-Modelling-MiXed-Emotions-and-Discourse-Dynamics" class="headerlink" title="EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling   MiXed Emotions and Discourse Dynamics"></a>EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling   MiXed Emotions and Discourse Dynamics</h2><p><strong>Authors:Chenwei Wan, Matthieu Labeau, Chloé Clavel</strong></p>
<p>Designing emotionally intelligent conversational systems to provide comfort and advice to people experiencing distress is a compelling area of research. Recently, with advancements in large language models (LLMs), end-to-end dialogue agents without explicit strategy prediction steps have become prevalent. However, implicit strategy planning lacks transparency, and recent studies show that LLMs’ inherent preference bias towards certain socio-emotional strategies hinders the delivery of high-quality emotional support. To address this challenge, we propose decoupling strategy prediction from language generation, and introduce a novel dialogue strategy prediction framework, EmoDynamiX, which models the discourse dynamics between user fine-grained emotions and system strategies using a heterogeneous graph for better performance and transparency. Experimental results on two ESC datasets show EmoDynamiX outperforms previous state-of-the-art methods with a significant margin (better proficiency and lower preference bias). Our approach also exhibits better transparency by allowing backtracing of decision making. </p>
<blockquote>
<p>设计具有情感智能的对话系统，为经历压力的人提供安慰和建议是一个引人入胜的研究领域。最近，随着大型语言模型（LLM）的进步，无需明确策略预测步骤的端到端对话代理已经变得普遍。然而，隐式策略规划缺乏透明度，最近的研究表明，LLM对某些社会情感策略的固有偏好偏向阻碍了提供高质量的情感支持。为了应对这一挑战，我们提出了将策略预测与语言生成解耦，并引入了一种新型对话策略预测框架EmoDynamiX。该框架使用异构图对用户精细情绪与系统策略之间的对话动态进行建模，以实现更好的性能和透明度。在两个ESC数据集上的实验结果表明，EmoDynamiX以前所未有的优势超越了以前的最先进方法（更高的熟练程度和更低的偏好偏见）。我们的方法还通过允许回溯决策制定而展现出更好的透明度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.08782v5">PDF</a> Accepted to NAACL 2025 main, long paper</p>
<p><strong>Summary</strong></p>
<p>设计具有情感智能的对话系统，为经历困扰的人提供安慰和建议是一个引人入胜的研究领域。随着大型语言模型（LLMs）的进步，端到端的对话代理无需明确的策略预测步骤变得普遍起来。然而，隐式策略规划缺乏透明度，且研究表明LLMs对特定社会情感策略的固有偏好偏向阻碍了高质量情感支持的提供。为解决这一挑战，我们提出了将策略预测与语言生成相分离的方法，并引入了一种新型对话策略预测框架EmoDynamiX。该框架利用异构图对用户精细情绪与系统策略之间的对话动态进行建模，以实现更好的性能和透明度。在两项ESC数据集上的实验结果表明，EmoDynamiX显著优于以前的最先进方法。我们的方法还通过允许回溯决策制定而具有更好的透明度。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>设计情感智能对话系统对于为经历困扰的人提供支持和建议具有重要意义。</li>
<li>大型语言模型（LLMs）的进步使得端到端对话系统的普及成为可能，但隐式策略规划缺乏透明度。</li>
<li>LLMs对社会情感策略的固有偏好可能影响提供高质量情感支持的能力。</li>
<li>提出了一种新的对话策略预测框架EmoDynamiX，旨在解决上述问题。</li>
<li>EmoDynamiX利用异构图对用户精细情绪与系统策略之间的对话动态进行建模，提升性能和透明度。</li>
<li>在两个ESC数据集上的实验显示，EmoDynamiX显著优于其他方法，具有更高的专业能力和更低的偏好偏见。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.08782">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-363b65bbaf2111dc970b2c2701808a66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07b14beb901584594a50e5ff5804f4af.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-22/Interactive/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-22/Interactive/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Interactive/">
                                    <span class="chip bg-color">Interactive</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-22/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-7fc9c25ff5e6004e58af44b81d0d2df3.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2025-06-22  Audio-Visual Driven Compression for Low-Bitrate Talking Head Videos
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-22/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ae5ea89989805d02f0cf79d2c2aa9f32.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-06-22  TTSOps A Closed-Loop Corpus Optimization Framework for Training   Multi-Speaker TTS Models from Dark Data
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">24595.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
