<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-03-11  Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting   Accuracy">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-1aed4888193e304bbf0f01177a2cb2c2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    27 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-11-更新"><a href="#2025-03-11-更新" class="headerlink" title="2025-03-11 更新"></a>2025-03-11 更新</h1><h2 id="Ensemble-Debiasing-Across-Class-and-Sample-Levels-for-Fairer-Prompting-Accuracy"><a href="#Ensemble-Debiasing-Across-Class-and-Sample-Levels-for-Fairer-Prompting-Accuracy" class="headerlink" title="Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting   Accuracy"></a>Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting   Accuracy</h2><p><strong>Authors:Ruixi Lin, Ziqiao Wang, Yang You</strong></p>
<p>Language models are strong few-shot learners and achieve good overall accuracy in text classification tasks, masking the fact that their results suffer from great class accuracy imbalance. We believe that the pursuit of overall accuracy should not come from enriching the strong classes, but from raising up the weak ones. To address the imbalance, we propose a post-hoc nonlinear integer programming based debiasing method that ensembles weight correction and membership correction to enable flexible rectifications of class probabilities at both class and sample levels, enhancing the performance of LLMs directly from their outputs. Evaluations with Llama-2-13B on seven text classification benchmarks show that our approach achieves state-of-the-art overall accuracy gains with balanced class accuracies. The resulted probability correction scheme demonstrates that sample-level corrections are necessary to elevate weak classes. In addition, due to effectively correcting weak classes, our method also brings significant performance gains to Llama-2-70B, especially on a biomedical domain task, demonstrating its effectiveness across both small and large model variants. </p>
<blockquote>
<p>语言模型是强大的少样本学习者，在文本分类任务中总体准确率较高，但存在类别准确率严重失衡的问题。我们认为追求总体准确率不应通过增强强类别来实现，而应通过提升弱类别来实现。为了解决不平衡问题，我们提出了一种基于事后非线性整数规划的去偏方法，通过集成权重修正和成员修正，能够在类和样本级别灵活地校正类概率，直接提升LLM的输出性能。使用Llama-2-13B在七个文本分类基准测试上的评估表明，我们的方法实现了最先进的总体准确率增益，同时类别准确率保持平衡。所得的概率校正方案表明，样本级校正对于提升弱类别是必要的。此外，由于有效地校正了弱类别，我们的方法还为Llama-2-70B带来了显著的性能提升，特别是在生物医学领域任务上，这证明了其在小型和大型模型变体中的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.05157v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>语言模型在少样本学习上表现出色，文本分类任务总体准确度较高，但存在类别准确度失衡的问题。为提高弱类别的性能，提出一种基于非线性整数规划的后期去偏方法，通过权重修正和成员修正来灵活调整类别概率，提高LLM的性能。在Llama-2-13B模型上的七个文本分类基准测试显示，该方法实现了最先进的总体精度增益，平衡了类别精度。概率校正方案表明，样本级别的校正对于提升弱类别是必要的。此外，该方法对Llama-2-70B模型也有显著的性能提升，尤其在生物医学领域任务中表现突出，证明其适用于不同规模的模型。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语言模型在少样本学习上有良好表现，但存在类别准确度失衡问题。</li>
<li>提出一种基于非线性整数规划的后期去偏方法，通过权重和成员修正来解决类别概率失衡问题。</li>
<li>这种方法提高了LLM的性能，特别是在弱类别上。</li>
<li>在多个文本分类基准测试中，该方法实现了最佳的总体精度和平衡类别精度。</li>
<li>概率校正方案表明样本级别的校正对提升弱类别性能至关重要。</li>
<li>该方法适用于不同规模的模型，包括大型语言模型如Llama-2-70B。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.05157">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bd2391f223550a8684b6d39302bf1731.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8b3f97b67e683d6e7bce324cc555a06d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ecd8ca82f1a755c4d7a0a140bbecc274.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Leveraging-Domain-Knowledge-at-Inference-Time-for-LLM-Translation-Retrieval-versus-Generation"><a href="#Leveraging-Domain-Knowledge-at-Inference-Time-for-LLM-Translation-Retrieval-versus-Generation" class="headerlink" title="Leveraging Domain Knowledge at Inference Time for LLM Translation:   Retrieval versus Generation"></a>Leveraging Domain Knowledge at Inference Time for LLM Translation:   Retrieval versus Generation</h2><p><strong>Authors:Bryan Li, Jiaming Luo, Eleftheria Briakou, Colin Cherry</strong></p>
<p>While large language models (LLMs) have been increasingly adopted for machine translation (MT), their performance for specialist domains such as medicine and law remains an open challenge. Prior work has shown that LLMs can be domain-adapted at test-time by retrieving targeted few-shot demonstrations or terminologies for inclusion in the prompt. Meanwhile, for general-purpose LLM MT, recent studies have found some success in generating similarly useful domain knowledge from an LLM itself, prior to translation. Our work studies domain-adapted MT with LLMs through a careful prompting setup, finding that demonstrations consistently outperform terminology, and retrieval consistently outperforms generation. We find that generating demonstrations with weaker models can close the gap with larger model’s zero-shot performance. Given the effectiveness of demonstrations, we perform detailed analyses to understand their value. We find that domain-specificity is particularly important, and that the popular multi-domain benchmark is testing adaptation to a particular writing style more so than to a specific domain. </p>
<blockquote>
<p>虽然大型语言模型（LLM）在机器翻译（MT）中的采用率越来越高，但它们在医学和法律等特定领域的表现仍然是一个挑战。先前的工作已经表明，可以通过在测试时检索有针对性的少量演示或术语来将LLM适应特定领域，并将其包含在提示中。同时，对于通用LLM MT，最近的研究发现，在翻译之前从LLM本身生成同样有用的领域知识是成功的。我们的工作通过精心设计的提示来研究LLM的域适应MT，发现演示始终优于术语，检索始终优于生成。我们发现，使用较弱模型生成演示可以缩小与大型模型的零射击性能差距。考虑到演示的有效性，我们进行详细的分析来理解它们的价值。我们发现领域特异性特别重要，流行的多领域基准测试更多的是测试对特定写作风格的适应，而不是对特定领域的适应。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.05010v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在机器翻译（MT）领域的应用日益广泛，但在医学、法律等专业领域的性能仍面临挑战。本文研究了通过精心设计的提示来进行领域适应的MT，发现演示始终优于术语，检索始终优于生成。利用较弱的模型生成演示可以缩小与大型模型的零样本性能的差距。本文还详细分析了演示的价值，发现领域特异性尤为重要，流行的多领域基准测试更多的是测试对特定写作风格的适应，而非特定领域的适应。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在机器翻译领域的表现逐渐受到重视，尤其在专业领域的表现尤为关键。</li>
<li>通过有针对性的少镜头演示和术语的检索可以实现对模型的领域适应。</li>
<li>演示效果优于术语检索，生成演示能够缩小与大型模型零样本性能的差距。</li>
<li>演示的价值在于其领域特异性，对于特定领域的适应至关重要。</li>
<li>多领域基准测试更多地是测试模型对特定写作风格的适应，而非特定领域的适应。</li>
<li>本文强调了仔细设计提示的重要性，对于提高模型在特定领域的性能至关重要。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.05010">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6f88ff550b5fea54c0c9842757140ada.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-227278085b8822ba9ce549f2a5b0c689.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d33f7c7634c732a25c5af48988d57120.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd48c4ceabe9c522fd47ab14e2be40ec.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Beyond-RAG-Task-Aware-KV-Cache-Compression-for-Comprehensive-Knowledge-Reasoning"><a href="#Beyond-RAG-Task-Aware-KV-Cache-Compression-for-Comprehensive-Knowledge-Reasoning" class="headerlink" title="Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge   Reasoning"></a>Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge   Reasoning</h2><p><strong>Authors:Giulio Corallo, Orion Weller, Fabio Petroni, Paolo Papotti</strong></p>
<p>Incorporating external knowledge in large language models (LLMs) enhances their utility across diverse applications, but existing methods have trade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via similarity search, but key information may fall outside top ranked results. Long-context models can process multiple documents but are computationally expensive and limited by context window size. Inspired by students condensing study material for open-book exams, we propose task-aware key-value (KV) cache compression, which compresses external knowledge in a zero- or few-shot setup. This enables LLMs to reason efficiently over a compacted representation of all relevant information. Experiments show our approach outperforms both RAG and task-agnostic compression methods. On LongBench v2, it improves accuracy by up to 7 absolute points over RAG with a 30x compression rate, while reducing inference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG performs well when sparse evidence suffices, whereas task-aware compression is superior for broad knowledge tasks. </p>
<blockquote>
<p>将大型语言模型（LLM）中的外部知识相结合，可以在各种应用程序中增强其效用，但现有方法存在权衡。检索增强生成（RAG）通过相似性搜索获取证据，但关键信息可能不在排名靠前的结果中。长上下文模型可以处理多个文档，但计算成本高昂，且受限于上下文窗口大小。通过借鉴学生为开卷考试浓缩学习材料的方法，我们提出了任务感知的键值（KV）缓存压缩，它可以在零次或少数镜头设置中对外部知识进行压缩。这使得LLM能够在压缩后表示的所有相关信息上进行高效推理。实验表明，我们的方法优于RAG和任务无关压缩方法。在LongBench v2上，它在压缩率为30倍的情况下，较RAG提高了高达7个绝对点的准确性，同时将推理延迟从0.43秒减少到0.16秒。合成数据集的重点是，当稀疏证据足够时，RAG表现良好，而对于广泛的知识任务，任务感知压缩表现更优。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04973v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>在大型语言模型中融入外部知识可提升其跨不同应用的实用性，但现有方法存在权衡。本文提出一种任务感知键值缓存压缩方法，该方法通过零次或少数次设置压缩外部知识，使语言模型能够在紧凑的表示形式中高效地处理所有相关信息。实验表明，该方法优于检索增强生成方法和任务无关压缩方法，在长榜数据集上准确度提高最多达7个百分点，且实现了高达三十倍的压缩率和减少了推理延迟。研究指出任务感知的压缩对于大量知识任务更占优势，而检索增强生成方法则更适合稀疏证据的情况。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型融入外部知识可以提高其实用性。</li>
<li>现有融入方法存在权衡。如检索增强生成法可以获取证据，但可能遗漏关键信息；长语境模型可以处理多文档但计算成本较高并受限于语境窗口大小。</li>
<li>本文提出了一种任务感知键值缓存压缩方法，实现零次或少数次设置下的外部知识压缩。</li>
<li>该方法允许语言模型在紧凑的信息表示中高效推理。</li>
<li>实验显示此方法优于其他方法，在长榜数据集上准确度提高显著，同时实现高压缩率和减少推理延迟。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04973">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-332f524e6c36ad65d614cdb0df8763c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cf9b4bae8727ffe10ecb1b87639834d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa73b6dd7abd271f3066cf3cbfd0fa5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e2f97ed2de0ce138d2ffd5783eae6c6c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1341fb45e84af530e3384b827d2a9fb6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Spectral-Informed-Mamba-for-Robust-Point-Cloud-Processing"><a href="#Spectral-Informed-Mamba-for-Robust-Point-Cloud-Processing" class="headerlink" title="Spectral Informed Mamba for Robust Point Cloud Processing"></a>Spectral Informed Mamba for Robust Point Cloud Processing</h2><p><strong>Authors:Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, Sahar Dastani, Milad Cheraghalikhani, David Osowiechi, Gustavo Adolfo Vargas Hakim, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers</strong></p>
<p>State space models have shown significant promise in Natural Language Processing (NLP) and, more recently, computer vision. This paper introduces a new methodology leveraging Mamba and Masked Autoencoder networks for point cloud data in both supervised and self-supervised learning. We propose three key contributions to enhance Mamba’s capability in processing complex point cloud structures. First, we exploit the spectrum of a graph Laplacian to capture patch connectivity, defining an isometry-invariant traversal order that is robust to viewpoints and better captures shape manifolds than traditional 3D grid-based traversals. Second, we adapt segmentation via a recursive patch partitioning strategy informed by Laplacian spectral components, allowing finer integration and segment analysis. Third, we address token placement in Masked Autoencoder for Mamba by restoring tokens to their original positions, which preserves essential order and improves learning. Extensive experiments demonstrate the improvements of our approach in classification, segmentation, and few-shot tasks over state-of-the-art baselines. </p>
<blockquote>
<p>状态空间模型在自然语言处理（NLP）中显示出巨大的潜力，最近在计算机视觉领域也受到了广泛关注。本文介绍了一种新的方法，利用Mamba和Masked Autoencoder网络对点云数据进行有监督和自监督学习。我们提出了三项关键贡献，以增强Mamba处理复杂点云结构的能力。首先，我们利用图拉普拉斯算子的谱来捕捉斑块连接性，定义了一个等距不变遍历顺序，该顺序对视角具有鲁棒性，并且比传统的基于三维网格的遍历更好地捕捉形状流形。其次，我们通过拉普拉斯谱分量进行递归斑块分割策略来适应分割，这允许更精细的集成和分段分析。第三，我们通过将令牌恢复到其原始位置来解决Mamba中的Masked Autoencoder的令牌放置问题，这保留了重要的顺序并提高了学习效果。大量实验表明，我们的方法在分类、分割和少样本任务上的表现优于最先进的基线方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04953v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种新的利用Mamba和Masked Autoencoder网络处理点云数据的方法，包括监督学习和自监督学习。文章提出了三个主要贡献以增强Mamba处理复杂点云结构的能力：利用图拉普拉斯谱捕捉斑块连接性；通过递归斑块分区策略进行分段；以及在Masked Autoencoder中为Mamba恢复令牌位置。实验证明，该方法在分类、分割和少样本任务上均优于现有技术基线。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>引入了一种新的利用Mamba和Masked Autoencoder网络处理点云数据的方法，适用于NLP和计算机视觉领域。</li>
<li>通过利用图拉普拉斯谱，增强了对点云数据的处理能力，能更准确地捕捉形状流形信息。</li>
<li>提出了一种基于拉普拉斯谱的递归斑块分区策略，实现了更精细的集成和分段分析。</li>
<li>通过恢复令牌到其原始位置，解决了Masked Autoencoder中的令牌放置问题，保留了重要的顺序信息，提高了学习效果。</li>
<li>与现有的技术基线相比，该方法在分类、分割和少样本任务上均表现出优势。</li>
<li>该方法具有处理复杂点云结构的能力，可以应用于不同的领域，如医疗、遥感等。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04953">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-fc5a604c7b5875834bc7b177227c58be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42815d82b3ec4917ddf7293a1b314ee5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d80e8ab2b4596e594f5896887a5d5469.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-358115bec4445ff6cb1756c3fb9f74da.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="HILGEN-Hierarchically-Informed-Data-Generation-for-Biomedical-NER-Using-Knowledgebases-and-Large-Language-Models"><a href="#HILGEN-Hierarchically-Informed-Data-Generation-for-Biomedical-NER-Using-Knowledgebases-and-Large-Language-Models" class="headerlink" title="HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using   Knowledgebases and Large Language Models"></a>HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using   Knowledgebases and Large Language Models</h2><p><strong>Authors:Yao Ge, Yuting Guo, Sudeshna Das, Swati Rajwal, Selen Bozkurt, Abeed Sarker</strong></p>
<p>We present HILGEN, a Hierarchically-Informed Data Generation approach that combines domain knowledge from the Unified Medical Language System (UMLS) with synthetic data generated by large language models (LLMs), specifically GPT-3.5. Our approach leverages UMLS’s hierarchical structure to expand training data with related concepts, while incorporating contextual information from LLMs through targeted prompts aimed at automatically generating synthetic examples for sparsely occurring named entities. The performance of the HILGEN approach was evaluated across four biomedical NER datasets (MIMIC III, BC5CDR, NCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation with Nearest Neighbor Classifier) models, applying various data generation strategies, including UMLS, GPT-3.5, and their best ensemble. For the BERT-Large model, incorporating UMLS led to an average F1 score improvement of 40.36%, while using GPT-3.5 resulted in a comparable average increase of 40.52%. The Best-Ensemble approach using BERT-Large achieved the highest improvement, with an average increase of 42.29%. DANN model’s F1 score improved by 22.74% on average using the UMLS-only approach. The GPT-3.5-based method resulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more notable improvement, with an average increase of 25.03%. Our proposed HILGEN approach improves NER performance in few-shot settings without requiring additional manually annotated data. Our experiments demonstrate that an effective strategy for optimizing biomedical NER is to combine biomedical knowledge curated in the past, such as the UMLS, and generative LLMs to create synthetic training instances. Our future research will focus on exploring additional innovative synthetic data generation strategies for further improving NER performance. </p>
<blockquote>
<p>我们提出了HILGEN方法，这是一种结合统一医学语言系统（UMLS）领域知识和由大型语言模型（尤其是GPT-3.5）生成合成数据分层信息的数据生成方法。我们的方法利用UMLS的层次结构来扩展训练数据的相关概念，同时通过有针对性的提示融入大型语言模型的上下文信息，旨在自动生成稀疏命名实体的合成示例。HILGEN方法在四个生物医学命名实体识别数据集（MIMIC III、BC5CDR、NCBI-Disease和Med-Mentions）上的性能表现通过使用BERT-Large和DANN（基于最近邻分类器的数据增强）模型进行了评估，并应用了各种数据生成策略，包括UMLS、GPT-3.5及其最佳组合。对于BERT-Large模型，结合UMLS平均F1分数提高了40.36%，而使用GPT-3.5也实现了相当的平均增幅40.52%。使用BERT-Large的最佳组合方法实现了最高的改进，平均提高了42.29%。对于DANN模型，使用仅UMLS的方法平均F1分数提高了22.74%，GPT-3.5的方法导致提高了21.53%，最佳组合DANN模型显示出更显著的改进，平均提高了25.03%。我们提出的HILGEN方法提高了少样本设置中的命名实体识别性能，无需额外手动注释的数据。我们的实验表明，优化生物医学命名实体识别的有效策略是结合过去整理好的生物医学知识（如UMLS）和生成式大型语言模型来创建合成训练实例。我们未来的研究将专注于探索更多创新合成数据生成策略，以进一步提高命名实体识别的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04930v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于统一医学语言系统（UMLS）的层次结构信息和大型语言模型（特别是GPT-3.5）生成的合成数据，我们提出了HILGEN方法。该方法利用UMLS的层次结构来扩展训练数据，并通过有针对性的提示自动生成稀疏命名实体的合成示例。在四个生物医学命名实体识别数据集上进行的评估表明，该方法在不额外需要手动注释数据的情况下提高了命名实体识别的性能。我们的实验表明，结合过去整理的生物医学知识和生成式LLM来创建合成训练实例是一种优化生物医学命名实体识别的有效策略。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HILGEN方法结合了UMLS的层次结构信息和GPT-3.5生成的合成数据。</li>
<li>UMLS的层次结构用于扩展训练数据，并生成与特定概念相关的合成示例。</li>
<li>在四个生物医学NER数据集上评估，使用BERT-Large模型，结合UMLS和GPT-3.5的方法分别提高了平均F1分数40.36%和40.52%。</li>
<li>最佳组合方法（使用BERT-Large）的平均F1分数提高了42.29%。</li>
<li>DANN模型的F1分数使用UMLS方法平均提高了22.74%，GPT-3.5方法提高了21.53%。</li>
<li>无需额外手动注释数据，HILGEN方法即可提高NER性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04930">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1aed4888193e304bbf0f01177a2cb2c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-12a858589d9f20e9c93e4b4192071f3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bcc94e02dffa84d108e6779d43d1a12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02ed2f87b234f4d3457a3304c4429a1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20931a18aab879884f2d1eb376eb0ed3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Rethinking-Few-Shot-Medical-Image-Segmentation-by-SAM2-A-Training-Free-Framework-with-Augmentative-Prompting-and-Dynamic-Matching"><a href="#Rethinking-Few-Shot-Medical-Image-Segmentation-by-SAM2-A-Training-Free-Framework-with-Augmentative-Prompting-and-Dynamic-Matching" class="headerlink" title="Rethinking Few-Shot Medical Image Segmentation by SAM2: A Training-Free   Framework with Augmentative Prompting and Dynamic Matching"></a>Rethinking Few-Shot Medical Image Segmentation by SAM2: A Training-Free   Framework with Augmentative Prompting and Dynamic Matching</h2><p><strong>Authors:Haiyue Zu, Jun Ge, Heting Xiao, Jile Xie, Zhangzhe Zhou, Yifan Meng, Jiayi Ni, Junjie Niu, Linlin Zhang, Li Ni, Huilin Yang</strong></p>
<p>The reliance on large labeled datasets presents a significant challenge in medical image segmentation. Few-shot learning offers a potential solution, but existing methods often still require substantial training data. This paper proposes a novel approach that leverages the Segment Anything Model 2 (SAM2), a vision foundation model with strong video segmentation capabilities. We conceptualize 3D medical image volumes as video sequences, departing from the traditional slice-by-slice paradigm. Our core innovation is a support-query matching strategy: we perform extensive data augmentation on a single labeled support image and, for each frame in the query volume, algorithmically select the most analogous augmented support image. This selected image, along with its corresponding mask, is used as a mask prompt, driving SAM2’s video segmentation. This approach entirely avoids model retraining or parameter updates. We demonstrate state-of-the-art performance on benchmark few-shot medical image segmentation datasets, achieving significant improvements in accuracy and annotation efficiency. This plug-and-play method offers a powerful and generalizable solution for 3D medical image segmentation. </p>
<blockquote>
<p>在医学图像分割中，对大量标记数据集的依赖构成了一大挑战。小样本学习提供了一个潜在的解决方案，但现有方法通常仍然需要大量的训练数据。本文提出了一种利用Segment Anything Model 2（SAM2）的新方法，这是一个具有强大视频分割能力的视觉基础模型。我们将3D医学图像体积概念化为视频序列，摒弃了传统的逐片处理模式。我们的核心创新之处在于支持查询匹配策略：我们对单个标记的支持图像进行大量数据增强，并针对查询体积中的每一帧，算法选择最类似的增强支持图像。所选图像及其相应的掩膜被用作掩膜提示，驱动SAM2的视频分割。这种方法完全避免了模型重新训练或参数更新。我们在基准的少量医学图像分割数据集上展示了卓越的性能，在准确性和注释效率方面取得了显著的提升。这种即插即用的方法为3D医学图像分割提供了强大且通用的解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04826v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文提出了一种利用Segment Anything Model 2（SAM2）进行医学图像分割的新方法，通过把3D医学图像体积概念化为视频序列，实现了对单一标记支持图像的大规模数据增强，提高了少样本医学图像分割的准确性和标注效率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医学图像分割对大量标记数据集存在依赖，少样本学习为解决此问题提供了潜在方案。</li>
<li>本文提出了一个利用Segment Anything Model 2 (SAM2)的新方法，这是一个具有强大视频分割能力的视觉基础模型。</li>
<li>将传统的切片-by-切片模式转变为将3D医学图像体积概念化为视频序列的方法。</li>
<li>核心创新在于支持查询匹配策略：对单一标记的支持图像进行大规模数据增强，并对于查询体积中的每一帧，算法选择最类似的增强支持图像。</li>
<li>选定的图像及其对应的掩膜被用作掩膜提示，推动SAM2的视频分割。</li>
<li>此方法避免了模型重新训练或参数更新，实现了即插即用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04826">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-419cd1ae8355968af7b09762edb4669e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-39a938d457bc457bec9f634b911c8e89.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d2cd0daa69baaef5b4804bd728e675ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0da8f7ea6c174497756b87d14f56db7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DeFT-Decoding-with-Flash-Tree-attention-for-Efficient-Tree-structured-LLM-Inference"><a href="#DeFT-Decoding-with-Flash-Tree-attention-for-Efficient-Tree-structured-LLM-Inference" class="headerlink" title="DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured   LLM Inference"></a>DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured   LLM Inference</h2><p><strong>Authors:Jinwei Yao, Kaiqi Chen, Kexun Zhang, Jiaxuan You, Binhang Yuan, Zeke Wang, Tao Lin</strong></p>
<p>Large language models (LLMs) are increasingly employed for complex tasks that process multiple generation calls in a tree structure with shared prefixes of tokens, including few-shot prompting, multi-step reasoning, speculative decoding, etc. However, existing inference systems for tree-based applications are inefficient due to improper partitioning of queries and KV cache during attention calculation. This leads to two main issues: (1) a lack of memory access (IO) reuse for KV cache of shared prefixes, and (2) poor load balancing.As a result, there is redundant KV cache IO between GPU global memory and shared memory, along with low GPU utilization. To address these challenges, we propose DeFT(Decoding with Flash Tree-Attention), a hardware-efficient attention algorithm with prefix-aware and load-balanced KV cache partitions. DeFT reduces the number of read&#x2F;write operations of KV cache during attention calculation through KV-Guided Grouping, a method that avoids repeatedly loading KV cache of shared prefixes in attention computation. Additionally, we propose Flattened Tree KV Splitting, a mechanism that ensures even distribution of the KV cache across partitions with little computation redundancy, enhancing GPU utilization during attention computations. By reducing 73-99% KV cache IO and nearly 100% IO for partial results during attention calculation, DeFT achieves up to 2.23&#x2F;3.59x speedup in the end-to-end&#x2F;attention latency across three practical tree-based workloads compared to state-of-the-art attention algorithms. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/LINs-lab/DeFT">https://github.com/LINs-lab/DeFT</a>. </p>
<blockquote>
<p>大型语言模型（LLM）越来越多地被用于处理树结构中的多代呼叫的复杂任务，这些任务具有共享前缀的令牌，包括少量提示、多步推理、推测解码等。然而，基于树的现有推理系统由于在注意力计算过程中的查询和KV缓存划分不当，导致效率不高。这引发了两个问题：（1）共享前缀的KV缓存缺乏内存访问（IO）重用；（2）负载不均衡。因此，存在GPU全局内存和共享内存之间的冗余KV缓存IO，以及GPU利用率低。为了解决这些挑战，我们提出了DeFT（带有闪电树注意力的解码），这是一种硬件高效的注意力算法，具有前缀感知和负载平衡的KV缓存分区。DeFT通过KV引导的分组方法，减少了注意力计算过程中KV缓存的读写操作次数，避免了重复加载共享前缀的KV缓存。此外，我们提出了扁平树KV拆分机制，确保KV缓存均匀分布在各分区内，计算冗余度低，提高了注意力计算时的GPU利用率。通过减少73-99%的KV缓存IO和近100%的注意力计算过程中部分结果的IO，DeFT在实际的树结构工作负载上实现了端到端延迟&#x2F;注意力延迟最高达2.23倍&#x2F;3.59倍的加速效果。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/LINs-lab/DeFT%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/LINs-lab/DeFT获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.00242v4">PDF</a> Update DeFT-v4, accepted by ICLR’25   (<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=2c7pfOqu9k">https://openreview.net/forum?id=2c7pfOqu9k</a>). Our code is available at   <a target="_blank" rel="noopener" href="https://github.com/LINs-lab/DeFT">https://github.com/LINs-lab/DeFT</a></p>
<p><strong>Summary</strong></p>
<p>该文介绍了大型语言模型在处理具有共享前缀的令牌树结构中的多代呼叫任务时面临的挑战。为解决现有推理系统在注意力计算中的不当查询分区和KV缓存问题，提出了名为DeFT的硬件高效注意力算法，具有前缀感知和负载均衡的KV缓存分区。DeFT通过KV缓存的读&#x2F;写操作次数减少了注意力计算过程中的冗余操作，实现了高效的树结构处理速度提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在处理包含共享前缀的令牌树结构中的多代调用任务时面临效率挑战。</li>
<li>现存推理系统在注意力计算中的查询分区和KV缓存存在问题，导致内存访问（IO）复用不足和负载不均衡。</li>
<li>DeFT是一种硬件高效的注意力算法，具有前缀感知和负载均衡的KV缓存分区，旨在解决上述问题。</li>
<li>DeFT通过KV缓存的读&#x2F;写操作次数减少了冗余操作，提高了注意力计算效率。</li>
<li>DeFT实现了对实际树结构工作负载的端到端和注意力延迟高达2.23倍和3.59倍的速度提升。</li>
<li>DeFT代码已公开发布在<a target="_blank" rel="noopener" href="https://github.com/LINs-lab/DeFT%E3%80%82">https://github.com/LINs-lab/DeFT。</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.00242">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-186e8db6556ad1f3706a08505f3504ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1823e3bb62f96cecbb8e21e23194206e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47b442e315ef520f9077eb87bc19a783.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e3163810fc2c7c4c4064d5bfa97060f7.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-11/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-11/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-11/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-76fb292fb5818f71bc22eddf4397cecf.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-03-11  Impoola The Power of Average Pooling for Image-Based Deep Reinforcement   Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-11/MMT/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-6c577c4d7f273e8ef5bf75ee6b07afca.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-03-11  Parallel Corpora for Machine Translation in Low-resource Indic   Languages A Comprehensive Review
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29301k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
