<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Taking a SEAT Predicting Value Interpretations from Sentiment, Emotion,   Argument, and Topic Annotations">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01165v1/page_1_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-04-æ›´æ–°"><a href="#2025-10-04-æ›´æ–°" class="headerlink" title="2025-10-04 æ›´æ–°"></a>2025-10-04 æ›´æ–°</h1><h2 id="Taking-a-SEAT-Predicting-Value-Interpretations-from-Sentiment-Emotion-Argument-and-Topic-Annotations"><a href="#Taking-a-SEAT-Predicting-Value-Interpretations-from-Sentiment-Emotion-Argument-and-Topic-Annotations" class="headerlink" title="Taking a SEAT: Predicting Value Interpretations from Sentiment, Emotion,   Argument, and Topic Annotations"></a>Taking a SEAT: Predicting Value Interpretations from Sentiment, Emotion,   Argument, and Topic Annotations</h2><p><strong>Authors:Adina Nicola Dobrinoiu, Ana Cristiana Marcu, Amir Homayounirad, Luciano Cavalcante Siebert, Enrico Liscio</strong></p>
<p>Our interpretation of value concepts is shaped by our sociocultural background and lived experiences, and is thus subjective. Recognizing individual value interpretations is important for developing AI systems that can align with diverse human perspectives and avoid bias toward majority viewpoints. To this end, we investigate whether a language model can predict individual value interpretations by leveraging multi-dimensional subjective annotations as a proxy for their interpretive lens. That is, we evaluate whether providing examples of how an individual annotates Sentiment, Emotion, Argument, and Topics (SEAT dimensions) helps a language model in predicting their value interpretations. Our experiment across different zero- and few-shot settings demonstrates that providing all SEAT dimensions simultaneously yields superior performance compared to individual dimensions and a baseline where no information about the individual is provided. Furthermore, individual variations across annotators highlight the importance of accounting for the incorporation of individual subjective annotators. To the best of our knowledge, this controlled setting, although small in size, is the first attempt to go beyond demographics and investigate the impact of annotation behavior on value prediction, providing a solid foundation for future large-scale validation. </p>
<blockquote>
<p>æˆ‘ä»¬å¯¹ä»·å€¼æ¦‚å¿µçš„ç†è§£å—åˆ°æˆ‘ä»¬çš„ç¤¾ä¼šæ–‡åŒ–èƒŒæ™¯å’Œç”Ÿæ´»ç»å†çš„å½±å“ï¼Œå› æ­¤æ˜¯ä¸»è§‚çš„ã€‚è¯†åˆ«ä¸ªä½“çš„ä»·å€¼è§£è¯»å¯¹äºå¼€å‘èƒ½å¤Ÿä¸å¤šæ ·åŒ–çš„äººç±»è§†è§’ç›¸å»åˆå¹¶é¿å…åå‘å¤šæ•°è§‚ç‚¹çš„AIç³»ç»Ÿå¾ˆé‡è¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è°ƒæŸ¥è¯­è¨€æ¨¡å‹æ˜¯å¦å¯ä»¥åˆ©ç”¨å¤šç»´ä¸»è§‚æ³¨é‡Šä½œä¸ºè§£è¯»é€é•œçš„ä»£ç†æ¥é¢„æµ‹ä¸ªä½“ä»·å€¼è§£è¯»ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è¯„ä¼°æä¾›ä¸ªäººå¦‚ä½•æ³¨é‡Šæƒ…æ„Ÿã€æƒ…ç»ªã€è§‚ç‚¹å’Œè¯é¢˜ï¼ˆSEATç»´åº¦ï¼‰çš„ä¾‹å­æ˜¯å¦æœ‰åŠ©äºè¯­è¨€æ¨¡å‹é¢„æµ‹ä»–ä»¬çš„ä»·å€¼è§£è¯»ã€‚æˆ‘ä»¬åœ¨ä¸åŒçš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸‹çš„å®éªŒè¡¨æ˜ï¼ŒåŒæ—¶æä¾›æ‰€æœ‰SEATç»´åº¦ç›¸æ¯”å•ç‹¬ç»´åº¦å’Œä¸€ä¸ªä¸æä¾›ä¸ªä½“ä¿¡æ¯çš„åŸºå‡†çº¿èƒ½å¸¦æ¥æ›´å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ ‡æ³¨è€…ä¹‹é—´çš„ä¸ªä½“å·®å¼‚çªæ˜¾äº†éœ€è¦è€ƒè™‘èå…¥ä¸ªä½“ä¸»è§‚æ ‡æ³¨è€…çš„é‡è¦æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™ä¸ªå—æ§è®¾ç½®è™½ç„¶è§„æ¨¡è¾ƒå°ï¼Œä½†æ˜¯é¦–æ¬¡å°è¯•è¶…è¶Šäººå£ç»Ÿè®¡å­¦ï¼Œç ”ç©¶æ ‡æ³¨è¡Œä¸ºå¯¹ä»·å€¼é¢„æµ‹çš„å½±å“ï¼Œä¸ºæœªæ¥çš„å¤§è§„æ¨¡éªŒè¯æä¾›äº†åšå®çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01976v1">PDF</a> Accepted at VALE workshop (ECAI 2025)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä¸ªäººä»·å€¼è§‚å¿µçš„è§£è¯»å—åˆ°ç¤¾ä¼šæ–‡åŒ–èƒŒæ™¯å’Œç”Ÿæ´»ç»å†çš„å½±å“ï¼Œå…·æœ‰ä¸»è§‚æ€§ã€‚ä¸ºäº†å‘å±•èƒ½å¤Ÿç¬¦åˆå¤šå…ƒäººç±»è§†è§’å¹¶é¿å…åå‘ä¸»æµè§‚ç‚¹çš„AIç³»ç»Ÿï¼Œç ”ç©¶æ˜¯å¦å¯ä»¥é€šè¿‡åˆ©ç”¨å¤šç»´ä¸»è§‚æ³¨é‡Šä½œä¸ºä¸ªä½“è§£è¯»çš„é€é•œæ¥é¢„æµ‹ä¸ªä½“ä»·å€¼è§£è¯»ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ä¸åŒé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒåŒæ—¶æä¾›æƒ…æ„Ÿã€æƒ…ç»ªã€è®ºè¯å’Œä¸»é¢˜ï¼ˆSEATç»´åº¦ï¼‰çš„æ³¨é‡Šä¿¡æ¯èƒ½æé«˜é¢„æµ‹æ€§èƒ½ï¼Œä¸”æ¯”ä»…æä¾›ä¸ªåˆ«ç»´åº¦æˆ–æ²¡æœ‰æä¾›ä¸ªä½“ä¿¡æ¯çš„åŸºç¡€æ¨¡å‹è¡¨ç°æ›´ä½³ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œä¸åŒæ³¨é‡Šè€…ä¹‹é—´çš„ä¸ªä½“å·®å¼‚å‡¸æ˜¾å‡ºè€ƒè™‘ä¸ªä½“ä¸»è§‚æ³¨é‡Šçš„é‡è¦æ€§ã€‚è¯¥å®éªŒè™½è§„æ¨¡è¾ƒå°ï¼Œä½†å´æ˜¯é¦–æ¬¡å°è¯•è¶…è¶Šäººå£ç»Ÿè®¡å­¦å»æ¢ç©¶æ³¨é‡Šè¡Œä¸ºå¯¹ä»·å€¼é¢„æµ‹çš„å½±å“ï¼Œä¸ºæœªæ¥å¤§è§„æ¨¡éªŒè¯æä¾›äº†åšå®çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸ªäººä»·å€¼è§‚å¿µçš„è§£è¯»å…·æœ‰ä¸»è§‚æ€§ï¼Œå—åˆ°ç¤¾ä¼šæ–‡åŒ–èƒŒæ™¯å’Œç”Ÿæ´»ç»å†çš„å½±å“ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨å¤šç»´ä¸»è§‚æ³¨é‡Šä½œä¸ºä¸ªä½“è§£è¯»ä»·å€¼çš„é€é•œï¼Œå¯ä»¥é¢„æµ‹ä¸ªä½“ä»·å€¼è§£è¯»ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒåŒæ—¶æä¾›æƒ…æ„Ÿã€æƒ…ç»ªã€è®ºè¯å’Œä¸»é¢˜çš„æ³¨é‡Šä¿¡æ¯èƒ½æé«˜é¢„æµ‹æ€§èƒ½ã€‚</li>
<li>ä¸ªä½“å·®å¼‚åœ¨ä»·å€¼é¢„æµ‹ä¸­å¾ˆé‡è¦ï¼Œéœ€è¦è€ƒè™‘åˆ°ä¸åŒæ³¨é‡Šè€…ä¹‹é—´çš„å·®å¼‚æ€§ã€‚</li>
<li>æ­¤ç ”ç©¶æ˜¯é¦–æ¬¡å°è¯•è¶…è¶Šäººå£ç»Ÿè®¡å­¦æ¢ç©¶æ³¨é‡Šè¡Œä¸ºå¯¹ä»·å€¼é¢„æµ‹çš„å½±å“ã€‚</li>
<li>æä¾›äº†ä¸€ç§åŸºäºå°‘é‡æ•°æ®éªŒè¯çš„æœ‰æ•ˆæ–¹æ³•ï¼Œä¸ºæœªæ¥çš„å¤§è§„æ¨¡éªŒè¯æä¾›äº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01976v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01976v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MPMAvatar-Learning-3D-Gaussian-Avatars-with-Accurate-and-Robust-Physics-Based-Dynamics"><a href="#MPMAvatar-Learning-3D-Gaussian-Avatars-with-Accurate-and-Robust-Physics-Based-Dynamics" class="headerlink" title="MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust   Physics-Based Dynamics"></a>MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust   Physics-Based Dynamics</h2><p><strong>Authors:Changmin Lee, Jihyun Lee, Tae-Kyun Kim</strong></p>
<p>While there has been significant progress in the field of 3D avatar creation from visual observations, modeling physically plausible dynamics of humans with loose garments remains a challenging problem. Although a few existing works address this problem by leveraging physical simulation, they suffer from limited accuracy or robustness to novel animation inputs. In this work, we present MPMAvatar, a framework for creating 3D human avatars from multi-view videos that supports highly realistic, robust animation, as well as photorealistic rendering from free viewpoints. For accurate and robust dynamics modeling, our key idea is to use a Material Point Method-based simulator, which we carefully tailor to model garments with complex deformations and contact with the underlying body by incorporating an anisotropic constitutive model and a novel collision handling algorithm. We combine this dynamics modeling scheme with our canonical avatar that can be rendered using 3D Gaussian Splatting with quasi-shadowing, enabling high-fidelity rendering for physically realistic animations. In our experiments, we demonstrate that MPMAvatar significantly outperforms the existing state-of-the-art physics-based avatar in terms of (1) dynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and efficiency. Additionally, we present a novel application in which our avatar generalizes to unseen interactions in a zero-shot manner-which was not achievable with previous learning-based methods due to their limited simulation generalizability. Our project page is at: <a target="_blank" rel="noopener" href="https://kaistchangmin.github.io/MPMAvatar/">https://KAISTChangmin.github.io/MPMAvatar/</a> </p>
<blockquote>
<p>åœ¨3Dé˜¿å‡¡è¾¾ï¼ˆavatarï¼‰ä»è§†è§‰è§‚å¯Ÿè¿›è¡Œåˆ›ä½œçš„é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•çš„åŒæ—¶ï¼Œç”¨å®½æ¾è¡£ç‰©æ¨¡æ‹Ÿäººç±»ç‰©ç†ä¸Šå¯è¡Œçš„åŠ¨æ€ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚è™½ç„¶æœ‰ä¸€äº›ç°æœ‰å·¥ä½œé€šè¿‡åˆ©ç”¨ç‰©ç†æ¨¡æ‹Ÿæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä»¬åœ¨å‡†ç¡®æ€§å’Œå¯¹æ–°å‹åŠ¨ç”»è¾“å…¥çš„ç¨³å¥æ€§æ–¹é¢å­˜åœ¨å±€é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MPMAvataræ¡†æ¶ï¼Œå®ƒå¯ä»¥ä»å¤šè§†è§’è§†é¢‘åˆ›å»º3Däººç±»é˜¿å‡¡è¾¾ï¼Œæ”¯æŒé«˜åº¦é€¼çœŸã€ç¨³å¥çš„åŠ¨ç”»ï¼Œä»¥åŠä»è‡ªç”±è§†è§’è¿›è¡ŒçœŸå®æ„Ÿæ¸²æŸ“ã€‚ä¸ºäº†è¿›è¡Œç²¾ç¡®è€Œç¨³å¥çš„åŠ¨æ€å»ºæ¨¡ï¼Œæˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨åŸºäºç‰©è´¨ç‚¹æ–¹æ³•çš„æ¨¡æ‹Ÿå™¨ï¼Œæˆ‘ä»¬ç²¾å¿ƒå®šåˆ¶å®ƒæ¥æ¨¡æ‹Ÿè¡£ç‰©çš„å¤æ‚å˜å½¢ä»¥åŠä¸åº•å±‚èº«ä½“çš„æ¥è§¦ï¼Œé€šè¿‡å¼•å…¥ä¸€ä¸ªå„å‘å¼‚æ€§æœ¬æ„æ¨¡å‹å’Œä¸€ç§æ–°å‹ç¢°æ’å¤„ç†ç®—æ³•ã€‚æˆ‘ä»¬å°†è¿™ç§åŠ¨æ€å»ºæ¨¡æ–¹æ¡ˆä¸æˆ‘ä»¬çš„è§„èŒƒé˜¿å‡¡è¾¾ç›¸ç»“åˆï¼Œè¯¥é˜¿å‡¡è¾¾å¯ä»¥ä½¿ç”¨å¸¦æœ‰å‡†é˜´å½±çš„3Dé«˜æ–¯è´´å›¾è¿›è¡Œæ¸²æŸ“ï¼Œä¸ºç‰©ç†çœŸå®çš„åŠ¨ç”»æä¾›é«˜ä¿çœŸæ¸²æŸ“ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†MPMAvataråœ¨ï¼ˆ1ï¼‰åŠ¨æ€å»ºæ¨¡å‡†ç¡®æ€§ã€ï¼ˆ2ï¼‰æ¸²æŸ“å‡†ç¡®æ€§å’Œï¼ˆ3ï¼‰ç¨³å¥æ€§å’Œæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäºç‰©ç†çš„é˜¿å‡¡è¾¾æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸€é¡¹æ–°é¢–çš„åº”ç”¨ï¼Œå³æˆ‘ä»¬çš„é˜¿å‡¡è¾¾èƒ½å¤Ÿä»¥é›¶é•œå¤´çš„æ–¹å¼æ³›åŒ–åˆ°æœªè§è¿‡çš„äº¤äº’-è¿™æ˜¯ä»¥å‰åŸºäºå­¦ä¹ çš„æ–¹æ³•ç”±äºæœ‰é™çš„æ¨¡æ‹Ÿæ³›åŒ–èƒ½åŠ›è€Œæ— æ³•å®ç°çš„ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ˜¯ï¼š<a target="_blank" rel="noopener" href="https://kaistchangmin.github.io/MPMAvatar/">https://KAISTChangmin.github.io/MPMAvatar/</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01619v1">PDF</a> Accepted to NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†MPMAvataræ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ”¯æŒä»å¤šè§†è§’è§†é¢‘åˆ›å»º3Däººç±»è§’è‰²åŠ¨ç”»ï¼Œå…·æœ‰é€¼çœŸã€ç¨³å¥çš„ç‰¹ç‚¹ï¼Œå¹¶èƒ½ä»è‡ªç”±è§†è§’è¿›è¡Œç…§ç‰‡çº§æ¸²æŸ“ã€‚å…³é”®æ€æƒ³æ˜¯é‡‡ç”¨åŸºäºç‰©è´¨ç‚¹æ–¹æ³•çš„æ¨¡æ‹Ÿå™¨æ¥ç²¾ç¡®æ¨¡æ‹Ÿè¡£ç‰©çš„å¤æ‚å˜å½¢ä»¥åŠä¸åº•å±‚èº«ä½“çš„æ¥è§¦ç¢°æ’ã€‚é€šè¿‡å®éªŒè¯æ˜ï¼ŒMPMAvataråœ¨åŠ¨åŠ›å­¦å»ºæ¨¡ã€æ¸²æŸ“å‡†ç¡®æ€§ä»¥åŠç¨³å¥æ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¿˜å±•ç¤ºäº†å…¶åœ¨æ–°äº’åŠ¨åœºæ™¯ä¸‹çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MPMAvataræ¡†æ¶æ”¯æŒä»å¤šè§†è§’è§†é¢‘åˆ›å»ºé«˜åº¦é€¼çœŸçš„3Däººç±»è§’è‰²åŠ¨ç”»ã€‚</li>
<li>é‡‡ç”¨ç‰©è´¨ç‚¹æ–¹æ³•æ¨¡æ‹Ÿå™¨ï¼Œèƒ½ç²¾ç¡®æ¨¡æ‹Ÿè¡£ç‰©çš„å¤æ‚å˜å½¢å’Œä¸èº«ä½“çš„æ¥è§¦ç¢°æ’ã€‚</li>
<li>MPMAvataråœ¨åŠ¨åŠ›å­¦å»ºæ¨¡ã€æ¸²æŸ“å‡†ç¡®æ€§ä»¥åŠç¨³å¥æ€§å’Œæ•ˆç‡æ–¹é¢è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚</li>
<li>å±•ç¤ºäº†å¯¹æœªè§äº’åŠ¨çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿå¤„ç†å¤æ‚åœºæ™¯ä¸‹çš„ç‰©ç†ä»¿çœŸï¼Œæé«˜äº†åŠ¨ç”»çš„çœŸå®æ„Ÿå’Œè§‚çœ‹ä½“éªŒã€‚</li>
<li>MPMAvataré€šè¿‡ç»“åˆç‰©è´¨ç‚¹æ–¹æ³•å’Œå…¸å‹è§’è‰²æ¨¡å‹ï¼Œå®ç°äº†ç‰©ç†ç°å®ä¸»ä¹‰çš„åŠ¨ç”»æ¸²æŸ“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01619v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01619v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="One-More-Question-is-Enough-Expert-Question-Decomposition-EQD-Model-for-Domain-Quantitative-Reasoning"><a href="#One-More-Question-is-Enough-Expert-Question-Decomposition-EQD-Model-for-Domain-Quantitative-Reasoning" class="headerlink" title="One More Question is Enough, Expert Question Decomposition (EQD) Model   for Domain Quantitative Reasoning"></a>One More Question is Enough, Expert Question Decomposition (EQD) Model   for Domain Quantitative Reasoning</h2><p><strong>Authors:Mengyu Wang, Sotirios Sabanis, Miguel de Carvalho, Shay B. Cohen, Tiejun Ma</strong></p>
<p>Domain-specific quantitative reasoning remains a major challenge for large language models (LLMs), especially in fields requiring expert knowledge and complex question answering (QA). In this work, we propose Expert Question Decomposition (EQD), an approach designed to balance the use of domain knowledge with computational efficiency. EQD is built on a two-step fine-tuning framework and guided by a reward function that measures the effectiveness of generated sub-questions in improving QA outcomes. It requires only a few thousand training examples and a single A100 GPU for fine-tuning, with inference time comparable to zero-shot prompting. Beyond its efficiency, EQD outperforms state-of-the-art domain-tuned models and advanced prompting strategies. We evaluate EQD in the financial domain, characterized by specialized knowledge and complex quantitative reasoning, across four benchmark datasets. Our method consistently improves QA performance by 0.6% to 10.5% across different LLMs. Our analysis reveals an important insight: in domain-specific QA, a single supporting question often provides greater benefit than detailed guidance steps. </p>
<blockquote>
<p>é¢†åŸŸç‰¹å®šçš„é‡åŒ–æ¨ç†å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è¯´ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå¤æ‚é—®ç­”ï¼ˆQAï¼‰çš„é¢†åŸŸã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸“å®¶é—®é¢˜åˆ†è§£ï¼ˆEQDï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡é¢†åŸŸçŸ¥è¯†çš„ä½¿ç”¨ä¸è®¡ç®—æ•ˆç‡ã€‚EQDå»ºç«‹åœ¨ä¸¤æ­¥å¾®è°ƒæ¡†æ¶ä¸Šï¼Œå¹¶å—å¥–åŠ±å‡½æ•°çš„æŒ‡å¯¼ï¼Œè¯¥å¥–åŠ±å‡½æ•°è¡¡é‡ç”Ÿæˆçš„å­é—®é¢˜åœ¨æé«˜é—®ç­”ç»“æœæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®ƒåªéœ€è¦å‡ åƒä¸ªè®­ç»ƒæ ·æœ¬å’Œä¸€ä¸ªA100 GPUè¿›è¡Œå¾®è°ƒï¼Œæ¨ç†æ—¶é—´ä¸é›¶æ ·æœ¬æç¤ºç›¸å½“ã€‚é™¤äº†é«˜æ•ˆæ€§å¤–ï¼ŒEQDè¿˜ä¼˜äºæœ€å…ˆè¿›çš„é¢†åŸŸè°ƒæ•´æ¨¡å‹å’Œé«˜çº§æç¤ºç­–ç•¥ã€‚æˆ‘ä»¬åœ¨é‡‘èé¢†åŸŸè¯„ä¼°äº†EQDï¼Œè¯¥é¢†åŸŸå…·æœ‰ä¸“ä¸šçŸ¥è¯†å’Œå¤æ‚çš„é‡åŒ–æ¨ç†ï¼Œè·¨è¶Šå››ä¸ªåŸºå‡†æ•°æ®é›†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒçš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šå§‹ç»ˆæé«˜äº†é—®ç­”æ€§èƒ½ï¼Œå¹…åº¦ä»0.6%åˆ°10.5%ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ä¸€ä¸ªé‡è¦è§è§£ï¼šåœ¨ç‰¹å®šé¢†åŸŸçš„é—®ç­”ä¸­ï¼Œä¸€ä¸ªæ”¯æŒé—®é¢˜å¾€å¾€æ¯”è¯¦ç»†çš„æŒ‡å¯¼æ­¥éª¤æ›´èƒ½å¸¦æ¥ç›Šå¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01526v1">PDF</a> Accepted by EMNLP 2025</p>
<p><strong>Summary</strong></p>
<p>é¢†åŸŸç‰¹å®šçš„é‡åŒ–æ¨ç†å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå¤æ‚é—®ç­”ï¼ˆQAï¼‰çš„é¢†åŸŸã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸“å®¶é—®é¢˜åˆ†è§£ï¼ˆEQDï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡é¢†åŸŸçŸ¥è¯†çš„ä½¿ç”¨ä¸è®¡ç®—æ•ˆç‡ã€‚EQDå»ºç«‹åœ¨ä¸¤æ­¥å¾®è°ƒæ¡†æ¶ä¸Šï¼Œç”±å¥–åŠ±å‡½æ•°å¼•å¯¼ï¼Œè¯¥å¥–åŠ±å‡½æ•°è¡¡é‡ç”Ÿæˆçš„å­é—®é¢˜åœ¨æé«˜é—®ç­”ç»“æœæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®ƒä»…éœ€è¦å‡ åƒä¸ªè®­ç»ƒæ ·æœ¬å’Œä¸€ä¸ªA100 GPUè¿›è¡Œå¾®è°ƒï¼Œæ¨ç†æ—¶é—´ä¸é›¶æ ·æœ¬æç¤ºç›¸å½“ã€‚åœ¨è´¢åŠ¡é¢†åŸŸï¼ŒEQDçš„è¡¨ç°ä¼˜äºæœ€å…ˆè¿›çš„é¢†åŸŸè°ƒæ•´æ¨¡å‹å’Œé«˜çº§æç¤ºç­–ç•¥ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è·¨ä¸åŒLLMçš„QAæ€§èƒ½æ–¹é¢æé«˜äº†0.6%è‡³10.5%ã€‚åˆ†æè¡¨æ˜ï¼Œåœ¨ç‰¹å®šé¢†åŸŸçš„é—®ç­”ä¸­ï¼Œä¸€ä¸ªæ”¯æŒé—®é¢˜å¾€å¾€æ¯”è¯¦ç»†çš„æŒ‡å¯¼æ­¥éª¤æ›´èƒ½å¸¦æ¥ç›Šå¤„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é¢†åŸŸç‰¹å®šçš„é‡åŒ–æ¨ç†æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå¤æ‚é—®ç­”çš„é¢†åŸŸã€‚</li>
<li>ä¸“å®¶é—®é¢˜åˆ†è§£ï¼ˆEQDï¼‰æ–¹æ³•æ—¨åœ¨å¹³è¡¡é¢†åŸŸçŸ¥è¯†çš„ä½¿ç”¨ä¸è®¡ç®—æ•ˆç‡ã€‚</li>
<li>EQDé€šè¿‡ä¸¤æ­¥å¾®è°ƒæ¡†æ¶å’Œå¥–åŠ±å‡½æ•°å¼•å¯¼ï¼Œå¥–åŠ±å‡½æ•°è¡¡é‡ç”Ÿæˆçš„å­é—®é¢˜åœ¨æé«˜é—®ç­”ç»“æœæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>EQDä»…éœ€è¦æœ‰é™çš„è®­ç»ƒæ ·æœ¬å’Œè®¡ç®—èµ„æºè¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”æ¨ç†æ—¶é—´ä¸é›¶æ ·æœ¬æç¤ºç›¸å½“ã€‚</li>
<li>åœ¨è´¢åŠ¡é¢†åŸŸçš„è¯„ä¼°ä¸­ï¼ŒEQDè¡¨ç°ä¼˜äºå…¶ä»–å…ˆè¿›æ–¹æ³•ï¼Œæé«˜äº†é—®ç­”æ€§èƒ½çš„0.6%è‡³10.5%ã€‚</li>
<li>åˆ†ææ˜¾ç¤ºï¼Œåœ¨ç‰¹å®šé¢†åŸŸçš„é—®ç­”ä¸­ï¼Œä¸€ä¸ªå…³é”®çš„æ”¯æŒé—®é¢˜æ¯”è¯¦ç»†çš„æŒ‡å¯¼æ­¥éª¤æ›´æœ‰ç›Šã€‚</li>
<li>EQDæ–¹æ³•ä¸ºé¢†åŸŸç‰¹å®šçš„é‡åŒ–æ¨ç†æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01526">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01526v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01526v1/page_2_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LVTINO-LAtent-Video-consisTency-INverse-sOlver-for-High-Definition-Video-Restoration"><a href="#LVTINO-LAtent-Video-consisTency-INverse-sOlver-for-High-Definition-Video-Restoration" class="headerlink" title="LVTINO: LAtent Video consisTency INverse sOlver for High Definition   Video Restoration"></a>LVTINO: LAtent Video consisTency INverse sOlver for High Definition   Video Restoration</h2><p><strong>Authors:Alessio Spagnoletti, AndrÃ©s Almansa, Marcelo Pereyra</strong></p>
<p>Computational imaging methods increasingly rely on powerful generative diffusion models to tackle challenging image restoration tasks. In particular, state-of-the-art zero-shot image inverse solvers leverage distilled text-to-image latent diffusion models (LDMs) to achieve unprecedented accuracy and perceptual quality with high computational efficiency. However, extending these advances to high-definition video restoration remains a significant challenge, due to the need to recover fine spatial detail while capturing subtle temporal dependencies. Consequently, methods that naively apply image-based LDM priors on a frame-by-frame basis often result in temporally inconsistent reconstructions. We address this challenge by leveraging recent advances in Video Consistency Models (VCMs), which distill video latent diffusion models into fast generators that explicitly capture temporal causality. Building on this foundation, we propose LVTINO, the first zero-shot or plug-and-play inverse solver for high definition video restoration with priors encoded by VCMs. Our conditioning mechanism bypasses the need for automatic differentiation and achieves state-of-the-art video reconstruction quality with only a few neural function evaluations, while ensuring strong measurement consistency and smooth temporal transitions across frames. Extensive experiments on a diverse set of video inverse problems show significant perceptual improvements over current state-of-the-art methods that apply image LDMs frame by frame, establishing a new benchmark in both reconstruction fidelity and computational efficiency. </p>
<blockquote>
<p>è®¡ç®—æˆåƒæ–¹æ³•è¶Šæ¥è¶Šä¾èµ–äºå¼ºå¤§çš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥åº”å¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„å›¾åƒæ¢å¤ä»»åŠ¡ã€‚ç‰¹åˆ«æ˜¯ï¼Œæœ€å…ˆè¿›çš„é›¶æ ·æœ¬å›¾åƒé€†æ±‚è§£å™¨åˆ©ç”¨æç‚¼çš„æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ä»¥æé«˜çš„è®¡ç®—æ•ˆç‡å®ç°äº†å‰æ‰€æœªæœ‰çš„ç²¾åº¦å’Œæ„ŸçŸ¥è´¨é‡ã€‚ç„¶è€Œï¼Œå°†è¿™äº›è¿›å±•æ‰©å±•åˆ°é«˜æ¸…è§†é¢‘æ¢å¤ä»ç„¶æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºéœ€è¦åœ¨æ¢å¤ç²¾ç»†ç©ºé—´ç»†èŠ‚çš„åŒæ—¶æ•æ‰å¾®å¦™çš„æ—¶é—´ä¾èµ–æ€§ã€‚å› æ­¤ï¼ŒåŸºäºå›¾åƒçš„æ–¹æ³•ï¼ˆä¾‹å¦‚åœ¨é€å¸§åŸºç¡€ä¸Šåº”ç”¨LDMå…ˆéªŒçš„æ–¹æ³•ï¼‰å¸¸å¸¸ä¼šå¯¼è‡´æ—¶é—´ä¸ä¸€è‡´çš„é‡æ„ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ï¼ˆVCMï¼‰çš„æœ€æ–°è¿›å±•æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè¯¥æ¨¡å‹å°†è§†é¢‘æ½œåœ¨æ‰©æ•£æ¨¡å‹æç‚¼ä¸ºå¿«é€Ÿç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿæ˜¾å¼æ•è·æ—¶é—´å› æœå…³ç³»ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†LVTINOï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªç”¨äºé«˜æ¸…è§†é¢‘æ¢å¤çš„é›¶æ ·æœ¬æˆ–å³æ’å³ç”¨é€†æ±‚è§£å™¨ï¼Œé€šè¿‡VCMç¼–ç å…ˆéªŒçŸ¥è¯†ã€‚æˆ‘ä»¬çš„æ¡ä»¶æœºåˆ¶ç»•è¿‡è‡ªåŠ¨å¾®åˆ†ï¼Œé€šè¿‡å‡ æ¬¡ç¥ç»åŠŸèƒ½è¯„ä¼°å³å¯å®ç°ä¸šç•Œé¢†å…ˆçš„è§†é¢‘é‡å»ºè´¨é‡ï¼ŒåŒæ—¶ç¡®ä¿å¼ºå¤§çš„æµ‹é‡ä¸€è‡´æ€§å’Œè·¨å¸§çš„å¹³æ»‘æ—¶é—´è¿‡æ¸¡ã€‚åœ¨å¤šç§è§†é¢‘åé—®é¢˜çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ˆå³åœ¨é€å¸§åº”ç”¨å›¾åƒLDMçš„æ–¹æ³•ï¼‰ï¼Œæ„ŸçŸ¥æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ï¼Œåœ¨é‡å»ºä¿çœŸåº¦å’Œè®¡ç®—æ•ˆç‡æ–¹é¢éƒ½æ ‘ç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01339v1">PDF</a> 23 pages, 12 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºåˆ©ç”¨è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ï¼ˆVCMsï¼‰è’¸é¦è§†é¢‘æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•æ¥è§£å†³é«˜æ¸…è§†é¢‘æ¢å¤é—®é¢˜ã€‚é€šè¿‡æ„å»ºLVTINOæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨VCMsç¼–ç å…ˆéªŒçŸ¥è¯†ï¼Œä½œä¸ºé›¶æ ·æœ¬æˆ–å³æ’å³ç”¨é€†æ±‚è§£å™¨ï¼Œé¦–æ¬¡å®ç°äº†é«˜æ¸…æ™°åº¦è§†é¢‘æ¢å¤ã€‚è¯¥æ–¹æ³•é¿å…äº†è‡ªåŠ¨å¾®åˆ†çš„éœ€æ±‚ï¼Œä»¥è¾ƒå°‘çš„ç¥ç»ç½‘ç»œè¯„ä¼°æ¬¡æ•°å®ç°äº†é¢†å…ˆçš„è§†é¢‘é‡å»ºè´¨é‡ï¼Œç¡®ä¿äº†å¼ºå¤§çš„æµ‹é‡ä¸€è‡´æ€§å’Œå¹³æ»‘çš„å¸§é—´è¿‡æ¸¡ã€‚å®éªŒè¡¨æ˜ï¼Œä¸é€å¸§åº”ç”¨å›¾åƒLDMçš„å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºä¿çœŸåº¦å’Œè®¡ç®—æ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æ„ŸçŸ¥æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†å›¾åƒæ¢å¤ä»»åŠ¡æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>é«˜æ¸…è§†é¢‘æ¢å¤é¢ä¸´æ¢å¤ç²¾ç»†ç©ºé—´ç»†èŠ‚å’Œæ•æ‰å¾®å¦™æ—¶é—´ä¾èµ–æ€§çš„æŒ‘æˆ˜ã€‚</li>
<li>å•çº¯åº”ç”¨åŸºäºå›¾åƒçš„LDMå…ˆéªŒçš„å¸§-å¸§æ–¹æ³•ä¼šå¯¼è‡´æ—¶é—´ä¸Šçš„ä¸ä¸€è‡´é‡å»ºã€‚</li>
<li>åˆ©ç”¨è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ï¼ˆVCMsï¼‰æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæ˜¾å¼æ•æ‰æ—¶é—´å› æœå…³ç³»ã€‚</li>
<li>LVTINOæ¨¡å‹æ˜¯é¦–ä¸ªåˆ©ç”¨VCMså…ˆéªŒçŸ¥è¯†çš„é›¶æ ·æœ¬æˆ–å³æ’å³ç”¨é€†æ±‚è§£å™¨ï¼Œç”¨äºé«˜æ¸…è§†é¢‘æ¢å¤ã€‚</li>
<li>LVTINOæ¨¡å‹å®ç°äº†é¢†å…ˆçš„è§†é¢‘é‡å»ºè´¨é‡ï¼Œå¹¶å…·æœ‰å¼ºå¤§çš„æµ‹é‡ä¸€è‡´æ€§å’Œå¹³æ»‘çš„å¸§é—´è¿‡æ¸¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01339">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01339v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01339v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="GRAD-Generative-Retrieval-Aligned-Demonstration-Sampler-for-Efficient-Few-Shot-Reasoning"><a href="#GRAD-Generative-Retrieval-Aligned-Demonstration-Sampler-for-Efficient-Few-Shot-Reasoning" class="headerlink" title="GRAD: Generative Retrieval-Aligned Demonstration Sampler for Efficient   Few-Shot Reasoning"></a>GRAD: Generative Retrieval-Aligned Demonstration Sampler for Efficient   Few-Shot Reasoning</h2><p><strong>Authors:Oussama Gabouj, Kamel Charaf, Ivan Zakazov, Nicolas Baldwin, Robert West</strong></p>
<p>Large Language Models (LLMs) achieve strong performance across diverse tasks, but their effectiveness often depends on the quality of the provided context. Retrieval-Augmented Generation (RAG) enriches prompts with external information, but its reliance on static databases constrains adaptability and can result in irrelevant demonstrations. In this work, we propose a Generative Retrieval-Aligned Demonstrator (GRAD), a dynamic demonstration-based approach where an LLM model is trained to generate input-specific concise demonstrations. By tailoring demonstrations to each input, our method offers better contextual support than traditional RAG approaches. We demonstrate the superiority of GRAD under budget constraints, where we limit both the number of tokens used per demonstration and the number of tokens used for the final output. Trained solely on a math dataset, GRAD consistently outperforms strong baselines on Qwen2.5-14B across mathematical reasoning and advanced STEM questions, highlighting GRADâ€™s robust generalization to out-of-distribution (OOD) domains such as physics, chemistry, and computer science. Furthermore, we show that demonstrations generated by trained smaller models can effectively guide larger target models, reducing training costs while maintaining competitive accuracy. Overall, this work introduces a scalable demonstration generator model presenting the first step toward a dynamic few-shot learning paradigm in resource-constrained settings. We release the code used for the project. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†å…¶æœ‰æ•ˆæ€§å¾€å¾€å–å†³äºæä¾›çš„ä¸Šä¸‹æ–‡çš„è´¨é‡ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡å¤–éƒ¨ä¿¡æ¯ä¸°å¯Œæç¤ºï¼Œä½†å…¶å¯¹é™æ€æ•°æ®åº“çš„ä¾èµ–é™åˆ¶äº†é€‚åº”æ€§ï¼Œå¹¶å¯èƒ½å¯¼è‡´å‡ºç°ä¸ç›¸å…³çš„æ¼”ç¤ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆçš„æ£€ç´¢å¯¹é½æ¼”ç¤ºå™¨ï¼ˆGRADï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŠ¨æ€æ¼”ç¤ºæ–¹æ³•ï¼Œå…¶ä¸­LLMæ¨¡å‹ç»è¿‡è®­ç»ƒä»¥ç”Ÿæˆé’ˆå¯¹è¾“å…¥çš„ç®€æ´æ¼”ç¤ºã€‚é€šè¿‡ä¸ºæ¯ä¸ªè¾“å…¥å®šåˆ¶æ¼”ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æä¾›ä¸Šä¸‹æ–‡æ”¯æŒæ–¹é¢ä¼˜äºä¼ ç»ŸRAGæ–¹æ³•ã€‚æˆ‘ä»¬åœ¨é¢„ç®—çº¦æŸä¸‹è¯æ˜äº†GRADçš„ä¼˜è¶Šæ€§ï¼Œæˆ‘ä»¬é™åˆ¶äº†æ¯ä¸ªæ¼”ç¤ºå’Œæœ€ç»ˆè¾“å‡ºæ‰€ä½¿ç”¨çš„ä»¤ç‰Œæ•°é‡ã€‚ä»…åœ¨æ•°å­¦æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒGRADåœ¨Qwen2.5-14Bä¸Šå§‹ç»ˆä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼Œåœ¨æ•°å­¦æ¨ç†å’Œé«˜çº§STEMé—®é¢˜æ–¹é¢è¡¨ç°çªå‡ºï¼Œçªæ˜¾äº†GRADå¯¹åˆ†å¸ƒå¤–ï¼ˆOODï¼‰é¢†åŸŸçš„ç¨³å¥æ¦‚æ‹¬èƒ½åŠ›ï¼Œå¦‚ç‰©ç†ã€åŒ–å­¦å’Œè®¡ç®—æœºç§‘å­¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œç”±è®­ç»ƒæœ‰ç´ çš„å°å‹æ¨¡å‹ç”Ÿæˆçš„æ¼”ç¤ºå¯ä»¥æœ‰æ•ˆåœ°æŒ‡å¯¼å¤§å‹ç›®æ ‡æ¨¡å‹ï¼Œåœ¨ä¿æŒç«äº‰å‡†ç¡®æ€§çš„åŒæ—¶é™ä½è®­ç»ƒæˆæœ¬ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™é¡¹å·¥ä½œä»‹ç»äº†ä¸€ç§å¯æ‰©å±•çš„æ¼”ç¤ºç”Ÿæˆå™¨æ¨¡å‹ï¼Œæœç€èµ„æºå—é™ç¯å¢ƒä¸­çš„åŠ¨æ€å°‘æ ·æœ¬å­¦ä¹ æ¨¡å¼è¿ˆå‡ºäº†ç¬¬ä¸€æ­¥ã€‚æˆ‘ä»¬å‘å¸ƒäº†ç”¨äºè¯¥é¡¹ç›®çš„ä»£ç ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01165v1">PDF</a> EMNLP 2025 (findings)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†å…¶æœ‰æ•ˆæ€§å¾€å¾€å–å†³äºæä¾›çš„ä¸Šä¸‹æ–‡è´¨é‡ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡å¤–éƒ¨ä¿¡æ¯ä¸°å¯Œæç¤ºï¼Œä½†å…¶å¯¹é™æ€æ•°æ®åº“çš„ä¾èµ–é™åˆ¶äº†é€‚åº”æ€§ï¼Œå¹¶å¯èƒ½å¯¼è‡´ä¸ç›¸å…³çš„æ¼”ç¤ºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆçš„æ£€ç´¢å¯¹é½æ¼”ç¤ºè€…ï¼ˆGRADï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŠ¨æ€æ¼”ç¤ºæ–¹æ³•ï¼Œå…¶ä¸­LLMæ¨¡å‹ç»è¿‡è®­ç»ƒä»¥é’ˆå¯¹æ¯ä¸ªè¾“å…¥ç”Ÿæˆç®€æ´çš„æ¼”ç¤ºã€‚é€šè¿‡ä¸ºæ¯ä¸ªè¾“å…¥å®šåˆ¶æ¼”ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸Šä¸‹æ–‡æ”¯æŒæ–¹é¢ä¼˜äºä¼ ç»ŸRAGæ–¹æ³•ã€‚åœ¨é¢„ç®—æœ‰é™çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è¯æ˜äº†GRADçš„ä¼˜è¶Šæ€§ï¼Œåœ¨æ¼”ç¤ºå’Œæœ€ç»ˆè¾“å‡ºçš„ä»¤ç‰Œæ•°é‡å—åˆ°é™åˆ¶çš„æƒ…å†µä¸‹ï¼Œä»…å‡­æ•°å­¦æ•°æ®é›†è®­ç»ƒçš„GRADåœ¨Qwen2.5-14Bä¸Šå§‹ç»ˆä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼Œåœ¨æ•°å­¦æ¨ç†å’Œé«˜çº§STEMé—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œç”±è®­ç»ƒè¿‡çš„è¾ƒå°æ¨¡å‹ç”Ÿæˆçš„æ¼”ç¤ºå¯ä»¥æœ‰æ•ˆåœ°æŒ‡å¯¼æ›´å¤§çš„ç›®æ ‡æ¨¡å‹ï¼Œåœ¨ä¿æŒç«äº‰æ€§çš„å‡†ç¡®æ€§çš„åŒæ—¶é™ä½è®­ç»ƒæˆæœ¬ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™é¡¹å·¥ä½œä»‹ç»äº†ä¸€ç§å¯æ‰©å±•çš„æ¼”ç¤ºç”Ÿæˆå™¨æ¨¡å‹ï¼Œæœç€èµ„æºå—é™ç¯å¢ƒä¸­çš„åŠ¨æ€å°‘æ ·æœ¬å­¦ä¹ èŒƒå¼è¿ˆå‡ºäº†ç¬¬ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsçš„æ•ˆåŠ›ä¾èµ–äºæä¾›çš„ä¸Šä¸‹æ–‡è´¨é‡ã€‚</li>
<li>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•å­˜åœ¨é™æ€æ•°æ®åº“ä¾èµ–çš„é—®é¢˜ã€‚</li>
<li>GRADæ˜¯ä¸€ç§åŠ¨æ€æ¼”ç¤ºæ–¹æ³•ï¼Œé’ˆå¯¹æ¯ä¸ªè¾“å…¥ç”Ÿæˆç‰¹å®šçš„æ¼”ç¤ºï¼Œæä¾›æ›´ä½³çš„ä¸Šä¸‹æ–‡æ”¯æŒã€‚</li>
<li>åœ¨é¢„ç®—æœ‰é™å’Œä»¤ç‰Œæ•°é‡å—é™çš„æƒ…å†µä¸‹ï¼ŒGRADåœ¨æ•°å­¦æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºåŸºçº¿ã€‚</li>
<li>GRADåœ¨è·¨æ•°å­¦æ¨ç†å’Œé«˜çº§STEMé—®é¢˜ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå°¤å…¶åœ¨ç‰©ç†ã€åŒ–å­¦å’Œè®¡ç®—æœºç§‘å­¦ç­‰OODé¢†åŸŸã€‚</li>
<li>ç”±è¾ƒå°æ¨¡å‹ç”Ÿæˆçš„æ¼”ç¤ºå¯ä»¥æœ‰æ•ˆåœ°æŒ‡å¯¼è¾ƒå¤§çš„ç›®æ ‡æ¨¡å‹ï¼Œé™ä½è®­ç»ƒæˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01165">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01165v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01165v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.01165v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="FusionAdapter-for-Few-Shot-Relation-Learning-in-Multimodal-Knowledge-Graphs"><a href="#FusionAdapter-for-Few-Shot-Relation-Learning-in-Multimodal-Knowledge-Graphs" class="headerlink" title="FusionAdapter for Few-Shot Relation Learning in Multimodal Knowledge   Graphs"></a>FusionAdapter for Few-Shot Relation Learning in Multimodal Knowledge   Graphs</h2><p><strong>Authors:Ran Liu, Yuan Fang, Xiaoli Li</strong></p>
<p>Multimodal Knowledge Graphs (MMKGs) incorporate various modalities, including text and images, to enhance entity and relation representations. Notably, different modalities for the same entity often present complementary and diverse information. However, existing MMKG methods primarily align modalities into a shared space, which tends to overlook the distinct contributions of specific modalities, limiting their performance particularly in low-resource settings. To address this challenge, we propose FusionAdapter for the learning of few-shot relationships (FSRL) in MMKG. FusionAdapter introduces (1) an adapter module that enables efficient adaptation of each modality to unseen relations and (2) a fusion strategy that integrates multimodal entity representations while preserving diverse modality-specific characteristics. By effectively adapting and fusing information from diverse modalities, FusionAdapter improves generalization to novel relations with minimal supervision. Extensive experiments on two benchmark MMKG datasets demonstrate that FusionAdapter achieves superior performance over state-of-the-art methods. </p>
<blockquote>
<p>å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±ï¼ˆMMKGsï¼‰ç»“åˆäº†å¤šç§æ¨¡å¼ï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œå›¾åƒï¼Œä»¥å¢å¼ºå®ä½“å’Œå…³ç³»è¡¨ç¤ºã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒåŒä¸€å®ä½“çš„ä¸åŒæ¨¡å¼é€šå¸¸å‘ˆç°äº’è¡¥å’Œå¤šæ ·åŒ–çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç°æœ‰çš„MMKGæ–¹æ³•ä¸»è¦å°†æ¨¡å¼å¯¹é½åˆ°å…±äº«ç©ºé—´ï¼Œè¿™å¾€å¾€å¿½è§†äº†ç‰¹å®šæ¨¡å¼çš„ç‹¬ç‰¹è´¡çŒ®ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½èµ„æºç¯å¢ƒä¸­é™åˆ¶äº†å…¶æ€§èƒ½ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬ä¸ºMMKGä¸­çš„å­¦ä¹ å°‘æ ·æœ¬å…³ç³»ï¼ˆFSRLï¼‰æå‡ºäº†FusionAdapterã€‚FusionAdapterå¼•å…¥äº†ï¼ˆ1ï¼‰ä¸€ä¸ªé€‚é…å™¨æ¨¡å—ï¼Œä½¿æ¯ä¸ªæ¨¡å¼éƒ½èƒ½æœ‰æ•ˆåœ°é€‚åº”æœªè§è¿‡çš„å…³ç³»ï¼›ï¼ˆ2ï¼‰ä¸€ç§èåˆç­–ç•¥ï¼Œåœ¨ä¿ç•™å¤šæ ·åŒ–æ¨¡å¼ç‰¹å®šç‰¹æ€§çš„åŒæ—¶ï¼Œèåˆäº†å¤šæ¨¡å¼å®ä½“è¡¨ç¤ºã€‚é€šè¿‡æœ‰æ•ˆåœ°é€‚åº”å’Œèåˆæ¥è‡ªå¤šç§æ¨¡å¼çš„ä¿¡æ¯ï¼ŒFusionAdapteråœ¨å°‘é‡ç›‘ç£ä¸‹æé«˜äº†å¯¹æ–°å‹å…³ç³»çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨ä¸¤ä¸ªåŸºå‡†MMKGæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒFusionAdapteråœ¨æœ€æ–°æŠ€æœ¯æ–¹é¢å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00894v1">PDF</a> Archived paper</p>
<p><strong>Summary</strong><br>    å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±ï¼ˆMMKGï¼‰èåˆå¤šç§æ¨¡æ€ï¼Œå¦‚æ–‡æœ¬å’Œå›¾åƒï¼Œä»¥å¢å¼ºå®ä½“å’Œå…³ç³»è¡¨ç¤ºã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å°†ä¸åŒæ¨¡æ€å¯¹é½åˆ°å…±äº«ç©ºé—´ï¼Œè¿™å¿½ç•¥äº†ç‰¹å®šæ¨¡æ€çš„ç‹¬ç‰¹è´¡çŒ®ï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹é™åˆ¶äº†æ€§èƒ½ã€‚ä¸ºè§£å†³æ­¤æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºç”¨äºå¤šæ¨¡æ€çŸ¥è¯†å›¾è°±ä¸­å°‘æ ·æœ¬å…³ç³»å­¦ä¹ çš„FusionAdapteræ–¹æ³•ã€‚è¯¥æ–¹æ³•å¼•å…¥é€‚é…å™¨æ¨¡å—ï¼Œä½¿æ¯ä¸ªæ¨¡æ€éƒ½èƒ½æœ‰æ•ˆé€‚åº”æœªè§è¿‡çš„å…³ç³»ï¼Œå¹¶æå‡ºèåˆç­–ç•¥ï¼Œæ•´åˆå¤šæ¨¡æ€å®ä½“è¡¨ç¤ºçš„åŒæ—¶ä¿ç•™ä¸åŒæ¨¡æ€çš„ç‰¹å®šç‰¹å¾ã€‚é€šè¿‡é€‚åº”å’Œèåˆæ¥è‡ªä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼ŒFusionAdapteråœ¨å°‘é‡ç›‘ç£ä¸‹æé«˜äº†å¯¹æ–°å‹å…³ç³»çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒFusionAdapteråœ¨åŸºå‡†MMKGæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±ï¼ˆMMKGï¼‰ç»“åˆå¤šç§æ¨¡æ€ä»¥å¢å¼ºå®ä½“å’Œå…³ç³»è¡¨ç¤ºã€‚</li>
<li>ç°æœ‰MMKGæ–¹æ³•ä¸»è¦å°†ä¸åŒæ¨¡æ€å¯¹é½åˆ°å…±äº«ç©ºé—´ï¼Œå¿½ç•¥äº†ç‰¹å®šæ¨¡æ€çš„ç‹¬ç‰¹è´¡çŒ®ã€‚</li>
<li>FusionAdapteré€šè¿‡å¼•å…¥é€‚é…å™¨æ¨¡å—ï¼Œä½¿æ¯ä¸ªæ¨¡æ€éƒ½èƒ½æœ‰æ•ˆé€‚åº”æœªè§è¿‡çš„å…³ç³»ã€‚</li>
<li>FusionAdapteræå‡ºèåˆç­–ç•¥ï¼Œæ•´åˆå¤šæ¨¡æ€å®ä½“è¡¨ç¤ºçš„åŒæ—¶ä¿ç•™ä¸åŒæ¨¡æ€çš„ç‰¹å®šç‰¹å¾ã€‚</li>
<li>FusionAdapteræé«˜äº†å¯¹æ–°å‹å…³ç³»çš„æ³›åŒ–èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒFusionAdapteråœ¨åŸºå‡†MMKGæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00894">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00894v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00894v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00894v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00894v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00894v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Agent-Fine-tuning-through-Distillation-for-Domain-specific-LLMs-in-Microdomains"><a href="#Agent-Fine-tuning-through-Distillation-for-Domain-specific-LLMs-in-Microdomains" class="headerlink" title="Agent Fine-tuning through Distillation for Domain-specific LLMs in   Microdomains"></a>Agent Fine-tuning through Distillation for Domain-specific LLMs in   Microdomains</h2><p><strong>Authors:Yawen Xue, Masaya Tsunokake, Yuta Koreeda, Ekant Muljibhai Amin, Takashi Sumiyoshi, Yasuhiro Sogawa</strong></p>
<p>Agentic large language models (LLMs) have become prominent for autonomously interacting with external environments and performing multi-step reasoning tasks. Most approaches leverage these capabilities via in-context learning with few-shot prompts, but this often results in lengthy inputs and higher computational costs. Agent fine-tuning offers an alternative by enabling LLMs to internalize procedural reasoning and domain-specific knowledge through training on relevant data and demonstration trajectories. While prior studies have focused on general domains, their effectiveness in specialized technical microdomains remains unclear. This paper explores agent fine-tuning for domain adaptation within Hitachiâ€™s JP1 middleware, a microdomain for specialized IT operations. We fine-tuned LLMs using JP1-specific datasets derived from domain manuals and distilled reasoning trajectories generated by LLMs themselves, enhancing decision making accuracy and search efficiency. During inference, we used an agentic prompt with retrieval-augmented generation and introduced a context-answer extractor to improve information relevance. On JP1 certification exam questions, our method achieved a 14% performance improvement over the base model, demonstrating the potential of agent fine-tuning for domain-specific reasoning in complex microdomains. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªä¸»ä¸å¤–éƒ¨ç¯å¢ƒä¸­äº¤äº’å¹¶æ‰§è¡Œå¤šæ­¥éª¤æ¨ç†ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚å¤§å¤šæ•°æ–¹æ³•é€šè¿‡åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆcontext learningï¼‰å’Œå°‘é‡çš„æç¤ºï¼ˆfew-shot promptsï¼‰æ¥å‘æŒ¥è¿™äº›èƒ½åŠ›ï¼Œä½†è¿™é€šå¸¸ä¼šå¯¼è‡´è¾“å…¥å†—é•¿å¹¶å¢åŠ è®¡ç®—æˆæœ¬ã€‚é€šè¿‡é’ˆå¯¹ç›¸å…³æ•°æ®å’Œåº”ç”¨è½¨è¿¹è¿›è¡Œè®­ç»ƒï¼ŒAgent fine-tuningï¼ˆæ¨¡å‹å¾®è°ƒï¼‰ä¸ºLLMæä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆï¼Œä½¿å…¶èƒ½å¤Ÿå†…åŒ–ç¨‹åºæ¨ç†å’Œç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ã€‚è™½ç„¶å…ˆå‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨é€šç”¨é¢†åŸŸï¼Œä½†å®ƒä»¬å¯¹ç‰¹å®šæŠ€æœ¯å¾®åŸŸçš„æ•ˆç”¨å°šä¸æ¸…æ¥šã€‚æœ¬æ–‡æ¢è®¨äº†é’ˆå¯¹æ—¥ç«‹JP1ä¸­é—´ä»¶çš„åŸŸé€‚åº”çš„Agent fine-tuningæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä¸“ä¸šITæ“ä½œçš„å¾®åŸŸã€‚æˆ‘ä»¬ä½¿ç”¨ä»åŸŸæ‰‹å†Œæ´¾ç”Ÿçš„JP1ç‰¹å®šæ•°æ®é›†å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œå¹¶ä½¿ç”¨LLMæœ¬èº«ç”Ÿæˆçš„æ¨ç†è½¨è¿¹è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜å†³ç­–å‡†ç¡®æ€§å’Œæœç´¢æ•ˆç‡ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¸¦æ£€ç´¢å¢å¼ºçš„ç”Ÿæˆå¼çš„ä»£ç†æç¤ºï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªä¸Šä¸‹æ–‡ç­”æ¡ˆæå–å™¨ä»¥æé«˜ä¿¡æ¯çš„ç›¸å…³æ€§ã€‚åœ¨JP1è®¤è¯è€ƒè¯•é—®é¢˜ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºåŸºç¡€æ¨¡å‹å®ç°äº†14%çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„å¤æ‚å¾®åŸŸä¸­çš„æ¨ç†çš„Agent fine-tuningæ–¹æ³•çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00482v1">PDF</a> Accepted by AIxB 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªä¸»ä¸å¤–éƒ¨äº¤äº’å’Œå¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚å¤§å¤šæ•°æ–¹æ³•é€šè¿‡å°‘æ•°ç¤ºä¾‹æç¤ºè¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ æ¥åˆ©ç”¨è¿™äº›èƒ½åŠ›ï¼Œä½†è¿™å¸¸å¸¸å¯¼è‡´å†—é•¿çš„è¾“å…¥å’Œæ›´é«˜çš„è®¡ç®—æˆæœ¬ã€‚Agent fine-tuningé€šè¿‡è®­ç»ƒLLMåœ¨ç›¸å…³æ•°æ®å’Œæ¼”ç¤ºè½¨è¿¹ä¸Šå†…åŒ–ç¨‹åºæ¨ç†å’Œé¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œæä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶é›†ä¸­åœ¨ä¸€èˆ¬é¢†åŸŸï¼Œä½†åœ¨ä¸“ä¸šæŠ€æœ¯å¾®é¢†åŸŸå†…çš„æœ‰æ•ˆæ€§ä»ä¸æ˜ç¡®ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†é’ˆå¯¹æ—¥ç«‹å…¬å¸JP1ä¸­é—´ä»¶çš„é¢†åŸŸè‡ªé€‚åº”çš„agent fine-tuningï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä¸“ä¸šITæ“ä½œçš„å¾®é¢†åŸŸã€‚é€šè¿‡ä½¿ç”¨JP1ç‰¹å®šæ•°æ®é›†å’Œç”±LLMæœ¬èº«ç”Ÿæˆçš„ç²¾ç‚¼æ¨ç†è½¨è¿¹å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œæé«˜äº†å†³ç­–å‡†ç¡®æ€§å’Œæœç´¢æ•ˆç‡ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†å¸¦æ£€ç´¢å¢å¼ºç”ŸæˆåŠŸèƒ½çš„agenticæç¤ºï¼Œå¹¶å¼•å…¥äº†ä¸Šä¸‹æ–‡ç­”æ¡ˆæå–å™¨ä»¥æé«˜ä¿¡æ¯ç›¸å…³æ€§ã€‚åœ¨JP1è®¤è¯è€ƒè¯•é—®é¢˜ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºåŸºç¡€æ¨¡å‹å®ç°äº†14%çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†agent fine-tuningåœ¨å¤æ‚å¾®é¢†åŸŸä¸­çš„é¢†åŸŸç‰¹å®šæ¨ç†æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·å¤‡è‡ªä¸»ä¸å¤–éƒ¨äº¤äº’åŠå¤šæ­¥æ¨ç†ä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡å°‘æ•°ç¤ºä¾‹æç¤ºè¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ è™½èƒ½åˆ©ç”¨è¿™äº›èƒ½åŠ›ï¼Œä½†ä¼šå¯¼è‡´å†—é•¿è¾“å…¥å’Œè®¡ç®—æˆæœ¬å¢åŠ ã€‚</li>
<li>Agent fine-tuningä½¿LLMèƒ½å¤Ÿåœ¨ç›¸å…³æ•°æ®å’Œæ¼”ç¤ºè½¨è¿¹ä¸Šå†…åŒ–ç¨‹åºæ¨ç†å’Œé¢†åŸŸçŸ¥è¯†ã€‚</li>
<li>åœ¨ä¸“ä¸šæŠ€æœ¯å¾®é¢†åŸŸçš„æœ‰æ•ˆæ€§å°šæœªæ˜ç¡®ï¼Œæœ¬ç ”ç©¶æ¢ç´¢äº†é’ˆå¯¹JP1ä¸­é—´ä»¶çš„agent fine-tuningåº”ç”¨ã€‚</li>
<li>ä½¿ç”¨JP1ç‰¹å®šæ•°æ®é›†å’ŒLLMç”Ÿæˆçš„æ¨ç†è½¨è¿¹å¾®è°ƒæ¨¡å‹ï¼Œæé«˜äº†å†³ç­–å‡†ç¡®æ€§å’Œæœç´¢æ•ˆç‡ã€‚</li>
<li>åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨å¸¦æ£€ç´¢å¢å¼ºç”ŸæˆåŠŸèƒ½çš„agenticæç¤ºå’Œä¸Šä¸‹æ–‡ç­”æ¡ˆæå–å™¨ï¼Œå¢å¼ºäº†ä¿¡æ¯ç›¸å…³æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00482">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00482v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00482v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00482v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00482v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00482v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2510.00482v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="RS-OOD-A-Vision-Language-Augmented-Framework-for-Out-of-Distribution-Detection-in-Remote-Sensing"><a href="#RS-OOD-A-Vision-Language-Augmented-Framework-for-Out-of-Distribution-Detection-in-Remote-Sensing" class="headerlink" title="RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution   Detection in Remote Sensing"></a>RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution   Detection in Remote Sensing</h2><p><strong>Authors:Chenhao Wang, Yingrui Ji, Yu Meng, Yunjian Zhang, Yao Zhu</strong></p>
<p>Out-of-distribution (OOD) detection represents a critical challenge in remote sensing applications, where reliable identification of novel or anomalous patterns is essential for autonomous monitoring, disaster response, and environmental assessment. Despite remarkable progress in OOD detection for natural images, existing methods and benchmarks remain poorly suited to remote sensing imagery due to data scarcity, complex multi-scale scene structures, and pronounced distribution shifts. To this end, we propose RS-OOD, a novel framework that leverages remote sensing-specific vision-language modeling to enable robust few-shot OOD detection. Our approach introduces three key innovations: spatial feature enhancement that improved scene discrimination, a dual-prompt alignment mechanism that cross-verifies scene context against fine-grained semantics for spatial-semantic consistency, and a confidence-guided self-training loop that dynamically mines pseudo-labels to expand training data without manual annotation. RS-OOD consistently outperforms existing methods across multiple remote sensing benchmarks and enables efficient adaptation with minimal labeled data, demonstrating the critical value of spatial-semantic integration. </p>
<blockquote>
<p>åœ¨é¥æ„Ÿåº”ç”¨ä¸­ï¼Œå¼‚å¸¸åˆ†å¸ƒï¼ˆOut-of-Distributionï¼Œç®€ç§°OODï¼‰æ£€æµ‹æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚åœ¨æ–°çš„æˆ–å¼‚å¸¸æ¨¡å¼çš„æœ‰æ•ˆè¯†åˆ«ä¸­ï¼Œè¿™å¯¹è‡ªä¸»ç›‘æ§ã€ç¾å®³å“åº”å’Œç¯å¢ƒè¯„ä¼°è‡³å…³é‡è¦ã€‚å°½ç®¡åœ¨è‡ªç„¶å›¾åƒçš„OODæ£€æµ‹æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç”±äºæ•°æ®ç¨€ç¼ºã€å¤æ‚çš„åœºæ™¯ç»“æ„ä»¥åŠæ˜æ˜¾çš„åˆ†å¸ƒè½¬ç§»ç­‰é—®é¢˜ï¼Œç°æœ‰çš„æ–¹æ³•å’ŒåŸºå‡†æµ‹è¯•å¹¶ä¸é€‚åˆé¥æ„Ÿå›¾åƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†RS-OODï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨é¥æ„Ÿç‰¹å®šçš„è§†è§‰è¯­è¨€å»ºæ¨¡æ¥å®ç°ç¨³å¥çš„å°‘é‡å¼‚å¸¸åˆ†å¸ƒæ£€æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹ï¼šç©ºé—´ç‰¹å¾å¢å¼ºæé«˜äº†åœºæ™¯é‰´åˆ«èƒ½åŠ›ï¼›åŒæç¤ºå¯¹é½æœºåˆ¶é€šè¿‡åœºæ™¯ä¸Šä¸‹æ–‡ä¸ç²¾ç»†è¯­ä¹‰çš„äº¤å‰éªŒè¯å®ç°ç©ºé—´è¯­ä¹‰ä¸€è‡´æ€§ï¼›ä»¥åŠåŸºäºç½®ä¿¡åº¦çš„è‡ªè®­ç»ƒå¾ªç¯å¯ä»¥åŠ¨æ€æŒ–æ˜ä¼ªæ ‡ç­¾ä»¥æ‰©å……è®­ç»ƒæ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚åœ¨å¤šä¸ªé¥æ„ŸåŸºå‡†æµ‹è¯•ä¸­ï¼ŒRS-OODå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨æœ€å°‘çš„æ ‡è®°æ•°æ®ä¸‹å®ç°é«˜æ•ˆé€‚åº”ï¼Œè¯æ˜äº†ç©ºé—´è¯­ä¹‰é›†æˆçš„å…³é”®ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.02273v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>åœ¨é¥æ„Ÿåº”ç”¨ä¸­ï¼Œå¯¹æ–°å‹æˆ–å¼‚å¸¸æ¨¡å¼çš„å¯é è¯†åˆ«å¯¹äºè‡ªä¸»ç›‘æ§ã€ç¾å®³å“åº”å’Œç¯å¢ƒè¯„ä¼°è‡³å…³é‡è¦ï¼Œå› æ­¤ï¼Œæ–°å‹åˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ£€æµ‹æ˜¯ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚å°½ç®¡åœ¨è‡ªç„¶å›¾åƒä¸­çš„OODæ£€æµ‹å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç”±äºæ•°æ®ç¨€ç¼ºã€å¤æ‚çš„å¤šå°ºåº¦åœºæ™¯ç»“æ„å’Œæ˜æ˜¾çš„åˆ†å¸ƒåç§»ç­‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å’ŒåŸºå‡†æµ‹è¯•å¯¹é¥æ„Ÿå›¾åƒå¹¶ä¸é€‚ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†RS-OODæ¡†æ¶ï¼Œåˆ©ç”¨é¥æ„Ÿä¸“ç”¨è§†è§‰è¯­è¨€å»ºæ¨¡ï¼Œå®ç°ç¨³å¥çš„å°‘æ•°é•œå¤´OODæ£€æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šç©ºé—´ç‰¹å¾å¢å¼ºæé«˜äº†åœºæ™¯é‰´åˆ«èƒ½åŠ›ï¼›åŒæç¤ºå¯¹é½æœºåˆ¶é€šè¿‡åœºæ™¯ä¸Šä¸‹æ–‡ä¸ç²¾ç»†è¯­ä¹‰å¯¹æ¯”éªŒè¯ç©ºé—´è¯­ä¹‰ä¸€è‡´æ€§ï¼›ä¿¡å¿ƒå¼•å¯¼çš„è‡ªæˆ‘è®­ç»ƒå¾ªç¯åŠ¨æ€æŒ–æ˜ä¼ªæ ‡ç­¾æ¥æ‰©å±•è®­ç»ƒæ•°æ®è€Œæ— éœ€æ‰‹åŠ¨æ³¨é‡Šã€‚RS-OODåœ¨å¤šä¸ªé¥æ„ŸåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†æœ‰æ•ˆçš„é€‚åº”ï¼Œè¯æ˜äº†ç©ºé—´è¯­ä¹‰æ•´åˆçš„å…³é”®ä»·å€¼ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>OODæ£€æµ‹åœ¨é¥æ„Ÿåº”ç”¨ä¸­è‡³å…³é‡è¦ï¼Œç”¨äºè¯†åˆ«æ–°å‹æˆ–å¼‚å¸¸æ¨¡å¼ï¼Œæœ‰åŠ©äºè‡ªä¸»ç›‘æ§ã€ç¾å®³å“åº”å’Œç¯å¢ƒè¯„ä¼°ã€‚</li>
<li>ç°æœ‰OODæ£€æµ‹æ–¹æ³•å’ŒåŸºå‡†æµ‹è¯•å› æ•°æ®ç¨€ç¼ºã€å¤æ‚åœºæ™¯ç»“æ„å’Œåˆ†å¸ƒåç§»ç­‰é—®é¢˜ï¼Œåœ¨é¥æ„Ÿå›¾åƒä¸Šè¡¨ç°ä¸ä½³ã€‚</li>
<li>RS-OODæ¡†æ¶åˆ©ç”¨é¥æ„Ÿä¸“ç”¨è§†è§‰è¯­è¨€å»ºæ¨¡å®ç°ç¨³å¥çš„å°‘æ•°é•œå¤´OODæ£€æµ‹ã€‚</li>
<li>RS-OODå¼•å…¥ç©ºé—´ç‰¹å¾å¢å¼ºï¼Œæé«˜åœºæ™¯é‰´åˆ«èƒ½åŠ›ã€‚</li>
<li>åŒæç¤ºå¯¹é½æœºåˆ¶é€šè¿‡åœºæ™¯ä¸Šä¸‹æ–‡ä¸ç²¾ç»†è¯­ä¹‰å¯¹æ¯”ï¼ŒéªŒè¯ç©ºé—´è¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>ä¿¡å¿ƒå¼•å¯¼çš„è‡ªæˆ‘è®­ç»ƒå¾ªç¯èƒ½åŠ¨æ€æŒ–æ˜ä¼ªæ ‡ç­¾ï¼Œæ‰©å±•è®­ç»ƒæ•°æ®ï¼Œå‡å°‘å¯¹æ‰‹åŠ¨æ³¨é‡Šçš„ä¾èµ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.02273">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2509.02273v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2509.02273v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2509.02273v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="One-Policy-to-Run-Them-All-an-End-to-end-Learning-Approach-to-Multi-Embodiment-Locomotion"><a href="#One-Policy-to-Run-Them-All-an-End-to-end-Learning-Approach-to-Multi-Embodiment-Locomotion" class="headerlink" title="One Policy to Run Them All: an End-to-end Learning Approach to   Multi-Embodiment Locomotion"></a>One Policy to Run Them All: an End-to-end Learning Approach to   Multi-Embodiment Locomotion</h2><p><strong>Authors:Nico Bohlinger, Grzegorz Czechmanowski, Maciej Krupka, Piotr Kicki, Krzysztof Walas, Jan Peters, Davide Tateo</strong></p>
<p>Deep Reinforcement Learning techniques are achieving state-of-the-art results in robust legged locomotion. While there exists a wide variety of legged platforms such as quadruped, humanoids, and hexapods, the field is still missing a single learning framework that can control all these different embodiments easily and effectively and possibly transfer, zero or few-shot, to unseen robot embodiments. We introduce URMA, the Unified Robot Morphology Architecture, to close this gap. Our framework brings the end-to-end Multi-Task Reinforcement Learning approach to the realm of legged robots, enabling the learned policy to control any type of robot morphology. The key idea of our method is to allow the network to learn an abstract locomotion controller that can be seamlessly shared between embodiments thanks to our morphology-agnostic encoders and decoders. This flexible architecture can be seen as a potential first step in building a foundation model for legged robot locomotion. Our experiments show that URMA can learn a locomotion policy on multiple embodiments that can be easily transferred to unseen robot platforms in simulation and the real world. </p>
<blockquote>
<p>æ·±åº¦å¼ºåŒ–å­¦ä¹ æŠ€æœ¯æ­£åœ¨å®ç°æœ€å…ˆè¿›çš„ç¨³å¥çš„è…¿è¶³è¿åŠ¨ç»“æœã€‚å°½ç®¡å­˜åœ¨å¤šç§è…¿è¶³å¹³å°ï¼Œå¦‚å››è¶³ã€äººå½¢å’Œå…­è¶³ç­‰ï¼Œä½†è¯¥é¢†åŸŸä»ç„¶ç¼ºå°‘ä¸€ä¸ªå•ä¸€çš„å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿè½»æ¾æœ‰æ•ˆåœ°æ§åˆ¶æ‰€æœ‰è¿™äº›ä¸åŒçš„ä½“ç°å½¢å¼ï¼Œå¹¶å¯èƒ½ä»¥é›¶æˆ–å°‘é‡æ ·æœ¬çš„æ–¹å¼è½¬ç§»åˆ°æœªè§è¿‡çš„æœºå™¨äººä½“ç°å½¢å¼ã€‚æˆ‘ä»¬å¼•å…¥URMAï¼Œå³ç»Ÿä¸€æœºå™¨äººå½¢æ€æ¶æ„ï¼Œä»¥å¼¥è¡¥è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†ç«¯åˆ°ç«¯å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¼•å…¥åˆ°è…¿è¶³æœºå™¨äººçš„é¢†åŸŸï¼Œä½¿å­¦ä¹ åˆ°çš„ç­–ç•¥èƒ½å¤Ÿæ§åˆ¶ä»»ä½•ç±»å‹çš„æœºå™¨äººå½¢æ€ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å…³é”®æ€æƒ³æ˜¯è®©ç½‘ç»œå­¦ä¹ ä¸€ä¸ªæŠ½è±¡çš„è¿åŠ¨æ§åˆ¶å™¨ï¼Œç”±äºæˆ‘ä»¬çš„å½¢æ€æ— å…³ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œè¯¥æ§åˆ¶å™¨å¯ä»¥åœ¨å„ç§å½¢æ€ä¹‹é—´æ— ç¼å…±äº«ã€‚è¿™ç§çµæ´»æ¶æ„å¯ä»¥è¢«è§†ä¸ºæ„å»ºè…¿è¶³æœºå™¨äººè¿åŠ¨åŸºç¡€æ¨¡å‹çš„ä¸€ä¸ªæ½œåœ¨çš„ç¬¬ä¸€æ­¥ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒURMAå¯ä»¥åœ¨å¤šç§å½¢æ€ä¸Šå­¦ä¹ è¿åŠ¨ç­–ç•¥ï¼Œå¹¶å¯ä»¥è½»æ¾å°†å…¶è½¬ç§»åˆ°æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œä¸­çš„æœªçŸ¥æœºå™¨äººå¹³å°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.06366v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç»Ÿä¸€æœºå™¨äººå½¢æ€æ¶æ„ï¼ˆURMAï¼‰çš„å‡ºç°å¡«è¡¥äº†ä¸åŒå½¢æ€è…¿å¼æœºå™¨äººå­¦ä¹ æ§åˆ¶çš„ç©ºç™½ã€‚URMAé‡‡ç”¨ç«¯åˆ°ç«¯å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ ï¼Œä½¿å¾—å­¦ä¹ åˆ°çš„ç­–ç•¥å¯ä»¥æ§åˆ¶ä»»ä½•ç±»å‹çš„æœºå™¨äººå½¢æ€ã€‚å…¶å…³é”®æ€æƒ³åœ¨äºå…è®¸ç½‘ç»œå­¦ä¹ ä¸€ä¸ªæŠ½è±¡çš„æ­¥æ€æ§åˆ¶å™¨ï¼Œå€ŸåŠ©å½¢æ€æ— å…³çš„ç¼–ç å™¨å’Œè§£ç å™¨åœ¨ä¸åŒçš„å½¢æ€ä¹‹é—´æ— ç¼å…±äº«ã€‚è¯¥çµæ´»çš„æ¶æ„å¯è¢«è§†ä¸ºæ„å»ºè…¿å¼æœºå™¨äººè¿åŠ¨åŸºç¡€æ¨¡å‹çš„ç¬¬ä¸€æ­¥ã€‚å®éªŒè¡¨æ˜ï¼ŒURMAå¯ä»¥åœ¨å¤šç§å½¢æ€ä¸Šå­¦ä¹ æ­¥æ€ç­–ç•¥ï¼Œå¹¶è½»æ¾åº”ç”¨äºä»¿çœŸå’Œç°å®ä¸–ç•Œä¸­æœªè§è¿‡çš„æ–°å¹³å°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>URMAä¸ºä¸åŒå½¢æ€çš„è…¿å¼æœºå™¨äººæä¾›äº†ç»Ÿä¸€çš„å­¦ä¹ æ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„Multi-Taskå¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚</li>
<li>URMAå…è®¸ç½‘ç»œå­¦ä¹ æŠ½è±¡çš„æ­¥æ€æ§åˆ¶å™¨ï¼Œé€‚åº”å¤šç§æœºå™¨äººå½¢æ€ã€‚</li>
<li>å€ŸåŠ©å½¢æ€æ— å…³çš„ç¼–ç å™¨å’Œè§£ç å™¨ï¼ŒURMAå®ç°äº†åœ¨ä¸åŒå½¢æ€é—´çš„æ— ç¼å…±äº«æ§åˆ¶ç­–ç•¥ã€‚</li>
<li>URMAçš„çµæ´»æ¶æ„è¢«è§†ä¸ºæ„å»ºè…¿å¼æœºå™¨äººè¿åŠ¨åŸºç¡€æ¨¡å‹çš„é‡è¦ä¸€æ­¥ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºURMAåœ¨ä»¿çœŸå’Œç°å®ä¸­å‡èƒ½æœ‰æ•ˆåº”ç”¨äºæ–°å¹³å°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.06366">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2409.06366v4/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2409.06366v4/page_3_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Meta-Transfer-Derm-Diagnosis-Exploring-Few-Shot-Learning-and-Transfer-Learning-for-Skin-Disease-Classification-in-Long-Tail-Distribution"><a href="#Meta-Transfer-Derm-Diagnosis-Exploring-Few-Shot-Learning-and-Transfer-Learning-for-Skin-Disease-Classification-in-Long-Tail-Distribution" class="headerlink" title="Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer   Learning for Skin Disease Classification in Long-Tail Distribution"></a>Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer   Learning for Skin Disease Classification in Long-Tail Distribution</h2><p><strong>Authors:Zeynep Ã–zdemir, Hacer Yalim Keles, Ã–mer Ã–zgÃ¼r TanrÄ±Ã¶ver</strong></p>
<p>Building accurate models for rare skin diseases remains challenging due to the lack of sufficient labeled data and the inherently long-tailed distribution of available samples. These issues are further complicated by inconsistencies in how datasets are collected and their varying objectives. To address these challenges, we compare three learning strategies: episodic learning, supervised transfer learning, and contrastive self-supervised pretraining, within a few-shot learning framework. We evaluate five training setups on three benchmark datasets: ISIC2018, Derm7pt, and SD-198. Our findings show that traditional transfer learning approaches, particularly those based on MobileNetV2 and Vision Transformer (ViT) architectures, consistently outperform episodic and self-supervised methods as the number of training examples increases. When combined with batch-level data augmentation techniques such as MixUp, CutMix, and ResizeMix, these models achieve state-of-the-art performance on the SD-198 and Derm7pt datasets, and deliver highly competitive results on ISIC2018. All the source codes related to this work will be made publicly available soon at the provided URL. </p>
<blockquote>
<p>é’ˆå¯¹ç½•è§çš®è‚¤ç–¾ç—…å»ºç«‹ç²¾ç¡®æ¨¡å‹ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºç¼ºä¹è¶³å¤Ÿçš„æ ‡è®°æ•°æ®ä»¥åŠå¯ç”¨æ ·æœ¬çš„å›ºæœ‰é•¿å°¾åˆ†å¸ƒã€‚è¿™äº›é—®é¢˜è¿˜å› æ•°æ®é›†æ”¶é›†æ–¹å¼çš„ä¸ä¸€è‡´å’Œå…¶ä¸åŒç›®æ ‡è€Œè¿›ä¸€æ­¥å¤æ‚åŒ–ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬åœ¨å°æ ·æœ¬å­¦ä¹ æ¡†æ¶å†…æ¯”è¾ƒäº†ä¸‰ç§å­¦ä¹ ç­–ç•¥ï¼šæƒ…æ™¯å­¦ä¹ ã€ç›‘ç£è¿ç§»å­¦ä¹ å’Œå¯¹æ¯”è‡ªç›‘ç£é¢„è®­ç»ƒã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆISIC2018ã€Derm7ptå’ŒSD-198ï¼‰ä¸Šè¯„ä¼°äº†äº”ç§è®­ç»ƒè®¾ç½®ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œéšç€è®­ç»ƒæ ·æœ¬æ•°é‡çš„å¢åŠ ï¼ŒåŸºäºMobileNetV2å’ŒVision Transformerï¼ˆViTï¼‰æ¶æ„çš„ä¼ ç»Ÿè¿ç§»å­¦ä¹ æ–¹æ³•å§‹ç»ˆè¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†æƒ…æ™¯å­¦ä¹ å’Œè‡ªç›‘ç£æ–¹æ³•ã€‚ç»“åˆæ‰¹é‡çº§åˆ«çš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼ˆå¦‚MixUpã€CutMixå’ŒResizeMixï¼‰ï¼Œè¿™äº›æ¨¡å‹åœ¨SD-198å’ŒDerm7ptæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨ISIC2018ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚ä¸æ­¤å·¥ä½œç›¸å…³çš„æ‰€æœ‰æºä»£ç å¾ˆå¿«å°†åœ¨æä¾›çš„URLä¸Šå…¬å¼€å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.16814v2">PDF</a> This is the accepted version of the article to appear in IEEE Journal   of Biomedical and Health Informatics. DOI: 10.1109&#x2F;JBHI.2025.3615479</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç½•è§çš®è‚¤ç–¾ç—…å»ºæ¨¡çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç¼ºä¹è¶³å¤Ÿçš„æ ‡è®°æ•°æ®å’Œæ ·æœ¬åˆ†å¸ƒé•¿å°¾åŒ–çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œä½œè€…åœ¨å°‘æ ·æœ¬å­¦ä¹ æ¡†æ¶ä¸‹æ¯”è¾ƒäº†ä¸‰ç§å­¦ä¹ ç­–ç•¥ï¼šæƒ…æ™¯å­¦ä¹ ã€ç›‘ç£è¿ç§»å­¦ä¹ å’Œå¯¹æ¯”è‡ªç›‘ç£é¢„è®­ç»ƒã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ISIC2018ã€Derm7ptå’ŒSD-198ä¸Šè¿›è¡Œå®éªŒï¼Œå‘ç°ä¼ ç»Ÿè¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºMobileNetV2å’ŒVision Transformerï¼ˆViTï¼‰æ¶æ„çš„æ–¹æ³•ï¼Œåœ¨è®­ç»ƒæ ·æœ¬æ•°é‡å¢åŠ æ—¶è¡¨ç°æœ€ä½³ã€‚ç»“åˆæ‰¹é‡çº§æ•°æ®å¢å¼ºæŠ€æœ¯å¦‚MixUpã€CutMixå’ŒResizeMixï¼Œè¿™äº›æ¨¡å‹åœ¨SD-198å’ŒDerm7ptæ•°æ®é›†ä¸Šè¾¾åˆ°æœ€æ–°æ€§èƒ½ï¼Œå¹¶åœ¨ISIC2018ä¸Šå–å¾—æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç½•è§çš®è‚¤ç–¾ç—…å»ºæ¨¡é¢ä¸´æ•°æ®ä¸è¶³å’Œæ ·æœ¬åˆ†å¸ƒé•¿å°¾åŒ–æŒ‘æˆ˜ã€‚</li>
<li>æƒ…æ™¯å­¦ä¹ ã€ç›‘ç£è¿ç§»å­¦ä¹ å’Œå¯¹æ¯”è‡ªç›‘ç£é¢„è®­ç»ƒæ˜¯åº”å¯¹è¿™äº›æŒ‘æˆ˜çš„ç­–ç•¥ã€‚</li>
<li>åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ä¼ ç»Ÿè¿ç§»å­¦ä¹ æ–¹æ³•è¡¨ç°æœ€ä½³ã€‚</li>
<li>åŸºäºMobileNetV2å’ŒVision Transformerï¼ˆViTï¼‰æ¶æ„çš„æ–¹æ³•è¡¨ç°å°¤å…¶å‡ºè‰²ã€‚</li>
<li>ç»“åˆæ‰¹é‡çº§æ•°æ®å¢å¼ºæŠ€æœ¯å¯è¿›ä¸€æ­¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹åœ¨SD-198å’ŒDerm7ptæ•°æ®é›†ä¸Šè¾¾åˆ°æœ€æ–°æ€§èƒ½ï¼Œå¹¶åœ¨ISIC2018ä¸Šè¡¨ç°æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.16814">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2404.16814v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2404.16814v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2404.16814v2/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2404.16814v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Few-Shot/2404.16814v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-04/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-04/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_I2I Translation/2510.00665v2/page_4_0.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Multi-Domain Brain Vessel Segmentation Through Feature Disentanglement
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/Agent/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-10-04\./crop_Agent/2510.02204v1/page_5_0.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  InfoMosaic-Bench Evaluating Multi-Source Information Seeking in   Tool-Augmented Agents
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29774.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
