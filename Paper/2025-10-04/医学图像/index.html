<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Noisy Timing Behavior is a Feature of Central Compact Object Pulsars">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-4f44294221847e7a520cb94c4dcb3ecd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030965&auth_key=1760030965-0-0-26495b717ed77098283e7fdd207d5c84&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    84 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-04-æ›´æ–°"><a href="#2025-10-04-æ›´æ–°" class="headerlink" title="2025-10-04 æ›´æ–°"></a>2025-10-04 æ›´æ–°</h1><h2 id="Noisy-Timing-Behavior-is-a-Feature-of-Central-Compact-Object-Pulsars"><a href="#Noisy-Timing-Behavior-is-a-Feature-of-Central-Compact-Object-Pulsars" class="headerlink" title="Noisy Timing Behavior is a Feature of Central Compact Object Pulsars"></a>Noisy Timing Behavior is a Feature of Central Compact Object Pulsars</h2><p><strong>Authors:K. I. Perez, E. V. Gotthelf, J. P. Halpern</strong></p>
<p>We present a timing study of the three known central compact object (CCO) pulsars, isolated cooling neutron stars in supernova remnants, using Chandra, XMM-Newton and NICER observations spanning two decades. Relative to canonical young pulsars, CCOs are spinning down at a very slow rate $|\dot f| &lt;10^{-15}$ s$^{-2}$, implying a surface dipole magnetic field strength $B_s &lt; 10^{11}$ G that is too weak to account for their X-ray emitting hot spots. Two CCO pulsars with sufficiently long monitoring, 1E 1207.4$-$5209 and PSR J0821$-$4300, are seen to deviate from steady spin-down; their timing residuals can be modeled by one or more glitches in $f$ and $\dot f$, or alternatively by extreme timing noise. For the third CCO pulsar, PSR J1852+0400, the sparse temporal coverage was insufficient to detect such effects. Glitch activity and timing noise in large samples of rotation-powered pulsars correlate best with $\dot f$, while the timing irregularities of the first two CCOs are extreme compared to pulsars of the same $\dot f$. Nevertheless, timing activity in CCOs may arise from properties that they share with other young but more energetic pulsars: high internal temperature, strong buried magnetic field and superfluid behavior. Alternatively, continuing low-level accretion of supernova debris is not ruled out as a source of timing noise in CCOs. </p>
<blockquote>
<p>æˆ‘ä»¬å¯¹ä¸‰é¢—å·²çŸ¥çš„ä¸­å¿ƒè‡´å¯†ç‰©ï¼ˆCCOï¼‰è„‰å†²æ˜Ÿè¿›è¡Œäº†æ—¶åºç ”ç©¶ï¼Œè¿™äº›è„‰å†²æ˜Ÿæ˜¯è¶…æ–°æ˜Ÿé—è¿¹ä¸­çš„å­¤ç«‹å†·å´ä¸­å­æ˜Ÿï¼Œä½¿ç”¨è·¨è¶ŠäºŒåå¹´çš„é’±å¾·æ‹‰ã€XMM-ç‰›é¡¿å’ŒNICERè§‚æµ‹æ•°æ®ã€‚ä¸å…¸å‹çš„å¹´è½»è„‰å†²æ˜Ÿç›¸æ¯”ï¼ŒCCOçš„æ—‹è½¬é€Ÿåº¦ä¸‹é™å¾—éå¸¸æ…¢ï¼Œè½¬é€Ÿå˜åŒ–ç‡|f.| &lt; 10^-15 s^-2ï¼Œè¿™æ„å‘³ç€è¡¨é¢å¶æç£åœºå¼ºåº¦Bs &lt; 10^11 Gï¼Œä¸è¶³ä»¥è§£é‡Šå®ƒä»¬çš„Xå°„çº¿å‘å°„çƒ­ç‚¹ã€‚ä¸¤é¢—ç›‘æµ‹æ—¶é—´è¶³å¤Ÿé•¿çš„CCOè„‰å†²æ˜Ÿï¼Œå³1E 1207.4-5209å’ŒPSR J0821-4300ï¼Œè¡¨ç°å‡ºåç¦»ç¨³å®šè‡ªè½¬çš„æƒ…å†µï¼›å®ƒä»¬çš„è®¡æ—¶æ®‹å·®å¯ä»¥é€šè¿‡få’Œfçš„ä¸€åˆ°å¤šæ¬¡æ•…éšœæˆ–æç«¯çš„è®¡æ—¶å™ªå£°æ¥å»ºæ¨¡ã€‚å¯¹äºç¬¬ä¸‰é¢—CCOè„‰å†²æ˜ŸPSR J1852+0400ï¼Œç¨€ç–çš„æ—¶é—´è¦†ç›–èŒƒå›´ä¸è¶³ä»¥æ£€æµ‹åˆ°æ­¤ç±»æ•ˆåº”ã€‚åœ¨å¤§æ ·æœ¬æ—‹è½¬åŠŸç‡è„‰å†²æ˜Ÿä¸­ï¼Œæ•…éšœæ´»åŠ¨å’Œè®¡æ—¶å™ªå£°ä¸fç‚¹ç›¸å…³æ€§æœ€å¼ºï¼Œè€Œå‰ä¸¤ä¸ªCCOçš„è®¡æ—¶ä¸è§„åˆ™æ€§ä¸ç›¸åŒfçš„è„‰å†²æ˜Ÿç›¸æ¯”æä¸ºæç«¯ã€‚ç„¶è€Œï¼ŒCCOä¸­çš„è®¡æ—¶æ´»åŠ¨å¯èƒ½æºäºå®ƒä»¬ä¸å…¶ä»–å¹´è½»ä½†èƒ½é‡æ›´é«˜çš„è„‰å†²æ˜Ÿæ‰€å…±æœ‰çš„ç‰¹æ€§ï¼šå†…éƒ¨æ¸©åº¦é«˜ã€åŸ‹è—ç£åœºå¼ºä»¥åŠè¶…æµä½“è¡Œä¸ºã€‚æˆ–è€…ï¼Œä¹Ÿä¸æ’é™¤è¶…æ–°æ˜Ÿæ®‹éª¸çš„æŒç»­ä½æ°´å¹³ç§¯èšæ˜¯CCOè®¡æ—¶å™ªå£°çš„æ¥æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02233v1">PDF</a> 14 pages, 6 figures, submitted to ApJ</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡åˆ©ç”¨é’±å¾·æ‹‰ã€XMM-ç‰›é¡¿å’ŒNICERé•¿è¾¾äºŒåå¹´çš„è§‚æµ‹æ•°æ®ï¼Œå¯¹ä¸‰ç§å·²çŸ¥çš„ä¸­å¿ƒè‡´å¯†ç‰©å¤©ä½“ï¼ˆCCOï¼‰è„‰å†²æ˜Ÿçš„è‡ªè½¬æ—¶é—´è¿›è¡Œäº†ç ”ç©¶ã€‚ç›¸å¯¹äºå…¸å‹çš„å¹´è½»è„‰å†²æ˜Ÿï¼ŒCCOsçš„è‡ªè½¬å‡é€Ÿç‡æä½ï¼Œè¡¨é¢å¶æç£åœºå¼ºåº¦è¾ƒå¼±ï¼Œæ— æ³•è§£é‡Šå…¶Xå°„çº¿å‘å°„çƒ­ç‚¹ã€‚ä¸¤é¢—è‡ªè½¬ç›‘æµ‹æ—¶é—´è¾ƒé•¿çš„CCOè„‰å†²æ˜Ÿï¼ˆ1E 1207.4-5209å’ŒPSR J0821-4300ï¼‰è¡¨ç°å‡ºéç¨³æ€è‡ªè½¬å‡é€Ÿè¡Œä¸ºï¼Œå…¶æ—¶åºæ®‹å·®å¯é€šè¿‡ä¸€ä¸ªæˆ–å¤šä¸ªè‡ªè½¬é¢‘ç‡å’Œè‡ªè½¬å‡é€Ÿç‡çš„é—´æ–­ï¼ˆå³æ‰€è°“çš„â€œæ•…éšœâ€ï¼‰æˆ–æç«¯æ—¶åºå™ªå£°æ¥å»ºæ¨¡ã€‚ç¬¬ä¸‰é¢—CCOè„‰å†²æ˜ŸPSR J1852+0400ç”±äºè§‚æµ‹æ—¶é—´è·¨åº¦è¾ƒçŸ­ï¼Œæœªèƒ½æ£€æµ‹åˆ°æ­¤ç±»æ•ˆåº”ã€‚åœ¨å¤§é‡æ—‹è½¬åŠŸç‡è„‰å†²æ˜Ÿæ ·æœ¬ä¸­ï¼Œæ•…éšœæ´»åŠ¨ä¸è‡ªè½¬å‡é€Ÿç‡çš„ç›¸å…³æ€§æœ€ä½³ï¼Œè€Œå‰ä¸¤ä¸ªCCOçš„æ—¶åºä¸è§„åˆ™ç°è±¡ä¸åŒè‡ªè½¬å‡é€Ÿç‡çš„è„‰å†²æ˜Ÿç›¸æ¯”æä¸ºæç«¯ã€‚ç„¶è€Œï¼ŒCCOsçš„æ—¶åºæ´»åŠ¨å¯èƒ½æºäºå®ƒä»¬ä¸å…¶ä»–å¹´è½»ä½†èƒ½é‡æ›´é«˜çš„è„‰å†²æ˜Ÿå…±æœ‰çš„ç‰¹æ€§ï¼šå¦‚é«˜å†…éƒ¨æ¸©åº¦ã€å¼ºåŸ‹è—ç£åœºå’Œè¶…æµä½“è¡Œä¸ºã€‚å¦å¤–ï¼Œä¹Ÿä¸æ’é™¤ç»§ç»­ä½æ°´å¹³èšé›†è¶…æ–°æ˜Ÿæ®‹éª¸ä½œä¸ºCCOsæ—¶åºå™ªå£°çš„æ¥æºã€‚</p>
<p><strong>å…³é”®å‘ç°</strong></p>
<ol>
<li>CCOè„‰å†²æ˜Ÿçš„è‡ªè½¬å‡é€Ÿç‡æä½ï¼Œè¡¨é¢å¶æç£åœºå¼ºåº¦è¾ƒå¼±ã€‚</li>
<li>ä¸¤é¢—CCOè„‰å†²æ˜Ÿï¼ˆ1E 1207.4-5209å’ŒPSR J0821-4300ï¼‰è¡¨ç°å‡ºéç¨³æ€è‡ªè½¬å‡é€Ÿè¡Œä¸ºï¼Œå¯èƒ½ç”±äºæ•…éšœæˆ–æç«¯æ—¶åºå™ªå£°å¯¼è‡´ã€‚</li>
<li>ç¬¬ä¸‰é¢—CCOè„‰å†²æ˜ŸPSR J1852+0400ç”±äºè§‚æµ‹æ—¶é—´è¾ƒçŸ­ï¼Œæœªæ£€æµ‹åˆ°æ­¤ç±»æ•ˆåº”ã€‚</li>
<li>CCOè„‰å†²æ˜Ÿçš„æ—¶åºæ´»åŠ¨ä¸é«˜å†…éƒ¨æ¸©åº¦ã€å¼ºåŸ‹è—ç£åœºå’Œè¶…æµä½“è¡Œä¸ºæœ‰å…³ã€‚</li>
<li>CCOè„‰å†²æ˜Ÿçš„æ—¶åºå™ªå£°å¯èƒ½æ¥æºäºç»§ç»­ä½æ°´å¹³èšé›†è¶…æ–°æ˜Ÿæ®‹éª¸ã€‚</li>
<li>æ•…éšœæ´»åŠ¨ä¸è‡ªè½¬å‡é€Ÿç‡åœ¨å¤§é‡æ—‹è½¬åŠŸç‡è„‰å†²æ˜Ÿæ ·æœ¬ä¸­çš„ç›¸å…³æ€§æœ€ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02233">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0a0846ab3c868c945695fe2e68de1e73~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030972&auth_key=1760030972-0-0-93e725d81ecbccf4bae87d723e4c85fe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bfbf86e4b97f449c6541bc19e90ccdec~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030980&auth_key=1760030980-0-0-e1511598c85441e1e0d9794e7e89e011&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-344f8cca4631e8c2a866ae2f43cc3f35~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030987&auth_key=1760030987-0-0-40416886a988b2abb952da9df62dfee2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b762d115b85f11bbd32d05d89127a4f4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030994&auth_key=1760030994-0-0-908642633435c0915bcbbfd96e185625&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3e12612f2dda144e244412e494ee61d6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031001&auth_key=1760031001-0-0-df0b3013ac0eb637e385db7716632e61&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SpurBreast-A-Curated-Dataset-for-Investigating-Spurious-Correlations-in-Real-world-Breast-MRI-Classification"><a href="#SpurBreast-A-Curated-Dataset-for-Investigating-Spurious-Correlations-in-Real-world-Breast-MRI-Classification" class="headerlink" title="SpurBreast: A Curated Dataset for Investigating Spurious Correlations in   Real-world Breast MRI Classification"></a>SpurBreast: A Curated Dataset for Investigating Spurious Correlations in   Real-world Breast MRI Classification</h2><p><strong>Authors:Jong Bum Won, Wesley De Neve, Joris Vankerschaver, Utku Ozbulak</strong></p>
<p>Deep neural networks (DNNs) have demonstrated remarkable success in medical imaging, yet their real-world deployment remains challenging due to spurious correlations, where models can learn non-clinical features instead of meaningful medical patterns. Existing medical imaging datasets are not designed to systematically study this issue, largely due to restrictive licensing and limited supplementary patient data. To address this gap, we introduce SpurBreast, a curated breast MRI dataset that intentionally incorporates spurious correlations to evaluate their impact on model performance. Analyzing over 100 features involving patient, device, and imaging protocol, we identify two dominant spurious signals: magnetic field strength (a global feature influencing the entire image) and image orientation (a local feature affecting spatial alignment). Through controlled dataset splits, we demonstrate that DNNs can exploit these non-clinical signals, achieving high validation accuracy while failing to generalize to unbiased test data. Alongside these two datasets containing spurious correlations, we also provide benchmark datasets without spurious correlations, allowing researchers to systematically investigate clinically relevant and irrelevant features, uncertainty estimation, adversarial robustness, and generalization strategies. Models and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/utkuozbulak/spurbreast">https://github.com/utkuozbulak/spurbreast</a>. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨åŒ»å­¦æˆåƒé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†ç”±äºå¶ç„¶å…³è”çš„å­˜åœ¨ï¼Œå®ƒä»¬åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨éƒ¨ç½²ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™äº›å…³è”ä¸­ï¼Œæ¨¡å‹å¯èƒ½ä¼šå­¦ä¹ éä¸´åºŠç‰¹å¾è€Œéæœ‰æ„ä¹‰çš„åŒ»å­¦æ¨¡å¼ã€‚ç°æœ‰çš„åŒ»å­¦æˆåƒæ•°æ®é›†å¹¶æœªé’ˆå¯¹è¿™ä¸€é—®é¢˜è¿›è¡Œç³»ç»Ÿç ”ç©¶ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºè®¸å¯è¯çš„é™åˆ¶å’Œé™„åŠ çš„ç—…äººæ•°æ®æœ‰é™ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†SpurBreastï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡æ•´ç†çš„ä¹³è…ºMRIæ•°æ®é›†ï¼Œæœ‰æ„çº³å…¥å¶ç„¶å…³è”ä»¥è¯„ä¼°å…¶å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡åˆ†ææ¶‰åŠæ‚£è€…ã€è®¾å¤‡å’Œæˆåƒåè®®çš„100å¤šé¡¹ç‰¹å¾ï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸¤ä¸ªä¸»è¦çš„å¶ç„¶ä¿¡å·ï¼šç£åœºå¼ºåº¦ï¼ˆå½±å“æ•´ä¸ªå›¾åƒçš„å…¨å±€ç‰¹å¾ï¼‰å’Œå›¾åƒæ–¹å‘ï¼ˆå½±å“ç©ºé—´å¯¹é½çš„å±€éƒ¨ç‰¹å¾ï¼‰ã€‚é€šè¿‡æ§åˆ¶æ•°æ®é›†åˆ†å‰²ï¼Œæˆ‘ä»¬è¯æ˜æ·±åº¦ç¥ç»ç½‘ç»œå¯ä»¥åˆ©ç”¨è¿™äº›éä¸´åºŠä¿¡å·ï¼Œåœ¨éªŒè¯é›†ä¸Šè·å¾—é«˜å‡†ç¡®ç‡ï¼Œä½†åœ¨æ— åè§æµ‹è¯•æ•°æ®ä¸Šå´æ— æ³•æ¨å¹¿ã€‚é™¤äº†è¿™ä¸¤ä¸ªåŒ…å«å¶ç„¶å…³è”çš„æ•°æ®é›†å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†æ²¡æœ‰å¶ç„¶å…³è”çš„åŸºå‡†æ•°æ®é›†ï¼Œè®©ç ”ç©¶äººå‘˜èƒ½å¤Ÿç³»ç»Ÿåœ°ç ”ç©¶ä¸´åºŠç›¸å…³å’Œæ— å…³çš„ç‰¹å¾ã€ä¸ç¡®å®šæ€§ä¼°è®¡ã€å¯¹æŠ—ç¨³å¥æ€§å’Œæ¨å¹¿ç­–ç•¥ã€‚æ¨¡å‹å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/utkuozbulak/spurbreast%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/utkuozbulak/spurbreastè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02109v1">PDF</a> Accepted for publication in the 28th International Conference on   Medical Image Computing and Computer Assisted Intervention (MICCAI), 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SpurBreastæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºç ”ç©¶æ·±åº¦ç¥ç»ç½‘ç»œåœ¨åŒ»å­¦æˆåƒä¸­çš„æŠ—å¹²æ‰°èƒ½åŠ›è€Œè®¾è®¡çš„ä¹³æˆ¿MRIæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æœ‰æ„å¼•å…¥ä¸¤ç§ä¸»è¦çš„éä¸´åºŠç‰¹å¾ä½œä¸ºå¹²æ‰°å› ç´ ï¼Œå³ç£åœºå¼ºåº¦å’Œå›¾åƒæ–¹å‘ã€‚é€šè¿‡å¯¹æ¯”å®éªŒï¼Œå±•ç¤ºäº†æ·±åº¦ç¥ç»ç½‘ç»œå¯¹è¿™äº›å¹²æ‰°å› ç´ çš„ä¾èµ–ç¨‹åº¦ä»¥åŠå¯¹æ— å¹²æ‰°åŸºå‡†æ•°æ®é›†çš„è¡¨ç°ã€‚è¯¥æ•°æ®é›†æ—¨åœ¨å¸®åŠ©ç ”ç©¶äººå‘˜ç³»ç»Ÿç ”ç©¶åŒ»å­¦å›¾åƒç‰¹å¾çš„é€‰æ‹©å’Œå¹²æ‰°å› ç´ çš„åº”å¯¹ç­–ç•¥ã€‚æ•°æ®é›†ä¸ä»£ç å·²ç»å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SpurBreastæ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºè¯„ä¼°æ·±åº¦ç¥ç»ç½‘ç»œåœ¨åŒ»å­¦æˆåƒä¸­çš„æŠ—å¹²æ‰°èƒ½åŠ›è€Œè®¾è®¡çš„ä¹³æˆ¿MRIæ•°æ®é›†ã€‚</li>
<li>è¯¥æ•°æ®é›†æœ‰æ„å¼•å…¥äº†ä¸¤ç§ä¸»è¦çš„éä¸´åºŠç‰¹å¾ä½œä¸ºå¹²æ‰°å› ç´ ï¼šç£åœºå¼ºåº¦å’Œå›¾åƒæ–¹å‘ã€‚</li>
<li>é€šè¿‡å¯¹æ¯”å®éªŒï¼Œå‘ç°æ·±åº¦ç¥ç»ç½‘ç»œå¯èƒ½ä¼šä¾èµ–è¿™äº›éä¸´åºŠç‰¹å¾è¿›è¡Œé¢„æµ‹ï¼Œä»è€Œå½±å“å…¶åœ¨çœŸå®ä¸–ç•Œä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ•°æ®é›†åŒæ—¶æä¾›äº†æ— å¹²æ‰°çš„åŸºå‡†æ•°æ®é›†ï¼Œä»¥ä¾›ç ”ç©¶äººå‘˜ç ”ç©¶ä¸´åºŠç›¸å…³ç‰¹å¾å’Œå…¶ä»–ä¸»é¢˜ã€‚</li>
<li>è¯¥æ•°æ®é›†æœ‰åŠ©äºç ”ç©¶ä¸ç¡®å®šæ€§ä¼°è®¡ã€å¯¹æŠ—ç¨³å¥æ€§å’Œæ³›åŒ–ç­–ç•¥ç­‰ä¸»é¢˜ã€‚</li>
<li>æ•°æ®é›†å’Œä»£ç å·²ç»å…¬å¼€å‘å¸ƒï¼Œä¾¿äºç ”ç©¶äººå‘˜ä½¿ç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02109">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-883b2c42ee857a196f81c6fd5f6cc8e9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031008&auth_key=1760031008-0-0-895a6b2d7995c4de40ce13e9e7374953&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cf611db75cae5f926102f9e89a080f53~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031017&auth_key=1760031017-0-0-7af6ff2591dfc3acae137874fe4ee7f1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2d3da84a7bc743d5dbf04ea58e4019f0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031023&auth_key=1760031023-0-0-bd991b79d4c118701be3363559cf125a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bd63d17678dd3a2126b0eb9042f70223~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031030&auth_key=1760031030-0-0-35c9870a19991a4f6c5be350a2b63c44&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="VGDM-Vision-Guided-Diffusion-Model-for-Brain-Tumor-Detection-and-Segmentation"><a href="#VGDM-Vision-Guided-Diffusion-Model-for-Brain-Tumor-Detection-and-Segmentation" class="headerlink" title="VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and   Segmentation"></a>VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and   Segmentation</h2><p><strong>Authors:Arman Behnam</strong></p>
<p>Accurate detection and segmentation of brain tumors from magnetic resonance imaging (MRI) are essential for diagnosis, treatment planning, and clinical monitoring. While convolutional architectures such as U-Net have long been the backbone of medical image segmentation, their limited capacity to capture long-range dependencies constrains performance on complex tumor structures. Recent advances in diffusion models have demonstrated strong potential for generating high-fidelity medical images and refining segmentation boundaries.   In this work, we propose VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation framework, a transformer-driven diffusion framework for brain tumor detection and segmentation. By embedding a vision transformer at the core of the diffusion process, the model leverages global contextual reasoning together with iterative denoising to enhance both volumetric accuracy and boundary precision. The transformer backbone enables more effective modeling of spatial relationships across entire MRI volumes, while diffusion refinement mitigates voxel-level errors and recovers fine-grained tumor details.   This hybrid design provides a pathway toward improved robustness and scalability in neuro-oncology, moving beyond conventional U-Net baselines. Experimental validation on MRI brain tumor datasets demonstrates consistent gains in Dice similarity and Hausdorff distance, underscoring the potential of transformer-guided diffusion models to advance the state of the art in tumor segmentation. </p>
<blockquote>
<p>ä»ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰å¯¹è„‘è‚¿ç˜¤è¿›è¡Œç²¾ç¡®æ£€æµ‹å’Œåˆ†å‰²å¯¹äºè¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œä¸´åºŠç›‘æµ‹è‡³å…³é‡è¦ã€‚è™½ç„¶U-Netç­‰å·ç§¯æ¶æ„é•¿æœŸä»¥æ¥ä¸€ç›´æ˜¯åŒ»å­¦å›¾åƒåˆ†å‰²çš„æ”¯æŸ±ï¼Œä½†å…¶æ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»çš„æœ‰é™èƒ½åŠ›åœ¨å¤æ‚è‚¿ç˜¤ç»“æ„ä¸Šçš„æ€§èƒ½å—åˆ°åˆ¶çº¦ã€‚æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹è¿›å±•æ˜¾ç¤ºå‡ºç”Ÿæˆé«˜ä¿çœŸåŒ»å­¦å›¾åƒå’Œç»†åŒ–åˆ†å‰²è¾¹ç•Œçš„å¼ºå¤§æ½œåŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†VGDMï¼šç”¨äºè„‘è‚¿ç˜¤æ£€æµ‹å’Œåˆ†å‰²çš„è§†åŠ›å¼•å¯¼æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè„‘è‚¿ç˜¤æ£€æµ‹å’Œåˆ†å‰²çš„åŸºäºå˜å‹å™¨çš„æ‰©æ•£æ¡†æ¶ã€‚é€šè¿‡åœ¨æ‰©æ•£è¿‡ç¨‹çš„æ ¸å¿ƒä¸­åµŒå…¥è§†è§‰å˜å‹å™¨ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨å…¨å±€ä¸Šä¸‹æ–‡æ¨ç†å’Œè¿­ä»£å»å™ªï¼Œæé«˜äº†ä½“ç§¯ç²¾åº¦å’Œè¾¹ç•Œç²¾åº¦ã€‚å˜å‹å™¨éª¨æ¶èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å»ºæ¨¡æ•´ä¸ªMRIä½“ç§¯ä¸­çš„ç©ºé—´å…³ç³»ï¼Œè€Œæ‰©æ•£ç»†åŒ–å‡è½»äº†ä½“ç´ çº§é”™è¯¯å¹¶æ¢å¤äº†ç²¾ç»†çš„è‚¿ç˜¤ç»†èŠ‚ã€‚è¿™ç§æ··åˆè®¾è®¡ä¸ºæé«˜ç¥ç»è‚¿ç˜¤å­¦ä¸­çš„ç¨³å¥æ€§å’Œå¯æ‰©å±•æ€§æä¾›äº†é€”å¾„ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„U-NetåŸºçº¿ã€‚åœ¨MRIè„‘è‚¿ç˜¤æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯æ˜¾ç¤ºï¼ŒDiceç›¸ä¼¼åº¦å’ŒHausdorffè·ç¦»çš„å¢ç›ŠæŒç»­ä¸€è‡´ï¼Œè¿™çªæ˜¾äº†å˜å‹å™¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹åœ¨æ¨åŠ¨è‚¿ç˜¤åˆ†å‰²æŠ€æœ¯å‰æ²¿çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02086v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒé¢†åŸŸå¯¹è„‘éƒ¨è‚¿ç˜¤æ£€æµ‹å’Œåˆ†å‰²çš„å‡†ç¡®æ€§è‡³å…³é‡è¦ï¼Œå¸¸ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„å·ç§¯æ¶æ„è™½å–å¾—ä¸€å®šæˆæœï¼Œä½†åœ¨å¤æ‚è‚¿ç˜¤ç»“æ„ä¸Šçš„æ€§èƒ½å—é™ã€‚æœ¬ç ”ç©¶æå‡ºVGDMæ¨¡å‹ï¼Œå³åŸºäºè§†è§‰å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œè„‘éƒ¨è‚¿ç˜¤æ£€æµ‹å’Œåˆ†å‰²æ¡†æ¶ï¼Œé‡‡ç”¨æ‰©æ•£æ¨¡å‹ç»“åˆè§†è§‰è½¬æ¢å™¨ï¼Œé€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡æ¨ç†å’Œè¿­ä»£å»å™ªæé«˜ä½“ç§¯ç²¾åº¦å’Œè¾¹ç•Œç²¾åº¦ã€‚è¯¥æ¨¡å‹å¯æœ‰æ•ˆæ¨¡æ‹Ÿæ•´ä¸ªMRIä½“ç§¯çš„ç©ºé—´å…³ç³»ï¼Œæ‰©æ•£ä¼˜åŒ–å‡è½»åƒç´ çº§é”™è¯¯å¹¶æ¢å¤è‚¿ç˜¤ç»†èŠ‚ã€‚å®éªŒéªŒè¯è¡¨æ˜Diceç›¸ä¼¼æ€§å’ŒHausdorffè·ç¦»æŒ‡æ ‡å‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·æœ‰æ½œåœ¨çš„é¢†å…ˆæ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å·ç§¯æ¶æ„åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„å±€é™æ€§ï¼šå°½ç®¡å·ç§¯æ¶æ„å¦‚U-Netåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å–å¾—æˆæœï¼Œä½†å…¶æ•æ‰é•¿è·ç¦»ä¾èµ–çš„èƒ½åŠ›æœ‰é™ï¼Œå¯¹äºå¤æ‚è‚¿ç˜¤ç»“æ„çš„æ€§èƒ½è¡¨ç°æœ‰æ‰€åˆ¶çº¦ã€‚</li>
<li>VGDMæ¨¡å‹ä»‹ç»ï¼šæœ¬ç ”ç©¶æå‡ºäº†VGDMæ¨¡å‹ï¼Œå³åŸºäºè§†è§‰å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œè„‘éƒ¨è‚¿ç˜¤æ£€æµ‹å’Œåˆ†å‰²æ¡†æ¶ã€‚è¯¥æ¨¡å‹ç»“åˆäº†æ‰©æ•£æ¨¡å‹å’Œè§†è§‰è½¬æ¢å™¨ï¼Œæ—¨åœ¨æé«˜åŒ»å­¦å›¾åƒä¸­è„‘éƒ¨è‚¿ç˜¤æ£€æµ‹å’Œåˆ†å‰²çš„å‡†ç¡®æ€§ã€‚</li>
<li>è§†è§‰è½¬æ¢å™¨çš„ä½œç”¨ï¼šé€šè¿‡åµŒå…¥è§†è§‰è½¬æ¢å™¨ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ¨¡æ‹Ÿæ•´ä¸ªMRIä½“ç§¯çš„ç©ºé—´å…³ç³»ï¼Œä»è€Œæé«˜åˆ†å‰²çš„ç²¾ç¡®åº¦ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ï¼šæ‰©æ•£æ¨¡å‹é€šè¿‡è¿­ä»£å»å™ªå’Œç²¾ç»†ä¼˜åŒ–ï¼Œèƒ½å¤Ÿå‡è½»åƒç´ çº§é”™è¯¯å¹¶æ¢å¤è‚¿ç˜¤çš„ç»†èŠ‚ä¿¡æ¯ã€‚</li>
<li>å®éªŒéªŒè¯ç»“æœï¼šåœ¨MRIè„‘éƒ¨è‚¿ç˜¤æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯è¡¨æ˜ï¼ŒVGDMæ¨¡å‹åœ¨Diceç›¸ä¼¼æ€§å’ŒHausdorffè·ç¦»ç­‰æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè¯æ˜äº†è¯¥æ¨¡å‹çš„æ½œåŠ›å’Œå…ˆè¿›æ€§ã€‚</li>
<li>æ¨¡å‹çš„å½±å“å’Œæœªæ¥æ–¹å‘ï¼šVGDMæ¨¡å‹ä¸ºç¥ç»è‚¿ç˜¤å­¦ä¸­çš„ç¨³å¥æ€§å’Œå¯æ‰©å±•æ€§æä¾›äº†æ–°çš„é€”å¾„ï¼Œæœ‰æœ›æ¨åŠ¨åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02086">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b1bbd52fe85d59156603ba5ce1e53fd2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031036&auth_key=1760031036-0-0-4523078965525f8673d4e6b995373828&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9c06905b4edc087b85564e79ea3894d3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031043&auth_key=1760031043-0-0-fb79a28e10f6c701e05a277e14cbbd63&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Pulsed-laser-induced-gold-microparticle-fragmentation-by-thermal-strain"><a href="#Pulsed-laser-induced-gold-microparticle-fragmentation-by-thermal-strain" class="headerlink" title="Pulsed-laser induced gold microparticle fragmentation by thermal strain"></a>Pulsed-laser induced gold microparticle fragmentation by thermal strain</h2><p><strong>Authors:Yogesh Pokhrel, Meike Tack, Sven Reichenberger, Matteo Levantino, Anton Plech</strong></p>
<p>Laser fragmentation of suspended microparticles is an upcoming alternative to laser ablation in liquid (LAL) that allows to streamline the the delivery process and optimize the irradiation conditions for best efficiency. Yet, the structural basis of this process is not well understood to date. Herein we employed ultrafast x-ray scattering upon picosecond laser excitation of a gold microparticle suspension in order to understand the thermal kinetics as well as structure evolution after fragmentation. The experiments are complemented by simulations according to the two-temperature model to verify the spatiotemporal temperature distribution. It is found that above a fluence threshold of 750 J&#x2F;m$^2$ the microparticles are fragmented within a nanosecond into several large pieces where the driving force is the strain due to a strongly inhomogenous heat distribution on the one hand and stress confinement due to the ultrafast heating compared to stress propagation on the other hand. The additional limited formation of small clusters is attributed to photothermal decomposition on the front side of the microparticles at the fluence of 2700 J&#x2F;m$^2$. </p>
<blockquote>
<p>æ‚¬æµ®å¾®ç²’çš„æ¿€å…‰ç ´ç¢æ˜¯æ¶²ç›¸æ¿€å…‰æ¶ˆèï¼ˆLALï¼‰çš„ä¸€ç§æ–°å…´æ›¿ä»£æ–¹æ³•ï¼Œå®ƒå…è®¸ç®€åŒ–ç»™è¯è¿‡ç¨‹å¹¶ä¼˜åŒ–è¾å°„æ¡ä»¶ä»¥è¾¾åˆ°æœ€ä½³æ•ˆç‡ã€‚ç„¶è€Œï¼Œè¿„ä»Šä¸ºæ­¢ï¼Œè¯¥è¿‡ç¨‹çš„ç»“æ„åŸºç¡€å°šä¸å®Œå…¨æ¸…æ¥šã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬å¯¹çš®ç§’æ¿€å…‰æ¿€å‘çš„é‡‘å¾®ç²’æ‚¬æµ®æ¶²è¿›è¡Œäº†è¶…å¿«Xå°„çº¿æ•£å°„å®éªŒï¼Œä»¥äº†è§£ç ´ç¢åçš„çƒ­åŠ¨åŠ›å­¦å’Œç»“æ„æ¼”å˜ã€‚å®éªŒæ ¹æ®ä¸¤æ¸©åº¦æ¨¡å‹è¿›è¡Œæ¨¡æ‹Ÿï¼Œä»¥éªŒè¯æ—¶ç©ºæ¸©åº¦åˆ†å¸ƒã€‚ç ”ç©¶å‘ç°ï¼Œå½“æµæ³¨é˜ˆå€¼è¶…è¿‡750 J&#x2F;m^2æ—¶ï¼Œå¾®ç²’åœ¨çº³ç§’å†…è¢«ç ´ç¢æˆå‡ å—ï¼Œé©±åŠ¨åŠ›ä¸€æ–¹é¢æ˜¯ç”±äºå¼ºçƒˆä¸å‡åŒ€çš„çƒ­é‡åˆ†å¸ƒå¼•èµ·çš„åº”å˜ï¼Œå¦ä¸€æ–¹é¢æ˜¯ç”±äºä¸åº”åŠ›ä¼ æ’­ç›¸æ¯”çš„å¿«é€ŸåŠ çƒ­é€ æˆçš„åº”åŠ›çº¦æŸã€‚åœ¨æµæ³¨ä¸º2700 J&#x2F;m^2çš„æƒ…å†µä¸‹ï¼Œå¾®ç²’å‰ä¾§çš„å…‰çƒ­åˆ†è§£å½¢æˆäº†å°‘é‡é™„åŠ çš„å°å›¢ç°‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02011v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æ¿€å…‰å¯¹æ‚¬æµ®å¾®ç²’è¿›è¡Œç¢ç‰‡åŒ–å¤„ç†æ˜¯æ¿€å…‰æ¶²ä½“æ¶ˆèï¼ˆLALï¼‰çš„ä¸€ç§æ–°å…´æ›¿ä»£æ–¹æ¡ˆï¼Œå¯ä¼˜åŒ–è¾“é€è¿‡ç¨‹å’Œè¾å°„æ¡ä»¶ä»¥æé«˜æ•ˆç‡ã€‚ç„¶è€Œï¼Œè¯¥è¿‡ç¨‹çš„ç»“æ„åŸºç¡€å°šä¸æ¸…æ¥šã€‚æœ¬ç ”ç©¶é‡‡ç”¨è¶…å¿«Xå°„çº¿æ•£å°„æ³•ï¼Œå¯¹çš®ç§’æ¿€å…‰æ¿€å‘çš„é‡‘å¾®ç²’æ‚¬æµ®æ¶²è¿›è¡Œçƒ­åŠ¨åŠ›å­¦å’Œç»“æ„æ¼”å˜ç ”ç©¶ã€‚å®éªŒè¾…ä»¥åŒæ¸©æ¨¡å‹æ¨¡æ‹Ÿï¼ŒéªŒè¯æ—¶ç©ºæ¸©åº¦åˆ†å¸ƒã€‚ç ”ç©¶å‘ç°ï¼Œå½“èƒ½é‡å¯†åº¦é˜ˆå€¼è¶…è¿‡750 J&#x2F;mÂ²æ—¶ï¼Œå¾®ç²’åœ¨ä¸€çº³ç§’å†…ç¢è£‚æˆè‹¥å¹²å¤§å—ï¼Œé©±åŠ¨åŠ›æ¥æºäºå¼ºçƒˆä¸å‡åŒ€çš„çƒ­åˆ†å¸ƒæ‰€äº§ç”Ÿçš„åº”å˜ä»¥åŠè¶…å¿«åŠ çƒ­æ‰€å¯¼è‡´çš„åº”åŠ›é›†ä¸­ä¸åº”åŠ›ä¼ æ’­ä¹‹é—´çš„å¯¹æ¯”ã€‚åœ¨èƒ½é‡å¯†åº¦ä¸º2700 J&#x2F;mÂ²æ—¶ï¼Œå¾®ç²’å‰ä¾§çš„å…‰çƒ­åˆ†è§£å¯¼è‡´å½¢æˆå°‘é‡å°ç°‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¿€å…‰å¯¹æ‚¬æµ®å¾®ç²’çš„ç¢ç‰‡åŒ–å¤„ç†æ˜¯æ¿€å…‰æ¶²ä½“æ¶ˆèçš„ä¸€ç§æ–°å…´æ›¿ä»£æ–¹æ¡ˆã€‚</li>
<li>è¯¥ç ”ç©¶é‡‡ç”¨è¶…å¿«Xå°„çº¿æ•£å°„æ³•æ¥æ¢ç©¶æ¿€å…‰æ¿€å‘ä¸‹é‡‘å¾®ç²’æ‚¬æµ®æ¶²çš„çƒ­åŠ¨åŠ›å­¦å’Œç»“æ„æ¼”å˜ã€‚</li>
<li>å½“èƒ½é‡å¯†åº¦è¶…è¿‡ä¸€å®šé˜ˆå€¼æ—¶ï¼Œå¾®ç²’ä¼šè¿…é€Ÿç¢è£‚æˆè‹¥å¹²å¤§å—ã€‚</li>
<li>å¾®ç²’ç¢è£‚çš„é©±åŠ¨åŠ›æ¥æºäºä¸å‡åŒ€çƒ­åˆ†å¸ƒäº§ç”Ÿçš„åº”å˜ä»¥åŠè¶…å¿«åŠ çƒ­å¯¼è‡´çš„åº”åŠ›é›†ä¸­ä¸åº”åŠ›ä¼ æ’­å¯¹æ¯”ã€‚</li>
<li>åŒæ¸©æ¨¡å‹æ¨¡æ‹Ÿå®éªŒéªŒè¯äº†æ—¶ç©ºæ¸©åº¦åˆ†å¸ƒã€‚</li>
<li>åœ¨è¾ƒé«˜èƒ½é‡å¯†åº¦ä¸‹ï¼Œå¾®ç²’å‰ä¾§ä¼šå‘ç”Ÿå…‰çƒ­åˆ†è§£ï¼Œå½¢æˆå°‘é‡å°ç°‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02011">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-63d8953a45efb8326457d23c7219ddf6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031052&auth_key=1760031052-0-0-4985971d5c81ce6517416aed7bed4380&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-687df157a6f1756f4cbb0f88e3f4c6e8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031059&auth_key=1760031059-0-0-94dbdeb6a238acbc339ee118f89496d6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0a5717f3d37837e15532eaca67e83e13~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031066&auth_key=1760031066-0-0-bbebd5a09b2ef7d098dd31d06ffd32a0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Wearable-and-Ultra-Low-Power-Fusion-of-EMG-and-A-Mode-US-for-Hand-Wrist-Kinematic-Tracking"><a href="#Wearable-and-Ultra-Low-Power-Fusion-of-EMG-and-A-Mode-US-for-Hand-Wrist-Kinematic-Tracking" class="headerlink" title="Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist   Kinematic Tracking"></a>Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist   Kinematic Tracking</h2><p><strong>Authors:Giusy Spacone, Sebastian Frey, Mattia Orlandi, Pierangelo Maria Rapa, Victor Kartsch, Simone Benatti, Luca Benini, Andrea Cossettini</strong></p>
<p>Hand gesture recognition based on biosignals has shown strong potential for developing intuitive human-machine interaction strategies that closely mimic natural human behavior. In particular, sensor fusion approaches have gained attention for combining complementary information and overcoming the limitations of individual sensing modalities, thereby enabling more robust and reliable systems. Among them, the fusion of surface electromyography (EMG) and A-mode ultrasound (US) is very promising. However, prior solutions rely on power-hungry platforms unsuitable for multi-day use and are limited to discrete gesture classification. In this work, we present an ultra-low-power (sub-50 mW) system for concurrent acquisition of 8-channel EMG and 4-channel A-mode US signals, integrating two state-of-the-art platforms into fully wearable, dry-contact armbands. We propose a framework for continuous tracking of 23 degrees of freedom (DoFs), 20 for the hand and 3 for the wrist, using a kinematic glove for ground-truth labeling. Our method employs lightweight encoder-decoder architectures with multi-task learning to simultaneously estimate hand and wrist joint angles. Experimental results under realistic sensor repositioning conditions demonstrate that EMG-US fusion achieves a root mean squared error of $10.6^\circ\pm2.0^\circ$, compared to $12.0^\circ\pm1^\circ$ for EMG and $13.1^\circ\pm2.6^\circ$ for US, and a R$^2$ score of $0.61\pm0.1$, with $0.54\pm0.03$ for EMG and $0.38\pm0.20$ for US. </p>
<blockquote>
<p>åŸºäºç”Ÿç‰©ä¿¡å·çš„æ‰‹åŠ¿è¯†åˆ«åœ¨å¼€å‘ç›´è§‚çš„äººæœºäº¤äº’ç­–ç•¥æ–¹é¢è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œè¿™äº›ç­–ç•¥èƒ½å¤Ÿç´§å¯†æ¨¡ä»¿è‡ªç„¶äººç±»è¡Œä¸ºã€‚ç‰¹åˆ«æ˜¯ï¼Œå¤šä¼ æ„Ÿå™¨èåˆæ–¹æ³•ç»“åˆäº†äº’è¡¥ä¿¡æ¯ï¼Œå…‹æœäº†å•ä¸€ä¼ æ„Ÿæ¨¡å¼çš„å±€é™æ€§ï¼Œä»è€Œå®ç°äº†æ›´ç¨³å¥å’Œå¯é çš„ç³»ç»Ÿã€‚å…¶ä¸­ï¼Œè¡¨é¢è‚Œç”µå›¾ï¼ˆEMGï¼‰å’ŒAæ¨¡å¼è¶…å£°ï¼ˆUSï¼‰çš„èåˆå‰æ™¯éå¸¸å¹¿é˜”ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è§£å†³æ–¹æ¡ˆä¾èµ–äºåŠŸè€—è¾ƒå¤§çš„å¹³å°ï¼Œä¸é€‚åˆå¤šå¤©ä½¿ç”¨ï¼Œä¸”ä»…é™äºç¦»æ•£æ‰‹åŠ¿åˆ†ç±»ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¶…ä½åŠŸè€—ï¼ˆä½äº50æ¯«ç“¦ï¼‰çš„ç³»ç»Ÿï¼Œå¯ä»¥åŒæ—¶é‡‡é›†8é€šé“EMGå’Œ4é€šé“Aæ¨¡å¼USä¿¡å·ï¼Œå°†ä¸¤ç§æœ€å…ˆè¿›çš„å¹³å°é›†æˆåˆ°å¯ç©¿æˆ´çš„å¹²æ¥è§¦å¼è‡‚ç« ä¸­ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºè¿ç»­è·Ÿè¸ª23ä¸ªè‡ªç”±åº¦ï¼ˆDoFsï¼‰ï¼Œå…¶ä¸­æ‰‹éƒ¨20ä¸ªï¼Œæ‰‹è…•3ä¸ªï¼Œä½¿ç”¨è¿åŠ¨æ‰‹å¥—è¿›è¡ŒçœŸå®æ ‡ç­¾æ ‡æ³¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨è½»é‡çº§çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œç»“åˆå¤šä»»åŠ¡å­¦ä¹ æ¥åŒæ—¶ä¼°è®¡æ‰‹å’Œæ‰‹è…•çš„å…³èŠ‚è§’åº¦ã€‚åœ¨ç°å®çš„ä¼ æ„Ÿå™¨é‡æ–°å®šä½æ¡ä»¶ä¸‹è¿›è¡Œçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸EMGå’ŒUSç›¸æ¯”ï¼ŒEMG-USèåˆå®ç°çš„å¹³å‡å‡æ–¹æ ¹è¯¯å·®ä¸º$10.6^\circ\pm2.0^\circ$ï¼Œè€ŒEMGçš„ä¸º$12.0^\circ\pm1^\circ$ï¼ŒUSçš„ä¸º$13.1^\circ\pm2.6^\circ$ï¼›æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜å®ç°äº†R$^2$åˆ†æ•°ä¸º$0.61\pm0.1$ï¼Œè€ŒEMGçš„ä¸º$0.54\pm0.03$ï¼ŒUSçš„ä¸º$0.38\pm0.20$ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02000v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºç”Ÿç‰©ä¿¡å·çš„æ‰‹åŠ¿è¯†åˆ«åœ¨å¼€å‘ç›´è§‚çš„äººæœºäº¤äº’ç­–ç•¥æ–¹é¢æ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ½œåŠ›ï¼Œè¿™äº›ç­–ç•¥èƒ½å¤Ÿç´§å¯†æ¨¡ä»¿è‡ªç„¶äººç±»è¡Œä¸ºã€‚ç‰¹åˆ«æ˜¯ï¼Œä¼ æ„Ÿå™¨èåˆæ–¹æ³•ç»“åˆäº†äº’è¡¥ä¿¡æ¯ï¼Œå…‹æœäº†å•ä¸ªä¼ æ„Ÿæ¨¡å¼çš„å±€é™æ€§ï¼Œä»è€Œå®ç°äº†æ›´ç¨³å¥å’Œå¯é çš„ç³»ç»Ÿã€‚å…¶ä¸­ï¼Œè¡¨é¢è‚Œç”µå›¾ï¼ˆEMGï¼‰å’ŒAæ¨¡å¼è¶…å£°ï¼ˆUSï¼‰çš„èåˆå‰æ™¯éå¸¸æ˜æœ—ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è§£å†³æ–¹æ¡ˆä¾èµ–äºåŠŸè€—è¾ƒå¤§çš„å¹³å°ï¼Œä¸é€‚ç”¨äºå¤šæ—¥ä½¿ç”¨ï¼Œä¸”ä»…é™äºç¦»æ•£æ‰‹åŠ¿åˆ†ç±»ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¶…ä½åŠŸè€—ï¼ˆä½äº50mWï¼‰çš„ç³»ç»Ÿï¼Œå¯åŒæ—¶è¿›è¡Œ8é€šé“EMGå’Œ4é€šé“Aæ¨¡å¼USä¿¡å·çš„é‡‡é›†ï¼Œå°†ä¸¤ç§æœ€å…ˆè¿›çš„å¹³å°é›†æˆåˆ°å¯ç©¿æˆ´çš„å¹²æ¥è§¦å¼è‡‚ç« ä¸­ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œç”¨äºè¿ç»­è·Ÿè¸ªæ‰‹éƒ¨çš„20ä¸ªè‡ªç”±åº¦å’Œæ‰‹è…•çš„3ä¸ªè‡ªç”±åº¦ï¼Œé‡‡ç”¨è¿åŠ¨æ‰‹å¥—è¿›è¡ŒçœŸå®æ ‡ç­¾æ ‡æ³¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨è½»é‡çº§ç¼–ç å™¨-è§£ç å™¨æ¶æ„è¿›è¡Œå¤šä»»åŠ¡å­¦ä¹ ï¼Œå¯åŒæ—¶ä¼°è®¡æ‰‹å’Œæ‰‹è…•çš„å…³èŠ‚è§’åº¦ã€‚åœ¨ä¼ æ„Ÿå™¨é‡æ–°å®šä½çš„å®é™…æ¡ä»¶ä¸‹è¿›è¡Œçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒEMG-USèåˆå®ç°äº†å¹³å‡è¯¯å·®è§’ä¸º$10.6^\circ\pm2.0^\circ$çš„å‡æ–¹æ ¹è¯¯å·®ï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼ŒEMGä¸º$12.0^\circ\pm1^\circ$ï¼Œè€Œè¶…å£°ä¸º$13.1^\circ\pm2.6^\circ$ï¼›å¹¶ä¸”ç¡®å®šäº†ç›¸å…³æŒ‡æ•°ï¼ˆRÂ²ï¼‰å¾—åˆ†ä¸º$0.61\pm0.1$ç­‰æ€§èƒ½æŒ‡æ ‡çš„æå‡ç›¸æ¯”äºEMGå’Œè¶…å£°çš„å•æ¨¡æ€æ•°æ®æœ‰æ‰€è¶…è¶Šã€‚æ­¤å¤–æ‰€æç³»ç»Ÿä¾¿æºè½»ä¾¿å¯æŒç»­ç©¿æˆ´ç­‰ä¼˜åŠ¿ä½¿å¾—äººæœºäº¤äº’çš„ä½“éªŒè¿›ä¸€æ­¥æå‡ã€‚ç®€è€Œè¨€ä¹‹å…¶æ½œåœ¨çš„ä»·å€¼ä¸»è¦ä½“ç°åœ¨é«˜ç²¾åº¦æ‰‹éƒ¨å’Œæ‰‹è…•å§¿æ€ä¼°ç®—æå‡äººæœºäº¤äº’ä¾¿æ·æ€§å’Œå®ç”¨æ€§æ–¹é¢ç­‰ä»·å€¼æ„ä¹‰æ·±è¿œä¸”æ·±è¿œåº”ç”¨å‰æ™¯å¹¿é˜”å€¼å¾—æœŸå¾…æ·±å…¥ç ”ç©¶å’Œæ¨å¹¿åº”ç”¨ç­‰ç»“è®ºæ„è§è¡¨è¾¾æ·±åˆ»å®¢è§‚è€Œå…·ä½“ä¸”å……åˆ†å±•ç°å‡ºè®ºæ–‡ç ”ç©¶æˆæœçš„ä¼˜è¶Šæ€§å’Œé‡è¦æ€§ç­‰ç‰¹ç‚¹ä»¥åŠåœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿é˜”å‰æ™¯ç­‰æ ¸å¿ƒä»·å€¼ã€‚æ–‡ä¸­å‘ˆç°çš„ç³»ç»Ÿå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œé€‚ç”¨äºäººæœºäº¤äº’é¢†åŸŸä»¥åŠåŒ»ç–—åº·å¤ç­‰é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨æ¨å¹¿ç­‰æ–¹å‘çš„ç ”ç©¶ä¸åº”ç”¨ç­‰ã€‚æ­¤å¤–ç³»ç»Ÿæ‰€å±•ç°å‡ºçš„æ€§èƒ½ä¼˜è¶Šæ€§å¦‚ä½åŠŸè€—ä»¥åŠç©¿æˆ´ä¾¿æ·æ€§ç­‰ç‰¹ç‚¹ä¹Ÿæ˜¯æœªæ¥ç ”ç©¶çš„é‡ç‚¹æ–¹å‘ä¹‹ä¸€å€¼å¾—æŒç»­å…³æ³¨å’Œç ”ç©¶æ¢ç´¢ç­‰ç»“è®ºæ€»ç»“ç²¾è¾Ÿåˆ‡ä¸­è¦æ—¨å½’çº³å¾—ç²¾å‡†æ— è¯¯åæ˜ äº†ç ”ç©¶æ ¸å¿ƒå’Œç ”ç©¶ä»·å€¼çš„é˜è¿°ç»“æœæå…·å­¦æœ¯å‚è€ƒä»·å€¼ä»¥åŠç°å®æŒ‡å¯¼æ„ä¹‰åŒæ—¶ç¡®ä¿äº†ä½¿ç”¨æ›´ä¸ºæ¸…æ™°çš„è¯­è¨€å®Œæˆæè¿°å®ç°ä½¿ç”¨æœ¬ç¯‡æ–‡ç« çš„å¿«é€Ÿé˜…è¯»å’Œæœ‰æ•ˆç†è§£å¤§å¤§æé«˜ç†è§£å’ŒæŒæ¡ä¿¡æ¯çš„æ•ˆç‡å…·æœ‰é‡è¦æ„ä¹‰åœ¨æœªæ¥çš„å‘å±•ä¸­ç›¸å…³é¢†åŸŸä¸“å®¶å°†åœ¨åŸºç¡€ç ”ç©¶ä¸­ä»¥æ›´å¥½åœ°å®Œå–„å’Œæé«˜æ™ºèƒ½äº¤äº’æ•ˆç‡æ¢ç´¢é¢å‘æ›´é«˜ç²¾åº¦æ›´åŠ å¯é ç¨³å®šçš„åº”ç”¨é¢†åŸŸæ‰©å±•å®ç°ç ”ç©¶æˆæœçš„æ›´å¹¿æ³›åº”ç”¨ä¸ºç›®æ ‡çš„æ¢ç´¢ä¸­åšå‡ºæ›´å¤§çš„è´¡çŒ®ä½“ç°äº†ä½œè€…ä»¬æ·±åšçš„å­¦æœ¯ç§¯æ·€å’Œå¯¹æœªæ¥çš„æ·±åˆ»é¢„è§æ€§ã€‚ã€‚æ€»ä½“æ¥è¯´è¿™æ˜¯ä¸€é¡¹æå…·ä»·å€¼çš„ç ”ç©¶æˆæœå°†å¯¹æœªæ¥çš„æ™ºèƒ½äººæœºäº¤äº’é¢†åŸŸäº§ç”Ÿæ·±è¿œçš„å½±å“æœªæ¥æœ‰ç€å¹¿é˜”çš„åº”ç”¨å‰æ™¯å€¼å¾—æˆ‘ä»¬æŒç»­å…³æ³¨ä¸æ¢ç´¢æŒ–æ˜å…¶ä»·å€¼å†…æ¶µå’Œåº”ç”¨æ½œåŠ›åŒæ—¶ä½œè€…åœ¨æ–‡ç« ä¸­å±•ç¤ºçš„ä¼˜ç§€æ€»ç»“èƒ½åŠ›å’Œå…³é”®è¦ç‚¹æç‚¼èƒ½åŠ›ä¹Ÿæ˜¯å€¼å¾—å­¦ä¹ å’Œå€Ÿé‰´çš„ä¼˜ç§€å“è´¨ä¹‹ä¸€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰‹åŠ¿è¯†åˆ«åŸºäºç”Ÿç‰©ä¿¡å·å…·æœ‰å‘å±•ç›´è§‚äººæœºäº¤äº’ç­–ç•¥çš„æ½œåŠ›ï¼Œæ¨¡ä»¿è‡ªç„¶äººç±»è¡Œä¸ºã€‚</li>
<li>ä¼ æ„Ÿå™¨èåˆæ–¹æ³•ç»“åˆäº†äº’è¡¥ä¿¡æ¯ï¼Œçªç ´å•ä¸€ä¼ æ„Ÿæ¨¡å¼çš„å±€é™ã€‚</li>
<li>EMGå’ŒAæ¨¡å¼USèåˆç³»ç»Ÿæå‡ºä¸€ç§å¯ç©¿æˆ´ã€ä½èƒ½è€—çš„å¤šé€šé“ä¿¡å·é‡‡é›†ç³»ç»Ÿã€‚</li>
<li>ç³»ç»Ÿå®ç°äº†å¯¹æ‰‹éƒ¨20ä¸ªè‡ªç”±åº¦å’Œæ‰‹è…•3ä¸ªè‡ªç”±åº¦çš„è¿ç»­è·Ÿè¸ªã€‚</li>
<li>é€šè¿‡å®éªŒéªŒè¯äº†èåˆç³»ç»Ÿç›¸æ¯”å•ä¸€æ¨¡æ€çš„å‡†ç¡®æ€§æå‡ã€‚</li>
<li>ç³»ç»Ÿå…·å¤‡å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œé€‚ç”¨äºäººæœºäº¤äº’å’ŒåŒ»ç–—åº·å¤ç­‰é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨æ¨å¹¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02000">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5ebb1d92702db5d04f360a14fb364175~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031074&auth_key=1760031074-0-0-726ed819c5047db74d037f020d1a84f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9c8297f1d084852c06edde106686d3d2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031125&auth_key=1760031125-0-0-90ec61f8ee8ae837c7085192a64fcb2b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5754c3f59d37c7ef180be9d6799a300b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031132&auth_key=1760031132-0-0-156ba6b7e2a0143180ef850c3e9cde89&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d1cf5c0fb8a939ef09a50daa302fd5cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031138&auth_key=1760031138-0-0-ea200a2a213a7b224f7d6e60850cda19&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cef4562db62f076149fed9a1c7015e4e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031145&auth_key=1760031145-0-0-d55edd3e48bac2959ad5b0288dd17667&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Flow-Matching-Guided-Deep-Unfolding-for-Hyperspectral-Image-Reconstruction"><a href="#Flow-Matching-Guided-Deep-Unfolding-for-Hyperspectral-Image-Reconstruction" class="headerlink" title="Flow-Matching Guided Deep Unfolding for Hyperspectral Image   Reconstruction"></a>Flow-Matching Guided Deep Unfolding for Hyperspectral Image   Reconstruction</h2><p><strong>Authors:Yi Ai, Yuanhao Cai, Yulun Zhang, Xiaokang Yang</strong></p>
<p>Hyperspectral imaging (HSI) provides rich spatial-spectral information but remains costly to acquire due to hardware limitations and the difficulty of reconstructing three-dimensional data from compressed measurements. Although compressive sensing systems such as CASSI improve efficiency, accurate reconstruction is still challenged by severe degradation and loss of fine spectral details. We propose the Flow-Matching-guided Unfolding network (FMU), which, to our knowledge, is the first to integrate flow matching into HSI reconstruction by embedding its generative prior within a deep unfolding framework. To further strengthen the learned dynamics, we introduce a mean velocity loss that enforces global consistency of the flow, leading to a more robust and accurate reconstruction. This hybrid design leverages the interpretability of optimization-based methods and the generative capacity of flow matching. Extensive experiments on both simulated and real datasets show that FMU significantly outperforms existing approaches in reconstruction quality. Code and models will be available at <a target="_blank" rel="noopener" href="https://github.com/YiAi03/FMU">https://github.com/YiAi03/FMU</a>. </p>
<blockquote>
<p>é«˜å…‰è°±æˆåƒï¼ˆHSIï¼‰æä¾›äº†ä¸°å¯Œçš„ç©ºé—´å…‰è°±ä¿¡æ¯ï¼Œä½†ç”±äºç¡¬ä»¶é™åˆ¶ä»¥åŠä»å‹ç¼©æµ‹é‡ä¸­é‡å»ºä¸‰ç»´æ•°æ®çš„å›°éš¾ï¼Œå…¶è·å–æˆæœ¬ä»ç„¶å¾ˆé«˜ã€‚è™½ç„¶å‹ç¼©æ„ŸçŸ¥ç³»ç»Ÿï¼ˆå¦‚CASSIï¼‰æé«˜äº†æ•ˆç‡ï¼Œä½†å‡†ç¡®é‡å»ºä»é¢ä¸´ä¸¥é‡é€€åŒ–ä»¥åŠç²¾ç»†å…‰è°±ç»†èŠ‚æŸå¤±çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†æµåŒ¹é…å¼•å¯¼å±•å¼€ç½‘ç»œï¼ˆFMUï¼‰ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªå°†æµåŒ¹é…æ•´åˆåˆ°HSIé‡å»ºä¸­çš„ç½‘ç»œï¼Œé€šè¿‡åœ¨æ·±åº¦å±•å¼€æ¡†æ¶å†…åµŒå…¥å…¶ç”Ÿæˆå…ˆéªŒã€‚ä¸ºäº†è¿›ä¸€æ­¥å¼ºåŒ–å­¦ä¹ åˆ°çš„åŠ¨æ€ç‰¹æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¹³å‡é€Ÿåº¦æŸå¤±ï¼Œå¼ºåˆ¶æµçš„å…¨å±€ä¸€è‡´æ€§ï¼Œä»è€Œå¯¼è‡´æ›´ç¨³å¥å’Œå‡†ç¡®çš„é‡å»ºã€‚è¿™ç§æ··åˆè®¾è®¡åˆ©ç”¨äº†åŸºäºä¼˜åŒ–çš„æ–¹æ³•çš„å¯è§£é‡Šæ€§å’ŒæµåŒ¹é…çš„ç”Ÿæˆèƒ½åŠ›ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFMUåœ¨é‡å»ºè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/YiAi03/FMU">https://github.com/YiAi03/FMU</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01912v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é«˜å…‰è°±æˆåƒï¼ˆHSIï¼‰ä¸­çš„æµåŒ¹é…å¼•å¯¼å±•å¼€ç½‘ç»œï¼ˆFMUï¼‰ã€‚è¯¥ç½‘ç»œç»“åˆäº†æµåŒ¹é…æŠ€æœ¯ï¼Œæé«˜äº†å‹ç¼©æ„ŸçŸ¥æˆåƒç³»ç»Ÿä¸­çš„é‡å»ºæ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡ä½¿ç”¨å‡å€¼é€Ÿåº¦æŸå¤±å¢å¼ºå­¦ä¹ åŠ¨åŠ›å­¦ï¼Œä½¿å¾—é‡å»ºç»“æœæ›´åŠ ç¨³å¥å’Œå‡†ç¡®ã€‚FMUé€šè¿‡æ·±åº¦å±•å¼€æ¡†æ¶èåˆäº†ä¼˜åŒ–æ–¹æ³•çš„å¯è§£é‡Šæ€§å’ŒæµåŒ¹é…çš„ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå’Œå®é™…æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†å…¶åœ¨é‡å»ºè´¨é‡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜å…‰è°±æˆåƒï¼ˆHSIï¼‰èƒ½æä¾›ä¸°å¯Œçš„ç©ºé—´å…‰è°±ä¿¡æ¯ï¼Œä½†ç¡¬ä»¶é™åˆ¶å’Œä»å‹ç¼©æµ‹é‡ä¸­é‡å»ºä¸‰ç»´æ•°æ®çš„å›°éš¾å¯¼è‡´è·å–æˆæœ¬è¾ƒé«˜ã€‚</li>
<li>å‹ç¼©æ„ŸçŸ¥ç³»ç»Ÿå¦‚CASSIæé«˜äº†æ•ˆç‡ï¼Œä½†åœ¨ä¸¥é‡é€€åŒ–å’Œä¸¢å¤±ç²¾ç»†å…‰è°±ç»†èŠ‚çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®é‡å»ºä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>FMUç½‘ç»œé¦–æ¬¡å°†æµåŒ¹é…æŠ€æœ¯é›†æˆåˆ°HSIé‡å»ºä¸­ï¼Œé€šè¿‡æ·±åº¦å±•å¼€æ¡†æ¶åµŒå…¥å…¶ç”Ÿæˆå…ˆéªŒã€‚</li>
<li>å¼•å…¥å‡å€¼é€Ÿåº¦æŸå¤±ä»¥åŠ å¼ºå­¦ä¹ åŠ¨åŠ›å­¦ï¼Œæé«˜æµçš„å…¨å±€ä¸€è‡´æ€§ï¼Œä»è€Œå¾—åˆ°æ›´ç¨³å¥å’Œå‡†ç¡®çš„é‡å»ºç»“æœã€‚</li>
<li>FMUç»“åˆäº†ä¼˜åŒ–æ–¹æ³•çš„å¯è§£é‡Šæ€§å’ŒæµåŒ¹é…çš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿå’Œå®é™…æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFMUåœ¨é‡å»ºè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01912">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ea2440e669188a6c188e7a2c23a2456b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031152&auth_key=1760031152-0-0-fe886cd0fced3217d7705e42a385dafe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-69b501a7f0d6a3161160a059252ddc6a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031159&auth_key=1760031159-0-0-606de62552f5d84966d4123cd002ae76&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6129d5eba86478fccb7a58de1c428307~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031166&auth_key=1760031166-0-0-7516de3e329c6e9ccb7d15076f0779f0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e07b532f726c24971270d8ec9b99858a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031173&auth_key=1760031173-0-0-9d64059232274ea4a36865af60ce842c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MedQ-Bench-Evaluating-and-Exploring-Medical-Image-Quality-Assessment-Abilities-in-MLLMs"><a href="#MedQ-Bench-Evaluating-and-Exploring-Medical-Image-Quality-Assessment-Abilities-in-MLLMs" class="headerlink" title="MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment   Abilities in MLLMs"></a>MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment   Abilities in MLLMs</h2><p><strong>Authors:Jiyao Liu, Jinjie Wei, Wanying Qu, Chenglong Ma, Junzhi Ning, Yunheng Li, Ying Chen, Xinzhe Luo, Pengcheng Chen, Xin Gao, Ming Hu, Huihui Xu, Xin Wang, Shujian Gao, Dingkang Yang, Zhongying Deng, Jin Ye, Lihao Liu, Junjun He, Ningsheng Xu</strong></p>
<p>Medical Image Quality Assessment (IQA) serves as the first-mile safety gate for clinical AI, yet existing approaches remain constrained by scalar, score-based metrics and fail to reflect the descriptive, human-like reasoning process central to expert evaluation. To address this gap, we introduce MedQ-Bench, a comprehensive benchmark that establishes a perception-reasoning paradigm for language-based evaluation of medical image quality with Multi-modal Large Language Models (MLLMs). MedQ-Bench defines two complementary tasks: (1) MedQ-Perception, which probes low-level perceptual capability via human-curated questions on fundamental visual attributes; and (2) MedQ-Reasoning, encompassing both no-reference and comparison reasoning tasks, aligning model evaluation with human-like reasoning on image quality. The benchmark spans five imaging modalities and over forty quality attributes, totaling 2,600 perceptual queries and 708 reasoning assessments, covering diverse image sources including authentic clinical acquisitions, images with simulated degradations via physics-based reconstructions, and AI-generated images. To evaluate reasoning ability, we propose a multi-dimensional judging protocol that assesses model outputs along four complementary axes. We further conduct rigorous human-AI alignment validation by comparing LLM-based judgement with radiologists. Our evaluation of 14 state-of-the-art MLLMs demonstrates that models exhibit preliminary but unstable perceptual and reasoning skills, with insufficient accuracy for reliable clinical use. These findings highlight the need for targeted optimization of MLLMs in medical IQA. We hope that MedQ-Bench will catalyze further exploration and unlock the untapped potential of MLLMs for medical image quality evaluation. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ï¼ˆIQAï¼‰ä½œä¸ºä¸´åºŠäººå·¥æ™ºèƒ½çš„ç¬¬ä¸€é“å®‰å…¨é—¨ï¼Œä½†ç°æœ‰æ–¹æ³•ä»å—åˆ°åŸºäºæ ‡é‡å¾—åˆ†çš„æŒ‡æ ‡çš„åˆ¶çº¦ï¼Œæ— æ³•åæ˜ ä»¥äººç±»ä¸ºä¸­å¿ƒçš„è¯„ä¼°ä¸­çš„æè¿°æ€§å’Œæ¨ç†è¿‡ç¨‹ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MedQ-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œå®ƒå»ºç«‹äº†åŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ„ŸçŸ¥-æ¨ç†èŒƒå¼ï¼Œç”¨äºåŸºäºè¯­è¨€çš„åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ã€‚MedQ-Benchå®šä¹‰äº†ä¸¤ä¸ªäº’è¡¥çš„ä»»åŠ¡ï¼šï¼ˆ1ï¼‰MedQ-Perceptionï¼Œé€šè¿‡äººä¸ºåˆ¶å®šçš„é—®é¢˜æ¢ç´¢åŸºæœ¬çš„è§†è§‰å±æ€§æ¥æµ‹è¯•ä½å±‚æ¬¡çš„æ„ŸçŸ¥èƒ½åŠ›ï¼›ï¼ˆ2ï¼‰MedQ-Reasoningï¼ŒåŒ…å«æ— å‚è€ƒå’Œæ¯”è¾ƒæ¨ç†ä»»åŠ¡ï¼Œä½¿æ¨¡å‹è¯„ä¼°ä¸å›¾åƒè´¨é‡çš„äººç±»æ¨ç†ç›¸ä¸€è‡´ã€‚è¯¥åŸºå‡†æµ‹è¯•æ¶µç›–äº†äº”ç§æˆåƒæ¨¡å¼å’Œå››åå¤šç§è´¨é‡å±æ€§ï¼Œæ€»å…±åŒ…æ‹¬2600ä¸ªæ„ŸçŸ¥æŸ¥è¯¢å’Œ708ä¸ªæ¨ç†è¯„ä¼°ï¼Œæ¶µç›–äº†åŒ…æ‹¬çœŸå®ä¸´åºŠé‡‡é›†ã€åŸºäºç‰©ç†é‡å»ºçš„æ¨¡æ‹Ÿé€€åŒ–å›¾åƒä»¥åŠAIç”Ÿæˆçš„å›¾åƒç­‰å¤šç§å›¾åƒæ¥æºã€‚ä¸ºäº†è¯„ä¼°æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šç»´åº¦çš„åˆ¤æ–­åè®®ï¼Œè¯¥åè®®æ²¿ç€å››ä¸ªäº’è¡¥çš„è½´è¯„ä¼°æ¨¡å‹è¾“å‡ºã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡æ¯”è¾ƒåŸºäºLLMçš„åˆ¤æ–­å’Œæ”¾å°„ç§‘åŒ»å¸ˆçš„åˆ¤æ–­ï¼Œè¿›è¡Œäº†ä¸¥æ ¼çš„äººæœºå¯¹é½éªŒè¯ã€‚å¯¹14ç§æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°è¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹è™½ç„¶åˆæ­¥å…·å¤‡æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œä½†è¿˜ä¸å¤Ÿç¨³å®šï¼Œåœ¨ä¸´åºŠä½¿ç”¨ä¸­çš„å‡†ç¡®æ€§ä¸è¶³ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†é’ˆå¯¹åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬å¸Œæœ›MedQ-Benchèƒ½å¤Ÿæ¨åŠ¨è¿›ä¸€æ­¥çš„æ¢ç´¢ï¼Œå¹¶è§£é”å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01691v1">PDF</a> 26 pages, 13 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ï¼ˆIQAï¼‰ä½œä¸ºä¸´åºŠäººå·¥æ™ºèƒ½çš„ç¬¬ä¸€é“å®‰å…¨é—¨ï¼Œä½†ç°æœ‰æ–¹æ³•å—é™äºåŸºäºæ ‡é‡çš„è¯„åˆ†æŒ‡æ ‡ï¼Œæ— æ³•åæ˜ æè¿°æ€§çš„ã€ç±»ä¼¼äºäººç±»çš„æ¨ç†è¿‡ç¨‹ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºMedQ-Benchï¼Œå»ºç«‹äº†ä¸€ä¸ªæ„ŸçŸ¥æ¨ç†èŒƒå¼ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¯¹åŒ»å­¦å›¾åƒè´¨é‡è¿›è¡Œè¯­è¨€è¯„ä¼°ã€‚MedQ-Benchå®šä¹‰äº†ä¸¤ä¸ªäº’è¡¥ä»»åŠ¡ï¼šä¸€æ˜¯MedQ-æ„ŸçŸ¥ï¼Œé€šè¿‡äººå·¥è®¾è®¡çš„é—®é¢˜æ¥æ¢ç´¢åŸºç¡€è§†è§‰å±æ€§ï¼›äºŒæ˜¯MedQ-æ¨ç†ï¼ŒåŒ…æ‹¬æ— å‚è€ƒå’Œæ¯”è¾ƒæ¨ç†ä»»åŠ¡ï¼Œä½¿æ¨¡å‹è¯„ä¼°ä¸å›¾åƒè´¨é‡çš„ç±»ä¼¼äººç±»æ¨ç†ä¿æŒä¸€è‡´ã€‚è¯¥åŸºå‡†æµ‹è¯•æ¶µç›–äº†äº”ç§æˆåƒæ¨¡å¼å’Œå››åå¤šç§è´¨é‡å±æ€§ï¼Œæ€»å…±æœ‰2600ä¸ªæ„ŸçŸ¥æŸ¥è¯¢å’Œ708ä¸ªæ¨ç†è¯„ä¼°ï¼ŒåŒ…æ‹¬å„ç§å›¾åƒæ¥æºï¼Œå¦‚çœŸå®çš„ä¸´åºŠé‡‡é›†å›¾åƒã€åŸºäºç‰©ç†é‡å»ºçš„æ¨¡æ‹Ÿé€€åŒ–å›¾åƒä»¥åŠAIç”Ÿæˆçš„å›¾åƒã€‚ä¸ºäº†è¯„ä¼°æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šç»´åº¦çš„åˆ¤æ–­åè®®ï¼Œè¯¥åè®®æ²¿ç€å››ä¸ªäº’è¡¥è½´è¯„ä¼°æ¨¡å‹è¾“å‡ºã€‚é€šè¿‡ä¸æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œä¸¥æ ¼çš„â€œäººæœºå¯¹é½â€éªŒè¯ï¼Œè¿›ä¸€æ­¥è¯„ä»·äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„åˆ¤æ–­èƒ½åŠ›ã€‚æˆ‘ä»¬å¯¹æœ€å…ˆè¿›çš„14ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°è¿™äº›æ¨¡å‹è™½ç„¶åˆæ­¥å…·å¤‡æ„ŸçŸ¥å’Œæ¨ç†æŠ€èƒ½ï¼Œä½†ä¸´åºŠåº”ç”¨ä¸­å°šä¸å¯é ã€‚è¿™å¼ºè°ƒäº†é’ˆå¯¹åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°çš„éœ€è¦ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„éœ€è¦ã€‚æˆ‘ä»¬å¸Œæœ›MedQ-Benchèƒ½å¤Ÿä¿ƒè¿›è¿›ä¸€æ­¥çš„ç ”ç©¶ï¼Œå‘æ˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>MedQ-Benchæ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ä¸­äººå·¥æ™ºèƒ½ä¸äººç±»è¯„ä»·ä¹‹é—´çš„å·®è·ã€‚</li>
<li>å®ƒç»“åˆäº†æ„ŸçŸ¥å’Œæ¨ç†ä»»åŠ¡ï¼Œåæ˜ äº†ç±»ä¼¼äººç±»çš„è¯„ä¼°è¿‡ç¨‹ã€‚</li>
<li>åŸºå‡†æµ‹è¯•æ¶µç›–äº†å¤šç§æˆåƒæ¨¡å¼å’Œå›¾åƒè´¨é‡å±æ€§ï¼Œå¹¶æä¾›äº†ä¸°å¯Œçš„æ•°æ®ç”¨äºè¯„ä¼°å’Œè®­ç»ƒæ¨¡å‹ã€‚</li>
<li>é€šè¿‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œçš„æ¨ç†èƒ½åŠ›è¯„ä»·æ­ç¤ºäº†ç°æœ‰æ¨¡å‹çš„ä¸è¶³å’Œéœ€è¦æ”¹è¿›çš„æ–¹å‘ã€‚</li>
<li>ä¸æ”¾å°„å­¦ä¸“å®¶çš„äººæœºå¯¹é½éªŒè¯è¯æ˜äº†åŸºå‡†æµ‹è¯•çš„ä¸¥è°¨æ€§å’Œå®ç”¨æ€§ã€‚</li>
<li>MedQ-Benchå¼ºè°ƒäº†é’ˆå¯¹åŒ»å­¦å›¾åƒè´¨é‡è¯„ä¼°ä»»åŠ¡çš„ç‰¹å®šä¼˜åŒ–å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01691">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3301e70de5e6e9b369aac7511a7ff54e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031180&auth_key=1760031180-0-0-5a9a4d5530f4e590b1a5db24ead87e73&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2907eaa9ddfdfa896bd10643b6d1a4fc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031188&auth_key=1760031188-0-0-09eac543340b16db18be2681b430fb27&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-102666c2a0516401fba886f74d1c565a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031195&auth_key=1760031195-0-0-25f6144f9188a72d2c23e5283a99fecd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7fcdb211340d3775c735dbb82a96299f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031202&auth_key=1760031202-0-0-027884d489e4a909f1567e21fec45592&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b93d3d16d48bde01957d36157eb19eba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031209&auth_key=1760031209-0-0-577e4a5c1a36d33589375391e97a82c2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Touching-the-tumor-boundary-A-pilot-study-on-ultrasound-based-virtual-fixtures-for-breast-conserving-surgery"><a href="#Touching-the-tumor-boundary-A-pilot-study-on-ultrasound-based-virtual-fixtures-for-breast-conserving-surgery" class="headerlink" title="Touching the tumor boundary: A pilot study on ultrasound based virtual   fixtures for breast-conserving surgery"></a>Touching the tumor boundary: A pilot study on ultrasound based virtual   fixtures for breast-conserving surgery</h2><p><strong>Authors:Laura Connolly, Tamas Ungi, Adnan Munawar, Anton Deguet, Chris Yeung, Russell H. Taylor, Parvin Mousavi, Gabor Fichtinger Keyvan Hashtrudi-Zaad</strong></p>
<p>Purpose: Delineating tumor boundaries during breast-conserving surgery is challenging as tumors are often highly mobile, non-palpable, and have irregularly shaped borders. To address these challenges, we introduce a cooperative robotic guidance system that applies haptic feedback for tumor localization. In this pilot study, we aim to assess if and how this system can be successfully integrated into breast cancer care.   Methods: A small haptic robot is retrofitted with an electrocautery blade to operate as a cooperatively controlled surgical tool. Ultrasound and electromagnetic navigation are used to identify the tumor boundaries and position. A forbidden region virtual fixture is imposed when the surgical tool collides with the tumor boundary. We conducted a study where users were asked to resect tumors from breast simulants both with and without the haptic guidance. We then assess the results of these simulated resections both qualitatively and quantitatively.   Results: Virtual fixture guidance is shown to improve resection margins. On average, users find the task to be less mentally demanding, frustrating, and effort intensive when haptic feedback is available. We also discovered some unanticipated impacts on surgical workflow that will guide design adjustments and training protocol moving forward.   Conclusion: Our results suggest that virtual fixtures can help localize tumor boundaries in simulated breast-conserving surgery. Future work will include an extensive user study to further validate these results and fine-tune our guidance system. </p>
<blockquote>
<p>ç›®çš„ï¼šåœ¨ä¿ä¹³æ‰‹æœ¯ä¸­æç»˜è‚¿ç˜¤è¾¹ç•Œæ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºè‚¿ç˜¤ç»å¸¸é«˜åº¦ç§»åŠ¨ã€ä¸å¯è§¦åŠï¼Œå¹¶ä¸”å…·æœ‰ä¸è§„åˆ™å½¢çŠ¶çš„è¾¹ç•Œã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åä½œå¼æœºå™¨äººå¼•å¯¼ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨è§¦è§‰åé¦ˆæ¥è¿›è¡Œè‚¿ç˜¤å®šä½ã€‚åœ¨æœ¬è¯•ç‚¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¯„ä¼°æ­¤ç³»ç»Ÿèƒ½å¦æˆåŠŸæ•´åˆåˆ°ä¹³è…ºç™ŒæŠ¤ç†ä¸­ï¼Œä»¥åŠå¦‚ä½•å®ç°æ•´åˆã€‚</p>
</blockquote>
<p>æ–¹æ³•ï¼šä¸€ä¸ªå°å‹è§¦è§‰åé¦ˆæœºå™¨äººè¢«é‡æ–°é…å¤‡ç”µå¤–ç§‘æ‰‹æœ¯åˆ€ï¼Œç”¨ä½œåä½œæ§åˆ¶çš„æ‰‹æœ¯å·¥å…·ã€‚è¶…å£°å’Œç”µç£å¯¼èˆªè¢«ç”¨æ¥ç¡®å®šè‚¿ç˜¤è¾¹ç•Œå’Œä½ç½®ã€‚å½“æ‰‹æœ¯å·¥å…·ä¸è‚¿ç˜¤è¾¹ç•Œç¢°æ’æ—¶ï¼Œä¼šæ–½åŠ ä¸€ä¸ªç¦æ­¢åŒºåŸŸè™šæ‹Ÿå¤¹å…·ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹ç ”ç©¶ï¼Œè¦æ±‚å‚ä¸è€…å¯¹å¸¦æœ‰å’Œä¸å¸¦è§¦è§‰å¼•å¯¼çš„ä¹³æˆ¿æ¨¡æ‹Ÿç‰©è¿›è¡Œè‚¿ç˜¤åˆ‡é™¤ã€‚ç„¶åï¼Œæˆ‘ä»¬å®šæ€§å’Œå®šé‡åœ°è¯„ä¼°è¿™äº›æ¨¡æ‹Ÿåˆ‡é™¤çš„ç»“æœã€‚</p>
<p>ç»“æœï¼šè™šæ‹Ÿå¤¹å…·æŒ‡å¯¼è¢«è¯æ˜å¯ä»¥æ”¹å–„åˆ‡é™¤è¾¹ç¼˜ã€‚å¹³å‡è€Œè¨€ï¼Œå½“æä¾›è§¦è§‰åé¦ˆæ—¶ï¼Œç”¨æˆ·å‘ç°ä»»åŠ¡åœ¨ç²¾ç¥ä¸Šã€æ²®ä¸§æ„Ÿå’ŒåŠ³åŠ¨å¼ºåº¦ä¸Šéƒ½æœ‰æ‰€å‡å°‘ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†ä¸€äº›å¯¹æ‰‹æœ¯å·¥ä½œæµç¨‹çš„æ„å¤–å½±å“ï¼Œè¿™å°†æŒ‡å¯¼æˆ‘ä»¬æœªæ¥çš„è®¾è®¡è°ƒæ•´å’ŒåŸ¹è®­åè®®ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01452v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§åº”ç”¨è§¦è§‰åé¦ˆè¿›è¡Œè‚¿ç˜¤å®šä½çš„åä½œå¼æœºå™¨äººå¼•å¯¼ç³»ç»Ÿï¼Œä»¥è§£å†³ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯ä¸­è‚¿ç˜¤è¾¹ç•Œéš¾ä»¥ç¡®å®šçš„é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡æ¨¡æ‹Ÿåˆ‡é™¤æ‰‹æœ¯è¯„ä¼°è¯¥ç³»ç»Ÿçš„æ•ˆæœï¼Œå‘ç°è™šæ‹Ÿå¤¹å…·å¼•å¯¼å¯ä»¥æ”¹å–„åˆ‡é™¤è¾¹ç¼˜ï¼Œå‡å°‘ç”¨æˆ·å®Œæˆä»»åŠ¡çš„è®¤çŸ¥è´Ÿè·ã€‚ä½†ç³»ç»Ÿä¸­å­˜åœ¨ä¸€äº›æ„å¤–å½±å“ï¼Œæœªæ¥å°†å¯¹è¯¥ç³»ç»Ÿè¿›è¡Œå®Œå–„å’Œä¼˜åŒ–ã€‚æ•´ä½“ç ”ç©¶å»ºè®®å¼•å…¥æ›´å¤šçš„å®éªŒéªŒè¯ç³»ç»Ÿæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æ—¨åœ¨è§£å†³ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯ä¸­è‚¿ç˜¤è¾¹ç•Œéš¾ä»¥ç¡®å®šçš„é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨å°å‹è§¦è§‰æœºå™¨äººä½œä¸ºåˆä½œæ§åˆ¶çš„æ‰‹æœ¯å·¥å…·ï¼Œé…å¤‡ç”µåˆ€è¿›è¡Œæ¨¡æ‹Ÿåˆ‡é™¤æ‰‹æœ¯ã€‚</li>
<li>åˆ©ç”¨è¶…å£°å’Œç”µç£å¯¼èˆªæŠ€æœ¯è¯†åˆ«è‚¿ç˜¤è¾¹ç•Œå’Œä½ç½®ã€‚</li>
<li>å½“æ‰‹æœ¯å·¥å…·è§¦åŠè‚¿ç˜¤è¾¹ç•Œæ—¶ï¼Œç³»ç»Ÿä¼šå®æ–½è™šæ‹Ÿå¤¹å…·çº¦æŸã€‚</li>
<li>æ¨¡æ‹Ÿåˆ‡é™¤æ‰‹æœ¯è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè™šæ‹Ÿå¤¹å…·å¼•å¯¼å¯ä»¥æ”¹å–„åˆ‡é™¤è¾¹ç¼˜ã€‚</li>
<li>ç”¨æˆ·åœ¨æœ‰è§¦è§‰åé¦ˆçš„æƒ…å†µä¸‹ï¼Œè®¤ä¸ºä»»åŠ¡æ›´è½»æ¾ã€ä¸è´¹åŠ›ä¸”å‡å°‘äº†æŒ«è´¥æ„Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01452">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-1873dfe203ad4d01538b64708807bf8c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031216&auth_key=1760031216-0-0-3001ee11818ee8072dd6d68afd69424b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e8a692c6ac4aa00c8cfd860dcdb15177~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031223&auth_key=1760031223-0-0-8098efeecd5580f0f5e5efe8688825c4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-31ebad80b89bcc6c5e99daf916815f2e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031230&auth_key=1760031230-0-0-2559037bf4d4732304602cbbca99b569&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c8afbd17f2717883b264737eaa14aef7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031237&auth_key=1760031237-0-0-ebec8f0c6d024c33b7abd93145d39999&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="PhraseStereo-The-First-Open-Vocabulary-Stereo-Image-Segmentation-Dataset"><a href="#PhraseStereo-The-First-Open-Vocabulary-Stereo-Image-Segmentation-Dataset" class="headerlink" title="PhraseStereo: The First Open-Vocabulary Stereo Image Segmentation   Dataset"></a>PhraseStereo: The First Open-Vocabulary Stereo Image Segmentation   Dataset</h2><p><strong>Authors:Thomas Campagnolo, Ezio Malis, Philippe Martinet, Gaetan Bahl</strong></p>
<p>Understanding how natural language phrases correspond to specific regions in images is a key challenge in multimodal semantic segmentation. Recent advances in phrase grounding are largely limited to single-view images, neglecting the rich geometric cues available in stereo vision. For this, we introduce PhraseStereo, the first novel dataset that brings phrase-region segmentation to stereo image pairs. PhraseStereo builds upon the PhraseCut dataset by leveraging GenStereo to generate accurate right-view images from existing single-view data, enabling the extension of phrase grounding into the stereo domain. This new setting introduces unique challenges and opportunities for multimodal learning, particularly in leveraging depth cues for more precise and context-aware grounding. By providing stereo image pairs with aligned segmentation masks and phrase annotations, PhraseStereo lays the foundation for future research at the intersection of language, vision, and 3D perception, encouraging the development of models that can reason jointly over semantics and geometry. The PhraseStereo dataset will be released online upon acceptance of this work. </p>
<blockquote>
<p>åœ¨å¤šæ¨¡æ€è¯­ä¹‰åˆ†å‰²ä¸­ï¼Œç†è§£è‡ªç„¶è¯­è¨€çŸ­è¯­å¦‚ä½•å¯¹åº”å›¾åƒä¸­çš„ç‰¹å®šåŒºåŸŸæ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æœ€è¿‘çš„çŸ­è¯­å®šä½æŠ€æœ¯è¿›å±•ä¸»è¦å±€é™äºå•ç›®å›¾åƒï¼Œå¿½è§†äº†ç«‹ä½“è§†è§‰ä¸­ä¸°å¯Œçš„å‡ ä½•çº¿ç´¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†PhraseStereoï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†çŸ­è¯­åŒºåŸŸåˆ†å‰²å¸¦å…¥ç«‹ä½“å›¾åƒå¯¹çš„æ–°å‹æ•°æ®é›†ã€‚PhraseStereoåŸºäºPhraseCutæ•°æ®é›†æ„å»ºï¼Œåˆ©ç”¨GenStereoé€šè¿‡ç°æœ‰çš„å•ç›®æ•°æ®ç”Ÿæˆå‡†ç¡®çš„å³è§†å›¾å›¾åƒï¼Œä»è€Œå®ç°çŸ­è¯­å®šä½åœ¨ç«‹ä½“é¢†åŸŸçš„åº”ç”¨ã€‚è¿™ä¸€æ–°è®¾ç½®å¼•å…¥äº†å¤šæ¨¡æ€å­¦ä¹ çš„ç‹¬ç‰¹æŒ‘æˆ˜å’Œæœºä¼šï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ©ç”¨æ·±åº¦çº¿ç´¢è¿›è¡Œæ›´ç²¾ç¡®å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å®šä½æ–¹é¢ã€‚é€šè¿‡æä¾›å¸¦æœ‰å¯¹é½åˆ†å‰²æ©è†œå’ŒçŸ­è¯­æ³¨é‡Šçš„ç«‹ä½“å›¾åƒå¯¹ï¼ŒPhraseStereoä¸ºè¯­è¨€ã€è§†è§‰å’Œ3Dæ„ŸçŸ¥çš„äº¤å‰ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œé¼“åŠ±å¼€å‘èƒ½å¤Ÿåœ¨è¯­ä¹‰å’Œå‡ ä½•ä¸Šå…±åŒæ¨ç†çš„æ¨¡å‹ã€‚PhraseStereoæ•°æ®é›†å°†åœ¨æ¥å—æœ¬å·¥ä½œååœ¨çº¿å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00818v1">PDF</a> Accepted to X-Sense Ego-Exo Sensing for Smart Mobility Workshop at   ICCV 2025 Conference</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†PhraseStereoæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†é¦–æ¬¡å°†çŸ­è¯­åŒºåŸŸåˆ†å‰²å¼•å…¥ç«‹ä½“å›¾åƒå¯¹ï¼Œåˆ©ç”¨GenStereoç”Ÿæˆå‡†ç¡®çš„å³è§†å›¾å›¾åƒï¼Œå®ç°çŸ­è¯­å®šä½å‘ç«‹ä½“é¢†åŸŸçš„æ‰©å±•ã€‚PhraseStereoçš„è®¾ç«‹ä¸ºè·¨è¯­è¨€ã€è§†è§‰å’Œä¸‰ç»´æ„ŸçŸ¥çš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œå¹¶é¼“åŠ±å¼€å‘èƒ½å¤Ÿè”åˆå¤„ç†è¯­ä¹‰å’Œå‡ ä½•çš„æ¨¡å‹ã€‚è¯¥æ•°æ®é›†å°†åœ¨è®ºæ–‡è¢«æ¥å—ååœ¨çº¿å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PhraseStereoæ˜¯é¦–ä¸ªå°†çŸ­è¯­åŒºåŸŸåˆ†å‰²å¼•å…¥ç«‹ä½“å›¾åƒå¯¹çš„åˆ›æ–°æ•°æ®é›†ã€‚</li>
<li>æ•°æ®é›†åˆ©ç”¨GenStereoæŠ€æœ¯ç”Ÿæˆå‡†ç¡®çš„å³è§†å›¾å›¾åƒï¼Œå°†çŸ­è¯­å®šä½æ‰©å±•åˆ°ç«‹ä½“é¢†åŸŸã€‚</li>
<li>PhraseStereoçš„è®¾ç«‹ä¸ºè·¨è¯­è¨€ã€è§†è§‰å’Œä¸‰ç»´æ„ŸçŸ¥çš„ç ”ç©¶å¸¦æ¥ç‹¬ç‰¹æŒ‘æˆ˜å’Œæœºä¼šã€‚</li>
<li>æ•°æ®é›†å¼ºè°ƒæ·±åº¦çº¿ç´¢åœ¨æ›´ç²¾ç¡®å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥å®šä½ä¸­çš„ä½œç”¨ã€‚</li>
<li>æä¾›ç«‹ä½“å›¾åƒå¯¹ã€å¯¹é½çš„åˆ†å‰²æ©è†œå’ŒçŸ­è¯­æ³¨é‡Šï¼Œä¸ºè”åˆå¤„ç†è¯­ä¹‰å’Œå‡ ä½•çš„æ¨¡å‹çš„å‘å±•æ‰“ä¸‹åŸºç¡€ã€‚</li>
<li>PhraseStereoæ•°æ®é›†å°†åœ¨è®ºæ–‡è¢«æ¥å—ååœ¨çº¿å‘å¸ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00818">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0b029bd73b5e5c44d9906885af6fa634~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031244&auth_key=1760031244-0-0-2cb1d69312f5466a1f7dd59ff8a9953c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-42bfd1509b123f0bf8da7d38e610e7c9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031251&auth_key=1760031251-0-0-850c0837038fc5534247c15b8726e188&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b4a32cb2cc405aa988a5817409fa423e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031258&auth_key=1760031258-0-0-1e303da7d40b87ef64b4cdfa5a7480aa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-564c1110e0de6fadc4de2e551ca82f01~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031266&auth_key=1760031266-0-0-6af546c8a5b3984cc1d7f0bf1d160013&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="ProtoMask-Segmentation-Guided-Prototype-Learning"><a href="#ProtoMask-Segmentation-Guided-Prototype-Learning" class="headerlink" title="ProtoMask: Segmentation-Guided Prototype Learning"></a>ProtoMask: Segmentation-Guided Prototype Learning</h2><p><strong>Authors:Steffen Meinert, Philipp Schlinge, Nils Strodthoff, Martin Atzmueller</strong></p>
<p>XAI gained considerable importance in recent years. Methods based on prototypical case-based reasoning have shown a promising improvement in explainability. However, these methods typically rely on additional post-hoc saliency techniques to explain the semantics of learned prototypes. Multiple critiques have been raised about the reliability and quality of such techniques. For this reason, we study the use of prominent image segmentation foundation models to improve the truthfulness of the mapping between embedding and input space. We aim to restrict the computation area of the saliency map to a predefined semantic image patch to reduce the uncertainty of such visualizations. To perceive the information of an entire image, we use the bounding box from each generated segmentation mask to crop the image. Each mask results in an individual input in our novel model architecture named ProtoMask. We conduct experiments on three popular fine-grained classification datasets with a wide set of metrics, providing a detailed overview on explainability characteristics. The comparison with other popular models demonstrates competitive performance and unique explainability features of our model. <a target="_blank" rel="noopener" href="https://github.com/uos-sis/quanproto">https://github.com/uos-sis/quanproto</a> </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼ŒXAIè·å¾—äº†æå¤§çš„é‡è§†ã€‚åŸºäºå…¸å‹èŒƒä¾‹æ¨ç†çš„æ–¹æ³•åœ¨æé«˜è§£é‡Šæ€§æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºé¢å¤–çš„åéªŒæ˜¾è‘—æ€§æŠ€æœ¯æ¥è§£é‡Šå­¦ä¹ åˆ°çš„åŸå‹çš„è¯­ä¹‰ã€‚å…³äºè¿™äº›æŠ€æœ¯çš„å¯é æ€§å’Œè´¨é‡å·²ç»æå‡ºäº†å¤šæ¬¡æ‰¹è¯„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä½¿ç”¨é‡è¦çš„å›¾åƒåˆ†å‰²åŸºç¡€æ¨¡å‹æ¥æé«˜åµŒå…¥å’Œè¾“å…¥ç©ºé—´ä¹‹é—´æ˜ å°„çš„çœŸå®æ€§çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†æ˜¾è‘—æ€§å›¾çš„è®¡ç®—åŒºåŸŸé™åˆ¶åœ¨é¢„å®šä¹‰çš„è¯­ä¹‰å›¾åƒå—å†…ï¼Œä»¥å‡å°‘æ­¤ç±»å¯è§†åŒ–çš„ä¸ç¡®å®šæ€§ã€‚ä¸ºäº†æ„ŸçŸ¥æ•´ä¸ªå›¾åƒçš„ä¿¡æ¯ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¯ä¸ªç”Ÿæˆçš„åˆ†å‰²æ©æ¨¡çš„è¾¹ç•Œæ¡†æ¥è£å‰ªå›¾åƒã€‚æ¯ä¸ªæ©æ¨¡åœ¨æˆ‘ä»¬çš„åä¸ºProtoMaskçš„æ–°å‹æ¨¡å‹æ¶æ„ä¸­äº§ç”Ÿå•ç‹¬çš„è¾“å…¥ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªæµè¡Œçš„ç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä½¿ç”¨å¹¿æ³›çš„åº¦é‡æ ‡å‡†ï¼Œæä¾›äº†å…³äºè§£é‡Šæ€§ç‰¹å¾çš„è¯¦ç»†æ¦‚è¿°ã€‚ä¸å…¶ä»–æµè¡Œæ¨¡å‹çš„æ¯”è¾ƒè¯æ˜äº†æˆ‘ä»¬çš„æ¨¡å‹çš„ç«äº‰æ€§èƒ½å’Œç‹¬ç‰¹çš„è§£é‡Šæ€§ç‰¹å¾ã€‚è¯¦æƒ…è¯·è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/uos-sis/quanproto">https://github.com/uos-sis/quanproto</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00683v1">PDF</a> </p>
<p><strong>Summary</strong><br>     åŸºäºåŸå‹æ¡ˆä¾‹æ¨ç†çš„æ–¹æ³•åœ¨æå‡è§£é‡Šæ€§æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ä»éœ€å€ŸåŠ©é¢å¤–çš„åéªŒæ˜¾è‘—æ€§æŠ€æœ¯æ¥è§£é‡Šå­¦ä¹ åˆ°çš„åŸå‹çš„è¯­ä¹‰ã€‚ä¸ºæå‡æ˜ å°„åµŒå…¥å’Œè¾“å…¥ç©ºé—´çœŸå®æ€§çš„å¯é æ€§ï¼Œç ”ç©¶ä½¿ç”¨çŸ¥åå›¾åƒåˆ†å‰²åŸºç¡€æ¨¡å‹ã€‚é€šè¿‡é™åˆ¶æ˜¾è‘—æ€§åœ°å›¾çš„è®¡ç®—åŒºåŸŸè‡³é¢„å®šä¹‰çš„è¯­ä¹‰å›¾åƒå—ï¼Œä»¥å‡å°‘æ­¤ç±»å¯è§†åŒ–çš„ä¸ç¡®å®šæ€§ã€‚ä½¿ç”¨æ•´ä¸ªå›¾åƒçš„ä¿¡æ¯ï¼Œä»¥åˆ†æ®µé®ç½©ç”Ÿæˆçš„è¾¹ç•Œæ¡†æ¥è£å‰ªå›¾åƒã€‚å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹åœ¨ç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œä¸”å…·å¤‡ç‹¬ç‰¹çš„è§£é‡Šæ€§ç‰¹ç‚¹ã€‚è¯¦æƒ…è¯·è§<a target="_blank" rel="noopener" href="https://github.com/uos-sis/quanproto%E3%80%82">https://github.com/uos-sis/quanprotoã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>XAIè¿‘å¹´å—åˆ°é‡è§†ï¼ŒåŸºäºåŸå‹æ¡ˆä¾‹æ¨ç†çš„æ–¹æ³•æ”¹å–„äº†æ¨¡å‹çš„è§£é‡Šæ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–é¢å¤–çš„åéªŒæ˜¾è‘—æ€§æŠ€æœ¯æ¥è§£é‡ŠåŸå‹è¯­ä¹‰ï¼Œå­˜åœ¨å¯é æ€§å’Œè´¨é‡é—®é¢˜ã€‚</li>
<li>ç ”ç©¶åˆ©ç”¨çŸ¥åå›¾åƒåˆ†å‰²åŸºç¡€æ¨¡å‹æå‡æ˜ å°„åµŒå…¥å’Œè¾“å…¥ç©ºé—´çœŸå®æ€§çš„å¯é æ€§ã€‚</li>
<li>é€šè¿‡é™åˆ¶æ˜¾è‘—æ€§åœ°å›¾è®¡ç®—åŒºåŸŸè‡³é¢„å®šä¹‰çš„è¯­ä¹‰å›¾åƒå—ï¼Œé™ä½å¯è§†åŒ–ä¸ç¡®å®šæ€§ã€‚</li>
<li>ä½¿ç”¨æ•´ä¸ªå›¾åƒä¿¡æ¯ï¼Œç»“åˆåˆ†æ®µé®ç½©ç”Ÿæˆçš„è¾¹ç•Œæ¡†æ¥è£å‰ªå›¾åƒã€‚</li>
<li>å®éªŒåœ¨å¤šä¸ªç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œå±•ç¤ºæ¨¡å‹çš„ä¼˜è¶Šæ€§èƒ½å’Œç‹¬ç‰¹è§£é‡Šæ€§ç‰¹ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00683">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-415d782f254983624e287ed03b35a2c1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031274&auth_key=1760031274-0-0-acb7aa13013635d262f12f7c9c912baf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-67586b4a2642d7887c09e2ba41a991e8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031281&auth_key=1760031281-0-0-5e931a4c77569364a848e38b5112f9c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-da70cdc5c143e800d865711918ec90f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031288&auth_key=1760031288-0-0-a855c8b15e682990950c73b88ac42a86&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8570a6845e962bc1da1988672aa2fd53~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031294&auth_key=1760031294-0-0-4435f6be18617d396315bdb264e69d80&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-262915fb4b56d86022f3fb460cbb9c18~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031301&auth_key=1760031301-0-0-b8b9f175bfb4b30aa7f42dab39739b79&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dd80f393acd02fd98d491d933c916ad1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031308&auth_key=1760031308-0-0-d49e5d99d92a5dd8e6bb00f39dbacd3f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3e432edb95fe7eb43c2bcf1253945a10~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031315&auth_key=1760031315-0-0-d0fdc5a9490eae5cc986ab6cd4fb31c5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Beyond-one-hot-encoding-Journey-into-compact-encoding-for-large-multi-class-segmentation"><a href="#Beyond-one-hot-encoding-Journey-into-compact-encoding-for-large-multi-class-segmentation" class="headerlink" title="Beyond one-hot encoding? Journey into compact encoding for large   multi-class segmentation"></a>Beyond one-hot encoding? Journey into compact encoding for large   multi-class segmentation</h2><p><strong>Authors:Aaron Kujawa, Thomas Booth, Tom Vercauteren</strong></p>
<p>This work presents novel methods to reduce computational and memory requirements for medical image segmentation with a large number of classes. We curiously observe challenges in maintaining state-of-the-art segmentation performance with all of the explored options. Standard learning-based methods typically employ one-hot encoding of class labels. The computational complexity and memory requirements thus increase linearly with the number of classes. We propose a family of binary encoding approaches instead of one-hot encoding to reduce the computational complexity and memory requirements to logarithmic in the number of classes. In addition to vanilla binary encoding, we investigate the effects of error-correcting output codes (ECOCs), class weighting, hard&#x2F;soft decoding, class-to-codeword assignment, and label embedding trees. We apply the methods to the use case of whole brain parcellation with 108 classes based on 3D MRI images. While binary encodings have proven efficient in so-called extreme classification problems in computer vision, we faced challenges in reaching state-of-the-art segmentation quality with binary encodings. Compared to one-hot encoding (Dice Similarity Coefficient (DSC) &#x3D; 82.4 (2.8)), we report reduced segmentation performance with the binary segmentation approaches, achieving DSCs in the range from 39.3 to 73.8. Informative negative results all too often go unpublished. We hope that this work inspires future research of compact encoding strategies for large multi-class segmentation tasks. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€äº›å‡å°‘åŒ»å­¦å›¾åƒåˆ†å‰²å¤§è§„æ¨¡ç±»åˆ«æ‰€éœ€çš„è®¡ç®—é‡å’Œå†…å­˜ä½¿ç”¨çš„æ–°å‹æ–¹æ³•ã€‚æˆ‘ä»¬åœ¨æ‰€æœ‰æ¢ç´¢çš„é€‰é¡¹ä¸­éƒ½è§‚å¯Ÿåˆ°ä¿æŒå‰æ²¿åˆ†å‰²æ€§èƒ½çš„æŒ‘æˆ˜ã€‚åŸºäºå­¦ä¹ çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨ç±»åˆ«æ ‡ç­¾çš„ä¸€çƒ­ç¼–ç ã€‚å› æ­¤ï¼Œè®¡ç®—å¤æ‚æ€§å’Œå†…å­˜éœ€æ±‚ä¼šéšç€ç±»åˆ«çš„æ•°é‡çº¿æ€§å¢åŠ ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç³»åˆ—äºŒè¿›åˆ¶ç¼–ç æ–¹æ³•ï¼Œä»£æ›¿ä¸€çƒ­ç¼–ç ï¼Œä»¥å‡å°‘è®¡ç®—å¤æ‚æ€§å’Œå†…å­˜éœ€æ±‚ï¼Œä½¿å…¶å¯¹æ•°å¢é•¿åœ¨ç±»åˆ«æ•°é‡ä¸­ã€‚é™¤äº†åŸºæœ¬çš„äºŒè¿›åˆ¶ç¼–ç å¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†çº é”™è¾“å‡ºç ï¼ˆECOCsï¼‰ã€ç±»åˆ«æƒé‡ã€ç¡¬&#x2F;è½¯è§£ç ã€ç±»åˆ«åˆ°ç å­—çš„åˆ†é…å’Œæ ‡ç­¾åµŒå…¥æ ‘çš„å½±å“ã€‚æˆ‘ä»¬å°†è¿™äº›æ–¹æ³•åº”ç”¨äºåŸºäº3D MRIå›¾åƒçš„108ç±»å…¨è„‘ç»†åˆ†ç”¨ä¾‹ã€‚è™½ç„¶äºŒè¿›åˆ¶ç¼–ç åœ¨è®¡ç®—æœºè§†è§‰ä¸­æ‰€è°“çš„æç«¯åˆ†ç±»é—®é¢˜ä¸­è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œä½†åœ¨ä½¿ç”¨äºŒè¿›åˆ¶ç¼–ç è¾¾åˆ°å‰æ²¿åˆ†å‰²è´¨é‡æ—¶æˆ‘ä»¬é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ä¸€çƒ­ç¼–ç ï¼ˆDiceç›¸ä¼¼ç³»æ•°ï¼ˆDSCï¼‰&#x3D; 82.4ï¼ˆ2.8ï¼‰ï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬æŠ¥å‘Šçš„äºŒè¿›åˆ¶åˆ†å‰²æ–¹æ³•çš„åˆ†å‰²æ€§èƒ½æœ‰æ‰€ä¸‹é™ï¼ŒDSCèŒƒå›´åœ¨39.3åˆ°73.8ä¹‹é—´ã€‚ä¿¡æ¯æ€§çš„è´Ÿé¢ç»“æœå¾€å¾€æœªå…¬å¼€å‘è¡¨ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½æ¿€å‘æœªæ¥é’ˆå¯¹å¤§è§„æ¨¡å¤šç±»åˆ†å‰²ä»»åŠ¡è¿›è¡Œç´§å‡‘ç¼–ç ç­–ç•¥çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00667v1">PDF</a> Presented at EMA4MICCAI 2025 Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç³»åˆ—å‡å°‘åŒ»å­¦å›¾åƒåˆ†å‰²è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚çš„æ–°æ–¹æ³•ï¼Œå°¤å…¶é’ˆå¯¹å…·æœ‰å¤§é‡ç±»åˆ«çš„åˆ†å‰²ä»»åŠ¡ã€‚æ–‡ç« ä»‹ç»äº†ä½¿ç”¨äºŒè¿›åˆ¶ç¼–ç ä»£æ›¿ä¼ ç»Ÿçš„ç‹¬çƒ­ç¼–ç ï¼ˆone-hot encodingï¼‰æ¥é™ä½è®¡ç®—å¤æ‚æ€§å’Œå†…å­˜éœ€æ±‚çš„ç­–ç•¥ï¼Œå¹¶åœ¨å…¨è„‘ç»†åˆ†ï¼ˆåŒ…å«108ç±»ï¼‰çš„åº”ç”¨åœºæ™¯ä¸‹å®è·µè¿™äº›æ–¹æ³•ã€‚å°½ç®¡äºŒè¿›åˆ¶ç¼–ç åœ¨æç«¯åˆ†ç±»é—®é¢˜ä¸­è¡¨ç°å‡ºæ•ˆç‡ï¼Œä½†åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è¾¾åˆ°ä¸€æµåˆ†å‰²è´¨é‡æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œå¤„ç†å¤§é‡ç±»åˆ«æ—¶é¢ä¸´è®¡ç®—å¤æ‚æ€§å’Œå†…å­˜éœ€æ±‚çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä½¿ç”¨äºŒè¿›åˆ¶ç¼–ç ç­–ç•¥æ›¿ä»£ä¼ ç»Ÿçš„ç‹¬çƒ­ç¼–ç ï¼Œä»¥é™ä½è®¡ç®—å¤æ‚æ€§å’Œå†…å­˜éœ€æ±‚ã€‚</li>
<li>å¯¹æ¯”äº†äºŒè¿›åˆ¶ç¼–ç ä¸ç‹¬çƒ­ç¼–ç åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>äºŒè¿›åˆ¶ç¼–ç åœ¨æç«¯åˆ†ç±»é—®é¢˜ä¸­è¡¨ç°å‡ºæ•ˆç‡ï¼Œä½†åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è¾¾åˆ°ä¸€æµæ€§èƒ½å…·æœ‰æŒ‘æˆ˜ã€‚</li>
<li>é‡‡ç”¨å¤šç§ç­–ç•¥æ”¹è¿›äºŒè¿›åˆ¶ç¼–ç æ–¹æ³•ï¼ŒåŒ…æ‹¬é”™è¯¯ä¿®æ­£è¾“å‡ºç ï¼ˆECOCsï¼‰ã€ç±»åˆ«æƒé‡ã€ç¡¬&#x2F;è½¯è§£ç ç­‰ã€‚</li>
<li>åœ¨å…¨è„‘ç»†åˆ†çš„åº”ç”¨åœºæ™¯ä¸‹å®è·µè¿™äº›æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†å…·ä½“ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00667">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-80ed0d3f4d8b2b36de5e1a7bf2f51e45~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031322&auth_key=1760031322-0-0-bb221d954215d37c12efcc16a7ac904a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4df55ac605659245285155156dc4dc5f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031329&auth_key=1760031329-0-0-4a2a4223f5507e8b0a4ad53237927eca&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Multi-Domain-Brain-Vessel-Segmentation-Through-Feature-Disentanglement"><a href="#Multi-Domain-Brain-Vessel-Segmentation-Through-Feature-Disentanglement" class="headerlink" title="Multi-Domain Brain Vessel Segmentation Through Feature Disentanglement"></a>Multi-Domain Brain Vessel Segmentation Through Feature Disentanglement</h2><p><strong>Authors:Francesco Galati, Daniele Falcetta, Rosa Cortese, Ferran Prados, Ninon Burgos, Maria A. Zuluaga</strong></p>
<p>The intricate morphology of brain vessels poses significant challenges for automatic segmentation models, which usually focus on a single imaging modality. However, accurately treating brain-related conditions requires a comprehensive understanding of the cerebrovascular tree, regardless of the specific acquisition procedure. Our framework effectively segments brain arteries and veins in various datasets through image-to-image translation while avoiding domain-specific model design and data harmonization between the source and the target domain. This is accomplished by employing disentanglement techniques to independently manipulate different image properties, allowing them to move from one domain to another in a label-preserving manner. Specifically, we focus on manipulating vessel appearances during adaptation while preserving spatial information, such as shapes and locations, which are crucial for correct segmentation. Our evaluation effectively bridges large and varied domain gaps across medical centers, image modalities, and vessel types. Additionally, we conduct ablation studies on the optimal number of required annotations and other architectural choices. The results highlight our frameworkâ€™s robustness and versatility, demonstrating the potential of domain adaptation methodologies to perform cerebrovascular image segmentation in multiple scenarios accurately. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/i-vesseg/MultiVesSeg">https://github.com/i-vesseg/MultiVesSeg</a>. </p>
<blockquote>
<p>å¤§è„‘è¡€ç®¡çš„å¤æ‚å½¢æ€ç»™è‡ªåŠ¨åˆ†å‰²æ¨¡å‹å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ï¼Œé€šå¸¸è¿™äº›æ¨¡å‹åªä¸“æ³¨äºå•ä¸€çš„æˆåƒæ¨¡å¼ã€‚ç„¶è€Œï¼Œå‡†ç¡®åœ°æ²»ç–—ä¸å¤§è„‘ç›¸å…³çš„ç–¾ç—…éœ€è¦å¯¹è„‘è¡€ç®¡æ ‘æœ‰ä¸€ä¸ªå…¨é¢çš„äº†è§£ï¼Œæ— è®ºé‡‡ç”¨ä½•ç§ç‰¹å®šçš„é‡‡é›†ç¨‹åºã€‚æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿé€šè¿‡å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ï¼Œåœ¨å„ç§æ•°æ®é›†ä¸­æœ‰æ•ˆåœ°åˆ†å‰²è„‘åŠ¨è„‰å’Œé™è„‰ã€‚è¿™ä¸€è¿‡ç¨‹ä¸­é¿å…äº†é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„æ¨¡å‹è®¾è®¡å’ŒæºåŸŸä¸ç›®æ ‡åŸŸä¹‹é—´çš„æ•°æ®è°ƒå’Œã€‚è¿™æ˜¯é€šè¿‡é‡‡ç”¨è§£çº ç¼ æŠ€æœ¯ç‹¬ç«‹æ“ä½œä¸åŒçš„å›¾åƒå±æ€§æ¥å®ç°çš„ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿä»¥ä¿ç•™æ ‡ç­¾çš„æ–¹å¼ä»ä¸€ä¸ªåŸŸè½¬ç§»åˆ°å¦ä¸€ä¸ªåŸŸã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨é€‚åº”è¿‡ç¨‹ä¸­ä¸“æ³¨äºæ“ä½œè¡€ç®¡çš„å¤–è§‚ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ï¼Œå¦‚å½¢çŠ¶å’Œä½ç½®ï¼Œè¿™å¯¹äºæ­£ç¡®çš„åˆ†å‰²è‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„è¯„ä¼°æœ‰æ•ˆåœ°å¼¥åˆäº†è·¨åŒ»å­¦ä¸­å¿ƒã€å›¾åƒæ¨¡æ€å’Œè¡€ç®¡ç±»å‹çš„å¤§å‹ä¸”å¤šæ ·åŒ–çš„é¢†åŸŸå·®è·ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å…³äºæ‰€éœ€æ³¨é‡Šçš„æœ€ä½³æ•°é‡å’Œå…¶å®ƒæ¶æ„é€‰æ‹©çš„æ¶ˆèç ”ç©¶ã€‚ç»“æœçªå‡ºäº†æˆ‘ä»¬æ¡†æ¶çš„ç¨³å¥æ€§å’Œé€šç”¨æ€§ï¼Œè¯æ˜äº†åŸŸé€‚åº”æ–¹æ³•åœ¨å¤šç§åœºæ™¯ä¸‹å‡†ç¡®è¿›è¡Œè„‘è¡€ç®¡å›¾åƒåˆ†å‰²çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/i-vesseg/MultiVesSeg">https://github.com/i-vesseg/MultiVesSeg</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00665v2">PDF</a> 19 pages, 7 figures, 3 tables. Joint first authors: Francesco Galati   and Daniele Falcetta. Accepted for publication at the Journal of Machine   Learning for Biomedical Imaging (MELBA) <a target="_blank" rel="noopener" href="https://melba-journal.org/2025:021">https://melba-journal.org/2025:021</a>.   Code available at <a target="_blank" rel="noopener" href="https://github.com/i-vesseg/MultiVesSeg">https://github.com/i-vesseg/MultiVesSeg</a></p>
<p><strong>Summary</strong><br>     è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ä¸ªæ¡†æ¶ï¼Œèƒ½æœ‰æ•ˆè·¨è¶Šä¸åŒæ•°æ®é›†å¯¹è„‘åŠ¨è„‰å’Œé™è„‰è¿›è¡Œåˆ†å‰²ï¼Œé€šè¿‡å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢å®ç°ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šé¢†åŸŸè®¾è®¡æ¨¡å‹å’Œè°ƒå’ŒæºåŸŸä¸ç›®æ ‡åŸŸçš„æ•°æ®ã€‚é‡‡ç”¨è§£çº ç¼ æŠ€æœ¯ç‹¬ç«‹æ“ä½œä¸åŒå›¾åƒå±æ€§ï¼Œåœ¨ä¿æŒæ ‡ç­¾çš„åŒæ—¶ï¼Œè®©å›¾åƒå±æ€§ä»ä¸€ä¸ªé¢†åŸŸè½¬ç§»åˆ°å¦ä¸€ä¸ªé¢†åŸŸã€‚è¯¥æ¡†æ¶åœ¨é€‚åº”è¿‡ç¨‹ä¸­é‡ç‚¹å…³æ³¨è¡€ç®¡å¤–è§‚ï¼ŒåŒæ—¶ä¿ç•™å½¢çŠ¶å’Œä½ç½®ç­‰ç©ºé—´ä¿¡æ¯ï¼Œå¯¹æ­£ç¡®åˆ†å‰²è‡³å…³é‡è¦ã€‚è¯„ä¼°ç»“æœæœ‰æ•ˆè·¨è¶Šäº†ä¸åŒåŒ»ç–—ä¸­å¿ƒã€å›¾åƒæ¨¡æ€å’Œè¡€ç®¡ç±»å‹çš„é¢†åŸŸå·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¡†æ¶å¯å®ç°è„‘åŠ¨è„‰å’Œé™è„‰åœ¨ä¸åŒæ•°æ®é›†ä¸­çš„è‡ªåŠ¨åˆ†å‰²ã€‚</li>
<li>é€šè¿‡å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘å®ç°åˆ†å‰²ï¼Œæ— éœ€ç‰¹å®šé¢†åŸŸæ¨¡å‹è®¾è®¡å’Œæ•°æ®è°ƒå’Œã€‚</li>
<li>é‡‡ç”¨è§£çº ç¼ æŠ€æœ¯æ“çºµå›¾åƒå±æ€§ï¼Œå®ç°é¢†åŸŸé—´è½¬ç§»å¹¶ä¿ç•™æ ‡ç­¾ã€‚</li>
<li>æ¡†æ¶åœ¨é€‚åº”è¿‡ç¨‹ä¸­å…³æ³¨è¡€ç®¡å¤–è§‚ï¼ŒåŒæ—¶ä¿ç•™å½¢çŠ¶å’Œä½ç½®ç­‰å…³é”®ç©ºé—´ä¿¡æ¯ã€‚</li>
<li>è¯„ä¼°ç»“æœæœ‰æ•ˆè·¨è¶Šäº†åŒ»ç–—ä¸­å¿ƒã€å›¾åƒæ¨¡æ€å’Œè¡€ç®¡ç±»å‹çš„å·®å¼‚ã€‚</li>
<li>æ¡†æ¶å…·æœ‰é²æ£’æ€§å’Œå¤šåŠŸèƒ½æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00665">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7555e7d65f37c45cd6d2c98267729e28~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031336&auth_key=1760031336-0-0-de6f7b3ae5d11ca7ca181fb7a31177b4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-449929177ae5d7cb2d4dd12632fb5293~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031344&auth_key=1760031344-0-0-90729106074313b7c505508a794cad91&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-614c8968ba2b338a47b2d2cc93b3301e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031350&auth_key=1760031350-0-0-8c9cfc9f987ceb953c31f3ae826d3ee4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="U-DFA-A-Unified-DINOv2-Unet-with-Dual-Fusion-Attention-for-Multi-Dataset-Medical-Segmentation"><a href="#U-DFA-A-Unified-DINOv2-Unet-with-Dual-Fusion-Attention-for-Multi-Dataset-Medical-Segmentation" class="headerlink" title="U-DFA: A Unified DINOv2-Unet with Dual Fusion Attention for   Multi-Dataset Medical Segmentation"></a>U-DFA: A Unified DINOv2-Unet with Dual Fusion Attention for   Multi-Dataset Medical Segmentation</h2><p><strong>Authors:Zulkaif Sajjad, Furqan Shaukat, Junaid Mir</strong></p>
<p>Accurate medical image segmentation plays a crucial role in overall diagnosis and is one of the most essential tasks in the diagnostic pipeline. CNN-based models, despite their extensive use, suffer from a local receptive field and fail to capture the global context. A common approach that combines CNNs with transformers attempts to bridge this gap but fails to effectively fuse the local and global features. With the recent emergence of VLMs and foundation models, they have been adapted for downstream medical imaging tasks; however, they suffer from an inherent domain gap and high computational cost. To this end, we propose U-DFA, a unified DINOv2-Unet encoder-decoder architecture that integrates a novel Local-Global Fusion Adapter (LGFA) to enhance segmentation performance. LGFA modules inject spatial features from a CNN-based Spatial Pattern Adapter (SPA) module into frozen DINOv2 blocks at multiple stages, enabling effective fusion of high-level semantic and spatial features. Our method achieves state-of-the-art performance on the Synapse and ACDC datasets with only 33% of the trainable model parameters. These results demonstrate that U-DFA is a robust and scalable framework for medical image segmentation across multiple modalities. </p>
<blockquote>
<p>ç²¾ç¡®çš„åŒ»ç–—å›¾åƒåˆ†å‰²åœ¨æ•´ä½“è¯Šæ–­ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œæ˜¯è¯Šæ–­æµç¨‹ä¸­æœ€åŸºæœ¬çš„ä»»åŠ¡ä¹‹ä¸€ã€‚è™½ç„¶åŸºäºCNNçš„æ¨¡å‹å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œä½†å®ƒä»¬å­˜åœ¨å±€éƒ¨æ„Ÿå—é‡çš„é—®é¢˜ï¼Œæ— æ³•æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ã€‚ä¸€ç§å°†CNNä¸Transformerç»“åˆèµ·æ¥çš„å¸¸è§æ–¹æ³•è¯•å›¾å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œä½†æœªèƒ½æœ‰æ•ˆåœ°èåˆå±€éƒ¨å’Œå…¨å±€ç‰¹å¾ã€‚éšç€æœ€è¿‘è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å’ŒåŸºç¡€æ¨¡å‹çš„å…´èµ·ï¼Œå®ƒä»¬å·²è¢«åº”ç”¨äºä¸‹æ¸¸åŒ»å­¦æˆåƒä»»åŠ¡ï¼›ç„¶è€Œï¼Œå®ƒä»¬å­˜åœ¨å›ºæœ‰çš„é¢†åŸŸå·®è·å’Œé«˜è®¡ç®—æˆæœ¬çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†U-DFAï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„DINOv2-Unetç¼–ç å™¨è§£ç å™¨æ¶æ„ï¼Œå®ƒé›†æˆäº†æ–°å‹å±€éƒ¨å…¨å±€èåˆé€‚é…å™¨ï¼ˆLGFAï¼‰ä»¥å¢å¼ºåˆ†å‰²æ€§èƒ½ã€‚LGFAæ¨¡å—å°†æ¥è‡ªåŸºäºCNNçš„ç©ºé—´æ¨¡å¼é€‚é…å™¨ï¼ˆSPAï¼‰æ¨¡å—çš„ç©ºé—´ç‰¹å¾æ³¨å…¥åˆ°å¤šä¸ªé˜¶æ®µçš„å†»ç»“DINOv2å—ä¸­ï¼Œå®ç°äº†é«˜çº§è¯­ä¹‰å’Œç©ºé—´ç‰¹å¾çš„æœ‰æ•ˆèåˆã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨Synapseå’ŒACDCæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”åªæœ‰33%çš„å¯è®­ç»ƒæ¨¡å‹å‚æ•°ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒU-DFAæ˜¯ä¸€ä¸ªç¨³å¥ä¸”å¯æ‰©å±•çš„è·¨å¤šæ¨¡æ€åŒ»ç–—å›¾åƒåˆ†å‰²æ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00585v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²çš„å‡†ç¡®æ€§å¯¹æ•´ä½“è¯Šæ–­è‡³å…³é‡è¦ï¼Œæ˜¯æœ€åŸºæœ¬çš„è¯Šæ–­ä»»åŠ¡ä¹‹ä¸€ã€‚CNNæ¨¡å‹è™½ç„¶å¹¿æ³›åº”ç”¨ï¼Œä½†å­˜åœ¨å±€éƒ¨æ„Ÿå—é‡çš„é—®é¢˜ï¼Œæ— æ³•æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç»“åˆCNNä¸transformerçš„å¸¸è§„æ–¹æ³•è¯•å›¾å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œä½†æœªèƒ½æœ‰æ•ˆèåˆå±€éƒ¨å’Œå…¨å±€ç‰¹å¾ã€‚æ–°å…´VLMså’Œé¢„è®­ç»ƒæ¨¡å‹è™½è¢«ç”¨äºåŒ»å­¦æˆåƒä»»åŠ¡ï¼Œä½†å­˜åœ¨é¢†åŸŸå·®è·å’Œè®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºU-DFAï¼Œä¸€ç§åŸºäºDINOv2-Unetçš„ç¼–è§£ç å™¨æ¶æ„ï¼Œé›†æˆæ–°å‹Local-Global Fusion Adapterï¼ˆLGFAï¼‰å¢å¼ºåˆ†å‰²æ€§èƒ½ã€‚LGFAæ¨¡å—å°†CNNçš„Spatial Pattern Adapterï¼ˆSPAï¼‰æ¨¡å—çš„ç©ºé—´ç‰¹å¾æ³¨å…¥åˆ°å†»ç»“çš„DINOv2å—ä¸­ï¼Œå®ç°é«˜çº§è¯­ä¹‰å’Œç©ºé—´ç‰¹å¾çš„èåˆã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨Synapseå’ŒACDCæ•°æ®é›†ä¸Šå®ç°æœ€ä½³æ€§èƒ½ï¼Œä»…ä½¿ç”¨33%çš„å¯è®­ç»ƒæ¨¡å‹å‚æ•°ã€‚è¯æ˜U-DFAæ˜¯è·¨å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†å‰²çš„ç¨³å¥ä¸”å¯æ‰©å±•æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹è¯Šæ–­è‡³å…³é‡è¦ï¼Œæ˜¯åŸºæœ¬è¯Šæ–­ä»»åŠ¡ä¹‹ä¸€ã€‚</li>
<li>CNNæ¨¡å‹å­˜åœ¨å±€éƒ¨æ„Ÿå—é‡é—®é¢˜ï¼Œæ— æ³•æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>ç»“åˆCNNä¸transformerçš„æ–¹æ³•æœªèƒ½æœ‰æ•ˆèåˆå±€éƒ¨å’Œå…¨å±€ç‰¹å¾ã€‚</li>
<li>VLMså’Œé¢„è®­ç»ƒæ¨¡å‹åœ¨åŒ»å­¦æˆåƒä»»åŠ¡ä¸­å­˜åœ¨é¢†åŸŸå·®è·å’Œè®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚</li>
<li>U-DFAæ˜¯ä¸€ä¸ªåŸºäºDINOv2-Unetçš„ç¼–è§£ç å™¨æ¶æ„ï¼Œé›†æˆLGFAæ¨¡å—ä»¥å¢å¼ºåˆ†å‰²æ€§èƒ½ã€‚</li>
<li>LGFAæ¨¡å—å®ç°äº†é«˜çº§è¯­ä¹‰å’Œç©ºé—´ç‰¹å¾çš„èåˆã€‚</li>
<li>U-DFAæ–¹æ³•åœ¨Synapseå’ŒACDCæ•°æ®é›†ä¸Šå®ç°æœ€ä½³æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00585">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-24af08b930bb2a2d2a218cf431618263~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031357&auth_key=1760031357-0-0-3e2a9f8f41b6c7ecde8d87e6f982aca1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-af2c89ef979d69dff9b92ff4c3c18275~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031364&auth_key=1760031364-0-0-37211ee451edcc94cdbe2b8884ea4446&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-36ba073bc91e014dd47606c445cb97ad~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031370&auth_key=1760031370-0-0-04a057e7d92f252fe32fbf3a7e508c63&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7f8310b207cf874bebcf9605e1bfc286~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031377&auth_key=1760031377-0-0-6d9d5b30c545a036125aee88ad56e6f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Automated-Structured-Radiology-Report-Generation-with-Rich-Clinical-Context"><a href="#Automated-Structured-Radiology-Report-Generation-with-Rich-Clinical-Context" class="headerlink" title="Automated Structured Radiology Report Generation with Rich Clinical   Context"></a>Automated Structured Radiology Report Generation with Rich Clinical   Context</h2><p><strong>Authors:Seongjae Kang, Dong Bok Lee, Juho Jung, Dongseop Kim, Won Hwa Kim, Sunghoon Joo</strong></p>
<p>Automated structured radiology report generation (SRRG) from chest X-ray images offers significant potential to reduce workload of radiologists by generating reports in structured formats that ensure clarity, consistency, and adherence to clinical reporting standards. While radiologists effectively utilize available clinical contexts in their diagnostic reasoning, existing SRRG systems overlook these essential elements. This fundamental gap leads to critical problems including temporal hallucinations when referencing non-existent clinical contexts. To address these limitations, we propose contextualized SRRG (C-SRRG) that comprehensively incorporates rich clinical context for SRRG. We curate C-SRRG dataset by integrating comprehensive clinical context encompassing 1) multi-view X-ray images, 2) clinical indication, 3) imaging techniques, and 4) prior studies with corresponding comparisons based on patient histories. Through extensive benchmarking with state-of-the-art multimodal large language models, we demonstrate that incorporating clinical context with the proposed C-SRRG significantly improves report generation quality. We publicly release dataset, code, and checkpoints to facilitate future research for clinically-aligned automated RRG at <a target="_blank" rel="noopener" href="https://github.com/vuno/contextualized-srrg">https://github.com/vuno/contextualized-srrg</a>. </p>
<blockquote>
<p>ä»èƒ¸éƒ¨Xå°„çº¿å›¾åƒä¸­è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æ”¾å°„å­¦æŠ¥å‘Šï¼ˆSRRGï¼‰å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œé€šè¿‡ç”Ÿæˆç»“æ„åŒ–æ ¼å¼çš„æŠ¥å‘Šï¼Œå¯ä»¥å‡å°‘æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œé‡ï¼ŒåŒæ—¶ç¡®ä¿æŠ¥å‘Šçš„æ¸…æ™°æ€§ã€ä¸€è‡´æ€§å’Œç¬¦åˆä¸´åºŠæŠ¥å‘Šæ ‡å‡†ã€‚è™½ç„¶æ”¾å°„ç§‘åŒ»ç”Ÿåœ¨è¯Šæ–­æ¨ç†ä¸­ä¼šæœ‰æ•ˆåœ°åˆ©ç”¨å¯ç”¨çš„ä¸´åºŠèƒŒæ™¯ï¼Œä½†ç°æœ‰çš„SRRGç³»ç»Ÿå´å¿½è§†äº†è¿™äº›å…³é”®è¦ç´ ã€‚è¿™ä¸€åŸºæœ¬å·®è·å¯¼è‡´äº†å½“å‚è€ƒä¸å­˜åœ¨çš„ä¸´åºŠèƒŒæ™¯æ—¶å‡ºç°æ—¶é—´é”™è§‰ç­‰å…³é”®é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†èå…¥ä¸°å¯Œä¸´åºŠèƒŒæ™¯çš„ä¸Šä¸‹æ–‡ç»“æ„åŒ–æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆC-SRRGï¼‰ã€‚æˆ‘ä»¬é€šè¿‡æ•´åˆä¸°å¯Œçš„ä¸´åºŠèƒŒæ™¯æ¥æ„å»ºC-SRRGæ•°æ®é›†ï¼ŒåŒ…æ‹¬ï¼š1ï¼‰å¤šè§†è§’Xå°„çº¿å›¾åƒï¼Œ2ï¼‰ä¸´åºŠè¡¨ç°ï¼Œ3ï¼‰æˆåƒæŠ€æœ¯ï¼Œä»¥åŠ4ï¼‰åŸºäºç—…äººå†å²çš„ç›¸åº”å¯¹æ¯”çš„å…ˆå‰ç ”ç©¶ã€‚é€šè¿‡ä¸æœ€æ–°å…ˆè¿›çš„å¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¹¿æ³›åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬è¯æ˜ï¼Œç»“åˆæ‰€æå‡ºçš„C-SRRGçš„ä¸´åºŠèƒŒæ™¯å¯ä»¥æ˜¾è‘—æé«˜æŠ¥å‘Šç”Ÿæˆè´¨é‡ã€‚ä¸ºäº†æ–¹ä¾¿æœªæ¥ä¸ä¸´åºŠå¯¹é½çš„è‡ªåŠ¨åŒ–RRGç ”ç©¶ï¼Œæˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/vuno/contextualized-srrg%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E4%BA%86%E6%95%B0%E6%8D%AE%E9%9B%86%E3%80%81%E4%BB%A3%E7%A0%81%E5%92%8C%E6%A3%80%E6%9F%A5%E7%82%B9%E3%80%82">https://github.com/vuno/contextualized-srrgä¸Šå…¬å¼€å‘å¸ƒäº†æ•°æ®é›†ã€ä»£ç å’Œæ£€æŸ¥ç‚¹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00428v1">PDF</a> 34 pages, 30 figures, preprint</p>
<p><strong>Summary</strong></p>
<p>è‡ªåŠ¨åŒ–ç»“æ„æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆSRRGï¼‰ä»èƒ¸éƒ¨Xå…‰å›¾åƒä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œé€šè¿‡ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šï¼Œå‡è½»æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œé‡ï¼Œå¹¶ç¡®ä¿æŠ¥å‘Šçš„æ¸…æ™°åº¦ã€ä¸€è‡´æ€§å’Œç¬¦åˆä¸´åºŠæŠ¥å‘Šæ ‡å‡†ã€‚ç°æœ‰SRRGç³»ç»Ÿå¿½ç•¥äº†ä¸´åºŠä¸Šä¸‹æ–‡è¿™ä¸€å…³é”®å…ƒç´ ï¼Œå¯¼è‡´å‡ºç°å¼•ç”¨ä¸å­˜åœ¨çš„ä¸´åºŠä¸Šä¸‹æ–‡ç­‰é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºèå…¥ä¸°å¯Œä¸´åºŠä¸Šä¸‹æ–‡çš„ä¸Šä¸‹æ–‡åŒ–SRRGï¼ˆC-SRRGï¼‰ã€‚æˆ‘ä»¬é€šè¿‡æ•´åˆå¤šè§†è§’Xå…‰å›¾åƒã€ä¸´åºŠæŒ‡ç¤ºã€æˆåƒæŠ€æœ¯å’ŒåŸºäºæ‚£è€…ç—…å²çš„å…ˆå‰ç ”ç©¶åŠç›¸åº”å¯¹æ¯”ï¼Œæ„å»ºäº†C-SRRGæ•°æ®é›†ã€‚é€šè¿‡ä¸å›½å®¶æœ€å…ˆè¿›çš„å¤šåª’ä½“è¯­è¨€æ¨¡å‹è¿›è¡Œå¹¿æ³›åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬è¯æ˜èå…¥ä¸´åºŠä¸Šä¸‹æ–‡åçš„C-SRRGåœ¨æŠ¥å‘Šç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬å…¬å¼€å‘å¸ƒæ•°æ®é›†ã€ä»£ç å’Œæ£€æŸ¥ç‚¹ï¼Œä»¥ä¿ƒè¿›ä¸´åºŠå¯¹é½çš„è‡ªåŠ¨åŒ–RRGçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨åŒ–ç»“æ„æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆSRRGï¼‰å¯ä»¥ä»èƒ¸éƒ¨Xå…‰å›¾åƒä¸­å‡è½»æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œé‡ï¼Œæé«˜æŠ¥å‘Šçš„æ¸…æ™°åº¦ã€ä¸€è‡´æ€§å’Œç¬¦åˆä¸´åºŠæŠ¥å‘Šæ ‡å‡†ã€‚</li>
<li>ç°æœ‰SRRGç³»ç»Ÿå¿½ç•¥äº†ä¸´åºŠä¸Šä¸‹æ–‡çš„é‡è¦æ€§ï¼Œå¯¼è‡´æŠ¥å‘Šè´¨é‡å—é™ã€‚</li>
<li>ä¸Šä¸‹æ–‡åŒ–SRRGï¼ˆC-SRRGï¼‰æ—¨åœ¨è§£å†³ç°æœ‰é—®é¢˜ï¼Œå…¨é¢èå…¥ä¸°å¯Œçš„ä¸´åºŠä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>C-SRRGæ•°æ®é›†æ•´åˆäº†å¤šè§†è§’Xå…‰å›¾åƒã€ä¸´åºŠæŒ‡ç¤ºã€æˆåƒæŠ€æœ¯å’Œæ‚£è€…ç—…å²ç­‰èµ„æ–™ã€‚</li>
<li>é€šè¿‡ä¸å›½å®¶æœ€å…ˆè¿›çš„å¤šåª’ä½“è¯­è¨€æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè¯æ˜èå…¥ä¸´åºŠä¸Šä¸‹æ–‡åC-SRRGçš„æŠ¥å‘Šç”Ÿæˆè´¨é‡æ˜¾è‘—æé«˜ã€‚</li>
<li>æ•°æ®é›†ã€ä»£ç å’Œæ£€æŸ¥ç‚¹å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¾¿è¿›è¡Œè¿›ä¸€æ­¥çš„ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00428">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-80c9996e3d62940e00a14f7d781e3fcd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031385&auth_key=1760031385-0-0-7e0987a1fa78b4eb52dbeffcd74959c4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cead83a3829f57284d6d6d7ab366a216~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031392&auth_key=1760031392-0-0-8a1a9c602aa83233c85105606123383c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cc8cb80400a8fdf4968a599f0f9d1c85~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031399&auth_key=1760031399-0-0-f8049e88dd7dab660e7e9c83e5665ce6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-46a1a6da8aa5d4b0ddbafaf3ee0a3e8c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031406&auth_key=1760031406-0-0-0ce7711c732b04385a22e7d9289741a3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-55511649d5882d2935b10eec8b7334b7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031413&auth_key=1760031413-0-0-005d51452459a209ecc2a67d5bc00099&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-742e92a5a5f93147a9ee754ad72bfe22~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031420&auth_key=1760031420-0-0-19851138e6b6c756c294c1e55f03ad75&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Improving-Virtual-Contrast-Enhancement-using-Longitudinal-Data"><a href="#Improving-Virtual-Contrast-Enhancement-using-Longitudinal-Data" class="headerlink" title="Improving Virtual Contrast Enhancement using Longitudinal Data"></a>Improving Virtual Contrast Enhancement using Longitudinal Data</h2><p><strong>Authors:Pierre Fayolle, Alexandre BÃ´ne, NoÃ«lie Debs, Philippe Robert, Pascal Bourdon, Remy Guillevin, David Helbert</strong></p>
<p>Gadolinium-based contrast agents (GBCAs) are widely used in magnetic resonance imaging (MRI) to enhance lesion detection and characterisation, particularly in the field of neuro-oncology. Nevertheless, concerns regarding gadolinium retention and accumulation in brain and body tissues, most notably for diseases that require close monitoring and frequent GBCA injection, have led to the need for strategies to reduce dosage. In this study, a deep learning framework is proposed for the virtual contrast enhancement of full-dose post-contrast T1-weighted MRI images from corresponding low-dose acquisitions. The contribution of the presented model is its utilisation of longitudinal information, which is achieved by incorporating a prior full-dose MRI examination from the same patient. A comparative evaluation against a non-longitudinal single session model demonstrated that the longitudinal approach significantly improves image quality across multiple reconstruction metrics. Furthermore, experiments with varying simulated contrast doses confirmed the robustness of the proposed method. These results emphasize the potential of integrating prior imaging history into deep learning-based virtual contrast enhancement pipelines to reduce GBCA usage without compromising diagnostic utility, thus paving the way for safer, more sustainable longitudinal monitoring in clinical MRI practice. </p>
<blockquote>
<p>é’†åŸºé€ å½±å‰‚ï¼ˆGBCAsï¼‰åœ¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­å¹¿æ³›åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¥ç»è‚¿ç˜¤å­¦é¢†åŸŸï¼Œç”¨äºå¢å¼ºç—…å˜çš„æ£€æµ‹å’Œç‰¹å¾åˆ†æã€‚ç„¶è€Œï¼Œå…³äºåœ¨å¤§è„‘å’Œèº«ä½“ç»„ç»‡ä¸­é’†çš„ä¿ç•™å’Œç§¯èšçš„æ‹…å¿§ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¯†åˆ‡ç›‘æµ‹å’Œé¢‘ç¹æ³¨å°„GBCAçš„ç–¾ç—…ä¸­ï¼Œå·²ç»å¼•å‘äº†å‡å°‘å‰‚é‡çš„éœ€æ±‚ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»ç›¸åº”çš„ä½å‰‚é‡é‡‡é›†ä¸­å¯¹å…¨å‰‚é‡å¯¹æ¯”å‰‚åçš„T1åŠ æƒMRIå›¾åƒè¿›è¡Œè™šæ‹Ÿå¯¹æ¯”åº¦å¢å¼ºã€‚æ‰€æå‡ºæ¨¡å‹çš„è´¡çŒ®åœ¨äºå…¶åˆ©ç”¨äº†çºµå‘ä¿¡æ¯ï¼Œè¿™æ˜¯é€šè¿‡ç»“åˆæ¥è‡ªåŒä¸€æ‚£è€…çš„å…ˆå‰å…¨å‰‚é‡MRIæ£€æŸ¥æ¥å®ç°çš„ã€‚ä¸éçºµå‘å•ä¼šè¯æ¨¡å‹çš„æ¯”è¾ƒè¯„ä¼°è¡¨æ˜ï¼Œçºµå‘æ–¹æ³•åœ¨å¤šä¸ªé‡å»ºæŒ‡æ ‡ä¸Šæ˜¾è‘—æé«˜äº†å›¾åƒè´¨é‡ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ä¸åŒæ¨¡æ‹Ÿå¯¹æ¯”å‰‚å‰‚é‡çš„å®éªŒè¯å®äº†æ‰€æå‡ºæ–¹æ³•çš„ç¨³å¥æ€§ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†å°†å…ˆå‰æˆåƒå†å²èå…¥åŸºäºæ·±åº¦å­¦ä¹ çš„è™šæ‹Ÿå¯¹æ¯”åº¦å¢å¼ºç®¡é“ä¸­çš„æ½œåŠ›ï¼Œå¯ä»¥åœ¨ä¸æŸå®³è¯Šæ–­æ•ˆç”¨çš„æƒ…å†µä¸‹å‡å°‘GBCAçš„ä½¿ç”¨ï¼Œä»è€Œä¸ºä¸´åºŠMRIå®è·µä¸­æ›´å®‰å…¨ã€æ›´å¯æŒç»­çš„çºµå‘ç›‘æµ‹é“ºå¹³é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00418v2">PDF</a> 11 pages, 4 figures, Workshop MICCAI 2025 - Learning with   Longitudinal Medical Images and Data</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œé€šè¿‡åˆ©ç”¨æ‚£è€…çš„çºµå‘ä¿¡æ¯ï¼Œå¯¹ä½å‰‚é‡MRIå›¾åƒè¿›è¡Œè™šæ‹Ÿå¯¹æ¯”å¢å¼ºï¼Œä»¥å‡å°‘é’†åŸºé€ å½±å‰‚çš„ä½¿ç”¨é‡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æé«˜å›¾åƒè´¨é‡ï¼Œå¹¶å…·å¤‡åœ¨ä¸åŒæ¨¡æ‹Ÿå¯¹æ¯”å‰‚é‡ä¸‹çš„ç¨³å¥æ€§ã€‚è¿™ä¸ºä¸´åºŠMRIå®è·µä¸­æ›´å®‰å…¨ã€æ›´å¯æŒç»­çš„çºµå‘ç›‘æµ‹é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é’†åŸºé€ å½±å‰‚ï¼ˆGBCAsï¼‰åœ¨æ ¸ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†ä¿ç•™å’Œç§¯ç´¯åœ¨å¤§è„‘å’Œäººä½“ç»„ç»‡ä¸­çš„é—®é¢˜å¼•å‘äº†å‡å°‘ç”¨é‡çš„éœ€æ±‚ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨æ‚£è€…çš„çºµå‘ä¿¡æ¯ï¼Œä»å¯¹åº”çš„ä½å‰‚é‡å›¾åƒä¸­è™šæ‹Ÿå¢å¼ºå…¨å‰‚é‡å¯¹æ¯”åçš„T1åŠ æƒMRIå›¾åƒã€‚</li>
<li>è¯¥æ¨¡å‹é€šè¿‡èå…¥æ‚£è€…å…ˆå‰çš„å…¨å‰‚é‡MRIæ£€æŸ¥æ¥å®ç°çºµå‘ä¿¡æ¯åˆ©ç”¨ã€‚</li>
<li>ä¸éçºµå‘çš„å•æ¬¡ä¼šè¯æ¨¡å‹ç›¸æ¯”ï¼Œçºµå‘æ–¹æ³•æ˜¾è‘—æé«˜äº†å›¾åƒè´¨é‡ï¼Œä½“ç°åœ¨å¤šç§é‡å»ºæŒ‡æ ‡ä¸Šã€‚</li>
<li>é€šè¿‡ä¸åŒæ¨¡æ‹Ÿå¯¹æ¯”å‰‚é‡çš„å®éªŒï¼ŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„ç¨³å¥æ€§ã€‚</li>
<li>æ•´åˆå…ˆå‰æˆåƒå†å²è¿›å…¥æ·±åº¦å­¦ä¹ è™šæ‹Ÿå¯¹æ¯”å¢å¼ºæµç¨‹ï¼Œå¯åœ¨ä¸æŸå®³è¯Šæ–­æ•ˆç”¨çš„æƒ…å†µä¸‹å‡å°‘GBCAçš„ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00418">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f0c50d895a61a60646c9969d2a4055c4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031427&auth_key=1760031427-0-0-e0071c4de3bdb56a21a519d28e4d6f99&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-974ce1d7a699957b4ab6eddc5861c841~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031434&auth_key=1760031434-0-0-3fd03975cdb6e8db6bcf7be238caeeff&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-139a60fb5159b3f12b0bb9df2299ff01~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031440&auth_key=1760031440-0-0-e2b3972fcf7eb2b19707133ffcf33714&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-28e6690318667a471a0cc185f5672026~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031447&auth_key=1760031447-0-0-e2625c5b668606167963fbd921318204&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Domain-Specialized-Interactive-Segmentation-Framework-for-Meningioma-Radiotherapy-Planning"><a href="#Domain-Specialized-Interactive-Segmentation-Framework-for-Meningioma-Radiotherapy-Planning" class="headerlink" title="Domain-Specialized Interactive Segmentation Framework for Meningioma   Radiotherapy Planning"></a>Domain-Specialized Interactive Segmentation Framework for Meningioma   Radiotherapy Planning</h2><p><strong>Authors:Junhyeok Lee, Han Jang, Kyu Sung Choi</strong></p>
<p>Precise delineation of meningiomas is crucial for effective radiotherapy (RT) planning, directly influencing treatment efficacy and preservation of adjacent healthy tissues. While automated deep learning approaches have demonstrated considerable potential, achieving consistently accurate clinical segmentation remains challenging due to tumor heterogeneity. Interactive Medical Image Segmentation (IMIS) addresses this challenge by integrating advanced AI techniques with clinical input. However, generic segmentation tools, despite widespread applicability, often lack the specificity required for clinically critical and disease-specific tasks like meningioma RT planning. To overcome these limitations, we introduce Interactive-MEN-RT, a dedicated IMIS tool specifically developed for clinician-assisted 3D meningioma segmentation in RT workflows. The system incorporates multiple clinically relevant interaction methods, including point annotations, bounding boxes, lasso tools, and scribbles, enhancing usability and clinical precision. In our evaluation involving 500 contrast-enhanced T1-weighted MRI scans from the BraTS 2025 Meningioma RT Segmentation Challenge, Interactive-MEN-RT demonstrated substantial improvement compared to other segmentation methods, achieving Dice similarity coefficients of up to 77.6% and Intersection over Union scores of 64.8%. These results emphasize the need for clinically tailored segmentation solutions in critical applications such as meningioma RT planning. The code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/snuh-rad-aicon/Interactive-MEN-RT">https://github.com/snuh-rad-aicon/Interactive-MEN-RT</a> </p>
<blockquote>
<p>è„‘è†œç˜¤çš„ç²¾ç¡®è½®å»“æç»˜å¯¹äºæœ‰æ•ˆçš„æ”¾å°„æ²»ç–—ï¼ˆRTï¼‰è®¡åˆ’è‡³å…³é‡è¦ï¼Œç›´æ¥å½±å“æ²»ç–—æ•ˆæœå’Œé‚»è¿‘å¥åº·ç»„ç»‡çš„ä¿æŠ¤ã€‚è™½ç„¶è‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ çš„æ–¹æ³•å·²ç»æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ç”±äºè‚¿ç˜¤çš„å¼‚è´¨æ€§ï¼Œå®ç°ä¸€è‡´çš„å‡†ç¡®ä¸´åºŠåˆ†å‰²ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚äº¤äº’å¼åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆIMISï¼‰é€šè¿‡æ•´åˆå…ˆè¿›çš„AIæŠ€æœ¯å’Œä¸´åºŠè¾“å…¥æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œé€šç”¨åˆ†å‰²å·¥å…·è™½ç„¶åº”ç”¨å¹¿æ³›ï¼Œä½†å¾€å¾€ç¼ºä¹ç”¨äºä¸´åºŠå…³é”®å’Œç‰¹å®šç–¾ç—…ä»»åŠ¡æ‰€éœ€çš„ç‰¹å¼‚æ€§ï¼Œå¦‚è„‘è†œç˜¤RTè§„åˆ’ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Interactive-MEN-RTï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“é—¨ä¸ºä¸´åºŠåŒ»ç”Ÿè¾…åŠ©RTå·¥ä½œæµç¨‹ä¸­çš„3Dè„‘è†œç˜¤åˆ†å‰²è€Œå¼€å‘çš„ä¸“ç”¨IMISå·¥å…·ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†å¤šç§ä¸´åºŠä¸Šç›¸å…³çš„äº¤äº’æ–¹æ³•ï¼ŒåŒ…æ‹¬ç‚¹æ³¨é‡Šã€è¾¹ç•Œæ¡†ã€å¥—ç´¢å·¥å…·å’Œæ¶‚é¸¦ï¼Œå¢å¼ºäº†å¯ç”¨æ€§å’Œä¸´åºŠç²¾ç¡®åº¦ã€‚åœ¨æˆ‘ä»¬çš„è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ªBraTS 2025è„‘è†œç˜¤RTåˆ†å‰²æŒ‘æˆ˜çš„500å¼ å¯¹æ¯”å¢å¼ºçš„T1åŠ æƒMRIæ‰«æã€‚ç›¸è¾ƒäºå…¶ä»–åˆ†å‰²æ–¹æ³•ï¼ŒInteractive-MEN-RTè¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ï¼Œç‹„å…‹ç›¸ä¼¼ç³»æ•°æœ€é«˜è¾¾åˆ°77.6ï¼…ï¼Œäº¤å¹¶æ¯”åˆ†æ•°ä¸º64.8ï¼…ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†åœ¨å…³é”®åº”ç”¨å¦‚è„‘è†œç˜¤RTè§„åˆ’ä¸­ï¼Œéœ€è¦é‡èº«å®šåˆ¶çš„ä¸´åºŠåˆ†å‰²è§£å†³æ–¹æ¡ˆã€‚ä»£ç å…¬å¼€å¯ç”¨åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/snuh-rad-aicon/Interactive-MEN-RT">https://github.com/snuh-rad-aicon/Interactive-MEN-RT</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00416v1">PDF</a> Clinical Image-Based Procedures (CLIP 2025), MICCAI 2025 Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºInteractive-MEN-RTçš„äº¤äº’å¼åŒ»å­¦å›¾åƒåˆ†å‰²å·¥å…·ï¼Œè¯¥å·¥å…·ä¸“ä¸ºä¸´åºŠåŒ»ç”Ÿè¾…åŠ©çš„ä¸‰ç»´è„‘è†œç˜¤æ”¾å°„æ²»ç–—è®¡åˆ’åˆ†å‰²è€Œå¼€å‘ã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„AIæŠ€æœ¯å’Œä¸´åºŠè¾“å…¥ï¼Œè§£å†³äº†é€šç”¨åˆ†å‰²å·¥å…·ç¼ºä¹ç‰¹å®šç–¾ç—…åº”ç”¨ç‰¹å¼‚æ€§çš„é—®é¢˜ã€‚åœ¨æ¶‰åŠBraTS 2025è„‘è†œç˜¤RTåˆ†å‰²æŒ‘æˆ˜çš„500ä¸ªå¢å¼ºT1åŠ æƒMRIæ‰«æçš„è¯„ä¼°ä¸­ï¼ŒInteractive-MEN-RTç›¸è¾ƒäºå…¶ä»–åˆ†å‰²æ–¹æ³•è¡¨ç°å‡ºæ˜¾è‘—æ”¹å–„ï¼Œå®ç°äº†é«˜è¾¾77.6%çš„Diceç›¸ä¼¼ç³»æ•°å’Œ64.8%çš„äº¤é›†æ¯”ã€‚è¿™è¡¨æ˜åœ¨ä¸´åºŠåº”ç”¨å¦‚è„‘è†œç˜¤RTè§„åˆ’ä¸­éœ€è¦é’ˆå¯¹æ€§çš„åˆ†å‰²è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è„‘è†œç˜¤çš„ç²¾ç¡®åˆ†å‰²å¯¹æ”¾å°„æ²»ç–—è®¡åˆ’è‡³å…³é‡è¦ï¼Œå½±å“æ²»ç–—æ•ˆæœå’Œé‚»è¿‘å¥åº·ç»„ç»‡çš„ä¿æŠ¤ã€‚</li>
<li>è‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­æœ‰æ½œåŠ›ï¼Œä½†å®ç°å‡†ç¡®ä¸´åºŠåˆ†å‰²ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä¸»è¦ç”±äºè‚¿ç˜¤å¼‚è´¨æ€§ã€‚</li>
<li>äº¤äº’å¼åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆIMISï¼‰é€šè¿‡æ•´åˆå…ˆè¿›AIæŠ€æœ¯å’Œä¸´åºŠè¾“å…¥æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>é€šç”¨åˆ†å‰²å·¥å…·ç¼ºä¹é’ˆå¯¹ç‰¹å®šç–¾ç—…å¦‚è„‘è†œç˜¤RTè§„åˆ’çš„ä¸´åºŠç‰¹å¼‚æ€§éœ€æ±‚ã€‚</li>
<li>Interactive-MEN-RTæ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºä¸´åºŠåŒ»ç”Ÿè¾…åŠ©çš„è„‘è†œç˜¤æ”¾å°„æ²»ç–—è®¡åˆ’ä¸­çš„ä¸‰ç»´åˆ†å‰²å¼€å‘çš„IMISå·¥å…·ã€‚</li>
<li>è¯¥ç³»ç»Ÿç»“åˆäº†å¤šç§ä¸´åºŠç›¸å…³çš„äº¤äº’æ–¹æ³•ï¼Œå¦‚ç‚¹æ³¨é‡Šã€è¾¹ç•Œæ¡†ã€æ‹‰ç´¢å·¥å…·å’Œæ¶‚é¸¦ï¼Œæé«˜äº†å¯ç”¨æ€§å’Œä¸´åºŠç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00416">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-87408d7c8bebc652626c45a23417d671~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031455&auth_key=1760031455-0-0-a8d58c721aa06a8af9a31e8db4d2308d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b5d1dddcb1c8d09ef9317759d6900952~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031462&auth_key=1760031462-0-0-97505272e5e2c54d4cbcff7a8d5e8201&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4f44294221847e7a520cb94c4dcb3ecd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031469&auth_key=1760031469-0-0-44fbd1149e1db126fcab21cb404606e9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1d068b718a58bf789fb80880cb0d2766~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031475&auth_key=1760031475-0-0-d43e3682002a6174623907927b93d4c9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Causal-Adapter-Taming-Text-to-Image-Diffusion-for-Faithful-Counterfactual-Generation"><a href="#Causal-Adapter-Taming-Text-to-Image-Diffusion-for-Faithful-Counterfactual-Generation" class="headerlink" title="Causal-Adapter: Taming Text-to-Image Diffusion for Faithful   Counterfactual Generation"></a>Causal-Adapter: Taming Text-to-Image Diffusion for Faithful   Counterfactual Generation</h2><p><strong>Authors:Lei Tong, Zhihua Liu, Chaochao Lu, Dino Oglic, Tom Diethe, Philip Teare, Sotirios A. Tsaftaris, Chen Jin</strong></p>
<p>We present Causal-Adapter, a modular framework that adapts frozen text-to-image diffusion backbones for counterfactual image generation. Our method enables causal interventions on target attributes, consistently propagating their effects to causal dependents without altering the core identity of the image. In contrast to prior approaches that rely on prompt engineering without explicit causal structure, Causal-Adapter leverages structural causal modeling augmented with two attribute regularization strategies: prompt-aligned injection, which aligns causal attributes with textual embeddings for precise semantic control, and a conditioned token contrastive loss to disentangle attribute factors and reduce spurious correlations. Causal-Adapter achieves state-of-the-art performance on both synthetic and real-world datasets, with up to 91% MAE reduction on Pendulum for accurate attribute control and 87% FID reduction on ADNI for high-fidelity MRI image generation. These results show that our approach enables robust, generalizable counterfactual editing with faithful attribute modification and strong identity preservation. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†å› æœé€‚é…å™¨ï¼ˆCausal-Adapterï¼‰è¿™ä¸€æ¨¡å—åŒ–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨é€‚åº”å†»ç»“çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œåäº‹å®å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨ç›®æ ‡å±æ€§ä¸Šå®æ–½å› æœå¹²é¢„ï¼Œå¹¶å§‹ç»ˆå¦‚ä¸€åœ°å°†å®ƒä»¬çš„å½±å“ä¼ æ’­åˆ°å› æœä¾èµ–é¡¹ï¼Œè€Œä¸ä¼šæ”¹å˜å›¾åƒçš„æ ¸å¿ƒèº«ä»½ã€‚ä¸ä¾èµ–æç¤ºå·¥ç¨‹è€Œä¸å…·å¤‡æ˜ç¡®å› æœç»“æ„çš„å‰æœŸæ–¹æ³•ç›¸æ¯”ï¼Œå› æœé€‚é…å™¨åˆ©ç”¨ç»“æ„å› æœå»ºæ¨¡å¹¶è¾…ä»¥ä¸¤ç§å±æ€§æ­£åˆ™åŒ–ç­–ç•¥ï¼šæç¤ºå¯¹é½æ³¨å…¥ï¼Œè¯¥ç­–ç•¥å°†å› æœå±æ€§ä¸æ–‡æœ¬åµŒå…¥è¿›è¡Œå¯¹é½ä»¥ç²¾ç¡®è¯­ä¹‰æ§åˆ¶ï¼›ä»¥åŠæ¡ä»¶ä»¤ç‰Œå¯¹æ¯”æŸå¤±ï¼Œä»¥åˆ†ç¦»å±æ€§å› ç´ å¹¶å‡å°‘ä¼ªç›¸å…³æ€§ã€‚å› æœé€‚é…å™¨åœ¨åˆæˆæ•°æ®é›†å’Œç°å®ä¸–ç•Œæ•°æ®é›†ä¸Šéƒ½å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨æ‘†é”¤æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾91%çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰é™ä½ä»¥å®ç°ç²¾ç¡®çš„å±æ€§æ§åˆ¶ï¼Œåœ¨ADNIæ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾87%çš„å¼—é›·æ­‡ç‰¹æƒ¯æ€§è·ç¦»ï¼ˆFIDï¼‰é™ä½ä»¥å®ç°é«˜ä¿çœŸç£å…±æŒ¯æˆåƒå›¾åƒç”Ÿæˆã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°ç¨³å¥ã€é€šç”¨çš„åäº‹å®ç¼–è¾‘ï¼Œå…·æœ‰å¯é çš„å±æ€§ä¿®æ”¹å’Œå¼ºå¤§çš„èº«ä»½ä¿ç•™èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24798v2">PDF</a> 9 pages, 26 figures</p>
<p><strong>Summary</strong></p>
<p>Causal-Adapteræ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œç”¨äºé€‚åº”å†»ç»“çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ä¸»å¹²ï¼Œä»¥è¿›è¡Œåäº‹å®å›¾åƒç”Ÿæˆã€‚é€šè¿‡å› æœå¹²é¢„ç›®æ ‡å±æ€§ï¼Œè¯¥æ¡†æ¶èƒ½åœ¨ä¸å½±å“å›¾åƒæ ¸å¿ƒèº«ä»½çš„æƒ…å†µä¸‹ï¼Œå°†æ•ˆåº”ä¸€è‡´åœ°ä¼ æ’­åˆ°å› æœä¾èµ–é¡¹ã€‚ä¸åŒäºä¾èµ–æç¤ºå·¥ç¨‹ä¸”æ— æ˜ç¡®å› æœç»“æ„çš„æ–¹æ³•ï¼ŒCausal-Adapterç»“åˆäº†ç»“æ„å› æœå»ºæ¨¡åŠä¸¤ç§å±æ€§æ­£åˆ™åŒ–ç­–ç•¥ï¼šä¸æ–‡æœ¬åµŒå…¥å¯¹é½çš„æ³¨å…¥æ³•ç”¨äºç²¾ç¡®è¯­ä¹‰æ§åˆ¶ï¼Œæ¡ä»¶ä»¤ç‰Œå¯¹æ¯”æŸå¤±æ³•ç”¨äºåˆ†è§£å±æ€§å› ç´ å¹¶å‡å°‘å¶ç„¶å…³è”ã€‚Causal-Adapteråœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡å–å¾—å“è¶Šè¡¨ç°ï¼Œå®ç°äº†ç²¾å‡†çš„å±æ€§æ§åˆ¶å’Œèº«ä»½ä¿ç•™ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Causal-Adapteræ˜¯ä¸€ä¸ªç”¨äºåäº‹å®å›¾åƒç”Ÿæˆçš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œé€‚åº”å†»ç»“çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½é€šè¿‡å› æœå¹²é¢„ç›®æ ‡å±æ€§ï¼Œä¸€è‡´åœ°å½±å“å› æœä¾èµ–é¡¹ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„æ ¸å¿ƒèº«ä»½ä¸å˜ã€‚</li>
<li>ä¸ä¾èµ–æç¤ºå·¥ç¨‹ä¸”æ— æ˜ç¡®å› æœç»“æ„çš„æ–¹æ³•ä¸åŒï¼ŒCausal-Adapterç»“åˆç»“æ„å› æœå»ºæ¨¡ã€‚</li>
<li>Causal-Adapteré‡‡ç”¨ä¸¤ç§å±æ€§æ­£åˆ™åŒ–ç­–ç•¥ï¼šä¸æ–‡æœ¬åµŒå…¥å¯¹é½çš„æ³¨å…¥æ³•å’Œæ¡ä»¶ä»¤ç‰Œå¯¹æ¯”æŸå¤±æ³•ã€‚</li>
<li>å¯¹ç§°æ³•å®ç°äº†ç²¾å‡†çš„å±æ€§æ§åˆ¶ï¼Œé€šè¿‡ç»“æ„å› æœå»ºæ¨¡ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒå›¾åƒèº«ä»½çš„åŒæ—¶ä¿®æ”¹å±æ€§ã€‚</li>
<li>Causal-Adapteråœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å±æ€§æ§åˆ¶å’Œèº«ä»½ä¿ç•™æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24798">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2085fcc818d49752747eb4e8696b308e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031483&auth_key=1760031483-0-0-e85d67227439c03d5e076704661a8725&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1f91aabcf0a92ff67f7b3aac155b1709~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031491&auth_key=1760031491-0-0-6c98d7d23cb451e82c45213911ebd668&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7e4b0d05ef2fa28981b9f5a7ae403ede~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031497&auth_key=1760031497-0-0-d52bda95f7068f9971039170e54ff50d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3afac3e97d200b9e29b522d2fc74472b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031504&auth_key=1760031504-0-0-c8b7f0c6f122aed3b50376023bcd567a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-acc1f9c10b5d013a6b0e98327d00595a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031511&auth_key=1760031511-0-0-0d135415520d689c0cc2c63762357916&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="RIFLE-Removal-of-Image-Flicker-Banding-via-Latent-Diffusion-Enhancement"><a href="#RIFLE-Removal-of-Image-Flicker-Banding-via-Latent-Diffusion-Enhancement" class="headerlink" title="RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement"></a>RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement</h2><p><strong>Authors:Libo Zhu, Zihan Zhou, Xiaoyang Liu, Weihang Zhang, Keyu Shi, Yifan Fu, Yulun Zhang</strong></p>
<p>Capturing screens is now routine in our everyday lives. But the photographs of emissive displays are often influenced by the flicker-banding (FB), which is alternating bright%u2013dark stripes that arise from temporal aliasing between a cameraâ€™s rolling-shutter readout and the displayâ€™s brightness modulation. Unlike moire degradation, which has been extensively studied, the FB remains underexplored despite its frequent and severe impact on readability and perceived quality. We formulate FB removal as a dedicated restoration task and introduce Removal of Image Flicker-Banding via Latent Diffusion Enhancement, RIFLE, a diffusion-based framework designed to remove FB while preserving fine details. We propose the flicker-banding prior estimator (FPE) that predicts key banding attributes and injects it into the restoration network. Additionally, Masked Loss (ML) is proposed to concentrate supervision on banded regions without sacrificing global fidelity. To overcome data scarcity, we provide a simulation pipeline that synthesizes FB in the luminance domain with stochastic jitter in banding angle, banding spacing, and banding width. Feathered boundaries and sensor noise are also applied for a more realistic simulation. For evaluation, we collect a paired real-world FB dataset with pixel-aligned banding-free references captured via long exposure. Across quantitative metrics and visual comparisons on our real-world dataset, RIFLE consistently outperforms recent image reconstruction baselines from mild to severe flicker-banding. To the best of our knowledge, it is the first work to research the simulation and removal of FB. Our work establishes a great foundation for subsequent research in both the dataset construction and the removal model design. Our dataset and code will be released soon. </p>
<blockquote>
<p>å±å¹•æˆªå›¾ç°åœ¨å·²ç»æˆä¸ºäº†æˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»ä¸­çš„å¸¸è§„æ“ä½œã€‚ç„¶è€Œï¼Œå‘å…‰æ˜¾ç¤ºå™¨çš„ç…§ç‰‡å¾€å¾€å—åˆ°é¢‘é—ªå¸¦çŠ¶ç°è±¡ï¼ˆFBï¼‰çš„å½±å“ï¼Œè¯¥ç°è±¡æ˜¯ç”±äºç›¸æœºæ»šåŠ¨å¿«é—¨è¯»å‡ºä¸æ˜¾ç¤ºå™¨äº®åº¦è°ƒåˆ¶ä¹‹é—´çš„æ—¶é—´æ··å è€Œäº§ç”Ÿçš„æ˜æš—äº¤æ›¿æ¡çº¹ã€‚ä¸æ‘©å°”çº¹é€€åŒ–ï¼ˆå·²è¢«å¹¿æ³›ç ”ç©¶ï¼‰ä¸åŒï¼Œå°½ç®¡é¢‘é—ªå¸¦çŠ¶ç°è±¡å¯¹å¯è¯»æ€§å’Œæ„ŸçŸ¥è´¨é‡é€ æˆé¢‘ç¹ä¸”ä¸¥é‡çš„å½±å“ï¼Œä½†å…¶ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚æˆ‘ä»¬å°†é¢‘é—ªå¸¦çŠ¶ç°è±¡çš„å»é™¤åˆ¶å®šä¸ºä¸“é—¨çš„æ¢å¤ä»»åŠ¡ï¼Œå¹¶å¼•å…¥äº†é€šè¿‡æ½œåœ¨æ‰©æ•£å¢å¼ºå»é™¤å›¾åƒé¢‘é—ªå¸¦çŠ¶ç°è±¡ï¼ˆRIFLEï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£çš„æ¡†æ¶ï¼Œæ—¨åœ¨å»é™¤é¢‘é—ªå¸¦çŠ¶ç°è±¡åŒæ—¶ä¿ç•™ç»†èŠ‚ã€‚æˆ‘ä»¬æå‡ºäº†é¢‘é—ªå¸¦çŠ¶å…ˆéªŒä¼°è®¡å™¨ï¼ˆFPEï¼‰ï¼Œå®ƒé¢„æµ‹å…³é”®çš„å¸¦çŠ¶å±æ€§å¹¶å°†å…¶æ³¨å…¥æ¢å¤ç½‘ç»œã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†æ©è†œæŸå¤±ï¼ˆMLï¼‰ï¼Œä»¥å°†ç›‘ç£é›†ä¸­åœ¨å¸¦çŠ¶åŒºåŸŸä¸Šï¼Œè€Œä¸ç‰ºç‰²å…¨å±€ä¿çœŸåº¦ã€‚ä¸ºäº†å…‹æœæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåˆæˆé¢‘é—ªå¸¦çŠ¶ç°è±¡çš„ä»¿çœŸæµç¨‹ï¼Œè¯¥æµç¨‹åœ¨äº®åº¦åŸŸä¸­åˆæˆé¢‘é—ªå¸¦çŠ¶ç°è±¡ï¼ŒåŒ…æ‹¬å¸¦çŠ¶è§’åº¦ã€å¸¦çŠ¶é—´è·å’Œå¸¦çŠ¶å®½åº¦çš„éšæœºæŠ–åŠ¨ã€‚è¿˜åº”ç”¨äº†æŸ”å’Œè¾¹ç•Œå’Œä¼ æ„Ÿå™¨å™ªå£°ä»¥æ¨¡æ‹Ÿæ›´çœŸå®çš„æƒ…å†µã€‚ä¸ºäº†è¯„ä¼°ï¼Œæˆ‘ä»¬æ”¶é›†äº†ä¸€å¯¹çœŸå®ä¸–ç•Œçš„é¢‘é—ªå¸¦çŠ¶ç°è±¡æ•°æ®é›†ï¼Œé€šè¿‡é•¿æ—¶é—´æ›å…‰æ•æ‰ä¸é¢‘é—ªå¸¦çŠ¶ç°è±¡ç›¸åŒ¹é…çš„åƒç´ æ— é¢‘é—ªå‚è€ƒå›¾åƒã€‚åœ¨æˆ‘ä»¬çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼Œæ— è®ºæ˜¯å®šé‡æŒ‡æ ‡è¿˜æ˜¯è§†è§‰æ¯”è¾ƒï¼ŒRIFLEåœ¨è½»å¾®åˆ°ä¸¥é‡çš„é¢‘é—ªå¸¦çŠ¶ç°è±¡æƒ…å†µä¸‹å‡ä¼˜äºæœ€è¿‘çš„å›¾åƒé‡å»ºåŸºçº¿ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œå®ƒæ˜¯ç¬¬ä¸€é¡¹ç ”ç©¶é¢‘é—ªå¸¦çŠ¶ç°è±¡çš„æ¨¡æ‹Ÿå’Œå»é™¤çš„å·¥ä½œã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºåç»­ç ”ç©¶åœ¨æ•°æ®é›†æ„å»ºå’Œå»é™¤æ¨¡å‹è®¾è®¡æ–¹é¢å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å°†å¾ˆå¿«å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24644v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡ç ”ç©¶äº†å±å¹•æˆªå›¾ä¸­çš„é—ªçƒæ¡çº¹ï¼ˆFBï¼‰é—®é¢˜ï¼Œæå‡ºä¸€ç§åŸºäºæ‰©æ•£çš„æ¡†æ¶RIFLEï¼Œç”¨äºå»é™¤FBåŒæ—¶ä¿ç•™ç»†èŠ‚ã€‚æ–‡ç« ä»‹ç»äº†é—ªçƒæ¡çº¹çš„å…ˆéªŒä¼°è®¡å™¨FPEå’ŒMasked Lossï¼ˆMLï¼‰ï¼Œä»¥æé«˜å»é™¤æ•ˆæœã€‚ä¸ºå…‹æœæ•°æ®ç¼ºä¹ï¼Œæå‡ºäº†ä¸€ç§åˆæˆFBçš„ä»¿çœŸç®¡é“ã€‚æ­¤å¤–ï¼Œæ–‡ç« å»ºç«‹äº†çœŸå®ä¸–ç•Œçš„FBæ•°æ®é›†å¹¶è¿›è¡Œäº†è¯„ä¼°ã€‚è¯¥ç ”ç©¶ä¸ºå±å¹•æˆªå›¾çš„FBé—®é¢˜å¤„ç†å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>é—ªçƒæ¡çº¹ï¼ˆFBï¼‰æ˜¯ä¸€ç§å¸¸è§çš„å±å¹•æˆªå›¾é—®é¢˜ï¼Œå½±å“å¯è¯»æ€§å’Œæ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>RIFLEæ˜¯é¦–ä¸ªé’ˆå¯¹FBå»é™¤çš„æ‰©æ•£æ¡†æ¶ï¼Œèƒ½æœ‰æ•ˆå»é™¤FBåŒæ—¶ä¿ç•™ç»†èŠ‚ã€‚</li>
<li>FPEï¼ˆé—ªçƒæ¡çº¹å…ˆéªŒä¼°è®¡å™¨ï¼‰é¢„æµ‹å…³é”®æ¡çº¹å±æ€§å¹¶æ³¨å…¥ä¿®å¤ç½‘ç»œä»¥æé«˜æ•ˆæœã€‚</li>
<li>Masked Lossï¼ˆMLï¼‰é›†ä¸­äºæ¡çº¹åŒºåŸŸçš„ç›‘ç£ï¼Œä¸å½±å“å…¨å±€ä¿çœŸåº¦ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åˆæˆFBçš„ä»¿çœŸç®¡é“ï¼Œé€šè¿‡éšæœºæŠ–åŠ¨æ¡çº¹è§’åº¦ã€é—´è·å’Œå®½åº¦æ¥æ¨¡æ‹ŸçœŸå®æƒ…å†µã€‚</li>
<li>å»ºç«‹äº†çœŸå®ä¸–ç•Œçš„FBæ•°æ®é›†å¹¶è¿›è¡Œè¯„ä¼°ï¼ŒRIFLEåœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰æ¯”è¾ƒä¸Šéƒ½è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>ç›®å‰çš„ç ”ç©¶ä¸ºåç»­çš„æ•°æ®é›†æ„å»ºå’Œå»é™¤æ¨¡å‹è®¾è®¡å¥ å®šäº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24644">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-363405db3e963be3b197fe437319f2a8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031519&auth_key=1760031519-0-0-09c8ebcdca0f12cf29713cf41019905b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f4feadd52ad0541ebf2adb38d87a2599~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031526&auth_key=1760031526-0-0-6bf25339d466bb7ba1c2d6b1c1160abc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-023cce094e9742cd33a765d2c38992f7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031532&auth_key=1760031532-0-0-2c656d4b1686f50e18ca8ab6a6466bc0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fd7f3a1c6f450f03c99f66ff9ad90ca9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031539&auth_key=1760031539-0-0-8cf60e0ad21e7d1fb9d7fe570c8cde01&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9003161138fb490e8ec5b1c87007106f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031546&auth_key=1760031546-0-0-511f5371e5c88db7bbad23d9ec2a55e7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="UltraUPConvNet-A-UPerNet-and-ConvNeXt-Based-Multi-Task-Network-for-Ultrasound-Tissue-Segmentation-and-Disease-Prediction"><a href="#UltraUPConvNet-A-UPerNet-and-ConvNeXt-Based-Multi-Task-Network-for-Ultrasound-Tissue-Segmentation-and-Disease-Prediction" class="headerlink" title="UltraUPConvNet: A UPerNet- and ConvNeXt-Based Multi-Task Network for   Ultrasound Tissue Segmentation and Disease Prediction"></a>UltraUPConvNet: A UPerNet- and ConvNeXt-Based Multi-Task Network for   Ultrasound Tissue Segmentation and Disease Prediction</h2><p><strong>Authors:Zhi Chen, Le Zhang</strong></p>
<p>Ultrasound imaging is widely used in clinical practice due to its cost-effectiveness, mobility, and safety. However, current AI research often treats disease prediction and tissue segmentation as two separate tasks and their model requires substantial computational overhead. In such a situation, we introduce UltraUPConvNet, a computationally efficient universal framework designed for both ultrasound image classification and segmentation. Trained on a large-scale dataset containing more than 9,700 annotations across seven different anatomical regions, our model achieves state-of-the-art performance on certain datasets with lower computational overhead. Our model weights and codes are available at <a target="_blank" rel="noopener" href="https://github.com/yyxl123/UltraUPConvNet">https://github.com/yyxl123/UltraUPConvNet</a> </p>
<blockquote>
<p>è¶…å£°æˆåƒå› å…¶æˆæœ¬æ•ˆç›Šã€ç§»åŠ¨æ€§å’Œå®‰å…¨æ€§è€Œåœ¨ä¸´åºŠå®è·µä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„AIç ”ç©¶é€šå¸¸å°†ç–¾ç—…é¢„æµ‹å’Œå›¾åƒåˆ†å‰²è§†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼Œå…¶æ¨¡å‹éœ€è¦å¤§é‡çš„è®¡ç®—å¼€é”€ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬æ¨å‡ºäº†UltraUPConvNetï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºè¶…å£°å›¾åƒåˆ†ç±»å’Œåˆ†å‰²è€Œè®¾è®¡çš„è®¡ç®—æ•ˆç‡é«˜çš„é€šç”¨æ¡†æ¶ã€‚è¯¥æ¨¡å‹ç»è¿‡åŒ…å«ä¸ƒä¸ªä¸åŒè§£å‰–åŒºåŸŸè¶…è¿‡9700ä¸ªæ³¨é‡Šçš„å¤§è§„æ¨¡æ•°æ®é›†çš„è®­ç»ƒï¼Œåœ¨æŸäº›æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶ä¸”é™ä½äº†è®¡ç®—å¼€é”€ã€‚æˆ‘ä»¬çš„æ¨¡å‹æƒé‡å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/yyxl123/UltraUPConvNet%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/yyxl123/UltraUPConvNetæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11108v2">PDF</a> 8 pages</p>
<p><strong>Summary</strong>ï¼šè¶…å£°æˆåƒå› å…¶æˆæœ¬æ•ˆç›Šã€ç§»åŠ¨æ€§å’Œå®‰å…¨æ€§è€Œåœ¨ä¸´åºŠå®è·µä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„äººå·¥æ™ºèƒ½ç ”ç©¶å¾€å¾€å°†ç–¾ç—…é¢„æµ‹å’Œå›¾åƒåˆ†å‰²è§†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†UltraUPConvNetï¼Œè¿™æ˜¯ä¸€ä¸ªè®¡ç®—æ•ˆç‡é«˜ã€å¯ç”¨äºè¶…å£°å›¾åƒåˆ†ç±»å’Œåˆ†å‰²çš„é€šç”¨æ¡†æ¶ã€‚è¯¥æ¨¡å‹åœ¨åŒ…å«è¶…è¿‡9700ä¸ªæ³¨é‡Šçš„å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¦†ç›–äº†ä¸ƒä¸ªä¸åŒçš„è§£å‰–åŒºåŸŸï¼Œä»¥è¾ƒä½çš„è®¡ç®—å¼€é”€åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è¶…å£°æˆåƒåœ¨ä¸´åºŠå®è·µä¸­å¹¿æ³›åº”ç”¨ï¼Œå› å…¶æˆæœ¬æ•ˆç›Šã€ç§»åŠ¨æ€§å’Œå®‰å…¨æ€§ã€‚</li>
<li>å½“å‰äººå·¥æ™ºèƒ½ç ”ç©¶åœ¨å¤„ç†è¶…å£°å›¾åƒæ—¶ï¼Œç–¾ç—…é¢„æµ‹å’Œå›¾åƒåˆ†å‰²è¢«è§†ä¸ºä¸¤ä¸ªç‹¬ç«‹ä»»åŠ¡ã€‚</li>
<li>UltraUPConvNetæ˜¯ä¸€ä¸ªè®¡ç®—æ•ˆç‡é«˜çš„é€šç”¨æ¡†æ¶ï¼Œå¯ç”¨äºè¶…å£°å›¾åƒåˆ†ç±»å’Œåˆ†å‰²ã€‚</li>
<li>UltraUPConvNetæ¨¡å‹åœ¨åŒ…å«è¶…è¿‡9700ä¸ªæ³¨é‡Šçš„å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¦†ç›–ä¸ƒä¸ªä¸åŒè§£å‰–åŒºåŸŸã€‚</li>
<li>è¯¥æ¨¡å‹ä»¥è¾ƒä½çš„è®¡ç®—å¼€é”€åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>UltraUPConvNetæ¨¡å‹çš„æƒé‡å’Œä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šåˆ†äº«ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11108">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6f1f57712c0be5b65e95b50b347317df~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031553&auth_key=1760031553-0-0-b56ffedc35ddd52d4cb467afa27161e0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0284513f4b6d7a8952aef9ce654ca5aa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031560&auth_key=1760031560-0-0-b58de7f8aafdcae5dcb1c38433c0ece2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-28ebdba12edabdb2c0f8a63d20d29222~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031567&auth_key=1760031567-0-0-e2e55dde2687d14ac9c394676dd8d9a7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5f2ff04bf3d4b4472218189dc30460b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031574&auth_key=1760031574-0-0-fc76129e1f20feadd67aa1fe00c4f95c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="Enhancing-Corpus-Callosum-Segmentation-in-Fetal-MRI-via-Pathology-Informed-Domain-Randomization"><a href="#Enhancing-Corpus-Callosum-Segmentation-in-Fetal-MRI-via-Pathology-Informed-Domain-Randomization" class="headerlink" title="Enhancing Corpus Callosum Segmentation in Fetal MRI via   Pathology-Informed Domain Randomization"></a>Enhancing Corpus Callosum Segmentation in Fetal MRI via   Pathology-Informed Domain Randomization</h2><p><strong>Authors:Marina Grifell i Plana, Vladyslav Zalevskyi, LÃ©a Schmidt, Yvan Gomez, Thomas Sanchez, Vincent Dunet, MÃ©riam Koob, Vanessa Siffredi, Meritxell Bach Cuadra</strong></p>
<p>Accurate fetal brain segmentation is crucial for extracting biomarkers and assessing neurodevelopment, especially in conditions such as corpus callosum dysgenesis (CCD), which can induce drastic anatomical changes. However, the rarity of CCD severely limits annotated data, hindering the generalization of deep learning models. To address this, we propose a pathology-informed domain randomization strategy that embeds prior knowledge of CCD manifestations into a synthetic data generation pipeline. By simulating diverse brain alterations from healthy data alone, our approach enables robust segmentation without requiring pathological annotations.   We validate our method on a cohort comprising 248 healthy fetuses, 26 with CCD, and 47 with other brain pathologies, achieving substantial improvements on CCD cases while maintaining performance on both healthy fetuses and those with other pathologies. From the predicted segmentations, we derive clinically relevant biomarkers, such as corpus callosum length (LCC) and volume, and show their utility in distinguishing CCD subtypes. Our pathology-informed augmentation reduces the LCC estimation error from 1.89 mm to 0.80 mm in healthy cases and from 10.9 mm to 0.7 mm in CCD cases. Beyond these quantitative gains, our approach yields segmentations with improved topological consistency relative to available ground truth, enabling more reliable shape-based analyses. Overall, this work demonstrates that incorporating domain-specific anatomical priors into synthetic data pipelines can effectively mitigate data scarcity and enhance analysis of rare but clinically significant malformations. </p>
<blockquote>
<p>ç²¾ç¡®çš„èƒå„¿å¤§è„‘åˆ†å‰²å¯¹äºæå–ç”Ÿç‰©æ ‡è®°ç‰©å’Œè¯„ä¼°ç¥ç»å‘è‚²è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯¸å¦‚èƒ¼èƒä½“å‘è‚²ä¸è‰¯ï¼ˆCCDï¼‰ç­‰æƒ…å†µä¸‹ï¼Œå®ƒå¯èƒ½å¯¼è‡´è§£å‰–ç»“æ„å‘ç”Ÿå‰§çƒˆå˜åŒ–ã€‚ç„¶è€Œï¼ŒCCDçš„ç½•è§æ€§ä¸¥é‡é™åˆ¶äº†æ ‡æ³¨æ•°æ®çš„å¯ç”¨æ€§ï¼Œé˜»ç¢äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ™®åŠã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç—…ç†çŸ¥è¯†çš„é¢†åŸŸéšæœºåŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†æœ‰å…³CCDè¡¨ç°çš„å…ˆéªŒçŸ¥è¯†åµŒå…¥åˆ°åˆæˆæ•°æ®ç”Ÿæˆæµç¨‹ä¸­ã€‚é€šè¿‡ä»…ä»å¥åº·æ•°æ®ä¸­æ¨¡æ‹Ÿå„ç§å¤§è„‘å˜åŒ–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨æ— éœ€ç—…ç†æ³¨é‡Šçš„æƒ…å†µä¸‹å®ç°ç¨³å¥çš„åˆ†å‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.20475v2">PDF</a> Presented at the PIPPI Workshop of MICCAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç—…ç†çŸ¥è¯†çš„é¢†åŸŸéšæœºåŒ–ç­–ç•¥ï¼Œç”¨äºèƒå„¿è„‘éƒ¨åˆ†å‰²ã€‚è¯¥æ–¹æ³•å°†å…³äºè„‘è£‚å‘è‚²ä¸å…¨ï¼ˆCCDï¼‰çš„å…ˆéªŒçŸ¥è¯†åµŒå…¥åˆæˆæ•°æ®ç”Ÿæˆæµç¨‹ä¸­ï¼Œé€šè¿‡æ¨¡æ‹Ÿå„ç§è„‘éƒ¨å˜åŒ–è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è¿™ç§åŸºäºåˆæˆæ•°æ®çš„æ–¹æ³•èƒ½åœ¨æ— ç‰¹å®šç–¾ç—…æ ‡è®°æ•°æ®é›†çš„æƒ…å†µä¸‹å®ç°å¯¹CCDç­‰è„‘éƒ¨å¼‚å¸¸ç»“æ„çš„é²æ£’æ€§åˆ†å‰²ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¥åº·èƒå„¿ã€è„‘è£‚å‘è‚²ä¸å…¨å’Œå…¶ä»–è„‘éƒ¨ç–¾ç—…æ‚£è€…ç¾¤ä½“ä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ï¼Œå¹¶èƒ½ä»é¢„æµ‹åˆ†å‰²ä¸­æå–å‡ºé‡è¦çš„ä¸´åºŠæŒ‡æ ‡å¦‚è„‘è£‚é•¿åº¦å’Œä½“ç§¯ã€‚è¿™ä¸€ç ”ç©¶ç­–ç•¥æœ‰æ•ˆå‡è½»äº†ç½•è§ç—…ä¾‹æ•°æ®çš„ç¼ºä¹ï¼Œå¢å¼ºäº†å¤æ‚ç—…ä¾‹çš„è¯„ä¼°èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§ç—…ç†çŸ¥è¯†æŒ‡å¯¼çš„åŸŸéšæœºåŒ–ç­–ç•¥æ¥è§£å†³ç½•è§ç–¾ç—…æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡åˆæˆæ•°æ®æ¨¡æ‹Ÿå¤šç§è„‘éƒ¨å˜åŒ–è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå®ç°å¯¹ç½•è§ç—…ä¾‹çš„é²æ£’æ€§åˆ†å‰²ã€‚</li>
<li>æ–¹æ³•åœ¨å¥åº·èƒå„¿å’Œè„‘è£‚å‘è‚²ä¸å…¨ç­‰è„‘éƒ¨ç–¾ç—…æ‚£è€…ç¾¤ä½“ä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ã€‚</li>
<li>èƒ½å¤Ÿä»é¢„æµ‹åˆ†å‰²ä¸­æå–å‡ºé‡è¦çš„ä¸´åºŠæŒ‡æ ‡å¦‚è„‘è£‚é•¿åº¦å’Œä½“ç§¯ï¼Œä¸ºè¯Šæ–­æä¾›å…³é”®å‚è€ƒã€‚</li>
<li>æé«˜äº†å¯¹ç½•è§ç—…ä¾‹åˆ†æçš„å¯é æ€§ï¼Œå°¤å…¶æ˜¯å½¢çŠ¶åˆ†ææ–¹é¢çš„æ”¹è¿›å°¤ä¸ºæ˜¾è‘—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.20475">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c79b28b8a0d338e3be9547d3f3d1505d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031581&auth_key=1760031581-0-0-7a2160c2b31f04aaaeac0780c33c3b75&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cbb03c21b7280b5cff8295d9206cb518~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031589&auth_key=1760031589-0-0-d277a826aa1a8f07276974bff966c570&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d565c7005d410f979e1cfa97ff1e7016~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031596&auth_key=1760031596-0-0-eaf5688e1606ff3bf55f06065cb226c8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-04/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-04/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-8f538d18a6f863a1206c6eb7c6b08831~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031603&auth_key=1760031603-0-0-1708a109317c20307bbc7c42c7ce6cc2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Emotional Text-To-Speech Based on Mutual-Information-Guided   Emotion-Timbre Disentanglement
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-4fd7c05622c6bb8b0f574ec8ddaec0c9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030463&auth_key=1760030463-0-0-793ca779bce6d66c56c6da9122d0f847&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Optimal Control Meets Flow Matching A Principled Route to Multi-Subject   Fidelity
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32102k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
