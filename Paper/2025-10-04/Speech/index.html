<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  High-Fidelity Speech Enhancement via Discrete Audio Tokens">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-940cfd770f57e29be167a30728e99cc2')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-04-æ›´æ–°"><a href="#2025-10-04-æ›´æ–°" class="headerlink" title="2025-10-04 æ›´æ–°"></a>2025-10-04 æ›´æ–°</h1><h2 id="High-Fidelity-Speech-Enhancement-via-Discrete-Audio-Tokens"><a href="#High-Fidelity-Speech-Enhancement-via-Discrete-Audio-Tokens" class="headerlink" title="High-Fidelity Speech Enhancement via Discrete Audio Tokens"></a>High-Fidelity Speech Enhancement via Discrete Audio Tokens</h2><p><strong>Authors:Luca A. LanzendÃ¶rfer, FrÃ©dÃ©ric Berdoz, Antonis Asonitis, Roger Wattenhofer</strong></p>
<p>Recent autoregressive transformer-based speech enhancement (SE) methods have shown promising results by leveraging advanced semantic understanding and contextual modeling of speech. However, these approaches often rely on complex multi-stage pipelines and low sampling rate codecs, limiting them to narrow and task-specific speech enhancement. In this work, we introduce DAC-SE1, a simplified language model-based SE framework leveraging discrete high-resolution audio representations; DAC-SE1 preserves fine-grained acoustic details while maintaining semantic coherence. Our experiments show that DAC-SE1 surpasses state-of-the-art autoregressive SE methods on both objective perceptual metrics and in a MUSHRA human evaluation. We release our codebase and model checkpoints to support further research in scalable, unified, and high-quality speech enhancement. </p>
<blockquote>
<p>æœ€è¿‘åŸºäºè‡ªå›å½’è½¬æ¢å™¨çš„è¯­éŸ³å¢å¼ºï¼ˆSEï¼‰æ–¹æ³•é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„è¯­ä¹‰ç†è§£å’Œè¯­éŸ³ä¸Šä¸‹æ–‡å»ºæ¨¡ï¼Œå–å¾—äº†ä»¤äººé¼“èˆçš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤æ‚çš„å¤šé˜¶æ®µç®¡é“å’Œä½é‡‡æ ·ç‡ç¼–è§£ç å™¨ï¼Œå°†å®ƒä»¬å±€é™äºç‹­çª„ä¸”ç‰¹å®šçš„è¯­éŸ³å¢å¼ºä»»åŠ¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†DAC-SE1ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºç®€åŒ–è¯­è¨€æ¨¡å‹çš„è¯­éŸ³å¢å¼ºæ¡†æ¶ï¼Œåˆ©ç”¨ç¦»æ•£çš„é«˜åˆ†è¾¨ç‡éŸ³é¢‘è¡¨ç¤ºï¼›DAC-SE1åœ¨ä¿æŒè¯­ä¹‰è¿è´¯æ€§çš„åŒæ—¶ï¼Œä¿ç•™äº†ç²¾ç»†çš„å£°å­¦ç»†èŠ‚ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒDAC-SE1åœ¨å®¢è§‚æ„ŸçŸ¥æŒ‡æ ‡å’ŒMUSHRAäººç±»è¯„ä¼°æ–¹é¢éƒ½è¶…è¶Šäº†æœ€æ–°çš„è‡ªå›å½’SEæ–¹æ³•ã€‚æˆ‘ä»¬å…¬å¼€äº†æˆ‘ä»¬çš„ä»£ç åº“å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œä»¥æ”¯æŒåœ¨å¯æ‰©å±•ã€ç»Ÿä¸€å’Œé«˜è´¨é‡çš„è¯­éŸ³å¢å¼ºæ–¹é¢çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02187v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæœ€æ–°çš„è‡ªå›å½’Transformerè¯­éŸ³å¢å¼ºæ–¹æ³•é€šè¿‡å…ˆè¿›çš„è¯­ä¹‰ç†è§£å’Œè¯­éŸ³ä¸Šä¸‹æ–‡å»ºæ¨¡å±•ç°å‡ºè‰¯å¥½çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¸¸å¸¸ä¾èµ–äºå¤æ‚çš„å¤šé˜¶æ®µæµç¨‹å’Œä½é‡‡æ ·ç‡ç¼–ç ï¼Œé™åˆ¶äº†å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¯­éŸ³å¢å¼ºåº”ç”¨ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºDAC-SE1ï¼Œä¸€ä¸ªåŸºäºç®€åŒ–è¯­è¨€æ¨¡å‹çš„è¯­éŸ³å¢å¼ºæ¡†æ¶ï¼Œåˆ©ç”¨ç¦»æ•£çš„é«˜åˆ†è¾¨ç‡éŸ³é¢‘è¡¨å¾ï¼›DAC-SE1åœ¨ä¿æŒç²¾ç»†å£°å­¦ç»†èŠ‚çš„åŒæ—¶ç»´æŒè¯­ä¹‰è¿è´¯æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDAC-SE1åœ¨å®¢è§‚æ„ŸçŸ¥æŒ‡æ ‡å’ŒMUSHRAäººç±»è¯„ä¼°ä¸­éƒ½è¶…è¶Šäº†æœ€å…ˆè¿›çš„è‡ªå›å½’è¯­éŸ³å¢å¼ºæ–¹æ³•ã€‚æˆ‘ä»¬å‘å¸ƒæˆ‘ä»¬çš„ä»£ç åº“å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ä»¥æ”¯æŒåœ¨å¯æ‰©å±•ã€ç»Ÿä¸€å’Œé«˜è´¨é‡çš„è¯­éŸ³å¢å¼ºæ–¹é¢çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªå›å½’Transformerè¯­éŸ³å¢å¼ºæ–¹æ³•å±•ç°å‡ºè‰¯å¥½ç»“æœï¼Œä½†ä»å­˜åœ¨å¤æ‚æµç¨‹ä¸é‡‡æ ·ç‡é™åˆ¶é—®é¢˜ã€‚</li>
<li>DAC-SE1æ˜¯ä¸€ä¸ªåŸºäºç®€åŒ–è¯­è¨€æ¨¡å‹çš„è¯­éŸ³å¢å¼ºæ¡†æ¶ã€‚</li>
<li>DAC-SE1åˆ©ç”¨ç¦»æ•£çš„é«˜åˆ†è¾¨ç‡éŸ³é¢‘è¡¨å¾ä»¥ä¿ç•™ç²¾ç»†å£°å­¦ç»†èŠ‚ã€‚</li>
<li>DAC-SE1èƒ½åœ¨ä¿æŒè¯­ä¹‰è¿è´¯æ€§çš„åŒæ—¶å¢å¼ºè¯­éŸ³è´¨é‡ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºDAC-SE1åœ¨å®¢è§‚æ„ŸçŸ¥æŒ‡æ ‡å’Œäººæœºè¯„ä¼°ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶äººå‘˜å…¬å¼€äº†ä»£ç åº“å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ä»¥æ”¯æŒåç»­ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02187">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0fa34176099d79ea2213fd81cb468442" align="middle">
<img src="https://picx.zhimg.com/v2-dba2d4355262528de2208c6068f5653b" align="middle">
<img src="https://picx.zhimg.com/v2-2637b9980ecb3fa68894d88971ccb9ae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2abdc1c5d17997c2e40247177e820656.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-073f4bcb1422104e5c43967b4f5a6ae2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Exploring-Resolution-Wise-Shared-Attention-in-Hybrid-Mamba-U-Nets-for-Improved-Cross-Corpus-Speech-Enhancement"><a href="#Exploring-Resolution-Wise-Shared-Attention-in-Hybrid-Mamba-U-Nets-for-Improved-Cross-Corpus-Speech-Enhancement" class="headerlink" title="Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for   Improved Cross-Corpus Speech Enhancement"></a>Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for   Improved Cross-Corpus Speech Enhancement</h2><p><strong>Authors:Nikolai Lund KÃ¼hne, Jesper Jensen, Jan Ã˜stergaard, Zheng-Hua Tan</strong></p>
<p>Recent advances in speech enhancement have shown that models combining Mamba and attention mechanisms yield superior cross-corpus generalization performance. At the same time, integrating Mamba in a U-Net structure has yielded state-of-the-art enhancement performance, while reducing both model size and computational complexity. Inspired by these insights, we propose RWSA-MambaUNet, a novel and efficient hybrid model combining Mamba and multi-head attention in a U-Net structure for improved cross-corpus performance. Resolution-wise shared attention (RWSA) refers to layerwise attention-sharing across corresponding time- and frequency resolutions. Our best-performing RWSA-MambaUNet model achieves state-of-the-art generalization performance on two out-of-domain test sets. Notably, our smallest model surpasses all baselines on the out-of-domain DNS 2020 test set in terms of PESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in terms of SSNR, ESTOI, and SI-SDR, while using less than half the model parameters and a fraction of the FLOPs. </p>
<blockquote>
<p>è¿‘æœŸè¯­éŸ³å¢å¼ºæŠ€æœ¯çš„è¿›å±•è¡¨æ˜ï¼Œç»“åˆMambaå’Œæ³¨æ„åŠ›æœºåˆ¶çš„æ¨¡å‹è¡¨ç°å‡ºä¼˜å¼‚çš„è·¨è¯­æ–™åº“æ³›åŒ–æ€§èƒ½ã€‚åŒæ—¶ï¼Œå°†Mambaé›†æˆåˆ°U-Netç»“æ„ä¸­ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å¢å¼ºæ€§èƒ½ï¼ŒåŒæ—¶å‡å°äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚å—åˆ°è¿™äº›è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†RWSA-MambaUNetï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆMambaå’ŒU-Netç»“æ„ä¸­çš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„æ–°å‹é«˜æ•ˆæ··åˆæ¨¡å‹ï¼Œæ—¨åœ¨æé«˜è·¨è¯­æ–™åº“æ€§èƒ½ã€‚åˆ†è¾¨ç‡å±‚é¢çš„å…±äº«æ³¨æ„åŠ›ï¼ˆRWSAï¼‰æ˜¯æŒ‡å¯¹åº”æ—¶é—´å’Œé¢‘ç‡åˆ†è¾¨ç‡ä¹‹é—´çš„åˆ†å±‚æ³¨æ„åŠ›å…±äº«ã€‚æˆ‘ä»¬è¡¨ç°æœ€ä½³çš„RWSA-MambaUNetæ¨¡å‹åœ¨ä¸¤ä¸ªåŸŸå¤–æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ³›åŒ–æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬æœ€å°çš„æ¨¡å‹åœ¨DNS 2020æµ‹è¯•é›†ï¼ˆä»¥PESQã€SSNRå’ŒESTOIä¸ºæ ‡å‡†ï¼‰å’ŒEARS-WHAM_v2æµ‹è¯•é›†ï¼ˆä»¥SSNRã€ESTOIå’ŒSI-SDRä¸ºæ ‡å‡†ï¼‰ä¸Šçš„è¡¨ç°è¶…è¿‡äº†æ‰€æœ‰åŸºçº¿æ¨¡å‹ï¼ŒåŒæ—¶ä½¿ç”¨çš„æ¨¡å‹å‚æ•°ä¸åˆ°ä¸€åŠï¼ŒFLOPsä¹Ÿå¤§å¤§å‡å°‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01958v1">PDF</a> Submitted to IEEE for possible publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆMambaå’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„U-Netç»“æ„æ¨¡å‹RWSA-MambaUNetï¼Œæ—¨åœ¨æé«˜è·¨è¯­æ–™åº“æ€§èƒ½ã€‚è¯¥æ¨¡å‹é‡‡ç”¨åˆ†è¾¨ç‡å…±äº«æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶åœ¨ä¸¤ä¸ªè·¨åŸŸæµ‹è¯•é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ³›åŒ–æ€§èƒ½ã€‚å…¶ä¸­ï¼Œæœ€å°æ¨¡å‹åœ¨DNS 2020æµ‹è¯•é›†ä¸Šçš„PESQã€SSNRå’ŒESTOIæŒ‡æ ‡ä¸Šè¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼ŒåŒæ—¶åœ¨EARS-WHAM_v2æµ‹è¯•é›†ä¸Šçš„SSNRã€ESTOIå’ŒSI-SDRæŒ‡æ ‡ä¸Šä¹Ÿæœ‰æ˜¾è‘—è¡¨ç°ï¼ŒåŒæ—¶æ¨¡å‹å‚æ•°å’Œè®¡ç®—å¤æ‚åº¦å‡å¤§å¹…é™ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç»“åˆMambaå’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„æ¨¡å‹RWSA-MambaUNetèƒ½å¤Ÿæé«˜è·¨è¯­æ–™åº“æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹ç»“åˆäº†U-Netç»“æ„ï¼Œè¾¾åˆ°å½“å‰æœ€ä½³çš„å¢å¼ºæ€§èƒ½ã€‚</li>
<li>é€šè¿‡åœ¨U-Netç»“æ„ä¸­é›†æˆMambaï¼Œå‡å°‘äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚æ€§ã€‚</li>
<li>RWSA-MambaUNetæ¨¡å‹é‡‡ç”¨åˆ†è¾¨ç‡å…±äº«æ³¨æ„åŠ›æœºåˆ¶ï¼ˆRWSAï¼‰ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨ä¸¤ä¸ªè·¨åŸŸæµ‹è¯•é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>æœ€å°çš„RWSA-MambaUNetæ¨¡å‹åœ¨DNS 2020å’ŒEARS-WHAM_v2æµ‹è¯•é›†ä¸Šçš„å¤šé¡¹æŒ‡æ ‡ä¸Šè¶…è¶ŠåŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01958">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1032d02e82d06b7c5bf9afac1112341f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abe6f9785836aca26bcc44c2ee258046" align="middle">
<img src="https://picx.zhimg.com/v2-95709d65d2e90017b1fb6719a46b2ead" align="middle">
<img src="https://picx.zhimg.com/v2-168752e8598f833b256c21949042cb46" align="middle">
<img src="https://picx.zhimg.com/v2-e4d33b7af23b83795b8e9d766ea93da4" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Emotional-Text-To-Speech-Based-on-Mutual-Information-Guided-Emotion-Timbre-Disentanglement"><a href="#Emotional-Text-To-Speech-Based-on-Mutual-Information-Guided-Emotion-Timbre-Disentanglement" class="headerlink" title="Emotional Text-To-Speech Based on Mutual-Information-Guided   Emotion-Timbre Disentanglement"></a>Emotional Text-To-Speech Based on Mutual-Information-Guided   Emotion-Timbre Disentanglement</h2><p><strong>Authors:Jianing Yang, Sheng Li, Takahiro Shinozaki, Yuki Saito, Hiroshi Saruwatari</strong></p>
<p>Current emotional Text-To-Speech (TTS) and style transfer methods rely on reference encoders to control global style or emotion vectors, but do not capture nuanced acoustic details of the reference speech. To this end, we propose a novel emotional TTS method that enables fine-grained phoneme-level emotion embedding prediction while disentangling intrinsic attributes of the reference speech. The proposed method employs a style disentanglement method to guide two feature extractors, reducing mutual information between timbre and emotion features, and effectively separating distinct style components from the reference speech. Experimental results demonstrate that our method outperforms baseline TTS systems in generating natural and emotionally rich speech. This work highlights the potential of disentangled and fine-grained representations in advancing the quality and flexibility of emotional TTS systems. </p>
<blockquote>
<p>å½“å‰çš„æƒ…æ„Ÿæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰å’Œé£æ ¼è½¬æ¢æ–¹æ³•ä¾èµ–äºå‚è€ƒç¼–ç å™¨æ¥æ§åˆ¶å…¨å±€é£æ ¼æˆ–æƒ…æ„Ÿå‘é‡ï¼Œä½†å®ƒä»¬æ²¡æœ‰æ•æ‰åˆ°å‚è€ƒè¯­éŸ³çš„å¾®å¦™å£°å­¦ç»†èŠ‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æƒ…æ„ŸTTSæ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿå®ç°ç²¾ç»†çš„éŸ³ç´ çº§æƒ…æ„ŸåµŒå…¥é¢„æµ‹ï¼ŒåŒæ—¶è§£å¼€å‚è€ƒè¯­éŸ³çš„å†…åœ¨å±æ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•é‡‡ç”¨é£æ ¼åˆ†ç¦»æ–¹æ³•æ¥æŒ‡å¯¼ä¸¤ä¸ªç‰¹å¾æå–å™¨ï¼Œå‡å°‘éŸ³è´¨å’Œæƒ…æ„Ÿç‰¹å¾ä¹‹é—´çš„ç›¸äº’ä¿¡æ¯ï¼Œæœ‰æ•ˆåˆ†ç¦»å‚è€ƒè¯­éŸ³ä¸­çš„ä¸åŒé£æ ¼æˆåˆ†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆè‡ªç„¶ä¸”æƒ…æ„Ÿä¸°å¯Œçš„è¯­éŸ³æ–¹é¢ä¼˜äºåŸºçº¿TTSç³»ç»Ÿã€‚è¿™é¡¹å·¥ä½œçªå‡ºäº†è§£å¼€å’Œç²¾ç»†ç²’åº¦è¡¨ç¤ºåœ¨æå‡æƒ…æ„ŸTTSç³»ç»Ÿçš„è´¨é‡å’Œçµæ´»æ€§æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01722v1">PDF</a> In Proceedings of the 17th Asia Pacific Signal and Information   Processing Association Annual Summit and Conference (APSIPA ASC 2025)</p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æƒ…æ„Ÿæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ç²¾ç»†çš„è¯­éŸ³çº§åˆ«ä¸Šé¢„æµ‹æƒ…æ„ŸåµŒå…¥ï¼ŒåŒæ—¶è§£è€¦å‚è€ƒè¯­éŸ³çš„å†…åœ¨å±æ€§ã€‚è¯¥æ–¹æ³•é‡‡ç”¨é£æ ¼è§£è€¦æ–¹æ³•æ¥æŒ‡å¯¼ä¸¤ä¸ªç‰¹å¾æå–å™¨ï¼Œå‡å°‘éŸ³è‰²å’Œæƒ…æ„Ÿç‰¹å¾ä¹‹é—´çš„äº’ä¿¡æ¯ï¼Œæœ‰æ•ˆåœ°ä»å‚è€ƒè¯­éŸ³ä¸­åˆ†ç¦»å‡ºä¸åŒçš„é£æ ¼æˆåˆ†ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆè‡ªç„¶ä¸”æƒ…æ„Ÿä¸°å¯Œçš„è¯­éŸ³æ–¹é¢ä¼˜äºåŸºå‡†TTSç³»ç»Ÿã€‚æœ¬æ–‡å¼ºè°ƒäº†ç²¾ç»†åŒ–å’Œè§£è€¦è¡¨ç¤ºåœ¨æå‡æƒ…æ„ŸTTSç³»ç»Ÿè´¨é‡å’Œçµæ´»æ€§æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰æƒ…æ„Ÿæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰å’Œæ–¹æ³•ä¾èµ–äºå‚è€ƒç¼–ç å™¨æ¥æ§åˆ¶å…¨å±€é£æ ¼æˆ–æƒ…æ„Ÿå‘é‡ï¼Œä½†æ— æ³•æ•æ‰å‚è€ƒè¯­éŸ³çš„ç»†å¾®å£°å­¦ç»†èŠ‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„æƒ…æ„ŸTTSæ–¹æ³•ï¼Œèƒ½å¤Ÿå®ç°åœ¨ç²¾ç»†çš„è¯­éŸ³çº§åˆ«ä¸Šçš„æƒ…æ„ŸåµŒå…¥é¢„æµ‹ï¼ŒåŒæ—¶è§£è€¦å‚è€ƒè¯­éŸ³çš„å†…åœ¨å±æ€§ã€‚</li>
<li>é‡‡ç”¨é£æ ¼è§£è€¦æ–¹æ³•æ¥æŒ‡å¯¼ä¸¤ä¸ªç‰¹å¾æå–å™¨ï¼Œå‡å°‘éŸ³è‰²å’Œæƒ…æ„Ÿç‰¹å¾ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚</li>
<li>æ–¹æ³•æœ‰æ•ˆåœ°ä»å‚è€ƒè¯­éŸ³ä¸­åˆ†ç¦»å‡ºä¸åŒçš„é£æ ¼æˆåˆ†ï¼Œæå‡æƒ…æ„ŸTTSç³»ç»Ÿçš„æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆè‡ªç„¶ä¸”æƒ…æ„Ÿä¸°å¯Œçš„è¯­éŸ³æ–¹é¢ä¼˜äºåŸºå‡†TTSç³»ç»Ÿã€‚</li>
<li>æ‰€ææ–¹æ³•å¯¹äºæå‡æƒ…æ„ŸTTSç³»ç»Ÿçš„è´¨é‡å’Œçµæ´»æ€§å…·æœ‰æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01722">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-79a94fcf30c5fc44e48f61dbb75b6412" align="middle">
<img src="https://picx.zhimg.com/v2-cbe538941af78bf499e918b66013d47b" align="middle">
<img src="https://picx.zhimg.com/v2-645239cfc828ce5b33f56180db0b68e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d48f8b332c7c415412628abe66b295b" align="middle">
<img src="https://picx.zhimg.com/v2-8f538d18a6f863a1206c6eb7c6b08831.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Enhancing-Noise-Robustness-of-Parkinsonâ€™s-Disease-Telemonitoring-via-Contrastive-Feature-Augmentation"><a href="#Enhancing-Noise-Robustness-of-Parkinsonâ€™s-Disease-Telemonitoring-via-Contrastive-Feature-Augmentation" class="headerlink" title="Enhancing Noise Robustness of Parkinsonâ€™s Disease Telemonitoring via   Contrastive Feature Augmentation"></a>Enhancing Noise Robustness of Parkinsonâ€™s Disease Telemonitoring via   Contrastive Feature Augmentation</h2><p><strong>Authors:Ziming Tang, Chengbin Hou, Tianyu Zhang, Bangxu Tian, Jinbao Wang, Hairong Lv</strong></p>
<p>Parkinsonâ€™s disease (PD) is one of the most common neurodegenerative disorder. PD telemonitoring emerges as a novel assessment modality enabling self-administered at-home tests of Unified Parkinsonâ€™s Disease Rating Scale (UPDRS) scores, enhancing accessibility for PD patients. However, three types of noise would occur during measurements: (1) patient-induced measurement inaccuracies, (2) environmental noise, and (3) data packet loss during transmission, resulting in higher prediction errors. To address these challenges, NoRo, a noise-robust UPDRS prediction framework is proposed. First, the original speech features are grouped into ordered bins, based on the continuous values of a selected feature, to construct contrastive pairs. Second, the contrastive pairs are employed to train a multilayer perceptron encoder for generating noise-robust features. Finally, these features are concatenated with the original features as the augmented features, which are then fed into the UPDRS prediction models. Notably, we further introduces a novel evaluation approach with customizable noise injection module, and extensive experiments show that NoRo can successfully enhance the noise robustness of UPDRS prediction across various downstream prediction models under different noisy environments. </p>
<blockquote>
<p>å¸•é‡‘æ£®ç—…ï¼ˆPDï¼‰æ˜¯æœ€å¸¸è§çš„ç¥ç»é€€è¡Œæ€§ç–¾ç—…ä¹‹ä¸€ã€‚PDé¥æµ‹ä½œä¸ºä¸€ç§æ–°çš„è¯„ä¼°æ¨¡å¼å‡ºç°ï¼Œä½¿æ‚£è€…åœ¨å®¶é‡Œèƒ½å¤Ÿè‡ªæˆ‘è¿›è¡Œç»Ÿä¸€å¸•é‡‘æ£®ç—…è¯„åˆ†é‡è¡¨ï¼ˆUPDRSï¼‰çš„æµ‹è¯•ï¼Œæé«˜äº†å¸•é‡‘æ£®ç—…æ‚£è€…çš„å¯è®¿é—®æ€§ã€‚ç„¶è€Œï¼Œåœ¨æµ‹é‡è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿä¸‰ç§å™ªå£°ï¼šï¼ˆ1ï¼‰æ‚£è€…å¼•èµ·çš„æµ‹é‡è¯¯å·®ã€ï¼ˆ2ï¼‰ç¯å¢ƒå™ªå£°å’Œï¼ˆ3ï¼‰ä¼ è¾“è¿‡ç¨‹ä¸­çš„æ•°æ®åŒ…ä¸¢å¤±ï¼Œå¯¼è‡´é¢„æµ‹è¯¯å·®å¢å¤§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å™ªå£°é²æ£’çš„UPDRSé¢„æµ‹æ¡†æ¶NoRoã€‚é¦–å…ˆï¼Œæ ¹æ®é€‰å®šç‰¹å¾çš„è¿ç»­å€¼ï¼Œå°†åŸå§‹è¯­éŸ³ç‰¹å¾åˆ†ç»„ä¸ºæœ‰åºbinï¼Œä»¥æ„å»ºå¯¹æ¯”å¯¹ã€‚å…¶æ¬¡ï¼Œåˆ©ç”¨å¯¹æ¯”å¯¹è®­ç»ƒå¤šå±‚æ„ŸçŸ¥å™¨ç¼–ç å™¨ï¼Œä»¥ç”Ÿæˆå™ªå£°é²æ£’ç‰¹å¾ã€‚æœ€åï¼Œå°†è¿™äº›ç‰¹å¾ä¸åŸå§‹ç‰¹å¾ç»„åˆä¸ºå¢å¼ºç‰¹å¾ï¼Œç„¶åè¾“å…¥åˆ°UPDRSé¢„æµ‹æ¨¡å‹ä¸­ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§å…·æœ‰å¯å®šåˆ¶å™ªå£°æ³¨å…¥æ¨¡å—çš„æ–°å‹è¯„ä¼°æ–¹æ³•ï¼Œå¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨å„ç§å™ªå£°ç¯å¢ƒä¸‹ï¼ŒNoRoå¯ä»¥æˆåŠŸæé«˜UPDRSé¢„æµ‹åœ¨ä¸åŒä¸‹æ¸¸é¢„æµ‹æ¨¡å‹ä¸­çš„å™ªå£°é²æ£’æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01588v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¸•é‡‘æ£®ç—…ï¼ˆPDï¼‰æ˜¯ä¸€ç§å¸¸è§çš„ç¥ç»é€€è¡Œæ€§ç–¾ç—…ã€‚è¿œç¨‹ç›‘æµ‹ï¼ˆtelemonitoringï¼‰ä½œä¸ºä¸€ç§æ–°å‹çš„è¯„ä¼°æ–¹å¼ï¼Œè®©æ‚£è€…åœ¨å®¶é‡Œè¿›è¡Œå¸•é‡‘æ£®ç—…ç»Ÿä¸€è¯„åˆ†é‡è¡¨ï¼ˆUPDRSï¼‰çš„è‡ªæˆ‘æµ‹è¯•æˆä¸ºå¯èƒ½ï¼Œä»è€Œæé«˜äº†PDæ‚£è€…çš„è¯„ä¼°ä¾¿åˆ©æ€§ã€‚ç„¶è€Œï¼Œæµ‹é‡è¿‡ç¨‹ä¸­å¯èƒ½ä¼šå‡ºç°ä¸‰ç§ç±»å‹çš„å™ªå£°å¹²æ‰°è¯„ä¼°å‡†ç¡®æ€§ï¼ŒåŒ…æ‹¬æ‚£è€…æ“ä½œè¯¯å·®ã€ç¯å¢ƒå™ªå£°ä»¥åŠæ•°æ®ä¼ è¾“è¿‡ç¨‹ä¸­çš„æ•°æ®åŒ…ä¸¢å¤±ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å™ªå£°é²æ£’çš„UPDRSé¢„æµ‹æ¡†æ¶ï¼ˆNoRoï¼‰ã€‚å®ƒé€šè¿‡ç‰¹å¾åˆ†ç»„å’Œè®­ç»ƒå¤šå±‚æ„ŸçŸ¥æœºç¼–ç å™¨æ¥ç”Ÿæˆé²æ£’æ€§ç‰¹å¾ï¼Œå†é€šè¿‡æ–°å‹è¯„ä¼°æ–¹æ³•åœ¨ä¸åŒå™ªå£°ç¯å¢ƒä¸‹è¿›è¡Œæµ‹è¯•ï¼Œè¯æ˜å…¶å¯ä»¥æœ‰æ•ˆæé«˜ä¸‹æ¸¸é¢„æµ‹æ¨¡å‹çš„é¢„æµ‹ç²¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¸•é‡‘æ£®ç—…è¿œç¨‹ç›‘æµ‹æé«˜äº†æ‚£è€…è‡ªæˆ‘è¯„ä¼°çš„ä¾¿åˆ©æ€§ã€‚</li>
<li>å­˜åœ¨ä¸‰ç§ä¸»è¦çš„å™ªå£°å¹²æ‰°ç±»å‹å½±å“è¯„ä¼°å‡†ç¡®æ€§ï¼šæ‚£è€…æ“ä½œè¯¯å·®ã€ç¯å¢ƒå™ªå£°å’Œæ•°æ®ä¼ è¾“é—®é¢˜ã€‚</li>
<li>NoRoæ¡†æ¶é€šè¿‡ç‰¹å¾åˆ†ç»„å’Œè®­ç»ƒå¤šå±‚æ„ŸçŸ¥æœºæ¥æé«˜é¢„æµ‹ç‰¹å¾çš„é²æ£’æ€§ã€‚</li>
<li>NoRoå¼•å…¥äº†å¯å®šåˆ¶å™ªå£°æ³¨å…¥æ¨¡å—çš„æ–°å‹è¯„ä¼°æ–¹æ³•ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒNoRoåœ¨ä¸åŒå™ªå£°ç¯å¢ƒä¸‹å’Œä¸åŒä¸‹æ¸¸é¢„æµ‹æ¨¡å‹ä¸­éƒ½èƒ½æé«˜é¢„æµ‹ç²¾åº¦ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01588">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-af8ba2a36cec003efbd61dbe68a8bf9a" align="middle">
<img src="https://pic1.zhimg.com/v2-23b4d78e7f57231af0b87f8c77dc74bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e685f8b81a699c3c2c7a96b524b72dd" align="middle">
<img src="https://pic1.zhimg.com/v2-37094ab1b5b29f9526fd6f6bddcda83e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54b2152221bbf44fc10ecceca81b7981.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d74a4d2ce4f0b650860300716bf7c7bf" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Ovi-Twin-Backbone-Cross-Modal-Fusion-for-Audio-Video-Generation"><a href="#Ovi-Twin-Backbone-Cross-Modal-Fusion-for-Audio-Video-Generation" class="headerlink" title="Ovi: Twin Backbone Cross-Modal Fusion for Audio-Video Generation"></a>Ovi: Twin Backbone Cross-Modal Fusion for Audio-Video Generation</h2><p><strong>Authors:Chetwin Low, Weimin Wang, Calder Katyal</strong></p>
<p>Audio-video generation has often relied on complex multi-stage architectures or sequential synthesis of sound and visuals. We introduce Ovi, a unified paradigm for audio-video generation that models the two modalities as a single generative process. By using blockwise cross-modal fusion of twin-DiT modules, Ovi achieves natural synchronization and removes the need for separate pipelines or post hoc alignment. To facilitate fine-grained multimodal fusion modeling, we initialize an audio tower with an architecture identical to that of a strong pretrained video model. Trained from scratch on hundreds of thousands of hours of raw audio, the audio tower learns to generate realistic sound effects, as well as speech that conveys rich speaker identity and emotion. Fusion is obtained by jointly training the identical video and audio towers via blockwise exchange of timing (via scaled-RoPE embeddings) and semantics (through bidirectional cross-attention) on a vast video corpus. Our model enables cinematic storytelling with natural speech and accurate, context-matched sound effects, producing movie-grade video clips. All the demos, code and model weights are published at <a target="_blank" rel="noopener" href="https://aaxwaz.github.io/Ovi">https://aaxwaz.github.io/Ovi</a> </p>
<blockquote>
<p>éŸ³è§†é¢‘ç”Ÿæˆç»å¸¸ä¾èµ–äºå¤æ‚çš„å¤šé˜¶æ®µæ¶æ„æˆ–å£°éŸ³å’Œè§†è§‰çš„è¿ç»­åˆæˆã€‚æˆ‘ä»¬å¼•å…¥äº†Oviï¼Œè¿™æ˜¯ä¸€ä¸ªéŸ³è§†é¢‘ç”Ÿæˆçš„ç»Ÿä¸€èŒƒå¼ï¼Œå®ƒå°†ä¸¤ç§æ¨¡å¼å»ºæ¨¡ä¸ºä¸€ä¸ªå•ä¸€çš„ç”Ÿæˆè¿‡ç¨‹ã€‚é€šè¿‡ä½¿ç”¨åŒDiTæ¨¡å—çš„åˆ†å—è·¨æ¨¡æ€èåˆï¼ŒOviå®ç°äº†è‡ªç„¶åŒæ­¥ï¼Œå¹¶æ¶ˆé™¤äº†å¯¹å•ç‹¬ç®¡é“æˆ–äº‹åå¯¹é½çš„éœ€æ±‚ã€‚ä¸ºäº†ä¿ƒè¿›ç²¾ç»†çš„è·¨æ¨¡æ€èåˆå»ºæ¨¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸å¼ºå¤§çš„é¢„è®­ç»ƒè§†é¢‘æ¨¡å‹ç›¸åŒçš„æ¶æ„åˆå§‹åŒ–éŸ³é¢‘å¡”ã€‚éŸ³é¢‘å¡”åœ¨æ•°ä»¥ä¸‡è®¡çš„åŸå§‹éŸ³é¢‘ä¸Šä»å¤´å¼€å§‹è®­ç»ƒï¼Œå­¦ä¹ ç”Ÿæˆé€¼çœŸçš„éŸ³æ•ˆä»¥åŠä¼ è¾¾ä¸°å¯Œçš„è¯´è¯äººèº«ä»½å’Œæƒ…æ„Ÿçš„è¯­éŸ³ã€‚èåˆæ˜¯é€šè¿‡è”åˆè®­ç»ƒç›¸åŒçš„è§†é¢‘å’ŒéŸ³é¢‘å¡”è·å¾—çš„ï¼Œé€šè¿‡å®šæ—¶ï¼ˆé€šè¿‡ç¼©æ”¾RoPEåµŒå…¥ï¼‰å’Œè¯­ä¹‰ï¼ˆé€šè¿‡åŒå‘äº¤å‰æ³¨æ„åŠ›ï¼‰è¿›è¡Œå—äº¤æ¢ï¼Œåœ¨å¤§é‡çš„è§†é¢‘è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„æ¨¡å‹ä»¥è‡ªç„¶è¯­éŸ³å’Œå‡†ç¡®ã€ç¬¦åˆè¯­å¢ƒçš„éŸ³æ•ˆè¿›è¡Œç”µå½±å™äº‹ï¼Œç”Ÿæˆç”µå½±çº§åˆ«çš„è§†é¢‘ç‰‡æ®µã€‚æ‰€æœ‰æ¼”ç¤ºã€ä»£ç å’Œæ¨¡å‹æƒé‡éƒ½åœ¨<a target="_blank" rel="noopener" href="https://aaxwaz.github.io/Ovi%E5%8F%91%E5%B8%83%E3%80%82">https://aaxwaz.github.io/Oviå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01284v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºOviçš„éŸ³é¢‘è§†é¢‘ç”Ÿæˆç»Ÿä¸€æ¡†æ¶ï¼Œå®ƒå°†éŸ³é¢‘å’Œè§†é¢‘ä½œä¸ºå•ä¸€ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡å—çº§è·¨æ¨¡æ€èåˆçš„åŒæ¨¡æ€æ¨¡å—ï¼ŒOviå®ç°äº†è‡ªç„¶åŒæ­¥ï¼Œæ— éœ€å•ç‹¬ç®¡é“æˆ–åæœŸå¯¹é½ã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡è§†é¢‘è¯­æ–™åº“ä¸Šè”åˆè®­ç»ƒç›¸åŒçš„è§†é¢‘å’ŒéŸ³é¢‘å¡”ï¼Œè¿›è¡Œæ—¶é—´å’Œè¯­ä¹‰çš„å—çº§äº¤æ¢ï¼Œå®ç°äº†ç²¾ç»†çš„å¤šæ¨¡æ€èåˆå»ºæ¨¡ã€‚Ovièƒ½ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è¯­éŸ³å’Œå‡†ç¡®çš„ä¸Šä¸‹æ–‡åŒ¹é…éŸ³æ•ˆï¼Œè¾¾åˆ°ç”µå½±çº§åˆ«çš„è§†é¢‘å‰ªè¾‘æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Oviæ˜¯ä¸€ä¸ªéŸ³é¢‘è§†é¢‘ç”Ÿæˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œå°†éŸ³é¢‘å’Œè§†é¢‘è§†ä¸ºå•ä¸€ç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡å—çº§è·¨æ¨¡æ€èåˆå®ç°è‡ªç„¶åŒæ­¥ã€‚</li>
<li>æ— éœ€å•ç‹¬çš„å¤„ç†ç®¡é“æˆ–åæœŸå¯¹é½ã€‚</li>
<li>é‡‡ç”¨å¤§è§„æ¨¡è§†é¢‘è¯­æ–™åº“è¿›è¡Œè”åˆè®­ç»ƒï¼Œå®ç°æ—¶é—´å’Œè¯­ä¹‰çš„å—çº§äº¤æ¢ã€‚</li>
<li>ç²¾ç»†çš„å¤šæ¨¡æ€èåˆå»ºæ¨¡ï¼Œé€šè¿‡éŸ³é¢‘å¡”ç”Ÿæˆé€¼çœŸçš„å£°éŸ³æ•ˆæœå’Œå¯Œæœ‰è¡¨ç°åŠ›çš„è¯­éŸ³ã€‚</li>
<li>æ¨¡å‹èƒ½äº§ç”Ÿå‡†ç¡®ã€ä¸Šä¸‹æ–‡åŒ¹é…çš„éŸ³æ•ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01284">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5aaeb8e9011c33e87e76e656fad6c28a" align="middle">
<img src="https://picx.zhimg.com/v2-95a28a1f521f7dd8636ea100dcb10ef2" align="middle">
<img src="https://picx.zhimg.com/v2-ac89d3c3c137ec9fe85006e6ae028b4b" align="middle">
<img src="https://picx.zhimg.com/v2-aed20c0e120d0a20ac3d72250e9e6d67" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="An-Analysis-of-the-New-EU-AI-Act-and-A-Proposed-Standardization-Framework-for-Machine-Learning-Fairness"><a href="#An-Analysis-of-the-New-EU-AI-Act-and-A-Proposed-Standardization-Framework-for-Machine-Learning-Fairness" class="headerlink" title="An Analysis of the New EU AI Act and A Proposed Standardization   Framework for Machine Learning Fairness"></a>An Analysis of the New EU AI Act and A Proposed Standardization   Framework for Machine Learning Fairness</h2><p><strong>Authors:Mike Teodorescu, Yongxu Sun, Haren N. Bhatia, Christos Makridis</strong></p>
<p>The European Unionâ€™s AI Act represents a crucial step towards regulating ethical and responsible AI systems. However, we find an absence of quantifiable fairness metrics and the ambiguity in terminology, particularly the interchangeable use of the keywords transparency, explainability, and interpretability in the new EU AI Act and no reference of transparency of ethical compliance. We argue that this ambiguity creates substantial liability risk that would deter investment. Fairness transparency is strategically important. We recommend a more tailored regulatory framework to enhance the new EU AI regulation. Further-more, we propose a public system framework to assess the fairness and transparency of AI systems. Drawing from past work, we advocate for the standardization of industry best practices as a necessary addition to broad regulations to achieve the level of details required in industry, while preventing stifling innovation and investment in the AI sector. The proposals are exemplified with the case of ASR and speech synthesizers. </p>
<blockquote>
<p>æ¬§ç›Ÿçš„ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹æ˜¯æœç€è§„èŒƒé“å¾·å’Œè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°å­˜åœ¨ç¼ºä¹å¯é‡åŒ–çš„å…¬å¹³æŒ‡æ ‡å’Œæœ¯è¯­æ¨¡ç³Šçš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–°çš„æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹ä¸­é€æ˜ã€å¯è§£é‡Šæ€§å’Œå¯è§£è¯»æ€§ç­‰å…³é”®è¯çš„äº’æ¢ä½¿ç”¨ï¼Œæ²¡æœ‰æåŠé“å¾·åˆè§„çš„é€æ˜åº¦ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ç§æ¨¡ç³Šæ€§ä¼šäº§ç”Ÿå·¨å¤§çš„è´£ä»»é£é™©ï¼Œä»è€Œé˜»ç¢æŠ•èµ„ã€‚å…¬å¹³é€æ˜å…·æœ‰æˆ˜ç•¥é‡è¦æ€§ã€‚æˆ‘ä»¬å»ºè®®åˆ¶å®šæ›´å…·ä½“çš„ç›‘ç®¡æ¡†æ¶ï¼Œä»¥åŠ å¼ºæ¬§ç›Ÿæ–°çš„AIæ³•è§„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå…¬å…±ç³»ç»Ÿæ¡†æ¶æ¥è¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œé€æ˜åº¦ã€‚å€Ÿé‰´è¿‡å»çš„å·¥ä½œï¼Œæˆ‘ä»¬ä¸»å¼ æ ‡å‡†åŒ–è¡Œä¸šçš„æœ€ä½³å®è·µä½œä¸ºå¹¿æ³›æ³•è§„çš„å¿…è¦è¡¥å……ï¼Œä»¥è¾¾åˆ°è¡Œä¸šæ‰€éœ€çš„ç»†èŠ‚æ°´å¹³ï¼ŒåŒæ—¶é˜²æ­¢é˜»ç¢äººå·¥æ™ºèƒ½é¢†åŸŸçš„åˆ›æ–°å’ŒæŠ•èµ„ã€‚ä»¥è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆå™¨ä¸ºä¾‹ï¼Œå¯¹ææ¡ˆè¿›è¡Œäº†è¯´æ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01281v1">PDF</a> 6 pages; IEEE HPEC 2025 Poster Session 4-P1 (12:15-13:15):   AI&#x2F;ML&#x2F;GenAI Poster Session Thursday September 18 2025</p>
<p><strong>Summary</strong></p>
<p>æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆæ˜¯æœç€è§„èŒƒä¼¦ç†å’Œè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚ç„¶è€Œï¼Œè¯¥æ³•æ¡ˆç¼ºä¹å¯é‡åŒ–çš„å…¬å¹³æ€§æŒ‡æ ‡ï¼Œæœ¯è¯­ä½¿ç”¨æ¨¡ç³Šï¼Œå°¤å…¶æ˜¯å¯¹é€æ˜åº¦ã€å¯è§£é‡Šæ€§å’Œå¯è§£è¯»æ€§ç­‰å…³é”®è¯çš„ç›¸äº’æ›¿æ¢ä½¿ç”¨ï¼Œä¸”æ²¡æœ‰æåŠé“å¾·åˆè§„çš„é€æ˜åº¦ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ç§æ¨¡ç³Šæ€§é€ æˆäº†å·¨å¤§çš„æ½œåœ¨è´£ä»»é£é™©ï¼Œå¯èƒ½ä¼šé˜»ç¢æŠ•èµ„ã€‚å…¬å¹³é€æ˜å…·æœ‰æˆ˜ç•¥æ„ä¹‰ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨æ›´å…·ä½“çš„ç›‘ç®¡æ¡†æ¶æ¥å®Œå–„æ¬§ç›Ÿæ–°çš„äººå·¥æ™ºèƒ½æ³•è§„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æè®®å»ºç«‹ä¸€ä¸ªå…¬å…±ç³»ç»Ÿæ¡†æ¶æ¥è¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œé€æ˜åº¦ã€‚ç»“åˆè¿‡å»çš„å·¥ä½œï¼Œæˆ‘ä»¬ä¸»å¼ æ ‡å‡†åŒ–è¡Œä¸šæœ€ä½³å®è·µä½œä¸ºå¯¹å¹¿æ³›æ³•è§„çš„å¿…è¦è¡¥å……ï¼Œä»¥è¾¾åˆ°è¡Œä¸šæ‰€éœ€çš„ç»†èŠ‚æ°´å¹³ï¼ŒåŒæ—¶é˜²æ­¢éåˆ¶äººå·¥æ™ºèƒ½é¢†åŸŸçš„åˆ›æ–°å’ŒæŠ•èµ„ã€‚ä»¥è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆå™¨ä¸ºä¾‹è¯´æ˜äº†è¿™äº›æè®®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆåœ¨è§„èŒƒäººå·¥æ™ºèƒ½ç³»ç»Ÿæ–¹é¢è¿ˆå‡ºé‡è¦ä¸€æ­¥ï¼Œä½†ç¼ºä¹å…¬å¹³æ€§æŒ‡æ ‡å’Œé“å¾·åˆè§„çš„é€æ˜åº¦ã€‚</li>
<li>é€æ˜åº¦ã€å¯è§£é‡Šæ€§å’Œå¯è§£è¯»æ€§ç­‰å…³é”®è¯åœ¨æ³•æ¡ˆä¸­çš„ä½¿ç”¨å­˜åœ¨æ¨¡ç³Šå’Œäº’æ¢ç°è±¡ã€‚</li>
<li>æ¨¡ç³Šæ€§å¯èƒ½å¯¼è‡´é‡å¤§è´£ä»»é£é™©ï¼Œå¯èƒ½é˜»ç¢æŠ•èµ„ã€‚</li>
<li>å…¬å¹³é€æ˜å…·æœ‰æˆ˜ç•¥æ„ä¹‰ã€‚</li>
<li>å»ºè®®ä½¿ç”¨æ›´å…·ä½“çš„ç›‘ç®¡æ¡†æ¶æ¥æ”¹å–„æ¬§ç›Ÿçš„äººå·¥æ™ºèƒ½æ³•è§„ã€‚</li>
<li>æè®®å»ºç«‹å…¬å…±ç³»ç»Ÿæ¡†æ¶æ¥è¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œé€æ˜åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01281">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b33c9c825fcca09209a67afa098106c4" align="middle">
<img src="https://picx.zhimg.com/v2-e7c8ec7ee90aba879908f98724834bc8" align="middle">
<img src="https://picx.zhimg.com/v2-dde4eb826dd2abc9ff5f9a5b6c8bf829" align="middle">
<img src="https://picx.zhimg.com/v2-0e91141458e05960bc2790b93b6c098b" align="middle">
<img src="https://picx.zhimg.com/v2-3f4a9b6a7387051ab165f911142a3db7" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="NLDSI-BWE-Non-Linear-Dynamical-Systems-Inspired-Multi-Resolution-Discriminators-for-Speech-Bandwidth-Extension"><a href="#NLDSI-BWE-Non-Linear-Dynamical-Systems-Inspired-Multi-Resolution-Discriminators-for-Speech-Bandwidth-Extension" class="headerlink" title="NLDSI-BWE: Non Linear Dynamical Systems-Inspired Multi Resolution   Discriminators for Speech Bandwidth Extension"></a>NLDSI-BWE: Non Linear Dynamical Systems-Inspired Multi Resolution   Discriminators for Speech Bandwidth Extension</h2><p><strong>Authors:Tarikul Islam Tamiti, Anomadarshi Barua</strong></p>
<p>In this paper, we design two nonlinear dynamical systems-inspired discriminators â€“ the Multi-Scale Recurrence Discriminator (MSRD) and the Multi-Resolution Lyapunov Discriminator (MRLD) â€“ to \textit{explicitly} model the inherent deterministic chaos of speech. MSRD is designed based on Recurrence representations to capture self-similarity dynamics. MRLD is designed based on Lyapunov exponents to capture nonlinear fluctuations and sensitivity to initial conditions. Through extensive design optimization and the use of depthwise-separable convolutions in the discriminators, our framework surpasses prior AP-BWE model with a 44x reduction in the discriminator parameter count \textbf{($\sim$ 22M vs $\sim$ 0.48M)}. To the best of our knowledge, for the first time, this paper demonstrates how BWE can be supervised by the subtle non-linear chaotic physics of voiced sound production to achieve a significant reduction in the discriminator size. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸¤ä¸ªå—éçº¿æ€§åŠ¨åŠ›ç³»ç»Ÿå¯å‘çš„åˆ¤åˆ«å™¨â€”â€”å¤šå°ºåº¦å¤å‘åˆ¤åˆ«å™¨ï¼ˆMSRDï¼‰å’Œå¤šåˆ†è¾¨ç‡æé›…æ™®è¯ºå¤«åˆ¤åˆ«å™¨ï¼ˆMRLDï¼‰ï¼Œä»¥æ˜ç¡®åœ°æ¨¡æ‹Ÿè¯­éŸ³çš„å›ºæœ‰ç¡®å®šæ€§æ··æ²Œã€‚MSRDåŸºäºå¤å‘è¡¨ç¤ºè®¾è®¡ï¼Œç”¨äºæ•æ‰è‡ªç›¸ä¼¼åŠ¨æ€ã€‚MRLDåˆ™æ˜¯åŸºäºæé›…æ™®è¯ºå¤«æŒ‡æ•°è®¾è®¡ï¼Œç”¨äºæ•æ‰éçº¿æ€§æ³¢åŠ¨å’Œåˆå§‹æ¡ä»¶çš„æ•æ„Ÿæ€§ã€‚é€šè¿‡å¹¿æ³›çš„è®¾è®¡ä¼˜åŒ–å’Œåˆ¤åˆ«å™¨ä¸­æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬çš„æ¡†æ¶è¶…è¶Šäº†å…ˆå‰çš„AP-BWEæ¨¡å‹ï¼Œåˆ¤åˆ«å™¨å‚æ•°è®¡æ•°å‡å°‘äº†44å€ï¼ˆçº¦22M vsçº¦0.48Mï¼‰ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæœ¬è®ºæ–‡é¦–æ¬¡å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æœ‰å£°éŸ³é¢‘äº§ç”Ÿçš„å¾®å¦™éçº¿æ€§æ··æ²Œç‰©ç†æ¥ç›‘ç£BWEï¼Œä»è€Œå®ç°åˆ¤åˆ«å™¨å¤§å°çš„æ˜¾è‘—å‡å°‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01109v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬è®¾è®¡ä¸¤ç§éçº¿æ€§åŠ¨æ€ç³»ç»Ÿå¯å‘é‰´åˆ«å™¨â€”â€”å¤šå°ºåº¦é€’å½’é‰´åˆ«å™¨ï¼ˆMSRDï¼‰å’Œå¤šåˆ†è¾¨ç‡æé›…æ™®è¯ºå¤«é‰´åˆ«å™¨ï¼ˆMRLDï¼‰ï¼Œä»¥æ˜¾å¼å»ºæ¨¡è¯­éŸ³çš„å›ºæœ‰ç¡®å®šæ€§æ··æ²Œã€‚MSRDåŸºäºé€’å½’è¡¨ç¤ºè®¾è®¡ï¼Œç”¨äºæ•æ‰è‡ªç›¸ä¼¼æ€§åŠ¨åŠ›å­¦ã€‚MRLDåŸºäºæé›…æ™®è¯ºå¤«æŒ‡æ•°è®¾è®¡ï¼Œç”¨äºæ•æ‰éçº¿æ€§æ³¢åŠ¨å’Œåˆå§‹æ¡ä»¶çš„æ•æ„Ÿæ€§ã€‚é€šè¿‡è®¾è®¡ä¼˜åŒ–å’Œé‰´åˆ«å™¨ä¸­æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å‚æ•°è®¡æ•°æ–¹é¢è¶…è¿‡äº†å…ˆå‰çš„AP-BWEæ¨¡å‹ï¼Œå®ç°äº†44å€çš„å‚æ•°å‡å°‘ï¼ˆçº¦22M vsçº¦0.48Mï¼‰ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæœ¬æ–‡é¦–æ¬¡å±•ç¤ºäº†å¦‚ä½•é€šè¿‡åˆ©ç”¨æœ‰å£°å£°éŸ³äº§ç”Ÿçš„å¾®å¦™éçº¿æ€§æ··æ²Œç‰©ç†æ¥ç›‘ç£BWEï¼Œä»è€Œå®ç°é‰´åˆ«å™¨å¤§å°çš„æ˜¾è‘—å‡å°‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬ä¸­æå‡ºäº†ä¸¤ç§éçº¿æ€§åŠ¨æ€ç³»ç»Ÿå¯å‘é‰´åˆ«å™¨ï¼šå¤šå°ºåº¦é€’å½’é‰´åˆ«å™¨ï¼ˆMSRDï¼‰å’Œå¤šåˆ†è¾¨ç‡æé›…æ™®è¯ºå¤«é‰´åˆ«å™¨ï¼ˆMRLDï¼‰ã€‚</li>
<li>å®ƒä»¬è¢«è®¾è®¡ç”¨äºæ˜¾å¼å»ºæ¨¡è¯­éŸ³çš„å›ºæœ‰ç¡®å®šæ€§æ··æ²Œã€‚</li>
<li>MSRDåŸºäºé€’å½’è¡¨ç¤ºæ•æ‰è‡ªç›¸ä¼¼æ€§åŠ¨åŠ›å­¦ã€‚</li>
<li>MRLDåŸºäºæé›…æ™®è¯ºå¤«æŒ‡æ•°æ•æ‰éçº¿æ€§æ³¢åŠ¨å’Œåˆå§‹æ¡ä»¶çš„æ•æ„Ÿæ€§ã€‚</li>
<li>é€šè¿‡è®¾è®¡ä¼˜åŒ–å’Œæ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„ä½¿ç”¨ï¼Œå®ç°äº†é‰´åˆ«å™¨çš„å‚æ•°æ˜¾è‘—å‡å°‘ã€‚</li>
<li>ä¸å…ˆå‰çš„AP-BWEæ¨¡å‹ç›¸æ¯”ï¼Œæ–°çš„æ¡†æ¶åœ¨å‚æ•°è®¡æ•°ä¸Šå®ç°äº†æ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01109">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-99ff6e75dd39ad3f94392044dc3623f3" align="middle">
<img src="https://picx.zhimg.com/v2-f452f3fa8b6cfdc205fee229e4f0b98b" align="middle">
<img src="https://picx.zhimg.com/v2-78e7102d1b7bd7afb97a8bf9753fd80e" align="middle">
<img src="https://picx.zhimg.com/v2-bc122e3fd559ee911890fa7eb67f8a02" align="middle">
<img src="https://picx.zhimg.com/v2-f9e505d76179c2f3ff0fd56aa550d65f" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="UniverSR-Unified-and-Versatile-Audio-Super-Resolution-via-Vocoder-Free-Flow-Matching"><a href="#UniverSR-Unified-and-Versatile-Audio-Super-Resolution-via-Vocoder-Free-Flow-Matching" class="headerlink" title="UniverSR: Unified and Versatile Audio Super-Resolution via Vocoder-Free   Flow Matching"></a>UniverSR: Unified and Versatile Audio Super-Resolution via Vocoder-Free   Flow Matching</h2><p><strong>Authors:Woongjib Choi, Sangmin Lee, Hyungseob Lim, Hong-Goo Kang</strong></p>
<p>In this paper, we present a vocoder-free framework for audio super-resolution that employs a flow matching generative model to capture the conditional distribution of complex-valued spectral coefficients. Unlike conventional two-stage diffusion-based approaches that predict a mel-spectrogram and then rely on a pre-trained neural vocoder to synthesize waveforms, our method directly reconstructs waveforms via the inverse Short-Time Fourier Transform (iSTFT), thereby eliminating the dependence on a separate vocoder. This design not only simplifies end-to-end optimization but also overcomes a critical bottleneck of two-stage pipelines, where the final audio quality is fundamentally constrained by vocoder performance. Experiments show that our model consistently produces high-fidelity 48 kHz audio across diverse upsampling factors, achieving state-of-the-art performance on both speech and general audio datasets. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€vocoderçš„éŸ³é¢‘è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œå®ƒé‡‡ç”¨æµåŒ¹é…ç”Ÿæˆæ¨¡å‹æ¥æ•æ‰å¤æ•°è°±ç³»æ•°çš„æ¡ä»¶åˆ†å¸ƒã€‚ä¸åŒäºä¼ ç»Ÿçš„ä¸¤é˜¶æ®µæ‰©æ•£æ–¹æ³•ï¼Œå®ƒéœ€è¦é¢„æµ‹æ¢…å°”é¢‘è°±å›¾ç„¶åä¾èµ–äºé¢„è®­ç»ƒçš„ç¥ç»vocoderæ¥åˆæˆæ³¢å½¢ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›´æ¥é€šè¿‡é€†çŸ­æ—¶å‚…é‡Œå¶å˜æ¢ï¼ˆiSTFTï¼‰é‡å»ºæ³¢å½¢ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹å•ç‹¬vocoderçš„ä¾èµ–ã€‚è¿™ç§è®¾è®¡ä¸ä»…ç®€åŒ–äº†ç«¯åˆ°ç«¯çš„ä¼˜åŒ–ï¼Œè¿˜å…‹æœäº†ä¸¤é˜¶æ®µæµç¨‹çš„å…³é”®ç“¶é¢ˆï¼Œå…¶ä¸­æœ€ç»ˆéŸ³é¢‘è´¨é‡ä»æ ¹æœ¬ä¸Šå—åˆ°vocoderæ€§èƒ½çš„é™åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¤šç§ä¸Šé‡‡æ ·å› å­ä¸‹å§‹ç»ˆäº§ç”Ÿé«˜ä¿çœŸåº¦çš„48kHzéŸ³é¢‘ï¼Œåœ¨è¯­éŸ³å’Œé€šç”¨éŸ³é¢‘æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00771v1">PDF</a> Submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— vocoderçš„éŸ³é¢‘è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œé‡‡ç”¨æµåŒ¹é…ç”Ÿæˆæ¨¡å‹æ•æ‰å¤æ•°è°±ç³»æ•°çš„æ¡ä»¶åˆ†å¸ƒã€‚ä¸åŒäºä¼ ç»Ÿçš„ä¸¤é˜¶æ®µæ‰©æ•£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç›´æ¥é€šè¿‡é€†çŸ­æ—¶å‚…é‡Œå¶å˜æ¢ï¼ˆiSTFTï¼‰é‡å»ºæ³¢å½¢ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹å•ç‹¬vocoderçš„ä¾èµ–ã€‚è¿™ç§è®¾è®¡ä¸ä»…ç®€åŒ–äº†ç«¯åˆ°ç«¯çš„ä¼˜åŒ–ï¼Œè¿˜å…‹æœäº†ä¸¤é˜¶æ®µç®¡é“çš„å…³é”®ç“¶é¢ˆï¼Œå…¶ä¸­æœ€ç»ˆéŸ³é¢‘è´¨é‡ä»æ ¹æœ¬ä¸Šå—åˆ°vocoderæ€§èƒ½çš„é™åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¯­éŸ³å’Œé€šç”¨éŸ³é¢‘æ•°æ®é›†ä¸Šå‡å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶èƒ½ä¸€è‡´åœ°ç”Ÿæˆé«˜ä¿çœŸ48kHzéŸ³é¢‘ï¼Œé€‚ç”¨äºå¤šç§ä¸Šé‡‡æ ·å› å­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥æ¡†æ¶æ˜¯ä¸€ä¸ªvocoder-freeçš„éŸ³é¢‘è¶…åˆ†è¾¨ç‡æ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨æµåŒ¹é…ç”Ÿæˆæ¨¡å‹æ•æ‰å¤æ•°è°±ç³»æ•°çš„æ¡ä»¶åˆ†å¸ƒã€‚</li>
<li>ç›´æ¥é€šè¿‡iSTFTé‡å»ºæ³¢å½¢ï¼Œæ¶ˆé™¤äº†å¯¹å•ç‹¬vocoderçš„ä¾èµ–ã€‚</li>
<li>ç®€åŒ–äº†ç«¯åˆ°ç«¯çš„ä¼˜åŒ–æµç¨‹ã€‚</li>
<li>å…‹æœäº†ä¸¤é˜¶æ®µç®¡é“ä¸­vocoderæ€§èƒ½çš„ç“¶é¢ˆé™åˆ¶ã€‚</li>
<li>åœ¨è¯­éŸ³å’Œé€šç”¨éŸ³é¢‘æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00771">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-92a0c6130a1b7e54de507bb0f54da6e6" align="middle">
<img src="https://picx.zhimg.com/v2-098b991c8f1edf8cf3b63e91f6a1c994" align="middle">
<img src="https://picx.zhimg.com/v2-940cfd770f57e29be167a30728e99cc2" align="middle">
<img src="https://picx.zhimg.com/v2-f4c102b684899b317637b66bf3c0efe5" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MambAttention-Mamba-with-Multi-Head-Attention-for-Generalizable-Single-Channel-Speech-Enhancement"><a href="#MambAttention-Mamba-with-Multi-Head-Attention-for-Generalizable-Single-Channel-Speech-Enhancement" class="headerlink" title="MambAttention: Mamba with Multi-Head Attention for Generalizable   Single-Channel Speech Enhancement"></a>MambAttention: Mamba with Multi-Head Attention for Generalizable   Single-Channel Speech Enhancement</h2><p><strong>Authors:Nikolai Lund KÃ¼hne, Jesper Jensen, Jan Ã˜stergaard, Zheng-Hua Tan</strong></p>
<p>With the advent of new sequence models like Mamba and xLSTM, several studies have shown that these models match or outperform state-of-the-art models in single-channel speech enhancement, automatic speech recognition, and self-supervised audio representation learning. However, prior research has demonstrated that sequence models like LSTM and Mamba tend to overfit to the training set. To address this issue, previous works have shown that adding self-attention to LSTMs substantially improves generalization performance for single-channel speech enhancement. Nevertheless, neither the concept of hybrid Mamba and time-frequency attention models nor their generalization performance have been explored for speech enhancement. In this paper, we propose a novel hybrid architecture, MambAttention, which combines Mamba and shared time- and frequency-multi-head attention modules for generalizable single-channel speech enhancement. To train our model, we introduce VoiceBank+Demand Extended (VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging noise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our proposed MambAttention model significantly outperforms existing state-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar complexity across all reported metrics on two out-of-domain datasets: DNS 2020 and EARS-WHAM_v2, while matching their performance on the in-domain dataset VB-DemandEx. Ablation studies highlight the role of weight sharing between the time- and frequency-multi-head attention modules for generalization performance. Finally, we explore integrating the shared time- and frequency-multi-head attention modules with LSTM and xLSTM, which yields a notable performance improvement on the out-of-domain datasets. However, our MambAttention model remains superior on both out-of-domain datasets across all reported evaluation metrics. </p>
<blockquote>
<p>éšç€Mambaå’ŒxLSTMç­‰æ–°åºåˆ—æ¨¡å‹çš„å…´èµ·ï¼Œå¤šé¡¹ç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹åœ¨å•é€šé“è¯­éŸ³å¢å¼ºã€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè‡ªæˆ‘ç›‘ç£éŸ³é¢‘è¡¨ç¤ºå­¦ä¹ æ–¹é¢è¾¾åˆ°äº†æˆ–è¶…è¶Šäº†ç°æœ‰æ¨¡å‹çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒåƒLSTMå’ŒMambaè¿™æ ·çš„åºåˆ—æ¨¡å‹å®¹æ˜“å¯¹è®­ç»ƒé›†è¿‡åº¦æ‹Ÿåˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä»¥å‰çš„ç ”ç©¶è¡¨æ˜ï¼Œåœ¨LSTMä¸­æ·»åŠ è‡ªæ³¨æ„åŠ›å¯ä»¥æ˜¾è‘—æé«˜å•é€šé“è¯­éŸ³å¢å¼ºçš„æ³›åŒ–æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…³äºæ··åˆMambaå’Œæ—¶é—´-é¢‘ç‡æ³¨æ„åŠ›æ¨¡å‹çš„æ¦‚å¿µåŠå…¶æ³›åŒ–æ€§èƒ½åœ¨è¯­éŸ³å¢å¼ºæ–¹é¢çš„æ¢ç´¢å°šæœªå‡ºç°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„æ··åˆæ¶æ„MambAttentionï¼Œå®ƒç»“åˆäº†Mambaå’Œå…±äº«çš„æ—¶é—´ä¸é¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºå¯æ³›åŒ–çš„å•é€šé“è¯­éŸ³å¢å¼ºã€‚ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†VoiceBank+Demand Extendedï¼ˆVB-DemandExï¼‰æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä»¥VoiceBank+Demandä¸ºçµæ„Ÿï¼Œä½†å…·æœ‰æ›´å…·æŒ‘æˆ˜æ€§çš„å™ªå£°ç±»å‹å’Œæ›´ä½çš„ä¿¡å™ªæ¯”ã€‚åœ¨VB-DemandExä¸Šè®­ç»ƒçš„MambAttentionæ¨¡å‹åœ¨ä¸¤ä¸ªåŸŸå¤–æ•°æ®é›†DNS 2020å’ŒEARS-WHAM_v2ä¸Šæ‰€æœ‰æŠ¥å‘Šçš„æŒ‡æ ‡ä¸­éƒ½æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰åŸºäºLSTMã€xLSTMã€Mambaå’ŒConformerçš„ç±»ä¼¼å¤æ‚åº¦çš„ç³»ç»Ÿï¼ŒåŒæ—¶åœ¨åŸŸå†…æ•°æ®é›†VB-DemandExä¸Šçš„æ€§èƒ½ä¸ä¹‹ç›¸åŒ¹é…ã€‚æ¶ˆèç ”ç©¶çªå‡ºäº†æ—¶é—´å’Œé¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—æƒé‡å…±äº«åœ¨æ³›åŒ–æ€§èƒ½ä¸­çš„ä½œç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬æ¢ç´¢äº†å°†å…±äº«çš„æ—¶é—´å’Œé¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ä¸LSTMå’ŒxLSTMç›¸ç»“åˆï¼Œè¿™åœ¨åŸŸå¤–æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„MambAttentionæ¨¡å‹åœ¨æ‰€æœ‰çš„è¯„ä¼°æŒ‡æ ‡ä¸Šä»ç„¶åœ¨è¿™ä¸¤ä¸ªåŸŸå¤–æ•°æ®é›†ä¸­è¡¨ç°æœ€ä½³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00966v2">PDF</a> Submitted to IEEE&#x2F;ACM Transactions on Audio, Speech, and Language   Processing for possible publication</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºMambAttentionçš„æ··åˆæ¶æ„ï¼Œç»“åˆäº†Mambaå’Œå…±äº«æ—¶é—´-é¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºé€šç”¨å•é€šé“è¯­éŸ³å¢å¼ºã€‚å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†VB-DemandExï¼Œè®­ç»ƒå‡ºçš„MambAttentionæ¨¡å‹åœ¨DNS 2020å’ŒEARS-WHAM_v2ä¸¤ä¸ªè·¨åŸŸæ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰å…ˆè¿›çš„LSTMã€xLSTMã€Mambaå’ŒConformerç³»ç»Ÿï¼ŒåŒæ—¶åœ¨åŸŸå†…æ•°æ®é›†VB-DemandExä¸Šä¸ä¹‹ç›¸åŒ¹é…ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ç»“åˆMambaå’Œå…±äº«æ—¶é—´-é¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—çš„æ··åˆæ¶æ„MambAttentionï¼Œæ—¨åœ¨æé«˜è¯­éŸ³å¢å¼ºä»»åŠ¡çš„æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>å¼•å…¥æ–°çš„æ•°æ®é›†VB-DemandExï¼ŒåŒ…å«æ›´å…·æŒ‘æˆ˜æ€§çš„å™ªå£°ç±»å‹å’Œè¾ƒä½ä¿¡å™ªæ¯”ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ã€‚</li>
<li>MambAttentionæ¨¡å‹åœ¨è·¨åŸŸæ•°æ®é›†DNS 2020å’ŒEARS-WHAM_v2ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºå…¶ä»–å…ˆè¿›ç³»ç»Ÿã€‚</li>
<li>æ¶ˆèç ”ç©¶å¼ºè°ƒäº†æ—¶é—´-é¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—æƒé‡å…±äº«å¯¹æ³›åŒ–æ€§èƒ½çš„ä½œç”¨ã€‚</li>
<li>å°†å…±äº«æ—¶é—´-é¢‘ç‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ä¸LSTMå’ŒxLSTMç»“åˆï¼Œæé«˜äº†è·¨åŸŸæ•°æ®é›†çš„æ€§èƒ½ã€‚</li>
<li>MambAttentionæ¨¡å‹åœ¨æ‰€æœ‰æŠ¥å‘Šçš„è¯„ä»·æŒ‡æ ‡ä¸Šå‡è¡¨ç°æœ€ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00966">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b5c1b68ccc66755ff034204083c1f6ae" align="middle">
<img src="https://picx.zhimg.com/v2-e8c63c77a856865bdd330b20b95ba239" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-04/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-04/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-97d43a2762892e8e021f104e56d3f04d" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  ZK-WAGON Imperceptible Watermark for Image Generation Models using   ZK-SNARKs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-31ebad80b89bcc6c5e99daf916815f2e" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Touching the tumor boundary A pilot study on ultrasound based virtual   fixtures for breast-conserving surgery
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
