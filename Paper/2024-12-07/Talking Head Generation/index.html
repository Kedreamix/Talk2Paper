<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-12-07  MEMO Memory-Guided Diffusion for Expressive Talking Video Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-1495909db6c3934be6b148d04c1c0a90.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-07-更新"><a href="#2024-12-07-更新" class="headerlink" title="2024-12-07 更新"></a>2024-12-07 更新</h1><h2 id="MEMO-Memory-Guided-Diffusion-for-Expressive-Talking-Video-Generation"><a href="#MEMO-Memory-Guided-Diffusion-for-Expressive-Talking-Video-Generation" class="headerlink" title="MEMO: Memory-Guided Diffusion for Expressive Talking Video Generation"></a>MEMO: Memory-Guided Diffusion for Expressive Talking Video Generation</h2><p><strong>Authors:Longtao Zheng, Yifan Zhang, Hanzhong Guo, Jiachun Pan, Zhenxiong Tan, Jiahao Lu, Chuanxin Tang, Bo An, Shuicheng Yan</strong></p>
<p>Recent advances in video diffusion models have unlocked new potential for realistic audio-driven talking video generation. However, achieving seamless audio-lip synchronization, maintaining long-term identity consistency, and producing natural, audio-aligned expressions in generated talking videos remain significant challenges. To address these challenges, we propose Memory-guided EMOtion-aware diffusion (MEMO), an end-to-end audio-driven portrait animation approach to generate identity-consistent and expressive talking videos. Our approach is built around two key modules: (1) a memory-guided temporal module, which enhances long-term identity consistency and motion smoothness by developing memory states to store information from a longer past context to guide temporal modeling via linear attention; and (2) an emotion-aware audio module, which replaces traditional cross attention with multi-modal attention to enhance audio-video interaction, while detecting emotions from audio to refine facial expressions via emotion adaptive layer norm. Extensive quantitative and qualitative results demonstrate that MEMO generates more realistic talking videos across diverse image and audio types, outperforming state-of-the-art methods in overall quality, audio-lip synchronization, identity consistency, and expression-emotion alignment. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04448v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://memoavatar.github.io/">https://memoavatar.github.io</a></p>
<p><strong>Summary</strong><br>提出基于记忆引导的EMO情感感知扩散模型（MEMO），实现身份一致性、表情自然且与音频同步的说话视频生成。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>研究针对视频扩散模型在说话视频生成中的新潜力。</li>
<li>面临音频唇同步、身份一致性和表情自然性的挑战。</li>
<li>提出MEMO模型，包含记忆引导时序模块和情感感知音频模块。</li>
<li>记忆引导模块通过线性注意力指导时序建模，增强长期身份一致性和运动平滑性。</li>
<li>情感感知模块使用多模态注意力增强音频-视频交互，并通过情感自适应层规范调整面部表情。</li>
<li>MEMO模型在多种图像和音频类型上生成更逼真的说话视频，全面超越现有方法。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: 基于记忆引导扩散模型的表达性对话视频生成研究（MEMO: Memory-Guided Diffusion for Expressive Talking Video Generation）</p>
</li>
<li><p>Authors: Longtao Zheng, Yifan Zhang, Hanzhong Guo, Jiachun Pan, Zhenxiong Tan, Jiahao Lu, Chuanxin Tang, Bo An, Shuicheng Yan</p>
</li>
<li><p>Affiliation:<br>部分作者来自于天空AI公司（Skywork AI），南洋理工大学（Nanyang Technological University），新加坡国立大学（National University of Singapore）。</p>
</li>
<li><p>Keywords: 音频驱动的视频生成，记忆引导扩散模型，身份一致性，表情与情感对齐，视频扩散模型。</p>
</li>
<li><p>Urls: Paper Url: 暂时无法提供直接链接。Github代码链接：Github: None（若存在，请提供链接）</p>
</li>
<li><p>Summary:</p>
</li>
</ol>
<p>(1) 研究背景：随着虚拟形象、数字内容创作和实时通信等领域的快速发展，音频驱动对话视频生成技术受到广泛关注。然而，实现无缝的音频与口型同步、长期身份一致性以及自然、与音频对齐的表情生成仍是该技术的挑战。</p>
<p>(2) 过去的方法及问题：现有的视频扩散模型虽然在音频驱动的对话视频生成方面取得进展，但在保持长期身份一致性、口型与音频同步以及自然表情生成方面仍存在不足。大部分方法使用交叉注意力来结合音频指导视频生成，并通常基于过去2-4帧进行生成以提高运动平滑度，但这种方法存在长期身份不一致的问题。此外，一些方法使用单一的情感标签来指导整个视频的情感表达，忽略了音频中情感的细微变化。</p>
<p>(3) 研究方法：针对上述问题，本文提出了基于记忆引导扩散模型的表达性对话视频生成方法（MEMO）。该方法包含两个关键模块：a. 记忆引导时序模块，通过开发记忆状态来存储更长时间的上下文信息，并通过线性注意力来指导时序建模，从而提高长期身份一致性和运动平滑度；b. 情感感知音频模块，通过多模态注意力增强音频与视频的交互，同时通过从音频中检测到的情感来微调面部表情。使用情感自适应层归一化来细化表情表达。本文提出了MEMO模型生成更具真实感的对话视频。通过广泛的定量和定性评估证明MEMO在整体质量、音频口型同步、身份一致性和表情情感对齐方面优于现有方法。</p>
<p>(4) 任务与性能：本文的方法在音频驱动的对话视频生成任务上取得了显著的性能提升。生成的视频展示出了更高的身份一致性、音频口型同步精度以及更自然的表情表达。实验结果表明该方法能够有效支持其设定的目标。<br>7. 方法论：</p>
<p>(1) 研究背景：该研究针对音频驱动对话视频生成技术展开，针对无缝音频与口型同步、长期身份一致性以及自然情感表达生成技术的挑战展开研究。</p>
<p>(2) 现有方法的问题：现有视频扩散模型在音频驱动对话视频生成方面虽有所进展，但在长期身份一致性、口型与音频同步以及自然表情生成方面仍存在不足。大部分方法使用交叉注意力来结合音频指导视频生成，但这种方法存在长期身份不一致的问题。此外，一些方法忽略了音频中情感的细微变化。</p>
<p>(3) 研究方法：针对上述问题，提出了基于记忆引导扩散模型的表达性对话视频生成方法（MEMO）。首先，设计了一个记忆引导时序模块，通过开发记忆状态来存储更长时间的上下文信息，并通过线性注意力来指导时序建模，以提高长期身份一致性和运动平滑度。其次，设计了一个情感感知音频模块，通过多模态注意力增强音频与视频的交互，同时根据音频中检测到的情感微调面部表情。使用情感自适应层归一化来细化表情表达。通过广泛的定量和定性评估，证明MEMO在整体质量、音频口型同步、身份一致性和表情情感对齐方面优于现有方法。</p>
<p>(4) 训练策略：MEMO的训练分为两个阶段，每个阶段都有特定的目标。第一阶段是面部域适应，初始化Reference Net和Diffusion Net的空间模块使用SD 1.5的权重。在此阶段，适应Reference Net、Diffusion Net的空间注意力模块和原始文本交叉注意力模块到面部域。第二阶段是情感解耦稳健训练，将情感感知音频模块和记忆引导时序模块集成到Diffusion Net中。首先对新添加的模块进行热身训练，保持第一阶段模块固定。热身完成后，所有模块联合训练。在此阶段使用情感条件流损失并扩大数据集进行更全面的训练。当训练视频片段来源于MEAD时采用情感解耦训练策略。此外，研究还发现即使应用了数据处理管道后仍然存在一些噪声数据导致扩散训练不稳定和模型优化偏差。为了缓解这一问题，进一步开发了一种稳健的训练策略，通过过滤掉损失值突然超过特定大值（本例中为0.1）的数据点来提高模型的鲁棒性。该方法的情感条件流损失通常会收敛并波动在约0.03左右。<br>8. Conclusion:</p>
<ul>
<li>(1) 该研究工作的意义在于针对音频驱动对话视频生成技术的挑战展开研究，特别是在无缝音频与口型同步、长期身份一致性以及自然情感表达生成技术方面。这项工作为相关领域提供了一种有效的方法，有望推动虚拟形象、数字内容创作和实时通信等领域的发展。</li>
<li>(2) 创新点：该文章提出了基于记忆引导扩散模型的表达性对话视频生成方法（MEMO），通过记忆引导时序模块和情感感知音频模块的设计，有效提高了长期身份一致性、音频口型同步精度以及表情表达的自然度。</li>
<li>性能：通过实验验证，MEMO在音频驱动的对话视频生成任务上取得了显著的性能提升，生成的视频展示出了更高的身份一致性、音频口型同步精度以及更自然的表情表达。</li>
<li>工作量：文章进行了广泛的实验验证，包括方法论和训练策略的研究，证明了MEMO的有效性。然而，文章未提供Github代码链接，无法评估其代码复现的难度和工作量。</li>
</ul>
<p>希望以上内容能够满足您的要求。</p>
<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-941476c2fc5c6159d9632247e8c47468.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-bf7673e12ff785c7eba3e37be48bdc1c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-73104f1334c96e8289a517f970d92d87.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-92f13d51fe48e01fec21c2b9ef7e6a43.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-98b5c4a01c41fe9eaf0f7d5662ccd784.jpg" align="middle">
</details>




<h2 id="INFP-Audio-Driven-Interactive-Head-Generation-in-Dyadic-Conversations"><a href="#INFP-Audio-Driven-Interactive-Head-Generation-in-Dyadic-Conversations" class="headerlink" title="INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations"></a>INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations</h2><p><strong>Authors:Yongming Zhu, Longhao Zhang, Zhengkun Rong, Tianshu Hu, Shuang Liang, Zhipeng Ge</strong></p>
<p>Imagine having a conversation with a socially intelligent agent. It can attentively listen to your words and offer visual and linguistic feedback promptly. This seamless interaction allows for multiple rounds of conversation to flow smoothly and naturally. In pursuit of actualizing it, we propose INFP, a novel audio-driven head generation framework for dyadic interaction. Unlike previous head generation works that only focus on single-sided communication, or require manual role assignment and explicit role switching, our model drives the agent portrait dynamically alternates between speaking and listening state, guided by the input dyadic audio. Specifically, INFP comprises a Motion-Based Head Imitation stage and an Audio-Guided Motion Generation stage. The first stage learns to project facial communicative behaviors from real-life conversation videos into a low-dimensional motion latent space, and use the motion latent codes to animate a static image. The second stage learns the mapping from the input dyadic audio to motion latent codes through denoising, leading to the audio-driven head generation in interactive scenarios. To facilitate this line of research, we introduce DyConv, a large scale dataset of rich dyadic conversations collected from the Internet. Extensive experiments and visualizations demonstrate superior performance and effectiveness of our method. Project Page: <a target="_blank" rel="noopener" href="https://grisoon.github.io/INFP/">https://grisoon.github.io/INFP/</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04037v1">PDF</a> </p>
<p><strong>Summary</strong><br>提出INFP，一种基于音频的双向头部生成框架，实现社交智能对话。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>INFP旨在实现社交智能对话，注重双向互动。</li>
<li>模型自动切换发言与聆听状态，无需手动分配角色。</li>
<li>包含运动头部模仿和音频引导运动生成两个阶段。</li>
<li>运动头部模仿从视频学习面部交流行为。</li>
<li>音频引导运动生成通过去噪将音频映射到运动代码。</li>
<li>使用DyConv数据集，包含丰富的双向对话。</li>
<li>实验证明方法具有优越性能和有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: INFP：双人对话中的音频驱动交互式头部生成</p>
</li>
<li><p>Authors: Yongming Zhu，Longhao Zhang，Zhengkun Rong，Tianshu Hu，Shuang Liang，Zhipeng Ge（由字节跳动公司支持）</p>
</li>
<li><p>Affiliation: 作者们均来自字节跳动公司。</p>
</li>
<li><p>Keywords: 音频驱动头部生成，双人对话，交互性，面部表达，动作生成，深度学习。</p>
</li>
<li><p>Urls: <a target="_blank" rel="noopener" href="https://arisecvpr24.github.io/INFP_ProjectPage/">https://arisecvpr24.github.io/INFP_ProjectPage/</a> 论文链接，Github代码链接（如有可用）。当前暂无代码链接提供。</p>
</li>
<li><p>Summary: </p>
<ul>
<li><p>(1) 研究背景：随着人工智能技术的发展，构建具有交互性的对话代理成为了一个热门的研究领域。本文旨在解决在双人对话场景中音频驱动的交互式头部生成问题，使代理能够根据不同的音频信号进行动态的面部表情和头部动作。</p>
</li>
<li><p>(2) 过去的方法及其问题：现有研究主要集中在单方面的音频驱动头部生成，如说话或聆听，忽视了双人对话中的交互性。此外，大多数方法需要手动分配角色和明确的角色切换，无法适应动态的对话场景。</p>
</li>
<li><p>(3) 研究方法：本文提出了一种新颖的音频驱动头部生成框架INFP，适用于双人对话场景。该框架包含两个阶段：基于运动的头部模仿阶段和音频引导的运动生成阶段。第一阶段学习从真实对话视频中将面部沟通行为投影到一个低维运动潜在空间，并使用这些运动潜在代码来驱动静态图像。第二阶段学习从输入的双人对话音频到运动潜在代码的映射，从而实现音频驱动的头部生成。</p>
</li>
<li><p>(4) 任务与性能：本文在DyConv数据集上进行了实验和可视化展示，该数据集包含丰富的双人对话场景。实验结果表明，INFP方法在交互式场景中实现了优越的头部生成性能，能够根据不同的音频信号进行动态的面部表情和头部动作切换。性能支持达到了研究目标。</p>
</li>
</ul>
</li>
</ol>
<p>希望以上回答能满足您的要求！<br>7. Methods:</p>
<ul>
<li>(1) 研究首先明确了问题的定义和背景，包括音频驱动的交互式头部生成在双人对话场景中的重要性。此外，对当前的研究现状进行了回顾，指出了现有方法的不足和局限性。</li>
<li>(2) 针对现有方法的不足，研究提出了一种新颖的音频驱动头部生成框架INFP。该框架包含两个阶段：基于运动的头部模仿阶段和音频引导的运动生成阶段。在第一个阶段中，研究使用深度学习模型从真实对话视频中提取面部沟通行为，并将这些行为投影到一个低维运动潜在空间。此外，该研究还利用这些运动潜在代码来驱动静态图像。在第二个阶段中，研究通过训练深度学习模型来学习从双人对话音频到运动潜在代码的映射，从而实现音频驱动的头部生成。</li>
<li>(3) 为了验证所提出方法的有效性，研究在DyConv数据集上进行了实验和可视化展示。实验结果表明，INFP方法在交互式场景中实现了优越的头部生成性能，能够根据不同的音频信号进行动态的面部表情和头部动作切换。此外，该研究还对所提出方法的关键参数进行了详细的分析和讨论，以验证其有效性和可靠性。</li>
</ul>
<p>希望以上内容符合您的要求！<br>8. Conclusion:</p>
<ul>
<li>(1) 这项研究工作的意义在于提出了一种新颖的音频驱动交互式头部生成框架INFP，旨在解决双人对话场景中的音频驱动交互式头部生成问题。该研究对于提升人工智能技术在对话代理领域的应用具有重要意义，能够更好地模拟人类对话时的面部表情和头部动作，提高对话代理的真实感和交互性。</li>
<li>(2) 创新点：本文提出了一个适用于双人对话场景的音频驱动头部生成框架INFP，该框架能够根据不同的音频信号进行动态的面部表情和头部动作生成，且能够适应不同的对话角色，无需手动分配角色和明确的角色切换。<br>性能：在DyConv数据集上的实验结果表明，INFP方法实现了优越的头部生成性能。<br>工作量：文章对方法的原理、实验设计、实验过程以及结果分析等方面进行了详细的阐述，但文章未提及该研究的代码开源情况，且数据量和工作复杂度方面未进行具体阐述。</li>
</ul>
<p>希望以上答复能够满足您的要求！</p>
<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-16c76e149541f70b8cde77669efb7290.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c3be762eba6154196ed65c70710399ee.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-c084dff357cd500a71ead5639334cda0.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1495909db6c3934be6b148d04c1c0a90.jpg" align="middle">
</details>




<h2 id="IF-MDM-Implicit-Face-Motion-Diffusion-Model-for-High-Fidelity-Realtime-Talking-Head-Generation"><a href="#IF-MDM-Implicit-Face-Motion-Diffusion-Model-for-High-Fidelity-Realtime-Talking-Head-Generation" class="headerlink" title="IF-MDM: Implicit Face Motion Diffusion Model for High-Fidelity Realtime   Talking Head Generation"></a>IF-MDM: Implicit Face Motion Diffusion Model for High-Fidelity Realtime   Talking Head Generation</h2><p><strong>Authors:Sejong Yang, Seoung Wug Oh, Yang Zhou, Seon Joo Kim</strong></p>
<p>We introduce a novel approach for high-resolution talking head generation from a single image and audio input. Prior methods using explicit face models, like 3D morphable models (3DMM) and facial landmarks, often fall short in generating high-fidelity videos due to their lack of appearance-aware motion representation. While generative approaches such as video diffusion models achieve high video quality, their slow processing speeds limit practical application. Our proposed model, Implicit Face Motion Diffusion Model (IF-MDM), employs implicit motion to encode human faces into appearance-aware compressed facial latents, enhancing video generation. Although implicit motion lacks the spatial disentanglement of explicit models, which complicates alignment with subtle lip movements, we introduce motion statistics to help capture fine-grained motion information. Additionally, our model provides motion controllability to optimize the trade-off between motion intensity and visual quality during inference. IF-MDM supports real-time generation of 512x512 resolution videos at up to 45 frames per second (fps). Extensive evaluations demonstrate its superior performance over existing diffusion and explicit face models. The code will be released publicly, available alongside supplementary materials. The video results can be found on <a target="_blank" rel="noopener" href="https://bit.ly/ifmdm_supplementary">https://bit.ly/ifmdm_supplementary</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04000v1">PDF</a> underreview in CVPR 2025</p>
<p><strong>Summary</strong><br>提出了一种基于单图和音频输入的高分辨率说话头生成新方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>新方法可从单图和音频生成高分辨率说话头视频。</li>
<li>避免了显式人脸模型（如3DMM和面部特征点）的局限性。</li>
<li>使用隐式运动编码面部，提高视频生成质量。</li>
<li>解决了隐式运动与细微唇部动作对齐的问题。</li>
<li>提供运动可控性，优化运动强度与视觉质量之间的权衡。</li>
<li>支持实时生成512x512分辨率的视频，最高45fps。</li>
<li>性能优于现有扩散模型和显式人脸模型。</li>
<li>公开代码和补充材料。</li>
<li>视频结果可在指定链接查看。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: 隐式面部运动扩散模型用于高质量实时对话头部生成研究</p>
</li>
<li><p>Authors: Sejong Yang, Seoung Wug Oh, Yang Zhou, Seon Joo Kim (Adobe Research &amp; Yonsei University)</p>
</li>
<li><p>Affiliation: 第一作者来自Yonsei University。其他几位作者来自Adobe Research。</p>
</li>
<li><p>Keywords: Talking Head Generation, Video Diffusion Model, Implicit Face Motion, High-Fidelity Realtime Generation</p>
</li>
<li><p>Urls: 论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/cs.CV/papers/2412.04000v1">论文链接</a>（暂时无法提供GitHub代码链接）</p>
</li>
<li><p>Summary:</p>
</li>
</ol>
<p>(1) 研究背景：本文主要关注从单张图像和音频输入生成高质量对话视频的任务。尽管已有使用显式面部模型（如3D形态模型，面部特征点）的方法在该任务上取得一定成果，但它们生成的高保真视频质量仍有待提高。同时，基于生成模型的视频扩散模型虽然可以实现高视频质量，但其处理速度慢，难以应用于实际场景。因此，本文提出了一种新的隐式面部运动扩散模型（IF-MDM）。</p>
<p>(2) 过去的方法及其问题：过去的方法主要分为两类，一类是使用显式面部模型的方法，这类方法虽然计算效率较高，但难以生成高质量的视频，因为它们缺乏对面部运动的精确捕捉以及细节帧的生成能力。另一类是视频扩散模型，虽然它们可以生成高质量的视频，但计算量大，处理速度慢。因此，现有的方法难以在保持高视频质量的同时实现实时生成。</p>
<p>(3) 研究方法：针对上述问题，本文提出了隐式面部运动扩散模型（IF-MDM）。该模型采用隐式运动编码人类面部到面向感知的压缩面部潜在空间，从而增强视频生成能力。尽管隐式运动缺乏显式模型的空间分离特性，我们引入了运动统计信息来帮助捕获精细的运动信息。此外，我们的模型还提供了运动可控性，以在推理过程中优化运动强度与视觉质量的权衡。IF-MDM支持以高达每秒45帧的速度实时生成512x512分辨率的视频。</p>
<p>(4) 任务与性能：本文的方法在谈话头部生成任务上取得了显著成果。与现有的扩散和显式面部模型相比，IF-MDM表现出卓越的性能。实验结果表明，IF-MDM能够生成高质量的视频，同时保持实时性能，证明了其有效性。论文中提供的视频结果可以在相关链接中找到。<br>7. 方法：</p>
<p>(1) 研究背景：文章主要关注如何从单张图像和音频输入生成高质量对话视频的任务。针对现有方法存在的问题，如显式面部模型生成视频质量不高和基于生成模型的视频扩散模型处理速度慢等，提出了一种新的隐式面部运动扩散模型（IF-MDM）。</p>
<p>(2) 方法概述：首先，文章介绍了隐式运动编码人类面部的理论基础知识，将其编码到面向感知的压缩面部潜在空间，以增强视频生成能力。为了捕获精细的运动信息，引入了运动统计信息。此外，该模型还提供了运动可控性，以在推理过程中优化运动强度与视觉质量的权衡。</p>
<p>(3) 扩散模型初步介绍：介绍了扩散模型的理论基础，这是一种通过正向过程将数据分布转化为已知噪声分布，并通过反向过程生成新数据样本的生成模型。在本文中，隐式运动生成器被集成到扩散管道中用于推理。</p>
<p>(4) 训练过程：训练分为两个阶段。第一阶段的目标是学习外观和运动的表示分离，通过利用身份图像和对应的运动图像进行训练，学习压缩运动向量。第二阶段则训练隐式运动生成器学习自然运动序列的分布，使用冻结的视觉编码器和语音编码器，提取运动向量序列和语音向量序列进行训练。</p>
<p>(5) 隐式运动生成器设计：介绍了隐式运动生成器的详细架构，包括其如何接受语音指导以合成表达和同步的头部视频。为了提高生成的运动质量，引入了运动均值和标准差作为附加条件指导，帮助模型学习整体运动动力学。同时，利用时序调制技术将语音向量和扩散时间融入生成过程，确保生成的视频与音频节奏和动力学对齐。</p>
<p>总的来说，本文提出的隐式面部运动扩散模型（IF-MDM）在谈话头部生成任务上取得了显著成果，实现了高质量实时视频生成。<br>8. Conclusion:</p>
<p>(1) 这项工作的意义在于提出了一种新的隐式面部运动扩散模型（IF-MDM），用于从单张图像和音频输入生成高质量对话视频。该模型在谈话头部生成任务上具有显著成果，具有重要的实际应用价值，可应用于虚拟助手、数字化身、视频会议和内容创作等领域，能够提升用户体验、可访问性和个性化，为数字媒体、通信和娱乐等领域带来革新。</p>
<p>(2) 创新点：该文章提出了隐式面部运动扩散模型（IF-MDM），结合隐式运动编码和扩散模型理论，实现了高质量实时视频生成。其引入运动统计信息和可控性优化，提高了运动信息的捕获和生成质量。此外，该模型在谈话头部生成任务上取得了显著成果，证明了其有效性和创新性。</p>
<p>性能：该模型实现了高质量的视频生成，同时保持了实时性能，支持高达每秒45帧的速度生成512x512分辨率的视频。与现有的扩散和显式面部模型相比，IF-MDM表现出卓越的性能。</p>
<p>工作量：文章详细阐述了模型的设计和实现过程，包括训练过程、隐式运动生成器的设计和实现等。工作量较大，但文章结构清晰，逻辑严谨，易于理解。</p>
<p>然而，该文章也存在一定的局限性，未来工作将聚焦于扩展IF-MDM的能力，处理更复杂的场景、多样化的环境条件和进一步提高生成视频的可控性和表现力。同时，也需要关注潜在伦理问题，如虚假信息等问题。</p>
<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d0e2109339e6dadf6720d378c36b617e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-00138b9c881d5f5772c1ecfefc967c46.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-fa55c6f6b4e5341598b00eea17364722.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-d7687d5dd74e676e999fbf3aeac19020.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-07/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-07/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-07/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-f99336e9eaadb0ddb4c3dfffa1d84b60.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2024-12-07  Turbo3D Ultra-fast Text-to-3D Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-02/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e5ef3abf9236ee85102c6a23d5df63e2.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2024-12-02  Uniform Attention Maps Boosting Image Fidelity in Reconstruction and   Editing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">6050.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
