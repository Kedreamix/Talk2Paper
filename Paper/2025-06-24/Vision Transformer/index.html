<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Vision Transformer">
    <meta name="description" content="Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-24  Class Agnostic Instance-level Descriptor for Visual Instance Search">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Vision Transformer | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-3635515263bf8e0528cc1713204e66fe.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Vision Transformer</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Vision-Transformer/">
                                <span class="chip bg-color">Vision Transformer</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                Vision Transformer
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-24-æ›´æ–°"><a href="#2025-06-24-æ›´æ–°" class="headerlink" title="2025-06-24 æ›´æ–°"></a>2025-06-24 æ›´æ–°</h1><h2 id="Class-Agnostic-Instance-level-Descriptor-for-Visual-Instance-Search"><a href="#Class-Agnostic-Instance-level-Descriptor-for-Visual-Instance-Search" class="headerlink" title="Class Agnostic Instance-level Descriptor for Visual Instance Search"></a>Class Agnostic Instance-level Descriptor for Visual Instance Search</h2><p><strong>Authors:Qi-Ying Sun, Wan-Lei Zhao, Yi-Bo Miao, Chong-Wah Ngo</strong></p>
<p>Despite the great success of the deep features in content-based image retrieval, the visual instance search remains challenging due to the lack of effective instance level feature representation. Supervised or weakly supervised object detection methods are not among the options due to their poor performance on the unknown object categories. In this paper, based on the feature set output from self-supervised ViT, the instance level region discovery is modeled as detecting the compact feature subsets in a hierarchical fashion. The hierarchical decomposition results in a hierarchy of feature subsets. The non-leaf nodes and leaf nodes on the hierarchy correspond to the various instance regions in an image of different semantic scales. The hierarchical decomposition well addresses the problem of object embedding and occlusions, which are widely observed in the real scenarios. The features derived from the nodes on the hierarchy make up a comprehensive representation for the latent instances in the image. Our instance-level descriptor remains effective on both the known and unknown object categories. Empirical studies on three instance search benchmarks show that it outperforms state-of-the-art methods considerably. </p>
<blockquote>
<p>å°½ç®¡æ·±åº¦ç‰¹å¾åœ¨åŸºäºå†…å®¹çš„å›¾åƒæ£€ç´¢ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ç”±äºç¼ºä¹æœ‰æ•ˆçš„å®ä¾‹çº§ç‰¹å¾è¡¨ç¤ºï¼Œè§†è§‰å®ä¾‹æœç´¢ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç”±äºå…¶åœ¨æœªçŸ¥å¯¹è±¡ç±»åˆ«ä¸Šçš„è¡¨ç°ä¸ä½³ï¼Œç›‘ç£æˆ–å¼±ç›‘ç£å¯¹è±¡æ£€æµ‹æ–¹æ³•å¹¶ä¸é€‚ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼ŒåŸºäºè‡ªç›‘ç£ViTè¾“å‡ºçš„ç‰¹å¾é›†ï¼Œå°†å®ä¾‹çº§åŒºåŸŸå‘ç°å»ºæ¨¡ä¸ºä»¥åˆ†å±‚æ–¹å¼æ£€æµ‹ç´§å‡‘ç‰¹å¾å­é›†ã€‚åˆ†å±‚åˆ†è§£çš„ç»“æœæ˜¯ä¸€ç³»åˆ—ç‰¹å¾å­é›†ã€‚å±‚æ¬¡ç»“æ„ä¸Šçš„éå¶èŠ‚ç‚¹å’Œå¶èŠ‚ç‚¹å¯¹åº”äºå›¾åƒä¸­ä¸åŒè¯­ä¹‰å°ºåº¦çš„å„ç§å®ä¾‹åŒºåŸŸã€‚åˆ†å±‚åˆ†è§£å¾ˆå¥½åœ°è§£å†³äº†å¯¹è±¡åµŒå…¥å’Œé®æŒ¡é—®é¢˜ï¼Œè¿™äº›é—®é¢˜åœ¨å®é™…åœºæ™¯ä¸­å¹¿æ³›å­˜åœ¨ã€‚ä»å±‚æ¬¡ç»“æ„ä¸Šçš„èŠ‚ç‚¹æ´¾ç”Ÿçš„ç‰¹å¾æ„æˆäº†å›¾åƒä¸­æ½œåœ¨å®ä¾‹çš„å…¨é¢è¡¨ç¤ºã€‚æˆ‘ä»¬çš„å®ä¾‹çº§æè¿°ç¬¦åœ¨å·²çŸ¥å’ŒæœªçŸ¥å¯¹è±¡ç±»åˆ«ä¸Šå‡ä¿æŒæœ‰æ•ˆã€‚åœ¨ä¸‰ä¸ªå®ä¾‹æœç´¢åŸºå‡†æµ‹è¯•ä¸Šçš„ç»éªŒç ”ç©¶è¡¨æ˜ï¼Œå®ƒçš„æ€§èƒ½æ˜æ˜¾ä¼˜äºæœ€æ–°æŠ€æœ¯çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16745v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºè‡ªç›‘ç£ViTçš„ç‰¹å¾é›†è¾“å‡ºï¼Œæœ¬æ–‡å°†å®ä¾‹çº§åˆ«çš„åŒºåŸŸå‘ç°å»ºæ¨¡ä¸ºä»¥åˆ†å±‚æ–¹å¼æ£€æµ‹ç´§å‡‘ç‰¹å¾å­é›†çš„é—®é¢˜ã€‚åˆ†å±‚åˆ†è§£äº§ç”Ÿä¸€ç³»åˆ—çš„ç‰¹å¾å­é›†å±‚æ¬¡ç»“æ„ï¼Œå…¶ä¸­çš„éå¶å­èŠ‚ç‚¹å’Œå¶å­èŠ‚ç‚¹å¯¹åº”äºå›¾åƒä¸­ä¸åŒè¯­ä¹‰å°ºåº¦çš„å„ç§å®ä¾‹åŒºåŸŸã€‚åˆ†å±‚åˆ†è§£å¾ˆå¥½åœ°è§£å†³äº†ç‰©ä½“åµŒå…¥å’Œé®æŒ¡é—®é¢˜ï¼Œè¿™äº›é—®é¢˜åœ¨çœŸå®åœºæ™¯ä¸­æ™®éå­˜åœ¨ã€‚ä»å±‚æ¬¡ç»“æ„ä¸Šæå–çš„ç‰¹å¾ä¸ºå›¾åƒä¸­çš„æ½œåœ¨å®ä¾‹æä¾›äº†å…¨é¢çš„è¡¨ç¤ºã€‚æœ¬æ–‡çš„å®ä¾‹çº§æè¿°ç¬¦åœ¨å·²çŸ¥å’ŒæœªçŸ¥å¯¹è±¡ç±»åˆ«ä¸Šå‡ä¿æŒæœ‰æ•ˆã€‚åœ¨ä¸‰ä¸ªå®ä¾‹æœç´¢åŸºå‡†æµ‹è¯•ä¸Šçš„å®è¯ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å®ä¾‹çº§åˆ«çš„åŒºåŸŸå‘ç°å¯ä»¥é€šè¿‡æ£€æµ‹è‡ªç›‘ç£ViTç‰¹å¾é›†çš„ç´§å‡‘ç‰¹å¾å­é›†æ¥è§£å†³ã€‚</li>
<li>åˆ†å±‚åˆ†è§£äº§ç”Ÿä¸€ç³»åˆ—ç‰¹å¾å­é›†ï¼Œå…¶ä¸­éå¶å­èŠ‚ç‚¹å’Œå¶å­èŠ‚ç‚¹ä»£è¡¨å›¾åƒä¸­ä¸åŒè¯­ä¹‰å°ºåº¦çš„å®ä¾‹åŒºåŸŸã€‚</li>
<li>åˆ†å±‚åˆ†è§£æœ‰æ•ˆè§£å†³äº†ç‰©ä½“åµŒå…¥å’Œé®æŒ¡é—®é¢˜ã€‚</li>
<li>ä»å±‚æ¬¡ç»“æ„ä¸Šæå–çš„ç‰¹å¾ä¸ºå›¾åƒä¸­çš„æ½œåœ¨å®ä¾‹æä¾›äº†å…¨é¢çš„è¡¨ç¤ºã€‚</li>
<li>å®ä¾‹çº§æè¿°ç¬¦å¯¹å·²çŸ¥å’ŒæœªçŸ¥å¯¹è±¡ç±»åˆ«å‡æœ‰æ•ˆã€‚</li>
<li>åœ¨ä¸‰ä¸ªå®ä¾‹æœç´¢åŸºå‡†æµ‹è¯•ä¸Šï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16745">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3635515263bf8e0528cc1713204e66fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-50064f6e1450e3caba282c982f7e9e52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2223a226f7ffd9d80424cc15653a1fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c173c9100a11957033d3215bfad90b21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-354730537a9915ae900353da2af1cbb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0aeddde17fce859dfeb92233fd2aeec7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-44e437fcf37efab83507c91a9feb54b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b25c926d8a528fa32e89b9a7d4fb4e23.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Prompt-based-Dynamic-Token-Pruning-to-Guide-Transformer-Attention-in-Efficient-Segmentation"><a href="#Prompt-based-Dynamic-Token-Pruning-to-Guide-Transformer-Attention-in-Efficient-Segmentation" class="headerlink" title="Prompt-based Dynamic Token Pruning to Guide Transformer Attention in   Efficient Segmentation"></a>Prompt-based Dynamic Token Pruning to Guide Transformer Attention in   Efficient Segmentation</h2><p><strong>Authors:Pallabi Dutta, Anubhab Maity, Sushmita Mitra</strong></p>
<p>The high computational demands of Vision Transformers (ViTs), in processing a huge number of tokens, often constrain their practical application in analyzing medical images. This research proposes an adaptive prompt-guided pruning method to selectively reduce the processing of irrelevant tokens in the segmentation pipeline. The prompt-based spatial prior helps to rank the tokens according to their relevance. Tokens with low-relevance scores are down-weighted, ensuring that only the relevant ones are propagated for processing across subsequent stages. This data-driven pruning strategy facilitates end-to-end training, maintains gradient flow, and improves segmentation accuracy by focusing computational resources on essential regions. The proposed framework is integrated with several state-of-the-art models to facilitate the elimination of irrelevant tokens; thereby, enhancing computational efficiency while preserving segmentation accuracy. The experimental results show a reduction of $\sim$ 35-55% tokens; thus reducing the computational costs relative to the baselines. Cost-effective medical image processing, using our framework, facilitates real-time diagnosis by expanding its applicability in resource-constrained environments. </p>
<blockquote>
<p>è§†è§‰Transformerï¼ˆViTï¼‰çš„è®¡ç®—éœ€æ±‚æé«˜ï¼Œåœ¨å¤„ç†å¤§é‡æ ‡è®°æ—¶ï¼Œç»å¸¸é™åˆ¶å…¶åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­çš„å®é™…åº”ç”¨ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æç¤ºå¼•å¯¼ä¿®å‰ªæ–¹æ³•ï¼Œæœ‰é€‰æ‹©åœ°å‡å°‘åˆ†å‰²ç®¡é“ä¸­ä¸ç›¸å…³æ ‡è®°çš„å¤„ç†ã€‚åŸºäºæç¤ºçš„ç©ºé—´å…ˆéªŒæœ‰åŠ©äºæ ¹æ®ç›¸å…³æ€§å¯¹æ ‡è®°è¿›è¡Œæ’åã€‚ä½ç›¸å…³æ€§å¾—åˆ†çš„æ ‡è®°è¢«é™æƒï¼Œç¡®ä¿åªæœ‰ç›¸å…³çš„æ ‡è®°åœ¨åç»­é˜¶æ®µè¿›è¡Œå¤„ç†ã€‚è¿™ç§æ•°æ®é©±åŠ¨çš„ä¿®å‰ªç­–ç•¥ä¿ƒè¿›äº†ç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œä¿æŒäº†æ¢¯åº¦æµï¼Œå¹¶é€šè¿‡å°†è®¡ç®—èµ„æºé›†ä¸­åœ¨å…³é”®åŒºåŸŸä¸Šï¼Œæé«˜äº†åˆ†å‰²çš„å‡†ç¡®åº¦ã€‚æ‰€æå‡ºçš„æ¡†æ¶ä¸å¤šç§æœ€æ–°æ¨¡å‹é›†æˆï¼Œä»¥æ¶ˆé™¤ä¸ç›¸å…³çš„æ ‡è®°ï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒåˆ†å‰²ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜å‡å°‘äº†çº¦35-55ï¼…çš„æ ‡è®°ï¼Œä¸åŸºçº¿ç›¸æ¯”é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ä½¿ç”¨æˆ‘ä»¬çš„æ¡†æ¶å®ç°ç»æµé«˜æ•ˆçš„åŒ»å­¦å›¾åƒå¤„ç†ï¼Œé€šè¿‡æ‰©å¤§å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œä¿ƒè¿›å®æ—¶è¯Šæ–­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16369v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æç¤ºå¼•å¯¼è£å‰ªæ–¹æ³•ï¼Œç”¨äºé€‰æ‹©æ€§å‡å°‘å¤„ç†åŒ»å­¦å›¾åƒåˆ†æä¸­Vision Transformerï¼ˆViTï¼‰çš„ä¸ç›¸å…³ä»¤ç‰Œã€‚æç¤ºç©ºé—´å…ˆéªŒæœ‰åŠ©äºæ ¹æ®ç›¸å…³æ€§å¯¹ä»¤ç‰Œè¿›è¡Œæ’åã€‚ä½ç›¸å…³æ€§å¾—åˆ†çš„ä»¤ç‰Œè¢«é™æƒå¤„ç†ï¼Œç¡®ä¿åªå¤„ç†ç›¸å…³çš„ä»¤ç‰Œã€‚è¿™ç§æ•°æ®é©±åŠ¨çš„è£å‰ªç­–ç•¥ä¾¿äºç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œä¿æŒæ¢¯åº¦æµåŠ¨ï¼Œå¹¶é€šè¿‡é›†ä¸­è®¡ç®—èµ„æºäºå…³é”®åŒºåŸŸæé«˜åˆ†å‰²ç²¾åº¦ã€‚è¯¥æ¡†æ¶ä¸å¤šä¸ªæœ€æ–°æ¨¡å‹é›†æˆï¼Œä»¥æ¶ˆé™¤ä¸ç›¸å…³çš„ä»¤ç‰Œï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡å¹¶ä¿æŒåˆ†å‰²ç²¾åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºä»¤ç‰Œæ•°é‡å‡å°‘äº†çº¦35-55%ï¼Œç›¸å¯¹äºåŸºçº¿é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ä½¿ç”¨æ­¤æ¡†æ¶çš„ç»æµå‹åŒ»å­¦å›¾åƒå¤„ç†æ‰©å¤§äº†å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„é€‚ç”¨æ€§ï¼Œæœ‰åŠ©äºå®æ—¶è¯Šæ–­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Vision Transformers (ViTs)é¢ä¸´é«˜è®¡ç®—éœ€æ±‚ï¼Œå¤„ç†å¤§é‡ä»¤ç‰Œæ—¶å­˜åœ¨å®è·µåº”ç”¨ä¸Šçš„é™åˆ¶ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æç¤ºå¼•å¯¼è£å‰ªæ–¹æ³•ï¼Œä»¥é€‰æ‹©æ€§å‡å°‘ä¸ç›¸å…³ä»¤ç‰Œçš„å¤„ç†ã€‚</li>
<li>æç¤ºç©ºé—´å…ˆéªŒç”¨äºæ ¹æ®ä»¤ç‰Œçš„ç›¸å…³æ€§è¿›è¡Œæ’åã€‚</li>
<li>ä½ç›¸å…³æ€§ä»¤ç‰Œè¢«é™æƒå¤„ç†ï¼Œç¡®ä¿ä»…å¤„ç†ç›¸å…³ä»¤ç‰Œã€‚</li>
<li>æ•°æ®é©±åŠ¨çš„è£å‰ªç­–ç•¥æ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒï¼Œç»´æŒæ¢¯åº¦æµåŠ¨ï¼Œå¹¶æé«˜åˆ†å‰²ç²¾åº¦ã€‚</li>
<li>æ¡†æ¶ä¸å¤šä¸ªæœ€æ–°æ¨¡å‹é›†æˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¶ˆé™¤ä¸ç›¸å…³ä»¤ç‰Œï¼Œæé«˜è®¡ç®—æ•ˆç‡å¹¶ä¿æŒåˆ†å‰²ç²¾åº¦ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºè®¡ç®—æˆæœ¬ç›¸å¯¹è¾ƒä½ï¼Œä»¤ç‰Œæ•°é‡å‡å°‘äº†çº¦35-55%ï¼Œé€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒï¼Œæœ‰åŠ©äºå®æ—¶è¯Šæ–­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16369">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-44ee9eeeecb5680fd6ff7b4e42e9aa99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8e384d6c800f9b9c1848904b48e3e14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd517bdc34fcb50c2ecd62cb24053016.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c3547fb3b9afac588e0d8006a6ed810.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Integrating-Generative-Adversarial-Networks-and-Convolutional-Neural-Networks-for-Enhanced-Traffic-Accidents-Detection-and-Analysis"><a href="#Integrating-Generative-Adversarial-Networks-and-Convolutional-Neural-Networks-for-Enhanced-Traffic-Accidents-Detection-and-Analysis" class="headerlink" title="Integrating Generative Adversarial Networks and Convolutional Neural   Networks for Enhanced Traffic Accidents Detection and Analysis"></a>Integrating Generative Adversarial Networks and Convolutional Neural   Networks for Enhanced Traffic Accidents Detection and Analysis</h2><p><strong>Authors:Zhenghao Xi, Xiang Liu, Yaqi Liu, Yitong Cai, Yangyu Zheng</strong></p>
<p>Accident detection using Closed Circuit Television (CCTV) footage is one of the most imperative features for enhancing transport safety and efficient traffic control. To this end, this research addresses the issues of supervised monitoring and data deficiency in accident detection systems by adapting excellent deep learning technologies. The motivation arises from rising statistics in the number of car accidents worldwide; this calls for innovation and the establishment of a smart, efficient and automated way of identifying accidents and calling for help to save lives. Addressing the problem of the scarcity of data, the presented framework joins Generative Adversarial Networks (GANs) for synthesizing data and Convolutional Neural Networks (CNN) for model training. Video frames for accidents and non-accidents are collected from YouTube videos, and we perform resizing, image enhancement and image normalisation pixel range adjustments. Three models are used: CNN, Fine-tuned Convolutional Neural Network (FTCNN) and Vision Transformer (VIT) worked best for detecting accidents from CCTV, obtaining an accuracy rate of 94% and 95%, while the CNN model obtained 88%. Such results show that the proposed framework suits traffic safety applications due to its high real-time accident detection capabilities and broad-scale applicability. This work lays the foundation for intelligent surveillance systems in the future for real-time traffic monitoring, smart city framework, and integration of intelligent surveillance systems into emergency management systems. </p>
<blockquote>
<p>ä½¿ç”¨é—­è·¯ç”µè§†ï¼ˆCCTVï¼‰ç”»é¢è¿›è¡Œäº‹æ•…æ£€æµ‹æ˜¯å¢å¼ºäº¤é€šå®‰å…¨æ€§å’Œæé«˜äº¤é€šæ•ˆç‡çš„å…³é”®åŠŸèƒ½ä¹‹ä¸€ã€‚ä¸ºæ­¤ï¼Œæœ¬ç ”ç©¶é€šè¿‡é€‚åº”å“è¶Šçš„æ·±åº¦å­¦ä¹ æŠ€æœ¯æ¥è§£å†³äº‹æ•…æ£€æµ‹ç³»ç»Ÿä¸­çš„ç›‘ç£ç›‘æ§å’Œæ•°æ®ç¼ºä¹é—®é¢˜ã€‚è¿™ç§åŠ¨æœºæºäºå…¨çƒæ±½è½¦äº‹æ•…æ•°é‡ç»Ÿè®¡æ•°æ®çš„ä¸Šå‡ï¼›è¿™éœ€è¦åˆ›æ–°å¹¶å»ºç«‹ä¸€ç§æ™ºèƒ½ã€é«˜æ•ˆã€è‡ªåŠ¨åŒ–çš„æ–¹å¼æ¥è¯†åˆ«äº‹æ•…å¹¶å¯»æ±‚å¸®åŠ©ä»¥æŒ½æ•‘ç”Ÿå‘½ã€‚é’ˆå¯¹æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶ç»“åˆäº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰è¿›è¡Œæ•°æ®åˆæˆå’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚æˆ‘ä»¬ä»YouTubeè§†é¢‘ä¸­æ”¶é›†äº†äº‹æ•…å’Œéäº‹æ•…çš„è§†é¢‘å¸§ï¼Œå¹¶è¿›è¡Œäº†å°ºå¯¸è°ƒæ•´ã€å›¾åƒå¢å¼ºå’Œå›¾åƒå½’ä¸€åŒ–åƒç´ èŒƒå›´è°ƒæ•´ã€‚æˆ‘ä»¬ä½¿ç”¨äº†ä¸‰ç§æ¨¡å‹ï¼šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€å¾®è°ƒå·ç§¯ç¥ç»ç½‘ç»œï¼ˆFTCNNï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆVITï¼‰ï¼Œå®ƒä»¬åœ¨ä»CCTVæ£€æµ‹äº‹æ•…æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡åˆ†åˆ«ä¸º94%å’Œ95%ï¼Œè€ŒCNNæ¨¡å‹çš„å‡†ç¡®ç‡ä¸º88%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶å› å…¶é«˜å®æ—¶äº‹æ•…æ£€æµ‹èƒ½åŠ›å’Œå¹¿æ³›çš„é€‚ç”¨æ€§è€Œé€‚ç”¨äºäº¤é€šå®‰å…¨åº”ç”¨ã€‚è¿™é¡¹å·¥ä½œä¸ºæœªæ¥æ™ºèƒ½ç›‘æ§ç³»ç»Ÿåœ¨å®æ—¶äº¤é€šç›‘æ§ã€æ™ºèƒ½åŸå¸‚æ¡†æ¶ä»¥åŠæ™ºèƒ½ç›‘æ§ç³»ç»Ÿä¸ç´§æ€¥ç®¡ç†ç³»ç»Ÿé›†æˆä¸­çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16186v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>åˆ©ç”¨é—­è·¯ç”µè§†ï¼ˆCCTVï¼‰è§†é¢‘è¿›è¡Œäº‹æ•…æ£€æµ‹æ˜¯æå‡äº¤é€šå®‰å…¨å’Œæœ‰æ•ˆäº¤é€šæ§åˆ¶çš„å…³é”®åŠŸèƒ½ä¹‹ä¸€ã€‚æœ¬ç ”ç©¶é€šè¿‡åº”ç”¨ä¼˜ç§€çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯è§£å†³äº‹æ•…æ£€æµ‹ç³»ç»Ÿä¸­çš„ç›‘æ§å’Œç›‘ç£ä»¥åŠæ•°æ®ç¼ºå¤±é—®é¢˜ã€‚æœ¬ç ”ç©¶çš„åŠ¨æœºæºäºå…¨çƒæ±½è½¦äº‹æ•…æ•°é‡çš„ä¸Šå‡ç»Ÿè®¡ï¼Œè¿™è¦æ±‚åˆ›æ–°å’Œå»ºç«‹ä¸€ä¸ªæ™ºèƒ½ã€é«˜æ•ˆã€è‡ªåŠ¨åŒ–çš„è¯†åˆ«äº‹æ•…å’Œå‘¼å«æ•‘æ´ç³»ç»Ÿä»¥æŒ½æ•‘ç”Ÿå‘½ã€‚ä¸ºè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œç ”ç©¶ç»“åˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰è¿›è¡Œæ•°æ®åˆæˆå’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚ä»YouTubeè§†é¢‘æ”¶é›†äº‹æ•…å’Œéäº‹æ•…çš„è§†é¢‘å¸§ï¼Œå¹¶è¿›è¡Œå°ºå¯¸è°ƒæ•´ã€å›¾åƒå¢å¼ºå’Œå›¾åƒå½’ä¸€åŒ–åƒç´ èŒƒå›´è°ƒæ•´ã€‚å…¶ä¸­å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€å¾®è°ƒå·ç§¯ç¥ç»ç½‘ç»œï¼ˆFTCNNï¼‰å’Œè§†è§‰å˜å‹å™¨ï¼ˆVITï¼‰åœ¨æ£€æµ‹CCTVäº‹æ•…æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°94%å’Œ95%ï¼Œè€ŒCNNæ¨¡å‹å‡†ç¡®ç‡ä¸º88%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶é€‚ç”¨äºäº¤é€šå®‰å…¨åº”ç”¨ï¼Œå…·æœ‰å®æ—¶äº‹æ•…æ£€æµ‹èƒ½åŠ›å¹¶åœ¨å¤§è§„æ¨¡åº”ç”¨ä¸Šæœ‰æ½œåŠ›ã€‚æ­¤å·¥ä½œä¸ºæœªæ¥æ™ºèƒ½äº¤é€šç›‘æ§ç³»ç»Ÿæ‰“ä¸‹åšå®çš„åŸºç¡€ï¼ŒåŠ©åŠ›å®æ—¶ç›‘æ§äº¤é€šå’Œé›†æˆåˆ°æ™ºèƒ½åŸå¸‚æ¡†æ¶åŠç´§æ€¥ç®¡ç†ç³»ç»Ÿä¹‹ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>ç ”ç©¶è§£å†³äº†æé«˜äº¤é€šå®‰å…¨åŠé«˜æ•ˆäº¤é€šæ§åˆ¶çš„å…³é”®é—®é¢˜ä¹‹ä¸€ â€”â€” åˆ©ç”¨é—­è·¯ç”µè§†ç›‘æ§ç³»ç»Ÿè¿›è¡Œäº‹æ•…æ£€æµ‹ã€‚</li>
<li>æœ¬ç ”ç©¶ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¸­çš„ä¼˜ç§€æ–¹æ³•ï¼Œç‰¹åˆ«ç»“åˆäº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œå·ç§¯ç¥ç»ç½‘ç»œå¤„ç†äº‹æ•…æ£€æµ‹ç³»ç»Ÿé¢ä¸´çš„ç›‘ç£ç›‘æ§å’Œæ•°æ®ç¼ºä¹çš„é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16186">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2ec762ca649be9cd2fa03153635466cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edd01bc760dba039e19394547c766cc8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-77d8e4d5bfb2d7bbddae79f4fb2d69f0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1982efdfd8fc1cc54c7b34ef1f8eaefe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c89fbb4578f342cde122fab2b6fc7032.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98d14e14068f1f178db6b36a2a8bfabb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Polyline-Path-Masked-Attention-for-Vision-Transformer"><a href="#Polyline-Path-Masked-Attention-for-Vision-Transformer" class="headerlink" title="Polyline Path Masked Attention for Vision Transformer"></a>Polyline Path Masked Attention for Vision Transformer</h2><p><strong>Authors:Zhongchen Zhao, Chaodong Xiao, Hui Lin, Qi Xie, Lei Zhang, Deyu Meng</strong></p>
<p>Global dependency modeling and spatial position modeling are two core issues of the foundational architecture design in current deep learning frameworks. Recently, Vision Transformers (ViTs) have achieved remarkable success in computer vision, leveraging the powerful global dependency modeling capability of the self-attention mechanism. Furthermore, Mamba2 has demonstrated its significant potential in natural language processing tasks by explicitly modeling the spatial adjacency prior through the structured mask. In this paper, we propose Polyline Path Masked Attention (PPMA) that integrates the self-attention mechanism of ViTs with an enhanced structured mask of Mamba2, harnessing the complementary strengths of both architectures. Specifically, we first ameliorate the traditional structured mask of Mamba2 by introducing a 2D polyline path scanning strategy and derive its corresponding structured mask, polyline path mask, which better preserves the adjacency relationships among image tokens. Notably, we conduct a thorough theoretical analysis on the structural characteristics of the proposed polyline path mask and design an efficient algorithm for the computation of the polyline path mask. Next, we embed the polyline path mask into the self-attention mechanism of ViTs, enabling explicit modeling of spatial adjacency prior. Extensive experiments on standard benchmarks, including image classification, object detection, and segmentation, demonstrate that our model outperforms previous state-of-the-art approaches based on both state-space models and Transformers. For example, our proposed PPMA-T&#x2F;S&#x2F;B models achieve 48.7%&#x2F;51.1%&#x2F;52.3% mIoU on the ADE20K semantic segmentation task, surpassing RMT-T&#x2F;S&#x2F;B by 0.7%&#x2F;1.3%&#x2F;0.3%, respectively. Code is available at <a target="_blank" rel="noopener" href="https://github.com/zhongchenzhao/PPMA">https://github.com/zhongchenzhao/PPMA</a>. </p>
<blockquote>
<p>å…¨å±€ä¾èµ–å»ºæ¨¡å’Œç©ºé—´ä½ç½®å»ºæ¨¡æ˜¯å½“å‰æ·±åº¦å­¦ä¹ æ¡†æ¶åŸºç¡€æ¶æ„è®¾è®¡ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚æœ€è¿‘ï¼ŒVision Transformersï¼ˆViTsï¼‰åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å¼ºå¤§å…¨å±€ä¾èµ–å»ºæ¨¡èƒ½åŠ›ï¼Œåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚æ­¤å¤–ï¼ŒMamba2é€šè¿‡æ˜ç¡®çš„ç©ºé—´é‚»æ¥å…ˆéªŒå»ºæ¨¡ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å±•ç¤ºäº†å…¶æ˜¾è‘—æ½œåŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Polyline Path Masked Attentionï¼ˆPPMAï¼‰ï¼Œå®ƒç»“åˆäº†ViTsçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶å’ŒMamba2çš„å¢å¼ºç»“æ„æ©ç ï¼Œå……åˆ†åˆ©ç”¨äº†ä¸¤ç§æ¶æ„çš„äº’è¡¥ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡å¼•å…¥2DæŠ˜çº¿è·¯å¾„æ‰«æç­–ç•¥ï¼Œæ”¹è¿›äº†Mamba2çš„ä¼ ç»Ÿç»“æ„æ©ç ï¼Œå¹¶æ´¾ç”Ÿå‡ºå…¶ç›¸åº”çš„ç»“æ„æ©ç ï¼Œå³æŠ˜çº¿è·¯å¾„æ©ç ï¼Œèƒ½æ›´å¥½åœ°ä¿ç•™å›¾åƒæ ‡è®°ä¹‹é—´çš„é‚»æ¥å…³ç³»ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å¯¹æ‰€æå‡ºçš„æŠ˜çº¿è·¯å¾„æ©ç çš„ç»“æ„ç‰¹æ€§è¿›è¡Œäº†å…¨é¢çš„ç†è®ºåˆ†æï¼Œå¹¶è®¾è®¡äº†è®¡ç®—æŠ˜çº¿è·¯å¾„æ©ç çš„é«˜æ•ˆç®—æ³•ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.15940v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºå°†Vision Transformerä¸Mamba2çš„ç»“æ„åŒ–æ©ç ç»“åˆçš„Polyline Path Masked Attentionï¼ˆPPMAï¼‰ã€‚æ–°æ–¹æ³•é€šè¿‡å¼•å…¥2DæŠ˜çº¿è·¯å¾„æ‰«æç­–ç•¥æ”¹è¿›äº†Mamba2çš„ç»“æ„åŒ–æ©ç ï¼Œå¾—åˆ°Polyline Path Maskï¼Œæ›´å¥½åœ°ä¿ç•™äº†å›¾åƒæ ‡è®°é—´çš„é‚»æ¥å…³ç³»ã€‚åœ¨æ ‡å‡†å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ–°æ–¹æ³•æ€§èƒ½ä¼˜äºå½“å‰æœ€å‰æ²¿æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PPMAç»“åˆäº†Vision Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶å’ŒMamba2çš„ç»“æ„åŒ–æ©ç æŠ€æœ¯ã€‚</li>
<li>PPMAå¼•å…¥çš„2DæŠ˜çº¿è·¯å¾„æ©ç èƒ½å¤Ÿæ›´å¥½åœ°ä¿ç•™å›¾åƒæ ‡è®°é—´çš„é‚»æ¥å…³ç³»ã€‚</li>
<li>å¯¹æå‡ºçš„polyline path maskè¿›è¡Œäº†ç†è®ºåˆ†æå’Œé«˜æ•ˆç®—æ³•è®¾è®¡ã€‚</li>
<li>PPMAåœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šå®ç°äº†æ€§èƒ½è¶…è¶Šã€‚</li>
<li>åœ¨ADE20Kè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šï¼ŒPPMA-T&#x2F;S&#x2F;Bæ¨¡å‹ç›¸è¾ƒäºRMT-T&#x2F;S&#x2F;Båˆ†åˆ«æé«˜äº†0.7%&#x2F;1.3%&#x2F;0.3%çš„mIoUã€‚</li>
<li>è¯¥æ¨¡å‹å¼ºåŒ–äº†ç©ºé—´é‚»æ¥å…ˆéªŒçš„å»ºæ¨¡èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.15940">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d48d93347ddde982a5c3619384669612.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-05ec3b53a4a7ebc7c4e3ca2ba813bc23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25a246d40760c59c7265a59faaa7057d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4085aab682a851125227923d4396d560.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="OpenPath-Open-Set-Active-Learning-for-Pathology-Image-Classification-via-Pre-trained-Vision-Language-Models"><a href="#OpenPath-Open-Set-Active-Learning-for-Pathology-Image-Classification-via-Pre-trained-Vision-Language-Models" class="headerlink" title="OpenPath: Open-Set Active Learning for Pathology Image Classification   via Pre-trained Vision-Language Models"></a>OpenPath: Open-Set Active Learning for Pathology Image Classification   via Pre-trained Vision-Language Models</h2><p><strong>Authors:Lanfeng Zhong, Xin Liao, Shichuan Zhang, Shaoting Zhang, Guotai Wang</strong></p>
<p>Pathology image classification plays a crucial role in accurate medical diagnosis and treatment planning. Training high-performance models for this task typically requires large-scale annotated datasets, which are both expensive and time-consuming to acquire. Active Learning (AL) offers a solution by iteratively selecting the most informative samples for annotation, thereby reducing the labeling effort. However, most AL methods are designed under the assumption of a closed-set scenario, where all the unannotated images belong to target classes. In real-world clinical environments, the unlabeled pool often contains a substantial amount of Out-Of-Distribution (OOD) data, leading to low efficiency of annotation in traditional AL methods. Furthermore, most existing AL methods start with random selection in the first query round, leading to a significant waste of labeling costs in open-set scenarios. To address these challenges, we propose OpenPath, a novel open-set active learning approach for pathological image classification leveraging a pre-trained Vision-Language Model (VLM). In the first query, we propose task-specific prompts that combine target and relevant non-target class prompts to effectively select In-Distribution (ID) and informative samples from the unlabeled pool. In subsequent queries, Diverse Informative ID Sampling (DIS) that includes Prototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic Sampling (EGSS) is proposed to ensure both purity and informativeness in a query, avoiding the selection of OOD samples. Experiments on two public pathology image datasets show that OpenPath significantly enhances the modelâ€™s performance due to its high purity of selected samples, and outperforms several state-of-the-art open-set AL methods. The code is available at \href{<a target="_blank" rel="noopener" href="https://github.com/HiLab-git/OpenPath%7D%7Bhttps://github.com/HiLab-git/OpenPath%7D">https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}</a>.. </p>
<blockquote>
<p>ç—…ç†å­¦å›¾åƒåˆ†ç±»åœ¨å‡†ç¡®çš„åŒ»å­¦è¯Šæ–­å’Œæ²»ç–—è®¡åˆ’ä¸­å‘æŒ¥è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ä¸ºæ­¤ä»»åŠ¡è®­ç»ƒé«˜æ€§èƒ½æ¨¡å‹é€šå¸¸éœ€è¦å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†ï¼Œè¿™äº›æ•°æ®çš„è·å–æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚ä¸»åŠ¨å­¦ä¹ ï¼ˆALï¼‰é€šè¿‡è¿­ä»£é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼Œä»è€Œå‡å°‘äº†æ ‡æ³¨å·¥ä½œé‡ï¼Œä¸ºæ­¤æä¾›äº†è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ALæ–¹æ³•çš„è®¾è®¡æ˜¯åŸºäºå°é—­é›†åœºæ™¯çš„å‡è®¾ï¼Œå³æ‰€æœ‰æœªæ ‡æ³¨çš„å›¾åƒéƒ½å±äºç›®æ ‡ç±»åˆ«ã€‚åœ¨ç°å®ä¸–ç•Œä¸­çš„ä¸´åºŠç¯å¢ƒä¸­ï¼Œæœªæ ‡æ³¨æ± ä¸­ç»å¸¸åŒ…å«å¤§é‡æ¥è‡ªåŸŸå¤–çš„æ•°æ®ï¼ˆOODï¼‰ï¼Œè¿™å¯¼è‡´ä¼ ç»ŸALæ–¹æ³•çš„æ ‡æ³¨æ•ˆç‡é™ä½ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°ç°æœ‰çš„ALæ–¹æ³•åœ¨ç¬¬ä¸€æ¬¡æŸ¥è¯¢è½®æ¬¡ä¸­éšæœºé€‰æ‹©æ ·æœ¬ï¼Œåœ¨å¼€æ”¾å¼åœºæ™¯ä¸­å¯¼è‡´æ ‡æ³¨æˆæœ¬çš„å¤§é‡æµªè´¹ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†OpenPathï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œç—…ç†å­¦å›¾åƒåˆ†ç±»çš„æ–°å‹å¼€æ”¾å¼ä¸»åŠ¨å­¦ä¹ ã€‚åœ¨ç¬¬ä¸€æ¬¡æŸ¥è¯¢ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä»»åŠ¡ç‰¹å®šçš„æç¤ºï¼Œè¿™äº›æç¤ºç»“åˆäº†ç›®æ ‡å’Œç›¸å…³çš„éç›®æ ‡ç±»åˆ«æç¤ºï¼Œä»¥æœ‰æ•ˆåœ°ä»æœªæ ‡æ³¨æ± ä¸­é€‰æ‹©æ¥è‡ªåŸŸå†…ï¼ˆIDï¼‰å’Œå…·æœ‰ä¿¡æ¯é‡çš„æ ·æœ¬ã€‚åœ¨éšåçš„æŸ¥è¯¢ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ ·åŒ–çš„ä¿¡æ¯IDé‡‡æ ·ï¼ˆDISï¼‰ï¼Œå…¶ä¸­åŒ…æ‹¬åŸºäºåŸå‹çš„IDå€™é€‰æ ·æœ¬é€‰æ‹©ï¼ˆPISï¼‰å’ŒåŸºäºç†µå¼•å¯¼çš„éšæœºé‡‡æ ·ï¼ˆEGSSï¼‰ï¼Œä»¥ç¡®ä¿æŸ¥è¯¢ä¸­çš„çº¯å‡€åº¦å’Œä¿¡æ¯é‡ï¼Œé¿å…é€‰æ‹©åŸŸå¤–æ ·æœ¬ã€‚åœ¨ä¸¤ä¸ªå…¬å…±ç—…ç†å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç”±äºæ‰€é€‰æ ·æœ¬çš„é«˜çº¯å‡€åº¦ï¼ŒOpenPathæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¼˜äºå‡ ç§å…ˆè¿›çš„å¼€æ”¾å¼ALæ–¹æ³•ã€‚ä»£ç å¯é€šè¿‡é“¾æ¥<a target="_blank" rel="noopener" href="https://github.com/HiLab-git/OpenPath%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/HiLab-git/OpenPathè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.15318v2">PDF</a> MICCAI 2025 early accept</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§å¼€æ”¾é›†ä¸‹çš„ç—…ç†å­¦å›¾åƒåˆ†ç±»ä¸»åŠ¨å­¦ä¹ æ–¹æ³•ï¼Œåä¸ºOpenPathã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šæç¤ºå’Œå¤šæ ·ä¿¡æ¯é‡‡æ ·ç­–ç•¥ï¼Œæœ‰æ•ˆé€‰æ‹©æ ·æœ¬å¹¶é¿å…é€‰æ‹©å‡ºåˆ†å¸ƒå¤–çš„æ ·æœ¬ã€‚å®éªŒè¯æ˜ï¼ŒOpenPathåœ¨å…¬å¼€ç—…ç†å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºå…¶ä»–ä¸»æµå¼€æ”¾é›†ä¸»åŠ¨å­¦ä¹ æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç—…ç†å­¦å›¾åƒåˆ†ç±»åœ¨åŒ»ç–—è¯Šæ–­å’Œæ²»ç–—è®¡åˆ’ä¸­è‡³å…³é‡è¦ï¼Œéœ€è¦å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†æ¥è®­ç»ƒé«˜æ€§èƒ½æ¨¡å‹ï¼Œä½†æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚</li>
<li>ä¸»åŠ¨å­¦ä¹ æ–¹æ³•å¯é€šè¿‡é€‰æ‹©ä¿¡æ¯é‡æœ€å¤§çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼Œé™ä½æ ‡æ³¨æˆæœ¬ã€‚</li>
<li>ç°æœ‰ä¸»åŠ¨å­¦ä¹ æ–¹æ³•å¤šåœ¨å°é—­é›†åœºæ™¯ä¸‹è®¾è®¡ï¼Œéš¾ä»¥å¤„ç†çœŸå®ä¸–ç•Œä¸­çš„å¼€æ”¾é›†åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯åŒ…å«å¤§é‡éç›®æ ‡åˆ†å¸ƒçš„æ•°æ®ã€‚</li>
<li>OpenPathæ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šæç¤ºå’Œå¤šæ ·ä¿¡æ¯é‡‡æ ·ç­–ç•¥æ¥é€‰æ‹©æ ·æœ¬ï¼Œç¡®ä¿é€‰æ‹©çš„æ ·æœ¬æ—¢æœ‰ä»£è¡¨æ€§åˆä¿¡æ¯é‡ä¸°å¯Œã€‚</li>
<li>OpenPathæ–¹æ³•åœ¨å…¬å…±ç—…ç†å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜å¼‚ï¼Œé€‰æ ·çº¯åº¦è¾ƒé«˜ã€‚</li>
<li>OpenPathä»£ç å·²å…¬å¼€ï¼Œä¾¿äºå…¶ä»–ç ”ç©¶è€…ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.15318">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3dc0689e2c8a8614ba3b6acfc2bba7f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b047c3148cb95a814d4cf9bf03b12f31.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BreastDCEDL-Curating-a-Comprehensive-DCE-MRI-Dataset-and-developing-a-Transformer-Implementation-for-Breast-Cancer-Treatment-Response-Prediction"><a href="#BreastDCEDL-Curating-a-Comprehensive-DCE-MRI-Dataset-and-developing-a-Transformer-Implementation-for-Breast-Cancer-Treatment-Response-Prediction" class="headerlink" title="BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a   Transformer Implementation for Breast Cancer Treatment Response Prediction"></a>BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a   Transformer Implementation for Breast Cancer Treatment Response Prediction</h2><p><strong>Authors:Naomi Fridman, Bubby Solway, Tomer Fridman, Itamar Barnea, Anat Goldstein</strong></p>
<p>Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+&#x2F;HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging. </p>
<blockquote>
<p>ä¹³è…ºç™Œä»ç„¶æ˜¯å…¨çƒç™Œç—‡ç›¸å…³æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œå› æ­¤æ—©æœŸæ£€æµ‹å’Œç²¾ç¡®çš„æ²»ç–—ååº”ç›‘æµ‹æˆä¸ºè‡³å…³é‡è¦çš„ä¼˜å…ˆäº‹é¡¹ã€‚æˆ‘ä»¬æ¨å‡ºäº†BreastDCEDLï¼Œè¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„ã€å‡†å¤‡å¥½ç”¨äºæ·±åº¦å­¦ä¹ æ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªI-SPY1ã€I-SPY2å’ŒDukeé˜Ÿåˆ—çš„2070ä¾‹ä¹³è…ºç™Œæ‚£è€…çš„æ²»ç–—å‰3DåŠ¨æ€å¢å¼ºMRIï¼ˆDCE-MRIï¼‰æ‰«æï¼Œæ‰€æœ‰æ•°æ®æºå‡æ¥è‡ªç™Œç—‡æˆåƒæ¡£æ¡ˆã€‚åŸå§‹çš„DICOMæˆåƒæ•°æ®è¢«ä¸¥æ ¼è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„3DNIfTIä½“ç§¯æ•°æ®ï¼ŒåŒæ—¶ä¿ç•™äº†ä¿¡å·å®Œæ•´æ€§ï¼Œå¹¶é™„æœ‰ç»Ÿä¸€çš„è‚¿ç˜¤æ³¨é‡Šå’Œåè°ƒçš„ä¸´åºŠå…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ç—…ç†å®Œå…¨ååº”ï¼ˆpCRï¼‰ã€æ¿€ç´ å—ä½“ï¼ˆHRï¼‰å’ŒHER2çŠ¶æ€ã€‚å°½ç®¡DCE-MRIæä¾›äº†é‡è¦çš„è¯Šæ–­ä¿¡æ¯ï¼Œæ·±åº¦å­¦ä¹ åœ¨åˆ†ææ­¤ç±»å¤æ‚æ•°æ®æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†ç”±äºç¼ºä¹å¯è®¿é—®çš„ã€å…¬å¼€çš„ã€å¤šä¸­å¿ƒæ•°æ®é›†ï¼Œè¿›å±•ä¸€ç›´å—åˆ°é™åˆ¶ã€‚BreastDCEDLé€šè¿‡æ”¯æŒå¼€å‘å…ˆè¿›æ¨¡å‹æ¥è§£å†³è¿™ä¸€å·®è·ï¼ŒåŒ…æ‹¬éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®çš„æœ€æ–°å˜å‹å™¨æ¶æ„ã€‚ä¸ºäº†å±•ç¤ºå…¶ç¨³å¥å»ºæ¨¡çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼€å‘äº†åŸºäºå˜å‹å™¨çš„é¦–ä¸ªä¹³è…ºç™ŒDCE-MRIæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨åœ¨ä¸‰ä¸ªå¯¹æ¯”é˜¶æ®µï¼ˆé¢„å¯¹æ¯”ã€æ—©æœŸå¯¹æ¯”åå’Œæ™šæœŸå¯¹æ¯”åï¼‰çš„RGBèåˆå›¾åƒä¸Šè®­ç»ƒçš„Vision Transformerï¼ˆViTï¼‰æ¶æ„ã€‚æˆ‘ä»¬çš„ViTæ¨¡å‹åœ¨HR+&#x2F;HER2-æ‚£è€…ä¸­å®ç°äº†æœ€å…ˆè¿›çš„pCRé¢„æµ‹æ€§èƒ½ï¼ˆAUC 0.94ï¼Œå‡†ç¡®ç‡0.93ï¼‰ã€‚BreastDCEDLåŒ…æ‹¬é¢„å®šä¹‰çš„åŸºå‡†æµ‹è¯•åˆ†å‰²ï¼Œä¸ºå¯é‡å¤çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œå¹¶åœ¨ä¹³è…ºç™Œæˆåƒä¸­å®ç°äº†å…·æœ‰ä¸´åºŠæ„ä¹‰çš„å»ºæ¨¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.12190v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>ä¹³è…ºç™Œä»æ˜¯å…¨çƒç™Œç—‡æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œæ—©æœŸæ£€æµ‹å’Œç²¾ç¡®çš„æ²»ç–—ååº”ç›‘æµ‹æ˜¯å…³é”®ã€‚æˆ‘ä»¬æ¨å‡ºBreastDCEDLï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡æ·±åº¦å­¦ä¹ çš„æ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªI-SPY1ã€I-SPY2å’ŒDukeç­‰é˜Ÿä¼çš„2,070ä¾‹ä¹³è…ºç™Œæ‚£è€…çš„é¢„æ²»ç–—ä¸‰ç»´åŠ¨æ€å¢å¼ºMRIæ‰«ææ•°æ®ã€‚åŸå§‹DICOMå›¾åƒæ•°æ®è¢«ä¸¥æ ¼è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„ä¸‰ç»´NIfTIä½“ç§¯ï¼Œä¿ç•™äº†ä¿¡å·å®Œæ•´æ€§ï¼Œå¹¶é…æœ‰ç»Ÿä¸€çš„è‚¿ç˜¤æ³¨é‡Šå’Œåè°ƒçš„ä¸´åºŠå…ƒæ•°æ®ã€‚è™½ç„¶DCE-MRIæä¾›äº†é‡è¦çš„è¯Šæ–­ä¿¡æ¯ï¼Œæ·±åº¦å­¦ä¹ åœ¨åˆ†æè¿™äº›æ•°æ®æ–¹é¢æ½œåŠ›å·¨å¤§ï¼Œä½†ç”±äºç¼ºä¹å…¬å¼€çš„å¤šä¸­å¿ƒæ•°æ®é›†ï¼Œè¿›å±•ä¸€ç›´å—åˆ°é™åˆ¶ã€‚BreastDCEDLé€šè¿‡æ”¯æŒå…ˆè¿›æ¨¡å‹çš„å‘å±•è§£å†³äº†è¿™ä¸€å·®è·ï¼ŒåŒ…æ‹¬éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®çš„æœ€æ–°å˜å‹å™¨æ¶æ„ã€‚ä¸ºäº†å±•ç¤ºå…¶åœ¨ç¨³å¥å»ºæ¨¡æ–¹é¢çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼€å‘äº†åŸºäºVision Transformerï¼ˆViTï¼‰çš„é¦–ä¸ªä¹³è…ºç™ŒDCE-MRIæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨RGBèåˆå›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ¥è‡ªä¸‰ä¸ªå¯¹æ¯”é˜¶æ®µï¼ˆé¢„å¯¹æ¯”ã€æ—©æœŸåå¯¹æ¯”å’Œæ™šæœŸåå¯¹æ¯”ï¼‰ã€‚æˆ‘ä»¬çš„ViTæ¨¡å‹åœ¨HR+&#x2F;HER2-æ‚£è€…ä¸­å®ç°äº†æœ€å…ˆè¿›çš„pCRé¢„æµ‹æ€§èƒ½ï¼ˆAUC 0.94ï¼Œå‡†ç¡®ç‡0.93ï¼‰ã€‚BreastDCEDLåŒ…æ‹¬é¢„è®¾çš„åŸºå‡†åˆ†å‰²ï¼Œä¸ºå¯é‡å¤çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œå¹¶èƒ½å®ç°ä¹³è…ºç™Œæˆåƒçš„ä¸´åºŠæ„ä¹‰å»ºæ¨¡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>ä¹³è…ºç™Œä»æ˜¯å…¨çƒå…³æ³¨çš„ç™Œç—‡è‡´æ­»åŸå› ï¼Œæ—©æœŸæ£€æµ‹å’Œç²¾å‡†æ²»ç–—ååº”ç›‘æµ‹è‡³å…³é‡è¦ã€‚</li>
<li>BreastDCEDLæ˜¯ä¸€ä¸ªç»è¿‡æ·±åº¦å­¦ä¹ çš„æ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªå¤šä¸ªæ¥æºçš„ä¹³è…ºç™Œæ‚£è€…çš„é¢„æ²»ç–—ä¸‰ç»´åŠ¨æ€å¢å¼ºMRIæ‰«ææ•°æ®ã€‚</li>
<li>æ•°æ®é›†è§£å†³äº†ç¼ºä¹å…¬å¼€å¤šä¸­å¿ƒæ•°æ®é›†çš„éš¾é¢˜ï¼Œæ”¯æŒå…ˆè¿›æ¨¡å‹çš„å‘å±•ã€‚</li>
<li>åŸºäºVision Transformerï¼ˆViTï¼‰çš„æ¨¡å‹åœ¨RGBèåˆå›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨HR+&#x2F;HER2-æ‚£è€…ä¸­å®ç°ä¼˜è¶Šçš„pCRé¢„æµ‹æ€§èƒ½ã€‚</li>
<li>BreastDCEDLåŒ…å«é¢„è®¾çš„åŸºå‡†åˆ†å‰²ï¼Œä¸ºç ”ç©¶è€…æä¾›å¯é‡å¤çš„ç ”ç©¶æ¡†æ¶ã€‚</li>
<li>æ•°æ®é›†å¯å®ç°ä¹³è…ºç™Œæˆåƒçš„ä¸´åºŠæ„ä¹‰å»ºæ¨¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.12190">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3835c0516c0ba853d6f3b0d1fb0d1ba1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-100bd057869bb8cf967db06d3455a640.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a9f0ec1c0db9c5ca2eebe0ec3ac097f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b64260b9af43fcc9c67030971d20f4c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-24/Vision%20Transformer/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-24/Vision%20Transformer/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Vision-Transformer/">
                                    <span class="chip bg-color">Vision Transformer</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-24/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b123c5f34ab534380c2633e21c7da5cd.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-24  ADAM-Dehaze Adaptive Density-Aware Multi-Stage Dehazing for Improved   Object Detection in Foggy Conditions
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-24/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2f5922d7ace749899b09a181dc11cbfd.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-24  Seeing is Fixing Cross-Modal Reasoning with Multimodal LLMs for Visual   Software Issue Fixing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28172.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
