<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-06-24  RAGentA Multi-Agent Retrieval-Augmented Generation for Attributed   Question Answering">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-9f35788449f25c3ac391d6d19c4e11b0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    44 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-06-24-更新"><a href="#2025-06-24-更新" class="headerlink" title="2025-06-24 更新"></a>2025-06-24 更新</h1><h2 id="RAGentA-Multi-Agent-Retrieval-Augmented-Generation-for-Attributed-Question-Answering"><a href="#RAGentA-Multi-Agent-Retrieval-Augmented-Generation-for-Attributed-Question-Answering" class="headerlink" title="RAGentA: Multi-Agent Retrieval-Augmented Generation for Attributed   Question Answering"></a>RAGentA: Multi-Agent Retrieval-Augmented Generation for Attributed   Question Answering</h2><p><strong>Authors:Ines Besrour, Jingbo He, Tobias Schreieder, Michael Färber</strong></p>
<p>We present RAGentA, a multi-agent retrieval-augmented generation (RAG) framework for attributed question answering (QA). With the goal of trustworthy answer generation, RAGentA focuses on optimizing answer correctness, defined by coverage and relevance to the question and faithfulness, which measures the extent to which answers are grounded in retrieved documents. RAGentA uses a multi-agent architecture that iteratively filters retrieved documents, generates attributed answers with in-line citations, and verifies completeness through dynamic refinement. Central to the framework is a hybrid retrieval strategy that combines sparse and dense methods, improving Recall@20 by 12.5% compared to the best single retrieval model, resulting in more correct and well-supported answers. Evaluated on a synthetic QA dataset derived from the FineWeb index, RAGentA outperforms standard RAG baselines, achieving gains of 1.09% in correctness and 10.72% in faithfulness. These results demonstrate the effectiveness of the multi-agent architecture and hybrid retrieval in advancing trustworthy QA. </p>
<blockquote>
<p>我们提出了RAGentA，这是一个用于属性问答（QA）的多代理检索增强生成（RAG）框架。RAGentA以生成可信答案为目标，专注于优化答案的正确性，这由答案对问题的覆盖率和相关性以及忠实度来定义，忠实度衡量答案在检索文档中的扎实程度。RAGentA采用多代理架构，该架构可迭代地过滤检索到的文档，生成带有内联引用的属性答案，并通过动态细化验证完整性。该框架的核心是混合检索策略，它结合了稀疏和密集方法，与最佳单一检索模型相比，Recall@20提高了12.5%，从而得到更多正确且扎实的答案。在来自FineWeb索引的合成问答数据集上进行的评估表明，RAGentA在标准RAG基线之上表现出色，在正确性和忠实度上分别提高了1.09%和提高了10.72%。这些结果证明了多代理架构和混合检索在提高可信问答方面的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16988v1">PDF</a> Accepted at SIGIR 2025</p>
<p><strong>Summary</strong><br>RAGentA是一个多智能体检索增强生成框架，旨在实现可靠的答案生成。它优化了答案的正确性，涵盖对问题的覆盖率和相关性以及忠实度，衡量答案是否基于检索到的文档。该框架采用多智能体架构，通过迭代过滤检索到的文档，生成具有内联引用的属性答案，并通过动态优化验证完整性。其核心是结合了稀疏和密集方法的混合检索策略，提高了Recall@20的召回率，并在合成QA数据集上取得了优异表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RAGentA是一个多智能体检索增强生成框架，用于属性问答。</li>
<li>它追求可靠答案生成，优化答案的正确性、覆盖率和与问题的相关性以及忠实度。</li>
<li>框架采用多智能体架构，通过迭代过程过滤文档、生成属性答案并验证完整性。</li>
<li>核心是混合检索策略，结合了稀疏和密集方法，提高了Recall@20的召回率。</li>
<li>与单一最佳检索模型相比，RAGentA提高了Recall@20的准确率12.5%。</li>
<li>在合成QA数据集上，RAGentA表现出色，在正确性和忠实度方面分别实现了1.09%和10.72%的提升。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16988">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-59d8667f94c5c6f30b8511feb9b9fd03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94ed550b6168e982749e123721df8685.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fe63ca26e2005af1673e7275b260ad15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0860671dfb54d0a84e753c87c1da511.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42b55652854c1104535452f43add93bf.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Language-Informed-Synthesis-of-Rational-Agent-Models-for-Grounded-Theory-of-Mind-Reasoning-On-The-Fly"><a href="#Language-Informed-Synthesis-of-Rational-Agent-Models-for-Grounded-Theory-of-Mind-Reasoning-On-The-Fly" class="headerlink" title="Language-Informed Synthesis of Rational Agent Models for Grounded   Theory-of-Mind Reasoning On-The-Fly"></a>Language-Informed Synthesis of Rational Agent Models for Grounded   Theory-of-Mind Reasoning On-The-Fly</h2><p><strong>Authors:Lance Ying, Ryan Truong, Katherine M. Collins, Cedegao E. Zhang, Megan Wei, Tyler Brooke-Wilson, Tan Zhi-Xuan, Lionel Wong, Joshua B. Tenenbaum</strong></p>
<p>Drawing real world social inferences usually requires taking into account information from multiple modalities. Language is a particularly powerful source of information in social settings, especially in novel situations where language can provide both abstract information about the environment dynamics and concrete specifics about an agent that cannot be easily visually observed. In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a framework for drawing context-specific social inferences that integrate linguistic and visual inputs. LIRAS frames multimodal social reasoning as a process of constructing structured but situation-specific agent and environment representations - leveraging multimodal language models to parse language and visual inputs into unified symbolic representations, over which a Bayesian inverse planning engine can be run to produce granular probabilistic judgments. On a range of existing and new social reasoning tasks derived from cognitive science experiments, we find that our model (instantiated with a comparatively lightweight VLM) outperforms ablations and state-of-the-art models in capturing human judgments across all domains. </p>
<blockquote>
<p>在真实世界中，进行社会推理通常需要综合考虑来自多种模态的信息。在社交环境中，语言是一种特别强大的信息来源，特别是在新情境中，语言可以提供关于环境动态抽象信息和关于个体具体信息，这些信息无法仅通过视觉轻易观察到。在本文中，我们提出了“语言信息理性代理合成”（LIRAS）框架，这是一个结合语言和视觉输入进行特定上下文社会推理的框架。LIRAS将多模态社会推理视为一个过程，构建结构化但特定情境下的代理和环境表示——利用多模态语言模型解析语言和视觉输入到统一的符号表示，在此基础上运行贝叶斯逆规划引擎以产生精细的概率判断。在来自认知科学实验的现有和新社会推理任务上，我们发现我们的模型（使用相对轻量级的VLM实例化）在所有领域中都优于剥离模型和最新的模型在人类判断捕捉上的表现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16755v1">PDF</a> 5 figures, 19 pages</p>
<p><strong>Summary</strong></p>
<p>本文提出了一个结合语言和视觉输入的框架——语言信息理性代理合成（LIRAS），用于进行语境特定的社会推理。LIRAS将多模态社会推理视为构建结构化但情境特定的代理和环境表示的过程，利用多模态语言模型解析语言和视觉输入为统一的符号表示，在此基础上运行贝叶斯逆向规划引擎，以产生精细的概率判断。在来自认知科学实验的一系列现有和新的社会推理任务上，我们的模型（用相对轻量级的VLM实例化）在捕捉人类判断方面优于消融模型和当前最先进模型。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>社交推理需要综合考虑多种模式的信息。</li>
<li>语言是社交环境中特别有力的信息来源，尤其在新型情境中，语言能提供关于环境动态抽象信息和难以通过观察得到的代理具体信息。</li>
<li>提出了一种结合语言和视觉输入的框架LIRAS，用于进行语境特定的社会推理。</li>
<li>LIRAS将多模态社会推理视为构建结构化情境特定代理和环境表示的过程。</li>
<li>多模态语言模型能够解析语言和视觉输入为统一的符号表示。<br>*LIRAS利用贝叶斯逆向规划引擎产生精细的概率判断。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16755">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8f60dffdf7c2f7553a56b6d4801abf7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91f619e893807cfbb01d3a5d56410838.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-26cdd1e9f2ecff3174a4a7aa5b03868a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Generalizable-Agent-Modeling-for-Agent-Collaboration-Competition-Adaptation-with-Multi-Retrieval-and-Dynamic-Generation"><a href="#Generalizable-Agent-Modeling-for-Agent-Collaboration-Competition-Adaptation-with-Multi-Retrieval-and-Dynamic-Generation" class="headerlink" title="Generalizable Agent Modeling for Agent Collaboration-Competition   Adaptation with Multi-Retrieval and Dynamic Generation"></a>Generalizable Agent Modeling for Agent Collaboration-Competition   Adaptation with Multi-Retrieval and Dynamic Generation</h2><p><strong>Authors:Chenxu Wang, Yonggang Jin, Cheng Hu, Youpeng Zhao, Zipeng Dai, Jian Zhao, Shiyu Huang, Liuyu Xiang, Junge Zhang, Zhaofeng He</strong></p>
<p>Adapting a single agent to a new multi-agent system brings challenges, necessitating adjustments across various tasks, environments, and interactions with unknown teammates and opponents. Addressing this challenge is highly complex, and researchers have proposed two simplified scenarios, Multi-agent reinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on these foundations, we propose a more comprehensive setting, Agent Collaborative-Competitive Adaptation (ACCA), which evaluates an agent to generalize across diverse scenarios, tasks, and interactions with both unfamiliar opponents and teammates. In ACCA, agents adjust to task and environmental changes, collaborate with unseen teammates, and compete against unknown opponents. We introduce a new modeling approach, Multi-Retrieval and Dynamic Generation (MRDG), that effectively models both teammates and opponents using their behavioral trajectories. This method incorporates a positional encoder for varying team sizes and a hypernetwork module to boost agents’ learning and adaptive capabilities. Additionally, a viewpoint alignment module harmonizes the observational perspectives of retrieved teammates and opponents with the learning agent. Extensive tests in benchmark scenarios like SMAC, Overcooked-AI, and Melting Pot show that MRDG significantly improves robust collaboration and competition with unseen teammates and opponents, surpassing established baselines. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/vcis-wangchenxu/MRDG.git">https://github.com/vcis-wangchenxu/MRDG.git</a> </p>
<blockquote>
<p>适应新的多智能体系统对单一智能体而言带来了挑战，需要在各种任务、环境和与未知队友和对手的互动中进行调整。应对这一挑战是非常复杂的，研究者已经提出了两种简化场景，即用于零学习学习的多智能体强化学习和即兴团队工作。在此基础上，我们提出了一个更全面的环境——智能体协作竞争适应（ACCA），用于评估智能体在不同场景、任务和与陌生对手和队友的互动中的泛化能力。在ACCA中，智能体能适应任务和环境的改变，与看不见的队友协作，并与未知对手竞争。我们引入了一种新的建模方法——多检索和动态生成（MRDG），该方法能有效地利用队友和对手的行为轨迹进行建模。该方法采用位置编码器来处理不同团队规模，并引入超网络模块来提升智能体的学习和适应能力。此外，视角对齐模块能协调检索到的队友和对手与学习智能体的观察视角。在像SMAC、Overcooked-AI和Melting Pot等基准场景的大量测试表明，MRDG在与未见过的队友和对手进行协作和竞争时，显著提高了稳健性，超越了现有的基线。我们的代码可在此处找到：<a target="_blank" rel="noopener" href="https://github.com/vcis-wangchenxu/MRDG.git">https://github.com/vcis-wangchenxu/MRDG.git</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16718v1">PDF</a> This manuscript is under submission to Neurocomputing</p>
<p><strong>Summary</strong><br>适应单代理到多代理系统面临诸多挑战，需在不同任务、环境和与未知队友对手互动中进行调整。研究者提出两种简化情境：多代理强化学习零学习法和即兴合作。在此基础上，我们提出更全面的设置——代理协作竞争适应（ACCA），评估代理在不同场景、任务和互动中的泛化能力，与陌生队友和对手协作竞争。我们引入新的建模方法——多检索和动态生成（MRDG），利用行为轨迹有效模拟队友和对手。此方法包含位置编码器和超网络模块，提高代理学习和适应能力。观点对齐模块协调学习代理与检索队友对手的观察角度。在SMAC、Overcooked-AI和Melting Pot等基准测试场景中，MRDG显著提高与未见队友对手的稳健协作和竞争能力，超越现有基线。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>适应单代理到多代理系统需要应对跨任务、环境和与未知队友对手互动的挑战。</li>
<li>提出Agent Collaborative-Competitive Adaptation (ACCA)设置，评估代理在多样场景、任务和互动中的泛化能力。</li>
<li>引入Multi-Retrieval and Dynamic Generation (MRDG)建模方法，利用行为轨迹模拟队友和对手。</li>
<li>MRDG包含位置编码器、超网络模块和观点对齐模块。</li>
<li>位置编码器适应不同团队大小，超网络模块提升代理学习和适应能力。</li>
<li>观点对齐模块协调学习代理与检索队友对手的观察角度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16718">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4962c902684793522799dba4f0e1179f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fa03d0830a0e9a2be2a710718cd1d10b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b9889dbef85ae2977b4ccd3469cc0a8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Mean-field-and-Monte-Carlo-Analysis-of-Multi-Species-Dynamics-of-agents"><a href="#Mean-field-and-Monte-Carlo-Analysis-of-Multi-Species-Dynamics-of-agents" class="headerlink" title="Mean-field and Monte Carlo Analysis of Multi-Species Dynamics of agents"></a>Mean-field and Monte Carlo Analysis of Multi-Species Dynamics of agents</h2><p><strong>Authors:Eduardo Velasco Stock, Roberto da Silva, Sebastian Gonçalves</strong></p>
<p>We propose a mean-field (MF) approximation for the recurrence relation governing the dynamics of $m$ species of particles on a square lattice, and we simultaneously perform Monte Carlo (MC) simulations under identical initial conditions to emulate the intricate motion observed in environments such as subway corridors and scramble crossings in large cities. Each species moves according to transition probabilities influenced by its respective static floor field and the state of neighboring cells. To illustrate the methodology, we analyze statistical fluctuations in the spatial distribution for $m &#x3D; 1$, $m &#x3D; 2$, and $m &#x3D; 4$ and for different regimes of average density and biased movement. A numerical comparison is conducted to determine the best agreement between the MC simulations and the MF approximation considering a renormalization exponent $\beta$ that optimizes the fit between methods. Finally, we report a phenomenon we term “Gaussian-to-Gaussian” behavior, in which an initially normal distribution of particles becomes distorted due to interactions among same and opposing species, passes through a transient regime, and eventually returns to a Gaussian-like profile in the steady state, after multiple rounds of motion under periodic boundary conditions. </p>
<blockquote>
<p>对于方格晶格上m种粒子的动力学所遵循的递推关系，我们提出了一种平均场近似方法。同时，在相同的初始条件下进行蒙特卡洛模拟，以模拟在大城市的地铁走廊和十字路口等环境中观察到的复杂运动。每种粒子根据其各自的静态场和相邻单元的状态所影响的转移概率进行移动。为了说明方法，我们分析了m&#x3D;1、m&#x3D;2和m&#x3D;4时统计波动在不同平均密度和偏向运动状态下的空间分布。通过数值比较，确定了蒙特卡洛模拟与平均场近似之间的最佳一致性，考虑到了优化两种方法拟合度的重归一化指数β。最后，我们报告了一种称为“高斯到高斯”的现象，即由于相同和相对物种之间的相互作用，最初的正态粒子分布会发生扭曲，经过一个短暂状态，最终进入稳态后在周期性边界条件下经过多次移动后返回类似高斯分布的状态。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16717v1">PDF</a> 20 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>文中提出对$m$种粒子在方格晶格上动态行为的复发关系进行平均场近似（MF），并利用蒙特卡洛（MC）模拟进行仿真，模拟城市中的地铁走廊和拥挤路口等复杂环境下的运动行为。分析各物种在不同平均密度和偏斜运动情况下的空间分布统计波动，并与平均场近似进行对比。结果显示最优的重标准化指数$\beta$下的数值模拟与理论模型相吻合，还出现了一种被称为“高斯到高斯”的现象，即初始正态分布的粒子因物种间的相互作用而发生扭曲，经过短暂状态后最终恢复稳态下的高斯分布。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>利用平均场近似研究多种粒子在方格晶格上的动态行为复发关系。</li>
<li>使用蒙特卡洛模拟进行仿真，以模拟复杂环境下的粒子运动行为。</li>
<li>分析不同物种在不同平均密度和偏斜运动情况下的空间分布统计波动。</li>
<li>发现名为“高斯到高斯”的现象，描述了初始分布的粒子在交互后的分布演变过程。</li>
<li>该现象呈现的是由物种间相互作用引起的粒子分布扭曲，并在短暂状态后恢复稳态下的高斯分布。</li>
<li>通过数值比较，发现蒙特卡洛模拟与平均场近似之间的最佳一致性是通过优化重标准化指数$\beta$实现的。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16717">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-43e93ebf0ad36450d4650bbec2ee014d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ab4f40b94642529a2e47a44c6cc8fdf0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Distribution-Parameter-Actor-Critic-Shifting-the-Agent-Environment-Boundary-for-Diverse-Action-Spaces"><a href="#Distribution-Parameter-Actor-Critic-Shifting-the-Agent-Environment-Boundary-for-Diverse-Action-Spaces" class="headerlink" title="Distribution Parameter Actor-Critic: Shifting the Agent-Environment   Boundary for Diverse Action Spaces"></a>Distribution Parameter Actor-Critic: Shifting the Agent-Environment   Boundary for Diverse Action Spaces</h2><p><strong>Authors:Jiamin He, A. Rupam Mahmood, Martha White</strong></p>
<p>We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces. </p>
<blockquote>
<p>我们引入了一种新型强化学习（RL）框架，该框架将分布参数视为动作，重新定义了智能体与环境之间的界限。这种重新参数化使得新的动作空间具有连续性，无论原始动作类型如何（离散、连续、混合等）。在这种新的参数化下，我们开发了一种通用的确定性策略梯度估计器——分布参数策略梯度（DPPG），其方差低于原始动作空间中的梯度。尽管在分布参数上学习评论家带来了新的挑战，但我们引入了插值评论家学习（ICL）策略，这是一种简单有效的增强学习的方法，受到bandit设置的启发。在TD3这一连续控制的强大基准之上，我们提出了一种基于DPPG的actor-critic算法——分布参数Actor-Critic（DPAC）。经验表明，DPAC在OpenAI Gym和DeepMind Control Suite的MuJoCo连续控制任务上的表现优于TD3，并在具有离散动作空间的相同环境中表现出竞争力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16608v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>引入了一种新型强化学习框架，将分布参数视为动作，重新定义了智能体与环境之间的界限。这种重新参数化使得新的动作空间具有连续性，无论原始动作类型是离散、连续还是混合等。在此新参数化下，开发了一种广义确定性策略梯度估计器——分布参数策略梯度（DPPG），其方差低于原始动作空间的梯度。尽管在分布参数上学习批判者带来了新的挑战，但引入了插值批判学习（ICL）这一简单有效的策略来促进学习，该策略得到了多臂赌博机设置的启示。基于TD3（连续控制的强大基线），提出了一种实用的基于DPPG的Actor-Critic算法——分布参数Actor-Critic（DPAC）。经验表明，DPAC在OpenAI Gym和DeepMind Control Suite的MuJoCo连续控制任务上优于TD3，并在具有离散动作空间的环境中表现出竞争力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>新型强化学习框架将分布参数视为动作，实现智能体与环境界限的重定义。</li>
<li>分布参数化使得动作空间具有连续性，适应各种原始动作类型。</li>
<li>提出广义确定性策略梯度估计器——分布参数策略梯度（DPPG），降低梯度方差。</li>
<li>插值批判学习（ICL）作为简单有效的学习策略，用于应对分布参数学习中的挑战。</li>
<li>基于TD3的DPAC算法在连续控制任务上表现优越，特别是在MuJoCo环境中的OpenAI Gym和DeepMind Control Suite。</li>
<li>DPAC在具有离散动作空间的环境中展现出竞争力。</li>
<li>该框架为处理不同动作类型的强化学习任务提供了新的视角和方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16608">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-99bfbc3da0e8f829849204789c45551f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-627b66aaecf52bd297af43b12b53ef47.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6adda938b4cff1d5ee6646607aa1f820.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="StoryWriter-A-Multi-Agent-Framework-for-Long-Story-Generation"><a href="#StoryWriter-A-Multi-Agent-Framework-for-Long-Story-Generation" class="headerlink" title="StoryWriter: A Multi-Agent Framework for Long Story Generation"></a>StoryWriter: A Multi-Agent Framework for Long Story Generation</h2><p><strong>Authors:Haotian Xia, Hao Peng, Yunjia Qi, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li</strong></p>
<p>Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation. </p>
<blockquote>
<p>长篇故事生成对于现有的大型语言模型（LLM）来说仍然是一个挑战，这主要是由于两个主要因素：（1）篇章连贯性，它要求情节一致性、逻辑连贯性和长篇生成中的完整性；（2）叙事复杂性，它要求叙事交织且引人入胜。为了解决这些挑战，我们提出了StoryWriter，这是一个多代理故事生成框架，包含三个主要模块：（1）大纲代理，它生成基于事件的大纲，包含丰富的事件情节、角色和事件关系。（2）规划代理，它进一步细化事件，并计划每个章节应编写哪些事件以保持交织且引人入胜的故事。（3）写作代理，它根据当前事件动态压缩故事历史，生成并反映新情节，确保生成的故事连贯性。我们进行了人工和自动评估，StoryWriter在故事质量和长度方面都显著优于现有的故事生成基线。此外，我们使用StoryWriter生成了一个数据集，其中包含大约6000个高质量的长篇故事，平均长度8000字。我们使用LongStory对模型Llama3.1-8B和GLM4-9B进行有监督微调，并开发了StoryWriter_GLM和StoryWriter_GLM，这在长篇故事生成中表现出了先进性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16445v1">PDF</a> </p>
<p><strong>Summary</strong>：针对长篇故事生成面临的挑战，如情节连贯性和叙事复杂性，提出了StoryWriter多代理故事生成框架。该框架包括三个主要模块：提纲代理、规划代理和写作代理。通过人类和自动化评估，StoryWriter在故事质量和长度方面显著优于现有故事生成基线。此外，使用StoryWriter生成了一个包含约6000个高质量长篇故事的数据集，平均长度为8000字。并在此基础上训练了模型Llama3.1-8B和GLM4-9B。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>StoryWriter是一个多代理故事生成框架，旨在解决长篇故事生成中的情节连贯性和叙事复杂性挑战。</li>
<li>StoryWriter包括三个主要模块：提纲代理、规划代理和写作代理，分别负责生成事件提纲、详细规划事件和动态生成故事情节。</li>
<li>通过人类和自动化评估，StoryWriter在故事质量和长度方面优于现有基线。</li>
<li>使用StoryWriter生成了一个包含约6000个高质量长篇故事的数据集，平均长度为8000字。</li>
<li>基于该数据集，训练了模型Llama3.1-8B和GLM4-9B，展现出卓越的长篇故事生成性能。</li>
<li>StoryWriter框架具有潜在的应用价值，可进一步推动长篇故事生成领域的发展。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16445">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-322e2a55c907416035c2f7d1d9adef6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f0975f1c09b237c1e54854360ae21615.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b401249e52e88d30515e7beb8830965.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a7faf94ff21fa3e3106a706bc099fb6.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Embodied-Web-Agents-Bridging-Physical-Digital-Realms-for-Integrated-Agent-Intelligence"><a href="#Embodied-Web-Agents-Bridging-Physical-Digital-Realms-for-Integrated-Agent-Intelligence" class="headerlink" title="Embodied Web Agents: Bridging Physical-Digital Realms for Integrated   Agent Intelligence"></a>Embodied Web Agents: Bridging Physical-Digital Realms for Integrated   Agent Intelligence</h2><p><strong>Authors:Yining Hong, Rui Sun, Bingxuan Li, Xingcheng Yao, Maxine Wu, Alexander Chien, Da Yin, Ying Nian Wu, Zhecan James Wang, Kai-Wei Chang</strong></p>
<p>AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page <a target="_blank" rel="noopener" href="https://embodied-web-agent.github.io/">https://embodied-web-agent.github.io/</a>. </p>
<blockquote>
<p>当前的人工智能代理大多处于独立状态，它们要么在线获取和推理大量的数字信息和知识，要么通过实体感知、规划和行动与物理世界互动，但很少两者兼顾。这种分离限制了它们解决需要融合物理和数字智能的任务的能力，如根据网络菜谱烹饪、使用动态地图数据导航或使用网络知识解读现实世界的地标。我们引入了Embodied Web Agents（嵌入式网络代理），这是一种新型的人工智能代理范式，能够灵活地连接实体和网络规模推理。为了实施这一概念，我们首先开发了Embodied Web Agents任务环境，这是一个统一的模拟平台，紧密集成了现实的3D室内和室外环境与功能网页界面。在此基础上，我们构建并发布了Embodied Web Agents Benchmark（嵌入式网络代理基准测试），涵盖了一系列任务，包括烹饪、导航、购物、旅游和地理位置等，这些任务都需要在物理和数字领域进行协调推理，以系统评估跨域智能。实验结果揭示了最先进的人工智能系统与人类能力之间的显著性能差距，既提出了挑战也提供了机会，在实体认知和网络规模知识访问的交汇处。所有数据集、代码和网站都可在我们的项目页面<a target="_blank" rel="noopener" href="https://embodied-web-agent.github.io/%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://embodied-web-agent.github.io/上公开获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.15677v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>新一代的人工智能（AI）面临着一种困境：要么是在线知识的检索与推理，要么是物理世界的互动，这两者常常处于分离状态。这一现状限制了解决复杂任务的能力，例如通过在线菜谱进行烹饪，借助动态地图数据进行导航，或使用网络知识解读现实地标等。为此，本文提出了“Embodied Web Agents”概念，构建了跨越实体与网络认知的人工智能范例，打造了Embodied Web Agents任务环境平台，并发布了包含多种任务的基准测试。实验结果显示，当前的人工智能系统在跨域智能方面与人类能力存在显著差距。本文提供了关于AI如何跨越实体与网络界限的重要见解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>当前AI在实体和网络互动上存在分离现象。</li>
<li>这种分离限制了AI解决需要整合实体和数字智能的任务的能力。</li>
<li>Embodied Web Agents概念旨在实现实体和网络认知的流畅桥梁。</li>
<li>构建并发布了Embodied Web Agents任务环境平台和基准测试。</li>
<li>平台包括一个统一的模拟环境，紧密集成真实的室内外环境和功能性网络界面。</li>
<li>测试涵盖多种任务，包括烹饪、导航、购物、旅游等，需要跨实体和数字领域的协同推理。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.15677">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-d3c431addd773c783525b1d443930435.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f51ec387115f7fbefd6c991d1c57b6b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-801483c3d5ad84d1de1f15844cfff48f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa68fbf15297bc02a035f7ed4d0f488a.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="RiOSWorld-Benchmarking-the-Risk-of-Multimodal-Computer-Use-Agents"><a href="#RiOSWorld-Benchmarking-the-Risk-of-Multimodal-Computer-Use-Agents" class="headerlink" title="RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents"></a>RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents</h2><p><strong>Authors:Jingyi Yang, Shuai Shao, Dongrui Liu, Jing Shao</strong></p>
<p>With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce \textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on \textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at <a target="_blank" rel="noopener" href="https://yjyddq.github.io/RiOSWorld.github.io/">https://yjyddq.github.io/RiOSWorld.github.io/</a>. </p>
<blockquote>
<p>随着多模态大型语言模型（MLLMs）的快速发展，它们越来越多地被部署为能够完成复杂计算机任务的自主计算机使用代理。然而，一个紧迫的问题出现了：为对话场景中的通用MLLMs设计和对齐的安全风险原则是否可以有效地转移到现实世界的计算机使用场景？现有关于评估基于MLLM的计算机使用代理的安全风险的研究存在几个局限性：缺乏现实交互环境，或者只关注一种或几种特定的风险类型。这些局限性忽视了现实世界的复杂性、多变性和多样性，从而限制了计算机使用代理的全面风险评估。为此，我们引入了<strong>RiOSWorld</strong>，这是一个旨在评估基于MLLM的代理在现实世界计算机操作中的潜在风险的基准测试。我们的基准测试包括492个涉及各种计算机应用程序的危险任务，包括网页、社交媒体、多媒体、操作系统、电子邮件和办公软件。我们根据风险来源将这些风险分为两大类：（i）用户产生的风险（ii）环境风险。在评估中，我们从两个角度评估安全风险：（i）风险目标意图和（ii）风险目标完成。在<strong>RiOSWorld</strong>上进行的多模式代理的大量实验表明，当前计算机使用代理在现实场景中存在重大安全风险。我们的研究结果强调了现实世界计算机操作中计算机使用代理安全对齐的必要性和紧迫性，为开发可信赖的计算机使用代理提供了宝贵的见解。我们的基准测试在<a target="_blank" rel="noopener" href="https://yjyddq.github.io/RiOSWorld.github.io/%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://yjyddq.github.io/RiOSWorld.github.io/公开可用。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00618v3">PDF</a> 40 pages, 6 figures, Project Page:   <a target="_blank" rel="noopener" href="https://yjyddq.github.io/RiOSWorld.github.io/">https://yjyddq.github.io/RiOSWorld.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了随着多模态大型语言模型（MLLMs）的快速发展，它们被部署为可以完成复杂计算机任务的自主计算机使用代理。然而，对于通用MLLM对话场景中的安全风险评估原则是否能有效地转移到现实世界的计算机使用场景，存在一个问题。针对现有研究在评估基于MLLM的计算机使用代理的安全风险方面的局限性，引入了一个名为RiOSWorld的基准测试平台。该平台旨在评估计算机操控中基于MLLM的代理的潜在风险，并包括了涵盖各种计算机应用的492个危险任务。基于风险来源将风险分为两大类：（i）用户起源的风险和（ii）环境风险。通过两个角度评估安全风险：（i）风险目标意图和（ii）风险目标完成。在RiOSWorld上的实验表明，当前计算机使用代理在现实场景中面临重大安全风险，强调了为计算机使用代理进行安全对齐的必要性和紧迫性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多模态大型语言模型（MLLMs）被用作自主计算机使用代理，能完成复杂任务。</li>
<li>通用MLLM对话场景中的安全风险评估原则在现实世界的计算机使用场景中的转移存在疑问。</li>
<li>现有研究在评估基于MLLM的计算机使用代理的安全风险方面存在局限性，缺乏现实互动环境或仅关注少数特定风险类型。</li>
<li>引入RiOSWorld基准测试平台，涵盖各种计算机应用的492个危险任务，以全面评估基于MLLM的代理的潜在风险。</li>
<li>风险分为两大类：用户起源的风险和环境风险。</li>
<li>从两个角度评估安全风险：风险目标意图和风险目标完成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00618">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9f35788449f25c3ac391d6d19c4e11b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bdc3c0dbb443bc4f56a57c0cb18e983.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1869cb4150e76da402eccda16c69b4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-707268b57fe2c00a1042f893f273ad85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eebc01d2b33689825978702ed56762a7.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Build-Agent-Advocates-Not-Platform-Agents"><a href="#Build-Agent-Advocates-Not-Platform-Agents" class="headerlink" title="Build Agent Advocates, Not Platform Agents"></a>Build Agent Advocates, Not Platform Agents</h2><p><strong>Authors:Sayash Kapoor, Noam Kolt, Seth Lazar</strong></p>
<p>Language model agents are poised to mediate how people navigate and act online. If the companies that already dominate internet search, communication, and commerce – or the firms trying to unseat them – control these agents, the resulting platform agents will likely deepen surveillance, tighten lock-in, and further entrench incumbents. To resist that trajectory, this position paper argues that we should promote agent advocates: user-controlled agents that safeguard individual autonomy and choice. Doing so demands three coordinated moves: broad public access to both compute and capable AI models that are not platform-owned, open interoperability and safety standards, and market regulation that prevents platforms from foreclosing competition. </p>
<blockquote>
<p>语言模型代理正处于为人们提供网络导航和在线行为服务的中介位置。如果已经主导互联网搜索、通信和电子商务的公司，或者试图取代他们的公司，控制了这些代理，那么由此产生的平台代理可能会加深监控，加强锁定，并进一步巩固现有企业的地位。为了抵制这一趋势，本立场论文认为我们应该提倡代理支持者：用户控制的代理，保障个人自主权和选择权。为此需要三个协同动作：广泛公众可以访问的非平台拥有的计算和有能力的人工智能模型，开放的互操作性和安全标准，以及防止平台阻止竞争的市场监管。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04345v2">PDF</a> Accepted to ICML 2025 position paper track</p>
<p><strong>Summary</strong>：语言模型代理将中介人们在线导航和行动的方式。如果主导互联网搜索、通信和商务的公司或试图取代他们的公司控制这些代理，结果可能会加深监视、加剧锁定现状并巩固现有公司的地位。为抵抗这一趋势，本文主张推广代理拥护者，即用户控制的代理，保障个人自主权和选择权。因此，需要三项协同行动：提供非平台拥有的计算和智能模型的大众普遍访问权限、开放互通性和安全标准以及防止平台阻止竞争的市场监管。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>语言模型代理在中介人们在线行为方面扮演重要角色。</li>
<li>控制语言模型代理的公司可能会加深监视、加剧锁定现状并巩固现有市场地位。</li>
<li>为抵抗这一趋势，应推广代理拥护者，保障个人自主权和选择权。</li>
<li>需要提供大众对计算和智能模型的普遍访问权限。</li>
<li>需要开放互通性和安全标准，以确保语言模型代理的良性发展。</li>
<li>市场监管应防止平台阻止竞争，以促进语言模型代理市场的公平竞争。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04345">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b2e3d6749b5768a60ae5cbe8dad76e2a.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="EmoAgent-A-Multi-Agent-Framework-for-Diverse-Affective-Image-Manipulation"><a href="#EmoAgent-A-Multi-Agent-Framework-for-Diverse-Affective-Image-Manipulation" class="headerlink" title="EmoAgent: A Multi-Agent Framework for Diverse Affective Image   Manipulation"></a>EmoAgent: A Multi-Agent Framework for Diverse Affective Image   Manipulation</h2><p><strong>Authors:Qi Mao, Haobo Hu, Yujie He, Difei Gao, Haokun Chen, Libiao Jin</strong></p>
<p>Affective Image Manipulation (AIM) aims to alter visual elements within an image to evoke specific emotional responses from viewers. However, existing AIM approaches rely on rigid \emph{one-to-one} mappings between emotions and visual cues, making them ill-suited for the inherently subjective and diverse ways in which humans perceive and express emotion.To address this, we introduce a novel task setting termed \emph{Diverse AIM (D-AIM)}, aiming to generate multiple visually distinct yet emotionally consistent image edits from a single source image and target emotion. We propose \emph{EmoAgent}, the first multi-agent framework tailored specifically for D-AIM. EmoAgent explicitly decomposes the manipulation process into three specialized phases executed by collaborative agents: a Planning Agent that generates diverse emotional editing strategies, an Editing Agent that precisely executes these strategies, and a Critic Agent that iteratively refines the results to ensure emotional accuracy. This collaborative design empowers EmoAgent to model \emph{one-to-many} emotion-to-visual mappings, enabling semantically diverse and emotionally faithful edits.Extensive quantitative and qualitative evaluations demonstrate that EmoAgent substantially outperforms state-of-the-art approaches in both emotional fidelity and semantic diversity, effectively generating multiple distinct visual edits that convey the same target emotion. </p>
<blockquote>
<p>情感图像操作（AIM）旨在改变图像中的视觉元素，以激发观众特定的情绪反应。然而，现有的AIM方法依赖于情绪与视觉线索之间的僵化“一对一”映射，这使得它们不适合人类感知和表达情绪的固有主观性和多样性。为了解决这一问题，我们引入了一种新型任务设置，称为多样化AIM（D-AIM），旨在从单个源图像和目标情绪生成多个视觉上不同但情感上一致的图片编辑。我们提出了专为D-AIM定制的第一个多代理框架EmoAgent。EmoAgent显式地将操作过程分解为由协作代理执行的三项专门任务：生成多种情感编辑策略的规划代理、精确执行这些策略的编辑代理，以及迭代优化结果以确保情感准确的评价代理。这种协作设计使EmoAgent能够建立“一到多”的情绪到视觉映射，从而实现语义多样、情感真实的编辑。大量的定量和定性评估表明，EmoAgent在情感保真度和语义多样性方面显著优于最新方法，能够生成有效传达同一目标情绪的多张不同视觉图片编辑。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11290v2">PDF</a> </p>
<p><strong>Summary</strong>：<br>情感图像操作（AIM）旨在改变图像的视觉元素以激发观众特定的情感反应。然而，现有的AIM方法依赖于情绪与视觉线索之间的僵化的一一映射，这使得它们不适合人类感知和表达情绪的固有主观性和多样性。为了解决这个问题，我们引入了一个名为多样化AIM（D-AIM）的新任务设置，旨在从单个源图像和目标情绪生成多个视觉上不同但情感上一致的图片编辑。我们提出了针对D-AIM定制的第一个多代理框架EmoAgent。EmoAgent显式地将操作过程分解为三个阶段，由协作代理执行：生成多种情感编辑策略的规划代理、精确执行这些策略的编辑代理，以及确保情感准确性的评论家代理。这种协作设计使EmoAgent能够模拟一对一的情绪到视觉映射，从而实现语义多样且情感真实的编辑。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>Affective Image Manipulation (AIM)旨在通过改变图像的视觉元素来激发特定情感反应。</li>
<li>现有AIM方法依赖于僵化的情绪与视觉线索的一一映射，不适用于人类情感和感知的多样性。</li>
<li>为了解决这一问题，提出了Diverse AIM (D-AIM)任务设置，旨在从单一源图像生成多个情感上一致但视觉上不同的图像编辑。</li>
<li>引入了EmoAgent，一个针对D-AIM的多代理框架，包括规划、编辑和评论家代理，以执行多样化的情感编辑。</li>
<li>EmoAgent通过分解操作过程并引入多个代理来模拟情绪与视觉之间的多种映射，实现语义多样且情感真实的编辑。</li>
<li>定量和定性评估表明，EmoAgent在情感保真和语义多样性方面显著优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11290">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9abc0a04395fc80c08fc3b004715b673.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0dcfe6c68c4bd63568fe0370ad6f3e7b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-937346cf4e042690af52c6bef6aec193.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0b3c860f2e8ad071fd696bbb6d2afd75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc317fac306ae07e2c5edcc5081fd20b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-71c26ec98872f254463789ed2a3136c1.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Infrastructure-for-AI-Agents"><a href="#Infrastructure-for-AI-Agents" class="headerlink" title="Infrastructure for AI Agents"></a>Infrastructure for AI Agents</h2><p><strong>Authors:Alan Chan, Kevin Wei, Sihao Huang, Nitarshan Rajkumar, Elija Perrier, Seth Lazar, Gillian K. Hadfield, Markus Anderljung</strong></p>
<p>AI agents plan and execute interactions in open-ended environments. For example, OpenAI’s Operator can use a web browser to do product comparisons and buy online goods. Much research on making agents useful and safe focuses on directly modifying their behaviour, such as by training them to follow user instructions. Direct behavioural modifications are useful, but do not fully address how heterogeneous agents will interact with each other and other actors. Rather, we will need external protocols and systems to shape such interactions. For instance, agents will need more efficient protocols to communicate with each other and form agreements. Attributing an agent’s actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of \textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents’ interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents. </p>
<blockquote>
<p>人工智能代理在开放环境中进行计划和执行交互。例如，OpenAI的操作员可以使用网页浏览器进行产品比较并在线购买商品。关于如何使代理有用和安全的研究重点是对其行为进行直接修改，例如通过训练它们遵循用户指令。直接的行为修改是有用的，但没有完全解决不同代理之间以及与其他参与者之间的交互问题。因此，我们需要外部协议和系统来塑造这样的交互。例如，代理需要更有效的协议来进行相互通信并形成协议。将代理的行动归因于特定的人类或其他法律实体，有助于建立信任，并抑制滥用行为。鉴于此动机，我们提出了“代理基础设施”的概念：设计用于中介和影响代理与其环境之间相互作用的外部技术系统和共享协议。正如互联网依赖于HTTPS等协议一样，我们的工作认为代理基础设施对于代理生态系统来说同样不可或缺。我们确定了代理基础设施的三个功能：1）将行动、属性和其他信息归因于特定代理、其用户或其他参与者；2）塑造代理之间的交互；3）检测和补救代理的有害行为。我们提供了此类功能的研究方向的不完全目录。对于每个方向，我们包括对用例、基础设施采用、与现有（互联网）基础设施的关系、局限性和开放问题的分析。在代理基础设施方面取得进展可以为更先进的代理的采用做好准备。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10114v3">PDF</a> Accepted to TMLR</p>
<p><strong>Summary</strong><br>     人工智能代理在开放环境中规划和执行交互。例如，OpenAI的操作员可以使用网页进行产品比较并在线购买商品。研究如何使代理有用和安全主要侧重于直接改变其行为，例如通过训练它们遵循用户指令。然而，为了应对不同代理之间的交互以及与其他参与者的交互，我们需要外部协议和系统来塑造这些交互。因此，我们提出了“代理基础设施”的概念，即设计用于调解和影响代理与其环境之间交互的技术系统和共享协议。我们确定了代理基础设施的三个功能：1）将行动、属性和其他信息归因于特定代理、其用户或其他参与者；2）塑造代理之间的交互；以及3）检测和补救代理的有害行为。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI代理在开放环境中具有交互能力，如OpenAI的操作员使用网页进行产品比较和在线购物。</li>
<li>对代理的有用性和安全性进行研究主要侧重于直接改变其行为。</li>
<li>仅靠直接改变行为不足以应对多样化的代理和其他参与者的交互。</li>
<li>需要外部协议和系统来塑造代理之间的交互，并需要更高效的通信协议来达成协定。</li>
<li>将代理的行为归因于特定的人类或其他法律实体有助于建立信任并抑制滥用。</li>
<li>提出“代理基础设施”概念，即设计用于调解和影响代理与其环境之间交互的技术系统和共享协议。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10114">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-53646c25b420bc2ac8b37ee29f51874d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-942242f68eec8fa294e8e2c33ead6041.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4178a74b36ff5eb08cf2dede7f147062.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ee58459556428e41ad9521b4715cea6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-99ab6bcae368fafd5c685f90dcd1a675.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-24/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-24/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-24/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-eb1257e8598da3ad107b8138434c8199.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-06-24  Universal Music Representations? Evaluating Foundation Models on World   Music Corpora
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-24/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c3545f79463c4933987b03be47936731.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-06-24  Confidence Scoring for LLM-Generated SQL in Supply Chain Data Extraction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27544.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
