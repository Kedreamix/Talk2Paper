<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-21  ComputerRL Scaling End-to-End Online Reinforcement Learning for   Computer Use Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-09044d5bf6f2fd548f1712059536c58c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    66 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-21-æ›´æ–°"><a href="#2025-08-21-æ›´æ–°" class="headerlink" title="2025-08-21 æ›´æ–°"></a>2025-08-21 æ›´æ–°</h1><h2 id="ComputerRL-Scaling-End-to-End-Online-Reinforcement-Learning-for-Computer-Use-Agents"><a href="#ComputerRL-Scaling-End-to-End-Online-Reinforcement-Learning-for-Computer-Use-Agents" class="headerlink" title="ComputerRL: Scaling End-to-End Online Reinforcement Learning for   Computer Use Agents"></a>ComputerRL: Scaling End-to-End Online Reinforcement Learning for   Computer Use Agents</h2><p><strong>Authors:Hanyu Lai, Xiao Liu, Yanxiao Zhao, Han Xu, Hanchen Zhang, Bohao Jing, Yanyu Ren, Shuntian Yao, Yuxiao Dong, Jie Tang</strong></p>
<p>We introduce ComputerRL, a framework for autonomous desktop intelligence that enables agents to operate complex digital workspaces skillfully. ComputerRL features the API-GUI paradigm, which unifies programmatic API calls and direct GUI interaction to address the inherent mismatch between machine agents and human-centric desktop environments. Scaling end-to-end RL training is crucial for improvement and generalization across diverse desktop tasks, yet remains challenging due to environmental inefficiency and instability in extended training. To support scalable and robust training, we develop a distributed RL infrastructure capable of orchestrating thousands of parallel virtual desktop environments to accelerate large-scale online RL. Furthermore, we propose Entropulse, a training strategy that alternates reinforcement learning with supervised fine-tuning, effectively mitigating entropy collapse during extended training runs. We employ ComputerRL on open models GLM-4-9B-0414 and Qwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B based on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%, demonstrating significant improvements for general agents in desktop automation. The algorithm and framework are adopted in building AutoGLM (Liu et al., 2024a) </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ComputerRLï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªä¸»æ¡Œé¢æ™ºèƒ½æ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿä½¿ä»£ç†ç†Ÿç»ƒåœ°æ“ä½œå¤æ‚çš„æ•°å­—å·¥ä½œç©ºé—´ã€‚ComputerRLä»¥API-GUIèŒƒå¼ä¸ºç‰¹è‰²ï¼Œè¯¥èŒƒå¼ç»Ÿä¸€äº†ç¨‹åºåŒ–APIè°ƒç”¨å’Œç›´æ¥GUIäº¤äº’ï¼Œè§£å†³äº†æœºå™¨ä»£ç†å’Œäººç±»ä¸ºä¸­å¿ƒçš„æ¡Œé¢ç¯å¢ƒä¹‹é—´çš„å›ºæœ‰ä¸åŒ¹é…é—®é¢˜ã€‚ç«¯åˆ°ç«¯çš„å¯æ‰©å±•RLè®­ç»ƒå¯¹äºåœ¨å¤šç§æ¡Œé¢ä»»åŠ¡ä¸­è¿›è¡Œæ”¹è¿›å’Œæ³›åŒ–è‡³å…³é‡è¦ï¼Œä½†ç”±äºç¯å¢ƒæ•ˆç‡å’Œé•¿æœŸè®­ç»ƒä¸ç¨³å®šæ€§çš„æŒ‘æˆ˜ï¼Œå…¶ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†æ”¯æŒå¯æ‰©å±•å’Œç¨³å¥çš„è®­ç»ƒï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåˆ†å¸ƒå¼RLåŸºç¡€è®¾æ–½ï¼Œèƒ½å¤Ÿåè°ƒæ•°åƒä¸ªå¹¶è¡Œè™šæ‹Ÿæ¡Œé¢ç¯å¢ƒï¼Œä»¥åŠ é€Ÿå¤§è§„æ¨¡åœ¨çº¿RLã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†Entropulseè®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥äº¤æ›¿è¿›è¡Œå¼ºåŒ–å­¦ä¹ ä¸ç›‘ç£å¾®è°ƒï¼Œæœ‰æ•ˆåœ°ç¼“è§£äº†é•¿æœŸè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç†µå´©æºƒé—®é¢˜ã€‚æˆ‘ä»¬åœ¨å¼€æ”¾æ¨¡å‹GLM-4-9B-0414å’ŒQwen2.5-14Bä¸Šåº”ç”¨äº†ComputerRLï¼Œå¹¶åœ¨OSWorldåŸºå‡†ä¸Šå¯¹å…¶è¿›è¡Œäº†è¯„ä¼°ã€‚åŸºäºGLM-4-9B-0414çš„AutoGLM-OS-9Bè¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„æœ€é«˜ç²¾åº¦48.1%ï¼Œè¯æ˜äº†è¯¥ç®—æ³•åœ¨æ¡Œé¢è‡ªåŠ¨åŒ–ä¸­å¯¹äºé€šç”¨ä»£ç†çš„æ˜¾è‘—æ”¹è¿›ã€‚è¯¥ç®—æ³•å’Œæ¡†æ¶è¢«ç”¨äºæ„å»ºAutoGLMï¼ˆLiuç­‰äººï¼Œ2024aï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14040v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ComputerRLæ¡†æ¶ä¸ºè‡ªä¸»æ¡Œé¢æ™ºèƒ½æä¾›äº†è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒæ™ºèƒ½ä»£ç†åœ¨å¤æ‚çš„æ•°å­—å·¥ä½œç©ºé—´ä¸­ç†Ÿç»ƒæ“ä½œã€‚é€šè¿‡API-GUIèŒƒå¼ï¼Œæ•´åˆç¨‹åºAPIè°ƒç”¨å’Œç›´æ¥GUIäº¤äº’ï¼Œè§£å†³äº†æœºå™¨ä»£ç†ä¸äººç±»ä¸­å¿ƒæ¡Œé¢ç¯å¢ƒä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ã€‚ä¸ºæ”¯æŒå¯æ‰©å±•å’Œç¨³å¥çš„è®­ç»ƒï¼Œå¼€å‘äº†åˆ†å¸ƒå¼RLåŸºç¡€è®¾æ–½ï¼Œèƒ½å¤Ÿåè°ƒæ•°åƒä¸ªå¹¶è¡Œè™šæ‹Ÿæ¡Œé¢ç¯å¢ƒï¼ŒåŠ é€Ÿå¤§è§„æ¨¡åœ¨çº¿RLã€‚æ­¤å¤–ï¼Œæå‡ºEntropulseè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡äº¤æ›¿å¼ºåŒ–å­¦ä¹ ä¸ç›‘ç£å¾®è°ƒï¼Œæœ‰æ•ˆç¼“è§£é•¿æœŸè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç†µå´©æºƒé—®é¢˜ã€‚åœ¨OSWorldåŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŸºäºGLM-4-9B-0414çš„AutoGLM-OS-9Bè¾¾åˆ°48.1%çš„æ–°SOTAç²¾åº¦ï¼Œè¯æ˜å¯¹æ¡Œé¢è‡ªåŠ¨åŒ–é€šç”¨ä»£ç†çš„æ˜¾è‘—æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ComputerRLæ¡†æ¶æä¾›è‡ªä¸»æ¡Œé¢æ™ºèƒ½è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒæ™ºèƒ½ä»£ç†åœ¨å¤æ‚æ•°å­—å·¥ä½œç©ºé—´ä¸­çš„ç†Ÿç»ƒæ“ä½œã€‚</li>
<li>API-GUIèŒƒå¼æ•´åˆç¨‹åºAPIè°ƒç”¨å’Œç›´æ¥GUIäº¤äº’ï¼Œè§£å†³æœºå™¨ä»£ç†ä¸äººç±»ä¸­å¿ƒæ¡Œé¢ç¯å¢ƒçš„ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>åˆ†å¸ƒå¼RLåŸºç¡€è®¾æ–½æ”¯æŒå¯æ‰©å±•å’Œç¨³å¥çš„è®­ç»ƒï¼Œèƒ½åè°ƒæ•°åƒä¸ªå¹¶è¡Œè™šæ‹Ÿæ¡Œé¢ç¯å¢ƒï¼ŒåŠ é€Ÿå¤§è§„æ¨¡åœ¨çº¿RLã€‚</li>
<li>Entropulseè®­ç»ƒç­–ç•¥äº¤æ›¿å¼ºåŒ–å­¦ä¹ ä¸ç›‘ç£å¾®è°ƒï¼Œç¼“è§£é•¿æœŸè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç†µå´©æºƒé—®é¢˜ã€‚</li>
<li>åŸºäºGLM-4-9B-0414çš„AutoGLM-OS-9Båœ¨OSWorldåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°48.1%çš„æ–°SOTAç²¾åº¦ã€‚</li>
<li>ComputerRLæ¡†æ¶å¯¹æ¡Œé¢è‡ªåŠ¨åŒ–é€šç”¨ä»£ç†çš„æ”¹è¿›æ˜¾è‘—ã€‚</li>
<li>è¯¥ç®—æ³•å’Œæ¡†æ¶è¢«ç”¨äºæ„å»ºAutoGLMã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fc5fe83ebade0e6265a65df04f9308cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09044d5bf6f2fd548f1712059536c58c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e158cb4c69bf0c5623edd6a266a47cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40e2a3181eafdeaf1d887b0015977dcb.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Unintended-Misalignment-from-Agentic-Fine-Tuning-Risks-and-Mitigation"><a href="#Unintended-Misalignment-from-Agentic-Fine-Tuning-Risks-and-Mitigation" class="headerlink" title="Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation"></a>Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation</h2><p><strong>Authors:Dongyoon Hahm, Taywon Min, Woogyeol Jin, Kimin Lee</strong></p>
<p>Beyond simple text generation, Large Language Models (LLMs) have evolved into agentic systems capable of planning and interacting with external tools to solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific tasks to enhance their proficiency. However, safety concerns are frequently overlooked during this fine-tuning process. In this work, we show that aligned LLMs can become unintentionally misaligned, leading to a higher likelihood of executing harmful tasks and a reduced tendency to refuse them when fine-tuned to execute agentic tasks. To address these safety challenges, we propose Prefix INjection Guard (PING), a simple yet effective method that prepends automatically generated natural language prefixes to agent responses, guiding them to refuse harmful requests while preserving performance on benign tasks. Specifically, we introduce an iterative approach that alternates between (1) generating candidate prefixes and (2) selecting those that optimize both task performance and refusal behavior. Experimental results demonstrate that PING significantly enhances the safety of fine-tuned LLM agents without sacrificing their effectiveness. PING consistently outperforms existing prompting approaches across diverse benchmarks in both web navigation and code generation tasks. Our analysis of internal hidden states via linear probes reveals that prefix tokens are crucial for behavior modification, explaining the performance gains. WARNING: This paper contains contents that are unethical or offensive in nature. </p>
<blockquote>
<p>é™¤äº†ç®€å•çš„æ–‡æœ¬ç”Ÿæˆï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»è¿›åŒ–æˆèƒ½å¤Ÿè§„åˆ’ã€ä¸å¤–éƒ¨å·¥å…·äº¤äº’ä»¥è§£å†³å¤æ‚ä»»åŠ¡çš„ä»£ç†ç³»ç»Ÿã€‚è¿™ç§è¿›åŒ–æ¶‰åŠå¯¹ç‰¹å®šä»»åŠ¡çš„LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜å…¶ç†Ÿç»ƒç¨‹åº¦ã€‚ç„¶è€Œï¼Œåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå®‰å…¨é—®é¢˜ç»å¸¸è¢«å¿½è§†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œå¯¹é½çš„LLMå¯èƒ½ä¼šæ— æ„ä¸­å¤±å»å¯¹é½ï¼Œå¯¼è‡´æ‰§è¡Œæœ‰å®³ä»»åŠ¡çš„å¯èƒ½æ€§æ›´é«˜ï¼Œå¹¶ä¸”åœ¨æ‰§è¡Œä»£ç†ä»»åŠ¡è¿›è¡Œå¾®è°ƒæ—¶æ‹’ç»å®ƒä»¬çš„å€¾å‘é™ä½ã€‚ä¸ºäº†è§£å†³è¿™äº›å®‰å…¨æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Prefix INjection Guardï¼ˆPINGï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå‘ä»£ç†å“åº”è‡ªåŠ¨ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€å‰ç¼€ï¼ŒæŒ‡å¯¼å®ƒä»¬æ‹’ç»æœ‰å®³çš„è¯·æ±‚ï¼ŒåŒæ—¶ä¿ç•™åœ¨è‰¯æ€§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§è¿­ä»£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•äº¤æ›¿è¿›è¡Œï¼ˆ1ï¼‰ç”Ÿæˆå€™é€‰å‰ç¼€å’Œï¼ˆ2ï¼‰é€‰æ‹©é‚£äº›æ—¢èƒ½ä¼˜åŒ–ä»»åŠ¡æ€§èƒ½åˆèƒ½ä¼˜åŒ–æ‹’ç»è¡Œä¸ºçš„å‰ç¼€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPINGåœ¨ä¸å½±å“LLMä»£ç†æœ‰æ•ˆæ€§çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æé«˜äº†å…¶å®‰å…¨æ€§ã€‚åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ— è®ºæ˜¯åœ¨ç½‘é¡µå¯¼èˆªè¿˜æ˜¯ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒPINGéƒ½å§‹ç»ˆä¼˜äºç°æœ‰çš„æç¤ºæ–¹æ³•ã€‚æˆ‘ä»¬é€šè¿‡çº¿æ€§æ¢é’ˆå¯¹å†…éƒ¨éšè—çŠ¶æ€çš„åˆ†æè¡¨æ˜ï¼Œå‰ç¼€ä»¤ç‰Œå¯¹è¡Œä¸ºä¿®æ”¹è‡³å…³é‡è¦ï¼Œè§£é‡Šäº†æ€§èƒ½æå‡çš„åŸå› ã€‚è­¦å‘Šï¼šæœ¬æ–‡å«æœ‰åœ¨æœ¬è´¨ä¸Šæ˜¯éé“å¾·æˆ–å…·æœ‰å†’çŠ¯æ€§çš„å†…å®¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.14031v1">PDF</a> Source code: <a target="_blank" rel="noopener" href="https://github.com/HahmDY/prefix_injection_guard">https://github.com/HahmDY/prefix_injection_guard</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²è¿›åŒ–ä¸ºèƒ½å¤Ÿè§„åˆ’å¹¶ä¸å¤–éƒ¨å·¥å…·äº¤äº’ä»¥å®Œæˆå¤æ‚ä»»åŠ¡çš„ä»£ç†ç³»ç»Ÿã€‚ç„¶è€Œï¼Œåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå®‰å…¨æ€§é—®é¢˜å¸¸è¢«å¿½è§†ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œå¯¹é½çš„LLMså¯èƒ½ä¼šæ„å¤–åœ°å‡ºç°ä¸å¯¹é½çš„æƒ…å†µï¼Œå¯¼è‡´æ›´å®¹æ˜“æ‰§è¡Œæœ‰å®³ä»»åŠ¡ï¼Œå¹¶å‡å°‘æ‹’ç»è¿™äº›ä»»åŠ¡çš„å¯èƒ½æ€§ã€‚ä¸ºåº”å¯¹è¿™äº›å®‰å…¨æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åä¸ºPINGçš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨ä»£ç†å“åº”å‰è‡ªåŠ¨æ·»åŠ è‡ªç„¶è¯­è¨€å‰ç¼€æ¥å¼•å¯¼å®ƒä»¬æ‹’ç»æœ‰å®³è¯·æ±‚ï¼ŒåŒæ—¶ä¿æŒå¯¹è‰¯æ€§ä»»åŠ¡çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPINGåœ¨ä¸å½±å“LLMä»£ç†æ•ˆèƒ½çš„å‰æä¸‹æ˜¾è‘—æé«˜äº†å…¶å®‰å…¨æ€§ã€‚ç›¸è¾ƒäºç°æœ‰çš„æç¤ºæ–¹æ³•ï¼ŒPINGåœ¨ç½‘é¡µå¯¼èˆªå’Œä»£ç ç”Ÿæˆä»»åŠ¡ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æ›´ä½³ã€‚é€šè¿‡åˆ†æå†…éƒ¨éšè—çŠ¶æ€ï¼Œæˆ‘ä»¬å‘ç°å‰ç¼€æ ‡è®°å¯¹è¡Œä¸ºæ”¹å˜è‡³å…³é‡è¦ï¼Œè§£é‡Šäº†æ€§èƒ½æå‡çš„åŸå› ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså·²è¿›åŒ–ä¸ºèƒ½å®Œæˆå¤æ‚ä»»åŠ¡çš„ä»£ç†ç³»ç»Ÿï¼Œä½†å¾®è°ƒè¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§å¸¸è¢«å¿½è§†ã€‚</li>
<li>å¯¹é½çš„LLMså¯èƒ½æ„å¤–å‡ºç°ä¸å¯¹é½ï¼Œæ˜“æ‰§è¡Œæœ‰å®³ä»»åŠ¡å¹¶å‡å°‘æ‹’ç»å‡ ç‡ã€‚</li>
<li>æå‡ºPINGæ–¹æ³•ï¼Œé€šè¿‡è‡ªåŠ¨æ·»åŠ è‡ªç„¶è¯­è¨€å‰ç¼€æ¥å¼•å¯¼LLMä»£ç†æ‹’ç»æœ‰å®³è¯·æ±‚ã€‚</li>
<li>PINGæ˜¾è‘—æé«˜LLMä»£ç†çš„å®‰å…¨æ€§ï¼ŒåŒæ—¶ä¿æŒå¯¹è‰¯æ€§ä»»åŠ¡çš„æ€§èƒ½ã€‚</li>
<li>PINGåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºç°æœ‰æç¤ºæ–¹æ³•ã€‚</li>
<li>å†…éƒ¨éšè—çŠ¶æ€åˆ†ææ˜¾ç¤ºï¼Œå‰ç¼€æ ‡è®°å¯¹LLMè¡Œä¸ºæ”¹å˜å’Œæ€§èƒ½æå‡æœ‰é‡è¦ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.14031">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b88ab9ad84bf1dda7237ea976b024cb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8862d04bf6dff131ca511ba3641de15a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a765d3cbe2433bd2b2f5429b80d78522.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-684cad5b774d387d7ced22e94aebebce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de083283a8b9ba75b0d4eb42037e8b33.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-24752f6793c0ba1b3a40b2aa66ae42b2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="LLMind-2-0-Distributed-IoT-Automation-with-Natural-Language-M2M-Communication-and-Lightweight-LLM-Agents"><a href="#LLMind-2-0-Distributed-IoT-Automation-with-Natural-Language-M2M-Communication-and-Lightweight-LLM-Agents" class="headerlink" title="LLMind 2.0: Distributed IoT Automation with Natural Language M2M   Communication and Lightweight LLM Agents"></a>LLMind 2.0: Distributed IoT Automation with Natural Language M2M   Communication and Lightweight LLM Agents</h2><p><strong>Authors:Yuyang Du, Qun Yang, Liujianfu Wang, Jingqi Lin, Hongwei Cui, Soung Chang Liew</strong></p>
<p>Recent advances in large language models (LLMs) have sparked interest in their application to IoT and automation systems, particularly for facilitating device management through natural language instructions. However, existing centralized approaches face significant scalability challenges when managing and coordinating the collaboration between IoT devices of diverse capabilities in large-scale heterogeneous IoT systems. This paper introduces LLMind 2.0, a distributed IoT automation framework that addresses the scalability challenges through lightweight LLM-empowered device agents via natural language-based machine-to-machine (M2M) communication. Unlike previous LLM-controlled automation systems that rely on a centralized coordinator to generate device-specific code to be executed on individual devices, LLMind 2.0 distributes intelligence across individual devices through lightweight LLMs embedded in IoT devices. The central coordinator translates human instructions into simple subtasks described in natural human language, which are then processed by device-specific agents to generate device-specific code locally at the associated devices. This approach transcends device heterogeneity barriers by using natural language as a unified communication medium, enabling seamless collaboration between devices from different manufacturers. The system incorporates several key innovations: a Retrieval-Augmented Generation (RAG) mechanism for accurate subtask-to-API mapping, fine-tuned lightweight LLMs for reliable code generation, and a finite state machine-based task execution framework. Experimental validation in multi-robot warehouse scenarios and real-world WiFi network deployments demonstrates significant improvements in scalability, reliability, and privacy protection compared to the centralized approach. </p>
<blockquote>
<p>è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å¼•å‘äº†å°†å…¶åº”ç”¨äºç‰©è”ç½‘å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿé¢†åŸŸçš„å…´è¶£ï¼Œç‰¹åˆ«æ˜¯åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤å®ç°è®¾å¤‡ç®¡ç†æ–¹é¢çš„åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é›†ä¸­å¼æ–¹æ³•åœ¨å¤§å‹å¼‚æ„ç‰©è”ç½‘ç³»ç»Ÿä¸­ç®¡ç†å¹¶åè°ƒå…·æœ‰ä¸åŒåŠŸèƒ½çš„ç‰©è”ç½‘è®¾å¤‡ä¹‹é—´çš„åä½œæ—¶ï¼Œé¢ä¸´ç€å·¨å¤§çš„å¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†LLMind 2.0ï¼Œä¸€ä¸ªåˆ†å¸ƒå¼ç‰©è”ç½‘è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œå®ƒé€šè¿‡åŸºäºè‡ªç„¶è¯­è¨€çš„æœºå™¨å¯¹æœºå™¨ï¼ˆM2Mï¼‰é€šä¿¡ï¼Œåˆ©ç”¨è½»é‡çº§çš„å¤§å‹è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„è®¾å¤‡ä»£ç†æ¥è§£å†³å¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚ä¸åŒäºä¹‹å‰ä¾èµ–é›†ä¸­å¼åè°ƒå™¨ç”Ÿæˆé’ˆå¯¹ç‰¹å®šè®¾å¤‡çš„ä»£ç å¹¶åœ¨å„ä¸ªè®¾å¤‡ä¸Šæ‰§è¡Œçš„å¤§å‹è¯­è¨€æ¨¡å‹æ§åˆ¶çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼ŒLLMind 2.0é€šè¿‡ä¸ªäººè®¾å¤‡ä¸ŠåµŒå…¥çš„è½»é‡çº§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸ªäººè®¾å¤‡ä¹‹é—´åˆ†é…æ™ºèƒ½ã€‚ä¸­å¤®åè°ƒå™¨å°†äººç±»æŒ‡ä»¤ç¿»è¯‘æˆç”¨è‡ªç„¶è¯­è¨€æè¿°çš„ç®€å•å­ä»»åŠ¡ï¼Œç„¶åç”±ç‰¹å®šè®¾å¤‡ä»£ç†å¤„ç†ï¼Œå¹¶åœ¨ç›¸å…³è®¾å¤‡ä¸Šæœ¬åœ°ç”Ÿæˆç‰¹å®šè®¾å¤‡çš„ä»£ç ã€‚è¿™ç§æ–¹æ³•é€šè¿‡ä½¿ç”¨è‡ªç„¶è¯­è¨€ä½œä¸ºç»Ÿä¸€çš„é€šä¿¡åª’ä»‹ï¼Œè¶…è¶Šäº†è®¾å¤‡å¼‚æ„æ€§çš„éšœç¢ï¼Œå®ç°äº†ä¸åŒåˆ¶é€ å•†è®¾å¤‡ä¹‹é—´çš„æ— ç¼åä½œã€‚è¯¥ç³»ç»Ÿèåˆäº†å¤šé¡¹å…³é”®åˆ›æ–°æŠ€æœ¯ï¼šç”¨äºå‡†ç¡®å®ç°å­ä»»åŠ¡åˆ°APIæ˜ å°„çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æœºåˆ¶ã€ç”¨äºå¯é ä»£ç ç”Ÿæˆçš„å¾®è°ƒè½»é‡çº§å¤§å‹è¯­è¨€æ¨¡å‹ä»¥åŠåŸºäºæœ‰é™çŠ¶æ€æœºçš„ä»»åŠ¡æ‰§è¡Œæ¡†æ¶ã€‚åœ¨å¤šæœºå™¨äººä»“åº“åœºæ™¯å’ŒçœŸå®WiFiç½‘ç»œéƒ¨ç½²ä¸­çš„å®éªŒéªŒè¯è¡¨æ˜ï¼Œä¸é›†ä¸­å¼æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒåœ¨å¯æ‰©å±•æ€§ã€å¯é æ€§å’Œéšç§ä¿æŠ¤æ–¹é¢å®ç°äº†æ˜¾ç€æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13920v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•æ¿€å‘äº†å…¶åœ¨ç‰©è”ç½‘ï¼ˆIoTï¼‰å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿåº”ç”¨çš„å…´è¶£ï¼Œå°¤å…¶æ˜¯åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤è¿›è¡Œè®¾å¤‡ç®¡ç†æ–¹é¢ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é›†ä¸­åŒ–æ–¹æ³•åœ¨é¢å¯¹å¤§è§„æ¨¡å¼‚æ„IoTç³»ç»Ÿä¸­ç®¡ç†ä¸åŒèƒ½åŠ›çš„è®¾å¤‡åä½œæ—¶ï¼Œé¢ä¸´é‡å¤§çš„å¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†LLMind 2.0ï¼Œä¸€ä¸ªåˆ†å¸ƒå¼IoTè‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œå®ƒé€šè¿‡è½»é‡çº§LLMèµ‹èƒ½çš„è®¾å¤‡ä»£ç†å’ŒåŸºäºè‡ªç„¶è¯­è¨€çš„æœºå™¨åˆ°æœºå™¨ï¼ˆM2Mï¼‰é€šä¿¡æ¥è§£å†³å¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚ä¸åŒäºä»¥å‰ä¾èµ–äºé›†ä¸­åè°ƒå™¨ç”Ÿæˆç‰¹å®šè®¾å¤‡ä»£ç åœ¨ä¸ªåˆ«è®¾å¤‡ä¸Šæ‰§è¡Œçš„LLMæ§åˆ¶è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼ŒLLMind 2.0å°†æ™ºèƒ½åˆ†å¸ƒåœ¨å„ä¸ªè®¾å¤‡ä¸Šï¼Œé€šè¿‡åœ¨IoTè®¾å¤‡ä¸­åµŒå…¥è½»é‡çº§çš„LLMã€‚é›†ä¸­åè°ƒå™¨å°†äººç±»æŒ‡ä»¤ç¿»è¯‘æˆç®€å•çš„å­ä»»åŠ¡ï¼Œä»¥è‡ªç„¶è¯­è¨€æè¿°ï¼Œç„¶åç”±ç‰¹å®šè®¾å¤‡ä»£ç†å¤„ç†ï¼Œå¹¶åœ¨ç›¸å…³è®¾å¤‡ä¸Šæœ¬åœ°ç”Ÿæˆç‰¹å®šè®¾å¤‡çš„ä»£ç ã€‚è¿™ç§æ–¹æ³•é€šè¿‡ä½¿ç”¨è‡ªç„¶è¯­è¨€ä½œä¸ºç»Ÿä¸€çš„é€šä¿¡åª’ä»‹ï¼Œè¶…è¶Šäº†è®¾å¤‡å¼‚æ„æ€§çš„éšœç¢ï¼Œå®ç°äº†ä¸åŒåˆ¶é€ å•†è®¾å¤‡ä¹‹é—´çš„æ— ç¼åä½œã€‚ç³»ç»Ÿé‡‡ç”¨äº†å‡ é¡¹å…³é”®åˆ›æ–°æŠ€æœ¯ï¼šç”¨äºå‡†ç¡®å­ä»»åŠ¡åˆ°APIæ˜ å°„çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æœºåˆ¶ã€ç”¨äºå¯é ä»£ç ç”Ÿæˆçš„å¾®è°ƒè½»é‡çº§LLMã€ä»¥åŠåŸºäºæœ‰é™çŠ¶æ€æœºçš„ä»»åŠ¡æ‰§è¡Œæ¡†æ¶ã€‚åœ¨å¤šæœºå™¨äººä»“åº“åœºæ™¯å’ŒçœŸå®WiFiç½‘ç»œéƒ¨ç½²ä¸­çš„å®éªŒéªŒè¯è¡¨æ˜ï¼Œä¸é›†ä¸­å¼æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒåœ¨å¯æ‰©å±•æ€§ã€å¯é æ€§å’Œéšç§ä¿æŠ¤æ–¹é¢å–å¾—äº†æ˜¾è‘—æ”¹å–„ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>LLMind 2.0æ˜¯ä¸€ä¸ªç”¨äºå¤§è§„æ¨¡å¼‚æ„IoTç³»ç»Ÿçš„åˆ†å¸ƒå¼è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨è½»é‡çº§LLMèµ‹èƒ½çš„è®¾å¤‡ä»£ç†ï¼Œå®ç°æ™ºèƒ½åˆ†å¸ƒåœ¨å„ä¸ªè®¾å¤‡ä¸Šã€‚</li>
<li>é›†ä¸­åè°ƒå™¨å°†äººç±»æŒ‡ä»¤è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€æè¿°çš„ç®€å•å­ä»»åŠ¡ã€‚</li>
<li>LLMind 2.0é‡‡ç”¨è‡ªç„¶è¯­è¨€ä½œä¸ºç»Ÿä¸€é€šä¿¡åª’ä»‹ï¼Œå®ç°è®¾å¤‡æ— ç¼åä½œã€‚</li>
<li>ç³»ç»Ÿå…³é”®åˆ›æ–°åŒ…æ‹¬RAGæœºåˆ¶ã€å¾®è°ƒè½»é‡çº§LLMå’Œæœ‰é™çŠ¶æ€æœºä»»åŠ¡æ‰§è¡Œæ¡†æ¶ã€‚</li>
<li>å®éªŒéªŒè¯æ˜¾ç¤ºï¼Œä¸é›†ä¸­å¼æ–¹æ³•ç›¸æ¯”ï¼ŒLLMind 2.0åœ¨å¯æ‰©å±•æ€§ã€å¯é æ€§å’Œéšç§ä¿æŠ¤æ–¹é¢æœ‰æ˜¾è‘—æ”¹å–„ã€‚</li>
<li>LLMind 2.0ä¸ºç‰©è”ç½‘è‡ªåŠ¨åŒ–æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13920">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d84fcc47344943038bce9767cc8dfc95.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b314cb0a816adad26f83d55ea6396177.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-68bc0ccba117b81c808d41249ed1a6d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8de939e53ea2e8147828a533b6cbd336.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-203d341ea8429f0943a94e7d1dc5f473.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Structured-Agentic-Workflows-for-Financial-Time-Series-Modeling-with-LLMs-and-Reflective-Feedback"><a href="#Structured-Agentic-Workflows-for-Financial-Time-Series-Modeling-with-LLMs-and-Reflective-Feedback" class="headerlink" title="Structured Agentic Workflows for Financial Time-Series Modeling with   LLMs and Reflective Feedback"></a>Structured Agentic Workflows for Financial Time-Series Modeling with   LLMs and Reflective Feedback</h2><p><strong>Authors:Yihao Ang, Yifan Bao, Lei Jiang, Jiajie Tao, Anthony K. H. Tung, Lukasz Szpruch, Hao Ni</strong></p>
<p>Time-series data is central to decision-making in financial markets, yet building high-performing, interpretable, and auditable models remains a major challenge. While Automated Machine Learning (AutoML) frameworks streamline model development, they often lack adaptability and responsiveness to domain-specific needs and evolving objectives. Concurrently, Large Language Models (LLMs) have enabled agentic systems capable of reasoning, memory management, and dynamic code generation, offering a path toward more flexible workflow automation. In this paper, we introduce \textsf{TS-Agent}, a modular agentic framework designed to automate and enhance time-series modeling workflows for financial applications. The agent formalizes the pipeline as a structured, iterative decision process across three stages: model selection, code refinement, and fine-tuning, guided by contextual reasoning and experimental feedback. Central to our architecture is a planner agent equipped with structured knowledge banks, curated libraries of models and refinement strategies, which guide exploration, while improving interpretability and reducing error propagation. \textsf{TS-Agent} supports adaptive learning, robust debugging, and transparent auditing, key requirements for high-stakes environments such as financial services. Empirical evaluations on diverse financial forecasting and synthetic data generation tasks demonstrate that \textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic baselines, achieving superior accuracy, robustness, and decision traceability. </p>
<blockquote>
<p>æ—¶é—´åºåˆ—æ•°æ®åœ¨é‡‘èå¸‚åœºçš„å†³ç­–åˆ¶å®šä¸­å æ®æ ¸å¿ƒåœ°ä½ï¼Œç„¶è€Œï¼Œæ„å»ºé«˜æ€§èƒ½ã€å¯è§£é‡Šå’Œå¯å®¡è®¡çš„æ¨¡å‹ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚å°½ç®¡è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰æ¡†æ¶ç®€åŒ–äº†æ¨¡å‹å¼€å‘ï¼Œä½†å®ƒä»¬å¾€å¾€ç¼ºä¹é€‚åº”æ€§å’Œå¯¹ç‰¹å®šé¢†åŸŸéœ€æ±‚å’Œä¸æ–­å˜åŒ–ç›®æ ‡çš„å“åº”èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿå®ç°å…·æœ‰æ¨ç†ã€å†…å­˜ç®¡ç†å’ŒåŠ¨æ€ä»£ç ç”Ÿæˆèƒ½åŠ›çš„ä»£ç†ç³»ç»Ÿï¼Œä¸ºæ›´çµæ´»çš„å·¥ä½œæµè‡ªåŠ¨åŒ–æä¾›äº†é€”å¾„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†\textsf{TS-Agent}ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–ä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–å¹¶å¢å¼ºæ—¶é—´åºåˆ—å»ºæ¨¡å·¥ä½œæµç¨‹ï¼Œç”¨äºé‡‘èåº”ç”¨ç¨‹åºã€‚è¯¥ä»£ç†å°†ç®¡é“æ­£å¼åŒ–ä¸ºä¸€ä¸ªç»“æ„åŒ–ã€è¿­ä»£å†³ç­–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼šæ¨¡å‹é€‰æ‹©ã€ä»£ç ç»†åŒ–å’Œå¾®è°ƒï¼Œç”±ä¸Šä¸‹æ–‡æ¨ç†å’Œå®éªŒåé¦ˆæŒ‡å¯¼ã€‚æˆ‘ä»¬æ¶æ„çš„æ ¸å¿ƒæ˜¯é…å¤‡ç»“æ„åŒ–çŸ¥è¯†åº“ã€ç²¾é€‰çš„æ¨¡å‹å’Œç»†åŒ–ç­–ç•¥åº“çš„è§„åˆ’ä»£ç†ï¼Œå®ƒå¼•å¯¼æ¢ç´¢ï¼ŒåŒæ—¶æé«˜å¯è§£é‡Šæ€§å¹¶å‡å°‘é”™è¯¯ä¼ æ’­ã€‚\textsf{TS-Agent}æ”¯æŒè‡ªé€‚åº”å­¦ä¹ ã€ç¨³å¥çš„è°ƒè¯•å’Œé€æ˜çš„å®¡è®¡ï¼Œè¿™æ˜¯é‡‘èæœåŠ¡ç­‰é«˜é£é™©ç¯å¢ƒä¸­çš„å…³é”®è¦æ±‚ã€‚åœ¨å¤šæ ·åŒ–çš„é‡‘èé¢„æµ‹å’Œåˆæˆæ•°æ®ç”Ÿæˆä»»åŠ¡ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œ\textsf{TS-Agent}æŒç»­ä¼˜äºæœ€æ–°çš„AutoMLå’Œä»£ç†åŸºå‡†æµ‹è¯•ï¼Œå®ç°äº†æ›´é«˜çš„å‡†ç¡®æ€§ã€ç¨³å¥æ€§å’Œå†³ç­–å¯è¿½æº¯æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13915v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæœ¬æ–‡ä»‹ç»äº†é¢å‘é‡‘èåº”ç”¨çš„è‡ªåŠ¨åŒ–å¢å¼ºæ—¶é—´åºåˆ—å»ºæ¨¡å·¥ä½œæµçš„æ¨¡å—åŒ–æ™ºèƒ½æ¡†æ¶TS-Agentã€‚è¯¥æ¡†æ¶å°†ç®¡é“å½¢å¼åŒ–ä¸ºä¸€ä¸ªç»“æ„åŒ–ã€è¿­ä»£çš„å†³ç­–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€ä»£ç ç»†åŒ–å’Œå¾®è°ƒä¸‰ä¸ªé˜¶æ®µï¼Œå¹¶ç”±ä¸Šä¸‹æ–‡æ¨ç†å’Œå®éªŒåé¦ˆæŒ‡å¯¼ã€‚é€šè¿‡è§„åˆ’æ™ºèƒ½ä½“å’Œç»“æ„åŒ–çŸ¥è¯†åº“æ¥å¼•å¯¼æ¢ç´¢ï¼Œæé«˜å¯è§£é‡Šæ€§å¹¶å‡å°‘é”™è¯¯ä¼ æ’­ã€‚TS-Agentæ”¯æŒè‡ªé€‚åº”å­¦ä¹ ã€ç¨³å¥è°ƒè¯•å’Œé€æ˜å®¡è®¡ï¼Œé€‚åˆé‡‘èæœåŠ¡ç­‰é«˜é£é™©ç¯å¢ƒã€‚åœ¨è´¢åŠ¡é¢„æµ‹å’Œåˆæˆæ•°æ®ç”Ÿæˆä»»åŠ¡ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒTS-Agentçš„æ€§èƒ½ä¼˜äºæœ€æ–°çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ™ºèƒ½ä»£ç†æ¨¡å‹ï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§ã€ç¨³å¥æ€§å’Œå†³ç­–å¯è¿½æº¯æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>æ—¶é—´åºåˆ—æ•°æ®åœ¨é‡‘èå¸‚åœºçš„å†³ç­–åˆ¶å®šä¸­è‡³å…³é‡è¦ï¼Œä½†æ„å»ºé«˜æ€§èƒ½ã€å¯è§£é‡Šå’Œå¯å®¡è®¡çš„æ¨¡å‹ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>å½“å‰AutoMLæ¡†æ¶è™½ç„¶å¯ä»¥ç®€åŒ–æ¨¡å‹å¼€å‘ï¼Œä½†å®ƒä»¬é€šå¸¸ç¼ºä¹é€‚åº”æ€§å’Œå“åº”æ€§ï¼Œä¸èƒ½æ»¡è¶³ç‰¹å®šé¢†åŸŸçš„ç‰¹å®šéœ€æ±‚å’Œä¸æ–­å˜åŒ–çš„ç›®æ ‡ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºæ™ºèƒ½ç³»ç»Ÿæä¾›äº†æ¨ç†ã€å†…å­˜ç®¡ç†å’ŒåŠ¨æ€ä»£ç ç”Ÿæˆçš„èƒ½åŠ›ï¼Œä¸ºæ›´çµæ´»çš„å·¥ä½œæµè‡ªåŠ¨åŒ–æä¾›äº†é€”å¾„ã€‚</li>
<li>TS-Agentæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ™ºèƒ½æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–å’Œå¢å¼ºæ—¶é—´åºåˆ—å»ºæ¨¡å·¥ä½œæµç¨‹ï¼Œé€‚ç”¨äºé‡‘èåº”ç”¨ã€‚</li>
<li>TS-Agentå°†ç®¡é“å½¢å¼åŒ–ä¸ºç»“æ„åŒ–è¿­ä»£å†³ç­–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€ä»£ç ç»†åŒ–å’Œå¾®è°ƒä¸‰ä¸ªé˜¶æ®µï¼Œå—åˆ°ä¸Šä¸‹æ–‡æ¨ç†å’Œå®éªŒåé¦ˆçš„æŒ‡å¯¼ã€‚</li>
<li>TS-Agentçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªé…å¤‡ç»“æ„åŒ–çŸ¥è¯†åº“å’Œç²¾é€‰æ¨¡å‹å’Œç»†åŒ–ç­–ç•¥åº“çš„è§„åˆ’æ™ºèƒ½ä½“ï¼Œè¿™å¯ä»¥å¼•å¯¼æ¢ç´¢è¿‡ç¨‹ï¼ŒåŒæ—¶æé«˜æ¨¡å‹çš„è§£é‡Šæ€§å’Œå‡å°‘é”™è¯¯ä¼ æ’­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13915">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1f3210e86952085276b52c80703f45b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82377df016cb7b99feee7a28380818d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da6611ae5533b12c6249dc2227cd029a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7fd24b88fc1ba0eeeecbcbf168cdf9f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="COCO-Cognitive-Operating-System-with-Continuous-Oversight-for-Multi-Agent-Workflow-Reliability"><a href="#COCO-Cognitive-Operating-System-with-Continuous-Oversight-for-Multi-Agent-Workflow-Reliability" class="headerlink" title="COCO: Cognitive Operating System with Continuous Oversight for   Multi-Agent Workflow Reliability"></a>COCO: Cognitive Operating System with Continuous Oversight for   Multi-Agent Workflow Reliability</h2><p><strong>Authors:Churong Liang, Jinling Gan, Kairan Hong, Qiushi Tian, Zongze Wu, Runnan Li</strong></p>
<p>Large-scale multi-agent workflows exhibit inherent vulnerability to error propagation and quality degradation, where downstream agents compound upstream failures without corrective mechanisms. We introduce COCO (Cognitive Operating System with Continuous Oversight), a theoretically-grounded framework that implements asynchronous self-monitoring and adaptive error correction in multi-agent driven systems. COCO addresses the fundamental trade-off between quality assurance and computational efficiency through a novel decoupled architecture that separates error detection from the critical execution path, achieving $O(1)$ monitoring overhead relative to workflow complexity. COCO employs three key algorithmic innovations to address systematic and stochastic errors: (1) Contextual Rollback Mechanism - a stateful restart protocol that preserves execution history and error diagnostics, enabling informed re-computation rather than naive retry; (2) Bidirectional Reflection Protocol - a mutual validation system between monitoring and execution modules that prevents oscillatory behavior and ensures convergence; (3) Heterogeneous Cross-Validation - leveraging model diversity to detect systematic biases and hallucinations through ensemble disagreement metrics. Extensive experiments on benchmark multi-agent tasks demonstrate 6.5% average performance improvement, establishing new state-of-the-art for autonomous workflow reliability. </p>
<blockquote>
<p>å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“å·¥ä½œæµç¨‹å­˜åœ¨å›ºæœ‰çš„é”™è¯¯ä¼ æ’­å’Œè´¨é‡ä¸‹é™é£é™©ï¼Œä¸‹æ¸¸æ™ºèƒ½ä½“åœ¨æ²¡æœ‰çº æ­£æœºåˆ¶çš„æƒ…å†µä¸‹ä¼šåŠ å‰§ä¸Šæ¸¸æ•…éšœã€‚æˆ‘ä»¬å¼•å…¥äº†COCOï¼ˆå¸¦æœ‰æŒç»­ç›‘ç£çš„è®¤çŸ¥æ“ä½œç³»ç»Ÿï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰ç†è®ºæ”¯æ’‘çš„æ¡†æ¶ï¼Œåœ¨æ™ºèƒ½ä½“é©±åŠ¨ç³»ç»Ÿä¸­å®ç°äº†å¼‚æ­¥è‡ªæˆ‘ç›‘æ§å’Œè‡ªé€‚åº”é”™è¯¯çº æ­£ã€‚COCOé€šè¿‡ä¸€ç§æ–°å‹è§£è€¦æ¶æ„è§£å†³äº†è´¨é‡ä¿è¯å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´çš„åŸºæœ¬æƒè¡¡ï¼Œè¯¥æ¶æ„å°†é”™è¯¯æ£€æµ‹ä¸å…³é”®æ‰§è¡Œè·¯å¾„åˆ†ç¦»ï¼Œå®ç°ç›¸å¯¹äºå·¥ä½œæµç¨‹å¤æ‚æ€§çš„O(1)ç›‘æ§å¼€é”€ã€‚COCOé€šè¿‡ä¸‰ä¸ªå…³é”®ç®—æ³•åˆ›æ–°æ¥è§£å†³ç³»ç»Ÿæ€§éšæœºé”™è¯¯å’Œéšæœºé”™è¯¯ï¼šï¼ˆ1ï¼‰ä¸Šä¸‹æ–‡å›æ»šæœºåˆ¶â€”â€”ä¸€ç§å¸¦æœ‰çŠ¶æ€é‡å¯åè®®ï¼Œä¿ç•™æ‰§è¡Œå†å²å’Œé”™è¯¯è¯Šæ–­ï¼Œä»¥å®ç°çŸ¥æƒ…çš„é‡æ–°è®¡ç®—è€Œä¸æ˜¯ç®€å•çš„é‡è¯•ï¼›ï¼ˆ2ï¼‰åŒå‘åå°„åè®®â€”â€”ç›‘æµ‹æ¨¡å—å’Œæ‰§è¡Œæ¨¡å—ä¹‹é—´çš„ç›¸äº’éªŒè¯ç³»ç»Ÿï¼Œé˜²æ­¢æŒ¯è¡è¡Œä¸ºå¹¶ç¡®ä¿æ”¶æ•›ï¼›ï¼ˆ3ï¼‰å¼‚æ„äº¤å‰éªŒè¯â€”â€”åˆ©ç”¨æ¨¡å‹å¤šæ ·æ€§é€šè¿‡é›†åˆåˆ†æ­§æŒ‡æ ‡æ£€æµ‹ç³»ç»Ÿæ€§åè§å’Œå¹»è§‰ã€‚åœ¨åŸºå‡†å¤šæ™ºèƒ½ä½“ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œå¹³å‡æ€§èƒ½æé«˜äº†6.5%ï¼Œä¸ºè‡ªä¸»å·¥ä½œæµç¨‹å¯é æ€§å»ºç«‹äº†æ–°çš„æœ€æ–°æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13815v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹å¤šæ™ºèƒ½ä½“å·¥ä½œæµå­˜åœ¨è¯¯å·®ä¼ æ’­å’Œè´¨é‡ä¸‹é™çš„å†…åœ¨è„†å¼±æ€§ï¼Œä¸‹æ¸¸æ™ºèƒ½ä½“å¯èƒ½æ”¾å¤§ä¸Šæ¸¸é”™è¯¯ï¼Œä¸”ç¼ºä¹çº æ­£æœºåˆ¶ã€‚æˆ‘ä»¬æå‡ºäº†COCOï¼ˆå…·å¤‡æŒç»­ç›‘æ§çš„è®¤çŸ¥æ“ä½œç³»ç»Ÿï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç†è®ºåŸºç¡€çš„æ¡†æ¶ï¼Œåœ¨å¤šæ™ºèƒ½ä½“é©±åŠ¨ç³»ç»Ÿä¸­å®ç°å¼‚æ­¥è‡ªæˆ‘ç›‘æ§å’Œè‡ªé€‚åº”é”™è¯¯æ ¡æ­£ã€‚COCOé€šè¿‡æ–°é¢–çš„è§£è€¦æ¶æ„è§£å†³äº†è´¨é‡ä¿è¯å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´çš„åŸºæœ¬æƒè¡¡ï¼Œåˆ†ç¦»é”™è¯¯æ£€æµ‹ä¸å…³é”®æ‰§è¡Œè·¯å¾„ï¼Œå®ç°äº†ç›¸å¯¹äºå·¥ä½œæµç¨‹å¤æ‚æ€§çš„O(1)ç›‘æ§å¼€é”€ã€‚COCOé€šè¿‡ä¸‰ä¸ªæ ¸å¿ƒç®—æ³•åˆ›æ–°è§£å†³ç³»ç»Ÿæ€§å’Œéšæœºæ€§é”™è¯¯ï¼šï¼ˆ1ï¼‰ä¸Šä¸‹æ–‡å›æ»šæœºåˆ¶â€”â€”æœ‰çŠ¶æ€é‡å¯åè®®ä¿ç•™æ‰§è¡Œå†å²å’Œé”™è¯¯è¯Šæ–­ï¼Œå®ç°çŸ¥æƒ…é‡æ–°è®¡ç®—è€Œéç›²ç›®é‡è¯•ï¼›ï¼ˆ2ï¼‰åŒå‘åå°„åè®®â€”â€”ç›‘æ§å’Œæ‰§è¡Œæ¨¡å—ä¹‹é—´çš„ç›¸äº’éªŒè¯ç³»ç»Ÿï¼Œé˜²æ­¢æŒ¯è¡è¡Œä¸ºå¹¶ç¡®ä¿æ”¶æ•›ï¼›ï¼ˆ3ï¼‰å¼‚è´¨äº¤å‰éªŒè¯â€”â€”åˆ©ç”¨æ¨¡å‹å¤šæ ·æ€§æ£€æµ‹ç³»ç»Ÿæ€§åè§å’Œå¹»è§‰ï¼Œé€šè¿‡ç¾¤ä½“åˆ†æ­§æŒ‡æ ‡ã€‚åœ¨åŸºå‡†å¤šæ™ºèƒ½ä½“ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜å¹³å‡æ€§èƒ½æé«˜äº†6.5%ï¼Œä¸ºè‡ªä¸»å·¥ä½œæµå¯é æ€§å»ºç«‹äº†æ–°çš„æŠ€æœ¯é¢†å…ˆåœ°ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹å¤šæ™ºèƒ½ä½“å·¥ä½œæµå­˜åœ¨è¯¯å·®ä¼ æ’­å’Œè´¨é‡ä¸‹é™çš„é£é™©ã€‚</li>
<li>COCOæ¡†æ¶é€šè¿‡å¼‚æ­¥è‡ªæˆ‘ç›‘æ§å’Œè‡ªé€‚åº”é”™è¯¯æ ¡æ­£æ¥å¢å¼ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç¨³å¥æ€§ã€‚</li>
<li>COCOé€šè¿‡è§£è€¦æ¶æ„å®ç°è´¨é‡ä¿è¯å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>COCOé‡‡ç”¨ä¸Šä¸‹æ–‡å›æ»šæœºåˆ¶æ¥é‡å¯å¹¶ä¿ç•™æ‰§è¡Œå†å²å’Œé”™è¯¯è¯Šæ–­ã€‚</li>
<li>åŒå‘åå°„åè®®ç¡®ä¿æ™ºèƒ½ä½“ä¹‹é—´çš„æœ‰æ•ˆç›¸äº’éªŒè¯å’Œæ”¶æ•›ã€‚</li>
<li>COCOåˆ©ç”¨å¼‚è´¨äº¤å‰éªŒè¯åˆ©ç”¨æ¨¡å‹å¤šæ ·æ€§æ¥æé«˜æ£€æµ‹é”™è¯¯çš„æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13815">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4928863d44849785b34cf05883c93ee4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c93b3152c2b5b829ae2f9faceb856128.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0aad15d985eb723d8856f01ff5d7053d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0614689a5a52653cc20c2ebe9a2e273.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c1365f8535e6b839f2d7fb9f9cbfbc0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e2c971a1bbdf4af6b919441df09c899.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BetaWeb-Towards-a-Blockchain-enabled-Trustworthy-Agentic-Web"><a href="#BetaWeb-Towards-a-Blockchain-enabled-Trustworthy-Agentic-Web" class="headerlink" title="BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web"></a>BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web</h2><p><strong>Authors:Zihan Guo, Yuanjian Zhou, Chenyi Wang, Linlin You, Minjie Bian, Weinan Zhang</strong></p>
<p>The rapid development of large language models (LLMs) has significantly propelled the development of artificial intelligence (AI) agents, which are increasingly evolving into diverse autonomous entities, advancing the LLM-based multi-agent systems (LaMAS). However, current agentic ecosystems remain fragmented and closed. Establishing an interconnected and scalable paradigm for Agentic AI has become a critical prerequisite. Although Agentic Web proposes an open architecture to break the ecosystem barriers, its implementation still faces core challenges such as privacy protection, data management, and value measurement. Existing centralized or semi-centralized paradigms suffer from inherent limitations, making them inadequate for supporting large-scale, heterogeneous, and cross-domain autonomous interactions. To address these challenges, this paper introduces the blockchain-enabled trustworthy Agentic Web (BetaWeb). By leveraging the inherent strengths of blockchain, BetaWeb not only offers a trustworthy and scalable infrastructure for LaMAS but also has the potential to advance the Web paradigm from Web3 (centered on data ownership) towards Web3.5, which emphasizes ownership of agent capabilities and the monetization of intelligence. Beyond a systematic examination of the BetaWeb framework, this paper presents a five-stage evolutionary roadmap, outlining the path of LaMAS from passive execution to advanced collaboration and autonomous governance. We also conduct a comparative analysis of existing products and discuss key challenges of BetaWeb from multiple perspectives. Ultimately, we argue that deep integration between blockchain and LaMAS can lay the foundation for a resilient, trustworthy, and sustainably incentivized digital ecosystem. A summary of the enabling technologies for each stage is available at <a target="_blank" rel="noopener" href="https://github.com/MatZaharia/BetaWeb">https://github.com/MatZaharia/BetaWeb</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•æå¤§åœ°æ¨åŠ¨äº†äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä»£ç†çš„å‘å±•ï¼Œè¿™äº›ä»£ç†æ­£é€æ¸æ¼”å˜ä¸ºå¤šæ ·åŒ–çš„è‡ªä¸»å®ä½“ï¼Œæ¨åŠ¨äº†åŸºäºLLMçš„å¤šä»£ç†ç³»ç»Ÿï¼ˆLaMASï¼‰çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå½“å‰çš„ä»£ç†ç”Ÿæ€ç³»ç»Ÿä»ç„¶å‘ˆç°ç¢ç‰‡åŒ–å’Œå°é—­çŠ¶æ€ã€‚å»ºç«‹äº’è”å’Œå¯æ‰©å±•çš„ä»£ç†æ™ºèƒ½AIèŒƒå¼å·²æˆä¸ºå…³é”®å‰æã€‚å°½ç®¡ä»£ç†Webæå‡ºäº†ä¸€ç§å¼€æ”¾æ¶æ„æ¥æ‰“ç ´ç”Ÿæ€ç³»ç»Ÿéšœç¢ï¼Œä½†å…¶å®ç°ä»é¢ä¸´éšç§ä¿æŠ¤ã€æ•°æ®ç®¡ç†å’Œä»·å€¼è¡¡é‡ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç°æœ‰çš„é›†ä¸­åŒ–æˆ–åŠé›†ä¸­åŒ–èŒƒå¼å­˜åœ¨å›ºæœ‰å±€é™æ€§ï¼Œéš¾ä»¥æ”¯æŒå¤§è§„æ¨¡ã€å¼‚è´¨ã€è·¨åŸŸè‡ªä¸»äº¤äº’ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡å¼•å…¥äº†åŒºå—é“¾èµ‹èƒ½çš„å¯ä¿¡ä»£ç†Webï¼ˆBetaWebï¼‰ã€‚é€šè¿‡åˆ©ç”¨åŒºå—é“¾çš„å›ºæœ‰ä¼˜åŠ¿ï¼ŒBetaWebä¸ä»…ä¸ºLaMASæä¾›äº†å¯ä¿¡å’Œå¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ï¼Œè€Œä¸”è¿˜æœ‰æ½œåŠ›å°†WebèŒƒå¼ä»ä»¥æ•°æ®æ‰€æœ‰æƒä¸ºä¸­å¿ƒçš„Web3æ¨å‘å¼ºè°ƒä»£ç†èƒ½åŠ›æ‰€æœ‰æƒå’Œæ™ºèƒ½åŒ–è´§å¸åŒ–çš„Web3.5ã€‚æœ¬æ–‡ä¸ä»…ç³»ç»Ÿæ£€æŸ¥äº†BetaWebæ¡†æ¶ï¼Œè¿˜æå‡ºäº†ä¸€ä¸ªäº”é˜¶æ®µè¿›åŒ–è·¯çº¿å›¾ï¼Œæ¦‚è¿°äº†LaMASä»è¢«åŠ¨æ‰§è¡Œåˆ°é«˜çº§åä½œå’Œè‡ªä¸»æ²»ç†çš„è·¯å¾„ã€‚æˆ‘ä»¬è¿˜å¯¹ç°æœ‰äº§å“è¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼Œå¹¶ä»å¤šä¸ªè§’åº¦è®¨è®ºäº†BetaWebçš„å…³é”®æŒ‘æˆ˜ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬è®¤ä¸ºåŒºå—é“¾å’ŒLaMASä¹‹é—´çš„æ·±åº¦é›†æˆå¯ä»¥ä¸ºæœ‰éŸ§æ€§ã€å¯ä¿¡ã€å¯æŒç»­æ¿€åŠ±çš„æ•°å­—ç”Ÿæ€ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚æœ‰å…³æ¯ä¸ªé˜¶æ®µçš„èµ‹èƒ½æŠ€æœ¯æ€»ç»“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MatZaharia/BetaWeb">https://github.com/MatZaharia/BetaWeb</a>å¤„æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13787v1">PDF</a> A technical report with 21 pages, 3 figures, and 3 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•æ¨åŠ¨äº†äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä»£ç†çš„å¤šæ ·åŒ–å‘å±•ï¼Œä¿ƒè¿›äº†åŸºäºLLMçš„å¤šä»£ç†ç³»ç»Ÿï¼ˆLaMASï¼‰çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†ç”Ÿæ€ç³»ç»Ÿä»ç„¶å‘ˆç°ç¢ç‰‡åŒ–å’Œå°é—­çŠ¶æ€ã€‚å»ºç«‹äº’è”äº’é€šçš„ä»£ç†AIèŒƒå¼å·²æˆä¸ºå…³é”®å‰æã€‚å°½ç®¡Agentic Webæå‡ºäº†å¼€æ”¾æ¶æ„æ¥æ‰“ç ´ç”Ÿæ€ç³»ç»Ÿå£å’ï¼Œä½†å…¶å®ç°ä»é¢ä¸´éšç§ä¿æŠ¤ã€æ•°æ®ç®¡ç†å’Œä»·å€¼è¡¡é‡ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡å¼•å…¥äº†åŒºå—é“¾èµ‹èƒ½çš„å¯ä¿¡Agentic Webï¼ˆBetaWebï¼‰ã€‚BetaWebä¸ä»…ä¸ºLaMASæä¾›äº†å¯ä¿¡å’Œå¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ï¼Œè¿˜æœ‰æ½œåŠ›å°†WebèŒƒå¼ä»ä»¥æ•°æ®æ‰€æœ‰æƒä¸ºä¸­å¿ƒçš„Web3æ¨å‘å¼ºè°ƒä»£ç†èƒ½åŠ›æ‰€æœ‰æƒå’Œæ™ºèƒ½åŒ–è´§å¸åŒ–çš„Web3.5ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•æ¨åŠ¨äº†äººå·¥æ™ºèƒ½ä»£ç†çš„è‡ªä¸»å‘å±•ã€‚</li>
<li>å½“å‰AIä»£ç†ç”Ÿæ€ç³»ç»Ÿå­˜åœ¨ç¢ç‰‡åŒ–å’Œå°é—­çš„é—®é¢˜ã€‚</li>
<li>Agentic Webè™½æå‡ºå¼€æ”¾æ¶æ„ï¼Œä½†å®æ–½ä¸­é¢ä¸´éšç§ä¿æŠ¤ã€æ•°æ®ç®¡ç†å’Œä»·å€¼è¡¡é‡ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚</li>
<li>åŒºå—é“¾èµ‹èƒ½çš„å¯ä¿¡Agentic Webï¼ˆBetaWebï¼‰ä¸ºè§£å†³è¿™äº›é—®é¢˜æä¾›äº†æ–¹æ¡ˆã€‚</li>
<li>BetaWebä¸ºLaMASæä¾›äº†å¯ä¿¡å’Œå¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ï¼Œå¹¶æœ‰æœ›æ¨åŠ¨WebèŒƒå¼å‘Web3.5è½¬å˜ã€‚</li>
<li>BetaWebæ¡†æ¶åŒ…å«ä¸€ä¸ªäº”é˜¶æ®µçš„è¿›åŒ–è·¯çº¿å›¾ï¼Œä»è¢«åŠ¨æ‰§è¡Œåˆ°é«˜çº§åä½œå’Œè‡ªä¸»æ²»ç†ã€‚</li>
<li>æ·±åº¦æ•´åˆåŒºå—é“¾å’ŒLaMASå¯ä»¥ä¸ºæœ‰éŸ§æ€§çš„ã€å¯ä¿¡çš„ã€å¯æŒç»­æ¿€åŠ±çš„æ•°å­—åŒ–ç”Ÿæ€ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13787">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-03c16524bf47fe61d7f94f758c92d81d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac3df7e92896bf32d105dc80eeb1603c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b19db22044b2f3dd32cf679434010b27.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Self-Organizing-Agent-Network-for-LLM-based-Workflow-Automation"><a href="#Self-Organizing-Agent-Network-for-LLM-based-Workflow-Automation" class="headerlink" title="Self-Organizing Agent Network for LLM-based Workflow Automation"></a>Self-Organizing Agent Network for LLM-based Workflow Automation</h2><p><strong>Authors:Yiming Xiong, Jian Wang, Bing Li, Yuhan Zhu, Yuqi Zhao</strong></p>
<p>Recent multi-agent frameworks built upon large language models (LLMs) have demonstrated remarkable capabilities in complex task planning. However, in real-world enterprise environments, business workflows are typically composed through modularization and reuse of numerous subprocesses, resulting in intricate workflows characterized by lengthy and deeply nested execution paths. Such complexity poses significant challenges for LLM-driven orchestration, as extended reasoning chains and state-space explosions severely impact planning effectiveness and the proper sequencing of tool invocations. Therefore, developing an orchestration method with controllable structures capable of handling multi-layer nesting becomes a critical issue. To address this, we propose a novel structure-driven orchestration framework Self-Organizing Agent Network (SOAN). SOAN incrementally builds a formalized agent network by identifying and encapsulating structural units as independent agents, enhancing modularity and clarity in orchestration. Extensive evaluations were performed using multiple benchmarks as well as a real-world enterprise workflow dataset. Experimental results demonstrate that SOAN significantly outperforms state-of-the-art methods in terms of adaptability, fault tolerance, and execution efficiency. </p>
<blockquote>
<p>æœ€è¿‘å»ºç«‹åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¹‹ä¸Šçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶åœ¨å¤æ‚ä»»åŠ¡è§„åˆ’æ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨çœŸå®çš„ä¼ä¸šç¯å¢ƒä¸­ï¼Œä¸šåŠ¡å·¥ä½œæµç¨‹é€šå¸¸æ˜¯é€šè¿‡æ¨¡å—åŒ–å¹¶é‡å¤ä½¿ç”¨è®¸å¤šå­æµç¨‹æ¥ç»„æˆçš„ï¼Œè¿™å¯¼è‡´äº†ä»¥æ¼«é•¿ä¸”æ·±åº¦åµŒå¥—çš„æ‰§è¡Œè·¯å¾„ä¸ºç‰¹å¾çš„å¤æ‚å·¥ä½œæµç¨‹ã€‚è¿™ç§å¤æ‚æ€§ç»™LLMé©±åŠ¨çš„ç¼–æ’å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºæ‰©å±•çš„æ¨ç†é“¾å’ŒçŠ¶æ€ç©ºé—´çˆ†ç‚¸ä¸¥é‡å½±å“äº†è§„åˆ’çš„æœ‰æ•ˆæ€§å’Œå·¥å…·è°ƒç”¨çš„é€‚å½“æ’åºã€‚å› æ­¤ï¼Œå¼€å‘å…·æœ‰å¯æ§ç»“æ„å¹¶èƒ½å¤Ÿå¤„ç†å¤šå±‚åµŒå¥—é—®é¢˜çš„ç¼–æ’æ–¹æ³•æˆä¸ºäº†ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„ç»“æ„é©±åŠ¨ç¼–æ’æ¡†æ¶â€”â€”è‡ªç»„ç»‡æ™ºèƒ½ä½“ç½‘ç»œï¼ˆSOANï¼‰ã€‚SOANé€šè¿‡è¯†åˆ«å’Œå°è£…ç»“æ„å•å…ƒä½œä¸ºç‹¬ç«‹æ™ºèƒ½ä½“æ¥é€æ­¥æ„å»ºå½¢å¼åŒ–çš„æ™ºèƒ½ä½“ç½‘ç»œï¼Œæé«˜äº†ç¼–æ’çš„æ¨¡å—åŒ–å’Œæ¸…æ™°åº¦ã€‚æˆ‘ä»¬ä½¿ç”¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä»¥åŠçœŸå®ä¼ä¸šå·¥ä½œæµç¨‹æ•°æ®é›†è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSOANåœ¨é€‚åº”æ€§ã€å®¹é”™æ€§å’Œæ‰§è¡Œæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13732v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»£ç†æ¡†æ¶åœ¨å¤æ‚ä»»åŠ¡è§„åˆ’æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨ä¼ä¸šå®é™…ç¯å¢ƒä¸­ï¼Œä¸šåŠ¡æµç¨‹é€šå¸¸é€šè¿‡æ¨¡å—åŒ–å’Œé‡ç”¨å¤šä¸ªå­æµç¨‹æ¥æ„å»ºï¼Œå½¢æˆå…·æœ‰å¤æ‚åµŒå¥—æ‰§è¡Œè·¯å¾„çš„ç²¾ç»†å·¥ä½œæµç¨‹ã€‚è¿™ç§å¤æ‚æ€§ç»™LLMé©±åŠ¨çš„ååŒå·¥ä½œå¸¦æ¥äº†æŒ‘æˆ˜ï¼Œå› ä¸ºæ‰©å±•çš„æ¨ç†é“¾å’ŒçŠ¶æ€ç©ºé—´çš„çˆ†ç‚¸ä¸¥é‡å½±å“äº†è§„åˆ’çš„æœ‰æ•ˆæ€§å’Œå·¥å…·è°ƒç”¨çš„æ­£ç¡®æ’åºã€‚å› æ­¤ï¼Œå¼€å‘å…·æœ‰å¯æ§ç»“æ„ã€èƒ½å¤Ÿå¤„ç†å¤šå±‚åµŒå¥—é—®é¢˜çš„ååŒæ–¹æ³•æˆä¸ºäº†ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç»“æ„é©±åŠ¨ååŒå·¥ä½œæ¡†æ¶â€”â€”è‡ªç»„ç»‡ä»£ç†ç½‘ç»œï¼ˆSOANï¼‰ã€‚SOANé€šè¿‡è¯†åˆ«å¹¶å°è£…ç»“æ„å•å…ƒä¸ºç‹¬ç«‹ä»£ç†æ¥æ„å»ºå½¢å¼åŒ–ä»£ç†ç½‘ç»œï¼Œæé«˜äº†ååŒå·¥ä½œçš„æ¨¡å—åŒ–å’Œæ¸…æ™°åº¦ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä»¥åŠçœŸå®ä¼ä¸šå·¥ä½œæµç¨‹æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSOANåœ¨é€‚åº”æ€§ã€å®¹é”™æ€§å’Œæ‰§è¡Œæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤šä»£ç†æ¡†æ¶åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡è§„åˆ’ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚</li>
<li>ä¼ä¸šå®é™…ç¯å¢ƒä¸­çš„ä¸šåŠ¡æµç¨‹å…·æœ‰å¤æ‚ä¸”ç²¾ç»†çš„å·¥ä½œæµç¨‹ç‰¹ç‚¹ã€‚</li>
<li>LLMé©±åŠ¨çš„ååŒå·¥ä½œé¢ä¸´æ‰©å±•æ¨ç†é“¾å’ŒçŠ¶æ€ç©ºé—´çˆ†ç‚¸çš„æŒ‘æˆ˜ã€‚</li>
<li>å¤„ç†å¤šå±‚åµŒå¥—é—®é¢˜çš„ååŒæ–¹æ³•å¼€å‘æˆä¸ºå…³é”®éœ€æ±‚ã€‚</li>
<li>è‡ªç»„ç»‡ä»£ç†ç½‘ç»œï¼ˆSOANï¼‰é€šè¿‡æ„å»ºå½¢å¼åŒ–ä»£ç†ç½‘ç»œæé«˜ååŒå·¥ä½œçš„æ¨¡å—åŒ–å’Œæ¸…æ™°åº¦ã€‚</li>
<li>SOANåœ¨é€‚åº”æ€§ã€å®¹é”™æ€§å’Œæ‰§è¡Œæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13732">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-be5d90d3eca0262db35a3b13352afdfb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb9e9243286486e6f0c5a4bb125775fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5092bde171efe1be6652f279a990c78d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c39175bd1e840f97f4fd38e95397e9f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c7bd537915b5695908accc1cfb5f15c5.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MACTAS-Self-Attention-Based-Module-for-Inter-Agent-Communication-in-Multi-Agent-Reinforcement-Learning"><a href="#MACTAS-Self-Attention-Based-Module-for-Inter-Agent-Communication-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="MACTAS: Self-Attention-Based Module for Inter-Agent Communication in   Multi-Agent Reinforcement Learning"></a>MACTAS: Self-Attention-Based Module for Inter-Agent Communication in   Multi-Agent Reinforcement Learning</h2><p><strong>Authors:Maciej Wojtala, Bogusz StefaÅ„czyk, Dominik Bogucki, Åukasz Lepak, Jakub Strykowski, PaweÅ‚ WawrzyÅ„ski</strong></p>
<p>Communication is essential for the collective execution of complex tasks by human agents, motivating interest in communication mechanisms for multi-agent reinforcement learning (MARL). However, existing communication protocols in MARL are often complex and non-differentiable. In this work, we introduce a self-attention-based communication module that exchanges information between the agents in MARL. Our proposed approach is fully differentiable, allowing agents to learn to generate messages in a reward-driven manner. The module can be seamlessly integrated with any action-value function decomposition method and can be viewed as an extension of such decompositions. Notably, it includes a fixed number of trainable parameters, independent of the number of agents. Experimental results on the SMAC benchmark demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on several maps. </p>
<blockquote>
<p>åœ¨äººç±»æ™ºèƒ½ä½“æ‰§è¡Œå¤æ‚ä»»åŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œæ²Ÿé€šæ˜¯è‡³å…³é‡è¦çš„ï¼Œè¿™ä¹Ÿæ¿€å‘äº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­æ²Ÿé€šæœºåˆ¶çš„å…´è¶£ã€‚ç„¶è€Œï¼Œç°æœ‰çš„MARLé€šä¿¡åè®®é€šå¸¸å¤æ‚ä¸”ä¸å¯å¾®åˆ†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„é€šä¿¡æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥åœ¨MARLä¸­æ™ºèƒ½ä½“ä¹‹é—´äº¤æ¢ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•æ˜¯å®Œå…¨å¯å¾®åˆ†çš„ï¼Œå…è®¸æ™ºèƒ½ä½“ä»¥å¥–åŠ±é©±åŠ¨çš„æ–¹å¼å­¦ä¹ ç”Ÿæˆæ¶ˆæ¯ã€‚è¯¥æ¨¡å—å¯ä»¥æ— ç¼åœ°é›†æˆåˆ°ä»»ä½•åŠ¨ä½œä»·å€¼å‡½æ•°åˆ†è§£æ–¹æ³•ä¸­ï¼Œå¹¶ä¸”å¯ä»¥è¢«è§†ä¸ºæ­¤ç±»åˆ†è§£çš„æ‰©å±•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå®ƒåŒ…å«å›ºå®šæ•°é‡çš„å¯è®­ç»ƒå‚æ•°ï¼Œä¸æ™ºèƒ½ä½“çš„æ•°é‡æ— å…³ã€‚åœ¨SMACåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåœ°å›¾ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13661v1">PDF</a> Submitted for AAAI 2026</p>
<p><strong>æ€»ç»“</strong></p>
<p>åœ¨å¤šå˜ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œé€šä¿¡å¯¹äºäººç±»ä»£ç†äººå…±åŒå®Œæˆå¤æ‚ä»»åŠ¡è‡³å…³é‡è¦ã€‚ç°æœ‰é€šä¿¡åè®®å¾€å¾€å¤æ‚ä¸”ä¸å¯å¾®åˆ†ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„é€šä¿¡æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥åœ¨MARLä¸­äº¤æ¢ä»£ç†ä¹‹é—´çš„ä¿¡æ¯ã€‚æ‰€æå‡ºçš„é€šä¿¡æ¨¡å—å®Œå…¨å¯å¾®åˆ†ï¼Œå…è®¸ä»£ç†ä»¥å¥–åŠ±é©±åŠ¨çš„æ–¹å¼å­¦ä¹ ç”Ÿæˆæ¶ˆæ¯ã€‚è¯¥æ¨¡å—å¯ä»¥æ— ç¼é›†æˆåˆ°ä»»ä½•åŠ¨ä½œä»·å€¼å‡½æ•°åˆ†è§£æ–¹æ³•ä¸­ï¼Œå¹¶ä¸”å¯ä»¥è¢«è§†ä¸ºæ­¤ç±»åˆ†è§£çš„æ‰©å±•ã€‚ç‰¹åˆ«çš„æ˜¯ï¼Œå®ƒçš„è®­ç»ƒå‚æ•°æ•°é‡å›ºå®šï¼Œä¸ä»£ç†çš„æ•°é‡æ— å…³ã€‚åœ¨SMACåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåœ°å›¾ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>é€šä¿¡åœ¨å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­å®Œæˆå¤æ‚ä»»åŠ¡æ—¶è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰é€šä¿¡åè®®é€šå¸¸å¤æ‚ä¸”ä¸å¯å¾®åˆ†ï¼Œé™åˆ¶äº†ä»£ç†çš„å­¦ä¹ èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„é€šä¿¡æ¨¡å—ï¼Œå®ç°äº†ä»£ç†ä¹‹é—´çš„ä¿¡æ¯äº¤æ¢ã€‚</li>
<li>è¯¥é€šä¿¡æ¨¡å—å®Œå…¨å¯å¾®åˆ†ï¼Œå…è®¸ä»¥å¥–åŠ±é©±åŠ¨çš„æ–¹å¼å­¦ä¹ ç”Ÿæˆæ¶ˆæ¯ã€‚</li>
<li>é€šä¿¡æ¨¡å—å¯æ— ç¼é›†æˆåˆ°ä»»ä½•åŠ¨ä½œä»·å€¼å‡½æ•°åˆ†è§£æ–¹æ³•ä¸­ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å›ºå®šçš„è®­ç»ƒå‚æ•°æ•°é‡ï¼Œä¸ä»£ç†æ•°é‡æ— å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13661">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57a85f630d682e17c091adc4b0ed542a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57421fb36a31766ef85affab75a6bac6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac8d1caaddc478766fe5e12a6f2ef954.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb005e5b1172e0dbe1461b053edef4ee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6af07c23e0bc93fd4d1674d49fa55485.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Atom-Searcher-Enhancing-Agentic-Deep-Research-via-Fine-Grained-Atomic-Thought-Reward"><a href="#Atom-Searcher-Enhancing-Agentic-Deep-Research-via-Fine-Grained-Atomic-Thought-Reward" class="headerlink" title="Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic   Thought Reward"></a>Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic   Thought Reward</h2><p><strong>Authors:Yong Deng, Guoqing Wang, Zhenzhe Ying, Xiaofeng Wu, Jinzhen Lin, Wenwen Xiong, Yuqin Dai, Shuo Yang, Zhanwei Zhang, Qiwen Wang, Yang Qin, Changhua Meng</strong></p>
<p>Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°å‡ºå“è¶Šçš„è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œä½†ç”±äºé™æ€å†…éƒ¨çŸ¥è¯†ï¼Œå®ƒä»¬åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶é‡åˆ°å›°éš¾ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å¢å¼ºäº†è®¿é—®å¤–éƒ¨ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä½†ç”±äºåƒµåŒ–çš„å·¥ä½œæµç¨‹ï¼Œå®ƒåœ¨å¤šè·³æ¨ç†å’Œæˆ˜ç•¥æœç´¢æ–¹é¢ä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚æœ€è¿‘çš„ä»£ç†æ·±åº¦ç ”ç©¶çš„è¿›å±•ä½¿LLMèƒ½å¤Ÿè‡ªä¸»æ¨ç†ã€æœç´¢å’Œåˆæˆä¿¡æ¯ã€‚ç„¶è€Œï¼Œå½“å‰ä¾èµ–ç»“æœåŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•é¢ä¸´å…³é”®æ€§é—®é¢˜ï¼Œå¦‚æ¢¯åº¦å†²çªå’Œå¥–åŠ±ç¨€ç–ï¼Œè¿™é™åˆ¶äº†æ€§èƒ½æå‡å’Œè®­ç»ƒæ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºåŸå­æ€ç»´ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„LLMæ€è€ƒèŒƒå¼ï¼Œå°†æ¨ç†åˆ†è§£ä¸ºç²¾ç»†çš„åŠŸèƒ½å•å…ƒã€‚è¿™äº›å•å…ƒç”±æ¨ç†å¥–åŠ±æ¨¡å‹ï¼ˆRRMï¼‰ç›‘ç£ï¼Œä¸ºç²¾ç»†æŒ‡å¯¼æä¾›åŸå­æ€ç»´å¥–åŠ±ï¼ˆATRï¼‰ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†Atom-Searcherï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»£ç†æ·±åº¦ç ”ç©¶çš„æ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œèåˆäº†åŸå­æ€ç»´å’ŒATRã€‚Atom-Searcherä½¿ç”¨å—è¯¾ç¨‹å¯å‘å¥–åŠ±æ—¶é—´è¡¨ï¼Œä¼˜å…ˆåœ¨æ—©æœŸæä¾›è¿‡ç¨‹çº§çš„ATRï¼Œç„¶åè¿‡æ¸¡åˆ°ç»“æœå¥–åŠ±ï¼ŒåŠ å¿«å¯¹æœ‰æ•ˆæ¨ç†è·¯å¾„çš„æ”¶æ•›ã€‚åœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œå®ƒè¡¨ç°å‡ºæŒç»­çš„ä¸€è‡´æ€§æ”¹è¿›ã€‚ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰Atom-Searcheråœ¨æµ‹è¯•æ—¶æ‰©å¤§äº†è®¡ç®—è§„æ¨¡ã€‚ï¼ˆ2ï¼‰åŸå­æ€ç»´ä¸ºRRMæä¾›äº†ç›‘ç£é”šç‚¹ï¼Œæ¡¥æ¥äº†æ·±åº¦ç ”ç©¶ä»»åŠ¡å’ŒRRMã€‚ï¼ˆ3ï¼‰Atom-Searcherå±•ç°å‡ºæ›´å¯è§£é‡Šã€æ›´äººæ€§åŒ–çš„æ¨ç†æ¨¡å¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12800v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·æœ‰å‡ºè‰²çš„è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œä½†ç”±äºé™æ€å†…éƒ¨çŸ¥è¯†è€Œéš¾ä»¥åº”å¯¹å¤æ‚ä»»åŠ¡ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æé«˜äº†å¯¹å¤–éƒ¨ä¿¡æ¯çš„è®¿é—®èƒ½åŠ›ï¼Œä½†ç”±äºå·¥ä½œæµç¨‹åƒµåŒ–ï¼Œå®ƒåœ¨å¤šè·³æ¨ç†å’Œæˆ˜ç•¥æœç´¢æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚æœ€è¿‘çš„æ·±åº¦ç ”ç©¶ä¸­ï¼Œå‡ºç°äº†è‡ªä¸»æ¨ç†ã€æœç´¢å’Œåˆæˆä¿¡æ¯çš„ä»£ç†æ™ºèƒ½å¼ºåŒ–ç ”ç©¶ã€‚ç„¶è€Œï¼Œä¾èµ–ç»“æœå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•é¢ä¸´å…³é”®æŒ‘æˆ˜ï¼Œå¦‚æ¢¯åº¦å†²çªå’Œå¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼Œé™åˆ¶äº†æ€§èƒ½æå‡å’ŒåŸ¹è®­æ•ˆç‡ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåŸå­æ€ç»´ï¼ˆAtomic Thoughtï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„LLMæ€è€ƒèŒƒå¼ï¼Œå°†æ¨ç†åˆ†è§£ä¸ºç²¾ç»†çš„åŠŸèƒ½å•å…ƒï¼Œå¹¶ç”±æ¨ç†å¥–åŠ±æ¨¡å‹ï¼ˆRRMsï¼‰è¿›è¡Œç›‘ç£ï¼Œä¸ºç²¾ç»†çš„å¼•å¯¼æä¾›åŸå­æ€ç»´å¥–åŠ±ï¼ˆATRï¼‰ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†Atom-Searcherï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ·±åº¦ä»£ç†ç ”ç©¶çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆäº†åŸå­æ€ç»´å’ŒATRã€‚Atom-Searcheré‡‡ç”¨å¯å‘å¼æ•™å­¦å¥–åŠ±è®¡åˆ’ï¼Œæ—©æœŸä¾§é‡äºè¿‡ç¨‹çº§åˆ«çš„ATRï¼Œå¹¶é€æ­¥è¿‡æ¸¡åˆ°ç»“æœå¥–åŠ±ï¼Œä»¥åŠ é€Ÿåœ¨æœ‰æ•ˆæ¨ç†è·¯å¾„ä¸Šçš„æ”¶æ•›ã€‚å®éªŒè¡¨æ˜ï¼ŒAtom-Searcheråœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡å®ç°äº†å¯¹æœ€æ–°æŠ€æœ¯çš„æŒç»­æ”¹è¿›ã€‚å…¶å…³é”®ä¼˜åŠ¿åŒ…æ‹¬ï¼š1ï¼‰Atom-Searcheråœ¨è®¡ç®—è§„æ¨¡ä¸Šæœ‰æ‰€æ‰©å±•ï¼›2ï¼‰åŸå­æ€ç»´ä¸ºRRMsæä¾›äº†ç›‘ç£é”šç‚¹ï¼›3ï¼‰Atom-Searcherå±•ç°å‡ºæ›´å¯è§£é‡Šã€æ›´äººæ€§åŒ–çš„æ¨ç†æ¨¡å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·æœ‰å“è¶Šçš„è§£å†³é—®é¢˜èƒ½åŠ›ï¼Œä½†é¢å¯¹å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°æœ‰é™ã€‚</li>
<li>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æé«˜äº†å¤–éƒ¨ä¿¡æ¯è®¿é—®èƒ½åŠ›ï¼Œä½†åœ¨å¤šè·³æ¨ç†å’Œæˆ˜ç•¥æœç´¢æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>ç°æœ‰ä¾èµ–ç»“æœå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•é¢ä¸´æ¢¯åº¦å†²çªå’Œå¥–åŠ±ç¨€ç–æ€§é—®é¢˜ã€‚</li>
<li>åŸå­æ€ç»´ï¼ˆAtomic Thoughtï¼‰ä½œä¸ºä¸€ç§æ–°çš„LLMæ€è€ƒèŒƒå¼è¢«æå‡ºï¼Œå°†æ¨ç†åˆ†è§£ä¸ºç²¾ç»†åŠŸèƒ½å•å…ƒã€‚</li>
<li>æ¨ç†å¥–åŠ±æ¨¡å‹ï¼ˆRRMsï¼‰ç”¨äºç›‘ç£è¿™äº›åŠŸèƒ½å•å…ƒï¼Œæä¾›åŸå­æ€ç»´å¥–åŠ±ï¼ˆATRï¼‰ã€‚</li>
<li>Atom-Searcheræ¡†æ¶ç»“åˆäº†åŸå­æ€ç»´å’ŒATRï¼Œé‡‡ç”¨å¯å‘å¼æ•™å­¦å¥–åŠ±è®¡åˆ’æ¥åŠ é€Ÿæœ‰æ•ˆæ¨ç†è·¯å¾„çš„æ”¶æ•›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f17e48c16e8f9ec35d90c2f4034cb14f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d71e84c2ed3b992e40dd7cbadded5b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-847fe97327e36bfe692c937f850560ee.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="MedKGent-A-Large-Language-Model-Agent-Framework-for-Constructing-Temporally-Evolving-Medical-Knowledge-Graph"><a href="#MedKGent-A-Large-Language-Model-Agent-Framework-for-Constructing-Temporally-Evolving-Medical-Knowledge-Graph" class="headerlink" title="MedKGent: A Large Language Model Agent Framework for Constructing   Temporally Evolving Medical Knowledge Graph"></a>MedKGent: A Large Language Model Agent Framework for Constructing   Temporally Evolving Medical Knowledge Graph</h2><p><strong>Authors:Duzhen Zhang, Zixiao Wang, Zhong-Zhi Li, Yahan Yu, Shuncheng Jia, Jiahua Dong, Haotian Xu, Xing Wu, Yingying Zhang, Tielin Zhang, Jie Yang, Xiuying Chen, Le Song</strong></p>
<p>The rapid expansion of medical literature presents growing challenges for structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs) offer a promising solution by enabling efficient retrieval, automated reasoning, and knowledge discovery. However, current KG construction methods often rely on supervised pipelines with limited generalizability or naively aggregate outputs from Large Language Models (LLMs), treating biomedical corpora as static and ignoring the temporal dynamics and contextual uncertainty of evolving knowledge. To address these limitations, we introduce MedKGent, a LLM agent framework for constructing temporally evolving medical KGs. Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we simulate the emergence of biomedical knowledge via a fine-grained daily time series. MedKGent incrementally builds the KG in a day-by-day manner using two specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor Agent identifies knowledge triples and assigns confidence scores via sampling-based estimation, which are used to filter low-confidence extractions and inform downstream processing. The Constructor Agent incrementally integrates the retained triples into a temporally evolving graph, guided by confidence scores and timestamps to reinforce recurring knowledge and resolve conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational triples. Quality assessments by two SOTA LLMs and three domain experts demonstrate an accuracy approaching 90%, with strong inter-rater agreement. To evaluate downstream utility, we conduct RAG across seven medical question answering benchmarks using five leading LLMs, consistently observing significant improvements over non-augmented baselines. Case studies further demonstrate the KGâ€™s value in literature-based drug repurposing via confidence-aware causal inference. </p>
<blockquote>
<p>åŒ»å­¦æ–‡çŒ®çš„è¿…é€Ÿæ‰©å¼ ç»™å¤§è§„æ¨¡ç»“æ„åŒ–æ•´åˆé¢†åŸŸçŸ¥è¯†å¸¦æ¥äº†æ—¥ç›Šå¢é•¿çš„æŒ‘æˆ˜ã€‚çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰é€šè¿‡å®ç°é«˜æ•ˆæ£€ç´¢ã€è‡ªåŠ¨åŒ–æ¨ç†å’ŒçŸ¥è¯†å‘ç°ï¼Œæä¾›äº†å…·æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå½“å‰çš„çŸ¥è¯†å›¾è°±æ„å»ºæ–¹æ³•å¾€å¾€ä¾èµ–äºç›‘ç£ç®¡é“ï¼Œå…¶é€šç”¨æ€§æœ‰é™ï¼Œæˆ–è€…ç®€å•åœ°èšåˆæ¥è‡ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¾“å‡ºï¼Œå°†ç”Ÿç‰©åŒ»å­¦è¯­æ–™è§†ä¸ºé™æ€ï¼Œå¿½ç•¥äº†çŸ¥è¯†çš„æ—¶åŠ¨æ€å’Œä¸Šä¸‹æ–‡ä¸ç¡®å®šæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†MedKGentï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºæ—¶åºæ¼”åŒ–åŒ»å­¦çŸ¥è¯†å›¾è°±çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†æ¡†æ¶ã€‚åˆ©ç”¨1975å¹´è‡³2023å¹´é—´å‡ºç‰ˆçš„è¶…è¿‡1000ä¸‡ç¯‡PubMedæ‘˜è¦ï¼Œæˆ‘ä»¬é€šè¿‡ç²¾ç»†çš„æ¯æ—¥æ—¶é—´åºåˆ—æ¨¡æ‹Ÿç”Ÿç‰©åŒ»å­¦çŸ¥è¯†çš„æ¶Œç°ã€‚MedKGentä»¥æ—¥ä¸ºå•ä½é€æ­¥æ„å»ºçŸ¥è¯†å›¾è°±ï¼Œä½¿ç”¨ä¸¤ä¸ªç”±Qwen2.5-32B-Instructæ¨¡å‹é©±åŠ¨çš„ä¸“ä¸šä»£ç†ã€‚æå–ä»£ç†é€šè¿‡åŸºäºé‡‡æ ·çš„ä¼°è®¡æ¥è¯†åˆ«çŸ¥è¯†ä¸‰å…ƒç»„å¹¶åˆ†é…ç½®ä¿¡åº¦åˆ†æ•°ï¼Œè¿™äº›åˆ†æ•°ç”¨äºè¿‡æ»¤ä½ç½®ä¿¡åº¦çš„æå–å¹¶å‘ŠçŸ¥ä¸‹æ¸¸å¤„ç†ã€‚æ„é€ ä»£ç†é€æ­¥å°†ä¿ç•™çš„ä¸‰å…ƒç»„é›†æˆåˆ°éšæ—¶é—´æ¼”åŒ–çš„å›¾ä¸­ï¼Œå—ç½®ä¿¡åˆ†æ•°å’Œæ—¶é—´æˆ³çš„æŒ‡å¯¼ï¼Œä»¥åŠ å¼ºé‡å¤å‡ºç°çš„çŸ¥è¯†å¹¶è§£å†³å†²çªã€‚æ‰€å¾—çŸ¥è¯†å›¾è°±åŒ…å«156,275ä¸ªå®ä½“å’Œ2,971,384ä¸ªå…³ç³»ä¸‰å…ƒç»„ã€‚ä¸¤ä½é¡¶å°–çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸“å®¶å’Œä¸‰ä½é¢†åŸŸä¸“å®¶è¿›è¡Œçš„è´¨é‡è¯„ä¼°æ˜¾ç¤ºï¼Œå…¶å‡†ç¡®ç‡æ¥è¿‘90%ï¼Œå¹¶ä¸”å…·æœ‰å¼ºå¤§çš„å†…éƒ¨ä¸€è‡´æ€§ã€‚ä¸ºäº†è¯„ä¼°ä¸‹æ¸¸å®ç”¨æ€§ï¼Œæˆ‘ä»¬åœ¨ä¸ƒä¸ªåŒ»å­¦é—®ç­”åŸºå‡†ä¸Šè¿›è¡Œäº†RAGæµ‹è¯•ï¼Œä½¿ç”¨äº”ä¸ªé¢†å…ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸éå¢å¼ºåŸºçº¿ç›¸æ¯”ï¼Œå…¶è¡¨ç°ä¸€ç›´è¡¨ç°å‡ºæ˜¾ç€æé«˜ã€‚æ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†çŸ¥è¯†å›¾è°±åœ¨åŸºäºæ–‡çŒ®çš„è¯ç‰©å†åˆ©ç”¨æ–¹é¢çš„ä»·å€¼ï¼Œå³é€šè¿‡ä¿¡å¿ƒæ„ŸçŸ¥çš„å› æœæ¨ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12393v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŒ»å­¦æ–‡çŒ®çš„å¿«é€Ÿæ‰©å¼ å¸¦æ¥çš„æŒ‘æˆ˜ä»¥åŠçŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä½œä¸ºè§£å†³æ–¹æ¡ˆçš„æ½œåŠ›ã€‚é’ˆå¯¹ç°æœ‰KGæ„å»ºæ–¹æ³•çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„MedKGentæ¡†æ¶ï¼Œç”¨äºæ„å»ºéšæ—¶é—´æ¼”åŒ–çš„åŒ»ç–—KGã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¶…è¿‡1000ä¸‡ç¯‡PubMedæ‘˜è¦ï¼Œé€šè¿‡ç²¾ç»†çš„æ—¶é—´åºåˆ—æ¨¡æ‹Ÿç”Ÿç‰©åŒ»å­¦çŸ¥è¯†çš„æ¶Œç°ã€‚MedKGenté€šè¿‡ä¸¤ä¸ªä¸“ä¸šä»£ç†ä»¥æ—¥å¤ä¸€æ—¥çš„æ–¹å¼æ„å»ºKGï¼Œä¸€ä¸ªæå–ä»£ç†ç”¨äºè¯†åˆ«çŸ¥è¯†ä¸‰å…ƒç»„å¹¶åˆ†é…ç½®ä¿¡åº¦åˆ†æ•°ï¼Œä¸€ä¸ªæ„é€ ä»£ç†åˆ™å°†è¿™äº›ä¿ç•™çš„ä¸‰å…ƒç»„é€æ¸èå…¥æ—¶é—´æ¼”åŒ–å›¾è°±ä¸­ã€‚æœ€ç»ˆæ„å»ºçš„KGåŒ…å«å¤§é‡å®ä½“å’Œå…³ç³»ä¸‰å…ƒç»„ï¼Œä¸”å‡†ç¡®ç‡é«˜ï¼Œè¯„ä»·æ•ˆæœå¥½ã€‚å…¶åº”ç”¨åœºæ™¯å¹¿æ³›ï¼Œæœ‰åŠ©äºåŒ»å­¦é—®ç­”å’ŒçŸ¥è¯†å‘ç°ã€‚é€šè¿‡å®è¯ç ”ç©¶è¯æ˜å…¶æ½œåŠ›å·¨å¤§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŒ»å­¦æ–‡çŒ®çš„å¿«é€Ÿæ‰©å¼ å¯¼è‡´ç»“æ„åŒ–æ•´åˆå¤§è§„æ¨¡é¢†åŸŸçŸ¥è¯†çš„æŒ‘æˆ˜å¢åŠ ã€‚</li>
<li>çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜æä¾›äº†æœ‰æ•ˆæ–¹æ³•ï¼ŒåŒ…æ‹¬é«˜æ•ˆæ£€ç´¢ã€è‡ªåŠ¨åŒ–æ¨ç†å’ŒçŸ¥è¯†å‘ç°ç­‰åŠŸèƒ½ã€‚</li>
<li>å½“å‰KGæ„å»ºæ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œå¦‚ä¾èµ–ç›‘ç£ç®¡é“æœ‰é™çš„æ³›åŒ–èƒ½åŠ›æˆ–ç®€å•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è€Œå¿½è§†çŸ¥è¯†çš„åŠ¨æ€å˜åŒ–å’Œä¸Šä¸‹æ–‡ä¸ç¡®å®šæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12393">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-749059c83d3198f9a7b5009a295065b1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a260abf342b79a593eb206b523566880.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6664d6518ec6f482a881b255c56ce532.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="A-Survey-of-LLM-based-Deep-Search-Agents-Paradigm-Optimization-Evaluation-and-Challenges"><a href="#A-Survey-of-LLM-based-Deep-Search-Agents-Paradigm-Optimization-Evaluation-and-Challenges" class="headerlink" title="A Survey of LLM-based Deep Search Agents: Paradigm, Optimization,   Evaluation, and Challenges"></a>A Survey of LLM-based Deep Search Agents: Paradigm, Optimization,   Evaluation, and Challenges</h2><p><strong>Authors:Yunjia Xi, Jianghao Lin, Yongzhao Xiao, Zheli Zhou, Rong Shan, Te Gao, Jiachen Zhu, Weiwen Liu, Yong Yu, Weinan Zhang</strong></p>
<p>The advent of Large Language Models (LLMs) has significantly revolutionized web search. The emergence of LLM-based Search Agents marks a pivotal shift towards deeper, dynamic, autonomous information seeking. These agents can comprehend user intentions and environmental context and execute multi-turn retrieval with dynamic planning, extending search capabilities far beyond the web. Leading examples like OpenAIâ€™s Deep Research highlight their potential for deep information mining and real-world applications. This survey provides the first systematic analysis of search agents. We comprehensively analyze and categorize existing works from the perspectives of architecture, optimization, application, and evaluation, ultimately identifying critical open challenges and outlining promising future research directions in this rapidly evolving field. Our repository is available on <a target="_blank" rel="noopener" href="https://github.com/YunjiaXi/Awesome-Search-Agent-Papers">https://github.com/YunjiaXi/Awesome-Search-Agent-Papers</a>. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œç½‘ç»œæœç´¢å‘ç”Ÿäº†é‡å¤§å˜é©ã€‚åŸºäºLLMçš„æœç´¢ä»£ç†äººçš„æ¶Œç°ï¼Œæ ‡å¿—ç€å‘æ›´æ·±å±‚æ¬¡ã€æ›´åŠ¨æ€ã€æ›´è‡ªä¸»çš„ä¿¡æ¯æœç´¢æ–¹å‘çš„é‡å¤§è½¬å˜ã€‚è¿™äº›ä»£ç†äººèƒ½å¤Ÿç†è§£ç”¨æˆ·æ„å›¾å’Œç¯å¢ƒèƒŒæ™¯ï¼Œé€šè¿‡åŠ¨æ€è§„åˆ’æ‰§è¡Œå¤šè½®æ£€ç´¢ï¼Œå°†æœç´¢èƒ½åŠ›å»¶ä¼¸åˆ°ç½‘ç»œä¹‹å¤–ã€‚åƒOpenAIçš„æ·±åº¦ç ”ç©¶ç­‰é¢†å…ˆå®ä¾‹çªå‡ºäº†å®ƒä»¬åœ¨æ·±åº¦ä¿¡æ¯æŒ–æ˜å’Œå®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚è¿™ç¯‡ç»¼è¿°é¦–æ¬¡å¯¹æœç´¢ä»£ç†äººè¿›è¡Œäº†ç³»ç»Ÿåˆ†æã€‚æˆ‘ä»¬ä»æ¶æ„ã€ä¼˜åŒ–ã€åº”ç”¨å’Œè¯„ä¼°ç­‰è§’åº¦å…¨é¢åˆ†æå’Œåˆ†ç±»äº†ç°æœ‰å·¥ä½œï¼Œæœ€ç»ˆç¡®å®šäº†å…³é”®å¼€æ”¾æŒ‘æˆ˜ï¼Œå¹¶æ¦‚è¿°äº†åœ¨è¿™ä¸ªå¿«é€Ÿæ¼”å˜çš„é¢†åŸŸä¸­æœ‰å‰é€”çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚æˆ‘ä»¬çš„ä»“åº“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/YunjiaXi/Awesome-Search-Agent-Papers">https://github.com/YunjiaXi/Awesome-Search-Agent-Papers</a>è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05668v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°å¯¹ç½‘é¡µæœç´¢äº§ç”Ÿäº†é‡å¤§å˜é©ã€‚LLMé©±åŠ¨çš„æœç´¢ä»£ç†äººçš„æ¶Œç°ï¼Œæ ‡å¿—ç€æœç´¢å‘æ›´æ·±ã€æ›´åŠ¨æ€ã€æ›´è‡ªä¸»çš„èµ„è®¯æœå¯»æ–¹å‘è½¬å˜ã€‚è¿™äº›ä»£ç†äººèƒ½å¤Ÿäº†è§£ç”¨æˆ·æ„å›¾å’Œä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œå¹¶é€šè¿‡åŠ¨æ€è§„åˆ’æ‰§è¡Œå¤šè½®æ£€ç´¢ï¼Œå°†æœç´¢èƒ½åŠ›å»¶ä¼¸åˆ°äº’è”ç½‘ä¹‹å¤–ã€‚å¦‚OpenAIçš„æ·±åº¦ç ”ç©¶ç­‰é¢†å…ˆå®ä¾‹çªæ˜¾äº†å…¶åœ¨æ·±åº¦ä¿¡æ¯æŒ–æ˜å’Œå®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåˆ†æäº†æœç´¢ä»£ç†äººï¼Œä»æ¶æ„ã€ä¼˜åŒ–ã€åº”ç”¨å’Œè¯„ä¼°ç­‰æ–¹é¢å…¨é¢åˆ†æå’Œåˆ†ç±»ç°æœ‰å·¥ä½œï¼Œå¹¶ç¡®å®šäº†å…³é”®å¼€æ”¾æŒ‘æˆ˜ï¼Œæ¦‚è¿°äº†æ­¤å¿«é€Ÿæ¼”å˜é¢†åŸŸçš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚æˆ‘ä»¬çš„ä»“åº“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/YunjiaXi/Awesome-Search-Agent-Papers%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/YunjiaXi/Awesome-Search-Agent-Papersæ‰¾åˆ°ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»æ”¹å˜äº†ç½‘é¡µæœç´¢çš„æ ¼å±€ã€‚</li>
<li>LLMé©±åŠ¨çš„æœç´¢ä»£ç†äººèƒ½å¤Ÿå®ç°æ›´æ·±ã€æ›´åŠ¨æ€ã€æ›´è‡ªä¸»çš„èµ„è®¯æœå¯»ã€‚</li>
<li>æœç´¢ä»£ç†äººèƒ½å¤Ÿäº†è§£ç”¨æˆ·æ„å›¾å’Œä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œå¹¶æ‰§è¡Œå¤šè½®æ£€ç´¢ã€‚</li>
<li>æœç´¢ä»£ç†äººçš„èƒ½åŠ›å·²ç»å»¶ä¼¸åˆ°äº’è”ç½‘ä¹‹å¤–ã€‚</li>
<li>é¢†å…ˆçš„å®ä¾‹å¦‚OpenAIçš„æ·±åº¦ç ”ç©¶å±•ç¤ºäº†LLMåœ¨æ·±åº¦ä¿¡æ¯æŒ–æ˜å’Œå®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåˆ†æäº†æœç´¢ä»£ç†äººï¼Œæ¶µç›–äº†æ¶æ„ã€ä¼˜åŒ–ã€åº”ç”¨å’Œè¯„ä¼°ç­‰æ–¹é¢çš„å…¨é¢åˆ†æã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05668">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-95492d2d1f933ba2a73b7fe92bbbc86a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d51c6261c033bc57c0be2cdebdd85668.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="MCN-SLAM-Multi-Agent-Collaborative-Neural-SLAM-with-Hybrid-Implicit-Neural-Scene-Representation"><a href="#MCN-SLAM-Multi-Agent-Collaborative-Neural-SLAM-with-Hybrid-Implicit-Neural-Scene-Representation" class="headerlink" title="MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit   Neural Scene Representation"></a>MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit   Neural Scene Representation</h2><p><strong>Authors:Tianchen Deng, Guole Shen, Xun Chen, Shenghai Yuan, Hongming Shen, Guohao Peng, Zhenyu Wu, Jingchuan Wang, Lihua Xie, Danwei Wang, Hesheng Wang, Weidong Chen</strong></p>
<p>Neural implicit scene representations have recently shown promising results in dense visual SLAM. However, existing implicit SLAM algorithms are constrained to single-agent scenarios, and fall difficulties in large-scale scenes and long sequences. Existing NeRF-based multi-agent SLAM frameworks cannot meet the constraints of communication bandwidth. To this end, we propose the first distributed multi-agent collaborative neural SLAM framework with hybrid scene representation, distributed camera tracking, intra-to-inter loop closure, and online distillation for multiple submap fusion. A novel triplane-grid joint scene representation method is proposed to improve scene reconstruction. A novel intra-to-inter loop closure method is designed to achieve local (single-agent) and global (multi-agent) consistency. We also design a novel online distillation method to fuse the information of different submaps to achieve global consistency. Furthermore, to the best of our knowledge, there is no real-world dataset for NeRF-based&#x2F;GS-based SLAM that provides both continuous-time trajectories groundtruth and high-accuracy 3D meshes groundtruth. To this end, we propose the first real-world Dense slam (DES) dataset covering both single-agent and multi-agent scenarios, ranging from small rooms to large-scale outdoor scenes, with high-accuracy ground truth for both 3D mesh and continuous-time camera trajectory. This dataset can advance the development of the research in both SLAM, 3D reconstruction, and visual foundation model. Experiments on various datasets demonstrate the superiority of the proposed method in both mapping, tracking, and communication. The dataset and code will open-source on <a target="_blank" rel="noopener" href="https://github.com/dtc111111/mcnslam">https://github.com/dtc111111/mcnslam</a>. </p>
<blockquote>
<p>ç¥ç»éšå¼åœºæ™¯è¡¨ç¤ºåœ¨å¯†é›†è§†è§‰SLAMä¸­æœ€è¿‘æ˜¾ç¤ºå‡ºæœ‰å‰é€”çš„ç»“æœã€‚ç„¶è€Œï¼Œç°æœ‰çš„éšå¼SLAMç®—æ³•å—é™äºå•æ™ºèƒ½ä½“åœºæ™¯ï¼Œå¹¶åœ¨å¤§è§„æ¨¡åœºæ™¯å’Œé•¿åºåˆ—ä¸­é¢ä¸´å›°éš¾ã€‚åŸºäºNeRFçš„å¤šæ™ºèƒ½ä½“SLAMæ¡†æ¶æ— æ³•æ»¡è¶³é€šä¿¡å¸¦å®½çš„çº¦æŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ä¸ªåˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“ååŒç¥ç»SLAMæ¡†æ¶ï¼Œå…·æœ‰æ··åˆåœºæ™¯è¡¨ç¤ºã€åˆ†å¸ƒå¼ç›¸æœºè·Ÿè¸ªã€å†…éƒ¨åˆ°è·¨ç¯é—­åˆä»¥åŠé’ˆå¯¹å¤šå­å›¾èåˆçš„åœ¨çº¿è’¸é¦æŠ€æœ¯ã€‚æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸‰å¹³é¢ç½‘æ ¼è”åˆåœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œä»¥æ”¹è¿›åœºæ™¯é‡å»ºã€‚è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å†…å¤–ç¯é—­åˆæ–¹æ³•ï¼Œä»¥å®ç°å±€éƒ¨ï¼ˆå•æ™ºèƒ½ä½“ï¼‰å’Œå…¨å±€ï¼ˆå¤šæ™ºèƒ½ä½“ï¼‰çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„åœ¨çº¿è’¸é¦æ–¹æ³•ï¼Œä»¥èåˆä¸åŒå­å›¾çš„ä¿¡æ¯ï¼Œå®ç°å…¨å±€ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæ²¡æœ‰åŸºäºNeRFæˆ–GSçš„SLAMçœŸå®ä¸–ç•Œæ•°æ®é›†èƒ½å¤Ÿæä¾›è¿ç»­æ—¶é—´è½¨è¿¹çš„åœ°é¢çœŸå®æ€§å’Œé«˜ç²¾åº¦3Dç½‘æ ¼çš„åœ°é¢çœŸå®æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ä¸ªçœŸå®ä¸–ç•Œçš„å¯†é›†SLAMï¼ˆDESï¼‰æ•°æ®é›†ï¼Œæ¶µç›–å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“åœºæ™¯ï¼Œä»å°æˆ¿é—´åˆ°å¤§è§„æ¨¡æˆ·å¤–åœºæ™¯ï¼Œä¸º3Dç½‘æ ¼å’Œè¿ç»­æ—¶é—´ç›¸æœºè½¨è¿¹æä¾›é«˜ç²¾åº¦åœ°é¢çœŸå®æ•°æ®ã€‚è¯¥æ•°æ®é›†å¯ä»¥ä¿ƒè¿›SLAMã€3Dé‡å»ºå’Œè§†è§‰åŸºç¡€æ¨¡å‹çš„ç ”ç©¶å‘å±•ã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æ˜ å°„ã€è·Ÿè¸ªå’Œé€šä¿¡æ–¹é¢éƒ½è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚æ•°æ®é›†å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/dtc111111/mcnslam">https://github.com/dtc111111/mcnslam</a>ä¸Šå¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18678v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºç¥ç»çš„éšå¼åœºæ™¯è¡¨ç¤ºåœ¨å¯†é›†è§†è§‰SLAMä¸­çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æŠ€æœ¯ä¸»è¦å±€é™äºå•ä»£ç†åœºæ™¯ï¼Œé¢ä¸´å¤§è§„æ¨¡åœºæ™¯å’Œé•¿åºåˆ—çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†é¦–ä¸ªåˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“ååŒç¥ç»SLAMæ¡†æ¶ï¼ŒåŒ…å«æ··åˆåœºæ™¯è¡¨ç¤ºã€åˆ†å¸ƒå¼ç›¸æœºè·Ÿè¸ªã€å†…å¤–é—­ç¯åŠåœ¨çº¿è’¸é¦ç­‰å¤šç§æŠ€æœ¯ã€‚è¿˜åˆ›æ–°äº†triplane-gridè”åˆåœºæ™¯è¡¨ç¤ºæ–¹æ³•ä»¥æå‡åœºæ™¯é‡å»ºæ•ˆæœã€‚æ­¤å¤–ï¼Œç¼ºä¹é’ˆå¯¹NeRF-based&#x2F;GS-based SLAMçš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œå› æ­¤æ¨å‡ºäº†é¦–ä¸ªæ¶µç›–å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“åœºæ™¯çš„çœŸå®ä¸–ç•ŒDense slamï¼ˆDESï¼‰æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ä»å°å‹æˆ¿é—´åˆ°å¤§å‹å®¤å¤–åœºæ™¯éƒ½æœ‰æ‰€æ¶‰åŠï¼Œä¸º3Dç½‘æ ¼å’Œè¿ç»­æ—¶é—´ç›¸æœºè½¨è¿¹æä¾›äº†é«˜ç²¾åº¦åœ°é¢çœŸå®æ•°æ®ï¼Œæœ‰æœ›æ¨åŠ¨SLAMã€3Dé‡å»ºå’Œè§†è§‰åŸºç¡€æ¨¡å‹çš„ç ”ç©¶å‘å±•ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨æ˜ å°„ã€è·Ÿè¸ªå’Œé€šä¿¡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚æ•°æ®é›†å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/dtc111111/mcnslam%E4%B8%8A%E5%BC%BA%E6%BA%90%E3%80%82">https://github.com/dtc111111/mcnslamä¸Šå¼€æºã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰éšå¼SLAMç®—æ³•ä¸»è¦å±€é™äºå•ä»£ç†åœºæ™¯ï¼Œéš¾ä»¥å¤„ç†å¤§è§„æ¨¡åœºæ™¯å’Œé•¿åºåˆ—ã€‚</li>
<li>é¦–ä¸ªåˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“ååŒç¥ç»SLAMæ¡†æ¶è¢«æå‡ºï¼Œå…·å¤‡æ··åˆåœºæ™¯è¡¨ç¤ºã€åˆ†å¸ƒå¼ç›¸æœºè·Ÿè¸ªç­‰åŠŸèƒ½ã€‚</li>
<li>åˆ›æ–°äº†triplane-gridè”åˆåœºæ™¯è¡¨ç¤ºæ–¹æ³•ä»¥æå‡åœºæ™¯é‡å»ºæ•ˆæœã€‚</li>
<li>ç¼ºä¹é’ˆå¯¹NeRF-based&#x2F;GS-based SLAMçš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œä¸ºæ­¤æ¨å‡ºäº†é¦–ä¸ªDESæ•°æ®é›†ï¼Œæ¶µç›–å¤šç§åœºæ™¯å¹¶å…·å¤‡é«˜ç²¾åº¦åœ°é¢çœŸå®æ•°æ®ã€‚</li>
<li>æå‡ºäº†æ–°å‹çš„å†…åˆ°å¤–é—­ç¯æ–¹æ³•å’Œåœ¨çº¿è’¸é¦æ–¹æ³•ï¼Œå®ç°å±€éƒ¨å’Œå…¨å±€ä¸€è‡´æ€§ã€‚</li>
<li>æ–¹æ³•åœ¨æ˜ å°„ã€è·Ÿè¸ªå’Œé€šä¿¡æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18678">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eea4895bf70329e392cb8764aa75db02.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cce32ed6babefec4e509871518807f23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-579dd5e77535e0552095b0048294a7bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e1fcf2b38ba4a4656dee8796fbe40720.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Two-Heads-are-Better-Than-One-Test-time-Scaling-of-Multi-agent-Collaborative-Reasoning"><a href="#Two-Heads-are-Better-Than-One-Test-time-Scaling-of-Multi-agent-Collaborative-Reasoning" class="headerlink" title="Two Heads are Better Than One: Test-time Scaling of Multi-agent   Collaborative Reasoning"></a>Two Heads are Better Than One: Test-time Scaling of Multi-agent   Collaborative Reasoning</h2><p><strong>Authors:Can Jin, Hongwu Peng, Qixin Zhang, Yujin Tang, Dimitris N. Metaxas, Tong Che</strong></p>
<p>Multi-agent systems (MAS) built on large language models (LLMs) offer a promising path toward solving complex, real-world tasks that single-agent systems often struggle to manage. While recent advancements in test-time scaling (TTS) have significantly improved single-agent performance on challenging reasoning tasks, how to effectively scale collaboration and reasoning in MAS remains an open question. In this work, we introduce an adaptive multi-agent framework designed to enhance collaborative reasoning through both model-level training and system-level coordination. We construct M500, a high-quality dataset containing 500 multi-agent collaborative reasoning traces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a model optimized for multi-agent collaboration. To further enable adaptive reasoning, we propose a novel CEO agent that dynamically manages the discussion process, guiding agent collaboration and adjusting reasoning depth for more effective problem-solving. Evaluated in an open-source MAS across a range of tasks-including general understanding, mathematical reasoning, and coding-our system significantly outperforms strong baselines. For instance, M1-32B achieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on MBPP-Sanitized, matching the performance of state-of-the-art models like DeepSeek-R1 on some tasks. These results highlight the importance of both learned collaboration and adaptive coordination in scaling multi-agent reasoning. Code is available at <a target="_blank" rel="noopener" href="https://github.com/jincan333/MAS-TTS">https://github.com/jincan333/MAS-TTS</a> </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ä¸ºè§£å†³å¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡æä¾›äº†å‰æ™¯å¹¿é˜”çš„é“è·¯ï¼Œè¿™äº›ä»»åŠ¡å¾€å¾€æ˜¯å•ä¸€æ™ºèƒ½ä½“ç³»ç»Ÿéš¾ä»¥åº”å¯¹çš„ã€‚è™½ç„¶æœ€è¿‘åœ¨æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰æ–¹é¢çš„è¿›å±•å¤§å¤§æé«˜äº†å•ä¸€æ™ºèƒ½ä½“åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä½†å¦‚ä½•åœ¨MASä¸­æœ‰æ•ˆåœ°æ‰©å±•åä½œå’Œæ¨ç†ä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡å‹çº§è®­ç»ƒå’Œç³»ç»Ÿçº§åè°ƒæ¥æé«˜åä½œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬æ„å»ºäº†M500ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«500ä¸ªå¤šæ™ºèƒ½ä½“åä½œæ¨ç†è½¨è¿¹çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤æ•°æ®é›†ä¸Šå¾®è°ƒäº†Qwen2.5-32B-Instructæ¨¡å‹ï¼Œä»è€Œç”Ÿæˆäº†é’ˆå¯¹å¤šæ™ºèƒ½ä½“åä½œä¼˜åŒ–çš„M1-32Bæ¨¡å‹ã€‚ä¸ºäº†è¿›ä¸€æ­¥å®ç°è‡ªé€‚åº”æ¨ç†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹CEOæ™ºèƒ½ä½“ï¼Œå®ƒèƒ½åŠ¨æ€ç®¡ç†è®¨è®ºè¿‡ç¨‹ï¼Œå¼•å¯¼æ™ºèƒ½ä½“åä½œå¹¶è°ƒæ•´æ¨ç†æ·±åº¦ï¼Œä»¥æ›´æœ‰æ•ˆåœ°è§£å†³é—®é¢˜ã€‚æˆ‘ä»¬åœ¨åŒ…æ‹¬é€šç”¨ç†è§£ã€æ•°å­¦æ¨ç†å’Œç¼–ç ç­‰ä¸€ç³»åˆ—ä»»åŠ¡çš„å¼€æºMASä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„ç³»ç»Ÿï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºå¼ºå¤§çš„åŸºçº¿ã€‚ä¾‹å¦‚ï¼ŒM1-32Båœ¨GPQA-Diamondä¸Šå®ç°äº†12%çš„æ”¹è¿›ï¼Œåœ¨AIME2024ä¸Šå®ç°äº†41%çš„æ”¹è¿›ï¼Œåœ¨MBPP-Sanitizedä¸Šå®ç°äº†10%çš„æ”¹è¿›ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šä¸DeepSeek-R1ç­‰å…ˆè¿›æ¨¡å‹ç›¸åŒ¹é…ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†å­¦ä¹ åä½œå’Œè‡ªé€‚åº”åè°ƒåœ¨æ‰©å±•å¤šæ™ºèƒ½ä½“æ¨ç†ä¸­çš„é‡è¦æ€§ã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/jincan333/MAS-TTS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jincan333/MAS-TTSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09772v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ï¼Œæ—¨åœ¨è§£å†³å•ä¸ªæ™ºèƒ½ä½“ç³»ç»Ÿéš¾ä»¥åº”å¯¹çš„å¤æ‚ç°å®ä¸–ç•Œä»»åŠ¡ã€‚æ–‡ç« é€šè¿‡æ¨¡å‹çº§åˆ«çš„è®­ç»ƒå’Œç³»ç»Ÿçº§åˆ«çš„åè°ƒï¼Œæå‡ºäº†ä¸€ä¸ªè‡ªé€‚åº”çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå¢å¼ºäº†åä½œæ¨ç†èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æ„å»ºäº†M500æ•°æ®é›†ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œäº§ç”Ÿäº†é’ˆå¯¹å¤šæ™ºèƒ½ä½“åä½œä¼˜åŒ–çš„M1-32Bæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§åŠ¨æ€ç®¡ç†è®¨è®ºè¿‡ç¨‹çš„é¦–å¸­æ‰§è¡Œå®˜æ™ºèƒ½ä½“ï¼Œä»¥è¿›ä¸€æ­¥å®ç°è‡ªé€‚åº”æ¨ç†ã€‚åœ¨å¼€æ”¾æºç çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤šç§ä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿ï¼ŒåŒ…æ‹¬é€šç”¨ç†è§£ã€æ•°å­¦æ¨ç†å’Œç¼–ç ä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºè§£å†³å¤æ‚ç°å®ä¸–ç•Œä»»åŠ¡æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚</li>
<li>æœ€è¿‘æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰æŠ€æœ¯çš„è¿›å±•å·²æ˜¾è‘—æé«˜å•æ™ºèƒ½ä½“çš„æŒ‘æˆ˜æ€§æ¨ç†ä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>å¼•å…¥è‡ªé€‚åº”å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡æ¨¡å‹çº§åˆ«çš„è®­ç»ƒå’Œç³»ç»Ÿçº§åˆ«çš„åè°ƒï¼Œå¢å¼ºåä½œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>æ„å»ºå¹¶å¾®è°ƒäº†M500æ•°æ®é›†ï¼Œäº§ç”Ÿé’ˆå¯¹å¤šæ™ºèƒ½ä½“åä½œä¼˜åŒ–çš„M1-32Bæ¨¡å‹ã€‚</li>
<li>æå‡ºåŠ¨æ€ç®¡ç†è®¨è®ºè¿‡ç¨‹çš„CEOæ™ºèƒ½ä½“ï¼Œå®ç°è‡ªé€‚åº”æ¨ç†ã€‚</li>
<li>åœ¨å¤šç§ä»»åŠ¡ä¸Šï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—è¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿ï¼ŒåŒ…æ‹¬é€šç”¨ç†è§£ã€æ•°å­¦æ¨ç†å’Œç¼–ç ä»»åŠ¡ã€‚</li>
<li>ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šï¼Œä¾›å…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09772">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f5575222a7bf92310d9969865170f37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-363f1a70a3d3350f357af80f7c4319a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-997a3ca3080ebae30c9bd2eeec20b183.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0992a6c405ce67cbdd7fb9adf320cc95.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Image-Augmentation-Agent-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Image-Augmentation-Agent-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Image Augmentation Agent for Weakly Supervised Semantic Segmentation"></a>Image Augmentation Agent for Weakly Supervised Semantic Segmentation</h2><p><strong>Authors:Wangyu Wu, Xianglin Qiu, Siqi Song, Zhenhong Chen, Xiaowei Huang, Fei Ma, Jimin Xiao</strong></p>
<p>Weakly-supervised semantic segmentation (WSSS) has achieved remarkable progress using only image-level labels. However, most existing WSSS methods focus on designing new network structures and loss functions to generate more accurate dense labels, overlooking the limitations imposed by fixed datasets, which can constrain performance improvements. We argue that more diverse trainable images provides WSSS richer information and help model understand more comprehensive semantic pattern. Therefore in this paper, we introduce a novel approach called Image Augmentation Agent (IAA) which shows that it is possible to enhance WSSS from data generation perspective. IAA mainly design an augmentation agent that leverages large language models (LLMs) and diffusion models to automatically generate additional images for WSSS. In practice, to address the instability in prompt generation by LLMs, we develop a prompt self-refinement mechanism. It allow LLMs to re-evaluate the rationality of generated prompts to produce more coherent prompts. Additionally, we insert an online filter into diffusion generation process to dynamically ensure the quality and balance of generated images. Experimental results show that our method significantly surpasses state-of-the-art WSSS approaches on the PASCAL VOC 2012 and MS COCO 2014 datasets. </p>
<blockquote>
<p>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰ä»…ä½¿ç”¨å›¾åƒçº§æ ‡ç­¾å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„WSSSæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è®¾è®¡æ–°çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°æ¥ç”Ÿæˆæ›´å‡†ç¡®çš„å¯†é›†æ ‡ç­¾ï¼Œå¿½è§†äº†å›ºå®šæ•°æ®é›†å¸¦æ¥çš„é™åˆ¶ï¼Œè¿™äº›é™åˆ¶å¯èƒ½ä¼šé™åˆ¶æ€§èƒ½æ”¹è¿›ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæä¾›æ›´å¤šå¯è®­ç»ƒå›¾åƒå¯ä»¥ä¸ºWSSSæä¾›æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œå¹¶å¸®åŠ©æ¨¡å‹ç†è§£æ›´å…¨é¢çš„è¯­ä¹‰æ¨¡å¼ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç§°ä¸ºå›¾åƒå¢å¼ºä»£ç†ï¼ˆIAAï¼‰ï¼Œå®ƒè¡¨æ˜ä»æ•°æ®ç”Ÿæˆçš„è§’åº¦å¢å¼ºWSSSæ˜¯å¯èƒ½çš„ã€‚IAAä¸»è¦è®¾è®¡äº†ä¸€ä¸ªå¢å¼ºä»£ç†ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ä¸ºWSSSç”Ÿæˆé¢å¤–å›¾åƒã€‚åœ¨å®è·µä¸­ï¼Œä¸ºäº†è§£å†³LLMç”Ÿæˆæç¤ºçš„ä¸ç¨³å®šæ€§ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æç¤ºè‡ªæˆ‘ä¼˜åŒ–æœºåˆ¶ã€‚å®ƒå…è®¸LLMé‡æ–°è¯„ä¼°ç”Ÿæˆçš„æç¤ºçš„åˆç†æ€§ï¼Œä»¥äº§ç”Ÿæ›´è¿è´¯çš„æç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥äº†ä¸€ä¸ªåœ¨çº¿è¿‡æ»¤å™¨ï¼Œä»¥åŠ¨æ€ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†æœ€å…ˆè¿›çš„WSSSæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20439v3">PDF</a> Accepted at Neurocomputing 2025</p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨å›¾åƒçº§æ ‡ç­¾å®ç°çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤šå…³æ³¨è®¾è®¡æ–°ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ä»¥ç”Ÿæˆæ›´å‡†ç¡®çš„å¯†é›†æ ‡ç­¾ï¼Œå¿½è§†äº†å›ºå®šæ•°æ®é›†å¸¦æ¥çš„é™åˆ¶ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºå›¾åƒå¢å¼ºä»£ç†ï¼ˆIAAï¼‰çš„æ–°æ–¹æ³•ï¼Œä»æ•°æ®ç”Ÿæˆè§’åº¦æå‡WSSSæ€§èƒ½ã€‚IAAè®¾è®¡äº†ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆé¢å¤–å›¾åƒçš„å¢å¼ºä»£ç†ã€‚ä¸ºè§£å†³LLMsåœ¨æç¤ºç”Ÿæˆä¸­çš„ä¸ç¨³å®šé—®é¢˜ï¼Œå¼€å‘äº†ä¸€ç§æç¤ºè‡ªæˆ‘å®Œå–„æœºåˆ¶ï¼Œä½¿LLMsèƒ½å¤Ÿé‡æ–°è¯„ä¼°ç”Ÿæˆçš„æç¤ºçš„åˆç†æ€§ï¼Œäº§ç”Ÿæ›´è¿è´¯çš„æç¤ºã€‚æ­¤å¤–ï¼Œåœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥åœ¨çº¿è¿‡æ»¤å™¨ï¼Œä»¥åŠ¨æ€ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰WSSSæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WSSSåˆ©ç”¨å›¾åƒçº§æ ‡ç­¾å®ç°æ˜¾è‘—è¿›å±•ï¼Œä½†å—é™äºå›ºå®šæ•°æ®é›†ã€‚</li>
<li>æå‡ºä¸€ç§åä¸ºImage Augmentation Agent (IAA)çš„æ–°æ–¹æ³•ï¼Œä»æ•°æ®ç”Ÿæˆè§’åº¦æå‡WSSSæ€§èƒ½ã€‚</li>
<li>IAAåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆé¢å¤–å›¾åƒã€‚</li>
<li>ä¸ºè§£å†³LLMsåœ¨æç¤ºç”Ÿæˆä¸­çš„ä¸ç¨³å®šé—®é¢˜ï¼Œå¼€å‘äº†æç¤ºè‡ªæˆ‘å®Œå–„æœºåˆ¶ã€‚</li>
<li>åœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥åœ¨çº¿è¿‡æ»¤å™¨ï¼Œç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>IAAé€šè¿‡å¢åŠ å›¾åƒå¤šæ ·æ€§å’Œè´¨é‡ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£æ›´å…¨é¢çš„è¯­ä¹‰æ¨¡å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20439">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2e7d8f479fa40cf856cd3813f060316f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e600ce67b4bc330051c553eed649b691.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="WHALES-A-Multi-Agent-Scheduling-Dataset-for-Enhanced-Cooperation-in-Autonomous-Driving"><a href="#WHALES-A-Multi-Agent-Scheduling-Dataset-for-Enhanced-Cooperation-in-Autonomous-Driving" class="headerlink" title="WHALES: A Multi-Agent Scheduling Dataset for Enhanced Cooperation in   Autonomous Driving"></a>WHALES: A Multi-Agent Scheduling Dataset for Enhanced Cooperation in   Autonomous Driving</h2><p><strong>Authors:Yinsong Wang, Siwei Chen, Ziyi Song, Sheng Zhou</strong></p>
<p>Cooperative perception research is hindered by the limited availability of datasets that capture the complexity of real-world Vehicle-to-Everything (V2X) interactions, particularly under dynamic communication constraints. To address this gap, we introduce WHALES (Wireless enhanced Autonomous vehicles with Large number of Engaged agents), the first large-scale V2X dataset explicitly designed to benchmark communication-aware agent scheduling and scalable cooperative perception. WHALES introduces a new benchmark that enables state-of-the-art (SOTA) research in communication-aware cooperative perception, featuring an average of 8.4 cooperative agents per scene and 2.01 million annotated 3D objects across diverse traffic scenarios. It incorporates detailed communication metadata to emulate real-world communication bottlenecks, enabling rigorous evaluation of scheduling strategies. To further advance the field, we propose the Coverage-Aware Historical Scheduler (CAHS), a novel scheduling baseline that selects agents based on historical viewpoint coverage, improving perception performance over existing SOTA methods. WHALES bridges the gap between simulated and real-world V2X challenges, providing a robust framework for exploring perception-scheduling co-design, cross-data generalization, and scalability limits. The WHALES dataset and code are available at <a target="_blank" rel="noopener" href="https://github.com/chensiweiTHU/WHALES">https://github.com/chensiweiTHU/WHALES</a>. </p>
<blockquote>
<p>ååŒæ„ŸçŸ¥ç ”ç©¶å—é™äºæ•°æ®é›†çš„å¯è·å–æ€§ï¼Œè¿™äº›æ•°æ®é›†éœ€è¦æ•æ‰ç°å®ä¸–ç•Œä¸­è½¦è¾†ä¸ä¸‡ç‰©ï¼ˆV2Xï¼‰äº¤äº’çš„å¤æ‚æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨åŠ¨æ€é€šä¿¡çº¦æŸä¸‹ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†WHALESï¼ˆæ— çº¿å¢å¼ºå‹è‡ªä¸»è½¦è¾†ä¸å¤§é‡å‚ä¸è€…çš„äº¤äº’ï¼‰ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ä¸ºåŸºå‡†æµ‹è¯•é€šä¿¡æ„ŸçŸ¥ä»£ç†è°ƒåº¦å’Œå¯æ‰©å±•ååŒæ„ŸçŸ¥è€Œè®¾è®¡çš„å¤§è§„æ¨¡V2Xæ•°æ®é›†ã€‚WHALESå¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œä½¿æœ€å…ˆè¿›çš„ï¼ˆSOTAï¼‰é€šä¿¡æ„ŸçŸ¥ååŒç ”ç©¶æˆä¸ºå¯èƒ½ï¼Œæ¯ä¸ªåœºæ™¯å¹³å‡æœ‰8.4ä¸ªåˆä½œä»£ç†ï¼Œè·¨è¶Šå„ç§äº¤é€šåœºæ™¯çš„201ä¸‡ä¸ªæ³¨é‡Šçš„3Då¯¹è±¡ã€‚å®ƒç»“åˆäº†è¯¦ç»†çš„é€šä¿¡å…ƒæ•°æ®æ¥æ¨¡æ‹ŸçœŸå®çš„é€šä¿¡ç“¶é¢ˆï¼Œå¯ä»¥å¯¹è°ƒåº¦ç­–ç•¥è¿›è¡Œä¸¥æ ¼è¯„ä¼°ã€‚ä¸ºäº†è¿›ä¸€æ­¥å‘å±•è¯¥é¢†åŸŸï¼Œæˆ‘ä»¬æå‡ºäº†Coverage-Aware Historical Schedulerï¼ˆCAHSï¼‰â€”â€”ä¸€ç§åŸºäºå†å²è§‚ç‚¹è¦†ç›–ç‡é€‰æ‹©ä»£ç†çš„æ–°å‹è°ƒåº¦åŸºçº¿ï¼Œåœ¨ç°æœ‰SOTAæ–¹æ³•çš„åŸºç¡€ä¸Šæé«˜äº†æ„ŸçŸ¥æ€§èƒ½ã€‚WHALESç¼©å°äº†æ¨¡æ‹Ÿä¸ç°å®ä¸–ç•ŒV2XæŒ‘æˆ˜ä¹‹é—´çš„å·®è·ï¼Œä¸ºæ¢ç´¢æ„ŸçŸ¥è°ƒåº¦ååŒè®¾è®¡ã€è·¨æ•°æ®æ³›åŒ–å’Œå¯æ‰©å±•æ€§æé™æä¾›äº†ç¨³å¥çš„æ¡†æ¶ã€‚WHALESæ•°æ®é›†å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/chensiweiTHU/WHALES%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/chensiweiTHU/WHALESè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13340v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>WHALESæ˜¯é¦–ä¸ªä¸“ä¸ºé€šä¿¡æ„ŸçŸ¥ååŒè°ƒåº¦è€Œè®¾è®¡çš„å¤§è§„æ¨¡V2Xæ•°æ®é›†ã€‚å®ƒæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„é€šä¿¡ç“¶é¢ˆï¼Œä¸ºå…ˆè¿›çš„ç ”ç©¶æä¾›äº†åŸºå‡†æµ‹è¯•å¹³å°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§åŸºäºå†å²è§†è§’è¦†ç›–çš„è°ƒåº¦åŸºçº¿â€”â€”Coverage-Aware Historical Schedulerï¼ˆCAHSï¼‰ï¼Œæé«˜äº†æ„ŸçŸ¥æ€§èƒ½ã€‚WHALESæ•°æ®é›†ä¸ºæ¢ç´¢æ„ŸçŸ¥è°ƒåº¦ååŒè®¾è®¡ã€è·¨æ•°æ®æ³›åŒ–ä»¥åŠå¯æ‰©å±•æ€§æé™æä¾›äº†ç¨³å¥æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WHALESæ•°æ®é›†ä¸“ä¸ºè§£å†³ç°å®ä¸–ç•Œä¸­è½¦è¾†ä¸ä¸‡ç‰©ï¼ˆV2Xï¼‰äº¤äº’çš„å¤æ‚æ€§è€Œè®¾è®¡ï¼Œå¡«è¡¥äº†ç°æœ‰æ•°æ®é›†çš„ç©ºç™½ã€‚</li>
<li>WHALESæ•°æ®é›†å…·æœ‰å¤§è§„æ¨¡ç‰¹æ€§ï¼Œå¹³å‡æ¯ä¸ªåœºæ™¯æœ‰8.4ä¸ªåˆä½œä»£ç†ï¼Œæ¶µç›–å¤šæ ·åŒ–çš„äº¤é€šåœºæ™¯ï¼Œå¹¶å¸¦æœ‰201ä¸‡ä¸ªæ ‡æ³¨çš„3Då¯¹è±¡ã€‚</li>
<li>æ•°æ®é›†èå…¥äº†è¯¦ç»†çš„é€šä¿¡å…ƒæ•°æ®ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„é€šä¿¡ç“¶é¢ˆï¼Œä½¿å¾—è°ƒåº¦ç­–ç•¥çš„è¯„ä»·æ›´ä¸ºä¸¥æ ¼ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œä¸ºå…ˆè¿›çš„ç ”ç©¶æä¾›äº†é€šä¿¡æ„ŸçŸ¥ååŒè°ƒåº¦çš„æœºä¼šã€‚</li>
<li>æå‡ºäº†Coverage-Aware Historical Schedulerï¼ˆCAHSï¼‰è¿™ä¸€æ–°é¢–çš„è°ƒåº¦åŸºçº¿æ–¹æ³•ï¼ŒåŸºäºå†å²è§†è§’è¦†ç›–è¿›è¡Œé€‰æ‹©ï¼Œæé«˜äº†æ„ŸçŸ¥æ€§èƒ½ã€‚</li>
<li>WHALESæ•°æ®é›†æœ‰åŠ©äºæ¢ç´¢æ„ŸçŸ¥è°ƒåº¦ååŒè®¾è®¡ã€è·¨æ•°æ®æ³›åŒ–ç­‰è®®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13340">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b1424a23c2415a514f835e9d5da16058.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9259fbf4b3f05a47d762bcb3b1bd2fb1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cbc5a40962f0efcfe3e5adaddde488c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c94157fbc3d7bcf2f6519030511a6b7f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d10381154c4dc5b400a78e6acb1ef0cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e1c637c98d7faf0761c5e5a3c6c6f67.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-64640c50997263e8da5b7ed299d543dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb1d7d6351b944cbd78a0523331128ed.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-21/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-21/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-21/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bd8c4a3b464e51d4bf1a247a25254577.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-21  DictAS A Framework for Class-Generalizable Few-Shot Anomaly   Segmentation via Dictionary Lookup
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-21/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a056dd40246c173f2f35e909473a12a2.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-21  Unintended Misalignment from Agentic Fine-Tuning Risks and Mitigation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28791.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
