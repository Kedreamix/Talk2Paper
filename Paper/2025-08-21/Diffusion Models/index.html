<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-21  Latent Interpolation Learning Using Diffusion Models for Cardiac Volume   Reconstruction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6f8d303bf54cf2d273a6f5b383176b78.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    47 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-21-æ›´æ–°"><a href="#2025-08-21-æ›´æ–°" class="headerlink" title="2025-08-21 æ›´æ–°"></a>2025-08-21 æ›´æ–°</h1><h2 id="Latent-Interpolation-Learning-Using-Diffusion-Models-for-Cardiac-Volume-Reconstruction"><a href="#Latent-Interpolation-Learning-Using-Diffusion-Models-for-Cardiac-Volume-Reconstruction" class="headerlink" title="Latent Interpolation Learning Using Diffusion Models for Cardiac Volume   Reconstruction"></a>Latent Interpolation Learning Using Diffusion Models for Cardiac Volume   Reconstruction</h2><p><strong>Authors:Niklas Bubeck, Suprosanna Shit, Chen Chen, Can Zhao, Pengfei Guo, Dong Yang, Georg Zitzlsberger, Daguang Xu, Bernhard Kainz, Daniel Rueckert, Jiazhen Pan</strong></p>
<p>Cardiac Magnetic Resonance (CMR) imaging is a critical tool for diagnosing and managing cardiovascular disease, yet its utility is often limited by the sparse acquisition of 2D short-axis slices, resulting in incomplete volumetric information. Accurate 3D reconstruction from these sparse slices is essential for comprehensive cardiac assessment, but existing methods face challenges, including reliance on predefined interpolation schemes (e.g., linear or spherical), computational inefficiency, and dependence on additional semantic inputs such as segmentation labels or motion data. To address these limitations, we propose a novel \textbf{Ca}rdiac \textbf{L}atent \textbf{I}nterpolation \textbf{D}iffusion (CaLID) framework that introduces three key innovations. First, we present a data-driven interpolation scheme based on diffusion models, which can capture complex, non-linear relationships between sparse slices and improves reconstruction accuracy. Second, we design a computationally efficient method that operates in the latent space and speeds up 3D whole-heart upsampling time by a factor of 24, reducing computational overhead compared to previous methods. Third, with only sparse 2D CMR images as input, our method achieves SOTA performance against baseline methods, eliminating the need for auxiliary input such as morphological guidance, thus simplifying workflows. We further extend our method to 2D+T data, enabling the effective modeling of spatiotemporal dynamics and ensuring temporal coherence. Extensive volumetric evaluations and downstream segmentation tasks demonstrate that CaLID achieves superior reconstruction quality and efficiency. By addressing the fundamental limitations of existing approaches, our framework advances the state of the art for spatio and spatiotemporal whole-heart reconstruction, offering a robust and clinically practical solution for cardiovascular imaging. </p>
<blockquote>
<p>å¿ƒè„ç£å…±æŒ¯ï¼ˆCMRï¼‰æˆåƒåœ¨å¿ƒè¡€ç®¡ç–¾ç—…çš„è¯Šæ–­å’Œæ²»ç–—ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œä½†å…¶åº”ç”¨å¸¸å¸¸å—é™äºäºŒç»´çŸ­è½´åˆ‡ç‰‡çš„ç¨€ç–é‡‡é›†ï¼Œå¯¼è‡´ä½“ç§¯ä¿¡æ¯ä¸å®Œæ•´ã€‚ä»ç¨€ç–åˆ‡ç‰‡è¿›è¡Œå‡†ç¡®çš„3Dé‡å»ºå¯¹äºå…¨é¢çš„å¿ƒè„è¯„ä¼°è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•é¢ä¸´æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä¾èµ–é¢„å®šä¹‰çš„æ’å€¼æ–¹æ¡ˆï¼ˆä¾‹å¦‚çº¿æ€§æˆ–çƒå½¢æ’å€¼ï¼‰ã€è®¡ç®—æ•ˆç‡ä½ä¸‹ä»¥åŠä¾èµ–äºé¢å¤–çš„è¯­ä¹‰è¾“å…¥ï¼ˆå¦‚åˆ†å‰²æ ‡ç­¾æˆ–è¿åŠ¨æ•°æ®ï¼‰ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„<strong>å¿ƒè„æ½œåœ¨æ’å€¼æ‰©æ•£ï¼ˆCaLIDï¼‰æ¡†æ¶</strong>ï¼Œå®ƒå¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ•°æ®é©±åŠ¨æ’å€¼æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆå¯ä»¥æ•æ‰ç¨€ç–åˆ‡ç‰‡ä¹‹é—´çš„å¤æ‚éçº¿æ€§å…³ç³»ï¼Œæé«˜é‡å»ºç²¾åº¦ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åœ¨æ½œåœ¨ç©ºé—´è¿è¡Œçš„é«˜æ•ˆæ–¹æ³•ï¼Œå°†å¿ƒè„3Dä¸Šé‡‡æ ·çš„æ—¶é—´åŠ å¿«äº†24å€ï¼Œä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨ç¨€ç–çš„äºŒç»´CMRå›¾åƒä½œä¸ºè¾“å…¥ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ— éœ€è¾…åŠ©è¾“å…¥ï¼ˆå¦‚å½¢æ€æŒ‡å¯¼ï¼‰ï¼Œä»è€Œç®€åŒ–äº†å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬è¿˜å°†è¯¥æ–¹æ³•æ‰©å±•åˆ°äºŒç»´+æ—¶é—´æ•°æ®ä¸Šï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ¨¡æ‹Ÿæ—¶ç©ºåŠ¨æ€å˜åŒ–å¹¶ç¡®ä¿æ—¶é—´è¿è´¯æ€§ã€‚å¹¿æ³›çš„ä½“ç§¯è¯„ä¼°å’Œä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡è¡¨æ˜ï¼ŒCaLIDåœ¨é‡å»ºè´¨é‡å’Œæ•ˆç‡æ–¹é¢è¾¾åˆ°äº†å…ˆè¿›æŠ€æœ¯æ°´å¹³ã€‚é€šè¿‡è§£å†³ç°æœ‰æ–¹æ³•çš„åŸºæœ¬å±€é™æ€§ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ¨åŠ¨äº†ç©ºé—´å’Œæ—¶é—´ç»´åº¦ä¸Šå¿ƒè„é‡å»ºçš„æœ€æ–°æŠ€æœ¯å‰æ²¿ï¼Œä¸ºå¿ƒè¡€ç®¡æˆåƒæä¾›äº†ç¨³å¥ä¸”å®ç”¨çš„ä¸´åºŠè§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13826v1">PDF</a> </p>
<p><strong>Summary</strong><br>     å¿ƒè„ç£å…±æŒ¯ï¼ˆCMRï¼‰æˆåƒåœ¨è¯Šæ–­å’Œæ²»ç–—å¿ƒè¡€ç®¡ç–¾ç—…ä¸­è‡³å…³é‡è¦ï¼Œä½†å…¶æ•ˆç”¨å¸¸å—é™äºäºŒç»´çŸ­è½´åˆ‡ç‰‡çš„ç¨€ç–é‡‡é›†ï¼Œå¯¼è‡´ä½“ç§¯ä¿¡æ¯ä¸å®Œæ•´ã€‚ä¸ºè§£å†³ç°æœ‰æ–¹æ³•åœ¨å¿ƒè„æ½œåœ¨æ’å€¼æ–¹é¢çš„å±€é™ï¼Œæå‡ºäº†å…¨æ–°çš„å¿ƒè„æ½œåœ¨æ’å€¼æ‰©æ•£ï¼ˆCaLIDï¼‰æ¡†æ¶ã€‚æ­¤æ¡†æ¶é‡‡ç”¨æ•°æ®é©±åŠ¨æ’å€¼æ–¹æ¡ˆï¼Œæé«˜é‡å»ºç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ï¼Œä»…ä¾èµ–ç¨€ç–çš„äºŒç»´CMRå›¾åƒå³å¯å®ç°å“è¶Šæ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜èƒ½å¤„ç†äºŒç»´åŠ æ—¶é—´çš„æ—¶ç©ºåŠ¨æ€æ•°æ®ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ã€‚ç»¼åˆä½“ç§¯è¯„ä¼°å’Œä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡è¯æ˜ï¼ŒCaLIDæ¡†æ¶å…·æœ‰å‡ºè‰²çš„é‡å»ºè´¨é‡å’Œæ•ˆç‡ï¼Œä¸ºå¿ƒè¡€ç®¡æˆåƒæä¾›äº†ç¨³å¥ä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CMRæˆåƒåœ¨å¿ƒè¡€ç®¡ç–¾ç—…çš„è¯Šæ–­å’Œç®¡ç†ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å—é™äºäºŒç»´åˆ‡ç‰‡çš„ç¨€ç–é‡‡é›†é€ æˆçš„ä½“ç§¯ä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚</li>
<li>æå‡ºä¸€ç§æ–°é¢–çš„å¿ƒè„æ½œåœ¨æ’å€¼æ‰©æ•£ï¼ˆCaLIDï¼‰æ¡†æ¶ï¼Œé€šè¿‡æ•°æ®é©±åŠ¨çš„æ’å€¼æ–¹æ¡ˆæé«˜é‡å»ºç²¾åº¦ã€‚</li>
<li>CaLIDæ¡†æ¶èƒ½åœ¨æ½œåœ¨ç©ºé—´å†…æ“ä½œå¹¶å®ç°é«˜æ•ˆè®¡ç®—ï¼Œæ˜¾è‘—ç¼©çŸ­äº†ä¸‰ç»´å¿ƒè„æ•´ä½“æ”¾å¤§æ—¶é—´ã€‚</li>
<li>è¯¥æ¡†æ¶æ— éœ€é¢å¤–çš„è¯­ä¹‰è¾“å…¥å¦‚åˆ†å‰²æ ‡ç­¾æˆ–è¿åŠ¨æ•°æ®ï¼Œä»…ä¾èµ–ç¨€ç–çš„äºŒç»´CMRå›¾åƒå³å¯å®ç°å“è¶Šæ€§èƒ½ã€‚</li>
<li>CaLIDæ¡†æ¶å¯æ‰©å±•åˆ°äºŒç»´åŠ æ—¶é—´çš„æ—¶ç©ºæ•°æ®å¤„ç†ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>ç»¼åˆä½“ç§¯è¯„ä¼°å’Œä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡æ˜¾ç¤ºï¼ŒCaLIDæ¡†æ¶åœ¨æ—¶ç©ºå…¨å¿ƒè„é‡å»ºæ–¹é¢å–å¾—äº†å…ˆè¿›æˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13826">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8866a8ba3da55723b601cdb42f474c6d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1b3c2aacf31192a2998523e57c1e2452.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9db76104ad21d445d80009b4eb9b5fd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b3e8fbd563620fc41599e9edf300cdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b595fe2d116ad3426b59833e331eab7.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Sketch3DVE-Sketch-based-3D-Aware-Scene-Video-Editing"><a href="#Sketch3DVE-Sketch-based-3D-Aware-Scene-Video-Editing" class="headerlink" title="Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing"></a>Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing</h2><p><strong>Authors:Feng-Lin Liu, Shi-Yang Li, Yan-Pei Cao, Hongbo Fu, Lin Gao</strong></p>
<p>Recent video editing methods achieve attractive results in style transfer or appearance modification. However, editing the structural content of 3D scenes in videos remains challenging, particularly when dealing with significant viewpoint changes, such as large camera rotations or zooms. Key challenges include generating novel view content that remains consistent with the original video, preserving unedited regions, and translating sparse 2D inputs into realistic 3D video outputs. To address these issues, we propose Sketch3DVE, a sketch-based 3D-aware video editing method to enable detailed local manipulation of videos with significant viewpoint changes. To solve the challenge posed by sparse inputs, we employ image editing methods to generate edited results for the first frame, which are then propagated to the remaining frames of the video. We utilize sketching as an interaction tool for precise geometry control, while other mask-based image editing methods are also supported. To handle viewpoint changes, we perform a detailed analysis and manipulation of the 3D information in the video. Specifically, we utilize a dense stereo method to estimate a point cloud and the camera parameters of the input video. We then propose a point cloud editing approach that uses depth maps to represent the 3D geometry of newly edited components, aligning them effectively with the original 3D scene. To seamlessly merge the newly edited content with the original video while preserving the features of unedited regions, we introduce a 3D-aware mask propagation strategy and employ a video diffusion model to produce realistic edited videos. Extensive experiments demonstrate the superiority of Sketch3DVE in video editing. Homepage and code: <a target="_blank" rel="noopener" href="http://http//geometrylearning.com/Sketch3DVE/">http://http://geometrylearning.com/Sketch3DVE/</a> </p>
<blockquote>
<p>æœ€è¿‘çš„è§†é¢‘ç¼–è¾‘æ–¹æ³•åœ¨é£æ ¼è½¬æ¢æˆ–å¤–è§‚ä¿®æ”¹æ–¹é¢å–å¾—äº†å¸å¼•äººçš„æˆæœã€‚ç„¶è€Œï¼Œç¼–è¾‘åŒ…å«è§†ç‚¹å˜åŒ–çš„3Dåœºæ™¯çš„è§†é¢‘ä¸­çš„ç»“æ„å†…å®¹ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é‡å¤§è§†ç‚¹å˜åŒ–ï¼Œå¦‚å¤§å¹…åº¦çš„ç›¸æœºæ—‹è½¬æˆ–ç¼©æ”¾æ—¶ã€‚ä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬ç”Ÿæˆä¸åŸå§‹è§†é¢‘ä¿æŒä¸€è‡´çš„æ–°è§†å›¾å†…å®¹ã€ä¿ç•™æœªç¼–è¾‘åŒºåŸŸï¼Œä»¥åŠå°†ç¨€ç–çš„äºŒç»´è¾“å…¥è½¬åŒ–ä¸ºé€¼çœŸçš„ä¸‰ç»´è§†é¢‘è¾“å‡ºã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Sketch3DVEï¼Œä¸€ç§åŸºäºè‰å›¾çš„ä¸‰ç»´è§†é¢‘ç¼–è¾‘æ–¹æ³•ï¼Œå®ç°å¯¹è§†ç‚¹å˜åŒ–æ˜¾è‘—çš„è§†é¢‘çš„è¯¦ç»†å±€éƒ¨æ“ä½œã€‚ä¸ºäº†è§£å†³ç¨€ç–è¾“å…¥å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é‡‡ç”¨å›¾åƒç¼–è¾‘æ–¹æ³•ä¸ºç¬¬ä¸€å¸§ç”Ÿæˆç¼–è¾‘ç»“æœï¼Œç„¶åå°†è¿™äº›ç»“æœä¼ æ’­åˆ°è§†é¢‘çš„å…¶ä½™å¸§ã€‚æˆ‘ä»¬ä½¿ç”¨è‰å›¾ä½œä¸ºä¸€ç§äº¤äº’å·¥å…·è¿›è¡Œç²¾ç¡®çš„å‡ ä½•æ§åˆ¶ï¼ŒåŒæ—¶æ”¯æŒå…¶ä»–åŸºäºé®ç½©çš„å›¾åƒç¼–è¾‘æ–¹æ³•ã€‚ä¸ºäº†å¤„ç†è§†ç‚¹å˜åŒ–ï¼Œæˆ‘ä»¬å¯¹è§†é¢‘ä¸­çš„ä¸‰ç»´ä¿¡æ¯è¿›è¡Œè¯¦ç»†çš„åˆ†æå’Œæ“ä½œã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨å¯†é›†ç«‹ä½“æ–¹æ³•ä¼°è®¡ç‚¹äº‘å’Œè¾“å…¥è§†é¢‘çš„ç›¸æœºå‚æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‚¹äº‘ç¼–è¾‘æ–¹æ³•ï¼Œä½¿ç”¨æ·±åº¦å›¾æ¥è¡¨ç¤ºæ–°ç¼–è¾‘ç»„ä»¶çš„ä¸‰ç»´å‡ ä½•å½¢çŠ¶ï¼Œå¹¶å°†å…¶æœ‰æ•ˆåœ°ä¸åŸå§‹ä¸‰ç»´åœºæ™¯å¯¹é½ã€‚ä¸ºäº†æ— ç¼åœ°å°†æ–°ç¼–è¾‘çš„å†…å®¹ä¸åŸå§‹è§†é¢‘åˆå¹¶ï¼ŒåŒæ—¶ä¿ç•™æœªç¼–è¾‘åŒºåŸŸçš„ç‰¹ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸‰ç»´æ„ŸçŸ¥é®ç½©ä¼ æ’­ç­–ç•¥ï¼Œå¹¶é‡‡ç”¨äº†è§†é¢‘æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆé€¼çœŸçš„ç¼–è¾‘è§†é¢‘ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSketch3DVEåœ¨è§†é¢‘ç¼–è¾‘æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚ä¸»é¡µå’Œä»£ç ï¼š<a target="_blank" rel="noopener" href="http://geometrylearning.com/Sketch3DVE/%EF%BC%88%E6%B3%A8%EF%BC%9A%E7%BD%91%E5%9D%80%E9%83%A8%E5%88%86%E4%BC%BC%E4%B9%8E%E6%9C%89%E8%AF%AF%E9%87%8D%E5%A4%8D%EF%BC%8C%E5%8E%9F%E6%96%87%E4%B8%AD%E7%9A%84%E7%BD%91%E5%9D%80%E9%93%BE%E6%8E%A5%E9%9C%80%E8%A6%81%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%A3%80%E6%9F%A5%E5%B9%B6%E4%BF%AE%E6%AD%A3%EF%BC%89">http://geometrylearning.com/Sketch3DVE/ï¼ˆæ³¨ï¼šç½‘å€éƒ¨åˆ†ä¼¼ä¹æœ‰è¯¯é‡å¤ï¼ŒåŸæ–‡ä¸­çš„ç½‘å€é“¾æ¥éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥å¹¶ä¿®æ­£ï¼‰</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13797v1">PDF</a> SIGGRAPH 2025</p>
<p><strong>æ‘˜è¦</strong><br>è§†é¢‘ç¼–è¾‘ä¸­ç»“æ„å†…å®¹çš„ç¼–è¾‘ä»ç„¶æ˜¯éš¾ç‚¹ï¼Œç‰¹åˆ«æ˜¯é¢å¯¹å¤§è§†è§’å˜åŒ–æ—¶çš„ç¼–è¾‘æŒ‘æˆ˜é‡é‡ã€‚ä¸ºå®ç°ç²¾ç¡®çš„å±€éƒ¨æ“ä½œï¼Œæå‡ºäº†ä¸€ç§åŸºäºè‰å›¾çš„3Dæ„ŸçŸ¥è§†é¢‘ç¼–è¾‘æ–¹æ³•Sketch3DVEã€‚åˆ©ç”¨å›¾åƒç¼–è¾‘æ–¹æ³•è§£å†³ç¨€ç–è¾“å…¥é—®é¢˜ï¼Œåˆ©ç”¨è‰å›¾ä½œä¸ºäº¤äº’å·¥å…·è¿›è¡Œç²¾ç¡®çš„å‡ ä½•æ§åˆ¶ã€‚é€šè¿‡å¯†é›†ç«‹ä½“æ³•ä¼°è®¡ç‚¹äº‘å’Œè¾“å…¥è§†é¢‘çš„æ‘„åƒæœºå‚æ•°ï¼Œæå‡ºä¸€ç§ç‚¹äº‘ç¼–è¾‘æ–¹æ³•ï¼Œä½¿ç”¨æ·±åº¦å›¾è¡¨ç¤ºæ–°ç¼–è¾‘ç»„ä»¶çš„3Då‡ ä½•ç»“æ„ï¼Œæœ‰æ•ˆåœ°ä¸åŸå§‹3Dåœºæ™¯å¯¹é½ã€‚æ— ç¼èåˆæ–°å†…å®¹ä¸åŸå§‹è§†é¢‘ï¼ŒåŒæ—¶ä¿ç•™æœªç¼–è¾‘åŒºåŸŸç‰¹å¾ï¼Œé‡‡ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹ç”ŸæˆçœŸå®ç¼–è¾‘è§†é¢‘ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è§†é¢‘çš„ç»“æ„å†…å®¹ç¼–è¾‘ï¼Œç‰¹åˆ«æ˜¯å¤§è§†è§’å˜åŒ–çš„ç¼–è¾‘ï¼Œä»æ˜¯ç ”ç©¶çš„æŒ‘æˆ˜ã€‚</li>
<li>Sketch3DVEæ–¹æ³•å®ç°äº†åŸºäºè‰å›¾çš„3Dæ„ŸçŸ¥è§†é¢‘ç¼–è¾‘ï¼Œæ”¯æŒè¯¦ç»†å±€éƒ¨æ“ä½œã€‚</li>
<li>åˆ©ç”¨å›¾åƒç¼–è¾‘æ–¹æ³•è§£å†³ç¨€ç–è¾“å…¥é—®é¢˜ï¼Œé€šè¿‡è‰å›¾è¿›è¡Œç²¾ç¡®çš„å‡ ä½•æ§åˆ¶ã€‚</li>
<li>é‡‡ç”¨å¯†é›†ç«‹ä½“æ³•ä¼°è®¡ç‚¹äº‘å’Œæ‘„åƒæœºå‚æ•°ï¼Œå¤„ç†è§†è§’å˜åŒ–ã€‚</li>
<li>ç‚¹äº‘ç¼–è¾‘æ–¹æ³•ä½¿ç”¨æ·±åº¦å›¾ä¸åŸå§‹3Dåœºæ™¯å¯¹é½æ–°ç¼–è¾‘çš„3Då‡ ä½•ç»“æ„ã€‚</li>
<li>åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹ç”ŸæˆçœŸå®ä¸”æ— ç¼èåˆæ–°å†…å®¹ä¸åŸå§‹è§†é¢‘ã€‚</li>
<li>Sketch3DVEåœ¨è§†é¢‘ç¼–è¾‘æ–¹é¢çš„ä¼˜è¶Šæ€§å¾—åˆ°äº†å¹¿æ³›å®éªŒçš„éªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13797">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-80c805b39ad2e1e74a0361e2984a8d21.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d013a4311e283c7834fe5ea23dd7ea3d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58a59461c5f99748fd9764c968638e27.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Eliminating-Rasterization-Direct-Vector-Floor-Plan-Generation-with-DiffPlanner"><a href="#Eliminating-Rasterization-Direct-Vector-Floor-Plan-Generation-with-DiffPlanner" class="headerlink" title="Eliminating Rasterization: Direct Vector Floor Plan Generation with   DiffPlanner"></a>Eliminating Rasterization: Direct Vector Floor Plan Generation with   DiffPlanner</h2><p><strong>Authors:Shidong Wang, Renato Pajarola</strong></p>
<p>The boundary-constrained floor plan generation problem aims to generate the topological and geometric properties of a set of rooms within a given boundary. Recently, learning-based methods have made significant progress in generating realistic floor plans. However, these methods involve a workflow of converting vector data into raster images, using image-based generative models, and then converting the results back into vector data. This process is complex and redundant, often resulting in information loss. Raster images, unlike vector data, cannot scale without losing detail and precision. To address these issues, we propose a novel deep learning framework called DiffPlanner for boundary-constrained floor plan generation, which operates entirely in vector space. Our framework is a Transformer-based conditional diffusion model that integrates an alignment mechanism in training, aligning the optimization trajectory of the model with the iterative design processes of designers. This enables our model to handle complex vector data, better fit the distribution of the predicted targets, accomplish the challenging task of floor plan layout design, and achieve user-controllable generation. We conduct quantitative comparisons, qualitative evaluations, ablation experiments, and perceptual studies to evaluate our method. Extensive experiments demonstrate that DiffPlanner surpasses existing state-of-the-art methods in generating floor plans and bubble diagrams in the creative stages, offering more controllability to users and producing higher-quality results that closely match the ground truths. </p>
<blockquote>
<p>è¾¹ç•Œçº¦æŸçš„å¹³é¢å›¾ç”Ÿæˆé—®é¢˜æ—¨åœ¨ç”Ÿæˆç»™å®šè¾¹ç•Œå†…çš„ä¸€ç»„æˆ¿é—´çš„æ‹“æ‰‘å’Œå‡ ä½•å±æ€§ã€‚æœ€è¿‘ï¼ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨ç”Ÿæˆé€¼çœŸçš„å¹³é¢å›¾æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éœ€è¦å°†çŸ¢é‡æ•°æ®è½¬æ¢ä¸ºæ …æ ¼å›¾åƒï¼Œä½¿ç”¨åŸºäºå›¾åƒçš„ç”Ÿæˆæ¨¡å‹ï¼Œç„¶åå°†ç»“æœè½¬å›çŸ¢é‡æ•°æ®çš„å·¥ä½œæµç¨‹ã€‚è¿™ä¸ªè¿‡ç¨‹å¤æ‚ä¸”å†—ä½™ï¼Œç»å¸¸å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ã€‚ä¸çŸ¢é‡æ•°æ®ä¸åŒï¼Œæ …æ ¼å›¾åƒæ— æ³•åœ¨ä¸æŸå¤±ç»†èŠ‚å’Œç²¾åº¦çš„æƒ…å†µä¸‹è¿›è¡Œç¼©æ”¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºDiffPlannerçš„æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè¾¹ç•Œçº¦æŸçš„å¹³é¢å›¾ç”Ÿæˆï¼Œå®ƒå®Œå…¨åœ¨çŸ¢é‡ç©ºé—´ä¸­è¿›è¡Œæ“ä½œã€‚æˆ‘ä»¬çš„æ¡†æ¶æ˜¯ä¸€ä¸ªåŸºäºTransformerçš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œåœ¨è®­ç»ƒä¸­é›†æˆäº†å¯¹é½æœºåˆ¶ï¼Œä½¿æ¨¡å‹çš„ä¼˜åŒ–è½¨è¿¹ä¸è®¾è®¡å¸ˆçš„è¿­ä»£è®¾è®¡è¿‡ç¨‹å¯¹é½ã€‚è¿™ä½¿å¾—æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿå¤„ç†å¤æ‚çš„çŸ¢é‡æ•°æ®ï¼Œæ›´å¥½åœ°é€‚åº”é¢„æµ‹ç›®æ ‡åˆ†å¸ƒï¼Œå®Œæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„å¹³é¢å›¾å¸ƒå±€è®¾è®¡ä»»åŠ¡ï¼Œå¹¶å®ç°ç”¨æˆ·å¯æ§çš„ç”Ÿæˆã€‚æˆ‘ä»¬è¿›è¡Œäº†å®šé‡æ¯”è¾ƒã€å®šæ€§è¯„ä¼°ã€å‰”é™¤å®éªŒå’Œæ„ŸçŸ¥ç ”ç©¶æ¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDiffPlanneråœ¨åˆ›æ„é˜¶æ®µç”Ÿæˆå¹³é¢å›¾å’Œæ°”æ³¡å›¾æ–¹é¢è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¤šå¯æ§æ€§ï¼Œå¹¶äº§ç”Ÿæ›´æ¥è¿‘çœŸå®çš„é«˜è´¨é‡ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13738v1">PDF</a> accepted to IEEE Transactions on Visualization and Computer Graphics</p>
<p><strong>Summary</strong></p>
<p>åŸºäºè¾¹ç•Œçº¦æŸçš„å¹³é¢å›¾ç”Ÿæˆé—®é¢˜æ—¨åœ¨ç”Ÿæˆç»™å®šè¾¹ç•Œå†…çš„ä¸€ç»„æˆ¿é—´çš„æ‹“æ‰‘å’Œå‡ ä½•å±æ€§ã€‚ä¼ ç»Ÿçš„åŸºäºå­¦ä¹ çš„æ–¹æ³•éœ€è¦å°†çŸ¢é‡æ•°æ®è½¬æ¢ä¸ºæ …æ ¼å›¾åƒï¼Œä½¿ç”¨åŸºäºå›¾åƒçš„ç”Ÿæˆæ¨¡å‹ï¼Œç„¶åå†å°†ç»“æœè½¬å›çŸ¢é‡æ•°æ®ï¼Œè¿™ä¸€è¿‡ç¨‹å¤æ‚ä¸”å†—ä½™ï¼Œå¸¸å¸¸å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åä¸ºDiffPlannerçš„æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåœ¨çŸ¢é‡ç©ºé—´å†…å®Œå…¨è¿›è¡Œè¾¹ç•Œçº¦æŸçš„å¹³é¢å›¾ç”Ÿæˆã€‚é€šè¿‡é›†æˆå¯¹é½æœºåˆ¶è¿›è¡ŒåŸ¹è®­ï¼ŒDiffPlannerå°†æ¨¡å‹ä¼˜åŒ–è½¨è¿¹ä¸è®¾è®¡å¸ˆçš„è¿­ä»£è®¾è®¡è¿‡ç¨‹å¯¹é½ï¼Œä»è€Œæ›´å¥½åœ°å¤„ç†å¤æ‚çŸ¢é‡æ•°æ®ï¼Œæ›´å¥½åœ°é€‚åº”é¢„æµ‹ç›®æ ‡çš„åˆ†å¸ƒï¼Œå®Œæˆå¤æ‚çš„å¹³é¢å›¾å¸ƒå±€è®¾è®¡ä»»åŠ¡ï¼Œå¹¶å®ç°ç”¨æˆ·å¯æ§çš„ç”Ÿæˆã€‚å®éªŒè¯æ˜ï¼ŒDiffPlanneråœ¨åˆ›æ„é˜¶æ®µçš„å¹³é¢å›¾ç”Ÿæˆå’Œæ°”æ³¡å›¾ç”Ÿæˆæ–¹é¢è¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¤šæ§åˆ¶åŠ›å¹¶äº§ç”Ÿæ›´æ¥è¿‘çœŸå®çš„é«˜è´¨é‡ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¾¹ç•Œçº¦æŸçš„å¹³é¢å›¾ç”Ÿæˆé—®é¢˜æ—¨åœ¨ç”Ÿæˆç»™å®šè¾¹ç•Œå†…çš„æˆ¿é—´æ‹“æ‰‘å’Œå‡ ä½•å±æ€§ã€‚</li>
<li>ç°æœ‰å­¦ä¹ æ–¹æ³•çš„è½¬æ¢æµç¨‹å¤æ‚ä¸”å†—ä½™ï¼Œå­˜åœ¨ä¿¡æ¯ä¸¢å¤±çš„é—®é¢˜ã€‚</li>
<li>DiffPlanneræ˜¯ä¸€ä¸ªæ–°å‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®Œå…¨åœ¨çŸ¢é‡ç©ºé—´å†…è¿›è¡Œè¾¹ç•Œçº¦æŸçš„å¹³é¢å›¾ç”Ÿæˆã€‚</li>
<li>DiffPlanneré›†æˆäº†å¯¹é½æœºåˆ¶è¿›è¡ŒåŸ¹è®­ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹å¤„ç†å¤æ‚çŸ¢é‡æ•°æ®çš„èƒ½åŠ›ã€‚</li>
<li>DiffPlannerå¯ä»¥æ›´å¥½åœ°é€‚åº”é¢„æµ‹ç›®æ ‡çš„åˆ†å¸ƒï¼Œå®Œæˆå¤æ‚çš„å¹³é¢å›¾å¸ƒå±€è®¾è®¡ä»»åŠ¡ã€‚</li>
<li>DiffPlannerå®ç°äº†ç”¨æˆ·å¯æ§çš„ç”Ÿæˆï¼Œä¸ºç”¨æˆ·æä¾›äº†æ›´å¤šæ§åˆ¶åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13738">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b40b2406d1a4fb9eb4b80c07610d3820.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-020ab9a5a8c388ce8ac4d26514c2179c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a734c880fe89137110041f5e09beafbd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bcc1e2275233d41a0beba57d6fc12da7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bdab3f877dacd0e94ef927bba2342e5e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction"><a href="#DiffIER-Optimizing-Diffusion-Models-with-Iterative-Error-Reduction" class="headerlink" title="DiffIER: Optimizing Diffusion Models with Iterative Error Reduction"></a>DiffIER: Optimizing Diffusion Models with Iterative Error Reduction</h2><p><strong>Authors:Ao Chen, Lihe Ding, Tianfan Xue</strong></p>
<p>Diffusion models have demonstrated remarkable capabilities in generating high-quality samples and enhancing performance across diverse domains through Classifier-Free Guidance (CFG). However, the quality of generated samples is highly sensitive to the selection of the guidance weight. In this work, we identify a critical &#96;&#96;training-inference gapâ€™â€™ and we argue that it is the presence of this gap that undermines the performance of conditional generation and renders outputs highly sensitive to the guidance weight. We quantify this gap by measuring the accumulated error during the inference stage and establish a correlation between the selection of guidance weight and minimizing this gap. Furthermore, to mitigate this gap, we propose DiffIER, an optimization-based method for high-quality generation. We demonstrate that the accumulated error can be effectively reduced by an iterative error minimization at each step during inference. By introducing this novel plug-and-play optimization framework, we enable the optimization of errors at every single inference step and enhance generation quality. Empirical results demonstrate that our proposed method outperforms baseline approaches in conditional generation tasks. Furthermore, the method achieves consistent success in text-to-image generation, image super-resolution, and text-to-speech generation, underscoring its versatility and potential for broad applications in future research. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å’Œæé«˜ä¸åŒé¢†åŸŸçš„æ€§èƒ½æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”Ÿæˆæ ·æœ¬çš„è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºäº†ä¸€ä¸ªå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œæˆ‘ä»¬è®¤ä¸ºæ­£æ˜¯è¿™ä¸ªå·®è·å½±å“äº†æ¡ä»¶ç”Ÿæˆçš„è¡¨ç°ï¼Œå¹¶ä½¿è¾“å‡ºé«˜åº¦ä¾èµ–äºå¼•å¯¼æƒé‡ã€‚æˆ‘ä»¬é€šè¿‡æµ‹é‡æ¨ç†é˜¶æ®µçš„ç´¯ç§¯è¯¯å·®æ¥é‡åŒ–è¿™ä¸ªå·®è·ï¼Œå¹¶å»ºç«‹äº†é€‰æ‹©å¼•å¯¼æƒé‡ä¸æœ€å°åŒ–è¿™ä¸ªå·®è·ä¹‹é—´çš„å…³è”ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¼“è§£è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†DiffIERï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¼˜åŒ–çš„é«˜è´¨é‡ç”Ÿæˆæ–¹æ³•ã€‚æˆ‘ä»¬è¯æ˜ï¼Œé€šè¿‡æ¨ç†è¿‡ç¨‹ä¸­æ¯ä¸€æ­¥çš„è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘ç´¯ç§¯è¯¯å·®ã€‚é€šè¿‡å¼•å…¥è¿™ç§æ–°é¢–å³æ’å³ç”¨çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¯ä¸€ä¸ªå•ç‹¬æ¨ç†æ­¥éª¤ä¸­ä¼˜åŒ–è¯¯å·®ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆæ–¹é¢å–å¾—äº†æŒç»­çš„æˆåŠŸï¼Œè¿™çªæ˜¾äº†å…¶åœ¨æœªæ¥ç ”ç©¶ä¸­çš„é€šç”¨æ€§å’Œå¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.13628v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å’Œæå‡æ€§èƒ½æ–¹é¢çš„æ˜¾è‘—èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰å®ç°ã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„æ ·æœ¬è´¨é‡å¯¹å¼•å¯¼æƒé‡çš„é€‰æ‹©éå¸¸æ•æ„Ÿã€‚æœ¬æ–‡è¯†åˆ«å‡ºå…³é”®çš„â€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œå¹¶è®¤ä¸ºè¿™ä¸€å·®è·å½±å“äº†æ¡ä»¶ç”Ÿæˆæ€§èƒ½ï¼Œä½¿è¾“å‡ºå¯¹å¼•å¯¼æƒé‡é«˜åº¦æ•æ„Ÿã€‚ä¸ºå‡å°‘è¿™ä¸€å·®è·ï¼Œæå‡ºäº†DiffIERè¿™ä¸€åŸºäºä¼˜åŒ–çš„é«˜è´¨é‡ç”Ÿæˆæ–¹æ³•ã€‚é€šè¿‡è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œåœ¨æ¨ç†é˜¶æ®µæ¯ä¸€æ­¥ä¼˜åŒ–è¯¯å·®ï¼Œæé«˜äº†ç”Ÿæˆè´¨é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œå¹¶åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡å’Œæ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆç­‰ä»»åŠ¡ä¸­å–å¾—äº†æŒç»­çš„æˆåŠŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰å±•ç°å‡ºå¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>ç”Ÿæˆçš„æ ·æœ¬è´¨é‡å—å¼•å¯¼æƒé‡é€‰æ‹©çš„æ˜¾è‘—å½±å“ã€‚</li>
<li>æ–‡ä¸­è¯†åˆ«å‡ºâ€œè®­ç»ƒ-æ¨ç†å·®è·â€ï¼Œè¿™ä¸€å·®è·å½±å“æ¡ä»¶ç”Ÿæˆæ€§èƒ½ã€‚</li>
<li>æå‡ºDiffIERæ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–å‡å°‘æ¨ç†é˜¶æ®µçš„è¯¯å·®ç§¯ç´¯ã€‚</li>
<li>DiffIERæ–¹æ³•é€šè¿‡è¿­ä»£è¯¯å·®æœ€å°åŒ–ï¼Œåœ¨æ¨ç†æ¯ä¸€æ­¥ä¼˜åŒ–è¯¯å·®ã€‚</li>
<li>DiffIERæ–¹æ³•åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.13628">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ce8567172c5b65f3efbc7b60363c2a9a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b930ab27e19b587a0b375e5b562d4d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e391cf99658d7fa44fd322b3db1d0ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d613ceafcd367c3788f918797f75b6e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90754254ba6f2d1faf962c9d63bcf529.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Dataset-Condensation-with-Color-Compensation"><a href="#Dataset-Condensation-with-Color-Compensation" class="headerlink" title="Dataset Condensation with Color Compensation"></a>Dataset Condensation with Color Compensation</h2><p><strong>Authors:Huyu Wu, Duo Su, Junjie Hou, Guang Li</strong></p>
<p>Dataset condensation always faces a constitutive trade-off: balancing performance and fidelity under extreme compression. Existing methods struggle with two bottlenecks: image-level selection methods (Coreset Selection, Dataset Quantization) suffer from inefficiency condensation, while pixel-level optimization (Dataset Distillation) introduces semantic distortion due to over-parameterization. With empirical observations, we find that a critical problem in dataset condensation is the oversight of colorâ€™s dual role as an information carrier and a basic semantic representation unit. We argue that improving the colorfulness of condensed images is beneficial for representation learning. Motivated by this, we propose DC3: a Dataset Condensation framework with Color Compensation. After a calibrated selection strategy, DC3 utilizes the latent diffusion model to enhance the color diversity of an image rather than creating a brand-new one. Extensive experiments demonstrate the superior performance and generalization of DC3 that outperforms SOTA methods across multiple benchmarks. To the best of our knowledge, besides focusing on downstream tasks, DC3 is the first research to fine-tune pre-trained diffusion models with condensed datasets. The FID results prove that training networks with our high-quality datasets is feasible without model collapse or other degradation issues. Code and generated data are available at <a target="_blank" rel="noopener" href="https://github.com/528why/Dataset-Condensation-with-Color-Compensation">https://github.com/528why/Dataset-Condensation-with-Color-Compensation</a>. </p>
<blockquote>
<p>æ•°æ®é›†å‹ç¼©å§‹ç»ˆé¢ä¸´ä¸€ä¸ªåŸºæœ¬çš„æƒè¡¡ï¼šåœ¨æç«¯å‹ç¼©æƒ…å†µä¸‹å¹³è¡¡æ€§èƒ½å’Œä¿çœŸåº¦ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´ä¸¤ä¸ªç“¶é¢ˆï¼šå›¾åƒçº§åˆ«çš„é€‰æ‹©æ–¹æ³•ï¼ˆæ ¸å¿ƒé›†é€‰æ‹©ã€æ•°æ®é›†é‡åŒ–ï¼‰å­˜åœ¨å‹ç¼©æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œè€Œåƒç´ çº§åˆ«çš„ä¼˜åŒ–ï¼ˆæ•°æ®é›†è’¸é¦ï¼‰ç”±äºè¿‡åº¦å‚æ•°åŒ–è€Œå¯¼è‡´è¯­ä¹‰å¤±çœŸã€‚é€šè¿‡ç»éªŒè§‚å¯Ÿï¼Œæˆ‘ä»¬å‘ç°æ•°æ®é›†å‹ç¼©ä¸­çš„å…³é”®é—®é¢˜æ˜¯å¿½è§†äº†é¢œè‰²ä½œä¸ºä¿¡æ¯è½½ä½“å’ŒåŸºæœ¬è¯­ä¹‰è¡¨ç¤ºå•å…ƒçš„åŒé‡ä½œç”¨ã€‚æˆ‘ä»¬è®¤ä¸ºæé«˜æµ“ç¼©å›¾åƒçš„è‰²å½©ä¸°å¯Œåº¦å¯¹è¡¨ç¤ºå­¦ä¹ æ˜¯æœ‰ç›Šçš„ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†DC3ï¼šä¸€ç§å…·æœ‰é¢œè‰²è¡¥å¿çš„æ•°æ®é›†å‹ç¼©æ¡†æ¶ã€‚ç»è¿‡æ ¡å‡†çš„é€‰æ‹©ç­–ç•¥åï¼ŒDC3åˆ©ç”¨æ½œåœ¨çš„æ‰©æ•£æ¨¡å‹æ¥æé«˜å›¾åƒçš„é¢œè‰²å¤šæ ·æ€§ï¼Œè€Œä¸æ˜¯åˆ›å»ºå…¨æ–°çš„å›¾åƒã€‚å¤§é‡å®éªŒè¯æ˜äº†DC3çš„å“è¶Šæ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå®ƒåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œé™¤äº†å…³æ³¨ä¸‹æ¸¸ä»»åŠ¡å¤–ï¼ŒDC3æ˜¯é¦–æ¬¡ä½¿ç”¨æµ“ç¼©æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒçš„ç ”ç©¶ã€‚FIDç»“æœè¯æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬é«˜è´¨é‡çš„æ•°æ®é›†è®­ç»ƒç½‘ç»œæ˜¯å¯è¡Œçš„ï¼Œä¸ä¼šå‡ºç°æ¨¡å‹å´©æºƒæˆ–å…¶ä»–é€€åŒ–é—®é¢˜ã€‚ä»£ç å’Œç”Ÿæˆçš„æ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/528why/Dataset-Condensation-with-Color-Compensation%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/528why/Dataset-Condensation-with-Color-Compensationæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01139v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ•°æ®é›†å‹ç¼©ä¸­é¢œè‰²è¡¥å¿çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§åä¸ºDC3çš„æ–°çš„æ•°æ®é›†å‹ç¼©æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹æé«˜å›¾åƒçš„é¢œè‰²å¤šæ ·æ€§ï¼Œè€Œéåˆ›å»ºå…¨æ–°å›¾åƒã€‚å®éªŒè¯æ˜ï¼ŒDC3åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒDC3è¿˜æ˜¯é¦–æ¬¡å°è¯•ä½¿ç”¨å‹ç¼©æ•°æ®é›†å¾®è°ƒé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°æ®é›†å‹ç¼©é¢ä¸´æ€§èƒ½ä¸ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>ç°å­˜æ–¹æ³•é¢ä¸´ä¸¤ä¸ªç“¶é¢ˆï¼šå›¾åƒçº§åˆ«çš„é€‰æ‹©æ–¹æ³•æ•ˆç‡ä½ä¸‹ï¼Œåƒç´ çº§åˆ«çš„ä¼˜åŒ–åˆ™ä¼šå¯¼è‡´è¯­ä¹‰å¤±çœŸã€‚</li>
<li>é¢œè‰²åœ¨æ•°æ®é›†å‹ç¼©ä¸­è¢«å¿½è§†ï¼Œå…¶ä½œä¸ºä¿¡æ¯è½½ä½“å’ŒåŸºæœ¬è¯­ä¹‰è¡¨ç¤ºå•å…ƒçš„åŒé‡è§’è‰²è‡³å…³é‡è¦ã€‚</li>
<li>æé«˜å‹ç¼©å›¾åƒçš„è‰²å½©ä¸°å¯Œæ€§å¯¹è¡¨ç¤ºå­¦ä¹ æœ‰ç›Šã€‚</li>
<li>DC3æ¡†æ¶åˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹å¢å¼ºå›¾åƒé¢œè‰²å¤šæ ·æ€§ï¼Œè€Œéåˆ›å»ºæ–°å›¾åƒã€‚</li>
<li>DC3åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01139">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-630b00efd2d061afd9a11ab944027c66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56864f32a6be3157cf8419598b8a0ef3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cb4ca5253346b54422b59417f9e47a24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-74b82e4cecdb2b1c651ed8d1c683724a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9598b7bdd0694b6317b792c181241df0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8ad3d49e29ca448dc9ffb35a01428f9b.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="LoRA-Edit-Controllable-First-Frame-Guided-Video-Editing-via-Mask-Aware-LoRA-Fine-Tuning"><a href="#LoRA-Edit-Controllable-First-Frame-Guided-Video-Editing-via-Mask-Aware-LoRA-Fine-Tuning" class="headerlink" title="LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware   LoRA Fine-Tuning"></a>LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware   LoRA Fine-Tuning</h2><p><strong>Authors:Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, Tianfan Xue</strong></p>
<p>Video editing using diffusion models has achieved remarkable results in generating high-quality edits for videos. However, current methods often rely on large-scale pretraining, limiting flexibility for specific edits. First-frame-guided editing provides control over the first frame, but lacks flexibility over subsequent frames. To address this, we propose a mask-based LoRA (Low-Rank Adaptation) tuning method that adapts pretrained Image-to-Video (I2V) models for flexible video editing. Our key innovation is using a spatiotemporal mask to strategically guide the LoRA fine-tuning process. This teaches the model two distinct skills: first, to interpret the mask as a command to either preserve content from the source video or generate new content in designated regions. Second, for these generated regions, LoRA learns to synthesize either temporally consistent motion inherited from the video or novel appearances guided by user-provided reference frames. This dual-capability LoRA grants users control over the editâ€™s entire temporal evolution, allowing complex transformations like an object rotating or a flower blooming. Experimental results show our method achieves superior video editing performance compared to baseline methods. Project Page: <a target="_blank" rel="noopener" href="https://cjeen.github.io/LoRAEdit">https://cjeen.github.io/LoRAEdit</a> </p>
<blockquote>
<p>ä½¿ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œè§†é¢‘ç¼–è¾‘å·²ç»åœ¨ä¸ºé«˜è´¨é‡è§†é¢‘ç”Ÿæˆç¼–è¾‘æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œè¿™é™åˆ¶äº†ç‰¹å®šç¼–è¾‘çš„çµæ´»æ€§ã€‚ç¬¬ä¸€å¸§å¼•å¯¼ç¼–è¾‘æä¾›äº†å¯¹ç¬¬ä¸€å¸§çš„æ§åˆ¶ï¼Œä½†ç¼ºä¹å¯¹åç»­å¸§çš„çµæ´»æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ©è†œçš„LoRAï¼ˆä½ç§©é€‚åº”ï¼‰è°ƒä¼˜æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯é€‚åº”é¢„è®­ç»ƒçš„å›¾ç”Ÿè§†é¢‘ï¼ˆI2Vï¼‰æ¨¡å‹ï¼Œç”¨äºçµæ´»è§†é¢‘ç¼–è¾‘ã€‚æˆ‘ä»¬çš„ä¸»è¦åˆ›æ–°ä¹‹å¤„åœ¨äºä½¿ç”¨æ—¶ç©ºæ©è†œæ¥æˆ˜ç•¥æ€§æŒ‡å¯¼LoRAå¾®è°ƒè¿‡ç¨‹ã€‚è¿™æ•™ä¼šäº†æ¨¡å‹ä¸¤ç§ç‹¬ç‰¹æŠ€èƒ½ï¼šé¦–å…ˆï¼Œå°†æ©è†œè§£é‡Šä¸ºæ¥è‡ªæºè§†é¢‘çš„æŒ‡ä»¤ï¼Œè¦ä¹ˆä¿ç•™å†…å®¹ï¼Œè¦ä¹ˆåœ¨æŒ‡å®šåŒºåŸŸç”Ÿæˆæ–°å†…å®¹ã€‚å…¶æ¬¡ï¼Œå¯¹äºè¿™äº›ç”Ÿæˆçš„åŒºåŸŸï¼ŒLoRAå­¦ä¹ åˆæˆä»è§†é¢‘ä¸­ç»§æ‰¿çš„æ—¶é—´è¿è´¯è¿åŠ¨æˆ–æ ¹æ®ç”¨æˆ·æä¾›çš„å‚è€ƒå¸§å¼•å¯¼çš„æ–°å¤–è§‚ã€‚è¿™ç§åŒåŠŸèƒ½çš„LoRAä½¿ç”¨æˆ·èƒ½å¤Ÿæ§åˆ¶æ•´ä¸ªæ—¶é—´è½´çš„ç¼–è¾‘è¿‡ç¨‹ï¼Œä»è€Œå®ç°å¤æ‚çš„è½¬æ¢ï¼Œå¦‚ç‰©ä½“æ—‹è½¬æˆ–èŠ±æœµç»½æ”¾ç­‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•å®ç°äº†æ›´å‡ºè‰²çš„è§†é¢‘ç¼–è¾‘æ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://cjeen.github.io/LoRAEdit">https://cjeen.github.io/LoRAEdit</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.10082v5">PDF</a> 9 pages</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨è§†é¢‘ç¼–è¾‘é¢†åŸŸå·²å–å¾—æ˜¾è‘—æˆæœï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ç¼–è¾‘ã€‚ä½†ç°æœ‰æ–¹æ³•å¸¸ä¾èµ–å¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œå¯¹ç‰¹å®šç¼–è¾‘çš„çµæ´»æ€§æœ‰é™ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåŸºäºæ©è†œçš„LoRAï¼ˆä½ç§©é€‚åº”ï¼‰è°ƒä¼˜æ–¹æ³•ï¼Œç”¨äºé€‚åº”é¢„è®­ç»ƒçš„å›¾ç”Ÿè§†é¢‘ï¼ˆI2Vï¼‰æ¨¡å‹ä»¥å®ç°çµæ´»çš„è§†é¢‘ç¼–è¾‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•å®ç°äº†æ›´ä¼˜è¶Šçš„è§†é¢‘ç¼–è¾‘æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨è§†é¢‘ç¼–è¾‘ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½ç”Ÿæˆé«˜è´¨é‡ç¼–è¾‘ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–å¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œç¼ºä¹ç‰¹å®šç¼–è¾‘çš„çµæ´»æ€§ã€‚</li>
<li>æå‡ºåŸºäºæ©è†œçš„LoRAè°ƒä¼˜æ–¹æ³•ï¼Œé€‚åº”I2Væ¨¡å‹è¿›è¡Œçµæ´»è§†é¢‘ç¼–è¾‘ã€‚</li>
<li>ä½¿ç”¨æ—¶ç©ºæ©è†œæŒ‡å¯¼LoRAå¾®è°ƒè¿‡ç¨‹ï¼Œæ•™ä¼šæ¨¡å‹ä¸¤ç§æŠ€èƒ½ï¼šä¿ç•™æºè§†é¢‘å†…å®¹æˆ–åœ¨æŒ‡å®šåŒºåŸŸç”Ÿæˆæ–°å†…å®¹ã€‚</li>
<li>LoRAå­¦ä¼šåˆæˆä¸è§†é¢‘ä¸€è‡´çš„ä¸´æ—¶è¿åŠ¨æˆ–æ ¹æ®ç”¨æˆ·æä¾›çš„å‚è€ƒå¸§ç”Ÿæˆæ–°å¤–è§‚ã€‚</li>
<li>åŒèƒ½åŠ›LoRAè®©ç”¨æˆ·æ§åˆ¶æ•´ä¸ªæ—¶é—´æ¼”åŒ–çš„ç¼–è¾‘ï¼Œå®ç°å¤æ‚è½¬æ¢ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.10082">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8780bfbcc28ad387e3a2fa9ca6ff71b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b523bea842cbe6864369eb70527919c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afc1b58b28c47fc05816d61943753412.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cbd38fa37eb7e2f5814e8a2fceab919c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-52615007f314127bbbab7a1f524cf042.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e694cbae35f3db72a7c567e0dbd23157.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Hyperspectral-Image-Generation-with-Unmixing-Guided-Diffusion-Model"><a href="#Hyperspectral-Image-Generation-with-Unmixing-Guided-Diffusion-Model" class="headerlink" title="Hyperspectral Image Generation with Unmixing Guided Diffusion Model"></a>Hyperspectral Image Generation with Unmixing Guided Diffusion Model</h2><p><strong>Authors:Shiyu Shen, Bin Pan, Ziye Zhang, Zhenwei Shi</strong></p>
<p>We address hyperspectral image (HSI) synthesis, a problem that has garnered growing interest yet remains constrained by the conditional generative paradigms that limit sample diversity. While diffusion models have emerged as a state-of-the-art solution for high-fidelity image generation, their direct extension from RGB to hyperspectral domains is challenged by the high spectral dimensionality and strict physical constraints inherent to HSIs. To overcome the challenges, we introduce a diffusion framework explicitly guided by hyperspectral unmixing. The approach integrates two collaborative components: (i) an unmixing autoencoder that projects generation from the image domain into a low-dimensional abundance manifold, thereby reducing computational burden while maintaining spectral fidelity; and (ii) an abundance diffusion process that enforces non-negativity and sum-to-one constraints, ensuring physical consistency of the synthesized data. We further propose two evaluation metrics tailored to hyperspectral characteristics. Comprehensive experiments, assessed with both conventional measures and the proposed metrics, demonstrate that our method produces HSIs with both high quality and diversity, advancing the state of the art in hyperspectral data generation. </p>
<blockquote>
<p>æˆ‘ä»¬å…³æ³¨é«˜å…‰è°±å›¾åƒï¼ˆHSIï¼‰çš„åˆæˆé—®é¢˜ã€‚è¿™ä¸€é—®é¢˜è™½ç„¶å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…´è¶£ï¼Œä½†ä»å—åˆ°æœ‰æ¡ä»¶ç”ŸæˆèŒƒå¼çš„çº¦æŸï¼Œè¿™äº›èŒƒå¼é™åˆ¶äº†æ ·æœ¬çš„å¤šæ ·æ€§ã€‚è™½ç„¶æ‰©æ•£æ¨¡å‹å·²æˆä¸ºé«˜ä¿çœŸå›¾åƒç”Ÿæˆçš„æœ€å…ˆè¿›è§£å†³æ–¹æ¡ˆï¼Œä½†å®ƒä»¬ä»RGBç›´æ¥æ‰©å±•åˆ°é«˜å…‰è°±é¢†åŸŸå´é¢ä¸´ç€é«˜å…‰è°±ç»´åº¦é«˜å’ŒHSIå›ºæœ‰çš„ä¸¥æ ¼ç‰©ç†çº¦æŸçš„æŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç”±é«˜å…‰è°±è§£æ··æ˜ç¡®æŒ‡å¯¼çš„æ‰©æ•£æ¡†æ¶ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä¸¤ä¸ªåä½œç»„ä»¶ï¼šï¼ˆiï¼‰ä¸€ä¸ªè§£æ··è‡ªç¼–ç å™¨ï¼Œå°†å›¾åƒåŸŸçš„ç”ŸæˆæŠ•å½±åˆ°ä½ç»´ä¸°åº¦æµå½¢ä¸Šï¼Œä»è€Œåœ¨ä¿æŒå…‰è°±ä¿çœŸåº¦çš„åŒæ—¶å‡å°‘è®¡ç®—è´Ÿæ‹…ï¼›ï¼ˆiiï¼‰ä¸€ä¸ªä¸°åº¦æ‰©æ•£è¿‡ç¨‹ï¼Œå¼ºåˆ¶æ‰§è¡Œéè´Ÿæ€§å’Œæ€»å’Œä¸ºä¸€çš„çº¦æŸï¼Œç¡®ä¿åˆæˆæ•°æ®çš„ç‰©ç†ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸¤ä¸ªé’ˆå¯¹é«˜å…‰è°±ç‰¹æ€§å®šåˆ¶çš„è¯„ä»·æŒ‡æ ‡ã€‚é€šè¿‡å¸¸è§„åº¦é‡æ–¹æ³•å’Œæ‰€æå‡ºçš„æŒ‡æ ‡è¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„é«˜å…‰è°±å›¾åƒè´¨é‡é«˜ã€å¤šæ ·æ€§å¥½ï¼Œæ¨åŠ¨äº†é«˜å…‰è°±æ•°æ®ç”Ÿæˆçš„æœ€æ–°æŠ€æœ¯è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02601v3">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>é’ˆå¯¹é«˜å…‰è°±å›¾åƒï¼ˆHSIï¼‰åˆæˆé—®é¢˜ï¼Œç”±äºæ¡ä»¶ç”ŸæˆèŒƒå¼é™åˆ¶äº†æ ·æœ¬å¤šæ ·æ€§ï¼Œè™½ç„¶æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†å…¶ç›´æ¥æ‰©å±•åˆ°é«˜å…‰è°±é¢†åŸŸé¢ä¸´é«˜å…‰è°±ç»´åº¦å’Œä¸¥æ ¼ç‰©ç†çº¦æŸçš„æŒ‘æˆ˜ã€‚ä¸ºå…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”±é«˜å…‰è°±è§£æ··å¼•å¯¼çš„æ‰©æ•£æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªåä½œç»„ä»¶ï¼šä¸€ï¼‰è§£æ··è‡ªç¼–ç å™¨å°†å›¾åƒåŸŸçš„ç”ŸæˆæŠ•å°„åˆ°ä½ç»´ä¸°åº¦æµå½¢ä¸Šï¼Œä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…å¹¶ä¿æŒå…‰è°±ä¿çœŸåº¦ï¼›äºŒï¼‰ä¸°åº¦æ‰©æ•£è¿‡ç¨‹å¼ºåˆ¶å®æ–½éè´Ÿæ€§å’Œæ€»å’Œä¸ºä¸€çš„çº¦æŸï¼Œä»¥ç¡®ä¿åˆæˆæ•°æ®çš„ç‰©ç†ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„é«˜å…‰è°±å›¾åƒå…·æœ‰é«˜è´¨é‡å’Œå¤šæ ·æ€§ï¼Œæ¨åŠ¨äº†é«˜å…‰è°±æ•°æ®ç”Ÿæˆçš„æœ€æ–°æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>é«˜å…‰è°±å›¾åƒåˆæˆé—®é¢˜å—é™äºæ¡ä»¶ç”ŸæˆèŒƒå¼çš„æ ·æœ¬å¤šæ ·æ€§ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å…·æœ‰å“è¶Šæ€§èƒ½ï¼Œä½†ç›´æ¥åº”ç”¨äºé«˜å…‰è°±é¢†åŸŸé¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºçš„æ‰©æ•£æ¡†æ¶ç”±é«˜å…‰è°±è§£æ··å¼•å¯¼ï¼ŒåŒ…æ‹¬è§£æ··è‡ªç¼–ç å™¨å’Œä¸°åº¦æ‰©æ•£è¿‡ç¨‹ä¸¤ä¸ªåä½œç»„ä»¶ã€‚</li>
<li>è§£æ··è‡ªç¼–ç å™¨å°†å›¾åƒç”ŸæˆæŠ•å°„åˆ°ä½ç»´ä¸°åº¦æµå½¢ä¸Šï¼Œä»¥ç»´æŒå…‰è°±ä¿çœŸåº¦å¹¶é™ä½è®¡ç®—è´Ÿæ‹…ã€‚</li>
<li>ä¸°åº¦æ‰©æ•£è¿‡ç¨‹ç¡®ä¿åˆæˆæ•°æ®çš„ç‰©ç†ä¸€è‡´æ€§ï¼Œé€šè¿‡å®æ–½éè´Ÿæ€§å’Œæ€»å’Œä¸ºä¸€çš„çº¦æŸã€‚</li>
<li>æå‡ºçš„æ–¹æ³•ç”Ÿæˆçš„é«˜å…‰è°±å›¾åƒå…·æœ‰é«˜è´¨é‡å’Œå¤šæ ·æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02601">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b8a07d4ee1d25cfc666ae508eb50897.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-adb3684ccff21516b9e30045d0378912.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-672383b77264f0a88ace6ac3bad1a191.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4eab5c0bc29cd9fd2d904aeb92d34906.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a82671eaeabd16ced1b2872e6d6d1d9c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Image-Augmentation-Agent-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Image-Augmentation-Agent-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Image Augmentation Agent for Weakly Supervised Semantic Segmentation"></a>Image Augmentation Agent for Weakly Supervised Semantic Segmentation</h2><p><strong>Authors:Wangyu Wu, Xianglin Qiu, Siqi Song, Zhenhong Chen, Xiaowei Huang, Fei Ma, Jimin Xiao</strong></p>
<p>Weakly-supervised semantic segmentation (WSSS) has achieved remarkable progress using only image-level labels. However, most existing WSSS methods focus on designing new network structures and loss functions to generate more accurate dense labels, overlooking the limitations imposed by fixed datasets, which can constrain performance improvements. We argue that more diverse trainable images provides WSSS richer information and help model understand more comprehensive semantic pattern. Therefore in this paper, we introduce a novel approach called Image Augmentation Agent (IAA) which shows that it is possible to enhance WSSS from data generation perspective. IAA mainly design an augmentation agent that leverages large language models (LLMs) and diffusion models to automatically generate additional images for WSSS. In practice, to address the instability in prompt generation by LLMs, we develop a prompt self-refinement mechanism. It allow LLMs to re-evaluate the rationality of generated prompts to produce more coherent prompts. Additionally, we insert an online filter into diffusion generation process to dynamically ensure the quality and balance of generated images. Experimental results show that our method significantly surpasses state-of-the-art WSSS approaches on the PASCAL VOC 2012 and MS COCO 2014 datasets. </p>
<blockquote>
<p>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰ä»…ä½¿ç”¨å›¾åƒçº§æ ‡ç­¾å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„WSSSæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è®¾è®¡æ–°çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°æ¥ç”Ÿæˆæ›´å‡†ç¡®çš„å¯†é›†æ ‡ç­¾ï¼Œå¿½è§†äº†å›ºå®šæ•°æ®é›†æ‰€å¸¦æ¥çš„é™åˆ¶ï¼Œè¿™äº›é™åˆ¶å¯èƒ½ä¼šé™åˆ¶æ€§èƒ½çš„æå‡ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæä¾›æ›´å¤šå¯è®­ç»ƒå›¾åƒçš„å¤šæ ·æ€§å¯ä»¥ä¸ºWSSSæä¾›æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œå¹¶å¸®åŠ©æ¨¡å‹ç†è§£æ›´å…¨é¢çš„è¯­ä¹‰æ¨¡å¼ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç§°ä¸ºå›¾åƒå¢å¼ºä»£ç†ï¼ˆIAAï¼‰ï¼Œå®ƒè¡¨æ˜ä»æ•°æ®ç”Ÿæˆçš„è§’åº¦å¢å¼ºWSSSæ˜¯å¯èƒ½çš„ã€‚IAAä¸»è¦è®¾è®¡ä¸€ä¸ªå¢å¼ºä»£ç†ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ä¸ºWSSSç”Ÿæˆé¢å¤–çš„å›¾åƒã€‚åœ¨å®è·µä¸­ï¼Œä¸ºäº†è§£å†³LLMæç¤ºç”Ÿæˆä¸­çš„ä¸ç¨³å®šé—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æç¤ºè‡ªæˆ‘ä¼˜åŒ–æœºåˆ¶ã€‚å®ƒå…è®¸LLMé‡æ–°è¯„ä¼°ç”Ÿæˆçš„æç¤ºçš„åˆç†æ€§ï¼Œä»¥äº§ç”Ÿæ›´è¿è´¯çš„æç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥äº†ä¸€ä¸ªåœ¨çº¿è¿‡æ»¤å™¨ï¼Œä»¥åŠ¨æ€ç¡®ä¿ç”Ÿæˆçš„å›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†æœ€å…ˆè¿›çš„WSSSæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20439v3">PDF</a> Accepted at Neurocomputing 2025</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§åä¸ºImage Augmentation Agentï¼ˆIAAï¼‰çš„æ–¹æ³•ï¼Œä»æ•°æ®ç”Ÿæˆçš„è§’åº¦æå‡å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆé¢å¤–çš„å›¾åƒï¼Œå¢å¼ºWSSSçš„è®­ç»ƒå›¾åƒå¤šæ ·æ€§ã€‚åŒæ—¶ï¼Œä¸ºè§£å†³LLMsåœ¨ç”Ÿæˆæç¤ºæ—¶çš„ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œæå‡ºäº†æç¤ºè‡ªæˆ‘ä¼˜åŒ–æœºåˆ¶ï¼Œå¹¶é€šè¿‡åœ¨çº¿è¿‡æ»¤å™¨ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡æ€§ã€‚åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„WSSSæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>IAAæ–¹æ³•ä»æ•°æ®ç”Ÿæˆè§’åº¦æå‡WSSSæ€§èƒ½ï¼Œé€šè¿‡è‡ªåŠ¨ç”Ÿæˆé¢å¤–å›¾åƒå¢åŠ è®­ç»ƒå›¾åƒå¤šæ ·æ€§ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹å®ç°å›¾åƒè‡ªåŠ¨ç”Ÿæˆã€‚</li>
<li>æå‡ºæç¤ºè‡ªæˆ‘ä¼˜åŒ–æœºåˆ¶ï¼Œè§£å†³LLMsåœ¨ç”Ÿæˆæç¤ºæ—¶çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚</li>
<li>é€šè¿‡åœ¨çº¿è¿‡æ»¤å™¨ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡æ€§ã€‚</li>
<li>IAAæ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—è¶…è¶Šç°æœ‰WSSSæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸°å¯Œäº†è¯­ä¹‰ä¿¡æ¯ï¼Œæœ‰åŠ©äºæ¨¡å‹ç†è§£æ›´å…¨é¢çš„è¯­ä¹‰æ¨¡å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20439">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2e7d8f479fa40cf856cd3813f060316f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e600ce67b4bc330051c553eed649b691.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Understanding-and-Mitigating-Memorization-in-Generative-Models-via-Sharpness-of-Probability-Landscapes"><a href="#Understanding-and-Mitigating-Memorization-in-Generative-Models-via-Sharpness-of-Probability-Landscapes" class="headerlink" title="Understanding and Mitigating Memorization in Generative Models via   Sharpness of Probability Landscapes"></a>Understanding and Mitigating Memorization in Generative Models via   Sharpness of Probability Landscapes</h2><p><strong>Authors:Dongjae Jeon, Dueun Kim, Albert No</strong></p>
<p>In this paper, we introduce a geometric framework to analyze memorization in diffusion models through the sharpness of the log probability density. We mathematically justify a previously proposed score-difference-based memorization metric by demonstrating its effectiveness in quantifying sharpness. Additionally, we propose a novel memorization metric that captures sharpness at the initial stage of image generation in latent diffusion models, offering early insights into potential memorization. Leveraging this metric, we develop a mitigation strategy that optimizes the initial noise of the generation process using a sharpness-aware regularization term. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/Dongjae0324/sharpness_memorization_diffusion">https://github.com/Dongjae0324/sharpness_memorization_diffusion</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåŸºäºå‡ ä½•çš„æ¡†æ¶ï¼Œé€šè¿‡å¯¹æ•°æ¦‚ç‡å¯†åº¦çš„å°–é”ç¨‹åº¦æ¥åˆ†ææ‰©æ•£æ¨¡å‹ä¸­çš„è®°å¿†åŒ–ã€‚æˆ‘ä»¬é€šè¿‡è¯æ˜å…¶åœ¨é‡åŒ–å°–é”åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºä¹‹å‰æå‡ºçš„åŸºäºåˆ†æ•°å·®å¼‚çš„è®°å¿†åŒ–åº¦é‡æä¾›äº†æ•°å­¦ä¾æ®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„è®°å¿†åŒ–åº¦é‡æ ‡å‡†ï¼Œè¯¥æ ‡å‡†èƒ½å¤Ÿæ•æ‰æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆåˆå§‹é˜¶æ®µçš„å°–é”åº¦ï¼Œä¸ºæ½œåœ¨çš„è®°å¿†åŒ–æä¾›æ—©æœŸè§è§£ã€‚åˆ©ç”¨è¿™ä¸€åº¦é‡æ ‡å‡†ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç¼“è§£ç­–ç•¥ï¼Œé€šè¿‡é‡‡ç”¨å°–é”åº¦æ„ŸçŸ¥æ­£åˆ™åŒ–é¡¹æ¥ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹çš„åˆå§‹å™ªå£°ã€‚ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/Dongjae0324/sharpness_memorization_diffusion%E3%80%82">https://github.com/Dongjae0324/sharpness_memorization_diffusionã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04140v5">PDF</a> Accepted at ICML 2025 (Spotlight). Code:   <a target="_blank" rel="noopener" href="https://github.com/Dongjae0324/sharpness_memorization_diffusion">https://github.com/Dongjae0324/sharpness_memorization_diffusion</a></p>
<p><strong>Summary</strong>ï¼š<br>æœ¬è®ºæ–‡é€šè¿‡å‡ ä½•æ¡†æ¶åˆ†æäº†æ‰©æ•£æ¨¡å‹ä¸­çš„è®°å¿†èƒ½åŠ›ï¼Œä¸»è¦é€šè¿‡æ¦‚ç‡å¯†åº¦å¯¹æ•°çš„é”åº¦è¿›è¡Œé˜è¿°ã€‚æ–‡ç« ä»æ•°å­¦è§’åº¦è¯æ˜äº†ä¸€ä¸ªåŸºäºè¯„åˆ†å·®å¼‚çš„è®°å¿†åŠ›æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºå…¶åœ¨é‡åŒ–é”åº¦æ–¹é¢çš„ä½œç”¨ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æå‡ºäº†ä¸€ç§æ–°çš„è®°å¿†åŠ›æŒ‡æ ‡ï¼Œç”¨äºæ•æ‰å›¾åƒç”ŸæˆåˆæœŸåœ¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸­çš„é”åº¦ï¼Œä¸ºæ½œåœ¨è®°å¿†åŠ›æä¾›æ—©æœŸæ´å¯Ÿã€‚åˆ©ç”¨è¿™ä¸€æŒ‡æ ‡ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹åˆå§‹å™ªå£°çš„ç­–ç•¥ï¼Œå³é‡‡ç”¨é”åº¦æ„ŸçŸ¥çš„æ­£åˆ™åŒ–é¡¹ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/Dongjae0324/sharpness_memorization_diffusion%E3%80%82">https://github.com/Dongjae0324/sharpness_memorization_diffusionã€‚</a></p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¼•å…¥å‡ ä½•æ¡†æ¶åˆ†ææ‰©æ•£æ¨¡å‹ä¸­çš„è®°å¿†åŠ›ã€‚</li>
<li>é€šè¿‡æ¦‚ç‡å¯†åº¦å¯¹æ•°çš„é”åº¦è¿›è¡Œé˜è¿°ã€‚</li>
<li>æ•°å­¦è¯æ˜äº†åŸºäºè¯„åˆ†å·®å¼‚çš„è®°å¿†åŠ›æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æå‡ºæ–°çš„è®°å¿†åŠ›æŒ‡æ ‡ï¼Œæ•æ‰å›¾åƒç”ŸæˆåˆæœŸçš„é”åº¦ã€‚</li>
<li>åˆ©ç”¨æ–°çš„è®°å¿†åŠ›æŒ‡æ ‡å¼€å‘äº†ä¸€ç§ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹çš„æ–¹æ³•ã€‚</li>
<li>ä¼˜åŒ–ç­–ç•¥èšç„¦äºåˆå§‹å™ªå£°çš„ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.04140">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e9b546197bfa5c7c93e7db3bb2a17a16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2456f7bcce1b2687d2077f7b0e83408.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f8d303bf54cf2d273a6f5b383176b78.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5e692c9963094f7eef5a04af0ffab94f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2145a309848de8395686f607d60345dc.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="HouseCrafter-Lifting-Floorplans-to-3D-Scenes-with-2D-Diffusion-Model"><a href="#HouseCrafter-Lifting-Floorplans-to-3D-Scenes-with-2D-Diffusion-Model" class="headerlink" title="HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model"></a>HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model</h2><p><strong>Authors:Hieu T. Nguyen, Yiwen Chen, Vikram Voleti, Varun Jampani, Huaizu Jiang</strong></p>
<p>We introduce HouseCrafter, a novel approach that can lift a floorplan into a complete large 3D indoor scene (e.g., a house). Our key insight is to adapt a 2D diffusion model, which is trained on web-scale images, to generate consistent multi-view color (RGB) and depth (D) images across different locations of the scene. Specifically, the RGB-D images are generated autoregressively in a batch-wise manner along sampled locations based on the floorplan, where previously generated images are used as condition to the diffusion model to produce images at nearby locations. The global floorplan and attention design in the diffusion model ensures the consistency of the generated images, from which a 3D scene can be reconstructed. Through extensive evaluation on the 3D-Front dataset, we demonstrate that HouseCraft can generate high-quality house-scale 3D scenes. Ablation studies also validate the effectiveness of different design choices. We will release our code and model weights. Project page: <a target="_blank" rel="noopener" href="https://neu-vi.github.io/houseCrafter/">https://neu-vi.github.io/houseCrafter/</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†HouseCrafterè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿå°†å¹³é¢åœ°æ¿è®¾è®¡è½¬åŒ–ä¸ºä¸€ä¸ªå®Œæ•´çš„å¤§å‹å®¤å†…ä¸‰ç»´åœºæ™¯ï¼ˆä¾‹å¦‚æˆ¿å­ï¼‰ã€‚æˆ‘ä»¬çš„ä¸»è¦è§è§£æ˜¯é€‚åº”äºŒç»´æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨ç½‘é¡µè§„æ¨¡å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥ç”Ÿæˆä¸åŒåœºæ™¯ä½ç½®çš„ä¸€è‡´çš„å¤šè§†è§’å½©è‰²ï¼ˆRGBï¼‰å’Œæ·±åº¦ï¼ˆDï¼‰å›¾åƒã€‚å…·ä½“è€Œè¨€ï¼ŒåŸºäºåœ°æ¿è®¾è®¡ï¼Œæ²¿ç€é‡‡æ ·ä½ç½®ä»¥æ‰¹é‡æ–¹å¼ç”ŸæˆRGB-Då›¾åƒï¼Œå…¶ä¸­å…ˆå‰ç”Ÿæˆçš„å›¾åƒè¢«ç”¨ä½œæ‰©æ•£æ¨¡å‹çš„è°ƒèŠ‚æ¡ä»¶ä»¥äº§ç”Ÿé‚»è¿‘ä½ç½®çš„å›¾åƒã€‚å…¨å±€çš„åœ°æ¿è®¾è®¡å’Œæ‰©æ•£æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿äº†ç”Ÿæˆå›¾åƒçš„ä¸€è‡´æ€§ï¼Œä»è€Œå¯ä»¥ä»è¿™äº›å›¾åƒé‡å»ºä¸‰ç»´åœºæ™¯ã€‚æˆ‘ä»¬åœ¨3D-Frontæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œè¯æ˜äº†HouseCraftå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æˆ¿å­è§„æ¨¡ä¸‰ç»´åœºæ™¯ã€‚æ¶ˆèç ”ç©¶ä¹ŸéªŒè¯äº†ä¸åŒè®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å°†å‘å¸ƒæˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚é¡¹ç›®é¡µé¢ï¼š[é“¾æ¥]ï¼ˆå¾…å¡«å†™å…·ä½“é“¾æ¥åœ°å€ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.20077v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæˆ‘ä»¬æ¨å‡ºHouseCrafterï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œèƒ½å°†å¹³é¢å›¾æå‡ä¸ºå®Œæ•´çš„å¤§å‹å®¤å†…ä¸‰ç»´åœºæ™¯ï¼ˆä¾‹å¦‚æˆ¿å±‹ï¼‰ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯é€‚åº”äºŒç»´æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨ç½‘é¡µè§„æ¨¡å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥ç”Ÿæˆåœºæ™¯ä¸åŒä½ç½®çš„è¿ç»­å¤šè§†å›¾å½©è‰²ï¼ˆRGBï¼‰å’Œæ·±åº¦ï¼ˆDï¼‰å›¾åƒã€‚å…·ä½“æ¥è¯´ï¼ŒåŸºäºå¹³é¢å›¾é‡‡æ ·çš„ä½ç½®ä»¥æ‰¹å¤„ç†æ–¹å¼è‡ªåŠ¨ç”ŸæˆRGB-Då›¾åƒï¼Œå…¶ä¸­å…ˆå‰ç”Ÿæˆçš„å›¾åƒç”¨ä½œæ‰©æ•£æ¨¡å‹çš„æ¡ä»¶æ¥ç”Ÿæˆé™„è¿‘ä½ç½®çš„å›¾åƒã€‚æ‰©æ•£æ¨¡å‹ä¸­çš„å…¨å±€å¹³é¢å›¾å’Œæ³¨æ„åŠ›è®¾è®¡ç¡®ä¿äº†ç”Ÿæˆå›¾åƒçš„ä¸€è‡´æ€§ï¼Œä»ä¸­å¯ä»¥é‡å»ºä¸‰ç»´åœºæ™¯ã€‚åœ¨3D-Frontæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒHouseCraftå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æˆ¿å­è§„æ¨¡ä¸‰ç»´åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>HouseCrafteræ˜¯ä¸€ç§å°†å¹³é¢å›¾è½¬åŒ–ä¸ºå®Œæ•´å¤§å‹å®¤å†…ä¸‰ç»´åœºæ™¯çš„æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨äºŒç»´æ‰©æ•£æ¨¡å‹ï¼Œåœ¨ç½‘é¡µè§„æ¨¡å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>HouseCrafterèƒ½ç”Ÿæˆåœºæ™¯ä¸åŒä½ç½®çš„è¿ç»­å¤šè§†å›¾å½©è‰²ï¼ˆRGBï¼‰å’Œæ·±åº¦ï¼ˆDï¼‰å›¾åƒã€‚</li>
<li>RGB-Då›¾åƒæ˜¯åŸºäºå¹³é¢å›¾é‡‡æ ·çš„ä½ç½®ä»¥æ‰¹å¤„ç†æ–¹å¼ç”Ÿæˆçš„ã€‚</li>
<li>å…ˆå‰ç”Ÿæˆçš„å›¾åƒè¢«ç”¨ä½œæ¡ä»¶æ¥ç”Ÿæˆé™„è¿‘ä½ç½®çš„å›¾åƒï¼Œç¡®ä¿äº†ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡å…¨å±€å¹³é¢å›¾å’Œæ‰©æ•£æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›è®¾è®¡ï¼Œç”Ÿæˆäº†è¿è´¯çš„ä¸‰ç»´åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.20077">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d6a1f69ea2c303b2a8296869c0c40ba7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c727ce5a1be140cdd8f8875b68695801.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4e36d928ce8c239f7ca2e529fa0934f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5bdbfe2040708564a8127a017be6c823.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cebe93f960c870aac06a74cb4db587af.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="CCDM-Continuous-Conditional-Diffusion-Models-for-Image-Generation"><a href="#CCDM-Continuous-Conditional-Diffusion-Models-for-Image-Generation" class="headerlink" title="CCDM: Continuous Conditional Diffusion Models for Image Generation"></a>CCDM: Continuous Conditional Diffusion Models for Image Generation</h2><p><strong>Authors:Xin Ding, Yongwei Wang, Kao Zhang, Z. Jane Wang</strong></p>
<p>Continuous Conditional Generative Modeling (CCGM) estimates high-dimensional data distributions, such as images, conditioned on scalar continuous variables (aka regression labels). While Continuous Conditional Generative Adversarial Networks (CcGANs) were designed for this task, their instability during adversarial learning often leads to suboptimal results. Conditional Diffusion Models (CDMs) offer a promising alternative, generating more realistic images, but their diffusion processes, label conditioning, and model fitting procedures are either not optimized for or incompatible with CCGM, making it difficult to integrate CcGANsâ€™ vicinal approach. To address these issues, we introduce Continuous Conditional Diffusion Models (CCDMs), the first CDM specifically tailored for CCGM. CCDMs address existing limitations with specially designed conditional diffusion processes, a novel hard vicinal image denoising loss, a customized label embedding method, and efficient conditional sampling procedures. Through comprehensive experiments on four datasets with resolutions ranging from 64x64 to 192x192, we demonstrate that CCDMs outperform state-of-the-art CCGM models, establishing a new benchmark. Ablation studies further validate the model design and implementation, highlighting that some widely used CDM implementations are ineffective for the CCGM task. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/UBCDingXin/CCDM">https://github.com/UBCDingXin/CCDM</a>. </p>
<blockquote>
<p>è¿ç»­æ¡ä»¶ç”Ÿæˆæ¨¡å‹ï¼ˆCCGMï¼‰ç”¨äºä¼°è®¡é«˜ç»´æ•°æ®åˆ†å¸ƒï¼Œå¦‚å›¾åƒï¼Œå¹¶æ ¹æ®æ ‡é‡è¿ç»­å˜é‡ï¼ˆå³å›å½’æ ‡ç­¾ï¼‰è¿›è¡Œæ¡ä»¶åŒ–ã€‚è™½ç„¶è¿ç»­æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆCcGANsï¼‰æ˜¯ä¸ºè¿™ä¸€ä»»åŠ¡è€Œè®¾è®¡çš„ï¼Œä½†å®ƒä»¬åœ¨å¯¹æŠ—å­¦ä¹ è¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§å¾€å¾€å¯¼è‡´ç»“æœä¸å°½äººæ„ã€‚æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCDMsï¼‰æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸçš„å›¾åƒï¼Œä½†å®ƒä»¬çš„æ‰©æ•£è¿‡ç¨‹ã€æ ‡ç­¾æ¡ä»¶å’Œæ¨¡å‹æ‹Ÿåˆç¨‹åºå¹¶æœªé’ˆå¯¹CCGMè¿›è¡Œä¼˜åŒ–æˆ–ä¸å…¼å®¹ï¼Œè¿™ä½¿å¾—éš¾ä»¥èå…¥CcGANsçš„é‚»è¿‘æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¿ç»­æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCCDMsï¼‰ï¼Œè¿™æ˜¯ä¸“é—¨ä¸ºCCGMè®¾è®¡çš„ç¬¬ä¸€ä¸ªCDMã€‚CCDMsé€šè¿‡ç‰¹æ®Šè®¾è®¡çš„æ¡ä»¶æ‰©æ•£è¿‡ç¨‹ã€æ–°é¢–çš„ç¡¬é‚»è¿‘å›¾åƒå»å™ªæŸå¤±ã€å®šåˆ¶çš„æ ‡ç­¾åµŒå…¥æ–¹æ³•å’Œé«˜æ•ˆçš„æ¡ä»¶é‡‡æ ·ç¨‹åºï¼Œè§£å†³äº†ç°æœ‰é™åˆ¶ã€‚æˆ‘ä»¬åœ¨å››ä¸ªä¸åŒåˆ†è¾¨ç‡ï¼ˆä»64x64åˆ°192x192ï¼‰çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œè¯æ˜CCDMsè¶…è¶Šäº†æœ€æ–°çš„CCGMæ¨¡å‹ï¼Œå»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†æ¨¡å‹è®¾è®¡å’Œå®ç°ï¼Œå¼ºè°ƒä¸€äº›å¹¿æ³›ä½¿ç”¨çš„CDMå®ç°å¯¹äºCCGMä»»åŠ¡æ— æ•ˆã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/UBCDingXin/CCDM%E3%80%82">https://github.com/UBCDingXin/CCDMã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.03546v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿ç»­æ¡ä»¶ç”Ÿæˆæ¨¡å‹ï¼ˆCCGMï¼‰ç”¨äºä¼°è®¡å›¾åƒç­‰é«˜ç»´æ•°æ®åˆ†å¸ƒï¼Œè¯¥åˆ†å¸ƒå—æ ‡é‡è¿ç»­å˜é‡ï¼ˆå³å›å½’æ ‡ç­¾ï¼‰çš„åˆ¶çº¦ã€‚è™½ç„¶è¿ç»­æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆCcGANsï¼‰è¢«è®¾è®¡ç”¨äºæ­¤ä»»åŠ¡ï¼Œä½†å…¶å¯¹æŠ—å­¦ä¹ è¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§å¸¸å¸¸å¯¼è‡´ç»“æœä¸å°½äººæ„ã€‚æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCDMsï¼‰æä¾›äº†ä¸€ä¸ªå‰æ™¯å¯è§‚çš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½ç”Ÿæˆæ›´çœŸå®çš„å›¾åƒï¼Œä½†å®ƒä»¬å¯¹æ‰©æ•£è¿‡ç¨‹ã€æ ‡ç­¾åˆ¶çº¦å’Œæ¨¡å‹æ‹Ÿåˆç¨‹åºçš„è®¾è®¡å¹¶ä¸ä¼˜åŒ–ç”šè‡³ä¸CCGMä¸å…¼å®¹ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºä¸“é—¨é¢å‘CCGMè®¾è®¡çš„è¿ç»­æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCCDMsï¼‰ã€‚CCDMsè§£å†³äº†ç°æœ‰é™åˆ¶ï¼Œå…·å¤‡ç‰¹æ®Šè®¾è®¡çš„æ¡ä»¶æ‰©æ•£è¿‡ç¨‹ã€æ–°é¢–çš„ç¡¬vicinalå›¾åƒå»å™ªæŸå¤±ã€å®šåˆ¶åŒ–çš„æ ‡ç­¾åµŒå…¥æ–¹æ³•å’Œé«˜æ•ˆçš„æ¡ä»¶é‡‡æ ·ç¨‹åºã€‚åœ¨å››ä¸ªä¸åŒåˆ†è¾¨ç‡ï¼ˆä»64x64åˆ°192x192ï¼‰çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒCCDMsçš„è¡¨ç°ä¼˜äºæœ€å…ˆè¿›çš„çŠ¶æ€CCGMæ¨¡å‹ï¼Œå¹¶å»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿ç»­æ¡ä»¶ç”Ÿæˆæ¨¡å‹ï¼ˆCCGMï¼‰æ—¨åœ¨ä¼°è®¡é«˜ç»´æ•°æ®åˆ†å¸ƒï¼Œå¦‚å›¾åƒï¼Œå—è¿ç»­å˜é‡ï¼ˆå›å½’æ ‡ç­¾ï¼‰åˆ¶çº¦ã€‚</li>
<li>è¿ç»­æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆCcGANsï¼‰è™½ç„¶ä¸ºæ­¤ä»»åŠ¡è®¾è®¡ï¼Œä½†å¯¹æŠ—å­¦ä¹ è¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§å¯¼è‡´ç»“æœä¸ä½³ã€‚</li>
<li>æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCDMsï¼‰èƒ½ç”Ÿæˆæ›´çœŸå®çš„å›¾åƒï¼Œä½†å¯¹CCGMçš„æ‰©æ•£è¿‡ç¨‹ã€æ ‡ç­¾åˆ¶çº¦å’Œæ¨¡å‹æ‹Ÿåˆç¨‹åºå¹¶æœªä¼˜åŒ–æˆ–ä¸å…¼å®¹ã€‚</li>
<li>ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæå‡ºäº†è¿ç»­æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCCDMsï¼‰ï¼Œé’ˆå¯¹CCGMè¿›è¡Œäº†ç‰¹æ®Šè®¾è®¡ã€‚</li>
<li>CCDMsé€šè¿‡ç‰¹æ®Šçš„æ‰©æ•£è¿‡ç¨‹ã€æ–°çš„ç¡¬vicinalå›¾åƒå»å™ªæŸå¤±ã€å®šåˆ¶åŒ–çš„æ ‡ç­¾åµŒå…¥æ–¹æ³•å’Œé«˜æ•ˆçš„é‡‡æ ·ç¨‹åºè§£å†³äº†ç°æœ‰é—®é¢˜ã€‚</li>
<li>ç»¼åˆå®éªŒè¯æ˜ï¼ŒCCDMsåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–å…ˆè¿›CCGMæ¨¡å‹ï¼Œå»ºç«‹äº†æ–°çš„æ€§èƒ½åŸºå‡†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.03546">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-710ef938794470bc2916ca31ca71f36c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a855bd5531f0739adfa236d176f472df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-98d3eacfc06315a3bc806c69d4db2c33.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8f41e4db9f37a179b36294affa7acf18.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Diffusion-Noise-Feature-Accurate-and-Fast-Generated-Image-Detection"><a href="#Diffusion-Noise-Feature-Accurate-and-Fast-Generated-Image-Detection" class="headerlink" title="Diffusion Noise Feature: Accurate and Fast Generated Image Detection"></a>Diffusion Noise Feature: Accurate and Fast Generated Image Detection</h2><p><strong>Authors:Yichi Zhang, Xiaogang Xu</strong></p>
<p>Generative models now produce images with such stunning realism that they can easily deceive the human eye. While this progress unlocks vast creative potential, it also presents significant risks, such as the spread of misinformation. Consequently, detecting generated images has become a critical research challenge. However, current detection methods are often plagued by low accuracy and poor generalization. In this paper, to address these limitations and enhance the detection of generated images, we propose a novel representation, Diffusion Noise Feature (DNF). Derived from the inverse process of diffusion models, DNF effectively amplifies the subtle, high-frequency artifacts that act as fingerprints of artificial generation. Our key insight is that real and generated images exhibit distinct DNF signatures, providing a robust basis for differentiation. By training a simple classifier such as ResNet-50 on DNF, our approach achieves remarkable accuracy, robustness, and generalization in detecting generated images, including those from unseen generators or with novel content. Extensive experiments across four training datasets and five test sets confirm that DNF establishes a new state-of-the-art in generated image detection. The code is available at <a target="_blank" rel="noopener" href="https://github.com/YichiCS/Diffusion-Noise-Feature">https://github.com/YichiCS/Diffusion-Noise-Feature</a>. </p>
<blockquote>
<p>ç”Ÿæˆæ¨¡å‹ç°åœ¨èƒ½å¤Ÿç”Ÿæˆå¦‚æ­¤é€¼çœŸçš„å›¾åƒï¼Œä»¥è‡³äºå®ƒä»¬å¯ä»¥è½»æ¾æ¬ºéª—äººçœ¼ã€‚è™½ç„¶è¿™ä¸€è¿›å±•é‡Šæ”¾äº†å·¨å¤§çš„åˆ›é€ åŠ›ï¼Œä½†ä¹Ÿå¸¦æ¥äº†æ˜¾è‘—çš„é£é™©ï¼Œä¾‹å¦‚è¯¯å¯¼ä¿¡æ¯çš„ä¼ æ’­ã€‚å› æ­¤ï¼Œæ£€æµ‹ç”Ÿæˆå›¾åƒå·²æˆä¸ºä¸€é¡¹é‡è¦çš„ç ”ç©¶æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ£€æµ‹æ–¹æ³•å¾€å¾€å­˜åœ¨å‡†ç¡®æ€§ä½å’Œæ³›åŒ–èƒ½åŠ›å·®çš„å›°æ‰°ã€‚é’ˆå¯¹è¿™äº›å±€é™æ€§å¹¶å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ£€æµ‹èƒ½åŠ›ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¡¨ç¤ºæ–¹æ³•ï¼šæ‰©æ•£å™ªå£°ç‰¹å¾ï¼ˆDNFï¼‰ã€‚DNFæ¥æºäºæ‰©æ•£æ¨¡å‹çš„é€†è¿‡ç¨‹ï¼Œæœ‰æ•ˆåœ°æ”¾å¤§äº†ä½œä¸ºäººå·¥ç”ŸæˆæŒ‡çº¹çš„å¾®å¦™é«˜é¢‘ä¼ªå½±ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼ŒçœŸå®å’Œç”Ÿæˆçš„å›¾åƒè¡¨ç°å‡ºä¸åŒçš„DNFç­¾åï¼Œè¿™ä¸ºåŒºåˆ†å®ƒä»¬æä¾›äº†åšå®çš„åŸºç¡€ã€‚é€šè¿‡åœ¨DNFä¸Šè®­ç»ƒåƒResNet-50è¿™æ ·çš„ç®€å•åˆ†ç±»å™¨ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ£€æµ‹ç”Ÿæˆå›¾åƒæ—¶å®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æ€§ã€ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ¥è‡ªæœªè§è¿‡çš„ç”Ÿæˆå™¨æˆ–å…·æœ‰æ–°å†…å®¹çš„æƒ…å†µã€‚åœ¨å››ä¸ªè®­ç»ƒæ•°æ®é›†å’Œäº”ä¸ªæµ‹è¯•é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¯å®ï¼ŒDNFåœ¨ç”Ÿæˆå›¾åƒæ£€æµ‹æ–¹é¢å»ºç«‹äº†æœ€æ–°çš„æœ€å…ˆè¿›çš„æ°´å¹³ã€‚ä»£ç å¯ç”¨åœ¨<a target="_blank" rel="noopener" href="https://github.com/YichiCS/Diffusion-Noise-Feature%E3%80%82">https://github.com/YichiCS/Diffusion-Noise-Featureã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02625v3">PDF</a> Accepted by ECAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹å›¾åƒæ£€æµ‹ç­–ç•¥ï¼Œå³æ‰©æ•£å™ªå£°ç‰¹å¾ï¼ˆDNFï¼‰ï¼Œç”¨ä»¥è¯†åˆ«ç”Ÿæˆæ¨¡å‹çš„å›¾åƒã€‚è¯¥ç­–ç•¥åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é€†è¿‡ç¨‹æå–ç‰¹å¾ï¼Œæœ‰æ•ˆæ”¾å¤§ç”Ÿæˆå›¾åƒçš„é«˜é¢‘ä¼ªå½±ï¼Œä»è€Œå®ç°ç²¾å‡†è¯†åˆ«ã€‚å®éªŒè¯æ˜ï¼ŒDNFåœ¨æ£€æµ‹ä¸åŒç”Ÿæˆå™¨ç”šè‡³æ–°å‹å†…å®¹çš„ç”Ÿæˆå›¾åƒæ—¶ï¼Œå…·æœ‰å‡ºè‰²çš„å‡†ç¡®æ€§ã€ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä¸ºç”Ÿæˆå›¾åƒæ£€æµ‹é¢†åŸŸæ ‘ç«‹äº†æ–°çš„æ ‡æ†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆæ¨¡å‹çš„å›¾åƒå…·æœ‰é€¼çœŸçš„ç°å®ä¸»ä¹‰æ•ˆæœï¼Œä½†åŒæ—¶ä¹Ÿå­˜åœ¨ä¼ æ’­è¯¯å¯¼ä¿¡æ¯çš„é‡å¤§é£é™©ã€‚</li>
<li>å½“å‰å›¾åƒæ£€æµ‹æ–¹æ³•çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›æœ‰å¾…æé«˜ã€‚</li>
<li>æ‰©æ•£å™ªå£°ç‰¹å¾ï¼ˆDNFï¼‰æ˜¯ä»æ‰©æ•£æ¨¡å‹çš„é€†è¿‡ç¨‹ä¸­æå–çš„æ–°å‹è¡¨ç¤ºæ–¹æ³•ã€‚</li>
<li>DNFèƒ½æœ‰æ•ˆæ”¾å¤§ç”Ÿæˆå›¾åƒçš„é«˜é¢‘ä¼ªå½±ï¼Œè¿™äº›ä¼ªå½±ä½œä¸ºäººå·¥ç”Ÿæˆçš„æŒ‡çº¹ã€‚</li>
<li>DNFæ˜¾ç¤ºçœŸå®å’Œç”Ÿæˆå›¾åƒä¹‹é—´çš„æ˜æ˜¾å·®å¼‚ï¼Œä¸ºåŒºåˆ†å®ƒä»¬æä¾›äº†ç¨³å¥çš„åŸºç¡€ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨å¦‚ResNet-50ç­‰ç®€å•åˆ†ç±»å™¨è¿›è¡Œè®­ç»ƒï¼ŒDNFç­–ç•¥åœ¨æ£€æµ‹ç”Ÿæˆå›¾åƒæ–¹é¢å–å¾—äº†çªç ´æ€§æˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.02625">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-462db27cd7deecd35d1eca7be1136b65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7672dc6dd2de545464185f2697da87b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61f41f8452d3b2c9077bb1a13b5b3989.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-756bc807e52e596e99d927d7be75ef83.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3bf08cfe397336b3f2c6584c33750d16.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5f411c4d6e85e52f77b56ebdc71e7a88.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-21/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-21/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-21/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e8eb254c468079debe400db19dd9614a.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-21  ASDFormer A Transformer with Mixtures of Pooling-Classifier Experts for   Robust Autism Diagnosis and Biomarker Discovery
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-21/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-f46bd541e3d005664e10464a34b8fe16.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-21  Is-NeRF In-scattering Neural Radiance Field for Blurred Images
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
