<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-24  Why disentanglement-based speaker anonymization systems fail at   preserving emotions?">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-e6ff55b2815f096bf5e92d26c0ec9c22.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-24-æ›´æ–°"><a href="#2025-01-24-æ›´æ–°" class="headerlink" title="2025-01-24 æ›´æ–°"></a>2025-01-24 æ›´æ–°</h1><h2 id="Why-disentanglement-based-speaker-anonymization-systems-fail-at-preserving-emotions"><a href="#Why-disentanglement-based-speaker-anonymization-systems-fail-at-preserving-emotions" class="headerlink" title="Why disentanglement-based speaker anonymization systems fail at   preserving emotions?"></a>Why disentanglement-based speaker anonymization systems fail at   preserving emotions?</h2><p><strong>Authors:Ãœnal Ege Gaznepoglu, Nils Peters</strong></p>
<p>Disentanglement-based speaker anonymization involves decomposing speech into a semantically meaningful representation, altering the speaker embedding, and resynthesizing a waveform using a neural vocoder. State-of-the-art systems of this kind are known to remove emotion information. Possible reasons include mode collapse in GAN-based vocoders, unintended modeling and modification of emotions through speaker embeddings, or excessive sanitization of the intermediate representation. In this paper, we conduct a comprehensive evaluation of a state-of-the-art speaker anonymization system to understand the underlying causes. We conclude that the main reason is the lack of emotion-related information in the intermediate representation. The speaker embeddings also have a high impact, if they are learned in a generative context. The vocoderâ€™s out-of-distribution performance has a smaller impact. Additionally, we discovered that synthesis artifacts increase spectral kurtosis, biasing emotion recognition evaluation towards classifying utterances as angry. Therefore, we conclude that reporting unweighted average recall alone for emotion recognition performance is suboptimal. </p>
<blockquote>
<p>åŸºäºçº ç¼ å‰¥ç¦»çš„è¯´è¯äººåŒ¿ååŒ–æŠ€æœ¯æ¶‰åŠå°†è¯­éŸ³åˆ†è§£æˆå…·æœ‰è¯­ä¹‰æ„ä¹‰çš„è¡¨ç¤ºï¼Œæ”¹å˜è¯´è¯äººçš„åµŒå…¥ï¼Œå¹¶ä½¿ç”¨ç¥ç»ç½‘ç»œç¼–è§£ç å™¨é‡æ–°åˆæˆæ³¢å½¢ã€‚ç›®å‰æœ€å…ˆè¿›çš„è¿™ç±»ç³»ç»Ÿå·²çŸ¥ä¼šæ¶ˆé™¤æƒ…ç»ªä¿¡æ¯ã€‚å¯èƒ½çš„åŸå› åŒ…æ‹¬åŸºäºGANçš„ç¼–è§£ç å™¨ä¸­çš„æ¨¡å¼å´©æºƒã€é€šè¿‡è¯´è¯äººåµŒå…¥è¿›è¡Œæƒ…æ„Ÿå’Œæƒ…æ„Ÿçš„æ„å¤–å»ºæ¨¡å’Œä¿®æ”¹ï¼Œæˆ–å¯¹ä¸­é—´è¡¨ç¤ºçš„è¿‡åº¦å‡€åŒ–ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹æœ€å…ˆè¿›çš„è¯´è¯äººåŒ¿ååŒ–ç³»ç»Ÿè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œä»¥äº†è§£æ½œåœ¨åŸå› ã€‚æˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œä¸»è¦åŸå› æ˜¯ä¸­é—´è¡¨ç¤ºä¸­ç¼ºä¹ä¸æƒ…æ„Ÿç›¸å…³çš„ä¿¡æ¯ã€‚å¦‚æœè¯´è¯äººçš„åµŒå…¥æ˜¯åœ¨ç”Ÿæˆç¯å¢ƒä¸­å­¦ä¹ åˆ°çš„ï¼Œé‚£ä¹ˆå®ƒä»¬ä¹Ÿä¼šäº§ç”Ÿé‡å¤§å½±å“ã€‚ç¼–è§£ç å™¨çš„è¶…å‡ºåˆ†å¸ƒæ€§èƒ½çš„å½±å“è¾ƒå°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°åˆæˆäº§ç”Ÿçš„ä¼ªè¿¹ä¼šå¢åŠ é¢‘è°±å³°åº¦ï¼Œå¯¼è‡´æƒ…ç»ªè¯†åˆ«è¯„ä¼°åå‘äºå°†è¯è¯­åˆ†ç±»ä¸ºæ„¤æ€’æƒ…ç»ªã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œä»…æŠ¥å‘Šæƒ…ç»ªè¯†åˆ«çš„æœªåŠ æƒå¹³å‡å¬å›ç‡æ˜¯ä¸ç†æƒ³çš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13000v1">PDF</a> 5 pages, accepted to ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åŸºäºåˆ†ç¦»æŠ€æœ¯çš„è¯´è¯äººåŒ¿ååŒ–æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯é€šè¿‡å°†è¯­éŸ³åˆ†è§£ä¸ºå…·æœ‰è¯­ä¹‰æ„ä¹‰çš„è¡¨ç¤ºï¼Œæ”¹å˜è¯´è¯äººåµŒå…¥ï¼Œå¹¶ä½¿ç”¨ç¥ç»ç½‘ç»œvocoderé‡æ–°åˆæˆæ³¢å½¢æ¥å®ç°ã€‚å½“å‰å…ˆè¿›æŠ€æœ¯ä¸»è¦é¢ä¸´çš„é—®é¢˜æ˜¯æ¶ˆé™¤æƒ…æ„Ÿä¿¡æ¯ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºæƒ…æ„Ÿä¿¡æ¯çš„ç¼ºå¤±åœ¨ç”Ÿæˆè¿‡ç¨‹çš„è¯­è¨€åŒ¿ååŒ–çš„é‡è¦åŸå› ä¸­å‘æŒ¥äº†ä¸»è¦ä½œç”¨ï¼Œå°¤å…¶æ˜¯ï¼Œç»è¿‡å¯¹ç°ä»£è¯­éŸ³è¯†åˆ«æŠ€æœ¯çš„è¯„ä¼°åå‘ç°ä¸»è¦æ˜¯ç”±äºä¸­é—´è¡¨è¾¾çš„æƒ…æ„Ÿä¿¡æ¯ç¼ºå¤±ï¼Œä¸”ç”Ÿæˆçš„è¯´è¯äººåµŒå…¥è‹¥ç”Ÿæˆäºä¸€ä¸ªç”Ÿæˆä¸Šä¸‹æ–‡èƒŒæ™¯ä¸‹å°†å¸¦æ¥é‡å¤§å½±å“ã€‚åŒæ—¶å‘ç°åˆæˆç‰©çš„åˆæˆåˆ¶å“å¢åŠ äº†è°±å³°ååº¦åˆ†å¸ƒå˜åŒ–å½±å“æƒ…æ„Ÿè¯†åˆ«ç»“æœå‡†ç¡®ã€‚æœ€åæ€»ç»“å½“å‰å•çº¯çš„æŠ¥å‘Šå¹³å‡æœªåŠ æƒå¬å›ç‡æ¥è¡¡é‡æƒ…æ„Ÿè¯†åˆ«æ€§èƒ½æ˜¯ä¸å¤Ÿçš„ã€‚æˆ‘ä»¬å°†æŒç»­è¯„ä¼°æ–°å‹çš„ç³»ç»Ÿä»¥ä¾¿å¯»æ‰¾æ›´é€‚åˆçš„è¯„ä»·æ–¹æ³•ä»¥æ›´å‡†ç¡®æµ‹é‡å‡ºæ¨¡å‹åœ¨å¤„ç†çœŸå®å¤æ‚æƒ…å¢ƒä¸‹çš„æ•ˆæœã€‚   </p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13000">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8217b28e02f5a08e2bfbc1e18090fba0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-640b36e38a11939c1a14bad6bc97c4b8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f4919cf326929ae0f6a3f1174706d7b8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a148f4b289ad7132d4523b1eedd9b018.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FlanEC-Exploring-Flan-T5-for-Post-ASR-Error-Correction"><a href="#FlanEC-Exploring-Flan-T5-for-Post-ASR-Error-Correction" class="headerlink" title="FlanEC: Exploring Flan-T5 for Post-ASR Error Correction"></a>FlanEC: Exploring Flan-T5 for Post-ASR Error Correction</h2><p><strong>Authors:Moreno La Quatra, Valerio Mario Salerno, Yu Tsao, Sabato Marco Siniscalchi</strong></p>
<p>In this paper, we present an encoder-decoder model leveraging Flan-T5 for post-Automatic Speech Recognition (ASR) Generative Speech Error Correction (GenSEC), and we refer to it as FlanEC. We explore its application within the GenSEC framework to enhance ASR outputs by mapping n-best hypotheses into a single output sentence. By utilizing n-best lists from ASR models, we aim to improve the linguistic correctness, accuracy, and grammaticality of final ASR transcriptions. Specifically, we investigate whether scaling the training data and incorporating diverse datasets can lead to significant improvements in post-ASR error correction. We evaluate FlanEC using the HyPoradise dataset, providing a comprehensive analysis of the modelâ€™s effectiveness in this domain. Furthermore, we assess the proposed approach under different settings to evaluate model scalability and efficiency, offering valuable insights into the potential of instruction-tuned encoder-decoder models for this task. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨Flan-T5è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰åçš„ç”Ÿæˆå¼è¯­éŸ³é”™è¯¯æ ¡æ­£ï¼ˆGenSECï¼‰çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºFlanECã€‚æˆ‘ä»¬æ¢ç´¢äº†å…¶åœ¨GenSECæ¡†æ¶å†…çš„åº”ç”¨ï¼Œé€šè¿‡å°†n-bestå‡è®¾æ˜ å°„åˆ°å•ä¸ªè¾“å‡ºå¥å­æ¥ä¼˜åŒ–ASRçš„è¾“å‡ºç»“æœã€‚æˆ‘ä»¬åˆ©ç”¨ASRæ¨¡å‹çš„n-beståˆ—è¡¨ï¼Œæ—¨åœ¨æé«˜æœ€ç»ˆASRè½¬å½•çš„è¯­è¨€æ­£ç¡®æ€§ã€å‡†ç¡®æ€§å’Œè¯­æ³•æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ‰©å¤§è®­ç»ƒæ•°æ®å¹¶èå…¥å¤šç§æ•°æ®é›†æ˜¯å¦èƒ½åœ¨ASRä¹‹åçš„é”™è¯¯æ ¡æ­£æ–¹é¢å¸¦æ¥æ˜¾è‘—æ”¹è¿›ã€‚æˆ‘ä»¬ä½¿ç”¨HyPoradiseæ•°æ®é›†å¯¹FlanECè¿›è¡Œäº†è¯„ä¼°ï¼Œå…¨é¢åˆ†æäº†è¯¥æ¨¡å‹åœ¨æ­¤é¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ä¸åŒçš„è®¾ç½®ä¸‹è¯„ä¼°äº†æ‰€æå‡ºçš„æ–¹æ³•ï¼Œä»¥è¯„ä¼°æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ï¼Œä¸ºæŒ‡ä»¤å¾®è°ƒç¼–ç å™¨-è§£ç å™¨æ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸Šçš„æ½œåŠ›æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12979v1">PDF</a> Accepted at the 2024 IEEE Workshop on Spoken Language Technology   (SLT) - GenSEC Challenge</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨Flan-T5çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰åçš„ç”Ÿæˆæ€§è¯­éŸ³é”™è¯¯æ ¡æ­£ï¼ˆGenSECï¼‰ï¼Œç§°ä¸ºFlanECã€‚è¯¥ç ”ç©¶æ—¨åœ¨æ”¹è¿›ASRè¾“å‡ºç»“æœçš„å‡†ç¡®æ€§ã€è¯­æ³•æ­£ç¡®æ€§ï¼Œå¹¶æ¢ç´¢é€šè¿‡æ˜ å°„n-bestå‡è®¾åˆ°å•ä¸€è¾“å‡ºå¥å­çš„æ–¹æ³•æ¥å¢å¼ºASRè¾“å‡ºçš„è´¨é‡ã€‚é€šè¿‡æ‰©å¤§è®­ç»ƒæ•°æ®å¹¶å¼•å…¥å„ç§æ•°æ®é›†æ¥æµ‹è¯•è¯¥æ¨¡å‹çš„æ•ˆæœï¼Œå¹¶åˆ©ç”¨HyPoradiseæ•°æ®é›†å¯¹FlanECè¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶è¿˜æ¢è®¨äº†æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ï¼Œä¸ºæŒ‡ä»¤å¾®è°ƒç¼–ç å™¨-è§£ç å™¨æ¨¡å‹åœ¨è¯¥é¢†åŸŸçš„æ½œåŠ›æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æå‡ºäº†åˆ©ç”¨Flan-T5çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹è¿›è¡Œè¯­éŸ³é”™è¯¯æ ¡æ­£çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ”¹è¿›ASRè¾“å‡ºçš„å‡†ç¡®æ€§ã€è¯­æ³•æ­£ç¡®æ€§ã€‚</li>
<li>é€šè¿‡æ˜ å°„n-bestå‡è®¾åˆ°å•ä¸€è¾“å‡ºå¥å­æ¥å¢å¼ºASRè¾“å‡ºçš„è´¨é‡ã€‚</li>
<li>ç ”ç©¶é€šè¿‡æ‰©å¤§è®­ç»ƒæ•°æ®å’Œå¼•å…¥å¤šç§æ•°æ®é›†æ¥æµ‹è¯•æ¨¡å‹æ•ˆæœã€‚</li>
<li>åˆ©ç”¨HyPoradiseæ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>ç ”ç©¶æ¢è®¨äº†æ¨¡å‹åœ¨ä¸åŒè®¾ç½®ä¸‹çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚</li>
<li>æŒ‡ä»¤å¾®è°ƒç¼–ç å™¨-è§£ç å™¨æ¨¡å‹åœ¨è¯¥é¢†åŸŸçš„æ½œåŠ›å¾—åˆ°äº†å±•ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12979">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4ca44c8e81056ffc64a078564a39d0bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-803186aabcf0848555d0e8e71be0d4ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4379b1077cdd82aba6b3e990e436c09e.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EmoFormer-A-Text-Independent-Speech-Emotion-Recognition-using-a-Hybrid-Transformer-CNN-model"><a href="#EmoFormer-A-Text-Independent-Speech-Emotion-Recognition-using-a-Hybrid-Transformer-CNN-model" class="headerlink" title="EmoFormer: A Text-Independent Speech Emotion Recognition using a Hybrid   Transformer-CNN model"></a>EmoFormer: A Text-Independent Speech Emotion Recognition using a Hybrid   Transformer-CNN model</h2><p><strong>Authors:Rashedul Hasan, Meher Nigar, Nursadul Mamun, Sayan Paul</strong></p>
<p>Speech Emotion Recognition is a crucial area of research in human-computer interaction. While significant work has been done in this field, many state-of-the-art networks struggle to accurately recognize emotions in speech when the data is both speech and speaker-independent. To address this limitation, this study proposes, EmoFormer, a hybrid model combining CNNs (CNNs) with Transformer encoders to capture emotion patterns in speech data for such independent datasets. The EmoFormer network was trained and tested using the Expressive Anechoic Recordings of Speech (EARS) dataset, recently released by META. We experimented with two feature extraction techniques: MFCCs and x-vectors. The model was evaluated on different emotion sets comprising 5, 7, 10, and 23 distinct categories. The results demonstrate that the model achieved its best performance with five emotions, attaining an accuracy of 90%, a precision of 0.92, a recall, and an F1-score of 0.91. However, performance decreased as the number of emotions increased, with an accuracy of 83% for seven emotions compared to 70% for the baseline network. This study highlights the effectiveness of combining CNNs and Transformer-based architectures for emotion recognition from speech, particularly when using MFCC features. </p>
<blockquote>
<p>è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ˜¯è®¡ç®—æœºäººæœºäº¤äº’é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶æ–¹å‘ã€‚å°½ç®¡è¯¥é¢†åŸŸå·²ç»è¿›è¡Œäº†å¤§é‡å·¥ä½œï¼Œä½†åœ¨è¯­éŸ³å’Œè¯´è¯äººç‹¬ç«‹çš„æ•°æ®é›†ä¸Šï¼Œè®¸å¤šæœ€å…ˆè¿›çš„ç½‘ç»œåœ¨å‡†ç¡®è¯†åˆ«æƒ…æ„Ÿæ–¹é¢ä»é¢ä¸´å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæœ¬ç ”ç©¶æå‡ºäº†EmoFormerï¼Œè¿™æ˜¯ä¸€ä¸ªæ··åˆæ¨¡å‹ï¼Œç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒTransformerç¼–ç å™¨ï¼Œä»¥æ•è·æ­¤ç±»ç‹¬ç«‹æ•°æ®é›†ä¸­çš„è¯­éŸ³æƒ…æ„Ÿæ¨¡å¼ã€‚EmoFormerç½‘ç»œä½¿ç”¨METAæœ€è¿‘å‘å¸ƒçš„è¡¨è¾¾æ— å£°è¯­éŸ³è®°å½•ï¼ˆEARSï¼‰æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚æˆ‘ä»¬å®éªŒäº†ä¸¤ç§ç‰¹å¾æå–æŠ€æœ¯ï¼šMFCCå’Œx-vectorsã€‚è¯¥æ¨¡å‹åœ¨ä¸åŒçš„æƒ…æ„Ÿé›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬åŒ…å«5ä¸ªã€7ä¸ªã€10ä¸ªå’Œ23ä¸ªä¸åŒç±»åˆ«çš„æƒ…æ„Ÿé›†ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨äº”ç§æƒ…æ„Ÿä¸Šè¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº†90%ï¼Œç²¾ç¡®åº¦è¾¾åˆ°äº†0.92ï¼Œå¬å›ç‡å’ŒF1åˆ†æ•°ä¹Ÿå‡ä¸º0.91ã€‚ç„¶è€Œï¼Œéšç€æƒ…æ„Ÿæ•°é‡çš„å¢åŠ ï¼Œæ€§èƒ½æœ‰æ‰€ä¸‹é™ï¼Œåœ¨ä¸ƒç§æƒ…æ„Ÿä¸Šçš„å‡†ç¡®ç‡ä¸º83%ï¼Œè€ŒåŸºçº¿ç½‘ç»œçš„å‡†ç¡®ç‡ä¸º70%ã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†å°†CNNå’ŒåŸºäºTransformerçš„æ¶æ„ç›¸ç»“åˆï¼Œç”¨äºä»è¯­éŸ³ä¸­è¯†åˆ«æƒ…æ„Ÿçš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨MFCCç‰¹å¾æ—¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12682v1">PDF</a> </p>
<p><strong>Summary</strong><br>è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ˜¯è®¡ç®—æœºäººæœºäº¤äº’é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶è¯¾é¢˜ã€‚é’ˆå¯¹ç°æœ‰æŠ€æœ¯å¯¹ç½‘ç»œåœ¨è¯­éŸ³å’Œè¯´è¯äººç‹¬ç«‹æƒ…æ„Ÿè¯†åˆ«æ–¹é¢çš„å±€é™ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºEmoFormerçš„æ··åˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒTransformerç¼–ç å™¨ï¼Œä»¥æ•æ‰è¯­éŸ³æ•°æ®ä¸­çš„æƒ…æ„Ÿæ¨¡å¼ã€‚ä½¿ç”¨METAæœ€è¿‘å‘å¸ƒçš„è¡¨è¾¾æ— å£°å½•éŸ³è¯­éŸ³ï¼ˆEARSï¼‰æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå®éªŒé‡‡ç”¨äº†ä¸¤ç§ç‰¹å¾æå–æŠ€æœ¯ï¼šMFCCså’Œx-vectorsã€‚åœ¨åŒ…å«5ã€7ã€10å’Œ23ä¸ªä¸åŒç±»åˆ«çš„æƒ…æ„Ÿé›†ä¸Šè¯„ä¼°è¯¥æ¨¡å‹ï¼Œç»“æœæ˜¾ç¤ºï¼Œåœ¨äº”ä¸ªæƒ…æ„Ÿç±»åˆ«ä¸Šï¼Œæ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº†90%ï¼Œç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°åˆ†åˆ«ä¸º0.92ã€0.91ã€‚ä½†éšç€æƒ…æ„Ÿç±»åˆ«çš„å¢åŠ ï¼Œæ€§èƒ½æœ‰æ‰€ä¸‹é™ï¼Œä¸ƒä¸ªæƒ…æ„Ÿçš„å‡†ç¡®ç‡ä¸º83%ï¼Œè€ŒåŸºå‡†ç½‘ç»œçš„å‡†ç¡®ç‡ä¸º70%ã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†ç»“åˆCNNå’ŒåŸºäºTransformerçš„æ¶æ„è¿›è¡Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨MFCCç‰¹å¾æ—¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ˜¯è®¡ç®—æœºäººæœºäº¤äº’çš„é‡è¦ç ”ç©¶é¢†åŸŸã€‚</li>
<li>å½“å‰ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºEmoFormerçš„æ··åˆæ¨¡å‹ï¼Œç»“åˆäº†CNNå’ŒTransformerç¼–ç å™¨ä»¥è¯†åˆ«è¯­éŸ³ä¸­çš„æƒ…æ„Ÿã€‚</li>
<li>EmoFormeræ¨¡å‹åœ¨åŒ…å«ä¸åŒæ•°é‡æƒ…æ„Ÿç±»åˆ«çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæœ€ä½³è¡¨ç°æ˜¯åœ¨äº”ä¸ªæƒ…æ„Ÿç±»åˆ«ä¸Šï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº†90%ã€‚</li>
<li>éšç€æƒ…æ„Ÿç±»åˆ«çš„å¢åŠ ï¼Œæ¨¡å‹çš„æ€§èƒ½æœ‰æ‰€ä¸‹é™ã€‚</li>
<li>ä½¿ç”¨MFCCç‰¹å¾æ—¶ï¼ŒEmoFormeræ¨¡å‹è¡¨ç°æ›´ä¼˜ç§€ã€‚</li>
<li>è¯¥ç ”ç©¶å¼ºè°ƒäº†ç»“åˆCNNå’ŒåŸºäºTransformerçš„æ¶æ„è¿›è¡Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12682">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b7300143091ead7aa9abcedb4e56009e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea4595845f672a9999d3165bb93629a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11abf6b5c8c0e1eb0641737ec9a61c85.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-67a1cf2518ae61682e69abf7ef50aa6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3826a39582e6baf9c15303923053c9e7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-76d87d6d22012208651befc878c02ae4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5110b6e8e272908f45bf250e268243ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6ff55b2815f096bf5e92d26c0ec9c22.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EmoTech-A-Multi-modal-Speech-Emotion-Recognition-Using-Multi-source-Low-level-Information-with-Hybrid-Recurrent-Network"><a href="#EmoTech-A-Multi-modal-Speech-Emotion-Recognition-Using-Multi-source-Low-level-Information-with-Hybrid-Recurrent-Network" class="headerlink" title="EmoTech: A Multi-modal Speech Emotion Recognition Using Multi-source   Low-level Information with Hybrid Recurrent Network"></a>EmoTech: A Multi-modal Speech Emotion Recognition Using Multi-source   Low-level Information with Hybrid Recurrent Network</h2><p><strong>Authors:Shamin Bin Habib Avro, Taieba Taher, Nursadul Mamun</strong></p>
<p>Emotion recognition is a critical task in human-computer interaction, enabling more intuitive and responsive systems. This study presents a multimodal emotion recognition system that combines low-level information from audio and text, leveraging both Convolutional Neural Networks (CNNs) and Bidirectional Long Short-Term Memory Networks (BiLSTMs). The proposed system consists of two parallel networks: an Audio Block and a Text Block. Mel Frequency Cepstral Coefficients (MFCCs) are extracted and processed by a BiLSTM network and a 2D convolutional network to capture low-level intrinsic and extrinsic features from speech. Simultaneously, a combined BiLSTM-CNN network extracts the low-level sequential nature of text from word embeddings corresponding to the available audio. This low-level information from speech and text is then concatenated and processed by several fully connected layers to classify the speech emotion. Experimental results demonstrate that the proposed EmoTech accurately recognizes emotions from combined audio and text inputs, achieving an overall accuracy of 84%. This solution outperforms previously proposed approaches for the same dataset and modalities. </p>
<blockquote>
<p>æƒ…æ„Ÿè¯†åˆ«æ˜¯äººæœºäº¤äº’ä¸­çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ï¼Œå®ƒä½¿ç³»ç»Ÿæ›´åŠ ç›´è§‚å’Œå“åº”è¿…é€Ÿã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†éŸ³é¢‘å’Œæ–‡æœ¬ä¸­çš„ä½çº§ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒåŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆBiLSTMï¼‰ã€‚æ‰€æå‡ºçš„ç³»ç»Ÿç”±ä¸¤ä¸ªå¹¶è¡Œç½‘ç»œç»„æˆï¼šéŸ³é¢‘å—å’Œæ–‡æœ¬å—ã€‚æå–æ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°ï¼ˆMFCCï¼‰ï¼Œå¹¶é€šè¿‡åŒå‘LSTMç½‘ç»œå’ŒäºŒç»´å·ç§¯ç½‘ç»œè¿›è¡Œå¤„ç†ï¼Œä»¥æ•è·è¯­éŸ³ä¸­çš„ä½çº§å†…åœ¨å’Œå¤–åœ¨ç‰¹å¾ã€‚åŒæ—¶ï¼Œç»“åˆåŒå‘LSTM-CNNç½‘ç»œä»ä¸å¯ç”¨éŸ³é¢‘å¯¹åº”çš„è¯åµŒå…¥ä¸­æå–æ–‡æœ¬çš„ä½çº§åºåˆ—ç‰¹å¾ã€‚ç„¶åï¼Œå°†æ¥è‡ªè¯­éŸ³å’Œæ–‡æœ¬çš„ä½çº§ä¿¡æ¯è¿æ¥èµ·æ¥ï¼Œå¹¶é€šè¿‡å‡ ä¸ªå…¨è¿æ¥å±‚å¯¹è¯­éŸ³æƒ…æ„Ÿè¿›è¡Œåˆ†ç±»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æŠ€æœ¯èƒ½å¤Ÿä»ç»„åˆçš„éŸ³é¢‘å’Œæ–‡æœ¬è¾“å…¥ä¸­å‡†ç¡®è¯†åˆ«æƒ…æ„Ÿï¼Œæ€»ä½“å‡†ç¡®ç‡è¾¾åˆ°äº†84%ã€‚å¯¹äºåŒä¸€æ•°æ®é›†å’Œæ¨¡æ€è€Œè¨€ï¼Œæ­¤è§£å†³æ–¹æ¡ˆçš„æ€§èƒ½è¶…è¿‡äº†å…ˆå‰æå‡ºçš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12674v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆéŸ³é¢‘å’Œæ–‡æœ¬çš„ä½çº§ä¿¡æ¯ï¼Œåˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒåŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆBiLSTMï¼‰è¿›è¡Œæƒ…æ„Ÿè¯†åˆ«ã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬ä¸¤ä¸ªå¹¶è¡Œç½‘ç»œï¼šéŸ³é¢‘å—å’Œæ–‡æœ¬å—ã€‚é€šè¿‡åŒå‘LSTMç½‘ç»œå’ŒäºŒç»´å·ç§¯ç½‘ç»œå¤„ç†æ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°ï¼ˆMFCCsï¼‰ï¼Œä»¥æ•è·è¯­éŸ³çš„å†…åœ¨å’Œå¤–åœ¨ç‰¹å¾ã€‚åŒæ—¶ï¼Œé€šè¿‡åŒå‘LSTM-CNNç½‘ç»œæå–ä¸éŸ³é¢‘ç›¸å¯¹åº”çš„æ–‡æœ¬è¯åµŒå…¥çš„ä½çº§åºåˆ—ç‰¹å¾ã€‚ç„¶åå°†è¯­éŸ³å’Œæ–‡æœ¬çš„ä½çº§ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œé€šè¿‡å¤šä¸ªå…¨è¿æ¥å±‚å¯¹è¯­éŸ³æƒ…æ„Ÿè¿›è¡Œåˆ†ç±»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„EmoTechç³»ç»Ÿèƒ½å¤Ÿå‡†ç¡®åœ°è¯†åˆ«æ¥è‡ªéŸ³é¢‘å’Œæ–‡æœ¬è¾“å…¥çš„æƒ…æ„Ÿï¼Œæ€»ä½“å‡†ç¡®ç‡ä¸º84%ï¼Œå¹¶ä¸”ä¼˜äºå…ˆå‰é’ˆå¯¹åŒä¸€æ•°æ®é›†å’Œæ¨¡æ€æå‡ºçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿç»“åˆäº†éŸ³é¢‘å’Œæ–‡æœ¬çš„ä½çº§ä¿¡æ¯ã€‚</li>
<li>åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒåŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆBiLSTMï¼‰è¿›è¡Œæƒ…æ„Ÿè¯†åˆ«ã€‚</li>
<li>ç³»ç»ŸåŒ…æ‹¬ä¸¤ä¸ªå¹¶è¡Œç½‘ç»œï¼šéŸ³é¢‘å—å’Œæ–‡æœ¬å—ï¼Œåˆ†åˆ«å¤„ç†è¯­éŸ³å’Œæ–‡æœ¬ä¿¡æ¯ã€‚</li>
<li>MFCCsç”¨äºæ•æ‰è¯­éŸ³çš„å†…åœ¨å’Œå¤–åœ¨ç‰¹å¾ã€‚</li>
<li>åŒå‘LSTM-CNNç½‘ç»œç”¨äºæå–ä¸éŸ³é¢‘ç›¸å¯¹åº”çš„æ–‡æœ¬è¯åµŒå…¥çš„ä½çº§åºåˆ—ç‰¹å¾ã€‚</li>
<li>ç³»ç»Ÿé€šè¿‡å°†è¯­éŸ³å’Œæ–‡æœ¬çš„ä½çº§ä¿¡æ¯ç»“åˆï¼Œå®ç°æƒ…æ„Ÿåˆ†ç±»ï¼Œæ€»ä½“å‡†ç¡®ç‡ä¸º84%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12674">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-962b049dd3ad67d3e05fc8a1754dc091.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-706648e4da9cb36cdb649a7d95497658.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-039e39e288c17bce48a5e92f7a2ea2d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e1d15d45cf83a67448a72d8742089a56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffeef06c1dd06a2de345ccfdcbb1bcb5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e346864ebf7d93459fdecf8deaed6461.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d2596bc1aedf47213ea662c8ffbd15e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8da58fccf9dfeccf7be49163e6138c74.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a89af7dcc8cddd68dcb67b621f4a39b6.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="GALD-SE-Guided-Anisotropic-Lightweight-Diffusion-for-Efficient-Speech-Enhancement"><a href="#GALD-SE-Guided-Anisotropic-Lightweight-Diffusion-for-Efficient-Speech-Enhancement" class="headerlink" title="GALD-SE: Guided Anisotropic Lightweight Diffusion for Efficient Speech   Enhancement"></a>GALD-SE: Guided Anisotropic Lightweight Diffusion for Efficient Speech   Enhancement</h2><p><strong>Authors:Chengzhong Wang, Jianjun Gu, Dingding Yao, Junfeng Li, Yonghong Yan</strong></p>
<p>Speech enhancement is designed to enhance the intelligibility and quality of speech across diverse noise conditions. Recently, diffusion model has gained lots of attention in speech enhancement area, achieving competitive results. Current diffusion-based methods blur the signal with isotropic Gaussian noise and recover clean speech from the prior. However, these methods often suffer from a substantial computational burden. We argue that the computational inefficiency partially stems from the oversight that speech enhancement is not purely a generative task; it primarily involves noise reduction and completion of missing information, while the clean clues in the original mixture do not need to be regenerated. In this paper, we propose a method that introduces noise with anisotropic guidance during the diffusion process, allowing the neural network to preserve clean clues within noisy recordings. This approach substantially reduces computational complexity while exhibiting robustness against various forms of noise and speech distortion. Experiments demonstrate that the proposed method achieves state-of-the-art results with only approximately 4.5 million parameters, a number significantly lower than that required by other diffusion methods. This effectively narrows the model size disparity between diffusion-based and predictive speech enhancement approaches. Additionally, the proposed method performs well in very noisy scenarios, demonstrating its potential for applications in highly challenging environments. </p>
<blockquote>
<p>è¯­éŸ³å¢å¼ºæ—¨åœ¨æé«˜è¯­éŸ³åœ¨ä¸åŒå™ªå£°æ¡ä»¶ä¸‹çš„æ¸…æ™°åº¦å’Œè´¨é‡ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹åœ¨è¯­éŸ³å¢å¼ºé¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œå¹¶å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚å½“å‰åŸºäºæ‰©æ•£çš„æ–¹æ³•é€šè¿‡ç­‰å‘é«˜æ–¯å™ªå£°æ¨¡ç³Šä¿¡å·ï¼Œå¹¶ä»å…ˆå‰çŠ¶æ€æ¢å¤å¹²å‡€è¯­éŸ³ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸é¢ä¸´å·¨å¤§çš„è®¡ç®—è´Ÿæ‹…ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè®¡ç®—æ•ˆç‡ä½ä¸‹éƒ¨åˆ†æºäºå¯¹è¯­éŸ³å¢å¼ºçš„è¯¯è§£ï¼Œå®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªç”Ÿæˆä»»åŠ¡ï¼›å®ƒä¸»è¦æ¶‰åŠå™ªå£°å‡å°‘å’Œç¼ºå¤±ä¿¡æ¯çš„è¡¥å……ï¼Œè€ŒåŸå§‹æ··åˆä¸­çš„å¹²å‡€çº¿ç´¢ä¸éœ€è¦é‡æ–°ç”Ÿæˆã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å¼•å…¥å„å‘å¼‚æ€§å¼•å¯¼å™ªå£°çš„æ–¹æ³•ï¼Œå…è®¸ç¥ç»ç½‘ç»œåœ¨å˜ˆæ‚çš„å½•éŸ³ä¸­ä¿ç•™å¹²å‡€çº¿ç´¢ã€‚è¿™ç§æ–¹æ³•åœ¨é™ä½è®¡ç®—å¤æ‚æ€§çš„åŒæ—¶ï¼Œå¯¹å„ç§å½¢å¼çš„å™ªå£°å’Œè¯­éŸ³å¤±çœŸè¡¨ç°å‡ºç¨³å¥æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å¤§çº¦450ä¸‡ä¸ªå‚æ•°å°±è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œè¿™ä¸ªæ•°å­—è¿œä½äºå…¶ä»–æ‰©æ•£æ–¹æ³•æ‰€éœ€çš„å‚æ•°ã€‚è¿™æœ‰æ•ˆåœ°ç¼©å°äº†åŸºäºæ‰©æ•£çš„è¯­éŸ³å¢å¼ºæ–¹æ³•å’Œé¢„æµ‹æ€§è¯­éŸ³å¢å¼ºæ–¹æ³•ä¹‹é—´çš„æ¨¡å‹è§„æ¨¡å·®è·ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å™ªå£°å¾ˆå¤§çš„åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æå…·æŒ‘æˆ˜æ€§çš„ç¯å¢ƒä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.15101v5">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨è¯­éŸ³å¢å¼ºé¢†åŸŸå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†è®¡ç®—æ•ˆç‡è¾ƒä½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥å…·æœ‰å®šå‘æŒ‡å¯¼çš„å™ªå£°æ‰©æ•£è¿‡ç¨‹ï¼Œå‡å°‘è®¡ç®—å¤æ‚åº¦å¹¶æé«˜å¯¹ä¸åŒå™ªå£°å’Œè¯­éŸ³å¤±çœŸçš„é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œç¼©å°äº†æ‰©æ•£æ–¹æ³•å’Œé¢„æµ‹è¯­éŸ³å¢å¼ºæ–¹æ³•ä¹‹é—´çš„æ¨¡å‹è§„æ¨¡å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨è¯­éŸ³å¢å¼ºé¢†åŸŸå¤‡å—ç©ç›®ï¼Œå…·æœ‰ç«äº‰æ€§çš„ç»“æœã€‚</li>
<li>å½“å‰æ‰©æ•£æ¨¡å‹å­˜åœ¨è®¡ç®—æ•ˆç‡é—®é¢˜ã€‚</li>
<li>è¯­éŸ³å¢å¼ºä¸ä»…æ˜¯ç”Ÿæˆä»»åŠ¡ï¼Œæ›´ä¸»è¦æ˜¯å™ªå£°å‡å°‘å’Œç¼ºå¤±ä¿¡æ¯çš„è¡¥å……ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥å…·æœ‰å®šå‘æŒ‡å¯¼çš„å™ªå£°æ‰©æ•£è¿‡ç¨‹ï¼Œæé«˜è®¡ç®—æ•ˆç‡å’Œé²æ£’æ€§ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•å®ç°äº†å“è¶Šæ€§èƒ½ï¼Œæ¨¡å‹å‚æ•°æ•°é‡å¤§å¹…é™ä½ã€‚</li>
<li>ä¸å…¶ä»–æ‰©æ•£æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•ç¼©å°äº†æ¨¡å‹è§„æ¨¡å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.15101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1e119874fc64c3c61956bfec43f8bebf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78258d21f0e9223865e63baa3c61a07d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4ac02365ff25619f53fca8057f1e2139.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-863f4a2fef283d9f360e15f3371f5966.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Communication-Efficient-Personalized-Federated-Learning-for-Speech-to-Text-Tasks"><a href="#Communication-Efficient-Personalized-Federated-Learning-for-Speech-to-Text-Tasks" class="headerlink" title="Communication-Efficient Personalized Federated Learning for   Speech-to-Text Tasks"></a>Communication-Efficient Personalized Federated Learning for   Speech-to-Text Tasks</h2><p><strong>Authors:Yichao Du, Zhirui Zhang, Linan Yue, Xu Huang, Yuqing Zhang, Tong Xu, Linli Xu, Enhong Chen</strong></p>
<p>To protect privacy and meet legal regulations, federated learning (FL) has gained significant attention for training speech-to-text (S2T) systems, including automatic speech recognition (ASR) and speech translation (ST). However, the commonly used FL approach (i.e., \textsc{FedAvg}) in S2T tasks typically suffers from extensive communication overhead due to multi-round interactions based on the whole model and performance degradation caused by data heterogeneity among clients.To address these issues, we propose a personalized federated S2T framework that introduces \textsc{FedLoRA}, a lightweight LoRA module for client-side tuning and interaction with the server to minimize communication overhead, and \textsc{FedMem}, a global model equipped with a $k$-nearest-neighbor ($k$NN) classifier that captures client-specific distributional shifts to achieve personalization and overcome data heterogeneity. Extensive experiments based on Conformer and Whisper backbone models on CoVoST and GigaSpeech benchmarks show that our approach significantly reduces the communication overhead on all S2T tasks and effectively personalizes the global model to overcome data heterogeneity. </p>
<blockquote>
<p>ä¸ºäº†ä¿æŠ¤éšç§å¹¶æ»¡è¶³æ³•è§„è¦æ±‚ï¼Œè”é‚¦å­¦ä¹ ï¼ˆFLï¼‰åœ¨è®­ç»ƒè¯­éŸ³åˆ°æ–‡æœ¬ï¼ˆS2Tï¼‰ç³»ç»Ÿæ–¹é¢å¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œè¿™äº›ç³»ç»ŸåŒ…æ‹¬è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³ç¿»è¯‘ï¼ˆSTï¼‰ã€‚ç„¶è€Œï¼ŒS2Tä»»åŠ¡ä¸­å¸¸ç”¨çš„è”é‚¦å­¦ä¹ ï¼ˆå³\text{FedAvg}ï¼‰æ–¹æ³•é€šå¸¸é¢ä¸´ç”±äºåŸºäºæ•´ä¸ªæ¨¡å‹çš„å¤šæ¬¡äº¤äº’å¯¼è‡´çš„é€šä¿¡å¼€é”€è¿‡å¤§ï¼Œä»¥åŠå› å®¢æˆ·ç«¯ä¹‹é—´çš„æ•°æ®å¼‚è´¨æ€§å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–çš„è”é‚¦S2Tæ¡†æ¶ï¼Œå¼•å…¥\text{FedLoRA}ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„LoRAæ¨¡å—ï¼Œç”¨äºå®¢æˆ·ç«¯è°ƒä¼˜å’Œä¸æœåŠ¡å™¨äº¤äº’ï¼Œä»¥æœ€å°åŒ–é€šä¿¡å¼€é”€ï¼›ä»¥åŠ\text{FedMem}ï¼Œè¿™æ˜¯ä¸€ä¸ªé…å¤‡kè¿‘é‚»ï¼ˆkNNï¼‰åˆ†ç±»å™¨çš„å…¨å±€æ¨¡å‹ï¼Œèƒ½å¤Ÿæ•æ‰å®¢æˆ·ç«¯ç‰¹å®šçš„åˆ†å¸ƒå˜åŒ–ï¼Œä»¥å®ç°ä¸ªæ€§åŒ–å’Œå…‹æœæ•°æ®å¼‚è´¨æ€§ã€‚åŸºäºConformerå’ŒWhisperéª¨å¹²æ¨¡å‹åœ¨CoVoSTå’ŒGigaSpeechåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—å‡å°‘äº†æ‰€æœ‰S2Tä»»åŠ¡çš„é€šä¿¡å¼€é”€ï¼Œå¹¶æœ‰æ•ˆåœ°å°†å…¨å±€ä¸ªæ€§åŒ–ä»¥å…‹æœæ•°æ®å¼‚è´¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.10070v2">PDF</a> ICASSP 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨äºè”é‚¦å­¦ä¹ ï¼ˆFLï¼‰åœ¨è®­ç»ƒè¯­éŸ³åˆ°æ–‡æœ¬ï¼ˆS2Tï¼‰ç³»ç»Ÿä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³ç¿»è¯‘ï¼ˆSTï¼‰ã€‚é’ˆå¯¹ç°æœ‰è”é‚¦å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚FedAvgï¼‰åœ¨S2Tä»»åŠ¡ä¸­é¢ä¸´çš„é€šä¿¡å¼€é”€å¤§å’Œæ•°æ®å¼‚æ„æ€§å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œæå‡ºä¸€ç§ä¸ªæ€§åŒ–è”é‚¦S2Tæ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥FedLoRAæ¨¡å—è¿›è¡Œå®¢æˆ·ç«¯è°ƒä¼˜å’Œä¸æœåŠ¡å™¨äº¤äº’ï¼Œä»¥å‡å°é€šä¿¡å¼€é”€ï¼Œå¹¶é‡‡ç”¨FedMemå…¨å±€æ¨¡å‹é…å¤‡k-æœ€è¿‘é‚»ï¼ˆk-NNï¼‰åˆ†ç±»å™¨ï¼Œä»¥æ•æ‰å®¢æˆ·ç«¯ç‰¹å®šçš„åˆ†å¸ƒå˜åŒ–ï¼Œå®ç°ä¸ªæ€§åŒ–å¹¶å…‹æœæ•°æ®å¼‚æ„æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡å°‘é€šä¿¡å¼€é”€å’Œä¸ªæ€§åŒ–å…¨å±€æ¨¡å‹æ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰åœ¨è®­ç»ƒè¯­éŸ³åˆ°æ–‡æœ¬ï¼ˆS2Tï¼‰ç³»ç»Ÿï¼ŒåŒ…æ‹¬è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³ç¿»è¯‘ï¼ˆSTï¼‰ä¸­å—åˆ°å…³æ³¨ã€‚</li>
<li>ç°æœ‰è”é‚¦å­¦ä¹ æ–¹æ³•åœ¨S2Tä»»åŠ¡ä¸­é¢ä¸´é€šä¿¡å¼€é”€å¤§å’Œæ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚</li>
<li>æå‡ºçš„ä¸ªæ€§åŒ–è”é‚¦S2Tæ¡†æ¶é€šè¿‡å¼•å…¥FedLoRAæ¨¡å—å’ŒFedMemå…¨å±€æ¨¡å‹ï¼Œè§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>FedLoRAæ¨¡å—ç”¨äºå®¢æˆ·ç«¯è°ƒä¼˜å’Œä¸æœåŠ¡å™¨äº¤äº’ï¼Œå‡å°é€šä¿¡å¼€é”€ã€‚</li>
<li>FedMemå…¨å±€æ¨¡å‹é…å¤‡k-æœ€è¿‘é‚»ï¼ˆk-NNï¼‰åˆ†ç±»å™¨ï¼Œæ•æ‰å®¢æˆ·ç«¯ç‰¹å®šåˆ†å¸ƒå˜åŒ–ï¼Œå®ç°ä¸ªæ€§åŒ–å¹¶å…‹æœæ•°æ®å¼‚æ„æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡å°‘é€šä¿¡å¼€é”€å’Œä¸ªæ€§åŒ–å…¨å±€æ¨¡å‹æ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚</li>
<li>è¯¥æ¡†æ¶çš„åº”ç”¨æœ‰åŠ©äºæå‡S2Tä»»åŠ¡çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.10070">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-24\./crop_Speech/2401.10070v2/page_0_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66d67d2976822b7d5045587d3b5b6f9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bdc66aaab118771b35f17b0e24ccd10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d474bbabb0deac4d6b8f7286dd78df4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe6214254e5c27f88f70178a1a8cea75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1691fc77d54a1385fe193d2306144d70.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DurFlex-EVC-Duration-Flexible-Emotional-Voice-Conversion-Leveraging-Discrete-Representations-without-Text-Alignment"><a href="#DurFlex-EVC-Duration-Flexible-Emotional-Voice-Conversion-Leveraging-Discrete-Representations-without-Text-Alignment" class="headerlink" title="DurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging   Discrete Representations without Text Alignment"></a>DurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging   Discrete Representations without Text Alignment</h2><p><strong>Authors:Hyung-Seok Oh, Sang-Hoon Lee, Deok-Hyeon Cho, Seong-Whan Lee</strong></p>
<p>Emotional voice conversion (EVC) involves modifying various acoustic characteristics, such as pitch and spectral envelope, to match a desired emotional state while preserving the speakerâ€™s identity. Existing EVC methods often rely on text transcriptions or time-alignment information and struggle to handle varying speech durations effectively. In this paper, we propose DurFlex-EVC, a duration-flexible EVC framework that operates without the need for text or alignment information. We introduce a unit aligner that models contextual information by aligning speech with discrete units representing content, eliminating the need for text or speech-text alignment. Additionally, we design a style autoencoder that effectively disentangles content and emotional style, allowing precise manipulation of the emotional characteristics of the speech. We further enhance emotional expressiveness through a hierarchical stylize encoder that applies the target emotional style at multiple hierarchical levels, refining the stylization process to improve the naturalness and expressiveness of the converted speech. Experimental results from subjective and objective evaluations demonstrate that our approach outperforms baseline models, effectively handling duration variability and enhancing emotional expressiveness in the converted speech. </p>
<blockquote>
<p>æƒ…æ„Ÿè¯­éŸ³è½¬æ¢ï¼ˆEVCï¼‰æ¶‰åŠä¿®æ”¹å„ç§å£°å­¦ç‰¹å¾ï¼Œå¦‚éŸ³é«˜å’Œé¢‘è°±åŒ…ç»œï¼Œä»¥åŒ¹é…æ‰€éœ€çš„æƒ…æ„ŸçŠ¶æ€ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯è€…çš„èº«ä»½ã€‚ç°æœ‰çš„EVCæ–¹æ³•é€šå¸¸ä¾èµ–äºæ–‡æœ¬è½¬å½•æˆ–æ—¶é—´å¯¹é½ä¿¡æ¯ï¼Œå¹¶ä¸”åœ¨æœ‰æ•ˆå¤„ç†ä¸åŒè¯­éŸ³æ—¶é•¿æ–¹é¢å­˜åœ¨å›°éš¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†æ— éœ€æ–‡æœ¬æˆ–å¯¹é½ä¿¡æ¯çš„æ—¶é•¿çµæ´»EVCæ¡†æ¶DurFlex-EVCã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå•å…ƒå¯¹é½å™¨ï¼Œé€šè¿‡å°†å¯¹é½è¯­éŸ³ä¸ä»£è¡¨å†…å®¹çš„ç¦»æ•£å•å…ƒæ¥å»ºæ¨¡ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹æ–‡æœ¬æˆ–è¯­éŸ³æ–‡æœ¬å¯¹é½çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé£æ ¼è‡ªç¼–ç å™¨ï¼Œå®ƒèƒ½æœ‰æ•ˆåœ°åˆ†ç¦»å†…å®¹å’Œæƒ…æ„Ÿé£æ ¼ï¼Œå…è®¸ç²¾ç¡®æ“çºµè¯­éŸ³çš„æƒ…æ„Ÿç‰¹å¾ã€‚æˆ‘ä»¬è¿˜é€šè¿‡åˆ†å±‚é£æ ¼åŒ–ç¼–ç å™¨è¿›ä¸€æ­¥å¢å¼ºäº†æƒ…æ„Ÿè¡¨ç°åŠ›ï¼Œè¯¥ç¼–ç å™¨åœ¨å¤šä¸ªå±‚æ¬¡ä¸Šåº”ç”¨ç›®æ ‡æƒ…æ„Ÿé£æ ¼ï¼Œæ”¹è¿›äº†é£æ ¼åŒ–è¿‡ç¨‹ï¼Œæé«˜äº†è½¬æ¢è¯­éŸ³çš„è‡ªç„¶åº¦å’Œè¡¨ç°åŠ›ã€‚ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æ—¶é•¿å˜åŒ–ï¼Œå¢å¼ºè½¬æ¢è¯­éŸ³çš„æƒ…æ„Ÿè¡¨ç°åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.08095v4">PDF</a> 15 pages, 11 figures, 12 tables</p>
<p><strong>Summary</strong><br>æƒ…æ„Ÿè¯­éŸ³è½¬æ¢ï¼ˆEVCï¼‰é€šè¿‡ä¿®æ”¹éŸ³é«˜å’Œé¢‘è°±åŒ…ç»œç­‰å£°å­¦ç‰¹å¾ï¼Œä»¥è¾¾åˆ°åŒ¹é…ç‰¹å®šæƒ…æ„ŸçŠ¶æ€çš„åŒæ—¶ä¿ç•™è¯´è¯è€…èº«ä»½ã€‚ç°æœ‰çš„EVCæ–¹æ³•å¸¸ä¾èµ–äºæ–‡æœ¬è½¬å½•æˆ–æ—¶é—´å¯¹é½ä¿¡æ¯ï¼Œå¹¶éš¾ä»¥æœ‰æ•ˆå¤„ç†ä¸åŒè¯­é•¿çš„è¯­éŸ³ã€‚æœ¬æ–‡æå‡ºæ— éœ€æ–‡æœ¬æˆ–å¯¹é½ä¿¡æ¯çš„æ—¶é•¿çµæ´»EVCæ¡†æ¶DurFlex-EVCã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå•ä½å¯¹é½å™¨ï¼Œé€šè¿‡å°†å¯¹é½è¯­éŸ³ä¸ä»£è¡¨å†…å®¹çš„ç¦»æ•£å•å…ƒå»ºæ¨¡ï¼Œæ¶ˆé™¤äº†å¯¹æ–‡æœ¬æˆ–è¯­éŸ³æ–‡æœ¬å¯¹é½çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé£æ ¼è‡ªç¼–ç å™¨ï¼Œæœ‰æ•ˆåœ°åˆ†ç¦»å†…å®¹å’Œæƒ…æ„Ÿé£æ ¼ï¼Œå…è®¸ç²¾ç¡®æ“æ§è¯­éŸ³çš„æƒ…æ„Ÿç‰¹å¾ã€‚æˆ‘ä»¬è¿˜é€šè¿‡åˆ†å±‚é£æ ¼ç¼–ç å™¨å¢å¼ºæƒ…æ„Ÿè¡¨ç°åŠ›ï¼Œè¯¥ç¼–ç å™¨åœ¨å¤šä¸ªå±‚æ¬¡ä¸Šåº”ç”¨ç›®æ ‡æƒ…æ„Ÿé£æ ¼ï¼Œç»†åŒ–é£æ ¼åŒ–è¿‡ç¨‹ï¼Œä»¥æé«˜è½¬æ¢è¯­éŸ³çš„è‡ªç„¶åº¦å’Œè¡¨ç°åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æ—¶é•¿å˜åŒ–ï¼Œå¢å¼ºè½¬æ¢è¯­éŸ³çš„æƒ…æ„Ÿè¡¨ç°åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æƒ…æ„Ÿè¯­éŸ³è½¬æ¢ï¼ˆEVCï¼‰æ˜¯é€šè¿‡æ”¹å˜å£°å­¦ç‰¹å¾æ¥åŒ¹é…æƒ…æ„ŸçŠ¶æ€ï¼ŒåŒæ—¶ä¿æŒè¯´è¯è€…èº«ä»½ã€‚</li>
<li>ç°æœ‰EVCæ–¹æ³•ä¾èµ–æ–‡æœ¬è½¬å½•æˆ–æ—¶é—´å¯¹é½ä¿¡æ¯ï¼Œå¤„ç†ä¸åŒè¯­é•¿æ—¶å­˜åœ¨å›°éš¾ã€‚</li>
<li>DurFlex-EVCæ¡†æ¶æ— éœ€æ–‡æœ¬æˆ–å¯¹é½ä¿¡æ¯ï¼Œé€šè¿‡å•ä½å¯¹é½å™¨ä¸é£æ ¼è‡ªç¼–ç å™¨æœ‰æ•ˆè¿›è¡Œè¯­éŸ³è½¬æ¢ã€‚</li>
<li>å•ä½å¯¹é½å™¨åˆ©ç”¨ç¦»æ•£å•å…ƒä»£è¡¨å†…å®¹ï¼Œæ¶ˆé™¤äº†å¯¹æ–‡æœ¬å’Œè¯­éŸ³æ–‡æœ¬å¯¹é½çš„éœ€æ±‚ã€‚</li>
<li>é£æ ¼è‡ªç¼–ç å™¨èƒ½å¤Ÿåˆ†ç¦»å†…å®¹å’Œæƒ…æ„Ÿé£æ ¼ï¼Œå…è®¸ç²¾ç¡®æ“æ§è¯­éŸ³çš„æƒ…æ„Ÿç‰¹å¾ã€‚</li>
<li>æå‡ºçš„åˆ†å±‚é£æ ¼ç¼–ç å™¨èƒ½å¢å¼ºæƒ…æ„Ÿè¡¨ç°åŠ›ï¼Œé€šè¿‡å®éªŒéªŒè¯å…¶ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.08095">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-24\./crop_Speech/2401.08095v4/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-24\./crop_Speech/2401.08095v4/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-24\./crop_Speech/2401.08095v4/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-24\./crop_Speech/2401.08095v4/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-24/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-24/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-24/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1a1261f37839c32f4bcc44800933edd0.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-24  HAC++ Towards 100X Compression of 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-24/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-28527ed630acfd819768664e3affe5f6.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-24  Condition-Invariant Semantic Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33297.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
