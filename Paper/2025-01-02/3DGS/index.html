<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Prometheus 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D   Scene Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-b51444c746b853c2990f78df6232bb9c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-03
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    67 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-02-æ›´æ–°"><a href="#2025-01-02-æ›´æ–°" class="headerlink" title="2025-01-02 æ›´æ–°"></a>2025-01-02 æ›´æ–°</h1><h2 id="Prometheus-3D-Aware-Latent-Diffusion-Models-for-Feed-Forward-Text-to-3D-Scene-Generation"><a href="#Prometheus-3D-Aware-Latent-Diffusion-Models-for-Feed-Forward-Text-to-3D-Scene-Generation" class="headerlink" title="Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D   Scene Generation"></a>Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D   Scene Generation</h2><p><strong>Authors:Yuanbo Yang, Jiahao Shao, Xinyang Li, Yujun Shen, Andreas Geiger, Yiyi Liao</strong></p>
<p>In this work, we introduce Prometheus, a 3D-aware latent diffusion model for text-to-3D generation at both object and scene levels in seconds. We formulate 3D scene generation as multi-view, feed-forward, pixel-aligned 3D Gaussian generation within the latent diffusion paradigm. To ensure generalizability, we build our model upon pre-trained text-to-image generation model with only minimal adjustments, and further train it using a large number of images from both single-view and multi-view datasets. Furthermore, we introduce an RGB-D latent space into 3D Gaussian generation to disentangle appearance and geometry information, enabling efficient feed-forward generation of 3D Gaussians with better fidelity and geometry. Extensive experimental results demonstrate the effectiveness of our method in both feed-forward 3D Gaussian reconstruction and text-to-3D generation. Project page: <a target="_blank" rel="noopener" href="https://freemty.github.io/project-prometheus/">https://freemty.github.io/project-prometheus/</a> </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Prometheusï¼Œè¿™æ˜¯ä¸€ä¸ª3Dæ„ŸçŸ¥æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¯åœ¨å¯¹è±¡å’Œåœºæ™¯çº§åˆ«å®ç°æ–‡æœ¬åˆ°3Dçš„å³æ—¶ç”Ÿæˆã€‚æˆ‘ä»¬å°†3Dåœºæ™¯ç”Ÿæˆå…¬å¼åŒ–ä¸ºæ½œåœ¨æ‰©æ•£èŒƒå¼å†…çš„å¤šè§†è§’ã€å‰é¦ˆã€åƒç´ å¯¹é½çš„3Dé«˜æ–¯ç”Ÿæˆã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹çš„é€šç”¨æ€§ï¼Œæˆ‘ä»¬åœ¨åŸºäºé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„åŸºç¡€ä¸Šä»…è¿›è¡Œå¾®è°ƒæ„å»ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å¤§é‡çš„æ¥è‡ªå•è§†è§’å’Œå¤šè§†è§’æ•°æ®é›†å›¾åƒè¿›ä¸€æ­¥è®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†RGB-Dæ½œåœ¨ç©ºé—´å¼•å…¥3Dé«˜æ–¯ç”Ÿæˆä¸­ï¼Œä»¥åˆ†ç¦»å¤–è§‚å’Œå‡ ä½•ä¿¡æ¯ï¼Œå®ç°é«˜æ•ˆçš„å‰é¦ˆ3Dé«˜æ–¯ç”Ÿæˆï¼Œæé«˜ä¿çœŸåº¦å’Œå‡ ä½•æ•ˆæœã€‚å¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å‰é¦ˆ3Dé«˜æ–¯é‡å»ºå’Œæ–‡æœ¬åˆ°3Dç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://freemty.github.io/project-prometheus/">https://freemty.github.io/project-prometheus/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.21117v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åä¸ºPrometheusçš„3Dæ„ŸçŸ¥æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯åœ¨å¯¹è±¡å’Œåœºæ™¯çº§åˆ«å®ç°æ–‡æœ¬åˆ°3Dçš„å³æ—¶ç”Ÿæˆã€‚æ¨¡å‹åŸºäºæ½œåœ¨æ‰©æ•£èŒƒå¼ï¼Œå°†å¤šè§†è§’ã€å‰é¦ˆã€åƒç´ å¯¹é½çš„3Dé«˜æ–¯ç”Ÿæˆåº”ç”¨äºåœºæ™¯ç”Ÿæˆä»»åŠ¡ã€‚æ¨¡å‹åœ¨é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„åŸºç¡€ä¸Šæ„å»ºï¼Œé€šè¿‡è°ƒæ•´è¾ƒå°çš„æ•°æ®å¾®è°ƒç”¨äºè¿›ä¸€æ­¥è®­ç»ƒæ¨¡å‹çš„å¤§å‹å›¾åƒé›†æ•°æ®æ¶µç›–å•ä¸€è§†è§’å’Œå¤šç§è§†è§’æ•°æ®é›†ï¼Œä¸ºå¢åŠ å…¶æ•ˆæœæ·»åŠ äº†RGB-Dæ½œåœ¨ç©ºé—´è¿›å…¥é«˜æ–¯çš„ç»´åº¦ä»¥æé«˜ç”Ÿæˆçš„ä¸‰ç»´å›¾åƒçš„ä¿çœŸåº¦å’Œå‡ ä½•å½¢çŠ¶ã€‚å®éªŒè¯æ˜è¯¥æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Prometheusæ˜¯ä¸€ä¸ªç”¨äºæ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆçš„3Dæ„ŸçŸ¥æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹èƒ½å¤ŸåŒæ—¶å¤„ç†å¯¹è±¡å’Œåœºæ™¯çº§åˆ«çš„ç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>é‡‡ç”¨æ½œåœ¨æ‰©æ•£èŒƒå¼å’Œå¤šè§†è§’åƒç´ å¯¹é½è¿›è¡Œåœºæ™¯ç”Ÿæˆã€‚</li>
<li>æ¨¡å‹åœ¨é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„åŸºç¡€ä¸Šæ„å»ºï¼Œå¹¶è¿›è¡Œäº†å¤§å‹å›¾åƒé›†çš„æ•°æ®å¾®è°ƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.21117">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2778e0db5bc3638b2cd58683b762ed75.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21f302ba85971abb997416d889cd19ef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa23e3ff59e9121764b32b3887734fd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7045da7717bf68e670514bd038da7d62.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="KeyGS-A-Keyframe-Centric-Gaussian-Splatting-Method-for-Monocular-Image-Sequences"><a href="#KeyGS-A-Keyframe-Centric-Gaussian-Splatting-Method-for-Monocular-Image-Sequences" class="headerlink" title="KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image   Sequences"></a>KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image   Sequences</h2><p><strong>Authors:Keng-Wei Chang, Zi-Ming Wang, Shang-Hong Lai</strong></p>
<p>Reconstructing high-quality 3D models from sparse 2D images has garnered significant attention in computer vision. Recently, 3D Gaussian Splatting (3DGS) has gained prominence due to its explicit representation with efficient training speed and real-time rendering capabilities. However, existing methods still heavily depend on accurate camera poses for reconstruction. Although some recent approaches attempt to train 3DGS models without the Structure-from-Motion (SfM) preprocessing from monocular video datasets, these methods suffer from prolonged training times, making them impractical for many applications.   In this paper, we present an efficient framework that operates without any depth or matching model. Our approach initially uses SfM to quickly obtain rough camera poses within seconds, and then refines these poses by leveraging the dense representation in 3DGS. This framework effectively addresses the issue of long training times. Additionally, we integrate the densification process with joint refinement and propose a coarse-to-fine frequency-aware densification to reconstruct different levels of details. This approach prevents camera pose estimation from being trapped in local minima or drifting due to high-frequency signals. Our method significantly reduces training time from hours to minutes while achieving more accurate novel view synthesis and camera pose estimation compared to previous methods. </p>
<blockquote>
<p>ä»ç¨€ç–çš„2Då›¾åƒé‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´æ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå·²ç»å¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ã€‚è¿‘æœŸï¼Œç”±äºä¸‰ç»´é«˜æ–¯æ˜ å°„ï¼ˆ3DGSï¼‰å…·æœ‰é«˜æ•ˆçš„è®­ç»ƒé€Ÿåº¦å’Œå®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œå…¶æ˜¾å¼è¡¨ç¤ºæ–¹æ³•å—åˆ°äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é‡å»ºæ–¹æ³•ä»ç„¶ä¸¥é‡ä¾èµ–äºå‡†ç¡®çš„ç›¸æœºå§¿æ€ã€‚å°½ç®¡æœ€è¿‘çš„ä¸€äº›æ–¹æ³•è¯•å›¾åœ¨ä¸ä½¿ç”¨ä»å•ç›®è§†é¢‘æ•°æ®é›†ä¸­çš„è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰é¢„å¤„ç†çš„æƒ…å†µä¸‹è®­ç»ƒ3DGSæ¨¡å‹ï¼Œä½†è¿™äº›æ–¹æ³•çš„è®­ç»ƒæ—¶é—´å»¶é•¿ï¼Œä½¿å¾—å®ƒä»¬åœ¨è®¸å¤šåº”ç”¨ä¸­ä¸åˆ‡å®é™…ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ— éœ€ä»»ä½•æ·±åº¦æˆ–åŒ¹é…æ¨¡å‹å³å¯è¿è¡Œã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆä½¿ç”¨SfMåœ¨å‡ ç§’å†…å¿«é€Ÿè·å¾—ç²—ç•¥çš„ç›¸æœºå§¿æ€ï¼Œç„¶åé€šè¿‡åˆ©ç”¨3DGSä¸­çš„å¯†é›†è¡¨ç¤ºæ¥ä¼˜åŒ–è¿™äº›å§¿æ€ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆåœ°è§£å†³äº†è®­ç»ƒæ—¶é—´é•¿çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ç¨ åŒ–è¿‡ç¨‹ä¸è”åˆä¼˜åŒ–ç›¸ç»“åˆï¼Œå¹¶æå‡ºä¸€ç§ä»ç²—åˆ°ç»†çš„é¢‘ç‡æ„ŸçŸ¥ç¨ åŒ–æ–¹æ³•ï¼Œä»¥é‡å»ºä¸åŒçº§åˆ«çš„ç»†èŠ‚ã€‚è¿™ç§æ–¹æ³•é˜²æ­¢äº†ç”±äºé«˜é¢‘ä¿¡å·å¯¼è‡´çš„ç›¸æœºå§¿æ€ä¼°è®¡é™·å…¥å±€éƒ¨æœ€å°å€¼æˆ–æ¼‚ç§»ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†è®­ç»ƒæ—¶é—´ä»æ•°å°æ—¶ç¼©çŸ­åˆ°æ•°åˆ†é’Ÿï¼ŒåŒæ—¶ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ç°äº†æ›´å‡†ç¡®çš„æ–°è§†å›¾åˆæˆå’Œç›¸æœºå§¿æ€ä¼°è®¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20767v1">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ¡†æ¶ï¼Œåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œæ— éœ€æ·±åº¦æˆ–åŒ¹é…æ¨¡å‹å³å¯è¿›è¡Œå·¥ä½œã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨SfMå¿«é€Ÿè·å–ç²—ç•¥çš„ç›¸æœºå§¿æ€ï¼Œç„¶åç»“åˆ3DGSçš„å¯†é›†è¡¨ç¤ºè¿›è¡Œå§¿æ€ä¼˜åŒ–ï¼Œè§£å†³äº†é•¿æ—¶é—´è®­ç»ƒçš„é—®é¢˜ã€‚åŒæ—¶ï¼Œé€šè¿‡æ•´åˆç²—åˆ°ç»†çš„é¢‘åŸŸæ„ŸçŸ¥å¯†é›†åŒ–è¿‡ç¨‹ï¼Œå®ç°äº†ä¸åŒå±‚æ¬¡çš„ç»†èŠ‚é‡å»ºï¼Œæé«˜äº†æ–°å‹è§†è§’åˆæˆå’Œç›¸æœºå§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3D Gaussian Splatting (3DGS)å…·æœ‰æ˜¾å¼è¡¨ç¤ºã€é«˜æ•ˆè®­ç»ƒé€Ÿåº¦å’Œå®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œå·²å—åˆ°å¹¿æ³›å…³æ³¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä»ä¸¥é‡ä¾èµ–äºå‡†ç¡®çš„ç›¸æœºå§¿æ€è¿›è¡Œé‡å»ºã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€æ·±åº¦æˆ–åŒ¹é…æ¨¡å‹çš„æ¡†æ¶ï¼Œè§£å†³äº†é•¿æ—¶é—´è®­ç»ƒçš„é—®é¢˜ã€‚</li>
<li>æ¡†æ¶é¦–å…ˆåˆ©ç”¨SfMå¿«é€Ÿè·å–ç²—ç•¥ç›¸æœºå§¿æ€ã€‚</li>
<li>é€šè¿‡ç»“åˆ3DGSçš„å¯†é›†è¡¨ç¤ºï¼Œå¯¹ç›¸æœºå§¿æ€è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>æ•´åˆç²—åˆ°ç»†çš„é¢‘åŸŸæ„ŸçŸ¥å¯†é›†åŒ–è¿‡ç¨‹ï¼Œå®ç°ä¸åŒå±‚æ¬¡çš„ç»†èŠ‚é‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6496cab65e650a55413688b337b907d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3d414e3be93c7391844c275a8d89dc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5da6166bc851275bf11675391667378.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0ef7b207506f69b22120f2c6f8f7af3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc0979e8762a945ae1820b0dbfb563ef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-eb2f86725609c855892ede3fa4a458dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97e7a365fd256d3568c1cbb34dd5a702.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="4D-Gaussian-Splatting-Modeling-Dynamic-Scenes-with-Native-4D-Primitives"><a href="#4D-Gaussian-Splatting-Modeling-Dynamic-Scenes-with-Native-4D-Primitives" class="headerlink" title="4D Gaussian Splatting: Modeling Dynamic Scenes with Native 4D Primitives"></a>4D Gaussian Splatting: Modeling Dynamic Scenes with Native 4D Primitives</h2><p><strong>Authors:Zeyu Yang, Zijie Pan, Xiatian Zhu, Li Zhang, Yu-Gang Jiang, Philip H. S. Torr</strong></p>
<p>Dynamic 3D scene representation and novel view synthesis from captured videos are crucial for enabling immersive experiences required by AR&#x2F;VR and metaverse applications. However, this task is challenging due to the complexity of unconstrained real-world scenes and their temporal dynamics. In this paper, we frame dynamic scenes as a spatio-temporal 4D volume learning problem, offering a native explicit reformulation with minimal assumptions about motion, which serves as a versatile dynamic scene learning framework. Specifically, we represent a target dynamic scene using a collection of 4D Gaussian primitives with explicit geometry and appearance features, dubbed as 4D Gaussian splatting (4DGS). This approach can capture relevant information in space and time by fitting the underlying spatio-temporal volume. Modeling the spacetime as a whole with 4D Gaussians parameterized by anisotropic ellipses that can rotate arbitrarily in space and time, our model can naturally learn view-dependent and time-evolved appearance with 4D spherindrical harmonics. Notably, our 4DGS model is the first solution that supports real-time rendering of high-resolution, photorealistic novel views for complex dynamic scenes. To enhance efficiency, we derive several compact variants that effectively reduce memory footprint and mitigate the risk of overfitting. Extensive experiments validate the superiority of 4DGS in terms of visual quality and efficiency across a range of dynamic scene-related tasks (e.g., novel view synthesis, 4D generation, scene understanding) and scenarios (e.g., single object, indoor scenes, driving environments, synthetic and real data). </p>
<blockquote>
<p>åŠ¨æ€ä¸‰ç»´åœºæ™¯è¡¨ç¤ºå’Œä»æ•è·çš„è§†é¢‘ä¸­åˆæˆæ–°å‹è§†å›¾å¯¹äºå¢å¼ºç°å®ï¼ˆARï¼‰&#x2F;è™šæ‹Ÿç°å®ï¼ˆVRï¼‰å’Œå…ƒå®‡å®™åº”ç”¨æ‰€éœ€æ²‰æµ¸å¼ä½“éªŒè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºä¸å—é™åˆ¶çš„ç°å®åœºæ™¯å¤æ‚æ€§å’Œå…¶æ—¶é—´åŠ¨æ€æ€§ï¼Œæ­¤ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†åŠ¨æ€åœºæ™¯ä½œä¸ºæ—¶ç©ºå››ç»´ä½“ç§¯å­¦ä¹ é—®é¢˜åŠ ä»¥æè¿°ï¼Œæä¾›äº†ä¸€ä¸ªæœ¬åœ°æ˜¾å¼é‡æ„çš„æ–¹æ³•ï¼Œå¯¹è¿åŠ¨åšå‡ºäº†æå°‘å‡è®¾ï¼Œä»è€Œä½œä¸ºä¸€ä¸ªé€šç”¨åŠ¨æ€åœºæ™¯å­¦ä¹ æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„å…·æœ‰æ˜ç¡®å‡ ä½•å’Œå¤–è§‚ç‰¹å¾çš„å››ç»´é«˜æ–¯åŸå§‹æ•°æ®æ¥è¡¨ç¤ºç›®æ ‡åŠ¨æ€åœºæ™¯ï¼Œç§°ä¸ºå››ç»´é«˜æ–¯å–·æ¶‚ï¼ˆ4DGSï¼‰ã€‚æ­¤æ–¹æ³•å¯ä»¥é€šè¿‡æ‹Ÿåˆåº•å±‚æ—¶ç©ºä½“ç§¯æ¥æ•è·ç©ºé—´å’Œæ—¶é—´çš„æœ‰å…³ä¿¡æ¯ã€‚å°†æ—¶ç©ºä½œä¸ºæ•´ä½“ç”¨å››ç»´é«˜æ–¯å»ºæ¨¡ï¼Œé€šè¿‡ç”±å¯ä»»æ„æ—‹è½¬çš„ç©ºé—´å’Œæ—¶é—´ä¸­çš„æ¤­åœ†ä½“å‚æ•°åŒ–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿè‡ªç„¶åœ°åˆ©ç”¨å››ç»´çƒé¢è°æ³¢å­¦ä¹ è§†ç‚¹å’Œéšæ—¶é—´å˜åŒ–çš„å¤–è§‚ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„4DGSæ¨¡å‹æ˜¯ç¬¬ä¸€ä¸ªæ”¯æŒå¤æ‚åŠ¨æ€åœºæ™¯çš„é«˜åˆ†è¾¨ç‡ã€ç…§ç‰‡çº§çœŸå®æ„Ÿæ–°è§†å›¾çš„å®æ—¶æ¸²æŸ“çš„è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†æé«˜æ•ˆç‡ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†å‡ ç§ç´§å‡‘å˜ä½“ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†å†…å­˜å ç”¨å¹¶é™ä½äº†è¿‡æ‹Ÿåˆçš„é£é™©ã€‚å¤§é‡å®éªŒéªŒè¯äº†4DGSåœ¨å¤šç§åŠ¨æ€åœºæ™¯ç›¸å…³ä»»åŠ¡ï¼ˆä¾‹å¦‚æ–°è§†å›¾åˆæˆã€å››ç»´ç”Ÿæˆã€åœºæ™¯ç†è§£ï¼‰å’Œåœºæ™¯ï¼ˆä¾‹å¦‚å•ä¸ªç‰©ä½“ã€å®¤å†…åœºæ™¯ã€é©¾é©¶ç¯å¢ƒã€åˆæˆå’ŒçœŸå®æ•°æ®ï¼‰çš„è§†è§‰è´¨é‡å’Œæ•ˆç‡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20720v1">PDF</a> Journal extension of ICLR 2024. arXiv admin note: text overlap with   arXiv:2310.10642</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäº4Dé«˜æ–¯åŸå§‹æ•°æ®çš„åŠ¨æ€åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸º4Dé«˜æ–¯å–·æ¶‚ï¼ˆ4DGSï¼‰ã€‚è¯¥æ–¹æ³•å°†åŠ¨æ€åœºæ™¯è§†ä¸ºä¸€ä¸ªæ—¶ç©ºä½“ç§¯å­¦ä¹ é—®é¢˜ï¼Œå¹¶ä½¿ç”¨éšå¼å‡ ä½•å’Œå¤–è§‚ç‰¹å¾è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡æ‹Ÿåˆæ—¶ç©ºä½“ç§¯ï¼Œå¯ä»¥æ•æ‰ç©ºé—´å’Œæ—¶é—´çš„ç›¸å…³ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹æ”¯æŒå¯¹å¤æ‚åŠ¨æ€åœºæ™¯è¿›è¡Œé«˜åˆ†è¾¨ç‡ã€çœŸå®æ„Ÿçš„æ–°å‹å®æ—¶æ¸²æŸ“ï¼Œæé«˜äº†æ•ˆç‡å’Œè§†è§‰è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼Œ4DGSåœ¨å¤šç§åŠ¨æ€åœºæ™¯ç›¸å…³ä»»åŠ¡å’Œåœºæ™¯ä¸­è¡¨ç°ä¼˜è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŠ¨æ€åœºæ™¯è¡¨ç¤ºä¸ºæ—¶ç©ºä½“ç§¯å­¦ä¹ é—®é¢˜ï¼Œæå‡º4Dé«˜æ–¯å–·æ¶‚ï¼ˆ4DGSï¼‰æ–¹æ³•ã€‚</li>
<li>4DGSä½¿ç”¨éšå¼å‡ ä½•å’Œå¤–è§‚ç‰¹å¾è¿›è¡Œå»ºæ¨¡ï¼Œæ•æ‰ç©ºé—´å’Œæ—¶é—´çš„ç›¸å…³ä¿¡æ¯ã€‚</li>
<li>4DGSæ”¯æŒå¯¹å¤æ‚åŠ¨æ€åœºæ™¯è¿›è¡Œé«˜åˆ†è¾¨ç‡ã€çœŸå®æ„Ÿçš„æ–°å‹å®æ—¶æ¸²æŸ“ã€‚</li>
<li>4DGSåœ¨å¤šç§åŠ¨æ€åœºæ™¯ç›¸å…³ä»»åŠ¡ï¼ˆå¦‚æ–°å‹è§†å›¾åˆæˆã€4Dç”Ÿæˆã€åœºæ™¯ç†è§£ï¼‰å’Œåœºæ™¯ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>é€šè¿‡å®éªŒéªŒè¯äº†4DGSåœ¨è§†è§‰è´¨é‡å’Œæ•ˆç‡æ–¹é¢çš„ä¼˜åŠ¿ã€‚</li>
<li>4DGSèƒ½å¤Ÿè‡ªç„¶åœ°å­¦ä¹ è§†è§’ä¾èµ–å’Œæ—¶é—´æ¼”åŒ–çš„å¤–è§‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3290f7db265b0d51389532f26471b61.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9c506151ffbf7e678e4ff5f782fca456.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MaskGaussian-Adaptive-3D-Gaussian-Representation-from-Probabilistic-Masks"><a href="#MaskGaussian-Adaptive-3D-Gaussian-Representation-from-Probabilistic-Masks" class="headerlink" title="MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic   Masks"></a>MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic   Masks</h2><p><strong>Authors:Yifei Liu, Zhihang Zhong, Yifan Zhan, Sheng Xu, Xiao Sun</strong></p>
<p>While 3D Gaussian Splatting (3DGS) has demonstrated remarkable performance in novel view synthesis and real-time rendering, the high memory consumption due to the use of millions of Gaussians limits its practicality. To mitigate this issue, improvements have been made by pruning unnecessary Gaussians, either through a hand-crafted criterion or by using learned masks. However, these methods deterministically remove Gaussians based on a snapshot of the pruning moment, leading to sub-optimized reconstruction performance from a long-term perspective. To address this issue, we introduce MaskGaussian, which models Gaussians as probabilistic entities rather than permanently removing them, and utilize them according to their probability of existence. To achieve this, we propose a masked-rasterization technique that enables unused yet probabilistically existing Gaussians to receive gradients, allowing for dynamic assessment of their contribution to the evolving scene and adjustment of their probability of existence. Hence, the importance of Gaussians iteratively changes and the pruned Gaussians are selected diversely. Extensive experiments demonstrate the superiority of the proposed method in achieving better rendering quality with fewer Gaussians than previous pruning methods, pruning over 60% of Gaussians on average with only a 0.02 PSNR decline. Our code can be found at: <a target="_blank" rel="noopener" href="https://github.com/kaikai23/MaskGaussian">https://github.com/kaikai23/MaskGaussian</a> </p>
<blockquote>
<p>è™½ç„¶3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†è§’åˆæˆå’Œå®æ—¶æ¸²æŸ“æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä½†ç”±äºä½¿ç”¨äº†æ•°ç™¾ä¸‡ä¸ªé«˜æ–¯ï¼Œå…¶é«˜å†…å­˜æ¶ˆè€—é™åˆ¶äº†å®ç”¨æ€§ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œå·²ç»é€šè¿‡åˆ é™¤ä¸å¿…è¦çš„é«˜æ–¯è¿›è¡Œäº†æ”¹è¿›ï¼Œæ–¹æ³•åŒ…æ‹¬æ‰‹å·¥åˆ¶å®šçš„æ ‡å‡†æˆ–ä½¿ç”¨å­¦ä¹ åˆ°çš„æ©è†œã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åŸºäºå‰ªææ—¶åˆ»çš„å¿«ç…§ç¡®å®šæ€§åœ°åˆ é™¤é«˜æ–¯ï¼Œä»é•¿è¿œæ¥çœ‹å¯¼è‡´é‡å»ºæ€§èƒ½æ¬¡ä¼˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†MaskGaussianï¼Œå®ƒå°†é«˜æ–¯å»ºæ¨¡ä¸ºæ¦‚ç‡å®ä½“ï¼Œè€Œä¸æ˜¯æ°¸ä¹…åˆ é™¤å®ƒä»¬ï¼Œå¹¶æ ¹æ®å…¶å­˜åœ¨çš„æ¦‚ç‡æ¥ä½¿ç”¨å®ƒä»¬ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ©è†œæ …æ ¼åŒ–æŠ€æœ¯ï¼Œä½¿æœªä½¿ç”¨ä½†æ¦‚ç‡å­˜åœ¨çš„é«˜æ–¯èƒ½å¤Ÿè·å¾—æ¢¯åº¦ï¼Œä»è€Œèƒ½å¤ŸåŠ¨æ€è¯„ä¼°å®ƒä»¬å¯¹ä¸æ–­å˜åŒ–çš„åœºæ™¯çš„è´¡çŒ®å¹¶è°ƒæ•´å…¶å­˜åœ¨çš„æ¦‚ç‡ã€‚å› æ­¤ï¼Œé«˜æ–¯çš„é‡è¦æ€§ä¼šè¿­ä»£åœ°æ”¹å˜ï¼Œè¢«å‰ªæçš„é«˜æ–¯é€‰æ‹©ä¹Ÿä¼šå¤šæ ·åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è¾¾åˆ°æ›´å¥½çš„æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºä»¥å‰çš„é«˜æ–¯å‰ªææ–¹æ³•ï¼Œå¹³å‡å‰ªæè¶…è¿‡60%çš„é«˜æ–¯ï¼Œè€ŒPSNRä»…ä¸‹é™0.02ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/kaikai23/MaskGaussian">https://github.com/kaikai23/MaskGaussian</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20522v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è®¨è®ºäº†ä½¿ç”¨æ¦‚ç‡å»ºæ¨¡ä¼˜åŒ–ä¸‰ç»´é«˜æ–¯æ··åˆæ¨¡å‹çš„æ–¹æ³•ã€‚ä¼ ç»Ÿçš„å‰ªææ–¹æ³•ç›´æ¥åˆ é™¤æŸäº›é«˜æ–¯ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´é‡å»ºæ€§èƒ½ä¸ä½³ã€‚æ–°æå‡ºçš„MaskGaussianæ¨¡å‹åˆ™æ ¹æ®æ¦‚ç‡æ¥åŠ¨æ€è°ƒæ•´æ¯ä¸ªé«˜æ–¯çš„ä½¿ç”¨æƒ…å†µï¼Œå³ä½¿åˆ é™¤ä¸€éƒ¨åˆ†ä¹Ÿèƒ½æé«˜æ¸²æŸ“è´¨é‡ã€‚è¿™ç§æ–¹æ³•é‡‡ç”¨äº†å¸¦æœ‰æ©è†œçš„æ …æ ¼åŒ–æŠ€æœ¯ï¼Œé€šè¿‡è¿™ç§æ–¹æ³•å¯ä»¥å®ç°æ›´ä½³çš„é«˜æ–¯ç­›é€‰ï¼Œä»è€Œè¾¾åˆ°æ›´ä½³çš„æ¸²æŸ“æ•ˆæœã€‚è¯¥æ–¹æ³•å‡å°‘äº†é«˜æ–¯ä½¿ç”¨çš„æ•°é‡ï¼Œä¸”å½±å“æœ‰é™ã€‚é¡¹ç›®ä»£ç å·²åœ¨GitHubä¸Šå…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MaskGaussianæ–¹æ³•åˆ©ç”¨æ¦‚ç‡å»ºæ¨¡å¯¹ä¸‰ç»´é«˜æ–¯æ··åˆæ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´æ¯ä¸ªé«˜æ–¯çš„ä½¿ç”¨æƒ…å†µï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>ä¼ ç»Ÿå‰ªææ–¹æ³•åŸºäºç‰¹å®šæ—¶åˆ»çš„å‰ªæå†³ç­–ï¼Œå¯èƒ½ä¼šå¯¼è‡´é•¿æœŸé‡å»ºæ€§èƒ½çš„æ¬¡ä¼˜åŒ–ã€‚</li>
<li>MaskGaussianæ¨¡å‹é€šè¿‡å¼•å…¥æ©è†œæŠ€æœ¯å®ç°äº†åŠ¨æ€çš„å‰ªæå†³ç­–ï¼Œå³ä½¿å‰ªå»ä¸€éƒ¨åˆ†é«˜æ–¯ï¼Œä¹Ÿå¯ä»¥æ”¹å–„åœºæ™¯çš„æ¸²æŸ“è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20522">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e5eea6c8a070b632eb13cee04cd80626.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3faddd546e580b056080c482dc9c6d60.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8f464425bd8bd6ea97b4e5c254618f4d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-180365436b5c7c46cd365ec33c812774.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DEGSTalk-Decomposed-Per-Embedding-Gaussian-Fields-for-Hair-Preserving-Talking-Face-Synthesis"><a href="#DEGSTalk-Decomposed-Per-Embedding-Gaussian-Fields-for-Hair-Preserving-Talking-Face-Synthesis" class="headerlink" title="DEGSTalk: Decomposed Per-Embedding Gaussian Fields for Hair-Preserving   Talking Face Synthesis"></a>DEGSTalk: Decomposed Per-Embedding Gaussian Fields for Hair-Preserving   Talking Face Synthesis</h2><p><strong>Authors:Kaijun Deng, Dezhi Zheng, Jindong Xie, Jinbao Wang, Weicheng Xie, Linlin Shen, Siyang Song</strong></p>
<p>Accurately synthesizing talking face videos and capturing fine facial features for individuals with long hair presents a significant challenge. To tackle these challenges in existing methods, we propose a decomposed per-embedding Gaussian fields (DEGSTalk), a 3D Gaussian Splatting (3DGS)-based talking face synthesis method for generating realistic talking faces with long hairs. Our DEGSTalk employs Deformable Pre-Embedding Gaussian Fields, which dynamically adjust pre-embedding Gaussian primitives using implicit expression coefficients. This enables precise capture of dynamic facial regions and subtle expressions. Additionally, we propose a Dynamic Hair-Preserving Portrait Rendering technique to enhance the realism of long hair motions in the synthesized videos. Results show that DEGSTalk achieves improved realism and synthesis quality compared to existing approaches, particularly in handling complex facial dynamics and hair preservation. Our code will be publicly available at <a target="_blank" rel="noopener" href="https://github.com/CVI-SZU/DEGSTalk">https://github.com/CVI-SZU/DEGSTalk</a>. </p>
<blockquote>
<p>å‡†ç¡®åˆæˆè¯´è¯äººè„¸è§†é¢‘å¹¶ä¸ºé•¿å‘ä¸ªä½“æ•æ‰ç²¾ç»†é¢éƒ¨ç‰¹å¾æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹ç°æœ‰æ–¹æ³•ä¸­çš„è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ†è§£åµŒå…¥é«˜æ–¯åœºï¼ˆDEGSTalkï¼‰çš„æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰çš„è¯´è¯äººè„¸åˆæˆæ–¹æ³•ï¼Œç”¨äºç”Ÿæˆå…·æœ‰é•¿å‘çš„çœŸå®è¯´è¯äººè„¸ã€‚æˆ‘ä»¬çš„DEGSTalké‡‡ç”¨å¯å˜å½¢é¢„åµŒå…¥é«˜æ–¯åœºï¼Œä½¿ç”¨éšå¼è¡¨è¾¾å¼ç³»æ•°åŠ¨æ€è°ƒæ•´é¢„åµŒå…¥é«˜æ–¯åŸå§‹æ•°æ®ã€‚è¿™èƒ½å¤Ÿå®ç°åŠ¨æ€é¢éƒ¨åŒºåŸŸå’Œå¾®å¦™è¡¨æƒ…çš„ç²¾ç¡®æ•æ‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŠ¨æ€ä¿å‘è‚–åƒæ¸²æŸ“æŠ€æœ¯ï¼Œä»¥æé«˜åˆæˆè§†é¢‘ä¸­é•¿å‘è¿åŠ¨çš„çœŸå®æ„Ÿã€‚ç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDEGSTalkåœ¨å®ç°çœŸå®æ„Ÿå’Œåˆæˆè´¨é‡æ–¹é¢æœ‰æ‰€æé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤æ‚çš„é¢éƒ¨åŠ¨æ€å’Œä¿æŒå¤´å‘æ–¹é¢ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/CVI-SZU/DEGSTalk%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/CVI-SZU/DEGSTalkå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20148v1">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„è¯´è¯é¢å­”åˆæˆæ–¹æ³•ï¼Œåä¸ºåˆ†è§£åµŒå…¥é«˜æ–¯åœºï¼ˆDEGSTalkï¼‰ï¼Œç”¨äºç”Ÿæˆå…·æœ‰é•¿å‘çš„çœŸå®æ„Ÿè¯´è¯é¢å­”ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¯å˜å½¢é¢„åµŒå…¥é«˜æ–¯åœºï¼Œé€šè¿‡éšå¼è¡¨è¾¾å¼ç³»æ•°åŠ¨æ€è°ƒæ•´é¢„åµŒå…¥é«˜æ–¯åŸå§‹æ•°æ®ï¼Œèƒ½ç²¾ç¡®æ•æ‰é¢éƒ¨åŠ¨æ€åŒºåŸŸå’Œç»†å¾®è¡¨æƒ…ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§åŠ¨æ€ä¿å‘è‚–åƒæ¸²æŸ“æŠ€æœ¯ï¼Œæé«˜äº†åˆæˆè§†é¢‘ä¸­é•¿å‘è¿åŠ¨çš„çœŸå®æ„Ÿã€‚ç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒDEGSTalkåœ¨é¢éƒ¨åŠ¨æ€å’Œå¤´å‘ä¿æŠ¤æ–¹é¢æ›´å…·çœŸå®æ„Ÿå’Œåˆæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„è¯´è¯é¢å­”åˆæˆæ–¹æ³•DEGSTalkï¼Œç”¨äºç”Ÿæˆå…·æœ‰é•¿å‘çš„çœŸå®æ„Ÿè¯´è¯é¢å­”ã€‚</li>
<li>DEGSTalké‡‡ç”¨å¯å˜å½¢é¢„åµŒå…¥é«˜æ–¯åœºï¼Œèƒ½ç²¾ç¡®æ•æ‰é¢éƒ¨åŠ¨æ€åŒºåŸŸå’Œç»†å¾®è¡¨æƒ…ã€‚</li>
<li>DEGSTalké€šè¿‡åŠ¨æ€è°ƒæ•´é¢„åµŒå…¥é«˜æ–¯åŸå§‹æ•°æ®ï¼Œæé«˜äº†é¢éƒ¨åˆæˆçš„çœŸå®æ„Ÿå’Œè´¨é‡ã€‚</li>
<li>æå‡ºäº†åŠ¨æ€ä¿å‘è‚–åƒæ¸²æŸ“æŠ€æœ¯ï¼Œä»¥æ”¹è¿›åˆæˆè§†é¢‘ä¸­é•¿å‘çš„è¿åŠ¨è¡¨ç°ã€‚</li>
<li>DEGSTalkåœ¨å¤æ‚é¢éƒ¨åŠ¨æ€å’Œå¤´å‘ä¿æŠ¤æ–¹é¢è¾ƒç°æœ‰æ–¹æ³•æœ‰æ‰€æå‡ã€‚</li>
<li>DEGSTalkçš„ä»£ç å°†å…¬å¼€åœ¨GitHubä¸Šï¼Œæ–¹ä¾¿å…¶ä»–ç ”ç©¶è€…ä½¿ç”¨å’Œè¿›ä¸€æ­¥å¼€å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20148">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8d5ad1b16614d515de0bce55a11364e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-863725046b2a582fa0391bc8189b8b45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-497ba8081386bfa73c780d3a39dfd3fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d37163e114370b58863daea4991a28d4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DAS3R-Dynamics-Aware-Gaussian-Splatting-for-Static-Scene-Reconstruction"><a href="#DAS3R-Dynamics-Aware-Gaussian-Splatting-for-Static-Scene-Reconstruction" class="headerlink" title="DAS3R: Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction"></a>DAS3R: Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction</h2><p><strong>Authors:Kai Xu, Tze Ho Elden Tse, Jizong Peng, Angela Yao</strong></p>
<p>We propose a novel framework for scene decomposition and static background reconstruction from everyday videos. By integrating the trained motion masks and modeling the static scene as Gaussian splats with dynamics-aware optimization, our method achieves more accurate background reconstruction results than previous works. Our proposed method is termed DAS3R, an abbreviation for Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction. Compared to existing methods, DAS3R is more robust in complex motion scenarios, capable of handling videos where dynamic objects occupy a significant portion of the scene, and does not require camera pose inputs or point cloud data from SLAM-based methods. We compared DAS3R against recent distractor-free approaches on the DAVIS and Sintel datasets; DAS3R demonstrates enhanced performance and robustness with a margin of more than 2 dB in PSNR. The projectâ€™s webpage can be accessed via \url{<a target="_blank" rel="noopener" href="https://kai422.github.io/DAS3R/%7D">https://kai422.github.io/DAS3R/}</a> </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºä»æ—¥å¸¸è§†é¢‘ä¸­åˆ†è§£åœºæ™¯å¹¶é‡å»ºé™æ€èƒŒæ™¯ã€‚é€šè¿‡æ•´åˆè®­ç»ƒåçš„è¿åŠ¨æ©è†œï¼Œå¹¶å°†é™æ€åœºæ™¯å»ºæ¨¡ä¸ºå…·æœ‰åŠ¨æ€æ„ŸçŸ¥ä¼˜åŒ–çš„é«˜æ–¯æ–‘å—ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†æ¯”å…ˆå‰å·¥ä½œæ›´å‡†ç¡®çš„èƒŒæ™¯é‡å»ºç»“æœã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•è¢«ç§°ä¸ºDAS3Rï¼Œå³åŠ¨æ€æ„ŸçŸ¥é«˜æ–¯æ–‘å—æ³•ç”¨äºé™æ€åœºæ™¯é‡å»ºçš„ç®€ç§°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDAS3Råœ¨å¤æ‚çš„è¿åŠ¨åœºæ™¯ä¸­æ›´åŠ ç¨³å¥ï¼Œèƒ½å¤Ÿå¤„ç†åŠ¨æ€ç‰©ä½“å æ®åœºæ™¯å¾ˆå¤§æ¯”ä¾‹çš„è§†é¢‘ï¼Œå¹¶ä¸”ä¸éœ€è¦æ¥è‡ªåŸºäºSLAMæ–¹æ³•çš„ç›¸æœºå§¿æ€è¾“å…¥æˆ–ç‚¹äº‘æ•°æ®ã€‚æˆ‘ä»¬åœ¨DAVISå’ŒSintelæ•°æ®é›†ä¸Šå°†DAS3Rä¸æœ€è¿‘çš„æ— å¹²æ‰°ç‰©æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼›DAS3Råœ¨PSNRä¸Šçš„æ€§èƒ½æå‡å’Œç¨³å¥æ€§è¶…è¿‡2dBã€‚é¡¹ç›®ç½‘é¡µå¯é€šè¿‡\url{<a target="_blank" rel="noopener" href="https://kai422.github.io/DAS3R/%7D%E8%AE%BF%E9%97%AE%E3%80%82">https://kai422.github.io/DAS3R/}è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19584v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åœºæ™¯åˆ†è§£å’Œé™æ€èƒŒæ™¯é‡å»ºæ¡†æ¶ï¼Œä»æ—¥å¸¸è§†é¢‘ä¸­é€šè¿‡è®­ç»ƒè¿åŠ¨æ©è†œå¹¶æ¨¡æ‹Ÿé™æ€åœºæ™¯ä¸ºé«˜æ–¯æ–‘ç‚¹ï¼Œç»“åˆåŠ¨æ€æ„ŸçŸ¥ä¼˜åŒ–ï¼Œå®ç°äº†æ›´å‡†ç¡®çš„èƒŒæ™¯é‡å»ºç»“æœã€‚è¯¥æ–¹æ³•ç§°ä¸ºDAS3Rï¼Œå³åŠ¨æ€æ„ŸçŸ¥é«˜æ–¯æ–‘ç‚¹é™æ€åœºæ™¯é‡å»ºã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDAS3Råœ¨å¤æ‚è¿åŠ¨åœºæ™¯ä¸­æ›´ä¸ºç¨³å¥ï¼Œèƒ½å¤Ÿå¤„ç†åŠ¨æ€ç‰©ä½“å æ®åœºæ™¯å¤§éƒ¨åˆ†åŒºåŸŸçš„æƒ…å†µï¼Œå¹¶ä¸”ä¸éœ€è¦SLAMæ–¹æ³•çš„ç›¸æœºå§¿æ€è¾“å…¥æˆ–ç‚¹äº‘æ•°æ®ã€‚åœ¨DAVISå’ŒSintelæ•°æ®é›†ä¸Šä¸æœ€æ–°çš„æ— å¹²æ‰°ç‰©æ–¹æ³•å¯¹æ¯”ï¼ŒDAS3Rè¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½å’Œç¨³å¥æ€§ï¼ŒPSNRå€¼é«˜å‡ºè¶…è¿‡2dBã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åœºæ™¯åˆ†è§£å’Œé™æ€èƒŒæ™¯é‡å»ºæ¡†æ¶ã€‚</li>
<li>é€šè¿‡ç»“åˆè®­ç»ƒè¿åŠ¨æ©è†œå’Œæ¨¡æ‹Ÿé™æ€åœºæ™¯ä¸ºé«˜æ–¯æ–‘ç‚¹å®ç°æ›´å‡†ç¡®èƒŒæ™¯é‡å»ºã€‚</li>
<li>æ–¹æ³•åä¸ºDAS3Rï¼Œå³åŠ¨æ€æ„ŸçŸ¥é«˜æ–¯æ–‘ç‚¹é™æ€åœºæ™¯é‡å»ºã€‚</li>
<li>DAS3Råœ¨å¤æ‚è¿åŠ¨åœºæ™¯ä¸­è¡¨ç°ç¨³å¥ï¼Œå°¤å…¶èƒ½å¤„ç†åŠ¨æ€ç‰©ä½“å æ®å¤šçš„æƒ…å†µã€‚</li>
<li>DAS3Rä¸éœ€è¦SLAMæ–¹æ³•çš„ç›¸æœºå§¿æ€è¾“å…¥æˆ–ç‚¹äº‘æ•°æ®ã€‚</li>
<li>åœ¨DAVISå’ŒSintelæ•°æ®é›†ä¸Šï¼ŒDAS3Ræ€§èƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19584">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8a6a0372d02550ada4f55adb33445849.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-651f6a3a64f5138775a158cf1f5e130b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be5d676dbf5fa8432faf6a3038886f10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-533913db03d2f926fefa6a3203c01630.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-040756d6bb6be2cf45713dc68e319e28.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Dust-to-Tower-Coarse-to-Fine-Photo-Realistic-Scene-Reconstruction-from-Sparse-Uncalibrated-Images"><a href="#Dust-to-Tower-Coarse-to-Fine-Photo-Realistic-Scene-Reconstruction-from-Sparse-Uncalibrated-Images" class="headerlink" title="Dust to Tower: Coarse-to-Fine Photo-Realistic Scene Reconstruction from   Sparse Uncalibrated Images"></a>Dust to Tower: Coarse-to-Fine Photo-Realistic Scene Reconstruction from   Sparse Uncalibrated Images</h2><p><strong>Authors:Xudong Cai, Yongcai Wang, Zhaoxin Fan, Deng Haoran, Shuo Wang, Wanting Li, Deying Li, Lun Luo, Minhang Wang, Jintao Xu</strong></p>
<p>Photo-realistic scene reconstruction from sparse-view, uncalibrated images is highly required in practice. Although some successes have been made, existing methods are either Sparse-View but require accurate camera parameters (i.e., intrinsic and extrinsic), or SfM-free but need densely captured images. To combine the advantages of both methods while addressing their respective weaknesses, we propose Dust to Tower (D2T), an accurate and efficient coarse-to-fine framework to optimize 3DGS and image poses simultaneously from sparse and uncalibrated images. Our key idea is to first construct a coarse model efficiently and subsequently refine it using warped and inpainted images at novel viewpoints. To do this, we first introduce a Coarse Construction Module (CCM) which exploits a fast Multi-View Stereo model to initialize a 3D Gaussian Splatting (3DGS) and recover initial camera poses. To refine the 3D model at novel viewpoints, we propose a Confidence Aware Depth Alignment (CADA) module to refine the coarse depth maps by aligning their confident parts with estimated depths by a Mono-depth model. Then, a Warped Image-Guided Inpainting (WIGI) module is proposed to warp the training images to novel viewpoints by the refined depth maps, and inpainting is applied to fulfill the &#96;&#96;holesâ€ in the warped images caused by view-direction changes, providing high-quality supervision to further optimize the 3D model and the camera poses. Extensive experiments and ablation studies demonstrate the validity of D2T and its design choices, achieving state-of-the-art performance in both tasks of novel view synthesis and pose estimation while keeping high efficiency. Codes will be publicly available. </p>
<blockquote>
<p>ä»ç¨€ç–è§†è§’ã€æœªæ ¡å‡†çš„å›¾åƒä¸­è¿›è¡Œé€¼çœŸçš„åœºæ™¯é‡å»ºåœ¨å®é™…æ“ä½œä¸­æœ‰ç€å¾ˆé«˜çš„éœ€æ±‚ã€‚è™½ç„¶å·²æœ‰ä¸€äº›æˆåŠŸçš„å°è¯•ï¼Œä½†ç°æœ‰æ–¹æ³•è¦ä¹ˆæ˜¯ç¨€ç–è§†è§’ä½†éœ€è¦å‡†ç¡®çš„ç›¸æœºå‚æ•°ï¼ˆå³å†…éƒ¨å‚æ•°å’Œå¤–éƒ¨å‚æ•°ï¼‰ï¼Œè¦ä¹ˆæ˜¯æ— éœ€SfMä½†éœ€è¦å¯†é›†æ•æ‰çš„å›¾åƒã€‚ä¸ºäº†ç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹å¹¶å…‹æœå…¶å„è‡ªçš„ç¼ºç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†Dust to Towerï¼ˆD2Tï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç²¾ç¡®é«˜æ•ˆçš„ç”±ç²—åˆ°ç»†çš„æ¡†æ¶ï¼Œå¯ä»¥ä»ç¨€ç–å’Œæœªæ ¡å‡†çš„å›¾åƒä¸­åŒæ—¶ä¼˜åŒ–3DGSå’Œå›¾åƒå§¿æ€ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯å…ˆæœ‰æ•ˆåœ°æ„å»ºç²—æ¨¡å‹ï¼Œç„¶åä½¿ç”¨åœ¨æ–°è§†è§’ä¸‹ç”Ÿæˆçš„å¡«å……å›¾åƒå¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥äº†ä¸€ä¸ªç²—ç•¥æ„é€ æ¨¡å—ï¼ˆCCMï¼‰ï¼Œè¯¥æ¨¡å—åˆ©ç”¨å¿«é€Ÿçš„å¤šè§†å›¾ç«‹ä½“æ¨¡å‹æ¥åˆå§‹åŒ–ä¸‰ç»´é«˜æ–¯æº…ç‚¹ï¼ˆ3DGSï¼‰å¹¶æ¢å¤åˆå§‹ç›¸æœºå§¿æ€ã€‚ä¸ºäº†åœ¨æ–°è§†è§’ä¸Šä¼˜åŒ–ä¸‰ç»´æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç½®ä¿¡æ·±åº¦å¯¹é½ï¼ˆCADAï¼‰æ¨¡å—ï¼Œé€šè¿‡å°†ä¸€ä¸ªæ·±åº¦ä¼°è®¡æ¨¡å‹å¾—åˆ°çš„ç½®ä¿¡éƒ¨åˆ†çš„æ·±åº¦ä¸ç²—ç•¥æ·±åº¦å›¾å¯¹é½æ¥ä¼˜åŒ–ç²—ç•¥æ·±åº¦å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæ‰­æ›²å›¾åƒå¼•å¯¼çš„å¡«å……ï¼ˆWIGIï¼‰æ¨¡å—ï¼Œé€šè¿‡ä¼˜åŒ–åçš„æ·±åº¦å›¾å°†è®­ç»ƒå›¾åƒæ‰­æ›²åˆ°æ–°è§†è§’ï¼Œå¹¶åº”ç”¨å¡«å……æŠ€æœ¯æ¥å¡«è¡¥å› è§†ç‚¹æ–¹å‘å˜åŒ–è€Œåœ¨æ‰­æ›²å›¾åƒä¸­äº§ç”Ÿçš„â€œç©ºæ´â€ï¼Œä¸ºè¿›ä¸€æ­¥ä¼˜åŒ–ä¸‰ç»´æ¨¡å‹å’Œç›¸æœºå§¿æ€æä¾›é«˜è´¨é‡ç›‘ç£ã€‚å¤§é‡å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜äº†D2TåŠå…¶è®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼Œåœ¨æ–°å‹è§†å›¾åˆæˆå’Œå§¿æ€ä¼°è®¡ä»»åŠ¡ä¸­éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ•ˆç‡ã€‚ä»£ç å°†å…¬å¼€å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19518v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»ç¨€ç–è§†è§’çš„æœªæ ¡å‡†å›¾åƒè¿›è¡ŒçœŸå®åœºæ™¯é‡å»ºï¼Œæå‡ºä¸€ç§ç»“åˆç¨€ç–è§†è§’å’Œæ— ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰æ–¹æ³•ä¼˜åŠ¿çš„åŒæ—¶å…‹æœå…¶åŠ£åŠ¿çš„æ¡†æ¶â€”â€”Dust to Towerï¼ˆD2Tï¼‰ã€‚D2Tæ˜¯ä¸€ä¸ªç”±ç²—åˆ°ç»†çš„æ¡†æ¶ï¼Œèƒ½åŒæ—¶ä¼˜åŒ–3DGSå’Œå›¾åƒå§¿æ€ã€‚é¦–å…ˆé€šè¿‡ç²—å»ºæ¨¡å—ï¼ˆCCMï¼‰åˆ©ç”¨å¿«é€Ÿå¤šè§†è§’ç«‹ä½“æ¨¡å‹åˆå§‹åŒ–3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰å¹¶æ¢å¤åˆå§‹ç›¸æœºå§¿æ€ã€‚ç„¶åï¼Œé€šè¿‡ç½®ä¿¡æ·±åº¦å¯¹é½ï¼ˆCADAï¼‰æ¨¡å—åœ¨æ–°å‹è§†è§’ç»†åŒ–3Dæ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¿å½¢å›¾åƒå¼•å¯¼ä¿®å¤ï¼ˆWIGIï¼‰æ¨¡å—å°†è®­ç»ƒå›¾åƒå˜å½¢åˆ°æ–°å‹è§†è§’ï¼Œå¯¹å˜å½¢å›¾åƒä¸­çš„ç©ºæ´è¿›è¡Œä¿®å¤ï¼Œä¸ºè¿›ä¸€æ­¥ä¼˜åŒ–3Dæ¨¡å‹å’Œç›¸æœºå§¿æ€æä¾›é«˜è´¨é‡ç›‘ç£ã€‚å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜äº†D2TåŠå…¶è®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼Œåœ¨æ–°å‹è§†è§’åˆæˆå’Œå§¿æ€ä¼°è®¡ä»»åŠ¡ä¸Šè¾¾åˆ°ä¸€æµæ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆç‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§ç»“åˆç¨€ç–è§†è§’å’Œæ— ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰æ–¹æ³•ä¼˜åŠ¿çš„æ¡†æ¶â€”â€”Dust to Towerï¼ˆD2Tï¼‰ï¼Œç”¨äºä¼˜åŒ–3Dåœºæ™¯é‡å»ºå’Œå›¾åƒå§¿æ€ã€‚</li>
<li>å¼•å…¥Coarse Construction Moduleï¼ˆCCMï¼‰å¿«é€Ÿåˆå§‹åŒ–3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰å’Œæ¢å¤åˆå§‹ç›¸æœºå§¿æ€ã€‚</li>
<li>æå‡ºäº†Confidence Aware Depth Alignmentï¼ˆCADAï¼‰æ¨¡å—ï¼Œç”¨äºåœ¨æ–°å‹è§†è§’ç»†åŒ–3Dæ¨¡å‹ã€‚</li>
<li>å¼•å…¥äº†Warped Image-Guided Inpaintingï¼ˆWIGIï¼‰æ¨¡å—ï¼Œé€šè¿‡å˜å½¢å›¾åƒå’Œä¿®å¤æŠ€æœ¯æä¾›é«˜è´¨é‡ç›‘ç£ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–3Dæ¨¡å‹å’Œç›¸æœºå§¿æ€ã€‚</li>
<li>æ¡†æ¶å®ç°äº†é«˜æ•ˆä¸”é«˜æ€§èƒ½çš„ç¨€ç–è§†è§’å’Œæœªæ ¡å‡†å›¾åƒçš„çœŸå®åœºæ™¯é‡å»ºã€‚</li>
<li>é€šè¿‡å¹¿æ³›å®éªŒå’Œæ¶ˆèç ”ç©¶éªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œè®¾è®¡é€‰æ‹©çš„åˆç†æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19518">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-95a1ac34932deffd11ba0b96d014ba7c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9b931ea1a1965c029df47e009d0cd21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-783b4fdecc0e807c06d1bd93fcc02a3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f070998dac006546ef27d9a2abfe498.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Learning-Radiance-Fields-from-a-Single-Snapshot-Compressive-Image"><a href="#Learning-Radiance-Fields-from-a-Single-Snapshot-Compressive-Image" class="headerlink" title="Learning Radiance Fields from a Single Snapshot Compressive Image"></a>Learning Radiance Fields from a Single Snapshot Compressive Image</h2><p><strong>Authors:Yunhao Li, Xiang Liu, Xiaodong Wang, Xin Yuan, Peidong Liu</strong></p>
<p>In this paper, we explore the potential of Snapshot Compressive Imaging (SCI) technique for recovering the underlying 3D scene structure from a single temporal compressed image. SCI is a cost-effective method that enables the recording of high-dimensional data, such as hyperspectral or temporal information, into a single image using low-cost 2D imaging sensors. To achieve this, a series of specially designed 2D masks are usually employed, reducing storage and transmission requirements and offering potential privacy protection. Inspired by this, we take one step further to recover the encoded 3D scene information leveraging powerful 3D scene representation capabilities of neural radiance fields (NeRF). Specifically, we propose SCINeRF, in which we formulate the physical imaging process of SCI as part of the training of NeRF, allowing us to exploit its impressive performance in capturing complex scene structures. In addition, we further integrate the popular 3D Gaussian Splatting (3DGS) framework and propose SCISplat to improve 3D scene reconstruction quality and training&#x2F;rendering speed by explicitly optimizing point clouds into 3D Gaussian representations. To assess the effectiveness of our method, we conduct extensive evaluations using both synthetic data and real data captured by our SCI system. Experimental results demonstrate that our proposed approach surpasses the state-of-the-art methods in terms of image reconstruction and novel view synthesis. Moreover, our method also exhibits the ability to render high frame-rate multi-view consistent images in real time by leveraging SCI and the rendering capabilities of 3DGS. Codes will be available at: <a target="_blank" rel="noopener" href="https://github.com/WU-">https://github.com/WU-</a> CVGL&#x2F;SCISplat. </p>
<blockquote>
<p>æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†Snapshot Compressive Imagingï¼ˆSCIï¼‰æŠ€æœ¯ä»å•ä¸ªæ—¶é—´å‹ç¼©å›¾åƒä¸­æ¢å¤æ½œåœ¨çš„ä¸‰ç»´åœºæ™¯ç»“æ„çš„æ½œåŠ›ã€‚SCIæ˜¯ä¸€ç§ç»æµé«˜æ•ˆçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå°†é«˜ç»´æ•°æ®ï¼ˆå¦‚è¶…å…‰è°±æˆ–æ—¶é—´ä¿¡æ¯ï¼‰ä½¿ç”¨ä½æˆæœ¬çš„äºŒç»´æˆåƒä¼ æ„Ÿå™¨è®°å½•ä¸ºå•ä¸ªå›¾åƒã€‚ä¸ºå®ç°è¿™ä¸€ç‚¹ï¼Œé€šå¸¸é‡‡ç”¨ä¸€ç³»åˆ—ä¸“é—¨è®¾è®¡çš„äºŒç»´æ©è†œï¼Œä»¥é™ä½å­˜å‚¨å’Œä¼ è¾“è¦æ±‚ï¼Œå¹¶æä¾›æ½œåœ¨çš„éšç§ä¿æŠ¤ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥é‡‡å–ä¸€æ­¥ï¼Œåˆ©ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å¼ºå¤§ä¸‰ç»´åœºæ™¯è¡¨ç¤ºèƒ½åŠ›æ¥æ¢å¤ç¼–ç çš„ä¸‰ç»´åœºæ™¯ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºSCINeRFï¼Œæˆ‘ä»¬å°†SCIçš„ç‰©ç†æˆåƒè¿‡ç¨‹ä½œä¸ºNeRFè®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼Œä»è€Œèƒ½å¤Ÿåˆ©ç”¨å…¶æ•æ‰å¤æ‚åœºæ™¯ç»“æ„çš„ä»¤äººå°è±¡æ·±åˆ»çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥é›†æˆäº†æµè¡Œçš„ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ¡†æ¶ï¼Œå¹¶æå‡ºSCISplatï¼Œé€šè¿‡æ˜¾å¼ä¼˜åŒ–ç‚¹äº‘åˆ°ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºæ¥æé«˜ä¸‰ç»´åœºæ™¯é‡å»ºè´¨é‡ä»¥åŠè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆæˆæ•°æ®å’Œç”±æˆ‘ä»¬çš„SCIç³»ç»Ÿæ•è·çš„çœŸå®æ•°æ®è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å›¾åƒé‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆæ–¹é¢è¶…è¶Šäº†æœ€æ–°æŠ€æœ¯ã€‚è€Œä¸”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜å±•ç¤ºäº†åˆ©ç”¨SCIå’Œ3DGSçš„æ¸²æŸ“èƒ½åŠ›å®æ—¶å‘ˆç°é«˜å¸§ç‡ã€å¤šè§†è§’ä¸€è‡´å›¾åƒçš„èƒ½åŠ›ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/WU-CVGL/SCISplat%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/WU-CVGL/SCISplatä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19483v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†Snapshot Compressive Imagingï¼ˆSCIï¼‰æŠ€æœ¯åœ¨ä»å•ä¸ªæ—¶é—´å‹ç¼©å›¾åƒä¸­æ¢å¤æ½œåœ¨çš„3Dåœºæ™¯ç»“æ„æ–¹é¢çš„æ½œåŠ›ã€‚æ–‡ç« ä»‹ç»äº†SCIæŠ€æœ¯ç»“åˆç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä»¥åŠæµè¡Œçš„3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰æ¡†æ¶æ¥æ”¹è¿›3Dåœºæ™¯é‡å»ºè´¨é‡å’Œè®­ç»ƒ&#x2F;æ¸²æŸ“é€Ÿåº¦çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒé‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆæ–¹é¢è¶…è¿‡äº†ç°æœ‰æŠ€æœ¯ï¼Œå¹¶å±•ç¤ºäº†å®æ—¶æ¸²æŸ“é«˜å¸§ç‡å¤šè§†è§’ä¸€è‡´å›¾åƒçš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SCIæŠ€æœ¯èƒ½å¤Ÿä»å•ä¸ªæ—¶é—´å‹ç¼©å›¾åƒä¸­æ¢å¤å‡ºæ½œåœ¨çš„3Dåœºæ™¯ç»“æ„ã€‚</li>
<li>SCIæŠ€æœ¯åˆ©ç”¨ä¸€ç³»åˆ—ä¸“é—¨è®¾è®¡çš„2Dæ©è†œå°†é«˜ç»´æ•°æ®ç¼–ç æˆå•ä¸ªå›¾åƒï¼Œé™ä½å­˜å‚¨å’Œä¼ è¾“è¦æ±‚ï¼ŒåŒæ—¶æä¾›éšç§ä¿æŠ¤æ½œåŠ›ã€‚</li>
<li>SCINeRFæ–¹æ³•é€šè¿‡å°†SCIçš„ç‰©ç†æˆåƒè¿‡ç¨‹çº³å…¥NeRFçš„è®­ç»ƒï¼Œå……åˆ†åˆ©ç”¨å…¶æ•æ‰å¤æ‚åœºæ™¯ç»“æ„çš„èƒ½åŠ›ã€‚</li>
<li>SCISplatæ–¹æ³•æ•´åˆäº†SCINeRFå’Œæµè¡Œçš„3DGSæ¡†æ¶ï¼Œæé«˜äº†3Dåœºæ™¯é‡å»ºè´¨é‡å¹¶ä¼˜åŒ–äº†è®­ç»ƒ&#x2F;æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜SCISplatæ–¹æ³•åœ¨å›¾åƒé‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆæ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</li>
<li>SCISplatæ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨SCIæŠ€æœ¯å’Œ3DGSçš„æ¸²æŸ“èƒ½åŠ›å®ç°å®æ—¶çš„é«˜å¸§ç‡å¤šè§†è§’ä¸€è‡´å›¾åƒæ¸²æŸ“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-078e653f005f60dd8eddb8f7e540ad8a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0aa43ff602cb8e162d882386d84cb03d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-975272d5740b4d803f8a988529d6283f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="BeSplat-â€“-Gaussian-Splatting-from-a-Single-Blurry-Image-and-Event-Stream"><a href="#BeSplat-â€“-Gaussian-Splatting-from-a-Single-Blurry-Image-and-Event-Stream" class="headerlink" title="BeSplat â€“ Gaussian Splatting from a Single Blurry Image and Event   Stream"></a>BeSplat â€“ Gaussian Splatting from a Single Blurry Image and Event   Stream</h2><p><strong>Authors:Gopi Raju Matta, Reddypalli Trisha, Kaushik Mitra</strong></p>
<p>Novel view synthesis has been greatly enhanced by the development of radiance field methods. The introduction of 3D Gaussian Splatting (3DGS) has effectively addressed key challenges, such as long training times and slow rendering speeds, typically associated with Neural Radiance Fields (NeRF), while maintaining high-quality reconstructions. In this work (BeSplat), we demonstrate the recovery of sharp radiance field (Gaussian splats) from a single motion-blurred image and its corresponding event stream. Our method jointly learns the scene representation via Gaussian Splatting and recovers the camera motion through Bezier SE(3) formulation effectively, minimizing discrepancies between synthesized and real-world measurements of both blurry image and corresponding event stream. We evaluate our approach on both synthetic and real datasets, showcasing its ability to render view-consistent, sharp images from the learned radiance field and the estimated camera trajectory. To the best of our knowledge, ours is the first work to address this highly challenging ill-posed problem in a Gaussian Splatting framework with the effective incorporation of temporal information captured using the event stream. </p>
<blockquote>
<p>éšç€è¾å°„åœºæ–¹æ³•çš„å‘å±•ï¼Œæ–°å‹è§†å›¾åˆæˆæŠ€æœ¯å¾—åˆ°äº†æå¤§çš„å¢å¼ºã€‚3Dé«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„å¼•å…¥æœ‰æ•ˆè§£å†³äº†ä¸€äº›å…³é”®é—®é¢˜ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é€šå¸¸é¢ä¸´çš„è®­ç»ƒæ—¶é—´é•¿å’Œæ¸²æŸ“é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„é‡å»ºæ•ˆæœã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼ˆBeSplatï¼‰ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä»å•ä¸€çš„è¿åŠ¨æ¨¡ç³Šå›¾åƒå’Œå¯¹åº”çš„äº‹ä»¶æµä¸­æ¢å¤é”åŒ–çš„è¾å°„åœºï¼ˆé«˜æ–¯è´´å›¾ï¼‰çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡é«˜æ–¯è´´å›¾è”åˆå­¦ä¹ åœºæ™¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡è´å¡å°”SEï¼ˆ3ï¼‰å…¬å¼æœ‰æ•ˆæ¢å¤ç›¸æœºè¿åŠ¨ï¼Œä»è€Œæœ€å°åŒ–åˆæˆä¸æ¨¡ç³Šå›¾åƒå’Œå¯¹åº”äº‹ä»¶æµçš„çœŸå®ä¸–ç•Œæµ‹é‡ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†ä»å­¦ä¹ çš„è¾å°„åœºå’Œä¼°è®¡çš„ç›¸æœºè½¨è¿¹ä¸­å‘ˆç°ä¸€è‡´ã€æ¸…æ™°è§†å›¾å›¾åƒçš„èƒ½åŠ›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯åœ¨é«˜æ–¯è´´å›¾æ¡†æ¶ä¸‹è§£å†³è¿™ä¸€æå…·æŒ‘æˆ˜æ€§çš„ä¸é€‚å®šé—®é¢˜çš„é¦–æ¬¡å°è¯•ï¼Œæœ‰æ•ˆç»“åˆäº†ä½¿ç”¨äº‹ä»¶æµæ•è·çš„æ—¶é—´ä¿¡æ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19370v1">PDF</a> Accepted for publication at EVGEN2025, WACV-25 Workshop</p>
<p><strong>Summary</strong><br>     æ–°å‹è§†å›¾åˆæˆæŠ€æœ¯é€šè¿‡è¾å°„åœºæ–¹æ³•çš„å‘å±•å¾—åˆ°äº†æå¤§çš„æå‡ã€‚å¼•å…¥çš„3Dé«˜æ–¯è´´å›¾æŠ€æœ¯æœ‰æ•ˆåœ°è§£å†³äº†ä¸ç¥ç»è¾å°„åœºç›¸å…³çš„ä¸€äº›å…³é”®æŒ‘æˆ˜ï¼Œå¦‚è®­ç»ƒæ—¶é—´é•¿å’Œæ¸²æŸ“é€Ÿåº¦æ…¢ç­‰é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„é‡å»ºæ•ˆæœã€‚æœ¬ç ”ç©¶é€šè¿‡é«˜æ–¯è´´å›¾æ¢å¤è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„æ¸…æ™°è¾å°„åœºï¼Œå¹¶é€šè¿‡è´å¡å°”SEï¼ˆ3ï¼‰å…¬å¼æœ‰æ•ˆæ¢å¤ç›¸æœºè¿åŠ¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•è”åˆå­¦ä¹ åœºæ™¯çš„é«˜æ–¯è´´å›¾è¡¨ç¤ºï¼Œå¹¶é€šè¿‡æœ€å°åŒ–åˆæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å·®å¼‚ä»¥åŠäº‹ä»¶æµçš„æµ‹é‡è¯¯å·®ï¼Œä»è€Œæœ‰æ•ˆåœ°ä¼°è®¡ç›¸æœºè½¨è¿¹ã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶ä»å­¦ä¹ åˆ°çš„è¾å°„åœºå’Œä¼°è®¡çš„ç›¸æœºè½¨è¿¹ä¸­æ¸²æŸ“å‡ºä¸€è‡´ã€æ¸…æ™°å›¾åƒçš„èƒ½åŠ›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯é¦–ä¸ªåœ¨åŒ…å«äº‹ä»¶æµæ•æ‰çš„æ—¶é—´ä¿¡æ¯çš„æƒ…å†µä¸‹è§£å†³æ­¤é«˜æ–¯è´´å›¾æ¡†æ¶ä¸­æå…·æŒ‘æˆ˜æ€§çš„åé—®é¢˜çš„å·¥ä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼•å…¥çš„3Dé«˜æ–¯è´´å›¾æŠ€æœ¯è§£å†³äº†ç¥ç»è¾å°„åœºåœ¨è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢çš„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼Œå¯ä»¥ä»å•ä¸ªè¿åŠ¨æ¨¡ç³Šå›¾åƒå’Œå…¶å¯¹åº”çš„äº‹ä»¶æµä¸­æ¢å¤æ¸…æ™°çš„è¾å°„åœºã€‚</li>
<li>é€šè¿‡è´å¡å°”SE(3)å…¬å¼ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°æ¢å¤ç›¸æœºè¿åŠ¨è½¨è¿¹ã€‚</li>
<li>æ–¹æ³•è”åˆå­¦ä¹ åœºæ™¯çš„é«˜æ–¯è´´å›¾è¡¨ç¤ºå¹¶æœ€å°åŒ–åˆæˆä¸çœŸå®å›¾åƒä¹‹é—´çš„å·®å¼‚ä»¥åŠäº‹ä»¶æµçš„æµ‹é‡è¯¯å·®ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚</li>
<li>æ­¤æŠ€æœ¯å¯¹äºä»æ¨¡ç³Šçš„å›¾åƒä¸­é‡å»ºæ¸…æ™°çš„è§†å›¾å…·æœ‰æ½œåŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19370">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dab0d13209460a513c971d77a5e93e0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6935f2f426b133e610bbdd5ce6245dfb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21b9e3e3453ea7e8aa8e5bc0f84b2ee4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de024f1fe0d234244b550d2c09cffce8.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Generating-Editable-Head-Avatars-with-3D-Gaussian-GANs"><a href="#Generating-Editable-Head-Avatars-with-3D-Gaussian-GANs" class="headerlink" title="Generating Editable Head Avatars with 3D Gaussian GANs"></a>Generating Editable Head Avatars with 3D Gaussian GANs</h2><p><strong>Authors:Guohao Li, Hongyu Yang, Yifang Men, Di Huang, Weixin Li, Ruijie Yang, Yunhong Wang</strong></p>
<p>Generating animatable and editable 3D head avatars is essential for various applications in computer vision and graphics. Traditional 3D-aware generative adversarial networks (GANs), often using implicit fields like Neural Radiance Fields (NeRF), achieve photorealistic and view-consistent 3D head synthesis. However, these methods face limitations in deformation flexibility and editability, hindering the creation of lifelike and easily modifiable 3D heads. We propose a novel approach that enhances the editability and animation control of 3D head avatars by incorporating 3D Gaussian Splatting (3DGS) as an explicit 3D representation. This method enables easier illumination control and improved editability. Central to our approach is the Editable Gaussian Head (EG-Head) model, which combines a 3D Morphable Model (3DMM) with texture maps, allowing precise expression control and flexible texture editing for accurate animation while preserving identity. To capture complex non-facial geometries like hair, we use an auxiliary set of 3DGS and tri-plane features. Extensive experiments demonstrate that our approach delivers high-quality 3D-aware synthesis with state-of-the-art controllability. Our code and models are available at <a target="_blank" rel="noopener" href="https://github.com/liguohao96/EGG3D">https://github.com/liguohao96/EGG3D</a>. </p>
<blockquote>
<p>ç”Ÿæˆå¯åŠ¨ç”»åŒ–å’Œå¯ç¼–è¾‘çš„3Då¤´åƒå¯¹äºè®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦çš„å„ç§åº”ç”¨è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„åŸºäº3Dçš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ç»å¸¸ä½¿ç”¨å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä¹‹ç±»çš„éšå¼åœºï¼Œä»¥å®ç°é€¼çœŸçš„å’Œè§†è§’ä¸€è‡´çš„3Då¤´éƒ¨åˆæˆã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨å˜å½¢çµæ´»æ€§å’Œå¯ç¼–è¾‘æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œé˜»ç¢äº†é€¼çœŸä¸”æ˜“äºä¿®æ”¹çš„3Då¤´éƒ¨çš„åˆ›å»ºã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ä½œä¸ºæ˜¾å¼3Dè¡¨ç¤ºçš„æ–°æ–¹æ³•ï¼Œä»¥æé«˜3Då¤´åƒçš„å¯ç¼–è¾‘æ€§å’ŒåŠ¨ç”»æ§åˆ¶ã€‚è¿™ç§æ–¹æ³•ä½¿ç…§æ˜æ§åˆ¶æ›´åŠ å®¹æ˜“ï¼Œå¹¶ä¸”æé«˜äº†å¯ç¼–è¾‘æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯å¯ç¼–è¾‘é«˜æ–¯å¤´ï¼ˆEG-Headï¼‰æ¨¡å‹ï¼Œå®ƒå°†3Då½¢æ€æ¨¡å‹ï¼ˆ3DMMï¼‰ä¸çº¹ç†å›¾ç›¸ç»“åˆï¼Œå…è®¸ç²¾ç¡®çš„è¡¨æƒ…æ§åˆ¶ä»¥åŠçµæ´»çš„çº¹ç†ç¼–è¾‘æ¥å®ç°å‡†ç¡®åŠ¨ç”»çš„åŒæ—¶ä¿æŒèº«ä»½ç‰¹å¾ã€‚ä¸ºäº†æ•æ‰å¤´å‘ç­‰å¤æ‚çš„éé¢éƒ¨å‡ ä½•å½¢çŠ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨è¾…åŠ©çš„3DGSå’Œä¸‰è§’å¹³é¢ç‰¹å¾é›†ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†å…·æœ‰å…ˆè¿›å¯æ§æ€§çš„é«˜è´¨é‡3Dæ„ŸçŸ¥åˆæˆã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/liguohao96/EGG3D%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/liguohao96/EGG3Dè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19149v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç”Ÿæˆå¯åŠ¨ç”»å’Œå¯ç¼–è¾‘çš„3Då¤´åƒçš„é‡è¦æ€§åŠå…¶åœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„å¤šç§åº”ç”¨ã€‚é’ˆå¯¹ç°æœ‰æŠ€æœ¯å˜å½¢çµæ´»æ€§å’Œå¯ç¼–è¾‘æ€§çš„é™åˆ¶ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆ3Dé«˜æ–¯å–·å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰ä½œä¸ºæ˜¾å¼ä¸‰ç»´è¡¨ç¤ºçš„æ–°æ–¹æ³•ï¼Œå¢å¼ºäº†ä¸‰ç»´å¤´åƒçš„å¯ç¼–è¾‘æ€§å’ŒåŠ¨ç”»æ§åˆ¶åŠŸèƒ½ã€‚é€šè¿‡åˆ›å»ºEditable Gaussian Headï¼ˆEG-Headï¼‰æ¨¡å‹ï¼Œå®ç°äº†ç²¾å‡†çš„è¡¨æƒ…æ§åˆ¶å’Œçµæ´»çš„çº¹ç†ç¼–è¾‘ï¼Œå¯ä»¥åœ¨ä¿æŒäººç‰©èº«ä»½çš„åŒæ—¶è¿›è¡Œç²¾ç¡®åŠ¨ç”»æ“ä½œã€‚æ­¤æ–¹æ³•è¿˜èƒ½æ•æ‰å¤æ‚çš„éé¢éƒ¨å‡ ä½•å½¢çŠ¶å¦‚å¤´å‘ç­‰ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰é«˜è´¨é‡çš„ä¸‰ç»´æ„ŸçŸ¥åˆæˆå’Œå…ˆè¿›çš„å¯æ§æ€§ã€‚ä»£ç å’Œæ¨¡å‹å·²å…¬å¼€å‘å¸ƒåœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç”Ÿæˆå¯åŠ¨ç”»å’Œå¯ç¼–è¾‘çš„3Då¤´åƒåœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨éšå¼åœºï¼ˆå¦‚NeRFï¼‰å®ç°çœŸå®æ„Ÿçš„ä¸‰ç»´å¤´åˆæˆï¼Œä½†å˜å½¢çµæ´»æ€§å’Œå¯ç¼–è¾‘æ€§å—é™ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç»“åˆ3Dé«˜æ–¯å–·å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„æ–°æ–¹æ³•ï¼Œå¢å¼ºä¸‰ç»´å¤´åƒçš„å¯ç¼–è¾‘æ€§å’ŒåŠ¨ç”»æ§åˆ¶åŠŸèƒ½ã€‚</li>
<li>é€šè¿‡åˆ›å»ºEditable Gaussian Headï¼ˆEG-Headï¼‰æ¨¡å‹ï¼Œå®ç°äº†ç²¾å‡†çš„è¡¨æƒ…æ§åˆ¶å’Œçµæ´»çš„çº¹ç†ç¼–è¾‘ã€‚</li>
<li>æ­¤æ–¹æ³•å…è®¸æ•æ‰å¤æ‚çš„éé¢éƒ¨å‡ ä½•å½¢çŠ¶å¦‚å¤´å‘ç­‰ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰é«˜è´¨é‡çš„ä¸‰ç»´æ„ŸçŸ¥åˆæˆå’Œå…ˆè¿›çš„å¯æ§æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19149">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3892a306159a58dca2515cad8e802c6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-519b6cc1bd7cf2c02053876e12ac88ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cad7b562387e86a3f6562767bcf1c692.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="CLIP-GS-Unifying-Vision-Language-Representation-with-3D-Gaussian-Splatting"><a href="#CLIP-GS-Unifying-Vision-Language-Representation-with-3D-Gaussian-Splatting" class="headerlink" title="CLIP-GS: Unifying Vision-Language Representation with 3D Gaussian   Splatting"></a>CLIP-GS: Unifying Vision-Language Representation with 3D Gaussian   Splatting</h2><p><strong>Authors:Siyu Jiao, Haoye Dong, Yuyang Yin, Zequn Jie, Yinlong Qian, Yao Zhao, Humphrey Shi, Yunchao Wei</strong></p>
<p>Recent works in 3D multimodal learning have made remarkable progress. However, typically 3D multimodal models are only capable of handling point clouds. Compared to the emerging 3D representation technique, 3D Gaussian Splatting (3DGS), the spatially sparse point cloud cannot depict the texture information of 3D objects, resulting in inferior reconstruction capabilities. This limitation constrains the potential of point cloud-based 3D multimodal representation learning. In this paper, we present CLIP-GS, a novel multimodal representation learning framework grounded in 3DGS. We introduce the GS Tokenizer to generate serialized gaussian tokens, which are then processed through transformer layers pre-initialized with weights from point cloud models, resulting in the 3DGS embeddings. CLIP-GS leverages contrastive loss between 3DGS and the visual-text embeddings of CLIP, and we introduce an image voting loss to guide the directionality and convergence of gradient optimization. Furthermore, we develop an efficient way to generate triplets of 3DGS, images, and text, facilitating CLIP-GS in learning unified multimodal representations. Leveraging the well-aligned multimodal representations, CLIP-GS demonstrates versatility and outperforms point cloud-based models on various 3D tasks, including multimodal retrieval, zero-shot, and few-shot classification. </p>
<blockquote>
<p>è¿‘æœŸï¼Œåœ¨ä¸‰ç»´å¤šæ¨¡æ€å­¦ä¹ é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå…¸å‹çš„ä¸‰ç»´å¤šæ¨¡æ€æ¨¡å‹é€šå¸¸åªèƒ½å¤„ç†ç‚¹äº‘æ•°æ®ã€‚ä¸æ–°å…´çš„ä¸‰ç»´è¡¨ç¤ºæŠ€æœ¯ç›¸æ¯”ï¼Œå³ä¸‰ç»´é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆ3DGSï¼‰ï¼Œç©ºé—´ç¨€ç–ç‚¹äº‘æ— æ³•æè¿°ä¸‰ç»´å¯¹è±¡çš„çº¹ç†ä¿¡æ¯ï¼Œå¯¼è‡´é‡å»ºèƒ½åŠ›è¾ƒå·®ã€‚è¿™ä¸€å±€é™æ€§åˆ¶çº¦äº†åŸºäºç‚¹äº‘çš„3Då¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ çš„æ½œåŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯è´´å›¾ï¼ˆCLIP-GSï¼‰çš„å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ æ–°æ¡†æ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†GSæ ‡è®°å™¨ç”Ÿæˆåºåˆ—åŒ–é«˜æ–¯æ ‡è®°ï¼Œè¿™äº›æ ‡è®°ç»è¿‡é¢„å…ˆç”¨ç‚¹äº‘æ¨¡å‹æƒé‡åˆå§‹åŒ–çš„å˜æ¢å±‚å¤„ç†ï¼Œç”Ÿæˆä¸‰ç»´é«˜æ–¯è´´å›¾åµŒå…¥ã€‚CLIP-GSåˆ©ç”¨ä¸‰ç»´é«˜æ–¯è´´å›¾å’ŒCLIPçš„è§†è§‰æ–‡æœ¬åµŒå…¥ä¹‹é—´çš„å¯¹æ¯”æŸå¤±ã€‚åŒæ—¶æˆ‘ä»¬å¼•å…¥äº†å›¾åƒæŠ•ç¥¨æŸå¤±æ¥æŒ‡å¯¼æ¢¯åº¦ä¼˜åŒ–çš„æ–¹å‘æ€§å’Œæ”¶æ•›æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥ç”Ÿæˆä¸‰ç»´é«˜æ–¯è´´å›¾ã€å›¾åƒå’Œæ–‡æœ¬çš„ä¸‰å…ƒç»„ï¼Œæœ‰åŠ©äºCLIP-GSå­¦ä¹ ç»Ÿä¸€çš„å¤šæ¨¡æ€è¡¨ç¤ºã€‚åˆ©ç”¨å¯¹é½è‰¯å¥½çš„å¤šæ¨¡æ€è¡¨ç¤ºï¼ŒCLIP-GSè¡¨ç°å‡ºé€šç”¨æ€§ï¼Œåœ¨å„ç§ä¸‰ç»´ä»»åŠ¡ä¸Šä¼˜äºåŸºäºç‚¹äº‘çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€æ£€ç´¢ã€é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19142v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäº3DGSçš„æ–°å‹å¤šæ¨¡æ€å­¦ä¹ æ¡†æ¶CLIP-GSçš„ç ”ç©¶ä»‹ç»äº†ä½¿ç”¨GS Tokenizerç”Ÿæˆé«˜æ–¯åºåˆ—åŒ–ä»¤ç‰Œï¼Œå¹¶ç»“åˆç‚¹äº‘æ¨¡å‹é¢„åˆå§‹åŒ–æƒé‡è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆ3DGSåµŒå…¥ã€‚CLIP-GSåˆ©ç”¨å¯¹æ¯”æŸå¤±åœ¨3DGSå’ŒCLIPçš„è§†è§‰æ–‡æœ¬åµŒå…¥ä¹‹é—´è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶å¼•å…¥å›¾åƒæŠ•ç¥¨æŸå¤±æŒ‡å¯¼æ¢¯åº¦ä¼˜åŒ–çš„æ–¹å‘æ€§ã€‚é€šè¿‡ç”Ÿæˆé«˜æ•ˆçš„ä¸‰å…ƒç»„æ•°æ®ï¼ŒCLIP-GSå¯ä»¥å­¦ä¹ ç»Ÿä¸€çš„å¤šæ¨¡æ€è¡¨ç¤ºå¹¶è¶…è¶Šç‚¹äº‘æ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰3Då¤šæ¨¡æ€æ¨¡å‹ä¸»è¦å¤„ç†ç‚¹äº‘æ•°æ®ï¼Œå­˜åœ¨çº¹ç†ä¿¡æ¯æè¿°ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>3DGSæŠ€æœ¯èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¡¨ç¤º3Då¯¹è±¡çš„çº¹ç†ä¿¡æ¯ã€‚</li>
<li>CLIP-GSæ˜¯ä¸€ä¸ªåŸºäº3DGSçš„æ–°å‹å¤šæ¨¡æ€å­¦ä¹ æ¡†æ¶ï¼Œå¼•å…¥GS Tokenizerç”Ÿæˆé«˜æ–¯åºåˆ—åŒ–ä»¤ç‰Œã€‚</li>
<li>CLIP-GSåˆ©ç”¨å¯¹æ¯”æŸå¤±å’Œå›¾åƒæŠ•ç¥¨æŸå¤±è¿›è¡Œä¼˜åŒ–ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>CLIP-GSèƒ½å¤Ÿç”Ÿæˆä¸‰å…ƒç»„æ•°æ®ï¼Œä¿ƒè¿›å¤šæ¨¡æ€ç»Ÿä¸€è¡¨ç¤ºçš„å­¦ä¹ ã€‚</li>
<li>CLIP-GSåœ¨å¤šç§3Dä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€æ£€ç´¢ã€é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19142">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dcbc138552113253a621cb50d857496d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d55fb43103e5b6f0ffd9fbf5a090d464.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f564696445487fc2b998cee8e8e25454.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-003a21e2cc14126fa6e89a6254a0e537.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ebab259c5516d6d9a6c0cc4040baad7.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="MVS-GS-High-Quality-3D-Gaussian-Splatting-Mapping-via-Online-Multi-View-Stereo"><a href="#MVS-GS-High-Quality-3D-Gaussian-Splatting-Mapping-via-Online-Multi-View-Stereo" class="headerlink" title="MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View   Stereo"></a>MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View   Stereo</h2><p><strong>Authors:Byeonggwon Lee, Junkyu Park, Khang Truong Giang, Sungho Jo, Soohwan Song</strong></p>
<p>This study addresses the challenge of online 3D model generation for neural rendering using an RGB image stream. Previous research has tackled this issue by incorporating Neural Radiance Fields (NeRF) or 3D Gaussian Splatting (3DGS) as scene representations within dense SLAM methods. However, most studies focus primarily on estimating coarse 3D scenes rather than achieving detailed reconstructions. Moreover, depth estimation based solely on images is often ambiguous, resulting in low-quality 3D models that lead to inaccurate renderings. To overcome these limitations, we propose a novel framework for high-quality 3DGS modeling that leverages an online multi-view stereo (MVS) approach. Our method estimates MVS depth using sequential frames from a local time window and applies comprehensive depth refinement techniques to filter out outliers, enabling accurate initialization of Gaussians in 3DGS. Furthermore, we introduce a parallelized backend module that optimizes the 3DGS model efficiently, ensuring timely updates with each new keyframe. Experimental results demonstrate that our method outperforms state-of-the-art dense SLAM methods, particularly excelling in challenging outdoor environments. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä½¿ç”¨RGBå›¾åƒæµè¿›è¡Œç¥ç»æ¸²æŸ“çš„åœ¨çº¿3Dæ¨¡å‹ç”ŸæˆæŒ‘æˆ˜ã€‚å…ˆå‰çš„ç ”ç©¶å·²ç»é€šè¿‡ç»“åˆç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ä½œä¸ºå¯†é›†SLAMæ–¹æ³•å†…çš„åœºæ™¯è¡¨ç¤ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç ”ç©¶ä¸»è¦ä¾§é‡äºä¼°è®¡ç²—ç³™çš„3Dåœºæ™¯ï¼Œè€Œéå®ç°è¯¦ç»†çš„é‡å»ºã€‚æ­¤å¤–ï¼Œä»…åŸºäºå›¾åƒè¿›è¡Œæ·±åº¦ä¼°è®¡é€šå¸¸å…·æœ‰æ¨¡ç³Šæ€§ï¼Œå¯¼è‡´è´¨é‡ä½ä¸‹çš„3Dæ¨¡å‹ï¼Œä»è€Œå¯¼è‡´æ¸²æŸ“ä¸å‡†ç¡®ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åœ¨çº¿å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•çš„é«˜è´¨é‡3DGSå»ºæ¨¡æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨å±€éƒ¨æ—¶é—´çª—å£å†…çš„è¿ç»­å¸§ä¼°è®¡MVSæ·±åº¦ï¼Œå¹¶åº”ç”¨å…¨é¢çš„æ·±åº¦ç»†åŒ–æŠ€æœ¯æ¥è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œå®ç°å¯¹3DGSä¸­çš„é«˜æ–¯åˆ†å¸ƒçš„å‡†ç¡®åˆå§‹åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªå¹¶è¡ŒåŒ–çš„åç«¯æ¨¡å—ï¼Œä»¥é«˜æ•ˆä¼˜åŒ–3DGSæ¨¡å‹ï¼Œç¡®ä¿æ¯ä¸ªæ–°å…³é”®å¸§éƒ½èƒ½åŠæ—¶å¾—åˆ°æ›´æ–°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å¤–ç¯å¢ƒä¸­è¡¨ç°ä¼˜äºæœ€å…ˆè¿›çš„å¯†é›†SLAMæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19130v1">PDF</a> 7 pages, 6 figures, submitted to IEEE ICRA 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåœ¨çº¿å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰çš„åœ¨çº¿ä¸‰ç»´æ¨¡å‹ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é«˜æ•ˆçš„å¹¶è¡Œåç«¯æ¨¡å—å’Œæ·±åº¦ç»†åŒ–æŠ€æœ¯ï¼Œå®ç°é«˜è´¨é‡çš„ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰å»ºæ¨¡ã€‚è¯¥æ–¹æ³•å…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä¸»è¦ä¼°è®¡ç²—ç³™ä¸‰ç»´åœºæ™¯çš„å±€é™æ€§ï¼Œæé«˜äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä»è€Œç”Ÿæˆæ›´ç²¾ç¡®çš„ä¸‰ç»´æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶èƒŒæ™¯ï¼šé’ˆå¯¹åœ¨çº¿ä¸‰ç»´æ¨¡å‹ç”Ÿæˆçš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨RGBå›¾åƒæµè¿›è¡Œç¥ç»æ¸²æŸ“æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>ä¸»è¦é—®é¢˜ï¼šæ·±åº¦ä¼°è®¡ä»…åŸºäºå›¾åƒæ—¶å­˜åœ¨æ­§ä¹‰ï¼Œå¯¼è‡´ä½è´¨é‡çš„ä¸‰ç»´æ¨¡å‹å’Œä¸å‡†ç¡®æ¸²æŸ“ã€‚</li>
<li>ç ”ç©¶æ–¹æ³•ï¼šæå‡ºä¸€ç§æ–°å‹æ¡†æ¶è¿›è¡Œé«˜è´¨é‡çš„ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰å»ºæ¨¡ï¼Œåˆ©ç”¨åœ¨çº¿å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•è¿›è¡Œæ·±åº¦ä¼°è®¡ã€‚é€šè¿‡æ·±åº¦ç»†åŒ–æŠ€æœ¯æé«˜æ·±åº¦ä¼°è®¡å‡†ç¡®æ€§ï¼Œå¹¶åˆ©ç”¨å¹¶è¡Œåç«¯æ¨¡å—ä¼˜åŒ–æ¨¡å‹ã€‚</li>
<li>æŠ€æœ¯ç‰¹ç‚¹ï¼šä½¿ç”¨å±€éƒ¨æ—¶é—´çª—å£å†…çš„è¿ç»­å¸§è¿›è¡Œæ·±åº¦ä¼°è®¡ï¼Œå¹¶é‡‡ç”¨æ·±åº¦ç»†åŒ–æŠ€æœ¯è¿‡æ»¤å¼‚å¸¸å€¼ã€‚å¼•å…¥å¹¶è¡Œåç«¯æ¨¡å—å®ç°é«˜æ•ˆä¼˜åŒ–å’Œå®æ—¶æ›´æ–°ã€‚</li>
<li>å®éªŒç»“æœï¼šè¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„å¯†é›†SLAMæ–¹æ³•ï¼Œå°¤å…¶åœ¨æˆ·å¤–ç¯å¢ƒä¸­è¡¨ç°çªå‡ºã€‚</li>
<li>çªç ´ç‚¹ï¼šçªç ´äº†ä¼ ç»Ÿæ–¹æ³•ä¸»è¦ä¼°è®¡ç²—ç³™ä¸‰ç»´åœºæ™¯çš„å±€é™æ€§ï¼Œæé«˜äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œç”Ÿæˆæ›´ç²¾ç¡®çš„ä¸‰ç»´æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19130">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e3972536eeef7a870fd4b6f2e82c4eff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e26773a7c0b29e8469003d8fd2c8b0d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e2488254f795e6af4e6e6e3a7288a8b2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1bc1c8b72af53bd6298553df981f5fac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a64f64cd37fbee41aeaab3cc2f4d545a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8636ce2cc6fb43899937bfaa1789ea4a.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="WeatherGS-3D-Scene-Reconstruction-in-Adverse-Weather-Conditions-via-Gaussian-Splatting"><a href="#WeatherGS-3D-Scene-Reconstruction-in-Adverse-Weather-Conditions-via-Gaussian-Splatting" class="headerlink" title="WeatherGS: 3D Scene Reconstruction in Adverse Weather Conditions via   Gaussian Splatting"></a>WeatherGS: 3D Scene Reconstruction in Adverse Weather Conditions via   Gaussian Splatting</h2><p><strong>Authors:Chenghao Qian, Yuhu Guo, Wenjing Li, Gustav Markkula</strong></p>
<p>3D Gaussian Splatting (3DGS) has gained significant attention for 3D scene reconstruction, but still suffers from complex outdoor environments, especially under adverse weather. This is because 3DGS treats the artifacts caused by adverse weather as part of the scene and will directly reconstruct them, largely reducing the clarity of the reconstructed scene. To address this challenge, we propose WeatherGS, a 3DGS-based framework for reconstructing clear scenes from multi-view images under different weather conditions. Specifically, we explicitly categorize the multi-weather artifacts into the dense particles and lens occlusions that have very different characters, in which the former are caused by snowflakes and raindrops in the air, and the latter are raised by the precipitation on the camera lens. In light of this, we propose a dense-to-sparse preprocess strategy, which sequentially removes the dense particles by an Atmospheric Effect Filter (AEF) and then extracts the relatively sparse occlusion masks with a Lens Effect Detector (LED). Finally, we train a set of 3D Gaussians by the processed images and generated masks for excluding occluded areas, and accurately recover the underlying clear scene by Gaussian splatting. We conduct a diverse and challenging benchmark to facilitate the evaluation of 3D reconstruction under complex weather scenarios. Extensive experiments on this benchmark demonstrate that our WeatherGS consistently produces high-quality, clean scenes across various weather scenarios, outperforming existing state-of-the-art methods. See project page:<a target="_blank" rel="noopener" href="https://jumponthemoon.github.io/weather-gs">https://jumponthemoon.github.io/weather-gs</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰åœ¨3Dåœºæ™¯é‡å»ºä¸­å—åˆ°äº†å¹¿æ³›å…³æ³¨ï¼Œä½†ä»é¢ä¸´å¤æ‚å®¤å¤–ç¯å¢ƒçš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶åŠ£å¤©æ°”ä¸‹ã€‚è¿™æ˜¯å› ä¸º3DGSå°†æ¶åŠ£å¤©æ°”å¼•èµ·çš„ä¼ªå½±è§†ä¸ºåœºæ™¯çš„ä¸€éƒ¨åˆ†å¹¶ç›´æ¥é‡å»ºå®ƒä»¬ï¼Œå¤§å¤§é™ä½äº†é‡å»ºåœºæ™¯çš„æ¸…æ™°åº¦ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†WeatherGSï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº3DGSçš„æ¡†æ¶ï¼Œå¯ä»¥ä»ä¸åŒå¤©æ°”æ¡ä»¶ä¸‹çš„å¤šè§†è§’å›¾åƒé‡å»ºæ¸…æ™°çš„åœºæ™¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ˜ç¡®åœ°å°†å¤šå¤©æ°”ä¼ªå½±åˆ†ä¸ºå¯†é›†ç²’å­å’Œé•œå¤´é®æŒ¡ç‰©ä¸¤ç±»ï¼Œè¿™ä¸¤ç±»å…·æœ‰æˆªç„¶ä¸åŒçš„ç‰¹å¾ï¼Œå‰è€…æ˜¯ç”±ç©ºæ°”ä¸­çš„é›ªèŠ±å’Œé›¨æ»´å¼•èµ·çš„ï¼Œåè€…æ˜¯ç”±ç›¸æœºé•œå¤´ä¸Šçš„æ²‰æ·€ç‰©å¼•èµ·çš„ã€‚é‰´äºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±å¯†é›†åˆ°ç¨€ç–çš„é¢„å¤„ç†ç­–ç•¥ï¼Œä¾æ¬¡é€šè¿‡å¤§æ°”æ•ˆåº”æ»¤æ³¢å™¨ï¼ˆAEFï¼‰å»é™¤å¯†é›†ç²’å­ï¼Œç„¶åä½¿ç”¨é•œå¤´æ•ˆåº”æ£€æµ‹å™¨ï¼ˆLEDï¼‰æå–ç›¸å¯¹ç¨€ç–çš„é®æŒ¡æ©è†œã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨å¤„ç†è¿‡çš„å›¾åƒå’Œç”Ÿæˆçš„æ©è†œè®­ç»ƒä¸€ç»„3Dé«˜æ–¯ï¼Œæ’é™¤é®æŒ¡åŒºåŸŸï¼Œå¹¶é€šè¿‡é«˜æ–¯èåˆå‡†ç¡®æ¢å¤æ½œåœ¨çš„æ¸…æ™°åœºæ™¯ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹å¤šæ ·ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥ä¿ƒè¿›åœ¨å¤æ‚å¤©æ°”åœºæ™¯ä¸‹3Dé‡å»ºçš„è¯„ä¼°ã€‚åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„WeatherGSåœ¨å„ç§å¤©æ°”åœºæ™¯ä¸‹å§‹ç»ˆäº§ç”Ÿé«˜è´¨é‡çš„æ¸…æ™°åœºæ™¯ï¼Œä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¯¦æƒ…è§é¡¹ç›®ç½‘é¡µï¼š<a target="_blank" rel="noopener" href="https://jumponthemoon.github.io/weather-gs%E3%80%82">https://jumponthemoon.github.io/weather-gsã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18862v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†åœ¨å¤æ‚çš„æˆ·å¤–ç¯å¢ƒä¸‹ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹ï¼Œä¸‰ç»´é«˜æ–¯Splattingï¼ˆ3DGSï¼‰åœ¨ä¸‰ç»´åœºæ™¯é‡å»ºä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†WeatherGSæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäº3DGSï¼Œå¯ä»ä¸åŒå¤©æ°”æ¡ä»¶ä¸‹çš„å¤šè§†è§’å›¾åƒé‡å»ºæ¸…æ™°åœºæ™¯ã€‚é€šè¿‡æ˜ç¡®åŒºåˆ†å¤šå¤©æ°”é€ æˆçš„ä¼ªå½±ï¼Œå¦‚å¯†é›†ç²’å­å’Œé•œå¤´é®æŒ¡ç‰©ï¼Œæå‡ºä¸€ç§ç”±å¯†åˆ°ç–çš„é¢„å¤„ç†ç­–ç•¥ï¼Œä¾æ¬¡å»é™¤å¯†é›†ç²’å­å¹¶æå–ç›¸å¯¹ç¨€ç–çš„é®æŒ¡ç‰©æ©è†œã€‚ç»è¿‡å¤„ç†çš„å›¾åƒå’Œç”Ÿæˆçš„æ©è†œç”¨äºè®­ç»ƒä¸€ç»„ä¸‰ç»´é«˜æ–¯æ¨¡å‹ï¼Œæ’é™¤é®æŒ¡åŒºåŸŸï¼Œå¹¶é€šè¿‡é«˜æ–¯Splattingå‡†ç¡®æ¢å¤åº•å±‚æ¸…æ™°åœºæ™¯ã€‚åœ¨å¤æ‚çš„å¤©æ°”åœºæ™¯é‡å»ºæ–¹é¢è¿›è¡Œäº†å¤šæ ·æ€§å’ŒæŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ï¼Œå®éªŒè¡¨æ˜ï¼ŒWeatherGSåœ¨å„ç§å¤©æ°”åœºæ™¯ä¸‹å§‹ç»ˆäº§ç”Ÿé«˜è´¨é‡ã€æ¸…æ™°çš„åœºæ™¯ï¼Œä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¶åŠ£å¤©æ°”ç»™ä¸‰ç»´åœºæ™¯é‡å»ºå¸¦æ¥æŒ‘æˆ˜ï¼Œç°æœ‰çš„ä¸‰ç»´é«˜æ–¯Splattingï¼ˆ3DGSï¼‰æ–¹æ³•æ˜“å—åˆ°è¿™äº›å¤æ‚ç¯å¢ƒå› ç´ çš„å½±å“ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªåä¸ºWeatherGSçš„æ–°æ¡†æ¶æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥æ¡†æ¶åŸºäº3DGSæŠ€æœ¯ï¼Œèƒ½å¤Ÿä»ä¸åŒå¤©æ°”æ¡ä»¶ä¸‹çš„å¤šè§†è§’å›¾åƒé‡å»ºæ¸…æ™°åœºæ™¯ã€‚</li>
<li>WeatherGSé€šè¿‡æ˜ç¡®åŒºåˆ†å¤šç§å¤©æ°”é€ æˆçš„ä¼ªå½±ï¼ˆå¦‚å¯†é›†ç²’å­å’Œé•œå¤´é®æŒ¡ï¼‰ï¼Œé‡‡ç”¨ç”±å¯†åˆ°ç–çš„é¢„å¤„ç†ç­–ç•¥è¿›è¡Œå¤„ç†ã€‚</li>
<li>è¯¥ç­–ç•¥åŒ…æ‹¬ä½¿ç”¨å¤§æ°”æ•ˆåº”è¿‡æ»¤å™¨ï¼ˆAEFï¼‰å»é™¤å¯†é›†ç²’å­ï¼Œç„¶åä½¿ç”¨é•œå¤´æ•ˆåº”æ£€æµ‹å™¨ï¼ˆLEDï¼‰æå–ç¨€ç–é®æŒ¡æ©è†œã€‚</li>
<li>åˆ©ç”¨å¤„ç†åçš„å›¾åƒå’Œç”Ÿæˆçš„æ©è†œè®­ç»ƒä¸€ç»„ä¸‰ç»´é«˜æ–¯æ¨¡å‹ï¼Œæ’é™¤é®æŒ¡åŒºåŸŸåé‡å»ºæ¸…æ™°åœºæ™¯ã€‚</li>
<li>åœ¨å¤æ‚å¤©æ°”åœºæ™¯é‡å»ºæ–¹é¢è¿›è¡Œäº†å…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œè¯æ˜WeatherGSåœ¨å„ç§å¤©æ°”æ¡ä»¶ä¸‹éƒ½èƒ½äº§ç”Ÿé«˜è´¨é‡çš„ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18862">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a1c52bcac9b6104a93b4415f43bc9bb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3d541db189f8e4cd4a79d14f286b53d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1cd63eae81cd2418c81a01d654ed683b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a04dff2b23ecd7230c7ba9aa526750f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53aabffb4d97ca520a6c5e580f337d4f.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Topology-Aware-3D-Gaussian-Splatting-Leveraging-Persistent-Homology-for-Optimized-Structural-Integrity"><a href="#Topology-Aware-3D-Gaussian-Splatting-Leveraging-Persistent-Homology-for-Optimized-Structural-Integrity" class="headerlink" title="Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for   Optimized Structural Integrity"></a>Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for   Optimized Structural Integrity</h2><p><strong>Authors:Tianqi Shen, Shaohua Liu, Jiaqi Feng, Ziye Ma, Ning An</strong></p>
<p>Gaussian Splatting (GS) has emerged as a crucial technique for representing discrete volumetric radiance fields. It leverages unique parametrization to mitigate computational demands in scene optimization. This work introduces Topology-Aware 3D Gaussian Splatting (Topology-GS), which addresses two key limitations in current approaches: compromised pixel-level structural integrity due to incomplete initial geometric coverage, and inadequate feature-level integrity from insufficient topological constraints during optimization. To overcome these limitations, Topology-GS incorporates a novel interpolation strategy, Local Persistent Voronoi Interpolation (LPVI), and a topology-focused regularization term based on persistent barcodes, named PersLoss. LPVI utilizes persistent homology to guide adaptive interpolation, enhancing point coverage in low-curvature areas while preserving topological structure. PersLoss aligns the visual perceptual similarity of rendered images with ground truth by constraining distances between their topological features. Comprehensive experiments on three novel-view synthesis benchmarks demonstrate that Topology-GS outperforms existing methods in terms of PSNR, SSIM, and LPIPS metrics, while maintaining efficient memory usage. This study pioneers the integration of topology with 3D-GS, laying the groundwork for future research in this area. </p>
<blockquote>
<p>é«˜æ–¯é‡‡æ ·ï¼ˆGSï¼‰å·²ç»æˆä¸ºè¡¨ç¤ºç¦»æ•£ä½“ç§¯è¾å°„åœºçš„å…³é”®æŠ€æœ¯ã€‚å®ƒåˆ©ç”¨ç‹¬ç‰¹çš„å‚æ•°åŒ–æ–¹æ³•ï¼Œä»¥å‡è½»åœºæ™¯ä¼˜åŒ–ä¸­çš„è®¡ç®—éœ€æ±‚ã€‚æœ¬æ–‡ä»‹ç»äº†æ‹“æ‰‘æ„ŸçŸ¥ä¸‰ç»´é«˜æ–¯é‡‡æ ·ï¼ˆTopology-GSï¼‰ï¼Œè§£å†³äº†å½“å‰æ–¹æ³•çš„ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šç”±äºåˆå§‹å‡ ä½•è¦†ç›–ä¸å®Œæ•´è€ŒæŸå®³åƒç´ çº§ç»“æ„å®Œæ•´æ€§ï¼Œä»¥åŠåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç”±äºæ‹“æ‰‘çº¦æŸä¸è¶³è€Œå¯¼è‡´ç‰¹å¾çº§å®Œæ•´æ€§ä¸è¶³ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼ŒTopology-GSèå…¥äº†ä¸€ç§æ–°å‹æ’å€¼ç­–ç•¥â€”â€”å±€éƒ¨æŒä¹…Voronoiæ’å€¼ï¼ˆLPVIï¼‰å’Œä¸€ç§åŸºäºæŒä¹…æ¡ç çš„ä¸“æ³¨äºæ‹“æ‰‘çš„æ­£åˆ™åŒ–é¡¹ï¼Œç§°ä¸ºPersLossã€‚LPVIåˆ©ç”¨æŒä¹…åŒæºæ€§æ¥å¼•å¯¼è‡ªé€‚åº”æ’å€¼ï¼Œåœ¨ä½æ›²ç‡åŒºåŸŸå¢å¼ºç‚¹è¦†ç›–çš„åŒæ—¶ä¿æŒæ‹“æ‰‘ç»“æ„ã€‚PersLossé€šè¿‡çº¦æŸæ¸²æŸ“å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´æ‹“æ‰‘ç‰¹å¾çš„è·ç¦»ï¼Œä½¿æ¸²æŸ“å›¾åƒçš„è§†è§‰æ„ŸçŸ¥ç›¸ä¼¼æ€§ç¬¦åˆçœŸå®æƒ…å†µã€‚åœ¨ä¸‰ä¸ªæ–°å‹è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œåœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡æ–¹é¢ï¼ŒTopology-GSä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒå†…å­˜ä½¿ç”¨æ•ˆç‡ã€‚æœ¬ç ”ç©¶é¦–åˆ›äº†æ‹“æ‰‘ä¸3D-GSçš„é›†æˆï¼Œä¸ºè¿™ä¸€é¢†åŸŸçš„æœªæ¥ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16619v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é«˜æ–¯å¹³é“ºï¼ˆGSï¼‰åœ¨è¡¨ç¤ºç¦»æ•£ä½“ç§¯è¾å°„åœºä¸­çš„é‡è¦ä½œç”¨ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„æŠ€æœ¯â€”â€”æ‹“æ‰‘æ„ŸçŸ¥ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼ˆTopology-GSï¼‰ã€‚è¯¥æŠ€æœ¯è§£å†³äº†å½“å‰æ–¹æ³•åœ¨åœºæ™¯ä¼˜åŒ–ä¸­é¢ä¸´çš„ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šå› åˆå§‹å‡ ä½•è¦†ç›–ä¸å®Œå…¨å¯¼è‡´çš„åƒç´ çº§ç»“æ„å®Œæ•´æ€§å—æŸï¼Œä»¥åŠä¼˜åŒ–è¿‡ç¨‹ä¸­å› æ‹“æ‰‘çº¦æŸä¸è¶³å¯¼è‡´çš„ç‰¹å¾çº§å®Œæ•´æ€§ä¸è¶³ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼ŒTopology-GSå¼•å…¥äº†å±€éƒ¨æŒä¹…Voronoiæ’å€¼ï¼ˆLPVIï¼‰å’ŒåŸºäºæŒä¹…æ¡å½¢ç çš„æ‹“æ‰‘é‡ç‚¹æ­£åˆ™åŒ–é¡¹PersLossã€‚LPVIåˆ©ç”¨æŒä¹…åŒæºæ€§æŒ‡å¯¼è‡ªé€‚åº”æ’å€¼ï¼Œå¢å¼ºä½æ›²ç‡åŒºåŸŸçš„ç‚¹è¦†ç›–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒæ‹“æ‰‘ç»“æ„ã€‚PersLossé€šè¿‡çº¦æŸæ¸²æŸ“å›¾åƒä¸åœ°é¢çœŸå®å›¾åƒä¹‹é—´æ‹“æ‰‘ç‰¹å¾çš„è·ç¦»ï¼Œä½¿ä¸¤è€…åœ¨è§†è§‰æ„ŸçŸ¥ä¸Šæ›´åŠ ç›¸ä¼¼ã€‚åœ¨ä¸‰ä¸ªæ–°è§†è§’åˆæˆåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTopology-GSåœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„å†…å­˜ä½¿ç”¨ã€‚è¯¥ç ”ç©¶å¼€åˆ›æ€§åœ°å®ç°äº†æ‹“æ‰‘ä¸3D-GSçš„é›†æˆï¼Œä¸ºæœªæ¥è¯¥é¢†åŸŸçš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ–¯å¹³é“ºï¼ˆGSï¼‰æ˜¯è¡¨ç¤ºç¦»æ•£ä½“ç§¯è¾å°„åœºçš„é‡è¦æŠ€æœ¯ã€‚</li>
<li>æ‹“æ‰‘æ„ŸçŸ¥ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼ˆTopology-GSï¼‰è§£å†³äº†å› åˆå§‹å‡ ä½•è¦†ç›–ä¸å®Œå…¨å’Œæ‹“æ‰‘çº¦æŸä¸è¶³å¯¼è‡´çš„é—®é¢˜ã€‚</li>
<li>Topology-GSå¼•å…¥å±€éƒ¨æŒä¹…Voronoiæ’å€¼ï¼ˆLPVIï¼‰å’ŒåŸºäºæŒä¹…æ¡å½¢ç çš„æ‹“æ‰‘é‡ç‚¹æ­£åˆ™åŒ–é¡¹PersLossã€‚</li>
<li>LPVIåˆ©ç”¨æŒä¹…åŒæºæ€§å¢å¼ºä½æ›²ç‡åŒºåŸŸçš„ç‚¹è¦†ç›–ï¼Œå¹¶ä¿æŒæ‹“æ‰‘ç»“æ„ã€‚</li>
<li>PersLossçº¦æŸæ¸²æŸ“å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´æ‹“æ‰‘ç‰¹å¾çš„è·ç¦»ï¼Œæå‡è§†è§‰æ„ŸçŸ¥ç›¸ä¼¼æ€§ã€‚</li>
<li>Topology-GSåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-445f3b03329cecfa7b015462a85fa1c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f48338fb3a9c2f9825df52c4f60f7b7f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6336e82444c90f3e423b235b9468df0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c178336a046238006a6201ba039a2029.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5126ec456f8faccef17946a7462a38f6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3898879becbe4124485b60552e6a2c9e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b78ef0ec11cd26ba13bcf4e26a8bf85e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f99d376e15640d0f41139b9352e1f5f0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="LiHi-GS-LiDAR-Supervised-Gaussian-Splatting-for-Highway-Driving-Scene-Reconstruction"><a href="#LiHi-GS-LiDAR-Supervised-Gaussian-Splatting-for-Highway-Driving-Scene-Reconstruction" class="headerlink" title="LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene   Reconstruction"></a>LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene   Reconstruction</h2><p><strong>Authors:Pou-Chun Kung, Xianling Zhang, Katherine A. Skinner, Nikita Jaipuria</strong></p>
<p>Photorealistic 3D scene reconstruction plays an important role in autonomous driving, enabling the generation of novel data from existing datasets to simulate safety-critical scenarios and expand training data without additional acquisition costs. Gaussian Splatting (GS) facilitates real-time, photorealistic rendering with an explicit 3D Gaussian representation of the scene, providing faster processing and more intuitive scene editing than the implicit Neural Radiance Fields (NeRFs). While extensive GS research has yielded promising advancements in autonomous driving applications, they overlook two critical aspects: First, existing methods mainly focus on low-speed and feature-rich urban scenes and ignore the fact that highway scenarios play a significant role in autonomous driving. Second, while LiDARs are commonplace in autonomous driving platforms, existing methods learn primarily from images and use LiDAR only for initial estimates or without precise sensor modeling, thus missing out on leveraging the rich depth information LiDAR offers and limiting the ability to synthesize LiDAR data. In this paper, we propose a novel GS method for dynamic scene synthesis and editing with improved scene reconstruction through LiDAR supervision and support for LiDAR rendering. Unlike prior works that are tested mostly on urban datasets, to the best of our knowledge, we are the first to focus on the more challenging and highly relevant highway scenes for autonomous driving, with sparse sensor views and monotone backgrounds. Visit our project page at: <a target="_blank" rel="noopener" href="https://umautobots.github.io/lihi_gs">https://umautobots.github.io/lihi_gs</a> </p>
<blockquote>
<p>çœŸå®æ„Ÿä¸‰ç»´åœºæ™¯é‡å»ºåœ¨è‡ªåŠ¨é©¾é©¶ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚å®ƒèƒ½å¤Ÿä»ç°æœ‰æ•°æ®é›†ä¸­ç”Ÿæˆæ–°æ•°æ®ï¼Œæ¨¡æ‹Ÿå®‰å…¨å…³é”®åœºæ™¯ï¼Œå¹¶åœ¨æ— éœ€é¢å¤–é‡‡é›†æˆæœ¬çš„æƒ…å†µä¸‹æ‰©å±•è®­ç»ƒæ•°æ®ã€‚é«˜æ–¯è´´ç‰‡æŠ€æœ¯ï¼ˆGSï¼‰èƒ½å¤Ÿåˆ©ç”¨åœºæ™¯çš„æ˜¾å¼ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºè¿›è¡Œå®æ—¶ã€çœŸå®æ„Ÿæ¸²æŸ“ï¼Œä¸éšå¼ç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰ç›¸æ¯”ï¼Œæä¾›äº†æ›´å¿«çš„å¤„ç†å’Œæ›´ç›´è§‚çš„åœºæ™¯ç¼–è¾‘åŠŸèƒ½ã€‚å°½ç®¡å…³äºé«˜æ–¯è´´ç‰‡æŠ€æœ¯çš„å¹¿æ³›ç ”ç©¶åœ¨è‡ªåŠ¨é©¾é©¶åº”ç”¨ä¸­å–å¾—äº†æœ‰å‰æ™¯çš„è¿›å±•ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šé¦–å…ˆï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½é€Ÿå’Œç‰¹å¾ä¸°å¯Œçš„åŸå¸‚åœºæ™¯ä¸Šï¼Œå¿½è§†äº†é«˜é€Ÿå…¬è·¯åœºæ™¯åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„é‡è¦ä½œç”¨ã€‚å…¶æ¬¡ï¼Œè™½ç„¶æ¿€å…‰é›·è¾¾åœ¨è‡ªåŠ¨é©¾é©¶å¹³å°ä¸­å¾ˆå¸¸è§ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦ä»å›¾åƒä¸­å­¦ä¹ ï¼Œä»…å°†æ¿€å…‰é›·è¾¾ç”¨äºåˆæ­¥ä¼°è®¡æˆ–ä¸è¿›è¡Œç²¾ç¡®çš„ä¼ æ„Ÿå™¨å»ºæ¨¡ï¼Œå› æ­¤é”™è¿‡äº†åˆ©ç”¨æ¿€å…‰é›·è¾¾æä¾›çš„ä¸°å¯Œæ·±åº¦ä¿¡æ¯çš„æœºä¼šï¼Œå¹¶é™åˆ¶äº†åˆæˆæ¿€å…‰é›·è¾¾æ•°æ®çš„èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯è´´ç‰‡æŠ€æœ¯ï¼Œç”¨äºåŠ¨æ€åœºæ™¯åˆæˆå’Œç¼–è¾‘ã€‚é€šè¿‡æ¿€å…‰é›·è¾¾ç›‘ç£å’Œæ¿€å…‰é›·è¾¾æ¸²æŸ“æ”¯æŒï¼Œæ”¹è¿›äº†åœºæ™¯é‡å»ºã€‚ä¸ä¸»è¦åŸºäºåŸå¸‚æ•°æ®é›†è¿›è¡Œæµ‹è¯•çš„å…ˆå‰å·¥ä½œä¸åŒï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªä¸“æ³¨äºæ›´å…·æŒ‘æˆ˜æ€§å’Œé«˜åº¦ç›¸å…³çš„é«˜é€Ÿå…¬è·¯åœºæ™¯çš„è‡ªåŠ¨é©¾é©¶ç ”ç©¶ï¼Œå…·æœ‰ç¨€ç–çš„ä¼ æ„Ÿå™¨è§†è§’å’Œå•è‰²èƒŒæ™¯ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://umautobots.github.io/lihi_gs">https://umautobots.github.io/lihi_gs</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15447v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸä¸­ï¼ŒåŸºäºé«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆGSï¼‰çš„å…‰ç…§çœŸå®ä¸‰ç»´åœºæ™¯é‡å»ºçš„é‡è¦æ€§ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°å‹çš„é«˜æ–¯è´´å›¾æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€åœºæ™¯åˆæˆå’Œç¼–è¾‘ï¼Œæ”¹è¿›äº†åœºæ™¯é‡å»ºè¿‡ç¨‹ï¼Œå¹¶é€šè¿‡æ¿€å…‰é›·è¾¾ç›‘ç£ä¸æ¸²æŸ“æ”¯æŒæé«˜é‡å»ºç²¾åº¦å’Œåˆ©ç”¨æ¿€å…‰é›·è¾¾ä¸°å¯Œçš„æ·±åº¦ä¿¡æ¯ã€‚è¯¥æ–¹æ³•çš„é‡ç‚¹æ˜¯åœ¨é«˜é€Ÿå…¬è·¯åœºæ™¯ä¸Šï¼Œè¿™æ˜¯ç›®å‰è‡ªåŠ¨é©¾é©¶é¢†åŸŸä¸­æ›´å…·æŒ‘æˆ˜æ€§å’Œé«˜åº¦ç›¸å…³æ€§çš„åœºæ™¯ã€‚é€šè¿‡æ¿€å…‰é›·è¾¾çš„æ·±åº¦ä¿¡æ¯ï¼Œæé«˜åœºæ™¯é‡å»ºçš„å‡†ç¡®æ€§å’Œé€¼çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…‰ç…§çœŸå®çš„ä¸‰ç»´åœºæ™¯é‡å»ºå¯¹äºæ¨¡æ‹Ÿå®‰å…¨å…³é”®çš„è‡ªåŠ¨é©¾é©¶åœºæ™¯å’Œæé«˜è®­ç»ƒæ•°æ®è´¨é‡è‡³å…³é‡è¦ã€‚</li>
<li>é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆGSï¼‰å…·æœ‰å®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œèƒ½æ˜ç¡®è¡¨ç¤ºä¸‰ç»´åœºæ™¯çš„é«˜æ–¯åˆ†å¸ƒï¼Œç›¸è¾ƒäºéšå¼ç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰ï¼Œå…·æœ‰æ›´å¿«çš„å¤„ç†å’Œæ›´ç›´è§‚çš„ç¼–è¾‘ä¼˜åŠ¿ã€‚</li>
<li>å½“å‰GSç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä½é€Ÿåº¦å’Œç‰¹å¾ä¸°å¯Œçš„åŸå¸‚åœºæ™¯ä¸Šï¼Œå¿½ç•¥äº†é«˜é€Ÿå…¬è·¯åœºæ™¯åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>æ¿€å…‰é›·è¾¾åœ¨è‡ªåŠ¨é©¾é©¶å¹³å°ä¸­å·²æ™®åŠï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å›¾åƒå­¦ä¹ ï¼Œå¹¶æœªå……åˆ†åˆ©ç”¨æ¿€å…‰é›·è¾¾æä¾›çš„ä¸°å¯Œæ·±åº¦ä¿¡æ¯ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹GSæ–¹æ³•ï¼Œç»“åˆäº†æ¿€å…‰é›·è¾¾çš„ç›‘ç£ä¸æ¸²æŸ“æ”¯æŒï¼Œç”¨äºåŠ¨æ€åœºæ™¯åˆæˆå’Œç¼–è¾‘ã€‚</li>
<li>ä¸ä¸»è¦æµ‹è¯•åŸå¸‚æ•°æ®é›†çš„å‰æœŸå·¥ä½œä¸åŒï¼Œæœ¬æ–‡ä¸“æ³¨äºæ›´å…·æŒ‘æˆ˜æ€§å’Œé«˜åº¦ç›¸å…³æ€§çš„é«˜é€Ÿå…¬è·¯åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15447">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-84726a72b31a702cc0e7e50f20e6b797.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b914278b4ab4040b4fff83b0f97ae386.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c03668d4232ef3060541db9668ec81c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc807d9bc5dfd097b8376314e642a7ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45b042aa74d3b92a52cf1a4ba431f5f6.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Grid4D-4D-Decomposed-Hash-Encoding-for-High-Fidelity-Dynamic-Gaussian-Splatting"><a href="#Grid4D-4D-Decomposed-Hash-Encoding-for-High-Fidelity-Dynamic-Gaussian-Splatting" class="headerlink" title="Grid4D: 4D Decomposed Hash Encoding for High-Fidelity Dynamic Gaussian   Splatting"></a>Grid4D: 4D Decomposed Hash Encoding for High-Fidelity Dynamic Gaussian   Splatting</h2><p><strong>Authors:Jiawei Xu, Zexin Fan, Jian Yang, Jin Xie</strong></p>
<p>Recently, Gaussian splatting has received more and more attention in the field of static scene rendering. Due to the low computational overhead and inherent flexibility of explicit representations, plane-based explicit methods are popular ways to predict deformations for Gaussian-based dynamic scene rendering models. However, plane-based methods rely on the inappropriate low-rank assumption and excessively decompose the space-time 4D encoding, resulting in overmuch feature overlap and unsatisfactory rendering quality. To tackle these problems, we propose Grid4D, a dynamic scene rendering model based on Gaussian splatting and employing a novel explicit encoding method for the 4D input through the hash encoding. Different from plane-based explicit representations, we decompose the 4D encoding into one spatial and three temporal 3D hash encodings without the low-rank assumption. Additionally, we design a novel attention module that generates the attention scores in a directional range to aggregate the spatial and temporal features. The directional attention enables Grid4D to more accurately fit the diverse deformations across distinct scene components based on the spatial encoded features. Moreover, to mitigate the inherent lack of smoothness in explicit representation methods, we introduce a smooth regularization term that keeps our model from the chaos of deformation prediction. Our experiments demonstrate that Grid4D significantly outperforms the state-of-the-art models in visual quality and rendering speed. </p>
<blockquote>
<p>è¿‘æœŸï¼Œé«˜æ–¯æ‹¼è´´ï¼ˆGaussian Splattingï¼‰åœ¨é™æ€åœºæ™¯æ¸²æŸ“é¢†åŸŸå¾—åˆ°äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç”±äºæ˜¾å¼è¡¨ç¤ºæ³•å…·æœ‰è¾ƒä½çš„è®¡ç®—å¼€é”€å’Œå›ºæœ‰çš„çµæ´»æ€§ï¼ŒåŸºäºå¹³é¢çš„æ˜¾å¼æ–¹æ³•æˆä¸ºé¢„æµ‹åŸºäºé«˜æ–¯çš„åŠ¨åŠ›å­¦åœºæ™¯æ¸²æŸ“æ¨¡å‹çš„å˜å½¢çš„æµè¡Œæ–¹å¼ã€‚ç„¶è€Œï¼ŒåŸºäºå¹³é¢çš„æ–¹æ³•ä¾èµ–äºä¸é€‚å½“çš„ä½ç§©å‡è®¾ï¼Œè¿‡åº¦åˆ†è§£äº†æ—¶ç©º4Dç¼–ç ï¼Œå¯¼è‡´ç‰¹å¾é‡å è¿‡å¤šå’Œæ¸²æŸ“è´¨é‡ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Grid4Dï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé«˜æ–¯æ‹¼è´´çš„åŠ¨åŠ›å­¦åœºæ™¯æ¸²æŸ“æ¨¡å‹ï¼Œé‡‡ç”¨ä¸€ç§æ–°çš„æ˜¾å¼ç¼–ç æ–¹æ³•å¯¹4Dè¾“å…¥è¿›è¡Œå“ˆå¸Œç¼–ç ã€‚ä¸åŒäºåŸºäºå¹³é¢çš„æ˜¾å¼è¡¨ç¤ºæ–¹æ³•ï¼Œæˆ‘ä»¬å°†4Dç¼–ç åˆ†è§£æˆä¸€ä¸ªç©ºé—´ç¼–ç å’Œä¸‰ä¸ªä¸´æ—¶3Då“ˆå¸Œç¼–ç ï¼Œæ— éœ€ä½ç§©å‡è®¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§æ–°å‹æ³¨æ„åŠ›æ¨¡å—ï¼Œè¯¥æ¨¡å—åœ¨å®šå‘èŒƒå›´å†…ç”Ÿæˆæ³¨æ„åŠ›åˆ†æ•°ï¼Œä»¥èšåˆç©ºé—´å’Œæ—¶é—´ç‰¹å¾ã€‚å®šå‘æ³¨æ„åŠ›ä½¿Grid4Dèƒ½å¤ŸåŸºäºç©ºé—´ç¼–ç ç‰¹å¾æ›´å‡†ç¡®åœ°æ‹Ÿåˆä¸åŒåœºæ™¯ç»„ä»¶çš„å¤šæ ·å˜å½¢ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¼“è§£æ˜¾å¼è¡¨ç¤ºæ–¹æ³•å›ºæœ‰çš„å¹³æ»‘æ€§ä¸è¶³ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€é¡¹å¹³æ»‘æ­£åˆ™åŒ–é¡¹ï¼Œä½¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿé¿å…å˜å½¢é¢„æµ‹çš„æ··ä¹±ã€‚å®éªŒè¡¨æ˜ï¼ŒGrid4Dåœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ä¸Šå‡æ˜¾è‘—ä¼˜äºæœ€æ–°æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.20815v3">PDF</a> Accepted by NeurIPS 2024</p>
<p><strong>Summary</strong><br>åŸºäºé«˜æ–¯è´´å›¾çš„åŠ¨æ€åœºæ™¯æ¸²æŸ“ä¸­ï¼ŒGrid4Dæ¨¡å‹é‡‡ç”¨æ–°å‹æ˜¾å¼ç¼–ç æ–¹æ³•ï¼Œé€šè¿‡å“ˆå¸Œç¼–ç è¿›è¡Œ4Dè¾“å…¥ã€‚ä¸å¹³é¢åŸºäºæ˜¾å¼è¡¨ç¤ºæ–¹æ³•ä¸åŒï¼Œè¯¥æ¨¡å‹å°†4Dç¼–ç åˆ†è§£ä¸º1ä¸ªç©ºé—´ç¼–ç å’Œ3ä¸ªæ—¶é—´ç¼–ç ï¼Œæ‘’å¼ƒä½é˜¶å‡è®¾ã€‚å…¶è®¾è®¡çš„æ–°æ³¨æ„åŠ›æ¨¡å—å¯åœ¨å®šå‘èŒƒå›´å†…ç”Ÿæˆæ³¨æ„åŠ›åˆ†æ•°ï¼Œæ±‡èšæ—¶ç©ºç‰¹å¾ã€‚æ­¤å¤–ï¼Œä¸ºç¼“è§£æ˜¾å¼è¡¨ç¤ºæ–¹æ³•çš„å›ºæœ‰ä¸å…‰æ»‘æ€§ï¼Œå¼•å…¥å¹³æ»‘æ­£åˆ™åŒ–é¡¹ï¼Œæé«˜æ¨¡å‹åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Gaussian splattingåœ¨é™æ€åœºæ™¯æ¸²æŸ“ä¸­å—åˆ°å…³æ³¨ã€‚</li>
<li>å¹³é¢åŸºäºæ˜¾å¼æ–¹æ³•é¢„æµ‹å˜å½¢å­˜åœ¨ç‰¹å¾é‡å å’Œæ¸²æŸ“è´¨é‡ä¸ä½³çš„é—®é¢˜ã€‚</li>
<li>Grid4Dæ¨¡å‹é‡‡ç”¨æ–°å‹æ˜¾å¼ç¼–ç æ–¹æ³•ï¼Œæ‘’å¼ƒä½é˜¶å‡è®¾ï¼Œé€šè¿‡å“ˆå¸Œç¼–ç è¿›è¡Œ4Dè¾“å…¥ã€‚</li>
<li>Grid4Dæ¨¡å‹åˆ†è§£æ—¶ç©ºç‰¹å¾ï¼Œé‡‡ç”¨æ³¨æ„åŠ›æ¨¡å—åœ¨å®šå‘èŒƒå›´å†…ç”Ÿæˆæ³¨æ„åŠ›åˆ†æ•°ã€‚</li>
<li>Grid4Dæ¨¡å‹å¼•å…¥å¹³æ»‘æ­£åˆ™åŒ–é¡¹ï¼Œè§£å†³æ˜¾å¼è¡¨ç¤ºæ–¹æ³•çš„å›ºæœ‰ä¸å…‰æ»‘é—®é¢˜ã€‚</li>
<li>Grid4Dæ¨¡å‹åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.20815">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fb3cb2a255a7af0c14f91b54f73e600d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b51444c746b853c2990f78df6232bb9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d48ad664abc446384ec691c867c7bb5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0186e149f266a5b9c2c70a278f5e015d.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="AugGS-Self-augmented-Gaussians-with-Structural-Masks-for-Sparse-view-3D-Reconstruction"><a href="#AugGS-Self-augmented-Gaussians-with-Structural-Masks-for-Sparse-view-3D-Reconstruction" class="headerlink" title="AugGS: Self-augmented Gaussians with Structural Masks for Sparse-view 3D   Reconstruction"></a>AugGS: Self-augmented Gaussians with Structural Masks for Sparse-view 3D   Reconstruction</h2><p><strong>Authors:Biâ€™an Du, Lingbei Meng, Wei Hu</strong></p>
<p>Sparse-view 3D reconstruction is a major challenge in computer vision, aiming to create complete three-dimensional models from limited viewing angles. Key obstacles include: 1) a small number of input images with inconsistent information; 2) dependence on input image quality; and 3) large model parameter sizes. To tackle these issues, we propose a self-augmented two-stage Gaussian splatting framework enhanced with structural masks for sparse-view 3D reconstruction. Initially, our method generates a basic 3D Gaussian representation from sparse inputs and renders multi-view images. We then fine-tune a pre-trained 2D diffusion model to enhance these images, using them as augmented data to further optimize the 3D Gaussians.Additionally, a structural masking strategy during training enhances the modelâ€™s robustness to sparse inputs and noise. Experiments on benchmarks like MipNeRF360, OmniObject3D, and OpenIllumination demonstrate that our approach achieves state-of-the-art performance in perceptual quality and multi-view consistency with sparse inputs. </p>
<blockquote>
<p>ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸»è¦æŒ‘æˆ˜ï¼Œå…¶ç›®æ ‡æ˜¯åŸºäºæœ‰é™çš„è§†è§’åˆ›å»ºå®Œæ•´çš„ä¸‰ç»´æ¨¡å‹ã€‚å…³é”®éš¾é¢˜åŒ…æ‹¬ï¼š1ï¼‰è¾“å…¥å›¾åƒæ•°é‡å°‘ä¸”ä¿¡æ¯ä¸ä¸€è‡´ï¼›2ï¼‰ä¾èµ–äºè¾“å…¥å›¾åƒçš„è´¨é‡ï¼›ä»¥åŠ3ï¼‰æ¨¡å‹å‚æ•°è§„æ¨¡å¤§ã€‚ä¸ºäº†åº”å¯¹è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¢å¼ºç»“æ„çš„ç¨€ç–è§†è§’ä¸‰ç»´é‡å»ºè‡ªå¢å¼ºä¸¤é˜¶æ®µé«˜æ–¯å–·å°„æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»ç¨€ç–è¾“å…¥ç”ŸæˆåŸºæœ¬çš„ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œå¹¶å‘ˆç°å¤šè§†è§’å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„äºŒç»´æ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥å¢å¼ºè¿™äº›å›¾åƒï¼Œå°†å…¶ä½œä¸ºå¢å¼ºæ•°æ®è¿›ä¸€æ­¥ä¼˜åŒ–ä¸‰ç»´é«˜æ–¯ã€‚æ­¤å¤–ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨ç»“æ„æ©ç ç­–ç•¥æé«˜äº†æ¨¡å‹å¯¹ç¨€ç–è¾“å…¥å’Œå™ªå£°çš„é²æ£’æ€§ã€‚åœ¨MipNeRF360ã€OmniObject3Då’ŒOpenIlluminationç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ„ŸçŸ¥è´¨é‡å’Œå¤šè§†è§’ä¸€è‡´æ€§æ–¹é¢è¾¾åˆ°äº†ç¨€ç–è¾“å…¥çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.04831v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºæŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç»“åˆè‡ªå¢å¼ºæŠ€æœ¯ä¸ä¸¤é˜¶æ®µé«˜æ–¯è´´å›¾æ¡†æ¶çš„è§£å†³æ–¹æ¡ˆã€‚æ­¤æ–¹æ³•èƒ½å¤Ÿç”ŸæˆåŸºæœ¬çš„ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡æ¸²æŸ“å¤šè§†è§’å›¾åƒè¿›è¡Œå¾®è°ƒã€‚é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„äºŒç»´æ‰©æ•£æ¨¡å‹å¢å¼ºå›¾åƒï¼Œå¹¶ä½¿ç”¨ç»“æ„æ©è†œç­–ç•¥æé«˜æ¨¡å‹å¯¹ç¨€ç–è¾“å…¥å’Œå™ªå£°çš„é²æ£’æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ„ŸçŸ¥è´¨é‡å’Œå¤šè§†è§’ä¸€è‡´æ€§æ–¹é¢è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ï¼Œéœ€è¦ä»æœ‰é™çš„è§†è§’åˆ›å»ºå®Œæ•´çš„ä¸‰ç»´æ¨¡å‹ã€‚</li>
<li>ä¸»è¦éš¾é¢˜åŒ…æ‹¬è¾“å…¥å›¾åƒæ•°é‡å°‘ä¸”ä¿¡æ¯ä¸ä¸€è‡´ã€ä¾èµ–è¾“å…¥å›¾åƒè´¨é‡ã€æ¨¡å‹å‚æ•°è§„æ¨¡è¾ƒå¤§ã€‚</li>
<li>æå‡ºçš„è§£å†³æ–¹æ¡ˆæ˜¯ä¸€ä¸ªç»“åˆè‡ªå¢å¼ºæŠ€æœ¯ä¸ä¸¤é˜¶æ®µé«˜æ–¯è´´å›¾æ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆä¸‰ç»´é«˜æ–¯è¡¨ç¤ºå¹¶æ¸²æŸ“å¤šè§†è§’å›¾åƒã€‚</li>
<li>é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒçš„äºŒç»´æ‰©æ•£æ¨¡å‹å¢å¼ºå›¾åƒï¼Œå°†å…¶ä½œä¸ºå¢å¼ºæ•°æ®è¿›ä¸€æ­¥ä¼˜åŒ–ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>ç»“æ„æ©è†œç­–ç•¥æé«˜æ¨¡å‹å¯¹ç¨€ç–è¾“å…¥å’Œå™ªå£°çš„é²æ£’æ€§ã€‚</li>
<li>åœ¨MipNeRF360ã€OmniObject3Då’ŒOpenIlluminationç­‰åŸºå‡†æµ‹è¯•ä¸Šï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†å…ˆè¿›çš„æ„ŸçŸ¥è´¨é‡å’Œå¤šè§†è§’ä¸€è‡´æ€§æ°´å¹³ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹äºè§£å†³ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºé—®é¢˜å…·æœ‰æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.04831">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d41f901345d70cc461cbb26eccba820b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-52a4a78f54cfd0e14644f544afee6778.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-264f5c7c995c8c886b0f1cb2044b1802.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8855da46d8089177baaf2ead6ab9ba36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06316088fb123dc015a86b70f4a19ddd.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e0d61a3ec03e4f212d16afb4fead0a57.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Bringing Objects to Life 4D generation from 3D objects
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-519b6cc1bd7cf2c02053876e12ac88ff.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Generating Editable Head Avatars with 3D Gaussian GANs
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">11370.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
