<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Distributed Mixture-of-Agents for Edge Inference with Large Language   Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-d420af9d7c6e4b553c221ca8efb92b25.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    62 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-02-æ›´æ–°"><a href="#2025-01-02-æ›´æ–°" class="headerlink" title="2025-01-02 æ›´æ–°"></a>2025-01-02 æ›´æ–°</h1><h2 id="Distributed-Mixture-of-Agents-for-Edge-Inference-with-Large-Language-Models"><a href="#Distributed-Mixture-of-Agents-for-Edge-Inference-with-Large-Language-Models" class="headerlink" title="Distributed Mixture-of-Agents for Edge Inference with Large Language   Models"></a>Distributed Mixture-of-Agents for Edge Inference with Large Language   Models</h2><p><strong>Authors:Purbesh Mitra, Priyanka Kaswan, Sennur Ulukus</strong></p>
<p>Mixture-of-Agents (MoA) has recently been proposed as a method to enhance performance of large language models (LLMs), enabling multiple individual LLMs to work together for collaborative inference. This collaborative approach results in improved responses to user prompts compared to relying on a single LLM. In this paper, we consider such an MoA architecture in a distributed setting, where LLMs operate on individual edge devices, each uniquely associated with a user and equipped with its own distributed computing power. These devices exchange information using decentralized gossip algorithms, allowing different device nodes to talk without the supervision of a centralized server. In the considered setup, different users have their own LLM models to address user prompts. Additionally, the devices gossip either their own user-specific prompts or augmented prompts to generate more refined answers to certain queries. User prompts are temporarily stored in the device queues when their corresponding LLMs are busy. Given the memory limitations of edge devices, it is crucial to ensure that the average queue sizes in the system remain bounded. In this paper, we address this by theoretically calculating the queuing stability conditions for the device queues under reasonable assumptions, which we validate experimentally as well. Further, we demonstrate through experiments, leveraging open-source LLMs for the implementation of distributed MoA, that certain MoA configurations produce higher-quality responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The implementation is available at: <a target="_blank" rel="noopener" href="https://github.com/purbeshmitra/distributed_moa">https://github.com/purbeshmitra/distributed_moa</a>. </p>
<blockquote>
<p>Mixture-of-Agents (MoA)ä½œä¸ºä¸€ç§æ–¹æ³•è¢«æå‡ºï¼Œæ—¨åœ¨å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½ã€‚å®ƒä½¿å¤šä¸ªç‹¬ç«‹çš„LLMèƒ½å¤ŸååŒå·¥ä½œä»¥è¿›è¡ŒååŒæ¨ç†ã€‚è¿™ç§ååŒæ–¹æ³•ç›¸æ¯”ä¾èµ–å•ä¸ªLLMï¼Œèƒ½äº§ç”Ÿæ›´å¥½çš„ç”¨æˆ·æç¤ºå“åº”ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ä½¿ç”¨è¿™æ ·çš„MoAæ¶æ„ï¼Œå…¶ä¸­LLMåœ¨ä¸ªåˆ«è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œï¼Œæ¯ä¸ªè®¾å¤‡éƒ½ä¸ç”¨æˆ·å”¯ä¸€å…³è”ï¼Œå¹¶æ‹¥æœ‰è‡ªå·±çš„åˆ†å¸ƒå¼è®¡ç®—èƒ½åŠ›ã€‚è¿™äº›è®¾å¤‡ä½¿ç”¨å»ä¸­å¿ƒåŒ–çš„é—²èŠç®—æ³•äº¤æ¢ä¿¡æ¯ï¼Œå…è®¸ä¸åŒçš„è®¾å¤‡èŠ‚ç‚¹åœ¨æ²¡æœ‰ä¸­å¤®æœåŠ¡å™¨ç›‘ç£çš„æƒ…å†µä¸‹è¿›è¡Œäº¤æµã€‚åœ¨è€ƒè™‘çš„ç³»ç»Ÿä¸­ï¼Œä¸åŒç”¨æˆ·æ‹¥æœ‰ä»–ä»¬è‡ªå·±çš„LLMæ¨¡å‹æ¥å¤„ç†ç”¨æˆ·æç¤ºã€‚æ­¤å¤–ï¼Œè®¾å¤‡ä¼šé—²èŠå®ƒä»¬è‡ªå·±çš„ç”¨æˆ·ç‰¹å®šæç¤ºæˆ–å¢å¼ºæç¤ºï¼Œä»¥ç”Ÿæˆå¯¹æŸäº›æŸ¥è¯¢çš„æ›´ç²¾ç»†ç­”æ¡ˆã€‚å½“ç”¨æˆ·å¯¹åº”çš„LLMå¿™äºå¤„ç†æ—¶ï¼Œç”¨æˆ·æç¤ºä¼šæš‚æ—¶å­˜å‚¨åœ¨è®¾å¤‡é˜Ÿåˆ—ä¸­ã€‚è€ƒè™‘åˆ°è¾¹ç¼˜è®¾å¤‡çš„å†…å­˜é™åˆ¶ï¼Œç¡®ä¿ç³»ç»Ÿä¸­çš„å¹³å‡é˜Ÿåˆ—å¤§å°ä¿æŒæœ‰ç•Œè‡³å…³é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ç†è®ºè®¡ç®—è®¾å¤‡é˜Ÿåˆ—çš„æ’é˜Ÿç¨³å®šæ€§æ¡ä»¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿™äº›æ¡ä»¶åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ä¹Ÿå¾—åˆ°äº†éªŒè¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨å¼€æºLLMå®ç°åˆ†å¸ƒå¼MoAï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜æŸäº›MoAé…ç½®äº§ç”Ÿçš„å“åº”è´¨é‡æ›´é«˜ï¼Œè¿™æ˜¯åœ¨AlpacaEval 2.0åŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°çš„ã€‚å®ç°å¯è®¿é—®äºï¼š<a target="_blank" rel="noopener" href="https://github.com/purbeshmitra/distributed_moa%E3%80%82">https://github.com/purbeshmitra/distributed_moaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.21200v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‘æœŸæå‡ºMixture-of-Agentsï¼ˆMoAï¼‰æ–¹æ³•æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ€§èƒ½ï¼Œä½¿å¤šä¸ªLLMååŒå·¥ä½œä»¥è¿›è¡ŒååŒæ¨ç†ã€‚åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è€ƒè™‘MoAæ¶æ„ï¼Œå…¶ä¸­LLMåœ¨å„è‡ªè¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œï¼Œæ¯ä¸ªè®¾å¤‡ä¸ç”¨æˆ·å”¯ä¸€å…³è”å¹¶æ‹¥æœ‰è‡ªå·±çš„åˆ†å¸ƒå¼è®¡ç®—èƒ½åŠ›ã€‚è¿™äº›è®¾å¤‡ä½¿ç”¨å»ä¸­å¿ƒåŒ–çš„é—²èŠç®—æ³•äº¤æ¢ä¿¡æ¯ï¼Œå…è®¸ä¸åŒè®¾å¤‡èŠ‚ç‚¹ä¹‹é—´æ— éœ€ä¸­å¿ƒæœåŠ¡å™¨çš„ç›‘ç£å³å¯é€šä¿¡ã€‚åœ¨æ­¤è®¾ç½®ä¸­ï¼Œç”¨æˆ·æ‹¥æœ‰è‡ªå·±çš„LLMæ¨¡å‹æ¥å“åº”æç¤ºã€‚è®¾å¤‡ä¼šé—²èŠç”¨æˆ·ç‰¹å®šçš„æç¤ºæˆ–å¢å¼ºæç¤ºä»¥ç”Ÿæˆæ›´ç²¾ç»†çš„ç­”æ¡ˆã€‚ç”¨æˆ·æç¤ºä¼šåœ¨ç›¸åº”LLMç¹å¿™æ—¶ä¸´æ—¶å­˜å‚¨åœ¨è®¾å¤‡é˜Ÿåˆ—ä¸­ã€‚é‰´äºè¾¹ç¼˜è®¾å¤‡çš„å†…å­˜é™åˆ¶ï¼Œç¡®ä¿ç³»ç»Ÿä¸­å¹³å‡é˜Ÿåˆ—å¤§å°ä¿æŒç•Œé™è‡³å…³é‡è¦ã€‚æœ¬æ–‡é€šè¿‡ç†è®ºè®¡ç®—è®¾å¤‡é˜Ÿåˆ—çš„ç¨³å®šæ¡ä»¶æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¹¶åœ¨å®éªŒä¸­è¿›è¡Œäº†éªŒè¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å€ŸåŠ©å¼€æºLLMå®ç°åˆ†å¸ƒå¼MoAè¿›è¡Œå®éªŒï¼Œè¯æ˜æŸäº›MoAé…ç½®äº§ç”Ÿçš„å“åº”è´¨é‡è¾ƒé«˜ï¼Œå¦‚åœ¨AlpacaEval 2.0åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ã€‚ç›¸å…³å®ç°å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/purbeshmitra/distributed_moa">https://github.com/purbeshmitra/distributed_moa</a>ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>MoAæ–¹æ³•èƒ½å¤Ÿä¿ƒè¿›å¤šä¸ªLLMåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ååŒå·¥ä½œï¼Œæé«˜å¯¹ç”¨æˆ·æç¤ºçš„å“åº”è´¨é‡ã€‚</li>
<li>è¾¹ç¼˜è®¾å¤‡é—´çš„ä¿¡æ¯äº¤æ¢é‡‡ç”¨å»ä¸­å¿ƒåŒ–é—²èŠç®—æ³•ï¼Œå®ç°è®¾å¤‡é—´è‡ªä¸»é€šä¿¡ï¼Œæ— éœ€ä¸­å¤®æœåŠ¡å™¨ç›‘ç£ã€‚</li>
<li>ä¸åŒç”¨æˆ·æ‹¥æœ‰å„è‡ªçš„LLMæ¨¡å‹ä»¥å¤„ç†ç”¨æˆ·æç¤ºï¼ŒåŒæ—¶è®¾å¤‡èƒ½å¤Ÿå¤„ç†æ’é˜Ÿçš„ç”¨æˆ·æç¤ºã€‚</li>
<li>ç†è®ºè®¡ç®—è®¾å¤‡é˜Ÿåˆ—çš„ç¨³å®šæ¡ä»¶ï¼Œç¡®ä¿å†…å­˜æœ‰é™çš„è¾¹ç¼˜è®¾å¤‡èƒ½ç»´æŒç³»ç»Ÿå¹³å‡é˜Ÿåˆ—å¤§å°ã€‚</li>
<li>é€šè¿‡å®éªŒéªŒè¯ï¼ŒæŸäº›MoAé…ç½®èƒ½äº§ç”Ÿæ¯”å…¶ä»–é…ç½®æ›´é«˜è´¨é‡çš„å“åº”ã€‚</li>
<li>æä¾›åŸºäºå¼€æºLLMçš„åˆ†å¸ƒå¼MoAå®ç°ï¼Œå¹¶åœ¨AlpacaEval 2.0åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°è‰¯å¥½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.21200">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-92053527df11ccaa7e9bdcc19f358342.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-732a93b239ac84b7c361335645ed46e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f45f698f5949fd64088a763e35d91036.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dd799638a4a194b36da3fffb687aaf1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb71ec41e1afe2fd81f0dae2d6ac5f4b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Training-Software-Engineering-Agents-and-Verifiers-with-SWE-Gym"><a href="#Training-Software-Engineering-Agents-and-Verifiers-with-SWE-Gym" class="headerlink" title="Training Software Engineering Agents and Verifiers with SWE-Gym"></a>Training Software Engineering Agents and Verifiers with SWE-Gym</h2><p><strong>Authors:Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang</strong></p>
<p>We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to train language model based SWE agents , achieving up to 19% absolute gains in resolve rate on the popular SWE-Bench Verified and Lite test sets. We also experiment with inference-time scaling through verifiers trained on agent trajectories sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve 32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new state-of-the-art for open-weight SWE agents. To facilitate further research, we publicly release SWE-Gym, models, and agent trajectories. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºSWE-Gymï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè®­ç»ƒç°å®ä¸–ç•Œè½¯ä»¶å·¥ç¨‹ï¼ˆSWEï¼‰ä»£ç†çš„ç¯å¢ƒã€‚SWE-GymåŒ…å«2438ä¸ªç°å®ä¸–ç•Œçš„Pythonä»»åŠ¡å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹éƒ½åŒ…å«ä¸€ä¸ªå¸¦æœ‰å¯æ‰§è¡Œè¿è¡Œæ—¶ç¯å¢ƒã€å•å…ƒæµ‹è¯•å’Œç”¨è‡ªç„¶è¯­è¨€æŒ‡å®šçš„ä»»åŠ¡çš„åŸºç¡€ä»£ç ã€‚æˆ‘ä»¬ä½¿ç”¨SWE-Gymè®­ç»ƒåŸºäºè¯­è¨€æ¨¡å‹çš„SWEä»£ç†ï¼Œåœ¨æµè¡Œçš„SWE-Bench Verifiedå’ŒLiteæµ‹è¯•é›†ä¸Šå®ç°é«˜è¾¾19%çš„ç»å¯¹è§£å†³ç‡å¢ç›Šã€‚æˆ‘ä»¬è¿˜é€šè¿‡å®éªŒéªŒè¯äº†åœ¨SWE-Gymé‡‡æ ·çš„ä»£ç†è½¨è¿¹ä¸Šè®­ç»ƒçš„éªŒè¯å™¨è¿›è¡Œæ¨ç†æ—¶é—´ç¼©æ”¾ã€‚ç»“åˆæˆ‘ä»¬å¾®è°ƒè¿‡çš„SWEä»£ç†ï¼Œæˆ‘ä»¬åœ¨SWE-Bench Verifiedå’ŒLiteä¸Šåˆ†åˆ«è¾¾åˆ°äº†32.0%å’Œ26.0%ï¼Œåæ˜ äº†å¼€æ”¾æƒé‡SWEä»£ç†çš„æœ€æ–°çŠ¶æ€ã€‚ä¸ºäº†ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ï¼Œæˆ‘ä»¬å…¬å¼€å‘å¸ƒSWE-Gymã€æ¨¡å‹å’Œä»£ç†è½¨è¿¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.21139v1">PDF</a> Code at <a target="_blank" rel="noopener" href="https://github.com/SWE-Gym/SWE-Gym">https://github.com/SWE-Gym/SWE-Gym</a></p>
<p><strong>Summary</strong>ï¼š<br>æˆ‘ä»¬æ¨å‡ºäº†SWE-Gymï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè®­ç»ƒçœŸå®ä¸–ç•Œè½¯ä»¶å·¥ç¨‹ï¼ˆSWEï¼‰ä»£ç†çš„ç¯å¢ƒã€‚SWE-GymåŒ…å«2438ä¸ªçœŸå®ä¸–ç•Œçš„Pythonä»»åŠ¡å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹éƒ½åŒ…å«ä¸€ä¸ªå¯æ‰§è¡Œè¿è¡Œæ—¶ç¯å¢ƒã€å•å…ƒæµ‹è¯•å’Œç”¨è‡ªç„¶è¯­è¨€æŒ‡å®šçš„ä»»åŠ¡ã€‚æˆ‘ä»¬ä½¿ç”¨SWE-Gymè®­ç»ƒåŸºäºè¯­è¨€æ¨¡å‹çš„SWEä»£ç†ï¼Œåœ¨æµè¡Œçš„SWE-Bench Verifiedå’ŒLiteæµ‹è¯•é›†ä¸Šå®ç°äº†é«˜è¾¾19%çš„ç»å¯¹è§£å†³ç‡å¢é•¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°è¯•é€šè¿‡è®­ç»ƒåœ¨SWE-Gymä¸­é‡‡æ ·çš„ä»£ç†è½¨è¿¹çš„éªŒè¯å™¨æ¥è¿›è¡Œæ¨ç†æ—¶é—´ç¼©æ”¾ã€‚ç»“åˆæˆ‘ä»¬å¾®è°ƒè¿‡çš„SWEä»£ç†ï¼Œæˆ‘ä»¬åœ¨SWE-Bench Verifiedå’ŒLiteä¸Šåˆ†åˆ«è¾¾åˆ°äº†32.0%å’Œ26.0%çš„è¡¨ç°ï¼Œåæ˜ äº†å¼€æ”¾æƒé‡SWEä»£ç†çš„æœ€æ–°çŠ¶æ€ã€‚ä¸ºäº†ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ï¼Œæˆ‘ä»¬å…¬å¼€å‘å¸ƒäº†SWE-Gymã€æ¨¡å‹å’Œä»£ç†è½¨è¿¹ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>SWE-Gymæ˜¯é¦–ä¸ªç”¨äºè®­ç»ƒçœŸå®ä¸–ç•Œè½¯ä»¶å·¥ç¨‹ä»£ç†çš„ç¯å¢ƒï¼ŒåŒ…å«2438ä¸ªçœŸå®ä¸–ç•Œçš„Pythonä»»åŠ¡å®ä¾‹ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨SWE-Gymè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ŒSWEä»£ç†åœ¨SWE-Bench Verifiedå’ŒLiteæµ‹è¯•é›†ä¸Šçš„è§£å†³ç‡æœ‰äº†æ˜¾è‘—æé«˜ã€‚</li>
<li>æ¨ç†æ—¶é—´ç¼©æ”¾é€šè¿‡è®­ç»ƒåœ¨SWE-Gymä¸­é‡‡æ ·çš„ä»£ç†è½¨è¿¹çš„éªŒè¯å™¨å®ç°ã€‚</li>
<li>ç»“åˆå¾®è°ƒè¿‡çš„SWEä»£ç†ï¼Œåœ¨SWE-Bench Verifiedå’ŒLiteä¸Šçš„è¡¨ç°åæ˜ äº†å¼€æ”¾æƒé‡SWEä»£ç†çš„æœ€æ–°æ°´å¹³ã€‚</li>
<li>SWE-Gymã€æ¨¡å‹å’Œä»£ç†è½¨è¿¹ç°å·²å…¬å¼€ï¼Œä»¥ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ã€‚</li>
<li>SWE-Gymç¯å¢ƒä¸ºè½¯ä»¶å·¥ç¨‹çš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–æä¾›äº†æ–°çš„å¯èƒ½æ€§ï¼Œæœ‰åŠ©äºæ¨åŠ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.21139">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-902c6b5c6860197973353058888bf870.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2516d26085e49ea79c1e13ac6dfa85cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e53f12dd1121cf31e54a821904dd3d12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c55b8e50e0ae7b4334fc21218cdb105d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c54239facf7ef0ee8fb08df996e20dea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-10d31acf6d9a6351e611b8fbbece6069.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Exploring-and-Controlling-Diversity-in-LLM-Agent-Conversation"><a href="#Exploring-and-Controlling-Diversity-in-LLM-Agent-Conversation" class="headerlink" title="Exploring and Controlling Diversity in LLM-Agent Conversation"></a>Exploring and Controlling Diversity in LLM-Agent Conversation</h2><p><strong>Authors:KuanChao Chu, Yi-Pei Chen, Hideki Nakayama</strong></p>
<p>Diversity is a critical aspect of multi-agent communication. In this paper, we focus on controlling and exploring diversity in the context of open-domain multi-agent conversations, particularly for world simulation applications. We propose Adaptive Prompt Pruning (APP), a novel method that dynamically adjusts the content of the utterance generation prompt to control diversity using a single parameter, lambda. Through extensive experiments, we show that APP effectively controls the output diversity across models and datasets, with pruning more information leading to more diverse output. We comprehensively analyze the relationship between prompt content and conversational diversity. Our findings reveal that information from all components of the prompt generally constrains the diversity of the output, with the Memory block exerting the most significant influence. APP is compatible with established techniques like temperature sampling and top-p sampling, providing a versatile tool for diversity management. To address the trade-offs of increased diversity, such as inconsistencies with omitted information, we incorporate a post-generation correction step, which effectively balances diversity enhancement with output consistency. Additionally, we examine how prompt structure, including component order and length, impacts diversity. This study addresses key questions surrounding diversity in multi-agent world simulation, offering insights into its control, influencing factors, and associated trade-offs. Our contributions lay the foundation for systematically engineering diversity in LLM-based multi-agent collaborations, advancing their effectiveness in real-world applications. </p>
<blockquote>
<p>å¤šæ ·æ€§æ˜¯å¤šæ™ºèƒ½ä½“é€šä¿¡çš„å…³é”®æ–¹é¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºåœ¨å¼€æ”¾åŸŸå¤šæ™ºèƒ½ä½“å¯¹è¯çš„æƒ…å¢ƒä¸­æ§åˆ¶å’Œæ¢ç´¢å¤šæ ·æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸–ç•Œæ¨¡æ‹Ÿåº”ç”¨æ–¹é¢ã€‚æˆ‘ä»¬æå‡ºäº†è‡ªé€‚åº”æç¤ºä¿®å‰ªï¼ˆAPPï¼‰è¿™ä¸€æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å•ä¸ªå‚æ•°Î»åŠ¨æ€è°ƒæ•´è¯è¯­ç”Ÿæˆæç¤ºçš„å†…å®¹ï¼Œä»¥æ§åˆ¶å¤šæ ·æ€§ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†APPåœ¨æ¨¡å‹å’Œæ•°æ®é›†ä¹‹é—´æœ‰æ•ˆåœ°æ§åˆ¶äº†è¾“å‡ºå¤šæ ·æ€§ï¼Œä¿®å‰ªæ›´å¤šä¿¡æ¯ä¼šå¯¼è‡´è¾“å‡ºæ›´åŠ å¤šæ ·åŒ–ã€‚æˆ‘ä»¬å…¨é¢åˆ†æäº†æç¤ºå†…å®¹ä¸å¯¹è¯å¤šæ ·æ€§ä¹‹é—´çš„å…³ç³»ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œæç¤ºçš„æ‰€æœ‰ç»„æˆéƒ¨åˆ†çš„ä¿¡æ¯é€šå¸¸éƒ½é™åˆ¶äº†è¾“å‡ºçš„å¤šæ ·æ€§ï¼Œå…¶ä¸­è®°å¿†å—çš„å½±å“æœ€ä¸ºæ˜¾è‘—ã€‚APPå¯ä»¥ä¸æ¸©åº¦é‡‡æ ·ã€top-pé‡‡æ ·ç­‰ç°æœ‰æŠ€æœ¯ç›¸ç»“åˆï¼Œæä¾›å¤šæ ·åŒ–çš„å·¥å…·æ¥è¿›è¡Œå¤šæ ·æ€§ç®¡ç†ã€‚ä¸ºäº†è§£å†³å¢åŠ å¤šæ ·æ€§å¸¦æ¥çš„æƒè¡¡é—®é¢˜ï¼Œå¦‚çœç•¥ä¿¡æ¯ä¸ä¸€è‡´æ€§ä¹‹é—´çš„ä¸ä¸€è‡´ï¼Œæˆ‘ä»¬å¼•å…¥äº†åç”Ÿæˆæ ¡æ­£æ­¥éª¤ï¼Œè¿™æœ‰æ•ˆåœ°å¹³è¡¡äº†å¤šæ ·æ€§å¢å¼ºä¸è¾“å‡ºä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†æç¤ºç»“æ„ï¼ŒåŒ…æ‹¬ç»„ä»¶çš„é¡ºåºå’Œé•¿åº¦ï¼Œå¯¹å¤šæ ·æ€§çš„å½±å“ã€‚æœ¬ç ”ç©¶è§£å†³äº†å¤šæ™ºèƒ½ä½“ä¸–ç•Œæ¨¡æ‹Ÿä¸­å¤šæ ·æ€§çš„å…³é”®é—®é¢˜ï¼Œä¸ºæ§åˆ¶ã€å½±å“å› ç´ å’Œç›¸å…³çš„æƒè¡¡æä¾›äº†è§è§£ã€‚æˆ‘ä»¬çš„è´¡çŒ®ä¸ºåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“åä½œä¸­ç³»ç»Ÿåœ°å·¥ç¨‹åŒ–å¤šæ ·æ€§å¥ å®šäº†åŸºç¡€ï¼Œæé«˜äº†å…¶åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.21102v1">PDF</a> Accepted for the AAAI 2025 Workshop on Advancing LLM-Based   Multi-Agent Collaboration</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡ç ”ç©¶äº†å¤šæ™ºèƒ½ä½“é€šä¿¡ä¸­çš„å¤šæ ·æ€§æ§åˆ¶é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¼€æ”¾é¢†åŸŸå¤šæ™ºèƒ½ä½“å¯¹è¯ä¸­çš„å¤šæ ·æ€§æ¢ç´¢ã€‚æå‡ºäº†ä¸€ç§åä¸ºè‡ªé€‚åº”æç¤ºä¿®å‰ªï¼ˆAPPï¼‰çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´è¯è¯­ç”Ÿæˆæç¤ºçš„å†…å®¹æ¥æ§åˆ¶å¤šæ ·æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒAPPèƒ½æœ‰æ•ˆæ§åˆ¶ä¸åŒæ¨¡å‹å’Œæ•°æ®çš„è¾“å‡ºå¤šæ ·æ€§ï¼Œé€šè¿‡åˆ é™¤æ›´å¤šä¿¡æ¯æ¥è·å¾—æ›´å¤šä¸åŒçš„è¾“å‡ºã€‚æœ¬æ–‡ç»¼åˆåˆ†æäº†æç¤ºå†…å®¹ä¸å¯¹è¯å¤šæ ·æ€§çš„å…³ç³»ï¼Œå‘ç°æç¤ºçš„æ‰€æœ‰ç»„æˆéƒ¨åˆ†çš„ä¿¡æ¯é€šå¸¸éƒ½ä¼šé™åˆ¶è¾“å‡ºçš„å¤šæ ·æ€§ï¼Œå…¶ä¸­è®°å¿†å—çš„å½±å“æœ€ä¸ºæ˜¾è‘—ã€‚æ­¤å¤–ï¼ŒAPPå¯ä»¥ä¸ç°æœ‰çš„æŠ€æœ¯å¦‚æ¸©åº¦é‡‡æ ·å’Œtop-pé‡‡æ ·ç›¸ç»“åˆï¼Œæä¾›å¤šæ ·åŒ–çš„ç®¡ç†å·¥å…·ã€‚ä¸ºäº†è§£å†³å¢åŠ å¤šæ ·æ€§æ‰€å¸¦æ¥çš„æƒè¡¡é—®é¢˜ï¼Œå¦‚çœç•¥ä¿¡æ¯çš„ä¸ä¸€è‡´æ€§ï¼Œæœ¬æ–‡å¼•å…¥äº†åç”Ÿæˆæ ¡æ­£æ­¥éª¤ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†å¤šæ ·æ€§å¢å¼ºä¸è¾“å‡ºä¸€è‡´æ€§ã€‚ç ”ç©¶è¿˜å‘ç°æç¤ºç»“æ„å¦‚ç»„ä»¶é¡ºåºå’Œé•¿åº¦ä¹Ÿä¼šå½±å“å¤šæ ·æ€§ã€‚æœ¬ç ”ç©¶è§£å†³äº†å¤šæ™ºèƒ½ä½“ä¸–ç•Œæ¨¡æ‹Ÿä¸­å¤šæ ·æ€§çš„å…³é”®é—®é¢˜ï¼Œä¸ºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹åŸºç¡€ä¸Šç³»ç»Ÿåœ°å·¥ç¨‹åŒ–å¤šæ ·æ€§æä¾›äº†è§è§£ï¼Œæé«˜äº†å…¶åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤šæ™ºèƒ½ä½“é€šä¿¡ä¸­çš„å¤šæ ·æ€§æ§åˆ¶æ˜¯é‡è¦ç ”ç©¶æ–¹å‘ã€‚</li>
<li>è‡ªé€‚åº”æç¤ºä¿®å‰ªï¼ˆAPPï¼‰æ–¹æ³•é€šè¿‡åŠ¨æ€è°ƒæ•´è¯è¯­ç”Ÿæˆæç¤ºçš„å†…å®¹æ¥æ§åˆ¶å¤šæ ·æ€§ã€‚</li>
<li>APPæ–¹æ³•èƒ½æœ‰æ•ˆæ§åˆ¶ä¸åŒæ¨¡å‹å’Œæ•°æ®çš„è¾“å‡ºå¤šæ ·æ€§ã€‚</li>
<li>æç¤ºçš„æ‰€æœ‰ç»„æˆéƒ¨åˆ†éƒ½ä¼šé™åˆ¶è¾“å‡ºçš„å¤šæ ·æ€§ï¼Œå…¶ä¸­è®°å¿†å—å½±å“æœ€æ˜¾è‘—ã€‚</li>
<li>APPå¯ä¸ç°æœ‰æŠ€æœ¯ç»“åˆï¼Œæä¾›å¤šæ ·åŒ–çš„ç®¡ç†å·¥å…·ã€‚</li>
<li>åç”Ÿæˆæ ¡æ­£æ­¥éª¤æœ‰æ•ˆå¹³è¡¡äº†å¤šæ ·æ€§å¢å¼ºä¸è¾“å‡ºä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.21102">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-84874cdeb5b43d0781163379c24afb21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e2d0c62c317ffbf5f7cbf1590cc572e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-264e3d1ab662c4c493ad0b25d3a709bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5b89dedbeac7b19498f4d415aa13e14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05573722ada88a5827569313e18bd23e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2acd99ae4e6de1b4e7dcc261f794d98c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97f9571e4d3cd0d28fabf6fbe7193496.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Planning-Living-and-Judging-A-Multi-agent-LLM-based-Framework-for-Cyclical-Urban-Planning"><a href="#Planning-Living-and-Judging-A-Multi-agent-LLM-based-Framework-for-Cyclical-Urban-Planning" class="headerlink" title="Planning, Living and Judging: A Multi-agent LLM-based Framework for   Cyclical Urban Planning"></a>Planning, Living and Judging: A Multi-agent LLM-based Framework for   Cyclical Urban Planning</h2><p><strong>Authors:Hang Ni, Yuzhi Wang, Hao Liu</strong></p>
<p>Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process. </p>
<blockquote>
<p>åœ¨åŸå¸‚åŒ–èƒŒæ™¯ä¸‹ï¼ŒåŸå¸‚å†ç”Ÿé¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦é€‚åº”æ€§çš„æ–¹æ³•æ¥åº”å¯¹ä¸æ–­å˜åŒ–çš„éœ€æ±‚ã€‚æˆ‘ä»¬å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ï¼Œæå‡ºå¾ªç¯åŸå¸‚è§„åˆ’ï¼ˆCUPï¼‰è¿™ä¸€æ–°èŒƒå¼ï¼Œè¯¥èŒƒå¼ä»¥é—­ç¯æ–¹å¼è¿ç»­ç”Ÿæˆã€è¯„ä¼°å’Œä¼˜åŒ–åŸå¸‚è§„åˆ’ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„åŸºäºå¤šæ™ºèƒ½ä½“çš„LLMæ¡†æ¶åŒ…å«ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ï¼šï¼ˆ1ï¼‰è§„åˆ’ï¼Œå…¶ä¸­LLMæ™ºèƒ½ä½“åŸºäºä¸Šä¸‹æ–‡æ•°æ®ç”Ÿæˆå’Œç»†åŒ–åŸå¸‚è§„åˆ’ï¼›ï¼ˆ2ï¼‰ç”Ÿæ´»ï¼Œå…¶ä¸­æ™ºèƒ½ä½“æ¨¡æ‹Ÿå±…æ°‘çš„è¡Œä¸ºå’Œäº’åŠ¨ï¼Œæ¨¡æ‹ŸåŸå¸‚ç¯å¢ƒä¸­çš„ç”Ÿæ´»ï¼›ï¼ˆ3ï¼‰åˆ¤æ–­ï¼Œæ¶‰åŠè¯„ä¼°è§„åˆ’çš„æœ‰æ•ˆæ€§å¹¶æä¾›æ”¹è¿›è¿­ä»£åé¦ˆã€‚å¾ªç¯è¿‡ç¨‹ä½¿è§„åˆ’æ–¹æ³•å…·æœ‰åŠ¨æ€æ€§å’Œå“åº”æ€§ã€‚åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æ¡†æ¶ä½œä¸ºè¿ç»­è‡ªé€‚åº”è§„åˆ’è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20505v1">PDF</a> 4 pages, 2 figures, accepted by The 1st Workshop on AI for Urban   Planning (AAAI 2025â€™s Workshop)</p>
<p><strong>Summary</strong></p>
<p>å¾ªç¯åŸå¸‚è®¡åˆ’ï¼ˆCUPï¼‰åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åº”å¯¹åŸå¸‚åŒ–ä¸­çš„å†ç”ŸæŒ‘æˆ˜ï¼Œé€šè¿‡æŒç»­ç”Ÿæˆã€è¯„ä¼°å’Œä¿®æ­£åŸå¸‚è®¡åˆ’ï¼Œå½¢æˆäº†ä¸€ä¸ªå°é—­çš„å¾ªç¯ä½“ç³»ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬è§„åˆ’ã€ç”Ÿæ´»å’Œè¯„åˆ¤ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼Œæ—¨åœ¨åŠ¨æ€å“åº”åŸå¸‚éœ€æ±‚å¹¶æ”¹è¿›åŸå¸‚è®¡åˆ’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸå¸‚åŒ–èƒŒæ™¯ä¸‹çš„åŸå¸‚å†ç”Ÿé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œéœ€è¦é€‚åº”æ€§çš„æ–¹æ³•æ¥è§£å†³ä¸æ–­å˜åŒ–çš„éœ€æ±‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å¾ªç¯åŸå¸‚è§„åˆ’ï¼ˆCUPï¼‰èŒƒå¼ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿ç»­ç”Ÿæˆã€è¯„ä¼°å’Œä¿®æ­£åŸå¸‚è®¡åˆ’ã€‚</li>
<li>å¾ªç¯åŸå¸‚è®¡åˆ’æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šè§„åˆ’ã€ç”Ÿæ´»å’Œè¯„åˆ¤ã€‚</li>
<li>è§„åˆ’ç»„ä»¶åˆ©ç”¨LLMä»£ç†åŸºäºä¸Šä¸‹æ–‡æ•°æ®ç”Ÿæˆå’Œç»†åŒ–åŸå¸‚è®¡åˆ’ã€‚</li>
<li>ç”Ÿæ´»ç»„ä»¶æ¨¡æ‹Ÿå±…æ°‘çš„è¡Œä¸ºå’Œäº’åŠ¨ï¼Œæ¨¡æ‹ŸåŸå¸‚ç¯å¢ƒä¸­çš„ç”Ÿæ´»ã€‚</li>
<li>è¯„åˆ¤ç»„ä»¶è¯„ä¼°è®¡åˆ’çš„æœ‰æ•ˆæ€§å¹¶æä¾›åé¦ˆä»¥è¿›è¡Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20505">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0eff83ff1487a40666a4f3e0abc5d29e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4847eff39ced544dabbae7293e4fa1a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d464f05972a3840c3b6e2a8de01a94f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efb42ed3c27c985219e0936970c9c677.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Image-Augmentation-Agent-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Image-Augmentation-Agent-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Image Augmentation Agent for Weakly Supervised Semantic Segmentation"></a>Image Augmentation Agent for Weakly Supervised Semantic Segmentation</h2><p><strong>Authors:Wangyu Wu, Xianglin Qiu, Siqi Song, Zhenhong Chen, Xiaowei Huang, Fei Ma, Jimin Xiao</strong></p>
<p>Weakly-supervised semantic segmentation (WSSS) has achieved remarkable progress using only image-level labels. However, most existing WSSS methods focus on designing new network structures and loss functions to generate more accurate dense labels, overlooking the limitations imposed by fixed datasets, which can constrain performance improvements. We argue that more diverse trainable images provides WSSS richer information and help model understand more comprehensive semantic pattern. Therefore in this paper, we introduce a novel approach called Image Augmentation Agent (IAA) which shows that it is possible to enhance WSSS from data generation perspective. IAA mainly design an augmentation agent that leverages large language models (LLMs) and diffusion models to automatically generate additional images for WSSS. In practice, to address the instability in prompt generation by LLMs, we develop a prompt self-refinement mechanism. It allow LLMs to re-evaluate the rationality of generated prompts to produce more coherent prompts. Additionally, we insert an online filter into diffusion generation process to dynamically ensure the quality and balance of generated images. Experimental results show that our method significantly surpasses state-of-the-art WSSS approaches on the PASCAL VOC 2012 and MS COCO 2014 datasets. </p>
<blockquote>
<p>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰ä»…ä½¿ç”¨å›¾åƒçº§æ ‡ç­¾å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„WSSSæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è®¾è®¡æ–°çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°æ¥ç”Ÿæˆæ›´å‡†ç¡®çš„å¯†é›†æ ‡ç­¾ï¼Œè€Œå¿½è§†äº†å›ºå®šæ•°æ®é›†æ‰€å¸¦æ¥çš„é™åˆ¶ï¼Œè¿™äº›é™åˆ¶å¯èƒ½é˜»ç¢æ€§èƒ½çš„æå‡ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæä¾›æ›´å¤šå¯è®­ç»ƒå›¾åƒå¯ä»¥ä¸ºWSSSæä¾›æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œå¹¶å¸®åŠ©æ¨¡å‹ç†è§£æ›´å…¨é¢çš„è¯­ä¹‰æ¨¡å¼ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç§°ä¸ºå›¾åƒå¢å¼ºä»£ç†ï¼ˆIAAï¼‰ï¼Œå®ƒè¡¨æ˜ä»æ•°æ®ç”Ÿæˆçš„è§’åº¦å¢å¼ºWSSSæ˜¯å¯èƒ½çš„ã€‚IAAä¸»è¦è®¾è®¡äº†ä¸€ä¸ªå¢å¼ºä»£ç†ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ä¸ºWSSSç”Ÿæˆé¢å¤–çš„å›¾åƒã€‚åœ¨å®è·µä¸­ï¼Œä¸ºäº†è§£å†³LLMç”Ÿæˆæç¤ºçš„ä¸ç¨³å®šæ€§é—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æç¤ºè‡ªæˆ‘å®Œå–„æœºåˆ¶ã€‚å®ƒå…è®¸LLMé‡æ–°è¯„ä¼°ç”Ÿæˆçš„æç¤ºçš„åˆç†æ€§ï¼Œä»¥äº§ç”Ÿæ›´è¿è´¯çš„æç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥äº†ä¸€ä¸ªåœ¨çº¿è¿‡æ»¤å™¨ï¼Œä»¥åŠ¨æ€ç¡®ä¿ç”Ÿæˆçš„å›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—è¶…è¶Šäº†æœ€æ–°çš„WSSSæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20439v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºå›¾åƒçº§æ ‡ç­¾çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰å·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤šå…³æ³¨è®¾è®¡æ–°ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ä»¥ç”Ÿæˆæ›´å‡†ç¡®çš„å¯†é›†æ ‡ç­¾ï¼Œå¿½è§†äº†å›ºå®šæ•°æ®é›†å¸¦æ¥çš„é™åˆ¶ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºå›¾åƒå¢å¼ºä»£ç†ï¼ˆIAAï¼‰çš„æ–°æ–¹æ³•ï¼Œä»æ•°æ®ç”Ÿæˆè§’åº¦æå‡WSSSæ€§èƒ½ã€‚IAAè®¾è®¡äº†ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆé¢å¤–å›¾åƒçš„å¢å¼ºä»£ç†ã€‚ä¸ºè§£å†³LLMsåœ¨æç¤ºç”Ÿæˆä¸­çš„ä¸ç¨³å®šé—®é¢˜ï¼Œæœ¬æ–‡å¼€å‘äº†ä¸€ç§æç¤ºè‡ªæˆ‘ä¼˜åŒ–æœºåˆ¶ï¼Œä½¿LLMsèƒ½å¤Ÿé‡æ–°è¯„ä¼°ç”Ÿæˆæç¤ºçš„åˆç†æ€§ï¼Œäº§ç”Ÿæ›´è¿è´¯çš„æç¤ºã€‚æ­¤å¤–ï¼Œè¿˜åœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥åœ¨çº¿è¿‡æ»¤å™¨ï¼Œä»¥åŠ¨æ€ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰WSSSæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WSSSå·²å€ŸåŠ©å›¾åƒçº§æ ‡ç­¾å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å›ºå®šæ•°æ®é›†çš„é™åˆ¶å½±å“äº†æ€§èƒ½æå‡ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åä¸ºå›¾åƒå¢å¼ºä»£ç†ï¼ˆIAAï¼‰çš„æ–°æ–¹æ³•ï¼Œä»æ•°æ®ç”Ÿæˆè§’åº¦æå‡WSSSã€‚</li>
<li>IAAåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆé¢å¤–å›¾åƒã€‚</li>
<li>å¼€å‘äº†ä¸€ç§æç¤ºè‡ªæˆ‘ä¼˜åŒ–æœºåˆ¶ï¼Œè§£å†³LLMsåœ¨æç¤ºç”Ÿæˆä¸­çš„ä¸ç¨³å®šé—®é¢˜ã€‚</li>
<li>åœ¨æ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ä¸­æ’å…¥åœ¨çº¿è¿‡æ»¤å™¨ï¼Œç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¹³è¡¡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨PASCAL VOC 2012å’ŒMS COCO 2014æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20439">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-af2a3ebd09a1bf1b97a1d039283df260.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d420af9d7c6e4b553c221ca8efb92b25.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50df88fe53c498b6f64d28ef4ad06123.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a7d6bc9d163130f0f670b8ebe70adb5c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4acc489d52ac34b0db3e21364468b2a6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Decentralized-Unlabeled-Multi-Agent-Navigation-in-Continuous-Space"><a href="#Decentralized-Unlabeled-Multi-Agent-Navigation-in-Continuous-Space" class="headerlink" title="Decentralized Unlabeled Multi-Agent Navigation in Continuous Space"></a>Decentralized Unlabeled Multi-Agent Navigation in Continuous Space</h2><p><strong>Authors:Stepan Dergachev, Konstantin Yakovlev</strong></p>
<p>In this work, we study the problem where a group of mobile agents needs to reach a set of goal locations, but it does not matter which agent reaches a specific goal. Unlike most of the existing works on this topic that typically assume the existence of the centralized planner (or controller) and limit the agentsâ€™ moves to a predefined graph of locations and transitions between them, in this work we focus on the decentralized scenarios, when each agent acts individually relying only on local observations&#x2F;communications and is free to move in arbitrary direction at any time. Our iterative approach involves agents individually selecting goals, exchanging them, planning paths, and at each time step choose actions that balance between progressing along the paths and avoiding collisions. The proposed method is shown to be complete under specific assumptions on how agents progress towards their current goals, and our empirical evaluation demonstrates its superiority over a baseline decentralized navigation approach in success rate (i.e. is able to solve more problem instances under a given time limit) and a comparison with the centralized TSWAP algorithm reveals its efficiency in minimizing trajectory lengths for mission accomplishment. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸€ç»„ç§»åŠ¨ä»£ç†éœ€è¦è¾¾åˆ°ä¸€ç»„ç›®æ ‡ä½ç½®çš„é—®é¢˜ï¼Œä½†å“ªä¸ªä»£ç†è¾¾åˆ°ç‰¹å®šç›®æ ‡å¹¶ä¸é‡è¦ã€‚ä¸å¤§å¤šæ•°å…³äºè¯¥ä¸»é¢˜çš„ç°æœ‰å·¥ä½œä¸åŒï¼Œè¿™äº›å·¥ä½œé€šå¸¸å‡è®¾å­˜åœ¨é›†ä¸­è§„åˆ’å™¨ï¼ˆæˆ–æ§åˆ¶å™¨ï¼‰ï¼Œå¹¶å°†ä»£ç†çš„ç§»åŠ¨é™åˆ¶åœ¨é¢„å…ˆå®šä¹‰çš„ä½ç½®å›¾å’Œå®ƒä»¬ä¹‹é—´çš„è½¬æ¢ä¸Šï¼Œæˆ‘ä»¬çš„å·¥ä½œé‡ç‚¹æ˜¯åœ¨åˆ†æ•£åœºæ™¯ä¸­ï¼Œå½“æ¯ä¸ªä»£ç†åªä¾èµ–å±€éƒ¨è§‚å¯Ÿ&#x2F;é€šä¿¡å•ç‹¬è¡ŒåŠ¨ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ä»»ä½•æ—¶é—´è‡ªç”±åœ°å‘ä»»æ„æ–¹å‘ç§»åŠ¨ã€‚æˆ‘ä»¬çš„è¿­ä»£æ–¹æ³•æ¶‰åŠä»£ç†å•ç‹¬é€‰æ‹©ç›®æ ‡ã€äº¤æ¢ç›®æ ‡ã€è§„åˆ’è·¯å¾„ï¼Œå¹¶åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­é€‰æ‹©è¡ŒåŠ¨ï¼Œåœ¨æ²¿è·¯å¾„è¿›æ­¥å’Œé¿å…ç¢°æ’ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åœ¨ç‰¹å®šå‡è®¾ä¸‹ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æ˜¯å®Œæ•´çš„ï¼Œå…³äºä»£ç†å¦‚ä½•æœç€ä»–ä»¬çš„å½“å‰ç›®æ ‡è¿›æ­¥ã€‚æˆ‘ä»¬çš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œå®ƒåœ¨æˆåŠŸç‡æ–¹é¢ä¼˜äºåŸºæœ¬çš„åˆ†æ•£å¼å¯¼èˆªæ–¹æ³•ï¼ˆå³èƒ½å¤Ÿåœ¨ç»™å®šæ—¶é—´é™åˆ¶å†…è§£å†³æ›´å¤šçš„é—®é¢˜å®ä¾‹ï¼‰ï¼Œä¸é›†ä¸­åŒ–çš„TSWAPç®—æ³•çš„æ¯”è¾ƒè¡¨æ˜ï¼Œå®ƒåœ¨å®Œæˆä½¿å‘½æ—¶æœ€å°åŒ–è½¨è¿¹é•¿åº¦æ–¹é¢çš„æ•ˆç‡å¾ˆé«˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20233v1">PDF</a> This is a pre-print of the paper accepted to ICR 2024. It contains 16   pages, 5 figures, 1 table</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬ç ”ç©¶æ¢è®¨ä¸€ç»„ç§»åŠ¨ä»£ç†éœ€è¦åˆ°è¾¾ä¸€ç»„ç›®æ ‡ä½ç½®çš„é—®é¢˜ï¼Œä½†å“ªä¸ªä»£ç†åˆ°è¾¾ç‰¹å®šç›®æ ‡å¹¶ä¸é‡è¦ã€‚ä¸åŒäºå¤§å¤šæ•°ç°æœ‰å·¥ä½œé€šå¸¸å‡è®¾å­˜åœ¨é›†ä¸­è§„åˆ’å™¨ï¼ˆæˆ–æ§åˆ¶å™¨ï¼‰ï¼Œå¹¶é™åˆ¶ä»£ç†çš„ç§»åŠ¨è‡³é¢„å…ˆå®šä¹‰çš„ä½ç½®å›¾å’Œä½ç½®ä¹‹é—´çš„è½¬æ¢ï¼Œæœ¬ç ”ç©¶é‡ç‚¹å…³æ³¨åˆ†æ•£åœºæ™¯ï¼Œæ¯ä¸ªä»£ç†ä»…ä¾é å±€éƒ¨è§‚å¯Ÿ&#x2F;é€šä¿¡ç‹¬ç«‹è¡ŒåŠ¨ï¼Œä¸”ä»»ä½•æ—¶å€™éƒ½å¯è‡ªç”±åœ°å‘ä»»æ„æ–¹å‘ç§»åŠ¨ã€‚æˆ‘ä»¬çš„è¿­ä»£æ–¹æ³•åŒ…æ‹¬ä»£ç†å•ç‹¬é€‰æ‹©ç›®æ ‡ã€äº¤æ¢ç›®æ ‡ã€è§„åˆ’è·¯å¾„ï¼Œå¹¶åœ¨æ¯ä¸ªæ—¶é—´æ­¥é€‰æ‹©æ—¢èƒ½æ²¿è·¯å¾„å‰è¿›åˆèƒ½é¿å…ç¢°æ’çš„è¡ŒåŠ¨ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨ç‰¹å®šå‡è®¾ä¸‹è¢«è¯æ˜æ˜¯å®Œæ•´çš„ï¼Œä¸”æˆ‘ä»¬çš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œå…¶åœ¨æˆåŠŸç‡ä¸Šä¼˜äºåŸºçº¿åˆ†æ•£å¯¼èˆªæ–¹æ³•ï¼ˆå³ï¼Œåœ¨ç»™å®šçš„æ—¶é—´é™åˆ¶å†…èƒ½å¤Ÿè§£å†³æ›´å¤šçš„é—®é¢˜å®ä¾‹ï¼‰ï¼Œä¸é›†ä¸­åŒ–çš„TSWAPç®—æ³•çš„æ¯”è¾ƒåˆ™æ˜¾ç¤ºå‡ºå…¶åœ¨å®Œæˆä½¿å‘½æ—¶æœ€å°åŒ–è½¨è¿¹é•¿åº¦çš„æ•ˆç‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶çš„æ˜¯ç§»åŠ¨ä»£ç†ç¾¤ä½“è¾¾åˆ°ä¸€ç³»åˆ—ç›®æ ‡ä½ç½®çš„é—®é¢˜ï¼Œé‡ç‚¹åœ¨åˆ†æ•£åœºæ™¯ï¼Œå³æ¯ä¸ªä»£ç†ç‹¬ç«‹è¡ŒåŠ¨ï¼Œå¯è‡ªç”±åœ°å‘ä»»æ„æ–¹å‘ç§»åŠ¨ã€‚</li>
<li>æå‡ºä¸€ç§è¿­ä»£æ–¹æ³•ï¼ŒåŒ…æ‹¬ä»£ç†é€‰æ‹©ç›®æ ‡ã€äº¤æ¢ç›®æ ‡ã€è§„åˆ’è·¯å¾„ï¼Œå¹¶å¹³è¡¡æ²¿è·¯å¾„å‰è¿›å’Œé¿å…ç¢°æ’çš„è¡ŒåŠ¨é€‰æ‹©ã€‚</li>
<li>æ–¹æ³•çš„å®Œæ•´æ€§åœ¨ç‰¹å®šå‡è®¾ä¸‹å¾—åˆ°éªŒè¯ã€‚</li>
<li>ç›¸è¾ƒäºåŸºçº¿åˆ†æ•£å¯¼èˆªæ–¹æ³•ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æˆåŠŸç‡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</li>
<li>ä¸é›†ä¸­åŒ–çš„TSWAPç®—æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æœ€å°åŒ–è½¨è¿¹é•¿åº¦æ–¹é¢å±•ç°å‡ºæ•ˆç‡ã€‚</li>
<li>ç ”ç©¶å¤„ç†äº†å“ªäº›ä»£ç†è¾¾åˆ°ç‰¹å®šç›®æ ‡å¹¶ä¸é‡è¦çš„é—®é¢˜ï¼Œå¢åŠ äº†åº”ç”¨åœºæ™¯çš„å®ç”¨æ€§ã€‚</li>
<li>åœ¨å¤„ç†åˆ†æ•£ç§»åŠ¨ä»£ç†é—®é¢˜æ—¶ï¼Œè€ƒè™‘åˆ°äº†å±€éƒ¨è§‚å¯Ÿå’Œé€šä¿¡çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20233">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-af4856b755d8707159c1cc656e6f0bb1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-da52d5e22b3774e4c45eee121197ff96.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93ff7756c89fca97fd5cba24fefef31f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ffec01be392091fa13c1d2d69be15c46.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Efficient-Multi-Agent-Collaboration-with-Tool-Use-for-Online-Planning-in-Complex-Table-Question-Answering"><a href="#Efficient-Multi-Agent-Collaboration-with-Tool-Use-for-Online-Planning-in-Complex-Table-Question-Answering" class="headerlink" title="Efficient Multi-Agent Collaboration with Tool Use for Online Planning in   Complex Table Question Answering"></a>Efficient Multi-Agent Collaboration with Tool Use for Online Planning in   Complex Table Question Answering</h2><p><strong>Authors:Wei Zhou, Mohsen Mesgar, Annemarie Friedrich, Heike Adel</strong></p>
<p>Complex table question answering (TQA) aims to answer questions that require complex reasoning, such as multi-step or multi-category reasoning, over data represented in tabular form. Previous approaches demonstrated notable performance by leveraging either closed-source large language models (LLMs) or fine-tuned open-weight LLMs. However, fine-tuning LLMs requires high-quality training data, which is costly to obtain, and utilizing closed-source LLMs poses accessibility challenges and leads to reproducibility issues. In this paper, we propose Multi-Agent Collaboration with Tool use (MACT), a framework that requires neither closed-source models nor fine-tuning. In MACT, a planning agent and a coding agent that also make use of tools collaborate to answer questions. Our experiments on four TQA benchmarks show that MACT outperforms previous SoTA systems on three out of four benchmarks and that it performs comparably to the larger and more expensive closed-source model GPT-4 on two benchmarks, even when using only open-weight models without any fine-tuning. We conduct extensive analyses to prove the effectiveness of MACTâ€™s multi-agent collaboration in TQA. </p>
<blockquote>
<p>å¤æ‚è¡¨æ ¼é—®ç­”ï¼ˆTQAï¼‰æ—¨åœ¨å›ç­”éœ€è¦å¤æ‚æ¨ç†çš„é—®é¢˜ï¼Œå¦‚å¤šæ­¥éª¤æˆ–å¤šç±»åˆ«æ¨ç†ï¼Œè¿™äº›é—®é¢˜æ¶‰åŠä»¥è¡¨æ ¼å½¢å¼å‘ˆç°çš„æ•°æ®ã€‚ä¹‹å‰çš„æ–¹æ³•é€šè¿‡åˆ©ç”¨å°é—­çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æˆ–å¾®è°ƒå¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¥å±•ç¤ºæ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹éœ€è¦é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€Œè¿™äº›æ•°æ®çš„è·å–æˆæœ¬å¾ˆé«˜ï¼Œè€Œåˆ©ç”¨å°é—­çš„å¤§å‹è¯­è¨€æ¨¡å‹åˆ™å¸¦æ¥äº†å¯è®¿é—®æ€§æŒ‘æˆ˜å’Œå¯é‡å¤æ€§é—®é¢˜çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸éœ€è¦å°é—­æ¨¡å‹æˆ–å¾®è°ƒçš„å¤šæ™ºèƒ½ä½“åä½œå·¥å…·ä½¿ç”¨ï¼ˆMACTï¼‰æ¡†æ¶ã€‚åœ¨MACTä¸­ï¼Œä¸€ä¸ªè§„åˆ’æ™ºèƒ½ä½“å’Œä¸€ä¸ªä½¿ç”¨å·¥å…·çš„ç¼–ç æ™ºèƒ½ä½“ç›¸äº’åä½œæ¥å›ç­”é—®é¢˜ã€‚æˆ‘ä»¬åœ¨å››ä¸ªTQAåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMACTåœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¿‡äº†ä»¥å‰çš„æœ€å…ˆè¿›çš„ç³»ç»Ÿï¼Œå¹¶ä¸”åœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šä¸æ›´å¤§ã€æ›´æ˜‚è´µçš„å°é—­æ¨¡å‹GPT-4è¡¨ç°ç›¸å½“ï¼Œå³ä½¿æˆ‘ä»¬åªä½¿ç”¨æœªè¿›è¡Œä»»ä½•å¾®è°ƒçš„å¼€æºæ¨¡å‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„åˆ†æï¼Œä»¥è¯æ˜MACTåœ¨TQAä¸­çš„å¤šæ™ºèƒ½ä½“åä½œçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20145v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤æ‚è¡¨æ ¼é—®ç­”ï¼ˆTQAï¼‰æ—¨åœ¨å›ç­”éœ€è¦å¤æ‚æ¨ç†çš„é—®é¢˜ï¼Œå¦‚å¤šæ­¥éª¤æˆ–å¤šç±»åˆ«æ¨ç†ï¼Œæ¶‰åŠè¡¨æ ¼å½¢å¼çš„æ•°æ®ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡åˆ©ç”¨å°é—­æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æˆ–å¾®è°ƒå¼€æ”¾æƒé‡LLMså–å¾—äº†æ˜¾è‘—æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¾®è°ƒLLMséœ€è¦é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œæˆæœ¬é«˜æ˜‚ï¼Œä½¿ç”¨å°é—­æºLLMså¸¦æ¥è®¿é—®æŒ‘æˆ˜å’Œå¯é‡å¤æ€§é—®é¢˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ— éœ€å°é—­æºæ¨¡å‹å’Œå¾®è°ƒçš„å¤šæ™ºèƒ½ä½“åä½œå·¥å…·ä½¿ç”¨ï¼ˆMACTï¼‰æ¡†æ¶ã€‚åœ¨MACTä¸­ï¼Œè§„åˆ’æ™ºèƒ½ä½“å’Œç¼–ç æ™ºèƒ½ä½“åˆ©ç”¨å·¥å…·è¿›è¡Œåä½œå›ç­”é—®é¢˜ã€‚åœ¨å››ä¸ªTQAåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMACTåœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›ç³»ç»Ÿï¼Œå¹¶åœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šä¸æ›´å¤§ã€æ›´æ˜‚è´µçš„å°é—­æºæ¨¡å‹GPT-4è¡¨ç°ç›¸å½“ï¼Œå³ä½¿ä½¿ç”¨çš„æ˜¯æœªç»ä»»ä½•å¾®è°ƒçš„å¼€æ”¾æƒé‡æ¨¡å‹ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„åˆ†æï¼Œä»¥è¯æ˜MACTåœ¨TQAä¸­çš„å¤šæ™ºèƒ½ä½“åä½œçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤æ‚è¡¨æ ¼é—®ç­”ï¼ˆTQAï¼‰æ—¨åœ¨è§£å†³éœ€è¦å¤æ‚æ¨ç†çš„è¡¨æ ¼æ•°æ®é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å°é—­æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æˆ–å¾®è°ƒå¼€æ”¾æƒé‡LLMsï¼Œä½†å­˜åœ¨æˆæœ¬é«˜æ˜‚å’Œå¯è®¿é—®æ€§é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”å¤šæ™ºèƒ½ä½“åä½œå·¥å…·ä½¿ç”¨ï¼ˆMACTï¼‰ï¼Œæ— éœ€å°é—­æºæ¨¡å‹å’Œå¾®è°ƒã€‚</li>
<li>åœ¨MACTæ¡†æ¶ä¸­ï¼Œè§„åˆ’æ™ºèƒ½ä½“å’Œç¼–ç æ™ºèƒ½ä½“åˆ©ç”¨å·¥å…·è¿›è¡Œåä½œä»¥å›ç­”é—®é¢˜ã€‚</li>
<li>åœ¨å››ä¸ªTQAåŸºå‡†æµ‹è¯•ä¸Šï¼ŒMACTåœ¨å¤šæ•°æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›ç³»ç»Ÿã€‚</li>
<li>MACTä¸å¤§å‹ã€æ˜‚è´µçš„å°é—­æºæ¨¡å‹GPT-4åœ¨éƒ¨åˆ†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ç›¸å½“ï¼Œå³ä½¿ä½¿ç”¨çš„æ˜¯æœªç»å¾®è°ƒçš„å¼€æ”¾æƒé‡æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20145">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-97c15f3c1c40b0bf1fcefa1e17e84ab7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9ff54fdedc85588a69d58307a27e892.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1dcbae7245c8a605356ab1b6446a4c9e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a1348f77e13343fbd0e56bd3d3ecd5c9.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="TradingAgents-Multi-Agents-LLM-Financial-Trading-Framework"><a href="#TradingAgents-Multi-Agents-LLM-Financial-Trading-Framework" class="headerlink" title="TradingAgents: Multi-Agents LLM Financial Trading Framework"></a>TradingAgents: Multi-Agents LLM Financial Trading Framework</h2><p><strong>Authors:Yijia Xiao, Edward Sun, Di Luo, Wei Wang</strong></p>
<p>Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systemsâ€™ potential to replicate real-world trading firmsâ€™ collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. </p>
<blockquote>
<p>åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“ç¤¾ä¼šè¿›è¡Œè‡ªåŠ¨åŒ–é—®é¢˜è§£å†³æ–¹é¢ï¼Œå·²ç»å–å¾—äº†é‡å¤§è¿›å±•ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œç›¸å…³åŠªåŠ›ä¸»è¦é›†ä¸­åœ¨å¤„ç†ç‰¹å®šä»»åŠ¡çš„å•ä¸€æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæˆ–ç‹¬ç«‹æ”¶é›†æ•°æ®çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¸Šã€‚ç„¶è€Œï¼Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤åˆ¶ç°å®ä¸–ç•Œäº¤æ˜“å…¬å¸çš„åä½œåŠ¨æ€æ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚TradingAgentsæå‡ºäº†ä¸€ä¸ªå—äº¤æ˜“å…¬å¸å¯å‘çš„è‚¡ç¥¨äº¤æ˜“æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…·æœ‰ä¸“é—¨è§’è‰²çš„LLMé©±åŠ¨çš„æ™ºèƒ½ä½“ï¼Œå¦‚åŸºæœ¬é¢åˆ†æå¸ˆã€æƒ…ç»ªåˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆå’Œå…·æœ‰ä¸åŒé£é™©ç‰¹å¾çš„äº¤æ˜“å‘˜ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ç‰›å¸‚å’Œç†Šå¸‚ç ”ç©¶äººå‘˜æ™ºèƒ½ä½“å¯¹å¸‚åœºæ¡ä»¶è¿›è¡Œè¯„ä¼°ã€é£é™©ç®¡ç†å›¢é˜Ÿç›‘æ§æ›å…‰æƒ…å†µã€äº¤æ˜“å‘˜ç»¼åˆè¾©è®ºå’Œå†å²æ•°æ®æ¥åšå‡ºæ˜æ™ºå†³ç­–ã€‚é€šè¿‡æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œæ­¤æ¡†æ¶æ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚è¯¦ç»†çš„æ¶æ„å’Œå¹¿æ³›çš„å®éªŒæ˜¾ç¤ºå…¶åœ¨åŸºå‡†æ¨¡å‹ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œç´¯ç§¯æ”¶ç›Šã€å¤æ™®æ¯”ç‡ä»¥åŠæœ€å¤§å›æ’¤æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ”¹å–„ï¼Œè¿™çªæ˜¾äº†å¤šæ™ºèƒ½ä½“LLMæ¡†æ¶åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20138v1">PDF</a> Multi-Agent AI in the Real World, AAAI 2025</p>
<p><strong>Summary</strong>ï¼šåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç¤¾ä¼šåœ¨è‡ªåŠ¨åŒ–é—®é¢˜è§£å†³æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œå°½ç®¡å•ä»£ç†ç³»ç»Ÿå¤„ç†ç‰¹å®šä»»åŠ¡æˆ–å¤šä»£ç†æ¡†æ¶ç‹¬ç«‹æ”¶é›†æ•°æ®çš„å·¥ä½œå·²å¾—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†å¤šä»£ç†ç³»ç»Ÿå¤åˆ¶ç°å®ä¸–ç•Œäº¤æ˜“å…¬å¸åä½œåŠ¨åŠ›çš„æ½œåŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚TradingAgentsæå‡ºä¸€ä¸ªå—äº¤æ˜“å…¬å¸å¯å‘çš„è‚¡ç¥¨äº¤æ˜“æ–°æ¡†æ¶ï¼Œå…¶ä¸­åŒ…å«ç”±LLMé©±åŠ¨çš„ä¸“é—¨ä»äº‹å„ç§è§’è‰²çš„ä»£ç†ï¼Œå¦‚åŸºæœ¬é¢åˆ†æå¸ˆã€æƒ…ç»ªåˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆå’Œå…·æœ‰ä¸åŒé£é™©é…ç½®çš„äº¤æ˜“å‘˜ã€‚è¯¥æ¡†æ¶æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œæ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚è¯¦ç»†çš„æ¶æ„å’Œå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä¸åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨ç´¯è®¡å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œçªæ˜¾äº†å¤šä»£ç†LLMæ¡†æ¶åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ä»£ç†ç¤¾ä¼šåœ¨è‡ªåŠ¨åŒ–é—®é¢˜è§£å†³ä¸Šå–å¾—æ˜¾è‘—è¿›æ­¥ã€‚</li>
<li>é‡‘èé¢†åŸŸä¸­çš„å¤šä»£ç†ç³»ç»Ÿæ½œåŠ›æœªè¢«å……åˆ†æ¢ç´¢ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤åˆ¶äº¤æ˜“å…¬å¸çš„åä½œåŠ¨åŠ›æ–¹é¢ã€‚</li>
<li>TradingAgentsæ¡†æ¶å—åˆ°çœŸå®äº¤æ˜“å…¬å¸çš„å¯å‘ï¼ŒåŒ…å«å¤šç§è§’è‰²ä»£ç†ï¼Œå¦‚åŸºæœ¬é¢ã€æƒ…ç»ªå’ŒæŠ€æœ¯åˆ†æå¸ˆä»¥åŠäº¤æ˜“å‘˜ã€‚</li>
<li>è¯¥æ¡†æ¶æ¨¡æ‹ŸåŠ¨æ€ã€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œæ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚</li>
<li>è¯¦ç»†æ¶æ„å’Œå¹¿æ³›å®éªŒæ˜¾ç¤ºè¯¥æ¡†æ¶åœ¨ç´¯è®¡å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚</li>
<li>è¯¥æ¡†æ¶å¼ºè°ƒé£é™©ç®¡ç†çš„é‡è¦æ€§ï¼Œæœ‰ä¸“é—¨çš„é£é™©ç®¡ç†å›¢é˜Ÿç›‘æ§æš´éœ²æƒ…å†µã€‚</li>
<li>æ¡†æ¶ä¸­çš„ä»£ç†é€šè¿‡è¾©è®ºå’Œå†å²æ•°æ®åˆæˆè§è§£ä»¥åšå‡ºå†³ç­–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20138">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-27f6dfe5441ef4fc6bd44f7e15c7907b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b30fff5ccc871c8eb463e0482df36120.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-25633305684d8ad1c87d09dcdbe8556b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d197b1f9955d8a4274d4868459c4e223.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2392627f16ccbb5128eef44ea40c6a0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="M-MAD-Multidimensional-Multi-Agent-Debate-Framework-for-Fine-grained-Machine-Translation-Evaluation"><a href="#M-MAD-Multidimensional-Multi-Agent-Debate-Framework-for-Fine-grained-Machine-Translation-Evaluation" class="headerlink" title="M-MAD: Multidimensional Multi-Agent Debate Framework for Fine-grained   Machine Translation Evaluation"></a>M-MAD: Multidimensional Multi-Agent Debate Framework for Fine-grained   Machine Translation Evaluation</h2><p><strong>Authors:Zhaopeng Feng, Jiayuan Su, Jiamei Zheng, Jiahan Ren, Yan Zhang, Jian Wu, Hongwei Wang, Zuozhu Liu</strong></p>
<p>Recent advancements in large language models (LLMs) have given rise to the LLM-as-a-judge paradigm, showcasing their potential to deliver human-like judgments. However, in the field of machine translation (MT) evaluation, current LLM-as-a-judge methods fall short of learned automatic metrics. In this paper, we propose Multidimensional Multi-Agent Debate (M-MAD), a systematic LLM-based multi-agent framework for advanced LLM-as-a-judge MT evaluation. Our findings demonstrate that M-MAD achieves significant advancements by (1) decoupling heuristic MQM criteria into distinct evaluation dimensions for fine-grained assessments; (2) employing multi-agent debates to harness the collaborative reasoning capabilities of LLMs; (3) synthesizing dimension-specific results into a final evaluation judgment to ensure robust and reliable outcomes. Comprehensive experiments show that M-MAD not only outperforms all existing LLM-as-a-judge methods but also competes with state-of-the-art reference-based automatic metrics, even when powered by a suboptimal model like GPT-4o mini. Detailed ablations and analysis highlight the superiority of our framework design, offering a fresh perspective for LLM-as-a-judge paradigm. Our code and data are publicly available at <a target="_blank" rel="noopener" href="https://github.com/SU-JIAYUAN/M-MAD">https://github.com/SU-JIAYUAN/M-MAD</a>. </p>
<blockquote>
<p>æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å‚¬ç”Ÿäº†LLMä½œä¸ºè¯„åˆ¤å‘˜çš„èŒƒå¼ï¼Œå±•ç¤ºäº†å®ƒä»¬æä¾›ç±»ä¼¼äººç±»çš„åˆ¤æ–­åŠ›çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œåœ¨æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰è¯„ä¼°é¢†åŸŸï¼Œå½“å‰çš„LLMä½œä¸ºè¯„åˆ¤å‘˜çš„æ–¹æ³•è¿˜è¾¾ä¸åˆ°å­¦ä¹ åˆ°çš„è‡ªåŠ¨åº¦é‡æ ‡å‡†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šç»´åº¦å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆM-MADï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºå…ˆè¿›çš„LLMä½œä¸ºè¯„åˆ¤å‘˜çš„MTè¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼ŒM-MADé€šè¿‡ä»¥ä¸‹æ–¹å¼å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼šï¼ˆ1ï¼‰å°†å¯å‘å¼MQMæ ‡å‡†è§£è€¦ä¸ºä¸åŒçš„è¯„ä¼°ç»´åº¦ï¼Œè¿›è¡Œç²¾ç»†åŒ–çš„è¯„ä¼°ï¼›ï¼ˆ2ï¼‰åˆ©ç”¨å¤šæ™ºèƒ½ä½“è¾©è®ºæ¥åˆ©ç”¨LLMçš„ååŒæ¨ç†èƒ½åŠ›ï¼›ï¼ˆ3ï¼‰å°†ç‰¹å®šç»´åº¦çš„ç»“æœç»¼åˆæˆæœ€ç»ˆçš„è¯„ä¼°åˆ¤æ–­ï¼Œä»¥ç¡®ä¿ç¨³å¥å’Œå¯é çš„ç»“æœã€‚å…¨é¢çš„å®éªŒè¡¨æ˜ï¼ŒM-MADä¸ä»…ä¼˜äºæ‰€æœ‰ç°æœ‰çš„LLMä½œä¸ºè¯„åˆ¤å‘˜çš„æ–¹æ³•ï¼Œè€Œä¸”ä¸æœ€æ–°çš„å‚è€ƒåŸºå‡†è‡ªåŠ¨åº¦é‡æ ‡å‡†ç›¸ç«äº‰ï¼Œå³ä½¿åœ¨åƒGPT-4o miniè¿™æ ·çš„æ¬¡ä¼˜æ¨¡å‹é©±åŠ¨ä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¯¦ç»†çš„æ¶ˆèå®éªŒå’Œåˆ†æçªæ˜¾äº†æˆ‘ä»¬æ¡†æ¶è®¾è®¡çš„ä¼˜è¶Šæ€§ï¼Œä¸ºLLMä½œä¸ºè¯„åˆ¤å‘˜èŒƒå¼æä¾›äº†æ–°çš„è§†è§’ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®åœ¨<a target="_blank" rel="noopener" href="https://github.com/SU-JIAYUAN/M-MAD%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/SU-JIAYUAN/M-MADå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20127v1">PDF</a> Work in progress. Code and data are available at   <a target="_blank" rel="noopener" href="https://github.com/SU-JIAYUAN/M-MAD">https://github.com/SU-JIAYUAN/M-MAD</a></p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•å‚¬ç”Ÿäº†LLMä½œä¸ºè¯„åˆ¤è€…çš„æ¨¡å¼ï¼Œå±•ç°å‡ºå®ƒä»¬æä¾›ç±»ä¼¼äººç±»åˆ¤æ–­çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰è¯„ä¼°é¢†åŸŸï¼Œå½“å‰LLMä½œä¸ºè¯„åˆ¤è€…çš„æ–¹æ³•ç›¸è¾ƒäºè‡ªåŠ¨è¯„ä»·æŒ‡æ ‡æœ‰æ‰€ä¸è¶³ã€‚æœ¬æ–‡æå‡ºäº†å¤šç»´åº¦å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆM-MADï¼‰ç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºé«˜çº§LLMä½œä¸ºè¯„åˆ¤è€…çš„MTè¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼ŒM-MADé€šè¿‡å°†å¯å‘å¼MQMæ ‡å‡†è§£è€¦ä¸ºä¸åŒçš„è¯„ä¼°ç»´åº¦è¿›è¡Œç²¾ç»†è¯„ä¼°ã€åˆ©ç”¨å¤šæ™ºèƒ½ä½“è¾©è®ºå‘æŒ¥LLMçš„ååŒæ¨ç†èƒ½åŠ›ã€ä»¥åŠåˆæˆç‰¹å®šç»´åº¦çš„ç»“æœä»¥è¿›è¡Œæœ€ç»ˆè¯„ä¼°åˆ¤æ–­ï¼Œå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚è¿™ä¸ºLLMä½œä¸ºè¯„åˆ¤è€…çš„æ¨¡å¼æä¾›äº†æ–°çš„è§†è§’ã€‚ä»£ç å’Œæ•°æ®å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMçš„å‘å±•æ¨åŠ¨äº†LLMä½œä¸ºè¯„åˆ¤è€…æ¨¡å¼çš„å…´èµ·ï¼Œå…·æœ‰æä¾›ç±»ä¼¼äººç±»åˆ¤æ–­çš„èƒ½åŠ›ã€‚</li>
<li>å½“å‰LLMä½œä¸ºè¯„åˆ¤è€…åœ¨æœºå™¨ç¿»è¯‘è¯„ä¼°é¢†åŸŸä¸è‡ªåŠ¨è¯„ä»·æŒ‡æ ‡å­˜åœ¨å·®è·ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„LLMå¤šæ™ºèƒ½ä½“æ¡†æ¶â€”â€”å¤šç»´åº¦å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆM-MADï¼‰ç³»ç»Ÿï¼Œç”¨äºé«˜çº§LLMä½œä¸ºè¯„åˆ¤è€…çš„æœºå™¨ç¿»è¯‘è¯„ä¼°ã€‚</li>
<li>M-MADé€šè¿‡å°†å¯å‘å¼MQMæ ‡å‡†è§£è€¦ä¸ºä¸åŒçš„è¯„ä¼°ç»´åº¦æ¥ç²¾ç»†è¯„ä¼°ç¿»è¯‘è´¨é‡ã€‚</li>
<li>M-MADåˆ©ç”¨å¤šæ™ºèƒ½ä½“è¾©è®ºå‘æŒ¥LLMçš„ååŒæ¨ç†èƒ½åŠ›ï¼Œæé«˜äº†è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</li>
<li>M-MADçš„åˆæˆæ–¹æ³•ç¡®ä¿äº†è¯„ä¼°ç»“æœçš„ç¨³å¥æ€§å’Œå¯é æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20127">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0360d02203efe010a06223a610434e08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d96af466d06a528645f037bff389378.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-006fa58a06f82237ab10cae2d452d7ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-35f52e05ec06a077c8fcf4f25a2e9c8b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ee67441c71a8b5fc0f1995eac6af404.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-74d94cb7b0d44669785cecea34c009a8.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Towards-Human-AI-Synergy-in-UI-Design-Enhancing-Multi-Agent-Based-UI-Generation-with-Intent-Clarification-and-Alignment"><a href="#Towards-Human-AI-Synergy-in-UI-Design-Enhancing-Multi-Agent-Based-UI-Generation-with-Intent-Clarification-and-Alignment" class="headerlink" title="Towards Human-AI Synergy in UI Design: Enhancing Multi-Agent Based UI   Generation with Intent Clarification and Alignment"></a>Towards Human-AI Synergy in UI Design: Enhancing Multi-Agent Based UI   Generation with Intent Clarification and Alignment</h2><p><strong>Authors:Mingyue Yuan, Jieshan Chen, Yongquan Hu, Sidong Feng, Mulong Xie, Gelareh Mohammadi, Zhenchang Xing, Aaron Quigley</strong></p>
<p>In automated user interface (UI) design generation, a key challenge is the lack of support for iterative processes, as most systems only focus on end-to-end generation of designs as starting points. This results from (1) limited capabilities to fully interpret user design intent from text or images, and (2) a lack of transparency, which prevents designers from refining intermediate results. To address existing limitations, we introduce PrototypeAgent, a human-centered, multi-agent system for automated UI generation. The core of PrototypeAgent is a theme design agent that clarifies implicit design intent through prompt augmentation, coordinating with specialized sub-agents to generate specific components. Designers interact with the system via an intuitive interface, providing natural language descriptions and layout preferences. During generation, PrototypeAgent enables designers to refine generated intermediate guidance or specific components, ensuring alignment with their intent throughout the generation workflow. Evaluations through experiments and user studies show PrototypeAgentâ€™s effectiveness in producing high-fidelity prototypes that accurately reflect design intent as well as its superiority over baseline models in terms of both quality and diversity. </p>
<blockquote>
<p>åœ¨è‡ªåŠ¨åŒ–ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰è®¾è®¡ç”Ÿæˆé¢†åŸŸï¼Œä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯ç¼ºä¹è¿­ä»£è¿‡ç¨‹çš„æ”¯æŒï¼Œå› ä¸ºå¤§å¤šæ•°ç³»ç»Ÿåªå…³æ³¨ä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„è®¾è®¡ç”Ÿæˆã€‚è¿™æºäºï¼ˆ1ï¼‰ä»æ–‡æœ¬æˆ–å›¾åƒå…¨é¢è§£è¯»ç”¨æˆ·è®¾è®¡æ„å›¾çš„èƒ½åŠ›æœ‰é™ï¼Œï¼ˆ2ï¼‰ç¼ºä¹é€æ˜åº¦ï¼Œå¯¼è‡´è®¾è®¡å¸ˆæ— æ³•å¯¹ä¸­é—´ç»“æœè¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚ä¸ºäº†è§£å†³ç°æœ‰å±€é™æ€§ï¼Œæˆ‘ä»¬æ¨å‡ºäº†PrototypeAgentï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥äººç±»ä¸ºä¸­å¿ƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç”¨äºè‡ªåŠ¨åŒ–UIç”Ÿæˆã€‚PrototypeAgentçš„æ ¸å¿ƒæ˜¯ä¸»é¢˜è®¾è®¡æ™ºèƒ½ä½“ï¼Œå®ƒé€šè¿‡æç¤ºå¢å¼ºæ¥æ˜ç¡®éšå«çš„è®¾è®¡æ„å›¾ï¼Œå¹¶ä¸ä¸“ä¸šå­æ™ºèƒ½ä½“åè°ƒä»¥ç”Ÿæˆç‰¹å®šç»„ä»¶ã€‚è®¾è®¡å¸ˆé€šè¿‡ç›´è§‚ç•Œé¢ä¸ç³»ç»Ÿäº¤äº’ï¼Œæä¾›è‡ªç„¶è¯­è¨€æè¿°å’Œå¸ƒå±€åå¥½ã€‚åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒPrototypeAgentå…è®¸è®¾è®¡å¸ˆå¯¹ç”Ÿæˆçš„ä¸­é—´æŒ‡å¯¼æˆ–ç‰¹å®šç»„ä»¶è¿›è¡Œå¾®è°ƒï¼Œç¡®ä¿åœ¨æ•´ä¸ªç”Ÿæˆå·¥ä½œæµç¨‹ä¸­ä¸ä»–ä»¬çš„æ„å›¾ä¿æŒä¸€è‡´ã€‚é€šè¿‡å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒPrototypeAgentåœ¨ç”Ÿæˆé«˜ä¿çœŸåŸå‹æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œèƒ½å¤Ÿå‡†ç¡®åæ˜ è®¾è®¡æ„å›¾ï¼ŒåŒæ—¶åœ¨è´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20071v1">PDF</a> 21 pages,9 figures</p>
<p><strong>Summary</strong>ï¼š<br>è‡ªåŠ¨åŒ–ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰è®¾è®¡ç”Ÿæˆä¸­é¢ä¸´çš„å…³é”®æŒ‘æˆ˜æ˜¯ç¼ºä¹è¿­ä»£è¿‡ç¨‹çš„æ”¯æŒï¼Œå¤§å¤šæ•°ç³»ç»Ÿä»…å…³æ³¨è®¾è®¡çš„ç«¯å¯¹ç«¯ç”Ÿæˆä½œä¸ºèµ·ç‚¹ã€‚ä¸ºè§£å†³ç°æœ‰å±€é™æ€§ï¼Œæˆ‘ä»¬æ¨å‡ºPrototypeAgentâ€”â€”ä¸€ç§ä»¥äººä¸ºæœ¬ã€å¤šä»£ç†çš„è‡ªåŠ¨åŒ–UIç”Ÿæˆç³»ç»Ÿã€‚å…¶æ ¸å¿ƒæ˜¯ä¸»é¢˜è®¾è®¡ä»£ç†ï¼Œé€šè¿‡æç¤ºå¢å¼ºæ¥æ˜ç¡®éšå«çš„è®¾è®¡æ„å›¾ï¼Œå¹¶ä¸ä¸“ä¸šå­ä»£ç†åè°ƒç”Ÿæˆç‰¹å®šç»„ä»¶ã€‚è®¾è®¡å¸ˆé€šè¿‡ç›´è§‚ç•Œé¢ä¸ç³»ç»Ÿäº¤äº’ï¼Œæä¾›è‡ªç„¶è¯­è¨€æè¿°å’Œå¸ƒå±€åå¥½ã€‚PrototypeAgentåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä½¿è®¾è®¡å¸ˆèƒ½å¤Ÿç»†åŒ–ç”Ÿæˆçš„ä¸­é—´æŒ‡å¯¼æˆ–ç‰¹å®šç»„ä»¶ï¼Œç¡®ä¿æ•´ä¸ªç”Ÿæˆå·¥ä½œæµç¨‹ä¸ä»–ä»¬çš„æ„å›¾ä¿æŒä¸€è‡´ã€‚å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¯„ä¼°è¡¨æ˜ï¼ŒPrototypeAgentåœ¨ç”Ÿæˆé«˜è´¨é‡ã€é«˜ä¿çœŸåº¦çš„åŸå‹æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œèƒ½å¤Ÿå‡†ç¡®åæ˜ è®¾è®¡æ„å›¾ï¼Œå¹¶ä¸”åœ¨è´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è‡ªåŠ¨åŒ–UIè®¾è®¡ç”Ÿæˆé¢ä¸´æŒ‘æˆ˜ï¼šç¼ºä¹è¿­ä»£è¿‡ç¨‹æ”¯æŒï¼Œç³»ç»Ÿä¸»è¦å…³æ³¨ç«¯å¯¹ç«¯ç”Ÿæˆã€‚</li>
<li>PrototypeAgentæ˜¯ä¸€ä¸ªä»¥äººä¸ºæœ¬ã€å¤šä»£ç†çš„è‡ªåŠ¨åŒ–UIç”Ÿæˆç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æŒ‘æˆ˜ã€‚</li>
<li>PrototypeAgentçš„æ ¸å¿ƒæ˜¯ä¸»é¢˜è®¾è®¡ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡æç¤ºå¢å¼ºæ˜ç¡®éšå«çš„è®¾è®¡æ„å›¾ã€‚</li>
<li>PrototypeAgenté…å¤‡ä¸“ä¸šå­ä»£ç†ï¼Œç”¨äºç”Ÿæˆç‰¹å®šç»„ä»¶ã€‚</li>
<li>è®¾è®¡å¸ˆé€šè¿‡ç›´è§‚ç•Œé¢ä¸PrototypeAgentäº¤äº’ï¼Œæä¾›è‡ªç„¶è¯­è¨€æè¿°å’Œå¸ƒå±€åå¥½ã€‚</li>
<li>PrototypeAgentå…è®¸è®¾è®¡å¸ˆåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç»†åŒ–ä¸­é—´ç»“æœæˆ–ç‰¹å®šç»„ä»¶ï¼Œä»¥ç¬¦åˆå…¶æ„å›¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20071">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fc3c4fab89d0be54deed079c752848e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07185a2036dc88336eb140679275af1f.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="OneKE-A-Dockerized-Schema-Guided-LLM-Agent-based-Knowledge-Extraction-System"><a href="#OneKE-A-Dockerized-Schema-Guided-LLM-Agent-based-Knowledge-Extraction-System" class="headerlink" title="OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction   System"></a>OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction   System</h2><p><strong>Authors:Yujie Luo, Xiangyuan Ru, Kangwei Liu, Lin Yuan, Mengshu Sun, Ningyu Zhang, Lei Liang, Zhiqiang Zhang, Jun Zhou, Lanning Wei, Da Zheng, Haofen Wang, Huajun Chen</strong></p>
<p>We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKEâ€™s efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code at <a target="_blank" rel="noopener" href="https://github.com/zjunlp/OneKE">https://github.com/zjunlp/OneKE</a> and released a Video at <a target="_blank" rel="noopener" href="http://oneke.openkg.cn/demo.mp4">http://oneke.openkg.cn/demo.mp4</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»OneKEï¼Œè¿™æ˜¯ä¸€ä¸ªDockeråŒ–çš„schemaå¼•å¯¼çŸ¥è¯†æå–ç³»ç»Ÿï¼Œå¯ä»¥ä»ç½‘é¡µå’ŒåŸå§‹PDFä¹¦ç±ä¸­æå–çŸ¥è¯†ï¼Œå¹¶æ”¯æŒå¤šä¸ªé¢†åŸŸï¼ˆå¦‚ç§‘å­¦ã€æ–°é—»ç­‰ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡OneKEæ—¶é‡‡ç”¨äº†å¤šä¸ªä»£ç†å’Œä¸€ä¸ªé…ç½®çŸ¥è¯†åº“ã€‚ä¸åŒçš„ä»£ç†æ‰§è¡Œå„è‡ªçš„è§’è‰²ï¼Œä¸ºå„ç§æå–åœºæ™¯æä¾›æ”¯æŒã€‚é…ç½®çŸ¥è¯†åº“æœ‰åŠ©äºæ¨¡å¼é…ç½®ã€é”™è¯¯æƒ…å†µè°ƒè¯•å’Œä¿®æ­£ï¼Œä»è€Œè¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„ç»éªŒè¯„ä¼°è¯æ˜äº†OneKEçš„æœ‰æ•ˆæ€§ï¼Œè€Œæ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¯´æ˜äº†å®ƒåœ¨å¤šä¸ªé¢†åŸŸé€‚åº”ä¸åŒä»»åŠ¡çš„é€‚åº”æ€§ï¼Œå‡¸æ˜¾äº†å…¶åœ¨å¹¿æ³›åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/zjunlp/OneKE%E4%B8%8A%E5%85%AC%E5%BC%80%E4%BA%86%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%B9%B6%E5%9C%A8http://oneke.openkg.cn/demo.mp4%E4%B8%8A%E5%8F%91%E5%B8%83%E4%BA%86%E8%A7%86%E9%A2%91%E3%80%82">https://github.com/zjunlp/OneKEä¸Šå…¬å¼€äº†ä»£ç ï¼Œå¹¶åœ¨http://oneke.openkg.cn/demo.mp4ä¸Šå‘å¸ƒäº†è§†é¢‘ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20005v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æˆ‘ä»¬æ¨å‡ºäº†ä¸€æ¬¾åä¸ºOneKEçš„DockeråŒ–ã€æ¨¡å¼å¼•å¯¼çš„çŸ¥è¯†æå–ç³»ç»Ÿï¼Œå¯ä»ç½‘é¡µå’ŒPDFä¹¦ç±ä¸­æå–çŸ¥è¯†ï¼Œå¹¶æ¶µç›–å¤šä¸ªé¢†åŸŸï¼ˆå¦‚ç§‘å­¦ã€æ–°é—»ç­‰ï¼‰ã€‚OneKEé‡‡ç”¨å¤šä»£ç†é…ç½®çŸ¥è¯†åº“è®¾è®¡ï¼Œä¸åŒä»£ç†æ‰§è¡Œå„è‡ªä»»åŠ¡ï¼Œæ”¯æŒå¤šç§æå–åœºæ™¯ã€‚é…ç½®çŸ¥è¯†åº“æœ‰åŠ©äºæ¨¡å¼é…ç½®ã€é”™è¯¯è°ƒè¯•å’Œä¿®æ­£ï¼Œæé«˜äº†ç³»ç»Ÿæ€§èƒ½ã€‚åŸºå‡†æ•°æ®é›†ä¸Šçš„å®è¯è¯„ä¼°è¯æ˜äº†OneKEçš„æœ‰æ•ˆæ€§ï¼Œæ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¯´æ˜äº†å…¶åœ¨å¤šä¸ªé¢†åŸŸä¸åŒä»»åŠ¡çš„é€‚åº”æ€§ï¼Œå±•ç°å‡ºå¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚æˆ‘ä»¬å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/zjunlp/OneKE%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%B9%B6%E5%8F%91%E5%B8%83%E4%BA%86%E6%BC%94%E7%A4%BA%E8%A7%86%E9%A2%91http://oneke.openkg.cn/demo.mp4%E3%80%82">https://github.com/zjunlp/OneKEå¼€æºä»£ç ï¼Œå¹¶å‘å¸ƒäº†æ¼”ç¤ºè§†é¢‘http://oneke.openkg.cn/demo.mp4ã€‚</a></p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>OneKEæ˜¯ä¸€ä¸ªDockeråŒ–çš„æ¨¡å¼å¼•å¯¼çŸ¥è¯†æå–ç³»ç»Ÿï¼Œå¯ä»¥ä»ç½‘é¡µå’ŒPDFä¹¦ç±ä¸­æå–çŸ¥è¯†ã€‚</li>
<li>OneKEæ”¯æŒå¤šç§é¢†åŸŸï¼Œå¦‚ç§‘å­¦å’Œæ–°é—»ã€‚</li>
<li>OneKEé‡‡ç”¨å¤šä»£ç†è®¾è®¡ï¼Œæ¯ä¸ªä»£ç†æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œä»¥é€‚åº”ä¸åŒçš„æå–åœºæ™¯ã€‚</li>
<li>é…ç½®çŸ¥è¯†åº“æœ‰åŠ©äºæ¨¡å¼é…ç½®ã€é”™è¯¯è°ƒè¯•å’Œä¿®æ­£ï¼Œæå‡äº†ç³»ç»Ÿæ€§èƒ½ã€‚</li>
<li>å®è¯è¯„ä¼°è¯æ˜OneKEåœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†OneKEåœ¨å¤šä¸ªé¢†åŸŸä¸åŒä»»åŠ¡çš„é€‚åº”æ€§ã€‚</li>
<li>OneKEå·²å¼€æºï¼Œå¹¶æä¾›äº†æ¼”ç¤ºè§†é¢‘ä¾›ç”¨æˆ·å‚è€ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20005">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1df1f946514d6b9c441db49d6d3ebb08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-acaca8651d2720053d7d16c4321ccc86.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-96c1ddebe50a188057a3e6018b8cc14c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-93ca0b22cb9c9752b067b145b44117b0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Large-Language-Model-Brained-GUI-Agents-A-Survey"><a href="#Large-Language-Model-Brained-GUI-Agents-A-Survey" class="headerlink" title="Large Language Model-Brained GUI Agents: A Survey"></a>Large Language Model-Brained GUI Agents: A Survey</h2><p><strong>Authors:Chaoyun Zhang, Shilin He, Jiaxu Qian, Bowen Li, Liqun Li, Si Qin, Yu Kang, Minghua Ma, Guyue Liu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</strong></p>
<p>GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing. This has paved the way for a new generation of LLM-brained GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry.   To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-brained GUI agents, exploring their historical evolution, core components, and advanced techniques. We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-brained GUI agents. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIsï¼‰é•¿æœŸä»¥æ¥ä¸€ç›´æ˜¯äººæœºäº¤äº’çš„æ ¸å¿ƒï¼Œæä¾›äº†ä¸€ç§ç›´è§‚å’Œè§†è§‰é©±åŠ¨çš„æ–¹å¼æ¥è®¿é—®å’Œä¸æ•°å­—ç³»ç»Ÿäº¤äº’ã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œå·²ç»å¼€å¯äº†GUIè‡ªåŠ¨åŒ–çš„æ–°æ—¶ä»£ã€‚å®ƒä»¬åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ä»£ç ç”Ÿæˆå’Œè§†è§‰å¤„ç†æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ã€‚è¿™ä¸ºæ–°ä¸€ä»£åŸºäºLLMçš„GUIä»£ç†é“ºå¹³äº†é“è·¯ï¼Œè¿™äº›ä»£ç†èƒ½å¤Ÿè§£é‡Šå¤æ‚çš„GUIå…ƒç´ å¹¶åŸºäºè‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚è¿™äº›ä»£ç†ä»£è¡¨äº†èŒƒå¼è½¬å˜ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ç®€å•çš„å‘½ä»¤æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚å®ƒä»¬çš„åº”ç”¨èŒƒå›´æ¶µç›–ç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ï¼Œæä¾›å˜é©æ€§çš„ç”¨æˆ·ä½“éªŒï¼Œå½»åº•æ”¹å˜ä¸ªäººä¸è½¯ä»¶çš„äº¤äº’æ–¹å¼ã€‚è¿™ä¸ªæ–°å…´é¢†åŸŸæ­£åœ¨è¿…é€Ÿå‘å±•ï¼Œåœ¨ç ”ç©¶å’Œå·¥ä¸šé¢†åŸŸéƒ½å–å¾—äº†é‡å¤§è¿›å±•ã€‚ä¸ºäº†å¯¹è¿™ä¸€è¶‹åŠ¿æœ‰ä¸€ä¸ªç»“æ„åŒ–çš„ç†è§£ï¼Œæœ¬æ–‡å…¨é¢å›é¡¾äº†åŸºäºLLMçš„GUIä»£ç†ï¼Œæ¢ç´¢äº†å®ƒä»¬çš„å†å²æ¼”å˜ã€æ ¸å¿ƒç»„ä»¶å’Œå…ˆè¿›æŠ€æœ¯ã€‚æˆ‘ä»¬å›ç­”äº†ä¸€äº›ç ”ç©¶é—®é¢˜ï¼Œå¦‚ç°æœ‰çš„GUIä»£ç†æ¡†æ¶ã€æ”¶é›†å’Œåˆ©ç”¨æ•°æ®æ¥è®­ç»ƒä¸“ä¸šçš„GUIä»£ç†ã€ä¸ºGUIä»»åŠ¡å¼€å‘çš„å¤§å‹åŠ¨ä½œæ¨¡å‹ã€ä»¥åŠè¯„ä¼°å…¶æœ‰æ•ˆæ€§çš„è¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æµ‹è¯•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä»‹ç»äº†è¿™äº›ä»£ç†æ¨åŠ¨çš„çš„æ–°å…´åº”ç”¨ã€‚é€šè¿‡è¯¦ç»†åˆ†æï¼Œæœ¬è°ƒæŸ¥ç¡®å®šäº†å…³é”®çš„ç ”ç©¶ç©ºç™½ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥è¿›æ­¥åˆ¶å®šäº†è·¯çº¿å›¾ã€‚é€šè¿‡æ•´åˆåŸºç¡€çŸ¥è¯†å’Œæœ€æ–°å‘å±•ï¼Œæœ¬å·¥ä½œæ—¨åœ¨æŒ‡å¯¼ç ”ç©¶è€…å’Œå®è·µè€…å…‹æœæŒ‘æˆ˜ï¼Œå……åˆ†å‘æŒ¥åŸºäºLLMçš„GUIä»£ç†çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18279v6">PDF</a> The collection of papers reviewed in this survey will be hosted and   regularly updated on the GitHub repository:   <a target="_blank" rel="noopener" href="https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey">https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey</a> Additionally, a   searchable webpage is available at <a target="_blank" rel="noopener" href="https://aka.ms/gui-agent">https://aka.ms/gui-agent</a> for easier access   and exploration</p>
<p><strong>æ‘˜è¦</strong></p>
<p>GUIé•¿æœŸä»¥æ¥ä¸€ç›´å æ®äººæœºäº¤äº’çš„ä¸­å¿ƒåœ°ä½ï¼Œä¸ºè®¿é—®å’Œä¸æ•°å­—ç³»ç»Ÿè¿›è¡Œäº¤äº’æä¾›äº†ä¸€ä¸ªç›´è§‚å’Œè§†è§‰é©±åŠ¨çš„æ–¹å¼ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œå·²ç»å¼€å¯äº†GUIè‡ªåŠ¨åŒ–çš„æ–°æ—¶ä»£ã€‚ä»–ä»¬åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ä»£ç ç”Ÿæˆå’Œè§†è§‰å¤„ç†æ–¹é¢è¡¨ç°å‡ºäº†æƒŠäººçš„èƒ½åŠ›ã€‚è¿™ä¸ºæ–°ä¸€ä»£åŸºäºLLMçš„GUIä»£ç†çš„å‘å±•é“ºå¹³äº†é“è·¯ï¼Œè¿™äº›ä»£ç†èƒ½å¤Ÿè§£é‡Šå¤æ‚çš„GUIå…ƒç´ å¹¶æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚è¿™äº›ä»£ç†ä»£è¡¨äº†èŒƒå¼è½¬å˜ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ç®€å•çš„å‘½ä»¤æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚å®ƒä»¬çš„åº”ç”¨ç¨‹åºè·¨è¶Šç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ç§å˜é©æ€§çš„ä½“éªŒï¼Œå½»åº•æ”¹å˜äº†ä¸ªäººä¸è½¯ä»¶çš„äº¤äº’æ–¹å¼ã€‚æœ¬æ–‡ä¸ºäº†æä¾›å¯¹è¿™ä¸€è¶‹åŠ¿çš„ç»“æ„æ€§ç†è§£ï¼Œå…¨é¢å›é¡¾äº†åŸºäºLLMçš„GUIä»£ç†ï¼Œæ¢ç´¢äº†å®ƒä»¬çš„å†å²æ¼”å˜ã€æ ¸å¿ƒç»„ä»¶å’Œå…ˆè¿›æŠ€æœ¯ã€‚æˆ‘ä»¬è§£ç­”äº†è¯¸å¦‚ç°æœ‰GUIä»£ç†æ¡†æ¶ã€æ”¶é›†å’Œåˆ©ç”¨æ•°æ®æ¥è®­ç»ƒä¸“ä¸šGUIä»£ç†ã€ä¸ºGUIä»»åŠ¡å¼€å‘å¤§å‹åŠ¨ä½œæ¨¡å‹ä»¥åŠè¯„ä¼°å…¶æœ‰æ•ˆæ€§çš„è¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æµ‹è¯•ç­‰ç ”ç©¶é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†è¿™äº›ä»£ç†æ¨åŠ¨çš„æ–°å…´åº”ç”¨ã€‚é€šè¿‡è¯¦ç»†åˆ†æï¼Œæœ¬ç»¼è¿°ç¡®å®šäº†å…³é”®çš„ç ”ç©¶ç©ºç™½å¹¶ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥è¿›æ­¥åˆ¶å®šäº†è·¯çº¿å›¾ã€‚é€šè¿‡æ•´åˆåŸºç¡€çŸ¥è¯†å’Œæœ€æ–°å‘å±•ï¼Œæœ¬å·¥ä½œæ—¨åœ¨æŒ‡å¯¼ç ”ç©¶è€…å’Œå®è·µè€…å…‹æœæŒ‘æˆ˜å¹¶è§£é”åŸºäºLLMçš„GUIä»£ç†çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²åœ¨GUIè‡ªåŠ¨åŒ–é¢†åŸŸå±•ç°å‡ºå…¶æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªç„¶è¯­è¨€ç†è§£å’Œè§†è§‰å¤„ç†æ–¹é¢ã€‚</li>
<li>åŸºäºLLMçš„GUIä»£ç†èƒ½è§£é‡Šå¤æ‚çš„GUIå…ƒç´ å¹¶æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œï¼Œä»£è¡¨äººæœºäº¤äº’çš„èŒƒå¼è½¬å˜ã€‚</li>
<li>è¿™äº›ä»£ç†çš„åº”ç”¨èŒƒå›´å¹¿æ³›ï¼ŒåŒ…æ‹¬ç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ï¼Œæä¾›äº†æ›´ç›´è§‚å’Œç”¨æˆ·å‹å¥½çš„äº¤äº’ä½“éªŒã€‚</li>
<li>å½“å‰çš„ç ”ç©¶é¢†åŸŸåŒ…æ‹¬GUIä»£ç†æ¡†æ¶ã€æ•°æ®æ”¶é›†å’Œåˆ©ç”¨ã€å¤§å‹åŠ¨ä½œæ¨¡å‹çš„å¼€å‘ä»¥åŠä»£ç†æ•ˆæœçš„è¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æµ‹è¯•ã€‚</li>
<li>åŸºäºLLMçš„GUIä»£ç†çš„ç ”ç©¶ä»å¤„äºå‘å±•åˆæœŸï¼Œå­˜åœ¨è®¸å¤šç ”ç©¶ç©ºç™½ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„æ¢ç´¢å’Œåˆ›æ–°ã€‚</li>
<li>é€šè¿‡æ•´åˆåŸºç¡€çŸ¥è¯†å’Œæœ€æ–°å‘å±•ï¼Œè¯¥é¢†åŸŸçš„è°ƒç ”å·¥ä½œæ—¨åœ¨ä¸ºç ”ç©¶è€…å’Œå®è·µè€…æä¾›æŒ‡å¯¼ï¼Œä»¥å…‹æœæŒ‘æˆ˜å¹¶å……åˆ†å‘æŒ¥åŸºäºLLMçš„GUIä»£ç†çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18279">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-182ac92d1322483ac0a4db62afe73e55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6a4be3fb98a0b63af42b7b053140fa6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b44c0945e92a024d22f3bb7cb133b485.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ff2f9194ea9b361fc79cc5d28a051b8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f015afe26577de227ef494148ee5c0c.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="A-Multi-Agent-Multi-Environment-Mixed-Q-Learning-for-Partially-Decentralized-Wireless-Network-Optimization"><a href="#A-Multi-Agent-Multi-Environment-Mixed-Q-Learning-for-Partially-Decentralized-Wireless-Network-Optimization" class="headerlink" title="A Multi-Agent Multi-Environment Mixed Q-Learning for Partially   Decentralized Wireless Network Optimization"></a>A Multi-Agent Multi-Environment Mixed Q-Learning for Partially   Decentralized Wireless Network Optimization</h2><p><strong>Authors:Talha Bozkus, Urbashi Mitra</strong></p>
<p>Q-learning is a powerful tool for network control and policy optimization in wireless networks, but it struggles with large state spaces. Recent advancements, like multi-environment mixed Q-learning (MEMQ), improves performance and reduces complexity by integrating multiple Q-learning algorithms across multiple related environments so-called digital cousins. However, MEMQ is designed for centralized single-agent networks and is not suitable for decentralized or multi-agent networks. To address this challenge, we propose a novel multi-agent MEMQ algorithm for partially decentralized wireless networks with multiple mobile transmitters (TXs) and base stations (BSs), where TXs do not have access to each otherâ€™s states and actions. In uncoordinated states, TXs act independently to minimize their individual costs. In coordinated states, TXs use a Bayesian approach to estimate the joint state based on local observations and share limited information with leader TX to minimize joint cost. The cost of information sharing scales linearly with the number of TXs and is independent of the joint state-action space size. The proposed scheme is 50% faster than centralized MEMQ with only a 20% increase in average policy error (APE) and is 25% faster than several advanced decentralized Q-learning algorithms with 40% less APE. The convergence of the algorithm is also demonstrated. </p>
<blockquote>
<p>Qå­¦ä¹ æ˜¯æ— çº¿ç½‘ç»œä¸­ç½‘ç»œæ§åˆ¶å’Œç­–ç•¥ä¼˜åŒ–çš„ä¸€ç§å¼ºå¤§å·¥å…·ï¼Œä½†åœ¨å¤§è§„æ¨¡çŠ¶æ€ç©ºé—´ä¸­è¡¨ç°ä¸ä½³ã€‚æœ€è¿‘çš„è¿›å±•ï¼Œå¦‚å¤šç¯å¢ƒæ··åˆQå­¦ä¹ ï¼ˆMEMQï¼‰ï¼Œé€šè¿‡æ•´åˆå¤šä¸ªç›¸å…³ç¯å¢ƒä¸­çš„å¤šä¸ªQå­¦ä¹ ç®—æ³•ï¼Œæé«˜äº†æ€§èƒ½å¹¶é™ä½äº†å¤æ‚æ€§ï¼Œè¿™äº›ç¯å¢ƒè¢«ç§°ä¸ºæ•°å­—åŒèƒã€‚ç„¶è€Œï¼ŒMEMQæ˜¯ä¸ºé›†ä¸­å¼å•ä»£ç†ç½‘ç»œè®¾è®¡çš„ï¼Œå¹¶ä¸é€‚åˆåˆ†å¸ƒå¼æˆ–å¤šä»£ç†ç½‘ç»œã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šä»£ç†MEMQç®—æ³•ï¼Œé€‚ç”¨äºéƒ¨åˆ†åˆ†æ•£çš„æ— çº¿ç½‘ç»œï¼Œå…·æœ‰å¤šä¸ªç§»åŠ¨å‘å°„æœºï¼ˆTXï¼‰å’ŒåŸºç«™ï¼ˆBSï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒTXæ— æ³•ç›¸äº’è®¿é—®å½¼æ­¤çš„çŠ¶æ€å’Œè¡ŒåŠ¨ã€‚åœ¨ä¸åè°ƒçš„çŠ¶æ€ä¸‹ï¼ŒTXç‹¬ç«‹è¡ŒåŠ¨ä»¥æœ€å°åŒ–å…¶ä¸ªäººæˆæœ¬ã€‚åœ¨åè°ƒçŠ¶æ€ä¸‹ï¼ŒTXä½¿ç”¨è´å¶æ–¯æ–¹æ³•æ ¹æ®å±€éƒ¨è§‚å¯Ÿæ¥ä¼°è®¡è”åˆçŠ¶æ€ï¼Œå¹¶ä¸é¢†å¯¼TXå…±äº«æœ‰é™ä¿¡æ¯ä»¥æœ€å°åŒ–è”åˆæˆæœ¬ã€‚ä¿¡æ¯å…±äº«çš„æˆæœ¬éšTXæ•°é‡çš„å¢åŠ è€Œçº¿æ€§å¢é•¿ï¼Œä¸è”åˆçŠ¶æ€-è¡ŒåŠ¨ç©ºé—´å¤§å°æ— å…³ã€‚æ‰€æå‡ºçš„æ–¹æ¡ˆæ¯”é›†ä¸­å¼MEMQå¿«50%ï¼Œå¹³å‡ç­–ç•¥è¯¯å·®ï¼ˆAPEï¼‰ä»…å¢åŠ 20%ï¼Œå¹¶ä¸”æ¯”å‡ ç§å…ˆè¿›çš„åˆ†å¸ƒå¼Qå­¦ä¹ ç®—æ³•å¿«25%ï¼ŒåŒæ—¶APEé™ä½äº†40%ã€‚è¯¥ç®—æ³•çš„æ”¶æ•›æ€§ä¹Ÿå¾—åˆ°äº†è¯æ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.16450v2">PDF</a> Accepted to 2025 IEEE International Conference on Acoustics, Speech,   and Signal Processing (ICASSP 2025)</p>
<p><strong>Summary</strong><br>     æ–°å‹å¤šæ™ºèƒ½ä½“MEMQç®—æ³•åº”ç”¨äºéƒ¨åˆ†åˆ†æ•£å¼æ— çº¿ç½‘ç»œï¼Œé’ˆå¯¹å¤šç§»åŠ¨å‘å°„å™¨ä¸åŸºç«™çš„ç¯å¢ƒè¿›è¡Œè®¾è®¡ã€‚åœ¨åˆ†æ•£çŠ¶æ€ä¸‹ï¼Œå‘å°„å™¨ç‹¬ç«‹è¿ä½œä»¥é™ä½ä¸ªåˆ«æˆæœ¬ï¼›åœ¨ååŒçŠ¶æ€ä¸‹ï¼Œå‘å°„å™¨ä½¿ç”¨è´å¶æ–¯æ–¹æ³•ä¼°è®¡è”åˆçŠ¶æ€å¹¶å®ç°ä¿¡æ¯å…±äº«ä»¥æœ€å°åŒ–è”åˆæˆæœ¬ã€‚æ–°æ–¹æ¡ˆæ¯”é›†ä¸­å¼çš„MEMQæ›´å¿«ï¼ŒåŒæ—¶å¹³å‡ç­–ç•¥è¯¯å·®æœ‰æ‰€å¢åŠ ï¼Œä½†ä»ä¼˜äºå…¶ä»–å…ˆè¿›çš„åˆ†æ•£å¼Q-å­¦ä¹ ç®—æ³•ã€‚ç®—æ³•æ”¶æ•›æ€§å¾—åˆ°éªŒè¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Q-å­¦ä¹ åœ¨ç½‘ç»œæ§åˆ¶å’Œç­–ç•¥ä¼˜åŒ–ä¸­å…·æœ‰å¼ºå¤§åŠŸèƒ½ï¼Œä½†åœ¨å¤§å‹çŠ¶æ€ç©ºé—´ä¸­è¡¨ç°æ¬ ä½³ã€‚</li>
<li>MEMQç®—æ³•é€šè¿‡æ•´åˆå¤šä¸ªç›¸å…³ç¯å¢ƒä¸­çš„Q-å­¦ä¹ ç®—æ³•æ¥æå‡æ€§èƒ½å¹¶é™ä½å¤æ‚æ€§ã€‚</li>
<li>ä¼ ç»ŸMEMQè®¾è®¡é€‚ç”¨äºé›†ä¸­å¼å•æ™ºèƒ½ä½“ç½‘ç»œï¼Œä¸é€‚ç”¨äºåˆ†æ•£å¼æˆ–å¤šæ™ºèƒ½ä½“ç½‘ç»œã€‚</li>
<li>æå‡ºçš„æ–°å‹å¤šæ™ºèƒ½ä½“MEMQç®—æ³•é€‚ç”¨äºéƒ¨åˆ†åˆ†æ•£å¼æ— çº¿ç½‘ç»œï¼Œæ¶‰åŠå¤šä¸ªç§»åŠ¨å‘å°„å™¨å’ŒåŸºç«™ã€‚</li>
<li>åœ¨åˆ†æ•£çŠ¶æ€ä¸‹ï¼Œå‘å°„å™¨ç‹¬ç«‹è¿ä½œä»¥é™ä½ä¸ªåˆ«æˆæœ¬ï¼›åœ¨ååŒçŠ¶æ€ä¸‹ï¼Œé€šè¿‡ä¿¡æ¯å…±äº«æœ€å°åŒ–è”åˆæˆæœ¬ã€‚</li>
<li>æ–°æ–¹æ¡ˆåœ¨æ‰§è¡Œé€Ÿåº¦ä¸Šæ¯”é›†ä¸­å¼MEMQæ›´å¿«ï¼ŒåŒæ—¶å¹³å‡ç­–ç•¥è¯¯å·®æœ‰æ‰€ä¸Šå‡ï¼Œä½†ç›¸è¾ƒäºå…¶ä»–å…ˆè¿›çš„åˆ†æ•£å¼Q-å­¦ä¹ ç®—æ³•ä»æœ‰ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.16450">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-41edd869bf04fa9e4318f740bdb1755d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f9b1411b96284e6b9b2729de48dc6a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-384538fee20081912c8fcbb177c7f646.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8422e359b4a859689838bacb38119258.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Multimodal-Human-Autonomous-Agents-Interaction-Using-Pre-Trained-Language-and-Visual-Foundation-Models"><a href="#Multimodal-Human-Autonomous-Agents-Interaction-Using-Pre-Trained-Language-and-Visual-Foundation-Models" class="headerlink" title="Multimodal Human-Autonomous Agents Interaction Using Pre-Trained   Language and Visual Foundation Models"></a>Multimodal Human-Autonomous Agents Interaction Using Pre-Trained   Language and Visual Foundation Models</h2><p><strong>Authors:Linus Nwankwo, Elmar Rueckert</strong></p>
<p>In this paper, we extended the method proposed in [21] to enable humans to interact naturally with autonomous agents through vocal and textual conversations. Our extended method exploits the inherent capabilities of pre-trained large language models (LLMs), multimodal visual language models (VLMs), and speech recognition (SR) models to decode the high-level natural language conversations and semantic understanding of the robotâ€™s task environment, and abstract them to the robotâ€™s actionable commands or queries. We performed a quantitative evaluation of our frameworkâ€™s natural vocal conversation understanding with participants from different racial backgrounds and English language accents. The participants interacted with the robot using both spoken and textual instructional commands. Based on the logged interaction data, our framework achieved 87.55% vocal commands decoding accuracy, 86.27% commands execution success, and an average latency of 0.89 seconds from receiving the participantsâ€™ vocal chat commands to initiating the robotâ€™s actual physical action. The video demonstrations of this paper can be found at <a target="_blank" rel="noopener" href="https://linusnep.github.io/MTCC-IRoNL/">https://linusnep.github.io/MTCC-IRoNL/</a>. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬æ‰©å±•äº†[21]ä¸­æå‡ºçš„æ–¹æ³•ï¼Œä½¿äººç±»èƒ½å¤Ÿé€šè¿‡è¯­éŸ³å’Œæ–‡æœ¬å¯¹è¯è‡ªç„¶åœ°ä¸è‡ªä¸»æ™ºèƒ½ä½“è¿›è¡Œäº¤äº’ã€‚æˆ‘ä»¬çš„æ‰©å±•æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å’Œè¯­éŸ³è¯†åˆ«ï¼ˆSRï¼‰æ¨¡å‹çš„å›ºæœ‰åŠŸèƒ½ï¼Œè§£ç é«˜çº§è‡ªç„¶è¯­è¨€å¯¹è¯å’Œæœºå™¨äººä»»åŠ¡ç¯å¢ƒçš„è¯­ä¹‰ç†è§£ï¼Œå¹¶å°†å…¶æŠ½è±¡åŒ–ä¸ºæœºå™¨äººçš„å¯æ‰§è¡Œå‘½ä»¤æˆ–æŸ¥è¯¢ã€‚æˆ‘ä»¬å¯¹æ¡†æ¶çš„è‡ªç„¶è¯­éŸ³å¯¹è¯ç†è§£èƒ½åŠ›è¿›è¡Œäº†å®šé‡è¯„ä¼°ï¼Œå‚ä¸è€…æ¥è‡ªä¸åŒçš„ç§æ—èƒŒæ™¯å’Œè‹±è¯­å£éŸ³ã€‚å‚ä¸è€…ä½¿ç”¨å£å¤´å’Œæ–‡æœ¬æŒ‡ä»¤å‘½ä»¤ä¸æœºå™¨äººè¿›è¡Œäº¤äº’ã€‚åŸºäºè®°å½•çš„äº¤äº’æ•°æ®ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å®ç°äº†87.55%çš„è¯­éŸ³å‘½ä»¤è§£ç å‡†ç¡®ç‡ã€86.27%çš„å‘½ä»¤æ‰§è¡ŒæˆåŠŸç‡ï¼Œä»æ¥æ”¶å‚ä¸è€…çš„è¯­éŸ³èŠå¤©å‘½ä»¤åˆ°å¯åŠ¨æœºå™¨äººçš„å®é™…ç‰©ç†åŠ¨ä½œçš„å¹³å‡å»¶è¿Ÿæ—¶é—´ä¸º0.89ç§’ã€‚æœ¬è®ºæ–‡çš„è§†é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://linusnep.github.io/MTCC-IRoNL/%E6%89%BE%E5%88%B0%E3%80%82">https://linusnep.github.io/MTCC-IRoNL/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.12273v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æ‰©å±•äº†[21]ä¸­æå‡ºçš„æ–¹æ³•ï¼Œä½¿äººç±»èƒ½å¤Ÿé€šè¿‡è¯­éŸ³å’Œæ–‡æœ¬ä¸è‡ªä¸»ä»£ç†è¿›è¡Œè‡ªç„¶äº¤äº’ã€‚æ‰©å±•çš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å’Œè¯­éŸ³è¯†åˆ«ï¼ˆSRï¼‰æ¨¡å‹çš„å›ºæœ‰åŠŸèƒ½ï¼Œè§£ç é«˜çº§è‡ªç„¶è¯­è¨€å¯¹è¯å’Œæœºå™¨äººä»»åŠ¡ç¯å¢ƒçš„è¯­ä¹‰ç†è§£ï¼Œå¹¶å°†å…¶æŠ½è±¡ä¸ºæœºå™¨äººçš„å¯æ“ä½œå‘½ä»¤æˆ–æŸ¥è¯¢ã€‚æˆ‘ä»¬å¯¹æ¡†æ¶çš„è‡ªç„¶è¯­éŸ³å¯¹è¯ç†è§£è¿›è¡Œäº†å®šé‡è¯„ä¼°ï¼Œå‚ä¸è€…æ¥è‡ªä¸åŒçš„ç§æ—èƒŒæ™¯å’Œè‹±è¯­å£éŸ³ã€‚å‚ä¸è€…é€šè¿‡å£è¯­å’Œæ–‡æœ¬æŒ‡ä»¤ä¸æœºå™¨äººäº’åŠ¨ã€‚åŸºäºè®°å½•çš„äº’åŠ¨æ•°æ®ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å®ç°äº†87.55%çš„è¯­éŸ³å‘½ä»¤è§£ç å‡†ç¡®ç‡ã€86.27%çš„å‘½ä»¤æ‰§è¡ŒæˆåŠŸç‡å’Œå¹³å‡0.89ç§’çš„å»¶è¿Ÿï¼Œä»æ¥æ”¶å‚ä¸è€…çš„è¯­éŸ³èŠå¤©å‘½ä»¤åˆ°å¯åŠ¨æœºå™¨äººçš„å®é™…ç‰©ç†åŠ¨ä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©å±•äº†åŸæœ‰æ–¹æ³•ï¼Œä½¿äººç±»èƒ½é€šè¿‡è¯­éŸ³å’Œæ–‡æœ¬ä¸è‡ªä¸»ä»£ç†è‡ªç„¶äº¤äº’ã€‚</li>
<li>åˆ©ç”¨äº†é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹å’Œè¯­éŸ³è¯†åˆ«æ¨¡å‹çš„å›ºæœ‰åŠŸèƒ½ã€‚</li>
<li>æ¡†æ¶èƒ½å¤Ÿå®ç°é«˜çº§è‡ªç„¶è¯­è¨€å¯¹è¯è§£ç å’Œæœºå™¨äººä»»åŠ¡ç¯å¢ƒçš„è¯­ä¹‰ç†è§£ã€‚</li>
<li>æ¡†æ¶å¯å°†è¯­ä¹‰ç†è§£è½¬åŒ–ä¸ºæœºå™¨äººçš„å¯æ“ä½œå‘½ä»¤æˆ–æŸ¥è¯¢ã€‚</li>
<li>æ¡†æ¶çš„è‡ªç„¶è¯­éŸ³å¯¹è¯ç†è§£è¯„ä¼°æ˜¾ç¤ºï¼Œè¯­éŸ³å‘½ä»¤è§£ç å‡†ç¡®ç‡ä¸º87.55%ï¼Œå‘½ä»¤æ‰§è¡ŒæˆåŠŸç‡ä¸º86.27%ã€‚</li>
<li>æ¡†æ¶ä»æ¥æ”¶è¯­éŸ³å‘½ä»¤åˆ°å¯åŠ¨æœºå™¨äººåŠ¨ä½œçš„å¹³å‡å»¶è¿Ÿä¸º0.89ç§’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.12273">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3a97419e55049fd1cbc10d7c7fb26d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7a91e48e51d6f8a2aaaf953f7aff5eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50f24188c445ad15e0ea6b67806fc889.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents"><a href="#Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents" class="headerlink" title="Is ChatGPT Good at Search? Investigating Large Language Models as   Re-Ranking Agents"></a>Is ChatGPT Good at Search? Investigating Large Language Models as   Re-Ranking Agents</h2><p><strong>Authors:Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, Zhaochun Ren</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge. In this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. Furthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the modelâ€™s ability to rank unknown knowledge. Finally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme. Our evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark. The code to reproduce our results is available at <a target="_blank" rel="noopener" href="http://www.github.com/sunnweiwei/RankGPT">www.github.com/sunnweiwei/RankGPT</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è¯­è¨€ç›¸å…³ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬æœç´¢å¼•æ“ã€‚ç„¶è€Œï¼Œç°æœ‰å·¥ä½œåˆ©ç”¨LLMsçš„ä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰ç”Ÿæˆèƒ½åŠ›ï¼Œè€Œéç›´æ¥è¿›è¡Œæ®µè½æ’åã€‚LLMsçš„é¢„è®­ç»ƒç›®æ ‡ä¸æ’åç›®æ ‡ä¹‹é—´çš„å·®å¼‚æ„æˆäº†å¦ä¸€ä¸ªæŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè°ƒæŸ¥äº†ç”¨äºä¿¡æ¯æ£€ç´¢ç›¸å…³æ€§æ’åçš„ç”Ÿæˆå¼LLMsï¼Œå¦‚ChatGPTå’ŒGPT-4ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œåœ¨å¾—åˆ°é€‚å½“æŒ‡ä»¤çš„æƒ…å†µä¸‹ï¼ŒLLMså¯ä»¥æä¾›æœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œç”šè‡³åœ¨æµè¡Œçš„IRåŸºå‡†æµ‹è¯•ä¸Šä¼˜äºæœ€æ–°çš„ç›‘ç£æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³å¯¹LLMsæ•°æ®æ±¡æŸ“çš„æ‹…å¿§ï¼Œæˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªæ–°çš„æµ‹è¯•é›†ï¼Œç§°ä¸ºNovelEvalï¼Œå®ƒåŸºäºæœ€æ–°çŸ¥è¯†ï¼Œæ—¨åœ¨éªŒè¯æ¨¡å‹å¯¹æœªçŸ¥çŸ¥è¯†çš„æ’åèƒ½åŠ›ã€‚æœ€åï¼Œä¸ºäº†æé«˜åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æ•ˆç‡ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº†ä½¿ç”¨ç½®æ¢è’¸é¦æ–¹æ¡ˆå°†ChatGPTçš„æ’åèƒ½åŠ›è’¸é¦åˆ°å°å‹ä¸“ç”¨æ¨¡å‹ä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä¸€ä¸ªè’¸é¦åçš„4.4äº¿å‚æ•°æ¨¡å‹åœ¨BEIRåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä¸€ä¸ª30äº¿å‚æ•°çš„ç›‘ç£æ¨¡å‹ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="http://www.github.com/sunnweiwei/RankGPT%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">www.github.com/sunnweiwei/RankGPTä¸Šè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2304.09542v3">PDF</a> EMNLP 2023</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§è¯­è¨€ä»»åŠ¡ä¸­å±•ç°äº†å‡ºè‰²çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬æœç´¢å¼•æ“ã€‚æœ¬ç ”ç©¶é¦–æ¬¡æ¢è®¨äº†åˆ©ç”¨ChatGPTå’ŒGPT-4ç­‰ç”Ÿæˆå¼LLMè¿›è¡Œä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰çš„ç›¸å…³æ€§æ’åã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€‚å½“æŒ‡å¯¼çš„LLMsåœ¨æµè¡ŒIRåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å¯ä¸æœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ç›¸ç«äº‰ï¼Œç”šè‡³æ›´ä¼˜ç§€ã€‚ä¸ºè§£å†³LLMsæ•°æ®æ±¡æŸ“é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºæ–°çš„æµ‹è¯•é›†NovelEvalï¼Œæ—¨åœ¨éªŒè¯æ¨¡å‹å¯¹æœªçŸ¥çŸ¥è¯†çš„æ’åèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä¸ºæé«˜å®é™…åº”ç”¨çš„æ•ˆç‡ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†ä½¿ç”¨ç½®æ¢è’¸é¦æ–¹æ¡ˆå°†ChatGPTçš„æ’åèƒ½åŠ›è’¸é¦åˆ°å°å‹ä¸“ç”¨æ¨¡å‹ä¸­çš„æ½œåŠ›ã€‚æœ€ç»ˆå®éªŒè¯å®è’¸é¦åçš„440Mæ¨¡å‹åœ¨BEIRåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†3Bç›‘ç£æ¨¡å‹çš„è¡¨ç°ã€‚ç ”ç©¶æˆæœå¯åœ¨<a href="www.github.com/sunnweiwei/RankGPT">www.github.com/sunnweiwei/RankGPT</a>å¤ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸åŒè¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>LLMsåœ¨ä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰çš„ç›¸å…³æ€§æ’åä»»åŠ¡ä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>é€‚å½“æŒ‡å¯¼çš„LLMsåœ¨IRåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜ç§€ï¼Œå¯ä¸æœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ç›¸ç«äº‰ã€‚</li>
<li>ä¸ºè§£å†³LLMsæ•°æ®æ±¡æŸ“é—®é¢˜ï¼Œæ¨å‡ºäº†æ–°çš„æµ‹è¯•é›†NovelEvalã€‚</li>
<li>ä½¿ç”¨ç½®æ¢è’¸é¦æ–¹æ¡ˆå¯æé«˜LLMsåœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡ã€‚</li>
<li>è’¸é¦åçš„440Mæ¨¡å‹åœ¨BEIRåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äº3Bç›‘ç£æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2304.09542">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bf3b3a611cb1f6b4beaaa62df58b7d6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b63db53fcba13e1926cd6938121a9423.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4660698e1379ae3973426cb4da344f08.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-46a67bbe1cf1176ce4d1e8a308c058ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ed0c5e2f414879892079cedd6e44bb8.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b01de80e41cf94f03899138149fddebb.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Defending Multimodal Backdoored Models by Repulsive Visual Prompt Tuning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c7827bb6f2f165dd9d946225924095f9.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Distributed Mixture-of-Agents for Edge Inference with Large Language   Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">20064.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
