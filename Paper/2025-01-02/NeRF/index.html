<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Bringing Objects to Life 4D generation from 3D objects">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-e0d61a3ec03e4f212d16afb4fead0a57.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-02-æ›´æ–°"><a href="#2025-01-02-æ›´æ–°" class="headerlink" title="2025-01-02 æ›´æ–°"></a>2025-01-02 æ›´æ–°</h1><h2 id="Bringing-Objects-to-Life-4D-generation-from-3D-objects"><a href="#Bringing-Objects-to-Life-4D-generation-from-3D-objects" class="headerlink" title="Bringing Objects to Life: 4D generation from 3D objects"></a>Bringing Objects to Life: 4D generation from 3D objects</h2><p><strong>Authors:Ohad Rahamim, Ori Malca, Dvir Samuel, Gal Chechik</strong></p>
<p>Recent advancements in generative modeling now enable the creation of 4D content (moving 3D objects) controlled with text prompts. 4D generation has large potential in applications like virtual worlds, media, and gaming, but existing methods provide limited control over the appearance and geometry of generated content. In this work, we introduce a method for animating user-provided 3D objects by conditioning on textual prompts to guide 4D generation, enabling custom animations while maintaining the identity of the original object. We first convert a 3D mesh into a &#96;&#96;staticâ€ 4D Neural Radiance Field (NeRF) that preserves the visual attributes of the input object. Then, we animate the object using an Image-to-Video diffusion model driven by text. To improve motion realism, we introduce an incremental viewpoint selection protocol for sampling perspectives to promote lifelike movement and a masked Score Distillation Sampling (SDS) loss, which leverages attention maps to focus optimization on relevant regions. We evaluate our model in terms of temporal coherence, prompt adherence, and visual fidelity and find that our method outperforms baselines that are based on other approaches, achieving up to threefold improvements in identity preservation measured using LPIPS scores, and effectively balancing visual quality with dynamic content. </p>
<blockquote>
<p>æœ€è¿‘ç”Ÿæˆæ¨¡å‹é¢†åŸŸçš„è¿›å±•ç°åœ¨å·²èƒ½å¤Ÿå®ç°ä½¿ç”¨æ–‡æœ¬æç¤ºåˆ›å»º4Då†…å®¹ï¼ˆåŠ¨æ€3Dç‰©ä½“ï¼‰ã€‚4Dç”Ÿæˆåœ¨è™šæ‹Ÿä¸–ç•Œã€åª’ä½“å’Œæ¸¸æˆç­‰é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•å¯¹äºç”Ÿæˆå†…å®¹çš„å¤–è²Œå’Œå‡ ä½•ç»“æ„çš„æ§åˆ¶æœ‰é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§é€šè¿‡æ–‡æœ¬æç¤ºè¿›è¡Œæ¡ä»¶åŠ¨ç”»å¤„ç†ç”¨æˆ·æä¾›çš„3Dç‰©ä½“çš„æ–¹æ³•ï¼Œä»¥æŒ‡å¯¼4Dç”Ÿæˆï¼Œå®ç°åœ¨ä¿æŒåŸå§‹ç‰©ä½“èº«ä»½çš„åŒæ—¶è¿›è¡Œè‡ªå®šä¹‰åŠ¨ç”»ã€‚æˆ‘ä»¬é¦–å…ˆå°†3Dç½‘æ ¼è½¬æ¢ä¸ºâ€œé™æ€â€çš„4Dç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œä»¥ä¿ç•™è¾“å…¥ç‰©ä½“çš„è§†è§‰å±æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹å¯¹ç‰©ä½“è¿›è¡ŒåŠ¨ç”»å¤„ç†ã€‚ä¸ºäº†æé«˜è¿åŠ¨é€¼çœŸåº¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¢é‡è§†è§’é€‰æ‹©åè®®ç”¨äºé‡‡æ ·è§†è§’ï¼Œä»¥ä¿ƒè¿›æ›´é€¼çœŸçš„è¿åŠ¨ï¼Œä»¥åŠé®ç½©åˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±ï¼Œè¯¥æŸå¤±åˆ©ç”¨æ³¨æ„åŠ›å›¾å°†ä¼˜åŒ–é‡ç‚¹æ”¾åœ¨ç›¸å…³åŒºåŸŸã€‚æˆ‘ä»¬ä»æ—¶é—´è¿è´¯æ€§ã€æç¤ºéµå¾ªç¨‹åº¦å’Œè§†è§‰ä¿çœŸåº¦ä¸‰ä¸ªæ–¹é¢è¯„ä¼°äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå‘ç°æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¶ä»–æ–¹æ³•çš„åŸºç¡€ä¸Šè¡¨ç°æ›´å¥½ï¼Œåœ¨é€šè¿‡LPIPSåˆ†æ•°æµ‹é‡çš„èº«ä»½ä¿ç•™æ–¹é¢å®ç°äº†é«˜è¾¾ä¸‰å€çš„æå‡ï¼Œå¹¶åœ¨è§†è§‰è´¨é‡ä¸åŠ¨æ€å†…å®¹ä¹‹é—´å®ç°äº†æœ‰æ•ˆå¹³è¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20422v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€šè¿‡æ–‡æœ¬æç¤ºé©±åŠ¨ç”¨æˆ·æä¾›çš„3Då¯¹è±¡åŠ¨ç”»çš„æ–¹æ³•ï¼Œå®ç°äº†4Då†…å®¹çš„ç”Ÿæˆã€‚è¯¥æ–¹æ³•å…ˆå°†3Dç½‘æ ¼è½¬æ¢ä¸ºé™æ€çš„4Dç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œä¿ç•™è¾“å…¥å¯¹è±¡çš„è§†è§‰å±æ€§ï¼Œç„¶åä½¿ç”¨å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹è¿›è¡ŒåŠ¨ç”»åŒ–ã€‚ä¸ºæé«˜è¿åŠ¨çœŸå®æ„Ÿï¼Œå¼•å…¥äº†å¢é‡è§†è§’é€‰æ‹©åè®®å’Œå¸¦æ³¨æ„åŠ›å›¾çš„æ©è†œå¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒèº«ä»½è¿ç»­æ€§ã€éµå¾ªæç¤ºå’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå®ç°äº†ä¸‰å€çš„èº«ä»½ä¿ç•™æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥æŠ€æœ¯èƒ½å¤Ÿåˆ›å»ºé€šè¿‡æ–‡æœ¬æç¤ºæ§åˆ¶çš„4Då†…å®¹ï¼ˆåŠ¨æ€3Då¯¹è±¡ï¼‰ã€‚</li>
<li>å°†3Dç½‘æ ¼è½¬æ¢ä¸ºé™æ€çš„4Dç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œä¿ç•™å¯¹è±¡çš„è§†è§‰å±æ€§ã€‚</li>
<li>ä½¿ç”¨å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹å¯¹å¯¹è±¡è¿›è¡ŒåŠ¨ç”»åŒ–ã€‚</li>
<li>å¼•å…¥å¢é‡è§†è§’é€‰æ‹©åè®®ï¼Œä¿ƒè¿›æ›´é€¼çœŸçš„è¿åŠ¨ã€‚</li>
<li>ä½¿ç”¨æ©è†œå¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±æé«˜è¿åŠ¨çœŸå®æ„Ÿï¼Œåˆ©ç”¨æ³¨æ„åŠ›å›¾ä¼˜åŒ–ç›¸å…³åŒºåŸŸã€‚</li>
<li>åœ¨ä¿æŒèº«ä»½è¿ç»­æ€§ã€éµå¾ªæç¤ºå’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20422">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-438771f144c153b43a01cfe97fab3ae4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0e9598f4e678da3d65c4be1085d22a3c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Learning-Radiance-Fields-from-a-Single-Snapshot-Compressive-Image"><a href="#Learning-Radiance-Fields-from-a-Single-Snapshot-Compressive-Image" class="headerlink" title="Learning Radiance Fields from a Single Snapshot Compressive Image"></a>Learning Radiance Fields from a Single Snapshot Compressive Image</h2><p><strong>Authors:Yunhao Li, Xiang Liu, Xiaodong Wang, Xin Yuan, Peidong Liu</strong></p>
<p>In this paper, we explore the potential of Snapshot Compressive Imaging (SCI) technique for recovering the underlying 3D scene structure from a single temporal compressed image. SCI is a cost-effective method that enables the recording of high-dimensional data, such as hyperspectral or temporal information, into a single image using low-cost 2D imaging sensors. To achieve this, a series of specially designed 2D masks are usually employed, reducing storage and transmission requirements and offering potential privacy protection. Inspired by this, we take one step further to recover the encoded 3D scene information leveraging powerful 3D scene representation capabilities of neural radiance fields (NeRF). Specifically, we propose SCINeRF, in which we formulate the physical imaging process of SCI as part of the training of NeRF, allowing us to exploit its impressive performance in capturing complex scene structures. In addition, we further integrate the popular 3D Gaussian Splatting (3DGS) framework and propose SCISplat to improve 3D scene reconstruction quality and training&#x2F;rendering speed by explicitly optimizing point clouds into 3D Gaussian representations. To assess the effectiveness of our method, we conduct extensive evaluations using both synthetic data and real data captured by our SCI system. Experimental results demonstrate that our proposed approach surpasses the state-of-the-art methods in terms of image reconstruction and novel view synthesis. Moreover, our method also exhibits the ability to render high frame-rate multi-view consistent images in real time by leveraging SCI and the rendering capabilities of 3DGS. Codes will be available at: <a target="_blank" rel="noopener" href="https://github.com/WU-">https://github.com/WU-</a> CVGL&#x2F;SCISplat. </p>
<blockquote>
<p>æœ¬æ–‡æ¢è®¨äº†å¿«ç…§å‹ç¼©æˆåƒï¼ˆSCIï¼‰æŠ€æœ¯åœ¨ä»å•ä¸ªæ—¶é—´å‹ç¼©å›¾åƒä¸­æ¢å¤æ½œåœ¨çš„ä¸‰ç»´åœºæ™¯ç»“æ„æ–¹é¢çš„æ½œåŠ›ã€‚SCIæ˜¯ä¸€ç§ç»æµé«˜æ•ˆçš„æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿå°†é«˜ç»´æ•°æ®ï¼ˆå¦‚å…‰è°±æˆ–æ—¶é—´ä¿¡æ¯ï¼‰ä½¿ç”¨ä½æˆæœ¬çš„äºŒç»´æˆåƒä¼ æ„Ÿå™¨è®°å½•ä¸ºå•ä¸ªå›¾åƒã€‚ä¸ºå®ç°è¿™ä¸€ç‚¹ï¼Œé€šå¸¸é‡‡ç”¨ä¸€ç³»åˆ—ä¸“é—¨è®¾è®¡çš„äºŒç»´æ©è†œï¼Œä»¥é™ä½å­˜å‚¨å’Œä¼ è¾“è¦æ±‚å¹¶æä¾›æ½œåœ¨çš„éšç§ä¿æŠ¤ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ›´è¿›ä¸€æ­¥åˆ©ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å¼ºå¤§ä¸‰ç»´åœºæ™¯è¡¨ç¤ºèƒ½åŠ›ï¼Œæ¢å¤ç¼–ç çš„ä¸‰ç»´åœºæ™¯ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†SCINeRFï¼Œå…¶ä¸­æˆ‘ä»¬å°†SCIçš„ç‰©ç†æˆåƒè¿‡ç¨‹ä½œä¸ºNeRFè®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨å…¶æ•æ‰å¤æ‚åœºæ™¯ç»“æ„çš„ä»¤äººå°è±¡æ·±åˆ»çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥é›†æˆäº†æµè¡Œçš„ä¸‰ç»´é«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰æ¡†æ¶ï¼Œå¹¶æå‡ºäº†SCISplatï¼Œé€šè¿‡æ˜¾å¼ä¼˜åŒ–ç‚¹äº‘åˆ°ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºæ¥æé«˜ä¸‰ç»´åœºæ™¯é‡å»ºè´¨é‡ä»¥åŠè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆæˆæ•°æ®å’Œç”±æˆ‘ä»¬çš„SCIç³»ç»Ÿæ•è·çš„çœŸå®æ•°æ®è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å›¾åƒé‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆæ–¹é¢è¶…è¿‡äº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è€Œä¸”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜å±•ç¤ºäº†åˆ©ç”¨SCIå’Œ3DGSçš„æ¸²æŸ“èƒ½åŠ›å®æ—¶å‘ˆç°é«˜å¸§ç‡å¤šè§†è§’ä¸€è‡´å›¾åƒçš„èƒ½åŠ›ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/WU-CVGL/SCISplat%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/WU-CVGL/SCISplatä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19483v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºå¿«ç…§å‹ç¼©æˆåƒï¼ˆSCIï¼‰æŠ€æœ¯æ¢å¤æ½œåœ¨ä¸‰ç»´åœºæ™¯ç»“æ„çš„æ–¹æ³•ï¼Œä»å•å¼ æ—¶é—´å‹ç¼©å›¾åƒä¸­æ¢å¤ä¸‰ç»´åœºæ™¯ä¿¡æ¯ã€‚SCIæ˜¯ä¸€ç§ç»æµé«˜æ•ˆçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä½¿ç”¨ä½æˆæœ¬çš„äºŒç»´æˆåƒä¼ æ„Ÿå™¨è®°å½•é«˜ç»´æ•°æ®ï¼Œå¦‚è¶…å…‰è°±æˆ–æ—¶é—´ä¿¡æ¯ã€‚é€šè¿‡è®¾è®¡ä¸€ç³»åˆ—äºŒç»´æ©è†œå®ç°ç¼–ç è¿‡ç¨‹ï¼Œè¿™ç§æ–¹æ³•å‡å°‘äº†å­˜å‚¨å’Œä¼ è¾“éœ€æ±‚ï¼Œå¹¶æä¾›æ½œåœ¨éšç§ä¿æŠ¤ã€‚æœ¬ç ”ç©¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥é‡‡ç”¨ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰å¼ºå¤§çš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºèƒ½åŠ›æ¢å¤ç¼–ç çš„ä¸‰ç»´åœºæ™¯ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†SCINeRFæ–¹æ³•ï¼Œå°†SCIçš„ç‰©ç†æˆåƒè¿‡ç¨‹çº³å…¥NeRFçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨å…¶åœ¨æ•æ‰å¤æ‚åœºæ™¯ç»“æ„æ–¹é¢çš„å‡ºè‰²æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ•´åˆäº†æµè¡Œçš„ä¸‰ç»´é«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰æ¡†æ¶ï¼Œæå‡ºäº†SCISplatæ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–ç‚¹äº‘åˆ°ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºå½¢å¼æé«˜ä¸‰ç»´åœºæ™¯é‡å»ºè´¨é‡å¹¶åŠ é€Ÿè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚é€šè¿‡åˆæˆæ•°æ®å’Œç”±æˆ‘ä»¬çš„SCIç³»ç»Ÿæ•è·çš„çœŸå®æ•°æ®è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•è¶…è¶Šæœ€å…ˆè¿›çš„å›¾åƒé‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆæ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜å±•ç°äº†å€ŸåŠ©SCIå’Œ3DGSçš„æ¸²æŸ“èƒ½åŠ›å®æ—¶æ¸²æŸ“é«˜å¸§ç‡å¤šè§†è§’ä¸€è‡´å›¾åƒçš„èƒ½åŠ›ã€‚ç›¸å…³ä»£ç å°†å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/WU-CVGL/SCISplat%E3%80%82">https://github.com/WU-CVGL/SCISplatã€‚</a></p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>ç ”ç©¶åˆ©ç”¨å¿«ç…§å‹ç¼©æˆåƒï¼ˆSCIï¼‰æŠ€æœ¯ä»å•å¼ æ—¶é—´å‹ç¼©å›¾åƒä¸­æ¢å¤ä¸‰ç»´åœºæ™¯ç»“æ„ã€‚</li>
<li>SCIæ–¹æ³•åˆ©ç”¨ä½æˆæœ¬çš„äºŒç»´æˆåƒä¼ æ„Ÿå™¨è®°å½•é«˜ç»´æ•°æ®ã€‚</li>
<li>æå‡ºSCINeRFæ–¹æ³•ï¼Œç»“åˆNeRFçš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºèƒ½åŠ›æ¢å¤ç¼–ç çš„ä¸‰ç»´åœºæ™¯ä¿¡æ¯ã€‚</li>
<li>ç»“åˆä¸‰ç»´é«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰æ¡†æ¶çš„SCISplatæ–¹æ³•æé«˜äº†ä¸‰ç»´åœºæ™¯é‡å»ºè´¨é‡å’Œè®­ç»ƒ&#x2F;æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å›¾åƒé‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆæ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</li>
<li>æ–¹æ³•èƒ½å¤Ÿå®æ—¶æ¸²æŸ“é«˜å¸§ç‡å¤šè§†è§’ä¸€è‡´å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-078e653f005f60dd8eddb8f7e540ad8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0aa43ff602cb8e162d882386d84cb03d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-975272d5740b4d803f8a988529d6283f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="BeSplat-â€“-Gaussian-Splatting-from-a-Single-Blurry-Image-and-Event-Stream"><a href="#BeSplat-â€“-Gaussian-Splatting-from-a-Single-Blurry-Image-and-Event-Stream" class="headerlink" title="BeSplat â€“ Gaussian Splatting from a Single Blurry Image and Event   Stream"></a>BeSplat â€“ Gaussian Splatting from a Single Blurry Image and Event   Stream</h2><p><strong>Authors:Gopi Raju Matta, Reddypalli Trisha, Kaushik Mitra</strong></p>
<p>Novel view synthesis has been greatly enhanced by the development of radiance field methods. The introduction of 3D Gaussian Splatting (3DGS) has effectively addressed key challenges, such as long training times and slow rendering speeds, typically associated with Neural Radiance Fields (NeRF), while maintaining high-quality reconstructions. In this work (BeSplat), we demonstrate the recovery of sharp radiance field (Gaussian splats) from a single motion-blurred image and its corresponding event stream. Our method jointly learns the scene representation via Gaussian Splatting and recovers the camera motion through Bezier SE(3) formulation effectively, minimizing discrepancies between synthesized and real-world measurements of both blurry image and corresponding event stream. We evaluate our approach on both synthetic and real datasets, showcasing its ability to render view-consistent, sharp images from the learned radiance field and the estimated camera trajectory. To the best of our knowledge, ours is the first work to address this highly challenging ill-posed problem in a Gaussian Splatting framework with the effective incorporation of temporal information captured using the event stream. </p>
<blockquote>
<p>éšç€è¾å°„åœºæ–¹æ³•çš„å‘å±•ï¼Œæ–°å‹è§†å›¾åˆæˆæŠ€æœ¯å¾—åˆ°äº†æå¤§çš„å¢å¼ºã€‚3Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„å¼•å…¥æœ‰æ•ˆåœ°è§£å†³äº†ä¸ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é€šå¸¸ç›¸å…³çš„ä¸»è¦æŒ‘æˆ˜ï¼Œå¦‚è®­ç»ƒæ—¶é—´é•¿å’Œæ¸²æŸ“é€Ÿåº¦æ…¢ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„é‡å»ºã€‚åœ¨è¿™é¡¹å·¥ä½œï¼ˆBeSplatï¼‰ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä»å•ä¸ªè¿åŠ¨æ¨¡ç³Šå›¾åƒåŠå…¶ç›¸åº”çš„äº‹ä»¶æµä¸­æ¢å¤é”åˆ©çš„è¾å°„åœºï¼ˆé«˜æ–¯å–·æ¶‚ï¼‰çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡é«˜æ–¯å–·æ¶‚è”åˆå­¦ä¹ åœºæ™¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡è´å¡å°”SE(3)å…¬å¼æœ‰æ•ˆæ¢å¤ç›¸æœºè¿åŠ¨ï¼Œä»è€Œæœ€å°åŒ–åˆæˆå’ŒçœŸå®ä¸–ç•Œæµ‹é‡ä¹‹é—´çš„æ¨¡ç³Šå›¾åƒå’Œç›¸åº”äº‹ä»¶æµçš„å·®å¼‚ã€‚æˆ‘ä»¬åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†ä»å­¦ä¹ çš„è¾å°„åœºå’Œä¼°è®¡çš„ç›¸æœºè½¨è¿¹æ¸²æŸ“å‡ºä¸€è‡´ã€æ¸…æ™°å›¾åƒçš„èƒ½åŠ›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯åœ¨é«˜æ–¯å–·æ¶‚æ¡†æ¶ä¸‹è§£å†³è¿™ä¸€æå…·æŒ‘æˆ˜æ€§çš„ä¸é€‚å®šé—®é¢˜çš„é¦–æ‰¹å·¥ä½œä¹‹ä¸€ï¼Œæœ‰æ•ˆåœ°ç»“åˆäº†ä½¿ç”¨äº‹ä»¶æµæ•è·çš„æ—¶é—´ä¿¡æ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19370v1">PDF</a> Accepted for publication at EVGEN2025, WACV-25 Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•é€šè¿‡å¼•å…¥3Dé«˜æ–¯Splattingï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œè§£å†³ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é•¿æœŸå­˜åœ¨çš„è®­ç»ƒæ—¶é—´é•¿å’Œæ¸²æŸ“é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„é‡æ„ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†ä»å•å¼ è¿åŠ¨æ¨¡ç³Šå›¾åƒåŠå…¶å¯¹åº”çš„äº‹ä»¶æµä¸­æ¢å¤å‡ºé”åŒ–çš„è¾å°„åœºï¼ˆé«˜æ–¯Splatsï¼‰çš„èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡é«˜æ–¯Splattingå­¦ä¹ åœºæ™¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡Bezier SE(3)å…¬å¼æœ‰æ•ˆåœ°æ¢å¤ç›¸æœºè¿åŠ¨ï¼Œæœ€å°åŒ–åˆæˆå›¾åƒå’ŒçœŸå®ä¸–ç•Œæµ‹é‡ä¹‹é—´çš„æ¨¡ç³Šå›¾åƒå’Œå¯¹åº”äº‹ä»¶æµçš„å·®å¼‚ã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†è¯¥æ–¹æ³•èƒ½å¤Ÿä»å­¦ä¹ çš„è¾å°„åœºå’Œä¼°è®¡çš„ç›¸æœºè½¨è¿¹ä¸­æ¸²æŸ“å‡ºè¿è´¯ã€æ¸…æ™°çš„å›¾åƒã€‚è¿™æ˜¯é¦–æ¬¡åœ¨Gaussian Splattingæ¡†æ¶ä¸‹è§£å†³è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„ä¸é€‚å®šé—®é¢˜ï¼Œå¹¶æœ‰æ•ˆåˆ©ç”¨äº‹ä»¶æµæ•è·çš„æš‚æ—¶ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†3Dé«˜æ–¯SplattingæŠ€æœ¯ä»¥è§£å†³NeRFå­˜åœ¨çš„è®­ç»ƒæ—¶é—´é•¿å’Œæ¸²æŸ“é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚</li>
<li>æˆåŠŸä»å•å¼ è¿åŠ¨æ¨¡ç³Šå›¾åƒåŠå…¶å¯¹åº”çš„äº‹ä»¶æµä¸­æ¢å¤å‡ºé”åŒ–çš„è¾å°„åœºã€‚</li>
<li>é€šè¿‡é«˜æ–¯Splattingå­¦ä¹ åœºæ™¯è¡¨ç¤ºï¼Œå¹¶æœ‰æ•ˆåœ°æ¢å¤ç›¸æœºè¿åŠ¨ã€‚</li>
<li>åˆ©ç”¨Bezier SE(3)å…¬å¼æœ€å°åŒ–åˆæˆå›¾åƒå’ŒçœŸå®æµ‹é‡ä¹‹é—´çš„å·®å¼‚ã€‚</li>
<li>åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæ¸²æŸ“å‡ºè¿è´¯ã€æ¸…æ™°çš„å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19370">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dab0d13209460a513c971d77a5e93e0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6935f2f426b133e610bbdd5ce6245dfb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21b9e3e3453ea7e8aa8e5bc0f84b2ee4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de024f1fe0d234244b550d2c09cffce8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Generating-Editable-Head-Avatars-with-3D-Gaussian-GANs"><a href="#Generating-Editable-Head-Avatars-with-3D-Gaussian-GANs" class="headerlink" title="Generating Editable Head Avatars with 3D Gaussian GANs"></a>Generating Editable Head Avatars with 3D Gaussian GANs</h2><p><strong>Authors:Guohao Li, Hongyu Yang, Yifang Men, Di Huang, Weixin Li, Ruijie Yang, Yunhong Wang</strong></p>
<p>Generating animatable and editable 3D head avatars is essential for various applications in computer vision and graphics. Traditional 3D-aware generative adversarial networks (GANs), often using implicit fields like Neural Radiance Fields (NeRF), achieve photorealistic and view-consistent 3D head synthesis. However, these methods face limitations in deformation flexibility and editability, hindering the creation of lifelike and easily modifiable 3D heads. We propose a novel approach that enhances the editability and animation control of 3D head avatars by incorporating 3D Gaussian Splatting (3DGS) as an explicit 3D representation. This method enables easier illumination control and improved editability. Central to our approach is the Editable Gaussian Head (EG-Head) model, which combines a 3D Morphable Model (3DMM) with texture maps, allowing precise expression control and flexible texture editing for accurate animation while preserving identity. To capture complex non-facial geometries like hair, we use an auxiliary set of 3DGS and tri-plane features. Extensive experiments demonstrate that our approach delivers high-quality 3D-aware synthesis with state-of-the-art controllability. Our code and models are available at <a target="_blank" rel="noopener" href="https://github.com/liguohao96/EGG3D">https://github.com/liguohao96/EGG3D</a>. </p>
<blockquote>
<p>ç”Ÿæˆå¯åŠ¨ç”»åŒ–å’Œå¯ç¼–è¾‘çš„3Då¤´åƒå¯¹äºè®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„å„ç§åº”ç”¨è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„åŸºäºéšå¼åœºçš„3Dæ„ŸçŸ¥ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ï¼Œå¸¸å¸¸ä½¿ç”¨å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ç­‰æŠ€æœ¯ï¼Œå®ç°äº†é€¼çœŸçš„ã€è§†è§’ä¸€è‡´çš„3Då¤´åƒåˆæˆã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨å˜å½¢çµæ´»æ€§å’Œå¯ç¼–è¾‘æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œé˜»ç¢äº†ç”ŸåŠ¨ä¸”æ˜“äºä¿®æ”¹çš„3Då¤´åƒçš„åˆ›å»ºã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆæ˜¾å¼ä¸‰ç»´è¡¨ç¤ºæ³•â€”â€”ä¸‰ç»´é«˜æ–¯å–·å°„ï¼ˆ3DGSï¼‰çš„æ–°æ–¹æ³•ï¼Œä»¥æé«˜ä¸‰ç»´å¤´åƒçš„å¯ç¼–è¾‘æ€§å’ŒåŠ¨ç”»æ§åˆ¶åŠ›ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—å…‰ç…§æ§åˆ¶æ›´åŠ å®¹æ˜“ï¼Œå¯ç¼–è¾‘æ€§ä¹Ÿæ›´å¼ºã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯å¯ç¼–è¾‘é«˜æ–¯å¤´ï¼ˆEG-Headï¼‰æ¨¡å‹ï¼Œå®ƒå°†ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰ä¸çº¹ç†æ˜ å°„ç›¸ç»“åˆï¼Œå…è®¸ç²¾ç¡®çš„è¡¨æƒ…æ§åˆ¶å’Œçµæ´»çš„çº¹ç†ç¼–è¾‘ï¼Œä»¥å®ç°å‡†ç¡®çš„åŠ¨ç”»åŒæ—¶ä¿ç•™èº«ä»½ç‰¹å¾ã€‚ä¸ºäº†æ•æ‰å¤´å‘ç­‰éé¢éƒ¨å¤æ‚å‡ ä½•ç»“æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„è¾…åŠ©çš„3DGSå’Œä¸‰å¹³é¢ç‰¹å¾ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„å…·æœ‰å…ˆè¿›å¯æ§æ€§çš„ä¸‰ç»´æ„ŸçŸ¥åˆæˆã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/liguohao96/EGG3D%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/liguohao96/EGG3Dè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19149v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç”Ÿæˆå¯åŠ¨ç”»å’Œå¯ç¼–è¾‘çš„3Då¤´åƒçš„é‡è¦æ€§åŠå…¶åœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„å¤šç§åº”ç”¨ã€‚ä¼ ç»Ÿçš„ä½¿ç”¨NeRFç­‰éšå¼åœºçš„3D GANsè™½ç„¶å¯ä»¥å®ç°é€¼çœŸçš„3Då¤´åƒåˆæˆï¼Œä½†åœ¨å˜å½¢çµæ´»æ€§å’Œå¯ç¼–è¾‘æ€§æ–¹é¢å­˜åœ¨å±€é™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥3Dé«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰ä½œä¸ºæ˜ç¡®çš„3Dè¡¨ç¤ºï¼Œæé«˜äº†3Då¤´åƒçš„å¯ç¼–è¾‘æ€§å’ŒåŠ¨ç”»æ§åˆ¶ã€‚è¯¥æ–¹æ³•ä½¿ç”¨å¯ç¼–è¾‘çš„é«˜æ–¯å¤´åƒï¼ˆEG-Headï¼‰æ¨¡å‹ï¼Œç»“åˆ3Då½¢æ€æ¨¡å‹å’Œçº¹ç†æ˜ å°„ï¼Œå®ç°ç²¾ç¡®çš„è¡¨æƒ…æ§åˆ¶å’Œçµæ´»çš„çº¹ç†ç¼–è¾‘ï¼ŒåŒæ—¶ä¿æŒèº«ä»½è¯†åˆ«ã€‚ä¸ºäº†æ•æ‰éé¢éƒ¨å‡ ä½•å½¢çŠ¶ï¼ˆå¦‚å¤´å‘ï¼‰ï¼Œä½¿ç”¨äº†è¾…åŠ©çš„3DGSå’Œä¸‰å¹³é¢ç‰¹å¾ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„3Dæ„ŸçŸ¥åˆæˆï¼Œå¹¶å…·æœ‰è¾ƒé«˜çš„å¯æ§æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¯åŠ¨ç”»å’Œå¯ç¼–è¾‘çš„3Då¤´åƒå¯¹äºè®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦åº”ç”¨è‡³å…³é‡è¦ã€‚</li>
<li>ä¼ ç»Ÿä½¿ç”¨NeRFçš„3D GANsåœ¨å˜å½¢çµæ´»æ€§å’Œå¯ç¼–è¾‘æ€§æ–¹é¢å­˜åœ¨å±€é™ã€‚</li>
<li>å¼•å…¥3Dé«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰ä½œä¸ºæ˜ç¡®çš„3Dè¡¨ç¤ºï¼Œæé«˜äº†3Då¤´åƒçš„å¯ç¼–è¾‘æ€§å’ŒåŠ¨ç”»æ§åˆ¶ã€‚</li>
<li>å¯ç¼–è¾‘çš„é«˜æ–¯å¤´åƒï¼ˆEG-Headï¼‰æ¨¡å‹ç»“åˆäº†3Då½¢æ€æ¨¡å‹å’Œçº¹ç†æ˜ å°„ï¼Œå®ç°ç²¾ç¡®çš„è¡¨æƒ…æ§åˆ¶å’Œçµæ´»çš„çº¹ç†ç¼–è¾‘ã€‚</li>
<li>ä¸ºäº†æ•æ‰éé¢éƒ¨å‡ ä½•å½¢çŠ¶ï¼ˆå¦‚å¤´å‘ï¼‰ï¼Œä½¿ç”¨äº†è¾…åŠ©çš„3DGSå’Œä¸‰å¹³é¢ç‰¹å¾ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„3Dæ„ŸçŸ¥åˆæˆï¼Œå¹¶å…·æœ‰é«˜åº¦çš„å¯æ§æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19149">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3892a306159a58dca2515cad8e802c6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-519b6cc1bd7cf2c02053876e12ac88ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cad7b562387e86a3f6562767bcf1c692.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MVS-GS-High-Quality-3D-Gaussian-Splatting-Mapping-via-Online-Multi-View-Stereo"><a href="#MVS-GS-High-Quality-3D-Gaussian-Splatting-Mapping-via-Online-Multi-View-Stereo" class="headerlink" title="MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View   Stereo"></a>MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View   Stereo</h2><p><strong>Authors:Byeonggwon Lee, Junkyu Park, Khang Truong Giang, Sungho Jo, Soohwan Song</strong></p>
<p>This study addresses the challenge of online 3D model generation for neural rendering using an RGB image stream. Previous research has tackled this issue by incorporating Neural Radiance Fields (NeRF) or 3D Gaussian Splatting (3DGS) as scene representations within dense SLAM methods. However, most studies focus primarily on estimating coarse 3D scenes rather than achieving detailed reconstructions. Moreover, depth estimation based solely on images is often ambiguous, resulting in low-quality 3D models that lead to inaccurate renderings. To overcome these limitations, we propose a novel framework for high-quality 3DGS modeling that leverages an online multi-view stereo (MVS) approach. Our method estimates MVS depth using sequential frames from a local time window and applies comprehensive depth refinement techniques to filter out outliers, enabling accurate initialization of Gaussians in 3DGS. Furthermore, we introduce a parallelized backend module that optimizes the 3DGS model efficiently, ensuring timely updates with each new keyframe. Experimental results demonstrate that our method outperforms state-of-the-art dense SLAM methods, particularly excelling in challenging outdoor environments. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æ—¨åœ¨åº”å¯¹ä½¿ç”¨RGBå›¾åƒæµè¿›è¡Œç¥ç»æ¸²æŸ“çš„åœ¨çº¿3Dæ¨¡å‹ç”ŸæˆæŒ‘æˆ˜ã€‚ä¹‹å‰çš„ç ”ç©¶å·²ç»é€šè¿‡ç»“åˆç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–3Dé«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰ä½œä¸ºå¯†é›†SLAMæ–¹æ³•å†…çš„åœºæ™¯è¡¨ç¤ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä¼°è®¡ç²—ç³™çš„3Dåœºæ™¯ï¼Œè€Œä¸æ˜¯å®ç°è¯¦ç»†çš„é‡å»ºã€‚æ­¤å¤–ï¼Œä»…åŸºäºå›¾åƒçš„æ·±åº¦ä¼°è®¡å¾€å¾€å…·æœ‰æ¨¡ç³Šæ€§ï¼Œå¯¼è‡´è´¨é‡è¾ƒä½çš„3Dæ¨¡å‹ï¼Œä»è€Œå¯¼è‡´æ¸²æŸ“ä¸å‡†ç¡®ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåœ¨çº¿å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•çš„é«˜è´¨é‡çš„3DGSå»ºæ¨¡æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨æ¥è‡ªå±€éƒ¨æ—¶é—´çª—å£çš„è¿ç»­å¸§æ¥ä¼°è®¡MVSæ·±åº¦ï¼Œå¹¶é‡‡ç”¨å…¨é¢çš„æ·±åº¦ç»†åŒ–æŠ€æœ¯æ¥è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œä»è€Œå®ç°3DGSä¸­é«˜æ–¯å€¼çš„å‡†ç¡®åˆå§‹åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªå¹¶è¡ŒåŒ–çš„åç«¯æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥æœ‰æ•ˆåœ°ä¼˜åŒ–3DGSæ¨¡å‹ï¼Œç¡®ä¿æ¯ä¸ªæ–°å…³é”®å¸§éƒ½èƒ½åŠæ—¶å¾—åˆ°æ›´æ–°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æŒ‘æˆ˜æ€§æˆ·å¤–ç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„å¯†é›†SLAMæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19130v1">PDF</a> 7 pages, 6 figures, submitted to IEEE ICRA 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåœ¨çº¿å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•çš„é«˜è´¨é‡ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰å»ºæ¨¡æ¡†æ¶ï¼Œç”¨äºè§£å†³åœ¨çº¿ä¸‰ç»´æ¨¡å‹ç”Ÿæˆä¸­çš„ç¥ç»æ¸²æŸ“æŒ‘æˆ˜ã€‚é€šè¿‡åˆ©ç”¨åºåˆ—å¸§çš„å±€éƒ¨æ—¶é—´çª—å£ä¼°è®¡MVSæ·±åº¦ï¼Œå¹¶åº”ç”¨å…¨é¢çš„æ·±åº¦ä¼˜åŒ–æŠ€æœ¯è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œå®ç°äº†é«˜ç²¾åº¦çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ¸²æŸ“ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†å¹¶è¡Œåç«¯æ¨¡å—ï¼Œä¼˜åŒ–3DGSæ¨¡å‹çš„æ•ˆç‡ï¼Œç¡®ä¿åŠæ—¶æ›´æ–°æ¯ä¸ªæ–°å…³é”®å¸§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰å¯†é›†SLAMæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å¤–ç¯å¢ƒä¸­è¡¨ç°æ›´ä¼˜ç§€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li><p>ç ”ç©¶èƒŒæ™¯ï¼šåœ¨çº¿ä¸‰ç»´æ¨¡å‹ç”Ÿæˆå¯¹äºç¥ç»æ¸²æŸ“æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åŸºäºRGBå›¾åƒæµè¿›è¡Œä¼°è®¡ã€‚å…ˆå‰çš„ç ”ç©¶ä¸»è¦èšç„¦äºé€šè¿‡å¼•å…¥NeRFæˆ–3DGSæŠ€æœ¯æ¥å»ºç«‹åœºæ™¯è¡¨ç¤ºï¼Œä½†è¿™äº›ç ”ç©¶æ›´å¤šåœ°å…³æ³¨ç²—ç•¥çš„ä¸‰ç»´åœºæ™¯ä¼°è®¡è€Œéè¯¦ç»†é‡å»ºã€‚</p>
</li>
<li><p>å±€é™æ€§çš„è§£å†³ï¼šé’ˆå¯¹ç°æœ‰ç ”ç©¶çš„ä¸è¶³ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºåœ¨çº¿å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•çš„æ¡†æ¶è¿›è¡Œé«˜è´¨é‡å»ºæ¨¡ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨å±€éƒ¨æ—¶é—´çª—å£å†…çš„åºåˆ—å¸§ä¼°è®¡MVSæ·±åº¦ï¼Œè§£å†³äº†æ·±åº¦ä¼°è®¡çš„æ¨¡ç³Šæ€§é—®é¢˜ã€‚</p>
</li>
<li><p>æ·±åº¦ä¼˜åŒ–æŠ€æœ¯ï¼šé€šè¿‡å…¨é¢çš„æ·±åº¦ä¼˜åŒ–æŠ€æœ¯è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œæé«˜äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä»è€Œå®ç°äº†é«˜ç²¾åº¦çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ¸²æŸ“ã€‚</p>
</li>
<li><p>å¹¶è¡Œåç«¯æ¨¡å—ï¼šå¼•å…¥å¹¶è¡Œåç«¯æ¨¡å—ä»¥ä¼˜åŒ–3DGSæ¨¡å‹çš„æ•ˆç‡ï¼Œç¡®ä¿æ¯ä¸ªæ–°å…³é”®å¸§éƒ½èƒ½å¾—åˆ°åŠæ—¶æ›´æ–°ã€‚</p>
</li>
<li><p>å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç ”ç©¶æå‡ºçš„æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰çš„å¯†é›†SLAMæ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨æŒ‘æˆ˜æ€§çš„å®¤å¤–ç¯å¢ƒä¸­ï¼Œå…¶è¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®ã€æ›´ç²¾ç»†çš„ä¸‰ç»´æ¨¡å‹ã€‚</p>
</li>
<li><p>æ–¹æ³•åˆ›æ–°ç‚¹ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†åœ¨çº¿å¤šè§†è§’ç«‹ä½“æ–¹æ³•å’Œæ·±åº¦ä¼˜åŒ–æŠ€æœ¯ï¼Œå®ç°äº†é«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ¸²æŸ“æ•ˆæœã€‚åŒæ—¶ï¼Œå¼•å…¥çš„å¹¶è¡Œåç«¯æ¨¡å—è¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡ã€‚</p>
</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19130">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e3972536eeef7a870fd4b6f2e82c4eff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e26773a7c0b29e8469003d8fd2c8b0d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2488254f795e6af4e6e6e3a7288a8b2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1bc1c8b72af53bd6298553df981f5fac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a64f64cd37fbee41aeaab3cc2f4d545a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8636ce2cc6fb43899937bfaa1789ea4a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Humans-as-a-Calibration-Pattern-Dynamic-3D-Scene-Reconstruction-from-Unsynchronized-and-Uncalibrated-Videos"><a href="#Humans-as-a-Calibration-Pattern-Dynamic-3D-Scene-Reconstruction-from-Unsynchronized-and-Uncalibrated-Videos" class="headerlink" title="Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from   Unsynchronized and Uncalibrated Videos"></a>Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from   Unsynchronized and Uncalibrated Videos</h2><p><strong>Authors:Changwoon Choi, Jeongjun Kim, Geonho Cha, Minkwan Kim, Dongyoon Wee, Young Min Kim</strong></p>
<p>Recent works on dynamic neural field reconstruction assume input from synchronized multi-view videos with known poses. These input constraints are often unmet in real-world setups, making the approach impractical. We demonstrate that unsynchronized videos with unknown poses can generate dynamic neural fields if the videos capture human motion. Humans are one of the most common dynamic subjects whose poses can be estimated using state-of-the-art methods. While noisy, the estimated human shape and pose parameters provide a decent initialization for the highly non-convex and under-constrained problem of training a consistent dynamic neural representation. Given the sequences of pose and shape of humans, we estimate the time offsets between videos, followed by camera pose estimations by analyzing 3D joint locations. Then, we train dynamic NeRF employing multiresolution rids while simultaneously refining both time offsets and camera poses. The setup still involves optimizing many parameters, therefore, we introduce a robust progressive learning strategy to stabilize the process. Experiments show that our approach achieves accurate spatiotemporal calibration and high-quality scene reconstruction in challenging conditions. </p>
<blockquote>
<p>å…³äºåŠ¨æ€ç¥ç»ç½‘ç»œé‡å»ºçš„æœ€æ–°å·¥ä½œå‡è®¾è¾“å…¥æ¥è‡ªåŒæ­¥çš„å¤šè§†è§’è§†é¢‘ï¼Œå¹¶ä¸”å·²çŸ¥å§¿æ€ã€‚ç„¶è€Œåœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™äº›è¾“å…¥çº¦æŸé€šå¸¸æ— æ³•å¾—åˆ°æ»¡è¶³ï¼Œä½¿å¾—è¿™ç§æ–¹æ³•ä¸åˆ‡å®é™…ã€‚æˆ‘ä»¬è¯æ˜ï¼Œå¯¹äºæ•æ‰äººç±»åŠ¨ä½œçš„è§†é¢‘ï¼Œå³ä½¿è§†é¢‘ä¸åŒæ­¥ä¸”å§¿æ€æœªçŸ¥ï¼Œä¹Ÿèƒ½ç”ŸæˆåŠ¨æ€ç¥ç»ç½‘ç»œã€‚äººç±»æ˜¯æœ€å¸¸è§çš„åŠ¨æ€ä¸»é¢˜ä¹‹ä¸€ï¼Œå…¶å§¿æ€å¯ä»¥ä½¿ç”¨æœ€æ–°æ–¹æ³•è¿›è¡Œä¼°è®¡ã€‚è™½ç„¶å­˜åœ¨å™ªå£°ï¼Œä½†ä¼°è®¡å‡ºçš„äººç±»å½¢çŠ¶å’Œå§¿æ€å‚æ•°å¯¹äºè®­ç»ƒä¸€è‡´çš„åŠ¨æ€ç¥ç»ç½‘ç»œè¿™ä¸€é«˜åº¦éå‡¸å’Œæ¬ çº¦æŸçš„é—®é¢˜æä¾›äº†ä¸€ä¸ªä¸é”™çš„åˆå§‹å€¼ã€‚ç»™å®šäººç±»å§¿åŠ¿å’Œå½¢çŠ¶çš„åºåˆ—ï¼Œæˆ‘ä»¬ä¼°è®¡è§†é¢‘ä¹‹é—´çš„æ—¶é—´åç§»ï¼Œç„¶åé€šè¿‡åˆ†æ3Då…³èŠ‚ä½ç½®è¿›è¡Œç›¸æœºå§¿æ€ä¼°è®¡ã€‚ç„¶åï¼Œæˆ‘ä»¬é‡‡ç”¨å¤šåˆ†è¾¨ç‡ç½‘æ ¼è®­ç»ƒåŠ¨æ€NeRFï¼ŒåŒæ—¶è°ƒæ•´æ—¶é—´åç§»å’Œç›¸æœºå§¿æ€ã€‚è¯¥è®¾ç½®ä»ç„¶éœ€è¦ä¼˜åŒ–è®¸å¤šå‚æ•°ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç¨³å¥çš„æ¸è¿›å­¦ä¹ ç­–ç•¥æ¥ç¨³å®šè¿™ä¸€è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†å‡†ç¡®çš„æ—¶ç©ºæ ‡å®šå’Œé«˜è´¨é‡çš„åœºæ™¯é‡å»ºï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜çš„ç¯å¢ƒä¸­ä¹Ÿèƒ½å–å¾—è‰¯å¥½çš„æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19089v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³åŠ¨æ€ç¥ç»åœºé‡å»ºåœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„å®ç”¨æ€§é—®é¢˜ã€‚é€šè¿‡å¯¹äººä½“å§¿æ€çš„ä¼°è®¡å’Œæ—¶ç©ºæ ¡å‡†çš„ä¼˜åŒ–ï¼Œå®ç°åŠ¨æ€ç¥ç»åœºé‡å»ºã€‚ä½¿ç”¨å¤šåˆ†è¾¨ç‡ç½‘æ ¼å’Œæ¸è¿›å­¦ä¹ æ–¹æ³•ï¼Œæé«˜äº†åœºæ™¯é‡å»ºçš„è´¨é‡å’Œç¨³å®šæ€§ã€‚å³ä½¿é¢å¯¹ä¸åŒæ­¥è§†é¢‘å’ŒæœªçŸ¥å§¿æ€çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä»ç„¶å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„åœºæ™¯é‡å»ºç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å·¥ä½œè§£å†³åŠ¨æ€ç¥ç»åœºé‡å»ºåœ¨çœŸå®åœºæ™¯ä¸­çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯è§†é¢‘åŒæ­¥å’Œå§¿æ€æœªçŸ¥çš„é—®é¢˜ã€‚</li>
<li>æå‡ºä½¿ç”¨äººä½“å§¿æ€ä¼°è®¡æ¥è§£å†³è®­ç»ƒåŠ¨æ€ç¥ç»è¡¨ç¤ºä¸­çš„é«˜åº¦éå‡¸å’Œæ¬ çº¦æŸé—®é¢˜ã€‚</li>
<li>é€šè¿‡å¯¹äººä½“å§¿æ€å’Œå½¢çŠ¶çš„åºåˆ—è¿›è¡Œæ—¶é—´åç§»ä¼°è®¡å’Œæ‘„åƒæœºå§¿æ€ä¼°è®¡ï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè§’åº¦çš„è°ƒæ•´å’Œä¼˜åŒ–ã€‚</li>
<li>åˆ©ç”¨å¤šåˆ†è¾¨ç‡ç½‘æ ¼æŠ€æœ¯è®­ç»ƒåŠ¨æ€NeRFæ¨¡å‹ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æå‡ºä¸€ç§ç¨³å¥çš„æ¸è¿›å­¦ä¹ ç­–ç•¥æ¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œå³ä½¿åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ï¼Œè¯¥æ–¹æ³•çš„æ—¶ç©ºæ ¡å‡†å‡†ç¡®æ€§è¾ƒé«˜ä¸”åœºæ™¯é‡å»ºè´¨é‡è¾ƒå¥½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19089">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fca17d77eea34ee6a279440b357d94bb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-258a5fd0cfe85172780255e5bcadd5e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-861a6a221059ed3122f6776120082d83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3c161c3e3ef89e5c6697a800176ef66.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0d61a3ec03e4f212d16afb4fead0a57.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Developing-Cryptocurrency-Trading-Strategy-Based-on-Autoencoder-CNN-GANs-Algorithms"><a href="#Developing-Cryptocurrency-Trading-Strategy-Based-on-Autoencoder-CNN-GANs-Algorithms" class="headerlink" title="Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs   Algorithms"></a>Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs   Algorithms</h2><p><strong>Authors:Zhuohuan Hu, Richard Yu, Zizhou Zhang, Haoran Zheng, Qianying Liu, Yining Zhou</strong></p>
<p>This paper leverages machine learning algorithms to forecast and analyze financial time series. The process begins with a denoising autoencoder to filter out random noise fluctuations from the main contract price data. Then, one-dimensional convolution reduces the dimensionality of the filtered data and extracts key information. The filtered and dimensionality-reduced price data is fed into a GANs network, and its output serve as input of a fully connected network. Through cross-validation, a model is trained to capture features that precede large price fluctuations. The model predicts the likelihood and direction of significant price changes in real-time price sequences, placing trades at moments of high prediction accuracy. Empirical results demonstrate that using autoencoders and convolution to filter and denoise financial data, combined with GANs, achieves a certain level of predictive performance, validating the capabilities of machine learning algorithms to discover underlying patterns in financial sequences. Keywords - CNN;GANs; Cryptocurrency; Prediction. </p>
<blockquote>
<p>æœ¬æ–‡åˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å¯¹é‡‘èæ—¶é—´åºåˆ—è¿›è¡Œé¢„æµ‹å’Œåˆ†æã€‚æµç¨‹å§‹äºä½¿ç”¨é™å™ªè‡ªç¼–ç å™¨å¯¹ä¸»åˆçº¦ä»·æ ¼æ•°æ®è¿›è¡Œéšæœºå™ªå£°æ³¢åŠ¨çš„è¿‡æ»¤ã€‚ç„¶åï¼Œä¸€ç»´å·ç§¯å¯¹è¿‡æ»¤åçš„æ•°æ®è¿›è¡Œé™ç»´å¹¶æå–å…³é”®ä¿¡æ¯ã€‚è¿‡æ»¤å’Œé™ç»´åçš„ä»·æ ¼æ•°æ®è¢«è¾“å…¥åˆ°GANsç½‘ç»œä¸­ï¼Œå…¶è¾“å‡ºä½œä¸ºå…¨è¿æ¥ç½‘ç»œçš„è¾“å…¥ã€‚é€šè¿‡äº¤å‰éªŒè¯ï¼Œè®­ç»ƒæ¨¡å‹ä»¥æ•è·å…ˆäºå¤§å¹…ä»·æ ¼æ³¢åŠ¨çš„ç‰¹å¾ã€‚è¯¥æ¨¡å‹é¢„æµ‹å®æ—¶ä»·æ ¼åºåˆ—ä¸­é‡å¤§ä»·æ ¼å˜åŠ¨çš„å¯èƒ½æ€§å’Œæ–¹å‘ï¼Œåœ¨é«˜é¢„æµ‹å‡†ç¡®æ€§çš„æ—¶åˆ»è¿›è¡Œäº¤æ˜“ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œç»“åˆä½¿ç”¨è‡ªç¼–ç å™¨å’Œå·ç§¯å¯¹é‡‘èæ•°æ®è¿›è¡Œè¿‡æ»¤å’Œå»å™ªï¼Œç»“åˆGANsï¼Œè¾¾åˆ°äº†ä¸€å®šçš„é¢„æµ‹æ€§èƒ½ï¼ŒéªŒè¯äº†æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å‘ç°é‡‘èåºåˆ—ä¸­æ½œåœ¨æ¨¡å¼æ–¹é¢çš„èƒ½åŠ›ã€‚å…³é”®è¯â€”â€”å·ç§¯ç¥ç»ç½‘ç»œã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€åŠ å¯†è´§å¸ã€é¢„æµ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18202v2">PDF</a> The paper was accepted by 2024 4th International Conference on   Artificial Intelligence, Robotics, and Communication(ICAIRC 2024)</p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡åˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å¯¹é‡‘èæ—¶é—´åºåˆ—è¿›è¡Œé¢„æµ‹ä¸åˆ†æã€‚é€šè¿‡é™å™ªè‡ªç¼–ç å™¨è¿‡æ»¤ä¸»åˆåŒä»·æ ¼æ•°æ®ä¸­çš„éšæœºå™ªå£°æ³¢åŠ¨ï¼Œä¸€ç»´å·ç§¯é™ä½æ•°æ®ç»´åº¦å¹¶æå–å…³é”®ä¿¡æ¯ã€‚ç»è¿‡è¿‡æ»¤å’Œé™ç»´çš„ä»·æ ¼æ•°æ®è¾“å…¥ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œå…¶è¾“å‡ºä½œä¸ºå…¨è¿æ¥ç½‘ç»œçš„è¾“å…¥ã€‚é€šè¿‡äº¤å‰éªŒè¯ï¼Œè®­ç»ƒæ¨¡å‹æ•æ‰å¤§ä»·æ ¼æ³¢åŠ¨å‰çš„ç‰¹å¾ã€‚è¯¥æ¨¡å‹é¢„æµ‹å®æ—¶ä»·æ ¼åºåˆ—ä¸­é‡å¤§ä»·æ ¼å˜åŒ–çš„å¯èƒ½æ€§å’Œæ–¹å‘ï¼Œåœ¨é«˜é¢„æµ‹å‡†ç¡®ç‡æ—¶åˆ»è¿›è¡Œäº¤æ˜“ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œç»“åˆè‡ªç¼–ç å™¨ã€å·ç§¯é™å™ªå’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œæœºå™¨å­¦ä¹ ç®—æ³•åœ¨å‘ç°é‡‘èåºåˆ—ä¸­çš„æ½œåœ¨æ¨¡å¼æ–¹é¢å…·æœ‰ä¸€å®šçš„é¢„æµ‹æ€§èƒ½ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>ä½¿ç”¨é™å™ªè‡ªç¼–ç å™¨è¿‡æ»¤é‡‘èæ—¶é—´åºåˆ—æ•°æ®ä¸­çš„éšæœºå™ªå£°ã€‚</li>
<li>ä¸€ç»´å·ç§¯ç”¨äºé™ä½æ•°æ®ç»´åº¦å¹¶æå–å…³é”®ä¿¡æ¯ã€‚</li>
<li>ç»“åˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œå…¨è¿æ¥ç½‘ç»œè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚</li>
<li>é€šè¿‡äº¤å‰éªŒè¯ï¼Œæ¨¡å‹èƒ½å¤Ÿæ•æ‰å¤§ä»·æ ¼æ³¢åŠ¨å‰çš„ç‰¹å¾ã€‚</li>
<li>æ¨¡å‹å¯é¢„æµ‹å®æ—¶ä»·æ ¼åºåˆ—ä¸­é‡å¤§ä»·æ ¼å˜åŒ–çš„å¯èƒ½æ€§å’Œæ–¹å‘ã€‚</li>
<li>å®è¯ç»“æœè¡¨æ˜ï¼Œç»“åˆè‡ªç¼–ç å™¨å’Œå·ç§¯çš„é‡‘èæ•°æ®é¢„å¤„ç†ï¼Œä»¥åŠGANsçš„ä½¿ç”¨ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•å…·æœ‰è‰¯å¥½çš„é¢„æµ‹æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18202">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-712324057607daf0b286f3c929152760.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-718132e6f5bbf9d8ece72adb831f3ee7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-775bd2dbb4b1d784c9ce616ede537d86.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="LiHi-GS-LiDAR-Supervised-Gaussian-Splatting-for-Highway-Driving-Scene-Reconstruction"><a href="#LiHi-GS-LiDAR-Supervised-Gaussian-Splatting-for-Highway-Driving-Scene-Reconstruction" class="headerlink" title="LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene   Reconstruction"></a>LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene   Reconstruction</h2><p><strong>Authors:Pou-Chun Kung, Xianling Zhang, Katherine A. Skinner, Nikita Jaipuria</strong></p>
<p>Photorealistic 3D scene reconstruction plays an important role in autonomous driving, enabling the generation of novel data from existing datasets to simulate safety-critical scenarios and expand training data without additional acquisition costs. Gaussian Splatting (GS) facilitates real-time, photorealistic rendering with an explicit 3D Gaussian representation of the scene, providing faster processing and more intuitive scene editing than the implicit Neural Radiance Fields (NeRFs). While extensive GS research has yielded promising advancements in autonomous driving applications, they overlook two critical aspects: First, existing methods mainly focus on low-speed and feature-rich urban scenes and ignore the fact that highway scenarios play a significant role in autonomous driving. Second, while LiDARs are commonplace in autonomous driving platforms, existing methods learn primarily from images and use LiDAR only for initial estimates or without precise sensor modeling, thus missing out on leveraging the rich depth information LiDAR offers and limiting the ability to synthesize LiDAR data. In this paper, we propose a novel GS method for dynamic scene synthesis and editing with improved scene reconstruction through LiDAR supervision and support for LiDAR rendering. Unlike prior works that are tested mostly on urban datasets, to the best of our knowledge, we are the first to focus on the more challenging and highly relevant highway scenes for autonomous driving, with sparse sensor views and monotone backgrounds. Visit our project page at: <a target="_blank" rel="noopener" href="https://umautobots.github.io/lihi_gs">https://umautobots.github.io/lihi_gs</a> </p>
<blockquote>
<p>çœŸå®æ„Ÿä¸‰ç»´åœºæ™¯é‡å»ºåœ¨è‡ªåŠ¨é©¾é©¶ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚å®ƒå¯ä»¥ä»ç°æœ‰æ•°æ®é›†ä¸­ç”Ÿæˆæ–°çš„æ•°æ®ï¼Œæ¨¡æ‹Ÿå…³é”®å®‰å…¨åœºæ™¯ï¼Œå¹¶åœ¨æ— éœ€é¢å¤–é‡‡é›†æˆæœ¬çš„æƒ…å†µä¸‹æ‰©å±•è®­ç»ƒæ•°æ®ã€‚é«˜æ–¯æ‹¼è´´ï¼ˆGSï¼‰æŠ€æœ¯é€šè¿‡åœºæ™¯çš„æ˜¾å¼ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œå®ç°äº†å®æ—¶çœŸå®æ„Ÿæ¸²æŸ“ï¼Œç›¸è¾ƒäºéšå¼ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æä¾›äº†æ›´å¿«çš„å¤„ç†å’Œæ›´ç›´è§‚çš„åœºæ™¯ç¼–è¾‘ã€‚å°½ç®¡å…³äºé«˜æ–¯æ‹¼è´´çš„ç ”ç©¶å·²ç»åœ¨è‡ªåŠ¨é©¾é©¶åº”ç”¨æ–¹é¢å–å¾—äº†æœ‰å‰æ™¯çš„è¿›å±•ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šé¦–å…ˆï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½é€Ÿä¸”ç‰¹å¾ä¸°å¯Œçš„åŸå¸‚åœºæ™¯ä¸Šï¼Œå¿½ç•¥äº†é«˜é€Ÿå…¬è·¯åœºæ™¯åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„é‡è¦åœ°ä½ã€‚å…¶æ¬¡ï¼Œè™½ç„¶æ¿€å…‰é›·è¾¾åœ¨è‡ªåŠ¨é©¾é©¶å¹³å°ä¸­å¾ˆæ™®éï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å›¾åƒè¿›è¡Œå­¦ä¹ ï¼Œä»…å°†æ¿€å…‰é›·è¾¾ç”¨äºåˆæ­¥ä¼°è®¡æˆ–ä¸ç²¾ç¡®çš„ä¼ æ„Ÿå™¨å»ºæ¨¡ï¼Œä»è€Œæœªèƒ½å……åˆ†åˆ©ç”¨æ¿€å…‰é›·è¾¾æä¾›çš„ä¸°å¯Œæ·±åº¦ä¿¡æ¯ï¼Œå¹¶é™åˆ¶äº†åˆæˆæ¿€å…‰é›·è¾¾æ•°æ®çš„èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯æ‹¼è´´æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€åœºæ™¯åˆæˆå’Œç¼–è¾‘ã€‚é€šè¿‡æ¿€å…‰é›·è¾¾ç›‘ç£å’Œæ”¯æŒæ¿€å…‰é›·è¾¾æ¸²æŸ“ï¼Œæ”¹è¿›äº†åœºæ™¯é‡å»ºã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œä¸å¤§å¤šæ•°ä»…åœ¨åŸå¸‚æ•°æ®é›†ä¸Šæµ‹è¯•çš„å…ˆå‰å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬é¦–æ¬¡å…³æ³¨æ›´å…·æŒ‘æˆ˜æ€§å’Œé«˜åº¦ç›¸å…³çš„è‡ªåŠ¨é©¾é©¶é«˜é€Ÿå…¬è·¯åœºæ™¯ï¼Œå…·æœ‰ç¨€ç–çš„ä¼ æ„Ÿå™¨è§†å›¾å’Œå•è°ƒçš„èƒŒæ™¯ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://umautobots.github.io/lihi_gs">https://umautobots.github.io/lihi_gs</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15447v2">PDF</a> </p>
<p><strong>Summary</strong><br>åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒåŸºäºLiDARçš„ä¸‰ç»´åœºæ™¯é‡å»ºå…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼Œç»“åˆLiDARçš„ä¸°å¯Œæ·±åº¦ä¿¡æ¯ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„åŠ¨æ€åœºæ™¯åˆæˆä¸ç¼–è¾‘æ–¹æ³•ã€‚æ­¤æ–¹æ³•ä¸ä»…æé«˜äº†åœºæ™¯é‡å»ºçš„ç²¾åº¦ï¼Œè¿˜æ”¯æŒLiDARæ¸²æŸ“ï¼Œé€‚ç”¨äºé«˜é€Ÿå…¬è·¯åœºæ™¯ã€‚æ­¤ç ”ç©¶å¯¹è‡ªåŠ¨é©¾é©¶çš„æ•°æ®æ‰©å……åŠæ¨¡æ‹Ÿå®‰å…¨å…³é”®åœºæ™¯å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…‰åœºæ¸²æŸ“æŠ€æœ¯åœ¨è‡ªåŠ¨é©¾é©¶ä¸­å…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯ç”Ÿæˆæ–°çš„æ•°æ®é›†ä»¥æ¨¡æ‹Ÿå®‰å…¨å…³é”®åœºæ™¯å’Œæ‰©å¤§è®­ç»ƒæ•°æ®æ–¹é¢ã€‚</li>
<li>é«˜æ–¯æ¸²æŸ“ï¼ˆGSï¼‰æ–¹æ³•æä¾›äº†ä¸€ç§å®æ—¶ã€é€¼çœŸçš„æ¸²æŸ“æ–¹å¼ï¼Œé€šè¿‡æ˜ç¡®çš„3Dé«˜æ–¯åœºæ™¯è¡¨ç¤ºï¼Œå®ç°æ›´å¿«çš„å¤„ç†å’Œæ›´ç›´è§‚çš„åœºæ™¯ç¼–è¾‘ã€‚</li>
<li>ç›®å‰GSæ–¹æ³•ä¸»è¦å…³æ³¨ä½é€Ÿåº¦ã€ç‰¹å¾ä¸°å¯Œçš„åŸå¸‚åœºæ™¯ï¼Œä½†åœ¨é«˜é€Ÿå…¬è·¯åœºæ™¯çš„è‡ªåŠ¨é©¾é©¶åº”ç”¨ä¸­ä»æ˜¾ä¸è¶³ã€‚</li>
<li>LiDARåœ¨è‡ªåŠ¨é©¾é©¶å¹³å°ä¸­æ™®åŠï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å›¾åƒå­¦ä¹ ï¼Œæœªå……åˆ†åˆ©ç”¨LiDARæä¾›çš„ä¸°å¯Œæ·±åº¦ä¿¡æ¯ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„GSæ–¹æ³•ï¼Œé€šè¿‡LiDARç›‘ç£å’Œæ”¯æŒLiDARæ¸²æŸ“ï¼Œæ”¹å–„äº†åœºæ™¯é‡å»ºæ•ˆæœã€‚</li>
<li>ä¸å¤§å¤šæ•°ä»…åœ¨åŸå¸‚æ•°æ®é›†ä¸Šæµ‹è¯•çš„æ–¹æ³•ä¸åŒï¼Œæœ¬æ–‡é¦–æ¬¡ä¸“æ³¨äºæ›´å…·æŒ‘æˆ˜æ€§å’Œé«˜åº¦ç›¸å…³çš„é«˜é€Ÿå…¬è·¯åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15447">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-84726a72b31a702cc0e7e50f20e6b797.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b914278b4ab4040b4fff83b0f97ae386.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c03668d4232ef3060541db9668ec81c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc807d9bc5dfd097b8376314e642a7ed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-45b042aa74d3b92a52cf1a4ba431f5f6.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Topo-Field-Topometric-mapping-with-Brain-inspired-Hierarchical-Layout-Object-Position-Fields"><a href="#Topo-Field-Topometric-mapping-with-Brain-inspired-Hierarchical-Layout-Object-Position-Fields" class="headerlink" title="Topo-Field: Topometric mapping with Brain-inspired Hierarchical   Layout-Object-Position Fields"></a>Topo-Field: Topometric mapping with Brain-inspired Hierarchical   Layout-Object-Position Fields</h2><p><strong>Authors:Jiawei Hou, Wenhao Guan, Longfei Liang, Jianfeng Feng, Xiangyang Xue, Taiping Zeng</strong></p>
<p>Mobile robots require comprehensive scene understanding to operate effectively in diverse environments, enriched with contextual information such as layouts, objects, and their relationships. Although advances like neural radiation fields (NeRFs) offer high-fidelity 3D reconstructions, they are computationally intensive and often lack efficient representations of traversable spaces essential for planning and navigation. In contrast, topological maps are computationally efficient but lack the semantic richness necessary for a more complete understanding of the environment. Inspired by a population code in the postrhinal cortex (POR) strongly tuned to spatial layouts over scene content rapidly forming a high-level cognitive map, this work introduces Topo-Field, a framework that integrates Layout-Object-Position (LOP) associations into a neural field and constructs a topometric map from this learned representation. LOP associations are modeled by explicitly encoding object and layout information, while a Large Foundation Model (LFM) technique allows for efficient training without extensive annotations. The topometric map is then constructed by querying the learned neural representation, offering both semantic richness and computational efficiency. Empirical evaluations in multi-room environments demonstrate the effectiveness of Topo-Field in tasks such as position attribute inference, query localization, and topometric planning, successfully bridging the gap between high-fidelity scene understanding and efficient robotic navigation. </p>
<blockquote>
<p>ç§»åŠ¨æœºå™¨äººéœ€è¦å…¨é¢çš„åœºæ™¯ç†è§£ï¼Œæ‰èƒ½åœ¨å„ç§ç¯å¢ƒä¸­æœ‰æ•ˆè¿è¡Œï¼Œè¿™äº›ç¯å¢ƒå¯Œå«å¸ƒå±€ã€ç‰©ä½“åŠå…¶å…³ç³»çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å°½ç®¡ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ç­‰å…ˆè¿›æŠ€æœ¯æä¾›äº†é«˜ä¿çœŸåº¦çš„3Dé‡å»ºï¼Œä½†å®ƒä»¬è®¡ç®—é‡å¤§ï¼Œé€šå¸¸ç¼ºä¹å¯¹å¯é€šè¡Œç©ºé—´çš„æœ‰æ•ˆè¡¨ç¤ºï¼Œè¿™å¯¹äºè§„åˆ’å’Œå¯¼èˆªè‡³å…³é‡è¦ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ‹“æ‰‘åœ°å›¾è®¡ç®—æ•ˆç‡é«˜ï¼Œä½†ç¼ºä¹å¿…è¦çš„è¯­ä¹‰ä¸°å¯Œæ€§ï¼Œæ— æ³•æ›´å…¨é¢åœ°ç†è§£ç¯å¢ƒã€‚è¿™é¡¹å·¥ä½œå—åˆ°åæ¢¨çŠ¶çš®å±‚ï¼ˆPORï¼‰ä¸­äººç¾¤ç¼–ç çš„å¯å‘ï¼Œè¯¥ç¼–ç å¯¹åœºæ™¯å†…å®¹ä¸­çš„ç©ºé—´å¸ƒå±€è¿›è¡Œå¿«é€Ÿé«˜çº§è®¤çŸ¥åœ°å›¾æ„å»ºï¼Œä»‹ç»äº†ä¸€ç§åä¸ºTopo-Fieldçš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†å¸ƒå±€-å¯¹è±¡-ä½ç½®ï¼ˆLOPï¼‰å…³è”é›†æˆåˆ°ç¥ç»åœºä¸­ï¼Œå¹¶ä»è¿™ç§å­¦ä¹ è¡¨ç¤ºä¸­æ„å»ºæ‹“æ‰‘åœ°å›¾ã€‚LOPå…³è”é€šè¿‡æ˜¾å¼ç¼–ç å¯¹è±¡å’Œå¸ƒå±€ä¿¡æ¯æ¥å»ºæ¨¡ï¼Œè€Œå¤§å‹åŸºç¡€æ¨¡å‹ï¼ˆLFMï¼‰æŠ€æœ¯åˆ™å¯å®ç°é«˜æ•ˆè®­ç»ƒï¼Œæ— éœ€å¹¿æ³›æ³¨é‡Šã€‚ç„¶åï¼Œé€šè¿‡æŸ¥è¯¢å­¦ä¹ åˆ°çš„ç¥ç»è¡¨ç¤ºæ¥æ„å»ºæ‹“æ‰‘åœ°å›¾ï¼Œæä¾›ä¸°å¯Œçš„è¯­ä¹‰å’Œè®¡ç®—æ•ˆç‡ã€‚åœ¨å¤šæˆ¿é—´ç¯å¢ƒä¸­çš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒTopo-Fieldåœ¨ä½ç½®å±æ€§æ¨æ–­ã€æŸ¥è¯¢å®šä½å’Œæ‹“æ‰‘è§„åˆ’ç­‰ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼ŒæˆåŠŸå¼¥åˆäº†é«˜ä¿çœŸåœºæ™¯ç†è§£å’Œé«˜æ•ˆæœºå™¨äººå¯¼èˆªä¹‹é—´çš„å·®è·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.05985v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºTopo-Fieldçš„æ¡†æ¶ï¼Œèåˆå¸ƒå±€-ç‰©ä½“-ä½ç½®ï¼ˆLOPï¼‰å…³è”åˆ°ç¥ç»ç½‘ç»œä¸­ï¼Œæ„å»ºæ‹“æ‰‘åœ°å›¾ã€‚åˆ©ç”¨ç§ç¾¤ç¼–ç å’Œåé¢å¶çš®å±‚ï¼ˆPORï¼‰çš„ç©ºé—´å¸ƒå±€æ•æ„Ÿæ€§ï¼Œä»¥åŠå¤§å‹åŸºç¡€æ¨¡å‹ï¼ˆLFMï¼‰æŠ€æœ¯ï¼Œå®ç°é«˜æ•ˆå­¦ä¹ ä¸è®­ç»ƒã€‚Topo-Fieldèƒ½åœ¨å¤šæˆ¿é—´ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆè¯„ä¼°ï¼ŒæˆåŠŸåº”ç”¨äºä½ç½®å±æ€§æ¨æ–­ã€æŸ¥è¯¢å®šä½å’Œæ‹“æ‰‘è§„åˆ’ä»»åŠ¡ï¼Œå®ç°äº†é«˜ä¿çœŸåœºæ™¯ç†è§£ä¸é«˜æ•ˆæœºå™¨äººå¯¼èˆªä¹‹é—´çš„æ¡¥æ¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Topo-Fieldæ¡†æ¶ç»“åˆäº†å¸ƒå±€ã€ç‰©ä½“å’Œä½ç½®ï¼ˆLOPï¼‰çš„å…³è”ï¼Œæ„å»ºäº†ä¸€ä¸ªç¥ç»åœºæ¨¡å‹ç”¨äºæœºå™¨äººåœºæ™¯ç†è§£ã€‚</li>
<li>å€Ÿé‰´åé¢å¶çš®å±‚ï¼ˆPORï¼‰çš„ç§ç¾¤ç¼–ç æ€æƒ³ï¼Œå¿«é€Ÿå½¢æˆé«˜çº§è®¤çŸ¥åœ°å›¾ã€‚</li>
<li>é‡‡ç”¨å¤§å‹åŸºç¡€æ¨¡å‹ï¼ˆLFMï¼‰æŠ€æœ¯ï¼Œå®ç°æ— éœ€å¤§é‡æ ‡æ³¨çš„é«˜æ•ˆè®­ç»ƒã€‚</li>
<li>Topo-Fieldèƒ½æ„å»ºæ‹“æ‰‘åœ°å›¾ï¼Œå…¼å…·è¯­ä¹‰ä¸°å¯Œæ€§å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>åœ¨å¤šæˆ¿é—´ç¯å¢ƒä¸­è¿›è¡Œå®è¯è¯„ä¼°ï¼Œè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>æˆåŠŸåº”ç”¨äºä½ç½®å±æ€§æ¨æ–­ã€æŸ¥è¯¢å®šä½å’Œæ‹“æ‰‘è§„åˆ’ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.05985">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-716b83cf82910d21feb0e3387a0ee090.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f98270ffa533f295a774a030506d9eb5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7cd400622784450b987d48614f138df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95683416866809e158ee5579eeebff5d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-53d0570834843767bf1a3e1a677169b5.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="NeRF-DetS-Enhanced-Adaptive-Spatial-wise-Sampling-and-View-wise-Fusion-Strategies-for-NeRF-based-Indoor-Multi-view-3D-Object-Detection"><a href="#NeRF-DetS-Enhanced-Adaptive-Spatial-wise-Sampling-and-View-wise-Fusion-Strategies-for-NeRF-based-Indoor-Multi-view-3D-Object-Detection" class="headerlink" title="NeRF-DetS: Enhanced Adaptive Spatial-wise Sampling and View-wise Fusion   Strategies for NeRF-based Indoor Multi-view 3D Object Detection"></a>NeRF-DetS: Enhanced Adaptive Spatial-wise Sampling and View-wise Fusion   Strategies for NeRF-based Indoor Multi-view 3D Object Detection</h2><p><strong>Authors:Chi Huang, Xinyang Li, Yansong Qu, Changli Wu, Xiaofan Li, Shengchuan Zhang, Liujuan Cao</strong></p>
<p>In indoor scenes, the diverse distribution of object locations and scales makes the visual 3D perception task a big challenge.   Previous works (e.g, NeRF-Det) have demonstrated that implicit representation has the capacity to benefit the visual 3D perception task in indoor scenes with high amount of overlap between input images.   However, previous works cannot fully utilize the advancement of implicit representation because of fixed sampling and simple multi-view feature fusion.   In this paper, inspired by sparse fashion method (e.g, DETR3D), we propose a simple yet effective method, NeRF-DetS, to address above issues. NeRF-DetS includes two modules: Progressive Adaptive Sampling Strategy (PASS) and Depth-Guided Simplified Multi-Head Attention Fusion (DS-MHA).   Specifically,   (1)PASS can automatically sample features of each layer within a dense 3D detector, using offsets predicted by the previous layer.   (2)DS-MHA can not only efficiently fuse multi-view features with strong occlusion awareness but also reduce computational cost.   Extensive experiments on ScanNetV2 dataset demonstrate our NeRF-DetS outperforms NeRF-Det, by achieving +5.02% and +5.92% improvement in mAP under IoU25 and IoU50, respectively. Also, NeRF-DetS shows consistent improvements on ARKITScenes. </p>
<blockquote>
<p>åœ¨å®¤å†…åœºæ™¯ä¸­ï¼Œç‰©ä½“ä½ç½®å’Œå°ºåº¦çš„å¤šæ ·åˆ†å¸ƒä½¿å¾—è§†è§‰3Dæ„ŸçŸ¥ä»»åŠ¡é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚å…ˆå‰çš„å·¥ä½œï¼ˆä¾‹å¦‚NeRF-Detï¼‰å·²ç»è¯æ˜ï¼Œéšå¼è¡¨ç¤ºæœ‰ç›Šäºå®¤å†…åœºæ™¯çš„è§†è§‰3Dæ„ŸçŸ¥ä»»åŠ¡ï¼Œå°¤å…¶åœ¨è¾“å…¥å›¾åƒä¹‹é—´å­˜åœ¨å¤§é‡é‡å æ—¶ã€‚ç„¶è€Œï¼Œç”±äºå›ºå®šçš„é‡‡æ ·å’Œç®€å•çš„å¤šè§†å›¾ç‰¹å¾èåˆï¼Œå…ˆå‰çš„å·¥ä½œä¸èƒ½å®Œå…¨åˆ©ç”¨éšå¼è¡¨ç¤ºçš„è¿›æ­¥ã€‚æœ¬æ–‡å—ç¨€ç–æ–¹å¼æ–¹æ³•çš„å¯å‘ï¼ˆä¾‹å¦‚DETR3Dï¼‰ï¼Œæå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•NeRF-DetSæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚NeRF-DetSåŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼šæ¸è¿›å¼è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼ˆPASSï¼‰å’Œæ·±åº¦å¼•å¯¼ç®€åŒ–å¤šå¤´æ³¨æ„åŠ›èåˆï¼ˆDS-MHAï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œï¼ˆ1ï¼‰PASSå¯ä»¥è‡ªåŠ¨åœ¨å¯†é›†3Dæ£€æµ‹å™¨å†…çš„æ¯ä¸€å±‚é‡‡æ ·ç‰¹å¾ï¼Œä½¿ç”¨å‰ä¸€å±‚çš„é¢„æµ‹åç§»ã€‚ï¼ˆ2ï¼‰DS-MHAä¸ä»…å¯ä»¥æœ‰æ•ˆåœ°èåˆå¤šè§†å›¾ç‰¹å¾ï¼Œå…·æœ‰å¼ºçƒˆçš„é®æŒ¡æ„è¯†ï¼Œè€Œä¸”å¯ä»¥é™ä½è®¡ç®—æˆæœ¬ã€‚åœ¨ScanNetV2æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„NeRF-DetSä¼˜äºNeRF-Detï¼Œåœ¨IoU25å’ŒIoU50çš„mAPä¸Šåˆ†åˆ«æé«˜äº†+5.02%å’Œ+5.92%ã€‚æ­¤å¤–ï¼ŒNeRF-DetSåœ¨ARKITScenesä¸Šä¹Ÿè¡¨ç°å‡ºäº†ä¸€è‡´æ€§çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.13921v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å®¤å†…åœºæ™¯ä¸­ï¼Œç‰©ä½“ä½ç½®å’Œå°ºåº¦çš„å¤šæ ·æ€§ä½¿å¾—è§†è§‰3Dæ„ŸçŸ¥ä»»åŠ¡æå…·æŒ‘æˆ˜ã€‚NeRF-DetSæ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè§£å†³äº†ä¹‹å‰å·¥ä½œä¸­å›ºå®šé‡‡æ ·å’Œç®€å•å¤šè§†è§’ç‰¹å¾èåˆçš„é—®é¢˜ã€‚NeRF-DetSåŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼šæ¸è¿›è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼ˆPASSï¼‰å’Œæ·±åº¦å¼•å¯¼ç®€åŒ–å¤šå¤´æ³¨æ„åŠ›èåˆï¼ˆDS-MHAï¼‰ã€‚PASSå¯è‡ªåŠ¨åœ¨å¯†é›†3Dæ£€æµ‹å™¨ä¸­æ¯å±‚é‡‡æ ·ç‰¹å¾ï¼Œä½¿ç”¨å‰ä¸€å±‚çš„é¢„æµ‹åç§»ã€‚DS-MHAä¸ä»…èƒ½æœ‰æ•ˆåœ°èåˆå…·æœ‰å¼ºé®æŒ¡æ„è¯†çš„å¤šä¸ªè§†è§’ç‰¹å¾ï¼Œè¿˜èƒ½é™ä½è®¡ç®—æˆæœ¬ã€‚åœ¨ScanNetV2æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒNeRF-DetSä¼˜äºNeRF-Detï¼Œåœ¨IoU25å’ŒIoU50ä¸‹mAPåˆ†åˆ«æé«˜äº†+5.02%å’Œ+5.92%ã€‚åŒæ—¶ï¼ŒNeRF-DetSåœ¨ARKITScenesä¸Šä¹Ÿè¡¨ç°å‡ºä¸€è‡´çš„æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®¤å†…åœºæ™¯ä¸­ï¼Œç‰©ä½“ä½ç½®å’Œå°ºåº¦çš„å¤šæ ·æ€§ä½¿å¾—è§†è§‰3Dæ„ŸçŸ¥å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>ä¹‹å‰çš„ä½œå“å¦‚NeRF-Detè™½å±•ç¤ºäº†éšå¼è¡¨ç¤ºåœ¨è§†è§‰3Dæ„ŸçŸ¥ä»»åŠ¡ä¸­çš„æ½œåŠ›ï¼Œä½†æ— æ³•å……åˆ†åˆ©ç”¨å…¶ä¼˜åŠ¿ã€‚</li>
<li>NeRF-DetSé€šè¿‡å¼•å…¥ä¸¤ä¸ªæ¨¡å—ï¼šPASSå’ŒDS-MHAï¼Œè§£å†³äº†å›ºå®šé‡‡æ ·å’Œç®€å•å¤šè§†è§’ç‰¹å¾èåˆçš„é—®é¢˜ã€‚</li>
<li>PASSèƒ½è‡ªåŠ¨åœ¨å¯†é›†3Dæ£€æµ‹å™¨çš„æ¯ä¸€å±‚è¿›è¡Œç‰¹å¾é‡‡æ ·ã€‚</li>
<li>DS-MHAèƒ½é«˜æ•ˆèåˆå¤šè§†è§’ç‰¹å¾ï¼Œå¢å¼ºé®æŒ¡æ„è¯†å¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚</li>
<li>åœ¨ScanNetV2æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒNeRF-DetSç›¸æ¯”NeRF-Detæœ‰æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.13921">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-306731d7f1d69eb434e06e08799097f7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6cfddae21ae946b554002b6fbfddba5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81289d67066949786f358bca9834b9d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-584e618350edd2bbd3f4bc1b85781e60.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-57ee6efda62aa34115ce79937185712e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c606b27e21365bf72d1c862888c3d944.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Prometheus 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D   Scene Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b51444c746b853c2990f78df6232bb9c.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Prometheus 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D   Scene Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19211.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
