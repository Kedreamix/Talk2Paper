<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GAN">
    <meta name="description" content="GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  StyleAutoEncoder for manipulating image attributes using pre-trained   StyleGAN">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GAN | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-caf3ad39b704755169a9ae027e45fd58.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/GAN/">
                                <span class="chip bg-color">GAN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                GAN
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    36 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-02-æ›´æ–°"><a href="#2025-01-02-æ›´æ–°" class="headerlink" title="2025-01-02 æ›´æ–°"></a>2025-01-02 æ›´æ–°</h1><h2 id="StyleAutoEncoder-for-manipulating-image-attributes-using-pre-trained-StyleGAN"><a href="#StyleAutoEncoder-for-manipulating-image-attributes-using-pre-trained-StyleGAN" class="headerlink" title="StyleAutoEncoder for manipulating image attributes using pre-trained   StyleGAN"></a>StyleAutoEncoder for manipulating image attributes using pre-trained   StyleGAN</h2><p><strong>Authors:Andrzej Bedychaj, Jacek Tabor, Marek Åšmieja</strong></p>
<p>Deep conditional generative models are excellent tools for creating high-quality images and editing their attributes. However, training modern generative models from scratch is very expensive and requires large computational resources. In this paper, we introduce StyleAutoEncoder (StyleAE), a lightweight AutoEncoder module, which works as a plugin for pre-trained generative models and allows for manipulating the requested attributes of images. The proposed method offers a cost-effective solution for training deep generative models with limited computational resources, making it a promising technique for a wide range of applications. We evaluate StyleAutoEncoder by combining it with StyleGAN, which is currently one of the top generative models. Our experiments demonstrate that StyleAutoEncoder is at least as effective in manipulating image attributes as the state-of-the-art algorithms based on invertible normalizing flows. However, it is simpler, faster, and gives more freedom in designing neural </p>
<blockquote>
<p>æ·±åº¦æ¡ä»¶ç”Ÿæˆæ¨¡å‹æ˜¯åˆ›å»ºé«˜è´¨é‡å›¾åƒå’Œç¼–è¾‘å…¶å±æ€§çš„å‡ºè‰²å·¥å…·ã€‚ç„¶è€Œï¼Œä»å¤´å¼€å§‹è®­ç»ƒç°ä»£ç”Ÿæˆæ¨¡å‹æ˜¯éå¸¸æ˜‚è´µçš„ï¼Œå¹¶ä¸”éœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†StyleAutoEncoderï¼ˆStyleAEï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„AutoEncoderæ¨¡å—ï¼Œå¯ä½œä¸ºé¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„æ’ä»¶ï¼Œå…è®¸æ“ä½œå›¾åƒçš„è¯·æ±‚å±æ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ºåœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹è®­ç»ƒæ·±åº¦ç”Ÿæˆæ¨¡å‹æä¾›äº†ç»æµé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œä½¿å…¶æˆä¸ºå¹¿æ³›åº”ç”¨çš„æœ‰å‰é€”çš„æŠ€æœ¯ã€‚æˆ‘ä»¬é€šè¿‡å°†å…¶ä¸ç›®å‰é¡¶çº§çš„ç”Ÿæˆæ¨¡å‹StyleGANç›¸ç»“åˆæ¥è¯„ä¼°StyleAutoEncoderã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒStyleAutoEncoderåœ¨æ“çºµå›¾åƒå±æ€§æ–¹é¢è‡³å°‘ä¸åŸºäºå¯é€†å½’ä¸€åŒ–æµçš„æœ€æ–°ç®—æ³•ä¸€æ ·æœ‰æ•ˆã€‚ä½†æ˜¯å®ƒæ›´ç®€å•ã€æ›´å¿«ï¼Œå¹¶ä¸”åœ¨è®¾è®¡ç¥ç»ç½‘ç»œæ—¶æä¾›äº†æ›´å¤§çš„è‡ªç”±åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20164v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦æ¡ä»¶ç”Ÿæˆæ¨¡å‹æ˜¯åˆ›å»ºé«˜è´¨é‡å›¾åƒå’Œç¼–è¾‘å…¶å±æ€§çš„ä¼˜ç§€å·¥å…·ã€‚ç„¶è€Œï¼Œä»å¤´å¼€å§‹è®­ç»ƒç°ä»£ç”Ÿæˆæ¨¡å‹éå¸¸æ˜‚è´µï¼Œéœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºã€‚æœ¬æ–‡ä»‹ç»äº†StyleAutoEncoderï¼ˆStyleAEï¼‰ï¼Œè¿™æ˜¯ä¸€æ¬¾è½»é‡çº§çš„AutoEncoderæ¨¡å—ï¼Œå¯ä½œä¸ºé¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„æ’ä»¶ï¼Œå…è®¸æ“ä½œå›¾åƒçš„æŒ‡å®šå±æ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ºåœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹è®­ç»ƒæ·±åº¦ç”Ÿæˆæ¨¡å‹æä¾›äº†æˆæœ¬æ•ˆç›Šé«˜çš„è§£å†³æ–¹æ¡ˆï¼Œæˆä¸ºå¹¿æ³›åº”ç”¨çš„æœ‰å‰é€”çš„æŠ€æœ¯ã€‚æˆ‘ä»¬å°†StyleAutoEncoderä¸ç›®å‰é¡¶çº§çš„ç”Ÿæˆæ¨¡å‹ä¹‹ä¸€StyleGANç›¸ç»“åˆè¿›è¡Œè¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼ŒStyleAutoEncoderåœ¨æ“çºµå›¾åƒå±æ€§æ–¹é¢è‡³å°‘ä¸åŸºäºå¯é€†å½’ä¸€åŒ–æµçš„æœ€æ–°ç®—æ³•ä¸€æ ·æœ‰æ•ˆï¼Œä½†æ›´ç®€å•ã€æ›´å¿«ï¼Œå¹¶ä¸”åœ¨è®¾è®¡ç¥ç»ç½‘ç»œæ—¶æä¾›äº†æ›´å¤§çš„è‡ªç”±åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>StyleAutoEncoderæ˜¯ä¸€ç§è½»é‡çº§çš„AutoEncoderæ¨¡å—ï¼Œå¯ä½œä¸ºé¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹çš„æ’ä»¶ï¼Œç”¨äºæ“ä½œå›¾åƒçš„æŒ‡å®šå±æ€§ã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•ä¸ºåœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹è®­ç»ƒæ·±åº¦ç”Ÿæˆæ¨¡å‹æä¾›äº†æˆæœ¬æ•ˆç›Šé«˜çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>StyleAutoEncoderä¸StyleGANç›¸ç»“åˆï¼Œå±•ç¤ºäº†å¯¹å›¾åƒå±æ€§çš„æœ‰æ•ˆæ“ä½œã€‚</li>
<li>StyleAutoEncoderçš„æ•ˆæœè‡³å°‘ä¸åŸºäºå¯é€†å½’ä¸€åŒ–æµçš„æœ€æ–°ç®—æ³•ä¸€æ ·å¥½ã€‚</li>
<li>StyleAutoEncoderå…·æœ‰ç®€å•ã€å¿«é€Ÿçš„ç‰¹ç‚¹ï¼Œå¹¶ä¸”åœ¨è®¾è®¡ç¥ç»ç½‘ç»œæ—¶æä¾›äº†æ›´å¤§çš„è‡ªç”±åº¦ã€‚</li>
<li>è¯¥æ–¹æ³•é€‚ç”¨äºå¹¿æ³›çš„åº”ç”¨é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20164">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cc181b8ee1469721c421d66f8969d6ee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dba23f74eb33b8e0272ac62683940c10.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f92c796e3b7b6204d9b5dff311436b67.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f7c1d53039d12e098b00f618bb65024c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Comprehensive-Review-of-EEG-to-Output-Research-Decoding-Neural-Signals-into-Images-Videos-and-Audio"><a href="#Comprehensive-Review-of-EEG-to-Output-Research-Decoding-Neural-Signals-into-Images-Videos-and-Audio" class="headerlink" title="Comprehensive Review of EEG-to-Output Research: Decoding Neural Signals   into Images, Videos, and Audio"></a>Comprehensive Review of EEG-to-Output Research: Decoding Neural Signals   into Images, Videos, and Audio</h2><p><strong>Authors:Yashvir Sabharwal, Balaji Rama</strong></p>
<p>Electroencephalography (EEG) is an invaluable tool in neuroscience, offering insights into brain activity with high temporal resolution. Recent advancements in machine learning and generative modeling have catalyzed the application of EEG in reconstructing perceptual experiences, including images, videos, and audio. This paper systematically reviews EEG-to-output research, focusing on state-of-the-art generative methods, evaluation metrics, and data challenges. Using PRISMA guidelines, we analyze 1800 studies and identify key trends, challenges, and opportunities in the field. The findings emphasize the potential of advanced models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformers, while highlighting the pressing need for standardized datasets and cross-subject generalization. A roadmap for future research is proposed that aims to improve decoding accuracy and broadening real-world applications. </p>
<blockquote>
<p>è„‘ç”µå›¾ï¼ˆEEGï¼‰æ˜¯ç¥ç»ç§‘å­¦ä¸­ä¸€ç§å®è´µçš„å·¥å…·ï¼Œèƒ½ä»¥é«˜æ—¶é—´åˆ†è¾¨ç‡æä¾›å¯¹å¤§è„‘æ´»åŠ¨çš„æ´å¯Ÿã€‚æœ€è¿‘æœºå™¨å­¦ä¹ é¢†åŸŸçš„è¿›å±•ä»¥åŠç”Ÿæˆæ¨¡å‹çš„å‘å±•ï¼Œä¿ƒè¿›äº†EEGåœ¨é‡å»ºæ„ŸçŸ¥ä½“éªŒä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°å›é¡¾äº†EEGåˆ°è¾“å‡ºçš„ç ”ç©¶ï¼Œé‡ç‚¹å…³æ³¨æœ€å…ˆè¿›çš„ç”Ÿæˆæ–¹æ³•ã€è¯„ä¼°æŒ‡æ ‡å’Œæ•°æ®æŒ‘æˆ˜ã€‚æˆ‘ä»¬æŒ‰ç…§PRISMAæŒ‡å—åˆ†æäº†1800é¡¹ç ”ç©¶ï¼Œå¹¶ç¡®å®šäº†è¯¥é¢†åŸŸçš„å…³é”®è¶‹åŠ¿ã€æŒ‘æˆ˜å’Œæœºé‡ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†å…ˆè¿›æ¨¡å‹ï¼ˆå¦‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ã€å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰å’Œå˜å‹å™¨ï¼‰çš„æ½œåŠ›ï¼ŒåŒæ—¶å¼ºè°ƒäº†æ ‡å‡†åŒ–æ•°æ®é›†å’Œè·¨ä¸»é¢˜æ³›åŒ–çš„è¿«åˆ‡éœ€æ±‚ã€‚ä¸ºæœªæ¥ç ”ç©¶æå‡ºäº†è·¯çº¿å›¾ï¼Œæ—¨åœ¨æé«˜è§£ç ç²¾åº¦å¹¶æ‰©å¤§åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19999v1">PDF</a> 15 pages. Submitted as a conference paper to IntelliSys 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç³»ç»Ÿç»¼è¿°äº†EEGåœ¨é‡å»ºæ„ŸçŸ¥ä½“éªŒæ–¹é¢çš„åº”ç”¨ï¼Œé‡ç‚¹ä»‹ç»äº†æœ€æ–°çš„ç”Ÿæˆæ–¹æ³•ã€è¯„ä¼°æŒ‡æ ‡å’Œæ•°æ®æŒ‘æˆ˜ã€‚é€šè¿‡å¯¹1800é¡¹ç ”ç©¶çš„åˆ†æï¼Œå¼ºè°ƒäº†å…ˆè¿›æ¨¡å‹å¦‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ã€å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰å’ŒTransformersçš„æ½œåŠ›ï¼ŒåŒæ—¶æŒ‡å‡ºæ ‡å‡†åŒ–æ•°æ®é›†å’Œè·¨ä¸»ä½“æ¨å¹¿çš„è¿«åˆ‡éœ€æ±‚ã€‚æå‡ºäº†æœªæ¥ç ”ç©¶çš„è·¯çº¿å›¾ï¼Œæ—¨åœ¨æé«˜è§£ç ç²¾åº¦å¹¶æ‹“å®½å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EEGæ˜¯ç¥ç»ç§‘å­¦ä¸­çš„å®è´µå·¥å…·ï¼Œå…·æœ‰é«˜çš„æ—¶é—´åˆ†è¾¨ç‡ï¼Œèƒ½æ´å¯Ÿå¤§è„‘æ´»åŠ¨ã€‚</li>
<li>æœºå™¨å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹çš„å‘å±•æ¨åŠ¨äº†EEGåœ¨é‡å»ºæ„ŸçŸ¥ä½“éªŒæ–¹é¢çš„åº”ç”¨ï¼Œå¦‚å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ã€‚</li>
<li>ç»¼è¿°é‡ç‚¹å…³æ³¨äº†æœ€æ–°çš„ç”Ÿæˆæ–¹æ³•ã€è¯„ä¼°æŒ‡æ ‡å’Œæ•°æ®æŒ‘æˆ˜ã€‚</li>
<li>ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ã€å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰å’ŒTransformersç­‰å…ˆè¿›æ¨¡å‹åœ¨EEGåˆ†æä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>æ ‡å‡†åŒ–æ•°æ®é›†å’Œè·¨ä¸»ä½“æ¨å¹¿æ˜¯å½“å‰çš„è¿«åˆ‡éœ€æ±‚ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†æé«˜è§£ç ç²¾åº¦å’Œæ‹“å®½ç°å®åº”ç”¨ä¸­çš„è·¯çº¿å›¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19999">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-35b19541d94e5b1c3c382ec1b54daaa0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e600429d52a586e73b6329b9d9a50c5.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="NijiGAN-Transform-What-You-See-into-Anime-with-Contrastive-Semi-Supervised-Learning-and-Neural-Ordinary-Differential-Equations"><a href="#NijiGAN-Transform-What-You-See-into-Anime-with-Contrastive-Semi-Supervised-Learning-and-Neural-Ordinary-Differential-Equations" class="headerlink" title="NijiGAN: Transform What You See into Anime with Contrastive   Semi-Supervised Learning and Neural Ordinary Differential Equations"></a>NijiGAN: Transform What You See into Anime with Contrastive   Semi-Supervised Learning and Neural Ordinary Differential Equations</h2><p><strong>Authors:Kevin Putra Santoso, Anny Yuniarti, Dwiyasa Nakula, Dimas Prihady Setyawan, Adam Haidar Azizi, Jeany Aurellia P. Dewati, Farah Dhia Fadhila, Maria T. Elvara Bumbungan</strong></p>
<p>Generative AI has transformed the animation industry. Several models have been developed for image-to-image translation, particularly focusing on converting real-world images into anime through unpaired translation. Scenimefy, a notable approach utilizing contrastive learning, achieves high fidelity anime scene translation by addressing limited paired data through semi-supervised training. However, it faces limitations due to its reliance on paired data from a fine-tuned StyleGAN in the anime domain, often producing low-quality datasets. Additionally, Scenimefyâ€™s high parameter architecture presents opportunities for computational optimization. This research introduces NijiGAN, a novel model incorporating Neural Ordinary Differential Equations (NeuralODEs), which offer unique advantages in continuous transformation modeling compared to traditional residual networks. NijiGAN successfully transforms real-world scenes into high fidelity anime visuals using half of Scenimefyâ€™s parameters. It employs pseudo-paired data generated through Scenimefy for supervised training, eliminating dependence on low-quality paired data and improving the training process. Our comprehensive evaluation includes ablation studies, qualitative, and quantitative analysis comparing NijiGAN to similar models. The testing results demonstrate that NijiGAN produces higher-quality images compared to AnimeGAN, as evidenced by a Mean Opinion Score (MOS) of 2.192, it surpasses AnimeGANâ€™s MOS of 2.160. Furthermore, our model achieved a Frechet Inception Distance (FID) score of 58.71, outperforming Scenimefyâ€™s FID score of 60.32. These results demonstrate that NijiGAN achieves competitive performance against existing state-of-the-arts, especially Scenimefy as the baseline model. </p>
<blockquote>
<p>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å·²ç»æ”¹å˜äº†åŠ¨ç”»äº§ä¸šã€‚å·²ç»å¼€å‘äº†å‡ ä¸ªå›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘æ¨¡å‹ï¼Œç‰¹åˆ«ä¸“æ³¨äºé€šè¿‡éé…å¯¹ç¿»è¯‘å°†ç°å®ä¸–ç•Œå›¾åƒè½¬æ¢ä¸ºåŠ¨æ¼«ã€‚Scenimefyæ˜¯ä¸€ç§åˆ©ç”¨å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•ï¼Œé€šè¿‡åŠç›‘ç£è®­ç»ƒè§£å†³é…å¯¹æ•°æ®æœ‰é™çš„é—®é¢˜ï¼Œå®ç°äº†é«˜ä¿çœŸåŠ¨æ¼«åœºæ™¯ç¿»è¯‘ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºç²¾ç»†è°ƒæ•´çš„åŠ¨æ¼«é¢†åŸŸStyleGANçš„é…å¯¹æ•°æ®ï¼Œå› æ­¤é¢ä¸´å±€é™æ€§ï¼Œç»å¸¸äº§ç”Ÿä½è´¨é‡çš„æ•°æ®é›†ã€‚æ­¤å¤–ï¼ŒScenimefyçš„é«˜å‚æ•°æ¶æ„ä¸ºè®¡ç®—ä¼˜åŒ–æä¾›äº†æœºä¼šã€‚æœ¬ç ”ç©¶å¼•å…¥äº†NijiGANï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆNeuralODEsï¼‰çš„æ–°æ¨¡å‹ï¼Œä¸ä¼ ç»Ÿçš„æ®‹å·®ç½‘ç»œç›¸æ¯”ï¼Œå®ƒåœ¨è¿ç»­å˜æ¢å»ºæ¨¡æ–¹é¢å…·æœ‰ç‹¬ç‰¹ä¼˜åŠ¿ã€‚NijiGANæˆåŠŸåœ°å°†ç°å®ä¸–ç•Œåœºæ™¯è½¬åŒ–ä¸ºé«˜ä¿çœŸåŠ¨æ¼«è§†è§‰ï¼Œä½¿ç”¨çš„æ˜¯Scenimefyä¸€åŠçš„å‚æ•°ã€‚å®ƒé‡‡ç”¨é€šè¿‡Scenimefyç”Ÿæˆä¼ªé…å¯¹æ•°æ®è¿›è¡Œç›‘ç£è®­ç»ƒï¼Œæ¶ˆé™¤äº†å¯¹ä½è´¨é‡é…å¯¹æ•°æ®çš„ä¾èµ–ï¼Œæ”¹è¿›äº†è®­ç»ƒè¿‡ç¨‹ã€‚æˆ‘ä»¬çš„ç»¼åˆè¯„ä¼°åŒ…æ‹¬æ¶ˆèç ”ç©¶ã€å®šæ€§å’Œå®šé‡åˆ†æï¼Œæ¯”è¾ƒäº†NijiGANä¸ç±»ä¼¼æ¨¡å‹çš„è¡¨ç°ã€‚æµ‹è¯•ç»“æœè¡¨æ˜ï¼ŒNijiGANç”Ÿæˆçš„å›¾åƒè´¨é‡é«˜äºAnimeGANï¼Œå¹³å‡æ„è§å¾—åˆ†ï¼ˆMOSï¼‰ä¸º2.192ï¼Œè¶…è¿‡äº†AnimeGANçš„MOSå¾—åˆ†2.160ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¾¾åˆ°äº†Frechet Inception Distanceï¼ˆFIDï¼‰å¾—åˆ†58.71ï¼Œè¶…è¿‡äº†Scenimefyçš„FIDå¾—åˆ†60.32ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒNijiGANåœ¨ç°æœ‰å…ˆè¿›æŠ€æœ¯ä¸­è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå°¤å…¶æ˜¯ä»¥Scenimefyä¸ºåŸºå‡†æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19455v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    ç”Ÿæˆå¼AIå·²å¯¹åŠ¨ç”»äº§ä¸šäº§ç”Ÿæ·±åˆ»å˜é©ã€‚æ–°çš„æ¨¡å‹è¢«å¼€å‘ç”¨äºå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ï¼Œç‰¹åˆ«æ˜¯å°†ç°å®ä¸–ç•Œå›¾åƒè½¬åŒ–ä¸ºåŠ¨æ¼«çš„æœªé…å¯¹ç¿»è¯‘é¢†åŸŸã€‚å°½ç®¡Scenimefyåˆ©ç”¨å¯¹æ¯”å­¦ä¹ å®ç°é«˜ä¿çœŸåŠ¨æ¼«åœºæ™¯ç¿»è¯‘ï¼Œå¹¶è§£å†³äº†é…å¯¹æ•°æ®çš„é™åˆ¶é—®é¢˜ï¼Œä½†å…¶ä¾èµ–äºç²¾ç»†è°ƒæ•´çš„åŠ¨æ¼«é¢†åŸŸçš„StyleGANé…å¯¹æ•°æ®ï¼Œå¸¸äº§ç”Ÿä½è´¨é‡æ•°æ®é›†ã€‚æ­¤å¤–ï¼ŒScenimefyå‚æ•°æ¶æ„å¤æ‚ï¼Œå­˜åœ¨è®¡ç®—ä¼˜åŒ–çš„æœºä¼šã€‚æœ¬ç ”ç©¶å¼•å…¥NijiGANï¼Œç»“åˆç¥ç»ç½‘ç»œå¸¸å¾®åˆ†æ–¹ç¨‹ç»„ï¼ˆNeuralODEsï¼‰çš„æ–°æ¨¡å‹ï¼Œåœ¨è¿ç»­å˜æ¢å»ºæ¨¡æ–¹é¢å…·æœ‰ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„æ®‹å·®ç½‘ç»œã€‚NijiGANæˆåŠŸå°†ç°å®åœºæ™¯è½¬åŒ–ä¸ºé«˜ä¿çœŸåŠ¨æ¼«è§†è§‰å›¾åƒï¼Œä½¿ç”¨Scenimefyçš„ä¸€åŠå‚æ•°ã€‚å®ƒåˆ©ç”¨ä¼ªé…å¯¹æ•°æ®ç”¨äºç›‘ç£è®­ç»ƒï¼Œæ¶ˆé™¤äº†å¯¹ä½è´¨é‡é…å¯¹æ•°æ®çš„ä¾èµ–ï¼Œæ”¹è¿›äº†è®­ç»ƒè¿‡ç¨‹ã€‚ç»¼åˆè¯„ä»·åŒ…æ‹¬æ¶ˆèç ”ç©¶ã€å®šæ€§å’Œå®šé‡åˆ†æï¼Œæ¯”è¾ƒNijiGANä¸ç±»ä¼¼æ¨¡å‹ã€‚æµ‹è¯•ç»“æœè¡¨æ˜ï¼ŒNijiGANäº§ç”Ÿçš„å›¾åƒè´¨é‡é«˜äºAnimeGANï¼Œå¹³å‡æ„è§å¾—åˆ†ï¼ˆMOSï¼‰ä¸º2.192ï¼Œè¶…è¿‡AnimeGANçš„MOS 2.160ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹çš„Frechet Inception Distanceï¼ˆFIDï¼‰å¾—åˆ†ä¸º58.71ï¼Œä¼˜äºScenimefyçš„FIDå¾—åˆ†60.32ã€‚ç»“æœè¡¨æ˜ï¼ŒNijiGANåœ¨ç°æœ‰å…ˆè¿›æŠ€æœ¯ä¸­è¡¨ç°å…·æœ‰ç«äº‰åŠ›ï¼Œå°¤å…¶æ˜¯ä»¥Scenimefyä¸ºåŸºçº¿æ¨¡å‹ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç”Ÿæˆå¼AIå·²æ·±åˆ»æ”¹å˜åŠ¨ç”»äº§ä¸šï¼Œå°¤å…¶æ˜¯å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢é¢†åŸŸã€‚</li>
<li>Scenimefyåˆ©ç”¨å¯¹æ¯”å­¦ä¹ å®ç°é«˜ä¿çœŸåŠ¨æ¼«åœºæ™¯ç¿»è¯‘ï¼Œä½†ä»é¢ä¸´ä¾èµ–ç²¾ç»†è°ƒæ•´çš„é…å¯¹æ•°æ®çš„é—®é¢˜ã€‚</li>
<li>NijiGANæ¨¡å‹å¼•å…¥ç¥ç»ç½‘ç»œå¸¸å¾®åˆ†æ–¹ç¨‹ç»„ï¼ˆNeuralODEsï¼‰ï¼Œå®ç°ç°å®åœºæ™¯åˆ°é«˜ä¿çœŸåŠ¨æ¼«çš„è§†è§‰è½¬åŒ–ã€‚</li>
<li>NijiGANä½¿ç”¨ä¼ªé…å¯¹æ•°æ®è¿›è¡Œç›‘ç£è®­ç»ƒï¼Œæé«˜è®­ç»ƒè¿‡ç¨‹çš„æ•ˆç‡å’Œè´¨é‡ã€‚</li>
<li>NijiGANç›¸è¾ƒäºScenimefyå’ŒAnimeGANï¼Œåœ¨å›¾åƒè´¨é‡ä¸Šè¡¨ç°æ›´ä¼˜ç§€ï¼Œå¹³å‡æ„è§å¾—åˆ†ï¼ˆMOSï¼‰å’ŒFrechet Inception Distanceï¼ˆFIDï¼‰ç­‰æŒ‡æ ‡å‡æœ‰æ‰€æ”¹è¿›ã€‚</li>
<li>NijiGANçš„å‚æ•°æ•°é‡ä»…ä¸ºScenimefyçš„ä¸€åŠï¼Œæš—ç¤ºå…¶è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚</li>
<li>ç»¼åˆè¯„ä»·æ˜¾ç¤ºNijiGANåœ¨ç°æœ‰æ¨¡å‹ä¸­è¡¨ç°å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19455">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-61575447c83d4dfc76638be99fb8da06.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-caf3ad39b704755169a9ae027e45fd58.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-26bf6af9d4fa02ba7360e7ce2302ab72.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="An-End-to-End-Depth-Based-Pipeline-for-Selfie-Image-Rectification"><a href="#An-End-to-End-Depth-Based-Pipeline-for-Selfie-Image-Rectification" class="headerlink" title="An End-to-End Depth-Based Pipeline for Selfie Image Rectification"></a>An End-to-End Depth-Based Pipeline for Selfie Image Rectification</h2><p><strong>Authors:Ahmed Alhawwary, Phong Nguyen-Ha, Janne Mustaniemi, Janne HeikkilÃ¤</strong></p>
<p>Portraits or selfie images taken from a close distance typically suffer from perspective distortion. In this paper, we propose an end-to-end deep learning-based rectification pipeline to mitigate the effects of perspective distortion. We learn to predict the facial depth by training a deep CNN. The estimated depth is utilized to adjust the camera-to-subject distance by moving the camera farther, increasing the camera focal length, and reprojecting the 3D image features to the new perspective. The reprojected features are then fed to an inpainting module to fill in the missing pixels. We leverage a differentiable renderer to enable end-to-end training of our depth estimation and feature extraction nets to improve the rectified outputs. To boost the results of the inpainting module, we incorporate an auxiliary module to predict the horizontal movement of the camera which decreases the area that requires hallucination of challenging face parts such as ears. Unlike previous works, we process the full-frame input image at once without cropping the subjectâ€™s face and processing it separately from the rest of the body, eliminating the need for complex post-processing steps to attach the face back to the subjectâ€™s body. To train our network, we utilize the popular game engine Unreal Engine to generate a large synthetic face dataset containing various subjects, head poses, expressions, eyewear, clothes, and lighting. Quantitative and qualitative results show that our rectification pipeline outperforms previous methods, and produces comparable results with a time-consuming 3D GAN-based method while being more than 260 times faster. </p>
<blockquote>
<p>ä»è¿‘è·ç¦»æ‹æ‘„çš„è‚–åƒæˆ–è‡ªæ‹å›¾åƒé€šå¸¸ä¼šå—åˆ°é€è§†å¤±çœŸçš„å½±å“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ ¡æ­£ç®¡é“ï¼Œä»¥å‡è½»é€è§†å¤±çœŸçš„å½±å“ã€‚æˆ‘ä»¬é€šè¿‡å­¦ä¹ é¢„æµ‹é¢éƒ¨æ·±åº¦æ¥è®­ç»ƒæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œã€‚ä¼°è®¡çš„æ·±åº¦ç”¨äºè°ƒæ•´ç›¸æœºåˆ°ä¸»ä½“çš„è·ç¦»ï¼Œé€šè¿‡å°†ç›¸æœºç§»å¾—æ›´è¿œã€å¢åŠ ç›¸æœºçš„ç„¦è·ï¼Œå¹¶å°†3Då›¾åƒç‰¹å¾æŠ•å½±åˆ°æ–°çš„é€è§†ç‚¹ä¸Šã€‚ç„¶åå°†é‡æ–°æŠ•å½±çš„ç‰¹å¾è¾“å…¥åˆ°å¡«å……æ¨¡å—ä¸­ä»¥å¡«å……ç¼ºå¤±çš„åƒç´ ã€‚æˆ‘ä»¬åˆ©ç”¨å¯å¾®æ¸²æŸ“å™¨ï¼Œå®ç°å¯¹æ·±åº¦ä¼°è®¡å’Œç‰¹å¾æå–ç½‘ç»œçš„ç«¯åˆ°ç«¯è®­ç»ƒï¼Œä»¥æé«˜æ ¡æ­£åçš„è¾“å‡ºæ•ˆæœã€‚ä¸ºäº†æå‡å¡«å……æ¨¡å—çš„æ•ˆæœï¼Œæˆ‘ä»¬å¼•å…¥äº†è¾…åŠ©æ¨¡å—æ¥é¢„æµ‹ç›¸æœºçš„æ°´å¹³è¿åŠ¨ï¼Œè¿™å‡å°‘äº†éœ€è¦è™šæ„å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢éƒ¨éƒ¨ä½ï¼ˆä¾‹å¦‚è€³æœµï¼‰çš„åŒºåŸŸã€‚ä¸ä»¥å‰çš„å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬ä¸€æ¬¡æ€§å¤„ç†å…¨å¸§è¾“å…¥å›¾åƒï¼Œè€Œæ— éœ€è£å‰ªä¸»ä½“çš„é¢éƒ¨å¹¶å•ç‹¬å¤„ç†å…¶ä¸èº«ä½“çš„å…¶ä»–éƒ¨åˆ†ï¼Œä»è€Œæ— éœ€å¤æ‚çš„åæœŸå¤„ç†æ­¥éª¤å°†é¢éƒ¨é‡æ–°é™„åŠ åˆ°ä¸»ä½“çš„èº«ä½“ä¸Šã€‚ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œï¼Œæˆ‘ä»¬åˆ©ç”¨æµè¡Œçš„æ¸¸æˆå¼•æ“Unreal Engineç”Ÿæˆäº†ä¸€ä¸ªå¤§å‹åˆæˆé¢éƒ¨æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å„ç§ä¸»ä½“ã€å¤´éƒ¨å§¿åŠ¿ã€è¡¨æƒ…ã€çœ¼é•œã€è¡£ç‰©å’Œç…§æ˜ã€‚å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ ¡æ­£ç®¡é“ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œå¹¶ä¸”ä¸è€—æ—¶çš„åŸºäº3D GANçš„æ–¹æ³•äº§ç”Ÿç›¸å½“çš„ç»“æœï¼ŒåŒæ—¶é€Ÿåº¦æé«˜äº†è¶…è¿‡260å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19189v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯æ ¡æ­£ç®¡é“ï¼Œç”¨äºå‡è½»è¿‘è·ç¦»æ‹æ‘„è‚–åƒæˆ–è‡ªæ‹æ—¶å¸¸è§çš„é€è§†å¤±çœŸé—®é¢˜ã€‚é€šè¿‡è®­ç»ƒæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œé¢„æµ‹é¢éƒ¨æ·±åº¦ï¼Œå¹¶æ®æ­¤è°ƒæ•´ç›¸æœºåˆ°ä¸»ä½“çš„è·ç¦»ã€å¢åŠ ç›¸æœºç„¦è·ï¼Œä»¥åŠå°†3Då›¾åƒç‰¹å¾é‡æ–°æŠ•å½±åˆ°æ–°çš„é€è§†è§’åº¦ã€‚æ­¤æ–¹æ³•åˆ©ç”¨å¯å¾®æ¸²æŸ“å™¨è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œæé«˜äº†æ ¡æ­£æ•ˆæœã€‚ä¸ºå¢å¼ºä¿®å¤æ¨¡å—çš„æ•ˆæœï¼Œå¼•å…¥äº†ä¸€ä¸ªè¾…åŠ©æ¨¡å—æ¥é¢„æµ‹ç›¸æœºçš„æ°´å¹³ç§»åŠ¨ï¼Œå‡å°‘äº†éœ€è¦è™šæ„å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢éƒ¨éƒ¨ä½ï¼ˆå¦‚è€³æœµï¼‰çš„åŒºåŸŸã€‚ä¸ä»¥å¾€çš„å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬ä¸€æ¬¡æ€§å¤„ç†å…¨å¸§è¾“å…¥å›¾åƒï¼Œæ— éœ€å°†ä¸»ä½“é¢éƒ¨è£å‰ªå‡ºæ¥å•ç‹¬å¤„ç†ï¼Œä»è€Œé¿å…äº†å¤æ‚çš„åæœŸå¤„ç†æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ ¡æ­£ç®¡é“åœ¨æ€§èƒ½å’Œé€Ÿåº¦ä¸Šå‡ä¼˜äºä¹‹å‰çš„æ–¹æ³•ï¼Œå¹¶ä¸”ä¸è€—æ—¶è¾ƒé•¿çš„åŸºäº3D GANçš„æ–¹æ³•äº§ç”Ÿçš„æ•ˆæœç›¸å½“ï¼Œä½†è¿è¡Œæ—¶é—´æ˜¯å…¶çš„çº¦1&#x2F;260ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡é’ˆå¯¹è¿‘è·ç¦»æ‹æ‘„çš„è‚–åƒæˆ–è‡ªæ‹ä¸­çš„é€è§†å¤±çœŸé—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯æ ¡æ­£ç®¡é“ã€‚</li>
<li>é€šè¿‡è®­ç»ƒæ·±åº¦CNNé¢„æµ‹é¢éƒ¨æ·±åº¦ï¼Œå¹¶åˆ©ç”¨æ­¤æ·±åº¦ä¿¡æ¯è°ƒæ•´ç›¸æœºå‚æ•°å’Œé‡æ–°æŠ•å½±å›¾åƒæ¥æ ¡æ­£é€è§†å¤±çœŸã€‚</li>
<li>åˆ©ç”¨å¯å¾®æ¸²æŸ“å™¨å®ç°ç«¯åˆ°ç«¯è®­ç»ƒï¼Œæå‡æ ¡æ­£æ•ˆæœã€‚</li>
<li>é€šè¿‡å¼•å…¥è¾…åŠ©æ¨¡å—é¢„æµ‹ç›¸æœºæ°´å¹³ç§»åŠ¨ï¼Œå‡å°‘éœ€è¦è™šæ„çš„é¢éƒ¨åŒºåŸŸã€‚</li>
<li>è®ºæ–‡é‡‡ç”¨å…¨å¸§å¤„ç†æ–¹æ³•ï¼Œé¿å…äº†å¤æ‚çš„åæœŸå¤„ç†æ­¥éª¤ã€‚</li>
<li>ä½¿ç”¨Unreal Engineç”Ÿæˆå¤§å‹åˆæˆé¢éƒ¨æ•°æ®é›†ï¼Œç”¨äºç½‘ç»œè®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19189">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-091460b28e08a91ceded4e6a38754d95.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-12fb7b588bf81028827f95396cf8b057.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3629e02a6517c14d6745e192a0c5e049.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51ee988be2d19251d226e1e0cf3082c3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MGAN-CRCM-A-Novel-Multiple-Generative-Adversarial-Network-and-Coarse-Refinement-Based-Cognizant-Method-for-Image-Inpainting"><a href="#MGAN-CRCM-A-Novel-Multiple-Generative-Adversarial-Network-and-Coarse-Refinement-Based-Cognizant-Method-for-Image-Inpainting" class="headerlink" title="MGAN-CRCM: A Novel Multiple Generative Adversarial Network and   Coarse-Refinement Based Cognizant Method for Image Inpainting"></a>MGAN-CRCM: A Novel Multiple Generative Adversarial Network and   Coarse-Refinement Based Cognizant Method for Image Inpainting</h2><p><strong>Authors:Nafiz Al Asad, Md. Appel Mahmud Pranto, Shbiruzzaman Shiam, Musaddeq Mahmud Akand, Mohammad Abu Yousuf, Khondokar Fida Hasan, Mohammad Ali Moni</strong></p>
<p>Image inpainting is a widely used technique in computer vision for reconstructing missing or damaged pixels in images. Recent advancements with Generative Adversarial Networks (GANs) have demonstrated superior performance over traditional methods due to their deep learning capabilities and adaptability across diverse image domains. Residual Networks (ResNet) have also gained prominence for their ability to enhance feature representation and compatibility with other architectures. This paper introduces a novel architecture combining GAN and ResNet models to improve image inpainting outcomes. Our framework integrates three components: Transpose Convolution-based GAN for guided and blind inpainting, Fast ResNet-Convolutional Neural Network (FR-CNN) for object removal, and Co-Modulation GAN (Co-Mod GAN) for refinement. The modelâ€™s performance was evaluated on benchmark datasets, achieving accuracies of 96.59% on Image-Net, 96.70% on Places2, and 96.16% on CelebA. Comparative analyses demonstrate that the proposed architecture outperforms existing methods, highlighting its effectiveness in both qualitative and quantitative evaluations. </p>
<blockquote>
<p>å›¾åƒè¡¥å…¨ï¼ˆImage inpaintingï¼‰æ˜¯è®¡ç®—æœºè§†è§‰ä¸­ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯ï¼Œç”¨äºé‡å»ºå›¾åƒä¸­ç¼ºå¤±æˆ–æŸåçš„åƒç´ ã€‚ç”±äºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„æ·±åº¦å­¦ä¹ èƒ½åŠ›ä»¥åŠåœ¨å¤šä¸ªå›¾åƒé¢†åŸŸä¸­çš„é€‚åº”æ€§ï¼Œå…¶ä¸ä¼ ç»Ÿæ–¹æ³•çš„å¯¹æ¯”æ˜¾ç¤ºå‡ºå“è¶Šçš„æ€§èƒ½ã€‚æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰ä¹Ÿå› å…¶å¢å¼ºç‰¹å¾è¡¨ç¤ºå’Œä¸å…¶ä»–æ¶æ„çš„å…¼å®¹æ€§è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆGANå’ŒResNetæ¨¡å‹çš„æ–°å‹æ¶æ„ï¼Œä»¥æé«˜å›¾åƒè¡¥å…¨çš„ç»“æœã€‚æˆ‘ä»¬çš„æ¡†æ¶é›†æˆäº†ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼šåŸºäºè½¬ç½®å·ç§¯çš„GANç”¨äºæœ‰æŒ‡å¯¼å’Œæ— æŒ‡å¯¼çš„è¡¥å…¨ã€ç”¨äºç›®æ ‡ç§»é™¤çš„å¿«é€ŸResNetå·ç§¯ç¥ç»ç½‘ç»œï¼ˆFR-CNNï¼‰ä»¥åŠç”¨äºç»†åŒ–çš„ååŒè°ƒåˆ¶GANï¼ˆCo-Mod GANï¼‰ã€‚è¯¥æ¨¡å‹åœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨Image-Netä¸Šå‡†ç¡®ç‡ä¸º96.59%ï¼Œåœ¨Places2ä¸Šå‡†ç¡®ç‡ä¸º96.70%ï¼Œåœ¨CelebAä¸Šå‡†ç¡®ç‡ä¸º96.16%ã€‚å¯¹æ¯”åˆ†æè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¶æ„ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­éƒ½å‡¸æ˜¾äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19000v1">PDF</a> 34 pages</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰çš„å›¾åƒä¿®å¤æŠ€æœ¯è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆGANå’ŒResNetæ¨¡å‹çš„æ–°å‹æ¶æ„ï¼ŒåŒ…æ‹¬åŸºäºè½¬ç½®å·ç§¯çš„GANç”¨äºå¼•å¯¼å’Œç›²ä¿®å¤ã€ç”¨äºå¯¹è±¡ç§»é™¤çš„å¿«é€ŸResNetå·ç§¯ç¥ç»ç½‘ç»œï¼ˆFR-CNNï¼‰ä»¥åŠç”¨äºç²¾ç»†åŒ–çš„ååŒè°ƒåˆ¶GANï¼ˆCo-Mod GANï¼‰ã€‚è¯¥æ¨¡å‹åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½è¯„ä¼°è¡¨æ˜ï¼Œå®ƒåœ¨ImageNetä¸Šçš„å‡†ç¡®ç‡ä¸º96.59%ï¼Œåœ¨Places2ä¸Šçš„å‡†ç¡®ç‡ä¸º96.70%ï¼Œåœ¨CelebAä¸Šçš„å‡†ç¡®ç‡ä¸º96.16%ï¼Œå¹¶ä¸”åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GANå’ŒResNetæ¨¡å‹ç»“åˆç”¨äºå›¾åƒä¿®å¤ï¼Œè¾¾åˆ°ä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>æå‡ºæ–°å‹æ¶æ„åŒ…å«ä¸‰ç§ç»„ä»¶ï¼šåŸºäºè½¬ç½®å·ç§¯çš„GANã€FR-CNNå’ŒCo-Mod GANã€‚</li>
<li>è½¬ç½®å·ç§¯GANç”¨äºå¼•å¯¼å’Œç›²ä¿®å¤ã€‚</li>
<li>FR-CNNç”¨äºå¯¹è±¡ç§»é™¤ã€‚</li>
<li>Co-Mod GANç”¨äºå›¾åƒä¿®å¤ç»“æœçš„ç²¾ç»†åŒ–ã€‚</li>
<li>æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°é«˜å‡†ç¡®ç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19000">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8a51d953c2ed8222cded41b201b81013.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25e3c3e024ec2d1dd29fd870e1258beb.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Video-Is-Worth-a-Thousand-Images-Exploring-the-Latest-Trends-in-Long-Video-Generation"><a href="#Video-Is-Worth-a-Thousand-Images-Exploring-the-Latest-Trends-in-Long-Video-Generation" class="headerlink" title="Video Is Worth a Thousand Images: Exploring the Latest Trends in Long   Video Generation"></a>Video Is Worth a Thousand Images: Exploring the Latest Trends in Long   Video Generation</h2><p><strong>Authors:Faraz Waseem, Muhammad Shahzad</strong></p>
<p>An image may convey a thousand words, but a video composed of hundreds or thousands of image frames tells a more intricate story. Despite significant progress in multimodal large language models (MLLMs), generating extended videos remains a formidable challenge. As of this writing, OpenAIâ€™s Sora, the current state-of-the-art system, is still limited to producing videos that are up to one minute in length. This limitation stems from the complexity of long video generation, which requires more than generative AI techniques for approximating density functions essential aspects such as planning, story development, and maintaining spatial and temporal consistency present additional hurdles. Integrating generative AI with a divide-and-conquer approach could improve scalability for longer videos while offering greater control. In this survey, we examine the current landscape of long video generation, covering foundational techniques like GANs and diffusion models, video generation strategies, large-scale training datasets, quality metrics for evaluating long videos, and future research areas to address the limitations of the existing video generation capabilities. We believe it would serve as a comprehensive foundation, offering extensive information to guide future advancements and research in the field of long video generation. </p>
<blockquote>
<p>å›¾åƒå¯èƒ½ä¼ è¾¾åƒè¨€ä¸‡è¯­ï¼Œä½†ç”±æ•°ç™¾æˆ–æ•°åƒä¸ªå›¾åƒå¸§ç»„æˆçš„è§†é¢‘åˆ™è®²è¿°äº†ä¸€ä¸ªæ›´å¤æ‚çš„æ•…äº‹ã€‚å°½ç®¡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ç”Ÿæˆé•¿è§†é¢‘ä»ç„¶æ˜¯ä¸€é¡¹è‰°å·¨çš„æŒ‘æˆ˜ã€‚æˆªè‡³æœ¬æ–‡å†™ä½œæ—¶ï¼Œå½“å‰æœ€å…ˆè¿›çš„ç³»ç»ŸOpenAIçš„Soraä»ç„¶ä»…é™äºç”Ÿæˆæœ€é•¿ä¸ºä¸€åˆ†é’Ÿçš„è§†é¢‘ã€‚è¿™ä¸€é™åˆ¶æºäºé•¿è§†é¢‘ç”Ÿæˆçš„å¤æ‚æ€§ï¼Œä¸ä»…éœ€è¦ç”Ÿæˆå¼AIæŠ€æœ¯æ¥è¿‘ä¼¼å¯†åº¦å‡½æ•°ï¼Œè€Œä¸”è§„åˆ’ã€æ•…äº‹å‘å±•å’Œä¿æŒç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§ç­‰å…³é”®æ–¹é¢è¿˜å­˜åœ¨é¢å¤–çš„éšœç¢ã€‚å°†ç”Ÿæˆå¼AIä¸åˆ†è€Œæ²»ä¹‹çš„æ–¹æ³•ç›¸ç»“åˆï¼Œå¯ä»¥æé«˜é•¿è§†é¢‘çš„æ‰©å±•æ€§ï¼ŒåŒæ—¶æä¾›æ›´å¼ºå¤§çš„æ§åˆ¶èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†é•¿è§†é¢‘ç”Ÿæˆçš„å½“å‰çŠ¶å†µï¼Œæ¶µç›–äº†è¯¸å¦‚GANså’Œæ‰©æ•£æ¨¡å‹ç­‰åŸºç¡€æŠ€æœ¯ã€è§†é¢‘ç”Ÿæˆç­–ç•¥ã€å¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†ã€é•¿è§†é¢‘è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥åŠé’ˆå¯¹ç°æœ‰è§†é¢‘ç”Ÿæˆèƒ½åŠ›çš„å±€é™æ€§çš„æœªæ¥ç ”ç©¶é¢†åŸŸã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™å°†æˆä¸ºä¸€é¡¹å…¨é¢çš„åŸºç¡€ï¼Œæä¾›å¹¿æ³›çš„ä¿¡æ¯ï¼Œä»¥æŒ‡å¯¼é•¿è§†é¢‘ç”Ÿæˆé¢†åŸŸçš„æœªæ¥å‘å±•ä¸ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18688v1">PDF</a> 35 pages, 18 figures, Manuscript submitted to ACM</p>
<p><strong>Summary</strong><br>è§†é¢‘ç”ŸæˆæŠ€æœ¯é¢ä¸´ç”Ÿæˆé•¿è§†é¢‘çš„éš¾é¢˜ï¼Œå°½ç®¡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æœ‰æ‰€è¿›æ­¥ï¼Œä½†ç›®å‰æœ€å…ˆè¿›ç³»ç»ŸOpenAIçš„Soraä»ç„¶åªèƒ½ç”Ÿæˆä¸€åˆ†é’Ÿé•¿åº¦çš„è§†é¢‘ã€‚é•¿è§†é¢‘ç”Ÿæˆéœ€è¦è¶…è¶Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¤æ‚æŠ€æœ¯ï¼Œå¦‚è§„åˆ’ã€æ•…äº‹å‘å±•å’Œä¿æŒæ—¶ç©ºä¸€è‡´æ€§ç­‰ï¼Œå› æ­¤éœ€è¦é‡‡ç”¨åˆ†è€Œæ²»ä¹‹çš„é›†æˆç­–ç•¥æ¥æé«˜ç”Ÿæˆé•¿è§†é¢‘çš„æ‰©å±•æ€§ã€‚å½“å‰æ–‡ç« å¯¹å½“å‰é•¿è§†é¢‘ç”Ÿæˆé¢†åŸŸè¿›è¡Œäº†å…¨é¢è°ƒæŸ¥ï¼ŒåŒ…æ‹¬åŸºç¡€æŠ€æœ¯ã€è§†é¢‘ç”Ÿæˆç­–ç•¥ã€å¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†ç­‰ï¼Œå¯¹æœªæ¥ç ”ç©¶æå‡ºäº†ä¸€äº›è§£å†³ç°æœ‰è§†é¢‘ç”Ÿæˆèƒ½åŠ›å±€é™æ€§çš„æ–¹æ³•ã€‚è¿™ç¯‡æ–‡ç« å°†æˆä¸ºè¯¥é¢†åŸŸä¸€ä¸ªå…¨é¢çš„ç ”ç©¶åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†é¢‘ç”ŸæˆæŠ€æœ¯é¢ä¸´ç”Ÿæˆé•¿è§†é¢‘çš„éš¾é¢˜ï¼Œç›®å‰æœ€å…ˆè¿›ç³»ç»Ÿä»æœ‰é™åˆ¶ã€‚</li>
<li>é•¿è§†é¢‘ç”Ÿæˆéœ€è¦è¶…è¶Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¤æ‚æŠ€æœ¯ï¼ŒåŒ…æ‹¬è§„åˆ’ã€æ•…äº‹å‘å±•ç­‰ã€‚</li>
<li>åˆ†è€Œæ²»ä¹‹çš„é›†æˆç­–ç•¥å¯ä»¥æé«˜ç”Ÿæˆé•¿è§†é¢‘çš„æ‰©å±•æ€§ã€‚</li>
<li>å½“å‰æ–‡ç« å¯¹å½“å‰é•¿è§†é¢‘ç”Ÿæˆé¢†åŸŸè¿›è¡Œäº†å…¨é¢è°ƒæŸ¥ã€‚</li>
<li>æ–‡ç« æ¶µç›–äº†åŸºç¡€æŠ€æœ¯ã€è§†é¢‘ç”Ÿæˆç­–ç•¥ã€å¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†ç­‰æ–¹é¢çš„å†…å®¹ã€‚</li>
<li>å¯¹æœªæ¥ç ”ç©¶æå‡ºäº†ä¸€äº›è§£å†³ç°æœ‰è§†é¢‘ç”Ÿæˆèƒ½åŠ›å±€é™æ€§çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18688">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-450fdb2b6244b8e0969c9d277c45f5a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57a4946465503b433b61ee79829dff7d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-06230c7b3abef2dc3de43df7352eb972.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f3186609bba8f2b60c8e929a846820e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Multiscale-Latent-Diffusion-Model-for-Enhanced-Feature-Extraction-from-Medical-Images"><a href="#Multiscale-Latent-Diffusion-Model-for-Enhanced-Feature-Extraction-from-Medical-Images" class="headerlink" title="Multiscale Latent Diffusion Model for Enhanced Feature Extraction from   Medical Images"></a>Multiscale Latent Diffusion Model for Enhanced Feature Extraction from   Medical Images</h2><p><strong>Authors:Rabeya Tus Sadia, Jie Zhang, Jin Chen</strong></p>
<p>Various imaging modalities are used in patient diagnosis, each offering unique advantages and valuable insights into anatomy and pathology. Computed Tomography (CT) is crucial in diagnostics, providing high-resolution images for precise internal organ visualization. CTâ€™s ability to detect subtle tissue variations is vital for diagnosing diseases like lung cancer, enabling early detection and accurate tumor assessment. However, variations in CT scanner models and acquisition protocols introduce significant variability in the extracted radiomic features, even when imaging the same patient. This variability poses considerable challenges for downstream research and clinical analysis, which depend on consistent and reliable feature extraction. Current methods for medical image feature extraction, often based on supervised learning approaches, including GAN-based models, face limitations in generalizing across different imaging environments. In response to these challenges, we propose LTDiff++, a multiscale latent diffusion model designed to enhance feature extraction in medical imaging. The model addresses variability by standardizing non-uniform distributions in the latent space, improving feature consistency. LTDiff++ utilizes a UNet++ encoder-decoder architecture coupled with a conditional Denoising Diffusion Probabilistic Model (DDPM) at the latent bottleneck to achieve robust feature extraction and standardization. Extensive empirical evaluations on both patient and phantom CT datasets demonstrate significant improvements in image standardization, with higher Concordance Correlation Coefficients (CCC) across multiple radiomic feature categories. Through these advancements, LTDiff++ represents a promising solution for overcoming the inherent variability in medical imaging data, offering improved reliability and accuracy in feature extraction processes. </p>
<blockquote>
<p>åœ¨æ‚£è€…è¯Šæ–­ä¸­ï¼Œå¤šç§æˆåƒæ¨¡å¼è¢«å¹¿æ³›åº”ç”¨ï¼Œæ¯ç§æ¨¡å¼éƒ½æœ‰å…¶ç‹¬ç‰¹çš„ä¼˜åŠ¿å’Œå…³äºè§£å‰–å­¦å’Œç—…ç†å­¦çš„å®è´µè§è§£ã€‚è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰åœ¨è¯Šæ–­ä¸­è‡³å…³é‡è¦ï¼Œå®ƒæä¾›é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œç”¨äºç²¾ç¡®çš„å†…éƒ¨å™¨å®˜å¯è§†åŒ–ã€‚CTæ£€æµ‹ç»†å¾®ç»„ç»‡å˜åŒ–çš„èƒ½åŠ›å¯¹äºè¯Šæ–­è‚ºç™Œç­‰ç–¾ç—…è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿå®ç°æ—©æœŸæ£€æµ‹å’Œå‡†ç¡®çš„è‚¿ç˜¤è¯„ä¼°ã€‚ç„¶è€Œï¼ŒCTæ‰«æä»ªå‹å·å’Œé‡‡é›†åè®®çš„å˜åŒ–ä¼šåœ¨æå–æ”¾å°„å­¦ç‰¹å¾æ—¶å¼•å…¥é‡å¤§å·®å¼‚ï¼Œå³ä½¿åœ¨æˆåƒåŒä¸€æ‚£è€…æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ç§å·®å¼‚ç»™ä¸‹æ¸¸ç ”ç©¶å’Œä¸´åºŠåˆ†æå¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ï¼Œåè€…ä¾èµ–äºä¸€è‡´å’Œå¯é çš„ç‰¹å¾æå–ã€‚å½“å‰åŸºäºåŒ»ç–—å›¾åƒç‰¹å¾æå–çš„æ–¹æ³•ï¼Œé€šå¸¸åŸºäºæœ‰ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºGANçš„æ¨¡å‹ï¼Œåœ¨è·¨ä¸åŒæˆåƒç¯å¢ƒæ¨å¹¿æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†LTDiff++ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šå°ºåº¦æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜åŒ»ç–—æˆåƒä¸­çš„ç‰¹å¾æå–èƒ½åŠ›ã€‚è¯¥æ¨¡å‹é€šè¿‡æ ‡å‡†åŒ–æ½œåœ¨ç©ºé—´ä¸­çš„éå‡åŒ€åˆ†å¸ƒæ¥è§£å†³å˜å¼‚æ€§é—®é¢˜ï¼Œæé«˜ç‰¹å¾çš„ä¸€è‡´æ€§ã€‚LTDiff++é‡‡ç”¨UNet++ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œç»“åˆæ½œåœ¨ç“¶é¢ˆå¤„çš„æ¡ä»¶å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ï¼Œå®ç°ç¨³å¥çš„ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–ã€‚åœ¨æ‚£è€…å’Œå¹»å½±CTæ•°æ®é›†ä¸Šçš„å¤§é‡å®è¯è¯„ä¼°è¡¨æ˜ï¼Œå›¾åƒæ ‡å‡†åŒ–æ–¹é¢æœ‰äº†æ˜¾ç€æ”¹è¿›ï¼Œå¤šä¸ªæ”¾å°„å­¦ç‰¹å¾ç±»åˆ«çš„ç¬¦åˆåº¦ç›¸å…³ç³»æ•°ï¼ˆCCCï¼‰æ›´é«˜ã€‚é€šè¿‡è¿™äº›è¿›å±•ï¼ŒLTDiff++æˆä¸ºå…‹æœåŒ»ç–—æˆåƒæ•°æ®å›ºæœ‰å¯å˜æ€§çš„æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºç‰¹å¾æå–è¿‡ç¨‹æä¾›äº†æ”¹è¿›çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.04000v3">PDF</a> version_3</p>
<p><strong>Summary</strong>ï¼š<br>CTåœ¨è¯Šæ–­ä¸­æä¸ºé‡è¦ï¼Œèƒ½æä¾›é«˜è§£æåº¦å›¾åƒä»¥ç²¾ç¡®å‘ˆç°å†…éƒ¨å™¨å®˜ã€‚ç„¶è€Œï¼Œä¸åŒCTæ‰«æä»ªå‹å·å’Œé‡‡é›†åè®®å¯¼è‡´çš„æ”¾å°„ç»„å­¦ç‰¹å¾æå–çš„å˜å¼‚æ€§ï¼Œä¸ºä¸‹æ¸¸ç ”ç©¶å’Œä¸´åºŠåˆ†æå¸¦æ¥æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºLTDiff++æ¨¡å‹ï¼Œé‡‡ç”¨å¤šå°ºåº¦æ½œåœ¨æ‰©æ•£æœºåˆ¶æ ‡å‡†åŒ–æ½œåœ¨ç©ºé—´ä¸­çš„éå‡åŒ€åˆ†å¸ƒï¼Œæ”¹å–„ç‰¹å¾ä¸€è‡´æ€§ï¼Œæé«˜åŒ»å­¦æˆåƒä¸­çš„ç‰¹å¾æå–æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>CTåœ¨è¯Šæ–­ä¸­æä¾›é«˜è§£æåº¦å›¾åƒï¼Œæœ‰åŠ©äºç²¾ç¡®å‘ˆç°å†…éƒ¨å™¨å®˜å’Œæ£€æµ‹å¾®å¦™ç»„ç»‡å˜åŒ–ã€‚</li>
<li>ä¸åŒCTæ‰«æä»ªå’Œé‡‡é›†åè®®å¯¼è‡´æ”¾å°„ç»„å­¦ç‰¹å¾æå–çš„æ˜¾è‘—å˜å¼‚æ€§ã€‚</li>
<li>ç°æœ‰åŸºäºç›‘ç£å­¦ä¹ çš„åŒ»å­¦å›¾åƒç‰¹å¾æå–æ–¹æ³•ï¼ˆåŒ…æ‹¬åŸºäºGANçš„æ¨¡å‹ï¼‰åœ¨è·¨ä¸åŒæˆåƒç¯å¢ƒä¸­æ³›åŒ–æ—¶é¢ä¸´å±€é™æ€§ã€‚</li>
<li>LTDiff++æ¨¡å‹é€šè¿‡æ ‡å‡†åŒ–æ½œåœ¨ç©ºé—´ä¸­çš„éå‡åŒ€åˆ†å¸ƒæ¥åº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>LTDiff++åˆ©ç”¨UNet++ç¼–ç å™¨-è§£ç å™¨æ¶æ„å’Œæ½œåœ¨ç“¶é¢ˆå¤„çš„æ¡ä»¶å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹å®ç°ç¨³å¥çš„ç‰¹å¾æå–å’Œæ ‡å‡†åŒ–ã€‚</li>
<li>åœ¨æ‚£è€…å’Œå¹»å½±CTæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒLTDiff++åœ¨å›¾åƒæ ‡å‡†åŒ–æ–¹é¢å®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼Œå¤šä¸ªæ”¾å°„ç»„å­¦ç‰¹å¾ç±»åˆ«çš„å»åˆåº¦ç›¸å…³ç³»æ•°ï¼ˆCCCï¼‰æ›´é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.04000">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-42fba0ca2d0d87acb68cb50cf245107c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d6927fb523b7e67b714836e5fdf28fa6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c956697bd9db9ba503eb4abaf7e018b6.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="BLS-GAN-A-Deep-Layer-Separation-Framework-for-Eliminating-Bone-Overlap-in-Conventional-Radiographs"><a href="#BLS-GAN-A-Deep-Layer-Separation-Framework-for-Eliminating-Bone-Overlap-in-Conventional-Radiographs" class="headerlink" title="BLS-GAN: A Deep Layer Separation Framework for Eliminating Bone Overlap   in Conventional Radiographs"></a>BLS-GAN: A Deep Layer Separation Framework for Eliminating Bone Overlap   in Conventional Radiographs</h2><p><strong>Authors:Haolin Wang, Yafei Ou, Prasoon Ambalathankandy, Gen Ota, Pengyu Dai, Masayuki Ikebe, Kenji Suzuki, Tamotsu Kamishima</strong></p>
<p>Conventional radiography is the widely used imaging technology in diagnosing, monitoring, and prognosticating musculoskeletal (MSK) diseases because of its easy availability, versatility, and cost-effectiveness. In conventional radiographs, bone overlaps are prevalent, and can impede the accurate assessment of bone characteristics by radiologists or algorithms, posing significant challenges to conventional and computer-aided diagnoses. This work initiated the study of a challenging scenario - bone layer separation in conventional radiographs, in which separate overlapped bone regions enable the independent assessment of the bone characteristics of each bone layer and lay the groundwork for MSK disease diagnosis and its automation. This work proposed a Bone Layer Separation GAN (BLS-GAN) framework that can produce high-quality bone layer images with reasonable bone characteristics and texture. This framework introduced a reconstructor based on conventional radiography imaging principles, which achieved efficient reconstruction and mitigates the recurrent calculations and training instability issues caused by soft tissue in the overlapped regions. Additionally, pre-training with synthetic images was implemented to enhance the stability of both the training process and the results. The generated images passed the visual Turing test, and improved performance in downstream tasks. This work affirms the feasibility of extracting bone layer images from conventional radiographs, which holds promise for leveraging bone layer separation technology to facilitate more comprehensive analytical research in MSK diagnosis, monitoring, and prognosis. Code and dataset: <a target="_blank" rel="noopener" href="https://github.com/pokeblow/BLS-GAN.git">https://github.com/pokeblow/BLS-GAN.git</a>. </p>
<blockquote>
<p>ä¼ ç»Ÿæ”¾å°„æ‘„å½±æ˜¯å¹¿æ³›åº”ç”¨äºè¯Šæ–­ã€ç›‘æµ‹å’Œé¢„æµ‹è‚Œè‚‰éª¨éª¼ï¼ˆMSKï¼‰ç–¾ç—…çš„æˆåƒæŠ€æœ¯ï¼Œå› å…¶æ˜“äºè·å–ã€å¤šåŠŸèƒ½å’Œæˆæœ¬æ•ˆç›Šé«˜ã€‚åœ¨ä¼ ç»Ÿæ”¾å°„æ‘„å½±ä¸­ï¼Œéª¨éª¼é‡å ç°è±¡æ™®éï¼Œå¯èƒ½ä¼šé˜»ç¢æ”¾å°„ç§‘åŒ»ç”Ÿæˆ–ç®—æ³•å¯¹éª¨éª¼ç‰¹å¾çš„å‡†ç¡®è¯„ä¼°ï¼Œç»™ä¼ ç»Ÿå’Œè®¡ç®—æœºè¾…åŠ©è¯Šæ–­å¸¦æ¥é‡å¤§æŒ‘æˆ˜ã€‚è¿™é¡¹å·¥ä½œå¼€å§‹ç ”ç©¶ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯â€”â€”ä¼ ç»Ÿæ”¾å°„æ‘„å½±ä¸­çš„éª¨éª¼å±‚æ¬¡åˆ†ç¦»æŠ€æœ¯ã€‚åœ¨ç ”ç©¶ä¸­ï¼Œé€šè¿‡å°†é‡å çš„éª¨éª¼åŒºåŸŸè¿›è¡Œåˆ†ç¦»è¯„ä¼°ï¼Œç‹¬ç«‹åˆ†æå„ä¸ªéª¨éª¼å±‚æ¬¡çš„éª¨éª¼ç‰¹å¾ï¼Œä¸ºMSKç–¾ç—…çš„è¯Šæ–­å’Œè‡ªåŠ¨åŒ–è¯Šæ–­å¥ å®šåŸºç¡€ã€‚è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ä¸ªéª¨å±‚åˆ†ç¦»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆBLS-GANï¼‰æ¡†æ¶ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰åˆç†éª¨éª¼ç‰¹å¾å’Œçº¹ç†çš„é«˜è´¨é‡éª¨å±‚å›¾åƒã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªåŸºäºä¼ ç»Ÿæ”¾å°„æˆåƒåŸç†çš„é‡æ„å™¨ï¼Œå®ç°äº†æœ‰æ•ˆçš„é‡å»ºï¼Œå¹¶å‡è½»äº†é‡å åŒºåŸŸè½¯ç»„ç»‡å¼•èµ·çš„é‡å¤è®¡ç®—å’Œè®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆæˆå›¾åƒè¿›è¡Œé¢„è®­ç»ƒï¼Œå¢å¼ºäº†è®­ç»ƒè¿‡ç¨‹å’Œç»“æœçš„ç¨³å®šæ€§ã€‚ç”Ÿæˆçš„å›¾åƒé€šè¿‡äº†è§†è§‰å›¾çµæµ‹è¯•ï¼Œå¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­æé«˜äº†æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œè¯å®äº†ä»å¸¸è§„æ”¾å°„æ‘„å½±ä¸­æå–éª¨å±‚å›¾åƒçš„å¯è¡Œæ€§ï¼Œè¿™ä¸ºåˆ©ç”¨éª¨å±‚åˆ†ç¦»æŠ€æœ¯ä¿ƒè¿›MSKè¯Šæ–­ã€ç›‘æµ‹å’Œé¢„åé¢„æµ‹çš„æ›´å…¨é¢åˆ†æç ”ç©¶æä¾›äº†å¸Œæœ›ã€‚ä»£ç å’Œæ•°æ®é›†é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://github.com/pokeblow/BLS-GAN.git%E3%80%82">https://github.com/pokeblow/BLS-GAN.gitã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.07304v2">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong>ï¼š<br>ä¼ ç»Ÿæ”¾å°„çº¿ç…§ç›¸æœ¯å¹¿æ³›åº”ç”¨äºè¯Šæ–­ã€ç›‘æµ‹å’Œé¢„æµ‹è‚Œè‚‰éª¨éª¼ç–¾ç—…ï¼Œä½†ç”±äºéª¨é‡å é—®é¢˜ç»™æ”¾å°„ç§‘åŒ»ç”Ÿæˆ–ç®—æ³•å‡†ç¡®è¯„ä¼°éª¨ç‰¹å¾å¸¦æ¥æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§åä¸ºBLS-GANçš„éª¨å±‚åˆ†ç¦»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¡†æ¶ï¼Œå¯ç”Ÿæˆé«˜è´¨é‡éª¨å±‚å›¾åƒï¼Œé‡‡ç”¨åŸºäºä¼ ç»Ÿæ”¾å°„å­¦æˆåƒåŸç†çš„é‡æ„å™¨ï¼Œå®ç°æœ‰æ•ˆé‡å»ºå¹¶å‡å°‘é‡å åŒºåŸŸè½¯ç»„ç»‡å¼•èµ·çš„åå¤è®¡ç®—å’Œè®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚é¢„è®­ç»ƒåˆæˆå›¾åƒå¢å¼ºäº†è®­ç»ƒå’Œç»“æœçš„ç¨³å®šæ€§ã€‚ç”Ÿæˆå›¾åƒé€šè¿‡è§†è§‰å›¾çµæµ‹è¯•ï¼Œå¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œè¯å®äº†ä»å¸¸è§„æ”¾å°„çº¿ç…§ç‰‡ä¸­æå–éª¨å±‚å›¾åƒçš„å¯èƒ½æ€§ï¼Œä¸ºåˆ©ç”¨éª¨å±‚åˆ†ç¦»æŠ€æœ¯ä¿ƒè¿›è‚Œè‚‰éª¨éª¼ç–¾ç—…çš„è¯Šæ–­ã€ç›‘æµ‹å’Œé¢„æµ‹çš„ç»¼åˆåˆ†ææä¾›äº†å¸Œæœ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ä¼ ç»Ÿæ”¾å°„çº¿ç…§ç›¸æœ¯åœ¨è¯Šæ–­ã€ç›‘æµ‹å’Œé¢„æµ‹è‚Œè‚‰éª¨éª¼ç–¾ç—…æ–¹é¢ä»è¢«å¹¿æ³›ä½¿ç”¨ï¼Œä½†ç”±äºéª¨é‡å é—®é¢˜å¸¦æ¥äº†è¯„ä¼°æŒ‘æˆ˜ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„BLS-GANæ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡çš„éª¨å±‚å›¾åƒã€‚</li>
<li>BLS-GANé‡‡ç”¨äº†åŸºäºä¼ ç»Ÿæ”¾å°„å­¦æˆåƒåŸç†çš„é‡æ„å™¨ï¼Œæé«˜äº†é‡å»ºæ•ˆç‡å¹¶å‡å°‘äº†é‡å åŒºåŸŸè½¯ç»„ç»‡å¼•èµ·çš„è®¡ç®—é—®é¢˜ã€‚</li>
<li>é€šè¿‡é¢„è®­ç»ƒåˆæˆå›¾åƒå¢å¼ºäº†è®­ç»ƒå’Œç»“æœçš„ç¨³å®šæ€§ã€‚</li>
<li>ç”Ÿæˆçš„å›¾åƒé€šè¿‡äº†è§†è§‰å›¾çµæµ‹è¯•ï¼Œå¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>éª¨å±‚åˆ†ç¦»æŠ€æœ¯çš„å®ç°ä¸ºæ›´å…¨é¢çš„è‚Œè‚‰éª¨éª¼ç–¾ç—…è¯Šæ–­ã€ç›‘æµ‹å’Œé¢„æµ‹æä¾›äº†å¯èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.07304">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c823ed0e1334e661bd83595e798c1069.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-710110038e2a13dc556fd8357fe760bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89fa0b86cbf50e6ddcc7a2205436bfc2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb5f5a5e89367b2efcdcdcbb8e53ea8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c709d8f788cf067972a9a21ee1ebff6e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="LatentForensics-Towards-frugal-deepfake-detection-in-the-StyleGAN-latent-space"><a href="#LatentForensics-Towards-frugal-deepfake-detection-in-the-StyleGAN-latent-space" class="headerlink" title="LatentForensics: Towards frugal deepfake detection in the StyleGAN   latent space"></a>LatentForensics: Towards frugal deepfake detection in the StyleGAN   latent space</h2><p><strong>Authors:Matthieu Delmas, Renaud Seguier</strong></p>
<p>The classification of forged videos has been a challenge for the past few years. Deepfake classifiers can now reliably predict whether or not video frames have been tampered with. However, their performance is tied to both the dataset used for training and the analystâ€™s computational power. We propose a deepfake detection method that operates in the latent space of a state-of-the-art generative adversarial network (GAN) trained on high-quality face images. The proposed method leverages the structure of the latent space of StyleGAN to learn a lightweight binary classification model. Experimental results on standard datasets reveal that the proposed approach outperforms other state-of-the-art deepfake classification methods, especially in contexts where the data available to train the models is rare, such as when a new manipulation method is introduced. To the best of our knowledge, this is the first study showing the interest of the latent space of StyleGAN for deepfake classification. Combined with other recent studies on the interpretation and manipulation of this latent space, we believe that the proposed approach can further help in developing frugal deepfake classification methods based on interpretable high-level properties of face images. </p>
<blockquote>
<p>è§†é¢‘ä¼ªé€ åˆ†ç±»åœ¨è¿‡å»å‡ å¹´ä¸­ä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æ·±åº¦ä¼ªé€ åˆ†ç±»å™¨ç°åœ¨å¯ä»¥å¯é åœ°é¢„æµ‹è§†é¢‘å¸§æ˜¯å¦è¢«ç¯¡æ”¹ã€‚ä½†æ˜¯ï¼Œå®ƒä»¬çš„æ€§èƒ½æ—¢å–å†³äºç”¨äºè®­ç»ƒçš„æ•°æ®é›†ï¼Œä¹Ÿå–å†³äºåˆ†æäººå‘˜çš„è®¡ç®—èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè®­ç»ƒæœ‰ç´ çš„æœ€æ–°ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„æ½œåœ¨ç©ºé—´çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•ï¼Œè¯¥ç½‘ç»œä½¿ç”¨é«˜è´¨é‡çš„äººè„¸å›¾åƒè¿›è¡Œè®­ç»ƒã€‚è¯¥æ–¹æ³•åˆ©ç”¨StyleGANçš„æ½œåœ¨ç©ºé—´ç»“æ„æ¥å­¦ä¹ è½»é‡çº§çš„äºŒåˆ†ç±»æ¨¡å‹ã€‚åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–æœ€æ–°çš„æ·±åº¦ä¼ªé€ åˆ†ç±»æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯ç”¨æ•°æ®ç¨€å°‘çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹æ—¶è¡¨ç°å¾—å°¤ä¸ºå‡ºè‰²ï¼Œä¾‹å¦‚å¼•å…¥æ–°çš„æ“ä½œæ–¹æ³•æ—¶ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡ç ”ç©¶StyleGANçš„æ½œåœ¨ç©ºé—´åœ¨æ·±åº¦ä¼ªé€ åˆ†ç±»æ–¹é¢çš„å…´è¶£ã€‚ç»“åˆæœ€è¿‘å…³äºè§£é‡Šå’Œæ“çºµè¿™ä¸€æ½œåœ¨ç©ºé—´çš„ç ”ç©¶ï¼Œæˆ‘ä»¬ç›¸ä¿¡æ‰€æå‡ºçš„æ–¹æ³•å¯ä»¥å¸®åŠ©å¼€å‘åŸºäºäººè„¸å›¾åƒå¯è§£é‡Šçš„é«˜çº§ç‰¹æ€§çš„èŠ‚ä¿­å‹æ·±åº¦ä¼ªé€ åˆ†ç±»æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2303.17222v4">PDF</a> 7 pages, 3 figures, 5 tables</p>
<p><strong>Summary</strong><br>åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„æ½œåœ¨ç©ºé—´ï¼Œæå‡ºä¸€ç§æ·±åº¦ä¼ªé€ æ£€æµ‹æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨StyleGANçš„æ½œåœ¨ç©ºé—´ç»“æ„ï¼Œå­¦ä¹ è½»é‡çº§äºŒåˆ†ç±»æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–å…ˆè¿›æ·±åº¦ä¼ªé€ åˆ†ç±»æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–°æ“çºµæ–¹æ³•å¼•å…¥ç­‰ç½•è§æ•°æ®æƒ…å†µä¸‹ã€‚è¿™æ˜¯é¦–æ¬¡ç ”ç©¶StyleGANæ½œåœ¨ç©ºé—´åœ¨æ·±åº¦ä¼ªé€ åˆ†ç±»ä¸­çš„åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦ä¼ªé€ è§†é¢‘åˆ†ç±»æ˜¯è¿‘å¹´æ¥çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ·±åº¦ä¼ªé€ åˆ†ç±»å™¨å¯é¢„æµ‹è§†é¢‘å¸§æ˜¯å¦è¢«ç¯¡æ”¹ï¼Œä½†å…¶æ€§èƒ½å—è®­ç»ƒæ•°æ®é›†å’Œè®¡ç®—èµ„æºçš„å½±å“ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºStyleGANæ½œåœ¨ç©ºé—´çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å­¦ä¹ è½»é‡çº§äºŒåˆ†ç±»æ¨¡å‹ï¼Œåˆ©ç”¨StyleGANçš„æ½œåœ¨ç©ºé—´ç»“æ„ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ã€‚</li>
<li>è¿™æ˜¯é¦–æ¬¡ç ”ç©¶StyleGANæ½œåœ¨ç©ºé—´åœ¨æ·±åº¦ä¼ªé€ åˆ†ç±»ä¸­çš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2303.17222">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-47c02ce4a6b882d734dcca971f1b4aaa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-524aa944fa93105f4f3cfadfafc02f9d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa5e528dea537cce436af8aa5c29c8d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-066b759e688a9a19111037d42e978e60.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb69b268c41a42646333449f774e7f45.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/GAN/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-02/GAN/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/GAN/">
                                    <span class="chip bg-color">GAN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-519b6cc1bd7cf2c02053876e12ac88ff.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  Generating Editable Head Avatars with 3D Gaussian GANs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-02/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bb372937362ebe61d84b01951b971cab.jpg" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-02  KunServe Elastic and Efficient Large Language Model Serving with   Parameter-centric Memory Management
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23539.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
