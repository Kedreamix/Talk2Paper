<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-05-15  NavDP Learning Sim-to-Real Navigation Diffusion Policy with Privileged   Information Guidance">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-bdc0acd6a5fe314eb86caac9509ed4d9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-15-更新"><a href="#2025-05-15-更新" class="headerlink" title="2025-05-15 更新"></a>2025-05-15 更新</h1><h2 id="NavDP-Learning-Sim-to-Real-Navigation-Diffusion-Policy-with-Privileged-Information-Guidance"><a href="#NavDP-Learning-Sim-to-Real-Navigation-Diffusion-Policy-with-Privileged-Information-Guidance" class="headerlink" title="NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged   Information Guidance"></a>NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged   Information Guidance</h2><p><strong>Authors:Wenzhe Cai, Jiaqi Peng, Yuqiang Yang, Yujian Zhang, Meng Wei, Hanqing Wang, Yilun Chen, Tai Wang, Jiangmiao Pang</strong></p>
<p>Learning navigation in dynamic open-world environments is an important yet challenging skill for robots. Most previous methods rely on precise localization and mapping or learn from expensive real-world demonstrations. In this paper, we propose the Navigation Diffusion Policy (NavDP), an end-to-end framework trained solely in simulation and can zero-shot transfer to different embodiments in diverse real-world environments. The key ingredient of NavDP’s network is the combination of diffusion-based trajectory generation and a critic function for trajectory selection, which are conditioned on only local observation tokens encoded from a shared policy transformer. Given the privileged information of the global environment in simulation, we scale up the demonstrations of good quality to train the diffusion policy and formulate the critic value function targets with contrastive negative samples. Our demonstration generation approach achieves about 2,500 trajectories&#x2F;GPU per day, 20$\times$ more efficient than real-world data collection, and results in a large-scale navigation dataset with 363.2km trajectories across 1244 scenes. Trained with this simulation dataset, NavDP achieves state-of-the-art performance and consistently outstanding generalization capability on quadruped, wheeled, and humanoid robots in diverse indoor and outdoor environments. In addition, we present a preliminary attempt at using Gaussian Splatting to make in-domain real-to-sim fine-tuning to further bridge the sim-to-real gap. Experiments show that adding such real-to-sim data can improve the success rate by 30% without hurting its generalization capability. </p>
<blockquote>
<p>机器人学习动态开放环境中的导航是一项重要且具有挑战性的技能。大多数之前的方法依赖于精确的定位和地图构建，或者从昂贵的真实世界演示中学习。在本文中，我们提出了导航扩散策略（NavDP），这是一种端到端的框架，仅通过模拟进行训练，并可以在不同的实体中零样本迁移到各种真实世界环境中。NavDP网络的关键成分是结合基于扩散的轨迹生成和用于轨迹选择的评论家函数，它们仅基于来自共享政策转换器的局部观察标记。利用模拟中全局环境的特权信息，我们扩大了高质量演示的规模来训练扩散策略，并用对比负样本制定评论家价值函数的目标。我们的演示生成方法每天每GPU生成约2500条轨迹，比真实世界的数据收集效率高出20倍，并形成了包含跨越1244个场景的363.2公里轨迹的大规模导航数据集。使用该模拟数据集进行训练，NavDP在多种室内和室外环境中的四足、轮式和人形机器人上达到了最新性能，并始终具有出色的泛化能力。此外，我们初步尝试使用高斯平铺（Gaussian Splatting）来进行域内真实到模拟的微调，以进一步缩小模拟到真实的差距。实验表明，添加此类真实到模拟的数据可以在不损害其泛化能力的情况下将成功率提高3%个百分点。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08712v1">PDF</a> 14 pages, 6 figures</p>
<p><strong>摘要</strong></p>
<pre><code>本文提出一种名为NavDP的端到端框架，用于在动态开放世界环境中学习机器人导航。该框架仅通过模拟进行训练，并能零样本迁移至不同实体的各种现实环境。NavDP网络的关键在于结合基于扩散的轨迹生成和用于轨迹选择的评价函数，这两个部分仅基于共享策略转换器的局部观测符号。利用模拟中的全局环境特权信息，我们扩大了优质演示数据的规模，以训练扩散策略和制定评价价值函数的目标，同时采用对比负样本。我们的演示生成方法每天每GPU可实现约2500条轨迹，比现实数据收集的效率高出20倍，并生成了一个大型导航数据集，包含1244个场景中的363.2公里轨迹。使用该模拟数据集进行训练，NavDP在多种四足、轮式和人形机器人上实现了最先进的性能，并在室内和室外环境中表现出卓越的一致泛化能力。此外，我们还初步尝试使用高斯贴图进行领域内实到模拟微调，以进一步缩小模拟到现实的差距。实验表明，添加这种实到模拟数据可以在不影响泛化能力的情况下将成功率提高30%。
</code></pre>
<p><strong>关键见解</strong></p>
<ol>
<li>机器人学习在动态开放世界环境中的导航是一项重要而具有挑战性的技能。</li>
<li>NavDP是一个端到端的框架，能够在模拟中训练并零样本迁移到不同的现实环境。</li>
<li>NavDP结合了基于扩散的轨迹生成和轨迹选择的评价函数，仅基于局部观测符号。</li>
<li>使用模拟中的全局环境信息来训练扩散策略和制定评价价值函数的目标，采用对比负样本的方法。</li>
<li>演示生成方法高效，每天每GPU可生成大量轨迹数据。</li>
<li>NavDP在多种机器人上实现先进性能，并在室内和室外环境表现出卓越的泛化能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08712">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ae94521c26ec5316de842a35f841a992.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5ece77ee4ea536081b25b2564ab0c799.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6f7975423f5c24b90adca34e50fd5914.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69468c355f30e773041a385d497a8628.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b706f04ae285ca6c40b92c41833dbc0e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FOCI-Trajectory-Optimization-on-Gaussian-Splats"><a href="#FOCI-Trajectory-Optimization-on-Gaussian-Splats" class="headerlink" title="FOCI: Trajectory Optimization on Gaussian Splats"></a>FOCI: Trajectory Optimization on Gaussian Splats</h2><p><strong>Authors:Mario Gomez Andreu, Maximum Wilder-Smith, Victor Klemm, Vaishakh Patil, Jesus Tordesillas, Marco Hutter</strong></p>
<p>3D Gaussian Splatting (3DGS) has recently gained popularity as a faster alternative to Neural Radiance Fields (NeRFs) in 3D reconstruction and view synthesis methods. Leveraging the spatial information encoded in 3DGS, this work proposes FOCI (Field Overlap Collision Integral), an algorithm that is able to optimize trajectories directly on the Gaussians themselves. FOCI leverages a novel and interpretable collision formulation for 3DGS using the notion of the overlap integral between Gaussians. Contrary to other approaches, which represent the robot with conservative bounding boxes that underestimate the traversability of the environment, we propose to represent the environment and the robot as Gaussian Splats. This not only has desirable computational properties, but also allows for orientation-aware planning, allowing the robot to pass through very tight and narrow spaces. We extensively test our algorithm in both synthetic and real Gaussian Splats, showcasing that collision-free trajectories for the ANYmal legged robot that can be computed in a few seconds, even with hundreds of thousands of Gaussians making up the environment. The project page and code are available at <a target="_blank" rel="noopener" href="https://rffr.leggedrobotics.com/works/foci/">https://rffr.leggedrobotics.com/works/foci/</a> </p>
<blockquote>
<p>3D高斯Splatting（3DGS）作为一种更快的替代方法，在三维重建和视图合成方法中受到欢迎，成为神经辐射场（NeRFs）的替代方案。利用编码在3DGS中的空间信息，这项工作提出了FOCI（场重叠碰撞积分）算法，该算法能够在高斯本身上直接优化轨迹。FOCI利用一种新颖的、可解释的碰撞公式为3DGS使用高斯之间的重叠积分的概念。与其他使用保守边界框表示机器人并低估环境可通行性的方法不同，我们提出将环境和机器人表示为高斯Splats。这不仅具有理想的计算属性，而且允许具有方向感知的规划，允许机器人在非常紧凑和狭窄的空间中通过。我们在合成和真实的高斯Splats中都测试了我们的算法，展示了即使在由数十万个高斯组成的环境中，也可以在几秒钟内计算出ANYmal腿式机器人的无碰撞轨迹。项目页面和代码可在<a target="_blank" rel="noopener" href="https://rffr.leggedrobotics.com/works/foci/%E6%89%BE%E5%88%B0%E3%80%82">https://rffr.leggedrobotics.com/works/foci/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08510v1">PDF</a> 7 pages, 8 figures, Mario Gomez Andreu and Maximum Wilder-Smith   contributed equally</p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于三维高斯贴片（3DGS）技术的最新研究成果，提出一种名为FOCI（基于高斯重叠积分的碰撞算法）的算法。该算法利用高斯贴片的空间信息优化轨迹，通过高斯之间的重叠积分实现碰撞检测，进而应用于环境机器人学的任务。该算法相比保守框近似方式更具有准确性，并且能够针对狭窄空间的精确操作，能够自主穿越复杂的非线性空间进行执行任务。已在仿真与实际场景中的测试和性能验证展示了FOCI的高效性。此外项目内容和代码均已在线公开可供参考和学习。 </p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS作为一种更快的替代方法被广泛应用于三维重建和视图合成方法中替代NeRFs技术。</li>
<li>FOCI算法通过优化高斯贴片来优化轨迹，能够更准确地评估机器人的移动性能和环境情况。</li>
<li>FOCI利用高斯重叠积分进行碰撞检测，提供了一种新颖且可解释的碰撞公式。</li>
<li>与保守框近似方法不同，FOCI算法将机器人和环境表示为高斯贴片，具有更好的计算性能和方向感知规划能力。</li>
<li>FOCI算法能够在狭窄空间内实现精确操作，允许机器人穿越复杂的非线性空间执行任务。</li>
<li>在合成和实际高斯贴片环境中进行了广泛的测试，验证了FOCI算法的高效性。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08510">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-a5d13a33c1a252b2109a69ef7836ace5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64fb760ed1c8ae83783cfbeaf541d97a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fc47821dfa18766c7b71d57c66045bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b2a07a4e82592d3e12465460e264fd7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-486a9183a78d5bdff34ba6147c9e6817.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-39e620b5399348bd6967332697f0301f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ADC-GS-Anchor-Driven-Deformable-and-Compressed-Gaussian-Splatting-for-Dynamic-Scene-Reconstruction"><a href="#ADC-GS-Anchor-Driven-Deformable-and-Compressed-Gaussian-Splatting-for-Dynamic-Scene-Reconstruction" class="headerlink" title="ADC-GS: Anchor-Driven Deformable and Compressed Gaussian Splatting for   Dynamic Scene Reconstruction"></a>ADC-GS: Anchor-Driven Deformable and Compressed Gaussian Splatting for   Dynamic Scene Reconstruction</h2><p><strong>Authors:He Huang, Qi Yang, Mufan Liu, Yiling Xu, Zhu Li</strong></p>
<p>Existing 4D Gaussian Splatting methods rely on per-Gaussian deformation from a canonical space to target frames, which overlooks redundancy among adjacent Gaussian primitives and results in suboptimal performance. To address this limitation, we propose Anchor-Driven Deformable and Compressed Gaussian Splatting (ADC-GS), a compact and efficient representation for dynamic scene reconstruction. Specifically, ADC-GS organizes Gaussian primitives into an anchor-based structure within the canonical space, enhanced by a temporal significance-based anchor refinement strategy. To reduce deformation redundancy, ADC-GS introduces a hierarchical coarse-to-fine pipeline that captures motions at varying granularities. Moreover, a rate-distortion optimization is adopted to achieve an optimal balance between bitrate consumption and representation fidelity. Experimental results demonstrate that ADC-GS outperforms the per-Gaussian deformation approaches in rendering speed by 300%-800% while achieving state-of-the-art storage efficiency without compromising rendering quality. The code is released at <a target="_blank" rel="noopener" href="https://github.com/H-Huang774/ADC-GS.git">https://github.com/H-Huang774/ADC-GS.git</a>. </p>
<blockquote>
<p>现有的4D高斯贴片方法依赖于从规范空间到目标帧的高斯变形，这忽略了相邻高斯基元之间的冗余性，导致性能不佳。为了解决这一局限性，我们提出了锚驱动可变形和压缩高斯贴片（ADC-GS），这是一种用于动态场景重建的紧凑高效表示方法。具体而言，ADC-GS在规范空间内采用基于锚点的结构来组织高斯基元，并使用基于时间重要性的锚点优化策略进行增强。为了减少变形冗余，ADC-GS引入了一个分层粗细管道，以捕获不同粒度的运动。此外，采用速率失真优化以实现比特率消耗和表示保真度之间的最佳平衡。实验结果表明，在渲染速度方面，ADC-GS较基于高斯变形的传统方法提高了300%-800%，同时实现了最先进的存储效率，而渲染质量并未受到影响。代码已发布在<a target="_blank" rel="noopener" href="https://github.com/H-Huang774/ADC-GS.git%E4%B8%8A%E3%80%82">https://github.com/H-Huang774/ADC-GS.git上。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08196v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文针对现有4D高斯绘制方法在处理高斯原始数据时的冗余问题，提出了基于锚点驱动的可变形和压缩高斯绘制（ADC-GS）方法。该方法将高斯原始数据组织成基于锚点的结构，并采用基于时间重要性的锚点优化策略。通过层次化的粗到细流程来减少变形冗余，并实现了在比特率消耗和表示保真度之间的最优平衡。实验结果表明，ADC-GS在渲染速度上比基于高斯原始数据的方法提高了300%-800%，同时达到了业界领先的存储效率，且不影响渲染质量。相关代码已发布在GitHub上。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ADC-GS解决了现有4D高斯绘制方法在处理高斯原始数据时的冗余问题。</li>
<li>方法通过基于锚点的结构组织高斯原始数据，并利用时间重要性策略进行锚点优化。</li>
<li>ADC-GS引入了层次化的粗到细流程以减少变形冗余。</li>
<li>方法采用率失真优化来实现比特率消耗和表示保真度之间的平衡。</li>
<li>ADC-GS提高了渲染速度，最高可达传统方法的3到8倍。此方法提供了业界领先的存储效率，且不会牺牲渲染质量。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08196">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-4c77f7b72033479cc76c14dd21606e83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-483cf4534465df02acaf6b645b12cda2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f105abc7845c38820b2aa4da15f00da5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93271148b0b1cab20758400363688cf8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b0b983697e9d7a1e94d673f7b390280.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8ddc61b5e8b97d2f3a73acbc57373f4.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SLAG-Scalable-Language-Augmented-Gaussian-Splatting"><a href="#SLAG-Scalable-Language-Augmented-Gaussian-Splatting" class="headerlink" title="SLAG: Scalable Language-Augmented Gaussian Splatting"></a>SLAG: Scalable Language-Augmented Gaussian Splatting</h2><p><strong>Authors:Laszlo Szilagyi, Francis Engelmann, Jeannette Bohg</strong></p>
<p>Language-augmented scene representations hold great promise for large-scale robotics applications such as search-and-rescue, smart cities, and mining. Many of these scenarios are time-sensitive, requiring rapid scene encoding while also being data-intensive, necessitating scalable solutions. Deploying these representations on robots with limited computational resources further adds to the challenge. To address this, we introduce SLAG, a multi-GPU framework for language-augmented Gaussian splatting that enhances the speed and scalability of embedding large scenes. Our method integrates 2D visual-language model features into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG eliminates the need for a loss function to compute per-Gaussian language embeddings. Instead, it derives embeddings from 3D Gaussian scene parameters via a normalized weighted average, enabling highly parallelized scene encoding. Additionally, we introduce a vector database for efficient embedding storage and retrieval. Our experiments show that SLAG achieves an 18 times speedup in embedding computation on a 16-GPU setup compared to OpenGaussian, while preserving embedding quality on the ScanNet and LERF datasets. For more details, visit our project website: <a target="_blank" rel="noopener" href="https://slag-project.github.io/">https://slag-project.github.io/</a>. </p>
<blockquote>
<p>语言增强的场景表示在大型机器人应用方面，如搜索和救援、智能城市和采矿等领域具有巨大潜力。许多这些场景都是时间敏感型的，需要在快速场景编码的同时处理大量数据，需要可扩展的解决方案。在具有有限计算资源的机器人上部署这些表示形式进一步增加了挑战。为了解决这一问题，我们引入了SLAG，这是一个用于语言增强的多GPU高斯拼接框架，提高了大规模场景嵌入的速度和可扩展性。我们的方法通过将2D视觉语言模型特征集成到3D场景中，使用SAM和CLIP。不同于以前的方法，SLAG不需要使用损失函数来计算每个高斯语言嵌入。相反，它通过归一化加权平均从3D高斯场景参数中提取嵌入，实现高度并行的场景编码。此外，我们还引入了一个向量数据库，用于有效地存储和检索嵌入。我们的实验表明，与OpenGaussian相比，SLAG在16 GPU设置上实现了嵌入计算的速度提升18倍，同时在ScanNet和LERF数据集上保持了嵌入质量。如需更多详细信息，请访问我们的项目网站：<a target="_blank" rel="noopener" href="https://slag-project.github.io/">https://slag-project.github.io/。</a>%E3%80%82</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08124v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文本介绍了语言增强场景表示在机器人等大型应用场景中的潜力，如搜救、智能城市和采矿。针对大型场景的快速编码和数据密集需求，提出了一种基于多GPU的语言增强高斯喷绘框架SLAG。该方法通过整合二维视觉语言模型特征到三维场景，提升了场景编码的速度和可扩展性。SLAG通过归一化加权平均从三维高斯场景参数中导出嵌入，无需使用损失函数计算每个高斯语言的嵌入。此外，还引入了向量数据库，以便高效存储和检索嵌入。实验表明，SLAG在16 GPU设置上的嵌入计算速度比OpenGaussian快18倍，同时在ScanNet和LERF数据集上保持嵌入质量。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语言增强场景表示在大型应用场景（如搜救、智能城市和采矿）中具有巨大潜力。</li>
<li>SLAG是一种多GPU框架，用于语言增强的高斯喷绘，可提高场景编码的速度和可扩展性。</li>
<li>SLAG通过将2D视觉语言模型特征集成到3D场景中，改进了场景表示。</li>
<li>SLAG通过归一化加权平均从3D高斯场景参数中导出嵌入，简化了计算过程。</li>
<li>SLAG引入向量数据库，实现高效嵌入存储和检索。</li>
<li>实验显示，SLAG在嵌入计算速度方面比OpenGaussian快18倍，同时保持嵌入质量。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08124">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0e224ca390f9ef2025c24c3e58a1e609.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85320b835337c6e5d28afac43bbf1d35.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ce65035c36ffa7e535f2579c3482f76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-989b73cf113f45fb0bc155527793d6cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bdc0acd6a5fe314eb86caac9509ed4d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-179774fce630f8f197a0d01895391f6e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Monocular-Online-Reconstruction-with-Enhanced-Detail-Preservation"><a href="#Monocular-Online-Reconstruction-with-Enhanced-Detail-Preservation" class="headerlink" title="Monocular Online Reconstruction with Enhanced Detail Preservation"></a>Monocular Online Reconstruction with Enhanced Detail Preservation</h2><p><strong>Authors:Songyin Wu, Zhaoyang Lv, Yufeng Zhu, Duncan Frost, Zhengqin Li, Ling-Qi Yan, Carl Ren, Richard Newcombe, Zhao Dong</strong></p>
<p>We propose an online 3D Gaussian-based dense mapping framework for photorealistic details reconstruction from a monocular image stream. Our approach addresses two key challenges in monocular online reconstruction: distributing Gaussians without relying on depth maps and ensuring both local and global consistency in the reconstructed maps. To achieve this, we introduce two key modules: the Hierarchical Gaussian Management Module for effective Gaussian distribution and the Global Consistency Optimization Module for maintaining alignment and coherence at all scales. In addition, we present the Multi-level Occupancy Hash Voxels (MOHV), a structure that regularizes Gaussians for capturing details across multiple levels of granularity. MOHV ensures accurate reconstruction of both fine and coarse geometries and textures, preserving intricate details while maintaining overall structural integrity. Compared to state-of-the-art RGB-only and even RGB-D methods, our framework achieves superior reconstruction quality with high computational efficiency. Moreover, it integrates seamlessly with various tracking systems, ensuring generality and scalability. </p>
<blockquote>
<p>我们提出了一种基于在线三维高斯分布的密集映射框架，用于从单目图像流中重建逼真的细节。我们的方法解决了单目在线重建中的两个关键挑战：在不依赖深度图的情况下分布高斯，以及在重建地图中确保局部和全局的一致性。为了实现这一点，我们引入了两个关键模块：分层高斯管理模块，用于有效的高斯分布；全局一致性优化模块，用于在所有尺度上保持对齐和连贯性。此外，我们提出了多级占用哈希体素（MOHV），这是一种使高斯正规化的结构，能够捕捉多粒度级别的细节。MOHV确保精细和粗糙的几何形状和纹理的准确重建，保留细节的同时保持整体结构完整性。与最先进的仅使用RGB甚至是RGB-D方法相比，我们的框架在计算效率高的情况下实现了更出色的重建质量。此外，它与各种跟踪系统无缝集成，确保了通用性和可扩展性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07887v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文提出了一种在线三维高斯密集映射框架，用于从单目图像流重建逼真的细节。该方法解决了单目在线重建中的两个关键挑战：在不依赖深度图的情况下分布高斯并确保了重建地图的局部和全局一致性。为实现这一目标，引入了关键的两个模块：分层高斯管理模块用于有效的高斯分布和全局一致性优化模块，以在所有尺度上保持对齐和连贯性。此外，还提出了多级别占用哈希体素（MOHV），这种结构可以规范高斯分布以捕捉多个粒度级别的细节。MOHV确保精细和粗糙几何以及纹理的准确重建，保留细节的同时保持整体结构完整性。与最新的仅RGB甚至RGB-D方法相比，该框架具有更高的计算效率和优越的重建质量。此外，它与各种跟踪系统无缝集成，确保通用性和可扩展性。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是关键要点概述：</p>
<ul>
<li>提出了一种在线三维高斯密集映射框架用于单目图像流的逼真细节重建。</li>
<li>解决单目在线重建中的两个关键挑战：高斯分布与深度图的无关性和局部与全局一致性的保证。</li>
<li>引入两个核心模块：分层高斯管理模块和全局一致性优化模块。</li>
<li>提出多级别占用哈希体素（MOHV）以捕捉多个粒度级别的细节并实现准确的重建细节和整体结构完整性。</li>
<li>与现有方法相比，该框架具有更高的计算效率和优越的重建质量。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07887">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9de0bf233f60e0e2050ad5dd8875493d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-db2180c55383844c0a403110c37e3f0f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-901e19b94c2633f8204b6c4e893de3ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0c13b198dca81ca916413bb85e73eea1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bc67131f3dc2fa15d0c67a2b5f6e84a0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TUM2TWIN-Introducing-the-Large-Scale-Multimodal-Urban-Digital-Twin-Benchmark-Dataset"><a href="#TUM2TWIN-Introducing-the-Large-Scale-Multimodal-Urban-Digital-Twin-Benchmark-Dataset" class="headerlink" title="TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin   Benchmark Dataset"></a>TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin   Benchmark Dataset</h2><p><strong>Authors:Olaf Wysocki, Benedikt Schwab, Manoj Kumar Biswanath, Michael Greza, Qilin Zhang, Jingwei Zhu, Thomas Froech, Medhini Heeramaglore, Ihab Hijazi, Khaoula Kanna, Mathias Pechinger, Zhaiyu Chen, Yao Sun, Alejandro Rueda Segura, Ziyang Xu, Omar AbdelGafar, Mansour Mehranfar, Chandan Yeshwanth, Yueh-Cheng Liu, Hadi Yazdi, Jiapan Wang, Stefan Auer, Katharina Anders, Klaus Bogenberger, Andre Borrmann, Angela Dai, Ludwig Hoegner, Christoph Holst, Thomas H. Kolbe, Ferdinand Ludwig, Matthias Nießner, Frank Petzold, Xiao Xiang Zhu, Boris Jutzi</strong></p>
<p>Urban Digital Twins (UDTs) have become essential for managing cities and integrating complex, heterogeneous data from diverse sources. Creating UDTs involves challenges at multiple process stages, including acquiring accurate 3D source data, reconstructing high-fidelity 3D models, maintaining models’ updates, and ensuring seamless interoperability to downstream tasks. Current datasets are usually limited to one part of the processing chain, hampering comprehensive UDTs validation. To address these challenges, we introduce the first comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN. This dataset includes georeferenced, semantically aligned 3D models and networks along with various terrestrial, mobile, aerial, and satellite observations boasting 32 data subsets over roughly 100,000 $m^2$ and currently 767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high accuracy, and multimodal data integration, the benchmark supports robust analysis of sensors and the development of advanced reconstruction methods. Additionally, we explore downstream tasks demonstrating the potential of TUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar potential analysis, point cloud semantic segmentation, and LoD3 building reconstruction. We are convinced this contribution lays a foundation for overcoming current limitations in UDT creation, fostering new research directions and practical solutions for smarter, data-driven urban environments. The project is available under: <a target="_blank" rel="noopener" href="https://tum2t.win/">https://tum2t.win</a> </p>
<blockquote>
<p>城市数字双胞胎（UDTs）对于管理城市以及整合来自不同源的复杂、异构数据已经变得至关重要。创建UDTs涉及多个流程阶段的挑战，包括获取准确的3D源数据、重建高保真3D模型、保持模型的更新以及确保无缝集成到下游任务中。当前的数据集通常仅限于处理链的一部分，阻碍了全面的UDTs验证。为了解决这些挑战，我们引入了第一个全面的多模式城市数字双胞胎基准数据集：TUM2TWIN。该数据集包括地理参考、语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测，拥有超过约10万平方米的32个数据子集和目前767GB的数据。通过确保地理参考的室内外采集、高精度和多模式数据集成，该基准支持对传感器的稳健分析和高级重建方法的发展。此外，我们还探索了展示TUM2TWIN潜力的下游任务，包括NeRF和高斯拼贴的新视图合成、太阳能潜力分析、点云语义分割和LOD3建筑重建。我们相信这一贡献为克服UDTs创建中的当前局限性奠定了基础，促进了新的研究方向和针对数据驱动的智能城市环境的实用解决方案。项目网址为：<a target="_blank" rel="noopener" href="https://tum2t.win/">https://tum2t.win</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07396v2">PDF</a> Submitted to the ISPRS Journal of Photogrammetry and Remote Sensing</p>
<p><strong>Summary</strong></p>
<p>本文介绍了城市数字双胞胎（UDTs）在管理城市和整合复杂、异构数据方面的作用。针对创建UDTs所面临的挑战，如获取准确的3D源数据、重建高保真3D模型等，提出了一种新的综合多模态城市数字双胞胎基准数据集——TUM2TWIN。该数据集包含地理参考的语义对齐的3D模型和网络，以及各种地面、移动、空中和卫星观测数据，包含约10万平米的32个数据子集和目前共767GB的数据。该基准数据集支持传感器稳健性分析以及高级重建方法的发展。此外，还探讨了下游任务，展示了TUM2TWIN的潜力，包括新型视图合成、太阳能潜力分析、点云语义分割和LOD3建筑重建等。此贡献为克服当前UDT创建中的限制奠定了基础，为智能数据驱动的城市环境研究提供了新的研究方向和实用解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UDTs在现代城市管理中的作用：管理复杂、异构数据，提升城市智能化水平。</li>
<li>创建UDTs的挑战包括获取准确的3D源数据、模型重建、模型更新和无缝集成等。</li>
<li>TUM2TWIN是一个综合多模态城市数字双胞胎基准数据集，包含地理参考的语义对齐的3D模型和各种观测数据。</li>
<li>数据集大小为约767GB，覆盖多个领域，如地面、移动、空中和卫星观测数据。</li>
<li>基准数据集支持传感器稳健性分析以及高级重建方法的发展。</li>
<li>TUM2TWIN的下游任务展示了其在新型视图合成、太阳能潜力分析等领域的潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07396">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b7b9f046da91752f8f1495d496d4d45b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d2c04c9186e2d3af46c3370e418625d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b84a340c0778072c0bc4ba3574de24ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb439d15b23eec98ae5b0ce75e646dc2.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="HoloTime-Taming-Video-Diffusion-Models-for-Panoramic-4D-Scene-Generation"><a href="#HoloTime-Taming-Video-Diffusion-Models-for-Panoramic-4D-Scene-Generation" class="headerlink" title="HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene   Generation"></a>HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene   Generation</h2><p><strong>Authors:Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan</strong></p>
<p>The rapid advancement of diffusion models holds the promise of revolutionizing the application of VR and AR technologies, which typically require scene-level 4D assets for user experience. Nonetheless, existing diffusion models predominantly concentrate on modeling static 3D scenes or object-level dynamics, constraining their capacity to provide truly immersive experiences. To address this issue, we propose HoloTime, a framework that integrates video diffusion models to generate panoramic videos from a single prompt or reference image, along with a 360-degree 4D scene reconstruction method that seamlessly transforms the generated panoramic video into 4D assets, enabling a fully immersive 4D experience for users. Specifically, to tame video diffusion models for generating high-fidelity panoramic videos, we introduce the 360World dataset, the first comprehensive collection of panoramic videos suitable for downstream 4D scene reconstruction tasks. With this curated dataset, we propose Panoramic Animator, a two-stage image-to-video diffusion model that can convert panoramic images into high-quality panoramic videos. Following this, we present Panoramic Space-Time Reconstruction, which leverages a space-time depth estimation method to transform the generated panoramic videos into 4D point clouds, enabling the optimization of a holistic 4D Gaussian Splatting representation to reconstruct spatially and temporally consistent 4D scenes. To validate the efficacy of our method, we conducted a comparative analysis with existing approaches, revealing its superiority in both panoramic video generation and 4D scene reconstruction. This demonstrates our method’s capability to create more engaging and realistic immersive environments, thereby enhancing user experiences in VR and AR applications. </p>
<blockquote>
<p>扩散模型的快速发展有望彻底改变VR和AR技术的应用，这些技术通常需要场景级的四维资产来提升用户体验。然而，现有的扩散模型主要集中在静态三维场景的建模或对象级别的动态建模上，这限制了它们提供真正沉浸式体验的能力。为了解决这个问题，我们提出了HoloTime框架，它结合了视频扩散模型来生成全景视频，从一个单一的提示或参考图像开始，以及一种360度的四维场景重建方法，它将生成的全景视频无缝地转换为四维资产，为用户提供了完整的沉浸式四维体验。具体来说，为了驾驭视频扩散模型以生成高保真全景视频，我们引入了全景视频数据集——迄今为止最全面的全景视频集之一，这些视频适用于下游四维场景重建任务。有了这个精选的数据集，我们提出了全景动画生成器（Panoramic Animator），这是一个两阶段的图像到视频的扩散模型，可以将全景图像转换为高质量的全景视频。之后，我们提出了全景时空重建技术（Panoramic Space-Time Reconstruction），它利用时空深度估计方法将生成的全景视频转换为四维点云，从而优化整体的四维高斯映射表示法（Gaussian Splatting）来重建时间和空间一致的四维场景。为了验证我们方法的效力，我们与现有方法进行了比较分析，揭示了其在全景视频生成和四维场景重建方面的优势。这表明我们的方法能够创建更加引人入胜和现实主义的沉浸式环境，从而增强VR和AR应用中的用户体验。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21650v2">PDF</a> Project Homepage: <a target="_blank" rel="noopener" href="https://zhouhyocean.github.io/holotime/">https://zhouhyocean.github.io/holotime/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/PKU-YuanGroup/HoloTime">https://github.com/PKU-YuanGroup/HoloTime</a></p>
<p><strong>摘要</strong></p>
<p>扩散模型的快速发展有望彻底改变VR和AR技术的应用，这些技术通常需要场景级的4D资产来提升用户体验。然而，现有的扩散模型主要集中在静态3D场景的建模或对象级的动态建模上，这限制了它们提供真正沉浸式体验的能力。为了解决这个问题，我们提出了HoloTime框架，它集成了视频扩散模型来生成全景视频，从一个单一的提示或参考图像开始，以及一种360度的4D场景重建方法，无缝地将生成的全景视频转化为4D资产，为用户提供全方位的沉浸式体验。具体来说，为了驾驭生成高保真全景视频的视频扩散模型，我们引入了首个全景视频综合数据集——360World数据集，适用于下游的4D场景重建任务。借助这个数据集，我们提出了全景动画师（Panoramic Animator）——一个两阶段的图像到视频的扩散模型，能将全景图像转换为高质量的全景视频。之后我们推出全景时空重建技术（Panoramic Space-Time Reconstruction），它采用时空深度估计方法来生成全景视频转换为空间的点云模型为整个四维场景的构建在时间上都实现了空间和时间的连贯性一致性重建在时空上的连贯性验证。我们的比较分析揭示了其在全景视频生成和场景重建上的优势在展现全息场景中实现的虚拟现实应用大幅增强了用户体验中的吸引力和现实沉浸感证明其出色的用户互动能力和娱乐效果吸引力潜力大潜力巨大。</p>
<p><strong>关键要点</strong></p>
<p>一、扩散模型的快速发展对VR和AR技术革命具有巨大潜力。它们正在推动全景视频和沉浸式体验的进步。然而，现有的扩散模型主要集中在静态场景的建模上，缺乏动态场景建模的能力。</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21650">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-eafde3db9264ac8bfb9d80002c0e9518.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0baf1ba6ea5c06b24daee2b38e068005.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8fe1655f21afe59bf14160f97d1bbee8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f1de9cfc11315e4521be6b0b3b9142e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Motion-Blender-Gaussian-Splatting-for-Dynamic-Scene-Reconstruction"><a href="#Motion-Blender-Gaussian-Splatting-for-Dynamic-Scene-Reconstruction" class="headerlink" title="Motion Blender Gaussian Splatting for Dynamic Scene Reconstruction"></a>Motion Blender Gaussian Splatting for Dynamic Scene Reconstruction</h2><p><strong>Authors:Xinyu Zhang, Haonan Chang, Yuhan Liu, Abdeslam Boularias</strong></p>
<p>Gaussian splatting has emerged as a powerful tool for high-fidelity reconstruction of dynamic scenes. However, existing methods primarily rely on implicit motion representations, such as encoding motions into neural networks or per-Gaussian parameters, which makes it difficult to further manipulate the reconstructed motions. This lack of explicit controllability limits existing methods to replaying recorded motions only, which hinders a wider application in robotics. To address this, we propose Motion Blender Gaussian Splatting (MBGS), a novel framework that uses motion graphs as an explicit and sparse motion representation. The motion of a graph’s links is propagated to individual Gaussians via dual quaternion skinning, with learnable weight painting functions that determine the influence of each link. The motion graphs and 3D Gaussians are jointly optimized from input videos via differentiable rendering. Experiments show that MBGS achieves state-of-the-art performance on the highly challenging iPhone dataset while being competitive on HyperNeRF. We demonstrate the application potential of our method in animating novel object poses, synthesizing real robot demonstrations, and predicting robot actions through visual planning. The source code, models, video demonstrations can be found at <a target="_blank" rel="noopener" href="http://mlzxy.github.io/motion-blender-gs">http://mlzxy.github.io/motion-blender-gs</a>. </p>
<blockquote>
<p>高斯混合法已经成为重建动态场景的高保真工具。然而，现有的方法主要依赖于隐式运动表示，如将运动编码到神经网络或每个高斯参数中，这使得进一步操纵重建运动变得困难。这种缺乏明确的可控性限制了现有方法只能回放记录的运动，阻碍了其在机器人技术中的更广泛应用。为解决这一问题，我们提出了运动混合高斯混合法（MBGS），这是一种使用运动图作为显式且稀疏运动表示的新型框架。图链接的运动通过双四元数蒙皮传播到单个高斯，通过可学习的权重绘制函数来确定每个链接的影响。运动图和三维高斯通过可微分渲染从输入视频联合优化。实验表明，MBGS在极具挑战性的iPhone数据集上达到了最先进的性能，同时在HyperNeRF上表现具有竞争力。我们展示了该方法在动画新物体姿态、合成真实机器人演示以及通过视觉规划预测机器人动作方面的应用潜力。源代码、模型和视频演示可在<a target="_blank" rel="noopener" href="http://mlzxy.github.io/motion-blender-gs%E6%89%BE%E5%88%B0%E3%80%82">http://mlzxy.github.io/motion-blender-gs找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09040v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>高斯贴片技术已成为重建动态场景的高保真工具。然而，现有方法主要依赖于隐式运动表示，如将运动编码到神经网络或每个高斯参数中，这使得难以进一步操作重建的运动。缺乏明确的可控性限制了现有方法仅回放记录的运动，阻碍了其在机器人技术中的更广泛应用。为解决此问题，我们提出使用运动图作为显式且稀疏的运动表示的新框架——Motion Blender Gaussian Splatting (MBGS)。图链接的运动通过双四元数蒙皮传播到各个高斯，通过可学习的权重绘制函数来确定每个链接的影响。运动图和3D高斯通过可微分渲染从输入视频联合优化。实验表明，MBGS在极具挑战性的iPhone数据集上达到了最先进的性能，同时在HyperNeRF上具有很强的竞争力。我们在动画新颖物体姿态、合成真实机器人演示以及通过视觉规划预测机器人动作等方面展示了该方法的潜力。更多详情可访问<a target="_blank" rel="noopener" href="http://mlzxy.github.io/motion-blender-gs%E3%80%82">http://mlzxy.github.io/motion-blender-gs。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>高斯贴片技术已成为重建动态场景的重要工具。</li>
<li>现有方法主要依赖隐式运动表示，存在操作难度和可控性限制。</li>
<li>MBGS框架使用运动图作为显式和稀疏的运动表示来解决这一问题。</li>
<li>运动图链接的运动通过双四元数蒙皮传播到高斯。</li>
<li>MBGS通过可微分渲染联合优化运动图和3D高斯。</li>
<li>MBGS在多个数据集上表现优秀，包括具有挑战性的iPhone数据集和HyperNeRF。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09040">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7374cfc9b75d72a8a973a4834d89e6d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30fe4dd28f7d7bd0bf57e03f0812362e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fda2345d6eb9a53a9f26c8a0b756237a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7d11c4d68e5a1f1f166de7355580bab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b609da3f025571159826c0adde7e717.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83551c60a386e66d3811af47084eaa9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54b18eaf5fbca76dfc090d903ed422f5.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-15/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-15/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-15/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d732cdb9730690481115522e7ce59722.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-05-15  FOCI Trajectory Optimization on Gaussian Splats
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-15/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-be2407db72daf1fc2d8eb946e3104af5.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 方向最新论文已更新，请持续关注 Update in 2025-05-15  Unsupervised Raindrop Removal from a Single Image using Conditional   Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27544.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
