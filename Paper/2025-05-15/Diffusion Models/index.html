<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-15  Boosting Zero-shot Stereo Matching using Large-scale Mixed Images   Sources in the Real World">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-44b8b4993fc331ade1ede53e2e9933eb.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    45 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-15-æ›´æ–°"><a href="#2025-05-15-æ›´æ–°" class="headerlink" title="2025-05-15 æ›´æ–°"></a>2025-05-15 æ›´æ–°</h1><h2 id="Boosting-Zero-shot-Stereo-Matching-using-Large-scale-Mixed-Images-Sources-in-the-Real-World"><a href="#Boosting-Zero-shot-Stereo-Matching-using-Large-scale-Mixed-Images-Sources-in-the-Real-World" class="headerlink" title="Boosting Zero-shot Stereo Matching using Large-scale Mixed Images   Sources in the Real World"></a>Boosting Zero-shot Stereo Matching using Large-scale Mixed Images   Sources in the Real World</h2><p><strong>Authors:Yuran Wang, Yingping Liang, Ying Fu</strong></p>
<p>Stereo matching methods rely on dense pixel-wise ground truth labels, which are laborious to obtain, especially for real-world datasets. The scarcity of labeled data and domain gaps between synthetic and real-world images also pose notable challenges. In this paper, we propose a novel framework, \textbf{BooSTer}, that leverages both vision foundation models and large-scale mixed image sources, including synthetic, real, and single-view images. First, to fully unleash the potential of large-scale single-view images, we design a data generation strategy combining monocular depth estimation and diffusion models to generate dense stereo matching data from single-view images. Second, to tackle sparse labels in real-world datasets, we transfer knowledge from monocular depth estimation models, using pseudo-mono depth labels and a dynamic scale- and shift-invariant loss for additional supervision. Furthermore, we incorporate vision foundation model as an encoder to extract robust and transferable features, boosting accuracy and generalization. Extensive experiments on benchmark datasets demonstrate the effectiveness of our approach, achieving significant improvements in accuracy over existing methods, particularly in scenarios with limited labeled data and domain shifts. </p>
<blockquote>
<p>ç«‹ä½“åŒ¹é…æ–¹æ³•ä¾èµ–äºå¯†é›†åƒç´ çº§çš„çœŸå®æ ‡ç­¾ï¼Œè€Œè¿™äº›æ ‡ç­¾çš„è·å–éå¸¸è€—æ—¶ï¼Œå°¤å…¶æ˜¯å¯¹äºçœŸå®ä¸–ç•Œçš„æ•°æ®é›†ã€‚æ ‡è®°æ•°æ®çš„ç¨€ç¼ºä»¥åŠåˆæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„é¢†åŸŸå·®è·ä¹Ÿæ„æˆäº†æ˜¾è‘—çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåä¸ºâ€œBooSTerâ€ï¼Œå®ƒåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹å’Œå¤§è§„æ¨¡æ··åˆå›¾åƒæºï¼ŒåŒ…æ‹¬åˆæˆå›¾åƒã€çœŸå®å›¾åƒå’Œå•è§†å›¾å›¾åƒã€‚é¦–å…ˆï¼Œä¸ºäº†å……åˆ†å‘æŒ¥å¤§è§„æ¨¡å•è§†å›¾å›¾åƒçš„ä¼˜åŠ¿ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ•°æ®ç”Ÿæˆç­–ç•¥ï¼Œç»“åˆå•ç›®æ·±åº¦ä¼°è®¡å’Œæ‰©æ•£æ¨¡å‹ï¼Œä»å•è§†å›¾å›¾åƒç”Ÿæˆå¯†é›†çš„ç«‹ä½“åŒ¹é…æ•°æ®ã€‚å…¶æ¬¡ï¼Œä¸ºäº†è§£å†³çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸­çš„ç¨€ç–æ ‡ç­¾é—®é¢˜ï¼Œæˆ‘ä»¬ä»å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹ä¸­è½¬ç§»çŸ¥è¯†ï¼Œä½¿ç”¨ä¼ªå•ç›®æ·±åº¦æ ‡ç­¾å’ŒåŠ¨æ€å°ºåº¦åŠå¹³ç§»ä¸å˜æŸå¤±è¿›è¡Œé¢å¤–ç›‘ç£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†è§†è§‰åŸºç¡€æ¨¡å‹ä½œä¸ºç¼–ç å™¨ï¼Œæå–ç¨³å¥å’Œå¯è¿ç§»çš„ç‰¹å¾ï¼Œæé«˜å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å‡†ç¡®ç‡ä¸Šå®ç°äº†å¯¹ç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ ‡è®°æ•°æ®æœ‰é™å’Œé¢†åŸŸåç§»çš„åœºæ™¯ä¸‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08607v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶BooSTerï¼Œå®ƒåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹å’Œå¤§è§„æ¨¡æ··åˆå›¾åƒæºï¼ŒåŒ…æ‹¬åˆæˆå›¾åƒã€çœŸå®å›¾åƒå’Œå•è§†å›¾å›¾åƒã€‚é€šè¿‡ç»“åˆå•ç›®æ·±åº¦ä¼°è®¡å’Œæ‰©æ•£æ¨¡å‹ï¼Œä»å•è§†å›¾å›¾åƒç”Ÿæˆå¯†é›†ç«‹ä½“åŒ¹é…æ•°æ®ï¼Œè§£å†³ç°å®ä¸–ç•Œæ•°æ®é›†æ ‡ç­¾ç¨€å°‘å’Œåˆæˆå›¾åƒä¸çœŸå®å›¾åƒé¢†åŸŸå·®è·çš„é—®é¢˜ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„ä¼ªå•ç›®æ·±åº¦æ ‡ç­¾å’ŒåŠ¨æ€å°ºåº¦ä¸å¹³ç§»ä¸å˜æŸå¤±è¿›è¡Œé¢å¤–ç›‘ç£ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ ‡ç­¾æ•°æ®æœ‰é™å’Œé¢†åŸŸåç§»çš„åœºæ™¯ä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç«‹ä½“åŒ¹é…æ¡†æ¶BooSTerï¼Œç»“åˆäº†è§†è§‰åŸºç¡€æ¨¡å‹ä¸å¤§è§„æ¨¡æ··åˆå›¾åƒæºã€‚</li>
<li>åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡å’Œæ‰©æ•£æ¨¡å‹ä»å•è§†å›¾å›¾åƒç”Ÿæˆå¯†é›†ç«‹ä½“åŒ¹é…æ•°æ®ã€‚</li>
<li>è§£å†³ç°å®ä¸–ç•Œæ•°æ®é›†æ ‡ç­¾ç¨€å°‘å’Œåˆæˆå›¾åƒä¸çœŸå®å›¾åƒé¢†åŸŸå·®è·çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡ä¼ªå•ç›®æ·±åº¦æ ‡ç­¾å’ŒåŠ¨æ€å°ºåº¦ä¸å¹³ç§»ä¸å˜æŸå¤±è¿›è¡Œé¢å¤–ç›‘ç£ã€‚</li>
<li>èåˆè§†è§‰åŸºç¡€æ¨¡å‹ä½œä¸ºç¼–ç å™¨ï¼Œæå–ç¨³å¥ä¸”å¯è¿ç§»çš„ç‰¹å¾ã€‚</li>
<li>åœ¨åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08607">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-44b8b4993fc331ade1ede53e2e9933eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-274f0a560254ca33787df9b83abd25a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98286ed4c64c6d80a59ee9186254ad36.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f5c365ec8789e4df4fc4300d1415ff0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-96171d7b179621d25963eec628974de2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Ultra-Lowrate-Image-Compression-with-Semantic-Residual-Coding-and-Compression-aware-Diffusion"><a href="#Ultra-Lowrate-Image-Compression-with-Semantic-Residual-Coding-and-Compression-aware-Diffusion" class="headerlink" title="Ultra Lowrate Image Compression with Semantic Residual Coding and   Compression-aware Diffusion"></a>Ultra Lowrate Image Compression with Semantic Residual Coding and   Compression-aware Diffusion</h2><p><strong>Authors:Anle Ke, Xu Zhang, Tong Chen, Ming Lu, Chao Zhou, Jiawen Gu, Zhan Ma</strong></p>
<p>Existing multimodal large model-based image compression frameworks often rely on a fragmented integration of semantic retrieval, latent compression, and generative models, resulting in suboptimal performance in both reconstruction fidelity and coding efficiency. To address these challenges, we propose a residual-guided ultra lowrate image compression named ResULIC, which incorporates residual signals into both semantic retrieval and the diffusion-based generation process. Specifically, we introduce Semantic Residual Coding (SRC) to capture the semantic disparity between the original image and its compressed latent representation. A perceptual fidelity optimizer is further applied for superior reconstruction quality. Additionally, we present the Compression-aware Diffusion Model (CDM), which establishes an optimal alignment between bitrates and diffusion time steps, improving compression-reconstruction synergy. Extensive experiments demonstrate the effectiveness of ResULIC, achieving superior objective and subjective performance compared to state-of-the-art diffusion-based methods with - 80.7%, -66.3% BD-rate saving in terms of LPIPS and FID. Project page is available at https: &#x2F;&#x2F;njuvision.github.io&#x2F;ResULIC&#x2F;. </p>
<blockquote>
<p>ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹æ¨¡å‹å›¾åƒå‹ç¼©æ¡†æ¶é€šå¸¸ä¾èµ–äºè¯­ä¹‰æ£€ç´¢ã€æ½œåœ¨å‹ç¼©å’Œç”Ÿæˆæ¨¡å‹çš„ç‰‡æ®µåŒ–é›†æˆï¼Œå¯¼è‡´åœ¨é‡å»ºä¿çœŸåº¦å’Œç¼–ç æ•ˆç‡æ–¹é¢çš„æ€§èƒ½ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºResULICçš„æ®‹å·®å¼•å¯¼è¶…ä½é¢‘å›¾åƒå‹ç¼©æ–¹æ³•ï¼Œå®ƒå°†æ®‹å·®ä¿¡å·èå…¥è¯­ä¹‰æ£€ç´¢å’ŒåŸºäºæ‰©æ•£çš„ç”Ÿæˆè¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­ä¹‰æ®‹å·®ç¼–ç ï¼ˆSRCï¼‰ï¼Œä»¥æ•è·åŸå§‹å›¾åƒä¸å…¶å‹ç¼©æ½œåœ¨è¡¨ç¤ºä¹‹é—´çš„è¯­ä¹‰å·®å¼‚ã€‚è¿›ä¸€æ­¥åº”ç”¨äº†æ„ŸçŸ¥ä¿çœŸåº¦ä¼˜åŒ–å™¨ï¼Œä»¥è·å¾—æ›´ä¼˜çš„é‡å»ºè´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ„ŸçŸ¥å‹ç¼©æ‰©æ•£æ¨¡å‹ï¼ˆCDMï¼‰ï¼Œå»ºç«‹äº†æ¯”ç‰¹ç‡ä¸æ‰©æ•£æ—¶é—´æ­¥éª¤ä¹‹é—´çš„æœ€ä½³å¯¹é½ï¼Œæé«˜äº†å‹ç¼©ä¸é‡å»ºçš„ååŒä½œç”¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒResULICçš„æœ‰æ•ˆæ€§ï¼Œä¸æœ€å…ˆè¿›çš„æ‰©æ•£æ–¹æ³•ç›¸æ¯”ï¼Œå…¶åœ¨LPIPSå’ŒFIDæ–¹é¢å®ç°äº†-80.7%ã€-66.3%çš„BD-rateèŠ‚çœã€‚é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://njuvision.github.io/ResULIC/%E6%89%BE%E5%88%B0%E3%80%82">https://njuvision.github.io/ResULIC/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08281v1">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€å¤§å‹æ¨¡å‹å›¾åƒå‹ç¼©æ¡†æ¶åœ¨é‡å»ºä¿çœŸåº¦å’Œç¼–ç æ•ˆç‡æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†åŸºäºæ®‹å·®å¼•å¯¼çš„è¶…ä½ç ç‡å›¾åƒå‹ç¼©æ–¹æ³•ResULICã€‚è¯¥æ–¹æ³•ç»“åˆè¯­ä¹‰æ£€ç´¢å’Œæ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ï¼Œå¼•å…¥è¯­ä¹‰æ®‹å·®ç¼–ç ï¼ˆSRCï¼‰æ•æ‰åŸå§‹å›¾åƒä¸å…¶å‹ç¼©æ½œåœ¨è¡¨ç¤ºä¹‹é—´çš„è¯­ä¹‰å·®å¼‚ï¼Œå¹¶åº”ç”¨æ„ŸçŸ¥ä¿çœŸåº¦ä¼˜åŒ–å™¨ä»¥æé«˜é‡å»ºè´¨é‡ã€‚åŒæ—¶ï¼Œæå‡ºäº†é¢å‘å‹ç¼©çš„æ‰©æ•£æ¨¡å‹ï¼ˆCDMï¼‰ï¼Œä¼˜åŒ–äº†æ¯”ç‰¹ç‡å’Œæ‰©æ•£æ—¶é—´æ­¥ä¹‹é—´çš„å¯¹é½ï¼Œæé«˜äº†å‹ç¼©ä¸é‡å»ºçš„ååŒä½œç”¨ã€‚å®éªŒè¯æ˜ï¼ŒResULICåœ¨å®¢è§‚å’Œä¸»è§‚æ€§èƒ½ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨LPIPSå’ŒFIDæŒ‡æ ‡ä¸Šåˆ†åˆ«èŠ‚çœäº†-80.7%å’Œ-66.3%çš„æ¯”ç‰¹ç‡ã€‚é¡¹ç›®é¡µé¢å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://njuvision.github.io/ResULIC/">https://njuvision.github.io/ResULIC/</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰å›¾åƒå‹ç¼©æ¡†æ¶å­˜åœ¨é‡å»ºä¿çœŸåº¦å’Œç¼–ç æ•ˆç‡æ–¹é¢çš„æŒ‘æˆ˜ã€‚</li>
<li>ResULICæ–¹æ³•ç»“åˆäº†è¯­ä¹‰æ£€ç´¢å’Œæ‰©æ•£ç”Ÿæˆè¿‡ç¨‹ï¼Œæé«˜äº†å›¾åƒå‹ç¼©æ€§èƒ½ã€‚</li>
<li>è¯­ä¹‰æ®‹å·®ç¼–ç ï¼ˆSRCï¼‰ç”¨äºæ•æ‰åŸå§‹å›¾åƒä¸å‹ç¼©æ½œåœ¨è¡¨ç¤ºä¹‹é—´çš„è¯­ä¹‰å·®å¼‚ã€‚</li>
<li>æ„ŸçŸ¥ä¿çœŸåº¦ä¼˜åŒ–å™¨ç”¨äºæé«˜é‡å»ºè´¨é‡ã€‚</li>
<li>é¢å‘å‹ç¼©çš„æ‰©æ•£æ¨¡å‹ï¼ˆCDMï¼‰ä¼˜åŒ–äº†æ¯”ç‰¹ç‡å’Œæ‰©æ•£æ—¶é—´æ­¥ä¹‹é—´çš„å¯¹é½ã€‚</li>
<li>ResULICåœ¨LPIPSå’ŒFIDæŒ‡æ ‡ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸æ¯”å…ˆè¿›æ–¹æ³•åˆ†åˆ«èŠ‚çœäº†-80.7%å’Œ-66.3%çš„æ¯”ç‰¹ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08281">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ed50d764e05836b72170b1ff000e440f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6e1192e84a34a3738b0ccd541d4ae6f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-38cb7745803d256e85e58a2d2385d8ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1b89993c184444ed0bef6bfe4f8e372.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-279fd25a20599aa6a1994dfaad10fc67.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d24855bf5a5b30e1cbf4cb9f86efe32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04acea63eba7592e6dfad6a66b4e13db.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Skeleton-Guided-Diffusion-Model-for-Accurate-Foot-X-ray-Synthesis-in-Hallux-Valgus-Diagnosis"><a href="#Skeleton-Guided-Diffusion-Model-for-Accurate-Foot-X-ray-Synthesis-in-Hallux-Valgus-Diagnosis" class="headerlink" title="Skeleton-Guided Diffusion Model for Accurate Foot X-ray Synthesis in   Hallux Valgus Diagnosis"></a>Skeleton-Guided Diffusion Model for Accurate Foot X-ray Synthesis in   Hallux Valgus Diagnosis</h2><p><strong>Authors:Midi Wan, Pengfei Li, Yizhuo Liang, Di Wu, Yushan Pan, Guangzhen Zhu, Hao Wang</strong></p>
<p>Medical image synthesis plays a crucial role in providing anatomically accurate images for diagnosis and treatment. Hallux valgus, which affects approximately 19% of the global population, requires frequent weight-bearing X-rays for assessment, placing additional strain on both patients and healthcare providers. Existing X-ray models often struggle to balance image fidelity, skeletal consistency, and physical constraints, particularly in diffusion-based methods that lack skeletal guidance. We propose the Skeletal-Constrained Conditional Diffusion Model (SCCDM) and introduce KCC, a foot evaluation method utilizing skeletal landmarks. SCCDM incorporates multi-scale feature extraction and attention mechanisms, improving the Structural Similarity Index (SSIM) by 5.72% (0.794) and Peak Signal-to-Noise Ratio (PSNR) by 18.34% (21.40 dB). When combined with KCC, the model achieves an average score of 0.85, demonstrating strong clinical applicability. The code is available at <a target="_blank" rel="noopener" href="https://github.com/midisec/SCCDM">https://github.com/midisec/SCCDM</a>. </p>
<blockquote>
<p>åŒ»å­¦å½±åƒåˆæˆåœ¨æä¾›ç”¨äºè¯Šæ–­å’Œæ²»ç–—è§£å‰–å‡†ç¡®çš„å›¾åƒæ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æ‹‡è¶¾å¤–ç¿»å½±å“å…¨çƒçº¦19%çš„äººå£ï¼Œéœ€è¦è¿›è¡Œé¢‘ç¹çš„è´Ÿé‡Xå°„çº¿æ£€æŸ¥è¿›è¡Œè¯„ä¼°ï¼Œè¿™ç»™ç—…äººå’ŒåŒ»ç–—æœåŠ¡æä¾›è€…éƒ½å¸¦æ¥äº†é¢å¤–çš„å‹åŠ›ã€‚ç°æœ‰çš„Xå°„çº¿æ¨¡å‹å¾€å¾€éš¾ä»¥åœ¨å›¾åƒä¿çœŸåº¦ã€éª¨éª¼ä¸€è‡´æ€§å’Œç‰©ç†çº¦æŸä¹‹é—´å–å¾—å¹³è¡¡ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¼ºä¹éª¨éª¼æŒ‡å¯¼çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•ä¸­æ›´æ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬æå‡ºäº†éª¨éª¼çº¦æŸæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆSCCDMï¼‰ï¼Œå¹¶å¼•å…¥äº†KCCï¼Œä¸€ç§åˆ©ç”¨éª¨éª¼åœ°æ ‡è¿›è¡Œè¶³éƒ¨è¯„ä¼°çš„æ–¹æ³•ã€‚SCCDMç»“åˆäº†å¤šå°ºåº¦ç‰¹å¾æå–å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œæé«˜äº†ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰5.72%ï¼ˆ0.794ï¼‰ï¼Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æé«˜18.34%ï¼ˆ21.40åˆ†è´ï¼‰ã€‚ä¸KCCç»“åˆä½¿ç”¨æ—¶ï¼Œè¯¥æ¨¡å‹çš„å¹³å‡å¾—åˆ†ä¸º0.85ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„ä¸´åºŠé€‚ç”¨æ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/midisec/SCCDM%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/midisec/SCCDMæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08247v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŒ»å­¦å›¾åƒåˆæˆåœ¨è¯Šæ–­ä¸æ²»ç–—ä¸­çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆè§£å‰–ç»“æ„å‡†ç¡®çš„å›¾åƒæ–¹é¢çš„åº”ç”¨ã€‚é’ˆå¯¹è¶³éª¨ç—…å˜å¦‚æ‹‡å¤–ç¿»ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†éª¨éª¼çº¦æŸæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆSCCDMï¼‰ï¼Œå¹¶å¼•å…¥äº†åˆ©ç”¨éª¨éª¼åœ°æ ‡çš„è¶³éƒ¨è¯„ä¼°æ–¹æ³•KCCã€‚SCCDMé€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–å’Œæ³¨æ„åŠ›æœºåˆ¶æ”¹å–„äº†å›¾åƒçš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ï¼Œæé«˜äº†åŒ»å­¦å›¾åƒçš„ç”Ÿæˆè´¨é‡ã€‚ç»“åˆKCCæ–¹æ³•ï¼Œæ¨¡å‹çš„ä¸´åºŠé€‚ç”¨æ€§å¾—åˆ°æ˜¾è‘—å¢å¼ºï¼Œå¹³å‡å¾—åˆ†è¾¾åˆ°0.85ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€äºGitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆæˆåœ¨è¯Šæ–­ä¸æ²»ç–—ä¸­å…·æœ‰é‡è¦ä½œç”¨ï¼Œéœ€ç”Ÿæˆè§£å‰–ç»“æ„å‡†ç¡®çš„å›¾åƒã€‚</li>
<li>æ‹‡å¤–ç¿»æ˜¯ä¸€ç§å¸¸è§çš„è¶³éª¨ç—…å˜ï¼Œéœ€è¦é¢‘ç¹è¿›è¡Œè´Ÿé‡Xå°„çº¿æ£€æŸ¥ï¼Œå¯¹ç—…äººå’ŒåŒ»ç–—æä¾›è€…é€ æˆé¢å¤–è´Ÿæ‹…ã€‚</li>
<li>ç°æœ‰Xå°„çº¿æ¨¡å‹åœ¨å¹³è¡¡å›¾åƒä¿çœŸåº¦ã€éª¨éª¼ä¸€è‡´æ€§å’Œç‰©ç†çº¦æŸæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨åŸºäºæ‰©æ•£çš„æ–¹æ³•ä¸­ç¼ºä¹éª¨éª¼æŒ‡å¯¼ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæå‡ºäº†éª¨éª¼çº¦æŸæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆSCCDMï¼‰ï¼Œè¯¥æ¨¡å‹é€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–å’Œæ³¨æ„åŠ›æœºåˆ¶æé«˜äº†ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚</li>
<li>SCCDMä¸è¶³éƒ¨è¯„ä¼°æ–¹æ³•KCCç»“åˆä½¿ç”¨ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„ä¸´åºŠé€‚ç”¨æ€§ã€‚</li>
<li>æ¨¡å‹å¹³å‡å¾—åˆ†è¾¾åˆ°0.85ï¼Œè¡¨æ˜å…¶å¼ºå¤§çš„ä¸´åºŠå®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08247">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-fa628ffd908654f6b3abcbc00580857f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-68d4c8f9542aaf67cfd32cc5d7b9fc75.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-00f2a6685402e1d840976b04fbb02756.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-261b4361989aa5c5a81211a63f83bd6f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EventDiff-A-Unified-and-Efficient-Diffusion-Model-Framework-for-Event-based-Video-Frame-Interpolation"><a href="#EventDiff-A-Unified-and-Efficient-Diffusion-Model-Framework-for-Event-based-Video-Frame-Interpolation" class="headerlink" title="EventDiff: A Unified and Efficient Diffusion Model Framework for   Event-based Video Frame Interpolation"></a>EventDiff: A Unified and Efficient Diffusion Model Framework for   Event-based Video Frame Interpolation</h2><p><strong>Authors:Hanle Zheng, Xujie Han, Zegang Peng, Shangbin Zhang, Guangxun Du, Zhuo Zou, Xilin Wang, Jibin Wu, Hao Guo, Lei Deng</strong></p>
<p>Video Frame Interpolation (VFI) is a fundamental yet challenging task in computer vision, particularly under conditions involving large motion, occlusion, and lighting variation. Recent advancements in event cameras have opened up new opportunities for addressing these challenges. While existing event-based VFI methods have succeeded in recovering large and complex motions by leveraging handcrafted intermediate representations such as optical flow, these designs often compromise high-fidelity image reconstruction under subtle motion scenarios due to their reliance on explicit motion modeling. Meanwhile, diffusion models provide a promising alternative for VFI by reconstructing frames through a denoising process, eliminating the need for explicit motion estimation or warping operations. In this work, we propose EventDiff, a unified and efficient event-based diffusion model framework for VFI. EventDiff features a novel Event-Frame Hybrid AutoEncoder (HAE) equipped with a lightweight Spatial-Temporal Cross Attention (STCA) module that effectively fuses dynamic event streams with static frames. Unlike previous event-based VFI methods, EventDiff performs interpolation directly in the latent space via a denoising diffusion process, making it more robust across diverse and challenging VFI scenarios. Through a two-stage training strategy that first pretrains the HAE and then jointly optimizes it with the diffusion model, our method achieves state-of-the-art performance across multiple synthetic and real-world event VFI datasets. The proposed method outperforms existing state-of-the-art event-based VFI methods by up to 1.98dB in PSNR on Vimeo90K-Triplet and shows superior performance in SNU-FILM tasks with multiple difficulty levels. Compared to the emerging diffusion-based VFI approach, our method achieves up to 5.72dB PSNR gain on Vimeo90K-Triplet and 4.24X faster inference. </p>
<blockquote>
<p>è§†é¢‘å¸§æ’å€¼ï¼ˆVFIï¼‰æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€é¡¹åŸºæœ¬ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤§è¿åŠ¨ã€é®æŒ¡å’Œå…‰ç…§å˜åŒ–çš„æƒ…å†µä¸‹ã€‚äº‹ä»¶ç›¸æœºçš„æœ€æ–°è¿›å±•ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜æä¾›äº†æ–°çš„æœºä¼šã€‚è™½ç„¶ç°æœ‰çš„åŸºäºäº‹ä»¶é©±åŠ¨çš„VFIæ–¹æ³•å·²ç»æˆåŠŸåˆ©ç”¨æ‰‹å·¥è®¾è®¡çš„ä¸­é—´è¡¨ç¤ºï¼ˆå¦‚å…‰æµï¼‰æ¢å¤äº†å¤æ‚çš„å¤§è¿åŠ¨ï¼Œä½†è¿™äº›è®¾è®¡åœ¨ç»†å¾®è¿åŠ¨åœºæ™¯ä¸‹å¾€å¾€ç‰ºç‰²äº†é«˜ä¿çœŸå›¾åƒé‡å»ºï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–äºæ˜¾å¼è¿åŠ¨å»ºæ¨¡ã€‚åŒæ—¶ï¼Œæ‰©æ•£æ¨¡å‹é€šè¿‡å»å™ªè¿‡ç¨‹é‡å»ºå¸§ä¸ºVFIæä¾›äº†æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ— éœ€æ˜¾å¼è¿åŠ¨ä¼°è®¡æˆ–æ‰­æ›²æ“ä½œã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºäº‹ä»¶çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶EventDiffï¼Œç”¨äºVFIã€‚EventDiffå…·æœ‰æ–°é¢–çš„äº‹ä»¶å¸§æ··åˆè‡ªåŠ¨ç¼–ç å™¨ï¼ˆHAEï¼‰ï¼Œé…å¤‡è½»é‡çº§æ—¶ç©ºäº¤å‰æ³¨æ„åŠ›ï¼ˆSTCAï¼‰æ¨¡å—ï¼Œå¯æœ‰æ•ˆèåˆåŠ¨æ€äº‹ä»¶æµå’Œé™æ€å¸§ã€‚ä¸ä»¥å‰çš„åŸºäºäº‹ä»¶çš„VFIæ–¹æ³•ä¸åŒï¼ŒEventDiffé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œå»å™ªæ‰©æ•£è¿‡ç¨‹ç›´æ¥æ‰§è¡Œæ’å€¼ï¼Œä½¿å…¶åœ¨å¤šæ ·ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„VFIåœºæ™¯ä¸­æ›´åŠ ç¨³å¥ã€‚é€šè¿‡é¦–å…ˆé¢„è®­ç»ƒHAEï¼Œç„¶åä¸å…¶æ‰©æ•£æ¨¡å‹è”åˆä¼˜åŒ–çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªåˆæˆå’Œç°å®ä¸–ç•Œçš„äº‹ä»¶VFIæ•°æ®é›†ä¸Šå®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨Vimeo90K-Tripletä¸Šçš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ¯”ç°æœ‰çš„åŸºäºäº‹ä»¶çš„VFIæ–¹æ³•é«˜å‡º1.98dBï¼Œå¹¶ä¸”åœ¨å…·æœ‰ä¸åŒéš¾åº¦çš„SNU-FILMä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ä¸æ–°å…´çš„åŸºäºæ‰©æ•£çš„VFIæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Vimeo90K-Tripletä¸Šå®ç°äº†é«˜è¾¾5.72dBçš„PSNRå¢ç›Šï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†4.24å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08235v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è§†é¢‘å¸§æ’å€¼ï¼ˆVFIï¼‰æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€é¡¹åŸºæœ¬ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤§åŠ¨ä½œã€é®æŒ¡å’Œå…‰ç…§å˜åŒ–çš„æ¡ä»¶ä¸‹ã€‚åŸºäºäº‹ä»¶ç›¸æœºçš„æœ€æ–°è¿›å±•ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜æä¾›äº†æ–°çš„æœºé‡ã€‚ç°æœ‰çš„åŸºäºäº‹ä»¶VFIæ–¹æ³•é€šè¿‡åˆ©ç”¨æ‰‹å·¥åˆ¶ä½œçš„ä¸­ä»‹è¡¨ç¤ºï¼ˆå¦‚å…‰æµï¼‰æ¥æ¢å¤å¤§å‹å¤æ‚è¿åŠ¨å–å¾—äº†æˆåŠŸï¼Œä½†ç”±äºå¯¹æ˜¾å¼è¿åŠ¨å»ºæ¨¡çš„ä¾èµ–ï¼Œè¿™äº›æ–¹æ³•åœ¨è½»å¾®è¿åŠ¨åœºæ™¯ä¸‹å¾€å¾€éš¾ä»¥å®ç°é«˜ä¿çœŸå›¾åƒé‡å»ºã€‚æ‰©æ•£æ¨¡å‹ä¸ºVFIæä¾›äº†ä¸€ä¸ªæœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡å»å™ªè¿‡ç¨‹é‡å»ºæ¡†æ¶ï¼Œæ— éœ€æ˜¾å¼è¿åŠ¨ä¼°è®¡æˆ–å¼¯æ›²æ“ä½œã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºäº‹ä»¶çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶EventDiffï¼Œç”¨äºVFIã€‚EventDiffå…·æœ‰é…å¤‡è½»é‡çº§æ—¶ç©ºäº¤å‰æ³¨æ„ï¼ˆSTCAï¼‰æ¨¡å—çš„äº‹ä»¶æ¡†æ¶æ··åˆè‡ªåŠ¨ç¼–ç å™¨ï¼ˆHAEï¼‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆåŠ¨æ€äº‹ä»¶æµå’Œé™æ€æ¡†æ¶ã€‚ä¸åŒäºä»¥å‰çš„åŸºäºäº‹ä»¶çš„VFIæ–¹æ³•ï¼ŒEventDiffé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œå»å™ªæ‰©æ•£è¿‡ç¨‹ç›´æ¥æ‰§è¡Œæ’å€¼ï¼Œä½¿å…¶åœ¨ä¸åŒå¤šæ ·åŒ–å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„VFIåœºæ™¯ä¸­æ›´åŠ ç¨³å¥ã€‚é€šè¿‡é¦–å…ˆé¢„è®­ç»ƒHAEï¼Œç„¶åä¸å…¶æ‰©æ•£æ¨¡å‹è”åˆä¼˜åŒ–çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªåˆæˆå’ŒçœŸå®ä¸–ç•Œäº‹ä»¶VFIæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸ç°æœ‰çš„åŸºäºäº‹ä»¶çš„VFIæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Vimeo90K-Tripletä¸Šçš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æé«˜äº†é«˜è¾¾1.98dBï¼Œå¹¶ä¸”åœ¨å…·æœ‰å¤šä¸ªéš¾åº¦çº§åˆ«çš„SNU-FILMä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ä¸æ–°å…´çš„åŸºäºæ‰©æ•£çš„VFIæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Vimeo90K-Tripletä¸Šçš„PSNRæé«˜äº†é«˜è¾¾5.72dBï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†4.24å€ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>è§†é¢‘å¸§æ’å€¼ï¼ˆVFIï¼‰æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå°¤å…¶åœ¨å¤„ç†å¤§åŠ¨ä½œã€é®æŒ¡å’Œå…‰ç…§å˜åŒ–æ—¶ã€‚</li>
<li>åŸºäºäº‹ä»¶ç›¸æœºçš„æ–°æŠ€æœ¯ä¸ºVFIå¸¦æ¥äº†æ–°æœºé‡ã€‚</li>
<li>ç°æœ‰åŸºäºäº‹ä»¶çš„VFIæ–¹æ³•è™½ç„¶èƒ½æˆåŠŸæ¢å¤å¤§å‹å¤æ‚è¿åŠ¨ï¼Œä½†åœ¨è½»å¾®è¿åŠ¨åœºæ™¯ä¸‹å›¾åƒé‡å»ºçš„ä¿çœŸåº¦å—é™ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹æä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ³•ï¼Œé€šè¿‡å»å™ªè¿‡ç¨‹é‡å»ºæ¡†æ¶ï¼Œæ— éœ€æ˜¾å¼è¿åŠ¨ä¼°è®¡ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„EventDiffæ¡†æ¶ç»“åˆäº†äº‹ä»¶å’Œæ¡†æ¶ä¿¡æ¯ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å®ç°VFIã€‚</li>
<li>EventDiffé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°å…ˆè¿›æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08235">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7f6282d30bdba5df60d4bdb664f8c90d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-947a8d18dceabff7cf49a4e21ed9a7e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2b830bd0a6cfebe68ea3132abb2b9fb0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9123eb7d17a9edc71f0644f05bb016f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-986e0875fc30a20aaf1fe57a2d1500ca.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Removing-Watermarks-with-Partial-Regeneration-using-Semantic-Information"><a href="#Removing-Watermarks-with-Partial-Regeneration-using-Semantic-Information" class="headerlink" title="Removing Watermarks with Partial Regeneration using Semantic Information"></a>Removing Watermarks with Partial Regeneration using Semantic Information</h2><p><strong>Authors:Krti Tallam, John Kevin Cava, Caleb Geniesse, N. Benjamin Erichson, Michael W. Mahoney</strong></p>
<p>As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged as a primary line of defense for copyright and provenance. The newest watermarking schemes embed semantic signals - content-aware patterns that are designed to survive common image manipulations - yet their true robustness against adaptive adversaries remains under-explored. We expose a previously unreported vulnerability and introduce SemanticRegen, a three-stage, label-free attack that erases state-of-the-art semantic and invisible watermarks while leaving an imageâ€™s apparent meaning intact. Our pipeline (i) uses a vision-language model to obtain fine-grained captions, (ii) extracts foreground masks with zero-shot segmentation, and (iii) inpaints only the background via an LLM-guided diffusion model, thereby preserving salient objects and style cues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing, StegaStamp, StableSig, and DWT&#x2F;DCT - SemanticRegen is the only method to defeat the semantic TreeRing watermark (p &#x3D; 0.10 &gt; 0.05) and reduces bit-accuracy below 0.75 for the remaining schemes, all while maintaining high perceptual quality (masked SSIM &#x3D; 0.94 +&#x2F;- 0.01). We further introduce masked SSIM (mSSIM) to quantify fidelity within foreground regions, showing that our attack achieves up to 12 percent higher mSSIM than prior diffusion-based attackers. These results highlight an urgent gap between current watermark defenses and the capabilities of adaptive, semantics-aware adversaries, underscoring the need for watermarking algorithms that are resilient to content-preserving regenerative attacks. </p>
<blockquote>
<p>éšç€äººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒè¶Šæ¥è¶Šæ™®éï¼Œéšå½¢æ°´å°ä½œä¸ºç‰ˆæƒå’Œæ¥æºçš„ä¸»è¦é˜²çº¿å·²ç»å‡ºç°ã€‚æœ€æ–°çš„æ°´å°æŠ€æœ¯åµŒå…¥è¯­ä¹‰ä¿¡å·â€”â€”å†…å®¹æ„ŸçŸ¥æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼è¢«è®¾è®¡æˆèƒ½å¤ŸæŠµå¾¡å¸¸è§çš„å›¾åƒæ“ä½œâ€”â€”ç„¶è€Œï¼Œå®ƒä»¬å¯¹è‡ªé€‚åº”å¯¹æ‰‹çš„çœŸæ­£ç¨³å¥æ€§ä»ç„¶å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æˆ‘ä»¬æ­éœ²äº†ä¸€ä¸ªä»¥å‰æœªæŠ¥é“çš„æ¼æ´ï¼Œå¹¶ä»‹ç»äº†SemanticRegenï¼Œè¿™æ˜¯ä¸€ç§ä¸‰é˜¶æ®µçš„æ— æ ‡ç­¾æ”»å‡»ï¼Œå¯ä»¥æ¶ˆé™¤æœ€å…ˆè¿›è¯­ä¹‰å’Œéšå½¢æ°´å°ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„è¡¨é¢æ„ä¹‰å®Œæ•´ã€‚æˆ‘ä»¬çš„ç®¡é“ï¼ˆiï¼‰ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹æ¥è·å¾—ç²¾ç»†çš„æ ‡é¢˜ï¼Œï¼ˆiiï¼‰ä½¿ç”¨é›¶æ ·æœ¬åˆ†å‰²æå–å‰æ™¯æ©ç ï¼Œï¼ˆiiiï¼‰ä»…é€šè¿‡LLMå¼•å¯¼æ‰©æ•£æ¨¡å‹è¿›è¡ŒèƒŒæ™¯å¡«å……ï¼Œä»è€Œä¿ç•™æ˜¾è‘—ç‰©ä½“å’Œé£æ ¼çº¿ç´¢ã€‚åœ¨é’ˆå¯¹å››ç§æ°´å°ç³»ç»Ÿçš„1000ä¸ªæç¤ºä¸‹è¿›è¡Œè¯„ä¼°â€”â€”TreeRingã€StegaStampã€StableSigå’ŒDWT&#x2F;DCTâ€”â€”SemanticRegenæ˜¯å”¯ä¸€ä¸€ç§èƒ½å¤Ÿå‡»è´¥è¯­ä¹‰TreeRingæ°´å°çš„æ–¹æ³•ï¼ˆp&#x3D;0.10&gt;0.05ï¼‰ï¼Œå¹¶ä¸”å¯¹å…¶ä»–æ–¹æ¡ˆçš„æ¯”ç‰¹å‡†ç¡®åº¦é™è‡³ä½äº0.75ï¼ŒåŒæ—¶ä¿æŒé«˜æ„ŸçŸ¥è´¨é‡ï¼ˆmasked SSIM&#x3D;0.94+&#x2F;-0.01ï¼‰ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†masked SSIMï¼ˆmSSIMï¼‰æ¥é‡åŒ–å‰æ™¯åŒºåŸŸçš„ä¿çœŸåº¦ï¼Œæ˜¾ç¤ºæˆ‘ä»¬çš„æ”»å‡»åœ¨mSSIMæ–¹é¢æ¯”å…ˆå‰çš„åŸºäºæ‰©æ•£çš„æ”»å‡»é«˜å‡ºé«˜è¾¾12%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†å½“å‰æ°´å°é˜²å¾¡ä¸è‡ªé€‚åº”ã€è¯­ä¹‰æ„ŸçŸ¥å¯¹æ‰‹çš„èƒ½åŠ›ä¹‹é—´å­˜åœ¨çš„ç´§è¿«å·®è·ï¼Œå¼ºè°ƒäº†éœ€è¦èƒ½å¤ŸæŠµå¾¡å†…å®¹ä¿ç•™å†ç”Ÿæ”»å‡»çš„æ°´å°ç®—æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08234v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>éšç€AIç”Ÿæˆçš„å›¾åƒè¶Šæ¥è¶Šæ™®éï¼Œéšå½¢æ°´å°ä½œä¸ºç‰ˆæƒå’Œæ¥æºè¯æ˜çš„ä¸»è¦é˜²çº¿å·²ç»å‡ºç°ã€‚æœ€æ–°çš„æ°´å°æŠ€æœ¯åµŒå…¥è¯­ä¹‰ä¿¡å·ï¼Œè¿™äº›ä¿¡å·è®¾è®¡çš„ç›®çš„æ˜¯èƒ½å¤Ÿåœ¨å¸¸è§çš„å›¾åƒæ“ä½œä¸‹å­˜æ´»ä¸‹æ¥ï¼Œä½†å®ƒä»¬å¯¹æŠ—é€‚åº”æ€§å¯¹æ‰‹çš„çœŸå®ç¨³å¥æ€§ä»å¾…æ¢ç´¢ã€‚æœ¬ç ”ç©¶æ­ç¤ºäº†ä¸€ä¸ªä»¥å‰æœªæŠ¥é“çš„æ¼æ´ï¼Œå¹¶ä»‹ç»äº†SemanticRegenï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€æ ‡ç­¾çš„ä¸‰é˜¶æ®µæ”»å‡»æ–¹æ³•ï¼Œå¯ä»¥æŠ¹å»æœ€å…ˆè¿›çš„è¯­ä¹‰å’Œéšå½¢æ°´å°ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„è¡¨é¢æ„ä¹‰å®Œæ•´ã€‚æˆ‘ä»¬çš„ç®¡é“é€šè¿‡ï¼ˆiï¼‰ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è·å–ç²¾ç»†çš„æ ‡é¢˜ï¼Œï¼ˆiiï¼‰ä½¿ç”¨é›¶å°„å‡»åˆ†å‰²æå–å‰æ™¯æ©è†œï¼Œï¼ˆiiiï¼‰é€šè¿‡LLMå¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ä»…ä¿®å¤èƒŒæ™¯ï¼Œä»è€Œä¿ç•™äº†æ˜¾è‘—ç‰©ä½“å’Œé£æ ¼çº¿ç´¢ã€‚åœ¨TreeRingã€StegaStampã€StableSigå’ŒDWT&#x2F;DCTå››ç§æ°´å°ç³»ç»Ÿçš„1000ä¸ªæç¤ºä¸‹è¿›è¡Œè¯„ä¼°ï¼ŒSemanticRegenæ˜¯å”¯ä¸€èƒ½å¤Ÿå‡»è´¥è¯­ä¹‰TreeRingæ°´å°çš„æ–¹æ³•ï¼ˆp&#x3D;0.10&gt;0.05ï¼‰ï¼Œå¹¶ä¸”å…¶ä½™æ–¹æ¡ˆçš„ä½ç²¾åº¦å‡ä½äº0.75ï¼ŒåŒæ—¶ä¿æŒé«˜æ„ŸçŸ¥è´¨é‡ï¼ˆæ©è”½SSIM&#x3D;0.94Â±0.01ï¼‰ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†æ©è”½SSIMï¼ˆmSSIMï¼‰æ¥è¡¡é‡å‰æ™¯åŒºåŸŸå†…çš„ä¿çœŸåº¦ï¼Œæ˜¾ç¤ºæˆ‘ä»¬çš„æ”»å‡»æ–¹æ³•çš„mSSIMé«˜äºå…ˆå‰çš„æ‰©æ•£æ”»å‡»æ–¹æ³•é«˜è¾¾12%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†å½“å‰æ°´å°é˜²å¾¡ä¸é€‚åº”æ€§è¯­ä¹‰æ„ŸçŸ¥å¯¹æ‰‹çš„èƒ½åŠ›ä¹‹é—´çš„ç´§è¿«å·®è·ï¼Œå¼ºè°ƒäº†éœ€è¦èƒ½å¤ŸæŠµå¾¡å†…å®¹ä¿å­˜å†ç”Ÿæ”»å‡»çš„æ°´å°ç®—æ³•ã€‚</p>
<p><strong>å…³é”®å‘ç°</strong></p>
<ol>
<li>éšå½¢æ°´å°æˆä¸ºAIç”Ÿæˆå›¾åƒç‰ˆæƒä¿æŠ¤çš„ä¸»è¦æ‰‹æ®µã€‚</li>
<li>æœ€æ–°çš„æ°´å°æŠ€æœ¯åµŒå…¥è¯­ä¹‰ä¿¡å·ä»¥æé«˜ç¨³å¥æ€§ã€‚</li>
<li>æ­ç¤ºäº†ä¸€ç§æ–°çš„é’ˆå¯¹æ°´å°çš„æ”»å‡»æ–¹æ³•â€”â€”SemanticRegenï¼Œèƒ½å¤ŸæŠ¹å»æ°´å°åŒæ—¶ä¿æŒå›¾åƒæ„ä¹‰å®Œæ•´ã€‚</li>
<li>SemanticRegené€šè¿‡ç²¾ç»†çš„æ ‡é¢˜ã€å‰æ™¯æ©è†œæå–å’ŒèƒŒæ™¯ä¿®å¤æ¥å®æ–½æ”»å‡»ã€‚</li>
<li>SemanticRegenåœ¨å¤šç§æ°´å°ç³»ç»Ÿä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹TreeRingæ°´å°ã€‚</li>
<li>å¼•å…¥æ–°çš„è¯„ä¼°æŒ‡æ ‡mSSIMæ¥è¡¡é‡æ”»å‡»ä¸­çš„å›¾åƒä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08234">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-21531edabc8501439beeb249216a2bf4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc77ee3bccee3eab3c6c398c82d71667.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Object-detection-in-adverse-weather-conditions-for-autonomous-vehicles-using-Instruct-Pix2Pix"><a href="#Object-detection-in-adverse-weather-conditions-for-autonomous-vehicles-using-Instruct-Pix2Pix" class="headerlink" title="Object detection in adverse weather conditions for autonomous vehicles   using Instruct Pix2Pix"></a>Object detection in adverse weather conditions for autonomous vehicles   using Instruct Pix2Pix</h2><p><strong>Authors:Unai Gurbindo, Axel Brando, Jaume Abella, Caroline KÃ¶nig</strong></p>
<p>Enhancing the robustness of object detection systems under adverse weather conditions is crucial for the advancement of autonomous driving technology. This study presents a novel approach leveraging the diffusion model Instruct Pix2Pix to develop prompting methodologies that generate realistic datasets with weather-based augmentations aiming to mitigate the impact of adverse weather on the perception capabilities of state-of-the-art object detection models, including Faster R-CNN and YOLOv10. Experiments were conducted in two environments, in the CARLA simulator where an initial evaluation of the proposed data augmentation was provided, and then on the real-world image data sets BDD100K and ACDC demonstrating the effectiveness of the approach in real environments.   The key contributions of this work are twofold: (1) identifying and quantifying the performance gap in object detection models under challenging weather conditions, and (2) demonstrating how tailored data augmentation strategies can significantly enhance the robustness of these models. This research establishes a solid foundation for improving the reliability of perception systems in demanding environmental scenarios, and provides a pathway for future advancements in autonomous driving. </p>
<blockquote>
<p>å¢å¼ºæ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹ç‰©ä½“æ£€æµ‹ç³»ç»Ÿç¨³å¥æ€§å¯¹äºè‡ªåŠ¨é©¾é©¶æŠ€æœ¯å‘å±•è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹Instruct Pix2Pixæ¥å¼€å‘æç¤ºæ–¹æ³•ï¼Œç”Ÿæˆå…·æœ‰å¤©æ°”å¢å¼ºçš„ç°å®æ•°æ®é›†ï¼Œæ—¨åœ¨å‡è½»æ¶åŠ£å¤©æ°”å¯¹æœ€æ–°ç‰©ä½“æ£€æµ‹æ¨¡å‹æ„ŸçŸ¥èƒ½åŠ›çš„å½±å“ï¼ŒåŒ…æ‹¬Faster R-CNNå’ŒYOLOv10ã€‚å®éªŒåœ¨ä¸¤ä¸ªç¯å¢ƒä¸­è¿›è¡Œï¼ŒåŒ…æ‹¬CARLAæ¨¡æ‹Ÿå™¨ï¼Œåˆæ­¥è¯„ä¼°äº†æ‰€æå‡ºçš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä»¥åŠåœ¨BDD100Kå’ŒACDCçœŸå®ä¸–ç•Œå›¾åƒæ•°æ®é›†ä¸Šå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œçš„å…³é”®è´¡çŒ®æœ‰ä¸¤æ–¹é¢ï¼šï¼ˆ1ï¼‰è¯†åˆ«å’Œé‡åŒ–ç‰©ä½“æ£€æµ‹æ¨¡å‹åœ¨æ¶åŠ£æ¡ä»¶ä¸‹çš„æ€§èƒ½å·®è·ï¼›ï¼ˆ2ï¼‰å±•ç¤ºé’ˆå¯¹æ€§æ•°æ®å¢å¼ºç­–ç•¥å¦‚ä½•æ˜¾è‘—å¢å¼ºè¿™äº›æ¨¡å‹çš„ç¨³å¥æ€§ã€‚æœ¬ç ”ç©¶ä¸ºæé«˜éœ€æ±‚ç¯å¢ƒåœºæ™¯ä¸­æ„ŸçŸ¥ç³»ç»Ÿçš„å¯é æ€§å¥ å®šäº†åšå®åŸºç¡€ï¼Œå¹¶ä¸ºè‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„æœªæ¥å‘å±•æä¾›äº†é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08228v1">PDF</a> 8 pages, 5 figures. Accepted at the International Joint Conference on   Neural Networks (IJCNN) 2025 (to appear)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡åˆ©ç”¨æ‰©æ•£æ¨¡å‹Instruct Pix2Pixå¼€å‘äº†ä¸€ç§æ–°çš„æç¤ºæ–¹æ³•ï¼Œç”Ÿæˆå…·æœ‰å¤©æ°”å¢å¼ºçš„ç°å®æ•°æ®é›†ï¼Œæ—¨åœ¨å‡è½»æ¶åŠ£å¤©æ°”å¯¹æœ€å…ˆè¿›çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„å½±å“ã€‚è¯¥ç ”ç©¶åœ¨CARLAæ¨¡æ‹Ÿå™¨ä»¥åŠçœŸå®ä¸–ç•Œæ•°æ®é›†BDD100Kå’ŒACDCä¸Šè¿›è¡Œäº†å®éªŒéªŒè¯ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡çš„å…³é”®è´¡çŒ®åœ¨äºè¯†åˆ«å’Œé‡åŒ–ç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹çš„æ€§èƒ½å·®è·ï¼Œå¹¶å±•ç¤ºäº†å®šåˆ¶æ•°æ®å¢å¼ºç­–ç•¥å¦‚ä½•æ˜¾è‘—å¢å¼ºè¿™äº›æ¨¡å‹çš„ç¨³å¥æ€§ã€‚è¿™ä¸ºæ”¹å–„ç¯å¢ƒæ¶åŠ£åœºæ™¯ä¸­çš„æ„ŸçŸ¥ç³»ç»Ÿå¯é æ€§å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨æ‰©æ•£æ¨¡å‹Instruct Pix2Pixå¼€å‘æ–°çš„æç¤ºæ–¹æ³•ï¼Œç”Ÿæˆå…·æœ‰å¤©æ°”å¢å¼ºçš„ç°å®æ•°æ®é›†ã€‚</li>
<li>æ—¨åœ¨æé«˜ç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹çš„ç¨³å¥æ€§ã€‚</li>
<li>åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸Šè¿›è¡Œåˆæ­¥è¯„ä¼°ï¼ŒéªŒè¯æ•°æ®å¢å¼ºçš„æ•ˆæœã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†BDD100Kå’ŒACDCä¸Šè¿›è¡Œå®éªŒï¼Œè¯æ˜æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯†åˆ«å’Œé‡åŒ–ç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹çš„æ€§èƒ½å·®è·ã€‚</li>
<li>å±•ç¤ºå®šåˆ¶æ•°æ®å¢å¼ºç­–ç•¥å¦‚ä½•æ˜¾è‘—å¢å¼ºç›®æ ‡æ£€æµ‹æ¨¡å‹çš„ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08228">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a6da414e4792ae1e1cedaa4a0edf2ed2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-363d6e00b239a37beb20eff28e2ae720.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f6bd6eea63376b53ec2482b74727555.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3fc3cd889849877f499467f17eaeb420.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ba6e4714986ed45478cc2cbdf6cef4a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8cebb960c3997ce9f322cacae2d410dd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5335cdcd125ad772b7155427a903557.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Unsupervised-Raindrop-Removal-from-a-Single-Image-using-Conditional-Diffusion-Models"><a href="#Unsupervised-Raindrop-Removal-from-a-Single-Image-using-Conditional-Diffusion-Models" class="headerlink" title="Unsupervised Raindrop Removal from a Single Image using Conditional   Diffusion Models"></a>Unsupervised Raindrop Removal from a Single Image using Conditional   Diffusion Models</h2><p><strong>Authors:Lhuqita Fazry, Valentino Vito</strong></p>
<p>Raindrop removal is a challenging task in image processing. Removing raindrops while relying solely on a single image further increases the difficulty of the task. Common approaches include the detection of raindrop regions in the image, followed by performing a background restoration process conditioned on those regions. While various methods can be applied for the detection step, the most common architecture used for background restoration is the Generative Adversarial Network (GAN). Recent advances in the use of diffusion models have led to state-of-the-art image inpainting techniques. In this paper, we introduce a novel technique for raindrop removal from a single image using diffusion-based image inpainting. </p>
<blockquote>
<p>é›¨æ»´å»é™¤æ˜¯å›¾åƒå¤„ç†ä¸­çš„ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ä»…ä¾èµ–å•å¼ å›¾åƒè¿›è¡Œé›¨æ»´å»é™¤è¿›ä¸€æ­¥å¢åŠ äº†ä»»åŠ¡çš„éš¾åº¦ã€‚å¸¸è§çš„æ–¹æ³•åŒ…æ‹¬æ£€æµ‹å›¾åƒä¸­çš„é›¨æ»´åŒºåŸŸï¼Œç„¶åå¯¹è¿™äº›åŒºåŸŸæ‰§è¡ŒèƒŒæ™¯æ¢å¤è¿‡ç¨‹ã€‚è™½ç„¶æ£€æµ‹æ­¥éª¤å¯ä»¥åº”ç”¨å„ç§æ–¹æ³•ï¼Œä½†ç”¨äºèƒŒæ™¯æ¢å¤çš„æœ€å¸¸ç”¨æ¶æ„æ˜¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ã€‚æ‰©æ•£æ¨¡å‹çš„ä½¿ç”¨æ–¹é¢çš„æœ€æ–°è¿›å±•å¯¼è‡´äº†æœ€å…ˆè¿›çš„å›¾åƒä¿®å¤æŠ€æœ¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ä½¿ç”¨åŸºäºæ‰©æ•£çš„å›¾åƒä¿®å¤ä»å•å¼ å›¾åƒä¸­å»é™¤é›¨æ»´çš„æ–°æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08190v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹å›¾åƒå»é›¨æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯ä¾§é‡äºå¯¹å›¾åƒä¸­çš„é›¨æ»´åŒºåŸŸè¿›è¡Œæ£€æµ‹ï¼Œéšååˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰è¿›è¡ŒèƒŒæ™¯ä¿®å¤ã€‚æœ€è¿‘æ‰©æ•£æ¨¡å‹çš„è¿›æ­¥ä½¿å¾—å›¾åƒä¿®å¤æŠ€æœ¯è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼Œæœ¬æ–‡åˆ©ç”¨è¿™ç§æŠ€æœ¯å®ç°å•å›¾åƒå»é›¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é›¨æ»´å»é™¤æ˜¯å›¾åƒå¤„ç†ä¸­çš„ä¸€é¡¹æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä»…ä½¿ç”¨å•å›¾åƒçš„æƒ…å†µä¸‹éš¾åº¦æ›´é«˜ã€‚</li>
<li>å¸¸è§çš„å»é›¨æ–¹æ³•åŒ…æ‹¬æ£€æµ‹å›¾åƒä¸­çš„é›¨æ»´åŒºåŸŸï¼Œç„¶åå¯¹è¿™äº›åŒºåŸŸè¿›è¡ŒèƒŒæ™¯æ¢å¤ã€‚</li>
<li>ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æ˜¯èƒŒæ™¯æ¢å¤æœ€å¸¸ç”¨çš„æ¶æ„ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨å»é›¨æ–¹é¢çš„åº”ç”¨æ˜¯è¿‘å¹´æ¥çš„ä¸€ä¸ªç ”ç©¶çƒ­ç‚¹ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤æŠ€æœ¯æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å•å›¾åƒå»é›¨æ–°æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08190">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-15257b03510672ae8dcf6a898d38ee1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf779c606e9e684766443b9529cb8e18.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-be2407db72daf1fc2d8eb946e3104af5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6dcc689d85b44ee96d70657fab0b3028.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-610be6a8340b2c876bf5335c10371f45.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HoloTime-Taming-Video-Diffusion-Models-for-Panoramic-4D-Scene-Generation"><a href="#HoloTime-Taming-Video-Diffusion-Models-for-Panoramic-4D-Scene-Generation" class="headerlink" title="HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene   Generation"></a>HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene   Generation</h2><p><strong>Authors:Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan</strong></p>
<p>The rapid advancement of diffusion models holds the promise of revolutionizing the application of VR and AR technologies, which typically require scene-level 4D assets for user experience. Nonetheless, existing diffusion models predominantly concentrate on modeling static 3D scenes or object-level dynamics, constraining their capacity to provide truly immersive experiences. To address this issue, we propose HoloTime, a framework that integrates video diffusion models to generate panoramic videos from a single prompt or reference image, along with a 360-degree 4D scene reconstruction method that seamlessly transforms the generated panoramic video into 4D assets, enabling a fully immersive 4D experience for users. Specifically, to tame video diffusion models for generating high-fidelity panoramic videos, we introduce the 360World dataset, the first comprehensive collection of panoramic videos suitable for downstream 4D scene reconstruction tasks. With this curated dataset, we propose Panoramic Animator, a two-stage image-to-video diffusion model that can convert panoramic images into high-quality panoramic videos. Following this, we present Panoramic Space-Time Reconstruction, which leverages a space-time depth estimation method to transform the generated panoramic videos into 4D point clouds, enabling the optimization of a holistic 4D Gaussian Splatting representation to reconstruct spatially and temporally consistent 4D scenes. To validate the efficacy of our method, we conducted a comparative analysis with existing approaches, revealing its superiority in both panoramic video generation and 4D scene reconstruction. This demonstrates our methodâ€™s capability to create more engaging and realistic immersive environments, thereby enhancing user experiences in VR and AR applications. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•æœ‰æœ›å½»åº•æ”¹å˜VRå’ŒARæŠ€æœ¯çš„åº”ç”¨å‰æ™¯ï¼Œè¿™äº›æŠ€æœ¯é€šå¸¸éœ€è¦åœºæ™¯çº§çš„å››ç»´èµ„äº§æ¥æå‡ç”¨æˆ·ä½“éªŒã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ‰©æ•£æ¨¡å‹ä¸»è¦é›†ä¸­åœ¨é™æ€ä¸‰ç»´åœºæ™¯çš„å»ºæ¨¡æˆ–å¯¹è±¡çº§åˆ«çš„åŠ¨æ€å»ºæ¨¡ä¸Šï¼Œé™åˆ¶äº†å®ƒä»¬æä¾›çœŸæ­£æ²‰æµ¸å¼ä½“éªŒçš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†HoloTimeæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†è§†é¢‘æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå…¨æ™¯è§†é¢‘ï¼Œé€šè¿‡ä¸€ä¸ªæç¤ºæˆ–å‚è€ƒå›¾åƒä»¥åŠä¸€ç§æ— ç¼å°†ç”Ÿæˆçš„å…¨æ™¯è§†é¢‘è½¬æ¢ä¸ºå››ç»´èµ„äº§çš„å…¨æ™¯å››ç»´åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œä¸ºç”¨æˆ·æä¾›å…¨æ–¹ä½çš„æ²‰æµ¸å¼å››ç»´ä½“éªŒã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†æ§åˆ¶è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜ä¿çœŸå…¨æ™¯è§†é¢‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†å…¨æ™¯ä¸–ç•Œæ•°æ®é›†ï¼Œè¿™æ˜¯å…¨æ™¯è§†é¢‘çš„ç¬¬ä¸€ä¸ªç»¼åˆé›†åˆï¼Œé€‚ç”¨äºä¸‹æ¸¸å››ç»´åœºæ™¯é‡å»ºä»»åŠ¡ã€‚æœ‰äº†è¿™ä¸ªç²¾é€‰çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†å…¨æ™¯åŠ¨ç”»å¸ˆè¿™ä¸€å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹ä¸¤é˜¶æ®µæ¨¡å‹ï¼Œèƒ½å¤Ÿå°†å…¨æ™¯å›¾åƒè½¬æ¢ä¸ºé«˜è´¨é‡å…¨æ™¯è§†é¢‘ã€‚éšåï¼Œæˆ‘ä»¬å±•ç¤ºäº†å…¨æ™¯æ—¶ç©ºé‡å»ºæŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯åˆ©ç”¨æ—¶ç©ºæ·±åº¦ä¼°è®¡æ–¹æ³•å°†ç”Ÿæˆçš„å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸ºå››ç»´ç‚¹äº‘æ•°æ®é›†ä¸ºä¼˜åŒ–å…¨æ¯å››ç»´é«˜æ–¯é‡‡æ ·å›¾æä¾›ä¾æ®æœ€ç»ˆé‡æ„ç©ºé—´å’Œæ—¶é—´ä¸€è‡´çš„å››ç»´åœºæ™¯ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§æˆ‘ä»¬è¿›è¡Œäº†ä¸ç°æœ‰æ–¹æ³•çš„æ¯”è¾ƒåˆ†æå‘ç°åœ¨å…¨æ™¯è§†é¢‘ç”Ÿæˆå’Œå››ç»´åœºæ™¯é‡å»ºæ–¹é¢å‡è¡¨ç°å‡ºä¼˜è¶Šæ€§è¿™è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨åˆ›å»ºæ›´å…·å¸å¼•åŠ›å’Œæ›´é€¼çœŸçš„æ²‰æµ¸å¼ç¯å¢ƒæ–¹é¢çš„èƒ½åŠ›ä»è€Œå¢å¼ºVRå’ŒARåº”ç”¨ç¨‹åºä¸­çš„ç”¨æˆ·ä½“éªŒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21650v2">PDF</a> Project Homepage: <a target="_blank" rel="noopener" href="https://zhouhyocean.github.io/holotime/">https://zhouhyocean.github.io/holotime/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/PKU-YuanGroup/HoloTime">https://github.com/PKU-YuanGroup/HoloTime</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºHoloTimeçš„æ¡†æ¶ï¼Œæ•´åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…¨æ™¯è§†é¢‘ï¼Œå¹¶åˆ©ç”¨360åº¦4Dåœºæ™¯é‡å»ºæ–¹æ³•å°†ç”Ÿæˆçš„å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸º4Dèµ„äº§ï¼Œä¸ºç”¨æˆ·å¸¦æ¥æ²‰æµ¸å¼4Dä½“éªŒã€‚ä¸ºè§£å†³ç”Ÿæˆé«˜è´¨é‡å…¨æ™¯è§†é¢‘çš„é—®é¢˜ï¼Œå¼•å…¥360Worldæ•°æ®é›†ï¼Œå¹¶æå‡ºå…¨æ™¯åŠ¨ç”»å¸ˆï¼ˆPanoramic Animatorï¼‰çš„ä¸¤é˜¶æ®µå›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚éšåï¼Œé‡‡ç”¨ç©ºé—´æ—¶é—´æ·±åº¦ä¼°è®¡æ–¹æ³•å°†å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸º4Dç‚¹äº‘ï¼Œä¼˜åŒ–æ•´ä½“4Dé«˜æ–¯æ‹¼è´´è¡¨ç¤ºï¼Œå®ç°ç©ºé—´å’Œæ—¶é—´ä¸Šä¸€è‡´çš„4Dåœºæ™¯é‡å»ºã€‚å®éªŒéªŒè¯è¯¥æ–¹æ³•åœ¨å…¨æ™¯è§†é¢‘ç”Ÿæˆå’Œ4Dåœºæ™¯é‡å»ºæ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œèƒ½åˆ›å»ºæ›´å¼•äººå…¥èƒœã€æ›´é€¼çœŸçš„æ²‰æµ¸å¼ç¯å¢ƒï¼Œæå‡VRå’ŒARåº”ç”¨ä¸­çš„ç”¨æˆ·ä½“éªŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•æœ‰æœ›é©å‘½æ€§åº”ç”¨äºVRå’ŒARæŠ€æœ¯ã€‚</li>
<li>å½“å‰æ‰©æ•£æ¨¡å‹ä¸»è¦é›†ä¸­åœ¨é™æ€åœºæ™¯çš„å»ºæ¨¡æˆ–ç‰©ä½“çº§åˆ«çš„åŠ¨æ€ï¼Œéš¾ä»¥æä¾›çœŸæ­£çš„æ²‰æµ¸å¼ä½“éªŒã€‚</li>
<li>æå‡ºHoloTimeæ¡†æ¶æ•´åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…¨æ™¯è§†é¢‘ã€‚</li>
<li>å¼•å…¥360Worldæ•°æ®é›†ï¼Œä¸ºå…¨æ™¯è§†é¢‘ç”Ÿæˆæä¾›é€‚ç”¨æ•°æ®ã€‚</li>
<li>æå‡ºå…¨æ™¯åŠ¨ç”»å¸ˆï¼ˆPanoramic Animatorï¼‰çš„ä¸¤é˜¶æ®µå›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>åˆ©ç”¨ç©ºé—´æ—¶é—´æ·±åº¦ä¼°è®¡æ–¹æ³•å°†å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸º4Dç‚¹äº‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21650">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-eafde3db9264ac8bfb9d80002c0e9518.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0baf1ba6ea5c06b24daee2b38e068005.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8fe1655f21afe59bf14160f97d1bbee8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f1de9cfc11315e4521be6b0b3b9142e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Gaussian-Shading-Rethinking-the-Realistic-Deployment-Challenge-of-Performance-Lossless-Image-Watermark-for-Diffusion-Models"><a href="#Gaussian-Shading-Rethinking-the-Realistic-Deployment-Challenge-of-Performance-Lossless-Image-Watermark-for-Diffusion-Models" class="headerlink" title="Gaussian Shading++: Rethinking the Realistic Deployment Challenge of   Performance-Lossless Image Watermark for Diffusion Models"></a>Gaussian Shading++: Rethinking the Realistic Deployment Challenge of   Performance-Lossless Image Watermark for Diffusion Models</h2><p><strong>Authors:Zijin Yang, Xin Zhang, Kejiang Chen, Kai Zeng, Qiyi Yao, Han Fang, Weiming Zhang, Nenghai Yu</strong></p>
<p>Ethical concerns surrounding copyright protection and inappropriate content generation pose challenges for the practical implementation of diffusion models. One effective solution involves watermarking the generated images. Existing methods primarily focus on ensuring that watermark embedding does not degrade the model performance. However, they often overlook critical challenges in real-world deployment scenarios, such as the complexity of watermark key management, user-defined generation parameters, and the difficulty of verification by arbitrary third parties. To address this issue, we propose Gaussian Shading++, a diffusion model watermarking method tailored for real-world deployment. We propose a double-channel design that leverages pseudorandom error-correcting codes to encode the random seed required for watermark pseudorandomization, achieving performance-lossless watermarking under a fixed watermark key and overcoming key management challenges. Additionally, we model the distortions introduced during generation and inversion as an additive white Gaussian noise channel and employ a novel soft decision decoding strategy during extraction, ensuring strong robustness even when generation parameters vary. To enable third-party verification, we incorporate public key signatures, which provide a certain level of resistance against forgery attacks even when model inversion capabilities are fully disclosed. Extensive experiments demonstrate that Gaussian Shading++ not only maintains performance losslessness but also outperforms existing methods in terms of robustness, making it a more practical solution for real-world deployment. </p>
<blockquote>
<p>å…³äºæ‰©æ•£æ¨¡å‹çš„å®ç”¨åŒ–å®æ–½ï¼Œå›´ç»•ç‰ˆæƒä¿æŠ¤å’Œä¸å½“å†…å®¹ç”Ÿæˆæ‰€äº§ç”Ÿçš„é“å¾·é—®é¢˜æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆæ˜¯åœ¨ç”Ÿæˆçš„å›¾åƒä¸Šæ·»åŠ æ°´å°ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ç¡®ä¿æ°´å°åµŒå…¥ä¸ä¼šé™ä½æ¨¡å‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œä»–ä»¬å¾€å¾€å¿½è§†äº†çœŸå®éƒ¨ç½²åœºæ™¯ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œå¦‚æ°´å°å¯†é’¥ç®¡ç†çš„å¤æ‚æ€§ã€ç”¨æˆ·å®šä¹‰çš„ç”Ÿæˆå‚æ•°ä»¥åŠç¬¬ä¸‰æ–¹éªŒè¯çš„å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†é«˜æ–¯é˜´å½±++ï¼ˆGaussian Shading++ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹çœŸå®ä¸–ç•Œéƒ¨ç½²é‡èº«å®šåˆ¶çš„æ‰©æ•£æ¨¡å‹æ°´å°æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒé€šé“è®¾è®¡ï¼Œåˆ©ç”¨ä¼ªéšæœºçº é”™ç¼–ç å¯¹æ°´å°ä¼ªéšæœºåŒ–æ‰€éœ€çš„éšæœºç§å­è¿›è¡Œç¼–ç ï¼Œå®ç°åœ¨å›ºå®šæ°´å°å¯†é’¥ä¸‹çš„æ€§èƒ½æ— æŸæ°´å°ï¼Œå¹¶å…‹æœå¯†é’¥ç®¡ç†æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆå’Œåè½¬è¿‡ç¨‹ä¸­å¼•å…¥çš„å¤±çœŸå»ºæ¨¡ä¸ºåŠ æ€§ç™½é«˜æ–¯å™ªå£°é€šé“ï¼Œå¹¶åœ¨æå–è¿‡ç¨‹ä¸­é‡‡ç”¨æ–°å‹è½¯å†³ç­–è§£ç ç­–ç•¥ï¼Œç¡®ä¿å³ä½¿åœ¨ç”Ÿæˆå‚æ•°å˜åŒ–æ—¶ä¹Ÿèƒ½ä¿æŒå¼ºå¤§çš„ç¨³å¥æ€§ã€‚ä¸ºäº†å®ç°ç¬¬ä¸‰æ–¹éªŒè¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†å…¬é’¥ç­¾åï¼Œå³ä½¿åœ¨æ¨¡å‹åè½¬èƒ½åŠ›å®Œå…¨å…¬å¼€çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æä¾›ä¸€å®šçš„æŠ—ä¼ªé€ æ”»å‡»èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œé«˜æ–¯é˜´å½±++ä¸ä»…ä¿æŒäº†æ€§èƒ½æ— æŸï¼Œè€Œä¸”åœ¨ç¨³å¥æ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œä½¿å…¶æˆä¸ºæ›´å®ç”¨çš„çœŸå®ä¸–ç•Œéƒ¨ç½²è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15026v2">PDF</a> 18 pages, 8 figures</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹æ‰©æ•£æ¨¡å‹å®é™…åº”ç”¨ä¸­çš„ç‰ˆæƒä¿æŠ¤ä¸ä¸å½“å†…å®¹ç”Ÿæˆç­‰ä¼¦ç†é—®é¢˜ï¼Œæå‡ºä¸€ç§åä¸ºGaussian Shading++çš„æ¨¡å‹æ°´å°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŒé€šé“è®¾è®¡ï¼Œåˆ©ç”¨ä¼ªéšæœºçº é”™ç å¯¹éšæœºç§å­è¿›è¡Œç¼–ç ï¼Œå®ç°æ€§èƒ½æ— æŸçš„æ°´å°åµŒå…¥å’Œå›ºå®šæ°´å°å¯†é’¥ç®¡ç†ï¼ŒåŒæ—¶å»ºæ¨¡ç”Ÿæˆå’Œåè½¬è¿‡ç¨‹ä¸­çš„å¤±çœŸä¸ºåŠ æ€§ç™½é«˜æ–¯å™ªå£°é€šé“ï¼Œå¹¶é‡‡ç”¨è½¯å†³ç­–è§£ç ç­–ç•¥ç¡®ä¿ç¨³å¥æ€§ã€‚ä¸ºç¬¬ä¸‰æ–¹éªŒè¯ï¼Œå¼•å…¥äº†å…¬é’¥ç­¾åï¼Œå¯¹æŠ—ä¼ªé€ æ”»å‡»ã€‚å®éªŒè¯æ˜ï¼ŒGaussian Shading++åœ¨ä¿æŒæ€§èƒ½æ— æŸçš„åŒæ—¶ï¼Œç¨³å¥æ€§ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ›´é€‚åˆå®é™…éƒ¨ç½²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å®é™…åº”ç”¨ä¸­é¢ä¸´ç‰ˆæƒä¿æŠ¤å’Œä¸å½“å†…å®¹ç”Ÿæˆç­‰ä¼¦ç†æŒ‘æˆ˜ã€‚</li>
<li>Gaussian Shading++æ˜¯ä¸€ç§é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„æ°´å°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°å®é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨åŒé€šé“è®¾è®¡å’Œä¼ªéšæœºçº é”™ç ï¼Œå®ç°æ€§èƒ½æ— æŸçš„æ°´å°åµŒå…¥ã€‚</li>
<li>Gaussian Shading++è§£å†³äº†æ°´å°å¯†é’¥ç®¡ç†å¤æ‚åº¦é«˜çš„æŒ‘æˆ˜ã€‚</li>
<li>æ–¹æ³•å°†ç”Ÿæˆå’Œåè½¬è¿‡ç¨‹ä¸­çš„å¤±çœŸå»ºæ¨¡ä¸ºåŠ æ€§ç™½é«˜æ–¯å™ªå£°é€šé“ï¼Œé‡‡ç”¨è½¯å†³ç­–è§£ç ç­–ç•¥ç¡®ä¿ç¨³å¥æ€§ã€‚</li>
<li>ä¸ºå®ç°ç¬¬ä¸‰æ–¹éªŒè¯ï¼Œå¼•å…¥äº†å…¬é’¥ç­¾åï¼Œå¢å¼ºå¯¹æŠ—ä¼ªé€ æ”»å‡»çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15026">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dd4ba7af730d49a029e3221ba4fc014f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-342b7c4609fe523c5422be75ea9e035a.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Ptychographic-Image-Reconstruction-from-Limited-Data-via-Score-Based-Diffusion-Models-with-Physics-Guidance"><a href="#Ptychographic-Image-Reconstruction-from-Limited-Data-via-Score-Based-Diffusion-Models-with-Physics-Guidance" class="headerlink" title="Ptychographic Image Reconstruction from Limited Data via Score-Based   Diffusion Models with Physics-Guidance"></a>Ptychographic Image Reconstruction from Limited Data via Score-Based   Diffusion Models with Physics-Guidance</h2><p><strong>Authors:Refik Mert Cam, Junjing Deng, Rajkumar Kettimuthu, Mathew J. Cherukara, Tekin Bicer</strong></p>
<p>Ptychography is a data-intensive computational imaging technique that achieves high spatial resolution over large fields of view. The technique involves scanning a coherent beam across overlapping regions and recording diffraction patterns. Conventional reconstruction algorithms require substantial overlap, increasing data volume and experimental time, reaching PiB-scale experimental data and weeks to month-long data acquisition times. To address this, we propose a reconstruction method employing a physics-guided score-based diffusion model. Our approach trains a diffusion model on representative object images to learn an object distribution prior. During reconstruction, we modify the reverse diffusion process to enforce data consistency, guiding reverse diffusion toward a physically plausible solution. This method requires a single pretraining phase, allowing it to generalize across varying scan overlap ratios and positions. Our results demonstrate that the proposed method achieves high-fidelity reconstructions with only a 20% overlap, while the widely employed rPIE method requires a 62% overlap to achieve similar accuracy. This represents a significant reduction in data requirements, offering an alternative to conventional techniques. </p>
<blockquote>
<p>Ptychographyæ˜¯ä¸€ç§æ•°æ®å¯†é›†å‹çš„è®¡ç®—æˆåƒæŠ€æœ¯ï¼Œå¯ä»¥åœ¨å¤§è§†é‡èŒƒå›´å†…å®ç°é«˜ç©ºé—´åˆ†è¾¨ç‡ã€‚è¯¥æŠ€æœ¯æ¶‰åŠæ‰«æç›¸å¹²å…‰æŸç©¿è¿‡é‡å åŒºåŸŸå¹¶è®°å½•è¡å°„å›¾æ¡ˆã€‚ä¼ ç»Ÿçš„é‡å»ºç®—æ³•éœ€è¦å¤§é‡çš„é‡å ï¼Œè¿™å¢åŠ äº†æ•°æ®é‡å’Œå®éªŒæ—¶é—´ï¼Œè¾¾åˆ°PiBè§„æ¨¡çš„å®éªŒæ•°æ®å’Œé•¿è¾¾æ•°å‘¨çš„æ•°æ®é‡‡é›†æ—¶é—´ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é‡‡ç”¨ç‰©ç†å¼•å¯¼è¯„åˆ†æ‰©æ•£æ¨¡å‹çš„é‡å»ºæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡åœ¨å…·æœ‰ä»£è¡¨æ€§çš„ç›®æ ‡å›¾åƒä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ ç›®æ ‡åˆ†å¸ƒå…ˆéªŒã€‚åœ¨é‡å»ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¿®æ”¹åå‘æ‰©æ•£è¿‡ç¨‹ä»¥å¼ºåˆ¶æ‰§è¡Œæ•°æ®ä¸€è‡´æ€§ï¼Œå¼•å¯¼åå‘æ‰©æ•£æœç€ç‰©ç†å¯è¡Œè§£è¿›è¡Œã€‚è¯¥æ–¹æ³•ä»…éœ€ä¸€ä¸ªé¢„è®­ç»ƒé˜¶æ®µï¼Œå¯ä»¥è·¨ä¸åŒçš„æ‰«æé‡å ç‡å’Œä½ç½®è¿›è¡Œæ¨å¹¿ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨ä»…23%çš„é‡å æƒ…å†µä¸‹å®ç°äº†é«˜ä¿çœŸé‡å»ºï¼Œè€Œå¹¿æ³›ä½¿ç”¨çš„rPIEæ–¹æ³•éœ€è¦è¾¾åˆ°ç±»ä¼¼ç²¾åº¦åˆ™éœ€è¦é«˜è¾¾62%çš„é‡å ç‡ã€‚è¿™ä»£è¡¨äº†æ•°æ®éœ€æ±‚çš„æ˜¾è‘—å‡å°‘ï¼Œä¸ºä¼ ç»ŸæŠ€æœ¯æä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18767v2">PDF</a> Preprint submitted to IEEE MLSP 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†ç”¨äºå®ç°å¤§é¢ç§¯é«˜ç©ºé—´åˆ†è¾¨ç‡æˆåƒçš„å®šé‡æˆåƒæŠ€æœ¯â€”â€”æ–‘ç‚¹æ‰«ææˆåƒã€‚æ–‡ä¸­æŒ‡å‡ºä¼ ç»Ÿé‡å»ºç®—æ³•éœ€è¦å¤§é‡é‡å åŒºåŸŸï¼Œå¯¼è‡´æ•°æ®é‡å’Œå®éªŒæ—¶é—´å¢åŠ ã€‚ä¸ºæ”¹å–„è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç‰©ç†å¼•å¯¼å’Œæ‰©æ•£æ¨¡å‹çš„é‡å»ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨ä»£è¡¨æ€§ç›®æ ‡å›¾åƒä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ ç›®æ ‡åˆ†å¸ƒå…ˆéªŒã€‚åœ¨é‡å»ºè¿‡ç¨‹ä¸­ï¼Œä¿®æ”¹åå‘æ‰©æ•£è¿‡ç¨‹ä»¥å¼ºåˆ¶æ•°æ®ä¸€è‡´æ€§ï¼Œä»è€Œå¼•å¯¼å…¶å‘ç‰©ç†å¯è¡Œè§£æ–¹å‘è¿›è¡Œã€‚è¯¥æ–¹æ³•ä»…éœ€ä¸€æ¬¡é¢„è®­ç»ƒé˜¶æ®µï¼Œå¯æ³›åŒ–äºä¸åŒæ‰«æé‡å ç‡å’Œä½ç½®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•ä»…éœ€è¦20%é‡å ç‡å³å¯å®ç°é«˜ä¿çœŸé‡å»ºï¼Œè€Œå¹¿æ³›ä½¿ç”¨çš„rPIEæ–¹æ³•éœ€è¦62%é‡å ç‡æ‰èƒ½è¾¾åˆ°ç›¸ä¼¼ç²¾åº¦ã€‚è¿™æ˜¾è‘—é™ä½äº†æ•°æ®è¦æ±‚ï¼Œä¸ºä¼ ç»ŸæŠ€æœ¯æä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‘ç‚¹æ‰«ææˆåƒæ˜¯ä¸€ç§æ•°æ®å¯†é›†å‹è®¡ç®—æˆåƒæŠ€æœ¯ï¼Œå¯åœ¨å¤§è§†é‡ä¸Šå®ç°é«˜ç©ºé—´åˆ†è¾¨ç‡ã€‚</li>
<li>ä¼ ç»Ÿé‡å»ºç®—æ³•éœ€è¦å¤§é‡é‡å åŒºåŸŸï¼Œå¢åŠ äº†æ•°æ®é‡å’Œå®éªŒæ—¶é—´ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç‰©ç†å¼•å¯¼å’Œæ‰©æ•£æ¨¡å‹çš„é‡å»ºæ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ ç›®æ ‡åˆ†å¸ƒå…ˆéªŒã€‚</li>
<li>ä¿®æ”¹äº†åå‘æ‰©æ•£è¿‡ç¨‹ä»¥å¼ºåˆ¶æ•°æ®ä¸€è‡´æ€§ï¼Œå¼•å¯¼è§£å†³æ–¹æ¡ˆå‘ç‰©ç†å¯è¡Œæ–¹å‘è¿›è¡Œã€‚</li>
<li>è¯¥æ–¹æ³•ä»…éœ€è¦ä¸€æ¬¡é¢„è®­ç»ƒé˜¶æ®µï¼Œå¹¶å¯ä»¥æ³›åŒ–åˆ°ä¸åŒçš„æ‰«æé‡å ç‡å’Œä½ç½®ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åªéœ€20%é‡å å³å¯å®ç°é«˜ä¿çœŸé‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-26d4d96e9e9d4a382003bfa6e3761ea1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef4eeb1bbbbc7f1933c5275369ba5304.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73247140ab45f0453ba26a05692744ae.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-18ffe276aaa83bb9cbcbd91e50198bd7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d3a898b4cdf5c37b519be10fc401c15c.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Optimized-View-and-Geometry-Distillation-from-Multi-view-Diffuser"><a href="#Optimized-View-and-Geometry-Distillation-from-Multi-view-Diffuser" class="headerlink" title="Optimized View and Geometry Distillation from Multi-view Diffuser"></a>Optimized View and Geometry Distillation from Multi-view Diffuser</h2><p><strong>Authors:Youjia Zhang, Zikai Song, Junqing Yu, Yawei Luo, Wei Yang</strong></p>
<p>Generating multi-view images from a single input view using image-conditioned diffusion models is a recent advancement and has shown considerable potential. However, issues such as the lack of consistency in synthesized views and over-smoothing in extracted geometry persist. Previous methods integrate multi-view consistency modules or impose additional supervisory to enhance view consistency while compromising on the flexibility of camera positioning and limiting the versatility of view synthesis. In this study, we consider the radiance field optimized during geometry extraction as a more rigid consistency prior, compared to volume and ray aggregation used in previous works. We further identify and rectify a critical bias in the traditional radiance field optimization process through score distillation from a multi-view diffuser. We introduce an Unbiased Score Distillation (USD) that utilizes unconditioned noises from a 2D diffusion model, greatly refining the radiance field fidelity. We leverage the rendered views from the optimized radiance field as the basis and develop a two-step specialization process of a 2D diffusion model, which is adept at conducting object-specific denoising and generating high-quality multi-view images. Finally, we recover faithful geometry and texture directly from the refined multi-view images. Empirical evaluations demonstrate that our optimized geometry and view distillation technique generates comparable results to the state-of-the-art models trained on extensive datasets, all while maintaining freedom in camera positioning. Please see our project page at <a target="_blank" rel="noopener" href="https://youjiazhang.github.io/USD/">https://youjiazhang.github.io/USD/</a>. </p>
<blockquote>
<p>ä½¿ç”¨å›¾åƒæ¡ä»¶æ‰©æ•£æ¨¡å‹ä»å•ä¸€è¾“å…¥è§†å›¾ç”Ÿæˆå¤šè§†å›¾å›¾åƒæ˜¯æœ€è¿‘çš„ä¸€é¡¹è¿›å±•ï¼Œå¹¶æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œåˆæˆè§†å›¾çš„ä¸ä¸€è‡´æ€§ä»¥åŠæå–å‡ ä½•å›¾å½¢æ—¶çš„è¿‡åº¦å¹³æ»‘ç­‰é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚ä¹‹å‰çš„æ–¹æ³•æ˜¯é€šè¿‡é›†æˆå¤šè§†å›¾ä¸€è‡´æ€§æ¨¡å—æˆ–æ–½åŠ é¢å¤–çš„ç›‘ç£æ¥å¢å¼ºè§†å›¾ä¸€è‡´æ€§ï¼Œä½†è¿™ä¼šæŸå®³ç›¸æœºå®šä½çš„è‡ªç”±åº¦å¹¶é™åˆ¶è§†å›¾åˆæˆçš„çµæ´»æ€§ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºåœ¨å‡ ä½•æå–è¿‡ç¨‹ä¸­ä¼˜åŒ–çš„è¾å°„åœºæ˜¯ä¸€ä¸ªæ›´ä¸¥æ ¼çš„ä¸€è‡´æ€§å…ˆéªŒï¼Œä¸ä¹‹å‰ä½¿ç”¨çš„ä½“ç§¯å’Œå°„çº¿èšåˆç›¸æ¯”ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡æ¥è‡ªå¤šè§†å›¾æ‰©æ•£å™¨çš„åˆ†æ•°è’¸é¦æ¥è¯†åˆ«å’Œçº æ­£ä¼ ç»Ÿè¾å°„åœºä¼˜åŒ–è¿‡ç¨‹ä¸­çš„å…³é”®åè§ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ— ååˆ†æ•°è’¸é¦ï¼ˆUSDï¼‰ï¼Œå®ƒåˆ©ç”¨æ¥è‡ªäºŒç»´æ‰©æ•£æ¨¡å‹çš„æ— æ¡ä»¶å™ªå£°ï¼Œå¤§å¤§æé«˜äº†è¾å°„åœºçš„ä¿çœŸåº¦ã€‚æˆ‘ä»¬åˆ©ç”¨ä¼˜åŒ–åçš„è¾å°„åœºæ‰€å‘ˆç°çš„è§†å›¾ä½œä¸ºåŸºç¡€ï¼Œå¼€å‘äº†ä¸€ä¸ªä¸¤æ­¥ç‰¹åŒ–è¿‡ç¨‹çš„äºŒç»´æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ“…é•¿è¿›è¡Œå¯¹è±¡ç‰¹å®šçš„å»å™ªå’Œç”Ÿæˆé«˜è´¨é‡çš„å¤šè§†å›¾å›¾åƒã€‚æœ€åï¼Œæˆ‘ä»¬ä»ç²¾è‡´çš„å¤šè§†å›¾å›¾åƒä¸­ç›´æ¥æ¢å¤å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ã€‚ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„å‡ ä½•å’Œè§†å›¾è’¸é¦æŠ€æœ¯ç”Ÿæˆçš„ç»“æœä¸åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æœ€æ–°æ¨¡å‹ç›¸å½“ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸æœºå®šä½çš„è‡ªç”±åº¦ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢<a target="_blank" rel="noopener" href="https://youjiazhang.github.io/USD/%E4%BA%86%E8%A7%A3%E8%AF%A6%E6%83%85%E3%80%82">https://youjiazhang.github.io/USD/äº†è§£è¯¦æƒ…ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.06198v4">PDF</a> IJCAI 2025. Project page: <a target="_blank" rel="noopener" href="https://youjiazhang.github.io/USD/">https://youjiazhang.github.io/USD/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå›¾åƒæ¡ä»¶çš„æ‰©æ•£æ¨¡å‹åœ¨å¤šè§†è§’å›¾åƒç”Ÿæˆé¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ä»å­˜åœ¨è§†å›¾ä¸ä¸€è‡´å’Œå‡ ä½•æå–è¿‡åº¦å¹³æ»‘ç­‰é—®é¢˜ã€‚æœ¬ç ”ç©¶é€šè¿‡ä¼˜åŒ–å‡ ä½•æå–è¿‡ç¨‹ä¸­çš„è¾å°„åœºï¼Œå¼•å…¥æ— åè¯„åˆ†è’¸é¦ï¼ˆUSDï¼‰æŠ€æœ¯ï¼Œå¹¶å‘å±•äº†ä¸€ä¸ªåŸºäºä¼˜åŒ–è¾å°„åœºçš„ä¸¤æ­¥ä¸“ä¸šåŒ–è¿‡ç¨‹ï¼Œæ—¨åœ¨ç”Ÿæˆé«˜è´¨é‡çš„å¤šè§†è§’å›¾åƒã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶èƒ½å¤Ÿä»ä¼˜åŒ–åçš„å¤šè§†è§’å›¾åƒä¸­æ¢å¤çœŸå®çš„å‡ ä½•å’Œçº¹ç†ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å¤šè§†è§’å›¾åƒç”Ÿæˆä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚</li>
<li>å­˜åœ¨è§†å›¾ä¸ä¸€è‡´æ€§å’Œå‡ ä½•æå–è¿‡åº¦å¹³æ»‘çš„é—®é¢˜ã€‚</li>
<li>ä¼˜åŒ–å‡ ä½•æå–è¿‡ç¨‹ä¸­çš„è¾å°„åœºä»¥æé«˜è§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>å¼•å…¥æ— åè¯„åˆ†è’¸é¦ï¼ˆUSDï¼‰æŠ€æœ¯ï¼Œåˆ©ç”¨æ— æ¡ä»¶å™ªå£°æé«˜è¾å°„åœºçš„ä¿çœŸåº¦ã€‚</li>
<li>å‘å±•åŸºäºä¼˜åŒ–è¾å°„åœºçš„ä¸¤æ­¥ä¸“ä¸šåŒ–è¿‡ç¨‹ï¼Œæ“…é•¿è¿›è¡Œå¯¹è±¡ç‰¹å®šçš„å»å™ªå’Œé«˜è´¨é‡å¤šè§†è§’å›¾åƒç”Ÿæˆã€‚</li>
<li>ä»ä¼˜åŒ–åçš„å¤šè§†è§’å›¾åƒä¸­æ¢å¤çœŸå®çš„å‡ ä½•å’Œçº¹ç†ä¿¡æ¯ã€‚</li>
<li>å®è¯è¯„ä¼°è¡¨æ˜ï¼Œä¼˜åŒ–åçš„å‡ ä½•å’Œè§†å›¾è’¸é¦æŠ€æœ¯äº§ç”Ÿçš„ç»“æœä¸åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æœ€æ–°æ¨¡å‹ç›¸å½“ï¼ŒåŒæ—¶ä¿æŒç›¸æœºå®šä½çš„è‡ªç”±åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.06198">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cae3f1b3742fecc573e22fb75309467a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5bad6ffed54069eb1b9f041f4eb56a3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e499d158b90c7488692f8cd2a412519.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-faa449615bb60d573a72941630b96095.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e582884a9f8a61abe7214727c1f35486.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0052fb87e2e082640d191274740ba57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f42e8b7627bccf2c0cd521562453bf2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-084c1e215a1906a23135d2cc17d3be7e.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-15/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-15/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-15/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-986e0875fc30a20aaf1fe57a2d1500ca.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-15  VIViT Variable-Input Vision Transformer Framework for 3D MR Image   Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-15/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d732cdb9730690481115522e7ce59722.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-15  FOCI Trajectory Optimization on Gaussian Splats
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29580.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
