<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-01  DeltaLLM Compress LLMs with Low-Rank Deltas between Shared Weights">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-a6e5a673f0255b153fa7eebca7411234.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    70 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-01-æ›´æ–°"><a href="#2025-02-01-æ›´æ–°" class="headerlink" title="2025-02-01 æ›´æ–°"></a>2025-02-01 æ›´æ–°</h1><h2 id="DeltaLLM-Compress-LLMs-with-Low-Rank-Deltas-between-Shared-Weights"><a href="#DeltaLLM-Compress-LLMs-with-Low-Rank-Deltas-between-Shared-Weights" class="headerlink" title="DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights"></a>DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights</h2><p><strong>Authors:Liana Mikaelyan, Ayyoob Imani, Mathew Salvaris, Parth Pathak, Mohsen Fayyaz</strong></p>
<p>We introduce DeltaLLM, a new post-training compression technique to reduce the memory footprint of LLMs. We propose an alternative way of structuring LLMs with weight sharing between layers in subsequent Transformer blocks, along with additional low-rank difference matrices between them. For training, we adopt the progressing module replacement method and show that the lightweight training of the low-rank modules with approximately 30M-40M tokens is sufficient to achieve performance on par with LLMs of comparable sizes trained from scratch. We release the resultant models, DeltaLLAMA and DeltaPHI, with a 12% parameter reduction, retaining 90% of the performance of the base Llama and Phi models on common knowledge and reasoning benchmarks. Our method also outperforms compression techniques JointDrop, LaCo, ShortGPT and SliceGPT with the same number of parameters removed. For example, DeltaPhi 2.9B with a 24% reduction achieves similar average zero-shot accuracies as recovery fine-tuned SlicedPhi 3.3B with a 12% reduction, despite being approximately 400M parameters smaller with no fine-tuning applied. This work provides new insights into LLM architecture design and compression methods when storage space is critical. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†DeltaLLMï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„è®­ç»ƒåå‹ç¼©æŠ€æœ¯ï¼Œç”¨äºå‡å°‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å†…å­˜å ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£çš„LLMç»“æ„æ–¹å¼ï¼Œåç»­Transformerå—ä¹‹é—´çš„æƒé‡å…±äº«ï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´çš„é™„åŠ ä½ç§©å·®åˆ†çŸ©é˜µã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†é€æ­¥æ¨¡å—æ›¿æ¢æ³•ï¼Œå¹¶è¯æ˜ä½¿ç”¨çº¦30M-40Mæ ‡è®°å¯¹ä½ç§©æ¨¡å—è¿›è¡Œè½»é‡åŒ–è®­ç»ƒè¶³ä»¥è¾¾åˆ°ä¸ä»å¤´å¼€å§‹è®­ç»ƒçš„ç›¸å½“å¤§å°çš„LLMçš„æ€§èƒ½ç›¸å½“ã€‚æˆ‘ä»¬å‘å¸ƒäº†ç»“æœæ¨¡å‹DeltaLLAMAå’ŒDeltaPHIï¼Œå‚æ•°å‡å°‘äº†12%ï¼Œåœ¨å¸¸è¯†å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ä¿ç•™äº†åŸºç¡€Llamaå’ŒPhiæ¨¡å‹æ€§èƒ½çš„90%ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿä¼˜äºç§»é™¤ç›¸åŒæ•°é‡å‚æ•°çš„å‹ç¼©æŠ€æœ¯ï¼Œå¦‚JointDropã€LaCoã€ShortGPTå’ŒSliceGPTã€‚ä¾‹å¦‚ï¼Œå°½ç®¡DeltaPhi 2.9Bçš„æ¨¡å‹å‡å°‘äº†24%ï¼Œä¸”æœªç»å¾®è°ƒåº”ç”¨è€Œå¤§å°çº¦å‡å°‘äº†è¿‘å››åäº¿å‚æ•°çš„æƒ…å†µä¸‹ï¼Œä»å®ç°äº†ä¸æ¢å¤ç²¾ç»†è®­ç»ƒçš„SlicedPhi 3.3Bç±»ä¼¼çš„å¹³å‡é›¶æ ·æœ¬å‡†ç¡®åº¦ã€‚è¿™é¡¹å·¥ä½œæä¾›äº†å¯¹å­˜å‚¨ç©ºé—´è‡³å…³é‡è¦çš„å…³é”®æ—¶åˆ»åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¶æ„è®¾è®¡å’Œå‹ç¼©æ–¹æ³•æ–¹é¢çš„æ–°è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18596v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>DeltaLLMæ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°å‹è®­ç»ƒåå‹ç¼©æŠ€æœ¯ã€‚å®ƒé€šè¿‡é‡æ–°æ„å»ºLLMç»“æ„ï¼Œå…±äº«åç»­Transformerå—ä¹‹é—´çš„æƒé‡ï¼Œå¹¶å¼•å…¥ä½é˜¶å·®å¼‚çŸ©é˜µï¼Œå‡å°‘äº†LLMçš„å†…å­˜å ç”¨ã€‚è¯¥æŠ€æœ¯é‡‡ç”¨æ¸è¿›æ¨¡å—æ›¿æ¢æ–¹æ³•è¿›è¡Œè®­ç»ƒï¼Œä»…ä½¿ç”¨çº¦30M-40Mçš„ä»¤ç‰Œå¯¹ä½é˜¶æ¨¡å—è¿›è¡Œè½»é‡åŒ–è®­ç»ƒï¼Œå³å¯è¾¾åˆ°ä¸ä»å¤´å¼€å§‹è®­ç»ƒçš„ç›¸ä¼¼è§„æ¨¡LLMç›¸å½“çš„æ€§èƒ½ã€‚æ–°æ¨å‡ºçš„DeltaLLAMAå’ŒDeltaPHIæ¨¡å‹åœ¨å¸¸è¯†å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ä¿ç•™äº†åŸºç¡€æ¨¡å‹æ€§èƒ½çš„90%ï¼ŒåŒæ—¶å®ç°äº†12%çš„å‚æ•°ç¼©å‡ã€‚ç›¸è¾ƒäºå…¶ä»–å‹ç¼©æŠ€æœ¯ï¼Œå¦‚JointDropã€LaCoã€ShortGPTå’ŒSliceGPTï¼ŒDeltaLLMåœ¨ç›¸åŒå‚æ•°ç¼©å‡æ¯”ä¾‹ä¸‹è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼ŒDeltaPhi 2.9Båœ¨å‡å°‘24%çš„å‚æ•°åï¼Œå…¶é›¶æ¬¡å°„å‡»ç²¾åº¦ä¸ç»è¿‡æ¢å¤çš„fine-tuned SlicedPhi 3.3Bç›¸ä¼¼ï¼Œå°½ç®¡DeltaPhiçš„å‚æ•°å°äº†çº¦4äº¿ï¼Œä¸”æ— éœ€è¿›è¡Œfine-tuningã€‚è¿™é¡¹ç ”ç©¶ä¸ºLLMæ¶æ„è®¾è®¡å’Œå‹ç¼©æ–¹æ³•æä¾›äº†æ–°çš„è§è§£ï¼Œå°¤å…¶æ˜¯åœ¨å­˜å‚¨ç©ºé—´è‡³å…³é‡è¦çš„æƒ…å†µä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeltaLLMæ˜¯ä¸€ç§æ–°å‹çš„LLMå‹ç¼©æŠ€æœ¯ï¼Œé€šè¿‡é‡æ–°æ„å»ºæ¨¡å‹ç»“æ„å’Œé‡‡ç”¨æƒé‡å…±äº«æ–¹æ³•å‡å°‘å†…å­˜å ç”¨ã€‚</li>
<li>é‡‡ç”¨æ¸è¿›æ¨¡å—æ›¿æ¢æ–¹æ³•è¿›è¡Œè®­ç»ƒï¼Œè½»é‡åŒ–è®­ç»ƒä½é˜¶æ¨¡å—è¾¾åˆ°ä¸å…¨è§„æ¨¡æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚</li>
<li>æ¨å‡ºçš„DeltaLLAMAå’ŒDeltaPHIæ¨¡å‹åœ¨å‚æ•°å‡å°‘12%çš„æƒ…å†µä¸‹ï¼Œä¿ç•™äº†åŸºç¡€æ¨¡å‹90%çš„æ€§èƒ½ã€‚</li>
<li>DeltaLLMåœ¨ç›¸åŒå‚æ•°ç¼©å‡æ¯”ä¾‹ä¸‹ä¼˜äºå…¶ä»–å‹ç¼©æŠ€æœ¯ã€‚</li>
<li>DeltaPhi 2.9Båœ¨å‡å°‘24%å‚æ•°åè¡¨ç°å‡ºä¸fine-tunedæ¨¡å‹ç›¸ä¼¼çš„æ€§èƒ½ï¼Œä¸”æ— éœ€fine-tuningã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºLLMæ¶æ„è®¾è®¡å’Œå‹ç¼©æ–¹æ³•æä¾›äº†æ–°çš„è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18596">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5873172a9f76c5468bd37c1be19f5294.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91a92a869cd2afbd37bba73856610bd0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf3ded435ce94eed84ba0263fe2f5c98.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5694d33662061d6e21a800a98ee2b25c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ff71b2ea5ad90569dc7d5979127c9303.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95be885eb92b27858efc9efef2f5c0f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-875e2ec8f11123724bd751e44daa7562.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Can-we-Retrieve-Everything-All-at-Once-ARM-An-Alignment-Oriented-LLM-based-Retrieval-Method"><a href="#Can-we-Retrieve-Everything-All-at-Once-ARM-An-Alignment-Oriented-LLM-based-Retrieval-Method" class="headerlink" title="Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented   LLM-based Retrieval Method"></a>Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented   LLM-based Retrieval Method</h2><p><strong>Authors:Peter Baile Chen, Yi Zhang, Michael Cafarella, Dan Roth</strong></p>
<p>Real-world open-domain questions can be complicated, particularly when answering them involves information from multiple information sources. LLMs have demonstrated impressive performance in decomposing complex tasks into simpler steps, and previous work has used it for better retrieval in support of complex questions. However, LLMâ€™s decomposition of questions is unaware of what data is available and how data is organized, often leading to a sub-optimal retrieval performance. Recent effort in agentic RAG proposes to perform retrieval in an iterative fashion, where a followup query is derived as an action based on previous rounds of retrieval. While this provides one way of interacting with the data collection, agentic RAGâ€™s exploration of data is inefficient because successive queries depend on previous results rather than being guided by the organization of available data in the collection. To address this problem, we propose an LLM-based retrieval method â€“ ARM, that aims to better align the question with the organization of the data collection by exploring relationships among data objects beyond matching the utterance of the query, thus leading to a retrieve-all-at-once solution for complex queries. We evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms standard RAG with query decomposition by up to 5.2 pt in execution accuracy and agentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and 19.3 pt higher F1 match scores compared to these approaches. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œå¼€æ”¾åŸŸçš„é—®é¢˜å¯èƒ½å¾ˆå¤æ‚ï¼Œç‰¹åˆ«æ˜¯å½“å›ç­”è¿™äº›é—®é¢˜éœ€è¦æ¥è‡ªå¤šä¸ªä¿¡æ¯æºçš„ä¿¡æ¯æ—¶ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å°†å¤æ‚ä»»åŠ¡åˆ†è§£æˆæ›´ç®€å•æ­¥éª¤æ–¹é¢è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä¹‹å‰çš„å·¥ä½œä¹Ÿç”¨å®ƒæ¥æ”¯æŒå¤æ‚é—®é¢˜çš„æ›´å¥½æ£€ç´¢ã€‚ç„¶è€Œï¼ŒLLMå¯¹é—®é¢˜çš„åˆ†è§£å¹¶ä¸çŸ¥é“å“ªäº›æ•°æ®å¯ç”¨ä»¥åŠæ•°æ®æ˜¯å¦‚ä½•ç»„ç»‡çš„ï¼Œè¿™å¸¸å¸¸å¯¼è‡´æ¬¡ä¼˜çš„æ£€ç´¢æ€§èƒ½ã€‚æœ€è¿‘çš„åŸºäºagentçš„RAGï¼ˆååº”å¼é—®ç­”ç”Ÿæˆï¼‰å·¥ä½œæå‡ºä»¥è¿­ä»£çš„æ–¹å¼è¿›è¡Œæ£€ç´¢ï¼Œå…¶ä¸­åç»­æŸ¥è¯¢æ˜¯åŸºäºå‰å‡ è½®çš„æ£€ç´¢ç»“æœæ¨å¯¼å‡ºçš„åŠ¨ä½œã€‚è™½ç„¶è¿™ä¸ºä¸æ•°æ®é›†äº¤äº’æä¾›äº†ä¸€ç§æ–¹å¼ï¼Œä½†åŸºäºagentçš„RAGå¯¹æ•°æ®é›†çš„æ¢ç´¢æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºåç»­æŸ¥è¯¢ä¾èµ–äºä¹‹å‰çš„ç»“æœï¼Œè€Œä¸æ˜¯ç”±æ•°æ®é›†ä¸­å¯ç”¨æ•°æ®çš„ç»„ç»‡æ¥æŒ‡å¯¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºLLMçš„æ£€ç´¢æ–¹æ³•â€”â€”ARMï¼ˆå¯¹é½æ£€ç´¢æ–¹æ³•ï¼‰ï¼Œæ—¨åœ¨é€šè¿‡æ¢ç´¢æ•°æ®å¯¹è±¡ä¹‹é—´çš„å…³ç³»ï¼ˆè€Œä¸ä»…ä»…æ˜¯åŒ¹é…æŸ¥è¯¢çš„è¡¨è¿°ï¼‰ï¼Œæ›´å¥½åœ°å°†é—®é¢˜ä¸æ•°æ®é›†çš„ç»„ç»‡å¯¹é½ï¼Œä»è€Œä¸ºå¤æ‚æŸ¥è¯¢æä¾›ä¸€æ¬¡æ€§æ£€ç´¢çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬åœ¨Birdå’ŒOTT-QAä¸¤ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°äº†ARMã€‚åœ¨Birdæ•°æ®é›†ä¸Šï¼Œä¸å…·æœ‰æŸ¥è¯¢åˆ†è§£çš„æ ‡å‡†RAGç›¸æ¯”ï¼ŒARMçš„æ‰§è¡Œå‡†ç¡®ç‡æé«˜äº†é«˜è¾¾5.2ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸ååº”å¼RAGç›¸æ¯”æé«˜äº†é«˜è¾¾15.9ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨OTT-QAä¸Šï¼Œä¸è¿™äº›æ–¹æ³•ç›¸æ¯”ï¼ŒARMçš„F1åŒ¹é…å¾—åˆ†æé«˜äº†é«˜è¾¾5.5ä¸ªç™¾åˆ†ç‚¹å’Œ19.3ä¸ªç™¾åˆ†ç‚¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18539v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨çœŸå®ä¸–ç•Œå¼€æ”¾é¢†åŸŸé—®é¢˜å¤„ç†ä¸­çš„å¤æ‚æ€§å’ŒæŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰LLMåœ¨é—®é¢˜åˆ†è§£å’Œæ•°æ®æ£€ç´¢æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLLMçš„æ•°æ®æ£€ç´¢æ–¹æ³•ARMã€‚ARMæ—¨åœ¨é€šè¿‡æ¢ç´¢æ•°æ®å¯¹è±¡ä¹‹é—´çš„å…³ç³»ï¼Œå®ç°å¯¹æ•°æ®é›†åˆç»„ç»‡çš„æ›´å¥½å¯¹é½ï¼Œä»è€Œæé«˜å¤æ‚æŸ¥è¯¢çš„æ£€ç´¢æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARMåœ¨Birdæ•°æ®é›†ä¸Šçš„æ‰§è¡Œå‡†ç¡®ç‡ä¼˜äºæ ‡å‡†RAGå’Œagentic RAGï¼ˆReActï¼‰ï¼Œåœ¨OTT-QAæ•°æ®é›†ä¸Šçš„F1åŒ¹é…åˆ†æ•°ä¹Ÿæœ‰æ‰€æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨å¤„ç†çœŸå®ä¸–ç•Œå¼€æ”¾é¢†åŸŸé—®é¢˜æ—¶é¢ä¸´å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯æ¶‰åŠå¤šä¿¡æ¯æºçš„é—®é¢˜åˆ†è§£æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰LLMåœ¨é—®é¢˜åˆ†è§£æ—¶æ— æ³•æœ‰æ•ˆè¯†åˆ«æ•°æ®å¯ç”¨æ€§å’Œç»„ç»‡æ–¹å¼ï¼Œå¯¼è‡´æ£€ç´¢æ€§èƒ½ä¸ä½³ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºLLMçš„æ•°æ®æ£€ç´¢æ–¹æ³•ARMï¼Œé€šè¿‡æ¢ç´¢æ•°æ®å¯¹è±¡ä¹‹é—´çš„å…³ç³»ï¼Œå®ç°å¯¹æ•°æ®é›†åˆç»„ç»‡çš„æ›´å¥½å¯¹é½ã€‚</li>
<li>ARMé‡‡ç”¨ä¸€æ¬¡æ€§æ£€ç´¢æ‰€æœ‰ç›¸å…³æ•°æ®çš„ç­–ç•¥ï¼Œä¸ºå¤æ‚æŸ¥è¯¢æä¾›è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åœ¨Birdæ•°æ®é›†ä¸Šï¼ŒARMçš„æ‰§è¡Œå‡†ç¡®ç‡ä¼˜äºæ ‡å‡†RAGå’Œagentic RAGï¼ˆReActï¼‰ã€‚</li>
<li>åœ¨OTT-QAæ•°æ®é›†ä¸Šï¼ŒARMçš„F1åŒ¹é…åˆ†æ•°é«˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18539">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-316a66a7bee2771bb292a68d9f84c975.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a24335b918abd790bc97bffbe118483.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Illusions-of-Relevance-Using-Content-Injection-Attacks-to-Deceive-Retrievers-Rerankers-and-LLM-Judges"><a href="#Illusions-of-Relevance-Using-Content-Injection-Attacks-to-Deceive-Retrievers-Rerankers-and-LLM-Judges" class="headerlink" title="Illusions of Relevance: Using Content Injection Attacks to Deceive   Retrievers, Rerankers, and LLM Judges"></a>Illusions of Relevance: Using Content Injection Attacks to Deceive   Retrievers, Rerankers, and LLM Judges</h2><p><strong>Authors:Manveer Singh Tamber, Jimmy Lin</strong></p>
<p>Consider a scenario in which a user searches for information, only to encounter texts flooded with misleading or non-relevant content. This scenario exemplifies a simple yet potent vulnerability in neural Information Retrieval (IR) pipelines: content injection attacks. We find that embedding models for retrieval, rerankers, and large language model (LLM) relevance judges are vulnerable to these attacks, in which adversaries insert misleading text into passages to manipulate model judgements. We identify two primary threats: (1) inserting unrelated or harmful content within passages that still appear deceptively â€œrelevantâ€, and (2) inserting entire queries or key query terms into passages to boost their perceived relevance. While the second tactic has been explored in prior research, we present, to our knowledge, the first empirical analysis of the first threat, demonstrating how state-of-the-art models can be easily misled. Our study systematically examines the factors that influence an attackâ€™s success, such as the placement of injected content and the balance between relevant and non-relevant material. Additionally, we explore various defense strategies, including adversarial passage classifiers, retriever fine-tuning to discount manipulated content, and prompting LLM judges to adopt a more cautious approach. However, we find that these countermeasures often involve trade-offs, sacrificing effectiveness for attack robustness and sometimes penalizing legitimate documents in the process. Our findings highlight the need for stronger defenses against these evolving adversarial strategies to maintain the trustworthiness of IR systems. We release our code and scripts to facilitate further research. </p>
<blockquote>
<p>è€ƒè™‘ä¸€ç§ç”¨æˆ·æœç´¢ä¿¡æ¯æ—¶é‡åˆ°å¤§é‡è¯¯å¯¼æ€§æˆ–éç›¸å…³å†…å®¹çš„åœºæ™¯ã€‚è¿™ä¸€åœºæ™¯å‡¸æ˜¾äº†ç¥ç»ä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰ç®¡é“ä¸­çš„ä¸€ä¸ªç®€å•ä½†å¼ºå¤§çš„æ¼æ´ï¼šå†…å®¹æ³¨å…¥æ”»å‡»ã€‚æˆ‘ä»¬å‘ç°ï¼Œç”¨äºæ£€ç´¢çš„åµŒå…¥æ¨¡å‹ã€é‡æ–°æ’åºå™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç›¸å…³æ€§åˆ¤æ–­è€…éƒ½å®¹æ˜“å—åˆ°è¿™äº›æ”»å‡»çš„å½±å“ï¼Œæ”»å‡»è€…ä¼šåœ¨æ®µè½ä¸­æ’å…¥è¯¯å¯¼æ€§æ–‡æœ¬ä»¥æ“çºµæ¨¡å‹åˆ¤æ–­ã€‚æˆ‘ä»¬ç¡®å®šäº†ä¸¤ä¸ªä¸»è¦å¨èƒï¼šï¼ˆ1ï¼‰åœ¨æ®µè½ä¸­æ’å…¥ä¸ç›¸å…³æˆ–æœ‰å®³çš„å†…å®¹ï¼Œè¿™äº›å†…å®¹è¡¨é¢ä¸Šä»ç„¶å…·æœ‰æ¬ºéª—æ€§çš„â€œç›¸å…³æ€§â€ï¼Œï¼ˆ2ï¼‰åœ¨æ®µè½ä¸­æ’å…¥æ•´ä¸ªæŸ¥è¯¢æˆ–å…³é”®æŸ¥è¯¢æœ¯è¯­ä»¥æé«˜å…¶æ„ŸçŸ¥çš„ç›¸å…³æ€§ã€‚è™½ç„¶ç¬¬äºŒç§ç­–ç•¥åœ¨ä»¥å‰çš„ç ”ç©¶ä¸­å·²ç»æœ‰æ‰€æ¢è®¨ï¼Œä½†æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬å¯¹ç¬¬ä¸€ç§å¨èƒè¿›è¡Œäº†é¦–æ¬¡å®è¯åˆ†æï¼Œè¯æ˜äº†æœ€å…ˆè¿›çš„æ¨¡å‹æ˜¯å¦‚ä½•è½»æ˜“å—åˆ°è¯¯å¯¼çš„ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç³»ç»Ÿåœ°ç ”ç©¶äº†å½±å“æ”»å‡»æˆåŠŸçš„å› ç´ ï¼Œå¦‚æ³¨å…¥å†…å®¹çš„æ”¾ç½®ä½ç½®å’Œç›¸å…³ä¸éç›¸å…³ææ–™çš„å¹³è¡¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢äº†å„ç§é˜²å¾¡ç­–ç•¥ï¼ŒåŒ…æ‹¬å¯¹æ•Œæ®µè½åˆ†ç±»å™¨ã€æ£€ç´¢å™¨å¾®è°ƒä»¥å¿½ç•¥æ“çºµå†…å®¹ï¼Œä»¥åŠæç¤ºLLMåˆ¤æ–­è€…é‡‡å–æ›´è°¨æ…çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°è¿™äº›å¯¹ç­–é€šå¸¸æ¶‰åŠæƒè¡¡ï¼Œéœ€è¦åœ¨æ”»å‡»é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ä¹‹é—´è¿›è¡Œå–èˆï¼Œæœ‰æ—¶è¿˜ä¼šåœ¨æ­¤è¿‡ç¨‹ä¸­æƒ©ç½šåˆæ³•æ–‡æ¡£ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†éœ€è¦å¯¹è¿™äº›ä¸æ–­å‘å±•çš„å¯¹æŠ—ç­–ç•¥è¿›è¡Œæ›´å¼ºå¤§çš„é˜²å¾¡ï¼Œä»¥ç»´æŒIRç³»ç»Ÿçš„å¯ä¿¡åº¦ã€‚æˆ‘ä»¬å‘å¸ƒäº†æˆ‘ä»¬çš„ä»£ç å’Œè„šæœ¬ï¼Œä»¥ä¿ƒè¿›è¿›ä¸€æ­¥çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18536v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨ä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰ç®¡é“ä¸­å­˜åœ¨ç€ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„æ¼æ´ï¼Œå³å†…å®¹æ³¨å…¥æ”»å‡»ï¼Œç”¨æˆ·æœç´¢ä¿¡æ¯æ—¶å¯èƒ½ä¼šé‡åˆ°å……æ–¥è¯¯å¯¼æˆ–éç›¸å…³å†…å®¹çš„æ–‡æœ¬ï¼Œæ­£æ˜¯è¿™ç§æƒ…æ™¯çš„ä½“ç°ã€‚æˆ‘ä»¬å‘ç°ç”¨äºæ£€ç´¢çš„åµŒå…¥æ¨¡å‹ã€é‡æ–°æ’åå™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç›¸å…³æ€§åˆ¤æ–­éƒ½å®¹æ˜“å—åˆ°è¿™äº›æ”»å‡»çš„å½±å“ã€‚æ”»å‡»è€…ä¼šåœ¨æ®µè½ä¸­æ’å…¥è¯¯å¯¼æ€§æ–‡æœ¬ï¼Œä»¥æ“çºµæ¨¡å‹åˆ¤æ–­ã€‚æˆ‘ä»¬ç¡®å®šäº†ä¸¤ç§ä¸»è¦çš„å¨èƒï¼šä¸€æ˜¯åœ¨æ®µè½ä¸­æ’å…¥ä¸ç›¸å…³æˆ–æœ‰å®³å†…å®¹ï¼Œè¿™äº›æ®µè½ä»ç„¶å…·æœ‰æ¬ºéª—æ€§çš„â€œç›¸å…³æ€§â€ï¼›äºŒæ˜¯åœ¨æ®µè½ä¸­æ’å…¥æ•´ä¸ªæŸ¥è¯¢æˆ–å…³é”®æŸ¥è¯¢æœ¯è¯­ä»¥æé«˜å…¶æ„ŸçŸ¥çš„ç›¸å…³æ€§ã€‚æˆ‘ä»¬å¯¹ç¬¬ä¸€ä¸ªå¨èƒè¿›è¡Œäº†æ®æˆ‘ä»¬æ‰€çŸ¥çš„é¦–æ¬¡å®è¯åˆ†æï¼Œè¯æ˜äº†æœ€å…ˆè¿›çš„æ¨¡å‹å¦‚ä½•è½»æ˜“å—åˆ°è¯¯å¯¼ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç³»ç»Ÿåœ°ç ”ç©¶äº†å½±å“æ”»å‡»æˆåŠŸçš„å› ç´ ï¼Œå¦‚æ³¨å…¥å†…å®¹çš„æ”¾ç½®å’Œå¹³è¡¡ç›¸å…³ä¸éç›¸å…³å†…å®¹ç­‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†å„ç§é˜²å¾¡ç­–ç•¥ï¼ŒåŒ…æ‹¬å¯¹æ•Œå®£ä¼ æ®µè½åˆ†ç±»å™¨ã€å¯¹æ“çºµå†…å®¹è¿›è¡Œå¾®è°ƒæ£€ç´¢å™¨ä»¥åŠæç¤ºLLMæ³•å®˜é‡‡å–æ›´è°¨æ…çš„æ–¹æ³•ç­‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°è¿™äº›å¯¹ç­–å¾€å¾€æ¶‰åŠæƒè¡¡å–èˆï¼Œç‰ºç‰²æ”»å‡»ç¨³å¥æ€§çš„æœ‰æ•ˆæ€§å¹¶æœ‰æ—¶æƒ©ç½šåˆæ³•æ–‡ä»¶ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†åº”å¯¹è¿™äº›ä¸æ–­å‘å±•çš„å¯¹æŠ—æ€§ç­–ç•¥è¿›è¡Œæ›´å¼ºæœ‰åŠ›çš„é˜²å¾¡ï¼Œä»¥ç»´æŒIRç³»ç»Ÿçš„å¯ä¿¡åº¦ã€‚æˆ‘ä»¬å‘å¸ƒæˆ‘ä»¬çš„ä»£ç å’Œè„šæœ¬æ¥ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å†…å®¹æ³¨å…¥æ”»å‡»æ˜¯ç¥ç»ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿä¸­çš„ä¸€ä¸ªé‡è¦æ¼æ´ã€‚</li>
<li>å¯¹ç¥ç»ä¿¡æ¯æ£€ç´¢ç®¡é“çš„åµŒå…¥æ¨¡å‹ã€é‡æ–°æ’åå™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„ç›¸å…³æ€§åˆ¤æ–­éƒ½å—åˆ°å†…å®¹æ³¨å…¥æ”»å‡»çš„å½±å“ã€‚</li>
<li>å­˜åœ¨ä¸¤ç§ä¸»è¦å¨èƒå½¢å¼ï¼šåœ¨çœ‹ä¼¼ç›¸å…³çš„æ®µè½ä¸­æ’å…¥ä¸ç›¸å…³æˆ–æœ‰å®³å†…å®¹ï¼›æˆ–åœ¨æ®µè½ä¸­æ’å…¥æŸ¥è¯¢å…³é”®è¯æˆ–æ•´ä½“æŸ¥è¯¢ä»¥åŠ å¼ºç›¸å…³æ€§æ„ŸçŸ¥ã€‚</li>
<li>å½“å‰ç ”ç©¶ç³»ç»Ÿåˆ†æäº†å½±å“æ”»å‡»æˆåŠŸçš„å› ç´ ï¼Œå¦‚æ³¨å…¥å†…å®¹çš„æ”¾ç½®å’Œä¸ç›¸å…³å†…å®¹ä¹‹é—´çš„å¹³è¡¡ç­‰ã€‚</li>
<li>ç ”ç©¶æ¢è®¨äº†å¤šç§é˜²å¾¡ç­–ç•¥ï¼ŒåŒ…æ‹¬ä½¿ç”¨å¯¹æŠ—æ€§å®£ä¼ åˆ†ç±»å™¨ã€å¾®è°ƒæ£€ç´¢å™¨ä»¥æ’é™¤æ“çºµå†…å®¹ä»¥åŠæç¤ºLLMæ³•å®˜é‡‡å–æ›´è°¨æ…çš„æ–¹æ³•ç­‰ã€‚ç„¶è€Œï¼Œè¿™äº›ç­–ç•¥å­˜åœ¨æƒè¡¡é—®é¢˜ï¼Œå¯èƒ½ç‰ºç‰²äº†æ”»å‡»ç¨³å¥æ€§å’Œ&#x2F;æˆ–å¯¹åˆæ³•å†…å®¹çš„å¤„ç½šé—®é¢˜ã€‚å› æ­¤æå‡ºäº†å¼ºçƒˆçš„é˜²å¾¡éœ€æ±‚ä»¥åº”å¯¹ä¸æ–­è¿›åŒ–çš„å¯¹æŠ—æ€§ç­–ç•¥ä»¥ä¿æŒIRç³»ç»Ÿçš„å¯ä¿¡åº¦é‡è¦æ€§å¾—åˆ°å¼ºè°ƒå¹¶æå‡ºäº†ç›¸å…³çš„å¯¹ç­–å»ºè®®ã€‚â€åœ¨è§£å†³è¿™ä¸€é—®é¢˜çš„åŒæ—¶æˆ‘ä»¬è¿˜å‘ç°å¹¶æå‡ºå…¬å¼€æˆ‘ä»¬çš„ä»£ç å’Œè„šæœ¬ä¸ºä»Šåçš„ç ”ç©¶æä¾›ä¾¿åˆ©çš„å‘ç°ä¸æ”¯æŒæå‡ºç›¸åº”ç¼“è§£éœ€æ±‚çš„æ¸ é“ç´§è¿«çš„é—®é¢˜éœ€è¦æœ‰å…·ä½“çš„è§£å†³æ–¹æ³•è€Œè¿™ä¸€å·¥ä½œéœ€è¦æ‰å®çš„è¡Œä¸šåŸºç¡€ä¿¡æ¯å’Œæ·±åˆ»çš„è®¤è¯†é‡è¦æ€§æé†’åº”å½“åœ¨æœªæ¥æ­¤é¢†åŸŸå†…å¯¹æ­¤ä¸»é¢˜ç»™äºˆæ›´å¤šå…³æ³¨ä»¥ç¡®ä¿ç¥ç»ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿçš„å®‰å…¨å’Œå¯ä¿¡åº¦åŒæ—¶ä¹Ÿä¿ƒè¿›äº†å­¦æœ¯ç•Œå’Œè¡Œä¸šç•Œåœ¨è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•å¼ºè°ƒäº†ç»§ç»­æ·±å…¥ç ”ç©¶è¿™ä¸€é¢†åŸŸçš„å¿…è¦æ€§ä»¥åŠè§£å†³è¿™äº›é—®é¢˜çš„ç´§è¿«æ€§â€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18536">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-afa8f115be70c30d8eb953c5e82bc2bf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d4d65e911b788b7fbbb01993c7698a12.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f07fe86e6b92b21de9d6462492c694c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b1e9846dad9ad0ee61e7f8988fe5921.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Differentially-Private-Steering-for-Large-Language-Model-Alignment"><a href="#Differentially-Private-Steering-for-Large-Language-Model-Alignment" class="headerlink" title="Differentially Private Steering for Large Language Model Alignment"></a>Differentially Private Steering for Large Language Model Alignment</h2><p><strong>Authors:Anmol Goel, Yaxi Hu, Iryna Gurevych, Amartya Sanyal</strong></p>
<p>Aligning Large Language Models (LLMs) with human values and away from undesirable behaviors (such as hallucination) has become increasingly important. Recently, steering LLMs towards a desired behavior via activation editing has emerged as an effective method to mitigate harmful generations at inference-time. Activation editing modifies LLM representations by preserving information from positive demonstrations (e.g., truthful) and minimising information from negative demonstrations (e.g., hallucinations). When these demonstrations come from a private dataset, the aligned LLM may leak private information contained in those private samples. In this work, we present the first study of aligning LLM behavior with private datasets. Our work proposes the \textit{\underline{P}rivate \underline{S}teering for LLM \underline{A}lignment (PSA)} algorithm to edit LLM activations with differential privacy (DP) guarantees. We conduct extensive experiments on seven different benchmarks with open-source LLMs of different sizes (0.5B to 7B) and model families (LlaMa, Qwen, Mistral and Gemma). Our results show that PSA achieves DP guarantees for LLM alignment with minimal loss in performance, including alignment metrics, open-ended text generation quality, and general-purpose reasoning. We also develop the first Membership Inference Attack (MIA) for evaluating and auditing the empirical privacy for the problem of LLM steering via activation editing. Our attack is tailored for activation editing and relies solely on the generated texts without their associated probabilities. Our experiments support the theoretical guarantees by showing improved guarantees for our \textit{PSA} algorithm compared to several existing non-private techniques. </p>
<blockquote>
<p>å¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸äººç±»ä»·å€¼è§‚å’Œè¿œç¦»ä¸è‰¯è¡Œä¸ºï¼ˆå¦‚å¹»è§‰ï¼‰å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚æœ€è¿‘ï¼Œé€šè¿‡æ¿€æ´»ç¼–è¾‘æ¥å¼•å¯¼LLMå®ç°æœŸæœ›çš„è¡Œä¸ºå·²ç»å‡ºç°ä¸ºä¸€ç§åœ¨æ¨ç†æ—¶é—´å‡å°‘æœ‰å®³ç”Ÿæˆçš„æœ‰æ•ˆæ–¹æ³•ã€‚æ¿€æ´»ç¼–è¾‘é€šè¿‡ä¿ç•™æ­£é¢æ¼”ç¤ºï¼ˆä¾‹å¦‚ï¼ŒçœŸå®ï¼‰ä¸­çš„ä¿¡æ¯å¹¶æœ€å°åŒ–è´Ÿé¢æ¼”ç¤ºï¼ˆä¾‹å¦‚ï¼Œå¹»è§‰ï¼‰ä¸­çš„ä¿¡æ¯æ¥ä¿®æ”¹LLMè¡¨ç¤ºã€‚å½“è¿™äº›æ¼”ç¤ºæ¥è‡ªç§æœ‰æ•°æ®é›†æ—¶ï¼Œå¯¹é½çš„LLMå¯èƒ½ä¼šæ³„éœ²è¿™äº›ç§æœ‰æ ·æœ¬ä¸­çš„ç§æœ‰ä¿¡æ¯ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡ç ”ç©¶äº†å°†LLMè¡Œä¸ºä¸ç§æœ‰æ•°æ®é›†å¯¹é½ã€‚æˆ‘ä»¬çš„å·¥ä½œæå‡ºäº†åä¸ºPSAï¼ˆç§æœ‰è½¬å‘å¯¹é½ç®—æ³•ï¼‰çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•ä½¿ç”¨å·®åˆ†éšç§ï¼ˆDPï¼‰ä¿è¯ç¼–è¾‘LLMæ¿€æ´»ã€‚æˆ‘ä»¬åœ¨ä¸ƒä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸Šå¯¹å¼€æºLLMè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œè¿™äº›æ¨¡å‹è§„æ¨¡ä»0.5Båˆ°7Bä¸ç­‰ï¼Œæ¨¡å‹å®¶æ—åŒ…æ‹¬LlaMaã€Qwenã€Mistralå’ŒGemmaã€‚ç»“æœè¡¨æ˜ï¼ŒPSAåœ¨LLMå¯¹é½æ–¹é¢å®ç°äº†å·®åˆ†éšç§ä¿è¯ï¼Œæ€§èƒ½æŸå¤±æœ€å°ï¼ŒåŒ…æ‹¬å¯¹é½æŒ‡æ ‡ã€å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆè´¨é‡å’Œé€šç”¨æ¨ç†ã€‚æˆ‘ä»¬è¿˜å¼€å‘äº†é¦–ä¸ªç”¨äºè¯„ä¼°å’Œå®¡è®¡é€šè¿‡æ¿€æ´»ç¼–è¾‘è¿›è¡ŒLLMå¼•å¯¼é—®é¢˜çš„ç»éªŒéšç§çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼ˆMIAï¼‰ã€‚æˆ‘ä»¬çš„æ”»å‡»é’ˆå¯¹æ¿€æ´»ç¼–è¾‘å®šåˆ¶ï¼Œä»…ä¾èµ–äºç”Ÿæˆçš„æ–‡æœ¬ï¼Œè€Œä¸ä¾èµ–äºä¸ä¹‹ç›¸å…³çš„æ¦‚ç‡ã€‚æˆ‘ä»¬çš„å®éªŒæ”¯æŒPSAç®—æ³•çš„ç†è®ºä¿è¯ï¼Œä¸å‡ ç§ç°æœ‰çš„éç§æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ç®—æ³•æä¾›äº†æ›´å¥½çš„ä¿è¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18532v1">PDF</a> ICLR 2025; Code: <a target="_blank" rel="noopener" href="https://github.com/UKPLab/iclr2025-psa">https://github.com/UKPLab/iclr2025-psa</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å¦‚ä½•é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¿€æ´»ç¼–è¾‘æ¥å®ç°ä¸ç§äººæ•°æ®é›†çš„å¯¹é½ï¼ŒåŒæ—¶ç¡®ä¿éšç§å®‰å…¨ã€‚æå‡ºä¸€ç§åä¸ºPSAï¼ˆPrivate Steering for LLM Alignmentï¼‰çš„ç®—æ³•ï¼Œèƒ½åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œç¡®ä¿LLMä¸ç§äººæ•°æ®é›†å¯¹é½æ—¶çš„éšç§ä¿æŠ¤ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒéªŒè¯ï¼ŒPSAç®—æ³•åœ¨LLMå¯¹é½é—®é¢˜ä¸Šå®ç°äº†å·®åˆ†éšç§ï¼ˆDPï¼‰ä¿è¯ï¼Œæé«˜äº†éšç§ä¿æŠ¤æ°´å¹³ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†é’ˆå¯¹æ¿€æ´»ç¼–è¾‘é—®é¢˜çš„é¦–ä¸ªæˆå‘˜æ¨ç†æ”»å‡»ï¼ˆMIAï¼‰ï¼Œç”¨äºè¯„ä¼°å’Œå®¡è®¡LLMæ¿€æ´»ç¼–è¾‘çš„å®è¯éšç§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPSAç®—æ³•ç›¸è¾ƒäºå…¶ä»–éç§æœ‰æŠ€æœ¯ï¼Œå…·æœ‰æ›´å¥½çš„éšç§ä¿æŠ¤æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¯¹é½é—®é¢˜æ„ˆå‘é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨é¿å…ä¸è‰¯è¡Œä¸ºï¼ˆå¦‚å¹»è§‰ï¼‰æ–¹é¢ã€‚</li>
<li>æ¿€æ´»ç¼–è¾‘æ˜¯å¼•å¯¼LLMå®ç°æœŸæœ›è¡Œä¸ºçš„æœ‰æ•ˆæ–¹æ³•ï¼Œé€šè¿‡ä¿ç•™æ­£é¢ç¤ºèŒƒä¿¡æ¯å¹¶æœ€å°åŒ–è´Ÿé¢ç¤ºèŒƒä¿¡æ¯æ¥å®ç°ã€‚</li>
<li>å½“ä½¿ç”¨ç§äººæ•°æ®é›†ä½œä¸ºç¤ºèŒƒæ—¶ï¼ŒLLMå¯¹é½å¯èƒ½æ³„éœ²ç§äººä¿¡æ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºPSAçš„ç®—æ³•ï¼Œèƒ½åœ¨LLMæ¿€æ´»ç¼–è¾‘ä¸­å®ç°å·®åˆ†éšç§ï¼ˆDPï¼‰ä¿è¯ã€‚</li>
<li>PSAç®—æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œå®ç°äº†DPä¿è¯çš„åŒæ—¶ä¿æŒè¾ƒä½çš„æ€§èƒ½æŸå¤±ã€‚</li>
<li>é¦–æ¬¡æå‡ºäº†é’ˆå¯¹æ¿€æ´»ç¼–è¾‘é—®é¢˜çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼ˆMIAï¼‰ï¼Œç”¨äºè¯„ä¼°å’Œå®¡è®¡LLMçš„å®è¯éšç§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18532">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31d877c40c3c49d08fcc197ebe9e5b68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00b9f8c2b506fd246abdc67ce0b871af.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee09b3336ed53c00f8c7f517987f39fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7a69778b17c22e6acb743ac0b203a11.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="GuardReasoner-Towards-Reasoning-based-LLM-Safeguards"><a href="#GuardReasoner-Towards-Reasoning-based-LLM-Safeguards" class="headerlink" title="GuardReasoner: Towards Reasoning-based LLM Safeguards"></a>GuardReasoner: Towards Reasoning-based LLM Safeguards</h2><p><strong>Authors:Yue Liu, Hongcheng Gao, Shengfang Zhai, Jun Xia, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, Bryan Hooi</strong></p>
<p>As LLMs increasingly impact safety-critical applications, ensuring their safety using guardrails remains a key challenge. This paper proposes GuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to reason. Concretely, we first create the GuardReasonerTrain dataset, which consists of 127K samples with 460K detailed reasoning steps. Then, we introduce reasoning SFT to unlock the reasoning capability of guard models. In addition, we present hard sample DPO to further strengthen their reasoning ability. In this manner, GuardReasoner achieves better performance, explainability, and generalizability. Extensive experiments and analyses on 13 benchmarks of 3 guardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B surpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on average. We release the training data, code, and models with different scales (1B, 3B, 8B) of GuardReasoner : <a target="_blank" rel="noopener" href="https://github.com/yueliu1999/GuardReasoner/">https://github.com/yueliu1999/GuardReasoner/</a>. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹å®‰å…¨å…³é”®åº”ç”¨çš„å½±å“æ—¥ç›Šå¢åŠ ï¼Œä½¿ç”¨æŠ¤æ ç¡®ä¿å®ƒä»¬çš„å®‰å…¨ä»æ˜¯å…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†GuardReasonerï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨ä¿éšœæªæ–½ï¼Œå®ƒé€šè¿‡å¼•å¯¼é˜²æŠ¤æ¨¡å‹å­¦ä¹ æ¨ç†æ¥å®ç°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†GuardReasonerTrainæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«12.7ä¸‡ä¸ªæ ·æœ¬å’Œ460ä¸‡ä¸ªè¯¦ç»†çš„æ¨ç†æ­¥éª¤ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥æ¨ç†SFTæ¥è§£é”é˜²æŠ¤æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ç¡¬æ ·æœ¬DPOæ¥è¿›ä¸€æ­¥å¢å¼ºå…¶æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒGuardReasonerå®ç°äº†æ›´å¥½çš„æ€§èƒ½ã€è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨ä¸‰ä¸ªé˜²æŠ¤æ ä»»åŠ¡çš„13ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒå’Œåˆ†æè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGuardReasoner 8Båœ¨F1åˆ†æ•°ä¸Šå¹³å‡è¶…è¿‡äº†GPT-4o+CoT 5.74%ï¼Œä»¥åŠLLaMA Guard 3 8B 20.84%ã€‚æˆ‘ä»¬å‘å¸ƒäº†ä¸åŒè§„æ¨¡ï¼ˆ1Bã€3Bã€8Bï¼‰çš„GuardReasonerçš„è®­ç»ƒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹ï¼š<a target="_blank" rel="noopener" href="https://github.com/yueliu1999/GuardReasoner/">https://github.com/yueliu1999/GuardReasoner/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18492v1">PDF</a> 22 pages, 18 figures</p>
<p><strong>Summary</strong></p>
<p>GuardReasoneræ˜¯ä¸€ç§ä¸ºLLMsæä¾›å®‰å…¨ä¿éšœçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡å¼•å¯¼æ¨¡å‹å­¦ä¹ æ¨ç†èƒ½åŠ›æ¥è§£å†³å®‰å…¨å…³é”®é—®é¢˜ã€‚è¯¥ç ”ç©¶åˆ›å»ºäº†GuardReasonerTrainæ•°æ®é›†ï¼Œå¼•å…¥æ¨ç†SFTï¼Œå¹¶æå‡ºç¡¬æ ·æœ¬DPOæ¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚GuardReasoneråœ¨æ€§èƒ½ã€è§£é‡Šæ€§å’Œé€šç”¨æ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ•ˆæœï¼Œåœ¨13ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„å¹³å‡F1åˆ†æ•°è¶…è¿‡äº†GPT-4o+CoTå’ŒLLaMA Guard 3 8Bã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨å®‰å…¨æ€§å…³é”®åº”ç”¨ä¸­çš„å®‰å…¨ä¿è¯æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚</li>
<li>GuardReasoneræ˜¯ä¸€ç§æ–°çš„LLMsä¿éšœæ–¹æ³•ï¼Œé€šè¿‡å¼•å¯¼æ¨¡å‹å­¦ä¹ æ¨ç†æ¥è§£å†³å®‰å…¨å…³é”®é—®é¢˜ã€‚</li>
<li>ç ”ç©¶äººå‘˜åˆ›å»ºäº†GuardReasonerTrainæ•°æ®é›†ï¼ŒåŒ…å«127Kæ ·æœ¬å’Œ460Kè¯¦ç»†æ¨ç†æ­¥éª¤ã€‚</li>
<li>å¼•å…¥æ¨ç†SFTè§£é”äº†æ¨¡å‹çš„å®‰å…¨ä¿éšœèƒ½åŠ›ã€‚</li>
<li>ç¡¬æ ·æœ¬DPOçš„æå‡ºè¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>GuardReasoneråœ¨æ€§èƒ½ã€è§£é‡Šæ€§å’Œé€šç”¨æ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18492">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ee25be30698d78458353cb2a0bcc5d94.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-928453f03edd2b7c2849d07fc01e0dea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af1cf5ebbd07a337a201fb94a637b8bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2dd901ef26c272d2a51c452ce2d3dfa3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ecbbd0f6a28a0092276966743f06487.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-25a66ff263223b297d0cfbd10b17ad53.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Tool-for-In-depth-Analysis-of-Code-Execution-Reasoning-of-Large-Language-Models"><a href="#A-Tool-for-In-depth-Analysis-of-Code-Execution-Reasoning-of-Large-Language-Models" class="headerlink" title="A Tool for In-depth Analysis of Code Execution Reasoning of Large   Language Models"></a>A Tool for In-depth Analysis of Code Execution Reasoning of Large   Language Models</h2><p><strong>Authors:Changshu Liu, Reyhaneh Jabbarvand</strong></p>
<p>Code Executing Reasoning is becoming a new non-functional metric that assesses the ability of large language models (LLMs) in programming tasks. State-of-the-art frameworks (CodeMind or REval) and benchmarks (CruxEval) usually focus on LLMâ€™s prediction of a given codeâ€™s input&#x2F;output or intermediate variable states&#x2F;values on limited programs. However, there is no tool for more in-depth analysis of the results. Without such a tool, the observations about LLMâ€™s code execution reasoning cannot be generalized to more datasets, preventing the research community and practitioners from devising the next generation of LLMs with better code execution reasoning abilities. This paper introduces ExeRScope, a series of tools and heuristics to analyze the result of code execution reasoning frameworks to understand better the impact of code properties in the studied benchmarks on the code execution reasoning. With such tooling, analysis can be generalized to code with similar properties without the urgent need to design more benchmarks, which is a cumbersome effort. </p>
<blockquote>
<p>ä»£ç æ‰§è¡Œæ¨ç†æ­£æˆä¸ºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­çš„èƒ½åŠ›çš„æ–°éåŠŸèƒ½æ€§æŒ‡æ ‡ã€‚å…ˆè¿›æ¡†æ¶ï¼ˆå¦‚CodeMindæˆ–REvalï¼‰å’ŒåŸºå‡†æµ‹è¯•ï¼ˆå¦‚CruxEvalï¼‰é€šå¸¸ä¾§é‡äºLLMå¯¹ç»™å®šä»£ç çš„è¾“å…¥&#x2F;è¾“å‡ºçš„é¢„æµ‹ï¼Œæˆ–åœ¨æœ‰é™ç¨‹åºä¸Šçš„ä¸­é—´å˜é‡çŠ¶æ€&#x2F;å€¼ã€‚ç„¶è€Œï¼Œæ²¡æœ‰å·¥å…·å¯¹ç»“æœè¿›è¡Œæ·±å…¥åˆ†æã€‚æ²¡æœ‰è¿™æ ·çš„å·¥å…·ï¼Œå…³äºLLMä»£ç æ‰§è¡Œæ¨ç†çš„è§‚å¯Ÿç»“æœæ— æ³•æ¨å¹¿åˆ°æ›´å¤šæ•°æ®é›†ï¼Œé˜»ç¢äº†ç ”ç©¶ç•Œå’Œå®è·µè€…å¼€å‘å…·æœ‰æ›´å¥½ä»£ç æ‰§è¡Œæ¨ç†èƒ½åŠ›çš„æ–°ä¸€ä»£LLMã€‚æœ¬æ–‡ä»‹ç»äº†ExeRScopeï¼Œè¿™æ˜¯ä¸€ç³»åˆ—å·¥å…·å’Œå¯å‘å¼æ–¹æ³•æ¥åˆ†æä»£ç æ‰§è¡Œæ¨ç†æ¡†æ¶çš„ç»“æœï¼Œä»¥æ›´å¥½åœ°äº†è§£ç ”ç©¶ä¸­ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­ä»£ç å±æ€§å¯¹ä»£ç æ‰§è¡Œæ¨ç†çš„å½±å“ã€‚å€ŸåŠ©è¿™ç§å·¥å…·ï¼Œå¯ä»¥æ¨å¹¿åˆ°å…·æœ‰ç±»ä¼¼å±æ€§çš„ä»£ç ï¼Œè€Œæ— éœ€è¿«åˆ‡è®¾è®¡æ›´å¤šçš„åŸºå‡†æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€é¡¹ç¹ççš„å·¥ä½œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18482v1">PDF</a> 5 pages</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç æ‰§è¡Œèƒ½åŠ›è¯„ä¼°æˆä¸ºäº†ä¸€ä¸ªæ–°çš„éåŠŸèƒ½åº¦é‡æ ‡å‡†ï¼Œä¸“æ³¨äºå¯¹ç¼–ç¨‹ä»»åŠ¡çš„è¯„ä¼°ã€‚ç°æœ‰æ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨LLMå¯¹ç»™å®šä»£ç çš„è¾“å…¥&#x2F;è¾“å‡ºçš„é¢„æµ‹ï¼Œæˆ–è€…å…³æ³¨æœ‰é™ç¨‹åºä¸Šçš„ä¸­é—´å˜é‡çŠ¶æ€å’Œå€¼ã€‚ç„¶è€Œï¼Œç¼ºä¹æ·±å…¥åˆ†æç»“æœçš„å·¥å…·ï¼Œå› æ­¤æ— æ³•æ¦‚æ‹¬è§‚å¯Ÿåˆ°çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç æ‰§è¡Œæ¨ç†åˆ°æ›´å¤šæ•°æ®é›†ä¸Šï¼Œé˜»ç¢äº†ä¸‹ä¸€ä»£å…·æœ‰æ›´å¥½ä»£ç æ‰§è¡Œæ¨ç†èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„å‘å±•ã€‚æœ¬æ–‡ä»‹ç»äº†ExeRScopeå·¥å…·ç³»åˆ—ï¼Œå®ƒç”¨äºåˆ†æä»£ç æ‰§è¡Œæ¨ç†æ¡†æ¶çš„ç»“æœï¼Œæ›´å¥½åœ°ç†è§£ä»£ç å±æ€§å¯¹åŸºå‡†æµ‹è¯•çš„å½±å“ï¼Œä»è€Œå®ç°å¯¹è¯¥åˆ†æçš„å·¥å…·åŒ–ã€‚è¿™å¯ä»¥åœ¨æ— éœ€è®¾è®¡æ›´å¤šåŸºå‡†æµ‹è¯•çš„æƒ…å†µä¸‹æ¨å¹¿åˆ°å…·æœ‰ç±»ä¼¼å±æ€§çš„ä»£ç ä¸Šã€‚ExeRScopeæœ‰æœ›æˆä¸ºç†è§£LLMåœ¨å¤„ç†ä¸åŒå±æ€§ä»£ç æ—¶æ¨ç†èƒ½åŠ›çš„æœ‰åŠ›å·¥å…·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»£ç æ‰§è¡Œæ¨ç†æˆä¸ºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°éåŠŸèƒ½åº¦é‡æ ‡å‡†ã€‚</li>
<li>å½“å‰æ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­åœ¨LLMå¯¹ç»™å®šä»£ç çš„é¢„æµ‹èƒ½åŠ›ä¸Šï¼Œç¼ºä¹æ·±åº¦åˆ†æç»“æœå·¥å…·ã€‚</li>
<li>LLMçš„ä»£ç æ‰§è¡Œæ¨ç†è§‚å¯Ÿæ— æ³•æ¨å¹¿åˆ°æ›´å¤šæ•°æ®é›†ä¸Šï¼Œé™åˆ¶äº†ç ”ç©¶å’Œåº”ç”¨çš„è¿›ä¸€æ­¥å‘å±•ã€‚</li>
<li>æœ¬è®ºæ–‡ä»‹ç»äº†ExeRScopeå·¥å…·ç³»åˆ—ï¼Œæ—¨åœ¨åˆ†æä»£ç æ‰§è¡Œæ¨ç†æ¡†æ¶çš„ç»“æœã€‚</li>
<li>ExeRScopeèƒ½å¤Ÿå¸®åŠ©ç†è§£ä»£ç å±æ€§å¯¹åŸºå‡†æµ‹è¯•çš„å½±å“ï¼Œè¿›è€Œæ¨å¹¿åˆ†æåˆ°å…·æœ‰ç±»ä¼¼å±æ€§çš„ä»£ç ä¸Šã€‚</li>
<li>ä½¿ç”¨ExeRScopeå·¥å…·ç³»åˆ—æ— éœ€è®¾è®¡æ›´å¤šçš„åŸºå‡†æµ‹è¯•ï¼Œæé«˜äº†æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18482">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5bd91860961ac89926192191a95e571b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6416440a6c36b8a44eafa44821d7a8b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-928492ecb6f0644e525fdf527fa8df87.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ad9e41322dc977c41e375d1ee6f72c5a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="CLoQ-Enhancing-Fine-Tuning-of-Quantized-LLMs-via-Calibrated-LoRA-Initialization"><a href="#CLoQ-Enhancing-Fine-Tuning-of-Quantized-LLMs-via-Calibrated-LoRA-Initialization" class="headerlink" title="CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA   Initialization"></a>CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA   Initialization</h2><p><strong>Authors:Yanxia Deng, Aozhong Zhang, Naigang Wang, Selcuk Gurses, Zi Yang, Penghang Yin</strong></p>
<p>Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has become a highly efficient approach for downstream tasks, particularly in scenarios with limited computational resources. However, applying LoRA techniques to quantized LLMs poses unique challenges due to the reduced representational precision of quantized weights. In this paper, we introduce CLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic initialization strategy designed to overcome these challenges. Our approach focuses on minimizing the layer-wise discrepancy between the original LLM and its quantized counterpart with LoRA components during initialization. By leveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and determines the optimal LoRA components for each layer, ensuring a strong foundation for subsequent fine-tuning. A key contribution of this work is a novel theoretical result that enables the accurate and closed-form construction of these optimal LoRA components. We validate the efficacy of CLoQ across multiple tasks such as language generation, arithmetic reasoning, and commonsense reasoning, demonstrating that it consistently outperforms existing LoRA fine-tuning methods for quantized LLMs, especially at ultra low-bit widths. </p>
<blockquote>
<p>ä½¿ç”¨ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¾®è°ƒå·²æˆä¸ºä¸€ç§é«˜æ•ˆçš„ä¸‹æ¸¸ä»»åŠ¡å¤„ç†æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚ç„¶è€Œï¼Œç”±äºé‡åŒ–æƒé‡è¡¨ç¤ºç²¾åº¦çš„é™ä½ï¼Œå°†LoRAæŠ€æœ¯åº”ç”¨äºé‡åŒ–LLMé¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†é’ˆå¯¹é‡åŒ–LLMçš„æ ¡å‡†LoRAåˆå§‹åŒ–ï¼ˆCLoQï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œæ—¨åœ¨å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¾§é‡äºåœ¨åˆå§‹åŒ–æœŸé—´æœ€å°åŒ–åŸå§‹LLMå’Œå…¶é‡åŒ–å¯¹åº”ä¹‹é—´çš„é€å±‚å·®å¼‚ï¼ŒåŒæ—¶åŒ…å«LoRAç»„ä»¶ã€‚é€šè¿‡åˆ©ç”¨ä¸€ä¸ªå°å‹æ ¡å‡†æ•°æ®é›†ï¼ŒCLoQå¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œé‡åŒ–ï¼Œå¹¶ç¡®å®šæ¯å±‚çš„æœ€ä½³LoRAç»„ä»¶ï¼Œä¸ºç¡®ä¿éšåçš„å¾®è°ƒå¥ å®šåšå®åŸºç¡€ã€‚è¿™é¡¹å·¥ä½œçš„ä¸€ä¸ªé‡è¦è´¡çŒ®æ˜¯ä¸€ä¸ªæ–°çš„ç†è®ºç»“æœï¼Œå®ƒèƒ½å¤Ÿå®ç°è¿™äº›æœ€ä½³LoRAç»„ä»¶çš„ç²¾ç¡®å’Œå°é—­å½¢å¼æ„é€ ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªä»»åŠ¡ä¸ŠéªŒè¯äº†CLoQçš„æœ‰æ•ˆæ€§ï¼Œå¦‚è¯­è¨€ç”Ÿæˆã€ç®—æœ¯æ¨ç†å’Œå¸¸è¯†æ¨ç†ï¼Œè¯æ˜å®ƒåœ¨é‡åŒ–LLMçš„LoRAå¾®è°ƒæ–¹æ³•ä¸Šå§‹ç»ˆè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨è¶…ä½ä½å®½åº¦ä¸‹æ›´æ˜¯å¦‚æ­¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18475v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é‡‡ç”¨ä½ç§©é€‚é…ï¼ˆLoRAï¼‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¾®è°ƒï¼Œå·²æˆä¸ºä¸€ç§é«˜æ•ˆçš„ä¸‹æ¸¸ä»»åŠ¡å¤„ç†æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚ç„¶è€Œï¼Œå°†LoRAæŠ€æœ¯åº”ç”¨äºé‡åŒ–LLMæ—¶ï¼Œç”±äºé‡åŒ–æƒé‡çš„è¡¨ç¤ºç²¾åº¦é™ä½ï¼Œä¼šé¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ä¸ºé‡åŒ–LLMè®¾è®¡çš„ç®€æ´åˆå§‹åŒ–ç­–ç•¥â€”â€”CLoQï¼ˆç”¨äºé‡åŒ–LLMçš„æ ¡å‡†LoRAåˆå§‹åŒ–ï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¾§é‡äºåœ¨åˆå§‹åŒ–æœŸé—´æœ€å°åŒ–åŸå§‹LLMå’Œå…¶å¸¦æœ‰LoRAç»„ä»¶çš„é‡åŒ–å¯¹åº”ç‰ˆæœ¬ä¹‹é—´çš„é€å±‚å·®å¼‚ã€‚é€šè¿‡åˆ©ç”¨ä¸€ä¸ªå°å‹æ ¡å‡†æ•°æ®é›†ï¼ŒCLoQå¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œé‡åŒ–ï¼Œå¹¶ä¸ºæ¯å±‚ç¡®å®šæœ€ä½³çš„LoRAç»„ä»¶ï¼Œä»è€Œä¸ºéšåçš„å¾®è°ƒå¥ å®šåšå®åŸºç¡€ã€‚æœ¬å·¥ä½œçš„ä¸€ä¸ªå…³é”®è´¡çŒ®æ˜¯æä¾›äº†ä¸€ä¸ªæ–°çš„ç†è®ºç»“æœï¼Œèƒ½å¤Ÿå®ç°è¿™äº›æœ€ä½³LoRAç»„ä»¶çš„ç²¾ç¡®å’Œå°é—­å½¢å¼æ„é€ ã€‚æˆ‘ä»¬åœ¨è¯­è¨€ç”Ÿæˆã€ç®—æœ¯æ¨ç†å’Œå¸¸è¯†æ¨ç†ç­‰å¤šé¡¹ä»»åŠ¡ä¸ŠéªŒè¯äº†CLoQçš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å®ƒåœ¨è¶…ä½ä½å®½ä¸‹å°¤å…¶å‡ºè‰²ï¼Œå¹¶ä¸”å§‹ç»ˆä¼˜äºç°æœ‰çš„é’ˆå¯¹é‡åŒ–LLMçš„LoRAå¾®è°ƒæ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>CLoQæ˜¯ä¸€ç§é’ˆå¯¹é‡åŒ–LLMçš„åˆå§‹åŒ–ç­–ç•¥ï¼Œæ—¨åœ¨å…‹æœåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ç”±äºé‡åŒ–æƒé‡çš„è¡¨ç¤ºç²¾åº¦é™ä½è€Œé¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>CLoQä¾§é‡äºåœ¨åˆå§‹åŒ–é˜¶æ®µæœ€å°åŒ–åŸå§‹LLMå’Œé‡åŒ–æ¨¡å‹ä¹‹é—´çš„é€å±‚å·®å¼‚ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨æ ¡å‡†æ•°æ®é›†ï¼ŒCLoQèƒ½ç¡®ä¿å¯¹é¢„è®­ç»ƒLLMçš„å‡†ç¡®é‡åŒ–ï¼Œå¹¶ä¸ºæ¯ä¸€å±‚ç¡®å®šæœ€ä½³çš„LoRAç»„ä»¶ã€‚</li>
<li>CLoQåŒ…å«ä¸€ç§æ–°ç†è®ºï¼Œå¯ä»¥ç²¾ç¡®è®¡ç®—è¿™äº›æœ€ä½³LoRAç»„ä»¶ã€‚</li>
<li>åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¿›è¡Œçš„å®éªŒè¯æ˜ï¼ŒCLoQåœ¨è¶…ä½ä½å®½ä¸‹è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„é’ˆå¯¹é‡åŒ–LLMçš„LoRAå¾®è°ƒæ–¹æ³•ã€‚è¿™è¡¨æ˜CLoQåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚</li>
<li>CLoQç­–ç•¥å…·æœ‰æ™®éé€‚ç”¨æ€§ï¼Œå¯ä»¥åº”ç”¨äºä¸åŒçš„è¯­è¨€ç”Ÿæˆã€ç®—æœ¯æ¨ç†å’Œå¸¸è¯†æ¨ç†ç­‰ä»»åŠ¡åœºæ™¯ã€‚</li>
<li>CLoQæœ‰åŠ©äºæå‡é‡åŒ–LLMçš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18475">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fe7a238e00b7ec4f60b0a61bd4bbad55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73ad83057b9bd36f5f326303386b6f6e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7a7751747cf65ecae78654283b0a6a7b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff7c8a0092825fd84f23b91242d7b598.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcc1e00812a5553b6bdb6ccd2f33b951.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="ExeCoder-Empowering-Large-Language-Models-with-Executability-Representation-for-Code-Translation"><a href="#ExeCoder-Empowering-Large-Language-Models-with-Executability-Representation-for-Code-Translation" class="headerlink" title="ExeCoder: Empowering Large Language Models with Executability   Representation for Code Translation"></a>ExeCoder: Empowering Large Language Models with Executability   Representation for Code Translation</h2><p><strong>Authors:Minghua He, Fangkai Yang, Pu Zhao, Wenjie Yin, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</strong></p>
<p>Code translation is a crucial activity in the software development and maintenance process, and researchers have recently begun to focus on using pre-trained large language models (LLMs) for code translation. However, existing LLMs only learn the contextual semantics of code during pre-training, neglecting executability information closely related to the execution state of the code, which results in unguaranteed code executability and unreliable automated code translation. To address this issue, we propose ExeCoder, an LLM specifically designed for code translation, aimed at utilizing executability representations such as functional semantics, syntax structures, and variable dependencies to enhance the capabilities of LLMs in code translation. To evaluate the effectiveness of ExeCoder, we manually enhanced the widely used benchmark TransCoder-test, resulting in a benchmark called TransCoder-test-X that serves LLMs. Evaluation of TransCoder-test-X indicates that ExeCoder achieves state-of-the-art performance in code translation, surpassing existing open-source code LLMs by over 10.88% to 38.78% and over 27.44% to 42.97% on two metrics, and even outperforms the renowned closed-source LLM GPT-4o. Website: <a target="_blank" rel="noopener" href="https://execoder4trans.github.io/">https://execoder4trans.github.io/</a> </p>
<blockquote>
<p>ä»£ç ç¿»è¯‘æ˜¯è½¯ä»¶å¼€å‘å’Œç»´æŠ¤è¿‡ç¨‹ä¸­çš„ä¸€é¡¹é‡è¦æ´»åŠ¨ï¼Œæœ€è¿‘ç ”ç©¶è€…å¼€å§‹å…³æ³¨ä½¿ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œä»£ç ç¿»è¯‘ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMä»…åœ¨é¢„è®­ç»ƒæœŸé—´å­¦ä¹ ä»£ç ä¸Šä¸‹æ–‡è¯­ä¹‰ï¼Œå¿½ç•¥äº†ä¸ä»£ç æ‰§è¡ŒçŠ¶æ€å¯†åˆ‡ç›¸å…³çš„å¯æ‰§è¡Œä¿¡æ¯ï¼Œå¯¼è‡´ä»£ç æ‰§è¡Œæ€§æ— æ³•ä¿è¯å’Œè‡ªåŠ¨åŒ–ä»£ç ç¿»è¯‘ä¸å¯é ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ExeCoderï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºä»£ç ç¿»è¯‘çš„è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨åˆ©ç”¨å¯æ‰§è¡Œæ€§è¡¨ç¤ºï¼ˆå¦‚åŠŸèƒ½è¯­ä¹‰ã€è¯­æ³•ç»“æ„å’Œå˜é‡ä¾èµ–å…³ç³»ï¼‰ï¼Œä»¥å¢å¼ºLLMåœ¨ä»£ç ç¿»è¯‘æ–¹é¢çš„èƒ½åŠ›ã€‚ä¸ºäº†è¯„ä¼°ExeCoderçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¢å¼ºäº†å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•TransCoder-testï¼Œä»è€Œå½¢æˆäº†åä¸ºTransCoder-test-Xçš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºæµ‹è¯•LLMã€‚å¯¹TransCoder-test-Xçš„è¯„ä¼°è¡¨æ˜ï¼ŒExeCoderåœ¨ä»£ç ç¿»è¯‘æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œåœ¨ä¸¤é¡¹æŒ‡æ ‡ä¸Šåˆ†åˆ«è¶…è¿‡äº†ç°æœ‰å¼€æºä»£ç LLMè¶…è¿‡10.88%è‡³38.78%å’Œè¶…è¿‡27.44%è‡³42.97%ï¼Œç”šè‡³è¶…è¿‡äº†è‘—åçš„é—­æºLLM GPT-4oã€‚ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://execoder4trans.github.io/%EF%BC%88%E6%B3%A8%EF%BC%9A%E7%94%B1%E4%BA%8E%E6%88%91%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%87%E5%AD%97AI%EF%BC%8C%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E7%BD%91%E5%9D%80%EF%BC%89%E3%80%82">https://execoder4trans.github.io/ï¼ˆæ³¨ï¼šç”±äºæˆ‘æ˜¯ä¸€ä¸ªæ–‡å­—AIï¼Œæ— æ³•æ‰“å¼€ç½‘å€ï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18460v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä»£ç ç¿»è¯‘ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œä½†ç°æœ‰LLMä»…å­¦ä¹ ä»£ç ä¸Šä¸‹æ–‡è¯­ä¹‰ï¼Œå¿½ç•¥äº†ä¸æ‰§è¡ŒçŠ¶æ€å¯†åˆ‡ç›¸å…³çš„å¯æ‰§è¡Œæ€§ä¿¡æ¯ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸“ä¸ºä»£ç ç¿»è¯‘è®¾è®¡çš„ExeCoderï¼Œæ—¨åœ¨åˆ©ç”¨åŠŸèƒ½è¯­ä¹‰ã€è¯­æ³•ç»“æ„å’Œå˜é‡ä¾èµ–ç­‰å¯æ‰§è¡Œæ€§è¡¨ç¤ºæ¥å¢å¼ºLLMåœ¨ä»£ç ç¿»è¯‘æ–¹é¢çš„èƒ½åŠ›ã€‚è¯„ä¼°æ˜¾ç¤ºï¼ŒExeCoderåœ¨ä»£ç ç¿»è¯‘æ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œåœ¨æŸäº›æŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰å¼€æºä»£ç LLMé«˜è¾¾38.78%ï¼Œç”šè‡³è¶…è¿‡äº†è‘—åçš„é—­æºLLM GPT-4oã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è½¯ä»¶å¼€å‘çš„ä»£ç ç¿»è¯‘ä¸­å æ®é‡è¦åœ°ä½ã€‚</li>
<li>ç°æœ‰LLMä¸»è¦å­¦ä¹ ä»£ç çš„ä¸Šä¸‹æ–‡è¯­ä¹‰ï¼Œå¿½ç•¥äº†ä¸æ‰§è¡ŒçŠ¶æ€ç›¸å…³çš„å¯æ‰§è¡Œæ€§ä¿¡æ¯ã€‚</li>
<li>ä¸ºäº†æ”¹å–„è¿™ä¸€é—®é¢˜ï¼Œæ¨å‡ºExeCoderæ¨¡å‹ï¼Œä¸“é—¨ç”¨äºä»£ç ç¿»è¯‘ï¼Œæ³¨é‡åŠŸèƒ½è¯­ä¹‰ã€è¯­æ³•ç»“æ„å’Œå˜é‡ä¾èµ–ç­‰æ–¹é¢ã€‚</li>
<li>åœ¨å¹¿æ³›ä½¿ç”¨çš„TransCoder-teståŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†æ”¹è¿›ï¼Œåˆ›å»ºäº†TransCoder-test-XåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°LLMæ€§èƒ½ã€‚</li>
<li>è¯„ä¼°æ˜¾ç¤ºExeCoderåœ¨ä»£ç ç¿»è¯‘æ–¹é¢è¡¨ç°å“è¶Šï¼Œåœ¨æŸäº›æŒ‡æ ‡ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰å¼€æºä»£ç LLMå’ŒGPT-4oæ¨¡å‹ã€‚</li>
<li>ExeCoderåˆ©ç”¨å¯æ‰§è¡Œæ€§è¡¨ç¤ºæ¥å¢å¼ºå…¶åœ¨ä»£ç ç¿»è¯‘æ–¹é¢çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18460">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-acae2ea8bdec9c4276d72520e33cedd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-649f3243d966965bf58f09b3e91d953e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b42902572737bd59d4beff1a774a1e5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3e6b55c43425c8fa2b02a276f0b636a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-08112dfbf6b3a3d678555280d2e1f60d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="xJailbreak-Representation-Space-Guided-Reinforcement-Learning-for-Interpretable-LLM-Jailbreaking"><a href="#xJailbreak-Representation-Space-Guided-Reinforcement-Learning-for-Interpretable-LLM-Jailbreaking" class="headerlink" title="xJailbreak: Representation Space Guided Reinforcement Learning for   Interpretable LLM Jailbreaking"></a>xJailbreak: Representation Space Guided Reinforcement Learning for   Interpretable LLM Jailbreaking</h2><p><strong>Authors:Sunbowen Lee, Shiwen Ni, Chi Wei, Shuaimin Li, Liyang Fan, Ahmadreza Argha, Hamid Alinejad-Rokny, Ruifeng Xu, Yicheng Gong, Min Yang</strong></p>
<p>Safety alignment mechanism are essential for preventing large language models (LLMs) from generating harmful information or unethical content. However, cleverly crafted prompts can bypass these safety measures without accessing the modelâ€™s internal parameters, a phenomenon known as black-box jailbreak. Existing heuristic black-box attack methods, such as genetic algorithms, suffer from limited effectiveness due to their inherent randomness, while recent reinforcement learning (RL) based methods often lack robust and informative reward signals. To address these challenges, we propose a novel black-box jailbreak method leveraging RL, which optimizes prompt generation by analyzing the embedding proximity between benign and malicious prompts. This approach ensures that the rewritten prompts closely align with the intent of the original prompts while enhancing the attackâ€™s effectiveness. Furthermore, we introduce a comprehensive jailbreak evaluation framework incorporating keywords, intent matching, and answer validation to provide a more rigorous and holistic assessment of jailbreak success. Experimental results show the superiority of our approach, achieving state-of-the-art (SOTA) performance on several prominent open and closed-source LLMs, including Qwen2.5-7B-Instruct, Llama3.1-8B-Instruct, and GPT-4o-0806. Our method sets a new benchmark in jailbreak attack effectiveness, highlighting potential vulnerabilities in LLMs. The codebase for this work is available at <a target="_blank" rel="noopener" href="https://github.com/Aegis1863/xJailbreak">https://github.com/Aegis1863/xJailbreak</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨å¯¹é½æœºåˆ¶å¯¹äºé˜²æ­¢ç”Ÿæˆæœ‰å®³ä¿¡æ¯æˆ–ä¸é“å¾·å†…å®¹è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç²¾å¿ƒè®¾è®¡çš„æç¤ºå¯ä»¥ç»•è¿‡è¿™äº›å®‰å…¨æªæ–½ï¼Œè€Œæ— éœ€è®¿é—®æ¨¡å‹çš„å†…éƒ¨å‚æ•°ï¼Œè¿™ä¸€ç°è±¡è¢«ç§°ä¸ºâ€œé»‘ç®±çªç ´â€ã€‚ç°æœ‰çš„å¯å‘å¼é»‘ç®±æ”»å‡»æ–¹æ³•ï¼Œå¦‚é—ä¼ ç®—æ³•ï¼Œç”±äºå…¶å›ºæœ‰çš„éšæœºæ€§è€Œæ•ˆæœæœ‰é™ï¼Œè€Œæœ€è¿‘çš„åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•å¾€å¾€ç¼ºä¹ç¨³å¥å’Œæœ‰ç”¨çš„å¥–åŠ±ä¿¡å·ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å¼ºåŒ–å­¦ä¹ çš„æ–°å‹é»‘ç®±çªç ´æ–¹æ³•ï¼Œé€šè¿‡åˆ†æå’Œä¼˜åŒ–è‰¯æ€§æç¤ºå’Œæ¶æ„æç¤ºä¹‹é—´çš„åµŒå…¥æ¥è¿‘åº¦æ¥ä¼˜åŒ–æç¤ºç”Ÿæˆã€‚è¿™ç§æ–¹æ³•ç¡®ä¿äº†é‡å†™åçš„æç¤ºä¸åŸå§‹æç¤ºçš„æ„å›¾ç´§å¯†å¯¹é½ï¼ŒåŒæ—¶æé«˜äº†æ”»å‡»çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå…¨é¢çš„çªç ´è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬å…³é”®è¯ã€æ„å›¾åŒ¹é…å’Œç­”æ¡ˆéªŒè¯ï¼Œä»¥æä¾›æ›´ä¸¥æ ¼å’Œå…¨é¢çš„çªç ´æˆåŠŸè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ï¼Œåœ¨åŒ…æ‹¬Qwen2.5-7B-Instructã€Llama3.1-8B-Instructå’ŒGPT-4o-0806ç­‰å¤šä¸ªçŸ¥åå¼€æºå’Œé—­æºLLMä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºçªç ´æ”»å‡»çš„æœ‰æ•ˆæ€§è®¾å®šäº†æ–°çš„åŸºå‡†ï¼Œçªå‡ºäº†LLMçš„æ½œåœ¨æ¼æ´ã€‚è¯¥å·¥ä½œçš„ä»£ç åº“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Aegis1863/xJailbreak%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Aegis1863/xJailbreakæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16727v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨å¯¹é½æœºåˆ¶å¯¹äºé˜²æ­¢ç”Ÿæˆæœ‰å®³ä¿¡æ¯è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå·§å¦™è®¾è®¡çš„æç¤ºå¯ä»¥ç»•è¿‡è¿™äº›å®‰å…¨æªæ–½è€Œä¸æ¥è§¦æ¨¡å‹çš„å†…éƒ¨å‚æ•°ï¼Œè¿™ç§ç°è±¡è¢«ç§°ä¸ºé»‘ç®±è¶Šç‹±ã€‚é’ˆå¯¹ç°æœ‰å¯å‘å¼é»‘ç®±æ”»å‡»æ–¹æ³•ï¼ˆå¦‚é—ä¼ ç®—æ³•ï¼‰çš„å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„é»‘ç®±è¶Šç‹±æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¼˜åŒ–æç¤ºç”Ÿæˆï¼Œåˆ†æè‰¯æ€§æç¤ºå’Œæ¶æ„æç¤ºä¹‹é—´çš„åµŒå…¥æ¥è¿‘åº¦ï¼Œç¡®ä¿é‡å†™æç¤ºä¸åŸå§‹æç¤ºçš„æ„å›¾ä¸€è‡´ï¼Œæé«˜æ”»å‡»çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªå…¨é¢çš„è¶Šç‹±è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬å…³é”®è¯ã€æ„å›¾åŒ¹é…å’Œç­”æ¡ˆéªŒè¯ï¼Œä¸ºè¶Šç‹±çš„æˆåŠŸæä¾›æ›´ä¸¥æ ¼å’Œå…¨é¢çš„è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³å¹¶åœ¨å‡ ä¸ªçŸ¥åå¼€æºå’Œéå¼€æºLLMä¸Šå–å¾—ä¼˜å¼‚æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ­ç¤ºäº†LLMçš„æ½œåœ¨æ¼æ´å¹¶è®¾å®šäº†æ–°çš„è¶Šç‹±æ”»å‡»æ€§èƒ½åŸºå‡†ã€‚ä»£ç åº“å¯åœ¨xxxä¸Šæ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å®‰å…¨å¯¹é½æœºåˆ¶å¯¹LLMè‡³å…³é‡è¦ï¼Œé˜²æ­¢ç”Ÿæˆæœ‰å®³ä¿¡æ¯ã€‚</li>
<li>é»‘ç®±è¶Šç‹±ç°è±¡æŒ‡ç»•è¿‡LLMå®‰å…¨æœºåˆ¶è€Œä¸æ¥è§¦æ¨¡å‹å†…éƒ¨å‚æ•°çš„ç°è±¡ã€‚</li>
<li>ç°æœ‰å¯å‘å¼é»‘ç®±æ”»å‡»æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œå¦‚é—ä¼ ç®—æ³•çš„éšæœºæ€§å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„å¥–åŠ±ä¿¡å·ä¸è¶³ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„é»‘ç®±è¶Šç‹±æ–°æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–æç¤ºç”Ÿæˆæé«˜æ”»å‡»æ•ˆæœã€‚</li>
<li>å¼•å…¥å…¨é¢çš„è¶Šç‹±è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬å…³é”®è¯åŒ¹é…ã€æ„å›¾åŒ¹é…å’Œç­”æ¡ˆéªŒè¯ï¼Œä¸ºè¯„ä¼°è¶Šç‹±æˆåŠŸæä¾›æ›´ä¸¥æ ¼æ ‡å‡†ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºæ–°æ–¹æ³•åœ¨å¤šä¸ªçŸ¥åLLMä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16727">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-602edd4d141461c1ab42b4ea1e8d7da5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fae8ea64312bd7232b43aee010a21791.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c848dbdd3223107b54edc8311510746.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1bf355ba39a37b066f654e46b8f144aa.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="LLM-AutoDiff-Auto-Differentiate-Any-LLM-Workflow"><a href="#LLM-AutoDiff-Auto-Differentiate-Any-LLM-Workflow" class="headerlink" title="LLM-AutoDiff: Auto-Differentiate Any LLM Workflow"></a>LLM-AutoDiff: Auto-Differentiate Any LLM Workflow</h2><p><strong>Authors:Li Yin, Zhangyang Wang</strong></p>
<p>Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows. Yet, prompt engineering â€“ the task of crafting textual inputs to effectively direct LLMs â€“ remains difficult and labor-intensive, particularly for complex pipelines that combine multiple LLM calls with functional operations like retrieval and data formatting. We introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods (such as Text-Grad) to multi-component, potentially cyclic LLM architectures. Implemented within the AdalFlow library, LLM-AutoDiff treats each textual input as a trainable parameter and uses a frozen backward engine LLM to generate feedback-akin to textual gradients â€“ that guide iterative prompt updates. Unlike prior single-node approaches, LLM-AutoDiff inherently accommodates functional nodes, preserves time-sequential behavior in repeated calls (e.g., multi-hop loops), and combats the â€œlost-in-the-middleâ€ problem by isolating distinct sub-prompts (instructions, formats, or few-shot examples). It further boosts training efficiency by focusing on error-prone samples through selective gradient computation. Across diverse tasks, including single-step classification, multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff consistently outperforms existing textual gradient baselines in both accuracy and training cost. By unifying prompt optimization through a graph-centric lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating LLM workflows - mirroring the transformative role that automatic differentiation libraries have long played in neural network research. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†çš„å½¢æ€ï¼Œä¸ºä»å¤šè·³æ£€ç´¢å’Œé—®ç­”åˆ°è‡ªä¸»ä»£ç†å·¥ä½œæµç¨‹çš„åº”ç”¨ç¨‹åºæä¾›äº†åŠ¨åŠ›ã€‚ç„¶è€Œï¼Œæç¤ºå·¥ç¨‹â€”â€”å³æ„å»ºæ–‡æœ¬è¾“å…¥ä»¥æœ‰æ•ˆæŒ‡å¯¼LLMçš„ä»»åŠ¡â€”â€”ä»ç„¶æ˜¯ä¸€é¡¹å›°éš¾å’ŒåŠ³åŠ¨å¯†é›†çš„å·¥ä½œï¼Œç‰¹åˆ«æ˜¯å¯¹äºå°†å¤šä¸ªLLMè°ƒç”¨ä¸æ£€ç´¢å’Œæ•°æ®æ ¼å¼åŒ–ç­‰åŠŸèƒ½æ“ä½œç›¸ç»“åˆçš„å¤æ‚ç®¡é“ã€‚æˆ‘ä»¬æ¨å‡ºäº†LLM-AutoDiffï¼šä¸€ç§ç”¨äºè‡ªåŠ¨æç¤ºå·¥ç¨‹ï¼ˆAPEï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œå®ƒå°†åŸºäºæ–‡æœ¬çš„æ¢¯åº¦æ–¹æ³•ï¼ˆå¦‚Text-Gradï¼‰æ‰©å±•åˆ°å¤šç»„ä»¶ã€å¯èƒ½å¾ªç¯çš„LLMæ¶æ„ã€‚LLM-AutoDiffåœ¨AdalFlowåº“ä¸­å®ç°ï¼Œå®ƒå°†æ¯ä¸ªæ–‡æœ¬è¾“å…¥è§†ä¸ºå¯è®­ç»ƒå‚æ•°ï¼Œå¹¶ä½¿ç”¨å†»ç»“çš„å‘åå¼•æ“LLMç”Ÿæˆåé¦ˆâ€”â€”ç±»ä¼¼äºæ–‡æœ¬æ¢¯åº¦â€”â€”æ¥æŒ‡å¯¼è¿­ä»£æç¤ºæ›´æ–°ã€‚ä¸åŒäºå…ˆå‰çš„å•ç‚¹æ–¹æ³•ï¼ŒLLM-AutoDiffå¤©ç„¶åœ°å®¹çº³åŠŸèƒ½èŠ‚ç‚¹ï¼Œåœ¨é‡å¤è°ƒç”¨ä¸­ä¿æŒæ—¶é—´é¡ºåºè¡Œä¸ºï¼ˆä¾‹å¦‚ï¼Œå¤šè·³å¾ªç¯ï¼‰ï¼Œå¹¶é€šè¿‡éš”ç¦»ä¸åŒçš„å­æç¤ºï¼ˆæŒ‡ä»¤ã€æ ¼å¼æˆ–å°‘é‡ç¤ºä¾‹ï¼‰æ¥è§£å†³â€œè¿·å¤±åœ¨ä¸­é—´â€çš„é—®é¢˜ã€‚å®ƒè¿›ä¸€æ­¥é€šè¿‡é€‰æ‹©æ€§æ¢¯åº¦è®¡ç®—ä¸“æ³¨äºæ˜“å‡ºé”™æ ·æœ¬ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚åœ¨åŒ…æ‹¬å•æ­¥åˆ†ç±»ã€å¤šè·³æ£€ç´¢é—®ç­”å’Œä»£ç†é©±åŠ¨ç®¡é“ç­‰å¤šæ ·åŒ–ä»»åŠ¡ä¸­ï¼ŒLLM-AutoDiffåœ¨å‡†ç¡®æ€§å’Œè®­ç»ƒæˆæœ¬æ–¹é¢å‡ä¼˜äºç°æœ‰çš„æ–‡æœ¬æ¢¯åº¦åŸºçº¿ã€‚é€šè¿‡å›¾å½¢ä¸­å¿ƒè§†è§’ç»Ÿä¸€æç¤ºä¼˜åŒ–ï¼ŒLLM-AutoDiffä¸ºæ‰©å±•å’Œè‡ªåŠ¨åŒ–LLMå·¥ä½œæµç¨‹æä¾›äº†å¼ºå¤§çš„æ–°èŒƒå¼â€”â€”è¿™åæ˜ äº†è‡ªåŠ¨å¾®åˆ†åº“åœ¨ç¥ç»ç½‘ç»œç ”ç©¶ä¸­é•¿æœŸå‘æŒ¥çš„å˜é©æ€§ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16673v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰å·²ç»é‡å¡‘äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œå¹¿æ³›åº”ç”¨äºå¤šè·³æ£€ç´¢ã€é—®ç­”å’Œè‡ªä¸»ä»£ç†å·¥ä½œæµç¨‹ç­‰åº”ç”¨ã€‚ç„¶è€Œï¼Œæç¤ºå·¥ç¨‹ï¼ˆå³è®¾è®¡æ–‡æœ¬è¾“å…¥ä»¥æœ‰æ•ˆæŒ‡å¯¼LLMçš„ä»»åŠ¡ï¼‰ä»ç„¶å›°éš¾ä¸”åŠ³åŠ¨å¯†é›†ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»“åˆå¤šä¸ªLLMè°ƒç”¨ä¸åŠŸèƒ½æ“ä½œï¼ˆå¦‚æ£€ç´¢å’Œæ•°æ®æ ¼å¼åŒ–ï¼‰çš„å¤æ‚ç®¡é“ä¸­ã€‚æˆ‘ä»¬æ¨å‡ºLLM-AutoDiffï¼šä¸€ç§ç”¨äºè‡ªåŠ¨æç¤ºå·¥ç¨‹ï¼ˆAPEï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œå®ƒå°†æ–‡æœ¬æ¢¯åº¦æ–¹æ³•ï¼ˆå¦‚Text-Gradï¼‰æ‰©å±•åˆ°å¤šç»„ä»¶ã€æ½œåœ¨å¾ªç¯çš„LLMæ¶æ„ã€‚LLM-AutoDiffåœ¨AdalFlowåº“ä¸­å®ç°ï¼Œå®ƒå°†æ¯ä¸ªæ–‡æœ¬è¾“å…¥è§†ä¸ºå¯è®­ç»ƒå‚æ•°ï¼Œå¹¶ä½¿ç”¨å†»ç»“çš„å‘åå¼•æ“LLMç”Ÿæˆåé¦ˆâ€”â€”ç±»ä¼¼äºæ–‡æœ¬æ¢¯åº¦â€”â€”æ¥æŒ‡å¯¼è¿­ä»£æç¤ºæ›´æ–°ã€‚ä¸åŒäºå…ˆå‰çš„å•ç‚¹æ–¹æ³•ï¼ŒLLM-AutoDiffå¤©ç„¶åœ°å®¹çº³åŠŸèƒ½èŠ‚ç‚¹ï¼Œä¿æŒé‡å¤è°ƒç”¨ä¸­çš„æ—¶é—´é¡ºåºè¡Œä¸ºï¼ˆä¾‹å¦‚ï¼Œå¤šè·³å¾ªç¯ï¼‰ï¼Œå¹¶é€šè¿‡éš”ç¦»ä¸åŒçš„å­æç¤ºï¼ˆæŒ‡ä»¤ã€æ ¼å¼æˆ–å°‘é‡ç¤ºä¾‹ï¼‰æ¥è§£å†³â€œè¿·å¤±åœ¨ä¸­é—´â€çš„é—®é¢˜ã€‚å®ƒè¿›ä¸€æ­¥æé«˜è®­ç»ƒæ•ˆç‡ï¼Œé€šè¿‡é€‰æ‹©æ€§æ¢¯åº¦è®¡ç®—ä¸“æ³¨äºæ˜“å‡ºé”™æ ·æœ¬ã€‚åœ¨åŒ…æ‹¬å•æ­¥åˆ†ç±»ã€å¤šè·³æ£€ç´¢é—®ç­”å’Œä»£ç†é©±åŠ¨ç®¡é“ç­‰å¤šæ ·åŒ–ä»»åŠ¡ä¸­ï¼ŒLLM-AutoDiffåœ¨å‡†ç¡®æ€§å’Œè®­ç»ƒæˆæœ¬æ–¹é¢å‡ä¼˜äºç°æœ‰æ–‡æœ¬æ¢¯åº¦åŸºçº¿ã€‚é€šè¿‡å›¾ä¸­å¿ƒé€é•œç»Ÿä¸€æç¤ºä¼˜åŒ–ï¼ŒLLM-AutoDiffä¸ºæ‰©å±•å’Œè‡ªåŠ¨åŒ–LLMå·¥ä½œæµç¨‹æä¾›äº†å¼ºå¤§çš„æ–°èŒƒå¼ï¼Œç±»ä¼¼äºè‡ªåŠ¨å¾®åˆ†åº“åœ¨ç¥ç»ç½‘ç»œç ”ç©¶ä¸­çš„é•¿æœŸä½œç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨NLPé¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼šåŒ…æ‹¬å¤šè·³æ£€ç´¢ã€é—®ç­”å’Œè‡ªä¸»ä»£ç†å·¥ä½œæµç¨‹ç­‰ã€‚</li>
<li>æç¤ºå·¥ç¨‹åœ¨æŒ‡å¯¼LLMä¸­çš„æŒ‘æˆ˜ï¼šéœ€è¦è®¾è®¡æœ‰æ•ˆçš„æ–‡æœ¬è¾“å…¥ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚çš„ç®¡é“ä¸­ç»“åˆå¤šä¸ªLLMè°ƒç”¨å’ŒåŠŸèƒ½æ“ä½œã€‚</li>
<li>LLM-AutoDiffæ¡†æ¶çš„ä»‹ç»ï¼šæ‰©å±•äº†æ–‡æœ¬æ¢¯åº¦æ–¹æ³•è‡³å¤šç»„ä»¶LLMæ¶æ„ï¼Œå®ç°è‡ªåŠ¨æç¤ºå·¥ç¨‹ã€‚</li>
<li>LLM-AutoDiffçš„ä¸»è¦ä¼˜åŠ¿ï¼šèƒ½å¤Ÿå®¹çº³åŠŸèƒ½èŠ‚ç‚¹ã€ä¿æŒæ—¶é—´é¡ºåºè¡Œä¸ºï¼Œè§£å†³â€œè¿·å¤±åœ¨ä¸­é—´â€é—®é¢˜ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>LLM-AutoDiffåœ¨å¤šç§ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼šåŒ…æ‹¬å•æ­¥åˆ†ç±»ã€å¤šè·³æ£€ç´¢é—®ç­”å’Œä»£ç†é©±åŠ¨ç®¡é“ç­‰ï¼Œæ˜¾ç¤ºå‡ºåœ¨å‡†ç¡®æ€§å’Œè®­ç»ƒæˆæœ¬æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>LLM-AutoDiffçš„ç»Ÿä¸€æ–¹æ³•ï¼šé€šè¿‡å›¾ä¸­å¿ƒé€é•œç»Ÿä¸€æç¤ºä¼˜åŒ–ï¼Œä¸ºæ‰©å±•å’Œè‡ªåŠ¨åŒ–LLMå·¥ä½œæµç¨‹æä¾›äº†æ–°èŒƒå¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16673">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8681184a1616789905ffeb6241f4c3f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dce38effb4121f3eacbec53ca24a6c37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6e5a673f0255b153fa7eebca7411234.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Verify-with-Caution-The-Pitfalls-of-Relying-on-Imperfect-Factuality-Metrics"><a href="#Verify-with-Caution-The-Pitfalls-of-Relying-on-Imperfect-Factuality-Metrics" class="headerlink" title="Verify with Caution: The Pitfalls of Relying on Imperfect Factuality   Metrics"></a>Verify with Caution: The Pitfalls of Relying on Imperfect Factuality   Metrics</h2><p><strong>Authors:Ameya Godbole, Robin Jia</strong></p>
<p>Improvements in large language models have led to increasing optimism that they can serve as reliable evaluators of natural language generation outputs. In this paper, we challenge this optimism by thoroughly re-evaluating five state-of-the-art factuality metrics on a collection of 11 datasets for summarization, retrieval-augmented generation, and question answering. We find that these evaluators are inconsistent with each other and often misestimate system-level performance, both of which can lead to a variety of pitfalls. We further show that these metrics exhibit biases against highly paraphrased outputs and outputs that draw upon faraway parts of the source documents. We urge users of these factuality metrics to proceed with caution and manually validate the reliability of these metrics in their domain of interest before proceeding. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ”¹è¿›ï¼Œäººä»¬è¶Šæ¥è¶Šä¹è§‚åœ°è®¤ä¸ºå®ƒä»¬å¯ä»¥ä½œä¸ºè‡ªç„¶è¯­è¨€ç”Ÿæˆè¾“å‡ºçš„å¯é è¯„ä¼°å™¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡é‡æ–°å…¨é¢è¯„ä¼°11ä¸ªæ•°æ®é›†ä¸Šçš„äº”ç§æœ€æ–°äº‹å®æ€§æŒ‡æ ‡ï¼ˆç”¨äºæ€»ç»“ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œé—®ç­”ï¼‰ï¼Œå¯¹è¿™ä¸€ä¹è§‚æƒ…ç»ªæå‡ºäº†æŒ‘æˆ˜ã€‚æˆ‘ä»¬å‘ç°ï¼Œè¿™äº›è¯„ä¼°å™¨å½¼æ­¤ä¹‹é—´å­˜åœ¨ä¸ä¸€è‡´ï¼Œå¹¶ä¸”ç»å¸¸è¯¯ä¼°ç³»ç»Ÿçº§æ€§èƒ½ï¼Œè¿™ä¸¤è€…éƒ½å¯èƒ½å¯¼è‡´å„ç§é™·é˜±ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œè¿™äº›æŒ‡æ ‡å¯¹é«˜åº¦æ”¹è¿°çš„è¾“å‡ºå’Œå¼•ç”¨æºæ–‡æ¡£è¿œç«¯çš„è¾“å‡ºå­˜åœ¨åè§ã€‚æˆ‘ä»¬æ•¦ä¿ƒä½¿ç”¨è¿™äº›äº‹å®æ€§æŒ‡æ ‡çš„ç”¨æˆ·åº”è°¨æ…è¡Œäº‹ï¼Œå¹¶åœ¨ç»§ç»­ä¹‹å‰åœ¨å…¶æ„Ÿå…´è¶£çš„é¢†åŸŸæ‰‹åŠ¨éªŒè¯è¿™äº›æŒ‡æ ‡çš„å¯é æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14883v2">PDF</a> v2: Added Acknowledgements to funding sources and advisors</p>
<p><strong>Summary</strong>ï¼š<br>å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°å™¨åœ¨è¯„ä¼°è‡ªç„¶è¯­è¨€ç”Ÿæˆè¾“å‡ºæ–¹é¢å­˜åœ¨ä¸ä¸€è‡´æ€§å’Œè¯¯ä¼°ç³»ç»Ÿæ€§èƒ½çš„é—®é¢˜ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¯¹è¿™äº›è¯„ä¼°å™¨è¿›è¡Œäº†å…¨é¢é‡æ–°è¯„ä¼°åï¼Œæœ¬æ–‡å»ºè®®ä½¿ç”¨è€…åœ¨ä½¿ç”¨è¿™äº›äº‹å®è¯„ä¼°æŒ‡æ ‡æ—¶è¦è°¨æ…è¡Œäº‹ï¼Œå¹¶åœ¨ç‰¹å®šé¢†åŸŸå†…è¿›è¡Œå¯é æ€§éªŒè¯ã€‚è¯¥ç ”ç©¶çš„æ·±å…¥åˆ†æäº†åœ¨é«˜åº¦æ„è¯‘çš„è¾“å‡ºå’Œæºäºæ–‡æ¡£è¾ƒè¿œå¤„çš„è¾“å‡ºæ–¹é¢å­˜åœ¨çš„åè§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°å™¨åœ¨è¯„ä¼°è‡ªç„¶è¯­è¨€çš„ç”Ÿæˆè¾“å‡ºæ—¶å­˜åœ¨ä¸ä¸€è‡´æ€§ã€‚</li>
<li>è¿™äº›è¯„ä¼°å™¨æœ‰æ—¶ä¼šè¯¯ä¼°ç³»ç»Ÿæ€§èƒ½ï¼Œå¯¼è‡´å¤šç§é™·é˜±ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14883">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2d33f9ef135492d111599d58fe9d6aeb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d33baa8e8f86e81c9ed3438105754fd.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Swin-fMRI-Transformer-Predicts-Early-Neurodevelopmental-Outcomes-from-Neonatal-fMRI"><a href="#Swin-fMRI-Transformer-Predicts-Early-Neurodevelopmental-Outcomes-from-Neonatal-fMRI" class="headerlink" title="Swin fMRI Transformer Predicts Early Neurodevelopmental Outcomes from   Neonatal fMRI"></a>Swin fMRI Transformer Predicts Early Neurodevelopmental Outcomes from   Neonatal fMRI</h2><p><strong>Authors:Patrick Styll, Dowon Kim, Jiook Cha</strong></p>
<p>Brain development in the first few months of human life is a critical phase characterized by rapid structural growth and functional organization. Accurately predicting developmental outcomes during this time is crucial for identifying delays and enabling timely interventions. This study introduces the SwiFT (Swin 4D fMRI Transformer) model, designed to predict Bayley-III composite scores using neonatal fMRI from the Developing Human Connectome Project (dHCP). To enhance predictive accuracy, we apply dimensionality reduction via group independent component analysis (ICA) and pretrain SwiFT on large adult fMRI datasets to address the challenges of limited neonatal data. Our analysis shows that SwiFT significantly outperforms baseline models in predicting cognitive, motor, and language outcomes, leveraging both single-label and multi-label prediction strategies. The modelâ€™s attention-based architecture processes spatiotemporal data end-to-end, delivering superior predictive performance. Additionally, we use Integrated Gradients with Smoothgrad sQuare (IG-SQ) to interpret predictions, identifying neural spatial representations linked to early cognitive and behavioral development. These findings underscore the potential of Transformer models to advance neurodevelopmental research and clinical practice. </p>
<blockquote>
<p>åœ¨äººç±»ç”Ÿå‘½çš„å‰å‡ ä¸ªæœˆï¼Œå¤§è„‘å‘è‚²æ˜¯ä¸€ä¸ªå…³é”®é˜¶æ®µï¼Œä»¥å¿«é€Ÿçš„ç»“æ„å¢é•¿å’ŒåŠŸèƒ½ç»„ç»‡ä¸ºç‰¹å¾ã€‚å‡†ç¡®é¢„æµ‹è¿™ä¸€æ—¶æœŸçš„å‘è‚²ç»“æœå¯¹äºå‘ç°å‘è‚²å»¶è¿Ÿå’Œå®æ–½åŠæ—¶å¹²é¢„è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†SwiFTï¼ˆSwin 4D fMRI Transformerï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨åˆ©ç”¨å‘å±•äººç±»è¿æ¥ç»„é¡¹ç›®ï¼ˆdHCPï¼‰çš„æ–°ç”Ÿå„¿fMRIæ•°æ®é¢„æµ‹Bayley-IIIç»¼åˆè¯„åˆ†ã€‚ä¸ºäº†æé«˜é¢„æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬é€šè¿‡ç¾¤ä½“ç‹¬ç«‹æˆåˆ†åˆ†æï¼ˆICAï¼‰è¿›è¡Œé™ç»´ï¼Œå¹¶åœ¨å¤§å‹æˆäººfMRIæ•°æ®é›†ä¸Šé¢„è®­ç»ƒSwiFTæ¨¡å‹ï¼Œä»¥è§£å†³æ–°ç”Ÿå„¿æ•°æ®é‡æœ‰é™æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼ŒSwiFTæ¨¡å‹åœ¨é¢„æµ‹è®¤çŸ¥ã€è¿åŠ¨å’Œè¯­è¨€ç»“æœæ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œé‡‡ç”¨å•æ ‡ç­¾å’Œå¤šæ ‡ç­¾é¢„æµ‹ç­–ç•¥ã€‚è¯¥æ¨¡å‹çš„åŸºäºæ³¨æ„åŠ›çš„æ¶æ„èƒ½å¤Ÿç«¯åˆ°ç«¯åœ°å¤„ç†æ—¶ç©ºæ•°æ®ï¼Œæä¾›å‡ºè‰²çš„é¢„æµ‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨å¸¦æœ‰Smoothgrad sQuareçš„ç»¼åˆæ¢¯åº¦ï¼ˆIG-SQï¼‰æ¥è§£é‡Šé¢„æµ‹ç»“æœï¼Œè¯†åˆ«ä¸æ—©æœŸè®¤çŸ¥å’Œè¡Œä¸ºå‘å±•ç›¸å…³çš„ç¥ç»ç©ºé—´è¡¨å¾ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†Transformeræ¨¡å‹åœ¨ç¥ç»å‘è‚²ç ”ç©¶å’Œä¸´åºŠå®è·µä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07783v3">PDF</a> fMRI Transformer, Developing Human Connectome Project, Bayley Scales   of Infant Development, Personalized Therapy, XAI</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨SwiFTæ¨¡å‹é¢„æµ‹äººç±»ç”Ÿå‘½æ—©æœŸï¼ˆæ–°ç”Ÿå„¿æœŸï¼‰å¤§è„‘å‘è‚²æƒ…å†µçš„ç ”ç©¶ã€‚è¯¥ç ”ç©¶é€šè¿‡å››ç»´åŠŸèƒ½ç£å…±æŒ¯æˆåƒæŠ€æœ¯ï¼ˆ4D fMRIï¼‰ï¼Œç»“åˆSwini 4D fMRI Transformeræ¨¡å‹ï¼Œä½¿ç”¨æ¥è‡ªå‘è‚²äººç±»è¿æ¥ç»„é¡¹ç›®ï¼ˆdHCPï¼‰çš„æ–°ç”Ÿå„¿æ•°æ®é¢„æµ‹Bayley-IIIç»¼åˆè¯„åˆ†ã€‚é€šè¿‡ç¾¤ä½“ç‹¬ç«‹æˆåˆ†åˆ†æï¼ˆICAï¼‰è¿›è¡Œé™ç»´ä»¥æé«˜é¢„æµ‹ç²¾åº¦ï¼Œå¹¶åœ¨å¤§å‹æˆäººfMRIæ•°æ®é›†ä¸Šé¢„è®­ç»ƒSwiFTæ¨¡å‹ä»¥åº”å¯¹æ–°ç”Ÿå„¿æ•°æ®æœ‰é™çš„é—®é¢˜ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒSwiFTæ¨¡å‹åœ¨é¢„æµ‹è®¤çŸ¥ã€è¿åŠ¨å’Œè¯­è¨€å‘å±•ç»“æœæ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œæ”¯æŒå•æ ‡ç­¾å’Œå¤šæ ‡ç­¾é¢„æµ‹ç­–ç•¥ã€‚è¯¥æ¨¡å‹åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¤„ç†æ—¶ç©ºæ•°æ®ç«¯è‡³ç«¯ï¼Œè¡¨ç°å‡ºå‡ºè‰²çš„é¢„æµ‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ä½¿ç”¨Integrated Gradients with Smoothgrad sQuareï¼ˆIG-SQï¼‰æ¥è§£é‡Šé¢„æµ‹ç»“æœï¼Œç¡®å®šäº†ä¸æ—©æœŸè®¤çŸ¥å’Œå‘è‚²ç›¸å…³çš„ç¥ç»ç©ºé—´è¡¨ç°ã€‚æ­¤ç ”ç©¶å±•ç°äº†Transformeræ¨¡å‹åœ¨ç¥ç»å‘è‚²ç ”ç©¶å’Œä¸´åºŠå®è·µä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººç±»ç”Ÿå‘½æ—©æœŸçš„å¤§è„‘å‘è‚²æ˜¯ä¸€ä¸ªå…³é”®é˜¶æ®µï¼Œæ¶‰åŠå¿«é€Ÿçš„ç»“æ„å¢é•¿å’ŒåŠŸèƒ½ç»„ç»‡ã€‚å‡†ç¡®é¢„æµ‹è¿™ä¸€æ—¶æœŸçš„å‘è‚²ç»“æœå¯¹äºåŠæ—¶å‘ç°å»¶è¿Ÿå’Œè¿›è¡Œå¹²é¢„è‡³å…³é‡è¦ã€‚</li>
<li>ç ”ç©¶å¼•å…¥äº†SwiFTæ¨¡å‹ï¼Œç”¨äºåŸºäºå››ç»´åŠŸèƒ½ç£å…±æŒ¯æˆåƒæŠ€æœ¯ï¼ˆ4D fMRIï¼‰é¢„æµ‹Bayley-IIIç»¼åˆè¯„åˆ†ã€‚</li>
<li>é‡‡ç”¨ç¾¤ä½“ç‹¬ç«‹æˆåˆ†åˆ†æï¼ˆICAï¼‰è¿›è¡Œé™ç»´ï¼Œä»¥æé«˜å¯¹æ–°ç”Ÿå„¿æ•°æ®çš„é¢„æµ‹ç²¾åº¦ã€‚</li>
<li>SwiFTæ¨¡å‹åœ¨æˆäººfMRIæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥åº”å¯¹æ–°ç”Ÿå„¿æ•°æ®æœ‰é™çš„é—®é¢˜ã€‚</li>
<li>SwiFTæ¨¡å‹åœ¨é¢„æµ‹è®¤çŸ¥ã€è¿åŠ¨å’Œè¯­è¨€å‘å±•ç»“æœæ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œæ”¯æŒå¤šç§é¢„æµ‹ç­–ç•¥ã€‚</li>
<li>æ¨¡å‹åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶å¤„ç†æ—¶ç©ºæ•°æ®ï¼Œå…·æœ‰å‡ºè‰²çš„é¢„æµ‹æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07783">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-401ac852e577a151e418bd17e98c5eec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c8b58cd326399158923ac9f8a6105fa1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a44d425a25be5a8a71ca868f965881ad.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a72cb51387de3e95cdb6c99687f8b6e4.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Towards-Automated-Penetration-Testing-Introducing-LLM-Benchmark-Analysis-and-Improvements"><a href="#Towards-Automated-Penetration-Testing-Introducing-LLM-Benchmark-Analysis-and-Improvements" class="headerlink" title="Towards Automated Penetration Testing: Introducing LLM Benchmark,   Analysis, and Improvements"></a>Towards Automated Penetration Testing: Introducing LLM Benchmark,   Analysis, and Improvements</h2><p><strong>Authors:Isamu Isozaki, Manil Shrestha, Rick Console, Edward Kim</strong></p>
<p>Hacking poses a significant threat to cybersecurity, inflicting billions of dollars in damages annually. To mitigate these risks, ethical hacking, or penetration testing, is employed to identify vulnerabilities in systems and networks. Recent advancements in large language models (LLMs) have shown potential across various domains, including cybersecurity. However, there is currently no comprehensive, open, end-to-end automated penetration testing benchmark to drive progress and evaluate the capabilities of these models in security contexts. This paper introduces a novel open benchmark for LLM-based automated penetration testing, addressing this critical gap. We first evaluate the performance of LLMs, including GPT-4o and Llama 3.1-405B, using the state-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1 demonstrates an edge over GPT-4o, both models currently fall short of performing fully automated, end-to-end penetration testing. Next, we advance the state-of-the-art and present ablation studies that provide insights into improving the PentestGPT tool. Our research illuminates the challenges LLMs face in each aspect of Pentesting, e.g. enumeration, exploitation, and privilege escalation. This work contributes to the growing body of knowledge on AI-assisted cybersecurity and lays the foundation for future research in automated penetration testing using large language models. </p>
<blockquote>
<p>é»‘å®¢æ”»å‡»å¯¹ç½‘ç»œå®‰å…¨æ„æˆé‡å¤§å¨èƒï¼Œæ¯å¹´é€ æˆæ•°åäº¿ç¾å…ƒçš„æŸå¤±ã€‚ä¸ºäº†å‡è½»è¿™äº›é£é™©ï¼Œé‡‡ç”¨é“å¾·é»‘å®¢æ”»å‡»æˆ–æ¸—é€æµ‹è¯•æ¥è¯†åˆ«ç³»ç»Ÿå’Œç½‘ç»œä¸­çš„æ¼æ´ã€‚æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥åœ¨å„ä¸ªé¢†åŸŸéƒ½è¡¨ç°å‡ºäº†æ½œåŠ›ï¼ŒåŒ…æ‹¬ç½‘ç»œå®‰å…¨é¢†åŸŸã€‚ç„¶è€Œï¼Œç›®å‰å°šæ— å…¨é¢ã€å¼€æ”¾ã€ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•åŸºå‡†æ¥æ¨åŠ¨è¿›å±•å¹¶è¯„ä¼°è¿™äº›æ¨¡å‹åœ¨å®‰å…¨ç¯å¢ƒä¸­çš„èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºLLMçš„è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•çš„æ–°å‹å¼€æ”¾åŸºå‡†æµ‹è¯•ï¼Œä»¥è§£å†³è¿™ä¸€å…³é”®å·®è·ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨æœ€å…ˆè¿›çš„PentestGPTå·¥å…·è¯„ä¼°äº†LLMçš„æ€§èƒ½ï¼ŒåŒ…æ‹¬GPT-4oå’ŒLlama 3.1-405Bã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶Llama 3.1åœ¨æ€§èƒ½ä¸Šç•¥èƒœä¸€ç­¹ï¼Œä½†è¿™ä¸¤ä¸ªæ¨¡å‹ç›®å‰å°šæ— æ³•è¿›è¡Œå®Œå…¨è‡ªåŠ¨åŒ–ã€ç«¯åˆ°ç«¯çš„æ¸—é€æµ‹è¯•ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¨åŠ¨äº†æœ€æ–°æŠ€æœ¯çš„å‘å±•ï¼Œå¹¶è¿›è¡Œäº†æ¶ˆèç ”ç©¶ï¼Œä¸ºæ”¹è¿›PentestGPTå·¥å…·æä¾›äº†è§è§£ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†LLMåœ¨æ¸—é€æµ‹è¯•çš„å„ä¸ªæ–¹é¢æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚æšä¸¾ã€åˆ©ç”¨å’Œç‰¹æƒå‡çº§ã€‚è¿™é¡¹å·¥ä½œä¸ºAIè¾…åŠ©ç½‘ç»œå®‰å…¨çš„çŸ¥è¯†ä½“ç³»åšå‡ºäº†è´¡çŒ®ï¼Œå¹¶ä¸ºæœªæ¥ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17141v3">PDF</a> Main Paper 1-9 pages, Supplementary Materials: 10-17, 13 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸï¼Œé»‘å®¢æ”»å‡»é€ æˆäº†å·¨å¤§çš„ç»æµæŸå¤±ï¼Œå› æ­¤éœ€è¦è¿›è¡Œé“å¾·é»‘å®¢æ”»å‡»æˆ–æ¸—é€æµ‹è¯•æ¥è¯†åˆ«ç³»ç»Ÿå’Œç½‘ç»œä¸­çš„æ¼æ´ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ï¼Œå…¶åœ¨ç½‘ç»œå®‰å…¨ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›é€æ¸æ˜¾ç°ã€‚ç„¶è€Œï¼Œç›®å‰å°šç¼ºä¹å…¨é¢ã€å¼€æ”¾ã€ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•åŸºå‡†æ¥æ¨åŠ¨è¿›å±•å¹¶è¯„ä¼°è¿™äº›æ¨¡å‹åœ¨å®‰å…¨ç¯å¢ƒä¸­çš„èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªç”¨äºLLMè‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•çš„æ–°å‹å¼€æ”¾åŸºå‡†æµ‹è¯•ï¼Œå¡«è¡¥äº†è¿™ä¸€å…³é”®ç©ºç™½ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€å…ˆè¿›çš„PentestGPTå·¥å…·è¯„ä¼°äº†LLMçš„æ€§èƒ½ï¼ŒåŒ…æ‹¬GPT-4oå’ŒLlama 3.1-405Bæ¨¡å‹çš„è¡¨ç°ã€‚æˆ‘ä»¬å‘ç°ï¼Œå°½ç®¡Llama 3.1åœ¨æŸäº›æ–¹é¢è¡¨ç°å‡ºä¼˜äºGPT-4oçš„æ½œåŠ›ï¼Œä½†è¿™ä¸¤ä¸ªæ¨¡å‹ç›®å‰å°šæ— æ³•å®Œæˆç«¯åˆ°ç«¯çš„å®Œå…¨è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯¹ç°çŠ¶è¿›è¡Œäº†æ·±å…¥ç ”ç©¶å¹¶è¿›è¡Œäº†å»é™¤å®éªŒï¼ˆablation studiesï¼‰ï¼Œä»¥ä¸ºæ”¹å–„PentestGPTå·¥å…·æä¾›è§è§£ã€‚æœ¬ç ”ç©¶æ­ç¤ºäº†LLMåœ¨æ¸—é€æµ‹è¯•çš„å„ä¸ªæ–¹é¢æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚æšä¸¾ã€æ”»å‡»å’Œåˆ©ç”¨ç‰¹æƒå‡çº§ç­‰ã€‚è¿™é¡¹å·¥ä½œä¸ºäººå·¥æ™ºèƒ½è¾…åŠ©ç½‘ç»œå®‰å…¨çš„çŸ¥è¯†å¢é•¿åšå‡ºäº†è´¡çŒ®ï¼Œå¹¶ä¸ºæœªæ¥çš„å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸçš„åº”ç”¨å¼€å§‹æ˜¾ç°æ½œåŠ›ã€‚</li>
<li>å½“å‰ç¼ºä¹å…¨é¢çš„å¼€æ”¾åŸºå‡†æ¥è¯„ä¼°LLMåœ¨è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•æ–¹é¢çš„èƒ½åŠ›ã€‚</li>
<li>GPT-4oå’ŒLlama 3.1-405Bç­‰LLMåœ¨å®Œå…¨è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•æ–¹é¢ä»æœ‰ä¸è¶³ã€‚</li>
<li>åœ¨æ¸—é€æµ‹è¯•çš„å„ä¸ªæ–¹é¢ï¼ŒLLMé¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚æšä¸¾ã€æ”»å‡»å’Œåˆ©ç”¨ç‰¹æƒå‡çº§ç­‰ã€‚</li>
<li>ç ”ç©¶æä¾›äº†å¯¹PentestGPTå·¥å…·çš„æ·±å…¥äº†è§£å’Œæ”¹è¿›æ–¹å‘ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºäººå·¥æ™ºèƒ½è¾…åŠ©ç½‘ç»œå®‰å…¨çš„çŸ¥è¯†å¢é•¿åšå‡ºäº†è´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17141">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5190db01d012f6ee46a252eeab8fb43b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5716e6141523e8d222aaf2b2a41d2249.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82b0f1d3d18a4221c3fcc134b5169765.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-529d9721213b6aebec913281ab1f356f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-131a4c1c21da68cc2455dceaf7c1acd2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d077779bec00503d44b011b39b5c3ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c3f72e5cc1e57769c6b4f4c5e0f2f20.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Transformer-Guided-Coevolution-Improved-Team-Selection-in-Multiagent-Adversarial-Team-Games"><a href="#Transformer-Guided-Coevolution-Improved-Team-Selection-in-Multiagent-Adversarial-Team-Games" class="headerlink" title="Transformer Guided Coevolution: Improved Team Selection in Multiagent   Adversarial Team Games"></a>Transformer Guided Coevolution: Improved Team Selection in Multiagent   Adversarial Team Games</h2><p><strong>Authors:Pranav Rajbhandari, Prithviraj Dasgupta, Donald Sofge</strong></p>
<p>We consider the problem of team selection within multiagent adversarial team games. We propose BERTeam, a novel algorithm that uses a transformer-based deep neural network with Masked Language Model training to select the best team of players from a trained population. We integrate this with coevolutionary deep reinforcement learning, which trains a diverse set of individual players to choose from. We test our algorithm in the multiagent adversarial game Marine Capture-The-Flag, and find that BERTeam learns non-trivial team compositions that perform well against unseen opponents. For this game, we find that BERTeam outperforms MCAA, an algorithm that similarly optimizes team selection. </p>
<blockquote>
<p>æˆ‘ä»¬è€ƒè™‘å¤šæ™ºèƒ½ä½“å¯¹æŠ—å›¢é˜Ÿæ¸¸æˆä¸­çš„å›¢é˜Ÿé€‰æ‹©é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹ç®—æ³•BERTeamï¼Œè¯¥ç®—æ³•ä½¿ç”¨åŸºäºè½¬æ¢å™¨çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¹¶ç»“åˆæ©ç è¯­è¨€æ¨¡å‹è®­ç»ƒï¼Œä»å·²è®­ç»ƒçš„äººç¾¤ä¸­é€‰æ‹©æœ€ä½³å›¢é˜Ÿã€‚æˆ‘ä»¬å°†è¯¥ç®—æ³•ä¸ååŒæ·±åº¦å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œè®­ç»ƒå„ç§ä¸ªä½“ç©å®¶ä»¥ä¾›é€‰æ‹©ã€‚æˆ‘ä»¬åœ¨å¤šæ™ºèƒ½ä½“å¯¹æŠ—æ¸¸æˆâ€œæµ·æ´‹å¤ºæ——â€ä¸­æµ‹è¯•äº†æˆ‘ä»¬çš„ç®—æ³•ï¼Œå‘ç°BERTeamèƒ½å¤Ÿå­¦ä¹ éå¹³å‡¡å›¢é˜Ÿç»„åˆï¼Œèƒ½å¤Ÿåœ¨æœªè§è¿‡çš„å¯¹æ‰‹é¢å‰è¡¨ç°è‰¯å¥½ã€‚å¯¹äºè¿™æ¬¾æ¸¸æˆï¼Œæˆ‘ä»¬å‘ç°BERTeamçš„è¡¨ç°ä¼˜äºMCAAï¼ˆä¸€ç§åŒæ ·ä¼˜åŒ–å›¢é˜Ÿé€‰æ‹©çš„ç®—æ³•ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.13769v3">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹å¤šæ™ºèƒ½ä½“å¯¹æŠ—å›¢é˜Ÿæ¸¸æˆå†…çš„å›¢é˜Ÿé€‰æ‹©é—®é¢˜ï¼Œæå‡ºBERTeamç®—æ³•ã€‚è¯¥ç®—æ³•é‡‡ç”¨åŸºäºå˜å‹å™¨çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç»“åˆæ©ç è¯­è¨€æ¨¡å‹è®­ç»ƒï¼Œä»å·²è®­ç»ƒçš„äººç¾¤ä¸­é€‰æ‹©æœ€ä½³å›¢é˜Ÿã€‚è¯¥ç®—æ³•ä¸ååŒè¿›åŒ–çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œè®­ç»ƒä¸€ç³»åˆ—ä¸ªä½“ç©å®¶è¿›è¡Œé€‰æ‹©ã€‚åœ¨æµ·æ´‹æ•è·æ——å¸œçš„å¤šæ™ºèƒ½ä½“å¯¹æŠ—æ¸¸æˆä¸­æµ‹è¯•è¡¨æ˜ï¼ŒBERTeamèƒ½å­¦ä¹ éå¹³å‡¡å›¢é˜Ÿç»„åˆï¼Œå¯¹æœªè§è¿‡çš„å¯¹æ‰‹è¡¨ç°è‰¯å¥½ï¼Œä¸”ä¼˜äºMCAAç®—æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>BERTeamç®—æ³•è§£å†³äº†å¤šæ™ºèƒ½ä½“å¯¹æŠ—å›¢é˜Ÿæ¸¸æˆä¸­çš„å›¢é˜Ÿé€‰æ‹©é—®é¢˜ã€‚</li>
<li>BERTeamé‡‡ç”¨åŸºäºå˜å‹å™¨çš„æ·±åº¦ç¥ç»ç½‘ç»œå’Œæ©ç è¯­è¨€æ¨¡å‹è®­ç»ƒæ¥é€‰æ‹©æœ€ä½³å›¢é˜Ÿã€‚</li>
<li>BERTeamä¸ååŒè¿›åŒ–çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œèƒ½å¤Ÿè®­ç»ƒå¤šä¸ªä¸ªä½“ç©å®¶ã€‚</li>
<li>åœ¨æµ·æ´‹æ•è·æ——å¸œæ¸¸æˆä¸­æµ‹è¯•è¡¨æ˜ï¼ŒBERTeamèƒ½å­¦ä¹ æœ‰æ•ˆå›¢é˜Ÿç»„åˆã€‚</li>
<li>BERTeamç®—æ³•æ€§èƒ½ä¼˜äºMCAAç®—æ³•ã€‚</li>
<li>BERTeamå¯¹æœªè§è¿‡çš„å¯¹æ‰‹ä¹Ÿèƒ½è¡¨ç°å‡ºè‰¯å¥½æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.13769">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1352416135b08a99f6c358cefb458bd0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e6744bc527287b9d0a607584bee2fc8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a715f174a857f9f6190e67f4a3ee2ea2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8256816db78a72dcd4a7efcb066b0a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f93e6d08c033c54c18ffacac08e07ee6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0f6a7e32b71a67911b76936f11bcee93.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="GroUSE-A-Benchmark-to-Evaluate-Evaluators-in-Grounded-Question-Answering"><a href="#GroUSE-A-Benchmark-to-Evaluate-Evaluators-in-Grounded-Question-Answering" class="headerlink" title="GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question   Answering"></a>GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question   Answering</h2><p><strong>Authors:Sacha Muller, AntÃ³nio Loison, Bilel Omrani, Gautier Viaud</strong></p>
<p>Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use Large Language Models (LLMs) alongside private and up-to-date knowledge bases. In this work, we address the challenges of using LLM-as-a-Judge when evaluating grounded answers generated by RAG systems. To assess the calibration and discrimination capabilities of judge models, we identify 7 generator failure modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a meta-evaluation benchmark of 144 unit tests. This benchmark reveals that existing automated RAG evaluation frameworks often overlook important failure modes, even when using GPT-4 as a judge.   To improve on the current design of automated RAG evaluation frameworks, we propose a novel pipeline and find that while closed models perform well on GroUSE, state-of-the-art open-source judges do not generalize to our proposed criteria, despite strong correlation with GPT-4â€™s judgement. Our findings suggest that correlation with GPT-4 is an incomplete proxy for the practical performance of judge models and should be supplemented with evaluations on unit tests for precise failure mode detection.   We further show that finetuning Llama-3 on GPT-4â€™s reasoning traces significantly boosts its evaluation capabilities, improving upon both correlation with GPT-4â€™s evaluations and calibration on reference situations. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å·²ç»æˆä¸ºä¸€ç§å¸¸è§çš„èŒƒå¼ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ç§æœ‰å’Œæœ€æ–°çš„çŸ¥è¯†åº“ä¸€èµ·ä½¿ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†åœ¨ä½¿ç”¨RAGç³»ç»Ÿç”Ÿæˆçš„åŸºäºäº‹å®çš„ç­”æ¡ˆæ—¶è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæ³•å®˜çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è¯„ä¼°æ³•å®˜æ¨¡å‹çš„æ ¡å‡†å’Œé‰´åˆ«èƒ½åŠ›ï¼Œæˆ‘ä»¬ç¡®å®šäº†7ç§ç”Ÿæˆå™¨å¤±æ•ˆæ¨¡å¼ï¼Œå¹¶å¼•å…¥äº†GroUSEï¼ˆåŸºäºäº‹å®çš„é—®ç­”å•å…ƒè¯„åˆ†è¯„ä¼°å‘˜ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«144ä¸ªå•å…ƒæµ‹è¯•çš„å…ƒè¯„ä¼°åŸºå‡†ã€‚è¿™ä¸ªåŸºå‡†æµ‹è¯•å‘ç°ï¼Œç°æœ‰çš„è‡ªåŠ¨åŒ–RAGè¯„ä¼°æ¡†æ¶å¾€å¾€ä¼šå¿½ç•¥é‡è¦çš„å¤±æ•ˆæ¨¡å¼ï¼Œå³ä½¿ä½¿ç”¨GPT-4ä½œä¸ºæ³•å®˜ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
</blockquote>
<p>ä¸ºäº†æ”¹è¿›å½“å‰çš„è‡ªåŠ¨åŒ–RAGè¯„ä¼°æ¡†æ¶è®¾è®¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„æµç¨‹ï¼Œå¹¶å‘ç°è™½ç„¶å°é—­æ¨¡å‹åœ¨GroUSEä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†æœ€å…ˆè¿›çš„å¼€æºæ³•å®˜å¹¶ä¸ç¬¦åˆæˆ‘ä»¬æå‡ºçš„æ ‡å‡†ï¼Œå°½ç®¡ä»–ä»¬ä¸GPT-4çš„åˆ¤æ–­æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸GPT-4çš„ç›¸å…³æ€§å¹¶ä¸èƒ½å®Œå…¨ä»£è¡¨æ³•å®˜æ¨¡å‹çš„å®é™…æ€§èƒ½ï¼Œåº”åœ¨å•å…ƒæµ‹è¯•è¯„ä¼°ä¸­è¡¥å……ç²¾ç¡®å¤±æ•ˆæ¨¡å¼æ£€æµ‹ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.06595v3">PDF</a> Proceedings of the 31st International Conference on Computational   Linguistics</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¯„ä¼°å™¨è¯„ä¼°åŸºäºæ£€ç´¢çš„ç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿç”Ÿæˆçš„ç­”æ¡ˆçš„æŒ‘æˆ˜ã€‚ä¸ºäº†è¯„ä¼°è¯„ä¼°å™¨çš„æ ¡å‡†å’Œé‰´åˆ«èƒ½åŠ›ï¼Œä½œè€…ç¡®å®šäº†7ç§ç”Ÿæˆå™¨å¤±è´¥æ¨¡å¼ï¼Œå¹¶å¼•å…¥äº†GroUSEï¼ˆåŸºäºé—®é¢˜çš„å•ä½è¯„åˆ†è¯„ä¼°å™¨ï¼‰ä½œä¸ºåŒ…å«144ä¸ªå•å…ƒæµ‹è¯•çš„å…ƒè¯„ä¼°åŸºå‡†ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç°æœ‰çš„è‡ªåŠ¨åŒ–RAGè¯„ä¼°æ¡†æ¶å¾€å¾€å¿½ç•¥äº†é‡è¦çš„å¤±è´¥æ¨¡å¼ï¼Œå³ä½¿ä½¿ç”¨GPT-4ä½œä¸ºè¯„ä¼°å™¨ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ä¸ºäº†æé«˜å½“å‰çš„è‡ªåŠ¨åŒ–RAGè¯„ä¼°æ¡†æ¶çš„è®¾è®¡ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„ç®¡é“ï¼Œå¹¶å‘ç°è™½ç„¶å°é—­å¼æ¨¡å‹åœ¨GroUSEä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†ç°æœ‰çš„å¼€æºè¯„ä¼°å™¨å¹¶ä¸é€‚ç”¨äºä½œè€…æå‡ºçš„æ ‡å‡†ã€‚ç ”ç©¶è¿˜è¡¨æ˜ï¼Œé€šè¿‡åˆ©ç”¨GPT-4çš„æ¨ç†è½¨è¿¹å¯¹Llama-3è¿›è¡Œå¾®è°ƒå¯ä»¥æ˜¾è‘—æé«˜å…¶è¯„ä¼°èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¢«ç”¨äºè¯„ä¼°åŸºäºæ£€ç´¢çš„ç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿçš„ç­”æ¡ˆè´¨é‡ã€‚</li>
<li>ç¡®å®šäº†ä¸ƒç§ç”Ÿæˆå™¨å¤±è´¥æ¨¡å¼ï¼Œæå‡ºäº†GroUSEå…ƒè¯„ä¼°åŸºå‡†ä»¥æ›´å…¨é¢åœ°è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>ç°æœ‰è‡ªåŠ¨åŒ–RAGè¯„ä¼°æ¡†æ¶æ˜“å¿½ç•¥é‡è¦å¤±è´¥æ¨¡å¼ï¼Œå³ä½¿ä½¿ç”¨GPT-4ä¹Ÿå­˜åœ¨æ­¤é—®é¢˜ã€‚</li>
<li>å°é—­å¼æ¨¡å‹åœ¨GroUSEåŸºå‡†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œè€Œç°æœ‰å¼€æºè¯„ä¼°å™¨ä¸å®Œå…¨ç¬¦åˆæ–°æå‡ºçš„æ ‡å‡†ã€‚</li>
<li>ä¸GPT-4çš„å…³è”æ˜¯ä¸å®Œæ•´çš„ä»£ç†æŒ‡æ ‡ï¼Œéœ€è¦æ›´ç²¾ç¡®çš„å¤±è´¥æ¨¡å¼æ£€æµ‹ã€‚</li>
<li>åˆ©ç”¨GPT-4çš„æ¨ç†è½¨è¿¹å¯¹Llama-3è¿›è¡Œå¾®è°ƒå¯ä»¥æé«˜å…¶è¯„ä¼°èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.06595">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cc849cae2d6f5bfe52bee5aa3cbeda3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88a2e79282d174aa43b0c536b5c7689a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbecf83c6eff8507f8575bc1b629af8b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e8acaa33a7941e4ef507e698417a9ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-839c4366206c1c98f41500c22377a224.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Evaluating-LLM-based-Personal-Information-Extraction-and-Countermeasures"><a href="#Evaluating-LLM-based-Personal-Information-Extraction-and-Countermeasures" class="headerlink" title="Evaluating LLM-based Personal Information Extraction and Countermeasures"></a>Evaluating LLM-based Personal Information Extraction and Countermeasures</h2><p><strong>Authors:Yupei Liu, Yuqi Jia, Jinyuan Jia, Neil Zhenqiang Gong</strong></p>
<p>Automatically extracting personal informationâ€“such as name, phone number, and email addressâ€“from publicly available profiles at a large scale is a stepstone to many other security attacks including spear phishing. Traditional methodsâ€“such as regular expression, keyword search, and entity detectionâ€“achieve limited success at such personal information extraction. In this work, we perform a systematic measurement study to benchmark large language model (LLM) based personal information extraction and countermeasures. Towards this goal, we present a framework for LLM-based extraction attacks; collect four datasets including a synthetic dataset generated by GPT-4 and three real-world datasets with manually labeled eight categories of personal information; introduce a novel mitigation strategy based on prompt injection; and systematically benchmark LLM-based attacks and countermeasures using ten LLMs and five datasets. Our key findings include: LLM can be misused by attackers to accurately extract various personal information from personal profiles; LLM outperforms traditional methods; and prompt injection can defend against strong LLM-based attacks, reducing the attack to less effective traditional ones. </p>
<blockquote>
<p>è‡ªåŠ¨ä»å¤§è§„æ¨¡å…¬å¼€ä¸ªäººèµ„æ–™ä¸­æå–ä¸ªäººä¿¡æ¯ï¼ˆå¦‚å§“åã€ç”µè¯å·ç å’Œç”µå­é‚®ä»¶åœ°å€ï¼‰æ˜¯è®¸å¤šå…¶ä»–å®‰å…¨æ”»å‡»ï¼ˆåŒ…æ‹¬é’“é±¼é‚®ä»¶æ”»å‡»ï¼‰çš„åŸºçŸ³ã€‚ä¼ ç»Ÿçš„æ–¹æ³•ï¼ˆå¦‚æ­£åˆ™è¡¨è¾¾å¼ã€å…³é”®è¯æœç´¢å’Œå®ä½“æ£€æµ‹ï¼‰åœ¨ä¸ªäººä¿¡æ¯æå–æ–¹é¢çš„æˆåŠŸæœ‰é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸ªäººä¿¡æ¯æå–å’Œååˆ¶æªæ–½è¿›è¡Œäº†ç³»ç»Ÿçš„æµ‹é‡ç ”ç©¶ã€‚ä¸ºæ­¤ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºLLMçš„æå–æ”»å‡»æ¡†æ¶ï¼›æ”¶é›†äº†å››ä¸ªæ•°æ®é›†ï¼ŒåŒ…æ‹¬ç”±GPT-4ç”Ÿæˆçš„ä¸€ä¸ªåˆæˆæ•°æ®é›†å’Œä¸‰ä¸ªåŒ…å«æ‰‹åŠ¨æ ‡è®°çš„å…«ç±»ä¸ªäººä¿¡æ¯ç°å®ä¸–ç•Œæ•°æ®é›†ï¼›ä»‹ç»äº†ä¸€ç§åŸºäºæç¤ºæ³¨å…¥çš„æ–°å‹ç¼“è§£ç­–ç•¥ï¼›å¹¶ä½¿ç”¨åä¸ªLLMå’Œäº”ä¸ªæ•°æ®é›†ç³»ç»Ÿåœ°è¯„ä¼°äº†åŸºäºLLMçš„æ”»å‡»å’Œååˆ¶æªæ–½ã€‚æˆ‘ä»¬çš„å…³é”®å‘ç°åŒ…æ‹¬ï¼šæ”»å‡»è€…å¯æ»¥ç”¨LLMå‡†ç¡®æå–ä¸ªäººèµ„æ–™çš„å„ç±»ä¿¡æ¯ï¼›LLMçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼›æç¤ºæ³¨å…¥å¯ä»¥æœ‰æ•ˆé˜²å¾¡å¼ºå¤§çš„åŸºäºLLMçš„æ”»å‡»ï¼Œå°†å…¶é™ä½ä¸ºæ•ˆæœè¾ƒå¼±çš„ä¼ ç»Ÿæ”»å‡»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.07291v2">PDF</a> To appear in USENIX Security Symposium 2025</p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶å¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸ªäººä¿¡æ¯æå–è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºæç¤ºæ³¨å…¥çš„ç¼“è§£ç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMå¯è¢«æ”»å‡»è€…ç”¨äºä»ä¸ªäººèµ„æ–™ä¸­å‡†ç¡®æå–å„ç±»ä¸ªäººä¿¡æ¯ï¼Œä¸”è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚è€Œæç¤ºæ³¨å…¥ç­–ç•¥èƒ½æœ‰æ•ˆç¼“è§£LLMæ”»å‡»ï¼Œé™ä½å…¶æ•ˆæœè‡³ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMå¯è¢«ç”¨äºå¤§è§„æ¨¡åœ°ä»å…¬å¼€ä¸ªäººèµ„æ–™ä¸­æå–ä¸ªäººä¿¡æ¯ï¼Œå¦‚å§“åã€ç”µè¯å·ç å’Œç”µå­é‚®ä»¶åœ°å€ã€‚</li>
<li>LLMåœ¨è¿™ç§ä¿¡æ¯æå–ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚æ­£åˆ™è¡¨è¾¾å¼ã€å…³é”®è¯æœç´¢å’Œå®ä½“è¯†åˆ«ã€‚</li>
<li>åŸºäºLLMçš„ä¿¡æ¯æå–æ”»å‡»å¯æˆä¸ºè®¸å¤šå…¶ä»–å®‰å…¨æ”»å‡»çš„è·³æ¿ï¼Œå¦‚é’“é±¼é‚®ä»¶æ”»å‡»ã€‚</li>
<li>ä¸€ç§æ–°çš„åŸºäºæç¤ºæ³¨å…¥çš„ç¼“è§£ç­–ç•¥è¢«æå‡ºï¼Œä»¥å¯¹æŠ—åŸºäºLLMçš„æ”»å‡»ã€‚</li>
<li>æç¤ºæ³¨å…¥ç­–ç•¥èƒ½æœ‰æ•ˆé™ä½LLMæ”»å‡»çš„æ•ˆæœï¼Œä½¿å…¶æ›´æ¥è¿‘ä¼ ç»Ÿæ–¹æ³•çš„è¡¨ç°ã€‚</li>
<li>ç ”ç©¶è€…åˆ›å»ºäº†ä¸€ä¸ªç”¨äºLLMæå–æ”»å‡»çš„æ¡†æ¶å’Œå››ä¸ªæ•°æ®é›†ï¼ŒåŒ…æ‹¬ç”±GPT-4ç”Ÿæˆçš„ä¸€ä¸ªåˆæˆæ•°æ®é›†å’Œä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„æ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.07291">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bc666e7e9f0fd2feb61e41346667bc2c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-426bbcc9659b347082643a00a436f023.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b57c4eefcf2fd53dc95ab791c8e444c8.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="LLaRA-Supercharging-Robot-Learning-Data-for-Vision-Language-Policy"><a href="#LLaRA-Supercharging-Robot-Learning-Data-for-Vision-Language-Policy" class="headerlink" title="LLaRA: Supercharging Robot Learning Data for Vision-Language Policy"></a>LLaRA: Supercharging Robot Learning Data for Vision-Language Policy</h2><p><strong>Authors:Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo</strong></p>
<p>Vision Language Models (VLMs) have recently been leveraged to generate robotic actions, forming Vision-Language-Action (VLA) models. However, directly adapting a pretrained VLM for robotic control remains challenging, particularly when constrained by a limited number of robot demonstrations. In this work, we introduce LLaRA: Large Language and Robotics Assistant, a framework that formulates robot action policy as visuo-textual conversations and enables an efficient transfer of a pretrained VLM into a powerful VLA, motivated by the success of visual instruction tuning in Computer Vision. First, we present an automated pipeline to generate conversation-style instruction tuning data for robots from existing behavior cloning datasets, aligning robotic actions with image pixel coordinates. Further, we enhance this dataset in a self-supervised manner by defining six auxiliary tasks, without requiring any additional action annotations. We show that a VLM finetuned with a limited amount of such datasets can produce meaningful action decisions for robotic control. Through experiments across multiple simulated and real-world tasks, we demonstrate that LLaRA achieves state-of-the-art performance while preserving the generalization capabilities of large language models. The code, datasets, and pretrained models are available at <a target="_blank" rel="noopener" href="https://github.com/LostXine/LLaRA">https://github.com/LostXine/LLaRA</a>. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æœ€è¿‘è¢«ç”¨æ¥ç”Ÿæˆæœºå™¨äººåŠ¨ä½œï¼Œå½¢æˆè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ã€‚ç„¶è€Œï¼Œç›´æ¥å°†é¢„è®­ç»ƒçš„VLMç”¨äºæœºå™¨äººæ§åˆ¶ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å—åˆ°æœ‰é™æœºå™¨äººæ¼”ç¤ºæ•°é‡çš„é™åˆ¶æ—¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†LLaRAï¼šå¤§å‹è¯­è¨€å’Œæœºå™¨äººåŠ©ç†ï¼Œä¸€ä¸ªå°†æœºå™¨äººåŠ¨ä½œç­–ç•¥åˆ¶å®šä¸ºè§†è§‰æ–‡æœ¬å¯¹è¯çš„æ¡†æ¶ï¼Œå¹¶èƒ½æœ‰æ•ˆåœ°å°†é¢„è®­ç»ƒçš„VLMè½¬åŒ–ä¸ºå¼ºå¤§çš„VLAï¼Œè¿™å¾—ç›Šäºè®¡ç®—æœºè§†è§‰ä¸­è§†è§‰æŒ‡ä»¤è°ƒæ•´çš„æˆåŠŸçš„å¯ç¤ºã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–ç®¡é“ï¼Œç”¨äºä»ç°æœ‰çš„è¡Œä¸ºå…‹éš†æ•°æ®é›†ä¸­ç”Ÿæˆé¢å‘å¯¹è¯å¼çš„æŒ‡ä»¤è°ƒæ•´æ•°æ®ï¼Œä½¿æœºå™¨äººåŠ¨ä½œä¸å›¾åƒåƒç´ åæ ‡å¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å®šä¹‰å…­ä¸ªè¾…åŠ©ä»»åŠ¡æ¥ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼å¢å¼ºæ­¤æ•°æ®é›†ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„åŠ¨ä½œæ³¨é‡Šã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œä½¿ç”¨æœ‰é™æ•°é‡çš„æ­¤ç±»æ•°æ®é›†è¿›è¡Œå¾®è°ƒçš„VLMå¯ä»¥ä¸ºæœºå™¨äººæ§åˆ¶äº§ç”Ÿæœ‰æ„ä¹‰çš„åŠ¨ä½œå†³ç­–ã€‚é€šè¿‡å¤šé¡¹æ¨¡æ‹Ÿå’ŒçœŸå®ä»»åŠ¡çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†LLaRAåœ¨ä¿æŒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç ã€æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/LostXine/LLaRA%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/LostXine/LLaRAæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.20095v3">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ‘˜è¦ä»¥ä¸­æ–‡ç®€è¦æ¦‚æ‹¬äº†æ–‡æœ¬å†…å®¹ï¼šåœ¨æœºå™¨äººæ§åˆ¶é¢†åŸŸï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç”Ÿæˆæœºå™¨äººåŠ¨ä½œå½¢æˆè§†è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å­˜åœ¨æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºLLaRAçš„æ¡†æ¶ï¼Œé€šè¿‡åˆ¶å®šæœºå™¨äººåŠ¨ä½œç­–ç•¥ä¸ºè§†è§‰æ–‡æœ¬å¯¹è¯ï¼Œå®ç°äº†é¢„è®­ç»ƒçš„VLMåˆ°å¼ºå¤§çš„VLAçš„æœ‰æ•ˆè¿ç§»ã€‚æå‡ºè‡ªåŠ¨åŒ–ç®¡é“ä¸ºæœºå™¨äººç”Ÿæˆå¯¹è¯é£æ ¼çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®ï¼Œé€šè¿‡è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼å¢å¼ºæ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å®é™…å’Œæ¨¡æ‹Ÿä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯ä¸ƒä¸ªå…³é”®è§è§£ï¼š</p>
<ol>
<li>VLMså·²è¢«ç”¨äºç”Ÿæˆæœºå™¨äººåŠ¨ä½œï¼Œå½¢æˆVLAæ¨¡å‹ã€‚</li>
<li>ç›´æ¥é€‚åº”é¢„è®­ç»ƒçš„VLMåˆ°æœºå™¨äººæ§åˆ¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æœ‰é™æœºå™¨äººæ¼”ç¤ºçš„æƒ…å†µä¸‹ã€‚</li>
<li>LLaRAæ¡†æ¶é€šè¿‡åˆ¶å®šæœºå™¨äººåŠ¨ä½œç­–ç•¥ä¸ºè§†è§‰æ–‡æœ¬å¯¹è¯ï¼Œå®ç°äº†é¢„è®­ç»ƒçš„VLMåˆ°VLAçš„è¿ç§»ã€‚</li>
<li>è‡ªåŠ¨åŒ–ç®¡é“ç”¨äºä»ç°æœ‰è¡Œä¸ºå…‹éš†æ•°æ®é›†ä¸­ç”Ÿæˆå¯¹è¯å¼æŒ‡ä»¤è°ƒæ•´æ•°æ®ï¼Œä¸å›¾åƒåƒç´ åæ ‡å¯¹é½ã€‚</li>
<li>é€šè¿‡å®šä¹‰å…­ä¸ªè¾…åŠ©ä»»åŠ¡ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼å¢å¼ºæ•°æ®é›†ï¼Œæ— éœ€é¢å¤–çš„åŠ¨ä½œæ³¨é‡Šã€‚</li>
<li>é€šè¿‡æœ‰é™çš„æ•°æ®é›†å¯¹VLMè¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥äº§ç”Ÿæœ‰æ„ä¹‰çš„æœºå™¨äººæ§åˆ¶åŠ¨ä½œå†³ç­–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.20095">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d90184c725f8ed0b7df8bd171749f3c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0359e636d470001a49ce828ed8d60cb4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9929ce5695c06479be66657f4f51c0c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9c18064fbb0b8d620571895f2c3690e4.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-01/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-01/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-01/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3b029f1f88cf3345a4a2c4ffee16d379.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-01  Leveraging LLM Agents for Automated Optimization Modeling for SASP   Problems A Graph-RAG based Approach
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-31/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f223e03ee332c540efaad161475b7830.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-31  Better Slow than Sorry Introducing Positive Friction for Reliable   Dialogue Systems
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-31
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">16042k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
