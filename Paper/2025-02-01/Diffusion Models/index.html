<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-01  DiffusionRenderer Neural Inverse and Forward Rendering with Video   Diffusion Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-96d5591974fd0a745f3e1b0631a054d7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    30 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-01-æ›´æ–°"><a href="#2025-02-01-æ›´æ–°" class="headerlink" title="2025-02-01 æ›´æ–°"></a>2025-02-01 æ›´æ–°</h1><h2 id="DiffusionRenderer-Neural-Inverse-and-Forward-Rendering-with-Video-Diffusion-Models"><a href="#DiffusionRenderer-Neural-Inverse-and-Forward-Rendering-with-Video-Diffusion-Models" class="headerlink" title="DiffusionRenderer: Neural Inverse and Forward Rendering with Video   Diffusion Models"></a>DiffusionRenderer: Neural Inverse and Forward Rendering with Video   Diffusion Models</h2><p><strong>Authors:Ruofan Liang, Zan Gojcic, Huan Ling, Jacob Munkberg, Jon Hasselgren, Zhi-Hao Lin, Jun Gao, Alexander Keller, Nandita Vijaykumar, Sanja Fidler, Zian Wang</strong></p>
<p>Understanding and modeling lighting effects are fundamental tasks in computer vision and graphics. Classic physically-based rendering (PBR) accurately simulates the light transport, but relies on precise scene representationsâ€“explicit 3D geometry, high-quality material properties, and lighting conditionsâ€“that are often impractical to obtain in real-world scenarios. Therefore, we introduce DiffusionRenderer, a neural approach that addresses the dual problem of inverse and forward rendering within a holistic framework. Leveraging powerful video diffusion model priors, the inverse rendering model accurately estimates G-buffers from real-world videos, providing an interface for image editing tasks, and training data for the rendering model. Conversely, our rendering model generates photorealistic images from G-buffers without explicit light transport simulation. Experiments demonstrate that DiffusionRenderer effectively approximates inverse and forwards rendering, consistently outperforming the state-of-the-art. Our model enables practical applications from a single video inputâ€“including relighting, material editing, and realistic object insertion. </p>
<blockquote>
<p>ç†è§£å’Œå»ºæ¨¡å…‰ç…§æ•ˆæœæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„åŸºæœ¬ä»»åŠ¡ã€‚ç»å…¸çš„åŸºäºç‰©ç†çš„æ¸²æŸ“ï¼ˆPBRï¼‰èƒ½å‡†ç¡®æ¨¡æ‹Ÿå…‰ä¼ è¾“ï¼Œä½†ä¾èµ–äºç²¾ç¡®çš„åœºæ™¯è¡¨ç¤ºâ€”â€”æ˜ç¡®çš„3Då‡ ä½•ã€é«˜è´¨é‡çš„ææ–™å±æ€§å’Œå…‰ç…§æ¡ä»¶ï¼Œè¿™äº›åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­å¾€å¾€éš¾ä»¥è·å¾—ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†DiffusionRendererï¼Œè¿™æ˜¯ä¸€ç§ç¥ç»æ–¹æ³•ï¼Œåœ¨ä¸€ä¸ªæ•´ä½“æ¡†æ¶å†…è§£å†³äº†é€†å‘å’Œæ­£å‘æ¸²æŸ“çš„åŒé‡é—®é¢˜ã€‚åˆ©ç”¨å¼ºå¤§çš„è§†é¢‘æ‰©æ•£æ¨¡å‹å…ˆéªŒçŸ¥è¯†ï¼Œé€†å‘æ¸²æŸ“æ¨¡å‹èƒ½å‡†ç¡®åœ°ä»çœŸå®è§†é¢‘ä¼°è®¡Gç¼“å†²åŒºï¼Œä¸ºå›¾åƒç¼–è¾‘ä»»åŠ¡æä¾›æ¥å£ï¼Œå¹¶ä¸ºæ¸²æŸ“æ¨¡å‹æä¾›è®­ç»ƒæ•°æ®ã€‚ç›¸åï¼Œæˆ‘ä»¬çš„æ¸²æŸ“æ¨¡å‹èƒ½å¤Ÿä»Gç¼“å†²åŒºç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œè€Œæ— éœ€æ˜¾å¼æ¨¡æ‹Ÿå…‰ä¼ è¾“ã€‚å®éªŒè¡¨æ˜ï¼ŒDiffusionRendereræœ‰æ•ˆåœ°è¿‘ä¼¼äº†é€†å‘å’Œæ­£å‘æ¸²æŸ“ï¼Œå¹¶å§‹ç»ˆä¼˜äºå½“å‰æœ€ä½³æ°´å¹³ã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿä»å•ä¸ªè§†é¢‘è¾“å…¥ä¸­å®ç°å®é™…åº”ç”¨ï¼ŒåŒ…æ‹¬é‡æ–°ç…§æ˜ã€ææ–™ç¼–è¾‘å’Œé€¼çœŸçš„å¯¹è±¡æ’å…¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18590v1">PDF</a> Project page: research.nvidia.com&#x2F;labs&#x2F;toronto-ai&#x2F;DiffusionRenderer&#x2F;</p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œæ¸²æŸ“å™¨DiffusionRendererç»“åˆäº†é€†å‘å’Œæ­£å‘æ¸²æŸ“ï¼Œå€ŸåŠ©è§†é¢‘æ‰©æ•£æ¨¡å‹å…ˆéªŒå‡†ç¡®ä¼°è®¡Gç¼“å†²åŒºï¼Œä»çœŸå®è§†é¢‘ç”Ÿæˆå›¾åƒç¼–è¾‘ä»»åŠ¡çš„æ¥å£å’Œæ¸²æŸ“æ¨¡å‹çš„è®­ç»ƒæ•°æ®ã€‚æ¸²æŸ“æ¨¡å‹å¯ç›´æ¥ä»Gç¼“å†²åŒºç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œæ— éœ€æ˜¾å¼æ¨¡æ‹Ÿå…‰çº¿ä¼ è¾“ã€‚å®éªŒè¯æ˜ï¼ŒDiffusionRendereråœ¨é€†å‘å’Œæ­£å‘æ¸²æŸ“æ–¹é¢çš„è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶èƒ½ä»å•ä¸€è§†é¢‘è¾“å…¥å®ç°å®ç”¨åº”ç”¨ï¼Œå¦‚é‡æ–°ç…§æ˜ã€ææ–™ç¼–è¾‘å’ŒçœŸå®å¯¹è±¡æ’å…¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DiffusionRendererç»“åˆäº†é€†å‘å’Œæ­£å‘æ¸²æŸ“ã€‚</li>
<li>åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹å‡†ç¡®ä¼°è®¡Gç¼“å†²åŒºï¼Œæœ‰åŠ©äºçœŸå®è§†é¢‘çš„å›¾åƒç¼–è¾‘ä»»åŠ¡åŠæ¸²æŸ“æ¨¡å‹çš„è®­ç»ƒã€‚</li>
<li>æ— éœ€æ¨¡æ‹Ÿæ˜¾å¼å…‰çº¿ä¼ è¾“å°±èƒ½ä»Gç¼“å†²åŒºç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚</li>
<li>DiffusionRendereråœ¨é€†å‘å’Œæ­£å‘æ¸²æŸ“æ–¹é¢çš„è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ¨¡å‹å¯ä»å•ä¸€è§†é¢‘è¾“å…¥å®ç°å®ç”¨åº”ç”¨ï¼Œå¦‚é‡æ–°ç…§æ˜ã€ææ–™ç¼–è¾‘å’ŒçœŸå®å¯¹è±¡æ’å…¥ç­‰ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½åº”å¯¹å¤æ‚åœºæ™¯çš„æ¸²æŸ“é—®é¢˜ï¼Œæä¾›æ›´é«˜çš„çµæ´»æ€§å’Œé€¼çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18590">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-82a2cad7ab583ef8654768271578a073.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1b9aef01fa7e6b97aead43a26d56600a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08d9acd1c63b55302d05e729ea0bb4bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-519896a11b3dc43a386cd7af553205db.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SAeUron-Interpretable-Concept-Unlearning-in-Diffusion-Models-with-Sparse-Autoencoders"><a href="#SAeUron-Interpretable-Concept-Unlearning-in-Diffusion-Models-with-Sparse-Autoencoders" class="headerlink" title="SAeUron: Interpretable Concept Unlearning in Diffusion Models with   Sparse Autoencoders"></a>SAeUron: Interpretable Concept Unlearning in Diffusion Models with   Sparse Autoencoders</h2><p><strong>Authors:Bartosz CywiÅ„ski, Kamil Deja</strong></p>
<p>Recent machine unlearning approaches offer promising solution for removing unwanted concepts from diffusion models. However, traditional methods, which largely rely on fine-tuning, provide little insight into the changes they introduce to the base model, making it unclear whether concepts are truly removed or only masked. In this work, we introduce SAeUron, a novel method leveraging features learned by sparse autoencoders (SAEs) to unlearn unwanted concepts in text-to-image diffusion models. First, we demonstrate that SAEs, trained in an unsupervised manner on activations from multiple denoising timesteps of the diffusion model, capture sparse and interpretable features corresponding to specific concepts. Building on this, we propose a method of selecting concept-specific features. This enables precise interventions on the modelâ€™s activations to block targeted content while preserving the modelâ€™s overall performance. Evaluation on the competitive UnlearnCanvas benchmark on object and style unlearning highlights SAeUronâ€™s state-of-the-art performance. Moreover, we show that with a single SAE, we can remove multiple concepts simultaneously and that in contrast to other methods, SAeUron dismisses the possibility of generating unwanted content, even under adversarial attack. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œæœºå™¨å­¦ä¹ å»å­¦ä¹ çš„æŠ€æœ¯ä¸ºä»æ‰©æ•£æ¨¡å‹ä¸­ç§»é™¤ä¸éœ€è¦çš„æ¦‚å¿µæä¾›äº†å¾ˆæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„æ–¹æ³•å¤§å¤šä¾èµ–äºå¾®è°ƒï¼Œå¯¹äºå®ƒä»¬ç»™åŸºç¡€æ¨¡å‹å¸¦æ¥çš„æ”¹å˜å¹¶æ²¡æœ‰æä¾›å¤ªå¤šè§è§£ï¼Œå› æ­¤ä¸æ¸…æ¥šæ¦‚å¿µæ˜¯å¦çœŸçš„è¢«ç§»é™¤ï¼Œè¿˜åªæ˜¯è¢«æ©ç›–äº†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†SAeUronï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰å­¦ä¹ åˆ°çš„ç‰¹å¾æ¥å»é™¤æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­ä¸éœ€è¦çš„æ¦‚å¿µçš„æ–°æ–¹æ³•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¯æ˜åœ¨æ‰©æ•£æ¨¡å‹çš„å¤šä¸ªå»å™ªæ—¶é—´æ­¥é•¿çš„æ¿€æ´»ä¸Šæ¥å—æ— ç›‘ç£è®­ç»ƒçš„SAEèƒ½å¤Ÿæ•è·å¯¹åº”ç‰¹å®šæ¦‚å¿µçš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾ç¨€ç–ä¸”å¯è§£é‡Šæ€§å¼ºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€‰æ‹©ç‰¹å®šæ¦‚å¿µç‰¹å¾çš„æ–¹æ³•ã€‚è¿™èƒ½å¤Ÿå¯¹æ¨¡å‹çš„æ¿€æ´»è¿›è¡Œç²¾ç¡®å¹²é¢„ï¼Œä»¥é˜»æ­¢ç›®æ ‡å†…å®¹ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„æ€»ä½“æ€§èƒ½ã€‚åœ¨ç«äº‰æ€§çš„UnlearnCanvasåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å¯¹è±¡ä¸é£æ ¼å»å­¦ä¹ çš„è¯„ä¼°å‡¸æ˜¾äº†SAeUronçš„å“è¶Šæ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä½¿ç”¨ä¸€ä¸ªå•ä¸€çš„SAEå¯ä»¥åŒæ—¶ç§»é™¤å¤šä¸ªæ¦‚å¿µï¼Œå¹¶ä¸”ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒSAeUronæ¶ˆé™¤äº†ç”Ÿæˆä¸éœ€è¦å†…å®¹çš„å¯èƒ½æ€§ï¼Œå³ä½¿åœ¨å¯¹æŠ—æ”»å‡»ä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18052v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•SAeUronï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰çš„ç‰¹æ€§ï¼Œä»æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹ä¸­å»é™¤ä¸éœ€è¦çš„æ¦‚å¿µã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸å¹²æ‰°æ¨¡å‹æ•´ä½“æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œç²¾ç¡®å¹²é¢„æ¨¡å‹çš„æ¿€æ´»ï¼Œä»¥é˜»æ­¢ç‰¹å®šå†…å®¹çš„ç”Ÿæˆã€‚åœ¨UnlearnCanvasåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°çªå‡ºï¼Œå¯ä»¥åŒæ—¶å»é™¤å¤šä¸ªæ¦‚å¿µï¼Œä¸”ä¸ä¼šç”Ÿæˆä¸éœ€è¦çš„å†…å®¹ï¼Œå…·æœ‰é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SAeUronæ˜¯ä¸€ç§åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰å»é™¤æ‰©æ•£æ¨¡å‹ä¸­ä¸éœ€è¦æ¦‚å¿µçš„æ–°æ–¹æ³•ã€‚</li>
<li>SAEåœ¨å¤šä¸ªå»å™ªæ—¶é—´æ­¥é•¿çš„æ‰©æ•£æ¨¡å‹æ¿€æ´»ä¸Šè¿›è¡Œæ— ç›‘ç£è®­ç»ƒï¼Œèƒ½å¤Ÿæ•è·å¯¹åº”ç‰¹å®šæ¦‚å¿µçš„ç‰¹å¾ã€‚</li>
<li>SAeUronå¯ä»¥ç²¾ç¡®å¹²é¢„æ¨¡å‹çš„æ¿€æ´»ï¼Œä»¥å»é™¤ç‰¹å®šå†…å®¹ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„æ€»ä½“æ€§èƒ½ã€‚</li>
<li>åœ¨UnlearnCanvasåŸºå‡†æµ‹è¯•ä¸Šï¼ŒSAeUronè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå¯åŒæ—¶è¿›è¡Œå¯¹è±¡å’Œé£æ ¼çš„å»é™¤ã€‚</li>
<li>SAeUronå¯ä»¥åŒæ—¶å»é™¤å¤šä¸ªæ¦‚å¿µã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒSAeUronåœ¨ç”Ÿæˆå†…å®¹æ–¹é¢å…·æœ‰æ›´é«˜çš„å¯æ§æ€§ï¼Œä¸ä¼šç”Ÿæˆä¸éœ€è¦çš„å†…å®¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18052">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4f26be24b03319ff23a555af7940de3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a66012f69e1a8da122b7856c64e66308.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac2793ddbe34ddfb401ccbaaca51d35d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b2e99192360b0df759338ab0c8d2816.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Can-Location-Embeddings-Enhance-Super-Resolution-of-Satellite-Imagery"><a href="#Can-Location-Embeddings-Enhance-Super-Resolution-of-Satellite-Imagery" class="headerlink" title="Can Location Embeddings Enhance Super-Resolution of Satellite Imagery?"></a>Can Location Embeddings Enhance Super-Resolution of Satellite Imagery?</h2><p><strong>Authors:Daniel Panangian, Ksenia Bittner</strong></p>
<p>Publicly available satellite imagery, such as Sentinel- 2, often lacks the spatial resolution required for accurate analysis of remote sensing tasks including urban planning and disaster response. Current super-resolution techniques are typically trained on limited datasets, leading to poor generalization across diverse geographic regions. In this work, we propose a novel super-resolution framework that enhances generalization by incorporating geographic context through location embeddings. Our framework employs Generative Adversarial Networks (GANs) and incorporates techniques from diffusion models to enhance image quality. Furthermore, we address tiling artifacts by integrating information from neighboring images, enabling the generation of seamless, high-resolution outputs. We demonstrate the effectiveness of our method on the building segmentation task, showing significant improvements over state-of-the-art methods and highlighting its potential for real-world applications. </p>
<blockquote>
<p>å…¬å¼€å¯ç”¨çš„å«æ˜Ÿå›¾åƒï¼Œå¦‚Sentinel-2ï¼Œé€šå¸¸ç¼ºä¹ç”¨äºå‡†ç¡®åˆ†æåŸå¸‚è§„åˆ’ã€ç¾å®³åº”å¯¹ç­‰é¥æ„Ÿä»»åŠ¡æ‰€éœ€çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚å½“å‰çš„è¶…åˆ†è¾¨ç‡æŠ€æœ¯é€šå¸¸åªåœ¨æœ‰é™çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¯¼è‡´å…¶åœ¨ä¸åŒåœ°ç†åŒºåŸŸçš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œå®ƒé€šè¿‡å¼•å…¥åœ°ç†ä½ç½®åµŒå…¥æŠ€æœ¯æ¥æé«˜åœ°ç†ä¸Šä¸‹æ–‡æ–¹é¢çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¡†æ¶é‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ï¼Œå¹¶ç»“åˆæ‰©æ•£æ¨¡å‹çš„æŠ€å·§æ¥æé«˜å›¾åƒè´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡æ•´åˆé‚»è¿‘å›¾åƒçš„ä¿¡æ¯æ¥è§£å†³æ‹¼è´´ç—•è¿¹é—®é¢˜ï¼Œä»è€Œç”Ÿæˆæ— ç¼ã€é«˜åˆ†è¾¨ç‡çš„è¾“å‡ºã€‚æˆ‘ä»¬åœ¨å»ºç­‘åˆ†å‰²ä»»åŠ¡ä¸Šå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›çš„æ–¹æ³•æœ‰æ˜æ˜¾çš„æ”¹è¿›ï¼Œå¹¶çªå‡ºäº†å…¶åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15847v2">PDF</a> Accepted to IEEE&#x2F;CVF Winter Conference on Applications of Computer   Vision (WACV)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆåœ°ç†ä¸Šä¸‹æ–‡é€šè¿‡ä½ç½®åµŒå…¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚å®ƒé‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹æŠ€æœ¯æé«˜å›¾åƒè´¨é‡ï¼Œå¹¶è§£å†³å¹³é“ºä¼ªå½±é—®é¢˜ï¼Œé€šè¿‡æ•´åˆé‚»è¿‘å›¾åƒçš„ä¿¡æ¯æ¥ç”Ÿæˆæ— ç¼ã€é«˜åˆ†è¾¨ç‡çš„è¾“å‡ºã€‚åœ¨å»ºç­‘ç‰©åˆ†å‰²ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•æ•ˆæœæ˜¾è‘—ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰æ˜æ˜¾æ”¹è¿›ï¼Œå¹¶å±•ç°å‡ºåœ¨çœŸå®ä¸–ç•Œåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…¬å¼€å«æ˜Ÿå›¾åƒå¦‚Sentinel-2çš„ç©ºé—´åˆ†è¾¨ç‡é€šå¸¸ä¸è¶³ä»¥è¿›è¡Œè¿œç¨‹æ„Ÿåº”ä»»åŠ¡ã€‚</li>
<li>å½“å‰è¶…åˆ†è¾¨ç‡æŠ€æœ¯é€šå¸¸åœ¨æœ‰é™æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¯¼è‡´åœ¨ä¸åŒåœ°ç†åŒºåŸŸçš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚</li>
<li>æå‡ºçš„æ–°å‹è¶…åˆ†è¾¨ç‡æ¡†æ¶é€šè¿‡èå…¥åœ°ç†ä¸Šä¸‹æ–‡å’Œä½ç½®åµŒå…¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹æŠ€æœ¯æé«˜å›¾åƒè´¨é‡ã€‚</li>
<li>æ¡†æ¶è§£å†³äº†ç”±äºå›¾åƒåˆ†å‰²äº§ç”Ÿçš„å¹³é“ºä¼ªå½±é—®é¢˜ï¼Œé€šè¿‡æ•´åˆé‚»è¿‘å›¾åƒä¿¡æ¯ç”Ÿæˆæ— ç¼é«˜åˆ†è¾¨ç‡è¾“å‡ºã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å»ºç­‘ç‰©åˆ†å‰²ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15847">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-45043dcacd79e0d6ba042ecf6f8ef63c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-557fd575c806a577ff9095ae6b519170.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b14916c16d3d32298e69c2323e02fc21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b1919cb1b16c24a870540fda20c0312.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b766eac585b1fe425eabd4dfb6a861b6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EliGen-Entity-Level-Controlled-Image-Generation-with-Regional-Attention"><a href="#EliGen-Entity-Level-Controlled-Image-Generation-with-Regional-Attention" class="headerlink" title="EliGen: Entity-Level Controlled Image Generation with Regional Attention"></a>EliGen: Entity-Level Controlled Image Generation with Regional Attention</h2><p><strong>Authors:Hong Zhang, Zhongjie Duan, Xingjun Wang, Yingda Chen, Yu Zhang</strong></p>
<p>Recent advancements in diffusion models have significantly advanced text-to-image generation, yet global text prompts alone remain insufficient for achieving fine-grained control over individual entities within an image. To address this limitation, we present EliGen, a novel framework for Entity-level controlled image Generation. Firstly, we put forward regional attention, a mechanism for diffusion transformers that requires no additional parameters, seamlessly integrating entity prompts and arbitrary-shaped spatial masks. By contributing a high-quality dataset with fine-grained spatial and semantic entity-level annotations, we train EliGen to achieve robust and accurate entity-level manipulation, surpassing existing methods in both spatial precision and image quality. Additionally, we propose an inpainting fusion pipeline, extending its capabilities to multi-entity image inpainting tasks. We further demonstrate its flexibility by integrating it with other open-source models such as IP-Adapter, In-Context LoRA and MLLM, unlocking new creative possibilities. The source code, model, and dataset are published at <a target="_blank" rel="noopener" href="https://github.com/modelscope/DiffSynth-Studio.git">https://github.com/modelscope/DiffSynth-Studio.git</a>. </p>
<blockquote>
<p>æœ€è¿‘æ‰©æ•£æ¨¡å‹æ–¹é¢çš„è¿›å±•æå¤§åœ°æ¨åŠ¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆï¼Œç„¶è€Œï¼Œä»…ä½¿ç”¨å…¨å±€æ–‡æœ¬æç¤ºä»ä¸è¶³ä»¥å®ç°å¯¹å›¾åƒå†…å•ä¸ªå®ä½“çš„ç²¾ç»†æ§åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†EliGenï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå®ä½“çº§åˆ«æ§åˆ¶å›¾åƒç”Ÿæˆçš„æ–°å‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†åŒºåŸŸæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€é¢å¤–å‚æ•°çš„æ‰©æ•£å˜å‹å™¨æœºåˆ¶ï¼Œæ— ç¼é›†æˆäº†å®ä½“æç¤ºå’Œä»»æ„å½¢çŠ¶çš„ç©ºé—´æ©ç ã€‚é€šè¿‡æä¾›ä¸€ä¸ªå…·æœ‰ç²¾ç»†ç©ºé—´è¯­ä¹‰å’Œå®ä½“çº§æ³¨é‡Šçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œæˆ‘ä»¬è®­ç»ƒEliGenå®ç°ç¨³å¥å‡†ç¡®çš„å®ä½“çº§æ“ä½œï¼Œåœ¨ç©ºé—´å’Œå›¾åƒè´¨é‡æ–¹é¢éƒ½è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¡¥å…¨èåˆç®¡é“ï¼Œå°†å…¶èƒ½åŠ›æ‰©å±•åˆ°å¤šå®ä½“å›¾åƒè¡¥å…¨ä»»åŠ¡ã€‚æˆ‘ä»¬é€šè¿‡å°†å…¶ä¸å…¶ä»–å¼€æºæ¨¡å‹ï¼ˆå¦‚IP-Adapterã€In-Context LoRAå’ŒMLLMï¼‰é›†æˆï¼Œè¿›ä¸€æ­¥å±•ç¤ºäº†å…¶çµæ´»æ€§ï¼Œè§£é”äº†æ–°çš„åˆ›æ„å¯èƒ½æ€§ã€‚æºä»£ç ã€æ¨¡å‹å’Œæ•°æ®é›†å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/modelscope/DiffSynth-Studio.git%E3%80%82">https://github.com/modelscope/DiffSynth-Studio.gitã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01097v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸæ‰©æ•£æ¨¡å‹çš„æ–°è¿›å±•æå¤§åœ°æ¨åŠ¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆèƒ½åŠ›ï¼Œç„¶è€Œï¼Œä»…ä¾èµ–å…¨å±€æ–‡æœ¬æç¤ºæ— æ³•å®ç°å›¾åƒå†…ä¸ªä½“å®ä½“çš„ç²¾ç»†æ§åˆ¶ã€‚ä¸ºè§£å†³è¿™ä¸€å±€é™ï¼Œæˆ‘ä»¬æå‡ºäº†EliGenæ¡†æ¶ï¼Œå®ç°å®ä½“çº§åˆ«çš„å›¾åƒç”Ÿæˆæ§åˆ¶ã€‚é€šè¿‡å¼•å…¥æ— éœ€é¢å¤–å‚æ•°çš„åŒºåŸŸæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ‰©æ•£å˜å‹å™¨èƒ½å¤Ÿæ— ç¼é›†æˆå®ä½“æç¤ºå’Œä»»æ„å½¢çŠ¶çš„ç©ºé—´æ©ç ã€‚æˆ‘ä»¬ä½¿ç”¨ç²¾ç»†çš„ç©ºé—´å’Œè¯­ä¹‰å®ä½“çº§æ³¨é‡Šçš„é«˜è´¨é‡æ•°æ®é›†è®­ç»ƒEliGenï¼Œå®ç°åœ¨å®ä½“çº§åˆ«çš„ç¨³å¥å’Œç²¾ç¡®æ“æ§ï¼Œåœ¨ç©ºé—´ç²¾åº¦å’Œå›¾åƒè´¨é‡ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ‰©å±•å…¶èƒ½åŠ›çš„è¡¥å…¨èåˆç®¡é“ï¼Œç”¨äºå¤šå®ä½“å›¾åƒè¡¥å…¨ä»»åŠ¡ã€‚é€šè¿‡ä¸å…¶ä»–å¼€æºæ¨¡å‹ï¼ˆå¦‚IP-Adapterã€In-Context LoRAå’ŒMLLMï¼‰çš„é›†æˆï¼Œå±•ç¤ºäº†å…¶çµæ´»æ€§ï¼Œå¼€å¯äº†æ–°çš„åˆ›æ„å¯èƒ½æ€§ã€‚ç›¸å…³æºç ã€æ¨¡å‹å’Œæ•°æ®é›†å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/modelscope/DiffSynth-Studio.git%E3%80%82">https://github.com/modelscope/DiffSynth-Studio.gitã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•å·²æ˜¾è‘—æ”¹å–„æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–äºå…¨å±€æ–‡æœ¬æç¤ºï¼Œæ— æ³•å®ç°å›¾åƒå†…ä¸ªä½“å®ä½“çš„ç²¾ç»†æ§åˆ¶ã€‚</li>
<li>æå‡ºäº†EliGenæ¡†æ¶ï¼Œé€šè¿‡åŒºåŸŸæ³¨æ„åŠ›æœºåˆ¶å®ç°å®ä½“çº§åˆ«çš„å›¾åƒç”Ÿæˆæ§åˆ¶ã€‚</li>
<li>æ— éœ€é¢å¤–å‚æ•°ï¼Œæ‰©æ•£å˜å‹å™¨èƒ½æ— ç¼é›†æˆå®ä½“æç¤ºå’Œç©ºé—´æ©ç ã€‚</li>
<li>ä½¿ç”¨é«˜è´¨é‡æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå®ç°ç¨³å¥å’Œç²¾ç¡®çš„å®ä½“çº§åˆ«æ“æ§ã€‚</li>
<li>åœ¨ç©ºé—´ç²¾åº¦å’Œå›¾åƒè´¨é‡ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01097">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5ad2543709a26b72b8cdacca26cd7396.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-539944f573a718dd36c331e8adcf3332.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f01a12ea2b5ccfa91f3e1f4177e0664.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e23638d3b152f1506cbc1ee3b099a7af.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PixelMan-Consistent-Object-Editing-with-Diffusion-Models-via-Pixel-Manipulation-and-Generation"><a href="#PixelMan-Consistent-Object-Editing-with-Diffusion-Models-via-Pixel-Manipulation-and-Generation" class="headerlink" title="PixelMan: Consistent Object Editing with Diffusion Models via Pixel   Manipulation and Generation"></a>PixelMan: Consistent Object Editing with Diffusion Models via Pixel   Manipulation and Generation</h2><p><strong>Authors:Liyao Jiang, Negar Hassanpour, Mohammad Salameh, Mohammadreza Samadi, Jiao He, Fengyu Sun, Di Niu</strong></p>
<p>Recent research explores the potential of Diffusion Models (DMs) for consistent object editing, which aims to modify object position, size, and composition, etc., while preserving the consistency of objects and background without changing their texture and attributes. Current inference-time methods often rely on DDIM inversion, which inherently compromises efficiency and the achievable consistency of edited images. Recent methods also utilize energy guidance which iteratively updates the predicted noise and can drive the latents away from the original image, resulting in distortions. In this paper, we propose PixelMan, an inversion-free and training-free method for achieving consistent object editing via Pixel Manipulation and generation, where we directly create a duplicate copy of the source object at target location in the pixel space, and introduce an efficient sampling approach to iteratively harmonize the manipulated object into the target location and inpaint its original location, while ensuring image consistency by anchoring the edited image to be generated to the pixel-manipulated image as well as by introducing various consistency-preserving optimization techniques during inference. Experimental evaluations based on benchmark datasets as well as extensive visual comparisons show that in as few as 16 inference steps, PixelMan outperforms a range of state-of-the-art training-based and training-free methods (usually requiring 50 steps) on multiple consistent object editing tasks. </p>
<blockquote>
<p>è¿‘æœŸç ”ç©¶æ¢è®¨äº†Diffusion Modelsï¼ˆDMsï¼‰åœ¨å¯¹è±¡ä¸€è‡´æ€§ç¼–è¾‘æ–¹é¢çš„æ½œåŠ›ã€‚å¯¹è±¡ä¸€è‡´æ€§ç¼–è¾‘æ—¨åœ¨ä¿®æ”¹å¯¹è±¡çš„ä½ç½®ã€å¤§å°ã€ç»„æˆç­‰ï¼ŒåŒæ—¶ä¿æŒå¯¹è±¡çš„è¿è´¯æ€§å’ŒèƒŒæ™¯ä¸€è‡´æ€§ï¼Œè€Œä¸æ”¹å˜å…¶çº¹ç†å’Œå±æ€§ã€‚å½“å‰æ¨ç†æ—¶é—´çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºDDIMåæ¼”ï¼Œè¿™å›ºæœ‰çš„ç‰ºç‰²äº†æ•ˆç‡å’Œç¼–è¾‘å›¾åƒçš„å¯å®ç°ä¸€è‡´æ€§ã€‚è¿‘æœŸçš„æ–¹æ³•è¿˜ä½¿ç”¨èƒ½é‡å¼•å¯¼ï¼Œé€šè¿‡è¿­ä»£æ›´æ–°é¢„æµ‹å™ªå£°å¹¶å¯èƒ½é©±åŠ¨æ½œåœ¨ç©ºé—´è¿œç¦»åŸå§‹å›¾åƒï¼Œä»è€Œå¯¼è‡´å¤±çœŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†PixelManï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€åæ¼”å’Œè®­ç»ƒçš„æ–¹æ³•ï¼Œé€šè¿‡åƒç´ æ“ä½œå’Œç”Ÿæˆå®ç°å¯¹è±¡çš„ä¸€è‡´æ€§ç¼–è¾‘ã€‚æˆ‘ä»¬ç›´æ¥åœ¨åƒç´ ç©ºé—´ä¸­åˆ›å»ºæºå¯¹è±¡çš„ç›®æ ‡ä½ç½®å‰¯æœ¬ï¼Œå¹¶å¼•å…¥é«˜æ•ˆçš„é‡‡æ ·æ–¹æ³•æ¥è¿­ä»£å°†æ“ä½œå¯¹è±¡å’Œè°åœ°èåˆåˆ°ç›®æ ‡ä½ç½®å¹¶å¯¹å…¶åŸå§‹ä½ç½®è¿›è¡Œå¡«å……ï¼ŒåŒæ—¶é€šè¿‡é”šå®šç”Ÿæˆçš„ç¼–è¾‘å›¾åƒåˆ°åƒç´ æ“ä½œå›¾åƒä»¥åŠå¼•å…¥å„ç§ä¸€è‡´æ€§ä¿æŒä¼˜åŒ–æŠ€æœ¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç¡®ä¿å›¾åƒçš„ä¸€è‡´æ€§ã€‚åŸºäºåŸºå‡†æ•°æ®é›†çš„å®éªŒè¯„ä¼°ä»¥åŠå¹¿æ³›çš„è§†è§‰æ¯”è¾ƒè¡¨æ˜ï¼Œåœ¨ä»…16æ­¥æ¨ç†çš„æƒ…å†µä¸‹ï¼ŒPixelManåœ¨å¤šä¸ªå¯¹è±¡ä¸€è‡´æ€§ç¼–è¾‘ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºä¸€ç³»åˆ—æœ€å…ˆè¿›çš„åŸºäºè®­ç»ƒå’Œå…è®­ç»ƒçš„æ–¹æ³•ï¼ˆé€šå¸¸éœ€è¦50æ­¥æ¨ç†ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.14283v2">PDF</a> AAAI 2025; version includes supplementary material; 27 Pages, 15   Figures, 6 Tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†Diffusion Modelsåœ¨ç‰©ä½“ç¼–è¾‘æ–¹é¢çš„æ½œåŠ›ï¼Œæå‡ºäº†ä¸€ç§åä¸ºPixelMançš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€åæ¼”å’Œè®­ç»ƒï¼Œå³å¯é€šè¿‡åƒç´ æ“ä½œå’Œç”Ÿæˆå®ç°ä¸€è‡´çš„ç‰©ä½“ç¼–è¾‘ã€‚å®ƒé€šè¿‡ç›´æ¥åœ¨ç›®æ ‡ä½ç½®åˆ›å»ºæºç‰©ä½“çš„å‰¯æœ¬ï¼Œå¹¶é‡‡ç”¨é«˜æ•ˆçš„é‡‡æ ·æ–¹æ³•æ¥è¿­ä»£åœ°å°†æ“ä½œç‰©ä½“å’Œè°åœ°èå…¥ç›®æ ‡ä½ç½®ï¼ŒåŒæ—¶ä¿è¯å›¾åƒçš„ä¸€è‡´æ€§ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒPixelManåœ¨å°‘æ•°æ¨ç†æ­¥éª¤ä¸­å°±èƒ½ä¼˜äºä¸€ç³»åˆ—æœ€å…ˆè¿›çš„åŸºäºè®­ç»ƒå’Œéè®­ç»ƒçš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Diffusion Models (DMs) åœ¨ç‰©ä½“ç¼–è¾‘æ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œèƒ½å¤Ÿä¿®æ”¹ç‰©ä½“ä½ç½®ã€å¤§å°ã€ç»„æˆç­‰ï¼ŒåŒæ—¶ä¿æŒç‰©ä½“å’ŒèƒŒæ™¯çš„è¿è´¯æ€§ã€‚</li>
<li>å½“å‰çš„æ–¹æ³•å¸¸å¸¸ä¾èµ–DDIMåæ¼”ï¼Œè¿™å½±å“äº†æ•ˆç‡å’Œå›¾åƒçš„ä¸€è‡´æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä½¿ç”¨èƒ½é‡å¼•å¯¼ï¼Œä½†å¯èƒ½å¯¼è‡´é¢„æµ‹å™ªå£°çš„æ›´æ–°å’Œæ½œåœ¨åç¦»åŸå§‹å›¾åƒï¼Œé€ æˆå¤±çœŸã€‚</li>
<li>PixelManæ–¹æ³•é€šè¿‡åƒç´ æ“ä½œå’Œç”Ÿæˆå®ç°ä¸€è‡´çš„ç‰©ä½“ç¼–è¾‘ï¼Œæ— éœ€åæ¼”å’Œè®­ç»ƒã€‚</li>
<li>PixelMané€šè¿‡åœ¨ç›®æ ‡ä½ç½®åˆ›å»ºæºç‰©ä½“çš„å‰¯æœ¬ï¼Œå¹¶è¿­ä»£åœ°å°†æ“ä½œç‰©ä½“èå…¥ç›®æ ‡ä½ç½®ã€‚</li>
<li>PixelMané‡‡ç”¨é«˜æ•ˆçš„é‡‡æ ·æ–¹æ³•æ¥ä¿®å¤å’Œå’Œè°ç‰©ä½“åœ¨åŸä½ç½®çš„å½¢è±¡ï¼ŒåŒæ—¶ç¡®ä¿å›¾åƒçš„ä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.14283">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-16774f6b7f3bd614b1ec3e3ef2ec68d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6878d114317453c51ba8a7dc633a365.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e1f64cc7b2eccd96e799f9fb373d211.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5e1b1a3d342c4abc3a9157d9ab18d8e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="AniDoc-Animation-Creation-Made-Easier"><a href="#AniDoc-Animation-Creation-Made-Easier" class="headerlink" title="AniDoc: Animation Creation Made Easier"></a>AniDoc: Animation Creation Made Easier</h2><p><strong>Authors:Yihao Meng, Hao Ouyang, Hanlin Wang, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Zhiheng Liu, Yujun Shen, Huamin Qu</strong></p>
<p>The production of 2D animation follows an industry-standard workflow, encompassing four essential stages: character design, keyframe animation, in-betweening, and coloring. Our research focuses on reducing the labor costs in the above process by harnessing the potential of increasingly powerful generative AI. Using video diffusion models as the foundation, AniDoc emerges as a video line art colorization tool, which automatically converts sketch sequences into colored animations following the reference character specification. Our model exploits correspondence matching as an explicit guidance, yielding strong robustness to the variations (e.g., posture) between the reference character and each line art frame. In addition, our model could even automate the in-betweening process, such that users can easily create a temporally consistent animation by simply providing a character image as well as the start and end sketches. Our code is available at: <a target="_blank" rel="noopener" href="https://yihao-meng.github.io/AniDoc_demo">https://yihao-meng.github.io/AniDoc_demo</a>. </p>
<blockquote>
<p>äºŒç»´åŠ¨ç”»çš„åˆ¶ä½œéµå¾ªè¡Œä¸šæ ‡å‡†çš„å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬å››ä¸ªåŸºæœ¬é˜¶æ®µï¼šè§’è‰²è®¾è®¡ã€å…³é”®å¸§åŠ¨ç”»ã€ä¸­é—´å¸§ç”Ÿæˆå’Œä¸Šè‰²ã€‚æˆ‘ä»¬çš„ç ”ç©¶è‡´åŠ›äºé€šè¿‡åˆ©ç”¨æ—¥ç›Šå¼ºå¤§çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æ½œåŠ›æ¥é™ä½ä¸Šè¿°è¿‡ç¨‹ä¸­çš„åŠ³åŠ¨åŠ›æˆæœ¬ã€‚ä»¥è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸ºåŸºç¡€ï¼ŒAniDocä½œä¸ºä¸€ç§è§†é¢‘çº¿è‰ºæœ¯ä¸Šè‰²å·¥å…·åº”è¿è€Œç”Ÿï¼Œå®ƒä¼šè‡ªåŠ¨å°†è‰å›¾åºåˆ—è½¬æ¢ä¸ºå½©è‰²åŠ¨ç”»ï¼Œå¹¶éµå¾ªå‚è€ƒè§’è‰²è§„èŒƒã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ©ç”¨å¯¹åº”åŒ¹é…ä½œä¸ºæ˜ç¡®æŒ‡å¯¼ï¼Œå¯¹å‚è€ƒè§’è‰²å’Œæ¯ä¸ªçº¿è‰ºæœ¯æ¡†æ¶ä¹‹é—´çš„å˜åŒ–ï¼ˆä¾‹å¦‚å§¿åŠ¿ï¼‰å…·æœ‰å¾ˆå¼ºçš„ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ç”šè‡³å¯ä»¥è‡ªåŠ¨åŒ–ä¸­é—´è¿‡ç¨‹ï¼Œè¿™æ ·ç”¨æˆ·åªéœ€æä¾›è§’è‰²å›¾åƒä»¥åŠå¼€å§‹å’Œç»“æŸçš„è‰å›¾ï¼Œå°±å¯ä»¥è½»æ¾åˆ›å»ºæ—¶é—´ä¸Šè¿è´¯çš„åŠ¨ç”»ã€‚æˆ‘ä»¬çš„ä»£ç åœ¨ï¼š<a target="_blank" rel="noopener" href="https://yihao-meng.github.io/AniDoc_demo%E3%80%82">https://yihao-meng.github.io/AniDoc_demoã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.14173v2">PDF</a> Project page and code: <a target="_blank" rel="noopener" href="https://yihao-meng.github.io/AniDoc_demo">https://yihao-meng.github.io/AniDoc_demo</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€é¡¹åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹å¼€å‘çš„æ–°å‹åŠ¨ç”»ç”Ÿäº§å·¥å…·â€”â€”AniDocã€‚è¯¥å·¥å…·æ—¨åœ¨é™ä½äºŒç»´åŠ¨ç”»åˆ¶ä½œè¿‡ç¨‹ä¸­çš„åŠ³åŠ¨åŠ›æˆæœ¬ï¼Œé€šè¿‡è‡ªåŠ¨å°†è‰å›¾åºåˆ—è½¬æ¢ä¸ºå½©è‰²åŠ¨ç”»ï¼Œä»è€Œç®€åŒ–è§’è‰²è®¾è®¡ã€å…³é”®å¸§åŠ¨ç”»ã€ä¸­é—´å¸§ç”Ÿæˆå’Œä¸Šè‰²ç­‰æµç¨‹ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯åŒ…æ‹¬åˆ©ç”¨å¯¹åº”åŒ¹é…ä½œä¸ºæ˜ç¡®æŒ‡å¯¼ï¼Œå¢å¼ºæ¨¡å‹å¯¹ä¸åŒè§’è‰²å§¿æ€å˜åŒ–çš„é²æ£’æ€§ï¼Œå¹¶èƒ½è‡ªåŠ¨åŒ–å®Œæˆä¸­é—´å¸§ç”Ÿæˆè¿‡ç¨‹ã€‚ç”¨æˆ·åªéœ€æä¾›è§’è‰²å›¾åƒåŠèµ·å§‹å’Œç»“æŸè‰å›¾ï¼Œå³å¯è½»æ¾åˆ›å»ºå‡ºæ—¶é—´è¿è´¯çš„åŠ¨ç”»ã€‚ç›¸å…³ä»£ç å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://yihao-meng.github.io/AniDoc_demo">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AniDocæ˜¯ä¸€ä¸ªåŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„äºŒç»´åŠ¨ç”»ç”Ÿäº§å·¥å…·ï¼Œæ—¨åœ¨é™ä½åŠ³åŠ¨åŠ›æˆæœ¬ã€‚</li>
<li>å®ƒå¯ä»¥å°†è‰å›¾åºåˆ—è‡ªåŠ¨è½¬æ¢ä¸ºå½©è‰²åŠ¨ç”»ï¼Œæ¶µç›–è§’è‰²è®¾è®¡ã€å…³é”®å¸§åŠ¨ç”»ç­‰æµç¨‹ã€‚</li>
<li>è¯¥å·¥å…·åˆ©ç”¨å¯¹åº”åŒ¹é…æŠ€æœ¯ä½œä¸ºæ˜ç¡®æŒ‡å¯¼ï¼Œå¢å¼ºå¯¹ä¸åŒè§’è‰²å§¿æ€å˜åŒ–çš„é²æ£’æ€§ã€‚</li>
<li>AniDocèƒ½å¤Ÿè‡ªåŠ¨åŒ–å®Œæˆä¸­é—´å¸§ç”Ÿæˆè¿‡ç¨‹ï¼Œç®€åŒ–åŠ¨ç”»åˆ›ä½œæµç¨‹ã€‚</li>
<li>ç”¨æˆ·åªéœ€æä¾›è§’è‰²å›¾åƒåŠèµ·å§‹å’Œç»“æŸè‰å›¾ï¼Œå³å¯è½»æ¾åˆ›å»ºæ—¶é—´è¿è´¯çš„åŠ¨ç”»ã€‚</li>
<li>è¯¥å·¥å…·çš„æ ¸å¿ƒæŠ€æœ¯äº®ç‚¹åœ¨äºå…¶åˆ›æ–°æ€§çš„å¯¹åº”åŒ¹é…æŠ€æœ¯åŠå…¶åœ¨åŠ¨ç”»ç”Ÿäº§ä¸­çš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.14173">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fddf8453905c9d37cb3a71cc7f68e895.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8aaa76958c834fd9840cf11cd36be3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d31db743f7a767ab45a653d120968c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fccbeb9b521b4250ae3e1825e3877013.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e982dabbb02cd0d3a1f9e118e5f9243f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="How-to-Backdoor-Consistency-Models"><a href="#How-to-Backdoor-Consistency-Models" class="headerlink" title="How to Backdoor Consistency Models?"></a>How to Backdoor Consistency Models?</h2><p><strong>Authors:Chengen Wang, Murat Kantarcioglu</strong></p>
<p>Consistency models are a new class of models that generate images by directly mapping noise to data, allowing for one-step generation and significantly accelerating the sampling process. However, their robustness against adversarial attacks has not yet been thoroughly investigated. In this work, we conduct the first study on the vulnerability of consistency models to backdoor attacks. While previous research has explored backdoor attacks on diffusion models, those studies have primarily focused on conventional diffusion models, employing a customized backdoor training process and objective, whereas consistency models have distinct training processes and objectives. Our proposed framework demonstrates the vulnerability of consistency models to backdoor attacks. During image generation, poisoned consistency models produce images with a Fr&#39;echet Inception Distance (FID) comparable to that of a clean model when sampling from Gaussian noise. However, once the trigger is activated, they generate backdoor target images. We explore various trigger and target configurations to evaluate the vulnerability of consistency models, including the use of random noise as a trigger. This novel trigger is visually inconspicuous, more challenging to detect, and aligns well with the sampling process of consistency models. Across all configurations, our framework successfully compromises the consistency models while maintaining high utility and specificity. We also examine the stealthiness of our proposed attack, which is attributed to the unique properties of consistency models and the elusive nature of the Gaussian noise trigger. </p>
<blockquote>
<p>ä¸€è‡´æ€§æ¨¡å‹æ˜¯ä¸€ç±»æ–°çš„æ¨¡å‹ï¼Œå®ƒä»¬é€šè¿‡ç›´æ¥å°†å™ªå£°æ˜ å°„åˆ°æ•°æ®æ¥ç”Ÿæˆå›¾åƒï¼Œå®ç°äº†ä¸€æ­¥ç”Ÿæˆï¼Œå¹¶æ˜¾è‘—åŠ é€Ÿäº†é‡‡æ ·è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹æŠ—å¯¹æŠ—æ€§æ”»å‡»çš„é²æ£’æ€§å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹ä¸€è‡´æ€§æ¨¡å‹å¯¹åé—¨æ”»å‡»çš„è„†å¼±æ€§è¿›è¡Œäº†é¦–æ¬¡ç ”ç©¶ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†æ‰©æ•£æ¨¡å‹ä¸Šçš„åé—¨æ”»å‡»ï¼Œä½†è¿™äº›ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹ä¸Šï¼Œé‡‡ç”¨å®šåˆ¶çš„åé—¨è®­ç»ƒè¿‡ç¨‹å’Œç›®æ ‡ï¼Œè€Œä¸€è‡´æ€§æ¨¡å‹å…·æœ‰ä¸åŒçš„è®­ç»ƒè¿‡ç¨‹å’Œç›®æ ‡ã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶å±•ç¤ºäº†ä¸€è‡´æ€§æ¨¡å‹å¯¹åé—¨æ”»å‡»çš„è„†å¼±æ€§ã€‚åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä¸­æ¯’çš„ä¸€è‡´æ€§æ¨¡å‹åœ¨ä»é«˜æ–¯å™ªå£°é‡‡æ ·æ—¶äº§ç”Ÿçš„å›¾åƒçš„FrÃ©chet Inceptionè·ç¦»ï¼ˆFIDï¼‰ä¸å¹²å‡€æ¨¡å‹çš„FIDç›¸å½“ã€‚ç„¶è€Œï¼Œä¸€æ—¦è§¦å‘ï¼Œå®ƒä»¬ä¼šç”Ÿæˆåé—¨ç›®æ ‡å›¾åƒã€‚æˆ‘ä»¬æ¢ç´¢äº†å„ç§è§¦å‘å™¨å’Œç›®æ ‡é…ç½®æ¥è¯„ä¼°ä¸€è‡´æ€§æ¨¡å‹çš„è„†å¼±æ€§ï¼ŒåŒ…æ‹¬ä½¿ç”¨éšæœºå™ªå£°ä½œä¸ºè§¦å‘å™¨ã€‚è¿™ç§æ–°å‹è§¦å‘å™¨åœ¨è§†è§‰ä¸Šå¹¶ä¸æ˜¾çœ¼ï¼Œæ›´éš¾ä»¥æ£€æµ‹ï¼Œå¹¶ä¸”ä¸ä¸€è‡´æ€§æ¨¡å‹çš„é‡‡æ ·è¿‡ç¨‹éå¸¸å¥‘åˆã€‚åœ¨æ‰€æœ‰é…ç½®ä¸­ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æˆåŠŸåœ°æ”»å‡»äº†ä¸€è‡´æ€§æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å®ç”¨æ€§å’Œç‰¹å¼‚æ€§ã€‚æˆ‘ä»¬è¿˜æ£€æŸ¥äº†æ‰€æå‡ºçš„æ”»å‡»çš„éšè”½æ€§ï¼Œè¿™å½’å› äºä¸€è‡´æ€§æ¨¡å‹çš„ç‹¬ç‰¹å±æ€§å’Œé«˜æ–¯å™ªå£°è§¦å‘çš„ä¸æ˜“å¯Ÿè§‰æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19785v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ä¸€è‡´æ€§æ¨¡å‹æ˜¯ä¸€ç±»æ–°çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä»¬é€šè¿‡ç›´æ¥å°†å™ªå£°æ˜ å°„åˆ°æ•°æ®ä¸Šæ¥ç”Ÿæˆå›¾åƒï¼Œå®ç°äº†ä¸€æ­¥ç”Ÿæˆï¼Œå¹¶æ˜¾è‘—åŠ é€Ÿäº†é‡‡æ ·è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹æŠ—å¯¹æŠ—æ€§æ”»å‡»çš„ç¨³å¥æ€§å°šæœªå¾—åˆ°å……åˆ†äº†è§£ã€‚æœ¬ç ”ç©¶é¦–æ¬¡æ¢è®¨äº†ä¸€è‡´æ€§æ¨¡å‹å¯¹åé—¨æ”»å‡»çš„è„†å¼±æ€§ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†æ‰©æ•£æ¨¡å‹çš„åé—¨æ”»å‡»ï¼Œä½†è¿™äº›ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹ä¸Šï¼Œé‡‡ç”¨å®šåˆ¶çš„åé—¨è®­ç»ƒè¿‡ç¨‹å’Œç›®æ ‡ï¼Œè€Œä¸€è‡´æ€§æ¨¡å‹å…·æœ‰ä¸åŒçš„è®­ç»ƒè¿‡ç¨‹å’Œç›®æ ‡ã€‚æœ¬ç ”ç©¶æå‡ºçš„æ¡†æ¶å±•ç¤ºäº†ä¸€è‡´æ€§æ¨¡å‹å¯¹åé—¨æ”»å‡»çš„è„†å¼±æ€§ã€‚åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä¸­æ¯’çš„ä¸€è‡´æ€§æ¨¡å‹èƒ½å¤Ÿä»é«˜æ–¯å™ªå£°ä¸­é‡‡æ ·ç”Ÿæˆå…·æœ‰ä¸å¹²å‡€æ¨¡å‹ç›¸å½“çš„FrÃ©chet Inception Distance (FID)çš„å›¾åƒã€‚ç„¶è€Œï¼Œä¸€æ—¦è§¦å‘æ¡ä»¶è¢«æ¿€æ´»ï¼Œå®ƒä»¬å°±ä¼šç”Ÿæˆåé—¨ç›®æ ‡å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸€è‡´æ€§æ¨¡å‹æ˜¯ä¸€ç§æ–°çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡å™ªå£°æ˜ å°„ç”Ÿæˆå›¾åƒï¼ŒåŠ é€Ÿé‡‡æ ·è¿‡ç¨‹ã€‚</li>
<li>ç›®å‰å¯¹äºä¸€è‡´æ€§æ¨¡å‹å¯¹æŠ—æ”»å‡»çš„ç¨³å¥æ€§ç ”ç©¶å°šä¸å……åˆ†ã€‚</li>
<li>ç ”ç©¶é¦–æ¬¡æ¢è®¨äº†ä¸€è‡´æ€§æ¨¡å‹å¯¹åé—¨æ”»å‡»çš„è„†å¼±æ€§ã€‚</li>
<li>ä¹‹å‰çš„ç ”ç©¶ä¸»è¦å…³æ³¨ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹çš„åé—¨æ”»å‡»ï¼Œè€Œä¸€è‡´æ€§æ¨¡å‹å…·æœ‰ä¸åŒçš„è®­ç»ƒè¿‡ç¨‹å’Œç›®æ ‡ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶å±•ç¤ºäº†ä¸€è‡´æ€§æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­æ˜“å—åé—¨æ”»å‡»çš„å½±å“ã€‚</li>
<li>ä¸­æ¯’çš„ä¸€è‡´æ€§æ¨¡å‹åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ç”Ÿæˆçš„å›¾åƒä¸å¹²å‡€æ¨¡å‹çš„FIDç›¸å½“ï¼Œä½†è§¦å‘æ¡ä»¶æ¿€æ´»åä¼šç”Ÿæˆåé—¨ç›®æ ‡å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19785">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6fcc04cf9ba43eaa9459710333972202.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-49885af4493d624f0f14208a76273084.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a92b0e7e5e9d8e0529a2e75b1abeaa94.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8f3d1bc7a936b69e49e44160b24d72c5.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Zero-Shot-Medical-Phrase-Grounding-with-Off-the-shelf-Diffusion-Models"><a href="#Zero-Shot-Medical-Phrase-Grounding-with-Off-the-shelf-Diffusion-Models" class="headerlink" title="Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models"></a>Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models</h2><p><strong>Authors:Konstantinos Vilouras, Pedro Sanchez, Alison Q. Oâ€™Neil, Sotirios A. Tsaftaris</strong></p>
<p>Localizing the exact pathological regions in a given medical scan is an important imaging problem that traditionally requires a large amount of bounding box ground truth annotations to be accurately solved. However, there exist alternative, potentially weaker, forms of supervision, such as accompanying free-text reports, which are readily available. The task of performing localization with textual guidance is commonly referred to as phrase grounding. In this work, we use a publicly available Foundation Model, namely the Latent Diffusion Model, to perform this challenging task. This choice is supported by the fact that the Latent Diffusion Model, despite being generative in nature, contains cross-attention mechanisms that implicitly align visual and textual features, thus leading to intermediate representations that are suitable for the task at hand. In addition, we aim to perform this task in a zero-shot manner, i.e., without any training on the target task, meaning that the modelâ€™s weights remain frozen. To this end, we devise strategies to select features and also refine them via post-processing without extra learnable parameters. We compare our proposed method with state-of-the-art approaches which explicitly enforce image-text alignment in a joint embedding space via contrastive learning. Results on a popular chest X-ray benchmark indicate that our method is competitive with SOTA on different types of pathology, and even outperforms them on average in terms of two metrics (mean IoU and AUC-ROC). Source code will be released upon acceptance at <a target="_blank" rel="noopener" href="https://github.com/vios-s">https://github.com/vios-s</a>. </p>
<blockquote>
<p>å®šä½ç»™å®šåŒ»å­¦æ‰«æä¸­çš„ç²¾ç¡®ç—…ç†åŒºåŸŸæ˜¯ä¸€ä¸ªé‡è¦çš„æˆåƒé—®é¢˜ï¼Œä¼ ç»Ÿä¸Šéœ€è¦å¤§é‡çš„è¾¹ç•Œæ¡†çœŸå®æ ‡æ³¨æ¥å‡†ç¡®è§£å†³ã€‚ç„¶è€Œï¼Œå­˜åœ¨æ›¿ä»£çš„ã€æ½œåœ¨çš„è¾ƒå¼±å½¢å¼çš„ç›‘ç£ï¼Œä¾‹å¦‚ä¼´éšçš„è‡ªç”±æ–‡æœ¬æŠ¥å‘Šï¼Œè¿™äº›æŠ¥å‘Šå¾ˆå®¹æ˜“è·å¾—ã€‚ä½¿ç”¨æ–‡æœ¬æŒ‡å¯¼è¿›è¡Œå®šä½çš„ä»»åŠ¡é€šå¸¸è¢«ç§°ä¸ºçŸ­è¯­æ¥åœ°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå…¬å¼€çš„Foundationæ¨¡å‹ï¼Œå³æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œæ¥æ‰§è¡Œè¿™é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚æˆ‘ä»¬é€‰æ‹©è¿™ä¸ªæ¨¡å‹çš„æ”¯æŒåœ¨äºï¼Œå°½ç®¡æ½œåœ¨æ‰©æ•£æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯ç”Ÿæˆå¼çš„ï¼Œä½†å®ƒåŒ…å«äº¤å‰æ³¨æ„æœºåˆ¶ï¼Œèƒ½å¤Ÿéšå¼åœ°å¯¹é½è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ï¼Œä»è€Œäº§ç”Ÿé€‚åˆå½“å‰ä»»åŠ¡çš„ä¸­é—´è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ—¨åœ¨ä»¥é›¶æ ·æœ¬çš„æ–¹å¼è¿›è¡Œæ­¤ä»»åŠ¡ï¼Œå³æ— éœ€å¯¹ç›®æ ‡ä»»åŠ¡è¿›è¡Œä»»ä½•è®­ç»ƒï¼Œè¿™æ„å‘³ç€æ¨¡å‹çš„æƒé‡ä¿æŒå†»ç»“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ¶å®šäº†é€‰æ‹©ç‰¹å¾çš„ç­–ç•¥ï¼Œå¹¶é€šè¿‡åå¤„ç†å¯¹å®ƒä»¬è¿›è¡Œç»†åŒ–ï¼Œè€Œæ— éœ€é¢å¤–çš„å¯å­¦ä¹ å‚æ•°ã€‚æˆ‘ä»¬å°†æ‰€æå‡ºçš„æ–¹æ³•ä¸æœ€æ–°æŠ€æœ¯è¿›è¡Œæ¯”è¾ƒï¼Œåè€…é€šè¿‡å¯¹æ¯”å­¦ä¹ åœ¨è”åˆåµŒå…¥ç©ºé—´ä¸­æ˜¾å¼åœ°æ‰§è¡Œå›¾åƒæ–‡æœ¬å¯¹é½ã€‚åœ¨æµè¡Œçš„èƒ¸éƒ¨Xå°„çº¿åŸºå‡†æµ‹è¯•ä¸Šçš„ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒç±»å‹çš„ç—…ç†ä¸Šä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ï¼Œç”šè‡³åœ¨ä¸¤ä¸ªæŒ‡æ ‡ï¼ˆå¹³å‡IoUå’ŒAUC-ROCï¼‰ä¸Šçš„å¹³å‡è¡¨ç°ä¼˜äºå®ƒä»¬ã€‚æºä»£ç å°†åœ¨æ¥å—åå‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/vios-s%E3%80%82">https://github.com/vios-sã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12920v4">PDF</a> 10 pages, 3 figures, IEEE J-BHI Special Issue on Foundation Models in   Medical Imaging</p>
<p><strong>æ‘˜è¦</strong><br>åŸºäºå…¬å¼€å¯ç”¨çš„åŸºç¡€æ¨¡å‹â€”â€”æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå®ç°æ— éœ€æ ‡æ³¨æ•°æ®çš„åŒ»å­¦å›¾åƒç—…å˜åŒºåŸŸå®šä½ï¼ˆç§°ä¸ºçŸ­è¯­å®šä½ä»»åŠ¡ï¼‰ã€‚æ¨¡å‹æ— éœ€é’ˆå¯¹ç›®æ ‡ä»»åŠ¡è¿›è¡Œè®­ç»ƒï¼Œå¯å€ŸåŠ©æ¨¡å‹å†…å»ºçš„è·¨æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œè§†è§‰ä¸æ–‡æœ¬ç‰¹å¾çš„éšå¼å¯¹é½ï¼Œä»¥äº§ç”Ÿé€‚ç”¨äºè¯¥ä»»åŠ¡çš„ä¸­ä»‹è¡¨ç¤ºã€‚é€šè¿‡ç­–ç•¥é€‰æ‹©åŠåå¤„ç†ç²¾ç‚¼ç‰¹å¾ï¼Œæ— éœ€é¢å¤–å­¦ä¹ å‚æ•°ã€‚ä¸é€šè¿‡å¯¹æ¯”å­¦ä¹ åœ¨è”åˆåµŒå…¥ç©ºé—´ä¸­æ˜¾å¼æ‰§è¡Œå›¾åƒæ–‡æœ¬å¯¹é½çš„æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¬å…±èƒ¸Xå°„çº¿åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå¹¶åœ¨ä¸¤ç§æŒ‡æ ‡ï¼ˆå¹³å‡IoUå’ŒAUC-ROCï¼‰ä¸Šå¹³å‡è¡¨ç°æ›´ä¼˜ã€‚æºä»£ç å°†åœ¨æ¥å—åå‘å¸ƒäºGitHubã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åˆ©ç”¨å…¬å¼€çš„åŸºç¡€æ¨¡å‹â€”â€”æ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡ŒåŒ»å­¦å›¾åƒç—…å˜åŒºåŸŸå®šä½ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨é›¶æ ·æœ¬è®­ç»ƒæ–¹å¼ï¼Œæ— éœ€é’ˆå¯¹ç›®æ ‡ä»»åŠ¡è¿›è¡Œè®­ç»ƒã€‚</li>
<li>æ¨¡å‹åˆ©ç”¨è·¨æ³¨æ„åŠ›æœºåˆ¶éšå¼å¯¹é½è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ã€‚</li>
<li>æå‡ºç‰¹å¾é€‰æ‹©å’Œåå¤„ç†ç­–ç•¥ä»¥ç²¾ç‚¼ç‰¹å¾ï¼Œæ— éœ€é¢å¤–å­¦ä¹ å‚æ•°ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å…¬å…±èƒ¸Xå°„çº¿åŸºå‡†æµ‹è¯•ä¸Šå…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>åœ¨ä¸¤ç§è¯„ä¼°æŒ‡æ ‡ä¸Šå¹³å‡è¡¨ç°æ›´ä¼˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.12920">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-52a118dfaa5bdf689cf583ea4b38a6cf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-67b0e20024063b7da6a0486c12e12d59.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96d5591974fd0a745f3e1b0631a054d7.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-01/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-01/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-01/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-3313172443e1fb5a4d8285eaf2c522ef.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-01  Diffusion Autoencoders are Scalable Image Tokenizers
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-01/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-3bd5ff2abd6a8aef1dfc73fbb8d0838c.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-01  VoD-3DGS View-opacity-Dependent 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24801.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
