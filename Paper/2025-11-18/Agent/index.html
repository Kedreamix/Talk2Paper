<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-18  DocLens  A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9af9c660188a1cf64857328efc238ec7')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    64 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-18-æ›´æ–°"><a href="#2025-11-18-æ›´æ–°" class="headerlink" title="2025-11-18 æ›´æ–°"></a>2025-11-18 æ›´æ–°</h1><h2 id="DocLens-A-Tool-Augmented-Multi-Agent-Framework-for-Long-Visual-Document-Understanding"><a href="#DocLens-A-Tool-Augmented-Multi-Agent-Framework-for-Long-Visual-Document-Understanding" class="headerlink" title="DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding"></a>DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding</h2><p><strong>Authors:Dawei Zhu, Rui Meng, Jiefeng Chen, Sujian Li, Tomas Pfister, Jinsung Yoon</strong></p>
<p>Comprehending long visual documents, where information is distributed across extensive pages of text and visual elements, is a critical but challenging task for modern Vision-Language Models (VLMs). Existing approaches falter on a fundamental challenge: evidence localization. They struggle to retrieve relevant pages and overlook fine-grained details within visual elements, leading to limited performance and model hallucination. To address this, we propose DocLens, a tool-augmented multi-agent framework that effectively &#96;&#96;zooms inâ€™â€™ on evidence like a lens. It first navigates from the full document to specific visual elements on relevant pages, then employs a sampling-adjudication mechanism to generate a single, reliable answer. Paired with Gemini-2.5-Pro, DocLens achieves state-of-the-art performance on MMLongBench-Doc and FinRAGBench-V, surpassing even human experts. The frameworkâ€™s superiority is particularly evident on vision-centric and unanswerable queries, demonstrating the power of its enhanced localization capabilities.</p>
<blockquote>
<p>ç†è§£å’Œå¤„ç†é•¿è§†è§‰æ–‡æ¡£æ˜¯ä¸€ä¸ªå¯¹ç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è‡³å…³é‡è¦ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¿¡æ¯åˆ†å¸ƒåœ¨å¤§é‡æ–‡æœ¬å’Œè§†è§‰å…ƒç´ ä¸­ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼šè¯æ®å®šä½ã€‚ä»–ä»¬éš¾ä»¥æ£€ç´¢ç›¸å…³é¡µé¢ï¼Œå¹¶å¿½ç•¥äº†è§†è§‰å…ƒç´ ä¸­çš„ç»†å¾®ç»†èŠ‚ï¼Œå¯¼è‡´æ€§èƒ½æœ‰é™å’Œæ¨¡å‹å¹»è§‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DocLensï¼Œè¿™æ˜¯ä¸€ä¸ªå·¥å…·å¢å¼ºå‹å¤šä»£ç†æ¡†æ¶ï¼Œå¯ä»¥åƒé•œå¤´ä¸€æ ·æœ‰æ•ˆåœ°â€œæ”¾å¤§â€è¯æ®ã€‚å®ƒé¦–å…ˆä»æ•´ä¸ªæ–‡æ¡£å¯¼èˆªåˆ°ç›¸å…³é¡µé¢ä¸Šçš„ç‰¹å®šè§†è§‰å…ƒç´ ï¼Œç„¶åé‡‡ç”¨é‡‡æ ·åˆ¤å†³æœºåˆ¶ç”Ÿæˆå•ä¸€ã€å¯é çš„ç­”æ¡ˆã€‚ä¸Gemini-2.5-Proé…å¯¹ï¼ŒDocLensåœ¨MMLongBench-Docå’ŒFinRAGBench-Vä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†äººç±»ä¸“å®¶ã€‚è¯¥æ¡†æ¶åœ¨è§†è§‰ä¸ºä¸­å¿ƒå’Œæ— æ³•å›ç­”çš„é—®é¢˜ä¸Šè¡¨ç°å¾—å°¤ä¸ºå‡ºè‰²ï¼Œè¯æ˜äº†å…¶å¢å¼ºå®šä½èƒ½åŠ›çš„å¼ºå¤§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11552v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šé’ˆå¯¹ç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤„ç†é•¿æ–‡æ¡£æ—¶çš„æŒ‘æˆ˜ï¼Œå¦‚è¯æ®å®šä½é—®é¢˜å’Œå¿½è§†ç»†å¾®ç»†èŠ‚çš„é—®é¢˜ï¼Œæå‡ºäº†DocLenså·¥å…·å¢å¼ºå¤šä»£ç†æ¡†æ¶ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåƒé€é•œä¸€æ ·æœ‰æ•ˆåœ°â€œæ”¾å¤§â€è¯æ®ï¼Œé¦–å…ˆåœ¨æ•´ç¯‡æ–‡æ¡£ä¸­å¯¼èˆªåˆ°ç›¸å…³é¡µé¢çš„ç‰¹å®šè§†è§‰å…ƒç´ ï¼Œç„¶åé‡‡ç”¨é‡‡æ ·åˆ¤å†³æœºåˆ¶ç”Ÿæˆå•ä¸€å¯é çš„ç­”æ¡ˆã€‚ç»“åˆGemini-2.5-Proï¼ŒDocLensåœ¨MMLongBench-Docå’ŒFinRAGBench-Vä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œç”šè‡³è¶…è¶Šäº†äººç±»ä¸“å®¶ã€‚ç‰¹åˆ«æ˜¯åœ¨ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„ä¸å¯å›ç­”æŸ¥è¯¢ä¸­ï¼Œè¯¥æ¡†æ¶çš„å“è¶Šæ€§èƒ½æ˜¾ç¤ºäº†å…¶å¢å¼ºå®šä½èƒ½åŠ›çš„å¼ºå¤§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤„ç†é•¿æ–‡æ¡£æ—¶é¢ä¸´æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è¯æ®å®šä½é—®é¢˜å’Œå¿½è§†ç»†å¾®ç»†èŠ‚çš„é—®é¢˜ã€‚</li>
<li>DocLensæ˜¯ä¸€ä¸ªå·¥å…·å¢å¼ºå¤šä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>DocLensé€šè¿‡å¯¼èˆªåˆ°ç›¸å…³é¡µé¢çš„ç‰¹å®šè§†è§‰å…ƒç´ å¹¶æ”¾å¤§è¿™äº›å…ƒç´ æ¥å·¥ä½œã€‚</li>
<li>DocLensé‡‡ç”¨é‡‡æ ·åˆ¤å†³æœºåˆ¶ç”Ÿæˆå•ä¸€å¯é çš„ç­”æ¡ˆã€‚</li>
<li>ç»“åˆGemini-2.5-Proï¼ŒDocLensåœ¨MMLongBench-Docå’ŒFinRAGBench-Vä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>DocLensåœ¨è§†è§‰ä¸­å¿ƒå’Œä¸å¯å›ç­”æŸ¥è¯¢æ–¹é¢çš„è¡¨ç°å°¤å…¶å‡ºè‰²ï¼Œæ˜¾ç¤ºäº†å…¶å¢å¼ºå®šä½èƒ½åŠ›çš„å¼ºå¤§ã€‚</li>
<li>DocLensçš„æ€§èƒ½ç”šè‡³è¶…è¶Šäº†äººç±»ä¸“å®¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11552">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cdd65206f009b3cfa2e2324b3a88cdb0" align="middle">
<img src="https://picx.zhimg.com/v2-7d509259dec03fee08eec546a19ffaf7" align="middle">
<img src="https://picx.zhimg.com/v2-438764aff46709c8719b653d9ab34c00" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Aligning-Machiavellian-Agents-Behavior-Steering-via-Test-Time-Policy-Shaping"><a href="#Aligning-Machiavellian-Agents-Behavior-Steering-via-Test-Time-Policy-Shaping" class="headerlink" title="Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping"></a>Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping</h2><p><strong>Authors:Dena Mujtaba, Brian Hu, Anthony Hoogs, Arslan Basharat</strong></p>
<p>The deployment of decision-making AI agents presents a critical challenge in maintaining alignment with human values or guidelines while operating in complex, dynamic environments. Agents trained solely to achieve their objectives may adopt harmful behavior, exposing a key trade-off between maximizing the reward function and maintaining the alignment. For the pre-trained agents, ensuring alignment is particularly challenging, as retraining can be a costly and slow process. This is further complicated by the diverse and potentially conflicting attributes representing the ethical values for alignment. To address these challenges, we propose a test-time alignment technique based on model-guided policy shaping. Our method allows precise control over individual behavioral attributes, generalizes across diverse reinforcement learning (RL) environments, and facilitates a principled trade-off between ethical alignment and reward maximization without requiring agent retraining. We evaluate our approach using the MACHIAVELLI benchmark, which comprises 134 text-based game environments and thousands of annotated scenarios involving ethical decisions. The RL agents are first trained to maximize the reward in their respective games. At test time, we apply policy shaping via scenario-action attribute classifiers to ensure decision alignment with ethical attributes. We compare our approach against prior training-time methods and general-purpose agents, as well as study several types of ethical violations and power-seeking behavior. Our results demonstrate that test-time policy shaping provides an effective and scalable solution for mitigating unethical behavior across diverse environments and alignment attributes.</p>
<blockquote>
<p>å†³ç­–AIä»£ç†çš„éƒ¨ç½²åœ¨å¤æ‚ã€åŠ¨æ€çš„ç¯å¢ƒä¸­è¿è¡Œæ—¶ï¼Œå¦‚ä½•ä¿æŒä¸äººç±»ä»·å€¼è§‚æˆ–æŒ‡å—çš„ä¸€è‡´æ€§æ˜¯ä¸€ä¸ªå…³é”®çš„æŒ‘æˆ˜ã€‚ä»…ä¸ºäº†è¾¾æˆç›®æ ‡è€Œè®­ç»ƒçš„ä»£ç†å¯èƒ½ä¼šé‡‡å–æœ‰å®³çš„è¡Œä¸ºï¼Œè¿™æš´éœ²å‡ºåœ¨æœ€å¤§åŒ–å¥–åŠ±å‡½æ•°å’Œä¿æŒä¸€è‡´æ€§ä¹‹é—´çš„å…³é”®æƒè¡¡ã€‚å¯¹äºé¢„è®­ç»ƒçš„ä»£ç†æ¥è¯´ï¼Œç¡®ä¿ä¸€è‡´æ€§å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºé‡æ–°è®­ç»ƒå¯èƒ½æ˜¯ä¸€ä¸ªæˆæœ¬é«˜ä¸”é€Ÿåº¦æ…¢çš„è¿‡ç¨‹ã€‚ç”±ä»£è¡¨å¯¹é½é“å¾·ä»·å€¼çš„å¤šæ ·åŒ–å’Œæ½œåœ¨å†²çªçš„å±æ€§è¿›ä¸€æ­¥åŠ å‰§äº†è¿™ä¸€å¤æ‚æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å‹å¼•å¯¼ç­–ç•¥å¡‘é€ çš„æµ‹è¯•æ—¶å¯¹é½æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å¯¹å•ä¸ªè¡Œä¸ºå±æ€§è¿›è¡Œç²¾ç¡®æ§åˆ¶ï¼Œå¯ä»¥æ³›åŒ–åˆ°å„ç§å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç¯å¢ƒä¸­ï¼Œå¹¶åœ¨ä¸éœ€è¦ä»£ç†é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿåœ¨é“å¾·å¯¹é½å’Œå¥–åŠ±æœ€å¤§åŒ–ä¹‹é—´å®ç°æœ‰åŸåˆ™çš„æƒè¡¡ã€‚æˆ‘ä»¬ä½¿ç”¨MACHIAVELLIåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯¥åŸºå‡†æµ‹è¯•åŒ…æ‹¬134ä¸ªåŸºäºæ–‡æœ¬çš„æ¸¸æˆç¯å¢ƒå’Œæ¶‰åŠé“å¾·å†³ç­–çš„æ•°åƒä¸ªæ³¨é‡Šåœºæ™¯ã€‚é¦–å…ˆï¼ŒRLä»£ç†è¢«è®­ç»ƒåœ¨å…¶å„è‡ªçš„æ¸¸æˆä¸­æœ€å¤§åŒ–å¥–åŠ±ã€‚åœ¨æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡æƒ…æ™¯åŠ¨ä½œå±æ€§åˆ†ç±»å™¨è¿›è¡Œç­–ç•¥å¡‘é€ ï¼Œä»¥ç¡®ä¿å†³ç­–ä¸é“å¾·å±æ€§å¯¹é½ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸å…ˆå‰çš„è®­ç»ƒæ—¶æ–¹æ³•å’Œé€šç”¨ä»£ç†è¿›è¡Œäº†æ¯”è¾ƒï¼Œå¹¶ç ”ç©¶äº†å¤šç§ç±»å‹çš„é“å¾·è¿è§„å’ŒæƒåŠ›å¯»æ±‚è¡Œä¸ºã€‚ç»“æœè¡¨æ˜ï¼Œæµ‹è¯•æ—¶çš„ç­–ç•¥å¡‘é€ ä¸ºå‡è½»ä¸åŒç¯å¢ƒå’Œå¯¹é½å±æ€§ä¸­çš„ä¸é“å¾·è¡Œä¸ºæä¾›äº†ä¸€ç§æœ‰æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11551v1">PDF</a> Accepted to AAAI 2026 AI Alignment Track</p>
<p><strong>Summary</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11551">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a5d157465d617c9542e61b8d657c9e3b" align="middle">
<img src="https://picx.zhimg.com/v2-4f7a0e6740a0376267d7d056e6013a71" align="middle">
<img src="https://picx.zhimg.com/v2-181d15627cbea2bb97db4057840c1159" align="middle">
<img src="https://picx.zhimg.com/v2-b10beb8503933f918367f7fe752902ce" align="middle">
<img src="https://picx.zhimg.com/v2-8971f75d50fa21101acac7e5ff8ac346" align="middle">
<img src="https://picx.zhimg.com/v2-f69c4b697bebf690a7622ed4fb3e2da3" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ImAgent-A-Unified-Multimodal-Agent-Framework-for-Test-Time-Scalable-Image-Generation"><a href="#ImAgent-A-Unified-Multimodal-Agent-Framework-for-Test-Time-Scalable-Image-Generation" class="headerlink" title="ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable Image Generation"></a>ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable Image Generation</h2><p><strong>Authors:Kaishen Wang, Ruibo Chen, Tong Zheng, Heng Huang</strong></p>
<p>Recent text-to-image (T2I) models have made remarkable progress in generating visually realistic and semantically coherent images. However, they still suffer from randomness and inconsistency with the given prompts, particularly when textual descriptions are vague or underspecified. Existing approaches, such as prompt rewriting, best-of-N sampling, and self-refinement, can mitigate these issues but usually require additional modules and operate independently, hindering test-time scaling efficiency and increasing computational overhead. In this paper, we introduce ImAgent, a training-free unified multimodal agent that integrates reasoning, generation, and self-evaluation within a single framework for efficient test-time scaling. Guided by a policy controller, multiple generation actions dynamically interact and self-organize to enhance image fidelity and semantic alignment without relying on external models. Extensive experiments on image generation and editing tasks demonstrate that ImAgent consistently improves over the backbone and even surpasses other strong baselines where the backbone model fails, highlighting the potential of unified multimodal agents for adaptive and efficient image generation under test-time scaling.</p>
<blockquote>
<p>è¿‘æœŸæ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹åœ¨ç”Ÿæˆè§†è§‰ä¸Šé€¼çœŸä¸”è¯­ä¹‰ä¸Šè¿è´¯çš„å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶å—åˆ°ç»™å®šæç¤ºçš„éšæœºæ€§å’Œä¸ä¸€è‡´æ€§çš„å›°æ‰°ï¼Œå°¤å…¶æ˜¯åœ¨æ–‡æœ¬æè¿°æ¨¡ç³Šæˆ–æœªæŒ‡å®šæ—¶ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚æç¤ºé‡å†™ã€æœ€ä½³Né‡‡æ ·å’Œè‡ªæˆ‘å®Œå–„ï¼Œå¯ä»¥ç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†å®ƒä»¬é€šå¸¸éœ€è¦é¢å¤–çš„æ¨¡å—å¹¶ä¸”ç‹¬ç«‹æ“ä½œï¼Œé˜»ç¢äº†æµ‹è¯•æ—¶çš„è§„æ¨¡æ‰©å±•æ•ˆç‡å¹¶å¢åŠ äº†è®¡ç®—å¼€é”€ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ImAgentï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç†ï¼Œå®ƒåœ¨ä¸€ä¸ªæ¡†æ¶å†…é›†æˆäº†æ¨ç†ã€ç”Ÿæˆå’Œè‡ªæˆ‘è¯„ä¼°ï¼Œä»¥å®ç°æœ‰æ•ˆçš„æµ‹è¯•æ—¶é—´ç¼©æ”¾ã€‚åœ¨ç­–ç•¥æ§åˆ¶å™¨çš„å¼•å¯¼ä¸‹ï¼Œå¤šä¸ªç”ŸæˆåŠ¨ä½œèƒ½å¤ŸåŠ¨æ€äº¤äº’å¹¶è‡ªæˆ‘ç»„ç»‡ï¼Œä»¥æé«˜å›¾åƒçš„çœŸå®æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨æ¨¡å‹ã€‚åœ¨å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒImAgentå§‹ç»ˆåœ¨ä¸»å¹²ç½‘ç»œä¸Šæœ‰æ‰€æå‡ï¼Œç”šè‡³åœ¨ä¸»å¹²æ¨¡å‹å¤±è´¥çš„æƒ…å†µä¸‹ä¹Ÿè¶…è¿‡äº†å…¶ä»–å¼ºå¤§çš„åŸºçº¿ï¼Œè¿™çªæ˜¾äº†ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç†åœ¨æµ‹è¯•æ—¶é—´ç¼©æ”¾ä¸‹çš„è‡ªé€‚åº”å’Œé«˜æ•ˆå›¾åƒç”Ÿæˆçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11483v1">PDF</a> 12 pages, 5 tables, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹åœ¨ç”Ÿæˆè§†è§‰çœŸå®ä¸”è¯­ä¹‰è¿è´¯çš„å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä½†ä»å­˜åœ¨éšæœºæ€§å’Œä¸æç¤ºä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå°¤å…¶åœ¨æ–‡æœ¬æè¿°æ¨¡ç³Šæˆ–æœªæ˜ç¡®æŒ‡å®šæ—¶ã€‚ç°æœ‰æ–¹æ³•å¦‚æç¤ºé‡å†™ã€æœ€ä½³Né‡‡æ ·å’Œè‡ªæˆ‘å®Œå–„ç­‰ï¼Œè™½èƒ½ç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†éœ€è¦é¢å¤–çš„æ¨¡å—å¹¶ä¸”æ“ä½œç‹¬ç«‹ï¼Œå½±å“æµ‹è¯•æ—¶çš„ç¼©æ”¾æ•ˆç‡å¹¶å¢åŠ äº†è®¡ç®—å¼€é”€ã€‚æœ¬æ–‡æå‡ºImAgentï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç†ï¼Œå®ƒåœ¨ä¸€ä¸ªæ¡†æ¶å†…é›†æˆäº†æ¨ç†ã€ç”Ÿæˆå’Œè‡ªæˆ‘è¯„ä¼°ï¼Œä»¥å®ç°é«˜æ•ˆçš„æµ‹è¯•æ—¶ç¼©æ”¾ã€‚å—ç­–ç•¥æ§åˆ¶å™¨çš„å¼•å¯¼ï¼Œå¤šä¸ªç”ŸæˆåŠ¨ä½œèƒ½åŠ¨æ€äº¤äº’å’Œè‡ªæˆ‘ç»„ç»‡ï¼Œæé«˜å›¾åƒä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼Œæ— éœ€ä¾èµ–å¤–éƒ¨æ¨¡å‹ã€‚åœ¨å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒImAgentä¸æ–­æ”¹å–„å¹¶è¶…è¶Šå…¶ä»–å¼ºå¤§åŸºçº¿ï¼Œå³ä½¿èƒŒæ™¯æ¨¡å‹å¤±è´¥ä¹Ÿå¦‚æ­¤ï¼Œå‡¸æ˜¾å‡ºç»Ÿä¸€å¤šæ¨¡æ€ä»£ç†åœ¨æµ‹è¯•æ—¶ç¼©æ”¾è‡ªé€‚åº”å’Œé«˜æ•ˆå›¾åƒç”Ÿæˆçš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹åœ¨ç”Ÿæˆè§†è§‰ä¸ŠçœŸå®å’Œè¯­ä¹‰ä¸Šè¿è´¯çš„å›¾åƒæ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚</li>
<li>å½“å‰æ¨¡å‹ä»é¢ä¸´éšæœºæ€§å’Œä¸æç¤ºä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå°¤å…¶åœ¨æ–‡æœ¬æè¿°æ¨¡ç³Šæ—¶ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚æç¤ºé‡å†™ã€æœ€ä½³Né‡‡æ ·å’Œè‡ªæˆ‘å®Œå–„éœ€è¦é¢å¤–çš„æ¨¡å—ï¼Œæ“ä½œç‹¬ç«‹ï¼Œå½±å“æ•ˆç‡ã€‚</li>
<li>ImAgentæ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„ç»Ÿä¸€å¤šæ¨¡æ€ä»£ç†ï¼Œé›†æˆäº†æ¨ç†ã€ç”Ÿæˆå’Œè‡ªæˆ‘è¯„ä¼°ã€‚</li>
<li>ImAgenté€šè¿‡ç­–ç•¥æ§åˆ¶å™¨å¼•å¯¼å¤šä¸ªç”ŸæˆåŠ¨ä½œçš„åŠ¨æ€äº¤äº’å’Œè‡ªæˆ‘ç»„ç»‡ã€‚</li>
<li>ImAgentæé«˜äº†å›¾åƒä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼Œä¸”æ— éœ€ä¾èµ–å¤–éƒ¨æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c0f12726d17ef4a9258449a5e9cc5ce2" align="middle">
<img src="https://picx.zhimg.com/v2-226b0570ec9c347da4ee51fcb163817a" align="middle">
<img src="https://picx.zhimg.com/v2-6052c110c57cd9c4ae5cb6f1a87075a0" align="middle">
<img src="https://picx.zhimg.com/v2-61c643ffc15036bbe8b5983ea8238639" align="middle">
<img src="https://picx.zhimg.com/v2-993a9a38cadef608025b04185f94be13" align="middle">
<img src="https://picx.zhimg.com/v2-a19b7102f6d9297b4e8420998ccc1c6e" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SRLF-An-Agent-Driven-Set-Wise-Reflective-Learning-Framework-for-Sequential-Recommendation"><a href="#SRLF-An-Agent-Driven-Set-Wise-Reflective-Learning-Framework-for-Sequential-Recommendation" class="headerlink" title="SRLF: An Agent-Driven Set-Wise Reflective Learning Framework for Sequential Recommendation"></a>SRLF: An Agent-Driven Set-Wise Reflective Learning Framework for Sequential Recommendation</h2><p><strong>Authors:Jiahao Wang, Bokang Fu, Yu Zhu, Yuli Liu</strong></p>
<p>LLM-based agents are emerging as a promising paradigm for simulating user behavior to enhance recommender systems. However, their effectiveness is often limited by existing studies that focus on modeling user ratings for individual items. This point-wise approach leads to prevalent issues such as inaccurate user preference comprehension and rigid item-semantic representations.   To address these limitations, we propose the novel Set-wise Reflective Learning Framework (SRLF). Our framework operationalizes a closed-loop â€œassess-validate-reflectâ€ cycle that harnesses the powerful in-context learning capabilities of LLMs. SRLF departs from conventional point-wise assessment by formulating a holistic judgment on an entire set of items. It accomplishes this by comprehensively analyzing both the intricate interrelationships among items within the set and their collective alignment with the userâ€™s preference profile. This method of set-level contextual understanding allows our model to capture complex relational patterns essential to user behavior, making it significantly more adept for sequential recommendation. Extensive experiments validate our approach, confirming that this set-wise perspective is crucial for achieving state-of-the-art performance in sequential recommendation tasks.</p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†ï¼ˆLLM-based agentsï¼‰ä½œä¸ºä¸€ç§æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºä»¥å¢å¼ºæ¨èç³»ç»Ÿçš„æœ‰å‰é€”çš„æ¨¡å¼æ­£å´­éœ²å¤´è§’ã€‚ç„¶è€Œï¼Œå…¶æœ‰æ•ˆæ€§é€šå¸¸å—é™äºç°æœ‰ç ”ç©¶ï¼Œè¿™äº›ç ”ç©¶é›†ä¸­åœ¨ä¸ºå•ä¸ªé¡¹ç›®å»ºç«‹ç”¨æˆ·è¯„çº§æ¨¡å‹ä¸Šã€‚è¿™ç§ç‚¹å¯¹ç‚¹çš„æ–¹æ³•å¯¼è‡´äº†æ™®éå­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚ç”¨æˆ·åå¥½ç†è§£ä¸å‡†ç¡®å’Œé¡¹ç›®è¯­ä¹‰è¡¨ç¤ºåƒµåŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„é›†åˆçº§åæ€å­¦ä¹ æ¡†æ¶ï¼ˆSRLFï¼‰ã€‚æˆ‘ä»¬çš„æ¡†æ¶å®æ–½äº†ä¸€ä¸ªé—­ç¯çš„â€œè¯„ä¼°-éªŒè¯-åæ€â€å‘¨æœŸï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚SRLFé€šè¿‡å¯¹æ•´ä¸ªé¡¹ç›®é›†è¿›è¡Œæ•´ä½“åˆ¤æ–­ï¼Œä»è€Œæ”¹å˜äº†ä¼ ç»Ÿçš„ç‚¹å¯¹ç‚¹è¯„ä¼°æ–¹å¼ã€‚å®ƒé€šè¿‡ç»¼åˆåˆ†æé›†åˆå†…é¡¹ç›®ä¹‹é—´å¤æ‚çš„å…³ç³»ä»¥åŠå®ƒä»¬ä¸ç”¨æˆ·åå¥½é…ç½®çš„é›†ä½“ä¸€è‡´æ€§æ¥å®ç°è¿™ä¸€ç‚¹ã€‚è¿™ç§é›†åˆçº§åˆ«çš„ä¸Šä¸‹æ–‡ç†è§£æ–¹æ³•ä½¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°å¯¹ç”¨æˆ·è¡Œä¸ºè‡³å…³é‡è¦çš„å¤æ‚å…³ç³»æ¨¡å¼ï¼Œä½¿å…¶åœ¨åºåˆ—æ¨èæ–¹é¢æ›´åŠ æ“…é•¿ã€‚å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†é›†åˆè§‚ç‚¹å¯¹äºå®ç°æœ€å…ˆè¿›çš„åºåˆ—æ¨èä»»åŠ¡æ€§èƒ½è‡³å…³é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11370v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>åŸºäºLLMçš„ä»£ç†æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºä»¥å¢å¼ºæ¨èç³»ç»Ÿï¼Œå±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç ”ç©¶å¤šèšç„¦äºå¯¹ç”¨æˆ·å•ä¸ªé¡¹ç›®çš„è¯„åˆ†å»ºæ¨¡ï¼Œè¿™ç§æ–¹å¼å¯¼è‡´ç”¨æˆ·åå¥½ç†è§£ä¸å‡†ç¡®å’Œé¡¹ç›®è¯­ä¹‰è¡¨ç¤ºåƒµåŒ–ç­‰é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„Set-wise Reflective Learning Frameworkï¼ˆSRLFï¼‰ã€‚æˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡æ“ä½œä¸€ä¸ªé—­ç¯çš„â€œè¯„ä¼°-éªŒè¯-åæ€â€å‘¨æœŸï¼Œåˆ©ç”¨LLMçš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚SRLFä¸åŒäºä¼ ç»Ÿçš„ç‚¹æ€è¯„ä¼°ï¼Œå®ƒå¯¹æ•´ä¸ªé¡¹ç›®é›†è¿›è¡Œæ•´ä½“åˆ¤æ–­ã€‚é€šè¿‡å…¨é¢åˆ†æé¡¹ç›®ä¹‹é—´çš„å¤æ‚ç›¸äº’å…³ç³»ä»¥åŠå®ƒä»¬ä¸ç”¨æˆ·åå¥½ä¹‹é—´çš„é›†ä½“ä¸€è‡´æ€§ï¼Œå®ç°äº†é›†åˆçº§åˆ«çš„ä¸Šä¸‹æ–‡ç†è§£ï¼Œä»è€Œæ•æ‰å¯¹ç”¨æˆ·è¡Œä¸ºè‡³å…³é‡è¦çš„å¤æ‚å…³ç³»æ¨¡å¼ï¼Œä½¿å…¶å¯¹åºåˆ—æ¨èä»»åŠ¡æ›´åŠ æ“…é•¿ã€‚å®éªŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†é›†åˆè§†è§’å¯¹äºå®ç°æœ€å…ˆè¿›çš„åºåˆ—æ¨èä»»åŠ¡æ€§èƒ½è‡³å…³é‡è¦ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>LLM-based agentså±•ç°å‡ºåœ¨æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºä»¥å¢å¼ºæ¨èç³»ç»Ÿä¸­çš„æ½œåŠ›ã€‚</li>
<li>ç°æœ‰ç ”ç©¶èšç„¦äºç”¨æˆ·å•ä¸ªé¡¹ç›®çš„è¯„åˆ†å»ºæ¨¡ï¼Œå¯¼è‡´ç”¨æˆ·åå¥½ç†è§£ä¸å‡†ç¡®å’Œé¡¹ç›®è¯­ä¹‰è¡¨ç¤ºåƒµåŒ–ã€‚</li>
<li>æå‡ºçš„Set-wise Reflective Learning Framework (SRLF) é€šè¿‡æ“ä½œé—­ç¯çš„â€œè¯„ä¼°-éªŒè¯-åæ€â€å‘¨æœŸæ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>SRLFåˆ©ç”¨LLMçš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œå®ç°äº†é›†åˆçº§åˆ«çš„æ•´ä½“åˆ¤æ–­ï¼Œå…¨é¢åˆ†æé¡¹ç›®é—´çš„å¤æ‚å…³ç³»ä»¥åŠå®ƒä»¬ä¸ç”¨æˆ·åå¥½çš„ä¸€è‡´æ€§ã€‚</li>
<li>SRLFé€šè¿‡æ•æ‰å¤æ‚çš„å…³ç³»æ¨¡å¼æé«˜äº†æ¨¡å‹å¯¹åºåˆ—æ¨èä»»åŠ¡çš„é€‚åº”æ€§ã€‚</li>
<li>å®éªŒè¯æ˜äº†é›†åˆè§†è§’å¯¹äºå®ç°æœ€å…ˆè¿›çš„åºåˆ—æ¨èä»»åŠ¡æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11370">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6903cd10971eea9e8118fecde6e39e22" align="middle">
<img src="https://picx.zhimg.com/v2-f29f0a3409f0b3f35cdc35a33f17cba4" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="NOVA-An-Agentic-Framework-for-Automated-Histopathology-Analysis-and-Discovery"><a href="#NOVA-An-Agentic-Framework-for-Automated-Histopathology-Analysis-and-Discovery" class="headerlink" title="NOVA: An Agentic Framework for Automated Histopathology Analysis and Discovery"></a>NOVA: An Agentic Framework for Automated Histopathology Analysis and Discovery</h2><p><strong>Authors:Anurag J. Vaidya, Felix Meissen, Daniel C. Castro, Shruthi Bannur, Tristan Lazard, Drew F. K. Williamson, Faisal Mahmood, Javier Alvarez-Valle, Stephanie L. Hyland, Kenza Bouzid</strong></p>
<p>Digitized histopathology analysis involves complex, time-intensive workflows and specialized expertise, limiting its accessibility. We introduce NOVA, an agentic framework that translates scientific queries into executable analysis pipelines by iteratively generating and running Python code. NOVA integrates 49 domain-specific tools (e.g., nuclei segmentation, whole-slide encoding) built on open-source software, and can also create new tools ad hoc. To evaluate such systems, we present SlideQuest, a 90-question benchmark â€“ verified by pathologists and biomedical scientists â€“ spanning data processing, quantitative analysis, and hypothesis testing. Unlike prior biomedical benchmarks focused on knowledge recall or diagnostic QA, SlideQuest demands multi-step reasoning, iterative coding, and computational problem solving. Quantitative evaluation shows NOVA outperforms coding-agent baselines, and a pathologist-verified case study links morphology to prognostically relevant PAM50 subtypes, demonstrating its scalable discovery potential.</p>
<blockquote>
<p>æ•°å­—åŒ–ç—…ç†åˆ†ææ¶‰åŠå¤æ‚ä¸”è€—æ—¶çš„æµç¨‹ï¼Œéœ€è¦ä¸“ä¸šçš„æŠ€æœ¯çŸ¥è¯†ï¼Œè¿™å°±é™åˆ¶äº†å…¶æ™®åŠæ€§ã€‚æˆ‘ä»¬ä»‹ç»äº†NOVAï¼Œè¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½æ¡†æ¶ï¼Œèƒ½å¤Ÿå°†ç§‘å­¦æŸ¥è¯¢è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„åˆ†æç®¡é“ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆå’Œè¿è¡ŒPythonä»£ç æ¥å®ç°ã€‚NOVAæ•´åˆäº†49ä¸ªåŸºäºå¼€æºè½¯ä»¶çš„é¢†åŸŸç‰¹å®šå·¥å…·ï¼ˆä¾‹å¦‚ï¼Œç»†èƒæ ¸åˆ†å‰²ã€å…¨å¹»ç¯ç‰‡ç¼–ç ï¼‰ï¼Œå¹¶èƒ½å¤Ÿå³å…´åˆ›å»ºæ–°å·¥å…·ã€‚ä¸ºäº†è¯„ä¼°è¿™æ ·çš„ç³»ç»Ÿï¼Œæˆ‘ä»¬æ¨å‡ºäº†SlideQuestï¼Œè¿™æ˜¯ä¸€ä¸ªç”±ç—…ç†å­¦å®¶å’Œç”Ÿç‰©åŒ»å­¦ç§‘å­¦å®¶éªŒè¯çš„åŒ…å«90ä¸ªé—®é¢˜çš„åŸºå‡†æµ‹è¯•ï¼Œæ¶‰åŠæ•°æ®å¤„ç†ã€å®šé‡åˆ†æå’Œå‡è®¾æ£€éªŒã€‚ä¸ä»¥å¾€ä¾§é‡äºçŸ¥è¯†å›å¿†æˆ–è¯Šæ–­è´¨é‡ä¿éšœçš„ç”Ÿç‰©åŒ»å­¦åŸºå‡†æµ‹è¯•ä¸åŒï¼ŒSlideQuestéœ€è¦å¤šæ­¥éª¤æ¨ç†ã€è¿­ä»£ç¼–ç å’Œè®¡ç®—é—®é¢˜è§£å†³ã€‚å®šé‡è¯„ä¼°æ˜¾ç¤ºï¼ŒNOVAçš„è¡¨ç°ä¼˜äºç¼–ç ä»£ç†åŸºå‡†æµ‹è¯•ï¼Œå¹¶ä¸”ç»è¿‡ç—…ç†å­¦å®¶éªŒè¯çš„æ¡ˆä¾‹ç ”ç©¶å°†å½¢æ€ä¸é¢„åç›¸å…³çš„PAM50äºšå‹è”ç³»èµ·æ¥ï¼Œè¯æ˜äº†å…¶å¯æ‰©å±•çš„å‘ç°æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11324v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ•°å­—åŒ–ç»„ç»‡ç—…ç†å­¦åˆ†ææµç¨‹å¤æ‚ä¸”è€—æ—¶ï¼Œéœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œé™åˆ¶äº†å…¶æ™®åŠæ€§ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†NOVAåˆ†ææ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå°†ç§‘å­¦æŸ¥è¯¢è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„åˆ†ææµç¨‹ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆå’Œè¿è¡ŒPythonä»£ç å®ç°ã€‚NOVAæ•´åˆäº†49ç§ç‰¹å®šé¢†åŸŸçš„å·¥å…·ï¼Œè¿™äº›å·¥å…·åŸºäºå¼€æºè½¯ä»¶æ„å»ºï¼Œä¸ä»…å¯ä»¥ç”¨äºç°æœ‰å·¥å…·çš„ä½¿ç”¨ï¼Œè¿˜å¯ä»¥æ ¹æ®éœ€æ±‚åˆ›å»ºæ–°å·¥å…·ã€‚æœ¬ç ”ç©¶è¿˜æ¨å‡ºäº†SlideQueståŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«ç”±ç—…ç†å­¦å®¶å’Œç”Ÿç‰©åŒ»å­¦ç§‘å­¦å®¶éªŒè¯çš„90ä¸ªé—®é¢˜ï¼Œæ¶µç›–æ•°æ®å¤„ç†ã€å®šé‡åˆ†æå’Œå‡è®¾æ£€éªŒç­‰æ–¹é¢ã€‚ç›¸è¾ƒäºä»¥å¾€ä¾§é‡äºçŸ¥è¯†å›å¿†æˆ–è¯Šæ–­è´¨é‡è¯„ä¼°çš„åŸºå‡†æµ‹è¯•ï¼ŒSlideQuestè¦æ±‚å¤šæ­¥éª¤æ¨ç†ã€è¿­ä»£ç¼–ç å’Œè®¡ç®—é—®é¢˜è§£å†³èƒ½åŠ›ã€‚å®šé‡è¯„ä¼°æ˜¾ç¤ºï¼ŒNOVAä¼˜äºç¼–ç ä»£ç†åŸºçº¿ï¼Œå¹¶é€šè¿‡ç—…ç†å­¦å®¶éªŒè¯çš„ä¸ªæ¡ˆç ”ç©¶å°†å½¢æ€ä¸é¢„åç›¸å…³çš„PAM50äºšå‹ç›¸è”ç³»ï¼Œå±•ç¤ºäº†å…¶å¯å‘ç°æ½œåœ¨åº”ç”¨çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°å­—åŒ–ç»„ç»‡ç—…ç†å­¦åˆ†æå­˜åœ¨å¤æ‚æ€§ã€è€—æ—¶çš„é™åˆ¶ä»¥åŠä¸“ä¸šè¦æ±‚è¾ƒé«˜çš„éš¾é¢˜ã€‚</li>
<li>NOVAæ¡†æ¶å¯å°†ç§‘å­¦æŸ¥è¯¢è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„åˆ†ææµç¨‹ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆå’Œè¿è¡ŒPythonä»£ç å®ç°ã€‚</li>
<li>NOVAæ•´åˆäº†å¤šç§ç‰¹å®šé¢†åŸŸçš„å·¥å…·ï¼Œå¹¶å¯ä»¥åˆ›å»ºæ–°çš„å·¥å…·ä»¥æ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚</li>
<li>SlideQueståŸºå‡†æµ‹è¯•åŒ…å«ç”±ä¸“å®¶éªŒè¯çš„å¤šä¸ªé—®é¢˜ï¼Œæ¶µç›–æ•°æ®å¤„ç†ã€å®šé‡åˆ†æå’Œå‡è®¾æ£€éªŒç­‰æ–¹é¢ã€‚</li>
<li>SlideQuestä¸åŒäºä»¥å¾€ä¾§é‡äºçŸ¥è¯†å›å¿†æˆ–è¯Šæ–­è´¨é‡è¯„ä¼°çš„åŸºå‡†æµ‹è¯•ï¼Œæ›´æ³¨é‡å¤šæ­¥éª¤æ¨ç†ã€è¿­ä»£ç¼–ç å’Œè®¡ç®—é—®é¢˜è§£å†³èƒ½åŠ›ã€‚</li>
<li>NOVAæ¡†æ¶åœ¨å®šé‡è¯„ä¼°ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºç¼–ç ä»£ç†åŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11324">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f8577be915f074ed8a7bfa90f81b3e1b" align="middle">
<img src="https://picx.zhimg.com/v2-ebf32ebca6fd64c3bfdcabda07d44fdb" align="middle">
<img src="https://picx.zhimg.com/v2-5927dd5c27c394a714fb9e7c29d077a3" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="iMAD-Intelligent-Multi-Agent-Debate-for-Efficient-and-Accurate-LLM-Inference"><a href="#iMAD-Intelligent-Multi-Agent-Debate-for-Efficient-and-Accurate-LLM-Inference" class="headerlink" title="iMAD: Intelligent Multi-Agent Debate for Efficient and Accurate LLM Inference"></a>iMAD: Intelligent Multi-Agent Debate for Efficient and Accurate LLM Inference</h2><p><strong>Authors:Wei Fan, JinYi Yoon, Bo Ji</strong></p>
<p>Large Language Model (LLM) agent systems have advanced rapidly, driven by their strong generalization in zero-shot settings. To further enhance reasoning and accuracy on complex tasks, Multi-Agent Debate (MAD) has emerged as a promising framework that engages multiple LLM agents in structured debates to encourage diverse reasoning. However, triggering MAD for every query is inefficient, as it incurs substantial computational (token) cost and may even degrade accuracy by overturning correct single-agent answers. To address these limitations, we propose intelligent Multi-Agent Debate (iMAD), a token-efficient framework that selectively triggers MAD only when it is likely to be beneficial (i.e., correcting an initially wrong answer). To achieve this goal, iMAD learns generalizable model behaviors to make accurate debate decisions. Specifically, iMAD first prompts a single agent to produce a structured self-critique response, from which we extract 41 interpretable linguistic and semantic features capturing hesitation cues. Then, iMAD uses a lightweight debate-decision classifier, trained using our proposed FocusCal loss, to determine whether to trigger MAD, enabling robust debate decisions without test dataset-specific tuning. Through extensive experiments using six (visual) question answering datasets against five competitive baselines, we have shown that iMAD significantly reduces token usage (by up to 92%) while also improving final answer accuracy (by up to 13.5%).</p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿå‘å±•è¿…é€Ÿï¼Œå¾—ç›Šäºå®ƒä»¬åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸­çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æ¨ç†å’Œå‡†ç¡®æ€§ï¼Œå¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰ä½œä¸ºä¸€ä¸ªæœ‰å‰æ™¯çš„æ¡†æ¶åº”è¿è€Œç”Ÿï¼Œå®ƒè®©å¤šä¸ªLLMä»£ç†å‚ä¸ç»“æ„åŒ–è¾©è®ºï¼Œä»¥é¼“åŠ±å¤šæ ·åŒ–çš„æ¨ç†ã€‚ç„¶è€Œï¼Œä¸ºæ¯æ¬¡æŸ¥è¯¢è§¦å‘MADæ˜¯ä¸é«˜æ•ˆçš„ï¼Œå› ä¸ºå®ƒä¼šäº§ç”Ÿå¤§é‡çš„è®¡ç®—ï¼ˆä»¤ç‰Œï¼‰æˆæœ¬ï¼Œç”šè‡³å¯èƒ½é€šè¿‡æ¨ç¿»æ­£ç¡®çš„å•ä»£ç†ç­”æ¡ˆæ¥é™ä½å‡†ç¡®æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ™ºèƒ½å¤šä»£ç†è¾©è®ºï¼ˆiMADï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¤ç‰Œé«˜æ•ˆçš„æ¡†æ¶ï¼Œå®ƒåªé€‰æ‹©æ€§åœ°è§¦å‘MADï¼Œå½“è¿™å¾ˆå¯èƒ½æ˜¯æœ‰ç›Šçš„æ—¶å€™ï¼ˆå³çº æ­£ä¸€ä¸ªæœ€åˆçš„é”™è¯¯ç­”æ¡ˆï¼‰ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼ŒiMADå­¦ä¹ å¯æ¨å¹¿çš„æ¨¡å‹è¡Œä¸ºæ¥åšå‡ºå‡†ç¡®çš„è¾©è®ºå†³ç­–ã€‚å…·ä½“æ¥è¯´ï¼ŒiMADé¦–å…ˆæç¤ºå•ä¸ªä»£ç†äº§ç”Ÿç»“æ„åŒ–çš„è‡ªæˆ‘æ‰¹åˆ¤å“åº”ï¼Œä»ä¸­æˆ‘ä»¬æå–41ä¸ªå¯è§£é‡Šçš„è¯­è¨€å’Œè¯­ä¹‰ç‰¹å¾ï¼Œæ•æ‰çŠ¹è±«çš„çº¿ç´¢ã€‚ç„¶åï¼ŒiMADä½¿ç”¨è½»é‡çº§çš„è¾©è®ºå†³ç­–åˆ†ç±»å™¨ï¼Œä½¿ç”¨æˆ‘ä»¬æå‡ºçš„FocusCalæŸå¤±è¿›è¡Œè®­ç»ƒï¼Œä»¥ç¡®å®šæ˜¯å¦éœ€è¦è§¦å‘MADï¼Œä»è€Œå®ç°ç¨³å¥çš„è¾©è®ºå†³ç­–è€Œæ— éœ€é’ˆå¯¹æµ‹è¯•æ•°æ®é›†è¿›è¡Œç‰¹å®šè°ƒæ•´ã€‚é€šè¿‡åœ¨ä¸äº”ä¸ªç«äº‰æ€§åŸºå‡†æµ‹è¯•çš„å…­ä¸ªï¼ˆè§†è§‰ï¼‰é—®ç­”æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒï¼Œæˆ‘ä»¬å·²ç»è¯æ˜iMADæ˜¾è‘—å‡å°‘äº†ä»¤ç‰Œä½¿ç”¨ï¼ˆæœ€å¤šå‡å°‘92%ï¼‰ï¼ŒåŒæ—¶æé«˜äº†æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼ˆæœ€å¤šæé«˜1.å€æˆ–æ›´å¤§ã€‚ç®€åŒ–åçš„ç¿»è¯‘å¦‚ä¸‹ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿè¿›æ­¥è¿…é€Ÿï¼Œç‰¹åˆ«æ˜¯å…¶åœ¨é›¶æ ·æœ¬ç¯å¢ƒä¸‹çš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›æ˜¯ä¸€å¤§é©±åŠ¨åŠ›ã€‚ä¸ºäº†æé«˜å¤æ‚ä»»åŠ¡çš„æ¨ç†å’Œå‡†ç¡®æ€§ï¼Œä¸€ç§åä¸ºå¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰çš„æ–¹æ³•å¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œæ¯æ¬¡æŸ¥è¯¢éƒ½è§¦å‘MADå¹¶ä¸é«˜æ•ˆï¼Œå› ä¸ºå®ƒéœ€è¦å¤§é‡çš„è®¡ç®—æˆæœ¬å¹¶å¯èƒ½é™ä½å‡†ç¡®æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†æ™ºèƒ½å¤šä»£ç†è¾©è®ºï¼ˆiMADï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªèƒ½æœ‰æ•ˆèŠ‚çœä»¤ç‰Œçš„æ¡†æ¶ã€‚å®ƒåªåœ¨å¯èƒ½æœ‰ç›Šçš„æƒ…å†µä¸‹è§¦å‘è¾©è®ºåŠŸèƒ½ï¼ˆå³çº æ­£åŸå…ˆçš„é”™è¯¯ç­”æ¡ˆï¼‰ã€‚ä¸ºäº†åšå‡ºæ˜æ™ºçš„è¾©è®ºå†³ç­–ï¼ŒiMADå­¦ä¹ äº†å¯æ¨å¹¿çš„æ¨¡å‹è¡Œä¸ºã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒé€šè¿‡è§‚å¯Ÿå•ä¸ªä»£ç†çš„è‡ªæˆ‘æ‰¹åˆ¤å“åº”æ¥è¯†åˆ«çŠ¹è±«çº¿ç´¢ç­‰ç‰¹å¾ã€‚æ¥ç€ä½¿ç”¨è½»é‡çº§çš„è¾©è®ºå†³ç­–åˆ†ç±»å™¨å†³å®šæ˜¯å¦è§¦å‘è¾©è®ºåŠŸèƒ½ã€‚ç»è¿‡åœ¨å¤šä¸ªé—®ç­”æ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒiMADæ˜¾è‘—å‡å°‘äº†ä»¤ç‰Œçš„ä½¿ç”¨é‡å¹¶æé«˜äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11306v1">PDF</a> Accepted in AAAI 2026 (Oral)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿçš„å¿«é€Ÿå‘å±•æ¨åŠ¨äº†å…¶åœ¨é›¶æ ·æœ¬ç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜å¤æ‚ä»»åŠ¡çš„æ¨ç†å’Œå‡†ç¡®æ€§ï¼Œå‡ºç°äº†å¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰è¿™ä¸€æœ‰å‰æ™¯çš„æ¡†æ¶ï¼Œå®ƒè®©å¤šä¸ªLLMä»£ç†å‚ä¸ç»“æ„åŒ–è¾©è®ºï¼Œä»¥ä¿ƒè¿›å¤šæ ·åŒ–çš„æ¨ç†ã€‚ç„¶è€Œï¼Œä¸ºæ¯æ¬¡æŸ¥è¯¢è§¦å‘MADæ˜¯ä¸é«˜æ•ˆçš„ï¼Œå› ä¸ºå®ƒä¼šå¼•èµ·å¤§é‡çš„è®¡ç®—ï¼ˆä»¤ç‰Œï¼‰æˆæœ¬ï¼Œç”šè‡³å¯èƒ½é€šè¿‡æ¨ç¿»æ­£ç¡®çš„å•ä»£ç†ç­”æ¡ˆæ¥é™ä½å‡†ç¡®æ€§ã€‚ä¸ºè§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ™ºèƒ½å¤šä»£ç†è¾©è®ºï¼ˆiMADï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä»¤ç‰Œé«˜æ•ˆçš„æ¡†æ¶ï¼Œå®ƒä»…é€‰æ‹©æ€§åœ°è§¦å‘MADï¼Œå½“è¿™å¯èƒ½æœ‰ç›Šæ—¶ï¼ˆå³çº æ­£æœ€åˆçš„é”™è¯¯ç­”æ¡ˆï¼‰ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼ŒiMADå­¦ä¹ å¯æ¨å¹¿çš„æ¨¡å‹è¡Œä¸ºä»¥åšå‡ºå‡†ç¡®çš„è¾©è®ºå†³ç­–ã€‚å®éªŒè¡¨æ˜ï¼ŒiMADåœ¨å‡å°‘ä»¤ç‰Œä½¿ç”¨çš„åŒæ—¶ï¼Œä¹Ÿæé«˜äº†æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿå·²å¿«é€Ÿå‘å±•ï¼Œå¹¶åœ¨é›¶æ ·æœ¬ç¯å¢ƒä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰æ¡†æ¶ç”¨äºä¿ƒè¿›LLMä»£ç†ä¹‹é—´çš„å¤šæ ·åŒ–æ¨ç†ï¼Œæé«˜å¤æ‚ä»»åŠ¡çš„æ¨ç†å’Œå‡†ç¡®æ€§ã€‚</li>
<li>ä¸ºæ¯æ¬¡æŸ¥è¯¢è§¦å‘MADæ˜¯ä¸é«˜æ•ˆçš„ï¼Œä¼šå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ å’Œå‡†ç¡®æ€§ä¸‹é™ã€‚</li>
<li>æ™ºèƒ½å¤šä»£ç†è¾©è®ºï¼ˆiMADï¼‰æ¡†æ¶æ—¨åœ¨é€‰æ‹©æ€§è§¦å‘MADï¼Œä»…åœ¨å¯èƒ½çº æ­£é”™è¯¯ç­”æ¡ˆæ—¶ã€‚</li>
<li>iMADé€šè¿‡æå–è¯­è¨€å’Œè¡Œä¸ºç‰¹å¾æ¥åšå‡ºè¾©è®ºå†³ç­–ï¼Œè¿™äº›ç‰¹å¾åæ˜ äº†ä»£ç†çš„çŠ¹è±«å’Œä¸ç¡®å®šæ€§ã€‚</li>
<li>iMADä½¿ç”¨è½»é‡çº§çš„è¾©è®ºå†³ç­–åˆ†ç±»å™¨ï¼Œé€šè¿‡FocusCalæŸå¤±è¿›è¡Œè®­ç»ƒï¼Œä»¥åšå‡ºç¨³å¥çš„è¾©è®ºå†³ç­–ï¼Œæ— éœ€é’ˆå¯¹æµ‹è¯•æ•°æ®é›†è¿›è¡Œç‰¹å®šè°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7d43ff288b0c6ce91ff9dca3e19cb2cd" align="middle">
<img src="https://picx.zhimg.com/v2-1fbca2a593b2e2e35993cbfc39c83f08" align="middle">
<img src="https://picx.zhimg.com/v2-ebfe8bca9a7120b29c58a66c385ec3e2" align="middle">
<img src="https://picx.zhimg.com/v2-5214a8c2ffdc0e83e60fb576f3190acd" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="AIonopedia-an-LLM-agent-orchestrating-multimodal-learning-for-ionic-liquid-discovery"><a href="#AIonopedia-an-LLM-agent-orchestrating-multimodal-learning-for-ionic-liquid-discovery" class="headerlink" title="AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery"></a>AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery</h2><p><strong>Authors:Yuqi Yin, Yibo Fu, Siyuan Wang, Peng Sun, Hongyu Wang, Xiaohui Wang, Lei Zheng, Zhiyong Li, Zhirong Liu, Jianji Wang, Zhaoxi Sun</strong></p>
<p>The discovery of novel Ionic Liquids (ILs) is hindered by critical challenges in property prediction, including limited data, poor model accuracy, and fragmented workflows. Leveraging the power of Large Language Models (LLMs), we introduce AIonopedia, to the best of our knowledge, the first LLM agent for IL discovery. Powered by an LLM-augmented multimodal domain foundation model for ILs, AIonopedia enables accurate property predictions and incorporates a hierarchical search architecture for molecular screening and design. Trained and evaluated on a newly curated and comprehensive IL dataset, our model delivers superior performance. Complementing these results, evaluations on literature-reported systems indicate that the agent can perform effective IL modification. Moving beyond offline tests, the practical efficacy was further confirmed through real-world wet-lab validation, in which the agent demonstrated exceptional generalization capabilities on challenging out-of-distribution tasks, underscoring its ability to accelerate real-world IL discovery.</p>
<blockquote>
<p>ç¦»å­æ¶²ä½“çš„æ–°å‹å‘ç°å—åˆ°å±æ€§é¢„æµ‹æ–¹é¢çš„é‡å¤§æŒ‘æˆ˜æ‰€é˜»ç¢ï¼ŒåŒ…æ‹¬æ•°æ®æœ‰é™ã€æ¨¡å‹ç²¾åº¦ä¸è¶³ä»¥åŠå·¥ä½œæµç¨‹ç¢ç‰‡åŒ–ã€‚æˆ‘ä»¬å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŠ›é‡ï¼Œæ¨å‡ºäº†AIonopediaï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¾ç”¨äºç¦»å­æ¶²ä½“ï¼ˆILï¼‰å‘ç°çš„LLMä»£ç†ã€‚AIonopediaç”±LLMå¢å¼ºçš„ç¦»å­æ¶²ä½“å¤šæ¨¡å¼åŸŸåŸºç¡€æ¨¡å‹æä¾›åŠ¨åŠ›ï¼Œèƒ½å¤Ÿè¿›è¡Œå‡†ç¡®çš„å±æ€§é¢„æµ‹ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚æœç´¢æ¶æ„è¿›è¡Œåˆ†å­ç­›é€‰å’Œè®¾è®¡ã€‚æˆ‘ä»¬çš„æ¨¡å‹æ˜¯åœ¨æ–°æ•´ç†çš„ç»¼åˆç¦»å­æ¶²ä½“æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°çš„ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¯¹æ–‡çŒ®æŠ¥é“ç³»ç»Ÿçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥ä»£ç†å¯ä»¥æœ‰æ•ˆè¿›è¡Œç¦»å­æ¶²ä½“æ”¹é€ ã€‚é™¤äº†çº¿ä¸‹æµ‹è¯•ä¹‹å¤–ï¼Œé€šè¿‡ç°å®ä¸–ç•Œæ¹¿å®éªŒå®¤çš„éªŒè¯è¿›ä¸€æ­¥è¯å®äº†å…¶å®ç”¨æ€§ï¼Œä»£ç†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¦»ç¾¤ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œçªæ˜¾äº†å…¶åŠ é€Ÿç°å®ä¸–ç•Œç¦»å­æ¶²ä½“å‘ç°çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11257v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šå€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„åŠ›é‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¿„ä»Šä¸ºæ­¢é¦–ä¸ªç”¨äºç¦»å­æ¶²ä½“ï¼ˆILsï¼‰å‘ç°çš„LLMä»£ç†â€”â€”AIonopediaã€‚è¯¥æ¨¡å‹é€šè¿‡LLMå¢å¼ºçš„å¤šæ¨¡å¼åŸŸåŸºç¡€æ¨¡å‹è¿›è¡Œèµ‹èƒ½ï¼Œå¯å®ç°ç¦»å­æ¶²ä½“çš„ç²¾ç¡®å±æ€§é¢„æµ‹ï¼Œå¹¶èå…¥åˆ†å±‚æœç´¢æ¶æ„è¿›è¡Œåˆ†å­ç­›é€‰å’Œè®¾è®¡ã€‚åœ¨æ–°æ•´ç†çš„ç»¼åˆILæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚é€šè¿‡æ–‡çŒ®æŠ¥é“ç³»ç»Ÿçš„è¯„ä¼°ï¼Œè¯¥ä»£ç†å¯æœ‰æ•ˆè¿›è¡Œç¦»å­æ¶²ä½“çš„æ”¹é€ ã€‚é€šè¿‡æ¹¿å®éªŒå®¤éªŒè¯ï¼Œè¿›ä¸€æ­¥è¯å®äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„å®ç”¨æ€§ï¼Œè¯¥ä»£ç†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¦»åˆ†å¸ƒä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ³›åŒ–èƒ½åŠ›ï¼Œçªæ˜¾å…¶åŠ é€Ÿç°å®ä¸–ç•Œä¸­ç¦»å­æ¶²ä½“å‘ç°çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç¦»å­æ¶²ä½“ï¼ˆILsï¼‰å‘ç°é¢ä¸´å±æ€§é¢„æµ‹çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®æœ‰é™ã€æ¨¡å‹ç²¾åº¦ä½å’Œæµç¨‹ç¢ç‰‡åŒ–ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ILå‘ç°ä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>AIonopediaæ˜¯é¦–ä¸ªç”¨äºILå‘ç°çš„LLMä»£ç†ï¼Œå…·å¤‡å‡†ç¡®å±æ€§é¢„æµ‹èƒ½åŠ›ã€‚</li>
<li>AIonopediaé‡‡ç”¨åˆ†å±‚æœç´¢æ¶æ„è¿›è¡Œåˆ†å­ç­›é€‰å’Œè®¾è®¡ã€‚</li>
<li>åœ¨æ–°ç»¼åˆILæ•°æ®é›†ä¸Šè®­ç»ƒå’Œè¯„ä¼°çš„AIonopediaè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>AIonopediaèƒ½åœ¨æ–‡çŒ®æŠ¥é“çš„ç³»ç»Ÿä¸­è¿›è¡Œæœ‰æ•ˆILæ”¹é€ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11257">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f69a13dbe7fa2eae180ee741174a82c5" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="UAVBench-An-Open-Benchmark-Dataset-for-Autonomous-and-Agentic-AI-UAV-Systems-via-LLM-Generated-Flight-Scenarios"><a href="#UAVBench-An-Open-Benchmark-Dataset-for-Autonomous-and-Agentic-AI-UAV-Systems-via-LLM-Generated-Flight-Scenarios" class="headerlink" title="UAVBench: An Open Benchmark Dataset for Autonomous and Agentic AI UAV Systems via LLM-Generated Flight Scenarios"></a>UAVBench: An Open Benchmark Dataset for Autonomous and Agentic AI UAV Systems via LLM-Generated Flight Scenarios</h2><p><strong>Authors:Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah</strong></p>
<p>Autonomous aerial systems increasingly rely on large language models (LLMs) for mission planning, perception, and decision-making, yet the lack of standardized and physically grounded benchmarks limits systematic evaluation of their reasoning capabilities. To address this gap, we introduce UAVBench, an open benchmark dataset comprising 50,000 validated UAV flight scenarios generated through taxonomy-guided LLM prompting and multi-stage safety validation. Each scenario is encoded in a structured JSON schema that includes mission objectives, vehicle configuration, environmental conditions, and quantitative risk labels, providing a unified representation of UAV operations across diverse domains. Building on this foundation, we present UAVBench_MCQ, a reasoning-oriented extension containing 50,000 multiple-choice questions spanning ten cognitive and ethical reasoning styles, ranging from aerodynamics and navigation to multi-agent coordination and integrated reasoning. This framework enables interpretable and machine-checkable assessment of UAV-specific cognition under realistic operational contexts. We evaluate 32 state-of-the-art LLMs, including GPT-5, ChatGPT-4o, Gemini 2.5 Flash, DeepSeek V3, Qwen3 235B, and ERNIE 4.5 300B, and find strong performance in perception and policy reasoning but persistent challenges in ethics-aware and resource-constrained decision-making. UAVBench establishes a reproducible and physically grounded foundation for benchmarking agentic AI in autonomous aerial systems and advancing next-generation UAV reasoning intelligence. To support open science and reproducibility, we release the UAVBench dataset, the UAVBench_MCQ benchmark, evaluation scripts, and all related materials on GitHub at <a target="_blank" rel="noopener" href="https://github.com/maferrag/UAVBench">https://github.com/maferrag/UAVBench</a></p>
<blockquote>
<p>è‡ªä¸»ç©ºä¸­ç³»ç»Ÿè¶Šæ¥è¶Šä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œä»»åŠ¡è§„åˆ’ã€æ„ŸçŸ¥å’Œå†³ç­–ï¼Œä½†ç”±äºç¼ºä¹æ ‡å‡†åŒ–å’Œç‰©ç†åŸºç¡€çš„åŸºå‡†æµ‹è¯•ï¼Œå…¶æ¨ç†èƒ½åŠ›çš„ç³»ç»Ÿè¯„ä¼°å—åˆ°é™åˆ¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†UAVBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„æ ‡å‡†æ•°æ®é›†ï¼ŒåŒ…å«é€šè¿‡åˆ†ç±»å­¦æŒ‡å¯¼çš„LLMæç¤ºå’Œå¤šé˜¶æ®µå®‰å…¨éªŒè¯ç”Ÿæˆçš„50000ä¸ªç»è¿‡éªŒè¯çš„æ— äººæœºé£è¡Œåœºæ™¯ã€‚æ¯ä¸ªåœºæ™¯éƒ½æŒ‰ç…§ç»“æ„åŒ–JSONæ¨¡å¼ç¼–ç ï¼ŒåŒ…æ‹¬ä»»åŠ¡ç›®æ ‡ã€è½¦è¾†é…ç½®ã€ç¯å¢ƒæ¡ä»¶å’Œå®šé‡é£é™©æ ‡ç­¾ï¼Œä¸ºä¸åŒé¢†åŸŸçš„æ— äººæœºæ“ä½œæä¾›äº†ç»Ÿä¸€è¡¨ç¤ºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†UAVBench_MCQï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥æ¨ç†ä¸ºå¯¼å‘çš„æ‰©å±•é›†ï¼ŒåŒ…å«5ä¸‡ä¸ªæ¶‰åŠåç§è®¤çŸ¥å’Œé“å¾·æ¨ç†é£æ ¼çš„å¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ¶µç›–ç©ºæ°”åŠ¨åŠ›å­¦ã€å¯¼èˆªã€å¤šæ™ºèƒ½ä½“åè°ƒä»¥åŠç»¼åˆæ¨ç†ç­‰ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ç°å®æ“ä½œç¯å¢ƒä¸‹å¯¹æ— äººæœºç‰¹å®šè®¤çŸ¥è¿›è¡Œå¯è§£é‡Šå’Œæœºå™¨æ£€æµ‹è¯„ä¼°ã€‚æˆ‘ä»¬è¯„ä¼°äº†32ç§æœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬GPT-5ã€ChatGPT-4oã€Gemini 2.5 Flashã€DeepSeek V3ã€Qwen3 235Bå’ŒERNIE 4.5 300Bç­‰ï¼Œå‘ç°åœ¨æ„ŸçŸ¥å’Œæ”¿ç­–æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é“å¾·æ„è¯†å’Œèµ„æºå—é™çš„å†³ç­–åˆ¶å®šæ–¹é¢ä»å­˜åœ¨æŒç»­æŒ‘æˆ˜ã€‚UAVBenchä¸ºè‡ªä¸»ç©ºä¸­ç³»ç»Ÿçš„æ™ºèƒ½ä»£ç†åŸºå‡†æµ‹è¯•æä¾›äº†å¯é‡å¤å’Œç‰©ç†åŸºç¡€çš„åŸºç¡€ï¼Œæ¨åŠ¨äº†ä¸‹ä¸€ä»£æ— äººæœºæ¨ç†æ™ºèƒ½çš„å‘å±•ã€‚ä¸ºäº†æ”¯æŒå¼€æ”¾ç§‘å­¦å’Œå¯é‡å¤æ€§ï¼Œæˆ‘ä»¬åœ¨GitHubä¸Šå‘å¸ƒäº†UAVBenchæ•°æ®é›†ã€UAVBench_MCQåŸºå‡†æµ‹è¯•ã€è¯„ä¼°è„šæœ¬å’Œæ‰€æœ‰ç›¸å…³ææ–™ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/maferrag/UAVBench%EF%BC%89%E3%80%82">https://github.com/maferrag/UAVBenchï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11252v1">PDF</a> 18 pages, 5 Figures</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†è‡ªä¸»ç©ºä¸­ç³»ç»Ÿè¶Šæ¥è¶Šä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä»»åŠ¡è§„åˆ’ã€æ„ŸçŸ¥å’Œå†³ç­–ï¼Œä½†ç¼ºä¹æ ‡å‡†åŒ–å’Œç‰©ç†åŸºç¡€çš„åŸºå‡†æµ‹è¯•é™åˆ¶äº†å¯¹å…¶æ¨ç†èƒ½åŠ›çš„ç³»ç»Ÿè¯„ä¼°ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œå¼•å…¥äº†UAVBenchæ•°æ®é›†ï¼ŒåŒ…å«é€šè¿‡åˆ†ç±»å­¦æŒ‡å¯¼çš„è¯­è¨€æ¨¡å‹æç¤ºå’Œå¤šé˜¶æ®µå®‰å…¨éªŒè¯ç”Ÿæˆçš„5ä¸‡ä¸ªéªŒè¯è¿‡çš„æ— äººæœºé£è¡Œåœºæ™¯ã€‚æ­¤å¤–ï¼Œè¿˜æ¨å‡ºäº†UAVBench_MCQåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«æ¶‰åŠè®¤çŸ¥ä¸é“å¾·æ¨ç†çš„å¤šä¸ªé€‰æ‹©é¢˜ã€‚è¯„ä¼°äº†å¤šä¸ªå…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå‘ç°å®ƒä»¬åœ¨æ„ŸçŸ¥å’Œæ”¿ç­–æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é“å¾·æ„è¯†å’Œèµ„æºå—é™çš„å†³ç­–åˆ¶å®šæ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚UAVBenchä¸ºè‡ªä¸»ç©ºä¸­ç³»ç»Ÿçš„æ™ºèƒ½ä»£ç†åŸºå‡†æµ‹è¯•æä¾›äº†å¯å¤åˆ¶å’Œç‰©ç†åŸºç¡€çš„åŸºçŸ³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªä¸»ç©ºä¸­ç³»ç»Ÿçš„ä»»åŠ¡è§„åˆ’ã€æ„ŸçŸ¥å’Œå†³ç­–ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚</li>
<li>ç¼ºä¹æ ‡å‡†åŒ–å’Œç‰©ç†åŸºç¡€çš„åŸºå‡†æµ‹è¯•é™åˆ¶äº†è¯­è¨€æ¨¡å‹åœ¨è‡ªä¸»ç©ºä¸­ç³»ç»Ÿä¸­çš„æ¨ç†èƒ½åŠ›è¯„ä¼°ã€‚</li>
<li>UAVBenchæ•°æ®é›†åŒ…å«é€šè¿‡åˆ†ç±»å­¦æŒ‡å¯¼çš„è¯­è¨€æ¨¡å‹æç¤ºç”Ÿæˆçš„æ— äººæœºé£è¡Œåœºæ™¯ï¼Œå¹¶è¿›è¡Œäº†å¤šé˜¶æ®µå®‰å…¨éªŒè¯ã€‚</li>
<li>UAVBench_MCQåŸºå‡†æµ‹è¯•åŒ…å«æ¶‰åŠè®¤çŸ¥ä¸é“å¾·æ¨ç†çš„å¤šä¸ªé€‰æ‹©é¢˜ï¼Œç”¨äºè¯„ä¼°æ— äººæœºçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ„ŸçŸ¥å’Œæ”¿ç­–æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>åœ¨é“å¾·æ„è¯†å’Œèµ„æºå—é™çš„å†³ç­–åˆ¶å®šæ–¹é¢ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ä»å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11252">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ff28d8e7b766d1ab2292b2df57ce1f9a" align="middle">
<img src="https://picx.zhimg.com/v2-784ff6c7965e97c2b970d84f59712557" align="middle">
<img src="https://picx.zhimg.com/v2-9af9c660188a1cf64857328efc238ec7" align="middle">
<img src="https://picx.zhimg.com/v2-40636d025fcf6b1dbeabadfcd734a718" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Multi-agent-Undercover-Gaming-Hallucination-Removal-via-Counterfactual-Test-for-Multimodal-Reasoning"><a href="#Multi-agent-Undercover-Gaming-Hallucination-Removal-via-Counterfactual-Test-for-Multimodal-Reasoning" class="headerlink" title="Multi-agent Undercover Gaming: Hallucination Removal via Counterfactual Test for Multimodal Reasoning"></a>Multi-agent Undercover Gaming: Hallucination Removal via Counterfactual Test for Multimodal Reasoning</h2><p><strong>Authors:Dayong Liang, Xiao-Yong Wei, Changmeng Zheng</strong></p>
<p>Hallucination continues to pose a major obstacle in the reasoning capabilities of large language models (LLMs). Although the Multi-Agent Debate (MAD) paradigm offers a promising solution by promoting consensus among multiple agents to enhance reliability, it relies on the unrealistic assumption that all debaters are rational and reflective, which is a condition that may not hold when agents themselves are prone to hallucinations. To address this gap, we introduce the Multi-agent Undercover Gaming (MUG) protocol, inspired by social deduction games like â€œWho is Undercover?â€. MUG reframes MAD as a process of detecting â€œundercoverâ€ agents (those suffering from hallucinations) by employing multimodal counterfactual tests. Specifically, we modify reference images to introduce counterfactual evidence and observe whether agents can accurately identify these changes, providing ground-truth for identifying hallucinating agents and enabling robust, crowd-powered multimodal reasoning. MUG advances MAD protocols along three key dimensions: (1) enabling factual verification beyond statistical consensus through counterfactual testing; (2) introducing cross-evidence reasoning via dynamically modified evidence sources instead of relying on static inputs; and (3) fostering active reasoning, where agents engage in probing discussions rather than passively answering questions. Collectively, these innovations offer a more reliable and effective framework for multimodal reasoning in LLMs. The source code can be accessed at <a target="_blank" rel="noopener" href="https://github.com/YongLD/MUG.git">https://github.com/YongLD/MUG.git</a>.</p>
<blockquote>
<p>å¹»è§‰ä»ç„¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›çš„ä¸»è¦éšœç¢ã€‚è™½ç„¶å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰èŒƒå¼é€šè¿‡ä¿ƒè¿›å¤šä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„å…±è¯†ä»¥æé«˜å¯é æ€§æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œä½†å®ƒä¾èµ–äºæ‰€æœ‰è¾©è®ºè€…éƒ½æ˜¯ç†æ€§å’Œåæ€çš„è¿™ä¸€ä¸åˆ‡å®é™…çš„å‡è®¾ï¼Œè€Œå½“æ™ºèƒ½ä½“è‡ªèº«ä¹Ÿå®¹æ˜“å‘ç”Ÿå¹»è§‰æ—¶ï¼Œè¿™ä¸€æ¡ä»¶å¯èƒ½å¹¶ä¸æˆç«‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†å—â€œè°æ˜¯å§åº•ï¼Ÿâ€ç­‰ç¤¾ä¼šæ¨ç†æ¸¸æˆå¯å‘è€Œè¯ç”Ÿçš„å¤šæ™ºèƒ½ä½“éšè”½æ¸¸æˆï¼ˆMUGï¼‰åè®®ã€‚MUGé€šè¿‡å°†MADé‡æ„ä¸ºæ£€æµ‹â€œå§åº•â€æ™ºèƒ½ä½“ï¼ˆå³é‚£äº›å‡ºç°å¹»è§‰çš„æ™ºèƒ½ä½“ï¼‰çš„è¿‡ç¨‹ï¼Œé‡‡ç”¨å¤šæ¨¡å¼åäº‹å®æµ‹è¯•ï¼Œæ¥é‡æ–°å¡‘é€ MADã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¿®æ”¹å‚è€ƒå›¾åƒä»¥å¼•å…¥åäº‹å®è¯æ®ï¼Œå¹¶è§‚å¯Ÿæ™ºèƒ½ä½“æ˜¯å¦èƒ½å‡†ç¡®è¯†åˆ«è¿™äº›å˜åŒ–ï¼Œä¸ºè¯†åˆ«å¹»è§‰æ™ºèƒ½ä½“æä¾›çœŸå®ä¾æ®ï¼Œä»è€Œå®ç°ç¨³å¥çš„ä¼—æºå¤šæ¨¡å¼æ¨ç†ã€‚MUGåœ¨ä¸‰ä¸ªå…³é”®ç»´åº¦ä¸Šæ¨è¿›äº†MADåè®®ï¼šï¼ˆ1ï¼‰é€šè¿‡åäº‹å®æµ‹è¯•å®ç°è¶…è¶Šç»Ÿè®¡å…±è¯†çš„äº‹å®éªŒè¯ï¼›ï¼ˆ2ï¼‰é€šè¿‡åŠ¨æ€ä¿®æ”¹çš„è¯æ®æºå¼•å…¥äº¤å‰è¯æ®æ¨ç†ï¼Œè€Œä¸æ˜¯ä¾èµ–é™æ€è¾“å…¥ï¼›ï¼ˆ3ï¼‰åŸ¹å…»ä¸»åŠ¨æ¨ç†ï¼Œè®©æ™ºèƒ½ä½“å‚ä¸æ¢è®¨è®¨è®ºè€Œä¸æ˜¯è¢«åŠ¨å›ç­”é—®é¢˜ã€‚è¿™äº›åˆ›æ–°å…±åŒä¸ºLLMä¸­çš„å¤šæ¨¡å¼æ¨ç†æä¾›äº†æ›´å¯é å’Œæœ‰æ•ˆçš„æ¡†æ¶ã€‚æºä»£ç å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/YongLD/MUG.git%E3%80%82">https://github.com/YongLD/MUG.gitã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11182v1">PDF</a> Accepted by AAAI 2026</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„æ¨ç†èƒ½åŠ›ä¸»è¦é¢ä¸´å¹»è§‰è¿™ä¸€éš¾é¢˜ã€‚è™½ç„¶å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰èŒƒå¼é€šè¿‡ä¿ƒè¿›å¤šä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„å…±è¯†å¢å¼ºå¯é æ€§ï¼Œä¸ºè§£å†³æ­¤é—®é¢˜æä¾›äº†å¸Œæœ›ï¼Œä½†å®ƒä¾èµ–äºæ‰€æœ‰è¾©è®ºè€…éƒ½æ˜¯ç†æ€§å’Œåæ€çš„è¿™ä¸€ä¸åˆ‡å®é™…çš„å‡è®¾ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å—â€œè°æ˜¯å§åº•ï¼Ÿâ€ç­‰ç¤¾ä¼šæ¨ç†æ¸¸æˆçš„å¯å‘ï¼Œæå‡ºäº†å¤šæ™ºèƒ½ä½“å§åº•æ¸¸æˆï¼ˆMUGï¼‰åè®®ã€‚MUGå°†MADé‡æ„ä¸ºæ£€æµ‹â€œå§åº•â€æ™ºèƒ½ä½“ï¼ˆå³é‚£äº›å‡ºç°å¹»è§‰çš„æ™ºèƒ½ä½“ï¼‰çš„è¿‡ç¨‹ï¼Œé‡‡ç”¨å¤šæ¨¡å¼åäº‹å®æµ‹è¯•ã€‚é€šè¿‡ä¿®æ”¹å‚è€ƒå›¾åƒæ¥å¼•å…¥åäº‹å®è¯æ®ï¼Œè§‚å¯Ÿæ™ºèƒ½ä½“æ˜¯å¦èƒ½å‡†ç¡®è¯†åˆ«è¿™äº›å˜åŒ–ï¼Œä¸ºè¯†åˆ«å‡ºç°å¹»è§‰çš„æ™ºèƒ½ä½“æä¾›çœŸå®ä¾æ®ï¼Œä»è€Œå®ç°å¥å£®çš„ã€ä¼—æºå¤šæ¨¡å¼æ¨ç†ã€‚MUGåœ¨ä¸‰ä¸ªæ–¹é¢æ¨è¿›äº†MADåè®®ï¼š1ï¼‰é€šè¿‡åäº‹å®æµ‹è¯•å®ç°äº‹å®éªŒè¯ï¼Œè¶…è¶Šç»Ÿè®¡å…±è¯†ï¼›2ï¼‰é€šè¿‡åŠ¨æ€ä¿®æ”¹è¯æ®æ¥æºå¼•å…¥äº¤å‰è¯æ®æ¨ç†ï¼Œè€Œä¸æ˜¯ä¾èµ–é™æ€è¾“å…¥ï¼›3ï¼‰åŸ¹å…»ä¸»åŠ¨æ¨ç†ï¼Œæ™ºèƒ½ä½“è¿›è¡Œæ¢ç©¶è®¨è®ºï¼Œè€Œä¸æ˜¯è¢«åŠ¨å›ç­”é—®é¢˜ã€‚è¿™äº›åˆ›æ–°ä¸ºLLMä¸­çš„å¤šæ¨¡å¼æ¨ç†æä¾›äº†æ›´å¯é å’Œæœ‰æ•ˆçš„æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯å¹»è§‰ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰èŒƒå¼è™½æœ‰åŠ©äºå¢å¼ºå¯é æ€§ï¼Œä½†å­˜åœ¨ä¸åˆ‡å®é™…çš„å‡è®¾ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“å§åº•æ¸¸æˆï¼ˆMUGï¼‰åè®®æ—¨åœ¨è§£å†³MADèŒƒå¼ä¸­çš„é—®é¢˜ï¼Œé€šè¿‡æ£€æµ‹â€œå§åº•â€æ™ºèƒ½ä½“ï¼ˆå³å‡ºç°å¹»è§‰çš„æ™ºèƒ½ä½“ï¼‰æ¥å¢å¼ºå¯é æ€§ã€‚</li>
<li>MUGé‡‡ç”¨å¤šæ¨¡å¼åäº‹å®æµ‹è¯•ï¼Œé€šè¿‡ä¿®æ”¹å‚è€ƒå›¾åƒæ¥è¯†åˆ«æ™ºèƒ½ä½“çš„å¹»è§‰ã€‚</li>
<li>MUGå®ç°äº†äº‹å®éªŒè¯ã€äº¤å‰è¯æ®æ¨ç†å’Œä¸»åŠ¨æ¨ç†ï¼Œæ¨è¿›äº†MADåè®®ã€‚</li>
<li>MUGæ¡†æ¶ä¸ºLLMä¸­çš„å¤šæ¨¡å¼æ¨ç†æä¾›äº†æ›´å¯é å’Œæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11182">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-28fa06fbd6238a4f04d1b181c39f1610" align="middle">
<img src="https://picx.zhimg.com/v2-ab5c68aa02449a8de2883b0525fbb870" align="middle">
<img src="https://picx.zhimg.com/v2-06df1f9066e75b8ba18fea72a604a05a" align="middle">
<img src="https://picx.zhimg.com/v2-5c0b57196e6c6b02102daab64b423e8f" align="middle">
<img src="https://picx.zhimg.com/v2-f28ce0b00667d8a68fb4d998859d750a" align="middle">
<img src="https://picx.zhimg.com/v2-09e98810a621e201d2328d3e2b569a82" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Refine-and-Align-Confidence-Calibration-through-Multi-Agent-Interaction-in-VQA"><a href="#Refine-and-Align-Confidence-Calibration-through-Multi-Agent-Interaction-in-VQA" class="headerlink" title="Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA"></a>Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA</h2><p><strong>Authors:Ayush Pandey, Jai Bardhan, Ishita Jain, Ramya S Hebbalaguppe, Rohan Raju Dhanakshirur, Lovekesh Vig</strong></p>
<p>In the context of Visual Question Answering (VQA) and Agentic AI, calibration refers to how closely an AI systemâ€™s confidence in its answers reflects their actual correctness. This aspect becomes especially important when such systems operate autonomously and must make decisions under visual uncertainty. While modern VQA systems, powered by advanced vision-language models (VLMs), are increasingly used in high-stakes domains like medical diagnostics and autonomous navigation due to their improved accuracy, the reliability of their confidence estimates remains under-examined. Particularly, these systems often produce overconfident responses. To address this, we introduce AlignVQA, a debate-based multi-agent framework, in which diverse specialized VLM â€“ each following distinct prompting strategies â€“ generate candidate answers and then engage in two-stage interaction: generalist agents critique, refine and aggregate these proposals. This debate process yields confidence estimates that more accurately reflect the modelâ€™s true predictive performance. We find that more calibrated specialized agents produce better aligned confidences. Furthermore, we introduce a novel differentiable calibration-aware loss function called aligncal designed to fine-tune the specialized agents by minimizing an upper bound on the calibration error. This objective explicitly improves the fidelity of each agentâ€™s confidence estimates. Empirical results across multiple benchmark VQA datasets substantiate the efficacy of our approach, demonstrating substantial reductions in calibration discrepancies. Furthermore, we propose a novel differentiable calibration-aware loss to fine-tune the specialized agents and improve the quality of their individual confidence estimates based on minimising upper bound calibration error.</p>
<blockquote>
<p>åœ¨è§†è§‰é—®ç­”ï¼ˆVQAï¼‰å’Œæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½çš„èƒŒæ™¯ä¸‹ï¼Œæ ¡å‡†æ˜¯æŒ‡äººå·¥æ™ºèƒ½ç³»ç»Ÿå¯¹å…¶ç­”æ¡ˆçš„ä¿¡å¿ƒä¸å®é™…æ­£ç¡®æ€§ä¹‹é—´çš„å»åˆç¨‹åº¦ã€‚å½“è¿™äº›ç³»ç»Ÿè‡ªä¸»è¿è¡Œå¹¶åœ¨è§†è§‰ä¸ç¡®å®šæ€§ä¸‹åšå‡ºå†³ç­–æ—¶ï¼Œè¿™ä¸€æ–¹é¢å˜å¾—å°¤ä¸ºé‡è¦ã€‚è™½ç„¶ç°ä»£VQAç³»ç»Ÿå‡­å€Ÿå…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨åŒ»ç–—è¯Šæ–­ã€è‡ªä¸»å¯¼èˆªç­‰é«˜é£é™©é¢†åŸŸçš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ï¼Œç”±äºå…¶ç²¾åº¦çš„æé«˜ï¼Œä½†å…¶ä¿¡å¿ƒä¼°è®¡çš„å¯é æ€§ä»æœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚ç‰¹åˆ«åœ°ï¼Œè¿™äº›ç³»ç»Ÿé€šå¸¸ä¼šäº§ç”Ÿè¿‡äºè‡ªä¿¡çš„å›åº”ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†AlignVQAï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè¾©è®ºçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå…¶ä¸­ä¸åŒçš„ä¸“ä¸šVLMâ€”â€”æ¯ä¸ªéƒ½éµå¾ªç‹¬ç‰¹çš„æç¤ºç­–ç•¥â€”â€”ç”Ÿæˆå€™é€‰ç­”æ¡ˆï¼Œç„¶åè¿›è¡Œä¸¤é˜¶æ®µäº¤äº’ï¼šé€šç”¨æ™ºèƒ½ä½“å¯¹è¿™äº›ææ¡ˆè¿›è¡Œæ‰¹åˆ¤ã€ç»†åŒ–å’Œèšåˆã€‚è¿™ç§è¾©è®ºè¿‡ç¨‹äº§ç”Ÿçš„ä¿¡å¿ƒä¼°è®¡æ›´èƒ½å‡†ç¡®åæ˜ æ¨¡å‹çš„çœŸæ­£é¢„æµ‹æ€§èƒ½ã€‚æˆ‘ä»¬å‘ç°æ›´æ ¡å‡†çš„ä¸“é—¨æ™ºèƒ½ä½“äº§ç”Ÿçš„ä¿¡å¿ƒæ›´ç¬¦åˆå®é™…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¯å¾®æ ¡å‡†æ„ŸçŸ¥æŸå¤±å‡½æ•°ï¼Œç§°ä¸ºaligncalï¼Œæ—¨åœ¨é€šè¿‡æœ€å°åŒ–æ ¡å‡†è¯¯å·®çš„ä¸Šç•Œæ¥å¾®è°ƒä¸“ä¸šæ™ºèƒ½ä½“ã€‚è¿™ä¸€ç›®æ ‡æ˜ç¡®æé«˜äº†æ¯ä¸ªæ™ºèƒ½ä½“ä¿¡å¿ƒä¼°è®¡çš„å¿ å®åº¦ã€‚åœ¨å¤šä¸ªåŸºå‡†VQAæ•°æ®é›†ä¸Šçš„å®è¯ç»“æœè¯å®äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºæ ¡å‡†å·®å¼‚çš„å¤§å¹…å‡å°‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å¯å¾®æ ¡å‡†æŸå¤±æ¥å¾®è°ƒä¸“ä¸šæ™ºèƒ½ä½“ï¼Œä»¥æé«˜å…¶ä¸ªä½“ä¿¡å¿ƒä¼°è®¡çš„è´¨é‡ï¼Œè¿™æ˜¯åŸºäºæœ€å°åŒ–ä¸Šç•Œæ ¡å‡†è¯¯å·®æ¥å®ç°çš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11169v1">PDF</a> 17 pages, 6 figures, 5 tables. Accepted to Special Track on AI Alignment, AAAI 2026. Project Page- <a target="_blank" rel="noopener" href="https://refine-align.github.io/">https://refine-align.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è§†è§‰é—®ç­”ï¼ˆVQAï¼‰å’Œæ™ºèƒ½ä½“AIä¸­çš„æ ¡å‡†é—®é¢˜ã€‚æ–‡ç« ä»‹ç»äº†å¦‚ä½•è¯„ä¼°AIç³»ç»Ÿç­”æ¡ˆçš„ç½®ä¿¡åº¦ä¸å…¶å®é™…æ­£ç¡®æ€§çš„åŒ¹é…ç¨‹åº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªä¸»è¿è¡Œå’Œè§†è§‰ä¸ç¡®å®šæ€§çš„æƒ…å†µä¸‹ã€‚é’ˆå¯¹ç°ä»£VQAç³»ç»Ÿåœ¨åŒ»ç–—è¯Šæ–­å’Œè‡ªä¸»å¯¼èˆªç­‰é«˜é£é™©é¢†åŸŸçš„åº”ç”¨ï¼Œæ–‡ç« æå‡ºäº†ä¸€ä¸ªåŸºäºè¾©è®ºçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶AlignVQAï¼Œé€šè¿‡ä¸åŒä¸“ä¸šVLMä¹‹é—´çš„äº¤äº’å’Œè¾©è®ºè¿‡ç¨‹ï¼Œç”Ÿæˆæ›´å‡†ç¡®çš„ç½®ä¿¡åº¦ä¼°è®¡ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜ä»‹ç»äº†ä¸€ç§æ–°å‹çš„å¾®åˆ†æ ¡å‡†æ„ŸçŸ¥æŸå¤±å‡½æ•°aligncalï¼Œç”¨äºç²¾ç»†è°ƒæ•´æ™ºèƒ½ä½“ï¼Œä»¥å‡å°‘æ ¡å‡†è¯¯å·®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VQAç³»ç»Ÿå’Œæ™ºèƒ½ä½“AIä¸­çš„æ ¡å‡†æ˜¯æŒ‡AIç³»ç»Ÿç­”æ¡ˆçš„ç½®ä¿¡åº¦ä¸å…¶å®é™…æ­£ç¡®æ€§çš„åŒ¹é…ç¨‹åº¦ã€‚</li>
<li>åœ¨è‡ªä¸»è¿è¡Œå’Œè§†è§‰ä¸ç¡®å®šæ€§çš„æƒ…å†µä¸‹ï¼Œæ ¡å‡†å˜å¾—å°¤ä¸ºé‡è¦ã€‚</li>
<li>ç°ä»£VQAç³»ç»Ÿè™½ç„¶åœ¨åŒ»ç–—è¯Šæ–­å’Œè‡ªä¸»å¯¼èˆªç­‰é¢†åŸŸåº”ç”¨å¹¿æ³›ï¼Œä½†å…¶ç½®ä¿¡åº¦ä¼°è®¡çš„å¯é æ€§å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚</li>
<li>æå‡ºçš„AlignVQAæ¡†æ¶åˆ©ç”¨å¤šæ™ºèƒ½ä½“è¾©è®ºè¿‡ç¨‹ç”Ÿæˆæ›´å‡†ç¡®çš„ç½®ä¿¡åº¦ä¼°è®¡ã€‚</li>
<li>AlignVQAæ¡†æ¶åŒ…æ‹¬å¤šç§ä¸“ä¸šVLMï¼Œå®ƒä»¬éµå¾ªä¸åŒçš„æç¤ºç­–ç•¥ï¼Œå¹¶é€šè¿‡ä¸¤é˜¶æ®µäº¤äº’è¿›è¡Œè¾©è®ºã€‚</li>
<li>æ–°å‹å¾®åˆ†æ ¡å‡†æ„ŸçŸ¥æŸå¤±å‡½æ•°aligncalè¢«ç”¨äºç²¾ç»†è°ƒæ•´æ™ºèƒ½ä½“ï¼Œä»¥å‡å°‘æ ¡å‡†è¯¯å·®ï¼Œæé«˜ç½®ä¿¡åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11169">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b6ff9b54da4bda35b9c5ec8f7395508a" align="middle">
<img src="https://picx.zhimg.com/v2-20668bc63c7cdb0cce342e24d2da0e96" align="middle">
<img src="https://picx.zhimg.com/v2-75c7022a21e81c04d64145da90e95884" align="middle">
<img src="https://picx.zhimg.com/v2-da62cf467e27a93de0a6011b905bb284" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Key-Decision-Makers-in-Multi-Agent-Debates-Who-Holds-the-Power"><a href="#Key-Decision-Makers-in-Multi-Agent-Debates-Who-Holds-the-Power" class="headerlink" title="Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?"></a>Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?</h2><p><strong>Authors:Qian Zhang, Yan Zheng, Jinyi Liu, Hebin Liang, Lanjun Wang</strong></p>
<p>Recent studies on LLM agent scaling have highlighted the potential of Multi-Agent Debate (MAD) to enhance reasoning abilities. However, the critical aspect of role allocation strategies remains underexplored. In this study, we demonstrate that allocating roles with differing viewpoints to specific positions significantly impacts MADâ€™s performance in reasoning tasks. Specifically, we find a novel role allocation strategy, â€œTruth Lastâ€, which can improve MAD performance by up to 22% in reasoning tasks. To address the issue of unknown truth in practical applications, we propose the Multi-Agent Debate Consistency (MADC) strategy, which systematically simulates and optimizes its core mechanisms. MADC incorporates path consistency to assess agreement among independent roles, simulating the role with the highest consistency score as the truth. We validated MADC across a range of LLMs (9 models), including the DeepSeek-R1 Distilled Models, on challenging reasoning tasks. MADC consistently demonstrated advanced performance, effectively overcoming MADâ€™s performance bottlenecks and providing a crucial pathway for further improvements in LLM agent scaling.</p>
<blockquote>
<p>å…³äºLLMä»£ç†æ‰©å±•çš„æœ€æ–°ç ”ç©¶å·²ç»çªå‡ºäº†å¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰åœ¨å¢å¼ºæ¨ç†èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè§’è‰²åˆ†é…ç­–ç•¥çš„å…³é”®æ–¹é¢ä»ç„¶è¢«å¿½è§†ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨ç‰¹å®šä½ç½®åˆ†é…å…·æœ‰ä¸åŒè§‚ç‚¹çš„è§’è‰²ä¼šå¯¹å¤šä»£ç†è¾©è®ºåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°äº§ç”Ÿé‡å¤§å½±å“ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§æ–°å‹çš„è§’è‰²åˆ†é…ç­–ç•¥ï¼Œå³â€œçœŸç†è‡³ä¸Šâ€ï¼Œè¯¥ç­–ç•¥å¯ä»¥å°†å¤šä»£ç†è¾©è®ºåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°æé«˜æœ€å¤šè¾¾22%ã€‚ä¸ºäº†è§£å†³å®é™…åº”ç”¨ä¸­æœªçŸ¥çœŸç†çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šä»£ç†è¾©è®ºä¸€è‡´æ€§ï¼ˆMADCï¼‰ç­–ç•¥ï¼Œå®ƒé€šè¿‡æ¨¡æ‹Ÿå’Œä¼˜åŒ–æ ¸å¿ƒæœºåˆ¶æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚MADCé‡‡ç”¨è·¯å¾„ä¸€è‡´æ€§æ¥è¯„ä¼°ç‹¬ç«‹è§’è‰²ä¹‹é—´çš„å…±è¯†ç¨‹åº¦ï¼Œå¹¶å°†å¾—åˆ†æœ€é«˜çš„è§’è‰²æ¨¡æ‹Ÿä¸ºçœŸç†ã€‚æˆ‘ä»¬åœ¨ä¸€ç³»åˆ—LLMï¼ˆåŒ…æ‹¬DeepSeek-R1è’¸é¦æ¨¡å‹åœ¨å†…çš„ä¹ä¸ªæ¨¡å‹ï¼‰ä¸ŠéªŒè¯äº†MADCåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚MADCçš„æŒç»­é«˜çº§æ€§èƒ½è¡¨æ˜å…¶æˆåŠŸçªç ´äº†MADçš„æ€§èƒ½ç“¶é¢ˆï¼Œä¸ºè¿›ä¸€æ­¥æé«˜LLMä»£ç†æ‰©å±•æä¾›äº†ä¸€æ¡å…³é”®é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11040v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥ç ”ç©¶è¡¨æ˜ï¼Œåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†æ‰©å±•ä¸­ï¼Œå¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰çš„æ¨ç†èƒ½åŠ›å…·æœ‰æ½œåŠ›ã€‚é€šè¿‡åˆ†é…ä¸åŒè§‚ç‚¹çš„è§’è‰²åˆ°ç‰¹å®šä½ç½®ï¼Œè§’è‰²åˆ†é…ç­–ç•¥å¯¹MADåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°äº§ç”Ÿæ˜¾è‘—å½±å“ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„è§’è‰²åˆ†é…ç­–ç•¥â€œçœŸç†æœ€åâ€ï¼Œå¯ä»¥æé«˜MADåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½é«˜è¾¾22%ã€‚ä¸ºäº†è§£å†³å®é™…åº”ç”¨ä¸­æœªçŸ¥çœŸç†çš„é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†å¤šä»£ç†è¾©è®ºä¸€è‡´æ€§ï¼ˆMADCï¼‰ç­–ç•¥ï¼Œå®ƒé€šè¿‡æ¨¡æ‹Ÿå’Œä¼˜åŒ–æ ¸å¿ƒæœºåˆ¶æ¥ç³»ç»Ÿåœ°è§£å†³è¿™ä¸€é—®é¢˜ã€‚åœ¨å¤šç§LLMä¸ŠéªŒè¯äº†MADCç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬DeepSeek-R1è’¸é¦æ¨¡å‹ï¼Œå®ƒåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œæœ‰æ•ˆå…‹æœäº†MADçš„æ€§èƒ½ç“¶é¢ˆï¼Œä¸ºLLMä»£ç†æ‰©å±•çš„è¿›ä¸€æ­¥æ”¹è¿›æä¾›äº†å…³é”®é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šä»£ç†è¾©è®ºï¼ˆMADï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ä¸Šå…·æœ‰æ½œåŠ›ã€‚</li>
<li>è§’è‰²åˆ†é…ç­–ç•¥å¯¹MADåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°è‡³å…³é‡è¦ã€‚</li>
<li>â€œçœŸç†æœ€åâ€æ˜¯ä¸€ç§æ–°çš„è§’è‰²åˆ†é…ç­–ç•¥ï¼Œèƒ½æé«˜MADåœ¨æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</li>
<li>å¤šä»£ç†è¾©è®ºä¸€è‡´æ€§ï¼ˆMADCï¼‰ç­–ç•¥è§£å†³äº†å®é™…åº”ç”¨ä¸­æœªçŸ¥çœŸç†çš„é—®é¢˜ã€‚</li>
<li>MADCç­–ç•¥é€šè¿‡æ¨¡æ‹Ÿå’Œä¼˜åŒ–æ ¸å¿ƒæœºåˆ¶æ¥ç³»ç»Ÿåœ°æé«˜LLMçš„æ€§èƒ½ã€‚</li>
<li>åœ¨å¤šç§LLMä¸ŠéªŒè¯äº†MADCç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬DeepSeek-R1è’¸é¦æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d79f8c94b4fb7450573e4dd6139bcf75" align="middle">
<img src="https://picx.zhimg.com/v2-40f1264ddfac5fdfcb7ff3b17383dce4" align="middle">
<img src="https://picx.zhimg.com/v2-a1fb66dcf73f15ec5238269f95df6e27" align="middle">
<img src="https://picx.zhimg.com/v2-dc4062a34e87663f7da3cd0f3ee5fa98" align="middle">
<img src="https://picx.zhimg.com/v2-c353df41491536d7ac76e3a8b5ee3ca0" align="middle">
<img src="https://picx.zhimg.com/v2-a8e6942a800101fe1b14855213431746" align="middle">
<img src="https://picx.zhimg.com/v2-0ccab7fd118a015578d2b14e3476675d" align="middle">
<img src="https://picx.zhimg.com/v2-9cd245e34ab04aa66243c50c9aa27158" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="GraphMASAL-A-Graph-based-Multi-Agent-System-for-Adaptive-Learning"><a href="#GraphMASAL-A-Graph-based-Multi-Agent-System-for-Adaptive-Learning" class="headerlink" title="GraphMASAL: A Graph-based Multi-Agent System for Adaptive Learning"></a>GraphMASAL: A Graph-based Multi-Agent System for Adaptive Learning</h2><p><strong>Authors:Biqing Zeng, Mengquan Liu, Zongwei Zhen</strong></p>
<p>The advent of Intelligent Tutoring Systems (ITSs) has marked a paradigm shift in education, enabling highly personalized learning pathways. However, true personalization requires adapting to learnersâ€™ complex knowledge states (multi-source) and diverse goals (multi-sink); existing ITSs often lack the necessary structural-reasoning capability and knowledge dynamism to generate genuinely effective learning paths, and they lack scientifically rigorous validation paradigms. In this paper we propose GraphMASAL (A Graph-based Multi-Agent System for Adaptive Learning), which integrates (i) a dynamic knowledge graph for persistent, stateful learner modeling; (ii) a LangGraph-orchestrated trio of agents (Diagnostician, Planner, Tutor); (iii) a knowledge-graph-grounded two-stage neural IR component (dual-encoder dense retrieval with cross-encoder listwise re-ranking and calibrated score fusion); and (iv) a multi-source multi-sink (MSMS) planning engine with a cognitively grounded cost and an approximation guarantee via greedy set cover. Under blinded automated evaluations with matched inputs and inference settings across diverse student profiles, GraphMASAL consistently outperforms LLM prompting and structured ablations in planningâ€“achieving stronger structural&#x2F;sequence alignment of learning paths, higher coverage of weak concepts, and lower learning costâ€“while also surpassing prompt-based baselines in cognitive diagnosis. Agreement with expert&#x2F;LLM-proxy ratings further supports the validity of our evaluation protocol. These findings indicate that grounding LLM agents in a dynamic knowledge graph, coupled with optimization under educational constraints, yields reliable, interpretable, and pedagogically plausible learning plans, advancing personalized and goal-oriented education.</p>
<blockquote>
<p>æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿï¼ˆITSï¼‰çš„å‡ºç°æ ‡å¿—ç€æ•™è‚²é¢†åŸŸçš„èŒƒå¼è½¬å˜ï¼Œä¸ºä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„çš„å¼€å¯æä¾›äº†å¯èƒ½ã€‚ç„¶è€Œï¼ŒçœŸæ­£çš„ä¸ªæ€§åŒ–éœ€è¦é€‚åº”å­¦ä¹ è€…çš„å¤æ‚çŸ¥è¯†çŠ¶æ€ï¼ˆå¤šæºï¼‰å’Œå¤šæ ·åŒ–çš„ç›®æ ‡ï¼ˆå¤šæ±‡ï¼‰ï¼›ç°æœ‰çš„ITSé€šå¸¸ç¼ºä¹å¿…è¦çš„ç»“æ„åŒ–æ¨ç†èƒ½åŠ›å’ŒçŸ¥è¯†åŠ¨æ€æ€§ï¼Œæ— æ³•ç”ŸæˆçœŸæ­£æœ‰æ•ˆçš„å­¦ä¹ è·¯å¾„ï¼Œä¹Ÿç¼ºä¹ç§‘å­¦ä¸¥è°¨çš„éªŒè¯èŒƒå¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GraphMASALï¼ˆåŸºäºå›¾çš„å¤šæ™ºèƒ½ä½“è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿï¼‰ï¼Œå®ƒé›†æˆäº†ï¼ˆiï¼‰åŠ¨æ€çŸ¥è¯†å›¾ï¼Œç”¨äºæŒä¹…ã€æœ‰çŠ¶æ€çš„å­¦ä¹ è€…å»ºæ¨¡ï¼›ï¼ˆiiï¼‰ç”±LangGraphåè°ƒçš„ä¸‰ä¸ªæ™ºèƒ½ä½“ï¼ˆè¯Šæ–­ä¸“å®¶ã€è§„åˆ’è€…ã€è¾…å¯¼å‘˜ï¼‰ï¼›ï¼ˆiiiï¼‰åŸºäºçŸ¥è¯†å›¾çš„ä¸¤ä¸ªé˜¶æ®µç¥ç»IRç»„ä»¶ï¼ˆåŒç¼–ç å™¨å¯†é›†æ£€ç´¢ï¼Œè·¨ç¼–ç å™¨åˆ—è¡¨çº§é‡æ–°æ’åå’Œæ ¡å‡†åˆ†æ•°èåˆï¼‰ï¼›ä»¥åŠï¼ˆivï¼‰å¤šæºå¤šæ±‡ï¼ˆMSMSï¼‰è§„åˆ’å¼•æ“ï¼Œå…·æœ‰è®¤çŸ¥åŸºç¡€çš„æˆæœ¬å’Œé€šè¿‡è´ªå¿ƒé›†åˆè¦†ç›–çš„è¿‘ä¼¼ä¿è¯ã€‚åœ¨å¤šæ ·åŒ–çš„å­¦ç”Ÿé…ç½®æ–‡ä»¶åŒ¹é…è¾“å…¥å’Œæ¨ç†è®¾ç½®çš„ç›²è‡ªåŠ¨è¯„ä¼°ä¸‹ï¼ŒGraphMASALåœ¨è§„åˆ’æ–¹é¢å§‹ç»ˆä¼˜äºå¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºå’Œç»“æ„åŒ–æ¶ˆè§£ï¼Œå®ç°äº†æ›´å¼ºçš„å­¦ä¹ è·¯å¾„ç»“æ„&#x2F;åºåˆ—å¯¹é½ã€æ›´é«˜çš„å¼±æ¦‚å¿µè¦†ç›–ç‡ã€æ›´ä½çš„å­¦ä¹ æˆæœ¬â€”â€”åŒæ—¶ä¹Ÿåœ¨è®¤çŸ¥è¯Šæ–­ä¸Šè¶…è¶Šäº†åŸºäºæç¤ºçš„åŸºçº¿ã€‚ä¸ä¸“å®¶&#x2F;å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†è¯„åˆ†çš„åè®®è¿›ä¸€æ­¥æ”¯æŒäº†æˆ‘ä»¬è¯„ä¼°åè®®çš„æœ‰æ•ˆæ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å»ºç«‹åœ¨åŠ¨æ€çŸ¥è¯†å›¾ä¸Šï¼Œå¹¶åœ¨æ•™è‚²çº¦æŸä¸‹è¿›è¡Œä¼˜åŒ–ï¼Œå¯ä»¥äº§ç”Ÿå¯é ã€å¯è§£é‡Šã€ç¬¦åˆæ•™å­¦æ³•çš„å­¦ä¹ è®¡åˆ’ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–å’Œç›®æ ‡å¯¼å‘çš„æ•™è‚²å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.11035v1">PDF</a> 9 pages, 3 figures,submitted to AAMAS 2026</p>
<p><strong>Summary</strong><br>     æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿï¼ˆITSï¼‰çš„å‡ºç°æ ‡å¿—ç€æ•™è‚²é¢†åŸŸçš„èŒƒå¼è½¬å˜ï¼Œä¸ºå®ç°é«˜åº¦ä¸ªæ€§åŒ–çš„å­¦ä¹ è·¯å¾„æä¾›äº†å¯èƒ½ã€‚ç„¶è€Œï¼ŒçœŸæ­£çš„ä¸ªæ€§åŒ–éœ€è¦é€‚åº”å­¦ä¹ è€…çš„å¤æ‚çŸ¥è¯†çŠ¶æ€å’Œå¤šæ ·åŒ–çš„ç›®æ ‡ã€‚ç°æœ‰ITSç³»ç»Ÿç¼ºä¹å¿…è¦çš„ç»“æ„åŒ–æ¨ç†èƒ½åŠ›å’ŒçŸ¥è¯†åŠ¨æ€æ€§ï¼Œéš¾ä»¥ç”ŸæˆçœŸæ­£æœ‰æ•ˆçš„å­¦ä¹ è·¯å¾„ï¼Œå¹¶ä¸”ç¼ºä¹ç§‘å­¦ä¸¥è°¨æ€§éªŒè¯èŒƒå¼ã€‚æœ¬æ–‡æå‡ºGraphMASALï¼ˆåŸºäºå›¾çš„å¤šæ™ºèƒ½ä½“è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿï¼‰ï¼Œé€šè¿‡åŠ¨æ€çŸ¥è¯†å›¾è°±è¿›è¡ŒæŒä¹…çŠ¶æ€å­¦ä¹ è€…å»ºæ¨¡ã€LangGraphååŒçš„ä¸‰ä¸ªæ™ºèƒ½ä½“ï¼ˆè¯Šæ–­å¸ˆã€è§„åˆ’å¸ˆã€è¾…å¯¼è€…ï¼‰ã€çŸ¥è¯†å›¾è°±ä¸ºåŸºç¡€çš„ä¸¤é˜¶æ®µç¥ç»ç½‘ç»œIRç»„ä»¶ï¼Œä»¥åŠå¤šæºå¤šæ±‡è§„åˆ’å¼•æ“ï¼Œå®ç°äº†æœ‰æ•ˆçš„ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„ç”Ÿæˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGraphMASALåœ¨è‡ªåŠ¨åŒ–è¯„ä¼°ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºLLMæç¤ºå’Œç»“æ„åŒ–åˆ é™¤æ³•ç”Ÿæˆçš„å­¦ä¹ è·¯å¾„æ›´å…·ä¼˜åŠ¿ï¼Œä½“ç°åœ¨å­¦ä¹ è·¯å¾„çš„ç»“æ„åŒ–&#x2F;åºåˆ—å¯¹é½æ›´å¼ºã€è¦†ç›–çš„è–„å¼±ç¯èŠ‚æ›´é«˜ã€å­¦ä¹ æˆæœ¬æ›´ä½ã€‚æ­¤å¤–ï¼Œä¸ä¸“å®¶&#x2F;LLMä»£ç†è¯„åˆ†çš„å¥‘åˆè¿›ä¸€æ­¥éªŒè¯äº†å…¶è¯„ä¼°åè®®çš„æœ‰æ•ˆæ€§ã€‚æ­¤ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°†LLMæ™ºèƒ½ä½“å»ºç«‹åœ¨åŠ¨æ€çŸ¥è¯†å›¾è°±ä¸Šï¼Œç»“åˆæ•™è‚²çº¦æŸä¼˜åŒ–ï¼Œå¯ç”Ÿæˆå¯é ã€å¯è§£é‡Šã€æ•™è‚²ä¸Šåˆç†çš„ä¸ªæ€§åŒ–å­¦ä¹ è®¡åˆ’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿï¼ˆITSï¼‰åœ¨æ•™è‚²é¢†åŸŸå®ç°äº†ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„çš„æ½œåŠ›ã€‚</li>
<li>ç°æœ‰ITSç³»ç»Ÿåœ¨ç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„æ—¶ï¼Œç¼ºä¹ç»“æ„åŒ–æ¨ç†èƒ½åŠ›ã€çŸ¥è¯†åŠ¨æ€æ€§å’Œç§‘å­¦éªŒè¯æ–¹æ³•ã€‚</li>
<li>GraphMASALé€šè¿‡åŠ¨æ€çŸ¥è¯†å›¾è°±å®ç°æŒä¹…çŠ¶æ€å­¦ä¹ è€…å»ºæ¨¡ã€‚</li>
<li>GraphMASALé›†æˆäº†å¤šä¸ªç»„ä»¶ï¼šè¯Šæ–­æ™ºèƒ½ä½“ã€è§„åˆ’æ™ºèƒ½ä½“ã€è¾…å¯¼æ™ºèƒ½ä½“ä»¥åŠåŸºäºçŸ¥è¯†å›¾è°±çš„ä¸¤é˜¶æ®µç¥ç»ç½‘ç»œIRç»„ä»¶ã€‚</li>
<li>GraphMASALåœ¨å¤šæºå¤šæ±‡è§„åˆ’å¼•æ“çš„æ”¯æŒä¸‹ï¼Œèƒ½æœ‰æ•ˆç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„ã€‚</li>
<li>è‡ªåŠ¨åŒ–è¯„ä¼°ç»“æœæ˜¾ç¤ºGraphMASALåœ¨è§„åˆ’æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç›¸å¯¹äºå…¶ä»–æ–¹æ³•æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.11035">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-09b3e9dabfaec09b99e6463e1098dd9c" align="middle">
<img src="https://picx.zhimg.com/v2-08ec34ed3a0acfca327c00af8e620d9b" align="middle">
<img src="https://picx.zhimg.com/v2-9969af0768c9929287f2cdc3adbe5a6f" align="middle">
<img src="https://picx.zhimg.com/v2-fd34dd63c53c371d19732f4e52b2e181" align="middle">
<img src="https://picx.zhimg.com/v2-c0cdec259529da0ffcac0c941dc4dfc9" align="middle">
<img src="https://picx.zhimg.com/v2-5a2cda8ddbfe361fa8f55c294706ba0e" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Exposing-Weak-Links-in-Multi-Agent-Systems-under-Adversarial-Prompting"><a href="#Exposing-Weak-Links-in-Multi-Agent-Systems-under-Adversarial-Prompting" class="headerlink" title="Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting"></a>Exposing Weak Links in Multi-Agent Systems under Adversarial Prompting</h2><p><strong>Authors:Nirmit Arora, Sathvik Joel, Ishan Kavathekar,  Palak, Rohan Gandhi, Yash Pandya, Tanuja Ganu, Aditya Kanade, Akshay Nambi</strong></p>
<p>LLM-based agents are increasingly deployed in multi-agent systems (MAS). As these systems move toward real-world applications, their security becomes paramount. Existing research largely evaluates single-agent security, leaving a critical gap in understanding the vulnerabilities introduced by multi-agent design. However, existing systems fall short due to lack of unified frameworks and metrics focusing on unique rejection modes in MAS. We present SafeAgents, a unified and extensible framework for fine-grained security assessment of MAS. SafeAgents systematically exposes how design choices such as plan construction strategies, inter-agent context sharing, and fallback behaviors affect susceptibility to adversarial prompting. We introduce Dharma, a diagnostic measure that helps identify weak links within multi-agent pipelines. Using SafeAgents, we conduct a comprehensive study across five widely adopted multi-agent architectures (centralized, decentralized, and hybrid variants) on four datasets spanning web tasks, tool use, and code generation. Our findings reveal that common design patterns carry significant vulnerabilities. For example, centralized systems that delegate only atomic instructions to sub-agents obscure harmful objectives, reducing robustness. Our results highlight the need for security-aware design in MAS. Link to code is <a target="_blank" rel="noopener" href="https://github.com/microsoft/SafeAgents">https://github.com/microsoft/SafeAgents</a></p>
<blockquote>
<p>åŸºäºå¤§å‹æ¨¡å‹çš„æ™ºèƒ½ä½“åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ä¸­çš„éƒ¨ç½²æ—¥ç›Šå¢å¤šã€‚éšç€è¿™äº›ç³»ç»Ÿå‘å®é™…åº”ç”¨å‘å±•ï¼Œå…¶å®‰å…¨æ€§å˜å¾—è‡³å…³é‡è¦ã€‚ç°æœ‰çš„ç ”ç©¶å¤§å¤šè¯„ä¼°å•æ™ºèƒ½ä½“çš„å®‰å…¨æ€§ï¼Œè€Œå¯¹äºå¤šæ™ºèƒ½ä½“è®¾è®¡æ‰€å¸¦æ¥çš„æ¼æ´ç¼ºä¹ç†è§£ï¼Œè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶è¿˜å­˜åœ¨å·¨å¤§çš„ç©ºç™½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç³»ç»Ÿç”±äºç¼ºä¹ä¸“æ³¨äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ç‹¬ç‰¹æ‹’ç»æ¨¡å¼çš„ç»Ÿä¸€æ¡†æ¶å’ŒæŒ‡æ ‡ï¼Œè€Œæ— æ³•å……åˆ†å‘æŒ¥å…¶æ•ˆèƒ½ã€‚æˆ‘ä»¬æå‡ºäº†SafeAgentsï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿›è¡Œç²¾ç»†çš„å®‰å…¨è¯„ä¼°ã€‚SafeAgentsç³»ç»Ÿåœ°æ­ç¤ºäº†è®¾è®¡é€‰æ‹©ï¼Œå¦‚è®¡åˆ’æ„å»ºç­–ç•¥ã€æ™ºèƒ½ä½“é—´ä¸Šä¸‹æ–‡å…±äº«å’Œå›é€€è¡Œä¸ºç­‰ï¼Œå¦‚ä½•å½±å“å¯¹æŠ—æ€§æç¤ºçš„æ˜“æ„Ÿæ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†Dharmaè¿™ä¸€è¯Šæ–­åº¦é‡æ ‡å‡†ï¼Œæœ‰åŠ©äºè¯†åˆ«å¤šæ™ºèƒ½ä½“ç®¡é“ä¸­çš„è–„å¼±ç¯èŠ‚ã€‚ä½¿ç”¨SafeAgentsï¼Œæˆ‘ä»¬å¯¹äº”ä¸ªå¹¿æ³›é‡‡ç”¨çš„å¤šæ™ºèƒ½ä½“æ¶æ„ï¼ˆé›†ä¸­å¼ã€åˆ†æ•£å¼å’Œæ··åˆå˜ç§ï¼‰è¿›è¡Œäº†å…¨é¢ç ”ç©¶ï¼Œæ¶‰åŠå››ä¸ªæ¶µç›–ç½‘ç»œä»»åŠ¡ã€å·¥å…·ä½¿ç”¨å’Œä»£ç ç”Ÿæˆçš„æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œå¸¸è§çš„è®¾è®¡æ¨¡å¼å­˜åœ¨é‡å¤§æ¼æ´ã€‚ä¾‹å¦‚ï¼Œé›†ä¸­å¼ç³»ç»Ÿä»…å‘å­æ™ºèƒ½ä½“å§”æ´¾åŸå­æŒ‡ä»¤ä¼šæ©ç›–æœ‰å®³ç›®æ ‡ï¼Œé™ä½å…¶ç¨³å¥æ€§ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å®‰å…¨è®¾è®¡çš„å¿…è¦æ€§ã€‚ä»£ç é“¾æ¥æ˜¯<a target="_blank" rel="noopener" href="https://github.com/microsoft/SafeAgents%E3%80%82">https://github.com/microsoft/SafeAgentsã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10949v1">PDF</a> 10 pages, 3 figures. Code available at <a target="_blank" rel="noopener" href="https://github.com/microsoft/SafeAgents">https://github.com/microsoft/SafeAgents</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ä»£ç†åœ¨å¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰ä¸­çš„åº”ç”¨æ—¥ç›Šæ™®åŠã€‚éšç€è¿™äº›ç³»ç»Ÿå‘å®é™…åº”ç”¨å‘å±•ï¼Œå…¶å®‰å…¨æ€§å˜å¾—è‡³å…³é‡è¦ã€‚å½“å‰ç ”ç©¶ä¸»è¦è¯„ä¼°å•ä¸€ä»£ç†çš„å®‰å…¨æ€§ï¼Œå¿½è§†äº†å¤šä»£ç†è®¾è®¡å¼•å…¥çš„æ¼æ´æ‰€å¸¦æ¥çš„é£é™©ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç³»ç»Ÿç”±äºç¼ºä¹ç»Ÿä¸€æ¡†æ¶å’Œä¸“æ³¨äºå¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰ä¸­çš„ç‹¬ç‰¹æ‹’ç»æ¨¡å¼çš„åº¦é‡æ ‡å‡†è€Œæ˜¾å¾—ä¸è¶³ã€‚æœ¬æ–‡æå‡ºäº†SafeAgentsï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºå¯¹MASè¿›è¡Œç²¾ç»†ç²’åº¦çš„å®‰å…¨è¯„ä¼°ã€‚SafeAgentsç³»ç»Ÿåœ°æ­ç¤ºäº†è®¾è®¡é€‰æ‹©ï¼ˆå¦‚è®¡åˆ’æ„å»ºç­–ç•¥ã€ä»£ç†é—´ä¸Šä¸‹æ–‡å…±äº«å’Œæ•…éšœæ¢å¤è¡Œä¸ºï¼‰å¦‚ä½•å½±å“å¯¹å¯¹æŠ—æ€§æç¤ºçš„æ•æ„Ÿæ€§ã€‚æœ¬æ–‡è¿˜ä»‹ç»äº†Dharmaï¼Œè¿™æ˜¯ä¸€ç§è¯Šæ–­æªæ–½ï¼Œæœ‰åŠ©äºè¯†åˆ«å¤šä»£ç†ç®¡é“ä¸­çš„è–„å¼±ç¯èŠ‚ã€‚ä½¿ç”¨SafeAgentsï¼Œæˆ‘ä»¬åœ¨äº”ä¸ªå¹¿æ³›é‡‡ç”¨çš„å¤šä»£ç†æ¶æ„ï¼ˆé›†ä¸­å¼ã€åˆ†æ•£å¼å’Œæ··åˆå˜ä½“ï¼‰ä»¥åŠæ¶µç›–ç½‘ç»œä»»åŠ¡ã€å·¥å…·ä½¿ç”¨å’Œä»£ç ç”Ÿæˆçš„å››ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†ç»¼åˆç ”ç©¶ã€‚ç»“æœè¡¨æ˜ï¼Œå¸¸è§çš„è®¾è®¡æ¨¡å¼å­˜åœ¨é‡å¤§å®‰å…¨æ¼æ´ã€‚ä¾‹å¦‚ï¼Œä»…å‘å­ä»£ç†å§”æ´¾åŸå­æŒ‡ä»¤çš„é›†ä¸­å¼ç³»ç»Ÿå¯èƒ½ä¼šæ©ç›–æœ‰å®³ç›®æ ‡ï¼Œä»è€Œé™ä½ç¨³å¥æ€§ã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†å¤šä»£ç†ç³»ç»Ÿè®¾è®¡ä¸­éœ€è¦æ³¨é‡å®‰å…¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based agentséƒ¨ç½²åœ¨å¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰ä¸­æ—¶ï¼Œå…¶å®‰å…¨æ€§è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦å…³æ³¨å•ä¸€ä»£ç†çš„å®‰å…¨æ€§è¯„ä¼°ï¼Œå¿½è§†äº†å¤šä»£ç†è®¾è®¡å¸¦æ¥çš„æ¼æ´ã€‚</li>
<li>SafeAgentsæ˜¯ä¸€ä¸ªç»Ÿä¸€ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºå¯¹MASè¿›è¡Œç²¾ç»†ç²’åº¦çš„å®‰å…¨è¯„ä¼°ã€‚</li>
<li>SafeAgentsæ­ç¤ºäº†è®¾è®¡é€‰æ‹©å¦‚ä½•å½±å“å¤šä»£ç†ç³»ç»Ÿå¯¹å¯¹æŠ—æ€§æç¤ºçš„æ•æ„Ÿæ€§ã€‚</li>
<li>Dharmaæ˜¯ä¸€ç§è¯Šæ–­æªæ–½ï¼Œç”¨äºè¯†åˆ«å¤šä»£ç†ç®¡é“ä¸­çš„è–„å¼±ç¯èŠ‚ã€‚</li>
<li>ç ”ç©¶è¡¨æ˜å¸¸è§çš„å¤šä»£ç†ç³»ç»Ÿè®¾è®¡æ¨¡å¼å­˜åœ¨é‡å¤§å®‰å…¨æ¼æ´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10949">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d75fee0ca837d567dcea764c6b320f09" align="middle">
<img src="https://picx.zhimg.com/v2-1c660fcbe42f49d8526dafe7feb0d545" align="middle">
<img src="https://picx.zhimg.com/v2-85f45fc55a313f0be18860132844da90" align="middle">
<img src="https://picx.zhimg.com/v2-19d70e73bdce54c331e4311007734224" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="HPCAgentTester-A-Multi-Agent-LLM-Approach-for-Enhanced-HPC-Unit-Test-Generation"><a href="#HPCAgentTester-A-Multi-Agent-LLM-Approach-for-Enhanced-HPC-Unit-Test-Generation" class="headerlink" title="HPCAgentTester: A Multi-Agent LLM Approach for Enhanced HPC Unit Test Generation"></a>HPCAgentTester: A Multi-Agent LLM Approach for Enhanced HPC Unit Test Generation</h2><p><strong>Authors:Rabimba Karanjai, Lei Xu, Weidong Shi</strong></p>
<p>Unit testing in High-Performance Computing (HPC) is critical but challenged by parallelism, complex algorithms, and diverse hardware. Traditional methods often fail to address non-deterministic behavior and synchronization issues in HPC applications. This paper introduces HPCAgentTester, a novel multi-agent Large Language Model (LLM) framework designed to automate and enhance unit test generation for HPC software utilizing OpenMP and MPI. HPCAgentTester employs a unique collaborative workflow where specialized LLM agents (Recipe Agent and Test Agent) iteratively generate and refine test cases through a critique loop. This architecture enables the generation of context-aware unit tests that specifically target parallel execution constructs, complex communication patterns, and hierarchical parallelism. We demonstrate HPCAgentTesterâ€™s ability to produce compilable and functionally correct tests for OpenMP and MPI primitives, effectively identifying subtle bugs that are often missed by conventional techniques. Our evaluation shows that HPCAgentTester significantly improves test compilation rates and correctness compared to standalone LLMs, offering a more robust and scalable solution for ensuring the reliability of parallel software systems.</p>
<blockquote>
<p>é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰ä¸­çš„å•å…ƒæµ‹è¯•è‡³å…³é‡è¦ï¼Œä½†é¢ä¸´ç€å¹¶è¡Œæ€§ã€å¤æ‚ç®—æ³•å’Œå¤šæ ·ç¡¬ä»¶çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•å¾€å¾€éš¾ä»¥è§£å†³HPCåº”ç”¨ç¨‹åºä¸­çš„éç¡®å®šæ€§è¡Œä¸ºå’ŒåŒæ­¥é—®é¢˜ã€‚æœ¬æ–‡ä»‹ç»äº†HPCAgentTesterï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨OpenMPå’ŒMPIè‡ªåŠ¨åŒ–å’Œæ”¹è¿›é«˜æ€§èƒ½è®¡ç®—è½¯ä»¶çš„å•å…ƒæµ‹è¯•ç”Ÿæˆã€‚HPCAgentTesteré‡‡ç”¨ç‹¬ç‰¹çš„åä½œå·¥ä½œæµç¨‹ï¼Œå…¶ä¸­çš„ä¸“ä¸šLLMæ™ºèƒ½ä½“ï¼ˆé…æ–¹æ™ºèƒ½ä½“å’Œæµ‹è¯•æ™ºèƒ½ä½“ï¼‰é€šè¿‡æ‰¹åˆ¤å¾ªç¯è¿­ä»£åœ°ç”Ÿæˆå’Œç»†åŒ–æµ‹è¯•ç”¨ä¾‹ã€‚è¿™ç§æ¶æ„èƒ½å¤Ÿç”Ÿæˆé¢å‘å¹¶è¡Œæ‰§è¡Œç»“æ„ã€å¤æ‚é€šä¿¡æ¨¡å¼å’Œå±‚æ¬¡åŒ–å¹¶è¡Œæ€§çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å•å…ƒæµ‹è¯•ã€‚æˆ‘ä»¬å±•ç¤ºäº†HPCAgentTesterä¸ºOpenMPå’ŒMPIåŸºæœ¬å…ƒç´ ç”Ÿæˆå¯ç¼–è¯‘ä¸”åŠŸèƒ½æ­£ç¡®çš„æµ‹è¯•çš„èƒ½åŠ›ï¼Œè¿™äº›æµ‹è¯•æœ‰æ•ˆåœ°è¯†åˆ«å‡ºä¼ ç»ŸæŠ€æœ¯å¸¸å¸¸å¿½ç•¥çš„å¾®å¦™é”™è¯¯ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œä¸ç‹¬ç«‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼ŒHPCAgentTesteråœ¨æµ‹è¯•ç¼–è¯‘ç‡å’Œæ­£ç¡®æ€§æ–¹é¢æœ‰äº†æ˜¾è‘—æé«˜ï¼Œä¸ºå¹¶è¡Œè½¯ä»¶ç³»ç»Ÿæä¾›äº†æ›´ç¨³å¥å’Œå¯æ‰©å±•çš„å¯é æ€§ä¿è¯è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10860v1">PDF</a> Accepted in AIWare 2025</p>
<p><strong>Summary</strong><br>é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰ä¸­çš„å•å…ƒæµ‹è¯•è‡³å…³é‡è¦ï¼Œä½†é¢ä¸´å¹¶è¡Œæ€§ã€å¤æ‚ç®—æ³•å’Œå¤šæ ·ç¡¬ä»¶çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•å¾€å¾€æ— æ³•è§£å†³HPCåº”ç”¨ç¨‹åºä¸­çš„éç¡®å®šæ€§è¡Œä¸ºå’ŒåŒæ­¥é—®é¢˜ã€‚æœ¬æ–‡ä»‹ç»äº†HPCAgentTesterï¼Œä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨OpenMPå’ŒMPIè‡ªåŠ¨åŒ–å’Œæé«˜HPCè½¯ä»¶çš„å•å…ƒæµ‹è¯•ç”Ÿæˆã€‚HPCAgentTesteré‡‡ç”¨ç‹¬ç‰¹çš„åä½œå·¥ä½œæµç¨‹ï¼Œä¸“ç”¨LLMæ™ºèƒ½ä½“ï¼ˆé…æ–¹æ™ºèƒ½ä½“å’Œæµ‹è¯•æ™ºèƒ½ä½“ï¼‰é€šè¿‡è¯„å®¡å¾ªç¯è¿­ä»£ç”Ÿæˆå’Œç»†åŒ–æµ‹è¯•ç”¨ä¾‹ã€‚æ­¤æ¶æ„èƒ½å¤Ÿç”Ÿæˆé’ˆå¯¹å¹¶è¡Œæ‰§è¡Œç»“æ„ã€å¤æ‚é€šä¿¡æ¨¡å¼å’Œå±‚æ¬¡å¹¶è¡Œçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å•å…ƒæµ‹è¯•ã€‚æˆ‘ä»¬è¯æ˜äº†HPCAgentTesterèƒ½å¤Ÿä¸ºOpenMPå’ŒMPIåŸºæœ¬ç»„ä»¶ç”Ÿæˆå¯ç¼–è¯‘å’ŒåŠŸèƒ½æ­£ç¡®çš„æµ‹è¯•ï¼Œæœ‰æ•ˆåœ°å‘ç°ä¼ ç»ŸæŠ€æœ¯å¸¸å¿½ç•¥çš„ç»†å¾®é”™è¯¯ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œä¸ç‹¬ç«‹LLMç›¸æ¯”ï¼ŒHPCAgentTesteræ˜¾è‘—æé«˜æµ‹è¯•ç¼–è¯‘ç‡å’Œæ­£ç¡®æ€§ï¼Œä¸ºå¹¶è¡Œè½¯ä»¶ç³»ç»Ÿæä¾›æ›´ä¸ºç¨³å¥å’Œå¯æ‰©å±•çš„å¯é æ€§ä¿è¯è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ€§èƒ½è®¡ç®—ä¸­çš„å•å…ƒæµ‹è¯•é¢ä¸´å¹¶è¡Œæ€§ã€å¤æ‚ç®—æ³•å’Œå¤šæ ·ç¡¬ä»¶çš„æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•åœ¨è§£å†³HPCåº”ç”¨ç¨‹åºçš„éç¡®å®šæ€§è¡Œä¸ºå’ŒåŒæ­¥é—®é¢˜ä¸Šå­˜åœ¨ä¸è¶³ã€‚</li>
<li>HPCAgentTesteræ˜¯ä¸€ä¸ªæ–°å‹å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–å’Œæé«˜HPCè½¯ä»¶çš„å•å…ƒæµ‹è¯•ç”Ÿæˆã€‚</li>
<li>HPCAgentTesteré‡‡ç”¨ç‹¬ç‰¹åä½œå·¥ä½œæµç¨‹ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆå’Œç»†åŒ–æµ‹è¯•ç”¨ä¾‹æ¥å¢å¼ºæµ‹è¯•æ•ˆæœã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿé’ˆå¯¹å¹¶è¡Œæ‰§è¡Œç»“æ„ã€å¤æ‚é€šä¿¡æ¨¡å¼å’Œå±‚æ¬¡å¹¶è¡Œç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥å•å…ƒæµ‹è¯•ã€‚</li>
<li>HPCAgentTesterèƒ½å¤Ÿç”Ÿæˆå¯ç¼–è¯‘å’ŒåŠŸèƒ½æ­£ç¡®çš„æµ‹è¯•ï¼ŒåŒ…æ‹¬å‘ç°ä¼ ç»ŸæŠ€æœ¯å¸¸å¿½ç•¥çš„ç»†å¾®é”™è¯¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10860">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6d1bf2c9628572b664ef4300a91edbab" align="middle">
<img src="https://picx.zhimg.com/v2-a9031f5f0d85414b59db934544914b46" align="middle">
<img src="https://picx.zhimg.com/v2-25dce1977d7910e6df817ac10d6022ca" align="middle">
<img src="https://picx.zhimg.com/v2-81f8f771b6346a7151235631c1162fe4" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="VoiceAgentEval-A-Dual-Dimensional-Benchmark-for-Expert-Level-Intelligent-Voice-Agent-Evaluation-of-Xbenchâ€™s-Professional-Aligned-Series"><a href="#VoiceAgentEval-A-Dual-Dimensional-Benchmark-for-Expert-Level-Intelligent-Voice-Agent-Evaluation-of-Xbenchâ€™s-Professional-Aligned-Series" class="headerlink" title="VoiceAgentEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Voice-Agent Evaluation of Xbenchâ€™s Professional-Aligned Series"></a>VoiceAgentEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Voice-Agent Evaluation of Xbenchâ€™s Professional-Aligned Series</h2><p><strong>Authors:Pengyu Xu, Shijia Li, Ao Sun, Feng Zhang, Yahan Li, Bo Wu, Zhanyu Ma, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He, Rui Wang, Yang Liu, Xiaobo Hu, Fan Yang, Jia Zheng, Guanghua Yao</strong></p>
<p>We propose OutboundEval, a comprehensive benchmark for evaluating large language models (LLMs) in expert-level intelligent outbound calling scenarios. Unlike existing methods that suffer from three key limitations - insufficient dataset diversity and category coverage, unrealistic user simulation, and inaccurate evaluation metrics - OutboundEval addresses these issues through a structured framework. First, we design a benchmark spanning six major business domains and 30 representative sub-scenarios, each with scenario-specific process decomposition, weighted scoring, and domain-adaptive metrics. Second, we develop a large-model-driven User Simulator that generates diverse, persona-rich virtual users with realistic behaviors, emotional variability, and communication styles, providing a controlled yet authentic testing environment. Third, we introduce a dynamic evaluation method that adapts to task variations, integrating automated and human-in-the-loop assessment to measure task execution accuracy, professional knowledge application, adaptability, and user experience quality. Experiments on 12 state-of-the-art LLMs reveal distinct trade-offs between expert-level task completion and interaction fluency, offering practical insights for building reliable, human-like outbound AI systems. OutboundEval establishes a practical, extensible, and domain-oriented standard for benchmarking LLMs in professional applications.</p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†OutboundEvalï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ä¸“å®¶çº§æ™ºèƒ½å¤–å‘¼åœºæ™¯ä¸­è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»¼åˆåŸºå‡†æµ‹è¯•ã€‚ä¸ç°æœ‰æ–¹æ³•å­˜åœ¨çš„ä¸‰ä¸ªä¸»è¦å±€é™æ€§â€”â€”æ•°æ®é›†å¤šæ ·æ€§å’Œç±»åˆ«è¦†ç›–ä¸è¶³ã€ç”¨æˆ·æ¨¡æ‹Ÿä¸çœŸå®ã€è¯„ä¼°æŒ‡æ ‡ä¸å‡†ç¡®â€”â€”ç›¸æ¯”ï¼ŒOutboundEvalé€šè¿‡ç»“æ„åŒ–æ¡†æ¶è§£å†³äº†è¿™äº›é—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè·¨è¶Šå…­å¤§ä¸šåŠ¡åŸŸå’Œ30ä¸ªä»£è¡¨æ€§å­åœºæ™¯çš„åŸºå‡†æµ‹è¯•ï¼Œæ¯ä¸ªåœºæ™¯éƒ½æœ‰ç‰¹å®šçš„æµç¨‹åˆ†è§£ã€åŠ æƒè¯„åˆ†å’ŒåŸŸè‡ªé€‚åº”æŒ‡æ ‡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªä»¥å¤§å‹æ¨¡å‹é©±åŠ¨çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Œç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–ã€ä¸°å¯Œä¸ªæ€§çš„è™šæ‹Ÿç”¨æˆ·ï¼Œå…·æœ‰çœŸå®è¡Œä¸ºã€æƒ…ç»ªå˜åŒ–å’Œäº¤æµé£æ ¼ï¼Œæä¾›äº†ä¸€ä¸ªå—æ§ä½†çœŸå®çš„æµ‹è¯•ç¯å¢ƒã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé€‚åº”ä»»åŠ¡å˜åŒ–ï¼Œç»“åˆè‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°ï¼Œæµ‹é‡ä»»åŠ¡æ‰§è¡Œå‡†ç¡®æ€§ã€ä¸“ä¸šçŸ¥è¯†åº”ç”¨ã€é€‚åº”æ€§å’Œç”¨æˆ·ä½“éªŒè´¨é‡ã€‚åœ¨12ä¸ªæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šçš„å®éªŒæ­ç¤ºäº†ä¸“ä¸šä»»åŠ¡å®Œæˆå’Œäº¤äº’æµç•…æ€§ä¹‹é—´çš„æ˜æ˜¾æƒè¡¡ï¼Œä¸ºæ„å»ºå¯é ã€äººæ€§åŒ–çš„å¤–å‘¼AIç³»ç»Ÿæä¾›äº†å®é™…è§è§£ã€‚OutboundEvalä¸ºä¸“ä¸šåº”ç”¨ä¸­å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºå‡†æµ‹è¯•å»ºç«‹äº†ä¸€ä¸ªå®ç”¨ã€å¯æ‰©å±•å’Œé¢å‘åŸŸçš„æ ‡å‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.21244v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æˆ‘ä»¬æå‡ºäº†OutboundEvalï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸“ä¸šçº§æ™ºèƒ½å¤–å‘¼åœºæ™¯çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç»¼åˆè¯„ä¼°åŸºå‡†ã€‚å®ƒé€šè¿‡ç»“æ„åŒ–æ¡†æ¶è§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸‰ä¸ªä¸»è¦å±€é™æ€§ï¼šæ•°æ®é›†å¤šæ ·æ€§å’Œç±»åˆ«è¦†ç›–ä¸è¶³ã€ç”¨æˆ·æ¨¡æ‹Ÿä¸çœŸå®ä»¥åŠè¯„ä¼°æŒ‡æ ‡ä¸å‡†ç¡®ã€‚æˆ‘ä»¬è®¾è®¡äº†æ¶µç›–å…­å¤§ä¸šåŠ¡åŸŸå’Œ30ä¸ªä»£è¡¨æ€§å­åœºæ™¯çš„åŸºå‡†æµ‹è¯•ï¼Œæ¯ä¸ªåœºæ™¯éƒ½æœ‰ç‰¹å®šçš„è¿‡ç¨‹åˆ†è§£ã€åŠ æƒè¯„åˆ†å’Œé¢†åŸŸè‡ªé€‚åº”æŒ‡æ ‡ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå¤§å‹æ¨¡å‹é©±åŠ¨çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Œç”Ÿæˆå…·æœ‰å¤šæ ·æ€§å’Œä¸°å¯Œä¸ªæ€§çš„è™šæ‹Ÿç”¨æˆ·ï¼Œæä¾›å—æ§ä½†çœŸå®çš„æµ‹è¯•ç¯å¢ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€è¯„ä¼°æ–¹æ³•ï¼Œé€‚åº”ä»»åŠ¡å˜åŒ–ï¼Œç»“åˆè‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°ï¼Œæµ‹é‡ä»»åŠ¡æ‰§è¡Œå‡†ç¡®æ€§ã€ä¸“ä¸šçŸ¥è¯†åº”ç”¨ã€é€‚åº”æ€§å’Œç”¨æˆ·ä½“éªŒè´¨é‡ã€‚å¯¹12æ¬¾æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„å®éªŒæ­ç¤ºäº†ä¸“ä¸šä»»åŠ¡å®Œæˆå’Œäº¤äº’æµç•…æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºæ„å»ºå¯é ã€äººæ€§åŒ–çš„å¤–å‘¼AIç³»ç»Ÿæä¾›äº†å®é™…è§è§£ã€‚OutboundEvalä¸ºä¸“ä¸šåº”ç”¨ä¸­å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°å»ºç«‹äº†ä¸€ä¸ªå®ç”¨ã€å¯æ‰©å±•å’Œé¢å‘é¢†åŸŸçš„æ ‡å‡†ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>OutboundEvalæ˜¯ä¸€ä¸ªé’ˆå¯¹æ™ºèƒ½å¤–å‘¼åœºæ™¯çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»¼åˆè¯„ä¼°åŸºå‡†ã€‚</li>
<li>å®ƒè§£å†³äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„ä¸è¶³ï¼ŒåŒ…æ‹¬æ•°æ®é›†å¤šæ ·æ€§ã€ç”¨æˆ·æ¨¡æ‹ŸçœŸå®æ€§å’Œè¯„ä¼°æŒ‡æ ‡å‡†ç¡®æ€§é—®é¢˜ã€‚</li>
<li>åŸºå‡†æµ‹è¯•æ¶µç›–å…­å¤§ä¸šåŠ¡åŸŸå’Œå¤šä¸ªå­åœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯éƒ½æœ‰ç‰¹å®šçš„è¿‡ç¨‹åˆ†è§£å’Œè¯„ä¼°æŒ‡æ ‡ã€‚</li>
<li>ç”¨æˆ·æ¨¡æ‹Ÿå™¨èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”å¯Œæœ‰ä¸ªæ€§çš„è™šæ‹Ÿç”¨æˆ·ï¼Œæä¾›çœŸå®çš„æµ‹è¯•ç¯å¢ƒã€‚</li>
<li>å¼•å…¥çš„åŠ¨æ€è¯„ä¼°æ–¹æ³•é€‚åº”ä»»åŠ¡å˜åŒ–ï¼Œç»“åˆè‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°ï¼Œå…¨é¢è¡¡é‡è¯­è¨€æ¨¡å‹çš„è¡¨ç°ã€‚</li>
<li>å®éªŒæ­ç¤ºäº†ä¸“ä¸šä»»åŠ¡å®Œæˆå’Œäº¤äº’æµç•…æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºæ„å»ºå¤–å‘¼AIç³»ç»Ÿæä¾›äº†å®é™…è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.21244">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-60e363c3a6b6b8135de9f1fbc48577b1" align="middle">
<img src="https://picx.zhimg.com/v2-f90833ae7fa66bc39475212f7b86f4bf" align="middle">
<img src="https://picx.zhimg.com/v2-d888d31caefb304f160dae39005acea1" align="middle">
<img src="https://picx.zhimg.com/v2-81839c4b990bfad8df911cc417218e5d" align="middle">
<img src="https://picx.zhimg.com/v2-940a5d419d100bb858048ea191a31cbd" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-18/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-18/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-18/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cc8d205fccf95de88f012f3a344007e3" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-18  HI-TransPA Hearing Impairments Translation Personal Assistant
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-18/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-897d803ec990f59bb3cc02d9c3e21d42" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-18  Human-AI collaborative autonomous synthesis with pulsed laser deposition for remote epitaxy
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33297.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
