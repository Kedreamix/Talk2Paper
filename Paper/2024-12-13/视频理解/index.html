<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="视频理解">
    <meta name="description" content="视频理解 方向最新论文已更新，请持续关注 Update in 2024-12-13  Neptune The Long Orbit to Benchmarking Long Video Understanding">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>视频理解 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-c9cec5c7dca2f54b544632ac7328bb7a.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">视频理解</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                <span class="chip bg-color">视频理解</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                视频理解
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    4.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    16 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-13-更新"><a href="#2024-12-13-更新" class="headerlink" title="2024-12-13 更新"></a>2024-12-13 更新</h1><h2 id="Neptune-The-Long-Orbit-to-Benchmarking-Long-Video-Understanding"><a href="#Neptune-The-Long-Orbit-to-Benchmarking-Long-Video-Understanding" class="headerlink" title="Neptune: The Long Orbit to Benchmarking Long Video Understanding"></a>Neptune: The Long Orbit to Benchmarking Long Video Understanding</h2><p><strong>Authors:Arsha Nagrani, Mingda Zhang, Ramin Mehran, Rachel Hornung, Nitesh Bharadwaj Gundavarapu, Nilpa Jha, Austin Myers, Xingyi Zhou, Boqing Gong, Cordelia Schmid, Mikhail Sirotenko, Yukun Zhu, Tobias Weyand</strong></p>
<p>This paper describes a semi-automatic pipeline to generate challenging question-answer-decoy sets for understanding long videos. Many existing video datasets and models are focused on short clips (10s-30s). While some long video datasets do exist, they can often be solved by powerful image models applied per frame (and often to very few frames) in a video, and are usually manually annotated at high cost. In order to mitigate both these problems, we propose a scalable dataset creation pipeline which leverages large models (VLMs and LLMs), to automatically generate dense, time-aligned video captions, as well as tough question answer decoy sets for video segments (up to 15 minutes in length). Our dataset Neptune covers a broad range of long video reasoning abilities and consists of a subset that emphasizes multimodal reasoning. Since existing metrics for open-ended question answering are either rule-based or may rely on proprietary models, we provide a new open source model-based metric GEM to score open-ended responses on Neptune. Benchmark evaluations reveal that most current open-source long video models perform poorly on Neptune, particularly on questions testing temporal ordering, counting and state changes. Through Neptune, we aim to spur the development of more advanced models capable of understanding long videos. The dataset is available at <a target="_blank" rel="noopener" href="https://github.com/google-deepmind/neptune">https://github.com/google-deepmind/neptune</a> </p>
<blockquote>
<p>本文介绍了一种半自动流程，用于生成用于理解长视频的具有挑战性的问答干扰选项集。许多现有的视频数据集和模型都专注于短视频片段（10秒至30秒）。虽然也有一些长视频数据集存在，但它们通常可以通过应用于视频的每一帧（并且经常是很少的帧）的强大图像模型来解决，并且通常以高昂的成本进行手动标注。为了解决这两个问题，我们提出了一种可扩展的数据集创建流程，该流程利用大型模型（视觉语言模型和大型语言模型），自动生成密集、时间对齐的视频字幕，以及针对视频片段（长达15分钟）的难以回答的问题答案干扰选项集。我们的数据集Neptune涵盖了广泛的长期视频理解能力，其中包括强调多媒体理解的子集。由于现有的开放问答答题指标要么是规则基础的，要么可能依赖于专有模型，因此我们提供了一个新的开源模型指标GEM来对Neptune上的开放答案进行评分。基准评估表明，大多数当前的开源长视频模型在Neptune上的表现较差，特别是在测试时间顺序、计数和状态更改的问题方面。通过Neptune，我们的目标是促进更先进模型的发展，使其能够理解长视频。数据集可在<a target="_blank" rel="noopener" href="https://github.com/google-deepmind/neptune%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/google-deepmind/neptune找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.09582v1">PDF</a> </p>
<p><strong>Summary</strong>：本文提出了一种半自动创建问答数据集的管道方法，用于生成理解长视频的挑战性问题集。文章强调了对长视频理解的必要性和现有数据集的不足，通过提出利用大型模型和自动化生成视频描述的方式解决了手动标注的高成本问题。此外，还介绍了一种新的开放源代码模型度量标准GEM，用于评估长视频问题回答的质量。数据集Neptune旨在推动长视频理解模型的发展。</p>
<p><strong>Key Takeaways</strong>：</p>
<ul>
<li>提出了一种半自动创建问答数据集的管道方法，旨在解决手动标注的高成本问题。</li>
<li>强调了现有视频数据集在处理长视频方面的局限性，如持续时间短、过于依赖图像模型等。</li>
<li>利用大型模型和自动化生成时间对齐的视频描述以及针对长视频的问答数据。</li>
<li>新推出的数据集Neptune包含了强调多种模式推理的子集。</li>
<li>为长视频问答评估引入了新的开放源代码模型度量标准GEM。</li>
<li>基准评估显示大多数现有模型在Neptune上的表现不佳，特别是在测试时间顺序、计数和状态变化方面的能力方面有待提高。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/">Cool Papers</a></strong> </p>
<details>
  <summary>点击展开 Cool Papers 详细信息</summary>
  <p class="faq-q"><strong>Q</strong>: 这篇论文试图解决什么问题？</p>
<p class="faq-a"><strong>A</strong>: 这篇论文试图解决的问题是如何为长视频理解任务生成具有挑战性的问题-答案-诱饵集（QADs）。具体来说，论文中提到了以下几个关键问题：

<ol>
<li><p><strong>长视频理解数据集的局限性</strong>：许多现有的视频数据集和模型都集中在短视频片段（10-30秒）上。虽然有一些长视频数据集存在，但它们通常可以通过强大的图像模型逐帧（甚至只处理视频中的少数几帧）应用来解决，并且这些数据集通常需要高昂的手动注释成本。</p>
</li>
<li><p><strong>长视频理解的挑战</strong>：创建一个真正的长视频理解数据集需要大量的手动工作来选择、观看、理解和注释长视频，这些工作不仅成本高，而且难以保持一致性和多样性。</p>
</li>
<li><p><strong>现有评估指标的不足</strong>：对于开放式问题回答，现有的评估指标要么基于规则，要么依赖于专有模型，这些指标可能无法准确衡量模型在长视频理解任务上的性能。</p>
</li>
</ol>
<p>为了解决这些问题，论文提出了一个半自动的数据集创建流程，该流程利用大型视觉语言模型（VLMs）和大型语言模型（LLMs）自动生成密集的、时间对齐的视频字幕，并从中自动派生出针对视频片段（最长可达15分钟）的困难QADs。此外，论文还提供了一个新的开源模型基评估指标（GEM），用于在Neptune数据集上评估开放式回答。通过这种方式，论文旨在推动更先进的长视频理解模型的发展。</p></p>
<p class="faq-q"><strong>Q</strong>: 有哪些相关研究？</p>
<p class="faq-a"><strong>A</strong>: 根据论文内容，相关研究主要涉及以下几个领域：

<ol>
<li><p><strong>视频问答（VideoQA）</strong>：</p>
<ul>
<li>早期的视频和语言模型，如Flamingo、BLIP2、Video-Llama、GIT2和PALI等，这些模型通常包含强大的视觉和语言编码器&#x2F;解码器。</li>
<li>Socratic风格的模型，结合了各种专门的冻结模型与精心提示的最新VLMs和LLMs，例如MoreVQA。</li>
<li>端到端的大型多模态模型，如Gemini和GPT-4，这些模型具有长上下文长度，能够处理包括视频、声音和文本在内的多模态数据。</li>
</ul>
</li>
<li><p><strong>视频QA基准测试</strong>：</p>
<ul>
<li>推动评估时间相关问题、长视频以及多样化领域（如指导性和自我中心视频）的关键数据集。</li>
<li>总结现有的VideoQA基准测试，大多数数据集要么关注短视频（少于100秒），要么是可以仅用几帧解决的短视视频数据集。</li>
</ul>
</li>
<li><p><strong>开放式视频QA的评估指标</strong>：</p>
<ul>
<li>早期QA数据集的评估指标，如BLEU、ROUGE和CIDEr等，这些指标主要测量n-gram重叠，并不完全捕捉任务的主观性。</li>
<li>其他指标包括SPICE（添加动作和对象关系），以及基于模型的指标，如BERT-Score、BERT-Score++、LEIC、NUBIA、TIGEr、CLIPScore和EMScore等。</li>
<li>特定于答案等价性的指标，如BEM，它在答案等价性数据集上微调BERT，显示出更好的QA评分。</li>
</ul>
</li>
<li><p><strong>长视频理解的数据集创建</strong>：</p>
<ul>
<li>EgoSchema，它通过提示LLMs生成，但覆盖的领域有限，依赖于现有注释，而Neptune覆盖更广泛的视频类型，其流程适用于任意视频。</li>
<li>其他通过提示LLMs生成的数据集，如ActivityNet-RTL、CinePile等。</li>
</ul>
</li>
</ol>
<p>这些相关研究为长视频理解领域的模型开发、数据集创建和评估指标提供了基础和对比。论文通过提出新的数据集Neptune和评估指标GEM，旨在进一步推动这一领域的研究进展。</p></p>
<p class="faq-q"><strong>Q</strong>: 论文如何解决这个问题？</p>
<p class="faq-a"><strong>A</strong>: 论文通过以下几个步骤解决长视频理解的问题：

<ol>
<li><p><strong>提出半自动数据集创建流程</strong>：</p>
<ul>
<li>利用大型视觉语言模型（VLMs）和大型语言模型（LLMs）自动生成密集的、时间对齐的视频字幕。</li>
<li>从这些字幕中自动派生出针对视频片段的问题-答案-诱饵（QAD）集。</li>
</ul>
</li>
<li><p><strong>视频选择和信号提取</strong>：</p>
<ul>
<li>从YT-Temporal-1Bn数据集中选择视频，并减少“谈话头”视频，以捕获更有趣的场景、对象和动作。</li>
<li>提取帧字幕、自动语音识别（ASR）、元数据和每个视频的镜头边界等信号。</li>
</ul>
</li>
<li><p><strong>自动视频字幕生成</strong>：</p>
<ul>
<li>将提取的信号（帧字幕、ASR、标题和描述、镜头边界）自动组合，通过多阶段过程创建视频级字幕。</li>
</ul>
</li>
<li><p><strong>QAD生成</strong>：</p>
<ul>
<li>通过定制的提示将视频字幕输入到LLMs中，自动生成问题、答案和诱饵。</li>
<li>采用两阶段方法：首先生成问题和答案，然后基于前一阶段的问题和答案生成六个诱饵。</li>
</ul>
</li>
<li><p><strong>基于LLM的盲过滤QAD</strong>：</p>
<ul>
<li>使用LLM对答案候选进行排名，以去除可以通过常识或外部世界知识回答的问题。</li>
</ul>
</li>
<li><p><strong>手动评分者验证</strong>：</p>
<ul>
<li>通过人工审核确保质量，评分者根据四个标准评估问题的质量，并标注所需模态。</li>
<li>评分者接受或修改答案，并从LLM生成的诱饵候选中选择最具挑战性的四个。</li>
</ul>
</li>
<li><p><strong>提供新的评估指标GEM</strong>：</p>
<ul>
<li>为了评估开放式问题回答，论文提出了一个新的开源模型基评估指标GEM（Gemma Equivalence Metric）。</li>
</ul>
</li>
<li><p><strong>基准测试</strong>：</p>
<ul>
<li>对现有的视频模型进行基准测试，揭示了开源视频模型和专有模型（如Gemini-1.5和GPT-4）之间的性能差距。</li>
</ul>
</li>
</ol>
<p>通过这些步骤，论文旨在创建一个能够评估长视频理解能力的可扩展数据集，并推动更先进的长视频理解模型的发展。此外，通过开源GEM评估指标，论文为学术界提供了一个可复用的、不受专有模型限制的评估工具。</p></p>
<p class="faq-q"><strong>Q</strong>: 论文做了哪些实验？</p>
<p class="faq-a"><strong>A</strong>: 根据论文内容，作者进行了以下实验：

<ol>
<li><p><strong>Neptune数据集的创建和评估</strong>：</p>
<ul>
<li>作者首先介绍了他们创建的Neptune数据集，并提供了两种评估协议：多项选择评估和开放式评估。</li>
</ul>
</li>
<li><p><strong>GEM（Gemma Equivalence Metric）的创建和评估</strong>：</p>
<ul>
<li>为了解决开放式问题回答的评估问题，作者手动构建了一个标记的开发集，并在这个集合上评估了多种基于规则和基于模型的指标。</li>
<li>他们比较了传统的指标（如CIDEr和ROUGE-L）和基于模型的指标（如BERT-Score和BEM）。</li>
<li>作者还微调了Gemma模型在BEM答案等价性数据集上，并提出了新的评估指标GEM。</li>
</ul>
</li>
<li><p><strong>基准测试</strong>：</p>
<ul>
<li>作者对多种视频问答模型进行了基准测试，包括盲基线测试（只使用文本提示）、图像模型（如BLIP2）、短上下文MLLMs（如Video-LLaVA和VideoLLaMA2）、长上下文MLLMs（包括开源和闭源模型，如MA-LMM、MiniGPT4-Video、Gemini 1.5-pro和GPT-4o）。</li>
<li>他们评估了这些模型在Neptune数据集上的性能，并进行了模态消融研究，比较了仅使用ASR、仅使用视频帧和同时使用两者的性能。</li>
</ul>
</li>
<li><p><strong>Neptune-MMH子集的评估</strong>：</p>
<ul>
<li>作者创建了Neptune-MMH子集，该子集包含视觉模态重要的问题，并评估了模型在这个更具挑战性的子集上的性能。</li>
</ul>
</li>
<li><p><strong>与人类提出的问题（HPQ）的比较</strong>：</p>
<ul>
<li>为了测试自动数据管道的有效性和效率，作者让评分者完全手动地为数据集中的一个子集提出问题和答案（称为HPQ），并与自动生成的问题进行比较。</li>
</ul>
</li>
<li><p><strong>不同问题类型的性能分析</strong>：</p>
<ul>
<li>作者分析了不同模型在Neptune数据集中不同问题类型（如时间排序、计数、状态变化等）上的性能，并指出了未来的研究方向。</li>
</ul>
</li>
</ol>
<p>这些实验旨在全面评估Neptune数据集的有效性，提出的GEM评估指标的性能，以及当前视频理解模型在长视频问答任务上的能力和局限性。通过这些实验，作者展示了Neptune作为一个评估长视频理解能力的基准测试的价值，并揭示了现有模型的不足。</p></p>
<p class="faq-q"><strong>Q</strong>: 有什么可以进一步探索的点？</p>
<p class="faq-a"><strong>A</strong>: 根据论文内容和实验结果，以下是一些可以进一步探索的点：

<ol>
<li><p><strong>改进视频选择和信号提取</strong>：</p>
<ul>
<li>研究更先进的视频选择算法，以从YouTube等平台中识别出更丰富、更具代表性的视频内容。</li>
<li>探索更多种类的视频信号提取技术，例如场景理解、物体检测和情绪分析，以增强视频字幕和QAD生成的上下文信息。</li>
</ul>
</li>
<li><p><strong>增强视频字幕生成</strong>：</p>
<ul>
<li>研究如何结合更复杂的自然语言处理技术，以生成更准确和详细的视频字幕。</li>
<li>考虑引入额外的上下文信息，比如视频的元数据、用户评论和相关文本，以提高字幕生成的质量。</li>
</ul>
</li>
<li><p><strong>优化QAD生成算法</strong>：</p>
<ul>
<li>探索不同的提示工程（prompt engineering）技术，以生成更多样化和更具挑战性的QADs。</li>
<li>研究如何利用强化学习或其他自动化方法来进一步减少人工审核的需求。</li>
</ul>
</li>
<li><p><strong>评估指标的改进</strong>：</p>
<ul>
<li>继续优化GEM评估指标，使其能够更准确地衡量模型在开放式问题回答任务上的性能。</li>
<li>探索结合人类评估和自动评估的混合评估方法，以提高评估的可靠性和效率。</li>
</ul>
</li>
<li><p><strong>长视频理解模型的开发</strong>：</p>
<ul>
<li>开发能够处理更长视频上下文和更复杂推理任务的新型视频语言模型。</li>
<li>研究如何将现有的长视频理解模型迁移到新的领域和数据集上，并评估其泛化能力。</li>
</ul>
</li>
<li><p><strong>减少模型偏见和提高数据集多样性</strong>：</p>
<ul>
<li>分析Neptune数据集中潜在的偏见，并探索减少这些偏见的方法。</li>
<li>增强数据集的多样性，包括视频类型、语言和文化背景，以提高模型的包容性和适用性。</li>
</ul>
</li>
<li><p><strong>跨模态学习</strong>：</p>
<ul>
<li>研究如何更有效地整合视觉、音频和文本信息，以提高模型的跨模态理解能力。</li>
<li>探索新的神经网络架构和学习算法，以增强模型对多模态数据的融合和推理能力。</li>
</ul>
</li>
<li><p><strong>实时视频理解和交互</strong>：</p>
<ul>
<li>研究如何使视频理解模型适用于实时视频流，并支持实时交互和问答。</li>
<li>探索视频理解技术在实际应用中的潜力，如监控、教育和娱乐。</li>
</ul>
</li>
</ol>
<p>这些探索点可以帮助推动长视频理解领域的研究进展，并为开发更先进的视频问答系统提供新的思路和方法。</p></p>
<p class="faq-q"><strong>Q</strong>: 总结一下论文的主要内容</p>
<p class="faq-a"><strong>A</strong>: 本文介绍了一个名为Neptune的长视频理解基准测试，旨在通过一个半自动流程生成具有挑战性的问题-答案-诱饵集（QADs），以推动长视频理解技术的发展。以下是论文的主要内容总结：

<ol>
<li><p><strong>问题陈述</strong>：</p>
<ul>
<li>许多现有的视频数据集和模型专注于短视频片段，而长视频数据集要么依赖于图像模型，要么手动注释成本高。</li>
</ul>
</li>
<li><p><strong>Neptune数据集</strong>：</p>
<ul>
<li>提出了一个可扩展的数据集创建流程，利用大型视觉语言模型（VLMs）和大型语言模型（LLMs）自动生成视频字幕和QADs。</li>
<li>数据集包含3,268个QAD注释，涵盖2,405个视频，视频长度从16秒到15分钟不等。</li>
</ul>
</li>
<li><p><strong>数据集创建流程</strong>：</p>
<ul>
<li>包括视频选择、信号提取、视频字幕生成、QAD生成、基于LLM的盲过滤和手动评分者验证等阶段。</li>
</ul>
</li>
<li><p><strong>评估指标</strong>：</p>
<ul>
<li>由于现有的开放式问题回答评估指标存在局限性，论文提出了一个新的开源模型基评估指标GEM（Gemma Equivalence Metric）。</li>
</ul>
</li>
<li><p><strong>实验与基准测试</strong>：</p>
<ul>
<li>对多种视频问答模型进行了评估，包括盲基线、图像模型、短上下文MLLMs和长上下文MLLMs。</li>
<li>揭示了开源视频模型与专有模型（如Gemini-1.5和GPT-4）之间的性能差距。</li>
</ul>
</li>
<li><p><strong>主要贡献</strong>：</p>
<ul>
<li>提出了一个可扩展的流程，用于为任何视频生成复杂的QAD注释，相比手动注释减少了一半的评分者时间。</li>
<li>发布了Neptune评估数据集，包括一个强调多模态推理的挑战性子集NEPTUNE-MMH。</li>
<li>提供了多项选择和开放式问题回答的评估协议，并提出了GEM这一新的开放式评估指标。</li>
<li>通过基准测试展示了当前开源长视频模型在Neptune上的性能，并指出了未来发展的方向。</li>
</ul>
</li>
<li><p><strong>未来工作</strong>：</p>
<ul>
<li>论文指出了长视频理解领域的一些潜在研究方向，包括改进视频选择和信号提取、优化QAD生成算法、开发新的评估指标和提高模型的长视频理解能力。</li>
</ul>
</li>
</ol>
<p>总体而言，Neptune基准测试旨在通过提供新的数据集和评估指标，推动长视频理解技术的研究和模型开发。</p></p>
<p class="faq-q"><strong>Q</strong>: 想要进一步了解论文</p>
<p class="faq-a"><strong>A</strong>: 以上只是了解一篇论文的几个基本FAQ。如果你还想与Kimi进一步讨论该论文，请点击 <a href="http://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neptune: The Long Orbit to Benchmarking Long Video Understanding，链接是 https://arxiv.org/pdf/2412.09582 ，已有的FAQ链接是 https://papers.cool/arxiv/kimi?paper=2412.09582 。请以此为基础，继续回答我后面的问题。&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false" target="_blank"><strong>这里 <i class="fa fa-external-link"></i></strong></a> 为你跳转Kimi AI网页版，并启动一个与该论文相关的新会话。</p>

</details>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ebc242d555a9567ea1c361c0a78bbbd5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-edfd7fe2c1061b9e344ff9c6798fada2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c9cec5c7dca2f54b544632ac7328bb7a.jpg" align="middle">
</details>




                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-13/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-13/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                    <span class="chip bg-color">视频理解</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-13/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-77c9aa05596185246575faf54c7a484d.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer 方向最新论文已更新，请持续关注 Update in 2024-12-13  Vision Transformers for Efficient Indoor Pathloss Radio Map Prediction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-13/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5972f7c429e18b5bc08972dacdc2e53c.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2024-12-13  Go With the Flow Fast Diffusion for Gaussian Mixture Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">7390.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
