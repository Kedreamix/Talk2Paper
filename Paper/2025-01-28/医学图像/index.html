<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-28  Gland Segmentation Using SAM With Cancer Grade as a Prompt">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4f8fe84793976935f9568dbf9989bde1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    52 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-28-æ›´æ–°"><a href="#2025-01-28-æ›´æ–°" class="headerlink" title="2025-01-28 æ›´æ–°"></a>2025-01-28 æ›´æ–°</h1><h2 id="Gland-Segmentation-Using-SAM-With-Cancer-Grade-as-a-Prompt"><a href="#Gland-Segmentation-Using-SAM-With-Cancer-Grade-as-a-Prompt" class="headerlink" title="Gland Segmentation Using SAM With Cancer Grade as a Prompt"></a>Gland Segmentation Using SAM With Cancer Grade as a Prompt</h2><p><strong>Authors:Yijie Zhu, Shan E Ahmed Raza</strong></p>
<p>Cancer grade is a critical clinical criterion that can be used to determine the degree of cancer malignancy. Revealing the condition of the glands, a precise gland segmentation can assist in a more effective cancer grade classification. In machine learning, binary classification information about glands (i.e., benign and malignant) can be utilized as a prompt for gland segmentation and cancer grade classification. By incorporating prior knowledge of the benign or malignant classification of the gland, the model can anticipate the likely appearance of the target, leading to better segmentation performance. We utilize Segment Anything Model to solve the segmentation task, by taking advantage of its prompt function and applying appropriate modifications to the model structure and training strategies. We improve the results from fine-tuned Segment Anything Model and produce SOTA results using this approach. </p>
<blockquote>
<p>ç™Œç—‡åˆ†çº§æ˜¯ä¸€ä¸ªé‡è¦çš„ä¸´åºŠæ ‡å‡†ï¼Œå¯ä»¥ç”¨æ¥ç¡®å®šç™Œç—‡çš„æ¶æ€§ç¨‹åº¦ã€‚ç²¾ç¡®çš„è…ºä½“åˆ†å‰²å¯ä»¥æ­ç¤ºè…ºä½“çš„çŠ¶å†µï¼Œä»è€Œæœ‰åŠ©äºæ›´æœ‰æ•ˆåœ°è¿›è¡Œç™Œç—‡åˆ†çº§åˆ†ç±»ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå…³äºè…ºä½“ï¼ˆå³è‰¯æ€§å’Œæ¶æ€§ï¼‰çš„äºŒå…ƒåˆ†ç±»ä¿¡æ¯å¯ä»¥ä½œä¸ºè…ºä½“åˆ†å‰²å’Œç™Œç—‡åˆ†çº§åˆ†ç±»çš„æç¤ºã€‚é€šè¿‡ç»“åˆè…ºä½“è‰¯æ€§æˆ–æ¶æ€§åˆ†ç±»çš„å…ˆéªŒçŸ¥è¯†ï¼Œæ¨¡å‹å¯ä»¥é¢„æµ‹ç›®æ ‡çš„å¯èƒ½å¤–è§‚ï¼Œä»è€Œæé«˜åˆ†å‰²æ€§èƒ½ã€‚æˆ‘ä»¬åˆ©ç”¨Segment Anything Modelæ¥è§£å†³åˆ†å‰²ä»»åŠ¡ï¼Œé€šè¿‡åˆ©ç”¨å…¶æç¤ºåŠŸèƒ½å¹¶å¯¹æ¨¡å‹ç»“æ„å’Œè®­ç»ƒç­–ç•¥è¿›è¡Œé€‚å½“çš„ä¿®æ”¹ã€‚æˆ‘ä»¬é€šè¿‡å¯¹Segment Anything Modelè¿›è¡Œå¾®è°ƒï¼Œæ”¹è¿›äº†ç»“æœï¼Œå¹¶ä½¿ç”¨è¿™ç§æ–¹æ³•å–å¾—äº†æœ€æ–°ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14718v1">PDF</a> Accepted by ISBI 2025</p>
<p><strong>Summary</strong></p>
<p>ç™Œç—‡åˆ†çº§æ˜¯è¯„ä¼°ç™Œç—‡æ¶æ€§ç¨‹åº¦çš„é‡è¦ä¸´åºŠæ ‡å‡†ã€‚ç²¾ç¡®çš„è…ºä½“åˆ†å‰²å¯ä»¥æ­ç¤ºè…ºä½“çŠ¶å†µï¼Œè¿›è€Œæ›´ç²¾å‡†åœ°è¿›è¡Œç™Œç—‡åˆ†çº§ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œåˆ©ç”¨è…ºä½“ï¼ˆè‰¯æ€§æˆ–æ¶æ€§ï¼‰çš„äºŒå…ƒåˆ†ç±»ä¿¡æ¯ï¼Œå¯ä½œä¸ºè…ºä½“åˆ†å‰²å’Œç™Œç—‡åˆ†çº§åˆ†ç±»çš„æç¤ºã€‚ç»“åˆè…ºä½“è‰¯æ€§æˆ–æ¶æ€§çš„å…ˆéªŒçŸ¥è¯†ï¼Œæ¨¡å‹å¯ä»¥é¢„æµ‹ç›®æ ‡çš„å¯èƒ½å‡ºç°æƒ…å†µï¼Œä»è€Œæé«˜åˆ†å‰²æ€§èƒ½ã€‚æˆ‘ä»¬åˆ©ç”¨Segment Anything Modelå®Œæˆåˆ†å‰²ä»»åŠ¡ï¼Œé€šè¿‡è°ƒæ•´æ¨¡å‹ç»“æ„å’Œè®­ç»ƒç­–ç•¥ï¼Œæ”¹è¿›äº†fine-tuned Segment Anything Modelçš„ç»“æœï¼Œå¹¶è·å¾—äº†å…ˆè¿›çš„æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç™Œç—‡åˆ†çº§æ˜¯è¯„ä¼°ç™Œç—‡æ¶æ€§ç¨‹åº¦çš„å…³é”®ä¸´åºŠæ ‡å‡†ã€‚</li>
<li>ç²¾ç¡®çš„è…ºä½“åˆ†å‰²æœ‰åŠ©äºæ›´å‡†ç¡®çš„ç™Œç—‡åˆ†çº§ã€‚</li>
<li>æœºå™¨å­¦ä¹ ä¸­å¯åˆ©ç”¨è…ºä½“çš„äºŒå…ƒåˆ†ç±»ä¿¡æ¯è¿›è¡Œç™Œç—‡åˆ†çº§ã€‚</li>
<li>ç»“åˆè…ºä½“çš„è‰¯æ€§æˆ–æ¶æ€§å…ˆéªŒçŸ¥è¯†å¯æé«˜æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>ä½¿ç”¨Segment Anything Modelè¿›è¡Œè…ºä½“åˆ†å‰²ï¼Œæ”¹è¿›äº†fine-tunedæ¨¡å‹çš„ç»“æœã€‚</li>
<li>é€‚å½“è°ƒæ•´æ¨¡å‹ç»“æ„å’Œè®­ç»ƒç­–ç•¥å¯æé«˜åˆ†å‰²æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14718">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6b0e25d88889f05e01a44ed4b679474b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4f8fe84793976935f9568dbf9989bde1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76c01138f1531b40042b0dc18fc65234.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b7af297c1f31fa84e9966d029647a94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-796a623938e334fe6aaf9d47e0339179.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Ambient-pressure-growth-of-bilayer-nickelate-single-crystals-with-superconductivity-over-90-K-under-high-pressure"><a href="#Ambient-pressure-growth-of-bilayer-nickelate-single-crystals-with-superconductivity-over-90-K-under-high-pressure" class="headerlink" title="Ambient pressure growth of bilayer nickelate single crystals with   superconductivity over 90 K under high pressure"></a>Ambient pressure growth of bilayer nickelate single crystals with   superconductivity over 90 K under high pressure</h2><p><strong>Authors:Feiyu Li, Di Peng, Jie Dou, Ning Guo, Liang Ma, Chao Liu, Lingzhen Wang, Yulin Zhang, Jun Luo, Jie Yang, Jian Zhang, Weizhao Cai, Jinguang Cheng, Qiang Zheng, Rui Zhou, Qiaoshi Zeng, Xutang Tao, Junjie Zhang</strong></p>
<p>Recently, the Ruddlesden-Popper bilayer nickelate La3Ni2O7 has been discovered as a high temperature superconductor with Tc near 80 K above 14 GPa.[1-3] The search for nickelate superconductors with higher Tc, the preparation of high-quality single crystals, and the removal of high-pressure conditions including single crystal growth under high gas pressure and achievement of high Tc superconductivity under high pressure, are the most challenging tasks. Here, we present ambient pressure flux growth of high-quality bilayer nickelate single crystals with superconductivity up to 91 K under high pressure. Single crystals of bilayer La3-xRxNi2O7-y with dimensions up to 220 um on the edge were successfully grown using flux method at atmosphere conditions. Single crystal X-ray diffraction, nuclear quadrupole resonance, energy dispersion spectroscopy and scanning transmission electron microscopy measurements evidenced high quality of bilayer La2SmNi2O7-y single crystals in average structure and local structure. Superconductivity has been observed in high pressure resistivity measurements of annealed La2SmNi2O7-y single crystals with Tc onset up to 91 K, which is the highest among the known superconducting nickelates. Our results not only demonstrate a new and easy-to-access method for synthesizing high-quality bilayer nickelate single crystals, but also providing a direction for discovering superconducting nickelates with higher Tc. </p>
<blockquote>
<p>æœ€è¿‘ï¼ŒRuddlesden-PopperåŒå±‚é•é…¸ç›La3Ni2O7è¢«å‘ç°æ˜¯ä¸€ç§é«˜æ¸©è¶…å¯¼ä½“ï¼Œåœ¨é«˜äº14 GPaçš„æ¡ä»¶ä¸‹ï¼Œå…¶å±…é‡Œæ¸©åº¦ï¼ˆTcï¼‰æ¥è¿‘80 K^[1-3]^ã€‚å¯»æ‰¾å…·æœ‰æ›´é«˜å±…é‡Œæ¸©åº¦çš„é•é…¸ç›è¶…å¯¼ä½“ã€åˆ¶å¤‡é«˜è´¨é‡å•æ™¶ä»¥åŠæ¶ˆé™¤é«˜å‹æ¡ä»¶ï¼ˆåŒ…æ‹¬é«˜å‹æ°”ä½“ç¯å¢ƒä¸‹çš„å•æ™¶ç”Ÿé•¿ä»¥åŠé«˜å‹ä¸‹å®ç°é«˜å±…é‡Œæ¸©åº¦è¶…å¯¼æ€§ï¼‰æ˜¯æœ€å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨ç¯å¢ƒå‹åŠ›ä¸‹é€šè¿‡åŠ©ç†”å‰‚æ³•ç”Ÿé•¿é«˜è´¨é‡åŒå±‚é•é…¸ç›å•æ™¶çš„æ–¹æ³•ï¼Œè¿™äº›å•æ™¶åœ¨é«˜å‹ä¸‹è¡¨ç°å‡ºé«˜è¾¾91 Kçš„è¶…å¯¼æ€§ã€‚åœ¨å¸¸å‹æ¡ä»¶ä¸‹ï¼Œæˆ‘ä»¬æˆåŠŸä½¿ç”¨åŠ©ç†”å‰‚æ³•ç”Ÿé•¿äº†è¾¹ç¼˜å°ºå¯¸é«˜è¾¾220å¾®ç±³åŒå±‚La3-xRxNi2O7-yå•æ™¶ã€‚é€šè¿‡å•æ™¶Xå°„çº¿è¡å°„ã€æ ¸å››æå…±æŒ¯ã€èƒ½é‡è‰²æ•£å…‰è°±å’Œæ‰«æé€å°„ç”µå­æ˜¾å¾®é•œæµ‹é‡ï¼Œè¯æ˜äº†La2SmNi2O7-yåŒå±‚å•æ™¶çš„å¹³å‡ç»“æ„å’Œå±€éƒ¨ç»“æ„çš„é«˜å“è´¨ã€‚æˆ‘ä»¬å¯¹é€€ç«åçš„La2SmNi2O7-yå•æ™¶è¿›è¡Œäº†é«˜å‹ç”µé˜»ç‡æµ‹é‡ï¼Œè§‚å¯Ÿåˆ°å…¶è¶…å¯¼æ€§ï¼Œèµ·å§‹å±…é‡Œæ¸©åº¦é«˜è¾¾91 Kï¼Œè¿™æ˜¯å·²çŸ¥è¶…å¯¼é•é…¸ç›ä¸­æœ€é«˜çš„ä¸€ç§ã€‚æˆ‘ä»¬çš„ç»“æœä¸ä»…å±•ç¤ºäº†ä¸€ç§åˆæˆé«˜è´¨é‡åŒå±‚é•é…¸ç›å•æ™¶çš„æ–°æ–¹æ³•ï¼Œä¹Ÿä¸ºå‘ç°å…·æœ‰æ›´é«˜å±…é‡Œæ¸©åº¦çš„é•é…¸ç›è¶…å¯¼ä½“æä¾›äº†æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14584v1">PDF</a> 4 figures and 1 table</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æŠ¥é“äº†é‡‡ç”¨å¤§æ°”å‹æµä½“ç”Ÿé•¿æ³•æˆåŠŸåˆæˆé«˜è´¨é‡åŒå±‚é•é…¸ç›å•æ™¶La3-xRxNi2O7-yï¼Œå¹¶åœ¨é«˜å‹ç”µé˜»ç‡æµ‹é‡ä¸­è§‚å¯Ÿåˆ°é«˜è¾¾91Kçš„è¶…å¯¼æ€§ã€‚è¿™ä¸ä»…å±•ç¤ºäº†åˆæˆé«˜è´¨é‡åŒå±‚é•é…¸ç›å•æ™¶çš„æ–°æ–¹æ³•ï¼Œè€Œä¸”ä¸ºå‘ç°å…·æœ‰æ›´é«˜ä¸´ç•Œæ¸©åº¦çš„è¶…å¯¼é•é…¸ç›æä¾›äº†æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>La3Ni2O7è¢«å‘ç°æ˜¯ä¸€ç§é«˜æ¸©è¶…å¯¼ä½“ï¼Œä¸´ç•Œæ¸©åº¦ï¼ˆTcï¼‰åœ¨é«˜å‹ä¸‹æ¥è¿‘80Kã€‚</li>
<li>ç ”ç©¶äººå‘˜æˆåŠŸåœ°åœ¨å¸¸å‹ä¸‹ä½¿ç”¨æµä½“ç”Ÿé•¿æ³•åˆæˆé«˜è´¨é‡çš„åŒå±‚é•é…¸ç›å•æ™¶La3-xRxNi2O7-yï¼Œå°ºå¯¸å¯è¾¾220å¾®ç±³ã€‚</li>
<li>é€šè¿‡Xå°„çº¿è¡å°„ã€æ ¸ç£å…±æŒ¯ã€èƒ½é‡è‰²æ•£å…‰è°±å’Œæ‰«æé€å°„ç”µå­æ˜¾å¾®é•œç­‰æŠ€æœ¯è¯å®äº†è¿™äº›å•æ™¶çš„é«˜å“è´¨ã€‚</li>
<li>åœ¨é€€ç«åçš„La2SmNi2O7-yå•æ™¶ä¸­è§‚å¯Ÿåˆ°é«˜è¾¾91Kçš„è¶…å¯¼æ€§ï¼Œè¿™æ˜¯å·²çŸ¥è¶…å¯¼é•é…¸ç›ä¸­çš„æœ€é«˜å€¼ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ä»…æ˜“äºè®¿é—®ï¼Œè€Œä¸”ä¸ºåˆæˆé«˜è´¨é‡åŒå±‚é•é…¸ç›å•æ™¶æä¾›äº†æ–°çš„é€”å¾„ã€‚</li>
<li>æ­¤é¡¹ç ”ç©¶ä¸ºå‘ç°å…·æœ‰æ›´é«˜ä¸´ç•Œæ¸©åº¦çš„è¶…å¯¼é•é…¸ç›æä¾›äº†æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14584">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b585d73c1cdd83910326d32db9fed092.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Large-scale-and-Fine-grained-Vision-language-Pre-training-for-Enhanced-CT-Image-Understanding"><a href="#Large-scale-and-Fine-grained-Vision-language-Pre-training-for-Enhanced-CT-Image-Understanding" class="headerlink" title="Large-scale and Fine-grained Vision-language Pre-training for Enhanced   CT Image Understanding"></a>Large-scale and Fine-grained Vision-language Pre-training for Enhanced   CT Image Understanding</h2><p><strong>Authors:Zhongyi Shui, Jianpeng Zhang, Weiwei Cao, Sinuo Wang, Ruizhe Guo, Le Lu, Lin Yang, Xianghua Ye, Tingbo Liang, Qi Zhang, Ling Zhang</strong></p>
<p>Artificial intelligence (AI) shows great potential in assisting radiologists to improve the efficiency and accuracy of medical image interpretation and diagnosis. However, a versatile AI model requires large-scale data and comprehensive annotations, which are often impractical in medical settings. Recent studies leverage radiology reports as a naturally high-quality supervision for medical images, using contrastive language-image pre-training (CLIP) to develop language-informed models for radiological image interpretation. Nonetheless, these approaches typically contrast entire images with reports, neglecting the local associations between imaging regions and report sentences, which may undermine model performance and interoperability. In this paper, we propose a fine-grained vision-language model (fVLM) for anatomy-level CT image interpretation. Specifically, we explicitly match anatomical regions of CT images with corresponding descriptions in radiology reports and perform contrastive pre-training for each anatomy individually. Fine-grained alignment, however, faces considerable false-negative challenges, mainly from the abundance of anatomy-level healthy samples and similarly diseased abnormalities. To tackle this issue, we propose identifying false negatives of both normal and abnormal samples and calibrating contrastive learning from patient-level to disease-aware pairing. We curated the largest CT dataset to date, comprising imaging and report data from 69,086 patients, and conducted a comprehensive evaluation of 54 major and important disease diagnosis tasks across 15 main anatomies. Experimental results demonstrate the substantial potential of fVLM in versatile medical image interpretation. In the zero-shot classification task, we achieved an average AUC of 81.3% on 54 diagnosis tasks, surpassing CLIP and supervised methods by 12.9% and 8.0%, respectively. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨ååŠ©æ”¾å°„ç§‘åŒ»ç”Ÿæé«˜åŒ»å­¦å›¾åƒè§£è¯»å’Œè¯Šæ–­çš„æ•ˆç‡ä¸å‡†ç¡®æ€§æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œä¸€ä¸ªå¤šæ‰å¤šè‰ºçš„AIæ¨¡å‹éœ€è¦å¤§è§„æ¨¡çš„æ•°æ®å’Œå…¨é¢çš„æ³¨é‡Šï¼Œè¿™åœ¨åŒ»ç–—ç¯å¢ƒä¸­å¾€å¾€ä¸åˆ‡å®é™…ã€‚æœ€è¿‘çš„ç ”ç©¶åˆ©ç”¨æ”¾å°„å­¦æŠ¥å‘Šä½œä¸ºåŒ»å­¦å›¾åƒçš„è‡ªç„¶é«˜è´¨é‡ç›‘ç£ï¼Œä½¿ç”¨å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰å¼€å‘ç”¨äºæ”¾å°„å­¦å›¾åƒè§£è¯»çš„è¯­è¨€ä¿¡æ¯æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å°†æ•´ä¸ªå›¾åƒä¸æŠ¥å‘Šè¿›è¡Œå¯¹æ¯”ï¼Œå¿½ç•¥äº†æˆåƒåŒºåŸŸä¸æŠ¥å‘Šå¥å­ä¹‹é—´çš„å±€éƒ¨å…³è”ï¼Œè¿™å¯èƒ½ä¼šæŸå®³æ¨¡å‹çš„æ€§èƒ½å’Œå¯äº’æ“ä½œæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºè§£å‰–å­¦å±‚é¢CTå›¾åƒè§£è¯»çš„ç²¾ç»†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆfVLMï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ˜¾å¼åœ°å°†CTå›¾åƒçš„è§£å‰–åŒºåŸŸä¸æ”¾å°„å­¦æŠ¥å‘Šä¸­çš„ç›¸åº”æè¿°ç›¸åŒ¹é…ï¼Œå¹¶å¯¹æ¯ä¸ªè§£å‰–ç»“æ„è¿›è¡Œå¯¹æ¯”é¢„è®­ç»ƒã€‚ç„¶è€Œï¼Œç²¾ç»†å¯¹é½é¢ä¸´ç€ç›¸å½“å¤§çš„å‡é˜´æ€§æŒ‘æˆ˜ï¼Œä¸»è¦æ¥è‡ªè§£å‰–å±‚é¢å¥åº·æ ·æœ¬çš„ä¸°å¯Œä»¥åŠç±»ä¼¼çš„ç–¾ç—…å¼‚å¸¸ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è¯†åˆ«æ­£å¸¸å’Œå¼‚å¸¸æ ·æœ¬çš„å‡é˜´æ€§ï¼Œå¹¶ä»æ‚£è€…å±‚é¢æ ¡å‡†å¯¹æ¯”å­¦ä¹ ä»¥è¯†åˆ«ç–¾ç—…æ„ŸçŸ¥é…å¯¹ã€‚æˆ‘ä»¬æ•´ç†äº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„CTæ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ª69,086åæ‚£è€…çš„æˆåƒå’ŒæŠ¥å‘Šæ•°æ®ï¼Œå¹¶å¯¹æ¶‰åŠ15ä¸ªä¸»è¦è§£å‰–ç»“æ„çš„54ä¸ªä¸»è¦å’Œé‡è¦ç–¾ç—…è¯Šæ–­ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜fVLMåœ¨å¤šç§åŒ»å­¦å›¾åƒè§£è¯»ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚åœ¨é›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬åœ¨54é¡¹è¯Šæ–­ä»»åŠ¡ä¸Šå®ç°äº†å¹³å‡AUCä¸º81.3%ï¼Œæ¯”CLIPå’Œç›‘ç£æ–¹æ³•åˆ†åˆ«é«˜å‡º12.9%å’Œ8.0%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14548v1">PDF</a> Accepted by ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦å›¾åƒè§£è¯»å’Œè¯Šæ–­ä¸­çš„è¾…åŠ©æ½œåŠ›ã€‚é’ˆå¯¹å½“å‰æ–¹æ³•åœ¨åŒ»ç–—ç¯å¢ƒä¸­å¤§è§„æ¨¡æ•°æ®å’Œå…¨é¢æ³¨é‡Šçš„éœ€æ±‚ï¼Œç ”ç©¶åˆ©ç”¨æ”¾å°„å­¦æŠ¥å‘Šä½œä¸ºé«˜è´¨é‡åŒ»å­¦å›¾åƒç›‘ç£çš„è‡ªç„¶æ¥æºï¼Œå¹¶é‡‡ç”¨å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¥å¼€å‘ç”¨äºæ”¾å°„å­¦å›¾åƒè§£è¯»çš„è¯­è¨€è¾…åŠ©æ¨¡å‹ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§ç²¾ç»†çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆfVLMï¼‰ï¼Œç”¨äºè§£å‰–çº§åˆ«çš„CTå›¾åƒè§£è¯»ã€‚é€šè¿‡æ˜ç¡®åŒ¹é…CTå›¾åƒçš„è§£å‰–åŒºåŸŸä¸æ”¾å°„å­¦æŠ¥å‘Šä¸­çš„ç›¸åº”æè¿°ï¼Œå¹¶å¯¹æ¯ä¸ªè§£å‰–éƒ¨ä½è¿›è¡Œä¸ªåˆ«å¯¹æ¯”é¢„è®­ç»ƒã€‚ä¸ºè§£å†³ç²¾ç»†å¯¹é½ä¸­çš„å‡é˜´æ€§æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºè¯†åˆ«æ­£å¸¸å’Œå¼‚å¸¸æ ·æœ¬çš„å‡é˜´æ€§ï¼Œå¹¶ä»æ‚£è€…çº§åˆ«æ ¡å‡†å¯¹æ¯”å­¦ä¹ è‡³ç–¾ç—…æ„ŸçŸ¥é…å¯¹ã€‚ç ”ç©¶ä½¿ç”¨äº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„CTæ•°æ®é›†ï¼Œæ¶µç›–äº†æ¥è‡ª69,086åæ‚£è€…çš„æˆåƒå’ŒæŠ¥å‘Šæ•°æ®ï¼Œå¹¶å¯¹æ¶‰åŠäº”å¤§è§£å‰–å­¦é¢†åŸŸçš„äº”å¤§é‡è¦ç–¾ç—…è¯Šæ–­ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºfVLMåœ¨å¤šæ ·åŒ»å­¦å›¾åƒè§£è¯»ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡å¹³å‡AUCè¾¾81.3%ï¼Œè¾ƒCLIPå’Œç›‘ç£æ–¹æ³•åˆ†åˆ«é«˜å‡º12.9%å’Œ8.0%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIåœ¨åŒ»å­¦å›¾åƒè§£è¯»å’Œè¯Šæ–­ä¸­å…·æœ‰è¾…åŠ©æ½œåŠ›ï¼Œå¯æé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>å½“å‰æ–¹æ³•éœ€è¦å¤§é‡æ•°æ®å’Œæ³¨é‡Šï¼Œè¿™åœ¨åŒ»ç–—ç¯å¢ƒä¸­ä¸å®é™…ã€‚</li>
<li>ç ”ç©¶åˆ©ç”¨æ”¾å°„å­¦æŠ¥å‘Šä½œä¸ºé«˜è´¨é‡åŒ»å­¦å›¾åƒç›‘ç£çš„è‡ªç„¶æ¥æºã€‚</li>
<li>é‡‡ç”¨å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰å¼€å‘è¯­è¨€è¾…åŠ©æ¨¡å‹ç”¨äºåŒ»å­¦å›¾åƒè§£è¯»ã€‚</li>
<li>æå‡ºç²¾ç»†çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆfVLMï¼‰ç”¨äºè§£å‰–çº§åˆ«çš„CTå›¾åƒè§£è¯»ã€‚</li>
<li>fVLMé€šè¿‡æ˜ç¡®åŒ¹é…CTå›¾åƒçš„è§£å‰–åŒºåŸŸä¸æŠ¥å‘Šæè¿°è¿›è¡Œå¯¹æ­£è®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14548">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ebedba3899fc6cb6ce6529e125ae5a53.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cde11c13d6cb691877c54a377f7bbb1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ee784c4d6ef04848611f9a294a38127.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4cc40dad5f4c82844de8deab8956fb95.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ECTIL-Label-efficient-Computational-Tumour-Infiltrating-Lymphocyte-TIL-assessment-in-breast-cancer-Multicentre-validation-in-2-340-patients-with-breast-cancer"><a href="#ECTIL-Label-efficient-Computational-Tumour-Infiltrating-Lymphocyte-TIL-assessment-in-breast-cancer-Multicentre-validation-in-2-340-patients-with-breast-cancer" class="headerlink" title="ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte   (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients   with breast cancer"></a>ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte   (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients   with breast cancer</h2><p><strong>Authors:Yoni Schirris, Rosie Voorthuis, Mark Opdam, Marte Liefaard, Gabe S Sonke, Gwen Dackus, Vincent de Jong, Yuwei Wang, Annelot Van Rossum, Tessa G Steenbruggen, Lars C Steggink, Liesbeth G. E. de Vries, Marc van de Vijver, Roberto Salgado, Efstratios Gavves, Paul J van Diest, Sabine C Linn, Jonas Teuwen, Renee Menezes, Marleen Kok, Hugo Horlings</strong></p>
<p>The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor for patients with (triple-negative) breast cancer (BC). Computational TIL assessment (CTA) has the potential to assist pathologists in this labour-intensive task, but current CTA models rely heavily on many detailed annotations. We propose and validate a fundamentally simpler deep learning based CTA that can be trained in only ten minutes on hundredfold fewer pathologist annotations. We collected whole slide images (WSIs) with TILs scores and clinical data of 2,340 patients with BC from six cohorts including three randomised clinical trials. Morphological features were extracted from whole slide images (WSIs) using a pathology foundation model. Our label-efficient Computational stromal TIL assessment model (ECTIL) directly regresses the TILs score from these features. ECTIL trained on only a few hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five heterogeneous external cohorts (r&#x3D;0.54-0.74, AUROC&#x3D;0.80-0.94). Training on all slides of five cohorts (ECTIL-combined) improved results on a held-out test set (r&#x3D;0.69, AUROC&#x3D;0.85). Multivariable Cox regression analyses indicated that every 10% increase of ECTIL scores was associated with improved overall survival independent of clinicopathological variables (HR 0.86, p&lt;0.01), similar to the pathologist score (HR 0.87, p&lt;0.001). We demonstrate that ECTIL is highly concordant with an expert pathologist and obtains a similar hazard ratio. ECTIL has a fundamentally simpler design than existing methods and can be trained on orders of magnitude fewer annotations. Such a CTA may be used to pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a tool to assist clinicians in the diagnostic work-up of patients with BC. Our model is available under an open source licence (<a target="_blank" rel="noopener" href="https://github.com/nki-ai/ectil">https://github.com/nki-ai/ectil</a>). </p>
<blockquote>
<p>è‚¿ç˜¤æµ¸æ¶¦æ·‹å·´ç»†èƒï¼ˆTILsï¼‰çš„æ°´å¹³æ˜¯ï¼ˆä¸‰é˜´æ€§ï¼‰ä¹³è…ºç™Œï¼ˆBCï¼‰æ‚£è€…çš„é¢„åå› ç´ ã€‚è®¡ç®—TILè¯„ä¼°ï¼ˆCTAï¼‰æœ‰æ½œåŠ›å¸®åŠ©ç—…ç†å­¦å®¶å®Œæˆè¿™é¡¹åŠ³åŠ¨å¯†é›†å‹ä»»åŠ¡ï¼Œä½†å½“å‰çš„CTAæ¨¡å‹ä¸¥é‡ä¾èµ–äºè®¸å¤šè¯¦ç»†çš„æ³¨é‡Šã€‚æˆ‘ä»¬æå‡ºå¹¶éªŒè¯äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ ¹æœ¬æ›´ç®€å•çš„CTAï¼Œåœ¨æ•°ç™¾å€æ›´å°‘çš„ç—…ç†å­¦å®¶æ³¨é‡Šä¸Šåªéœ€ååˆ†é’Ÿå³å¯å®Œæˆè®­ç»ƒã€‚æˆ‘ä»¬æ”¶é›†äº†æ¥è‡ªå…­ä¸ªé˜Ÿåˆ—çš„2340åä¹³è…ºç™Œæ‚£è€…çš„å…¨ç‰‡å›¾åƒï¼ˆWSIsï¼‰å’ŒTILsè¯„åˆ†åŠä¸´åºŠæ•°æ®ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸‰é¡¹éšæœºä¸´åºŠè¯•éªŒã€‚å½¢æ€å­¦ç‰¹å¾æ˜¯ä»å…¨ç‰‡å›¾åƒï¼ˆWSIsï¼‰ä¸­æå–å‡ºæ¥çš„ï¼Œä½¿ç”¨çš„æ˜¯ç—…ç†åŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ ‡ç­¾æ•ˆç‡è®¡ç®—æ€§é—´è´¨TILè¯„ä¼°æ¨¡å‹ï¼ˆECTILï¼‰ç›´æ¥ä»è¿™äº›ç‰¹å¾ä¸­å›å½’TILsè¯„åˆ†ã€‚ECTILä»…åœ¨æ•°ç™¾ä¸ªæ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆECTIL-TCGAï¼‰å°±èƒ½ä¸ç—…ç†å­¦å®¶åœ¨äº”ç»„ä¸åŒå¤–éƒ¨é˜Ÿåˆ—ä¸­çš„ç»“æœä¸€è‡´ï¼ˆr&#x3D;0.54-0.74ï¼ŒAUROC&#x3D;0.80-0.94ï¼‰ã€‚åœ¨äº”ä¸ªé˜Ÿåˆ—çš„æ‰€æœ‰å¹»ç¯ç‰‡ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆECTIL-combinedï¼‰æé«˜äº†åœ¨ä¿ç•™æµ‹è¯•é›†ä¸Šçš„ç»“æœï¼ˆr&#x3D;0.69ï¼ŒAUROC&#x3D;0.85ï¼‰ã€‚å¤šå…ƒCoxå›å½’åˆ†ææ˜¾ç¤ºï¼ŒECTILè¯„åˆ†æ¯å¢åŠ 10%ï¼Œæ€»ä½“ç”Ÿå­˜ç‡å°±ä¼šæé«˜ï¼Œè¿™ä¸ç—…ç†å­¦å®¶è¯„åˆ†ç›¸ä¼¼ï¼Œä¸”ç‹¬ç«‹äºä¸´åºŠç—…ç†å˜é‡ï¼ˆHR 0.86ï¼Œp&lt;0.01ï¼‰ã€‚æˆ‘ä»¬è¯æ˜ECTILä¸ä¸“å®¶ç—…ç†å­¦å®¶é«˜åº¦ä¸€è‡´ï¼Œå¹¶ä¸”è·å¾—ç±»ä¼¼çš„å±é™©æ¯”ç‡ã€‚ECTILçš„æ ¹æœ¬è®¾è®¡æ¯”ç°æœ‰æ–¹æ³•æ›´ç®€å•ï¼Œå¯ä»¥åœ¨æ•°é‡çº§æ›´å°‘çš„æ³¨é‡Šä¸Šè¿›è¡Œè®­ç»ƒã€‚è¿™ç§CTAå¯ç”¨äºå¯¹ä¾‹å¦‚å…ç–«ç–—æ³•ä¸´åºŠè¯•éªŒçš„å…¥é€‰æ‚£è€…è¿›è¡Œé¢„ç­›é€‰ï¼Œæˆ–ä½œä¸ºååŠ©ä¸´åºŠåŒ»ç”Ÿå¯¹ä¹³è…ºç™Œæ‚£è€…è¿›è¡Œè¯Šæ–­å·¥ä½œçš„å·¥å…·ã€‚æˆ‘ä»¬çš„æ¨¡å‹å¯åœ¨å¼€æºè®¸å¯è¯ä¸‹ä½¿ç”¨ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/nki-ai/ectil%EF%BC%89%E3%80%82">https://github.com/nki-ai/ectilï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14379v1">PDF</a> Under review. 54 pages including supplementary materials, 2 main   tables, 3 main figures, 14 supplementary figures, 4 supplementary tables</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†è‚¿ç˜¤æµ¸æ¶¦æ·‹å·´ç»†èƒï¼ˆTILsï¼‰æ°´å¹³åœ¨é¢„æµ‹ä¸‰é˜´æ€§ä¹³è…ºç™Œæ‚£è€…é¢„åä¸­çš„ä½œç”¨ã€‚æå‡ºå¹¶éªŒè¯äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„è®¡ç®—è‚¿ç˜¤æµ¸æ¶¦æ·‹å·´ç»†èƒè¯„ä¼°ï¼ˆCTAï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ›´ä¸ºç®€å•ï¼Œä»…éœ€ååˆ†ä¹‹ä¸€çš„ç—…ç†å­¦å®¶æ ‡æ³¨å³å¯è®­ç»ƒå®Œæˆã€‚ç ”ç©¶ä½¿ç”¨åŒ…å«ä¸‰é˜´æ€§ä¹³è…ºç™Œæ‚£è€…çš„2,340å¼ å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIsï¼‰å’Œä¸´åºŠæ•°æ®ï¼Œå»ºç«‹äº†ä¸€ç§æ ‡ç­¾æ•ˆç‡é«˜çš„è®¡ç®—æ€§é—´è´¨è‚¿ç˜¤æµ¸æ¶¦æ·‹å·´ç»†èƒè¯„ä¼°æ¨¡å‹ï¼ˆECTILï¼‰ã€‚è¯¥æ¨¡å‹ç›´æ¥ä»å½¢æ€ç‰¹å¾å›å½’TILsè¯„åˆ†ï¼Œä»…å¯¹æ•°ç™¾ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒå³å¯ä¸ç—…ç†å­¦å®¶è¾¾åˆ°ä¸€è‡´ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜è¡¨æ˜ï¼ŒECTILè¯„åˆ†æ¯å¢åŠ 10%ï¼Œæ‚£è€…çš„æ€»ä½“ç”Ÿå­˜ç‡å°±ä¼šæé«˜ï¼Œä¸ä¸´åºŠç—…ç†å˜é‡æ— å…³ã€‚æ€»ä½“è€Œè¨€ï¼ŒECTILä¸ç—…ç†å­¦å®¶è¯„ä¼°ç»“æœé«˜åº¦ä¸€è‡´ï¼Œä¸”æ¨¡å‹è®¾è®¡æ›´ç®€å•ï¼Œæ‰€éœ€æ ‡æ³¨æ•°æ®æ›´å°‘ã€‚è¿™ç§CTAå¯ç”¨äºç­›é€‰é€‚åˆå…ç–«æ²»ç–—ä¸´åºŠè¯•éªŒçš„æ‚£è€…ï¼Œæˆ–ä½œä¸ºè¯Šæ–­ä¹³è…ºç™Œæ‚£è€…çš„å·¥å…·ã€‚æ¨¡å‹å¯åœ¨å¼€æ”¾æºä»£ç è®¸å¯è¯ä¸‹è·å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‚¿ç˜¤æµ¸æ¶¦æ·‹å·´ç»†èƒï¼ˆTILsï¼‰æ°´å¹³æ˜¯ä¸‰é˜´æ€§ä¹³è…ºç™Œçš„é‡è¦é¢„åå› ç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„ç®€åŒ–è®¡ç®—è‚¿ç˜¤æµ¸æ¶¦æ·‹å·´ç»†èƒè¯„ä¼°ï¼ˆCTAï¼‰æ¨¡å‹ï¼ˆECTILï¼‰ã€‚</li>
<li>ECTILæ¨¡å‹å¯åœ¨ä»…ä½¿ç”¨å°‘æ•°ç—…ç†å­¦å®¶æ ‡æ³¨çš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒï¼Œå¤§å¤§æé«˜äº†æ ‡ç­¾æ•ˆç‡ã€‚</li>
<li>ECTILæ¨¡å‹çš„é¢„æµ‹ç»“æœä¸ç—…ç†å­¦å®¶é«˜åº¦ä¸€è‡´ï¼Œå¹¶åœ¨å¤šä¸ªå¤–éƒ¨é˜Ÿåˆ—ä¸­è¿›è¡Œäº†éªŒè¯ã€‚</li>
<li>ECTILè¯„åˆ†ä¸æ‚£è€…çš„æ€»ä½“ç”Ÿå­˜ç‡å‘ˆæ­£ç›¸å…³ã€‚</li>
<li>ECTILæ¨¡å‹å¯ç”¨äºç­›é€‰é€‚åˆå…ç–«æ²»ç–—ä¸´åºŠè¯•éªŒçš„æ‚£è€…æˆ–è¾…åŠ©ä¸´åºŠåŒ»ç”Ÿè¯Šæ–­ä¹³è…ºç™Œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14379">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0ba16c3ecbcfff146b8d96b2dcadfdc.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BrainGuard-Privacy-Preserving-Multisubject-Image-Reconstructions-from-Brain-Activities"><a href="#BrainGuard-Privacy-Preserving-Multisubject-Image-Reconstructions-from-Brain-Activities" class="headerlink" title="BrainGuard: Privacy-Preserving Multisubject Image Reconstructions from   Brain Activities"></a>BrainGuard: Privacy-Preserving Multisubject Image Reconstructions from   Brain Activities</h2><p><strong>Authors:Zhibo Tian, Ruijie Quan, Fan Ma, Kun Zhan, Yi Yang</strong></p>
<p>Reconstructing perceived images from human brain activity forms a crucial link between human and machine learning through Brain-Computer Interfaces. Early methods primarily focused on training separate models for each individual to account for individual variability in brain activity, overlooking valuable cross-subject commonalities. Recent advancements have explored multisubject methods, but these approaches face significant challenges, particularly in data privacy and effectively managing individual variability. To overcome these challenges, we introduce BrainGuard, a privacy-preserving collaborative training framework designed to enhance image reconstruction from multisubject fMRI data while safeguarding individual privacy. BrainGuard employs a collaborative global-local architecture where individual models are trained on each subjectâ€™s local data and operate in conjunction with a shared global model that captures and leverages cross-subject patterns. This architecture eliminates the need to aggregate fMRI data across subjects, thereby ensuring privacy preservation. To tackle the complexity of fMRI data, BrainGuard integrates a hybrid synchronization strategy, enabling individual models to dynamically incorporate parameters from the global model. By establishing a secure and collaborative training environment, BrainGuard not only protects sensitive brain data but also improves the image reconstructions accuracy. Extensive experiments demonstrate that BrainGuard sets a new benchmark in both high-level and low-level metrics, advancing the state-of-the-art in brain decoding through its innovative design. </p>
<blockquote>
<p>ä»äººç±»å¤§è„‘æ´»åŠ¨é‡å»ºæ„ŸçŸ¥å›¾åƒï¼Œæ˜¯è„‘æœºæ¥å£å®ç°äººç±»ä¸æœºå™¨å­¦ä¹ ä¹‹é—´è”ç³»çš„å…³é”®ç¯èŠ‚ã€‚æ—©æœŸçš„æ–¹æ³•ä¸»è¦å…³æ³¨äºé’ˆå¯¹æ¯ä¸ªä¸ªä½“è¿›è¡Œå•ç‹¬æ¨¡å‹çš„è®­ç»ƒï¼Œä»¥è§£é‡Šä¸ªä½“åœ¨å¤§è„‘æ´»åŠ¨ä¸Šçš„å·®å¼‚ï¼Œå¿½ç•¥äº†è·¨ä¸»ä½“çš„å…±æ€§ä»·å€¼ã€‚å°½ç®¡è¿‘æœŸçš„ç ”ç©¶å·²ç»æ¢ç´¢äº†è·¨ä¸»ä½“çš„æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®éšç§å’Œæœ‰æ•ˆç®¡ç†ä¸ªä½“å·®å¼‚æ–¹é¢ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†BrainGuardï¼Œè¿™æ˜¯ä¸€ä¸ªä¿æŠ¤éšç§çš„åä½œè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨æé«˜ä»å¤šä¸»ä½“fMRIæ•°æ®ä¸­é‡å»ºå›¾åƒçš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŠ¤ä¸ªäººéšç§ã€‚BrainGuardé‡‡ç”¨åä½œçš„å…¨å±€-å±€éƒ¨æ¶æ„ï¼Œå…¶ä¸­ä¸ªä½“æ¨¡å‹åœ¨æ¯ä¸ªä¸»ä½“çš„å±€éƒ¨æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸å…±äº«çš„å…¨å±€æ¨¡å‹ååŒå·¥ä½œï¼Œæ•è·å¹¶åˆ©ç”¨è·¨ä¸»ä½“çš„æ¨¡å¼ã€‚è¿™ç§æ¶æ„æ¶ˆé™¤äº†æ±‡æ€»å¤šä¸ªä¸»ä½“fMRIæ•°æ®çš„éœ€è¦ï¼Œä»è€Œç¡®ä¿äº†éšç§ä¿æŠ¤ã€‚ä¸ºäº†åº”å¯¹fMRIæ•°æ®çš„å¤æ‚æ€§ï¼ŒBrainGuardé›†æˆäº†ä¸€ç§æ··åˆåŒæ­¥ç­–ç•¥ï¼Œä½¿ä¸ªä½“æ¨¡å‹èƒ½å¤ŸåŠ¨æ€åœ°èå…¥å…¨å±€æ¨¡å‹çš„å‚æ•°ã€‚é€šè¿‡å»ºç«‹å®‰å…¨ã€åä½œçš„è®­ç»ƒç¯å¢ƒï¼ŒBrainGuardä¸ä»…ä¿æŠ¤äº†æ•æ„Ÿçš„è„‘æ•°æ®ï¼Œè€Œä¸”æé«˜äº†å›¾åƒé‡å»ºçš„å‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒBrainGuardåœ¨é«˜çº§å’Œä½çº§æŒ‡æ ‡ä¸Šå‡è®¾å®šäº†æ–°çš„åŸºå‡†ï¼Œé€šè¿‡å…¶åˆ›æ–°è®¾è®¡ï¼Œåœ¨è„‘è§£ç æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14309v1">PDF</a> AAAI 2025 oral</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†BrainGuardæ¡†æ¶åœ¨ä¿æŠ¤éšç§çš„åŒæ—¶æé«˜å¤šä¸»é¢˜fMRIæ•°æ®å›¾åƒé‡å»ºçš„å‡†ç¡®æ€§ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åä½œå…¨å±€-å±€éƒ¨æ¶æ„ï¼Œè®­ç»ƒä¸ªä½“æ¨¡å‹å¤„ç†æœ¬åœ°æ•°æ®ï¼Œå¹¶é€šè¿‡å…±äº«å…¨å±€æ¨¡å‹æ•æ‰å’Œåˆ©ç”¨è·¨ä¸»é¢˜æ¨¡å¼ï¼Œæ— éœ€èšåˆè·¨ä¸»é¢˜çš„fMRIæ•°æ®ï¼Œä»è€Œç¡®ä¿éšç§ä¿æŠ¤ã€‚BrainGuardé€šè¿‡æ··åˆåŒæ­¥ç­–ç•¥æé«˜fMRIæ•°æ®çš„å¤„ç†æ•ˆç‡ï¼Œæé«˜å›¾åƒé‡å»ºçš„å‡†ç¡®æ€§ï¼Œå¹¶ä¿æŠ¤æ•æ„Ÿçš„è„‘æ•°æ®ã€‚å®éªŒè¡¨æ˜ï¼ŒBrainGuardåœ¨è®¾è®¡åˆ›æ–°æ–¹é¢è¾¾åˆ°äº†é«˜æ°´å¹³æŒ‡æ ‡å’Œä½æ°´å¹³æŒ‡æ ‡çš„æœ€æ–°åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Brain-Computer Interfacesé‡å»ºäººè„‘æ„ŸçŸ¥å›¾åƒåœ¨æœºå™¨å­¦ä¹ é¢†åŸŸçš„é‡è¦æ€§ã€‚</li>
<li>æ—©æœŸæ–¹æ³•ä¸»è¦å…³æ³¨ä¸ºæ¯ä¸ªäººè®­ç»ƒå•ç‹¬çš„æ¨¡å‹ä»¥åº”å¯¹å¤§è„‘æ´»åŠ¨çš„ä¸ªä½“å·®å¼‚ï¼Œä½†å¿½ç•¥äº†è·¨ä¸»é¢˜çš„å…±æ€§ã€‚</li>
<li>BrainGuardæ¡†æ¶æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤çš„åˆä½œè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤šä¸»é¢˜fMRIæ•°æ®çš„å›¾åƒé‡å»ºç²¾åº¦ã€‚</li>
<li>BrainGuardé‡‡ç”¨åä½œå…¨å±€-å±€éƒ¨æ¶æ„ï¼Œé€šè¿‡ä¸ªä½“æ¨¡å‹å’Œå…¨å±€æ¨¡å‹çš„ç»“åˆæ¥å¤„ç†æ•°æ®éšç§å’Œä¸ªä½“å·®å¼‚æŒ‘æˆ˜ã€‚</li>
<li>BrainGuardæ¡†æ¶é›†æˆäº†æ··åˆåŒæ­¥ç­–ç•¥ï¼Œèƒ½å¤Ÿæé«˜fMRIæ•°æ®å¤„ç†æ•ˆç‡å¹¶æ”¹è¿›å›¾åƒé‡å»ºå‡†ç¡®æ€§ã€‚</li>
<li>BrainGuardé€šè¿‡åˆ›å»ºå®‰å…¨åˆä½œè®­ç»ƒç¯å¢ƒï¼Œæ—¢ä¿æŠ¤æ•æ„Ÿçš„å¤§è„‘æ•°æ®åˆæé«˜å›¾åƒé‡å»ºçš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14309">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5b6823281d2100ee242e144dbbe01867.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f7c04fad2d32e145be9ec095a0cbc84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e33cc825c1e43ef6b37386840f2b057e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c1528eb99b83fb2c599c276e8c7bbfb7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Additive-Manufacturing-Processes-Protocol-Prediction-by-Artificial-Intelligence-using-X-ray-Computed-Tomography-data"><a href="#Additive-Manufacturing-Processes-Protocol-Prediction-by-Artificial-Intelligence-using-X-ray-Computed-Tomography-data" class="headerlink" title="Additive Manufacturing Processes Protocol Prediction by Artificial   Intelligence using X-ray Computed Tomography data"></a>Additive Manufacturing Processes Protocol Prediction by Artificial   Intelligence using X-ray Computed Tomography data</h2><p><strong>Authors:Sunita Khod, Akshay Dvivedi, Mayank Goswami</strong></p>
<p>The quality of the part fabricated from the Additive Manufacturing (AM) process depends upon the process parameters used, and therefore, optimization is required for apt quality. A methodology is proposed to set these parameters non-iteratively without human intervention. It utilizes Artificial Intelligence (AI) to fully automate the process, with the capability to self-train any apt AI model by further assimilating the training data.This study includes three commercially available 3D printers for soft material printing based on the Material Extrusion (MEX) AM process. The samples are 3D printed for six different AM process parameters obtained by varying layer height and nozzle speed. The novelty part of the methodology is incorporating an AI-based image segmentation step in the decision-making stage that uses quality inspected training data from the Non-Destructive Testing (NDT) method. The performance of the trained AI model is compared with the two software tools based on the classical thresholding method. The AI-based Artificial Neural Network (ANN) model is trained from NDT-assessed and AI-segmented data to automate the selection of optimized process parameters. The AI-based model is 99.3 % accurate, while the best available commercial classical image method is 83.44 % accurate. The best value of overall R for training ANN is 0.82. The MEX process gives a 22.06 % porosity error relative to the design. The NDT-data trained two AI models integrated into a series pipeline for optimal process parameters are proposed and verified by classical optimization and mechanical testing methods. </p>
<blockquote>
<p>é€šè¿‡å¢æåˆ¶é€ ï¼ˆAMï¼‰å·¥è‰ºåˆ¶ä½œçš„é›¶ä»¶è´¨é‡å–å†³äºæ‰€ä½¿ç”¨çš„å·¥è‰ºå‚æ•°ï¼Œå› æ­¤éœ€è¦è¿›è¡Œä¼˜åŒ–ä»¥è¾¾åˆ°æ‰€éœ€çš„è´¨é‡ã€‚æå‡ºäº†ä¸€ç§éè¿­ä»£åœ°è®¾ç½®è¿™äº›å‚æ•°çš„æ–¹æ³•ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ¥å®Œå…¨è‡ªåŠ¨åŒ–æµç¨‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿé€šè¿‡è¿›ä¸€æ­¥åŒåŒ–è®­ç»ƒæ•°æ®æ¥è‡ªæˆ‘è®­ç»ƒä»»ä½•é€‚åˆçš„äººå·¥æ™ºèƒ½æ¨¡å‹ã€‚è¯¥ç ”ç©¶åŒ…æ‹¬ä¸‰ç§åŸºäºææ–™æŒ¤å‡ºï¼ˆMEXï¼‰AMå·¥è‰ºçš„å•†ç”¨3Dæ‰“å°è½¯ä»¶ï¼Œç”¨äºæ‰“å°è½¯ææ–™ã€‚æ ·æœ¬æ˜¯é€šè¿‡æ”¹å˜å±‚é«˜å’Œå–·å˜´é€Ÿåº¦è€Œè·å¾—çš„å…­ä¸ªä¸åŒçš„AMå·¥è‰ºå‚æ•°è¿›è¡Œ3Dæ‰“å°çš„ã€‚è¯¥æ–¹æ³•çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå†³ç­–é˜¶æ®µèå…¥äº†åŸºäºäººå·¥æ™ºèƒ½çš„å›¾åƒåˆ†å‰²æ­¥éª¤ï¼Œè¯¥æ­¥éª¤ä½¿ç”¨æ¥è‡ªæ— æŸæ£€æµ‹ï¼ˆNDTï¼‰æ–¹æ³•çš„è´¨æ£€è®­ç»ƒæ•°æ®ã€‚å°†è®­ç»ƒå¥½çš„AIæ¨¡å‹æ€§èƒ½ä¸åŸºäºç»å…¸é˜ˆå€¼æ–¹æ³•çš„ä¸¤ä¸ªè½¯ä»¶å·¥å…·è¿›è¡Œæ¯”è¾ƒã€‚åŸºäºAIçš„äººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰æ¨¡å‹é€šè¿‡NDTè¯„ä¼°å’ŒAIåˆ†å‰²æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»¥è‡ªåŠ¨é€‰æ‹©ä¼˜åŒ–çš„å·¥è‰ºå‚æ•°ã€‚åŸºäºAIçš„æ¨¡å‹çš„å‡†ç¡®åº¦ä¸º99.3%ï¼Œè€Œç°æœ‰æœ€ä½³å•†ä¸šç»å…¸å›¾åƒæ–¹æ³•çš„å‡†ç¡®åº¦ä¸º83.44%ã€‚è®­ç»ƒANNçš„æœ€ä½³æ•´ä½“Rå€¼ä¸º0.82ã€‚MEXå·¥è‰ºåœ¨è®¾è®¡åŸºç¡€ä¸Šå­˜åœ¨22.06%çš„å­”éš™ç‡è¯¯å·®ã€‚é€šè¿‡ç»å…¸ä¼˜åŒ–æ–¹æ³•å’Œæœºæ¢°æµ‹è¯•æ–¹æ³•å¯¹ç»è¿‡NDTæ•°æ®è®­ç»ƒçš„ä¸¤ä¸ªäººå·¥æ™ºèƒ½æ¨¡å‹è¿›è¡Œé›†æˆï¼Œç”¨äºä¼˜åŒ–å·¥è‰ºå‚æ•°çš„å»ºè®®å’ŒéªŒè¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14306v1">PDF</a> 21 pages, 21 figures, 5 tables</p>
<p><strong>æ‘˜è¦</strong><br>    å¢æåˆ¶é€ ï¼ˆAMï¼‰è¿‡ç¨‹ä¸­åˆ¶é€ çš„é›¶ä»¶è´¨é‡å–å†³äºæ‰€ä½¿ç”¨çš„å·¥è‰ºå‚æ•°ï¼Œå› æ­¤éœ€è¦è¿›è¡Œä¼˜åŒ–ä»¥è¾¾åˆ°é€‚å½“çš„è´¨é‡ã€‚æå‡ºäº†ä¸€ç§éè¿­ä»£è®¾ç½®è¿™äº›å‚æ•°çš„æ–¹æ³•ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚å®ƒåˆ©ç”¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ¥å®Œå…¨è‡ªåŠ¨åŒ–æµç¨‹ï¼Œå¹¶å…·æœ‰é€šè¿‡è¿›ä¸€æ­¥åŒåŒ–è®­ç»ƒæ•°æ®æ¥è‡ªæˆ‘è®­ç»ƒä»»ä½•é€‚å½“çš„äººå·¥æ™ºèƒ½æ¨¡å‹çš„èƒ½åŠ›ã€‚è¯¥ç ”ç©¶åŒ…æ‹¬ä¸‰ç§å•†ä¸šå¯ç”¨çš„åŸºäºææ–™æŒ¤å‡ºï¼ˆMEXï¼‰AMå·¥è‰ºçš„è½¯ææ–™3Dæ‰“å°æœºã€‚ä¸ºå…­ä¸ªä¸åŒçš„AMå·¥è‰ºå‚æ•°æ‰“å°æ ·å“ï¼Œé€šè¿‡æ”¹å˜å±‚é«˜å’Œå–·å˜´é€Ÿåº¦è·å¾—è¿™äº›å‚æ•°ã€‚è¯¥æ–¹æ³•çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå†³ç­–é˜¶æ®µèå…¥äº†åŸºäºAIçš„å›¾åƒåˆ†å‰²æ­¥éª¤ï¼Œä½¿ç”¨æ¥è‡ªæ— æŸæ£€æµ‹ï¼ˆNDTï¼‰æ–¹æ³•çš„è´¨é‡æ£€éªŒè®­ç»ƒæ•°æ®ã€‚å°†è®­ç»ƒæœ‰ç´ çš„äººå·¥æ™ºèƒ½æ¨¡å‹çš„æ€§èƒ½ä¸åŸºäºç»å…¸é˜ˆå€¼æ–¹æ³•çš„ä¸¤ä¸ªè½¯ä»¶å·¥å…·è¿›è¡Œæ¯”è¾ƒã€‚åŸºäºNDTè¯„ä¼°å’ŒAIåˆ†å‰²æ•°æ®è®­ç»ƒçš„ç¥ç»ç½‘ç»œï¼ˆANNï¼‰æ¨¡å‹è¢«è®­ç»ƒç”¨æ¥è‡ªåŠ¨é€‰æ‹©ä¼˜åŒ–çš„å·¥è‰ºå‚æ•°ã€‚AIæ¨¡å‹çš„å‡†ç¡®åº¦ä¸º99.3%ï¼Œè€Œç°æœ‰çš„æœ€ä½³å•†ä¸šç»å…¸å›¾åƒæ–¹æ³•çš„å‡†ç¡®åº¦ä¸º83.44%ã€‚è®­ç»ƒANNçš„æ•´ä½“æœ€ä½³Rå€¼ä¸º0.82ã€‚MEXå·¥è‰ºåœ¨è®¾è®¡ä¸Šäº§ç”Ÿ22.06%çš„å­”éš™ç‡è¯¯å·®ã€‚é€šè¿‡ç»å…¸ä¼˜åŒ–å’Œæœºæ¢°æµ‹è¯•æ–¹æ³•ï¼Œæå‡ºäº†ç”±NDTæ•°æ®è®­ç»ƒçš„ä¸¤ä¸ªäººå·¥æ™ºèƒ½æ¨¡å‹é›†æˆåˆ°ç³»åˆ—ç®¡é“ä¸­ä»¥è·å¾—æœ€ä½³å·¥è‰ºå‚æ•°çš„å»ºè®®ï¼Œå¹¶è¿›è¡Œäº†éªŒè¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¢æåˆ¶é€ è¿‡ç¨‹ä¸­é›¶ä»¶çš„è´¨é‡å–å†³äºå·¥è‰ºå‚æ•°çš„ä¼˜åŒ–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§éè¿­ä»£è®¾ç½®å·¥è‰ºå‚æ•°çš„æ–¹æ³•ï¼Œä½¿ç”¨äººå·¥æ™ºèƒ½å®Œå…¨è‡ªåŠ¨åŒ–æµç¨‹ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†åŸºäºAIçš„å›¾åƒåˆ†å‰²æ­¥éª¤ï¼Œä½¿ç”¨æ— æŸæ£€æµ‹ï¼ˆNDTï¼‰çš„è´¨é‡æ£€éªŒæ•°æ®ã€‚</li>
<li>AIæ¨¡å‹åœ¨è‡ªåŠ¨åŒ–é€‰æ‹©ä¼˜åŒ–å·¥è‰ºå‚æ•°æ–¹é¢è¡¨ç°å‡ºé«˜å‡†ç¡®æ€§ï¼ˆ99.3%ï¼‰ã€‚</li>
<li>ä¸ç°æœ‰å•†ä¸šç»å…¸å›¾åƒæ–¹æ³•ç›¸æ¯”ï¼ŒAIæ¨¡å‹å…·æœ‰æ›´é«˜çš„æ€§èƒ½ã€‚</li>
<li>MEXå·¥è‰ºåœ¨è®¾è®¡ä¸Šå­˜åœ¨ä¸€å®šçš„å­”éš™ç‡è¯¯å·®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cfd1c2425455c0c4aac4d13f6d9b66e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c4b47d12f38a80c639c1c6e17a65f11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6fa10ac9d2b77946d0377256d666239.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5716983438285b868015b930bdc6a75f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4d0e9180f50731c954832bd6f5b7d9a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4e2fa8f15d739f63d38079e2b793a78.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9545c82ffbee967862e41f485a9af4d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1df889b4df62de51a29b3a87281487a5.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Thermal-and-dimensional-stability-of-photocatalytic-material-ZnPS-3-under-extreme-environmental-conditions"><a href="#Thermal-and-dimensional-stability-of-photocatalytic-material-ZnPS-3-under-extreme-environmental-conditions" class="headerlink" title="Thermal and dimensional stability of photocatalytic material ZnPS$_3$   under extreme environmental conditions"></a>Thermal and dimensional stability of photocatalytic material ZnPS$_3$   under extreme environmental conditions</h2><p><strong>Authors:Abhishek Mukherjee, Vivian J. SantamarÃ­a-GarcÃ­a, Damian Wlodarczyk, Ajeesh K. Somakumar, Piotr Sybilski, Ryan Siebenaller, Emmanuel Rowe, Saranya Narayanan, Michael A. Susner, L. Marcelo Lozano-Sanchez, Andrzej Suchocki, Julio L. Palma, Svetlana V. Boriskina</strong></p>
<p>Zinc phosphorus trisulfide (ZnPS$_3$), a promising material for photocatalysis and energy storage, is shown in this study to exhibit remarkable stability under extreme conditions. We explore its optical and structural properties under high pressure and cryogenic temperatures using photoluminescence (PL) spectroscopy, Raman scattering, and density functional theory (DFT). Our results identify a pressure-induced phase transition starting at 6.75 GPa and stabilizing by 12.5 GPa, after which ZnPS$_3$ demonstrates robust stability across a broad pressure range of 15 to 100 GPa. DFT calculations predict a semiconductor-to-semimetal transition at 100 GPa, while PL measurements reveal defect-assisted emissions that quench under pressure due to enhanced non-radiative recombination. At cryogenic temperatures, PL quenching intensifies as non-radiative processes dominate, driven by a rising Gr&quot;uneisen parameter and reduced phonon population. Cryogenic X-ray diffraction (XRD) also reveals a high mean thermal expansion coefficient (TEC) of (4.369 $\pm$ 0.393) $\times$ 10$^{-5}$ K$^{-1}$, among the highest reported for 2D materials. This unique combination of tunable electronic properties under low pressure and high thermal sensitivity makes ZnPS$_3$ a strong candidate for sensing applications in extreme environments. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æ˜¾ç¤ºï¼Œä¸‰ç¡«åŒ–é”Œç£·ï¼ˆZnPS$_3$ï¼‰ä½œä¸ºå…‰å‚¬åŒ–ä¸èƒ½é‡å‚¨å­˜çš„æœ‰å‰æ™¯ææ–™ï¼Œåœ¨æç«¯æ¡ä»¶ä¸‹è¡¨ç°å‡ºæ˜¾è‘—çš„ç¨³å®šæ€§ã€‚æˆ‘ä»¬åˆ©ç”¨å…‰è‡´å‘å…‰ï¼ˆPLï¼‰å…‰è°±ã€æ‹‰æ›¼æ•£å°„å’Œå¯†åº¦æ³›å‡½ç†è®ºï¼ˆDFTï¼‰ç­‰æ–¹æ³•ï¼Œæ¢ç©¶å…¶é«˜å‹å’Œä½æ¸©æ¡ä»¶ä¸‹çš„å…‰å­¦å’Œç»“æ„ç‰¹æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œä»6.75 GPaå¼€å§‹å‘ç”Ÿå‹åŠ›è¯±å¯¼çš„ç›¸å˜ï¼Œå¹¶åœ¨è¾¾åˆ°12.5 GPaæ—¶ç¨³å®šä¸‹æ¥ã€‚æ­¤åï¼ŒZnPS$_3$åœ¨è¾ƒå®½çš„å‹å¼ºèŒƒå›´å†…è¡¨ç°å‡ºè¾ƒå¼ºçš„ç¨³å®šæ€§ï¼ˆæœ€é«˜è‡³å¸¸æ¸©æ—¶çš„æ°´å‹çš„æ•°åƒå€ï¼‰ã€‚DFTè®¡ç®—é¢„æµ‹åœ¨é«˜å‹ä¸‹ä¼šå‘ç”ŸåŠå¯¼ä½“åˆ°åŠé‡‘å±çš„è¿‡æ¸¡ï¼Œè€ŒPLæµ‹é‡æ˜¾ç¤ºç¼ºé™·è¾…åŠ©å‘å°„ï¼Œéšç€å‹åŠ›çš„å¢åŠ å› éè¾å°„å¤åˆå¢å¼ºè€ŒçŒç­ã€‚åœ¨ä½æ¸©ä¸‹ï¼Œç”±äºæ ¼é‡Œæ¶…æ£®å‚æ•°ä¸Šå‡å’ŒæŒ¯åŠ¨æ•°å‡å°‘ï¼Œéè¾å°„è¿‡ç¨‹å æ®ä¸»å¯¼åœ°ä½ï¼Œå¯¼è‡´PLçŒç­åŠ å‰§ã€‚ä½æ¸©Xå°„çº¿è¡å°„è¿˜æ­ç¤ºå…¶å¹³å‡çƒ­è†¨èƒ€ç³»æ•°ï¼ˆTECï¼‰è¾ƒé«˜ï¼Œä¸ºï¼ˆ4.369 $\pm$ 0.393ï¼‰Ã— 10$^{-5}$ K$^{-1}$ï¼Œåœ¨äºŒç»´ææ–™ä¸­æ˜¯æœ€é«˜çš„æŠ¥é“å€¼ä¹‹ä¸€ã€‚åœ¨å‹åŠ›è¾ƒå°çš„ç¯å¢ƒä¸­å¯è°ƒèŠ‚å…¶ç”µå­ç‰¹æ€§å’Œé«˜çƒ­æ•æ„Ÿæ€§ï¼Œè¿™ä½¿å¾—ZnPS$_3$æˆä¸ºåœ¨æç«¯ç¯å¢ƒä¸­ç”¨äºæ„Ÿåº”åº”ç”¨çš„å¼ºå¤§å€™é€‰ææ–™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14252v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬ç ”ç©¶å‘ç°é”Œç£·ç¡«åŒ–ç‰©ï¼ˆZnPS$_3$ï¼‰åœ¨æç«¯æ¡ä»¶ä¸‹è¡¨ç°å‡ºå“è¶Šç¨³å®šæ€§ï¼Œå¹¶æ¢ç´¢äº†å…¶é«˜å‹å’Œä½æ¸©ä¸‹çš„å…‰å­¦å’Œç»“æ„ç‰¹æ€§ã€‚é€šè¿‡å…‰è‡´å‘å…‰ï¼ˆPLï¼‰å…‰è°±å­¦ã€æ‹‰æ›¼æ•£å°„ã€å¯†åº¦æ³›å‡½ç†è®ºï¼ˆDFTï¼‰ç­‰ç ”ç©¶è¡¨æ˜ï¼ŒZnPS$_3$åœ¨é«˜å‹ä¸‹å‘ç”Ÿç›¸å˜ï¼Œå¹¶åœ¨ç‰¹å®šå‹åŠ›ä¸‹å±•ç°å‡ºç¨³å®šçš„åŠå¯¼ä½“è‡³åŠé‡‘å±è½¬å˜ã€‚æ­¤å¤–ï¼Œå…¶ç¼ºé™·è¾…åŠ©å‘å°„åœ¨é«˜å‹å’Œä½æ¸©ä¸‹å‘ç”Ÿéè¾å°„å¤åˆè€ŒçŒç­ã€‚å…¶é«˜çƒ­è†¨èƒ€ç³»æ•°ä½¿å…¶æˆä¸ºæç«¯ç¯å¢ƒæ„Ÿåº”åº”ç”¨çš„ä¼˜ç§€å€™é€‰ææ–™ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ZnPS$_3$åœ¨æç«¯æ¡ä»¶ä¸‹å±•ç°å‡ºå“è¶Šç¨³å®šæ€§ã€‚</li>
<li>é€šè¿‡PLå…‰è°±å­¦ã€æ‹‰æ›¼æ•£å°„å’ŒDFTç ”ç©¶äº†ZnPS$_3$çš„å…‰å­¦å’Œç»“æ„ç‰¹æ€§ã€‚</li>
<li>ZnPS$_3$åœ¨é«˜å‹ä¸‹å‘ç”Ÿç›¸å˜ï¼Œå¹¶åœ¨100 GPaæ—¶è¡¨ç°å‡ºåŠå¯¼ä½“è‡³åŠé‡‘å±çš„è½¬å˜ã€‚</li>
<li>PLæµ‹é‡æ­ç¤ºäº†ç¼ºé™·è¾…åŠ©å‘å°„ï¼Œè¿™äº›å‘å°„åœ¨é«˜å‹å’Œä½æ¸©ä¸‹ç”±äºéè¾å°„å¤åˆè€ŒçŒç­ã€‚</li>
<li>ZnPS$_3$çš„é«˜çƒ­è†¨èƒ€ç³»æ•°ä½¿å…¶æˆä¸ºæç«¯ç¯å¢ƒæ„Ÿåº”åº”ç”¨çš„ä¼˜ç§€å€™é€‰ææ–™ã€‚</li>
<li>DFTè®¡ç®—é¢„æµ‹äº†ZnPS$_3$åœ¨é«˜å‹ä¸‹çš„ç”µå­æ€§è´¨å˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14252">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7bae692793dbbfb0d38657e2a766355f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-846c55cd6628f8d4fa985634e2267111.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-538b06994943a43aefa043aa067e305f.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Sparse-Mixture-of-Experts-for-Non-Uniform-Noise-Reduction-in-MRI-Images"><a href="#Sparse-Mixture-of-Experts-for-Non-Uniform-Noise-Reduction-in-MRI-Images" class="headerlink" title="Sparse Mixture-of-Experts for Non-Uniform Noise Reduction in MRI Images"></a>Sparse Mixture-of-Experts for Non-Uniform Noise Reduction in MRI Images</h2><p><strong>Authors:Zeyun Deng, Joseph Campbell</strong></p>
<p>Magnetic Resonance Imaging (MRI) is an essential diagnostic tool in clinical settings, but its utility is often hindered by noise artifacts introduced during the imaging process.Effective denoising is critical for enhancing image quality while preserving anatomical structures. However, traditional denoising methods, which often assume uniform noise distributions, struggle to handle the non-uniform noise commonly present in MRI images. In this paper, we introduce a novel approach leveraging a sparse mixture-of-experts framework for MRI image denoising. Each expert is a specialized denoising convolutional neural network fine-tuned to target specific noise characteristics associated with different image regions. Our method demonstrates superior performance over state-of-the-art denoising techniques on both synthetic and real-world brain MRI datasets. Furthermore, we show that it generalizes effectively to unseen datasets, highlighting its robustness and adaptability. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ä¸´åºŠç¯å¢ƒä¸­é‡è¦çš„è¯Šæ–­å·¥å…·ï¼Œä½†åœ¨æˆåƒè¿‡ç¨‹ä¸­å¼•å…¥çš„å™ªå£°ä¼ªå½±ç»å¸¸é˜»ç¢å…¶åº”ç”¨ã€‚æœ‰æ•ˆå»å™ªå¯¹äºæé«˜å›¾åƒè´¨é‡åŒæ—¶ä¿ç•™è§£å‰–ç»“æ„è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„å»å™ªæ–¹æ³•é€šå¸¸å‡è®¾å™ªå£°åˆ†å¸ƒå‡åŒ€ï¼Œéš¾ä»¥å¤„ç†MRIå›¾åƒä¸­å¸¸è§çš„éå‡åŒ€å™ªå£°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åˆ©ç”¨ç¨€ç–æ··åˆä¸“å®¶æ¡†æ¶è¿›è¡ŒMRIå›¾åƒå»å™ªçš„æ–°æ–¹æ³•ã€‚æ¯ä¸ªä¸“å®¶éƒ½æ˜¯ä¸€ä¸ªé’ˆå¯¹ç‰¹å®šå™ªå£°ç‰¹æ€§è¿›è¡Œå¾®è°ƒçš„å»å™ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œè¿™äº›ç‰¹æ€§ä¸ä¸åŒå›¾åƒåŒºåŸŸç›¸å…³ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„å¤§è„‘MRIæ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºæœ€å…ˆè¿›çš„å»å™ªæŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œå®ƒå¯¹æœªè§æ•°æ®é›†å…·æœ‰æœ‰æ•ˆçš„æ³›åŒ–èƒ½åŠ›ï¼Œçªæ˜¾äº†å…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14198v1">PDF</a> Accepted to the WACV Workshop on Image Quality</p>
<p><strong>æ‘˜è¦</strong><br>     è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºç¨€ç–æ··åˆä¸“å®¶æ¡†æ¶çš„MRIå›¾åƒå»å™ªæ–°æ–¹æ³•ã€‚æ¯ä¸ªä¸“å®¶éƒ½æ˜¯ä¸€ä¸ªé’ˆå¯¹ç‰¹å®šå›¾åƒåŒºåŸŸå™ªå£°ç‰¹æ€§ç²¾ç»†è°ƒæ•´çš„ä¸“é—¨å»å™ªå·ç§¯ç¥ç»ç½‘ç»œã€‚è¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„å¤§è„‘MRIæ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜äºæœ€æ–°å»å™ªæŠ€æœ¯çš„æ€§èƒ½ï¼Œå¹¶å¯æœ‰æ•ˆæ¨å¹¿è‡³æœªè§æ•°æ®é›†ï¼Œå‡¸æ˜¾å…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>MRIåœ¨ä¸´åºŠè¯Šæ–­ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å…¶æˆåƒè¿‡ç¨‹ä¸­çš„å™ªå£°ä¼ªå½±å½±å“äº†å…¶æ•ˆç”¨ã€‚</li>
<li>æœ‰æ•ˆå»å™ªå¯¹äºæé«˜å›¾åƒè´¨é‡å¹¶ä¿ç•™è§£å‰–ç»“æ„è‡³å…³é‡è¦ã€‚</li>
<li>ä¼ ç»Ÿå»å™ªæ–¹æ³•åœ¨å¤„ç†MRIå›¾åƒä¸­å¸¸è§çš„éå‡åŒ€å™ªå£°æ—¶é‡åˆ°å›°éš¾ã€‚</li>
<li>è¯¥è®ºæ–‡å¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºç¨€ç–æ··åˆä¸“å®¶æ¡†æ¶çš„MRIå›¾åƒå»å™ªæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨å¤šä¸ªå·ç§¯ç¥ç»ç½‘ç»œä¸“å®¶ï¼Œæ¯ä¸ªä¸“å®¶é’ˆå¯¹ç‰¹å®šå›¾åƒåŒºåŸŸçš„ç‰¹å®šå™ªå£°ç‰¹æ€§è¿›è¡Œå¾®è°ƒã€‚</li>
<li>åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„å¤§è„‘MRIæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºå“è¶Šçš„å»å™ªæ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¨å¹¿è‡³æœªè§æ•°æ®é›†ï¼Œæ˜¾ç¤ºå‡ºå…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14198">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a38162bf134aeb555b71e8402cf5185e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dd5af67b60b345744c5f399e2d7d8aa1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c158dfc4ea5755ff41ba9f6688f7d279.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4fd70aac8cba137e8dbd21157cb153fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e85946d2c0ebeb13ebcf681a4e77d5f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Advancing-MRI-Reconstruction-A-Systematic-Review-of-Deep-Learning-and-Compressed-Sensing-Integration"><a href="#Advancing-MRI-Reconstruction-A-Systematic-Review-of-Deep-Learning-and-Compressed-Sensing-Integration" class="headerlink" title="Advancing MRI Reconstruction: A Systematic Review of Deep Learning and   Compressed Sensing Integration"></a>Advancing MRI Reconstruction: A Systematic Review of Deep Learning and   Compressed Sensing Integration</h2><p><strong>Authors:Mojtaba Safari, Zach Eidex, Chih-Wei Chang, Richard L. J. Qiu, Xiaofeng Yang</strong></p>
<p>Magnetic resonance imaging (MRI) is a non-invasive imaging modality and provides comprehensive anatomical and functional insights into the human body. However, its long acquisition times can lead to patient discomfort, motion artifacts, and limiting real-time applications. To address these challenges, strategies such as parallel imaging have been applied, which utilize multiple receiver coils to speed up the data acquisition process. Additionally, compressed sensing (CS) is a method that facilitates image reconstruction from sparse data, significantly reducing image acquisition time by minimizing the amount of data collection needed. Recently, deep learning (DL) has emerged as a powerful tool for improving MRI reconstruction. It has been integrated with parallel imaging and CS principles to achieve faster and more accurate MRI reconstructions. This review comprehensively examines DL-based techniques for MRI reconstruction. We categorize and discuss various DL-based methods, including end-to-end approaches, unrolled optimization, and federated learning, highlighting their potential benefits. Our systematic review highlights significant contributions and underscores the potential of DL in MRI reconstruction. Additionally, we summarize key results and trends in DL-based MRI reconstruction, including quantitative metrics, the dataset, acceleration factors, and the progress of and research interest in DL techniques over time. Finally, we discuss potential future directions and the importance of DL-based MRI reconstruction in advancing medical imaging. To facilitate further research in this area, we provide a GitHub repository that includes up-to-date DL-based MRI reconstruction publications and public datasets-<a target="_blank" rel="noopener" href="https://github.com/mosaf/Awesome-DL-based-CS-MRI">https://github.com/mosaf/Awesome-DL-based-CS-MRI</a>. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ä¸€ç§éä¾µå…¥æ€§çš„æˆåƒæŠ€æœ¯ï¼Œèƒ½å¤Ÿå…¨é¢æä¾›äººä½“è§£å‰–å’ŒåŠŸèƒ½æ€§æ´å¯Ÿã€‚ç„¶è€Œï¼Œå…¶è¾ƒé•¿çš„é‡‡é›†æ—¶é—´å¯èƒ½å¯¼è‡´æ‚£è€…ä¸é€‚ã€è¿åŠ¨ä¼ªå½±ï¼Œå¹¶é™åˆ¶å®æ—¶åº”ç”¨ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œå·²ç»åº”ç”¨äº†å¹¶è¡Œæˆåƒç­‰ç­–ç•¥ï¼Œåˆ©ç”¨å¤šä¸ªæ¥æ”¶å™¨çº¿åœˆæ¥åŠ é€Ÿæ•°æ®é‡‡é›†è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œå‹ç¼©æ„ŸçŸ¥ï¼ˆCSï¼‰æ˜¯ä¸€ç§æ–¹æ³•ï¼Œå¯ä»¥ä»ç¨€ç–æ•°æ®ä¸­ä¿ƒè¿›å›¾åƒé‡å»ºï¼Œé€šè¿‡æœ€å°åŒ–æ‰€éœ€çš„æ•°æ®æ”¶é›†é‡æ¥æ˜¾è‘—å‡å°‘å›¾åƒé‡‡é›†æ—¶é—´ã€‚æœ€è¿‘ï¼Œæ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰å·²ç»å´­éœ²å¤´è§’ï¼Œæˆä¸ºæé«˜MRIé‡å»ºçš„å¼ºå¤§å·¥å…·ã€‚å®ƒå·²ç»ä¸å¹¶è¡Œæˆåƒå’ŒCSåŸç†ç›¸ç»“åˆï¼Œå®ç°äº†æ›´å¿«ã€æ›´å‡†ç¡®çš„MRIé‡å»ºã€‚æœ¬æ–‡å…¨é¢å›é¡¾äº†åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºæŠ€æœ¯ã€‚æˆ‘ä»¬å¯¹å„ç§åŸºäºæ·±åº¦å­¦ä¹ æ–¹æ³•è¿›è¡Œåˆ†ç±»å’Œè®¨è®ºï¼ŒåŒ…æ‹¬ç«¯åˆ°ç«¯æ–¹æ³•ã€æ»šåŠ¨ä¼˜åŒ–å’Œè”é‚¦å­¦ä¹ ï¼Œå¹¶é‡ç‚¹ä»‹ç»å®ƒä»¬çš„æ½œåœ¨ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿè¯„ä»·çªå‡ºäº†é‡è¦è´¡çŒ®ï¼Œå¹¶å¼ºè°ƒäº†æ·±åº¦å­¦ä¹ åœ¨MRIé‡å»ºä¸­çš„æ½œåŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ€»ç»“äº†åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºçš„å…³é”®ç»“æœå’Œè¶‹åŠ¿ï¼ŒåŒ…æ‹¬å®šé‡æŒ‡æ ‡ã€æ•°æ®é›†ã€åŠ é€Ÿå› å­ä»¥åŠæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„è¿›å±•å’Œç ”ç©¶å…´è¶£éšæ—¶é—´çš„å˜åŒ–ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†æ½œåœ¨çš„æœªæ¥æ–¹å‘å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºåœ¨æ¨åŠ¨åŒ»å­¦æˆåƒæ–¹é¢çš„é‡è¦æ€§ã€‚ä¸ºäº†ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªGitHubä»“åº“ï¼Œå…¶ä¸­åŒ…å«æœ€æ–°çš„åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºå‡ºç‰ˆç‰©å’Œå…¬å…±æ•°æ®é›†ï¼š[<a target="_blank" rel="noopener" href="https://github.com/mosaf/Awesome-DL-based-CS-MRI%E3%80%82]">https://github.com/mosaf/Awesome-DL-based-CS-MRIã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14158v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç»¼è¿°äº†åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºæŠ€æœ¯ï¼Œè®¨è®ºäº†å„ç±»æ–¹æ³•å¦‚å¹¶è¡Œæˆåƒå’Œå‹ç¼©æ„ŸçŸ¥çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶é‡ç‚¹ä»‹ç»äº†æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨MRIé‡å»ºä¸­çš„åº”ç”¨åŠå…¶æ½œåŠ›ã€‚æ–‡ç« è¿˜æ€»ç»“äº†åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºçš„å…³é”®ç»“æœå’Œè¶‹åŠ¿ï¼Œæä¾›äº†GitHubä»“åº“ä»¥æ¨åŠ¨ç›¸å…³ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ä¸€ç§éä¾µå…¥æ€§çš„æˆåƒæ–¹å¼ï¼Œèƒ½å¤Ÿæä¾›å…¨é¢çš„è§£å‰–å’ŒåŠŸèƒ½æ€§äººä½“ä¿¡æ¯ã€‚</li>
<li>MRIçš„é•¿é‡‡é›†æ—¶é—´å¯èƒ½å¯¼è‡´æ‚£è€…ä¸é€‚ã€è¿åŠ¨ä¼ªå½±ï¼Œå¹¶é™åˆ¶å®æ—¶åº”ç”¨ã€‚</li>
<li>å¹¶è¡Œæˆåƒå’Œå‹ç¼©æ„ŸçŸ¥æ˜¯ä¸¤ç§è§£å†³MRIé‡‡é›†æ—¶é—´é—®é¢˜çš„ç­–ç•¥ã€‚å¹¶è¡Œæˆåƒåˆ©ç”¨å¤šæ¥æ”¶å™¨çº¿åœˆåŠ é€Ÿæ•°æ®é‡‡é›†è¿‡ç¨‹ï¼Œè€Œå‹ç¼©æ„ŸçŸ¥åˆ™ä»ç¨€ç–æ•°æ®ä¸­é‡å»ºå›¾åƒï¼Œæ˜¾è‘—å‡å°‘å›¾åƒé‡‡é›†æ—¶é—´ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨MRIé‡å»ºä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œå·²ç»“åˆå¹¶è¡Œæˆåƒå’Œå‹ç¼©æ„ŸçŸ¥åŸç†å®ç°æ›´å¿«ã€æ›´å‡†ç¡®çš„MRIé‡å»ºã€‚</li>
<li>æ–‡ç« ç»¼è¿°äº†åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºçš„å„ç§æ–¹æ³•ï¼ŒåŒ…æ‹¬ç«¯åˆ°ç«¯æ–¹æ³•ã€æœªæ»šåŠ¨ä¼˜åŒ–å’Œè”é‚¦å­¦ä¹ ç­‰ã€‚</li>
<li>æ–‡ç« æ€»ç»“äº†åŸºäºæ·±åº¦å­¦ä¹ çš„MRIé‡å»ºçš„å…³é”®ç»“æœå’Œè¶‹åŠ¿ï¼ŒåŒ…æ‹¬å®šé‡æŒ‡æ ‡ã€æ•°æ®é›†ã€åŠ é€Ÿå› å­ä»¥åŠæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„è¿›æ­¥å’Œç ”ç©¶å…´è¶£çš„å˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-39388ececb104a7049a068723d967c52.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-575f8f979dca682c1165fbfe167f78e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a1fb58977f5693c7e595e6f6d671579b.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Leveraging-Multiphase-CT-for-Quality-Enhancement-of-Portal-Venous-CT-Utility-for-Pancreas-Segmentation"><a href="#Leveraging-Multiphase-CT-for-Quality-Enhancement-of-Portal-Venous-CT-Utility-for-Pancreas-Segmentation" class="headerlink" title="Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT:   Utility for Pancreas Segmentation"></a>Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT:   Utility for Pancreas Segmentation</h2><p><strong>Authors:Xinya Wang, Tejas Sudharshan Mathai, Boah Kim, Ronald M. Summers</strong></p>
<p>Multiphase CT studies are routinely obtained in clinical practice for diagnosis and management of various diseases, such as cancer. However, the CT studies can be acquired with low radiation doses, different scanners, and are frequently affected by motion and metal artifacts. Prior approaches have targeted the quality improvement of one specific CT phase (e.g., non-contrast CT). In this work, we hypothesized that leveraging multiple CT phases for the quality enhancement of one phase may prove advantageous for downstream tasks, such as segmentation. A 3D progressive fusion and non-local (PFNL) network was developed. It was trained with three degraded (low-quality) phases (non-contrast, arterial, and portal venous) to enhance the quality of the portal venous phase. Then, the effect of scan quality enhancement was evaluated using a proxy task of pancreas segmentation, which is useful for tracking pancreatic cancer. The proposed approach improved the pancreas segmentation by 3% over the corresponding low-quality CT scan. To the best of our knowledge, we are the first to harness multiphase CT for scan quality enhancement and improved pancreas segmentation. </p>
<blockquote>
<p>åœ¨ä¸´åºŠå®è·µä¸­ï¼Œå¤šé˜¶æ®µCTæ£€æŸ¥å¸¸è¢«ç”¨äºå„ç§ç–¾ç—…çš„è¯Šæ–­å’Œæ²»ç–—ï¼Œå¦‚ç™Œç—‡ã€‚ç„¶è€Œï¼ŒCTæ£€æŸ¥å¯ä»¥ä»¥è¾ƒä½çš„è¾å°„å‰‚é‡è·å–ï¼Œä½¿ç”¨ä¸åŒçš„æ‰«æä»ªï¼Œå¹¶ç»å¸¸å—åˆ°è¿åŠ¨å’Œé‡‘å±ä¼ªå½±çš„å½±å“ã€‚ä¹‹å‰çš„æ–¹æ³•ä¸»è¦ç€çœ¼äºæé«˜æŸä¸€ç‰¹å®šCTé˜¶æ®µçš„è´¨é‡ï¼ˆä¾‹å¦‚ï¼Œéå¯¹æ¯”CTï¼‰ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‡è®¾åˆ©ç”¨å¤šä¸ªCTé˜¶æ®µæ¥æé«˜æŸä¸€é˜¶æ®µçš„è´¨é‡å¯èƒ½å¯¹ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²ï¼‰å…·æœ‰ä¼˜åŠ¿ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ª3Dæ¸è¿›èåˆå’Œéå±€éƒ¨ï¼ˆPFNLï¼‰ç½‘ç»œã€‚å®ƒé‡‡ç”¨ä¸‰ç§é€€åŒ–ï¼ˆä½è´¨é‡ï¼‰é˜¶æ®µï¼ˆéå¯¹æ¯”ã€åŠ¨è„‰å’Œé—¨é™è„‰ï¼‰è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜é—¨é™è„‰é˜¶æ®µçš„è´¨é‡ã€‚ç„¶åï¼Œé€šè¿‡èƒ°è…ºåˆ†å‰²çš„ä»£ç†ä»»åŠ¡è¯„ä¼°æ‰«æè´¨é‡æé«˜çš„æ•ˆæœï¼Œè¿™å¯¹è¿½è¸ªèƒ°è…ºç™Œéå¸¸æœ‰ç”¨ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨ç›¸åº”çš„ä½è´¨é‡CTæ‰«æä¸Šæé«˜äº†èƒ°è…ºåˆ†å‰²çš„å‡†ç¡®åº¦ä¸ºç™¾åˆ†ä¹‹ä¸‰ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯é¦–æ¬¡åˆ©ç”¨å¤šé˜¶æ®µCTè¿›è¡Œæ‰«æè´¨é‡æé«˜å’Œæ”¹è¿›èƒ°è…ºåˆ†å‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14013v1">PDF</a> ISBI 2025</p>
<p><strong>Summary</strong><br>     åˆ©ç”¨å¤šæœŸCTæ•°æ®è¿›è¡Œè´¨é‡æ§åˆ¶æ”¹è¿›å¯æé«˜èƒ°è…ºç™Œè·Ÿè¸ªæ£€æµ‹ä¸­çš„èƒ°è…ºåˆ†æ®µç²¾åº¦ã€‚é€šè¿‡ç ”å‘3Dæ¸è¿›èåˆä¸éå±€éƒ¨ç½‘ç»œï¼ˆPFNLï¼‰ï¼Œä»¥ä¸‰ä¸ªé™è´¨ï¼ˆä½è´¨é‡ï¼‰é˜¶æ®µï¼ˆéå¯¹æ¯”å‰‚ã€åŠ¨è„‰æœŸå’Œé—¨é™è„‰æœŸï¼‰çš„è®­ç»ƒæå‡é—¨é™è„‰æœŸå›¾åƒè´¨é‡ã€‚æ­¤æ–¹æ³•åœ¨æé«˜èƒ°è…ºåˆ†æ®µè´¨é‡æ–¹é¢ä¼˜äºå¯¹åº”çš„ä½è´¨é‡CTæ‰«æã€‚æœ¬ç ”ç©¶é¦–åˆ›åˆ©ç”¨å¤šæœŸCTæŠ€æœ¯æå‡æ‰«æè´¨é‡å’Œæ”¹è¿›èƒ°è…ºåˆ†æ®µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæœŸCTç ”ç©¶åœ¨ä¸´åºŠå®è·µä¸­è¢«å¹¿æ³›åº”ç”¨äºå„ç§ç–¾ç—…çš„è¯Šæ–­å’Œç®¡ç†ï¼Œå¦‚ç™Œç—‡ã€‚</li>
<li>CTç ”ç©¶å¯é‡‡ç”¨ä½å‰‚é‡è¾å°„ã€ä¸åŒæ‰«æä»ªè¿›è¡Œï¼Œä½†å¯èƒ½å—åˆ°è¿åŠ¨å’Œé‡‘å±ä¼ªå½±çš„å½±å“ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æŸä¸€ç‰¹å®šCTé˜¶æ®µçš„è´¨æ•ˆæå‡ï¼Œä¾‹å¦‚éå¯¹æ¯”å‰‚CTã€‚</li>
<li>åˆ©ç”¨å¤šæœŸCTæ•°æ®è¿›è¡Œè´¨é‡æ§åˆ¶æ”¹è¿›å¯æé«˜ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²ï¼‰çš„æ€§èƒ½ã€‚</li>
<li>ç ”å‘äº†3Dæ¸è¿›èåˆä¸éå±€éƒ¨ï¼ˆPFNLï¼‰ç½‘ç»œï¼Œä»¥ä½è´¨é‡CTé˜¶æ®µè®­ç»ƒæ¥æå‡é—¨é™è„‰æœŸå›¾åƒè´¨é‡ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨èƒ°è…ºåˆ†å‰²ä½œä¸ºä»£ç†ä»»åŠ¡ï¼Œè¯„ä¼°äº†æ‰«æè´¨é‡æå‡çš„æ•ˆæœï¼Œè¿™å¯¹èƒ°è…ºç™Œçš„è·Ÿè¸ªæ£€æµ‹å…·æœ‰å®ç”¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14013">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1dd5a3be250519fa11ac4287b909a1f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c246bf7461431d88e822954f36a2ff1b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c2dc7840496050a0c4463ef31fe40f35.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0f9a449c53f6a11e2ae709e7fc31514.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a8684f1846726a40887309d01aec26c0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Best-of-both-worlds-Fusing-hyperspectral-data-from-two-generations-of-spectro-imagers-for-X-ray-astrophysics"><a href="#Best-of-both-worlds-Fusing-hyperspectral-data-from-two-generations-of-spectro-imagers-for-X-ray-astrophysics" class="headerlink" title="Best of both worlds: Fusing hyperspectral data from two generations of   spectro-imagers for X-ray astrophysics"></a>Best of both worlds: Fusing hyperspectral data from two generations of   spectro-imagers for X-ray astrophysics</h2><p><strong>Authors:Julia Lascar, JÃ©rÃ´me Bobin, Fabio Acero</strong></p>
<p>With the launch of the X-Ray Imaging and Spectroscopy Mission (XRISM) and the advent of microcalorimeter detectors, X-ray astrophysics is entering in a new era of spatially resolved high resolution spectroscopy. But while this new generation of X-ray telescopes have much finer spectral resolutions than their predecessors (e.g. XMM-Newton, Chandra), they also have coarser spatial resolutions, leading to problematic cross-pixel contamination. This issue is currently a critical limitation for the study of extended sources such as galaxy clusters or supernova remnants. To increase the scientific output of XRISMâ€™s hyperspectral data, we propose to fuse it with XMM-Newton data, and seek to obtain a cube with the best spatial and spectral resolution of both generations. This is the aim of hyperspectral fusion. In this article, we have implemented an algorithm that jointly deconvolves the spatial response of XRISM and the spectral response of XMM-Newton. To do so, we construct a forward model adapted for instrumental systematic degradations and Poisson noise, then tackle hyperspectral fusion as a regularized inverse problem. We test three methods of regularization: low rank approximation with Sobolev regularization; low rank approximation with 2D wavelet sparsity ; and 2D-1D wavelet sparsity. We test our method on toy models constructed from hydrodynamic simulations of supernova remnants. We find that our method reconstructs the ground truth well even when the toy model is complex. For the regularization term, we find that while the low rank approximation worked well as a spectral denoiser in models with less spectral variability, it introduced a bias in models with more spectral variability, in which case the 2D-1D wavelet sparsity regularization worked best. After demonstrating a proof of concept in this article, we aim to apply this method to real X-ray astrophysical data in the near future. </p>
<blockquote>
<p>éšç€Xå°„çº¿æˆåƒä¸å…‰è°±ä»»åŠ¡ï¼ˆXRISMï¼‰çš„å‘å°„å’Œå¾®çƒ­é‡è®¡çš„è¯ç”Ÿï¼ŒXå°„çº¿å¤©ä½“ç‰©ç†å­¦æ­£è¿›å…¥ç©ºé—´é«˜åˆ†è¾¨ç‡å…‰è°±å­¦çš„æ–°æ—¶ä»£ã€‚è™½ç„¶è¿™ä¸€ä»£Xå°„çº¿æœ›è¿œé•œçš„å…‰è°±åˆ†è¾¨ç‡æ¯”å…¶å‰è¾ˆï¼ˆå¦‚XMM-ç‰›é¡¿å’Œé’±å¾·æ‹‰ï¼‰æ›´ä¸ºç²¾ç»†ï¼Œä½†å®ƒä»¬çš„ç©ºé—´åˆ†è¾¨ç‡ç›¸å¯¹è¾ƒå·®ï¼Œå¯¼è‡´äº†è·¨åƒç´ æ±¡æŸ“çš„é—®é¢˜ã€‚ç›®å‰è¿™ä¸€é—®é¢˜å¯¹äºæ‰©å±•æºï¼ˆå¦‚æ˜Ÿç³»å›¢æˆ–è¶…æ–°æ˜Ÿé—è¿¹ï¼‰çš„ç ”ç©¶æ˜¯ä¸€ä¸ªå…³é”®çš„é™åˆ¶ã€‚ä¸ºäº†æé«˜XRISMé«˜å…‰è°±æ•°æ®çš„ç§‘å­¦äº§å‡ºï¼Œæˆ‘ä»¬æè®®å°†å…¶ä¸XMM-ç‰›é¡¿æ•°æ®è¿›è¡Œèåˆï¼Œå¹¶å¯»æ±‚è·å¾—å…·æœ‰ä¸¤è€…æœ€ä½³ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡çš„ç«‹æ–¹ä½“ã€‚è¿™æ˜¯é«˜å…‰è°±èåˆçš„ç›®æ ‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç§ç®—æ³•ï¼Œè¯¥ç®—æ³•è”åˆåå·ç§¯XRISMçš„ç©ºé—´å“åº”å’ŒXMM-ç‰›é¡¿çš„å…‰è°±å“åº”ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªé€‚åº”ä»ªå™¨ç³»ç»Ÿé€€åŒ–å’Œæ³Šæ¾å™ªå£°çš„å‰å‘æ¨¡å‹ï¼Œç„¶åå°†é«˜å…‰è°±èåˆè§†ä¸ºæ­£åˆ™åŒ–é€†é—®é¢˜ã€‚æˆ‘ä»¬æµ‹è¯•äº†ä¸‰ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼šåŸºäºç´¢åšåˆ—å¤«æ­£åˆ™åŒ–çš„ä½ç§©é€¼è¿‘ã€åŸºäºäºŒç»´å°æ³¢ç¨€ç–æ€§çš„ä½ç§©é€¼è¿‘å’ŒäºŒç»´åˆ°ä¸€ç»´å°æ³¢ç¨€ç–æ€§ã€‚æˆ‘ä»¬ç”¨è¶…æ–°æ˜Ÿé—è¿¹çš„æ°´åŠ¨åŠ›æ¨¡æ‹Ÿæ„å»ºçš„ç©å…·æ¨¡å‹æ¥æµ‹è¯•æˆ‘ä»¬çš„æ–¹æ³•ã€‚æˆ‘ä»¬å‘ç°å³ä½¿åœ¨ç©å…·æ¨¡å‹å¤æ‚çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿèƒ½å¾ˆå¥½åœ°é‡å»ºçœŸå®å€¼ã€‚å¯¹äºæ­£åˆ™åŒ–é¡¹ï¼Œæˆ‘ä»¬å‘ç°ä½ç§©é€¼è¿‘åœ¨å…‰è°±å˜åŒ–è¾ƒå°‘çš„æ¨¡å‹ä¸­ä½œä¸ºå…‰è°±å»å™ªå™¨æ•ˆæœè¾ƒå¥½ï¼Œä½†åœ¨å…‰è°±å˜åŒ–è¾ƒå¤§çš„æ¨¡å‹ä¸­å¼•å…¥äº†åå·®ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒäºŒç»´åˆ°ä¸€ç»´å°æ³¢ç¨€ç–æ€§æ­£åˆ™åŒ–è¡¨ç°æœ€å¥½ã€‚åœ¨æœ¬æ–‡ä¸­éªŒè¯äº†è¿™ä¸€ç†å¿µåï¼Œæˆ‘ä»¬è®¡åˆ’åœ¨ä¸ä¹…çš„å°†æ¥å°†æ­¤æ–¹æ³•åº”ç”¨äºçœŸå®çš„Xå°„çº¿å¤©æ–‡æ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.15639v2">PDF</a> This article was accepted by Astronomy and Astophysics. The code   described in this article is available at:   <a target="_blank" rel="noopener" href="https://github.com/JMLascar/HIFReD_fusion">https://github.com/JMLascar/HIFReD_fusion</a></p>
<p><strong>æ‘˜è¦</strong><br>    æ–°ä¸€ä»£Xå°„çº¿æœ›è¿œé•œè¿›å…¥ç©ºé—´åˆ†è¾¨é«˜å…‰è°±æ—¶ä»£ï¼Œé¢ä¸´è·¨åƒç´ æ±¡æŸ“é—®é¢˜ã€‚ä¸ºæå‡XRISMé«˜å…‰è°±æ•°æ®ç§‘å­¦äº§å‡ºï¼Œæå‡ºèåˆXRISMä¸XMM-Newtonæ•°æ®çš„æ–¹æ³•ï¼Œæ—¨åœ¨è·å¾—å…¼å…·ä¸¤è€…æœ€ä½³ç©ºé—´ä¸å…‰è°±åˆ†è¾¨ç‡çš„æ•°æ®ç«‹æ–¹ä½“ã€‚æœ¬ç ”ç©¶å®ç°äº†ä¸€ç§è”åˆè§£å·ç®—æ³•ï¼Œé’ˆå¯¹XRISMçš„ç©ºé—´å“åº”å’ŒXMM-Newtonçš„å…‰è°±å“åº”è¿›è¡Œè§£å·ã€‚å»ºç«‹æ­£å‘æ¨¡å‹ä»¥åº”å¯¹ä»ªå™¨ç³»ç»Ÿé€€åŒ–å’Œæ³Šæ¾å™ªå£°é—®é¢˜ï¼Œå°†é«˜å…‰è°±èåˆè§†ä¸ºæ­£åˆ™åŒ–åé—®é¢˜è¿›è¡Œå¤„ç†ã€‚æµ‹è¯•ä¸‰ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå‘ç°å¯¹äºå…·æœ‰å¤æ‚å…‰è°±å˜åŒ–çš„æ¨¡å‹ï¼ŒäºŒç»´ä¸€ç»´å°æ³¢ç¨€ç–æ­£åˆ™åŒ–è¡¨ç°æœ€ä½³ã€‚æœ¬ç ”ç©¶ä¸ºå°†è¯¥æ–¹æ³•åº”ç”¨äºçœŸå®Xå°„çº¿å¤©æ–‡æ•°æ®å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>Xå°„çº¿å¤©ä½“ç‰©ç†å­¦è¿›å…¥é«˜å…‰è°±æ—¶ä»£ï¼Œé¢ä¸´è·¨åƒç´ æ±¡æŸ“é—®é¢˜ã€‚</li>
<li>XRISMä¸XMM-Newtonæ•°æ®èåˆæ—¨åœ¨æé«˜ç§‘å­¦äº§å‡ºï¼Œè·å¾—æœ€ä½³ç©ºé—´ä¸å…‰è°±åˆ†è¾¨ç‡çš„æ•°æ®ç«‹æ–¹ä½“ã€‚</li>
<li>å®æ–½è”åˆè§£å·ç®—æ³•ï¼Œé’ˆå¯¹XRISMå’ŒXMM-Newtonçš„æ•°æ®ç‰¹æ€§è¿›è¡Œè§£å·ã€‚</li>
<li>å»ºç«‹æ­£å‘æ¨¡å‹ä»¥åº”å¯¹ä»ªå™¨é€€åŒ–å’Œå™ªå£°é—®é¢˜ã€‚</li>
<li>æµ‹è¯•ä¸‰ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬ä½ç§©è¿‘ä¼¼ä¸Sobolevæ­£åˆ™åŒ–ã€ä½ç§©è¿‘ä¼¼ä¸äºŒç»´å°æ³¢ç¨€ç–æ€§ä»¥åŠäºŒç»´ä¸€ç»´å°æ³¢ç¨€ç–æ€§ã€‚</li>
<li>å¯¹äºå…·æœ‰å¤æ‚æˆ–å˜åŒ–ä¸°å¯Œçš„å…‰è°±æ¨¡å‹ï¼ŒäºŒç»´ä¸€ç»´å°æ³¢ç¨€ç–æ­£åˆ™åŒ–è¡¨ç°æœ€ä½³ã€‚</li>
<li>æœ¬ç ”ç©¶ä¸ºå°†ç®—æ³•åº”ç”¨äºçœŸå®Xå°„çº¿å¤©æ–‡æ•°æ®å¥ å®šäº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.15639">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-de93974b4a89a9be9118cf215148311c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9eb4775730cdc58cae289a4a2a22654.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4453d3712429cf7546ad1f21cea7efdf.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="ASCNet-Asymmetric-Sampling-Correction-Network-for-Infrared-Image-Destriping"><a href="#ASCNet-Asymmetric-Sampling-Correction-Network-for-Infrared-Image-Destriping" class="headerlink" title="ASCNet: Asymmetric Sampling Correction Network for Infrared Image   Destriping"></a>ASCNet: Asymmetric Sampling Correction Network for Infrared Image   Destriping</h2><p><strong>Authors:Shuai Yuan, Hanlin Qin, Xiang Yan, Shiqi Yang, Shuowen Yang, Naveed Akhtar, Huixin Zhou</strong></p>
<p>In a real-world infrared imaging system, effectively learning a consistent stripe noise removal model is essential. Most existing destriping methods cannot precisely reconstruct images due to cross-level semantic gaps and insufficient characterization of the global column features. To tackle this problem, we propose a novel infrared image destriping method, called Asymmetric Sampling Correction Network (ASCNet), that can effectively capture global column relationships and embed them into a U-shaped framework, providing comprehensive discriminative representation and seamless semantic connectivity. Our ASCNet consists of three core elements: Residual Haar Discrete Wavelet Transform (RHDWT), Pixel Shuffle (PS), and Column Non-uniformity Correction Module (CNCM). Specifically, RHDWT is a novel downsampler that employs double-branch modeling to effectively integrate stripe-directional prior knowledge and data-driven semantic interaction to enrich the feature representation. Observing the semantic patterns crosstalk of stripe noise, PS is introduced as an upsampler to prevent excessive apriori decoding and performing semantic-bias-free image reconstruction. After each sampling, CNCM captures the column relationships in long-range dependencies. By incorporating column, spatial, and self-dependence information, CNCM well establishes a global context to distinguish stripes from the sceneâ€™s vertical structures. Extensive experiments on synthetic data, real data, and infrared small target detection tasks demonstrate that the proposed method outperforms state-of-the-art single-image destriping methods both visually and quantitatively. Our code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/xdFai/ASCNet">https://github.com/xdFai/ASCNet</a>. </p>
<blockquote>
<p>åœ¨çœŸå®ä¸–ç•Œçš„çº¢å¤–æˆåƒç³»ç»Ÿä¸­ï¼Œæœ‰æ•ˆåœ°å­¦ä¹ ä¸€è‡´çš„æ¡çº¹å™ªå£°å»é™¤æ¨¡å‹è‡³å…³é‡è¦ã€‚å¤§å¤šæ•°ç°æœ‰çš„å»æ¡çº¹æ–¹æ³•ç”±äºè·¨çº§åˆ«è¯­ä¹‰é¸¿æ²Ÿå’Œå¯¹å…¨å±€åˆ—ç‰¹å¾æè¿°ä¸è¶³ï¼Œæ— æ³•ç²¾ç¡®é‡å»ºå›¾åƒã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„çº¢å¤–å›¾åƒå»æ¡çº¹æ–¹æ³•ï¼Œç§°ä¸ºä¸å¯¹ç§°é‡‡æ ·æ ¡æ­£ç½‘ç»œï¼ˆASCNetï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•è·å…¨å±€åˆ—å…³ç³»å¹¶å°†å…¶åµŒå…¥Uå½¢æ¡†æ¶ä¸­ï¼Œæä¾›å…¨é¢çš„åˆ¤åˆ«è¡¨ç¤ºå’Œæ— ç¼è¯­ä¹‰è¿æ¥ã€‚æˆ‘ä»¬çš„ASCNetç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼šæ®‹å·®å“ˆå°”ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆRHDWTï¼‰ã€åƒç´ æ´—ç‰Œï¼ˆPSï¼‰å’Œåˆ—éå‡åŒ€æ€§æ ¡æ­£æ¨¡å—ï¼ˆCNCMï¼‰ã€‚å…·ä½“æ¥è¯´ï¼ŒRHDWTæ˜¯ä¸€ç§æ–°å‹çš„ä¸‹é‡‡æ ·å™¨ï¼Œé‡‡ç”¨åŒåˆ†æ”¯å»ºæ¨¡ï¼Œæœ‰æ•ˆåœ°ç»“åˆäº†æ¡çº¹æ–¹å‘å…ˆéªŒçŸ¥è¯†å’Œæ•°æ®é©±åŠ¨çš„è¯­ä¹‰äº¤äº’ï¼Œä»¥ä¸°å¯Œç‰¹å¾è¡¨ç¤ºã€‚è§‚å¯Ÿåˆ°æ¡çº¹å™ªå£°çš„è¯­ä¹‰æ¨¡å¼ä¸²æ‰°ï¼Œå¼•å…¥PSä½œä¸ºä¸Šé‡‡æ ·å™¨ï¼Œä»¥é˜²æ­¢è¿‡åº¦å…ˆéªŒè§£ç å¹¶è¿›è¡Œè¯­ä¹‰æ— åå›¾åƒé‡å»ºã€‚æ¯æ¬¡é‡‡æ ·åï¼ŒCNCMæ•è·é•¿èŒƒå›´ä¾èµ–å…³ç³»ä¸­çš„åˆ—å…³ç³»ã€‚é€šè¿‡ç»“åˆåˆ—ã€ç©ºé—´å’Œè‡ªä¾èµ–ä¿¡æ¯ï¼ŒCNCMå¾ˆå¥½åœ°å»ºç«‹äº†å…¨å±€ä¸Šä¸‹æ–‡ï¼Œä»¥åŒºåˆ†æ¡çº¹å’Œåœºæ™¯çš„å‚ç›´ç»“æ„ã€‚åœ¨åˆæˆæ•°æ®ã€çœŸå®æ•°æ®å’Œçº¢å¤–å°ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰å’Œå®šé‡ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„å•å›¾åƒå»æ¡çº¹æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/xdFai/ASCNet">https://github.com/xdFai/ASCNet</a>ä¸Šå…¬å¼€æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.15578v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„çº¢å¤–å›¾åƒå»æ¡çº¹å™ªå£°æ–¹æ³•ï¼Œåä¸ºä¸å¯¹ç§°é‡‡æ ·æ ¡æ­£ç½‘ç»œï¼ˆASCNetï¼‰ã€‚è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæ•æ‰å…¨å±€åˆ—å…³ç³»ï¼Œå¹¶å°†å…¶åµŒå…¥Uå‹æ¡†æ¶ä¸­ï¼Œæä¾›å…¨é¢çš„åˆ¤åˆ«è¡¨ç¤ºå’Œæ— ç¼è¯­ä¹‰è¿æ¥ã€‚æ ¸å¿ƒå…ƒç´ åŒ…æ‹¬æ®‹å·®å“ˆå°”ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆRHDWTï¼‰ã€åƒç´ æ´—ç‰Œï¼ˆPSï¼‰å’Œåˆ—éå‡åŒ€æ ¡æ­£æ¨¡å—ï¼ˆCNCMï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆæ•°æ®ã€çœŸå®æ•°æ®å’Œçº¢å¤–å°ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæ— è®ºåœ¨è§†è§‰ä¸Šè¿˜æ˜¯æ•°é‡ä¸Šéƒ½ä¼˜äºæœ€æ–°çš„å•å›¾åƒå»æ¡çº¹æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†æ–°å‹çº¢å¤–å›¾åƒå»æ¡çº¹å™ªå£°æ–¹æ³•ASCNetã€‚</li>
<li>ASCNetèƒ½æœ‰æ•ˆæ•æ‰å…¨å±€åˆ—å…³ç³»å¹¶åµŒå…¥Uå‹æ¡†æ¶ã€‚</li>
<li>æ–¹æ³•åŒ…æ‹¬RHDWTã€PSå’ŒCNCMä¸‰ä¸ªæ ¸å¿ƒå…ƒç´ ã€‚</li>
<li>RHDWTæ˜¯æ–°å‹ä¸‹é‡‡æ ·å™¨ï¼Œèƒ½æ•´åˆæ¡çº¹æ–¹å‘å…ˆéªŒçŸ¥è¯†å’Œæ•°æ®é©±åŠ¨è¯­ä¹‰äº¤äº’ã€‚</li>
<li>PSä½œä¸ºä¸Šé‡‡æ ·å™¨ï¼Œèƒ½é˜²æ­¢è¿‡åº¦å…ˆéªŒè§£ç ï¼Œå®ç°è¯­ä¹‰åå·®è‡ªç”±å›¾åƒé‡å»ºã€‚</li>
<li>CNCMèƒ½æ•æ‰é•¿è·ç¦»ä¾èµ–ä¸­çš„åˆ—å…³ç³»ï¼Œå¹¶å»ºç«‹å…¨å±€ä¸Šä¸‹æ–‡ä»¥åŒºåˆ†æ¡çº¹å’Œåœºæ™¯å‚ç›´ç»“æ„ã€‚</li>
<li>åœ¨åˆæˆæ•°æ®ã€çœŸå®æ•°æ®å’Œçº¢å¤–å°ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒASCNetè¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.15578">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3a79f548855d6c7cdf039165f77c9e6e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-192119c32b3e336d0e2e482b57016322.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db9269baf031deeb34179c009dc93799.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f43b0d8abe42d93cd12ab95dc4ad9893.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-28/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-28/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-28/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-91809a59cae17f470cd1df6ba52f2750.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-28  Characteristic-Specific Partial Fine-Tuning for Efficient Emotion and   Speaker Adaptation in Codec Language Text-to-Speech Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-28/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ab41b8c1771e184bca1b15ff876f63cd.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-28  Training-Free Style and Content Transfer by Leveraging U-Net Skip   Connections in Stable Diffusion 2.*
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
