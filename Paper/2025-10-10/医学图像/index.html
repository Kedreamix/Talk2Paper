<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-10  Validation of Various Normalization Methods for Brain Tumor   Segmentation Can Federated Learning Overcome This Heterogeneity?">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-7e4c436ac5f510674cbe676065e934a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049798&auth_key=1760049798-0-0-50b80f9a76b73bef9b9252391c2cffaa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    22.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    91 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-10-æ›´æ–°"><a href="#2025-10-10-æ›´æ–°" class="headerlink" title="2025-10-10 æ›´æ–°"></a>2025-10-10 æ›´æ–°</h1><h2 id="Validation-of-Various-Normalization-Methods-for-Brain-Tumor-Segmentation-Can-Federated-Learning-Overcome-This-Heterogeneity"><a href="#Validation-of-Various-Normalization-Methods-for-Brain-Tumor-Segmentation-Can-Federated-Learning-Overcome-This-Heterogeneity" class="headerlink" title="Validation of Various Normalization Methods for Brain Tumor   Segmentation: Can Federated Learning Overcome This Heterogeneity?"></a>Validation of Various Normalization Methods for Brain Tumor   Segmentation: Can Federated Learning Overcome This Heterogeneity?</h2><p><strong>Authors:Jan Fiszer, Dominika Ciupek, Maciej Malawski</strong></p>
<p>Deep learning (DL) has been increasingly applied in medical imaging, however, it requires large amounts of data, which raises many challenges related to data privacy, storage, and transfer. Federated learning (FL) is a training paradigm that overcomes these issues, though its effectiveness may be reduced when dealing with non-independent and identically distributed (non-IID) data. This study simulates non-IID conditions by applying different MRI intensity normalization techniques to separate data subsets, reflecting a common cause of heterogeneity. These subsets are then used for training and testing models for brain tumor segmentation. The findings provide insights into the influence of the MRI intensity normalization methods on segmentation models, both training and inference. Notably, the FL methods demonstrated resilience to inconsistently normalized data across clients, achieving the 3D Dice score of 92%, which is comparable to a centralized model (trained using all data). These results indicate that FL is a solution to effectively train high-performing models without violating data privacy, a crucial concern in medical applications. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/SanoScience/fl-varying-normalization">https://github.com/SanoScience/fl-varying-normalization</a>. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œç„¶è€Œï¼Œå®ƒéœ€è¦å¤§é‡çš„æ•°æ®ï¼Œè¿™å°±å¼•å‘äº†ä¸æ•°æ®éšç§ã€å­˜å‚¨å’Œä¼ è¾“ç›¸å…³çš„è®¸å¤šæŒ‘æˆ˜ã€‚è”åˆå­¦ä¹ ï¼ˆFLï¼‰æ˜¯ä¸€ç§å…‹æœè¿™äº›é—®é¢˜çš„è®­ç»ƒèŒƒå¼ï¼Œä½†åœ¨å¤„ç†éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®æ—¶ï¼Œå…¶æ•ˆæœå¯èƒ½ä¼šé™ä½ã€‚æœ¬ç ”ç©¶é€šè¿‡åº”ç”¨ä¸åŒçš„MRIå¼ºåº¦å½’ä¸€åŒ–æŠ€æœ¯æ¥æ¨¡æ‹ŸéIIDæ¡ä»¶ï¼Œå°†æ•°æ®é›†åˆ†ç¦»ï¼Œä»¥åæ˜ å¼‚è´¨æ€§çš„å¸¸è§åŸå› ã€‚è¿™äº›å­é›†éšåç”¨äºè®­ç»ƒå’Œæµ‹è¯•è„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹ã€‚ç ”ç©¶ç»“æœæä¾›äº†MRIå¼ºåº¦å½’ä¸€åŒ–æ–¹æ³•å¯¹åˆ†å‰²æ¨¡å‹è®­ç»ƒå’Œæ¨ç†å½±å“çš„è§è§£ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè”é‚¦å­¦ä¹ æ–¹æ³•å¯¹å®¢æˆ·ç«¯é—´å½’ä¸€åŒ–ä¸ä¸€è‡´çš„æ•°æ®è¡¨ç°å‡ºéŸ§æ€§ï¼Œå®ç°äº†3DDiceåˆ†æ•°ä¸º92%ï¼Œä¸é›†ä¸­æ¨¡å‹ï¼ˆä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒï¼‰ç›¸å½“ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè”é‚¦å­¦ä¹ æ˜¯æœ‰æ•ˆè®­ç»ƒé«˜æ€§èƒ½æ¨¡å‹è€Œä¸è¿åæ•°æ®éšç§çš„è§£å†³æ–¹æ¡ˆï¼Œè¿™æ˜¯åŒ»å­¦åº”ç”¨ä¸­ä¸€ä¸ªå…³é”®çš„é—®é¢˜ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/SanoScience/fl-varying-normalization%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/SanoScience/fl-varying-normalizationè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.07126v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦æˆåƒé¢†åŸŸåº”ç”¨å¹¿æ³›ï¼Œä½†éœ€è¦å¤§é‡æ•°æ®ï¼Œå¸¦æ¥æ•°æ®éšç§ã€å­˜å‚¨å’Œä¼ è¾“æ–¹é¢çš„æŒ‘æˆ˜ã€‚è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰å…‹æœäº†è¿™äº›é—®é¢˜ï¼Œä½†åœ¨å¤„ç†éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®æ—¶æ•ˆæœå¯èƒ½é™ä½ã€‚æœ¬ç ”ç©¶é€šè¿‡åº”ç”¨ä¸åŒçš„MRIå¼ºåº¦å½’ä¸€åŒ–æŠ€æœ¯æ¥æ¨¡æ‹ŸéIIDæ¡ä»¶ï¼Œç”¨äºè®­ç»ƒå’Œæµ‹è¯•è„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹ã€‚ç ”ç©¶å‘ç°MRIå¼ºåº¦å½’ä¸€åŒ–æ–¹æ³•å¯¹åˆ†å‰²æ¨¡å‹çš„å½±å“ï¼Œè”é‚¦å­¦ä¹ æ–¹æ³•å¯¹ä¸ä¸€è‡´å½’ä¸€åŒ–æ•°æ®å…·æœ‰éŸ§æ€§ï¼Œ3D Diceè¯„åˆ†è¾¾åˆ°92%ï¼Œä¸é›†ä¸­æ¨¡å‹ç›¸å½“ã€‚è¿™è¯æ˜è”é‚¦å­¦ä¹ æ˜¯æœ‰æ•ˆè®­ç»ƒé«˜æ€§èƒ½æ¨¡å‹ä¸”ä¸ä¼šä¾µçŠ¯æ•°æ®éšç§çš„è§£å†³æ–¹æ¡ˆï¼Œè¿™åœ¨åŒ»å­¦åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦æˆåƒä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†éœ€å¤§é‡æ•°æ®ï¼Œå¼•å‘æ•°æ®éšç§ã€å­˜å‚¨å’Œä¼ è¾“æŒ‘æˆ˜ã€‚</li>
<li>è”é‚¦å­¦ä¹ å…‹æœè¿™äº›é—®é¢˜ï¼Œä½†åœ¨å¤„ç†éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®æ—¶æ•ˆæœå¯èƒ½é™ä½ã€‚</li>
<li>ç ”ç©¶é€šè¿‡MRIå¼ºåº¦å½’ä¸€åŒ–æŠ€æœ¯æ¨¡æ‹ŸéIIDæ¡ä»¶ï¼Œç”¨äºè®­ç»ƒå’Œæµ‹è¯•è„‘è‚¿ç˜¤åˆ†å‰²æ¨¡å‹ã€‚</li>
<li>è”é‚¦å­¦ä¹ æ–¹æ³•å¯¹ä¸ä¸€è‡´å½’ä¸€åŒ–æ•°æ®å…·æœ‰éŸ§æ€§ã€‚</li>
<li>3D Diceè¯„åˆ†è¾¾åˆ°92%ï¼Œä¸é›†ä¸­æ¨¡å‹ç›¸å½“ï¼Œè¯æ˜è”é‚¦å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è”é‚¦å­¦ä¹ æ˜¯æœ‰æ•ˆè®­ç»ƒé«˜æ€§èƒ½æ¨¡å‹ä¸”ä¸ä¼šä¾µçŠ¯æ•°æ®éšç§çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.07126">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d5dbdf7bb38033867ed2fd4e73a50921~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049687&auth_key=1760049687-0-0-718a0457a5305049e875c8c1c426933f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cc0eaa4ff83ac53ff983d244bf2af33e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049693&auth_key=1760049693-0-0-1cd1866c6debcdc0b9a6628e7d8f80fa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9edb48424c13c236bcd743e47b622860~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049700&auth_key=1760049700-0-0-4f0a8d715fa3156460a77aa98d7b61cc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1416cfd7f404dc553b5108aaa065ed03~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049707&auth_key=1760049707-0-0-2a5378280a1e1a60c0a028b56759d27a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="U-Bench-A-Comprehensive-Understanding-of-U-Net-through-100-Variant-Benchmarking"><a href="#U-Bench-A-Comprehensive-Understanding-of-U-Net-through-100-Variant-Benchmarking" class="headerlink" title="U-Bench: A Comprehensive Understanding of U-Net through 100-Variant   Benchmarking"></a>U-Bench: A Comprehensive Understanding of U-Net through 100-Variant   Benchmarking</h2><p><strong>Authors:Fenghe Tang, Chengqi Dong, Wenxin Ma, Zikang Xu, Heqin Zhu, Zihang Jiang, Rongsheng Wang, Yuhao Wang, Chenxu Wu, Shaohua Kevin Zhou</strong></p>
<p>Over the past decade, U-Net has been the dominant architecture in medical image segmentation, leading to the development of thousands of U-shaped variants. Despite its widespread adoption, there is still no comprehensive benchmark to systematically evaluate their performance and utility, largely because of insufficient statistical validation and limited consideration of efficiency and generalization across diverse datasets. To bridge this gap, we present U-Bench, the first large-scale, statistically rigorous benchmark that evaluates 100 U-Net variants across 28 datasets and 10 imaging modalities. Our contributions are threefold: (1) Comprehensive Evaluation: U-Bench evaluates models along three key dimensions: statistical robustness, zero-shot generalization, and computational efficiency. We introduce a novel metric, U-Score, which jointly captures the performance-efficiency trade-off, offering a deployment-oriented perspective on model progress. (2) Systematic Analysis and Model Selection Guidance: We summarize key findings from the large-scale evaluation and systematically analyze the impact of dataset characteristics and architectural paradigms on model performance. Based on these insights, we propose a model advisor agent to guide researchers in selecting the most suitable models for specific datasets and tasks. (3) Public Availability: We provide all code, models, protocols, and weights, enabling the community to reproduce our results and extend the benchmark with future methods. In summary, U-Bench not only exposes gaps in previous evaluations but also establishes a foundation for fair, reproducible, and practically relevant benchmarking in the next decade of U-Net-based segmentation models. The project can be accessed at: <a target="_blank" rel="noopener" href="https://fenghetan9.github.io/ubench">https://fenghetan9.github.io/ubench</a>. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/U-Bench">https://github.com/FengheTan9/U-Bench</a>. </p>
<blockquote>
<p>è¿‡å»åå¹´é‡Œï¼ŒU-Netåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸå æ®ä¸»å¯¼åœ°ä½ï¼Œå¹¶å‚¬ç”Ÿäº†æ•°åƒç§Uå‹å˜ä½“ã€‚å°½ç®¡å…¶åº”ç”¨å¹¿æ³›ï¼Œä½†ä»ç¼ºä¹ä¸€ä¸ªç»¼åˆåŸºå‡†æ¥ç³»ç»Ÿåœ°è¯„ä¼°å®ƒä»¬çš„æ€§èƒ½å’Œå®ç”¨æ€§ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºç»Ÿè®¡éªŒè¯ä¸è¶³ï¼Œä»¥åŠå¯¹ä¸åŒæ•°æ®é›†çš„æ•ˆç‡å’Œæ¨å¹¿çš„è€ƒè™‘æœ‰é™ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†U-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡ã€ç»Ÿè®¡ä¸¥è°¨çš„åŸºå‡†ï¼Œè¯„ä¼°äº†28ä¸ªæ•°æ®é›†çš„100ç§U-Netå˜ä½“ä»¥åŠ10ç§æˆåƒæ¨¡å¼ã€‚æˆ‘ä»¬çš„è´¡çŒ®åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šï¼ˆ1ï¼‰å…¨é¢è¯„ä¼°ï¼šU-Benchä»ä¸‰ä¸ªå…³é”®ç»´åº¦å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼šç»Ÿè®¡ç¨³å¥æ€§ã€é›¶å°„å‡»æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹æŒ‡æ ‡U-Scoreï¼Œå®ƒè”åˆæ•è·æ€§èƒ½æ•ˆç‡æƒè¡¡ï¼Œä¸ºæ¨¡å‹è¿›å±•æä¾›äº†é¢å‘éƒ¨ç½²çš„è§†è§’ã€‚ï¼ˆ2ï¼‰ç³»ç»Ÿåˆ†æä¸æ¨¡å‹é€‰æ‹©æŒ‡å—ï¼šæˆ‘ä»¬å¯¹å¤§è§„æ¨¡è¯„ä¼°çš„å…³é”®å‘ç°è¿›è¡Œäº†æ€»ç»“ï¼Œå¹¶å¯¹æ•°æ®é›†ç‰¹æ€§å’Œæ¶æ„èŒƒå¼å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“è¿›è¡Œäº†ç³»ç»Ÿåˆ†æã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¨¡å‹é¡¾é—®ä»£ç†ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜ä¸ºç‰¹å®šæ•°æ®é›†å’Œä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ã€‚ï¼ˆ3ï¼‰å…¬å¼€å¯ç”¨ï¼šæˆ‘ä»¬æä¾›äº†æ‰€æœ‰ä»£ç ã€æ¨¡å‹ã€åè®®å’Œæƒé‡ï¼Œä½¿ç¤¾åŒºèƒ½å¤Ÿå¤åˆ¶æˆ‘ä»¬çš„ç»“æœå¹¶ç”¨æœªæ¥æ–¹æ³•å¯¹åŸºå‡†æµ‹è¯•è¿›è¡Œæ‰©å±•ã€‚æ€»ä¹‹ï¼ŒU-Benchä¸ä»…æ­ç¤ºäº†ä»¥å‰è¯„ä¼°ä¸­çš„å·®è·ï¼Œè€Œä¸”ä¸ºä¸‹ä¸€ä¸ªåå¹´U-NetåŸºåˆ†å‰²æ¨¡å‹çš„å…¬å¹³ã€å¯é‡å¤å’Œå®é™…ç›¸å…³çš„åŸºå‡†æµ‹è¯•å¥ å®šäº†åŸºç¡€ã€‚é¡¹ç›®å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://fenghetan9.github.io/ubench">https://fenghetan9.github.io/ubench</a>ã€‚ä»£ç å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/FengheTan9/U-Bench">https://github.com/FengheTan9/U-Bench</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.07041v1">PDF</a> 54 pages. The project can be accessed at:   <a target="_blank" rel="noopener" href="https://fenghetan9.github.io/ubench">https://fenghetan9.github.io/ubench</a>. Code is available at:   <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/U-Bench">https://github.com/FengheTan9/U-Bench</a></p>
<p><strong>æ‘˜è¦</strong><br>    åå¹´æ¥ï¼ŒU-Netåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œå¹¶å‚¬ç”Ÿå‡ºæ•°åƒç§Uå‹å˜ä½“ã€‚å°½ç®¡å…¶å¹¿æ³›åº”ç”¨ï¼Œä½†ç›®å‰ä»ç¼ºä¹ç»¼åˆåŸºå‡†æµ‹è¯•æ¥ç³»ç»Ÿåœ°è¯„ä¼°å®ƒä»¬çš„æ€§èƒ½å’Œå®ç”¨æ€§ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºç»Ÿè®¡éªŒè¯ä¸è¶³ä»¥åŠå¯¹ä¸åŒæ•°æ®é›†æ•ˆç‡ä¸æ³›åŒ–èƒ½åŠ›çš„æœ‰é™è€ƒè™‘ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†U-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡ã€ç»Ÿè®¡ä¸¥è°¨çš„åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°äº†100ç§U-Netå˜ä½“åœ¨28ä¸ªæ•°æ®é›†å’Œ10ç§æˆåƒæ¨¡æ€ä¸‹çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰ä¸‰æ–¹é¢ï¼šé¦–å…ˆï¼Œå…¨é¢è¯„ä¼°ï¼šU-Benchä»ä¸‰ä¸ªå…³é”®ç»´åº¦è¯„ä¼°æ¨¡å‹ï¼šç»Ÿè®¡ç¨³å¥æ€§ã€é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æŒ‡æ ‡U-Scoreï¼Œå®ƒè”åˆæ•æ‰æ€§èƒ½ä¸æ•ˆç‡çš„æƒè¡¡ï¼Œä¸ºæ¨¡å‹è¿›å±•æä¾›äº†é¢å‘éƒ¨ç½²çš„è§†è§’ã€‚å…¶æ¬¡ï¼Œç³»ç»Ÿåˆ†æä¸æ¨¡å‹é€‰æ‹©æŒ‡å—ï¼šæˆ‘ä»¬æ€»ç»“äº†å¤§è§„æ¨¡è¯„ä¼°çš„å…³é”®å‘ç°ï¼Œå¹¶å¯¹æ•°æ®é›†ç‰¹æ€§å’Œæ¶æ„èŒƒå¼å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“è¿›è¡Œäº†ç³»ç»Ÿåˆ†æã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¨¡å‹é¡¾é—®ä»£ç†ï¼ŒæŒ‡å¯¼ç ”ç©¶äººå‘˜ä¸ºç‰¹å®šæ•°æ®é›†å’Œä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ã€‚æœ€åï¼Œå…¬å…±å¯ç”¨æ€§ï¼šæˆ‘ä»¬æä¾›äº†æ‰€æœ‰ä»£ç ã€æ¨¡å‹ã€åè®®å’Œæƒé‡ï¼Œä½¿ç¤¾åŒºèƒ½å¤Ÿå¤åˆ¶æˆ‘ä»¬çš„ç»“æœå¹¶ç”¨æœªæ¥çš„æ–¹æ³•æ‰©å±•åŸºå‡†æµ‹è¯•ã€‚æ€»ä¹‹ï¼ŒU-Benchä¸ä»…æ­ç¤ºäº†ä»¥å¾€è¯„ä¼°ä¸­çš„å·®è·ï¼Œè¿˜ä¸ºæœªæ¥åå¹´U-NetåŸºåˆ†å‰²æ¨¡å‹çš„å…¬å¹³ã€å¯é‡å¤å’Œå®ç”¨åŸºå‡†æµ‹è¯•å¥ å®šäº†åŸºç¡€ã€‚é¡¹ç›®å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://fenghetan9.github.io/ubench">é“¾æ¥</a>è®¿é—®ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/FengheTan9/U-Bench">é“¾æ¥</a>æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>U-Netåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œè¡ç”Ÿå‡ºä¼—å¤šå˜ä½“ã€‚</li>
<li>ç¼ºä¹ç»¼åˆåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°U-Netå˜ä½“çš„æ€§èƒ½ã€‚</li>
<li>U-Benchä½œä¸ºé¦–ä¸ªå¤§è§„æ¨¡ã€ç»Ÿè®¡ä¸¥è°¨çš„åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°äº†U-Netå˜ä½“çš„æ€§èƒ½ã€‚</li>
<li>U-Benchä»ç»Ÿè®¡ç¨³å¥æ€§ã€é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ä¸‰ä¸ªç»´åº¦è¯„ä¼°æ¨¡å‹ã€‚</li>
<li>å¼•å…¥æ–°å‹è¯„ä¼°æŒ‡æ ‡U-Scoreï¼Œä»¥è¯„ä¼°æ€§èƒ½ä¸æ•ˆç‡çš„æƒè¡¡ã€‚</li>
<li>åŸºäºå¤§è§„æ¨¡è¯„ä¼°ç»“æœï¼Œæä¾›äº†æ¨¡å‹é€‰æ‹©æŒ‡å—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.07041">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bd3a320a58b3e97945d6cf0c56625171~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049714&auth_key=1760049714-0-0-97e0fe40968917731e691ab5910277f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7f0c8eb8974be795c862707e8be9311b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049721&auth_key=1760049721-0-0-4b9c759557984917703c86035309c80f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d48281532542ed263a3a3a87eaba3e11~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049728&auth_key=1760049728-0-0-6a103bb8faf007b8595e94ca178b4287&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d9675254518d7738bee85b677f88d5b4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049735&auth_key=1760049735-0-0-0e337771dfcea3b02b7b9ec1576d2863&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5fa7760d8e60f9d0394236866d44538b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049742&auth_key=1760049742-0-0-6c5e0d75ab98faf2f39df9ed25154545&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="1FLAT-a-Firmamento-based-catalog-of-AGN-in-Fermi-LAT-high-Galactic-latitude-Î³-ray-sources"><a href="#1FLAT-a-Firmamento-based-catalog-of-AGN-in-Fermi-LAT-high-Galactic-latitude-Î³-ray-sources" class="headerlink" title="1FLAT: a Firmamento-based catalog of AGN in Fermi-LAT high Galactic   latitude Î³-ray sources"></a>1FLAT: a Firmamento-based catalog of AGN in Fermi-LAT high Galactic   latitude Î³-ray sources</h2><p><strong>Authors:P. Giommi, M. Doro, M. GouvÃªa, L. Fronte, F. Metruccio, F. Arneodo, U. Barres de Almeida, S. Di Pippo, T. Kerscher, A. MacciÃ³, B. Mazzon, M. Morrone, E. Prandini, A. RodrÃ­guez, A. Ruina, N. Sahakyan, L. Silveri, D. Tripathi</strong></p>
<p>We present a systematic reassessment of 5,062 high-Galactic latitude gamma-ray sources from the Fermi-LAT 4FGL-DR4 catalog using Firmamento, a web-based platform for multi-frequency source discovery and analysis. Our goal is to provide an independent evaluation of LAT gamma-ray source associations through alternative spectral and spatial methods that combine recent and legacy survey data, supplemented by human supervision of spectral energy distributions (SEDs), source morphology, flux variability, and template-based comparisons. Firmamento confirms the 4FGL-DR4 and 4LAC-DR3 counterparts or unassociated sources in 4,493 cases (88.8%), demonstrating the robustness of both approaches. Beyond this general agreement, we identify 421 new blazar counterparts among previously unassociated sources, thereby reducing the fraction of unidentified extragalactic Fermi-LAT sources from 25% to 17%. In addition, in 64 cases we find alternative blazar associations, while in 49 instances we do not confirm the 4FGL-DR4 association. For all confirmed blazar counterparts we provide homogeneous estimates of synchrotron peak frequency and peak flux using machine-learning and template-based methods; these agree with 4LAC-DR3 values in most cases, though significant discrepancies appear for a few dozen sources, often due to improved X-ray coverage. The primary outcome of this work is the 1st Firmamento LAT AGN table (1FLAT), made publicly available through the Firmamento platform (<a target="_blank" rel="noopener" href="https://firmamento.nyuad.nyu.edu/">https://firmamento.nyuad.nyu.edu</a>), where all related multi-wavelength data and images are available. The project involved extensive manual validation and benefited from the active participation of graduate and undergraduate students, highlighting the platformâ€™s value for both research and education. </p>
<blockquote>
<p>æˆ‘ä»¬åˆ©ç”¨Firmamentoè¿™ä¸€åŸºäºç½‘ç»œçš„å¤šé¢‘ç‡æºå‘ç°ä¸åˆ†æå¹³å°ï¼Œå¯¹è´¹ç±³LAT 4FGL-DR4ç›®å½•ä¸­çš„5062ä¸ªé«˜é“¶é“çº¬åº¦ä¼½é©¬å°„çº¿æºè¿›è¡Œäº†ç³»ç»Ÿçš„é‡æ–°è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹å…‰è°±å’Œç©ºé—´æ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæä¾›å¯¹LATä¼½é©¬å°„çº¿æºå…³è”çš„ç‹¬ç«‹è¯„ä¼°ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†æœ€æ–°çš„å’Œä¼ ç»Ÿçš„è§‚æµ‹æ•°æ®ï¼Œè¾…ä»¥è°±èƒ½é‡åˆ†å¸ƒï¼ˆSEDsï¼‰ã€æºå½¢æ€ã€æµé‡å˜åŒ–å’ŒåŸºäºæ¨¡æ¿çš„æ¯”è¾ƒç­‰äººä¸ºç›‘ç£ã€‚Firmamentoç¡®è®¤äº†4FGL-DR4å’Œ4LAC-DR3çš„å¯¹åº”ç‰©æˆ–æœªå…³è”çš„æºåœ¨4493ä¸ªæ¡ˆä¾‹ä¸­çš„å­˜åœ¨ï¼ˆå 88.8%ï¼‰ï¼Œè¯æ˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„ç¨³å¥æ€§ã€‚é™¤äº†è¿™ç§æ™®éçš„ä¸€è‡´æ€§å¤–ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æœªå…³è”æºä¸­ç¡®å®šäº†421ä¸ªæ–°çš„è€€æ˜Ÿå¯¹åº”ç‰©ï¼Œä»è€Œå°†æœªè¯†åˆ«çš„è´¹ç±³LATå¤–æ˜Ÿç³»çš„æºæ¯”ä¾‹ä»25%é™è‡³17%ã€‚æ­¤å¤–ï¼Œåœ¨64ä¸ªæ¡ˆä¾‹ä¸­æˆ‘ä»¬æ‰¾åˆ°äº†æ›¿ä»£çš„è€€æ˜Ÿå…³è”ï¼Œè€Œåœ¨å¦å¤–49ä¸ªæ¡ˆä¾‹ä¸­æˆ‘ä»¬æ²¡æœ‰ç¡®è®¤å…¶å¯¹åº”äºå·²çŸ¥å¯¹è±¡çš„ä¿¡æ¯æ˜¯å¦å…³è”ä¸å®é™…çš„4FGL-DR4æœ‰æ‰€ä¸åŒã€‚å¯¹äºæ‰€æœ‰ç¡®è®¤çš„è€€æ˜Ÿå¯¹åº”ç‰©ï¼Œæˆ‘ä»¬ä½¿ç”¨æœºå™¨å­¦ä¹ å’ŒåŸºäºæ¨¡æ¿çš„æ–¹æ³•æä¾›äº†å…³äºåŒæ­¥å³°å€¼é¢‘ç‡å’Œå³°å€¼æµé‡çš„å‡åŒ€ä¼°è®¡å€¼ï¼›è¿™äº›åœ¨å¤šæ•°æƒ…å†µä¸‹ä¸å¤§å¤šæ•°æ¡ˆä¾‹ä¸­çš„å…±è¯†ç›¸ä¸€è‡´ã€‚æˆ‘ä»¬é€šè¿‡æ¯”è¾ƒè·å¾—å¤§é‡è¯æ®è¡¨æ˜å°‘é‡ä¾‹å¤–ä¸»è¦æ˜¯å—ç›Šäºæˆ‘ä»¬è¿›ä¸€æ­¥å®Œå–„çš„Xå°„çº¿è¦†ç›–èŒƒå›´å¾—åˆ°äº†æ˜¾è‘—æå‡å’Œå…³é”®çš„æ•°æ®æ ¡å‡†æŠ€æœ¯æå‡åŠå…·æœ‰æ·±è¿œè§è§£çš„ä¸“å®¶åˆ†æã€‚è¿™é¡¹å·¥ä½œçš„ä¸»è¦æˆæœæ˜¯é¦–ä¸ªFirmamento LAT AGNè¡¨ï¼ˆç®€ç§°â€œLATâ€ï¼‰ï¼Œé€šè¿‡Firmamentoå¹³å°å…¬å¼€æä¾›ï¼ˆç½‘å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://firmamento.nyuad.nyu.edu).æ‰€æœ¬ç»¼åˆå¤šçº¿æµ‹åº¦å®½åº¦çš„æ•°æ®å’Œå›¾åƒéƒ½é€šè¿‡è¯¥å¹³å°å…¬å¼€è®¿é—®å’Œä½¿ç”¨.è¿™ä¸€é¡¹ç›®çš„æ¨è¿›ä¹Ÿå¾—ç›Šäºå¤§é‡çš„ä¸“ä¸šå›¢é˜ŸåŠçŸ¥è¯†èµ„æºä»¥åŠè€—è´¹æ—¶é—´æ•°æ®çš„èµ„æ·±åˆ†æä»¥åŠå¤šæ–¹é¢çš„æ”¯æŒå’Œåä½œçš„æˆæœåœ¨æ­¤é¡¹ç›®çš„å®æ–½è¿‡ç¨‹ä¸­åŒ…å«äº†å¤§é‡æ‰‹å·¥æ“ä½œä»¥åŠä¸“å®¶çº§åˆ«çš„çŸ¥è¯†è¾…åŠ©å®ƒæ¶‰åŠçš„ç ”ç©¶åŒ…æ‹¬ä¸“ä¸šçŸ¥è¯†å’ŒæŠ€æœ¯æ”¯æŒåœ¨ä¸åŒé¢†åŸŸçš„æ·±åº¦åº”ç”¨å’Œèåˆå¼ºè°ƒå…¶ä»·å€¼ä¸ä»…åœ¨äºç§‘å­¦ç ”ç©¶åŒæ—¶ä¹Ÿå¯¹æ•™è‚²äº‹ä¸šæœ‰ç€ç§¯æçš„æ¨åŠ¨ä½œç”¨./">https://firmamento.nyuad.nyu.eduï¼‰ã€‚æ‰€æœ‰ç›¸å…³çš„å¤šæ³¢é•¿æ•°æ®å’Œå›¾åƒéƒ½åœ¨è¯¥å¹³å°å…¬å¼€è®¿é—®å’Œä½¿ç”¨ã€‚ï¼ˆé¡¹ç›®è¿˜åŒ…æ‹¬å¤§é‡çš„æ‰‹åŠ¨éªŒè¯æµç¨‹ï¼‰ï¼ŒåŒæ—¶å¾—ç›Šäºç ”ç©¶ç”Ÿå’Œæœ¬ç§‘ç”Ÿçš„ç§¯æå‚ä¸ä»è€Œå¼ºè°ƒäº†è¯¥å¹³å°å¯¹äºç ”ç©¶å’Œæ•™è‚²çš„ä»·å€¼ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06962v1">PDF</a> Accepted for publication in ApJS</p>
<p><strong>Summary</strong></p>
<p>è¿™æ˜¯ä¸€ç¯‡å…³äºä½¿ç”¨Firmamentoå¹³å°å¯¹é«˜é“¶é“çº¬åº¦ä¼½é©¬å°„çº¿æºè¿›è¡Œç³»ç»Ÿæ€§é‡æ–°è¯„ä¼°çš„ç ”ç©¶ã€‚è¯¥ç ”ç©¶æ—¨åœ¨é€šè¿‡ç»“åˆå¤šç§é¢‘è°±å’Œç©ºé—´æ–¹æ³•ï¼Œç»“åˆæœ€æ–°çš„è°ƒç ”æ•°æ®ï¼Œå¯¹4FGL-DR4ç›®å½•ä¸­çš„5,062ä¸ªä¼½é©¬å°„çº¿æºè¿›è¡Œç‹¬ç«‹è¯„ä¼°ã€‚é€šè¿‡è¿™ä¸€è¯„ä¼°ï¼Œç¡®è®¤äº†å¤§å¤šæ•°æºï¼ŒåŒæ—¶è¯†åˆ«å‡ºäº†ä¸€æ‰¹æ–°çš„è€€å‘å¯¹åº”ä½“ï¼Œé™ä½äº†æœªè¯†åˆ«çš„è´¹ç±³-LATå¤–æ˜Ÿæºçš„æ¯”ä¾‹ã€‚åŒæ—¶æä¾›äº†ç»Ÿä¸€çš„åŒæ­¥å³°å€¼é¢‘ç‡å’Œå³°å€¼æµé‡ä¼°è®¡ã€‚æœ€é‡è¦çš„æˆæœæ˜¯å…¬å¼€å¯ç”¨çš„Firmamentoå¹³å°ä¸Šçš„é¦–ä¸ªLAT AGNè¡¨ï¼ˆ1FLATï¼‰ï¼Œè¯¥å¹³å°æä¾›äº†æ‰€æœ‰ç›¸å…³çš„å¤šæ³¢é•¿æ•°æ®å’Œå›¾åƒã€‚æ­¤é¡¹ç›®æ¶‰åŠå¹¿æ³›çš„æ‰‹åŠ¨éªŒè¯ï¼Œå¹¶å¾—ç›Šäºå­¦ç”Ÿå’Œæœ¬ç§‘ç”Ÿç§¯æå‚ä¸ï¼Œçªæ˜¾äº†å…¶åœ¨ç ”ç©¶å’Œæ•™è‚²æ–¹é¢çš„ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä½¿ç”¨Firmamentoå¹³å°å¯¹é«˜é“¶é“çº¬åº¦ä¼½é©¬å°„çº¿æºè¿›è¡Œç³»ç»Ÿè¯„ä¼°ã€‚</li>
<li>å¯¹4FGL-DR4ç›®å½•ä¸­çš„ä¼½é©¬å°„çº¿æºè¿›è¡Œç‹¬ç«‹è¯„ä¼°ï¼Œç¡®è®¤å¤§å¤šæ•°æºå¹¶å‘ç°æ–°çš„è€€å‘å¯¹åº”ä½“ã€‚</li>
<li>é™ä½äº†æœªè¯†åˆ«çš„è´¹ç±³-LATå¤–æ˜Ÿæºçš„æ¯”ä¾‹ã€‚</li>
<li>ä¸ºæ‰€æœ‰ç¡®è®¤çš„è€€å‘å¯¹åº”ä½“æä¾›äº†ç»Ÿä¸€çš„åŒæ­¥å³°å€¼é¢‘ç‡å’Œå³°å€¼æµé‡ä¼°è®¡ã€‚</li>
<li>å…¬å¼€å¯ç”¨çš„Firmamentoå¹³å°ä¸Šçš„é¦–ä¸ªLAT AGNè¡¨ï¼ˆ1FLATï¼‰ã€‚</li>
<li>è¯¥é¡¹ç›®æ¶‰åŠå¹¿æ³›çš„æ‰‹åŠ¨éªŒè¯ï¼Œä»¥ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06962">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-1ab498cd591220a0af9540d57ea199c6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049749&auth_key=1760049749-0-0-eacb7eb615c6a10dd05f2bcc9fd8f331&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3afbdc7745af6d8106b9e2c886fa2cd2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049757&auth_key=1760049757-0-0-6c59dbd56554a536ab7dc7040da41de6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4ce8d0267fcaec62b4ca05890652f212~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049763&auth_key=1760049763-0-0-e237b28e9e2cc93d4b8e79205ecd4e96&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e13107133945b3279b76684a510bba06~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049771&auth_key=1760049771-0-0-2e97b8998dfc52c3bb56c80f09b2d943&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Lung-Infection-Severity-Prediction-Using-Transformers-with-Conditional-TransMix-Augmentation-and-Cross-Attention"><a href="#Lung-Infection-Severity-Prediction-Using-Transformers-with-Conditional-TransMix-Augmentation-and-Cross-Attention" class="headerlink" title="Lung Infection Severity Prediction Using Transformers with Conditional   TransMix Augmentation and Cross-Attention"></a>Lung Infection Severity Prediction Using Transformers with Conditional   TransMix Augmentation and Cross-Attention</h2><p><strong>Authors:Bouthaina Slika, Fadi Dornaika, Fares Bougourzi, Karim Hammoudi</strong></p>
<p>Lung infections, particularly pneumonia, pose serious health risks that can escalate rapidly, especially during pandemics. Accurate AI-based severity prediction from medical imaging is essential to support timely clinical decisions and optimize patient outcomes. In this work, we present a novel method applicable to both CT scans and chest X-rays for assessing lung infection severity. Our contributions are twofold: (i) QCross-Att-PVT, a Transformer-based architecture that integrates parallel encoders, a cross-gated attention mechanism, and a feature aggregator to capture rich multi-scale features; and (ii) Conditional Online TransMix, a custom data augmentation strategy designed to address dataset imbalance by generating mixed-label image patches during training. Evaluated on two benchmark datasets, RALO CXR and Per-COVID-19 CT, our method consistently outperforms several state-of-the-art deep learning models. The results emphasize the critical role of data augmentation and gated attention in improving both robustness and predictive accuracy. This approach offers a reliable, adaptable tool to support clinical diagnosis, disease monitoring, and personalized treatment planning. The source code of this work is available at <a target="_blank" rel="noopener" href="https://github.com/bouthainas/QCross-Att-PVT">https://github.com/bouthainas/QCross-Att-PVT</a>. </p>
<blockquote>
<p>è‚ºéƒ¨æ„ŸæŸ“ï¼Œå°¤å…¶æ˜¯è‚ºç‚ï¼Œä¼šå¸¦æ¥ä¸¥é‡çš„å¥åº·é£é™©ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§æµè¡ŒæœŸé—´ï¼Œè¿™äº›é£é™©å¯èƒ½ä¼šè¿…é€Ÿå‡çº§ã€‚å› æ­¤ï¼Œåˆ©ç”¨åŒ»å­¦å›¾åƒè¿›è¡Œå‡†ç¡®çš„AIä¸¥é‡ç¨‹åº¦é¢„æµ‹å¯¹äºæ”¯æŒåŠæ—¶çš„ä¸´åºŠå†³ç­–å’Œä¼˜åŒ–æ‚£è€…ç»“æœè‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯ç”¨äºCTæ‰«æå’Œèƒ¸éƒ¨Xå°„çº¿è¯„ä¼°è‚ºéƒ¨æ„ŸæŸ“ä¸¥é‡ç¨‹åº¦çš„æ–°å‹æ–¹æ³•ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰ä¸¤æ–¹é¢ï¼šï¼ˆiï¼‰QCross-Att-PVTï¼Œè¿™æ˜¯ä¸€ç§åŸºäºTransformerçš„æ¶æ„ï¼Œå®ƒé›†æˆäº†å¹¶è¡Œç¼–ç å™¨ã€äº¤å‰é—¨æ§æ³¨æ„æœºåˆ¶å’Œç‰¹å¾èšåˆå™¨ï¼Œä»¥æ•è·ä¸°å¯Œçš„å¤šå°ºåº¦ç‰¹å¾ï¼›ï¼ˆiiï¼‰Conditional Online TransMixï¼Œè¿™æ˜¯ä¸€ç§è‡ªå®šä¹‰çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆæ··åˆæ ‡ç­¾å›¾åƒè¡¥ä¸æ¥è§£å†³æ•°æ®é›†ä¸å¹³è¡¡é—®é¢˜ã€‚åœ¨RALO CXRå’ŒPer-COVID-19 CTä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ç»“æœå¼ºè°ƒäº†æ•°æ®å¢å¼ºå’Œé—¨æ§æ³¨æ„åœ¨æ”¹å–„ç¨³å¥æ€§å’Œé¢„æµ‹ç²¾åº¦æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚è¯¥æ–¹æ³•æä¾›äº†ä¸€ä¸ªå¯é ã€çµæ´»çš„å·¥å…·ï¼Œå¯æ”¯æŒä¸´åºŠè¯Šæ–­ã€ç–¾ç—…ç›‘æµ‹å’Œä¸ªæ€§åŒ–æ²»ç–—è®¡åˆ’ã€‚è¯¥å·¥ä½œçš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bouthainas/QCross-Att-PVT">https://github.com/bouthainas/QCross-Att-PVT</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06887v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºè¯„ä¼°è‚ºéƒ¨æ„ŸæŸ“ä¸¥é‡ç¨‹åº¦çš„å…¨æ–°æ–¹æ³•ï¼Œé€‚ç”¨äºCTæ‰«æå’Œèƒ¸éƒ¨Xå…‰ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŸºäºTransformerçš„æ¶æ„QCross-Att-PVTï¼Œèåˆäº†å¹¶è¡Œç¼–ç å™¨ã€äº¤å‰é—¨æ§æ³¨æ„æœºåˆ¶å’Œç‰¹å¾èšåˆå™¨ï¼Œä»¥æ•æ‰ä¸°å¯Œçš„å¤šå°ºåº¦ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†è‡ªå®šä¹‰æ•°æ®å¢å¼ºç­–ç•¥Conditional Online TransMixï¼Œä»¥è§£å†³æ•°æ®é›†ä¸å¹³è¡¡é—®é¢˜ã€‚åœ¨ä¸¤å®¶åŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå¤šä¸ªæœ€æ–°æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¼ºè°ƒäº†æ•°æ®å¢å¼ºå’Œé—¨æ§æ³¨æ„åœ¨æé«˜ç¨³å¥æ€§å’Œé¢„æµ‹ç²¾åº¦æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚æ­¤å·¥å…·å¯ä¸ºä¸´åºŠè¯Šæ–­ã€ç–¾ç—…ç›‘æµ‹å’Œä¸ªæ€§åŒ–æ²»ç–—è®¡åˆ’æä¾›å¯é æ”¯æŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§åŸºäºAIçš„æ–¹æ³•ç”¨äºè¯„ä¼°è‚ºéƒ¨æ„ŸæŸ“ä¸¥é‡æ€§ã€‚</li>
<li>æ–¹æ³•é‡‡ç”¨æ–°å‹æ¶æ„QCross-Att-PVTï¼Œæ•´åˆäº†å¤šç§æŠ€æœ¯å¦‚å¹¶è¡Œç¼–ç å™¨ã€äº¤å‰é—¨æ§æ³¨æ„æœºåˆ¶ä»¥åŠç‰¹å¾èšåˆå™¨ã€‚</li>
<li>æå‡ºæ•°æ®å¢å¼ºç­–ç•¥Conditional Online TransMixä»¥å¤„ç†æ•°æ®é›†ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
<li>åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–å…ˆè¿›æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</li>
<li>æ•°æ®å¢å¼ºå’Œé—¨æ§æ³¨æ„åœ¨æé«˜æ¨¡å‹çš„ç¨³å¥æ€§å’Œé¢„æµ‹ç²¾åº¦æ–¹é¢å‘æŒ¥äº†å…³é”®ä½œç”¨ã€‚</li>
<li>æ­¤æ–¹æ³•å¯ä½œä¸ºä¸´åºŠè¾…åŠ©è¯Šæ–­ã€ç–¾ç—…ç›‘æµ‹å’Œä¸ªæ€§åŒ–æ²»ç–—çš„æœ‰æ•ˆå·¥å…·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06887">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f9946ff17f81f50773bbd8cac2073b47~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049779&auth_key=1760049779-0-0-b090a26b0ec3695c31bfa444edc6cd9a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f8256a9152a94e76e1326133894724b8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049786&auth_key=1760049786-0-0-789158892974280f24bd787911b85def&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cd1ce5a876b30c0919df7672e524b756~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049792&auth_key=1760049792-0-0-f19598ba2e326c1b8e2b59d74b12e8f1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7e4c436ac5f510674cbe676065e934a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049798&auth_key=1760049798-0-0-50b80f9a76b73bef9b9252391c2cffaa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-74fff3e76c2db40ac1f1287207bc1a9f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049805&auth_key=1760049805-0-0-8841a495666f35b54100ea9b732ff800&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Hard-X-ray-view-of-two-Î³-ray-detected-low-luminosity-active-galactic-nuclei-NGC-315-and-NGC-4261"><a href="#Hard-X-ray-view-of-two-Î³-ray-detected-low-luminosity-active-galactic-nuclei-NGC-315-and-NGC-4261" class="headerlink" title="Hard X-ray view of two $Î³$-ray detected low-luminosity active   galactic nuclei: NGC 315 and NGC 4261"></a>Hard X-ray view of two $Î³$-ray detected low-luminosity active   galactic nuclei: NGC 315 and NGC 4261</h2><p><strong>Authors:Yuwei Yu, Jin Zhang</strong></p>
<p>Aims. The accretion disk of low-luminosity active galactic nuclei (LLAGNs) is a radiatively inefficient accretion flow (RIAF). Our goal is to find evidence of RIAF radiation from LLAGNs with jets and analyze their radiation properties, which also adds samples to future research on LLAGNs. Methods. Weconducted an analysis of the X-ray data obtained from NuSTAR and XMM-Newton observations of NGC 315 and NGC 4261, encompassing both timing and spectral investigations. The joint X-ray spectra of the two LLAGNs were fitted using various functional forms and radiative models in XSPEC. Results. No significant variability on timescales of days is observed for both NGC 315 and NGC 4261. The X-ray continuum emission of NGC 315 is suitable for cutoff power-law (PL) fitting, yielding a cutoff energy of Ecut &#x3D; 18.45 keV, which is the lowest value found in LLAGNssofar. In contrast, the X-ray continuum of NGC 4261 is composed of two PL components, with no signs of a cutoff energy. A prominent neutral Fe K{\alpha} line is observed in NGC 315, while an ionized Fe XXV line is seen in NGC 4261. The derived reflection fractions are R &#x3D; 0.61 for NGC 315 and R &#x3D; 0.18 for NGC 4579. Neither NGC 315 nor NGC 4261 shows evidence of a Compton reflection bump. Conclusions. The X-ray spectral characteristics support the RIAF emission as the dominant origin of the X-rays in both sources, although an additional soft PL component originating from the inner jet is observed in NGC 4261. The higher reflection fraction compared to other LLAGNs, along with the detection of a neutral Fe K{\alpha} line, suggests the existence of a truncated accretion disk with a relatively small radius in NGC 315. Bremsstrahlung radiation appears to be the dominant cooling mechanism for the plasma in NGC315, while Comptonization within the RIAF is more likely responsible for the X-ray emission in NGC 4261. </p>
<blockquote>
<p>æ‘˜è¦ã€‚ä½å…‰åº¦æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆLLAGNsï¼‰çš„å¸ç§¯ç›˜æ˜¯ä¸€ç§è¾å°„æ•ˆç‡è¾ƒä½çš„å¸ç§¯æµï¼ˆRIAFï¼‰ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯»æ‰¾LLAGNsä¸­æœ‰å–·æµçš„RIAFè¾å°„çš„è¯æ®ï¼Œå¹¶åˆ†æå…¶è¾å°„ç‰¹æ€§ï¼Œè¿™ä¹Ÿä¸ºLLAGNsçš„è¿›ä¸€æ­¥ç ”ç©¶å¢åŠ äº†æ ·æœ¬ã€‚æ–¹æ³•ã€‚æˆ‘ä»¬å¯¹NGC 315å’ŒNGC 4261çš„NuSTARå’ŒXMM-Newtonè§‚æµ‹æ‰€å¾—çš„Xå°„çº¿æ•°æ®è¿›è¡Œäº†åˆ†æï¼ŒåŒ…æ‹¬æ—¶åºå’Œå…‰è°±åˆ†æã€‚ä½¿ç”¨XSPECä¸­çš„å„ç§å‡½æ•°å½¢å¼å’Œè¾å°„æ¨¡å‹å¯¹è¿™ä¸¤ä¸ªLLAGNsçš„è”åˆXå°„çº¿å…‰è°±è¿›è¡Œæ‹Ÿåˆã€‚ç»“æœã€‚NGC 315å’ŒNGC 4261åœ¨å‡ å¤©çš„æ—¶é—´å°ºåº¦ä¸Šå‡æ²¡æœ‰è§‚å¯Ÿåˆ°æ˜¾è‘—çš„å˜åŒ–ã€‚NGC 315çš„Xå°„çº¿è¿ç»­è°±é€‚åˆç”¨æˆªæ­¢å¹‚å¾‹ï¼ˆPLï¼‰æ‹Ÿåˆï¼Œå¾—åˆ°æˆªæ­¢èƒ½é‡Ecut&#x3D;18.45 keVï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢åœ¨LLAGNsä¸­å‘ç°çš„æœ€ä½å€¼ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒNGC 4261çš„Xå°„çº¿è¿ç»­è°±ç”±ä¸¤ä¸ªPLåˆ†é‡ç»„æˆï¼Œæ²¡æœ‰æˆªæ­¢èƒ½é‡çš„è¿¹è±¡ã€‚åœ¨NGC 315ä¸­è§‚å¯Ÿåˆ°æ˜æ˜¾çš„ä¸­æ€§Fe KÎ±çº¿ï¼Œè€Œåœ¨NGC 4261ä¸­è§‚å¯Ÿåˆ°ç”µç¦»Fe XXVçº¿ã€‚æ¨å¯¼å‡ºçš„åå°„ç‡åˆ†åˆ«ä¸ºR&#x3D;0.61ï¼ˆNGC 315ï¼‰å’ŒR&#x3D;0.18ï¼ˆNGC 4579ï¼‰ã€‚NGC 315å’ŒNGC 4261å‡æ²¡æœ‰æ˜¾ç¤ºå‡ºåº·æ™®é¡¿åå°„å³°çš„è¯æ®ã€‚ç»“è®ºã€‚Xå°„çº¿å…‰è°±ç‰¹å¾æ”¯æŒRIAFå‘å°„æ˜¯è¿™ä¸¤ä¸ªæºXå°„çº¿çš„ä¸»è¦æ¥æºï¼Œå°½ç®¡åœ¨NGC 4261ä¸­è§‚å¯Ÿåˆ°æ¥è‡ªå†…éƒ¨å–·å°„å™¨çš„é¢å¤–è½¯PLåˆ†é‡ã€‚ä¸å…¶ä»–LLAGNsç›¸æ¯”ï¼Œè¾ƒé«˜çš„åå°„ç‡ä»¥åŠä¸­æ€§Fe KÎ±çº¿çš„æ£€æµ‹ï¼Œè¡¨æ˜NGC 315ä¸­å­˜åœ¨ä¸€ä¸ªåŠå¾„è¾ƒå°çš„æˆªæ–­å¸ç§¯ç›˜ã€‚NGC 315ä¸­çš„è½«è‡´è¾å°„ä¼¼ä¹æ˜¯ç­‰ç¦»å­ä½“ä¸»è¦çš„å†·å´æœºåˆ¶ï¼Œè€Œåœ¨NGC 4261ä¸­ï¼ŒRIAFå†…çš„åº·æ™®é¡¿åŒ–æ›´å¯èƒ½æ˜¯Xå°„çº¿å‘å°„çš„åŸå› ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06810v1">PDF</a> 11 pages, 6 figures, 6 tables</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ç ”ç©¶ä½å…‰åº¦æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆLLAGNsï¼‰çš„è¾å°„ç‰¹æ€§ï¼Œç‰¹åˆ«æ˜¯å…¶å°„æµè¾å°„çš„è¯æ®ã€‚é€šè¿‡å¯¹NGC 315å’ŒNGC 4261çš„Xå°„çº¿æ•°æ®è¿›è¡Œåˆ†æï¼Œå‘ç°ä¸¤è€…çš„Xå°„çº¿è¿ç»­å‘å°„ä¸RIAFï¼ˆè¾å°„ä½æ•ˆå¸ç§¯æµï¼‰ç›¸å…³ã€‚NGC 315çš„Xå°„çº¿è¿ç»­å‘å°„é€‚åˆç”¨æˆªæ–­å¹‚å¾‹æ‹Ÿåˆï¼Œè€ŒNGC 4261åˆ™åŒ…å«ä¸¤ä¸ªå¹‚å¾‹æˆåˆ†ã€‚ä¸¤è€…å‡æœªæ˜¾ç¤ºåº·æ™®é¡¿åå°„å³°çš„è¯æ®ã€‚ç ”ç©¶ç»“æœæ”¯æŒRIAFè¾å°„æ˜¯è¿™ä¸¤ä¸ªæºXå°„çº¿çš„ä¸»è¦æ¥æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLAGNsçš„è¾å°„ç‰¹æ€§ç ”ç©¶æ—¨åœ¨å¯»æ‰¾RIAFçš„è¯æ®ï¼Œå¹¶å¢åŠ å¯¹æœªæ¥LLAGNsç ”ç©¶çš„æ ·æœ¬ã€‚</li>
<li>å¯¹NGC 315å’ŒNGC 4261çš„Xå°„çº¿æ•°æ®è¿›è¡Œäº†æ—¶åºå’Œå…‰è°±åˆ†æã€‚</li>
<li>NGC 315çš„Xå°„çº¿è¿ç»­å‘å°„é€‚åˆç”¨æˆªæ–­å¹‚å¾‹æ¨¡å‹æ‹Ÿåˆï¼Œæˆªæ–­èƒ½é‡Ecutè¾ƒä½ã€‚</li>
<li>NGC 4261çš„Xå°„çº¿è¿ç»­å‘å°„åŒ…å«ä¸¤ä¸ªå¹‚å¾‹æˆåˆ†ï¼Œæœªå‘ç°æˆªæ–­èƒ½é‡ã€‚</li>
<li>ä¸­æ€§Fe KÎ±çº¿åœ¨NGC 315ä¸­æ˜æ˜¾å¯è§ï¼Œè€Œåœ¨NGC 4261ä¸­è§‚å¯Ÿåˆ°ç”µç¦»çš„Fe XXVçº¿ã€‚</li>
<li>åå°„åˆ†æ•°Råœ¨NGC 315ä¸­è¾ƒé«˜ï¼Œæš—ç¤ºå­˜åœ¨æˆªæ–­åŠå¾„è¾ƒå°çš„å¸ç§¯ç›˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06810">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ad5082826c603317c44c8df81709b187~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049813&auth_key=1760049813-0-0-425faffe9e178bda2a4fd8296a20f3d5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-650321aade243f73c73a6fc3c4d9be53~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049820&auth_key=1760049820-0-0-e8691db1d40c9aa60c5ebe0780eed4f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5556c2f14abe5c2b213e11f562f3d226~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049827&auth_key=1760049827-0-0-4db4711a5db5fab8fe5cd730f71baffb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2775a98f1a7905a069c0ad335fad9484~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049834&auth_key=1760049834-0-0-1bc2d2bb80eeb93760254020288c7044&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-840c5ebf427d5a1ad2ac448c8b4e5415~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049840&auth_key=1760049840-0-0-1bca8abb4043b3b00b50f6c35bd0f8f4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c21d276a8349fa750e0ea72adcaa8a43~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049847&auth_key=1760049847-0-0-8f4c0556bf9d7ef57614327002adce20&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e29e6d06ea166f52b2439725d2be5ce3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049854&auth_key=1760049854-0-0-89dadbfc6841476bbf53322e84633381&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Fitzpatrick-Thresholding-for-Skin-Image-Segmentation"><a href="#Fitzpatrick-Thresholding-for-Skin-Image-Segmentation" class="headerlink" title="Fitzpatrick Thresholding for Skin Image Segmentation"></a>Fitzpatrick Thresholding for Skin Image Segmentation</h2><p><strong>Authors:Duncan Stothers, Sophia Xu, Carlie Reeves, Lia Gracey</strong></p>
<p>Accurate estimation of the body surface area (BSA) involved by a rash, such as psoriasis, is critical for assessing rash severity, selecting an initial treatment regimen, and following clinical treatment response. Attempts at segmentation of inflammatory skin disease such as psoriasis perform markedly worse on darker skin tones, potentially impeding equitable care. We assembled a psoriasis dataset sourced from six public atlases, annotated for Fitzpatrick skin type, and added detailed segmentation masks for every image. Reference models based on U-Net, ResU-Net, and SETR-small are trained without tone information. On the tuning split we sweep decision thresholds and select (i) global optima and (ii) per Fitzpatrick skin tone optima for Dice and binary IoU. Adapting Fitzpatrick specific thresholds lifted segmentation performance for the darkest subgroup (Fitz VI) by up to +31 % bIoU and +24 % Dice on UNet, with consistent, though smaller, gains in the same direction for ResU-Net (+25 % bIoU, +18 % Dice) and SETR-small (+17 % bIoU, +11 % Dice). Because Fitzpatrick skin tone classifiers trained on Fitzpatrick-17k now exceed 95 % accuracy, the cost of skin tone labeling required for this technique has fallen dramatically. Fitzpatrick thresholding is simple, model-agnostic, requires no architectural changes, no re-training, and is virtually cost free. We demonstrate the inclusion of Fitzpatrick thresholding as a potential future fairness baseline. </p>
<blockquote>
<p>å‡†ç¡®ä¼°è®¡ä½“è¡¨é¢ç§¯ï¼ˆBSAï¼‰çš„çš®ç‚ç—…å˜åŒºåŸŸï¼Œå¦‚ç‰›çš®ç™£ç­‰ï¼Œå¯¹äºè¯„ä¼°çš®ç‚ä¸¥é‡ç¨‹åº¦ã€é€‰æ‹©åˆå§‹æ²»ç–—æ–¹æ¡ˆä»¥åŠè·Ÿè¸ªä¸´åºŠæ²»ç–—ååº”è‡³å…³é‡è¦ã€‚å¯¹ç‰›çš®ç™£ç­‰ç‚ç—‡æ€§çš®è‚¤ç–¾ç—…è¿›è¡Œåˆ†å‰²çš„å°è¯•åœ¨æ·±è‰²è‚¤è‰²ä¸Šçš„è¡¨ç°æ˜æ˜¾è¾ƒå·®ï¼Œå¯èƒ½é˜»ç¢å…¬å¹³çš„åŒ»ç–—æŠ¤ç†ã€‚æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªç‰›çš®ç™£æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ¥æºäºå…­ä¸ªå…¬å¼€å›¾è°±ï¼Œæ ¹æ®Fitzpatrickçš®è‚¤ç±»å‹è¿›è¡Œæ ‡æ³¨ï¼Œå¹¶ä¸ºæ¯å¼ å›¾åƒæ·»åŠ äº†è¯¦ç»†çš„åˆ†å‰²æ©è†œã€‚åŸºäºU-Netã€ResU-Netå’ŒSETR-smallçš„å‚è€ƒæ¨¡å‹åœ¨ä¸ä½¿ç”¨è‚¤è‰²ä¿¡æ¯çš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒã€‚åœ¨è°ƒä¼˜åˆ†å‰²æ—¶ï¼Œæˆ‘ä»¬è°ƒæ•´å†³ç­–é˜ˆå€¼ï¼Œå¹¶é€‰æ‹©ï¼ˆiï¼‰å…¨å±€æœ€ä¼˜å’Œï¼ˆiiï¼‰é’ˆå¯¹Fitzpatrickçš®è‚¤ç±»å‹çš„æœ€ä¼˜é˜ˆå€¼ï¼Œä»¥è¿›è¡ŒDiceå’ŒäºŒè¿›åˆ¶IoUè¯„ä¼°ã€‚é€‚åº”Fitzpatrickç‰¹å®šé˜ˆå€¼æé«˜äº†æœ€æš—äºšç»„ï¼ˆFitz VIï¼‰çš„åˆ†å‰²æ€§èƒ½ï¼Œåœ¨UNetä¸ŠbIoUæé«˜äº†+31%ï¼ŒDiceæé«˜äº†+24%ï¼ŒResU-Netå’ŒSETR-smallä¹Ÿæœ‰ä¸€è‡´ä¸”è¾ƒå°çš„æå‡ï¼ˆ+25% bIoUï¼Œ+18% Diceå’Œ+17% bIoUï¼Œ+11% Diceï¼‰ã€‚ç”±äºåŸºäºFitzpatrick-17kè®­ç»ƒçš„Fitzpatrickçš®è‚¤è‰²è°ƒåˆ†ç±»å™¨çš„å‡†ç¡®ç‡ç°åœ¨è¶…è¿‡95%ï¼Œå› æ­¤è¿™é¡¹æŠ€æœ¯æ‰€éœ€çš„è‚¤è‰²æ ‡ç­¾æˆæœ¬å·²å¤§å¹…ä¸‹é™ã€‚Fitzpatrické˜ˆå€¼è®¾ç½®ç®€å•ï¼Œä¸æ¨¡å‹æ— å…³ï¼Œä¸éœ€è¦è¿›è¡Œæ¶æ„æ›´æ”¹ã€é‡æ–°è®­ç»ƒï¼Œå¹¶ä¸”å‡ ä¹æ— éœ€æˆæœ¬ã€‚æˆ‘ä»¬å±•ç¤ºäº†å°†Fitzpatrické˜ˆå€¼è®¾ç½®ä½œä¸ºæœªæ¥å…¬å¹³åŸºå‡†çº¿çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06655v1">PDF</a> Accepted to MICCAI 2025 ISIC Workshop. 24 minute Oral presentation   given. Awarded â€œBest Paper - Honorable Mentionâ€</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡å…³æ³¨äºå‡†ç¡®ä¼°ç®—ç”±çš®ç‚ï¼ˆå¦‚é“¶å±‘ç—…ï¼‰å¼•èµ·çš„ä½“è¡¨é¢ç§¯ï¼ˆBSAï¼‰ï¼Œè¿™å¯¹è¯„ä¼°çš®ç‚ä¸¥é‡ç¨‹åº¦ã€é€‰æ‹©åˆå§‹æ²»ç–—æ–¹æ¡ˆä»¥åŠè·Ÿè¸ªä¸´åºŠæ²»ç–—ååº”è‡³å…³é‡è¦ã€‚é’ˆå¯¹è‚¤è‰²è¾ƒæš—çš„äººç¾¤ï¼Œçš®ç‚ç­‰ç‚ç—‡æ€§çš®è‚¤ç—…çš„åˆ†å‰²æ•ˆæœè¾ƒå·®ï¼Œå¯èƒ½å½±å“å…¬å¹³æŠ¤ç†ã€‚æœ¬ç ”ç©¶æ”¶é›†äº†ä¸€ä¸ªåŒ…å«å…­ç§å…¬å¼€å›¾è°±çš„é“¶å±‘ç—…æ•°æ®é›†ï¼ŒæŒ‰Fitzpatrickçš®è‚¤ç±»å‹è¿›è¡Œæ ‡æ³¨ï¼Œå¹¶ä¸ºæ¯å¼ å›¾åƒæ·»åŠ äº†è¯¦ç»†çš„åˆ†å‰²æ©è†œã€‚åŸºäºU-Netã€ResU-Netå’ŒSETR-smallçš„å‚è€ƒæ¨¡å‹åœ¨ä¸ä½¿ç”¨è‚¤è‰²ä¿¡æ¯çš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒã€‚åœ¨è°ƒæ•´åˆ†å‰²é˜ˆå€¼æ—¶ï¼Œæˆ‘ä»¬é€‰æ‹©äº†å…¨å±€æœ€ä¼˜å’Œé’ˆå¯¹Fitzpatrickçš®è‚¤ç±»å‹çš„æœ€ä¼˜é˜ˆå€¼ï¼Œä»¥è¯„ä¼°Diceå’ŒäºŒè¿›åˆ¶IoUã€‚é€‚åº”Fitzpatrickç‰¹å®šé˜ˆå€¼å¯æé«˜æœ€æš—äºšç»„ï¼ˆFitz VIï¼‰çš„åˆ†å‰²æ€§èƒ½ï¼Œåœ¨UNetä¸ŠbIoUå’ŒDiceåˆ†åˆ«æé«˜äº†+31%å’Œ+24%ï¼ŒResU-Netå’ŒSETR-smallä¹Ÿæœ‰ç±»ä¼¼çš„æé«˜ã€‚ç”±äºåŸºäºFitzpatrick-17kè®­ç»ƒçš„Fitzpatrickçš®è‚¤è‰²è°ƒåˆ†ç±»å™¨çš„å‡†ç¡®åº¦ç°åœ¨è¶…è¿‡äº†95%ï¼Œå› æ­¤æ­¤æŠ€æœ¯æ‰€éœ€çš„è‚¤è‰²æ ‡ç­¾æˆæœ¬å·²å¤§å¹…ä¸‹é™ã€‚Fitzpatrické˜ˆå€¼è®¾ç½®ç®€å•ï¼Œæ¨¡å‹é€šç”¨æ€§å¼ºï¼Œæ— éœ€è¿›è¡Œæ¶æ„æ›´æ”¹æˆ–é‡æ–°è®­ç»ƒï¼Œä¸”å‡ ä¹æ— éœ€æˆæœ¬ã€‚æˆ‘ä»¬å±•ç¤ºäº†å°†Fitzpatrické˜ˆå€¼è®¾ç½®ä½œä¸ºæœªæ¥å…¬å¹³æ€§çš„åŸºå‡†çš„æ½œåŠ›ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å‡†ç¡®ä¼°ç®—çš®ç‚æ¶‰åŠçš„ä½“è¡¨é¢ç§¯å¯¹äºè¯„ä¼°çš®ç‚ä¸¥é‡ç¨‹åº¦å’Œæ²»ç–—ååº”è‡³å…³é‡è¦ã€‚</li>
<li>åœ¨è‚¤è‰²è¾ƒæš—çš„äººç¾¤ä¸­ï¼Œçš®ç‚åˆ†å‰²æ•ˆæœè¾ƒå·®ï¼Œå¯èƒ½å½±å“å…¬å¹³æŠ¤ç†ã€‚</li>
<li>ç ”ç©¶æ”¶é›†äº†åŒ…å«å¤šç§å›¾åƒçš„é“¶å±‘ç—…æ•°æ®é›†ï¼Œå¹¶æŒ‰Fitzpatrickçš®è‚¤ç±»å‹æ ‡æ³¨ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨äº†U-Netã€ResU-Netå’ŒSETR-smallæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€ä½¿ç”¨è‚¤è‰²ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡é€‚åº”Fitzpatrickç‰¹å®šé˜ˆå€¼ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æœ€æš—è‚¤è‰²çš„äºšç»„çš„åˆ†å‰²æ€§èƒ½ã€‚</li>
<li>Fitzpatrickçš®è‚¤è‰²è°ƒåˆ†ç±»å™¨çš„å‡†ç¡®åº¦ç°åœ¨è¶…è¿‡äº†95%ï¼Œé™ä½äº†è‚¤è‰²æ ‡ç­¾çš„æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06655">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b7cd94a9b27bd64e75683ac98d5fbf8c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049861&auth_key=1760049861-0-0-362a3af6d56a2d6c59d1c4e1ac6594c8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-50e355081ab0dedec62ef730e8b21aa5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049868&auth_key=1760049868-0-0-4ce35fb1f7250cfa21b0c50b8c581dcf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-91071309cc62cb43acf405afeab2931c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049874&auth_key=1760049874-0-0-2fcbf766d7105987c95d58ed151972cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d83000f3fee33906f45d18fd6c6d3bf4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083478&auth_key=1760083478-0-0-85977bdefbd7a0820b03474fb24e3b54&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3fd89aadaa0d2004aa4d2af8abb269d7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083485&auth_key=1760083485-0-0-dc9c3f482229f2d664a7d2dafd6f8b78&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="FEAorta-A-Fully-Automated-Framework-for-Finite-Element-Analysis-of-the-Aorta-From-3D-CT-Images"><a href="#FEAorta-A-Fully-Automated-Framework-for-Finite-Element-Analysis-of-the-Aorta-From-3D-CT-Images" class="headerlink" title="FEAorta: A Fully Automated Framework for Finite Element Analysis of the   Aorta From 3D CT Images"></a>FEAorta: A Fully Automated Framework for Finite Element Analysis of the   Aorta From 3D CT Images</h2><p><strong>Authors:Jiasong Chen, Linchen Qian, Ruonan Gong, Christina Sun, Tongran Qin, Thuy Pham, Caitlin Martin, Mohammad Zafar, John Elefteriades, Wei Sun, Liang Liang</strong></p>
<p>Aortic aneurysm disease ranks consistently in the top 20 causes of death in the U.S. population. Thoracic aortic aneurysm is manifested as an abnormal bulging of thoracic aortic wall and it is a leading cause of death in adults. From the perspective of biomechanics, rupture occurs when the stress acting on the aortic wall exceeds the wall strength. Wall stress distribution can be obtained by computational biomechanical analyses, especially structural Finite Element Analysis. For risk assessment, probabilistic rupture risk of TAA can be calculated by comparing stress with material strength using a material failure model. Although these engineering tools are currently available for TAA rupture risk assessment on patient specific level, clinical adoption has been limited due to two major barriers: labor intensive 3D reconstruction current patient specific anatomical modeling still relies on manual segmentation, making it time consuming and difficult to scale to a large patient population, and computational burden traditional FEA simulations are resource intensive and incompatible with time sensitive clinical workflows. The second barrier was successfully overcome by our team through the development of the PyTorch FEA library and the FEA DNN integration framework. By incorporating the FEA functionalities within PyTorch FEA and applying the principle of static determinacy, we reduced the FEA based stress computation time to approximately three minutes per case. Moreover, by integrating DNN and FEA through the PyTorch FEA library, our approach further decreases the computation time to only a few seconds per case. This work focuses on overcoming the first barrier through the development of an end to end deep neural network capable of generating patient specific finite element meshes of the aorta directly from 3D CT images. </p>
<blockquote>
<p>ä¸»åŠ¨è„‰ç˜¤ç–¾ç—…ä¸€ç›´æ˜¯ç¾å›½äººå£æ­»äº¡åŸå› çš„å‰20åä¹‹ä¸€ã€‚èƒ¸ä¸»åŠ¨è„‰ç˜¤è¡¨ç°ä¸ºèƒ¸ä¸»åŠ¨è„‰å£å¼‚å¸¸å‡¸èµ·ï¼Œæ˜¯æˆäººæ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚ä»ç”Ÿç‰©åŠ›å­¦è§’åº¦çœ‹ï¼Œå½“ä½œç”¨äºä¸»åŠ¨è„‰å£çš„åº”åŠ›è¶…è¿‡å…¶å¼ºåº¦æ—¶ï¼Œå°±ä¼šå‘ç”Ÿç ´è£‚ã€‚é€šè¿‡è®¡ç®—ç”Ÿç‰©åŠ›å­¦åˆ†æï¼Œç‰¹åˆ«æ˜¯ç»“æ„æœ‰é™å…ƒåˆ†æï¼Œå¯ä»¥è·å¾—å£åº”åŠ›åˆ†å¸ƒã€‚å¯¹äºé£é™©è¯„ä¼°ï¼Œé€šè¿‡ææ–™å¤±æ•ˆæ¨¡å‹æ¯”è¾ƒåº”åŠ›ä¸ææ–™å¼ºåº¦ï¼Œå¯ä»¥è®¡ç®—èƒ¸ä¸»åŠ¨è„‰ç˜¤çš„ç ´è£‚æ¦‚ç‡ã€‚å°½ç®¡ç›®å‰è¿™äº›å·¥ç¨‹å·¥å…·å¯ç”¨äºé’ˆå¯¹ç‰¹å®šæ‚£è€…çš„èƒ¸ä¸»åŠ¨è„‰ç˜¤ç ´è£‚é£é™©è¯„ä¼°ï¼Œä½†ç”±äºä¸¤å¤§éšœç¢ï¼Œä¸´åºŠé‡‡ç”¨å—åˆ°äº†é™åˆ¶ï¼šä¸€æ˜¯ç›®å‰é’ˆå¯¹ç‰¹å®šæ‚£è€…çš„è§£å‰–æ¨¡å‹é‡å»ºä»ä¾èµ–äºæ‰‹åŠ¨åˆ†å‰²ï¼Œè¿™ä½¿å¾—å…¶è€—æ—¶ä¸”éš¾ä»¥æ‰©å±•åˆ°å¤§é‡æ‚£è€…ï¼›äºŒæ˜¯ä¼ ç»Ÿæœ‰é™å…ƒåˆ†ææ¨¡æ‹Ÿè®¡ç®—é‡å¤§ï¼Œä¸ç¬¦åˆæ—¶é—´æ•æ„Ÿçš„ä¸´åºŠå·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬å›¢é˜ŸæˆåŠŸå…‹æœäº†ç¬¬äºŒä¸ªéšœç¢ï¼Œé€šè¿‡å¼€å‘PyTorchæœ‰é™å…ƒåº“å’Œæœ‰é™å…ƒæ·±åº¦ç¥ç»ç½‘ç»œé›†æˆæ¡†æ¶ã€‚é€šè¿‡åœ¨PyTorchæœ‰é™å…ƒåº“ä¸­èå…¥æœ‰é™å…ƒåŠŸèƒ½å¹¶åº”ç”¨é™å®šåŸç†ï¼Œæˆ‘ä»¬å°†åŸºäºæœ‰é™å…ƒçš„åº”åŠ›è®¡ç®—æ—¶é—´å‡å°‘åˆ°å¤§çº¦æ¯ä¾‹ä¸‰åˆ†é’Ÿã€‚æ­¤å¤–ï¼Œé€šè¿‡æ·±åº¦ç¥ç»ç½‘ç»œä¸æœ‰é™å…ƒåˆ†æé›†æˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†è®¡ç®—æ—¶é—´è¿›ä¸€æ­¥é™ä½åˆ°æ¯ä¾‹ä»…å‡ ç§’é’Ÿã€‚æœ¬å·¥ä½œä¸“æ³¨äºå¼€å‘ç«¯åˆ°ç«¯çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œä»¥å…‹æœç¬¬ä¸€ä¸ªéšœç¢ï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿä»3D CTå›¾åƒç›´æ¥ç”Ÿæˆé’ˆå¯¹ç‰¹å®šæ‚£è€…çš„æœ‰é™å…ƒç´ ç½‘æ ¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06621v1">PDF</a> </p>
<p><strong>Summary</strong><br>     ä¸»åŠ¨è„‰åŠ¨è„‰ç˜¤ç–¾ç—…æ˜¯ç¾å›½äººå£æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚ä»ç”Ÿç‰©åŠ›å­¦è§’åº¦çœ‹ï¼Œèƒ¸ä¸»åŠ¨è„‰ç˜¤çš„ç ´è£‚æ˜¯å› ä¸ºä¸»åŠ¨è„‰å£ä¸Šçš„åº”åŠ›è¶…è¿‡äº†å…¶æ‰¿å—åŠ›ã€‚æœ¬æ–‡å¼€å‘äº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç”¨äºç›´æ¥ä»3D CTå›¾åƒç”Ÿæˆæ‚£è€…çš„ç‰¹å®šæœ‰é™å…ƒç½‘æ ¼æ¨¡å‹ï¼Œå…‹æœäº†å½“å‰è¯„ä¼°èƒ¸ä¸»åŠ¨è„‰ç˜¤ç ´è£‚é£é™©çš„ä¸¤å¤§éšœç¢ï¼Œæé«˜äº†è¯„ä¼°æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸»åŠ¨è„‰åŠ¨è„‰ç˜¤ç–¾ç—…æ˜¯ç¾å›½äººå£æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œç‰¹åˆ«æ˜¯åœ¨æˆäººç¾¤ä½“ä¸­ã€‚</li>
<li>ä»ç”Ÿç‰©åŠ›å­¦è§’åº¦çœ‹ï¼Œèƒ¸ä¸»åŠ¨è„‰ç˜¤çš„ç ´è£‚æ˜¯å› ä¸ºä¸»åŠ¨è„‰å£ä¸Šçš„åº”åŠ›è¶…è¿‡äº†å…¶æ‰¿å—åŠ›ã€‚</li>
<li>èƒ¸ä¸»åŠ¨è„‰ç˜¤ç ´è£‚é£é™©çš„è¯„ä¼°å—é™äºä¸¤ä¸ªä¸»è¦éšœç¢ï¼šå½“å‰æ‚£è€…ç‰¹å®šè§£å‰–æ¨¡å‹çš„å»ºç«‹ä¾èµ–äºæ‰‹åŠ¨åˆ†å‰²ï¼Œè¿‡ç¨‹è€—æ—¶ä¸”éš¾ä»¥åº”ç”¨äºå¤§è§„æ¨¡æ‚£è€…ç¾¤ä½“ï¼›ä¼ ç»Ÿçš„æœ‰é™å…ƒåˆ†æï¼ˆFEAï¼‰æ¨¡æ‹Ÿè®¡ç®—é‡å¤§ï¼Œä¸é€‚ç”¨äºæ—¶é—´æ•æ„Ÿçš„ä¸´åºŠå·¥ä½œæµç¨‹ã€‚</li>
<li>å¼€å‘PyTorch FEAåº“å’ŒFEAæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰é›†æˆæ¡†æ¶æˆåŠŸå…‹æœäº†ç¬¬äºŒä¸ªéšœç¢ï¼Œå°†æœ‰é™å…ƒåˆ†æçš„åº”åŠ›è®¡ç®—æ—¶é—´å‡å°‘åˆ°å¤§çº¦æ¯ä¾‹ä¸‰åˆ†é’Ÿã€‚</li>
<li>é€šè¿‡åœ¨PyTorch FEAåº“ä¸­é›†æˆDNNå’ŒFEAï¼Œè¿›ä¸€æ­¥å°†è®¡ç®—æ—¶é—´å‡å°‘åˆ°æ¯ä¾‹ä»…å‡ ç§’é’Ÿã€‚</li>
<li>æœ¬æ–‡çš„é‡ç‚¹æ˜¯å¼€å‘ä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿç›´æ¥ä»3D CTå›¾åƒç”Ÿæˆæ‚£è€…çš„ç‰¹å®šæœ‰é™å…ƒç½‘æ ¼æ¨¡å‹ï¼Œä»¥å…‹æœç¬¬ä¸€ä¸ªéšœç¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06621">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a112059b3e05068959da39b04655a631~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083493&auth_key=1760083493-0-0-0b4c81a1a5a8a9f7cad0222dbea40041&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ff6e4c3f2b28d754aa41a7ff4b1e01a4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083500&auth_key=1760083500-0-0-68049adfca0e27735be89cfc3f73ad47&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5febed2a3cd59f3cd1309403ab6fc13f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099827&auth_key=1760099827-0-0-4008538c92b499d5967475b1cb6e421b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Self-supervised-Physics-guided-Model-with-Implicit-Representation-Regularization-for-Fast-MRI-Reconstruction"><a href="#Self-supervised-Physics-guided-Model-with-Implicit-Representation-Regularization-for-Fast-MRI-Reconstruction" class="headerlink" title="Self-supervised Physics-guided Model with Implicit Representation   Regularization for Fast MRI Reconstruction"></a>Self-supervised Physics-guided Model with Implicit Representation   Regularization for Fast MRI Reconstruction</h2><p><strong>Authors:Jingran Xu, Yuanyuan Liu, Yanjie Zhu</strong></p>
<p>Magnetic Resonance Imaging (MRI) is a vital clinical diagnostic tool, yet its widespread application is limited by prolonged scan times. Fast MRI reconstruction techniques effectively reduce acquisition duration by reconstructing high-fidelity MR images from undersampled k-space data. In recent years, deep learning-based methods have demonstrated remarkable progress in this field, with self-supervised and unsupervised learning approaches proving particularly valuable in scenarios where fully sampled data are difficult to obtain. This paper proposes a novel zero-shot self-supervised reconstruction framework named UnrollINR, which enables scan-specific MRI reconstruction without relying on external training data. The method adopts a physics-guided unrolled iterative reconstruction architecture and introduces Implicit Neural Representation (INR) as a regularization prior to effectively constrain the solution space. By combining a deep unrolled structure with the powerful implicit representation capability of INR, the modelâ€™s interpretability and reconstruction performance are enhanced. Experimental results demonstrate that even at a high acceleration rate of 10, UnrollINR achieves superior reconstruction performance compared to the supervised learning method, validating the superiority of the proposed method. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ä¸€ç§é‡è¦çš„ä¸´åºŠè¯Šæ–­å·¥å…·ï¼Œä½†å…¶å¹¿æ³›åº”ç”¨å—é™äºæ‰«ææ—¶é—´çš„å»¶é•¿ã€‚å¿«é€ŸMRIé‡å»ºæŠ€æœ¯é€šè¿‡ä»æ¬ é‡‡æ ·çš„kç©ºé—´æ•°æ®ä¸­é‡å»ºé«˜ä¿çœŸMRå›¾åƒï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†é‡‡é›†æ—¶é—´ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨è¯¥é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œè‡ªç›‘ç£å’Œæ— ç›‘ç£çš„å­¦ä¹ æ–¹æ³•åœ¨éš¾ä»¥è·å–å…¨é‡‡æ ·æ•°æ®çš„æƒ…å†µä¸‹ï¼Œç‰¹åˆ«å…·æœ‰ä»·å€¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„é›¶æ ·æœ¬è‡ªç›‘ç£é‡å»ºæ¡†æ¶ï¼Œåä¸ºUnrollINRï¼Œå®ƒèƒ½å¤Ÿåœ¨ä¸ä¾èµ–å¤–éƒ¨è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°ç‰¹å®šæ‰«æçš„MRIé‡å»ºã€‚è¯¥æ–¹æ³•é‡‡ç”¨ç‰©ç†å¼•å¯¼å±•å¼€çš„è¿­ä»£é‡å»ºæ¶æ„ï¼Œå¹¶å¼•å…¥éšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰ä½œä¸ºæ­£åˆ™åŒ–å…ˆéªŒï¼Œä»¥æœ‰æ•ˆåœ°çº¦æŸè§£ç©ºé—´ã€‚é€šè¿‡å°†æ·±åº¦å±•å¼€ç»“æ„ä¸INRçš„å¼ºå¤§éšå¼è¡¨ç¤ºèƒ½åŠ›ç›¸ç»“åˆï¼Œæé«˜äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œé‡å»ºæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨é«˜è¾¾10å€çš„åŠ é€Ÿç‡ä¸‹ï¼ŒUnrollINRçš„é‡å»ºæ€§èƒ½ä¹Ÿä¼˜äºç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06611v1">PDF</a> </p>
<p><strong>Summary</strong><br>    MRIé‡å»ºæŠ€æœ¯åˆ©ç”¨æ·±åº¦å­¦ä¹ å®ç°é«˜ä¿çœŸåº¦å¿«é€Ÿæ‰«æã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ–°å‹é›¶æ ·æœ¬è‡ªç›‘ç£é‡å»ºæ¡†æ¶UnrollINRï¼Œå¯åœ¨æ— éœ€å¤–éƒ¨è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°ç‰¹å®šæ‰«æMRIé‡å»ºã€‚ç»“åˆç‰©ç†å¼•å¯¼å±•å¼€è¿­ä»£é‡å»ºæ¶æ„ä¸éšå¼è¡¨ç¤ºï¼ˆINRï¼‰å…ˆéªŒï¼Œå¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§å’Œé‡å»ºæ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œåœ¨åŠ é€Ÿç‡ä¸º10æ—¶ï¼ŒUnrollINRç›¸è¾ƒäºç›‘ç£å­¦ä¹ æ–¹æ³•ä»è¡¨ç°ä¼˜è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MRIæ˜¯ä¸€ç§é‡è¦çš„ä¸´åºŠè¯Šæ–­å·¥å…·ï¼Œä½†å…¶åº”ç”¨å—é™äºé•¿æ—¶é—´çš„æ‰«æã€‚</li>
<li>å¿«é€ŸMRIé‡å»ºæŠ€æœ¯é€šè¿‡ä»æ¬ é‡‡æ ·çš„k-spaceæ•°æ®ä¸­é‡å»ºé«˜ä¿çœŸå›¾åƒæ¥å‡å°‘é‡‡é›†æ—¶é—´ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨MRIé‡å»ºé¢†åŸŸå–å¾—æ˜¾è‘—è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨éš¾ä»¥è·å–å…¨é‡‡æ ·æ•°æ®çš„æƒ…å†µä¸‹ï¼Œè‡ªç›‘ç£å’Œæ— ç›‘ç£å­¦ä¹ æ–¹æ³•å°¤ä¸ºæœ‰ä»·å€¼ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„é›¶æ ·æœ¬è‡ªç›‘ç£é‡å»ºæ¡†æ¶UnrollINRï¼Œæ— éœ€å¤–éƒ¨è®­ç»ƒæ•°æ®å³å¯å®ç°ç‰¹å®šæ‰«æMRIé‡å»ºã€‚</li>
<li>UnrollINRç»“åˆç‰©ç†å¼•å¯¼å±•å¼€è¿­ä»£é‡å»ºæ¶æ„å’Œéšå¼è¡¨ç¤ºï¼ˆINRï¼‰å…ˆéªŒï¼Œå¢å¼ºäº†æ¨¡å‹çš„è§£é‡Šæ€§å’Œé‡å»ºæ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒUnrollINRåœ¨é«˜é€Ÿç‡ï¼ˆå¦‚åŠ é€Ÿç‡ä¸º10ï¼‰ä¸‹ä»èƒ½å®ç°ä¼˜å¼‚çš„é‡å»ºæ€§èƒ½ï¼Œä¼˜äºç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06611">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2123579ff643e697c88a07eb5dd2bfaa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083572&auth_key=1760083572-0-0-837998312fe6216353d42e0e20d636e8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-440002aef046452346191200f6a7dc54~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083579&auth_key=1760083579-0-0-21dca6e6c627b8e5f5388d405368f855&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-adb5b6d268ebe509ed2577e8be0bd4d3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083586&auth_key=1760083586-0-0-8ef2e528190dada3de96ca31ee0fa69a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Improving-Artifact-Robustness-for-CT-Deep-Learning-Models-Without-Labeled-Artifact-Images-via-Domain-Adaptation"><a href="#Improving-Artifact-Robustness-for-CT-Deep-Learning-Models-Without-Labeled-Artifact-Images-via-Domain-Adaptation" class="headerlink" title="Improving Artifact Robustness for CT Deep Learning Models Without   Labeled Artifact Images via Domain Adaptation"></a>Improving Artifact Robustness for CT Deep Learning Models Without   Labeled Artifact Images via Domain Adaptation</h2><p><strong>Authors:Justin Cheung, Samuel Savine, Calvin Nguyen, Lin Lu, Alhassan S. Yasin</strong></p>
<p>Deep learning models which perform well on images from their training distribution can degrade substantially when applied to new distributions. If a CT scanner introduces a new artifact not present in the training labels, the model may misclassify the images. Although modern CT scanners include design features which mitigate these artifacts, unanticipated or difficult-to-mitigate artifacts can still appear in practice. The direct solution of labeling images from this new distribution can be costly. As a more accessible alternative, this study evaluates domain adaptation as an approach for training models that maintain classification performance despite new artifacts, even without corresponding labels. We simulate ring artifacts from detector gain error in sinogram space and evaluate domain adversarial neural networks (DANN) against baseline and augmentation-based approaches on the OrganAMNIST abdominal CT dataset. Our results demonstrate that baseline models trained only on clean images fail to generalize to images with ring artifacts, and traditional augmentation with other distortion types provides no improvement on unseen artifact domains. In contrast, the DANN approach successfully maintains high classification accuracy on ring artifact images using only unlabeled artifact data during training, demonstrating the viability of domain adaptation for artifact robustness. The domain-adapted model achieved classification performance on ring artifact test data comparable to models explicitly trained with labeled artifact images, while also showing unexpected generalization to uniform noise. These findings provide empirical evidence that domain adaptation can effectively address distribution shift in medical imaging without requiring expensive expert labeling of new artifact distributions, suggesting promise for deployment in clinical settings where novel artifacts may emerge. </p>
<blockquote>
<p>åœ¨æ·±å­¦ä¹ æ•ˆæœæ¨¡å‹ä¸­ï¼Œé’ˆå¯¹å…¶è®­ç»ƒå›¾åƒåˆ†å¸ƒçš„æ•ˆæœæ˜¾è‘—ï¼Œä½†å½“åº”ç”¨äºæ–°çš„åˆ†å¸ƒæ—¶æ€§èƒ½ä¼šæ˜æ˜¾ä¸‹é™ã€‚å¦‚æœCTæ‰«æä»ªå¼•å…¥äº†è®­ç»ƒæ ‡ç­¾ä¸­ä¸å­˜åœ¨çš„æ–°çš„ä¼ªå½±ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¯¯åˆ†ç±»å›¾åƒã€‚å°½ç®¡ç°ä»£CTæ‰«æä»ªåŒ…æ‹¬å‡å°‘è¿™äº›ä¼ªå½±çš„è®¾è®¡åŠŸèƒ½ï¼Œä½†åœ¨å®è·µä¸­ä»å¯èƒ½å‡ºç°æ— æ³•é¢„è§æˆ–éš¾ä»¥æ¶ˆé™¤çš„ä¼ªå½±ã€‚ç›´æ¥è§£å†³æ–°åˆ†å¸ƒå›¾åƒæ ‡ç­¾çš„é—®é¢˜æˆæœ¬é«˜æ˜‚ã€‚ä½œä¸ºæ›´å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆï¼Œæœ¬ç ”ç©¶è¯„ä¼°äº†åŸŸé€‚åº”ä½œä¸ºä¸€ç§è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ–°çš„ä¼ªå½±å‡ºç°çš„æƒ…å†µä¸‹ä¿æŒåˆ†ç±»æ€§èƒ½ï¼Œå³ä½¿åœ¨æ²¡æœ‰ç›¸åº”æ ‡ç­¾çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬åœ¨è¾›è¯ºå›¾ç©ºé—´ä¸­æ¨¡æ‹Ÿäº†ç”±æ£€æµ‹å™¨å¢ç›Šè¯¯å·®å¼•èµ·çš„ç¯å½¢ä¼ªå½±ï¼Œå¹¶åœ¨OrganAMNISTè…¹éƒ¨CTæ•°æ®é›†ä¸Šå¯¹åŸŸå¯¹æŠ—ç¥ç»ç½‘ç»œï¼ˆDANNï¼‰ä¸åŸºçº¿æ–¹æ³•å’ŒåŸºäºå¢å¼ºçš„æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œä»…åœ¨å¹²å‡€å›¾åƒä¸Šè®­ç»ƒçš„åŸºçº¿æ¨¡å‹æ— æ³•æ¨å¹¿åˆ°å¸¦æœ‰ç¯å½¢ä¼ªå½±çš„å›¾åƒï¼Œè€Œå…¶ä»–å¤±çœŸç±»å‹çš„ä¼ ç»Ÿå¢å¼ºå¯¹æœªè§è¿‡çš„ä¼ªå½±åŸŸæ²¡æœ‰æ”¹å–„ä½œç”¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDANNæ–¹æ³•ä»…ä½¿ç”¨æ— æ ‡ç­¾çš„ä¼ªå½±æ•°æ®å¯¹ç¯å½¢ä¼ªå½±å›¾åƒè¿›è¡Œè®­ç»ƒï¼ŒæˆåŠŸåœ°ä¿æŒäº†è¾ƒé«˜çš„åˆ†ç±»ç²¾åº¦ï¼Œè¯æ˜äº†åŸŸé€‚åº”åœ¨ä¼ªå½±ç¨³å¥æ€§æ–¹é¢çš„å¯è¡Œæ€§ã€‚åŸŸé€‚åº”æ¨¡å‹åœ¨ç¯å½¢ä¼ªå½±æµ‹è¯•æ•°æ®ä¸Šçš„åˆ†ç±»æ€§èƒ½ä¸ç”¨å¸¦æ ‡ç­¾çš„ä¼ªå½±å›¾åƒæ˜ç¡®è®­ç»ƒçš„æ¨¡å‹ç›¸å½“ï¼Œå¹¶ä¸”è¿˜æ˜¾ç¤ºå‡ºå¯¹å‡åŒ€å™ªå£°çš„æ„å¤–æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›å‘ç°æä¾›äº†å®è¯è¯æ®è¡¨æ˜ï¼ŒåŸŸé€‚åº”å¯ä»¥æœ‰æ•ˆåœ°è§£å†³åŒ»å­¦å½±åƒä¸­çš„åˆ†å¸ƒè½¬ç§»é—®é¢˜ï¼Œè€Œæ— éœ€å¯¹æ–°ä¼ªå½±åˆ†å¸ƒè¿›è¡Œæ˜‚è´µçš„ä¸“å®¶æ ‡æ³¨ï¼Œè¿™åœ¨å¯èƒ½å‡ºç°æ–°å‹ä¼ªå½±çš„ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²æ—¶å…·æœ‰å¹¿é˜”çš„å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06584v1">PDF</a> 8 pages, 12 figures, 1 table</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒåˆ†å¸ƒä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å½“åº”ç”¨äºæ–°çš„åˆ†å¸ƒæ—¶ï¼Œæ€§èƒ½å¯èƒ½ä¼šå¤§å¹…ä¸‹é™ã€‚å¦‚æœCTæ‰«æä»ªå¼•å…¥æ–°çš„è®­ç»ƒä¸­ä¸å­˜åœ¨çš„ä¼ªå½±ï¼Œæ¨¡å‹å¯èƒ½ä¼šå¯¹å›¾åƒè¯¯åˆ†ç±»ã€‚å°½ç®¡ç°ä»£CTæ‰«æä»ªè®¾è®¡äº†ä¸€äº›å‡å°‘ä¼ªå½±çš„ç‰¹å¾ï¼Œä½†åœ¨å®è·µä¸­ä»ç„¶å¯èƒ½å‡ºç°éš¾ä»¥é¢„è§æˆ–éš¾ä»¥æ¶ˆé™¤çš„ä¼ªå½±ã€‚å¯¹æ­¤æ–°åˆ†å¸ƒè¿›è¡Œæ ‡æ³¨çš„ç›´æ¥è§£å†³æ–¹æ¡ˆæˆæœ¬é«˜æ˜‚ã€‚ä½œä¸ºæ›´å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆï¼Œæœ¬ç ”ç©¶è¯„ä¼°äº†åŸŸé€‚åº”ä½œä¸ºè®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼Œå³ä½¿é¢å¯¹æ–°ä¼ªå½±ï¼Œä¹Ÿèƒ½ä¿æŒåˆ†ç±»æ€§èƒ½ï¼Œæ— éœ€å¯¹åº”æ ‡ç­¾ã€‚æˆ‘ä»¬åœ¨è¾›å›¾æ‹‰ç©ºé—´æ¨¡æ‹Ÿäº†å› æ¢æµ‹å™¨å¢ç›Šè¯¯å·®è€Œäº§ç”Ÿçš„ç¯å½¢ä¼ªå½±ï¼Œå¹¶åœ¨OrganAMNISTè…¹éƒ¨CTæ•°æ®é›†ä¸Šè¯„ä¼°äº†åŸŸå¯¹æŠ—ç¥ç»ç½‘ç»œï¼ˆDANNï¼‰ä¸åŸºå‡†æ–¹æ³•å’ŒåŸºäºå¢å¼ºæ–¹æ³•çš„æ•ˆæœã€‚ç»“æœè¡¨æ˜ï¼Œä»…å¯¹å¹²å‡€å›¾åƒè¿›è¡Œè®­ç»ƒçš„åŸºå‡†æ¨¡å‹æ— æ³•æ¨å¹¿åˆ°å¸¦æœ‰ç¯å½¢ä¼ªå½±çš„å›¾åƒï¼Œè€Œå…¶ä»–ç±»å‹ç•¸å˜çš„ä¼ ç»Ÿå¢å¼ºæ–¹æ³•å¯¹æœªè§è¿‡çš„ä¼ªå½±åŸŸæ²¡æœ‰ä»»ä½•æ”¹è¿›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDANNæ–¹æ³•ä»…ä½¿ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ— æ ‡ç­¾ä¼ªå½±æ•°æ®ï¼Œä¾¿æˆåŠŸåœ°åœ¨ç¯å½¢ä¼ªå½±å›¾åƒä¸Šä¿æŒäº†è¾ƒé«˜çš„åˆ†ç±»ç²¾åº¦ï¼Œè¯æ˜äº†åŸŸé€‚åº”åœ¨ä¼ªå½±ç¨³å¥æ€§æ–¹é¢çš„å¯è¡Œæ€§ã€‚åŸŸé€‚åº”æ¨¡å‹çš„åˆ†ç±»æ€§èƒ½ä¸æ˜ç¡®ä½¿ç”¨æ ‡è®°ä¼ªå½±å›¾åƒè®­ç»ƒçš„æ¨¡å‹åœ¨ç¯å½¢ä¼ªå½±æµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç°ç›¸å½“ï¼Œå¹¶ä¸”è¿˜æ„å¤–åœ°æ¨å¹¿åˆ°äº†å‡åŒ€å™ªå£°ã€‚è¿™äº›å‘ç°æä¾›äº†å®è¯è¯æ®è¡¨æ˜ï¼ŒåŸŸé€‚åº”å¯ä»¥æœ‰æ•ˆåœ°è§£å†³åŒ»å­¦æˆåƒä¸­çš„åˆ†å¸ƒè½¬ç§»é—®é¢˜ï¼Œè€Œæ— éœ€æ˜‚è´µçš„ä¸“å®¶ä¸ºæ–°ä¼ªå½±åˆ†å¸ƒè¿›è¡Œæ ‡æ³¨ï¼Œè¿™ä¸ºåœ¨ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²æä¾›äº†å¸Œæœ›ï¼Œå› ä¸ºé‚£é‡Œå¯èƒ½ä¼šå‡ºç°æ–°çš„ä¼ªå½±ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨é¢å¯¹æ–°çš„å›¾åƒåˆ†å¸ƒæ—¶å¯èƒ½ä¼šé­å—æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»å­¦å›¾åƒé¢†åŸŸã€‚</li>
<li>å½“CTæ‰«æä»ªå¼•å…¥æ–°çš„ä¼ªå½±æ—¶ï¼Œæ¨¡å‹å¯èƒ½å¯¹å›¾åƒäº§ç”Ÿè¯¯åˆ†ç±»ã€‚</li>
<li>ç°ä»£CTæ‰«æä»ªçš„è®¾è®¡ç‰¹æ€§è™½ç„¶èƒ½å‡å°‘ä¼ªå½±ï¼Œä½†åœ¨å®è·µä¸­ä»å¯èƒ½å‡ºç°ä¸å¯é¢„è§æˆ–éš¾ä»¥æ¶ˆé™¤çš„ä¼ªå½±ã€‚</li>
<li>ç›´æ¥å¯¹æ–°åˆ†å¸ƒçš„å›¾åƒè¿›è¡Œæ ‡æ³¨æˆæœ¬é«˜æ˜‚ä¸”ä¸å¯è¡Œã€‚</li>
<li>åŸŸé€‚åº”æ˜¯ä¸€ç§æœ‰æ•ˆçš„è®­ç»ƒæ¨¡å‹æ–¹æ³•ï¼Œèƒ½åœ¨é¢å¯¹æ–°ä¼ªå½±æ—¶ä¿æŒåˆ†ç±»æ€§èƒ½ï¼Œä¸”æ— éœ€å¯¹åº”æ ‡ç­¾ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿç¯å½¢ä¼ªå½±çš„æƒ…å†µä¸‹ï¼ŒåŸŸå¯¹æŠ—ç¥ç»ç½‘ç»œï¼ˆDANNï¼‰è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œèƒ½å¤Ÿåœ¨æ— æ ‡ç­¾ä¼ªå½±æ•°æ®çš„è®­ç»ƒä¸­ä¿æŒé«˜åˆ†ç±»ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06584">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5b2b5ca59a53cdcffc3a9bad22c331d9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083594&auth_key=1760083594-0-0-677e791211ec6d3d9acdd50f90444b23&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b76b48361079841bc0d79647c42c4984~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083601&auth_key=1760083601-0-0-e7ab1ceda166bcef1a3ff86195d4da26&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-abf9b2b535d993383b069d50f5d6625c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083608&auth_key=1760083608-0-0-72caf81f374fb9718555c853ee388389&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-71cfd51212f07bd65174a0ef52299be0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083614&auth_key=1760083614-0-0-8c637c13c200a50d84e5c7e974647307&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-16a3634ddc8d531b1151ba14d9ab2e93~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083621&auth_key=1760083621-0-0-5de1886cfe77dd4dc62ecebefb8debca&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d4e4e793be993219f223fb6fc002f8cf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083628&auth_key=1760083628-0-0-444d4e3f80e3d21176044661d3d689f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-709fce7edfc95649a49d0a5213a7d699~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083635&auth_key=1760083635-0-0-d91297f45850cc995ad07142519cd654&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-945c034241f6f939cc6a5cb69b832e0b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099833&auth_key=1760099833-0-0-4d5a72899d11023692d1b5093c2a3300&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Conditional-Denoising-Diffusion-Model-Based-Robust-MR-Image-Reconstruction-from-Highly-Undersampled-Data"><a href="#Conditional-Denoising-Diffusion-Model-Based-Robust-MR-Image-Reconstruction-from-Highly-Undersampled-Data" class="headerlink" title="Conditional Denoising Diffusion Model-Based Robust MR Image   Reconstruction from Highly Undersampled Data"></a>Conditional Denoising Diffusion Model-Based Robust MR Image   Reconstruction from Highly Undersampled Data</h2><p><strong>Authors:Mohammed Alsubaie, Wenxi Liu, Linxia Gu, Ovidiu C. Andronesi, Sirani M. Perera, Xianqi Li</strong></p>
<p>Magnetic Resonance Imaging (MRI) is a critical tool in modern medical diagnostics, yet its prolonged acquisition time remains a critical limitation, especially in time-sensitive clinical scenarios. While undersampling strategies can accelerate image acquisition, they often result in image artifacts and degraded quality. Recent diffusion models have shown promise for reconstructing high-fidelity images from undersampled data by learning powerful image priors; however, most existing approaches either (i) rely on unsupervised score functions without paired supervision or (ii) apply data consistency only as a post-processing step. In this work, we introduce a conditional denoising diffusion framework with iterative data-consistency correction, which differs from prior methods by embedding the measurement model directly into every reverse diffusion step and training the model on paired undersampled-ground truth data. This hybrid design bridges generative flexibility with explicit enforcement of MRI physics. Experiments on the fastMRI dataset demonstrate that our framework consistently outperforms recent state-of-the-art deep learning and diffusion-based methods in SSIM, PSNR, and LPIPS, with LPIPS capturing perceptual improvements more faithfully. These results demonstrate that integrating conditional supervision with iterative consistency updates yields substantial improvements in both pixel-level fidelity and perceptual realism, establishing a principled and practical advance toward robust, accelerated MRI reconstruction. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ç°ä»£åŒ»å­¦è¯Šæ–­ä¸­çš„é‡è¦å·¥å…·ï¼Œä½†å…¶é•¿æ—¶é—´çš„é‡‡é›†æ—¶é—´ä»æ˜¯å…¶å…³é”®é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—¶é—´æ•æ„Ÿçš„ä¸´åºŠåœºæ™¯ä¸­ã€‚å°½ç®¡æ¬ é‡‡æ ·ç­–ç•¥å¯ä»¥åŠ é€Ÿå›¾åƒé‡‡é›†ï¼Œä½†å®ƒä»¬é€šå¸¸ä¼šå¯¼è‡´å›¾åƒå‡ºç°ä¼ªå½±å’Œè´¨é‡ä¸‹é™ã€‚æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ å¼ºå¤§çš„å›¾åƒå…ˆéªŒæ¥ä»æ¬ é‡‡æ ·æ•°æ®ä¸­é‡å»ºé«˜ä¿çœŸå›¾åƒï¼Œæ˜¾ç¤ºå‡ºå¾ˆå¤§çš„æ½œåŠ›ï¼›ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ï¼ˆiï¼‰ä¾èµ–äºæ— é…å¯¹ç›‘ç£çš„æ— ç›‘ç£åˆ†æ•°å‡½æ•°ï¼Œæˆ–è€…ï¼ˆiiï¼‰ä»…å°†æ•°æ®ä¸€è‡´æ€§ä½œä¸ºåå¤„ç†æ­¥éª¤åº”ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå…·æœ‰è¿­ä»£æ•°æ®ä¸€è‡´æ€§æ ¡æ­£çš„æ¡ä»¶å»å™ªæ‰©æ•£æ¡†æ¶ï¼Œå®ƒä¸å…ˆå‰çš„æ–¹æ³•ä¸åŒï¼Œå°†æµ‹é‡æ¨¡å‹ç›´æ¥åµŒå…¥åˆ°æ¯ä¸ªåå‘æ‰©æ•£æ­¥éª¤ä¸­ï¼Œå¹¶åœ¨é…å¯¹æ¬ é‡‡æ ·-çœŸå®æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ã€‚è¿™ç§æ··åˆè®¾è®¡ç»“åˆäº†ç”Ÿæˆçµæ´»æ€§å’Œå¯¹MRIç‰©ç†çš„æ˜¾å¼å¼ºåˆ¶æ‰§è¡Œã€‚åœ¨fastMRIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰ã€å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œå±€éƒ¨æ„ŸçŸ¥å›¾åƒç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰æ–¹é¢å§‹ç»ˆä¼˜äºæœ€æ–°çš„æ·±åº¦å­¦ä¹ å’Œæ‰©æ•£æ–¹æ³•ã€‚LPIPSæ›´çœŸå®åœ°æ•æ‰åˆ°äº†æ„ŸçŸ¥æ”¹è¿›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå°†æ¡ä»¶ç›‘ç£ä¸è¿­ä»£ä¸€è‡´æ€§æ›´æ–°ç›¸ç»“åˆï¼Œåœ¨åƒç´ çº§ä¿çœŸåº¦å’Œæ„ŸçŸ¥çœŸå®æ€§æ–¹é¢éƒ½å–å¾—äº†é‡å¤§æ”¹è¿›ï¼Œä¸ºå®ç°ç¨³å¥ã€åŠ é€Ÿçš„MRIé‡å»ºæä¾›äº†æœ‰åŸåˆ™ä¸”å®ç”¨çš„è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06335v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ¡ä»¶å»å™ªæ‰©æ•£æ¡†æ¶ä¸è¿­ä»£æ•°æ®ä¸€è‡´æ€§æ ¡æ­£çš„æ–¹æ³•ï¼Œç”¨äºåŠ é€Ÿç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„é‡å»ºè¿‡ç¨‹ã€‚è¯¥æ–¹æ³•å°†æµ‹é‡æ¨¡å‹ç›´æ¥åµŒå…¥åˆ°æ¯ä¸ªåå‘æ‰©æ•£æ­¥éª¤ä¸­ï¼Œå¹¶åœ¨é…å¯¹æ¬ é‡‡æ ·-çœŸå®æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨SSIMã€PSNRå’ŒLPIPSæŒ‡æ ‡ä¸Šå‡ä¼˜äºæœ€æ–°çš„æ·±åº¦å­¦ä¹ å’Œæ‰©æ•£æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ„ŸçŸ¥æ”¹å–„æ–¹é¢è¡¨ç°æ›´å‡ºè‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ç°ä»£åŒ»å­¦è¯Šæ–­ä¸­çš„é‡è¦å·¥å…·ï¼Œä½†å…¶é•¿æ—¶é—´çš„é‡‡é›†æ—¶é—´ä»æ˜¯é™åˆ¶å…¶åº”ç”¨çš„å…³é”®å› ç´ ã€‚</li>
<li>æ¬ é‡‡æ ·ç­–ç•¥å¯ä»¥åŠ é€Ÿå›¾åƒé‡‡é›†ï¼Œä½†å¯èƒ½å¯¼è‡´å›¾åƒå‡ºç°ä¼ªå½±å’Œè´¨é‡ä¸‹é™ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨ä»æœªå®Œå…¨é‡‡æ ·çš„æ•°æ®ä¸­é‡å»ºé«˜è´¨é‡å›¾åƒæ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¤§å¤šä¾èµ–äºæ— ç›‘ç£çš„è¯„åˆ†å‡½æ•°æˆ–ä»…å°†æ•°æ®ä¸€è‡´æ€§ä½œä¸ºåå¤„ç†æ­¥éª¤ã€‚</li>
<li>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç»“åˆæ¡ä»¶å»å™ªæ‰©æ•£æ¡†æ¶å’Œè¿­ä»£æ•°æ®ä¸€è‡´æ€§æ ¡æ­£çš„æ–¹æ³•ï¼Œå°†æµ‹é‡æ¨¡å‹ç›´æ¥åµŒå…¥åˆ°æ¯ä¸ªåå‘æ‰©æ•£æ­¥éª¤ä¸­ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨é…å¯¹æ¬ é‡‡æ ·-çœŸå®æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨SSIMã€PSNRå’ŒLPIPSæŒ‡æ ‡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06335">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ed8b3160742ce192f18a08457140bd45~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099842&auth_key=1760099842-0-0-483988e1c39295cad6e0691a36055b6e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4a3182fbbb9dc6009f8d71fba37c7e63~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099849&auth_key=1760099849-0-0-c5ae15f96354c43b929e3737761326e9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f790d41f7e1893c270c91d01918e509a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099856&auth_key=1760099856-0-0-e0b8e14d75fc63856027292555b08484&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4c3db9fbaa3d5f95b052d749358bf897~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099862&auth_key=1760099862-0-0-026d09cc2c096ee613a6a34e0fbbfe5d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7790fa011158758e7e700c74906aa7db~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099869&auth_key=1760099869-0-0-ffe9d90427acdc6489fa75912dc27e04&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4b18c9aed058fc63e92c26f872bc905e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099876&auth_key=1760099876-0-0-627cae5beddfb80038a6bc1ad4411f51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Soft-Evidence-Fused-Graph-Neural-Network-for-Cancer-Driver-Gene-Identification-across-Multi-View-Biological-Graphs"><a href="#Soft-Evidence-Fused-Graph-Neural-Network-for-Cancer-Driver-Gene-Identification-across-Multi-View-Biological-Graphs" class="headerlink" title="Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene   Identification across Multi-View Biological Graphs"></a>Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene   Identification across Multi-View Biological Graphs</h2><p><strong>Authors:Bang Chen, Lijun Guo, Houli Fan, Wentao He, Rong Zhang</strong></p>
<p>Identifying cancer driver genes (CDGs) is essential for understanding cancer mechanisms and developing targeted therapies. Graph neural networks (GNNs) have recently been employed to identify CDGs by capturing patterns in biological interaction networks. However, most GNN-based approaches rely on a single protein-protein interaction (PPI) network, ignoring complementary information from other biological networks. Some studies integrate multiple networks by aligning features with consistency constraints to learn unified gene representations for CDG identification. However, such representation-level fusion often assumes congruent gene relationships across networks, which may overlook network heterogeneity and introduce conflicting information. To address this, we propose Soft-Evidence Fusion Graph Neural Network (SEFGNN), a novel framework for CDG identification across multiple networks at the decision level. Instead of enforcing feature-level consistency, SEFGNN treats each biological network as an independent evidence source and performs uncertainty-aware fusion at the decision level using Dempster-Shafer Theory (DST). To alleviate the risk of overconfidence from DST, we further introduce a Soft Evidence Smoothing (SES) module that improves ranking stability while preserving discriminative performance. Experiments on three cancer datasets show that SEFGNN consistently outperforms state-of-the-art baselines and exhibits strong potential in discovering novel CDGs. </p>
<blockquote>
<p>è¯†åˆ«ç™Œç—‡é©±åŠ¨åŸºå› ï¼ˆCDGsï¼‰å¯¹äºç†è§£ç™Œç—‡æœºåˆ¶å’Œå¼€å‘é¶å‘ç–—æ³•è‡³å…³é‡è¦ã€‚å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰æœ€è¿‘è¢«ç”¨æ¥é€šè¿‡æ•æ‰ç”Ÿç‰©äº¤äº’ç½‘ç»œä¸­çš„æ¨¡å¼æ¥è¯†åˆ«CDGsã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°åŸºäºGNNçš„æ–¹æ³•éƒ½ä¾èµ–äºå•ä¸€çš„è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ï¼ˆPPIï¼‰ç½‘ç»œï¼Œå¿½ç•¥äº†å…¶ä»–ç”Ÿç‰©ç½‘ç»œä¸­çš„è¡¥å……ä¿¡æ¯ã€‚ä¸€äº›ç ”ç©¶é€šè¿‡ç‰¹å¾å¯¹é½å’Œä¸€è‡´æ€§çº¦æŸæ¥æ•´åˆå¤šä¸ªç½‘ç»œï¼Œä»¥å­¦ä¹ ç»Ÿä¸€çš„åŸºå› è¡¨ç¤ºæ¥è¿›è¡ŒCDGè¯†åˆ«ã€‚ç„¶è€Œï¼Œè¿™ç§è¡¨ç¤ºçº§åˆ«çš„èåˆé€šå¸¸å‡è®¾ç½‘ç»œä¹‹é—´çš„åŸºå› å…³ç³»æ˜¯ä¸€è‡´çš„ï¼Œè¿™å¯èƒ½ä¼šå¿½ç•¥ç½‘ç»œçš„å¼‚è´¨æ€§å¹¶å¼•å…¥å†²çªä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Soft-Evidence Fusion Graph Neural Networkï¼ˆSEFGNNï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨å†³ç­–å±‚é¢è¿›è¡Œè·¨å¤šä¸ªç½‘ç»œCDGè¯†åˆ«çš„æ–°å‹æ¡†æ¶ã€‚ä¸å¼ºåˆ¶ç‰¹å¾å±‚é¢çš„ä¸€è‡´æ€§ä¸åŒï¼ŒSEFGNNå°†æ¯ä¸ªç”Ÿç‰©ç½‘ç»œè§†ä¸ºç‹¬ç«‹çš„è¯æ®æ¥æºï¼Œå¹¶ä½¿ç”¨Dempster-Shaferç†è®ºï¼ˆDSTï¼‰åœ¨å†³ç­–å±‚é¢è¿›è¡Œä¸ç¡®å®šæ€§æ„ŸçŸ¥èåˆã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡è½»DSTè¿‡åº¦è‡ªä¿¡çš„é£é™©ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†Soft Evidence Smoothingï¼ˆSESï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—æé«˜äº†æ’åç¨³å®šæ€§ï¼ŒåŒæ—¶ä¿ç•™äº†é‰´åˆ«æ€§èƒ½ã€‚åœ¨ä¸‰ä¸ªç™Œç—‡æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSEFGNNå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œå¹¶åœ¨å‘ç°æ–°çš„CDGsæ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06290v1">PDF</a> 8pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰çš„æ–°æ–¹æ³•â€”â€”è½¯è¯æ®èåˆå›¾ç¥ç»ç½‘ç»œï¼ˆSEFGNNï¼‰ï¼Œç”¨äºåœ¨å¤šä¸ªç½‘ç»œå±‚é¢è¯†åˆ«ç™Œç—‡é©±åŠ¨åŸºå› ï¼ˆCDGsï¼‰ã€‚SEFGNNåˆ©ç”¨Dempster-Shaferç†è®ºï¼ˆDSTï¼‰è¿›è¡Œå†³ç­–å±‚é¢çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥èåˆï¼Œè€Œéç‰¹å¾å±‚é¢çš„èåˆï¼Œä»è€Œæé«˜å¯¹å¤šç§ç”Ÿç‰©ç½‘ç»œä¿¡æ¯çš„åˆ©ç”¨æ•ˆç‡ã€‚åŒæ—¶ï¼Œå¼•å…¥è½¯è¯æ®å¹³æ»‘ï¼ˆSESï¼‰æ¨¡å—ï¼Œæé«˜æ’åç¨³å®šæ€§å¹¶ä¿æŒé‰´åˆ«æ€§èƒ½ã€‚åœ¨ä¸‰ä¸ªç™Œç—‡æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSEFGNNæŒç»­è¶…è¶Šç°æœ‰åŸºçº¿ï¼Œå¹¶åœ¨å‘ç°æ–°çš„CDGsæ–¹é¢å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GNNså·²è¢«ç”¨äºè¯†åˆ«ç™Œç—‡é©±åŠ¨åŸºå› ï¼ˆCDGsï¼‰ï¼Œé€šè¿‡æ•æ‰ç”Ÿç‰©äº¤äº’ç½‘ç»œä¸­çš„æ¨¡å¼æ¥å®ç°ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¤§å¤šä¾èµ–å•ä¸€çš„è›‹ç™½è´¨-è›‹ç™½è´¨äº¤äº’ï¼ˆPPIï¼‰ç½‘ç»œï¼Œå¿½ç•¥äº†å…¶ä»–ç”Ÿç‰©ç½‘ç»œä¸­çš„äº’è¡¥ä¿¡æ¯ã€‚</li>
<li>ä¸€äº›ç ”ç©¶é€šè¿‡ç‰¹å¾å¯¹é½å’Œä¸€è‡´æ€§çº¦æŸæ¥æ•´åˆå¤šä¸ªç½‘ç»œï¼Œå­¦ä¹ ç»Ÿä¸€çš„åŸºå› è¡¨ç¤ºæ¥è¿›è¡ŒCDGè¯†åˆ«ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½å¿½ç•¥ç½‘ç»œå¼‚è´¨æ€§å’Œå¼•å…¥å†²çªä¿¡æ¯ã€‚</li>
<li>SEFGNNæ¡†æ¶è¢«æå‡ºï¼Œç”¨äºåœ¨å†³ç­–å±‚é¢è·¨å¤šä¸ªç½‘ç»œè¿›è¡ŒCDGè¯†åˆ«ã€‚</li>
<li>SEFGNNä¸å¼ºåˆ¶ç‰¹å¾ä¸€è‡´æ€§ï¼Œè€Œæ˜¯å°†æ¯ä¸ªç”Ÿç‰©ç½‘ç»œè§†ä¸ºç‹¬ç«‹çš„è¯æ®æºï¼Œä½¿ç”¨Dempster-Shaferç†è®ºï¼ˆDSTï¼‰è¿›è¡Œä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„èåˆã€‚</li>
<li>ä¸ºäº†å‡è½»DSTå¯èƒ½å¸¦æ¥çš„è¿‡åº¦è‡ªä¿¡é£é™©ï¼Œå¼•å…¥äº†Soft Evidence Smoothingï¼ˆSESï¼‰æ¨¡å—ï¼Œæé«˜äº†æ’åç¨³å®šæ€§å¹¶ä¿æŒé‰´åˆ«æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06290">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cc00e06e3f424a2cfa75f684324b61cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099884&auth_key=1760099884-0-0-742f770f16f15302312512b93ad2e94e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ff80b884679afcd072b844e6877aff05~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099891&auth_key=1760099891-0-0-4aaff962253207f39dbebcbd7177a8e0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-be74822e95330a8e62c5f7561407415c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099899&auth_key=1760099899-0-0-31235dbce8f04bce56d31482270c08c9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2b979032f0dfa4d550cd665a90ff20c4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099907&auth_key=1760099907-0-0-e8790d85d4887ce0671ceda7ba69e8d9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3de8c14de8b03efe26f3704101cdec4f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099914&auth_key=1760099914-0-0-83c6a6d2aa4283a8d4a1c549a3733e0c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fc361f2d2ea90471b1da56b148e96a1f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099921&auth_key=1760099921-0-0-5f26cbd3aaa3bc850dc1cb2d7cae2823&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a5a04dec660140f23eb744c879fe6ad4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099928&auth_key=1760099928-0-0-8bce19b709d9dc228627b934f5fd5732&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1664751aeb33cd85ad37434343615ac0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099935&auth_key=1760099935-0-0-56e02a46f93b0e5f507f6078df1f4081&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-96ba56e16f4a321d98c7d4db2feb0fee~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099943&auth_key=1760099943-0-0-a8bd9a74f0807501d7c92da6b7b3762a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="SER-Diff-Synthetic-Error-Replay-Diffusion-for-Incremental-Brain-Tumor-Segmentation"><a href="#SER-Diff-Synthetic-Error-Replay-Diffusion-for-Incremental-Brain-Tumor-Segmentation" class="headerlink" title="SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor   Segmentation"></a>SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor   Segmentation</h2><p><strong>Authors:Sashank Makanaboyina</strong></p>
<p>Incremental brain tumor segmentation is critical for models that must adapt to evolving clinical datasets without retraining on all prior data. However, catastrophic forgetting, where models lose previously acquired knowledge, remains a major obstacle. Recent incremental learning frameworks with knowledge distillation partially mitigate forgetting but rely heavily on generative replay or auxiliary storage. Meanwhile, diffusion models have proven effective for refining tumor segmentations, but have not been explored in incremental learning contexts. We propose Synthetic Error Replay Diffusion (SER-Diff), the first framework that unifies diffusion-based refinement with incremental learning. SER-Diff leverages a frozen teacher diffusion model to generate synthetic error maps from past tasks, which are replayed during training on new tasks. A dual-loss formulation combining Dice loss for new data and knowledge distillation loss for replayed errors ensures both adaptability and retention. Experiments on BraTS2020, BraTS2021, and BraTS2023 demonstrate that SER-Diff consistently outperforms prior methods. It achieves the highest Dice scores of 95.8%, 94.9%, and 94.6%, along with the lowest HD95 values of 4.4 mm, 4.7 mm, and 4.9 mm, respectively. These results indicate that SER-Diff not only mitigates catastrophic forgetting but also delivers more accurate and anatomically coherent segmentations across evolving datasets. </p>
<blockquote>
<p>å¢é‡è„‘è‚¿ç˜¤åˆ†å‰²å¯¹äºå¿…é¡»é€‚åº”ä¸æ–­æ¼”å˜çš„ä¸´åºŠæ•°æ®é›†è€Œæ— éœ€å¯¹æ‰€æœ‰å…ˆå‰æ•°æ®è¿›è¡Œå†è®­ç»ƒæ¨¡å‹è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç¾éš¾æ€§é—å¿˜ï¼ˆæ¨¡å‹å¤±å»å…ˆå‰è·å¾—çš„çŸ¥è¯†ï¼‰ä»ç„¶æ˜¯ä¸»è¦éšœç¢ã€‚æœ€è¿‘çš„å¢é‡å­¦ä¹ æ¡†æ¶é€šè¿‡çŸ¥è¯†è’¸é¦åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡è½»äº†é—å¿˜ï¼Œä½†ä¸¥é‡ä¾èµ–äºç”Ÿæˆå›æ”¾æˆ–è¾…åŠ©å­˜å‚¨ã€‚åŒæ—¶ï¼Œæ‰©æ•£æ¨¡å‹åœ¨ç»†åŒ–è‚¿ç˜¤åˆ†å‰²æ–¹é¢å·²è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œä½†åœ¨å¢é‡å­¦ä¹ ç¯å¢ƒä¸­å°šæœªå¾—åˆ°æ¢ç´¢ã€‚æˆ‘ä»¬æå‡ºäº†åˆæˆè¯¯å·®å›æ”¾æ‰©æ•£ï¼ˆSER-Diffï¼‰ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†åŸºäºæ‰©æ•£çš„ç²¾ç‚¼ä¸å¢é‡å­¦ä¹ ç»Ÿä¸€èµ·æ¥çš„æ¡†æ¶ã€‚SER-Diffåˆ©ç”¨å†»ç»“çš„æ•™å¸ˆæ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆè¯¯å·®å›¾ï¼Œè¿™äº›è¯¯å·®å›¾ä¼šåœ¨æ–°ä»»åŠ¡è®­ç»ƒæœŸé—´è¿›è¡Œå›æ”¾ã€‚ç»“åˆDiceæŸå¤±ï¼ˆç”¨äºæ–°æ•°æ®ï¼‰å’ŒçŸ¥è¯†è’¸é¦æŸå¤±ï¼ˆç”¨äºå›æ”¾è¯¯å·®ï¼‰çš„åŒæŸå¤±å…¬å¼ç¡®ä¿äº†é€‚åº”æ€§å’Œä¿ç•™æ€§ã€‚åœ¨BraTS2020ã€BraTS2021å’ŒBraTS2023ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSER-Diffå§‹ç»ˆä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚å®ƒè¾¾åˆ°äº†æœ€é«˜çš„Diceåˆ†æ•°åˆ†åˆ«ä¸º95.8ï¼…ã€94.9ï¼…å’Œ94.6ï¼…ï¼Œä»¥åŠæœ€ä½çš„HD95å€¼åˆ†åˆ«ä¸º4.4æ¯«ç±³ã€4.7æ¯«ç±³å’Œ4.9æ¯«ç±³ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒSER-Diffä¸ä»…å‡è½»äº†ç¾éš¾æ€§é—å¿˜ï¼Œè€Œä¸”åœ¨ä¸æ–­å‘å±•çš„æ•°æ®é›†ä¸­æä¾›äº†æ›´å‡†ç¡®å’Œè§£å‰–ç»“æ„è¿è´¯çš„åˆ†å‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06283v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ‰©æ•£æ¨¡å‹ä¸å¢é‡å­¦ä¹ çš„æ–°æ¡†æ¶â€”â€”åˆæˆé”™è¯¯å›æ”¾æ‰©æ•£ï¼ˆSER-Diffï¼‰ï¼Œç”¨äºé€æ­¥ä¼˜åŒ–è‚¿ç˜¤åˆ†å‰²æ¨¡å‹ï¼Œåœ¨ä¸é‡æ–°è®­ç»ƒæ‰€æœ‰æ•°æ®çš„æƒ…å†µä¸‹é€‚åº”ä¸æ–­å‘å±•çš„ä¸´åºŠæ•°æ®é›†ã€‚é€šè¿‡åˆ©ç”¨å†»ç»“çš„æ•™å¸ˆæ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆè¯¯å·®å›¾ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå›æ”¾è®­ç»ƒï¼ŒSER-Diffæœ‰æ•ˆè§£å†³äº†æ¨¡å‹é—å¿˜å…ˆå‰çŸ¥è¯†çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿è¯äº†å¯¹æ–°æ•°æ®çš„é€‚åº”æ€§å’ŒçŸ¥è¯†çš„ä¿ç•™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSER-Diffåœ¨BraTSæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¢é‡è„‘è‚¿ç˜¤åˆ†å‰²å¯¹äºé€‚åº”ä¸æ–­å‘å±•çš„ä¸´åºŠæ•°æ®é›†è‡³å…³é‡è¦ï¼Œä½†æ¨¡å‹é—å¿˜å…ˆå‰çŸ¥è¯†çš„é—®é¢˜ä»æ˜¯ä¸»è¦æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰çš„å¢é‡å­¦ä¹ æ¡†æ¶å€ŸåŠ©çŸ¥è¯†è’¸é¦å‡è½»é—å¿˜ï¼Œä½†ä¾èµ–ç”Ÿæˆå›æ”¾æˆ–è¾…åŠ©å­˜å‚¨ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å·²è¢«è¯æ˜èƒ½æœ‰æ•ˆæ”¹è¿›è‚¿ç˜¤åˆ†å‰²ï¼Œä½†åœ¨å¢é‡å­¦ä¹ ç¯å¢ƒä¸­å°šæœªè¢«æ¢ç´¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”åˆæˆé”™è¯¯å›æ”¾æ‰©æ•£ï¼ˆSER-Diffï¼‰ï¼Œç»“åˆäº†æ‰©æ•£æ¨¡å‹çš„ç²¾ç‚¼å’Œå¢é‡å­¦ä¹ ã€‚</li>
<li>SER-Diffåˆ©ç”¨å†»ç»“çš„æ•™å¸ˆæ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆè¯¯å·®å›¾ï¼Œè¿™äº›è¯¯å·®å›¾åœ¨æ–°ä»»åŠ¡è®­ç»ƒæœŸé—´è¿›è¡Œå›æ”¾ã€‚</li>
<li>é€šè¿‡ç»“åˆDiceæŸå¤±å’Œå›æ”¾è¯¯å·®çš„çŸ¥è¯†è’¸é¦æŸå¤±ï¼Œç¡®ä¿æ¨¡å‹çš„é€‚åº”æ€§å’ŒçŸ¥è¯†ä¿ç•™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06283">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b3264ae4ed4da34c744787c124abb30a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099951&auth_key=1760099951-0-0-1968ee26800d373f525be4532aba3d30&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2838e4df9d2bbab515c028b26e72c24c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099959&auth_key=1760099959-0-0-c7c8f918d8b79cb6b9756666cc9b8bcb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="A-Total-Variation-Regularized-Framework-for-Epilepsy-Related-MRI-Image-Segmentation"><a href="#A-Total-Variation-Regularized-Framework-for-Epilepsy-Related-MRI-Image-Segmentation" class="headerlink" title="A Total Variation Regularized Framework for Epilepsy-Related MRI Image   Segmentation"></a>A Total Variation Regularized Framework for Epilepsy-Related MRI Image   Segmentation</h2><p><strong>Authors:Mehdi Rabiee, Sergio Greco, Reza Shahbazian, Irina Trubitsyna</strong></p>
<p>Focal Cortical Dysplasia (FCD) is a primary cause of drug-resistant epilepsy and is difficult to detect in brain {magnetic resonance imaging} (MRI) due to the subtle and small-scale nature of its lesions. Accurate segmentation of FCD regions in 3D multimodal brain MRI images is essential for effective surgical planning and treatment. However, this task remains highly challenging due to the limited availability of annotated FCD datasets, the extremely small size and weak contrast of FCD lesions, the complexity of handling 3D multimodal inputs, and the need for output smoothness and anatomical consistency, which is often not addressed by standard voxel-wise loss functions. This paper presents a new framework for segmenting FCD regions in 3D brain MRI images. We adopt state-of-the-art transformer-enhanced encoder-decoder architecture and introduce a novel loss function combining Dice loss with an anisotropic {Total Variation} (TV) term. This integration encourages spatial smoothness and reduces false positive clusters without relying on post-processing. The framework is evaluated on a public FCD dataset with 85 epilepsy patients and demonstrates superior segmentation accuracy and consistency compared to standard loss formulations. The model with the proposed TV loss shows an 11.9% improvement on the Dice coefficient and 13.3% higher precision over the baseline model. Moreover, the number of false positive clusters is reduced by 61.6% </p>
<blockquote>
<p>çš®å±‚å‘è‚²ä¸è‰¯ï¼ˆFocal Cortical Dysplasiaï¼Œç®€ç§°FCDï¼‰æ˜¯å¯¼è‡´è¯ç‰©éš¾æ²»æ€§ç™«ç—«çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚ç”±äºå…¶ç—…å˜å…·æœ‰ç»†å¾®å’Œå°è§„æ¨¡çš„ç‰¹ç‚¹ï¼Œåœ¨è„‘éƒ¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­éš¾ä»¥æ£€æµ‹ã€‚åœ¨3Då¤šæ¨¡æ€è„‘éƒ¨MRIå›¾åƒä¸­å¯¹FCDåŒºåŸŸè¿›è¡Œå‡†ç¡®çš„åˆ†å‰²å¯¹äºæœ‰æ•ˆçš„æ‰‹æœ¯è§„åˆ’å’Œæ²»ç–—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¿™ä¸€ä»»åŠ¡ä»ç„¶æå…·æŒ‘æˆ˜æ€§ï¼Œä¸»è¦æ˜¯ç”±äºæ ‡æ³¨çš„FCDæ•°æ®é›†æœ‰é™ã€FCDç—…å˜æå°ä¸”å¯¹æ¯”åº¦æå¼±ã€å¤„ç†3Då¤šæ¨¡æ€è¾“å…¥çš„å¤æ‚æ€§ä»¥åŠéœ€è¦è¾“å‡ºå¹³æ»‘å’Œè§£å‰–ä¸€è‡´æ€§ï¼Œè€Œæ ‡å‡†åƒç´ çº§æŸå¤±å‡½æ•°é€šå¸¸æ— æ³•è§£å†³è¿™ä¸€é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç”¨äºåœ¨3Dè„‘éƒ¨MRIå›¾åƒä¸­åˆ†å‰²FCDåŒºåŸŸã€‚æˆ‘ä»¬é‡‡ç”¨äº†æœ€å…ˆè¿›çš„å¢å¼ºå‹è½¬æ¢å™¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ç»“åˆDiceæŸå¤±å’Œå„é¡¹å¼‚æ€§æ€»å˜å·®ï¼ˆTotal Variationï¼Œç®€ç§°TVï¼‰æœ¯è¯­çš„æ–°å‹æŸå¤±å‡½æ•°ã€‚è¿™ç§é›†æˆé¼“åŠ±ç©ºé—´å¹³æ»‘æ€§ï¼Œå¹¶å‡å°‘å‡é˜³æ€§ç°‡ï¼Œæ— éœ€ä¾èµ–åå¤„ç†ã€‚è¯¥æ¡†æ¶åœ¨åŒ…å«85åç™«ç—«æ‚£è€…çš„å…¬å…±FCDæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶å±•ç¤ºäº†ä¸æ ‡å‡†æŸå¤±å…¬å¼ç›¸æ¯”çš„ä¼˜è¶Šåˆ†å‰²ç²¾åº¦å’Œä¸€è‡´æ€§ã€‚é‡‡ç”¨æ‰€æTVæŸå¤±çš„æ¨¡å‹åœ¨Diceç³»æ•°ä¸Šæé«˜äº†11.9%ï¼Œå¹¶ä¸”åœ¨ç²¾åº¦ä¸Šæ¯”åŸºçº¿æ¨¡å‹æé«˜äº†13.3%ã€‚æ­¤å¤–ï¼Œå‡é˜³æ€§ç°‡çš„æ•°é‡å‡å°‘äº†61.6%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06276v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç”¨äºåœ¨3Dè„‘MRIå›¾åƒä¸­å‡†ç¡®åˆ†å‰²Focal Cortical Dysplasiaï¼ˆFCDï¼‰åŒºåŸŸã€‚é‡‡ç”¨å…ˆè¿›çš„åŸºäºtransformerçš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ç»“åˆDiceæŸå¤±å’Œå„é¡¹å¼‚æ€§Total Variationï¼ˆTVï¼‰æœ¯è¯­çš„æ–°å‹æŸå¤±å‡½æ•°ã€‚è¯¥æ¡†æ¶åœ¨å…¬å…±FCDæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…å«85åç™«ç—«æ‚£è€…ï¼Œå±•ç¤ºäº†å‡ºè‰²çš„åˆ†å‰²ç²¾åº¦å’Œä¸€è‡´æ€§ã€‚ä¸ä¼ ç»Ÿçš„æŸå¤±å‡½æ•°ç›¸æ¯”ï¼Œæ–°æ¡†æ¶æé«˜äº†Diceç³»æ•°çš„11.9%ï¼Œç²¾ç¡®åº¦æé«˜äº†13.3%ï¼Œå¹¶å‡å°‘äº†61.6%çš„è¯¯æŠ¥ç°‡æ•°é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>FCDæ˜¯è¯ç‰©éš¾æ²»æ€§ç™«ç—«çš„ä¸»è¦åŸå› ï¼Œå…¶åœ¨è„‘MRIä¸­çš„æ£€æµ‹ç”±äºç—…å˜ç»†å¾®ä¸”å°è§„æ¨¡è€Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>å‡†ç¡®åˆ†å‰²FCDåŒºåŸŸå¯¹äºæœ‰æ•ˆçš„æ‰‹æœ¯è§„åˆ’å’Œæ²»ç–—è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰FCDåŒºåŸŸåˆ†å‰²é¢ä¸´æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®é›†æ ‡æ³¨æœ‰é™ã€FCDç—…å˜å°ºå¯¸å°ä¸”å¯¹æ¯”åº¦ä½ã€å¤„ç†3Då¤šæ¨¡æ€è¾“å…¥çš„å¤æ‚æ€§ä»¥åŠéœ€è¦è¾“å‡ºå¹³æ»‘å’Œè§£å‰–ä¸€è‡´æ€§çš„è¦æ±‚ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé‡‡ç”¨å…ˆè¿›çš„åŸºäºtransformerçš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„è¿›è¡ŒFCDåŒºåŸŸåˆ†å‰²ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§ç»“åˆDiceæŸå¤±å’Œå„é¡¹å¼‚æ€§Total Variationï¼ˆTVï¼‰æœ¯è¯­çš„æ–°å‹æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±ç©ºé—´å¹³æ»‘æ€§å¹¶å‡å°‘è¯¯æŠ¥ç°‡ï¼Œæ— éœ€ä¾èµ–åå¤„ç†ã€‚</li>
<li>åœ¨å…¬å…±FCDæ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œæ–°æ¡†æ¶åœ¨åˆ†å‰²å‡†ç¡®æ€§å’Œä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œä¸åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼ŒDiceç³»æ•°æé«˜äº†11.9%ï¼Œç²¾ç¡®åº¦æé«˜äº†13.3%ï¼Œè¯¯æŠ¥ç°‡æ•°é‡å‡å°‘äº†61.6%ã€‚</li>
<li>æ–°æ¡†æ¶çš„æå‡ºæœ‰æœ›æ”¹å–„FCDçš„è¯Šæ–­å’Œæ²»ç–—ï¼Œä¸ºç™«ç—«æ‚£è€…çš„æ‰‹æœ¯è§„åˆ’æä¾›æ›´æœ‰åŠ›çš„æ”¯æŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06276">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d575f24daf56be6670c038b2a36af51b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760099966&auth_key=1760099966-0-0-37a2d967892a4a77e0665a89d446c099&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9c357ae80dbb04d871cb3b65930c90f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102789&auth_key=1760102789-0-0-764d676370ad5daa63b50b21cd4f5213&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Efficient-Universal-Models-for-Medical-Image-Segmentation-via-Weakly-Supervised-In-Context-Learning"><a href="#Efficient-Universal-Models-for-Medical-Image-Segmentation-via-Weakly-Supervised-In-Context-Learning" class="headerlink" title="Efficient Universal Models for Medical Image Segmentation via Weakly   Supervised In-Context Learning"></a>Efficient Universal Models for Medical Image Segmentation via Weakly   Supervised In-Context Learning</h2><p><strong>Authors:Jiesi Hu, Yanwu Yang, Zhiyu Ye, Jinyan Zhou, Jianfeng Cao, Hanyang Peng, Ting Ma</strong></p>
<p>Universal models for medical image segmentation, such as interactive and in-context learning (ICL) models, offer strong generalization but require extensive annotations. Interactive models need repeated user prompts for each image, while ICL relies on dense, pixel-level labels. To address this, we propose Weakly Supervised In-Context Learning (WS-ICL), a new ICL paradigm that leverages weak prompts (e.g., bounding boxes or points) instead of dense labels for context. This approach significantly reduces annotation effort by eliminating the need for fine-grained masks and repeated user prompting for all images. We evaluated the proposed WS-ICL model on three held-out benchmarks. Experimental results demonstrate that WS-ICL achieves performance comparable to regular ICL models at a significantly lower annotation cost. In addition, WS-ICL is highly competitive even under the interactive paradigm. These findings establish WS-ICL as a promising step toward more efficient and unified universal models for medical image segmentation. Our code and model are publicly available at <a target="_blank" rel="noopener" href="https://github.com/jiesihu/Weak-ICL">https://github.com/jiesihu/Weak-ICL</a>. </p>
<blockquote>
<p>é’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†å‰²çš„é€šç”¨æ¨¡å‹ï¼Œå¦‚äº¤äº’å¼å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¨¡å‹ç­‰ï¼Œè™½ç„¶å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†éœ€è¦å¤§é‡çš„æ ‡æ³¨ã€‚äº¤äº’å¼æ¨¡å‹éœ€è¦é’ˆå¯¹æ¯å¼ å›¾åƒè¿›è¡Œå¤šæ¬¡ç”¨æˆ·æç¤ºï¼Œè€ŒICLåˆ™ä¾èµ–äºå¯†é›†çš„åƒç´ çº§æ ‡ç­¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¼±ç›‘ç£ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆWS-ICLï¼‰è¿™ä¸€æ–°çš„ICLèŒƒå¼ï¼Œå®ƒåˆ©ç”¨å¼±æç¤ºï¼ˆå¦‚è¾¹ç•Œæ¡†æˆ–ç‚¹ï¼‰è€Œä¸æ˜¯å¯†é›†æ ‡ç­¾æ¥è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ã€‚è¿™ç§æ–¹æ³•é€šè¿‡æ¶ˆé™¤å¯¹ç²¾ç»†æ©è†œå’Œæ‰€æœ‰å›¾åƒé‡å¤ç”¨æˆ·æç¤ºçš„éœ€æ±‚ï¼Œæ˜¾è‘—å‡å°‘äº†æ ‡æ³¨å·¥ä½œé‡ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªç‹¬ç«‹çš„åŸºå‡†æµ‹è¯•ä¸Šå¯¹æå‡ºçš„WS-ICLæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWS-ICLåœ¨æ ‡æ³¨æˆæœ¬æ˜¾è‘—é™ä½çš„æƒ…å†µä¸‹å®ç°äº†ä¸å¸¸è§„ICLæ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå³ä½¿åœ¨äº¤äº’å¼èŒƒå¼ä¸‹ï¼ŒWS-ICLä¹Ÿå…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒWS-ICLæ˜¯æœç€æ›´é«˜æ•ˆã€æ›´ç»Ÿä¸€çš„åŒ»å­¦å›¾åƒåˆ†å‰²é€šç”¨æ¨¡å‹è¿ˆå‡ºçš„æœ‰å‰é€”çš„ä¸€æ­¥ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/jiesihu/Weak-ICL%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/jiesihu/Weak-ICLå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.05899v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²çš„é€šç”¨æ¨¡å‹ï¼Œå¦‚äº¤äº’å¼å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¨¡å‹ï¼Œè™½ç„¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†éœ€è¦å¤§é‡çš„æ ‡æ³¨ã€‚äº¤äº’å¼æ¨¡å‹éœ€è¦é’ˆå¯¹æ¯å¼ å›¾åƒè¿›è¡Œå¤šæ¬¡ç”¨æˆ·æç¤ºï¼Œè€ŒICLåˆ™ä¾èµ–äºå¯†é›†çš„åƒç´ çº§æ ‡ç­¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¼±ç›‘ç£ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆWS-ICLï¼‰è¿™ä¸€æ–°çš„ICLæ¨¡å¼ï¼Œå®ƒåˆ©ç”¨å¼±æç¤ºï¼ˆå¦‚è¾¹ç•Œæ¡†æˆ–ç‚¹ï¼‰è€Œä¸æ˜¯å¯†é›†æ ‡ç­¾æ¥æä¾›ä¸Šä¸‹æ–‡ã€‚è¿™ç§æ–¹æ³•é€šè¿‡æ¶ˆé™¤å¯¹ç²¾ç»†æ©è†œå’Œæ‰€æœ‰å›¾åƒé‡å¤ç”¨æˆ·æç¤ºçš„éœ€æ±‚ï¼Œå¤§å¤§é™ä½äº†æ ‡æ³¨å·¥ä½œé‡ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªç‹¬ç«‹çš„åŸºå‡†æµ‹è¯•ä¸Šå¯¹WS-ICLæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWS-ICLåœ¨æ€§èƒ½ä¸Šå¯ä¸å¸¸è§„ICLæ¨¡å‹ç›¸åª²ç¾ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†æ ‡æ³¨æˆæœ¬ã€‚æ­¤å¤–ï¼Œå³ä½¿åœ¨äº¤äº’å¼æ¨¡å¼ä¸‹ï¼ŒWS-ICLä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„ç«äº‰åŠ›ã€‚è¿™äº›å‘ç°è¡¨æ˜WS-ICLæ˜¯æœç€æ›´é«˜æ•ˆã€æ›´ç»Ÿä¸€çš„åŒ»å­¦å›¾åƒåˆ†å‰²é€šç”¨æ¨¡å‹çš„é‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²çš„é€šç”¨æ¨¡å‹éœ€è¦è§£å†³æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚</li>
<li>äº¤äº’å¼å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¨¡å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†éœ€è¦å¤§é‡æ ‡æ³¨ã€‚</li>
<li>WS-ICLæ˜¯ä¸€ç§æ–°çš„ICLæ¨¡å¼ï¼Œåˆ©ç”¨å¼±æç¤ºæ¥æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ˜¾è‘—é™ä½äº†æ ‡æ³¨å·¥ä½œé‡ã€‚</li>
<li>WS-ICLæ¨¡å‹æ€§èƒ½ä¸å¸¸è§„ICLæ¨¡å‹ç›¸å½“ï¼Œä¸”æ›´èŠ‚çœæ ‡æ³¨æˆæœ¬ã€‚</li>
<li>WS-ICLåœ¨äº¤äº’å¼æ¨¡å¼ä¸‹ä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„ç«äº‰åŠ›ã€‚</li>
<li>å®éªŒç»“æœåœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸ŠéªŒè¯äº†WS-ICLçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.05899">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8a5292bc220ea1ed6572a212d89d1b19~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100039&auth_key=1760100039-0-0-227183f7b29c5d019829e9a1e4ffab1e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9eceb461264db6c6105295bd162d8311~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100047&auth_key=1760100047-0-0-9e687d577d5e75d86f7b8634b62a56b5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ba7ce3cab4ca9533495c8b3688cc820e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100053&auth_key=1760100053-0-0-91ac86d820604a2d99953f500022fc9c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bc5f78297c6f0373bf41e51a444d4fdf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102796&auth_key=1760102796-0-0-28569ee50af46babcff3c26e533eed36&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-91ab70b2458a03b0a0eaea80e5071d7e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102802&auth_key=1760102802-0-0-420f59340093dc099b07993a6dca7276&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e8d64bbf0d07cb523a6bfbb8370f1a55~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102809&auth_key=1760102809-0-0-46ad05e6a83e4378cfe59f6b1aa59177&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="acia-workflows-Automated-Single-cell-Imaging-Analysis-for-Scalable-and-Deep-Learning-based-Live-cell-Imaging-Analysis-Workflows"><a href="#acia-workflows-Automated-Single-cell-Imaging-Analysis-for-Scalable-and-Deep-Learning-based-Live-cell-Imaging-Analysis-Workflows" class="headerlink" title="acia-workflows: Automated Single-cell Imaging Analysis for Scalable and   Deep Learning-based Live-cell Imaging Analysis Workflows"></a>acia-workflows: Automated Single-cell Imaging Analysis for Scalable and   Deep Learning-based Live-cell Imaging Analysis Workflows</h2><p><strong>Authors:Johannes Seiffarth, Keitaro Kasahara, Michelle Bund, Benita LÃ¼ckel, Richard D. Paul, Matthias Pesch, Lennart Witting, Michael Bott, Dietrich Kohlheyer, Katharina NÃ¶h</strong></p>
<p>Live-cell imaging (LCI) technology enables the detailed spatio-temporal characterization of living cells at the single-cell level, which is critical for advancing research in the life sciences, from biomedical applications to bioprocessing. High-throughput setups with tens to hundreds of parallel cell cultivations offer the potential for robust and reproducible insights. However, these insights are obscured by the large amount of LCI data recorded per experiment. Recent advances in state-of-the-art deep learning methods for cell segmentation and tracking now enable the automated analysis of such large data volumes, offering unprecedented opportunities to systematically study single-cell dynamics. The next key challenge lies in integrating these powerful tools into accessible, flexible, and user-friendly workflows that support routine application in biological research. In this work, we present acia-workflows, a platform that combines three key components: (1) the Automated live-Cell Imaging Analysis (acia) Python library, which supports the modular design of image analysis pipelines offering eight deep learning segmentation and tracking approaches; (2) workflows that assemble the image analysis pipeline, its software dependencies, documentation, and visualizations into a single Jupyter Notebook, leading to accessible, reproducible and scalable analysis workflows; and (3) a collection of application workflows showcasing the analysis and customization capabilities in real-world applications. Specifically, we present three workflows to investigate various types of microfluidic LCI experiments ranging from growth rate comparisons to precise, minute-resolution quantitative analyses of individual dynamic cells responses to changing oxygen conditions. Our collection of more than ten application workflows is open source and publicly available at <a target="_blank" rel="noopener" href="https://github.com/JuBiotech/acia-workflows">https://github.com/JuBiotech/acia-workflows</a>. </p>
<blockquote>
<p>æ´»ç»†èƒæˆåƒï¼ˆLCIï¼‰æŠ€æœ¯èƒ½å¤Ÿåœ¨å•ç»†èƒæ°´å¹³ä¸Šå¯¹æ´»ç»†èƒè¿›è¡Œè¯¦ç»†çš„æ—¶ç©ºç‰¹å¾è¡¨å¾ï¼Œè¿™å¯¹äºæ¨åŠ¨ç”Ÿå‘½ç§‘å­¦é¢†åŸŸçš„ç ”ç©¶è‡³å…³é‡è¦ï¼Œä»ç”Ÿç‰©åŒ»å­¦åº”ç”¨åˆ°ç”Ÿç‰©åŠ å·¥ã€‚å…·æœ‰æ•°ååˆ°æ•°ç™¾ä¸ªå¹¶è¡Œç»†èƒåŸ¹å…»çš„é«˜é€šé‡è®¾ç½®æä¾›äº†è·å¾—ç¨³å¥ä¸”å¯é‡å¤è§è§£çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›è§è§£è¢«æ¯æ¬¡å®éªŒè®°å½•çš„å¤§é‡LCIæ•°æ®æ‰€æ©ç›–ã€‚æœ€è¿‘å…ˆè¿›çš„æ·±åº¦å­¦ä¹ ç»†èƒåˆ†å‰²å’Œè¿½è¸ªæ–¹æ³•çš„è¿›æ­¥ç°åœ¨èƒ½å¤Ÿå®ç°æ­¤ç±»å¤§æ•°æ®é‡çš„è‡ªåŠ¨åˆ†æï¼Œä¸ºç³»ç»Ÿç ”ç©¶å•ç»†èƒåŠ¨æ€æä¾›äº†å‰æ‰€æœªæœ‰çš„æœºä¼šã€‚ä¸‹ä¸€ä¸ªå…³é”®æŒ‘æˆ˜åœ¨äºå°†è¿™äº›å¼ºå¤§å·¥å…·é›†æˆåˆ°å¯è®¿é—®ã€çµæ´»ä¸”ç”¨æˆ·å‹å¥½çš„å·¥ä½œæµä¸­ï¼Œä»¥æ”¯æŒç”Ÿç‰©å­¦ç ”ç©¶ä¸­çš„å¸¸è§„åº”ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºäº†acia-workflowså¹³å°ï¼Œè¯¥å¹³å°ç»“åˆäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šï¼ˆ1ï¼‰Automated live-Cell Imaging Analysisï¼ˆaciaï¼‰Pythonåº“ï¼Œæ”¯æŒå›¾åƒåˆ†æç®¡é“æ¨¡å—åŒ–è®¾è®¡ï¼Œæä¾›å…«ç§æ·±åº¦å­¦ä¹ åˆ†å‰²å’Œè¿½è¸ªæ–¹æ³•ï¼›ï¼ˆ2ï¼‰å°†å›¾åƒåˆ†æç®¡é“ã€å…¶è½¯ä»¶ä¾èµ–é¡¹ã€æ–‡æ¡£å’Œå¯è§†åŒ–ç»„è£…æˆå•ä¸ªJupyter Notebookçš„å·¥ä½œæµï¼Œä»è€Œå®ç°å¯è®¿é—®ã€å¯é‡å¤å’Œå¯æ‰©å±•çš„åˆ†æå·¥ä½œæµï¼›ï¼ˆ3ï¼‰å±•ç¤ºå®é™…åº”ç”¨ç¨‹åºä¸­åˆ†æå’Œå®šåˆ¶èƒ½åŠ›çš„ä¸€ç³»åˆ—åº”ç”¨å·¥ä½œæµã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸‰ç§å·¥ä½œæµï¼Œç”¨äºç ”ç©¶ä»ç”Ÿé•¿é€Ÿç‡æ¯”è¾ƒåˆ°å¯¹å˜åŒ–æ°§æ°”æ¡ä»¶ä¸‹å•ä¸ªåŠ¨æ€ç»†èƒçš„ç²¾ç¡®åˆ†é’Ÿåˆ†è¾¨ç‡å®šé‡åˆ†æçš„å„ç§ç±»å‹çš„å¾®æµä½“LCIå®éªŒã€‚æˆ‘ä»¬çš„è¶…è¿‡åä¸ªåº”ç”¨å·¥ä½œæµæ˜¯å¼€æºçš„ï¼Œå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JuBiotech/acia-workflows%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/JuBiotech/acia-workflowså…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.05886v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æ´»ä½“ç»†èƒæˆåƒæŠ€æœ¯å¯å®ç°å•ç»†èƒæ°´å¹³çš„æ—¶ç©ºç‰¹å¾è¯¦ç»†è¡¨å¾ï¼Œå¯¹ç”Ÿå‘½ç§‘å­¦é¢†åŸŸçš„ç ”ç©¶è‡³å…³é‡è¦ã€‚æ·±åº¦å­¦ä¹ æ–¹æ³•çš„æœ€æ–°è¿›å±•ä¸ºç»†èƒåˆ†å‰²å’Œè¿½è¸ªæä¾›äº†è‡ªåŠ¨åŒ–åˆ†æå¤§å‹æ•°æ®é›†çš„æœºä¼šï¼Œä¸ºç ”ç©¶å•ç»†èƒåŠ¨æ€æä¾›äº†å‰æ‰€æœªæœ‰çš„æœºä¼šã€‚å½“å‰çš„å…³é”®æŒ‘æˆ˜åœ¨äºå°†è¿™äº›å¼ºå¤§å·¥å…·é›†æˆåˆ°æ˜“äºè®¿é—®ã€çµæ´»å’Œç”¨æˆ·å‹å¥½çš„å·¥ä½œæµä¸­ï¼Œä»¥æ”¯æŒç”Ÿç‰©å­¦ç ”ç©¶ä¸­çš„å¸¸è§„åº”ç”¨ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬å±•ç¤ºäº†acia-workflowså¹³å°ï¼Œè¯¥å¹³å°ç»“åˆäº†è‡ªåŠ¨åŒ–æ´»ç»†èƒæˆåƒåˆ†æåº“ã€å›¾åƒåˆ†æç®¡é“çš„å·¥ä½œæµä»¥åŠå±•ç¤ºå®é™…åº”ç”¨çš„åˆ†æå’Œå®šåˆ¶èƒ½åŠ›çš„å·¥ä½œæµé›†åˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ´»ç»†èƒæˆåƒæŠ€æœ¯å¯¹äºç”Ÿå‘½ç§‘å­¦é¢†åŸŸçš„ç ”ç©¶è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿå®ç°å•ç»†èƒæ°´å¹³çš„è¯¦ç»†æ—¶ç©ºè¡¨å¾ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•çš„æœ€æ–°è¿›å±•ä¸ºç»†èƒåˆ†å‰²å’Œè¿½è¸ªçš„è‡ªåŠ¨åŒ–åˆ†ææä¾›äº†æœºä¼šã€‚</li>
<li>ç›®å‰æŒ‘æˆ˜åœ¨äºå°†è‡ªåŠ¨åŒ–åˆ†æå·¥å…·é›†æˆåˆ°æ˜“äºè®¿é—®ã€çµæ´»å’Œç”¨æˆ·å‹å¥½çš„å·¥ä½œæµä¸­ã€‚</li>
<li>acia-workflowså¹³å°ç»“åˆäº†è‡ªåŠ¨åŒ–æ´»ç»†èƒæˆåƒåˆ†æåº“ã€å›¾åƒåˆ†æç®¡é“çš„å·¥ä½œæµä»¥åŠå±•ç¤ºå·¥ä½œæµé›†åˆçš„åº”ç”¨ç¨‹åºã€‚</li>
<li>æä¾›äº†è¶…è¿‡åç§åº”ç”¨å·¥ä½œæµï¼Œå‡ä¸ºå¼€æºå¹¶å¯åœ¨å…¬å¼€æ¸ é“è·å–ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.05886">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d3b02196d6b5e12dd5f070d38f59dbfd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102817&auth_key=1760102817-0-0-1bc1a23ffc74778cb463b6a8a3274c74&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b4e31bf6e5ba629e965c7206a07726bb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760144617&auth_key=1760144617-0-0-6072e12985f5753ebbf605f638c33bdd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="TFM-Dataset-A-Novel-Multi-task-Dataset-and-Integrated-Pipeline-for-Automated-Tear-Film-Break-Up-Segmentation"><a href="#TFM-Dataset-A-Novel-Multi-task-Dataset-and-Integrated-Pipeline-for-Automated-Tear-Film-Break-Up-Segmentation" class="headerlink" title="TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for   Automated Tear Film Break-Up Segmentation"></a>TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for   Automated Tear Film Break-Up Segmentation</h2><p><strong>Authors:Guangrong Wan, Jun liu, Qiyang Zhou, Tang tang, Lianghao Shi, Wenjun Luo, TingTing Xu</strong></p>
<p>Tear film break-up (TFBU) analysis is critical for diagnosing dry eye syndrome, but automated TFBU segmentation remains challenging due to the lack of annotated datasets and integrated solutions. This paper introduces the Tear Film Multi-task (TFM) Dataset, the first comprehensive dataset for multi-task tear film analysis, comprising 15 high-resolution videos (totaling 6,247 frames) annotated with three vision tasks: frame-level classification (â€˜clearâ€™, â€˜closedâ€™, â€˜brokenâ€™, â€˜blurâ€™), Placido Ring detection, and pixel-wise TFBU area segmentation. Leveraging this dataset, we first propose TF-Net, a novel and efficient baseline segmentation model. TF-Net incorporates a MobileOne-mini backbone with re-parameterization techniques and an enhanced feature pyramid network to achieve a favorable balance between accuracy and computational efficiency for real-time clinical applications. We further establish benchmark performance on the TFM segmentation subset by comparing TF-Net against several state-of-the-art medical image segmentation models. Furthermore, we design TF-Collab, a novel integrated real-time pipeline that synergistically leverages models trained on all three tasks of the TFM dataset. By sequentially orchestrating frame classification for BUT determination, pupil region localization for input standardization, and TFBU segmentation, TF-Collab fully automates the analysis. Experimental results demonstrate the effectiveness of the proposed TF-Net and TF-Collab, providing a foundation for future research in ocular surface diagnostics. Our code and the TFM datasets are available at <a target="_blank" rel="noopener" href="https://github.com/glory-wan/TF-Net">https://github.com/glory-wan/TF-Net</a> </p>
<blockquote>
<p>æ³ªè†œç ´è£‚åˆ†æï¼ˆTFBUï¼‰å¯¹äºå¹²çœ¼ç»¼åˆå¾çš„è¯Šæ–­è‡³å…³é‡è¦ï¼Œä½†ç”±äºç¼ºä¹æ ‡æ³¨æ•°æ®é›†å’Œé›†æˆè§£å†³æ–¹æ¡ˆï¼Œè‡ªåŠ¨åŒ–TFBUåˆ†å‰²ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†æ³ªè†œå¤šä»»åŠ¡ï¼ˆTFMï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯ç”¨äºå¤šä»»åŠ¡æ³ªè†œåˆ†æçš„é¦–ä¸ªç»¼åˆæ•°æ®é›†ï¼ŒåŒ…å«15ä¸ªé«˜æ¸…è§†é¢‘ï¼ˆå…±6247å¸§ï¼‰ï¼Œæ ‡æ³¨äº†ä¸‰ä¸ªè§†è§‰ä»»åŠ¡ï¼šå¸§çº§åˆ«åˆ†ç±»ï¼ˆæ¸…æ™°ã€é—­åˆã€ç ´è£‚ã€æ¨¡ç³Šï¼‰ã€æ™®æ‹‰è¨å¤šç¯æ£€æµ‹å’Œåƒç´ çº§TFBUåŒºåŸŸåˆ†å‰²ã€‚åˆ©ç”¨è¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬é¦–æ¬¡æå‡ºäº†TF-Netï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„åˆ†å‰²åŸºçº¿æ¨¡å‹ã€‚TF-Neté‡‡ç”¨MobileOne-miniéª¨å¹²ç½‘ä¸é‡æ–°å‚æ•°åŒ–æŠ€æœ¯ï¼Œå¹¶å¢å¼ºç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼Œä»¥å®ç°å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡çš„å¹³è¡¡ï¼Œé€‚ç”¨äºå®æ—¶ä¸´åºŠåº”ç”¨ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å°†TF-Netä¸å‡ ç§æœ€å…ˆè¿›çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼Œåœ¨TFMåˆ†å‰²å­é›†ä¸Šå»ºç«‹äº†åŸºå‡†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†TF-Collabï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„ä¸€ä½“åŒ–å®æ—¶ç®¡é“ï¼Œå®ƒååŒåˆ©ç”¨åœ¨TFMæ•°æ®é›†æ‰€æœ‰ä¸‰ä¸ªä»»åŠ¡ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚é€šè¿‡æŒ‰é¡ºåºåè°ƒå¸§åˆ†ç±»ä»¥ç¡®å®šBUTã€å®šä½ç³å­”åŒºåŸŸä»¥å®ç°è¾“å…¥æ ‡å‡†åŒ–å’ŒTFBUåˆ†å‰²ï¼ŒTF-Collabå®ç°äº†åˆ†æçš„å…¨è‡ªåŠ¨åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜TF-Netå’ŒTF-Collabçš„æœ‰æ•ˆæ€§ï¼Œä¸ºçœ¼è¡¨è¯Šæ–­çš„æœªæ¥ç ”ç©¶æä¾›äº†åŸºç¡€ã€‚æˆ‘ä»¬çš„ä»£ç å’ŒTFMæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/glory-wan/TF-Net%E4%B8%8A%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/glory-wan/TF-Netä¸Šè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.05615v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹å¹²çœ¼ç»¼åˆå¾è¯Šæ–­ä¸­çš„æ³ªè†œç ´è£‚åˆ†æçš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºè‡ªåŠ¨åŒ–TFBUåˆ†å‰²é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†Tear Film Multi-taskï¼ˆTFMï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºå¤šä»»åŠ¡æ³ªè†œåˆ†æçš„ç»¼åˆæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†TF-Netï¼Œä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„åˆ†å‰²æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å®æ—¶ä¸´åºŠåº”ç”¨ä¸­å®ç°å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚æœ€åï¼Œå»ºç«‹äº†ä¸€ä¸ªé›†æˆå®æ—¶ç®¡é“TF-Collabï¼Œè¯¥ç®¡é“èƒ½å¤ŸååŒåˆ©ç”¨åœ¨TFMæ•°æ®é›†æ‰€æœ‰ä»»åŠ¡ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œå…¨è‡ªåŠ¨è¿›è¡Œæ³ªè†œåˆ†æã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†æ³ªè†œç ´è£‚åˆ†æåœ¨å¹²çœ¼ç»¼åˆå¾è¯Šæ–­ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>è‡ªåŠ¨åŒ–TFBUåˆ†å‰²é¢ä¸´ç¼ºä¹æ ‡æ³¨æ•°æ®é›†å’Œç»¼åˆè§£å†³æ–¹æ¡ˆçš„æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥äº†Tear Film Multi-taskï¼ˆTFMï¼‰æ•°æ®é›†ï¼ŒåŒ…å«ç”¨äºå¤šä»»åŠ¡æ³ªè†œåˆ†æçš„é«˜åˆ†è¾¨ç‡è§†é¢‘ã€‚</li>
<li>æå‡ºäº†TF-Netï¼Œä¸€ç§ç”¨äºå®æ—¶ä¸´åºŠåº”ç”¨çš„é«˜æ•ˆä¸”å‡†ç¡®çš„åˆ†å‰²æ¨¡å‹ã€‚</li>
<li>TF-Neté‡‡ç”¨MobileOne-miniä½œä¸ºéª¨å¹²ç½‘ï¼Œå¹¶é€šè¿‡å‚æ•°åŒ–æŠ€æœ¯å’Œå¢å¼ºçš„ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œå®ç°å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡çš„å¹³è¡¡ã€‚</li>
<li>å»ºç«‹äº†ä¸€ä¸ªé›†æˆå®æ—¶ç®¡é“TF-Collabï¼Œè¯¥ç®¡é“èƒ½å…¨è‡ªåŠ¨è¿›è¡Œæ³ªè†œåˆ†æï¼ŒåŒ…æ‹¬å¸§åˆ†ç±»ã€ç³å­”åŒºåŸŸå®šä½å’ŒTFBUåˆ†å‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.05615">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bf0f1a08a0a614e893aa691595c10d04~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102890&auth_key=1760102890-0-0-500d432bf094055dfd74c4745cfa1070&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-45f18c3a2836b05e44aed922f31236bd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102897&auth_key=1760102897-0-0-8acc686f5de8fcdc429bf2cf12cc1f1f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b60f84ef2d07c0c0724c6055654c7847~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102905&auth_key=1760102905-0-0-294cc8301111df30f3e3d7c804d1ae83&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3b920b779ce1c14250dc3e6a9bc0229b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102911&auth_key=1760102911-0-0-b95e0fb251d35d61e8b0040b02a49469&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5c8b505a2f5b3a59bb2983809f628f3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102918&auth_key=1760102918-0-0-fabafa81c5e7917a8e573628b3c66848&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6b08565542fdbe064d72ddf3b4de8999~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102925&auth_key=1760102925-0-0-5687af9d4f8b94e005bb7f2049366a2a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Advances-in-Medical-Image-Segmentation-A-Comprehensive-Survey-with-a-Focus-on-Lumbar-Spine-Applications"><a href="#Advances-in-Medical-Image-Segmentation-A-Comprehensive-Survey-with-a-Focus-on-Lumbar-Spine-Applications" class="headerlink" title="Advances in Medical Image Segmentation: A Comprehensive Survey with a   Focus on Lumbar Spine Applications"></a>Advances in Medical Image Segmentation: A Comprehensive Survey with a   Focus on Lumbar Spine Applications</h2><p><strong>Authors:Ahmed Kabil, Ghada Khoriba, Mina Yousef, Essam A. Rashed</strong></p>
<p>Medical Image Segmentation (MIS) stands as a cornerstone in medical image analysis, playing a pivotal role in precise diagnostics, treatment planning, and monitoring of various medical conditions. This paper presents a comprehensive and systematic survey of MIS methodologies, bridging the gap between traditional image processing techniques and modern deep learning approaches. The survey encompasses thresholding, edge detection, region-based segmentation, clustering algorithms, and model-based techniques while also delving into state-of-the-art deep learning architectures such as Convolutional Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely adopted U-Net and its variants. Moreover, integrating attention mechanisms, semi-supervised learning, generative adversarial networks (GANs), and Transformer-based models is thoroughly explored. In addition to covering established methods, this survey highlights emerging trends, including hybrid architectures, cross-modality learning, federated and distributed learning frameworks, and active learning strategies, which aim to address challenges such as limited labeled datasets, computational complexity, and model generalizability across diverse imaging modalities. Furthermore, a specialized case study on lumbar spine segmentation is presented, offering insights into the challenges and advancements in this relatively underexplored anatomical region. Despite significant progress in the field, critical challenges persist, including dataset bias, domain adaptation, interpretability of deep learning models, and integration into real-world clinical workflows. </p>
<blockquote>
<p>åŒ»å­¦å½±åƒåˆ†å‰²ï¼ˆMISï¼‰æ˜¯åŒ»å­¦å½±åƒåˆ†æä¸­çš„åŸºçŸ³æŠ€æœ¯ï¼Œåœ¨ç²¾ç¡®è¯Šæ–­ã€æ²»ç–—è§„åˆ’å’Œå„ç§åŒ»ç–—çŠ¶å†µç›‘æµ‹ä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚æœ¬æ–‡å¯¹MISæ–¹æ³•è¿›è¡Œå…¨é¢ç³»ç»Ÿçš„ç»¼è¿°ï¼Œå¼¥åˆäº†ä¼ ç»Ÿå›¾åƒå¤„ç†æŠ€æœ¯ä¸ç°ä»£æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¹‹é—´çš„å·®è·ã€‚ç»¼è¿°å†…å®¹åŒ…æ‹¬é˜ˆå€¼åˆ†å‰²ã€è¾¹ç¼˜æ£€æµ‹ã€åŸºäºåŒºåŸŸçš„åˆ†å‰²ã€èšç±»ç®—æ³•å’ŒåŸºäºæ¨¡å‹çš„æŠ€å·§ï¼ŒåŒæ—¶æ·±å…¥æ¢è®¨äº†æœ€æ–°çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€å…¨å·ç§¯ç½‘ç»œï¼ˆFCNï¼‰ä»¥åŠå¹¿æ³›é‡‡ç”¨çš„U-NetåŠå…¶å˜ä½“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ·±å…¥æ¢è®¨äº†é›†æˆæ³¨æ„åŠ›æœºåˆ¶ã€åŠç›‘ç£å­¦ä¹ ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’ŒåŸºäºTransformerçš„æ¨¡å‹ã€‚é™¤äº†æ¶µç›–å·²å»ºç«‹çš„æ–¹æ³•å¤–ï¼Œæœ¬æ–‡è¿˜å¼ºè°ƒäº†æ–°å…´è¶‹åŠ¿ï¼ŒåŒ…æ‹¬æ··åˆæ¶æ„ã€è·¨æ¨¡æ€å­¦ä¹ ã€è”é‚¦å’Œåˆ†å¸ƒå¼å­¦ä¹ æ¡†æ¶ä»¥åŠä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³è¯¸å¦‚æœ‰é™æ ‡è®°æ•°æ®é›†ã€è®¡ç®—å¤æ‚åº¦å’Œæ¨¡å‹åœ¨ä¸åŒæˆåƒæ–¹å¼ä¸‹çš„æ³›åŒ–èƒ½åŠ›æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œè¿˜å¯¹è…°æ¤åˆ†å‰²è¿›è¡Œäº†ä¸“é¡¹æ¡ˆä¾‹ç ”ç©¶ï¼Œæ·±å…¥æ¢è®¨äº†è¿™ä¸€ç›¸å¯¹æœªè¢«å……åˆ†ç ”ç©¶çš„è§£å‰–åŒºåŸŸçš„æŒ‘æˆ˜å’Œè¿›å±•ã€‚å°½ç®¡è¯¥é¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ä»å­˜åœ¨å…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®é›†åè§ã€åŸŸé€‚åº”ã€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è§£é‡Šæ€§å’Œèå…¥ç°å®ä¸´åºŠå·¥ä½œæµç¨‹ç­‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03318v1">PDF</a> Computers in Biology and Medicine (to appear)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…¨é¢ç³»ç»Ÿåœ°ç»¼è¿°äº†åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆMISï¼‰çš„æ–¹æ³•ï¼Œæ¶µç›–äº†ä»ä¼ ç»Ÿå›¾åƒå¤„ç†æŠ€æœ¯åˆ°ç°ä»£æ·±åº¦å­¦ä¹ æ–¹æ³•çš„è¿‡æ¸¡ã€‚æ–‡ç« ä»‹ç»äº†åŒ…æ‹¬é˜ˆå€¼åˆ†å‰²ã€è¾¹ç¼˜æ£€æµ‹ã€åŸºäºåŒºåŸŸçš„åˆ†å‰²ã€èšç±»ç®—æ³•å’Œæ¨¡å‹åŸºç¡€æŠ€æœ¯ç­‰åœ¨å†…çš„åˆ†å‰²æ–¹æ³•ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰ã€å…¨å·ç§¯ç½‘ç»œï¼ˆFCNsï¼‰ä»¥åŠå¹¿æ³›é‡‡ç”¨çš„U-NetåŠå…¶å˜ä½“ç­‰æœ€æ–°æ·±åº¦å­¦ä¹ æ¶æ„ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ¢è®¨äº†é›†æˆæ³¨æ„åŠ›æœºåˆ¶ã€åŠç›‘ç£å­¦ä¹ ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’ŒåŸºäºTransformerçš„æ¨¡å‹ç­‰è¶‹åŠ¿ã€‚æ–‡ç« è¿˜é€šè¿‡è…°æ¤åˆ†å‰²çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†è¯¥é¢†åŸŸçš„æŒ‘æˆ˜å’Œè¿›å±•ã€‚å°½ç®¡æœ‰æ‰€è¿›å±•ï¼Œä½†ä»å­˜åœ¨æ•°æ®é›†åè§ã€åŸŸé€‚åº”ã€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œä¸çœŸå®ä¸´åºŠå·¥ä½œæµç¨‹çš„èåˆç­‰æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆMISï¼‰æ˜¯åŒ»å­¦å›¾åƒåˆ†æçš„æ ¸å¿ƒï¼Œå¯¹ç²¾ç¡®è¯Šæ–­ã€æ²»ç–—è§„åˆ’å’Œå„ç§åŒ»ç–—çŠ¶å†µçš„ç›‘ç£è‡³å…³é‡è¦ã€‚</li>
<li>æœ¬æ–‡ç»¼è¿°äº†MISçš„ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¦‚é˜ˆå€¼åˆ†å‰²ã€è¾¹ç¼˜æ£€æµ‹ç­‰ï¼Œä»¥åŠç°ä»£æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œç­‰ã€‚</li>
<li>æ–‡ç« è¿˜æ¢è®¨äº†é›†æˆæ³¨æ„åŠ›æœºåˆ¶ã€åŠç›‘ç£å­¦ä¹ ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç­‰è¶‹åŠ¿ï¼Œå¹¶ä»‹ç»äº†æ–°å…´è¶‹åŠ¿ï¼Œå¦‚æ··åˆæ¶æ„ã€è·¨æ¨¡æ€å­¦ä¹ ç­‰ã€‚</li>
<li>è…°æ¤åˆ†å‰²çš„æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†è¯¥é¢†åŸŸçš„æŒ‘æˆ˜å’Œè¿›å±•ã€‚</li>
<li>å°½ç®¡MISæœ‰æ‰€è¿›å±•ï¼Œä½†ä»é¢ä¸´æ•°æ®é›†åè§ã€åŸŸé€‚åº”ã€æ¨¡å‹å¯è§£é‡Šæ€§å’Œä¸ä¸´åºŠå·¥ä½œæµç¨‹çš„èåˆç­‰æŒ‘æˆ˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03318">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e4cd82510eee36698d242dc5b7c6866c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102932&auth_key=1760102932-0-0-2975962aa3d551d0697c7f6d1044f811&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f673e2cb32b8859abdcc041e10beb31b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102940&auth_key=1760102940-0-0-d6e23796b4d762e585d8aa28f1658123&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Semantic-Similarity-in-Radiology-Reports-via-LLMs-and-NER"><a href="#Semantic-Similarity-in-Radiology-Reports-via-LLMs-and-NER" class="headerlink" title="Semantic Similarity in Radiology Reports via LLMs and NER"></a>Semantic Similarity in Radiology Reports via LLMs and NER</h2><p><strong>Authors:Beth Pearson, Ahmed Adnan, Zahraa S. Abdallah</strong></p>
<p>Radiology report evaluation is a crucial part of radiologistsâ€™ training and plays a key role in ensuring diagnostic accuracy. As part of the standard reporting workflow, a junior radiologist typically prepares a preliminary report, which is then reviewed and edited by a senior radiologist to produce the final report. Identifying semantic differences between preliminary and final reports is essential for junior doctors, both as a training tool and to help uncover gaps in clinical knowledge. While AI in radiology is a rapidly growing field, the application of large language models (LLMs) remains challenging due to the need for specialised domain knowledge. In this paper, we explore the ability of LLMs to provide explainable and accurate comparisons of reports in the radiology domain. We begin by comparing the performance of several LLMs in comparing radiology reports. We then assess a more traditional approach based on Named-Entity-Recognition (NER). However, both approaches exhibit limitations in delivering accurate feedback on semantic similarity. To address this, we propose Llama-EntScore, a semantic similarity scoring method using a combination of Llama 3.1 and NER with tunable weights to emphasise or de-emphasise specific types of differences. Our approach generates a quantitative similarity score for tracking progress and also gives an interpretation of the score that aims to offer valuable guidance in reviewing and refining their reporting. We find our method achieves 67% exact-match accuracy and 93% accuracy within +&#x2F;- 1 when compared to radiologist-provided ground truth scores - outperforming both LLMs and NER used independently. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/otmive/llama_reports">https://github.com/otmive/llama_reports</a> </p>
<blockquote>
<p>æ”¾å°„å­¦æŠ¥å‘Šè¯„ä¼°æ˜¯æ”¾å°„ç§‘åŒ»ç”ŸåŸ¹è®­çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå¯¹äºç¡®ä¿è¯Šæ–­å‡†ç¡®æ€§èµ·ç€å…³é”®ä½œç”¨ã€‚ä½œä¸ºæ ‡å‡†æŠ¥å‘Šå·¥ä½œæµçš„ä¸€éƒ¨åˆ†ï¼Œåˆçº§æ”¾å°„ç§‘åŒ»ç”Ÿé€šå¸¸ä¼šç¼–å†™åˆæ­¥æŠ¥å‘Šï¼Œç„¶åç”±é«˜çº§æ”¾å°„ç§‘åŒ»ç”Ÿå®¡æŸ¥å¹¶ç¼–è¾‘ä»¥äº§ç”Ÿæœ€ç»ˆæŠ¥å‘Šã€‚è¯†åˆ«åˆæ­¥æŠ¥å‘Šå’Œæœ€ç»ˆæŠ¥å‘Šä¹‹é—´çš„è¯­ä¹‰å·®å¼‚å¯¹åˆçº§åŒ»ç”Ÿè‡³å…³é‡è¦ï¼Œæ—¢ä½œä¸ºåŸ¹è®­å·¥å…·ï¼Œä¹Ÿæœ‰åŠ©äºå‘ç°ä¸´åºŠçŸ¥è¯†æ–¹é¢çš„å·®è·ã€‚è™½ç„¶äººå·¥æ™ºèƒ½åœ¨æ”¾å°„å­¦é¢†åŸŸæ˜¯ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸï¼Œä½†ç”±äºéœ€è¦ä¸“ä¸šçš„é¢†åŸŸçŸ¥è¯†ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ”¾å°„å­¦æŠ¥å‘Šæ¯”è¾ƒæ–¹é¢çš„è§£é‡Šæ€§å’Œå‡†ç¡®æ€§èƒ½åŠ›ã€‚æˆ‘ä»¬é¦–å…ˆæ¯”è¾ƒäº†å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¯”è¾ƒæ”¾å°„å­¦æŠ¥å‘Šæ–¹é¢çš„æ€§èƒ½ã€‚ç„¶åè¯„ä¼°äº†åŸºäºå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰çš„æ›´ä¼ ç»Ÿçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œè¿™ä¸¤ç§æ–¹æ³•åœ¨æä¾›è¯­ä¹‰ç›¸ä¼¼æ€§å‡†ç¡®åé¦ˆæ–¹é¢éƒ½è¡¨ç°å‡ºå±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Llama-EntScoreæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨Llama 3.1å’ŒNERçš„ç»„åˆçš„è¯­ä¹‰ç›¸ä¼¼æ€§è¯„åˆ†æ–¹æ³•ï¼Œé€šè¿‡è°ƒæ•´æƒé‡æ¥å¼ºè°ƒæˆ–æ·¡åŒ–ç‰¹å®šç±»å‹çš„å·®å¼‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆä¸€ä¸ªå®šé‡ç›¸ä¼¼æ€§åˆ†æ•°æ¥è·Ÿè¸ªè¿›åº¦ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªåˆ†æ•°è§£é‡Šï¼Œæ—¨åœ¨æä¾›æœ‰ä»·å€¼çš„æŒ‡å¯¼æ¥å®¡æŸ¥å’Œä¿®æ­£æŠ¥å‘Šã€‚æˆ‘ä»¬å‘ç°ï¼Œä¸æ”¾å°„ç§‘åŒ»ç”Ÿæä¾›çš„çœŸå®åˆ†æ•°ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†67%çš„ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡å’Œ93%çš„+&#x2F;- 1å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†å•ç‹¬ä½¿ç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹å’ŒNERçš„æ€§èƒ½ã€‚ç›¸å…³ä»£ç å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/otmive/llama_reports">https://github.com/otmive/llama_reports</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03102v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ”¾å°„å­¦æŠ¥å‘Šæ¯”è¾ƒä¸­çš„åº”ç”¨ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰ç›¸ä¼¼æ€§è¯„åˆ†æ–¹æ³•Llama-EntScoreã€‚è¯¥æ–¹æ³•ç»“åˆäº†Llama 3.1å’Œå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ï¼Œå¯ä»¥ç”Ÿæˆå®šé‡ç›¸ä¼¼æ€§è¯„åˆ†å¹¶è§£é‡Šè¯„åˆ†ï¼Œæ—¨åœ¨æä¾›æœ‰ä»·å€¼çš„æŒ‡å¯¼ï¼Œå¸®åŠ©åŒ»ç”Ÿè¯„ä¼°å’Œç²¾è¿›æŠ¥å‘Šè´¨é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ”¾å°„å­¦æŠ¥å‘Šè¯„ä¼°ä¸­çš„å‡†ç¡®ç‡é«˜äºå•çº¯ä½¿ç”¨LLMså’ŒNERã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ”¾å°„å­¦æŠ¥å‘Šè¯„ä¼°æ˜¯æ”¾å°„ç§‘åŒ»ç”ŸåŸ¹è®­çš„å…³é”®ç¯èŠ‚ï¼Œæœ‰åŠ©äºç¡®ä¿è¯Šæ–­å‡†ç¡®æ€§ã€‚</li>
<li>åˆæ­¥æŠ¥å‘Šä¸æœ€ç»ˆæŠ¥å‘Šä¹‹é—´çš„è¯­ä¹‰å·®å¼‚åˆ†æå¯¹åˆçº§åŒ»ç”Ÿå…·æœ‰è®­ç»ƒä»·å€¼ï¼Œæœ‰åŠ©äºå‘ç°ä¸´åºŠçŸ¥è¯†ä¸Šçš„ä¸è¶³ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ”¾å°„å­¦é¢†åŸŸçš„åº”ç”¨æ­£é€æ¸å—åˆ°å…³æ³¨ï¼Œä½†å­˜åœ¨ä¸“ä¸šé¢†åŸŸçŸ¥è¯†éœ€æ±‚çš„æŒ‘æˆ˜ã€‚</li>
<li>å•ä¸€çš„LLMså’Œå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æ–¹æ³•åœ¨è¯„ä¼°æŠ¥å‘Šç›¸ä¼¼æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æå‡ºäº†Llama-EntScoreæ–¹æ³•ï¼Œç»“åˆäº†Llama 3.1å’ŒNERï¼Œå¹¶å¯é€šè¿‡è°ƒæ•´æƒé‡æ¥å¼ºè°ƒæˆ–æ·¡åŒ–ç‰¹å®šç±»å‹çš„å·®å¼‚ã€‚</li>
<li>Llama-EntScoreæ–¹æ³•å®ç°äº†è¾ƒé«˜çš„è¯„ä¼°å‡†ç¡®ç‡ï¼Œä¸æ”¾å°„ç§‘åŒ»ç”Ÿæä¾›çš„çœŸå®è¯„åˆ†ç›¸æ¯”ï¼Œç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡ä¸º67%ï¼Œåœ¨Â±1èŒƒå›´å†…çš„å‡†ç¡®ç‡ä¸º93%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03102">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c9e68be5e328595700d63064858cc2b1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102948&auth_key=1760102948-0-0-2e3fab942e49a8e2835e121ec0e13030&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Mask-What-Matters-Controllable-Text-Guided-Masking-for-Self-Supervised-Medical-Image-Analysis"><a href="#Mask-What-Matters-Controllable-Text-Guided-Masking-for-Self-Supervised-Medical-Image-Analysis" class="headerlink" title="Mask What Matters: Controllable Text-Guided Masking for Self-Supervised   Medical Image Analysis"></a>Mask What Matters: Controllable Text-Guided Masking for Self-Supervised   Medical Image Analysis</h2><p><strong>Authors:Ruilang Wang, Shuotong Xu, Bowen Liu, Runlin Huang, Donglong Chen, Weifeng Su</strong></p>
<p>The scarcity of annotated data in specialized domains such as medical imaging presents significant challenges to training robust vision models. While self-supervised masked image modeling (MIM) offers a promising solution, existing approaches largely rely on random high-ratio masking, leading to inefficiency and poor semantic alignment. Moreover, region-aware variants typically depend on reconstruction heuristics or supervised signals, limiting their adaptability across tasks and modalities. We propose Mask What Matters, a controllable text-guided masking framework for self-supervised medical image analysis. By leveraging vision-language models for prompt-based region localization, our method flexibly applies differentiated masking to emphasize diagnostically relevant regions while reducing redundancy in background areas. This controllable design enables better semantic alignment, improved representation learning, and stronger cross-task generalizability. Comprehensive evaluation across multiple medical imaging modalities, including brain MRI, chest CT, and lung X-ray, shows that Mask What Matters consistently outperforms existing MIM methods (e.g., SparK), achieving gains of up to +3.1 percentage points in classification accuracy, +1.3 in box average precision (BoxAP), and +1.1 in mask average precision (MaskAP) for detection. Notably, it achieves these improvements with substantially lower overall masking ratios (e.g., 40% vs. 70%). This work demonstrates that controllable, text-driven masking can enable semantically aligned self-supervised learning, advancing the development of robust vision models for medical image analysis. </p>
<blockquote>
<p>åœ¨åŒ»å­¦æˆåƒç­‰ä¸“ä¸šé¢†åŸŸï¼Œæ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºæ€§ç»™è®­ç»ƒç¨³å¥çš„è§†è§‰æ¨¡å‹å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚è™½ç„¶è‡ªç›‘ç£çš„æ©ç å›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰æä¾›äº†å¾ˆæœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰çš„æ–¹æ³•å¤§å¤šä¾èµ–äºéšæœºçš„é«˜æ¯”ä¾‹æ©ç ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œè¯­ä¹‰å¯¹é½ä¸ä½³ã€‚æ­¤å¤–ï¼ŒåŒºåŸŸæ„ŸçŸ¥å˜ä½“é€šå¸¸ä¾èµ–äºé‡å»ºå¯å‘å¼æˆ–ç›‘ç£ä¿¡å·ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨ä»»åŠ¡å’Œæ¨¡æ€ä¹‹é—´çš„é€‚åº”æ€§ã€‚æˆ‘ä»¬æå‡ºäº†â€œMask What Mattersâ€ï¼ˆæ©è—å…³é”®ä¿¡æ¯ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè‡ªç›‘ç£åŒ»å­¦å›¾åƒåˆ†æçš„å¯æ§æ–‡æœ¬å¼•å¯¼å¼æ©ç æ¡†æ¶ã€‚é€šè¿‡åˆ©ç”¨åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æç¤ºè¿›è¡ŒåŒºåŸŸå®šä½ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥çµæ´»åœ°åº”ç”¨å·®å¼‚åŒ–æ©ç ï¼Œä»¥å¼ºè°ƒä¸è¯Šæ–­ç›¸å…³çš„åŒºåŸŸï¼ŒåŒæ—¶å‡å°‘èƒŒæ™¯åŒºåŸŸçš„å†—ä½™ä¿¡æ¯ã€‚è¿™ç§å¯æ§çš„è®¾è®¡å®ç°äº†æ›´å¥½çš„è¯­ä¹‰å¯¹é½ã€æ”¹è¿›äº†è¡¨å¾å­¦ä¹ ï¼Œå¹¶å¢å¼ºäº†è·¨ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨åŒ…æ‹¬è„‘éƒ¨MRIã€èƒ¸éƒ¨CTå’Œè‚ºéƒ¨Xå°„çº¿ç­‰å¤šç§åŒ»å­¦å½±åƒæ¨¡æ€ä¸Šçš„å…¨é¢è¯„ä¼°è¡¨æ˜ï¼Œâ€œMask What Mattersâ€å§‹ç»ˆä¼˜äºç°æœ‰çš„MIMæ–¹æ³•ï¼ˆä¾‹å¦‚SparKï¼‰ï¼Œåœ¨åˆ†ç±»å‡†ç¡®åº¦ä¸Šæé«˜äº†é«˜è¾¾+3.1ä¸ªç™¾åˆ†ç‚¹ï¼Œæ¡†å¹³å‡ç²¾åº¦ï¼ˆBoxAPï¼‰æé«˜äº†+1.3ï¼Œæ©è†œå¹³å‡ç²¾åº¦ï¼ˆMaskAPï¼‰åœ¨æ£€æµ‹æ–¹é¢æé«˜äº†+1.1ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå®ƒåœ¨å®ç°è¿™äº›æ”¹è¿›çš„åŒæ—¶ï¼Œæ•´ä½“æ©ç æ¯”ä¾‹å¤§å¤§é™ä½ï¼ˆä¾‹å¦‚ï¼Œ40%å¯¹70%ï¼‰ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œå¯æ§çš„ã€æ–‡æœ¬é©±åŠ¨çš„æ©ç å¯ä»¥å®ç°å¯¹é½è¯­ä¹‰çš„è‡ªç›‘ç£å­¦ä¹ ï¼Œæ¨åŠ¨åŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸç¨³å¥è§†è§‰æ¨¡å‹çš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23054v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒé¢†åŸŸé¢ä¸´æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œè‡ªç›‘ç£æ©è†œå›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰æ˜¯è§£å†³è¯¥é—®é¢˜çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤§å¤šä¾èµ–éšæœºé«˜æ¯”ä¾‹æ©è†œï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œè¯­ä¹‰å¯¹é½ä¸ä½³ã€‚æœ¬æ–‡æå‡ºMask What Mattersï¼Œä¸€ç§å¯æ§æ–‡æœ¬å¼•å¯¼æ©è†œæ¡†æ¶ï¼Œç”¨äºè‡ªç›‘ç£åŒ»å­¦å›¾åƒåˆ†æã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡ŒåŸºäºæç¤ºçš„åŒºåŸŸå®šä½ï¼Œçµæ´»åº”ç”¨å·®å¼‚åŒ–æ©è†œï¼Œå¼ºè°ƒè¯Šæ–­ç›¸å…³åŒºåŸŸï¼Œå‡å°‘èƒŒæ™¯åŒºåŸŸçš„å†—ä½™ã€‚è¯¥å¯æ§è®¾è®¡å®ç°äº†æ›´å¥½çš„è¯­ä¹‰å¯¹é½ã€æ”¹è¿›äº†è¡¨ç¤ºå­¦ä¹ å’Œæ›´å¼ºçš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚åœ¨å¤šç§åŒ»å­¦æˆåƒæ¨¡æ€ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒMask What Mattersåœ¨åˆ†ç±»ç²¾åº¦ã€æ¡†å¹³å‡ç²¾åº¦å’Œæ©è†œå¹³å‡ç²¾åº¦æ–¹é¢å‡ä¼˜äºç°æœ‰MIMæ–¹æ³•ï¼Œä¸”å®ç°è¿™äº›æ”¹è¿›çš„åŒæ—¶ä½¿ç”¨æ›´ä½çš„æ€»ä½“æ©è†œæ¯”ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒé¢†åŸŸé¢ä¸´æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ã€‚</li>
<li>è‡ªç›‘ç£æ©è†œå›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰æ˜¯è§£å†³è¯¥é—®é¢˜çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨éšæœºé«˜æ¯”ä¾‹æ©è†œå¯¼è‡´çš„æ•ˆç‡ä½ä¸‹å’Œè¯­ä¹‰å¯¹é½ä¸ä½³çš„é—®é¢˜ã€‚</li>
<li>Mask What Mattersæ˜¯ä¸€ç§å¯æ§æ–‡æœ¬å¼•å¯¼æ©è†œæ¡†æ¶ï¼Œç”¨äºè‡ªç›‘ç£åŒ»å­¦å›¾åƒåˆ†æã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡ŒåŸºäºæç¤ºçš„åŒºåŸŸå®šä½ï¼Œå®ç°å·®å¼‚åŒ–æ©è†œï¼Œå¼ºè°ƒè¯Šæ–­ç›¸å…³åŒºåŸŸã€‚</li>
<li>Mask What Matterså®ç°äº†æ›´å¥½çš„è¯­ä¹‰å¯¹é½ã€æ”¹è¿›äº†è¡¨ç¤ºå­¦ä¹ å’Œæ›´å¼ºçš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨å¤šç§åŒ»å­¦æˆåƒæ¨¡æ€ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒMask What Mattersä¼˜äºç°æœ‰MIMæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23054">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bb7d1fad51aa5e24ffda5efaa8b1987e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102956&auth_key=1760102956-0-0-ef8b4a73ceeaabe4db45946eaca130ea&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9a9b77f37528ad3b0dbd3a78e5592431~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102964&auth_key=1760102964-0-0-567119c3c695ea1d7b0beb33f941eb19&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fe1061d4ddbf133c81b10db1428f0a39~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102972&auth_key=1760102972-0-0-13237b9780a2eec8d55f21770674bbc5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0b9a818f2a1ca134a250753278bd4fc8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102979&auth_key=1760102979-0-0-e111a7c6db390a7b5f9ddae1c760c459&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="EMedNeXt-An-Enhanced-Brain-Tumor-Segmentation-Framework-for-Sub-Saharan-Africa-using-MedNeXt-V2-with-Deep-Supervision"><a href="#EMedNeXt-An-Enhanced-Brain-Tumor-Segmentation-Framework-for-Sub-Saharan-Africa-using-MedNeXt-V2-with-Deep-Supervision" class="headerlink" title="EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan   Africa using MedNeXt V2 with Deep Supervision"></a>EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan   Africa using MedNeXt V2 with Deep Supervision</h2><p><strong>Authors:Ahmed Jaheen, Abdelrahman Elsayed, Damir Kim, Daniil Tikhonov, Matheus Scatolin, Mohor Banerjee, Qiankun Ji, Mostafa Salem, Hu Wang, Sarim Hashmi, Mohammad Yaqub</strong></p>
<p>Brain cancer affects millions worldwide, and in nearly every clinical setting, doctors rely on magnetic resonance imaging (MRI) to diagnose and monitor gliomas. However, the current standard for tumor quantification through manual segmentation of multi-parametric MRI is time-consuming, requires expert radiologists, and is often infeasible in under-resourced healthcare systems. This problem is especially pronounced in low-income regions, where MRI scanners are of lower quality and radiology expertise is scarce, leading to incorrect segmentation and quantification. In addition, the number of acquired MRI scans in Africa is typically small. To address these challenges, the BraTS-Lighthouse 2025 Challenge focuses on robust tumor segmentation in sub-Saharan Africa (SSA), where resource constraints and image quality degradation introduce significant shifts. In this study, we present EMedNeXt â€“ an enhanced brain tumor segmentation framework based on MedNeXt V2 with deep supervision and optimized post-processing pipelines tailored for SSA. EMedNeXt introduces three key contributions: a larger region of interest, an improved nnU-Net v2-based architectural skeleton, and a robust model ensembling system. Evaluated on the hidden validation set, our solution achieved an average LesionWise DSC of 0.897 with an average LesionWise NSD of 0.541 and 0.84 at a tolerance of 0.5 mm and 1.0 mm, respectively. </p>
<blockquote>
<p>è„‘ç™Œå½±å“å…¨çƒæ•°ç™¾ä¸‡äººï¼Œåœ¨å‡ ä¹æ‰€æœ‰çš„ä¸´åºŠç¯å¢ƒä¸­ï¼ŒåŒ»ç”Ÿéƒ½ä¾èµ–ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ¥è¯Šæ–­å’Œç›‘æµ‹èƒ¶è´¨ç˜¤ã€‚ç„¶è€Œï¼Œé€šè¿‡å¤šå‚æ•°MRIè¿›è¡Œè‚¿ç˜¤é‡åŒ–çš„æ‰‹åŠ¨åˆ†å‰²æ˜¯ç›®å‰çš„æ ‡å‡†ï¼Œè¿™ä¸€è¿‡ç¨‹æ—¢è€—æ—¶åˆéœ€è¦ä¸“ä¸šæ”¾å°„ç§‘åŒ»ç”Ÿï¼Œä¸”åœ¨èµ„æºä¸è¶³çš„å«ç”Ÿä¿å¥ç³»ç»Ÿä¸­é€šå¸¸ä¸å¯è¡Œã€‚è¿™ä¸€é—®é¢˜åœ¨ä½æ”¶å…¥åœ°åŒºå°¤ä¸ºçªå‡ºï¼Œé‚£é‡Œçš„MRIæ‰«æä»ªè´¨é‡è¾ƒä½ä¸”ç¼ºä¹æ”¾å°„å­¦ä¸“å®¶ï¼Œå¯¼è‡´åˆ†å‰²å’Œé‡åŒ–ä¸å‡†ç¡®ã€‚æ­¤å¤–ï¼Œéæ´²è·å¾—çš„MRIæ‰«ææ¬¡æ•°é€šå¸¸è¾ƒå°‘ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼ŒBraTS-Lighthouse 2025æŒ‘æˆ˜èµ›çš„é‡ç‚¹æ˜¯æ’’å“ˆæ‹‰ä»¥å—éæ´²ï¼ˆSSAï¼‰çš„ç¨³å¥è‚¿ç˜¤åˆ†å‰²ï¼Œé‚£é‡Œçš„èµ„æºçº¦æŸå’Œå›¾åƒè´¨é‡é€€åŒ–å¼•å…¥äº†é‡å¤§å˜åŒ–ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†EMedNeXtâ€”â€”ä¸€ä¸ªåŸºäºMedNeXt V2çš„å¢å¼ºå‹è„‘è‚¿ç˜¤åˆ†å‰²æ¡†æ¶ï¼Œå…·æœ‰æ·±åº¦ç›‘ç£å’Œé’ˆå¯¹SSAä¼˜åŒ–çš„åå¤„ç†ç®¡é“ã€‚EMedNeXtæœ‰ä¸‰ä¸ªä¸»è¦è´¡çŒ®ï¼šæ›´å¤§çš„æ„Ÿå…´è¶£åŒºåŸŸã€æ”¹è¿›çš„nnU-Net v2åŸºç¡€æ¶æ„å’Œç¨³å¥çš„æ¨¡å‹é›†æˆç³»ç»Ÿã€‚åœ¨éšè—éªŒè¯é›†ä¸Šè¯„ä¼°ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå¹³å‡LesionWise DSCè¾¾åˆ°0.897ï¼Œå¹³å‡LesionWise NSDä¸º0.541å’Œ0.84ï¼Œå®¹å¿åº¦åˆ†åˆ«ä¸º0.5æ¯«ç±³å’Œ1.0æ¯«ç±³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.23256v2">PDF</a> Submitted to the BraTS-Lighthouse 2025 Challenge (MICCAI 2025)</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹éæ´²åœ°åŒºåŒ»ç–—èµ„æºåŒ®ä¹ã€MRIæ‰«æè´¨é‡è¾ƒå·®çš„é—®é¢˜ï¼ŒEMedNeXtæ¡†æ¶è¢«æå‡ºä»¥è§£å†³è„‘èƒ¶è´¨ç˜¤åˆ†å‰²çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ä¼˜åŒ–äº†è‚¿ç˜¤åˆ†å‰²æµç¨‹ï¼Œå¼•å…¥äº†æ›´å¤§æ„Ÿå…´è¶£åŒºåŸŸã€æ”¹è¿›å‹nnU-Net v2æ¶æ„å’Œç¨³å¥æ¨¡å‹é›†æˆç³»ç»Ÿï¼Œå¹¶åœ¨éšè—éªŒè¯é›†ä¸Šå–å¾—äº†è‰¯å¥½çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰çš„è„‘ç™Œè¯Šæ–­ä¸»è¦ä¾èµ–MRIï¼Œä½†åœ¨èµ„æºä¸è¶³çš„å«ç”Ÿç³»ç»Ÿä¸­è¿›è¡Œè‚¿ç˜¤é‡åŒ–åˆ†å‰²ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç‰¹åˆ«æ˜¯åœ¨ä½æ”¶å…¥å’ŒåŒ»ç–—èµ„æºåŒ®ä¹çš„åœ°åŒºï¼Œå¦‚éæ´²ã€‚</li>
<li>EMedNeXtæ¡†æ¶æ˜¯ä¸ºäº†è§£å†³åœ¨æ’’å“ˆæ‹‰ä»¥å—éæ´²åœ°åŒºï¼ˆSSAï¼‰è¿›è¡Œç¨³å¥çš„è‚¿ç˜¤åˆ†å‰²é—®é¢˜è€Œå¼€å‘çš„ã€‚è¿™ä¸€åœ°åŒºé¢ä¸´ç€èµ„æºçº¦æŸå’Œå›¾åƒè´¨é‡ä¸‹é™çš„æŒ‘æˆ˜ã€‚</li>
<li>EMedNeXtæ¡†æ¶åŸºäºMedNeXt V2è¿›è¡Œäº†å¢å¼ºè®¾è®¡ï¼Œå¼•å…¥äº†æ·±åº¦ç›‘ç£å’Œä¼˜åŒ–åçš„åå¤„ç†ç®¡é“ã€‚</li>
<li>è¯¥æ¡†æ¶æœ‰ä¸‰ä¸ªå…³é”®è´¡çŒ®ï¼šæ›´å¤§çš„æ„Ÿå…´è¶£åŒºåŸŸã€æ”¹è¿›çš„nnU-Net v2æ¶æ„å’Œç¨³å¥çš„æ¨¡å‹é›†æˆç³»ç»Ÿã€‚</li>
<li>åœ¨éšè—éªŒè¯é›†ä¸Šè¿›è¡Œçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒEMedNeXtçš„è§£å†³æ–¹æ¡ˆåœ¨LesionWise DSCä¸Šå–å¾—äº†å¹³å‡0.897çš„æˆç»©ï¼ŒLesionWise NSDçš„å¹³å‡æˆç»©ä¸º0.541å’Œ0.84ï¼ˆå®¹å¿åº¦ä¸º0.5æ¯«ç±³å’Œ1æ¯«ç±³ï¼‰ã€‚è¿™è¡¨æ˜è¯¥æ¡†æ¶åœ¨è‚¿ç˜¤åˆ†å‰²æ–¹é¢å…·æœ‰è‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>è¯¥ç ”ç©¶å¼ºè°ƒäº†å¼€å‘é€‚ç”¨äºèµ„æºå—é™åœ°åŒºçš„åŒ»ç–—æŠ€æœ¯çš„å¿…è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨ç°ä»£æœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æ”¹å–„å…¨çƒå…¬å…±å«ç”ŸçŠ¶å†µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.23256">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-28af5e7fe2cbc39eb4bd00206c895873~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102986&auth_key=1760102986-0-0-7482cbbf39dd2b67f978b90f7e9293b6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ca8811a6cc12935992263eb4eeff0a8e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760102995&auth_key=1760102995-0-0-c7d813cd2cdc561f2c7959562d8c3455&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cf377d2ed4e195e8ff779c92d967cfba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760103001&auth_key=1760103001-0-0-bdd07d61a2a5eaebfb2fd81f44250f81&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ae128f5648daa610889e8ac3d0ea4314~resize:0:q75.jpg?source=1f5c5e47&expiration=1760103009&auth_key=1760103009-0-0-c5bb4fdfa8e6b5b57ee13221816941c0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d7287f66981914f6072452faeb537131~resize:0:q75.jpg?source=1f5c5e47&expiration=1760103016&auth_key=1760103016-0-0-73c7014e616f8abd42efaf6a8371e488&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dc984c7a0532b7be8dfa071e32958b8e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760103024&auth_key=1760103024-0-0-efe02f2dbbc462007fa3b7981ef1bfff&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-10/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-10/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-10/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-c981097f21d942ca619f24ad33241a35~resize:0:q75.jpg?source=1f5c5e47&expiration=1760083705&auth_key=1760083705-0-0-09ffbb7b8bcb24f1514393a2288a555f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-10  Making Machines Sound Sarcastic LLM-Enhanced and Retrieval-Guided   Sarcastic Speech Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-10/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-5c1dac7ca7b84dc25e84f11de04be385~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047566&auth_key=1760047566-0-0-7b2f1a428a78e17daf3a2cf76315d024&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-10  StyleKeeper Prevent Content Leakage using Negative Visual Query   Guidance
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30762.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
