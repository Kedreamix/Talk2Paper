<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-10  StyleKeeper Prevent Content Leakage using Negative Visual Query   Guidance">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-5c1dac7ca7b84dc25e84f11de04be385~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047566&auth_key=1760047566-0-0-7b2f1a428a78e17daf3a2cf76315d024&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    28 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-10-æ›´æ–°"><a href="#2025-10-10-æ›´æ–°" class="headerlink" title="2025-10-10 æ›´æ–°"></a>2025-10-10 æ›´æ–°</h1><h2 id="StyleKeeper-Prevent-Content-Leakage-using-Negative-Visual-Query-Guidance"><a href="#StyleKeeper-Prevent-Content-Leakage-using-Negative-Visual-Query-Guidance" class="headerlink" title="StyleKeeper: Prevent Content Leakage using Negative Visual Query   Guidance"></a>StyleKeeper: Prevent Content Leakage using Negative Visual Query   Guidance</h2><p><strong>Authors:Jaeseok Jeong, Junho Kim, Gayoung Lee, Yunjey Choi, Youngjung Uh</strong></p>
<p>In the domain of text-to-image generation, diffusion models have emerged as powerful tools. Recently, studies on visual prompting, where images are used as prompts, have enabled more precise control over style and content. However, existing methods often suffer from content leakage, where undesired elements of the visual style prompt are transferred along with the intended style. To address this issue, we 1) extend classifier-free guidance (CFG) to utilize swapping self-attention and propose 2) negative visual query guidance (NVQG) to reduce the transfer of unwanted contents. NVQG employs negative score by intentionally simulating content leakage scenarios that swap queries instead of key and values of self-attention layers from visual style prompts. This simple yet effective method significantly reduces content leakage. Furthermore, we provide careful solutions for using a real image as visual style prompts. Through extensive evaluation across various styles and text prompts, our method demonstrates superiority over existing approaches, reflecting the style of the references, and ensuring that resulting images match the text prompts. Our code is available \href{<a target="_blank" rel="noopener" href="https://github.com/naver-ai/StyleKeeper%7D%7Bhere%7D">https://github.com/naver-ai/StyleKeeper}{here}</a>. </p>
<blockquote>
<p>åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸï¼Œæ‰©æ•£æ¨¡å‹å·²å´­éœ²å¤´è§’æˆä¸ºå¼ºå¤§çš„å·¥å…·ã€‚æœ€è¿‘ï¼Œå…³äºè§†è§‰æç¤ºçš„ç ”ç©¶ï¼Œå³ä½¿ç”¨å›¾åƒä½œä¸ºæç¤ºï¼Œå·²ç»å®ç°å¯¹é£æ ¼å’Œå†…å®¹çš„æ›´ç²¾ç¡®æ§åˆ¶ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸å­˜åœ¨å†…å®¹æ³„éœ²çš„é—®é¢˜ï¼Œå³è§†è§‰é£æ ¼æç¤ºä¸­çš„ä¸éœ€è¦çš„å…ƒç´ ä¸é¢„æœŸé£æ ¼ä¸€èµ·è½¬ç§»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬1ï¼‰æ‰©å±•æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰ï¼Œåˆ©ç”¨äº¤æ¢è‡ªæ³¨æ„åŠ›ï¼Œå¹¶æå‡º2ï¼‰è´Ÿè§†è§‰æŸ¥è¯¢å¼•å¯¼ï¼ˆNVQGï¼‰ä»¥å‡å°‘ä¸æƒ³è¦å†…å®¹çš„è½¬ç§»ã€‚NVQGé€šè¿‡æœ‰æ„æ¨¡æ‹Ÿå†…å®¹æ³„éœ²æƒ…æ™¯è€Œé‡‡ç”¨è´Ÿåˆ†ï¼Œåœ¨è¿™ç§æƒ…æ™¯ä¸­ï¼Œäº¤æ¢æŸ¥è¯¢è€Œä¸æ˜¯è‡ªæ³¨æ„åŠ›å±‚çš„é”®å’Œå€¼æ¥è‡ªè§†è§‰é£æ ¼æç¤ºã€‚è¿™ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ˜¾è‘—å‡å°‘äº†å†…å®¹æ³„éœ²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä¸ºä½¿ç”¨çœŸå®å›¾åƒä½œä¸ºè§†è§‰é£æ ¼æç¤ºæä¾›äº†ç²¾å¿ƒè§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºçš„å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¯æ˜ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½åæ˜ å‚è€ƒçš„é£æ ¼ï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒç¬¦åˆæ–‡æœ¬æç¤ºã€‚æˆ‘ä»¬çš„ä»£ç &lt;è¿™é‡Œã€‚å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/naver-ai/StyleKeeper">https://github.com/naver-ai/StyleKeeper</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06827v1">PDF</a> Accepted to ICCV 2025; CVPRW AI4CC 2024 (Best Paper + Oral)</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ç”Ÿæˆé¢†åŸŸä¸­çš„æ‰©æ•£æ¨¡å‹å·²æˆä¸ºå¼ºå¤§çš„å·¥å…·ã€‚æœ€è¿‘ï¼Œå…³äºè§†è§‰æç¤ºçš„ç ”ç©¶ä½¿å¾—å›¾åƒä½œä¸ºæç¤ºæ›´ä¸ºç²¾å‡†åœ°æ§åˆ¶é£æ ¼å’Œå†…å®¹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸å­˜åœ¨å†…å®¹æ³„éœ²é—®é¢˜ï¼Œå³è§†è§‰é£æ ¼æç¤ºä¸­çš„ä¸æœŸæœ›å…ƒç´ ä¼šä¸€å¹¶è½¬ç§»ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ‰©å±•äº†æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰ï¼Œé‡‡ç”¨äº¤æ¢è‡ªæ³¨æ„åŠ›ï¼Œå¹¶æå‡ºè´Ÿè§†è§‰æŸ¥è¯¢å¼•å¯¼ï¼ˆNVQGï¼‰æ¥å‡å°‘ä¸æƒ³è¦å†…å®¹çš„è½¬ç§»ã€‚NVQGé€šè¿‡æ•…æ„æ¨¡æ‹Ÿå†…å®¹æ³„éœ²æƒ…æ™¯ï¼Œé‡‡ç”¨è´Ÿåˆ†æ•°ï¼Œäº¤æ¢è‡ªæ³¨æ„åŠ›å±‚çš„æŸ¥è¯¢è€Œä¸æ˜¯é”®å’Œå€¼ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘å†…å®¹æ³„éœ²ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ä¸ºä½¿ç”¨çœŸå®å›¾åƒä½œä¸ºè§†è§‰é£æ ¼æç¤ºæä¾›äº†ç²¾ç»†è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡è·¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºçš„å¹¿æ³›è¯„ä¼°ï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºå¯¹ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿåæ˜ å‚è€ƒçš„é£æ ¼å¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¸æ–‡æœ¬æç¤ºç›¸åŒ¹é…ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆé¢†åŸŸè¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚</li>
<li>è§†è§‰æç¤ºç ”ç©¶æé«˜äº†å¯¹å›¾åƒé£æ ¼å’Œå†…å®¹çš„ç²¾å‡†æ§åˆ¶ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨å†…å®¹æ³„éœ²é—®é¢˜ï¼Œå³ä¸æœŸæœ›çš„å…ƒç´ ä¼šè¢«è½¬ç§»ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ‰©å±•æ— åˆ†ç±»å™¨å¼•å¯¼å¹¶å¼•å…¥è´Ÿè§†è§‰æŸ¥è¯¢å¼•å¯¼æ¥è§£å†³å†…å®¹æ³„éœ²é—®é¢˜ã€‚</li>
<li>è´Ÿè§†è§‰æŸ¥è¯¢å¼•å¯¼é€šè¿‡æ¨¡æ‹Ÿå†…å®¹æ³„éœ²æƒ…æ™¯å¹¶é‡‡ç”¨è´Ÿåˆ†æ•°æ¥å‡å°‘ä¸å¿…è¦å†…å®¹çš„è½¬ç§»ã€‚</li>
<li>è¯¥æ–¹æ³•æä¾›ä½¿ç”¨çœŸå®å›¾åƒä½œä¸ºè§†è§‰é£æ ¼æç¤ºçš„ç²¾ç»†è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç»è¿‡å¹¿æ³›è¯„ä¼°ï¼Œè¯¥æ–¹æ³•åœ¨è·¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºçš„æƒ…å†µä¸‹è¡¨ç°å‡ºä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06827">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-054cc441a2095df47722186071620655~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047490&auth_key=1760047490-0-0-356f70ce629bd60db52b582bc82877f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-08ec1441f9a35fab27543023485d3ec9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047498&auth_key=1760047498-0-0-7550161b15b472b69c63534c684dd4d4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d77befce2fd69be0bb3ebf28fdd3d672~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047505&auth_key=1760047505-0-0-f8c972fc11e2cd94a794e0555a7fe842&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-df8eaf9c3d081451dc840ab95dbb2310~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047512&auth_key=1760047512-0-0-a6d8e5470409cd55cb15cb31a48494b9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-947578257cc4e760557c23e8af49083d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047518&auth_key=1760047518-0-0-e8dc2889c009c3de85969f041db53aa2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="OBS-Diff-Accurate-Pruning-For-Diffusion-Models-in-One-Shot"><a href="#OBS-Diff-Accurate-Pruning-For-Diffusion-Models-in-One-Shot" class="headerlink" title="OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot"></a>OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot</h2><p><strong>Authors:Junhan Zhu, Hesong Wang, Mingluo Su, Zefang Wang, Huan Wang</strong></p>
<p>Large-scale text-to-image diffusion models, while powerful, suffer from prohibitive computational cost. Existing one-shot network pruning methods can hardly be directly applied to them due to the iterative denoising nature of diffusion models. To bridge the gap, this paper presents OBS-Diff, a novel one-shot pruning framework that enables accurate and training-free compression of large-scale text-to-image diffusion models. Specifically, (i) OBS-Diff revitalizes the classic Optimal Brain Surgeon (OBS), adapting it to the complex architectures of modern diffusion models and supporting diverse pruning granularity, including unstructured, N:M semi-structured, and structured (MHA heads and FFN neurons) sparsity; (ii) To align the pruning criteria with the iterative dynamics of the diffusion process, by examining the problem from an error-accumulation perspective, we propose a novel timestep-aware Hessian construction that incorporates a logarithmic-decrease weighting scheme, assigning greater importance to earlier timesteps to mitigate potential error accumulation; (iii) Furthermore, a computationally efficient group-wise sequential pruning strategy is proposed to amortize the expensive calibration process. Extensive experiments show that OBS-Diff achieves state-of-the-art one-shot pruning for diffusion models, delivering inference acceleration with minimal degradation in visual quality. </p>
<blockquote>
<p>å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹è™½ç„¶åŠŸèƒ½å¼ºå¤§ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚ç°æœ‰çš„å•æ¬¡ç½‘ç»œå‰ªææ–¹æ³•ç”±äºæ‰©æ•£æ¨¡å‹çš„è¿­ä»£å»å™ªæ€§è´¨ï¼Œå‡ ä¹æ— æ³•ç›´æ¥åº”ç”¨äºå…¶ä¸­ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†OBS-Diffï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ä¸€æ¬¡æ€§å‰ªææ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç²¾ç¡®ã€æ— éœ€è®­ç»ƒå‹ç¼©ã€‚å…·ä½“æ¥è¯´ï¼Œï¼ˆiï¼‰OBS-Diffé‡æ–°ç„•å‘äº†ç»å…¸çš„æœ€ä¼˜è„‘å¤–ç§‘åŒ»ç”Ÿï¼ˆOBSï¼‰çš„æ´»åŠ›ï¼Œä½¿å…¶é€‚åº”ç°ä»£æ‰©æ•£æ¨¡å‹çš„å¤æ‚æ¶æ„ï¼Œå¹¶æ”¯æŒå¤šç§å‰ªæç²’åº¦ï¼ŒåŒ…æ‹¬éç»“æ„åŒ–ã€Nï¼šMåŠç»“æ„åŒ–å’Œç»“æ„åŒ–ï¼ˆMHAå¤´å’ŒFFNç¥ç»å…ƒï¼‰ç¨€ç–æ€§ï¼›ï¼ˆiiï¼‰ä¸ºäº†å°†å‰ªææ ‡å‡†ä¸æ‰©æ•£è¿‡ç¨‹çš„è¿­ä»£åŠ¨æ€ç›¸ä¸€è‡´ï¼Œæˆ‘ä»¬ä»è¯¯å·®ç´¯ç§¯çš„è§’åº¦å®¡è§†é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ—¶é—´æ­¥æ„ŸçŸ¥æµ·æ£®æ„é€ ï¼Œç»“åˆäº†å¯¹æ•°å‡å°‘åŠ æƒæ–¹æ¡ˆï¼Œä¸ºæ—©æœŸçš„æ—¶é—´æ­¥èµ‹äºˆæ›´å¤§çš„é‡è¦æ€§ï¼Œä»¥å‡è½»æ½œåœ¨çš„è¯¯å·®ç´¯ç§¯ï¼›ï¼ˆiiiï¼‰æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§è®¡ç®—æ•ˆç‡é«˜çš„åˆ†ç»„é¡ºåºå‰ªæç­–ç•¥ï¼Œä»¥æ‘Šé”€æ˜‚è´µçš„æ ¡å‡†è¿‡ç¨‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒOBS-Diffåœ¨æ‰©æ•£æ¨¡å‹çš„ä¸€ç«™å¼å‰ªææ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œå®ç°äº†æ¨ç†åŠ é€Ÿï¼Œè§†è§‰è´¨é‡å‡ ä¹æ²¡æœ‰ä¸‹é™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06751v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºOBS-Diffçš„æ–°å‹ä¸€æ¬¡æ€§ä¿®å‰ªæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¯¹å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå‡†ç¡®ä¸”æ— éœ€è®­ç»ƒå³å¯è¿›è¡Œå‹ç¼©ã€‚å®ƒæ”¯æŒå¤šç§ä¿®å‰ªç²’åº¦ï¼Œå¹¶åŸºäºè¯¯å·®ç´¯ç§¯è§†è§’æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„æ—¶é—´æ­¥æ„ŸçŸ¥çš„æµ·æ£®çŸ©é˜µæ„å»ºæ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œä¸ºäº†é™ä½æ ¡å‡†è¿‡ç¨‹çš„æˆæœ¬ï¼Œè¿˜æå‡ºäº†ä¸€ç§è®¡ç®—æ•ˆç‡é«˜çš„åˆ†ç»„é¡ºåºä¿®å‰ªç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼ŒOBS-Diffåœ¨æ‰©æ•£æ¨¡å‹çš„ä¸€ç«™å¼ä¿®å‰ªæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œå®ç°äº†æ¨ç†åŠ é€Ÿï¼Œå¹¶ä¸”åœ¨è§†è§‰è´¨é‡ä¸Šå‡ ä¹æ²¡æœ‰æŸå¤±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OBS-Diffæ¡†æ¶è§£å†³äº†å¤§å‹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ï¼Œé€šè¿‡æ— éœ€è®­ç»ƒçš„å‹ç¼©æ–¹å¼å®ç°äº†ä¸€ç«™å¼ä¿®å‰ªã€‚</li>
<li>OBS-Diffé€‚åº”äº†ç°ä»£æ‰©æ•£æ¨¡å‹çš„å¤æ‚æ¶æ„ï¼Œå¹¶æ”¯æŒå¤šç§ä¿®å‰ªç²’åº¦ï¼ŒåŒ…æ‹¬éç»“æ„åŒ–ã€N:MåŠç»“æ„åŒ–å’Œç»“æ„åŒ–ï¼ˆMHAå¤´å’ŒFFNç¥ç»å…ƒï¼‰ç¨€ç–æ€§ã€‚</li>
<li>åŸºäºè¯¯å·®ç´¯ç§¯è§†è§’ï¼Œæå‡ºäº†æ–°çš„æ—¶é—´æ­¥æ„ŸçŸ¥çš„æµ·æ£®çŸ©é˜µæ„å»ºæ–¹æ¡ˆï¼Œä¸ºä¿®å‰ªæ ‡å‡†ä¸æ‰©æ•£è¿‡ç¨‹çš„è¿­ä»£åŠ¨æ€æä¾›äº†å¯¹é½ã€‚</li>
<li>é€šè¿‡ä¸ºæ—©æœŸæ—¶é—´æ­¥èµ‹äºˆæ›´å¤§é‡è¦æ€§æ¥å‡è½»æ½œåœ¨è¯¯å·®ç§¯ç´¯çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è®¡ç®—é«˜æ•ˆçš„åˆ†ç»„é¡ºåºä¿®å‰ªç­–ç•¥ï¼Œä»¥å¹³è¡¡æ˜‚è´µçš„æ ¡å‡†è¿‡ç¨‹ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜äº†OBS-Diffåœ¨æ‰©æ•£æ¨¡å‹çš„ä¸€ç«™å¼ä¿®å‰ªæ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œå®ç°äº†æ¨ç†åŠ é€Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06751">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f4b6410d7198ef5e7b95cf091f51e044~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047526&auth_key=1760047526-0-0-996a43e8084b87bbbdb83f1573e022a2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7bd51d69c4e5562db0bbc68a1b8e4d4f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047533&auth_key=1760047533-0-0-a14f1364628c35f082eadbed3e2fbb5d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-Diffusion-Model-for-Regular-Time-Series-Generation-from-Irregular-Data-with-Completion-and-Masking"><a href="#A-Diffusion-Model-for-Regular-Time-Series-Generation-from-Irregular-Data-with-Completion-and-Masking" class="headerlink" title="A Diffusion Model for Regular Time Series Generation from Irregular Data   with Completion and Masking"></a>A Diffusion Model for Regular Time Series Generation from Irregular Data   with Completion and Masking</h2><p><strong>Authors:Gal Fadlon, Idan Arbiv, Nimrod Berman, Omri Azencot</strong></p>
<p>Generating realistic time series data is critical for applications in healthcare, finance, and science. However, irregular sampling and missing values present significant challenges. While prior methods address these irregularities, they often yield suboptimal results and incur high computational costs. Recent advances in regular time series generation, such as the diffusion-based ImagenTime model, demonstrate strong, fast, and scalable generative capabilities by transforming time series into image representations, making them a promising solution. However, extending ImagenTime to irregular sequences using simple masking introduces â€œunnaturalâ€ neighborhoods, where missing values replaced by zeros disrupt the learning process. To overcome this, we propose a novel two-step framework: first, a Time Series Transformer completes irregular sequences, creating natural neighborhoods; second, a vision-based diffusion model with masking minimizes dependence on the completed values. This approach leverages the strengths of both completion and masking, enabling robust and efficient generation of realistic time series. Our method achieves state-of-the-art performance, achieving a relative improvement in discriminative score by $70%$ and in computational cost by $85%$. Code is at <a target="_blank" rel="noopener" href="https://github.com/azencot-group/ImagenI2R">https://github.com/azencot-group/ImagenI2R</a>. </p>
<blockquote>
<p>ç”ŸæˆçœŸå®çš„æ—¶é—´åºåˆ—æ•°æ®å¯¹äºåŒ»ç–—ä¿å¥ã€é‡‘èå’Œç§‘å­¦ç­‰é¢†åŸŸçš„åº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¸è§„åˆ™é‡‡æ ·å’Œç¼ºå¤±å€¼å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡å…ˆå‰çš„æ–¹æ³•è§£å†³äº†è¿™äº›ä¸è§„åˆ™æ€§ï¼Œä½†å®ƒä»¬é€šå¸¸äº§ç”Ÿæ¬¡ä¼˜ç»“æœå¹¶äº§ç”Ÿé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚æœ€è¿‘ï¼ŒåŸºäºæ‰©æ•£çš„ImagenTimeæ¨¡å‹ç­‰å¸¸è§„æ—¶é—´åºåˆ—ç”Ÿæˆæ–¹é¢çš„è¿›å±•ï¼Œé€šè¿‡å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºå›¾åƒè¡¨ç¤ºï¼Œå±•ç¤ºäº†å¼ºå¤§ã€å¿«é€Ÿå’Œå¯æ‰©å±•çš„ç”Ÿæˆèƒ½åŠ›ï¼Œæˆä¸ºäº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå°†ImagenTimeæ‰©å±•åˆ°ä¸è§„åˆ™åºåˆ—æ—¶ï¼Œä½¿ç”¨ç®€å•æ©ç ä¼šå¼•å…¥â€œä¸è‡ªç„¶â€çš„é‚»å±…ï¼Œå…¶ä¸­ç¼ºå¤±å€¼è¢«é›¶æ›¿æ¢ä¼šç ´åå­¦ä¹ è¿‡ç¨‹ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤æ­¥æ¡†æ¶ï¼šé¦–å…ˆï¼Œæ—¶é—´åºåˆ—å˜å‹å™¨å®Œæˆä¸è§„åˆ™åºåˆ—ï¼Œåˆ›å»ºè‡ªç„¶é‚»å±…ï¼›å…¶æ¬¡ï¼Œå¸¦æœ‰æ©ç çš„åŸºäºè§†è§‰çš„æ‰©æ•£æ¨¡å‹æœ€å°åŒ–å¯¹å®Œæˆå€¼çš„ä¾èµ–ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†è¡¥å…¨å’Œæ©ç çš„ä¼˜ç‚¹ï¼Œèƒ½å¤Ÿå®ç°ç¨³å¥å’Œé«˜æ•ˆçš„çœŸå®æ—¶é—´åºåˆ—ç”Ÿæˆã€‚æˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåˆ¤åˆ«å¾—åˆ†ç›¸å¯¹æé«˜äº†70%ï¼Œè®¡ç®—æˆæœ¬é™ä½äº†8 ç»“ã€‚ä»£ç åœ°å€æ˜¯ï¼š<a target="_blank" rel="noopener" href="https://github.com/azencot-group/ImagenI2R%E3%80%82">https://github.com/azencot-group/ImagenI2Rã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06699v1">PDF</a> Accepted to NeurIPS 2025; The first two authors contributed equally   and are co-leading authors</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ç”ŸæˆæŠ€æœ¯åœ¨æ—¶é—´åºåˆ—æ•°æ®çš„å®é™…åº”ç”¨ä¸­ï¼Œé¢ä¸´ç€ä¸è§„åˆ™é‡‡æ ·å’Œç¼ºå¤±å€¼ç­‰æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„å¤„ç†æ–¹æ³•å¾€å¾€æ•ˆæœä¸å°½å¦‚äººæ„ä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚è¿‘æœŸæå‡ºçš„ImagenTimeæ¨¡å‹é€šè¿‡å°†æ—¶é—´åºåˆ—è½¬åŒ–ä¸ºå›¾åƒè¡¨ç¤ºï¼Œå±•ç°äº†å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¯¹äºä¸è§„åˆ™åºåˆ—çš„æ‰©å±•åº”ç”¨ï¼Œç®€å•æ©ç ä¼šå¯¼è‡´â€œä¸è‡ªç„¶â€çš„é‚»åŸŸå‡ºç°ï¼Œå½±å“å­¦ä¹ è¿›ç¨‹ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºä¸€ç§æ–°å‹ä¸¤æ­¥æ¡†æ¶ï¼šé¦–å…ˆä½¿ç”¨æ—¶é—´åºåˆ—è½¬æ¢å™¨å®Œæˆä¸è§„åˆ™åºåˆ—ï¼Œåˆ›å»ºè‡ªç„¶é‚»åŸŸï¼›å…¶æ¬¡é‡‡ç”¨å¸¦æœ‰æ©ç çš„è§†è§‰åŸºç¡€æ‰©æ•£æ¨¡å‹ï¼Œå‡å°‘å¯¹å®Œæˆå€¼çš„ä¾èµ–ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å®Œæˆå’Œæ©ç çš„ä¼˜åŠ¿ï¼Œå®ç°äº†ç¨³å¥ä¸”é«˜æ•ˆçš„æ—¶é—´åºåˆ—ç”Ÿæˆã€‚æ­¤æ–¹æ³•è¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ï¼Œåˆ¤åˆ«å¾—åˆ†ç›¸å¯¹æå‡70%ï¼Œè®¡ç®—æˆæœ¬é™ä½85%ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”ŸæˆçœŸå®çš„æ—¶é—´åºåˆ—æ•°æ®åœ¨åŒ»ç–—ä¿å¥ã€é‡‘èå’Œç§‘å­¦ç­‰é¢†åŸŸå…·æœ‰é‡è¦æ€§ã€‚</li>
<li>ä¸è§„åˆ™é‡‡æ ·å’Œç¼ºå¤±å€¼æ˜¯æ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•è™½èƒ½è§£å†³è¿™äº›ä¸è§„åˆ™æ€§ï¼Œä½†æ•ˆæœæ¬ ä½³ä¸”è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚</li>
<li>ImagenTimeæ¨¡å‹é€šè¿‡å°†æ—¶é—´åºåˆ—è½¬åŒ–ä¸ºå›¾åƒè¡¨ç¤ºå±•ç°äº†å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>å¯¹äºä¸è§„åˆ™åºåˆ—çš„æ‰©å±•ï¼Œç®€å•æ©ç ä¼šå¯¼è‡´å­¦ä¹ è¿‡ç¨‹ä¸­çš„â€œä¸è‡ªç„¶â€é‚»åŸŸé—®é¢˜ã€‚</li>
<li>æå‡ºçš„æ–°å‹ä¸¤æ­¥æ¡†æ¶ç»“åˆäº†å®Œæˆå’Œæ©ç çš„ä¼˜åŠ¿ï¼Œå®ç°äº†ç¨³å¥ä¸”é«˜æ•ˆçš„æ—¶é—´åºåˆ—ç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06699">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-26d60953d49df444bac92360a6cc7c1d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047540&auth_key=1760047540-0-0-e0932e75eaba52022d06b5d5901eb7da&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4d7a9e98cd3085ef6ee3e696f57ac0bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047547&auth_key=1760047547-0-0-d255a4db5fdca18ba2ffd85a34b6ceed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d70272aab7b783138d6dd0107bd3ebbb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047554&auth_key=1760047554-0-0-ca7bcd7a537526b0fc7f532dfddb2065&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8bcd6556236a8834ce5affbe515e0e0c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047560&auth_key=1760047560-0-0-e61edde17f70ab932a6e389bf95e2e40&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5c1dac7ca7b84dc25e84f11de04be385~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047566&auth_key=1760047566-0-0-7b2f1a428a78e17daf3a2cf76315d024&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d91cc2a9897ae00b17dd43e8ce694fcf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047573&auth_key=1760047573-0-0-fd3b5d735fc500705847b50198724f6f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Conditional-Denoising-Diffusion-Model-Based-Robust-MR-Image-Reconstruction-from-Highly-Undersampled-Data"><a href="#Conditional-Denoising-Diffusion-Model-Based-Robust-MR-Image-Reconstruction-from-Highly-Undersampled-Data" class="headerlink" title="Conditional Denoising Diffusion Model-Based Robust MR Image   Reconstruction from Highly Undersampled Data"></a>Conditional Denoising Diffusion Model-Based Robust MR Image   Reconstruction from Highly Undersampled Data</h2><p><strong>Authors:Mohammed Alsubaie, Wenxi Liu, Linxia Gu, Ovidiu C. Andronesi, Sirani M. Perera, Xianqi Li</strong></p>
<p>Magnetic Resonance Imaging (MRI) is a critical tool in modern medical diagnostics, yet its prolonged acquisition time remains a critical limitation, especially in time-sensitive clinical scenarios. While undersampling strategies can accelerate image acquisition, they often result in image artifacts and degraded quality. Recent diffusion models have shown promise for reconstructing high-fidelity images from undersampled data by learning powerful image priors; however, most existing approaches either (i) rely on unsupervised score functions without paired supervision or (ii) apply data consistency only as a post-processing step. In this work, we introduce a conditional denoising diffusion framework with iterative data-consistency correction, which differs from prior methods by embedding the measurement model directly into every reverse diffusion step and training the model on paired undersampled-ground truth data. This hybrid design bridges generative flexibility with explicit enforcement of MRI physics. Experiments on the fastMRI dataset demonstrate that our framework consistently outperforms recent state-of-the-art deep learning and diffusion-based methods in SSIM, PSNR, and LPIPS, with LPIPS capturing perceptual improvements more faithfully. These results demonstrate that integrating conditional supervision with iterative consistency updates yields substantial improvements in both pixel-level fidelity and perceptual realism, establishing a principled and practical advance toward robust, accelerated MRI reconstruction. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ç°ä»£åŒ»å­¦è¯Šæ–­ä¸­çš„é‡è¦å·¥å…·ï¼Œä½†å…¶æ¼«é•¿çš„é‡‡é›†æ—¶é—´ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®çš„é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—¶é—´æ•æ„Ÿçš„ä¸´åºŠåœºæ™¯ä¸­ã€‚å°½ç®¡æ¬ é‡‡æ ·ç­–ç•¥å¯ä»¥åŠ é€Ÿå›¾åƒé‡‡é›†ï¼Œä½†å®ƒä»¬é€šå¸¸ä¼šå¯¼è‡´å›¾åƒå‡ºç°ä¼ªå½±å’Œè´¨é‡ä¸‹é™ã€‚æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹æ˜¾ç¤ºå‡ºé€šè¿‡å­¦ä¹ å¼ºå¤§çš„å›¾åƒå…ˆéªŒçŸ¥è¯†ä»æ¬ é‡‡æ ·æ•°æ®ä¸­é‡å»ºé«˜ä¿çœŸå›¾åƒçš„æ½œåŠ›ï¼›ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•è¦ä¹ˆï¼ˆiï¼‰ä¾èµ–æ— é…å¯¹ç›‘ç£çš„æ— ç›‘ç£åˆ†æ•°å‡½æ•°ï¼Œè¦ä¹ˆï¼ˆiiï¼‰ä»…å°†æ•°æ®ä¸€è‡´æ€§ä½œä¸ºåå¤„ç†æ­¥éª¤åº”ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå…·æœ‰è¿­ä»£æ•°æ®ä¸€è‡´æ€§æ ¡æ­£çš„æ¡ä»¶å»å™ªæ‰©æ•£æ¡†æ¶ï¼Œå®ƒä¸å…ˆå‰çš„æ–¹æ³•çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œå®ƒå°†æµ‹é‡æ¨¡å‹ç›´æ¥åµŒå…¥åˆ°æ¯ä¸ªåå‘æ‰©æ•£æ­¥éª¤ä¸­ï¼Œå¹¶åœ¨é…å¯¹æ¬ é‡‡æ ·-çœŸå®æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ã€‚è¿™ç§æ··åˆè®¾è®¡ç»“åˆäº†ç”Ÿæˆçµæ´»æ€§å’ŒMRIç‰©ç†çš„æ˜¾å¼å®æ–½ã€‚åœ¨fastMRIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰ã€å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œå±€éƒ¨æ„ŸçŸ¥å›¾åƒæ„ŸçŸ¥ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰ä¸Šå§‹ç»ˆä¼˜äºæœ€æ–°çš„æ·±åº¦å­¦ä¹ å’Œæ‰©æ•£æ–¹æ³•ï¼ŒLPIPSæ›´çœŸå®åœ°æ•æ‰åˆ°äº†æ„ŸçŸ¥æ”¹è¿›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå°†æ¡ä»¶ç›‘ç£ä¸è¿­ä»£ä¸€è‡´æ€§æ›´æ–°ç›¸ç»“åˆï¼Œåœ¨åƒç´ çº§ä¿çœŸåº¦å’Œæ„ŸçŸ¥çœŸå®æ€§æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œä¸ºå®ç°ç¨³å¥ã€åŠ é€Ÿçš„MRIé‡å»ºæä¾›äº†æœ‰åŸåˆ™å’Œå®é™…è¿›æ­¥çš„çªç ´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06335v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨æ‰©æ•£æ¨¡å‹åŠ é€Ÿç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„æŠ€æœ¯ã€‚ä¼ ç»Ÿçš„MRIé‡‡é›†æ—¶é—´è¾ƒé•¿ï¼Œè€Œæ‰©æ•£æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿è¯å›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œé€šè¿‡å­¦ä¹ æ–¹æ³•åŠ é€Ÿå›¾åƒé‡‡é›†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ¡ä»¶å»å™ªæ‰©æ•£æ¡†æ¶å’Œè¿­ä»£æ•°æ®ä¸€è‡´æ€§æ ¡æ­£çš„æ–°æ–¹æ³•ï¼Œå°†æµ‹é‡æ¨¡å‹ç›´æ¥åµŒå…¥åˆ°æ¯ä¸ªåå‘æ‰©æ•£æ­¥éª¤ä¸­ï¼Œå¹¶åœ¨é…å¯¹æ¬ é‡‡æ ·-çœŸå®æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨SSIMã€PSNRå’ŒLPIPSç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºæœ€æ–°çš„æ·±åº¦å­¦ä¹ å’Œæ‰©æ•£æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ„ŸçŸ¥æ”¹å–„æ–¹é¢è¡¨ç°æ›´å‡ºè‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨MRIå›¾åƒé‡å»ºä¸­æœ‰å·¨å¤§æ½œåŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¿è¯å›¾åƒè´¨é‡çš„åŒæ—¶åŠ é€Ÿé‡‡é›†ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ— ç›‘ç£å¾—åˆ†å‡½æ•°æˆ–ä»…å°†æ•°æ®ä¸€è‡´æ€§ä½œä¸ºåå¤„ç†æ­¥éª¤ï¼Œè€Œæ–°æ–¹æ³•åˆ™å°†æµ‹é‡æ¨¡å‹åµŒå…¥æ¯ä¸ªåå‘æ‰©æ•£æ­¥éª¤ä¸­ã€‚</li>
<li>æ–°æ–¹æ³•ç»“åˆäº†æ¡ä»¶ç›‘ç£ä¸è¿­ä»£ä¸€è‡´æ€§æ›´æ–°ï¼Œæ˜¾è‘—æé«˜äº†åƒç´ çº§ä¿çœŸåº¦å’Œæ„ŸçŸ¥ç°å®æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨SSIMã€PSNRå’ŒLPIPSç­‰æŒ‡æ ‡ä¸Šçš„è¡¨ç°å‡ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ„ŸçŸ¥è´¨é‡æ–¹é¢ã€‚</li>
<li>é›†æˆæ‰©æ•£æ¨¡å‹ä¸MRIæŠ€æœ¯ä¸ºåŠ é€ŸMRIé‡å»ºæä¾›äº†ç†è®ºä¸Šçš„è¿›æ­¥ã€‚</li>
<li>æ–°æ–¹æ³•å°†ç”Ÿæˆçµæ´»æ€§ä¸MRIç‰©ç†çš„æ˜¾å¼å®æ–½ç›¸ç»“åˆï¼Œå®ç°äº†æ›´å¥½çš„å›¾åƒé‡å»ºæ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06335">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ed8b3160742ce192f18a08457140bd45~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047581&auth_key=1760047581-0-0-7327e9124e61a5024bc61205794ceba5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4a3182fbbb9dc6009f8d71fba37c7e63~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047588&auth_key=1760047588-0-0-b7a4a7f8abb1efd95491d0552913a7b9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f790d41f7e1893c270c91d01918e509a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047595&auth_key=1760047595-0-0-c1b7879fe4c5adfa39f14095c71bb7af&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4c3db9fbaa3d5f95b052d749358bf897~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047602&auth_key=1760047602-0-0-96b2a6d6630eb6e20d90c5b3bd4bdb3a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7790fa011158758e7e700c74906aa7db~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047608&auth_key=1760047608-0-0-b865850d23cfdea1d0fff092ace38738&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4b18c9aed058fc63e92c26f872bc905e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047615&auth_key=1760047615-0-0-fb494b1f13fe8e0ccad10f521c1603e3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Lumina-DiMOO-An-Omni-Diffusion-Large-Language-Model-for-Multi-Modal-Generation-and-Understanding"><a href="#Lumina-DiMOO-An-Omni-Diffusion-Large-Language-Model-for-Multi-Modal-Generation-and-Understanding" class="headerlink" title="Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal   Generation and Understanding"></a>Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal   Generation and Understanding</h2><p><strong>Authors:Yi Xin, Qi Qin, Siqi Luo, Kaiwen Zhu, Juncheng Yan, Yan Tai, Jiayi Lei, Yuewen Cao, Keqi Wang, Yibin Wang, Jinbin Bai, Qian Yu, Dengyang Jiang, Yuandong Pu, Haoxing Chen, Le Zhuo, Junjun He, Gen Luo, Tianbin Li, Ming Hu, Jin Ye, Shenglong Ye, Bo Zhang, Chang Xu, Wenhai Wang, Hongsheng Li, Guangtao Zhai, Tianfan Xue, Bin Fu, Xiaohong Liu, Yu Qiao, Yihao Liu</strong></p>
<p>We introduce Lumina-DiMOO, an open-source foundational model for seamless multi-modal generation and understanding. Lumina-DiMOO sets itself apart from prior unified models by utilizing a fully discrete diffusion modeling to handle inputs and outputs across various modalities. This innovative approach allows Lumina-DiMOO to achieve higher sampling efficiency compared to previous autoregressive (AR) or hybrid AR-Diffusion paradigms and adeptly support a broad spectrum of multi-modal tasks, including text-to-image generation, image-to-image generation (e.g., image editing, subject-driven generation, and image inpainting, etc.), as well as image understanding. Lumina-DiMOO achieves state-of-the-art performance on multiple benchmarks, surpassing existing open-source unified multi-modal models. To foster further advancements in multi-modal and discrete diffusion model research, we release our code and checkpoints to the community. Project Page: <a target="_blank" rel="noopener" href="https://synbol.github.io/Lumina-DiMOO">https://synbol.github.io/Lumina-DiMOO</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»Lumina-DiMOOï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾æºç çš„åŸºç¡€æ¨¡å‹ï¼Œç”¨äºæ— ç¼å¤šæ¨¡å¼ç”Ÿæˆå’Œç†è§£ã€‚Lumina-DiMOOé€šè¿‡é‡‡ç”¨å®Œå…¨ç¦»æ•£çš„æ‰©æ•£æ¨¡å‹æ¥å¤„ç†å„ç§æ¨¡æ€çš„è¾“å…¥å’Œè¾“å‡ºï¼Œä»è€Œä¸ä¹‹å‰çš„ç»Ÿä¸€æ¨¡å‹ç›¸åŒºåˆ«ã€‚è¿™ç§åˆ›æ–°çš„æ–¹æ³•ä½¿å¾—Lumina-DiMOOç›¸æ¯”ä¹‹å‰çš„è‡ªå›å½’ï¼ˆARï¼‰æˆ–æ··åˆAR-DiffusionèŒƒå¼å®ç°æ›´é«˜çš„é‡‡æ ·æ•ˆç‡ï¼Œå¹¶èƒ½ç†Ÿç»ƒåœ°æ”¯æŒå¹¿æ³›çš„å¤šæ¨¡å¼ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒåˆ°å›¾åƒç”Ÿæˆï¼ˆä¾‹å¦‚å›¾åƒç¼–è¾‘ã€ä¸»é¢˜é©±åŠ¨ç”Ÿæˆå’Œå›¾åƒä¿®å¤ç­‰ï¼‰ï¼Œä»¥åŠå›¾åƒç†è§£ã€‚Lumina-DiMOOåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼€æºç»Ÿä¸€å¤šæ¨¡å¼æ¨¡å‹ã€‚ä¸ºäº†ä¿ƒè¿›å¤šæ¨¡å¼å’Œç¦»æ•£æ‰©æ•£æ¨¡å‹çš„è¿›ä¸€æ­¥ç ”ç©¶ï¼Œæˆ‘ä»¬å‘ç¤¾åŒºå‘å¸ƒæˆ‘ä»¬çš„ä»£ç å’Œæ£€æŸ¥ç‚¹ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://synbol.github.io/Lumina-DiMOO%E3%80%82">https://synbol.github.io/Lumina-DiMOOã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06308v1">PDF</a> 33 pages, 13 figures, 10 tables</p>
<p><strong>Summary</strong></p>
<p>Lumina-DiMOOæ˜¯ä¸€æ¬¾å¼€æºçš„è·¨æ¨¡æ€ç”Ÿæˆä¸ç†è§£åŸºç¡€æ¨¡å‹ï¼Œé‡‡ç”¨å…¨ç¦»æ•£æ‰©æ•£å»ºæ¨¡æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ•ˆé‡‡æ ·å¹¶æ”¯æŒå¤šç§è·¨æ¨¡æ€ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆå›¾åƒã€å›¾åƒç¼–è¾‘ã€ä¸»é¢˜é©±åŠ¨ç”Ÿæˆå’Œå›¾åƒä¿®å¤ç­‰ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Lumina-DiMOOæ˜¯ä¸€ä¸ªå¼€æºçš„è·¨æ¨¡æ€æ¨¡å‹ã€‚</li>
<li>å®ƒé‡‡ç”¨å…¨ç¦»æ•£æ‰©æ•£å»ºæ¨¡æŠ€æœ¯å¤„ç†å¤šæ¨¡æ€è¾“å…¥è¾“å‡ºã€‚</li>
<li>Lumina-DiMOOå®ç°äº†é«˜æ•ˆé‡‡æ ·ï¼Œç›¸æ¯”ä¹‹å‰çš„ARæˆ–æ··åˆAR-Diffusionæ¨¡å‹æœ‰ä¼˜åŠ¿ã€‚</li>
<li>è¯¥æ¨¡å‹æ”¯æŒå¤šç§è·¨æ¨¡æ€ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆå›¾åƒã€å›¾åƒç¼–è¾‘ã€ä¸»é¢˜é©±åŠ¨ç”Ÿæˆå’Œå›¾åƒä¿®å¤ç­‰ã€‚</li>
<li>Lumina-DiMOOåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼€æºå¤šæ¨¡æ€æ¨¡å‹ã€‚</li>
<li>ä»£ç å’Œæ£€æŸ¥ç‚¹å·²å‘å¸ƒåˆ°ç¤¾åŒºï¼Œä»¥æ¨åŠ¨å¤šæ¨¡æ€å’Œç¦»æ•£æ‰©æ•£æ¨¡å‹çš„ç ”ç©¶è¿›å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06308">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6422c901ddfafa0820afba6e5e65b0fa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047622&auth_key=1760047622-0-0-12cd53fa30c2b6983cae65cda2f81cca&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-431980fee627d0ee8e4c771278422706~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047629&auth_key=1760047629-0-0-f8210441f7f654a7e4198d3cec0934c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-40a311e10807d3a783be879e5b37d600~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047636&auth_key=1760047636-0-0-350f4c67175a38ac5a38a432e40f2cb6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5373fd9e451689914dcbe89719b98b14~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047643&auth_key=1760047643-0-0-a68fc11c177ab6c46925f4f214df34fa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="RespoDiff-Dual-Module-Bottleneck-Transformation-for-Responsible-Faithful-T2I-Generation"><a href="#RespoDiff-Dual-Module-Bottleneck-Transformation-for-Responsible-Faithful-T2I-Generation" class="headerlink" title="RespoDiff: Dual-Module Bottleneck Transformation for Responsible &amp;   Faithful T2I Generation"></a>RespoDiff: Dual-Module Bottleneck Transformation for Responsible &amp;   Faithful T2I Generation</h2><p><strong>Authors:Silpa Vadakkeeveetil Sreelatha, Sauradip Nag, Muhammad Awais, Serge Belongie, Anjan Dutta</strong></p>
<p>The rapid advancement of diffusion models has enabled high-fidelity and semantically rich text-to-image generation; however, ensuring fairness and safety remains an open challenge. Existing methods typically improve fairness and safety at the expense of semantic fidelity and image quality. In this work, we propose RespoDiff, a novel framework for responsible text-to-image generation that incorporates a dual-module transformation on the intermediate bottleneck representations of diffusion models. Our approach introduces two distinct learnable modules: one focused on capturing and enforcing responsible concepts, such as fairness and safety, and the other dedicated to maintaining semantic alignment with neutral prompts. To facilitate the dual learning process, we introduce a novel score-matching objective that enables effective coordination between the modules. Our method outperforms state-of-the-art methods in responsible generation by ensuring semantic alignment while optimizing both objectives without compromising image fidelity. Our approach improves responsible and semantically coherent generation by 20% across diverse, unseen prompts. Moreover, it integrates seamlessly into large-scale models like SDXL, enhancing fairness and safety. Code will be released upon acceptance. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•å·²ç»å®ç°äº†é«˜ä¿çœŸå’Œè¯­ä¹‰ä¸°å¯Œçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼›ç„¶è€Œï¼Œç¡®ä¿å…¬å¹³å’Œå®‰å…¨ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä»¥æé«˜å…¬å¹³æ€§å’Œå®‰å…¨æ€§ä¸ºä»£ä»·æ¥ç‰ºç‰²è¯­ä¹‰ä¿çœŸå’Œå›¾åƒè´¨é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†RespoDiffï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè´Ÿè´£ä»»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æ–°å‹æ¡†æ¶ï¼Œå®ƒå¯¹æ‰©æ•£æ¨¡å‹çš„ä¸­é—´ç“¶é¢ˆè¡¨ç¤ºè¿›è¡Œäº†åŒé‡æ¨¡å—è½¬æ¢ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸¤ä¸ªç‹¬ç‰¹çš„å­¦ä¹ æ¨¡å—ï¼šä¸€ä¸ªä¸“æ³¨äºæ•è·å’Œæ‰§è¡Œè´Ÿè´£ä»»çš„æ¦‚å¿µï¼Œå¦‚å…¬å¹³æ€§å’Œå®‰å…¨æ€§ï¼›å¦ä¸€ä¸ªåˆ™è‡´åŠ›äºä¿æŒä¸ä¸­æ€§æç¤ºçš„è¯­ä¹‰å¯¹é½ã€‚ä¸ºäº†ä¿ƒè¿›åŒé‡å­¦ä¹ è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹å¾—åˆ†åŒ¹é…ç›®æ ‡ï¼Œä½¿æ¨¡å—ä¹‹é—´å®ç°æœ‰æ•ˆåè°ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡®ä¿è¯­ä¹‰å¯¹é½çš„åŒæ—¶ï¼Œé€šè¿‡ä¼˜åŒ–ä¸¤ä¸ªç›®æ ‡è€Œæ¯«ä¸å¦¥åå›¾åƒä¿çœŸåº¦ï¼Œå®ç°äº†è´Ÿè´£ä»»ç”Ÿæˆçš„å‰æ²¿çªç ´ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒä¸”æœªè§è¿‡çš„æç¤ºä¸‹ï¼Œæé«˜äº†è´Ÿè´£ä»»å’Œè¯­ä¹‰è¿è´¯çš„ç”Ÿæˆèƒ½åŠ›è¾¾20%ã€‚æ­¤å¤–ï¼Œå®ƒèƒ½æ— ç¼é›†æˆåˆ°å¤§å‹æ¨¡å‹å¦‚SDXLä¸­ï¼Œæé«˜å…¬å¹³æ€§å’Œå®‰å…¨æ€§ã€‚ä»£ç å°†åœ¨æ¥å—åå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15257v2">PDF</a> Accepted at NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•ä½¿å¾—é«˜ä¿çœŸå’Œè¯­ä¹‰ä¸°å¯Œçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæˆä¸ºå¯èƒ½ï¼Œä½†ä¿è¯å…¬å¹³å’Œå®‰å…¨ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åœ¨æé«˜å…¬å¹³å’Œå®‰å…¨æ€§çš„åŒæ—¶ç‰ºç‰²äº†è¯­ä¹‰ä¿çœŸå’Œå›¾åƒè´¨é‡ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹æ¡†æ¶RespoDiffï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹çš„ä¸­é—´ç“¶é¢ˆè¡¨ç¤ºè¿›è¡ŒåŒé‡æ¨¡å—è½¬æ¢ï¼Œå®ç°è´Ÿè´£ä»»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚è¯¥æ–¹æ³•å¼•å…¥ä¸¤ä¸ªç‹¬ç«‹çš„å­¦ä¹ æ¨¡å—ï¼Œä¸€ä¸ªä¸“æ³¨äºæ•æ‰å’Œæ‰§è¡Œè´Ÿè´£ä»»çš„æ¦‚å¿µï¼Œå¦‚å…¬å¹³å’Œå®‰å…¨ï¼Œå¦ä¸€ä¸ªè‡´åŠ›äºä¿æŒä¸ä¸­æ€§æç¤ºçš„è¯­ä¹‰å¯¹é½ã€‚é‡‡ç”¨æ–°å‹å¾—åˆ†åŒ¹é…ç›®æ ‡ï¼Œä¿ƒè¿›æ¨¡å—é—´çš„æœ‰æ•ˆåè°ƒã€‚è¯¥æ–¹æ³•åœ¨ä¿è¯è¯­ä¹‰å¯¹é½çš„åŒæ—¶ä¼˜åŒ–ä¸¤ä¸ªç›®æ ‡ï¼Œä¸æŸå®³å›¾åƒä¿çœŸåº¦ï¼Œæé«˜äº†è´Ÿè´£ä»»å’Œè¯­ä¹‰è¿è´¯çš„ç”Ÿæˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•ä¿ƒè¿›äº†æ–‡æœ¬åˆ°å›¾åƒçš„é«˜ä¿çœŸå’Œè¯­ä¹‰ä¸°å¯Œç”Ÿæˆã€‚</li>
<li>ä¿è¯å…¬å¹³å’Œå®‰å…¨åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨æé«˜å…¬å¹³å’Œå®‰å…¨æ€§çš„åŒæ—¶ï¼Œå¾€å¾€ä¼šç‰ºç‰²è¯­ä¹‰ä¿çœŸå’Œå›¾åƒè´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶RespoDiffï¼Œé€šè¿‡åŒé‡æ¨¡å—è½¬æ¢å®ç°è´Ÿè´£ä»»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚</li>
<li>RespoDiffæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªç‹¬ç«‹çš„å­¦ä¹ æ¨¡å—ï¼Œåˆ†åˆ«å…³æ³¨æ•æ‰å’Œæ‰§è¡Œè´Ÿè´£ä»»çš„æ¦‚å¿µä»¥åŠä¿æŒä¸ä¸­æ€§æç¤ºçš„è¯­ä¹‰å¯¹é½ã€‚</li>
<li>é‡‡ç”¨æ–°å‹å¾—åˆ†åŒ¹é…ç›®æ ‡ï¼Œæœ‰æ•ˆåè°ƒä¸¤ä¸ªæ¨¡å—çš„å­¦ä¹ è¿‡ç¨‹ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¿éšœè¯­ä¹‰å¯¹é½çš„åŒæ—¶ä¼˜åŒ–ä¸¤ä¸ªç›®æ ‡ï¼Œæé«˜äº†å›¾åƒç”Ÿæˆçš„å…¬å¹³æ€§å’Œå®‰å…¨æ€§ï¼ŒåŒæ—¶ä¸æŸå®³å›¾åƒä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15257">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-608579db2de69b091d4905ef2523cf98~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047649&auth_key=1760047649-0-0-a02572efd88e183bf30a89e0f98db701&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f7f336b6d92ebec4eb3dafd34e8325d8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047657&auth_key=1760047657-0-0-74fe86c132f8bc2de7859e53a20af534&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MoRE-Brain-Routed-Mixture-of-Experts-for-Interpretable-and-Generalizable-Cross-Subject-fMRI-Visual-Decoding"><a href="#MoRE-Brain-Routed-Mixture-of-Experts-for-Interpretable-and-Generalizable-Cross-Subject-fMRI-Visual-Decoding" class="headerlink" title="MoRE-Brain: Routed Mixture of Experts for Interpretable and   Generalizable Cross-Subject fMRI Visual Decoding"></a>MoRE-Brain: Routed Mixture of Experts for Interpretable and   Generalizable Cross-Subject fMRI Visual Decoding</h2><p><strong>Authors:Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun</strong></p>
<p>Decoding visual experiences from fMRI offers a powerful avenue to understand human perception and develop advanced brain-computer interfaces. However, current progress often prioritizes maximizing reconstruction fidelity while overlooking interpretability, an essential aspect for deriving neuroscientific insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework designed for high-fidelity, adaptable, and interpretable visual reconstruction. MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture where distinct experts process fMRI signals from functionally related voxel groups, mimicking specialized brain networks. The experts are first trained to encode fMRI into the frozen CLIP space. A finetuned diffusion model then synthesizes images, guided by expert outputs through a novel dual-stage routing mechanism that dynamically weighs expert contributions across the diffusion process. MoRE-Brain offers three main advancements: First, it introduces a novel Mixture-of-Experts architecture grounded in brain network principles for neuro-decoding. Second, it achieves efficient cross-subject generalization by sharing core expert networks while adapting only subject-specific routers. Third, it provides enhanced mechanistic insight, as the explicit routing reveals precisely how different modeled brain regions shape the semantic and spatial attributes of the reconstructed image. Extensive experiments validate MoRE-Brainâ€™s high reconstruction fidelity, with bottleneck analyses further demonstrating its effective utilization of fMRI signals, distinguishing genuine neural decoding from over-reliance on generative priors. Consequently, MoRE-Brain marks a substantial advance towards more generalizable and interpretable fMRI-based visual decoding. Code will be publicly available soon: <a target="_blank" rel="noopener" href="https://github.com/yuxiangwei0808/MoRE-Brain">https://github.com/yuxiangwei0808/MoRE-Brain</a>. </p>
<blockquote>
<p>ä»åŠŸèƒ½ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰ä¸­è§£ç è§†è§‰ä½“éªŒä¸ºæˆ‘ä»¬ç†è§£äººç±»æ„ŸçŸ¥å¹¶å¼€å‘å…ˆè¿›çš„è„‘æœºæ¥å£æä¾›äº†å¼ºå¤§çš„é€”å¾„ã€‚ç„¶è€Œï¼Œç›®å‰çš„è¿›å±•å¾€å¾€ä¼˜å…ˆæœ€å¤§åŒ–é‡å»ºä¿çœŸåº¦ï¼Œå´å¿½è§†äº†å¯è§£é‡Šæ€§è¿™ä¸€å¯¹äºè·å–ç¥ç»ç§‘å­¦æ´å¯ŸåŠ›çš„å…³é”®æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†MoRE-Brainï¼Œè¿™æ˜¯ä¸€ä¸ªç¥ç»å¯å‘çš„æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜ä¿çœŸã€å¯é€‚åº”å’Œå¯è§£é‡Šçš„è§†è§‰é‡å»ºã€‚MoRE-Brainç‹¬ç‰¹åœ°é‡‡ç”¨äº†ä¸€ç§å±‚æ¬¡åŒ–çš„æ··åˆä¸“å®¶æ¶æ„ï¼Œå…¶ä¸­ä¸åŒçš„ä¸“å®¶å¤„ç†æ¥è‡ªåŠŸèƒ½ç›¸å…³ä½“ç´ ç»„çš„fMRIä¿¡å·ï¼Œæ¨¡ä»¿ä¸“é—¨çš„è„‘ç½‘ç»œã€‚ä¸“å®¶é¦–å…ˆè¢«è®­ç»ƒå°†fMRIç¼–ç åˆ°å›ºå®šçš„CLIPç©ºé—´ä¸­ã€‚ç„¶åï¼Œä¸€ä¸ªå¾®è°ƒè¿‡çš„æ‰©æ•£æ¨¡å‹åœ¨ä¸“å®¶è¾“å‡ºçš„æŒ‡å¯¼ä¸‹ï¼Œé€šè¿‡ä¸€ç§æ–°çš„åŒé˜¶æ®µè·¯ç”±æœºåˆ¶åˆæˆå›¾åƒï¼Œè¯¥æœºåˆ¶åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­åŠ¨æ€æƒè¡¡ä¸“å®¶çš„è´¡çŒ®ã€‚MoRE-Brainæä¾›äº†ä¸‰ä¸ªä¸»è¦çš„è¿›æ­¥ï¼šé¦–å…ˆï¼Œå®ƒå¼•å…¥äº†ä¸€ç§åŸºäºè„‘ç½‘ç»œåŸç†çš„æ–°å‹æ··åˆä¸“å®¶æ¶æ„ï¼Œç”¨äºç¥ç»è§£ç ã€‚å…¶æ¬¡ï¼Œå®ƒé€šè¿‡å…±äº«æ ¸å¿ƒä¸“å®¶ç½‘ç»œå¹¶ä»…é€‚åº”ç‰¹å®šä¸»é¢˜çš„è·¯ç”±å™¨ï¼Œå®ç°äº†è·¨ä¸»é¢˜çš„æœ‰æ•ˆæ³›åŒ–ã€‚ç¬¬ä¸‰ï¼Œå®ƒæä¾›äº†å¢å¼ºçš„æœºæ¢°æ´å¯ŸåŠ›ï¼Œå› ä¸ºæ˜ç¡®çš„è·¯ç”±å¯ä»¥ç²¾ç¡®åœ°æ­ç¤ºä¸åŒçš„æ¨¡æ‹Ÿè„‘åŒºåŸŸå¦‚ä½•å¡‘é€ é‡å»ºå›¾åƒçš„è¯­ä¹‰å’Œç©ºé—´å±æ€§ã€‚å¤§é‡å®éªŒéªŒè¯äº†MoRE-Brainçš„é«˜é‡å»ºä¿çœŸåº¦ï¼Œç“¶é¢ˆåˆ†æè¿›ä¸€æ­¥è¯æ˜äº†å®ƒæœ‰æ•ˆåˆ©ç”¨fMRIä¿¡å·çš„èƒ½åŠ›ï¼ŒåŒºåˆ†äº†çœŸæ­£çš„ç¥ç»è§£ç å’Œè¿‡åº¦ä¾èµ–ç”Ÿæˆå…ˆéªŒã€‚å› æ­¤ï¼ŒMoRE-Brainæ ‡å¿—ç€æœç€æ›´å…·é€šç”¨æ€§å’Œå¯è§£é‡Šçš„åŸºäºfMRIçš„è§†è§‰è§£ç è¿ˆå‡ºäº†é‡å¤§çš„ä¸€æ­¥ã€‚ä»£ç å°†å¾ˆå¿«åœ¨<a target="_blank" rel="noopener" href="https://github.com/yuxiangwei0808/MoRE-Brain%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/yuxiangwei0808/MoRE-Brainä¸Šå…¬å¼€ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15946v3">PDF</a> Accepted to NeurIPS 2025</p>
<p><strong>Summary</strong><br>è§£ç fMRIä¸­çš„è§†è§‰ä½“éªŒæ˜¯äº†è§£äººç±»æ„ŸçŸ¥åŠ›å’Œå¼€å‘å…ˆè¿›è„‘æœºæ¥å£çš„é‡è¦æ¸ é“ã€‚é’ˆå¯¹ç°æœ‰è§£ç ç­–ç•¥çš„ä¸è¶³ï¼Œæå‡ºMoRE-Brainæ¡†æ¶ï¼Œå®ç°é«˜ä¿çœŸã€å¯é€‚åº”å’Œå¯è§£é‡Šçš„è§†è§‰é‡å»ºã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºç¥ç»ç½‘ç»œçš„æ··åˆä¸“å®¶æ¶æ„å¤„ç†fMRIä¿¡å·ï¼Œå¹¶å¼•å…¥CLIPç©ºé—´å’Œæ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒåˆæˆã€‚MoRE-Brainä¸»è¦è´¡çŒ®åœ¨äºå¼•å…¥åŸºäºè„‘ç½‘ç»œåŸç†çš„æ··åˆä¸“å®¶æ¶æ„ã€å®ç°è·¨ä¸»ä½“é«˜æ•ˆæ³›åŒ–ä»¥åŠæä¾›å¢å¼ºçš„æœºæ¢°æ´å¯ŸåŠ›ã€‚è¯¥æ¡†æ¶å°†ä¸ºè§£ç fMRIæä¾›æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚ä»£ç å³å°†å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MoRE-Brainæ¡†æ¶åˆ©ç”¨æ··åˆä¸“å®¶æ¶æ„è¿›è¡Œç¥ç»è§£ç ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç­–ç•¥ä¸­é‡è§†é‡å»ºä¿çœŸåº¦è€Œå¿½è§†è§£é‡Šæ€§çš„é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºç¥ç»ç½‘ç»œçš„ç­–ç•¥å¤„ç†fMRIä¿¡å·ï¼Œæ¨¡æ‹Ÿä¸“é—¨åŒ–çš„è„‘ç½‘ç»œã€‚</li>
<li>MoRE-Brainå¼•å…¥CLIPç©ºé—´è¿›è¡Œç¼–ç ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹åˆæˆå›¾åƒï¼Œé€šè¿‡åŒé‡é˜¶æ®µè·¯ç”±æœºåˆ¶æŒ‡å¯¼ä¸“å®¶è¾“å‡ºã€‚</li>
<li>MoRE-Brainå®ç°äº†è·¨ä¸»ä½“æ³›åŒ–ï¼Œé€šè¿‡å…±äº«æ ¸å¿ƒä¸“å®¶ç½‘ç»œå¹¶ä»…è°ƒæ•´ä¸»ä½“ç‰¹å®šè·¯ç”±å™¨ã€‚</li>
<li>æ˜ç¡®çš„è·¯ç”±æœºåˆ¶ä¸ºé‡å»ºå›¾åƒçš„è¯­ä¹‰å’Œç©ºé—´å±æ€§æä¾›äº†æœºæ¢°æ´å¯ŸåŠ›ï¼Œæ˜¾ç¤ºäº†ä¸åŒè„‘åŒºå¦‚ä½•å½±å“å›¾åƒé‡å»ºè¿‡ç¨‹ã€‚</li>
<li>å¹¿æ³›å®éªŒéªŒè¯äº†MoRE-Brainçš„é«˜é‡å»ºä¿çœŸåº¦ï¼Œç“¶é¢ˆåˆ†æè¿›ä¸€æ­¥è¯æ˜äº†å…¶åœ¨åˆ©ç”¨fMRIä¿¡å·æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15946">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a5ee0067a49f254ae1bdeaf6cb1d6515~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047664&auth_key=1760047664-0-0-3d377831bcc84c377212bbe2e594d95b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8e12ed1b6adc5fb3a97f076cec9470ea~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047671&auth_key=1760047671-0-0-e4453ca34ba6deeb3ac5ebd3db8b67f1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-645e01c92190ccd6f4f3b22d1c901e02~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047678&auth_key=1760047678-0-0-560dbf6feea872e17b96ce9435902f7e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8de6a61ae5f5f1b4e04a184b09a34118~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047685&auth_key=1760047685-0-0-a590b3ae784aeff97e0ade05a639a92c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ebc9394b2aac8a597cc316f64846fee4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760047692&auth_key=1760047692-0-0-1a2c289e4bf005b8724b7da519378f6f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-10/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-10/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-10/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-7e4c436ac5f510674cbe676065e934a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760049798&auth_key=1760049798-0-0-50b80f9a76b73bef9b9252391c2cffaa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-10  Validation of Various Normalization Methods for Brain Tumor   Segmentation Can Federated Learning Overcome This Heterogeneity?
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-10/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-dafbb93c92742d19c3bf732080370a7d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760046795&auth_key=1760046795-0-0-1a74f7df909cca562122e2a9ef26a679&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-10  VGGT-X When VGGT Meets Dense Novel View Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30762.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
