<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GAN">
    <meta name="description" content="GAN 方向最新论文已更新，请持续关注 Update in 2025-10-10  SSDD Single-Step Diffusion Decoder for Efficient Image Tokenization">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GAN | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-39f8493578ee364bc197068b17f4e99b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045185&auth_key=1760045185-0-0-224470a38eacbf9655ca33d68d5ebf6b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/GAN/">
                                <span class="chip bg-color">GAN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                GAN
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-10-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    25 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-10-10-更新"><a href="#2025-10-10-更新" class="headerlink" title="2025-10-10 更新"></a>2025-10-10 更新</h1><h2 id="SSDD-Single-Step-Diffusion-Decoder-for-Efficient-Image-Tokenization"><a href="#SSDD-Single-Step-Diffusion-Decoder-for-Efficient-Image-Tokenization" class="headerlink" title="SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization"></a>SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization</h2><p><strong>Authors:Théophane Vallaeys, Jakob Verbeek, Matthieu Cord</strong></p>
<p>Tokenizers are a key component of state-of-the-art generative image models, extracting the most important features from the signal while reducing data dimension and redundancy. Most current tokenizers are based on KL-regularized variational autoencoders (KL-VAE), trained with reconstruction, perceptual and adversarial losses. Diffusion decoders have been proposed as a more principled alternative to model the distribution over images conditioned on the latent. However, matching the performance of KL-VAE still requires adversarial losses, as well as a higher decoding time due to iterative sampling. To address these limitations, we introduce a new pixel diffusion decoder architecture for improved scaling and training stability, benefiting from transformer components and GAN-free training. We use distillation to replicate the performance of the diffusion decoder in an efficient single-step decoder. This makes SSDD the first diffusion decoder optimized for single-step reconstruction trained without adversarial losses, reaching higher reconstruction quality and faster sampling than KL-VAE. In particular, SSDD improves reconstruction FID from $0.87$ to $0.50$ with $1.4\times$ higher throughput and preserve generation quality of DiTs with $3.8\times$ faster sampling. As such, SSDD can be used as a drop-in replacement for KL-VAE, and for building higher-quality and faster generative models. </p>
<blockquote>
<p>令牌化器是先进生成图像模型的关键组件，能够从信号中提取最重要的特征，同时降低数据维度和冗余。目前大多数的令牌化器都是基于KL正则化变分自动编码器（KL-VAE），通过重建、感知和对抗损失进行训练。扩散解码器已被提出作为基于潜在条件的图像分布建模的更原则性的替代方案。然而，要达到KL-VAE的性能仍然需要对抗性损失，而且由于迭代采样，解码时间也较高。为了解决这些局限性，我们引入了一种新的像素扩散解码器架构，以提高扩展性和训练稳定性，受益于变压器组件和无GAN训练。我们使用蒸馏来在高效的单步解码器中复制扩散解码器的性能。这使得SSDD成为首个优化的单步重建扩散解码器，无需对抗性损失即可达到更高的重建质量和更快的采样速度，超越了KL-VAE。特别是，SSDD将重建FID从0.87提高到0.50，吞吐量提高了1.4倍，同时保持了DiT的生成质量，采样速度提高了3.8倍。因此，SSDD可以作为KL-VAE的即插即用替代方案，用于构建更高质量和更快的生成模型。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.04961v1">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>新型像素扩散解码器SSDD改进了缩放和训练稳定性，采用了变压器组件和无GAN训练。通过蒸馏技术，SSDD能够在无需对抗损失的情况下复制扩散解码器的性能，实现了高效的单步解码。与KL-VAE相比，SSDD提高了重建质量，加快了采样速度，可以作为KL-VAE的替代品，用于构建更高质量和更快的生成模型。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>令牌化器在生成图像模型中扮演关键角色，能够从信号中提取重要特征并降低数据维度和冗余。</li>
<li>当前大多数令牌化器基于KL正则化变分自编码器（KL-VAE），其训练使用重建、感知和对抗损失。</li>
<li>扩散解码器作为图像分布建模的替代方案被提出，但匹配KL-VAE性能仍需对抗损失，且由于迭代采样，解码时间较长。</li>
<li>新型像素扩散解码器（SSDD）改进了缩放和训练稳定性，并结合了变压器组件和无对抗损失的GAN训练。</li>
<li>SSDD使用蒸馏技术实现高效单步解码，无需对抗损失即可复制扩散解码器的性能。</li>
<li>SSDD提高了重建质量，与KL-VAE相比，其重建FID从0.87降低到0.50，同时提高了吞吐量。</li>
<li>SSDD能够保持与DiTs相当的生产质量，并实现了更快的采样速度（3.8倍）。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.04961">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-7ddb42b2ba934c49d714d0794f68a1df~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045046&auth_key=1760045046-0-0-b7aeed870f8081da3c05412093a5e988&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-92c2ced12f972a3b1f342096e30d9ab4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045053&auth_key=1760045053-0-0-349c2a7b6f3b409bad41fa3080008d28&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dd41fa2db37ae78fd50109f3eb1363ce~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045059&auth_key=1760045059-0-0-accf22c028e05b4075f688bb342442ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="The-best-performance-in-the-CARE-2025-–-Liver-Task-LiSeg-Contrast-Contrast-Aware-Semi-Supervised-Segmentation-with-Domain-Generalization-and-Test-Time-Adaptation"><a href="#The-best-performance-in-the-CARE-2025-–-Liver-Task-LiSeg-Contrast-Contrast-Aware-Semi-Supervised-Segmentation-with-Domain-Generalization-and-Test-Time-Adaptation" class="headerlink" title="The best performance in the CARE 2025 – Liver Task (LiSeg-Contrast):   Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and   Test-Time Adaptation"></a>The best performance in the CARE 2025 – Liver Task (LiSeg-Contrast):   Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and   Test-Time Adaptation</h2><p><strong>Authors:Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang</strong></p>
<p>Accurate liver segmentation from contrast-enhanced MRI is essential for diagnosis, treatment planning, and disease monitoring. However, it remains challenging due to limited annotated data, heterogeneous enhancement protocols, and significant domain shifts across scanners and institutions. Traditional image-to-image translation frameworks have made great progress in domain generalization, but their application is not straightforward. For example, Pix2Pix requires image registration, and cycle-GAN cannot be integrated seamlessly into segmentation pipelines. Meanwhile, these methods are originally used to deal with cross-modality scenarios, and often introduce structural distortions and suffer from unstable training, which may pose drawbacks in our single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised mean teacher scheme to exploit large amounts of unlabeled volumes. A domain adaptation module, incorporating a randomized histogram-based style appearance transfer function and a trainable contrast-aware network, enriches domain diversity and mitigates cross-center variability. Furthermore, a continual test-time adaptation strategy is employed to improve robustness during inference. Extensive experiments demonstrate that our framework consistently outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff Distance while exhibiting strong generalization to unseen domains under low-annotation conditions. </p>
<blockquote>
<p>从对比增强MRI进行准确的肝脏分割对于诊断、治疗计划和疾病监测至关重要。然而，由于标注数据有限、增强协议存在异质性以及扫描仪和机构之间的领域差异较大，这仍然是一个挑战。传统的图像到图像翻译框架在领域泛化方面取得了很大进展，但其应用并不直接。例如，Pix2Pix需要进行图像配准，而循环GAN无法无缝集成到分割管道中。同时，这些方法最初是用于处理跨模态场景的，往往会引入结构失真并面临训练不稳定的问题，这在我们这种单模态场景中可能会带来缺点。为了解决这些挑战，我们提出了CoSSeg-TTA，这是一个紧凑的分割框架，适用于GED4（Gd-EOB-DTPA增强肝胆期MRI）模态，基于nnU-Netv2构建，并使用半监督均值教师方案来利用大量未标记体积数据。一个领域适应模块，结合基于随机直方图的风格外观转换函数和一个可训练的对比感知网络，丰富了领域多样性并减轻了跨中心差异性。此外，采用持续测试时间适应策略，以提高推理过程中的稳健性。大量实验表明，我们的框架始终优于nnU-Netv2基线，在Dice得分和Hausdorff距离上表现优越，同时在低注释条件下对未见领域表现出强大的泛化能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.04243v1">PDF</a> 11 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于nnU-Netv2的紧凑分割框架CoSSeg-TTA，用于对GED4（Gd-EOB-DTPA增强肝胆期MRI）模态进行肝脏分割。该框架结合了半监督均值教师方案，利用大量未标注体积数据，并通过领域适应模块和持续测试时适应策略，解决了标注数据有限、增强协议异质化、扫描器和机构间领域漂移等问题，实现了对对比增强MRI的准确肝脏分割。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>准确肝脏分割在对比增强MRI中对诊断、治疗计划和疾病监测至关重要。</li>
<li>传统图像到图像翻译框架在领域推广方面取得进展，但在肝脏分割中面临挑战。</li>
<li>所提出的CoSSeg-TTA框架基于nnU-Netv2构建，针对GED4模态进行优化。</li>
<li>半监督均值教师方案用于利用大量未标注数据。</li>
<li>领域适应模块通过随机直方图样式转换函数和可训练对比感知网络，丰富了领域多样性和减轻了跨中心变化。</li>
<li>采用持续测试时适应策略，提高推理阶段的稳健性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.04243">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-d3a3d7e77135245aaacf48d35f7b8cdf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045066&auth_key=1760045066-0-0-36c2b77c88de3d6df7fc37c0cc9808e4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fd93b6d3ead1a4ebf9ee116bf4377edf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045073&auth_key=1760045073-0-0-e598e8ea6f574143bac47faa7502e384&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4759b31fe7fc13d067ccf4222b0acdc1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045080&auth_key=1760045080-0-0-1b485d39e245425ce1bfc12a38912978&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SDAKD-Student-Discriminator-Assisted-Knowledge-Distillation-for-Super-Resolution-Generative-Adversarial-Networks"><a href="#SDAKD-Student-Discriminator-Assisted-Knowledge-Distillation-for-Super-Resolution-Generative-Adversarial-Networks" class="headerlink" title="SDAKD: Student Discriminator Assisted Knowledge Distillation for   Super-Resolution Generative Adversarial Networks"></a>SDAKD: Student Discriminator Assisted Knowledge Distillation for   Super-Resolution Generative Adversarial Networks</h2><p><strong>Authors:Nikolaos Kaparinos, Vasileios Mezaris</strong></p>
<p>Generative Adversarial Networks (GANs) achieve excellent performance in generative tasks, such as image super-resolution, but their computational requirements make difficult their deployment on resource-constrained devices. While knowledge distillation is a promising research direction for GAN compression, effectively training a smaller student generator is challenging due to the capacity mismatch between the student generator and the teacher discriminator. In this work, we propose Student Discriminator Assisted Knowledge Distillation (SDAKD), a novel GAN distillation methodology that introduces a student discriminator to mitigate this capacity mismatch. SDAKD follows a three-stage training strategy, and integrates an adapted feature map distillation approach in its last two training stages. We evaluated SDAKD on two well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our experiments demonstrate consistent improvements over the baselines and SOTA GAN knowledge distillation methods. The SDAKD source code will be made openly available upon acceptance of the paper. </p>
<blockquote>
<p>生成对抗网络（GANs）在生成任务（如超分辨率图像）方面表现出卓越的性能，但其计算要求使得在资源受限的设备上部署它们变得困难。虽然知识蒸馏是GAN压缩的有前途的研究方向，但由于学生生成器和教师判别器之间的容量不匹配，有效训练小型学生生成器是一个挑战。在这项工作中，我们提出了学生判别器辅助知识蒸馏（SDAKD），这是一种新的GAN蒸馏方法，它引入了一个学生判别器来缓解这种容量不匹配的问题。SDAKD采用三阶段训练策略，并在最后两个阶段集成了一种改进的特征图蒸馏方法。我们在两个性能良好的超分辨率GANs（GCFSR和Real-ESRGAN）上评估了SDAKD。我们的实验证明，与基准方法和最先进GAN知识蒸馏方法相比，SDAKD具有持续的可改进性。论文被接受后，将公开提供SDAKD的源代码。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03870v1">PDF</a> Under review</p>
<p><strong>Summary</strong><br>GAN在生成任务（如超分辨率图像）上表现优异，但其计算需求使得在资源受限的设备上部署变得困难。知识蒸馏是一种有前景的研究方向，但训练小型学生生成器具有挑战性，因为学生生成器与教师鉴别器之间存在容量不匹配问题。本研究提出一种新型GAN蒸馏方法——学生鉴别器辅助知识蒸馏（SDAKD），引入学生鉴别器以缓解容量不匹配问题。SDAKD采用三阶段训练策略，并在最后两个阶段融入改进的特征图蒸馏方法。在两种高性能超分辨率GAN（GCFSR和Real-ESRGAN）上的实验表明，SDAKD较基线方法和现有最佳GAN知识蒸馏方法有明显改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GAN在生成任务上具有优异性能，但资源受限设备的部署存在挑战。</li>
<li>知识蒸馏是一种有前途的GAN压缩研究方向。</li>
<li>训练小型学生生成器存在挑战，主要是因为与学生鉴别器之间存在容量不匹配问题。</li>
<li>提出新型GAN蒸馏方法——学生鉴别器辅助知识蒸馏（SDAKD），引入学生鉴别器以缓解容量不匹配。</li>
<li>SDAKD采用三阶段训练策略，并在后两个阶段融入改进的特征图蒸馏。</li>
<li>在两种高性能超分辨率GAN上的实验表明SDAKD较基线方法和现有方法有明显改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03870">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-6cf4bc1bdb8513ed7331a42fed6da253~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045087&auth_key=1760045087-0-0-9ccf4ab5db6f8016bbb6d33a6caab373&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8fccb2e6ccbc34a07ec05df5ec79fbdf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045094&auth_key=1760045094-0-0-ea73d8d304ae5cba66947d7ab4f6aa41&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2b7e80a63720cd8613f7e57e14cba995~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045100&auth_key=1760045100-0-0-dca9edec90147e425ea68037623a1c09&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fa15d281a29a8852e608b025761d9b47~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045107&auth_key=1760045107-0-0-31cf39dafa35460340e2a23ed22d2a98&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Advances-in-Medical-Image-Segmentation-A-Comprehensive-Survey-with-a-Focus-on-Lumbar-Spine-Applications"><a href="#Advances-in-Medical-Image-Segmentation-A-Comprehensive-Survey-with-a-Focus-on-Lumbar-Spine-Applications" class="headerlink" title="Advances in Medical Image Segmentation: A Comprehensive Survey with a   Focus on Lumbar Spine Applications"></a>Advances in Medical Image Segmentation: A Comprehensive Survey with a   Focus on Lumbar Spine Applications</h2><p><strong>Authors:Ahmed Kabil, Ghada Khoriba, Mina Yousef, Essam A. Rashed</strong></p>
<p>Medical Image Segmentation (MIS) stands as a cornerstone in medical image analysis, playing a pivotal role in precise diagnostics, treatment planning, and monitoring of various medical conditions. This paper presents a comprehensive and systematic survey of MIS methodologies, bridging the gap between traditional image processing techniques and modern deep learning approaches. The survey encompasses thresholding, edge detection, region-based segmentation, clustering algorithms, and model-based techniques while also delving into state-of-the-art deep learning architectures such as Convolutional Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely adopted U-Net and its variants. Moreover, integrating attention mechanisms, semi-supervised learning, generative adversarial networks (GANs), and Transformer-based models is thoroughly explored. In addition to covering established methods, this survey highlights emerging trends, including hybrid architectures, cross-modality learning, federated and distributed learning frameworks, and active learning strategies, which aim to address challenges such as limited labeled datasets, computational complexity, and model generalizability across diverse imaging modalities. Furthermore, a specialized case study on lumbar spine segmentation is presented, offering insights into the challenges and advancements in this relatively underexplored anatomical region. Despite significant progress in the field, critical challenges persist, including dataset bias, domain adaptation, interpretability of deep learning models, and integration into real-world clinical workflows. </p>
<blockquote>
<p>医学影像分割（MIS）是医学影像分析中的核心部分，对于精确诊断、治疗规划和各种医疗状况监测起到至关重要的作用。本文全面系统地概述了MIS方法，弥合了传统图像处理技术与现代深度学习方法的差距。本文涵盖了阈值分割、边缘检测、基于区域的分割、聚类算法和基于模型的分割技术，同时还深入探讨了最新的深度学习架构，如卷积神经网络（CNN）、全卷积网络（FCN）以及广泛应用的U-Net及其变体。此外，本文还深入探讨了集成注意力机制、半监督学习、生成对抗网络（GANs）和基于Transformer的模型的方法。除了涵盖已建立的方法外，本文还强调了新兴趋势，包括混合架构、跨模态学习、联邦和分布式学习框架以及主动学习策略，旨在解决如有限标记数据集、计算复杂度和模型在多种成像模式中的通用化等挑战。此外，还针对腰椎分割进行了专项案例研究，介绍了这一相对未充分研究的解剖区域的挑战和进展。尽管在这一领域取得了重要进展，但仍存在一些挑战，包括数据集偏差、域适应、深度学习模型的解释性和融入现实世界临床工作流程等。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03318v1">PDF</a> Computers in Biology and Medicine (to appear)</p>
<p><strong>摘要</strong></p>
<p>医疗图像分割（MIS）是医学图像分析的核心，对于精确诊断、治疗规划和各种医疗状况的监督起到关键作用。本文全面系统地概述了MIS方法，包括传统图像处理技术和现代深度学习方法的融合。文章涵盖了阈值分割、边缘检测、基于区域的分割、聚类算法和模型基础技术，并探讨了最新的深度学习架构，如卷积神经网络（CNN）、全卷积网络（FCN）以及广泛应用的U-Net及其变体。此外，本文深入探讨了注意力机制、半监督学习、生成对抗网络（GANs）和基于Transformer的模型的集成。除了已建立的方法外，本文还强调了新兴趋势，包括混合架构、跨模态学习、联邦和分布式学习框架以及主动学习策略，旨在解决如有限标记数据集、计算复杂性和模型在不同成像方式下的泛化能力等方面的挑战。此外，对腰椎间盘分割的专项案例研究提供了对该解剖部位挑战和进展的见解。尽管该领域取得了重大进展，但仍存在数据集偏见、域适应、深度学习模型的可解释性和融入实际临床工作流程等挑战。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>医疗图像分割（MIS）在医学图像分析中起核心作用，对精确诊断和治疗后监测至关重要。</li>
<li>本文综述了传统图像处理方法与最新深度学习技术在MIS中的应用。</li>
<li>深度学习架构如CNN、FCN和U-Net在医疗图像分割中表现优异。</li>
<li>集成注意力机制、半监督学习和GANs等先进方法正在解决特定挑战。</li>
<li>新兴趋势包括混合架构、跨模态学习以及联邦和分布式学习框架等。</li>
<li>腰椎间盘分割的案例研究揭示了特定部位的挑战和最新进展。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03318">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-e4cd82510eee36698d242dc5b7c6866c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045115&auth_key=1760045115-0-0-82fffcf06b0adae814cacd9274a137d2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f673e2cb32b8859abdcc041e10beb31b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045123&auth_key=1760045123-0-0-a6e0d1c7855fbab72a70163b5682488a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="RoboSwap-A-GAN-driven-Video-Diffusion-Framework-For-Unsupervised-Robot-Arm-Swapping"><a href="#RoboSwap-A-GAN-driven-Video-Diffusion-Framework-For-Unsupervised-Robot-Arm-Swapping" class="headerlink" title="RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot   Arm Swapping"></a>RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot   Arm Swapping</h2><p><strong>Authors:Yang Bai, Liudi Yang, George Eskandar, Fengyi Shen, Dong Chen, Mohammad Altillawi, Ziyuan Liu, Gitta Kutyniok</strong></p>
<p>Recent advancements in generative models have revolutionized video synthesis and editing. However, the scarcity of diverse, high-quality datasets continues to hinder video-conditioned robotic learning, limiting cross-platform generalization. In this work, we address the challenge of swapping a robotic arm in one video with another: a key step for crossembodiment learning. Unlike previous methods that depend on paired video demonstrations in the same environmental settings, our proposed framework, RoboSwap, operates on unpaired data from diverse environments, alleviating the data collection needs. RoboSwap introduces a novel video editing pipeline integrating both GANs and diffusion models, combining their isolated advantages. Specifically, we segment robotic arms from their backgrounds and train an unpaired GAN model to translate one robotic arm to another. The translated arm is blended with the original video background and refined with a diffusion model to enhance coherence, motion realism and object interaction. The GAN and diffusion stages are trained independently. Our experiments demonstrate that RoboSwap outperforms state-of-the-art video and image editing models on three benchmarks in terms of both structural coherence and motion consistency, thereby offering a robust solution for generating reliable, cross-embodiment data in robotic learning. </p>
<blockquote>
<p>近期生成模型的进展为视频合成和编辑带来了革命性的变化。然而，多样且高质量数据集的稀缺仍然阻碍了基于视频条件的机器人学习，限制了跨平台的泛化能力。在这项工作中，我们解决了在一个视频中替换机器人手臂为另一个手臂的挑战，这是跨体态学习的关键步骤。不同于以前的方法，它们依赖于相同环境设置中的配对视频演示，我们提出的框架RoboSwap在来自不同环境的不配对数据上进行操作，减轻了数据收集的需求。RoboSwap引入了一种新的视频编辑管道，集成了生成对抗网络（GANs）和扩散模型，结合了它们的独立优势。具体来说，我们从背景中分割出机器人手臂，并训练一个不匹配的GAN模型来将一个机器人手臂转换为另一个手臂。翻译后的手臂与原始视频背景混合，并使用扩散模型进行精炼，以提高连贯性、运动现实性和物体交互。GAN和扩散阶段是独立训练的。我们的实验表明，RoboSwap在三个基准测试上的结构连贯性和运动一致性方面均优于最新的视频和图像编辑模型，从而为机器人学习中的可靠、跨体态数据生成提供了稳健的解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08632v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>近期生成模型的发展在视频合成和编辑方面带来了革新。然而，缺乏多样、高质量的数据集仍然阻碍着视频条件下的机器人学习，限制了跨平台的通用性。本研究致力于解决在一个视频中将一个机械臂替换为另一个机械臂的挑战，这是跨体态学习的关键步骤。不同于以前的方法依赖于相同环境设置中的配对视频演示，我们提出的框架RoboSwap在无配对数据的环境中操作，减轻了数据采集的需求。RoboSwap引入了一种新的视频编辑管道，集成了生成对抗网络（GANs）和扩散模型，结合了它们各自的优势。具体来说，我们从背景中分割出机械臂，训练一个无配对GAN模型将一个机械臂翻译成另一个机械臂。翻译后的机械臂与原始视频背景相结合，并使用扩散模型进行精炼，以提高连贯性、运动现实性和对象交互性。GAN和扩散阶段是独立训练的。实验表明，RoboSwap在结构连贯性和运动一致性方面优于最先进视频和图像编辑模型，在机器人学习的跨体态数据生成方面提供了稳健的解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>生成模型的新进展已革新视频合成和编辑技术。</li>
<li>缺乏多样、高质量数据集仍是视频条件机器人学习的挑战。</li>
<li>提出RoboSwap框架，能在不同环境中操作无配对数据，简化数据采集需求。</li>
<li>RoboSwap集成GANs和扩散模型，利用两者的优势进行视频编辑。</li>
<li>RoboSwap能分割机械臂并训练无配对GAN模型进行翻译。</li>
<li>精炼翻译后的机械臂与原始背景的结合，增强连贯性、运动现实性和对象交互性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08632">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-6c6719c933c8edc2516b1fd45a500113~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045131&auth_key=1760045131-0-0-2ba61b7c8fa3529f2b23f16722d9d732&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ab664779a71525b354b1b2dbe15003ed~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045138&auth_key=1760045138-0-0-2bfdabfb416e6fafd23925a993a99875&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2f722841c9a6fd8b74963f9305b7f289~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045145&auth_key=1760045145-0-0-47bac87811519e8461590ada7de354f1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-06e40d79b25479dd4de6d39f7a7b4472~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045151&auth_key=1760045151-0-0-86ae89f9583555ecc74fd72f0a58673b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e665a1b30dd34211e4ffe0954362bb05~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045158&auth_key=1760045158-0-0-ccf6c04a10e336a3d351fcbd74237c4e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9d3f93730aa68aa5f59be2548b0fbb8a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045164&auth_key=1760045164-0-0-8bb41749285854dd23d909d449a599e2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DiffMI-Breaking-Face-Recognition-Privacy-via-Diffusion-Driven-Training-Free-Model-Inversion"><a href="#DiffMI-Breaking-Face-Recognition-Privacy-via-Diffusion-Driven-Training-Free-Model-Inversion" class="headerlink" title="DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven   Training-Free Model Inversion"></a>DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven   Training-Free Model Inversion</h2><p><strong>Authors:Hanrui Wang, Shuo Wang, Chun-Shien Lu, Isao Echizen</strong></p>
<p>Face recognition poses serious privacy risks due to its reliance on sensitive and immutable biometric data. While modern systems mitigate privacy risks by mapping facial images to embeddings (commonly regarded as privacy-preserving), model inversion attacks reveal that identity information can still be recovered, exposing critical vulnerabilities. However, existing attacks are often computationally expensive and lack generalization, especially those requiring target-specific training. Even training-free approaches suffer from limited identity controllability, hindering faithful reconstruction of nuanced or unseen identities. In this work, we propose DiffMI, the first diffusion-driven, training-free model inversion attack. DiffMI introduces a novel pipeline combining robust latent code initialization, a ranked adversarial refinement strategy, and a statistically grounded, confidence-aware optimization objective. DiffMI applies directly to unseen target identities and face recognition models, offering greater adaptability than training-dependent approaches while significantly reducing computational overhead. Our method achieves 84.42%–92.87% attack success rates against inversion-resilient systems and outperforms the best prior training-free GAN-based approach by 4.01%–9.82%. The implementation is available at <a target="_blank" rel="noopener" href="https://github.com/azrealwang/DiffMI">https://github.com/azrealwang/DiffMI</a>. </p>
<blockquote>
<p>人脸识别依赖于敏感且不可更改的生物识别数据，从而带来严重的隐私风险。现代系统通过将面部图像映射到嵌入来减轻隐私风险（通常被认为是保护隐私的），但模型逆向攻击表明，身份信息仍然可以恢复，暴露出关键漏洞。然而，现有攻击通常计算量大且缺乏通用性，特别是那些需要针对目标进行特定训练的方法。即使是不需要训练的方法也面临身份可控性有限的问题，阻碍了微妙或未见过的身份的忠实重建。在这项工作中，我们提出了DiffMI，这是一种不需要训练的首个基于扩散的模型逆向攻击方法。DiffMI引入了一种新型管道，结合了稳健的潜在代码初始化、排名对抗细化策略以及基于统计的、具有置信度的优化目标。DiffMI可直接应用于未见过的目标身份和人脸识别模型，相比依赖于训练的方法提供了更大的适应性，同时大大降低了计算开销。我们的方法针对抗逆向攻击的系统的攻击成功率为84.42%~92.87%，并且相较于最佳的先前无训练GAN方法提高了4.01%~9.82%。实现代码可在<a target="_blank" rel="noopener" href="https://github.com/azrealwang/DiffMI%E5%A4%84%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/azrealwang/DiffMI处下载。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18015v3">PDF</a> </p>
<p><strong>Summary</strong><br>人脸识别技术依赖敏感且不可更改的生物识别数据，存在严重的隐私风险。尽管现代系统通过面部图像映射到嵌入来减轻这些风险，但模型反演攻击显示仍可以恢复身份信息，暴露出重大漏洞。本文提出的DiffMI是一种无需训练的反演攻击方法，通过结合稳健的潜在代码初始化、排名对抗性优化策略和统计置信度感知的优化目标，直接应用于未见过的目标身份和人脸识别模型。相较于依赖训练的方法，DiffMI具有更大的适应性和更低的计算开销，攻击成功率达到84.42%-92.87%，并对抗反演韧性系统，表现优于最佳的前期无需训练的GAN基础方法4.01%-9.82%。更多详情访问：<a target="_blank" rel="noopener" href="https://github.com/azrealwang/DiffMI%E3%80%82">https://github.com/azrealwang/DiffMI。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>人脸识别存在隐私风险，因为模型反演攻击可恢复身份信息。</li>
<li>现代系统通过面部图像映射到嵌入来减轻隐私风险，但仍存在漏洞。</li>
<li>DiffMI是一种新型模型反演攻击方法，无需训练，可直接应用于未见过的目标身份和人脸识别模型。</li>
<li>DiffMI结合稳健的潜在代码初始化、排名对抗性优化策略和统计置信度感知的优化目标。</li>
<li>DiffMI具有较大的适应性和较低的计算开销。</li>
<li>DiffMI的攻击成功率达到84.42%-92.87%，并能对抗反演韧性系统。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18015">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-df37953451db668115872255843a3610~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045171&auth_key=1760045171-0-0-67ec2c61c05bcbea4d1013a31b102ec8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5bf1a8825af7c02e473c26ee363c6517~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045178&auth_key=1760045178-0-0-0e68d23ae77ad93b20fe6e5f1212f68b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-39f8493578ee364bc197068b17f4e99b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045185&auth_key=1760045185-0-0-224470a38eacbf9655ca33d68d5ebf6b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fa2bff4839f2c32bb8d3f2f9df6885e0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045191&auth_key=1760045191-0-0-9788832936d7479aedf0736022e4fa6a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cacf979cecb3e95464aba66d7b8f6d2c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045197&auth_key=1760045197-0-0-e5bb6943050f42a40debce5f321faff2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6968542777548f62e12dad1d66bbdf5f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045204&auth_key=1760045204-0-0-ffbd9ebf7dd1b9d7bd5f3b58dce12093&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c06c7e14545f0b2bdd3ced0ea9ecd2f7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760045210&auth_key=1760045210-0-0-042486aca5325ff48c90df20ff094233&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-10/GAN/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-10/GAN/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/GAN/">
                                    <span class="chip bg-color">GAN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-10/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-dddfc02363ffac02b51894e515e3c4e1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760046107&auth_key=1760046107-0-0-6063b3515a05097cf4e25a5b81eaca62&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2025-10-10  RTGS Real-Time 3D Gaussian Splatting SLAM via Multi-Level Redundancy   Reduction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-10/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-45810d09557cc88586579a49aefb5ef9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760044523&auth_key=1760044523-0-0-b97931a7993fac155a158394a0cd4e4a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping 方向最新论文已更新，请持续关注 Update in 2025-10-10  Unmasking Puppeteers Leveraging Biometric Leakage to Disarm   Impersonation in AI-based Videoconferencing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
