<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-01-16  SAR Strikes Back A New Hope for RSVQA">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4c6d1c3d0ec7abcaf2f0ea1c61f31551.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-01-16-更新"><a href="#2025-01-16-更新" class="headerlink" title="2025-01-16 更新"></a>2025-01-16 更新</h1><h2 id="SAR-Strikes-Back-A-New-Hope-for-RSVQA"><a href="#SAR-Strikes-Back-A-New-Hope-for-RSVQA" class="headerlink" title="SAR Strikes Back: A New Hope for RSVQA"></a>SAR Strikes Back: A New Hope for RSVQA</h2><p><strong>Authors:Lucrezia Tosato, Flora Weissgerber, Laurent Wendling, Sylvain Lobry</strong></p>
<p>Remote sensing visual question answering (RSVQA) is a task that automatically extracts information from satellite images and processes a question to predict the answer from the images in textual form, helping with the interpretation of the image. While different methods have been proposed to extract information from optical images with different spectral bands and resolutions, no method has been proposed to answer questions from Synthetic Aperture Radar (SAR) images. SAR images capture electromagnetic information from the scene, and are less affected by atmospheric conditions, such as clouds. In this work, our objective is to introduce SAR in the RSVQA task, finding the best way to use this modality. In our research, we carry out a study on different pipelines for the task of RSVQA taking into account information from both SAR and optical data. To this purpose, we also present a dataset that allows for the introduction of SAR images in the RSVQA framework. We propose two different models to include the SAR modality. The first one is an end-to-end method in which we add an additional encoder for the SAR modality. In the second approach, we build on a two-stage framework. First, relevant information is extracted from SAR and, optionally, optical data. This information is then translated into natural language to be used in the second step which only relies on a language model to provide the answer. We find that the second pipeline allows us to obtain good results with SAR images alone. We then try various types of fusion methods to use SAR and optical images together, finding that a fusion at the decision level achieves the best results on the proposed dataset. We show that SAR data offers additional information when fused with the optical modality, particularly for questions related to specific land cover classes, such as water areas. </p>
<blockquote>
<p>遥感视觉问答（RSVQA）是一项任务，它会自动从卫星图像中提取信息，并处理问题以预测图像的文本形式的答案，有助于解释图像。虽然已经提出了不同的方法从具有不同光谱波段和分辨率的光学图像中提取信息，但还没有提出从合成孔径雷达（SAR）图像中回答问题的方法。SAR图像捕捉场景的电磁信息，并且受云层等大气条件的影响较小。在这项工作中，我们的目标是在RSVQA任务中引入SAR，寻找使用这种模态的最佳方式。在我们的研究中，我们研究了不同的RSVQA任务管道，考虑了SAR和光学数据的双重信息。为此，我们还提供了一个允许在RSVQA框架中引入SAR图像的数据集。我们提出了两种包含SAR模态的模型。第一种是端到端的方法，我们为SAR模态添加了一个额外的编码器。在第二种方法中，我们基于两阶段框架构建。首先，从SAR和（可选）光学数据中提取相关信息。然后将此信息转换为自然语言，用于第二步，该步骤仅依靠语言模型来提供答案。我们发现第二个管道允许我们仅使用SAR图像就获得良好的结果。然后，我们尝试了各种融合方法来同时使用SAR和光学图像，发现决策层融合在提出的数据集上取得了最佳效果。我们表明，SAR数据在与光学模态融合时提供了额外的信息，特别是对于与特定土地覆盖类相关的问题，例如水域。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.08131v1">PDF</a> 26 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>遥感视觉问答（RSVQA）能够从卫星图像中自动提取信息，并将问题转化为文本形式来预测答案，有助于图像解读。目前尚未有方法能够利用合成孔径雷达（SAR）图像回答问题。SAR图像捕捉场景电磁信息，较少受云层等大气条件影响。本研究旨在将SAR引入RSVQA任务，探索最佳使用方式。为此，研究提出两种包含SAR模态的模型。第一种是端到端方法，增加SAR模态的额外编码器。第二种是基于两阶段框架，首先提取SAR和（可选）光学数据的相关信息，然后将其翻译成自然语言，在仅依赖语言模型的情况下提供答案。研究发现，第二管道在使用仅SAR图像时即可获得良好结果。尝试将SAR和光学图像结合使用，发现决策级融合效果最佳。SAR数据在与光学模态融合时能提供额外信息，特别是在涉及特定土地覆盖类别的问题中表现突出，如水域。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>遥感视觉问答（RSVQA）能够从卫星图像中提取信息并转化为文本形式的答案。</li>
<li>目前没有方法能够利用合成孔径雷达（SAR）图像回答问题。</li>
<li>SAR图像捕捉场景的电磁信息，较少受大气条件影响。</li>
<li>研究提出两种包含SAR模态的模型：端到端方法和基于两阶段框架的方法。</li>
<li>第二管道在使用仅SAR图像时即可获得良好结果。</li>
<li>决策级融合在结合SAR和光学图像时效果最佳。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.08131">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-591b2ebd3bbc8e38613bf61d40a297a8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Diff-Ensembler-Learning-to-Ensemble-2D-Diffusion-Models-for-Volume-to-Volume-Medical-Image-Translation"><a href="#Diff-Ensembler-Learning-to-Ensemble-2D-Diffusion-Models-for-Volume-to-Volume-Medical-Image-Translation" class="headerlink" title="Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for   Volume-to-Volume Medical Image Translation"></a>Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for   Volume-to-Volume Medical Image Translation</h2><p><strong>Authors:Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko</strong></p>
<p>Despite success in volume-to-volume translations in medical images, most existing models struggle to effectively capture the inherent volumetric distribution using 3D representations. The current state-of-the-art approach combines multiple 2D-based networks through weighted averaging, thereby neglecting the 3D spatial structures. Directly training 3D models in medical imaging presents significant challenges due to high computational demands and the need for large-scale datasets. To address these challenges, we introduce Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective volumetric translations by ensembling perpendicularly trained 2D diffusion models with a 3D network in each diffusion step. Moreover, our model can naturally be used to ensemble diffusion models conditioned on different modalities, allowing flexible and accurate fusion of input conditions. Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy and volumetric realism in 3D medical image super-resolution and modality translation. We further demonstrate the strength of our model’s volumetric realism using tumor segmentation as a downstream task. </p>
<blockquote>
<p>尽管在医学图像体积到体积的翻译方面取得了一定的成功，但大多数现有模型在利用三维表示捕捉固有体积分布方面仍然存在困难。目前最先进的方法是通过加权平均组合多个基于二维的网络，从而忽略了三维空间结构。直接在医学影像中训练三维模型面临着计算需求高和需要大规模数据集等显著挑战。为了解决这些挑战，我们引入了Diff-Ensembler，这是一种新型混合的二维-三维模型，通过在每个扩散步骤中将垂直训练的二维扩散模型与三维网络组合，实现高效且有效的体积翻译。此外，我们的模型自然地可用于结合不同模态的扩散模型，实现输入条件的灵活和准确融合。大量实验表明，Diff-Ensembler在三维医学图像超分辨率和模态翻译方面达到了更高的准确性和体积真实性。我们进一步使用肿瘤分割作为下游任务来展示我们的模型在体积真实性方面的优势。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07430v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文探讨了在医学图像体积转换领域中的挑战和解决方案。现有模型难以有效捕捉医学图像的内在体积分布，而直接训练三维模型面临计算需求高和需要大量数据集的问题。为此，提出了一种新型混合的二维-三维模型Diff-Ensembler，它通过集成垂直训练的二维扩散模型与每个扩散步骤中的三维网络，实现了高效且准确的体积转换。该模型还可以根据不同模态进行条件扩散模型的集成，从而实现输入条件的灵活和精确融合。实验证明，Diff-Ensembler在三维医学图像超分辨率和模态转换中达到了较高的准确性和体积逼真度，并在肿瘤分割等下游任务中表现出强大的体积逼真度。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有模型在医学图像体积转换中面临挑战，难以捕捉内在体积分布。</li>
<li>直接训练三维模型在医学成像中面临高计算需求和大规模数据集的问题。</li>
<li>Diff-Ensembler是一种新型混合二维-三维模型，通过集成垂直训练的二维扩散模型和三维网络，实现高效且准确的体积转换。</li>
<li>Diff-Ensembler模型可以在不同模态下进行条件扩散模型的集成。</li>
<li>Diff-Ensembler在三维医学图像超分辨率和模态转换中具有高准确性和体积逼真度。</li>
<li>该模型在肿瘤分割等下游任务中表现出强大的体积逼真度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07430">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d8e883edb0eed8c205b07d1443916b5a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-badd674dae4f1fac96bbcc27dde31393.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c6d1c3d0ec7abcaf2f0ea1c61f31551.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Boosting-Text-To-Image-Generation-via-Multilingual-Prompting-in-Large-Multimodal-Models"><a href="#Boosting-Text-To-Image-Generation-via-Multilingual-Prompting-in-Large-Multimodal-Models" class="headerlink" title="Boosting Text-To-Image Generation via Multilingual Prompting in Large   Multimodal Models"></a>Boosting Text-To-Image Generation via Multilingual Prompting in Large   Multimodal Models</h2><p><strong>Authors:Yongyu Mu, Hengyu Li, Junxin Wang, Xiaoxuan Zhou, Chenglong Wang, Yingfeng Luo, Qiaozhi He, Tong Xiao, Guocheng Chen, Jingbo Zhu</strong></p>
<p>Previous work on augmenting large multimodal models (LMMs) for text-to-image (T2I) generation has focused on enriching the input space of in-context learning (ICL). This includes providing a few demonstrations and optimizing image descriptions to be more detailed and logical. However, as demand for more complex and flexible image descriptions grows, enhancing comprehension of input text within the ICL paradigm remains a critical yet underexplored area. In this work, we extend this line of research by constructing parallel multilingual prompts aimed at harnessing the multilingual capabilities of LMMs. More specifically, we translate the input text into several languages and provide the models with both the original text and the translations. Experiments on two LMMs across 3 benchmarks show that our method, PMT2I, achieves superior performance in general, compositional, and fine-grained assessments, especially in human preference alignment. Additionally, with its advantage of generating more diverse images, PMT2I significantly outperforms baseline prompts when incorporated with reranking methods. Our code and parallel multilingual data can be found at <a target="_blank" rel="noopener" href="https://github.com/takagi97/PMT2I">https://github.com/takagi97/PMT2I</a>. </p>
<blockquote>
<p>之前关于增强大型多模态模型（LMMs）以进行文本到图像（T2I）生成的工作主要集中在丰富上下文学习（ICL）的输入空间。这包括提供几个演示并优化图像描述以使其更详细和逻辑性强。然而，随着对更复杂和更灵活的图像描述的需求不断增长，增强在ICL范式内对输入文本的理解仍然是一个关键但尚未被充分研究的领域。在这项工作中，我们通过构建并行多语言提示来扩展这一研究领域，旨在利用大型多模态模型的多语言能力。更具体地说，我们将输入文本翻译成多种语言，并为模型提供原始文本和翻译文本。在三个基准测试上对两个大型多模态模型的实验表明，我们的方法PMT2I在总体、组合和精细评估中均取得了卓越的性能，特别是在与人类偏好对齐方面。此外，由于其生成更多样化图像的优势，当与重新排序方法相结合时，PMT2I明显超越了基线提示。我们的代码和多语言并行数据可以在 <a target="_blank" rel="noopener" href="https://github.com/takagi97/PMT2I">https://github.com/takagi97/PMT2I</a> 找到。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07086v1">PDF</a> Accepted to ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>该论文针对文本转图像生成任务，探索了增强大型多模态模型（LMMs）输入文本理解的方法。通过构建平行多语言提示，利用模型的多语言能力，将输入文本翻译成多种语言并提供给模型。实验表明，该方法在通用、组合和精细评估中都取得了优越的性能，特别是在与人类偏好对齐方面。此外，该方法还能生成更多样化的图像，当与重排序方法结合时，显著优于基准提示。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>该论文专注于增强大型多模态模型在文本转图像生成任务中对输入文本的理解。</li>
<li>通过构建平行多语言提示，利用模型的多语言能力。</li>
<li>将输入文本翻译成多种语言，并同时提供给模型原始文本和翻译文本。</li>
<li>实验表明，该方法在多种评估中都取得了优越性能。</li>
<li>该方法在人类偏好对齐方面表现特别出色。</li>
<li>与基准提示相比，该方法能生成更多样化的图像。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07086">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b1c262f67f9b59d0da355b94aa146c8d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee40cfb90443ffb12fa772f2d8a3a937.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20d3b080bec79955b92aeff5256afca5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83b43995d434f2c27a0264d8d7eb5fe5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f5a470228d2fee38bc7e1749cd91079.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multimodal-Structure-Aware-Quantum-Data-Processing"><a href="#Multimodal-Structure-Aware-Quantum-Data-Processing" class="headerlink" title="Multimodal Structure-Aware Quantum Data Processing"></a>Multimodal Structure-Aware Quantum Data Processing</h2><p><strong>Authors:Hala Hawashin, Mehrnoosh Sadrzadeh</strong></p>
<p>While large language models (LLMs) have advanced the field of natural language processing (NLP), their “black box” nature obscures their decision-making processes. To address this, researchers developed structured approaches using higher order tensors. These are able to model linguistic relations, but stall when training on classical computers due to their excessive size. Tensors are natural inhabitants of quantum systems and training on quantum computers provides a solution by translating text to variational quantum circuits. In this paper, we develop MultiQ-NLP: a framework for structure-aware data processing with multimodal text+image data. Here, “structure” refers to syntactic and grammatical relationships in language, as well as the hierarchical organization of visual elements in images. We enrich the translation with new types and type homomorphisms and develop novel architectures to represent structure. When tested on a main stream image classification task (SVO Probes), our best model showed a par performance with the state of the art classical models; moreover the best model was fully structured. </p>
<blockquote>
<p>虽然大型语言模型（LLM）在自然语言处理（NLP）领域取得了进展，但它们的“黑箱”性质掩盖了它们的决策过程。为了解决这一问题，研究人员采用了使用高阶张量的结构化方法。这些方法能够模拟语言关系，但在经典计算机上进行训练时，由于体积过大而陷入困境。张量是量子系统的天然组成部分，在量子计算机上进行训练通过将文本转换为变分量子电路来解决这一问题。在本文中，我们开发了MultiQ-NLP：一个用于结构感知数据处理的多模态文本+图像数据框架。在这里，“结构”是指语言中的句法、语法关系以及图像中视觉元素分层组织。我们通过新型张量以及类型同构丰富了翻译内容，并开发了新型架构来表示结构。在主流图像分类任务（SVO Probes）测试中，我们最佳模型的性能与最新经典模型相当，而且该模型是完全结构化的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04242v4">PDF</a> 10 Pages, 16 Figures</p>
<p><strong>Summary</strong></p>
<p>大型语言模型在自然语言处理领域取得了进展，但其“黑箱”性质掩盖了决策过程。为解决这个问题，研究者采用高阶张量构建结构化方法，虽然能建模语言关系，但在经典计算机上训练时因体积过大而受阻。张量是量子系统的自然元素，量子计算机训练通过将文本转换为变分量子电路提供解决方案。本文开发MultiQ-NLP框架，实现结构感知数据处理和多媒体文本+图像数据。这里，“结构”指语言中的语法和句法关系，以及图像中视觉元素分层组织。我们丰富翻译内容，发展新型架构来代表结构，并在主流图像分类任务（SVO Probes）上进行测试，最佳模型表现与最先进经典模型相当，且具备完全结构化特点。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）在自然语言处理中取得进展，但存在“黑箱”问题，决策过程不透明。</li>
<li>高阶张量用于构建结构化方法，能够建模语言关系，但在经典计算机上训练受限。</li>
<li>张量是量子系统的自然元素，量子计算机训练通过变分量子电路解决大型语言模型的训练问题。</li>
<li>开发出MultiQ-NLP框架，实现结构感知数据处理和多媒体文本+图像数据处理。</li>
<li>“结构”包括语言中的语法和句法关系，以及图像中视觉元素的分层组织。</li>
<li>通过丰富翻译内容和发展新型架构来代表结构，提高模型性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04242">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-965b71dc136011674e1161e55a73b02b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c35849b34d2792815d4a85580cef033.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20d9bc30a424c999f90e93952e752961.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51bfcc606de605cbdaf579764b067516.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-352b0270a235b4e9519b53780db6b22c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80cb43f9adb156dcecb8fd8d649a3c8b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-845d8799f0f280c7f35de5888ded0ede.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0b9a62559b5b843b76db26cc7bd81ae.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-89d7a90828e12e022d7dcbf940ec36fd.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="FaVoR-Features-via-Voxel-Rendering-for-Camera-Relocalization"><a href="#FaVoR-Features-via-Voxel-Rendering-for-Camera-Relocalization" class="headerlink" title="FaVoR: Features via Voxel Rendering for Camera Relocalization"></a>FaVoR: Features via Voxel Rendering for Camera Relocalization</h2><p><strong>Authors:Vincenzo Polizzi, Marco Cannici, Davide Scaramuzza, Jonathan Kelly</strong></p>
<p>Camera relocalization methods range from dense image alignment to direct camera pose regression from a query image. Among these, sparse feature matching stands out as an efficient, versatile, and generally lightweight approach with numerous applications. However, feature-based methods often struggle with significant viewpoint and appearance changes, leading to matching failures and inaccurate pose estimates. To overcome this limitation, we propose a novel approach that leverages a globally sparse yet locally dense 3D representation of 2D features. By tracking and triangulating landmarks over a sequence of frames, we construct a sparse voxel map optimized to render image patch descriptors observed during tracking. Given an initial pose estimate, we first synthesize descriptors from the voxels using volumetric rendering and then perform feature matching to estimate the camera pose. This methodology enables the generation of descriptors for unseen views, enhancing robustness to view changes. We extensively evaluate our method on the 7-Scenes and Cambridge Landmarks datasets. Our results show that our method significantly outperforms existing state-of-the-art feature representation techniques in indoor environments, achieving up to a 39% improvement in median translation error. Additionally, our approach yields comparable results to other methods for outdoor scenarios while maintaining lower memory and computational costs. </p>
<blockquote>
<p>相机重定位方法包括从密集图像对齐到直接从查询图像进行相机姿态回归。其中，稀疏特征匹配作为一种高效、通用且通常轻便的方法，具有众多应用。然而，基于特征的方法在视角和外观变化较大时往往会遇到困难，导致匹配失败和姿态估计不准确。为了克服这一局限性，我们提出了一种新的方法，该方法利用二维特征的全球稀疏但局部密集的3D表示。通过跟踪一系列帧中的地标并进行三角测量，我们构建了一个优化的稀疏体素地图，以呈现跟踪过程中观察到的图像补丁描述符。给定初始姿态估计，我们首先使用体积渲染技术从体素合成描述符，然后进行特征匹配以估计相机姿态。这种方法能够生成未见视图的描述符，增强了应对视角变化的稳健性。我们在7场景和剑桥地标数据集上对我们的方法进行了广泛评估。结果表明，我们的方法在室内环境下显著优于现有的最先进的特征表示技术，在中位平移误差上最多提高了39%。此外，我们的方法在室外场景的结果与其他方法相当，同时降低了内存和计算成本。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.07571v3">PDF</a> Accepted to the IEEE&#x2F;CVF Winter Conference on Applications of   Computer Vision (WACV), Tucson, Arizona, US, Feb 28-Mar 4, 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于稀疏特征匹配的相机定位方法，通过全局稀疏、局部密集的三维特征表示来解决现有方法在面对视角和外观变化时的匹配失败和姿态估计不准确问题。该方法通过追踪和三角测量地标序列帧构建稀疏体素地图，优化渲染图像补丁描述符。给定初始姿态估计，通过体积渲染合成体素描述符，然后进行特征匹配估计相机姿态。此方法能生成未见视图的描述符，增强对视角变化的稳健性。在7场景和剑桥地标数据集上的评估显示，该方法在室内环境下显著优于现有特征表示技术，中位数平移误差最多提高39%。同时，对于室外场景，该方法在保持较低内存和计算成本的情况下，结果与其他方法相当。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>相机定位方法包括从密集图像对齐到直接相机姿态回归查询图像等多种方法，其中稀疏特征匹配是一种高效、通用且轻量级的方法。</li>
<li>稀疏特征匹配在面临显著视角和外观变化时会出现匹配失败和姿态估计不准确的问题。</li>
<li>本文提出一种基于全局稀疏、局部密集的三维特征表示的新方法来解决上述问题。</li>
<li>方法通过追踪和三角测量地标序列帧构建稀疏体素地图，并优化渲染图像补丁描述符。</li>
<li>通过体积渲染合成体素描述符，进行特征匹配估计相机姿态。</li>
<li>该方法能生成未见视图的描述符，增强稳健性，特别是在室内环境下显著优于其他方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.07571">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9583a7cb5cc62bf93135d26aee4c89ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e987479d4654a01f61647d87fc458232.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94fb6159d82a9107dafa415d1280ee1a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0b81a60086e0a827a9ec9b77cd720429.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="An-Accurate-and-Real-time-Relative-Pose-Estimation-from-Triple-Point-line-Images-by-Decoupling-Rotation-and-Translation"><a href="#An-Accurate-and-Real-time-Relative-Pose-Estimation-from-Triple-Point-line-Images-by-Decoupling-Rotation-and-Translation" class="headerlink" title="An Accurate and Real-time Relative Pose Estimation from Triple   Point-line Images by Decoupling Rotation and Translation"></a>An Accurate and Real-time Relative Pose Estimation from Triple   Point-line Images by Decoupling Rotation and Translation</h2><p><strong>Authors:Zewen Xu, Yijia He, Hao Wei, Bo Xu, BinJian Xie, Yihong Wu</strong></p>
<p>Line features are valid complements for point features in man-made environments. 3D-2D constraints provided by line features have been widely used in Visual Odometry (VO) and Structure-from-Motion (SfM) systems. However, how to accurately solve three-view relative motion only with 2D observations of points and lines in real time has not been fully explored. In this paper, we propose a novel three-view pose solver based on rotation-translation decoupled estimation. First, a high-precision rotation estimation method based on normal vector coplanarity constraints that consider the uncertainty of observations is proposed, which can be solved by Levenberg-Marquardt (LM) algorithm efficiently. Second, a robust linear translation constraint that minimizes the degree of the rotation components and feature observation components in equations is elaborately designed for estimating translations accurately. Experiments on synthetic data and real-world data show that the proposed approach improves both rotation and translation accuracy compared to the classical trifocal-tensor-based method and the state-of-the-art two-view algorithm in outdoor and indoor environments. </p>
<blockquote>
<p>线条特征是人造环境中点特征的有效补充。由线条特征提供的3D-2D约束已广泛应用于视觉里程计（VO）和从运动恢复结构（SfM）系统中。然而，如何仅利用实时的二维点对和线条观察来准确解决三视相对运动尚未得到充分探索。在本文中，我们提出了一种基于旋转平移解耦估计的新型三视姿态求解器。首先，提出了一种基于法线向量共面约束的高精度旋转估计方法，该方法考虑了观测的不确定性，可通过列文贝格-马夸尔特（LM）算法有效地解决。其次，为了准确估计平移，精心设计了一种稳健的线性平移约束，该约束最小化了方程中的旋转分量和特征观测分量的程度。在合成数据和真实世界数据上的实验表明，与基于三焦点张量的经典方法和室外和室内环境中的最新两视算法相比，所提出的方法提高了旋转和平移的准确性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.11639v2">PDF</a> </p>
<p><strong>Summary</strong>:<br>本文提出一种基于旋转平移解耦估计的三视图姿态求解器。利用基于法向量共面约束的高精度旋转估计方法和精心设计的线性平移约束，实现了仅通过二维点线观测实时解决三视图相对运动的问题。实验表明，该方法相较于传统三焦点张量方法和当前主流的两视图算法，在室内外环境中提高了旋转和平移精度。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>线特征在人造环境中是点特征的有效补充，3D-2D约束在视觉里程计和从运动恢复结构系统中得到广泛应用。</li>
<li>本文提出了一种新的三视图姿态求解器，基于旋转平移解耦估计。</li>
<li>提出了一种考虑观测不确定性的基于法向量共面约束的高精度旋转估计方法，可通过Levenberg-Marquardt算法高效求解。</li>
<li>精心设计了一个线性平移约束，以最小化方程中的旋转分量和特征观测分量，从而更准确地估计平移。</li>
<li>实验表明，该方法在旋转和平移精度上优于传统的三焦点张量方法和当前主流的两视图算法。</li>
<li>该方法适用于室内外环境。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.11639">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-9579a15da57c0b8094f4fbb583013adf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5750974057e40b65feb02e9d8ed0bbf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9aff0f0df40969ac7dfae12570fbf77f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab293f4462092b7178dc760b8350666f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-317b0125fa0074a1d08074ab56ff2ebd.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5833537aa44ce898235bce02f83c37bb.jpg" class="responsive-img" alt="视频理解">
                        
                        <span class="card-title">视频理解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            视频理解 方向最新论文已更新，请持续关注 Update in 2025-01-16  Omni-RGPT Unifying Image and Video Region-level Understanding via Token   Marks
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    视频理解
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">视频理解</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_Few-Shot/2501.06903v1/page_2_0.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-01-16  Text-Diffusion Red-Teaming of Large Language Models Unveiling Harmful   Behaviors with Proximity Constraints
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23667.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
