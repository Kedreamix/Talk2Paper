<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  Threshold Attention Network for Semantic Segmentation of Remote Sensing   Images">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-eda112a70646e26e626a9e100d78d313.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-16-æ›´æ–°"><a href="#2025-01-16-æ›´æ–°" class="headerlink" title="2025-01-16 æ›´æ–°"></a>2025-01-16 æ›´æ–°</h1><h2 id="Threshold-Attention-Network-for-Semantic-Segmentation-of-Remote-Sensing-Images"><a href="#Threshold-Attention-Network-for-Semantic-Segmentation-of-Remote-Sensing-Images" class="headerlink" title="Threshold Attention Network for Semantic Segmentation of Remote Sensing   Images"></a>Threshold Attention Network for Semantic Segmentation of Remote Sensing   Images</h2><p><strong>Authors:Wei Long, Yongjun Zhang, Zhongwei Cui, Yujie Xu, Xuexue Zhang</strong></p>
<p>Semantic segmentation of remote sensing images is essential for various applications, including vegetation monitoring, disaster management, and urban planning. Previous studies have demonstrated that the self-attention mechanism (SA) is an effective approach for designing segmentation networks that can capture long-range pixel dependencies. SA enables the network to model the global dependencies between the input features, resulting in improved segmentation outcomes. However, the high density of attentional feature maps used in this mechanism causes exponential increases in computational complexity. Additionally, it introduces redundant information that negatively impacts the feature representation. Inspired by traditional threshold segmentation algorithms, we propose a novel threshold attention mechanism (TAM). This mechanism significantly reduces computational effort while also better modeling the correlation between different regions of the feature map. Based on TAM, we present a threshold attention network (TANet) for semantic segmentation. TANet consists of an attentional feature enhancement module (AFEM) for global feature enhancement of shallow features and a threshold attention pyramid pooling module (TAPP) for acquiring feature information at different scales for deep features. We have conducted extensive experiments on the ISPRS Vaihingen and Potsdam datasets. The results demonstrate the validity and superiority of our proposed TANet compared to the most state-of-the-art models. </p>
<blockquote>
<p>é¥æ„Ÿå›¾åƒçš„è¯­ä¹‰åˆ†å‰²å¯¹äºå„ç§åº”ç”¨è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬æ¤è¢«ç›‘æµ‹ã€ç¾å®³ç®¡ç†å’ŒåŸå¸‚è§„åˆ’ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSAï¼‰æ˜¯è®¾è®¡åˆ†å‰²ç½‘ç»œçš„æœ‰æ•ˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæ•è·è¿œç¨‹åƒç´ ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶ä½¿ç½‘ç»œèƒ½å¤Ÿå¯¹è¾“å…¥ç‰¹å¾ä¹‹é—´çš„å…¨å±€ä¾èµ–å…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæé«˜åˆ†å‰²æ•ˆæœã€‚ç„¶è€Œï¼Œè¯¥æœºåˆ¶ä¸­ä½¿ç”¨çš„æ³¨æ„åŠ›ç‰¹å¾å›¾çš„é«˜å¯†åº¦å¯¼è‡´è®¡ç®—å¤æ‚åº¦å‘ˆæŒ‡æ•°å¢é•¿ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¼•å…¥äº†å†—ä½™ä¿¡æ¯ï¼Œå¯¹ç‰¹å¾è¡¨ç¤ºäº§ç”Ÿè´Ÿé¢å½±å“ã€‚å—ä¼ ç»Ÿé˜ˆå€¼åˆ†å‰²ç®—æ³•çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹é˜ˆå€¼æ³¨æ„åŠ›æœºåˆ¶ï¼ˆTAMï¼‰ã€‚è¯¥æœºåˆ¶åœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œæ›´å¥½åœ°å¯¹ç‰¹å¾å›¾ä¸­ä¸åŒåŒºåŸŸçš„å…³è”æ€§è¿›è¡Œå»ºæ¨¡ã€‚åŸºäºTAMï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºè¯­ä¹‰åˆ†å‰²çš„é˜ˆå€¼æ³¨æ„åŠ›ç½‘ç»œï¼ˆTANetï¼‰ã€‚TANetåŒ…æ‹¬ä¸€ä¸ªæ³¨æ„åŠ›ç‰¹å¾å¢å¼ºæ¨¡å—ï¼ˆAFEMï¼‰ï¼Œç”¨äºå¢å¼ºæµ…å±‚ç‰¹å¾çš„å…¨å±€ç‰¹å¾ï¼Œä»¥åŠä¸€ä¸ªé˜ˆå€¼æ³¨æ„åŠ›é‡‘å­—å¡”æ± æ¨¡å—ï¼ˆTAPPï¼‰ï¼Œç”¨äºè·å–ä¸åŒå°ºåº¦çš„ç‰¹å¾ä¿¡æ¯ä»¥ä¾›æ·±åº¦ç‰¹å¾ä½¿ç”¨ã€‚æˆ‘ä»¬åœ¨ISPRS Vaihingenå’ŒPotsdamæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œä¸æˆ‘ä»¬æå‡ºçš„æœ€æ–°æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬æ‰€æå‡ºçš„TANetæ˜¯æœ‰æ•ˆå’Œä¼˜è¶Šçš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07984v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬ä»‹ç»äº†é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„é‡è¦æ€§åŠå…¶åœ¨å„ç§åº”ç”¨ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬æ¤è¢«ç›‘æµ‹ã€ç¾å®³ç®¡ç†å’ŒåŸå¸‚è§„åˆ’ã€‚æ–‡ç« æŒ‡å‡ºï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSAï¼‰åœ¨è®¾è®¡åˆ†å‰²ç½‘ç»œæ—¶èƒ½æœ‰æ•ˆæ•æ‰é•¿è·ç¦»åƒç´ ä¾èµ–å…³ç³»ï¼Œæé«˜åˆ†å‰²æ•ˆæœã€‚ç„¶è€Œï¼ŒSAçš„é«˜å¯†åº¦æ³¨æ„åŠ›ç‰¹å¾æ˜ å°„å¯¼è‡´äº†è®¡ç®—å¤æ‚æ€§çš„æŒ‡æ•°å¢é•¿ï¼Œå¹¶å¼•å…¥äº†å½±å“ç‰¹å¾è¡¨ç¤ºçš„å†—ä½™ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹é˜ˆå€¼æ³¨æ„åŠ›æœºåˆ¶ï¼ˆTAMï¼‰ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œæ›´å¥½åœ°å»ºæ¨¡äº†ç‰¹å¾æ˜ å°„ä¸åŒåŒºåŸŸä¹‹é—´çš„ç›¸å…³æ€§ã€‚åŸºäºTAMï¼Œæœ¬æ–‡æå‡ºäº†ç”¨äºè¯­ä¹‰åˆ†å‰²çš„é˜ˆå€¼æ³¨æ„åŠ›ç½‘ç»œï¼ˆTANetï¼‰ã€‚TANetåŒ…æ‹¬æ³¨æ„åŠ›ç‰¹å¾å¢å¼ºæ¨¡å—ï¼ˆAFEMï¼‰ç”¨äºå¢å¼ºæµ…å±‚ç‰¹å¾çš„å…¨å±€ç‰¹å¾ï¼Œä»¥åŠé˜ˆå€¼æ³¨æ„åŠ›é‡‘å­—å¡”æ± æ¨¡å—ï¼ˆTAPPï¼‰ç”¨äºè·å–ä¸åŒå°ºåº¦çš„æ·±å±‚ç‰¹å¾ä¿¡æ¯ã€‚åœ¨ISPRS Vaihingenå’ŒPotsdamæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„TANetæ¨¡å‹ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”å…·æœ‰æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²åœ¨æ¤è¢«ç›‘æµ‹ã€ç¾å®³ç®¡ç†å’ŒåŸå¸‚è§„åˆ’ç­‰å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSAï¼‰èƒ½æ•æ‰é•¿è·ç¦»åƒç´ ä¾èµ–å…³ç³»ï¼Œæé«˜åˆ†å‰²æ•ˆæœï¼Œä½†è®¡ç®—å¤æ‚åº¦é«˜ï¼Œå­˜åœ¨å†—ä½™ä¿¡æ¯ã€‚</li>
<li>æå‡ºçš„æ–°å‹é˜ˆå€¼æ³¨æ„åŠ›æœºåˆ¶ï¼ˆTAMï¼‰èƒ½æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼Œæ›´æœ‰æ•ˆåœ°å»ºæ¨¡ç‰¹å¾æ˜ å°„ä¸åŒåŒºåŸŸé—´çš„ç›¸å…³æ€§ã€‚</li>
<li>åŸºäºTAMçš„é˜ˆå€¼æ³¨æ„åŠ›ç½‘ç»œï¼ˆTANetï¼‰ç”±æ³¨æ„åŠ›ç‰¹å¾å¢å¼ºæ¨¡å—ï¼ˆAFEMï¼‰å’Œé˜ˆå€¼æ³¨æ„åŠ›é‡‘å­—å¡”æ± æ¨¡å—ï¼ˆTAPPï¼‰ç»„æˆã€‚</li>
<li>AFEMç”¨äºå¢å¼ºæµ…å±‚ç‰¹å¾çš„å…¨å±€ç‰¹å¾ã€‚</li>
<li>TAPPç”¨äºè·å–ä¸åŒå°ºåº¦çš„æ·±å±‚ç‰¹å¾ä¿¡æ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07984">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-271ab322defd97b608eb466f37198bca.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_æ£€æµ‹_åˆ†å‰²_è·Ÿè¸ª/2501.07984v1/page_1_0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb2f27ddf02bb3e178ba0d468f0503eb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0b84b5941b8edaee80c59c23dfcf8951.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-541ec1ac1c9dbc770ed919671be2ab61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-293a800f8a629d46db49754c446b79a4.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="LarvSeg-Exploring-Image-Classification-Data-For-Large-Vocabulary-Semantic-Segmentation-via-Category-wise-Attentive-Classifier"><a href="#LarvSeg-Exploring-Image-Classification-Data-For-Large-Vocabulary-Semantic-Segmentation-via-Category-wise-Attentive-Classifier" class="headerlink" title="LarvSeg: Exploring Image Classification Data For Large Vocabulary   Semantic Segmentation via Category-wise Attentive Classifier"></a>LarvSeg: Exploring Image Classification Data For Large Vocabulary   Semantic Segmentation via Category-wise Attentive Classifier</h2><p><strong>Authors:Haojun Yu, Di Dai, Ziwei Zhao, Di He, Han Hu, Liwei Wang</strong></p>
<p>Scaling up the vocabulary of semantic segmentation models is extremely challenging because annotating large-scale mask labels is labour-intensive and time-consuming. Recently, language-guided segmentation models have been proposed to address this challenge. However, their performance drops significantly when applied to out-of-distribution categories. In this paper, we propose a new large vocabulary semantic segmentation framework, called LarvSeg. Different from previous works, LarvSeg leverages image classification data to scale the vocabulary of semantic segmentation models as large-vocabulary classification datasets usually contain balanced categories and are much easier to obtain. However, for classification tasks, the category is image-level, while for segmentation we need to predict the label at pixel level. To address this issue, we first propose a general baseline framework to incorporate image-level supervision into the training process of a pixel-level segmentation model, making the trained network perform semantic segmentation on newly introduced categories in the classification data. We then observe that a model trained on segmentation data can group pixel features of categories beyond the training vocabulary. Inspired by this finding, we design a category-wise attentive classifier to apply supervision to the precise regions of corresponding categories to improve the model performance. Extensive experiments demonstrate that LarvSeg significantly improves the large vocabulary semantic segmentation performance, especially in the categories without mask labels. For the first time, we provide a 21K-category semantic segmentation model with the help of ImageNet21K. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HaojunYu1998/large_voc_seg">https://github.com/HaojunYu1998/large_voc_seg</a>. </p>
<blockquote>
<p>æ‰©å……è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„è¯æ±‡é‡æå…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå¤§è§„æ¨¡æ©è†œæ ‡ç­¾çš„æ ‡æ³¨å·¥ä½œç¹é‡ä¸”è€—æ—¶ã€‚æœ€è¿‘ï¼Œè¯­è¨€å¼•å¯¼åˆ†å‰²æ¨¡å‹è¢«æå‡ºæ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œå½“åº”ç”¨åˆ°åˆ†å¸ƒå¤–çš„ç±»åˆ«æ—¶ï¼Œå®ƒä»¬çš„æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¤§è¯æ±‡é‡è¯­ä¹‰åˆ†å‰²æ¡†æ¶ï¼Œç§°ä¸ºLarvSegã€‚ä¸åŒäºä»¥å‰çš„å·¥ä½œï¼ŒLarvSegåˆ©ç”¨å›¾åƒåˆ†ç±»æ•°æ®æ¥æ‰©å±•è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„è¯æ±‡é‡ï¼Œå› ä¸ºå¤§è¯æ±‡é‡åˆ†ç±»æ•°æ®é›†é€šå¸¸åŒ…å«å¹³è¡¡ç±»åˆ«ä¸”æ›´å®¹æ˜“è·å–ã€‚ç„¶è€Œï¼Œå¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œç±»åˆ«æ˜¯å›¾åƒçº§åˆ«çš„ï¼Œè€Œå¯¹äºåˆ†å‰²ï¼Œæˆ‘ä»¬éœ€è¦åœ¨åƒç´ çº§åˆ«é¢„æµ‹æ ‡ç­¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºä¸€ä¸ªé€šç”¨çš„åŸºçº¿æ¡†æ¶ï¼Œå°†å›¾åƒçº§åˆ«çš„ç›‘ç£çº³å…¥åƒç´ çº§åˆ«çš„åˆ†å‰²æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿è®­ç»ƒå¥½çš„ç½‘ç»œåœ¨æ–°å¼•å…¥çš„ç±»åˆ«ä¸Šè¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€‚ç„¶åæˆ‘ä»¬å‘ç°ä¸€ä¸ªè®­ç»ƒåœ¨åˆ†å‰²æ•°æ®ä¸Šçš„æ¨¡å‹å¯ä»¥æ±‡é›†è¶…å‡ºè®­ç»ƒè¯æ±‡é‡çš„ç±»åˆ«åƒç´ ç‰¹å¾ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç±»åˆ«ç‰¹å®šçš„æ³¨æ„åŠ›åˆ†ç±»å™¨ï¼Œå¯¹ç›¸åº”ç±»åˆ«çš„ç²¾ç¡®åŒºåŸŸæ–½åŠ ç›‘ç£ï¼Œä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLarvSegæ˜¾è‘—æé«˜äº†å¤§è¯æ±‡é‡è¯­ä¹‰åˆ†å‰²çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ²¡æœ‰æ©è†œæ ‡ç­¾çš„ç±»åˆ«ä¸­ã€‚æˆ‘ä»¬é¦–æ¬¡å€ŸåŠ©ImageNet21Kæä¾›äº†ä¸€ä¸ªåŒ…å«21Kç±»åˆ«çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HaojunYu1998/large_voc_seg">https://github.com/HaojunYu1998/large_voc_seg</a> è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06862v1">PDF</a> PRCV 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¤§è§„æ¨¡è¯æ±‡è¯­ä¹‰åˆ†å‰²æ¡†æ¶â€”â€”LarvSegã€‚å®ƒé€šè¿‡ç»“åˆå›¾åƒåˆ†ç±»æ•°æ®æ¥æ‰©å±•è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„è¯æ±‡é‡ï¼Œè§£å†³äº†æ ‡æ³¨å¤§è§„æ¨¡æ©è†œæ ‡ç­¾çš„åŠ³åŠ¨å¯†é›†å’Œæ—¶é—´æ¶ˆè€—é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ä½¿ç”¨å›¾åƒçº§åˆ«çš„ç›‘ç£ä¿¡æ¯è®­ç»ƒåƒç´ çº§åˆ«çš„åˆ†å‰²æ¨¡å‹ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨åˆ†ç±»æ•°æ®ä¸­å¯¹æ–°å¼•å…¥çš„ç±»åˆ«è¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†ä¸€ä¸ªç±»åˆ«æ„ŸçŸ¥çš„åˆ†ç±»å™¨ï¼Œä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒLarvSegåœ¨å¤§é‡è¯æ±‡çš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šæ˜¾è‘—æé«˜æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ²¡æœ‰æ©è†œæ ‡ç­¾çš„ç±»åˆ«ä¸Šã€‚è¯¥æ¨¡å‹é¦–æ¬¡æä¾›äº†ä½¿ç”¨ImageNet21Kæ•°æ®çš„21Kç±»åˆ«è¯­ä¹‰åˆ†å‰²æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LarvSegåˆ©ç”¨å›¾åƒåˆ†ç±»æ•°æ®æ¥æ‰©å±•è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„è¯æ±‡é‡ï¼Œè§£å†³å¤§è§„æ¨¡æ©è†œæ ‡ç­¾æ ‡æ³¨çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç»“åˆå›¾åƒçº§åˆ«ç›‘ç£ä¿¡æ¯è®­ç»ƒåƒç´ çº§åˆ«åˆ†å‰²æ¨¡å‹çš„é€šç”¨åŸºçº¿æ¡†æ¶ã€‚</li>
<li>é€šè¿‡å®éªŒå‘ç°ï¼Œåœ¨åˆ†å‰²æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹èƒ½å¤Ÿåˆ†ç»„è¶…å‡ºè®­ç»ƒè¯æ±‡é‡çš„ç±»åˆ«åƒç´ ç‰¹å¾ã€‚</li>
<li>å—åˆ°äº†è¿™ä¸€å‘ç°çš„å¯å‘ï¼Œè®¾è®¡äº†ä¸€ä¸ªç±»åˆ«æ„ŸçŸ¥çš„åˆ†ç±»å™¨ï¼Œå¯¹ç›¸åº”ç±»åˆ«çš„ç²¾ç¡®åŒºåŸŸè¿›è¡Œç›‘ç®¡ï¼Œä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>LarvSegåœ¨å¤§é‡è¯æ±‡çš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨æ²¡æœ‰æ©è†œæ ‡ç­¾çš„ç±»åˆ«ä¸Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06862">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7d4b96eefb38b8c96823fed42bb4c00f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b4194e2582f4a377291f66e565b33d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e47c49573cad0e8a12bdacebe2ce1e3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffbe9bba3b8c4b28d0a986d5d5aef2b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c88cf11aad2168cc9efe3394401eeb2a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CoreNet-Conflict-Resolution-Network-for-Point-Pixel-Misalignment-and-Sub-Task-Suppression-of-3D-LiDAR-Camera-Object-Detection"><a href="#CoreNet-Conflict-Resolution-Network-for-Point-Pixel-Misalignment-and-Sub-Task-Suppression-of-3D-LiDAR-Camera-Object-Detection" class="headerlink" title="CoreNet: Conflict Resolution Network for Point-Pixel Misalignment and   Sub-Task Suppression of 3D LiDAR-Camera Object Detection"></a>CoreNet: Conflict Resolution Network for Point-Pixel Misalignment and   Sub-Task Suppression of 3D LiDAR-Camera Object Detection</h2><p><strong>Authors:Yiheng Li, Yang Yang, Zhen Lei</strong></p>
<p>Fusing multi-modality inputs from different sensors is an effective way to improve the performance of 3D object detection. However, current methods overlook two important conflicts: point-pixel misalignment and sub-task suppression. The former means a pixel feature from the opaque object is projected to multiple point features of the same ray in the world space, and the latter means the classification prediction and bounding box regression may cause mutual suppression. In this paper, we propose a novel method named Conflict Resolution Network (CoreNet) to address the aforementioned issues. Specifically, we first propose a dual-stream transformation module to tackle point-pixel misalignment. It consists of ray-based and point-based 2D-to-BEV transformations. Both of them achieve approximately unique mapping from the image space to the world space. Moreover, we introduce a task-specific predictor to tackle sub-task suppression. It uses the dual-branch structure which adopts class-specific query and Bbox-specific query to corresponding sub-tasks. Each task-specific query is constructed of task-specific feature and general feature, which allows the heads to adaptively select information of interest based on different sub-tasks. Experiments on the large-scale nuScenes dataset demonstrate the superiority of our proposed CoreNet, by achieving 75.6% NDS and 73.3% mAP on the nuScenes test set without test-time augmentation and model ensemble techniques. The ample ablation study also demonstrates the effectiveness of each component. The code is released on <a target="_blank" rel="noopener" href="https://github.com/liyih/CoreNet">https://github.com/liyih/CoreNet</a>. </p>
<blockquote>
<p>èåˆä¸åŒä¼ æ„Ÿå™¨çš„å¤šæ¨¡æ€è¾“å…¥æ˜¯æé«˜3Dç›®æ ‡æ£€æµ‹æ€§èƒ½çš„æœ‰æ•ˆé€”å¾„ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•å¿½ç•¥äº†ä¸¤ä¸ªé‡è¦çš„å†²çªï¼šç‚¹åƒç´ ä¸å¯¹é½å’Œå­ä»»åŠ¡æŠ‘åˆ¶ã€‚å‰è€…æ„å‘³ç€æ¥è‡ªä¸é€æ˜å¯¹è±¡çš„åƒç´ ç‰¹å¾è¢«æŠ•å°„åˆ°ä¸–ç•Œç©ºé—´ä¸­çš„åŒä¸€å°„çº¿çš„å¤šä¸ªç‚¹ç‰¹å¾ä¸Šï¼Œåè€…åˆ™æ„å‘³ç€åˆ†ç±»é¢„æµ‹å’Œè¾¹ç•Œæ¡†å›å½’å¯èƒ½ä¼šç›¸äº’æŠ‘åˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºConflict Resolution Networkï¼ˆCoreNetï¼‰çš„æ–°æ–¹æ³•æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ä¸ªåŒæµè½¬æ¢æ¨¡å—æ¥è§£å†³ç‚¹åƒç´ ä¸å¯¹é½é—®é¢˜ã€‚å®ƒåŒ…æ‹¬åŸºäºå°„çº¿å’ŒåŸºäºç‚¹çš„2D-to-BEVè½¬æ¢ã€‚å®ƒä»¬éƒ½å®ç°äº†ä»å›¾åƒç©ºé—´åˆ°ä¸–ç•Œç©ºé—´çš„è¿‘ä¼¼å”¯ä¸€æ˜ å°„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé’ˆå¯¹å­ä»»åŠ¡æŠ‘åˆ¶çš„ç‰¹å®šä»»åŠ¡é¢„æµ‹å™¨ã€‚å®ƒé‡‡ç”¨åŒåˆ†æ”¯ç»“æ„ï¼Œé‡‡ç”¨ç±»ç‰¹å®šæŸ¥è¯¢å’ŒBboxç‰¹å®šæŸ¥è¯¢æ¥å¯¹åº”å­ä»»åŠ¡ã€‚æ¯ä¸ªç‰¹å®šä»»åŠ¡æŸ¥è¯¢ç”±ç‰¹å®šä»»åŠ¡ç‰¹å¾å’Œä¸€èˆ¬ç‰¹å¾æ„æˆï¼Œè¿™ä½¿å¾—å¤´éƒ¨èƒ½å¤Ÿæ ¹æ®ä¸åŒçš„å­ä»»åŠ¡è‡ªé€‚åº”åœ°é€‰æ‹©æ„Ÿå…´è¶£çš„ä¿¡æ¯ã€‚åœ¨å¤§å‹nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„CoreNetå…·æœ‰ä¼˜è¶Šæ€§ï¼Œåœ¨nuScenesæµ‹è¯•é›†ä¸Šå®ç°äº†75.6%çš„NDSå’Œ73.3%çš„mAPï¼Œæ— éœ€æµ‹è¯•æ—¶é—´å¢å¼ºå’Œæ¨¡å‹é›†æˆæŠ€æœ¯ã€‚ä¸°å¯Œçš„æ¶ˆèç ”ç©¶ä¹Ÿè¯æ˜äº†æ¯ä¸ªç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/liyih/CoreNet%E3%80%82">https://github.com/liyih/CoreNetã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06550v1">PDF</a> Accepted by Information Fusion 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºConflict Resolution Network (CoreNet)çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†å¤šæ¨¡æ€è¾“å…¥èåˆåœ¨3Dç›®æ ‡æ£€æµ‹ä¸­çš„ä¸¤å¤§å†²çªé—®é¢˜ï¼šç‚¹åƒç´ é”™ä½å’Œå­ä»»åŠ¡æŠ‘åˆ¶ã€‚é€šè¿‡å¼•å…¥åŒæµè½¬æ¢æ¨¡å—å’Œé’ˆå¯¹ä»»åŠ¡çš„é¢„æµ‹å™¨ï¼Œå®ç°äº†å¯¹è¿™ä¸¤ä¸ªé—®é¢˜çš„æœ‰æ•ˆå¤„ç†ï¼Œæé«˜äº†3Dç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†CoreNetçš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€è¾“å…¥èåˆæ˜¯æé«˜3Dç›®æ ‡æ£€æµ‹æ€§èƒ½çš„æœ‰æ•ˆæ–¹å¼ã€‚</li>
<li>å½“å‰æ–¹æ³•å¿½ç•¥äº†ç‚¹åƒç´ é”™ä½å’Œå­ä»»åŠ¡æŠ‘åˆ¶ä¸¤å¤§å†²çªã€‚</li>
<li>CoreNeté€šè¿‡å¼•å…¥åŒæµè½¬æ¢æ¨¡å—è§£å†³ç‚¹åƒç´ é”™ä½é—®é¢˜ã€‚</li>
<li>CoreNeté‡‡ç”¨ä»»åŠ¡ç‰¹å®šé¢„æµ‹å™¨è§£å†³å­ä»»åŠ¡æŠ‘åˆ¶é—®é¢˜ã€‚</li>
<li>åŒæµè½¬æ¢æ¨¡å—åŒ…æ‹¬åŸºäºå°„çº¿å’Œç‚¹åŸºçš„2D-to-BEVè½¬æ¢ï¼Œå®ç°äº†ä»å›¾åƒç©ºé—´åˆ°ä¸–ç•Œç©ºé—´çš„è¿‘ä¼¼å”¯ä¸€æ˜ å°„ã€‚</li>
<li>CoreNetåœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œè¾¾åˆ°äº†75.6%çš„NDSå’Œ73.3%çš„mAPã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06550">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-456a7ac80290e3cd11eee045c74e804b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8a8bb5fed2e6a32b2d2998fce27bef9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Feedback-driven-object-detection-and-iterative-model-improvement"><a href="#Feedback-driven-object-detection-and-iterative-model-improvement" class="headerlink" title="Feedback-driven object detection and iterative model improvement"></a>Feedback-driven object detection and iterative model improvement</h2><p><strong>Authors:SÃ¶nke Tenckhoff, Mario Koddenbrock, Erik Rodner</strong></p>
<p>Automated object detection has become increasingly valuable across diverse applications, yet efficient, high-quality annotation remains a persistent challenge. In this paper, we present the development and evaluation of a platform designed to interactively improve object detection models. The platform allows uploading and annotating images as well as fine-tuning object detection models. Users can then manually review and refine annotations, further creating improved snapshots that are used for automatic object detection on subsequent image uploads - a process we refer to as semi-automatic annotation resulting in a significant gain in annotation efficiency.   Whereas iterative refinement of model results to speed up annotation has become common practice, we are the first to quantitatively evaluate its benefits with respect to time, effort, and interaction savings. Our experimental results show clear evidence for a significant time reduction of up to 53% for semi-automatic compared to manual annotation. Importantly, these efficiency gains did not compromise annotation quality, while matching or occasionally even exceeding the accuracy of manual annotations. These findings demonstrate the potential of our lightweight annotation platform for creating high-quality object detection datasets and provide best practices to guide future development of annotation platforms.   The platform is open-source, with the frontend and backend repositories available on GitHub (<a target="_blank" rel="noopener" href="https://github.com/ml-lab-htw/iterative-annotate">https://github.com/ml-lab-htw/iterative-annotate</a>). To support the understanding of our labeling process, we have created an explanatory video demonstrating the methodology using microscopy images of E. coli bacteria as an example. The video is available on YouTube (<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=CM9uhE8NN5E">https://www.youtube.com/watch?v=CM9uhE8NN5E</a>). </p>
<blockquote>
<p>è‡ªåŠ¨ç›®æ ‡æ£€æµ‹åœ¨ä¸åŒåº”ç”¨ä¸­çš„ä»·å€¼æ—¥ç›Šå‡¸æ˜¾ï¼Œç„¶è€Œé«˜æ•ˆã€é«˜è´¨é‡çš„æ ‡æ³¨ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªäº¤äº’å¼æ”¹è¿›ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„å¹³å°çš„å¼€å‘è¯„ä¼°ã€‚è¯¥å¹³å°å…è®¸ä¸Šä¼ å’Œæ ‡æ³¨å›¾åƒï¼Œä»¥åŠå¾®è°ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚ç”¨æˆ·éšåå¯ä»¥æ‰‹åŠ¨å®¡æŸ¥å’Œä¿®æ”¹æ ‡æ³¨ï¼Œè¿›ä¸€æ­¥åˆ›å»ºæ”¹è¿›çš„å¿«ç…§ï¼Œç”¨äºåç»­å›¾åƒä¸Šä¼ çš„è‡ªåŠ¨ç›®æ ‡æ£€æµ‹â€”â€”æˆ‘ä»¬ç§°ä¹‹ä¸ºåŠè‡ªåŠ¨æ ‡æ³¨ï¼Œè¿™å¤§å¤§æé«˜äº†æ ‡æ³¨æ•ˆç‡ã€‚è™½ç„¶é€šè¿‡è¿­ä»£ä¼˜åŒ–æ¨¡å‹ç»“æœæ¥åŠ é€Ÿæ ‡æ³¨å·²æˆä¸ºä¸€ç§å¸¸è§åšæ³•ï¼Œä½†æˆ‘ä»¬æ˜¯é¦–æ¬¡å°±æ—¶é—´ã€ç²¾åŠ›å’Œäº¤äº’èŠ‚çœç­‰æ–¹é¢å®šé‡è¯„ä¼°å…¶æ•ˆç›Šã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ‰‹åŠ¨æ ‡æ³¨ç›¸æ¯”ï¼ŒåŠè‡ªåŠ¨æ ‡æ³¨çš„æ—¶é—´å‡å°‘äº†é«˜è¾¾53%ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™äº›æ•ˆç‡çš„æå‡å¹¶æ²¡æœ‰æŸå®³æ ‡æ³¨è´¨é‡ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¿˜è¶…è¿‡äº†æ‰‹åŠ¨æ ‡æ³¨çš„å‡†ç¡®åº¦ã€‚è¿™äº›å‘ç°è¯æ˜äº†æˆ‘ä»¬è½»é‡çº§æ ‡æ³¨å¹³å°çš„æ½œåŠ›ï¼Œå¯ç”¨äºåˆ›å»ºé«˜è´¨é‡çš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼Œå¹¶ä¸ºæœªæ¥æ ‡æ³¨å¹³å°çš„å‘å±•æä¾›äº†æœ€ä½³å®è·µæŒ‡å¯¼ã€‚å¹³å°æ˜¯å¼€æºçš„ï¼Œå‰ç«¯å’Œåç«¯ä»“åº“å¯åœ¨GitHubä¸Šæ‰¾åˆ°ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/ml-lab-htw/iterative-annotate%EF%BC%89%E3%80%82%E4%B8%BA%E4%BA%86%E6%94%AF%E6%8C%81%E5%AF%B9%E6%A0%87%E6%B3%A8%E8%BF%87%E7%A8%8B%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%8C%E6%88%91%E4%BB%AC%E5%88%B6%E4%BD%9C%E4%BA%86%E4%B8%80%E4%B8%AA%E8%A7%A3%E9%87%8A%E6%80%A7%E8%A7%86%E9%A2%91%EF%BC%8C%E4%BD%BF%E7%94%A8%E5%A4%A7%E8%82%A0%E6%9D%86%E8%8F%8C%E6%98%BE%E5%BE%AE%E9%95%9C%E5%9B%BE%E5%83%8F%E4%BD%9C%E4%B8%BA%E7%A4%BA%E4%BE%8B%E6%9D%A5%E5%B1%95%E7%A4%BA%E6%96%B9%E6%B3%95%E3%80%82%E8%A7%86%E9%A2%91%E5%8F%AF%E5%9C%A8YouTube%E4%B8%8A%E8%A7%82%E7%9C%8B%EF%BC%88https://www.youtube.com/watch?v=CM9uhE8NN5E%EF%BC%89%E3%80%82">https://github.com/ml-lab-htw/iterative-annotateï¼‰ã€‚ä¸ºäº†æ”¯æŒå¯¹æ ‡æ³¨è¿‡ç¨‹çš„ç†è§£ï¼Œæˆ‘ä»¬åˆ¶ä½œäº†ä¸€ä¸ªè§£é‡Šæ€§è§†é¢‘ï¼Œä½¿ç”¨å¤§è‚ æ†èŒæ˜¾å¾®é•œå›¾åƒä½œä¸ºç¤ºä¾‹æ¥å±•ç¤ºæ–¹æ³•ã€‚è§†é¢‘å¯åœ¨YouTubeä¸Šè§‚çœ‹ï¼ˆhttps://www.youtube.com/watch?v=CM9uhE8NN5Eï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.19835v2">PDF</a> AI4EA24</p>
<p><strong>Summary</strong>ï¼šæœ¬ç ”ç©¶å¼€å‘å¹¶è¯„ä¼°äº†ä¸€ä¸ªäº¤äº’å¼å¹³å°ï¼Œç”¨äºæé«˜ç‰©ä½“æ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚è¯¥å¹³å°æ”¯æŒå›¾åƒä¸Šä¼ ã€æ ‡æ³¨å’Œæ¨¡å‹å¾®è°ƒã€‚ç”¨æˆ·å¯æ‰‹åŠ¨å®¡æŸ¥å’Œä¿®æ­£æ ‡æ³¨ï¼Œåˆ›å»ºæ”¹è¿›åçš„å¿«ç…§ç”¨äºåç»­è‡ªåŠ¨ç‰©ä½“æ£€æµ‹ã€‚é€šè¿‡åŠè‡ªåŠ¨æ ‡æ³¨ï¼Œæ˜¾è‘—æé«˜äº†æ ‡æ³¨æ•ˆç‡ï¼Œå‡å°‘äº†æ—¶é—´å’Œäº¤äº’æˆæœ¬ï¼ŒåŒæ—¶ä¿è¯äº†æ ‡æ³¨è´¨é‡ã€‚å¹³å°å¼€æºï¼Œå¹¶æä¾›ç›¸å…³è§†é¢‘æ•™ç¨‹æ”¯æŒç†è§£æ ‡æ³¨è¿‡ç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è¯¥å¹³å°æ—¨åœ¨æé«˜ç‰©ä½“æ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œæ”¯æŒå›¾åƒä¸Šä¼ ã€æ ‡æ³¨å’Œæ¨¡å‹å¾®è°ƒã€‚</li>
<li>ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨å®¡æŸ¥å’Œä¿®æ­£æ ‡æ³¨ï¼Œè¿›ä¸€æ­¥æ”¹è¿›è‡ªåŠ¨ç‰©ä½“æ£€æµ‹æ•ˆæœã€‚</li>
<li>å¹³å°é€šè¿‡åŠè‡ªåŠ¨æ ‡æ³¨æ˜¾è‘—æé«˜äº†æ ‡æ³¨æ•ˆç‡ï¼Œå‡å°‘äº†æ—¶é—´å’Œäº¤äº’æˆæœ¬ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠè‡ªåŠ¨æ ‡æ³¨ä¸ä¼ ç»Ÿæ‰‹åŠ¨æ ‡æ³¨ç›¸æ¯”ï¼Œæ—¶é—´å¯å‡å°‘é«˜è¾¾53%ã€‚</li>
<li>å¹³å°åœ¨ä¿è¯æ ‡æ³¨è´¨é‡çš„åŒæ—¶å®ç°äº†æ•ˆç‡çš„æå‡ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¶…è¿‡äº†æ‰‹åŠ¨æ ‡æ³¨çš„å‡†ç¡®åº¦ã€‚</li>
<li>å¹³å°å¼€æºï¼Œå¹¶æä¾›GitHubå’ŒYouTubeä¸Šçš„ç›¸å…³èµ„æºä»¥ä¾›å­¦ä¹ å’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.19835">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9c3898778d74101f9ed5a2eba7705e43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06d40879c9a9ceb8bf640acf76ca66c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e99e056e486b130ed5c012ae102fbf7.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Rethinking-Decoders-for-Transformer-based-Semantic-Segmentation-A-Compression-Perspective"><a href="#Rethinking-Decoders-for-Transformer-based-Semantic-Segmentation-A-Compression-Perspective" class="headerlink" title="Rethinking Decoders for Transformer-based Semantic Segmentation: A   Compression Perspective"></a>Rethinking Decoders for Transformer-based Semantic Segmentation: A   Compression Perspective</h2><p><strong>Authors:Qishuai Wen, Chun-Guang Li</strong></p>
<p>State-of-the-art methods for Transformer-based semantic segmentation typically adopt Transformer decoders that are used to extract additional embeddings from image embeddings via cross-attention, refine either or both types of embeddings via self-attention, and project image embeddings onto the additional embeddings via dot-product. Despite their remarkable success, these empirical designs still lack theoretical justifications or interpretations, thus hindering potentially principled improvements. In this paper, we argue that there are fundamental connections between semantic segmentation and compression, especially between the Transformer decoders and Principal Component Analysis (PCA). From such a perspective, we derive a white-box, fully attentional DEcoder for PrIncipled semantiC segemenTation (DEPICT), with the interpretations as follows: 1) the self-attention operator refines image embeddings to construct an ideal principal subspace that aligns with the supervision and retains most information; 2) the cross-attention operator seeks to find a low-rank approximation of the refined image embeddings, which is expected to be a set of orthonormal bases of the principal subspace and corresponds to the predefined classes; 3) the dot-product operation yields compact representation for image embeddings as segmentation masks. Experiments conducted on dataset ADE20K find that DEPICT consistently outperforms its black-box counterpart, Segmenter, and it is light weight and more robust. </p>
<blockquote>
<p>åŸºäºTransformerçš„è¯­ä¹‰åˆ†å‰²çš„å…ˆè¿›æ–¹æ³•é€šå¸¸é‡‡ç”¨Transformerè§£ç å™¨ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›ä»å›¾åƒåµŒå…¥ä¸­æå–é¢å¤–çš„åµŒå…¥ï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›å¯¹ä»»ä¸€æˆ–ä¸¤ç§åµŒå…¥è¿›è¡Œç²¾ç‚¼ï¼Œå¹¶é€šè¿‡ç‚¹ç§¯å°†å›¾åƒåµŒå…¥æŠ•å½±åˆ°é¢å¤–çš„åµŒå…¥ä¸Šã€‚å°½ç®¡è¿™äº›æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†è¿™äº›ç»éªŒè®¾è®¡ä»ç„¶ç¼ºä¹ç†è®ºè¯æ˜æˆ–è§£é‡Šï¼Œä»è€Œé˜»ç¢äº†å¯èƒ½çš„åŸåˆ™æ€§æ”¹è¿›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºè¯­ä¹‰åˆ†å‰²ä¸å‹ç¼©ä¹‹é—´å­˜åœ¨æ ¹æœ¬è”ç³»ï¼Œç‰¹åˆ«æ˜¯Transformerè§£ç å™¨ä¸ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ä¹‹é—´çš„è”ç³»ã€‚ä»è¿™ä¸€è§’åº¦å‡ºå‘ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†ä¸€ä¸ªç™½ç›’ã€å…¨æ³¨æ„åŠ›çš„è§£ç å™¨DEPICTï¼ˆç”¨äºåŸåˆ™æ€§è¯­ä¹‰åˆ†å‰²ï¼‰ï¼Œå…¶è§£é‡Šå¦‚ä¸‹ï¼š1ï¼‰è‡ªæ³¨æ„åŠ›è¿ç®—ç¬¦é€šè¿‡å®Œå–„å›¾åƒåµŒå…¥æ¥æ„å»ºä¸€ä¸ªç†æƒ³çš„ä¸»å­ç©ºé—´ï¼Œè¯¥ç©ºé—´ä¸ç›‘ç£å¯¹é½å¹¶ä¿ç•™æœ€å¤šä¿¡æ¯ï¼›2ï¼‰äº¤å‰æ³¨æ„åŠ›è¿ç®—ç¬¦è¯•å›¾æ‰¾åˆ°ç²¾ç‚¼å›¾åƒåµŒå…¥çš„ä½é˜¶é€¼è¿‘ï¼Œè¿™æœŸæœ›æ˜¯ä¸€ç»„æ­£äº¤åŸºçš„å­é›†ï¼Œå¹¶ä¸é¢„å®šä¹‰çš„ç±»åˆ«ç›¸å¯¹åº”ï¼›3ï¼‰ç‚¹ç§¯æ“ä½œä¸ºå›¾åƒåµŒå…¥ç”Ÿæˆç´§å‡‘çš„è¡¨ç¤ºå½¢å¼ä½œä¸ºåˆ†å‰²æ©è†œã€‚åœ¨ADE20Kæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒå‘ç°ï¼ŒDEPICTæŒç»­ä¼˜äºå…¶é»‘ç›’ç«å“Segmenterï¼Œå¹¶ä¸”å®ƒæ›´åŠ è½»ä¾¿å’Œç¨³å¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03033v3">PDF</a> NeurIPS2024. Code:<a target="_blank" rel="noopener" href="https://github.com/QishuaiWen/DEPICT/">https://github.com/QishuaiWen/DEPICT/</a></p>
<p><strong>Summary</strong>ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹çš„å…¨æ–°ç†è®ºæ¡†æ¶DEPICTï¼Œå®ƒé€šè¿‡è§£é‡Šæ€§çš„è§’åº¦è§£æäº†Transformerè§£ç å™¨çš„å†…éƒ¨æœºåˆ¶ã€‚DEPICTé€šè¿‡è‡ªæˆ‘å…³æ³¨æ“ä½œç²¾ç‚¼å›¾åƒåµŒå…¥ï¼Œæ„å»ºä¸€ä¸ªç†æƒ³çš„ä¸»æˆåˆ†å­ç©ºé—´ï¼Œå¹¶é€šè¿‡äº¤å‰å…³æ³¨æ“ä½œå¯»æ‰¾ç²¾ç‚¼å›¾åƒåµŒå…¥çš„ä½ç§©è¿‘ä¼¼ï¼Œæœ€åé€šè¿‡ç‚¹ç§¯æ“ä½œå¾—åˆ°å›¾åƒåµŒå…¥çš„ç´§å‡‘è¡¨ç¤ºä½œä¸ºåˆ†å‰²æ©ç ã€‚å®éªŒè¯æ˜ï¼ŒDEPICTåœ¨ADE20Kæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºéè§£é‡Šæ€§çš„æ¨¡å‹Segmenterå…·æœ‰æ›´é«˜çš„æ€§èƒ½ã€æ›´è½»é‡çº§å’Œæ›´å¼ºçš„é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹DEPICTï¼Œé€šè¿‡è§£é‡ŠTransformerè§£ç å™¨çš„å†…éƒ¨æœºåˆ¶æ¥æ„å»ºæ¨¡å‹ã€‚</li>
<li>DEPICTé€šè¿‡è‡ªæˆ‘å…³æ³¨æ“ä½œç²¾ç‚¼å›¾åƒåµŒå…¥ï¼Œæ„å»ºä¸€ä¸ªç†æƒ³çš„ä¸»åˆ†å­ç©ºé—´ä»¥å¯¹é½ç›‘ç£ä¿¡æ¯å¹¶ä¿ç•™å¤§éƒ¨åˆ†ä¿¡æ¯ã€‚</li>
<li>DEPICTåˆ©ç”¨äº¤å‰å…³æ³¨æ“ä½œå¯»æ‰¾ç²¾ç‚¼å›¾åƒåµŒå…¥çš„ä½ç§©è¿‘ä¼¼ï¼Œè¯¥ä½ç§©è¿‘ä¼¼å¯¹åº”äºé¢„å®šä¹‰ç±»åˆ«çš„ä¸€ç»„æ­£äº¤åŸºã€‚</li>
<li>ç‚¹ç§¯æ“ä½œç”¨äºäº§ç”Ÿå›¾åƒåµŒå…¥çš„ç´§å‡‘è¡¨ç¤ºå½¢å¼ä½œä¸ºåˆ†å‰²æ©ç ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒDEPICTåœ¨ADE20Kæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰çš„é»‘ç®±æ¨¡å‹Segmenterã€‚</li>
<li>DEPICTæ¨¡å‹å…·æœ‰è½»é‡çº§å’Œé«˜åº¦é²æ£’æ€§çš„ç‰¹ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03033">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6647a0e3cd3fb0bdc6f8a11d4751f2c7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87a9eea614d20a6cec7db6f61c60688e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f66a85e0ca9a3bd7ab98fb8b81dbb560.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f8e7e1bf4a199ecbcd8590a7069f5d11.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Semantic-Prompt-Learning-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Semantic-Prompt-Learning-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation"></a>Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation</h2><p><strong>Authors:Ci-Siang Lin, Chien-Yi Wang, Yu-Chiang Frank Wang, Min-Hung Chen</strong></p>
<p>Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation models using image data with only image-level supervision. Since precise pixel-level annotations are not accessible, existing methods typically focus on producing pseudo masks for training segmentation models by refining CAM-like heatmaps. However, the produced heatmaps may capture only the discriminative image regions of object categories or the associated co-occurring backgrounds. To address the issues, we propose a Semantic Prompt Learning for WSSS (SemPLeS) framework, which learns to effectively prompt the CLIP latent space to enhance the semantic alignment between the segmented regions and the target object categories. More specifically, we propose Contrastive Prompt Learning and Prompt-guided Semantic Refinement to learn the prompts that adequately describe and suppress the co-occurring backgrounds associated with each object category. In this way, SemPLeS can perform better semantic alignment between object regions and class labels, resulting in desired pseudo masks for training segmentation models. The proposed SemPLeS framework achieves competitive performance on standard WSSS benchmarks, PASCAL VOC 2012 and MS COCO 2014, and shows compatibility with other WSSS methods. Code: <a target="_blank" rel="noopener" href="https://github.com/NVlabs/SemPLeS">https://github.com/NVlabs/SemPLeS</a>. </p>
<blockquote>
<p>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰æ—¨åœ¨ä½¿ç”¨ä»…å¸¦æœ‰å›¾åƒçº§ç›‘ç£çš„å›¾åƒæ•°æ®æ¥è®­ç»ƒåˆ†å‰²æ¨¡å‹ã€‚ç”±äºæ— æ³•è·å¾—ç²¾ç¡®çš„åƒç´ çº§æ³¨é‡Šï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡ä¼˜åŒ–CAMï¼ˆç±»æ¿€æ´»æ˜ å°„ï¼‰ç±»çƒ­å›¾æ¥ç”Ÿæˆç”¨äºè®­ç»ƒåˆ†å‰²æ¨¡å‹çš„ä¼ªæ©ç ã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„çƒ­å›¾å¯èƒ½åªæ•è·å¯¹è±¡ç±»åˆ«çš„è¾¨åˆ«æ€§å›¾åƒåŒºåŸŸæˆ–ç›¸å…³çš„å…±å‘ç”ŸèƒŒæ™¯ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„è¯­ä¹‰æç¤ºå­¦ä¹ ï¼ˆSemPLeSï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å­¦ä¹ æœ‰æ•ˆåœ°æç¤ºCLIPæ½œåœ¨ç©ºé—´ï¼Œä»¥å¢å¼ºåˆ†å‰²åŒºåŸŸä¸ç›®æ ‡å¯¹è±¡ç±»åˆ«ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†å¯¹æ¯”æç¤ºå­¦ä¹ å’Œæç¤ºå¼•å¯¼è¯­ä¹‰ç»†åŒ–ï¼Œä»¥å­¦ä¹ è¶³å¤Ÿæè¿°å¹¶æŠ‘åˆ¶ä¸æ¯ä¸ªå¯¹è±¡ç±»åˆ«ç›¸å…³çš„å…±å‘ç”ŸèƒŒæ™¯çš„æç¤ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒSemPLeSå¯ä»¥åœ¨å¯¹è±¡åŒºåŸŸå’Œç±»åˆ«æ ‡ç­¾ä¹‹é—´å®ç°æ›´å¥½çš„è¯­ä¹‰å¯¹é½ï¼Œä»è€Œç”Ÿæˆç”¨äºè®­ç»ƒåˆ†å‰²æ¨¡å‹çš„ç†æƒ³ä¼ªæ©ç ã€‚æ‰€æå‡ºçš„SemPLeSæ¡†æ¶åœ¨æ ‡å‡†WSSSåŸºå‡†æµ‹è¯•ï¼ˆPASCAL VOC 2012å’ŒMS COCO 2014ï¼‰ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶æ˜¾ç¤ºå‡ºä¸å…¶ä»–WSSSæ–¹æ³•çš„å…¼å®¹æ€§ã€‚ä»£ç åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/NVlabs/SemPLeS">https://github.com/NVlabs/SemPLeS</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.11791v4">PDF</a> WACV 2025. Code: <a target="_blank" rel="noopener" href="https://github.com/NVlabs/SemPLeS">https://github.com/NVlabs/SemPLeS</a>. Project page:   <a target="_blank" rel="noopener" href="https://projectdisr.github.io/semples/">https://projectdisr.github.io/semples/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶SemPLeSæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚SemPLeSåˆ©ç”¨CLIPæ½œåœ¨ç©ºé—´ä¸­çš„æç¤ºæ¥å­¦ä¹ æœ‰æ•ˆåœ°æè¿°ç›®æ ‡å¯¹è±¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶æŠ‘åˆ¶ä¸ä¹‹ç›¸å…³çš„èƒŒæ™¯ã€‚é€šè¿‡å¯¹æ¯”æç¤ºå­¦ä¹ å’Œæç¤ºå¼•å¯¼è¯­ä¹‰ç»†åŒ–ï¼ŒSemPLeSèƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®çš„ä¼ªæ©ç æ¥è®­ç»ƒåˆ†å‰²æ¨¡å‹ã€‚è¯¥æ¡†æ¶åœ¨PASCAL VOC 2012å’ŒMS COCO 2014ç­‰æ ‡å‡†WSSSåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰çš„ç›®æ ‡æ˜¯ä½¿ç”¨ä»…å¸¦æœ‰å›¾åƒçº§åˆ«ç›‘ç£çš„å›¾åƒæ•°æ®æ¥è®­ç»ƒåˆ†å‰²æ¨¡å‹ã€‚</li>
<li>ç”±äºç¼ºä¹ç²¾ç¡®çš„åƒç´ çº§åˆ«æ³¨é‡Šï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡ä¼˜åŒ–CAMçƒ­å›¾æ¥ç”Ÿæˆä¼ªæ©ç è¿›è¡Œè®­ç»ƒã€‚</li>
<li>æå‡ºçš„SemPLeSæ¡†æ¶æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•å¯èƒ½åªæ•è·å¯¹è±¡ç±»åˆ«çš„é‰´åˆ«æ€§å›¾åƒåŒºåŸŸæˆ–ç›¸å…³å…±å‘ç”ŸèƒŒæ™¯çš„é—®é¢˜ã€‚</li>
<li>SemPLeSåˆ©ç”¨CLIPæ½œåœ¨ç©ºé—´ä¸­çš„æç¤ºæ¥å­¦ä¹ æœ‰æ•ˆåœ°æè¿°ç›®æ ‡å¯¹è±¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶æŠ‘åˆ¶èƒŒæ™¯ã€‚</li>
<li>é€šè¿‡å¯¹æ¯”æç¤ºå­¦ä¹ å’Œæç¤ºå¼•å¯¼è¯­ä¹‰ç»†åŒ–ï¼ŒSemPLeSèƒ½æ›´å‡†ç¡®åœ°æè¿°å’ŒæŠ‘åˆ¶ä¸æ¯ä¸ªå¯¹è±¡ç±»åˆ«ç›¸å…³çš„å…±å‘ç”ŸèƒŒæ™¯ã€‚</li>
<li>SemPLeSæ¡†æ¶åœ¨æ ‡å‡†WSSSåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.11791">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-60769a1ed37392d1b4a0be9cd5d8f375.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6dc962294b118695a975dd024c8582b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcbbd2228136050f70aece6ab295e87e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eda112a70646e26e626a9e100d78d313.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="On-the-Robustness-of-Object-Detection-Models-on-Aerial-Images"><a href="#On-the-Robustness-of-Object-Detection-Models-on-Aerial-Images" class="headerlink" title="On the Robustness of Object Detection Models on Aerial Images"></a>On the Robustness of Object Detection Models on Aerial Images</h2><p><strong>Authors:Haodong He, Jian Ding, Bowen Xu, Gui-Song Xia</strong></p>
<p>The robustness of object detection models is a major concern when applied to real-world scenarios. The performance of most models tends to degrade when confronted with images affected by corruptions, since they are usually trained and evaluated on clean datasets. While numerous studies have explored the robustness of object detection models on natural images, there is a paucity of research focused on models applied to aerial images, which feature complex backgrounds, substantial variations in scales, and orientations of objects. This paper addresses the challenge of assessing the robustness of object detection models on aerial images, with a specific emphasis on scenarios where images are affected by clouds. In this study, we introduce two novel benchmarks based on DOTA-v1.0. The first benchmark encompasses 19 prevalent corruptions, while the second focuses on the cloud-corrupted condition-a phenomenon uncommon in natural images yet frequent in aerial photography. We systematically evaluate the robustness of mainstream object detection models and perform necessary ablation experiments. Through our investigations, we find that rotation-invariant modeling and enhanced backbone architectures can improve the robustness of models. Furthermore, increasing the capacity of Transformer-based backbones can strengthen their robustness. The benchmarks we propose and our comprehensive experimental analyses can facilitate research on robust object detection on aerial images. The codes and datasets are available at: <a target="_blank" rel="noopener" href="https://github.com/hehaodong530/DOTA-C">https://github.com/hehaodong530/DOTA-C</a>. </p>
<blockquote>
<p>å¯¹è±¡æ£€æµ‹æ¨¡å‹åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„åº”ç”¨çš„é²æ£’æ€§æ˜¯ä¸€ä¸ªé‡è¦çš„å…³æ³¨ç‚¹ã€‚å½“é¢å¯¹å—æ±¡æŸ“å½±å“çš„å›¾åƒæ—¶ï¼Œå¤§å¤šæ•°æ¨¡å‹çš„æ€§èƒ½å¾€å¾€ä¼šä¸‹é™ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸æ˜¯åœ¨å¹²å‡€çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°çš„ã€‚è™½ç„¶è®¸å¤šç ”ç©¶å·²ç»æ¢ç´¢äº†å¯¹è±¡æ£€æµ‹æ¨¡å‹åœ¨è‡ªç„¶å›¾åƒä¸Šçš„é²æ£’æ€§ï¼Œä½†å…³äºåº”ç”¨äºå…·æœ‰å¤æ‚èƒŒæ™¯ã€å°ºåº¦å˜åŒ–å¤§ä»¥åŠç‰©ä½“æ–¹å‘å˜åŒ–æ˜¾è‘—çš„é«˜ç©ºå›¾åƒæ¨¡å‹çš„æ·±å…¥ç ”ç©¶å¾ˆå°‘ã€‚æœ¬æ–‡è§£å†³äº†è¯„ä¼°å¯¹è±¡æ£€æµ‹æ¨¡å‹åœ¨é«˜ç©ºå›¾åƒä¸Šé²æ£’æ€§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒå—äº‘å±‚å½±å“çš„æƒ…å†µä¸‹çš„åœºæ™¯ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åŸºäºDOTA-v1.0å¼•å…¥äº†ä¸¤ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ã€‚ç¬¬ä¸€ä¸ªåŸºå‡†æµ‹è¯•åŒ…æ‹¬19ç§å¸¸è§çš„è…è´¥å½¢å¼ï¼Œè€Œç¬¬äºŒä¸ªåˆ™ä¸“æ³¨äºäº‘å±‚è…èš€çš„æ¡ä»¶â€”â€”è¿™æ˜¯ä¸€ç§åœ¨è‡ªç„¶å›¾åƒä¸­å¾ˆå°‘è§ï¼Œä½†åœ¨èˆªç©ºæ‘„å½±ä¸­ç»å¸¸å‘ç”Ÿçš„ç°è±¡ã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¸»æµå¯¹è±¡æ£€æµ‹æ¨¡å‹çš„é²æ£’æ€§ï¼Œå¹¶è¿›è¡Œäº†å¿…è¦çš„æ¶ˆèå®éªŒã€‚é€šè¿‡æˆ‘ä»¬çš„è°ƒæŸ¥ï¼Œæˆ‘ä»¬å‘ç°æ—‹è½¬ä¸å˜å»ºæ¨¡å’Œå¢å¼ºçš„ä¸»å¹²æ¶æ„å¯ä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œå¢åŠ åŸºäºTransformerçš„ä¸»å¹²çš„å®¹é‡å¯ä»¥åŠ å¼ºå…¶é²æ£’æ€§ã€‚æˆ‘ä»¬æå‡ºçš„åŸºå‡†æµ‹è¯•å’Œå…¨é¢çš„å®éªŒåˆ†æå¯ä»¥æ¨åŠ¨é«˜ç©ºå›¾åƒä¸Šé²æ£’å¯¹è±¡æ£€æµ‹çš„ç ”ç©¶ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®é›†å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š[<a target="_blank" rel="noopener" href="https://github.com/hehaodong530/DOTA-C]%E3%80%82">https://github.com/hehaodong530/DOTA-C]ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15378v2">PDF</a> accepted by IEEE TGRS</p>
<p><strong>Summary</strong>ï¼šé’ˆå¯¹ç°å®åœºæ™¯ä¸­çš„å¯¹è±¡æ£€æµ‹æ¨¡å‹é²æ£’æ€§é—®é¢˜ï¼Œè¯¥æ–‡å¯¹èˆªæ‹å›¾åƒçš„å¯¹è±¡æ£€æµ‹æ¨¡å‹é²æ£’æ€§è¿›è¡Œäº†è¯„ä¼°ã€‚é’ˆå¯¹èˆªæ‹å›¾åƒå¤æ‚èƒŒæ™¯ã€å°ºåº¦åŠæ–¹å‘å˜åŒ–ç­‰ç‰¹ç‚¹ï¼Œå¼•å…¥ä¸¤ä¸ªåŸºäºDOTA-v1.0çš„æ–°åŸºå‡†æµ‹è¯•é›†ï¼Œä¸€ä¸ªåŒ…å«19ç§å¸¸è§è…èš€æƒ…å†µï¼Œå¦ä¸€ä¸ªä¸“æ³¨äºäº‘è…èš€æƒ…å†µã€‚é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸»æµå¯¹è±¡æ£€æµ‹æ¨¡å‹çš„é²æ£’æ€§å’Œè¿›è¡Œå¿…è¦çš„æ¶ˆèå®éªŒï¼Œå‘ç°æ—‹è½¬ä¸å˜å»ºæ¨¡å’Œå¢å¼ºä¸»å¹²æ¶æ„èƒ½æé«˜æ¨¡å‹é²æ£’æ€§ï¼Œå¢åŠ åŸºäºTransformerçš„ä¸»å¹²å®¹é‡ä¹Ÿèƒ½å¢å¼ºé²æ£’æ€§ã€‚æå‡ºçš„åŸºå‡†æµ‹è¯•å’Œå®éªŒåˆ†ææœ‰åŠ©äºç ”ç©¶èˆªæ‹å›¾åƒä¸Šçš„ç¨³å¥å¯¹è±¡æ£€æµ‹ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¯¹è±¡æ£€æµ‹æ¨¡å‹åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„é²æ£’æ€§æ˜¯ä¸€ä¸ªé‡è¦é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢å¯¹å—è…èš€å½±å“çš„å›¾åƒæ—¶ã€‚</li>
<li>ç›®å‰å¯¹èˆªæ‹å›¾åƒä¸­çš„å¯¹è±¡æ£€æµ‹æ¨¡å‹é²æ£’æ€§çš„ç ”ç©¶è¾ƒå°‘ï¼Œè¿™äº›å›¾åƒå…·æœ‰å¤æ‚èƒŒæ™¯ã€å°ºåº¦åŠæ–¹å‘å˜åŒ–ç­‰ç‰¹ç‚¹ã€‚</li>
<li>å¼•å…¥ä¸¤ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•é›†ï¼Œä¸€ä¸ªåŒ…å«å¤šç§å¸¸è§è…èš€æƒ…å†µï¼Œå¦ä¸€ä¸ªä¸“æ³¨äºäº‘è…èš€æƒ…å†µã€‚</li>
<li>ç³»ç»Ÿè¯„ä¼°ä¸»æµå¯¹è±¡æ£€æµ‹æ¨¡å‹çš„é²æ£’æ€§ï¼Œå‘ç°æ—‹è½¬ä¸å˜å»ºæ¨¡å’Œå¢å¼ºä¸»å¹²æ¶æ„èƒ½æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>å¢åŠ åŸºäºTransformerçš„ä¸»å¹²å®¹é‡ä¹Ÿèƒ½å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚</li>
<li>æå‡ºçš„åŸºå‡†æµ‹è¯•å’Œå®éªŒåˆ†ææœ‰åŠ©äºæ¨è¿›èˆªæ‹å›¾åƒä¸Šçš„ç¨³å¥å¯¹è±¡æ£€æµ‹ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2308.15378">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-11740f03d5fb416599682b062718438a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1f8fa8f49b7e17efa514065b58dcc9de.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f017ad9a0d49a0b9c9f3724a76b93e59.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06975e82940abbbde679696a62484f8b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-09812d8a27c8a10046b4b6ab6396f036.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  Radial Distortion in Face Images Detection and Impact
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-7f262d0f78c82bdcda7a592ee0b830dd.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  DM-Mamba Dual-domain Multi-scale Mamba for MRI reconstruction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23667.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
