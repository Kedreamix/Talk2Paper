<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  VINGS-Mono Visual-Inertial Gaussian Splatting Monocular SLAM in Large   Scenes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06714v1/page_4_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    65 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-16-æ›´æ–°"><a href="#2025-01-16-æ›´æ–°" class="headerlink" title="2025-01-16 æ›´æ–°"></a>2025-01-16 æ›´æ–°</h1><h2 id="VINGS-Mono-Visual-Inertial-Gaussian-Splatting-Monocular-SLAM-in-Large-Scenes"><a href="#VINGS-Mono-Visual-Inertial-Gaussian-Splatting-Monocular-SLAM-in-Large-Scenes" class="headerlink" title="VINGS-Mono: Visual-Inertial Gaussian Splatting Monocular SLAM in Large   Scenes"></a>VINGS-Mono: Visual-Inertial Gaussian Splatting Monocular SLAM in Large   Scenes</h2><p><strong>Authors:Ke Wu, Zicheng Zhang, Muer Tie, Ziqing Ai, Zhongxue Gan, Wenchao Ding</strong></p>
<p>VINGS-Mono is a monocular (inertial) Gaussian Splatting (GS) SLAM framework designed for large scenes. The framework comprises four main components: VIO Front End, 2D Gaussian Map, NVS Loop Closure, and Dynamic Eraser. In the VIO Front End, RGB frames are processed through dense bundle adjustment and uncertainty estimation to extract scene geometry and poses. Based on this output, the mapping module incrementally constructs and maintains a 2D Gaussian map. Key components of the 2D Gaussian Map include a Sample-based Rasterizer, Score Manager, and Pose Refinement, which collectively improve mapping speed and localization accuracy. This enables the SLAM system to handle large-scale urban environments with up to 50 million Gaussian ellipsoids. To ensure global consistency in large-scale scenes, we design a Loop Closure module, which innovatively leverages the Novel View Synthesis (NVS) capabilities of Gaussian Splatting for loop closure detection and correction of the Gaussian map. Additionally, we propose a Dynamic Eraser to address the inevitable presence of dynamic objects in real-world outdoor scenes. Extensive evaluations in indoor and outdoor environments demonstrate that our approach achieves localization performance on par with Visual-Inertial Odometry while surpassing recent GS&#x2F;NeRF SLAM methods. It also significantly outperforms all existing methods in terms of mapping and rendering quality. Furthermore, we developed a mobile app and verified that our framework can generate high-quality Gaussian maps in real time using only a smartphone camera and a low-frequency IMU sensor. To the best of our knowledge, VINGS-Mono is the first monocular Gaussian SLAM method capable of operating in outdoor environments and supporting kilometer-scale large scenes. </p>
<blockquote>
<p>VINGS-Monoæ˜¯ä¸€ç§é’ˆå¯¹å¤§åœºæ™¯è®¾è®¡çš„å•ç›®ï¼ˆæƒ¯æ€§ï¼‰é«˜æ–¯æ··åˆï¼ˆGSï¼‰SLAMæ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«å››ä¸ªä¸»è¦ç»„ä»¶ï¼šVIOå‰ç«¯ã€2Dé«˜æ–¯åœ°å›¾ã€NVSç¯é—­åˆå’ŒåŠ¨æ€æ“¦é™¤å™¨ã€‚åœ¨VIOå‰ç«¯ï¼ŒRGBå¸§é€šè¿‡å¯†é›†æŸè°ƒæ•´å’Œä¸ç¡®å®šæ€§ä¼°è®¡æ¥æå–åœºæ™¯å‡ ä½•å’Œå§¿æ€ã€‚åŸºäºè¿™ä¸€è¾“å‡ºï¼Œæ˜ å°„æ¨¡å—é€æ­¥æ„å»ºå’Œç»´æŠ¤ä¸€ä¸ªäºŒç»´é«˜æ–¯åœ°å›¾ã€‚äºŒç»´é«˜æ–¯åœ°å›¾çš„å…³é”®ç»„ä»¶åŒ…æ‹¬åŸºäºæ ·æœ¬çš„æ …æ ¼åŒ–å™¨ã€è¯„åˆ†ç®¡ç†å™¨å’Œå§¿æ€ç»†åŒ–å™¨ï¼Œå®ƒä»¬å…±åŒæé«˜äº†æ˜ å°„é€Ÿåº¦å’Œå®šä½ç²¾åº¦ã€‚è¿™ä½¿å¾—SLAMç³»ç»Ÿèƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡çš„åŸå¸‚ç¯å¢ƒï¼Œé«˜è¾¾50ä¸‡ä¸ªé«˜æ–¯æ¤­åœ†ä½“ã€‚ä¸ºäº†ç¡®ä¿å¤§è§„æ¨¡åœºæ™¯çš„å…¨å±€ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç¯é—­åˆæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ›æ–°åœ°åˆ©ç”¨é«˜æ–¯æ··åˆçš„Novel View Synthesisï¼ˆNVSï¼‰åŠŸèƒ½è¿›è¡Œç¯é—­åˆæ£€æµ‹å’Œæ ¡æ­£é«˜æ–¯åœ°å›¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€æ“¦é™¤å™¨æ¥è§£å†³çœŸå®æˆ·å¤–åœºæ™¯ä¸­ä¸å¯é¿å…çš„å­˜åœ¨åŠ¨æ€ç‰©ä½“çš„é—®é¢˜ã€‚åœ¨å®¤å†…å’Œå®¤å¤–ç¯å¢ƒçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®ç°ä¸è§†è§‰æƒ¯æ€§æµ‹è·ç›¸å½“çš„å®šä½æ€§èƒ½çš„åŒæ—¶ï¼Œè¶…è¶Šäº†æœ€æ–°çš„GS&#x2F;NeRF SLAMæ–¹æ³•ã€‚åœ¨æ˜ å°„å’Œæ¸²æŸ“è´¨é‡æ–¹é¢ï¼Œå®ƒä¹Ÿå¤§å¤§ä¼˜äºæ‰€æœ‰ç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç§»åŠ¨åº”ç”¨ç¨‹åºï¼Œå¹¶éªŒè¯æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿä»…ä½¿ç”¨æ™ºèƒ½æ‰‹æœºæ‘„åƒå¤´å’Œä½é¢‘ç‡IMUä¼ æ„Ÿå™¨å®æ—¶ç”Ÿæˆé«˜è´¨é‡çš„é«˜æ–¯åœ°å›¾ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒVINGS-Monoæ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿåœ¨å®¤å¤–ç¯å¢ƒè¿è¡Œå¹¶æ”¯æŒå…¬é‡Œçº§å¤§åœºæ™¯çš„å•ç›®é«˜æ–¯SLAMæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.08286v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>VINGS-Monoæ˜¯ä¸€æ¬¾é’ˆå¯¹å¤§åœºæ™¯çš„å•ç›®ï¼ˆæƒ¯æ€§ï¼‰é«˜æ–¯èåˆSLAMæ¡†æ¶ï¼ŒåŒ…å«VIOå‰ç«¯ã€2Dé«˜æ–¯åœ°å›¾ã€NVSç¯é—­åˆå’ŒåŠ¨æ€æ“¦é™¤å™¨å››ä¸ªä¸»è¦ç»„ä»¶ã€‚æ¡†æ¶åˆ©ç”¨RGBå¸§å¤„ç†æå–åœºæ™¯å‡ ä½•å’Œå§¿æ€ï¼Œå¹¶æ„å»ºå’Œç»´æŠ¤ä¸€ä¸ªäºŒç»´é«˜æ–¯åœ°å›¾ã€‚è¯¥æ¡†æ¶å…·æœ‰é«˜æ•ˆçš„æ˜ å°„é€Ÿåº¦å’Œå®šä½ç²¾åº¦ï¼Œå¯å¤„ç†å¤§è§„æ¨¡åŸå¸‚ç¯å¢ƒï¼Œå¹¶æ”¯æŒé«˜è¾¾5åƒä¸‡é«˜æ–¯æ¤­åœ†ä½“ã€‚å…¶åˆ›æ–°è®¾è®¡çš„ç¯é—­åˆæ¨¡å—åˆ©ç”¨é«˜æ–¯èåˆçš„æ–°è§†è§’åˆæˆèƒ½åŠ›è¿›è¡Œç¯é—­åˆæ£€æµ‹å’Œåœ°å›¾æ ¡æ­£ã€‚æ­¤å¤–ï¼Œä¸ºè§£å†³æˆ·å¤–åœºæ™¯ä¸­åŠ¨æ€ç‰©ä½“çš„å½±å“ï¼Œæå‡ºäº†åŠ¨æ€æ“¦é™¤å™¨ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šä½å’Œæ˜ å°„æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–SLAMæ–¹æ³•ï¼Œå¹¶å¯åœ¨æ™ºèƒ½æ‰‹æœºå’Œä½é¢‘ç‡IMUä¼ æ„Ÿå™¨ä¸Šå®æ—¶ç”Ÿæˆé«˜è´¨é‡é«˜æ–¯åœ°å›¾ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒVINGS-Monoæ˜¯é¦–ä¸ªå¯åœ¨æˆ·å¤–ç¯å¢ƒè¿è¡Œå¹¶æ”¯æŒå…¬é‡Œçº§å¤§åœºæ™¯çš„å•ç›®é«˜æ–¯SLAMæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>VINGS-Monoæ˜¯ä¸€æ¬¾é’ˆå¯¹å¤§åœºæ™¯çš„å•ç›®SLAMæ¡†æ¶ã€‚</li>
<li>å®ƒåŒ…å«å››ä¸ªä¸»è¦ç»„ä»¶ï¼šVIOå‰ç«¯ã€2Dé«˜æ–¯åœ°å›¾ã€NVSç¯é—­åˆå’ŒåŠ¨æ€æ“¦é™¤å™¨ã€‚</li>
<li>åˆ©ç”¨RGBå¸§å¤„ç†æå–åœºæ™¯å‡ ä½•å’Œå§¿æ€ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡æ„å»ºå’Œç»´æŠ¤äºŒç»´é«˜æ–¯åœ°å›¾å®ç°é«˜æ•ˆçš„æ˜ å°„é€Ÿåº¦å’Œå®šä½ç²¾åº¦ã€‚</li>
<li>ç¯é—­åˆæ¨¡å—åˆ©ç”¨é«˜æ–¯èåˆçš„æ–°è§†è§’åˆæˆèƒ½åŠ›è¿›è¡Œç¯é—­åˆæ£€æµ‹å’Œåœ°å›¾æ ¡æ­£ã€‚</li>
<li>æå‡ºåŠ¨æ€æ“¦é™¤å™¨ä»¥è§£å†³æˆ·å¤–åœºæ™¯ä¸­åŠ¨æ€ç‰©ä½“çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.08286">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-737e1799970ed2a9b1e2154072e4b0f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-838cf5d4ee172e5cf3a464e95781ccd2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-05ee85124a86b84bc32c3f5ac51b0f63.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Evaluating-Human-Perception-of-Novel-View-Synthesis-Subjective-Quality-Assessment-of-Gaussian-Splatting-and-NeRF-in-Dynamic-Scenes"><a href="#Evaluating-Human-Perception-of-Novel-View-Synthesis-Subjective-Quality-Assessment-of-Gaussian-Splatting-and-NeRF-in-Dynamic-Scenes" class="headerlink" title="Evaluating Human Perception of Novel View Synthesis: Subjective Quality   Assessment of Gaussian Splatting and NeRF in Dynamic Scenes"></a>Evaluating Human Perception of Novel View Synthesis: Subjective Quality   Assessment of Gaussian Splatting and NeRF in Dynamic Scenes</h2><p><strong>Authors:Yuhang Zhang, Joshua Maraval, Zhengyu Zhang, Nicolas Ramin, Shishun Tian, Lu Zhang</strong></p>
<p>Gaussian Splatting (GS) and Neural Radiance Fields (NeRF) are two groundbreaking technologies that have revolutionized the field of Novel View Synthesis (NVS), enabling immersive photorealistic rendering and user experiences by synthesizing multiple viewpoints from a set of images of sparse views. The potential applications of NVS, such as high-quality virtual and augmented reality, detailed 3D modeling, and realistic medical organ imaging, underscore the importance of quality assessment of NVS methods from the perspective of human perception. Although some previous studies have explored subjective quality assessments for NVS technology, they still face several challenges, especially in NVS methods selection, scenario coverage, and evaluation methodology. To address these challenges, we conducted two subjective experiments for the quality assessment of NVS technologies containing both GS-based and NeRF-based methods, focusing on dynamic and real-world scenes. This study covers 360{\deg}, front-facing, and single-viewpoint videos while providing a richer and greater number of real scenes. Meanwhile, itâ€™s the first time to explore the impact of NVS methods in dynamic scenes with moving objects. The two types of subjective experiments help to fully comprehend the influences of different viewing paths from a human perception perspective and pave the way for future development of full-reference and no-reference quality metrics. In addition, we established a comprehensive benchmark of various state-of-the-art objective metrics on the proposed database, highlighting that existing methods still struggle to accurately capture subjective quality. The results give us some insights into the limitations of existing NVS methods and may promote the development of new NVS methods. </p>
<blockquote>
<p>é«˜æ–¯é‡‡æ ·ï¼ˆGSï¼‰å’Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯ä¸¤é¡¹çªç ´æ€§æŠ€æœ¯ï¼Œå®ƒä»¬å½»åº•æ”¹å˜äº†æ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰é¢†åŸŸï¼Œé€šè¿‡ä»ç¨€ç–è§†å›¾çš„ä¸€ç»„å›¾åƒä¸­åˆæˆå¤šä¸ªè§†ç‚¹ï¼Œå®ç°äº†æ²‰æµ¸å¼çš„å…‰ç…§çœŸå®æ¸²æŸ“å’Œç”¨æˆ·ä½“éªŒã€‚NVSçš„æ½œåœ¨åº”ç”¨ï¼Œå¦‚é«˜è´¨é‡è™šæ‹Ÿå’Œå¢å¼ºç°å®ã€è¯¦ç»†çš„3Då»ºæ¨¡å’Œé€¼çœŸçš„åŒ»å­¦å™¨å®˜æˆåƒï¼Œå¼ºè°ƒäº†ä»äººç±»æ„ŸçŸ¥è§’åº¦å¯¹NVSæ–¹æ³•è¿›è¡Œè´¨é‡è¯„ä¼°çš„é‡è¦æ€§ã€‚å°½ç®¡ä¹‹å‰çš„ä¸€äº›ç ”ç©¶å·²ç»æ¢ç´¢äº†NVSæŠ€æœ¯çš„ä¸»è§‚è´¨é‡è¯„ä¼°ï¼Œä½†å®ƒä»¬ä»ç„¶é¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨NVSæ–¹æ³•é€‰æ‹©ã€åœºæ™¯è¦†ç›–å’Œè¯„ä¼°æ–¹æ³•ä¸Šã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¯¹åŒ…å«åŸºäºGSå’ŒåŸºäºNeRFçš„æ–¹æ³•çš„NVSæŠ€æœ¯è¿›è¡Œäº†ä¸¤é¡¹ä¸»è§‚å®éªŒè´¨é‡è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨åŠ¨æ€å’ŒçœŸå®åœºæ™¯ã€‚è¯¥ç ”ç©¶æ¶µç›–äº†360åº¦ã€æ­£é¢å’Œå•è§†ç‚¹è§†é¢‘ï¼ŒåŒæ—¶æä¾›äº†æ›´ä¸°å¯Œã€æ•°é‡æ›´å¤šçš„çœŸå®åœºæ™¯ã€‚ä¸æ­¤åŒæ—¶ï¼Œå®ƒæ˜¯é¦–æ¬¡æ¢ç´¢NVSæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯ä¸­å¯¹ç§»åŠ¨ç‰©ä½“çš„å½±å“ã€‚è¿™ä¸¤ç§ç±»å‹çš„ä¸»è§‚å®éªŒæœ‰åŠ©äºä»äººç±»æ„ŸçŸ¥çš„è§’åº¦å……åˆ†ç†è§£ä¸åŒè§‚çœ‹è·¯å¾„çš„å½±å“ï¼Œä¸ºå…¨å‚è€ƒå’Œæ— å‚è€ƒè´¨é‡æŒ‡æ ‡çš„æœªæ¥å‘å±•é“ºå¹³é“è·¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨æå‡ºçš„æ•°æ®åº“ä¸Šå»ºç«‹äº†å„ç§æœ€æ–°å®¢è§‚æŒ‡æ ‡çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œçªå‡ºæ˜¾ç¤ºç°æœ‰æ–¹æ³•ä»ç„¶éš¾ä»¥å‡†ç¡®æ•æ‰ä¸»è§‚è´¨é‡ã€‚ç»“æœç»™æˆ‘ä»¬ä¸€äº›ç°æœ‰NVSæ–¹æ³•çš„å±€é™æ€§å¯ç¤ºï¼Œå¹¶å¯èƒ½ä¿ƒè¿›æ–°çš„NVSæ–¹æ³•çš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.08072v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†Gaussian Splattingï¼ˆGSï¼‰å’ŒNeural Radiance Fieldsï¼ˆNeRFï¼‰åœ¨Novel View Synthesisï¼ˆNVSï¼‰é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶è¿›è¡Œäº†è´¨é‡è¯„ä¼°ã€‚é€šè¿‡ä¸¤é¡¹ä¸»è§‚å®éªŒï¼Œå¯¹åŸºäºGSå’ŒNeRFçš„æ–¹æ³•åœ¨åŠ¨æ€å’ŒçœŸå®åœºæ™¯ä¸­çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå»ºç«‹äº†æœ€æ–°å®¢è§‚æŒ‡æ ‡çš„åŸºå‡†ï¼Œæ­ç¤ºäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Gaussian Splatting (GS) å’Œ Neural Radiance Fields (NeRF) é©æ–°äº†Novel View Synthesis (NVS)é¢†åŸŸï¼Œå®ç°äº†æ²‰æµ¸å¼é€¼çœŸçš„æ¸²æŸ“å’Œç”¨æˆ·ä½“éªŒã€‚</li>
<li>NVSåœ¨é«˜è´¨é‡è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è¯¦ç»†3Då»ºæ¨¡å’ŒçœŸå®åŒ»å­¦å™¨å®˜æˆåƒç­‰æ–¹é¢æœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>ä¸»è§‚è´¨é‡è¯„ä¼°å¯¹äºNVSæŠ€æœ¯éå¸¸é‡è¦ï¼Œå°¤å…¶æ˜¯ä»äººç±»æ„ŸçŸ¥çš„è§’åº¦ã€‚</li>
<li>ç°æœ‰ç ”ç©¶åœ¨NVSæŠ€æœ¯çš„ä¸»è§‚è´¨é‡è¯„ä¼°ä¸Šä»é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–¹æ³•é€‰æ‹©ã€åœºæ™¯è¦†ç›–å’Œè¯„ä¼°æ–¹æ³•ä¸Šã€‚</li>
<li>é€šè¿‡ä¸¤é¡¹ä¸»è§‚å®éªŒï¼Œå¯¹åŸºäºGSå’ŒNeRFçš„NVSæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚</li>
<li>å»ºç«‹äº†æœ€æ–°å®¢è§‚æŒ‡æ ‡çš„åŸºå‡†ï¼Œæ­ç¤ºäº†ç°æœ‰æ–¹æ³•åœ¨NVSæŠ€æœ¯è´¨é‡è¯„ä¼°ä¸­çš„å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.08072">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8fb9d620209685a5b88a9ee236d3013d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8056e9344da0ffeda6b350036010f74c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ca15035f399f5b445c47aada7d7f5aa0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bbeaee7c5b66e6ee924532e149d2c34a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee27f6ff6d45d455c6ac3525d158d395.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RMAvatar-Photorealistic-Human-Avatar-Reconstruction-from-Monocular-Video-Based-on-Rectified-Mesh-embedded-Gaussians"><a href="#RMAvatar-Photorealistic-Human-Avatar-Reconstruction-from-Monocular-Video-Based-on-Rectified-Mesh-embedded-Gaussians" class="headerlink" title="RMAvatar: Photorealistic Human Avatar Reconstruction from Monocular   Video Based on Rectified Mesh-embedded Gaussians"></a>RMAvatar: Photorealistic Human Avatar Reconstruction from Monocular   Video Based on Rectified Mesh-embedded Gaussians</h2><p><strong>Authors:Sen Peng, Weixing Xie, Zilong Wang, Xiaohu Guo, Zhonggui Chen, Baorong Yang, Xiao Dong</strong></p>
<p>We introduce RMAvatar, a novel human avatar representation with Gaussian splatting embedded on mesh to learn clothed avatar from a monocular video. We utilize the explicit mesh geometry to represent motion and shape of a virtual human and implicit appearance rendering with Gaussian Splatting. Our method consists of two main modules: Gaussian initialization module and Gaussian rectification module. We embed Gaussians into triangular faces and control their motion through the mesh, which ensures low-frequency motion and surface deformation of the avatar. Due to the limitations of LBS formula, the human skeleton is hard to control complex non-rigid transformations. We then design a pose-related Gaussian rectification module to learn fine-detailed non-rigid deformations, further improving the realism and expressiveness of the avatar. We conduct extensive experiments on public datasets, RMAvatar shows state-of-the-art performance on both rendering quality and quantitative evaluations. Please see our project page at <a target="_blank" rel="noopener" href="https://rm-avatar.github.io/">https://rm-avatar.github.io</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†RMAvatarï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„äººç±»åŒ–èº«è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡åœ¨ç½‘æ ¼ä¸ŠåµŒå…¥é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯æ¥å­¦ä¹ å•ç›®è§†é¢‘ä¸­çš„ç©¿è¡£åŒ–èº«ã€‚æˆ‘ä»¬åˆ©ç”¨æ˜ç¡®çš„ç½‘æ ¼å‡ ä½•æ¥è¡¨ç¤ºè™šæ‹Ÿäººç±»çš„è¿åŠ¨å’Œå½¢çŠ¶ï¼Œä»¥åŠä½¿ç”¨é«˜æ–¯æ¶‚æŠ¹çš„éšå¼å¤–è§‚æ¸²æŸ“ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼šé«˜æ–¯åˆå§‹åŒ–æ¨¡å—å’Œé«˜æ–¯æ ¡æ­£æ¨¡å—ã€‚æˆ‘ä»¬å°†é«˜æ–¯åµŒå…¥ä¸‰è§’å½¢é¢éƒ¨ï¼Œå¹¶é€šè¿‡ç½‘æ ¼æ§åˆ¶å…¶è¿åŠ¨ï¼Œè¿™ç¡®ä¿äº†åŒ–èº«çš„ä½é¢‘è¿åŠ¨å’Œè¡¨é¢å˜å½¢ã€‚ç”±äºLBSå…¬å¼çš„å±€é™æ€§ï¼Œäººç±»éª¨éª¼éš¾ä»¥æ§åˆ¶å¤æ‚çš„éåˆšæ€§å˜æ¢ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸å§¿åŠ¿ç›¸å…³çš„é«˜æ–¯æ ¡æ­£æ¨¡å—ï¼Œå­¦ä¹ ç²¾ç»†çš„éåˆšæ€§å˜å½¢ï¼Œè¿›ä¸€æ­¥æé«˜åŒ–èº«çš„çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ã€‚æˆ‘ä»¬åœ¨å…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼ŒRMAvataråœ¨æ¸²æŸ“è´¨é‡å’Œå®šé‡è¯„ä¼°æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://rm-avatar.github.ioäº†è§£ç»ƒ./">https://rm-avatar.github.ioäº†è§£è¯¦æƒ…ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07104v1">PDF</a> CVM2025</p>
<p><strong>Summary</strong></p>
<p>RMAvataræ˜¯ä¸€ç§æ–°å‹äººç±»åŒ–èº«è¡¨ç¤ºæ–¹æ³•ï¼Œé‡‡ç”¨é«˜æ–¯è´´å›¾åµŒå…¥ç½‘æ ¼æŠ€æœ¯ï¼Œä»å•ç›®è§†é¢‘ä¸­å­¦ä¹ ç€è£…åŒ–èº«ã€‚è¯¥æ–¹æ³•ç»“åˆæ˜¾å¼ç½‘æ ¼å‡ ä½•è¡¨ç¤ºè™šæ‹Ÿäººçš„è¿åŠ¨å’Œå½¢çŠ¶ï¼Œä»¥åŠéšå¼å¤–è§‚æ¸²æŸ“çš„é«˜æ–¯è´´å›¾æŠ€æœ¯ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé«˜æ–¯åˆå§‹åŒ–æ¨¡å—å’Œé«˜æ–¯æ ¡æ­£æ¨¡å—ã€‚é€šè¿‡å°†é«˜æ–¯åµŒå…¥ä¸‰è§’å½¢é¢éƒ¨å¹¶é€šè¿‡ç½‘æ ¼æ§åˆ¶å…¶è¿åŠ¨ï¼Œç¡®ä¿åŒ–èº«çš„ä½é¢‘è¿åŠ¨å’Œè¡¨é¢å˜å½¢ã€‚ç”±äºLBSå…¬å¼çš„å±€é™æ€§ï¼Œäººç±»éª¨éª¼éš¾ä»¥æ§åˆ¶å¤æ‚çš„éåˆšæ€§å˜æ¢ã€‚å› æ­¤ï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸å§¿åŠ¿ç›¸å…³çš„é«˜æ–¯æ ¡æ­£æ¨¡å—æ¥å­¦ä¹ ç²¾ç»†çš„éåˆšæ€§å˜å½¢ï¼Œè¿›ä¸€æ­¥æé«˜åŒ–èº«çš„çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒRMAvataråœ¨æ¸²æŸ“è´¨é‡å’Œå®šé‡è¯„ä¼°æ–¹é¢å‡è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RMAvataræ˜¯ä¸€ç§åŸºäºé«˜æ–¯è´´å›¾åµŒå…¥ç½‘æ ¼æŠ€æœ¯çš„æ–°å‹äººç±»åŒ–èº«è¡¨ç¤ºæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆæ˜¾å¼ç½‘æ ¼å‡ ä½•å’Œéšå¼å¤–è§‚æ¸²æŸ“æŠ€æœ¯ã€‚</li>
<li>RMAvataråŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé«˜æ–¯åˆå§‹åŒ–æ¨¡å—å’Œé«˜æ–¯æ ¡æ­£æ¨¡å—ã€‚</li>
<li>é«˜æ–¯åµŒå…¥ä¸‰è§’å½¢é¢éƒ¨å¹¶é€šè¿‡ç½‘æ ¼æ§åˆ¶å…¶è¿åŠ¨ï¼Œç¡®ä¿åŒ–èº«çš„ä½é¢‘è¿åŠ¨å’Œè¡¨é¢å˜å½¢ã€‚</li>
<li>ç”±äºLBSå…¬å¼çš„å±€é™æ€§ï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸å§¿åŠ¿ç›¸å…³çš„é«˜æ–¯æ ¡æ­£æ¨¡å—æ¥å­¦ä¹ ç²¾ç»†çš„éåˆšæ€§å˜å½¢ã€‚</li>
<li>RMAvataråœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07104">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d90330b3783b1586c2a70d19404a89eb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-482168a2d61041cb1c6d6d2dd2382313.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-622761ee68b572527e561ab78b3a1d76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-859d57e4af1395afbc06a31ab55b21ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4f9e5cda2ab2a8eb9b53e0d25abcb6c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-318e4e09aa21ab0436830154738187f7.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SplatMAP-Online-Dense-Monocular-SLAM-with-3D-Gaussian-Splatting"><a href="#SplatMAP-Online-Dense-Monocular-SLAM-with-3D-Gaussian-Splatting" class="headerlink" title="SplatMAP: Online Dense Monocular SLAM with 3D Gaussian Splatting"></a>SplatMAP: Online Dense Monocular SLAM with 3D Gaussian Splatting</h2><p><strong>Authors:Yue Hu, Rong Liu, Meida Chen, Andrew Feng, Peter Beerel</strong></p>
<p>Achieving high-fidelity 3D reconstruction from monocular video remains challenging due to the inherent limitations of traditional methods like Structure-from-Motion (SfM) and monocular SLAM in accurately capturing scene details. While differentiable rendering techniques such as Neural Radiance Fields (NeRF) address some of these challenges, their high computational costs make them unsuitable for real-time applications. Additionally, existing 3D Gaussian Splatting (3DGS) methods often focus on photometric consistency, neglecting geometric accuracy and failing to exploit SLAMâ€™s dynamic depth and pose updates for scene refinement. We propose a framework integrating dense SLAM with 3DGS for real-time, high-fidelity dense reconstruction. Our approach introduces SLAM-Informed Adaptive Densification, which dynamically updates and densifies the Gaussian model by leveraging dense point clouds from SLAM. Additionally, we incorporate Geometry-Guided Optimization, which combines edge-aware geometric constraints and photometric consistency to jointly optimize the appearance and geometry of the 3DGS scene representation, enabling detailed and accurate SLAM mapping reconstruction. Experiments on the Replica and TUM-RGBD datasets demonstrate the effectiveness of our approach, achieving state-of-the-art results among monocular systems. Specifically, our method achieves a PSNR of 36.864, SSIM of 0.985, and LPIPS of 0.040 on Replica, representing improvements of 10.7%, 6.4%, and 49.4%, respectively, over the previous SOTA. On TUM-RGBD, our method outperforms the closest baseline by 10.2%, 6.6%, and 34.7% in the same metrics. These results highlight the potential of our framework in bridging the gap between photometric and geometric dense 3D scene representations, paving the way for practical and efficient monocular dense reconstruction. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­å®ç°é«˜ä¿çœŸ3Dé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰å’Œå•ç›®SLAMï¼‰åœ¨å‡†ç¡®æ•æ‰åœºæ™¯ç»†èŠ‚æ–¹é¢çš„å›ºæœ‰å±€é™æ€§ã€‚è™½ç„¶ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ç­‰å¯å¾®åˆ†æ¸²æŸ“æŠ€æœ¯è§£å†³äº†å…¶ä¸­çš„ä¸€äº›æŒ‘æˆ˜ï¼Œä½†å®ƒä»¬çš„é«˜è®¡ç®—æˆæœ¬ä½¿å®ƒä»¬ä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ–¹æ³•é€šå¸¸ä¾§é‡äºå…‰åº¦ä¸€è‡´æ€§ï¼Œå¿½ç•¥äº†å‡ ä½•ç²¾åº¦ï¼Œå¹¶ä¸”æœªèƒ½åˆ©ç”¨SLAMçš„åŠ¨æ€æ·±åº¦å’Œå§¿æ€æ›´æ–°æ¥è¿›è¡Œåœºæ™¯ç»†åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆå¯†é›†SLAMå’Œ3DGSçš„å®æ—¶é«˜ä¿çœŸå¯†é›†é‡å»ºæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†SLAMä¿¡æ¯è‡ªé€‚åº”ç»†åŒ–æŠ€æœ¯ï¼Œå®ƒåˆ©ç”¨SLAMçš„å¯†é›†ç‚¹äº‘æ¥åŠ¨æ€æ›´æ–°å’Œç»†åŒ–é«˜æ–¯æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†åŸºäºå‡ ä½•çš„å¼•å¯¼ä¼˜åŒ–æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯ç»“åˆäº†è¾¹ç¼˜æ„ŸçŸ¥å‡ ä½•çº¦æŸå’Œå…‰åº¦ä¸€è‡´æ€§ï¼Œä»¥è”åˆä¼˜åŒ–3DGSåœºæ™¯è¡¨ç¤ºçš„å¤–è§‚å’Œå‡ ä½•å½¢çŠ¶ï¼Œä»è€Œå®ç°è¯¦ç»†è€Œå‡†ç¡®çš„SLAMæ˜ å°„é‡å»ºã€‚åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å•ç›®ç³»ç»Ÿä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆæœã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Replicaä¸Šè¾¾åˆ°äº†36.864çš„PSNRï¼Œ0.985çš„SSIMå’Œ0.040çš„LPIPSï¼Œåœ¨ä¹‹å‰çš„æœ€æ–°æˆæœçš„åŸºç¡€ä¸Šåˆ†åˆ«æé«˜äº†10.7%ï¼Œ6.4%å’Œ49.4%ã€‚åœ¨TUM-RGBDä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç›¸åŒçš„æŒ‡æ ‡ä¸Šæ¯”æœ€æ¥è¿‘çš„åŸºçº¿é«˜å‡º10.2%ï¼Œ6.6%å’Œ34.7%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æˆ‘ä»¬æ¡†æ¶åœ¨æ¡¥æ¥å…‰åº¦ä¸€è‡´æ€§å‡ ä½•å¯†é›†3Dåœºæ™¯è¡¨ç¤ºæ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºå®ç”¨å’Œé«˜æ•ˆçš„å•ç›®å¯†é›†é‡å»ºé“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07015v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§æ–°çš„å®ç°å®æ—¶é«˜ä¿çœŸä¸‰ç»´é‡å»ºçš„æ–¹æ³•ï¼Œå®ƒç»“åˆäº†å¯†é›†SLAMä¸ç°æœ‰çš„é«˜æ–¯æµ®é›•å»ºæ¨¡æŠ€æœ¯ã€‚æ­¤æ–¹æ³•é‡‡ç”¨åŸºäºSLAæŠ€æœ¯çš„åŠ¨æ€æ·±åº¦æ›´æ–°å’Œå§¿æ€æ›´æ–°è¿›è¡Œåœºæ™¯ç»†åŒ–ï¼Œå¹¶ç»“åˆå‡ ä½•çº¦æŸå’Œå…‰åº¦ä¸€è‡´æ€§ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºï¼Œå®ç°äº†è¯¦ç»†çš„å‡†ç¡®SLAMæ˜ å°„é‡å»ºã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å•ç›®ç³»ç»Ÿé¢†åŸŸå–å¾—äº†æœ€å…ˆè¿›çš„æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç»“åˆå¯†é›†SLAMä¸ç°æœ‰çš„é«˜æ–¯æµ®é›•å»ºæ¨¡æŠ€æœ¯å®ç°å®æ—¶é«˜ä¿çœŸä¸‰ç»´é‡å»ºã€‚</li>
<li>æ–¹æ³•åˆ©ç”¨å¯†é›†SLAMä¸­çš„åŠ¨æ€æ·±åº¦æ›´æ–°å’Œå§¿æ€æ›´æ–°ï¼Œä»¥æ›´ç²¾ç»†åœ°æ•è·åœºæ™¯ç»†èŠ‚ã€‚</li>
<li>ç»“åˆå‡ ä½•çº¦æŸå’Œå…‰åº¦ä¸€è‡´æ€§è¿›è¡Œè”åˆä¼˜åŒ–ï¼ŒåŒæ—¶æ”¹å–„åœºæ™¯çš„å¤–è§‚å’Œå‡ ä½•ç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07015">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f1523b1abbcb1c597ae35d040c9f4d47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa958801ce4e0ebafd95f802767a2bcb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0fb4dc6f6c58c584b812799e02ed00b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Synthetic-Prior-for-Few-Shot-Drivable-Head-Avatar-Inversion"><a href="#Synthetic-Prior-for-Few-Shot-Drivable-Head-Avatar-Inversion" class="headerlink" title="Synthetic Prior for Few-Shot Drivable Head Avatar Inversion"></a>Synthetic Prior for Few-Shot Drivable Head Avatar Inversion</h2><p><strong>Authors:Wojciech Zielonka, Stephan J. Garbin, Alexandros Lattas, George Kopanas, Paulo Gotardo, Thabo Beeler, Justus Thies, Timo Bolkart</strong></p>
<p>We present SynShot, a novel method for the few-shot inversion of a drivable head avatar based on a synthetic prior. We tackle two major challenges. First, training a controllable 3D generative network requires a large number of diverse sequences, for which pairs of images and high-quality tracked meshes are not always available. Second, state-of-the-art monocular avatar models struggle to generalize to new views and expressions, lacking a strong prior and often overfitting to a specific viewpoint distribution. Inspired by machine learning models trained solely on synthetic data, we propose a method that learns a prior model from a large dataset of synthetic heads with diverse identities, expressions, and viewpoints. With few input images, SynShot fine-tunes the pretrained synthetic prior to bridge the domain gap, modeling a photorealistic head avatar that generalizes to novel expressions and viewpoints. We model the head avatar using 3D Gaussian splatting and a convolutional encoder-decoder that outputs Gaussian parameters in UV texture space. To account for the different modeling complexities over parts of the head (e.g., skin vs hair), we embed the prior with explicit control for upsampling the number of per-part primitives. Compared to state-of-the-art monocular methods that require thousands of real training images, SynShot significantly improves novel view and expression synthesis. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºSynShotçš„æ–°æ–¹æ³•ï¼Œç”¨äºåŸºäºåˆæˆå…ˆéªŒçš„å°‘é‡é©¾é©¶å¤´éƒ¨åŒ–èº«åæ¼”ã€‚æˆ‘ä»¬è§£å†³äº†ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œè®­ç»ƒå¯æ§çš„3Dç”Ÿæˆç½‘ç»œéœ€è¦å¤§é‡çš„å„ç§åºåˆ—ï¼Œè€Œå›¾åƒå’Œé«˜è´¨é‡è·Ÿè¸ªç½‘æ ¼çš„é…å¯¹å¹¶ä¸æ€»æ˜¯å¯ç”¨çš„ã€‚å…¶æ¬¡ï¼Œæœ€å…ˆè¿›çš„å•ç›®åŒ–èº«æ¨¡å‹å¾ˆéš¾æ¨å¹¿åˆ°æ–°çš„è§†è§’å’Œè¡¨æƒ…ï¼Œç¼ºä¹å¼ºå¤§çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ä¸”ç»å¸¸è¿‡åº¦é€‚åº”ç‰¹å®šçš„è§†ç‚¹åˆ†å¸ƒã€‚å—åˆ°ä»…ç”±åˆæˆæ•°æ®è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»å¤§é‡åˆæˆå¤´éƒ¨æ•°æ®ä¸­å­¦ä¹ å…ˆéªŒæ¨¡å‹çš„æ–¹æ³•ï¼Œè¿™äº›åˆæˆå¤´éƒ¨æ•°æ®å…·æœ‰å„ç§èº«ä»½ã€è¡¨æƒ…å’Œè§†ç‚¹ã€‚å‡­å€Ÿå°‘é‡çš„è¾“å…¥å›¾åƒï¼ŒSynShotå¾®è°ƒäº†é¢„è®­ç»ƒçš„åˆæˆå…ˆéªŒï¼Œä»¥å¼¥åˆé¢†åŸŸå·®è·ï¼Œä»è€Œå»ºç«‹å¯¹æ–°å‹è¡¨è¾¾å’Œè§†ç‚¹é€šç”¨çš„é€¼çœŸå¤´éƒ¨åŒ–èº«æ¨¡å‹ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸‰ç»´é«˜æ–¯å–·ç»˜å’Œå·ç§¯ç¼–ç å™¨-è§£ç å™¨æ¥å»ºç«‹å¤´éƒ¨åŒ–èº«æ¨¡å‹ï¼Œè¯¥ç¼–ç å™¨-è§£ç å™¨åœ¨UVçº¹ç†ç©ºé—´ä¸­è¾“å‡ºé«˜æ–¯å‚æ•°ã€‚è€ƒè™‘åˆ°å¤´éƒ¨å„éƒ¨åˆ†çš„å»ºæ¨¡å¤æ‚æ€§ä¸åŒï¼ˆä¾‹å¦‚çš®è‚¤å’Œå¤´å‘ï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡å…ˆéªŒåµŒå…¥æ˜¾å¼æ§åˆ¶æ¥ä¸Šé‡‡æ ·æ¯ä¸ªéƒ¨åˆ†çš„åŸå§‹æ•°é‡ã€‚ä¸éœ€è¦æ•°åƒå¼ çœŸå®è®­ç»ƒå›¾åƒçš„æœ€å…ˆè¿›çš„å•ç›®æ–¹æ³•ç›¸æ¯”ï¼ŒSynShotæ˜¾è‘—æé«˜äº†æ–°è§†è§’å’Œè¡¨æƒ…çš„åˆæˆæ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06903v1">PDF</a> Website <a target="_blank" rel="noopener" href="https://zielon.github.io/synshot/">https://zielon.github.io/synshot/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºåˆæˆå…ˆéªŒçš„SynShotæ–¹æ³•ï¼Œè§£å†³äº†å¯æ§ä¸‰ç»´ç”Ÿæˆç½‘ç»œé¢ä¸´çš„ä¸¤é¡¹æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œè¯¥æ–¹æ³•ä»å¤§é‡åˆæˆå¤´éƒ¨æ•°æ®ä¸­å­¦ä¹ å…ˆéªŒæ¨¡å‹ï¼Œä»¥åº”å¯¹å¤šæ ·èº«ä»½ã€è¡¨æƒ…å’Œè§†è§’çš„æŒ‘æˆ˜ã€‚å…¶æ¬¡ï¼Œåˆ©ç”¨å°‘é‡è¾“å…¥å›¾åƒå¾®è°ƒé¢„è®­ç»ƒåˆæˆå…ˆéªŒæ¨¡å‹ï¼Œå»ºç«‹å…·æœ‰çœŸå®æ„Ÿçš„å¤´éƒ¨è§’è‰²æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯æ¨å¹¿è‡³æ–°çš„è§†è§’å’Œè¡¨æƒ…ã€‚SynShoté€šè¿‡åˆ©ç”¨é«˜æ–¯å˜å½¢å»ºæ¨¡å’Œå·ç§¯ç¼–ç å™¨-è§£ç å™¨ï¼Œæé«˜äº†ç›¸å¯¹äºå…ˆè¿›å•çœ¼æ–¹æ³•çš„è§†è§’å’Œè¡¨æƒ…åˆæˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SynShotæ˜¯ä¸€ç§åŸºäºåˆæˆå…ˆéªŒçš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†å°‘æ ·æœ¬ä¸‹é©±åŠ¨å¤´éƒ¨è§’è‰²çš„å€’åºé—®é¢˜ã€‚</li>
<li>è§£å†³äº†ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šç¼ºä¹å¤šæ ·åŒ–çš„å›¾åƒå’Œé«˜è´¨é‡è·Ÿè¸ªç½‘æ ¼çš„è®­ç»ƒæ•°æ®ä»¥åŠç°æœ‰æ¨¡å‹å¯¹æ–°è§†è§’å’Œè¡¨æƒ…çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚</li>
<li>é€šè¿‡å­¦ä¹ å¤§é‡åˆæˆå¤´éƒ¨æ•°æ®çš„å…ˆéªŒæ¨¡å‹åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹å…·å¤‡å¤šç§èº«ä»½ã€è¡¨æƒ…å’Œè§†è§’çš„ç‰¹æ€§ã€‚</li>
<li>ä½¿ç”¨å°‘é‡è¾“å…¥å›¾åƒå¾®è°ƒé¢„è®­ç»ƒçš„åˆæˆå…ˆéªŒæ¨¡å‹ï¼Œä»¥ç¼©å°é¢†åŸŸå·®è·å¹¶å»ºç«‹çœŸå®æ„Ÿçš„å¤´éƒ¨è§’è‰²æ¨¡å‹ã€‚æ­¤æ¨¡å‹å¯åœ¨æ–°çš„è§†è§’å’Œè¡¨æƒ…ä¸Šè¿›è¡Œæ¨å¹¿ã€‚</li>
<li>é€šè¿‡é«˜æ–¯å˜å½¢å»ºæ¨¡å’Œå·ç§¯ç¼–ç å™¨-è§£ç å™¨çš„ç»“åˆå®ç°å¤´éƒ¨è§’è‰²çš„å»ºæ¨¡ã€‚</li>
<li>ä¸ºäº†åº”å¯¹å¤´éƒ¨ä¸åŒéƒ¨åˆ†çš„å»ºæ¨¡å¤æ‚æ€§ï¼ˆå¦‚çš®è‚¤å’Œå¤´å‘ï¼‰ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¯¹æ¯éƒ¨åˆ†åŸå§‹æ•°é‡è¿›è¡Œä¸Šé‡‡æ ·çš„æ˜¾å¼æ§åˆ¶åŠŸèƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06903">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-49eecf52d586c0bd0c57bdf0d3563b34.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9f57cf04eb1b2d5db9068f560d4615ab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c89e44e74aee357d2176aa81bff4cffb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4197fb0e20dd6d8cdba7a51018dbe853.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-600b1edea485905e38b762f18883a97b.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="ActiveGAMER-Active-GAussian-Mapping-through-Efficient-Rendering"><a href="#ActiveGAMER-Active-GAussian-Mapping-through-Efficient-Rendering" class="headerlink" title="ActiveGAMER: Active GAussian Mapping through Efficient Rendering"></a>ActiveGAMER: Active GAussian Mapping through Efficient Rendering</h2><p><strong>Authors:Liyan Chen, Huangying Zhan, Kevin Chen, Xiangyu Xu, Qingan Yan, Changjiang Cai, Yi Xu</strong></p>
<p>We introduce ActiveGAMER, an active mapping system that utilizes 3D Gaussian Splatting (3DGS) to achieve high-quality, real-time scene mapping and exploration. Unlike traditional NeRF-based methods, which are computationally demanding and restrict active mapping performance, our approach leverages the efficient rendering capabilities of 3DGS, allowing effective and efficient exploration in complex environments. The core of our system is a rendering-based information gain module that dynamically identifies the most informative viewpoints for next-best-view planning, enhancing both geometric and photometric reconstruction accuracy. ActiveGAMER also integrates a carefully balanced framework, combining coarse-to-fine exploration, post-refinement, and a global-local keyframe selection strategy to maximize reconstruction completeness and fidelity. Our system autonomously explores and reconstructs environments with state-of-the-art geometric and photometric accuracy and completeness, significantly surpassing existing approaches in both aspects. Extensive evaluations on benchmark datasets such as Replica and MP3D highlight ActiveGAMERâ€™s effectiveness in active mapping tasks. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ActiveGAMERï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰å®ç°é«˜è´¨é‡ã€å®æ—¶åœºæ™¯æ˜ å°„å’Œæ¢ç´¢çš„ä¸»åŠ¨æ˜ å°„ç³»ç»Ÿã€‚ä¸ä¼ ç»Ÿçš„åŸºäºNeRFçš„æ–¹æ³•ä¸åŒï¼Œè¿™äº›æ–¹æ³•è®¡ç®—é‡å¤§ï¼Œé™åˆ¶ä¸»åŠ¨æ˜ å°„çš„æ€§èƒ½ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨3DGSçš„é«˜æ•ˆæ¸²æŸ“èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆå’Œé«˜æ•ˆçš„æ¢ç´¢ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿçš„æ ¸å¿ƒæ˜¯åŸºäºæ¸²æŸ“çš„ä¿¡æ¯å¢ç›Šæ¨¡å—ï¼Œè¯¥æ¨¡å—åŠ¨æ€åœ°ç¡®å®šæœ€å…·ä¿¡æ¯é‡çš„è§†ç‚¹ï¼Œç”¨äºè§„åˆ’ä¸‹ä¸€ä¸ªæœ€ä½³è§†ç‚¹ï¼Œæé«˜å‡ ä½•å’Œå…‰åº¦é‡å»ºçš„ç²¾åº¦ã€‚ActiveGAMERè¿˜æ•´åˆäº†ä¸€ä¸ªç²¾å¿ƒå¹³è¡¡çš„æ–¹æ¡ˆï¼Œç»“åˆäº†ç”±ç²—åˆ°ç»†çš„æ¢ç´¢ã€åä¼˜åŒ–å’Œå…¨å±€å±€éƒ¨å…³é”®å¸§é€‰æ‹©ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–é‡å»ºçš„å®Œæ•´æ€§å’Œä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿä»¥æœ€å…ˆè¿›çš„å‡ ä½•å’Œå…‰åº¦å‡†ç¡®æ€§å’Œå®Œæ•´æ€§è‡ªä¸»æ¢ç´¢å’Œé‡å»ºç¯å¢ƒï¼Œåœ¨å„ä¸ªæ–¹é¢éƒ½å¤§å¤§è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚åœ¨Replicaå’ŒMP3Dç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°çªå‡ºäº†ActiveGAMERåœ¨ä¸»åŠ¨æ˜ å°„ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06897v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ActiveGAMERç³»ç»Ÿåˆ©ç”¨ä¸‰ç»´é«˜æ–¯å–·æº…æŠ€æœ¯ï¼ˆ3DGSï¼‰å®ç°é«˜è´¨é‡å®æ—¶åœºæ™¯æ˜ å°„å’Œæ¢ç´¢ã€‚ä¸ä¼ ç»ŸåŸºäºNeRFçš„æ–¹æ³•ç›¸æ¯”ï¼ŒActiveGAMERç³»ç»Ÿå€ŸåŠ©é«˜æ•ˆæ¸²æŸ“èƒ½åŠ›å®ç°é«˜æ•ˆå¤æ‚ç¯å¢ƒæ¢ç´¢ã€‚æ ¸å¿ƒæ˜¯é€šè¿‡æ¸²æŸ“è¿›è¡Œä¿¡æ¯è·å–æ¨¡å—åŠ¨æ€ç¡®å®šæœ€æœ‰ä¿¡æ¯çš„è§‚æµ‹ç‚¹ä»¥è§„åˆ’ä¸‹ä¸€æ­¥æœ€ä½³è§†è§’ï¼Œå¢å¼ºå‡ ä½•å’Œå…‰åº¦é‡å»ºç²¾åº¦ã€‚ActiveGAMERç»“åˆç²—åˆ°ç»†æ¢ç´¢ã€åæœŸä¼˜åŒ–å’Œå…¨å±€å±€éƒ¨å…³é”®å¸§é€‰æ‹©ç­–ç•¥ï¼Œä»¥å®ç°é‡å»ºçš„å®Œæ•´æ€§å’Œé€¼çœŸåº¦æœ€å¤§åŒ–ã€‚ç³»ç»Ÿå¯åœ¨åŸºå‡†æ•°æ®é›†å¦‚Replicaå’ŒMP3Dä¸Šè‡ªä¸»æ¢ç´¢é‡å»ºç¯å¢ƒï¼Œå…·æœ‰ä¼˜ç§€çš„å‡ ä½•å’Œå…‰åº¦å‡†ç¡®åº¦å’Œå®Œæ•´æ€§ã€‚è¯¥æ€»ç»“ä½“ç°å…¶æ ¸å¿ƒæŠ€æœ¯ä¸ç‰¹è‰²ï¼Œç”¨è¯ç²¾ç‚¼ï¼Œé•¿åº¦é€‚å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ActiveGAMERé‡‡ç”¨ä¸‰ç»´é«˜æ–¯å–·æº…æŠ€æœ¯ï¼ˆ3DGSï¼‰å®ç°å®æ—¶åœºæ™¯æ˜ å°„ä¸é«˜æ•ˆæ¢ç´¢ã€‚</li>
<li>ActiveGAMERæœ‰åˆ«äºä¾èµ–å¤§é‡è®¡ç®—çš„ä¼ ç»ŸNeRFæ–¹æ³•ï¼Œä»¥é«˜æ•ˆæ¸²æŸ“æ¨åŠ¨é«˜æ•ˆæ€§èƒ½ã€‚</li>
<li>ç³»ç»Ÿçš„æ ¸å¿ƒæ˜¯ä¿¡æ¯è·å–æ¨¡å—ï¼Œèƒ½å¤ŸåŠ¨æ€é€‰æ‹©æœ€æœ‰ä¿¡æ¯çš„è§‚æµ‹ç‚¹è¿›è¡Œæœ€ä½³è§†è§’è§„åˆ’ã€‚</li>
<li>æ­¤ç³»ç»Ÿæå‡å‡ ä½•ä¸å…‰åº¦é‡å»ºçš„å‡†ç¡®æ€§ã€‚</li>
<li>ç»“åˆç²—åˆ°ç»†æ¢ç´¢ã€åæœŸä¼˜åŒ–å’Œå…³é”®å¸§é€‰æ‹©ç­–ç•¥ä»¥æé«˜é‡å»ºå®Œæ•´åº¦ã€‚</li>
<li>æ¡†æ¶ä¸­çš„å„éƒ¨åˆ†å¦‚æ¢ç´¢ç­–ç•¥ã€å…³é”®å¸§é€‰æ‹©ç­‰éƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ä»¥å®ç°æœ€ä¼˜æ•ˆæœã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06897">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-abd6b56d06d456d11b164cb9b5bd76a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ec14eb4cb933ec03aae06000294635e.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06897v1/page_4_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39039f9725c9caaa76b25907768bed3e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Generalized-and-Efficient-2D-Gaussian-Splatting-for-Arbitrary-scale-Super-Resolution"><a href="#Generalized-and-Efficient-2D-Gaussian-Splatting-for-Arbitrary-scale-Super-Resolution" class="headerlink" title="Generalized and Efficient 2D Gaussian Splatting for Arbitrary-scale   Super-Resolution"></a>Generalized and Efficient 2D Gaussian Splatting for Arbitrary-scale   Super-Resolution</h2><p><strong>Authors:Du Chen, Liyi Chen, Zhengqiang Zhang, Lei Zhang</strong></p>
<p>Equipped with the continuous representation capability of Multi-Layer Perceptron (MLP), Implicit Neural Representation (INR) has been successfully employed for Arbitrary-scale Super-Resolution (ASR). However, the limited receptive field of the linear layers in MLP restricts the representation capability of INR, while it is computationally expensive to query the MLP numerous times to render each pixel. Recently, Gaussian Splatting (GS) has shown its advantages over INR in both visual quality and rendering speed in 3D tasks, which motivates us to explore whether GS can be employed for the ASR task. However, directly applying GS to ASR is exceptionally challenging because the original GS is an optimization-based method through overfitting each single scene, while in ASR we aim to learn a single model that can generalize to different images and scaling factors. We overcome these challenges by developing two novel techniques. Firstly, to generalize GS for ASR, we elaborately design an architecture to predict the corresponding image-conditioned Gaussians of the input low-resolution image in a feed-forward manner. Secondly, we implement an efficient differentiable 2D GPU&#x2F;CUDA-based scale-aware rasterization to render super-resolved images by sampling discrete RGB values from the predicted contiguous Gaussians. Via end-to-end training, our optimized network, namely GSASR, can perform ASR for any image and unseen scaling factors. Extensive experiments validate the effectiveness of our proposed method. The project page can be found at \url{<a target="_blank" rel="noopener" href="https://mt-cly.github.io/GSASR.github.io/%7D">https://mt-cly.github.io/GSASR.github.io/}</a>. </p>
<blockquote>
<p>å…·å¤‡å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰çš„æŒç»­è¡¨ç¤ºèƒ½åŠ›ï¼Œéšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰å·²æˆåŠŸåº”ç”¨äºä»»æ„å°ºåº¦è¶…åˆ†è¾¨ç‡ï¼ˆASRï¼‰ã€‚ç„¶è€Œï¼ŒMLPä¸­çš„çº¿æ€§å±‚æœ‰é™çš„æ„Ÿå—é‡é™åˆ¶äº†INRçš„è¡¨ç¤ºèƒ½åŠ›ï¼Œè€Œå¤šæ¬¡æŸ¥è¯¢MLPä»¥æ¸²æŸ“æ¯ä¸ªåƒç´ çš„è®¡ç®—æˆæœ¬åˆå¾ˆé«˜ã€‚æœ€è¿‘ï¼Œé«˜æ–¯æ¶‚æŠ¹ï¼ˆGSï¼‰åœ¨3Dä»»åŠ¡çš„è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢éƒ½æ˜¾ç¤ºå‡ºå…¶ä¼˜äºINRçš„åœ°æ–¹ï¼Œè¿™æ¿€åŠ±æˆ‘ä»¬æ¢ç´¢æ˜¯å¦å¯ä»¥ä½¿ç”¨GSè¿›è¡ŒASRä»»åŠ¡ã€‚ç„¶è€Œï¼Œç›´æ¥å°†GSåº”ç”¨äºASRå…·æœ‰æå¤§çš„æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºåŸå§‹çš„GSæ˜¯é€šè¿‡è¿‡åº¦æ‹Ÿåˆæ¯ä¸ªå•ä¸€åœºæ™¯çš„ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œåœ¨ASRä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å­¦ä¹ ä¸€ä¸ªå¯ä»¥æ¨å¹¿åˆ°ä¸åŒå›¾åƒå’Œç¼©æ”¾å› å­çš„å•ä¸€æ¨¡å‹ã€‚æˆ‘ä»¬é€šè¿‡å¼€å‘ä¸¤ç§æ–°æŠ€æœ¯æ¥å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œä¸ºäº†å°†GSé€šç”¨åŒ–åˆ°ASRï¼Œæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸€ä¸ªæ¶æ„ï¼Œä»¥å‰é¦ˆæ–¹å¼é¢„æµ‹è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒå¯¹åº”çš„å›¾åƒæ¡ä»¶é«˜æ–¯åˆ†å¸ƒã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªé«˜æ•ˆçš„å¯å¾®åˆ†2D GPU&#x2F;CUDAåŸºå°ºåº¦æ„ŸçŸ¥å…‰æ …åŒ–ï¼Œé€šè¿‡ä»é¢„æµ‹è¿ç»­çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ç¦»æ•£RGBå€¼æ¥å‘ˆç°è¶…åˆ†è¾¨ç‡å›¾åƒã€‚é€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„ç½‘ç»œï¼Œå³GSASRï¼Œå¯ä»¥å¯¹ä»»ä½•å›¾åƒå’Œæœªè§çš„ç¼©æ”¾å› å­æ‰§è¡ŒASRã€‚å¤§é‡çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚é¡¹ç›®é¡µé¢å¯åœ¨\url{<a target="_blank" rel="noopener" href="https://mt-cly.github.io/GSASR.github.io/%7D%E6%89%BE%E5%88%B0%E3%80%82">https://mt-cly.github.io/GSASR.github.io/}æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06838v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰çš„è¿ç»­è¡¨ç¤ºèƒ½åŠ›ï¼Œéšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰å·²æˆåŠŸåº”ç”¨äºä»»æ„å°ºåº¦è¶…åˆ†è¾¨ç‡ï¼ˆASRï¼‰ã€‚ç„¶è€Œï¼ŒMLPçš„çº¿æ€§å±‚æœ‰é™çš„æ„Ÿå—é‡é™åˆ¶äº†INRçš„è¡¨ç¤ºèƒ½åŠ›ï¼Œå¹¶ä¸”å¤šæ¬¡æŸ¥è¯¢MLPä»¥æ¸²æŸ“æ¯ä¸ªåƒç´ çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚è¿‘æœŸï¼Œé«˜æ–¯æ‹¼è´´ï¼ˆGSï¼‰åœ¨3Dä»»åŠ¡ä¸­çš„è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢å±•ç°å‡ºä¼˜åŠ¿ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ¢ç´¢GSæ˜¯å¦å¯ç”¨äºASRä»»åŠ¡ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤é¡¹æ–°æŠ€æœ¯ã€‚é¦–å…ˆæ˜¯ä¸ºASRé€šç”¨åŒ–GSï¼Œè®¾è®¡äº†ä¸€ç§å‰é¦ˆç¥ç»ç½‘ç»œæ¶æ„æ¥é¢„æµ‹è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒçš„æ¡ä»¶é«˜æ–¯åˆ†å¸ƒã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç§é«˜æ•ˆçš„å¯å¾®åˆ†2D GPU&#x2F;CUDAåŸºå°ºåº¦æ„ŸçŸ¥å…‰æ …åŒ–æŠ€æœ¯ï¼Œé€šè¿‡ä»é¢„æµ‹çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ç¦»æ•£RGBå€¼æ¥æ¸²æŸ“è¶…åˆ†è¾¨ç‡å›¾åƒã€‚é€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„ç½‘ç»œGSASRå¯ä»¥å¯¹ä»»ä½•å›¾åƒå’Œæœªè§è¿‡çš„ç¼©æ”¾å› å­è¿›è¡ŒASRã€‚å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä¸€ã€éšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰å·²ç»æˆåŠŸåº”ç”¨äºä»»æ„å°ºåº¦è¶…åˆ†è¾¨ç‡ï¼ˆASRï¼‰ï¼Œä½†å…¶å—é™äºå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰çš„çº¿æ€§å±‚æ„Ÿå—é‡ã€‚<br>äºŒã€é«˜æ–¯æ‹¼è´´ï¼ˆGSï¼‰åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢å±•ç°å‡ºä¼˜åŠ¿ï¼Œå…·æœ‰æ½œåŠ›æ”¹å–„ASRä»»åŠ¡çš„æ•ˆæœã€‚<br>ä¸‰ã€ä¸ºäº†å°†GSåº”ç”¨äºASRï¼Œéœ€è¦è§£å†³GSåŸæ˜¯é’ˆå¯¹å•ä¸€åœºæ™¯ä¼˜åŒ–çš„é—®é¢˜ï¼Œè€ŒASRéœ€è¦å­¦ä¹ èƒ½åº”ç”¨äºä¸åŒå›¾åƒå’Œç¼©æ”¾å› å­çš„å•ä¸€æ¨¡å‹ã€‚<br>å››ã€æœ¬ç ”ç©¶é€šè¿‡è®¾è®¡å‰é¦ˆç¥ç»ç½‘ç»œæ¶æ„å’Œé«˜æ•ˆçš„å¯å¾®åˆ†å…‰æ …åŒ–æŠ€æœ¯æ¥å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚<br>äº”ã€ç½‘ç»œé€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œå¯ä»¥å®ç°å¯¹ä»»ä½•å›¾åƒå’Œæœªè§è¿‡çš„ç¼©æ”¾å› å­çš„ASRã€‚<br>å…­ã€å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06838">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9f98da98bbc3bd1ca3852da1e692a310.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-055844d65ea27ca1004f92da61303c54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2543aa5b983227dca615537e46bd0a95.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06838v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06838v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="F3D-Gaus-Feed-forward-3D-aware-Generation-on-ImageNet-with-Cycle-Consistent-Gaussian-Splatting"><a href="#F3D-Gaus-Feed-forward-3D-aware-Generation-on-ImageNet-with-Cycle-Consistent-Gaussian-Splatting" class="headerlink" title="F3D-Gaus: Feed-forward 3D-aware Generation on ImageNet with   Cycle-Consistent Gaussian Splatting"></a>F3D-Gaus: Feed-forward 3D-aware Generation on ImageNet with   Cycle-Consistent Gaussian Splatting</h2><p><strong>Authors:Yuxin Wang, Qianyi Wu, Dan Xu</strong></p>
<p>This paper tackles the problem of generalizable 3D-aware generation from monocular datasets, e.g., ImageNet. The key challenge of this task is learning a robust 3D-aware representation without multi-view or dynamic data, while ensuring consistent texture and geometry across different viewpoints. Although some baseline methods are capable of 3D-aware generation, the quality of the generated images still lags behind state-of-the-art 2D generation approaches, which excel in producing high-quality, detailed images. To address this severe limitation, we propose a novel feed-forward pipeline based on pixel-aligned Gaussian Splatting, coined as F3D-Gaus, which can produce more realistic and reliable 3D renderings from monocular inputs. In addition, we introduce a self-supervised cycle-consistent constraint to enforce cross-view consistency in the learned 3D representation. This training strategy naturally allows aggregation of multiple aligned Gaussian primitives and significantly alleviates the interpolation limitations inherent in single-view pixel-aligned Gaussian Splatting. Furthermore, we incorporate video model priors to perform geometry-aware refinement, enhancing the generation of fine details in wide-viewpoint scenarios and improving the modelâ€™s capability to capture intricate 3D textures. Extensive experiments demonstrate that our approach not only achieves high-quality, multi-view consistent 3D-aware generation from monocular datasets, but also significantly improves training and inference efficiency. </p>
<blockquote>
<p>æœ¬æ–‡è§£å†³äº†ä»å•ç›®æ•°æ®é›†ï¼ˆä¾‹å¦‚ImageNetï¼‰ä¸­è¿›è¡Œå¯æ³›åŒ–çš„3Dæ„ŸçŸ¥ç”Ÿæˆçš„é—®é¢˜ã€‚æ­¤ä»»åŠ¡çš„å…³é”®æŒ‘æˆ˜åœ¨äºï¼Œå¦‚ä½•åœ¨æ²¡æœ‰å¤šè§†è§’æˆ–åŠ¨æ€æ•°æ®çš„æƒ…å†µä¸‹å­¦ä¹ ç¨³å¥çš„3Dæ„ŸçŸ¥è¡¨ç¤ºï¼ŒåŒæ—¶ç¡®ä¿ä¸åŒè§†è§’ä¸‹çš„çº¹ç†å’Œå‡ ä½•ä¸€è‡´æ€§ã€‚å°½ç®¡ä¸€äº›åŸºå‡†æ–¹æ³•èƒ½å¤Ÿè¿›è¡Œ3Dæ„ŸçŸ¥ç”Ÿæˆï¼Œä½†æ‰€ç”Ÿæˆå›¾åƒçš„è´¨é‡ä»ç„¶è½åäºæœ€å…ˆè¿›çš„2Dç”Ÿæˆæ–¹æ³•ï¼Œåè€…åœ¨ç”Ÿæˆé«˜è´¨é‡ã€è¯¦ç»†çš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ä¸¥é‡é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåƒç´ å¯¹é½çš„é«˜æ–¯æ¶‚æ•·æŠ€æœ¯çš„æ–°å‹å‰é¦ˆç®¡é“ï¼Œç§°ä¸ºF3D-Gausï¼Œå®ƒå¯ä»¥ä»å•ç›®è¾“å…¥ä¸­äº§ç”Ÿæ›´çœŸå®å’Œå¯é çš„3Dæ¸²æŸ“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªç›‘ç£å¾ªç¯ä¸€è‡´æ€§çº¦æŸï¼Œä»¥å¼ºåˆ¶æ‰§è¡Œå­¦ä¹ åˆ°çš„3Dè¡¨ç¤ºä¸­çš„è·¨è§†å›¾ä¸€è‡´æ€§ã€‚è¿™ç§è®­ç»ƒç­–ç•¥è‡ªç„¶åœ°å…è®¸å¤šä¸ªå¯¹é½çš„é«˜æ–¯åŸºå…ƒè¿›è¡Œèšåˆï¼Œå¹¶æ˜¾è‘—ç¼“è§£äº†å•è§†å›¾åƒç´ å¯¹é½é«˜æ–¯æ¶‚æ•·æŠ€æœ¯æ‰€å›ºæœ‰çš„æ’å€¼é™åˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†è§†é¢‘æ¨¡å‹å…ˆéªŒçŸ¥è¯†æ¥è¿›è¡Œå‡ ä½•æ„ŸçŸ¥ç»†åŒ–ï¼Œå¢å¼ºäº†å®½è§†è§’åœºæ™¯ä¸­çš„ç»†èŠ‚ç”Ÿæˆï¼Œæé«˜äº†æ¨¡å‹æ•æ‰å¤æ‚3Dçº¹ç†çš„èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å®ç°äº†ä»å•ç›®æ•°æ®é›†è¿›è¡Œé«˜è´¨é‡ã€å¤šè§†è§’ä¸€è‡´çš„3Dæ„ŸçŸ¥ç”Ÿæˆï¼Œè¿˜æ˜¾è‘—æé«˜äº†è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06714v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://w-ted.github.io/publications/F3D-Gaus">https://w-ted.github.io/publications/F3D-Gaus</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡ç ”ç©¶äº†åŸºäºå•è§†è§’æ•°æ®é›†ï¼ˆå¦‚ImageNetï¼‰çš„å¯é€šç”¨åŒ–ä¸‰ç»´æ„ŸçŸ¥ç”Ÿæˆé—®é¢˜ã€‚æ–‡ç« é’ˆå¯¹å¦‚ä½•åœ¨ç¼ºä¹å¤šè§†è§’æˆ–åŠ¨æ€æ•°æ®çš„æƒ…å†µä¸‹å­¦ä¹ ç¨³å¥çš„ä¸‰ç»´è¡¨ç¤ºï¼Œå¹¶ä¿è¯ä¸åŒè§†è§’ä¸‹çš„çº¹ç†å’Œå‡ ä½•ä¸€è‡´æ€§è¿™ä¸€æ ¸å¿ƒæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåƒç´ å¯¹é½é«˜æ–¯æ‹¼è´´çš„æ–°å‹å‰é¦ˆç®¡é“ï¼ˆç§°ä¸ºF3D-Gausï¼‰ã€‚è¯¥ç®¡é“å¯ä»¥ç”Ÿæˆæ›´åŠ çœŸå®å’Œå¯é çš„ä¸‰ç»´æ¸²æŸ“ã€‚ä¸ºæå‡æ¨¡å‹æ€§èƒ½ï¼Œè®ºæ–‡è¿˜ä»‹ç»äº†è‡ªç›‘ç£å¾ªç¯ä¸€è‡´æ€§çº¦æŸå’Œèåˆè§†é¢‘æ¨¡å‹å…ˆéªŒçŸ¥è¯†çš„ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…å®ç°äº†é«˜è´¨é‡ã€å¤šè§†è§’ä¸€è‡´çš„ä¸‰ç»´æ„ŸçŸ¥ç”Ÿæˆï¼Œè¿˜æ˜¾è‘—æé«˜äº†è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡è§£å†³äº†åŸºäºå•è§†è§’æ•°æ®é›†çš„ä¸‰ç»´æ„ŸçŸ¥ç”Ÿæˆé—®é¢˜ï¼Œé’ˆå¯¹ç¼ºä¹å¤šè§†è§’æˆ–åŠ¨æ€æ•°æ®ä¸‹çš„ç¨³å¥ä¸‰ç»´è¡¨ç¤ºå­¦ä¹ æå‡ºäº†è§£å†³æ–¹æ¡ˆã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°å‹å‰é¦ˆç®¡é“F3D-Gausï¼ŒåŸºäºåƒç´ å¯¹é½é«˜æ–¯æ‹¼è´´ï¼Œèƒ½ç”Ÿæˆæ›´çœŸå®å¯é çš„ä¸‰ç»´æ¸²æŸ“ã€‚</li>
<li>ä¸ºæé«˜æ¨¡å‹æ€§èƒ½ï¼Œè®ºæ–‡å¼•å…¥äº†è‡ªç›‘ç£å¾ªç¯ä¸€è‡´æ€§çº¦æŸï¼Œå¢å¼ºäº†å­¦ä¹ åˆ°çš„ä¸‰ç»´è¡¨ç¤ºåœ¨ä¸åŒè§†è§’ä¸‹çš„ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡èåˆè§†é¢‘æ¨¡å‹å…ˆéªŒçŸ¥è¯†ï¼Œè®ºæ–‡æ–¹æ³•èƒ½å¤Ÿåœ¨å®½è§†è§’åœºæ™¯ä¸‹ç”Ÿæˆæ›´ç²¾ç»†çš„ç»†èŠ‚ï¼Œå¹¶æå‡æ¨¡å‹æ•æ‰å¤æ‚ä¸‰ç»´çº¹ç†çš„èƒ½åŠ›ã€‚</li>
<li>è®ºæ–‡é€šè¿‡å¤§é‡å®éªŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ä»…å®ç°äº†é«˜è´¨é‡ã€å¤šè§†è§’ä¸€è‡´çš„ä¸‰ç»´æ„ŸçŸ¥ç”Ÿæˆï¼Œè¿˜æå‡äº†è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚</li>
<li>F3D-Gausæ–¹æ³•èƒ½å¤Ÿåº”å¯¹å•è§†è§’åƒç´ å¯¹é½é«˜æ–¯æ‹¼è´´å›ºæœ‰çš„æ’å€¼é™åˆ¶ï¼Œé€šè¿‡è‡ªç„¶çš„æ–¹å¼å…è®¸å¤šä¸ªå¯¹é½çš„é«˜æ–¯åŸºå…ƒèšåˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06714">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06714v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06714v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06714v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06714v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06714v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MapGS-Generalizable-Pretraining-and-Data-Augmentation-for-Online-Mapping-via-Novel-View-Synthesis"><a href="#MapGS-Generalizable-Pretraining-and-Data-Augmentation-for-Online-Mapping-via-Novel-View-Synthesis" class="headerlink" title="MapGS: Generalizable Pretraining and Data Augmentation for Online   Mapping via Novel View Synthesis"></a>MapGS: Generalizable Pretraining and Data Augmentation for Online   Mapping via Novel View Synthesis</h2><p><strong>Authors:Hengyuan Zhang, David Paz, Yuliang Guo, Xinyu Huang, Henrik I. Christensen, Liu Ren</strong></p>
<p>Online mapping reduces the reliance of autonomous vehicles on high-definition (HD) maps, significantly enhancing scalability. However, recent advancements often overlook cross-sensor configuration generalization, leading to performance degradation when models are deployed on vehicles with different camera intrinsics and extrinsics. With the rapid evolution of novel view synthesis methods, we investigate the extent to which these techniques can be leveraged to address the sensor configuration generalization challenge. We propose a novel framework leveraging Gaussian splatting to reconstruct scenes and render camera images in target sensor configurations. The target config sensor data, along with labels mapped to the target config, are used to train online mapping models. Our proposed framework on the nuScenes and Argoverse 2 datasets demonstrates a performance improvement of 18% through effective dataset augmentation, achieves faster convergence and efficient training, and exceeds state-of-the-art performance when using only 25% of the original training data. This enables data reuse and reduces the need for laborious data labeling. Project page at <a target="_blank" rel="noopener" href="https://henryzhangzhy.github.io/mapgs">https://henryzhangzhy.github.io/mapgs</a>. </p>
<blockquote>
<p>åœ¨çº¿æ˜ å°„å‡å°‘äº†è‡ªåŠ¨é©¾é©¶è½¦è¾†å¯¹é«˜ç²¾åº¦åœ°å›¾çš„ä¾èµ–ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†å…¶å¯æ‰©å±•æ€§ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„è¿›å±•å¾€å¾€å¿½è§†äº†è·¨ä¼ æ„Ÿå™¨é…ç½®çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯¼è‡´æ¨¡å‹åœ¨éƒ¨ç½²åˆ°å…·æœ‰ä¸åŒç›¸æœºå†…éƒ¨å’Œå¤–éƒ¨å‚æ•°çš„è½¦è¾†ä¸Šæ—¶æ€§èƒ½ä¸‹é™ã€‚éšç€æ–°é¢–è§†å›¾åˆæˆæ–¹æ³•çš„å¿«é€Ÿå‘å±•ï¼Œæˆ‘ä»¬è°ƒæŸ¥äº†è¿™äº›æŠ€æœ¯åœ¨è§£å†³ä¼ æ„Ÿå™¨é…ç½®æ³›åŒ–æŒ‘æˆ˜æ–¹é¢çš„æ½œåŠ›ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨é«˜æ–¯å–·å°„æŠ€æœ¯é‡å»ºåœºæ™¯å¹¶åœ¨ç›®æ ‡ä¼ æ„Ÿå™¨é…ç½®ä¸­æ¸²æŸ“ç›¸æœºå›¾åƒã€‚ç›®æ ‡é…ç½®ä¼ æ„Ÿå™¨æ•°æ®ä»¥åŠä¸ç›®æ ‡é…ç½®æ˜ å°„çš„æ ‡ç­¾è¢«ç”¨äºè®­ç»ƒåœ¨çº¿æ˜ å°„æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨nuSceneså’ŒArgoverse 2æ•°æ®é›†ä¸Šæå‡ºçš„æ¡†æ¶é€šè¿‡æœ‰æ•ˆçš„æ•°æ®é›†å¢å¼ºå®ç°äº†18%çš„æ€§èƒ½æå‡ï¼Œå®ç°äº†æ›´å¿«çš„æ”¶æ•›å’Œé«˜æ•ˆçš„è®­ç»ƒï¼Œå¹¶ä¸”åœ¨ä»…ä½¿ç”¨åŸå§‹è®­ç»ƒæ•°æ®çš„25%æ—¶è¶…è¿‡äº†æœ€æ–°æŠ€æœ¯çš„æ€§èƒ½ã€‚è¿™å®ç°äº†æ•°æ®çš„å†åˆ©ç”¨ï¼Œå¹¶å‡å°‘äº†ç¹ççš„æ•°æ®æ ‡æ³¨éœ€æ±‚ã€‚é¡¹ç›®é¡µé¢ä¸ºï¼š<a target="_blank" rel="noopener" href="https://henryzhangzhy.github.io/mapgs%E3%80%82">https://henryzhangzhy.github.io/mapgsã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06660v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨çº¿æ˜ å°„æŠ€æœ¯å‡å°‘äº†è‡ªåŠ¨é©¾é©¶è½¦è¾†å¯¹é«˜æ¸…åœ°å›¾çš„ä¾èµ–ï¼Œæ˜¾è‘—æé«˜äº†å…¶å¯æ‰©å±•æ€§ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶è¿›å±•å¾€å¾€å¿½è§†äº†è·¨ä¼ æ„Ÿå™¨é…ç½®çš„é€šç”¨æ€§ï¼Œå¯¼è‡´æ¨¡å‹åœ¨éƒ¨ç½²åˆ°å…·æœ‰ä¸åŒç›¸æœºå†…éƒ¨å’Œå¤–éƒ¨å‚æ•°çš„è½¦ä¸Šæ—¶æ€§èƒ½ä¸‹é™ã€‚éšç€æ–°é¢–è§†å›¾åˆæˆæ–¹æ³•çš„å¿«é€Ÿå‘å±•ï¼Œæœ¬æ–‡æ¢è®¨äº†è¿™äº›æŠ€æœ¯å¯ä»¥åœ¨å¤šå¤§ç¨‹åº¦ä¸Šè¢«ç”¨æ¥è§£å†³ä¼ æ„Ÿå™¨é…ç½®é€šç”¨æ€§çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨é«˜æ–¯å–·æ¶‚é‡å»ºåœºæ™¯å¹¶æ¸²æŸ“ç›®æ ‡ä¼ æ„Ÿå™¨é…ç½®çš„ç›¸æœºå›¾åƒçš„æ–°æ¡†æ¶ã€‚ç›®æ ‡é…ç½®ä¼ æ„Ÿå™¨æ•°æ®ä»¥åŠæ˜ å°„åˆ°ç›®æ ‡é…ç½®çš„æ ‡ç­¾è¢«ç”¨æ¥è®­ç»ƒåœ¨çº¿æ˜ å°„æ¨¡å‹ã€‚åœ¨nuSceneså’ŒArgoverse 2æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œé€šè¿‡æœ‰æ•ˆçš„æ•°æ®é›†å¢å¼ºï¼Œæœ¬æ–‡æå‡ºçš„æ¡†æ¶æ€§èƒ½æé«˜äº†18%ï¼Œå®ç°äº†æ›´å¿«çš„æ”¶æ•›å’Œé«˜æ•ˆçš„è®­ç»ƒï¼Œå¹¶ä¸”åœ¨ä»…ä½¿ç”¨åŸå§‹è®­ç»ƒæ•°æ®çš„25%æ—¶è¶…è¿‡äº†ç°æœ‰æŠ€æœ¯çš„æ€§èƒ½ã€‚è¿™å®ç°äº†æ•°æ®çš„å†åˆ©ç”¨ï¼Œå¹¶å‡å°‘äº†ç¹ççš„æ•°æ®æ ‡æ³¨éœ€æ±‚ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>åœ¨çº¿æ˜ å°„æŠ€æœ¯å¢å¼ºè‡ªä¸»è½¦è¾†çš„çµæ´»æ€§å¹¶å‡å°‘äº†å¯¹é«˜æ¸…åœ°å›¾çš„ä¾èµ–ã€‚</li>
<li>å½“å‰ç ”ç©¶å¿½ç•¥äº†ä¸åŒä¼ æ„Ÿå™¨é…ç½®ä¹‹é—´çš„é€šç”¨æ€§ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ä¸åŒè½¦è¾†ä¸Šæ€§èƒ½ä¸‹é™ã€‚</li>
<li>æ–°é¢–è§†å›¾åˆæˆæ–¹æ³•ä¸ºè§£å†³ä¼ æ„Ÿå™¨é…ç½®é€šç”¨æ€§é—®é¢˜æä¾›äº†æ–°çš„è§†è§’ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºé«˜æ–¯å–·æ¶‚æŠ€æœ¯çš„æ¡†æ¶ï¼Œèƒ½é‡å»ºåœºæ™¯å¹¶æ¸²æŸ“ç›®æ ‡ä¼ æ„Ÿå™¨é…ç½®çš„ç›¸æœºå›¾åƒã€‚</li>
<li>åˆ©ç”¨ç›®æ ‡é…ç½®ä¼ æ„Ÿå™¨æ•°æ®å’Œæ ‡ç­¾è®­ç»ƒåœ¨çº¿æ˜ å°„æ¨¡å‹ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡æœ‰æ•ˆçš„æ•°æ®é›†å¢å¼ºæé«˜äº†æ€§èƒ½ï¼Œå®ç°äº†å¿«é€Ÿæ”¶æ•›å’Œé«˜æ•ˆè®­ç»ƒã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨ä»…ä½¿ç”¨å°‘é‡åŸå§‹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ä»è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¿ƒè¿›äº†æ•°æ®çš„å†åˆ©ç”¨å¹¶å‡å°‘äº†æ ‡æ³¨å·¥ä½œé‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06660">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06660v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06660v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06660v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06660v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="NVS-SQA-Exploring-Self-Supervised-Quality-Representation-Learning-for-Neurally-Synthesized-Scenes-without-References"><a href="#NVS-SQA-Exploring-Self-Supervised-Quality-Representation-Learning-for-Neurally-Synthesized-Scenes-without-References" class="headerlink" title="NVS-SQA: Exploring Self-Supervised Quality Representation Learning for   Neurally Synthesized Scenes without References"></a>NVS-SQA: Exploring Self-Supervised Quality Representation Learning for   Neurally Synthesized Scenes without References</h2><p><strong>Authors:Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Weidong Cai, Tongliang Liu</strong></p>
<p>Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting, effectively creates photorealistic scenes from sparse viewpoints, typically evaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However, these full-reference methods, which compare synthesized views to reference views, may not fully capture the perceptual quality of neurally synthesized scenes (NSS), particularly due to the limited availability of dense reference views. Furthermore, the challenges in acquiring human perceptual labels hinder the creation of extensive labeled datasets, risking model overfitting and reduced generalizability. To address these issues, we propose NVS-SQA, a NSS quality assessment method to learn no-reference quality representations through self-supervision without reliance on human labels. Traditional self-supervised learning predominantly relies on the â€œsame instance, similar representationâ€ assumption and extensive datasets. However, given that these conditions do not apply in NSS quality assessment, we employ heuristic cues and quality scores as learning objectives, along with a specialized contrastive pair preparation process to improve the effectiveness and efficiency of learning. The results show that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e., on average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second best) and even exceeds 16 full-reference methods across all evaluation metrics (i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best). </p>
<blockquote>
<p>ç¥ç»è§†å›¾åˆæˆï¼ˆNVSï¼‰ï¼Œå¦‚NeRFå’Œ3Dé«˜æ–¯æº…å°„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ä»ç¨€ç–è§†è§’ç”Ÿæˆé€¼çœŸçš„åœºæ™¯ï¼Œé€šå¸¸é€šè¿‡PSNRã€SSIMå’ŒLPIPSç­‰è´¨é‡è¯„ä¼°æ–¹æ³•è¿›è¡Œè¯„ä¼°ã€‚ç„¶è€Œï¼Œè¿™äº›å…¨å‚è€ƒæ–¹æ³•å°†åˆæˆè§†å›¾ä¸å‚è€ƒè§†å›¾è¿›è¡Œæ¯”è¾ƒï¼Œå¯èƒ½æ— æ³•å®Œå…¨æ•æ‰ç¥ç»åˆæˆåœºæ™¯ï¼ˆNSSï¼‰çš„æ„ŸçŸ¥è´¨é‡ï¼Œå°¤å…¶æ˜¯å› ä¸ºå¯†é›†å‚è€ƒè§†å›¾çš„å¯è·å¾—æ€§æœ‰é™ã€‚æ­¤å¤–ï¼Œè·å–äººç±»æ„ŸçŸ¥æ ‡ç­¾çš„æŒ‘æˆ˜é˜»ç¢äº†å¤§è§„æ¨¡æ ‡è®°æ•°æ®é›†çš„åˆ¶ä½œï¼Œå­˜åœ¨æ¨¡å‹è¿‡åº¦æ‹Ÿåˆå’Œæ³›åŒ–æ€§é™ä½çš„é£é™©ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†NVS-SQAï¼Œè¿™æ˜¯ä¸€ç§æ— å‚è€ƒè´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡è‡ªæˆ‘ç›‘ç£å­¦ä¹ æ— å‚è€ƒè´¨é‡è¡¨ç¤ºï¼Œæ— éœ€ä¾èµ–äººç±»æ ‡ç­¾ã€‚ä¼ ç»Ÿçš„è‡ªç›‘ç£å­¦ä¹ ä¸»è¦ä¾èµ–äºâ€œåŒä¸€å®ä¾‹ï¼Œç›¸ä¼¼è¡¨ç¤ºâ€çš„å‡è®¾å’Œå¤§è§„æ¨¡æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°è¿™äº›æ¡ä»¶ä¸é€‚ç”¨äºNSSè´¨é‡è¯„ä¼°ï¼Œæˆ‘ä»¬é‡‡ç”¨å¯å‘å¼çº¿ç´¢å’Œè´¨é‡åˆ†æ•°ä½œä¸ºå­¦ä¹ ç›®æ ‡ï¼ŒåŒæ—¶é…åˆä¸“é—¨çš„å¯¹æ¯”å¯¹å‡†å¤‡è¿‡ç¨‹ï¼Œä»¥æé«˜å­¦ä¹ çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚ç»“æœè¡¨æ˜ï¼ŒNVS-SQAåœ¨17ç§æ— å‚è€ƒæ–¹æ³•ä¸­æœ‰å¾ˆå¤§çš„ä¼˜åŠ¿ï¼ˆä¾‹å¦‚ï¼ŒSRCCå¹³å‡æé«˜109.5%ï¼ŒPLCCæé«˜98.6%ï¼ŒKRCCæé«˜91.5%ï¼‰ï¼›åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šï¼Œç”šè‡³è¶…è¿‡äº†16ç§å…¨å‚è€ƒæ–¹æ³•ï¼ˆä¾‹å¦‚ï¼ŒSRCCæé«˜22.9%ï¼ŒPLCCæé«˜19.1%ï¼ŒKRCCæé«˜18.6%ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06488v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    NVS-SQAæ–¹æ³•é€šè¿‡æ— å‚è€ƒè´¨é‡è¡¨ç¤ºå­¦ä¹ è§£å†³äº†ç¥ç»åˆæˆåœºæ™¯è´¨é‡è¯„ä¼°çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•æ— éœ€ä¾èµ–äººç±»æ ‡ç­¾ï¼Œé€šè¿‡è‡ªæˆ‘ç›‘ç£å­¦ä¹ è¯„ä¼°ç¥ç»æ¸²æŸ“åœºæ™¯çš„è´¨é‡ã€‚ä¼ ç»Ÿè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ä¸»è¦ä¾èµ–â€œåŒä¸€å®ä¾‹ï¼Œç›¸ä¼¼è¡¨ç¤ºâ€å‡è®¾å’Œå¤§é‡æ•°æ®é›†ï¼Œä½†è¿™ä¸€å‡è®¾å¹¶ä¸é€‚ç”¨äºNSSè´¨é‡è¯„ä¼°ã€‚å› æ­¤ï¼ŒNVS-SQAé‡‡ç”¨å¯å‘å¼çº¿ç´¢å’Œè´¨é‡åˆ†æ•°ä½œä¸ºå­¦ä¹ ç›®æ ‡ï¼Œå¹¶é€šè¿‡å¯¹æ¯”é…å¯¹å‡†å¤‡è¿‡ç¨‹æé«˜å­¦ä¹ æ•ˆç‡å’Œæ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNVS-SQAåœ¨æ— å‚è€ƒæ–¹æ³•ä¸Šå¤§å¹…è¶…è¶Šå…¶ä»–æ–¹æ³•ï¼Œå¹¶åœ¨å…¨å‚è€ƒæ–¹æ³•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>NVS-SQAæ˜¯ä¸€ä¸ªç”¨äºç¥ç»åˆæˆåœºæ™¯ï¼ˆNSSï¼‰è´¨é‡è¯„ä¼°çš„æ— å‚è€ƒè´¨é‡è¯„ä¼°æ–¹æ³•ã€‚</li>
<li>NVS-SQAé€šè¿‡è‡ªæˆ‘ç›‘ç£å­¦ä¹ ï¼Œæ— éœ€ä¾èµ–äººç±»æ ‡ç­¾è¿›è¡Œå­¦ä¹ ã€‚</li>
<li>ä¼ ç»Ÿè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•çš„â€œåŒä¸€å®ä¾‹ï¼Œç›¸ä¼¼è¡¨ç¤ºâ€å‡è®¾åœ¨NSSè´¨é‡è¯„ä¼°ä¸­ä¸é€‚ç”¨ã€‚</li>
<li>NVS-SQAé‡‡ç”¨å¯å‘å¼çº¿ç´¢å’Œè´¨é‡åˆ†æ•°ä½œä¸ºå­¦ä¹ ç›®æ ‡ã€‚</li>
<li>NVS-SQAé€šè¿‡å¯¹æ¯”é…å¯¹å‡†å¤‡è¿‡ç¨‹æé«˜å­¦ä¹ æ•ˆç‡å’Œæ•ˆæœã€‚</li>
<li>NVS-SQAåœ¨å¤šç§æ— å‚è€ƒæ–¹æ³•ä¸Šè¡¨ç°æ˜¾è‘—ä¼˜è¶Šï¼Œå¤§å¹…è¶…è¶Šå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06488">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06488v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06488v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06488v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06488v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06488v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.06488v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Arc2Avatar-Generating-Expressive-3D-Avatars-from-a-Single-Image-via-ID-Guidance"><a href="#Arc2Avatar-Generating-Expressive-3D-Avatars-from-a-Single-Image-via-ID-Guidance" class="headerlink" title="Arc2Avatar: Generating Expressive 3D Avatars from a Single Image via ID   Guidance"></a>Arc2Avatar: Generating Expressive 3D Avatars from a Single Image via ID   Guidance</h2><p><strong>Authors:Dimitrios Gerogiannis, Foivos Paraperas Papantoniou, Rolandos Alexandros Potamias, Alexandros Lattas, Stefanos Zafeiriou</strong></p>
<p>Inspired by the effectiveness of 3D Gaussian Splatting (3DGS) in reconstructing detailed 3D scenes within multi-view setups and the emergence of large 2D human foundation models, we introduce Arc2Avatar, the first SDS-based method utilizing a human face foundation model as guidance with just a single image as input. To achieve that, we extend such a model for diverse-view human head generation by fine-tuning on synthetic data and modifying its conditioning. Our avatars maintain a dense correspondence with a human face mesh template, allowing blendshape-based expression generation. This is achieved through a modified 3DGS approach, connectivity regularizers, and a strategic initialization tailored for our task. Additionally, we propose an optional efficient SDS-based correction step to refine the blendshape expressions, enhancing realism and diversity. Experiments demonstrate that Arc2Avatar achieves state-of-the-art realism and identity preservation, effectively addressing color issues by allowing the use of very low guidance, enabled by our strong identity prior and initialization strategy, without compromising detail. Please visit <a target="_blank" rel="noopener" href="https://arc2avatar.github.io/">https://arc2avatar.github.io</a> for more resources. </p>
<blockquote>
<p>å—3Dé«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰åœ¨å¤šè§†è§’è®¾ç½®ä¸­é‡å»ºè¯¦ç»†3Dåœºæ™¯çš„æœ‰æ•ˆæ€§ä»¥åŠå¤§å‹äºŒç»´äººç±»åŸºç¡€æ¨¡å‹çš„å‡ºç°å¯å‘ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Arc2Avatarã€‚è¿™æ˜¯åŸºäºSDSçš„é¦–ä¸ªæ–¹æ³•ï¼Œä»…ä½¿ç”¨å•å¼ å›¾åƒä½œä¸ºè¾“å…¥ï¼Œä»¥äººç±»é¢éƒ¨åŸºç¡€æ¨¡å‹ä¸ºæŒ‡å¯¼ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é€šè¿‡å¾®è°ƒåˆæˆæ•°æ®å¹¶ä¿®æ”¹å…¶æ¡ä»¶ï¼Œå°†è¯¥æ¨¡å‹æ‰©å±•ç”¨äºå¤šè§†è§’çš„äººå¤´ç”Ÿæˆã€‚æˆ‘ä»¬çš„è™šæ‹Ÿè§’è‰²ä¸ä¸€ä¸ªäººè„¸ç½‘æ ¼æ¨¡æ¿ä¿æŒå¯†é›†çš„å¯¹åº”å…³ç³»ï¼Œå…è®¸åŸºäºblendshapeçš„è¡¨è¾¾å¼ç”Ÿæˆã€‚è¿™æ˜¯é€šè¿‡ä¸€ä¸ªä¿®æ”¹çš„3DGSæ–¹æ³•ã€è¿æ¥æ­£åˆ™åŒ–ä»¥åŠé’ˆå¯¹æˆ‘ä»¬ä»»åŠ¡çš„æˆ˜ç•¥åˆå§‹åŒ–æ¥å®ç°çš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯é€‰çš„åŸºäºSDSçš„æ ¡æ­£æ­¥éª¤ï¼Œä»¥ä¼˜åŒ–blendshapeè¡¨è¾¾å¼ï¼Œæé«˜çœŸå®æ„Ÿå’Œå¤šæ ·æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒArc2Avatarè¾¾åˆ°äº†æœ€å…ˆè¿›çš„çœŸå®æ„Ÿå’Œèº«ä»½ä¿ç•™æ•ˆæœï¼Œé€šè¿‡å…è®¸ä½¿ç”¨éå¸¸ä½çš„æŒ‡å¯¼æœ‰æ•ˆåœ°è§£å†³äº†é¢œè‰²é—®é¢˜ï¼Œè¿™å¾—ç›Šäºæˆ‘ä»¬å¼ºå¤§çš„èº«ä»½ä¼˜å…ˆæƒå’Œåˆå§‹åŒ–ç­–ç•¥ï¼Œä¸ä¼šæŸå¤±ç»†èŠ‚ã€‚æ›´å¤šèµ„æºè¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://arc2avatar.github.io/">https://arc2avatar.github.io</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05379v2">PDF</a> Project Page <a target="_blank" rel="noopener" href="https://arc2avatar.github.io/">https://arc2avatar.github.io</a></p>
<p><strong>Summary</strong></p>
<p>Arc2Avataræ˜¯åŸºäºå•å¼ å›¾åƒçš„äººè„¸é‡å»ºæ–¹æ³•ï¼Œåˆ©ç”¨ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œç»“åˆäººè„¸åŸºç¡€æ¨¡å‹ï¼Œå®ç°å¤šè§’åº¦ä¸‹çš„äººè„¸é‡å»ºã€‚é€šè¿‡å¾®è°ƒåˆæˆæ•°æ®å¹¶ä¿®æ”¹å…¶æ¡ä»¶ï¼Œæ‰©å±•æ¨¡å‹ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„å¤´éƒ¨è§†å›¾ã€‚åˆ©ç”¨å¯†é›†å¯¹åº”çš„äººè„¸ç½‘æ ¼æ¨¡æ¿å®ç°è¡¨æƒ…ç”Ÿæˆï¼Œå¹¶æå‡ºåŸºäºSDSçš„é«˜æ•ˆä¿®æ­£æ­¥éª¤ï¼Œæé«˜è¡¨æƒ…çš„çœŸå®æ€§å’Œå¤šæ ·æ€§ã€‚Arc2Avataråœ¨çœŸå®æ„Ÿå’Œèº«ä»½ä¿ç•™æ–¹é¢è¾¾åˆ°é¢†å…ˆæ°´å¹³ï¼Œé€šè¿‡ä½æŒ‡å¯¼ç­–ç•¥è§£å†³è‰²å½©é—®é¢˜ï¼ŒåŒæ—¶ä¸æŸå¤±ç»†èŠ‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Arc2Avatarç»“åˆäº†ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰æŠ€æœ¯å’Œäººè„¸åŸºç¡€æ¨¡å‹ï¼Œå®ç°äº†åŸºäºå•å¼ å›¾åƒçš„äººè„¸é‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒåˆæˆæ•°æ®å¹¶ä¿®æ”¹æ¡ä»¶ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–çš„å¤´éƒ¨è§†å›¾ã€‚</li>
<li>Arc2Avataråˆ©ç”¨å¯†é›†å¯¹åº”çš„äººè„¸ç½‘æ ¼æ¨¡æ¿å®ç°è¡¨æƒ…ç”Ÿæˆã€‚</li>
<li>SDSè¢«ç”¨äºä¸€ä¸ªé«˜æ•ˆçš„ä¿®æ­£æ­¥éª¤ï¼Œæé«˜äº†è¡¨æƒ…çš„çœŸå®æ€§å’Œå¤šæ ·æ€§ã€‚</li>
<li>Arc2Avatarè¾¾åˆ°äº†å…ˆè¿›çš„çœŸå®æ„Ÿå’Œèº«ä»½ä¿ç•™æ°´å¹³ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡ä½æŒ‡å¯¼ç­–ç•¥è§£å†³äº†è‰²å½©é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒäº†ç»†èŠ‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05379">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.05379v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.05379v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.05379v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="DehazeGS-Seeing-Through-Fog-with-3D-Gaussian-Splatting"><a href="#DehazeGS-Seeing-Through-Fog-with-3D-Gaussian-Splatting" class="headerlink" title="DehazeGS: Seeing Through Fog with 3D Gaussian Splatting"></a>DehazeGS: Seeing Through Fog with 3D Gaussian Splatting</h2><p><strong>Authors:Jinze Yu, Yiqun Wang, Zhengda Lu, Jianwei Guo, Yong Li, Hongxing Qin, Xiaopeng Zhang</strong></p>
<p>Current novel view synthesis tasks primarily rely on high-quality and clear images. However, in foggy scenes, scattering and attenuation can significantly degrade the reconstruction and rendering quality. Although NeRF-based dehazing reconstruction algorithms have been developed, their use of deep fully connected neural networks and per-ray sampling strategies leads to high computational costs. Moreover, NeRFâ€™s implicit representation struggles to recover fine details from hazy scenes. In contrast, recent advancements in 3D Gaussian Splatting achieve high-quality 3D scene reconstruction by explicitly modeling point clouds into 3D Gaussians. In this paper, we propose leveraging the explicit Gaussian representation to explain the foggy image formation process through a physically accurate forward rendering process. We introduce DehazeGS, a method capable of decomposing and rendering a fog-free background from participating media using only muti-view foggy images as input. We model the transmission within each Gaussian distribution to simulate the formation of fog. During this process, we jointly learn the atmospheric light and scattering coefficient while optimizing the Gaussian representation of the hazy scene. In the inference stage, we eliminate the effects of scattering and attenuation on the Gaussians and directly project them onto a 2D plane to obtain a clear view. Experiments on both synthetic and real-world foggy datasets demonstrate that DehazeGS achieves state-of-the-art performance in terms of both rendering quality and computational efficiency. </p>
<blockquote>
<p>å½“å‰çš„æ–°å‹è§†å›¾åˆæˆä»»åŠ¡ä¸»è¦ä¾èµ–äºé«˜è´¨é‡ã€æ¸…æ™°çš„å›¾åƒã€‚ç„¶è€Œï¼Œåœ¨é›¾å¤©åœºæ™¯ä¸­ï¼Œæ•£å°„å’Œè¡°å‡ä¼šæ˜¾è‘—å½±å“é‡å»ºå’Œæ¸²æŸ“è´¨é‡ã€‚å°½ç®¡å·²ç»å¼€å‘äº†åŸºäºNeRFçš„å»é›¾é‡å»ºç®—æ³•ï¼Œä½†å®ƒä»¬ä½¿ç”¨æ·±åº¦å…¨è¿æ¥ç¥ç»ç½‘ç»œå’ŒæŒ‰å°„çº¿é‡‡æ ·ç­–ç•¥ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚æ­¤å¤–ï¼ŒNeRFçš„éšå¼è¡¨ç¤ºå¾ˆéš¾ä»é›¾å¤©åœºæ™¯ä¸­æ¢å¤ç»†èŠ‚ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯çš„æœ€æ–°è¿›å±•é€šè¿‡æ˜¾å¼å»ºæ¨¡ç‚¹äº‘ä¸º3Dé«˜æ–¯å®ç°äº†é«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯é‡å»ºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨æ˜¾å¼çš„é«˜æ–¯è¡¨ç¤ºï¼Œé€šè¿‡ä¸€ä¸ªç‰©ç†å‡†ç¡®çš„å‰å‘æ¸²æŸ“è¿‡ç¨‹æ¥è§£é‡Šé›¾å¤©å›¾åƒçš„å½¢æˆè¿‡ç¨‹ã€‚æˆ‘ä»¬ä»‹ç»äº†DehazeGSæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»å‚ä¸ä»‹è´¨ä¸­åˆ†è§£å¹¶æ¸²æŸ“æ— é›¾èƒŒæ™¯ï¼Œä»…ä½¿ç”¨å¤šè§†è§’é›¾å¤©å›¾åƒä½œä¸ºè¾“å…¥ã€‚æˆ‘ä»¬æ¨¡æ‹Ÿäº†æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒå†…çš„ä¼ è¾“ï¼Œä»¥æ¨¡æ‹Ÿé›¾çš„å½¢æˆã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è”åˆå­¦ä¹ å¤§æ°”å…‰å’Œæ•£å°„ç³»æ•°ï¼ŒåŒæ—¶ä¼˜åŒ–é›¾å¤©åœºæ™¯çš„é«˜æ–¯è¡¨ç¤ºã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬æ¶ˆé™¤äº†æ•£å°„å’Œè¡°å‡å¯¹é«˜æ–¯çš„å½±å“ï¼Œå¹¶å°†å…¶ç›´æ¥æŠ•å½±åˆ°äºŒç»´å¹³é¢ä¸Šä»¥è·å¾—æ¸…æ™°è§†å›¾ã€‚åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„é›¾å¤©æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDehazeGSåœ¨æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03659v2">PDF</a> 9 pages,4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäº3Dé«˜æ–¯æ•£æ–‘ï¼ˆGaussian Splattingï¼‰çš„å»é›¾æ–¹æ³•ï¼Œç§°ä¸ºDehazeGSã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ˜¾å¼é«˜æ–¯è¡¨ç¤ºæ¥æ¨¡æ‹Ÿé›¾å¤©å›¾åƒçš„å½¢æˆè¿‡ç¨‹ï¼Œé€šè¿‡å¤šè§†è§’é›¾å¤©å›¾åƒè¾“å…¥ï¼Œåˆ†è§£å¹¶æ¸²æŸ“å‡ºæ— é›¾çš„èƒŒæ™¯ã€‚è¯¥æ–¹æ³•æ¨¡æ‹Ÿé›¾çš„å½¢æˆè¿‡ç¨‹ï¼Œå¹¶ä¼˜åŒ–é«˜æ–¯è¡¨ç¤ºæ³•ï¼ŒåŒæ—¶å­¦ä¹ å¤§æ°”å…‰å’Œæ•£å°„ç³»æ•°ã€‚åœ¨æ¨æ–­é˜¶æ®µï¼Œæ¶ˆé™¤é«˜æ–¯ä¸Šçš„æ•£å°„å’Œè¡°å‡æ•ˆåº”ï¼Œç›´æ¥å°†å…¶æŠ•å½±åˆ°äºŒç»´å¹³é¢ä¸Šä»¥è·å–æ¸…æ™°çš„è§†å›¾ã€‚å®éªŒè¡¨æ˜ï¼ŒDehazeGSåœ¨æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å‡è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰è§†å›¾åˆæˆä»»åŠ¡ä¸»è¦ä¾èµ–äºé«˜è´¨é‡æ¸…æ™°å›¾åƒï¼Œä½†åœ¨é›¾å¤©åœºæ™¯ä¸­ï¼Œæ•£å°„å’Œè¡°å‡ä¼šä¸¥é‡å½±å“é‡å»ºå’Œæ¸²æŸ“è´¨é‡ã€‚</li>
<li>NeRFåŸºçš„å»é›¾é‡å»ºç®—æ³•è™½ç„¶å­˜åœ¨ï¼Œä½†å…¶æ·±åº¦å…¨è¿æ¥ç¥ç»ç½‘ç»œå’ŒæŒ‰å°„çº¿é‡‡æ ·ç­–ç•¥å¯¼è‡´é«˜è®¡ç®—æˆæœ¬ï¼Œä¸”éš¾ä»¥ä»é›¾åœºæ™¯ä¸­æ¢å¤ç»†èŠ‚ã€‚</li>
<li>3Dé«˜æ–¯æ•£æ–‘ï¼ˆGaussian Splattingï¼‰æ–¹æ³•èƒ½å®ç°é«˜è´¨é‡3Dåœºæ™¯é‡å»ºï¼Œé€šè¿‡æ˜¾å¼å»ºæ¨¡ç‚¹äº‘ä¸º3Dé«˜æ–¯ã€‚</li>
<li>æœ¬æ–‡æå‡ºåˆ©ç”¨æ˜¾å¼é«˜æ–¯è¡¨ç¤ºæ³•ï¼Œé€šè¿‡ç‰©ç†å‡†ç¡®çš„æ­£å‘æ¸²æŸ“è¿‡ç¨‹è§£é‡Šé›¾å¤©å›¾åƒå½¢æˆè¿‡ç¨‹ã€‚</li>
<li>DehazeGSæ–¹æ³•èƒ½å¤Ÿåˆ†è§£å¹¶æ¸²æŸ“å‡ºæ— é›¾èƒŒæ™¯ï¼Œåˆ©ç”¨å¤šè§†è§’é›¾å¤©å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæ¨¡æ‹Ÿé›¾çš„å½¢æˆè¿‡ç¨‹ï¼Œå¹¶ä¼˜åŒ–é«˜æ–¯è¡¨ç¤ºæ³•ã€‚</li>
<li>DehazeGSæ–¹æ³•åœ¨å­¦ä¹ å¤§æ°”å…‰å’Œæ•£å°„ç³»æ•°çš„åŒæ—¶ï¼Œèƒ½æ¶ˆé™¤é«˜æ–¯ä¸Šçš„æ•£å°„å’Œè¡°å‡æ•ˆåº”ï¼Œç›´æ¥æŠ•å½±åˆ°äºŒç»´å¹³é¢ä¸Šè·å–æ¸…æ™°è§†å›¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03659">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.03659v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.03659v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2501.03659v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="HeadGAP-Few-Shot-3D-Head-Avatar-via-Generalizable-Gaussian-Priors"><a href="#HeadGAP-Few-Shot-3D-Head-Avatar-via-Generalizable-Gaussian-Priors" class="headerlink" title="HeadGAP: Few-Shot 3D Head Avatar via Generalizable Gaussian Priors"></a>HeadGAP: Few-Shot 3D Head Avatar via Generalizable Gaussian Priors</h2><p><strong>Authors:Xiaozheng Zheng, Chao Wen, Zhaohu Li, Weiyi Zhang, Zhuo Su, Xu Chang, Yang Zhao, Zheng Lv, Xiaoyuan Zhang, Yongjie Zhang, Guidong Wang, Lan Xu</strong></p>
<p>In this paper, we present a novel 3D head avatar creation approach capable of generalizing from few-shot in-the-wild data with high-fidelity and animatable robustness. Given the underconstrained nature of this problem, incorporating prior knowledge is essential. Therefore, we propose a framework comprising prior learning and avatar creation phases. The prior learning phase leverages 3D head priors derived from a large-scale multi-view dynamic dataset, and the avatar creation phase applies these priors for few-shot personalization. Our approach effectively captures these priors by utilizing a Gaussian Splatting-based auto-decoder network with part-based dynamic modeling. Our method employs identity-shared encoding with personalized latent codes for individual identities to learn the attributes of Gaussian primitives. During the avatar creation phase, we achieve fast head avatar personalization by leveraging inversion and fine-tuning strategies. Extensive experiments demonstrate that our model effectively exploits head priors and successfully generalizes them to few-shot personalization, achieving photo-realistic rendering quality, multi-view consistency, and stable animation. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„3Då¤´éƒ¨åŒ–èº«åˆ›å»ºæ–¹æ³•ï¼Œèƒ½å¤Ÿä»å°‘é‡é‡å¤–æ•°æ®ä¸­è¿›è¡Œé«˜åº¦ä¿çœŸå’Œå¯åŠ¨ç”»çš„ç¨³å¥æ€§æ¨å¹¿ã€‚é‰´äºè¿™ä¸ªé—®é¢˜çš„çº¦æŸæ€§è¾ƒå¼±ï¼Œèå…¥å…ˆéªŒçŸ¥è¯†è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŒ…å«å…ˆéªŒå­¦ä¹ é˜¶æ®µå’ŒåŒ–èº«åˆ›å»ºé˜¶æ®µçš„æ¡†æ¶ã€‚å…ˆéªŒå­¦ä¹ é˜¶æ®µåˆ©ç”¨å¤§è§„æ¨¡å¤šè§†è§’åŠ¨æ€æ•°æ®é›†æ¨å¯¼å‡ºçš„3Då¤´éƒ¨å…ˆéªŒçŸ¥è¯†ï¼Œè€ŒåŒ–èº«åˆ›å»ºé˜¶æ®µåˆ™åº”ç”¨è¿™äº›å…ˆéªŒçŸ¥è¯†æ¥è¿›è¡Œå°‘é‡ä¸ªæ€§åŒ–è®¾ç½®ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡åˆ©ç”¨åŸºäºé«˜æ–¯æ‹¼è´´æŠ€æœ¯çš„è‡ªåŠ¨è§£ç ç½‘ç»œä»¥åŠåŸºäºéƒ¨åˆ†çš„åŠ¨æ€å»ºæ¨¡æ¥æœ‰æ•ˆåœ°æ•æ‰è¿™äº›å…ˆéªŒçŸ¥è¯†ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨å…·æœ‰ä¸ªæ€§åŒ–æ½œåœ¨ä»£ç çš„å…±äº«èº«ä»½ç¼–ç æ¥å­¦ä¹ é«˜æ–¯åŸå§‹æ•°æ®çš„å±æ€§ã€‚åœ¨åŒ–èº«åˆ›å»ºé˜¶æ®µï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨åæ¼”å’Œå¾®è°ƒç­–ç•¥å®ç°äº†å¿«é€Ÿçš„å¤´éƒ¨åŒ–èº«ä¸ªæ€§åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å¤´éƒ¨å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶æˆåŠŸå°†å…¶æ¨å¹¿åˆ°å°‘é‡ä¸ªæ€§åŒ–è®¾ç½®ä¸­ï¼Œå®ç°äº†ç…§ç‰‡çº§çš„æ¸²æŸ“è´¨é‡ã€å¤šè§†è§’ä¸€è‡´æ€§å’Œç¨³å®šçš„åŠ¨ç”»æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.06019v2">PDF</a> Accepted to 3DV 2025. Project page: <a target="_blank" rel="noopener" href="https://headgap.github.io/">https://headgap.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸‰ç»´å¤´éƒ¨åŒ–èº«åˆ›å»ºæ–¹æ³•ï¼Œèƒ½å¤Ÿä»å°‘é‡çœŸå®åœºæ™¯æ•°æ®ä¸­å®ç°é«˜ä¿çœŸã€å¯åŠ¨ç”»çš„ç¨³å¥æ€§æ³›åŒ–ã€‚é’ˆå¯¹æ­¤é—®é¢˜çš„çº¦æŸè¾ƒå°‘ï¼Œå› æ­¤èå…¥å…ˆéªŒçŸ¥è¯†è‡³å…³é‡è¦ã€‚æ–‡ç« æå‡ºäº†ä¸€ä¸ªåŒ…å«å…ˆéªŒå­¦ä¹ é˜¶æ®µå’ŒåŒ–èº«åˆ›å»ºé˜¶æ®µçš„æ¡†æ¶ã€‚å…ˆéªŒå­¦ä¹ é˜¶æ®µåˆ©ç”¨å¤§è§„æ¨¡å¤šè§†è§’åŠ¨æ€æ•°æ®é›†æå–çš„å¤´éƒ¨ä¸‰ç»´å…ˆéªŒä¿¡æ¯ï¼Œè€ŒåŒ–èº«åˆ›å»ºé˜¶æ®µåˆ™åº”ç”¨è¿™äº›å…ˆéªŒè¿›è¡Œå°‘é‡ä¸ªæ€§åŒ–è®¾ç½®ã€‚è¯¥ç ”ç©¶é‡‡ç”¨åŸºäºé«˜æ–¯æ–‘ç‚¹æŠ€æœ¯çš„è‡ªåŠ¨è§£ç ç½‘ç»œè¿›è¡Œå»ºæ¨¡ï¼Œå€ŸåŠ©èº«ä»½å…±äº«ç¼–ç å’Œä¸ªæ€§åŒ–æ½œåœ¨ä»£ç å­¦ä¹ é«˜æ–¯åŸå§‹æ•°æ®çš„å±æ€§ã€‚åœ¨åŒ–èº«åˆ›å»ºé˜¶æ®µï¼Œé€šè¿‡åæ¼”å’Œå¾®è°ƒç­–ç•¥å®ç°å¿«é€Ÿå¤´éƒ¨åŒ–èº«ä¸ªæ€§åŒ–ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹èƒ½æœ‰æ•ˆåˆ©ç”¨å¤´éƒ¨å…ˆéªŒä¿¡æ¯ï¼ŒæˆåŠŸæ³›åŒ–è‡³å°‘é‡ä¸ªæ€§åŒ–åœºæ™¯ï¼Œå®ç°ç…§ç‰‡çº§æ¸²æŸ“è´¨é‡ã€å¤šè§†è§’ä¸€è‡´æ€§å’Œç¨³å®šåŠ¨ç”»æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°å‹ä¸‰ç»´å¤´éƒ¨åŒ–èº«åˆ›å»ºæ–¹æ³•ï¼Œå¯ä»å°‘é‡çœŸå®åœºæ™¯æ•°æ®ä¸­å®ç°é«˜ä¿çœŸå’Œå¯åŠ¨ç”»çš„ç¨³å¥æ€§æ³›åŒ–ã€‚</li>
<li>èå…¥å…ˆéªŒçŸ¥è¯†è‡³å…³é‡è¦ï¼Œä¸ºæ­¤æ–‡ç« æ„å»ºäº†ä¸€ä¸ªåŒ…å«å…ˆéªŒå­¦ä¹ é˜¶æ®µå’ŒåŒ–èº«åˆ›å»ºé˜¶æ®µçš„æ¡†æ¶ã€‚</li>
<li>å…ˆéªŒå­¦ä¹ é˜¶æ®µåˆ©ç”¨å¤§è§„æ¨¡å¤šè§†è§’åŠ¨æ€æ•°æ®é›†æå–å¤´éƒ¨ä¸‰ç»´å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>åŒ–èº«åˆ›å»ºé˜¶æ®µåº”ç”¨è¿™äº›å…ˆéªŒè¿›è¡Œä¸ªæ€§åŒ–è®¾ç½®ï¼Œå¿«é€Ÿåˆ›å»ºå¤´éƒ¨åŒ–èº«ã€‚</li>
<li>é‡‡ç”¨åŸºäºé«˜æ–¯æ–‘ç‚¹æŠ€æœ¯çš„è‡ªåŠ¨è§£ç ç½‘ç»œè¿›è¡Œå»ºæ¨¡ï¼Œå­¦ä¹ é«˜æ–¯åŸå§‹æ•°æ®çš„å±æ€§ã€‚</li>
<li>é€šè¿‡åæ¼”å’Œå¾®è°ƒç­–ç•¥å®ç°å¿«é€Ÿå¤´éƒ¨åŒ–èº«ä¸ªæ€§åŒ–åˆ›å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.06019">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2408.06019v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2408.06019v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2408.06019v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2408.06019v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2408.06019v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Gaussian-Eigen-Models-for-Human-Heads"><a href="#Gaussian-Eigen-Models-for-Human-Heads" class="headerlink" title="Gaussian Eigen Models for Human Heads"></a>Gaussian Eigen Models for Human Heads</h2><p><strong>Authors:Wojciech Zielonka, Timo Bolkart, Thabo Beeler, Justus Thies</strong></p>
<p>Current personalized neural head avatars face a trade-off: lightweight models lack detail and realism, while high-quality, animatable avatars require significant computational resources, making them unsuitable for commodity devices. To address this gap, we introduce Gaussian Eigen Models (GEM), which provide high-quality, lightweight, and easily controllable head avatars. GEM utilizes 3D Gaussian primitives for representing the appearance combined with Gaussian splatting for rendering. Building on the success of mesh-based 3D morphable face models (3DMM), we define GEM as an ensemble of linear eigenbases for representing the head appearance of a specific subject. In particular, we construct linear bases to represent the position, scale, rotation, and opacity of the 3D Gaussians. This allows us to efficiently generate Gaussian primitives of a specific head shape by a linear combination of the basis vectors, only requiring a low-dimensional parameter vector that contains the respective coefficients. We propose to construct these linear bases (GEM) by distilling high-quality compute-intense CNN-based Gaussian avatar models that can generate expression-dependent appearance changes like wrinkles. These high-quality models are trained on multi-view videos of a subject and are distilled using a series of principal component analyses. Once we have obtained the bases that represent the animatable appearance space of a specific human, we learn a regressor that takes a single RGB image as input and predicts the low-dimensional parameter vector that corresponds to the shown facial expression. In a series of experiments, we compare GEMâ€™s self-reenactment and cross-person reenactment results to state-of-the-art 3D avatar methods, demonstrating GEMâ€™s higher visual quality and better generalization to new expressions. </p>
<blockquote>
<p>å½“å‰ä¸ªæ€§åŒ–ç¥ç»å¤´éƒ¨åŒ–èº«é¢ä¸´ä¸€ä¸ªæƒè¡¡ï¼šè½»é‡çº§æ¨¡å‹ç¼ºä¹ç»†èŠ‚å’ŒçœŸå®æ„Ÿï¼Œè€Œé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„åŒ–èº«éœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºï¼Œä½¿å¾—å®ƒä»¬ä¸é€‚åˆæ™®é€šè®¾å¤‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†é«˜æ–¯ç‰¹å¾æ¨¡å‹ï¼ˆGEMï¼‰ï¼Œå®ƒæä¾›é«˜è´¨é‡ã€è½»ä¾¿ä¸”æ˜“äºæ§åˆ¶çš„å¤´éƒ¨åŒ–èº«ã€‚GEMä½¿ç”¨3Dé«˜æ–¯åŸå§‹å›¾å½¢æ¥è¡¨ç¤ºå¤–è§‚ï¼Œå¹¶ç»“åˆé«˜æ–¯æ¶‚æŠ¹è¿›è¡Œæ¸²æŸ“ã€‚åŸºäºåŸºäºç½‘æ ¼çš„3Då¯å˜å½¢é¢éƒ¨æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æˆåŠŸï¼Œæˆ‘ä»¬å°†GEMå®šä¹‰ä¸ºè¡¨ç¤ºç‰¹å®šä¸»ä½“å¤´éƒ¨å¤–è§‚çš„çº¿æ€§ç‰¹å¾åŸºé›†åˆã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æ„å»ºäº†è¡¨ç¤ºä½ç½®ã€å°ºåº¦ã€æ—‹è½¬å’Œé€æ˜åº¦çš„çº¿æ€§åŸºã€‚è¿™å…è®¸æˆ‘ä»¬é€šè¿‡çº¿æ€§ç»„åˆåŸºå‘é‡æ¥æœ‰æ•ˆåœ°ç”Ÿæˆå…·æœ‰ç‰¹å®šå¤´éƒ¨å½¢çŠ¶çš„é«˜æ–¯åŸå§‹å›¾å½¢ï¼Œåªéœ€è¦ä¸€ä¸ªåŒ…å«ç›¸åº”ç³»æ•°çš„ä½ç»´å‚æ•°å‘é‡ã€‚æˆ‘ä»¬æè®®é€šè¿‡æç‚¼é«˜è´¨é‡çš„è®¡ç®—å¯†é›†å‹CNNé«˜æ–¯åŒ–èº«æ¨¡å‹æ¥æ„å»ºè¿™äº›çº¿æ€§åŸºï¼ˆGEMï¼‰ï¼Œè¯¥æ¨¡å‹å¯ä»¥ç”Ÿæˆä¸è¡¨æƒ…ç›¸å…³çš„å¤–è§‚å˜åŒ–ï¼Œå¦‚çš±çº¹ã€‚è¿™äº›é«˜è´¨é‡æ¨¡å‹æ˜¯åœ¨ä¸»ä½“çš„å¤šè§†è§’è§†é¢‘ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä½¿ç”¨ä¸€ç³»åˆ—ä¸»æˆåˆ†åˆ†æè¿›è¡Œæç‚¼ã€‚ä¸€æ—¦æˆ‘ä»¬è·å¾—äº†ä»£è¡¨ç‰¹å®šäººç±»å¯åŠ¨ç”»å¤–è§‚ç©ºé—´çš„åŸºåœ°ï¼Œæˆ‘ä»¬å°±ä¼šå­¦ä¹ ä¸€ä¸ªå›å½’å™¨ï¼Œå®ƒæ¥å—å•å¼ RGBå›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶é¢„æµ‹ä¸æ‰€ç¤ºé¢éƒ¨è¡¨æƒ…ç›¸å¯¹åº”çš„ä½ç»´å‚æ•°å‘é‡ã€‚åœ¨ä¸€ç³»åˆ—å®éªŒä¸­ï¼Œæˆ‘ä»¬å°†GEMçš„è‡ªæˆ‘å†æ¼”ç»å’Œè·¨äººå†æ¼”ç»ç»“æœä¸æœ€å…ˆè¿›çš„3DåŒ–èº«æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜äº†GEMæ›´é«˜çš„è§†è§‰è´¨é‡å’Œå¯¹æ–°è¡¨æƒ…æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.04545v2">PDF</a> <a target="_blank" rel="noopener" href="https://zielon.github.io/gem/">https://zielon.github.io/gem/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯ç‰¹å¾æ¨¡å‹ï¼ˆGEMï¼‰çš„ä¸ªæ€§åŒ–ç¥ç»å¤´éƒ¨åŒ–èº«è§£å†³æ–¹æ¡ˆï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿è¯é«˜è´¨é‡çš„åŒæ—¶ï¼Œå®ç°è½»é‡åŒ–ä¸”æ˜“äºæ§åˆ¶çš„å¤´éƒ¨åŒ–èº«ã€‚GEMé€šè¿‡ç»“åˆ3Dé«˜æ–¯åŸå§‹å›¾å½¢å’Œé«˜æ–¯æ‹¼æ¥æ¸²æŸ“æŠ€æœ¯ï¼ŒæˆåŠŸå¼¥è¡¥äº†è½»é‡åŒ–æ¨¡å‹ç¼ºä¹ç»†èŠ‚å’ŒçœŸå®æ„Ÿï¼Œä»¥åŠé«˜è´¨é‡å¯åŠ¨ç”»åŒ–èº«éœ€è¦å¤§é‡è®¡ç®—èµ„æºçš„å·®è·ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æœ€å…ˆè¿›çš„3DåŒ–èº«æ–¹æ³•ç›¸æ¯”ï¼ŒGEMåœ¨è‡ªæˆ‘é‡æ¼”å’Œè·¨äººé‡æ¼”æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„è§†è§‰è´¨é‡å’Œæ›´å¥½çš„æ–°è¡¨æƒ…æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰ä¸ªæ€§åŒ–ç¥ç»å¤´éƒ¨åŒ–èº«é¢ä¸´æƒè¡¡ï¼šè½»é‡åŒ–æ¨¡å‹ç¼ºä¹ç»†èŠ‚å’ŒçœŸå®æ€§ï¼Œè€Œé«˜è´¨é‡å¯åŠ¨ç”»åŒ–èº«éœ€è¦å¤§é‡è®¡ç®—èµ„æºï¼Œä¸é€‚ç”¨äºæ™®é€šè®¾å¤‡ã€‚</li>
<li>æå‡ºé«˜æ–¯ç‰¹å¾æ¨¡å‹ï¼ˆGEMï¼‰ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå®ç°é«˜è´¨é‡ã€è½»é‡åŒ–ä¸”æ˜“äºæ§åˆ¶çš„å¤´éƒ¨åŒ–èº«ã€‚</li>
<li>GEMåˆ©ç”¨3Dé«˜æ–¯åŸå§‹å›¾å½¢å’ŒGaussian splattingæ¸²æŸ“æŠ€æœ¯ï¼Œç»“åˆmesh-based 3D morphable face modelsï¼ˆ3DMMï¼‰çš„æˆåŠŸç»éªŒï¼Œå®šä¹‰äº†ä¸€ä¸ªç‰¹å®šå¤´éƒ¨å¤–è§‚çš„çº¿æ€§ç‰¹å¾åŸºé›†åˆã€‚</li>
<li>é€šè¿‡è’¸é¦è®¡ç®—å¯†é›†å‹CNNåŸºé«˜æ–¯åŒ–èº«æ¨¡å‹æ„å»ºè¿™äº›çº¿æ€§ç‰¹å¾åŸºï¼ˆGEMï¼‰ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆè¡¨æƒ…ç›¸å…³çš„å¤–è§‚å˜åŒ–ï¼Œå¦‚çš±çº¹ã€‚</li>
<li>é€šè¿‡ä¸»æˆåˆ†åˆ†æç³»åˆ—å¯¹é«˜è´¨é‡æ¨¡å‹è¿›è¡Œè’¸é¦ä»¥è·å–ç‰¹å¾åŸºã€‚</li>
<li>å­¦ä¹ ä¸€ä¸ªå›å½’å™¨ï¼Œä»¥å•å¼ RGBå›¾åƒä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸æ‰€ç¤ºé¢éƒ¨è¡¨æƒ…ç›¸å¯¹åº”çš„ä½ç»´å‚æ•°å‘é‡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æœ€å…ˆè¿›çš„3DåŒ–èº«æ–¹æ³•ç›¸æ¯”ï¼ŒGEMåœ¨è‡ªæˆ‘é‡æ¼”å’Œè·¨äººé‡æ¼”æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„è§†è§‰è´¨é‡å’Œæ›´å¥½çš„æ–°è¡¨æƒ…æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.04545">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2407.04545v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2407.04545v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2407.04545v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2407.04545v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2407.04545v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Splat-Nav-Safe-Real-Time-Robot-Navigation-in-Gaussian-Splatting-Maps"><a href="#Splat-Nav-Safe-Real-Time-Robot-Navigation-in-Gaussian-Splatting-Maps" class="headerlink" title="Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps"></a>Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps</h2><p><strong>Authors:Timothy Chen, Ola Shorinwa, Joseph Bruno, Aiden Swann, Javier Yu, Weijia Zeng, Keiko Nagami, Philip Dames, Mac Schwager</strong></p>
<p>We present Splat-Nav, a real-time robot navigation pipeline for Gaussian Splatting (GSplat) scenes, a powerful new 3D scene representation. Splat-Nav consists of two components: 1) Splat-Plan, a safe planning module, and 2) Splat-Loc, a robust vision-based pose estimation module. Splat-Plan builds a safe-by-construction polytope corridor through the map based on mathematically rigorous collision constraints and then constructs a B&#39;ezier curve trajectory through this corridor. Splat-Loc provides real-time recursive state estimates given only an RGB feed from an on-board camera, leveraging the point-cloud representation inherent in GSplat scenes. Working together, these modules give robots the ability to recursively re-plan smooth and safe trajectories to goal locations. Goals can be specified with position coordinates, or with language commands by using a semantic GSplat. We demonstrate improved safety compared to point cloud-based methods in extensive simulation experiments. In a total of 126 hardware flights, we demonstrate equivalent safety and speed compared to motion capture and visual odometry, but without a manual frame alignment required by those methods. We show online re-planning at more than 2 Hz and pose estimation at about 25 Hz, an order of magnitude faster than Neural Radiance Field (NeRF)-based navigation methods, thereby enabling real-time navigation. We provide experiment videos on our project page at <a target="_blank" rel="noopener" href="https://chengine.github.io/splatnav/">https://chengine.github.io/splatnav/</a>. Our codebase and ROS nodes can be found at <a target="_blank" rel="noopener" href="https://github.com/chengine/splatnav">https://github.com/chengine/splatnav</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºSplat-Navï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é«˜æ–¯æ‹¼è´´ï¼ˆGSplatï¼‰åœºæ™¯çš„å®æ—¶æœºå™¨äººå¯¼èˆªæµç¨‹ï¼Œæ˜¯ä¸€ç§å¼ºå¤§çš„æ–°å‹3Dåœºæ™¯è¡¨ç¤ºæ–¹æ³•ã€‚Splat-Navç”±ä¸¤ä¸ªç»„ä»¶æ„æˆï¼š1ï¼‰Splat-Planï¼Œä¸€ä¸ªå®‰å…¨è§„åˆ’æ¨¡å—ï¼›2ï¼‰Splat-Locï¼Œä¸€ä¸ªåŸºäºè§†è§‰çš„ç¨³å¥å§¿æ€ä¼°è®¡æ¨¡å—ã€‚Splat-Planåœ¨åœ°å›¾ä¸Šæ„å»ºä¸€ä¸ªåŸºäºæ•°å­¦ä¸¥è°¨ç¢°æ’çº¦æŸçš„æ„é€ å®‰å…¨å¤šé¢ä½“èµ°å»Šï¼Œç„¶ååœ¨è¯¥èµ°å»Šä¸Šæ„å»ºä¸€æ¡è´å¡å°”æ›²çº¿è½¨è¿¹ã€‚Splat-Locä»…å‡­æ¥è‡ªè½¦è½½æ‘„åƒå¤´çš„RGBé¦ˆé€ï¼Œæä¾›å®æ—¶é€’å½’çŠ¶æ€ä¼°è®¡ï¼Œå¹¶åˆ©ç”¨GSplatåœºæ™¯ä¸­çš„ç‚¹äº‘è¡¨ç¤ºã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿé€’å½’åœ°é‡æ–°è§„åˆ’å¹³æ»‘å®‰å…¨çš„è½¨è¿¹ä»¥è¾¾åˆ°ç›®æ ‡ä½ç½®ã€‚ç›®æ ‡å¯ä»¥ç”¨ä½ç½®åæ ‡æŒ‡å®šï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨é€šè¿‡è¯­ä¹‰åŒ–çš„GSplatè¾“å…¥çš„è¯­éŸ³å‘½ä»¤ã€‚æˆ‘ä»¬åœ¨å¹¿æ³›çš„æ¨¡æ‹Ÿå®éªŒä¸­è¯æ˜äº†ä¸åŸºäºç‚¹äº‘çš„æ–¹æ³•ç›¸æ¯”æœ‰æ‰€æé«˜çš„å®‰å…¨æ€§ã€‚åœ¨æ€»å…±çš„126æ¬¡ç¡¬ä»¶é£è¡Œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸è¿åŠ¨æ•è·å’Œè§†è§‰é‡Œç¨‹è®¡ç›¸å½“çš„å®‰å…¨æ€§å’Œé€Ÿåº¦ï¼Œä½†ä¸éœ€è¦è¿™äº›æ–¹æ³•æ‰€éœ€çš„æ‰‹åŠ¨å¸§å¯¹é½ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¶…è¿‡2Hzçš„åœ¨çº¿é‡æ–°è§„åˆ’é€Ÿåº¦å’Œå¤§çº¦æ¯ç§’25å¸§çš„å§¿æ€ä¼°è®¡é€Ÿåº¦ï¼Œè¿™æ¯”åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å¯¼èˆªæ–¹æ³•å¿«ä¸€ä¸ªæ•°é‡çº§ï¼Œä»è€Œå®ç°å®æ—¶å¯¼èˆªã€‚å®éªŒè§†é¢‘è¯·åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢<a target="_blank" rel="noopener" href="https://chengine.github.io/splatnav/%E8%A7%82%E7%9C%8B%E3%80%82%E6%88%91%E4%BB%AC%E7%9A%84%E4%BB%A3%E7%A0%81%E5%BA%93%E5%92%8CROS%E8%8A%82%E7%82%B9%E5%8F%AF%E4%BB%A5%E5%9C%A8https://github.com/chengine/splatnav%E6%89%BE%E5%88%B0%E3%80%82">https://chengine.github.io/splatnav/è§‚çœ‹ã€‚æˆ‘ä»¬çš„ä»£ç åº“å’ŒROSèŠ‚ç‚¹å¯ä»¥åœ¨https://github.com/chengine/splatnavæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.02751v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>Splat-Navä¸ºé«˜æ–¯ç»˜å›¾ï¼ˆGSplatï¼‰åœºæ™¯æä¾›äº†ä¸€ç§å®æ—¶æœºå™¨äººå¯¼èˆªç®¡é“ã€‚å®ƒåŒ…å«ä¸¤ä¸ªç»„ä»¶ï¼šSplat-Planå®‰å…¨è§„åˆ’æ¨¡å—å’ŒSplat-Locç¨³å¥çš„è§†è§‰å§¿æ€ä¼°è®¡æ¨¡å—ã€‚Splat-Planåœ¨åœ°å›¾ä¸Šæ„å»ºäº†ä¸€ä¸ªå®‰å…¨çš„å¤šè¾¹å½¢èµ°å»Šï¼Œå¹¶åŸºäºä¸¥æ ¼çš„æ•°å­¦ç¢°æ’çº¦æŸåœ¨æ­¤èµ°å»Šå†…æ„å»ºäº†ä¸€æ¡Bezieræ›²çº¿è½¨è¿¹ã€‚Splat-Locåˆ©ç”¨GSplatåœºæ™¯çš„ç‚¹äº‘è¡¨ç¤ºï¼Œä»…ä»è½¦è½½ç›¸æœºæä¾›RGBé¦ˆé€æµè¿›è¡Œå®æ—¶é€’å½’çŠ¶æ€ä¼°è®¡ã€‚è¿™ä¸¤ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ ¹æ®ç›®æ ‡ä½ç½®é€’å½’åœ°é‡æ–°è§„åˆ’å¹³æ»‘å®‰å…¨çš„è½¨è¿¹ã€‚ç›®æ ‡å¯ä»¥ç”¨ä½ç½®åæ ‡æˆ–è¯­è¨€å‘½ä»¤é€šè¿‡è¯­ä¹‰GSplatæ¥æŒ‡å®šã€‚åœ¨å¹¿æ³›çš„æ¨¡æ‹Ÿå®éªŒä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†ä¸ç‚¹äº‘æ–¹æ³•ç›¸æ¯”çš„å®‰å…¨æ€§èƒ½æå‡ã€‚åœ¨æ€»å…±çš„126æ¬¡ç¡¬ä»¶é£è¡Œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸è¿åŠ¨æ•è·å’Œè§†è§‰é‡Œç¨‹è®¡ç›¸å½“çš„å®‰å…¨æ€§å’Œé€Ÿåº¦ï¼Œä½†æ— éœ€è¿™äº›æ–¹æ³•æ‰€éœ€çš„æ‰‹åŠ¨å¸§å¯¹é½ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¶…è¿‡2Hzçš„åœ¨çº¿é‡æ–°è§„åˆ’é€Ÿåº¦å’Œå¤§çº¦æ¯ç§’å¸§æ•°çš„å§¿æ€ä¼°è®¡é€Ÿåº¦ï¼Œæ¯”åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å¯¼èˆªæ–¹æ³•å¿«å¾—å¤šï¼Œä»è€Œå®ç°å®æ—¶å¯¼èˆªã€‚ç›¸å…³å®éªŒè§†é¢‘å’Œé¡¹ç›®é¡µé¢ä½äº<a target="_blank" rel="noopener" href="https://chengine.github.io/splatnav/">https://chengine.github.io/splatnav/</a>ã€‚æˆ‘ä»¬çš„ä»£ç åº“å’ŒROSèŠ‚ç‚¹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/chengine/splatnav">https://github.com/chengine/splatnav</a>æ‰¾åˆ°ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>Splat-Navæä¾›å®æ—¶æœºå™¨äººå¯¼èˆªï¼Œé€‚ç”¨äºé«˜æ–¯ç»˜å›¾ï¼ˆGSplatï¼‰åœºæ™¯ã€‚</li>
<li>åŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼šSplat-Planå®‰å…¨è§„åˆ’æ¨¡å—å’ŒSplat-Locè§†è§‰å§¿æ€ä¼°è®¡æ¨¡å—ã€‚</li>
<li>Splat-PlanåŸºäºæ•°å­¦ç¢°æ’çº¦æŸæ„å»ºå®‰å…¨å¤šè¾¹å½¢èµ°å»Šå’ŒBezieræ›²çº¿è½¨è¿¹ã€‚</li>
<li>Splat-Locåˆ©ç”¨ç‚¹äº‘è¡¨ç¤ºè¿›è¡Œå®æ—¶é€’å½’çŠ¶æ€ä¼°è®¡ã€‚</li>
<li>æ¨¡å—ååŒå·¥ä½œï¼Œæ”¯æŒä»¥ä½ç½®åæ ‡æˆ–è¯­è¨€å‘½ä»¤æŒ‡å®šç›®æ ‡ä½ç½®çš„é€’å½’é‡æ–°è§„åˆ’å¹³æ»‘å®‰å…¨è½¨è¿¹çš„èƒ½åŠ›ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿå®éªŒä¸­è¯æ˜äº†ç›¸å¯¹äºç‚¹äº‘æ–¹æ³•çš„å®‰å…¨æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.02751">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2403.02751v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2403.02751v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2403.02751v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-01-16\./crop_3DGS/2403.02751v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-8056e9344da0ffeda6b350036010f74c.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  VINGS-Mono Visual-Inertial Gaussian Splatting Monocular SLAM in Large   Scenes
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-9f57cf04eb1b2d5db9068f560d4615ab.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  RMAvatar Photorealistic Human Avatar Reconstruction from Monocular   Video Based on Rectified Mesh-embedded Gaussians
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32140.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
