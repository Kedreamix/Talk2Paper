<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
    <meta name="description" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  Code and Pixels Multi-Modal Contrastive Pre-training for Enhanced   Tabular Data Analysis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4b2871166dd2aa179c39b325b67abb97.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-16-æ›´æ–°"><a href="#2025-01-16-æ›´æ–°" class="headerlink" title="2025-01-16 æ›´æ–°"></a>2025-01-16 æ›´æ–°</h1><h2 id="Code-and-Pixels-Multi-Modal-Contrastive-Pre-training-for-Enhanced-Tabular-Data-Analysis"><a href="#Code-and-Pixels-Multi-Modal-Contrastive-Pre-training-for-Enhanced-Tabular-Data-Analysis" class="headerlink" title="Code and Pixels: Multi-Modal Contrastive Pre-training for Enhanced   Tabular Data Analysis"></a>Code and Pixels: Multi-Modal Contrastive Pre-training for Enhanced   Tabular Data Analysis</h2><p><strong>Authors:Kankana Roy, Lars KrÃ¤mer, Sebastian Domaschke, Malik Haris, Roland Aydin, Fabian Isensee, Martin Held</strong></p>
<p>Learning from tabular data is of paramount importance, as it complements the conventional analysis of image and video data by providing a rich source of structured information that is often critical for comprehensive understanding and decision-making processes. We present Multi-task Contrastive Masked Tabular Modeling (MT-CMTM), a novel method aiming to enhance tabular models by leveraging the correlation between tabular data and corresponding images. MT-CMTM employs a dual strategy combining contrastive learning with masked tabular modeling, optimizing the synergy between these data modalities.   Central to our approach is a 1D Convolutional Neural Network with residual connections and an attention mechanism (1D-ResNet-CBAM), designed to efficiently process tabular data without relying on images. This enables MT-CMTM to handle purely tabular data for downstream tasks, eliminating the need for potentially costly image acquisition and processing.   We evaluated MT-CMTM on the DVM car dataset, which is uniquely suited for this particular scenario, and the newly developed HIPMP dataset, which connects membrane fabrication parameters with image data. Our MT-CMTM model outperforms the proposed tabular 1D-ResNet-CBAM, which is trained from scratch, achieving a relative 1.48% improvement in relative MSE on HIPMP and a 2.38% increase in absolute accuracy on DVM. These results demonstrate MT-CMTMâ€™s robustness and its potential to advance the field of multi-modal learning. </p>
<blockquote>
<p>ä»è¡¨æ ¼æ•°æ®è¿›è¡Œå­¦ä¹ è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒé€šè¿‡æä¾›ä¸°å¯Œçš„ç»“æ„åŒ–ä¿¡æ¯æ¥æºæ¥è¡¥å……å¯¹å›¾åƒå’Œè§†é¢‘æ•°æ®çš„ä¼ ç»Ÿåˆ†æï¼Œè¿™å¯¹äºå…¨é¢ç†è§£å’Œå†³ç­–è¿‡ç¨‹ç»å¸¸è‡³å…³é‡è¦ã€‚æˆ‘ä»¬æå‡ºäº†å¤šä»»åŠ¡å¯¹æ¯”æ©æ¨¡è¡¨æ ¼å»ºæ¨¡ï¼ˆMulti-task Contrastive Masked Tabular Modelingï¼Œç®€ç§°MT-CMTMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨åˆ©ç”¨è¡¨æ ¼æ•°æ®ä¸ç›¸åº”å›¾åƒä¹‹é—´å…³è”æ€§çš„æ–°æ–¹æ³•ï¼Œä»¥å¢å¼ºè¡¨æ ¼æ¨¡å‹ã€‚MT-CMTMé‡‡ç”¨äº†ä¸€ç§ç»“åˆå¯¹æ¯”å­¦ä¹ ä¸æ©æ¨¡è¡¨æ ¼å»ºæ¨¡çš„åŒé‡ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–è¿™äº›æ•°æ®æ¨¡å¼ä¹‹é—´çš„ååŒä½œç”¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼Œå…·æœ‰æ®‹å·®è¿æ¥å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼ˆ1D-ResNet-CBAMï¼‰ï¼Œæ—¨åœ¨æœ‰æ•ˆå¤„ç†è¡¨æ ¼æ•°æ®è€Œæ— éœ€ä¾èµ–å›¾åƒã€‚è¿™ä½¿å¾—MT-CMTMèƒ½å¤Ÿå¤„ç†çº¯è¡¨æ ¼æ•°æ®ä»¥è¿›è¡Œä¸‹æ¸¸ä»»åŠ¡ï¼Œä»è€Œæ— éœ€è¿›è¡Œå¯èƒ½æˆæœ¬é«˜æ˜‚çš„å›¾åƒè·å–å’Œå¤„ç†ã€‚æˆ‘ä»¬åœ¨DVMæ±½è½¦æ•°æ®é›†ä¸Šè¯„ä¼°äº†MT-CMTMï¼Œè¯¥æ•°æ®é›†éå¸¸é€‚åˆäºæ­¤ç‰¹å®šåœºæ™¯ï¼Œä»¥åŠæ–°å¼€å‘çš„HIPMPæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†å°†è†œåˆ¶é€ å‚æ•°ä¸å›¾åƒæ•°æ®ç›¸å…³è”ã€‚æˆ‘ä»¬çš„MT-CMTMæ¨¡å‹çš„è¡¨ç°ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„æè®®çš„è¡¨æ ¼æ•°æ®1D-ResNet-CBAMæ¨¡å‹ï¼Œåœ¨HIPMPä¸Šç›¸å¯¹MSEæé«˜äº†1.48%ï¼Œåœ¨DVMä¸Šç»å¯¹ç²¾åº¦æé«˜äº†2.38%ã€‚è¿™äº›ç»“æœè¯æ˜äº†MT-CMTMçš„ç¨³å¥æ€§ä»¥åŠå…¶åœ¨å¤šæ¨¡å¼å­¦ä¹ é¢†åŸŸå‘å±•çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07304v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„å¤šä»»åŠ¡å¯¹æ¯”æ©è†œè¡¨æ ¼å»ºæ¨¡ï¼ˆMT-CMTMï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨åˆ©ç”¨è¡¨æ ¼æ•°æ®ä¸å¯¹åº”å›¾åƒä¹‹é—´çš„å…³è”æ€§æ¥æé«˜è¡¨æ ¼æ¨¡å‹çš„æ€§èƒ½ã€‚å®ƒç»“åˆäº†å¯¹æ¯”å­¦ä¹ ä¸æ©è†œè¡¨æ ¼å»ºæ¨¡çš„åŒé‡ç­–ç•¥ï¼Œä¼˜åŒ–äº†ä¸åŒæ•°æ®æ¨¡å¼ä¹‹é—´çš„ååŒä½œç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»…å¤„ç†è¡¨æ ¼æ•°æ®å³å¯å¤„ç†ä¸‹æ¸¸ä»»åŠ¡ï¼Œè€Œæ— éœ€ä¾èµ–äºæˆæœ¬è¾ƒé«˜çš„å›¾åƒé‡‡é›†å’Œå¤„ç†ã€‚åœ¨DVMæ±½è½¦æ•°æ®é›†å’Œå…¨æ–°å¼€å‘çš„HIPMPæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMT-CMTMæ¨¡å‹çš„æ€§èƒ½ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„1D-ResNet-CBAMæ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºå…¶ç¨³å¥æ€§å’Œåœ¨å¤šæ¨¡æ€å­¦ä¹ é¢†åŸŸçš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MT-CMTMæ˜¯ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡åˆ©ç”¨è¡¨æ ¼æ•°æ®å’Œå¯¹åº”å›¾åƒä¹‹é—´çš„å…³è”æ€§æé«˜è¡¨æ ¼æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆäº†å¯¹æ¯”å­¦ä¹ ä¸æ©è†œè¡¨æ ¼å»ºæ¨¡çš„åŒé‡ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–ä¸åŒæ•°æ®æ¨¡å¼ä¹‹é—´çš„ååŒä½œç”¨ã€‚</li>
<li>MT-CMTMä½¿ç”¨ä¸€ä¸ªå…·æœ‰æ®‹å·®è¿æ¥å’Œæ³¨æ„åŠ›æœºåˆ¶çš„1Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆ1D-ResNet-CBAMï¼‰æ¥å¤„ç†è¡¨æ ¼æ•°æ®ï¼Œæ— éœ€ä¾èµ–å›¾åƒã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨DVMæ±½è½¦æ•°æ®é›†å’ŒHIPMPæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒéªŒè¯ï¼Œæ˜¾ç¤ºå‡ºå…¶ç¨³å¥æ€§å’Œå¤šæ¨¡æ€å­¦ä¹ æ½œåŠ›ã€‚</li>
<li>MT-CMTMæ¨¡å‹æ€§èƒ½ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„1D-ResNet-CBAMæ¨¡å‹ã€‚</li>
<li>åœ¨HIPMPæ•°æ®é›†ä¸Šï¼ŒMT-CMTMæ¨¡å‹ç›¸å¯¹äºMSEçš„æ”¹è¿›è¾¾åˆ°1.48%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07304">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4b2871166dd2aa179c39b325b67abb97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f88fe722da5735373cb41fe9a0d2944.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7beeeb634f50759ab6774e779d1071f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5176a278cdba0f97c816b5840d6f4c29.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-19176ad350d700bc6a82c46f17f73593.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Exploring-the-Use-of-Contrastive-Language-Image-Pre-Training-for-Human-Posture-Classification-Insights-from-Yoga-Pose-Analysis"><a href="#Exploring-the-Use-of-Contrastive-Language-Image-Pre-Training-for-Human-Posture-Classification-Insights-from-Yoga-Pose-Analysis" class="headerlink" title="Exploring the Use of Contrastive Language-Image Pre-Training for Human   Posture Classification: Insights from Yoga Pose Analysis"></a>Exploring the Use of Contrastive Language-Image Pre-Training for Human   Posture Classification: Insights from Yoga Pose Analysis</h2><p><strong>Authors:Andrzej D. Dobrzycki, Ana M. Bernardos, Luca Bergesio, Andrzej Pomirski, Daniel SÃ¡ez-Trigueros</strong></p>
<p>Accurate human posture classification in images and videos is crucial for automated applications across various fields, including work safety, physical rehabilitation, sports training, or daily assisted living. Recently, multimodal learning methods, such as Contrastive Language-Image Pretraining (CLIP), have advanced significantly in jointly understanding images and text. This study aims to assess the effectiveness of CLIP in classifying human postures, focusing on its application in yoga. Despite the initial limitations of the zero-shot approach, applying transfer learning on 15,301 images (real and synthetic) with 82 classes has shown promising results. The article describes the full procedure for fine-tuning, including the choice for image description syntax, models and hyperparameters adjustment. The fine-tuned CLIP model, tested on 3826 images, achieves an accuracy of over 85%, surpassing the current state-of-the-art of previous works on the same dataset by approximately 6%, its training time being 3.5 times lower than what is needed to fine-tune a YOLOv8-based model. For more application-oriented scenarios, with smaller datasets of six postures each, containing 1301 and 401 training images, the fine-tuned models attain an accuracy of 98.8% and 99.1%, respectively. Furthermore, our experiments indicate that training with as few as 20 images per pose can yield around 90% accuracy in a six-class dataset. This study demonstrates that this multimodal technique can be effectively used for yoga pose classification, and possibly for human posture classification, in general. Additionally, CLIP inference time (around 7 ms) supports that the model can be integrated into automated systems for posture evaluation, e.g., for developing a real-time personal yoga assistant for performance assessment. </p>
<blockquote>
<p>åœ¨å›¾åƒå’Œè§†é¢‘ä¸­è¿›è¡Œå‡†ç¡®çš„äººä½“å§¿åŠ¿åˆ†ç±»å¯¹äºè‡ªåŠ¨åŒ–åº”ç”¨åœ¨å¤šä¸ªé¢†åŸŸæ˜¯è‡³å…³é‡è¦çš„ï¼ŒåŒ…æ‹¬å·¥ä½œå®‰å…¨ã€ç‰©ç†åº·å¤ã€ä½“è‚²è®­ç»ƒæˆ–æ—¥å¸¸è¾…åŠ©ç”Ÿæ´»ã€‚æœ€è¿‘ï¼Œå¦‚Contrastive Language-Image Pretrainingï¼ˆCLIPï¼‰ç­‰å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•åœ¨è”åˆç†è§£å›¾åƒå’Œæ–‡æœ¬æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°CLIPåœ¨äººä½“å§¿åŠ¿åˆ†ç±»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œé‡ç‚¹å…³æ³¨å…¶åœ¨ç‘œä¼½ä¸­çš„åº”ç”¨ã€‚å°½ç®¡é›¶æ ·æœ¬æ–¹æ³•å­˜åœ¨åˆå§‹å±€é™æ€§ï¼Œä½†åœ¨å…·æœ‰82ç±»çš„15301å¼ ï¼ˆçœŸå®å’Œåˆæˆï¼‰å›¾åƒä¸Šåº”ç”¨è¿ç§»å­¦ä¹ å·²æ˜¾ç¤ºå‡ºä»¤äººé¼“èˆçš„ç»“æœã€‚æ–‡ç« è¯¦ç»†ä»‹ç»äº†å¾®è°ƒè¿‡ç¨‹çš„å®Œæ•´æ­¥éª¤ï¼ŒåŒ…æ‹¬å›¾åƒæè¿°è¯­æ³•ã€æ¨¡å‹çš„é€‰æ‹©å’Œè¶…å‚æ•°çš„è°ƒæ•´ã€‚ç»è¿‡ç²¾ç»†è°ƒæ•´çš„CLIPæ¨¡å‹åœ¨3826å¼ å›¾åƒä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå‡†ç¡®ç‡è¶…è¿‡85%ï¼Œè¾ƒåŒä¸€æ•°æ®é›†ä¸Šçš„å…ˆå‰æœ€ä½³å·¥ä½œé«˜å‡ºçº¦6%ï¼Œå…¶è®­ç»ƒæ—¶é—´æ˜¯å¾®è°ƒYOLOv8æ¨¡å‹æ‰€éœ€æ—¶é—´çš„3.5å€ã€‚å¯¹äºé¢å‘åº”ç”¨çš„å®é™…åœºæ™¯ï¼Œä½¿ç”¨æ¯ä¸ªå§¿åŠ¿ä»…åŒ…å«å°‘é‡å›¾åƒï¼ˆä¾‹å¦‚å…­ä¸ªå§¿åŠ¿ä¸­çš„å…­ä¸ªå›¾åƒï¼‰çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒæ—¶ï¼Œç²¾ç»†è°ƒæ•´åçš„æ¨¡å‹åœ¨åŒ…å«1301å¼ å’Œ401å¼ è®­ç»ƒå›¾åƒçš„æ•°æ®é›†ä¸Šåˆ†åˆ«è¾¾åˆ°äº†98.8%å’Œ99.1%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæ¯å§¿åŠ¿ä»…ä½¿ç”¨å°‘é‡å›¾åƒï¼ˆå¦‚æ¯ä¸ªå…­ç±»æ•°æ®é›†ä»…ä½¿ç”¨å¤§çº¦äºŒåå¼ å›¾åƒï¼‰è¿›è¡Œè®­ç»ƒå¯ä»¥è¾¾åˆ°å¤§çº¦90%çš„å‡†ç¡®ç‡ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§å¤šæ¨¡æ€æŠ€æœ¯å¯æœ‰æ•ˆç”¨äºç‘œä¼½å§¿åŠ¿åˆ†ç±»ï¼Œå¹¶å¯èƒ½é€‚ç”¨äºä¸€èˆ¬çš„äººä½“å§¿åŠ¿åˆ†ç±»ã€‚æ­¤å¤–ï¼ŒCLIPæ¨ç†æ—¶é—´çº¦ä¸º7æ¯«ç§’ï¼Œæ”¯æŒå°†è¯¥æ¨¡å‹é›†æˆåˆ°å§¿åŠ¿è¯„ä¼°çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿä¸­ï¼Œä¾‹å¦‚å¼€å‘ç”¨äºæ€§èƒ½è¯„ä¼°çš„å®æ—¶ä¸ªäººç‘œä¼½åŠ©ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07221v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶åˆ©ç”¨å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰è¿›è¡Œç‘œä¼½å§¿åŠ¿åˆ†ç±»ï¼Œé€šè¿‡å¯¹15,301å¼ å›¾åƒï¼ˆçœŸå®å’Œåˆæˆï¼‰è¿›è¡Œè¿ç§»å­¦ä¹ ï¼Œåœ¨ç‘œä¼½å§¿åŠ¿åˆ†ç±»ä¸Šå–å¾—äº†æ˜¾è‘—æ•ˆæœã€‚ç²¾ç»†è°ƒæ•´çš„CLIPæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šå‡†ç¡®ç‡è¶…è¿‡85%ï¼Œæ˜¾è‘—ä¼˜äºå…ˆå‰åœ¨åŒä¸€æ•°æ®é›†ä¸Šçš„æœ€ä½³è¡¨ç°ï¼ŒåŒæ—¶è®­ç»ƒæ—¶é—´å‡å°‘äº†çº¦ä¸‰å€ã€‚æ­¤å¤–ï¼Œå³ä½¿ä½¿ç”¨å°‘é‡å›¾åƒï¼ˆæ¯å§¿åŠ¿ä»…20å¼ ï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨å…­ç±»æ•°æ®é›†ä¸­ä»èƒ½è¾¾åˆ°çº¦90%çš„å‡†ç¡®ç‡ã€‚ç ”ç©¶è¯æ˜è¯¥æŠ€æœ¯å¯æœ‰æ•ˆåœ°ç”¨äºç‘œä¼½å§¿åŠ¿åˆ†ç±»åŠä¸€èˆ¬äººç±»å§¿åŠ¿åˆ†ç±»ï¼Œå¹¶ä¸”CLIPçš„å¿«é€Ÿæ¨ç†æ—¶é—´ä½¿å…¶å¯é›†æˆåˆ°å§¿åŠ¿è¯„ä¼°çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œç”¨äºç‘œä¼½å§¿åŠ¿åˆ†ç±»ã€‚</li>
<li>é€šè¿‡è¿ç§»å­¦ä¹ åœ¨å¤§é‡å›¾åƒæ•°æ®ä¸Šè¿›è¡Œç²¾ç»†è°ƒæ•´ï¼Œå®ç°äº†é«˜å‡†ç¡®ç‡çš„äººä½“ä½å§¿åˆ†ç±»ã€‚</li>
<li>CLIPæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡è¶…è¿‡85%ï¼Œæ˜¾è‘—ä¼˜äºå…ˆå‰çš„ç ”ç©¶ã€‚</li>
<li>ä½¿ç”¨å°‘é‡å›¾åƒï¼ˆæ¯å§¿åŠ¿ä»…20å¼ ï¼‰ä¹Ÿèƒ½å®ç°çº¦90%çš„å‡†ç¡®ç‡ã€‚</li>
<li>CLIPæ¨¡å‹çš„è®­ç»ƒæ—¶é—´æ¯”YOLOv8æ¨¡å‹ä½çº¦ä¸‰å€ã€‚</li>
<li>CLIPçš„å¿«é€Ÿæ¨ç†æ—¶é—´æ”¯æŒé›†æˆåˆ°è‡ªåŠ¨åŒ–ç³»ç»Ÿä¸­è¿›è¡Œå§¿åŠ¿è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07221">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4376acec429678811bc0d9e6a23e3c63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c8629abb2fc3ff40a9f4e82e8361053.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Towards-Counterfactual-and-Contrastive-Explainability-and-Transparency-of-DCNN-Image-Classifiers"><a href="#Towards-Counterfactual-and-Contrastive-Explainability-and-Transparency-of-DCNN-Image-Classifiers" class="headerlink" title="Towards Counterfactual and Contrastive Explainability and Transparency   of DCNN Image Classifiers"></a>Towards Counterfactual and Contrastive Explainability and Transparency   of DCNN Image Classifiers</h2><p><strong>Authors:Syed Ali Tariq, Tehseen Zia, Mubeen Ghafoor</strong></p>
<p>Explainability of deep convolutional neural networks (DCNNs) is an important research topic that tries to uncover the reasons behind a DCNN modelâ€™s decisions and improve their understanding and reliability in high-risk environments. In this regard, we propose a novel method for generating interpretable counterfactual and contrastive explanations for DCNN models. The proposed method is model intrusive that probes the internal workings of a DCNN instead of altering the input image to generate explanations. Given an input image, we provide contrastive explanations by identifying the most important filters in the DCNN representing features and concepts that separate the modelâ€™s decision between classifying the image to the original inferred class or some other specified alter class. On the other hand, we provide counterfactual explanations by specifying the minimal changes necessary in such filters so that a contrastive output is obtained.   Using these identified filters and concepts, our method can provide contrastive and counterfactual reasons behind a modelâ€™s decisions and makes the model more transparent. One of the interesting applications of this method is misclassification analysis, where we compare the identified concepts from a particular input image and compare them with class-specific concepts to establish the validity of the modelâ€™s decisions. The proposed method is compared with state-of-the-art and evaluated on the Caltech-UCSD Birds (CUB) 2011 dataset to show the usefulness of the explanations provided. </p>
<blockquote>
<p>æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆDCNNsï¼‰çš„è§£é‡Šæ€§æ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶è¯¾é¢˜ï¼Œæ—¨åœ¨æ­ç¤ºDCNNæ¨¡å‹å†³ç­–èƒŒåçš„åŸå› ï¼Œå¹¶åœ¨é«˜é£é™©ç¯å¢ƒä¸­æé«˜å¯¹å…¶ç†è§£å’Œå¯é æ€§ã€‚åœ¨è¿™æ–¹é¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸ºDCNNæ¨¡å‹ç”Ÿæˆå¯è§£é‡Šçš„å‡è®¾å’Œå¯¹æ¯”è§£é‡Šçš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•å…·æœ‰æ¨¡å‹ä¾µå…¥æ€§ï¼Œå®ƒé€šè¿‡æ¢æŸ¥DCNNçš„å†…éƒ¨å·¥ä½œåŸç†è€Œä¸æ˜¯æ”¹å˜è¾“å…¥å›¾åƒæ¥ç”Ÿæˆè§£é‡Šã€‚ç»™å®šä¸€ä¸ªè¾“å…¥å›¾åƒï¼Œæˆ‘ä»¬é€šè¿‡è¯†åˆ«DCNNä¸­æœ€é‡è¦çš„è¿‡æ»¤å™¨æ¥æä¾›å¯¹æ¯”è§£é‡Šï¼Œè¿™äº›è¿‡æ»¤å™¨ä»£è¡¨ç‰¹å¾å’Œæ¦‚å¿µï¼Œèƒ½å¤ŸåŒºåˆ†æ¨¡å‹å°†å›¾åƒåˆ†ç±»ä¸ºåŸå§‹æ¨æ–­ç±»åˆ«æˆ–å…¶ä»–æŒ‡å®šçš„æ›¿ä»£ç±»åˆ«ä¹‹é—´çš„å†³ç­–ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬é€šè¿‡æŒ‡å®šè¿™äº›è¿‡æ»¤å™¨ä¸­æ‰€éœ€çš„æœ€å°å˜åŒ–æ¥æä¾›åäº‹å®è§£é‡Šï¼Œä»¥ä¾¿è·å¾—å¯¹æ¯”è¾“å‡ºã€‚é€šè¿‡ä½¿ç”¨è¿™äº›ç¡®å®šçš„è¿‡æ»¤å™¨å’Œæ¦‚å¿µï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æä¾›æ¨¡å‹å†³ç­–èƒŒåçš„å¯¹æ¯”å’Œåäº‹å®åŸå› ï¼Œå¹¶ä½¿æ¨¡å‹æ›´åŠ é€æ˜ã€‚è¯¥æ–¹æ³•çš„æœ‰è¶£åº”ç”¨ä¹‹ä¸€æ˜¯è¯¯åˆ†ç±»åˆ†æï¼Œæˆ‘ä»¬æ¯”è¾ƒç‰¹å®šè¾“å…¥å›¾åƒä¸­è¯†åˆ«çš„æ¦‚å¿µå¹¶ä¸ç‰¹å®šç±»åˆ«çš„æ¦‚å¿µè¿›è¡Œæ¯”è¾ƒï¼Œä»¥éªŒè¯æ¨¡å‹å†³ç­–çš„åˆç†æ€§ã€‚è¯¥æ–¹æ³•ä¸å½“å‰å…ˆè¿›æŠ€æœ¯è¿›è¡Œäº†æ¯”è¾ƒï¼Œå¹¶åœ¨Caltech-UCSDé¸Ÿç±»ï¼ˆCUBï¼‰2011æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œä»¥å±•ç¤ºæ‰€æä¾›è§£é‡Šçš„æœ‰ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06831v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ å·ç§¯ç¥ç»ç½‘ç»œï¼ˆDCNNï¼‰çš„å¯è§£é‡Šæ€§ç ”ç©¶æ—¨åœ¨æ­ç¤ºæ¨¡å‹å†³ç­–èƒŒåçš„åŸå› ï¼Œæé«˜é«˜é£é™©ç¯å¢ƒä¸‹çš„ç†è§£å’Œå¯é æ€§ã€‚ä¸ºæ­¤ï¼Œæå‡ºä¸€ç§æ–°å‹ç”Ÿæˆè§£é‡ŠDCNNæ¨¡å‹å†³ç­–çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨æ¨¡å‹ä¾µå…¥æ–¹å¼æ¢æŸ¥DCNNçš„å†…éƒ¨å·¥ä½œæ–¹å¼ï¼Œè€Œä¸æ”¹å˜è¾“å…¥å›¾åƒæ¥ç”Ÿæˆè§£é‡Šã€‚å¯¹äºè¾“å…¥å›¾åƒï¼Œé€šè¿‡è¯†åˆ«ä»£è¡¨ç‰¹å¾å’Œæ¦‚å¿µçš„DCNNä¸­æœ€é‡è¦è¿‡æ»¤å™¨æ¥æä¾›å¯¹æ¯”è§£é‡Šï¼Œè¿™äº›ç‰¹å¾å’Œæ¦‚å¿µå°†æ¨¡å‹å¯¹å›¾åƒçš„åˆ†ç±»ä¸åŸå§‹æ¨æ–­ç±»åˆ«æˆ–å…¶ä»–ç‰¹å®šæ›¿ä»£ç±»åˆ«åŒºåˆ†å¼€æ¥ã€‚å¦ä¸€æ–¹é¢ï¼Œé€šè¿‡æŒ‡å®šè¿™äº›è¿‡æ»¤å™¨æ‰€éœ€çš„æœ€å°å˜åŒ–æ¥æä¾›åäº‹å®è§£é‡Šä»¥è·å¾—å¯¹æ¯”è¾“å‡ºã€‚åˆ©ç”¨è¿™äº›å·²è¯†åˆ«çš„è¿‡æ»¤å™¨å’Œæ¦‚å¿µï¼Œæ­¤æ–¹æ³•æä¾›äº†æ¨¡å‹çš„å†³ç­–èƒŒåçš„å¯¹æ¯”å’Œåäº‹å®åŸå› ï¼Œä½¿æ¨¡å‹æ›´åŠ é€æ˜ã€‚è¯¥æ–¹æ³•åœ¨Caltech-UCSDé¸Ÿç±»ï¼ˆCUBï¼‰æ•°æ®é›†ä¸Šè¿›è¡Œäº†æ¯”è¾ƒå’Œè¯„ä¼°ï¼Œä»¥å±•ç¤ºæ‰€æä¾›è§£é‡Šçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡ç‚¹ï¼šç ”ç©¶æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆDCNNï¼‰çš„å¯è§£é‡Šæ€§ï¼Œä»¥ç†è§£æ¨¡å‹å†³ç­–çš„æœºåˆ¶å’ŒåŸç†ã€‚</li>
<li>æå‡ºæ–°å‹æ–¹æ³•ï¼šå¼€å‘äº†ä¸€ç§æ–°é¢–çš„æ¨¡å‹ä¾µå…¥æ€§æ–¹æ³•æ¥è§£æDCNNæ¨¡å‹çš„å†…éƒ¨å·¥ä½œæœºåˆ¶ï¼Œæä¾›äº†å¯¹æ¨¡å‹å†³ç­–çš„å¯¹æ¯”å’Œåäº‹å®è§£é‡Šã€‚</li>
<li>å¯¹æ¯”è§£é‡Šå’Œåäº‹å®è§£é‡Šï¼šå¯¹æ¯”è§£é‡Šé€šè¿‡è¯†åˆ«åŒºåˆ†æ¨¡å‹å†³ç­–çš„å…³é”®ç‰¹å¾å’Œæ¦‚å¿µæ¥å®ç°ï¼›åäº‹å®è§£é‡Šåˆ™é€šè¿‡ç¡®å®šè¿‡æ»¤å™¨æ‰€éœ€çš„æœ€å°å˜åŒ–æ¥è·å¾—å¯¹æ¯”è¾“å‡ºã€‚</li>
<li>åº”ç”¨é¢†åŸŸï¼šè¯¥æŠ€æœ¯åœ¨è¯¯åˆ†ç±»åˆ†æä¸­å…·æœ‰é‡è¦çš„åº”ç”¨æ½œåŠ›ï¼Œå¯ä»¥é€šè¿‡å¯¹æ¯”ç‰¹å®šè¾“å…¥å›¾åƒçš„æ¦‚å¿µä¸ç±»åˆ«ç‰¹å®šæ¦‚å¿µæ¥éªŒè¯æ¨¡å‹çš„å†³ç­–æœ‰æ•ˆæ€§ã€‚</li>
<li>å®éªŒéªŒè¯ï¼šåœ¨Caltech-UCSDé¸Ÿç±»æ•°æ®é›†ä¸Šå¯¹æ‰€æå‡ºçš„æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ï¼Œæ˜¾ç¤ºäº†æ‰€æä¾›è§£é‡Šçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚</li>
<li>æ¨¡å‹é€æ˜åº¦æå‡ï¼šè¯¥æ–¹æ³•å¢å¼ºäº†DCNNæ¨¡å‹çš„é€æ˜åº¦ï¼Œä½¿å…¶å†³ç­–è¿‡ç¨‹æ›´åŠ æ˜“äºç†è§£å’Œä¿¡ä»»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06831">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ffed1dcf3b6b085dec6c0378a933bcca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4c5cdba34b1f9465eea4d48bae146aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e1db03b19c62d782a479eb5497ee3ea.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GLFC-Unified-Global-Local-Feature-and-Contrast-Learning-with-Mamba-Enhanced-UNet-for-Synthetic-CT-Generation-from-CBCT"><a href="#GLFC-Unified-Global-Local-Feature-and-Contrast-Learning-with-Mamba-Enhanced-UNet-for-Synthetic-CT-Generation-from-CBCT" class="headerlink" title="GLFC: Unified Global-Local Feature and Contrast Learning with   Mamba-Enhanced UNet for Synthetic CT Generation from CBCT"></a>GLFC: Unified Global-Local Feature and Contrast Learning with   Mamba-Enhanced UNet for Synthetic CT Generation from CBCT</h2><p><strong>Authors:Xianhao Zhou, Jianghao Wu, Huangxuan Zhao, Lei Chen, Shaoting Zhang, Guotai Wang</strong></p>
<p>Generating synthetic Computed Tomography (CT) images from Cone Beam Computed Tomography (CBCT) is desirable for improving the image quality of CBCT. Existing synthetic CT (sCT) generation methods using Convolutional Neural Networks (CNN) and Transformers often face difficulties in effectively capturing both global and local features and contrasts for high-quality sCT generation. In this work, we propose a Global-Local Feature and Contrast learning (GLFC) framework for sCT generation. First, a Mamba-Enhanced UNet (MEUNet) is introduced by integrating Mamba blocks into the skip connections of a high-resolution UNet for effective global and local feature learning. Second, we propose a Multiple Contrast Loss (MCL) that calculates synthetic loss at different intensity windows to improve quality for both soft tissues and bone regions. Experiments on the SynthRAD2023 dataset demonstrate that GLFC improved the SSIM of sCT from 77.91% to 91.50% compared with the original CBCT, and significantly outperformed several existing methods for sCT generation. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HiLab-git/GLFC">https://github.com/HiLab-git/GLFC</a> </p>
<blockquote>
<p>ä»é”¥æŸè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCBCTï¼‰ç”Ÿæˆåˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰å›¾åƒæ˜¯æé«˜CBCTå›¾åƒè´¨é‡çš„ç†æƒ³æ–¹æ³•ã€‚ç°æœ‰ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒTransformerçš„åˆæˆCTï¼ˆsCTï¼‰ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨æœ‰æ•ˆæ•è·å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ä»¥åŠå¯¹æ¯”ä»¥å®ç°é«˜è´¨é‡sCTç”Ÿæˆæ–¹é¢ç»å¸¸é¢ä¸´å›°éš¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºsCTç”Ÿæˆçš„å…¨çƒ-å±€éƒ¨ç‰¹å¾å’Œå¯¹æ¯”å­¦ä¹ ï¼ˆGLFCï¼‰æ¡†æ¶ã€‚é¦–å…ˆï¼Œé€šè¿‡åœ¨é«˜åˆ†è¾¨ç‡UNetçš„è·³è·ƒè¿æ¥ä¸­é›†æˆMambaå—ï¼Œå¼•å…¥äº†ä¸€ç§Mambaå¢å¼ºUNetï¼ˆMEUNetï¼‰ï¼Œä»¥å®ç°æœ‰æ•ˆçš„å…¨å±€å’Œå±€éƒ¨ç‰¹å¾å­¦ä¹ ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šå¯¹æ¯”åº¦æŸå¤±ï¼ˆMCLï¼‰ï¼Œè¯¥æŸå¤±åœ¨ä¸åŒçš„å¼ºåº¦çª—å£ä¸Šè®¡ç®—åˆæˆæŸå¤±ï¼Œä»¥æé«˜è½¯ç»„ç»‡å’Œéª¨åŒºåŸŸçš„å›¾åƒè´¨é‡ã€‚åœ¨SynthRAD2023æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸åŸå§‹CBCTç›¸æ¯”ï¼ŒGLFCå°†sCTçš„SSIMä»77.91%æé«˜åˆ°91.50%ï¼Œå¹¶ä¸”åœ¨sCTç”Ÿæˆæ–¹é¢æ˜¾è‘—ä¼˜äºå‡ ç§ç°æœ‰æ–¹æ³•ã€‚ä»£ç å¯ç”¨åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/HiLab-git/GLFC">https://github.com/HiLab-git/GLFC</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02992v2">PDF</a> Accepted by ISBI2025</p>
<p><strong>Summary</strong><br>    æœ¬æ‘˜è¦æå‡ºäº†ä¸€ç§åŸºäºå…¨å±€-å±€éƒ¨ç‰¹å¾ä¸å¯¹æ¯”åº¦å­¦ä¹ ï¼ˆGLFCï¼‰çš„æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆåˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆsCTï¼‰å›¾åƒã€‚é€šè¿‡é›†æˆMambaå—åˆ°é«˜åˆ†è¾¨ç‡UNetçš„è·³è¿‡è¿æ¥ä¸­ï¼Œå¼•å…¥Mambaå¢å¼ºUNetï¼ˆMEUNetï¼‰ä»¥æœ‰æ•ˆå­¦ä¹ å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ã€‚åŒæ—¶ï¼Œæå‡ºå¤šé‡å¯¹æ¯”åº¦æŸå¤±ï¼ˆMCLï¼‰ï¼Œé€šè¿‡åœ¨ä¸åŒå¼ºåº¦çª—å£è®¡ç®—åˆæˆæŸå¤±ï¼Œæé«˜è½¯ç»„ç»‡å’Œéª¨åŒºåŸŸçš„å›¾åƒè´¨é‡ã€‚åœ¨SynthRAD2023æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGLFCæ–¹æ³•æé«˜äº†sCTçš„SSIMæŒ‡æ•°ï¼Œä»77.91%æå‡è‡³91.50%ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–ç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆsCTï¼‰å›¾åƒç”Ÿæˆæ–¹æ³•â€”â€”å…¨å±€-å±€éƒ¨ç‰¹å¾ä¸å¯¹æ¯”åº¦å­¦ä¹ ï¼ˆGLFCï¼‰æ¡†æ¶ã€‚</li>
<li>é€šè¿‡é›†æˆMambaå—åˆ°UNetä¸­ï¼Œå½¢æˆMambaå¢å¼ºUNetï¼ˆMEUNetï¼‰ï¼Œæœ‰æ•ˆå­¦ä¹ å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ã€‚</li>
<li>å¼•å…¥äº†å¤šé‡å¯¹æ¯”åº¦æŸå¤±ï¼ˆMCLï¼‰ï¼Œä»¥æé«˜è½¯ç»„ç»‡å’Œéª¨åŒºåŸŸçš„å›¾åƒè´¨é‡ã€‚</li>
<li>åœ¨SynthRAD2023æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†GLFCæ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼ŒsCTå›¾åƒçš„SSIMæŒ‡æ•°å¾—åˆ°æ˜¾è‘—æå‡ã€‚</li>
<li>è¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºå…¶ä»–ç°æœ‰æ–¹æ³•ï¼Œä¸ºæ”¹å–„CBCTå›¾åƒè´¨é‡æä¾›äº†æ–°çš„é€”å¾„ã€‚</li>
<li>å…¬å¼€äº†ä»£ç ï¼Œä¾¿äºåç»­ç ”ç©¶ä½¿ç”¨ã€‚</li>
<li>è¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºåŒ»å­¦å›¾åƒåˆ†æã€è¯Šæ–­åŠæ²»ç–—ç­‰é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02992">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b44695195bfb5744c862aa5baf18d86f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7ec214d7778132da33c810eeda8d2df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a974ac81de3aecc842b542741b684678.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cfa05a84a9d9e681276dd5963951b065.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2ddd0100c851d865814a3e27dbbfc397.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="WeCromCL-Weakly-Supervised-Cross-Modality-Contrastive-Learning-for-Transcription-only-Supervised-Text-Spotting"><a href="#WeCromCL-Weakly-Supervised-Cross-Modality-Contrastive-Learning-for-Transcription-only-Supervised-Text-Spotting" class="headerlink" title="WeCromCL: Weakly Supervised Cross-Modality Contrastive Learning for   Transcription-only Supervised Text Spotting"></a>WeCromCL: Weakly Supervised Cross-Modality Contrastive Learning for   Transcription-only Supervised Text Spotting</h2><p><strong>Authors:Jingjing Wu, Zhengyao Fang, Pengyuan Lyu, Chengquan Zhang, Fanglin Chen, Guangming Lu, Wenjie Pei</strong></p>
<p>Transcription-only Supervised Text Spotting aims to learn text spotters relying only on transcriptions but no text boundaries for supervision, thus eliminating expensive boundary annotation. The crux of this task lies in locating each transcription in scene text images without location annotations. In this work, we formulate this challenging problem as a Weakly Supervised Cross-modality Contrastive Learning problem, and design a simple yet effective model dubbed WeCromCL that is able to detect each transcription in a scene image in a weakly supervised manner. Unlike typical methods for cross-modality contrastive learning that focus on modeling the holistic semantic correlation between an entire image and a text description, our WeCromCL conducts atomistic contrastive learning to model the character-wise appearance consistency between a text transcription and its correlated region in a scene image to detect an anchor point for the transcription in a weakly supervised manner. The detected anchor points by WeCromCL are further used as pseudo location labels to guide the learning of text spotting. Extensive experiments on four challenging benchmarks demonstrate the superior performance of our model over other methods. Code will be released. </p>
<blockquote>
<p>ä»…è½¬å½•ç›‘ç£æ–‡æœ¬ç‚¹è¯†åˆ«æ—¨åœ¨ä»…ä¾é è½¬å½•å­¦ä¹ æ–‡æœ¬è¯†åˆ«å™¨ï¼Œè€Œæ— éœ€æ–‡æœ¬è¾¹ç•Œè¿›è¡Œç›‘ç®¡ï¼Œä»è€Œæ¶ˆé™¤äº†æ˜‚è´µçš„è¾¹ç•Œæ³¨é‡Šã€‚è¿™é¡¹ä»»åŠ¡çš„å…³é”®åœ¨äºåœ¨æ²¡æœ‰ä½ç½®æ³¨é‡Šçš„åœºæ™¯æ–‡æœ¬å›¾åƒä¸­æ‰¾åˆ°æ¯ä¸ªè½¬å½•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜åˆ¶å®šä¸ºå¼±ç›‘ç£è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ é—®é¢˜ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„æ¨¡å‹ï¼Œç§°ä¸ºWeCromCLï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä»¥å¼±ç›‘ç£çš„æ–¹å¼åœ¨åœºæ™¯å›¾åƒä¸­æ£€æµ‹æ¯ä¸ªè½¬å½•ã€‚ä¸å…¸å‹çš„è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ æ–¹æ³•ä¸åŒï¼Œè¿™äº›æ–¹æ³•ä¾§é‡äºå»ºæ¨¡æ•´ä¸ªå›¾åƒå’Œæ–‡æœ¬æè¿°ä¹‹é—´çš„æ•´ä½“è¯­ä¹‰ç›¸å…³æ€§ï¼Œæˆ‘ä»¬çš„WeCromCLè¿›è¡ŒåŸå­å¯¹æ¯”å­¦ä¹ ï¼Œä»¥å»ºæ¨¡æ–‡æœ¬è½¬å½•ä¸å…¶åœ¨åœºæ™¯å›¾åƒä¸­çš„ç›¸å…³åŒºåŸŸä¹‹é—´çš„å­—ç¬¦çº§å¤–è§‚ä¸€è‡´æ€§ï¼Œä»¥å¼±ç›‘ç£çš„æ–¹å¼æ£€æµ‹è½¬å½•çš„é”šç‚¹ã€‚WeCromCLæ£€æµ‹åˆ°çš„é”šç‚¹è¿›ä¸€æ­¥ä½œä¸ºä¼ªä½ç½®æ ‡ç­¾ï¼Œç”¨äºæŒ‡å¯¼æ–‡æœ¬è¯†åˆ«çš„å­¦ä¹ ã€‚åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚ä»£ç å°†å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.19507v2">PDF</a> Accepted by ECCV 2024</p>
<p><strong>Summary</strong><br>æ–‡æœ¬æå‡ºäº†ä¸€ç§ä»…ä¾èµ–è½¬å½•è¿›è¡Œæ–‡æœ¬è¯†åˆ«çš„æ–¹æ³•ï¼Œæ— éœ€æ–‡æœ¬è¾¹ç•Œè¿›è¡Œæ ‡æ³¨ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºåœ¨æ²¡æœ‰ä½ç½®æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œåœ¨åœºæ™¯æ–‡æœ¬å›¾åƒä¸­å®šä½æ¯ä¸ªè½¬å½•ã€‚ä¸ºæ­¤ï¼Œè¯¥ä»»åŠ¡è¢«å½’çº³ä¸ºå¼±ç›‘ç£è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ¨¡å‹WeCromCLã€‚ä¸ä¼ ç»Ÿçš„å›¾åƒå’Œæ–‡æœ¬æè¿°çš„è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ä¸åŒï¼ŒWeCromCLæ¨¡å‹å­—ç¬¦çº§åˆ«çš„å¤–è§‚ä¸€è‡´æ€§æ¥æ£€æµ‹è½¬å½•ä¸­çš„é”šç‚¹ã€‚è¿™äº›é”šç‚¹è¿›ä¸€æ­¥ä½œä¸ºä¼ªä½ç½®æ ‡ç­¾æ¥æŒ‡å¯¼æ–‡æœ¬è¯†åˆ«çš„å­¦ä¹ ã€‚åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å®éªŒè¯æ˜äº†è¯¥æ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡ä»…ä¾èµ–è½¬å½•è¿›è¡Œæ–‡æœ¬è¯†åˆ«ï¼Œæ— éœ€æ˜‚è´µçš„è¾¹ç•Œæ ‡æ³¨ã€‚</li>
<li>æ ¸å¿ƒåœ¨äºåœ¨æ²¡æœ‰ä½ç½®æ ‡æ³¨çš„åœºæ™¯æ–‡æœ¬å›¾åƒä¸­å®šä½æ¯ä¸ªè½¬å½•ã€‚</li>
<li>å°†æ­¤ä»»åŠ¡å½’çº³ä¸ºå¼±ç›‘ç£è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ¨¡å‹WeCromCLè¿›è¡Œå¼±ç›‘ç£æ£€æµ‹ã€‚</li>
<li>WeCromCLæ¨¡å‹é€šè¿‡å­—ç¬¦çº§åˆ«çš„å¤–è§‚ä¸€è‡´æ€§æ¥æ£€æµ‹è½¬å½•ä¸­çš„é”šç‚¹ã€‚</li>
<li>æ£€æµ‹åˆ°çš„é”šç‚¹ä½œä¸ºä¼ªä½ç½®æ ‡ç­¾æ¥æŒ‡å¯¼æ–‡æœ¬è¯†åˆ«çš„å­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.19507">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1bb882c18bccae2c188deb361585bb2f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8edf974fc8760817abd518c5dc11eaec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-67862886168f9f1c14072af6091a8e66.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="XVertNet-Unsupervised-Contrast-Enhancement-of-Vertebral-Structures-with-Dynamic-Self-Tuning-Guidance-and-Multi-Stage-Analysis"><a href="#XVertNet-Unsupervised-Contrast-Enhancement-of-Vertebral-Structures-with-Dynamic-Self-Tuning-Guidance-and-Multi-Stage-Analysis" class="headerlink" title="XVertNet: Unsupervised Contrast Enhancement of Vertebral Structures with   Dynamic Self-Tuning Guidance and Multi-Stage Analysis"></a>XVertNet: Unsupervised Contrast Enhancement of Vertebral Structures with   Dynamic Self-Tuning Guidance and Multi-Stage Analysis</h2><p><strong>Authors:Ella Eidlin, Assaf Hoogi, Hila Rozen, Mohammad Badarne, Nathan S. Netanyahu</strong></p>
<p>Chest X-rays remain the primary diagnostic tool in emergency medicine, yet their limited ability to capture fine anatomical details can result in missed or delayed diagnoses. To address this, we introduce XVertNet, a novel deep-learning framework designed to enhance vertebral structure visualization in X-ray images significantly. Our framework introduces two key innovations: (1) An unsupervised learning architecture that eliminates reliance on manually labeled training data a persistent bottleneck in medical imaging, and (2) a dynamic self-tuned internal guidance mechanism featuring an adaptive feedback loop for real-time image optimization. Extensive validation across four major public datasets revealed that XVertNet outperforms state-of-the-art enhancement methods, as demonstrated by improvements in entropy scores, Tenengrad criterion values, the local phase coherence sharpness index (LPC-SI), and thetone mapped image quality index (TMQI). Furthermore, clinical validation conducted with two board-certified radiologists confirmed that the enhanced images enabled more sensitive detection of subtle vertebral fractures and degenerative changes. The unsupervised nature of XVertNet facilitates immediate clinical deployment without requiring additional training overhead. This innovation represents a transformative advancement in emergency radiology, providing a scalable and time-efficient solution to enhance diagnostic accuracy in high-pressure clinical environments. </p>
<blockquote>
<p>èƒ¸éƒ¨Xå…‰ç‰‡ä»ç„¶æ˜¯æ€¥è¯ŠåŒ»å­¦ä¸­çš„ä¸»è¦è¯Šæ–­å·¥å…·ï¼Œç„¶è€Œï¼Œå…¶æ•æ‰ç²¾ç»†è§£å‰–ç»“æ„çš„èƒ½åŠ›æœ‰é™ï¼Œå¯èƒ½å¯¼è‡´è¯Šæ–­é—æ¼æˆ–å»¶è¿Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†XVertNetï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æ˜¾è‘—æé«˜Xå…‰ç‰‡ä¸­æ¤éª¨ç»“æ„çš„å¯è§†åŒ–æ•ˆæœã€‚æˆ‘ä»¬çš„æ¡†æ¶å¼•å…¥äº†ä¸¤ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ä¸€ç§æ— éœ€ç›‘ç£çš„å­¦ä¹ æ¶æ„ï¼Œæ¶ˆé™¤äº†å¯¹æ‰‹åŠ¨æ ‡è®°è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œè¿™æ˜¯åŒ»å­¦å½±åƒä¸­çš„ä¸€ä¸ªæŒç»­ç“¶é¢ˆï¼›ï¼ˆ2ï¼‰ä¸€ç§åŠ¨æ€è‡ªè°ƒæ•´çš„å†…éƒ¨å¼•å¯¼æœºåˆ¶ï¼Œå…·æœ‰è‡ªé€‚åº”åé¦ˆå¾ªç¯ï¼Œç”¨äºå®æ—¶å›¾åƒä¼˜åŒ–ã€‚åœ¨å››ä¸ªä¸»è¦å…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›éªŒè¯è¡¨æ˜ï¼ŒXVertNetä¼˜äºæœ€æ–°å¢å¼ºæ–¹æ³•ï¼Œä½“ç°åœ¨ç†µåˆ†æ•°ã€Tenengradå‡†åˆ™å€¼ã€å±€éƒ¨ç›¸ä½ç›¸å¹²åº¦é”åº¦æŒ‡æ•°ï¼ˆLPC-SIï¼‰å’Œè‰²è°ƒæ˜ å°„å›¾åƒè´¨é‡æŒ‡æ•°ï¼ˆTMQIï¼‰çš„æ”¹è¿›ä¸Šã€‚æ­¤å¤–ï¼Œç”±ä¸¤ä½è®¤è¯æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œçš„ä¸´åºŠéªŒè¯è¯å®ï¼Œå¢å¼ºå›¾åƒèƒ½å¤Ÿæ›´æ•æ„Ÿåœ°æ£€æµ‹åˆ°ç»†å¾®çš„æ¤ä½“éª¨æŠ˜å’Œé€€è¡Œæ€§å˜åŒ–ã€‚XVertNetçš„æ— ç›‘ç£æ€§è´¨ä¿ƒè¿›äº†å…¶ç«‹å³åœ¨ä¸´åºŠä¸­éƒ¨ç½²ï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒå¼€é”€ã€‚è¿™é¡¹åˆ›æ–°ä»£è¡¨äº†æ€¥è¯Šæ”¾å°„å­¦ä¸­çš„ä¸€é¡¹çªç ´æ€§è¿›å±•ï¼Œä¸ºé«˜å‹ä¸´åºŠç¯å¢ƒä¸­æé«˜è¯Šæ–­å‡†ç¡®æ€§æä¾›äº†å¯ä¼¸ç¼©å’Œæ—¶é—´æ•ˆç‡é«˜çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.03983v2">PDF</a> 13 pages</p>
<p><strong>Summary</strong></p>
<p>XVertNetæ˜¯ä¸€ç§æ–°å‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜Xå…‰ç‰‡ä¸­æ¤ä½“ç»“æ„çš„å¯è§†åŒ–æ•ˆæœã€‚å®ƒå¼•å…¥äº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šä¸€æ˜¯é‡‡ç”¨æ— ç›‘ç£å­¦ä¹ æ¶æ„ï¼Œæ¶ˆé™¤äº†å¯¹æ‰‹åŠ¨æ ‡æ³¨è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼›äºŒæ˜¯å…·å¤‡åŠ¨æ€è‡ªæˆ‘è°ƒæ•´çš„å†…éƒ¨å¼•å¯¼æœºåˆ¶ï¼Œå…·æœ‰è‡ªé€‚åº”åé¦ˆå›è·¯ï¼Œç”¨äºå®æ—¶å›¾åƒä¼˜åŒ–ã€‚è¯¥æ¡†æ¶åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡è¶…è¶Šäº†ç°æœ‰å¢å¼ºæ–¹æ³•ï¼Œç»ä¸´åºŠéªŒè¯å¯æœ‰æ•ˆæé«˜è¯Šæ–­å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>XVertNetæ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜Xå…‰ç‰‡ä¸­æ¤ä½“ç»“æ„çš„å¯è§†åŒ–ã€‚</li>
<li>å¼•å…¥æ— ç›‘ç£å­¦ä¹ æ¶æ„ï¼Œå‡å°‘å¯¹æ‰‹åŠ¨æ ‡æ³¨è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚</li>
<li>å…·å¤‡åŠ¨æ€è‡ªæˆ‘è°ƒæ•´çš„å†…éƒ¨å¼•å¯¼æœºåˆ¶ï¼Œå…·æœ‰è‡ªé€‚åº”åé¦ˆå›è·¯ï¼Œå®ç°å®æ—¶å›¾åƒä¼˜åŒ–ã€‚</li>
<li>åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–å¢å¼ºæ–¹æ³•ã€‚</li>
<li>é€šè¿‡ç†µåˆ†æ•°ã€Tenengradæ ‡å‡†å€¼ã€å±€éƒ¨ç›¸ä½ç›¸å¹²é”åº¦æŒ‡æ•°ï¼ˆLPC-SIï¼‰å’Œè‰²è°ƒæ˜ å°„å›¾åƒè´¨é‡æŒ‡æ•°ï¼ˆTMQIï¼‰ç­‰æŒ‡æ ‡è¯„ä¼°æ€§èƒ½ã€‚</li>
<li>ä¸´åºŠéªŒè¯æ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶èƒ½æé«˜å¯¹ç»†å¾®æ¤ä½“éª¨æŠ˜å’Œé€€è¡Œæ€§å˜åŒ–çš„æ£€æµ‹æ•æ„Ÿæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2306.03983">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0b4f8659d0d148698e74de9ec1a482a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-321beaab1ccfc0a97a8e5bdd5faf4d43.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2710d9f9163589ac2ac713df4f4718f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e65917d3cae083b37918e4d9765d7a7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-16/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-dd0fc013160fe061c51062e2d26588ab.jpg" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  A Foundational Generative Model for Breast Ultrasound Image Analysis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-16/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-09812d8a27c8a10046b4b6ab6396f036.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-16  Radial Distortion in Face Images Detection and Impact
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">15230.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
