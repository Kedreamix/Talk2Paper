<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-12-17  Still &#34;Talking About Large Language Models&#34; Some Clarifications">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-d903e9a8b6f109a6410ad2e146374ec0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    29 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-17-更新"><a href="#2024-12-17-更新" class="headerlink" title="2024-12-17 更新"></a>2024-12-17 更新</h1><h2 id="Still-“Talking-About-Large-Language-Models”-Some-Clarifications"><a href="#Still-“Talking-About-Large-Language-Models”-Some-Clarifications" class="headerlink" title="Still “Talking About Large Language Models”: Some Clarifications"></a>Still “Talking About Large Language Models”: Some Clarifications</h2><p><strong>Authors:Murray Shanahan</strong></p>
<p>My paper “Talking About Large Language Models” has more than once been interpreted as advocating a reductionist stance towards large language models. But the paper was not intended that way, and I do not endorse such positions. This short note situates the paper in the context of a larger philosophical project that is concerned with the (mis)use of words rather than metaphysics, in the spirit of Wittgenstein’s later writing. </p>
<blockquote>
<p>我的论文《关于大型语言模型》曾被多次解读为倡导对大型语言模型的还原论立场。但论文并非此意，我也不支持这样的观点。这篇简短的笔记将论文定位在一个更大的哲学项目的背景中，关注的是词语的（误）用，而非形而上学，秉承维特根斯坦后期写作的精神。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10291v1">PDF</a> </p>
<p><strong>Summary</strong>：<br>我的论文《关于大型语言模型》被误解为支持对大语言模型的简约主义立场。但实际上并非如此，我不认同这种立场。此简短的笔记是在更大哲学项目的背景下论述论文内容，关注的是词汇的（误）使用而非形而上学问题，与维特根斯坦后期写作的精神相符。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>论文《关于大型语言模型》并未主张对大语言模型的简约主义立场。</li>
<li>作者不认同将论文解读为支持大语言模型的简化观点。</li>
<li>该论文被放置在更大的哲学项目中讨论，关注点在于词汇的（误）使用。</li>
<li>作者在论文中关注词汇使用的问题与维特根斯坦后期写作的精神相符。</li>
<li>论文的背景和意图被澄清。</li>
<li>作者强调论文的目的并非形而上学问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10291">Cool Papers</a></strong> </p>
<details>
  <summary>点击展开 Cool Papers 详细信息</summary>
  <p class="faq-q"><strong>Q</strong>: 这篇论文试图解决什么问题？</p>
<p class="faq-a"><strong>A</strong>: 这篇论文试图解决的问题是关于大型语言模型（LLMs）的哲学和语言使用上的误解。作者Murray Shanahan澄清了他之前论文《Talking About Large Language Models》中的一些观点，该论文被一些人误解为支持对大型语言模型的简化主义立场。作者强调，他并不支持这种立场，而是希望将论文置于一个更广泛的哲学项目中，该项目关注的是词语的（误）使用，而非形而上学问题，这与维特根斯坦后期的著作精神相一致。

<p>具体来说，作者试图解决以下几个问题：</p>
<ol>
<li><p><strong>对“简化主义”的误解</strong>：作者澄清，他并不认为LLMs仅仅是下一个词预测器，也不认为LLMs没有信念或知识。他反对将他的论点解释为对LLMs的简化主义理解。</p>
</li>
<li><p><strong>词语使用的哲学探讨</strong>：作者强调，他更关注于探讨词语如何被使用（或应该如何被使用），而不是做出形而上学的断言。他反对使用带有形而上学重量的“是”（is）的哲学断言。</p>
</li>
<li><p><strong>LLMs与信念的关系</strong>：作者讨论了在不同层次的LLMs系统中，使用“信念”一词的适当性。他提出了一个层次结构，随着系统的复杂性增加，使用“信念”一词的适当性也在增加。</p>
</li>
<li><p><strong>对LLMs的人类化语言的警告</strong>：作者提醒读者在使用人类化的语言来描述LLMs时要谨慎，因为LLMs在基本的机械层面上与人类非常不同。</p>
</li>
</ol>
<p>总的来说，这篇论文试图纠正对作者之前工作的误解，并提供一个更清晰的哲学视角来理解LLMs，特别是关于它们是否具有信念和知识的问题。</p></p>
<p class="faq-q"><strong>Q</strong>: 有哪些相关研究？</p>
<p class="faq-a"><strong>A</strong>: 这篇论文中提到了以下相关研究和文献：

<ol>
<li><p><strong>Daniel Dennett的工作</strong>：</p>
<ul>
<li>Dennett, D. (2009). Intentional systems theory. In The Oxford Handbook of Philosophy of Mind, pages 339–350. Oxford University Press.</li>
<li>Dennett的工作涉及意向性立场（Intentional Stance），这是一种解释行为的方式，将行为视为具有意图和信念的实体。作者引用Dennett的理论来讨论LLMs的行为。</li>
</ul>
</li>
<li><p><strong>S. M. Downes, P. Forber, 和 A. Grzankowski的研究</strong>：</p>
<ul>
<li>Downes, S. M., Forber, P., &amp; Grzankowski, A. (2024). LLMs are not just next token predictors. Inquiry, forthcoming, 2024. Also arXiv:2408.04666.</li>
<li>这篇论文讨论了LLMs不仅仅是下一个词的预测器，而是更复杂的系统。</li>
</ul>
</li>
<li><p><strong>S. Russell 和 P. Norvig的人工智能教科书</strong>：</p>
<ul>
<li>Russell, S., &amp; Norvig, P. (2010). Artificial Intelligence: A Modern Approach. Prentice Hall, 2010. Third Edition.</li>
<li>这本书是人工智能领域的经典教材，提供了AI领域的广泛知识，包括对智能体的定义和讨论。</li>
</ul>
</li>
<li><p><strong>Murray Shanahan的其他工作</strong>：</p>
<ul>
<li>Shanahan, M. (2010). Embodiment and the Inner Life: Cognition and Consciousness in the Space of Possible Minds. Oxford University Press.</li>
<li>Shanahan, M. (2024a). Simulacra as conscious exotica. Inquiry, <a target="_blank" rel="noopener" href="https://doi.org/10.1080/0020174X.2024.2434860">https://doi.org/10.1080/0020174X.2024.2434860</a>.</li>
<li>Shanahan, M. (2024b). Talking about large language models. Communications of the ACM, 67 (2):68–79, 2024b.</li>
<li>Shanahan, M., McDonell, K., &amp; Reynolds, L. (2023). Role play with large language models. Nature, 623:493–498, 2023.</li>
<li>这些论文和书籍涉及认知、意识、LLMs的行为和角色扮演等方面，与本论文的主题紧密相关。</li>
</ul>
</li>
<li><p><strong>Ludwig Wittgenstein的哲学研究</strong>：</p>
<ul>
<li>Wittgenstein, L. (1953). Philosophical Investigations. Basil Blackwell.</li>
<li>维特根斯坦的后期著作，特别是《哲学研究》，对语言的使用和哲学问题的处理提供了深刻的见解，影响了作者对LLMs的哲学探讨。</li>
</ul>
</li>
</ol>
<p>这些文献和研究为理解LLMs的哲学和认知问题提供了理论基础和背景，帮助作者构建了他对LLMs的哲学立场。</p></p>
<p class="faq-q"><strong>Q</strong>: 论文如何解决这个问题？</p>
<p class="faq-a"><strong>A</strong>: 论文通过以下几个步骤解决了关于大型语言模型（LLMs）的哲学和语言使用上的误解问题：

<ol>
<li><p><strong>澄清立场</strong>：</p>
<ul>
<li>作者首先澄清他并不支持将LLMs简化为仅仅是下一个词预测器的观点，也不认为LLMs没有信念或知识。他强调，他的工作被误解为支持简化主义立场，但实际上并非如此。</li>
</ul>
</li>
<li><p><strong>哲学项目定位</strong>：</p>
<ul>
<li>作者将自己的工作定位在一个更广泛的哲学项目中，该项目关注词语的（误）使用，而非形而上学问题。他引用了维特根斯坦后期的著作，特别是《哲学研究》，来支持他的观点，即关注词语的使用而非做出形而上学的断言。</li>
</ul>
</li>
<li><p><strong>讨论“信念”一词的使用</strong>：</p>
<ul>
<li>作者讨论了在不同层次的LLMs系统中，使用“信念”一词的适当性。他提出了一个层次结构，随着系统的复杂性增加，使用“信念”一词的适当性也在增加。</li>
</ul>
</li>
<li><p><strong>强调行为与信念的关系</strong>：</p>
<ul>
<li>作者强调，信念的概念与行为紧密相关。他认为，使用“信念”一词的原始语境是活跃的、行为化的人类（和其他动物），而将其用于完全被动的计算实体则偏离了这个词的原始语境。</li>
</ul>
</li>
<li><p><strong>提出层次结构</strong>：</p>
<ul>
<li>作者提出了一个从“bare-bones” LLM到更复杂的、能够进行多种行为的LLM-based系统的层次结构。在这个结构中，随着系统的复杂性增加，使用“信念”一词的适当性也在增加。</li>
</ul>
</li>
<li><p><strong>提醒人类化语言的谨慎使用</strong>：</p>
<ul>
<li>作者提醒读者在使用人类化的语言来描述LLMs时要谨慎，因为LLMs在基本的机械层面上与人类非常不同。</li>
</ul>
</li>
<li><p><strong>总结意图</strong>：</p>
<ul>
<li>作者总结他的意图不是采取关于信念的形而上学立场，也不是基于这些立场支持对LLM能力的简化观点。相反，他的目标是提醒读者LLM-based系统与人类在基本操作层面上的差异，并在使用拟人化语言描述它们时保持谨慎。</li>
</ul>
</li>
</ol>
<p>通过这些步骤，作者不仅澄清了自己的立场，还提供了一个框架来讨论和理解LLMs的哲学和语言问题，特别是关于它们是否具有信念和知识的问题。</p></p>
<p class="faq-q"><strong>Q</strong>: 论文做了哪些实验？</p>
<p class="faq-a"><strong>A</strong>: 根据提供的论文内容，这篇论文并没有提到进行任何具体的实验。相反，这篇论文是一个哲学性质的讨论，旨在澄清作者在之前论文中的观点，并探讨关于大型语言模型（LLMs）的哲学和语言使用问题。论文的重点在于概念分析和哲学论证，而不是实验研究。

<p>作者Murray Shanahan通过以下几个方面来阐述他的观点：</p>
<ul>
<li><p><strong>哲学立场的澄清</strong>：作者澄清了他并不支持将LLMs简化为仅仅是下一个词预测器的观点，也不认为LLMs没有信念或知识。</p>
</li>
<li><p><strong>哲学项目定位</strong>：作者将自己的工作定位在一个更广泛的哲学项目中，该项目关注词语的（误）使用，而非形而上学问题。</p>
</li>
<li><p><strong>讨论“信念”一词的使用</strong>：作者讨论了在不同层次的LLMs系统中，使用“信念”一词的适当性，并提出了一个层次结构。</p>
</li>
<li><p><strong>强调行为与信念的关系</strong>：作者强调，信念的概念与行为紧密相关，并讨论了如何将“信念”一词应用于LLMs。</p>
</li>
<li><p><strong>提出层次结构</strong>：作者提出了一个从“bare-bones” LLM到更复杂的、能够进行多种行为的LLM-based系统的层次结构。</p>
</li>
<li><p><strong>提醒人类化语言的谨慎使用</strong>：作者提醒读者在使用人类化的语言来描述LLMs时要谨慎。</p>
</li>
</ul>
<p>由于这篇论文是一个哲学讨论，它依赖于逻辑推理、概念分析和哲学论证，而不是实验数据。因此，论文中没有提到具体的实验设计或实验结果。</p></p>
<p class="faq-q"><strong>Q</strong>: 有什么可以进一步探索的点？</p>
<p class="faq-a"><strong>A</strong>: 基于这篇论文的内容和讨论，以下是一些可以进一步探索的点：

<ol>
<li><p><strong>LLMs的认知模型</strong>：</p>
<ul>
<li>研究LLMs在何种程度上可以被视为具有认知能力，以及它们的认知模型与人类认知模型之间的相似性和差异。</li>
</ul>
</li>
<li><p><strong>语言使用的哲学分析</strong>：</p>
<ul>
<li>深入分析“信念”、“知识”和“意图”等词汇在描述LLMs时的适用性，以及这些词汇的哲学含义。</li>
</ul>
</li>
<li><p><strong>人类化语言的限度</strong>：</p>
<ul>
<li>探讨在使用人类化语言描述LLMs时的限度和潜在的误导性，以及如何更准确地描述这些系统的行为和能力。</li>
</ul>
</li>
<li><p><strong>LLMs的行为和交互</strong>：</p>
<ul>
<li>研究LLMs在与人类交互时的行为模式，以及这些模式如何与人类行为相比较。</li>
</ul>
</li>
<li><p><strong>多模态LLMs的发展</strong>：</p>
<ul>
<li>探索多模态LLMs（能够处理视觉和文本输入的模型）的发展，以及它们如何改变我们对LLMs能力和认知的看法。</li>
</ul>
</li>
<li><p><strong>LLMs的伦理和社会影响</strong>：</p>
<ul>
<li>研究LLMs在社会中的使用所带来的伦理问题，包括隐私、偏见和责任归属等问题。</li>
</ul>
</li>
<li><p><strong>LLMs的自我修正能力</strong>：</p>
<ul>
<li>探索LLMs是否能够基于反馈进行自我修正，以及这种能力如何影响我们对它们的认知和行为的理解。</li>
</ul>
</li>
<li><p><strong>LLMs与意识的关系</strong>：</p>
<ul>
<li>深入探讨LLMs是否能够或在何种条件下可以被认为具有某种形式的意识，以及这对我们对“意识”概念的理解有何影响。</li>
</ul>
</li>
<li><p><strong>LLMs的教育应用</strong>：</p>
<ul>
<li>研究LLMs在教育领域的应用，包括个性化学习、自动评分和知识传递等方面。</li>
</ul>
</li>
<li><p><strong>LLMs的长期发展和未来展望</strong>：</p>
<ul>
<li>预测LLMs技术的长期发展趋势，以及它们可能对人类社会和文化的影响。</li>
</ul>
</li>
</ol>
<p>这些探索点涉及哲学、认知科学、人工智能、伦理学等多个领域，反映了LLMs作为一个跨学科研究领域的复杂性和多样性。</p></p>
<p class="faq-q"><strong>Q</strong>: 总结一下论文的主要内容</p>
<p class="faq-a"><strong>A</strong>: 这篇论文的主要内容可以总结如下：

<ol>
<li><p><strong>澄清误解</strong>：</p>
<ul>
<li>作者Murray Shanahan澄清了关于他之前论文《Talking About Large Language Models》的误解，强调他并不支持将大型语言模型（LLMs）简化为仅仅是下一个词预测器的观点，也不认为LLMs没有信念或知识。</li>
</ul>
</li>
<li><p><strong>哲学立场</strong>：</p>
<ul>
<li>作者将自己的工作定位在一个更广泛的哲学项目中，该项目关注词语的（误）使用，而非形而上学问题。他引用了维特根斯坦后期的著作，特别是《哲学研究》，来支持他的观点。</li>
</ul>
</li>
<li><p><strong>讨论“信念”一词的使用</strong>：</p>
<ul>
<li>作者讨论了在不同层次的LLMs系统中，使用“信念”一词的适当性，并提出了一个层次结构，随着系统的复杂性增加，使用“信念”一词的适当性也在增加。</li>
</ul>
</li>
<li><p><strong>行为与信念的关系</strong>：</p>
<ul>
<li>作者强调，信念的概念与行为紧密相关，并认为使用“信念”一词的原始语境是活跃的、行为化的人类（和其他动物），而将其用于完全被动的计算实体则偏离了这个词的原始语境。</li>
</ul>
</li>
<li><p><strong>层次结构</strong>：</p>
<ul>
<li>作者提出了一个从“bare-bones” LLM到更复杂的、能够进行多种行为的LLM-based系统的层次结构，在这个结构中，随着系统的复杂性增加，使用“信念”一词的适当性也在增加。</li>
</ul>
</li>
<li><p><strong>人类化语言的谨慎使用</strong>：</p>
<ul>
<li>作者提醒读者在使用人类化的语言来描述LLMs时要谨慎，因为LLMs在基本的机械层面上与人类非常不同。</li>
</ul>
</li>
<li><p><strong>论文的意图</strong>：</p>
<ul>
<li>作者总结他的意图不是采取关于信念的形而上学立场，也不是基于这些立场支持对LLM能力的简化观点。相反，他的目标是提醒读者LLM-based系统与人类在基本操作层面上的差异，并在使用拟人化语言描述它们时保持谨慎。</li>
</ul>
</li>
</ol>
<p>总的来说，这篇论文旨在纠正对作者之前工作的误解，并提供一个更清晰的哲学视角来理解LLMs，特别是关于它们是否具有信念和知识的问题。</p></p>
<p class="faq-q"><strong>Q</strong>: 想要进一步了解论文</p>
<p class="faq-a"><strong>A</strong>: 以上只是了解一篇论文的几个基本FAQ。如果你还想与Kimi进一步讨论该论文，请点击 <a href="http://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Still "Talking About Large Language Models": Some Clarifications，链接是 https://arxiv.org/pdf/2412.10291 ，已有的FAQ链接是 https://papers.cool/arxiv/kimi?paper=2412.10291 。请以此为基础，继续回答我后面的问题。&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false" target="_blank"><strong>这里 <i class="fa fa-external-link"></i></strong></a> 为你跳转Kimi AI网页版，并启动一个与该论文相关的新会话。</p>

</details>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-75662d17b0c8631f175a4b0138d42b3c.jpg" align="middle">
</details>



<h2 id="VQTalker-Towards-Multilingual-Talking-Avatars-through-Facial-Motion-Tokenization"><a href="#VQTalker-Towards-Multilingual-Talking-Avatars-through-Facial-Motion-Tokenization" class="headerlink" title="VQTalker: Towards Multilingual Talking Avatars through Facial Motion   Tokenization"></a>VQTalker: Towards Multilingual Talking Avatars through Facial Motion   Tokenization</h2><p><strong>Authors:Tao Liu, Ziyang Ma, Qi Chen, Feilong Chen, Shuai Fan, Xie Chen, Kai Yu</strong></p>
<p>We present VQTalker, a Vector Quantization-based framework for multilingual talking head generation that addresses the challenges of lip synchronization and natural motion across diverse languages. Our approach is grounded in the phonetic principle that human speech comprises a finite set of distinct sound units (phonemes) and corresponding visual articulations (visemes), which often share commonalities across languages. We introduce a facial motion tokenizer based on Group Residual Finite Scalar Quantization (GRFSQ), which creates a discretized representation of facial features. This method enables comprehensive capture of facial movements while improving generalization to multiple languages, even with limited training data. Building on this quantized representation, we implement a coarse-to-fine motion generation process that progressively refines facial animations. Extensive experiments demonstrate that VQTalker achieves state-of-the-art performance in both video-driven and speech-driven scenarios, particularly in multilingual settings. Notably, our method achieves high-quality results at a resolution of 512*512 pixels while maintaining a lower bitrate of approximately 11 kbps. Our work opens new possibilities for cross-lingual talking face generation. Synthetic results can be viewed at <a target="_blank" rel="noopener" href="https://x-lance.github.io/VQTalker">https://x-lance.github.io/VQTalker</a>. </p>
<blockquote>
<p>我们提出了VQTalker，这是一个基于向量量化的多语言说话人头部生成框架，解决了跨不同语言的嘴唇同步和自然动作挑战。我们的方法基于语音学原理，即人类语音由一组特定的声音单元（音素）和相应的视觉发音（可见单元）组成，这些单元往往在多种语言之间具有共性。我们引入了基于组残差有限标量量化（GRFSQ）的面部运动标记器，它创建了一种面部特征的离散表示。这种方法能够全面捕捉面部动作，同时提高在多种语言上的泛化能力，即使在有限的训练数据下也是如此。基于这种量化表示，我们实现了一种从粗到细的动作生成过程，逐步优化面部动画。大量实验表明，VQTalker在视频驱动和语音驱动的场景中都达到了最先进的性能，特别是在多语言环境中。值得注意的是，我们的方法在512*512像素的分辨率下达到了高质量的结果，同时保持了大约11kbps的较低比特率。我们的工作开辟了跨语言说话人脸生成的全新可能性。合成结果可在<a target="_blank" rel="noopener" href="https://x-lance.github.io/VQTalker%E6%9F%A5%E7%9C%8B%E3%80%82">https://x-lance.github.io/VQTalker查看。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.09892v1">PDF</a> 14 pages</p>
<p><strong>Summary</strong></p>
<p>基于向量量化的多语言说话人头生成框架VQTalker的研究介绍。该研究解决了不同语言之间的嘴唇同步和自然动作挑战。研究基于人类语音由有限数量的独特声音单元（音素）组成的语音学原理，以及与之对应的视觉表达（动素），这些元素在不同语言中通常具有共性。引入基于Group Residual Finite Scalar Quantization (GRFSQ)的面部运动标记器，能够创建面部特征的离散表示，提高了对多种语言的泛化能力，即使训练数据有限。基于这种量化表示，实现了从粗到细的运动生成过程，逐步优化面部动画。实验表明，VQTalker在视频驱动和语音驱动场景中均达到最新技术水平，特别是在多语言设置中。尤其值得关注的是，我们的方法以较低的比特率实现了高质量的512x512像素分辨率结果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VQTalker是一个基于向量量化的多语言说话人头生成框架。</li>
<li>它解决了嘴唇同步和自然动作在不同语言中的挑战。</li>
<li>研究利用音素和动素的共性，这些元素在不同语言中通常具有共性。</li>
<li>通过GRFSQ的面部运动标记器实现面部特征的离散表示。</li>
<li>该方法提高对不同语言的泛化能力，即使训练数据有限。</li>
<li>VQTalker在多种场景下表现出优秀的性能，特别是多语言环境中。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.09892">Cool Papers</a></strong> </p>
<details>
  <summary>点击展开 Cool Papers 详细信息</summary>
  <p class="faq-q"><strong>Q</strong>: 这篇论文试图解决什么问题？</p>
<p class="faq-a"><strong>A</strong>: 这篇论文介绍了一个名为VQTalker的框架，旨在解决多语言说话头像生成中的两个主要挑战：唇部同步和跨不同语言的自然运动。具体来说，论文试图解决的问题包括：

<ol>
<li><p><strong>唇部同步问题</strong>：精确的唇部同步对于创造真实的面部动画至关重要，由于McGurk效应，人类的语音感知受到听觉和视觉线索之间复杂交互的影响。现有的音频驱动的说话头像生成方法在唇部同步方面仍然存在问题，例如音频和视觉线索之间的错位或缺少特定的唇形。</p>
</li>
<li><p><strong>跨语言的泛化问题</strong>：大多数现有的训练数据集主要由印欧语系语言（如英语、德语和法语）主导，这导致在这些语言家族内训练的模型表现良好，但往往无法准确捕捉其他语言群体的唇部运动和面部表情。此外，现有方法依赖于连续表示，这可能导致训练难度增加，并导致模型过度拟合特定语言。</p>
</li>
<li><p><strong>数据量和泛化能力问题</strong>：虽然有些方法通过增加其他语言的训练数据量来改善模型性能，但这种策略资源密集，对于少数语言尤其具有挑战性。简单地增加数据量可能无法完全解决模型需要跨不同语言系统泛化的根本需求。</p>
</li>
</ol>
<p>VQTalker框架通过基于向量量化的方法来解决这些问题，通过将离散的语音单元映射到离散的面部运动标记，捕捉跨不同语言的语音驱动面部动画的基本元素，从而提高在多语言设置中的性能。</p></p>
<p class="faq-q"><strong>Q</strong>: 有哪些相关研究？</p>
<p class="faq-a"><strong>A</strong>: 论文中提到了多个与VQTalker框架相关的研究工作，涉及的领域包括语音驱动的头像生成、面部表示学习、面部标记化以及向量量化技术等。以下是一些具体的相关研究：

<ol>
<li><p><strong>语音驱动的头像生成方法</strong>：</p>
<ul>
<li>Zhang et al. (2023a)</li>
<li>Ma et al. (2023)</li>
<li>Liu et al. (2024)</li>
</ul>
</li>
<li><p><strong>面部表示学习</strong>：</p>
<ul>
<li>He et al. (2024)</li>
<li>Xu et al. (2024)</li>
<li>Drobyshev et al. (2024)</li>
</ul>
</li>
<li><p><strong>面部标记化（Facial Tokenization）</strong>：</p>
<ul>
<li>Xing et al. (2023a)</li>
<li>Tan, Ji, and Pan (2024)</li>
<li>Yu et al. (2024)</li>
</ul>
</li>
<li><p><strong>向量量化（Vector Quantization, VQ）技术</strong>：</p>
<ul>
<li>Group VQ (GVQ)：Baevski, Schneider, and Auli (2020); Chen, Watanabe, and Rudnicky (2023)</li>
<li>Residual VQ (RVQ)：Zeghidour et al. (2021); Copet et al. (2024)</li>
<li>Finite Scalar Quantization (FSQ)：Fabian et al. (2024)</li>
</ul>
</li>
<li><p><strong>其他相关技术</strong>：</p>
<ul>
<li>VQ-VAE (Esser, Rombach, and Ommer 2021)：用于面部标记化的方法。</li>
<li>BERT模型 (Devlin et al. 2019)：用于粗到细的运动生成过程。</li>
</ul>
</li>
</ol>
<p>这些研究为VQTalker框架提供了理论基础和技术背景，特别是在处理多语言说话头像生成中的唇部同步和自然运动方面。通过结合这些技术，VQTalker旨在提高跨语言的泛化能力，并在有限的训练数据下实现更高效的面部动画生成。</p></p>
<p class="faq-q"><strong>Q</strong>: 论文如何解决这个问题？</p>
<p class="faq-a"><strong>A</strong>: 论文通过提出VQTalker框架来解决多语言说话头像生成中的挑战，具体方法如下：

<ol>
<li><p><strong>基于向量量化的框架（Vector Quantization-based framework）</strong>：</p>
<ul>
<li>VQTalker利用基于向量量化的方法来捕捉面部运动，这种方法基于人类语音由有限的音素（phonemes）和相应的可视发音动作（visemes）组成的原理，这些在不同语言间通常有共通性。</li>
</ul>
</li>
<li><p><strong>面部运动标记化（Facial Motion Tokenization）</strong>：</p>
<ul>
<li>引入了基于Group Residual Finite Scalar Quantization（GRFSQ）的面部运动标记化方法，创建面部特征的离散表示。这种方法能够在有限的训练数据下改善对细微唇部运动的捕捉，并提高跨语言的泛化能力。</li>
</ul>
</li>
<li><p><strong>多策略量化方法（Multi-strategy Quantization Method）</strong>：</p>
<ul>
<li>采用GRFSQ方法，结合组量化、残差量化和有限标量量化策略，以实现高效的高分辨率面部运动建模，同时保持低比特率。</li>
</ul>
</li>
<li><p><strong>粗到细的运动生成过程（Coarse-to-fine Motion Generation Process）</strong>：</p>
<ul>
<li>实现了一个从粗到细的运动生成过程，使用BERT模型将离散的音频特征转换为面部运动标记，并逐步优化面部动画。这种方法结合了非自回归时序和自回归粒度方法，提高了动画的一致性和效率。</li>
</ul>
</li>
<li><p><strong>离散表示的优势</strong>：</p>
<ul>
<li>通过将连续的语音单元映射到离散的面部运动标记，VQTalker能够高效地模拟语音到面部运动的相关性，并且离散表示允许模型学习更紧凑的表示，减少信息泄露，而无需额外的模块或损失。</li>
</ul>
</li>
<li><p><strong>实验验证</strong>：</p>
<ul>
<li>通过广泛的实验，论文展示了VQTalker在视频驱动和语音驱动场景下都达到了最先进的性能，特别是在多语言设置中。此外，该方法在512×512像素的高分辨率下实现了高质量的结果，同时保持了大约11 kbps的低比特率。</li>
</ul>
</li>
</ol>
<p>总结来说，VQTalker框架通过结合面部运动的离散表示和粗到细的生成过程，有效地解决了多语言说话头像生成中的唇部同步和自然运动问题，并在保持低比特率的同时实现了高分辨率的动画生成。</p></p>
<p class="faq-q"><strong>Q</strong>: 论文做了哪些实验？</p>
<p class="faq-a"><strong>A</strong>: 论文中进行了一系列实验来评估VQTalker框架的性能，这些实验包括：

<ol>
<li><p><strong>视频重建结果（Video Reconstruction Result）</strong>：</p>
<ul>
<li>在HDTF数据集上评估了VQTalker与其他几种最先进的面部重演方法的性能，包括FOMM、DPE、MTIA、Vid2Vid、LIA、FADM、AniTalker、LivePortrait和EMOPortrait。评估指标包括结构相似性指数（SSIM）、学习感知图像补丁相似性（LPIPS）、余弦相似性（CSIM）、累积概率模糊检测（CPBD）等。</li>
</ul>
</li>
<li><p><strong>粗到细实验（Coarse-to-fine Experiment）</strong>：</p>
<ul>
<li>评估了VQTalker与其他几种语音驱动方法（SadTalker、EAT、PD-FGC、AniTalker、EDTalker、EchoMimic）的性能，包括在印欧语系（HDTF数据集）和非印欧语系（MNTE数据集）上的性能。评估指标与视频重建结果相同。</li>
</ul>
</li>
<li><p><strong>消融研究（Ablation Study）</strong>：</p>
<ul>
<li><strong>码本设计（Codebook Design）</strong>：比较了不同的码本设计在跨身份驱动场景下的性能，包括VQ、GVQ、RVQ和GRVQ等方法。</li>
<li><strong>离散与连续表示（Discrete vs. Continuous Representation）</strong>：比较了离散和连续表示在音频和运动特征中的性能，包括Whisper Large v2、VQ-Wav2vec、CosyVoice和GRFSQ等方法。</li>
</ul>
</li>
<li><p><strong>特定损失权重的影响（Effects of Loss Weight）</strong>：</p>
<ul>
<li>进行了消融实验来展示在眼动和口型建模中区域特定加权方法的有效性。通过比较有无眼动和口型损失的重建结果，展示了加权损失对于改善特定面部特征建模的作用。</li>
</ul>
</li>
<li><p><strong>VQ作为瓶颈结构（VQ as a Bottleneck Structure）</strong>：</p>
<ul>
<li>通过可视化消融实验来展示离散表示相比于连续表示在跨身份驱动场景下更不容易出现信息泄露的问题。</li>
</ul>
</li>
</ol>
<p>这些实验全面评估了VQTalker在不同方面的性能，包括视频重建、语音驱动的面部动画生成、不同码本设计的影响、离散与连续表示的比较，以及特定损失权重对模型性能的影响。通过这些实验，论文展示了VQTalker在多语言设置中生成高质量、高分辨率面部动画的能力。</p></p>
<p class="faq-q"><strong>Q</strong>: 有什么可以进一步探索的点？</p>
<p class="faq-a"><strong>A</strong>: 尽管VQTalker框架在多语言说话头像生成方面取得了令人瞩目的成果，但仍有一些领域可以进一步探索和改进：

<ol>
<li><p><strong>极端面部运动的处理</strong>：</p>
<ul>
<li>在涉及极端面部运动的场景中，可能会偶尔出现轻微的抖动。可以通过探索更高分辨率的量化空间或更先进的量化技术来减轻这一问题。</li>
</ul>
</li>
<li><p><strong>复杂背景和配饰的处理</strong>：</p>
<ul>
<li>由于使用包裹方法，复杂的背景或配饰有时会导致背景或配饰边缘出现模糊。未来的研究可以集中于改进背景处理和配饰集成方法。</li>
</ul>
</li>
<li><p><strong>提高跨语言泛化能力</strong>：</p>
<ul>
<li>尽管VQTalker在多语言设置中表现出色，但可以进一步研究如何提高模型对罕见或低资源语言的泛化能力。</li>
</ul>
</li>
<li><p><strong>计算效率优化</strong>：</p>
<ul>
<li>研究如何优化VQTalker的计算效率，使其能够在资源受限的设备上实时运行。</li>
</ul>
</li>
<li><p><strong>更精细的面部特征控制</strong>：</p>
<ul>
<li>进一步改进眼部、嘴部等关键面部特征的控制精度，以实现更加真实和准确的面部动画。</li>
</ul>
</li>
<li><p><strong>数据集和训练策略的改进</strong>：</p>
<ul>
<li>开发更多样化和平衡的数据集，包含更多非印欧语系语言，以提高模型的泛化能力。</li>
<li>探索更有效的训练策略，例如对抗训练或元学习，以提高模型的鲁棒性和适应性。</li>
</ul>
</li>
<li><p><strong>伦理和隐私问题</strong>：</p>
<ul>
<li>随着技术的发展，需要深入探讨与深度伪造、身份盗窃和错误信息传播相关的伦理和隐私问题，并制定相应的指导原则和验证系统。</li>
</ul>
</li>
<li><p><strong>多模态融合</strong>：</p>
<ul>
<li>研究如何将VQTalker与其他模态信息（如情感、手势）更有效地融合，以创造更丰富和自然的交流体验。</li>
</ul>
</li>
<li><p><strong>模型解释性和透明度</strong>：</p>
<ul>
<li>提高模型的可解释性，让研究人员和用户更好地理解模型的决策过程。</li>
</ul>
</li>
<li><p><strong>跨领域应用</strong>：</p>
<ul>
<li>探索VQTalker在其他领域的应用，如虚拟助手、游戏角色、教育和培训模拟等。</li>
</ul>
</li>
</ol>
<p>这些探索点不仅可以推动VQTalker技术的进步，还可能为计算机视觉、计算机图形学和人工智能领域的其他研究提供新的思路和方法。</p></p>
<p class="faq-q"><strong>Q</strong>: 总结一下论文的主要内容</p>
<p class="faq-a"><strong>A</strong>: 这篇论文介绍了VQTalker，一个基于向量量化的框架，用于生成多语言的说话头像。以下是论文的主要内容总结：

<ol>
<li><p><strong>问题陈述</strong>：</p>
<ul>
<li>针对音频驱动的头像生成中唇部同步和跨语言自然运动的挑战，尤其是在非印欧语系中。</li>
</ul>
</li>
<li><p><strong>核心理念</strong>：</p>
<ul>
<li>基于音素（phonemes）和可视发音动作（visemes）共享的普遍性，提出了一种将离散语音单元映射到离散面部运动标记的方法。</li>
</ul>
</li>
<li><p><strong>VQTalker框架</strong>：</p>
<ul>
<li>包含面部运动标记化和粗到细的运动生成过程。</li>
<li>利用Group Residual Finite Scalar Quantization（GRFSQ）进行面部运动的量化，以实现信息压缩和提高泛化能力。</li>
</ul>
</li>
<li><p><strong>技术贡献</strong>：</p>
<ul>
<li>提出了一种面部运动标记化方法，通过离散表示改善唇部运动捕捉和跨语言泛化。</li>
<li>GRFSQ方法结合了组量化、残差量化和有限标量量化策略，以实现高分辨率面部运动建模和低比特率。</li>
<li>实现了一个粗到细的运动生成过程，结合非自回归时序和自回归粒度方法，提高动画的一致性和效率。</li>
</ul>
</li>
<li><p><strong>实验结果</strong>：</p>
<ul>
<li>在视频驱动和语音驱动场景下均达到了最先进的性能，特别是在多语言设置中。</li>
<li>在512×512像素分辨率下实现了高质量的结果，同时保持了约11 kbps的低比特率。</li>
</ul>
</li>
<li><p><strong>消融研究和对比实验</strong>：</p>
<ul>
<li>对码本设计、离散与连续表示的影响进行了消融研究。</li>
<li>展示了VQTalker在不同语言上的性能，并与其他方法进行了对比。</li>
</ul>
</li>
<li><p><strong>潜在的改进和未来工作</strong>：</p>
<ul>
<li>提出了可能的改进方向，包括处理极端面部运动、优化背景和配饰处理、提高跨语言泛化能力等。</li>
</ul>
</li>
<li><p><strong>伦理考量</strong>：</p>
<ul>
<li>讨论了数字人类技术发展带来的伦理挑战，并强调了制定伦理指南和验证系统的重要性。</li>
</ul>
</li>
</ol>
<p>VQTalker通过其创新的离散表示和粗到细的生成方法，在多语言说话头像生成领域提供了一种有效的解决方案，同时为未来的研究提供了新的方向。</p></p>
<p class="faq-q"><strong>Q</strong>: 想要进一步了解论文</p>
<p class="faq-a"><strong>A</strong>: 以上只是了解一篇论文的几个基本FAQ。如果你还想与Kimi进一步讨论该论文，请点击 <a href="http://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VQTalker: Towards Multilingual Talking Avatars through Facial Motion Tokenization，链接是 https://arxiv.org/pdf/2412.09892 ，已有的FAQ链接是 https://papers.cool/arxiv/kimi?paper=2412.09892 。请以此为基础，继续回答我后面的问题。&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false" target="_blank"><strong>这里 <i class="fa fa-external-link"></i></strong></a> 为你跳转Kimi AI网页版，并启动一个与该论文相关的新会话。</p>

</details>


<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-eaa2ef91be4c38bf8e9e6ed69dd428f2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-d903e9a8b6f109a6410ad2e146374ec0.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-517e2e1de6cddffe89b3d76fd5e90cff.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-939465e52ea96050de776128eaa71669.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-9fce24eec4a9da3d2fecad6b047fa91f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2421a6952de4175341721627fed291bb.jpg" align="middle">
</details>




                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-17/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-17/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-17/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-d903e9a8b6f109a6410ad2e146374ec0.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-12-17  Still "Talking About Large Language Models" Some Clarifications
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-17/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-fb8685059f388de8b82e0bc6c456ffc6.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2024-12-17  Efficient Generative Modeling with Residual Vector Quantization-Based   Tokens
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">6736.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
