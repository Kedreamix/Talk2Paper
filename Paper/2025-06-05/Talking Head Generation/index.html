<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-05  TalkingMachines Real-Time Audio-Driven FaceTime-Style Video via   Autoregressive Diffusion Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-2e35b10a36d4c149c69be27a29f7472c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-05-æ›´æ–°"><a href="#2025-06-05-æ›´æ–°" class="headerlink" title="2025-06-05 æ›´æ–°"></a>2025-06-05 æ›´æ–°</h1><h2 id="TalkingMachines-Real-Time-Audio-Driven-FaceTime-Style-Video-via-Autoregressive-Diffusion-Models"><a href="#TalkingMachines-Real-Time-Audio-Driven-FaceTime-Style-Video-via-Autoregressive-Diffusion-Models" class="headerlink" title="TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via   Autoregressive Diffusion Models"></a>TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via   Autoregressive Diffusion Models</h2><p><strong>Authors:Chetwin Low, Weimin Wang</strong></p>
<p>In this paper, we present TalkingMachines â€“ an efficient framework that transforms pretrained video generation models into real-time, audio-driven character animators. TalkingMachines enables natural conversational experiences by integrating an audio large language model (LLM) with our video generation foundation model. Our primary contributions include: (1) We adapt a pretrained SOTA image-to-video DiT into an audio-driven avatar generation model of 18 billion parameters; (2) We enable infinite video streaming without error accumulation through asymmetric knowledge distillation from a bidirectional teacher model into a sparse causal, autoregressive student model; (3) We design a high-throughput, low-latency inference pipeline incorporating several key engineering optimizations such as: (a) disaggregation of the DiT and VAE decoder across separate devices, (b) efficient overlap of inter-device communication and computation using CUDA streams, (c) elimination of redundant recomputations to maximize frame-generation throughput. Please see demo videos here - <a target="_blank" rel="noopener" href="https://aaxwaz.github.io/TalkingMachines/">https://aaxwaz.github.io/TalkingMachines/</a> </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†TalkingMachinesâ€”â€”ä¸€ä¸ªé«˜æ•ˆæ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿå°†é¢„è®­ç»ƒçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹è½¬åŒ–ä¸ºå®æ—¶éŸ³é¢‘é©±åŠ¨çš„è§’è‰²åŠ¨ç”»ã€‚TalkingMachinesé€šè¿‡æ•´åˆéŸ³é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æˆ‘ä»¬çš„è§†é¢‘ç”ŸæˆåŸºç¡€æ¨¡å‹ï¼Œå®ç°äº†è‡ªç„¶çš„å¯¹è¯ä½“éªŒã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰æˆ‘ä»¬å°†é¢„è®­ç»ƒçš„å›¾åƒè½¬è§†é¢‘SOTA DiTæŠ€æœ¯è½¬åŒ–ä¸ºéŸ³é¢‘é©±åŠ¨çš„è§’è‰²ç”Ÿæˆæ¨¡å‹ï¼Œå‚æ•°è§„æ¨¡è¾¾åˆ°åå…«äº¿ï¼›ï¼ˆ2ï¼‰é€šè¿‡ä»åŒå‘æ•™å¸ˆæ¨¡å‹åˆ°ç¨€ç–å› æœè‡ªå›å½’å­¦ç”Ÿæ¨¡å‹çš„ä¸å¯¹ç§°çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œæˆ‘ä»¬å®ç°äº†æ— è¯¯å·®ç´¯ç§¯çš„æ— é™è§†é¢‘æµï¼›Â©æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜ååé‡çš„ä½å»¶è¿Ÿæ¨ç†ç®¡é“ï¼Œå¹¶è¿›è¡Œäº†å‡ é¡¹å…³é”®çš„å·¥ç¨‹ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ï¼šï¼ˆaï¼‰åœ¨å•ç‹¬çš„è®¾å¤‡ä¸Šåˆ†æ•£DiTå’ŒVAEè§£ç å™¨ï¼Œï¼ˆbï¼‰ä½¿ç”¨CUDAæµæœ‰æ•ˆåœ°é‡å è®¾å¤‡é—´é€šä¿¡å’Œè®¡ç®—ï¼Œï¼ˆcï¼‰æ¶ˆé™¤å†—ä½™é‡æ–°è®¡ç®—ä»¥æœ€å¤§åŒ–å¸§ç”Ÿæˆååé‡ã€‚ç›¸å…³æ¼”ç¤ºè§†é¢‘å¯è§<a target="_blank" rel="noopener" href="https://aaxwaz.github.io/TalkingMachines/%E3%80%82">https://aaxwaz.github.io/TalkingMachines/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03099v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä»‹ç»äº†TalkingMachinesæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯å°†é¢„è®­ç»ƒçš„å›¾åƒè½¬è§†é¢‘æ¨¡å‹è½¬åŒ–ä¸ºéŸ³é¢‘é©±åŠ¨çš„è™šæ‹Ÿè§’è‰²åŠ¨ç”»ç”Ÿæˆæ¨¡å‹ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ä½¿ç”¨å…ˆè¿›çš„å›¾åƒè½¬è§†é¢‘æŠ€æœ¯å®ç°å®æ—¶éŸ³é¢‘é©±åŠ¨çš„è§’è‰²åŠ¨ç”»ç”Ÿæˆï¼Œæ”¯æŒæ— é™è§†é¢‘æµä¸”ä¸ä¼šç´¯ç§¯è¯¯å·®ï¼Œä»¥åŠé«˜æ•ˆä½å»¶è¿Ÿçš„æ¨ç†ç®¡é“è®¾è®¡ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§æ¼”ç¤ºè§†é¢‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>TalkingMachinesæ˜¯ä¸€ä¸ªéŸ³é¢‘é©±åŠ¨çš„åŠ¨ç”»ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿè½¬æ¢é¢„è®­ç»ƒçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>é€šè¿‡æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¯¹è¯èƒ½åŠ›ã€‚</li>
<li>é‡‡ç”¨ä¸å¯¹ç§°çŸ¥è¯†è’¸é¦æŠ€æœ¯å®ç°è¿ç»­æ— è¯¯å·®çš„è§†é¢‘æµã€‚è¯¥æŠ€æœ¯ä½¿ç¨€ç–å› æœã€è‡ªå›å½’çš„å­¦ç”Ÿæ¨¡å‹ä»åŒå‘æ•™å¸ˆæ¨¡å‹ä¸­å­¦ä¹ ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03099">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e88bbe6307ae82f0717ada0b71c9f76e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fb8015874355c492456eb37cc85db06.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6cb0e86075fab363d9cdfd4f959e7217.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="NTIRE-2025-XGC-Quality-Assessment-Challenge-Methods-and-Results"><a href="#NTIRE-2025-XGC-Quality-Assessment-Challenge-Methods-and-Results" class="headerlink" title="NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results"></a>NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results</h2><p><strong>Authors:Xiaohong Liu, Xiongkuo Min, Qiang Hu, Xiaoyun Zhang, Jie Guo, Guangtao Zhai, Shushi Wang, Yingjie Zhou, Lu Liu, Jingxin Li, Liu Yang, Farong Wen, Li Xu, Yanwei Jiang, Xilei Zhu, Chunyi Li, Zicheng Zhang, Huiyu Duan, Xiele Wu, Yixuan Gao, Yuqin Cao, Jun Jia, Wei Sun, Jiezhang Cao, Radu Timofte, Baojun Li, Jiamian Huang, Dan Luo, Tao Liu, Weixia Zhang, Bingkun Zheng, Junlin Chen, Ruikai Zhou, Meiya Chen, Yu Wang, Hao Jiang, Xiantao Li, Yuxiang Jiang, Jun Tang, Yimeng Zhao, Bo Hu, Zelu Qi, Chaoyang Zhang, Fei Zhao, Ping Shi, Lingzhi Fu, Heng Cong, Shuai He, Rongyu Zhang, Jiarong He, Zongyao Hu, Wei Luo, Zihao Yu, Fengbin Guan, Yiting Lu, Xin Li, Zhibo Chen, Mengjing Su, Yi Wang, Tuo Chen, Chunxiao Li, Shuaiyu Zhao, Jiaxin Wen, Chuyi Lin, Sitong Liu, Ningxin Chu, Jing Wan, Yu Zhou, Baoying Chen, Jishen Zeng, Jiarui Liu, Xianjin Liu, Xin Chen, Lanzhi Zhou, Hangyu Li, You Han, Bibo Xiang, Zhenjie Liu, Jianzhang Lu, Jialin Gui, Renjie Lu, Shangfei Wang, Donghao Zhou, Jingyu Lin, Quanjian Song, Jiancheng Huang, Yufeng Yang, Changwei Wang, Shupeng Zhong, Yang Yang, Lihuo He, Jia Liu, Yuting Xing, Tida Fang, Yuchun Jin</strong></p>
<p>This paper reports on the NTIRE 2025 XGC Quality Assessment Challenge, which will be held in conjunction with the New Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025. This challenge is to address a major challenge in the field of video and talking head processing. The challenge is divided into three tracks, including user generated video, AI generated video and talking head. The user-generated video track uses the FineVD-GC, which contains 6,284 user generated videos. The user-generated video track has a total of 125 registered participants. A total of 242 submissions are received in the development phase, and 136 submissions are received in the test phase. Finally, 5 participating teams submitted their models and fact sheets. The AI generated video track uses the Q-Eval-Video, which contains 34,029 AI-Generated Videos (AIGVs) generated by 11 popular Text-to-Video (T2V) models. A total of 133 participants have registered in this track. A total of 396 submissions are received in the development phase, and 226 submissions are received in the test phase. Finally, 6 participating teams submitted their models and fact sheets. The talking head track uses the THQA-NTIRE, which contains 12,247 2D and 3D talking heads. A total of 89 participants have registered in this track. A total of 225 submissions are received in the development phase, and 118 submissions are received in the test phase. Finally, 8 participating teams submitted their models and fact sheets. Each participating team in every track has proposed a method that outperforms the baseline, which has contributed to the development of fields in three tracks. </p>
<blockquote>
<p>æœ¬æ–‡æŠ¥é“äº†å°†äºCVPR 2025ä¸¾åŠçš„NTIRE 2025 XGCè´¨é‡è¯„ä¼°æŒ‘æˆ˜èµ›ã€‚è¿™ä¸€æŒ‘æˆ˜æ˜¯ä¸ºäº†åº”å¯¹è§†é¢‘å’Œè¯­éŸ³å¤„ç†é¢†åŸŸçš„ä¸€å¤§æŒ‘æˆ˜ã€‚æŒ‘æˆ˜åˆ†ä¸ºä¸‰ä¸ªèµ›é“ï¼šç”¨æˆ·ç”Ÿæˆè§†é¢‘ã€AIç”Ÿæˆè§†é¢‘å’Œè¯­éŸ³è§†é¢‘ã€‚ç”¨æˆ·ç”Ÿæˆè§†é¢‘èµ›é“é‡‡ç”¨FineVD-GCæ•°æ®é›†ï¼ŒåŒ…å«6,284ä¸ªç”¨æˆ·ç”Ÿæˆçš„è§†é¢‘ï¼Œå…±æœ‰125åæ³¨å†Œå‚èµ›è€…ã€‚å¼€å‘é˜¶æ®µå…±æ”¶åˆ°242æ¬¡æäº¤ï¼Œæµ‹è¯•é˜¶æ®µæ”¶åˆ°136æ¬¡æäº¤ã€‚æœ€ç»ˆï¼Œæœ‰äº”ä¸ªå‚èµ›å›¢é˜Ÿæäº¤äº†ä»–ä»¬çš„æ¨¡å‹å’Œèµ„æ–™ã€‚AIç”Ÿæˆè§†é¢‘èµ›é“é‡‡ç”¨Q-Eval-Videoæ•°æ®é›†ï¼ŒåŒ…å«ç”±11ç§æµè¡Œçš„æ–‡æœ¬åˆ°è§†é¢‘ï¼ˆT2Vï¼‰æ¨¡å‹ç”Ÿæˆçš„34,029ä¸ªAIç”Ÿæˆè§†é¢‘ï¼ˆAIGVï¼‰ï¼Œå…±æœ‰133åæ³¨å†Œå‚èµ›è€…ã€‚å¼€å‘é˜¶æ®µå…±æ”¶åˆ°396æ¬¡æäº¤ï¼Œæµ‹è¯•é˜¶æ®µæ”¶åˆ°226æ¬¡æäº¤ã€‚æœ€ç»ˆï¼Œæœ‰å…­ä¸ªå‚èµ›å›¢é˜Ÿæäº¤äº†ä»–ä»¬çš„æ¨¡å‹å’Œèµ„æ–™ã€‚è¯­éŸ³èµ›é“é‡‡ç”¨THQA-NTIREæ•°æ®é›†ï¼ŒåŒ…å«12,247ä¸ªäºŒç»´å’Œä¸‰ç»´è¯­éŸ³å¤´ï¼Œå…±æœ‰89åæ³¨å†Œå‚èµ›è€…ã€‚å¼€å‘é˜¶æ®µå…±æ”¶åˆ°225æ¬¡æäº¤ï¼Œæµ‹è¯•é˜¶æ®µæ”¶åˆ°118æ¬¡æäº¤ã€‚æœ€ç»ˆï¼Œæœ‰å…«ä¸ªå‚èµ›å›¢é˜Ÿæäº¤äº†ä»–ä»¬çš„æ¨¡å‹å’Œèµ„æ–™ã€‚æ¯ä¸ªèµ›é“çš„å‚èµ›å›¢é˜Ÿéƒ½æå‡ºäº†è¶…è¶ŠåŸºçº¿çš„æ–¹æ³•ï¼Œä¸ºä¸‰ä¸ªé¢†åŸŸçš„å‘å±•åšå‡ºäº†è´¡çŒ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02875v1">PDF</a> NTIRE 2025 XGC Quality Assessment Challenge Report. arXiv admin note:   text overlap with arXiv:2404.16687</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å³å°†åœ¨CVPR 2025ä¸¾åŠçš„NTIRE 2025 XGCè´¨é‡è¯„ä¼°æŒ‘æˆ˜èµ›ã€‚è¯¥æŒ‘æˆ˜èµ›é’ˆå¯¹è§†é¢‘å’Œè°ˆè¯å¤´å¤„ç†é¢†åŸŸçš„ä¸»è¦æŒ‘æˆ˜ï¼Œåˆ†ä¸ºä¸‰ä¸ªèµ›é“ï¼šç”¨æˆ·ç”Ÿæˆè§†é¢‘ã€AIç”Ÿæˆè§†é¢‘å’Œè°ˆè¯å¤´ã€‚æ¯ä¸ªèµ›é“éƒ½æœ‰ç›¸åº”çš„æ•°æ®é›†å’Œå‚ä¸è€…ï¼Œå¹¶ä¸”æ¯ä¸ªå‚èµ›å›¢é˜Ÿåœ¨æ¯ä¸ªèµ›é“ä¸Šéƒ½æå‡ºäº†è¶…è¶ŠåŸºçº¿çš„æ–¹æ³•ï¼Œä¸ºå„èµ›é“çš„å‘å±•åšå‡ºäº†è´¡çŒ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NTIRE 2025 XGCè´¨é‡è¯„ä¼°æŒ‘æˆ˜èµ›å°†åœ¨CVPR 2025ä¸Šä¸¾åŠï¼Œæ—¨åœ¨è§£å†³è§†é¢‘å’Œè°ˆè¯å¤´å¤„ç†é¢†åŸŸçš„ä¸»è¦æŒ‘æˆ˜ã€‚</li>
<li>æŒ‘æˆ˜èµ›åˆ†ä¸ºä¸‰ä¸ªèµ›é“ï¼šç”¨æˆ·ç”Ÿæˆè§†é¢‘ã€AIç”Ÿæˆè§†é¢‘å’Œè°ˆè¯å¤´ã€‚</li>
<li>ç”¨æˆ·ç”Ÿæˆè§†é¢‘èµ›é“ä½¿ç”¨FineVD-GCæ•°æ®é›†ï¼ŒåŒ…å«6,284ä¸ªç”¨æˆ·ç”Ÿæˆè§†é¢‘ï¼Œæœ‰125åå‚èµ›è€…ã€‚</li>
<li>AIç”Ÿæˆè§†é¢‘èµ›é“ä½¿ç”¨Q-Eval-Videoæ•°æ®é›†ï¼ŒåŒ…å«34,029ä¸ªAIç”Ÿæˆè§†é¢‘ï¼Œç”±11ç§æµè¡Œçš„æ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹ç”Ÿæˆï¼Œæœ‰133åå‚èµ›è€…ã€‚</li>
<li>è°ˆè¯å¤´èµ›é“ä½¿ç”¨THQA-NTIREæ•°æ®é›†ï¼ŒåŒ…å«12,247ä¸ªäºŒç»´å’Œä¸‰ç»´è°ˆè¯å¤´ï¼Œæœ‰89åå‚èµ›è€…ã€‚</li>
<li>å„èµ›é“å‚èµ›å›¢é˜Ÿéƒ½æå‡ºäº†è¶…è¶ŠåŸºçº¿çš„æ–¹æ³•ï¼Œä¸ºå„èµ›é“çš„å‘å±•åšå‡ºäº†è´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02875">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8470501a8a97b841ef1b606f49084a84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9113f9fde4c841fbbd46528d9463f2b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01a620cf66708ca36b9834e318623986.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Cocktail-Party-Audio-Visual-Speech-Recognition"><a href="#Cocktail-Party-Audio-Visual-Speech-Recognition" class="headerlink" title="Cocktail-Party Audio-Visual Speech Recognition"></a>Cocktail-Party Audio-Visual Speech Recognition</h2><p><strong>Authors:Thai-Binh Nguyen, Ngoc-Quan Pham, Alexander Waibel</strong></p>
<p>Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech recognition in challenging environments, such as cocktail-party scenarios, where relying solely on audio proves insufficient. However, current AVSR models are often optimized for idealized scenarios with consistently active speakers, overlooking the complexities of real-world settings that include both speaking and silent facial segments. This study addresses this gap by introducing a novel audio-visual cocktail-party dataset designed to benchmark current AVSR systems and highlight the limitations of prior approaches in realistic noisy conditions. Additionally, we contribute a 1526-hour AVSR dataset comprising both talking-face and silent-face segments, enabling significant performance gains in cocktail-party environments. Our approach reduces WER by 67% relative to the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise, without relying on explicit segmentation cues. </p>
<blockquote>
<p>è§†å¬è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰ä¸ºåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¯å¢ƒä¸­è¿›è¡Œè¯­éŸ³è¯†åˆ«æä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆï¼Œå¦‚åœ¨é¸¡å°¾é…’ä¼šåœºæ™¯ä¸­ï¼Œä»…ä¾èµ–éŸ³é¢‘æ˜¯ä¸è¶³ä»¥åº”å¯¹çš„ã€‚ç„¶è€Œï¼Œå½“å‰çš„AVSRæ¨¡å‹é€šå¸¸é’ˆå¯¹ç†æƒ³åŒ–çš„åœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œè¿™äº›åœºæ™¯ä¸­å‘è¨€è€…å§‹ç»ˆæ´»è·ƒï¼Œå¿½ç•¥äº†åŒ…æ‹¬è¯´è¯å’Œæ— å£°é¢éƒ¨ç‰‡æ®µçš„å¤æ‚ç°å®ä¸–ç•Œçš„è®¾ç½®ã€‚æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥ä¸€ä¸ªæ–°é¢–çš„è§†å¬é¸¡å°¾é…’ä¼šæ•°æ®é›†æ¥è§£å†³è¿™ä¸€å·®è·ï¼Œè¯¥æ•°æ®é›†æ—¨åœ¨è¯„ä¼°å½“å‰çš„AVSRç³»ç»Ÿå¹¶çªå‡ºå…ˆå‰æ–¹æ³•åœ¨çœŸå®å˜ˆæ‚æ¡ä»¶ä¸‹çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è´¡çŒ®äº†ä¸€ä¸ªåŒ…å«è¯´è¯é¢éƒ¨å’Œæ— å£°é¢éƒ¨ç‰‡æ®µçš„1 5 2 6å°æ—¶AVSRæ•°æ®é›†ï¼Œèƒ½å¤Ÿåœ¨é¸¡å°¾é…’ä¼šç¯å¢ƒä¸­å®ç°æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºæœ€æ–°æŠ€æœ¯å°†å­—é”™è¯¯ç‡ï¼ˆWERï¼‰é™ä½äº†6 7ï¼…ï¼Œåœ¨æç«¯å™ªå£°æ¡ä»¶ä¸‹å°†WERä»1 1 9ï¼…é™ä½åˆ°3 9. 2ï¼…ï¼Œä¸”æ— éœ€ä¾èµ–æ˜ç¡®çš„åˆ†æ®µçº¿ç´¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02178v1">PDF</a> Accepted at Interspeech 2025</p>
<p><strong>Summary</strong>ï¼šè§†å¬è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰åœ¨å¤æ‚ç¯å¢ƒä¸­å…·æœ‰å¼ºå¤§çš„è¯­éŸ³è¯†åˆ«èƒ½åŠ›ï¼Œå¦‚é¸¡å°¾é…’ä¼šåœºæ™¯ã€‚ç„¶è€Œï¼Œå½“å‰AVSRæ¨¡å‹ä¸»è¦é’ˆå¯¹ç†æƒ³åŒ–åœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œå¿½ç•¥äº†ç°å®ä¸–ç•Œä¸­åŒ…æ‹¬è¯´è¯å’Œæ— å£°é¢éƒ¨ç‰‡æ®µçš„å¤æ‚æ€§ã€‚æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥æ–°çš„è§†å¬é¸¡å°¾é…’ä¼šæ•°æ®é›†æ¥è§£å†³è¿™ä¸€å·®è·ï¼Œè¯¥æ•°æ®é›†æ—¨åœ¨è¯„ä¼°å½“å‰AVSRç³»ç»Ÿå¹¶çªå‡ºå…ˆå‰æ–¹æ³•åœ¨çœŸå®å˜ˆæ‚æ¡ä»¶ä¸‹çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªåŒ…å«è¯´è¯é¢éƒ¨å’Œæ— å£°é¢éƒ¨ç‰‡æ®µçš„1526å°æ—¶AVSRæ•°æ®é›†ï¼Œå¯åœ¨é¸¡å°¾é…’ä¼šç¯å¢ƒä¸­å®ç°æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸ä¾èµ–æ˜ç¡®çš„åˆ†æ®µçº¿ç´¢çš„æƒ…å†µä¸‹ï¼Œç›¸å¯¹äºæœ€å…ˆè¿›çš„æŠ€æœ¯å°†å­—é”™è¯¯ç‡é™ä½äº†67%ï¼Œå°†æç«¯å™ªå£°ä¸‹çš„å­—é”™è¯¯ç‡ä»119%é™ä½åˆ°39.2%ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>AVSRåœ¨å¤æ‚ç¯å¢ƒä¸­å…·æœ‰ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨é¸¡å°¾é…’ä¼šåœºæ™¯ä¸­ã€‚</li>
<li>å½“å‰AVSRæ¨¡å‹ä¸»è¦å…³æ³¨ç†æƒ³åŒ–åœºæ™¯ï¼Œå¿½ç•¥äº†ç°å®ä¸–ç•Œçš„å¤æ‚æ€§ã€‚</li>
<li>å¼•å…¥æ–°çš„è§†å¬é¸¡å°¾é…’ä¼šæ•°æ®é›†ï¼Œä»¥è¯„ä¼°AVSRç³»ç»Ÿåœ¨ç°å®å˜ˆæ‚æ¡ä»¶ä¸‹çš„æ€§èƒ½ã€‚</li>
<li>æä¾›åŒ…å«è¯´è¯å’Œæ— å£°é¢éƒ¨ç‰‡æ®µçš„1526å°æ—¶AVSRæ•°æ®é›†ã€‚</li>
<li>æœ¬ç ”ç©¶çš„æ–¹æ³•åœ¨æç«¯å™ªå£°æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†æ€§èƒ½ï¼Œå°†å­—é”™è¯¯ç‡é™ä½äº†67%ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸ä¾èµ–æ˜ç¡®çš„åˆ†æ®µçº¿ç´¢çš„æƒ…å†µä¸‹å®ç°äº†æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cc36607e05a51d713f9c511e0e15d5bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e35b10a36d4c149c69be27a29f7472c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b356339adb5dff1f07b448cb12ffeb2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42bc00708561bcf29b7b5fcc585327c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0baa2356fe5fba1ac7f0549aeae2e0f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c28a3a4238927832867d7e165cd3704.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Silence-is-Golden-Leveraging-Adversarial-Examples-to-Nullify-Audio-Control-in-LDM-based-Talking-Head-Generation"><a href="#Silence-is-Golden-Leveraging-Adversarial-Examples-to-Nullify-Audio-Control-in-LDM-based-Talking-Head-Generation" class="headerlink" title="Silence is Golden: Leveraging Adversarial Examples to Nullify Audio   Control in LDM-based Talking-Head Generation"></a>Silence is Golden: Leveraging Adversarial Examples to Nullify Audio   Control in LDM-based Talking-Head Generation</h2><p><strong>Authors:Yuan Gan, Jiaxu Miao, Yunze Wang, Yi Yang</strong></p>
<p>Advances in talking-head animation based on Latent Diffusion Models (LDM) enable the creation of highly realistic, synchronized videos. These fabricated videos are indistinguishable from real ones, increasing the risk of potential misuse for scams, political manipulation, and misinformation. Hence, addressing these ethical concerns has become a pressing issue in AI security. Recent proactive defense studies focused on countering LDM-based models by adding perturbations to portraits. However, these methods are ineffective at protecting reference portraits from advanced image-to-video animation. The limitations are twofold: 1) they fail to prevent images from being manipulated by audio signals, and 2) diffusion-based purification techniques can effectively eliminate protective perturbations. To address these challenges, we propose Silencer, a two-stage method designed to proactively protect the privacy of portraits. First, a nullifying loss is proposed to ignore audio control in talking-head generation. Second, we apply anti-purification loss in LDM to optimize the inverted latent feature to generate robust perturbations. Extensive experiments demonstrate the effectiveness of Silencer in proactively protecting portrait privacy. We hope this work will raise awareness among the AI security community regarding critical ethical issues related to talking-head generation techniques. Code: <a target="_blank" rel="noopener" href="https://github.com/yuangan/Silencer">https://github.com/yuangan/Silencer</a>. </p>
<blockquote>
<p>åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„è°ˆè¯å¤´éƒ¨åŠ¨ç”»æŠ€æœ¯çš„è¿›æ­¥ï¼Œä½¿å¾—åˆ›å»ºé«˜åº¦é€¼çœŸã€åŒæ­¥çš„è§†é¢‘æˆä¸ºå¯èƒ½ã€‚è¿™äº›åˆæˆè§†é¢‘ä¸çœŸå®è§†é¢‘æ— æ³•åŒºåˆ†ï¼Œå¢åŠ äº†è¢«ç”¨äºæ¬ºè¯ˆã€æ”¿æ²»æ“çºµå’Œè¯¯å¯¼ä¿¡æ¯çš„æ½œåœ¨é£é™©ã€‚å› æ­¤ï¼Œè§£å†³è¿™äº›ä¼¦ç†é—®é¢˜å·²æˆä¸ºäººå·¥æ™ºèƒ½å®‰å…¨é¢†åŸŸçš„ç´§è¿«é—®é¢˜ã€‚æœ€è¿‘çš„ä¸»åŠ¨é˜²å¾¡ç ”ç©¶é›†ä¸­åœ¨é€šè¿‡å¯¹è‚–åƒæ·»åŠ æ‰°åŠ¨æ¥å¯¹æŠ—åŸºäºLDMçš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯¹äºä¿æŠ¤å‚è€ƒè‚–åƒå…å—å…ˆè¿›çš„å›¾åƒåˆ°è§†é¢‘åŠ¨ç”»æŠ€æœ¯çš„ä¾µå®³å¹¶ä¸æœ‰æ•ˆã€‚å…¶å±€é™æ€§æœ‰ä¸¤æ–¹é¢ï¼š1ï¼‰ä»–ä»¬æ— æ³•é˜²æ­¢å›¾åƒè¢«éŸ³é¢‘ä¿¡å·æ“çºµï¼›2ï¼‰åŸºäºæ‰©æ•£çš„å‡€åŒ–æŠ€æœ¯å¯ä»¥æœ‰æ•ˆåœ°æ¶ˆé™¤ä¿æŠ¤æ€§æ‰°åŠ¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Silencerï¼Œè¿™æ˜¯ä¸€ç§ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œæ—¨åœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤±æ•ˆæŸå¤±ï¼Œä»¥å¿½ç•¥å¤´éƒ¨è°ˆè¯ç”Ÿæˆä¸­çš„éŸ³é¢‘æ§åˆ¶ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨LDMä¸­åº”ç”¨äº†æŠ—å‡€åŒ–æŸå¤±ï¼Œä»¥ä¼˜åŒ–åå‘æ½œåœ¨ç‰¹å¾ï¼Œä»è€Œäº§ç”Ÿç¨³å¥çš„æ‰°åŠ¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSilenceråœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§æ–¹é¢éå¸¸æœ‰æ•ˆã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œå°†æé«˜äººå·¥æ™ºèƒ½å®‰å…¨ç¤¾åŒºå¯¹ä¸è°ˆè¯å¤´éƒ¨ç”ŸæˆæŠ€æœ¯ç›¸å…³çš„å…³é”®ä¼¦ç†é—®é¢˜çš„è®¤è¯†ã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/yuangan/Silencer%E3%80%82">https://github.com/yuangan/Silencerã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01591v1">PDF</a> Accepted to CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„è¯´è¯äººåŠ¨ç”»æŠ€æœ¯çš„è¿›å±•ï¼Œä½¿å¾—åˆ›å»ºé«˜åº¦é€¼çœŸã€åŒæ­¥çš„è§†é¢‘æˆä¸ºå¯èƒ½ã€‚è¿™äº›ä¼ªé€ çš„è§†é¢‘ä¸ç°å®ä¸­çš„è§†é¢‘éš¾ä»¥åŒºåˆ†ï¼Œå¢åŠ äº†è¢«ç”¨äºè¯ˆéª—ã€æ”¿æ²»æ“çºµå’Œè¯¯å¯¼ä¿¡æ¯æ½œåœ¨æ»¥ç”¨çš„é£é™©ã€‚å› æ­¤ï¼Œè§£å†³è¿™äº›ä¼¦ç†é—®é¢˜å·²æˆä¸ºäººå·¥æ™ºèƒ½å®‰å…¨é¢†åŸŸçš„ç´§è¿«è®®é¢˜ã€‚é’ˆå¯¹LDMæ¨¡å‹çš„æ–°é˜²å¾¡ç­–ç•¥é€šè¿‡æ·»åŠ æ‰°åŠ¨æ¥ä¿æŠ¤è‚–åƒï¼Œä½†è¿™ç§æ–¹æ³•å¯¹äºé˜²æ­¢éŸ³é¢‘ä¿¡å·æ“çºµå›¾åƒä»¥åŠæ¶ˆé™¤ä¿æŠ¤æ‰°åŠ¨æ–¹é¢çš„æ•ˆæœæœ‰é™ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Silencerï¼Œè¿™æ˜¯ä¸€ç§ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œæ—¨åœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§ã€‚é¦–å…ˆï¼Œæå‡ºä¸€ç§æ— æ•ˆæŸå¤±æ¥å¿½ç•¥è¯´è¯äººç”Ÿæˆä¸­çš„éŸ³é¢‘æ§åˆ¶ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨LDMä¸­åº”ç”¨æŠ—å‡€åŒ–æŸå¤±ï¼Œä»¥ä¼˜åŒ–åå‘æ½œåœ¨ç‰¹å¾ï¼Œäº§ç”Ÿç¨³å¥çš„æ‰°åŠ¨ã€‚å®éªŒè¯æ˜Silenceråœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½æé«˜äººå·¥æ™ºèƒ½å®‰å…¨ç¤¾åŒºå¯¹è¯´è¯äººç”ŸæˆæŠ€æœ¯ç›¸å…³é‡è¦ä¼¦ç†é—®é¢˜çš„è®¤è¯†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯´è¯äººåŠ¨ç”»æŠ€æœ¯åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰å‘å±•ï¼Œèƒ½åˆ›å»ºé«˜åº¦é€¼çœŸçš„è§†é¢‘ã€‚</li>
<li>ä¼ªé€ çš„è§†é¢‘ä¸ç°å®è§†é¢‘éš¾ä»¥åŒºåˆ†ï¼Œå¼•å‘å…³äºæ½œåœ¨æ»¥ç”¨çš„ä¼¦ç†æ‹…å¿§ã€‚</li>
<li>å½“å‰é˜²å¾¡ç­–ç•¥ä¸»è¦é€šè¿‡æ·»åŠ æ‰°åŠ¨æ¥ä¿æŠ¤è‚–åƒï¼Œä½†å¯¹éŸ³é¢‘ä¿¡å·æ“çºµå›¾åƒå’Œæ¶ˆé™¤ä¿æŠ¤æ‰°åŠ¨å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>Silenceræ–¹æ³•é€šè¿‡ä¸¤ä¸ªé˜¶æ®µä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§ï¼šæ— æ•ˆæŸå¤±ä»¥å¿½ç•¥éŸ³é¢‘æ§åˆ¶ï¼ŒæŠ—å‡€åŒ–æŸå¤±ä»¥ä¼˜åŒ–åå‘æ½œåœ¨ç‰¹å¾å¹¶äº§ç”Ÿç¨³å¥æ‰°åŠ¨ã€‚</li>
<li>å®éªŒè¯æ˜Silenceræ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥å·¥ä½œæ—¨åœ¨æé«˜äººå·¥æ™ºèƒ½å®‰å…¨ç¤¾åŒºå¯¹è¯´è¯äººç”ŸæˆæŠ€æœ¯ç›¸å…³ä¼¦ç†é—®é¢˜çš„è®¤è¯†ã€‚</li>
<li>ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/yuangan/Silencer%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/yuangan/Silencerè®¿é—®ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01591">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f7095e6165bb2376895185046f5c0147.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-929c41bfea4fe7e9f961e3b8614cbbc9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5adb306a5fc9adc6463bdab05bdf68a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-993d69840d9403c50dc9c500c3ef431b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bc566a47a349ec93cc5b45914d20fde.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Talking-to-Data-Designing-Smart-Assistants-for-Humanities-Databases"><a href="#Talking-to-Data-Designing-Smart-Assistants-for-Humanities-Databases" class="headerlink" title="Talking to Data: Designing Smart Assistants for Humanities Databases"></a>Talking to Data: Designing Smart Assistants for Humanities Databases</h2><p><strong>Authors:Alexander Sergeev, Valeriya Goloviznina, Mikhail Melnichenko, Evgeny Kotelnikov</strong></p>
<p>Access to humanities research databases is often hindered by the limitations of traditional interaction formats, particularly in the methods of searching and response generation. This study introduces an LLM-based smart assistant designed to facilitate natural language communication with digital humanities data. The assistant, developed in a chatbot format, leverages the RAG approach and integrates state-of-the-art technologies such as hybrid search, automatic query generation, text-to-SQL filtering, semantic database search, and hyperlink insertion. To evaluate the effectiveness of the system, experiments were conducted to assess the response quality of various language models. The testing was based on the Prozhito digital archive, which contains diary entries from predominantly Russian-speaking individuals who lived in the 20th century. The chatbot is tailored to support anthropology and history researchers, as well as non-specialist users with an interest in the field, without requiring prior technical training. By enabling researchers to query complex databases with natural language, this tool aims to enhance accessibility and efficiency in humanities research. The study highlights the potential of Large Language Models to transform the way researchers and the public interact with digital archives, making them more intuitive and inclusive. Additional materials are presented in GitHub repository: <a target="_blank" rel="noopener" href="https://github.com/alekosus/talking-to-data-intersys2025">https://github.com/alekosus/talking-to-data-intersys2025</a>. </p>
<blockquote>
<p>äººæ–‡ç§‘å­¦ç ”ç©¶çš„æ•°æ®åº“è®¿é—®å¸¸å¸¸å—åˆ°ä¼ ç»Ÿäº¤äº’å½¢å¼é™åˆ¶çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨æœç´¢å’Œå“åº”ç”Ÿæˆçš„æ–¹æ³•ä¸Šã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½åŠ©ç†ï¼Œæ—¨åœ¨ä¿ƒè¿›ä¸æ•°å­—äººæ–‡æ•°æ®çš„è‡ªç„¶è¯­è¨€äº¤æµã€‚è¯¥åŠ©ç†ä»¥èŠå¤©æœºå™¨äººå½¢å¼å¼€å‘ï¼Œé‡‡ç”¨RAGæ–¹æ³•ï¼Œå¹¶é›†æˆäº†æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œå¦‚æ··åˆæœç´¢ã€è‡ªåŠ¨æŸ¥è¯¢ç”Ÿæˆã€æ–‡æœ¬åˆ°SQLè¿‡æ»¤ã€è¯­ä¹‰æ•°æ®åº“æœç´¢å’Œè¶…é“¾æ¥æ’å…¥ã€‚ä¸ºäº†è¯„ä¼°ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ï¼Œè¿›è¡Œäº†ä¸€ç³»åˆ—å®éªŒæ¥è¯„ä¼°å„ç§è¯­è¨€æ¨¡å‹çš„å“åº”è´¨é‡ã€‚æµ‹è¯•åŸºäºProzhitoæ•°å­—æ¡£æ¡ˆé¦†è¿›è¡Œï¼Œè¯¥æ¡£æ¡ˆé¦†ä¸»è¦åŒ…å«20ä¸–çºªä¸»è¦ä½¿ç”¨ä¿„è¯­çš„ä¸ªäººæ—¥è®°ã€‚èŠå¤©æœºå™¨äººæ”¯æŒäººç±»å­¦å’Œå†å²ç ”ç©¶è€…ï¼Œä»¥åŠå¯¹è¯¥é¢†åŸŸæ„Ÿå…´è¶£çš„éä¸“ä¸šäººå£«ï¼Œæ— éœ€ä»–ä»¬æ¥å—äº‹å…ˆçš„æŠ€æœ¯åŸ¹è®­ã€‚é€šè¿‡ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¤æ‚æ•°æ®åº“ï¼Œè¿™ä¸ªå·¥å…·æ—¨åœ¨æé«˜äººæ–‡ç§‘å­¦ç ”ç©¶çš„å¯è®¿é—®æ€§å’Œæ•ˆç‡ã€‚è¯¥ç ”ç©¶çªå‡ºäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ½œåŠ›ï¼Œå¯ä»¥è½¬å˜ç ”ç©¶è€…å’Œå…¬ä¼—ä¸æ•°å­—æ¡£æ¡ˆçš„äº¤äº’æ–¹å¼ï¼Œä½¿å…¶æ›´åŠ ç›´è§‚å’ŒåŒ…å®¹ã€‚é™„åŠ ææ–™å‘ˆç°åœ¨GitHubä»“åº“ä¸­ï¼š<a target="_blank" rel="noopener" href="https://github.com/alekosus/talking-to-data-intersys2025%E3%80%82">https://github.com/alekosus/talking-to-data-intersys2025ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00986v1">PDF</a> Accepted for InterSys-2025 conference</p>
<p><strong>Summary</strong>ï¼šè¯¥ç ”ç©¶é€šè¿‡å¼•å…¥LLMæ™ºèƒ½åŠ©ç†æ¥è§£å†³ä¼ ç»Ÿäº¤äº’å½¢å¼åœ¨äººæ–‡å­¦ç§‘ç ”ç©¶æ•°æ®åº“ä½¿ç”¨ä¸Šçš„é™åˆ¶ã€‚æ™ºèƒ½åŠ©ç†ä»¥èŠå¤©æœºå™¨äººå½¢å¼å¼€å‘ï¼Œè¿ç”¨RAGæ–¹æ³•é›†æˆæ··åˆæœç´¢ç­‰æŠ€æœ¯ã€‚æµ‹è¯•è¡¨æ˜è¯¥å·¥å…·å¯ä»¥æœ‰æ•ˆæ”¯æŒäººç±»å­¦å’Œå†å²ç ”ç©¶ç­‰é¢†åŸŸçš„å­¦è€…è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢ã€‚å…¶å¯æå¤§æé«˜ç ”ç©¶è€…è®¿é—®å’Œä½¿ç”¨æ•°æ®åº“çš„æ•ˆç‡å’Œè´¨é‡ï¼Œæ¨åŠ¨äººæ–‡ç ”ç©¶æ•°å­—åŒ–å’Œå…¬å…±å‚ä¸åº¦æå‡ã€‚ç ”ç©¶çªå‡ºäº†å¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ”¹å–„ç ”ç©¶è€…å’Œå…¬ä¼—ä¸æ•°å­—æ¡£æ¡ˆäº¤äº’æ–¹å¼çš„æ½œåŠ›ã€‚å…·ä½“ä¿¡æ¯å’Œææ–™å¯é€šè¿‡GitHubè·å–ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ul>
<li>äººæ–‡å­¦ç§‘ç ”ç©¶æ•°æ®åº“å­˜åœ¨ä¼ ç»Ÿäº¤äº’å½¢å¼çš„å±€é™æ€§ï¼Œå¯¼è‡´è®¿é—®å’Œä½¿ç”¨æ•ˆç‡ä¸é«˜ã€‚</li>
<li>LLMæ™ºèƒ½åŠ©ç†å¼•å…¥ï¼Œè§£å†³æ­¤é—®é¢˜ï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ç®€åŒ–æ•°æ®åº“æŸ¥è¯¢æ–¹å¼ã€‚</li>
<li>æ™ºèƒ½åŠ©ç†ä»¥èŠå¤©æœºå™¨äººå½¢å¼å¼€å‘ï¼Œé›†æˆäº†æ··åˆæœç´¢ç­‰æŠ€æœ¯æ‰‹æ®µã€‚</li>
<li>å®éªŒè¯æ˜è¯¥å·¥å…·åœ¨æ”¯æŒäººç±»å­¦å’Œå†å²ç ”ç©¶æ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ”¹å–„ç ”ç©¶è€…å’Œå…¬ä¼—ä¸æ•°å­—æ¡£æ¡ˆäº¤äº’æ–¹é¢æ½œåŠ›å·¨å¤§ã€‚</li>
<li>æ™ºèƒ½åŠ©ç†çš„æ¨å‡ºæœ‰åŠ©äºæé«˜ç ”ç©¶è€…å’Œå…¬ä¼—è®¿é—®æ•°å­—æ¡£æ¡ˆçš„æ•ˆç‡å’Œä¾¿åˆ©æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00986">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-93632ad7f4f4e235ac8067c0b175ac42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e222e8b88d02fea96a8dc7905947741.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="HunyuanVideo-Avatar-High-Fidelity-Audio-Driven-Human-Animation-for-Multiple-Characters"><a href="#HunyuanVideo-Avatar-High-Fidelity-Audio-Driven-Human-Animation-for-Multiple-Characters" class="headerlink" title="HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for   Multiple Characters"></a>HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for   Multiple Characters</h2><p><strong>Authors:Yi Chen, Sen Liang, Zixiang Zhou, Ziyao Huang, Yifeng Ma, Junshu Tang, Qin Lin, Yuan Zhou, Qinglin Lu</strong></p>
<p>Recent years have witnessed significant progress in audio-driven human animation. However, critical challenges remain in (i) generating highly dynamic videos while preserving character consistency, (ii) achieving precise emotion alignment between characters and audio, and (iii) enabling multi-character audio-driven animation. To address these challenges, we propose HunyuanVideo-Avatar, a multimodal diffusion transformer (MM-DiT)-based model capable of simultaneously generating dynamic, emotion-controllable, and multi-character dialogue videos. Concretely, HunyuanVideo-Avatar introduces three key innovations: (i) A character image injection module is designed to replace the conventional addition-based character conditioning scheme, eliminating the inherent condition mismatch between training and inference. This ensures the dynamic motion and strong character consistency; (ii) An Audio Emotion Module (AEM) is introduced to extract and transfer the emotional cues from an emotion reference image to the target generated video, enabling fine-grained and accurate emotion style control; (iii) A Face-Aware Audio Adapter (FAA) is proposed to isolate the audio-driven character with latent-level face mask, enabling independent audio injection via cross-attention for multi-character scenarios. These innovations empower HunyuanVideo-Avatar to surpass state-of-the-art methods on benchmark datasets and a newly proposed wild dataset, generating realistic avatars in dynamic, immersive scenarios. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼ŒéŸ³é¢‘é©±åŠ¨çš„äººå½¢åŠ¨ç”»é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œä»ç„¶å­˜åœ¨ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š(i)åœ¨ä¿æŒè§’è‰²ä¸€è‡´æ€§çš„åŒæ—¶ç”Ÿæˆé«˜åº¦åŠ¨æ€çš„è§†é¢‘ï¼›(ii)å®ç°è§’è‰²å’ŒéŸ³é¢‘ä¹‹é—´çš„ç²¾ç¡®æƒ…æ„Ÿå¯¹é½ï¼›(iii)å®ç°å¤šè§’è‰²éŸ³é¢‘é©±åŠ¨åŠ¨ç”»ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¤šæ¨¡æ€æ‰©æ•£è½¬æ¢å™¨ï¼ˆMM-DiTï¼‰çš„â€œèƒ¡æºè§†é¢‘åŒ–èº«ï¼ˆHunyuanVideo-Avatarï¼‰â€ï¼Œå®ƒèƒ½å¤ŸåŒæ—¶ç”ŸæˆåŠ¨æ€ã€æƒ…æ„Ÿå¯æ§ã€å¤šè§’è‰²å¯¹è¯è§†é¢‘ã€‚å…·ä½“æ¥è¯´ï¼Œèƒ¡æºè§†é¢‘åŒ–èº«å¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼š(i)è®¾è®¡äº†è§’è‰²å›¾åƒæ³¨å…¥æ¨¡å—ï¼Œä»¥æ›¿ä»£ä¼ ç»Ÿçš„åŸºäºæ·»åŠ çš„è§’è‰²æ¡ä»¶æ–¹æ¡ˆï¼Œæ¶ˆé™¤äº†è®­ç»ƒå’Œæ¨ç†ä¹‹é—´å›ºæœ‰çš„æ¡ä»¶ä¸åŒ¹é…ï¼Œç¡®ä¿åŠ¨æ€è¿åŠ¨å’Œå¼ºçƒˆçš„è§’è‰²ä¸€è‡´æ€§ï¼›(ii)å¼•å…¥äº†éŸ³é¢‘æƒ…æ„Ÿæ¨¡å—ï¼ˆAEMï¼‰ï¼Œä»æƒ…æ„Ÿå‚è€ƒå›¾åƒä¸­æå–å¹¶è½¬ç§»æƒ…æ„Ÿçº¿ç´¢åˆ°ç›®æ ‡ç”Ÿæˆè§†é¢‘ï¼Œå®ç°ç²¾ç»†å’Œå‡†ç¡®çš„æƒ…æ„Ÿé£æ ¼æ§åˆ¶ï¼›(iii)æå‡ºäº†é¢éƒ¨æ„ŸçŸ¥éŸ³é¢‘é€‚é…å™¨ï¼ˆFAAï¼‰ï¼Œé€šè¿‡æ½œåœ¨å±‚é¢çš„é¢éƒ¨é®æŒ¡æ¥éš”ç¦»éŸ³é¢‘é©±åŠ¨çš„è§’è‰²ï¼Œå®ç°å¤šè§’è‰²åœºæ™¯ä¸­çš„ç‹¬ç«‹éŸ³é¢‘æ³¨å…¥ã€‚è¿™äº›åˆ›æ–°ä½¿èƒ¡æºè§†é¢‘åŒ–èº«åœ¨åŸºå‡†æ•°æ®é›†å’Œæ–°æå‡ºçš„é‡ç”Ÿæ•°æ®é›†ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨åŠ¨æ€ã€æ²‰æµ¸å¼åœºæ™¯ä¸­ç”Ÿæˆé€¼çœŸçš„åŒ–èº«ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20156v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸéŸ³é¢‘é©±åŠ¨çš„äººå½¢åŠ¨ç”»æŠ€æœ¯å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´ç”Ÿæˆé«˜åº¦åŠ¨æ€è§†é¢‘æ—¶ä¿æŒè§’è‰²ä¸€è‡´æ€§ã€å®ç°è§’è‰²æƒ…æ„Ÿä¸éŸ³é¢‘ç²¾å‡†å¯¹é½ä»¥åŠå®ç°å¤šè§’è‰²éŸ³é¢‘é©±åŠ¨åŠ¨ç”»ç­‰æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºåŸºäºå¤šæ¨¡æ€æ‰©æ•£å˜å‹å™¨ï¼ˆMM-DiTï¼‰çš„HunyuanVideo-Avataræ¨¡å‹ï¼Œèƒ½åŒæ—¶ç”ŸæˆåŠ¨æ€ã€æƒ…æ„Ÿå¯æ§ã€å¤šè§’è‰²å¯¹è¯è§†é¢‘ã€‚è¯¥æ¨¡å‹å¼•å…¥ä¸‰å¤§åˆ›æ–°ç‚¹ï¼šè§’è‰²å›¾åƒæ³¨å…¥æ¨¡å—ã€éŸ³é¢‘æƒ…æ„Ÿæ¨¡å—å’Œé¢éƒ¨æ„ŸçŸ¥éŸ³é¢‘é€‚é…å™¨ï¼Œåˆ†åˆ«è§£å†³ä»¥ä¸ŠæŒ‘æˆ˜ï¼Œä»è€Œåœ¨åŸºå‡†æµ‹è¯•é›†å’Œæ–°æå‡ºçš„é‡ç”Ÿæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œç”ŸæˆçœŸå®æ„Ÿå¼ºçš„åŠ¨æ€æ²‰æµ¸å¼è§’è‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éŸ³é¢‘é©±åŠ¨äººå½¢åŠ¨ç”»æŠ€æœ¯å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ç”Ÿæˆé«˜åº¦åŠ¨æ€è§†é¢‘çš„æŒ‘æˆ˜ï¼Œéœ€ä¿æŒè§’è‰²ä¸€è‡´æ€§ã€‚</li>
<li>æå‡ºåŸºäºå¤šæ¨¡æ€æ‰©æ•£å˜å‹å™¨çš„HunyuanVideo-Avataræ¨¡å‹ï¼Œèƒ½åŒæ—¶å¤„ç†åŠ¨æ€ã€æƒ…æ„Ÿå¯æ§ã€å¤šè§’è‰²å¯¹è¯è§†é¢‘ç”Ÿæˆã€‚</li>
<li>å¼•å…¥è§’è‰²å›¾åƒæ³¨å…¥æ¨¡å—ï¼Œæ›¿ä»£ä¼ ç»ŸåŸºäºæ·»åŠ çš„è§’è‰²æ¡ä»¶æ–¹æ¡ˆï¼Œç¡®ä¿åŠ¨æ€è¿åŠ¨å’Œå¼ºè§’è‰²ä¸€è‡´æ€§ã€‚</li>
<li>å¼•å…¥éŸ³é¢‘æƒ…æ„Ÿæ¨¡å—ï¼Œä»æƒ…æ„Ÿå‚è€ƒå›¾åƒä¸­æå–å¹¶è½¬ç§»æƒ…æ„Ÿçº¿ç´¢åˆ°ç›®æ ‡ç”Ÿæˆè§†é¢‘ï¼Œå®ç°ç²¾ç»†ç²’åº¦çš„æƒ…æ„Ÿé£æ ¼æ§åˆ¶ã€‚</li>
<li>æå‡ºé¢éƒ¨æ„ŸçŸ¥éŸ³é¢‘é€‚é…å™¨ï¼Œé€šè¿‡æ½œåœ¨å±‚é¢çš„é¢éƒ¨é®æŒ¡å®ç°ç‹¬ç«‹éŸ³é¢‘æ³¨å…¥ï¼Œæ”¯æŒå¤šè§’è‰²åœºæ™¯ä¸­çš„è·¨æ³¨æ„åŠ›ã€‚</li>
<li>HunyuanVideo-Avataræ¨¡å‹åœ¨åŸºå‡†æµ‹è¯•é›†å’Œæ–°æå‡ºçš„é‡ç”Ÿæ•°æ®é›†ä¸Šè¡¨ç°è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20156">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5739f239d8421552e167d8bed6a55a7d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b0451582f50bcc9dae6a596a50110b79.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f191e29f33badd4eb0eb9d5073fe3204.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="OmniTalker-One-shot-Real-time-Text-Driven-Talking-Audio-Video-Generation-With-Multimodal-Style-Mimicking"><a href="#OmniTalker-One-shot-Real-time-Text-Driven-Talking-Audio-Video-Generation-With-Multimodal-Style-Mimicking" class="headerlink" title="OmniTalker: One-shot Real-time Text-Driven Talking Audio-Video   Generation With Multimodal Style Mimicking"></a>OmniTalker: One-shot Real-time Text-Driven Talking Audio-Video   Generation With Multimodal Style Mimicking</h2><p><strong>Authors:Zhongjian Wang, Peng Zhang, Jinwei Qi, Guangyuan Wang, Chaonan Ji, Sheng Xu, Bang Zhang, Liefeng Bo</strong></p>
<p>Although significant progress has been made in audio-driven talking head generation, text-driven methods remain underexplored. In this work, we present OmniTalker, a unified framework that jointly generates synchronized talking audio-video content from input text while emulating the speaking and facial movement styles of the target identity, including speech characteristics, head motion, and facial dynamics. Our framework adopts a dual-branch diffusion transformer (DiT) architecture, with one branch dedicated to audio generation and the other to video synthesis. At the shallow layers, cross-modal fusion modules are introduced to integrate information between the two modalities. In deeper layers, each modality is processed independently, with the generated audio decoded by a vocoder and the video rendered using a GAN-based high-quality visual renderer. Leveraging the in-context learning capability of DiT through a masked-infilling strategy, our model can simultaneously capture both audio and visual styles without requiring explicit style extraction modules. Thanks to the efficiency of the DiT backbone and the optimized visual renderer, OmniTalker achieves real-time inference at 25 FPS. To the best of our knowledge, OmniTalker is the first one-shot framework capable of jointly modeling speech and facial styles in real time. Extensive experiments demonstrate its superiority over existing methods in terms of generation quality, particularly in preserving style consistency and ensuring precise audio-video synchronization, all while maintaining efficient inference. </p>
<blockquote>
<p>å°½ç®¡éŸ³é¢‘é©±åŠ¨çš„å¤´éƒ¨è¯´è¯ç”Ÿæˆå·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†æ–‡æœ¬é©±åŠ¨çš„æ–¹æ³•ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†OmniTalkerï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿä»è¾“å…¥æ–‡æœ¬ç”ŸæˆåŒæ­¥çš„éŸ³é¢‘è§†é¢‘å†…å®¹ï¼ŒåŒæ—¶æ¨¡æ‹Ÿç›®æ ‡èº«ä»½çš„è¯´è¯å’Œé¢éƒ¨è¿åŠ¨é£æ ¼ï¼ŒåŒ…æ‹¬è¯­éŸ³ç‰¹å¾ã€å¤´éƒ¨è¿åŠ¨å’Œé¢éƒ¨åŠ¨æ€ã€‚æˆ‘ä»¬çš„æ¡†æ¶é‡‡ç”¨äº†åŒåˆ†æ”¯æ‰©æ•£å˜å‹å™¨ï¼ˆDiTï¼‰æ¶æ„ï¼Œä¸€ä¸ªåˆ†æ”¯ç”¨äºéŸ³é¢‘ç”Ÿæˆï¼Œå¦ä¸€ä¸ªåˆ†æ”¯ç”¨äºè§†é¢‘åˆæˆã€‚åœ¨æµ…å±‚ï¼Œå¼•å…¥äº†è·¨æ¨¡æ€èåˆæ¨¡å—æ¥æ•´åˆä¸¤ç§æ¨¡æ€ä¹‹é—´çš„ä¿¡æ¯ã€‚åœ¨æ·±å±‚ï¼Œæ¯ä¸ªæ¨¡æ€ç‹¬ç«‹å¤„ç†ï¼Œç”Ÿæˆçš„éŸ³é¢‘ç”±vocoderè§£ç ï¼Œè§†é¢‘ä½¿ç”¨åŸºäºGANçš„é«˜è´¨é‡è§†è§‰æ¸²æŸ“å™¨å‘ˆç°ã€‚é€šè¿‡DiTçš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œç»“åˆæ©è†œå¡«å……ç­–ç•¥ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åŒæ—¶æ•æ‰éŸ³é¢‘å’Œè§†é¢‘é£æ ¼ï¼Œæ— éœ€æ˜ç¡®çš„é£æ ¼æå–æ¨¡å—ã€‚å¾—ç›ŠäºDiTéª¨å¹²ç½‘çš„æ•ˆç‡å’Œä¼˜åŒ–çš„è§†è§‰æ¸²æŸ“å™¨ï¼ŒOmniTalkerå®ç°äº†ä»¥æ¯ç§’25å¸§çš„å®æ—¶æ¨ç†ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒOmniTalkeræ˜¯é¦–ä¸ªèƒ½å¤Ÿå®æ—¶è”åˆå»ºæ¨¡è¯­éŸ³å’Œé¢éƒ¨é£æ ¼çš„å•æ¬¡æ¡†æ¶ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œå…¶åœ¨ç”Ÿæˆè´¨é‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä¿æŒé£æ ¼ä¸€è‡´æ€§å’Œç¡®ä¿éŸ³è§†é¢‘åŒæ­¥æ–¹é¢è¡¨ç°çªå‡ºï¼ŒåŒæ—¶ç»´æŒé«˜æ•ˆçš„æ¨ç†é€Ÿåº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02433v2">PDF</a> Project Page <a target="_blank" rel="noopener" href="https://humanaigc.github.io/omnitalker">https://humanaigc.github.io/omnitalker</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåä¸ºOmniTalkerçš„ç»Ÿä¸€æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»è¾“å…¥æ–‡æœ¬ç”ŸæˆåŒæ­¥çš„éŸ³é¢‘è§†é¢‘å†…å®¹ï¼ŒåŒæ—¶æ¨¡ä»¿ç›®æ ‡èº«ä»½çš„è¯´è¯å’Œé¢éƒ¨è¿åŠ¨é£æ ¼ï¼ŒåŒ…æ‹¬è¯­éŸ³ç‰¹å¾ã€å¤´éƒ¨è¿åŠ¨å’Œé¢éƒ¨åŠ¨æ€ã€‚OmniTalkeré‡‡ç”¨åŒåˆ†æ”¯æ‰©æ•£å˜å‹å™¨ï¼ˆDiTï¼‰æ¶æ„ï¼Œé€šè¿‡æ©è†œå¡«å……ç­–ç•¥å®ç°éŸ³é¢‘å’Œè§†é¢‘é£æ ¼çš„æ•æ‰ï¼Œæ— éœ€æ˜¾å¼é£æ ¼æå–æ¨¡å—ã€‚å€ŸåŠ©DiTçš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼ŒOmniTalkerèƒ½å®æ—¶ç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘å’Œè§†é¢‘å†…å®¹ï¼Œå®ç°å®æ—¶æ¨ç†ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒOmniTalkeræ˜¯é¦–ä¸ªèƒ½å¤Ÿå®æ—¶è”åˆå»ºæ¨¡è¯­éŸ³å’Œé¢éƒ¨é£æ ¼çš„å•é•œå¤´æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OmniTalkeræ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿä»è¾“å…¥æ–‡æœ¬ç”ŸæˆåŒæ­¥çš„éŸ³é¢‘è§†é¢‘å†…å®¹ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿæ¨¡ä»¿ç›®æ ‡èº«ä»½çš„è¯´è¯å’Œé¢éƒ¨è¿åŠ¨é£æ ¼ï¼ŒåŒ…æ‹¬è¯­éŸ³ç‰¹å¾ã€å¤´éƒ¨è¿åŠ¨å’Œé¢éƒ¨åŠ¨æ€ã€‚</li>
<li>OmniTalkeré‡‡ç”¨åŒåˆ†æ”¯æ‰©æ•£å˜å‹å™¨ï¼ˆDiTï¼‰æ¶æ„ï¼Œå®ç°éŸ³é¢‘å’Œè§†é¢‘å†…å®¹çš„ç”Ÿæˆã€‚</li>
<li>é€šè¿‡æ©è†œå¡«å……ç­–ç•¥ï¼ŒOmniTalkerèƒ½åŒæ—¶æ•æ‰éŸ³é¢‘å’Œè§†é¢‘é£æ ¼ï¼Œæ— éœ€æ˜¾å¼é£æ ¼æå–æ¨¡å—ã€‚</li>
<li>è¯¥æ¡†æ¶å…·æœ‰å®æ—¶ç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘å’Œè§†é¢‘çš„èƒ½åŠ›ï¼Œå®ç°å®æ—¶æ¨ç†ã€‚</li>
<li>OmniTalkeråœ¨ç”Ÿæˆè´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä¿æŒé£æ ¼ä¸€è‡´æ€§å’Œç¡®ä¿éŸ³è§†é¢‘åŒæ­¥æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02433">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c422af5e4fd7c15bd7808c77edd4867d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a68fb67dcd4f75f6a282dda8675f67e5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fc6877e804511b1d3bdfe8f16082c976.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bc67326813d3c1f912ec18496178c60b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-05/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-05/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-05/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-cb8907fe237c7478db2c8123ab464095.jpg" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-05  ANT Adaptive Neural Temporal-Aware Text-to-Motion Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-05/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-226f2d3a37045a091dcbce8e5c282893.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-05  Towards a Japanese Full-duplex Spoken Dialogue System
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
