<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="检测/分割/跟踪">
    <meta name="description" content="检测/分割/跟踪 方向最新论文已更新，请持续关注 Update in 2025-07-10  Efficient Event-Based Semantic Segmentation via Exploiting Frame-Event   Fusion A Hybrid Neural Network Approach">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>检测/分割/跟踪 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-7b0c651c0e221b3cf53d298dbc4f2ef5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">检测/分割/跟踪</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">检测/分割/跟踪</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                检测/分割/跟踪
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    21 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-10-更新"><a href="#2025-07-10-更新" class="headerlink" title="2025-07-10 更新"></a>2025-07-10 更新</h1><h2 id="Efficient-Event-Based-Semantic-Segmentation-via-Exploiting-Frame-Event-Fusion-A-Hybrid-Neural-Network-Approach"><a href="#Efficient-Event-Based-Semantic-Segmentation-via-Exploiting-Frame-Event-Fusion-A-Hybrid-Neural-Network-Approach" class="headerlink" title="Efficient Event-Based Semantic Segmentation via Exploiting Frame-Event   Fusion: A Hybrid Neural Network Approach"></a>Efficient Event-Based Semantic Segmentation via Exploiting Frame-Event   Fusion: A Hybrid Neural Network Approach</h2><p><strong>Authors:Hebei Li, Yansong Peng, Jiahui Yuan, Peixi Wu, Jin Wang, Yueyi Zhang, Xiaoyan Sun</strong></p>
<p>Event cameras have recently been introduced into image semantic segmentation, owing to their high temporal resolution and other advantageous properties. However, existing event-based semantic segmentation methods often fail to fully exploit the complementary information provided by frames and events, resulting in complex training strategies and increased computational costs. To address these challenges, we propose an efficient hybrid framework for image semantic segmentation, comprising a Spiking Neural Network branch for events and an Artificial Neural Network branch for frames. Specifically, we introduce three specialized modules to facilitate the interaction between these two branches: the Adaptive Temporal Weighting (ATW) Injector, the Event-Driven Sparse (EDS) Injector, and the Channel Selection Fusion (CSF) module. The ATW Injector dynamically integrates temporal features from event data into frame features, enhancing segmentation accuracy by leveraging critical dynamic temporal information. The EDS Injector effectively combines sparse event data with rich frame features, ensuring precise temporal and spatial information alignment. The CSF module selectively merges these features to optimize segmentation performance. Experimental results demonstrate that our framework not only achieves state-of-the-art accuracy across the DDD17-Seg, DSEC-Semantic, and M3ED-Semantic datasets but also significantly reduces energy consumption, achieving a 65% reduction on the DSEC-Semantic dataset. </p>
<blockquote>
<p>事件相机因其高时间分辨率和其他优势属性而最近被引入到图像语义分割中。然而，现有的基于事件的语义分割方法往往未能充分利用帧和事件提供的互补信息，导致复杂的训练策略和计算成本增加。为了应对这些挑战，我们提出了一种用于图像语义分割的高效混合框架，该框架包括用于事件的脉冲神经网络分支和用于帧的人工神经网络分支。具体来说，我们引入了三个专用模块来促进这两个分支之间的交互：自适应时间加权（ATW）注入器、事件驱动稀疏（EDS）注入器和通道选择融合（CSF）模块。ATW注入器动态地将事件数据的临时特征融合到帧特征中，利用关键动态临时信息提高分割精度。EDS注入器有效地将稀疏事件数据与丰富的帧特征相结合，确保精确的临时和空间信息对齐。CSF模块有选择地合并这些特征以优化分割性能。实验结果表明，我们的框架不仅在DDD17-Seg、DSEC-Semantic和M3ED-Semantic数据集上达到了最先进的精度，而且在DSEC-Semantic数据集上实现了65%的能耗减少。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03765v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>事件相机因其高时间分辨率和其他优势特性最近已被引入图像语义分割领域。然而，现有的基于事件语义分割方法未能充分利用帧和事件提供的互补信息，导致复杂的训练策略和增加的计算成本。为解决这些挑战，我们提出了一种高效的混合框架，包括用于事件的脉冲神经网络分支和用于帧的人工神经网络分支。具体地，我们引入了三个专业模块来促进这两个分支之间的交互：自适应时间加权（ATW）注入器、事件驱动稀疏（EDS）注入器和通道选择融合（CSF）模块。ATW注入器动态地将事件数据的时间特征集成到帧特征中，利用关键动态时间信息提高分割精度。EDS注入器有效地将稀疏事件数据与丰富的帧特征相结合，确保精确的时间和空间信息对齐。CSF模块选择性地合并这些特征以优化分割性能。实验结果表明，我们的框架不仅在DDD17-Seg、DSEC-Semantic和M3ED-Semantic数据集上实现了最先进的精度，而且显著降低了能耗，在DSEC-Semantic数据集上实现了65%的能耗减少。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>事件相机因其高时间分辨率和其他优势特性被引入图像语义分割领域。</li>
<li>现有方法未能充分利用事件和帧的互补信息。</li>
<li>提出的混合框架包括脉冲神经网络分支和人工神经网络分支。</li>
<li>引入三个专业模块：ATW注入器、EDS注入器和CSF模块，以促进框架内两个分支的交互。</li>
<li>ATW注入器通过集成事件数据的时间特征提高分割精度。</li>
<li>EDS注入器确保事件数据和帧特征的时空信息精确对齐。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03765">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-75282a56b5bc425c0cc6b7194be5b8cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc720aec19d73903a74692822aa2ada7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5591636a84d5d1945406f9217a13566.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-59b199b93c28e3b39f1a9a179e23f3ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ccb9fd04c564574410e05547b4f6235.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Leveraging-Out-of-Distribution-Unlabeled-Images-Semi-Supervised-Semantic-Segmentation-with-an-Open-Vocabulary-Model"><a href="#Leveraging-Out-of-Distribution-Unlabeled-Images-Semi-Supervised-Semantic-Segmentation-with-an-Open-Vocabulary-Model" class="headerlink" title="Leveraging Out-of-Distribution Unlabeled Images: Semi-Supervised   Semantic Segmentation with an Open-Vocabulary Model"></a>Leveraging Out-of-Distribution Unlabeled Images: Semi-Supervised   Semantic Segmentation with an Open-Vocabulary Model</h2><p><strong>Authors:Wooseok Shin, Jisu Kang, Hyeonki Jeong, Jin Sob Kim, Sung Won Han</strong></p>
<p>In semi-supervised semantic segmentation, existing studies have shown promising results in academic settings with controlled splits of benchmark datasets. However, the potential benefits of leveraging significantly larger sets of unlabeled images remain unexplored. In real-world scenarios, abundant unlabeled images are often available from online sources (web-scraped images) or large-scale datasets. However, these images may have different distributions from those of the target dataset, a situation known as out-of-distribution (OOD). Using these images as unlabeled data in semi-supervised learning can lead to inaccurate pseudo-labels, potentially misguiding network training. In this paper, we propose a new semi-supervised semantic segmentation framework with an open-vocabulary segmentation model (SemiOVS) to effectively utilize unlabeled OOD images. Extensive experiments on Pascal VOC and Context datasets demonstrate two key findings: (1) using additional unlabeled images improves the performance of semi-supervised learners in scenarios with few labels, and (2) using the open-vocabulary segmentation (OVS) model to pseudo-label OOD images leads to substantial performance gains. In particular, SemiOVS outperforms existing PrevMatch and SemiVL methods by +3.5 and +3.0 mIoU, respectively, on Pascal VOC with a 92-label setting, achieving state-of-the-art performance. These findings demonstrate that our approach effectively utilizes abundant unlabeled OOD images for semantic segmentation tasks. We hope this work can inspire future research and real-world applications. The code is available at <a target="_blank" rel="noopener" href="https://github.com/wooseok-shin/SemiOVS">https://github.com/wooseok-shin/SemiOVS</a> </p>
<blockquote>
<p>在半监督语义分割领域，现有研究在基准数据集的控制分割中已显示出令人鼓舞的结果。然而，利用大量未标记图像的优势仍未被探索。在真实世界场景中，大量未标记的图像通常可以从在线来源（网络爬取的图像）或大规模数据集中获得。但这些图像的分布可能与目标数据集的分布不同，这种情况被称为分布外（OOD）。将这些图像作为半监督学习的未标记数据可能导致不准确的伪标签，从而可能误导网络训练。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03302v1">PDF</a> 19pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新的半监督语义分割框架，利用开放词汇分割模型（SemiOVS）有效利用未标记的OOD图像。实验表明，使用额外的未标记图像在标签较少的情况下提高了半监督学习者的性能，使用开放词汇分割模型对OOD图像进行伪标签标注带来了显著的性能提升。该方法在Pascal VOC数据集上实现了最先进的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有半监督语义分割研究主要在学术设置下对基准数据集进行受控分割，但利用大量未标记图像的优势尚未被完全探索。</li>
<li>在现实世界中，可以从在线来源（如网络抓取图像）或大规模数据集获得大量未标记图像，但这些图像可能与目标数据集分布不同，即出现OOD情况。</li>
<li>使用未标记的OOD图像进行半监督学习可能导致不准确的伪标签，从而误导网络训练。</li>
<li>本文提出了一种新的半监督语义分割框架（SemiOVS），能有效利用未标记的OOD图像。</li>
<li>实验表明，使用额外未标记图像在标签有限的情况下能提高半监督学习者性能。</li>
<li>使用开放词汇分割模型（OVS）对OOD图像进行伪标签标注，带来了显著的性能提升。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03302">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-92c765c4d81afd95cd4d11d82ec47ca5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-81b56da2bdb3ac866fdb45759bc61db7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47d49205dc30e29f41e5c781546bfe71.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-53e39babc0e677fc537d5e68379e94b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c038306c412fa5bd7f31fda28d2883cb.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MaSS13K-A-Matting-level-Semantic-Segmentation-Benchmark"><a href="#MaSS13K-A-Matting-level-Semantic-Segmentation-Benchmark" class="headerlink" title="MaSS13K: A Matting-level Semantic Segmentation Benchmark"></a>MaSS13K: A Matting-level Semantic Segmentation Benchmark</h2><p><strong>Authors:Chenxi Xie, Minghan Li, Hui Zeng, Jun Luo, Lei Zhang</strong></p>
<p>High-resolution semantic segmentation is essential for applications such as image editing, bokeh imaging, AR&#x2F;VR, etc. Unfortunately, existing datasets often have limited resolution and lack precise mask details and boundaries. In this work, we build a large-scale, matting-level semantic segmentation dataset, named MaSS13K, which consists of 13,348 real-world images, all at 4K resolution. MaSS13K provides high-quality mask annotations of a number of objects, which are categorized into seven categories: human, vegetation, ground, sky, water, building, and others. MaSS13K features precise masks, with an average mask complexity 20-50 times higher than existing semantic segmentation datasets. We consequently present a method specifically designed for high-resolution semantic segmentation, namely MaSSFormer, which employs an efficient pixel decoder that aggregates high-level semantic features and low-level texture features across three stages, aiming to produce high-resolution masks with minimal computational cost. Finally, we propose a new learning paradigm, which integrates the high-quality masks of the seven given categories with pseudo labels from new classes, enabling MaSSFormer to transfer its accurate segmentation capability to other classes of objects. Our proposed MaSSFormer is comprehensively evaluated on the MaSS13K benchmark together with 14 representative segmentation models. We expect that our meticulously annotated MaSS13K dataset and the MaSSFormer model can facilitate the research of high-resolution and high-quality semantic segmentation. Datasets and codes can be found at <a target="_blank" rel="noopener" href="https://github.com/xiechenxi99/MaSS13K">https://github.com/xiechenxi99/MaSS13K</a>. </p>
<blockquote>
<p>高分辨率语义分割对于图像编辑、散景成像、增强现实&#x2F;虚拟现实等应用至关重要。然而，现有数据集往往分辨率有限，缺乏精确的掩膜细节和边界。在这项工作中，我们构建了一个大规模、材质级别的语义分割数据集，名为MaSS13K，由13348张真实世界的4K分辨率图像组成。MaSS13K提供了高质量的对象掩膜注释，这些对象被分为七大类：人类、植被、地面、天空、水、建筑和其他。MaSS13K的掩膜非常精确，其平均掩膜复杂度比现有语义分割数据集高20-50倍。因此，我们提出了一种专门用于高分辨率语义分割的方法，名为MaSSFormer，它采用高效的像素解码器，跨三个阶段聚合高级语义特征和低级纹理特征，旨在以最小的计算成本生成高分辨率掩膜。最后，我们提出了一种新的学习范式，它将给定的七类的高质量掩膜与来自新类别的伪标签相结合，使MaSSFormer能够将准确的分割能力迁移到其他类别的对象上。MaSSFormer在MaSS13K基准测试上与14种代表性的分割模型进行了全面评估。我们希望我们的精心标注的MaSS13K数据集和MaSSFormer模型能够促进高分辨率和高质量语义分割的研究。数据集和代码可在<a target="_blank" rel="noopener" href="https://github.com/xiechenxi99/MaSS13K%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/xiechenxi99/MaSS13K找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18364v2">PDF</a> CVPR2025</p>
<p><strong>Summary</strong><br>     本文构建了一个大规模、成像级别语义分割数据集MaSS13K，包含13,348张真实世界的4K图像，提供高质量的对象掩膜标注，分为七大类。同时提出了一种针对高分辨率语义分割的方法MaSSFormer，采用高效像素解码器聚合高级语义特征和低级纹理特征，并引入新的学习范式，利用高质量掩膜和伪标签提升分割能力。MaSS13K数据集和MaSSFormer模型有助于高分辨率和高质量语义分割的研究。</p>
<p><strong>Key Takeaways</strong></p>
<pre><code>1. 构建了一个大规模的高分辨率语义分割数据集MaSS13K，包含真实世界的图像，分辨率高达4K。
2. MaSS13K数据集提供了高质量的对象掩膜标注，分为七大类：人类、植被、地面、天空、水域、建筑和其他。
3. MaSS13K数据集的掩膜精度高于现有语义分割数据集，平均复杂度高出20-50倍。
4. 提出了一种针对高分辨率语义分割的方法MaSSFormer，能有效聚合高级语义特征和低级纹理特征。
5. MaSSFormer采用新的学习范式，结合高质量掩膜和伪标签，提高了对新类别对象的准确分割能力。
6. MaSSFormer在MaSS13K基准测试上进行了全面评估，并与其他代表性分割模型进行了比较。
</code></pre>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18364">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-869f5857b7bef6a2c7f3bcfd2b27efde.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c262b9525d3e0fc982a381cef083bd6b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b50db114e97b3c73e63c072bb7425c2c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CFMW-Cross-modality-Fusion-Mamba-for-Robust-Object-Detection-under-Adverse-Weather"><a href="#CFMW-Cross-modality-Fusion-Mamba-for-Robust-Object-Detection-under-Adverse-Weather" class="headerlink" title="CFMW: Cross-modality Fusion Mamba for Robust Object Detection under   Adverse Weather"></a>CFMW: Cross-modality Fusion Mamba for Robust Object Detection under   Adverse Weather</h2><p><strong>Authors:Haoyuan Li, Qi Hu, Binjia Zhou, You Yao, Jiacheng Lin, Kailun Yang, Peng Chen</strong></p>
<p>Visible-infrared image pairs provide complementary information, enhancing the reliability and robustness of object detection applications in real-world scenarios. However, most existing methods face challenges in maintaining robustness under complex weather conditions, which limits their applicability. Meanwhile, the reliance on attention mechanisms in modality fusion introduces significant computational complexity and storage overhead, particularly when dealing with high-resolution images. To address these challenges, we propose the Cross-modality Fusion Mamba with Weather-removal (CFMW) to augment stability and cost-effectiveness under adverse weather conditions. Leveraging the proposed Perturbation-Adaptive Diffusion Model (PADM) and Cross-modality Fusion Mamba (CFM) modules, CFMW is able to reconstruct visual features affected by adverse weather, enriching the representation of image details. With efficient architecture design, CFMW is 3 times faster than Transformer-style fusion (e.g., CFT). To bridge the gap in relevant datasets, we construct a new Severe Weather Visible-Infrared (SWVI) dataset, encompassing diverse adverse weather scenarios such as rain, haze, and snow. The dataset contains 64,281 paired visible-infrared images, providing a valuable resource for future research. Extensive experiments on public datasets (i.e., M3FD and LLVIP) and the newly constructed SWVI dataset conclusively demonstrate that CFMW achieves state-of-the-art detection performance. Both the dataset and source code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/lhy-zjut/CFMW">https://github.com/lhy-zjut/CFMW</a>. </p>
<blockquote>
<p>可见光红外图像对提供了互补信息，提高了现实世界场景中目标检测应用的可靠性和稳健性。然而，大多数现有方法在面对复杂天气条件下保持稳健性的挑战时存在局限性，这限制了其适用性。同时，模态融合中对注意力机制的依赖引入了显著的计算复杂性和存储开销，尤其是在处理高分辨率图像时。为了应对这些挑战，我们提出了跨模态融合Mamba带天气移除（CFMW）方案，以提高恶劣天气条件下的稳定性和成本效益。通过利用提出的扰动自适应扩散模型（PADM）和跨模态融合Mamba（CFM）模块，CFMW能够重建受恶劣天气影响的视觉特征，丰富了图像细节的表示。通过高效架构设计，CFMW的速度是Transformer风格融合（例如CFT）的3倍。为了填补相关数据集的空白，我们构建了一个新的恶劣天气可见光红外（SWVI）数据集，涵盖了雨、雾、雪等多种恶劣天气场景。该数据集包含64281对可见光红外图像，为未来的研究提供了宝贵的资源。在公开数据集（即M3FD和LLVIP）和新构建的SWVI数据集上的大量实验表明，CFMW实现了最先进的检测性能。数据集和源代码将在<a target="_blank" rel="noopener" href="https://github.com/lhy-zjut/CFMW">https://github.com/lhy-zjut/CFMW</a>上公开提供。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.16302v2">PDF</a> Accepted to IEEE Transactions on Circuits and Systems for Video   Technology (TCSVT). The dataset and source code will be made publicly   available at <a target="_blank" rel="noopener" href="https://github.com/lhy-zjut/CFMW">https://github.com/lhy-zjut/CFMW</a></p>
<p><strong>Summary</strong>：<br>可见光红外图像对提供了互补信息，提高了对象检测应用的可靠性和稳健性。然而，现有方法在面对复杂天气条件时，往往面临保持稳健性的挑战。为此，我们提出了跨模态融合Mamba与去天气化（CFMW）方案，旨在增强恶劣天气下的稳定性和成本效益。通过利用扰动自适应扩散模型（PADM）和跨模态融合Mamba（CFM）模块，CFMW能够重建受恶劣天气影响的视觉特征，丰富图像细节表示。此外，我们还构建了一个新的严重天气可见光红外（SWVI）数据集，包含各种恶劣天气场景，如降雨、雾霾和雪。实验结果证明，CFMW在公共数据集和新建的SWVI数据集上均实现了最先进的检测性能。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>可见光红外图像对提供互补信息，增强对象检测的可靠性和稳健性。</li>
<li>现有方法在复杂天气条件下面临稳健性挑战。</li>
<li>跨模态融合Mamba与去天气化（CFMW）方案旨在增强恶劣天气下的稳定性和成本效益。</li>
<li>CFMW利用扰动自适应扩散模型和跨模态融合模块，能重建受恶劣天气影响的视觉特征。</li>
<li>CFMW效率更高，是Transformer风格融合的3倍速度。</li>
<li>构建了一个新的严重天气可见光红外（SWVI）数据集，包含多样化的恶劣天气场景。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.16302">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-7b0c651c0e221b3cf53d298dbc4f2ef5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4542c392b13c3e361a58ab897e4fe191.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0bae9a4c45d4a2ceda20e8f547697cb4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e38fccbafe293f45beafb482e0f44b1.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ShareCMP-Polarization-Aware-RGB-P-Semantic-Segmentation"><a href="#ShareCMP-Polarization-Aware-RGB-P-Semantic-Segmentation" class="headerlink" title="ShareCMP: Polarization-Aware RGB-P Semantic Segmentation"></a>ShareCMP: Polarization-Aware RGB-P Semantic Segmentation</h2><p><strong>Authors:Zhuoyan Liu, Bo Wang, Lizhi Wang, Chenyu Mao, Ye Li</strong></p>
<p>Multimodal semantic segmentation is developing rapidly, but the modality of RGB-\textbf{P}olarization remains underexplored. To delve into this problem, we construct a UPLight RGB-P segmentation benchmark with 12 typical underwater semantic classes. In this work, we design the ShareCMP, an RGB-P semantic segmentation framework with a shared dual-branch architecture (ShareCMP Encoder), which reduces the parameters and memory space by about 33.8% compared to previous dual-branch models. It encompasses a Polarization Generate Attention (PGA) module designed to generate polarization modal images with richer polarization properties for the encoder. In addition, we introduce the Class Polarization-Aware Loss (CPALoss) with Class Polarization-Aware Auxiliary Head (CPAAHead) to improve the learning and understanding of the encoder for polarization modal information and to optimize the PGA module. With extensive experiments on a total of three RGB-P benchmarks, our ShareCMP achieves the best performance in mIoU with fewer parameters on the UPLight (92.45{\small (+0.32)}%), ZJU (92.7{\small (+0.1)}%), and MCubeS (50.99{\small (+1.51)}%) datasets. And our ShareCMP (w&#x2F;o PGA) achieves competitive or even higher performance on other RGB-X datasets compared to the corresponding state-of-the-art RGB-X methods. The code and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/LEFTeyex/ShareCMP">https://github.com/LEFTeyex/ShareCMP</a>. </p>
<blockquote>
<p>多模态语义分割正在迅速发展，但RGB-偏振模态仍未得到充分探索。为了深入研究这一问题，我们构建了UPLight RGB-P分割基准测试集，包含12个典型的水下语义类别。在这项工作中，我们设计了ShareCMP，这是一个RGB-P语义分割框架，采用共享双分支架构（ShareCMP Encoder），与之前的双分支模型相比，参数和内存空间减少了约33.8%。它包含一个偏振生成注意力（PGA）模块，该模块旨在生成具有更丰富偏振属性的偏振模态图像，以供编码器使用。此外，我们引入了类偏振感知损失（CPALoss）和类偏振感知辅助头（CPAAHead），以提高编码器对偏振模态信息的学习和理解，并优化PGA模块。我们在三个RGB-P基准测试集上进行了大量实验，ShareCMP在UPLight（提升0.32%，达到92.45%）、ZJU（提升0.1%，达到92.7%）和MCubeS（提升1.51%，达到50.99%）数据集上取得了最佳的性能。并且我们的ShareCMP（不含PGA）在其他RGB-X数据集上的性能与最新的RGB-X方法相比具有竞争力，甚至更高。相关代码和数据集可通过<a target="_blank" rel="noopener" href="https://github.com/LEFTeyex/ShareCMP%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/LEFTeyex/ShareCMP获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.03430v3">PDF</a> 17 pages, 8 figures, 12 tables, accepted by IEEE TCSVT</p>
<p><strong>Summary</strong></p>
<p>RGB-P模态的多模态语义分割发展快速，但仍被较少探索。为解决这个问题，本文构建了UPLight RGB-P分割基准测试集，包含12类典型水下语义类别。提出了ShareCMP框架，采用共享双分支架构，相较于之前的方法，参数和内存占用减少了约33.8%。设计Polarization Generate Attention（PGA）模块，生成具有更丰富极化属性的极化模态图像。引入Class Polarization-Aware Loss（CPALoss）和CPAAHead，提高编码器对极化模态信息的学习和理解，优化PGA模块。在三个RGB-P基准测试集上的实验表明，ShareCMP在参数更少的情况下实现了最佳性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RGB-P模态在多模态语义分割中的研究仍然不足，需要更多关注。</li>
<li>本文构建了UPLight RGB-P分割基准测试集，涵盖多种水下语义类别。</li>
<li>引入ShareCMP框架，采用共享双分支架构降低参数和内存占用。</li>
<li>PGA模块用于生成具有更丰富极化属性的极化模态图像。</li>
<li>CPALoss和CPAAHead的设计旨在提高编码器对极化模态信息的学习和性能优化。</li>
<li>在多个RGB-P基准测试集上，ShareCMP实现了最佳性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.03430">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7ed103d01b692062cb0de14d4cc6e613.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66c5a0abca4cf75667e87013dfaa8d7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-103f4b2b360db0990352d41487556ce6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d03dd5a0a6a2e9857ae73bce9ad885a6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-10/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-10/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">检测/分割/跟踪</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-10/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1269d4a30d4a85ab9d63fa4fbf1c40a3.jpg" class="responsive-img" alt="人脸相关">
                        
                        <span class="card-title">人脸相关</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            人脸相关 方向最新论文已更新，请持续关注 Update in 2025-07-10  CorrDetail Visual Detail Enhanced Self-Correction for Face Forgery   Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    人脸相关
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">人脸相关</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-10/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1db317c83616197bd0f8ae5d8ce95752.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer 方向最新论文已更新，请持续关注 Update in 2025-07-10  Automatic Synthesis of High-Quality Triplet Data for Composed Image   Retrieval
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">26024.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
