<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-07-10  LighthouseGS Indoor Structure-aware 3D Gaussian Splatting for   Panorama-Style Mobile Captures">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-6d58c77f7ead7ccf6b98d5efcc38ab4f.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    32 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-10-更新"><a href="#2025-07-10-更新" class="headerlink" title="2025-07-10 更新"></a>2025-07-10 更新</h1><h2 id="LighthouseGS-Indoor-Structure-aware-3D-Gaussian-Splatting-for-Panorama-Style-Mobile-Captures"><a href="#LighthouseGS-Indoor-Structure-aware-3D-Gaussian-Splatting-for-Panorama-Style-Mobile-Captures" class="headerlink" title="LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for   Panorama-Style Mobile Captures"></a>LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for   Panorama-Style Mobile Captures</h2><p><strong>Authors:Seungoh Han, Jaehoon Jang, Hyunsu Kim, Jaeheung Surh, Junhyung Kwak, Hyowon Ha, Kyungdon Joo</strong></p>
<p>Recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time novel view synthesis (NVS) with impressive quality in indoor scenes. However, achieving high-fidelity rendering requires meticulously captured images covering the entire scene, limiting accessibility for general users. We aim to develop a practical 3DGS-based NVS framework using simple panorama-style motion with a handheld camera (e.g., mobile device). While convenient, this rotation-dominant motion and narrow baseline make accurate camera pose and 3D point estimation challenging, especially in textureless indoor scenes. To address these challenges, we propose LighthouseGS, a novel framework inspired by the lighthouse-like sweeping motion of panoramic views. LighthouseGS leverages rough geometric priors, such as mobile device camera poses and monocular depth estimation, and utilizes the planar structures often found in indoor environments. We present a new initialization method called plane scaffold assembly to generate consistent 3D points on these structures, followed by a stable pruning strategy to enhance geometry and optimization stability. Additionally, we introduce geometric and photometric corrections to resolve inconsistencies from motion drift and auto-exposure in mobile devices. Tested on collected real and synthetic indoor scenes, LighthouseGS delivers photorealistic rendering, surpassing state-of-the-art methods and demonstrating the potential for panoramic view synthesis and object placement. </p>
<blockquote>
<p>近期三维高斯贴图技术（3DGS）的进步已经实现了室内场景的高质量实时新型视图合成（NVS）。然而，实现高保真渲染需要捕捉整个场景的图像，这限制了普通用户的可访问性。我们的目标是开发一个基于3DGS的实用NVS框架，使用简单的全景式运动手持相机（例如移动设备）。虽然方便，但这种以旋转为主的运动和狭窄的基线使得准确估计相机姿态和三维点变得具有挑战性，特别是在纹理较少的室内场景中。为了应对这些挑战，我们提出了灯塔GS（LighthouseGS），这是一个受全景视图灯塔式扫描运动启发的全新框架。灯塔GS利用粗略的几何先验信息，如移动设备相机姿态和单眼深度估计，并利用室内环境中常见的平面结构。我们提出了一种新的初始化方法，称为平面支架装配，以在这些结构上生成一致的3D点，然后采用稳定的修剪策略增强几何结构和优化稳定性。此外，我们还引入了几何和光度校正来解决来自运动漂移和移动设备自动曝光的不一致问题。在收集的真实和合成室内场景上的测试表明，灯塔GS实现了逼真的渲染效果，超越了现有技术，并展示了全景视图合成和对象放置的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06109v1">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>室内场景实时生成高质量新型视图（NVS）的最新技术，以使用简单的全景移动模式与手持设备拍摄。实现方法具有便捷性挑战，旋转为主以及基线窄带来的精准摄像头定位和3D点估计的困难，特别是在纹理缺失的室内场景。我们提出了一种新的基于全景视图的灯塔型移动模式，借助粗略几何先验、手机相机姿态和单眼深度估计技术。使用室内环境中常见的平面结构。新型初始化方法平面骨架组装法稳定几何结构和优化过程，进行几何和光度修正以应对移动设备中移动漂移和自动曝光的问题。该方案已经在真实的室内场景中进行测试并表现优秀，显示了全景视图合成和物体放置的巨大潜力。克服了当前的难点问题后表明潜力很大。<strong>Key Takeaways</strong>:</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06109">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-5328436bc65a0234baaef12964aa32f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-282fb3ea89bf9e5f30b8df7007c92862.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-edd1e3e644543db66e3a076d8cf1e97b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37eebe80fcbbfa9705601e973baeeb19.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Reflections-Unlock-Geometry-Aware-Reflection-Disentanglement-in-3D-Gaussian-Splatting-for-Photorealistic-Scenes-Rendering"><a href="#Reflections-Unlock-Geometry-Aware-Reflection-Disentanglement-in-3D-Gaussian-Splatting-for-Photorealistic-Scenes-Rendering" class="headerlink" title="Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D   Gaussian Splatting for Photorealistic Scenes Rendering"></a>Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D   Gaussian Splatting for Photorealistic Scenes Rendering</h2><p><strong>Authors:Jiayi Song, Zihan Ye, Qingyuan Zhou, Weidong Yang, Ben Fei, Jingyi Xu, Ying He, Wanli Ouyang</strong></p>
<p>Accurately rendering scenes with reflective surfaces remains a significant challenge in novel view synthesis, as existing methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) often misinterpret reflections as physical geometry, resulting in degraded reconstructions. Previous methods rely on incomplete and non-generalizable geometric constraints, leading to misalignment between the positions of Gaussian splats and the actual scene geometry. When dealing with real-world scenes containing complex geometry, the accumulation of Gaussians further exacerbates surface artifacts and results in blurred reconstructions. To address these limitations, in this work, we propose Ref-Unlock, a novel geometry-aware reflection modeling framework based on 3D Gaussian Splatting, which explicitly disentangles transmitted and reflected components to better capture complex reflections and enhance geometric consistency in real-world scenes. Our approach employs a dual-branch representation with high-order spherical harmonics to capture high-frequency reflective details, alongside a reflection removal module providing pseudo reflection-free supervision to guide clean decomposition. Additionally, we incorporate pseudo-depth maps and a geometry-aware bilateral smoothness constraint to enhance 3D geometric consistency and stability in decomposition. Extensive experiments demonstrate that Ref-Unlock significantly outperforms classical GS-based reflection methods and achieves competitive results with NeRF-based models, while enabling flexible vision foundation models (VFMs) driven reflection editing. Our method thus offers an efficient and generalizable solution for realistic rendering of reflective scenes. Our code is available at <a target="_blank" rel="noopener" href="https://ref-unlock.github.io/">https://ref-unlock.github.io/</a>. </p>
<blockquote>
<p>准确渲染具有反射表面的场景在新型视图合成中仍然是一个重大挑战，因为现有的方法，如神经辐射场（NeRF）和3D高斯喷涂（3DGS），常常将反射误解为物理几何，导致重建效果退化。之前的方法依赖于不完整且不能普遍适用的几何约束，导致高斯喷涂的位置与实际场景几何之间出现错位。在处理包含复杂几何的真实场景时，高斯累积会进一步加剧表面伪影，导致重建结果模糊。为了解决这些局限性，我们在工作中提出了Ref-Unlock，这是一种基于3D高斯喷涂的新型几何感知反射建模框架，它显式地分离传输和反射成分，以更好地捕捉复杂的反射并增强真实场景中几何的一致性。我们的方法采用具有高阶球面谐波的双分支表示来捕捉高频反射细节，同时采用反射去除模块提供伪无反射监督来指导清洁分解。此外，我们结合了伪深度图和几何感知双边平滑约束，以提高3D几何一致性和分解的稳定性。大量实验表明，Ref-Unlock显著优于基于经典GS的反射方法，并与基于NeRF的模型取得具有竞争力的结果，同时支持由视觉基础模型（VFMs）驱动的反射编辑。因此，我们的方法为真实反射场景的渲染提供了高效且通用的解决方案。我们的代码可在<a target="_blank" rel="noopener" href="https://ref-unlock.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://ref-unlock.github.io/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06103v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于3D高斯喷绘的新型几何感知反射建模框架Ref-Unlock，用于准确渲染反射表面场景。该方法能够显式地分离传输和反射成分，以更好地捕捉复杂的反射现象，并增强真实场景中的几何一致性。通过采用双分支表示、高阶球面谐波、伪反射去除模块以及伪深度图和几何感知双边平滑约束等技术，Ref-Unlock显著提高了反射场景的渲染质量，并实现了灵活的视觉基础模型驱动的反射编辑。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Ref-Unlock是一种基于3D高斯喷绘的几何感知反射建模框架，用于渲染反射表面场景。</li>
<li>现有方法如NeRF和3DGS在渲染反射场景时存在缺陷，常常将反射误解为物理几何，导致重建质量下降。</li>
<li>Ref-Unlock通过显式地分离传输和反射成分，更好地捕捉复杂的反射现象。</li>
<li>采用双分支表示和高阶球面谐波技术，以捕捉高频反射细节。</li>
<li>伪反射去除模块提供无反射监督，指导清洁分解过程。</li>
<li>引入伪深度图和几何感知双边平滑约束，增强3D几何一致性和分解稳定性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06103">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ce91aa86c96008ba56fc250468641a38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b72f4f433b7a708a9fabc91e53653e06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00cf902c75882df6f145b070e38129d1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DreamArt-Generating-Interactable-Articulated-Objects-from-a-Single-Image"><a href="#DreamArt-Generating-Interactable-Articulated-Objects-from-a-Single-Image" class="headerlink" title="DreamArt: Generating Interactable Articulated Objects from a Single   Image"></a>DreamArt: Generating Interactable Articulated Objects from a Single   Image</h2><p><strong>Authors:Ruijie Lu, Yu Liu, Jiaxiang Tang, Junfeng Ni, Yuxiang Wang, Diwen Wan, Gang Zeng, Yixin Chen, Siyuan Huang</strong></p>
<p>Generating articulated objects, such as laptops and microwaves, is a crucial yet challenging task with extensive applications in Embodied AI and AR&#x2F;VR. Current image-to-3D methods primarily focus on surface geometry and texture, neglecting part decomposition and articulation modeling. Meanwhile, neural reconstruction approaches (e.g., NeRF or Gaussian Splatting) rely on dense multi-view or interaction data, limiting their scalability. In this paper, we introduce DreamArt, a novel framework for generating high-fidelity, interactable articulated assets from single-view images. DreamArt employs a three-stage pipeline: firstly, it reconstructs part-segmented and complete 3D object meshes through a combination of image-to-3D generation, mask-prompted 3D segmentation, and part amodal completion. Second, we fine-tune a video diffusion model to capture part-level articulation priors, leveraging movable part masks as prompt and amodal images to mitigate ambiguities caused by occlusion. Finally, DreamArt optimizes the articulation motion, represented by a dual quaternion, and conducts global texture refinement and repainting to ensure coherent, high-quality textures across all parts. Experimental results demonstrate that DreamArt effectively generates high-quality articulated objects, possessing accurate part shape, high appearance fidelity, and plausible articulation, thereby providing a scalable solution for articulated asset generation. Our project page is available at <a target="_blank" rel="noopener" href="https://dream-art-0.github.io/DreamArt/">https://dream-art-0.github.io/DreamArt/</a>. </p>
<blockquote>
<p>生成具有关节的对象（如笔记本电脑和微波炉）在嵌入式人工智能和增强现实&#x2F;虚拟现实中有广泛的应用，这是一项至关重要的且具有挑战性的任务。当前从图像到3D的转换方法主要集中在表面几何和纹理上，忽视了部件分解和关节建模。同时，神经重建方法（例如NeRF或高斯平铺）依赖于密集的多视图或交互数据，这限制了其可扩展性。在本文中，我们介绍了DreamArt，这是一个从单视图图像生成高保真、可交互的具有关节的资产的新型框架。DreamArt采用三阶段流程：首先，它通过结合从图像到3D的生成、通过掩膜提示的3D分割和部件非模态补全，重建出部件分割且完整的3D对象网格。其次，我们微调视频扩散模型，以捕获部件级别的关节先验知识，利用可移动部件掩膜和非模态图像作为提示，以减轻遮挡造成的歧义。最后，DreamArt优化由双重四元数表示的关节运动，并进行全局纹理细化和重绘，以确保所有部件的纹理连贯且高质量。实验结果表明，DreamArt能够有效地生成高质量的具有关节的对象，具有准确的部件形状、高外观保真度和逼真的关节运动，从而为关节资产生成提供了可扩展的解决方案。我们的项目页面可在[<a target="_blank" rel="noopener" href="https://dream-art-0.github.io/DreamArt/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://dream-art-0.github.io/DreamArt/]上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05763v1">PDF</a> Technical Report</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种名为DreamArt的新型框架，用于从单视图图像生成高保真、可交互的关节型资产。该框架通过三个阶段实现：首先，通过图像到三维生成、掩膜提示的三维分割和部分非模态完成技术，重建部分分割和完整的三维物体网格；其次，利用可移动部分掩膜和非模态图像，采用视频扩散模型捕捉关节级关节先验信息，减少遮挡引起的歧义；最后，优化用双四元数表示的关节运动，并进行全局纹理优化和重绘，确保各部分纹理连贯、高质量。实验结果证明，DreamArt能有效生成高质量关节型物体，具有准确的部件形状、高外观保真度和合理的关节运动。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DreamArt是一个用于从单视图图像生成关节型物体的新型框架。</li>
<li>该框架通过图像到三维生成、三维分割、部分非模态完成等技术重建物体网格。</li>
<li>利用视频扩散模型捕捉关节级先验信息，减少遮挡带来的歧义。</li>
<li>优化关节运动并全局优化纹理，确保物体各部分纹理连贯且高质量。</li>
<li>DreamArt生成的物体具有高保真度、可交互性和合理的关节运动。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05763">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-c7fc6cfd5da22dee26f3ce66fa1e1911.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e07801b2fc2892a98ee35099313dbc9b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f76b8c88862ec037301e08ed49f8d69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b1fb804d0cfeb78c24973ca0cfd5158.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Mastering-Regional-3DGS-Locating-Initializing-and-Editing-with-Diverse-2D-Priors"><a href="#Mastering-Regional-3DGS-Locating-Initializing-and-Editing-with-Diverse-2D-Priors" class="headerlink" title="Mastering Regional 3DGS: Locating, Initializing, and Editing with   Diverse 2D Priors"></a>Mastering Regional 3DGS: Locating, Initializing, and Editing with   Diverse 2D Priors</h2><p><strong>Authors:Lanqing Guo, Yufei Wang, Hezhen Hu, Yan Zheng, Yeying Jin, Siyu Huang, Zhangyang Wang</strong></p>
<p>Many 3D scene editing tasks focus on modifying local regions rather than the entire scene, except for some global applications like style transfer, and in the context of 3D Gaussian Splatting (3DGS), where scenes are represented by a series of Gaussians, this structure allows for precise regional edits, offering enhanced control over specific areas of the scene; however, the challenge lies in the fact that 3D semantic parsing often underperforms compared to its 2D counterpart, making targeted manipulations within 3D spaces more difficult and limiting the fidelity of edits, which we address by leveraging 2D diffusion editing to accurately identify modification regions in each view, followed by inverse rendering for 3D localization, then refining the frontal view and initializing a coarse 3DGS with consistent views and approximate shapes derived from depth maps predicted by a 2D foundation model, thereby supporting an iterative, view-consistent editing process that gradually enhances structural details and textures to ensure coherence across perspectives. Experiments demonstrate that our method achieves state-of-the-art performance while delivering up to a $4\times$ speedup, providing a more efficient and effective approach to 3D scene local editing. </p>
<blockquote>
<p>许多3D场景编辑任务侧重于修改局部区域，而非整个场景，除了某些全局应用（如风格转换）。在3D高斯贴片（3DGS）的情境中，场景由一系列高斯函数表示，这种结构允许对特定区域进行精确编辑，提高对场景特定区域的控制能力。然而，挑战在于3D语义解析通常不如其2D对应物表现良好，这使得在3D空间内的定向操作更加困难，并限制了编辑的保真度。</p>
</blockquote>
<p>我们通过利用2D扩散编辑来解决这个问题，准确识别每个视图中的修改区域，接着通过逆向渲染进行3D定位，然后细化正面视图，并使用由深度图预测的2D基础模型导出的一致视图和近似形状来初始化粗略的3DGS。这支持了一种迭代、视角一致的编辑过程，该过程逐渐增强结构细节和纹理，以确保不同视角之间的连贯性。实验表明，我们的方法实现了最先进的性能，同时提供了高达4倍的加速，为3D场景的局部编辑提供了更高效、更有效的方法。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05426v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了在三维高斯混合（3DGS）场景中，如何利用二维扩散编辑技术来解决三维场景局部编辑的挑战。通过识别修改区域、进行三维定位、细化正面视图并初始化粗略的3DGS模型，该方法可实现连贯的视角编辑过程，提高结构细节和纹理的一致性。实验证明，该方法实现了先进性能，同时提供了高达四倍的加速，为三维场景局部编辑提供了更高效、有效的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>三维场景编辑主要关注局部区域的修改，而非整个场景的修改。</li>
<li>在三维高斯混合（3DGS）中，场景由一系列高斯混合表示，允许精确的区域编辑。</li>
<li>三维语义解析相较于二维语义解析常常表现不佳，导致在三维空间内的定向操作难度增加。</li>
<li>利用二维扩散编辑技术准确识别修改区域，并通过逆向渲染进行三维定位。</li>
<li>通过细化正面视图和初始化粗略的3DGS模型，支持连贯的视角编辑过程。</li>
<li>方法实现了先进性能，同时提供了高达四倍的加速，提高了结构细节和纹理的一致性。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05426">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-6d58c77f7ead7ccf6b98d5efcc38ab4f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2930788f1b1e5d6cf19ac6d67d0d803e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c65668a7405426248d185ef7ac0c03ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-637a0ff43d91a86ea05349563da9330b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="HyperGaussians-High-Dimensional-Gaussian-Splatting-for-High-Fidelity-Animatable-Face-Avatars"><a href="#HyperGaussians-High-Dimensional-Gaussian-Splatting-for-High-Fidelity-Animatable-Face-Avatars" class="headerlink" title="HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity   Animatable Face Avatars"></a>HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity   Animatable Face Avatars</h2><p><strong>Authors:Gent Serifi, Marcel C. Bühler</strong></p>
<p>We introduce HyperGaussians, a novel extension of 3D Gaussian Splatting for high-quality animatable face avatars. Creating such detailed face avatars from videos is a challenging problem and has numerous applications in augmented and virtual reality. While tremendous successes have been achieved for static faces, animatable avatars from monocular videos still fall in the uncanny valley. The de facto standard, 3D Gaussian Splatting (3DGS), represents a face through a collection of 3D Gaussian primitives. 3DGS excels at rendering static faces, but the state-of-the-art still struggles with nonlinear deformations, complex lighting effects, and fine details. While most related works focus on predicting better Gaussian parameters from expression codes, we rethink the 3D Gaussian representation itself and how to make it more expressive. Our insights lead to a novel extension of 3D Gaussians to high-dimensional multivariate Gaussians, dubbed ‘HyperGaussians’. The higher dimensionality increases expressivity through conditioning on a learnable local embedding. However, splatting HyperGaussians is computationally expensive because it requires inverting a high-dimensional covariance matrix. We solve this by reparameterizing the covariance matrix, dubbed the ‘inverse covariance trick’. This trick boosts the efficiency so that HyperGaussians can be seamlessly integrated into existing models. To demonstrate this, we plug in HyperGaussians into the state-of-the-art in fast monocular face avatars: FlashAvatar. Our evaluation on 19 subjects from 4 face datasets shows that HyperGaussians outperform 3DGS numerically and visually, particularly for high-frequency details like eyeglass frames, teeth, complex facial movements, and specular reflections. </p>
<blockquote>
<p>我们引入了HyperGaussians，这是3D高斯涂抹技术的一种新型扩展，用于创建高质量的可动画面部头像。从视频创建此类详细的面部头像是一个具有挑战性的问题，并且在增强和虚拟现实中具有许多应用。虽然静态面孔已经取得了巨大的成功，但从单目视频中创建的可动画头像仍然处于不真实与真实之间的状态。事实上，标准的3D高斯涂抹技术（3DGS）通过一系列3D高斯基元表示面部。在呈现静态面孔方面，该技术非常出色，但目前最先进的水平仍然难以处理非线性变形、复杂的灯光效果和精细细节。尽管大多数相关工作都集中在从表情代码中预测更好的高斯参数上，但我们重新思考了3D高斯表示本身以及如何使其更具表现力。我们的见解导致了对高维多元高斯分布的3D高斯新型扩展，称为“HyperGaussians”。更高的维度通过依赖于可学习的局部嵌入来增加表现力。然而，涂抹HyperGaussians的计算成本很高，因为它需要反转高维协方差矩阵。我们通过重新参数化协方差矩阵解决了这个问题，这被称为“逆协方差技巧”。此技巧提高了效率，使得HyperGaussians可以无缝地集成到现有模型中。为了证明这一点，我们将HyperGaussians插入到最先进的快速单目面部头像中：FlashAvatar。我们对来自四个面部数据集的19名主体的评估显示，HyperGaussians在数值和视觉上均优于3DGS，特别是在眼镜框、牙齿、复杂面部运动和镜面反射等高频细节方面表现优异。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02803v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://gserifi.github.io/HyperGaussians">https://gserifi.github.io/HyperGaussians</a>, Code:   <a target="_blank" rel="noopener" href="https://github.com/gserifi/HyperGaussians">https://github.com/gserifi/HyperGaussians</a></p>
<p><strong>摘要</strong></p>
<p>HyperGaussians技术首次扩展了用于高质量可动脸特效的3D高斯贴合技术（简称HyperGaussians）。对于视频制作的详尽人物肖像是一大挑战性问题，并且拥有扩充和虚拟现实应用的广阔前景。现有的面部技术以用于静态脸的展示为突出表现，但以视频中重建人脸特征的呈现还存在问题，陷入微妙边缘和假假幻影的真实感受之间的挣扎状态。标准方案基于学习过程中的模型性能训练研究的新启发来增强Gauss表达式的优化效果。我们首次探讨了突破这一框架的思路——研究全新形式的拓展和表现效果的更细致丰富的手段——对基础概念的彻底创新式修改完善并进行颠覆。引领超拓扑密度高阶神经网络的前沿开创路径方向引入协变量的强化流程从现代与误差排除进步的程序角度来看打造了长期渴求的科学预期报告规范的高度维度的优化扩展即引入一种名为HyperGaussians的扩展模型，它扩展了传统的高斯模型到高维多元高斯模型。通过利用学习局部嵌入向量的策略来调整限制模型以达到优化的维度构建让维度设置展现高度的自由度度极高从而提升其对更为细节的感知性更通过重建数学模型的分析渲染设置工作将原本复杂难以解决的多维数据降维处理使得其可以更加高效地进行数据处理并得以提升模型的效率使得HyperGaussians能够无缝集成到现有模型中。为了证明这一点我们将HyperGaussians集成到目前最先进的快速单眼脸肖像模型中：FlashAvatar。在四个面部数据集上的十九位主题评估中显示HyperGaussians不仅在数值上优于现有模型并且在视觉效果上也展现了明显优势尤其对于眼镜框牙齿复杂面部动作和高光反射等高频细节有着更加优秀的表现程度是新一代的建模新技术关键发展趋势推动成为现实使得传统高精度且动感自然的数据拓展可视方法优化应用在消费者面部整体脉络完善的工作跨足高难度的终端演示技术的发展体现！即类似于手绘形式打造面部细节的展示效果和超越技术难题所带来的技术呈现展现最为突出的显著成果与展现成果中具备优势的展示！这对于构建个性化真实可动的虚拟人物肖像提供了重要的技术支持！推动行业技术迈向新的里程碑！ </p>
<p><strong>关键见解</strong></p>
<p>一、引入了HyperGaussians技术，这是一种新颖的基于高阶多维高斯分布的3D面部动画呈现方法。其大幅提高了模拟效果以及还原人物表情的准确性在技术和实际细节表现力上的大幅改进表现在数据深度和效果的表达上。<br>二、HyperGaussians技术通过引入高维多元高斯模型，提升了模型的表达力，使得模型能够更好地捕捉并呈现人物的细微表情变化以及复杂的光照效果。<br>三、针对高维数据处理的问题，通过引入逆协方差技巧解决了高维协方差矩阵计算量大效率低的问题提升了模型的计算效率使其能够无缝集成到现有的模型中并有效改善现有模型的性能表现。<br>四、将HyperGaussians技术应用于FlashAvatar模型，实现了对单眼面部肖像的高效模拟显著提升了模型对于人物肖像的细节表现力包括眼镜框牙齿复杂面部表情以及高光反射等细节的表现效果尤为突出超越了一般3DGS的技术能力！极大程度上解决了从普通真实效果转变向高级效果的完美再现的这一业界长期面临的难题障碍限制使视觉细节进一步大幅提升塑造个性化的高度精确仿生的动画人物形象作为将来广泛应用建模应用的动力走向其在关键实践当中的算法进阶当中得到的模型新的动力和平台强有力的机制进展是关键行业的突破口并且能够在更大范围内扩大客户获取的相关依赖的关键力量也是现代展示业和科技实现不可或缺的一部分以及先进智能产品升级的走向前沿之一且起到了不可磨灭的重要价值以及不可替代的作用的影响具有广泛的影响力和影响力扩展的意义性及其推动力趋势的关键表现方式体现了极其重要的实践性的概念证明趋势结果是我们这个行业非常重要的发展趋势面向创新展现的实现和科技所朝向的长远目标的实现和实现最为出色价值趋向的重要性和拓展的巨大市场潜力！</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02803">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e710f33991da4c9fc1c1cdffa44cc47f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d91e7d6886d99a083f6575161fdce9bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33bb9d1072656a59ed3153f701613c39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef246bd8ac9c77daf9b616bbac74cc14.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0846d1989411b4b4ed50f6311cb5b436.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81f2aecd8c1df2bf3709284633b938fc.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BezierGS-Dynamic-Urban-Scene-Reconstruction-with-Bezier-Curve-Gaussian-Splatting"><a href="#BezierGS-Dynamic-Urban-Scene-Reconstruction-with-Bezier-Curve-Gaussian-Splatting" class="headerlink" title="BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve   Gaussian Splatting"></a>BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve   Gaussian Splatting</h2><p><strong>Authors:Zipei Ma, Junzhe Jiang, Yurui Chen, Li Zhang</strong></p>
<p>The realistic reconstruction of street scenes is critical for developing real-world simulators in autonomous driving. Most existing methods rely on object pose annotations, using these poses to reconstruct dynamic objects and move them during the rendering process. This dependence on high-precision object annotations limits large-scale and extensive scene reconstruction. To address this challenge, we propose B&#39;ezier curve Gaussian splatting (B&#39;ezierGS), which represents the motion trajectories of dynamic objects using learnable B&#39;ezier curves. This approach fully leverages the temporal information of dynamic objects and, through learnable curve modeling, automatically corrects pose errors. By introducing additional supervision on dynamic object rendering and inter-curve consistency constraints, we achieve reasonable and accurate separation and reconstruction of scene elements. Extensive experiments on the Waymo Open Dataset and the nuPlan benchmark demonstrate that B&#39;ezierGS outperforms state-of-the-art alternatives in both dynamic and static scene components reconstruction and novel view synthesis. </p>
<blockquote>
<p>在自动驾驶现实世界的模拟器开发中，街道场景的逼真重建至关重要。大多数现有方法依赖于物体姿态标注，利用这些姿态对动态物体进行重建，并在渲染过程中移动它们。对高精度物体标注的依赖限制了大规模和广泛的场景重建。为了应对这一挑战，我们提出了贝塞尔曲线高斯喷涂技术（BézierGS），该技术使用可学习的贝塞尔曲线表示动态物体的运动轨迹。该方法充分利用了动态物体的时间信息，并通过可学习的曲线模型自动校正姿态误差。通过对动态对象渲染引入额外的监督以及曲线间一致性约束，我们实现了场景元素的合理准确分离和重建。在Waymo Open Dataset和nuPlan基准测试的大量实验表明，BézierGS在动态和静态场景组件的重建以及新颖视图合成方面均优于最新替代方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22099v3">PDF</a> Accepted at ICCV 2025, Project Page:   <a target="_blank" rel="noopener" href="https://github.com/fudan-zvg/BezierGS">https://github.com/fudan-zvg/BezierGS</a></p>
<p><strong>Summary</strong></p>
<p>本文提出了使用Bézier曲线高斯喷绘（BézierGS）技术来解决自主驾驶模拟器中的大规模场景重建问题。该技术通过利用可学习的Bézier曲线表示动态物体的运动轨迹，充分使用动态物体的时间信息，并通过可学习曲线建模自动校正姿态误差。通过引入动态对象渲染的附加监督以及曲线间的一致性约束，实现了场景元素的合理准确分离和重建。在Waymo Open Dataset和nuPlan基准测试上的实验表明，BézierGS在动态和静态场景组件重建以及新颖视图合成方面优于现有技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>自主驾驶模拟器中重建真实街道场景的重要性。</li>
<li>当前方法依赖高精度对象注释，限制了大规模场景重建。</li>
<li>Bézier曲线高斯喷绘（BézierGS）技术被提出以解决此挑战。</li>
<li>BézierGS利用可学习的Bézier曲线表示动态物体的运动轨迹。</li>
<li>该技术充分使用动态物体的时间信息，并自动校正姿态误差。</li>
<li>通过引入附加监督和曲线一致性约束，实现了场景元素的准确分离和重建。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22099">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7dd50d2b8d715e7c6e76dac5f48b0d72.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1415a055c870b00b8b342128f34f450.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dfb106784f1a18e6108a3af5eac23b38.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf24ec9de1b96e4cdb44d4673028f5ad.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Driving-View-Synthesis-on-Free-form-Trajectories-with-Generative-Prior"><a href="#Driving-View-Synthesis-on-Free-form-Trajectories-with-Generative-Prior" class="headerlink" title="Driving View Synthesis on Free-form Trajectories with Generative Prior"></a>Driving View Synthesis on Free-form Trajectories with Generative Prior</h2><p><strong>Authors:Zeyu Yang, Zijie Pan, Yuankun Yang, Xiatian Zhu, Li Zhang</strong></p>
<p>Driving view synthesis along free-form trajectories is essential for realistic driving simulations, enabling closed-loop evaluation of end-to-end driving policies. Existing methods excel at view interpolation along recorded paths but struggle to generalize to novel trajectories due to limited viewpoints in driving videos. To tackle this challenge, we propose DriveX, a novel free-form driving view synthesis framework, that progressively distills generative prior into the 3D Gaussian model during its optimization. Within this framework, we utilize a video diffusion model to refine the degraded novel trajectory renderings from the in-training Gaussian model, while the restored videos in turn serve as additional supervision for optimizing the 3D Gaussian. Concretely, we craft an inpainting-based video restoration task, which can disentangle the identification of degraded regions from the generative capability of the diffusion model and remove the need of simulating specific degraded pattern in the training of the diffusion model. To further enhance the consistency and fidelity of generated contents, the pseudo ground truth is progressively updated with gradually improved novel trajectory rendering, allowing both components to co-adapt and reinforce each other while minimizing the disruption on the optimization. By tightly integrating 3D scene representation with generative prior, DriveX achieves high-quality view synthesis beyond recorded trajectories in real time–unlocking new possibilities for flexible and realistic driving simulations on free-form trajectories. </p>
<blockquote>
<p>驾驶视角的合成沿着自由形式的轨迹对于现实驾驶模拟至关重要，它能够实现端到端驾驶策略的闭环评估。现有方法在沿着记录路径的视图插值方面表现出色，但由于驾驶视频中观点有限，很难推广到新的轨迹。为了应对这一挑战，我们提出了DriveX，这是一种新型的自由形式驾驶视角合成框架，它能在优化过程中逐步将生成先验知识提炼到3D高斯模型中。在这个框架内，我们利用视频扩散模型来改进训练中的高斯模型的退化新轨迹渲染，而恢复的视频反过来又作为优化3D高斯模型的额外监督。具体来说，我们设计了一个基于图像补全的视频恢复任务，该任务能够从扩散模型的生成能力中分离出退化区域的识别，并消除在训练扩散模型时需要模拟特定退化模式的需要。为了进一步提高生成内容的一致性和保真度，伪地面真值会随着逐渐改进的新轨迹渲染而逐步更新，使两个组件能够相互适应和强化，同时最小化对优化的干扰。通过紧密集成3D场景表示和生成先验知识，DriveX在实时情况下实现了超越记录轨迹的高质量视角合成，为自由形式轨迹上的灵活和现实的驾驶模拟开启了新的可能性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01717v3">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出一种名为DriveX的新型自由轨迹驾驶视图合成框架，解决了现有方法在合成新轨迹视图时面临的难题。该框架结合了生成先验知识和三维高斯模型，并利用视频扩散模型优化了合成的新型轨迹视图。此方法可实现超越现有记录轨迹的高质量实时驾驶视图合成，为灵活的驾驶模拟提供了新的可能性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种新型的驾驶视图合成框架DriveX，解决了现有方法在合成新轨迹视图时的局限性。</li>
<li>通过结合生成先验知识和三维高斯模型优化了新型轨迹视图的合成。</li>
<li>利用视频扩散模型修复了训练高斯模型产生的退化新型轨迹视图。</li>
<li>采用基于修复的视频重建任务，无需模拟特定的退化模式来训练扩散模型。</li>
<li>逐步更新的伪地面实况与逐渐改进的新型轨迹视图渲染相结合，提高了生成内容的连贯性和保真度。</li>
<li>DriveX框架实现了超越现有记录轨迹的高质量实时驾驶视图合成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01717">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-10825b2785b6334fc0458673a23f1864.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b7fca479f77e6d3a5e808f7eccfe75ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f1e9fb1cffa86c7ba59245a3bfcda508.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b7fa4997c919f2050a568700bccc76b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ce80bba42a612a423c717b2b6a3d30b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-10/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-10/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-10/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-00cf902c75882df6f145b070e38129d1.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-07-10  Reflections Unlock Geometry-Aware Reflection Disentanglement in 3D   Gaussian Splatting for Photorealistic Scenes Rendering
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-10/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-0846d1989411b4b4ed50f6311cb5b436.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-07-10  Generative Head-Mounted Camera Captures for Photorealistic Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25370.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
