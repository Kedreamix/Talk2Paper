<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-02  SeMoBridge Semantic Modality Bridge for Efficient Few-Shot Adaptation   of CLIP">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-382e1516b4e0cc743d6007dc5b86247e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086886&auth_key=1760086886-0-0-414c8908216a2201c7bc6318ffdbd193&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    47 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-02-æ›´æ–°"><a href="#2025-10-02-æ›´æ–°" class="headerlink" title="2025-10-02 æ›´æ–°"></a>2025-10-02 æ›´æ–°</h1><h2 id="SeMoBridge-Semantic-Modality-Bridge-for-Efficient-Few-Shot-Adaptation-of-CLIP"><a href="#SeMoBridge-Semantic-Modality-Bridge-for-Efficient-Few-Shot-Adaptation-of-CLIP" class="headerlink" title="SeMoBridge: Semantic Modality Bridge for Efficient Few-Shot Adaptation   of CLIP"></a>SeMoBridge: Semantic Modality Bridge for Efficient Few-Shot Adaptation   of CLIP</h2><p><strong>Authors:Christoph Timmermann, Hyunse Lee, Woojin Lee</strong></p>
<p>While Contrastive Language-Image Pretraining (CLIP) excels at zero-shot tasks by aligning image and text embeddings, its performance in few-shot classification is hindered by a critical limitation: intra-modal misalignment. This issue, caused by a persistent modality gap and CLIPâ€™s exclusively inter-modal training objective, leaves the embedding spaces uncalibrated, making direct image-to-image comparisons unreliable. Existing methods attempt to address this by refining similarity logits or by computationally expensive per-sample optimization. To overcome these challenges, we introduce SeMoBridge, a lightweight yet powerful approach that directly addresses the misalignment. Our method maps images into the text modality, while keeping their semantic content intact through what we call a Semantic Modality Bridge. SeMoBridge is closed-form and can optionally be trained through multi-modal supervision, combining image and text-alignment losses to optimize the projection. Experiments show that the trained version, SeMoBridge-T, requires only a fraction of the training time while overall outperforming other methods, particularly in low-data scenarios (1, 2, and 4 shots). The code is available at \href{<a target="_blank" rel="noopener" href="https://github.com/christti98/semobridge%7D%7Bgithub.com/christti98/semobridge%7D">https://github.com/christti98/semobridge}{github.com/christti98/semobridge}</a>. </p>
<blockquote>
<p>å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰é€šè¿‡å¯¹é½å›¾åƒå’Œæ–‡æœ¬åµŒå…¥åœ¨é›¶æ ·æœ¬ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å°æ ·æœ¬åˆ†ç±»æ–¹é¢çš„æ€§èƒ½å´å—åˆ°å…³é”®é™åˆ¶ï¼šæ¨¡æ€å†…çš„ä¸å¯¹é½é—®é¢˜ã€‚è¿™ä¸€é—®é¢˜æ˜¯ç”±æŒç»­çš„æ¨¡æ€å·®è·å’ŒCLIPä»…è·¨æ¨¡æ€çš„è®­ç»ƒç›®æ ‡æ‰€å¯¼è‡´çš„ï¼Œä½¿å¾—åµŒå…¥ç©ºé—´æœªæ ¡å‡†ï¼Œç›´æ¥è¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„æ¯”è¾ƒå˜å¾—ä¸å¯é ã€‚ç°æœ‰æ–¹æ³•è¯•å›¾é€šè¿‡ä¼˜åŒ–ç›¸ä¼¼æ€§é€»è¾‘æˆ–è®¡ç®—æ˜‚è´µçš„æ¯ä¸ªæ ·æœ¬ä¼˜åŒ–æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SeMoBridgeï¼Œè¿™æ˜¯ä¸€ä¸ªè½»ä¾¿è€Œå¼ºå¤§çš„æ–¹æ³•ï¼Œç›´æ¥è§£å†³ä¸å¯¹é½é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å›¾åƒæ˜ å°„åˆ°æ–‡æœ¬æ¨¡æ€ï¼ŒåŒæ—¶é€šè¿‡æˆ‘ä»¬ç§°ä¹‹ä¸ºè¯­ä¹‰æ¨¡æ€æ¡¥çš„ä¸œè¥¿æ¥ä¿æŒå…¶è¯­ä¹‰å†…å®¹å®Œæ•´ã€‚SeMoBridgeæ˜¯å°é—­å½¢å¼çš„ï¼Œå¯ä»¥é€šè¿‡å¤šæ¨¡æ€ç›‘ç£è¿›è¡Œå¯é€‰è®­ç»ƒï¼Œç»“åˆå›¾åƒå’Œæ–‡æœ¬å¯¹é½æŸå¤±æ¥ä¼˜åŒ–æŠ•å½±ã€‚å®éªŒè¡¨æ˜ï¼Œç»è¿‡è®­ç»ƒçš„SeMoBridge-Tç‰ˆæœ¬ä»…éœ€è¦ä¸€å°éƒ¨åˆ†è®­ç»ƒæ—¶é—´ï¼ŒåŒæ—¶åœ¨æ€»ä½“ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½æ•°æ®åœºæ™¯ï¼ˆ1ã€2å’Œ4ä¸ªæ ·æœ¬ï¼‰ä¸‹è¡¨ç°çªå‡ºã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/christti98/semobridge">github.com&#x2F;christti98&#x2F;semobridge</a>è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26036v1">PDF</a> 19 pages, 12 figures, Under review as a conference paper at ICLR 2026</p>
<p><strong>Summary</strong></p>
<p>CLIPæ¨¡å‹åœ¨é›¶æ ·æœ¬ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸­å—åˆ°æ¨¡æ€é—´å¯¹é½é—®é¢˜çš„é™åˆ¶ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºSeMoBridgeæ–¹æ³•ï¼Œé€šè¿‡æ„å»ºè¯­ä¹‰æ¨¡æ€æ¡¥æ¢ï¼Œå°†å›¾åƒæ˜ å°„åˆ°æ–‡æœ¬æ¨¡æ€ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰å†…å®¹å®Œæ•´ã€‚è¯¥æ–¹æ³•å½¢å¼ç®€æ´ï¼Œå¯é€šè¿‡å¤šæ¨¡æ€ç›‘ç£è¿›è¡Œè®­ç»ƒï¼Œç»“åˆå›¾åƒå’Œæ–‡æœ¬å¯¹é½æŸå¤±ä¼˜åŒ–æŠ•å½±ã€‚å®éªŒè¡¨æ˜ï¼Œè®­ç»ƒç‰ˆSeMoBridge-Tåªéœ€å°‘é‡è®­ç»ƒæ—¶é—´ï¼Œå³å¯åœ¨å°‘æ•°æ®åœºæ™¯ä¸‹å®ç°ä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CLIPåœ¨é›¶æ ·æœ¬ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€ï¼Œä½†åœ¨å°‘æ ·æœ¬åˆ†ç±»ä¸­å—é™ï¼Œå­˜åœ¨æ¨¡æ€é—´å¯¹é½é—®é¢˜ã€‚</li>
<li>SeMoBridgeæ–¹æ³•æ—¨åœ¨è§£å†³æ­¤é—®é¢˜ï¼Œé€šè¿‡æ„å»ºè¯­ä¹‰æ¨¡æ€æ¡¥æ¢å®ç°å›¾åƒåˆ°æ–‡æœ¬æ¨¡æ€çš„æ˜ å°„ã€‚</li>
<li>SeMoBridgeæ–¹æ³•ä¿æŒè¯­ä¹‰å†…å®¹å®Œæ•´ï¼Œå½¢å¼ç®€æ´ä¸”å¯é€šè¿‡å¤šæ¨¡æ€ç›‘ç£è¿›è¡Œè®­ç»ƒã€‚</li>
<li>ç»“åˆå›¾åƒå’Œæ–‡æœ¬å¯¹é½æŸå¤±ä¼˜åŒ–æŠ•å½±ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>SeMoBridge-Tè®­ç»ƒæ—¶é—´çŸ­ï¼Œä¸”åœ¨å°‘æ•°æ®åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä»£ç å·²å…¬å¼€ï¼Œå¯è®¿é—®æŒ‡å®šGitHubé“¾æ¥è·å–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26036">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-26b4dc5a7fe8b09998d47249ab62e9b6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086893&auth_key=1760086893-0-0-9d384a705d9c8519a88e77e8bf5a8a0c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-928746d92002b396103844505e76b972~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086901&auth_key=1760086901-0-0-0e2ccb5e35102a0ef74367f5c3fa181e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9e4c08ad2d20fe7b680e0989cecfb4e5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086908&auth_key=1760086908-0-0-56d119f9623e0c62c44a187544083e46&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9ec99aa457a402d52debb4a3aadf5c57~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086914&auth_key=1760086914-0-0-52c6e51ab739fda6e2e127da1a19186e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="EchoingECG-An-Electrocardiogram-Cross-Modal-Model-for-Echocardiogram-Tasks"><a href="#EchoingECG-An-Electrocardiogram-Cross-Modal-Model-for-Echocardiogram-Tasks" class="headerlink" title="EchoingECG: An Electrocardiogram Cross-Modal Model for Echocardiogram   Tasks"></a>EchoingECG: An Electrocardiogram Cross-Modal Model for Echocardiogram   Tasks</h2><p><strong>Authors:Yuan Gao, Sangwook Kim, Chris McIntosh</strong></p>
<p>Electrocardiogram (ECG) is a widely used tool for assessing cardiac function due to its low cost and accessibility. Emergent research shows that ECGs can help make predictions on key outcomes traditionally derived from more complex modalities such as echocardiograms (ECHO), enabling the use of ECGs as a more accessible method to predict broader measurements of cardiac function. ECHO, in particular, are of great importance because they require considerable hospital resources while playing a key role in clinical cardiac assessment. To aid this use case, we introduce EchoingECG, a probabilistic student-teacher model that leverages uncertainty-aware ECG embeddings and ECHO supervision to improve ECG-based cardiac function prediction. Our approach integrates Probabilistic Cross-Modal Embeddings (PCME++), a probabilistic contrastive framework, with ECHO-CLIP, a vision-language pre-trained model trained on ECHO-text pairs, to distill ECHO knowledge into ECG representations. Through experiments and external validation, we showed that EchoingECG outperforms state-of-the-art foundation ECG models in zero-shot, few-shot, and fine-tune settings for ECHO predictions based on ECG. We also highlighted that variance estimation (enabled through our method) enhanced our understanding of model performance by identifying underlying regions of uncertainty within ECGs. The code is available: <a target="_blank" rel="noopener" href="https://github.com/mcintoshML/EchoingECG">https://github.com/mcintoshML/EchoingECG</a>. </p>
<blockquote>
<p>å¿ƒç”µå›¾ï¼ˆECGï¼‰æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºè¯„ä¼°å¿ƒè„åŠŸèƒ½çš„å·¥å…·ï¼Œå› å…¶æˆæœ¬ä½ä¸”æ˜“äºè·å–ã€‚æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œå¿ƒç”µå›¾å¯ä»¥å¸®åŠ©é¢„æµ‹ä¼ ç»Ÿä¸Šé€šè¿‡æ›´å¤æ‚çš„æ–¹å¼ï¼ˆå¦‚è¶…å£°å¿ƒåŠ¨å›¾ï¼ˆECHOï¼‰ï¼‰å¾—å‡ºçš„å…³é”®ç»“æœï¼Œä»è€Œä½¿å¿ƒç”µå›¾æˆä¸ºä¸€ç§æ›´æ˜“äºè·å–çš„æ–¹æ³•æ¥é¢„æµ‹æ›´å¹¿æ³›çš„å¿ƒè„åŠŸèƒ½æµ‹é‡ã€‚ç‰¹åˆ«æ˜¯è¶…å£°å¿ƒåŠ¨å›¾ï¼Œè™½ç„¶å®ƒä»¬éœ€è¦å ç”¨å¤§é‡çš„åŒ»é™¢èµ„æºï¼Œä½†åœ¨ä¸´åºŠå¿ƒè„è¯„ä¼°ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€åº”ç”¨åœºæ™¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†EchoingECGï¼Œè¿™æ˜¯ä¸€ç§æ¦‚ç‡æ€§å­¦ç”Ÿ-æ•™å¸ˆæ¨¡å‹ï¼Œå®ƒåˆ©ç”¨å…·æœ‰ä¸ç¡®å®šæ€§çš„å¿ƒç”µå›¾åµŒå…¥å’ŒECHOç›‘ç£æ¥æ”¹å–„åŸºäºå¿ƒç”µå›¾çš„å¿ƒè„åŠŸèƒ½é¢„æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†æ¦‚ç‡è·¨æ¨¡æ€åµŒå…¥ï¼ˆPCME++ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¦‚ç‡å¯¹æ¯”æ¡†æ¶ï¼Œä»¥åŠECHO-CLIPï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ECHO-æ–‡æœ¬å¯¹ä¸Šè®­ç»ƒçš„è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨äºå°†ECHOçŸ¥è¯†è’¸é¦åˆ°å¿ƒç”µå›¾è¡¨ç¤ºä¸­ã€‚é€šè¿‡å®éªŒå’Œå¤–éƒ¨éªŒè¯ï¼Œæˆ‘ä»¬è¯æ˜äº†EchoingECGåœ¨é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸­å‡ä¼˜äºæœ€æ–°åŸºç¡€å¿ƒç”µå›¾æ¨¡å‹ï¼Œç”¨äºåŸºäºå¿ƒç”µå›¾çš„ECHOé¢„æµ‹ã€‚æˆ‘ä»¬è¿˜å¼ºè°ƒï¼Œé€šè¿‡æˆ‘ä»¬çš„æ–¹æ³•å®ç°çš„æ–¹å·®ä¼°è®¡æé«˜äº†æˆ‘ä»¬å¯¹æ¨¡å‹æ€§èƒ½çš„ç†è§£ï¼Œé€šè¿‡è¯†åˆ«å¿ƒç”µå›¾ä¸­çš„æ½œåœ¨ä¸ç¡®å®šåŒºåŸŸæ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä»£ç å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/mcintoshML/EchoingECG%E3%80%82">https://github.com/mcintoshML/EchoingECGã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25791v1">PDF</a> MICCAI 2025</p>
<p><strong>Summary</strong><br>     å¿ƒç”µå›¾ï¼ˆECGï¼‰å¯é¢„æµ‹ä¼ ç»Ÿå¤æ‚æ¨¡å¼å¦‚è¶…å£°å¿ƒåŠ¨å›¾ï¼ˆECHOï¼‰çš„ç»“æœï¼Œæ˜¯è¯„ä¼°å¿ƒè„åŠŸèƒ½çš„é‡è¦å·¥å…·ã€‚æˆ‘ä»¬å¼•å…¥EchoingECGæ¨¡å‹ï¼Œé‡‡ç”¨æ¦‚ç‡å¼å­¦ç”Ÿæ•™å¸ˆæ¨¡å¼å¹¶ç»“åˆä¸ç¡®å®šæ€§æ„ŸçŸ¥å¿ƒç”µå›¾åµŒå…¥å’ŒECHOç›‘ç£ï¼Œä»¥æé«˜åŸºäºå¿ƒç”µå›¾çš„å¿ƒè„åŠŸèƒ½é¢„æµ‹èƒ½åŠ›ã€‚é€šè¿‡å¯¹æ¯”å®éªŒå’Œå¤–éƒ¨éªŒè¯ï¼ŒEchoingECGåœ¨é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸­å‡ä¼˜äºå½“å‰åŸºç¡€å¿ƒç”µå›¾æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡æ–¹å·®ä¼°è®¡ï¼Œæœ‰åŠ©äºè¯†åˆ«å¿ƒç”µå›¾ä¸­çš„ä¸ç¡®å®šæ€§åŒºåŸŸã€‚ç›¸å…³ä¿¡æ¯å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/mcintoshML/EchoingECG%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mcintoshML/EchoingECGè·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¿ƒç”µå›¾ï¼ˆECGï¼‰å¯é¢„æµ‹æ›´å¤æ‚æ¨¡å¼å¦‚è¶…å£°å¿ƒåŠ¨å›¾ï¼ˆECHOï¼‰çš„ç»“æœï¼Œç”¨äºè¯„ä¼°å¿ƒè„åŠŸèƒ½ã€‚</li>
<li>EchoingECGæ¨¡å‹é‡‡ç”¨æ¦‚ç‡å¼å­¦ç”Ÿæ•™å¸ˆæ¨¡å¼ï¼Œç»“åˆä¸ç¡®å®šæ€§æ„ŸçŸ¥å¿ƒç”µå›¾åµŒå…¥å’ŒECHOç›‘ç£ï¼Œæé«˜å¿ƒç”µå›¾é¢„æµ‹å‡†ç¡®æ€§ã€‚</li>
<li>EchoingECGæ¨¡å‹åœ¨é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸‹è¡¨ç°ä¼˜äºç°æœ‰åŸºç¡€å¿ƒç”µå›¾æ¨¡å‹ã€‚</li>
<li>EchoingECGé€šè¿‡æ–¹å·®ä¼°è®¡å¢å¼ºå¯¹æ¨¡å‹æ€§èƒ½çš„ç†è§£ï¼Œè¯†åˆ«å¿ƒç”µå›¾ä¸­çš„ä¸ç¡®å®šæ€§åŒºåŸŸã€‚</li>
<li>EchoingECGä»£ç å…¬å¼€å¯è·å–ï¼Œæœ‰åŠ©äºè¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨ã€‚</li>
<li>ECGä½œä¸ºè¯„ä¼°å¿ƒè„åŠŸèƒ½çš„å·¥å…·å…·æœ‰ä½æˆæœ¬å’Œæ˜“è·å–çš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25791">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-81af736eb9d05c6602b929151f14dd96~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086921&auth_key=1760086921-0-0-85277330550c2c940442fb486b2e7cfe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0de78e4ef721519557500ecb0dc43427~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086929&auth_key=1760086929-0-0-490a8888c96f040c1acfd94b1694f3ee&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-32690bb60d8d0a6018f14b5ac169f8e8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101633&auth_key=1760101633-0-0-9de89e716937cf1c7b045f7fd05f74d3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ProbMed-A-Probabilistic-Framework-for-Medical-Multimodal-Binding"><a href="#ProbMed-A-Probabilistic-Framework-for-Medical-Multimodal-Binding" class="headerlink" title="ProbMed: A Probabilistic Framework for Medical Multimodal Binding"></a>ProbMed: A Probabilistic Framework for Medical Multimodal Binding</h2><p><strong>Authors:Yuan Gao, Sangwook Kim, Jianzhong You, Chris McIntosh</strong></p>
<p>Medical decision-making requires integrating diverse medical information, from imaging to clinical narratives. These medical modalities are often acquired in a many-to-many manner. However, current medical vision-language pretraining models (Med-VLPMs) fail to directly account for this many-to-many mapping in their model training and embeddings. To address this, we present Probabilistic Modality-Enhanced Diagnosis (ProbMED), a multimodal Med-VLPM that employs probabilistic contrastive learning to model distributions over embeddings rather than deterministic estimates. ProbMED aligns four distinct modalities â€“ chest X-rays, electrocardiograms, echocardiograms, and clinical text â€“ into a unified probabilistic embedding space. We use InfoNCE loss with Hellinger distance to integrate inter-modality distributions. We introduce a probabilistic synthetic sampling loss that captures modality-specific mean and variance to improve intra-modality binding. Extensive experiments across 13 medical datasets demonstrate that our model outperforms current Med-VLPMs in cross-modality retrieval, zero-shot, and few-shot classification. We also demonstrate the robust integration of multiple modalities for prognostication, showing improved intra- and inter-medical modality binding. </p>
<blockquote>
<p>åŒ»ç–—å†³ç­–éœ€è¦æ•´åˆå„ç§åŒ»ç–—ä¿¡æ¯ï¼Œä»æˆåƒåˆ°ä¸´åºŠå™è¿°ã€‚è¿™äº›åŒ»ç–—æ¨¡å¼é€šå¸¸æ˜¯ä»¥å¤šå¯¹å¤šçš„æ–¹å¼è·å¾—ã€‚ç„¶è€Œï¼Œå½“å‰çš„åŒ»ç–—è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ï¼ˆMed-VLPMsï¼‰åœ¨æ¨¡å‹è®­ç»ƒå’ŒåµŒå…¥ä¸­æœªèƒ½ç›´æ¥è€ƒè™‘è¿™ç§å¤šå¯¹å¤šçš„æ˜ å°„ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ¦‚ç‡æ¨¡å¼å¢å¼ºè¯Šæ–­ï¼ˆProbMEDï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡å¼Med-VLPMï¼Œå®ƒé‡‡ç”¨æ¦‚ç‡å¯¹æ¯”å­¦ä¹ æ¥å¯¹åµŒå…¥åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œè€Œä¸æ˜¯ç¡®å®šæ€§ä¼°è®¡ã€‚ProbMEDå°†å››ç§ä¸åŒçš„æ¨¡å¼â€”â€”èƒ¸éƒ¨Xå…‰ç‰‡ã€å¿ƒç”µå›¾ã€è¶…å£°å¿ƒåŠ¨å›¾å’Œä¸´åºŠæ–‡æœ¬â€”â€”å¯¹é½åˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¦‚ç‡åµŒå…¥ç©ºé—´ã€‚æˆ‘ä»¬ä½¿ç”¨å¸¦æœ‰Hellingerè·ç¦»çš„InfoNCEæŸå¤±æ¥æ•´åˆè·¨æ¨¡å¼åˆ†å¸ƒã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ¦‚ç‡åˆæˆé‡‡æ ·æŸå¤±ï¼Œæ•æ‰ç‰¹å®šæ¨¡å¼çš„å‡å€¼å’Œæ–¹å·®ï¼Œä»¥æé«˜æ¨¡å¼å†…çš„ç»‘å®šã€‚åœ¨13ä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è·¨æ¨¡å¼æ£€ç´¢ã€é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»æ–¹é¢ä¼˜äºå½“å‰çš„Med-VLPMsã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†å¤šç§æ¨¡å¼çš„ç¨³å¥é›†æˆåœ¨é¢„åé¢„æµ‹æ–¹é¢çš„åº”ç”¨ï¼Œå¹¶æ˜¾ç¤ºäº†æ”¹è¿›çš„æ¨¡å¼å†…å’Œæ¨¡å¼é—´ç»‘å®šæ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25711v1">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬ä»‹ç»äº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€åŒ»ç–—å†³ç­–æ¨¡å‹â€”â€”ProbMEDã€‚ProbMEDåˆ©ç”¨æ¦‚ç‡å¯¹æ¯”å­¦ä¹ æŠ€æœ¯å»ºæ¨¡å¤šæ¨¡æ€åµŒå…¥åˆ†å¸ƒï¼Œè€Œéç¡®å®šæ€§ä¼°è®¡ã€‚å®ƒæ•´åˆäº†å››ç§ä¸åŒæ¨¡æ€ï¼ˆèƒ¸éƒ¨Xå…‰ã€å¿ƒç”µå›¾ã€è¶…å£°å¿ƒåŠ¨å›¾å’Œä¸´åºŠæ–‡æœ¬ï¼‰åˆ°ä¸€ä¸ªç»Ÿä¸€æ¦‚ç‡åµŒå…¥ç©ºé—´ï¼Œé€šè¿‡InfoNCEæŸå¤±å’ŒHellingerè·ç¦»æ•´åˆè·¨æ¨¡æ€åˆ†å¸ƒï¼Œå¹¶å¼•å…¥æ¦‚ç‡åˆæˆé‡‡æ ·æŸå¤±æ¥æ•æ‰æ¨¡æ€ç‰¹å®šå‡å€¼å’Œæ–¹å·®ï¼Œæå‡æ¨¡æ€å†…ç»‘å®šæ•ˆæœã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è·¨æ¨¡æ€æ£€ç´¢ã€é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»æ–¹é¢ä¼˜äºç°æœ‰åŒ»ç–—è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨é¢„åé¢„æµ‹ä¸­å±•ç¤ºäº†å¤šæ¨¡æ€ç¨³å¥é›†æˆçš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰åŒ»ç–—è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ï¼ˆMed-VLPMsï¼‰æ— æ³•ç›´æ¥å¤„ç†å¤šæ¨¡æ€æ•°æ®çš„è®¸å¤šå¯¹è®¸å¤šæ˜ å°„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ProbMEDæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ¦‚ç‡å¯¹æ¯”å­¦ä¹ æ¥å»ºæ¨¡åµŒå…¥åˆ†å¸ƒã€‚</li>
<li>ProbMEDå°†ä¸åŒæ¨¡æ€ï¼ˆå¦‚èƒ¸éƒ¨Xå…‰ã€å¿ƒç”µå›¾ã€è¶…å£°å¿ƒåŠ¨å›¾å’Œä¸´åºŠæ–‡æœ¬ï¼‰ç»Ÿä¸€åˆ°ä¸€ä¸ªæ¦‚ç‡åµŒå…¥ç©ºé—´ä¸­ã€‚</li>
<li>ä½¿ç”¨InfoNCEæŸå¤±å’ŒHellingerè·ç¦»æ•´åˆè·¨æ¨¡æ€åˆ†å¸ƒä¿¡æ¯ã€‚</li>
<li>å¼•å…¥æ¦‚ç‡åˆæˆé‡‡æ ·æŸå¤±ï¼Œä»¥æé«˜æ¨¡æ€å†…ç»‘å®šæ•ˆæœå¹¶æ•æ‰æ¨¡æ€ç‰¹å®šçš„å‡å€¼å’Œæ–¹å·®ã€‚</li>
<li>å®éªŒè¯æ˜ProbMEDåœ¨è·¨æ¨¡æ€æ£€ç´¢ã€é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»æ–¹é¢ä¼˜äºç°æœ‰Med-VLPMsã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25711">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-40ae4e2f914e4ffa72fcc04f45e7782f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760087001&auth_key=1760087001-0-0-4fcb224652ee3a5c10bd828ca02648cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0c3ab93781753544226e849f9d56b70a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760087008&auth_key=1760087008-0-0-e4ad456da79a5dce0fc64844ffb7b89d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-aeeb94a86bb8cb389380c7876f034b98~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101640&auth_key=1760101640-0-0-cf4d719e436f2535208514fcfcb79c94&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ed994b306e61e748714b5fdd9ab55466~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101647&auth_key=1760101647-0-0-2621d7c20723a148a35bd6b65ce71dad&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="OmniDFA-A-Unified-Framework-for-Open-Set-Synthesis-Image-Detection-and-Few-Shot-Attribution"><a href="#OmniDFA-A-Unified-Framework-for-Open-Set-Synthesis-Image-Detection-and-Few-Shot-Attribution" class="headerlink" title="OmniDFA: A Unified Framework for Open Set Synthesis Image Detection and   Few-Shot Attribution"></a>OmniDFA: A Unified Framework for Open Set Synthesis Image Detection and   Few-Shot Attribution</h2><p><strong>Authors:Shiyu Wu, Shuyan Li, Jing Li, Jing Liu, Yequan Wang</strong></p>
<p>AI-generated image (AIGI) detection and source model attribution remain central challenges in combating deepfake abuses, primarily due to the structural diversity of generative models. Current detection methods are prone to overfitting specific forgery traits, whereas source attribution offers a robust alternative through fine-grained feature discrimination. However, synthetic image attribution remains constrained by the scarcity of large-scale, well-categorized synthetic datasets, limiting its practicality and compatibility with detection systems. In this work, we propose a new paradigm for image attribution called open-set, few-shot source identification. This paradigm is designed to reliably identify unseen generators using only limited samples, making it highly suitable for real-world application. To this end, we introduce OmniDFA (Omni Detector and Few-shot Attributor), a novel framework for AIGI that not only assesses the authenticity of images, but also determines the synthesis origins in a few-shot manner. To facilitate this work, we construct OmniFake, a large class-aware synthetic image dataset that curates $1.17$ M images from $45$ distinct generative models, substantially enriching the foundational resources for research on both AIGI detection and attribution. Experiments demonstrate that OmniDFA exhibits excellent capability in open-set attribution and achieves state-of-the-art generalization performance on AIGI detection. Our dataset and code will be made available. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒï¼ˆAIGIï¼‰çš„æ£€æµ‹å’Œæºå¤´æ¨¡å‹å½’å±æ˜¯æ‰“å‡»æ·±åº¦ä¼ªé€ æ»¥ç”¨è¡Œä¸ºçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºç”Ÿæˆæ¨¡å‹çš„æœºæ„å¤šæ ·æ€§ã€‚å½“å‰çš„æ£€æµ‹æ–¹æ³•å®¹æ˜“è¿‡åº¦é€‚åº”ç‰¹å®šçš„ä¼ªé€ ç‰¹å¾ï¼Œè€Œæºå¤´å½’å±åˆ™é€šè¿‡ç²¾ç»†ç‰¹å¾è¾¨åˆ«æä¾›äº†ä¸€ä¸ªç¨³å¥çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œåˆæˆå›¾åƒå½’å±å—é™äºç¼ºä¹å¤§è§„æ¨¡ã€åˆ†ç±»è‰¯å¥½çš„åˆæˆæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨æ£€æµ‹ç³»ç»Ÿä¸­çš„å®ç”¨æ€§å’Œå…¼å®¹æ€§ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒå½’å±èŒƒå¼ï¼Œç§°ä¸ºå¼€æ”¾é›†å°æ ·æœ¬è¯†åˆ«ã€‚è¯¥èŒƒå¼æ—¨åœ¨ä»…ä½¿ç”¨æœ‰é™çš„æ ·æœ¬å¯é åœ°è¯†åˆ«çœ‹ä¸è§çš„ç”Ÿæˆå™¨ï¼Œä½¿å…¶éå¸¸é€‚åˆå®é™…åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†OmniDFAï¼ˆOmniæ£€æµ‹å™¨å’Œå°‘æ•°æ ·æœ¬å½’å±è€…ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹AIGIæ¡†æ¶ï¼Œä¸ä»…è¯„ä¼°å›¾åƒçš„çœŸå®æ€§ï¼Œè€Œä¸”ä»¥å°‘æ•°æ ·æœ¬çš„æ–¹å¼ç¡®å®šåˆæˆæ¥æºã€‚ä¸ºäº†æ¨åŠ¨è¿™é¡¹å·¥ä½œï¼Œæˆ‘ä»¬æ„å»ºäº†OmniFakeæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹ç±»åˆ«æ„è¯†åˆæˆå›¾åƒæ•°æ®é›†ï¼Œä»45ä¸ªä¸åŒçš„ç”Ÿæˆæ¨¡å‹ä¸­ç­›é€‰äº†117ä¸‡å¼ å›¾åƒï¼Œæå¤§åœ°ä¸°å¯Œäº†AIGIæ£€æµ‹å’Œå½’å±ç ”ç©¶çš„åŸºç¡€èµ„æºã€‚å®éªŒè¡¨æ˜ï¼ŒOmniDFAåœ¨å¼€æ”¾é›†å½’å±æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œå¹¶åœ¨AIGIæ£€æµ‹æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ³›åŒ–æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å°†å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25682v1">PDF</a> 19 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒï¼ˆAIGIï¼‰æ£€æµ‹å’Œæºæ¨¡å‹å½’å±çš„éš¾é¢˜ï¼ŒæŒ‡å‡ºå½“å‰æ£€æµ‹æ–¹æ³•çš„å±€é™æ€§ä»¥åŠæºå½’å±çš„é‡è¦æ€§ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒå½’å±èŒƒå¼â€”â€”å¼€æ”¾é›†å°æ ·æœ¬è¯†åˆ«ï¼Œå¹¶å¼•å…¥äº†OmniDFAæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸ä»…èƒ½è¯„ä¼°å›¾åƒçš„çœŸå®æ€§ï¼Œè¿˜èƒ½ä»¥å°‘é‡æ ·æœ¬ç¡®å®šåˆæˆæ¥æºã€‚ä¸ºæ­¤æ„å»ºäº†OmniFakeæ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ª45ç§ä¸åŒç”Ÿæˆæ¨¡å‹çš„117ä¸‡å¼ å›¾åƒï¼Œä¸°å¯Œäº†AIGIæ£€æµ‹å’Œå½’å±ç ”ç©¶çš„åŸºç¡€èµ„æºã€‚å®éªŒè¡¨æ˜ï¼ŒOmniDFAåœ¨å¼€æ”¾é›†å½’å±æ–¹é¢å…·æœ‰å‡ºè‰²çš„èƒ½åŠ›ï¼Œå¹¶åœ¨AIGIæ£€æµ‹æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ³›åŒ–æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰AIç”Ÿæˆå›¾åƒï¼ˆAIGIï¼‰æ£€æµ‹å’Œæºæ¨¡å‹å½’å±é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºç”Ÿæˆæ¨¡å‹çš„å¤šæ ·æ€§ã€‚</li>
<li>æºå½’å±é€šè¿‡ç²¾ç»†ç‰¹å¾è¾¨è¯†æä¾›äº†ä¸€ç§ç¨³å¥çš„æ›¿ä»£æ–¹æ³•ã€‚</li>
<li>åˆæˆå›¾åƒå½’å±å—é™äºç¼ºä¹å¤§è§„æ¨¡ã€åˆ†ç±»è‰¯å¥½çš„åˆæˆæ•°æ®é›†ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„å›¾åƒå½’å±èŒƒå¼â€”â€”å¼€æ”¾é›†å°æ ·æœ¬è¯†åˆ«ã€‚</li>
<li>æå‡ºäº†OmniDFAæ¡†æ¶ï¼Œèƒ½è¯„ä¼°å›¾åƒçœŸå®æ€§å¹¶ç¡®å®šåˆæˆæ¥æºã€‚</li>
<li>æ„å»ºäº†OmniFakeæ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ª45ç§ç”Ÿæˆæ¨¡å‹çš„117ä¸‡å¼ å›¾åƒï¼Œä¸°å¯Œäº†AIGIæ£€æµ‹å’Œå½’å±ç ”ç©¶èµ„æºã€‚</li>
<li>OmniDFAåœ¨å¼€æ”¾é›†å½’å±å’ŒAIGIæ£€æµ‹æ–¹é¢è¡¨ç°å‡ºä¼˜ç§€èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25682">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5a7d6a50cea08154d558bd2984ecd76a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101655&auth_key=1760101655-0-0-2ac84a8c8a55bf46db71ed954b9df41a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-823dc2cf2c8d28583daa41f9048436d5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101662&auth_key=1760101662-0-0-77615589494099fb4d5e9f1daab7d76e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1193c8aec096b3ea4765b318c54087c4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101668&auth_key=1760101668-0-0-bfb63c365d5d019d702cfde68c94565b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ef174b4b75af7a549f2c41d0c13c1fa5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101675&auth_key=1760101675-0-0-0b8baa1fce51dda2a00e55b6e5807d66&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3621e3c08c73c3a7302dd5b34ba37612~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101682&auth_key=1760101682-0-0-48a7629a001c3c83c1e52fb69da4136b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a434d8106dd73f4bb082d15cbc7f9caf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104103&auth_key=1760104103-0-0-3c910136a90056f9a1f76466346af417&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="K-Prism-A-Knowledge-Guided-and-Prompt-Integrated-Universal-Medical-Image-Segmentation-Model"><a href="#K-Prism-A-Knowledge-Guided-and-Prompt-Integrated-Universal-Medical-Image-Segmentation-Model" class="headerlink" title="K-Prism: A Knowledge-Guided and Prompt Integrated Universal Medical   Image Segmentation Model"></a>K-Prism: A Knowledge-Guided and Prompt Integrated Universal Medical   Image Segmentation Model</h2><p><strong>Authors:Bangwei Guo, Yunhe Gao, Meng Ye, Difei Gu, Yang Zhou, Leon Axel, Dimitris Metaxas</strong></p>
<p>Medical image segmentation is fundamental to clinical decision-making, yet existing models remain fragmented. They are usually trained on single knowledge sources and specific to individual tasks, modalities, or organs. This fragmentation contrasts sharply with clinical practice, where experts seamlessly integrate diverse knowledge: anatomical priors from training, exemplar-based reasoning from reference cases, and iterative refinement through real-time interaction. We present $\textbf{K-Prism}$, a unified segmentation framework that mirrors this clinical flexibility by systematically integrating three knowledge paradigms: (i) $\textit{semantic priors}$ learned from annotated datasets, (ii) $\textit{in-context knowledge}$ from few-shot reference examples, and (iii) $\textit{interactive feedback}$ from user inputs like clicks or scribbles. Our key insight is that these heterogeneous knowledge sources can be encoded into a dual-prompt representation: 1-D sparse prompts defining $\textit{what}$ to segment and 2-D dense prompts indicating $\textit{where}$ to attend, which are then dynamically routed through a Mixture-of-Experts (MoE) decoder. This design enables flexible switching between paradigms and joint training across diverse tasks without architectural modifications. Comprehensive experiments on 18 public datasets spanning diverse modalities (CT, MRI, X-ray, pathology, ultrasound, etc.) demonstrate that K-Prism achieves state-of-the-art performance across semantic, in-context, and interactive segmentation settings. Code will be released upon publication. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹ä¸´åºŠå†³ç­–è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ¨¡å‹ä»ç„¶å‘ˆç°ç¢ç‰‡åŒ–ã€‚å®ƒä»¬é€šå¸¸åŸºäºå•ä¸€çš„çŸ¥è¯†æºè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸“é—¨é’ˆå¯¹ç‰¹å®šçš„ä»»åŠ¡ã€æ¨¡æ€æˆ–å™¨å®˜ã€‚è¿™ç§ç¢ç‰‡åŒ–ä¸ä¸´åºŠå®è·µå½¢æˆäº†é²œæ˜çš„å¯¹æ¯”ï¼Œä¸“å®¶åœ¨å®è·µä¸­èƒ½æ— ç¼åœ°æ•´åˆå„ç§çŸ¥è¯†ï¼šæ¥è‡ªè®­ç»ƒçš„è§£å‰–å…ˆéªŒçŸ¥è¯†ã€åŸºäºå‚è€ƒæ¡ˆä¾‹çš„ç¤ºä¾‹æ¨ç†ï¼Œä»¥åŠé€šè¿‡å®æ—¶äº¤äº’çš„è¿­ä»£ä¼˜åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†$\textbf{K-Prism}$ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„åˆ†å‰²æ¡†æ¶ï¼Œå®ƒé€šè¿‡ç³»ç»Ÿåœ°æ•´åˆä¸‰ç§çŸ¥è¯†èŒƒå¼æ¥åæ˜ è¿™ç§ä¸´åºŠçµæ´»æ€§ï¼šï¼ˆiï¼‰ä»æ³¨é‡Šæ•°æ®é›†ä¸­å­¦ä¹ çš„$\textit{è¯­ä¹‰å…ˆéªŒ}$ï¼Œï¼ˆiiï¼‰æ¥è‡ªå°‘é‡å‚è€ƒç¤ºä¾‹çš„$\textit{ä¸Šä¸‹æ–‡çŸ¥è¯†}$ï¼Œä»¥åŠï¼ˆiiiï¼‰æ¥è‡ªç”¨æˆ·è¾“å…¥ï¼ˆå¦‚ç‚¹å‡»æˆ–æ¶‚é¸¦ï¼‰çš„$\textit{äº¤äº’å¼åé¦ˆ}$ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œè¿™äº›ä¸åŒçš„çŸ¥è¯†æºå¯ä»¥ç¼–ç æˆä¸€ç§åŒæç¤ºè¡¨ç¤ºï¼šå®šä¹‰$\textit{ä»€ä¹ˆ}$éœ€è¦åˆ†å‰²çš„1-Dç¨€ç–æç¤ºå’ŒæŒ‡ç¤º$\textit{åœ¨å“ªé‡Œ}$éœ€è¦æ³¨æ„çš„2-Då¯†é›†æç¤ºï¼Œç„¶åå®ƒä»¬é€šè¿‡æ··åˆä¸“å®¶ï¼ˆMoEï¼‰è§£ç å™¨è¿›è¡ŒåŠ¨æ€è·¯ç”±ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿå®ç°åœ¨èŒƒå¼ä¹‹é—´çš„çµæ´»åˆ‡æ¢ä»¥åŠåœ¨å„ç§ä»»åŠ¡ä¹‹é—´çš„è”åˆè®­ç»ƒï¼Œè€Œæ— éœ€è¿›è¡Œæ¶æ„ä¿®æ”¹ã€‚åœ¨æ¶µç›–å¤šç§æ¨¡æ€ï¼ˆCTã€MRIã€Xå…‰ã€ç—…ç†å­¦ã€è¶…å£°ç­‰ï¼‰çš„18ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒK-Prismåœ¨è¯­ä¹‰ã€ä¸Šä¸‹æ–‡å’Œäº¤äº’å¼åˆ†å‰²è®¾ç½®ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å°†åœ¨å‘è¡¨æ—¶å…¬å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25594v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹ä¸´åºŠå†³ç­–è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ¨¡å‹é€šå¸¸åŸºäºå•ä¸€çŸ¥è¯†æºè¿›è¡Œè®­ç»ƒå¹¶å±€é™äºç‰¹å®šçš„ä»»åŠ¡ã€æ¨¡æ€æˆ–å™¨å®˜åº”ç”¨ï¼Œæ˜¾å¾—éå¸¸é›¶æ•£ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§åä¸ºK-Prismçš„ç»Ÿä¸€åˆ†å‰²æ¡†æ¶ï¼Œé€šè¿‡ç³»ç»Ÿåœ°æ•´åˆä¸‰ç§çŸ¥è¯†èŒƒå¼æ¥æ¨¡æ‹Ÿä¸´åºŠä¸“å®¶çš„çµæ´»å®è·µï¼šä»æ ‡æ³¨æ•°æ®é›†ä¸­å­¦ä¹ çš„è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ã€ä»å°‘æ•°å‚è€ƒæ¡ˆä¾‹ä¸­å­¦ä¹ çš„ä¸Šä¸‹æ–‡çŸ¥è¯†å’Œæ¥è‡ªç”¨æˆ·è¾“å…¥ï¼ˆå¦‚ç‚¹å‡»æˆ–æ¶‚é¸¦ï¼‰çš„å®æ—¶äº¤äº’åé¦ˆã€‚æœ¬æ–‡çš„å…³é”®åœ¨äºå°†è¿™äº›å¼‚è´¨çŸ¥è¯†æºç¼–ç æˆåŒé‡æç¤ºè¡¨ç¤ºï¼Œå³å®šä¹‰è¦åˆ†å‰²çš„â€œä»€ä¹ˆâ€ï¼ˆè¯­ä¹‰æç¤ºï¼‰å’Œéœ€è¦æ³¨æ„çš„â€œä½ç½®â€ï¼ˆä½ç½®æç¤ºï¼‰ï¼Œç„¶åé€šè¿‡æ··åˆä¸“å®¶è§£ç å™¨åŠ¨æ€è·¯ç”±è¿™äº›æç¤ºã€‚è¿™ç§è®¾è®¡å¯å®ç°èŒƒå¼ä¹‹é—´çš„çµæ´»åˆ‡æ¢ï¼Œå¹¶åœ¨ä¸åŒä»»åŠ¡ä¹‹é—´è¿›è¡Œè”åˆè®­ç»ƒè€Œæ— éœ€è¿›è¡Œæ¶æ„ä¿®æ”¹ã€‚åœ¨è·¨è¶Šå¤šç§æ¨¡æ€çš„åå…«ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒK-Prismåœ¨è¯­ä¹‰ã€ä¸Šä¸‹æ–‡å’Œäº¤äº’å¼åˆ†å‰²è®¾ç½®ä¸­å‡è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚ä»£ç å°†åœ¨å‘è¡¨æ—¶å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹ä¸´åºŠå†³ç­–è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ¨¡å‹é›¶æ•£ï¼Œç¼ºä¹ç»Ÿä¸€æ€§å’Œçµæ´»æ€§ã€‚</li>
<li>K-Prismæ¡†æ¶æ—¨åœ¨æ¨¡æ‹Ÿä¸´åºŠä¸“å®¶çš„å®è·µï¼Œé€šè¿‡æ•´åˆå¤šç§çŸ¥è¯†èŒƒå¼æ¥å¢å¼ºæ¨¡å‹çš„çµæ´»æ€§ã€‚</li>
<li>K-Prismæ¡†æ¶æ•´åˆäº†è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ã€ä¸Šä¸‹æ–‡çŸ¥è¯†å’Œå®æ—¶äº¤äº’åé¦ˆã€‚</li>
<li>åŒé‡æç¤ºè¡¨ç¤ºæ–¹æ³•ç»“åˆäº†â€œä»€ä¹ˆâ€å’Œâ€œå“ªé‡Œâ€çš„ä¿¡æ¯ï¼Œå¢å¼ºäº†æ¨¡å‹çš„åˆ†å‰²èƒ½åŠ›ã€‚</li>
<li>æ··åˆä¸“å®¶è§£ç å™¨èƒ½å¤ŸåŠ¨æ€è·¯ç”±æç¤ºå¹¶å®ç°èŒƒå¼é—´çš„çµæ´»åˆ‡æ¢ã€‚</li>
<li>K-Prismæ¡†æ¶åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šå®ç°äº†æœ€æ–°çš„å›¾åƒåˆ†å‰²æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25594">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ad317c2450116111d22236de0bae9d3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101757&auth_key=1760101757-0-0-270b2e75bf6bef34be72729dbf68e01d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7007a675be3265e7d986c66bf62198de~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101764&auth_key=1760101764-0-0-218ac760b70429e1223d358995031542&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d8f05a18966bdf4b6a5610b3ef61cd6d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101771&auth_key=1760101771-0-0-343f4363639617ef53ea92b3e140c1bb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MetaChest-Generalized-few-shot-learning-of-patologies-from-chest-X-rays"><a href="#MetaChest-Generalized-few-shot-learning-of-patologies-from-chest-X-rays" class="headerlink" title="MetaChest: Generalized few-shot learning of patologies from chest X-rays"></a>MetaChest: Generalized few-shot learning of patologies from chest X-rays</h2><p><strong>Authors:Berenice Montalvo-Lezama, Gibran Fuentes-Pineda</strong></p>
<p>The limited availability of annotated data presents a major challenge for applying deep learning methods to medical image analysis. Few-shot learning methods aim to recognize new classes from only a small number of labeled examples. These methods are typically studied under the standard few-shot learning setting, where all classes in a task are new. However, medical applications such as pathology classification from chest X-rays often require learning new classes while simultaneously leveraging knowledge of previously known ones, a scenario more closely aligned with generalized few-shot classification. Despite its practical relevance, few-shot learning has been scarcely studied in this context. In this work, we present MetaChest, a large-scale dataset of 479,215 chest X-rays collected from four public databases. MetaChest includes a meta-set partition specifically designed for standard few-shot classification, as well as an algorithm for generating multi-label episodes. We conduct extensive experiments evaluating both a standard transfer learning approach and an extension of ProtoNet across a wide range of few-shot multi-label classification tasks. Our results demonstrate that increasing the number of classes per episode and the number of training examples per class improves classification performance. Notably, the transfer learning approach consistently outperforms the ProtoNet extension, despite not being tailored for few-shot learning. We also show that higher-resolution images improve accuracy at the cost of additional computation, while efficient model architectures achieve comparable performance to larger models with significantly reduced resource requirements. </p>
<blockquote>
<p>åœ¨åŒ»ç–—å›¾åƒåˆ†æä¸­ï¼Œæ ‡æ³¨æ•°æ®çš„æœ‰é™å¯ç”¨æ€§æ˜¯åº”ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„é‡å¤§æŒ‘æˆ˜ä¹‹ä¸€ã€‚å°æ ·æœ¬å­¦ä¹ æ–¹æ³•æ—¨åœ¨ä»å°‘é‡æ ‡è®°æ ·æœ¬ä¸­è¯†åˆ«å‡ºæ–°ç±»åˆ«ã€‚è¿™äº›æ–¹æ³•é€šå¸¸åœ¨æ ‡å‡†çš„å°æ ·æœ¬å­¦ä¹ ç¯å¢ƒä¸­è¿›è¡Œç ”ç©¶ï¼Œå³ä»»åŠ¡ä¸­çš„æ‰€æœ‰ç±»åˆ«éƒ½æ˜¯æ–°çš„ã€‚ç„¶è€Œï¼ŒåŒ»ç–—åº”ç”¨ï¼ˆå¦‚åŸºäºèƒ¸éƒ¨Xå°„ç‰‡çš„ç—…ç†åˆ†ç±»ï¼‰é€šå¸¸éœ€è¦åœ¨å­¦ä¹ æ–°ç±»åˆ«çš„åŒæ—¶åˆ©ç”¨å·²çŸ¥ç±»åˆ«çš„çŸ¥è¯†ï¼Œè¿™ä¸€åœºæ™¯æ›´ç¬¦åˆå¹¿ä¹‰å°æ ·æœ¬åˆ†ç±»ã€‚å°½ç®¡åœ¨å®é™…åº”ç”¨ä¸­å¾ˆé‡è¦ï¼Œä½†å°æ ·æœ¬å­¦ä¹ åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ç ”ç©¶å¾ˆå°‘ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MetaChestæ•°æ®é›†ï¼Œå®ƒåŒ…æ‹¬ä»å››ä¸ªå…¬å…±æ•°æ®åº“ä¸­æ”¶é›†çš„479,215å¼ èƒ¸éƒ¨Xå°„çº¿å›¾åƒã€‚MetaCheståŒ…æ‹¬ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„ç”¨äºæ ‡å‡†å°æ ·æœ¬åˆ†ç±»çš„å…ƒé›†åˆ†åŒºï¼Œä»¥åŠä¸€ç§ç”¨äºç”Ÿæˆå¤šæ ‡ç­¾æ’æ›²çš„ç®—æ³•ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œè¯„ä¼°äº†æ ‡å‡†è¿ç§»å­¦ä¹ æ–¹æ³•ä»¥åŠProtoNetæ‰©å±•åœ¨å¤šç§å°æ ·æœ¬å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¢åŠ æ¯ä¸ªæ’æ›²ä¸­çš„ç±»åˆ«æ•°é‡å’Œæ¯ä¸ªç±»åˆ«çš„è®­ç»ƒæ ·æœ¬æ•°é‡å¯ä»¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æœªç»ç‰¹åˆ«å®šåˆ¶äºå°æ ·æœ¬å­¦ä¹ æƒ…å¢ƒï¼Œè¿ç§»å­¦ä¹ æ–¹æ³•çš„è¡¨ç°æŒç»­ä¼˜äºProtoNetæ‰©å±•æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œé«˜åˆ†è¾¨ç‡å›¾åƒå¯ä»¥æé«˜å‡†ç¡®æ€§ä½†éœ€è¦é¢å¤–çš„è®¡ç®—æˆæœ¬ï¼Œè€Œé«˜æ•ˆçš„æ¨¡å‹æ¶æ„å¯ä»¥åœ¨æ˜¾è‘—å‡å°‘èµ„æºéœ€æ±‚çš„æƒ…å†µä¸‹å®ç°ä¸å¤§å‹æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25590v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    åŒ»å­¦å›¾åƒåˆ†æä¸­åº”ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºæ ‡æ³¨æ•°æ®çš„æœ‰é™å¯ç”¨æ€§ã€‚å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•æ—¨åœ¨ä»å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸­è¯†åˆ«æ–°ç±»åˆ«ã€‚è¿™äº›é€šå¸¸åœ¨æ ‡å‡†å°‘æ ·æœ¬å­¦ä¹ ç¯å¢ƒä¸‹è¿›è¡Œç ”ç©¶ï¼Œä»»åŠ¡ä¸­çš„æ‰€æœ‰ç±»åˆ«éƒ½æ˜¯æ–°çš„ã€‚ç„¶è€Œï¼ŒåŒ»å­¦åº”ç”¨ï¼ˆå¦‚åŸºäºèƒ¸éƒ¨Xå…‰ç‰‡çš„ç—…ç†åˆ†ç±»ï¼‰éœ€è¦å­¦ä¹ æ–°ç±»åˆ«çš„åŒæ—¶åˆ©ç”¨ä»¥å¾€å·²çŸ¥ç±»åˆ«çš„çŸ¥è¯†ï¼Œè¿™ä¸€åœºæ™¯æ›´æ¥è¿‘äºå¹¿ä¹‰çš„å°‘æ ·æœ¬åˆ†ç±»ã€‚å°½ç®¡å…·æœ‰å®é™…æ„ä¹‰ï¼Œä½†å°‘æ ·æœ¬å­¦ä¹ åœ¨è¿™ç§æƒ…å¢ƒä¸‹å´é²œæœ‰ç ”ç©¶ã€‚åœ¨æ­¤ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MetaChestæ•°æ®é›†ï¼ŒåŒ…å«ä»å››ä¸ªå…¬å¼€æ•°æ®åº“æ”¶é›†çš„479215å¼ èƒ¸éƒ¨Xå…‰ç‰‡ã€‚MetaCheståŒ…æ‹¬ä¸“é—¨ç”¨äºæ ‡å‡†å°‘æ ·æœ¬åˆ†ç±»çš„å…ƒé›†åˆ†åŒºä»¥åŠç”¨äºç”Ÿæˆå¤šæ ‡ç­¾ç‰‡æ®µçš„ç®—æ³•ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œè¯„ä¼°äº†æ ‡å‡†è¿ç§»å­¦ä¹ æ–¹æ³•ä»¥åŠProtoNetæ‰©å±•åœ¨å¤šç§å°‘æ ·æœ¬å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œå¢åŠ æ¯é›†ç±»åˆ«æ•°é‡å’Œæ¯ç±»çš„è®­ç»ƒæ ·æœ¬æ•°é‡å¯ä»¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿ç§»å­¦ä¹ æ–¹æ³•æŒç»­ä¼˜äºProtoNetæ‰©å±•ï¼Œå°½ç®¡å®ƒå¹¶éä¸“ä¸ºå°‘æ ·æœ¬å­¦ä¹ è®¾è®¡ã€‚åŒæ—¶ï¼Œé«˜åˆ†è¾¨ç‡å›¾åƒèƒ½æé«˜ç²¾åº¦ä½†ä¼šå¢åŠ è®¡ç®—æˆæœ¬ï¼Œè€Œé«˜æ•ˆæ¨¡å‹æ¶æ„å¯å®ç°ä¸å¤§å‹æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½èµ„æºéœ€æ±‚ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†æé¢ä¸´æ ‡æ³¨æ•°æ®æœ‰é™çš„é—®é¢˜ï¼Œè¿™ç»™æ·±åº¦å­¦ä¹ æ–¹æ³•çš„åº”ç”¨å¸¦æ¥äº†æŒ‘æˆ˜ã€‚</li>
<li>å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿä»å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸­è¯†åˆ«æ–°ç±»åˆ«ï¼Œä½†ä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ ‡å‡†ç¯å¢ƒä¸‹ï¼Œå¿½ç•¥äº†åŒ»å­¦åº”ç”¨ä¸­åŒæ—¶åˆ©ç”¨æ–°æ—§çŸ¥è¯†çš„éœ€æ±‚ã€‚</li>
<li>MetaChestæ•°æ®é›†çš„æ¨å‡ºä¸ºåŒ»å­¦å›¾åƒå°‘æ ·æœ¬å­¦ä¹ æä¾›äº†ç ”ç©¶èµ„æºï¼ŒåŒ…æ‹¬ä¸“é—¨ç”¨äºæ ‡å‡†å°‘æ ·æœ¬åˆ†ç±»çš„å…ƒé›†åˆ†åŒºå’Œå¤šæ ‡ç­¾ç‰‡æ®µç”Ÿæˆç®—æ³•ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œå¢åŠ æ¯é›†ç±»åˆ«æ•°é‡å’Œæ¯ç±»çš„è®­ç»ƒæ ·æœ¬æ•°é‡å¯ä»¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚</li>
<li>è¿ç§»å­¦ä¹ æ–¹æ³•åœ¨å°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºProtoNetæ‰©å±•ã€‚</li>
<li>é«˜åˆ†è¾¨ç‡å›¾åƒèƒ½æé«˜ç²¾åº¦ä½†ä¼šå¢åŠ è®¡ç®—æˆæœ¬ï¼Œéœ€è¦æƒè¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25590">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e323fd5fae830d4f38ff8ccd0e7eb11a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101778&auth_key=1760101778-0-0-8aaa1fd9eddb94662af51ebbb3ba8718&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-407664335c2656ae1374cf82a01a0533~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101787&auth_key=1760101787-0-0-e1617ceb8ebcbecbc2ad810cab15ffd7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Multi-Robot-Task-Planning-for-Multi-Object-Retrieval-Tasks-with-Distributed-On-Site-Knowledge-via-Large-Language-Models"><a href="#Multi-Robot-Task-Planning-for-Multi-Object-Retrieval-Tasks-with-Distributed-On-Site-Knowledge-via-Large-Language-Models" class="headerlink" title="Multi-Robot Task Planning for Multi-Object Retrieval Tasks with   Distributed On-Site Knowledge via Large Language Models"></a>Multi-Robot Task Planning for Multi-Object Retrieval Tasks with   Distributed On-Site Knowledge via Large Language Models</h2><p><strong>Authors:Kento Murata, Shoichi Hasegawa, Tomochika Ishikawa, Yoshinobu Hagiwara, Akira Taniguchi, Lotfi El Hafi, Tadahiro Taniguchi</strong></p>
<p>It is crucial to efficiently execute instructions such as â€œFind an apple and a bananaâ€ or â€œGet ready for a field trip,â€ which require searching for multiple objects or understanding context-dependent commands. This study addresses the challenging problem of determining which robot should be assigned to which part of a task when each robot possesses different situational on-site knowledge-specifically, spatial concepts learned from the area designated to it by the user. We propose a task planning framework that leverages large language models (LLMs) and spatial concepts to decompose natural language instructions into subtasks and allocate them to multiple robots. We designed a novel few-shot prompting strategy that enables LLMs to infer required objects from ambiguous commands and decompose them into appropriate subtasks. In our experiments, the proposed method achieved 47&#x2F;50 successful assignments, outperforming random (28&#x2F;50) and commonsense-based assignment (26&#x2F;50). Furthermore, we conducted qualitative evaluations using two actual mobile manipulators. The results demonstrated that our framework could handle instructions, including those involving ad hoc categories such as â€œGet ready for a field trip,â€ by successfully performing task decomposition, assignment, sequential planning, and execution. </p>
<blockquote>
<p>æ‰§è¡Œè¯¸å¦‚â€œæ‰¾ä¸€ä¸ªè‹¹æœå’Œä¸€ä¸ªé¦™è•‰â€æˆ–â€œä¸ºå®åœ°è€ƒå¯Ÿåšå¥½å‡†å¤‡â€ç­‰æŒ‡ä»¤è‡³å…³é‡è¦ï¼Œè¿™äº›æŒ‡ä»¤éœ€è¦æœç´¢å¤šä¸ªç‰©ä½“æˆ–ç†è§£ä¸Šä¸‹æ–‡ç›¸å…³çš„å‘½ä»¤ã€‚æœ¬ç ”ç©¶è§£å†³äº†è¿™æ ·ä¸€ä¸ªæŒ‘æˆ˜æ€§é—®é¢˜ï¼šå½“æ¯ä¸ªæœºå™¨äººæ‹¥æœ‰ä¸åŒçš„ç°åœºæƒ…å¢ƒçŸ¥è¯†â€”â€”ç‰¹åˆ«æ˜¯ç”¨æˆ·ä¸ºå…¶æŒ‡å®šçš„åŒºåŸŸä¸­æ‰€å­¦åˆ°çš„ç©ºé—´æ¦‚å¿µæ—¶ï¼Œåº”å†³å®šå°†å“ªä¸ªæœºå™¨äººåˆ†é…ç»™ä»»åŠ¡ä¸­çš„å“ªä¸ªéƒ¨åˆ†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œç©ºé—´æ¦‚å¿µçš„ä»»åŠ¡è§„åˆ’æ¡†æ¶ï¼Œå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤åˆ†è§£ä¸ºå­ä»»åŠ¡å¹¶åˆ†é…ç»™å¤šä¸ªæœºå™¨äººã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°å‹å°‘æç¤ºç­–ç•¥ï¼Œä½¿LLMèƒ½å¤Ÿä»æ¨¡ç³Šå‘½ä»¤ä¸­æ¨æ–­æ‰€éœ€ç‰©ä½“ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºé€‚å½“çš„å­ä»»åŠ¡ã€‚åœ¨å®éªŒä¸­ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†47&#x2F;50çš„æˆåŠŸåˆ†é…ä»»åŠ¡ï¼Œä¼˜äºéšæœºåˆ†é…ï¼ˆ28&#x2F;50ï¼‰å’ŒåŸºäºå¸¸è¯†çš„åˆ†é…ï¼ˆ26&#x2F;50ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ä¸¤ä¸ªå®é™…çš„ç§»åŠ¨æ“çºµå™¨è¿›è¡Œäº†å®šæ€§è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿå¤„ç†æŒ‡ä»¤ï¼ŒåŒ…æ‹¬æ¶‰åŠä¸´æ—¶æ€§ç±»åˆ«çš„æŒ‡ä»¤ï¼Œå¦‚â€œä¸ºå®åœ°è€ƒå¯Ÿåšå¥½å‡†å¤‡â€ï¼Œé€šè¿‡æˆåŠŸè¿›è¡Œä»»åŠ¡åˆ†è§£ã€åˆ†é…ã€åºåˆ—è§„åˆ’å’Œæ‰§è¡Œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12838v2">PDF</a> Submitted to AROB-ISBC 2026 (Journal Track option)</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç ”ç©¶äº†åœ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡æ—¶ï¼Œå¦‚ä½•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œç©ºé—´æ¦‚å¿µå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤åˆ†è§£ä¸ºå­ä»»åŠ¡å¹¶åˆ†é…ç»™å¤šä¸ªæœºå™¨äººã€‚æå‡ºä¸€ç§ä»»åŠ¡è§„åˆ’æ¡†æ¶ï¼Œé€šè¿‡æ–°é¢–çš„few-shotæç¤ºç­–ç•¥ï¼Œä½¿LLMsèƒ½ä»æ¨¡ç³ŠæŒ‡ä»¤ä¸­æ¨æ–­æ‰€éœ€ç‰©ä½“ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºé€‚å½“çš„å­ä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†é…ä»»åŠ¡æ—¶è¡¨ç°å‡ºè¾ƒé«˜çš„æˆåŠŸç‡ï¼Œå¹¶èƒ½å¤Ÿå¤„ç†åŒ…æ‹¬ä¸´æ—¶ç±»åˆ«åœ¨å†…çš„æŒ‡ä»¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡ç‚¹åœ¨äºæ‰§è¡Œå¤æ‚ä»»åŠ¡æ—¶ï¼Œä¸ºæœºå™¨äººåˆ†é…é€‚å½“çš„å­ä»»åŠ¡ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œç©ºé—´æ¦‚å¿µè¿›è¡Œä»»åŠ¡åˆ†è§£ã€‚</li>
<li>æå‡ºä¸€ç§æ–°é¢–çš„few-shotæç¤ºç­–ç•¥ï¼Œä½¿LLMsèƒ½ä»æ¨¡ç³ŠæŒ‡ä»¤ä¸­æ¨æ–­æ‰€éœ€ç‰©ä½“ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä»»åŠ¡åˆ†é…æ—¶çš„æˆåŠŸç‡ä¸º47&#x2F;50ï¼Œä¼˜äºéšæœºåˆ†é…ï¼ˆ28&#x2F;50ï¼‰å’ŒåŸºäºå¸¸è¯†çš„åˆ†é…ï¼ˆ26&#x2F;50ï¼‰ã€‚</li>
<li>æ¡†æ¶èƒ½å¤Ÿå¤„ç†åŒ…æ‹¬ä¸´æ—¶ç±»åˆ«åœ¨å†…çš„æŒ‡ä»¤ã€‚</li>
<li>é€šè¿‡å®šæ€§è¯„ä¼°ï¼Œä½¿ç”¨å®é™…ç§»åŠ¨æ“ä½œå™¨éªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12838">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-28c49341669edf7ba8a1d8d320bb2cc3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101794&auth_key=1760101794-0-0-9b45c71a530df2d9854bb37e0a4d1165&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-382e1516b4e0cc743d6007dc5b86247e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101802&auth_key=1760101802-0-0-1643fb22f8b04d8a23507189f22617ad&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-020e81f340b2fec8614f28d402738ce6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101809&auth_key=1760101809-0-0-b4f387a7d4ae02d69e36552c72554bfb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3fc1adb05128cc0b2467e9a25d96b25a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101816&auth_key=1760101816-0-0-cdbadf2e051080200969c72f8da1a98f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-85954db6fad5bd26e418d28c198c1916~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101823&auth_key=1760101823-0-0-b2789f5f44a0643091ed93b6a682e422&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7820b0109a30024f3d019f73bb8bc4ce~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104111&auth_key=1760104111-0-0-8010176d2b9779847d824608d6d48b07&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HealthSLM-Bench-Benchmarking-Small-Language-Models-for-Mobile-and-Wearable-Healthcare-Monitoring"><a href="#HealthSLM-Bench-Benchmarking-Small-Language-Models-for-Mobile-and-Wearable-Healthcare-Monitoring" class="headerlink" title="HealthSLM-Bench: Benchmarking Small Language Models for Mobile and   Wearable Healthcare Monitoring"></a>HealthSLM-Bench: Benchmarking Small Language Models for Mobile and   Wearable Healthcare Monitoring</h2><p><strong>Authors:Xin Wang, Ting Dang, Xinyu Zhang, Vassilis Kostakos, Michael J. Witbrock, Hong Jia</strong></p>
<p>Mobile and wearable healthcare monitoring play a vital role in facilitating timely interventions, managing chronic health conditions, and ultimately improving individualsâ€™ quality of life. Previous studies on large language models (LLMs) have highlighted their impressive generalization abilities and effectiveness in healthcare prediction tasks. However, most LLM-based healthcare solutions are cloud-based, which raises significant privacy concerns and results in increased memory usage and latency. To address these challenges, there is growing interest in compact models, Small Language Models (SLMs), which are lightweight and designed to run locally and efficiently on mobile and wearable devices. Nevertheless, how well these models perform in healthcare prediction remains largely unexplored. We systematically evaluated SLMs on health prediction tasks using zero-shot, few-shot, and instruction fine-tuning approaches, and deployed the best performing fine-tuned SLMs on mobile devices to evaluate their real-world efficiency and predictive performance in practical healthcare scenarios. Our results show that SLMs can achieve performance comparable to LLMs while offering substantial gains in efficiency and privacy. However, challenges remain, particularly in handling class imbalance and few-shot scenarios. These findings highlight SLMs, though imperfect in their current form, as a promising solution for next-generation, privacy-preserving healthcare monitoring. </p>
<blockquote>
<p>ç§»åŠ¨å’Œå¯ç©¿æˆ´å¼å¥åº·ç›‘æµ‹åœ¨ä¿ƒè¿›åŠæ—¶å¹²é¢„ã€ç®¡ç†æ…¢æ€§å¥åº·çŠ¶å†µä»¥åŠæœ€ç»ˆæé«˜ä¸ªäººç”Ÿæ´»è´¨é‡æ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ä»¥å¾€å…³äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç ”ç©¶å·²ç»çªå‡ºäº†å…¶åœ¨åŒ»ç–—ä¿å¥é¢„æµ‹ä»»åŠ¡ä¸­çš„æƒŠäººæ³›åŒ–èƒ½åŠ›å’Œæ•ˆæœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°åŸºäºLLMçš„åŒ»ç–—ä¿å¥è§£å†³æ–¹æ¡ˆéƒ½æ˜¯åŸºäºäº‘çš„ï¼Œè¿™å¼•å‘äº†é‡å¤§çš„éšç§æ‹…å¿§ï¼Œå¹¶å¯¼è‡´å†…å­˜ä½¿ç”¨å¢åŠ å’Œå»¶è¿Ÿã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œäººä»¬å¯¹ç´§å‡‘æ¨¡å‹â€”â€”å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„å…´è¶£æ—¥ç›Šæµ“åšï¼Œè¿™äº›æ¨¡å‹è½»ä¾¿ä¸”è®¾è®¡ç”¨äºåœ¨ç§»åŠ¨å’Œå¯ç©¿æˆ´è®¾å¤‡ä¸Šæœ¬åœ°é«˜æ•ˆè¿è¡Œã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨åŒ»ç–—ä¿å¥é¢„æµ‹æ–¹é¢çš„è¡¨ç°å¦‚ä½•ä»é²œä¸ºäººçŸ¥ã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†SLMåœ¨å¥åº·é¢„æµ‹ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’ŒæŒ‡ä»¤å¾®è°ƒæ–¹æ³•ï¼Œå¹¶å°†è¡¨ç°æœ€ä½³çš„å¾®è°ƒSLMéƒ¨ç½²åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šï¼Œä»¥è¯„ä¼°å…¶åœ¨ç°å®ä¸–ç•Œçš„æ•ˆç‡å’Œé¢„æµ‹æ€§èƒ½åœ¨å®é™…åŒ»ç–—ä¿å¥åœºæ™¯ä¸­çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼ŒSLMçš„æ€§èƒ½å¯ä¸LLMç›¸åª²ç¾ï¼ŒåŒæ—¶åœ¨æ•ˆç‡å’Œéšç§æ–¹é¢æä¾›äº†å®è´¨æ€§çš„æ”¹è¿›ã€‚ç„¶è€Œï¼Œä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œå°‘æ ·æœ¬åœºæ™¯æ–¹é¢ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå°½ç®¡SLMåœ¨å½“å‰å½¢å¼ä¸‹å¹¶ä¸å®Œç¾ï¼Œä½†å®ƒä»¬ä½œä¸ºä¸‹ä¸€ä»£éšç§ä¿æŠ¤å¥åº·ç›‘æµ‹çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆä»å…·æœ‰å¹¿é˜”çš„å‘å±•å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07260v4">PDF</a> 9 pages, 6 tables, 6 figures. Accepted at NeurIPS 2025 Workshop on   GenAI4Health</p>
<p><strong>Summary</strong></p>
<p>å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨ç§»åŠ¨å’Œå¯ç©¿æˆ´è®¾å¤‡ä¸Šçš„å¥åº·ç›‘æµ‹ä¸­å±•ç°å‡ºæ½œåŠ›ã€‚ç ”ç©¶è¯„ä¼°äº†SLMsåœ¨å¥åº·é¢„æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¹¶å°†å…¶ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç›¸æ¯”è¾ƒã€‚ç»“æœæ˜¾ç¤ºï¼ŒSLMsåœ¨æ•ˆç‡å’Œéšç§æ–¹é¢å®ç°äº†æ˜¾è‘—çš„æå‡ï¼ŒåŒæ—¶å¯å®Œæˆé›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå­¦ä¹ æŒ‡ä»¤å¾®è°ƒçš„ä»»åŠ¡ã€‚å°½ç®¡å­˜åœ¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œå°‘æ ·æœ¬åœºæ™¯çš„æŒ‘æˆ˜ï¼Œä½†SLMsä»è¢«è§†ä¸ºä¸‹ä¸€ä»£éšç§ä¿æŠ¤å¥åº·ç›‘æµ‹çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç§»åŠ¨å’Œå¯ç©¿æˆ´è®¾å¤‡åœ¨åŒ»ç–—ä¿å¥ç›‘æµ‹ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œæœ‰åŠ©äºåŠæ—¶å¹²é¢„ã€ç®¡ç†æ…¢æ€§å¥åº·é—®é¢˜å’Œæé«˜ç”Ÿæ´»è´¨é‡ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»ç–—ä¿å¥é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œæ•ˆæœã€‚</li>
<li>LLMsä¸»è¦ä½œä¸ºäº‘è§£å†³æ–¹æ¡ˆå­˜åœ¨éšç§å…³æ³¨ã€å†…å­˜ä½¿ç”¨å’Œå»¶è¿Ÿé—®é¢˜ã€‚</li>
<li>å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰æ˜¯ä¸€ç§è½»é‡çº§çš„è§£å†³æ–¹æ¡ˆï¼Œå¯æœ¬åœ°è¿è¡Œï¼Œåœ¨ç§»åŠ¨å’Œå¯ç©¿æˆ´è®¾å¤‡ä¸Šé«˜æ•ˆè¿è¡Œã€‚</li>
<li>SLMsåœ¨å¥åº·é¢„æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸LLMsç›¸å½“ï¼ŒåŒæ—¶å¸¦æ¥æ•ˆç‡å’Œéšç§æ–¹é¢çš„æ˜¾è‘—æå‡ã€‚</li>
<li>SLMsåœ¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œå°‘æ ·æœ¬åœºæ™¯æ—¶ä»å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07260">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-57a8a2aa96f343a93ea4d20ea20eac00~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104118&auth_key=1760104118-0-0-5a7d937cd58c3e055d42458815b95120&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-507a8b677549a961e88b8e19155d265e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104126&auth_key=1760104126-0-0-48e0efd5278dec10be8ff3ce1abe3012&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b4ad3614c9d6f13457a6c02ce29d7d01~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104132&auth_key=1760104132-0-0-e6f3828118b8d20d21f23800c92745d8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4f563b6f54bc2df1d0b0e7d003676e52~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104139&auth_key=1760104139-0-0-34a21a2d9953f190a594fca17cc43352&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Simple-yet-Effective-Semi-supervised-Knowledge-Distillation-from-Vision-Language-Models-via-Dual-Head-Optimization"><a href="#Simple-yet-Effective-Semi-supervised-Knowledge-Distillation-from-Vision-Language-Models-via-Dual-Head-Optimization" class="headerlink" title="Simple yet Effective Semi-supervised Knowledge Distillation from   Vision-Language Models via Dual-Head Optimization"></a>Simple yet Effective Semi-supervised Knowledge Distillation from   Vision-Language Models via Dual-Head Optimization</h2><p><strong>Authors:Seongjae Kang, Dong Bok Lee, Hyungjoon Jang, Sung Ju Hwang</strong></p>
<p>Semi-supervised learning (SSL) has emerged as a practical solution for addressing data scarcity challenges by leveraging unlabeled data. Recently, vision-language models (VLMs), pre-trained on massive image-text pairs, have demonstrated remarkable zero-&#x2F;few-shot performance that often surpasses SSL approaches due to their exceptional generalization capabilities. This gap motivates us to question: how can we effectively harness the powerful generalization capabilities of VLMs into task-specific models? Knowledge distillation (KD) offers a natural framework for transferring VLM capabilities, but we identify that it suffers from gradient conflicts between supervised and distillation losses. To address this challenge, we propose Dual-Head Optimization (DHO), which introduces dual prediction heads for each distinct signal. We observe that DHO resolves gradient conflicts, enabling improved feature learning compared to single-head KD baselines, with practical benefits of minimal computational overhead and test-time hyperparameter tuning without retraining. Extensive experiments across 15 datasets show that DHO consistently outperforms KD baselines, often outperforming teacher models with smaller student models. DHO also achieves new state-of-the-art performance on both in-distribution ImageNet semi-supervised learning and out-of-distribution generalization across ImageNet variants. We publicly release our code and model checkpoints to facilitate future research at <a target="_blank" rel="noopener" href="https://github.com/erjui/DHO">https://github.com/erjui/DHO</a>. </p>
<blockquote>
<p>åŠç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰å·²æˆä¸ºä¸€ç§åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®è§£å†³æ•°æ®ç¨€ç¼ºæŒ‘æˆ˜çš„å®é™…è§£å†³æ–¹æ¡ˆã€‚æœ€è¿‘ï¼Œåœ¨å¤§é‡å›¾åƒæ–‡æœ¬å¯¹ä¸Šé¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¡¨ç°å‡ºäº†ä»¤äººç©ç›®çš„é›¶æ ·æœ¬&#x2F;å°‘æ ·æœ¬æ€§èƒ½ï¼Œç”±äºå…¶å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€šå¸¸è¶…è¶Šäº†SSLæ–¹æ³•ã€‚è¿™ç§å·®è·ä¿ƒä½¿æˆ‘ä»¬æå‡ºä¸€ä¸ªé—®é¢˜ï¼šå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨VLMçš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›åˆ°ç‰¹å®šä»»åŠ¡æ¨¡å‹ä¸­ï¼ŸçŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰æä¾›äº†ä¸€ä¸ªè½¬ç§»VLMèƒ½åŠ›çš„å¤©ç„¶æ¡†æ¶ï¼Œä½†æˆ‘ä»¬å‘ç°å®ƒåœ¨ç›‘ç£æŸå¤±å’Œè’¸é¦æŸå¤±ä¹‹é—´å­˜åœ¨æ¢¯åº¦å†²çªã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŒå¤´ä¼˜åŒ–ï¼ˆDHOï¼‰ï¼Œå®ƒå¼•å…¥äº†é’ˆå¯¹æ¯ä¸ªä¸åŒä¿¡å·çš„åŒé‡é¢„æµ‹å¤´ã€‚æˆ‘ä»¬å‘ç°DHOè§£å†³äº†æ¢¯åº¦å†²çªï¼Œä¸å•å¤´KDåŸºçº¿ç›¸æ¯”ï¼Œå®ç°äº†æ”¹è¿›çš„ç‰¹å¾å­¦ä¹ ï¼Œå…·æœ‰æœ€å°çš„è®¡ç®—å¼€é”€å’Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯è¿›è¡Œæµ‹è¯•æ—¶è¶…å‚æ•°è°ƒæ•´çš„å®é™…å¥½å¤„ã€‚åœ¨15ä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDHOå§‹ç»ˆä¼˜äºKDåŸºçº¿ï¼Œé€šå¸¸ä½¿ç”¨è¾ƒå°çš„å­¦ç”Ÿæ¨¡å‹å°±èƒ½è¶…è¶Šæ•™å¸ˆæ¨¡å‹ã€‚DHOè¿˜åœ¨In-distribution ImageNetåŠç›‘ç£å­¦ä¹ å’Œè·¨ImageNetå˜ä½“çš„Out-of-distributionæ³›åŒ–æ–¹é¢å®ç°äº†æ–°çš„æœ€æ–°æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/erjui/DHO">https://github.com/erjui/DHO</a>ä¸Šå…¬å¼€å‘å¸ƒäº†æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œä»¥æ–¹ä¾¿æœªæ¥çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07675v2">PDF</a> 38 pages, 17 figures, preprint</p>
<p><strong>Summary</strong></p>
<p>åŠç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰åˆ©ç”¨æœªæ ‡è®°æ•°æ®è§£å†³æ•°æ®ç¨€ç¼ºæŒ‘æˆ˜ã€‚è§†è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨å›¾åƒæ–‡æœ¬å¯¹ä¸Šé¢„è®­ç»ƒï¼Œå±•ç°å‡ºæƒŠäººçš„é›¶&#x2F;å°‘æ ·æœ¬æ€§èƒ½ï¼Œå¸¸è¶…è¶ŠSSLæ–¹æ³•ï¼Œå› å…¶å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºåˆ©ç”¨VLMçš„æ³›åŒ–èƒ½åŠ›åˆ°ç‰¹å®šä»»åŠ¡æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºé‡‡ç”¨çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°KDå­˜åœ¨æ¢¯åº¦å†²çªé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºåŒå¤´ä¼˜åŒ–ï¼ˆDHOï¼‰ï¼Œä¸ºæ¯ä¸ªä¸åŒä¿¡å·å¼•å…¥åŒé¢„æµ‹å¤´ã€‚DHOè§£å†³æ¢¯åº¦å†²çªï¼Œä¸å•å¤´KDåŸºçº¿ç›¸æ¯”ï¼Œæ”¹å–„ç‰¹å¾å­¦ä¹ ï¼Œå…·æœ‰æä½çš„è®¡ç®—å¼€é”€å’Œæ— éœ€é‡æ–°è®­ç»ƒçš„æµ‹è¯•æ—¶é—´è¶…å‚æ•°è°ƒæ•´ä¼˜åŠ¿ã€‚åœ¨15ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒæ˜¾ç¤ºï¼ŒDHOå¸¸ä¼˜äºKDåŸºçº¿ï¼Œæœ‰æ—¶ä»¥å°æ¨¡å‹èƒœè¿‡æ•™å¸ˆæ¨¡å‹ã€‚DHOè¿˜åœ¨ImageNetåŠç›‘ç£å­¦ä¹ å’Œè·¨ImageNetå˜ç§çš„ä»»åŠ¡å¤–æ³›åŒ–æ–¹é¢è¾¾åˆ°æ–°çš„SOTAæ€§èƒ½ã€‚æˆ‘ä»¬å…¬å¼€ä»£ç å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ä»¥æ¨åŠ¨æœªæ¥ç ”ç©¶ï¼š<a target="_blank" rel="noopener" href="https://github.com/erjui/DHO">https://github.com/erjui/DHO</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠç›‘ç£å­¦ä¹ é€šè¿‡åˆ©ç”¨æœªæ ‡è®°æ•°æ®è§£å†³æ•°æ®ç¨€ç¼ºæŒ‘æˆ˜ã€‚</li>
<li>è§†è¯­è¨€æ¨¡å‹åœ¨å›¾åƒæ–‡æœ¬å¯¹ä¸Šé¢„è®­ç»ƒï¼Œå±•ç°å‡ºä¼˜ç§€æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>çŸ¥è¯†è’¸é¦æ˜¯æœ‰æ•ˆåˆ©ç”¨è§†è¯­è¨€æ¨¡å‹èƒ½åŠ›åˆ°ç‰¹å®šä»»åŠ¡æ¨¡å‹çš„æ‰‹æ®µã€‚</li>
<li>çŸ¥è¯†è’¸é¦è¿‡ç¨‹ä¸­å­˜åœ¨æ¢¯åº¦å†²çªé—®é¢˜ã€‚</li>
<li>åŒå¤´ä¼˜åŒ–ï¼ˆDHOï¼‰æ–¹æ³•é€šè¿‡å¼•å…¥åŒé¢„æµ‹å¤´è§£å†³æ¢¯åº¦å†²çªã€‚</li>
<li>DHOæ–¹æ³•ç›¸è¾ƒäºä¼ ç»ŸçŸ¥è¯†è’¸é¦æ–¹æ³•æœ‰æ›´å¥½çš„ç‰¹å¾å­¦ä¹ èƒ½åŠ›ã€æ›´ä½çš„è®¡ç®—å¼€é”€å’Œæ›´çµæ´»çš„æµ‹è¯•æ—¶é—´è¶…å‚æ•°è°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07675">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4687a52ea36eac147bf29820e2bfa2c3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104146&auth_key=1760104146-0-0-663e7af95c86b89b50c7baf000590123&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3e90329bf420eae316e5fb2355721b17~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104154&auth_key=1760104154-0-0-91c2cc99edf85a265dd13d230251520f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bfcecfc018096f071655edf59f8ecc7b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104160&auth_key=1760104160-0-0-dc71a7daf7ce7b4e2807c8e8c9c03f00&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d01106b0d5d5ddfd89ffc4e12ecb2460~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104167&auth_key=1760104167-0-0-e2203064026bfea654689187081ed1af&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e76fc619c043b9094a0a3693e2828b78~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104173&auth_key=1760104173-0-0-0799868d0e7d165ef6f6e356bcb2aa75&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ea4ea2b453243ce9e8848c4b8b2e6756~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104180&auth_key=1760104180-0-0-da7338b02836210a23366b3e4e0f2ce7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Unlocking-Transfer-Learning-for-Open-World-Few-Shot-Recognition"><a href="#Unlocking-Transfer-Learning-for-Open-World-Few-Shot-Recognition" class="headerlink" title="Unlocking Transfer Learning for Open-World Few-Shot Recognition"></a>Unlocking Transfer Learning for Open-World Few-Shot Recognition</h2><p><strong>Authors:Byeonggeun Kim, Juntae Lee, Kyuhong Shim, Simyung Chang</strong></p>
<p>Few-Shot Open-Set Recognition (FSOSR) targets a critical real-world challenge, aiming to categorize inputs into known categories, termed closed-set classes, while identifying open-set inputs that fall outside these classes. Although transfer learning where a model is tuned to a given few-shot task has become a prominent paradigm in closed-world, we observe that it fails to expand to open-world. To unlock this challenge, we propose a two-stage method which consists of open-set aware meta-learning with open-set free transfer learning. In the open-set aware meta-learning stage, a model is trained to establish a metric space that serves as a beneficial starting point for the subsequent stage. During the open-set free transfer learning stage, the model is further adapted to a specific target task through transfer learning. Additionally, we introduce a strategy to simulate open-set examples by modifying the training dataset or generating pseudo open-set examples. The proposed method achieves state-of-the-art performance on two widely recognized benchmarks, miniImageNet and tieredImageNet, with only a 1.5% increase in training effort. Our work demonstrates the effectiveness of transfer learning in FSOSR. </p>
<blockquote>
<p>å°‘æ•°å¼€æ”¾é›†è¯†åˆ«ï¼ˆFSOSRï¼‰æ—¨åœ¨è§£å†³ç°å®ä¸–ç•Œä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œæ—¨åœ¨å°†è¾“å…¥åˆ†ç±»ä¸ºå·²çŸ¥ç±»åˆ«ï¼ˆç§°ä¸ºå°é—­é›†ç±»åˆ«ï¼‰ï¼ŒåŒæ—¶è¯†åˆ«ä¸å±äºè¿™äº›ç±»åˆ«çš„å¼€æ”¾é›†è¾“å…¥ã€‚è™½ç„¶è¿ç§»å­¦ä¹ å·²æˆä¸ºå°é—­ä¸–ç•Œä¸­ä¸€ç§çªå‡ºçš„æ¨¡å¼ï¼Œå³æ¨¡å‹è¢«è°ƒæ•´åˆ°ç»™å®šçš„å°‘æ•°ä»»åŠ¡ä¸Šï¼Œä½†æˆ‘ä»¬å‘ç°å®ƒæ— æ³•æ‰©å±•åˆ°å¼€æ”¾ä¸–ç•Œã€‚ä¸ºäº†è§£é”è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å…·æœ‰å¼€æ”¾é›†è‡ªç”±è¿ç§»å­¦ä¹ çš„å¼€æ”¾é›†æ„ŸçŸ¥å…ƒå­¦ä¹ ã€‚åœ¨å¼€æ”¾é›†æ„ŸçŸ¥å…ƒå­¦ä¹ é˜¶æ®µï¼Œæ¨¡å‹è¢«è®­ç»ƒä»¥å»ºç«‹ä¸€ä¸ªåº¦é‡ç©ºé—´ï¼Œä½œä¸ºåç»­é˜¶æ®µçš„èµ·ç‚¹ã€‚åœ¨å¼€æ”¾é›†è‡ªç”±è¿ç§»å­¦ä¹ é˜¶æ®µï¼Œæ¨¡å‹è¿›ä¸€æ­¥é€‚åº”ç‰¹å®šçš„ç›®æ ‡ä»»åŠ¡ï¼Œé€šè¿‡è¿ç§»å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ç§é€šè¿‡ä¿®æ”¹è®­ç»ƒæ•°æ®é›†æˆ–ç”Ÿæˆä¼ªå¼€æ”¾é›†ç¤ºä¾‹æ¥æ¨¡æ‹Ÿå¼€æ”¾é›†ç¤ºä¾‹çš„ç­–ç•¥ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨å¹¿æ³›è®¤å¯çš„miniImageNetå’ŒtieredImageNetåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä»…å¢åŠ äº†1.5%çš„è®­ç»ƒåŠªåŠ›ã€‚æˆ‘ä»¬çš„å·¥ä½œè¯æ˜äº†è¿ç§»å­¦ä¹ åœ¨FSOSRä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.09986v3">PDF</a> Accepted at NeurIPS 2025 workshop</p>
<p><strong>Summary</strong><br>å°‘é‡æ ·æœ¬å¼€æ”¾é›†è¯†åˆ«ï¼ˆFSOSRï¼‰æ—¨åœ¨è§£å†³ç°å®ä¸–ç•Œä¸­çš„ä¸€é¡¹é‡è¦æŒ‘æˆ˜ï¼Œå³åœ¨å¯¹è¾“å…¥è¿›è¡Œåˆ†ç±»æ—¶ï¼Œæ—¢è¦å°†å…¶å½’ç±»åˆ°å·²çŸ¥ç±»åˆ«ï¼ˆå°é—­é›†ç±»åˆ«ï¼‰ï¼Œåˆè¦è¯†åˆ«å‡ºä¸å±äºè¿™äº›ç±»åˆ«çš„å¼€æ”¾é›†è¾“å…¥ã€‚è™½ç„¶è¿ç§»å­¦ä¹ å·²æˆä¸ºå°é—­ä¸–ç•Œä¸­çš„ä¸»æµèŒƒå¼ï¼Œä½†æˆ‘ä»¬å‘ç°å®ƒæ— æ³•æ‰©å±•åˆ°å¼€æ”¾ä¸–ç•Œã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å¼€æ”¾é›†æ„ŸçŸ¥å…ƒå­¦ä¹ ä¸å¼€æ”¾é›†è‡ªç”±è¿ç§»å­¦ä¹ ã€‚åœ¨å¼€æ”¾é›†æ„ŸçŸ¥å…ƒå­¦ä¹ é˜¶æ®µï¼Œæˆ‘ä»¬è®­ç»ƒæ¨¡å‹ä»¥å»ºç«‹åº¦é‡ç©ºé—´ï¼Œä½œä¸ºåç»­é˜¶æ®µçš„èµ·ç‚¹ã€‚åœ¨å¼€æ”¾é›†è‡ªç”±è¿ç§»å­¦ä¹ é˜¶æ®µï¼Œæ¨¡å‹é€šè¿‡è¿ç§»å­¦ä¹ è¿›ä¸€æ­¥é€‚åº”ç‰¹å®šçš„ç›®æ ‡ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡ä¿®æ”¹è®­ç»ƒæ•°æ®é›†æˆ–ç”Ÿæˆä¼ªå¼€æ”¾é›†æ ·æœ¬æ¥æ¨¡æ‹Ÿå¼€æ”¾é›†ç¤ºä¾‹ã€‚è¯¥æ–¹æ³•åœ¨å¹¿æ³›è®¤å¯çš„miniImageNetå’ŒtieredImageNetåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ï¼Œä»…å¢åŠ äº†1.5%çš„è®­ç»ƒåŠªåŠ›ã€‚æˆ‘ä»¬çš„å·¥ä½œè¯æ˜äº†è¿ç§»å­¦ä¹ åœ¨FSOSRä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-Shot Open-Set Recognition (FSOSR) æ—¨åœ¨è§£å†³åŒºåˆ†å°é—­é›†å’Œå¼€æ”¾é›†è¾“å…¥çš„åˆ†ç±»é—®é¢˜ã€‚</li>
<li>è¿ç§»å­¦ä¹ åœ¨å°é—­ä¸–ç•Œè¯†åˆ«ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†æ— æ³•ç›´æ¥åº”ç”¨äºå¼€æ”¾ä¸–ç•Œè¯†åˆ«ã€‚</li>
<li>æå‡ºçš„ä¸¤é˜¶æ®µæ–¹æ³•åŒ…æ‹¬å¼€æ”¾é›†æ„ŸçŸ¥å…ƒå­¦ä¹ å’Œå¼€æ”¾é›†è‡ªç”±è¿ç§»å­¦ä¹ ï¼Œæ—¨åœ¨è§£å†³å¼€æ”¾ä¸–ç•Œè¯†åˆ«é—®é¢˜ã€‚</li>
<li>åœ¨å¼€æ”¾é›†æ„ŸçŸ¥å…ƒå­¦ä¹ é˜¶æ®µï¼Œå»ºç«‹åº¦é‡ç©ºé—´ä½œä¸ºåç»­é˜¶æ®µçš„èµ·ç‚¹ã€‚</li>
<li>åœ¨å¼€æ”¾é›†è‡ªç”±è¿ç§»å­¦ä¹ é˜¶æ®µï¼Œæ¨¡å‹é€‚åº”ç‰¹å®šç›®æ ‡ä»»åŠ¡ã€‚</li>
<li>é€šè¿‡æ¨¡æ‹Ÿå¼€æ”¾é›†ç¤ºä¾‹æ¥å¢å¼ºæ–¹æ³•ï¼ŒåŒ…æ‹¬ä¿®æ”¹è®­ç»ƒæ•°æ®é›†æˆ–ç”Ÿæˆä¼ªå¼€æ”¾é›†æ ·æœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.09986">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bb4c3d625fde1930a60bdf39a1514aba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104187&auth_key=1760104187-0-0-5add8ba5cb46313fdb63d33e39ddee7d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-55e2bbe8afb6550214cdc0acecea6498~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104194&auth_key=1760104194-0-0-b058d791e5f9eb11c005560cee6036c0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c625b4fb044c11f129aed02cb20848ac~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104201&auth_key=1760104201-0-0-bd124860a2306213a03b6400f4535f9d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fbbbf796640899729e7f859fba492b59~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104208&auth_key=1760104208-0-0-a03ae42ec66fb0fc389cac2c387e4267&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Adaptive-Modality-Balanced-Online-Knowledge-Distillation-for-Brain-Eye-Computer-based-Dim-Object-Detection"><a href="#Adaptive-Modality-Balanced-Online-Knowledge-Distillation-for-Brain-Eye-Computer-based-Dim-Object-Detection" class="headerlink" title="Adaptive Modality Balanced Online Knowledge Distillation for   Brain-Eye-Computer based Dim Object Detection"></a>Adaptive Modality Balanced Online Knowledge Distillation for   Brain-Eye-Computer based Dim Object Detection</h2><p><strong>Authors:Zixing Li, Chao Yan, Zhen Lan, Xiaojia Xiang, Han Zhou, Jun Lai, Dengqing Tang</strong></p>
<p>Advanced cognition can be extracted from the human brain using brain-computer interfaces. Integrating these interfaces with computer vision techniques, which possess efficient feature extraction capabilities, can achieve more robust and accurate detection of dim targets in aerial images. However, existing target detection methods primarily concentrate on homogeneous data, lacking efficient and versatile processing capabilities for heterogeneous multimodal data. In this paper, we first build a brain-eye-computer based object detection system for aerial images under few-shot conditions. This system detects suspicious targets using region proposal networks, evokes the event-related potential (ERP) signal in electroencephalogram (EEG) through the eye-tracking-based slow serial visual presentation (ESSVP) paradigm, and constructs the EEG-image data pairs with eye movement data. Then, an adaptive modality balanced online knowledge distillation (AMBOKD) method is proposed to recognize dim objects with the EEG-image data. AMBOKD fuses EEG and image features using a multi-head attention module, establishing a new modality with comprehensive features. To enhance the performance and robust capability of the fusion modality, simultaneous training and mutual learning between modalities are enabled by end-to-end online knowledge distillation. During the learning process, an adaptive modality balancing module is proposed to ensure multimodal equilibrium by dynamically adjusting the weights of the importance and the training gradients across various modalities. The effectiveness and superiority of our method are demonstrated by comparing it with existing state-of-the-art methods. Additionally, experiments conducted on public datasets and system validations in real-world scenarios demonstrate the reliability and practicality of the proposed system and the designed method. </p>
<blockquote>
<p>åˆ©ç”¨è„‘æœºæ¥å£å¯ä»¥ä»äººè„‘ä¸­æå–é«˜çº§è®¤çŸ¥ã€‚å°†è¿™äº›æ¥å£ä¸æ‹¥æœ‰é«˜æ•ˆç‰¹å¾æå–èƒ½åŠ›çš„è®¡ç®—æœºè§†è§‰æŠ€æœ¯ç›¸ç»“åˆï¼Œå¯ä»¥å®ç°æ›´ç¨³å¥ã€æ›´å‡†ç¡®åœ°æ£€æµ‹èˆªç©ºå›¾åƒä¸­çš„å¾®å¼±ç›®æ ‡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç›®æ ‡æ£€æµ‹æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨åŒè´¨æ•°æ®ä¸Šï¼Œç¼ºä¹å¯¹å¼‚è´¨å¤šæ¨¡æ€æ•°æ®çš„é«˜æ•ˆé€šç”¨å¤„ç†èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨å°‘æ ·æœ¬æ¡ä»¶ä¸‹æ„å»ºäº†åŸºäºäººè„‘-çœ¼ç›-è®¡ç®—æœºçš„èˆªç©ºå›¾åƒç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨åŒºåŸŸææ¡ˆç½‘ç»œæ£€æµ‹å¯ç–‘ç›®æ ‡ï¼Œé€šè¿‡åŸºäºçœ¼åŠ¨çš„æ…¢é€Ÿåºåˆ—è§†è§‰å‘ˆç°ï¼ˆESSVPï¼‰èŒƒå¼æ¿€å‘è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¸­çš„äº‹ä»¶ç›¸å…³ç”µä½ï¼ˆERPï¼‰ä¿¡å·ï¼Œå¹¶æ„å»ºEEG-å›¾åƒæ•°æ®å¯¹ä»¥åŠçœ¼åŠ¨æ•°æ®ã€‚ç„¶åï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ¨¡æ€å¹³è¡¡åœ¨çº¿çŸ¥è¯†è’¸é¦ï¼ˆAMBOKDï¼‰æ–¹æ³•æ¥è¯†åˆ«å¾®å¼±çš„ç‰©ä½“ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨EEG-å›¾åƒæ•°æ®ã€‚AMBOKDä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æ¨¡å—èåˆEEGå’Œå›¾åƒç‰¹å¾ï¼Œå»ºç«‹å…·æœ‰ç»¼åˆç‰¹å¾çš„æ–°æ¨¡æ€ã€‚ä¸ºäº†æé«˜èåˆæ¨¡æ€çš„æ€§èƒ½å’Œç¨³å¥æ€§ï¼Œé€šè¿‡ç«¯åˆ°ç«¯çš„åœ¨çº¿çŸ¥è¯†è’¸é¦å®ç°äº†æ¨¡æ€ä¹‹é—´çš„åŒæ—¶è®­ç»ƒå’Œç›¸äº’å­¦ä¹ ã€‚åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ¨¡æ€å¹³è¡¡æ¨¡å—ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´ä¸åŒæ¨¡æ€ä¹‹é—´çš„é‡è¦æ€§å’Œè®­ç»ƒæ¢¯åº¦çš„æƒé‡ï¼Œä»¥ç¡®ä¿å¤šæ¨¡æ€å¹³è¡¡ã€‚é€šè¿‡ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œåœ¨å…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒä»¥åŠåœ¨ç°å®åœºæ™¯ä¸­çš„ç³»ç»ŸéªŒè¯è¯æ˜äº†æ‰€æå‡ºç³»ç»Ÿå’Œæ–¹æ³•çš„å¯é æ€§å’Œå®ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.01894v3">PDF</a> 18 pages,15 figures</p>
<p><strong>Summary</strong><br>     é€šè¿‡è„‘æœºæ¥å£æå–äººç±»é«˜çº§è®¤çŸ¥ï¼Œç»“åˆè®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œèƒ½æ›´ç¨³å¥å‡†ç¡®åœ°æ£€æµ‹èˆªç©ºå›¾åƒä¸­çš„å¾®å¼±ç›®æ ‡ã€‚é’ˆå¯¹ç°æœ‰ç›®æ ‡æ£€æµ‹æ–¹æ³•ä¸»è¦å¤„ç†åŒè´¨æ•°æ®çš„é—®é¢˜ï¼Œæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªåŸºäºè„‘çœ¼è®¡ç®—æœºçš„å°‘æ ·æœ¬èˆªç©ºå›¾åƒç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚ç³»ç»Ÿåˆ©ç”¨åŒºåŸŸææ¡ˆç½‘ç»œæ£€æµ‹å¯ç–‘ç›®æ ‡ï¼Œå¹¶é€šè¿‡çœ¼åŠ¨è¿½è¸ªçš„æ…¢é€Ÿåºåˆ—è§†è§‰å‘ˆç°èŒƒå¼æ¿€å‘è„‘ç”µå›¾ä¸­çš„äº‹ä»¶ç›¸å…³ç”µä½ä¿¡å·ï¼Œæ„å»ºEEG-å›¾åƒæ•°æ®ä¸çœ¼åŠ¨æ•°æ®å¯¹ã€‚æå‡ºè‡ªé€‚åº”æ¨¡æ€å¹³è¡¡åœ¨çº¿çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼ŒèåˆEEGå’Œå›¾åƒç‰¹å¾ï¼Œå»ºç«‹å…·æœ‰ç»¼åˆç‰¹å¾çš„æ–°æ¨¡æ€ã€‚é€šè¿‡ç«¯å¯¹ç«¯åœ¨çº¿çŸ¥è¯†è’¸é¦å®ç°æ¨¡æ€é—´çš„åŒæ­¥è®­ç»ƒå’Œç›¸äº’å­¦ä¹ ï¼Œæé«˜èåˆæ¨¡æ€çš„æ€§èƒ½å’Œç¨³å¥æ€§ã€‚é€šè¿‡è‡ªé€‚åº”æ¨¡æ€å¹³è¡¡æ¨¡å—ç¡®ä¿å¤šæ¨¡æ€å¹³è¡¡ï¼ŒåŠ¨æ€è°ƒæ•´ä¸åŒæ¨¡æ€çš„é‡è¦æ€§å’Œè®­ç»ƒæ¢¯åº¦çš„æƒé‡ã€‚æœ¬æ–‡æ–¹æ³•ä¸ç°æœ‰å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒå’ŒçœŸå®åœºæ™¯çš„ç³»ç»ŸéªŒè¯ï¼Œè¯æ˜äº†æ‰€æç³»ç»Ÿå’Œæ–¹æ³•çš„å¯é æ€§å’Œå®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨è„‘æœºæ¥å£æå–äººç±»é«˜çº§è®¤çŸ¥ä¿¡æ¯ã€‚</li>
<li>ç»“åˆè®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œæé«˜æ£€æµ‹èˆªç©ºå›¾åƒä¸­å¾®å¼±ç›®æ ‡çš„èƒ½åŠ›ã€‚</li>
<li>æ„å»ºåŸºäºè„‘çœ¼è®¡ç®—æœºç³»ç»Ÿçš„å°‘æ ·æœ¬èˆªç©ºå›¾åƒç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚</li>
<li>é€šè¿‡åŒºåŸŸææ¡ˆç½‘ç»œæ£€æµ‹å¯ç–‘ç›®æ ‡ã€‚</li>
<li>åˆ©ç”¨çœ¼åŠ¨è¿½è¸ªæ¿€å‘è„‘ç”µå›¾ä¸­çš„äº‹ä»¶ç›¸å…³ç”µä½ä¿¡å·ã€‚</li>
<li>æå‡ºè‡ªé€‚åº”æ¨¡æ€å¹³è¡¡åœ¨çº¿çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼ŒèåˆEEGå’Œå›¾åƒç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.01894">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c787f9146ffc604b87d17b96a917f8ef~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104215&auth_key=1760104215-0-0-b1466ed4408e5ebf556980967431c99b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ab1751eae05eed935ba8b4d1b7ca9d4a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104222&auth_key=1760104222-0-0-de6ea6a3e70e9f4c07570bfcd9c21056&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3105dc3ef22f1707283a96d035a804dc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104229&auth_key=1760104229-0-0-29d13744f5d2ffb8b3c5efa5d4bf03dd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6bb431813a8dcc8b3570d9d5987059c5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104235&auth_key=1760104235-0-0-126822df901be8e66c91847cefc1cffe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a684d825aeead4b7e5539ac9e90b495f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104242&auth_key=1760104242-0-0-6731da00ca3cbb98c9b2ec0181e1b106&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a87765fddc974d76ddf56701e5f1672e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760104248&auth_key=1760104248-0-0-64b4b92e1d629d2f613042a78f39f8c2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-02/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-02/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-02/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-71a3255627e058936fe1dff864b88463~resize:0:q75.jpg?source=1f5c5e47&expiration=1760087081&auth_key=1760087081-0-0-e674477126b4b7180edbef4843126118&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-02  Data-to-Energy Stochastic Dynamics
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-02/MMT/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-316ac343a4123541cf6b2a9c67fabb96~resize:0:q75.jpg?source=1f5c5e47&expiration=1760086781&auth_key=1760086781-0-0-d9ef4471783eb8cbbc567cb4cf43766c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-02  A Culturally-diverse Multilingual Multimodal Video Benchmark & Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30191.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
