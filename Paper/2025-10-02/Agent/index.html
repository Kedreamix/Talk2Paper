<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-02  OceanGym A Benchmark Environment for Underwater Embodied Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6c95fafcbda4086ea80cee5e6a942048')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    77 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-02-æ›´æ–°"><a href="#2025-10-02-æ›´æ–°" class="headerlink" title="2025-10-02 æ›´æ–°"></a>2025-10-02 æ›´æ–°</h1><h2 id="OceanGym-A-Benchmark-Environment-for-Underwater-Embodied-Agents"><a href="#OceanGym-A-Benchmark-Environment-for-Underwater-Embodied-Agents" class="headerlink" title="OceanGym: A Benchmark Environment for Underwater Embodied Agents"></a>OceanGym: A Benchmark Environment for Underwater Embodied Agents</h2><p><strong>Authors:Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei Qiao, Mengru Wang, Shumin Deng, Xinyu An, Ningyu Zhang, Ying Chen, Huajun Chen</strong></p>
<p>We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earthâ€™s last unexplored frontiers. The code and data are available at <a target="_blank" rel="noopener" href="https://github.com/OceanGPT/OceanGym">https://github.com/OceanGPT/OceanGym</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†OceanGymï¼Œè¿™æ˜¯é’ˆå¯¹æµ·æ´‹æ°´ä¸‹æ™ºèƒ½ä½“çš„é¦–ä¸ªå…¨é¢åŸºå‡†æµ‹è¯•å¹³å°ï¼Œæ—¨åœ¨åœ¨æœ€è‹›åˆ»çš„ç°å®ç¯å¢ƒä¹‹ä¸€ä¸­æ¨åŠ¨äººå·¥æ™ºèƒ½çš„å‘å±•ã€‚ä¸é™†åœ°æˆ–ç©ºä¸­é¢†åŸŸä¸åŒï¼Œæ°´ä¸‹ç¯å¢ƒå¸¦æ¥äº†æç«¯çš„æ„ŸçŸ¥å’Œå†³ç­–æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä½èƒ½è§åº¦ã€åŠ¨æ€æ´‹æµï¼Œä½¿å¾—æœ‰æ•ˆéƒ¨ç½²æ™ºèƒ½ä½“å˜å¾—å¼‚å¸¸å›°éš¾ã€‚OceanGymåŒ…å«å…«ä¸ªç°å®ä»»åŠ¡é¢†åŸŸå’Œä¸€ä¸ªç”±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰é©±åŠ¨çš„ç»Ÿä¸€æ™ºèƒ½ä½“æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†æ„ŸçŸ¥ã€è®°å¿†å’Œåºåˆ—å†³ç­–ã€‚æ™ºèƒ½ä½“éœ€è¦ç†è§£å…‰å­¦å’Œå£°çº³æ•°æ®ï¼Œè‡ªä¸»æ¢ç´¢å¤æ‚ç¯å¢ƒï¼Œå¹¶åœ¨è¿™äº›æ¶åŠ£æ¡ä»¶ä¸‹å®Œæˆé•¿æœŸç›®æ ‡ã€‚å¤§é‡å®éªŒæ­ç¤ºäº†æœ€å…ˆè¿›çš„MLLMé©±åŠ¨çš„æ™ºèƒ½ä½“ä¸äººç±»ä¸“å®¶ä¹‹é—´çš„å·¨å¤§å·®è·ï¼Œçªå‡ºäº†æµ·æ´‹æ°´ä¸‹ç¯å¢ƒä¸­æ„ŸçŸ¥ã€è§„åˆ’å’Œé€‚åº”æ€§çš„æŒä¹…æ€§å›°éš¾ã€‚é€šè¿‡æä¾›é«˜ä¿çœŸã€ä¸¥æ ¼è®¾è®¡çš„å¹³å°ï¼ŒOceanGymä¸ºå¼€å‘ç¨³å¥çš„åµŒå…¥å¼äººå·¥æ™ºèƒ½å¹¶å°†è¿™äº›èƒ½åŠ›è½¬ç§»åˆ°å®é™…çš„æ°´ä¸‹è‡ªåŠ¨é©¾é©¶è½¦è¾†å»ºç«‹äº†æµ‹è¯•åºŠï¼Œè¿™æ˜¯æœç€èƒ½å¤Ÿæ“ä½œåœ°çƒæœ€åä¸€ä¸ªæœªå¼€å‘å‰æ²¿ä¹‹ä¸€çš„æ™ºèƒ½ä½“è¿ˆå‡ºçš„å†³å®šæ€§ä¸€æ­¥ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/OceanGPT/OceanGym%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/OceanGPT/OceanGymæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26536v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>OceanGymæ˜¯ä¸€ä¸ªé’ˆå¯¹æµ·æ´‹æ°´ä¸‹æ™ºèƒ½ä½“è®¾è®¡çš„å…¨é¢åŸºå‡†æµ‹è¯•å¹³å°ï¼Œæ—¨åœ¨æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨æå…·æŒ‘æˆ˜æ€§çš„æ°´ä¸‹ç¯å¢ƒä¸­çš„å‘å±•ã€‚è¯¥å¹³å°æ¶µç›–å…«ä¸ªç°å®ä»»åŠ¡é¢†åŸŸï¼Œé‡‡ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ç»Ÿä¸€æ™ºèƒ½ä½“æ¡†æ¶ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥ã€è®°å¿†å’Œåºåˆ—å†³ç­–åˆ¶å®šç­‰åŠŸèƒ½ã€‚è¯¥å¹³å°ä¸ºå¼€å‘ç¨³å¥çš„æ°´ä¸‹äººå·¥æ™ºèƒ½æä¾›äº†ä¸€ä¸ªä¸¥æ ¼è®¾è®¡çš„é«˜ä¿çœŸæµ‹è¯•ç¯å¢ƒï¼Œæ ‡å¿—ç€å°†æ™ºèƒ½ä½“åº”ç”¨äºåœ°çƒæœ€åä¸€ä¸ªæœªè¢«æ¢ç´¢çš„å‰æ²¿â€”â€”æµ·æ´‹çš„é‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OceanGymæ˜¯é¦–ä¸ªé’ˆå¯¹æµ·æ´‹æ°´ä¸‹æ™ºèƒ½ä½“çš„å…¨é¢åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>å¹³å°æ—¨åœ¨æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨æå…·æŒ‘æˆ˜æ€§çš„æ°´ä¸‹ç¯å¢ƒä¸­çš„åº”ç”¨å’Œå‘å±•ã€‚</li>
<li>OceanGymæ¶µç›–å…«ä¸ªç°å®ä»»åŠ¡é¢†åŸŸï¼ŒåŒ…æ‹¬æ„ŸçŸ¥å’Œå†³ç­–åˆ¶å®šç­‰åŠŸèƒ½ã€‚</li>
<li>é‡‡ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ç»Ÿä¸€æ™ºèƒ½ä½“æ¡†æ¶ã€‚</li>
<li>æ™ºèƒ½ä½“éœ€è¦å¤„ç†å…‰å­¦å’Œå£°çº³æ•°æ®ï¼Œè‡ªä¸»æ¢ç´¢å¤æ‚ç¯å¢ƒï¼Œå®Œæˆé•¿æœŸç›®æ ‡ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œç°æœ‰æŠ€æœ¯ä¸äººä¸“å®¶ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œç‰¹åˆ«æ˜¯åœ¨æ„ŸçŸ¥ã€è§„åˆ’å’Œé€‚åº”æ€§æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26536">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-de80cdfa29da524f97005bb4836865b8" align="middle">
<img src="https://picx.zhimg.com/v2-8abf1108149bd21633629fe8558c8fc1" align="middle">
<img src="https://picx.zhimg.com/v2-752c00b703f42065918dd2ccc544699f" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="VitaBench-Benchmarking-LLM-Agents-with-Versatile-Interactive-Tasks-in-Real-world-Applications"><a href="#VitaBench-Benchmarking-LLM-Agents-with-Versatile-Interactive-Tasks-in-Real-world-Applications" class="headerlink" title="VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in   Real-world Applications"></a>VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in   Real-world Applications</h2><p><strong>Authors:Wei He, Yueqing Sun, Hongyan Hao, Xueyuan Hao, Zhikang Xia, Qi Gu, Chengcheng Han, Dengchang Zhao, Hui Su, Kefeng Zhang, Man Gao, Xi Su, Xiaodong Cai, Xunliang Cai, Yu Yang, Yunke Zhao</strong></p>
<p>As LLM-based agents are increasingly deployed in real-life scenarios, existing benchmarks fail to capture their inherent complexity of handling extensive information, leveraging diverse resources, and managing dynamic user interactions. To address this gap, we introduce VitaBench, a challenging benchmark that evaluates agents on versatile interactive tasks grounded in real-world settings. Drawing from daily applications in food delivery, in-store consumption, and online travel services, VitaBench presents agents with the most complex life-serving simulation environment to date, comprising 66 tools. Through a framework that eliminates domain-specific policies, we enable flexible composition of these scenarios and tools, yielding 100 cross-scenario tasks (main results) and 300 single-scenario tasks. Each task is derived from multiple real user requests and requires agents to reason across temporal and spatial dimensions, utilize complex tool sets, proactively clarify ambiguous instructions, and track shifting user intent throughout multi-turn conversations. Moreover, we propose a rubric-based sliding window evaluator, enabling robust assessment of diverse solution pathways in complex environments and stochastic interactions. Our comprehensive evaluation reveals that even the most advanced models achieve only 30% success rate on cross-scenario tasks, and less than 50% success rate on others. Overall, we believe VitaBench will serve as a valuable resource for advancing the development of AI agents in practical real-world applications. The code, dataset, and leaderboard are available at <a target="_blank" rel="noopener" href="https://vitabench.github.io/">https://vitabench.github.io/</a> </p>
<blockquote>
<p>éšç€åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨ç°å®ç”Ÿæ´»åœºæ™¯ä¸­çš„éƒ¨ç½²è¶Šæ¥è¶Šå¤šï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•æ— æ³•æ•æ‰åˆ°å®ƒä»¬å¤„ç†å¤§é‡ä¿¡æ¯ã€åˆ©ç”¨ä¸åŒèµ„æºå’Œå¤„ç†åŠ¨æ€ç”¨æˆ·äº¤äº’çš„å†…åœ¨å¤æ‚æ€§ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†VitaBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°ä»£ç†åœ¨ç°å®ç¯å¢ƒä¸­çš„é€šç”¨äº¤äº’ä»»åŠ¡è¡¨ç°ã€‚VitaBenchå€Ÿé‰´äº†é£Ÿå“é…é€ã€åº—å†…æ¶ˆè´¹å’Œåœ¨çº¿æ—…è¡ŒæœåŠ¡ç­‰æ—¥å¸¸åº”ç”¨ï¼Œä¸ºä»£ç†æä¾›äº†è¿„ä»Šä¸ºæ­¢æœ€å¤æ‚çš„ç”Ÿæ´»æœåŠ¡æ¨¡æ‹Ÿç¯å¢ƒï¼ŒåŒ…å«66ç§å·¥å…·ã€‚é€šè¿‡ä¸€ä¸ªæ¶ˆé™¤ç‰¹å®šé¢†åŸŸç­–ç•¥çš„æ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿçµæ´»åœ°ç»„åˆè¿™äº›åœºæ™¯å’Œå·¥å…·ï¼Œäº§ç”Ÿ100ä¸ªè·¨åœºæ™¯ä»»åŠ¡å’Œ300ä¸ªå•ä¸€åœºæ™¯ä»»åŠ¡ï¼ˆä¸»è¦ç»“æœï¼‰ã€‚æ¯ä¸ªä»»åŠ¡éƒ½æ¥æºäºå¤šä¸ªçœŸå®ç”¨æˆ·è¯·æ±‚ï¼Œè¦æ±‚ä»£ç†åœ¨æ—¶é—´å’Œç©ºé—´ç»´åº¦ä¸Šè¿›è¡Œæ¨ç†ï¼Œåˆ©ç”¨å¤æ‚çš„å·¥å…·é›†ï¼Œä¸»åŠ¨æ¾„æ¸…æ¨¡ç³ŠæŒ‡ä»¤ï¼Œå¹¶åœ¨å¤šè½®å¯¹è¯ä¸­è·Ÿè¸ªå˜åŒ–çš„ç”¨æˆ·æ„å›¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ¡ç›®çš„æ»‘åŠ¨çª—å£è¯„ä¼°å™¨ï¼Œèƒ½å¤Ÿå¯¹å¤æ‚ç¯å¢ƒå’Œéšæœºäº¤äº’ä¸­çš„ä¸åŒè§£å†³æ–¹æ¡ˆè·¯å¾„è¿›è¡Œç¨³å¥è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç»¼åˆè¯„ä¼°å‘ç°ï¼Œå³ä½¿åœ¨è·¨åœºæ™¯ä»»åŠ¡ä¸­ï¼Œæœ€å…ˆè¿›çš„æ¨¡å‹ä¹Ÿä»…è¾¾åˆ°30%çš„æˆåŠŸç‡ï¼Œå…¶ä»–ä»»åŠ¡çš„æˆåŠŸç‡ä¹Ÿä½äº50%ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬ç›¸ä¿¡VitaBenchå°†æˆä¸ºæ¨åŠ¨äººå·¥æ™ºèƒ½ä»£ç†åœ¨å®é™…ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„å‘å±•çš„å®è´µèµ„æºã€‚ç›¸å…³ä»£ç ã€æ•°æ®é›†å’Œæ’è¡Œæ¦œå¯åœ¨<a target="_blank" rel="noopener" href="https://vitabench.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://vitabench.github.io/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26490v1">PDF</a> The code, dataset, and leaderboard are available at   <a target="_blank" rel="noopener" href="https://vitabench.github.io/">https://vitabench.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å®é™…åœºæ™¯ä¸­éƒ¨ç½²è¶Šæ¥è¶Šå¤šï¼Œä½†ç°æœ‰åŸºå‡†æµ‹è¯•æ— æ³•æ•æ‰åˆ°å…¶å¤„ç†å¤§é‡ä¿¡æ¯ã€åˆ©ç”¨å¤šæ ·èµ„æºå’Œå¤„ç†åŠ¨æ€ç”¨æˆ·äº¤äº’çš„å†…åœ¨å¤æ‚æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºVitaBenchåŸºå‡†æµ‹è¯•ï¼Œå®ƒè¯„ä¼°ä»£ç†åœ¨ç°å®ç¯å¢ƒä¸­çš„é€šç”¨äº¤äº’ä»»åŠ¡è¡¨ç°ã€‚VitaBenchæ¨¡æ‹Ÿäº†é£Ÿå“é…é€ã€åº—å†…æ¶ˆè´¹å’Œåœ¨çº¿æ—…è¡ŒæœåŠ¡ç­‰æ—¥å¸¸åº”ç”¨ï¼Œä¸ºä»£ç†æä¾›äº†è¿„ä»Šä¸ºæ­¢æœ€å¤æ‚çš„ç”Ÿæ´»æœåŠ¡æ¨¡æ‹Ÿç¯å¢ƒï¼ŒåŒ…å«66ç§å·¥å…·ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªæ¡†æ¶æ¥æ¶ˆé™¤ç‰¹å®šé¢†åŸŸçš„æ”¿ç­–ï¼Œä½¿è¿™äº›åœºæ™¯å’Œå·¥å…·å…·æœ‰çµæ´»çš„ç»„åˆæ€§ï¼Œäº§ç”Ÿäº†100ä¸ªè·¨åœºæ™¯ä»»åŠ¡å’Œ300ä¸ªå•ä¸€åœºæ™¯ä»»åŠ¡ã€‚æ¯ä¸ªä»»åŠ¡éƒ½æºäºå¤šä¸ªçœŸå®ç”¨æˆ·éœ€æ±‚ï¼Œè¦æ±‚ä»£ç†åœ¨æ—¶é—´å’Œç©ºé—´ç»´åº¦ä¸Šè¿›è¡Œæ¨ç†ï¼Œä½¿ç”¨å¤æ‚çš„å·¥å…·é›†ï¼Œä¸»åŠ¨æ¾„æ¸…æ¨¡ç³ŠæŒ‡ä»¤ï¼Œå¹¶åœ¨å¤šè½®å¯¹è¯ä¸­è·Ÿè¸ªå˜åŒ–çš„ç”¨æˆ·æ„å›¾ã€‚æˆ‘ä»¬çš„ç»¼åˆè¯„ä¼°å‘ç°ï¼Œæœ€å…ˆè¿›çš„æ¨¡å‹åœ¨è·¨åœºæ™¯ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä»…ä¸º30%ï¼Œå…¶ä»–ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä¹Ÿä½äº50%ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ç›¸ä¿¡VitaBenchå°†ä¸ºæ¨è¿›AIä»£ç†åœ¨å®ç”¨ç°å®åº”ç”¨ä¸­çš„å‘å±•æä¾›äº†å®è´µçš„èµ„æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰åŸºå‡†æµ‹è¯•æ— æ³•å……åˆ†æ•æ‰LLMä»£ç†åœ¨å¤„ç†ç°å®åœºæ™¯ä¸­çš„å¤æ‚æ€§ã€‚</li>
<li>VitaBenchæ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°ä»£ç†åœ¨ç°å®ä¸–ç•Œç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚</li>
<li>VitaBenchåŒ…å«66ç§å·¥å…·ï¼Œæ¨¡æ‹Ÿäº†å¤æ‚çš„ç”Ÿæ´»ç¯å¢ƒã€‚</li>
<li>æ¡†æ¶å…è®¸çµæ´»çš„åœºæ™¯å’Œå·¥å…·ç»„åˆï¼Œç”Ÿæˆå¤šç§ä»»åŠ¡ã€‚</li>
<li>æ¯ä¸ªä»»åŠ¡æºäºçœŸå®ç”¨æˆ·éœ€æ±‚ï¼Œè¦æ±‚ä»£ç†è¿›è¡Œå¤æ‚çš„æ¨ç†å’Œäº¤äº’ã€‚</li>
<li>æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨è·¨åœºæ™¯ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡è¾ƒä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26490">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a21d168ac9f169160bb4d4a13970f110" align="middle">
<img src="https://picx.zhimg.com/v2-8d9924af4cec3c44f2e09e909c636bd4" align="middle">
<img src="https://picx.zhimg.com/v2-9f5917c58b07515ae5a838e285eeb470" align="middle">
<img src="https://picx.zhimg.com/v2-414bc9d6cbe91887cef6873d49318ac9" align="middle">
<img src="https://picx.zhimg.com/v2-60c7d2636cc8cbc9ec149ed0754b0f95" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CreAgentive-An-Agent-Workflow-Driven-Multi-Category-Creative-Generation-Engine"><a href="#CreAgentive-An-Agent-Workflow-Driven-Multi-Category-Creative-Generation-Engine" class="headerlink" title="CreAgentive: An Agent Workflow Driven Multi-Category Creative Generation   Engine"></a>CreAgentive: An Agent Workflow Driven Multi-Category Creative Generation   Engine</h2><p><strong>Authors:Yuyang Cheng, Linyue Cai, Changwei Peng, Yumiao Xu, Rongfang Bie, Yong Zhao</strong></p>
<p>We present CreAgentive, an agent workflow driven multi-category creative generation engine that addresses four key limitations of contemporary large language models in writing stories, drama and other categories of creatives: restricted genre diversity, insufficient output length, weak narrative coherence, and inability to enforce complex structural constructs. At its core, CreAgentive employs a Story Prototype, which is a genre-agnostic, knowledge graph-based narrative representation that decouples story logic from stylistic realization by encoding characters, events, and environments as semantic triples. CreAgentive engages a three-stage agent workflow that comprises: an Initialization Stage that constructs a user-specified narrative skeleton; a Generation Stage in which long- and short-term objectives guide multi-agent dialogues to instantiate the Story Prototype; a Writing Stage that leverages this prototype to produce multi-genre text with advanced structures such as retrospection and foreshadowing. This architecture reduces storage redundancy and overcomes the typical bottlenecks of long-form generation. In extensive experiments, CreAgentive generates thousands of chapters with stable quality and low cost (less than $1 per 100 chapters) using a general-purpose backbone model. To evaluate performance, we define a two-dimensional framework with 10 narrative indicators measuring both quality and length. Results show that CreAgentive consistently outperforms strong baselines and achieves robust performance across diverse genres, approaching the quality of human-authored novels. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†CreAgentiveï¼Œè¿™æ˜¯ä¸€æ¬¾ä»¥ä»£ç†å·¥ä½œæµç¨‹é©±åŠ¨çš„è·¨ç±»åˆ«åˆ›æ„ç”Ÿæˆå¼•æ“ï¼Œè§£å†³äº†å½“ä»£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†™ä½œæ•…äº‹ã€æˆå‰§å’Œå…¶ä»–ç±»åˆ«åˆ›æ„æ—¶é¢ä¸´çš„å››å¤§å±€é™ï¼šæœ‰é™çš„ä½“è£å¤šæ ·æ€§ã€è¾“å‡ºé•¿åº¦ä¸è¶³ã€å™äº‹è¿è´¯æ€§å¼±ä»¥åŠæ— æ³•æ‰§è¡Œå¤æ‚çš„ç»“æ„æ„å»ºã€‚CreAgentiveçš„æ ¸å¿ƒé‡‡ç”¨æ•…äº‹åŸå‹ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å™äº‹è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡ç¼–ç è§’è‰²ã€äº‹ä»¶å’Œç¯å¢ƒä¸ºè¯­ä¹‰ä¸‰å…ƒç»„ï¼Œå°†æ•…äº‹é€»è¾‘ä¸é£æ ¼å®ç°ç›¸åˆ†ç¦»ã€‚CreAgentiveé‡‡ç”¨ä¸‰é˜¶æ®µä»£ç†å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ï¼šæ„å»ºç”¨æˆ·æŒ‡å®šçš„å™äº‹éª¨æ¶çš„åˆå§‹åŒ–é˜¶æ®µï¼›é•¿çŸ­æœŸç›®æ ‡æŒ‡å¯¼å¤šä»£ç†å¯¹è¯ä»¥å®ä¾‹åŒ–æ•…äº‹åŸå‹çš„ç”Ÿæˆé˜¶æ®µï¼›ä»¥åŠåˆ©ç”¨è¯¥åŸå‹äº§ç”Ÿå…·æœ‰åæ€å’Œé¢„ç¤ºç­‰é«˜çº§ç»“æ„çš„å¤šä½“è£æ–‡æœ¬çš„å†™ä½œé˜¶æ®µã€‚è¿™ç§æ¶æ„å‡å°‘äº†å­˜å‚¨å†—ä½™ï¼Œå…‹æœäº†é•¿å½¢å¼ç”Ÿæˆçš„å…¸å‹ç“¶é¢ˆã€‚åœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒCreAgentiveä½¿ç”¨é€šç”¨éª¨å¹²æ¨¡å‹ä»¥ç¨³å®šçš„å“è´¨å’Œä½æˆæœ¬ï¼ˆæ¯100ç« ä¸åˆ°1ç¾å…ƒï¼‰ç”Ÿæˆäº†æˆåƒä¸Šä¸‡ç« çš„å†…å®¹ã€‚ä¸ºäº†è¯„ä¼°æ€§èƒ½ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªäºŒç»´æ¡†æ¶ï¼ŒåŒ…å«10ä¸ªè¡¡é‡è´¨é‡å’Œé•¿åº¦çš„å™äº‹æŒ‡æ ‡ã€‚ç»“æœè¡¨æ˜ï¼ŒCreAgentiveæŒç»­è¶…è¶Šå¼ºåŠ²çš„åŸºçº¿ï¼Œå¹¶åœ¨å„ç§ä½“è£ä¸­è¡¨ç°ç¨³å¥ï¼Œæ¥è¿‘äººç±»åˆ›ä½œçš„å°è¯´è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26461v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>CrAgentiveæ˜¯ä¸€æ¬¾é’ˆå¯¹å½“ä»£å¤§å‹è¯­è¨€æ¨¡å‹å†™ä½œæ•…äº‹ã€æˆå‰§å’Œå…¶ä»–ç±»åˆ«åˆ›æ„æ‰€å­˜åœ¨çš„å››å¤§å±€é™æ€§é—®é¢˜ï¼Œè€Œå¼€å‘çš„å¤šç±»åˆ«åˆ›æ„ç”Ÿæˆå¼•æ“ã€‚å®ƒèƒ½æœ‰æ•ˆè§£å†³åˆ›æ„é¢†åŸŸä¸­é¢ä¸´çš„å››å¤§é™åˆ¶ï¼šå±€é™çš„æµæ´¾å¤šæ ·æ€§ã€è¾“å‡ºçš„ä¸è¶³é•¿åº¦ã€å™äº‹è¿è´¯æ€§çš„å¼±åŒ–ä»¥åŠå¯¹å¤æ‚ç»“æ„å»ºæ„çš„æ‰§è¡Œèƒ½åŠ›ä¸è¶³ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨äº†æ•…äº‹åŸå‹ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å™äº‹è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡ç¼–ç è§’è‰²ã€äº‹ä»¶å’Œç¯å¢ƒä¸ºè¯­ä¹‰ä¸‰å…ƒç»„ï¼Œå°†æ•…äº‹é€»è¾‘ä¸é£æ ¼å®ç°ç›¸åˆ†ç¦»ã€‚CrAgentiveé‡‡ç”¨ä¸‰é˜¶æ®µä»£ç†å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æ„å»ºç”¨æˆ·æŒ‡å®šçš„å™äº‹éª¨æ¶çš„åˆå§‹åŒ–é˜¶æ®µï¼›é•¿çŸ­æœŸç›®æ ‡æŒ‡å¯¼å¤šä»£ç†å¯¹è¯ä»¥å®ä¾‹åŒ–æ•…äº‹åŸå‹çš„ç”Ÿæˆé˜¶æ®µï¼›ä»¥åŠåˆ©ç”¨æ­¤åŸå‹äº§ç”Ÿå…·æœ‰è¯¸å¦‚åæ€å’Œé¢„ç¤ºç­‰é«˜çº§ç»“æ„çš„å¤šæµæ´¾æ–‡æœ¬çš„å†™ä½œé˜¶æ®µã€‚è¿™ç§æ¶æ„å‡å°‘äº†å­˜å‚¨å†—ä½™ï¼Œå¹¶å…‹æœäº†é•¿å½¢å¼ç”Ÿæˆçš„å…¸å‹ç“¶é¢ˆã€‚åœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒCrAgentiveä½¿ç”¨é€šç”¨éª¨å¹²æ¨¡å‹ä»¥ä½äºæ¯100ç« ä¸åˆ°ä¸€ç¾å…ƒçš„æˆæœ¬ç”Ÿæˆäº†æ•°åƒç« çš„æ–‡æœ¬å¹¶ä¿æŒç¨³å®šçš„å“è´¨ã€‚ä¸ºè¯„ä¼°æ€§èƒ½ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ä¸ªåŒ…å«åä¸ªå™äº‹æŒ‡æ ‡çš„äºŒç»´æ¡†æ¶æ¥è¡¡é‡æ–‡æœ¬çš„è´¨é‡å’Œé•¿åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCrAgentiveæŒç»­è¶…è¶Šå¼ºå¤§çš„åŸºçº¿æ¨¡å‹å¹¶åœ¨å¤šç§æµæ´¾ä¸­è¡¨ç°ç¨³å¥ï¼Œæ¥è¿‘äººç±»ä½œè€…æ’°å†™çš„å°è¯´è´¨é‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>CrAgentiveè§£å†³äº†å½“ä»£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ›æ„å†™ä½œé¢†åŸŸçš„å››å¤§æ ¸å¿ƒé—®é¢˜ï¼šæµæ´¾å¤šæ ·æ€§ã€è¾“å‡ºé•¿åº¦ã€å™äº‹è¿è´¯æ€§å’Œå¤æ‚ç»“æ„å»ºæ„èƒ½åŠ›ã€‚</li>
<li>é‡‡ç”¨æ•…äº‹åŸå‹ä½œä¸ºæ ¸å¿ƒï¼Œé€šè¿‡çŸ¥è¯†å›¾è°±å™äº‹è¡¨ç¤ºæ³•ï¼Œå°†æ•…äº‹é€»è¾‘ä¸é£æ ¼å®ç°åˆ†ç¦»ã€‚</li>
<li>é€šè¿‡ä¸‰é˜¶æ®µä»£ç†å·¥ä½œæµç¨‹ï¼Œå®ç°ç”¨æˆ·å™äº‹éª¨æ¶çš„æ„å»ºã€æ•…äº‹åŸå‹çš„å®ä¾‹åŒ–å’Œå¤šæµæ´¾æ–‡æœ¬çš„ç”Ÿæˆã€‚</li>
<li>æ¶æ„å‡å°‘äº†å­˜å‚¨å†—ä½™ï¼Œå¹¶èƒ½å…‹æœé•¿æ–‡æœ¬ç”Ÿæˆçš„å…¸å‹ç“¶é¢ˆã€‚</li>
<li>å®éªŒæ˜¾ç¤ºCrAgentiveèƒ½ä»¥è¾ƒä½çš„æˆæœ¬ç”Ÿæˆå¤§é‡ç« èŠ‚æ–‡æœ¬å¹¶ä¿æŒç¨³å®šå“è´¨ã€‚</li>
<li>CrAgentiveçš„æ€§èƒ½è¯„ä¼°é‡‡ç”¨åŒ…å«è´¨é‡å’Œé•¿åº¦çš„äºŒç»´æ¡†æ¶ï¼Œè¡¨ç°è¶…è¶ŠåŸºçº¿æ¨¡å‹å¹¶åœ¨å¤šç§æµæ´¾ä¸­ç¨³å¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26461">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5d88016b02a97da8c354ce345bb1b45e" align="middle">
<img src="https://picx.zhimg.com/v2-6c95fafcbda4086ea80cee5e6a942048" align="middle">
<img src="https://picx.zhimg.com/v2-b7d9cf4aa1a514202322f34baf4276ef" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="PANDA-Towards-Generalist-Video-Anomaly-Detection-via-Agentic-AI-Engineer"><a href="#PANDA-Towards-Generalist-Video-Anomaly-Detection-via-Agentic-AI-Engineer" class="headerlink" title="PANDA: Towards Generalist Video Anomaly Detection via Agentic AI   Engineer"></a>PANDA: Towards Generalist Video Anomaly Detection via Agentic AI   Engineer</h2><p><strong>Authors:Zhiwei Yang, Chen Gao, Mike Zheng Shou</strong></p>
<p>Video anomaly detection (VAD) is a critical yet challenging task due to the complex and diverse nature of real-world scenarios. Previous methods typically rely on domain-specific training data and manual adjustments when applying to new scenarios and unseen anomaly types, suffering from high labor costs and limited generalization. Therefore, we aim to achieve generalist VAD, i.e., automatically handle any scene and any anomaly types without training data or human involvement. In this work, we propose PANDA, an agentic AI engineer based on MLLMs. Specifically, we achieve PANDA by comprehensively devising four key capabilities: (1) self-adaptive scene-aware strategy planning, (2) goal-driven heuristic reasoning, (3) tool-augmented self-reflection, and (4) self-improving chain-of-memory. Concretely, we develop a self-adaptive scene-aware RAG mechanism, enabling PANDA to retrieve anomaly-specific knowledge for anomaly detection strategy planning. Next, we introduce a latent anomaly-guided heuristic prompt strategy to enhance reasoning precision. Furthermore, PANDA employs a progressive reflection mechanism alongside a suite of context-aware tools to iteratively refine decision-making in complex scenarios. Finally, a chain-of-memory mechanism enables PANDA to leverage historical experiences for continual performance improvement. Extensive experiments demonstrate that PANDA achieves state-of-the-art performance in multi-scenario, open-set, and complex scenario settings without training and manual involvement, validating its generalizable and robust anomaly detection capability. Code is released at <a target="_blank" rel="noopener" href="https://github.com/showlab/PANDA">https://github.com/showlab/PANDA</a>. </p>
<blockquote>
<p>è§†é¢‘å¼‚å¸¸æ£€æµ‹ï¼ˆVADï¼‰æ˜¯ä¸€é¡¹è‡³å…³é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºç°å®ä¸–ç•Œçš„åœºæ™¯å¤æ‚å¤šå˜ã€‚ä»¥å‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºç‰¹å®šé¢†åŸŸçš„è®­ç»ƒæ•°æ®å’Œåœ¨åº”ç”¨åˆ°æ–°åœºæ™¯å’Œæœªè§å¼‚å¸¸ç±»å‹æ—¶çš„æ‰‹åŠ¨è°ƒæ•´ï¼Œå¯¼è‡´åŠ³åŠ¨æˆæœ¬é«˜æ˜‚å’Œæœ‰é™çš„æ³›åŒ–èƒ½åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å®ç°é€šç”¨VADï¼Œå³èƒ½å¤Ÿè‡ªåŠ¨å¤„ç†ä»»ä½•åœºæ™¯å’Œä»»ä½•å¼‚å¸¸ç±»å‹ï¼Œæ— éœ€è®­ç»ƒæ•°æ®æˆ–äººå·¥å‚ä¸ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºMLLMsçš„PANDAæ™ºèƒ½ä½“AIå·¥ç¨‹å¸ˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡å…¨é¢è®¾è®¡å››ä¸ªæ ¸å¿ƒèƒ½åŠ›æ¥å®ç°PANDAï¼šï¼ˆ1ï¼‰è‡ªé€‚åº”åœºæ™¯æ„ŸçŸ¥ç­–ç•¥è§„åˆ’ï¼Œï¼ˆ2ï¼‰ç›®æ ‡é©±åŠ¨å¯å‘å¼æ¨ç†ï¼Œï¼ˆ3ï¼‰å·¥å…·å¢å¼ºè‡ªæˆ‘åæ€ï¼Œä»¥åŠï¼ˆ4ï¼‰è‡ªæˆ‘æ”¹è¿›çš„è®°å¿†é“¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è‡ªé€‚åº”åœºæ™¯æ„ŸçŸ¥çš„RAGæœºåˆ¶ï¼Œä½¿PANDAèƒ½å¤Ÿä¸ºå¼‚å¸¸æ£€æµ‹ç­–ç•¥è§„åˆ’æ£€ç´¢ç‰¹å®šå¼‚å¸¸çš„çŸ¥è¯†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ½œåœ¨å¼‚å¸¸å¼•å¯¼çš„å¯å‘å¼æç¤ºç­–ç•¥ï¼Œä»¥æé«˜æ¨ç†ç²¾åº¦ã€‚æ­¤å¤–ï¼ŒPANDAé‡‡ç”¨äº†ä¸€ç§æ¸è¿›çš„åæ€æœºåˆ¶å’Œä¸€ç³»åˆ—ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·ï¼Œä»¥è¿­ä»£ä¼˜åŒ–å¤æ‚åœºæ™¯ä¸­çš„å†³ç­–åˆ¶å®šã€‚æœ€åï¼Œè®°å¿†é“¾æœºåˆ¶ä½¿PANDAèƒ½å¤Ÿåˆ©ç”¨å†å²ç»éªŒä¸æ–­æ”¹å–„æ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPANDAåœ¨æ— è®­ç»ƒå’Œäººå·¥å‚ä¸çš„å¤šåœºæ™¯ã€å¼€æ”¾é›†å’Œå¤æ‚åœºæ™¯è®¾ç½®ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æ³›åŒ–å’Œé²æ£’çš„å¼‚å¸¸æ£€æµ‹èƒ½åŠ›ã€‚ä»£ç å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/showlab/PANDA%E3%80%82">https://github.com/showlab/PANDAã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26386v1">PDF</a> Accepted by NeurIPS 2025</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¤šæ¨¡æ€è½»é‡çº§æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ™ºèƒ½ä»£ç†PANDAï¼Œæ—¨åœ¨å®ç°æ— éœ€è®­ç»ƒæ•°æ®å’Œäººå·¥å‚ä¸çš„é€šç”¨è§†é¢‘å¼‚å¸¸æ£€æµ‹ï¼ˆVADï¼‰ã€‚PANDAé€šè¿‡å››ä¸ªå…³é”®èƒ½åŠ›å®ç°è‡ªæˆ‘é€‚åº”çš„åœºæ™¯æ„ŸçŸ¥ç­–ç•¥è§„åˆ’ã€ç›®æ ‡é©±åŠ¨å¯å‘å¼æ¨ç†ã€å·¥å…·è¾…åŠ©çš„è‡ªæˆ‘åæ€ä»¥åŠè‡ªæˆ‘æå‡çš„è®°å¿†é“¾ã€‚å®éªŒè¡¨æ˜ï¼ŒPANDAåœ¨å¤šåœºæ™¯ã€å¼€æ”¾é›†å’Œå¤æ‚åœºæ™¯è®¾ç½®ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶é€šç”¨æ€§å’Œé²æ£’æ€§çš„å¼‚å¸¸æ£€æµ‹èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†é¢‘å¼‚å¸¸æ£€æµ‹ï¼ˆVADï¼‰æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§å’Œå®é™…æ„ä¹‰çš„ç ”ç©¶é¢†åŸŸï¼Œç”±äºç°å®åœºæ™¯çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚</li>
<li>æ­¤å‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºç‰¹å®šé¢†åŸŸçš„è®­ç»ƒæ•°æ®å’Œæ‰‹åŠ¨è°ƒæ•´ï¼Œåœ¨æ–°åœºæ™¯å’Œæœªè§å¼‚å¸¸ç±»å‹ä¸­çš„åº”ç”¨å­˜åœ¨é«˜åŠ³åŠ¨æˆæœ¬æœ‰é™æ³›åŒ–èƒ½åŠ›çš„é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨å®ç°é€šç”¨VADï¼Œå³æ— éœ€è®­ç»ƒæ•°æ®æˆ–äººå·¥å‚ä¸å³å¯è‡ªåŠ¨å¤„ç†ä»»ä½•åœºæ™¯å’Œä»»ä½•å¼‚å¸¸ç±»å‹ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºå¤šæ¨¡æ€è½»é‡çº§æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ™ºèƒ½ä»£ç†PANDAï¼Œé€šè¿‡å››ä¸ªå…³é”®èƒ½åŠ›å®ç°ï¼šè‡ªæˆ‘é€‚åº”çš„åœºæ™¯æ„ŸçŸ¥ç­–ç•¥è§„åˆ’ã€ç›®æ ‡é©±åŠ¨å¯å‘å¼æ¨ç†ã€å·¥å…·è¾…åŠ©çš„è‡ªæˆ‘åæ€ä»¥åŠè‡ªæˆ‘æå‡çš„è®°å¿†é“¾ã€‚</li>
<li>PANDAé‡‡ç”¨è‡ªé€‚åº”åœºæ™¯æ„ŸçŸ¥RAGæœºåˆ¶ï¼Œèƒ½å¤Ÿæ£€ç´¢å¼‚å¸¸ç‰¹å®šçš„çŸ¥è¯†æ¥è§„åˆ’å¼‚å¸¸æ£€æµ‹ç­–ç•¥ã€‚</li>
<li>PANDAé€šè¿‡æ½œåœ¨å¼‚å¸¸å¼•å¯¼çš„å¯å‘å¼æç¤ºç­–ç•¥æé«˜æ¨ç†ç²¾åº¦ï¼Œå¹¶é‡‡ç”¨æ¸è¿›åå°„æœºåˆ¶å’Œä¸€ç³»åˆ—ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·æ¥è¿­ä»£ä¼˜åŒ–å¤æ‚åœºæ™¯ä¸­çš„å†³ç­–åˆ¶å®šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26386">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e5c913ea160321a6ffbb68811fc17658" align="middle">
<img src="https://picx.zhimg.com/v2-c7e4ce2c190418732eaa95c6d856dff8" align="middle">
<img src="https://picx.zhimg.com/v2-2dadee9bff968fce804291ef1d447592" align="middle">
<img src="https://picx.zhimg.com/v2-37e2b8696adecfbe9720eafc174535b0" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Efficient-and-Transferable-Agentic-Knowledge-Graph-RAG-via-Reinforcement-Learning"><a href="#Efficient-and-Transferable-Agentic-Knowledge-Graph-RAG-via-Reinforcement-Learning" class="headerlink" title="Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement   Learning"></a>Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement   Learning</h2><p><strong>Authors:Jinyeop Song, Song Wang, Julian Shun, Yada Zhu</strong></p>
<p>Knowledge-graph retrieval-augmented generation (KG-RAG) couples large language models (LLMs) with structured, verifiable knowledge graphs (KGs) to reduce hallucinations and expose reasoning traces. However, many KG-RAG systems compose multiple LLM modules (e.g planning, reasoning, and responding), inflating inference cost and binding behavior to a specific target KG. To address this, we introduce KG-R1, an agentic KG retrieval-augmented generation (KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single agent that interacts with KGs as its environment, learning to retrieve at each step and incorporating the retrieved information into its reasoning and generation. The process is optimized through end-to-end RL. In controlled experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our method demonstrates both efficiency and transferability: Using Qwen-2.5-3B, KG-R1 improves answer accuracy with fewer generation tokens than prior multi-module workflow methods that use larger foundation or fine-tuned models. Furthermore, KG-R1 enables plug and play: after training, it maintains strong accuracy on new KGs without modification. These properties make KG-R1 a promising KG-RAG framework for real-world deployment. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/Jinyeop3110/KG-R1">https://github.com/Jinyeop3110/KG-R1</a>. </p>
<blockquote>
<p>çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ç»“æ„åŒ–çš„ã€å¯éªŒè¯çš„çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰ç›¸ç»“åˆï¼Œä»¥å‡å°‘å¹»è§‰å¹¶æš´éœ²æ¨ç†ç—•è¿¹ã€‚ç„¶è€Œï¼Œè®¸å¤šKG-RAGç³»ç»Ÿç”±å¤šä¸ªLLMæ¨¡å—ç»„æˆï¼ˆä¾‹å¦‚è§„åˆ’ã€æ¨ç†å’Œå“åº”ï¼‰ï¼Œå¢åŠ äº†æ¨ç†æˆæœ¬ï¼Œå¹¶ä¸”ä½¿è¡Œä¸ºç»‘å®šåˆ°ç‰¹å®šçš„ç›®æ ‡çŸ¥è¯†å›¾è°±ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†KG-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å®ç°çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰æ¡†æ¶ã€‚KG-R1åˆ©ç”¨å•ä¸ªæ™ºèƒ½ä½“ä¸å…¶ç¯å¢ƒï¼ˆçŸ¥è¯†å›¾è°±ï¼‰è¿›è¡Œäº¤äº’ï¼Œå­¦ä¹ åœ¨æ¯ä¸€æ­¥è¿›è¡Œæ£€ç´¢ï¼Œå¹¶å°†æ£€ç´¢åˆ°çš„ä¿¡æ¯èå…¥å…¶æ¨ç†å’Œç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚è¯¥è¿‡ç¨‹é€šè¿‡ç«¯åˆ°ç«¯çš„RLè¿›è¡Œä¼˜åŒ–ã€‚åœ¨çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰åŸºå‡†æµ‹è¯•ä¸Šçš„å—æ§å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ—¢æœ‰æ•ˆç‡ä¹Ÿæœ‰è¿ç§»æ€§ï¼šä½¿ç”¨Qwen-2.5-3Bï¼ŒKG-R1åœ¨æé«˜ç­”æ¡ˆå‡†ç¡®æ€§çš„åŒæ—¶ï¼Œç”Ÿæˆçš„æ ‡è®°ç¬¦å·å°‘äºä½¿ç”¨æ›´å¤§åŸºç¡€æˆ–å¾®è°ƒæ¨¡å‹çš„å¤šæ¨¡å—å·¥ä½œæµç¨‹æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒKG-R1å®ç°äº†å³æ’å³ç”¨ï¼šè®­ç»ƒåï¼Œå®ƒåœ¨æ–°çš„çŸ¥è¯†å›¾è°±ä¸Šæ— éœ€ä¿®æ”¹å°±èƒ½ä¿æŒé«˜å‡†ç¡®æ€§ã€‚è¿™äº›ç‰¹æ€§ä½¿KG-R1æˆä¸ºç°å®ä¸–ç•Œéƒ¨ç½²ä¸­å‰æ™¯å¹¿é˜”çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/Jinyeop3110/KG-R1">https://github.com/Jinyeop3110/KG-R1</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26383v1">PDF</a> 10 pages, 5 figures. Submitted to ICLR 2026</p>
<p><strong>Summary</strong></p>
<p>KG-R1æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰æ¡†æ¶ã€‚å®ƒä½¿ç”¨ä¸€ä¸ªå•ä¸€æ™ºèƒ½ä½“ä¸ç¯å¢ƒï¼ˆçŸ¥è¯†å›¾è°±ï¼‰è¿›è¡Œäº¤äº’ï¼Œå­¦ä¹ åœ¨æ¯ä¸€æ­¥è¿›è¡Œæ£€ç´¢ï¼Œå¹¶å°†æ£€ç´¢åˆ°çš„ä¿¡æ¯èå…¥å…¶æ¨ç†å’Œç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚KG-R1è§£å†³äº†ä¼ ç»ŸKG-RAGç³»ç»Ÿå­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚æ¨ç†æ¨¡å—è¿‡å¤šã€æ¨ç†æˆæœ¬é«˜æ˜‚ä»¥åŠè¡Œä¸ºç‰¹å®šäºç›®æ ‡çŸ¥è¯†å›¾è°±çš„æŸç¼šã€‚å®éªŒè¯æ˜ï¼ŒKG-R1åœ¨çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰åŸºå‡†æµ‹è¯•ä¸­å…·æœ‰è¾ƒé«˜çš„æ•ˆç‡å’Œå¯ç§»æ¤æ€§ï¼Œå¯åœ¨ä¸ä½¿ç”¨å¤§å‹åŸºç¡€æ¨¡å‹æˆ–ç²¾ç»†è°ƒæ•´æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œæé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§å¹¶å‡å°‘ç”Ÿæˆæ ‡è®°ã€‚æ­¤å¤–ï¼ŒKG-R1è¿˜å…·å¤‡â€œå³æ’å³ç”¨â€çš„ç‰¹æ€§ï¼Œåœ¨è®­ç»ƒåèƒ½å¤Ÿåœ¨æ–°çŸ¥è¯†å›¾è°±ä¸Šä¿æŒé«˜ç²¾ç¡®åº¦è€Œæ— éœ€è¿›è¡Œä¿®æ”¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KG-R1ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’ŒçŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ï¼Œä»¥å‡å°‘å¹»æƒ³å¹¶æš´éœ²æ¨ç†è½¨è¿¹ã€‚</li>
<li>ä¼ ç»ŸKG-RAGç³»ç»Ÿå­˜åœ¨æ¨¡å—è¿‡å¤šã€æ¨ç†æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚</li>
<li>KG-R1é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å®ç°å•ä¸€æ™ºèƒ½ä½“ä¸çŸ¥è¯†å›¾è°±çš„äº¤äº’ï¼Œç®€åŒ–äº†æµç¨‹å¹¶æé«˜äº†æ•ˆç‡ã€‚</li>
<li>KG-R1åœ¨çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæé«˜äº†ç­”æ¡ˆå‡†ç¡®æ€§å¹¶å‡å°‘äº†ç”Ÿæˆæ ‡è®°ã€‚</li>
<li>KG-R1å…·å¤‡â€œå³æ’å³ç”¨â€ç‰¹æ€§ï¼Œå¯é€‚åº”ä¸åŒçš„çŸ¥è¯†å›¾è°±è€Œæ— éœ€ä¿®æ”¹ã€‚</li>
<li>KG-R1ä¼˜åŒ–äº†çŸ¥è¯†å›¾è°±æ£€ç´¢è¿‡ç¨‹ï¼Œä½¿å…¶æ›´åŠ é«˜æ•ˆä¸”é€‚åº”æ€§å¼ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26383">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-46103d3b48b9feb5aaecbe0cdd64b115" align="middle">
<img src="https://picx.zhimg.com/v2-a57f2b36b5b6aa52b3aaa3dcce5bb2a1" align="middle">
<img src="https://picx.zhimg.com/v2-10ddfae4d76a7f98708a0cce9cae8d66" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Your-Agent-May-Misevolve-Emergent-Risks-in-Self-evolving-LLM-Agents"><a href="#Your-Agent-May-Misevolve-Emergent-Risks-in-Self-evolving-LLM-Agents" class="headerlink" title="Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents"></a>Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents</h2><p><strong>Authors:Shuai Shao, Qihan Ren, Chen Qian, Boyi Wei, Dadi Guo, Jingyi Yang, Xinhao Song, Linfeng Zhang, Weinan Zhang, Dongrui Liu, Jing Shao</strong></p>
<p>Advances in Large Language Models (LLMs) have enabled a new class of self-evolving agents that autonomously improve through interaction with the environment, demonstrating strong capabilities. However, self-evolution also introduces novel risks overlooked by current safety research. In this work, we study the case where an agentâ€™s self-evolution deviates in unintended ways, leading to undesirable or even harmful outcomes. We refer to this as Misevolution. To provide a systematic investigation, we evaluate misevolution along four key evolutionary pathways: model, memory, tool, and workflow. Our empirical findings reveal that misevolution is a widespread risk, affecting agents built even on top-tier LLMs (e.g., Gemini-2.5-Pro). Different emergent risks are observed in the self-evolutionary process, such as the degradation of safety alignment after memory accumulation, or the unintended introduction of vulnerabilities in tool creation and reuse. To our knowledge, this is the first study to systematically conceptualize misevolution and provide empirical evidence of its occurrence, highlighting an urgent need for new safety paradigms for self-evolving agents. Finally, we discuss potential mitigation strategies to inspire further research on building safer and more trustworthy self-evolving agents. Our code and data are available at <a target="_blank" rel="noopener" href="https://github.com/ShaoShuai0605/Misevolution">https://github.com/ShaoShuai0605/Misevolution</a> . Warning: this paper includes examples that may be offensive or harmful in nature. </p>
<blockquote>
<p>è‡ªç„¶è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å‚¬ç”Ÿäº†ä¸€ç§æ–°å‹çš„è‡ªè¿›åŒ–æ™ºèƒ½ä½“ï¼Œå®ƒä»¬èƒ½å¤Ÿé€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨è‡ªä¸»æ”¹è¿›ï¼Œå±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè‡ªæˆ‘è¿›åŒ–ä¹Ÿå¸¦æ¥äº†å½“å‰å®‰å…¨ç ”ç©¶å°šæœªå…³æ³¨çš„æ–°å‹é£é™©ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ™ºèƒ½ä½“è‡ªæˆ‘è¿›åŒ–å‡ºç°æ„å¤–åç¦»çš„æƒ…å†µï¼Œå¯¼è‡´å‡ºç°ä¸è‰¯ç”šè‡³æœ‰å®³çš„ç»“æœã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œåŠ£åŒ–è¿›åŒ–â€ï¼ˆMisevolutionï¼‰ã€‚ä¸ºäº†è¿›è¡Œç³»ç»Ÿçš„ç ”ç©¶ï¼Œæˆ‘ä»¬ä»æ¨¡å‹ã€è®°å¿†ã€å·¥å…·å’Œå·¥ä½œæµç¨‹å››ä¸ªæ–¹é¢å¯¹åŠ£åŒ–è¿›åŒ–è¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„å®è¯ç ”ç©¶å‘ç°ï¼ŒåŠ£åŒ–è¿›åŒ–æ˜¯ä¸€ç§å¹¿æ³›å­˜åœ¨çš„é£é™©ï¼Œç”šè‡³å½±å“é¡¶å°–çš„è‡ªç„¶è¯­è¨€æ¨¡å‹æ„å»ºçš„æ™ºèƒ½ä½“ï¼ˆä¾‹å¦‚Gemini-2.5-Proï¼‰ã€‚åœ¨è‡ªæˆ‘è¿›åŒ–çš„è¿‡ç¨‹ä¸­è§‚å¯Ÿåˆ°ä¸åŒçš„æ–°å…´é£é™©ï¼Œå¦‚è®°å¿†ç§¯ç´¯åå®‰å…¨å¯¹é½çš„é€€åŒ–ï¼Œæˆ–åœ¨å·¥å…·å’Œé‡ç”¨çš„åˆ›å»ºè¿‡ç¨‹ä¸­æ„å¤–å¼•å…¥çš„æ¼æ´ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡ç³»ç»Ÿåœ°æå‡ºå¹¶å®è¯äº†åŠ£åŒ–è¿›åŒ–çš„æ¦‚å¿µåŠå…¶å­˜åœ¨ï¼Œçªæ˜¾å‡ºè‡ªè¿›åŒ–æ™ºèƒ½ä½“å¯¹æ–°å‹å®‰å…¨èŒƒå¼çš„è¿«åˆ‡éœ€æ±‚ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†æ½œåœ¨çš„ç¼“è§£ç­–ç•¥ï¼Œä»¥æ¿€å‘å…³äºæ„å»ºæ›´å®‰å…¨ã€æ›´å¯é çš„è‡ªæˆ‘è¿›åŒ–æ™ºèƒ½ä½“çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/ShaoShuai0605/Misevolution">https://github.com/ShaoShuai0605/Misevolution</a> ä¸­æ‰¾åˆ°ã€‚è­¦å‘Šï¼šæœ¬æ–‡åŒ…å«å¯èƒ½å…·æœ‰å†’çŠ¯æ€§æˆ–æœ‰å®³æ€§è´¨çš„ç¤ºä¾‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26354v1">PDF</a> Preprint. Under Review</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å‚¬ç”Ÿäº†ä¸€ç§æ–°å‹çš„è‡ªè¿›åŒ–ä»£ç†ï¼Œå®ƒä»¬é€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨å®ç°è‡ªä¸»æ”¹è¿›ï¼Œå±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè‡ªè¿›åŒ–ä¹Ÿå¸¦æ¥äº†æ–°çš„é£é™©ï¼Œè¢«å½“å‰çš„å®‰å…¨ç ”ç©¶æ‰€å¿½è§†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†ä»£ç†è‡ªè¿›åŒ–äº§ç”Ÿéé¢„æœŸç»“æœçš„æƒ…å†µï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œä¸è‰¯è¿›åŒ–â€ï¼ˆMisevolutionï¼‰ã€‚ä¸ºäº†ç³»ç»Ÿåœ°ç ”ç©¶è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ²¿ç€æ¨¡å‹ã€è®°å¿†ã€å·¥å…·å’Œå·¥ä½œæµç¨‹å››æ¡å…³é”®è¿›åŒ–è·¯å¾„å¯¹ä¸è‰¯è¿›åŒ–è¿›è¡Œäº†è¯„ä¼°ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œä¸è‰¯è¿›åŒ–æ˜¯ä¸€ç§å¹¿æ³›å­˜åœ¨çš„é£é™©ï¼Œç”šè‡³å½±å“é¡¶å°–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚Gemini-2.5-Proï¼‰ã€‚åœ¨è‡ªè¿›åŒ–è¿‡ç¨‹ä¸­è§‚å¯Ÿåˆ°å¤šç§æ–°å…´é£é™©ï¼Œä¾‹å¦‚è®°å¿†ç§¯ç´¯åå®‰å…¨æ€§çš„å¯¹é½ç¨‹åº¦ä¸‹é™ï¼Œä»¥åŠå·¥å…·åˆ›å»ºå’Œå†åˆ©ç”¨è¿‡ç¨‹ä¸­æ„å¤–å¼•å…¥çš„è„†å¼±æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªç³»ç»Ÿåœ°æ¦‚å¿µåŒ–ä¸è‰¯è¿›åŒ–å¹¶æä¾›å®è¯è¯æ®çš„ç ”ç©¶ï¼Œçªæ˜¾äº†ä¸ºè‡ªè¿›åŒ–ä»£ç†å¼€å‘æ–°çš„å®‰å…¨èŒƒå¼ç´§è¿«æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†ç¼“è§£ç­–ç•¥ä»¥æ¿€å‘æ›´å®‰å…¨ã€æ›´å¯é çš„è‡ªè¿›åŒ–ä»£ç†çš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ä½¿å¾—è‡ªè¿›åŒ–ä»£ç†å…·å¤‡å¼ºå¤§çš„èƒ½åŠ›ï¼Œå¹¶èƒ½é€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨è‡ªä¸»æ”¹è¿›ã€‚</li>
<li>è‡ªè¿›åŒ–ä»£ç†å­˜åœ¨ä¸è‰¯è¿›åŒ–çš„é£é™©ï¼Œå¯èƒ½å¯¼è‡´éé¢„æœŸå’Œä¸å¸Œæœ›çš„ç»“æœã€‚</li>
<li>ä¸è‰¯è¿›åŒ–å½±å“é¡¶å°–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬åœ¨æ¨¡å‹ã€è®°å¿†ã€å·¥å…·å’Œå·¥ä½œæµç¨‹æ–¹é¢çš„å…³é”®è¿›åŒ–è·¯å¾„ä¸Šã€‚</li>
<li>åœ¨è‡ªè¿›åŒ–è¿‡ç¨‹ä¸­è§‚å¯Ÿåˆ°å¤šç§æ–°å…´é£é™©ï¼Œå¦‚å®‰å…¨æ€§å’Œè„†å¼±æ€§é—®é¢˜ã€‚</li>
<li>å½“å‰ç ”ç©¶æ˜¯é¦–ä¸ªç³»ç»Ÿåœ°æ¦‚å¿µåŒ–ä¸è‰¯è¿›åŒ–å¹¶æä¾›å®è¯è¯æ®çš„ç ”ç©¶ã€‚</li>
<li>éœ€è¦æ–°çš„å®‰å…¨èŒƒå¼æ¥åº”å¯¹è‡ªè¿›åŒ–ä»£ç†çš„ä¸è‰¯è¿›åŒ–é£é™©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26354">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-15f1db6efe8c26132f8e2c310e8e4a7a" align="middle">
<img src="https://picx.zhimg.com/v2-8a23769b912597b05a481118219abe11" align="middle">
<img src="https://picx.zhimg.com/v2-f2a748d3e442a2af8d49db81f56ae2b7" align="middle">
<img src="https://picx.zhimg.com/v2-769258aabcdb96ba2b0ce56d2b9f9bf6" align="middle">
<img src="https://picx.zhimg.com/v2-5f14d1657e6f32a609f651ea07e28008" align="middle">
<img src="https://picx.zhimg.com/v2-e4052449bee7a04d11dc9f89573ea6f5" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="LLM-Agents-for-Knowledge-Discovery-in-Atomic-Layer-Processing"><a href="#LLM-Agents-for-Knowledge-Discovery-in-Atomic-Layer-Processing" class="headerlink" title="LLM Agents for Knowledge Discovery in Atomic Layer Processing"></a>LLM Agents for Knowledge Discovery in Atomic Layer Processing</h2><p><strong>Authors:Andreas Werbrouck, Marshall B. Lindsay, Matthew Maschmann, Matthias J. Young</strong></p>
<p>Large Language Models (LLMs) have garnered significant attention for several years now. Recently, their use as independently reasoning agents has been proposed. In this work, we test the potential of such agents for knowledge discovery in materials science. We repurpose LangGraphâ€™s tool functionality to supply agents with a black box function to interrogate. In contrast to process optimization or performing specific, user-defined tasks, knowledge discovery consists of freely exploring the system, posing and verifying statements about the behavior of this black box, with the sole objective of generating and verifying generalizable statements. We provide proof of concept for this approach through a childrenâ€™s parlor game, demonstrating the role of trial-and-error and persistence in knowledge discovery, and the strong path-dependence of results. We then apply the same strategy to show that LLM agents can explore, discover, and exploit diverse chemical interactions in an advanced Atomic Layer Processing reactor simulation using intentionally limited probe capabilities without explicit instructions. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»å¼•èµ·äº†äººä»¬å¤šå¹´çš„å…³æ³¨ã€‚æœ€è¿‘ï¼Œæœ‰äººæå‡ºäº†å°†å…¶ç”¨ä½œç‹¬ç«‹æ¨ç†ä»£ç†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æµ‹è¯•äº†æ­¤ç±»ä»£ç†åœ¨ææ–™ç§‘å­¦ä¸­å‘ç°çŸ¥è¯†çš„æ½œåŠ›ã€‚æˆ‘ä»¬é‡æ–°åˆ©ç”¨LangGraphçš„å·¥å…·åŠŸèƒ½ï¼Œä¸ºä»£ç†æä¾›ä¸€ä¸ªé»‘ç®±å‡½æ•°è¿›è¡Œè¯¢é—®ã€‚ä¸æµç¨‹ä¼˜åŒ–æˆ–æ‰§è¡Œç‰¹å®šã€ç”¨æˆ·å®šä¹‰çš„ä»»åŠ¡ä¸åŒï¼ŒçŸ¥è¯†å‘ç°åŒ…æ‹¬è‡ªç”±æ¢ç´¢ç³»ç»Ÿï¼Œæå‡ºå¹¶éªŒè¯æœ‰å…³é»‘ç®±è¡Œä¸ºçš„é™ˆè¿°ï¼Œä»¥ç”Ÿæˆå’ŒéªŒè¯å¯æ¨å¹¿çš„é™ˆè¿°ä¸ºå”¯ä¸€ç›®æ ‡ã€‚æˆ‘ä»¬é€šè¿‡å„¿ç«¥æ¸¸ä¹æ¸¸æˆè¯æ˜äº†è¿™ç§æ–¹æ³•çš„æ¦‚å¿µï¼Œå±•ç¤ºäº†åœ¨çŸ¥è¯†å‘ç°ä¸­å°è¯•å’Œé”™è¯¯çš„é‡è¦æ€§ã€æ¯…åŠ›çš„ä½œç”¨ä»¥åŠç»“æœçš„å¼ºçƒˆè·¯å¾„ä¾èµ–æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬åº”ç”¨ç›¸åŒçš„ç­–ç•¥æ¥å±•ç¤ºLLMä»£ç†èƒ½å¤Ÿåœ¨å…ˆè¿›çš„åŸå­å±‚å¤„ç†ååº”å™¨æ¨¡æ‹Ÿä¸­æ¢ç´¢ã€å‘ç°å’Œåˆ©ç”¨å„ç§åŒ–å­¦ç›¸äº’ä½œç”¨ï¼Œå³ä½¿ä½¿ç”¨æœ‰æ„é™åˆ¶çš„æ¢æµ‹èƒ½åŠ›ä¸”æ²¡æœ‰æ˜ç¡®çš„æŒ‡ä»¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26201v1">PDF</a> Accepted submission to the AI4MAT workshop@NEURIPS 2025. As   submitted, except author names added</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿‘å¹´å¤‡å—ç©ç›®ï¼Œæœ€è¿‘äººä»¬æå‡ºå°†å…¶ç”¨ä½œç‹¬ç«‹æ¨ç†çš„ä»£ç†ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æµ‹è¯•æ­¤ç±»ä»£ç†åœ¨ææ–™ç§‘å­¦é¢†åŸŸçŸ¥è¯†å‘ç°çš„æ½œåŠ›ã€‚ç ”ç©¶ä½¿ç”¨LangGraphçš„å·¥å…·åŠŸèƒ½ï¼Œä¸ºä»£ç†æä¾›é»‘ç®±å‡½æ•°ä»¥è¿›è¡Œäº¤äº’ã€‚ä¸è¿‡ç¨‹ä¼˜åŒ–æˆ–æ‰§è¡Œç‰¹å®šçš„ç”¨æˆ·å®šä¹‰ä»»åŠ¡ä¸åŒï¼ŒçŸ¥è¯†å‘ç°æ˜¯å¯¹ç³»ç»Ÿè¿›è¡Œè‡ªç”±æ¢ç´¢ï¼Œå¯¹é»‘ç®±çš„è¡Œä¸ºæå‡ºå’ŒéªŒè¯é™ˆè¿°ï¼Œä»¥ç”Ÿæˆå’ŒéªŒè¯å¯æ¦‚æ‹¬çš„é™ˆè¿°ä¸ºä¸»è¦ç›®æ ‡ã€‚æœ¬ç ”ç©¶é€šè¿‡å„¿ç«¥æ¸¸æˆè¯æ˜äº†è¯¥æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œå±•ç¤ºäº†çŸ¥è¯†å‘ç°ä¸­å°è¯•å’Œé”™è¯¯çš„é‡è¦æ€§ã€æŒä¹…æ€§ä»¥åŠç»“æœçš„å¼ºçƒˆè·¯å¾„ä¾èµ–æ€§ã€‚éšåï¼Œç ”ç©¶åº”ç”¨ç›¸åŒçš„ç­–ç•¥å±•ç¤ºäº†LLMä»£ç†åœ¨å…ˆè¿›çš„åŸå­å±‚å¤„ç†ååº”å™¨æ¨¡æ‹Ÿä¸­æ¢ç´¢ã€å‘ç°å’Œåˆ©ç”¨å„ç§åŒ–å­¦äº¤äº’çš„èƒ½åŠ›ï¼Œå³ä½¿ä½¿ç”¨äº†æœ‰é™çš„æ¢æµ‹èƒ½åŠ›ä¸”æ— æ˜ç¡®çš„æŒ‡ä»¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºç‹¬ç«‹æ¨ç†ä»£ç†åœ¨çŸ¥è¯†å‘ç°é¢†åŸŸå…·æœ‰æ½œåŠ›ã€‚</li>
<li>ä½¿ç”¨LangGraphå·¥å…·åŠŸèƒ½ä¸ºä»£ç†æä¾›é»‘ç®±å‡½æ•°è¿›è¡Œäº¤äº’æµ‹è¯•ã€‚</li>
<li>çŸ¥è¯†å‘ç°ä¸åŒäºä»»åŠ¡ä¼˜åŒ–æˆ–ç‰¹å®šç”¨æˆ·ä»»åŠ¡ï¼Œæ—¨åœ¨è‡ªç”±æ¢ç´¢ç³»ç»Ÿå¹¶ç”Ÿæˆå¯æ¦‚æ‹¬çš„é™ˆè¿°ã€‚</li>
<li>é€šè¿‡å„¿ç«¥æ¸¸æˆè¯æ˜äº†çŸ¥è¯†å‘ç°æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œå¼ºè°ƒäº†å°è¯•å’Œé”™è¯¯çš„é‡è¦æ€§ä»¥åŠç»“æœçš„è·¯å¾„ä¾èµ–æ€§ã€‚</li>
<li>LLMä»£ç†èƒ½å¤Ÿåœ¨å¤æ‚çš„åŒ–å­¦äº¤äº’ç¯å¢ƒä¸­è¿›è¡Œæ¢ç´¢ã€å‘ç°å’Œåˆ©ç”¨ã€‚</li>
<li>å³ä½¿åœ¨æœ‰é™çš„æ¢æµ‹èƒ½åŠ›å’Œæ— æ˜ç¡®æŒ‡ä»¤çš„æƒ…å†µä¸‹ï¼ŒLLMä»£ç†ä»èƒ½å¤Ÿå±•ç°å…¶çŸ¥è¯†å‘ç°çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26201">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-472394b904e856ce8543589c1266fcf7" align="middle">
<img src="https://picx.zhimg.com/v2-bc3428163225de8d2b7cd8b739989501" align="middle">
<img src="https://picx.zhimg.com/v2-c0c98197a794b9c61e9ef805c21ca984" align="middle">
<img src="https://picx.zhimg.com/v2-726f5f396a9273d3270e777e7df9e6cd" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Toward-an-Unbiased-Collective-Memory-for-Efficient-LLM-Based-Agentic-6G-Cross-Domain-Management"><a href="#Toward-an-Unbiased-Collective-Memory-for-Efficient-LLM-Based-Agentic-6G-Cross-Domain-Management" class="headerlink" title="Toward an Unbiased Collective Memory for Efficient LLM-Based Agentic 6G   Cross-Domain Management"></a>Toward an Unbiased Collective Memory for Efficient LLM-Based Agentic 6G   Cross-Domain Management</h2><p><strong>Authors:Hatim Chergui, Miguel Catalan Cid, Pouria Sayyad Khodashenas, Daniel Camps Mur, Christos Verikoukis</strong></p>
<p>This paper introduces a novel framework for proactive cross-domain resource orchestration in 6G RAN-Edge networks, featuring large language model (LLM)-augmented agents. The system comprises specialized RAN (energy efficiency) and Edge (latency assurance) agents that engage in iterative negotiation, supported by advanced reasoning and planning capabilities. Agents dynamically interact with a digital twin (DT) to test their proposals and leverage a long-term collective memory where their joint successful and failed agreements along with the related network contexts are distilled into strategies to either follow or avoid and subsequently stored. Given that agents are subject to a plethora of cognitive distortions when retrieving those past experiences â€“ such as primacy, recency, confirmation and availability biases â€“ we propose in this work a novel unbiased memory design (A reusable mockup version of the unbiased memory source code is available for non-commercial use at <a target="_blank" rel="noopener" href="https://github.com/HatimChergui/unbiased-collective-memory">https://github.com/HatimChergui/unbiased-collective-memory</a>). featuring (i) semantic retrieval of past strategies via Jaccard similarity; (ii) learning from failures through amplified weighting of SLA violations and mandatory inclusion of failed negotiation cases to mitigate confirmation bias; (iii) diversity enforcement to minimize availability bias and (iv) recency and primacy weighting with slow decay to counteract temporal biases. Evaluation results showcase the impact of existing biases and how the unbiased memory allows to tackle them by learning from both successful and failed strategies, either present or old, resulting in $\times 4.5$ and $\times 3.5$ reductions of unresolved negotiations compared to non-memory and vanilla memory baselines, respectively, while totally mitigating SLA violations as well as improving latency and energy saving distributions. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äº6G RAN-Edgeç½‘ç»œä¸­ä¸»åŠ¨è·¨åŸŸèµ„æºç¼–æ’çš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…·æœ‰ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¢å¼ºçš„ä»£ç†ã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬ä¸“é—¨ä»äº‹èƒ½æºæ•ˆç‡ï¼ˆRANï¼‰å’Œå»¶è¿Ÿä¿è¯ï¼ˆè¾¹ç¼˜ï¼‰çš„ä»£ç†ï¼Œè¿™äº›ä»£ç†å‚ä¸è¿­ä»£åå•†ï¼Œå¹¶å¾—åˆ°å…ˆè¿›æ¨ç†å’Œè§„åˆ’èƒ½åŠ›çš„æ”¯æŒã€‚ä»£ç†ä¸æ•°å­—åŒèƒèƒï¼ˆDTï¼‰åŠ¨æ€äº¤äº’ä»¥æµ‹è¯•å…¶ææ¡ˆï¼Œå¹¶åˆ©ç”¨é•¿æœŸé›†ä½“è®°å¿†åŠŸèƒ½ï¼Œå°†ä»–ä»¬çš„è”åˆæˆåŠŸå’Œå¤±è´¥çš„åè®®ä»¥åŠç›¸å…³ç½‘ç»œä¸Šä¸‹æ–‡æç‚¼æˆè¦éµå¾ªæˆ–é¿å…çš„ç­–ç•¥ï¼Œç„¶åå­˜å‚¨èµ·æ¥ã€‚è€ƒè™‘åˆ°ä»£ç†åœ¨æ£€ç´¢è¿™äº›è¿‡å»ç»éªŒæ—¶ä¼šå—åˆ°å¤§é‡è®¤çŸ¥æ‰­æ›²çš„å½±å“ï¼Œä¾‹å¦‚é¦–å› æ•ˆåº”ã€è¿‘å› æ•ˆåº”ã€ç¡®è®¤åè§å’Œå¯å¾—æ€§åè§ç­‰ï¼Œæˆ‘ä»¬åœ¨æœ¬å·¥ä½œä¸­æå‡ºäº†ä¸€ç§æ–°å‹çš„æ— åè§å†…å­˜è®¾è®¡ã€‚ï¼ˆä¸€ä¸ªå¯é‡å¤ä½¿ç”¨çš„æ— åè§å†…å­˜æºä»£ç çš„æ¨¡æ‹Ÿç‰ˆæœ¬å¯ä¾›éå•†ä¸šä½¿ç”¨ï¼Œé“¾æ¥ä¸ºï¼š[<a target="_blank" rel="noopener" href="https://github.com/HatimChergui/unbiased-collective-memory%EF%BC%89%E3%80%82%E8%AF%A5%E8%AE%BE%E8%AE%A1%E7%89%B9%E7%82%B9%E5%8C%85%E6%8B%AC%EF%BC%9A%EF%BC%88i%EF%BC%89%E9%80%9A%E8%BF%87Jaccard%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%BF%9B%E8%A1%8C%E8%BF%87%E5%8E%BB%E7%AD%96%E7%95%A5%E7%9A%84%E8%AF%AD%E4%B9%89%E6%A3%80%E7%B4%A2%EF%BC%9B%EF%BC%88ii%EF%BC%89%E9%80%9A%E8%BF%87%E6%94%BE%E5%A4%A7%E6%9C%8D%E5%8A%A1%E7%BA%A7%E5%88%AB%E5%8D%8F%E8%AE%AE%E8%BF%9D%E8%A7%84%E7%9A%84%E6%9D%83%E9%87%8D%E4%BB%A5%E5%8F%8A%E5%BC%BA%E5%88%B6%E5%8C%85%E5%90%AB%E5%A4%B1%E8%B4%A5%E7%9A%84%E8%B0%88%E5%88%A4%E6%A1%88%E4%BE%8B%E6%9D%A5%E5%AD%A6%E4%B9%A0%E4%BB%8E%E5%A4%B1%E8%B4%A5%E4%B8%AD%E6%B1%B2%E5%8F%96%E6%95%99%E8%AE%AD%EF%BC%8C%E4%BB%A5%E5%87%8F%E8%BD%BB%E7%A1%AE%E8%AE%A4%E5%81%8F%E8%A7%81%EF%BC%9B%EF%BC%88iii%EF%BC%89%E5%BC%BA%E5%88%B6%E5%AE%9E%E6%96%BD%E5%A4%9A%E6%A0%B7%E6%80%A7%E4%BB%A5%E6%9C%80%E5%B0%8F%E5%8C%96%E5%8F%AF%E5%BE%97%E6%80%A7%E5%81%8F%E8%A7%81%EF%BC%9B%EF%BC%88iv%EF%BC%89%E9%80%9A%E8%BF%87%E7%BC%93%E6%85%A2%E8%A1%B0%E5%87%8F%E6%9D%A5%E5%B9%B3%E8%A1%A1%E8%BF%91%E5%9B%A0%E5%92%8C%E9%A6%96%E5%9B%A0%E6%95%88%E5%BA%94%EF%BC%8C%E4%BB%A5%E5%AF%B9%E6%8A%97%E6%97%B6%E9%97%B4%E5%81%8F%E8%A7%81%E3%80%82%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA%E4%BA%86%E7%8E%B0%E6%9C%89%E5%81%8F%E8%A7%81%E7%9A%84%E5%BD%B1%E5%93%8D%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%97%A0%E5%81%8F%E8%A7%81%E5%86%85%E5%AD%98%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E4%BB%8E%E6%88%90%E5%8A%9F%E5%92%8C%E5%A4%B1%E8%B4%A5%E7%9A%84%E7%AD%96%E7%95%A5%E4%B8%AD%E5%AD%A6%E4%B9%A0%E6%9D%A5%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E3%80%82%E4%B8%8E%E6%97%A0%E8%AE%B0%E5%BF%86%E5%9F%BA%E5%87%86%E5%92%8C%E5%B8%B8%E8%A7%84%E8%AE%B0%E5%BF%86%E5%9F%BA%E5%87%86%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%AA%E8%A7%A3%E5%86%B3%E7%9A%84%E8%B0%88%E5%88%A4%E5%87%8F%E5%B0%91%E4%BA%86%C3%974.5%E5%92%8C%C3%973.5%EF%BC%8C%E5%90%8C%E6%97%B6%E5%AE%8C%E5%85%A8%E5%87%8F%E8%BD%BB%E4%BA%86%E6%9C%8D%E5%8A%A1%E7%BA%A7%E5%88%AB%E5%8D%8F%E8%AE%AE%E8%BF%9D%E8%A7%84%E8%A1%8C%E4%B8%BA%EF%BC%8C%E5%B9%B6%E6%94%B9%E5%96%84%E4%BA%86%E5%BB%B6%E8%BF%9F%E5%92%8C%E8%8A%82%E8%83%BD%E5%88%86%E5%B8%83%E3%80%82]">https://github.com/HatimChergui/unbiased-collective-memoryï¼‰ã€‚è¯¥è®¾è®¡ç‰¹ç‚¹åŒ…æ‹¬ï¼šï¼ˆiï¼‰é€šè¿‡Jaccardç›¸ä¼¼æ€§è¿›è¡Œè¿‡å»ç­–ç•¥çš„è¯­ä¹‰æ£€ç´¢ï¼›ï¼ˆiiï¼‰é€šè¿‡æ”¾å¤§æœåŠ¡çº§åˆ«åè®®è¿è§„çš„æƒé‡ä»¥åŠå¼ºåˆ¶åŒ…å«å¤±è´¥çš„è°ˆåˆ¤æ¡ˆä¾‹æ¥å­¦ä¹ ä»å¤±è´¥ä¸­æ±²å–æ•™è®­ï¼Œä»¥å‡è½»ç¡®è®¤åè§ï¼›ï¼ˆiiiï¼‰å¼ºåˆ¶å®æ–½å¤šæ ·æ€§ä»¥æœ€å°åŒ–å¯å¾—æ€§åè§ï¼›ï¼ˆivï¼‰é€šè¿‡ç¼“æ…¢è¡°å‡æ¥å¹³è¡¡è¿‘å› å’Œé¦–å› æ•ˆåº”ï¼Œä»¥å¯¹æŠ—æ—¶é—´åè§ã€‚è¯„ä¼°ç»“æœå±•ç¤ºäº†ç°æœ‰åè§çš„å½±å“ï¼Œä»¥åŠæ— åè§å†…å­˜å¦‚ä½•é€šè¿‡ä»æˆåŠŸå’Œå¤±è´¥çš„ç­–ç•¥ä¸­å­¦ä¹ æ¥è§£å†³é—®é¢˜ã€‚ä¸æ— è®°å¿†åŸºå‡†å’Œå¸¸è§„è®°å¿†åŸºå‡†ç›¸æ¯”ï¼Œæœªè§£å†³çš„è°ˆåˆ¤å‡å°‘äº†Ã—4.5å’ŒÃ—3.5ï¼ŒåŒæ—¶å®Œå…¨å‡è½»äº†æœåŠ¡çº§åˆ«åè®®è¿è§„è¡Œä¸ºï¼Œå¹¶æ”¹å–„äº†å»¶è¿Ÿå’ŒèŠ‚èƒ½åˆ†å¸ƒã€‚]</a>(<a target="_blank" rel="noopener" href="https://github.com/HatimChergui/unbiased-collective-memory%EF%BC%89%E8%AF%A5%E8%AE%BE%E8%AE%A1%E7%89%B9%E7%82%B9%E5%8C%BA%E5%9C%B0%E5%AD%97%E5%AE%BD%E5%B9%B3%E6%AF%94%EF%BC%8C%E5%A6%82%E6%AD%A3%E5%AF%BC%E5%BC%BA%$">https://github.com/HatimChergui/unbiased-collective-memory%EF%BC%89%E8%AF%A5%E8%AE%BE%E8%AE%A1%E7%89%B9%E7%82%B9%E5%8C%BA%E5%9C%B0%E5%AD%97%E5%AE%BD%E5%B9%B3%E6%AF%94%EF%BC%8C%E5%A6%82%E6%AD%A3%E5%AF%BC%E5%BC%BA%$</a> %E7 %9A % 84 % E7 %BB % 8F % E9 %AA % 8C % E5 % B9 % B6 % E4 % B8 % 8D % E5 % A4 % A7 % E5 % B0 % BD % E6 % B2 % A2 % E5 % A4 % A7 % E7 %BA % A1 % EFF )</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26200v1">PDF</a> 12 pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äº6G RAN-Edgeç½‘ç»œä¸­çš„ä¸»åŠ¨è·¨åŸŸèµ„æºç¼–æ’çš„æ–°å‹æ¡†æ¶ã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬ä¸“ä¸šåŒ–çš„RANï¼ˆèƒ½æºæ•ˆç‡ï¼‰å’Œè¾¹ç¼˜ï¼ˆå»¶è¿Ÿä¿è¯ï¼‰ä»£ç†ï¼Œè¿™äº›ä»£ç†æ”¯æŒé«˜çº§æ¨ç†å’Œè§„åˆ’èƒ½åŠ›ï¼Œå¹¶å‚ä¸è¿­ä»£è°ˆåˆ¤ã€‚ä»£ç†é€šè¿‡æ•°å­—åŒèƒèƒè¿›è¡Œæµ‹è¯•å…¶æè®®å¹¶åŠ¨æ€äº¤äº’ï¼ŒåŒæ—¶åˆ©ç”¨é•¿æœŸé›†ä½“è®°å¿†å­˜å‚¨æˆåŠŸå’Œå¤±è´¥çš„åè®®ä»¥åŠç›¸å…³ç½‘ç»œä¸Šä¸‹æ–‡ä»¥åˆ¶å®šç­–ç•¥ã€‚é‰´äºä»£ç†åœ¨æ£€ç´¢è¿‡å»çš„ç»éªŒæ—¶ä¼šå—åˆ°è®¤çŸ¥åå·®çš„å½±å“ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æ— åè§è®°å¿†è®¾è®¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰æ£€ç´¢è¿‡å»ç­–ç•¥ã€ä»å¤±è´¥ä¸­å­¦ä¹ ã€å¤šæ ·æ€§å’Œæ‰§è¡Œæƒé‡çš„æ§åˆ¶ç­‰ç­–ç•¥ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºæ— åè§è®°å¿†æœ‰åŠ©äºè§£å†³ç°æœ‰åè§é—®é¢˜ï¼Œé€šè¿‡å­¦ä¹ æˆåŠŸå’Œå¤±è´¥çš„ç­–ç•¥æ¥å‡å°‘æœªè§£å†³çš„è°ˆåˆ¤å¹¶æé«˜ç½‘ç»œæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–°å‹æ¡†æ¶ç”¨äºä¸»åŠ¨è·¨åŸŸèµ„æºç¼–æ’åœ¨6G RAN-Edgeç½‘ç»œä¸­ã€‚</li>
<li>ç³»ç»ŸåŒ…æ‹¬ä¸“ä¸šåŒ–çš„RANå’Œè¾¹ç¼˜ä»£ç†ï¼Œé€šè¿‡æ•°å­—åŒèƒèƒè¿›è¡Œæµ‹è¯•å¹¶å‚ä¸è¿­ä»£è°ˆåˆ¤ã€‚</li>
<li>ä»£ç†å…·æœ‰é«˜çº§æ¨ç†å’Œè§„åˆ’èƒ½åŠ›ï¼Œå¹¶ä»è¿‡å»æˆåŠŸçš„ç»éªŒå’Œå¤±è´¥ä¸­å­¦ä¹ ï¼Œåˆ¶å®šå‡ºæœ‰æ•ˆçš„ç­–ç•¥æ¥æé«˜ç½‘ç»œæ€§èƒ½ã€‚è¿™äº›ç­–ç•¥ä¼šå­˜å‚¨åœ¨é•¿æœŸé›†ä½“è®°å¿†ä¸­ä»¥ä¾¿ä»¥åä½¿ç”¨ã€‚</li>
<li>è®ºæ–‡æŒ‡å‡ºä»£ç†åœ¨æ£€ç´¢è¿‡å»ç»éªŒæ—¶å­˜åœ¨çš„è®¤çŸ¥åè§é—®é¢˜ï¼Œå¹¶ä»‹ç»äº†ä¸€ç§æ–°å‹æ— åè§è®°å¿†è®¾è®¡æ¥åº”å¯¹è¿™äº›åè§ã€‚æ— åè§è®°å¿†åŒ…æ‹¬è¯­ä¹‰æ£€ç´¢ã€ä»å¤±è´¥ä¸­å­¦ä¹ ã€å¤šæ ·æ€§å’Œæ‰§è¡Œæƒé‡çš„æ§åˆ¶ç­‰ç­–ç•¥ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºæ— åè§è®°å¿†èƒ½å¤Ÿå‡å°‘æœªè§£å†³çš„è°ˆåˆ¤å¹¶æé«˜ç½‘ç»œæ€§èƒ½ã€‚è¯¥è®¾è®¡çš„æºä»£ç å·²å…¬å¼€å‘å¸ƒä¾›éå•†ä¸šä½¿ç”¨ã€‚</li>
<li>é€šè¿‡æ•°å­—åŒèƒèƒæŠ€æœ¯ï¼Œä»£ç†èƒ½å¤Ÿæ¨¡æ‹Ÿå¹¶æµ‹è¯•å…¶æè®®ï¼Œä»è€Œæé«˜ç½‘ç»œæ€§èƒ½å’Œå¯é æ€§ã€‚åŒæ—¶ï¼Œè¯¥æŠ€æœ¯ä¹Ÿæœ‰åŠ©äºå‡å°‘ç‰©ç†æµ‹è¯•çš„æˆæœ¬å’Œæ—¶é—´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26200">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1730bfd60406a93994b97017a977b6c1" align="middle">
<img src="https://picx.zhimg.com/v2-950f697e9ed4fb8176980c91b1cb25d2" align="middle">
<img src="https://picx.zhimg.com/v2-9f43d9b2550314d28b83e9e54e0ca325" align="middle">
<img src="https://picx.zhimg.com/v2-39439aa20b0de0d0162d55d1c8fa28e2" align="middle">
<img src="https://picx.zhimg.com/v2-dd5e2396c356fd73bcd1df04af83ffa2" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Beyond-the-Algorithm-A-Field-Guide-to-Deploying-AI-Agents-in-Clinical-Practice"><a href="#Beyond-the-Algorithm-A-Field-Guide-to-Deploying-AI-Agents-in-Clinical-Practice" class="headerlink" title="Beyond the Algorithm: A Field Guide to Deploying AI Agents in Clinical   Practice"></a>Beyond the Algorithm: A Field Guide to Deploying AI Agents in Clinical   Practice</h2><p><strong>Authors:Jack Gallifant, Katherine C. Kellogg, Matt Butler, Amanda Centi, Patrick F. Doyle, Sayon Dutta, Joyce Guo, Matthew J. Hadfield, Esther H. Kim, David E. Kozono, Hugo JWL Aerts, Adam B. Landman, Raymond H. Mak, Rebecca G. Mishuris, Tanna L. Nelson, Guergana K. Savova, Elad Sharon, Benjamin C. Silverman, Umit Topaloglu, Jeremy L. Warner, Danielle S. Bitterman</strong></p>
<p>Large language models (LLMs) integrated into agent-driven workflows hold immense promise for healthcare, yet a significant gap exists between their potential and practical implementation within clinical settings. To address this, we present a practitioner-oriented field manual for deploying generative agents that use electronic health record (EHR) data. This guide is informed by our experience deploying the â€œirAE-Agentâ€, an automated system to detect immune-related adverse events from clinical notes at Mass General Brigham, and by structured interviews with 20 clinicians, engineers, and informatics leaders involved in the project. Our analysis reveals a critical misalignment in clinical AI development: less than 20% of our effort was dedicated to prompt engineering and model development, while over 80% was consumed by the sociotechnical work of implementation. We distill this effort into five â€œheavy liftsâ€: data integration, model validation, ensuring economic value, managing system drift, and governance. By providing actionable solutions for each of these challenges, this field manual shifts the focus from algorithmic development to the essential infrastructure and implementation work required to bridge the â€œvalley of deathâ€ and successfully translate generative AI from pilot projects into routine clinical care. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆåˆ°ä»£ç†é©±åŠ¨çš„å·¥ä½œæµä¸­ï¼Œåœ¨åŒ»ç–—ä¿å¥é¢†åŸŸå…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œåœ¨ä¸´åºŠç¯å¢ƒä¸­å®ç°å…¶æ½œåŠ›å’Œå®é™…åº”ç”¨ä¹‹é—´å­˜åœ¨ç€æ˜¾è‘—çš„å·®è·ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬ç¼–åˆ¶äº†ä¸€æœ¬é¢å‘å®è·µçš„é¢†åŸŸæ‰‹å†Œï¼Œä»‹ç»å¦‚ä½•éƒ¨ç½²ä½¿ç”¨ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰æ•°æ®çš„ç”Ÿæˆä»£ç†ã€‚è¯¥æŒ‡å—çš„ç¼–å†™å‚è€ƒäº†æˆ‘ä»¬éƒ¨ç½²â€œirAE-Agentâ€ï¼ˆä¸€ç§ç”¨äºä»Mass General Brighamçš„ä¸´åºŠç¬”è®°ä¸­æ£€æµ‹å…ç–«ç›¸å…³ä¸è‰¯äº‹ä»¶çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼‰çš„ç»éªŒä»¥åŠä¸å‚ä¸è¯¥é¡¹ç›®çš„20åä¸´åºŠåŒ»ç”Ÿã€å·¥ç¨‹å¸ˆå’Œä¿¡æ¯æŠ€æœ¯é¢†å¯¼è¿›è¡Œçš„ç»“æ„åŒ–è®¿è°ˆã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½å‘å±•ä¸­å­˜åœ¨å…³é”®çš„ä¸åŒ¹é…é—®é¢˜ï¼šæˆ‘ä»¬çš„åŠªåŠ›ä¸­åªæœ‰ä¸åˆ°20%æŠ•å…¥åˆ°å³æ—¶å·¥ç¨‹å’Œæ¨¡å‹å¼€å‘ä¸­ï¼Œè€Œè¶…è¿‡80%çš„ç²¾åŠ›å´è€—è´¹åœ¨å®æ–½çš„ç¤¾ä¼šæŠ€æœ¯å·¥ä½œä¸Šã€‚æˆ‘ä»¬å°†è¿™äº›åŠªåŠ›å½’ç»“ä¸ºäº”ä¸ªâ€œè‰°å·¨çš„ä»»åŠ¡â€ï¼šæ•°æ®é›†æˆã€æ¨¡å‹éªŒè¯ã€ç¡®ä¿ç»æµä»·å€¼ã€ç®¡ç†ç³»ç»Ÿæ¼‚ç§»å’Œæ²»ç†ã€‚è¿™æœ¬é¢†åŸŸæ‰‹å†Œé’ˆå¯¹è¿™äº›æŒ‘æˆ˜æä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œä»è€Œå°†é‡ç‚¹ä»ç®—æ³•å¼€å‘è½¬å‘å¿…è¦çš„åŸºç¡€è®¾æ–½å’Œå®æ–½å·¥ä½œï¼Œä»¥å¡«è¡¥â€œæ­»äº¡ä¹‹è°·â€ï¼ŒæˆåŠŸåœ°å°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä»è¯•ç‚¹é¡¹ç›®è½¬åŒ–ä¸ºå¸¸è§„ä¸´åºŠæŠ¤ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26153v1">PDF</a> Under review. 5 Tables, 2 Figures</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å…¶åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„å®é™…åº”ç”¨ä¸å…¶æ½œåŠ›ä¹‹é—´å­˜åœ¨è¾ƒå¤§å·®è·ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æä¾›äº†é¢å‘å®è·µçš„é¢†åŸŸæ‰‹å†Œï¼Œä»‹ç»å¦‚ä½•éƒ¨ç½²ä½¿ç”¨ç”µå­å¥åº·è®°å½•æ•°æ®çš„ç”Ÿæˆå¼æ™ºèƒ½ä½“ã€‚é€šè¿‡éƒ¨ç½²â€œirAE-Agentâ€ç³»ç»Ÿçš„ç»éªŒå’Œä¸ç›¸å…³é¡¹ç›®å‚ä¸è€…çš„ç»“æ„åŒ–è®¿è°ˆï¼Œæœ¬æ–‡æ­ç¤ºäº†åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½å¼€å‘ä¸­çš„å…³é”®è¯¯åŒºï¼Œå¹¶æå‡ºäº†äº”ä¸ªé‡è¦æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ•°æ®é›†æˆã€æ¨¡å‹éªŒè¯ã€ç¡®ä¿ç»æµä»·å€¼ã€ç®¡ç†ç³»ç»Ÿæ¼‚ç§»å’Œæ²»ç†ç­‰æ–¹é¢ã€‚æ­¤æ‰‹å†Œæ—¨åœ¨å°†é‡ç‚¹ä»ç®—æ³•å¼€å‘è½¬å‘å¿…è¦çš„åŸºç¡€è®¾æ–½å’Œå®æ–½å·¥ä½œï¼Œä»¥æˆåŠŸå°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä»è¯•ç‚¹é¡¹ç›®è½¬åŒ–ä¸ºå¸¸è§„çš„ä¸´åºŠå…³æ€€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸæœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å®é™…åº”ç”¨ä¸æ½œåŠ›ä¹‹é—´å­˜åœ¨å·®è·ã€‚</li>
<li>éƒ¨ç½²ç”Ÿæˆå¼æ™ºèƒ½ä½“æ—¶ï¼Œéœ€è¦å…³æ³¨æ•°æ®é›†æˆã€æ¨¡å‹éªŒè¯ç­‰äº”ä¸ªé‡è¦æ–¹é¢ã€‚</li>
<li>æ•°æ®é›†æˆæ˜¯æ™ºèƒ½ä½“éƒ¨ç½²çš„å…³é”®ç¯èŠ‚ä¹‹ä¸€ï¼Œéœ€è¦è§£å†³æ•°æ®è´¨é‡å’Œæ ‡å‡†åŒ–é—®é¢˜ã€‚</li>
<li>æ¨¡å‹éªŒè¯æ˜¯ç¡®ä¿æ™ºèƒ½ä½“å‡†ç¡®æ€§å’Œå¯é æ€§çš„é‡è¦æ­¥éª¤ã€‚</li>
<li>åœ¨å®æ–½æ™ºèƒ½ä½“ç³»ç»Ÿæ—¶ï¼Œéœ€è¦ç¡®ä¿ç»æµä»·å€¼å’Œé•¿æœŸå¯æŒç»­æ€§ã€‚</li>
<li>ç®¡ç†ç³»ç»Ÿæ¼‚ç§»æ˜¯æ™ºèƒ½ä½“éƒ¨ç½²ä¸­éœ€è¦è§£å†³çš„æŒ‘æˆ˜ä¹‹ä¸€ï¼Œä»¥ç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26153">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3b5a08916ae6769a346d3a5a4951cf45" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DyFlow-Dynamic-Workflow-Framework-for-Agentic-Reasoning"><a href="#DyFlow-Dynamic-Workflow-Framework-for-Agentic-Reasoning" class="headerlink" title="DyFlow: Dynamic Workflow Framework for Agentic Reasoning"></a>DyFlow: Dynamic Workflow Framework for Agentic Reasoning</h2><p><strong>Authors:Yanbo Wang, Zixiang Xu, Yue Huang, Xiangqi Wang, Zirui Song, Lang Gao, Chenxi Wang, Xiangru Tang, Yue Zhao, Arman Cohan, Xiangliang Zhang, Xiuying Chen</strong></p>
<p>Agent systems based on large language models (LLMs) have shown great potential in complex reasoning tasks, but building efficient and generalizable workflows remains a major challenge. Most existing approaches rely on manually designed processes, which limits their adaptability across different tasks. While a few methods attempt automated workflow generation, they are often tied to specific datasets or query types and make limited use of intermediate feedback, reducing system robustness and reasoning depth. Moreover, their operations are typically predefined and inflexible. To address these limitations, we propose DyFlow, a dynamic workflow generation framework that adaptively constructs and adjusts reasoning procedures based on task requirements and real-time intermediate feedback, thereby enhancing cross-task generalization. DyFlow consists of two core components: a designer and an executor. The designer decomposes complex problems into a sequence of sub-goals defined by high-level objectives and dynamically plans the next steps based on intermediate outputs and feedback. These plans are then carried out by the executor, which executes each operation using dynamic operators with context-aware parameterization, enabling flexible and semantically grounded reasoning. We systematically evaluate DyFlow across diverse domains, including social reasoning, biomedical tasks, mathematical problem solving, and code generation. Results demonstrate that DyFlow significantly outperforms existing baselines, achieving substantial Pass@k improvements and exhibiting robust generalization across diverse domains. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/wyf23187/DyFlow">https://github.com/wyf23187/DyFlow</a>. </p>
<blockquote>
<p>åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Agentç³»ç»Ÿåœ¨å¤æ‚çš„æ¨ç†ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†æ„å»ºé«˜æ•ˆä¸”å¯æ¨å¹¿çš„å·¥ä½œæµç¨‹ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºæ‰‹åŠ¨è®¾è®¡çš„è¿‡ç¨‹ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚å°½ç®¡æœ‰ä¸€äº›æ–¹æ³•å°è¯•è¿›è¡Œè‡ªåŠ¨å·¥ä½œæµç¨‹ç”Ÿæˆï¼Œä½†å®ƒä»¬é€šå¸¸ä¸ç‰¹å®šæ•°æ®é›†æˆ–æŸ¥è¯¢ç±»å‹ç›¸å…³è”ï¼Œå¹¶ä¸”å¯¹ä¸­é—´åé¦ˆçš„åˆ©ç”¨æœ‰é™ï¼Œé™ä½äº†ç³»ç»Ÿçš„ç¨³å¥æ€§å’Œæ¨ç†æ·±åº¦ã€‚è€Œä¸”ï¼Œå®ƒä»¬çš„æ“ä½œé€šå¸¸æ˜¯é¢„å…ˆå®šä¹‰çš„ï¼Œä¸å¤Ÿçµæ´»ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†DyFlowï¼Œä¸€ä¸ªåŠ¨æ€å·¥ä½œæµç¨‹ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒå¯ä»¥æ ¹æ®ä»»åŠ¡éœ€æ±‚å’Œå®æ—¶ä¸­é—´åé¦ˆè‡ªé€‚åº”åœ°æ„å»ºå’Œè°ƒæ•´æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œæé«˜è·¨ä»»åŠ¡çš„é€šç”¨æ€§ã€‚DyFlowç”±ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼šè®¾è®¡å¸ˆå’Œæ‰§è¡Œè€…ã€‚è®¾è®¡å¸ˆå°†å¤æ‚çš„é—®é¢˜åˆ†è§£ä¸ºç”±é«˜çº§ç›®æ ‡å®šä¹‰çš„ä¸€ç³»åˆ—å­ç›®æ ‡ï¼Œå¹¶åŸºäºä¸­é—´è¾“å‡ºå’Œåé¦ˆåŠ¨æ€åœ°è§„åˆ’ä¸‹ä¸€æ­¥ã€‚ç„¶åï¼Œæ‰§è¡Œè€…æ ¹æ®è¿™äº›è®¡åˆ’æ‰§è¡Œæ“ä½œï¼Œä½¿ç”¨å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥å‚æ•°åŒ–çš„åŠ¨æ€æ“ä½œç¬¦ï¼Œå®ç°çµæ´»ä¸”è¯­ä¹‰ä¸°å¯Œçš„æ¨ç†ã€‚æˆ‘ä»¬åœ¨ç¤¾ä¼šæ¨ç†ã€ç”Ÿç‰©åŒ»å­¦ä»»åŠ¡ã€æ•°å­¦é—®é¢˜è§£å†³å’Œä»£ç ç”Ÿæˆç­‰å¤šä¸ªé¢†åŸŸå¯¹DyFlowè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼ŒDyFlowæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå®ç°äº†å®è´¨æ€§çš„Pass@kæ”¹è¿›ï¼Œå¹¶åœ¨å¤šä¸ªé¢†åŸŸä¸­è¡¨ç°å‡ºç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/wyf23187/DyFlow%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/wyf23187/DyFlowå…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26062v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Agentç³»ç»Ÿåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†æ„å»ºé«˜æ•ˆä¸”å¯æ¨å¹¿çš„å·¥ä½œæµç¨‹ä»æ˜¯ä¸»è¦æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¤§å¤šä¾èµ–æ‰‹åŠ¨è®¾è®¡è¿‡ç¨‹ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºDyFlowåŠ¨æ€å·¥ä½œæµç¨‹ç”Ÿæˆæ¡†æ¶ï¼Œæ ¹æ®ä»»åŠ¡éœ€æ±‚å’Œå®æ—¶ä¸­é—´åé¦ˆè‡ªé€‚åº”æ„å»ºå’Œè°ƒæ•´æ¨ç†æµç¨‹ï¼Œæé«˜è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚DyFlowåŒ…å«è®¾è®¡å¸ˆå’Œæ‰§è¡Œå®˜ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œè®¾è®¡å¸ˆå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å­ç›®æ ‡ï¼Œå¹¶æ ¹æ®ä¸­é—´è¾“å‡ºå’Œåé¦ˆåŠ¨æ€è§„åˆ’ä¸‹ä¸€æ­¥æ“ä½œï¼›æ‰§è¡Œå®˜åˆ™è´Ÿè´£æ‰§è¡Œæ¯ä¸ªæ“ä½œï¼Œé‡‡ç”¨å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å‚æ•°åŒ–åŠ¨æ€æ“ä½œç¬¦ï¼Œå®ç°çµæ´»ä¸”è¯­ä¹‰ä¸°å¯Œçš„æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDyFlowåœ¨ç¤¾äº¤æ¨ç†ã€ç”Ÿç‰©åŒ»å­¦ä»»åŠ¡ã€æ•°å­¦é—®é¢˜æ±‚è§£å’Œä»£ç ç”Ÿæˆç­‰å¤šä¸ªé¢†åŸŸå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†æ˜¾è‘—çš„Pass@kæå‡å’Œç¨³å¥çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agentç³»ç»ŸåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>æ„å»ºé«˜æ•ˆã€å¯æ¨å¹¿çš„å·¥ä½œæµç¨‹æ˜¯å½“å‰çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ‰‹åŠ¨è®¾è®¡è¿‡ç¨‹ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚</li>
<li>DyFlowæ˜¯ä¸€ä¸ªåŠ¨æ€å·¥ä½œæµç¨‹ç”Ÿæˆæ¡†æ¶ï¼Œå¯ä»¥è‡ªé€‚åº”åœ°æ„å»ºå’Œè°ƒæ•´æ¨ç†æµç¨‹ã€‚</li>
<li>DyFlowåŒ…æ‹¬è®¾è®¡å¸ˆå’Œæ‰§è¡Œå®˜ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œåˆ†åˆ«è´Ÿè´£é—®é¢˜åˆ†è§£ä¸åŠ¨æ€è§„åˆ’ã€æ“ä½œæ‰§è¡Œã€‚</li>
<li>DyFlowé€šè¿‡å®æ—¶ä¸­é—´åé¦ˆå’Œä»»åŠ¡éœ€æ±‚è°ƒæ•´æ¨ç†æµç¨‹ï¼Œæé«˜è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>DyFlowåœ¨å¤šä¸ªé¢†åŸŸå‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26062">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8addf3bfc79c9da3d4638ab076466068" align="middle">
<img src="https://picx.zhimg.com/v2-fe3f9ec8c9f0c376b168af30dc0ee3e9" align="middle">
<img src="https://picx.zhimg.com/v2-65b6957dd1576410c97e1f33a8794fca" align="middle">
<img src="https://picx.zhimg.com/v2-c01b6d9ff2b0878d1d5b736e74d50b23" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="RE-Searcher-Robust-Agentic-Search-with-Goal-oriented-Planning-and-Self-reflection"><a href="#RE-Searcher-Robust-Agentic-Search-with-Goal-oriented-Planning-and-Self-reflection" class="headerlink" title="RE-Searcher: Robust Agentic Search with Goal-oriented Planning and   Self-reflection"></a>RE-Searcher: Robust Agentic Search with Goal-oriented Planning and   Self-reflection</h2><p><strong>Authors:Daocheng Fu, Jianbiao Mei, Licheng Wen, Xuemeng Yang, Cheng Yang, Rong Wu, Tao Hu, Siqi Li, Yufan Shen, Xinyu Cai, Pinlong Cai, Botian Shi, Yong Liu, Yu Qiao</strong></p>
<p>Large language models (LLMs) excel at knowledge-intensive question answering and reasoning, yet their real-world deployment remains constrained by knowledge cutoff, hallucination, and limited interaction modalities. Augmenting LLMs with external search tools helps alleviate these issues, but it also exposes agents to a complex search environment in which small, plausible variations in query formulation can steer reasoning into unproductive trajectories and amplify errors. We present a systematic analysis that quantifies how environmental complexity induces fragile search behaviors and, in turn, degrades overall performance. To address this challenge, we propose a simple yet effective approach to instantiate a search agent, RE-Searcher. During search, RE-Searcher explicitly articulates a concrete search goal and subsequently reflects on whether the retrieved evidence satisfies that goal. This combination of goal-oriented planning and self-reflection enables RE-Searcher to resist spurious cues in complex search environments and perform robust search. Extensive experiments show that our method improves search accuracy and achieves state-of-the-art results. Perturbation studies further demonstrate substantial resilience to noisy or misleading external signals, mitigating the fragility of the search process. We believe these findings offer practical guidance for integrating LLM-powered agents into more complex interactive environments and enabling more autonomous decision-making. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹é—®ç­”å’Œæ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ä»å—åˆ°çŸ¥è¯†æˆªæ–­ã€å¹»è§‰å’Œæœ‰é™äº¤äº’æ¨¡å¼çš„åˆ¶çº¦ã€‚é€šè¿‡å¤–éƒ¨æœç´¢å·¥å…·å¢å¼ºLLMæœ‰åŠ©äºç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†åŒæ—¶ä¹Ÿå°†ä»£ç†æš´éœ²äºå¤æ‚çš„æœç´¢ç¯å¢ƒä¸­ï¼Œå…¶ä¸­æŸ¥è¯¢è¡¨è¿°çš„å¾®å°ã€çœ‹ä¼¼åˆç†çš„å˜åŒ–å¯èƒ½å¯¼è‡´æ¨ç†åç¦»æ­£ç¡®çš„æ–¹å‘å¹¶æ”¾å¤§é”™è¯¯ã€‚æˆ‘ä»¬å¯¹ç¯å¢ƒå¤æ‚æ€§å¦‚ä½•å¯¼è‡´è„†å¼±çš„æœç´¢è¡Œä¸ºè¿›è¡Œäº†ç³»ç»Ÿåˆ†æï¼Œå¹¶è½¬è€Œé™ä½äº†æ•´ä½“æ€§èƒ½ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•æ¥å®ä¾‹åŒ–æœç´¢ä»£ç†RE-Searcherã€‚åœ¨æœç´¢è¿‡ç¨‹ä¸­ï¼ŒRE-Searcheræ˜ç¡®è¡¨è¿°äº†å…·ä½“çš„æœç´¢ç›®æ ‡ï¼Œç„¶ååæ€æ£€ç´¢åˆ°çš„è¯æ®æ˜¯å¦æ»¡è¶³è¯¥ç›®æ ‡ã€‚ç›®æ ‡å¯¼å‘è§„åˆ’å’Œè‡ªæˆ‘åæ€çš„ç»“åˆä½¿RE-Searcherèƒ½å¤ŸæŠµæŠ—å¤æ‚æœç´¢ç¯å¢ƒä¸­çš„è™šå‡çº¿ç´¢ï¼Œå¹¶æ‰§è¡Œç¨³å¥çš„æœç´¢ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†æœç´¢å‡†ç¡®æ€§ï¼Œå¹¶è¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„ç»“æœã€‚æ‰°åŠ¨ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†å…¶å¯¹å˜ˆæ‚æˆ–è¯¯å¯¼æ€§å¤–éƒ¨ä¿¡å·çš„æ˜¾è‘—æŠ—æ€§ï¼Œå‡è½»äº†æœç´¢è¿‡ç¨‹çš„è„†å¼±æ€§ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™äº›å‘ç°ä¸ºå°†LLMé©±åŠ¨çš„ä»£ç†é›†æˆåˆ°æ›´å¤æ‚çš„äº¤äº’å¼ç¯å¢ƒä¸­ï¼Œå¹¶å®ç°æ›´è‡ªä¸»çš„å†³ç­–æä¾›äº†å®é™…æŒ‡å¯¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26048v1">PDF</a> 16 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹é—®ç­”å’Œæ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åœ¨å®é™…éƒ¨ç½²ä¸­ä»é¢ä¸´çŸ¥è¯†æˆªæ–­ã€å¹»è±¡å’Œäº¤äº’æ¨¡å¼æœ‰é™ç­‰é—®é¢˜ã€‚é€šè¿‡å¢æ´å¤–éƒ¨æœç´¢å·¥å…·å¯ç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†è¿™ä¹Ÿä½¿ä»£ç†é¢ä¸´å¤æ‚çš„æœç´¢ç¯å¢ƒï¼ŒæŸ¥è¯¢è¡¨è¿°ä¸­çš„å¾®å°ä¸”åˆç†çš„å˜åŒ–å¯èƒ½å¯¼è‡´æ¨ç†åç¦»æ­£ç¡®æ–¹å‘å¹¶æ”¾å¤§é”™è¯¯ã€‚æœ¬æ–‡è¿›è¡Œäº†ç³»ç»Ÿåˆ†æï¼Œé‡åŒ–ç¯å¢ƒå¤æ‚æ€§å¦‚ä½•å¯¼è‡´æœç´¢è¡Œä¸ºå˜å¾—è„†å¼±ï¼Œè¿›è€Œé™ä½æ•´ä½“æ€§èƒ½ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥å®ä¾‹åŒ–æœç´¢ä»£ç†RE-Searcherã€‚RE-Searcheråœ¨æœç´¢è¿‡ç¨‹ä¸­æ˜ç¡®å…·ä½“æœç´¢ç›®æ ‡ï¼Œå¹¶åæ€æ£€ç´¢åˆ°çš„è¯æ®æ˜¯å¦æ»¡è¶³ç›®æ ‡ã€‚è¿™ç§ç›®æ ‡å¯¼å‘çš„è§„åˆ’å’Œè‡ªæˆ‘åæ€çš„ç»“åˆï¼Œä½¿RE-Searcherèƒ½å¤Ÿåœ¨å¤æ‚çš„æœç´¢ç¯å¢ƒä¸­æŠµå¾¡é”™è¯¯çº¿ç´¢ï¼Œå®ç°ç¨³å¥æœç´¢ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†æœç´¢å‡†ç¡®æ€§å¹¶è¾¾åˆ°äº†æœ€æ–°ç»“æœã€‚æ‰°åŠ¨ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†å…¶å¯¹å˜ˆæ‚æˆ–è¯¯å¯¼æ€§å¤–éƒ¨ä¿¡å·çš„å¼ºå¤§æŠ—æ€§ï¼Œå‡è½»äº†æœç´¢è¿‡ç¨‹çš„è„†å¼±æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å­˜åœ¨çŸ¥è¯†æˆªæ–­ã€å¹»è±¡å’Œäº¤äº’é™åˆ¶ç­‰é—®é¢˜ã€‚</li>
<li>å¤–éƒ¨æœç´¢å·¥å…·å¢æ´å¯ä»¥ç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†å¼•å…¥å¤æ‚æœç´¢ç¯å¢ƒï¼Œå¾®å°æŸ¥è¯¢å˜åŒ–å¯èƒ½å½±å“ç»“æœã€‚</li>
<li>ç¯å¢ƒå¤æ‚æ€§å¯¼è‡´æœç´¢è¡Œä¸ºè„†å¼±ï¼Œå½±å“æ•´ä½“æ€§èƒ½ã€‚</li>
<li>RE-Searcheré€šè¿‡æ˜ç¡®å…·ä½“æœç´¢ç›®æ ‡å’Œåæ€æ£€ç´¢è¯æ®æ¥æ»¡è¶³ç›®æ ‡æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>RE-Searcherç»“åˆç›®æ ‡å¯¼å‘è§„åˆ’åŠè‡ªæˆ‘åæ€ï¼Œèƒ½åœ¨å¤æ‚ç¯å¢ƒä¸­ç¨³å¥æœç´¢ã€‚</li>
<li>å®éªŒè¯æ˜RE-Searcheræé«˜äº†æœç´¢å‡†ç¡®æ€§å¹¶è¾¾åˆ°æœ€æ–°ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26048">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3975fb56c9121bce6072cfcb9ced982" align="middle">
<img src="https://picx.zhimg.com/v2-6ff9f1e956aa3bb7a5b321a980b8ff5b" align="middle">
<img src="https://picx.zhimg.com/v2-f7ce74d75715e8a6be680b7b44379f44" align="middle">
<img src="https://picx.zhimg.com/v2-0fbc1686178c715a04ac817f8910439d" align="middle">
<img src="https://picx.zhimg.com/v2-2186a17d3cb4f6d950f0e485ae8836e5" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="MASLegalBench-Benchmarking-Multi-Agent-Systems-in-Deductive-Legal-Reasoning"><a href="#MASLegalBench-Benchmarking-Multi-Agent-Systems-in-Deductive-Legal-Reasoning" class="headerlink" title="MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal   Reasoning"></a>MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal   Reasoning</h2><p><strong>Authors:Huihao Jing, Wenbin Hu, Hongyu Luo, Jianhui Yang, Wei Fan, Haoran Li, Yangqiu Song</strong></p>
<p>Multi-agent systems (MAS), leveraging the remarkable capabilities of Large Language Models (LLMs), show great potential in addressing complex tasks. In this context, integrating MAS with legal tasks is a crucial step. While previous studies have developed legal benchmarks for LLM agents, none are specifically designed to consider the unique advantages of MAS, such as task decomposition, agent specialization, and flexible training. In fact, the lack of evaluation methods limits the potential of MAS in the legal domain. To address this gap, we propose MASLegalBench, a legal benchmark tailored for MAS and designed with a deductive reasoning approach. Our benchmark uses GDPR as the application scenario, encompassing extensive background knowledge and covering complex reasoning processes that effectively reflect the intricacies of real-world legal situations. Furthermore, we manually design various role-based MAS and conduct extensive experiments using different state-of-the-art LLMs. Our results highlight the strengths, limitations, and potential areas for improvement of existing models and MAS architectures. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºè‰²èƒ½åŠ›ï¼Œåœ¨åº”å¯¹å¤æ‚ä»»åŠ¡æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œå°†MASä¸æ³•å¾‹ä»»åŠ¡é›†æˆæ˜¯é‡è¦çš„ä¸€æ­¥ã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶å·²ç»ä¸ºLLMä»£ç†å¼€å‘äº†æ³•å¾‹åŸºå‡†ï¼Œä½†æ²¡æœ‰ä¸€ä¸ªæ˜¯ä¸“é—¨è€ƒè™‘MASçš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œå¦‚ä»»åŠ¡åˆ†è§£ã€ä»£ç†ä¸“ä¸šåŒ–å’Œçµæ´»è®­ç»ƒã€‚äº‹å®ä¸Šï¼Œç¼ºä¹è¯„ä¼°æ–¹æ³•é™åˆ¶äº†MASåœ¨æ³•å¾‹é¢†åŸŸçš„æ½œåŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºMASLegalBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºMASå®šåˆ¶çš„æ³•å¾‹åŸºå‡†ï¼Œé‡‡ç”¨æ¼”ç»æ¨ç†æ–¹æ³•è®¾è®¡ã€‚æˆ‘ä»¬çš„åŸºå‡†ä»¥GDPRä¸ºåº”ç”¨åœºæ™¯ï¼ŒåŒ…å«ä¸°å¯Œçš„èƒŒæ™¯çŸ¥è¯†ï¼Œæ¶µç›–æœ‰æ•ˆçš„å¤æ‚æ¨ç†è¿‡ç¨‹ï¼Œå……åˆ†åæ˜ äº†ç°å®æ³•å¾‹æƒ…å†µçš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ‰‹åŠ¨è®¾è®¡äº†å„ç§åŸºäºè§’è‰²çš„MASï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„æœ€æ–°LLMè¿›è¡Œå¹¿æ³›å®éªŒã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†ç°æœ‰æ¨¡å‹å’ŒMASæ¶æ„çš„ä¼˜åŠ¿ã€å±€é™æ€§å’Œæ½œåœ¨çš„æ”¹è¿›é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24922v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºè‰²èƒ½åŠ›ï¼Œåœ¨è§£å†³å¤æ‚ä»»åŠ¡æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚æœ¬æ–‡å°†MASä¸æ³•åŠ¡ä»»åŠ¡ç›¸ç»“åˆæ˜¯å…³é”®ä¸€æ­¥ã€‚è™½ç„¶å·²æœ‰æ³•åŠ¡åŸºå‡†ç”¨äºè¯„ä¼°LLMä»£ç†ï¼Œä½†æ²¡æœ‰ç‰¹å®šè€ƒè™‘MASçš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œå¦‚ä»»åŠ¡åˆ†è§£ã€ä»£ç†ä¸“ä¸šåŒ–å’Œçµæ´»è®­ç»ƒç­‰ã€‚ä¸ºè§£å†³æ­¤è¯„ä¼°æ–¹æ³•ç¼ºå¤±çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºMASLegalBenchï¼Œä¸€ä¸ªä¸“ä¸ºMASè®¾è®¡çš„æ³•åŠ¡åŸºå‡†ï¼Œé‡‡ç”¨æ¼”ç»æ¨ç†æ–¹æ³•ã€‚æ­¤åŸºå‡†ä»¥GDPRä¸ºåº”ç”¨åœºæ™¯ï¼ŒåŒ…å«ä¸°å¯Œçš„èƒŒæ™¯çŸ¥è¯†ï¼Œå¹¶èƒ½æœ‰æ•ˆåæ˜ ç°å®æ³•å¾‹æƒ…å¢ƒçš„å¤æ‚æ€§ã€‚åŒæ—¶ï¼Œæœ¬æ–‡é€šè¿‡ä¸åŒå…ˆè¿›çš„LLMè¿›è¡Œå¤§é‡å®éªŒï¼Œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹å’ŒMASæ¶æ„çš„ä¼˜åŠ¿ã€å±€é™æ€§å’Œæ½œåœ¨çš„æ”¹è¿›æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»“åˆåœ¨è§£å†³å¤æ‚ä»»åŠ¡æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>å°†MASåº”ç”¨äºæ³•å¾‹ä»»åŠ¡æ˜¯å…³é”®ä¸€æ­¥ï¼Œä½†ç°æœ‰çš„æ³•å¾‹åŸºå‡†æœªå……åˆ†è€ƒè™‘MASçš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚</li>
<li>ç¼ºå°‘é’ˆå¯¹MASçš„è¯„ä¼°æ–¹æ³•é™åˆ¶äº†å…¶åœ¨æ³•å¾‹é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚</li>
<li>æå‡ºMASLegalBenchï¼Œä¸€ä¸ªä¸“ä¸ºMASè®¾è®¡çš„æ³•å¾‹åŸºå‡†ï¼Œé‡‡ç”¨æ¼”ç»æ¨ç†æ–¹æ³•ã€‚</li>
<li>MASLegalBenchä»¥GDPRä¸ºåº”ç”¨åœºæ™¯ï¼ŒåŒ…å«ä¸°å¯Œçš„èƒŒæ™¯çŸ¥è¯†ï¼Œæœ‰æ•ˆåæ˜ ç°å®æ³•å¾‹æƒ…å¢ƒçš„å¤æ‚æ€§ã€‚</li>
<li>é€šè¿‡å¤§é‡å®éªŒæ­ç¤ºäº†ç°æœ‰æ¨¡å‹å’ŒMASæ¶æ„çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-41324f4c802518bd72bce6d67d6b8271" align="middle">
<img src="https://picx.zhimg.com/v2-11071a74e7cb408cd1b3b5c178f00d6e" align="middle">
<img src="https://picx.zhimg.com/v2-6678d96a90341802ab220f32f5831761" align="middle">
<img src="https://picx.zhimg.com/v2-86c2c517cbc4d5d106c3ac2e8ac49fbe" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Sequence-Pathfinder-for-Multi-Agent-Pickup-and-Delivery-in-the-Warehouse"><a href="#Sequence-Pathfinder-for-Multi-Agent-Pickup-and-Delivery-in-the-Warehouse" class="headerlink" title="Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse"></a>Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse</h2><p><strong>Authors:Zeyuan Zhao, Chaoran Li, Shao Zhang, Ying Wen</strong></p>
<p>Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of Multi-Agent Path Finding (MAPF), where agents are required to sequentially complete tasks with fixed-location pickup and delivery demands. Although learning-based methods have made progress in MAPD, they often perform poorly in warehouse-like environments with narrow pathways and long corridors when relying only on local observations for distributed decision-making. Communication learning can alleviate the lack of global information but introduce high computational complexity due to point-to-point communication. To address this challenge, we formulate MAPF as a sequence modeling problem and prove that path-finding policies under sequence modeling possess order-invariant optimality, ensuring its effectiveness in MAPD. Building on this, we propose the Sequential Pathfinder (SePar), which leverages the Transformer paradigm to achieve implicit information exchange, reducing decision-making complexity from exponential to linear while maintaining efficiency and global awareness. Experiments demonstrate that SePar consistently outperforms existing learning-based methods across various MAPF tasks and their variants, and generalizes well to unseen environments. Furthermore, we highlight the necessity of integrating imitation learning in complex maps like warehouses. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“æ¥é€ä»»åŠ¡ï¼ˆMAPDï¼‰æ˜¯å¤šæ™ºèƒ½ä½“è·¯å¾„æŸ¥æ‰¾ï¼ˆMAPFï¼‰çš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ‰©å±•ï¼Œå…¶ä¸­è¦æ±‚æ™ºèƒ½ä½“æŒ‰é¡ºåºå®Œæˆå…·æœ‰å›ºå®šä½ç½®æ¥é€éœ€æ±‚çš„ä»»åŠ¡ã€‚å°½ç®¡åŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨MAPDä¸­å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨ä»“åº“ç­‰ç¯å¢ƒä¸­ï¼Œå½“ä»…ä¾é å±€éƒ¨è§‚å¯Ÿè¿›è¡Œåˆ†å¸ƒå¼å†³ç­–æ—¶ï¼Œå®ƒä»¬åœ¨ç‹­çª„é€šé“å’Œé•¿èµ°å»Šä¸­çš„è¡¨ç°å¾€å¾€ä¸ä½³ã€‚é€šä¿¡å­¦ä¹ å¯ä»¥ç¼“è§£ç¼ºä¹å…¨å±€ä¿¡æ¯çš„é—®é¢˜ï¼Œä½†ç”±äºç‚¹å¯¹ç‚¹é€šä¿¡è€Œå¼•å…¥äº†è¾ƒé«˜çš„è®¡ç®—å¤æ‚åº¦ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å°†MAPFåˆ¶å®šä¸ºåºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œå¹¶è¯æ˜åºåˆ—å»ºæ¨¡ä¸‹çš„è·¯å¾„æŸ¥æ‰¾ç­–ç•¥å…·æœ‰é¡ºåºä¸å˜çš„æœ€ä¼˜æ€§ï¼Œç¡®ä¿å…¶é€‚ç”¨äºMAPDã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†Sequential Pathfinderï¼ˆSeParï¼‰ï¼Œå®ƒåˆ©ç”¨TransformerèŒƒå¼å®ç°éšå¼ä¿¡æ¯äº¤æ¢ï¼Œå°†å†³ç­–å¤æ‚æ€§ä»æŒ‡æ•°çº§é™ä½åˆ°çº¿æ€§ï¼ŒåŒæ—¶ä¿æŒæ•ˆç‡å’Œå…¨å±€æ„è¯†ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å„ç§MAPFä»»åŠ¡åŠå…¶å˜ç§ä¸­ï¼ŒSeParå§‹ç»ˆä¼˜äºç°æœ‰çš„åŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¾ˆå¥½åœ°æ¨å¹¿åˆ°æœªè§è¿‡çš„ç¯å¢ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†åœ¨åƒä»“åº“è¿™æ ·çš„å¤æ‚åœ°å›¾ä¸­é›†æˆæ¨¡ä»¿å­¦ä¹ çš„å¿…è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23778v2">PDF</a> Preprint Under Review</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä¸»è¦è®¨è®ºäº†åœ¨å¤šæ™ºèƒ½ä½“è·¯å¾„å¯»æ‰¾ï¼ˆMAPFï¼‰åŸºç¡€ä¸Šæå‡ºçš„æŒ‘æˆ˜æ€§æ‰©å±•ä»»åŠ¡â€”â€”å¤šæ™ºèƒ½ä½“æ‹¾å–ä¸é…é€ï¼ˆMAPDï¼‰ã€‚é’ˆå¯¹ä»“åº“ç­‰ç¯å¢ƒï¼Œæ–‡æœ¬æå‡ºå°†MAPFå»ºæ¨¡ä¸ºåºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œå¹¶åˆ©ç”¨åºåˆ—å»ºæ¨¡çš„ä¼˜åŠ¿è®¾è®¡äº†ä¸€ç§åä¸ºSequential Pathfinderï¼ˆSeParï¼‰çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆTransformerèŒƒå¼å®ç°éšæ€§ä¿¡æ¯äº¤æ¢ï¼Œé™ä½äº†å†³ç­–å¤æ‚æ€§ï¼ŒåŒæ—¶ä¿æŒäº†æ•ˆç‡å’Œå…¨å±€æ„è¯†ã€‚å®éªŒè¡¨æ˜ï¼ŒSeParåœ¨å„ç§MAPFä»»åŠ¡åŠå…¶å˜ç§ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶èƒ½å¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„ç¯å¢ƒã€‚æ­¤å¤–ï¼Œæ–‡ç« å¼ºè°ƒäº†å¤æ‚åœ°å›¾å¦‚ä»“åº“ä¸­é›†æˆæ¨¡ä»¿å­¦ä¹ çš„å¿…è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“æ‹¾å–ä¸é…é€ï¼ˆMAPDï¼‰æ˜¯å¤šæ™ºèƒ½ä½“è·¯å¾„å¯»æ‰¾ï¼ˆMAPFï¼‰çš„æŒ‘æˆ˜æ€§æ‰©å±•ã€‚</li>
<li>åœ¨ä»“åº“ç­‰ç¯å¢ƒä¸­ï¼ŒåŸºäºå±€éƒ¨è§‚å¯Ÿçš„å­¦ä¹ æ–¹æ³•è¡¨ç°ä¸ä½³ã€‚</li>
<li>é€šä¿¡å­¦ä¹ å¯ä»¥ç¼“è§£ç¼ºä¹å…¨å±€ä¿¡æ¯çš„é—®é¢˜ï¼Œä½†è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ã€‚</li>
<li>å°†MAPFå»ºæ¨¡ä¸ºåºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œè·¯å¾„æŸ¥æ‰¾ç­–ç•¥å…·æœ‰é¡ºåºä¸å˜çš„æœ€ä¼˜æ€§ã€‚</li>
<li>Sequential Pathfinderï¼ˆSeParï¼‰åˆ©ç”¨TransformerèŒƒå¼å®ç°éšæ€§ä¿¡æ¯äº¤æ¢ï¼Œé™ä½å†³ç­–å¤æ‚æ€§ã€‚</li>
<li>SeParåœ¨å„ç§MAPFä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶èƒ½å¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„ç¯å¢ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23778">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-93ea497da2c2545610d5b42770d0ecec" align="middle">
<img src="https://picx.zhimg.com/v2-9dcaa13f9706835cdf4b8b589588311a" align="middle">
<img src="https://picx.zhimg.com/v2-ce982d3d13140cf14c8b91c6b25cc4ab" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="InfiAgent-Self-Evolving-Pyramid-Agent-Framework-for-Infinite-Scenarios"><a href="#InfiAgent-Self-Evolving-Pyramid-Agent-Framework-for-Infinite-Scenarios" class="headerlink" title="InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios"></a>InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios</h2><p><strong>Authors:Chenglin Yu, Yang Yu, Songmiao Wang, Yucheng Wang, Yifan Yang, Jinjia Li, Ming Li, Hongxia Yang</strong></p>
<p>Large Language Model (LLM) agents have demonstrated remarkable capabilities in organizing and executing complex tasks, and many such agents are now widely used in various application scenarios. However, developing these agents requires carefully designed workflows, carefully crafted prompts, and iterative tuning, which requires LLM techniques and domain-specific expertise. These hand-crafted limitations hinder the scalability and cost-effectiveness of LLM agents across a wide range of industries. To address these challenges, we propose \textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that can be applied to \textbf{infi}nite scenarios, which introduces several key innovations: a generalized â€œagent-as-a-toolâ€ mechanism that automatically decomposes complex agents into hierarchical multi-agent systems; a dual-audit mechanism that ensures the quality and stability of task completion; an agent routing function that enables efficient task-agent matching; and an agent self-evolution mechanism that autonomously restructures the agent DAG based on new tasks, poor performance, or optimization opportunities. Furthermore, InfiAgentâ€™s atomic task design supports agent parallelism, significantly improving execution efficiency. This framework evolves into a versatile pyramid-like multi-agent system capable of solving a wide range of problems. Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9% higher performance compared to ADAS (similar auto-generated agent framework), while a case study of the AI research assistant InfiHelper shows that it generates scientific papers that have received recognition from human reviewers at top-tier IEEE conferences. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨ç»„ç»‡å’Œæ‰§è¡Œå¤æ‚ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ï¼Œå¹¶ä¸”è®¸å¤šè¿™æ ·çš„ä»£ç†ç°åœ¨å·²å¹¿æ³›åº”ç”¨äºå„ç§åº”ç”¨åœºæ™¯ã€‚ç„¶è€Œï¼Œå¼€å‘è¿™äº›ä»£ç†éœ€è¦ç²¾å¿ƒè®¾è®¡çš„å·¥ä½œæµç¨‹ã€ç²¾å¿ƒåˆ¶ä½œçš„æç¤ºå’Œè¿­ä»£è°ƒæ•´ï¼Œè¿™éœ€è¦LLMæŠ€æœ¯å’Œç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ã€‚è¿™äº›æ‰‹å·¥åˆ¶ä½œçš„å±€é™æ€§é˜»ç¢äº†LLMä»£ç†åœ¨å¹¿æ³›è¡Œä¸šä¸­çš„å¯æ‰©å±•æ€§å’Œæˆæœ¬æ•ˆç›Šã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>InfiAgent</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé‡‘å­—å¡”å¼çš„DAGå¤šä»£ç†æ¡†æ¶ï¼Œå¯åº”ç”¨äº<strong>æ— é™</strong>åœºæ™¯ï¼Œå®ƒå¼•å…¥äº†å‡ é¡¹å…³é”®åˆ›æ–°ï¼šä¸€ç§é€šç”¨çš„â€œä»£ç†ä½œä¸ºå·¥å…·â€æœºåˆ¶ï¼Œå¯è‡ªåŠ¨å°†å¤æ‚ä»£ç†åˆ†è§£ä¸ºåˆ†å±‚çš„å¤šä»£ç†ç³»ç»Ÿï¼›ä¸€ç§åŒé‡å®¡è®¡æœºåˆ¶ï¼Œç¡®ä¿ä»»åŠ¡å®Œæˆçš„å“è´¨å’Œç¨³å®šæ€§ï¼›ä¸€ä¸ªä»£ç†è·¯ç”±åŠŸèƒ½ï¼Œèƒ½å¤Ÿå®ç°é«˜æ•ˆçš„ä»»åŠ¡-ä»£ç†åŒ¹é…ï¼›ä»¥åŠä¸€ä¸ªä»£ç†è‡ªæˆ‘è¿›åŒ–æœºåˆ¶ï¼Œèƒ½å¤ŸåŸºäºæ–°ä»»åŠ¡ã€æ€§èƒ½ä¸ä½³æˆ–ä¼˜åŒ–æœºä¼šè‡ªä¸»é‡ç»„ä»£ç†DAGã€‚æ­¤å¤–ï¼ŒInfiAgentçš„åŸå­ä»»åŠ¡è®¾è®¡æ”¯æŒä»£ç†å¹¶è¡Œæ€§ï¼Œå¤§å¤§æé«˜äº†æ‰§è¡Œæ•ˆç‡ã€‚è¯¥æ¡†æ¶æ¼”å˜æˆä¸ºä¸€ä¸ªé€šç”¨çš„é‡‘å­—å¡”å¼å¤šä»£ç†ç³»ç»Ÿï¼Œèƒ½å¤Ÿè§£å†³ä¸€ç³»åˆ—å¹¿æ³›çš„é—®é¢˜ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒInfiAgentä¸ADASï¼ˆç±»ä¼¼çš„è‡ªåŠ¨ç”Ÿæˆä»£ç†æ¡†æ¶ï¼‰ç›¸æ¯”ï¼Œæ€§èƒ½æé«˜äº†9.9%ã€‚InfiHelperï¼ˆäººå·¥æ™ºèƒ½ç ”ç©¶åŠ©ç†çš„æ¡ˆä¾‹åˆ†æï¼‰ç”Ÿæˆçš„ç§‘å­¦è®ºæ–‡å¾—åˆ°äº†é¡¶çº§IEEEä¼šè®®çš„äººç±»è¯„å®¡è€…çš„è®¤å¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22502v2">PDF</a> 9 pages of main content and 32 pages of others, 2 figures, under   review as a conference paper at ICLR 2026</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨ç»„ç»‡æ‰§è¡Œå¤æ‚ä»»åŠ¡æ–¹é¢å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œå¹¶å¹¿æ³›åº”ç”¨äºå¤šç§åº”ç”¨åœºæ™¯ã€‚ç„¶è€Œï¼Œå¼€å‘è¿™äº›ä»£ç†éœ€è¦ç²¾å¿ƒè®¾è®¡çš„å·¥ä½œæµç¨‹ã€æç¤ºå’Œè¿­ä»£è°ƒæ•´ï¼Œè¿™éœ€è¦LLMæŠ€æœ¯å’Œç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ã€‚ä¸ºè§£å†³æ‰‹åŠ¨æ„å»ºçš„å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†InfiAgentï¼Œä¸€ä¸ªåŸºäºé‡‘å­—å¡”å‹DAGçš„å¤šä»£ç†æ¡†æ¶ï¼Œå¯åº”ç”¨äºæ— é™åœºæ™¯ã€‚å®ƒå¼•å…¥äº†å‡ ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šé€šç”¨çš„â€œä»£ç†å³å·¥å…·â€æœºåˆ¶ï¼Œè‡ªåŠ¨å°†å¤æ‚ä»£ç†åˆ†è§£ä¸ºåˆ†å±‚çš„å¤šä»£ç†ç³»ç»Ÿï¼›åŒå®¡è®¡æœºåˆ¶ç¡®ä¿ä»»åŠ¡å®Œæˆçš„å“è´¨å’Œç¨³å®šæ€§ï¼›ä»£ç†è·¯ç”±åŠŸèƒ½å®ç°é«˜æ•ˆçš„ä»»åŠ¡-ä»£ç†åŒ¹é…ï¼›ä»£ç†è‡ªæˆ‘è¿›åŒ–æœºåˆ¶å¯åŸºäºæ–°ä»»åŠ¡ã€æ€§èƒ½ä¸ä½³æˆ–ä¼˜åŒ–æœºä¼šè‡ªä¸»é‡ç»„ä»£ç†DAGã€‚è¯„ä¼°è¡¨æ˜ï¼ŒInfiAgentç›¸è¾ƒäºç±»ä¼¼çš„è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç†æ¡†æ¶ADASï¼Œæ€§èƒ½æé«˜äº†9.9%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMä»£ç†åœ¨ç»„ç»‡æ‰§è¡Œå¤æ‚ä»»åŠ¡æ–¹é¢å…·æœ‰å“è¶Šèƒ½åŠ›ï¼Œå¹¿æ³›åº”ç”¨äºå¤šä¸ªè¡Œä¸šã€‚</li>
<li>å¼€å‘LLMä»£ç†éœ€è¦ç²¾å¿ƒè®¾è®¡çš„å·¥ä½œæµç¨‹ã€æç¤ºå’Œè¿­ä»£è°ƒæ•´ï¼Œéœ€å…·å¤‡LLMæŠ€æœ¯å’Œç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ã€‚</li>
<li>æ‰‹åŠ¨æ„å»ºçš„å±€é™æ€§å½±å“äº†LLMä»£ç†çš„å¯æ‰©å±•æ€§å’Œæˆæœ¬æ•ˆç›Šã€‚</li>
<li>InfiAgentæ¡†æ¶è¢«æå‡ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºé‡‘å­—å¡”å‹DAGçš„å¤šä»£ç†æ¡†æ¶ï¼Œé€‚ç”¨äºæ— é™åœºæ™¯ã€‚</li>
<li>InfiAgentå¼•å…¥äº†å‡ ä¸ªå…³é”®åˆ›æ–°ï¼ŒåŒ…æ‹¬â€œä»£ç†å³å·¥å…·â€æœºåˆ¶ã€åŒå®¡è®¡æœºåˆ¶ã€ä»£ç†è·¯ç”±åŠŸèƒ½å’Œä»£ç†è‡ªæˆ‘è¿›åŒ–æœºåˆ¶ã€‚</li>
<li>InfiAgentæ¡†æ¶å…·æœ‰è‡ªåŠ¨åˆ†è§£å¤æ‚ä»£ç†ã€ä¿è¯ä»»åŠ¡å®Œæˆè´¨é‡ã€é«˜æ•ˆä»»åŠ¡-ä»£ç†åŒ¹é…å’Œè‡ªä¸»é‡ç»„ç­‰ç‰¹æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22502">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-437fd3d19cdba737cb0ba1ea1aae3d83" align="middle">
<img src="https://picx.zhimg.com/v2-d3c224f4a234349c51c257d8a7488eb1" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use"><a href="#VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use" class="headerlink" title="VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use"></a>VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use</h2><p><strong>Authors:Dongfu Jiang, Yi Lu, Zhuofeng Li, Zhiheng Lyu, Ping Nie, Haozhe Wang, Alex Su, Hui Chen, Kai Zou, Chao Du, Tianyu Pang, Wenhu Chen</strong></p>
<p>Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated success in enhancing LLM reasoning capabilities, but remains limited to single-turn interactions without tool integration. While recent Agentic Reinforcement Learning with Tool use (ARLT) approaches have emerged to address multi-turn tool interactions, existing works develop task-specific codebases that suffer from fragmentation, synchronous execution bottlenecks, and limited extensibility across domains. These inefficiencies hinder broader community adoption and algorithmic innovation. We introduce VerlTool, a unified and modular framework that addresses these limitations through systematic design principles. VerlTool provides four key contributions: (1) upstream alignment with VeRL ensuring compatibility and simplified maintenance, (2) unified tool management via standardized APIs supporting diverse modalities including code execution, search, SQL databases, and vision processing, (3) asynchronous rollout execution achieving near 2$\times$ speedup by eliminating synchronization bottlenecks, and (4) comprehensive evaluation demonstrating competitive performance across 6 ARLT domains. Our framework formalizes ARLT as multi-turn trajectories with multi-modal observation tokens (text&#x2F;image&#x2F;video), extending beyond single-turn RLVR paradigms. We train and evaluate models on mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web search, and software engineering tasks, achieving results comparable to specialized systems while providing unified training infrastructure. The modular plugin architecture enables rapid tool integration requiring only lightweight Python definitions, significantly reducing development overhead and providing a scalable foundation for tool-augmented RL research. Our code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/TIGER-AI-Lab/verl-tool">https://github.com/TIGER-AI-Lab/verl-tool</a>. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰å·²æˆåŠŸæé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½†ä»å±€é™äºæ²¡æœ‰å·¥å…·é›†æˆçš„å•è½®äº¤äº’ã€‚è™½ç„¶æœ€è¿‘å‡ºç°äº†å·¥å…·ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆARLTï¼‰çš„æ–¹æ³•æ¥è§£å†³å¤šè½®å·¥å…·äº¤äº’é—®é¢˜ï¼Œä½†ç°æœ‰å·¥ä½œå¼€å‘äº†ä»»åŠ¡ç‰¹å®šçš„ä»£ç åº“ï¼Œå­˜åœ¨ç¢ç‰‡åŒ–ã€åŒæ­¥æ‰§è¡Œç“¶é¢ˆä»¥åŠè·¨åŸŸæ‰©å±•æ€§æœ‰é™ç­‰ç¼ºç‚¹ã€‚è¿™äº›ä½æ•ˆæ€§é˜»ç¢äº†æ›´å¹¿æ³›çš„ç¤¾åŒºé‡‡çº³å’Œç®—æ³•åˆ›æ–°ã€‚æˆ‘ä»¬å¼•å…¥äº†VerlToolï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€å’Œæ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œé€šè¿‡ç³»ç»Ÿè®¾è®¡åŸåˆ™æ¥è§£å†³è¿™äº›é™åˆ¶ã€‚VerlToolæä¾›äº†å››ä¸ªä¸»è¦è´¡çŒ®ï¼šï¼ˆ1ï¼‰ä¸VeRLçš„ä¸Šæ¸¸å¯¹é½ï¼Œç¡®ä¿å…¼å®¹æ€§å¹¶ç®€åŒ–ç»´æŠ¤ï¼›ï¼ˆ2ï¼‰é€šè¿‡æ ‡å‡†åŒ–APIè¿›è¡Œç»Ÿä¸€å·¥å…·ç®¡ç†ï¼Œæ”¯æŒå¤šç§æ¨¡å¼ï¼ŒåŒ…æ‹¬ä»£ç æ‰§è¡Œã€æœç´¢ã€SQLæ•°æ®åº“å’Œè§†è§‰å¤„ç†ç­‰ï¼›ï¼ˆ3ï¼‰å®ç°å¼‚æ­¥æ¨å‡ºæ‰§è¡Œï¼Œé€šè¿‡æ¶ˆé™¤åŒæ­¥ç“¶é¢ˆå®ç°è¿‘2å€çš„é€Ÿåº¦æå‡ï¼›ï¼ˆ4ï¼‰å…¨é¢è¯„ä¼°ï¼Œåœ¨6ä¸ªARLTé¢†åŸŸå±•ç¤ºå…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†ARLTå½¢å¼åŒ–ä¸ºå¤šè½®è½¨è¿¹ï¼Œå…·æœ‰å¤šæ¨¡æ€è§‚å¯Ÿä»¤ç‰Œï¼ˆæ–‡æœ¬&#x2F;å›¾åƒ&#x2F;è§†é¢‘ï¼‰ï¼Œè¶…è¶Šäº†å•è½®RLVRèŒƒå¼ã€‚æˆ‘ä»¬åœ¨æ•°å­¦æ¨ç†ã€çŸ¥è¯†é—®ç­”ã€SQLç”Ÿæˆã€è§†è§‰æ¨ç†ã€ç½‘ç»œæœç´¢å’Œè½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œè™½ç„¶ç»“æœå¯ä¸ä¸“ä¸šç³»ç»Ÿç›¸æ¯”ï¼Œä½†æä¾›äº†ç»Ÿä¸€çš„è®­ç»ƒåŸºç¡€è®¾æ–½ã€‚æ¨¡å—åŒ–çš„æ’ä»¶æ¶æ„å¯ä»¥å¿«é€Ÿé›†æˆå·¥å…·ï¼Œåªéœ€è¦è½»é‡çº§çš„Pythonå®šä¹‰ï¼Œå¤§å¤§é™ä½äº†å¼€å‘æˆæœ¬ï¼Œä¸ºå·¥å…·å¢å¼ºå‹RLç ”ç©¶æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ã€‚æˆ‘ä»¬çš„ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/TIGER-AI-Lab/verl-tool%E3%80%82">https://github.com/TIGER-AI-Lab/verl-toolã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01055v2">PDF</a> 32 pages, 5 figures, 13 tables</p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æˆåŠŸï¼Œä½†ä»å±€é™äºæ²¡æœ‰å·¥å…·é›†æˆçš„å•è½®äº¤äº’ã€‚è™½ç„¶æœ€è¿‘å‡ºç°äº†å·¥å…·ä½¿ç”¨çš„ä»£ç†å¼ºåŒ–å­¦ä¹ ï¼ˆARLTï¼‰æ–¹æ³•æ¥è§£å†³å¤šè½®å·¥å…·äº¤äº’é—®é¢˜ï¼Œä½†ç°æœ‰å·¥ä½œå¼€å‘çš„ä»»åŠ¡ç‰¹å®šä»£ç åº“å­˜åœ¨ç¢ç‰‡åŒ–ã€åŒæ­¥æ‰§è¡Œç“¶é¢ˆå’Œè·¨åŸŸæ‰©å±•æ€§æœ‰é™ç­‰ç¼ºç‚¹ã€‚æˆ‘ä»¬å¼•å…¥VerlToolï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€å’Œæ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œé€šè¿‡ç³»ç»Ÿçš„è®¾è®¡åŸåˆ™æ¥è§£å†³è¿™äº›é™åˆ¶ã€‚VerlToolæä¾›å››ä¸ªå…³é”®è´¡çŒ®ï¼šä¸VeRLçš„ä¸Šæ¸¸å¯¹é½ç¡®ä¿å…¼å®¹æ€§å¹¶ç®€åŒ–ç»´æŠ¤ã€é€šè¿‡æ ‡å‡†åŒ–APIè¿›è¡Œç»Ÿä¸€å·¥å…·ç®¡ç†æ”¯æŒå¤šç§æ¨¡å¼åŒ…æ‹¬ä»£ç æ‰§è¡Œã€æœç´¢ã€SQLæ•°æ®åº“å’Œè§†è§‰å¤„ç†ã€å¼‚æ­¥æ¨å‡ºæ‰§è¡Œå®ç°è¿‘ä¸¤å€é€Ÿçš„æé«˜é€šè¿‡æ¶ˆé™¤åŒæ­¥ç“¶é¢ˆã€å…¨é¢çš„è¯„ä¼°åœ¨6ä¸ªARLTé¢†åŸŸè¡¨ç°å‡ºæœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†ARLTå½¢å¼åŒ–ä¸ºå¤šè½®è½¨è¿¹ä¸å¤šæ¨¡æ€è§‚å¯Ÿä»¤ç‰Œï¼ˆæ–‡æœ¬&#x2F;å›¾åƒ&#x2F;è§†é¢‘ï¼‰ï¼Œè¶…è¶Šäº†å•è½®RLVRèŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLVRåœ¨æå‡LLMæ¨ç†èƒ½åŠ›ä¸Šå–å¾—è¿›å±•ï¼Œä½†ä»…é™äºå•è½®äº¤äº’ã€‚</li>
<li>ARLTæ–¹æ³•è§£å†³äº†å¤šè½®å·¥å…·äº¤äº’é—®é¢˜ï¼Œä½†ç°æœ‰å·¥ä½œå­˜åœ¨ç¢ç‰‡åŒ–ã€åŒæ­¥æ‰§è¡Œç“¶é¢ˆå’Œè·¨åŸŸæ‰©å±•æ€§é—®é¢˜ã€‚</li>
<li>VerlToolæ¡†æ¶é€šè¿‡ç»Ÿä¸€å’Œæ¨¡å—åŒ–è®¾è®¡è§£å†³è¿™äº›é—®é¢˜ï¼Œä¸VeRLå¯¹é½ã€ç»Ÿä¸€å·¥å…·ç®¡ç†ã€å¼‚æ­¥æ‰§è¡Œä»¥æé«˜é€Ÿåº¦ã€‚</li>
<li>VerlToolæä¾›æ ‡å‡†åŒ–APIæ”¯æŒå¤šç§å·¥å…·æ¨¡å¼ï¼ŒåŒ…æ‹¬ä»£ç æ‰§è¡Œã€æœç´¢ã€SQLæ•°æ®åº“å’Œè§†è§‰å¤„ç†ã€‚</li>
<li>VerlToolå®ç°å…¨é¢çš„è¯„ä¼°ï¼Œåœ¨å¤šä¸ªé¢†åŸŸè¡¨ç°å‡ºç«äº‰åŠ›ï¼ŒåŒ…æ‹¬æ•°å­¦æ¨ç†ã€çŸ¥è¯†é—®ç­”ã€SQLç”Ÿæˆã€è§†è§‰æ¨ç†ã€ç½‘ç»œæœç´¢å’Œè½¯ä»¶å·¥ç¨‹ä»»åŠ¡ã€‚</li>
<li>VerlToolçš„æ¨¡å—åŒ–æ’ä»¶æ¶æ„ä¾¿äºå¿«é€Ÿå·¥å…·é›†æˆï¼Œåªéœ€è½»é‡çº§Pythonå®šä¹‰ï¼Œå‡å°‘å¼€å‘æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01055">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5b3b17147399209504612220dec50ec1" align="middle">
<img src="https://picx.zhimg.com/v2-b67d2ee4f23ae4fbe3ef00513f1dcf39" align="middle">
<img src="https://picx.zhimg.com/v2-fda67b37666c6068a9aa60edc10374ac" align="middle">
<img src="https://picx.zhimg.com/v2-e695e9f3902bd8d2e3f07ea8d24a6a92" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="GraphCogent-Mitigating-LLMsâ€™-Working-Memory-Constraints-via-Multi-Agent-Collaboration-in-Complex-Graph-Understanding"><a href="#GraphCogent-Mitigating-LLMsâ€™-Working-Memory-Constraints-via-Multi-Agent-Collaboration-in-Complex-Graph-Understanding" class="headerlink" title="GraphCogent: Mitigating LLMsâ€™ Working Memory Constraints via Multi-Agent   Collaboration in Complex Graph Understanding"></a>GraphCogent: Mitigating LLMsâ€™ Working Memory Constraints via Multi-Agent   Collaboration in Complex Graph Understanding</h2><p><strong>Authors:Rongzheng Wang, Shuang Liang, Qizhi Chen, Yihong Huang, Muquan Li, Yizhuo Ma, Dongyang Zhang, Ke Qin, Man-Fai Leung</strong></p>
<p>Large language models (LLMs) show promising performance on small-scale graph reasoning tasks but fail when handling real-world graphs with complex queries. This phenomenon arises from LLMsâ€™ working memory constraints, which result in their inability to retain long-range graph topology over extended contexts while sustaining coherent multi-step reasoning. However, real-world graphs are often structurally complex, such as Web, Transportation, Social, and Citation networks. To address these limitations, we propose GraphCogent, a collaborative agent framework inspired by human Working Memory Model that decomposes graph reasoning into specialized cognitive processes: sense, buffer, and execute. The framework consists of three modules: Sensory Module standardizes diverse graph text representations via subgraph sampling, Buffer Module integrates and indexes graph data across multiple formats, and Execution Module combines tool calling and tool creation for efficient reasoning. We also introduce Graph4real, a comprehensive benchmark that contains four domains of real-world graphs (Web, Transportation, Social, and Citation) to evaluate LLMsâ€™ graph reasoning capabilities. Our Graph4real covers 21 different graph reasoning tasks, categorized into three types (Structural Querying, Algorithmic Reasoning, and Predictive Modeling tasks), with graph scales up to 10 times larger than existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B). Compared to state-of-the-art agent-based baseline, our framework outperforms by 20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30% for out-toolset tasks. Code will be available after review. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å°è§„æ¨¡å›¾æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæœ‰å‰æ™¯çš„æ€§èƒ½ï¼Œä½†åœ¨å¤„ç†å…·æœ‰å¤æ‚æŸ¥è¯¢çš„çœŸå®ä¸–ç•Œå›¾æ—¶å´å¤±è´¥äº†ã€‚è¿™ä¸€ç°è±¡æºäºLLMsçš„å·¥ä½œè®°å¿†çº¦æŸï¼Œå¯¼è‡´å®ƒä»¬æ— æ³•åœ¨é•¿æœŸä¸Šä¸‹æ–‡ä¸­ä¿ç•™é•¿ç¨‹å›¾æ‹“æ‰‘ç»“æ„ï¼ŒåŒæ—¶ç»´æŒè¿è´¯çš„å¤šæ­¥æ¨ç†ã€‚ç„¶è€Œï¼ŒçœŸå®ä¸–ç•Œçš„å›¾é€šå¸¸æ˜¯ç»“æ„å¤æ‚çš„ï¼Œå¦‚ç½‘é¡µã€äº¤é€šã€ç¤¾äº¤å’Œå¼•æ–‡ç½‘ç»œã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†GraphCogentï¼Œè¿™æ˜¯ä¸€ä¸ªå—äººç±»å·¥ä½œè®°å¿†æ¨¡å‹å¯å‘çš„åä½œä»£ç†æ¡†æ¶ï¼Œå®ƒå°†å›¾æ¨ç†åˆ†è§£æˆä¸“é—¨çš„è®¤çŸ¥è¿‡ç¨‹ï¼šæ„ŸçŸ¥ã€ç¼“å†²å’Œæ‰§è¡Œã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆï¼šæ„Ÿå®˜æ¨¡å—é€šè¿‡å­å›¾é‡‡æ ·æ ‡å‡†åŒ–å„ç§å›¾å½¢æ–‡æœ¬è¡¨ç¤ºï¼Œç¼“å†²æ¨¡å—æ•´åˆå’Œç´¢å¼•è·¨å¤šç§æ ¼å¼çš„å›¾æ•°æ®ï¼Œæ‰§è¡Œæ¨¡å—ç»“åˆå·¥å…·è°ƒç”¨å’Œå·¥å…·åˆ›å»ºè¿›è¡Œé«˜æ•ˆæ¨ç†ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†Graph4realï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å››ä¸ªçœŸå®ä¸–ç•Œå›¾çš„é¢†åŸŸï¼ˆç½‘é¡µã€äº¤é€šã€ç¤¾äº¤å’Œå¼•æ–‡ï¼‰ï¼Œä»¥è¯„ä¼°LLMsçš„å›¾æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„Graph4realæ¶µç›–äº†21ç§ä¸åŒçš„å›¾æ¨ç†ä»»åŠ¡ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼ˆç»“æ„æŸ¥è¯¢ã€ç®—æ³•æ¨ç†å’Œé¢„æµ‹å»ºæ¨¡ä»»åŠ¡ï¼‰ï¼Œå›¾çš„è§„æ¨¡é«˜è¾¾ç°æœ‰åŸºå‡†æµ‹è¯•çš„10å€ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºLlama3.1-8Bçš„GraphCogentåœ¨å¤§å‹LLMsï¼ˆå¦‚DeepSeek-R1 671Bï¼‰ä¸Šå®ç°äº†50%çš„æ”¹è¿›ã€‚ä¸æœ€å…ˆè¿›çš„åŸºäºä»£ç†çš„åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å‡†ç¡®æ€§ä¸Šæé«˜äº†20%ï¼ŒåŒæ—¶å‡å°‘äº†å·¥å…·å†…ä»»åŠ¡ä»¤ç‰Œä½¿ç”¨é‡çš„80%å’Œå·¥å…·å¤–ä»»åŠ¡ä»¤ç‰Œä½¿ç”¨é‡çš„30%ã€‚ä»£ç å°†åœ¨å®¡æŸ¥åå…¬å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12379v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å°è§„æ¨¡å›¾æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†å…·æœ‰å¤æ‚æŸ¥è¯¢çš„çœŸå®ä¸–ç•Œå›¾æ—¶è¡¨ç°ä¸ä½³ã€‚è¿™æ˜¯ç”±äºå¤§å‹è¯­è¨€æ¨¡å‹å­˜åœ¨å·¥ä½œè®°å¿†çº¦æŸï¼Œæ— æ³•åœ¨é•¿æœŸå†…ä¿æŒå›¾çš„æ‹“æ‰‘ç»“æ„å¹¶åœ¨æ‰©å±•çš„ä¸Šä¸‹æ–‡ä¸­ç»´æŒè¿è´¯çš„å¤šæ­¥æ¨ç†ã€‚ä¸ºè§£å†³è¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†GraphCogentæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç”±æ„Ÿå®˜æ¨¡å—ã€ç¼“å†²æ¨¡å—å’Œæ‰§è¡Œæ¨¡å—ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼Œæ—¨åœ¨é€šè¿‡åˆ†è§£å›¾æ¨ç†ä»»åŠ¡ä¸ºç‰¹å®šçš„è®¤çŸ¥è¿‡ç¨‹æ¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚å›¾æ¨ç†ä»»åŠ¡æ—¶çš„å±€é™æ€§ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†Graph4realåŸºå‡†æµ‹è¯•é›†ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å›¾æ¨ç†èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºLlama3.1-8Bçš„GraphCogentæ¡†æ¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šå®ç°äº†50%çš„æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å°è§„æ¨¡å›¾æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†çœŸå®ä¸–ç•Œçš„å¤æ‚å›¾æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>å±€é™æ€§çš„ä¸»è¦åŸå› æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥ä½œè®°å¿†çº¦æŸï¼Œæ— æ³•é•¿æœŸä¿æŒå›¾çš„æ‹“æ‰‘ç»“æ„å¹¶è¿›è¡Œè¿è´¯çš„å¤šæ­¥æ¨ç†ã€‚</li>
<li>GraphCogentæ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿäººç±»å·¥ä½œè®°å¿†æ¨¡å‹æ¥è§£å†³è¿™äº›é™åˆ¶ï¼Œåˆ†è§£ä¸ºæ„Ÿå®˜æ¨¡å—ã€ç¼“å†²æ¨¡å—å’Œæ‰§è¡Œæ¨¡å—ä¸‰ä¸ªä¸“é—¨åŒ–çš„è®¤çŸ¥è¿‡ç¨‹ã€‚</li>
<li>Graph4realåŸºå‡†æµ‹è¯•é›†åŒ…å«å››ä¸ªçœŸå®ä¸–ç•Œå›¾çš„é¢†åŸŸï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å›¾æ¨ç†èƒ½åŠ›ã€‚</li>
<li>GraphCogentæ¡†æ¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ï¼Œç›¸å¯¹äºå…¶ä»–å…ˆè¿›çš„åŸºäºä»£ç†çš„åŸºçº¿æ¨¡å‹ï¼Œå‡†ç¡®åº¦é«˜å‡ºäº†20%ã€‚</li>
<li>GraphCogentåœ¨å†…éƒ¨ä»»åŠ¡ä¸Šå‡å°‘äº†80%çš„ä»¤ç‰Œä½¿ç”¨ï¼Œåœ¨å¤–éƒ¨ä»»åŠ¡ä¸Šå‡å°‘äº†30%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12379">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5cb94f3117abb2ff302bac15e47698d8" align="middle">
<img src="https://picx.zhimg.com/v2-eccb1ab6eb19c5baa9b024e957f9b4ef" align="middle">
<img src="https://picx.zhimg.com/v2-8c2b3eefaea78a279c51cd2831bac387" align="middle">
<img src="https://picx.zhimg.com/v2-cb743643dd742be24b109337a1839f50" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Structured-Agent-Distillation-for-Large-Language-Model"><a href="#Structured-Agent-Distillation-for-Large-Language-Model" class="headerlink" title="Structured Agent Distillation for Large Language Model"></a>Structured Agent Distillation for Large Language Model</h2><p><strong>Authors:Jun Liu, Zhenglun Kong, Peiyan Dong, Changdi Yang, Tianqi Li, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang</strong></p>
<p>Large language models (LLMs) exhibit strong capabilities as decision-making agents by interleaving reasoning and actions, as seen in ReAct-style frameworks. Yet, their practical deployment is constrained by high inference costs and large model sizes. We propose Structured Agent Distillation, a framework that compresses large LLM-based agents into smaller student models while preserving both reasoning fidelity and action consistency. Unlike standard token-level distillation, our method segments trajectories into {[REASON]} and {[ACT]} spans, applying segment-specific losses to align each component with the teacherâ€™s behavior. This structure-aware supervision enables compact agents to better replicate the teacherâ€™s decision process. Experiments on ALFWorld, HotPotQA-ReAct, and WebShop show that our approach consistently outperforms token-level and imitation learning baselines, achieving significant compression with minimal performance drop. Scaling and ablation results further highlight the importance of span-level alignment for efficient and deployable agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡æ¨ç†å’Œè¡ŒåŠ¨äº¤ç»‡å±•ç°å‡ºå¼ºå¤§çš„ä½œä¸ºå†³ç­–ä»£ç†çš„èƒ½åŠ›ï¼Œå¦‚åœ¨ReActé£æ ¼æ¡†æ¶ä¸­æ‰€è§ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„å®é™…åº”ç”¨å—åˆ°é«˜æ¨ç†æˆæœ¬å’Œå¤§å‹æ¨¡å‹è§„æ¨¡çš„é™åˆ¶ã€‚æˆ‘ä»¬æå‡ºäº†ç»“æ„åŒ–ä»£ç†è’¸é¦æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†å¤§å‹LLMä»£ç†å‹ç¼©æˆè¾ƒå°çš„å­¦ç”Ÿæ¨¡å‹ï¼ŒåŒæ—¶ä¿ç•™æ¨ç†ä¿çœŸåº¦å’Œè¡ŒåŠ¨ä¸€è‡´æ€§ã€‚ä¸åŒäºæ ‡å‡†çš„ä»¤ç‰Œçº§è’¸é¦ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†è½¨è¿¹åˆ†å‰²ä¸º{[REASON]}å’Œ{[ACT]}è·¨åº¦ï¼Œå¯¹æ¯ç§ç»„ä»¶åº”ç”¨ç‰¹å®šçš„æŸå¤±æ¥ä¸æ•™å¸ˆçš„è¡Œä¸ºå¯¹é½ã€‚è¿™ç§ç»“æ„æ„ŸçŸ¥çš„ç›‘ç£ä½¿ç´§å‡‘çš„ä»£ç†èƒ½å¤Ÿæ›´å¥½åœ°å¤åˆ¶æ•™å¸ˆçš„å†³ç­–è¿‡ç¨‹ã€‚åœ¨ALFWorldã€HotPotQA-ReActå’ŒWebShopä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºä»¤ç‰Œçº§å’Œæ¨¡ä»¿å­¦ä¹ åŸºçº¿ï¼Œå®ç°äº†æ˜¾è‘—çš„å‹ç¼©å’Œæœ€å°çš„æ€§èƒ½ä¸‹é™ã€‚è§„æ¨¡å’Œæ¶ˆèç»“æœè¿›ä¸€æ­¥å¼ºè°ƒäº†è·¨åº¦çº§å¯¹é½å¯¹äºé«˜æ•ˆå’Œå¯éƒ¨ç½²ä»£ç†çš„é‡è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13820v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡èåˆæ¨ç†ä¸è¡ŒåŠ¨å±•ç°å‡ºå¼ºå¤§çš„å†³ç­–èƒ½åŠ›ï¼Œå¦‚ReActæ¡†æ¶æ‰€ç¤ºã€‚ç„¶è€Œï¼Œå…¶å®è·µéƒ¨ç½²å—é™äºé«˜æ¨ç†æˆæœ¬å’Œåºå¤§çš„æ¨¡å‹è§„æ¨¡ã€‚æˆ‘ä»¬æå‡ºç»“æ„åŒ–ä»£ç†è’¸é¦æ¡†æ¶ï¼Œå®ƒèƒ½å°†å¤§å‹LLMä»£ç†å‹ç¼©æˆè¾ƒå°çš„å­¦ç”Ÿæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒæ¨ç†çš„ä¿çœŸåº¦å’Œè¡ŒåŠ¨çš„è¿è´¯æ€§ã€‚ä¸åŒäºæ ‡å‡†çš„tokençº§è’¸é¦ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†è½¨è¿¹åˆ†æ®µä¸ºæ¨ç†å’Œè¡ŒåŠ¨åŒºé—´ï¼Œå¹¶åº”ç”¨ç‰¹å®šåŒºé—´çš„æŸå¤±æ¥ä½¿æ¯ä¸ªç»„ä»¶ä¸æ•™å¸ˆçš„è¡Œä¸ºå¯¹é½ã€‚è¿™ç§ç»“æ„åŒ–çš„ç›‘ç£ä½¿å¾—ç´§å‡‘çš„ä»£ç†èƒ½æ›´å¥½åœ°å¤åˆ¶æ•™å¸ˆçš„å†³ç­–è¿‡ç¨‹ã€‚åœ¨ALFWorldã€HotPotQA-ReActå’ŒWebShopçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºtokençº§å’Œæ¨¡ä»¿å­¦ä¹ çš„åŸºçº¿ï¼Œå®ç°äº†æ˜¾è‘—å‹ç¼©å’Œæå°æ€§èƒ½æŸå¤±ã€‚æ¯”ä¾‹å’Œæ¶ˆèç»“æœè¿›ä¸€æ­¥çªæ˜¾äº†åŒºé—´çº§å¯¹é½å¯¹äºé«˜æ•ˆå’Œå¯éƒ¨ç½²ä»£ç†çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°å¼ºå¤§çš„å†³ç­–èƒ½åŠ›ï¼Œé€šè¿‡èåˆæ¨ç†ä¸è¡ŒåŠ¨ï¼Œä½†é¢ä¸´é«˜æ¨ç†æˆæœ¬å’Œåºå¤§æ¨¡å‹è§„æ¨¡çš„é—®é¢˜ã€‚</li>
<li>æå‡ºç»“æ„åŒ–ä»£ç†è’¸é¦æ¡†æ¶ï¼Œèƒ½åœ¨ä¿æŒæ¨ç†çš„ä¿çœŸåº¦å’Œè¡ŒåŠ¨çš„è¿è´¯æ€§çš„åŒæ—¶ï¼Œå°†å¤§å‹LLMä»£ç†å‹ç¼©æˆè¾ƒå°çš„å­¦ç”Ÿæ¨¡å‹ã€‚</li>
<li>ä¸æ ‡å‡†çš„tokençº§è’¸é¦ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡åˆ†æ®µè½¨è¿¹è¿›è¡Œæ¨ç†å’Œè¡ŒåŠ¨åŒºé—´çš„ç‰¹å®šæŸå¤±åº”ç”¨ï¼Œå®ç°ä¸æ•™å¸ˆè¡Œä¸ºçš„å¯¹é½ã€‚</li>
<li>ç»“æ„åŒ–çš„ç›‘ç£ä½¿å¾—ç´§å‡‘çš„ä»£ç†èƒ½æ›´å¥½åœ°å¤åˆ¶æ•™å¸ˆçš„å†³ç­–è¿‡ç¨‹ã€‚</li>
<li>åœ¨å¤šä¸ªå®éªŒç¯å¢ƒä¸­ï¼Œè¯¥æ–¹æ³•çš„æ€§èƒ½å§‹ç»ˆä¼˜äºtokençº§å’Œæ¨¡ä»¿å­¦ä¹ åŸºçº¿ï¼Œå®ç°äº†æ˜¾è‘—å‹ç¼©å’Œæå°æ€§èƒ½æŸå¤±ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜ï¼ŒåŒºé—´çº§å¯¹é½å¯¹äºé«˜æ•ˆå’Œå¯éƒ¨ç½²çš„ä»£ç†è‡³å…³é‡è¦ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶ä¸ºæœªæ¥å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨æä¾›äº†å¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13820">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ae3c9b5868a6f3fe7d15cb7a2337cd2a" align="middle">
<img src="https://picx.zhimg.com/v2-e763e1239257307405d7ab670da84823" align="middle">
<img src="https://picx.zhimg.com/v2-9060e4a9c0818ffb4297f4b66236bb9d" align="middle">
<img src="https://picx.zhimg.com/v2-8efd8d63ad50f04400a459b82e5adc1e" align="middle">
<img src="https://picx.zhimg.com/v2-06f69e01f0faa00482a5064f6295ad35" align="middle">
<img src="https://picx.zhimg.com/v2-e697517c8d187431aa7aa0d689ce9834" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-02/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-02/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-02/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-316ac343a4123541cf6b2a9c67fabb96" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-02  A Culturally-diverse Multilingual Multimodal Video Benchmark & Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-02/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ba8d094778b884fb914c501034be57f7.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-02  MLA A Multisensory Language-Action Model for Multimodal Understanding   and Forecasting in Robotic Manipulation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
