<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-16  DISCO Balances the Scales Adaptive Domain- and Difficulty-Aware   Reinforcement Learning on Imbalanced Data">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-5c48b8e8212f227dbb8a8da4815a0dfc.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    69 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-16-æ›´æ–°"><a href="#2025-06-16-æ›´æ–°" class="headerlink" title="2025-06-16 æ›´æ–°"></a>2025-06-16 æ›´æ–°</h1><h2 id="DISCO-Balances-the-Scales-Adaptive-Domain-and-Difficulty-Aware-Reinforcement-Learning-on-Imbalanced-Data"><a href="#DISCO-Balances-the-Scales-Adaptive-Domain-and-Difficulty-Aware-Reinforcement-Learning-on-Imbalanced-Data" class="headerlink" title="DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware   Reinforcement Learning on Imbalanced Data"></a>DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware   Reinforcement Learning on Imbalanced Data</h2><p><strong>Authors:Yuhang Zhou, Jing Zhu, Shengyi Qian, Zhuokai Zhao, Xiyao Wang, Xiaoyu Liu, Ming Li, Paiheng Xu, Wei Ai, Furong Huang</strong></p>
<p>Large Language Models (LLMs) are increasingly aligned with human preferences through Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods, Group Relative Policy Optimization (GRPO) has gained attention for its simplicity and strong performance, notably eliminating the need for a learned value function. However, GRPO implicitly assumes a balanced domain distribution and uniform semantic alignment across groups - assumptions that rarely hold in real-world datasets. When applied to multi-domain, imbalanced data, GRPO disproportionately optimizes for dominant domains, neglecting underrepresented ones and resulting in poor generalization and fairness. We propose Domain-Informed Self-Consistency Policy Optimization (DISCO), a principled extension to GRPO that addresses inter-group imbalance with two key innovations. Domain-aware reward scaling counteracts frequency bias by reweighting optimization based on domain prevalence. Difficulty-aware reward scaling leverages prompt-level self-consistency to identify and prioritize uncertain prompts that offer greater learning value. Together, these strategies promote more equitable and effective policy learning across domains. Extensive experiments across multiple LLMs and skewed training distributions show that DISCO improves generalization, outperforms existing GRPO variants by 5% on Qwen3 models, and sets new state-of-the-art results on multi-domain alignment benchmarks. </p>
<blockquote>
<p>éšç€é€šè¿‡äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰çš„ä¸æ–­è¿›æ­¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šç¬¦åˆäººç±»çš„åå¥½ã€‚åœ¨RLHFæ–¹æ³•ä¸­ï¼Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å› å…¶ç®€å•æ€§å’Œå‡ºè‰²çš„æ€§èƒ½è€Œå—åˆ°å…³æ³¨ï¼Œå°¤å…¶æ˜¯å®ƒä¸éœ€è¦å­¦ä¹ ä»·å€¼å‡½æ•°ã€‚ç„¶è€Œï¼ŒGRPOéšå«åœ°å‡è®¾äº†åŸŸåˆ†å¸ƒçš„å¹³è¡¡å’Œè·¨ç¾¤ä½“çš„è¯­ä¹‰å¯¹é½çš„å‡åŒ€æ€§â€”â€”è¿™äº›å‡è®¾åœ¨çœŸå®ä¸–ç•Œçš„æ•°æ®é›†ä¸­å¾ˆå°‘æˆç«‹ã€‚å½“åº”ç”¨äºå¤šåŸŸã€ä¸å¹³è¡¡æ•°æ®æ—¶ï¼ŒGRPOä¼šè¿‡åº¦ä¼˜åŒ–ä¸»å¯¼åŸŸï¼Œè€Œå¿½è§†ä»£è¡¨æ€§ä¸è¶³çš„åŸŸï¼Œå¯¼è‡´æ³›åŒ–å’Œå…¬å¹³æ€§è¾ƒå·®ã€‚æˆ‘ä»¬æå‡ºäº†é¢†åŸŸä¿¡æ¯è‡ªæˆ‘ä¸€è‡´æ€§ç­–ç•¥ä¼˜åŒ–ï¼ˆDISCOï¼‰ï¼Œè¿™æ˜¯å¯¹GRPOçš„ä¸€ç§åŸåˆ™æ€§æ‰©å±•ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°æ¥è§£å†³ç»„é—´ä¸å¹³è¡¡é—®é¢˜ã€‚é¢†åŸŸæ„ŸçŸ¥å¥–åŠ±ç¼©æ”¾é€šè¿‡æ ¹æ®é¢†åŸŸçš„æ™®åŠç¨‹åº¦é‡æ–°è°ƒæ•´ä¼˜åŒ–æ¥æŠµæ¶ˆé¢‘ç‡åè§ã€‚éš¾åº¦æ„ŸçŸ¥å¥–åŠ±ç¼©æ”¾åˆ©ç”¨æç¤ºçº§åˆ«çš„è‡ªæˆ‘ä¸€è‡´æ€§æ¥è¯†åˆ«å’Œä¼˜å…ˆå¤„ç†å…·æœ‰æ›´å¤§å­¦ä¹ ä»·å€¼çš„ä¸ç¡®å®šæç¤ºã€‚è¿™ä¸¤ç§ç­–ç•¥å…±åŒä¿ƒè¿›äº†è·¨é¢†åŸŸçš„æ›´å…¬å¹³å’Œæœ‰æ•ˆçš„ç­–ç•¥å­¦ä¹ ã€‚åœ¨å¤šä¸ªLLMå’Œåæ–œè®­ç»ƒåˆ†å¸ƒä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDISCOæé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨Qwen3æ¨¡å‹ä¸Šçš„è¡¨ç°æ¯”ç°æœ‰GRPOå˜ä½“é«˜å‡º5%ï¼Œå¹¶åœ¨å¤šåŸŸå¯¹é½åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15074v2">PDF</a> 13 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰ä¸­è¿›è¡Œå¯¹é½äººç±»åå¥½ã€‚ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ–¹æ³•å› å…¶ç®€å•æ€§å’Œé«˜æ€§èƒ½è€Œå—åˆ°å…³æ³¨ï¼Œå°¤å…¶æ˜¯å…¶ä¸éœ€è¦å­¦ä¹ ä»·å€¼å‡½æ•°ã€‚ç„¶è€Œï¼ŒGRPOéšå«åœ°å‡è®¾äº†åŸŸåˆ†å¸ƒçš„å¹³è¡¡å’Œç¾¤ä½“é—´çš„è¯­ä¹‰å¯¹é½ï¼Œè¿™äº›å‡è®¾åœ¨çœŸå®ä¸–ç•Œçš„æ•°æ®é›†ä¸­å¾ˆå°‘æˆç«‹ã€‚å½“åº”ç”¨äºå¤šåŸŸã€ä¸å¹³è¡¡æ•°æ®æ—¶ï¼ŒGRPOä¼šè¿‡åº¦ä¼˜åŒ–ä¸»å¯¼åŸŸï¼Œå¿½è§†ä»£è¡¨æ€§ä¸è¶³çš„åŸŸï¼Œå¯¼è‡´æ³›åŒ–å’Œå…¬å¹³æ€§é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†é¢†åŸŸä¿¡æ¯è‡ªæˆ‘ä¸€è‡´æ€§ç­–ç•¥ä¼˜åŒ–ï¼ˆDISCOï¼‰ï¼Œå®ƒæ˜¯GRPOçš„ä¸€ç§åŸåˆ™æ€§æ‰©å±•ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°è§£å†³ç»„é—´ä¸å¹³è¡¡é—®é¢˜ã€‚é¢†åŸŸæ„ŸçŸ¥å¥–åŠ±ç¼©æ”¾é€šè¿‡æ ¹æ®é¢†åŸŸæ™®åŠç‡é‡æ–°åŠ æƒä¼˜åŒ–æ¥å¯¹æŠ—é¢‘ç‡åè§ã€‚éš¾åº¦æ„ŸçŸ¥å¥–åŠ±ç¼©æ”¾åˆ©ç”¨æç¤ºçº§åˆ«çš„è‡ªæˆ‘ä¸€è‡´æ€§æ¥è¯†åˆ«å’Œä¼˜å…ˆå¤„ç†å…·æœ‰æ›´å¤§å­¦ä¹ ä»·å€¼çš„ä¸ç¡®å®šæç¤ºã€‚è¿™äº›ç­–ç•¥å…±åŒä¿ƒè¿›äº†è·¨é¢†åŸŸçš„æ›´å…¬å¹³å’Œæœ‰æ•ˆçš„ç­–ç•¥å­¦ä¹ ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰å¯¹é½äººç±»åå¥½ã€‚</li>
<li>Group Relative Policy Optimization (GRPO) æ–¹æ³•åœ¨LLMä¸­å—åˆ°å…³æ³¨ï¼Œä½†å­˜åœ¨å¯¹åŸŸåˆ†å¸ƒå’Œè¯­ä¹‰å¯¹é½çš„å‡è®¾é—®é¢˜ã€‚</li>
<li>GRPOåœ¨åº”ç”¨äºå¤šåŸŸã€ä¸å¹³è¡¡æ•°æ®æ—¶å­˜åœ¨é—®é¢˜ï¼Œä¼šè¿‡åº¦ä¼˜åŒ–ä¸»å¯¼åŸŸï¼Œå¿½è§†ä»£è¡¨æ€§ä¸è¶³çš„åŸŸã€‚</li>
<li>DISCOæ˜¯GRPOçš„ä¸€ç§æ‰©å±•ï¼Œé€šè¿‡é¢†åŸŸæ„ŸçŸ¥å¥–åŠ±ç¼©æ”¾å’Œéš¾åº¦æ„ŸçŸ¥å¥–åŠ±ç¼©æ”¾è§£å†³GRPOçš„é—®é¢˜ã€‚</li>
<li>DISCOé€šè¿‡é‡æ–°åŠ æƒä¼˜åŒ–æ¥è§£å†³é¢‘ç‡åè§é—®é¢˜ï¼Œå¹¶ä¼˜å…ˆå¤„ç†å…·æœ‰æ›´å¤§å­¦ä¹ ä»·å€¼çš„ä¸ç¡®å®šæç¤ºã€‚</li>
<li>DISCOèƒ½æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šä¸ªLLMå’Œåæ–œè®­ç»ƒåˆ†å¸ƒä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15074">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-389552fea27c64695d483c8212187cd9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6c6f8a54d0c74db32d1b0eac4e3eabe4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c86a3c12388aef30f14620fee3246c26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b26954f350c15264b2df0fdb937aec93.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MindOmni-Unleashing-Reasoning-Generation-in-Vision-Language-Models-with-RGPO"><a href="#MindOmni-Unleashing-Reasoning-Generation-in-Vision-Language-Models-with-RGPO" class="headerlink" title="MindOmni: Unleashing Reasoning Generation in Vision Language Models with   RGPO"></a>MindOmni: Unleashing Reasoning Generation in Vision Language Models with   RGPO</h2><p><strong>Authors:Yicheng Xiao, Lin Song, Yukang Chen, Yingmin Luo, Yuxin Chen, Yukang Gan, Wei Huang, Xiu Li, Xiaojuan Qi, Ying Shan</strong></p>
<p>Recent text-to-image systems face limitations in handling multimodal inputs and complex reasoning tasks. We introduce MindOmni, a unified multimodal large language model that addresses these challenges by incorporating reasoning generation through reinforcement learning. MindOmni leverages a three-phase training strategy: i) design of a unified vision language model with a decoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought (CoT) instruction data, and iii) our proposed Reasoning Generation Policy Optimization (RGPO) algorithm, utilizing multimodal feedback to effectively guide policy updates. Experimental results demonstrate that MindOmni outperforms existing models, achieving impressive performance on both understanding and generation benchmarks, meanwhile showcasing advanced fine-grained reasoning generation capabilities, especially with mathematical reasoning instruction. All codes will be made public at <a target="_blank" rel="noopener" href="https://github.com/TencentARC/MindOmni">https://github.com/TencentARC/MindOmni</a> </p>
<blockquote>
<p>è¿‘æœŸçš„æ–‡æœ¬åˆ°å›¾åƒç³»ç»Ÿåœ¨å¤„ç†å¤šæ¨¡æ€è¾“å…¥å’Œå¤æ‚æ¨ç†ä»»åŠ¡æ—¶é¢ä¸´å±€é™ã€‚æˆ‘ä»¬æ¨å‡ºäº†MindOmniï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ èå…¥æ¨ç†ç”Ÿæˆæ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚MindOmnié‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šä¸€ã€è®¾è®¡å¸¦æœ‰ä»…è§£ç å™¨æ‰©æ•£æ¨¡å—çš„ç»Ÿä¸€è§†è§‰è¯­è¨€æ¨¡å‹ï¼›äºŒã€ä½¿ç”¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æŒ‡ä»¤æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼›ä¸‰ã€æˆ‘ä»¬æå‡ºçš„åˆ©ç”¨å¤šæ¨¡æ€åé¦ˆæœ‰æ•ˆæŒ‡å¯¼ç­–ç•¥æ›´æ–°çš„æ¨ç†ç”Ÿæˆç­–ç•¥ä¼˜åŒ–ï¼ˆRGPOï¼‰ç®—æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMindOmniåœ¨ç†è§£å’Œç”ŸæˆåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä»¤äººå°è±¡æ·±åˆ»ï¼Œå±•ç°å‡ºç²¾ç»†çš„æ¨ç†ç”Ÿæˆèƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ•°å­¦æ¨ç†æŒ‡ä»¤æ–¹é¢ã€‚æ‰€æœ‰ä»£ç å°†äº<a target="_blank" rel="noopener" href="https://github.com/TencentARC/MindOmni%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/TencentARC/MindOmniå…¬å¼€ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13031v2">PDF</a> Code: <a target="_blank" rel="noopener" href="https://github.com/TencentARC/MindOmni">https://github.com/TencentARC/MindOmni</a></p>
<p><strong>Summary</strong></p>
<p>MindOmniæ˜¯ä¸€æ¬¾ç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è§£å†³æ–‡æœ¬è½¬å›¾åƒç³»ç»Ÿå¤„ç†å¤šæ¨¡æ€è¾“å…¥å’Œå¤æ‚æ¨ç†ä»»åŠ¡çš„å±€é™æ€§ã€‚å®ƒé‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šè®¾è®¡ç»Ÿä¸€è§†è§‰è¯­è¨€æ¨¡å‹ã€ä½¿ç”¨Chain-of-Thoughtï¼ˆCoTï¼‰æŒ‡ä»¤æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œä»¥åŠé‡‡ç”¨å¤šæ¨¡æ€åé¦ˆå¼•å¯¼ç­–ç•¥æ›´æ–°çš„Reasoning Generation Policy Optimizationï¼ˆRGPOï¼‰ç®—æ³•ã€‚MindOmniåœ¨ç†è§£å’Œç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°å­¦æ¨ç†æŒ‡ä»¤æ–¹é¢å±•ç°å‡ºç²¾ç»†çš„æ¨ç†ç”Ÿæˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MindOmniæ˜¯ä¸€æ¬¾å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æ–‡æœ¬è½¬å›¾åƒç³»ç»Ÿåœ¨å¤„ç†å¤šæ¨¡æ€è¾“å…¥å’Œå¤æ‚æ¨ç†ä»»åŠ¡æ–¹é¢çš„å±€é™æ€§ã€‚</li>
<li>MindOmnié‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬è®¾è®¡ç»Ÿä¸€è§†è§‰è¯­è¨€æ¨¡å‹ã€ç›‘ç£ç»†è°ƒå’Œä½¿ç”¨Chain-of-Thoughtï¼ˆCoTï¼‰æŒ‡ä»¤æ•°æ®ã€‚</li>
<li>MindOmniå¼•å…¥äº†Reasoning Generation Policy Optimizationï¼ˆRGPOï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•åˆ©ç”¨å¤šæ¨¡æ€åé¦ˆæ¥æœ‰æ•ˆåœ°å¼•å¯¼ç­–ç•¥æ›´æ–°ã€‚</li>
<li>MindOmniåœ¨ç†è§£å’Œç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>MindOmniç‰¹åˆ«æ“…é•¿å¤„ç†æ•°å­¦æ¨ç†æŒ‡ä»¤ï¼Œå±•ç°å‡ºç²¾ç»†çš„æ¨ç†ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>MindOmniçš„ä»£ç å°†å…¬å¼€åœ¨GitHubä¸Šï¼Œæ–¹ä¾¿å…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚</li>
<li>MindOmniçš„æ¨å‡ºå¯¹äºæ¨åŠ¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13031">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b5955b2876a0184b2c45e82c5bfbc3ac.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3bbe6e7e74137b1b6949d0df2ca0ecde.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03918d29726639a34829afe221216c8c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd39bd5f3ab613f5a58e3a8dfeba249f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3915c2ba09819e16e938d74bbf761387.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DisCO-Reinforcing-Large-Reasoning-Models-with-Discriminative-Constrained-Optimization"><a href="#DisCO-Reinforcing-Large-Reasoning-Models-with-Discriminative-Constrained-Optimization" class="headerlink" title="DisCO: Reinforcing Large Reasoning Models with Discriminative   Constrained Optimization"></a>DisCO: Reinforcing Large Reasoning Models with Discriminative   Constrained Optimization</h2><p><strong>Authors:Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang</strong></p>
<p>The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new Discriminative Constrained Optimization (DisCO) framework for reinforcing LRMs, grounded in the principle of discriminative learning. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint, ensuring stable training. As a result, DisCO offers notable advantages over GRPO and its variants: (i) it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7% over GRPO and 6% over DAPO across six benchmark tasks for an 1.5B model. </p>
<blockquote>
<p>è¿‘æœŸDeepSeek-R1çš„æˆåŠŸä¸å¼€æ”¾æ€§ä½¿äººä»¬å¼€å§‹å…³æ³¨ç”¨äºå¤§è§„æ¨¡æ¨ç†æ¨¡å‹ï¼ˆLRMï¼‰å¼ºåŒ–å­¦ä¹ çš„ç¾¤ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åœ¨äºŒè¿›åˆ¶å¥–åŠ±è®¾ç½®ä¸‹åˆ†æGRPOçš„ç›®æ ‡ï¼Œå¹¶æ­ç¤ºäº†é—®é¢˜çº§åˆ«éš¾åº¦åå¥½çš„å›ºæœ‰å±€é™æ€§ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†GRPOä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸­çš„åˆ¤åˆ«æ–¹æ³•ä¹‹é—´çš„è”ç³»ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”¨äºå¼ºåŒ–LRMçš„åˆ¤åˆ«çº¦æŸä¼˜åŒ–ï¼ˆDisCOï¼‰æ¡†æ¶ï¼Œå®ƒåŸºäºåˆ¤åˆ«å­¦ä¹ çš„åŸç†ã€‚DisCOä¸GRPOåŠå…¶æœ€è¿‘å˜ä½“ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼šï¼ˆ1ï¼‰å®ƒç”¨è¯„åˆ†å‡½æ•°å®šä¹‰çš„åˆ¤åˆ«ç›®æ ‡æ›¿ä»£äº†ç¾¤ä½“ç›¸å¯¹ç›®æ ‡ï¼›ï¼ˆ2ï¼‰å®ƒæ”¾å¼ƒäº†åŸºäºå‰ªè¾‘çš„æ›¿ä»£ç‰©ï¼Œè½¬è€Œä½¿ç”¨éå‰ªè¾‘çš„å¼ºåŒ–å­¦ä¹ æ›¿ä»£ç›®æ ‡ä½œä¸ºè¯„åˆ†å‡½æ•°ï¼›ï¼ˆ3ï¼‰å®ƒé‡‡ç”¨ç®€å•æœ‰æ•ˆçš„çº¦æŸä¼˜åŒ–æ–¹æ³•æ¥å¼ºåˆ¶æ‰§è¡ŒKLæ•£åº¦çº¦æŸï¼Œç¡®ä¿ç¨³å®šçš„è®­ç»ƒã€‚å› æ­¤ï¼Œç›¸è¾ƒäºGRPOåŠå…¶å˜ä½“ï¼ŒDisCOå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ï¼šï¼ˆiï¼‰å®ƒé‡‡ç”¨åˆ¤åˆ«ç›®æ ‡å®Œå…¨æ¶ˆé™¤äº†éš¾åº¦åå¥½ï¼›ï¼ˆiiï¼‰å®ƒé€šè¿‡ä½¿ç”¨éå‰ªè¾‘è¯„åˆ†å‡½æ•°å’Œçº¦æŸä¼˜åŒ–æ–¹æ³•è§£å†³äº†GRPOåŠå…¶å˜ä½“çš„ç†µä¸ç¨³å®šé—®é¢˜ï¼›ï¼ˆiiiï¼‰å®ƒå…è®¸èå…¥å…ˆè¿›çš„åˆ¤åˆ«å­¦ä¹ æŠ€æœ¯æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¤§é‡é—®é¢˜çš„ç”Ÿæˆç­”æ¡ˆä¸­è´Ÿæ ·æœ¬å¤šäºæ­£æ ·æœ¬ã€‚æˆ‘ä»¬åœ¨å¢å¼ºç»è¿‡SFTå¾®è°ƒæ¨¡å‹æ•°å­¦æ¨ç†èƒ½åŠ›çš„å®éªŒè¡¨æ˜ï¼ŒDisCOæ˜¾è‘—ä¼˜äºGRPOåŠå…¶æ”¹è¿›å˜ä½“ï¼ˆå¦‚DAPOï¼‰ï¼Œåœ¨1.5Bæ¨¡å‹çš„å…­ä¸ªåŸºå‡†ä»»åŠ¡ä¸Šå¹³å‡ä¼˜äºGRPO 7%ï¼Œä¼˜äºDAPO 6%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.12366v2">PDF</a> 20 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†DeepSeek-R1çš„æˆåŠŸå’Œå¼€æ”¾æ€§å¼•èµ·äº†äººä»¬å¯¹é›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰ä½œä¸ºå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„å¹¿æ³›å…³æ³¨ã€‚åˆ†æGRPOåœ¨äºŒå…ƒå¥–åŠ±è®¾ç½®ä¸‹çš„å†…åœ¨å±€é™æ€§ï¼Œå¹¶æ­ç¤ºäº†é—®é¢˜éš¾åº¦åç½®çš„å›ºæœ‰ç¼ºé™·ã€‚åŒæ—¶ï¼Œæœ¬æ–‡å‘ç°äº†GRPOä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸­çš„åˆ¤åˆ«å¼æ–¹æ³•çš„è”ç³»ã€‚åŸºäºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†é’ˆå¯¹LRMçš„åˆ¤åˆ«çº¦æŸä¼˜åŒ–ï¼ˆDisCOï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨åˆ¤åˆ«å­¦ä¹ åŸåˆ™ã€‚ç›¸æ¯”GRPOåŠå…¶å˜ä½“ï¼ŒDisCOä¸»è¦ä¼˜åŠ¿åœ¨äºï¼šé‡‡ç”¨åˆ¤åˆ«ç›®æ ‡æ¶ˆé™¤éš¾åº¦åç½®ï¼Œä½¿ç”¨éå‰ªè¾‘è¯„åˆ†å‡½æ•°å’Œçº¦æŸä¼˜åŒ–æ–¹æ³•è§£å†³ç†µä¸ç¨³å®šé—®é¢˜ï¼Œå¹¶å…è®¸å¼•å…¥å…ˆè¿›çš„åˆ¤åˆ«å­¦ä¹ æŠ€æœ¯æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒDisCOåœ¨å¢å¼ºSFTå¾®è°ƒæ¨¡å‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ–¹é¢æ˜¾è‘—ä¼˜äºGRPOåŠå…¶æ”¹è¿›ç‰ˆæœ¬DAPOï¼Œåœ¨å…­ä¸ªåŸºå‡†ä»»åŠ¡ä¸Šå¹³å‡å¢ç›Šè¾¾7%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeepSeek-R1çš„æˆåŠŸå¼•èµ·å¯¹é›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„å…³æ³¨ï¼Œä½œä¸ºä¸€ç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•åº”ç”¨äºå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ã€‚</li>
<li>åœ¨äºŒå…ƒå¥–åŠ±è®¾ç½®ä¸‹åˆ†æGRPOï¼Œæ­ç¤ºå…¶é—®é¢˜éš¾åº¦åç½®çš„å›ºæœ‰å±€é™æ€§ã€‚</li>
<li>å‘ç°GRPOä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸­çš„åˆ¤åˆ«æ–¹æ³•çš„è”ç³»ã€‚</li>
<li>å¼•å…¥æ–°çš„åˆ¤åˆ«çº¦æŸä¼˜åŒ–ï¼ˆDisCOï¼‰æ¡†æ¶ï¼ŒåŸºäºåˆ¤åˆ«å­¦ä¹ åŸåˆ™å¼ºåŒ–LRMã€‚</li>
<li>DisCOé‡‡ç”¨åˆ¤åˆ«ç›®æ ‡æ¶ˆé™¤éš¾åº¦åç½®ï¼Œä½¿ç”¨éå‰ªè¾‘RLè¯„åˆ†å‡½æ•°è§£å†³ç†µä¸ç¨³å®šé—®é¢˜ã€‚</li>
<li>DisCOå…è®¸å¼•å…¥å…ˆè¿›çš„åˆ¤åˆ«å­¦ä¹ æŠ€æœ¯æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.12366">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-989dce63ecd503100290e84973ecee7e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f7b2ca5c8537c2901906bf6370d6ed7.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="BLEUBERI-BLEU-is-a-surprisingly-effective-reward-for-instruction-following"><a href="#BLEUBERI-BLEU-is-a-surprisingly-effective-reward-for-instruction-following" class="headerlink" title="BLEUBERI: BLEU is a surprisingly effective reward for instruction   following"></a>BLEUBERI: BLEU is a surprisingly effective reward for instruction   following</h2><p><strong>Authors:Yapei Chang, Yekyung Kim, Michael Krumdick, Amir Zadeh, Chuan Li, Chris Tanner, Mohit Iyyer</strong></p>
<p>Reward models are central to aligning LLMs with human preferences, but they are costly to train, requiring large-scale human-labeled preference data and powerful pretrained LLM backbones. Meanwhile, the increasing availability of high-quality synthetic instruction-following datasets raises the question: can simpler, reference-based metrics serve as viable alternatives to reward models during RL-based alignment? In this paper, we show first that BLEU, a basic string-matching metric, surprisingly matches strong reward models in agreement with human preferences on general instruction-following datasets. Based on this insight, we develop BLEUBERI, a method that first identifies challenging instructions and then applies Group Relative Policy Optimization (GRPO) using BLEU directly as the reward function. We demonstrate that BLEUBERI-trained models are competitive with models trained via reward model-guided RL across four challenging instruction-following benchmarks and three different base language models. A human evaluation further supports that the quality of BLEUBERI model outputs is on par with those from reward model-aligned models. Moreover, BLEUBERI models generate outputs that are more factually grounded than competing methods. Overall, we show that given access to high-quality reference outputs (easily obtained via existing instruction-following datasets or synthetic data generation), string matching-based metrics are cheap yet effective proxies for reward models during alignment. We release our code and data at <a target="_blank" rel="noopener" href="https://github.com/lilakk/BLEUBERI">https://github.com/lilakk/BLEUBERI</a>. </p>
<blockquote>
<p>å¥–åŠ±æ¨¡å‹åœ¨å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººç±»åå¥½å¯¹é½æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ï¼Œä½†å®ƒä»¬è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦å¤§è§„æ¨¡çš„äººä¸ºæ ‡è®°åå¥½æ•°æ®å’Œå¼ºå¤§çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä½œä¸ºåç›¾ã€‚åŒæ—¶ï¼Œé«˜è´¨é‡åˆæˆæŒ‡ä»¤è·Ÿéšæ•°æ®é›†çš„æ—¥ç›Šå¯ç”¨æ€§æå‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼šåœ¨åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¯¹é½è¿‡ç¨‹ä¸­ï¼Œæ›´ç®€å•çš„åŸºäºå‚è€ƒçš„åº¦é‡æ ‡å‡†èƒ½å¦ä½œä¸ºå¥–åŠ±æ¨¡å‹çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆï¼Ÿåœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè¡¨æ˜ï¼ŒBLEUï¼ˆä¸€ç§åŸºæœ¬çš„å­—ç¬¦ä¸²åŒ¹é…åº¦é‡æ ‡å‡†ï¼‰å‡ºäººæ„æ–™åœ°ä¸äººç±»åå¥½åœ¨é€šç”¨æŒ‡ä»¤éµå¾ªæ•°æ®é›†ä¸ŠåŒ¹é…è‰¯å¥½çš„å¥–åŠ±æ¨¡å‹ã€‚åŸºäºè¿™ä¸€è§è§£ï¼Œæˆ‘ä»¬å¼€å‘äº†BLEUBERIæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é¦–å…ˆè¯†åˆ«å…·æœ‰æŒ‘æˆ˜æ€§çš„æŒ‡ä»¤ï¼Œç„¶åä½¿ç”¨BLEUä½œä¸ºå¥–åŠ±å‡½æ•°åº”ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ã€‚æˆ‘ä»¬åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æŒ‡ä»¤è·ŸéšåŸºå‡†æµ‹è¯•ã€ä¸‰ç§ä¸åŒçš„åŸºç¡€è¯­è¨€æ¨¡å‹ä¸Šè¯æ˜äº†BLEUBERIè®­ç»ƒçš„æ¨¡å‹ä¸é€šè¿‡å¥–åŠ±æ¨¡å‹å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ¨¡å‹ç«äº‰åŠ›ç›¸å½“ã€‚äººç±»è¯„ä¼°è¿›ä¸€æ­¥æ”¯æŒBLEUBERIæ¨¡å‹è¾“å‡ºçš„è´¨é‡ä¸å¥–åŠ±æ¨¡å‹å¯¹é½çš„æ¨¡å‹ç›¸å½“ã€‚æ­¤å¤–ï¼ŒBLEUBERIæ¨¡å‹äº§ç”Ÿçš„è¾“å‡ºæ›´åŠ åŸºäºäº‹å®ï¼Œç›¸è¾ƒäºå…¶ä»–æ–¹æ³•ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬è¯æ˜ï¼Œåœ¨è·å¾—é«˜è´¨é‡å‚è€ƒè¾“å‡ºï¼ˆå¯é€šè¿‡ç°æœ‰æŒ‡ä»¤è·Ÿéšæ•°æ®é›†æˆ–åˆæˆæ•°æ®ç”Ÿæˆè½»æ¾è·å¾—ï¼‰çš„æƒ…å†µä¸‹ï¼Œå­—ç¬¦ä¸²åŒ¹é…åŸºç¡€ä¸Šçš„åº¦é‡æ ‡å‡†æ˜¯å¥–åŠ±æ¨¡å‹çš„å»‰ä»·ä¸”æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/lilakk/BLEUBERI">https://github.com/lilakk/BLEUBERI</a>ä¸Šå‘å¸ƒäº†æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11080v2">PDF</a> 28 pages, 11 figures, 15 tables; updated table 1 with random reward   results, fixed broken references in appendix</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä½¿ç”¨BLEUç­‰åŸºäºå­—ç¬¦ä¸²åŒ¹é…çš„åº¦é‡æ ‡å‡†ä½œä¸ºå¥–åŠ±æ¨¡å‹çš„æ›¿ä»£æ–¹æ¡ˆï¼Œç”¨äºåœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»åå¥½å¯¹é½çš„è¿‡ç¨‹ä¸­ã€‚ç ”ç©¶å‘ç°ï¼ŒBLEUåœ¨æŸäº›æƒ…å†µä¸‹ä¸äººç±»åå¥½é«˜åº¦ä¸€è‡´ï¼Œå¹¶åŸºäºæ­¤æå‡ºäº†BLEUBERIæ–¹æ³•ã€‚è¯¥æ–¹æ³•é’ˆå¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„æŒ‡ä»¤è¿›è¡Œä¼˜åŒ–ï¼Œä½¿ç”¨BLEUä½œä¸ºå¥–åŠ±å‡½æ•°è¿›è¡Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨BLEUBERIè®­ç»ƒå‡ºçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¸å¥–åŠ±æ¨¡å‹å¼•å¯¼ä¸‹çš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹è¡¨ç°ç›¸å½“ï¼ŒåŒæ—¶ç”Ÿæˆçš„è¾“å‡ºæ›´ä¸ºè´´åˆäº‹å®ã€‚æ€»çš„æ¥è¯´ï¼Œåˆ©ç”¨é«˜è´¨é‡å‚è€ƒè¾“å‡ºï¼ˆå¯é€šè¿‡ç°æœ‰æŒ‡ä»¤è·Ÿéšæ•°æ®é›†æˆ–åˆæˆæ•°æ®ç”Ÿæˆï¼‰ï¼ŒåŸºäºå­—ç¬¦ä¸²åŒ¹é…çš„åº¦é‡æ ‡å‡†å¯ä»¥ä½œä¸ºå¥–åŠ±æ¨¡å‹çš„ä½æˆæœ¬æœ‰æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¥–åŠ±æ¨¡å‹åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸äººç±»åå¥½å¯¹é½ä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œä½†æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>é«˜è´¨é‡åˆæˆæŒ‡ä»¤è·Ÿéšæ•°æ®é›†çš„æ™®åŠä½¿å¾—ç ”ç©¶æ›´ç®€å•çš„æ›¿ä»£å¥–åŠ±æ¨¡å‹çš„å¯è¡Œæ€§æé«˜ã€‚</li>
<li>åŸºäºå®éªŒå‘ç°ï¼ŒBLEUä¸äººç±»çš„åå¥½é«˜åº¦ä¸€è‡´ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•BLEUBERIï¼Œé’ˆå¯¹éš¾ä»¥ç†è§£çš„æŒ‡ä»¤è¿›è¡Œä¼˜åŒ–ï¼Œä½¿ç”¨BLEUä½œä¸ºå¥–åŠ±å‡½æ•°è¿›è¡Œç­–ç•¥ä¼˜åŒ–ã€‚</li>
<li>BLEUBERIè®­ç»ƒå‡ºçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°è‰¯å¥½ï¼Œä¸å¥–åŠ±æ¨¡å‹è®­ç»ƒå‡ºçš„æ¨¡å‹ç›¸å½“ã€‚</li>
<li>BLEUBERIæ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºæ›´è´´åˆäº‹å®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7efcd101bf576d8c523bd41f70822f6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28058cc6bd943d7d7c7a4839f1644569.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1b81d4432b7f9c84d1cf57379cc161bf.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Sailing-by-the-Stars-A-Survey-on-Reward-Models-and-Learning-Strategies-for-Learning-from-Rewards"><a href="#Sailing-by-the-Stars-A-Survey-on-Reward-Models-and-Learning-Strategies-for-Learning-from-Rewards" class="headerlink" title="Sailing by the Stars: A Survey on Reward Models and Learning Strategies   for Learning from Rewards"></a>Sailing by the Stars: A Survey on Reward Models and Learning Strategies   for Learning from Rewards</h2><p><strong>Authors:Xiaobao Wu</strong></p>
<p>Recent developments in Large Language Models (LLMs) have shifted from pre-training scaling to post-training and test-time scaling. Across these developments, a key unified paradigm has arisen: Learning from Rewards, where reward signals act as the guiding stars to steer LLM behavior. It has underpinned a wide range of prevalent techniques, such as reinforcement learning (RLHF, RLAIF, DPO, and GRPO), reward-guided decoding, and post-hoc correction. Crucially, this paradigm enables the transition from passive learning from static data to active learning from dynamic feedback. This endows LLMs with aligned preferences and deep reasoning capabilities for diverse tasks. In this survey, we present a comprehensive overview of learning from rewards, from the perspective of reward models and learning strategies across training, inference, and post-inference stages. We further discuss the benchmarks for reward models and the primary applications. Finally we highlight the challenges and future directions. We maintain a paper collection at <a target="_blank" rel="noopener" href="https://github.com/bobxwu/learning-from-rewards-llm-papers">https://github.com/bobxwu/learning-from-rewards-llm-papers</a>. </p>
<blockquote>
<p>æœ€è¿‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘å±•å·²ç»ä»é¢„è®­ç»ƒæ‰©å±•è½¬å‘åè®­ç»ƒå’Œæµ‹è¯•æ—¶é—´æ‰©å±•ã€‚åœ¨è¿™äº›å‘å±•ä¸­ï¼Œå‡ºç°äº†ä¸€ä¸ªå…³é”®ç»Ÿä¸€èŒƒå¼ï¼šä»å¥–åŠ±ä¸­å­¦ä¹ ï¼Œå…¶ä¸­å¥–åŠ±ä¿¡å·å……å½“å¼•å¯¼LLMè¡Œä¸ºçš„æŒ‡å—é’ˆã€‚å®ƒå·²ç»æ”¯æŒäº†ä¸€ç³»åˆ—æµè¡ŒæŠ€æœ¯ï¼Œå¦‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFã€RLAIFã€DPOå’ŒGRPOï¼‰ã€å¥–åŠ±å¼•å¯¼è§£ç å’Œäº‹åæ ¡æ­£ã€‚å…³é”®çš„æ˜¯ï¼Œè¿™ä¸€èŒƒå¼å®ç°äº†ä»è¢«åŠ¨å­¦ä¹ é™æ€æ•°æ®åˆ°ä¸»åŠ¨å­¦ä¹ åŠ¨æ€åé¦ˆçš„è½¬å˜ã€‚è¿™ä½¿LLMå…·æœ‰å¯¹å„ç§ä»»åŠ¡çš„åå¥½å¯¹é½å’Œæ·±åº¦æ¨ç†èƒ½åŠ›ã€‚åœ¨è¿™ç¯‡ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬ä»å¥–åŠ±æ¨¡å‹å’Œè·¨è®­ç»ƒã€æ¨ç†å’Œåæ¨ç†é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥çš„è§’åº¦ï¼Œå…¨é¢æ¦‚è¿°äº†ä»å¥–åŠ±ä¸­å­¦ä¹ çš„æ¦‚å¿µã€‚æˆ‘ä»¬è¿˜è¿›ä¸€æ­¥è®¨è®ºäº†å¥–åŠ±æ¨¡å‹çš„åŸºå‡†æµ‹è¯•å’Œä¸»è¦åº”ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ã€‚æˆ‘ä»¬ä¿æŒè®ºæ–‡é›†åˆåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/bobxwu/learning-from-rewards-llm-papers">https://github.com/bobxwu/learning-from-rewards-llm-papers</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02686v2">PDF</a> 36 Pages</p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°å‘å±•å·²ä»é¢„è®­ç»ƒæ‰©å±•è½¬å‘åè®­ç»ƒå’Œæµ‹è¯•æ—¶æ‰©å±•ã€‚åœ¨è¿™äº›å‘å±•ä¸­ï¼Œä¸€ä¸ªå…³é”®ç»Ÿä¸€èŒƒå¼å·²ç»å‡ºç°ï¼šå­¦ä¹ å¥–åŠ±ï¼Œå…¶ä¸­å¥–åŠ±ä¿¡å·å……å½“å¼•å¯¼LLMè¡Œä¸ºçš„æŒ‡å¼•ã€‚è¿™ä¸€èŒƒå¼å·²æˆä¸ºä¸€ç³»åˆ—æµè¡ŒæŠ€æœ¯çš„åŸºçŸ³ï¼Œå¦‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFã€RLAIFã€DPOå’ŒGRPOï¼‰ã€å¥–åŠ±å¼•å¯¼è§£ç å’Œäº‹åæ ¡æ­£ç­‰ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œè¿™ç§èŒƒå¼ä½¿å¾—ä»è¢«åŠ¨å­¦ä¹ é™æ€æ•°æ®è½¬å‘ä¸»åŠ¨ä»åŠ¨æ€åé¦ˆä¸­å­¦ä¹ æˆä¸ºå¯èƒ½ã€‚è¿™ä¸ºLLMèµ‹äºˆäº†ç¬¦åˆåå¥½çš„æ·±åº¦æ¨ç†èƒ½åŠ›ï¼Œä»¥åº”å¯¹å„ç§ä»»åŠ¡ã€‚æœ¬æ–‡å°†ä»å¥–åŠ±æ¨¡å‹å’Œè·¨è®­ç»ƒã€æ¨ç†å’Œåæ¨ç†é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥çš„è§†è§’ï¼Œå…¨é¢æ¦‚è¿°å­¦ä¹ å¥–åŠ±ã€‚è¿˜å°†è®¨è®ºå¥–åŠ±æ¨¡å‹çš„åŸºå‡†å’Œä¸»è¦åº”ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ã€‚ç›¸å…³è®ºæ–‡é›†åˆè¯·å‚é˜…<a target="_blank" rel="noopener" href="https://github.com/bobxwu/learning-from-rewards-llm-papers%E3%80%82">https://github.com/bobxwu/learning-from-rewards-llm-papersã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å‘å±•çš„æœ€æ–°è¶‹åŠ¿æ˜¯ä»é¢„è®­ç»ƒæ‰©å±•è½¬å‘åè®­ç»ƒå’Œæµ‹è¯•æ—¶æ‰©å±•ã€‚</li>
<li>å­¦ä¹ å¥–åŠ±å·²æˆä¸ºä¸€ä¸ªå…³é”®ç»Ÿä¸€èŒƒå¼ï¼Œæ”¯æ’‘äº†å¼ºåŒ–å­¦ä¹ ã€å¥–åŠ±å¼•å¯¼è§£ç å’Œäº‹åæ ¡æ­£ç­‰æŠ€æœ¯ã€‚</li>
<li>å¥–åŠ±ä¿¡å·å¼•å¯¼LLMè¡Œä¸ºï¼Œä½¿å…¶ä»è¢«åŠ¨å­¦ä¹ è½¬å‘ä¸»åŠ¨ä»åŠ¨æ€åé¦ˆä¸­å­¦ä¹ ã€‚</li>
<li>å­¦ä¹ å¥–åŠ±èµ‹äºˆäº†LLMç¬¦åˆåå¥½çš„æ·±åº¦æ¨ç†èƒ½åŠ›ï¼Œé€‚åº”å„ç§ä»»åŠ¡ã€‚</li>
<li>è¯¥è®ºæ–‡å…¨é¢æ¦‚è¿°äº†å¥–åŠ±æ¨¡å‹å’Œè·¨è®­ç»ƒã€æ¨ç†åŠåæ¨ç†é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥ã€‚</li>
<li>è®ºæ–‡è®¨è®ºäº†å¥–åŠ±æ¨¡å‹çš„åŸºå‡†æµ‹è¯•å’Œä¸»è¦åº”ç”¨é¢†åŸŸã€‚</li>
<li>è®ºæ–‡å¼ºè°ƒäº†å½“å‰é¢ä¸´çš„æŒ‘æˆ˜å’Œæœªæ¥ç ”ç©¶æ–¹å‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02686">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5aace9210abe630d677e3a5eafea9f61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ec48bcdc9ad1835e16a6dabb184f9a3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c0a1258b5e5ebc11cc5968a0bd9478b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f55fc02860c598719485487386b5d711.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Skywork-R1V2-Multimodal-Hybrid-Reinforcement-Learning-for-Reasoning"><a href="#Skywork-R1V2-Multimodal-Hybrid-Reinforcement-Learning-for-Reasoning" class="headerlink" title="Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning"></a>Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning</h2><p><strong>Authors:Peiyu Wang, Yichen Wei, Yi Peng, Xiaokun Wang, Weijie Qiu, Wei Shen, Tianyidan Xie, Jiangbo Pei, Jianhao Zhang, Yunzhuo Hao, Xuchen Song, Yang Liu, Yahui Zhou</strong></p>
<p>We present Skywork R1V2, a next-generation multimodal reasoning model and a major leap forward from its predecessor, Skywork R1V. At its core, R1V2 introduces a hybrid reinforcement learning paradigm that jointly leverages the Mixed Preference Optimization (MPO) and the Group Relative Policy Optimization (GRPO), which harmonizes reward-model guidance with rule-based strategies, thereby addressing the long-standing challenge of balancing sophisticated reasoning capabilities with broad generalization. To further enhance training efficiency, we propose the Selective Sample Buffer (SSB) mechanism, which effectively addresses the vanishing advantages dilemma inherent in GRPO by prioritizing high-value samples throughout the optimization process. Notably, we observe that excessive reinforcement signals can induce visual hallucinationsâ€“a phenomenon we systematically monitor and mitigate through calibrated reward thresholds throughout the training process. Empirical results affirm the exceptional capability of R1V2, with benchmark-leading performances such as 62.6 on OlympiadBench, 78.9 on AIME2024, 63.6 on LiveCodeBench, and 73.6 on MMMU. These results underscore R1V2â€™s superiority over existing open-source models and demonstrate significant progress in closing the performance gap with premier proprietary systems, including Gemini 2.5 and OpenAI-o4-mini. The Skywork R1V2 model weights have been publicly released to promote openness and reproducibility <a target="_blank" rel="noopener" href="https://huggingface.co/Skywork/Skywork-R1V2-38B">https://huggingface.co/Skywork/Skywork-R1V2-38B</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºSkywork R1V2ï¼Œè¿™æ˜¯ä¸‹ä¸€ä»£å¤šæ¨¡æ€æ¨ç†æ¨¡å‹ï¼Œä¹Ÿæ˜¯å…¶å‰èº«Skywork R1Vçš„é‡å¤§é£è·ƒã€‚R1V2çš„æ ¸å¿ƒå¼•å…¥äº†ä¸€ç§æ··åˆå¼ºåŒ–å­¦ä¹ èŒƒå¼ï¼Œè¯¥èŒƒå¼ç»“åˆäº†æ··åˆåå¥½ä¼˜åŒ–ï¼ˆMPOï¼‰å’Œç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œå°†å¥–åŠ±æ¨¡å‹æŒ‡å¯¼ä¸åŸºäºè§„åˆ™çš„ç­–ç•¥ç›¸åè°ƒï¼Œä»è€Œè§£å†³äº†é•¿æœŸå­˜åœ¨çš„å¹³è¡¡å¤æ‚æ¨ç†èƒ½åŠ›ä¸å¹¿æ³›æ³›åŒ–èƒ½åŠ›ä¹‹é—´çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæˆ‘ä»¬æå‡ºäº†é€‰æ‹©æ€§æ ·æœ¬ç¼“å†²ï¼ˆSSBï¼‰æœºåˆ¶ï¼Œå®ƒé€šè¿‡åœ¨æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹ä¸­ä¼˜å…ˆå¤„ç†é«˜ä»·å€¼æ ·æœ¬ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†GRPOå›ºæœ‰çš„ä¼˜åŠ¿æ¶ˆå¤±å›°å¢ƒã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è¿‡å¤šçš„å¼ºåŒ–ä¿¡å·å¯èƒ½å¯¼è‡´è§†è§‰å¹»è§‰â€”â€”æˆ‘ä»¬é€šè¿‡è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ ¡å‡†å¥–åŠ±é˜ˆå€¼ç³»ç»Ÿåœ°ç›‘æµ‹å’Œç¼“è§£è¿™ä¸€ç°è±¡ã€‚å®è¯ç»“æœè¯å®äº†R1V2çš„å“è¶Šèƒ½åŠ›ï¼Œå…¶åœ¨OlympiadBenchä¸Šè¾¾åˆ°62.6ï¼ŒAIME2024ä¸Šè¾¾åˆ°78.9ï¼ŒLiveCodeBenchä¸Šè¾¾åˆ°63.6ï¼ŒMMMUä¸Šè¾¾åˆ°73.6ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†R1V2åœ¨ç°æœ‰å¼€æºæ¨¡å‹ä¸­çš„ä¼˜è¶Šæ€§ï¼Œå¹¶è¡¨æ˜åœ¨ç¼©å°ä¸é¡¶å°–ä¸“æœ‰ç³»ç»Ÿï¼ˆåŒ…æ‹¬Gemini 2.5å’ŒOpenAI-o4-miniï¼‰çš„æ€§èƒ½å·®è·æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚Skywork R1V2æ¨¡å‹æƒé‡å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›å¼€æ”¾æ€§å’Œå¯é‡å¤æ€§ã€‚<a target="_blank" rel="noopener" href="https://huggingface.co/Skywork/Skywork-R1V2-38B%E3%80%82">https://huggingface.co/Skywork/Skywork-R1V2-38Bã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16656v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Skywork R1V2æ˜¯ä¸‹ä¸€ä»£å¤šæ¨¡æ€æ¨ç†æ¨¡å‹ï¼Œç›¸æ¯”å…¶å‰èº«Skywork R1Væœ‰äº†é‡å¤§çªç ´ã€‚R1V2é‡‡ç”¨æ··åˆå¼ºåŒ–å­¦ä¹ èŒƒå¼ï¼Œç»“åˆMixed Preference Optimizationï¼ˆMPOï¼‰å’ŒGroup Relative Policy Optimizationï¼ˆGRPOï¼‰ï¼Œå¹³è¡¡äº†é«˜çº§æ¨ç†èƒ½åŠ›ä¸å¹¿æ³›æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºæé«˜è®­ç»ƒæ•ˆç‡ï¼Œæå‡ºäº†Selective Sample Bufferï¼ˆSSBï¼‰æœºåˆ¶ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹èƒ½æœ‰æ•ˆåº”å¯¹è¿‡åº¦å¼ºåŒ–ä¿¡å·å¼•èµ·çš„è§†è§‰å¹»è§‰é—®é¢˜ã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒR1V2åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¦‚OlympiadBenchã€AIME2024ã€LiveCodeBenchå’ŒMMMUï¼Œä¸”æ¨¡å‹æƒé‡å·²å…¬å¼€ä»¥ä¿ƒè¿›å¼€æ”¾å’Œå¯é‡å¤æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Skywork R1V2æ˜¯æ–°ä¸€ä»£å¤šæ¨¡æ€æ¨ç†æ¨¡å‹ï¼Œè¾ƒä¹‹å‰ç‰ˆæœ¬æœ‰é‡å¤§çªç ´ã€‚</li>
<li>R1V2é‡‡ç”¨æ··åˆå¼ºåŒ–å­¦ä¹ èŒƒå¼ï¼Œç»“åˆMPOå’ŒGRPOï¼Œä»¥å¹³è¡¡æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥SSBæœºåˆ¶æé«˜è®­ç»ƒæ•ˆç‡ï¼Œè§£å†³GRPOçš„å›ºæœ‰éš¾é¢˜ã€‚</li>
<li>æ¨¡å‹å¯åº”å¯¹è¿‡åº¦å¼ºåŒ–ä¿¡å·å¼•èµ·çš„è§†è§‰å¹»è§‰é—®é¢˜ã€‚</li>
<li>å®è¯ç»“æœè¡¨æ˜R1V2åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>æ¨¡å‹æƒé‡å·²å…¬å¼€ï¼Œä»¥ä¿ƒè¿›å¼€æ”¾å’Œå¯é‡å¤æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16656">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d666ed0b21d868fbeb0cd2e29228a842.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cdc5a21987e1ce0027d300ef8020c7b7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DeepSeek-R1-vs-o3-mini-How-Well-can-Reasoning-LLMs-Evaluate-MT-and-Summarization"><a href="#DeepSeek-R1-vs-o3-mini-How-Well-can-Reasoning-LLMs-Evaluate-MT-and-Summarization" class="headerlink" title="DeepSeek-R1 vs. o3-mini: How Well can Reasoning LLMs Evaluate MT and   Summarization?"></a>DeepSeek-R1 vs. o3-mini: How Well can Reasoning LLMs Evaluate MT and   Summarization?</h2><p><strong>Authors:Daniil Larionov, Sotaro Takeshita, Ran Zhang, Yanran Chen, Christoph Leiter, Zhipin Wang, Christian Greisinger, Steffen Eger</strong></p>
<p>Reasoning-enabled large language models (LLMs) excel in logical tasks, yet their utility for evaluating natural language generation remains unexplored. This study systematically compares reasoning LLMs with non-reasoning counterparts across machine translation and text summarization evaluation tasks. We evaluate eight models spanning state-of-the-art reasoning models (DeepSeek-R1, OpenAI o3), their distilled variants (8B-70B parameters), and equivalent non-reasoning LLMs. Experiments on WMT23 and SummEval benchmarks reveal architecture and task-dependent benefits: OpenAI o3-mini models show improved performance with increased reasoning on MT, while DeepSeek-R1 and generally underperforms compared to its non-reasoning variant except in summarization consistency evaluation. Correlation analysis demonstrates that reasoning token usage correlates with evaluation quality only in specific models, while almost all models generally allocate more reasoning tokens when identifying more quality issues. Distillation maintains reasonable performance up to 32B parameter models but degrades substantially at 8B scale. This work provides the first assessment of reasoning LLMs for NLG evaluation and comparison to non-reasoning models. We share our code to facilitate further research: <a target="_blank" rel="noopener" href="https://github.com/NL2G/reasoning-eval">https://github.com/NL2G/reasoning-eval</a>. </p>
<blockquote>
<p>å…·å¤‡æ¨ç†èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é€»è¾‘ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç„¶è€Œå®ƒä»¬åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆè¯„ä¼°æ–¹é¢çš„æ•ˆç”¨å°šæœªè¢«æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†æ¨ç†LLMä¸éæ¨ç†LLMåœ¨æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬æ‘˜è¦è¯„ä¼°ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚æˆ‘ä»¬è¯„ä¼°äº†å…«ç§æ¨¡å‹ï¼ŒåŒ…æ‹¬æœ€æ–°æ¨ç†æ¨¡å‹ï¼ˆDeepSeek-R1ï¼ŒOpenAI o3ï¼‰ã€å®ƒä»¬çš„è’¸é¦å˜ä½“ï¼ˆ8B-70Bå‚æ•°ï¼‰ï¼Œä»¥åŠç›¸åº”çš„éæ¨ç†LLMã€‚åœ¨WMT23å’ŒSummEvalåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒæ­ç¤ºäº†æ¶æ„å’Œä»»åŠ¡ä¾èµ–æ€§çš„å¥½å¤„ï¼šOpenAI o3-miniæ¨¡å‹åœ¨ç¿»è¯‘ä»»åŠ¡ä¸­å¢åŠ äº†æ¨ç†åŠŸèƒ½åè¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œè€ŒDeepSeek-R1é™¤äº†åœ¨æ‘˜è¦ä¸€è‡´æ€§è¯„ä¼°æ–¹é¢å¤–ï¼Œé€šå¸¸ä¸å…¶éæ¨ç†å˜ä½“ç›¸æ¯”è¡¨ç°è¾ƒå·®ã€‚ç›¸å…³æ€§åˆ†æè¡¨æ˜ï¼Œæ¨ç†ä»¤ç‰Œçš„ä½¿ç”¨ä»…åœ¨ä¸ç‰¹å®šæ¨¡å‹çš„è¯„ä»·è´¨é‡ç›¸å…³ï¼Œè€Œå‡ ä¹æ‰€æœ‰æ¨¡å‹åœ¨è¯†åˆ«æ›´å¤šè´¨é‡é—®é¢˜æ—¶ä¸€èˆ¬éƒ½ä¼šåˆ†é…æ›´å¤šçš„æ¨ç†ä»¤ç‰Œã€‚è’¸é¦æŠ€æœ¯å¯ä»¥åœ¨32Bå‚æ•°æ¨¡å‹ä¸Šä¿æŒåˆç†çš„æ€§èƒ½ï¼Œä½†åœ¨8Bè§„æ¨¡ä¸Šæ€§èƒ½ä¼šå¤§å¹…ä¸‹é™ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡å¯¹ç”¨äºè‡ªç„¶è¯­è¨€ç”Ÿæˆè¯„ä¼°çš„æ¨ç†LLMè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶ä¸éæ¨ç†æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬åˆ†äº«äº†æˆ‘ä»¬çš„ä»£ç ä»¥ä¿ƒè¿›è¿›ä¸€æ­¥çš„ç ”ç©¶ï¼š<a target="_blank" rel="noopener" href="https://github.com/NL2G/reasoning-eval%E3%80%82">https://github.com/NL2G/reasoning-evalã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08120v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å…·å¤‡æ¨ç†èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆè¯„ä¼°ä¸­çš„è¡¨ç°ã€‚æ–‡ç« é€šè¿‡å¯¹æ¯”å®éªŒå‘ç°ï¼Œåœ¨æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬æ‘˜è¦è¯„ä¼°ä»»åŠ¡ä¸­ï¼Œæ¨ç†LLMsä¸éæ¨ç†LLMsçš„è¡¨ç°å­˜åœ¨å·®å¼‚ã€‚æ–‡ç« è¿˜æŒ‡å‡ºï¼Œä¸åŒæ¨¡å‹å’Œä»»åŠ¡èƒŒæ™¯ä¸‹ï¼Œæ¨ç†èƒ½åŠ›å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“æœ‰æ‰€ä¸åŒã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¢è®¨äº†æ¨¡å‹è’¸é¦å¯¹æ¨ç†LLMsæ€§èƒ½çš„å½±å“ã€‚æœ¬æ–‡æä¾›äº†å¯¹æ¨ç†LLMsåœ¨NLGè¯„ä¼°ä¸­çš„é¦–æ¬¡è¯„ä¼°ï¼Œå¹¶ä¸éæ¨ç†æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨ç†LLMsåœ¨é€»è¾‘ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆè¯„ä¼°ä¸­çš„å®ç”¨æ€§å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>ç ”ç©¶å‘ç°ï¼Œåœ¨æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬æ‘˜è¦è¯„ä¼°ä»»åŠ¡ä¸­ï¼Œæ¨ç†LLMsä¸éæ¨ç†LLMsçš„è¡¨ç°ä¸åŒã€‚</li>
<li>OpenAI o3-miniæ¨¡å‹åœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸Šï¼Œå¢å¼ºæ¨ç†èƒ½åŠ›ä¼šæå‡æ€§èƒ½ã€‚</li>
<li>DeepSeek-R1æ¨¡å‹åœ¨å¤§éƒ¨åˆ†æƒ…å†µä¸‹ç›¸è¾ƒäºéæ¨ç†å˜ä½“åœ¨æ‘˜è¦ä¸€è‡´æ€§è¯„ä¼°æ–¹é¢è¡¨ç°è¾ƒå·®ã€‚</li>
<li>æ¨ç†æ ‡è®°çš„ä½¿ç”¨ä¸è¯„ä¼°è´¨é‡ä»…åœ¨ç‰¹å®šæ¨¡å‹ä¸­ç›¸å…³ï¼Œè€Œåœ¨å¤§å¤šæ•°æ¨¡å‹ä¸­ï¼Œè¯†åˆ«è´¨é‡é—®é¢˜æ—¶é€šå¸¸ä¼šåˆ†é…æ›´å¤šçš„æ¨ç†æ ‡è®°ã€‚</li>
<li>æ¨¡å‹è’¸é¦æŠ€æœ¯å¯ä»¥åœ¨å‚æ•°è§„æ¨¡è¾ƒå°çš„æ¨¡å‹ä¸­ä¿æŒè¾ƒå¥½çš„æ€§èƒ½ï¼Œä½†åœ¨8Bå‚æ•°è§„æ¨¡æ¨¡å‹ä¸­æ€§èƒ½ä¼šå¤§å¹…ä¸‹é™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08120">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-838e01e084b49a69071408450ac19b10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2fda1002c6e988bc23c2399be487b65.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2310a1d61a5a13c8c183f4eec908b548.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="FastCuRL-Curriculum-Reinforcement-Learning-with-Stage-wise-Context-Scaling-for-Efficient-Training-R1-like-Reasoning-Models"><a href="#FastCuRL-Curriculum-Reinforcement-Learning-with-Stage-wise-Context-Scaling-for-Efficient-Training-R1-like-Reasoning-Models" class="headerlink" title="FastCuRL: Curriculum Reinforcement Learning with Stage-wise Context   Scaling for Efficient Training R1-like Reasoning Models"></a>FastCuRL: Curriculum Reinforcement Learning with Stage-wise Context   Scaling for Efficient Training R1-like Reasoning Models</h2><p><strong>Authors:Mingyang Song, Mao Zheng, Zheng Li, Wenjie Yang, Xuan Luo, Yue Pan, Feng Zhang</strong></p>
<p>Improving training efficiency continues to be one of the primary challenges in large-scale Reinforcement Learning (RL). In this paper, we investigate how context length and the complexity of training data influence the RL scaling training process of R1-distilled small reasoning models, e.g., DeepSeek-R1-Distill-Qwen-1.5B. Our experimental results reveal that: (1) simply controlling the context length and curating the training data based on the input prompt length can effectively improve the training efficiency of scaling RL, achieving better performance with more concise CoT; (2) properly scaling the context length helps mitigate entropy collapse; and (3) choosing an optimal context length can improve the efficiency of model training and incentivize the modelâ€™s chain-of-thought reasoning capabilities. Inspired by these insights, we propose FastCuRL, a curriculum RL framework with stage-wise context scaling to achieve efficient training and concise CoT reasoning. Experiment results demonstrate that FastCuRL-1.5B-V3 significantly outperforms state-of-the-art reasoning models on five competition-level benchmarks and achieves 49.6% accuracy on AIME 2024. Furthermore, FastCuRL-1.5B-Preview surpasses DeepScaleR-1.5B-Preview on five benchmarks while only using a single node with 8 GPUs and a total of 50% of training steps. %The code, training data, and models will be publicly released. </p>
<blockquote>
<p>æ”¹è¿›è®­ç»ƒæ•ˆç‡ä»ç„¶æ˜¯å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸Šä¸‹æ–‡é•¿åº¦å’Œè®­ç»ƒæ•°æ®å¤æ‚æ€§å¯¹R1è’¸é¦å°å‹æ¨ç†æ¨¡å‹ï¼ˆä¾‹å¦‚DeepSeek-R1-Distill-Qwen-1.5Bï¼‰çš„RLè§„æ¨¡åŒ–è®­ç»ƒè¿‡ç¨‹çš„å½±å“ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœæ­ç¤ºï¼šï¼ˆ1ï¼‰é€šè¿‡æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦å¹¶æ ¹æ®è¾“å…¥æç¤ºé•¿åº¦ç­›é€‰è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜è§„æ¨¡åŒ–RLçš„è®­ç»ƒæ•ˆç‡ï¼Œå®ç°æ›´ç®€æ´çš„CoTï¼›ï¼ˆ2ï¼‰é€‚å½“ç¼©æ”¾ä¸Šä¸‹æ–‡é•¿åº¦æœ‰åŠ©äºå‡è½»ç†µå¡Œé™·ï¼›ï¼ˆ3ï¼‰é€‰æ‹©æœ€ä½³çš„ä¸Šä¸‹æ–‡é•¿åº¦å¯ä»¥æé«˜æ¨¡å‹è®­ç»ƒçš„æ•ˆç‡å¹¶æ¿€å‘æ¨¡å‹çš„æ€ç»´é“¾æ¨ç†èƒ½åŠ›ã€‚å—åˆ°è¿™äº›è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†FastCuRLï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰é˜¶æ®µæ€§ä¸Šä¸‹æ–‡ç¼©æ”¾çš„è¯¾ç¨‹RLæ¡†æ¶ï¼Œä»¥å®ç°é«˜æ•ˆçš„è®­ç»ƒå’Œç®€æ´çš„CoTæ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFastCuRL-1.5B-V3åœ¨äº”ä¸ªç«èµ›çº§åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡ä¼˜äºæœ€æ–°æ¨ç†æ¨¡å‹ï¼Œåœ¨AIME 2024ä¸Šè¾¾åˆ°49.6%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼ŒFastCuRL-1.5B-Previewåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†DeepScaleR-1.5B-Previewï¼ŒåŒæ—¶ä»…ä½¿ç”¨å•ä¸ªèŠ‚ç‚¹8ä¸ªGPUå’Œæ€»è®¡50%çš„è®­ç»ƒæ­¥éª¤ã€‚ç›¸å…³ä»£ç ã€è®­ç»ƒæ•°æ®å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17287v4">PDF</a> Ongoing Work</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä¸Šä¸‹æ–‡é•¿åº¦ä¸è®­ç»ƒæ•°æ®å¤æ‚æ€§å¯¹å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒæ•ˆç‡çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦å¹¶æ ¹æ®è¾“å…¥æç¤ºé•¿åº¦ç­›é€‰è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜RLè®­ç»ƒæ•ˆç‡ï¼Œå®ç°æ›´ç®€æ´çš„æ¨ç†è¿‡ç¨‹ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†FastCuRLè¯¾ç¨‹å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡é˜¶æ®µæ€§ä¸Šä¸‹æ–‡ç¼©æ”¾å®ç°é«˜æ•ˆè®­ç»ƒå’Œç®€æ´æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFastCuRLåœ¨å¤šä¸ªç«èµ›çº§åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦å’ŒåŸºäºè¾“å…¥æç¤ºé•¿åº¦ç­›é€‰è®­ç»ƒæ•°æ®å¯æœ‰æ•ˆæé«˜å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>é€‚å½“æ‰©å±•ä¸Šä¸‹æ–‡é•¿åº¦æœ‰åŠ©äºç¼“è§£ç†µå´©æºƒé—®é¢˜ã€‚</li>
<li>é€‰æ‹©æœ€ä½³ä¸Šä¸‹æ–‡é•¿åº¦èƒ½æå‡æ¨¡å‹è®­ç»ƒæ•ˆç‡å¹¶æ¿€å‘æ¨¡å‹çš„é“¾å¼æ¨ç†èƒ½åŠ›ã€‚</li>
<li>FastCuRLæ˜¯ä¸€ä¸ªç»“åˆé˜¶æ®µå¼ä¸Šä¸‹æ–‡ç¼©æ”¾çš„æ–°è¯¾ç¨‹å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆè®­ç»ƒå’Œç®€æ´æ¨ç†ã€‚</li>
<li>FastCuRLåœ¨å¤šä¸ªç«èµ›çº§åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ¨ç†æ¨¡å‹ã€‚</li>
<li>FastCuRL-1.5B-V3åœ¨AIME 2024ä¸Šè¾¾åˆ°49.6%çš„å‡†ç¡®ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17287">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-09102ec6c3604d5e62a4930be003baa0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ffa4cc8548c4776213af38b20f13fcd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f44de0422ab1091a44cdebfcc2930a2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e813df3d470a1238ef3a3ec9a5dd4a0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-24d970751b51814b76375456d86dfb0b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ada6043e79a325e8bad4c46c2ef795f0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ff9b0697bb11c4dc38f9413662dfc1f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e2dcdcdc3eb3827661dfde7ec629722.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8b6b1bff12b9d0b8a3dd1e2a2d718159.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Safety-Evaluation-and-Enhancement-of-DeepSeek-Models-in-Chinese-Contexts"><a href="#Safety-Evaluation-and-Enhancement-of-DeepSeek-Models-in-Chinese-Contexts" class="headerlink" title="Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts"></a>Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts</h2><p><strong>Authors:Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Limin Han, Jiaojiao Zhao, Junting Guo, Zhenhong Long, Shu Yang, Meijuan An, Beibei Huang, Rongjia Du, Ning Wang, Kai Wang, Shiguo Lian</strong></p>
<p>DeepSeek-R1, renowned for its exceptional reasoning capabilities and open-source strategy, is significantly influencing the global artificial intelligence landscape. However, it exhibits notable safety shortcomings. Recent research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 achieves a 100% attack success rate when processing harmful prompts. Furthermore, multiple security firms and research institutions have identified critical security vulnerabilities within the model. Although China Unicom has uncovered safety vulnerabilities of R1 in Chinese contexts, the safety capabilities of the remaining distilled models in the R1 series have not yet been comprehensively evaluated. To address this gap, this study utilizes the comprehensive Chinese safety benchmark CHiSafetyBench to conduct an in-depth safety evaluation of the DeepSeek-R1 series distilled models. The objective is to assess the safety capabilities of these models in Chinese contexts both before and after distillation, and to further elucidate the adverse effects of distillation on model safety. Building on these findings, we implement targeted safety enhancements for the entire DeepSeek-R1 model series. Evaluation results indicate that the enhanced models achieve significant improvements in safety while maintaining reasoning capabilities without notable degradation. We open-source the safety-enhanced models at <a target="_blank" rel="noopener" href="https://github.com/UnicomAI/DeepSeek-R1-Safe">https://github.com/UnicomAI/DeepSeek-R1-Safe</a> to serve as a valuable resource for future research and optimization of DeepSeek models. </p>
<blockquote>
<p>DeepSeek-R1ä»¥å…¶å‡ºè‰²çš„æ¨ç†èƒ½åŠ›å’Œå¼€æºç­–ç•¥è€Œé—»åï¼Œæ­£åœ¨å…¨çƒäººå·¥æ™ºèƒ½é¢†åŸŸäº§ç”Ÿé‡å¤§å½±å“ã€‚ç„¶è€Œï¼Œå®ƒå­˜åœ¨æ˜æ˜¾çš„å®‰å…¨ç¼ºé™·ã€‚æ€ç§‘å­å…¬å¸Robust Intelligenceä¸å®¾å¤•æ³•å°¼äºšå¤§å­¦æœ€è¿‘è¿›è¡Œçš„è”åˆç ”ç©¶è¡¨æ˜ï¼ŒDeepSeek-R1åœ¨å¤„ç†æœ‰å®³æç¤ºæ—¶è¾¾åˆ°äº†100%çš„æ”»å‡»æˆåŠŸç‡ã€‚æ­¤å¤–ï¼Œå¤šå®¶å®‰å…¨å…¬å¸å’Œç ”ç©¶æœºæ„å·²ç»å‘ç°äº†è¯¥æ¨¡å‹çš„å…³é”®å®‰å…¨æ¼æ´ã€‚è™½ç„¶ä¸­å›½è”é€šå·²ç»åœ¨ä¸­å›½èƒŒæ™¯ä¸‹å‘ç°äº†R1çš„å®‰å…¨æ¼æ´ï¼Œä½†R1ç³»åˆ—ä¸­å…¶ä½™è’¸é¦æ¨¡å‹çš„å®‰å…¨èƒ½åŠ›å°šæœªè¿›è¡Œå…¨é¢è¯„ä¼°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç©ºç™½ï¼Œæœ¬ç ”ç©¶åˆ©ç”¨å…¨é¢çš„ä¸­æ–‡å®‰å…¨åŸºå‡†CHiSafetyBenchå¯¹DeepSeek-R1ç³»åˆ—è’¸é¦æ¨¡å‹è¿›è¡Œæ·±å…¥çš„å®‰å…¨è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¯„ä¼°è¿™äº›æ¨¡å‹åœ¨ä¸­å›½èƒŒæ™¯ä¸‹çš„è’¸é¦å‰åçš„å®‰å…¨èƒ½åŠ›ï¼Œå¹¶è¿›ä¸€æ­¥é˜æ˜è’¸é¦å¯¹æ¨¡å‹å®‰å…¨çš„è´Ÿé¢å½±å“ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬å¯¹æ•´ä¸ªDeepSeek-R1æ¨¡å‹ç³»åˆ—å®æ–½äº†æœ‰é’ˆå¯¹æ€§çš„å®‰å…¨å¢å¼ºæªæ–½ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œå¢å¼ºå‹æ¨¡å‹åœ¨å®‰å…¨æ–¹é¢å®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒæ—¶ä¿æŒäº†æ¨ç†èƒ½åŠ›ï¼Œæ²¡æœ‰æ˜æ˜¾é€€åŒ–ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/UnicomAI/DeepSeek-R1-Safe">https://github.com/UnicomAI/DeepSeek-R1-Safe</a>å…¬å¼€äº†å¢å¼ºå®‰å…¨æ€§çš„æ¨¡å‹ï¼Œä»¥ä¾›æœªæ¥ç ”ç©¶å’Œä¼˜åŒ–DeepSeekæ¨¡å‹æ—¶ä½œä¸ºæœ‰ä»·å€¼çš„èµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.16529v2">PDF</a> 21 pages, 13 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>DeepSeek-R1æ¨¡å‹è™½ç„¶åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå±•ç°å‡ºè‰²çš„æ¨ç†èƒ½åŠ›å¹¶æ¨è¡Œå¼€æºç­–ç•¥ï¼Œä½†å…¶å­˜åœ¨é‡å¤§çš„å®‰å…¨éšæ‚£ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå½“é¢å¯¹æ¶æ„æç¤ºæ—¶ï¼ŒDeepSeek-R1ä¼šé­å—ç™¾åˆ†ä¹‹ç™¾çš„æ”»å‡»æˆåŠŸç‡ã€‚åŒæ—¶ï¼Œå¤šå®¶å®‰å…¨ä¼ä¸šå’Œç ”ç©¶æœºæ„å·²ç»å‘ç°äº†è¯¥æ¨¡å‹çš„å®‰å…¨æ¼æ´ã€‚ä¸­å›½è”é€šåˆ™å‘ç°äº†è¯¥æ¨¡å‹åœ¨ä¸­å›½è¯­å¢ƒä¸‹çš„å®‰å…¨æ¼æ´ï¼Œä½†å¯¹R1ç³»åˆ—å…¶ä»–è’¸é¦æ¨¡å‹çš„å®‰å…¨èƒ½åŠ›å°šæœªè¿›è¡Œå…¨é¢è¯„ä¼°ã€‚æœ¬ç ”ç©¶åˆ©ç”¨ä¸­æ–‡å®‰å…¨åŸºå‡†CHiSafetyBenchå¯¹DeepSeek-R1ç³»åˆ—è’¸é¦æ¨¡å‹è¿›è¡Œæ·±å…¥çš„å®‰å…¨è¯„ä¼°ï¼Œæ—¨åœ¨è¯„ä¼°è¿™äº›æ¨¡å‹åœ¨è’¸é¦å‰åçš„å®‰å…¨èƒ½åŠ›ï¼Œå¹¶è¿›ä¸€æ­¥ç ”ç©¶è’¸é¦å¯¹æ¨¡å‹å®‰å…¨çš„è´Ÿé¢å½±å“ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬å¯¹æ•´ä¸ªDeepSeek-R1æ¨¡å‹ç³»åˆ—å®æ–½äº†æœ‰é’ˆå¯¹æ€§çš„å®‰å…¨å¢å¼ºæªæ–½ï¼Œå¹¶åœ¨ä¿æŒæ¨ç†èƒ½åŠ›çš„åŒæ—¶æ˜¾è‘—æé«˜äº†å…¶å®‰å…¨æ€§ã€‚ç›¸å…³æˆæœå·²å¼€æºå…±äº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeepSeek-R1æ¨¡å‹åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå…·æœ‰å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å­˜åœ¨ä¸¥é‡çš„å®‰å…¨æ¼æ´ã€‚</li>
<li>å½“é¢å¯¹æ¶æ„æç¤ºæ—¶ï¼ŒDeepSeek-R1æ¨¡å‹ä¼šå—åˆ°ç™¾åˆ†ä¹‹ç™¾çš„æ”»å‡»ã€‚</li>
<li>å¤šå®¶å®‰å…¨ä¼ä¸šå’Œç ”ç©¶æœºæ„å·²ç»æŒ‡å‡ºè¯¥æ¨¡å‹çš„å®‰å…¨é—®é¢˜ã€‚</li>
<li>ä¸­å›½è”é€šåˆ™å‘ç°äº†è¯¥æ¨¡å‹åœ¨ä¸­å›½è¯­å¢ƒä¸‹çš„ç‰¹å®šå®‰å…¨æ¼æ´ã€‚</li>
<li>ç ”ç©¶åˆ©ç”¨CHiSafetyBenchå¯¹DeepSeek-R1ç³»åˆ—è’¸é¦æ¨¡å‹è¿›è¡Œäº†å…¨é¢çš„å®‰å…¨è¯„ä¼°ã€‚</li>
<li>è’¸é¦è¿‡ç¨‹å¯¹æ¨¡å‹çš„å®‰å…¨èƒ½åŠ›æœ‰è´Ÿé¢å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.16529">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b1210f228533444ae40f9ad4bd16df4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab078cfbb3cc0386d32853bd96dd4978.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c57acaeb951fdfa292f2da278b38e4b4.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="VeriContaminated-Assessing-LLM-Driven-Verilog-Coding-for-Data-Contamination"><a href="#VeriContaminated-Assessing-LLM-Driven-Verilog-Coding-for-Data-Contamination" class="headerlink" title="VeriContaminated: Assessing LLM-Driven Verilog Coding for Data   Contamination"></a>VeriContaminated: Assessing LLM-Driven Verilog Coding for Data   Contamination</h2><p><strong>Authors:Zeng Wang, Minghao Shao, Jitendra Bhandari, Likhitha Mankali, Ramesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel</strong></p>
<p>Large Language Models (LLMs) have revolutionized code generation, achieving exceptional results on various established benchmarking frameworks. However, concerns about data contamination - where benchmark data inadvertently leaks into pre-training or fine-tuning datasets - raise questions about the validity of these evaluations. While this issue is known, limiting the industrial adoption of LLM-driven software engineering, hardware coding has received little to no attention regarding these risks. For the first time, we analyze state-of-the-art (SOTA) evaluation frameworks for Verilog code generation (VerilogEval and RTLLM), using established methods for contamination detection (CCD and Min-K% Prob). We cover SOTA commercial and open-source LLMs (CodeGen2.5, Minitron 4b, Mistral 7b, phi-4 mini, LLaMA-{1,2,3.1}, GPT-{2,3.5,4o}, Deepseek-Coder, and CodeQwen 1.5), in baseline and fine-tuned models (RTLCoder and Verigen). Our study confirms that data contamination is a critical concern. We explore mitigations and the resulting trade-offs for code quality vs fairness (i.e., reducing contamination toward unbiased benchmarking). </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ï¼Œåœ¨å„ç§æˆç†Ÿçš„åŸºå‡†æµ‹è¯•æ¡†æ¶ä¸Šå–å¾—äº†éå‡¡çš„æˆæœã€‚ç„¶è€Œï¼Œå¯¹æ•°æ®æ±¡æŸ“çš„æ‹…å¿§â€”â€”å³åŸºå‡†æµ‹è¯•æ•°æ®æ— æ„ä¸­æ³„éœ²åˆ°é¢„è®­ç»ƒæˆ–å¾®è°ƒæ•°æ®é›†â€”â€”å¯¹è¿™äº›è¯„ä¼°çš„æœ‰æ•ˆæ€§æå‡ºäº†è´¨ç–‘ã€‚è™½ç„¶è¿™ä¸ªé—®é¢˜å·²ç»ä¸ºäººæ‰€çŸ¥ï¼Œå¹¶é™åˆ¶äº†LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹åœ¨å·¥ä¸šä¸Šçš„åº”ç”¨ï¼Œä½†ç¡¬ä»¶ç¼–ç å‡ ä¹æ²¡æœ‰å…³æ³¨è¿™äº›é£é™©ã€‚æˆ‘ä»¬é¦–æ¬¡ä½¿ç”¨æ±¡æŸ“æ£€æµ‹ç¡®ç«‹çš„æ–¹æ³•ï¼ˆCCDå’ŒMin-K% Probï¼‰åˆ†ææœ€å…ˆè¿›çš„Verilogä»£ç ç”Ÿæˆè¯„ä¼°æ¡†æ¶ï¼ˆVerilogEvalå’ŒRTLLMï¼‰ã€‚æˆ‘ä»¬æ¶µç›–äº†æœ€å…ˆè¿›çš„å•†ç”¨å’Œå¼€æºLLMï¼ˆCodeGen2.5ã€Minitron 4bã€Mistral 7bã€phi-4 miniã€LLaMA-{1,2,3.1}ã€GPT-{2,3.5,4o}ã€Deepseek-Coderå’ŒCodeQwen 1.5ï¼‰ï¼ŒåŸºçº¿æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹ï¼ˆRTLCoderå’ŒVerigenï¼‰ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¯å®äº†æ•°æ®æ±¡æŸ“æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚æˆ‘ä»¬æ¢è®¨äº†ç¼“è§£æªæ–½ä»¥åŠä»£ç è´¨é‡ä¸å…¬å¹³æ€§ä¹‹é—´çš„æƒè¡¡ï¼ˆå³å‡å°‘æ±¡æŸ“ä»¥å®ç°æ— åè§åŸºå‡†æµ‹è¯•ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13572v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢çš„å“è¶Šè¡¨ç°ï¼Œä½†æå‡ºäº†æ•°æ®æ±¡æŸ“çš„é—®é¢˜ï¼Œå¯¹è¯„ä¼°çš„åˆç†æ€§æå‡ºäº†è´¨ç–‘ã€‚ç ”ç©¶åˆ†æäº†æœ€å…ˆè¿›çš„Verilogä»£ç ç”Ÿæˆè¯„ä¼°æ¡†æ¶ï¼Œä½¿ç”¨æ±¡æŸ“æ£€æµ‹æ–¹æ³•æ¥è¦†ç›–å¤šä¸ªå•†ä¸šå’Œå¼€æºLLMsã€‚ç ”ç©¶ç¡®è®¤äº†æ•°æ®æ±¡æŸ“æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ï¼Œå¹¶æ¢è®¨äº†ç¼“è§£æªæ–½åŠå…¶ä¸ä»£ç è´¨é‡å’Œå…¬å¹³æ€§ä¹‹é—´çš„æƒè¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¹¶åœ¨å„ç§åŸºå‡†æµ‹è¯•æ¡†æ¶ä¸Šè¡¨ç°å‡ºè‰²ã€‚</li>
<li>æ•°æ®æ±¡æŸ“é—®é¢˜æˆä¸ºLLMåœ¨ä»£ç ç”Ÿæˆåº”ç”¨ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œå½±å“äº†è¯„ä¼°çš„åˆç†æ€§ã€‚</li>
<li>å¯¹æœ€å…ˆè¿›çš„Verilogä»£ç ç”Ÿæˆè¯„ä¼°æ¡†æ¶è¿›è¡Œäº†åˆ†æï¼ŒåŒ…æ‹¬VerilogEvalå’ŒRTLLMã€‚</li>
<li>ä½¿ç”¨äº†æ±¡æŸ“æ£€æµ‹æ–¹æ³•ï¼ˆå¦‚CCDå’ŒMin-K% Probï¼‰æ¥æ£€æµ‹æ•°æ®æ±¡æŸ“ã€‚</li>
<li>ç ”ç©¶è¦†ç›–äº†å¤šä¸ªå•†ä¸šå’Œå¼€æºLLMsï¼ŒåŒ…æ‹¬CodeGen2.5ã€Minitron 4bç­‰ã€‚</li>
<li>æ•°æ®æ±¡æŸ“å¯¹ä»£ç ç”Ÿæˆçš„è´¨é‡å’Œå…¬å¹³æ€§æ„æˆæƒè¡¡ï¼Œéœ€è¦è¿›è¡Œç¼“è§£æªæ–½çš„ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13572">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4e4e9a3f9398b0da48336c2352ae3724.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4709f17215072c2f1b7fbcfb5265a2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d9cbc0b5bf0382965889bea139ea0c37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ecd8384c56b1f966b0f8adc5a02e51b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e71ad7d5da003b540e398666068510b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-138220fc4df4e1398b017e4095b43b14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-38da2c008a157bae10609cf38641b4c4.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Reasoning-is-All-You-Need-for-Video-Generalization-A-Counterfactual-Benchmark-with-Sub-question-Evaluation"><a href="#Reasoning-is-All-You-Need-for-Video-Generalization-A-Counterfactual-Benchmark-with-Sub-question-Evaluation" class="headerlink" title="Reasoning is All You Need for Video Generalization: A Counterfactual   Benchmark with Sub-question Evaluation"></a>Reasoning is All You Need for Video Generalization: A Counterfactual   Benchmark with Sub-question Evaluation</h2><p><strong>Authors:Qiji Zhou, Yifan Gong, Guangsheng Bao, Hongjie Qiu, Jinqiang Li, Xiangrong Zhu, Huajian Zhang, Yue Zhang</strong></p>
<p>Counterfactual reasoning is crucial for robust video understanding but remains underexplored in existing multimodal benchmarks. In this paper, we introduce \textbf{COVER} (\textbf{\underline{CO}}unterfactual \textbf{\underline{V}}id\textbf{\underline{E}}o \textbf{\underline{R}}easoning), a multidimensional multimodal benchmark that systematically evaluates MLLMs across the abstract-concrete and perception-cognition dimensions. Beyond prior multimodal benchmarks, COVER decomposes complex queries into structured sub-questions, enabling fine-grained reasoning analysis. Experiments on commercial and open-source models reveal a strong correlation between sub-question accuracy and counterfactual reasoning performance, highlighting the role of structured inference in video understanding. Furthermore, our results suggest a key insight: enhancing the reasoning capability of models is essential for improving the robustness of video understanding. COVER establishes a new standard for assessing MLLMsâ€™ logical reasoning abilities in dynamic environments. Our work is available at <a target="_blank" rel="noopener" href="https://github.com/gongyifan-hash/COVER-Benchmark">https://github.com/gongyifan-hash/COVER-Benchmark</a>. </p>
<blockquote>
<p>å‡è®¾æ€§æ¨ç†å¯¹äºç¨³å¥çš„è§†é¢‘ç†è§£è‡³å…³é‡è¦ï¼Œä½†åœ¨ç°æœ‰çš„å¤šæ¨¡å¼åŸºå‡†æµ‹è¯•ä¸­ä»ç„¶è¢«æ¢ç´¢å¾—ä¸å¤Ÿæ·±å…¥ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†COVERï¼ˆCounterfactual Video Reasoning Benchmarkï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šç»´åº¦çš„å¤šæ¨¡å¼åŸºå‡†æµ‹è¯•ï¼Œç³»ç»Ÿåœ°è¯„ä¼°è·¨æŠ½è±¡ä¸å…·ä½“ç»´åº¦ä»¥åŠæ„ŸçŸ¥ä¸è®¤çŸ¥ç»´åº¦çš„å¤šæ¨¡æ€å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼ˆMLLMsï¼‰ã€‚ç›¸è¾ƒäºä¹‹å‰çš„æ¨¡æ€åŸºå‡†æµ‹è¯•ï¼ŒCOVERå°†å¤æ‚çš„æŸ¥è¯¢åˆ†è§£æˆç»“æ„åŒ–çš„å­é—®é¢˜ï¼Œä½¿ç²¾ç»†æ¨ç†åˆ†ææˆä¸ºå¯èƒ½ã€‚å¯¹å•†ä¸šå’Œå¼€æºæ¨¡å‹çš„å®éªŒæ˜¾ç¤ºå­é—®é¢˜å‡†ç¡®åº¦ä¸å‡è®¾æ€§æ¨ç†æ€§èƒ½ä¹‹é—´å­˜åœ¨å¼ºçƒˆç›¸å…³æ€§ï¼Œå‡¸æ˜¾ç»“æ„åŒ–æ¨ç†åœ¨è§†é¢‘ç†è§£ä¸­çš„ä½œç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœæ­ç¤ºäº†ä¸€ä¸ªå…³é”®è§è§£ï¼šæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ˜¯æå‡è§†é¢‘ç†è§£ç¨³å¥æ€§çš„å…³é”®ã€‚COVERä¸ºè¯„ä¼°å¤šæ¨¡æ€å¤§å‹é¢„è®­ç»ƒæ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€»è¾‘æ¨ç†èƒ½åŠ›å»ºç«‹äº†æ–°çš„æ ‡å‡†ã€‚æˆ‘ä»¬çš„å·¥ä½œå¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/gongyifan-hash/COVER-Benchmark%E3%80%82">https://github.com/gongyifan-hash/COVER-Benchmarkã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.10691v2">PDF</a> It has been accepted to the ACL-2025 Findings</p>
<p><strong>Summary</strong><br>è§†é¢‘ç†è§£ä¸­ï¼Œåäº‹å®æ¨ç†è‡³å…³é‡è¦ï¼Œä½†åœ¨ç°æœ‰çš„å¤šæ¨¡å¼åŸºå‡†æµ‹è¯•ä¸­ä»ç„¶è¢«å¿½è§†ã€‚æœ¬æ–‡ä»‹ç»äº†COVERåŸºå‡†æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šç»´åº¦çš„å¤šæ¨¡å¼åŸºå‡†æµ‹è¯•ï¼Œç³»ç»Ÿåœ°è¯„ä¼°äº†æŠ½è±¡ä¸å…·è±¡ã€æ„ŸçŸ¥ä¸è®¤çŸ¥ä¸¤ä¸ªç»´åº¦çš„å¤šåª’ä½“å­¦ä¹ æ¨¡å‹ã€‚ç›¸è¾ƒäºä¹‹å‰çš„å¤šåª’ä½“åŸºå‡†æµ‹è¯•ï¼ŒCOVERèƒ½å°†å¤æ‚çš„æŸ¥è¯¢åˆ†è§£æˆç»“æ„åŒ–çš„å­é—®é¢˜ï¼Œä»è€Œå®ç°ç²¾ç»†æ¨ç†åˆ†æã€‚å®éªŒè¡¨æ˜å­é—®é¢˜çš„å‡†ç¡®åº¦ä¸åäº‹å®æ¨ç†æ€§èƒ½ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸å…³æ€§ï¼Œçªæ˜¾ç»“æ„åŒ–æ¨ç†åœ¨è§†é¢‘ç†è§£ä¸­çš„ä½œç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ­ç¤ºäº†å…³é”®è§è§£ï¼šæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å¯¹äºæå‡è§†é¢‘ç†è§£çš„ç¨³å¥æ€§è‡³å…³é‡è¦ã€‚COVERä¸ºè¯„ä¼°å¤šåª’ä½“å­¦ä¹ æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€»è¾‘èƒ½åŠ›å»ºç«‹äº†æ–°æ ‡å‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†æ–°çš„å¤šæ¨¡å¼åŸºå‡†æµ‹è¯•COVERï¼Œç”¨äºè¯„ä¼°å¤šåª’ä½“å­¦ä¹ æ¨¡å‹åœ¨è§†é¢‘ç†è§£ä¸­çš„æ€§èƒ½ã€‚</li>
<li>COVERç³»ç»Ÿåœ°åœ¨æŠ½è±¡ä¸å…·è±¡ã€æ„ŸçŸ¥ä¸è®¤çŸ¥ä¸¤ä¸ªç»´åº¦ä¸Šè¯„ä¼°æ¨¡å‹ã€‚</li>
<li>é€šè¿‡å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºç»“æ„åŒ–å­é—®é¢˜ï¼ŒCOVERå®ç°äº†ç²¾ç»†æ¨ç†åˆ†æã€‚</li>
<li>å®éªŒæ˜¾ç¤ºå­é—®é¢˜çš„å‡†ç¡®åº¦ä¸åäº‹å®æ¨ç†æ€§èƒ½ä¹‹é—´å­˜åœ¨å¼ºçƒˆç›¸å…³æ€§ã€‚</li>
<li>ç»“æ„åŒ–æ¨ç†åœ¨è§†é¢‘ç†è§£ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚</li>
<li>æé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›èƒ½å¢å¼ºè§†é¢‘ç†è§£çš„ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.10691">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4ba1a5b9c4aace927c0a1bd69b897cc0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10d1d65b34ee3603f88949b83ae879c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b9935c6b0f8b41b97359d094ddde8d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05cea8fb9faa0e96e20c4c56611fd55d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14389d1d75e0f32bc19207b56f8235b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-add21b0e64e31a3d313a3e76f5dae4b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a29f30600bb8e3718697c13773629707.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="DAST-Difficulty-Adaptive-Slow-Thinking-for-Large-Reasoning-Models"><a href="#DAST-Difficulty-Adaptive-Slow-Thinking-for-Large-Reasoning-Models" class="headerlink" title="DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models"></a>DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models</h2><p><strong>Authors:Yi Shen, Jian Zhang, Jieyun Huang, Shuming Shi, Wenjing Zhang, Jiangze Yan, Ning Wang, Kai Wang, Zhaoxiang Liu, Shiguo Lian</strong></p>
<p>Recent advancements in slow thinking reasoning models have shown exceptional performance in complex reasoning tasks. However, these models often exhibit overthinking (generating redundant reasoning steps for simple problems), leading to excessive computational resource usage. While current mitigation strategies uniformly reduce reasoning tokens, they risk degrading performance on challenging tasks that require extended reasoning. This paper introduces Difficulty-Adaptive Slow Thinking (DAST), a novel framework that enables models to autonomously adjust the length of Chain-of-Thought (CoT) based on problem difficulty. We first propose a Token Length Budget (TLB) metric to quantify difficulty, then leverage budget-aware reward shaping and budget preference optimization to implement DAST. DAST penalizes overlong responses for simple tasks while incentivizing sufficient reasoning for complex problems. Experiments on diverse datasets and model scales demonstrate that DAST effectively mitigates overthinking (reducing token usage by over 30% on average) while preserving reasoning accuracy on complex problems. Our codes and models are available at <a target="_blank" rel="noopener" href="https://github.com/AnonymousUser0520/AnonymousRepo01">https://github.com/AnonymousUser0520/AnonymousRepo01</a>. </p>
<blockquote>
<p>è¿‘æœŸç¼“æ…¢æ€è€ƒæ¨ç†æ¨¡å‹çš„è¿›å±•åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¾€å¾€ä¼šå‡ºç°è¿‡åº¦æ€è€ƒçš„æƒ…å†µï¼ˆå¯¹ç®€å•é—®é¢˜äº§ç”Ÿå†—ä½™çš„æ¨ç†æ­¥éª¤ï¼‰ï¼Œå¯¼è‡´è®¡ç®—èµ„æºçš„ä½¿ç”¨è¿‡å¤šã€‚è™½ç„¶å½“å‰çš„ç¼“è§£ç­–ç•¥éƒ½ä¸€è‡´åœ°å‡å°‘æ¨ç†ä»¤ç‰Œï¼Œä½†å®ƒä»¬å¯èƒ½æŸå®³åœ¨éœ€è¦æ‰©å±•æ¨ç†çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æœ¬æ–‡ä»‹ç»äº†éš¾åº¦è‡ªé€‚åº”æ…¢æ€è€ƒï¼ˆDASTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®é—®é¢˜çš„éš¾åº¦è‡ªä¸»è°ƒæ•´æ€ç»´é“¾çš„é•¿åº¦ã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ä¸ªä»¤ç‰Œé•¿åº¦é¢„ç®—ï¼ˆTLBï¼‰æŒ‡æ ‡æ¥é‡åŒ–éš¾åº¦ï¼Œç„¶ååˆ©ç”¨é¢„ç®—æ„ŸçŸ¥å¥–åŠ±å¡‘é€ å’Œé¢„ç®—åå¥½ä¼˜åŒ–æ¥å®ç°DASTã€‚DASTå¯¹äºç®€å•çš„ä»»åŠ¡ä¼šæƒ©ç½šè¿‡é•¿çš„å›åº”ï¼ŒåŒæ—¶æ¿€åŠ±å¯¹å¤æ‚é—®é¢˜çš„å……åˆ†æ¨ç†ã€‚åœ¨å¤šæ ·æ•°æ®é›†å’Œä¸åŒè§„æ¨¡çš„æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDASTæœ‰æ•ˆåœ°ç¼“è§£äº†è¿‡åº¦æ€è€ƒçš„é—®é¢˜ï¼ˆå¹³å‡å‡å°‘è¶…è¿‡30%çš„ä»¤ç‰Œä½¿ç”¨ï¼‰ï¼ŒåŒæ—¶åœ¨è§£å†³å¤æ‚é—®é¢˜æ—¶ä¿æŒäº†æ¨ç†çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/AnonymousUser0520/AnonymousRepo01%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AnonymousUser0520/AnonymousRepo01è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04472v2">PDF</a> working in progress</p>
<p><strong>Summary</strong></p>
<p>æœ€è¿‘æ…¢æ€è€ƒæ¨ç†æ¨¡å‹çš„æ–°è¿›å±•åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†å¸¸æœ‰è¿‡åº¦æ€è€ƒç°è±¡ï¼Œé€ æˆè®¡ç®—èµ„æºæµªè´¹ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºDifficulty-Adaptive Slow Thinkingï¼ˆDASTï¼‰çš„æ–°æ¡†æ¶ï¼Œè®©æ¨¡å‹èƒ½æ ¹æ®é—®é¢˜éš¾åº¦è‡ªä¸»è°ƒæ•´æ€è€ƒé“¾é•¿åº¦ã€‚å®éªŒè¯æ˜ï¼ŒDASTæœ‰æ•ˆå‡å°‘è¿‡åº¦æ€è€ƒç°è±¡ï¼ŒåŒæ—¶ä¿æŒå¤æ‚é—®é¢˜çš„æ¨ç†å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ…¢æ€è€ƒæ¨ç†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>ç°æœ‰æ¨¡å‹å­˜åœ¨è¿‡åº¦æ€è€ƒç°è±¡ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚</li>
<li>DASTæ¡†æ¶èƒ½æ ¹æ®é—®é¢˜éš¾åº¦è‡ªä¸»è°ƒæ•´æ€è€ƒé“¾é•¿åº¦ã€‚</li>
<li>DASTé€šè¿‡Token Length Budgetï¼ˆTLBï¼‰åº¦é‡é—®é¢˜éš¾åº¦ã€‚</li>
<li>DASTé€šè¿‡é¢„ç®—æ„ŸçŸ¥å¥–åŠ±å¡‘å½¢å’Œé¢„ç®—åå¥½ä¼˜åŒ–æ¥å®ç°ã€‚</li>
<li>DASTåœ¨å®éªŒä¸­æœ‰æ•ˆå‡å°‘è¿‡åº¦æ€è€ƒç°è±¡ï¼Œå¹³å‡å‡å°‘ä»¤ç‰Œä½¿ç”¨è¶…è¿‡30%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04472">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db46f6f1feaa6961fd617f23cf79e1a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0aab8eb020d352f890bc3d8b4f148607.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-812dcf727e69dcc890620c0630c020d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f24090f5a1a035f2f641fcc74aff91c0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Marco-o1-v2-Towards-Widening-The-Distillation-Bottleneck-for-Reasoning-Models"><a href="#Marco-o1-v2-Towards-Widening-The-Distillation-Bottleneck-for-Reasoning-Models" class="headerlink" title="Marco-o1 v2: Towards Widening The Distillation Bottleneck for Reasoning   Models"></a>Marco-o1 v2: Towards Widening The Distillation Bottleneck for Reasoning   Models</h2><p><strong>Authors:Huifeng Yin, Yu Zhao, Minghao Wu, Xuanfan Ni, Bo Zeng, Hao Wang, Tianqi Shi, Liangying Shao, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang</strong></p>
<p>Large Reasoning Models(LRMs) such as OpenAI o1 and DeepSeek-R1 have shown remarkable reasoning capabilities by scaling test-time compute and generating long Chain-of-Thought(CoT). Distillationâ€“post-training on LRMs-generated dataâ€“is a straightforward yet effective method to enhance the reasoning abilities of smaller models, but faces a critical bottleneck: we found that distilled long CoT data poses learning difficulty for small models and leads to the inheritance of biases (i.e. over-thinking) when using Supervised Fine-tuning (SFT) and Reinforcement Learning (RL) methods. To alleviate this bottleneck, we propose constructing tree-based CoT data from scratch via Monte Carlo Tree Search(MCTS). We then exploit a set of CoT-aware approaches, including Thoughts Length Balance, Fine-grained DPO, and Joint Post-training Objective, to enhance SFT and RL on the constructed data. We conduct evaluation on various benchmarks such as math (GSM8K, MATH, AIME). instruction-following (Multi-IF) and planning (Blocksworld), results demonstrate our approaches substantially improve the reasoning performance of distilled models compared to standard distilled models via reducing the hallucinations in long-time thinking. The project homepage is <a target="_blank" rel="noopener" href="https://github.com/AIDC-AI/Marco-o1">https://github.com/AIDC-AI/Marco-o1</a>. </p>
<blockquote>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ï¼Œå¦‚OpenAI o1å’ŒDeepSeek-R1ï¼Œé€šè¿‡æ‰©å±•æµ‹è¯•æ—¶é—´è®¡ç®—å¹¶ç”Ÿæˆé•¿çš„æ€ç»´é“¾ï¼ˆCoTï¼‰è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ¨ç†èƒ½åŠ›ã€‚è’¸é¦â€”â€”åœ¨LRMsç”Ÿæˆçš„æ•°æ®ä¸Šè¿›è¡Œåè®­ç»ƒâ€”â€”æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥æé«˜è¾ƒå°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½†é¢ä¸´ä¸€ä¸ªå…³é”®çš„ç“¶é¢ˆï¼šæˆ‘ä»¬å‘ç°è’¸é¦å‡ºçš„é•¿CoTæ•°æ®ç»™å°å‹æ¨¡å‹å¸¦æ¥äº†å­¦ä¹ å›°éš¾ï¼Œåœ¨ä½¿ç”¨æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•æ—¶ä¼šå¯¼è‡´åè§ç»§æ‰¿ï¼ˆå³è¿‡åº¦æ€è€ƒï¼‰ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€ç“¶é¢ˆï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ä»å¤´æ„å»ºæ ‘çŠ¶CoTæ•°æ®ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸€ç³»åˆ—CoTæ„ŸçŸ¥æ–¹æ³•ï¼ŒåŒ…æ‹¬æ€ç»´é•¿åº¦å¹³è¡¡ã€ç²¾ç»†ç²’åº¦çš„DPOå’Œè”åˆåè®­ç»ƒç›®æ ‡ï¼Œæ¥æé«˜åœ¨æ„å»ºæ•°æ®ä¸Šçš„SFTå’ŒRLã€‚æˆ‘ä»¬åœ¨å„ç§åŸºå‡†æµ‹è¯•ï¼ˆå¦‚GSM8Kã€MATHã€AIMEçš„æ•°å­¦æµ‹è¯•ã€Multi-IFæŒ‡ä»¤éµå¾ªæµ‹è¯•å’ŒBlocksworldè§„åˆ’æµ‹è¯•ï¼‰ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å‡å°‘é•¿æ—¶é—´æ€è€ƒä¸­çš„å¹»è§‰ï¼Œæ˜¾è‘—æé«˜äº†è’¸é¦æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚é¡¹ç›®ä¸»é¡µæ˜¯<a target="_blank" rel="noopener" href="https://github.com/AIDC-AI/Marco-o1%E3%80%82">https://github.com/AIDC-AI/Marco-o1ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.01461v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆå¦‚OpenAI o1å’ŒDeepSeek-R1ï¼‰é€šè¿‡æ‰©å±•æµ‹è¯•æ—¶é—´è®¡ç®—å’Œç”Ÿæˆé•¿æœŸçš„æ€ç»´é“¾ï¼ˆCoTï¼‰å±•ç°å‡ºæƒŠäººçš„æ¨ç†èƒ½åŠ›ã€‚è’¸é¦â€”â€”åœ¨LRMsç”Ÿæˆçš„æ•°æ®ä¸Šè¿›è¡Œåè®­ç»ƒâ€”â€”æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æé«˜å°å‹æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æ–¹æ³•ï¼Œä½†é¢ä¸´ä¸€ä¸ªå…³é”®ç“¶é¢ˆï¼šæˆ‘ä»¬å‘ç°è’¸é¦çš„é•¿æœŸCoTæ•°æ®ç»™å°å‹æ¨¡å‹çš„å­¦ä¹ å¸¦æ¥äº†å›°éš¾ï¼Œå¹¶åœ¨ä½¿ç”¨æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•æ—¶å¯¼è‡´äº†åè§ï¼ˆå³è¿‡åº¦æ€è€ƒï¼‰çš„ç»§æ‰¿ã€‚ä¸ºç¼“è§£è¿™ä¸€ç“¶é¢ˆï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰æ„å»ºåŸºäºæ ‘çš„CoTæ•°æ®ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸€ç³»åˆ—CoTæ„ŸçŸ¥æ–¹æ³•ï¼ŒåŒ…æ‹¬æ€ç»´é•¿åº¦å¹³è¡¡ã€ç²¾ç»†ç²’åº¦çš„DPOå’Œè”åˆåè®­ç»ƒç›®æ ‡ï¼Œä»¥å¢å¼ºåœ¨æ„å»ºæ•°æ®ä¸Šçš„SFTå’ŒRLã€‚æˆ‘ä»¬åœ¨å„ç§åŸºå‡†æµ‹è¯•ï¼ˆå¦‚GSM8Kã€MATHã€AIMEçš„æ•°å­¦æµ‹è¯•ã€Multi-IFæŒ‡ä»¤éµå¾ªæµ‹è¯•å’ŒBlocksworldè§„åˆ’æµ‹è¯•ï¼‰ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•ç›¸æ¯”æ ‡å‡†è’¸é¦æ¨¡å‹ï¼Œé€šè¿‡å‡å°‘é•¿æœŸæ€è€ƒä¸­çš„å¹»è§‰ï¼Œå¤§å¤§æé«˜äº†è’¸é¦æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹æ¨ç†æ¨¡å‹å¦‚OpenAI o1å’ŒDeepSeek-R1å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡æ‰©å±•æµ‹è¯•æ—¶é—´è®¡ç®—å’Œç”Ÿæˆé•¿æœŸçš„æ€ç»´é“¾ã€‚</li>
<li>è’¸é¦æ˜¯ä¸€ç§æœ‰æ•ˆæé«˜å°å‹æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æ–¹æ³•ï¼Œä½†å­˜åœ¨å­¦ä¹ å›°éš¾å’Œåè§ç»§æ‰¿çš„é—®é¢˜ã€‚</li>
<li>è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰è¢«ç”¨äºæ„å»ºåŸºäºæ ‘çš„æ€ç»´é“¾æ•°æ®ï¼Œä»¥è§£å†³è’¸é¦ç“¶é¢ˆã€‚</li>
<li>æå‡ºäº†CoTæ„ŸçŸ¥æ–¹æ³•ï¼ŒåŒ…æ‹¬æ€ç»´é•¿åº¦å¹³è¡¡ã€ç²¾ç»†ç²’åº¦çš„DPOå’Œè”åˆåè®­ç»ƒç›®æ ‡ï¼Œä»¥å¢å¼ºå°å‹æ¨¡å‹åœ¨æ„å»ºæ•°æ®ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºæ–¹æ³•åœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—æé«˜äº†è’¸é¦æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>æ–¹æ³•é€šè¿‡å‡å°‘é•¿æœŸæ€è€ƒä¸­çš„å¹»è§‰æ¥å®ç°æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.01461">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-95ae85db25c067e512c338dbd8677cec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c1f0e6c618c20e67dbb32fb44dc4ea7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-696faa89902ff0a1647bd0259f7351c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24404ca17de1aa8e333275394c1717de.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-38fe6daaa57b5827d514a129f66091a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-413f2dd2d8f26ab18d4daa83700ef47c.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="From-System-1-to-System-2-A-Survey-of-Reasoning-Large-Language-Models"><a href="#From-System-1-to-System-2-A-Survey-of-Reasoning-Large-Language-Models" class="headerlink" title="From System 1 to System 2: A Survey of Reasoning Large Language Models"></a>From System 1 to System 2: A Survey of Reasoning Large Language Models</h2><p><strong>Authors:Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, Bao-Long Bi, Ling-Rui Mei, Junfeng Fang, Xiao Liang, Zhijiang Guo, Le Song, Cheng-Lin Liu</strong></p>
<p>Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 thinking. Recently, reasoning LLMs like OpenAIâ€™s o1&#x2F;o3 and DeepSeekâ€™s R1 have demonstrated expert-level performance in fields such as mathematics and coding, closely mimicking the deliberate reasoning of System 2 and showcasing human-like cognitive abilities. This survey begins with a brief overview of the progress in foundational LLMs and the early development of System 2 technologies, exploring how their combination has paved the way for reasoning LLMs. Next, we discuss how to construct reasoning LLMs, analyzing their features, the core methods enabling advanced reasoning, and the evolution of various reasoning LLMs. Additionally, we provide an overview of reasoning benchmarks, offering an in-depth comparison of the performance of representative reasoning LLMs. Finally, we explore promising directions for advancing reasoning LLMs and maintain a real-time \href{<a target="_blank" rel="noopener" href="https://github.com/zzli2022/Awesome-Slow-Reason-System%7D%7BGitHub">https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub</a> Repository} to track the latest developments. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this rapidly evolving field. </p>
<blockquote>
<p>å®ç°äººç±»æ°´å¹³çš„æ™ºèƒ½éœ€è¦å®Œå–„ä»å¿«é€Ÿç›´è§‰ç³»ç»Ÿ1åˆ°è¾ƒæ…¢ã€æ›´æ…é‡çš„ç³»ç»Ÿ2æ¨ç†çš„è½¬å˜ã€‚ç³»ç»Ÿ1æ“…é•¿å¿«é€Ÿã€å¯å‘å¼çš„å†³ç­–ï¼Œè€Œç³»ç»Ÿ2åˆ™ä¾èµ–äºé€»è¾‘æ¨ç†ä»¥åšå‡ºæ›´å‡†ç¡®çš„åˆ¤æ–­å’Œå‡å°‘åè§ã€‚åŸºç¡€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ“…é•¿å¿«é€Ÿå†³ç­–ï¼Œä½†åœ¨å¤æ‚æ¨ç†æ–¹é¢æ·±åº¦ä¸è¶³ï¼Œå› ä¸ºå®ƒä»¬å°šæœªå®Œå…¨æ¥å—ç³»ç»Ÿ2æ€ç»´æ‰€å…·æœ‰çš„æŒ‰éƒ¨å°±ç­åˆ†æçš„ç‰¹ç‚¹ã€‚æœ€è¿‘ï¼ŒåƒOpenAIçš„o1&#x2F;o3å’ŒDeepSeekçš„R1ç­‰æ¨ç†LLMåœ¨æ•°å­¦å’Œç¼–ç¨‹ç­‰é¢†åŸŸè¡¨ç°å‡ºäº†ä¸“å®¶çº§çš„æ€§èƒ½ï¼Œå®ƒä»¬å¾ˆå¥½åœ°æ¨¡ä»¿äº†ç³»ç»Ÿ2çš„æ…é‡æ¨ç†ï¼Œå±•ç¤ºäº†äººç±»èˆ¬çš„è®¤çŸ¥èƒ½åŠ›ã€‚è¿™ç¯‡ç»¼è¿°é¦–å…ˆç®€è¦æ¦‚è¿°äº†åŸºç¡€LLMå’Œç³»ç»Ÿ2æŠ€æœ¯çš„æ—©æœŸå‘å±•è¿›å±•ï¼Œæ¢è®¨äº†å®ƒä»¬ç›¸ç»“åˆå¦‚ä½•ä¸ºæ¨ç†LLMé“ºå¹³é“è·¯ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¨è®ºå¦‚ä½•æ„å»ºæ¨ç†LLMï¼Œåˆ†æå®ƒä»¬çš„ç‰¹ç‚¹ã€æ”¯æŒé«˜çº§æ¨ç†çš„æ ¸å¿ƒæ–¹æ³•ä»¥åŠå„ç§æ¨ç†LLMçš„æ¼”å˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¦‚è¿°äº†æ¨ç†åŸºå‡†æµ‹è¯•ï¼Œå¯¹ä»£è¡¨æ€§æ¨ç†LLMçš„æ€§èƒ½è¿›è¡Œäº†æ·±å…¥æ¯”è¾ƒã€‚æœ€åï¼Œæˆ‘ä»¬æ¢è®¨äº†æ¨è¿›æ¨ç†LLMçš„æœ‰å‰é€”çš„æ–¹å‘ï¼Œå¹¶ç»´æŠ¤ä¸€ä¸ªå®æ—¶GitHubä»“åº“æ¥è·Ÿè¸ªæœ€æ–°è¿›å±•ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ç¯‡ç»¼è¿°èƒ½åœ¨è¿™ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸæ¿€å‘åˆ›æ–°ï¼Œæ¨åŠ¨è¿›æ­¥ï¼Œæˆä¸ºæœ‰ä»·å€¼çš„èµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17419v4">PDF</a> Slow-thinking, Large Language Models, Human-like Reasoning, Decision   Making in AI, AGI</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†å®ç°äººç±»æ™ºèƒ½æ°´å¹³éœ€è¦å®Œå–„ä»å¿«é€Ÿç›´è§‰ç³»ç»Ÿ1åˆ°è¾ƒæ…¢ä½†æ›´æ…é‡çš„ç³»ç»Ÿ2æ¨ç†çš„è¿‡æ¸¡ã€‚æ–‡ç« æ¦‚è¿°äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ—©æœŸå‘å±•å’Œç³»ç»Ÿ2æŠ€æœ¯çš„èåˆï¼Œä»¥åŠæ¨ç†å‹LLMçš„è¿›æ­¥ã€‚æ–‡ç« è®¨è®ºäº†å¦‚ä½•æ„å»ºæ¨ç†å‹LLMï¼ŒåŒ…æ‹¬å…¶ç‰¹æ€§ã€æ ¸å¿ƒæ–¹æ³•å’Œä¸åŒæ¨ç†å‹LLMçš„å‘å±•æ¼”å˜ã€‚æ­¤å¤–ï¼Œè¿˜å¯¹æ¨ç†åŸºå‡†æµ‹è¯•è¿›è¡Œäº†æ¦‚è¿°ï¼Œæ·±å…¥æ¯”è¾ƒäº†ä»£è¡¨æ€§æ¨ç†å‹LLMçš„æ€§èƒ½ã€‚æœ€åï¼Œæ–‡ç« æ¢è®¨äº†æ¨è¿›æ¨ç†å‹LLMå‘å±•çš„å‰æ™¯ï¼Œå¹¶å®æ—¶æ›´æ–°GitHub Repositoryä»¥è¿½è¸ªæœ€æ–°è¿›å±•ã€‚æœ¬æ–‡æ—¨åœ¨ä¸ºè¿™ä¸€å¿«é€Ÿæ¼”å˜çš„é¢†åŸŸæä¾›æœ‰ä»·å€¼çš„èµ„æºï¼Œæ¿€å‘åˆ›æ–°ï¼Œæ¨åŠ¨è¿›æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®ç°äººç±»æ™ºèƒ½æ°´å¹³éœ€è¦æ”¹è¿›ä»ç›´è§‰å†³ç­–åˆ°æ…é‡æ¨ç†çš„è¿‡æ¸¡ï¼Œå³ç³»ç»Ÿ1åˆ°ç³»ç»Ÿ2çš„è½¬å˜ã€‚</li>
<li>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ“…é•¿å¿«é€Ÿå†³ç­–ï¼Œä½†ç¼ºä¹å¤æ‚æ¨ç†çš„æ·±åº¦ï¼Œæœªå®Œå…¨æ‹¥æŠ±ç³»ç»Ÿ2çš„é€æ­¥åˆ†æç‰¹æ€§ã€‚</li>
<li>æ¨ç†å‹LLMå¦‚OpenAIçš„o1&#x2F;o3å’ŒDeepSeekçš„R1å±•ç°å‡ºä¸“å®¶çº§æ€§èƒ½ï¼Œåœ¨æ¨¡æ‹Ÿç³»ç»Ÿ2çš„æ…é‡æ¨ç†å’Œå±•ç¤ºäººç±»è®¤çŸ¥ç‰¹å¾æ–¹é¢å–å¾—äº†è¿›å±•ã€‚</li>
<li>æ–‡ç« æ¦‚è¿°äº†åŸºç¡€LLMå’Œç³»ç»Ÿ2æŠ€æœ¯çš„èåˆè¿‡ç¨‹ï¼Œæ¢è®¨äº†å¦‚ä½•æ„å»ºæ¨ç†å‹LLMåŠå…¶æ ¸å¿ƒæ–¹æ³•å’Œç‰¹æ€§ã€‚</li>
<li>æ–‡ç« è®¨è®ºäº†æ¨ç†åŸºå‡†æµ‹è¯•ï¼Œæ·±å…¥æ¯”è¾ƒäº†ä»£è¡¨æ€§æ¨ç†å‹LLMçš„æ€§èƒ½å·®å¼‚ã€‚</li>
<li>æ–‡ç« å¼ºè°ƒäº†æ¨ç†å‹LLMçš„å‰æ™¯å’Œæ½œåœ¨å‘å±•æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17419">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2c1085980796db973ef870b71a6ded53.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc5aceef24f8e7e5983daa1fc44ee2eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c047003a9b7328a56b12c916bcec8935.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85d115415c9f1eb2f74be74b22e7364c.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Empowering-LLMs-with-Logical-Reasoning-A-Comprehensive-Survey"><a href="#Empowering-LLMs-with-Logical-Reasoning-A-Comprehensive-Survey" class="headerlink" title="Empowering LLMs with Logical Reasoning: A Comprehensive Survey"></a>Empowering LLMs with Logical Reasoning: A Comprehensive Survey</h2><p><strong>Authors:Fengxiang Cheng, Haoxuan Li, Fenrong Liu, Robert van Rooij, Kun Zhang, Zhouchen Lin</strong></p>
<p>Large language models (LLMs) have achieved remarkable successes on various tasks. However, recent studies have found that there are still significant challenges to the logical reasoning abilities of LLMs, which can be categorized into the following two aspects: (1) Logical question answering: LLMs often fail to generate the correct answer within a complex logical problem which requires sophisticated deductive, inductive or abductive reasoning given a collection of premises and constrains. (2) Logical consistency: LLMs are prone to producing responses contradicting themselves across different questions. For example, a state-of-the-art question-answering LLM Macaw, answers Yes to both questions Is a magpie a bird? and Does a bird have wings? but answers No to Does a magpie have wings?. To facilitate this research direction, we comprehensively investigate the most cutting-edge methods and propose a detailed taxonomy. Specifically, to accurately answer complex logic questions, previous methods can be categorized based on reliance on external solvers, prompts, and fine-tuning. To avoid logical contradictions, we discuss concepts and solutions of various logical consistencies, including implication, negation, transitivity, factuality consistencies, and their composites. In addition, we review commonly used benchmark datasets and evaluation metrics, and discuss promising research directions, such as extending to modal logic to account for uncertainty and developing efficient algorithms that simultaneously satisfy multiple logical consistencies. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆå°±ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶å‘ç°ï¼ŒLLMçš„é€»è¾‘æ¨ç†èƒ½åŠ›ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œè¿™äº›æŒ‘æˆ˜å¯å½’çº³ä¸ºä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢ï¼šï¼ˆ1ï¼‰é€»è¾‘é—®ç­”ï¼šåœ¨å¤æ‚çš„é€»è¾‘é—®é¢˜ä¸­ï¼ŒLLMå¾€å¾€æ— æ³•åœ¨ç»™å®šçš„å‰æå’Œçº¦æŸä¸‹ï¼Œé€šè¿‡æ¼”ç»ã€å½’çº³æˆ–æº¯å› æ¨ç†ç”Ÿæˆæ­£ç¡®çš„ç­”æ¡ˆã€‚ï¼ˆ2ï¼‰é€»è¾‘ä¸€è‡´æ€§ï¼šLLMå®¹æ˜“äº§ç”Ÿè‡ªç›¸çŸ›ç›¾çš„å›ç­”ã€‚ä¾‹å¦‚ï¼Œæœ€å…ˆè¿›çš„é—®ç­”LLM Macawå¯¹â€œå–œé¹Šæ˜¯é¸Ÿå—ï¼Ÿâ€å’Œâ€œé¸Ÿæœ‰ç¿…è†€å—ï¼Ÿâ€ä¸¤ä¸ªé—®é¢˜éƒ½å›ç­”â€œæ˜¯â€ï¼Œä½†å¯¹â€œå–œé¹Šæœ‰ç¿…è†€å—ï¼Ÿâ€çš„é—®é¢˜å´å›ç­”â€œå¦â€ã€‚ä¸ºäº†ä¿ƒè¿›è¿™ä¸ªç ”ç©¶æ–¹å‘ï¼Œæˆ‘ä»¬å…¨é¢è°ƒæŸ¥äº†æœ€å…ˆè¿›çš„æ–¹æ³•å¹¶æå‡ºäº†è¯¦ç»†çš„åˆ†ç±»ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å‡†ç¡®å›ç­”å¤æ‚çš„é€»è¾‘é—®é¢˜ï¼Œä»¥å‰çš„æ–¹æ³•å¯ä»¥æŒ‰å¯¹å¤–éƒ¨æ±‚è§£å™¨ã€æç¤ºå’Œå¾®è°ƒç­‰çš„ä¾èµ–è¿›è¡Œåˆ†ç±»ã€‚ä¸ºäº†é¿å…é€»è¾‘çŸ›ç›¾ï¼Œæˆ‘ä»¬è®¨è®ºäº†å„ç§é€»è¾‘ä¸€è‡´æ€§çš„æ¦‚å¿µåŠè§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬è•´æ¶µã€å¦å®šã€ä¼ é€’æ€§ã€äº‹å®ä¸€è‡´æ€§åŠå…¶ç»„åˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å›é¡¾äº†å¸¸ç”¨çš„åŸºå‡†æ•°æ®é›†å’Œè¯„ä»·æŒ‡æ ‡ï¼Œå¹¶è®¨è®ºäº†æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ï¼Œå¦‚æ‰©å±•åˆ°æ¨¡æ€é€»è¾‘ä»¥è€ƒè™‘ä¸ç¡®å®šæ€§ï¼Œå¹¶å¼€å‘èƒ½åŒæ—¶æ»¡è¶³å¤šç§é€»è¾‘ä¸€è‡´æ€§çš„é«˜æ•ˆç®—æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15652v3">PDF</a> Accepted by IJCAI 2025 (Survey Track)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„é¡¹ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†åœ¨é€»è¾‘æ¨ç†æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œä¸»è¦è¡¨ç°ä¸ºé€»è¾‘é—®ç­”å’Œé€»è¾‘ä¸€è‡´æ€§ä¸¤ä¸ªæ–¹é¢ã€‚é€»è¾‘é—®ç­”æ–¹é¢ï¼ŒLLMsåœ¨å¤æ‚é€»è¾‘é—®é¢˜ä¸­éš¾ä»¥ç»™å‡ºæ­£ç¡®ç­”æ¡ˆã€‚é€»è¾‘ä¸€è‡´æ€§æ–¹é¢ï¼ŒLLMsçš„å›ç­”ä¼šåœ¨ä¸åŒé—®é¢˜ä¸­å‡ºç°è‡ªç›¸çŸ›ç›¾çš„æƒ…å†µã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬è°ƒæŸ¥äº†æœ€å‰æ²¿çš„æ–¹æ³•ï¼Œå¹¶æå‡ºäº†è¯¦ç»†çš„åˆ†ç±»ã€‚ä¸ºè§£å†³é€»è¾‘çŸ›ç›¾ï¼Œæˆ‘ä»¬è®¨è®ºäº†å„ç§é€»è¾‘ä¸€è‡´æ€§çš„æ¦‚å¿µå’Œè§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€»è¾‘æ¨ç†æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬é€»è¾‘é—®ç­”å’Œé€»è¾‘ä¸€è‡´æ€§ã€‚</li>
<li>åœ¨é€»è¾‘é—®ç­”æ–¹é¢ï¼ŒLLMséš¾ä»¥ç»™å‡ºå¤æ‚é€»è¾‘é—®é¢˜çš„æ­£ç¡®ç­”æ¡ˆã€‚</li>
<li>åœ¨é€»è¾‘ä¸€è‡´æ€§æ–¹é¢ï¼ŒLLMsçš„å›ç­”ä¼šå‡ºç°è‡ªç›¸çŸ›ç›¾çš„æƒ…å†µã€‚</li>
<li>æœ€å‰æ²¿çš„æ–¹æ³•å¯ä»¥åŸºäºå¤–éƒ¨æ±‚è§£å™¨ã€æç¤ºå’Œå¾®è°ƒæ¥å›ç­”å¤æ‚çš„é€»è¾‘é—®é¢˜ã€‚</li>
<li>ä¸ºé¿å…é€»è¾‘çŸ›ç›¾ï¼Œéœ€è¦è®¨è®ºå„ç§é€»è¾‘ä¸€è‡´æ€§çš„æ¦‚å¿µå’Œè§£å†³æ–¹æ¡ˆã€‚</li>
<li>å¸¸ç”¨çš„åŸºå‡†æ•°æ®é›†å’Œè¯„ä»·æŒ‡æ ‡è¢«å›é¡¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15652">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee30c5fca10db3b8409e2bd929939728.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fb9cacb9394a54ea1f591ee452e98504.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5c48b8e8212f227dbb8a8da4815a0dfc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4a5bf547d59d73a13c0b9c38d0e3b56d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-384e916276ba0e3a5489a4d7e7c9921d.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Quantifying-the-Capability-Boundary-of-DeepSeek-Models-An-Application-Driven-Performance-Analysis"><a href="#Quantifying-the-Capability-Boundary-of-DeepSeek-Models-An-Application-Driven-Performance-Analysis" class="headerlink" title="Quantifying the Capability Boundary of DeepSeek Models: An   Application-Driven Performance Analysis"></a>Quantifying the Capability Boundary of DeepSeek Models: An   Application-Driven Performance Analysis</h2><p><strong>Authors:Kaikai Zhao, Zhaoxiang Liu, Xuejiao Lei, Jiaojiao Zhao, Zhenhong Long, Zipeng Wang, Ning Wang, Meijuan An, Qingliang Meng, Peijun Yang, Minjie Hua, Chaoyang Ma, Wen Liu, Kai Wang, Shiguo Lian</strong></p>
<p>DeepSeek-R1, known for its low training cost and exceptional reasoning capabilities, has achieved state-of-the-art performance on various benchmarks. However, detailed evaluations for DeepSeek Series models from the perspective of real-world applications are lacking, making it challenging for users to select the most suitable DeepSeek models for their specific needs. To address this gap, we presents the first comprehensive evaluation of the DeepSeek and its related models (including DeepSeek-V3, DeepSeek-R1, DeepSeek-R1-Distill-Qwen series, DeepSeek-R1-Distill-Llama series, their corresponding 4-bit quantized models, and the reasoning model QwQ-32B) using our enhanced A-Eval benchmark, A-Eval-2.0. Our systematic analysis reveals several key insights: (1) Given identical model architectures and training data, larger parameter models demonstrate superior performance, aligning with the scaling law. However, smaller models may achieve enhanced capabilities when employing optimized training strategies and higher-quality data; (2) Reasoning-enhanced model show significant performance gains in logical reasoning tasks but may underperform in text understanding and generation tasks; (3) As the data difficulty increases, distillation or reasoning enhancements yield higher performance gains for the models. Interestingly, reasoning enhancements can even have a negative impact on simpler problems; (4) Quantization impacts different capabilities unevenly, with significant drop on logical reasoning and minimal impact on text generation. Based on these results and findings, we design an model selection handbook enabling users to select the most cost-effective models without efforts. </p>
<blockquote>
<p>DeepSeek-R1ä»¥å…¶ä½è®­ç»ƒæˆæœ¬å’Œå‡ºè‰²çš„æ¨ç†èƒ½åŠ›è€Œè‘—ç§°ï¼Œå·²åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä»å®é™…åº”ç”¨çš„è§’åº¦å¯¹DeepSeekç³»åˆ—æ¨¡å‹çš„è¯¦ç»†è¯„ä¼°ä»ç„¶ç¼ºä¹ï¼Œè¿™ä½¿å¾—ç”¨æˆ·éš¾ä»¥é€‰æ‹©æœ€é€‚åˆå…¶ç‰¹å®šéœ€æ±‚çš„DeepSeekæ¨¡å‹ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬åˆ©ç”¨å¢å¼ºçš„A-EvalåŸºå‡†æµ‹è¯•ï¼Œå³A-Eval-2.0ï¼Œå¯¹DeepSeekåŠå…¶ç›¸å…³æ¨¡å‹ï¼ˆåŒ…æ‹¬DeepSeek-V3ã€DeepSeek-R1ã€DeepSeek-R1-Distill-Qwenç³»åˆ—ã€DeepSeek-R1-Distill-Llamaç³»åˆ—ã€å…¶å¯¹åº”çš„4ä½é‡åŒ–æ¨¡å‹ä»¥åŠæ¨ç†æ¨¡å‹QwQ-32Bï¼‰è¿›è¡Œäº†é¦–æ¬¡å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿåˆ†ææ­ç¤ºäº†å‡ ä¸ªå…³é”®è§è§£ï¼š</p>
</blockquote>
<p>ï¼ˆ1ï¼‰åœ¨ç›¸åŒçš„æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæ•°æ®ä¸‹ï¼Œå‚æ•°è§„æ¨¡è¾ƒå¤§çš„æ¨¡å‹è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œè¿™ä¸è§„æ¨¡å®šå¾‹ç›¸ç¬¦ã€‚ç„¶è€Œï¼Œå½“é‡‡ç”¨ä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥å’Œé«˜è´¨é‡æ•°æ®æ—¶ï¼Œå°å‹æ¨¡å‹å¯èƒ½ä¼šå®ç°å¢å¼ºçš„èƒ½åŠ›ï¼›</p>
<p>ï¼ˆ2ï¼‰å¢å¼ºæ¨ç†çš„æ¨¡å‹åœ¨é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä½†åœ¨æ–‡æœ¬ç†è§£å’Œç”Ÿæˆä»»åŠ¡ä¸­å¯èƒ½è¡¨ç°è¾ƒå·®ï¼›</p>
<p>ï¼ˆ3ï¼‰éšç€æ•°æ®éš¾åº¦çš„å¢åŠ ï¼Œè’¸é¦æˆ–æ¨ç†å¢å¼ºä¸ºæ¨¡å‹å¸¦æ¥äº†æ›´é«˜çš„æ€§èƒ½æå‡ã€‚æœ‰è¶£çš„æ˜¯ï¼Œæ¨ç†å¢å¼ºç”šè‡³å¯èƒ½å¯¹è¾ƒç®€å•çš„é—®é¢˜äº§ç”Ÿè´Ÿé¢å½±å“ï¼›</p>
<p>ï¼ˆ4ï¼‰é‡åŒ–å¯¹ä¸åŒèƒ½åŠ›çš„å½±å“ä¸å‡è¡¡ï¼Œå¯¹é€»è¾‘æ¨ç†æœ‰æ˜¾è‘—çš„ä¸‹é™ï¼Œå¯¹æ–‡æœ¬ç”Ÿæˆçš„å½±å“æœ€å°ã€‚åŸºäºè¿™äº›ç»“æœå’Œå‘ç°ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€æœ¬æ¨¡å‹é€‰æ‹©æ‰‹å†Œï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾é€‰æ‹©æœ€ç»æµå®æƒ çš„æ¨¡å‹ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11164v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¯¹DeepSeekç³»åˆ—æ¨¡å‹ï¼ˆåŒ…æ‹¬DeepSeek-V3ã€DeepSeek-R1ç­‰ï¼‰çš„é¦–æ¬¡å…¨é¢è¯„ä¼°ã€‚ç ”ç©¶ä½¿ç”¨A-Eval 2.0åŸºå‡†æµ‹è¯•ï¼Œå‘ç°å¤§å‹å‚æ•°æ¨¡å‹æ€§èƒ½ä¼˜è¶Šï¼Œä½†ä¼˜åŒ–è®­ç»ƒç­–ç•¥å’Œæé«˜æ•°æ®è´¨é‡ä¹Ÿå¯èƒ½æå‡å°å‹æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¢å¼ºæ¨ç†æ¨¡å‹åœ¨é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨æ–‡æœ¬ç†è§£å’Œç”Ÿæˆä»»åŠ¡ä¸­å¯èƒ½è¡¨ç°ä¸ä½³ã€‚éšç€æ•°æ®éš¾åº¦çš„å¢åŠ ï¼Œè’¸é¦æˆ–æ¨ç†å¢å¼ºå¯¹æ¨¡å‹æ€§èƒ½çš„æå‡æ›´å¤§ã€‚é‡åŒ–å¯¹ä¸åŒçš„èƒ½åŠ›å½±å“ä¸å‡ï¼Œé€»è¾‘æ¨ç†å—å½±å“è¾ƒå¤§ï¼Œæ–‡æœ¬ç”Ÿæˆå—å½±å“è¾ƒå°ã€‚åŸºäºè¿™äº›ç»“æœï¼Œè®¾è®¡äº†ä¸€ä¸ªæ¨¡å‹é€‰æ‹©æ‰‹å†Œï¼Œå¸®åŠ©ç”¨æˆ·é€‰æ‹©æœ€ç»æµé«˜æ•ˆçš„æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹å‚æ•°æ¨¡å‹åœ¨ç›¸åŒæ¶æ„å’Œè®­ç»ƒæ•°æ®ä¸‹è¡¨ç°ä¼˜è¶Šï¼Œä½†å°å‹æ¨¡å‹é€šè¿‡ä¼˜åŒ–è®­ç»ƒç­–ç•¥å’Œæé«˜æ•°æ®è´¨é‡ä¹Ÿå¯èƒ½å®ç°å¢å¼ºæ€§èƒ½ã€‚</li>
<li>æ¨ç†å¢å¼ºæ¨¡å‹åœ¨é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°æ˜¾è‘—ï¼Œä½†åœ¨æ–‡æœ¬ç†è§£å’Œç”Ÿæˆä»»åŠ¡ä¸­å¯èƒ½è¡¨ç°ä¸è¶³ã€‚</li>
<li>éšç€æ•°æ®éš¾åº¦çš„å¢åŠ ï¼Œæ¨¡å‹ä¸­çš„è’¸é¦æˆ–æ¨ç†å¢å¼ºå¸¦æ¥çš„æ€§èƒ½æå‡æ›´åŠ æ˜æ˜¾ã€‚</li>
<li>é‡åŒ–å¯¹æ¨¡å‹çš„ä¸åŒèƒ½åŠ›å½±å“ä¸åŒï¼Œé€»è¾‘æ¨ç†å—å½±å“è¾ƒå¤§ï¼Œè€Œæ–‡æœ¬ç”Ÿæˆå—å½±å“è¾ƒå°ã€‚</li>
<li>A-Eval 2.0åŸºå‡†æµ‹è¯•èƒ½æœ‰æ•ˆè¯„ä¼°DeepSeekç³»åˆ—æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>ç”¨æˆ·å¯ä»¥æ ¹æ®æ¨¡å‹é€‰æ‹©æ‰‹å†Œè½»æ¾é€‰æ‹©æœ€ç»æµé«˜æ•ˆçš„æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11164">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f897124c701e393d6f8d5c7bc68172da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-610ca94921a22b69af95da15ac53b01e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b51342aa4639fd000929d68e90ba1283.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Exposing-Numeracy-Gaps-A-Benchmark-to-Evaluate-Fundamental-Numerical-Abilities-in-Large-Language-Models"><a href="#Exposing-Numeracy-Gaps-A-Benchmark-to-Evaluate-Fundamental-Numerical-Abilities-in-Large-Language-Models" class="headerlink" title="Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical   Abilities in Large Language Models"></a>Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical   Abilities in Large Language Models</h2><p><strong>Authors:Haoyang Li, Xuejia Chen, Zhanchao XU, Darian Li, Nicole Hu, Fei Teng, Yiming Li, Luyu Qiu, Chen Jason Zhang, Qing Li, Lei Chen</strong></p>
<p>Large Language Models (LLMs) have demonstrated impressive capabilities in natural language processing tasks, such as text generation and semantic understanding. However, their performance on numerical reasoning tasks, such as basic arithmetic, numerical retrieval, and magnitude comparison, remains surprisingly poor. This gap arises from their reliance on surface-level statistical patterns rather than understanding numbers as continuous magnitudes. Existing benchmarks primarily focus on either linguistic competence or structured mathematical problem-solving, neglecting fundamental numerical reasoning required in real-world scenarios. To bridge this gap, we propose NumericBench, a comprehensive benchmark to evaluate six fundamental numerical capabilities: number recognition, arithmetic operations, contextual retrieval, comparison, summary, and logical reasoning. NumericBench includes datasets ranging from synthetic number lists to the crawled real-world data, addressing challenges like long contexts, noise, and multi-step reasoning. Extensive experiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal persistent weaknesses in numerical reasoning, highlighting the urgent need to improve numerically-aware language modeling. The benchmark is released in: <a target="_blank" rel="noopener" href="https://github.com/TreeAI-Lab/NumericBench">https://github.com/TreeAI-Lab/NumericBench</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆå’Œè¯­ä¹‰ç†è§£ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨æ•°å€¼æ¨ç†ä»»åŠ¡ï¼ˆå¦‚åŸºæœ¬ç®—æœ¯ã€æ•°å€¼æ£€ç´¢å’Œå¹…åº¦æ¯”è¾ƒï¼‰ä¸Šçš„è¡¨ç°å´å‡ºäººæ„æ–™åœ°å·®ã€‚è¿™ç§å·®è·çš„äº§ç”Ÿæ˜¯å› ä¸ºå®ƒä»¬ä¾èµ–äºè¡¨é¢å±‚æ¬¡çš„ç»Ÿè®¡æ¨¡å¼ï¼Œè€Œä¸æ˜¯å°†æ•°å­—è§†ä¸ºè¿ç»­çš„å¹…åº¦æ¥ç†è§£ã€‚ç°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­äºè¯­è¨€æŠ€èƒ½æˆ–ç»“æ„åŒ–çš„æ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›ï¼Œå¿½è§†äº†ç°å®åœºæ™¯ä¸­æ‰€éœ€çš„åŸºæœ¬æ•°å€¼æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†NumericBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å…­é¡¹åŸºæœ¬æ•°å€¼èƒ½åŠ›ï¼šæ•°å­—è¯†åˆ«ã€ç®—æœ¯è¿ç®—ã€ä¸Šä¸‹æ–‡æ£€ç´¢ã€æ¯”è¾ƒã€æ€»ç»“å’Œé€»è¾‘æ¨ç†ã€‚NumericBenchåŒ…å«äº†ä»åˆæˆæ•°å­—åˆ—è¡¨åˆ°çˆ¬å–çš„çœŸå®ä¸–ç•Œæ•°æ®çš„å„ç§æ•°æ®é›†ï¼Œè§£å†³äº†é•¿ä¸Šä¸‹æ–‡ã€å™ªå£°å’Œå¤šæ­¥æ¨ç†ç­‰æŒ‘æˆ˜ã€‚åœ¨åŒ…æ‹¬GPT-4å’ŒDeepSeekç­‰åœ¨å†…çš„æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œå®ƒä»¬åœ¨æ•°å€¼æ¨ç†æ–¹é¢å­˜åœ¨æŒä¹…çš„å¼±ç‚¹ï¼Œè¿™å‡¸æ˜¾äº†æé«˜æ•°å€¼æ„ŸçŸ¥è¯­è¨€æ¨¡å‹çš„ç´§è¿«éœ€æ±‚ã€‚è¯¥åŸºå‡†æµ‹è¯•å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/TreeAI-Lab/NumericBench%E3%80%82">https://github.com/TreeAI-Lab/NumericBenchã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11075v2">PDF</a> Accepted by ACL 2025</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†åœ¨æ•°å€¼æ¨ç†ä»»åŠ¡æ–¹é¢çš„è¡¨ç°å´ä»¤äººæƒŠè®¶åœ°ä¸è¶³ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¨¡å‹çš„æ–¹æ³•â€”â€”NumericBenchï¼Œå®ƒèƒ½è¯„ä»·æ¨¡å‹åœ¨å…­é¡¹åŸºç¡€æ•°å€¼èƒ½åŠ›ä¸Šçš„è¡¨ç°ã€‚åŒ…æ‹¬æ•°å­—è¯†åˆ«ã€ç®—æœ¯è¿ç®—ã€ä¸Šä¸‹æ–‡æ£€ç´¢ã€æ¯”è¾ƒã€æ€»ç»“å’Œé€»è¾‘æ¨ç†ã€‚å®éªŒç»“æœæ­ç¤ºäº†é¡¶å°–çš„å¤§å‹è¯­è¨€æ¨¡å‹å¦‚GPT-4å’ŒDeepSeekåœ¨æ•°å€¼æ¨ç†ä¸Šçš„æŒç»­å¼±ç‚¹ï¼Œçªæ˜¾äº†æé«˜æ•°å€¼æ„ŸçŸ¥è¯­è¨€æ¨¡å‹çš„ç´§è¿«æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†åœ¨æ•°å€¼æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸ä½³ã€‚</li>
<li>æ•°å€¼æ¨ç†èƒ½åŠ›çš„ç¼ºå¤±ä¸»è¦æºäºæ¨¡å‹ä¾èµ–è¡¨é¢ç»Ÿè®¡æ¨¡å¼ï¼Œè€Œéå¯¹æ•°å­—ä½œä¸ºè¿ç»­å¹…åº¦çš„ç†è§£ã€‚</li>
<li>ç°æœ‰åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨è¯­è¨€èƒ½åŠ›å’Œç»“æ„åŒ–æ•°å­¦é—®é¢˜è§£ç­”ï¼Œå¿½è§†äº†ç°å®ä¸–ç•Œä¸­æ‰€éœ€çš„åŸºæœ¬æ•°å€¼æ¨ç†èƒ½åŠ›ã€‚</li>
<li>NumericBenchæ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨å…­é¡¹åŸºç¡€æ•°å€¼èƒ½åŠ›ä¸Šçš„è¡¨ç°ï¼ŒåŒ…æ‹¬æ•°å­—è¯†åˆ«ã€ç®—æœ¯è¿ç®—ã€ä¸Šä¸‹æ–‡æ£€ç´¢ã€æ¯”è¾ƒã€æ€»ç»“å’Œé€»è¾‘æ¨ç†ã€‚</li>
<li>NumericBenchæ¶µç›–äº†ä»åˆæˆæ•°å­—åˆ—è¡¨åˆ°ç½‘ç»œçˆ¬å–çš„çœŸå®ä¸–ç•Œæ•°æ®çš„æ•°æ®é›†ï¼Œè§£å†³äº†é•¿ä¸Šä¸‹æ–‡ã€å™ªå£°å’Œå¤šæ­¥æ¨ç†ç­‰æŒ‘æˆ˜ã€‚</li>
<li>åœ¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šçš„å®éªŒæ­ç¤ºäº†å…¶åœ¨æ•°å€¼æ¨ç†æ–¹é¢çš„æŒç»­å¼±ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11075">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-be08aa66dc386b2d1c4a71dca571b6b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b71e7b24b228e9c47da1e1cc6f543dc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-52eaf5d6ffa8981968027384e69a7c46.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-16/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-16/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-17/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-0106ae2049aba135f37814fd5207b9e6.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-17  Schema-R1 A reasoning training approach for schema linking in   Text-to-SQL Task
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-15/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-9eb026e43b0e88695451e9c2a8a04736.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-15  ChartReasoner Code-Driven Modality Bridging for Long-Chain Reasoning in   Chart Question Answering
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23154.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
