<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-03-23  I2AM Interpreting Image-to-Image Latent Diffusion Models via   Bi-Attribution Maps">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-3b1cfb85ef253ce7d5d7780d27d9d33c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-23-更新"><a href="#2025-03-23-更新" class="headerlink" title="2025-03-23 更新"></a>2025-03-23 更新</h1><h2 id="I2AM-Interpreting-Image-to-Image-Latent-Diffusion-Models-via-Bi-Attribution-Maps"><a href="#I2AM-Interpreting-Image-to-Image-Latent-Diffusion-Models-via-Bi-Attribution-Maps" class="headerlink" title="I2AM: Interpreting Image-to-Image Latent Diffusion Models via   Bi-Attribution Maps"></a>I2AM: Interpreting Image-to-Image Latent Diffusion Models via   Bi-Attribution Maps</h2><p><strong>Authors:Junseo Park, Hyeryung Jang</strong></p>
<p>Large-scale diffusion models have made significant advances in image generation, particularly through cross-attention mechanisms. While cross-attention has been well-studied in text-to-image tasks, their interpretability in image-to-image (I2I) diffusion models remains underexplored. This paper introduces Image-to-Image Attribution Maps (I2AM), a method that enhances the interpretability of I2I models by visualizing bidirectional attribution maps, from the reference image to the generated image and vice versa. I2AM aggregates cross-attention scores across time steps, attention heads, and layers, offering insights into how critical features are transferred between images. We demonstrate the effectiveness of I2AM across object detection, inpainting, and super-resolution tasks. Our results demonstrate that I2AM successfully identifies key regions responsible for generating the output, even in complex scenes. Additionally, we introduce the Inpainting Mask Attention Consistency Score (IMACS) as a novel evaluation metric to assess the alignment between attribution maps and inpainting masks, which correlates strongly with existing performance metrics. Through extensive experiments, we show that I2AM enables model debugging and refinement, providing practical tools for improving I2I model’s performance and interpretability. </p>
<blockquote>
<p>大规模扩散模型在图像生成方面取得了重大进展，特别是通过交叉注意机制。虽然交叉注意在文本到图像的任务中已经被很好地研究过，但它们在图像到图像（I2I）扩散模型中的解释性仍然被忽视。本文介绍了图像到图像归因图（I2AM），这是一种通过可视化双向归因图增强I2I模型解释性的方法，从参考图像到生成的图像反之亦然。I2AM聚合了时间步长、注意力头和层的交叉注意力得分，提供了关于图像之间如何转移关键特征的见解。我们在对象检测、图像修复和超分辨率任务中展示了I2AM的有效性。我们的结果表明，I2AM成功地识别了负责生成输出的关键区域，即使在复杂的场景中也是如此。此外，我们引入了图像修复掩膜注意力一致性得分（IMACS）作为新的评估指标，以评估归因图与图像修复掩膜之间的对齐程度，这与现有的性能指标具有很强的相关性。通过大量实验，我们证明了I2AM能够实现模型调试和优化，为改进I2I模型的性能和解释性提供了实用工具。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.12331v2">PDF</a> 23 pages</p>
<p><strong>Summary</strong></p>
<p>大型扩散模型在图像生成方面取得了显著进展，特别是通过跨注意力机制。本文介绍了一种提高图像到图像（I2I）模型可解释性的方法——图像到图像归属图（I2AM）。I2AM通过可视化双向归属图，从参考图像到生成图像，反之亦然，增强了I2I模型的解释性。I2AM聚合了跨时间步长、注意力头和层的交叉注意力分数，揭示了关键特征如何在图像间转移。通过实验验证，I2AM在对象检测、图像修复和超分辨率任务中表现出有效性，并能成功识别出输出生成的关键区域，即使在复杂场景中也是如此。此外，还引入了修复遮罩注意力一致性得分（IMACS）作为评估归属图与修复遮罩对齐情况的新评价指标，与现有性能指标有强相关性。I2AM为模型调试和优化提供了实用工具，提高了I2I模型的性能和可解释性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型扩散模型在图像生成领域通过跨注意力机制取得了显著进展。</li>
<li>图像到图像（I2I）模型的解释性仍然有待探索。</li>
<li>I2AM方法通过可视化双向归属图增强I2I模型的解释性。</li>
<li>I2AM揭示了关键特征如何在图像间转移，通过聚合跨时间步长、注意力头和层的交叉注意力分数。</li>
<li>I2AM在对象检测、图像修复和超分辨率任务中表现出有效性。</li>
<li>IMACS作为新的评价指标，用于评估归属图与修复遮罩的对齐情况。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.12331">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-37fbabb0119b58ed09024f79ad2467b3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-949bffbbb414857314be4e3b4c4af128.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd59b6e3380f95e6279c4fa8f296d9f5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3b1cfb85ef253ce7d5d7780d27d9d33c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Tiny-models-from-tiny-data-Textual-and-null-text-inversion-for-few-shot-distillation"><a href="#Tiny-models-from-tiny-data-Textual-and-null-text-inversion-for-few-shot-distillation" class="headerlink" title="Tiny models from tiny data: Textual and null-text inversion for few-shot   distillation"></a>Tiny models from tiny data: Textual and null-text inversion for few-shot   distillation</h2><p><strong>Authors:Erik Landolsi, Fredrik Kahl</strong></p>
<p>Few-shot learning deals with problems such as image classification using very few training examples. Recent vision foundation models show excellent few-shot transfer abilities, but are large and slow at inference. Using knowledge distillation, the capabilities of high-performing but slow models can be transferred to tiny, efficient models. However, common distillation methods require a large set of unlabeled data, which is not available in the few-shot setting. To overcome this lack of data, there has been a recent interest in using synthetic data. We expand on this line of research by presenting a novel diffusion model inversion technique (TINT) combining the diversity of textual inversion with the specificity of null-text inversion. Using this method in a few-shot distillation pipeline leads to state-of-the-art accuracy among small student models on popular benchmarks, while being significantly faster than prior work. Popular few-shot benchmarks involve evaluation over a large number of episodes, which is computationally cumbersome for methods involving synthetic data generation. We also present a theoretical analysis on how the accuracy estimator variance depends on the number of episodes and query examples, and use these results to lower the computational effort required for method evaluation. Finally, to further motivate the use of generative models in few-shot distillation, we demonstrate that our method outperforms training on real data mined from the dataset used in the original diffusion model training. Source code is available at <a target="_blank" rel="noopener" href="https://github.com/pixwse/tiny2">https://github.com/pixwse/tiny2</a>. </p>
<blockquote>
<p>少量学习处理的问题包括使用极少训练样本的图像分类等。最近的视觉基础模型展现出优秀的少量转移能力，但在推理时体积庞大且速度较慢。使用知识蒸馏技术，高性能但速度较慢的模型的能力可以转移到微小、高效的模型上。然而，常见的蒸馏方法需要大量未标记数据，这在少量设置中是不可用的。为了克服数据缺乏的问题，最近对使用合成数据产生了兴趣。我们通过对文本反转的多样性和空文本反转的特异性相结合，提出了一种新型扩散模型反转技术（TINT）。将这种技术应用于少量蒸馏管道中，在流行基准测试上，小型学生模型的准确率达到了最新水平，同时比先前的工作显著更快。流行的少量基准测试涉及大量片段的评估，这对于涉及合成数据生成的方法在计算上很繁琐。我们还对准确度估算器方差如何依赖于片段数量和查询示例进行了理论分析，并利用这些结果降低了方法评估所需的计算工作量。最后，为了进一步推动生成模型在少量蒸馏中的应用，我们证明了我们的方法在真实数据训练上优于从原始扩散模型训练所用的数据集中挖掘的数据。源代码可在<a target="_blank" rel="noopener" href="https://github.com/pixwse/tiny2%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pixwse/tiny2找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.03146v2">PDF</a> 24 pages (13 main pages + references and appendix)</p>
<p><strong>Summary</strong></p>
<p>本文介绍了针对少样本图像分类问题的研究，通过使用知识蒸馏技术将高性能但运行缓慢的模型的能力转移到小型高效模型上。提出了一种新颖的扩散模型反演技术（TINT），结合了文本反演的多样性和无文本反演的特异性。在少样本蒸馏管道中使用此方法，小型学生模型在流行基准测试上达到了最先进的准确性，同时显著快于以前的工作。此外，文章还进行了理论分析和准确性估计方差与集会和查询示例数量之间的依赖关系，以降低评估方法的计算负担。最后，该研究展示了在少样本蒸馏中使用生成模型的优势，提出的方法优于在原始扩散模型训练数据集中挖掘的真实数据的训练效果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>介绍少样本学习问题及其挑战，特别是图像分类任务中利用极少训练样本的情况。</li>
<li>阐述最近愿景基础模型在少样本迁移能力方面的出色表现，但存在模型体积大、推理速度慢的问题。</li>
<li>利用知识蒸馏技术，将高性能模型的能力转移到小型高效模型上。</li>
<li>提出一种新颖的扩散模型反演技术（TINT），结合文本反演的多样性和无文本反演的特异性，用于少样本蒸馏。</li>
<li>TINT方法在流行基准测试上表现出优异的准确性，且计算效率高于以往方法。</li>
<li>进行理论分析和准确性估计方差分析，以降低评估方法的计算负担。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.03146">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-cd6ab3d5cd16a2668137ec591aa485a6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5be455852856e3c83c059532e49e3b44.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-40cf26792c35b11cb8c120150181abdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ceb7cc15d77dfec92d7646eda551a3f4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bf381ec319aa7cf4fd10cf8af3b82bac.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Paint-by-Inpaint-Learning-to-Add-Image-Objects-by-Removing-Them-First"><a href="#Paint-by-Inpaint-Learning-to-Add-Image-Objects-by-Removing-Them-First" class="headerlink" title="Paint by Inpaint: Learning to Add Image Objects by Removing Them First"></a>Paint by Inpaint: Learning to Add Image Objects by Removing Them First</h2><p><strong>Authors:Navve Wasserman, Noam Rotstein, Roy Ganz, Ron Kimmel</strong></p>
<p>Image editing has advanced significantly with the introduction of text-conditioned diffusion models. Despite this progress, seamlessly adding objects to images based on textual instructions without requiring user-provided input masks remains a challenge. We address this by leveraging the insight that removing objects (Inpaint) is significantly simpler than its inverse process of adding them (Paint), attributed to inpainting models that benefit from segmentation mask guidance. Capitalizing on this realization, by implementing an automated and extensive pipeline, we curate a filtered large-scale image dataset containing pairs of images and their corresponding object-removed versions. Using these pairs, we train a diffusion model to inverse the inpainting process, effectively adding objects into images. Unlike other editing datasets, ours features natural target images instead of synthetic ones while ensuring source-target consistency by construction. Additionally, we utilize a large Vision-Language Model to provide detailed descriptions of the removed objects and a Large Language Model to convert these descriptions into diverse, natural-language instructions. Our quantitative and qualitative results show that the trained model surpasses existing models in both object addition and general editing tasks. Visit our project page for the released dataset and trained models at <a target="_blank" rel="noopener" href="https://rotsteinnoam.github.io/Paint-by-Inpaint">https://rotsteinnoam.github.io/Paint-by-Inpaint</a>. </p>
<blockquote>
<p>图像编辑随着文本条件扩散模型的引入已经取得了显著的进步。尽管如此，根据文本指令无缝添加对象到图像中，而无需用户提供输入掩码仍然是一个挑战。我们通过利用这样一个见解来解决这个问题：去除物体（补画）比反向过程添加它们（绘画）要简单得多，这归功于受益于分割掩码指导的补画模型。基于这一认识，我们通过实现自动化和广泛的管道，整理了一个包含图像及其相应去对象版本配对的大规模图像数据集。使用这些配对数据，我们训练了一个扩散模型来反转补画过程，有效地将对象添加到图像中。与其他编辑数据集不同，我们的数据集以自然目标图像为特色，并通过构建确保源-目标一致性。此外，我们利用大型视觉语言模型为删除的对象提供详细描述，并利用大型语言模型将这些描述转换为多样、自然的指令。我们的定量和定性结果表明，训练模型在对象添加和一般编辑任务上都超越了现有模型。请访问我们的项目页面获取发布的数据集和训练模型：<a target="_blank" rel="noopener" href="https://rotsteinnoam.github.io/Paint-by-Inpaint%E3%80%82">https://rotsteinnoam.github.io/Paint-by-Inpaint。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.18212v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于文本条件的扩散模型在图像编辑中的最新进展。针对在图像中根据文本指令无缝添加对象而无需用户提供的输入掩模的挑战，研究团队提出了一种解决方案。他们利用去除对象（修复）比添加对象（绘画）更简单的事实，构建了一个自动化的大规模管道，从大型图像数据集中筛选出图像及其对应的去对象版本。使用这些数据对扩散模型进行训练，以反转修复过程，实现向图像中添加对象。该数据集包含自然目标图像而非合成图像，并在构建时确保源-目标一致性。此外，他们还使用大型视觉语言模型提供有关移除对象的详细描述，并利用大型语言模型将这些描述转换为多样化的自然语言指令。研究结果显示，训练出的模型在对象添加和一般编辑任务上均超越了现有模型。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文本条件的扩散模型在图像编辑中取得了显著进展。</li>
<li>在根据文本指令无缝添加对象到图像中仍存在挑战。</li>
<li>研究团队利用去除对象（修复）比添加对象（绘画）更简单的事实来解决问题。</li>
<li>构建了一个自动化的大规模管道来筛选图像及其对应的去对象版本作为数据集。</li>
<li>该数据集包含自然目标图像而非合成图像，确保源-目标一致性。</li>
<li>使用大型视觉语言模型和大型语言模型提供有关移除对象的详细描述并转换为自然语言指令。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.18212">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-feb71df8d75dae87c072ae7f34d428cd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-512de7ea95b15c5219a8b179a51422bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-523779e544c79d00d1b090b64c82f6ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ce78a46abbcfda33a093a80484ec2708.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-00c373105a235fe44c7a219664c68dd6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Label-efficient-multi-organ-segmentation-with-a-diffusion-model"><a href="#Label-efficient-multi-organ-segmentation-with-a-diffusion-model" class="headerlink" title="Label-efficient multi-organ segmentation with a diffusion model"></a>Label-efficient multi-organ segmentation with a diffusion model</h2><p><strong>Authors:Yongzhi Huang, Fengjun Xi, Liyun Tu, Jinxin Zhu, Haseeb Hassan, Liyilei Su, Yun Peng, Jingyu Li, Jun Ma, Bingding Huang</strong></p>
<p>Accurate segmentation of multiple organs in Computed Tomography (CT) images plays a vital role in computer-aided diagnosis systems. While various supervised learning approaches have been proposed recently, these methods heavily depend on a large amount of high-quality labeled data, which are expensive to obtain in practice. To address this challenge, we propose a label-efficient framework using knowledge transfer from a pre-trained diffusion model for CT multi-organ segmentation. Specifically, we first pre-train a denoising diffusion model on 207,029 unlabeled 2D CT slices to capture anatomical patterns. Then, the model backbone is transferred to the downstream multi-organ segmentation task, followed by fine-tuning with few labeled data. In fine-tuning, two fine-tuning strategies, linear classification and fine-tuning decoder, are employed to enhance segmentation performance while preserving learned representations. Quantitative results show that the pre-trained diffusion model is capable of generating diverse and realistic 256x256 CT images (Fr&#39;echet inception distance (FID): 11.32, spatial Fr&#39;echet inception distance (sFID): 46.93, F1-score: 73.1%). Compared to state-of-the-art methods for multi-organ segmentation, our method achieves competitive performance on the FLARE 2022 dataset, particularly in limited labeled data scenarios. After fine-tuning with 1% and 10% labeled data, our method achieves dice similarity coefficients (DSCs) of 71.56% and 78.51%, respectively. Remarkably, the method achieves a DSC score of 51.81% using only four labeled CT slices. These results demonstrate the efficacy of our approach in overcoming the limitations of supervised learning approaches that is highly dependent on large-scale labeled data. </p>
<blockquote>
<p>在计算机断层扫描（CT）图像中，多器官精准分割在计算机辅助诊断系统中起着至关重要的作用。尽管最近已经提出了各种监督学习方法，但这些方法严重依赖于大量高质量标记数据，而在实践中这些数据获取成本高昂。为了应对这一挑战，我们提出了一种使用预训练扩散模型进行CT多器官分割的标签有效框架。具体来说，我们首先在207,029张无标签的二维CT切片上预训练去噪扩散模型，以捕捉解剖模式。然后，将模型主干转移到下游多器官分割任务中，并使用少量标记数据进行微调。在微调过程中，我们采用了两种微调策略，即线性分类和微调解码器，以提高分割性能的同时保留学习到的表示。定量结果表明，预训练的扩散模型能够生成多样且逼真的256x256 CT图像（Fréchet inception distance (FID)：11.32，spatial Fréchet inception distance (sFID)：46.93，F1分数：73.1%）。与多器官分割的最先进方法相比，我们的方法在FLARE 2022数据集上实现了具有竞争力的性能，特别是在有限标记数据的情况下。使用1%和10%的标记数据进行微调后，我们的方法实现了迪克森相似系数（DSC）分别为71.56%和78.51%。值得注意的是，该方法仅使用四张标记的CT切片就达到了51.81%的DSC得分。这些结果证明了我们的方法在克服高度依赖于大规模标记数据的监督学习方法的局限性方面的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.15216v2">PDF</a> </p>
<p><strong>Summary</strong><br>     本文提出一种利用预训练的扩散模型进行计算机断层扫描（CT）多器官分割的标签有效框架。通过预训练捕捉解剖模式，再进行下游多器官分割任务，并少量标签数据进行微调。定量结果显示，预训练扩散模型能生成多样且真实的CT图像，且在有限标签数据场景下与最新多器官分割方法相比具有竞争力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出一种基于预训练的扩散模型的标签有效框架用于CT多器官分割。</li>
<li>通过在大量无标签的CT切片上预训练捕获解剖模式，然后将模型迁移到下游任务。</li>
<li>仅使用少量标签数据进行微调，采用两种策略提升分割性能并保持学到的表示。</li>
<li>预训练扩散模型能生成多样且真实的CT图像，定量评估结果良好。</li>
<li>与最新多器官分割方法相比，在有限标签数据场景下具有竞争力。</li>
<li>使用仅4个标签CT切片进行微调时，仍能获得较高的DSC分数。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.15216">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2d2cd6024660c3b22c96a5dcd28a10f8.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Image-is-All-You-Need-to-Empower-Large-scale-Diffusion-Models-for-In-Domain-Generation"><a href="#Image-is-All-You-Need-to-Empower-Large-scale-Diffusion-Models-for-In-Domain-Generation" class="headerlink" title="Image is All You Need to Empower Large-scale Diffusion Models for   In-Domain Generation"></a>Image is All You Need to Empower Large-scale Diffusion Models for   In-Domain Generation</h2><p><strong>Authors:Pu Cao, Feng Zhou, Lu Yang, Tianrui Huang, Qing Song</strong></p>
<p>In-domain generation aims to perform a variety of tasks within a specific domain, such as unconditional generation, text-to-image, image editing, 3D generation, and more. Early research typically required training specialized generators for each unique task and domain, often relying on fully-labeled data. Motivated by the powerful generative capabilities and broad applications of diffusion models, we are driven to explore leveraging label-free data to empower these models for in-domain generation. Fine-tuning a pre-trained generative model on domain data is an intuitive but challenging way and often requires complex manual hyper-parameter adjustments since the limited diversity of the training data can easily disrupt the model’s original generative capabilities. To address this challenge, we propose a guidance-decoupled prior preservation mechanism to achieve high generative quality and controllability by image-only data, inspired by preserving the pre-trained model from a denoising guidance perspective. We decouple domain-related guidance from the conditional guidance used in classifier-free guidance mechanisms to preserve open-world control guidance and unconditional guidance from the pre-trained model. We further propose an efficient domain knowledge learning technique to train an additional text-free UNet copy to predict domain guidance. Besides, we theoretically illustrate a multi-guidance in-domain generation pipeline for a variety of generative tasks, leveraging multiple guidances from distinct diffusion models and conditions. Extensive experiments demonstrate the superiority of our method in domain-specific synthesis and its compatibility with various diffusion-based control methods and applications. </p>
<blockquote>
<p>领域内的生成旨在在特定领域内执行各种任务，如无条件生成、文本到图像、图像编辑、3D生成等。早期的研究通常需要针对每个独特任务和领域训练专门的生成器，通常依赖于完全标记的数据。受扩散模型强大生成能力和广泛应用的影响，我们致力于探索利用无标签数据来支持这些模型进行域内生成。对域数据进行预训练生成模型的微调是一种直观但具有挑战性的方法，并且由于训练数据的有限多样性，常常需要复杂的手动超参数调整，这可能会破坏模型的原始生成能力。为了解决这一挑战，我们提出了一种指导解耦先验保留机制，通过仅图像数据实现高生成质量和可控性，其灵感来源于从去噪指导的角度保留预训练模型。我们将与领域相关的指导与分类器自由指导机制中使用的条件指导解耦，以保留开放世界控制指导和无条件指导来自预训练模型。我们进一步提出了一种有效的领域知识学习技术，训练一个额外的无文本UNet副本以预测领域指导。此外，我们从理论上说明了针对多种生成任务的域内生成管道，利用来自不同扩散模型和条件的多个指导。大量实验证明了我们方法在特定域合成的优越性，以及与各种基于扩散的控制方法和应用兼容性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.08195v2">PDF</a> Accepted to CVPR2025. Code is available at   <a target="_blank" rel="noopener" href="https://github.com/PRIV-Creation/In-domain-Generation-Diffusion">https://github.com/PRIV-Creation/In-domain-Generation-Diffusion</a></p>
<p><strong>摘要</strong></p>
<p>本研究探讨了基于扩散模型（Diffusion Models）的域内生成任务，包括无条件生成、文本转图像、图像编辑等。早期研究通常需要为每个特定任务和域训练专门的生成器，并依赖于完全标记的数据。本研究利用扩散模型的强大生成能力和广泛应用，探索利用无标签数据为这些模型赋能。针对预训练生成模型在域数据上的微调挑战，提出了一种基于图像数据的指导解耦先验保持机制，以实现高质量生成和控制，并从去噪指导角度保留预训练模型。通过从分类器自由指导机制中解耦出与域相关的指导，以保留开放世界控制指导和无条件指导。进一步提出了一种有效的领域知识学习技术，训练一个额外的无文本UNet副本以预测域指导。此外，从理论上阐述了一种用于多种生成任务的多指导域内生成管道，利用来自不同扩散模型和条件的多重指导。大量实验证明，该方法在特定领域的合成中具有优势，且与各种扩散控制方法和应用兼容。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>研究基于扩散模型的域内生成任务，涵盖多种应用如无条件生成、文本转图像等。</li>
<li>提出利用无标签数据赋能模型的方法。</li>
<li>针对预训练生成模型在特定域数据上的微调挑战，提出了一种新的指导解耦先验保持机制。</li>
<li>该机制从分类器自由指导中解耦域相关指导，保留开放世界控制和无条件指导的能力。</li>
<li>提出一种有效的领域知识学习技术，通过训练额外的无文本UNet副本预测域指导。</li>
<li>实现了一种多指导域内生成管道，融合了不同扩散模型和条件的指导。</li>
<li>实验表明，该方法在特定领域的合成任务上表现优越，具有良好的兼容性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.08195">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b7d82f119727414a3a0547890f255dd8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ee084d05bba6f827b5f8031e77b3430.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6fad8a76b3396c678e2e36750a13ad3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d2c4409b1a6207be785f58e906149097.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-be419b2b8b9507596bde8a24e21b8129.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-23/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-23/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-24/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f8b5ba8281591458d5956e0ce43c3bee.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning 方向最新论文已更新，请持续关注 Update in 2025-03-24  ReLearn Unlearning via Learning for Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-23/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-95b2c5cae75f3c8c7bee2c937d247270.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-03-23  Dita Scaling Diffusion Transformer for Generalist   Vision-Language-Action Policy
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27544.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
