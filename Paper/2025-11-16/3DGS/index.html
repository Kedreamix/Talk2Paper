<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-16  Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-096a025266934d1ffe54f10e907580e5')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    76 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-16-æ›´æ–°"><a href="#2025-11-16-æ›´æ–°" class="headerlink" title="2025-11-16 æ›´æ–°"></a>2025-11-16 æ›´æ–°</h1><h2 id="Depth-Consistent-3D-Gaussian-Splatting-via-Physical-Defocus-Modeling-and-Multi-View-Geometric-Supervision"><a href="#Depth-Consistent-3D-Gaussian-Splatting-via-Physical-Defocus-Modeling-and-Multi-View-Geometric-Supervision" class="headerlink" title="Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision"></a>Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision</h2><p><strong>Authors:Yu Deng, Baozhu Zhao, Junyan Su, Xiaohan Zhang, Qi Liu</strong></p>
<p>Three-dimensional reconstruction in scenes with extreme depth variations remains challenging due to inconsistent supervisory signals between near-field and far-field regions. Existing methods fail to simultaneously address inaccurate depth estimation in distant areas and structural degradation in close-range regions. This paper proposes a novel computational framework that integrates depth-of-field supervision and multi-view consistency supervision to advance 3D Gaussian Splatting. Our approach comprises two core components: (1) Depth-of-field Supervision employs a scale-recovered monocular depth estimator (e.g., Metric3D) to generate depth priors, leverages defocus convolution to synthesize physically accurate defocused images, and enforces geometric consistency through a novel depth-of-field loss, thereby enhancing depth fidelity in both far-field and near-field regions; (2) Multi-View Consistency Supervision employing LoFTR-based semi-dense feature matching to minimize cross-view geometric errors and enforce depth consistency via least squares optimization of reliable matched points. By unifying defocus physics with multi-view geometric constraints, our method achieves superior depth fidelity, demonstrating a 0.8 dB PSNR improvement over the state-of-the-art method on the Waymo Open Dataset. This framework bridges physical imaging principles and learning-based depth regularization, offering a scalable solution for complex depth stratification in urban environments.</p>
<blockquote>
<p>åœ¨æ·±åº¦å˜åŒ–æç«¯çš„åœºæ™¯ä¸­ï¼Œä¸‰ç»´é‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºè¿‘åœºå’Œè¿œåœºåŒºåŸŸä¹‹é—´çš„ç›‘ç£ä¿¡å·ä¸ä¸€è‡´ã€‚ç°æœ‰æ–¹æ³•æ— æ³•åŒæ—¶è§£å†³è¿œè·ç¦»æ·±åº¦ä¼°è®¡ä¸å‡†ç¡®å’Œè¿‘è·ç¦»åŒºåŸŸç»“æ„é€€åŒ–çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®¡ç®—æ¡†æ¶ï¼Œå°†è§†åœºæ·±åº¦ç›‘ç£å’Œå¤šè§†è§’ä¸€è‡´æ€§ç›‘ç£ç›¸ç»“åˆï¼Œä»¥ä¿ƒè¿›3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šï¼ˆ1ï¼‰è§†åœºæ·±åº¦ç›‘ç£é‡‡ç”¨å°ºåº¦æ¢å¤çš„å•ç›®æ·±åº¦ä¼°è®¡å™¨ï¼ˆä¾‹å¦‚Metric3Dï¼‰æ¥ç”Ÿæˆæ·±åº¦å…ˆéªŒï¼Œåˆ©ç”¨æ•£ç„¦å·ç§¯åˆæˆç‰©ç†å‡†ç¡®çš„æ•£ç„¦å›¾åƒï¼Œå¹¶é€šè¿‡æ–°å‹çš„è§†åœºæ·±åº¦æŸå¤±æ¥å¼ºåˆ¶æ‰§è¡Œå‡ ä½•ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜è¿œåœºå’Œè¿‘åœºåŒºåŸŸçš„æ·±åº¦ä¿çœŸåº¦ï¼›ï¼ˆ2ï¼‰å¤šè§†è§’ä¸€è‡´æ€§ç›‘ç£é‡‡ç”¨åŸºäºLoFTRçš„åŠå¯†é›†ç‰¹å¾åŒ¹é…æ¥æœ€å°åŒ–è·¨è§†è§’çš„å‡ ä½•è¯¯å·®ï¼Œå¹¶é€šè¿‡å¯é çš„åŒ¹é…ç‚¹çš„æœ€å°äºŒä¹˜ä¼˜åŒ–æ¥å¼ºåˆ¶æ‰§è¡Œæ·±åº¦ä¸€è‡´æ€§ã€‚é€šè¿‡å°†æ•£ç„¦ç‰©ç†ä¸å¤šè§†è§’å‡ ä½•çº¦æŸç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†å“è¶Šçš„æ·±åº¦ä¿çœŸåº¦ï¼Œåœ¨Waymo Openæ•°æ®é›†ä¸Šè¾ƒç°æœ‰æŠ€æœ¯æé«˜äº†0.8 dBçš„PSNRã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç‰©ç†æˆåƒåŸç†å’ŒåŸºäºå­¦ä¹ çš„æ·±åº¦æ­£åˆ™åŒ–ï¼Œä¸ºåŸå¸‚ç¯å¢ƒä¸­å¤æ‚çš„æ·±åº¦åˆ†å±‚æä¾›äº†å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10316v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ™¯æ·±ç›‘ç£å’Œå¤šè§†è§’ä¸€è‡´æ€§ç›‘ç£çš„æ–°å‹è®¡ç®—æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šæ™¯æ·±ç›‘ç£é€šè¿‡å°ºåº¦æ¢å¤çš„å•ç›®æ·±åº¦ä¼°è®¡å™¨ç”Ÿæˆæ·±åº¦å…ˆéªŒï¼Œåˆ©ç”¨æ•£ç„¦å·ç§¯åˆæˆç‰©ç†å‡†ç¡®çš„æ•£ç„¦å›¾åƒï¼Œå¹¶é€šè¿‡æ–°çš„æ™¯æ·±æŸå¤±å¢å¼ºè¿œè¿‘åœºæ™¯çš„æ·±åº¦ä¿çœŸåº¦ï¼›å¤šè§†è§’ä¸€è‡´æ€§ç›‘ç£åˆ™é‡‡ç”¨åŸºäºLoFTRçš„åŠå¯†é›†ç‰¹å¾åŒ¹é…ï¼Œå‡å°‘è·¨è§†è§’çš„å‡ ä½•è¯¯å·®ï¼Œå¹¶é€šè¿‡å¯é çš„åŒ¹é…ç‚¹è¿›è¡Œæœ€å°äºŒä¹˜ä¼˜åŒ–ï¼Œä»¥åŠ å¼ºæ·±åº¦ä¸€è‡´æ€§ã€‚æ­¤æ–¹æ³•èåˆäº†æ•£ç„¦ç‰©ç†å’Œå¤šè§†è§’å‡ ä½•çº¦æŸï¼Œå®ç°äº†æ›´é«˜çš„æ·±åº¦ä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡é’ˆå¯¹åœºæ™¯æ·±åº¦å˜åŒ–æå¤§çš„æƒ…å†µæå‡ºäº†ä¸€ä¸ªæ–°å‹è®¡ç®—æ¡†æ¶ï¼Œè§£å†³äº†è¿‘åœºå’Œè¿œåœºåŒºåŸŸä¹‹é—´ç›‘ç£ä¿¡å·ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>æ¡†æ¶åŒ…å«æ™¯æ·±ç›‘ç£å’Œå¤šè§†è§’ä¸€è‡´æ€§ç›‘ç£ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œæ—¨åœ¨è§£å†³è¿œè·ç¦»åŒºåŸŸçš„æ·±åº¦ä¼°è®¡ä¸å‡†ç¡®å’Œè¿‘è·ç¦»åŒºåŸŸçš„ç»“æ„é€€åŒ–é—®é¢˜ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨å°ºåº¦æ¢å¤çš„å•ç›®æ·±åº¦ä¼°è®¡å™¨ç”Ÿæˆæ·±åº¦å…ˆéªŒï¼Œå¹¶ç»“åˆæ•£ç„¦å·ç§¯æŠ€æœ¯æé«˜æ·±åº¦ä¿çœŸåº¦ã€‚</li>
<li>é€šè¿‡æ™¯æ·±æŸå¤±ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¢å¼ºåœ¨è¿œè¿‘åœºæ™¯ä¸­çš„æ·±åº¦è¡¨ç°ã€‚</li>
<li>å¤šè§†è§’ä¸€è‡´æ€§ç›‘ç£é‡‡ç”¨åŸºäºLoFTRçš„åŠå¯†é›†ç‰¹å¾åŒ¹é…æŠ€æœ¯ï¼Œå‡å°‘äº†è·¨è§†è§’çš„å‡ ä½•è¯¯å·®ï¼Œå¢å¼ºäº†æ·±åº¦ä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆäº†æ•£ç„¦ç‰©ç†å’Œå¤šè§†è§’å‡ ä½•çº¦æŸï¼Œå®ç°äº†æ›´ç²¾ç¡®çš„æ·±åº¦ä¼°è®¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10316">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c4131229af3e8fd91c594da2779f1fb7" align="middle">
<img src="https://picx.zhimg.com/v2-a51511c94b54cfce3bd2aea83074dd0a" align="middle">
<img src="https://picx.zhimg.com/v2-926ef861d98cfcd1048d49a85f4c703d" align="middle">
<img src="https://picx.zhimg.com/v2-26addc5abba58c0dba6a70653e120f8e" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Multivariate-Gaussian-Representation-Learning-for-Medical-Action-Evaluation"><a href="#Multivariate-Gaussian-Representation-Learning-for-Medical-Action-Evaluation" class="headerlink" title="Multivariate Gaussian Representation Learning for Medical Action Evaluation"></a>Multivariate Gaussian Representation Learning for Medical Action Evaluation</h2><p><strong>Authors:Luming Yang, Haoxian Liu, Siqing Li, Alper Yilmaz</strong></p>
<p>Fine-grained action evaluation in medical vision faces unique challenges due to the unavailability of comprehensive datasets, stringent precision requirements, and insufficient spatiotemporal dynamic modeling of very rapid actions. To support development and evaluation, we introduce CPREval-6k, a multi-view, multi-label medical action benchmark containing 6,372 expert-annotated videos with 22 clinical labels. Using this dataset, we present GaussMedAct, a multivariate Gaussian encoding framework, to advance medical motion analysis through adaptive spatiotemporal representation learning. Multivariate Gaussian Representation projects the joint motions to a temporally scaled multi-dimensional space, and decomposes actions into adaptive 3D Gaussians that serve as tokens. These tokens preserve motion semantics through anisotropic covariance modeling while maintaining robustness to spatiotemporal noise. Hybrid Spatial Encoding, employing a Cartesian and Vector dual-stream strategy, effectively utilizes skeletal information in the form of joint and bone features. The proposed method achieves 92.1% Top-1 accuracy with real-time inference on the benchmark, outperforming the ST-GCN baseline by +5.9% accuracy with only 10% FLOPs. Cross-dataset experiments confirm the superiority of our method in robustness.</p>
<blockquote>
<p>åŒ»ç–—è§†è§‰ä¸­çš„ç²¾ç»†åŠ¨ä½œè¯„ä¼°é¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œè¿™æ˜¯ç”±äºç¼ºä¹ç»¼åˆæ•°æ®é›†ã€ä¸¥æ ¼çš„ç²¾åº¦è¦æ±‚ä»¥åŠå¯¹éå¸¸å¿«é€ŸåŠ¨ä½œçš„æ—¶ç©ºåŠ¨æ€å»ºæ¨¡ä¸è¶³æ‰€å¯¼è‡´çš„ã€‚ä¸ºäº†æ”¯æŒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†CPREval-6kï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šè§†è§’ã€å¤šæ ‡ç­¾çš„åŒ»ç–—åŠ¨ä½œåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«6372ä¸ªä¸“å®¶æ ‡æ³¨çš„è§†é¢‘ï¼Œå¸¦æœ‰22ä¸ªä¸´åºŠæ ‡ç­¾ã€‚ä½¿ç”¨è¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†GaussMedActï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šå…ƒé«˜æ–¯ç¼–ç æ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”æ—¶ç©ºè¡¨å¾å­¦ä¹ ï¼Œæ¨åŠ¨åŒ»ç–—è¿åŠ¨åˆ†æçš„å‘å±•ã€‚å¤šå…ƒé«˜æ–¯è¡¨ç¤ºæ³•å°†è”åˆè¿åŠ¨æŠ•å°„åˆ°æ—¶é—´å°ºåº¦åŒ–çš„å¤šç»´ç©ºé—´ä¸­ï¼Œå¹¶å°†åŠ¨ä½œåˆ†è§£ä¸ºè‡ªé€‚åº”çš„3Dé«˜æ–¯å‡½æ•°ï¼Œä½œä¸ºä»¤ç‰Œã€‚è¿™äº›ä»¤ç‰Œé€šè¿‡å„å‘å¼‚æ€§åæ–¹å·®å»ºæ¨¡ä¿ç•™è¿åŠ¨è¯­ä¹‰ï¼ŒåŒæ—¶ä¿æŒå¯¹æ—¶ç©ºå™ªå£°çš„é²æ£’æ€§ã€‚æ··åˆç©ºé—´ç¼–ç é‡‡ç”¨ç¬›å¡å°”å’ŒçŸ¢é‡åŒæµç­–ç•¥ï¼Œæœ‰æ•ˆåˆ©ç”¨å…³èŠ‚å’Œéª¨éª¼ç‰¹å¾å½¢å¼çš„éª¨éª¼ä¿¡æ¯ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†å®æ—¶æ¨ç†çš„92.1% Top-1å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºST-GCNåŸºçº¿æ–¹æ³•ï¼Œä»…ä½¿ç”¨10%çš„FLOPså°±æé«˜äº†5.9%çš„å‡†ç¡®ç‡ã€‚è·¨æ•°æ®é›†å®éªŒè¯å®äº†æˆ‘ä»¬æ–¹æ³•åœ¨é²æ£’æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10060v1">PDF</a> Accepted to AAAI 2026</p>
<p><strong>Summary</strong><br>     å¼•å…¥CPREval-6kåŒ»ç–—åŠ¨ä½œåŸºå‡†æµ‹è¯•é›†ï¼ŒåŒ…å«6372ä¸ªä¸“å®¶æ ‡æ³¨çš„è§†é¢‘ï¼Œç”¨äºåŒ»ç–—åŠ¨ä½œåˆ†æã€‚æå‡ºGaussMedActæ¡†æ¶ï¼Œåˆ©ç”¨å¤šå…ƒé«˜æ–¯ç¼–ç è¿›è¡Œè‡ªé€‚åº”æ—¶ç©ºè¡¨å¾å­¦ä¹ ï¼Œå®ç°åŒ»ç–—åŠ¨ä½œåˆ†ææ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥CPREval-6kæ•°æ®é›†ï¼ŒåŒ…å«é«˜è´¨é‡åŒ»ç–—åŠ¨ä½œè§†é¢‘ï¼Œç”¨äºåŠ¨ä½œè¯„ä¼°ç ”ç©¶ã€‚</li>
<li>GaussMedActæ¡†æ¶è¢«æå‡ºï¼Œé‡‡ç”¨å¤šå…ƒé«˜æ–¯ç¼–ç è¿›è¡ŒåŒ»ç–—åŠ¨ä½œåˆ†æã€‚</li>
<li>å¤šå…ƒé«˜æ–¯è¡¨ç¤ºå°†è”åˆè¿åŠ¨æŠ•å½±åˆ°æ—¶é—´å°ºåº¦å¤šç»´ç©ºé—´ï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”3Dé«˜æ–¯åˆ†è§£åŠ¨ä½œã€‚</li>
<li>é«˜æ–¯ä»¤ç‰Œèƒ½ä¿ç•™è¿åŠ¨è¯­ä¹‰ï¼Œé€šè¿‡å„å‘å¼‚æ€§åæ–¹å·®å»ºæ¨¡ç»´æŒå¯¹æ—¶ç©ºå™ªå£°çš„ç¨³å¥æ€§ã€‚</li>
<li>æ··åˆç©ºé—´ç¼–ç ç­–ç•¥æœ‰æ•ˆè¿ç”¨éª¨æ¶ä¿¡æ¯ï¼Œé‡‡ç”¨ç¬›å¡å°”å’Œå‘é‡åŒæµç­–ç•¥ã€‚</li>
<li>åœ¨åŸºå‡†æµ‹è¯•é›†ä¸Šå®ç°92.1%çš„top-1å‡†ç¡®ç‡ï¼Œå®æ—¶æ¨ç†ï¼Œè¾ƒST-GCNåŸºçº¿æœ‰5.9%çš„å‡†ç¡®ç‡æå‡ï¼Œä¸”è®¡ç®—é‡ä»…å¢åŠ 10%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10060">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-64bae8730a7c5f82b5f33f8362f09c9d" align="middle">
<img src="https://picx.zhimg.com/v2-34b27eeae9ad2fc74638a61c6cc415a2" align="middle">
<img src="https://picx.zhimg.com/v2-f5c473f6e325982b30be6e32083c25df" align="middle">
<img src="https://picx.zhimg.com/v2-efadfdc32ac8a6b6381779fa2ac9212f" align="middle">
<img src="https://picx.zhimg.com/v2-7e5e8f7c77897078c2fa61400a1bbbbf" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="TSPE-GS-Probabilistic-Depth-Extraction-for-Semi-Transparent-Surface-Reconstruction-via-3D-Gaussian-Splatting"><a href="#TSPE-GS-Probabilistic-Depth-Extraction-for-Semi-Transparent-Surface-Reconstruction-via-3D-Gaussian-Splatting" class="headerlink" title="TSPE-GS: Probabilistic Depth Extraction for Semi-Transparent Surface Reconstruction via 3D Gaussian Splatting"></a>TSPE-GS: Probabilistic Depth Extraction for Semi-Transparent Surface Reconstruction via 3D Gaussian Splatting</h2><p><strong>Authors:Zhiyuan Xu, Nan Min, Yuhang Guo, Tong Wei</strong></p>
<p>3D Gaussian Splatting offers a strong speed-quality trade-off but struggles to reconstruct semi-transparent surfaces because most methods assume a single depth per pixel, which fails when multiple surfaces are visible. We propose TSPE-GS (Transparent Surface Probabilistic Extraction for Gaussian Splatting), which uniformly samples transmittance to model a pixel-wise multi-modal distribution of opacity and depth, replacing the prior single-peak assumption and resolving cross-surface depth ambiguity. By progressively fusing truncated signed distance functions, TSPE-GS reconstructs external and internal surfaces separately within a unified framework. The method generalizes to other Gaussian-based reconstruction pipelines without extra training overhead. Extensive experiments on public and self-collected semi-transparent and opaque datasets show TSPE-GS significantly improves semi-transparent geometry reconstruction while maintaining performance on opaque scenes.</p>
<blockquote>
<p>3Dé«˜æ–¯æ‘Šé“ºæŠ€æœ¯æä¾›äº†å¼ºå¤§çš„é€Ÿåº¦ä¸è´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œä½†åœ¨é‡å»ºåŠé€æ˜è¡¨é¢æ–¹é¢é‡åˆ°äº†å›°éš¾ï¼Œå› ä¸ºå¤§å¤šæ•°æ–¹æ³•å‡è®¾æ¯ä¸ªåƒç´ åªæœ‰ä¸€ä¸ªæ·±åº¦ï¼Œè¿™åœ¨å¯è§å¤šä¸ªè¡¨é¢æ—¶ä¼šå¤±æ•ˆã€‚æˆ‘ä»¬æå‡ºäº†TSPE-GSï¼ˆé«˜æ–¯æ‘Šé“ºçš„é€æ˜è¡¨é¢æ¦‚ç‡æå–ï¼‰ï¼Œå®ƒé€šè¿‡å‡åŒ€é‡‡æ ·é€å°„ç‡æ¥å»ºæ¨¡åƒç´ çº§çš„é€æ˜åº¦å’Œå¤šæ¨¡æ€æ·±åº¦åˆ†å¸ƒï¼Œå–ä»£äº†å…ˆå‰çš„å•å³°å‡è®¾å¹¶è§£å†³è·¨è¡¨é¢æ·±åº¦æ­§ä¹‰é—®é¢˜ã€‚é€šè¿‡æ¸è¿›èåˆæˆªæ–­çš„æœ‰ç¬¦å·è·ç¦»å‡½æ•°ï¼ŒTSPE-GSåœ¨ç»Ÿä¸€æ¡†æ¶å†…åˆ†åˆ«é‡å»ºå¤–éƒ¨å’Œå†…éƒ¨è¡¨é¢ã€‚è¯¥æ–¹æ³•å¯æ¨å¹¿åˆ°å…¶ä»–åŸºäºé«˜æ–¯çš„é‡æ„æµç¨‹ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒå¼€é”€ã€‚åœ¨å…¬å…±å’Œè‡ªæˆ‘æ”¶é›†çš„é€æ˜å’Œä¸é€æ˜æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTSPE-GSåœ¨æ”¹å–„åŠé€æ˜å‡ ä½•é‡æ„çš„åŒæ—¶ï¼Œåœ¨ä¸é€æ˜åœºæ™¯ä¸­çš„æ€§èƒ½ä¹Ÿå¾—åˆ°äº†ä¿æŒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09944v1">PDF</a> AAAI26 Poster</p>
<p><strong>Summary</strong></p>
<p>3Dé«˜æ–¯æ’å€¼æŠ€æœ¯åœ¨é€Ÿåº¦ä¸è´¨é‡ä¹‹é—´æä¾›äº†è‰¯å¥½çš„æƒè¡¡ï¼Œä½†åœ¨é‡å»ºåŠé€æ˜è¡¨é¢æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚å¤§å¤šæ•°æ–¹æ³•å‡è®¾æ¯ä¸ªåƒç´ åªæœ‰ä¸€ä¸ªæ·±åº¦ï¼Œè¿™åœ¨å¤šä¸ªè¡¨é¢å¯è§æ—¶ä¼šå‡ºç°é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†TSPE-GSï¼ˆé«˜æ–¯æ’å€¼çš„é€æ˜è¡¨é¢æ¦‚ç‡æå–ï¼‰ï¼Œå®ƒé€šè¿‡å‡åŒ€é‡‡æ ·é€å°„ç‡æ¥æ¨¡æ‹Ÿåƒç´ çº§çš„å¤šå…ƒåˆ†å¸ƒçš„ä¸é€æ˜åº¦å’Œæ·±åº¦ï¼Œå–ä»£äº†å…ˆå‰çš„å•å³°å‡è®¾ï¼Œè§£å†³äº†è·¨è¡¨é¢æ·±åº¦æ¨¡ç³Šçš„é—®é¢˜ã€‚é€šè¿‡æ¸è¿›èåˆæˆªæ–­çš„æœ‰ç¬¦å·è·ç¦»å‡½æ•°ï¼ŒTSPE-GSåœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…åˆ†åˆ«é‡å»ºå¤–éƒ¨å’Œå†…éƒ¨è¡¨é¢ã€‚è¯¥æ–¹æ³•å¯æ¨å¹¿åˆ°å…¶ä»–åŸºäºé«˜æ–¯çš„é‡æ„ç®¡é“ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒå¼€é”€ã€‚åœ¨å…¬å…±å’Œè‡ªæˆ‘æ”¶é›†çš„åŠé€æ˜å’Œä¸é€æ˜æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTSPE-GSåœ¨æ”¹å–„åŠé€æ˜å‡ ä½•é‡æ„çš„åŒæ—¶ï¼Œè¿˜èƒ½ä¿æŒåœ¨ä¸é€æ˜åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dé«˜æ–¯æ’å€¼æŠ€æœ¯å…·æœ‰é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡ï¼Œä½†åœ¨é‡å»ºåŠé€æ˜è¡¨é¢æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>å¤§å¤šæ•°æ–¹æ³•å‡è®¾æ¯ä¸ªåƒç´ åªæœ‰ä¸€ä¸ªæ·±åº¦ï¼Œè¿™åœ¨å¤„ç†å¤šä¸ªå¯è§è¡¨é¢æ—¶ä¼šå¯¼è‡´é—®é¢˜ã€‚</li>
<li>TSPE-GSé€šè¿‡æ¨¡æ‹Ÿåƒç´ çº§çš„å¤šå…ƒåˆ†å¸ƒçš„ä¸é€æ˜åº¦å’Œæ·±åº¦æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>TSPE-GSé‡‡ç”¨å‡åŒ€é‡‡æ ·é€å°„ç‡çš„æ–¹æ³•ï¼Œå–ä»£äº†å…ˆå‰çš„å•å³°å‡è®¾ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæ¸è¿›èåˆæˆªæ–­çš„æœ‰ç¬¦å·è·ç¦»å‡½æ•°ï¼Œä»¥é‡å»ºå¤–éƒ¨å’Œå†…éƒ¨è¡¨é¢ã€‚</li>
<li>TSPE-GSæ–¹æ³•å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯åº”ç”¨äºå…¶ä»–åŸºäºé«˜æ–¯çš„é‡æ„ç®¡é“ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09944">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fd00bc920d4e5b537665e104142de950" align="middle">
<img src="https://picx.zhimg.com/v2-53c3902c4145634c97e4a027e0ca2687" align="middle">
<img src="https://picx.zhimg.com/v2-a7c5af495bb617ea869403af9d5bf1e5" align="middle">
<img src="https://picx.zhimg.com/v2-8d88fbf24c4a605811decf7a73492325" align="middle">
<img src="https://picx.zhimg.com/v2-e173526daec8ab25dfed7e2425de16a8" align="middle">
<img src="https://picx.zhimg.com/v2-3a1b32e5131fbbfec15b5e6973a51739" align="middle">
<img src="https://picx.zhimg.com/v2-bfec21b012444317c867ed71837f4089" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="OUGS-Active-View-Selection-via-Object-aware-Uncertainty-Estimation-in-3DGS"><a href="#OUGS-Active-View-Selection-via-Object-aware-Uncertainty-Estimation-in-3DGS" class="headerlink" title="OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS"></a>OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS</h2><p><strong>Authors:Haiyi Li, Qi Chen, Denis Kalkofen, Hsiang-Ting Chen</strong></p>
<p>Recent advances in 3D Gaussian Splatting (3DGS) have achieved state-of-the-art results for novel view synthesis. However, efficiently capturing high-fidelity reconstructions of specific objects within complex scenes remains a significant challenge. A key limitation of existing active reconstruction methods is their reliance on scene-level uncertainty metrics, which are often biased by irrelevant background clutter and lead to inefficient view selection for object-centric tasks. We present OUGS, a novel framework that addresses this challenge with a more principled, physically-grounded uncertainty formulation for 3DGS. Our core innovation is to derive uncertainty directly from the explicit physical parameters of the 3D Gaussian primitives (e.g., position, scale, rotation). By propagating the covariance of these parameters through the rendering Jacobian, we establish a highly interpretable uncertainty model. This foundation allows us to then seamlessly integrate semantic segmentation masks to produce a targeted, object-aware uncertainty score that effectively disentangles the object from its environment. This allows for a more effective active view selection strategy that prioritizes views critical to improving object fidelity. Experimental evaluations on public datasets demonstrate that our approach significantly improves the efficiency of the 3DGS reconstruction process and achieves higher quality for targeted objects compared to existing state-of-the-art methods, while also serving as a robust uncertainty estimator for the global scene.</p>
<blockquote>
<p>åœ¨ä¸‰ç»´é«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰æ–¹é¢çš„æœ€æ–°è¿›å±•å·²ç»å®ç°äº†ç”¨äºæ–°å‹è§†å›¾åˆæˆçš„æœ€å…ˆè¿›çš„æˆæœã€‚ç„¶è€Œï¼Œåœ¨å¤æ‚çš„åœºæ™¯ä¸­æœ‰æ•ˆåœ°æ•è·ç‰¹å®šå¯¹è±¡çš„é«˜ä¿çœŸé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚ç°æœ‰ä¸»åŠ¨é‡å»ºæ–¹æ³•çš„å…³é”®å±€é™æ€§åœ¨äºå®ƒä»¬ä¾èµ–äºåœºæ™¯çº§åˆ«çš„ä¸ç¡®å®šæ€§åº¦é‡ï¼Œè¿™äº›åº¦é‡é€šå¸¸å—åˆ°æ— å…³èƒŒæ™¯å¹²æ‰°çš„å½±å“ï¼Œå¯¼è‡´å¯¹ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä»»åŠ¡è¿›è¡Œä½æ•ˆçš„è§†å›¾é€‰æ‹©ã€‚æˆ‘ä»¬æå‡ºäº†OUGSï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œé€šè¿‡ä¸º3DGSæä¾›æ›´ä¸¥è°¨ã€åŸºäºç‰©ç†çš„ä¸ç¡®å®šæ€§å…¬å¼æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ä»ä¸‰ç»´é«˜æ–¯åŸºå…ƒçš„æ˜¾å¼ç‰©ç†å‚æ•°ï¼ˆä¾‹å¦‚ä½ç½®ã€å°ºåº¦ã€æ—‹è½¬ï¼‰ç›´æ¥æ¨å¯¼å‡ºä¸ç¡®å®šæ€§ã€‚é€šè¿‡å°†è¿™äº›å‚æ•°çš„åæ–¹å·®ä¼ æ’­é€šè¿‡æ¸²æŸ“é›…å¯æ¯”çŸ©é˜µï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªé«˜åº¦å¯è§£é‡Šçš„ä¸ç¡®å®šæ€§æ¨¡å‹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥æ— ç¼é›†æˆè¯­ä¹‰åˆ†å‰²æ©è†œï¼Œä»¥äº§ç”Ÿæœ‰é’ˆå¯¹æ€§çš„ã€å¯¹è±¡æ„ŸçŸ¥çš„ä¸ç¡®å®šæ€§å¾—åˆ†ï¼Œæœ‰æ•ˆåœ°å°†å¯¹è±¡ä¸å…¶ç¯å¢ƒåˆ†å¼€ã€‚è¿™å…è®¸æ›´æœ‰æ•ˆçš„ä¸»åŠ¨è§†å›¾é€‰æ‹©ç­–ç•¥ï¼Œä¼˜å…ˆè€ƒè™‘å¯¹æé«˜å¯¹è±¡ä¿çœŸåº¦è‡³å…³é‡è¦çš„è§†å›¾ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†3DGSé‡å»ºè¿‡ç¨‹çš„æ•ˆç‡ï¼Œé’ˆå¯¹ç›®æ ‡å¯¹è±¡çš„è´¨é‡ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”æœ‰æ‰€æé«˜ï¼ŒåŒæ—¶è¿˜ä½œä¸ºå…¨å±€åœºæ™¯çš„ç¨³å¥ä¸ç¡®å®šæ€§ä¼°è®¡å™¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09397v1">PDF</a> 11 pages (10 main + 1 appendix), 7 figures, 3 tables. Preprint, under review for Eurographics 2026</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸï¼Œ3Dé«˜æ–¯ç»˜åˆ¶æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„æœ€æ–°è¿›å±•å·²ç»å®ç°äº†åœ¨åˆæˆæ–°è§†è§’æ—¶çš„å“è¶Šè¡¨ç°ã€‚ç„¶è€Œï¼Œå¦‚ä½•åœ¨å¤æ‚çš„åœºæ™¯ä¸­é«˜æ•ˆåœ°é‡å»ºç‰¹å®šå¯¹è±¡ä»æ˜¯é‡è¦æŒ‘æˆ˜ã€‚ç°æœ‰ä¸»åŠ¨é‡å»ºæ–¹æ³•çš„ä¸€ä¸ªå…³é”®å±€é™æ€§åœ¨äºå®ƒä»¬ä¾èµ–äºåœºæ™¯çº§åˆ«çš„ä¸ç¡®å®šæ€§åº¦é‡ï¼Œè¿™é€šå¸¸å—åˆ°æ— å…³èƒŒæ™¯å¹²æ‰°çš„å½±å“ï¼Œå¯¼è‡´å¯¹äºä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä»»åŠ¡çš„è§†è§’é€‰æ‹©æ•ˆç‡ä½ä¸‹ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶OUGSï¼Œé€šè¿‡æ›´ç³»ç»Ÿçš„ç‰©ç†åŸºç¡€ä¸ç¡®å®šæ€§å…¬å¼æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚å…¶æ ¸å¿ƒåˆ›æ–°ä¹‹å¤„åœ¨äºç›´æ¥ä»3Dé«˜æ–¯åŸºå…ƒçš„æ˜¾å¼ç‰©ç†å‚æ•°ï¼ˆå¦‚ä½ç½®ã€å°ºåº¦ã€æ—‹è½¬ï¼‰æ¨å¯¼ä¸ç¡®å®šæ€§ï¼Œå¹¶é€šè¿‡æ¸²æŸ“é›…å¯æ¯”çŸ©é˜µä¼ æ’­åæ–¹å·®ï¼Œå»ºç«‹é«˜åº¦å¯è§£é‡Šçš„ä¸ç¡®å®šæ€§æ¨¡å‹ã€‚ç»“åˆè¯­ä¹‰åˆ†å‰²æ©è†œï¼Œå½¢æˆæœ‰é’ˆå¯¹æ€§çš„å¯¹è±¡æ„ŸçŸ¥ä¸ç¡®å®šæ€§å¾—åˆ†ï¼Œæœ‰æ•ˆåœ°å°†å¯¹è±¡ä¸å…¶ç¯å¢ƒåˆ†ç¦»ã€‚è¿™å¯¼è‡´äº†ä¸€ä¸ªæ›´æœ‰æ•ˆçš„ä¸»åŠ¨è§†è§’é€‰æ‹©ç­–ç•¥ï¼Œä¼˜å…ˆé€‰æ‹©äº†èƒ½æé«˜å¯¹è±¡ä¿çœŸåº¦çš„è§†è§’ã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†3DGSé‡å»ºè¿‡ç¨‹çš„æ•ˆç‡ï¼Œé’ˆå¯¹ç›®æ ‡å¯¹è±¡çš„è´¨é‡é«˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶ä½œä¸ºå…¨å±€åœºæ™¯çš„é²æ£’ä¸ç¡®å®šæ€§ä¼°è®¡å™¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿‘æœŸ3DGSæŠ€æœ¯è™½ç„¶å–å¾—å“è¶Šæˆæœï¼Œä½†æ•æ‰å¤æ‚åœºæ™¯ä¸­ç‰¹å®šå¯¹è±¡çš„é«˜ä¿çœŸé‡å»ºä»æ˜¯æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰ä¸»åŠ¨é‡å»ºæ–¹æ³•ä¾èµ–äºåœºæ™¯çº§åˆ«çš„ä¸ç¡®å®šæ€§åº¦é‡ï¼Œæ˜“å—èƒŒæ™¯å¹²æ‰°å½±å“ã€‚</li>
<li>OUGSæ¡†æ¶é€šè¿‡ç‰©ç†åŸºç¡€çš„ä¸ç¡®å®šæ€§å…¬å¼è§£å†³æ­¤æŒ‘æˆ˜ã€‚</li>
<li>OUGSç›´æ¥ä»3Dé«˜æ–¯åŸºå…ƒçš„ç‰©ç†å‚æ•°æ¨å¯¼ä¸ç¡®å®šæ€§ï¼Œå»ºç«‹é«˜åº¦å¯è§£é‡Šçš„ä¸ç¡®å®šæ€§æ¨¡å‹ã€‚</li>
<li>ç»“åˆè¯­ä¹‰åˆ†å‰²æ©è†œå½¢æˆå¯¹è±¡æ„ŸçŸ¥ä¸ç¡®å®šæ€§å¾—åˆ†ï¼Œæœ‰æ•ˆåˆ†ç¦»å¯¹è±¡ä¸ç¯å¢ƒã€‚</li>
<li>OUGSå¯¼è‡´æ›´æœ‰æ•ˆçš„ä¸»åŠ¨è§†è§’é€‰æ‹©ç­–ç•¥ï¼Œä¼˜å…ˆæé«˜å¯¹è±¡ä¿çœŸåº¦çš„è§†è§’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09397">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8a704828cc1695184c0453cd9fca0202" align="middle">
<img src="https://picx.zhimg.com/v2-8e4fbe892d64b360b3030fb3726f2626" align="middle">
<img src="https://picx.zhimg.com/v2-6e58922bfead77044d11482fbdd1cc06" align="middle">
<img src="https://picx.zhimg.com/v2-0c41862f52326f6e0bf2b053d9bcfa4a" align="middle">
<img src="https://picx.zhimg.com/v2-b41c4a5deef38891182716d08be95a73" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SkelSplat-Robust-Multi-view-3D-Human-Pose-Estimation-with-Differentiable-Gaussian-Rendering"><a href="#SkelSplat-Robust-Multi-view-3D-Human-Pose-Estimation-with-Differentiable-Gaussian-Rendering" class="headerlink" title="SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering"></a>SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering</h2><p><strong>Authors:Laura Bragagnolo, Leonardo Barcellona, Stefano Ghidoni</strong></p>
<p>Accurate 3D human pose estimation is fundamental for applications such as augmented reality and human-robot interaction. State-of-the-art multi-view methods learn to fuse predictions across views by training on large annotated datasets, leading to poor generalization when the test scenario differs. To overcome these limitations, we propose SkelSplat, a novel framework for multi-view 3D human pose estimation based on differentiable Gaussian rendering. Human pose is modeled as a skeleton of 3D Gaussians, one per joint, optimized via differentiable rendering to enable seamless fusion of arbitrary camera views without 3D ground-truth supervision. Since Gaussian Splatting was originally designed for dense scene reconstruction, we propose a novel one-hot encoding scheme that enables independent optimization of human joints. SkelSplat outperforms approaches that do not rely on 3D ground truth in Human3.6M and CMU, while reducing the cross-dataset error up to 47.8% compared to learning-based methods. Experiments on Human3.6M-Occ and Occlusion-Person demonstrate robustness to occlusions, without scenario-specific fine-tuning. Our project page is available here: <a target="_blank" rel="noopener" href="https://skelsplat.github.io/">https://skelsplat.github.io</a>.</p>
<blockquote>
<p>ç²¾ç¡®çš„3Däººä½“å§¿æ€ä¼°è®¡æ˜¯å¢å¼ºç°å®å’Œäººæœºäº¤äº’ç­‰åº”ç”¨çš„åŸºç¡€ã€‚ç›®å‰æœ€å…ˆçš„å¤šè§†è§’æ–¹æ³•é€šè¿‡å­¦ä¹ åœ¨å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†ä¸Šè¿›è¡Œè·¨è§†è§’é¢„æµ‹èåˆï¼Œä½†å½“æµ‹è¯•åœºæ™¯ä¸åŒæ—¶ï¼Œå…¶æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†SkelSplatï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¯å¾®åˆ†é«˜æ–¯æ¸²æŸ“çš„å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡çš„æ–°æ¡†æ¶ã€‚äººä½“å§¿æ€è¢«å»ºæ¨¡ä¸º3Dé«˜æ–¯åˆ†å¸ƒéª¨æ¶ï¼Œæ¯ä¸ªå…³èŠ‚ä¸€ä¸ªï¼Œé€šè¿‡å¯å¾®åˆ†æ¸²æŸ“è¿›è¡Œä¼˜åŒ–ï¼Œä»¥å®ç°ä»»æ„ç›¸æœºè§†è§’æ— ç¼èåˆï¼Œæ— éœ€3DçœŸå®å€¼ç›‘ç£ã€‚ç”±äºé«˜æ–¯æ‹¼è´´æœ€åˆæ˜¯ä¸ºå¯†é›†åœºæ™¯é‡å»ºè€Œè®¾è®¡çš„ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸€çƒ­ç¼–ç æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå®ç°äººç±»å…³èŠ‚çš„ç‹¬ç«‹ä¼˜åŒ–ã€‚SkelSplatåœ¨Human3.6Må’ŒCMUæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºä¸ä¾èµ–3DçœŸå®å€¼çš„æ–¹æ³•ï¼Œä¸åŸºäºå­¦ä¹ çš„æ–¹æ³•ç›¸æ¯”ï¼Œè·¨æ•°æ®é›†è¯¯å·®é™ä½äº†é«˜è¾¾47.8%ã€‚åœ¨Human3.6M-Occå’ŒOcclusion-Personä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå®ƒå¯¹é®æŒ¡å…·æœ‰é²æ£’æ€§ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯åœ¨æ­¤æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://skelsplat.github.io/">https://skelsplat.github.io</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.08294v1">PDF</a> WACV 2026</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šè§†è§’çš„3Däººä½“å§¿æ€ä¼°è®¡æ˜¯å¢å¼ºç°å®å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸçš„é‡è¦åº”ç”¨ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¯¼è‡´æµ‹è¯•åœºæ™¯å·®å¼‚æ—¶æ³›åŒ–æ€§èƒ½ä¸ä½³ã€‚æœ¬æ–‡æå‡ºSkelSplatæ¡†æ¶ï¼Œåˆ©ç”¨å¯å¾®é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼Œå°†äººä½“å§¿æ€å»ºæ¨¡ä¸ºä¸€ç³»åˆ—é’ˆå¯¹æ¯ä¸ªå…³èŠ‚çš„3Dé«˜æ–¯åˆ†å¸ƒã€‚é€šè¿‡å¯å¾®æ¸²æŸ“å®ç°ä¸åŒç›¸æœºè§†è§’æ— ç¼èåˆï¼Œæ— éœ€3DçœŸå®æ ‡ç­¾ç›‘ç£ã€‚æœ¬æ–‡è®¾è®¡äº†ä¸€ç§æ–°å‹one-hotç¼–ç æ–¹æ¡ˆï¼Œå®ç°äººä½“å…³èŠ‚çš„ç‹¬ç«‹ä¼˜åŒ–ã€‚SkelSplatåœ¨ä¸ä¾èµ–3DçœŸå®æ ‡ç­¾çš„æƒ…å†µä¸‹åœ¨Human3.6Må’ŒCMUæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºå­¦ä¹ æ–¹æ³•å‡å°‘äº†è·¨æ•°æ®é›†è¯¯å·®è¾¾47.8%ã€‚åœ¨Human3.6M-Occå’ŒOcclusion-Personä¸Šçš„å®éªŒè¯æ˜äº†å…¶å¯¹é®æŒ¡çš„é²æ£’æ€§ï¼Œæ— éœ€é’ˆå¯¹åœºæ™¯è¿›è¡Œå¾®è°ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SkelSplatæ˜¯ä¸€ä¸ªåŸºäºå¤šè§†è§’çš„3Däººä½“å§¿æ€ä¼°è®¡æ¡†æ¶ï¼Œåˆ©ç”¨å¯å¾®é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ã€‚</li>
<li>å®ƒå°†äººä½“å§¿æ€å»ºæ¨¡ä¸ºé’ˆå¯¹æ¯ä¸ªå…³èŠ‚çš„3Dé«˜æ–¯åˆ†å¸ƒï¼Œå®ç°æ— ç¼èåˆä¸åŒç›¸æœºè§†è§’ã€‚</li>
<li>SkelSplatæ— éœ€3DçœŸå®æ ‡ç­¾ç›‘ç£ï¼Œå…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>æ–°å‹one-hotç¼–ç æ–¹æ¡ˆå®ç°äººä½“å…³èŠ‚çš„ç‹¬ç«‹ä¼˜åŒ–ã€‚</li>
<li>SkelSplatåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯è·¨æ•°æ®é›†è¯¯å·®å‡å°‘è¾¾47.8%ã€‚</li>
<li>SkelSplatå¯¹é®æŒ¡æƒ…å†µå…·æœ‰é²æ£’æ€§ï¼Œæ— éœ€é’ˆå¯¹åœºæ™¯è¿›è¡Œå¾®è°ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.08294">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2b19402c6d490880692cddeda3be67a1" align="middle">
<img src="https://picx.zhimg.com/v2-413ea2d30e924631be780377d24a9899" align="middle">
<img src="https://picx.zhimg.com/v2-33c365ad2c3db372caecc9b984afd026" align="middle">
<img src="https://picx.zhimg.com/v2-1b74a4b743f255671a3dfbcc90466031" align="middle">
<img src="https://picx.zhimg.com/v2-6029959718aec7ab2ca41a93c3cb0396" align="middle">
<img src="https://picx.zhimg.com/v2-d115610f2e04f6c58c31ad2397b8b926" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Perceptual-Quality-Assessment-of-3D-Gaussian-Splatting-A-Subjective-Dataset-and-Prediction-Metric"><a href="#Perceptual-Quality-Assessment-of-3D-Gaussian-Splatting-A-Subjective-Dataset-and-Prediction-Metric" class="headerlink" title="Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric"></a>Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric</h2><p><strong>Authors:Zhaolin Wan, Yining Diao, Jingqi Xu, Hao Wang, Zhiyang Li, Xiaopeng Fan, Wangmeng Zuo, Debin Zhao</strong></p>
<p>With the rapid advancement of 3D visualization, 3D Gaussian Splatting (3DGS) has emerged as a leading technique for real-time, high-fidelity rendering. While prior research has emphasized algorithmic performance and visual fidelity, the perceptual quality of 3DGS-rendered content, especially under varying reconstruction conditions, remains largely underexplored. In practice, factors such as viewpoint sparsity, limited training iterations, point downsampling, noise, and color distortions can significantly degrade visual quality, yet their perceptual impact has not been systematically studied. To bridge this gap, we present 3DGS-QA, the first subjective quality assessment dataset for 3DGS. It comprises 225 degraded reconstructions across 15 object types, enabling a controlled investigation of common distortion factors. Based on this dataset, we introduce a no-reference quality prediction model that directly operates on native 3D Gaussian primitives, without requiring rendered images or ground-truth references. Our model extracts spatial and photometric cues from the Gaussian representation to estimate perceived quality in a structure-aware manner. We further benchmark existing quality assessment methods, spanning both traditional and learning-based approaches. Experimental results show that our method consistently achieves superior performance, highlighting its robustness and effectiveness for 3DGS content evaluation. The dataset and code are made publicly available at <a target="_blank" rel="noopener" href="https://github.com/diaoyn/3DGSQA">https://github.com/diaoyn/3DGSQA</a> to facilitate future research in 3DGS quality assessment.</p>
<blockquote>
<p>éšç€3Då¯è§†åŒ–æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œ3Dé«˜æ–¯èåˆæŠ€æœ¯ï¼ˆ3DGSï¼‰å·²æˆä¸ºå®æ—¶é«˜ä¿çœŸæ¸²æŸ“çš„ä¸»æµæŠ€æœ¯ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶å·²ç»å¼ºè°ƒäº†ç®—æ³•æ€§èƒ½å’Œè§†è§‰ä¿çœŸåº¦ï¼Œä½†ç‰¹åˆ«æ˜¯åœ¨ä¸åŒé‡å»ºæ¡ä»¶ä¸‹ï¼Œå¯¹äº3DGSæ¸²æŸ“å†…å®¹çš„æ„ŸçŸ¥è´¨é‡ä»ç„¶å­˜åœ¨å¤§é‡çš„æ¢ç´¢ç©ºé—´ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè§†ç‚¹ç¨€ç–æ€§ã€è®­ç»ƒè¿­ä»£æ¬¡æ•°æœ‰é™ã€ç‚¹ä¸‹é‡‡æ ·ã€å™ªå£°å’Œé¢œè‰²å¤±çœŸç­‰å› ç´ éƒ½å¯èƒ½ä¸¥é‡å½±å“è§†è§‰è´¨é‡ï¼Œç„¶è€Œè¿™äº›å› ç´ å¯¹æ„ŸçŸ¥çš„å½±å“å°šæœªè¿›è¡Œç³»ç»Ÿæ€§çš„ç ”ç©¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†é¦–ä¸ªé’ˆå¯¹3DGSçš„ä¸»è§‚è´¨é‡è¯„ä¼°æ•°æ®é›†â€”â€”3DGS-QAã€‚è¯¥æ•°æ®é›†åŒ…å«è·¨è¶Šäº†åäº”ç§å¯¹è±¡ç±»å‹çš„å…±225ä¸ªé€€åŒ–é‡å»ºæ ·æœ¬ï¼Œå¯ä»¥è¿›è¡Œå¸¸è§å¤±çœŸå› ç´ çš„å—æ§ç ”ç©¶ã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€ç§æ— éœ€å‚è€ƒçš„è´¨é‡é¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ç›´æ¥å¯¹æœ¬åœ°åŒ–çš„åŸç”Ÿä¸‰ç»´é«˜æ–¯åŸºæœ¬ä½“è¿›è¡Œæ“ä½œï¼Œæ— éœ€æ¸²æŸ“å›¾åƒæˆ–çœŸå®å‚è€ƒå›¾åƒã€‚æˆ‘ä»¬çš„æ¨¡å‹ä»é«˜æ–¯è¡¨ç¤ºä¸­æå–ç©ºé—´å’Œå…‰åº¦çº¿ç´¢ï¼Œä»¥ç»“æ„æ„ŸçŸ¥çš„æ–¹å¼æ¥ä¼°è®¡æ„ŸçŸ¥è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯¹ç°æœ‰çš„è´¨é‡è¯„ä¼°æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿæ–¹æ³•å’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è¯„ä¼°ä¸‰ç»´é«˜æ–¯èåˆå†…å®¹æ–¹é¢çš„ç¨³å¥æ€§å’Œæœ‰æ•ˆæ€§ã€‚ä¸ºäº†æ–¹ä¾¿æœªæ¥å¯¹ä¸‰ç»´é«˜æ–¯èåˆè´¨é‡è¯„ä¼°çš„ç ”ç©¶ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å‘å¸ƒåœ¨ <a target="_blank" rel="noopener" href="https://github.com/diaoyn/3DGSQA">https://github.com/diaoyn/3DGSQA</a> ä¸Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.08032v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>éšç€3Då¯è§†åŒ–æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰å·²æˆä¸ºå®æ—¶é«˜ä¿çœŸæ¸²æŸ“çš„ä¸€ç§é¢†å…ˆæŠ€æœ¯ã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶å·²ç»å¼ºè°ƒäº†ç®—æ³•æ€§èƒ½å’Œè§†è§‰ä¿çœŸåº¦çš„é‡è¦æ€§ï¼Œä½†3DGSæ¸²æŸ“å†…å®¹åœ¨æ„ŸçŸ¥è´¨é‡æ–¹é¢ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸åŒé‡å»ºæ¡ä»¶ä¸‹çš„æ„ŸçŸ¥è´¨é‡ï¼Œä»ç„¶ç ”ç©¶ä¸è¶³ã€‚å®è·µä¸­ï¼Œè§†ç‚¹ç¨€ç–ã€è®­ç»ƒè¿­ä»£æ¬¡æ•°æœ‰é™ã€ç‚¹é™é‡‡æ ·ã€å™ªå£°å’Œé¢œè‰²å¤±çœŸç­‰å› ç´ å¯èƒ½ä¼šæ˜¾è‘—é™ä½è§†è§‰è´¨é‡ï¼Œç„¶è€Œå®ƒä»¬çš„æ„ŸçŸ¥å½±å“å°šæœªè¿›è¡Œç³»ç»Ÿç ”ç©¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†3DGS-QAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹3DGSçš„ä¸»è§‚è´¨é‡è¯„ä¼°æ•°æ®é›†ã€‚å®ƒåŒ…å«äº†15ç§å¯¹è±¡ç±»å‹çš„225ä¸ªé€€åŒ–é‡å»ºï¼Œèƒ½å¤Ÿæ§åˆ¶å¸¸è§çš„å¤±çœŸå› ç´ è¿›è¡Œç ”ç©¶ã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ— å‚è€ƒè´¨é‡é¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ç›´æ¥åœ¨æœ¬åœ°3Dé«˜æ–¯åŸå§‹æ•°æ®ä¸Šè¿è¡Œï¼Œæ— éœ€æ¸²æŸ“å›¾åƒæˆ–çœŸå®å‚è€ƒã€‚æˆ‘ä»¬çš„æ¨¡å‹ä»é«˜æ–¯è¡¨ç¤ºä¸­æå–ç©ºé—´å’Œå…‰åº¦çº¿ç´¢ï¼Œä»¥ç»“æ„æ„ŸçŸ¥çš„æ–¹å¼ä¼°è®¡æ„ŸçŸ¥è´¨é‡ã€‚æˆ‘ä»¬è¿˜å¯¹ç°æœ‰çš„è´¨é‡è¯„ä¼°æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿå’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆå®ç°å“è¶Šæ€§èƒ½ï¼Œçªæ˜¾å…¶åœ¨è¯„ä¼°3DGSå†…å®¹æ–¹é¢çš„ç¨³å¥æ€§å’Œæœ‰æ•ˆæ€§ã€‚æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/diaoyn/3DGSQA">https://github.com/diaoyn/3DGSQA</a>ï¼Œä»¥ä¾¿æœªæ¥è¿›è¡Œ3DGSè´¨é‡è¯„ä¼°çš„ç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ol>
<li>3DGSå·²æˆä¸ºå®æ—¶é«˜ä¿çœŸæ¸²æŸ“çš„é¢†å…ˆæŠ€æœ¯ï¼Œä½†åœ¨æ„ŸçŸ¥è´¨é‡æ–¹é¢ä»å­˜åœ¨ç ”ç©¶ç©ºç™½ã€‚</li>
<li>å®è·µä¸­å­˜åœ¨çš„å¤šç§å› ç´ ï¼ˆå¦‚è§†ç‚¹ç¨€ç–ã€è®­ç»ƒè¿­ä»£æ¬¡æ•°æœ‰é™ç­‰ï¼‰å¯èƒ½å¯¼è‡´è§†è§‰è´¨é‡ä¸‹é™ã€‚</li>
<li>æˆ‘ä»¬å¼•å…¥äº†é¦–ä¸ªé’ˆå¯¹3DGSçš„ä¸»è§‚è´¨é‡è¯„ä¼°æ•°æ®é›†â€”â€”3DGS-QAã€‚</li>
<li>åŸºäºæ•°æ®é›†æå‡ºäº†æ— å‚è€ƒè´¨é‡é¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½åœ¨é«˜æ–¯åŸå§‹æ•°æ®ä¸Šç›´æ¥è¿è¡Œå¹¶ä¼°è®¡æ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>ä¸ç°æœ‰è´¨é‡è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.08032">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c18bf3ba96dd3052ccb0c2af87fdfd71" align="middle">
<img src="https://picx.zhimg.com/v2-95a9c39f3895ff6a68c9fdd83f518870" align="middle">
<img src="https://picx.zhimg.com/v2-5ac91450e7531ecfe01589525555a38b" align="middle">
<img src="https://picx.zhimg.com/v2-80dc80a58b9d3d55d9803940f5470578" align="middle">
<img src="https://picx.zhimg.com/v2-fd0d1810aa677ae19907d750ac25643e" align="middle">
<img src="https://picx.zhimg.com/v2-fc3643d5f96b278c0293c8f794c8107f" align="middle">
<img src="https://picx.zhimg.com/v2-075b0d6d306afecaba35419ceeebe3ed" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Is-It-Truly-Necessary-to-Process-and-Fit-Minutes-Long-Reference-Videos-for-Personalized-Talking-Face-Generation"><a href="#Is-It-Truly-Necessary-to-Process-and-Fit-Minutes-Long-Reference-Videos-for-Personalized-Talking-Face-Generation" class="headerlink" title="Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?"></a>Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?</h2><p><strong>Authors:Rui-Qing Sun, Ang Li, Zhijing Wu, Tian Lan, Qianyu Lu, Xingshan Yao, Chen Xu, Xian-Ling Mao</strong></p>
<p>Talking Face Generation (TFG) aims to produce realistic and dynamic talking portraits, with broad applications in fields such as digital education, film and television production, e-commerce live streaming, and other related areas. Currently, TFG methods based on Neural Radiated Field (NeRF) or 3D Gaussian sputtering (3DGS) are received widespread attention. They learn and store personalized features from reference videos of each target individual to generate realistic speaking videos. To ensure models can capture sufficient 3D information and successfully learns the lip-audio mapping, previous studies usually require meticulous processing and fitting several minutes of reference video, which always takes hours. The computational burden of processing and fitting long reference videos severely limits the practical application value of these methods.However, is it really necessary to fit such minutes of reference video? Our exploratory case studies show that using some informative reference video segments of just a few seconds can achieve performance comparable to or even better than the full reference video. This indicates that video informative quality is much more important than its length. Inspired by this observation, we propose the ISExplore (short for Informative Segment Explore), a simple-yet-effective segment selection strategy that automatically identifies the informative 5-second reference video segment based on three key data quality dimensions: audio feature diversity, lip movement amplitude, and number of camera views. Extensive experiments demonstrate that our approach increases data processing and training speed by more than 5x for NeRF and 3DGS methods, while maintaining high-fidelity output. Project resources are available at xx.</p>
<blockquote>
<p>è¯´è¯äººè„¸ç”Ÿæˆï¼ˆTFGï¼‰æ—¨åœ¨ç”ŸæˆçœŸå®ä¸”åŠ¨æ€çš„è¯´è¯è‚–åƒï¼Œå¹¿æ³›åº”ç”¨äºæ•°å­—æ•™è‚²ã€å½±è§†åˆ¶ä½œã€ç”µå•†ç›´æ’­ç­‰é¢†åŸŸã€‚ç›®å‰ï¼ŒåŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–ä¸‰ç»´é«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰çš„TFGæ–¹æ³•å—åˆ°å¹¿æ³›å…³æ³¨ã€‚å®ƒä»¬ä»æ¯ä¸ªç›®æ ‡ä¸ªä½“çš„å‚è€ƒè§†é¢‘ä¸­å­¦ä¹ å’Œå­˜å‚¨ä¸ªæ€§åŒ–ç‰¹å¾ï¼Œä»¥ç”ŸæˆçœŸå®çš„è¯´è¯è§†é¢‘ã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ•è·è¶³å¤Ÿçš„3Dä¿¡æ¯å¹¶æˆåŠŸå­¦ä¹ å”‡éŸ³æ˜ å°„ï¼Œä¹‹å‰çš„ç ”ç©¶é€šå¸¸éœ€è¦ç²¾ç»†å¤„ç†å¹¶æ‹Ÿåˆæ•°åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘ï¼Œè¿™é€šå¸¸éœ€è¦æ•°å°æ—¶çš„æ—¶é—´ã€‚å¤„ç†å¹¶æ‹Ÿåˆé•¿å‚è€ƒè§†é¢‘çš„è®¡ç®—è´Ÿæ‹…ä¸¥é‡é™åˆ¶äº†è¿™äº›æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„ä»·å€¼ã€‚ç„¶è€Œï¼Œæ‹Ÿåˆå¦‚æ­¤é•¿æ—¶é—´çš„å‚è€ƒè§†é¢‘çœŸçš„æœ‰å¿…è¦å—ï¼Ÿæˆ‘ä»¬çš„æ¢ç´¢æ€§æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨ä»…å‡ ç§’é’Ÿçš„å‚è€ƒè§†é¢‘ç‰‡æ®µå°±å¯ä»¥å®ç°ä¸å®Œæ•´å‚è€ƒè§†é¢‘ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜è§†é¢‘çš„ä¿¡æ¯è´¨é‡è¿œæ¯”å…¶é•¿åº¦é‡è¦ã€‚å—è¿™ä¸€è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ISExploreï¼ˆå³ä¿¡æ¯ç‰‡æ®µæ¢ç´¢ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„ç‰‡æ®µé€‰æ‹©ç­–ç•¥ï¼Œå¯è‡ªåŠ¨ç¡®å®šåŸºäºä¸‰ä¸ªå…³é”®æ•°æ®è´¨é‡ç»´åº¦çš„ä¿¡æ¯ä¸°å¯Œçš„5ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µï¼šéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å˜´å”‡è¿åŠ¨å¹…åº¦å’Œæ‘„åƒæœºè§†è§’æ•°é‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†NeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†å’Œè®­ç»ƒé€Ÿåº¦æé«˜äº†5å€ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒé«˜ä¿çœŸè¾“å‡ºã€‚é¡¹ç›®èµ„æºå¯åœ¨xxæ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07940v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†è¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯ï¼ˆTFGï¼‰ï¼Œæ—¨åœ¨ç”ŸæˆçœŸå®åŠ¨æ€çš„è‚–åƒè§†é¢‘ï¼Œå¹¿æ³›åº”ç”¨äºæ•°å­—æ•™è‚²ã€å½±è§†åˆ¶ä½œã€ç”µå•†ç›´æ’­ç­‰é¢†åŸŸã€‚å½“å‰åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰çš„TFGæ–¹æ³•å—åˆ°å…³æ³¨ã€‚è¿™äº›æ–¹æ³•é€šè¿‡å­¦ä¹ å’Œå­˜å‚¨æ¥è‡ªç›®æ ‡ä¸ªä½“å‚è€ƒè§†é¢‘çš„ä¸ªäººç‰¹å¾æ¥ç”Ÿæˆé€¼çœŸçš„è¯´è¯è§†é¢‘ã€‚ä¸ºç¡®ä¿æ¨¡å‹æ•æ‰è¶³å¤Ÿçš„3Dä¿¡æ¯å’ŒæˆåŠŸå­¦ä¹ å”‡éŸ³æ˜ å°„ï¼Œå…ˆå‰ç ”ç©¶é€šå¸¸éœ€è¦ç²¾ç»†å¤„ç†å’Œæ‹Ÿåˆæ•°åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘ï¼Œè€—æ—¶è¾ƒé•¿ã€‚ç„¶è€Œï¼Œé€šè¿‡æ¢ç´¢æ€§æ¡ˆä¾‹ç ”ç©¶ï¼Œä½œè€…å‘ç°ä½¿ç”¨å‡ ç§’çš„å‚è€ƒè§†é¢‘ç‰‡æ®µå³å¯å®ç°ä¸å…¨è§†é¢‘ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ï¼Œè¡¨æ˜è§†é¢‘çš„ä¿¡æ¯è´¨é‡æ¯”é•¿åº¦æ›´é‡è¦ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œä½œè€…æå‡ºäº†ISExploreï¼ˆçŸ­è§†é¢‘æ®µä¿¡æ¯æ¢ç´¢ï¼‰ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯æ ¹æ®éŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨åŠ¨ä½œå¹…åº¦å’Œæ‘„åƒå¤´è§†è§’ç­‰ä¸‰ä¸ªå…³é”®æ•°æ®è´¨é‡ç»´åº¦è‡ªåŠ¨è¯†åˆ«å‡ºæœ€å…·ä»£è¡¨æ€§çš„5ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯æé«˜NeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†é€Ÿåº¦å’Œè®­ç»ƒé€Ÿåº¦è¶…è¿‡5å€ï¼ŒåŒæ—¶ä¿æŒé«˜ä¿çœŸè¾“å‡ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯ï¼ˆTFGï¼‰å¯ç”ŸæˆçœŸå®åŠ¨æ€çš„è‚–åƒè§†é¢‘ï¼Œå¹¿æ³›åº”ç”¨äºå¤šä¸ªé¢†åŸŸã€‚</li>
<li>å½“å‰TFGæ–¹æ³•ä¸»è¦åŸºäºNeRFæˆ–3DGSæŠ€æœ¯ï¼Œé€šè¿‡å­¦ä¹ å’Œå­˜å‚¨ä¸ªäººç‰¹å¾ä»å‚è€ƒè§†é¢‘ä¸­ç”Ÿæˆè¯´è¯è§†é¢‘ã€‚</li>
<li>å…ˆå‰çš„ç ”ç©¶é€šå¸¸éœ€è¦å¤„ç†å’Œæ‹Ÿåˆæ•°åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘ä»¥ç¡®ä¿æ¨¡å‹æ•æ‰è¶³å¤Ÿçš„3Dä¿¡æ¯å’Œå”‡éŸ³æ˜ å°„ï¼Œè¿™å¢åŠ äº†è®¡ç®—è´Ÿæ‹…å¹¶é™åˆ¶äº†å®é™…åº”ç”¨ä»·å€¼ã€‚</li>
<li>æ¢ç´¢æ€§æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨å‡ ç§’çš„å‚è€ƒè§†é¢‘ç‰‡æ®µå³å¯å®ç°è‰¯å¥½çš„æ€§èƒ½ï¼Œè¿™è¡¨æ˜è§†é¢‘çš„ä¿¡æ¯è´¨é‡æ¯”é•¿åº¦æ›´é‡è¦ã€‚</li>
<li>æå‡ºäº†ISExploreç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯è‡ªåŠ¨è¯†åˆ«æœ€å…·ä»£è¡¨æ€§çš„5ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µï¼ŒåŸºäºéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨åŠ¨ä½œå¹…åº¦å’Œæ‘„åƒå¤´è§†è§’ä¸‰ä¸ªå…³é”®æ•°æ®è´¨é‡ç»´åº¦ã€‚</li>
<li>ISExploreç­–ç•¥å¯æé«˜NeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†é€Ÿåº¦å’Œè®­ç»ƒé€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07940">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62a424c1a5296b7152788a243d566878" align="middle">
<img src="https://picx.zhimg.com/v2-da11e51d7c84f5733717486d55c20df4" align="middle">
<img src="https://picx.zhimg.com/v2-8dcca5f3a09cad2c41089af9d662173d" align="middle">
<img src="https://picx.zhimg.com/v2-fc3f9bcbefee193f1c713f94789218ea" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="UltraGS-Gaussian-Splatting-for-Ultrasound-Novel-View-Synthesis"><a href="#UltraGS-Gaussian-Splatting-for-Ultrasound-Novel-View-Synthesis" class="headerlink" title="UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis"></a>UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis</h2><p><strong>Authors:Yuezhe Yang, Wenjie Cai, Dexin Yang, Yufang Dong, Xingbo Dong, Zhe Jin</strong></p>
<p>Ultrasound imaging is a cornerstone of non-invasive clinical diagnostics, yet its limited field of view complicates novel view synthesis. We propose \textbf{UltraGS}, a Gaussian Splatting framework optimized for ultrasound imaging. First, we introduce a depth-aware Gaussian splatting strategy, where each Gaussian is assigned a learnable field of view, enabling accurate depth prediction and precise structural representation. Second, we design SH-DARS, a lightweight rendering function combining low-order spherical harmonics with ultrasound-specific wave physics, including depth attenuation, reflection, and scattering, to model tissue intensity accurately. Third, we contribute the Clinical Ultrasound Examination Dataset, a benchmark capturing diverse anatomical scans under real-world clinical protocols. Extensive experiments on three datasets demonstrate UltraGSâ€™s superiority, achieving state-of-the-art results in PSNR (up to 29.55), SSIM (up to 0.89), and MSE (as low as 0.002) while enabling real-time synthesis at 64.69 fps. The code and dataset are open-sourced at: <a target="_blank" rel="noopener" href="https://github.com/Bean-Young/UltraGS">https://github.com/Bean-Young/UltraGS</a>.</p>
<blockquote>
<p>è¶…å£°æˆåƒä½œä¸ºéä¾µå…¥æ€§ä¸´åºŠè¯Šæ–­çš„åŸºçŸ³ï¼Œä½†å…¶æœ‰é™çš„è§†é‡ç»™æ–°å‹è§†å›¾åˆæˆå¸¦æ¥äº†å›°éš¾ã€‚æˆ‘ä»¬æå‡ºäº†é’ˆå¯¹è¶…å£°æˆåƒä¼˜åŒ–çš„é«˜æ–¯Splattingæ¡†æ¶â€”â€”UltraGSã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ·±åº¦æ„ŸçŸ¥çš„é«˜æ–¯Splattingç­–ç•¥ï¼Œå…¶ä¸­æ¯ä¸ªé«˜æ–¯è¢«åˆ†é…ä¸€ä¸ªå¯å­¦ä¹ çš„è§†é‡ï¼Œä»è€Œå®ç°å‡†ç¡®çš„æ·±åº¦é¢„æµ‹å’Œç²¾ç¡®çš„ç»“æ„è¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†SH-DARSï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ¸²æŸ“åŠŸèƒ½ï¼Œç»“åˆäº†ä½é˜¶çƒè°å‡½æ•°å’Œè¶…å£°ç‰¹å®šçš„æ³¢ç‰©ç†ï¼ŒåŒ…æ‹¬æ·±åº¦è¡°å‡ã€åå°„å’Œæ•£å°„ï¼Œä»¥å‡†ç¡®æ¨¡æ‹Ÿç»„ç»‡å¼ºåº¦ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è´¡çŒ®äº†ä¸´åºŠè¶…å£°æ£€æŸ¥æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼Œæ•è·äº†çœŸå®ä¸–ç•Œä¸´åºŠåè®®ä¸‹çš„å¤šç§è§£å‰–æ‰«æã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†UltraGSçš„ä¼˜è¶Šæ€§ï¼Œåœ¨PSNRï¼ˆé«˜è¾¾29.55ï¼‰ã€SSIMï¼ˆé«˜è¾¾0.89ï¼‰å’ŒMSEï¼ˆä½è‡³0.002ï¼‰æ–¹é¢è¾¾åˆ°æœ€æ–°æ°´å¹³çš„ç»“æœï¼ŒåŒæ—¶ä»¥æ¯ç§’64.69å¸§çš„é€Ÿåº¦å®ç°å®æ—¶åˆæˆã€‚ä»£ç å’Œæ•°æ®é›†å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/Bean-Young/UltraGS%E5%BC%80%E6%BA%90%E3%80%82">https://github.com/Bean-Young/UltraGSå¼€æºã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07743v1">PDF</a> Under Review</p>
<p><strong>Summary</strong><br>è¶…å£°æ³¢æˆåƒåœ¨ä¸´åºŠè¯Šæ–­ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œä½†å…¶æœ‰é™çš„è§†é‡ç»™æ–°å‹è§†å›¾åˆæˆå¸¦æ¥æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§é’ˆå¯¹è¶…å£°æ³¢æˆåƒçš„Gaussian Splattingæ¡†æ¶â€”â€”UltraGSã€‚å®ƒé‡‡ç”¨æ·±åº¦æ„ŸçŸ¥çš„é«˜æ–¯å–·ç»˜ç­–ç•¥ï¼Œå¹¶ç»“åˆä½é˜¶çƒè°å‡½æ•°ä¸è¶…å£°æ³¢ç‰¹å®šæ³¢åŠ¨ç‰©ç†çš„è½»é‡åŒ–æ¸²æŸ“åŠŸèƒ½SH-DARSï¼Œå®ç°ç²¾å‡†ç»“æ„è¡¨å¾ä¸å¼ºåº¦å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å…¬å¼€äº†ç¬¦åˆçœŸå®ä¸´åºŠåè®®çš„å¤šè§£å‰–éƒ¨ä½æ‰«ææ•°æ®é›†ï¼Œå¹¶éªŒè¯äº†UltraGSåœ¨PSNRã€SSIMå’ŒMSEæŒ‡æ ‡ä¸Šçš„ä¼˜è¶Šæ€§ï¼ŒåŒæ—¶å®ç°å®æ—¶åˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>UltraGSæ˜¯ä¸€ä¸ªé’ˆå¯¹è¶…å£°æ³¢æˆåƒçš„Gaussian Splattingæ¡†æ¶ã€‚</li>
<li>å¼•å…¥æ·±åº¦æ„ŸçŸ¥çš„é«˜æ–¯å–·ç»˜ç­–ç•¥ï¼Œä½¿æ¯ä¸ªé«˜æ–¯å…·æœ‰å¯å­¦ä¹ çš„è§†é‡ï¼Œæé«˜æ·±åº¦é¢„æµ‹å’Œç»“æ„åŒ–è¡¨å¾çš„å‡†ç¡®æ€§ã€‚</li>
<li>è®¾è®¡äº†ç»“åˆä½é˜¶çƒè°å‡½æ•°ä¸è¶…å£°æ³¢ç‰¹å®šæ³¢åŠ¨ç‰©ç†çš„è½»é‡åŒ–æ¸²æŸ“åŠŸèƒ½SH-DARSï¼Œä»¥å‡†ç¡®æ¨¡æ‹Ÿç»„ç»‡å¼ºåº¦ã€‚</li>
<li>å…¬å¼€äº†ä¸´åºŠè¶…å£°æ³¢æ£€æŸ¥æ•°æ®é›†ï¼ŒåŒ…å«å¤šç§è§£å‰–éƒ¨ä½æ‰«æï¼Œç¬¦åˆçœŸå®ä¸´åºŠåè®®ã€‚</li>
<li>åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†UltraGSçš„ä¼˜è¶Šæ€§ï¼Œåœ¨PSNRã€SSIMå’ŒMSEæŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€æ–°æ°´å¹³ã€‚</li>
<li>UltraGSèƒ½å¤Ÿå®ç°å®æ—¶åˆæˆï¼Œè¾¾åˆ°64.69å¸§æ¯ç§’ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07743">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-678de33184e8d3d1beda89a7af567613" align="middle">
<img src="https://picx.zhimg.com/v2-02a53c7418316b1247e3d531b115eae8" align="middle">
<img src="https://picx.zhimg.com/v2-b20fc3ef0172f34a3b853ffc98d9fbaa" align="middle">
<img src="https://picx.zhimg.com/v2-dbec824d539633b37fab41c917728700" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects"><a href="#DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects" class="headerlink" title="DIMO: Diverse 3D Motion Generation for Arbitrary Objects"></a>DIMO: Diverse 3D Motion Generation for Arbitrary Objects</h2><p><strong>Authors:Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis</strong></p>
<p>We present DIMO, a generative approach capable of generating diverse 3D motions for arbitrary objects from a single image. The core idea of our work is to leverage the rich priors in well-trained video models to extract the common motion patterns and then embed them into a shared low-dimensional latent space. Specifically, we first generate multiple videos of the same object with diverse motions. We then embed each motion into a latent vector and train a shared motion decoder to learn the distribution of motions represented by a structured and compact motion representation, i.e., neural key point trajectories. The canonical 3D Gaussians are then driven by these key points and fused to model the geometry and appearance. During inference time with learned latent space, we can instantly sample diverse 3D motions in a single-forward pass and support several interesting applications including 3D motion interpolation and language-guided motion generation. Our project page is available at <a target="_blank" rel="noopener" href="https://linzhanm.github.io/dimo">https://linzhanm.github.io/dimo</a>.</p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†DIMOï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿä»å•å¼ å›¾åƒç”Ÿæˆä»»æ„å¯¹è±¡çš„å¤šç§3DåŠ¨ä½œçš„æ–¹æ³•ã€‚æˆ‘ä»¬å·¥ä½œçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨è®­ç»ƒè‰¯å¥½çš„è§†é¢‘æ¨¡å‹ä¸­çš„ä¸°å¯Œå…ˆéªŒä¿¡æ¯æ¥æå–å¸¸è§çš„è¿åŠ¨æ¨¡å¼ï¼Œç„¶åå°†å®ƒä»¬åµŒå…¥ä¸€ä¸ªå…±äº«çš„ä½ç»´æ½œåœ¨ç©ºé—´ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆç”ŸæˆåŒä¸€å¯¹è±¡çš„å¤šä¸ªå…·æœ‰ä¸åŒåŠ¨ä½œçš„è§†é¢‘ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ¯ä¸ªåŠ¨ä½œåµŒå…¥åˆ°ä¸€ä¸ªæ½œåœ¨å‘é‡ä¸­ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªå…±äº«çš„è¿åŠ¨è§£ç å™¨æ¥å­¦ä¹ ç”±ç»“æ„åŒ–ä¸”ç´§å‡‘çš„è¿åŠ¨è¡¨ç¤ºæ‰€è¡¨ç¤ºçš„è¿åŠ¨åˆ†å¸ƒï¼Œå³ç¥ç»å…³é”®ç‚¹è½¨è¿¹ã€‚è§„èŒƒçš„ä¸‰ç»´é«˜æ–¯éšåè¢«è¿™äº›å…³é”®ç‚¹é©±åŠ¨å¹¶èåˆä»¥æ¨¡æ‹Ÿå‡ ä½•å’Œå¤–è§‚ã€‚åœ¨å…·æœ‰å­¦ä¹ åˆ°çš„æ½œåœ¨ç©ºé—´çš„æ¨ç†æ—¶é—´ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç«‹å³åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­é‡‡æ ·å¤šç§å¤šæ ·çš„ä¸‰ç»´åŠ¨ä½œï¼Œå¹¶æ”¯æŒåŒ…æ‹¬ä¸‰ç»´è¿åŠ¨æ’å€¼å’Œè¯­è¨€å¼•å¯¼çš„è¿åŠ¨ç”Ÿæˆç­‰å‡ ä¸ªæœ‰è¶£çš„åº”ç”¨ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ä½äº<a target="_blank" rel="noopener" href="https://linzhanm.github.io/dimo%E3%80%82">https://linzhanm.github.io/dimoã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07409v1">PDF</a> Published in ICCV 2025, project page <a target="_blank" rel="noopener" href="https://linzhanm.github.io/dimo">https://linzhanm.github.io/dimo</a></p>
<p><strong>Summary</strong></p>
<p>DIMOæ–¹æ³•å¯ä»¥ä»å•å¹…å›¾åƒä¸ºä»»æ„å¯¹è±¡ç”Ÿæˆå¤šæ ·çš„3DåŠ¨ä½œã€‚å®ƒå€ŸåŠ©è®­ç»ƒè‰¯å¥½çš„è§†é¢‘æ¨¡å‹çš„ä¸°å¯Œå…ˆéªŒçŸ¥è¯†ï¼Œæå–å¸¸è§çš„è¿åŠ¨æ¨¡å¼ï¼Œç„¶ååµŒå…¥ä¸€ä¸ªå…±äº«çš„ä½ç»´æ½œåœ¨ç©ºé—´ã€‚é€šè¿‡ç”ŸæˆåŒä¸€å¯¹è±¡çš„å¤šä¸ªåŠ¨ä½œè§†é¢‘ï¼ŒåµŒå…¥æ¯ä¸ªåŠ¨ä½œåˆ°æ½œåœ¨å‘é‡ï¼Œè®­ç»ƒå…±äº«è¿åŠ¨è§£ç å™¨å­¦ä¹ ç”±ç»“æ„åŒ–ä¸”ç´§å‡‘çš„è¿åŠ¨è¡¨ç¤ºï¼ˆå³ç¥ç»å…³é”®ç‚¹è½¨è¿¹ï¼‰è¡¨ç¤ºçš„è¿åŠ¨åˆ†å¸ƒã€‚åœ¨æ¨æ–­é˜¶æ®µï¼Œåˆ©ç”¨å­¦ä¹ åˆ°çš„æ½œåœ¨ç©ºé—´ï¼Œå¯ä»¥ç«‹å³åœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­é‡‡æ ·å¤šæ ·çš„3DåŠ¨ä½œï¼Œå¹¶æ”¯æŒåŒ…æ‹¬3Dè¿åŠ¨æ’å€¼å’Œè¯­è¨€å¼•å¯¼çš„è¿åŠ¨ç”Ÿæˆç­‰æœ‰è¶£çš„åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DIMOæ˜¯ä¸€ç§èƒ½å¤Ÿä»å•å¹…å›¾åƒç”Ÿæˆä»»æ„å¯¹è±¡çš„å¤šæ ·3Dè¿åŠ¨çš„ç”Ÿæˆæ€§æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ¨¡å‹çš„ä¸°å¯Œå…ˆéªŒçŸ¥è¯†æ¥æå–å’ŒåµŒå…¥è¿åŠ¨æ¨¡å¼ã€‚</li>
<li>é€šè¿‡ç”ŸæˆåŒä¸€å¯¹è±¡çš„å¤šä¸ªåŠ¨ä½œè§†é¢‘ï¼Œè®­ç»ƒå…±äº«è¿åŠ¨è§£ç å™¨æ¥å­¦ä¹ è¿åŠ¨åˆ†å¸ƒã€‚</li>
<li>ä½¿ç”¨ç¥ç»å…³é”®ç‚¹è½¨è¿¹ä½œä¸ºç»“æ„åŒ–ä¸”ç´§å‡‘çš„è¿åŠ¨è¡¨ç¤ºã€‚</li>
<li>å‡ ä½•å’Œå¤–è§‚æ¨¡å‹ç”±è§„èŒƒåŒ–çš„3Dé«˜æ–¯å’Œå…³é”®ç‚¹é©±åŠ¨ã€‚</li>
<li>åœ¨æ¨æ–­é˜¶æ®µï¼Œèƒ½å¤Ÿç«‹å³é‡‡æ ·å¤šæ ·çš„3DåŠ¨ä½œå¹¶æ”¯æŒå¤šç§åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07409">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-54f1487394901ccb05f1138d5f45d1e9" align="middle">
<img src="https://picx.zhimg.com/v2-afaf08436c09fe5a5ced60bb531d8a5d" align="middle">
<img src="https://picx.zhimg.com/v2-2989533131ce553f0e8a8faebfcb2903" align="middle">
<img src="https://picx.zhimg.com/v2-166806995a8bc7d791f3c1ad470f53af" align="middle">
<img src="https://picx.zhimg.com/v2-0fef17b8cf0a1db29b350e52703b2a07" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="YoNoSplat-You-Only-Need-One-Model-for-Feedforward-3D-Gaussian-Splatting"><a href="#YoNoSplat-You-Only-Need-One-Model-for-Feedforward-3D-Gaussian-Splatting" class="headerlink" title="YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting"></a>YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting</h2><p><strong>Authors:Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys</strong></p>
<p>Fast and flexible 3D scene reconstruction from unstructured image collections remains a significant challenge. We present YoNoSplat, a feedforward model that reconstructs high-quality 3D Gaussian Splatting representations from an arbitrary number of images. Our model is highly versatile, operating effectively with both posed and unposed, calibrated and uncalibrated inputs. YoNoSplat predicts local Gaussians and camera poses for each view, which are aggregated into a global representation using either predicted or provided poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and camera parameters, we introduce a novel mixing training strategy. This approach mitigates the entanglement between the two tasks by initially using ground-truth poses to aggregate local Gaussians and gradually transitioning to a mix of predicted and ground-truth poses, which prevents both training instability and exposure bias. We further resolve the scale ambiguity problem by a novel pairwise camera-distance normalization scheme and by embedding camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates exceptional efficiency, reconstructing a scene from 100 views (at 280x518 resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves state-of-the-art performance on standard benchmarks in both pose-free and pose-dependent settings. Our project page is at <a target="_blank" rel="noopener" href="https://botaoye.github.io/yonosplat/">https://botaoye.github.io/yonosplat/</a>.</p>
<blockquote>
<p>ä»éç»“æ„åŒ–çš„å›¾åƒé›†åˆä¸­è¿›è¡Œå¿«é€Ÿã€çµæ´»çš„3Dåœºæ™¯é‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†YoNoSplatï¼Œè¿™æ˜¯ä¸€ç§å‰é¦ˆæ¨¡å‹ï¼Œå¯ä»¥ä»ä»»æ„æ•°é‡çš„å›¾åƒé‡å»ºé«˜è´¨é‡çš„3Dé«˜æ–¯å–·å°„è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ¨¡å‹éå¸¸é€šç”¨ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†æœ‰å§¿æ€å’Œæ— å§¿æ€ã€æ ¡å‡†å’Œæœªæ ¡å‡†çš„è¾“å…¥ã€‚YoNoSplaté¢„æµ‹æ¯ä¸ªè§†å›¾çš„å±€éƒ¨é«˜æ–¯å’Œç›¸æœºå§¿æ€ï¼Œè¿™äº›å±€éƒ¨é«˜æ–¯å’Œç›¸æœºå§¿æ€å°†ä½¿ç”¨é¢„æµ‹æˆ–æä¾›çš„å§¿æ€èšé›†åˆ°å…¨å±€è¡¨ç¤ºä¸­ã€‚ä¸ºäº†å…‹æœè”åˆå­¦ä¹ 3Dé«˜æ–¯å’Œç›¸æœºå‚æ•°çš„å›ºæœ‰å›°éš¾ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ··åˆè®­ç»ƒç­–ç•¥ã€‚è¿™ç§æ–¹æ³•é€šè¿‡æœ€åˆä½¿ç”¨åœ°é¢çœŸå®å§¿æ€æ¥èšé›†å±€éƒ¨é«˜æ–¯ï¼Œå¹¶é€æ¸è¿‡æ¸¡åˆ°æ··åˆé¢„æµ‹å’Œåœ°é¢çœŸå®å§¿æ€ï¼Œä»è€Œå‡è½»äº†è¿™ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´çš„çº ç¼ ï¼Œè¿™æ—¢é˜²æ­¢äº†è®­ç»ƒä¸ç¨³å®šä¹Ÿé¿å…äº†æ›å…‰åå·®ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ç§æ–°é¢–çš„æˆå¯¹ç›¸æœºè·ç¦»å½’ä¸€åŒ–æ–¹æ¡ˆå’Œç½‘ç»œåµŒå…¥ç›¸æœºå†…å‚ï¼Œè¿›ä¸€æ­¥è§£å†³äº†å°ºåº¦æ¨¡ç³Šé—®é¢˜ã€‚æ­¤å¤–ï¼ŒYoNoSplatè¿˜å¯ä»¥é¢„æµ‹å†…å‚ï¼Œä½¿å¾—å®ƒé€‚ç”¨äºæœªæ ¡å‡†çš„è¾“å…¥ã€‚YoNoSplatå±•ç°å‡ºå“è¶Šçš„æ•ˆç‡ï¼Œåœ¨NVIDIA GH200 GPUä¸Šï¼Œä»100ä¸ªè§†è§’ï¼ˆåœ¨280x518åˆ†è¾¨ç‡ä¸‹ï¼‰é‡å»ºåœºæ™¯åªéœ€2.69ç§’ã€‚å®ƒåœ¨æ— å§¿æ€å’Œä¾èµ–å§¿æ€çš„è®¾ç½®ä¸­å‡è¾¾åˆ°äº†æ ‡å‡†åŸºå‡†æµ‹è¯•çš„æœ€ä½³æ€§èƒ½ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ˜¯<a target="_blank" rel="noopener" href="https://botaoye.github.io/yonosplat/%E3%80%82">https://botaoye.github.io/yonosplat/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07321v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»ä»»æ„çš„å›¾åƒé›†åˆä¸­ï¼Œå¿«é€Ÿçµæ´»åœ°é‡å»ºå‡ºé«˜è´¨é‡çš„3Dé«˜æ–¯æç»˜è¡¨è¾¾ï¼ˆGaussian Splatting representationsï¼‰ã€‚æ‰€æå‡ºçš„YoNoSplatæ¨¡å‹æ—¢å¯ç”¨äºæœ‰å®šä½ä¿¡æ¯ä¹Ÿå¯ç”¨äºæ— å®šä½ä¿¡æ¯çš„è¾“å…¥ï¼Œå±•ç¤ºå‡ºäº†å…¶é«˜åº¦çš„é€šç”¨æ€§ã€‚YoNoSplaté¢„æµ‹æ¯ä¸ªè§†è§’çš„å±€éƒ¨é«˜æ–¯å’Œç›¸æœºå§¿æ€ï¼Œå¹¶ä½¿ç”¨é¢„æµ‹æˆ–æä¾›çš„å§¿æ€å°†å±€éƒ¨é«˜æ–¯èšåˆæˆå…¨å±€è¡¨è¾¾ã€‚ä¸ºè§£å†³è”åˆå­¦ä¹ 3Dé«˜æ–¯å’Œç›¸æœºå‚æ•°å›ºæœ‰çš„å›°éš¾ï¼Œå¼•å…¥äº†ä¸€ç§æ–°çš„æ··åˆè®­ç»ƒç­–ç•¥ã€‚è¯¥ç­–ç•¥é€šè¿‡å…ˆä½¿ç”¨çœŸå®å§¿æ€æ¥èšé›†å±€éƒ¨é«˜æ–¯ï¼Œç„¶åé€æ¸è¿‡æ¸¡åˆ°æ··åˆä½¿ç”¨é¢„æµ‹å’ŒçœŸå®å§¿æ€ï¼Œè§£å†³äº†è®­ç»ƒä¸ç¨³å®šå’Œæš´éœ²åå·®çš„é—®é¢˜ã€‚æ­¤å¤–ï¼ŒYoNoSplatè¿˜é€šè¿‡ä¸€ç§æ–°é¢–çš„æˆå¯¹ç›¸æœºè·ç¦»å½’ä¸€åŒ–æ–¹æ¡ˆå’Œç½‘ç»œåµŒå…¥ç›¸æœºå†…å‚ï¼Œè§£å†³äº†å°ºåº¦æ¨¡ç³Šé—®é¢˜ã€‚è¯¥æ¨¡å‹å¯¹äºæ— æ ‡å®šè¾“å…¥ä¹Ÿå…·æœ‰å¯è¡Œæ€§ã€‚åœ¨NVIDIA GH200 GPUä¸Šï¼ŒYoNoSplatä»100ä¸ªè§†è§’ï¼ˆåˆ†è¾¨ç‡ä¸º280x518ï¼‰é‡å»ºåœºæ™¯ä»…éœ€2.69ç§’ï¼Œå¹¶åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>YoNoSplatæ˜¯ä¸€ä¸ªå‰é¦ˆæ¨¡å‹ï¼Œèƒ½å¤Ÿä»ä»»æ„çš„å›¾åƒé›†åˆé‡å»ºå‡ºé«˜è´¨é‡çš„3Dé«˜æ–¯æç»˜è¡¨è¾¾ã€‚</li>
<li>è¯¥æ¨¡å‹å¯åœ¨æœ‰å®šä½ä¿¡æ¯æˆ–æ— å®šä½ä¿¡æ¯çš„è¾“å…¥ä¸‹æ“ä½œï¼Œå…·æœ‰é«˜åº¦é€šç”¨æ€§ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„æ··åˆè®­ç»ƒç­–ç•¥ï¼Œè§£å†³äº†è”åˆå­¦ä¹ 3Dé«˜æ–¯å’Œç›¸æœºå‚æ•°çš„å›°éš¾ã€‚</li>
<li>é€šè¿‡æ–°é¢–çš„æˆå¯¹ç›¸æœºè·ç¦»å½’ä¸€åŒ–æ–¹æ¡ˆå’Œç½‘ç»œåµŒå…¥ç›¸æœºå†…å‚ï¼Œè§£å†³äº†å°ºåº¦æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>YoNoSplatèƒ½å¤Ÿé¢„æµ‹å†…åœ¨å‚æ•°ï¼Œé€‚ç”¨äºæ— æ ‡å®šè¾“å…¥ã€‚</li>
<li>åœ¨NVIDIA GH200 GPUä¸Šï¼ŒYoNoSplatå®ç°äº†é«˜æ•ˆçš„åœºæ™¯é‡å»ºï¼Œå¤„ç†é€Ÿåº¦é¢†å…ˆã€‚</li>
<li>åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒYoNoSplatåœ¨æ— éœ€å®šä½ä¿¡æ¯æˆ–éœ€å®šä½ä¿¡æ¯çš„åœºæ™¯ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07321">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6bacf9906124c66f9269bd869c72cd0e" align="middle">
<img src="https://picx.zhimg.com/v2-0cce9add732fec4081bda45fab5ef16a" align="middle">
<img src="https://picx.zhimg.com/v2-5fb757c646bc82ebbe5fe98f44ad2023" align="middle">
<img src="https://picx.zhimg.com/v2-5e5f531745a90d785532216c1da36648" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="4DSTR-Advancing-Generative-4D-Gaussians-with-Spatial-Temporal-Rectification-for-High-Quality-and-Consistent-4D-Generation"><a href="#4DSTR-Advancing-Generative-4D-Gaussians-with-Spatial-Temporal-Rectification-for-High-Quality-and-Consistent-4D-Generation" class="headerlink" title="4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation"></a>4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation</h2><p><strong>Authors:Mengmeng Liu, Jiuming Liu, Yunpeng Zhang, Jiangtao Li, Michael Ying Yang, Francesco Nex, Hao Cheng</strong></p>
<p>Remarkable advances in recent 2D image and 3D shape generation have induced a significant focus on dynamic 4D content generation. However, previous 4D generation methods commonly struggle to maintain spatial-temporal consistency and adapt poorly to rapid temporal variations, due to the lack of effective spatial-temporal modeling. To address these problems, we propose a novel 4D generation network called 4DSTR, which modulates generative 4D Gaussian Splatting with spatial-temporal rectification. Specifically, temporal correlation across generated 4D sequences is designed to rectify deformable scales and rotations and guarantee temporal consistency. Furthermore, an adaptive spatial densification and pruning strategy is proposed to address significant temporal variations by dynamically adding or deleting Gaussian points with the awareness of their pre-frame movements. Extensive experiments demonstrate that our 4DSTR achieves state-of-the-art performance in video-to-4D generation, excelling in reconstruction quality, spatial-temporal consistency, and adaptation to rapid temporal movements.</p>
<blockquote>
<p>è¿‘æœŸåœ¨2Då›¾åƒå’Œ3Då½¢çŠ¶ç”Ÿæˆæ–¹é¢å–å¾—çš„æ˜¾è‘—è¿›å±•å¼•å‘äº†äººä»¬å¯¹åŠ¨æ€4Då†…å®¹ç”Ÿæˆçš„é«˜åº¦å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æœ‰æ•ˆçš„æ—¶ç©ºå»ºæ¨¡ï¼Œä»¥å¾€çš„4Dç”Ÿæˆæ–¹æ³•åœ¨ç»´æŒæ—¶ç©ºä¸€è‡´æ€§å’Œé€‚åº”å¿«é€Ÿæ—¶é—´å˜åŒ–æ–¹é¢å¸¸å¸¸é‡åˆ°å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„4Dç”Ÿæˆç½‘ç»œï¼Œç§°ä¸º4DSTRï¼Œå®ƒé€šè¿‡æ—¶ç©ºçŸ«æ­£è°ƒæ§ç”Ÿæˆå¼4Dé«˜æ–¯æ¶‚æ–‘ã€‚å…·ä½“æ¥è¯´ï¼Œè®¾è®¡çš„ç”Ÿæˆ4Dåºåˆ—çš„æ—¶ç©ºç›¸å…³æ€§ç”¨äºçŸ«æ­£å¯å˜å½¢å°ºåº¦å’Œæ—‹è½¬ï¼Œå¹¶ä¿è¯æ—¶é—´ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§è‡ªé€‚åº”çš„ç©ºé—´ç¨ åŒ–å’Œä¿®å‰ªç­–ç•¥ï¼Œé€šè¿‡åŠ¨æ€æ·»åŠ æˆ–åˆ é™¤é«˜æ–¯ç‚¹å¹¶æ„è¯†åˆ°å®ƒä»¬çš„å‰å¸§è¿åŠ¨æ¥è§£å†³æ˜¾è‘—çš„æ—¶é—´å˜åŒ–é—®é¢˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„4DSTRåœ¨è§†é¢‘åˆ°4Dçš„ç”Ÿæˆä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨é‡å»ºè´¨é‡ã€æ—¶ç©ºä¸€è‡´æ€§å’Œé€‚åº”å¿«é€Ÿè¿åŠ¨æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07241v1">PDF</a> Accepted by AAAI 2026.The first two authors contributed equally</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨åŠ¨æ€4Då†…å®¹ç”Ÿæˆé¢†åŸŸï¼Œé’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨ä¿æŒæ—¶ç©ºä¸€è‡´æ€§å’Œé€‚åº”å¿«é€Ÿæ—¶é—´å˜åŒ–æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„4Dç”Ÿæˆç½‘ç»œï¼Œåä¸º4DSTRã€‚è¯¥ç½‘ç»œç»“åˆäº†æ—¶ç©ºä¿®æ­£æŠ€æœ¯æ¥è°ƒæ•´ç”Ÿæˆåºåˆ—çš„ç©ºé—´å‡ ä½•å’Œå§¿æ€å·®å¼‚ï¼Œä»¥åŠé‡‡ç”¨è‡ªé€‚åº”çš„ç©ºé—´ç‚¹å¯†åŒ–å’Œç®€åŒ–ç­–ç•¥æ¥å¤„ç†æ˜¾è‘—çš„æ—¶åºå˜åŒ–ã€‚å®éªŒç»“æœè¯æ˜äº†å…¶åœ¨è§†é¢‘åˆ°4Dç”Ÿæˆçš„ä¼˜ç§€æ€§èƒ½ï¼Œå°¤å…¶åœ¨é‡å»ºè´¨é‡ã€æ—¶ç©ºä¸€è‡´æ€§å’Œé€‚åº”å¿«é€Ÿå˜åŒ–æ–¹é¢è¡¨ç°çªå‡ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼ºè°ƒåŠ¨æ€4Då†…å®¹ç”Ÿæˆçš„æ˜¾è‘—è¿›å±•å’ŒæŒ‘æˆ˜ã€‚</li>
<li>æå‡ºæ–°å‹4Dç”Ÿæˆç½‘ç»œæ¨¡å‹åä¸º4DSTRï¼Œé’ˆå¯¹æ—¶ç©ºä¸€è‡´æ€§éš¾é¢˜è¿›è¡Œäº†è®¾è®¡ã€‚</li>
<li>é‡‡ç”¨æ—¶ç©ºä¿®æ­£æŠ€æœ¯æ¥ä¿æŒå˜å½¢å°ºåº¦ä¸æ—‹è½¬çš„è¿ç»­ä¸€è‡´æ€§ã€‚</li>
<li>è‡ªé€‚åº”çš„ç©ºé—´ç‚¹å¯†åŒ–å’Œç®€åŒ–ç­–ç•¥å¯ä»¥åº”å¯¹æ˜¾è‘—çš„æ—¶åºå˜åŒ–ã€‚</li>
<li>å®éªŒç»“æœå±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨è§†é¢‘åˆ°4Dç”Ÿæˆä»»åŠ¡çš„å‡ºè‰²æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07241">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2daf10138ca0231d4c0c88a7a76abee0" align="middle">
<img src="https://picx.zhimg.com/v2-9734870c06f9a37e3278c76494a71be5" align="middle">
<img src="https://picx.zhimg.com/v2-9a1cf2218460b30ac7640fddb203786c" align="middle">
<img src="https://picx.zhimg.com/v2-a4375cc45652ac7055ed644bd863f554" align="middle">
<img src="https://picx.zhimg.com/v2-0366928aca1de9e59ec9506e2e39ebf6" align="middle">
<img src="https://picx.zhimg.com/v2-a7513d90ea40e2c69d48f08b149ec5d1" align="middle">
<img src="https://picx.zhimg.com/v2-769baf8cfbcd1347d39021364c35a415" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Physics-Informed-Deformable-Gaussian-Splatting-Towards-Unified-Constitutive-Laws-for-Time-Evolving-Material-Field"><a href="#Physics-Informed-Deformable-Gaussian-Splatting-Towards-Unified-Constitutive-Laws-for-Time-Evolving-Material-Field" class="headerlink" title="Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field"></a>Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field</h2><p><strong>Authors:Haoqin Hong, Ding Fan, Fubin Dou, Zhi-Li Zhou, Haoran Sun, Congcong Zhu, Jingrun Chen</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS), an explicit scene representation technique, has shown significant promise for dynamic novel-view synthesis from monocular video input. However, purely data-driven 3DGS often struggles to capture the diverse physics-driven motion patterns in dynamic scenes. To fill this gap, we propose Physics-Informed Deformable Gaussian Splatting (PIDG), which treats each Gaussian particle as a Lagrangian material point with time-varying constitutive parameters and is supervised by 2D optical flow via motion projection. Specifically, we adopt static-dynamic decoupled 4D decomposed hash encoding to reconstruct geometry and motion efficiently. Subsequently, we impose the Cauchy momentum residual as a physics constraint, enabling independent prediction of each particleâ€™s velocity and constitutive stress via a time-evolving material field. Finally, we further supervise data fitting by matching Lagrangian particle flow to camera-compensated optical flow, which accelerates convergence and improves generalization. Experiments on a custom physics-driven dataset as well as on standard synthetic and real-world datasets demonstrate significant gains in physical consistency and monocular dynamic reconstruction quality.</p>
<blockquote>
<p>è¿‘æœŸï¼Œä¸‰ç»´é«˜æ–¯å–·å°„ï¼ˆ3DGSï¼‰ä½œä¸ºä¸€ç§æ˜¾å¼åœºæ™¯è¡¨ç¤ºæŠ€æœ¯ï¼Œåœ¨ä»å•ç›®è§†é¢‘è¾“å…¥è¿›è¡ŒåŠ¨æ€æ–°è§†è§’åˆæˆæ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œçº¯ç²¹çš„æ•°æ®é©±åŠ¨å‹3DGSåœ¨æ•æ‰åŠ¨æ€åœºæ™¯ä¸­çš„å¤šæ ·åŒ–ç‰©ç†é©±åŠ¨è¿åŠ¨æ¨¡å¼æ–¹é¢å¸¸å¸¸é‡åˆ°å›°éš¾ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºç‰©ç†ä¿¡æ¯çš„å¯å˜å½¢é«˜æ–¯å–·å°„ï¼ˆPIDGï¼‰ï¼Œå®ƒå°†æ¯ä¸ªé«˜æ–¯ç²’å­è§†ä¸ºå…·æœ‰éšæ—¶é—´å˜åŒ–çš„ç»„æˆå‚æ•°çš„æ‹‰æ ¼æœ—æ—¥ç‰©è´¨ç‚¹ï¼Œå¹¶é€šè¿‡è¿åŠ¨æŠ•å½±å—åˆ°äºŒç»´å…‰æµçš„ç›‘ç£ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨é™æ€-åŠ¨æ€è§£è€¦çš„å››ç»´åˆ†è§£å“ˆå¸Œç¼–ç æ¥é«˜æ•ˆåœ°é‡å»ºå‡ ä½•å’Œè¿åŠ¨ã€‚ä¹‹åï¼Œæˆ‘ä»¬æ–½åŠ æŸ¯è¥¿åŠ¨é‡æ®‹å·®ä½œä¸ºç‰©ç†çº¦æŸï¼Œä½¿å¾—èƒ½å¤Ÿé€šè¿‡éšæ—¶é—´æ¼”åŒ–çš„ææ–™åœºç‹¬ç«‹é¢„æµ‹æ¯ä¸ªç²’å­çš„é€Ÿåº¦å’Œç»„æˆåº”åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å°†æ‹‰æ ¼æœ—æ—¥ç²’å­æµä¸ç›¸æœºè¡¥å¿çš„å…‰æµè¿›è¡ŒåŒ¹é…æ¥è¿›ä¸€æ­¥ç›‘ç£æ•°æ®æ‹Ÿåˆï¼Œè¿™åŠ é€Ÿäº†æ”¶æ•›å¹¶æé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚åœ¨å®šåˆ¶çš„åŸºäºç‰©ç†çš„æ•°æ®é›†ä»¥åŠæ ‡å‡†åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œå•ç›®åŠ¨æ€é‡å»ºè´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.06299v2">PDF</a> Accepted by AAAI-26</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå•ç›®è§†é¢‘è¾“å…¥çš„åŠ¨æ€åœºæ™¯é‡å»ºä¸­ï¼Œ3Dé«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆ3DGSï¼‰å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ä¸ºè§£å†³å•çº¯æ•°æ®é©±åŠ¨æ–¹æ³•éš¾ä»¥æ•æ‰åŠ¨æ€åœºæ™¯ä¸­çš„å¤æ‚ç‰©ç†è¿åŠ¨æ¨¡å¼çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºç‰©ç†ä¿¡æ¯çš„å¯å˜å½¢é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆPIDGï¼‰ã€‚è¯¥æŠ€æœ¯å°†æ¯ä¸ªé«˜æ–¯ç²’å­è§†ä¸ºæ‹‰æ ¼æœ—æ—¥ç‰©è´¨ç‚¹ï¼Œå…·æœ‰éšæ—¶é—´å˜åŒ–çš„ç»„æˆå‚æ•°ï¼Œå¹¶é€šè¿‡è¿åŠ¨æŠ•å½±é€šè¿‡äºŒç»´å…‰æµè¿›è¡Œç›‘æ§ã€‚é€šè¿‡é‡‡ç”¨é™æ€åŠ¨æ€è§£è€¦çš„4Dåˆ†è§£å“ˆå¸Œç¼–ç æŠ€æœ¯é«˜æ•ˆé‡å»ºå‡ ä½•å’Œè¿åŠ¨ç»“æ„ï¼Œå¹¶å¼•å…¥æŸ¯è¥¿åŠ¨é‡æ®‹å·®ä½œä¸ºç‰©ç†çº¦æŸï¼Œä½¿å¾—èƒ½å¤Ÿç‹¬ç«‹é¢„æµ‹æ¯ä¸ªç²’å­çš„é€Ÿåº¦å’Œç»„æˆåº”åŠ›ã€‚æœ€åé€šè¿‡æ‹‰æ ¼æœ—æ—¥ç²’å­æµä¸ç›¸æœºè¡¥å¿å…‰æµçš„åŒ¹é…åŠ å¼ºæ•°æ®æ‹Ÿåˆï¼ŒåŠ å¿«æ”¶æ•›å¹¶æé«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨å®šåˆ¶çš„åŸºäºç‰©ç†çš„æ•°æ®åº“ä»¥åŠæ ‡å‡†åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ç†ä¸€è‡´æ€§å’Œå•ç›®åŠ¨æ€é‡å»ºè´¨é‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSä½œä¸ºä¸€ç§æ˜¾å¼åœºæ™¯è¡¨ç¤ºæŠ€æœ¯ï¼Œåœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­å±•ç°å‡ºæ½œåŠ›ã€‚</li>
<li>PIDGæŠ€æœ¯è§£å†³äº†å•çº¯æ•°æ®é©±åŠ¨çš„3DGSéš¾ä»¥æ•æ‰å¤æ‚ç‰©ç†è¿åŠ¨æ¨¡å¼çš„é—®é¢˜ã€‚</li>
<li>PIDGå°†æ¯ä¸ªé«˜æ–¯ç²’å­è§†ä¸ºæ‹‰æ ¼æœ—æ—¥ç‰©è´¨ç‚¹ï¼Œå¹¶å¼•å…¥ç‰©ç†ä¿¡æ¯è¿›è¡Œç›‘ç£å­¦ä¹ ã€‚</li>
<li>é‡‡ç”¨é™æ€åŠ¨æ€è§£è€¦çš„4Dåˆ†è§£å“ˆå¸Œç¼–ç æŠ€æœ¯é«˜æ•ˆé‡å»ºå‡ ä½•å’Œè¿åŠ¨ç»“æ„ã€‚</li>
<li>å¼•å…¥æŸ¯è¥¿åŠ¨é‡æ®‹å·®ä½œä¸ºç‰©ç†çº¦æŸï¼Œç‹¬ç«‹é¢„æµ‹ç²’å­çš„é€Ÿåº¦å’Œç»„æˆåº”åŠ›ã€‚</li>
<li>é€šè¿‡æ‹‰æ ¼æœ—æ—¥ç²’å­æµä¸ç›¸æœºè¡¥å¿å…‰æµçš„åŒ¹é…åŠ å¼ºæ•°æ®æ‹Ÿåˆï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.06299">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a3abe0b0bb1c68df2095fa1e8f27eabc" align="middle">
<img src="https://picx.zhimg.com/v2-28bbf37a1e9d2e7eb7316b9984c2b455" align="middle">
<img src="https://picx.zhimg.com/v2-fb88bbbe36811e146da1c25572b8ddde" align="middle">
<img src="https://picx.zhimg.com/v2-a43917f63d343e8e2e8b8a3ec4be1f56" align="middle">
<img src="https://picx.zhimg.com/v2-c7f7b6689b3ef0e1e8f2162afc067e91" align="middle">
<img src="https://picx.zhimg.com/v2-42cc7f99f547b809c6c398813fdb36f8" align="middle">
<img src="https://picx.zhimg.com/v2-1d461bb1c3ba7cb9df0a97122037b4bb" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Real-to-Sim-Robot-Policy-Evaluation-with-Gaussian-Splatting-Simulation-of-Soft-Body-Interactions"><a href="#Real-to-Sim-Robot-Policy-Evaluation-with-Gaussian-Splatting-Simulation-of-Soft-Body-Interactions" class="headerlink" title="Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions"></a>Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions</h2><p><strong>Authors:Kaifeng Zhang, Shuo Sha, Hanxiao Jiang, Matthew Loper, Hyunjong Song, Guangyan Cai, Zhuo Xu, Xiaochen Hu, Changxi Zheng, Yunzhu Li</strong></p>
<p>Robotic manipulation policies are advancing rapidly, but their direct evaluation in the real world remains costly, time-consuming, and difficult to reproduce, particularly for tasks involving deformable objects. Simulation provides a scalable and systematic alternative, yet existing simulators often fail to capture the coupled visual and physical complexity of soft-body interactions. We present a real-to-sim policy evaluation framework that constructs soft-body digital twins from real-world videos and renders robots, objects, and environments with photorealistic fidelity using 3D Gaussian Splatting. We validate our approach on representative deformable manipulation tasks, including plush toy packing, rope routing, and T-block pushing, demonstrating that simulated rollouts correlate strongly with real-world execution performance and reveal key behavioral patterns of learned policies. Our results suggest that combining physics-informed reconstruction with high-quality rendering enables reproducible, scalable, and accurate evaluation of robotic manipulation policies. Website: <a target="_blank" rel="noopener" href="https://real2sim-eval.github.io/">https://real2sim-eval.github.io/</a></p>
<blockquote>
<p>æœºå™¨äººæ“ä½œç­–ç•¥æ­£åœ¨è¿…é€Ÿå‘å±•ï¼Œä½†åœ¨ç°å®ä¸–ç•Œä¸­è¿›è¡Œç›´æ¥è¯„ä¼°çš„æˆæœ¬ä»ç„¶å¾ˆé«˜ï¼Œè€—æ—¶é•¿ï¼Œä¸”éš¾ä»¥é‡ç°ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ¶‰åŠå¯å˜å½¢ç‰©ä½“çš„ä»»åŠ¡ã€‚ä»¿çœŸæä¾›äº†ä¸€ç§å¯æ‰©å±•å’Œç³»ç»Ÿçš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç°æœ‰ä»¿çœŸå™¨é€šå¸¸æ— æ³•æ•æ‰è½¯ä½“äº¤äº’çš„è€¦åˆè§†è§‰å’Œç‰©ç†å¤æ‚æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»ç°å®åˆ°ä»¿çœŸçš„ç­–ç•¥è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç°å®ä¸–ç•Œçš„è§†é¢‘æ„å»ºè½¯ä½“æ•°å­—åŒèƒèƒï¼Œå¹¶ä½¿ç”¨ä¸‰ç»´é«˜æ–¯æº…å°„æŠ€æœ¯ä»¥é€¼çœŸçš„ä¿çœŸåº¦æ¸²æŸ“æœºå™¨äººã€ç‰©ä½“å’Œç¯å¢ƒã€‚æˆ‘ä»¬åœ¨å…¸å‹çš„å¯å˜å½¢æ“ä½œä»»åŠ¡ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬æ¯›ç»’ç©å…·åŒ…è£…ã€ç»³ç´¢è·¯ç”±å’ŒTå—æ¨åŠ¨ï¼Œè¯æ˜æ¨¡æ‹Ÿç»“æœä¸çœŸå®ä¸–ç•Œæ‰§è¡Œæ€§èƒ½é«˜åº¦ç›¸å…³ï¼Œå¹¶æ­ç¤ºäº†å­¦ä¹ ç­–ç•¥çš„å…³é”®è¡Œä¸ºæ¨¡å¼ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œç»“åˆç‰©ç†ä¿¡æ¯é‡å»ºå’Œé«˜å“è´¨æ¸²æŸ“ï¼Œå¯ä»¥å®ç°æœºå™¨äººæ“ä½œç­–ç•¥çš„å¯é‡å¤ã€å¯æ‰©å±•å’Œå‡†ç¡®è¯„ä¼°ã€‚ç½‘ç«™åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://real2sim-eval.github.io/%E3%80%82">https://real2sim-eval.github.io/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.04665v2">PDF</a> The first two authors contributed equally. Website: <a target="_blank" rel="noopener" href="https://real2sim-eval.github.io/">https://real2sim-eval.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>ç°å®ä¸–ç•Œä¸­æœºå™¨äººæ“ä½œç­–ç•¥çš„ç›´æ¥è¯„ä¼°æˆæœ¬é«˜æ˜‚ã€è€—æ—¶é•¿ä¸”éš¾ä»¥å¤ç°ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ¶‰åŠå¯å˜å½¢ç‰©ä½“çš„ä»»åŠ¡ã€‚ä»¿çœŸæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”ç³»ç»Ÿçš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç°æœ‰ä»¿çœŸå™¨é€šå¸¸æ— æ³•æ•æ‰è½¯ä½“äº¤äº’çš„å¤æ‚è§†è§‰å’Œç‰©ç†ç‰¹æ€§ã€‚æˆ‘ä»¬æå‡ºä¸€ç§ä»ç°å®åˆ°ä»¿çœŸçš„ç­–ç•¥è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡ç°å®è§†é¢‘æ„å»ºè½¯ä½“æ•°å­—å­ªç”Ÿï¼Œå¹¶ä½¿ç”¨3Dé«˜æ–¯Splattingä»¥é€¼çœŸåº¦æ¸²æŸ“æœºå™¨äººã€ç‰©ä½“å’Œç¯å¢ƒã€‚æˆ‘ä»¬åœ¨ä»£è¡¨æ€§çš„å¯å˜å½¢æ“ä½œä»»åŠ¡ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å¡«å……æ¯›ç»’ç©å…·ã€è·¯çº¿è§„åˆ’å’Œæ¨åŠ¨Tå½¢å—ï¼Œè¯æ˜ä»¿çœŸæ¨¡æ‹Ÿä¸çœŸå®ä¸–ç•Œæ‰§è¡Œæ€§èƒ½é«˜åº¦ç›¸å…³ï¼Œå¹¶æ­ç¤ºäº†å­¦ä¹ ç­–ç•¥çš„å…³é”®è¡Œä¸ºæ¨¡å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°å®ä¸–ç•Œä¸­æœºå™¨äººæ“ä½œç­–ç•¥çš„ç›´æ¥è¯„ä¼°å­˜åœ¨æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æˆæœ¬é«˜æ˜‚ã€è€—æ—¶é•¿å’Œéš¾ä»¥å¤ç°çš„é—®é¢˜ã€‚</li>
<li>ä»¿çœŸä¸ºæœºå™¨äººæ“ä½œç­–ç•¥è¯„ä¼°æä¾›äº†å¯æ‰©å±•ä¸”ç³»ç»Ÿçš„æ›¿ä»£æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰ä»¿çœŸå™¨åœ¨æ•æ‰è½¯ä½“äº¤äº’çš„å¤æ‚è§†è§‰å’Œç‰©ç†ç‰¹æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>æå‡ºä¸€ç§ä»ç°å®åˆ°ä»¿çœŸçš„ç­–ç•¥è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡ç°å®è§†é¢‘æ„å»ºè½¯ä½“æ•°å­—å­ªç”Ÿã€‚</li>
<li>ä½¿ç”¨3Dé«˜æ–¯SplattingæŠ€æœ¯ä»¥é€¼çœŸåº¦æ¸²æŸ“æœºå™¨äººã€ç‰©ä½“å’Œç¯å¢ƒã€‚</li>
<li>åœ¨å¤šä¸ªä»£è¡¨æ€§å¯å˜å½¢æ“ä½œä»»åŠ¡ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ä»¿çœŸæ¨¡æ‹Ÿä¸çœŸå®ä¸–ç•Œæ‰§è¡Œæ€§èƒ½é«˜åº¦ç›¸å…³ï¼Œå¯æ­ç¤ºå­¦ä¹ ç­–ç•¥çš„å…³é”®è¡Œä¸ºæ¨¡å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.04665">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1f6605c66cad19a6c377c92a1110a77b" align="middle">
<img src="https://picx.zhimg.com/v2-cc8ed4bee02ea56cb1ec219de14f00bd" align="middle">
<img src="https://picx.zhimg.com/v2-527c5cda029a28fbf1aaf9a072db123c" align="middle">
<img src="https://picx.zhimg.com/v2-77a51f9c300e7a4dab3ee7f36906bba1" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="GauSSmart-Enhanced-3D-Reconstruction-through-2D-Foundation-Models-and-Geometric-Filtering"><a href="#GauSSmart-Enhanced-3D-Reconstruction-through-2D-Foundation-Models-and-Geometric-Filtering" class="headerlink" title="GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering"></a>GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering</h2><p><strong>Authors:Alexander Valverde, Brian Xu, Yuyin Zhou, Meng Xu, Hongyun Wang</strong></p>
<p>Scene reconstruction has emerged as a central challenge in computer vision, with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting achieving remarkable progress. While Gaussian Splatting demonstrates strong performance on large-scale datasets, it often struggles to capture fine details or maintain realism in regions with sparse coverage, largely due to the inherent limitations of sparse 3D training data.   In this work, we propose GauSSmart, a hybrid method that effectively bridges 2D foundational models and 3D Gaussian Splatting reconstruction. Our approach integrates established 2D computer vision techniques, including convex filtering and semantic feature supervision from foundational models such as DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D segmentation priors and high-dimensional feature embeddings, our method guides the densification and refinement of Gaussian splats, improving coverage in underrepresented areas and preserving intricate structural details.   We validate our approach across three datasets, where GauSSmart consistently outperforms existing Gaussian Splatting in the majority of evaluated scenes. Our results demonstrate the significant potential of hybrid 2D-3D approaches, highlighting how the thoughtful combination of 2D foundational models with 3D reconstruction pipelines can overcome the limitations inherent in either approach alone.</p>
<blockquote>
<p>åœºæ™¯é‡å»ºå·²æˆä¸ºè®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯å–·æº…ç­‰æ–¹æ³•å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚è™½ç„¶é«˜æ–¯å–·æº…åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨ç¨€ç–è¦†ç›–çš„åŒºåŸŸæ•æ‰ç»†èŠ‚æˆ–ä¿æŒçœŸå®æ€§æ–¹é¢å¾€å¾€é‡åˆ°å›°éš¾ï¼Œè¿™å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ç”±äºç¨€ç–3Dè®­ç»ƒæ•°æ®çš„å›ºæœ‰å±€é™æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GauSSmartï¼Œè¿™æ˜¯ä¸€ç§æœ‰æ•ˆèåˆ2DåŸºç¡€æ¨¡å‹å’Œ3Dé«˜æ–¯å–·æº…é‡å»ºçš„æ··åˆæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é›†æˆäº†æˆç†Ÿçš„2Dè®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼ŒåŒ…æ‹¬å‡¸è¿‡æ»¤å™¨å’Œæ¥è‡ªDINOç­‰åŸºç¡€æ¨¡å‹çš„è¯­ä¹‰ç‰¹å¾ç›‘ç£ï¼Œä»¥å¢å¼ºåŸºäºé«˜æ–¯çš„åœºæ™¯é‡å»ºã€‚é€šè¿‡åˆ©ç”¨2Dåˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æŒ‡å¯¼é«˜æ–¯å–·æº…çš„åŠ å¯†å’Œç»†åŒ–ï¼Œæ”¹è¿›äº†æ¬ ä»£è¡¨åŒºåŸŸçš„è¦†ç›–ï¼Œå¹¶ä¿ç•™äº†å¤æ‚ç»“æ„ç»†èŠ‚ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒGauSSmartåœ¨å¤§å¤šæ•°è¯„ä¼°åœºæ™¯ä¸­å§‹ç»ˆä¼˜äºç°æœ‰é«˜æ–¯å–·æº…ã€‚æˆ‘ä»¬çš„ç»“æœå±•ç¤ºäº†æ··åˆ2D-3Dæ–¹æ³•çš„å·¨å¤§æ½œåŠ›ï¼Œçªå‡ºäº†å¦‚ä½•å°†2DåŸºç¡€æ¨¡å‹ä¸3Dé‡å»ºç®¡é“ç›¸ç»“åˆï¼Œä»¥å…‹æœå•ä¸€æ–¹æ³•çš„å›ºæœ‰å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.14270v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œåä¸ºGauSSmartï¼Œè¯¥æ–¹æ³•ç»“åˆäº†äºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´é«˜æ–¯æº…å°„é‡å»ºæŠ€æœ¯ã€‚é€šè¿‡å¼•å…¥äºŒç»´è®¡ç®—æœºè§†è§‰æŠ€æœ¯å’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼Œè¯¥æ–¹æ³•æ”¹å–„äº†é«˜æ–¯æº…å°„åœºæ™¯é‡å»ºçš„ç²¾ç»†åº¦å’Œé€¼çœŸåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€ç–æ•°æ®åŒºåŸŸã€‚ç»è¿‡ä¸‰ä¸ªæ•°æ®é›†çš„éªŒè¯ï¼ŒGauSSmartåœ¨å¤šæ•°åœºæ™¯ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„é«˜æ–¯æº…å°„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœºæ™¯é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼Œå·²æœ‰æ–¹æ³•å¦‚NeRFå’ŒGaussian Splattingå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>Gaussian Splattingåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ•è·ç»†èŠ‚å’Œä¿æŒç¨€ç–åŒºåŸŸçš„ç°å®æ„Ÿæ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>GauSSmartæ˜¯ä¸€ä¸ªæ–°çš„æ··åˆæ–¹æ³•ï¼Œç»“åˆäº†äºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´Gaussian Splattingé‡å»ºã€‚</li>
<li>GauSSmartåˆ©ç”¨äºŒç»´åˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼ŒæŒ‡å¯¼é«˜æ–¯æº…å°„çš„å¯†é›†åŒ–å’Œç²¾ç»†åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•æ”¹å–„äº†ç¨€ç–åŒºåŸŸçš„è¦†ç›–å¹¶ä¿ç•™äº†ç²¾ç»†çš„ç»“æ„ç»†èŠ‚ã€‚</li>
<li>åœ¨ä¸‰ä¸ªæ•°æ®é›†çš„éªŒè¯ä¸­ï¼ŒGauSSmartåœ¨å¤šæ•°åœºæ™¯ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„é«˜æ–¯æº…å°„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.14270">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-096a025266934d1ffe54f10e907580e5" align="middle">
<img src="https://picx.zhimg.com/v2-ce10a941529e531a97f079066de5d6d9" align="middle">
<img src="https://picx.zhimg.com/v2-5410135cd5e523629df20d961f072fa8" align="middle">
<img src="https://picx.zhimg.com/v2-cf51a1426d76308cf72aa9b8477ee678" align="middle">
<img src="https://picx.zhimg.com/v2-f6e9c22b512063663f3d8690d02ff8f4" align="middle">
<img src="https://picx.zhimg.com/v2-669fe0349215e6435d5059ca30fbf691" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="UniGS-Unified-Geometry-Aware-Gaussian-Splatting-for-Multimodal-Rendering"><a href="#UniGS-Unified-Geometry-Aware-Gaussian-Splatting-for-Multimodal-Rendering" class="headerlink" title="UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering"></a>UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering</h2><p><strong>Authors:Yusen Xie, Zhenmin Huang, Jianhao Jiao, Dimitrios Kanoulas, Jun Ma</strong></p>
<p>In this paper, we propose UniGS, a unified map representation and differentiable framework for high-fidelity multimodal 3D reconstruction based on 3D Gaussian Splatting. Our framework integrates a CUDA-accelerated rasterization pipeline capable of rendering photo-realistic RGB images, geometrically accurate depth maps, consistent surface normals, and semantic logits simultaneously. We redesign the rasterization to render depth via differentiable ray-ellipsoid intersection rather than using Gaussian centers, enabling effective optimization of rotation and scale attribute through analytic depth gradients. Furthermore, we derive the analytic gradient formulation for surface normal rendering, ensuring geometric consistency among reconstructed 3D scenes. To improve computational and storage efficiency, we introduce a learnable attribute that enables differentiable pruning of Gaussians with minimal contribution during training. Quantitative and qualitative experiments demonstrate state-of-the-art reconstruction accuracy across all modalities, validating the efficacy of our geometry-aware paradigm. Source code and multimodal viewer will be available on GitHub.</p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†UniGSï¼Œä¸€ç§åŸºäº3Dé«˜æ–¯Splattingçš„é«˜ä¿çœŸåº¦å¤šæ¨¡æ€3Dé‡å»ºçš„ç»Ÿä¸€åœ°å›¾è¡¨ç¤ºå’Œå¯åŒºåˆ†æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ¡†æ¶é›†æˆäº†ä¸€ä¸ªCUDAåŠ é€Ÿçš„æ¸²æŸ“ç®¡çº¿ï¼Œèƒ½å¤ŸåŒæ—¶å‘ˆç°é€¼çœŸçš„RGBå›¾åƒã€å‡ ä½•å‡†ç¡®çš„æ·±åº¦å›¾ã€ä¸€è‡´çš„é¢æœæ–¹å‘å’Œè¯­ä¹‰æ—¥å¿—ã€‚æˆ‘ä»¬é‡æ–°è®¾è®¡äº†æ¸²æŸ“ï¼Œé€šè¿‡å¯åŒºåˆ†çš„å°„çº¿ä¸æ¤­çƒäº¤ç‚¹æ¥å‘ˆç°æ·±åº¦ï¼Œè€Œä¸æ˜¯ä½¿ç”¨é«˜æ–¯ä¸­å¿ƒï¼Œé€šè¿‡è§£ææ·±åº¦æ¢¯åº¦æœ‰æ•ˆåœ°ä¼˜åŒ–æ—‹è½¬å’Œç¼©æ”¾å±æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¨å¯¼äº†è¡¨é¢æ³•çº¿æ¸²æŸ“çš„è§£ææ¢¯åº¦å…¬å¼ï¼Œç¡®ä¿é‡å»ºçš„3Dåœºæ™¯ä¹‹é—´çš„å‡ ä½•ä¸€è‡´æ€§ã€‚ä¸ºäº†æé«˜è®¡ç®—å’Œå­˜å‚¨æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„å±æ€§ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒæœŸé—´é€šè¿‡å¯åŒºåˆ†çš„ä¿®å‰ªå¯¹è´¡çŒ®æœ€å°çš„é«˜æ–¯è¿›è¡Œæœ€å°åŒ–å¤„ç†ã€‚å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼Œåœ¨æ‰€æœ‰æ¨¡æ€çš„é‡å»ºç²¾åº¦æ–¹é¢ï¼Œæˆ‘ä»¬çš„å‡ ä½•æ„ŸçŸ¥èŒƒå¼éƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚æºä»£ç å’Œå¤šæ¨¡æ€æŸ¥çœ‹å™¨å°†åœ¨GitHubä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.12174v2">PDF</a> </p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†UniGSæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº3Dé«˜æ–¯æ‹¼è´´çš„é«˜ä¿çœŸåº¦å¤šæ¨¡æ€3Dé‡å»ºçš„ç»Ÿä¸€åœ°å›¾è¡¨ç¤ºå’Œå¯åˆ†åŒ–æ¡†æ¶ã€‚å®ƒé›†æˆäº†CUDAåŠ é€Ÿçš„å…‰æ …åŒ–ç®¡é“ï¼Œèƒ½å¤ŸåŒæ—¶å‘ˆç°é€¼çœŸçš„RGBå›¾åƒã€å‡ ä½•å‡†ç¡®çš„æ·±åº¦å›¾ã€ä¸€è‡´çš„é¢æœæ–¹å‘å’Œè¯­ä¹‰å¯¹æ•°ã€‚é€šè¿‡å¯å¾®åˆ†çš„å°„çº¿ä¸æ¤­çƒäº¤ç‚¹è¿›è¡Œæ·±åº¦æ¸²æŸ“ï¼Œå®ç°äº†æ—‹è½¬å’Œè§„æ¨¡å±æ€§çš„æœ‰æ•ˆä¼˜åŒ–ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¸ºè¡¨é¢æ­£å¸¸æ¸²æŸ“æ¨å¯¼äº†åˆ†ææ¢¯åº¦å…¬å¼ï¼Œç¡®ä¿äº†é‡å»ºçš„3Dåœºæ™¯ä¹‹é—´çš„å‡ ä½•ä¸€è‡´æ€§ã€‚ä¸ºäº†æé«˜è®¡ç®—å’Œå­˜å‚¨æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¯å­¦ä¹ çš„å±æ€§ï¼Œå¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯åˆ†åŒ–åœ°åˆ é™¤è´¡çŒ®æœ€å°çš„Gaussiansã€‚å®éªŒè¯æ˜ï¼Œè¯¥å‡ ä½•æ„ŸçŸ¥æ¨¡å¼åœ¨å¤šæ¨¡æ€é‡å»ºæ–¹é¢å…·æœ‰æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UniGSæ¡†æ¶é›†æˆäº†CUDAåŠ é€Ÿçš„å…‰æ …åŒ–ç®¡é“ï¼Œå®ç°äº†å¤šç§è§†è§‰å±æ€§çš„åŒæ­¥å‘ˆç°ï¼ŒåŒ…æ‹¬RGBå›¾åƒã€æ·±åº¦å›¾ã€é¢æœæ–¹å‘å’Œè¯­ä¹‰å¯¹æ•°ã€‚</li>
<li>é‡‡ç”¨äº†åŸºäºå¯å¾®åˆ†å°„çº¿ä¸æ¤­çƒäº¤ç‚¹çš„æ·±åº¦æ¸²æŸ“æ–¹æ³•ï¼Œä¼˜åŒ–äº†æ—‹è½¬å’Œè§„æ¨¡å±æ€§ã€‚</li>
<li>æ¨å¯¼äº†è¡¨é¢æ­£å¸¸æ¸²æŸ“çš„åˆ†ææ¢¯åº¦å…¬å¼ï¼Œç¡®ä¿äº†é‡å»ºçš„3Dåœºæ™¯ä¹‹é—´çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>å¼•å…¥äº†å¯å­¦ä¹ çš„å±æ€§ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åˆ†åŒ–åœ°åˆ é™¤è´¡çŒ®å°çš„Gaussiansï¼Œæé«˜äº†è®¡ç®—å’Œå­˜å‚¨æ•ˆç‡ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šæ¨¡æ€é‡å»ºæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ã€‚</li>
<li>UniGSæ¡†æ¶æä¾›äº†æºç å’Œå¤šæ¨¡æ€æŸ¥çœ‹å™¨ï¼Œä¾¿äºå…¬ä¼—è®¿é—®å’Œå­¦ä¹ ã€‚</li>
<li>è¯¥æ¡†æ¶æœ‰åŠ©äºæ¨åŠ¨é«˜ä¿çœŸåº¦3Dé‡å»ºæŠ€æœ¯çš„å‘å±•ï¼Œåœ¨å›¾å½¢æ¸²æŸ“ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.12174">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0ffc343f8057df6316560cc09873d771" align="middle">
<img src="https://picx.zhimg.com/v2-fe014b0eae97552b99a3683acae61dfd" align="middle">
<img src="https://picx.zhimg.com/v2-473e5319fdcfce54cb95c8dcdd51a461" align="middle">
<img src="https://picx.zhimg.com/v2-ba1e86e47e8064ac3896b32dfb510804" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="SPHERE-Semantic-PHysical-Engaged-REpresentation-for-3D-Semantic-Scene-Completion"><a href="#SPHERE-Semantic-PHysical-Engaged-REpresentation-for-3D-Semantic-Scene-Completion" class="headerlink" title="SPHERE: Semantic-PHysical Engaged REpresentation for 3D Semantic Scene Completion"></a>SPHERE: Semantic-PHysical Engaged REpresentation for 3D Semantic Scene Completion</h2><p><strong>Authors:Zhiwen Yang, Yuxin Peng</strong></p>
<p>Camera-based 3D Semantic Scene Completion (SSC) is a critical task in autonomous driving systems, assessing voxel-level geometry and semantics for holistic scene perception. While existing voxel-based and plane-based SSC methods have achieved considerable progress, they struggle to capture physical regularities for realistic geometric details. On the other hand, neural reconstruction methods like NeRF and 3DGS demonstrate superior physical awareness, but suffer from high computational cost and slow convergence when handling large-scale, complex autonomous driving scenes, leading to inferior semantic accuracy. To address these issues, we propose the Semantic-PHysical Engaged REpresentation (SPHERE) for camera-based SSC, which integrates voxel and Gaussian representations for joint exploitation of semantic and physical information. First, the Semantic-guided Gaussian Initialization (SGI) module leverages dual-branch 3D scene representations to locate focal voxels as anchors to guide efficient Gaussian initialization. Then, the Physical-aware Harmonics Enhancement (PHE) module incorporates semantic spherical harmonics to model physical-aware contextual details and promote semantic-geometry consistency through focal distribution alignment, generating SSC results with realistic details. Extensive experiments and analyses on the popular SemanticKITTI and SSCBench-KITTI-360 benchmarks validate the effectiveness of SPHERE. The code is available at <a target="_blank" rel="noopener" href="https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025">https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025</a>.</p>
<blockquote>
<p>åŸºäºæ‘„åƒå¤´çš„ä¸‰ç»´è¯­ä¹‰åœºæ™¯è¡¥å…¨ï¼ˆSSCï¼‰æ˜¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ï¼Œå®ƒè¯„ä¼°ä½“ç´ çº§çš„å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ä»¥å®ç°å…¨æ™¯åœºæ™¯æ„ŸçŸ¥ã€‚å°½ç®¡ç°æœ‰çš„åŸºäºä½“ç´ å’ŒåŸºäºå¹³é¢çš„SSCæ–¹æ³•å·²ç»å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ï¼Œä½†å®ƒä»¬åœ¨æ•æ‰ç‰©ç†è§„å¾‹ä»¥å‘ˆç°é€¼çœŸçš„å‡ ä½•ç»†èŠ‚æ–¹é¢ä»æœ‰å›°éš¾ã€‚å¦ä¸€æ–¹é¢ï¼ŒåƒNeRFå’Œ3DGSè¿™æ ·çš„ç¥ç»é‡å»ºæ–¹æ³•è¡¨ç°å‡ºå“è¶Šçš„ç‰©ç†æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡ã€å¤æ‚çš„è‡ªåŠ¨é©¾é©¶åœºæ™¯æ—¶ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”æ”¶æ•›ç¼“æ…¢ï¼Œå¯¼è‡´è¯­ä¹‰ç²¾åº¦è¾ƒä½ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºåŸºäºæ‘„åƒå¤´çš„SSCçš„è¯­ä¹‰ç‰©ç†å‚ä¸è¡¨ç¤ºï¼ˆSPHEREï¼‰ï¼Œå®ƒç»“åˆäº†ä½“ç´ å’Œé«˜æ–¯è¡¨ç¤ºï¼Œä»¥è”åˆåˆ©ç”¨è¯­ä¹‰å’Œç‰©ç†ä¿¡æ¯ã€‚é¦–å…ˆï¼Œè¯­ä¹‰å¼•å¯¼çš„é«˜æ–¯åˆå§‹åŒ–ï¼ˆSGIï¼‰æ¨¡å—åˆ©ç”¨åŒåˆ†æ”¯ä¸‰ç»´åœºæ™¯è¡¨ç¤ºæ¥ç¡®å®šå…³é”®ä½“ç´ ä½œä¸ºé”šç‚¹æ¥å¼•å¯¼é«˜æ•ˆçš„é«˜æ–¯åˆå§‹åŒ–ã€‚ç„¶åï¼Œç‰©ç†æ„ŸçŸ¥çš„è°æ³¢å¢å¼ºï¼ˆPHEï¼‰æ¨¡å—ç»“åˆäº†è¯­ä¹‰çƒé¢è°æ³¢æ¥æ¨¡æ‹Ÿç‰©ç†æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡ç»†èŠ‚ï¼Œå¹¶é€šè¿‡ç„¦ç‚¹åˆ†å¸ƒå¯¹é½ä¿ƒè¿›è¯­ä¹‰å‡ ä½•ä¸€è‡´æ€§ï¼Œç”Ÿæˆå…·æœ‰é€¼çœŸç»†èŠ‚çš„SSCç»“æœã€‚åœ¨æµè¡Œçš„SemanticKITTIå’ŒSSCBench-KITTI-360åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒå’Œåˆ†æéªŒè¯äº†SPHEREçš„æœ‰æ•ˆæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11171v2">PDF</a> 10 pages, 6 figures, accepted by ACM MM 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é¢å‘è‡ªä¸»é©¾é©¶ç³»ç»Ÿçš„åŸºäºæ‘„åƒå¤´çš„ä¸‰ç»´è¯­ä¹‰åœºæ™¯è¡¥å…¨ï¼ˆSSCï¼‰ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•å¦‚åŸºäºä½“ç´ å’ŒåŸºäºå¹³é¢çš„æ–¹æ³•è™½æœ‰è¿›å±•ï¼Œä½†åœ¨æ•æ‰ç‰©ç†è§„å¾‹å’Œå‡ ä½•ç»†èŠ‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚ç¥ç»ç½‘ç»œé‡å»ºæ–¹æ³•å¦‚NeRFå’Œ3DGSè™½ç„¶å¯¹ç‰©ç†è§„å¾‹æœ‰è¾ƒå¥½æ„ŸçŸ¥ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡å¤æ‚åœºæ™¯æ—¶è®¡ç®—æˆæœ¬é«˜ã€æ”¶æ•›æ…¢ï¼Œå¯¼è‡´è¯­ä¹‰ç²¾åº¦ä¸è¶³ã€‚æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆä½“ç´ å’Œé«˜æ–¯è¡¨ç¤ºçš„è¯­ä¹‰ç‰©ç†èåˆè¡¨ç¤ºï¼ˆSPHEREï¼‰æ–¹æ³•ï¼Œé€šè¿‡è¯­ä¹‰å¼•å¯¼çš„é«˜æ–¯åˆå§‹åŒ–ï¼ˆSGIï¼‰æ¨¡å—ä¸ç‰©ç†æ„ŸçŸ¥çš„è°æ³¢å¢å¼ºï¼ˆPHEï¼‰æ¨¡å—ï¼Œè”åˆåˆ©ç”¨è¯­ä¹‰å’Œç‰©ç†ä¿¡æ¯ï¼Œå®ç°äº†æ›´çœŸå®ç»†èŠ‚çš„SSCç»“æœã€‚åœ¨SemanticKITTIå’ŒSSCBench-KITTI-360åŸºå‡†æµ‹è¯•é›†ä¸Šçš„å®éªŒéªŒè¯äº†SPHEREçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢å‘è‡ªä¸»é©¾é©¶ç³»ç»Ÿçš„æ‘„åƒå¤´ä¸‰ç»´è¯­ä¹‰åœºæ™¯è¡¥å…¨ï¼ˆSSCï¼‰ä»»åŠ¡å…³é”®æ€§åœ¨äºå¯¹åœºæ™¯è¿›è¡Œæ•´ä½“æ„ŸçŸ¥ã€‚</li>
<li>ç›®å‰å­˜åœ¨çš„ä½“ç´ å’ŒåŸºäºå¹³é¢çš„æ–¹æ³•è™½ç„¶å–å¾—è¿›å±•ï¼Œä½†åœ¨æ•æ‰ç‰©ç†è§„å¾‹å’Œå‡ ä½•ç»†èŠ‚æ–¹é¢ä»æœ‰ä¸è¶³ã€‚</li>
<li>ç¥ç»ç½‘ç»œé‡å»ºæ–¹æ³•å¦‚NeRFå’Œ3DGSåœ¨å¤„ç†å¤§è§„æ¨¡å¤æ‚åœºæ™¯æ—¶é¢ä¸´è®¡ç®—æˆæœ¬é«˜å’Œæ”¶æ•›æ…¢çš„é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„SPHEREæ–¹æ³•ç»“åˆäº†ä½“ç´ å’Œé«˜æ–¯è¡¨ç¤ºï¼Œé€šè¿‡SGIå’ŒPHEæ¨¡å—è”åˆåˆ©ç”¨è¯­ä¹‰å’Œç‰©ç†ä¿¡æ¯ã€‚</li>
<li>SPHEREæ–¹æ³•åœ¨SemanticKITTIå’ŒSSCBench-KITTI-360åŸºå‡†æµ‹è¯•é›†ä¸Šå–å¾—äº†æœ‰æ•ˆéªŒè¯ã€‚</li>
<li>ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11171">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-83353c7315d821eb5b4723920a8c0951" align="middle">
<img src="https://picx.zhimg.com/v2-0bc67af9a568fdf963c718222f16eb6a" align="middle">
<img src="https://picx.zhimg.com/v2-36710c5d06f8825c65944ecdbf41c210" align="middle">
<img src="https://picx.zhimg.com/v2-fed8f8aee9e81e701f7c5f99d1799302" align="middle">
<img src="https://picx.zhimg.com/v2-d73f7ea75551048ed008a399e07e53b6" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="X-Scene-Large-Scale-Driving-Scene-Generation-with-High-Fidelity-and-Flexible-Controllability"><a href="#X-Scene-Large-Scale-Driving-Scene-Generation-with-High-Fidelity-and-Flexible-Controllability" class="headerlink" title="X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability"></a>X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability</h2><p><strong>Authors:Yu Yang, Alan Liang, Jianbiao Mei, Yukai Ma, Yong Liu, Gim Hee Lee</strong></p>
<p>Diffusion models are advancing autonomous driving by enabling realistic data synthesis, predictive end-to-end planning, and closed-loop simulation, with a primary focus on temporally consistent generation. However, large-scale 3D scene generation requiring spatial coherence remains underexplored. In this paper, we present X-Scene, a novel framework for large-scale driving scene generation that achieves geometric intricacy, appearance fidelity, and flexible controllability. Specifically, X-Scene supports multi-granular control, including low-level layout conditioning driven by user input or text for detailed scene composition, and high-level semantic guidance informed by user intent and LLM-enriched prompts for efficient customization. To enhance geometric and visual fidelity, we introduce a unified pipeline that sequentially generates 3D semantic occupancy and corresponding multi-view images and videos, ensuring alignment and temporal consistency across modalities. We further extend local regions into large-scale scenes via consistency-aware outpainting, which extrapolates occupancy and images from previously generated areas to maintain spatial and visual coherence. The resulting scenes are lifted into high-quality 3DGS representations, supporting diverse applications such as simulation and scene exploration. Extensive experiments demonstrate that X-Scene substantially advances controllability and fidelity in large-scale scene generation, empowering data generation and simulation for autonomous driving.</p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡å®ç°çœŸå®æ•°æ®åˆæˆã€ç«¯åˆ°ç«¯é¢„æµ‹è§„åˆ’ä»¥åŠé—­ç¯æ¨¡æ‹Ÿï¼Œæ¨åŠ¨äº†è‡ªåŠ¨é©¾é©¶çš„å‘å±•ï¼Œå…¶ä¸»è¦èšç„¦äºæ—¶é—´ä¸€è‡´çš„ç”Ÿæˆã€‚ç„¶è€Œï¼Œéœ€è¦å¤§é‡ç©ºé—´è¿è´¯æ€§çš„å¤§è§„æ¨¡3Dåœºæ™¯ç”Ÿæˆä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†X-Sceneï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤§è§„æ¨¡é©¾é©¶åœºæ™¯ç”Ÿæˆçš„æ–°å‹æ¡†æ¶ï¼Œå®ç°äº†å‡ ä½•ç²¾ç»†åº¦ã€å¤–è§‚ä¿çœŸåº¦å’Œçµæ´»å¯æ§æ€§ã€‚å…·ä½“æ¥è¯´ï¼ŒX-Sceneæ”¯æŒå¤šç²’åº¦æ§åˆ¶ï¼ŒåŒ…æ‹¬ç”±ç”¨æˆ·è¾“å…¥æˆ–æ–‡æœ¬é©±åŠ¨çš„ä½çº§å¸ƒå±€æ¡ä»¶ï¼Œç”¨äºè¯¦ç»†çš„åœºæ™¯æ„å›¾ï¼Œä»¥åŠç”±ç”¨æˆ·æ„å›¾å’Œä¸°å¯Œçš„LLMæç¤ºå¼•å¯¼çš„é«˜çº§è¯­ä¹‰æŒ‡å¯¼ï¼Œä»¥å®ç°é«˜æ•ˆçš„å®šåˆ¶ã€‚ä¸ºäº†æé«˜å‡ ä½•å’Œè§†è§‰ä¿çœŸåº¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç»Ÿä¸€æµç¨‹ï¼Œè¯¥æµç¨‹æŒ‰é¡ºåºç”Ÿæˆ3Dè¯­ä¹‰å ç”¨å’Œç›¸åº”çš„å¤šè§†å›¾å›¾åƒå’Œè§†é¢‘ï¼Œç¡®ä¿è·¨æ¨¡å¼çš„å¯¹é½å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡ä¸€è‡´æ€§æ„ŸçŸ¥çš„å¤–æ¨ç»˜ç”»å°†å±€éƒ¨åŒºåŸŸæ‰©å±•åˆ°å¤§è§„æ¨¡åœºæ™¯ï¼Œä»å·²ç”Ÿæˆçš„åŒºåŸŸå¤–æ¨å ç”¨å’Œå›¾åƒï¼Œä»¥ç»´æŒç©ºé—´å’Œè§†è§‰è¿è´¯æ€§ã€‚ç”Ÿæˆçš„åœºæ™¯æå‡ä¸ºé«˜è´¨é‡çš„3DGSè¡¨ç¤ºï¼Œæ”¯æŒå¤šç§åº”ç”¨ï¼Œå¦‚æ¨¡æ‹Ÿå’Œåœºæ™¯æ¢ç´¢ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒX-Sceneåœ¨å¤§å‹åœºæ™¯ç”Ÿæˆçš„æ§åˆ¶æ€§å’Œä¿çœŸåº¦æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶çš„æ•°æ®ç”Ÿæˆå’Œæ¨¡æ‹Ÿæä¾›äº†åŠ¨åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.13558v2">PDF</a> Accepted by NeurIPS 2025, Project page at <a target="_blank" rel="noopener" href="https://x-scene.github.io/">https://x-scene.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†X-Sceneæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç”¨äºå¤§è§„æ¨¡é©¾é©¶åœºæ™¯ç”Ÿæˆï¼Œå®ç°äº†å‡ ä½•ç²¾ç»†åº¦ã€å¤–è§‚ä¿çœŸåº¦å’Œçµæ´»å¯æ§æ€§ã€‚å®ƒæ”¯æŒå¤šç²’åº¦æ§åˆ¶ï¼ŒåŒ…æ‹¬ä½çº§åˆ«å¸ƒå±€æ¡ä»¶å’Œé«˜çº§åˆ«è¯­ä¹‰æŒ‡å¯¼ã€‚é€šè¿‡ç»Ÿä¸€ç®¡é“ç”Ÿæˆ3Dè¯­ä¹‰å ç”¨å’Œå¯¹åº”çš„å¤šè§†è§’å›¾åƒå’Œè§†é¢‘ï¼Œç¡®ä¿è·¨æ¨¡æ€çš„æ—¶ç©ºä¸€è‡´æ€§ã€‚é€šè¿‡ä¸€è‡´æ€§æ„ŸçŸ¥çš„å¤–æ¨æŠ€æœ¯ï¼Œå°†å±€éƒ¨åŒºåŸŸæ‰©å±•åˆ°å¤§è§„æ¨¡åœºæ™¯ï¼Œç»´æŒç©ºé—´å’Œè§†è§‰è¿è´¯æ€§ã€‚æœ€ç»ˆåœºæ™¯è½¬åŒ–ä¸ºé«˜è´¨é‡çš„ä¸‰ç»´å‡ ä½•è¡¨é¢åœºæ™¯ï¼ˆ3DGSï¼‰ï¼Œæ”¯æŒä»¿çœŸå’Œåœºæ™¯æ¢ç´¢ç­‰å¤šç§åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>X-Sceneæ¡†æ¶ç”¨äºå¤§è§„æ¨¡é©¾é©¶åœºæ™¯ç”Ÿæˆï¼Œå®ç°äº†å‡ ä½•ç²¾ç»†åº¦ã€å¤–è§‚ä¿çœŸåº¦å’Œçµæ´»å¯æ§æ€§ã€‚</li>
<li>æ”¯æŒå¤šç²’åº¦æ§åˆ¶ï¼ŒåŒ…æ‹¬ä½çº§åˆ«å¸ƒå±€æ¡ä»¶å’Œé«˜çº§åˆ«è¯­ä¹‰æŒ‡å¯¼ï¼Œå¯é€šè¿‡ç”¨æˆ·è¾“å…¥æˆ–æ–‡æœ¬è¿›è¡Œè¯¦ç»†çš„åœºæ™¯æ„å›¾ã€‚</li>
<li>é€šè¿‡ç»Ÿä¸€ç®¡é“ç”Ÿæˆ3Dè¯­ä¹‰å ç”¨å’Œå¯¹åº”çš„å¤šè§†è§’å›¾åƒå’Œè§†é¢‘ï¼Œç¡®ä¿ä¸åŒæ¨¡æ€ä¹‹é—´çš„å¯¹é½å’Œæ—¶ç©ºä¸€è‡´æ€§ã€‚</li>
<li>é‡‡ç”¨ä¸€è‡´æ€§æ„ŸçŸ¥çš„å¤–æ¨æŠ€æœ¯ï¼Œå°†å±€éƒ¨åŒºåŸŸæ‰©å±•åˆ°å¤§è§„æ¨¡åœºæ™¯ï¼Œä¿æŒç©ºé—´å’Œè§†è§‰è¿è´¯æ€§ã€‚</li>
<li>æœ€ç»ˆåœºæ™¯è½¬åŒ–ä¸ºé«˜è´¨é‡çš„ä¸‰ç»´å‡ ä½•è¡¨é¢åœºæ™¯ï¼ˆ3DGSï¼‰ï¼Œæ”¯æŒä»¿çœŸã€åœºæ™¯æ¢ç´¢ç­‰å¤šç§åº”ç”¨ã€‚</li>
<li>X-Sceneæ˜¾è‘—æé«˜äº†å¤§è§„æ¨¡åœºæ™¯ç”Ÿæˆçš„å¯æ§æ€§å’Œä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.13558">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4f595e93afbe17221642435cffe946de" align="middle">
<img src="https://picx.zhimg.com/v2-b71b1f57101c51c3e2f846f7df3ab369" align="middle">
<img src="https://picx.zhimg.com/v2-fe485b66076e835f623113e85b5e7718" align="middle">
<img src="https://picx.zhimg.com/v2-91b37f74f7dd4cb0bebe647f006eb92c" align="middle">
<img src="https://picx.zhimg.com/v2-c15f8fd76dd096c2a3653dfe513808fe" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="ELECTRA-A-Cartesian-Network-for-3D-Charge-Density-Prediction-with-Floating-Orbitals"><a href="#ELECTRA-A-Cartesian-Network-for-3D-Charge-Density-Prediction-with-Floating-Orbitals" class="headerlink" title="ELECTRA: A Cartesian Network for 3D Charge Density Prediction with Floating Orbitals"></a>ELECTRA: A Cartesian Network for 3D Charge Density Prediction with Floating Orbitals</h2><p><strong>Authors:Jonas Elsborg, Luca Thiede, AlÃ¡n Aspuru-Guzik, Tejs Vegge, Arghya Bhowmik</strong></p>
<p>We present the Electronic Tensor Reconstruction Algorithm (ELECTRA) - an equivariant model for predicting electronic charge densities using floating orbitals. Floating orbitals are a long-standing concept in the quantum chemistry community that promises more compact and accurate representations by placing orbitals freely in space, as opposed to centering all orbitals at the position of atoms. Finding the ideal placement of these orbitals requires extensive domain knowledge, though, which thus far has prevented widespread adoption. We solve this in a data-driven manner by training a Cartesian tensor network to predict the orbital positions along with orbital coefficients. This is made possible through a symmetry-breaking mechanism that is used to learn position displacements with lower symmetry than the input molecule while preserving the rotation equivariance of the charge density itself. Inspired by recent successes of Gaussian Splatting in representing densities in space, we are using Gaussian orbitals and predicting their weights and covariance matrices. Our method achieves a state-of-the-art balance between computational efficiency and predictive accuracy on established benchmarks. Furthermore, ELECTRA is able to lower the compute time required to arrive at converged DFT solutions - initializing calculations using our predicted densities yields an average 50.72 % reduction in self-consistent field (SCF) iterations on unseen molecules.</p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ç”µå­å¼ é‡é‡å»ºç®—æ³•ï¼ˆELECTRAï¼‰â€”â€”ä¸€ç§ä½¿ç”¨æµ®åŠ¨è½¨é“é¢„æµ‹ç”µå­ç”µè·å¯†åº¦çš„ç­‰ä»·æ¨¡å‹ã€‚æµ®åŠ¨è½¨é“æ˜¯é‡å­åŒ–å­¦ç•Œé•¿æœŸå­˜åœ¨çš„ä¸€ä¸ªæ¦‚å¿µï¼Œå®ƒé€šè¿‡è®©è½¨é“åœ¨ç©ºé—´ä¸­è‡ªç”±æ”¾ç½®ï¼Œè€Œä¸æ˜¯å°†æ‰€æœ‰è½¨é“å®šä½åœ¨åŸå­ä½ç½®ï¼Œä»è€Œæä¾›æ›´ç´§å‡‘å’Œå‡†ç¡®çš„è¡¨ç¤ºã€‚ç„¶è€Œï¼Œæ‰¾åˆ°è¿™äº›è½¨é“çš„ç†æƒ³ä½ç½®éœ€è¦å¤§é‡çš„ä¸“ä¸šçŸ¥è¯†ï¼Œè¿™è¿„ä»Šä¸ºæ­¢é˜»ç¢äº†å…¶å¹¿æ³›é‡‡ç”¨ã€‚æˆ‘ä»¬é€šè¿‡è®­ç»ƒç¬›å¡å°”å¼ é‡ç½‘ç»œæ¥é¢„æµ‹è½¨é“ä½ç½®å’Œè½¨é“ç³»æ•°ï¼Œä»¥æ•°æ®é©±åŠ¨çš„æ–¹å¼è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚è¿™æ˜¯é€šè¿‡ä¸€ç§å¯¹ç§°ç ´åæœºåˆ¶å®ç°çš„ï¼Œè¯¥æœºåˆ¶ç”¨äºå­¦ä¹ å…·æœ‰æ¯”è¾“å…¥åˆ†å­æ›´ä½å¯¹ç§°æ€§çš„ä½ç½®ä½ç§»ï¼ŒåŒæ—¶ä¿æŒç”µè·å¯†åº¦æœ¬èº«çš„æ—‹è½¬ç­‰ä»·æ€§ã€‚å—é«˜æ–¯æ‘Šé“ºåœ¨ç©ºé—´å¯†åº¦è¡¨ç¤ºæ–¹é¢è¿‘æœŸæˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯è½¨é“å¹¶é¢„æµ‹å…¶æƒé‡å’Œåæ–¹å·®çŸ©é˜µã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹ç²¾åº¦ä¹‹é—´çš„æœ€æ–°å¹³è¡¡ã€‚æ­¤å¤–ï¼ŒELECTRAèƒ½å¤Ÿé™ä½è¾¾åˆ°æ”¶æ•›çš„DFTè§£å†³æ–¹æ¡ˆæ‰€éœ€çš„è®¡ç®—æ—¶é—´â€”â€”ä½¿ç”¨æˆ‘ä»¬é¢„æµ‹çš„å¯†åº¦åˆå§‹åŒ–è®¡ç®—ï¼Œåœ¨æœªè§è¿‡çš„åˆ†å­ä¸Šå¹³å‡å‡å°‘äº†è‡ªæ´½åœºï¼ˆSCFï¼‰è¿­ä»£çš„50.72%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08305v3">PDF</a> 10 pages, 4 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Electronic Tensor Reconstruction Algorithmï¼ˆELECTRAï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æµ®åŠ¨è½¨é“é¢„æµ‹ç”µå­ç”µè·å¯†åº¦ã€‚æµ®åŠ¨è½¨é“æ˜¯é‡å­åŒ–å­¦é¢†åŸŸé•¿æœŸå­˜åœ¨çš„æ¦‚å¿µï¼Œé€šè¿‡è‡ªç”±æ”¾ç½®è½¨é“äºç©ºé—´ä¸­ï¼Œæä¾›æ›´ä¸ºç´§å‡‘å’Œå‡†ç¡®çš„è¡¨ç¤ºã€‚ELECTRAé€šè¿‡æ•°æ®é©±åŠ¨æ–¹å¼è§£å†³ç†æƒ³è½¨é“ä½ç½®çš„é—®é¢˜ï¼Œè®­ç»ƒç¬›å¡å°”å¼ é‡ç½‘ç»œé¢„æµ‹è½¨é“ä½ç½®å’Œè½¨é“ç³»æ•°ã€‚æ­¤æ¨¡å‹é€šè¿‡å¯¹ç§°ç ´åæœºåˆ¶å®ç°ä½ç½®é¢„æµ‹ï¼ŒåŒæ—¶ä¿æŒç”µè·å¯†åº¦çš„æ—‹è½¬ç­‰ä»·æ€§ã€‚ä½¿ç”¨é«˜æ–¯splatæ–¹æ³•è¡¨ç¤ºç©ºé—´å¯†åº¦ï¼Œä½¿ç”¨é«˜æ–¯è½¨é“å¹¶é¢„æµ‹å…¶æƒé‡å’Œåæ–¹å·®çŸ©é˜µã€‚ELECTRAåœ¨è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹å‡†ç¡®æ€§æ–¹é¢è¾¾åˆ°æœ€ä½³å¹³è¡¡ï¼Œå¹¶ä¸”èƒ½é™ä½DFTè§£å†³æ–¹æ¡ˆçš„è®¡ç®—æ—¶é—´ï¼Œä½¿ç”¨å…¶é¢„æµ‹çš„å¯†åº¦åˆå§‹åŒ–è®¡ç®—ï¼Œåœ¨æœªè§è¿‡çš„åˆ†å­ä¸Šå¹³å‡å‡å°‘50.72%çš„è‡ªæ´½åœºè¿­ä»£æ—¶é—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ELECTRAæ¨¡å‹åˆ©ç”¨æµ®åŠ¨è½¨é“é¢„æµ‹ç”µå­ç”µè·å¯†åº¦ï¼Œæä¾›æ›´ä¸ºå‡†ç¡®å’Œç´§å‡‘çš„è¡¨ç¤ºã€‚</li>
<li>é€šè¿‡æ•°æ®é©±åŠ¨æ–¹å¼æ‰¾åˆ°ç†æƒ³è½¨é“ä½ç½®ã€‚</li>
<li>ä½¿ç”¨ç¬›å¡å°”å¼ é‡ç½‘ç»œè¿›è¡Œé¢„æµ‹ï¼ŒåŒ…æ‹¬è½¨é“ä½ç½®å’Œè½¨é“ç³»æ•°ã€‚</li>
<li>é‡‡ç”¨å¯¹ç§°ç ´åæœºåˆ¶ä»¥å­¦ä¹ ä½ç½®ä½ç§»ï¼ŒåŒæ—¶ä¿æŒç”µè·å¯†åº¦çš„æ—‹è½¬ç­‰ä»·æ€§ã€‚</li>
<li>ç»“åˆé«˜æ–¯splatæ–¹æ³•è¡¨ç¤ºå¯†åº¦ï¼Œä½¿ç”¨é«˜æ–¯è½¨é“å¹¶é¢„æµ‹å…¶æƒé‡å’Œåæ–¹å·®çŸ©é˜µã€‚</li>
<li>ELECTRAåœ¨è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹å‡†ç¡®æ€§æ–¹é¢è¡¨ç°å“è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08305">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c8bb507e97bb1baabdc4a327a133076" align="middle">
<img src="https://picx.zhimg.com/v2-2c0f2e2d16907a8b56fadc5b4da01793" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Feature-EndoGaussian-Feature-Distilled-Gaussian-Splatting-in-Surgical-Deformable-Scene-Reconstruction"><a href="#Feature-EndoGaussian-Feature-Distilled-Gaussian-Splatting-in-Surgical-Deformable-Scene-Reconstruction" class="headerlink" title="Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction"></a>Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction</h2><p><strong>Authors:Kai Li, Junhao Wang, William Han, Ding Zhao</strong></p>
<p>Minimally invasive surgery (MIS) requires high-fidelity, real-time visual feedback of dynamic and low-texture surgical scenes. To address these requirements, we introduce FeatureEndo-4DGS (FE-4DGS), the first real time pipeline leveraging feature-distilled 4D Gaussian Splatting for simultaneous reconstruction and semantic segmentation of deformable surgical environments. Unlike prior feature-distilled methods restricted to static scenes, and existing 4D approaches that lack semantic integration, FE-4DGS seamlessly leverages pre-trained 2D semantic embeddings to produce a unified 4D representation-where semantics also deform with tissue motion. This unified approach enables the generation of real-time RGB and semantic outputs through a single, parallelized rasterization process. Despite the additional complexity from feature distillation, FE-4DGS sustains real-time rendering (61 FPS) with a compact footprint, achieves state-of-the-art rendering fidelity on EndoNeRF (39.1 PSNR) and SCARED (27.3 PSNR), and delivers competitive EndoVis18 segmentation, matching or exceeding strong 2D baselines for binary segmentation tasks (0.93 DSC) and remaining competitive for multi-label segmentation (0.77 DSC).</p>
<blockquote>
<p>å¾®åˆ›æ‰‹æœ¯ï¼ˆMISï¼‰éœ€è¦åŠ¨æ€ä¸”ä½çº¹ç†æ‰‹æœ¯åœºæ™¯çš„é«˜ä¿çœŸå®æ—¶è§†è§‰åé¦ˆã€‚ä¸ºè§£å†³è¿™ä¸€éœ€æ±‚ï¼Œæˆ‘ä»¬æ¨å‡ºäº†FeatureEndo-4DGSï¼ˆFE-4DGSï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªå®æ—¶ç®¡é“ï¼Œåˆ©ç”¨ç‰¹å¾è’¸é¦çš„4Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼Œå¯¹å¯å˜å½¢æ‰‹æœ¯ç¯å¢ƒè¿›è¡ŒåŒæ­¥é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²ã€‚ä¸åŒäºä»¥å¾€ä»…é™äºé™æ€åœºæ™¯çš„ç‰¹å¾è’¸é¦æ–¹æ³•ï¼Œä»¥åŠç¼ºä¹è¯­ä¹‰æ•´åˆçš„ç°æœ‰4Dæ–¹æ³•ï¼ŒFE-4DGSæ— ç¼åˆ©ç”¨é¢„è®­ç»ƒçš„2Dè¯­ä¹‰åµŒå…¥ï¼Œç”Ÿæˆä¸€ä¸ªç»Ÿä¸€çš„4Dè¡¨ç¤ºï¼Œå…¶ä¸­è¯­ä¹‰ä¹Ÿéšç»„ç»‡è¿åŠ¨è€Œå˜å½¢ã€‚è¿™ä¸€ç»Ÿä¸€çš„æ–¹æ³•é€šè¿‡å•ä¸€çš„å¹¶è¡Œæ …æ ¼åŒ–è¿‡ç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå®æ—¶çš„RGBå’Œè¯­ä¹‰è¾“å‡ºã€‚å°½ç®¡ç‰¹å¾è’¸é¦å¢åŠ äº†å¤æ‚æ€§ï¼Œä½†FE-4DGSä»èƒ½ä¿æŒå®æ—¶æ¸²æŸ“ï¼ˆ61 FPSï¼‰ï¼Œåœ¨EndoNeRFï¼ˆ39.1 PSNRï¼‰å’ŒSCAREDï¼ˆ27.3 PSNRï¼‰ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ¸²æŸ“ä¿çœŸåº¦ï¼Œå¹¶ä¸”åœ¨EndoVis18åˆ†å‰²æ–¹é¢è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå¯¹äºäºŒå…ƒåˆ†å‰²ä»»åŠ¡ï¼ˆ0.93 DSCï¼‰åŒ¹é…æˆ–è¶…è¿‡å¼ºå¤§çš„2DåŸºå‡†çº¿ï¼Œå¹¶åœ¨å¤šæ ‡ç­¾åˆ†å‰²æ–¹é¢ä¿æŒç«äº‰åŠ›ï¼ˆ0.77 DSCï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06161v2">PDF</a> 17 pages, 5 figures; Accepted to ML4H 2025</p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£ç‰¹å¾è’¸é¦4Dé«˜æ–¯æ‰©å±•æŠ€æœ¯ï¼Œå®ç°å®æ—¶é‡å»ºä¸åŠ¨æ€æ‰‹æœ¯ç¯å¢ƒè¯­ä¹‰åˆ†å‰²ã€‚åˆ©ç”¨é¢„è®­ç»ƒ2Dè¯­ä¹‰åµŒå…¥ç”Ÿæˆç»Ÿä¸€4Dè¡¨ç¤ºï¼Œæ”¯æŒå®æ—¶æ¸²æŸ“ä¸é«˜è´¨é‡æ¸²æŸ“æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç‰¹å¾è’¸é¦æŠ€æœ¯åº”ç”¨äºæ‰‹æœ¯åœºæ™¯ï¼Œå®ç°é«˜ä¿çœŸå®æ—¶åé¦ˆã€‚</li>
<li>FeatureEndo-4DGSç³»ç»Ÿåˆ©ç”¨ç‰¹å¾è’¸é¦çš„4Dé«˜æ–¯æ‰©å±•æŠ€æœ¯ï¼Œæ»¡è¶³å¾®åˆ›æ‰‹æœ¯å¯¹åŠ¨æ€ã€ä½çº¹ç†åœºæ™¯çš„è§†è§‰åé¦ˆéœ€æ±‚ã€‚</li>
<li>ç³»ç»Ÿåˆ©ç”¨é¢„è®­ç»ƒçš„2Dè¯­ä¹‰åµŒå…¥ï¼Œç”Ÿæˆç»Ÿä¸€çš„4Dè¡¨ç¤ºï¼Œå®ç°è¯­ä¹‰ä¿¡æ¯çš„å®æ—¶å˜å½¢ä¸åœºæ™¯é‡å»ºã€‚</li>
<li>è¯¥ç³»ç»Ÿé‡‡ç”¨å¹¶è¡Œæ …æ ¼åŒ–æŠ€æœ¯ï¼Œç”Ÿæˆå®æ—¶RGBå’Œè¯­ä¹‰è¾“å‡ºã€‚</li>
<li>ç‰¹å¾è’¸é¦æŠ€æœ¯è™½å¢åŠ å¤æ‚æ€§ï¼Œä½†FeatureEndo-4DGSç³»ç»Ÿä»ç»´æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼ˆæ¯ç§’æ¸²æŸ“å¸§æ•°è¾¾61å¸§ï¼‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06161">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c07c44c9831a869204343d46968a75ab" align="middle">
<img src="https://picx.zhimg.com/v2-354dc93fb5885cb34c9d322ff9bfe903" align="middle">
<img src="https://picx.zhimg.com/v2-f1aeda3fc7b4809f7ac23aca85ecd687" align="middle">
<img src="https://picx.zhimg.com/v2-5464137b6eea33943fd4f621e890c5fc" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-16/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-16/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-16/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-8dcca5f3a09cad2c41089af9d662173d" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-16  Mip-NeWRF Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-16/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fc9502ff0ef34b2b2fe3d95c0d9561fd" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-16  Dynamic Avatar-Scene Rendering from Human-centric Context
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33297.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
