<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-16  Mip-NeWRF Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-8dcca5f3a09cad2c41089af9d662173d')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    43 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-16-æ›´æ–°"><a href="#2025-11-16-æ›´æ–°" class="headerlink" title="2025-11-16 æ›´æ–°"></a>2025-11-16 æ›´æ–°</h1><h2 id="Mip-NeWRF-Enhanced-Wireless-Radiance-Field-with-Hybrid-Encoding-for-Channel-Prediction"><a href="#Mip-NeWRF-Enhanced-Wireless-Radiance-Field-with-Hybrid-Encoding-for-Channel-Prediction" class="headerlink" title="Mip-NeWRF: Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction"></a>Mip-NeWRF: Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction</h2><p><strong>Authors:Yulin Fu, Jiancun Fan, Shiyu Zhai, Zhibo Duan, Jie Luo</strong></p>
<p>Recent work on wireless radiance fields represents a promising deep learning approach for channel prediction, however, in complex environments these methods still exhibit limited robustness, slow convergence, and modest accuracy due to insufficiently refined modeling. To address this issue, we propose Mip-NeWRF, a physics-informed neural framework for accurate indoor channel prediction based on sparse channel measurements. The framework operates in a ray-based pipeline with coarse-to-fine importance sampling: frustum samples are encoded, processed by a shared multilayer perceptron (MLP), and the outputs are synthesized into the channel frequency response (CFR). Prior to MLP input, Mip-NeWRF performs conical-frustum sampling and applies a scale-consistent hybrid positional encoding to each frustum. The scale-consistent normalization aligns positional encodings across scene scales, while the hybrid encoding supplies both scale-robust, low-frequency stability to accelerate convergence and fine spatial detail to improve accuracy. During training, a curriculum learning schedule is applied to stabilize and accelerate convergence of the shared MLP. During channel synthesis, the MLP outputs, including predicted virtual transmitter presence probabilities and amplitudes, are combined with modeled pathloss and surface interaction attenuation to enhance physical fidelity and further improve accuracy. Simulation results demonstrate the effectiveness of the proposed approach: in typical scenarios, the normalized mean square error (NMSE) is reduced by 14.3 dB versus state-of-the-art baselines.</p>
<blockquote>
<p>è¿‘æœŸå…³äºæ— çº¿è¾å°„åœºçš„å·¥ä½œä»£è¡¨äº†ä¸€ç§ç”¨äºä¿¡é“é¢„æµ‹çš„æ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œåœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œè¿™äº›æ–¹æ³•ä»è¡¨ç°å‡ºæœ‰é™çš„ç¨³å¥æ€§ã€ç¼“æ…¢çš„æ”¶æ•›é€Ÿåº¦å’Œé€‚ä¸­çš„å‡†ç¡®æ€§ï¼Œè¿™æ˜¯ç”±äºå»ºæ¨¡ä¸å¤Ÿç²¾ç»†æ‰€å¯¼è‡´çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Mip-NeWRFï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç¨€ç–ä¿¡é“æµ‹é‡çš„å®¤å†…ä¿¡é“é¢„æµ‹å‡†ç¡®æ€§çš„ç‰©ç†å¯å‘ç¥ç»ç½‘ç»œæ¡†æ¶ã€‚è¯¥æ¡†æ¶ä»¥åŸºäºå°„çº¿çš„ç®¡é“è¿è¡Œï¼Œé‡‡ç”¨ä»ç²—åˆ°ç»†çš„é‡è¦æ€§é‡‡æ ·ï¼šæˆªæ–­æ ·æœ¬è¢«ç¼–ç ï¼Œé€šè¿‡å…±äº«çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰è¿›è¡Œå¤„ç†ï¼Œè¾“å‡ºè¢«åˆæˆæˆä¿¡é“é¢‘ç‡å“åº”ï¼ˆCFRï¼‰ã€‚åœ¨MLPè¾“å…¥ä¹‹å‰ï¼ŒMip-NeWRFæ‰§è¡Œé”¥å½¢æˆªæ–­é‡‡æ ·å¹¶ä¸”å¯¹æ¯ä¸ªæˆªæ–­åº”ç”¨å°ºåº¦ä¸€è‡´çš„æ··åˆä½ç½®ç¼–ç ã€‚å°ºåº¦ä¸€è‡´çš„å½’ä¸€åŒ–ä½¿åœºæ™¯å°ºåº¦ä¸Šçš„ä½ç½®ç¼–ç å¯¹é½ï¼Œè€Œæ··åˆç¼–ç æä¾›äº†æ—¢ç¨³å¥äºå°ºåº¦åˆåŠ é€Ÿæ”¶æ•›çš„ä½é¢‘ç¨³å®šæ€§ï¼Œä»¥åŠæé«˜å‡†ç¡®æ€§çš„ç²¾ç»†ç©ºé—´ç»†èŠ‚ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåº”ç”¨è¯¾ç¨‹å­¦ä¹ æ—¶é—´è¡¨ä»¥ç¨³å®šå’ŒåŠ é€Ÿå…±äº«MLPçš„æ”¶æ•›ã€‚åœ¨ä¿¡é“åˆæˆè¿‡ç¨‹ä¸­ï¼ŒMLPçš„è¾“å‡ºï¼ŒåŒ…æ‹¬é¢„æµ‹çš„è™šæ‹Ÿå‘å°„æœºå­˜åœ¨æ¦‚ç‡å’ŒæŒ¯å¹…ï¼Œä¸å»ºæ¨¡çš„è·¯å¾„æŸè€—å’Œè¡¨é¢äº¤äº’è¡°å‡ç›¸ç»“åˆï¼Œä»¥å¢å¼ºç‰©ç†ä¿çœŸåº¦å’Œè¿›ä¸€æ­¥æé«˜å‡†ç¡®æ€§ã€‚ä»¿çœŸç»“æœè¡¨æ˜æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼šåœ¨å…¸å‹åœºæ™¯ä¸­ï¼Œä¸æœ€æ–°æŠ€æœ¯åŸºå‡†ç›¸æ¯”ï¼Œå½’ä¸€åŒ–å‡æ–¹è¯¯å·®ï¼ˆNMSEï¼‰é™ä½äº†14.3 dBã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09150v1">PDF</a> 13 pages, 12 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç‰©ç†ä¿¡æ¯çš„ç¥ç»ç½‘ç»œæ¡†æ¶Mip-NeWRFï¼Œç”¨äºåŸºäºç¨€ç–ä¿¡é“æµ‹é‡çš„å®¤å†…ä¿¡é“å‡†ç¡®é¢„æµ‹ã€‚é€šè¿‡é‡‡ç”¨åŸºäºå°„çº¿çš„å¤„ç†ç®¡é“å’Œç²—ç»†é‡è¦æ€§é‡‡æ ·ï¼Œç»“åˆå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰è¿›è¡Œç¼–ç å¤„ç†ï¼Œå¹¶åˆæˆä¿¡é“é¢‘ç‡å“åº”ï¼ˆCFRï¼‰ã€‚æ¡†æ¶ä¸­çš„å…³é”®æ­¥éª¤åŒ…æ‹¬é”¥å½¢æˆªä½“é‡‡æ ·ã€å°ºåº¦ä¸€è‡´æ··åˆä½ç½®ç¼–ç ã€è¯¾ç¨‹å­¦ä¹ è°ƒåº¦å’Œä¿¡é“åˆæˆï¼Œæ—¨åœ¨æé«˜å¤æ‚ç¯å¢ƒä¸‹çš„ä¿¡é“é¢„æµ‹å‡†ç¡®æ€§ã€æ”¶æ•›é€Ÿåº¦å’Œé²æ£’æ€§ã€‚æ¨¡æ‹Ÿç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¸å‹åœºæ™¯ä¸‹çš„å½’ä¸€åŒ–å‡æ–¹è¯¯å·®ï¼ˆNMSEï¼‰ç›¸è¾ƒäºç°æœ‰æŠ€æœ¯é™ä½äº†14.3 dBã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Mip-NeWRFæ˜¯ä¸€ä¸ªåŸºäºç‰©ç†ä¿¡æ¯çš„ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºå®¤å†…ä¿¡é“é¢„æµ‹ã€‚</li>
<li>å®ƒé‡‡ç”¨åŸºäºå°„çº¿çš„å¤„ç†ç®¡é“å’Œç²—ç»†é‡è¦æ€§é‡‡æ ·ï¼Œä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚</li>
<li>Mip-NeWRFç»“åˆå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰è¿›è¡Œç¼–ç å¤„ç†ï¼Œå¹¶åˆæˆä¿¡é“é¢‘ç‡å“åº”ï¼ˆCFRï¼‰ã€‚</li>
<li>é”¥å½¢æˆªä½“é‡‡æ ·å’Œå°ºåº¦ä¸€è‡´æ··åˆä½ç½®ç¼–ç çš„å¼•å…¥ï¼Œå¢å¼ºäº†æ¡†æ¶çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>é€šè¿‡åº”ç”¨è¯¾ç¨‹å­¦ä¹ è°ƒåº¦ï¼Œç¨³å®šå¹¶åŠ é€Ÿäº†MLPçš„æ”¶æ•›ã€‚</li>
<li>MLPè¾“å‡ºä¸è·¯å¾„æŸè€—å’Œè¡¨é¢äº¤äº’è¡°å‡æ¨¡å‹çš„ç»“åˆï¼Œæé«˜äº†ç‰©ç†çœŸå®æ€§å’Œé¢„æµ‹ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09150">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-df6f65c055f78fa51cf2465232bd29a4" align="middle">
<img src="https://picx.zhimg.com/v2-b552de8ed44ea980659fc7807adc4b3f" align="middle">
<img src="https://picx.zhimg.com/v2-55f063c6c3edf70cc7bc14ac11dc4a6c" align="middle">
<img src="https://picx.zhimg.com/v2-4b94fa359c57b3e942e395ad8918b83e" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WarpGAN-Warping-Guided-3D-GAN-Inversion-with-Style-Based-Novel-View-Inpainting"><a href="#WarpGAN-Warping-Guided-3D-GAN-Inversion-with-Style-Based-Novel-View-Inpainting" class="headerlink" title="WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting"></a>WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting</h2><p><strong>Authors:Kaitao Huang, Yan Yan, Jing-Hao Xue, Hanzi Wang</strong></p>
<p>3D GAN inversion projects a single image into the latent space of a pre-trained 3D GAN to achieve single-shot novel view synthesis, which requires visible regions with high fidelity and occluded regions with realism and multi-view consistency. However, existing methods focus on the reconstruction of visible regions, while the generation of occluded regions relies only on the generative prior of 3D GAN. As a result, the generated occluded regions often exhibit poor quality due to the information loss caused by the low bit-rate latent code. To address this, we introduce the warping-and-inpainting strategy to incorporate image inpainting into 3D GAN inversion and propose a novel 3D GAN inversion method, WarpGAN. Specifically, we first employ a 3D GAN inversion encoder to project the single-view image into a latent code that serves as the input to 3D GAN. Then, we perform warping to a novel view using the depth map generated by 3D GAN. Finally, we develop a novel SVINet, which leverages the symmetry prior and multi-view image correspondence w.r.t. the same latent code to perform inpainting of occluded regions in the warped image. Quantitative and qualitative experiments demonstrate that our method consistently outperforms several state-of-the-art methods.</p>
<blockquote>
<p>3D GANåæŠ•å½±é€šè¿‡å°†å•å¼ å›¾åƒæŠ•å½±åˆ°é¢„è®­ç»ƒçš„3D GANçš„æ½œåœ¨ç©ºé—´æ¥å®ç°å•é•œå¤´æ–°é¢–è§†è§’åˆæˆï¼Œè¿™éœ€è¦é«˜ä¿çœŸå¯è§åŒºåŸŸã€é€¼çœŸçš„é®æŒ¡åŒºåŸŸä»¥åŠå¤šè§†è§’ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å¯è§åŒºåŸŸçš„é‡å»ºï¼Œè€Œé®æŒ¡åŒºåŸŸçš„ç”Ÿæˆä»…ä¾èµ–äº3D GANçš„ç”Ÿæˆå…ˆéªŒã€‚å› æ­¤ï¼Œç”±äºä½æ¯”ç‰¹ç‡æ½œåœ¨ä»£ç å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ï¼Œç”Ÿæˆçš„é®æŒ¡åŒºåŸŸå¾€å¾€è´¨é‡è¾ƒå·®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†warping-and-inpaintingç­–ç•¥ï¼Œå°†å›¾åƒä¿®å¤æŠ€æœ¯èå…¥3D GANåæŠ•å½±ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°å‹çš„3D GANåæŠ•å½±æ–¹æ³•â€”â€”WarpGANã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨3D GANåæŠ•å½±ç¼–ç å™¨å°†å•è§†å›¾å›¾åƒæŠ•å½±åˆ°æ½œåœ¨ä»£ç ä¸Šï¼Œè¯¥ä»£ç ä½œä¸ºè¾“å…¥ç”¨äºé©±åŠ¨3D GANã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ç”±3D GANç”Ÿæˆçš„æ·±åº¦å›¾è¿›è¡Œè§†è§’å˜æ¢ã€‚æœ€åï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°å‹çš„SVINetç½‘ç»œï¼Œå®ƒåˆ©ç”¨å¯¹ç§°æ€§å…ˆéªŒå’Œç›¸åŒæ½œåœ¨ä»£ç çš„å¤šè§†è§’å›¾åƒå¯¹åº”å…³ç³»ï¼Œå¯¹å˜æ¢åçš„å›¾åƒçš„é®æŒ¡åŒºåŸŸè¿›è¡Œå¡«å……ä¿®å¤ã€‚å®šé‡å’Œå®šæ€§å®éªŒå‡è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºå‡ ç§æœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.08178v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬é¡¹ç›®é’ˆå¯¹3D GANåå·ç§¯æŠ€æœ¯åœ¨å•è§†è§’å›¾åƒæŠ•å½±åˆ°æ½œåœ¨ç©ºé—´çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å¯è§åŒºåŸŸçš„é‡å»ºï¼Œè€Œå¿½ç•¥é®æŒ¡åŒºåŸŸçš„ç”Ÿæˆï¼Œå¯¼è‡´é®æŒ¡åŒºåŸŸè´¨é‡è¾ƒå·®ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡é‡‡ç”¨å›¾åƒè¡¥å…¨çš„æˆ˜äº‰ç­–ç•¥å¹¶æ¨å‡ºæ–°çš„WarpGANæ–¹æ³•ã€‚æ­¤æ–¹æ³•å°†å›¾åƒå…ˆè¿›è¡Œä¸‰ç»´GANåå·ç§¯ç¼–ç å™¨æŠ•å½±åˆ°æ½œåœ¨ç©ºé—´ï¼Œç„¶åä½¿ç”¨æ·±åº¦å›¾è¿›è¡Œè§†è§’å˜æ¢ï¼Œæœ€ååˆ©ç”¨å¯¹ç§°å…ˆéªŒå’Œå¤šè§†è§’å›¾åƒå¯¹åº”å…³ç³»è¿›è¡Œé®æŒ¡åŒºåŸŸçš„è¡¥å…¨ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰3D GANåå·ç§¯æŠ€æœ¯ä¸»è¦å…³æ³¨å¯è§åŒºåŸŸçš„é‡å»ºï¼Œå¿½ç•¥é®æŒ¡åŒºåŸŸç”Ÿæˆçš„é—®é¢˜ã€‚</li>
<li>é®æŒ¡åŒºåŸŸç”Ÿæˆè´¨é‡å·®çš„åŸå› æ˜¯ä¿¡æ¯æŸå¤±å’Œä½æ¯”ç‰¹ç‡çš„æ½œåœ¨ä»£ç ã€‚</li>
<li>é‡‡ç”¨æˆ˜äº‰ç­–ç•¥çš„å›¾åƒè¡¥å…¨æŠ€æœ¯è¢«å¼•å…¥3D GANåå·ç§¯ä¸­ã€‚</li>
<li>æå‡ºæ–°çš„WarpGANæ–¹æ³•ï¼Œé€šè¿‡ä¸‰ç»´GANåå·ç§¯ç¼–ç å™¨å°†å›¾åƒæŠ•å½±åˆ°æ½œåœ¨ç©ºé—´ã€‚</li>
<li>ä½¿ç”¨æ·±åº¦å›¾è¿›è¡Œè§†è§’å˜æ¢ã€‚</li>
<li>åˆ©ç”¨å¯¹ç§°å…ˆéªŒå’Œå¤šè§†è§’å›¾åƒå¯¹åº”å…³ç³»è¿›è¡Œé®æŒ¡åŒºåŸŸçš„è¡¥å…¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.08178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cd88daf813461008a169f6e77f1fd071" align="middle">
<img src="https://picx.zhimg.com/v2-ccf07de49701920825df339bd91ce85c" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="PrAda-GAN-A-Private-Adaptive-Generative-Adversarial-Network-with-Bayes-Network-Structure"><a href="#PrAda-GAN-A-Private-Adaptive-Generative-Adversarial-Network-with-Bayes-Network-Structure" class="headerlink" title="PrAda-GAN: A Private Adaptive Generative Adversarial Network with Bayes Network Structure"></a>PrAda-GAN: A Private Adaptive Generative Adversarial Network with Bayes Network Structure</h2><p><strong>Authors:Ke Jia, Yuheng Ma, Yang Li, Feifei Wang</strong></p>
<p>We revisit the problem of generating synthetic data under differential privacy. To address the core limitations of marginal-based methods, we propose the Private Adaptive Generative Adversarial Network with Bayes Network Structure (PrAda-GAN), which integrates the strengths of both GAN-based and marginal-based approaches. Our method adopts a sequential generator architecture to capture complex dependencies among variables, while adaptively regularizing the learned structure to promote sparsity in the underlying Bayes network. Theoretically, we establish diminishing bounds on the parameter distance, variable selection error, and Wasserstein distance. Our analysis shows that leveraging dependency sparsity leads to significant improvements in convergence rates. Empirically, experiments on both synthetic and real-world datasets demonstrate that PrAda-GAN outperforms existing tabular data synthesis methods in terms of the privacy-utility trade-off.</p>
<blockquote>
<p>æˆ‘ä»¬é‡æ–°ç ”ç©¶äº†åœ¨å·®åˆ†éšç§ä¸‹ç”Ÿæˆåˆæˆæ•°æ®çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³åŸºäºè¾¹ç¼˜æ–¹æ³•çš„æ ¸å¿ƒå±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†å¸¦æœ‰è´å¶æ–¯ç½‘ç»œç»“æ„çš„ç§æœ‰è‡ªé€‚åº”ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆPrAda-GANï¼‰ï¼Œå®ƒç»“åˆäº†åŸºäºGANçš„æ–¹æ³•å’ŒåŸºäºè¾¹ç¼˜æ–¹æ³•çš„ä¼˜ç‚¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨é¡ºåºç”Ÿæˆå™¨æ¶æ„æ¥æ•è·å˜é‡ä¹‹é—´çš„å¤æ‚ä¾èµ–æ€§ï¼ŒåŒæ—¶è‡ªé€‚åº”åœ°è°ƒæ•´å­¦ä¹ åˆ°çš„ç»“æ„ä»¥ä¿ƒè¿›åŸºç¡€è´å¶æ–¯ç½‘ç»œä¸­çš„ç¨€ç–æ€§ã€‚ä»ç†è®ºä¸Šè®²ï¼Œæˆ‘ä»¬å»ºç«‹äº†å‚æ•°è·ç¦»ã€å˜é‡é€‰æ‹©è¯¯å·®å’ŒWassersteinè·ç¦»ä¸Šçš„é€’å‡ç•Œé™ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œåˆ©ç”¨ä¾èµ–ç¨€ç–æ€§å¯ä»¥æé«˜æ”¶æ•›é€Ÿåº¦ã€‚ä»ç»éªŒä¸Šçœ‹ï¼Œåˆæˆæ•°æ®å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨éšç§æ•ˆç”¨æƒè¡¡æ–¹é¢ï¼ŒPrAda-GANä¼˜äºç°æœ‰çš„è¡¨æ ¼æ•°æ®åˆæˆæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07997v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åœ¨å·®åˆ†éšç§ä¸‹ç”Ÿæˆåˆæˆæ•°æ®çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†Private Adaptive Generative Adversarial Network with Bayes Network Structureï¼ˆPrAda-GANï¼‰æ–¹æ³•æ¥è§£å†³æ ¸å¿ƒé™åˆ¶ã€‚è¯¥æ–¹æ³•ç»“åˆäº†GANå’Œè¾¹é™…æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œé‡‡ç”¨é¡ºåºç”Ÿæˆå™¨æ¶æ„æ•æ‰å˜é‡é—´çš„å¤æ‚ä¾èµ–å…³ç³»ï¼Œè‡ªé€‚åº”è°ƒæ•´å­¦ä¹ ç»“æ„ä»¥ä¿ƒè¿›åº•å±‚è´å¶æ–¯ç½‘ç»œçš„ç¨€ç–æ€§ã€‚ç†è®ºåˆ†æå’Œå®éªŒè¡¨æ˜ï¼Œåˆ©ç”¨ä¾èµ–ç¨€ç–æ€§å¯ä»¥æé«˜æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶åœ¨éšç§æ•ˆç”¨æƒè¡¡æ–¹é¢ä¼˜äºç°æœ‰è¡¨æ ¼æ•°æ®åˆæˆæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é’ˆå¯¹å·®åˆ†éšç§ä¸‹çš„åˆæˆæ•°æ®ç”Ÿæˆé—®é¢˜ï¼Œæå‡ºäº†PrAda-GANæ–¹æ³•ï¼Œç»“åˆäº†GANå’Œè¾¹é™…æ–¹æ³•çš„ä¼˜ç‚¹ã€‚</li>
<li>PrAda-GANé‡‡ç”¨é¡ºåºç”Ÿæˆå™¨æ¶æ„æ¥æ•æ‰å˜é‡é—´çš„å¤æ‚ä¾èµ–å…³ç³»ã€‚</li>
<li>é€šè¿‡è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ ç»“æ„ï¼Œä¿ƒè¿›åº•å±‚è´å¶æ–¯ç½‘ç»œçš„ç¨€ç–æ€§ã€‚</li>
<li>ç†è®ºåˆ†æè¡¨æ˜ï¼Œåˆ©ç”¨ä¾èµ–ç¨€ç–æ€§æœ‰åŠ©äºæé«˜æ”¶æ•›é€Ÿåº¦ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒPrAda-GANåœ¨éšç§æ•ˆç”¨æƒè¡¡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨åˆæˆæ•°æ®å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07997">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e7d0e1cdc3d5e7bdb9d53c82d2fa74b5" align="middle">
<img src="https://picx.zhimg.com/v2-ac3974a5cfa0a39c7ecdba9e45e2b51b" align="middle">
<img src="https://picx.zhimg.com/v2-1885c058537cb838edfc4bb782ffe134" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Is-It-Truly-Necessary-to-Process-and-Fit-Minutes-Long-Reference-Videos-for-Personalized-Talking-Face-Generation"><a href="#Is-It-Truly-Necessary-to-Process-and-Fit-Minutes-Long-Reference-Videos-for-Personalized-Talking-Face-Generation" class="headerlink" title="Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?"></a>Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?</h2><p><strong>Authors:Rui-Qing Sun, Ang Li, Zhijing Wu, Tian Lan, Qianyu Lu, Xingshan Yao, Chen Xu, Xian-Ling Mao</strong></p>
<p>Talking Face Generation (TFG) aims to produce realistic and dynamic talking portraits, with broad applications in fields such as digital education, film and television production, e-commerce live streaming, and other related areas. Currently, TFG methods based on Neural Radiated Field (NeRF) or 3D Gaussian sputtering (3DGS) are received widespread attention. They learn and store personalized features from reference videos of each target individual to generate realistic speaking videos. To ensure models can capture sufficient 3D information and successfully learns the lip-audio mapping, previous studies usually require meticulous processing and fitting several minutes of reference video, which always takes hours. The computational burden of processing and fitting long reference videos severely limits the practical application value of these methods.However, is it really necessary to fit such minutes of reference video? Our exploratory case studies show that using some informative reference video segments of just a few seconds can achieve performance comparable to or even better than the full reference video. This indicates that video informative quality is much more important than its length. Inspired by this observation, we propose the ISExplore (short for Informative Segment Explore), a simple-yet-effective segment selection strategy that automatically identifies the informative 5-second reference video segment based on three key data quality dimensions: audio feature diversity, lip movement amplitude, and number of camera views. Extensive experiments demonstrate that our approach increases data processing and training speed by more than 5x for NeRF and 3DGS methods, while maintaining high-fidelity output. Project resources are available at xx.</p>
<blockquote>
<p>ç”Ÿæˆå¯¹è¯é¢éƒ¨ï¼ˆTFGï¼‰æ—¨åœ¨ç”ŸæˆçœŸå®ä¸”åŠ¨æ€çš„å¯¹è¯è‚–åƒï¼Œå¹¿æ³›åº”ç”¨äºæ•°å­—æ•™è‚²ã€å½±è§†åˆ¶ä½œã€ç”µå•†ç›´æ’­ç­‰é¢†åŸŸã€‚ç›®å‰ï¼ŒåŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–ä¸‰ç»´é«˜æ–¯å–·å°„ï¼ˆ3DGSï¼‰çš„TFGæ–¹æ³•å—åˆ°å¹¿æ³›å…³æ³¨ã€‚å®ƒä»¬ä»æ¯ä¸ªç›®æ ‡ä¸ªä½“çš„å‚è€ƒè§†é¢‘ä¸­å­¦ä¹ å’Œå­˜å‚¨ä¸ªæ€§åŒ–ç‰¹å¾ï¼Œä»¥ç”Ÿæˆé€¼çœŸçš„è¯´è¯è§†é¢‘ã€‚ä¸ºç¡®ä¿æ¨¡å‹æ•æ‰è¶³å¤Ÿçš„ä¸‰ç»´ä¿¡æ¯å¹¶æˆåŠŸå­¦ä¹ å”‡éŸ³æ˜ å°„ï¼Œå…ˆå‰çš„ç ”ç©¶é€šå¸¸éœ€è¦ç²¾ç»†å¤„ç†å’Œæ‹Ÿåˆå‡ åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘ï¼Œè¿™æ€»æ˜¯éœ€è¦èŠ±è´¹æ•°å°æ—¶çš„æ—¶é—´ã€‚å¤„ç†å’Œæ‹Ÿåˆé•¿å‚è€ƒè§†é¢‘çš„è®¡ç®—è´Ÿæ‹…ä¸¥é‡é™åˆ¶äº†è¿™äº›æ–¹æ³•çš„å®é™…åº”ç”¨ä»·å€¼ã€‚ç„¶è€Œï¼Œæ‹Ÿåˆå¦‚æ­¤å¤šçš„å‚è€ƒè§†é¢‘çœŸçš„æœ‰å¿…è¦å—ï¼Ÿæˆ‘ä»¬çš„æ¢ç´¢æ€§æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œä»…ä½¿ç”¨å‡ ç§’çš„å‚è€ƒè§†é¢‘ç‰‡æ®µå°±å¯ä»¥å®ç°ä¸å®Œæ•´å‚è€ƒè§†é¢‘ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜è§†é¢‘çš„ä¿¡æ¯è´¨é‡è¿œæ¯”å…¶é•¿åº¦é‡è¦ã€‚å—æ­¤è§‚å¯Ÿå¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ISExploreï¼ˆå³ä¿¡æ¯ç‰‡æ®µæ¢ç´¢ï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„ç‰‡æ®µé€‰æ‹©ç­–ç•¥ï¼Œå¯è‡ªåŠ¨æ ¹æ®ä¸‰ä¸ªå…³é”®æ•°æ®è´¨é‡ç»´åº¦ç¡®å®šæœ€å…·ä»£è¡¨æ€§çš„äº”ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µï¼šéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨åŠ¨ä½œå¹…åº¦å’Œæ‘„åƒæœºè§†è§’æ•°é‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½åŠ é€ŸNeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†å’Œè®­ç»ƒé€Ÿåº¦è¶…è¿‡äº”å€ï¼ŒåŒæ—¶ä¿æŒé«˜ä¿çœŸè¾“å‡ºã€‚é¡¹ç›®èµ„æºå¯åœ¨xxå¤„è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07940v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¯´è¯é¢å­”ç”Ÿæˆï¼ˆTFGï¼‰æ—¨åœ¨ç”ŸæˆçœŸå®ä¸”åŠ¨æ€çš„è‚–åƒè§†é¢‘ï¼Œå¹¿æ³›åº”ç”¨äºæ•°å­—æ•™è‚²ã€å½±è§†åˆ¶ä½œã€ç”µå•†ç›´æ’­ç­‰é¢†åŸŸã€‚åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰çš„TFGæ–¹æ³•é€šè¿‡å­¦ä¹ å‚è€ƒè§†é¢‘ä¸­çš„ä¸ªæ€§åŒ–ç‰¹å¾æ¥ç”ŸæˆçœŸå®è¯´è¯è§†é¢‘ã€‚ä¸ºç¡®ä¿æ¨¡å‹æ•æ‰è¶³å¤Ÿçš„3Dä¿¡æ¯å¹¶æˆåŠŸå­¦ä¹ å”‡éŸ³æ˜ å°„ï¼Œå…ˆå‰ç ”ç©¶é€šå¸¸éœ€è¦ç²¾ç»†å¤„ç†å’Œæ‹Ÿåˆæ•°åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘ï¼Œè€—æ—¶è‰¯ä¹…ã€‚ç„¶è€Œï¼ŒçœŸçš„éœ€è¦æ‹Ÿåˆè¿™ä¹ˆä¹…çš„å‚è€ƒè§†é¢‘å—ï¼Ÿæˆ‘ä»¬çš„æ¢ç´¢æ€§æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨å‡ ç§’çš„å‚è€ƒè§†é¢‘ç‰‡æ®µå°±èƒ½è¾¾åˆ°ç”šè‡³è¶…è¶Šå…¨è§†é¢‘çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜è§†é¢‘çš„ä¿¡æ¯è´¨é‡è¿œæ¯”å…¶é•¿åº¦é‡è¦ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ISExploreï¼ˆä¿¡æ¯ç‰‡æ®µæ¢ç´¢ï¼‰ç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½è‡ªåŠ¨è¯†åˆ«æœ€å…·ä¿¡æ¯é‡çš„5ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µï¼ŒåŸºäºä¸‰ä¸ªå…³é”®æ•°æ®è´¨é‡ç»´åº¦ï¼šéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å˜´å”‡è¿åŠ¨å¹…åº¦å’Œæ‘„åƒå¤´è§†è§’æ•°é‡ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½æå‡NeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†å’Œè®­ç»ƒé€Ÿåº¦è¶…è¿‡5å€ï¼ŒåŒæ—¶ä¿æŒé«˜ä¿çœŸè¾“å‡ºã€‚</p>
<p><strong>å…³é”®å‘ç°</strong></p>
<ol>
<li>è¯´è¯é¢å­”ç”Ÿæˆï¼ˆTFGï¼‰æŠ€æœ¯èƒ½ç”ŸæˆçœŸå®ä¸”åŠ¨æ€çš„è‚–åƒè§†é¢‘ï¼Œå¹¿æ³›åº”ç”¨äºå¤šä¸ªé¢†åŸŸã€‚</li>
<li>å½“å‰TFGæ–¹æ³•åŸºäºNeRFæˆ–3DGSï¼Œé€šè¿‡å­¦ä¹ å’Œå¤„ç†å‚è€ƒè§†é¢‘ç”Ÿæˆè¯´è¯è§†é¢‘ï¼Œé€šå¸¸éœ€æ•°åˆ†é’Ÿå‚è€ƒè§†é¢‘ï¼Œè€—æ—¶è¾ƒé•¿ã€‚</li>
<li>ç›¸æ¯”è§†é¢‘é•¿åº¦ï¼Œä¿¡æ¯è´¨é‡å¯¹TFGæ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>æå‡ºISExploreç­–ç•¥ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„5ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µã€‚</li>
<li>ISExploreç­–ç•¥åŸºäºéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å˜´å”‡è¿åŠ¨å¹…åº¦å’Œæ‘„åƒå¤´è§†è§’æ•°é‡ä¸‰ä¸ªç»´åº¦ã€‚</li>
<li>ä½¿ç”¨ISExploreç­–ç•¥èƒ½æ˜¾è‘—æå‡NeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†å’Œè®­ç»ƒé€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07940">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62a424c1a5296b7152788a243d566878" align="middle">
<img src="https://picx.zhimg.com/v2-da11e51d7c84f5733717486d55c20df4" align="middle">
<img src="https://picx.zhimg.com/v2-8dcca5f3a09cad2c41089af9d662173d" align="middle">
<img src="https://picx.zhimg.com/v2-fc3f9bcbefee193f1c713f94789218ea" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Sparse4DGS-4D-Gaussian-Splatting-for-Sparse-Frame-Dynamic-Scene-Reconstruction"><a href="#Sparse4DGS-4D-Gaussian-Splatting-for-Sparse-Frame-Dynamic-Scene-Reconstruction" class="headerlink" title="Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene Reconstruction"></a>Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene Reconstruction</h2><p><strong>Authors:Changyue Shi, Chuxiao Yang, Xinyuan Hu, Minghao Chen, Wenwen Pan, Yan Yang, Jiajun Ding, Zhou Yu, Jun Yu</strong></p>
<p>Dynamic Gaussian Splatting approaches have achieved remarkable performance for 4D scene reconstruction. However, these approaches rely on dense-frame video sequences for photorealistic reconstruction. In real-world scenarios, due to equipment constraints, sometimes only sparse frames are accessible. In this paper, we propose Sparse4DGS, the first method for sparse-frame dynamic scene reconstruction. We observe that dynamic reconstruction methods fail in both canonical and deformed spaces under sparse-frame settings, especially in areas with high texture richness. Sparse4DGS tackles this challenge by focusing on texture-rich areas. For the deformation network, we propose Texture-Aware Deformation Regularization, which introduces a texture-based depth alignment loss to regulate Gaussian deformation. For the canonical Gaussian field, we introduce Texture-Aware Canonical Optimization, which incorporates texture-based noise into the gradient descent process of canonical Gaussians. Extensive experiments show that when taking sparse frames as inputs, our method outperforms existing dynamic or few-shot techniques on NeRF-Synthetic, HyperNeRF, NeRF-DS, and our iPhone-4D datasets.</p>
<blockquote>
<p>åŠ¨æ€é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯å·²åœ¨4Dåœºæ™¯é‡å»ºæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæ•ˆã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºå¯†é›†å¸§è§†é¢‘åºåˆ—æ¥å®ç°é€¼çœŸçš„é‡å»ºã€‚åœ¨ç°å®ä¸–ç•Œçš„åœºæ™¯ä¸­ï¼Œç”±äºè®¾å¤‡é™åˆ¶ï¼Œæœ‰æ—¶åªèƒ½è·å–ç¨€ç–å¸§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Sparse4DGSï¼Œè¿™æ˜¯ä¸€ç§ç¨€ç–å¸§åŠ¨æ€åœºæ™¯é‡å»ºçš„é¦–ä¸ªæ–¹æ³•ã€‚æˆ‘ä»¬å‘ç°ï¼Œåœ¨ç¨€ç–å¸§è®¾ç½®ä¸‹ï¼Œæ— è®ºæ˜¯æ ‡å‡†ç©ºé—´è¿˜æ˜¯å˜å½¢ç©ºé—´ï¼ŒåŠ¨æ€é‡å»ºæ–¹æ³•éƒ½ä¼šå¤±æ•ˆï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†ä¸°å¯Œçš„åŒºåŸŸã€‚Sparse4DGSé€šè¿‡å…³æ³¨çº¹ç†ä¸°å¯Œçš„åŒºåŸŸæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚å¯¹äºå˜å½¢ç½‘ç»œï¼Œæˆ‘ä»¬æå‡ºäº†çº¹ç†æ„ŸçŸ¥å˜å½¢æ­£åˆ™åŒ–ï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºçº¹ç†çš„æ·±åº¦å¯¹é½æŸå¤±æ¥è§„èŒƒé«˜æ–¯å˜å½¢ã€‚å¯¹äºæ ‡å‡†é«˜æ–¯åœºï¼Œæˆ‘ä»¬å¼•å…¥äº†çº¹ç†æ„ŸçŸ¥è§„èŒƒä¼˜åŒ–ï¼Œå°†åŸºäºçº¹ç†çš„å™ªå£°çº³å…¥æ ‡å‡†é«˜æ–¯åœºçš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œå½“ä»¥ç¨€ç–å¸§ä¸ºè¾“å…¥æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨NeRF-Syntheticã€HyperNeRFã€NeRF-DSä»¥åŠæˆ‘ä»¬çš„iPhone-4Dæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„åŠ¨æ€æˆ–å°‘æ•°æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07122v1">PDF</a> AAAI 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†Sparse4DGSæ–¹æ³•ï¼Œè§£å†³äº†ç¨€ç–å¸§åŠ¨æ€åœºæ™¯é‡å»ºçš„é—®é¢˜ã€‚é’ˆå¯¹åŠ¨æ€é‡å»ºæ–¹æ³•åœ¨ç¨€ç–å¸§è®¾ç½®ä¸‹åœ¨è§„èŒƒç©ºé—´å’Œå˜å½¢ç©ºé—´ä¸­çš„å¤±è´¥ï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†ä¸°å¯ŒåŒºåŸŸçš„é—®é¢˜ï¼ŒSparse4DGSä¸“æ³¨äºçº¹ç†ä¸°å¯ŒåŒºåŸŸï¼Œå¹¶æå‡ºçº¹ç†æ„ŸçŸ¥å˜å½¢æ­£åˆ™åŒ–å’Œçº¹ç†æ„ŸçŸ¥è§„èŒƒä¼˜åŒ–ï¼Œæé«˜äº†æ€§èƒ½ã€‚åœ¨NeRF-Syntheticã€HyperNeRFã€NeRF-DSå’ŒiPhone-4Dæ•°æ®é›†ä¸Šï¼ŒSparse4DGSåœ¨ç¨€ç–å¸§è¾“å…¥ä¸‹ä¼˜äºç°æœ‰åŠ¨æ€æˆ–å°‘æ•°æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Sparse4DGSæ˜¯é¦–ä¸ªé’ˆå¯¹ç¨€ç–å¸§åŠ¨æ€åœºæ™¯é‡å»ºçš„æ–¹æ³•ã€‚</li>
<li>åŠ¨æ€é‡å»ºæ–¹æ³•åœ¨ç¨€ç–å¸§è®¾ç½®ä¸‹åœ¨è§„èŒƒç©ºé—´å’Œå˜å½¢ç©ºé—´ä¸­è¡¨ç°ä¸ä½³ã€‚</li>
<li>Sparse4DGSä¸“æ³¨äºå¤„ç†çº¹ç†ä¸°å¯ŒåŒºåŸŸçš„é‡å»ºé—®é¢˜ã€‚</li>
<li>æå‡ºäº†çº¹ç†æ„ŸçŸ¥å˜å½¢æ­£åˆ™åŒ–ï¼Œé€šè¿‡å¼•å…¥åŸºäºçº¹ç†çš„æ·±åº¦å¯¹é½æŸå¤±æ¥è§„èŒƒé«˜æ–¯å˜å½¢ã€‚</li>
<li>å¼•å…¥äº†çº¹ç†æ„ŸçŸ¥è§„èŒƒä¼˜åŒ–ï¼Œå°†çº¹ç†åŸºäºçš„å™ªå£°çº³å…¥è§„èŒƒé«˜æ–¯åœºçš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒSparse4DGSåœ¨ç¨€ç–å¸§è¾“å…¥ä¸‹çš„æ€§èƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07122">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a2a3e15a11a038b1a0636e162b0e67a8" align="middle">
<img src="https://picx.zhimg.com/v2-f0fd41cce98e61387614528abe4972c9" align="middle">
<img src="https://picx.zhimg.com/v2-1e7694e6db2740431d3f8a01f56e7dfe" align="middle">
<img src="https://picx.zhimg.com/v2-2f5bea910ef9b9e595d67b4ba9da5e63" align="middle">
<img src="https://picx.zhimg.com/v2-4194ff096762055e001eb0413b33da67" align="middle">
<img src="https://picx.zhimg.com/v2-adbb3a19016fcff2e4673cb94e64999e" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Inpaint360GS-Efficient-Object-Aware-3D-Inpainting-via-Gaussian-Splatting-for-360Â°-Scenes"><a href="#Inpaint360GS-Efficient-Object-Aware-3D-Inpainting-via-Gaussian-Splatting-for-360Â°-Scenes" class="headerlink" title="Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360Â° Scenes"></a>Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360Â° Scenes</h2><p><strong>Authors:Shaoxiang Wang, Shihong Zhang, Christen Millerdurai, RÃ¼diger Westermann, Didier Stricker, Alain Pagani</strong></p>
<p>Despite recent advances in single-object front-facing inpainting using NeRF and 3D Gaussian Splatting (3DGS), inpainting in complex 360Â° scenes remains largely underexplored. This is primarily due to three key challenges: (i) identifying target objects in the 3D field of 360Â° environments, (ii) dealing with severe occlusions in multi-object scenes, which makes it hard to define regions to inpaint, and (iii) maintaining consistent and high-quality appearance across views effectively. To tackle these challenges, we propose Inpaint360GS, a flexible 360Â° editing framework based on 3DGS that supports multi-object removal and high-fidelity inpainting in 3D space. By distilling 2D segmentation into 3D and leveraging virtual camera views for contextual guidance, our method enables accurate object-level editing and consistent scene completion. We further introduce a new dataset tailored for 360Â° inpainting, addressing the lack of ground truth object-free scenes. Experiments demonstrate that Inpaint360GS outperforms existing baselines and achieves state-of-the-art performance. Project page: <a target="_blank" rel="noopener" href="https://dfki-av.github.io/inpaint360gs/">https://dfki-av.github.io/inpaint360gs/</a></p>
<blockquote>
<p>å°½ç®¡æœ€è¿‘ä½¿ç”¨NeRFå’Œ3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰çš„å•å¯¹è±¡æ­£é¢è¡¥å…¨æŠ€æœ¯æœ‰æ‰€è¿›å±•ï¼Œä½†åœ¨å¤æ‚çš„360Â°åœºæ™¯ä¸­çš„è¡¥å…¨ä»ç„¶å¾ˆå°‘è¢«æ¢ç´¢ã€‚è¿™ä¸»è¦æ˜¯ç”±äºä»¥ä¸‹ä¸‰ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šï¼ˆiï¼‰åœ¨360Â°ç¯å¢ƒçš„3Dåœºæ™¯ä¸­è¯†åˆ«ç›®æ ‡å¯¹è±¡ï¼Œï¼ˆiiï¼‰å¤„ç†å¤šå¯¹è±¡åœºæ™¯ä¸­çš„ä¸¥é‡é®æŒ¡ï¼Œè¿™ä½¿å¾—éš¾ä»¥å®šä¹‰è¦è¡¥å…¨çš„åŒºåŸŸï¼Œä»¥åŠï¼ˆiiiï¼‰æœ‰æ•ˆåœ°åœ¨ä¸åŒè§†è§’ä¸Šä¿æŒä¸€è‡´ä¸”é«˜è´¨é‡çš„å¤–è²Œã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Inpaint360GSï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº3DGSçš„çµæ´»360Â°ç¼–è¾‘æ¡†æ¶ï¼Œæ”¯æŒåœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„å¤šå¯¹è±¡ç§»é™¤å’Œé«˜ä¿çœŸè¡¥å…¨ã€‚é€šè¿‡å°†äºŒç»´åˆ†å‰²è½¬åŒ–ä¸ºä¸‰ç»´å¹¶åˆ©ç”¨è™šæ‹Ÿç›¸æœºè§†è§’è¿›è¡Œä¸Šä¸‹æ–‡æŒ‡å¯¼ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°ç²¾ç¡®çš„å¯¹è±¡çº§ç¼–è¾‘å’Œä¸€è‡´çš„åœºæ™¯è¡¥å…¨ã€‚æˆ‘ä»¬è¿˜é’ˆå¯¹360Â°è¡¥å…¨å¼•å…¥äº†ä¸€ä¸ªæ–°æ•°æ®é›†ï¼Œè§£å†³äº†ç¼ºä¹æ— å¯¹è±¡åœºæ™¯çš„çœŸå®æ•°æ®é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒInpaint360GSä¼˜äºç°æœ‰åŸºçº¿å¹¶è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://dfki-av.github.io/inpaint360gs/%E3%80%82">https://dfki-av.github.io/inpaint360gs/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.06457v1">PDF</a> WACV 2026, project page: <a target="_blank" rel="noopener" href="https://dfki-av.github.io/inpaint360gs/">https://dfki-av.github.io/inpaint360gs/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§é’ˆå¯¹å¤æ‚360Â°åœºæ™¯ä¸­çš„å¯¹è±¡ç¼ºå¤±ä¿®å¤çš„æ–°æ–¹æ³•Inpaint360GSã€‚å®ƒåŸºäºä¸‰ç»´é«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰ï¼Œæ”¯æŒå¤šå¯¹è±¡åˆ é™¤å¹¶åœ¨ä¸‰ç»´ç©ºé—´ä¸­å®ç°é«˜ä¿çœŸè¡¥å…¨ã€‚é€šè¿‡è’¸é¦äºŒç»´åˆ†å‰²åˆ°ä¸‰ç»´å¹¶åˆ©ç”¨è™šæ‹Ÿç›¸æœºè§†è§’è¿›è¡Œä¸Šä¸‹æ–‡æŒ‡å¯¼ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå®ç°å‡†ç¡®çš„å¯¹è±¡çº§ç¼–è¾‘å’Œä¸€è‡´çš„åœºæ™¯è¡¥å…¨ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªé’ˆå¯¹360Â°è¡¥å…¨çš„æ–°æ•°æ®é›†ï¼Œè§£å†³äº†ç¼ºä¹æ— å¯¹è±¡åœºæ™¯çœŸå®æ•°æ®çš„é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒInpaint360GSä¼˜äºç°æœ‰åŸºçº¿å¹¶è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†é’ˆå¯¹å¤æ‚360Â°åœºæ™¯ä¸­çš„å¯¹è±¡ç¼ºå¤±ä¿®å¤çš„æœ€æ–°æ–¹æ³•Inpaint360GSã€‚</li>
<li>åŸºäºä¸‰ç»´é«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œæ”¯æŒå¤šå¯¹è±¡åˆ é™¤å’Œä¸‰ç»´ç©ºé—´ä¸­çš„é«˜ä¿çœŸè¡¥å…¨ã€‚</li>
<li>é€šè¿‡å°†äºŒç»´åˆ†å‰²è’¸é¦åˆ°ä¸‰ç»´å¹¶åˆ©ç”¨è™šæ‹Ÿç›¸æœºè§†è§’è¿›è¡Œä¸Šä¸‹æ–‡æŒ‡å¯¼ï¼Œå®ç°äº†å‡†ç¡®çš„å¯¹è±¡çº§ç¼–è¾‘å’Œä¸€è‡´çš„åœºæ™¯è¡¥å…¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®é›†ï¼Œç”¨äºè§£å†³é’ˆå¯¹360Â°è¡¥å…¨çš„ç¼ºä¹çœŸå®æ— å¯¹è±¡åœºæ™¯çš„é—®é¢˜ã€‚</li>
<li>Inpaint360GSçš„æ€§èƒ½è¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼Œå¹¶è¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½æ°´å¹³ã€‚</li>
<li>æ­¤æ–¹æ³•å¯ä»¥åº”ç”¨äºè™šæ‹Ÿç¼–è¾‘ã€æ¸¸æˆåœºæ™¯åˆ¶ä½œã€è™šæ‹Ÿç°å®ç­‰åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.06457">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-09568eee9cc44d882213c0bd44395a54" align="middle">
<img src="https://picx.zhimg.com/v2-85d9d973d928e63252d99be8f5fc9a9b" align="middle">
<img src="https://picx.zhimg.com/v2-13c77cfc02f0ee02910cb05734f50d60" align="middle">
<img src="https://picx.zhimg.com/v2-7c66ceb76210f4e377706d24eeff46ca" align="middle">
<img src="https://picx.zhimg.com/v2-29d9515ccca315c0577879ca0aef53ee" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="VDNeRF-Vision-only-Dynamic-Neural-Radiance-Field-for-Urban-Scenes"><a href="#VDNeRF-Vision-only-Dynamic-Neural-Radiance-Field-for-Urban-Scenes" class="headerlink" title="VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes"></a>VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes</h2><p><strong>Authors:Zhengyu Zou, Jingfeng Li, Hao Li, Xiaolei Hou, Jinwen Hu, Jingkun Chen, Lechao Cheng, Dingwen Zhang</strong></p>
<p>Neural Radiance Fields (NeRFs) implicitly model continuous three-dimensional scenes using a set of images with known camera poses, enabling the rendering of photorealistic novel views. However, existing NeRF-based methods encounter challenges in applications such as autonomous driving and robotic perception, primarily due to the difficulty of capturing accurate camera poses and limitations in handling large-scale dynamic environments. To address these issues, we propose Vision-only Dynamic NeRF (VDNeRF), a method that accurately recovers camera trajectories and learns spatiotemporal representations for dynamic urban scenes without requiring additional camera pose information or expensive sensor data. VDNeRF employs two separate NeRF models to jointly reconstruct the scene. The static NeRF model optimizes camera poses and static background, while the dynamic NeRF model incorporates the 3D scene flow to ensure accurate and consistent reconstruction of dynamic objects. To address the ambiguity between camera motion and independent object motion, we design an effective and powerful training framework to achieve robust camera pose estimation and self-supervised decomposition of static and dynamic elements in a scene. Extensive evaluations on mainstream urban driving datasets demonstrate that VDNeRF surpasses state-of-the-art NeRF-based pose-free methods in both camera pose estimation and dynamic novel view synthesis.</p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä½¿ç”¨ä¸€ç»„å·²çŸ¥ç›¸æœºå§¿æ€çš„å›¾åƒæ¥éšå¼åœ°æ¨¡æ‹Ÿè¿ç»­çš„ä¸‰ç»´åœºæ™¯ï¼Œä»è€Œå®ç°é€¼çœŸçš„æ–°è§†è§’æ¸²æŸ“ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºNeRFçš„æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæ„ŸçŸ¥ç­‰åº”ç”¨ä¸­é‡åˆ°äº†æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºæ•æ‰å‡†ç¡®ç›¸æœºå§¿æ€çš„å›°éš¾ä»¥åŠå¤„ç†å¤§è§„æ¨¡åŠ¨æ€ç¯å¢ƒçš„å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä»…è§†è§‰åŠ¨æ€NeRFï¼ˆVDNeRFï¼‰ï¼Œä¸€ç§æ— éœ€é¢å¤–çš„ç›¸æœºå§¿æ€ä¿¡æ¯æˆ–æ˜‚è´µçš„ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå°±èƒ½å‡†ç¡®æ¢å¤ç›¸æœºè½¨è¿¹å¹¶ä¸ºåŠ¨æ€åŸå¸‚åœºæ™¯å­¦ä¹ æ—¶ç©ºè¡¨å¾çš„æ–¹æ³•ã€‚VDNeRFé‡‡ç”¨ä¸¤ä¸ªå•ç‹¬çš„NeRFæ¨¡å‹è”åˆé‡å»ºåœºæ™¯ã€‚é™æ€NeRFæ¨¡å‹ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œé™æ€èƒŒæ™¯ï¼Œè€ŒåŠ¨æ€NeRFæ¨¡å‹åˆ™èå…¥3Dåœºæ™¯æµï¼Œä»¥ç¡®ä¿å¯¹åŠ¨æ€å¯¹è±¡çš„å‡†ç¡®ä¸”ä¸€è‡´é‡å»ºã€‚ä¸ºäº†è§£å†³ç›¸æœºè¿åŠ¨å’Œç‹¬ç«‹ç‰©ä½“è¿åŠ¨ä¹‹é—´çš„æ­§ä¹‰é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæœ‰æ•ˆä¸”å¼ºå¤§çš„è®­ç»ƒæ¡†æ¶ï¼Œä»¥å®ç°ç¨³å¥çš„ç›¸æœºå§¿æ€ä¼°è®¡å’Œåœºæ™¯ä¸­é™æ€ä¸åŠ¨æ€å…ƒç´ çš„è‡ªç›‘ç£åˆ†è§£ã€‚åœ¨ä¸»æµåŸå¸‚é©¾é©¶æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒVDNeRFåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’ŒåŠ¨æ€æ–°è§†è§’åˆæˆæ–¹é¢è¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºäºNeRFçš„æ— å§¿æ€æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.06408v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯çš„è§†è§‰ä»…åŠ¨æ€NeRFï¼ˆVDNeRFï¼‰æ–¹æ³•ï¼Œèƒ½å‡†ç¡®æ¢å¤ç›¸æœºè½¨è¿¹å¹¶å­¦ä¹ åŠ¨æ€åŸå¸‚åœºæ™¯çš„æ—¶ç©ºè¡¨ç¤ºï¼Œè€Œæ— éœ€é¢å¤–çš„ç›¸æœºå§¿æ€ä¿¡æ¯æˆ–æ˜‚è´µçš„ä¼ æ„Ÿå™¨æ•°æ®ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸¤ä¸ªç‹¬ç«‹çš„NeRFæ¨¡å‹è”åˆé‡å»ºåœºæ™¯ï¼Œé™æ€NeRFæ¨¡å‹ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œé™æ€èƒŒæ™¯ï¼ŒåŠ¨æ€NeRFæ¨¡å‹ç»“åˆ3Dåœºæ™¯æµï¼Œç¡®ä¿åŠ¨æ€ç‰©ä½“çš„å‡†ç¡®å’Œä¸€è‡´é‡å»ºã€‚VDNeRFè§£å†³äº†ç›¸æœºè¿åŠ¨å’Œç‹¬ç«‹ç‰©ä½“è¿åŠ¨ä¹‹é—´çš„æ¨¡ç³Šæ€§ï¼Œè®¾è®¡äº†ä¸€ä¸ªæœ‰æ•ˆä¸”å¼ºå¤§çš„è®­ç»ƒæ¡†æ¶ï¼Œå®ç°ç¨³å¥çš„ç›¸æœºå§¿æ€ä¼°è®¡å’Œåœºæ™¯ä¸­é™æ€ä¸åŠ¨æ€å…ƒç´ çš„è‡ªç›‘ç£åˆ†è§£ã€‚åœ¨ä¸»æµåŸå¸‚é©¾é©¶æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒVDNeRFåœ¨æ— éœ€å§¿æ€çš„NeRFæ–¹æ³•ä¸­è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’ŒåŠ¨æ€æ–°é¢–è§†å›¾åˆæˆæ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VDNeRFèƒ½å¤Ÿå‡†ç¡®æ¢å¤ç›¸æœºè½¨è¿¹å¹¶å­¦ä¹ åŠ¨æ€åŸå¸‚åœºæ™¯çš„æ—¶ç©ºè¡¨ç¤ºï¼Œæ— éœ€é¢å¤–çš„ç›¸æœºå§¿æ€ä¿¡æ¯æˆ–æ˜‚è´µçš„ä¼ æ„Ÿå™¨æ•°æ®ã€‚</li>
<li>æ–¹æ³•é‡‡ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„NeRFæ¨¡å‹è”åˆé‡å»ºåœºæ™¯ï¼ŒåŒ…æ‹¬é™æ€NeRFæ¨¡å‹å’ŒåŠ¨æ€NeRFæ¨¡å‹ã€‚</li>
<li>é™æ€NeRFæ¨¡å‹ä¸»è¦è´Ÿè´£ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œé™æ€èƒŒæ™¯ï¼Œè€ŒåŠ¨æ€NeRFæ¨¡å‹åˆ™ç»“åˆ3Dåœºæ™¯æµä»¥ç¡®ä¿åŠ¨æ€ç‰©ä½“çš„å‡†ç¡®é‡å»ºã€‚</li>
<li>VDNeRFè§£å†³äº†ç›¸æœºè¿åŠ¨å’Œç‹¬ç«‹ç‰©ä½“è¿åŠ¨ä¹‹é—´çš„æ¨¡ç³Šæ€§ï¼Œé€šè¿‡è®¾è®¡æœ‰æ•ˆçš„è®­ç»ƒæ¡†æ¶å®ç°ç¨³å¥çš„ç›¸æœºå§¿æ€ä¼°è®¡å’Œé™æ€ä¸åŠ¨æ€å…ƒç´ çš„è‡ªç›‘ç£åˆ†è§£ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸»æµåŸå¸‚é©¾é©¶æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’ŒåŠ¨æ€æ–°é¢–è§†å›¾åˆæˆæ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>VDNeRFæŠ€æœ¯å¯¹äºè‡ªä¸»é©¾é©¶å’Œæœºå™¨äººæ„ŸçŸ¥ç­‰åº”ç”¨å…·æœ‰é‡è¦çš„æ½œåœ¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.06408">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-40431e29ad985a777f3671833113a13e" align="middle">
<img src="https://picx.zhimg.com/v2-adea2a1d7ab4798b7be1f73d9205511f" align="middle">
<img src="https://picx.zhimg.com/v2-60086fd1072c9b241873ebb717822452" align="middle">
<img src="https://picx.zhimg.com/v2-613ddeffa781441b408d3a9a9e37a479" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="The-Evolving-Nature-of-Latent-Spaces-From-GANs-to-Diffusion"><a href="#The-Evolving-Nature-of-Latent-Spaces-From-GANs-to-Diffusion" class="headerlink" title="The Evolving Nature of Latent Spaces: From GANs to Diffusion"></a>The Evolving Nature of Latent Spaces: From GANs to Diffusion</h2><p><strong>Authors:Ludovica Schaerf</strong></p>
<p>This paper examines the evolving nature of internal representations in generative visual models, focusing on the conceptual and technical shift from GANs and VAEs to diffusion-based architectures. Drawing on Beatrice Faziâ€™s account of synthesis as the amalgamation of distributed representations, we propose a distinction between â€œsynthesis in a strict senseâ€, where a compact latent space wholly determines the generative process, and â€œsynthesis in a broad sense,â€ which characterizes models whose representational labor is distributed across layers. Through close readings of model architectures and a targeted experimental setup that intervenes in layerwise representations, we show how diffusion models fragment the burden of representation and thereby challenge assumptions of unified internal space. By situating these findings within media theoretical frameworks and critically engaging with metaphors such as the latent space and the Platonic Representation Hypothesis, we argue for a reorientation of how generative AI is understood: not as a direct synthesis of content, but as an emergent configuration of specialized processes.</p>
<blockquote>
<p>æœ¬æ–‡æ¢è®¨äº†ç”Ÿæˆè§†è§‰æ¨¡å‹ä¸­å†…éƒ¨è¡¨ç¤ºçš„ä¸æ–­æ¼”å˜æ€§è´¨ï¼Œé‡ç‚¹å…³æ³¨ä»GANå’ŒVAEåˆ°åŸºäºæ‰©æ•£çš„æ¶æ„çš„æ¦‚å¿µå’ŒæŠ€æœ¯è½¬å˜ã€‚æœ¬æ–‡å€Ÿé‰´äº†è´é˜¿ç‰¹ä¸½æ–¯Â·æ³•é½ï¼ˆBeatrice Faziï¼‰å…³äºåˆæˆæ˜¯åˆ†å¸ƒå¼è¡¨ç¤ºçš„èåˆçš„è§‚ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†â€œä¸¥æ ¼æ„ä¹‰ä¸Šçš„åˆæˆâ€å’Œâ€œå¹¿ä¹‰ä¸Šçš„åˆæˆâ€ä¹‹é—´çš„åŒºåˆ«ã€‚å…¶ä¸­ï¼Œâ€œä¸¥æ ¼æ„ä¹‰ä¸Šçš„åˆæˆâ€æ˜¯æŒ‡ä¸€ä¸ªç´§å‡‘çš„æ½œåœ¨ç©ºé—´å®Œå…¨å†³å®šç”Ÿæˆè¿‡ç¨‹ï¼Œè€Œâ€œå¹¿ä¹‰ä¸Šçš„åˆæˆâ€åˆ™æ˜¯æŒ‡è¡¨å¾å·¥ä½œåˆ†å¸ƒåœ¨å„å±‚çš„æ¨¡å‹ã€‚é€šè¿‡å¯¹æ¨¡å‹æ¶æ„çš„ä»”ç»†é˜…è¯»ä»¥åŠé’ˆå¯¹å±‚çº§è¡¨ç¤ºè¿›è¡Œå¹²é¢„çš„ç›®æ ‡å®éªŒè®¾ç½®ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æ‰©æ•£æ¨¡å‹å¦‚ä½•åˆ†æ•£è¡¨ç¤ºçš„è´Ÿæ‹…ï¼Œä»è€ŒæŒ‘æˆ˜äº†ç»Ÿä¸€å†…éƒ¨ç©ºé—´çš„å‡è®¾ã€‚é€šè¿‡å°†è¿™äº›å‘ç°ç½®äºåª’ä½“ç†è®ºæ¡†æ¶å†…ï¼Œå¹¶ä¸æ½œåœ¨ç©ºé—´å’ŒæŸæ‹‰å›¾è¡¨å¾å‡è®¾ç­‰éšå–»è¿›è¡Œæ‰¹åˆ¤æ€§äº’åŠ¨ï¼Œæˆ‘ä»¬ä¸»å¼ é‡æ–°æ€è€ƒå¦‚ä½•ç†è§£ç”Ÿæˆäººå·¥æ™ºèƒ½ï¼šä¸æ˜¯ä½œä¸ºå†…å®¹çš„ç›´æ¥åˆæˆï¼Œè€Œæ˜¯ä½œä¸ºä¸“é—¨è¿‡ç¨‹çš„çªå‘é…ç½®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17383v2">PDF</a> Presented and published at Ethics and Aesthetics of Artificial Intelligence Conference (EA-AIâ€™25)</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æ¢è®¨äº†ç”Ÿæˆè§†è§‰æ¨¡å‹å†…éƒ¨è¡¨ç¤ºå½¢å¼çš„æ¼”å˜è¿‡ç¨‹ï¼Œä»æ¦‚å¿µå’ŒæŠ€æœ¯è§’åº¦åˆ†æäº†ä»GANså’ŒVAEsåˆ°åŸºäºæ‰©æ•£çš„æ¶æ„çš„è½¬å˜ã€‚æ–‡ç« å€Ÿé‰´äº†Beatrice Faziå…³äºåˆæˆæ˜¯åˆ†å¸ƒå¼è¡¨ç¤ºèåˆçš„è§‚ç‚¹ï¼Œæå‡ºäº†â€œä¸¥æ ¼æ„ä¹‰ä¸Šçš„åˆæˆâ€å’Œâ€œå¹¿ä¹‰ä¸Šçš„åˆæˆâ€çš„åŒºåˆ†ã€‚å‰è€…æŒ‡ä¸€ä¸ªç´§å‡‘çš„æ½œåœ¨ç©ºé—´å®Œå…¨å†³å®šç”Ÿæˆè¿‡ç¨‹ï¼Œåè€…åˆ™æŒ‡æ¨¡å‹çš„å·¥ä½œè¡¨ç¤ºå½¢å¼åˆ†å¸ƒåœ¨å„å±‚ä¸­ã€‚é€šè¿‡ç»†è¯»æ¨¡å‹æ¶æ„å’Œæœ‰é’ˆå¯¹æ€§çš„å®éªŒè®¾ç½®ï¼Œæœ¬æ–‡å±•ç¤ºäº†æ‰©æ•£æ¨¡å‹å¦‚ä½•åˆ†æ‹…è¡¨ç¤ºçš„è´Ÿæ‹…ï¼Œä»è€ŒæŒ‘æˆ˜äº†ç»Ÿä¸€å†…éƒ¨ç©ºé—´çš„å‡è®¾ã€‚ç»“åˆåª’ä½“ç†è®ºæ¡†æ¶å’Œå…³äºæ½œåœ¨ç©ºé—´å’ŒæŸæ‹‰å›¾è¡¨å¾å‡è®¾çš„éšå–»ï¼Œæœ¬æ–‡ä¸»å¼ é‡æ–°ç†è§£ç”Ÿæˆäººå·¥æ™ºèƒ½ï¼šå®ƒä¸æ˜¯å†…å®¹çš„ç›´æ¥åˆæˆï¼Œè€Œæ˜¯ä¸“é—¨è¿‡ç¨‹çš„çªå‘é…ç½®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« åˆ†æäº†ç”Ÿæˆè§†è§‰æ¨¡å‹å†…éƒ¨è¡¨ç¤ºå½¢å¼çš„æ¼”å˜ï¼Œä»GANså’ŒVAEsè½¬å‘æ‰©æ•£æ¶æ„ã€‚</li>
<li>å¼•å…¥Beatrice Faziçš„è§‚ç‚¹ï¼Œæå‡ºâ€œä¸¥æ ¼æ„ä¹‰ä¸Šçš„åˆæˆâ€ä¸â€œå¹¿ä¹‰ä¸Šçš„åˆæˆâ€çš„åŒºåˆ†ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å°†è¡¨ç¤ºçš„è´Ÿæ‹…åˆ†æ•£åœ¨å„å±‚ä¸­ï¼ŒæŒ‘æˆ˜äº†ç»Ÿä¸€å†…éƒ¨ç©ºé—´çš„å‡è®¾ã€‚</li>
<li>é€šè¿‡å®éªŒè¯æ˜æ‰©æ•£æ¨¡å‹åœ¨å±‚é—´è¡¨ç¤ºä¸Šçš„ç‰¹æ®Šæ€§ã€‚</li>
<li>æ–‡ç« ç»“åˆåª’ä½“ç†è®ºæ¡†æ¶ï¼Œé‡æ–°æ€è€ƒç”ŸæˆAIçš„ç†è§£æ–¹å¼ã€‚</li>
<li>å¼ºè°ƒç”ŸæˆAIä¸æ˜¯å†…å®¹çš„ç›´æ¥åˆæˆï¼Œè€Œæ˜¯ä¸“é—¨è¿‡ç¨‹çš„çªå‘é…ç½®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17383">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e57f6b81455c1c39656e939f5316b51f" align="middle">
<img src="https://picx.zhimg.com/v2-214249a02cc9f3cb645c216d8d50b594" align="middle">
<img src="https://picx.zhimg.com/v2-dfe614a741b245ffad25ea47bdf64671" align="middle">
<img src="https://picx.zhimg.com/v2-cb374df397545a222388edc550c26fac" align="middle">
<img src="https://picx.zhimg.com/v2-83ad3868b7ffa16ca844721ad9363281" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="GauSSmart-Enhanced-3D-Reconstruction-through-2D-Foundation-Models-and-Geometric-Filtering"><a href="#GauSSmart-Enhanced-3D-Reconstruction-through-2D-Foundation-Models-and-Geometric-Filtering" class="headerlink" title="GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering"></a>GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering</h2><p><strong>Authors:Alexander Valverde, Brian Xu, Yuyin Zhou, Meng Xu, Hongyun Wang</strong></p>
<p>Scene reconstruction has emerged as a central challenge in computer vision, with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting achieving remarkable progress. While Gaussian Splatting demonstrates strong performance on large-scale datasets, it often struggles to capture fine details or maintain realism in regions with sparse coverage, largely due to the inherent limitations of sparse 3D training data.   In this work, we propose GauSSmart, a hybrid method that effectively bridges 2D foundational models and 3D Gaussian Splatting reconstruction. Our approach integrates established 2D computer vision techniques, including convex filtering and semantic feature supervision from foundational models such as DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D segmentation priors and high-dimensional feature embeddings, our method guides the densification and refinement of Gaussian splats, improving coverage in underrepresented areas and preserving intricate structural details.   We validate our approach across three datasets, where GauSSmart consistently outperforms existing Gaussian Splatting in the majority of evaluated scenes. Our results demonstrate the significant potential of hybrid 2D-3D approaches, highlighting how the thoughtful combination of 2D foundational models with 3D reconstruction pipelines can overcome the limitations inherent in either approach alone.</p>
<blockquote>
<p>åœºæ™¯é‡å»ºå·²æˆä¸ºè®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯è´´ç‰‡ï¼ˆGaussian Splattingï¼‰ç­‰æ–¹æ³•å·²å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚å°½ç®¡é«˜æ–¯è´´ç‰‡åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨æ•è·ç²¾ç»†ç»†èŠ‚æˆ–åœ¨ç¨€ç–è¦†ç›–åŒºåŸŸä¿æŒçœŸå®æ€§æ–¹é¢å¾€å¾€é‡åˆ°å›°éš¾ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºç¨€ç–çš„3Dè®­ç»ƒæ•°æ®å›ºæœ‰çš„å±€é™æ€§å¯¼è‡´çš„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºGauSSmartçš„æ··åˆæ–¹æ³•ï¼Œå®ƒæœ‰æ•ˆåœ°æ¡¥æ¥äº†äºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´é«˜æ–¯è´´ç‰‡é‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†æˆç†Ÿçš„äºŒç»´è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼ŒåŒ…æ‹¬å‡¸è¿‡æ»¤å’Œæ¥è‡ªåŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOï¼‰çš„è¯­ä¹‰ç‰¹å¾ç›‘ç£ï¼Œä»¥å¢å¼ºåŸºäºé«˜æ–¯çš„åœºæ™¯é‡å»ºã€‚é€šè¿‡åˆ©ç”¨äºŒç»´åˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æŒ‡å¯¼é«˜æ–¯è´´ç‰‡çš„ç¨ å¯†åŒ–å’Œç»†åŒ–ï¼Œæ”¹è¿›äº†æ¬ ä»£è¡¨çš„è¦†ç›–åŒºåŸŸå¹¶ä¿æŒå¤æ‚ç»“æ„ç»†èŠ‚ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œåœ¨å¤§å¤šæ•°è¯„ä¼°åœºæ™¯ä¸­ï¼ŒGauSSmartæŒç»­ä¼˜äºç°æœ‰é«˜æ–¯è´´ç‰‡æŠ€æœ¯ã€‚æˆ‘ä»¬çš„ç»“æœè¯æ˜äº†æ··åˆäºŒç»´å’Œä¸‰ç»´æ–¹æ³•çš„å·¨å¤§æ½œåŠ›ï¼Œçªå‡ºæ˜¾ç¤ºäº†å¦‚ä½•å°†äºŒç»´åŸºç¡€æ¨¡å‹ä¸ä¸‰ç»´é‡å»ºç®¡é“ç›¸ç»“åˆï¼Œå¯ä»¥å…‹æœå•ç‹¬ä½¿ç”¨ä»»ä½•ä¸€ç§æ–¹æ³•çš„å›ºæœ‰å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.14270v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯è´´å›¾ç­‰æ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰çš„åœºæ™¯é‡å»ºé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œé«˜æ–¯è´´å›¾åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°å¼ºåŠ²ï¼Œä½†åœ¨ç¨€ç–è¦†ç›–åŒºåŸŸæ•æ‰ç»†èŠ‚å’Œä¿æŒçœŸå®æ„Ÿæ–¹é¢å­˜åœ¨å›°éš¾ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºGauSSmartçš„æ··åˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆç»“åˆäº†äºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´é«˜æ–¯è´´å›¾é‡å»ºã€‚é€šè¿‡åˆ©ç”¨å‡¸è¿‡æ»¤å’Œæ¥è‡ªDINOç­‰åŸºç¡€æ¨¡å‹çš„è¯­ä¹‰ç‰¹å¾ç›‘ç£ç­‰äºŒç»´è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œè¯¥æ–¹æ³•å¢å¼ºäº†åŸºäºé«˜æ–¯çš„åœºæ™¯é‡å»ºã€‚åˆ©ç”¨äºŒç»´åˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼ŒGauSSmartæŒ‡å¯¼é«˜æ–¯è´´å›¾çš„å¯†é›†åŒ–å’Œç²¾ç»†åŒ–ï¼Œæé«˜äº†ä»£è¡¨æ€§ä¸è¶³åŒºåŸŸçš„è¦†ç›–ç‡ï¼Œå¹¶ä¿ç•™äº†ç²¾ç»†çš„ç»“æ„ç»†èŠ‚ã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„éªŒè¯è¡¨æ˜ï¼ŒGauSSmartåœ¨å¤§å¤šæ•°åœºæ™¯ä¸­å‡ä¼˜äºç°æœ‰çš„é«˜æ–¯è´´å›¾æ–¹æ³•ã€‚ç»“æœè¯æ˜äº†æ··åˆäºŒç»´-ä¸‰ç»´æ–¹æ³•çš„å·¨å¤§æ½œåŠ›ï¼Œçªæ˜¾äº†å°†äºŒç»´åŸºç¡€æ¨¡å‹ä¸ä¸‰ç»´é‡å»ºæµç¨‹ç›¸ç»“åˆå¦‚ä½•å…‹æœå•ä¸€æ–¹æ³•çš„å›ºæœ‰å±€é™æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯è´´å›¾ç­‰æ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰çš„åœºæ™¯é‡å»ºä¸­å–å¾—æ˜¾è‘—è¿›å±•ã€‚</li>
<li>é«˜æ–¯è´´å›¾åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç¨€ç–æ•°æ®åŒºåŸŸçš„ç»†èŠ‚æ•æ‰å’ŒçœŸå®æ„Ÿä¿æŒæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä¸€ç§åä¸ºGauSSmartçš„æ··åˆæ–¹æ³•ï¼Œç»“åˆäºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´é«˜æ–¯è´´å›¾é‡å»ºï¼Œä»¥æ”¹å–„åœºæ™¯é‡å»ºæ•ˆæœã€‚</li>
<li>GauSSmartåˆ©ç”¨äºŒç»´è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œå¦‚å‡¸è¿‡æ»¤å’Œè¯­ä¹‰ç‰¹å¾ç›‘ç£ï¼Œå¢å¼ºåŸºäºé«˜æ–¯çš„æ–¹æ³•ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨äºŒç»´åˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼ŒGauSSmartæé«˜äº†ç¨€ç–åŒºåŸŸçš„è¦†ç›–ç‡å¹¶ä¿ç•™äº†ç²¾ç»†ç»“æ„ç»†èŠ‚ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„éªŒè¯è¡¨æ˜ï¼ŒGauSSmartåœ¨åœºæ™¯é‡å»ºæ–¹é¢ä¼˜äºä¼ ç»Ÿçš„é«˜æ–¯è´´å›¾æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.14270">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-096a025266934d1ffe54f10e907580e5" align="middle">
<img src="https://picx.zhimg.com/v2-ce10a941529e531a97f079066de5d6d9" align="middle">
<img src="https://picx.zhimg.com/v2-5410135cd5e523629df20d961f072fa8" align="middle">
<img src="https://picx.zhimg.com/v2-cf51a1426d76308cf72aa9b8477ee678" align="middle">
<img src="https://picx.zhimg.com/v2-f6e9c22b512063663f3d8690d02ff8f4" align="middle">
<img src="https://picx.zhimg.com/v2-669fe0349215e6435d5059ca30fbf691" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="SPHERE-Semantic-PHysical-Engaged-REpresentation-for-3D-Semantic-Scene-Completion"><a href="#SPHERE-Semantic-PHysical-Engaged-REpresentation-for-3D-Semantic-Scene-Completion" class="headerlink" title="SPHERE: Semantic-PHysical Engaged REpresentation for 3D Semantic Scene Completion"></a>SPHERE: Semantic-PHysical Engaged REpresentation for 3D Semantic Scene Completion</h2><p><strong>Authors:Zhiwen Yang, Yuxin Peng</strong></p>
<p>Camera-based 3D Semantic Scene Completion (SSC) is a critical task in autonomous driving systems, assessing voxel-level geometry and semantics for holistic scene perception. While existing voxel-based and plane-based SSC methods have achieved considerable progress, they struggle to capture physical regularities for realistic geometric details. On the other hand, neural reconstruction methods like NeRF and 3DGS demonstrate superior physical awareness, but suffer from high computational cost and slow convergence when handling large-scale, complex autonomous driving scenes, leading to inferior semantic accuracy. To address these issues, we propose the Semantic-PHysical Engaged REpresentation (SPHERE) for camera-based SSC, which integrates voxel and Gaussian representations for joint exploitation of semantic and physical information. First, the Semantic-guided Gaussian Initialization (SGI) module leverages dual-branch 3D scene representations to locate focal voxels as anchors to guide efficient Gaussian initialization. Then, the Physical-aware Harmonics Enhancement (PHE) module incorporates semantic spherical harmonics to model physical-aware contextual details and promote semantic-geometry consistency through focal distribution alignment, generating SSC results with realistic details. Extensive experiments and analyses on the popular SemanticKITTI and SSCBench-KITTI-360 benchmarks validate the effectiveness of SPHERE. The code is available at <a target="_blank" rel="noopener" href="https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025">https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025</a>.</p>
<blockquote>
<p>åŸºäºæ‘„åƒå¤´çš„ä¸‰ç»´è¯­ä¹‰åœºæ™¯è¡¥å…¨ï¼ˆSSCï¼‰æ˜¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ï¼Œå®ƒè¯„ä¼°ä½“ç´ çº§å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ä»¥å®ç°æ•´ä½“åœºæ™¯æ„ŸçŸ¥ã€‚å°½ç®¡ç°æœ‰çš„åŸºäºä½“ç´ å’ŒåŸºäºå¹³é¢çš„SSCæ–¹æ³•å·²ç»å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ï¼Œä½†å®ƒä»¬å¾ˆéš¾æ•æ‰åˆ°çœŸå®çš„å‡ ä½•ç»†èŠ‚çš„ç‰©ç†è§„å¾‹ã€‚å¦ä¸€æ–¹é¢ï¼ŒåƒNeRFå’Œ3DGSè¿™æ ·çš„ç¥ç»é‡å»ºæ–¹æ³•å…·æœ‰å‡ºè‰²çš„ç‰©ç†æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡ã€å¤æ‚çš„è‡ªåŠ¨é©¾é©¶åœºæ™¯æ—¶ï¼Œå®ƒä»¬è®¡ç®—æˆæœ¬è¾ƒé«˜ä¸”æ”¶æ•›ç¼“æ…¢ï¼Œå¯¼è‡´è¯­ä¹‰å‡†ç¡®æ€§è¾ƒä½ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºåŸºäºæ‘„åƒå¤´çš„SSCçš„è¯­ä¹‰ç‰©ç†å‚ä¸è¡¨ç¤ºï¼ˆSPHEREï¼‰ï¼Œå®ƒç»“åˆäº†ä½“ç´ å’Œé«˜æ–¯è¡¨ç¤ºï¼Œä»¥å…±åŒåˆ©ç”¨è¯­ä¹‰å’Œç‰©ç†ä¿¡æ¯ã€‚é¦–å…ˆï¼Œè¯­ä¹‰å¼•å¯¼çš„é«˜æ–¯åˆå§‹åŒ–ï¼ˆSGIï¼‰æ¨¡å—åˆ©ç”¨åŒåˆ†æ”¯ä¸‰ç»´åœºæ™¯è¡¨ç¤ºæ¥ç¡®å®šå…³é”®ä½“ç´ ä½œä¸ºé”šç‚¹æ¥å¼•å¯¼é«˜æ•ˆçš„é«˜æ–¯åˆå§‹åŒ–ã€‚ç„¶åï¼Œç‰©ç†æ„ŸçŸ¥çš„è°æ³¢å¢å¼ºï¼ˆPHEï¼‰æ¨¡å—å°†è¯­ä¹‰çƒé¢è°æ³¢çº³å…¥å…¶ä¸­ï¼Œä»¥æ¨¡æ‹Ÿç‰©ç†æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡ç»†èŠ‚ï¼Œå¹¶é€šè¿‡ç„¦ç‚¹åˆ†å¸ƒå¯¹é½æ¥ä¿ƒè¿›è¯­ä¹‰å‡ ä½•ä¸€è‡´æ€§ï¼Œç”Ÿæˆå…·æœ‰çœŸå®ç»†èŠ‚SSCç»“æœã€‚åœ¨æµè¡Œçš„SemanticKITTIå’ŒSSCBench-KITTI-360åŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå’Œåˆ†æéªŒè¯äº†SPHEREçš„æœ‰æ•ˆæ€§ã€‚ä»£ç å¯ä» <a target="_blank" rel="noopener" href="https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025">https://github.com/PKU-ICST-MIPL/SPHERE_ACMMM2025</a> è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11171v2">PDF</a> 10 pages, 6 figures, accepted by ACM MM 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†é’ˆå¯¹åŸºäºæ‘„åƒå¤´çš„ä¸‰ç»´è¯­ä¹‰åœºæ™¯å®Œæˆï¼ˆSSCï¼‰ä»»åŠ¡çš„æ–°æ–¹æ³•â€”â€”è¯­ä¹‰ç‰©ç†å‚ä¸è¡¨ç¤ºï¼ˆSPHEREï¼‰ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä½“ç´ å’Œé«˜æ–¯è¡¨ç¤ºï¼Œæ—¨åœ¨æé«˜è‡ªä¸»é©¾é©¶ç³»ç»Ÿä¸­å¯¹åœºæ™¯æ„ŸçŸ¥çš„å‡ ä½•å’Œè¯­ä¹‰ç²¾åº¦ã€‚é€šè¿‡åŒåˆ†æ”¯ä¸‰ç»´åœºæ™¯è¡¨ç¤ºå®šä½å…³é”®ä½“ç´ ä½œä¸ºé”šç‚¹ï¼Œå®ç°é«˜æ•ˆé«˜æ–¯åˆå§‹åŒ–ï¼Œå¹¶é‡‡ç”¨ç‰©ç†æ„ŸçŸ¥çš„çƒå½¢è°æ³¢å¢å¼ºæ¨¡å—ï¼Œä»¥ä¼˜åŒ–è¯­ä¹‰å‡ ä½•ä¸€è‡´æ€§ï¼Œæå‡æ„ŸçŸ¥ç»“æœçš„é€¼çœŸåº¦ã€‚åœ¨SemanticKITTIå’ŒSSCBench-KITTI-360ç­‰æµè¡ŒåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒéªŒè¯äº†SPHEREçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç›¸æœºåŸºäºçš„3Dè¯­ä¹‰åœºæ™¯å®Œæˆï¼ˆSSCï¼‰åœ¨è‡ªä¸»é©¾é©¶ç³»ç»Ÿä¸­æ˜¯å…³é”®ä»»åŠ¡ï¼Œæ¶‰åŠå¯¹æ•´ä¸ªåœºæ™¯è¿›è¡Œä½“ç´ çº§çš„å‡ ä½•å’Œè¯­ä¹‰æ„ŸçŸ¥ã€‚</li>
<li>ç°å­˜çš„åŸºäºä½“ç´ å’ŒåŸºäºå¹³é¢çš„SSCæ–¹æ³•è™½ç„¶æœ‰æ‰€è¿›å±•ï¼Œä½†åœ¨æ•æ‰ç‰©ç†è§„åˆ™å’Œç”ŸæˆçœŸå®å‡ ä½•ç»†èŠ‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ç¥ç»ç½‘ç»œé‡å»ºæ–¹æ³•å¦‚NeRFå’Œ3DGSå…·æœ‰å‡ºè‰²çš„ç‰©ç†æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡å¤æ‚è‡ªä¸»é©¾é©¶åœºæ™¯æ—¶è®¡ç®—æˆæœ¬é«˜ã€æ”¶æ•›æ…¢ï¼Œå¯¼è‡´è¯­ä¹‰ç²¾åº¦ä¸é«˜ã€‚</li>
<li>æå‡ºçš„Semantic-PHysical Engaged REpresentationï¼ˆSPHEREï¼‰æ–¹æ³•ç»“åˆäº†ä½“ç´ å’Œé«˜æ–¯è¡¨ç¤ºï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>SPHEREé€šè¿‡åŒåˆ†æ”¯3Dåœºæ™¯è¡¨ç¤ºå®šä½å…³é”®ä½“ç´ ä½œä¸ºé”šç‚¹ï¼Œè¿›è¡Œé«˜æ•ˆçš„é«˜æ–¯åˆå§‹åŒ–ã€‚</li>
<li>ç‰©ç†æ„ŸçŸ¥çš„çƒå½¢è°æ³¢å¢å¼ºæ¨¡å—èƒ½å¤Ÿæ¨¡æ‹Ÿç‰©ç†è§„åˆ™å¹¶ä¼˜åŒ–è¯­ä¹‰å‡ ä½•ä¸€è‡´æ€§ï¼Œæé«˜æ„ŸçŸ¥ç»“æœçš„é€¼çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11171">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-83353c7315d821eb5b4723920a8c0951" align="middle">
<img src="https://picx.zhimg.com/v2-0bc67af9a568fdf963c718222f16eb6a" align="middle">
<img src="https://picx.zhimg.com/v2-36710c5d06f8825c65944ecdbf41c210" align="middle">
<img src="https://picx.zhimg.com/v2-fed8f8aee9e81e701f7c5f99d1799302" align="middle">
<img src="https://picx.zhimg.com/v2-d73f7ea75551048ed008a399e07e53b6" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Multispectral-NeRF-a-multispectral-modeling-approach-based-on-neural-radiance-fields"><a href="#Multispectral-NeRF-a-multispectral-modeling-approach-based-on-neural-radiance-fields" class="headerlink" title="Multispectral-NeRF:a multispectral modeling approach based on neural radiance fields"></a>Multispectral-NeRF:a multispectral modeling approach based on neural radiance fields</h2><p><strong>Authors:Hong Zhang, Fei Guo, Zihan Xie, Dizhao Yao</strong></p>
<p>3D reconstruction technology generates three-dimensional representations of real-world objects, scenes, or environments using sensor data such as 2D images, with extensive applications in robotics, autonomous vehicles, and virtual reality systems. Traditional 3D reconstruction techniques based on 2D images typically relies on RGB spectral information. With advances in sensor technology, additional spectral bands beyond RGB have been increasingly incorporated into 3D reconstruction workflows. Existing methods that integrate these expanded spectral data often suffer from expensive scheme prices, low accuracy and poor geometric features. Three - dimensional reconstruction based on NeRF can effectively address the various issues in current multispectral 3D reconstruction methods, producing high - precision and high - quality reconstruction results. However, currently, NeRF and some improved models such as NeRFacto are trained on three - band data and cannot take into account the multi - band information. To address this problem, we propose Multispectral-NeRF, an enhanced neural architecture derived from NeRF that can effectively integrates multispectral information. Our technical contributions comprise threefold modifications: Expanding hidden layer dimensionality to accommodate 6-band spectral inputs; Redesigning residual functions to optimize spectral discrepancy calculations between reconstructed and reference images; Adapting data compression modules to address the increased bit-depth requirements of multispectral imagery. Experimental results confirm that Multispectral-NeRF successfully processes multi-band spectral features while accurately preserving the original scenesâ€™ spectral characteristics.</p>
<blockquote>
<p>3Dé‡å»ºæŠ€æœ¯åˆ©ç”¨äºŒç»´å›¾åƒç­‰ä¼ æ„Ÿå™¨æ•°æ®ç”ŸæˆçœŸå®ä¸–ç•Œç‰©ä½“ã€åœºæ™¯æˆ–ç¯å¢ƒçš„ä¸‰ç»´è¡¨ç¤ºï¼Œåœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶æ±½è½¦å’Œè™šæ‹Ÿç°å®ç³»ç»Ÿç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚ä¼ ç»Ÿçš„åŸºäºäºŒç»´å›¾åƒçš„3Dé‡å»ºæŠ€æœ¯é€šå¸¸ä¾èµ–äºRGBå…‰è°±ä¿¡æ¯ã€‚éšç€ä¼ æ„Ÿå™¨æŠ€æœ¯çš„è¿›æ­¥ï¼Œé™¤äº†RGBä¹‹å¤–çš„å…¶ä»–å…‰è°±æ³¢æ®µå·²è¢«è¶Šæ¥è¶Šå¤šåœ°èå…¥åˆ°3Dé‡å»ºå·¥ä½œæµç¨‹ä¸­ã€‚ç°æœ‰èåˆè¿™äº›æ‰©å±•å…‰è°±æ•°æ®çš„æ–¹æ³•å¸¸å¸¸é¢ä¸´æˆæœ¬é«˜æ˜‚ã€ç²¾åº¦ä½ã€å‡ ä½•ç‰¹å¾å·®ç­‰é—®é¢˜ã€‚åŸºäºNeRFçš„ä¸‰ç»´é‡å»ºå¯ä»¥æœ‰æ•ˆè§£å†³å½“å‰å¤šå…‰è°±3Dé‡å»ºæ–¹æ³•çš„å„ç§é—®é¢˜ï¼Œäº§ç”Ÿé«˜ç²¾åº¦é«˜è´¨é‡çš„é‡å»ºç»“æœã€‚ç„¶è€Œï¼Œç›®å‰NeRFå’Œä¸€äº›æ”¹è¿›æ¨¡å‹å¦‚NeRFactoéƒ½æ˜¯åœ¨ä¸‰æ³¢æ®µæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ— æ³•è€ƒè™‘å¤šæ³¢æ®µä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Multispectral-NeRFï¼Œè¿™æ˜¯ä¸€ç§æºäºNeRFçš„å¢å¼ºå‹ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¯ä»¥æœ‰æ•ˆæ•´åˆå¤šå…‰è°±ä¿¡æ¯ã€‚æˆ‘ä»¬çš„æŠ€æœ¯è´¡çŒ®åŒ…æ‹¬ä¸‰æ–¹é¢æ”¹è¿›ï¼šæ‰©å±•éšè—å±‚çš„ç»´åº¦ä»¥é€‚åº”å…­æ³¢æ®µå…‰è°±è¾“å…¥ï¼›é‡æ–°è®¾è®¡æ®‹å·®å‡½æ•°ï¼Œä»¥ä¼˜åŒ–é‡å»ºå›¾åƒå’Œå‚è€ƒå›¾åƒä¹‹é—´çš„å…‰è°±å·®å¼‚è®¡ç®—ï¼›é€‚åº”æ•°æ®å‹ç¼©æ¨¡å—ï¼Œä»¥è§£å†³å¤šå…‰è°±å›¾åƒå¢åŠ çš„ä½æ·±åº¦è¦æ±‚ã€‚å®éªŒç»“æœè¯å®ï¼ŒMultispectral-NeRFæˆåŠŸå¤„ç†äº†å¤šæ³¢æ®µå…‰è°±ç‰¹å¾ï¼ŒåŒæ—¶å‡†ç¡®ä¿ç•™äº†åŸå§‹åœºæ™¯çš„å…‰è°±ç‰¹æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11169v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºNeRFçš„ä¸‰ç»´é‡å»ºæŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆèåˆå¤šå…‰è°±ä¿¡æ¯ï¼Œè§£å†³ç°æœ‰å¤šå…‰è°±ä¸‰ç»´é‡å»ºæ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚æˆæœ¬é«˜ã€ç²¾åº¦ä½ã€å‡ ä½•ç‰¹å¾å·®ç­‰ã€‚æœ¬æ–‡é€šè¿‡æ‰©å±•éšè—å±‚ç»´åº¦ã€é‡æ–°è®¾è®¡æ®‹å·®å‡½æ•°ä»¥åŠé€‚åº”æ•°æ®å‹ç¼©æ¨¡å—ç­‰æŠ€æœ¯æ‰‹æ®µï¼Œæå‡ºäº†ä¸€ç§åä¸ºMultispectral-NeRFçš„å¢å¼ºå‹ç¥ç»ç½‘ç»œæ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMultispectral-NeRFèƒ½å¤ŸæˆåŠŸå¤„ç†å¤šæ³¢æ®µå…‰è°±ç‰¹å¾ï¼ŒåŒæ—¶å‡†ç¡®ä¿ç•™åŸå§‹åœºæ™¯çš„å…‰è°±ç‰¹æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRFæŠ€æœ¯ç”¨äºä¸‰ç»´é‡å»ºå¯æœ‰æ•ˆè§£å†³å½“å‰å¤šå…‰è°±ä¸‰ç»´é‡å»ºæ–¹æ³•ä¸­å­˜åœ¨çš„é—®é¢˜ã€‚</li>
<li>Multispectral-NeRFæ˜¯ä¸€ç§åŸºäºNeRFçš„å¢å¼ºå‹ç¥ç»ç½‘ç»œæ¶æ„ï¼Œèƒ½å¤Ÿèåˆå¤šå…‰è°±ä¿¡æ¯ã€‚</li>
<li>Multispectral-NeRFé€šè¿‡æ‰©å±•éšè—å±‚ç»´åº¦æ¥é€‚åº”6æ³¢æ®µå…‰è°±è¾“å…¥ã€‚</li>
<li>è¯¥æŠ€æœ¯é‡æ–°è®¾è®¡äº†æ®‹å·®å‡½æ•°ï¼Œä»¥ä¼˜åŒ–é‡å»ºå›¾åƒä¸å‚è€ƒå›¾åƒä¹‹é—´çš„å…‰è°±å·®å¼‚è®¡ç®—ã€‚</li>
<li>æ•°æ®å‹ç¼©æ¨¡å—è¢«æ”¹ç¼–ä»¥é€‚åº”å¤šå…‰è°±å½±åƒå¢åŠ çš„ä½æ·±åº¦éœ€æ±‚ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒMultispectral-NeRFèƒ½å¤ŸæˆåŠŸå¤„ç†å¤šæ³¢æ®µå…‰è°±ç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11169">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6e0fda2838f62df23ae8e92fdfdec1a9" align="middle">
<img src="https://picx.zhimg.com/v2-67a266e2ba5571193c820eaf9e17dc8c" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-16/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-16/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-16/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-78be9d29ee5d64ce3b0b6b95e241ffc0" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-16  VLF-MSC Vision-Language Feature-Based Multimodal Semantic Communication System
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-16/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-096a025266934d1ffe54f10e907580e5" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-16  Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33125.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
