<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-20  GOUHFI a novel contrast- and resolution-agnostic segmentation tool for   Ultra-High Field MRI">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-d7635e32016c1ff643bb2aff7cc428ab.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-27
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    42 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-20-æ›´æ–°"><a href="#2025-05-20-æ›´æ–°" class="headerlink" title="2025-05-20 æ›´æ–°"></a>2025-05-20 æ›´æ–°</h1><h2 id="GOUHFI-a-novel-contrast-and-resolution-agnostic-segmentation-tool-for-Ultra-High-Field-MRI"><a href="#GOUHFI-a-novel-contrast-and-resolution-agnostic-segmentation-tool-for-Ultra-High-Field-MRI" class="headerlink" title="GOUHFI: a novel contrast- and resolution-agnostic segmentation tool for   Ultra-High Field MRI"></a>GOUHFI: a novel contrast- and resolution-agnostic segmentation tool for   Ultra-High Field MRI</h2><p><strong>Authors:Marc-Antoine Fortin, Anne Louise Kristoffersen, Michael Staff Larsen, Laurent Lamalle, Ruediger Stirnberg, Paal Erik Goa</strong></p>
<p>Recently, Ultra-High Field MRI (UHF-MRI) has become more available and one of the best tools to study the brain. One common step in quantitative neuroimaging is the brain segmentation. However, the differences between UHF-MRI and 1.5-3T images are such that the automatic segmentation techniques optimized at these field strengths usually produce unsatisfactory segmentation results for UHF images. It has been particularly challenging to perform quantitative analyses as typically done with 1.5-3T data, considerably limiting the potential of UHF-MRI. Hence, we propose a novel Deep Learning (DL)-based segmentation technique called GOUHFI: Generalized and Optimized segmentation tool for Ultra-High Field Images, designed to segment UHF images of various contrasts and resolutions. For training, we used a total of 206 label maps from four datasets acquired at 3T, 7T and 9.4T. In contrast to most DL strategies, we used a previously proposed domain randomization approach, where synthetic images generated from the label maps were used for training a 3D U-Net. GOUHFI was tested on seven different datasets and compared to techniques like FastSurferVINN and CEREBRUM-7T. GOUHFI was able to the segment six contrasts and seven resolutions tested at 3T, 7T and 9.4T. Average Dice-Sorensen Similarity Coefficient (DSC) scores of 0.87, 0.84, 0.91 were computed against the ground truth segmentations at 3T, 7T and 9.4T. Moreover, GOUHFI demonstrated impressive resistance to the typical inhomogeneities observed at UHF-MRI, making it a new powerful segmentation tool that allows to apply the usual quantitative analysis pipelines also at UHF. Ultimately, GOUHFI is a promising new segmentation tool, being the first of its kind proposing a contrast- and resolution-agnostic alternative for UHF-MRI, making it the forthcoming alternative for neuroscientists working with UHF-MRI or even lower field strengths. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œè¶…é«˜åœºç£å…±æŒ¯æˆåƒï¼ˆUHF-MRIï¼‰å˜å¾—è¶Šæ¥è¶Šæ™®åŠï¼Œå·²æˆä¸ºç ”ç©¶å¤§è„‘çš„æœ€ä½³å·¥å…·ä¹‹ä¸€ã€‚å®šé‡ç¥ç»å½±åƒå­¦ä¸­çš„ä¸€ä¸ªå¸¸è§æ­¥éª¤æ˜¯å¤§è„‘åˆ†å‰²ã€‚ç„¶è€Œï¼ŒUHF-MRIä¸1.5-3Tå›¾åƒä¹‹é—´çš„å·®å¼‚ä½¿å¾—é’ˆå¯¹è¿™äº›åœºå¼ºä¼˜åŒ–çš„è‡ªåŠ¨åˆ†å‰²æŠ€æœ¯é€šå¸¸ä¼šäº§ç”Ÿä»¤äººä¸æ»¡æ„çš„UHFå›¾åƒåˆ†å‰²ç»“æœã€‚ä½¿ç”¨é€šå¸¸ç”¨äº1.5-3Tæ•°æ®çš„å®šé‡åˆ†ææ–¹æ³•å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè¿™æå¤§åœ°é™åˆ¶äº†UHF-MRIçš„æ½œåŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å‰²æŠ€æœ¯ï¼Œç§°ä¸ºGOUHFIï¼šé€‚ç”¨äºè¶…é«˜åœºå›¾åƒçš„é€šç”¨ä¼˜åŒ–åˆ†å‰²å·¥å…·ï¼Œæ—¨åœ¨åˆ†å‰²å…·æœ‰å„ç§å¯¹æ¯”åº¦å’Œåˆ†è¾¨ç‡çš„UHFå›¾åƒã€‚ä¸ºäº†è®­ç»ƒï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»3Tã€7Tå’Œ9.4Té‡‡é›†çš„å››ä¸ªæ•°æ®é›†çš„å…±206ä¸ªæ ‡ç­¾å›¾ã€‚ä¸å¤§å¤šæ•°æ·±åº¦å­¦ä¹ ç­–ç•¥ä¸åŒï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…ˆå‰æå‡ºçš„åŸŸéšæœºåŒ–æ–¹æ³•ï¼Œå…¶ä¸­æ ¹æ®æ ‡ç­¾å›¾ç”Ÿæˆçš„åˆæˆå›¾åƒç”¨äºè®­ç»ƒ3D U-Netã€‚GOUHFIåœ¨ä¸ƒä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶ä¸FastSurferVINNå’ŒCEREBRUM-7Tç­‰æŠ€æœ¯è¿›è¡Œäº†æ¯”è¾ƒã€‚GOUHFIèƒ½å¤Ÿåœ¨3Tã€7Tå’Œ9.4Tæµ‹è¯•çš„å…­ç§å¯¹æ¯”åº¦å’Œä¸ƒç§åˆ†è¾¨ç‡ä¸‹è¿›è¡Œåˆ†å‰²ã€‚ä¸3Tã€7Tå’Œ9.4Tçš„åŸºå‡†åˆ†å‰²ç›¸æ¯”ï¼Œè®¡ç®—å‡ºçš„å¹³å‡Dice-Sorensenç›¸ä¼¼ç³»æ•°ï¼ˆDSCï¼‰åˆ†æ•°åˆ†åˆ«ä¸º0.87ã€0.84ã€0.91ã€‚æ­¤å¤–ï¼ŒGOUHFIå¯¹UHF-MRIä¸­å¸¸è§çš„éå‡åŒ€æ€§è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æŠ—æ€§ï¼Œæˆä¸ºäº†ä¸€ç§å¼ºå¤§çš„æ–°åˆ†å‰²å·¥å…·ï¼Œå…è®¸åœ¨UHFä¸Šåº”ç”¨é€šå¸¸çš„å®šé‡åˆ†ææµæ°´çº¿ã€‚æœ€ç»ˆï¼ŒGOUHFIæ˜¯ä¸€ç§æœ‰å‰é€”çš„æ–°åˆ†å‰²å·¥å…·ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªæå‡ºé€‚ç”¨äºUHF-MRIçš„å¯¹æ¯”åº¦å’Œåˆ†è¾¨ç‡æ— å…³æ›¿ä»£æ–¹æ¡ˆçš„å·¥å…·ï¼Œä½¿å…¶æˆä¸ºä»äº‹UHF-MRIç ”ç©¶çš„ç¥ç»ç§‘å­¦å®¶æˆ–ç”šè‡³ä½¿ç”¨è¾ƒä½åœºå¼ºçš„ç§‘å­¦å®¶çš„æœªæ¥æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11445v1">PDF</a> 45 pages, 9 Figures, 6 Tables, Submitted to Imaging Neuroscience on   16-05-25</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–°å‹è¶…é«˜é¢‘ç£å…±æŒ¯æˆåƒï¼ˆUHF-MRIï¼‰åˆ†å‰²å·¥å…·GOUHFIã€‚è¯¥å·¥å…·å¯ç”¨äºå¯¹å„ç§å¯¹æ¯”åº¦å’Œåˆ†è¾¨ç‡çš„UHFå›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œå¹¶é€šè¿‡ä½¿ç”¨åˆæˆå›¾åƒè¿›è¡Œè®­ç»ƒæ¥æé«˜æ€§èƒ½ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæµ‹è¯•åï¼ŒGOUHFIå±•ç°å‡ºè‰¯å¥½çš„åˆ†å‰²æ•ˆæœï¼Œå¹¶å…·æœ‰è¾ƒé«˜çš„æŠµæŠ—UHF-MRIå¸¸è§çš„ä¸å‡åŒ€æ€§èƒ½åŠ›ã€‚å®ƒä¸ºç¥ç»ç§‘å­¦å®¶æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„æ–°å·¥å…·ï¼Œå¯ä½œä¸ºè¶…é«˜é¢‘å’Œè¾ƒä½åœºå¼ºçš„MRIçš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UHF-MRIå·²æˆä¸ºç ”ç©¶å¤§è„‘çš„æœ€ä½³å·¥å…·ä¹‹ä¸€ï¼Œä½†åœ¨å®šé‡åˆ†æä¸­é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>è‡ªåŠ¨åˆ†å‰²æŠ€æœ¯åœ¨è¶…é«˜åœºMRIä¸Šä¼˜åŒ–é€šå¸¸äº§ç”Ÿä¸æ»¡æ„çš„åˆ†å‰²ç»“æœã€‚</li>
<li>GOUHFIæ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„æ–°å‹åˆ†å‰²å·¥å…·ï¼Œæ—¨åœ¨è§£å†³UHFå›¾åƒçš„åˆ†å‰²é—®é¢˜ã€‚</li>
<li>GOUHFIå¯ç”¨äºå¤šç§å¯¹æ¯”åº¦å’Œåˆ†è¾¨ç‡çš„UHFå›¾åƒåˆ†å‰²ã€‚</li>
<li>ä½¿ç”¨åˆæˆå›¾åƒè¿›è¡Œè®­ç»ƒï¼Œæé«˜GOUHFIçš„æ€§èƒ½ã€‚</li>
<li>GOUHFIåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„åˆ†å‰²æ•ˆæœï¼Œå¹¶å…·æœ‰è¾ƒé«˜çš„æŠµæŠ—UHF-MRIä¸å‡åŒ€æ€§çš„èƒ½åŠ›ã€‚</li>
<li>GOUHFIä¸ºç¥ç»ç§‘å­¦å®¶æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„æ–°å·¥å…·ï¼Œå¯åº”ç”¨äºè¶…é«˜é¢‘å’Œè¾ƒä½åœºå¼ºçš„MRIåˆ†æã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11445">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-73572fa160f532c0fc70cfaf7d3892c6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c448197cc3a62d77fdb5c156cb25ff7c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Diff-Unfolding-A-Model-Based-Score-Learning-Framework-for-Inverse-Problems"><a href="#Diff-Unfolding-A-Model-Based-Score-Learning-Framework-for-Inverse-Problems" class="headerlink" title="Diff-Unfolding: A Model-Based Score Learning Framework for Inverse   Problems"></a>Diff-Unfolding: A Model-Based Score Learning Framework for Inverse   Problems</h2><p><strong>Authors:Yuanhao Wang, Shirin Shoushtari, Ulugbek S. Kamilov</strong></p>
<p>Diffusion models are extensively used for modeling image priors for inverse problems. We introduce \emph{Diff-Unfolding}, a principled framework for learning posterior score functions of \emph{conditional diffusion models} by explicitly incorporating the physical measurement operator into a modular network architecture. Diff-Unfolding formulates posterior score learning as the training of an unrolled optimization scheme, where the measurement model is decoupled from the learned image prior. This design allows our method to generalize across inverse problems at inference time by simply replacing the forward operator without retraining. We theoretically justify our unrolling approach by showing that the posterior score can be derived from a composite model-based optimization formulation. Extensive experiments on image restoration and accelerated MRI show that Diff-Unfolding achieves state-of-the-art performance, improving PSNR by up to 2 dB and reducing LPIPS by $22.7%$, while being both compact (47M parameters) and efficient (0.72 seconds per $256 \times 256$ image). An optimized C++&#x2F;LibTorch implementation further reduces inference time to 0.63 seconds, underscoring the practicality of our approach. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹è¢«å¹¿æ³›ç”¨äºé€†å‘é—®é¢˜çš„å›¾åƒå…ˆéªŒå»ºæ¨¡ã€‚æˆ‘ä»¬ä»‹ç»äº†â€Diff-Unfoldingâ€ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡æ˜ç¡®åœ°å°†ç‰©ç†æµ‹é‡ç®—å­èå…¥æ¨¡å—åŒ–ç½‘ç»œæ¶æ„æ¥å­¦ä¹ â€æ¡ä»¶æ‰©æ•£æ¨¡å‹â€çš„åéªŒè¯„åˆ†å‡½æ•°çš„åŸç†æ€§æ¡†æ¶ã€‚Diff-Unfoldingå°†åéªŒè¯„åˆ†å­¦ä¹ åˆ¶å®šä¸ºå±•å¼€ä¼˜åŒ–æ–¹æ¡ˆçš„è®­ç»ƒï¼Œå…¶ä¸­æµ‹é‡æ¨¡å‹ä¸å­¦ä¹ çš„å›¾åƒå…ˆéªŒè§£è€¦ã€‚è¿™ç§è®¾è®¡ä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨ç†æ—¶é€šè¿‡ç®€å•åœ°æ›¿æ¢æ­£å‘ç®—å­è€Œæ³›åŒ–åˆ°å„ç§é€†å‘é—®é¢˜ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚æˆ‘ä»¬é€šè¿‡ç†è®ºè¯æ˜ï¼Œä»åŸºäºå¤åˆæ¨¡å‹çš„ä¼˜åŒ–å…¬å¼ä¸­å¯ä»¥æ¨å¯¼å‡ºåéªŒè¯„åˆ†ï¼Œä»è€Œè¯æ˜æˆ‘ä»¬çš„å±•å¼€æ–¹æ³•æ˜¯åˆç†çš„ã€‚åœ¨å›¾åƒæ¢å¤å’ŒåŠ é€ŸMRIçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDiff-Unfoldingè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒPSNRæé«˜äº†é«˜è¾¾2åˆ†è´ï¼ŒLPIPSé™ä½äº†22.7%ï¼ŒåŒæ—¶æ—¢ç´§å‡‘ï¼ˆ47Må‚æ•°ï¼‰åˆé«˜æ•ˆï¼ˆæ¯å¼ 256x256å›¾åƒ0.72ç§’ï¼‰ã€‚ç»è¿‡ä¼˜åŒ–çš„C++&#x2F;LibTorchå®ç°è¿›ä¸€æ­¥å°†æ¨ç†æ—¶é—´ç¼©çŸ­è‡³0.63ç§’ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬æ–¹æ³•çš„å®ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11393v1">PDF</a> 19 pages, 13 figures,</p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹å¹¿æ³›ç”¨äºå›¾åƒå…ˆéªŒå»ºæ¨¡ä¸­çš„åé—®é¢˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºDiff-Unfoldingçš„ç†è®ºæ¡†æ¶ï¼Œå®ƒé€šè¿‡æ˜ç¡®åœ°å°†ç‰©ç†æµ‹é‡ç®—å­èå…¥æ¨¡å—åŒ–ç½‘ç»œæ¶æ„ï¼Œå­¦ä¹ æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„åéªŒå¾—åˆ†å‡½æ•°ã€‚Diff-Unfoldingå°†åéªŒå¾—åˆ†å­¦ä¹ å…¬å¼åŒ–ä¸ºä¸€ç§å±•å¼€çš„ä¼˜åŒ–æ–¹æ¡ˆè®­ç»ƒï¼Œå°†æµ‹é‡æ¨¡å‹ä¸å­¦ä¹ çš„å›¾åƒå…ˆéªŒè§£è€¦ã€‚è¿™ç§è®¾è®¡ä½¿æˆ‘ä»¬åœ¨æ¨ç†æ—¶èƒ½çµæ´»åº”å¯¹ä¸åŒçš„åé—®é¢˜ï¼Œåªéœ€æ›¿æ¢å‰å‘ç®—å­è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚æœ¬æ–‡ç†è®ºè¯æ˜äº†å±•å¼€æ–¹æ³•çš„åˆç†æ€§ï¼Œå³é€šè¿‡å¤åˆæ¨¡å‹ä¸ºåŸºç¡€çš„ä¼˜åŒ–å…¬å¼æ¨å¯¼åéªŒå¾—åˆ†ã€‚åœ¨å›¾åƒæ¢å¤å’ŒåŠ é€ŸMRIçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDiff-Unfoldingè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒPSNRæé«˜äº†é«˜è¾¾2åˆ†è´ï¼ŒLPIPSé™ä½äº†22.7%ï¼ŒåŒæ—¶æ¨¡å‹ç´§å‡‘ï¼ˆ47Må‚æ•°ï¼‰ä¸”é«˜æ•ˆï¼ˆæ¯å¤„ç†ä¸€å¼ 256x256å›¾åƒéœ€0.72ç§’ï¼‰ã€‚ä½¿ç”¨ä¼˜åŒ–çš„C++&#x2F;LibTorchå®ç°è¿›ä¸€æ­¥å°†æ¨ç†æ—¶é—´ç¼©çŸ­è‡³0.63ç§’ï¼Œå‡¸æ˜¾äº†æ–¹æ³•çš„å®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å¹¿æ³›åº”ç”¨äºå›¾åƒå…ˆéªŒå»ºæ¨¡ä¸­çš„åé—®é¢˜ã€‚</li>
<li>æå‡ºäº†Diff-Unfoldingæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆç‰©ç†æµ‹é‡ç®—å­å­¦ä¹ æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„åéªŒå¾—åˆ†å‡½æ•°ã€‚</li>
<li>Diff-Unfoldingå°†åéªŒå¾—åˆ†å­¦ä¹ è¡¨è¿°ä¸ºä¸€ç§å±•å¼€çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œå®ç°äº†æµ‹é‡æ¨¡å‹ä¸å›¾åƒå…ˆéªŒçš„è§£è€¦ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µèƒ½çµæ´»åº”ç”¨äºå¤šç§åé—®é¢˜ï¼Œåªéœ€æ›¿æ¢å‰å‘ç®—å­ã€‚</li>
<li>ç†è®ºè¯æ˜äº†å±•å¼€æ–¹æ³•çš„åˆç†æ€§ï¼Œå³é€šè¿‡å¤åˆæ¨¡å‹ä¼˜åŒ–å…¬å¼æ¨å¯¼åéªŒå¾—åˆ†ã€‚</li>
<li>åœ¨å›¾åƒæ¢å¤å’ŒåŠ é€ŸMRIçš„å®éªŒä¸­ï¼ŒDiff-Unfoldingè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒPSNRå’ŒLPIPSæŒ‡æ ‡å‡æœ‰æ˜¾è‘—æ”¹å–„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11393">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-04b9c048e970fcdc1b0fc52ffeadf311.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f52cd10c2dafc88b564eda5be73ab756.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f229547ab1e8b09f50ade0a81de0e993.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1af47e187b5eba2348d82be4c653679.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d38ed3dab3d308f856365fb915c5e590.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CheX-DS-Improving-Chest-X-ray-Image-Classification-with-Ensemble-Learning-Based-on-DenseNet-and-Swin-Transformer"><a href="#CheX-DS-Improving-Chest-X-ray-Image-Classification-with-Ensemble-Learning-Based-on-DenseNet-and-Swin-Transformer" class="headerlink" title="CheX-DS: Improving Chest X-ray Image Classification with Ensemble   Learning Based on DenseNet and Swin Transformer"></a>CheX-DS: Improving Chest X-ray Image Classification with Ensemble   Learning Based on DenseNet and Swin Transformer</h2><p><strong>Authors:Xinran Li, Yu Liu, Xiujuan Xu, Xiaowei Zhao</strong></p>
<p>The automatic diagnosis of chest diseases is a popular and challenging task. Most current methods are based on convolutional neural networks (CNNs), which focus on local features while neglecting global features. Recently, self-attention mechanisms have been introduced into the field of computer vision, demonstrating superior performance. Therefore, this paper proposes an effective model, CheX-DS, for classifying long-tail multi-label data in the medical field of chest X-rays. The model is based on the excellent CNN model DenseNet for medical imaging and the newly popular Swin Transformer model, utilizing ensemble deep learning techniques to combine the two models and leverage the advantages of both CNNs and Transformers. The loss function of CheX-DS combines weighted binary cross-entropy loss with asymmetric loss, effectively addressing the issue of data imbalance. The NIH ChestX-ray14 dataset is selected to evaluate the modelâ€™s effectiveness. The model outperforms previous studies with an excellent average AUC score of 83.76%, demonstrating its superior performance. </p>
<blockquote>
<p>èƒ¸éƒ¨ç–¾ç—…çš„è‡ªåŠ¨è¯Šæ–­æ˜¯ä¸€é¡¹å—æ¬¢è¿ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å½“å‰å¤§å¤šæ•°æ–¹æ³•éƒ½æ˜¯åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰ï¼Œè¿™äº›ç½‘ç»œä¸“æ³¨äºå±€éƒ¨ç‰¹å¾è€Œå¿½ç•¥äº†å…¨å±€ç‰¹å¾ã€‚æœ€è¿‘ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸå¼•å…¥äº†è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ¨¡å‹CheX-DSï¼Œç”¨äºåŒ»å­¦é¢†åŸŸèƒ¸éƒ¨Xå°„çº¿é•¿å°¾å¤šæ ‡ç­¾æ•°æ®çš„åˆ†ç±»ã€‚è¯¥æ¨¡å‹åŸºäºä¼˜ç§€çš„åŒ»å­¦æˆåƒDenseNetæ¨¡å‹å’Œç›®å‰æµè¡Œçš„Swin Transformeræ¨¡å‹ï¼Œé‡‡ç”¨é›†æˆæ·±åº¦å­¦ä¹ æŠ€æœ¯ç»“åˆè¿™ä¸¤ç§æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œå……åˆ†åˆ©ç”¨CNNå’ŒTransformerçš„ä¼˜ç‚¹ã€‚CheX-DSçš„æŸå¤±å‡½æ•°ç»“åˆäº†åŠ æƒäºŒå…ƒäº¤å‰ç†µæŸå¤±å’Œä¸å¯¹ç§°æŸå¤±ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†æ•°æ®ä¸å¹³è¡¡çš„é—®é¢˜ã€‚é€‰ç”¨NIH ChestX-ray14æ•°æ®é›†å¯¹æ¨¡å‹çš„æœ‰æ•ˆæ€§è¿›è¡Œè¯„ä¼°ã€‚è¯¥æ¨¡å‹çš„å¹³å‡AUCå¾—åˆ†é«˜è¾¾83.76%ï¼Œè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¶…è¿‡äº†ä»¥å‰çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11168v1">PDF</a> BIBM</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å‹CheX-DSï¼Œç”¨äºè¯Šæ–­èƒ¸éƒ¨ç–¾ç—…ã€‚è¯¥æ¨¡å‹ç»“åˆäº†DenseNetå’ŒSwin Transformeræ¨¡å‹çš„ä¼˜åŠ¿ï¼Œåˆ©ç”¨é›†æˆæ·±åº¦å­¦ä¹ æŠ€æœ¯è¿›è¡Œåˆ†ç±»ã€‚æ¨¡å‹çš„æŸå¤±å‡½æ•°ç»“åˆäº†åŠ æƒäºŒå…ƒäº¤å‰ç†µæŸå¤±å’Œä¸å¯¹ç§°æŸå¤±ï¼Œä»¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚åœ¨NIH ChestX-ray14æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å…·æœ‰å‡ºè‰²çš„å¹³å‡AUCå¾—åˆ†ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰è¯Šæ–­èƒ¸éƒ¨ç–¾ç—…çš„æ–¹æ³•å¤§å¤šåŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰ï¼Œä½†å¿½ç•¥äº†å…¨å±€ç‰¹å¾ã€‚</li>
<li>è‡ªæ³¨æ„åŠ›æœºåˆ¶åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸè¢«å¼•å…¥ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</li>
<li>CheX-DSæ¨¡å‹ç»“åˆäº†DenseNetæ¨¡å‹å’ŒSwin Transformeræ¨¡å‹çš„ä¼˜åŠ¿ã€‚</li>
<li>CheX-DSæ¨¡å‹çš„æŸå¤±å‡½æ•°ç»“åˆäº†åŠ æƒäºŒå…ƒäº¤å‰ç†µæŸå¤±å’Œä¸å¯¹ç§°æŸå¤±ï¼Œä»¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
<li>CheX-DSæ¨¡å‹åœ¨NIH ChestX-ray14æ•°æ®é›†ä¸Šçš„å¹³å‡AUCå¾—åˆ†ä¸º83.76%ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†åŒ»å­¦é¢†åŸŸçš„é•¿å°¾å¤šæ ‡ç­¾æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11168">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c1a044421981ae89af75da41039a817c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-816a44117eea6c8f973214d038d744fb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d7635e32016c1ff643bb2aff7cc428ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-271c7fb72c2a3460b664bc65eddf4b69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-495a25bd1d970c4786cecb71745572fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0eb75744439aadfa8949655c8d53a01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5585810bd3d9e70fd7a9b077b50eb75e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba0c25216a9b8fae75fd5dec1eb760d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db491cdd57b375dfcfe62e2033a809ce.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Controlling-spatial-correlation-in-k-space-interpolation-networks-for-MRI-reconstruction-denoising-versus-apparent-blurring"><a href="#Controlling-spatial-correlation-in-k-space-interpolation-networks-for-MRI-reconstruction-denoising-versus-apparent-blurring" class="headerlink" title="Controlling spatial correlation in k-space interpolation networks for   MRI reconstruction: denoising versus apparent blurring"></a>Controlling spatial correlation in k-space interpolation networks for   MRI reconstruction: denoising versus apparent blurring</h2><p><strong>Authors:Istvan Homolya, Peter Dawood, Jannik Stebani, Felix Breuer, Grit Hein, Matthias Gamer, Florian Knoll, Martin Blaimer</strong></p>
<p>Purpose: To improve the interpretability of noise amplification and apparent blurring of k-space interpolation networks, and to optimize for them in the loss function as a model-based regularizer in k-space interpolation networks.   Methods: Network is subjected to noise amplification analysis through automatic differentiation of the input with respect to the input. Noise variance maps are decomposed into terms accounting for the linear and nonlinear characteristics of the network. Variance maps are derived in each iteration, allowing for runtime quality monitoring. Maximum variance (eigenpixel) and residual variance maps (pixel contamination) are introduced, which describe the network noise amplification and apparent blurring, respectively. By including the variance maps in the training, the loss function is enriched with a model-based regularizer beyond the k-space data consistency term. Accordingly, the proposed g-factor-informed RAKI (GIF-RAKI) establishes a recurrent flow of noise and apparent blurring information into the training, that drives the denoising via the trainable nonlinear activation function.   Results: GIF-RAKI outperforms other RAKI implementations, supported by difference maps, and image quality metrics. Eigenpixel and pixel contamination maps provide quantitative metrics for noise amplification and apparent blurring, respectively, without the need for a gold standard reference. RAKI with tuneable Leaky ReLU is capable of adjusting its own nonlinearity automatically.   Conclusion: The additional model-based loss terms allow to optimize for the trade-off between denoising and apparent blurring during RAKI training. This has the potential to eliminate the need for heuristic hyperparameter tweaking. </p>
<blockquote>
<p>ç›®çš„ï¼šæ—¨åœ¨æé«˜kç©ºé—´æ’å€¼ç½‘ç»œçš„å™ªå£°æ”¾å¤§å’Œæ˜æ˜¾æ¨¡ç³Šåº¦çš„å¯è§£é‡Šæ€§ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¯¹å®ƒä»¬è¿›è¡Œä¼˜åŒ–ï¼Œä½œä¸ºkç©ºé—´æ’å€¼ç½‘ç»œçš„åŸºäºæ¨¡å‹çš„æ­£è§„åŒ–å™¨ã€‚æ–¹æ³•ï¼šç½‘ç»œé€šè¿‡è¾“å…¥ç›¸å¯¹äºè‡ªèº«çš„è‡ªåŠ¨å¾®åˆ†æ¥è¿›è¡Œå™ªå£°æ”¾å¤§åˆ†æã€‚å™ªå£°æ–¹å·®å›¾è¢«åˆ†è§£æˆåæ˜ ç½‘ç»œçº¿æ€§ç‰¹å¾å’Œéçº¿æ€§ç‰¹å¾çš„é¡¹ã€‚æ¯æ¬¡è¿­ä»£éƒ½ä¼šæ¨å¯¼å‡ºæ–¹å·®å›¾ï¼Œä»è€Œå®ç°è¿è¡Œæ—¶è´¨é‡ç›‘æ§ã€‚å¼•å…¥äº†æœ€å¤§æ–¹å·®ï¼ˆç‰¹å¾åƒç´ ï¼‰å’Œæ®‹å·®æ–¹å·®å›¾ï¼ˆåƒç´ æ±¡æŸ“ï¼‰ï¼Œåˆ†åˆ«æè¿°ç½‘ç»œå™ªå£°æ”¾å¤§å’Œæ˜æ˜¾æ¨¡ç³Šåº¦ã€‚é€šè¿‡å°†æ–¹å·®å›¾çº³å…¥è®­ç»ƒï¼ŒæŸå¤±å‡½æ•°é™¤äº†kç©ºé—´æ•°æ®ä¸€è‡´æ€§é¡¹ä¹‹å¤–ï¼Œè¿˜åŒ…å«äº†åŸºäºæ¨¡å‹çš„æ­£è§„åŒ–å™¨ã€‚å› æ­¤ï¼Œæ‰€æå‡ºçš„gå› å­ä¿¡æ¯RAKIï¼ˆGIF-RAKIï¼‰å°†å™ªå£°å’Œæ˜æ˜¾æ¨¡ç³Šåº¦ä¿¡æ¯ä¸æ–­èå…¥è®­ç»ƒï¼Œé€šè¿‡å¯è®­ç»ƒçš„éçº¿æ€§æ¿€æ´»å‡½æ•°é©±åŠ¨å»å™ªã€‚ç»“æœï¼šGIF-RAKIåœ¨å…¶ä»–RAKIå®ç°ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¿™å¾—åˆ°äº†å·®å¼‚å›¾å’Œå›¾åƒè´¨é‡æŒ‡æ ‡çš„æ”¯æŒã€‚ç‰¹å¾åƒç´ å’Œåƒç´ æ±¡æŸ“å›¾åˆ†åˆ«ä¸ºå™ªå£°æ”¾å¤§å’Œæ˜æ˜¾æ¨¡ç³Šåº¦æä¾›äº†å®šé‡æŒ‡æ ‡ï¼Œè€Œæ— éœ€é‡‘æ ‡å‡†å‚è€ƒã€‚å…·æœ‰å¯è°ƒæ³„æ¼ReLUçš„RAKIèƒ½å¤Ÿè‡ªåŠ¨è°ƒæ•´å…¶éçº¿æ€§ã€‚ç»“è®ºï¼šé¢å¤–çš„åŸºäºæ¨¡å‹çš„æŸå¤±é¡¹å…è®¸åœ¨RAKIè®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜åŒ–å»å™ªå’Œæ˜æ˜¾æ¨¡ç³Šåº¦ä¹‹é—´çš„æƒè¡¡ã€‚è¿™æœ‰å¯èƒ½æ¶ˆé™¤å¯¹å¯å‘å¼è¶…å‚æ•°è°ƒæ•´çš„éœ€æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11155v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¯¥ç ”ç©¶æ—¨åœ¨æ”¹å–„å’Œæå‡kç©ºé—´æ’å€¼ç½‘ç»œçš„å™ªå£°æ”¾å¤§å’Œæ¨¡ç³Šè¡¨ç°çš„è§£é‡Šæ€§ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¯¹å…¶è¿›è¡Œä¼˜åŒ–ä½œä¸ºæ¨¡å‹æ­£åˆ™åŒ–å™¨ã€‚é€šè¿‡è‡ªåŠ¨åŒºåˆ†ç½‘ç»œè¾“å…¥ï¼Œè¿›è¡Œå™ªå£°æ”¾å¤§åˆ†æï¼Œåˆ†è§£å™ªå£°æ–¹å·®å›¾ä»¥è€ƒè™‘ç½‘ç»œçš„çº¿æ€§å’Œéçº¿æ€§ç‰¹å¾ã€‚åœ¨æ¯ä¸ªè¿­ä»£è¿‡ç¨‹ä¸­æ¨å¯¼æ–¹å·®å›¾ï¼Œå®ç°è¿è¡Œæ—¶è´¨é‡ç›‘æ§ã€‚å¼•å…¥æœ€å¤§æ–¹å·®ï¼ˆç‰¹å¾åƒç´ ï¼‰å’Œæ®‹å·®æ–¹å·®å›¾ï¼ˆåƒç´ æ±¡æŸ“ï¼‰æ¥æè¿°ç½‘ç»œå™ªå£°æ”¾å¤§å’Œæ¨¡ç³Šç°è±¡ã€‚é€šè¿‡å°†æ–¹å·®å›¾çº³å…¥è®­ç»ƒï¼ŒæŸå¤±å‡½æ•°é™¤äº†kç©ºé—´æ•°æ®ä¸€è‡´æ€§é¡¹å¤–è¿˜åŠ å…¥äº†åŸºäºæ¨¡å‹çš„æ­£è§„åŒ–å™¨ã€‚å› æ­¤ï¼Œæ‰€æå‡ºçš„åŸºäºgå› å­çš„RAKIï¼ˆGIF-RAKIï¼‰å°†å™ªå£°å’Œæ¨¡ç³Šä¿¡æ¯ä¸æ–­èå…¥è®­ç»ƒï¼Œé€šè¿‡å¯è®­ç»ƒçš„éçº¿æ€§æ¿€æ´»å‡½æ•°é©±åŠ¨å»å™ªã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶æ—¨åœ¨æé«˜kç©ºé—´æ’å€¼ç½‘ç»œä¸­çš„å™ªå£°æ”¾å¤§å’Œæ¨¡ç³Šè¡¨ç°çš„è§£é‡Šæ€§ï¼Œå¹¶å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>é€šè¿‡è‡ªåŠ¨åŒºåˆ†ç½‘ç»œè¾“å…¥è¿›è¡Œå™ªå£°æ”¾å¤§åˆ†æï¼Œå¹¶åˆ†è§£å™ªå£°æ–¹å·®å›¾ã€‚</li>
<li>åœ¨æ¯ä¸ªè¿­ä»£è¿‡ç¨‹ä¸­æ¨å¯¼æ–¹å·®å›¾ï¼Œå®ç°è¿è¡Œæ—¶è´¨é‡ç›‘æ§ï¼Œå¼•å…¥æœ€å¤§æ–¹å·®å’Œæ®‹å·®æ–¹å·®å›¾æ¥æè¿°ç½‘ç»œå™ªå£°æ”¾å¤§å’Œæ¨¡ç³Šç°è±¡ã€‚</li>
<li>å°†æ–¹å·®å›¾çº³å…¥è®­ç»ƒï¼Œä¸°å¯ŒæŸå¤±å‡½æ•°ï¼ŒåŒ…æ‹¬åŸºäºæ¨¡å‹çš„æ­£è§„åŒ–å™¨ã€‚</li>
<li>GIF-RAKIå»ºç«‹äº†ä¸€ä¸ªå°†å™ªå£°å’Œæ¨¡ç³Šä¿¡æ¯ä¸æ–­èå…¥è®­ç»ƒçš„æµç¨‹ï¼Œé€šè¿‡å¯è®­ç»ƒçš„éçº¿æ€§æ¿€æ´»å‡½æ•°é©±åŠ¨å»å™ªã€‚</li>
<li>GIF-RAKIåœ¨å…¶ä»–RAKIå®ç°ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ï¼Œå¹¶æä¾›å®šé‡æŒ‡æ ‡æ¥è¡¡é‡å™ªå£°æ”¾å¤§å’Œæ¨¡ç³Šç°è±¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11155">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e690d8aaf25d70475bae69f32c35b854.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="In-silico-tool-for-identification-of-colorectal-cancer-from-cell-free-DNA-biomarkers"><a href="#In-silico-tool-for-identification-of-colorectal-cancer-from-cell-free-DNA-biomarkers" class="headerlink" title="In silico tool for identification of colorectal cancer from cell-free   DNA biomarkers"></a>In silico tool for identification of colorectal cancer from cell-free   DNA biomarkers</h2><p><strong>Authors:Kartavya Mathur, Shipra Jain, Nisha Bajiya, Nishant Kumar, Gajendra P. S. Raghava</strong></p>
<p>Colorectal cancer remains a major global health concern, with early detection being pivotal for improving patient outcomes. In this study, we leveraged high throughput methylation profiling of cellfree DNA to identify and validate diagnostic biomarkers for CRC. The GSE124600 study data were downloaded from the Gene Expression Omnibus, as the discovery cohort, comprising 142 CRC and 132 normal cfDNA methylation profiles obtained via MCTA seq. After preprocessing and filtering, 97,863 CpG sites were retained for further analysis. Differential methylation analysis using statistical tests identified 30,791 CpG sites as significantly altered in CRC samples, where p is less than 0.05. Univariate scoring enabled the selection of top ranking features, which were further refined using multiple feature selection algorithms, including Recursive Feature Elimination, Sequential Feature Selection, and SVC L1. Various machine learning models such as Logistic Regression, Support Vector Machines, Random Forest, and Multi layer Perceptron were trained and tested using independent validation datasets. The best performance was achieved with an MLP model trained on 25 features selected by RFE, reaching an AUROC of 0.89 and MCC of 0.78 on validation data. Additionally, a deep learning based convolutional neural network achieved an AUROC of 0.78. Functional annotation of the most predictive CpG sites identified several genes involved in key cellular processes, some of which were validated for differential expression in CRC using the GEPIA2 platform. Our study highlights the potential of cfDNA methylation markers combined with ML and DL models for noninvasive and accurate CRC detection, paving the way for clinically relevant diagnostic tools. </p>
<blockquote>
<p>ç»“ç›´è‚ ç™Œä»ç„¶æ˜¯ä¸€ä¸ªå…¨çƒæ€§çš„é‡å¤§å¥åº·é—®é¢˜ï¼Œæ—©æœŸå‘ç°å¯¹äºæ”¹å–„æ‚£è€…é¢„åè‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨ç»†èƒæ¸¸ç¦»DNAçš„é«˜é€šé‡ç”²åŸºåŒ–è°±åˆ†ææŠ€æœ¯ï¼Œæ¥è¯†åˆ«å’ŒéªŒè¯CRCçš„è¯Šæ–­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚GSE124600ç ”ç©¶æ•°æ®ä»åŸºå› è¡¨è¾¾ç»¼åˆæ•°æ®åº“ä¸‹è½½ï¼Œä½œä¸ºå‘ç°é˜Ÿåˆ—ï¼ŒåŒ…å«142ä¾‹CRCå’Œ132ä¾‹æ­£å¸¸cfDNAç”²åŸºåŒ–è°±ï¼Œé€šè¿‡MCTA seqè·å¾—ã€‚ç»è¿‡é¢„å¤„ç†å’Œç­›é€‰åï¼Œä¿ç•™äº†97,863ä¸ªCpGä½ç‚¹ç”¨äºè¿›ä¸€æ­¥åˆ†æã€‚ä½¿ç”¨ç»Ÿè®¡æµ‹è¯•è¿›è¡Œå·®å¼‚ç”²åŸºåŒ–åˆ†æï¼Œç¡®å®šäº†30,791ä¸ªåœ¨CRCæ ·æœ¬ä¸­æ˜¾è‘—æ”¹å˜çš„CpGä½ç‚¹ï¼ˆp &lt; 0.05ï¼‰ã€‚å•å˜é‡è¯„åˆ†ä½¿å¾—èƒ½å¤Ÿé€‰æ‹©æ’åé å‰çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾è¿›ä¸€æ­¥ä½¿ç”¨å¤šç§ç‰¹å¾é€‰æ‹©ç®—æ³•è¿›è¡Œç²¾ç‚¼ï¼ŒåŒ…æ‹¬é€’å½’ç‰¹å¾æ¶ˆé™¤ã€åºåˆ—ç‰¹å¾é€‰æ‹©å’ŒSVC L1ã€‚ä½¿ç”¨ç‹¬ç«‹éªŒè¯æ•°æ®é›†è®­ç»ƒå’Œæµ‹è¯•äº†å„ç§æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¦‚é€»è¾‘å›å½’ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—å’Œå¤šå±‚æ„ŸçŸ¥å™¨ã€‚ä½¿ç”¨RFEé€‰æ‹©çš„25ä¸ªç‰¹å¾è®­ç»ƒçš„MLPæ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œåœ¨éªŒè¯æ•°æ®ä¸Šçš„AUROCè¾¾åˆ°0.89ï¼ŒMCCè¾¾åˆ°0.78ã€‚æ­¤å¤–ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„å·ç§¯ç¥ç»ç½‘ç»œè¾¾åˆ°äº†AUROCä¸º0.78ã€‚é¢„æµ‹æ€§æœ€é«˜çš„CpGä½ç‚¹çš„åŠŸèƒ½æ³¨é‡Šç¡®å®šäº†æ¶‰åŠå…³é”®ç»†èƒè¿‡ç¨‹çš„å‡ ä¸ªåŸºå› ï¼Œå…¶ä¸­ä¸€äº›åŸºå› åœ¨CRCä¸­çš„å·®å¼‚è¡¨è¾¾å·²é€šè¿‡GEPIA2å¹³å°è¿›è¡ŒéªŒè¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†cfDNAç”²åŸºåŒ–æ ‡å¿—ç‰©ç»“åˆæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æ— åˆ›ä¸”å‡†ç¡®çš„CRCæ£€æµ‹ä¸­çš„æ½œåŠ›ï¼Œä¸ºå¼€å‘ä¸´åºŠç›¸å…³çš„è¯Šæ–­å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11041v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶åˆ©ç”¨ç»†èƒæ¸¸ç¦»DNAçš„é«˜é€šé‡ç”²åŸºåŒ–è°±åˆ†ææŠ€æœ¯ï¼ŒæˆåŠŸé‰´å®šå¹¶éªŒè¯äº†ç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰çš„è¯Šæ–­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚ç ”ç©¶é‡‡ç”¨GSE124600æ•°æ®ï¼Œé€šè¿‡å·®å¼‚ç”²åŸºåŒ–åˆ†æå’Œæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç­›é€‰å…³é”®ç‰¹å¾å¹¶æ„å»ºæ¨¡å‹ï¼Œå…¶ä¸­å¤šå±‚æ„ŸçŸ¥å™¨æ¨¡å‹è¡¨ç°æœ€ä½³ï¼ŒéªŒè¯æ•°æ®é›†çš„å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯è¾¾åˆ°0.89ï¼Œæ˜¾ç¤ºcfDNAç”²åŸºåŒ–æ ‡è®°ç»“åˆæœºå™¨å­¦ä¹ åœ¨ç»“ç›´è‚ ç™Œæ— åˆ›æ£€æµ‹ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶åˆ©ç”¨ç»†èƒæ¸¸ç¦»DNAçš„é«˜é€šé‡ç”²åŸºåŒ–è°±åˆ†ææŠ€æœ¯ï¼Œæ—¨åœ¨é‰´å®šç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰çš„è¯Šæ–­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚</li>
<li>é€šè¿‡å·®å¼‚ç”²åŸºåŒ–åˆ†æï¼Œç¡®å®šäº†30,791ä¸ªåœ¨CRCæ ·æœ¬ä¸­æ˜¾è‘—æ”¹å˜çš„CpGä½ç‚¹ã€‚</li>
<li>ä½¿ç”¨å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå…¶ä¸­å¤šå±‚æ„ŸçŸ¥å™¨æ¨¡å‹è¡¨ç°æœ€ä½³ï¼ŒéªŒè¯æ•°æ®é›†çš„å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯è¾¾åˆ°0.89ã€‚</li>
<li>æ·±åº¦å­¦ä¹ å·ç§¯ç¥ç»ç½‘ç»œä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„è¯Šæ–­æ½œåŠ›ï¼Œå…¶å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯è¾¾åˆ°0.78ã€‚</li>
<li>æœ€å…·é¢„æµ‹æ€§çš„CpGä½ç‚¹çš„åŠŸèƒ½æ³¨é‡Šæ˜¾ç¤ºï¼Œæ¶‰åŠå…³é”®ç»†èƒè¿‡ç¨‹çš„å‡ ä¸ªåŸºå› è¢«ç¡®å®šï¼Œå¹¶åœ¨CRCä¸­éªŒè¯äº†å…¶å·®å¼‚è¡¨è¾¾ã€‚</li>
<li>ç ”ç©¶ç»“æœå¼ºè°ƒäº†ç»†èƒæ¸¸ç¦»DNAç”²åŸºåŒ–æ ‡è®°ä¸æœºå™¨å­¦ä¹ ç»“åˆåœ¨ç»“ç›´è‚ ç™Œæ— åˆ›æ£€æµ‹ä¸­çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11041">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e398b57283d5e2198b3902d0a4104fa7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Rethinking-the-Mean-Teacher-Strategy-from-the-Perspective-of-Self-paced-Learning"><a href="#Rethinking-the-Mean-Teacher-Strategy-from-the-Perspective-of-Self-paced-Learning" class="headerlink" title="Rethinking the Mean Teacher Strategy from the Perspective of Self-paced   Learning"></a>Rethinking the Mean Teacher Strategy from the Perspective of Self-paced   Learning</h2><p><strong>Authors:Pengchen Zhang, Alan J. X. Guo, Sipin Luo, Zhe Han, Lin Guo</strong></p>
<p>Semi-supervised medical image segmentation has attracted significant attention due to its potential to reduce manual annotation costs. The mean teacher (MT) strategy, commonly understood as introducing smoothed, temporally lagged consistency regularization, has demonstrated strong performance across various tasks in this field. In this work, we reinterpret the MT strategy on supervised data as a form of self-paced learning, regulated by the output agreement between the temporally lagged teacher model and the ground truth labels. This idea is further extended to incorporate agreement between a temporally lagged model and a cross-architectural model, which offers greater flexibility in regulating the learning pace and enables application to unlabeled data. Specifically, we propose dual teacher-student learning (DTSL), a framework that introduces two groups of teacher-student models with different architectures. The output agreement between the cross-group teacher and student models is used as pseudo-labels, generated via a Jensen-Shannon divergence-based consensus label generator (CLG). Extensive experiments on popular datasets demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches. Ablation studies further validate the effectiveness of the proposed modules. </p>
<blockquote>
<p>åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²å› å…¶é™ä½æ‰‹åŠ¨æ ‡æ³¨æˆæœ¬çš„æ½œåŠ›è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚å‡å€¼æ•™å¸ˆï¼ˆMean Teacherï¼Œç®€ç§°MTï¼‰ç­–ç•¥ï¼Œé€šå¸¸ç†è§£ä¸ºå¼•å…¥å¹³æ»‘ã€æ—¶é—´æ»åä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼Œåœ¨è¯¥é¢†åŸŸå„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†MTç­–ç•¥åœ¨ç›‘ç£æ•°æ®ä¸Šçš„åº”ç”¨é‡æ–°è§£é‡Šä¸ºä¸€ç§è‡ªæˆ‘èŠ‚å¥å­¦ä¹ ï¼Œå—æ—¶é—´æ»åæ•™å¸ˆæ¨¡å‹ä¸çœŸå®æ ‡ç­¾ä¹‹é—´è¾“å‡ºåè®®çš„æ§åˆ¶ã€‚è¿™ä¸ªæƒ³æ³•è¿›ä¸€æ­¥æ‰©å±•åˆ°åŒ…å«æ—¶é—´æ»åæ¨¡å‹ä¸è·¨æ¶æ„æ¨¡å‹ä¹‹é—´çš„åè®®ï¼Œè¿™ä¸ºè°ƒèŠ‚å­¦ä¹ è¿›åº¦æä¾›äº†æ›´å¤§çš„çµæ´»æ€§ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿåº”ç”¨äºæ— æ ‡ç­¾æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†åŒæ•™å¸ˆå­¦ç”Ÿå­¦ä¹ ï¼ˆDual Teacher-Student Learningï¼Œç®€ç§°DTSLï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤ç»„ä¸åŒæ¶æ„çš„æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹ã€‚è·¨ç»„æ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„è¾“å‡ºåè®®ä½œä¸ºé€šè¿‡Jensen-Shannonæ•£åº¦å…±è¯†æ ‡ç­¾ç”Ÿæˆå™¨ï¼ˆCLGï¼‰ç”Ÿæˆçš„ä¼ªæ ‡ç­¾ã€‚åœ¨æµè¡Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å§‹ç»ˆä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†æ‰€æå‡ºæ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11018v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­ï¼Œå‡å€¼æ•™å¸ˆï¼ˆMTï¼‰ç­–ç•¥è¢«é‡æ–°è§£é‡Šä¸ºä¸€ç§ç”±è¾“å‡ºåè®®ç›‘ç®¡çš„è‡ªæˆ‘è¿›åº¦å­¦ä¹ æ–¹å¼ï¼Œå¹¶æ‰©å±•åº”ç”¨äºæ— æ ‡ç­¾æ•°æ®ã€‚æå‡ºåŒæ•™å¸ˆå­¦ç”Ÿå­¦ä¹ ï¼ˆDTSLï¼‰æ¡†æ¶ï¼Œå¼•å…¥ä¸¤ç»„ä¸åŒæ¶æ„çš„æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹ï¼Œé€šè¿‡åŸºäºJensen-Shannonæ•£åº¦çš„å…±è¯†æ ‡ç­¾ç”Ÿæˆå™¨ï¼ˆCLGï¼‰ç”Ÿæˆä¼ªæ ‡ç­¾ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²æ—¨åœ¨é™ä½æ‰‹åŠ¨æ³¨é‡Šæˆæœ¬ã€‚</li>
<li>å‡å€¼æ•™å¸ˆï¼ˆMTï¼‰ç­–ç•¥è¢«é‡æ–°è§£é‡Šä¸ºè‡ªæˆ‘è¿›åº¦å­¦ä¹ ï¼Œç”±è¾“å‡ºåè®®ç›‘ç®¡ã€‚</li>
<li>æ‰©å±•MTç­–ç•¥ä»¥çº³å…¥ä¸åŒæ¶æ„æ¨¡å‹ä¹‹é—´çš„åè®®ï¼Œæä¾›æ›´çµæ´»çš„å­¦ä¹ é€Ÿåº¦è°ƒæ§ã€‚</li>
<li>æå‡ºåŒæ•™å¸ˆå­¦ç”Ÿå­¦ä¹ ï¼ˆDTSLï¼‰æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ç»„ä¸åŒæ¶æ„çš„æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹ã€‚</li>
<li>ä½¿ç”¨åŸºäºJensen-Shannonæ•£åº¦çš„å…±è¯†æ ‡ç­¾ç”Ÿæˆå™¨ï¼ˆCLGï¼‰ç”Ÿæˆä¼ªæ ‡ç­¾ã€‚</li>
<li>åœ¨æµè¡Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11018">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b4017a02df3d8f6e86eef739c185965.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86d231e6b4f201f6bcb651a565edfa41.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a22a98d02d2238fdccee350d429655b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-062b8cbd80dad1876721ab8e8418ef1c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="WeGA-Weakly-Supervised-Global-Local-Affinity-Learning-Framework-for-Lymph-Node-Metastasis-Prediction-in-Rectal-Cancer"><a href="#WeGA-Weakly-Supervised-Global-Local-Affinity-Learning-Framework-for-Lymph-Node-Metastasis-Prediction-in-Rectal-Cancer" class="headerlink" title="WeGA: Weakly-Supervised Global-Local Affinity Learning Framework for   Lymph Node Metastasis Prediction in Rectal Cancer"></a>WeGA: Weakly-Supervised Global-Local Affinity Learning Framework for   Lymph Node Metastasis Prediction in Rectal Cancer</h2><p><strong>Authors:Yifan Gao, Yaoxian Dong, Wenbin Wu, Chaoyang Ge, Feng Yuan, Jiaxi Sheng, Haoyue Li, Xin Gao</strong></p>
<p>Accurate lymph node metastasis (LNM) assessment in rectal cancer is essential for treatment planning, yet current MRI-based evaluation shows unsatisfactory accuracy, leading to suboptimal clinical decisions. Developing automated systems also faces significant obstacles, primarily the lack of node-level annotations. Previous methods treat lymph nodes as isolated entities rather than as an interconnected system, overlooking valuable spatial and contextual information. To solve this problem, we present WeGA, a novel weakly-supervised global-local affinity learning framework that addresses these challenges through three key innovations: 1) a dual-branch architecture with DINOv2 backbone for global context and residual encoder for local node details; 2) a global-local affinity extractor that aligns features across scales through cross-attention fusion; and 3) a regional affinity loss that enforces structural coherence between classification maps and anatomical regions. Experiments across one internal and two external test centers demonstrate that WeGA outperforms existing methods, achieving AUCs of 0.750, 0.822, and 0.802 respectively. By effectively modeling the relationships between individual lymph nodes and their collective context, WeGA provides a more accurate and generalizable approach for lymph node metastasis prediction, potentially enhancing diagnostic precision and treatment selection for rectal cancer patients. </p>
<blockquote>
<p>å¯¹ç›´è‚ ç™Œæ·‹å·´ç»“è½¬ç§»ï¼ˆLNMï¼‰çš„å‡†ç¡®è¯„ä¼°æ˜¯æ²»ç–—è®¡åˆ’çš„å…³é”®ï¼Œä½†ç›®å‰çš„MRIè¯„ä¼°å‡†ç¡®æ€§ä¸ä½³ï¼Œå¯èƒ½å¯¼è‡´ä¸´åºŠå†³ç­–å¤±è¯¯ã€‚è‡ªåŠ¨ç³»ç»Ÿçš„å¼€å‘ä¹Ÿé¢ä¸´é‡å¤§éšœç¢ï¼Œä¸»è¦æ˜¯ç¼ºä¹èŠ‚ç‚¹çº§åˆ«çš„æ³¨é‡Šã€‚ä»¥å¾€çš„æ–¹æ³•å°†æ·‹å·´ç»“è§†ä¸ºå­¤ç«‹çš„å®ä½“ï¼Œè€Œä¸æ˜¯ç›¸äº’å…³è”çš„ç³»ç»Ÿï¼Œä»è€Œå¿½ç•¥äº†å®è´µçš„ç©ºé—´å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†WeGAï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¼±ç›‘ç£å…¨å±€-å±€éƒ¨äº²å’ŒåŠ›å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ä»¥ä¸‹ä¸‰ä¸ªå…³é”®åˆ›æ–°è§£å†³äº†è¿™äº›æŒ‘æˆ˜ï¼š1ï¼‰å…·æœ‰DINOv2ä¸»å¹²å’Œæ®‹å·®ç¼–ç å™¨çš„åŒåˆ†æ”¯æ¶æ„ï¼Œç”¨äºå…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨èŠ‚ç‚¹ç»†èŠ‚ï¼›2ï¼‰å…¨å±€-å±€éƒ¨äº²å’ŒåŠ›æå–å™¨ï¼Œé€šè¿‡è·¨æ³¨æ„åŠ›èåˆæ¥å¯¹é½è·¨å°ºåº¦çš„ç‰¹å¾ï¼›3ï¼‰åŒºåŸŸäº²å’ŒåŠ›æŸå¤±ï¼Œåœ¨åˆ†ç±»å›¾å’Œè§£å‰–åŒºåŸŸä¹‹é—´å¼ºåˆ¶æ‰§è¡Œç»“æ„ä¸€è‡´æ€§ã€‚åœ¨ä¸€ä¸ªå†…éƒ¨å’Œä¸¤ä¸ªå¤–éƒ¨æµ‹è¯•ä¸­å¿ƒçš„å®éªŒè¡¨æ˜ï¼ŒWeGAä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåˆ†åˆ«å®ç°äº†AUCå€¼ä¸º0.750ã€0.822å’Œ0.802ã€‚é€šè¿‡æœ‰æ•ˆåœ°å»ºæ¨¡å•ä¸ªæ·‹å·´ç»“ä¹‹é—´çš„å…³ç³»åŠå…¶é›†ä½“ä¸Šä¸‹æ–‡ï¼ŒWeGAä¸ºæ·‹å·´ç»“è½¬ç§»é¢„æµ‹æä¾›äº†æ›´å‡†ç¡®å’Œå¯æ¨å¹¿çš„æ–¹æ³•ï¼Œå¯èƒ½æé«˜äº†ç›´è‚ ç™Œæ‚£è€…çš„è¯Šæ–­ç²¾åº¦å’Œæ²»ç–—é€‰æ‹©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10502v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„å¼±ç›‘ç£å…¨å±€å±€éƒ¨äº²å’ŒåŠ›å­¦ä¹ æ¡†æ¶WeGAï¼Œç”¨äºå‡†ç¡®è¯„ä¼°ç›´è‚ ç™Œæ·‹å·´ç»“èŠ‚è½¬ç§»æƒ…å†µã€‚è¯¥æ–¹æ³•é€šè¿‡èåˆå…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨èŠ‚ç‚¹ç»†èŠ‚ã€è·¨å°ºåº¦ç‰¹å¾å¯¹é½ä»¥åŠç»“æ„è¿è´¯æ€§ï¼Œæé«˜äº†é¢„æµ‹å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç›´è‚ ç™Œä¸­æ·‹å·´èŠ‚ç‚¹è½¬ç§»ï¼ˆLNMï¼‰çš„å‡†ç¡®è¯„ä¼°å¯¹æ²»ç–—è®¡åˆ’è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰MRIè¯„ä¼°å­˜åœ¨å‡†ç¡®æ€§é—®é¢˜ï¼Œå¯¼è‡´ä¸´åºŠå†³ç­–å¤±è¯¯ã€‚</li>
<li>å¼€å‘è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„éš¾ç‚¹åœ¨äºç¼ºä¹èŠ‚ç‚¹çº§åˆ«çš„æ³¨é‡Šã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¿½ç•¥æ·‹å·´èŠ‚ç‚¹çš„ç›¸äº’å…³è”æ€§å’Œç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>WeGAé€šè¿‡å…¨å±€å’Œå±€éƒ¨åˆ†æ”¯æ¶æ„ã€å…¨å±€å±€éƒ¨äº²å’ŒåŠ›æå–å™¨å’ŒåŒºåŸŸäº²å’ŒåŠ›æŸå¤±æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒWeGAåœ¨å†…éƒ¨å’Œå¤–éƒ¨æµ‹è¯•ä¸­å¿ƒå‡è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œæé«˜äº†é¢„æµ‹å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10502">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d48c4ce32e03665e92ef6019f9c68006.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0c3cfcfcb8371f4fb35016db2f0b63e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea13d034f63c5c07fb9783cb4ff421b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d3c72e94119894a999f3f1371bf7b17.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Leveraging-Automatic-CAD-Annotations-for-Supervised-Learning-in-3D-Scene-Understanding"><a href="#Leveraging-Automatic-CAD-Annotations-for-Supervised-Learning-in-3D-Scene-Understanding" class="headerlink" title="Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene   Understanding"></a>Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene   Understanding</h2><p><strong>Authors:Yuchen Rao, Stefan Ainetter, Sinisa Stekovic, Vincent Lepetit, Friedrich Fraundorfer</strong></p>
<p>High-level 3D scene understanding is essential in many applications. However, the challenges of generating accurate 3D annotations make development of deep learning models difficult. We turn to recent advancements in automatic retrieval of synthetic CAD models, and show that data generated by such methods can be used as high-quality ground truth for training supervised deep learning models. More exactly, we employ a pipeline akin to the one previously used to automatically annotate objects in ScanNet scenes with their 9D poses and CAD models. This time, we apply it to the recent ScanNet++ v1 dataset, which previously lacked such annotations. Our findings demonstrate that it is not only possible to train deep learning models on these automatically-obtained annotations but that the resulting models outperform those trained on manually annotated data. We validate this on two distinct tasks: point cloud completion and single-view CAD model retrieval and alignment. Our results underscore the potential of automatic 3D annotations to enhance model performance while significantly reducing annotation costs. To support future research in 3D scene understanding, we will release our annotations, which we call SCANnotate++, along with our trained models. </p>
<blockquote>
<p>é«˜çº§åˆ«çš„ä¸‰ç»´åœºæ™¯ç†è§£åœ¨è®¸å¤šåº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”Ÿæˆå‡†ç¡®çš„ä¸‰ç»´æ ‡æ³¨çš„æŒ‘æˆ˜ä½¿å¾—å¼€å‘æ·±åº¦å­¦ä¹ æ¨¡å‹å˜å¾—å›°éš¾ã€‚æˆ‘ä»¬è½¬å‘æœ€è¿‘è‡ªåŠ¨æ£€ç´¢åˆæˆCADæ¨¡å‹çš„è¿›å±•ï¼Œå¹¶è¯æ˜ç”±è¿™äº›æ–¹æ³•ç”Ÿæˆçš„æ•°æ®å¯ä»¥ç”¨ä½œé«˜è´¨é‡çš„çœŸå®æ ‡ç­¾ï¼Œç”¨äºè®­ç»ƒæœ‰ç›‘ç£çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æ›´ç¡®åˆ‡åœ°è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§ç±»ä¼¼äºä¹‹å‰ç”¨äºScanNetåœºæ™¯ä¸­è‡ªåŠ¨æ ‡æ³¨å¯¹è±¡çš„ç®¡é“ï¼Œè¿™äº›å¯¹è±¡å¸¦æœ‰å…¶9Då§¿æ€å’ŒCADæ¨¡å‹ã€‚è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†å…¶åº”ç”¨äºæœ€æ–°çš„ScanNet++ v1æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¹‹å‰ç¼ºä¹æ­¤ç±»æ³¨é‡Šã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸ä»…å¯ä»¥åœ¨è¿™äº›è‡ªåŠ¨è·å¾—çš„æ³¨é‡Šä¸Šè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè€Œä¸”æ‰€å¾—æ¨¡å‹çš„æ€§èƒ½ä¼˜äºæ‰‹åŠ¨æ³¨é‡Šæ•°æ®è®­ç»ƒçš„æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªä¸åŒçš„ä»»åŠ¡ä¸Šå¯¹æ­¤è¿›è¡Œäº†éªŒè¯ï¼šç‚¹äº‘è¡¥å…¨å’Œå•è§†å›¾CADæ¨¡å‹æ£€ç´¢ä¸å¯¹é½ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†è‡ªåŠ¨ä¸‰ç»´æ ‡æ³¨åœ¨æé«˜æ¨¡å‹æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½æ ‡æ³¨æˆæœ¬çš„æ½œåŠ›ã€‚ä¸ºäº†æ”¯æŒæœªæ¥å¯¹ä¸‰ç»´åœºæ™¯ç†è§£çš„ç ”ç©¶ï¼Œæˆ‘ä»¬å°†å‘å¸ƒæˆ‘ä»¬çš„æ³¨é‡Šï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºSCANnotate++ï¼Œä»¥åŠæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13580v4">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://stefan-ainetter.github.io/SCANnotatepp">https://stefan-ainetter.github.io/SCANnotatepp</a>; CVPRâ€™25   Workshop</p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬ä»‹ç»äº†è‡ªåŠ¨æ£€ç´¢åˆæˆCADæ¨¡å‹çš„æ–°è¿›å±•ï¼Œå¹¶å°†å…¶åº”ç”¨äºScanNet++ v1æ•°æ®é›†çš„è‡ªåŠ¨æ ‡æ³¨ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è‡ªåŠ¨è·å¾—çš„æ ‡æ³¨è®­ç»ƒæ·±åº¦æ¨¡å‹ä¸ä»…å¯è¡Œï¼Œè€Œä¸”å…¶æ€§èƒ½ä¼˜äºä½¿ç”¨æ‰‹åŠ¨æ ‡æ³¨æ•°æ®è®­ç»ƒçš„æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºå¢å¼ºæ¨¡å‹æ€§èƒ½å¹¶æ˜¾è‘—é™ä½æ ‡æ³¨æˆæœ¬æä¾›äº†æ½œåŠ›ï¼Œå¹¶å°†å‘å¸ƒå…¶æ ‡æ³¨å’Œè®­ç»ƒæ¨¡å‹ä»¥æ”¯æŒæœªæ¥ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨æ£€ç´¢åˆæˆCADæ¨¡å‹æŠ€æœ¯è¢«åº”ç”¨äºScanNet++ v1æ•°æ®é›†çš„æ ‡æ³¨ï¼Œä¸ºæ·±åº¦å­¦ä¹ ä»»åŠ¡æä¾›äº†é«˜è´¨é‡çš„åœ°æ ‡æ•°æ®ã€‚</li>
<li>ä½¿ç”¨è‡ªåŠ¨è·å¾—çš„æ ‡æ³¨è®­ç»ƒçš„æ·±åº¦æ¨¡å‹æ€§èƒ½ä¼˜äºä½¿ç”¨æ‰‹åŠ¨æ ‡æ³¨æ•°æ®è®­ç»ƒçš„æ¨¡å‹ã€‚</li>
<li>è‡ªåŠ¨è¿›è¡Œ3Dæ ‡æ³¨çš„æ–¹æ³•æ˜¾è‘—é™ä½äº†æ ‡æ³¨æˆæœ¬ã€‚</li>
<li>é€šè¿‡åº”ç”¨ç±»ä¼¼ScanNetåœºæ™¯çš„è‡ªåŠ¨æ ‡æ³¨æŠ€æœ¯ï¼Œå®ç°äº†å¯¹ç‰©ä½“è¿›è¡Œç²¾ç¡®æ ‡æ³¨çš„ç›®æ ‡ã€‚</li>
<li>ç ”ç©¶ç»“æœéªŒè¯äº†è‡ªåŠ¨è¿›è¡Œ3Dåœºæ™¯ç†è§£çš„å¯è¡Œæ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å¤šä¸ªåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</li>
<li>ç ”ç©¶ç»“æœå¼ºè°ƒäº†è‡ªåŠ¨è·å–é«˜è´¨é‡æ ‡æ³¨çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¼ºä¹æ‰‹åŠ¨æ ‡æ³¨æ•°æ®çš„åœºæ™¯ä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13580">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c388eab897e9fb3439eb46d1e69b9edd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-63032ce7a7c64077e664f27e6a061354.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-261fc97f44c75d77faa745b096a25866.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe3ea7b428a57cad58f9a68d93a6a9a8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0303bb75b63c6b19cecda0d4ca074201.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Resolving-the-Ambiguity-of-Complete-to-Partial-Point-Cloud-Registration-for-Image-Guided-Liver-Surgery-with-Patches-to-Partial-Matching"><a href="#Resolving-the-Ambiguity-of-Complete-to-Partial-Point-Cloud-Registration-for-Image-Guided-Liver-Surgery-with-Patches-to-Partial-Matching" class="headerlink" title="Resolving the Ambiguity of Complete-to-Partial Point Cloud Registration   for Image-Guided Liver Surgery with Patches-to-Partial Matching"></a>Resolving the Ambiguity of Complete-to-Partial Point Cloud Registration   for Image-Guided Liver Surgery with Patches-to-Partial Matching</h2><p><strong>Authors:Zixin Yang, Jon S. Heiselman, Cheng Han, Kelly Merrell, Richard Simon, Cristian. A. Linte</strong></p>
<p>In image-guided liver surgery, the initial rigid alignment between preoperative and intraoperative data, often represented as point clouds, is crucial for providing sub-surface information from preoperative CT&#x2F;MRI images to the surgeon during the procedure. Currently, this alignment is typically performed using semi-automatic methods, which, while effective to some extent, are prone to errors that demand manual correction. Point cloud correspondence-based registration methods are promising to serve as a fully automatic solution. However, they may struggle in scenarios with limited intraoperative surface visibility, a common challenge in liver surgery, particularly in laparoscopic procedures, which we refer to as complete-to-partial ambiguity. We first illustrate this ambiguity by evaluating the performance of state-of-the-art learning-based point cloud registration methods on our carefully constructed in silico and in vitro datasets. Then, we propose a patches-to-partial matching strategy as a plug-and-play module to resolve the ambiguity, which can be seamlessly integrated into learning-based registration methods without disrupting their end-to-end structure. It has proven effective and efficient in improving registration performance for cases with limited intraoperative visibility. The constructed benchmark and the proposed module establish a solid foundation for advancing applications of point cloud correspondence-based registration methods in image-guided liver surgery. </p>
<blockquote>
<p>åœ¨å›¾åƒå¼•å¯¼ä¸‹çš„è‚è„æ‰‹æœ¯ä¸­ï¼Œæœ¯å‰å’Œæœ¯ä¸­æ•°æ®ä¹‹é—´çš„åˆå§‹åˆšæ€§å¯¹é½è‡³å…³é‡è¦ã€‚è¿™äº›æ•°æ®é€šå¸¸ä»¥ç‚¹äº‘çš„å½¢å¼å‘ˆç°ï¼Œä»¥ä¾¿ä¸ºå¤–ç§‘åŒ»ç”Ÿæä¾›ä»æœ¯å‰CT&#x2F;MRIå›¾åƒä¸­è·å¾—çš„äºšè¡¨é¢ä¿¡æ¯ã€‚ç›®å‰ï¼Œè¿™ç§å¯¹é½é€šå¸¸ä½¿ç”¨åŠè‡ªåŠ¨æ–¹æ³•æ‰§è¡Œï¼Œè¿™äº›æ–¹æ³•å°½ç®¡åœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æ•ˆï¼Œä½†ä»å®¹æ˜“å‡ºç°éœ€è¦æ‰‹åŠ¨çº æ­£çš„é”™è¯¯ã€‚åŸºäºç‚¹äº‘å¯¹åº”çš„æ³¨å†Œæ–¹æ³•æœ‰æœ›æˆä¸ºå…¨è‡ªåŠ¨è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œåœ¨è‚å†…è¡¨é¢å¯è§æ€§æœ‰é™çš„åœºæ™¯ä¸­ï¼Œå®ƒä»¬å¯èƒ½ä¼šé‡åˆ°å›°éš¾ï¼Œè¿™æ˜¯è‚è„æ‰‹æœ¯ä¸­å¸¸è§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨è…¹è…”é•œæ‰‹æœ¯ä¸­ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºå®Œå…¨åˆ°éƒ¨åˆ†çš„æ¨¡ç³Šæ€§ã€‚æˆ‘ä»¬é¦–å…ˆé€šè¿‡è¯„ä¼°æœ€å…ˆè¿›çš„å­¦ä¹ å‹ç‚¹äº‘æ³¨å†Œæ–¹æ³•åœ¨ç²¾å¿ƒæ„å»ºçš„ä½“å†…å’Œä½“å¤–æ•°æ®é›†ä¸Šçš„è¡¨ç°æ¥è¯´æ˜è¿™ç§æ¨¡ç³Šæ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¡¥ä¸åˆ°éƒ¨åˆ†çš„åŒ¹é…ç­–ç•¥ï¼Œä½œä¸ºä¸€ç§å³æ’å³ç”¨çš„æ¨¡å—æ¥è§£å†³æ¨¡ç³Šæ€§é—®é¢˜ã€‚å®ƒå¯ä»¥æ— ç¼é›†æˆåˆ°åŸºäºå­¦ä¹ çš„æ³¨å†Œæ–¹æ³•ä¸­ï¼Œè€Œä¸ä¼šç ´åå…¶ç«¯åˆ°ç«¯çš„ç»“æ„ã€‚å¯¹äºæœ¯ä¸­è§†é‡æœ‰é™çš„ç—…ä¾‹ï¼Œè¯¥ç­–ç•¥å·²è¢«è¯æ˜èƒ½å¤Ÿæœ‰æ•ˆæé«˜æ³¨å†Œæ€§èƒ½ã€‚æ„å»ºçš„åŸºå‡†æµ‹è¯•å’Œæå‡ºçš„æ¨¡å—ä¸ºæ¨è¿›ç‚¹äº‘å¯¹åº”æ³¨å†Œæ–¹æ³•åœ¨å›¾åƒå¼•å¯¼è‚è„æ‰‹æœ¯ä¸­çš„åº”ç”¨å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19328v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨å›¾åƒå¼•å¯¼ä¸‹çš„è‚è„æ‰‹æœ¯ä¸­ï¼Œå¯¹æœ¯å‰å’Œæœ¯ä¸­æ•°æ®è¿›è¡Œåˆæ­¥ç²¾ç¡®å¯¹é½æä¸ºå…³é”®ï¼Œæ­¤è¿‡ç¨‹å¸¸è¡¨ç°ä¸ºç‚¹äº‘å½¢å¼ï¼Œæ—¨åœ¨å‘æ‰‹æœ¯åŒ»ç”Ÿæä¾›æ¥è‡ªæœ¯å‰CT&#x2F;MRIå›¾åƒçš„è¡¨é¢ä¸‹ä¿¡æ¯ã€‚å½“å‰ï¼Œé€šå¸¸é‡‡ç”¨åŠè‡ªåŠ¨æ–¹æ³•è¿›è¡Œæ­¤å¯¹é½ï¼Œè™½ç„¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æ•ˆï¼Œä½†æ˜“å‡ºç°é”™è¯¯éœ€è¦äººå·¥æ ¡æ­£ã€‚åŸºäºç‚¹äº‘å¯¹åº”çš„æ³¨å†Œæ–¹æ³•æœ‰æœ›æˆä¸ºå…¨è‡ªåŠ¨è§£å†³æ–¹æ¡ˆï¼Œä½†åœ¨æœ¯ä¸­è¡¨é¢å¯è§æ€§æœ‰é™çš„æƒ…å†µä¸‹å¯èƒ½ä¼šé‡åˆ°å›°éš¾ï¼Œè¿™åœ¨è‚è„æ‰‹æœ¯ä¸­å°¤ä¸ºå¸¸è§ï¼Œç‰¹åˆ«æ˜¯åœ¨è…¹è…”é•œæ‰‹æœ¯ä¸­æˆ‘ä»¬ç§°ä¹‹ä¸ºå®Œæ•´åˆ°éƒ¨åˆ†çš„æ­§ä¹‰æ€§ã€‚ä¸ºè§£å†³æ­¤æ­§ä¹‰æ€§ï¼Œæœ¬æ–‡æå‡ºä¸€ç§å³æ’å³ç”¨çš„â€œè¡¥ä¸åˆ°éƒ¨åˆ†â€åŒ¹é…ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯æ— ç¼é›†æˆåˆ°åŸºäºå­¦ä¹ çš„æ³¨å†Œæ–¹æ³•ä¸­ï¼Œä¸”ä¸å½±å“å…¶ç«¯åˆ°ç«¯çš„ç»“æ„ã€‚å¯¹äºæœ¯ä¸­å¯è§æ€§æœ‰é™çš„æƒ…å†µï¼Œè¯¥ç­–ç•¥åœ¨æ”¹å–„æ³¨å†Œæ€§èƒ½æ–¹é¢è¢«è¯æ˜æ˜¯æœ‰æ•ˆä¸”é«˜æ•ˆçš„ã€‚æœ¬æ–‡æ„å»ºçš„åŸºå‡†å’Œæå‡ºçš„æ¨¡å—ä¸ºæ¨è¿›ç‚¹äº‘å¯¹åº”æ³¨å†Œæ–¹æ³•åœ¨å›¾åƒå¼•å¯¼è‚è„æ‰‹æœ¯ä¸­çš„åº”ç”¨å¥ å®šäº†åšå®åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ¨å›¾åƒå¼•å¯¼è‚è„æ‰‹æœ¯ä¸­ï¼Œæœ¯å‰ä¸æœ¯ä¸­æ•°æ®çš„åˆå§‹ç²¾ç¡®å¯¹é½è‡³å…³é‡è¦ï¼Œä¸ºæ‰‹æœ¯åŒ»ç”Ÿæä¾›æ¥è‡ªæœ¯å‰å½±åƒçš„è¡¨é¢ä¸‹ä¿¡æ¯ã€‚</li>
<li>å½“å‰çš„å¯¹é½æ–¹æ³•ä¸»è¦ä¾èµ–åŠè‡ªåŠ¨æŠ€æœ¯ï¼Œå°½ç®¡æœ‰æ•ˆï¼Œä½†å­˜åœ¨éœ€è¦äººå·¥æ ¡æ­£çš„é”™è¯¯é£é™©ã€‚</li>
<li>ç‚¹äº‘å¯¹åº”çš„æ³¨å†Œæ–¹æ³•è¢«è§†ä¸ºå…¨è‡ªåŠ¨è§£å†³æ–¹æ¡ˆçš„å€™é€‰ï¼Œä½†åœ¨æœ¯ä¸­è¡¨é¢å¯è§æ€§æœ‰é™çš„æƒ…å†µä¸‹å¯èƒ½ä¼šé­é‡æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡å®šä¹‰äº†å®Œæ•´åˆ°éƒ¨åˆ†çš„æ­§ä¹‰æ€§é—®é¢˜ï¼Œå°¤å…¶åœ¨è…¹è…”é•œè‚è„æ‰‹æœ¯ä¸­å°¤ä¸ºçªå‡ºã€‚</li>
<li>ä¸ºè§£å†³ä¸Šè¿°æ­§ä¹‰æ€§ï¼Œæå‡ºäº†ä¸€ç§â€œè¡¥ä¸åˆ°éƒ¨åˆ†â€åŒ¹é…ç­–ç•¥ï¼Œå¯æ— ç¼é›†æˆåˆ°ç°æœ‰åŸºäºå­¦ä¹ çš„æ³¨å†Œæ–¹æ³•ä¸­ã€‚</li>
<li>æ­¤ç­–ç•¥åœ¨æ”¹å–„æ³¨å†Œæ€§èƒ½ä¸Šè¢«è¯å®æœ‰æ•ˆä¸”é«˜æ•ˆï¼Œç‰¹åˆ«æ˜¯åœ¨æœ¯ä¸­å¯è§æ€§æœ‰é™çš„æƒ…å†µä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19328">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-600426655e969fa25fdfa10e3fa85af3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-837ccce401f569033b43f4edc9ef7e0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c552527dbf1de37c1376db9340a27ae2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0362b2097230aa174b85e92ec7f50fd3.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="reBEN-Refined-BigEarthNet-Dataset-for-Remote-Sensing-Image-Analysis"><a href="#reBEN-Refined-BigEarthNet-Dataset-for-Remote-Sensing-Image-Analysis" class="headerlink" title="reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis"></a>reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis</h2><p><strong>Authors:Kai Norman Clasen, Leonard Hackel, Tom Burgert, Gencer Sumbul, BegÃ¼m Demir, Volker Markl</strong></p>
<p>This paper presents refined BigEarthNet (reBEN) that is a large-scale, multi-modal remote sensing dataset constructed to support deep learning (DL) studies for remote sensing image analysis. The reBEN dataset consists of 549,488 pairs of Sentinel-1 and Sentinel-2 image patches. To construct reBEN, we initially consider the Sentinel-1 and Sentinel-2 tiles used to construct the BigEarthNet dataset and then divide them into patches of size 1200 m x 1200 m. We apply atmospheric correction to the Sentinel-2 patches using the latest version of the sen2cor tool, resulting in higher-quality patches compared to those present in BigEarthNet. Each patch is then associated with a pixel-level reference map and scene-level multi-labels. This makes reBEN suitable for pixel- and scene-based learning tasks. The labels are derived from the most recent CORINE Land Cover (CLC) map of 2018 by utilizing the 19-class nomenclature as in BigEarthNet. The use of the most recent CLC map results in overcoming the label noise present in BigEarthNet. Furthermore, we introduce a new geographical-based split assignment algorithm that significantly reduces the spatial correlation among the train, validation, and test sets with respect to those present in BigEarthNet. This increases the reliability of the evaluation of DL models. To minimize the DL model training time, we introduce software tools that convert the reBEN dataset into a DL-optimized data format. In our experiments, we show the potential of reBEN for multi-modal multi-label image classification problems by considering several state-of-the-art DL models. The pre-trained model weights, associated code, and complete dataset are available at <a target="_blank" rel="noopener" href="https://bigearth.net/">https://bigearth.net</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ç²¾ç»†åŒ–çš„BigEarthNetï¼ˆreBENï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šæ¨¡æ€çš„é¥æ„Ÿæ•°æ®é›†ï¼Œæ—¨åœ¨æ”¯æŒç”¨äºé¥æ„Ÿå›¾åƒåˆ†æçš„æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰ç ”ç©¶ã€‚reBENæ•°æ®é›†åŒ…å«549,488å¯¹Sentinel-1å’ŒSentinel-2å›¾åƒæ–‘å—ã€‚ä¸ºäº†æ„å»ºreBENï¼Œæˆ‘ä»¬é¦–å…ˆè€ƒè™‘ç”¨äºæ„å»ºBigEarthNetæ•°æ®é›†çš„Sentinel-1å’ŒSentinel-2ç“¦ç‰‡ï¼Œç„¶åå°†å…¶åˆ’åˆ†ä¸ºå¤§å°ä¸º1200ç±³x 1200ç±³çš„æ–‘å—ã€‚æˆ‘ä»¬å¯¹Sentinel-2æ–‘å—åº”ç”¨å¤§æ°”æ ¡æ­£ï¼Œä½¿ç”¨sen2corå·¥å…·çš„æœ€æ–°ç‰ˆæœ¬ï¼Œä»è€Œå¾—åˆ°ä¸BigEarthNetä¸­ç°æœ‰çš„æ–‘å—ç›¸æ¯”è´¨é‡æ›´é«˜çš„æ–‘å—ã€‚ç„¶åï¼Œæ¯ä¸ªæ–‘å—éƒ½ä¸åƒç´ çº§å‚è€ƒåœ°å›¾å’Œåœºæ™¯çº§å¤šæ ‡ç­¾ç›¸å…³è”ã€‚è¿™ä½¿å¾—reBENé€‚åˆç”¨äºåŸºäºåƒç´ å’Œåœºæ™¯çš„å­¦ä¹ ä»»åŠ¡ã€‚æ ‡ç­¾æ˜¯é€šè¿‡ä½¿ç”¨ä¸BigEarthNetç›¸åŒçš„19ç±»å‘½åæ³•ï¼Œä»æœ€æ–°çš„2018å¹´CORINEåœŸåœ°è¦†ç›–ï¼ˆCLCï¼‰åœ°å›¾ä¸­å¾—å‡ºçš„ã€‚ä½¿ç”¨æœ€æ–°çš„CLCåœ°å›¾å…‹æœäº†BigEarthNetä¸­å­˜åœ¨çš„æ ‡ç­¾å™ªå£°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºåœ°ç†çš„åˆ†å‰²åˆ†é…ç®—æ³•ï¼Œè¯¥ç®—æ³•æ˜¾è‘—å‡å°‘äº†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„ç©ºé—´ç›¸å…³æ€§ï¼Œä¸BigEarthNetä¸­çš„ç›¸å…³æ€§ç›¸æ¯”ã€‚è¿™å¢åŠ äº†æ·±åº¦å­¦ä¹ æ¨¡å‹è¯„ä¼°çš„å¯é æ€§ã€‚ä¸ºäº†æœ€å°åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒæ—¶é—´ï¼Œæˆ‘ä»¬å¼•å…¥äº†å°†reBENæ•°æ®é›†è½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ ä¼˜åŒ–æ•°æ®æ ¼å¼çš„è½¯ä»¶å·¥å…·ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è€ƒè™‘ä¸€äº›æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå±•ç¤ºäº†reBENåœ¨å¤šæ¨¡æ€å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»é—®é¢˜ä¸Šçš„æ½œåŠ›ã€‚é¢„è®­ç»ƒæ¨¡å‹æƒé‡ã€ç›¸å…³ä»£ç å’Œå®Œæ•´æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://bigearth.netä¸Šæ‰¾åˆ°./">https://bigearth.netä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.03653v5">PDF</a> Accepted at IEEE International Geoscience and Remote Sensing   Symposium (IGARSS) 2025. Our code is available at   <a target="_blank" rel="noopener" href="https://github.com/rsim-tu-berlin/bigearthnet-pipeline">https://github.com/rsim-tu-berlin/bigearthnet-pipeline</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬è®ºæ–‡æ¨å‡ºç²¾ç»†åŒ–BigEarthNetï¼ˆreBENï¼‰ï¼Œè¿™æ˜¯ä¸€å¥—å¤§å‹ã€å¤šæ¨¡å¼é¥æ„Ÿæ•°æ®é›†ï¼Œä¸“ä¸ºæ”¯æŒé¥æ„Ÿå›¾åƒåˆ†æçš„æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰ç ”ç©¶è€Œæ„å»ºã€‚reBENæ•°æ®é›†åŒ…å«549,488å¯¹Sentinel-1å’ŒSentinel-2å›¾åƒè¡¥ä¸ã€‚ç›¸è¾ƒäºBigEarthNetï¼ŒreBENé€šè¿‡åº”ç”¨å¤§æ°”æ ¡æ­£æŠ€æœ¯æé«˜äº†è¡¥ä¸è´¨é‡ï¼Œå¹¶å¼•å…¥æ–°çš„åœ°ç†åˆ†å‰²åˆ†é…ç®—æ³•ä»¥å¢åŠ è¯„ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œä¸ºç¼©çŸ­æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒæ—¶é—´ï¼Œæˆ‘ä»¬æä¾›è½¯ä»¶å·¥å…·å°†reBENæ•°æ®é›†è½¬æ¢ä¸ºä¼˜åŒ–çš„æ•°æ®æ ¼å¼ã€‚å®éªŒæ˜¾ç¤ºï¼ŒreBENåœ¨å¤šæ¨¡æ€å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»é—®é¢˜æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚é¢„è®­ç»ƒæ¨¡å‹æƒé‡ã€ç›¸å…³ä»£ç å’Œå®Œæ•´æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://bigearth.netè®¿é—®./">https://bigearth.netè®¿é—®ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>reBENæ˜¯ä¸€ä¸ªå¤§å‹ã€å¤šæ¨¡å¼é¥æ„Ÿæ•°æ®é›†ï¼Œä¸“ä¸ºæ”¯æŒæ·±åº¦å­¦ä¹ ç ”ç©¶è€Œæ„å»ºã€‚</li>
<li>reBENåŒ…å«ç»è¿‡å¤§æ°”æ ¡æ­£çš„é«˜è´¨é‡å›¾åƒè¡¥ä¸ï¼Œé€‚ç”¨äºåƒç´ å’Œåœºæ™¯åŸºç¡€å­¦ä¹ ä»»åŠ¡ã€‚</li>
<li>åˆ©ç”¨æœ€æ–°çš„CORINE Land Coveråœ°å›¾å…‹æœBigEarthNetä¸­çš„æ ‡ç­¾å™ªå£°é—®é¢˜ã€‚</li>
<li>å¼•å…¥æ–°çš„åœ°ç†åˆ†å‰²åˆ†é…ç®—æ³•ä»¥æé«˜è¯„ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯ä¿¡åº¦ã€‚</li>
<li>æä¾›è½¯ä»¶å·¥å…·ä»¥ä¼˜åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ—¶é—´ã€‚</li>
<li>å®éªŒè¯æ˜reBENåœ¨å¤šæ¨¡æ€å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»é—®é¢˜ä¸Šçš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.03653">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a9844b7f3a16709fd87d654a508b3eb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa791f7729df39b9aa372f0d7d0a99be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0aa521d347dd0ac94c100c0c69944d41.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e5f8208787f9f52221eabba2a6a035f.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-20/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-20/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-20/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4efe663a379b9baddddf48687e2b2b1d.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-20  SoftCoT++ Test-Time Scaling with Soft Chain-of-Thought Reasoning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-20/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4e9118e1f98bd6af8c0e55280683c781.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-20  QVGen Pushing the Limit of Quantized Video Generative Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">25691.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
