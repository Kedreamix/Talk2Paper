<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-11  Latent Diffusion U-Net Representations Contain Positional Embeddings and   Anomalies">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-10fdc068544b555ab6cd9a453892ef07.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    44 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-11-æ›´æ–°"><a href="#2025-04-11-æ›´æ–°" class="headerlink" title="2025-04-11 æ›´æ–°"></a>2025-04-11 æ›´æ–°</h1><h2 id="Latent-Diffusion-U-Net-Representations-Contain-Positional-Embeddings-and-Anomalies"><a href="#Latent-Diffusion-U-Net-Representations-Contain-Positional-Embeddings-and-Anomalies" class="headerlink" title="Latent Diffusion U-Net Representations Contain Positional Embeddings and   Anomalies"></a>Latent Diffusion U-Net Representations Contain Positional Embeddings and   Anomalies</h2><p><strong>Authors:Jonas Loos, Lorenz Linhardt</strong></p>
<p>Diffusion models have demonstrated remarkable capabilities in synthesizing realistic images, spurring interest in using their representations for various downstream tasks. To better understand the robustness of these representations, we analyze popular Stable Diffusion models using representational similarity and norms. Our findings reveal three phenomena: (1) the presence of a learned positional embedding in intermediate representations, (2) high-similarity corner artifacts, and (3) anomalous high-norm artifacts. These findings underscore the need to further investigate the properties of diffusion model representations before considering them for downstream tasks that require robust features. Project page: <a target="_blank" rel="noopener" href="https://jonasloos.github.io/sd-representation-anomalies">https://jonasloos.github.io/sd-representation-anomalies</a> </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹åœ¨åˆæˆé€¼çœŸå›¾åƒæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œæ¿€å‘äº†äººä»¬å¯¹å…¶è¡¨ç¤ºæ³•ç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡çš„å…´è¶£ã€‚ä¸ºäº†æ›´å¥½åœ°äº†è§£è¿™äº›è¡¨ç¤ºçš„ç¨³å¥æ€§ï¼Œæˆ‘ä»¬é€šè¿‡åˆ†ææµè¡Œçš„Stable Diffusionæ¨¡å‹ä½¿ç”¨è¡¨ç¤ºç›¸ä¼¼æ€§è§„èŒƒå’Œå‡†åˆ™ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°äº†ä¸‰ç§ç°è±¡ï¼šï¼ˆ1ï¼‰ä¸­é—´è¡¨ç¤ºä¸­å­˜åœ¨å­¦ä¹ çš„ä½ç½®åµŒå…¥ï¼›ï¼ˆ2ï¼‰é«˜ç›¸ä¼¼åº¦è§’è½ä¼ªå½±ï¼›ï¼ˆ3ï¼‰å¼‚å¸¸é«˜è§„èŒƒä¼ªå½±ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨è€ƒè™‘å°†æ‰©æ•£æ¨¡å‹è¡¨ç¤ºæ³•ç”¨äºéœ€è¦ç¨³å¥ç‰¹å¾çš„ä¸‹æ¸¸ä»»åŠ¡ä¹‹å‰ï¼Œéœ€è¦è¿›ä¸€æ­¥ç ”ç©¶å…¶ç‰¹æ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://jonasloos.github.io/sd-representation-anomalies">https://jonasloos.github.io/sd-representation-anomalies</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.07008v1">PDF</a> ICLR 2025 Workshop on Deep Generative Models: Theory, Principle, and   Efficacy</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬æ¢è®¨äº†Diffusionæ¨¡å‹åœ¨åˆæˆçœŸå®å›¾åƒæ–¹é¢çš„å‡ºè‰²è¡¨ç°ï¼Œå¹¶åˆ†æäº†å…¶å¯¹äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡çš„æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚é’ˆå¯¹æµè¡Œçš„Stable Diffusionæ¨¡å‹ï¼Œç ”ç©¶é€šè¿‡ä»£è¡¨æ€§ç›¸ä¼¼æ€§å’ŒèŒƒæ•°è¿›è¡Œæ·±å…¥åˆ†æï¼Œæ­ç¤ºäº†æ¨¡å‹å­˜åœ¨çš„å­¦ä¹ ä½ç½®åµŒå…¥ã€é«˜ç›¸ä¼¼æ€§è§’è½å¼‚å¸¸å’Œé«˜èŒƒæ•°å¼‚å¸¸ç­‰ä¸‰ä¸ªç°è±¡ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†è¿›ä¸€æ­¥æ¢ç©¶Diffusionæ¨¡å‹ç‰¹æ€§å¯¹äºéœ€è¦ç¨³å¥ç‰¹å¾çš„ä¸‹æ¸¸ä»»åŠ¡çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Diffusionæ¨¡å‹åœ¨åˆæˆçœŸå®å›¾åƒæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚</li>
<li>Stable Diffusionæ¨¡å‹çš„åˆ†ææ­ç¤ºäº†ä¸‰ä¸ªå…³é”®ç°è±¡ã€‚</li>
<li>æ¨¡å‹ä¸­å­˜åœ¨å­¦ä¹ çš„ä½ç½®åµŒå…¥ç°è±¡ã€‚</li>
<li>æ¨¡å‹å¯èƒ½å‡ºç°é«˜ç›¸ä¼¼æ€§è§’è½å¼‚å¸¸ã€‚</li>
<li>æ¨¡å‹å¯èƒ½è¡¨ç°å‡ºå¼‚å¸¸çš„é«˜èŒƒæ•°ç‰¹å¾ã€‚</li>
<li>åœ¨è€ƒè™‘ä½¿ç”¨Diffusionæ¨¡å‹è¿›è¡Œéœ€è¦ç¨³å¥ç‰¹å¾çš„ä¸‹æ¸¸ä»»åŠ¡ä¹‹å‰ï¼Œéœ€è¦è¿›ä¸€æ­¥æ¢ç©¶å…¶ç‰¹æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.07008">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-10fdc068544b555ab6cd9a453892ef07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dbb34f13132f82d2f1404a7be3f7161.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-83224d221125968fa863b8d4b14c07bd.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PathSegDiff-Pathology-Segmentation-using-Diffusion-model-representations"><a href="#PathSegDiff-Pathology-Segmentation-using-Diffusion-model-representations" class="headerlink" title="PathSegDiff: Pathology Segmentation using Diffusion model   representations"></a>PathSegDiff: Pathology Segmentation using Diffusion model   representations</h2><p><strong>Authors:Sachin Kumar Danisetty, Alexandros Graikos, Srikar Yellapragada, Dimitris Samaras</strong></p>
<p>Image segmentation is crucial in many computational pathology pipelines, including accurate disease diagnosis, subtyping, outcome, and survivability prediction. The common approach for training a segmentation model relies on a pre-trained feature extractor and a dataset of paired image and mask annotations. These are used to train a lightweight prediction model that translates features into per-pixel classes. The choice of the feature extractor is central to the performance of the final segmentation model, and recent literature has focused on finding tasks to pre-train the feature extractor. In this paper, we propose PathSegDiff, a novel approach for histopathology image segmentation that leverages Latent Diffusion Models (LDMs) as pre-trained featured extractors. Our method utilizes a pathology-specific LDM, guided by a self-supervised encoder, to extract rich semantic information from H&amp;E stained histopathology images. We employ a simple, fully convolutional network to process the features extracted from the LDM and generate segmentation masks. Our experiments demonstrate significant improvements over traditional methods on the BCSS and GlaS datasets, highlighting the effectiveness of domain-specific diffusion pre-training in capturing intricate tissue structures and enhancing segmentation accuracy in histopathology images. </p>
<blockquote>
<p>å›¾åƒåˆ†å‰²åœ¨è®¡ç®—ç—…ç†å­¦æµç¨‹ä¸­éå¸¸é‡è¦ï¼ŒåŒ…æ‹¬å‡†ç¡®çš„ç–¾ç—…è¯Šæ–­ã€äºšå‹åˆ†ç±»ã€ç»“æœé¢„æµ‹å’Œç”Ÿå­˜é¢„æµ‹ã€‚è®­ç»ƒåˆ†å‰²æ¨¡å‹çš„ä¸€èˆ¬æ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œé…å¯¹å›¾åƒå’Œæ©è†œæ³¨é‡Šçš„æ•°æ®é›†ã€‚è¿™äº›è¢«ç”¨æ¥è®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„é¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†ç‰¹å¾è½¬åŒ–ä¸ºåƒç´ çº§åˆ«çš„ç±»åˆ«ã€‚ç‰¹å¾æå–å™¨çš„é€‰æ‹©å¯¹æœ€ç»ˆåˆ†å‰²æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ï¼Œæœ€è¿‘çš„æ–‡çŒ®ä¸»è¦é›†ä¸­åœ¨å¯»æ‰¾é¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†PathSegDiffï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„ç—…ç†å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ä½œä¸ºé¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨ä¸€ä¸ªç—…ç†ç‰¹å®šçš„LDMï¼Œç”±ä¸€ä¸ªè‡ªç›‘ç£ç¼–ç å™¨å¼•å¯¼ï¼Œä»HEæŸ“è‰²çš„ç—…ç†å›¾åƒä¸­æå–ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å…¨å·ç§¯ç½‘ç»œæ¥å¤„ç†ä»LDMæå–çš„ç‰¹å¾ï¼Œå¹¶ç”Ÿæˆåˆ†å‰²æ©è†œã€‚æˆ‘ä»¬çš„å®éªŒåœ¨BCSSå’ŒGlaSæ•°æ®é›†ä¸Šè¯æ˜äº†ä¼ ç»Ÿæ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ï¼Œçªå‡ºäº†é¢†åŸŸç‰¹å®šæ‰©æ•£é¢„è®­ç»ƒåœ¨æ•æ‰å¤æ‚ç»„ç»‡ç»“æ„å’Œæé«˜ç—…ç†å›¾åƒåˆ†å‰²å‡†ç¡®æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06950v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ç—…ç†å›¾åƒåˆ†å‰²æ–°æ–¹æ³•PathSegDiffã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç—…ç†ç‰¹å¼‚æ€§LDMå’Œè‡ªç›‘ç£ç¼–ç å™¨æå–H&amp;EæŸ“è‰²ç—…ç†å›¾åƒçš„ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å…¨å·ç§¯ç½‘ç»œç”Ÿæˆåˆ†å‰²æ©è†œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨BCSSå’ŒGlaSæ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œè¯æ˜äº†é¢†åŸŸç‰¹å®šæ‰©æ•£é¢„è®­ç»ƒåœ¨æ•æ‰å¤æ‚ç»„ç»‡ç»“æ„å’Œæé«˜ç—…ç†å›¾åƒåˆ†å‰²ç²¾åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒåˆ†å‰²åœ¨è®¡ç®—ç—…ç†å­¦ç®¡é“ä¸­è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬å‡†ç¡®ç–¾ç—…è¯Šæ–­ã€åˆ†å‹ã€ç»“æœé¢„æµ‹å’Œç”Ÿå­˜é¢„æµ‹ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œé…å¯¹å›¾åƒå’Œæ©è†œæ³¨é‡Šæ•°æ®é›†æ¥è®­ç»ƒè½»é‡çº§é¢„æµ‹æ¨¡å‹ã€‚</li>
<li>ç‰¹å¾æå–å™¨çš„é€‰æ‹©å¯¹æœ€ç»ˆåˆ†å‰²æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>PathSegDiffæ˜¯ä¸€ç§åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„æ–°æ–¹æ³•ï¼Œç”¨äºç—…ç†å›¾åƒåˆ†å‰²ã€‚</li>
<li>PathSegDiffåˆ©ç”¨ç—…ç†ç‰¹å¼‚æ€§LDMå’Œè‡ªç›‘ç£ç¼–ç å™¨æå–ç—…ç†å›¾åƒçš„ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒPathSegDiffåœ¨BCSSå’ŒGlaSæ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06950">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-867f9a46e9b49b7bcc6527aebfd51d46.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b32336274937ff636bcc427d04c8f23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-538d150ba9201ced64414fe6e0d229a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e05e38811f2846699247f81eb4a90db.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9ee00f85e8b288b5ab4a2206d3257def.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MedSegFactory-Text-Guided-Generation-of-Medical-Image-Mask-Pairs"><a href="#MedSegFactory-Text-Guided-Generation-of-Medical-Image-Mask-Pairs" class="headerlink" title="MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs"></a>MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs</h2><p><strong>Authors:Jiawei Mao, Yuhan Wang, Yucheng Tang, Daguang Xu, Kang Wang, Yang Yang, Zongwei Zhou, Yuyin Zhou</strong></p>
<p>This paper presents MedSegFactory, a versatile medical synthesis framework that generates high-quality paired medical images and segmentation masks across modalities and tasks. It aims to serve as an unlimited data repository, supplying image-mask pairs to enhance existing segmentation tools. The core of MedSegFactory is a dual-stream diffusion model, where one stream synthesizes medical images and the other generates corresponding segmentation masks. To ensure precise alignment between image-mask pairs, we introduce Joint Cross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic cross-conditioning between streams. This bidirectional interaction allows both representations to guide each otherâ€™s generation, enhancing consistency between generated pairs. MedSegFactory unlocks on-demand generation of paired medical images and segmentation masks through user-defined prompts that specify the target labels, imaging modalities, anatomical regions, and pathological conditions, facilitating scalable and high-quality data generation. This new paradigm of medical image synthesis enables seamless integration into diverse medical imaging workflows, enhancing both efficiency and accuracy. Extensive experiments show that MedSegFactory generates data of superior quality and usability, achieving competitive or state-of-the-art performance in 2D and 3D segmentation tasks while addressing data scarcity and regulatory constraints. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†MedSegFactoryï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„åŒ»å­¦åˆæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆè·¨æ¨¡æ€å’Œä»»åŠ¡çš„é«˜è´¨é‡é…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚å®ƒçš„ç›®æ ‡æ˜¯ä½œä¸ºä¸€ä¸ªæ— é™çš„æ•°æ®ä»“åº“ï¼Œæä¾›å›¾åƒ-æ©è†œå¯¹ï¼Œä»¥å¢å¼ºç°æœ‰çš„åˆ†å‰²å·¥å…·ã€‚MedSegFactoryçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªåŒæµæ‰©æ•£æ¨¡å‹ï¼Œå…¶ä¸­ä¸€ä¸ªæµåˆæˆåŒ»å­¦å›¾åƒï¼Œå¦ä¸€ä¸ªæµç”Ÿæˆç›¸åº”çš„åˆ†å‰²æ©è†œã€‚ä¸ºäº†ç¡®ä¿å›¾åƒ-æ©è†œå¯¹ä¹‹é—´çš„ç²¾ç¡®å¯¹é½ï¼Œæˆ‘ä»¬å¼•å…¥äº†è”åˆäº¤å‰æ³¨æ„ï¼ˆJCAï¼‰ï¼Œé€šè¿‡æµä¹‹é—´çš„åŠ¨æ€äº¤å‰æ¡ä»¶ï¼Œå®ç°ååŒå»å™ªæ¨¡å¼ã€‚è¿™ç§åŒå‘äº¤äº’å…è®¸ä¸¤ç§è¡¨ç¤ºç›¸äº’å¼•å¯¼ç”Ÿæˆï¼Œå¢å¼ºç”Ÿæˆå¯¹ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚MedSegFactoryé€šè¿‡ç”¨æˆ·å®šä¹‰çš„æç¤ºè§£é”æŒ‰éœ€ç”Ÿæˆçš„é…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œï¼Œè¿™äº›æç¤ºæŒ‡å®šç›®æ ‡æ ‡ç­¾ã€æˆåƒæ¨¡æ€ã€è§£å‰–åŒºåŸŸå’Œç—…ç†çŠ¶å†µï¼Œä¿ƒè¿›å¯æ‰©å±•å’Œé«˜è´¨é‡çš„æ•°æ®ç”Ÿæˆã€‚è¿™ç§æ–°çš„åŒ»å­¦å›¾åƒåˆæˆæ¨¡å¼èƒ½å¤Ÿæ— ç¼èå…¥å¤šæ ·åŒ–çš„åŒ»å­¦æˆåƒå·¥ä½œæµç¨‹ï¼Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMedSegFactoryç”Ÿæˆçš„æ•°æ®å…·æœ‰å“è¶Šçš„è´¨é‡å’Œå¯ç”¨æ€§ï¼Œåœ¨äºŒç»´å’Œä¸‰ç»´åˆ†å‰²ä»»åŠ¡ä¸­è¾¾åˆ°äº†ç«äº‰æˆ–æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶è§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œç›‘ç®¡çº¦æŸé—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06897v1">PDF</a> 12 pages, 8 figures, The project page can be accessed via   <a target="_blank" rel="noopener" href="https://jwmao1.github.io/MedSegFactory_web">https://jwmao1.github.io/MedSegFactory_web</a></p>
<p><strong>Summary</strong></p>
<p>MedSegFactoryæ˜¯ä¸€ä¸ªé€šç”¨åŒ»ç–—åˆæˆæ¡†æ¶ï¼Œèƒ½ç”Ÿæˆè·¨æ¨¡æ€å’Œä»»åŠ¡çš„é…å¯¹é«˜è´¨é‡åŒ»ç–—å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚å®ƒæ—¨åœ¨ä½œä¸ºä¸€ä¸ªæ— é™çš„æ•°æ®ä»“åº“ï¼Œä¸ºç°æœ‰çš„åˆ†å‰²å·¥å…·æä¾›å›¾åƒ-æ©è†œå¯¹ä»¥å¢å¼ºå…¶æ€§èƒ½ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯åŒé‡æµæ‰©æ•£æ¨¡å‹ï¼Œä¸€ä¸ªæµè´Ÿè´£åˆæˆåŒ»ç–—å›¾åƒï¼Œå¦ä¸€ä¸ªæµç”Ÿæˆç›¸åº”çš„åˆ†å‰²æ©è†œã€‚é€šè¿‡å¼•å…¥è”åˆäº¤å‰æ³¨æ„ï¼ˆJCAï¼‰æœºåˆ¶ï¼Œç¡®ä¿å›¾åƒ-æ©è†œå¯¹ä¹‹é—´çš„ç²¾ç¡®å¯¹é½ã€‚JCAå®ç°äº†æµä¹‹é—´çš„åŠ¨æ€äº¤å‰æ¡ä»¶ï¼Œæ¨åŠ¨ååŒå»å™ªæ¨¡å¼ã€‚è¿™ç§åŒå‘äº¤äº’å…è®¸ä¸¤ä¸ªè¡¨ç¤ºç›¸äº’å¼•å¯¼ç”Ÿæˆï¼Œæé«˜ç”Ÿæˆå¯¹çš„ä¸€è‡´æ€§ã€‚MedSegFactoryé€šè¿‡ç”¨æˆ·å®šä¹‰æç¤ºï¼ŒæŒ‰éœ€ç”Ÿæˆé…å¯¹åŒ»ç–—å›¾åƒå’Œåˆ†å‰²æ©è†œï¼Œæç¤ºå¯æŒ‡å®šç›®æ ‡æ ‡ç­¾ã€æˆåƒæ¨¡å¼ã€è§£å‰–åŒºåŸŸå’Œç—…ç†çŠ¶å†µç­‰ï¼Œä¿ƒè¿›äº†é«˜è´¨é‡æ•°æ®çš„å¯æ‰©å±•ç”Ÿæˆã€‚è¿™ä¸€æ–°çš„åŒ»ç–—å›¾åƒåˆæˆèŒƒå¼å¯æ— ç¼èå…¥å„ç§åŒ»ç–—æˆåƒå·¥ä½œæµç¨‹ï¼Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒMedSegFactoryç”Ÿæˆçš„æ•°æ®è´¨é‡é«˜ã€å®ç”¨æ€§å¼ºï¼Œåœ¨äºŒç»´å’Œä¸‰ç»´åˆ†å‰²ä»»åŠ¡ä¸Šè¾¾åˆ°äº†ç«äº‰æˆ–é¢†å…ˆæ°´å¹³ï¼ŒåŒæ—¶è§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œç›‘ç®¡çº¦æŸé—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MedSegFactoryæ˜¯ä¸€ä¸ªåŒ»ç–—åˆæˆæ¡†æ¶ï¼Œèƒ½ç”Ÿæˆé«˜è´¨é‡é…å¯¹åŒ»ç–—å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨åŒé‡æµæ‰©æ•£æ¨¡å‹ï¼Œåˆ†åˆ«è´Ÿè´£ç”ŸæˆåŒ»ç–—å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚</li>
<li>å¼•å…¥è”åˆäº¤å‰æ³¨æ„ï¼ˆJCAï¼‰æœºåˆ¶ï¼Œç¡®ä¿å›¾åƒå’Œæ©è†œä¹‹é—´çš„ç²¾ç¡®å¯¹é½ã€‚</li>
<li>ç”¨æˆ·å¯ä»¥é€šè¿‡å®šä¹‰æç¤ºï¼ˆå¦‚ç›®æ ‡æ ‡ç­¾ã€æˆåƒæ¨¡å¼ç­‰ï¼‰æŒ‰éœ€ç”Ÿæˆæ•°æ®ã€‚</li>
<li>MedSegFactoryèƒ½æé«˜åŒ»ç–—æˆåƒå·¥ä½œæµç¨‹çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒMedSegFactoryåœ¨æ•°æ®ç”Ÿæˆçš„è´¨é‡å’Œå®ç”¨æ€§ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°æˆ–è¶…è¶Šç°æœ‰æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06897">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c11aeb509d8b84999d1bb0e9b5bd34b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5136966fc5c824d9fe3cd8414dda1962.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1cee1c813ed6277fb8c6167a26c2e967.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a55c3c419f768f5fac8ccae852425662.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a7808eb0580cbb9679c48d802831938.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d78c323a4ded335c2985c17645871aac.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EIDT-V-Exploiting-Intersections-in-Diffusion-Trajectories-for-Model-Agnostic-Zero-Shot-Training-Free-Text-to-Video-Generation"><a href="#EIDT-V-Exploiting-Intersections-in-Diffusion-Trajectories-for-Model-Agnostic-Zero-Shot-Training-Free-Text-to-Video-Generation" class="headerlink" title="EIDT-V: Exploiting Intersections in Diffusion Trajectories for   Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation"></a>EIDT-V: Exploiting Intersections in Diffusion Trajectories for   Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation</h2><p><strong>Authors:Diljeet Jagpal, Xi Chen, Vinay P. Namboodiri</strong></p>
<p>Zero-shot, training-free, image-based text-to-video generation is an emerging area that aims to generate videos using existing image-based diffusion models. Current methods in this space require specific architectural changes to image generation models, which limit their adaptability and scalability. In contrast to such methods, we provide a model-agnostic approach. We use intersections in diffusion trajectories, working only with the latent values. We could not obtain localized frame-wise coherence and diversity using only the intersection of trajectories. Thus, we instead use a grid-based approach. An in-context trained LLM is used to generate coherent frame-wise prompts; another is used to identify differences between frames. Based on these, we obtain a CLIP-based attention mask that controls the timing of switching the prompts for each grid cell. Earlier switching results in higher variance, while later switching results in more coherence. Therefore, our approach can ensure appropriate control between coherence and variance for the frames. Our approach results in state-of-the-art performance while being more flexible when working with diverse image-generation models. The empirical analysis using quantitative metrics and user studies confirms our modelâ€™s superior temporal consistency, visual fidelity and user satisfaction, thus providing a novel way to obtain training-free, image-based text-to-video generation. </p>
<blockquote>
<p>é›¶æ ·æœ¬ã€æ— è®­ç»ƒã€åŸºäºå›¾åƒçš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ˜¯ä¸€ä¸ªæ–°å…´é¢†åŸŸï¼Œæ—¨åœ¨åˆ©ç”¨ç°æœ‰çš„åŸºäºå›¾åƒçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆè§†é¢‘ã€‚ç›®å‰è¯¥é¢†åŸŸçš„æ–¹æ³•éœ€è¦å¯¹å›¾åƒç”Ÿæˆæ¨¡å‹è¿›è¡Œç‰¹å®šçš„æ¶æ„æ›´æ”¹ï¼Œè¿™é™åˆ¶äº†å…¶é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚ä¸æ­¤ç±»æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§ä¸æ¨¡å‹æ— å…³çš„æ–¹æ³•ã€‚æˆ‘ä»¬åªä½¿ç”¨æ‰©æ•£è½¨è¿¹çš„äº¤ç‚¹ï¼Œåªå…³æ³¨æ½œåœ¨å€¼ã€‚ä»…ä½¿ç”¨è½¨è¿¹çš„äº¤ç‚¹ï¼Œæˆ‘ä»¬æ— æ³•è·å¾—å±€éƒ¨å¸§çº§çš„ä¸€è‡´æ€§å’Œå¤šæ ·æ€§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è½¬è€Œä½¿ç”¨åŸºäºç½‘æ ¼çš„æ–¹æ³•ã€‚ä½¿ç”¨ä¸Šä¸‹æ–‡è®­ç»ƒçš„LLMç”Ÿæˆè¿è´¯çš„å¸§çº§æç¤ºï¼›å¦ä¸€ä¸ªç”¨äºè¯†åˆ«å¸§ä¹‹é—´çš„å·®å¼‚ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬è·å¾—äº†åŸºäºCLIPçš„æ³¨æ„åŠ›æ©ç ï¼Œè¯¥æ©ç æ§åˆ¶æ¯ä¸ªç½‘æ ¼å•å…ƒæç¤ºåˆ‡æ¢çš„æ—¶æœºã€‚æå‰åˆ‡æ¢ä¼šå¯¼è‡´æ›´é«˜çš„æ–¹å·®ï¼Œè€Œå»¶è¿Ÿåˆ‡æ¢ä¼šå¯¼è‡´æ›´é«˜çš„è¿è´¯æ€§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨å¸§çš„è¿è´¯æ€§å’Œæ–¹å·®ä¹‹é—´å®ç°é€‚å½“çš„æ§åˆ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨å¤„ç†å„ç§å›¾åƒç”Ÿæˆæ¨¡å‹æ—¶æ›´åŠ çµæ´»ã€‚ä½¿ç”¨å®šé‡æŒ‡æ ‡å’Œç”¨æˆ·ç ”ç©¶è¿›è¡Œçš„å®è¯åˆ†æè¯å®äº†æˆ‘ä»¬æ¨¡å‹åœ¨æ—¶é—´ä¸Šçš„ä¸€è‡´æ€§ã€è§†è§‰ä¿çœŸåº¦å’Œç”¨æˆ·æ»¡æ„åº¦æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œä»è€Œä¸ºæ— è®­ç»ƒã€åŸºäºå›¾åƒçš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæä¾›äº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06861v1">PDF</a> Accepted at IEEE&#x2F;CVF Conference on Computer Vision and Pattern   Recognition (CVPR) 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå›¾åƒçš„æ— è®­ç»ƒæ–‡æœ¬è½¬è§†é¢‘ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£è½¨è¿¹çš„äº¤é›†ï¼Œç»“åˆç½‘æ ¼æŠ€æœ¯å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå®ç°äº†åœ¨å¤šç§å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­çš„çµæ´»åº”ç”¨ã€‚é€šè¿‡æ§åˆ¶åˆ‡æ¢æç¤ºçš„æ—¶é—´ï¼Œå®ç°äº†å¸§é—´çš„ä¸€è‡´æ€§å’Œå¤šæ ·æ€§å¹³è¡¡ã€‚å®è¯åˆ†ææ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ—¶åºä¸€è‡´æ€§ã€è§†è§‰ä¿çœŸåº¦å’Œç”¨æˆ·æ»¡æ„åº¦ä¸Šè¡¨ç°å“è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹çš„äº¤é›†å®ç°é›¶æ ·æœ¬è®­ç»ƒè½¬è§†é¢‘ç”Ÿæˆã€‚</li>
<li>é‡‡ç”¨ç½‘æ ¼æŠ€æœ¯ä»¥å¢å¼ºå±€éƒ¨å¸§çº§çš„è¿è´¯æ€§å’Œå¤šæ ·æ€§ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆè¿è´¯çš„å¸§çº§æç¤ºå’Œè¯†åˆ«å¸§é—´å·®å¼‚ã€‚</li>
<li>é€šè¿‡æ§åˆ¶åˆ‡æ¢æç¤ºçš„æ—¶é—´ï¼Œå®ç°äº†å¸§é—´è¿è´¯æ€§å’Œå¤šæ ·æ€§çš„å¹³è¡¡ã€‚</li>
<li>æ–¹æ³•å…·æœ‰é«˜åº¦çš„æ¨¡å‹é€‚åº”æ€§ï¼Œå¯åœ¨å¤šç§å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­çµæ´»åº”ç”¨ã€‚</li>
<li>å®è¯åˆ†ææ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè¾¾åˆ°æœ€æ–°æ°´å¹³ï¼Œå…·æœ‰å‡ºè‰²çš„æ—¶åºä¸€è‡´æ€§ã€è§†è§‰ä¿çœŸåº¦å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06861">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-317a3781f98fd9b8ee1beb928274ee32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-13539be864b012320483267d01cf4a4e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fca07ae04a61bdc88804fb17dd6ad098.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ae6146ad60658f93215f2d726b5c2ff.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DyDiT-Dynamic-Diffusion-Transformers-for-Efficient-Visual-Generation"><a href="#DyDiT-Dynamic-Diffusion-Transformers-for-Efficient-Visual-Generation" class="headerlink" title="DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation"></a>DyDiT++: Dynamic Diffusion Transformers for Efficient Visual Generation</h2><p><strong>Authors:Wangbo Zhao, Yizeng Han, Jiasheng Tang, Kai Wang, Hao Luo, Yibing Song, Gao Huang, Fan Wang, Yang You</strong></p>
<p>Diffusion Transformer (DiT), an emerging diffusion model for visual generation, has demonstrated superior performance but suffers from substantial computational costs. Our investigations reveal that these costs primarily stem from the \emph{static} inference paradigm, which inevitably introduces redundant computation in certain \emph{diffusion timesteps} and \emph{spatial regions}. To overcome this inefficiency, we propose \textbf{Dy}namic \textbf{Di}ffusion \textbf{T}ransformer (DyDiT), an architecture that \emph{dynamically} adjusts its computation along both \emph{timestep} and \emph{spatial} dimensions. Specifically, we introduce a \emph{Timestep-wise Dynamic Width} (TDW) approach that adapts model width conditioned on the generation timesteps. In addition, we design a \emph{Spatial-wise Dynamic Token} (SDT) strategy to avoid redundant computation at unnecessary spatial locations. TDW and SDT can be seamlessly integrated into DiT and significantly accelerates the generation process. Building on these designs, we further enhance DyDiT in three key aspects. First, DyDiT is integrated seamlessly with flow matching-based generation, enhancing its versatility. Furthermore, we enhance DyDiT to tackle more complex visual generation tasks, including video generation and text-to-image generation, thereby broadening its real-world applications. Finally, to address the high cost of full fine-tuning and democratize technology access, we investigate the feasibility of training DyDiT in a parameter-efficient manner and introduce timestep-based dynamic LoRA (TD-LoRA). Extensive experiments on diverse visual generation models, including DiT, SiT, Latte, and FLUX, demonstrate the effectiveness of DyDiT. </p>
<blockquote>
<p>æ‰©æ•£Transformerï¼ˆDiTï¼‰æ˜¯ä¸€ç§æ–°å…´çš„è§†è§‰ç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œå®ƒè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä½†è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚æˆ‘ä»¬çš„è°ƒæŸ¥è¡¨æ˜ï¼Œè¿™äº›æˆæœ¬ä¸»è¦æºäº\emph{é™æ€}æ¨ç†èŒƒå¼ï¼Œè¿™ç§èŒƒå¼ä¸å¯é¿å…åœ°ä¼šåœ¨æŸäº›\emph{æ‰©æ•£æ—¶é—´æ­¥}å’Œ\emph{ç©ºé—´åŒºåŸŸ}ä¸­å¼•å…¥å†—ä½™è®¡ç®—ã€‚ä¸ºäº†å…‹æœè¿™ç§ä½æ•ˆï¼Œæˆ‘ä»¬æå‡ºäº†\textbf{Dy}namic \textbf{Di}ffusion \textbf{T}ransformerï¼ˆDyDiTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§\emph{åŠ¨æ€}è°ƒæ•´å…¶åœ¨\emph{æ—¶é—´æ­¥}å’Œ\emph{ç©ºé—´}ç»´åº¦ä¸Šè®¡ç®—çš„ç»“æ„ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§\emph{æ—¶é—´æ­¥åŠ¨æ€å®½åº¦}ï¼ˆTDWï¼‰æ–¹æ³•ï¼Œæ ¹æ®ç”Ÿæˆæ—¶é—´æ­¥æ¥é€‚åº”æ¨¡å‹å®½åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§\emph{ç©ºé—´åŠ¨æ€ä»¤ç‰Œ}ï¼ˆSDTï¼‰ç­–ç•¥ï¼Œä»¥é¿å…åœ¨ä¸å¿…è¦çš„ç©ºé—´ä½ç½®è¿›è¡Œå†—ä½™è®¡ç®—ã€‚TDWå’ŒSDTå¯ä»¥æ— ç¼é›†æˆåˆ°DiTä¸­ï¼Œå¹¶æ˜¾è‘—åŠ é€Ÿç”Ÿæˆè¿‡ç¨‹ã€‚åŸºäºè¿™äº›è®¾è®¡ï¼Œæˆ‘ä»¬ä»ä¸‰ä¸ªæ–¹é¢è¿›ä¸€æ­¥å¢å¼ºäº†DyDiTã€‚é¦–å…ˆï¼ŒDyDiTå¯ä»¥æ— ç¼é›†æˆä¸æµåŒ¹é…ç”ŸæˆæŠ€æœ¯ï¼Œå¢å¼ºå…¶é€šç”¨æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¢å¼ºäº†DyDiTï¼Œä»¥è§£å†³æ›´å¤æ‚çš„è§†è§‰ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬è§†é¢‘ç”Ÿæˆå’Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼Œä»è€Œæ‰©å¤§äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚æœ€åï¼Œä¸ºäº†è§£å†³å…¨ç²¾ç»†è°ƒæ•´çš„é«˜æˆæœ¬å¹¶å®ç°æŠ€æœ¯çš„æ°‘ä¸»åŒ–ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä»¥å‚æ•°é«˜æ•ˆçš„æ–¹å¼è®­ç»ƒDyDiTçš„å¯è¡Œæ€§ï¼Œå¹¶å¼•å…¥äº†åŸºäºæ—¶é—´æ­¥çš„åŠ¨æ€LoRAï¼ˆTD-LoRAï¼‰ã€‚åœ¨åŒ…æ‹¬DiTã€SiTã€Latteå’ŒFLUXç­‰å¤šç§è§†è§‰ç”Ÿæˆæ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†DyDiTçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06803v1">PDF</a> Extended journal version for ICLR. arXiv admin note: substantial text   overlap with arXiv:2410.03456</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ‰©æ•£Transformerï¼ˆDiTï¼‰ä½œä¸ºè§†è§‰ç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™äº›æˆæœ¬ä¸»è¦æºäºé™æ€æ¨ç†èŒƒå¼ï¼Œå®ƒåœ¨æŸäº›æ‰©æ•£æ—¶é—´æ­¥é•¿å’Œç©ºé—´åŒºåŸŸä¸­ä¸å¯é¿å…åœ°å¼•å…¥äº†å†—ä½™è®¡ç®—ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ä¸è¶³ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€æ‰©æ•£Transformerï¼ˆDyDiTï¼‰ï¼Œå®ƒèƒ½å¤Ÿåœ¨æ—¶åºå’Œç©ºé—´ç»´åº¦ä¸ŠåŠ¨æ€è°ƒæ•´è®¡ç®—ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ—¶é—´æ­¥é•¿åŠ¨æ€å®½åº¦ï¼ˆTDWï¼‰æ–¹æ³•ï¼Œæ ¹æ®ç”Ÿæˆæ—¶é—´æ­¥é•¿è‡ªé€‚åº”è°ƒæ•´æ¨¡å‹å®½åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ç©ºé—´åŠ¨æ€ä»¤ç‰Œï¼ˆSDTï¼‰ç­–ç•¥ï¼Œä»¥é¿å…ä¸å¿…è¦ç©ºé—´ä½ç½®çš„å†—ä½™è®¡ç®—ã€‚TDWå’ŒSDTå¯ä»¥æ— ç¼é›†æˆåˆ°DiTä¸­ï¼Œæ˜¾è‘—åŠ é€Ÿç”Ÿæˆè¿‡ç¨‹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥ä»ä¸‰ä¸ªæ–¹é¢å¢å¼ºDyDiTã€‚é¦–å…ˆï¼ŒDyDiTå¯ä»¥ä¸åŸºäºæµåŒ¹é…çš„ç”Ÿæˆæ–¹æ³•æ— ç¼é›†æˆï¼Œæé«˜å…¶é€šç”¨æ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¢å¼ºDyDiTä»¥å¤„ç†æ›´å¤æ‚çš„è§†è§‰ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬è§†é¢‘ç”Ÿæˆå’Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼Œä»è€Œæ‰©å¤§å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚æœ€åï¼Œä¸ºäº†è§£å†³å…¨ç²¾ç»†è°ƒæ•´çš„é«˜æˆæœ¬å¹¶å®ç°æŠ€æœ¯æ™®åŠï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä»¥å‚æ•°é«˜æ•ˆçš„æ–¹å¼è®­ç»ƒDyDiTçš„å¯è¡Œæ€§ï¼Œå¹¶å¼•å…¥äº†åŸºäºæ—¶é—´æ­¥é•¿çš„åŠ¨æ€LoRAï¼ˆTD-LoRAï¼‰ã€‚åœ¨å¤šç§è§†è§‰ç”Ÿæˆæ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†DyDiTçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ‰©æ•£Transformerï¼ˆDiTï¼‰åœ¨è§†è§‰ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†å­˜åœ¨é«˜è®¡ç®—æˆæœ¬é—®é¢˜ã€‚</li>
<li>é«˜è®¡ç®—æˆæœ¬ä¸»è¦æºäºé™æ€æ¨ç†èŒƒå¼ï¼Œå¯¼è‡´æŸäº›æ‰©æ•£æ—¶é—´æ­¥é•¿å’Œç©ºé—´åŒºåŸŸçš„å†—ä½™è®¡ç®—ã€‚</li>
<li>æå‡ºäº†åŠ¨æ€æ‰©æ•£Transformerï¼ˆDyDiTï¼‰æ¶æ„ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´è®¡ç®—ä»¥é€‚åº”æ—¶é—´æ­¥é•¿å’Œç©ºé—´ç»´åº¦ã€‚</li>
<li>é€šè¿‡å¼•å…¥æ—¶é—´æ­¥é•¿åŠ¨æ€å®½åº¦ï¼ˆTDWï¼‰å’Œç©ºé—´åŠ¨æ€ä»¤ç‰Œï¼ˆSDTï¼‰ç­–ç•¥ï¼Œå®ç°äº†åœ¨DiTä¸­çš„æ— ç¼é›†æˆå¹¶æ˜¾è‘—åŠ é€Ÿç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>DyDiTä¸åŸºäºæµåŒ¹é…çš„ç”Ÿæˆæ–¹æ³•æ— ç¼é›†æˆï¼Œæé«˜å…¶é€šç”¨æ€§ï¼Œå¹¶èƒ½å¤„ç†æ›´å¤æ‚çš„è§†è§‰ç”Ÿæˆä»»åŠ¡ï¼Œå¦‚è§†é¢‘å’Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚</li>
<li>ä¸ºäº†é™ä½è®­ç»ƒæˆæœ¬ï¼Œç ”ç©¶äº†å‚æ•°é«˜æ•ˆçš„è®­ç»ƒæ–¹æ³•ï¼Œå¹¶å¼•å…¥äº†åŸºäºæ—¶é—´æ­¥é•¿çš„åŠ¨æ€LoRAï¼ˆTD-LoRAï¼‰ã€‚</li>
<li>åœ¨å¤šç§è§†è§‰ç”Ÿæˆæ¨¡å‹ä¸Šçš„å®éªŒè¯æ˜äº†DyDiTçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06803">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1127c0875439f0e5845fa21f7fabbc99.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-955078ccadd86f2db94ae6051465bcc5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e98597211d63e89b31262982a4906b04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df688688a767719ae1963e6731b90bb7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DIMA-DIffusing-Motion-Artifacts-for-unsupervised-correction-in-brain-MRI-images"><a href="#DIMA-DIffusing-Motion-Artifacts-for-unsupervised-correction-in-brain-MRI-images" class="headerlink" title="DIMA: DIffusing Motion Artifacts for unsupervised correction in brain   MRI images"></a>DIMA: DIffusing Motion Artifacts for unsupervised correction in brain   MRI images</h2><p><strong>Authors:Paolo Angella, Luca Balbi, Fabrizio Ferrando, Paolo Traverso, Rosario Varriale, Vito Paolo Pastore, Matteo Santacesaria</strong></p>
<p>Motion artifacts remain a significant challenge in Magnetic Resonance Imaging (MRI), compromising diagnostic quality and potentially leading to misdiagnosis or repeated scans. Existing deep learning approaches for motion artifact correction typically require paired motion-free and motion-affected images for training, which are rarely available in clinical settings. To overcome this requirement, we present DIMA (DIffusing Motion Artifacts), a novel framework that leverages diffusion models to enable unsupervised motion artifact correction in brain MRI. Our two-phase approach first trains a diffusion model on unpaired motion-affected images to learn the distribution of motion artifacts. This model then generates realistic motion artifacts on clean images, creating paired datasets suitable for supervised training of correction networks. Unlike existing methods, DIMA operates without requiring k-space manipulation or detailed knowledge of MRI sequence parameters, making it adaptable across different scanning protocols and hardware. Comprehensive evaluations across multiple datasets and anatomical planes demonstrate that our method achieves comparable performance to state-of-the-art supervised approaches while offering superior generalizability to real clinical data. DIMA represents a significant advancement in making motion artifact correction more accessible for routine clinical use, potentially reducing the need for repeat scans and improving diagnostic accuracy. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­çš„è¿åŠ¨ä¼ªå½±ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œä¼šå½±å“è¯Šæ–­è´¨é‡ï¼Œå¹¶å¯èƒ½å¯¼è‡´è¯¯è¯Šæˆ–é‡å¤æ‰«æã€‚ç°æœ‰çš„ç”¨äºè¿åŠ¨ä¼ªå½±æ ¡æ­£çš„æ·±åº¦å­¦ä¹ æ–¹æ³•é€šå¸¸è¦æ±‚é…å¯¹æ— è¿åŠ¨å’Œå—è¿åŠ¨å½±å“çš„å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨ä¸´åºŠç¯å¢ƒä¸­å¾ˆå°‘å¯ç”¨ã€‚ä¸ºäº†å…‹æœè¿™ä¸€è¦æ±‚ï¼Œæˆ‘ä»¬æå‡ºäº†DIMAï¼ˆæ‰©æ•£è¿åŠ¨ä¼ªå½±ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨æ‰©æ•£æ¨¡å‹å®ç°ç£å…±æŒ¯æˆåƒä¸­æ— ç›‘ç£è¿åŠ¨ä¼ªå½±æ ¡æ­£çš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µæ–¹æ³•é¦–å…ˆä½¿ç”¨æœªé…å¯¹çš„å—è¿åŠ¨å½±å“çš„å›¾åƒè®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥å­¦ä¹ è¿åŠ¨ä¼ªå½±çš„åˆ†å¸ƒã€‚ç„¶åï¼Œè¯¥æ¨¡å‹åœ¨å¹²å‡€çš„å›¾åƒä¸Šç”Ÿæˆé€¼çœŸçš„è¿åŠ¨ä¼ªå½±ï¼Œåˆ›å»ºé€‚åˆç›‘ç£æ ¡æ­£ç½‘ç»œè®­ç»ƒçš„é…å¯¹æ•°æ®é›†ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒDIMAæ— éœ€è¿›è¡Œkç©ºé—´æ“ä½œæˆ–å¯¹MRIåºåˆ—å‚æ•°æœ‰æ·±å…¥äº†è§£ï¼Œå› æ­¤å¯é€‚åº”ä¸åŒçš„æ‰«æåè®®å’Œç¡¬ä»¶ã€‚åœ¨å¤šæ•°æ®é›†å’Œè§£å‰–å¹³é¢çš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨çœŸå®ä¸´åºŠæ•°æ®ä¸Šæä¾›äº†æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚DIMAåœ¨ä½¿è¿åŠ¨ä¼ªå½±æ ¡æ­£æ›´æ˜“äºå¸¸è§„ä¸´åºŠä½¿ç”¨æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œæœ‰æœ›å‡å°‘é‡å¤æ‰«æçš„éœ€è¦ï¼Œæé«˜è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06767v1">PDF</a> 7 pages, 5 figures, 7 tables</p>
<p><strong>Summary</strong><br>ç£å…±æŒ¯æˆåƒä¸­çš„è¿åŠ¨ä¼ªå½±æ˜¯ä¸€å¤§æŒ‘æˆ˜ï¼Œå½±å“è¯Šæ–­è´¨é‡ï¼Œå¯èƒ½å¯¼è‡´è¯¯è¯Šæˆ–é‡å¤æ‰«æã€‚ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•éœ€è¦é…å¯¹æ— è¿åŠ¨å½±å“çš„å›¾åƒå’Œè¿åŠ¨å½±å“çš„å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨ä¸´åºŠç¯å¢ƒä¸­å¾ˆå°‘è§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DIMAï¼ˆæ‰©æ•£è¿åŠ¨ä¼ªå½±ï¼‰ï¼Œä¸€ç§åˆ©ç”¨æ‰©æ•£æ¨¡å‹å®ç°ç£å…±æŒ¯æˆåƒä¸­å¤§è„‘è¿åŠ¨ä¼ªå½±çš„æ— ç›‘ç£æ ¡æ­£çš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µæ–¹æ³•é¦–å…ˆè®­ç»ƒä¸€ä¸ªæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ è¿åŠ¨ä¼ªå½±çš„åˆ†å¸ƒã€‚ç„¶åè¯¥æ¨¡å‹åœ¨æ¸…æ´å›¾åƒä¸Šç”Ÿæˆé€¼çœŸçš„è¿åŠ¨ä¼ªå½±ï¼Œåˆ›å»ºé€‚åˆæ ¡æ­£ç½‘ç»œç›‘ç£è®­ç»ƒçš„é…å¯¹æ•°æ®é›†ã€‚ä¸åŒäºç°æœ‰æ–¹æ³•ï¼ŒDIMAä¸éœ€è¦æ“ä½œkç©ºé—´æˆ–æ·±å…¥äº†è§£ç£å…±æŒ¯æˆåƒåºåˆ—å‚æ•°ï¼Œå…·æœ‰ä¸åŒæ‰«æåè®®å’Œç¡¬ä»¶çš„é€‚åº”æ€§ã€‚åœ¨å¤šæ•°æ®é›†å’Œè§£å‰–å¹³é¢ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ç›¸æ¯”å–å¾—äº†ç›¸å½“çš„æ€§èƒ½ï¼Œåœ¨å®é™…ä¸´åºŠæ•°æ®ä¸Šè¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚DIMAä¸ºå¸¸è§„ä¸´åºŠä½¿ç”¨ä¸­çš„è¿åŠ¨ä¼ªå½±æ ¡æ­£æä¾›äº†æ›´ä¾¿æ·çš„è®¿é—®æ–¹å¼ï¼Œå¯èƒ½å‡å°‘é‡å¤æ‰«æçš„éœ€è¦ï¼Œæé«˜è¯Šæ–­å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿åŠ¨ä¼ªå½±æ˜¯ç£å…±æŒ¯æˆåƒä¸­çš„ä¸€å¤§æŒ‘æˆ˜ï¼Œå½±å“è¯Šæ–­è´¨é‡ã€‚</li>
<li>ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•é€šå¸¸éœ€è¦é…å¯¹çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨ä¸´åºŠç¯å¢ƒä¸­éš¾ä»¥å®ç°ã€‚</li>
<li>DIMAæ¡†æ¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œæ— ç›‘ç£è¿åŠ¨ä¼ªå½±æ ¡æ­£ï¼Œæ— éœ€é…å¯¹æ•°æ®é›†ã€‚</li>
<li>DIMAé€šè¿‡è®­ç»ƒæ‰©æ•£æ¨¡å‹å­¦ä¹ è¿åŠ¨ä¼ªå½±çš„åˆ†å¸ƒï¼Œå¹¶åœ¨æ¸…æ´å›¾åƒä¸Šç”Ÿæˆé€¼çœŸçš„è¿åŠ¨ä¼ªå½±ã€‚</li>
<li>DIMAé€‚ç”¨äºä¸åŒçš„æ‰«æåè®®å’Œç¡¬ä»¶ï¼Œå…·æœ‰å¹¿æ³›çš„é€‚åº”æ€§ã€‚</li>
<li>ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒDIMAæ–¹æ³•ä¸æœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•æ€§èƒ½ç›¸å½“ï¼Œå¹¶åœ¨å®é™…ä¸´åºŠæ•°æ®ä¸Šè¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6e74992e10f847d52dafdc2718c36f58.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34103cf7d6eb078caa10484a31f793b6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53e80aedc03eb915acc701d99287982d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-929426030cfb00e3aeaa0779234f4262.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbcda19f84a0cf529a0398e9d2f0e9ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77601f55a81ff09dde75f18347ee936e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-697ef6fbc73fe02717bc664852d36905.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b34ceb27d95f6ba8b10fab226786db34.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Compass-Control-Multi-Object-Orientation-Control-for-Text-to-Image-Generation"><a href="#Compass-Control-Multi-Object-Orientation-Control-for-Text-to-Image-Generation" class="headerlink" title="Compass Control: Multi Object Orientation Control for Text-to-Image   Generation"></a>Compass Control: Multi Object Orientation Control for Text-to-Image   Generation</h2><p><strong>Authors:Rishbuh Parihar, Vaibhav Agrawal, Sachidanand VS, R. Venkatesh Babu</strong></p>
<p>Existing approaches for controlling text-to-image diffusion models, while powerful, do not allow for explicit 3D object-centric control, such as precise control of object orientation. In this work, we address the problem of multi-object orientation control in text-to-image diffusion models. This enables the generation of diverse multi-object scenes with precise orientation control for each object. The key idea is to condition the diffusion model with a set of orientation-aware \textbf{compass} tokens, one for each object, along with text tokens. A light-weight encoder network predicts these compass tokens taking object orientation as the input. The model is trained on a synthetic dataset of procedurally generated scenes, each containing one or two 3D assets on a plain background. However, direct training this framework results in poor orientation control as well as leads to entanglement among objects. To mitigate this, we intervene in the generation process and constrain the cross-attention maps of each compass token to its corresponding object regions. The trained model is able to achieve precise orientation control for a) complex objects not seen during training and b) multi-object scenes with more than two objects, indicating strong generalization capabilities. Further, when combined with personalization methods, our method precisely controls the orientation of the new object in diverse contexts. Our method achieves state-of-the-art orientation control and text alignment, quantified with extensive evaluations and a user study. </p>
<blockquote>
<p>ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ§åˆ¶æ–¹æ³•è™½ç„¶å¼ºå¤§ï¼Œä½†æ— æ³•å®ç°æ˜ç¡®çš„3Då¯¹è±¡ä¸­å¿ƒæ§åˆ¶ï¼Œä¾‹å¦‚æ— æ³•ç²¾ç¡®æ§åˆ¶å¯¹è±¡çš„æ–¹å‘ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„å¤šå¯¹è±¡æ–¹å‘æ§åˆ¶é—®é¢˜ã€‚è¿™èƒ½å¤Ÿå®ç°ä¸ºæ¯ä¸ªå¯¹è±¡æä¾›ç²¾ç¡®æ–¹å‘æ§åˆ¶çš„å¤šæ ·åŒ–å¤šå¯¹è±¡åœºæ™¯ç”Ÿæˆã€‚ä¸»è¦æ€æƒ³æ˜¯ä½¿ç”¨ä¸€ç»„æ–¹å‘æ„ŸçŸ¥çš„æŒ‡å—é’ˆæ ‡è®°ç¬¦æ¥æ¡ä»¶åŒ–æ‰©æ•£æ¨¡å‹ï¼Œæ¯ä¸ªå¯¹è±¡ä¸€ä¸ªï¼Œä»¥åŠæ–‡æœ¬æ ‡è®°ç¬¦ã€‚ä¸€ä¸ªè½»é‡çº§çš„ç¼–ç å™¨ç½‘ç»œä»¥å¯¹è±¡æ–¹å‘ä½œä¸ºè¾“å…¥æ¥é¢„æµ‹è¿™äº›æŒ‡å—é’ˆæ ‡è®°ç¬¦ã€‚è¯¥æ¨¡å‹æ˜¯åœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œè¯¥æ•°æ®é›†åŒ…å«ç¨‹åºç”Ÿæˆçš„åœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯éƒ½åŒ…å«ä¸€ä¸ªæˆ–ä¸¤ä¸ªåœ¨çº¯è‰²èƒŒæ™¯ä¸Šçš„3Dèµ„äº§ã€‚ç„¶è€Œï¼Œç›´æ¥è®­ç»ƒæ­¤æ¡†æ¶ä¼šå¯¼è‡´æ–¹å‘æ§åˆ¶ä¸ä½³ä»¥åŠå¯¹è±¡ä¹‹é—´çš„çº ç¼ ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è¿›è¡Œå¹²é¢„ï¼Œå¹¶çº¦æŸæ¯ä¸ªæŒ‡å—é’ˆæ ‡è®°ç¬¦çš„äº¤å‰æ³¨æ„åŠ›å›¾åˆ°å…¶å¯¹åº”çš„å¯¹è±¡åŒºåŸŸã€‚è®­ç»ƒå¥½çš„æ¨¡å‹èƒ½å¤Ÿå¯¹ä»¥ä¸‹æ–¹é¢å®ç°ç²¾ç¡®çš„æ–¹å‘æ§åˆ¶ï¼šè®­ç»ƒæœŸé—´æœªè§åˆ°çš„å¤æ‚å¯¹è±¡ä»¥åŠå…·æœ‰è¶…è¿‡ä¸¤ä¸ªå¯¹è±¡çš„å¤šä¸ªå¯¹è±¡åœºæ™¯ï¼Œè¿™æ˜¾ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå½“ä¸ä¸ªäººåŒ–æ–¹æ³•ç›¸ç»“åˆæ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨å„ç§èƒŒæ™¯ä¸‹ç²¾ç¡®åœ°æ§åˆ¶æ–°å¯¹è±¡çš„æ–¹å‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†ä¸šç•Œæœ€ä½³çš„æ–¹å‘æ§åˆ¶å’Œæ–‡æœ¬å¯¹é½ï¼Œè¿™å·²é€šè¿‡å¹¿æ³›è¯„ä¼°å’Œç”¨æˆ·ä½“éªŒå¾—åˆ°äº†éªŒè¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06752v1">PDF</a> <a target="_blank" rel="noopener" href="https://rishubhpar.github.io/compasscontrol">https://rishubhpar.github.io/compasscontrol</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å¤šå¯¹è±¡æ–¹å‘æ§åˆ¶çš„é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥æ–¹å‘æ„ŸçŸ¥æŒ‡å—é’ˆä»¤ç‰Œï¼Œå®ç°å¯¹æ¯ä¸ªå¯¹è±¡ç²¾ç¡®çš„æ–¹å‘æ§åˆ¶ï¼Œç”Ÿæˆå¤šæ ·åŒ–å¤šå¯¹è±¡åœºæ™¯ã€‚è®­ç»ƒæ¨¡å‹èƒ½å¤Ÿåœ¨å¤æ‚å¯¹è±¡åŠå¤šå¯¹è±¡åœºæ™¯ä¸­å®ç°ç²¾ç¡®çš„æ–¹å‘æ§åˆ¶ï¼Œå¹¶ä¸ä¸ªæ€§åŒ–æ–¹æ³•ç»“åˆï¼Œå®ç°æ–°å¯¹è±¡åœ¨å¤šæ ·åŒ–ä¸Šä¸‹æ–‡ä¸­çš„ç²¾ç¡®æ–¹å‘æ§åˆ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥æŒ‡å—é’ˆä»¤ç‰Œä»¥å®ç°æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å¤šå¯¹è±¡çš„ç²¾ç¡®æ–¹å‘æ§åˆ¶ã€‚</li>
<li>é€šè¿‡è½»é‡çº§ç¼–ç å™¨ç½‘ç»œé¢„æµ‹æ¯ä¸ªå¯¹è±¡çš„æŒ‡å—é’ˆä»¤ç‰Œã€‚</li>
<li>æ¨¡å‹åœ¨åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒåŒ…å«å•ä¸ªæˆ–ä¸¤ä¸ª3Dèµ„äº§åœ¨å¹³é¢èƒŒæ™¯ä¸Šçš„åœºæ™¯ã€‚</li>
<li>é€šè¿‡å¹²é¢„ç”Ÿæˆè¿‡ç¨‹å¹¶çº¦æŸæ¯ä¸ªæŒ‡å—é’ˆä»¤ç‰Œçš„è·¨æ³¨æ„åŠ›å›¾ï¼Œè§£å†³æ–¹å‘æ§åˆ¶åŠå¯¹è±¡çº ç¼ é—®é¢˜ã€‚</li>
<li>æ¨¡å‹å¯¹æœªè§è¿‡çš„å¤æ‚å¯¹è±¡åŠå¤šå¯¹è±¡åœºæ™¯å®ç°ç²¾ç¡®æ–¹å‘æ§åˆ¶ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä¸ä¸ªæ€§åŒ–æ–¹æ³•ç»“åˆï¼Œå®ç°åœ¨å¤šæ ·åŒ–ä¸Šä¸‹æ–‡ä¸­çš„æ–°å¯¹è±¡ç²¾ç¡®æ–¹å‘æ§åˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06752">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5041322a152e249617ad6fbb20170b71.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed35c1bd7ef2fb4aff5d0f637ed94416.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f3ab88cacb1f0cfbb2e3c791b4666a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7655129300f1112574d111e423eaa2a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-443723f016076811fcfe017589519781.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a960d32b746050e6ce429b39cb55f81.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Probability-Density-Geodesics-in-Image-Diffusion-Latent-Space"><a href="#Probability-Density-Geodesics-in-Image-Diffusion-Latent-Space" class="headerlink" title="Probability Density Geodesics in Image Diffusion Latent Space"></a>Probability Density Geodesics in Image Diffusion Latent Space</h2><p><strong>Authors:Qingtao Yu, Jaskirat Singh, Zhaoyuan Yang, Peter Henry Tu, Jing Zhang, Hongdong Li, Richard Hartley, Dylan Campbell</strong></p>
<p>Diffusion models indirectly estimate the probability density over a data space, which can be used to study its structure. In this work, we show that geodesics can be computed in diffusion latent space, where the norm induced by the spatially-varying inner product is inversely proportional to the probability density. In this formulation, a path that traverses a high density (that is, probable) region of image latent space is shorter than the equivalent path through a low density region. We present algorithms for solving the associated initial and boundary value problems and show how to compute the probability density along the path and the geodesic distance between two points. Using these techniques, we analyze how closely video clips approximate geodesics in a pre-trained image diffusion space. Finally, we demonstrate how these techniques can be applied to training-free image sequence interpolation and extrapolation, given a pre-trained image diffusion model. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡é—´æ¥ä¼°è®¡æ•°æ®ç©ºé—´çš„æ¦‚ç‡å¯†åº¦ï¼Œå¯ç”¨äºç ”ç©¶å…¶ç»“æ„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨æ‰©æ•£æ½œåœ¨ç©ºé—´ä¸­è®¡ç®—æµ‹åœ°çº¿ï¼Œå…¶ä¸­ç”±ç©ºé—´å˜åŒ–çš„å†…ç§¯å¼•èµ·çš„èŒƒæ•°ä¸æ¦‚ç‡å¯†åº¦æˆåæ¯”ã€‚åœ¨è¿™ç§è¡¨è¿°ä¸­ï¼Œéå†å›¾åƒæ½œåœ¨ç©ºé—´çš„é«˜å¯†åº¦ï¼ˆå³å¯èƒ½çš„ï¼‰åŒºåŸŸçš„è·¯å¾„æ¯”é€šè¿‡ä½å¯†åº¦åŒºåŸŸçš„ç­‰æ•ˆè·¯å¾„æ›´çŸ­ã€‚æˆ‘ä»¬æå‡ºäº†è§£å†³ç›¸å…³åˆå§‹å€¼å’Œè¾¹ç•Œå€¼é—®é¢˜çš„ç®—æ³•ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•è®¡ç®—è·¯å¾„ä¸Šçš„æ¦‚ç‡å¯†åº¦ä»¥åŠä¸¤ç‚¹ä¹‹é—´çš„æµ‹åœ°è·ç¦»ã€‚ä½¿ç”¨è¿™äº›æŠ€æœ¯ï¼Œæˆ‘ä»¬åˆ†æäº†è§†é¢‘å‰ªè¾‘åœ¨é¢„è®­ç»ƒçš„å›¾åƒæ‰©æ•£ç©ºé—´ä¸­å¦‚ä½•è¿‘ä¼¼æµ‹åœ°çº¿ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨ç»™å®šé¢„è®­ç»ƒçš„å›¾åƒæ‰©æ•£æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå°†è¿™äº›æŠ€æœ¯åº”ç”¨äºæ— è®­ç»ƒå›¾åƒåºåˆ—çš„æ’å€¼å’Œå¤–æ¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06675v1">PDF</a> CVPR2025</p>
<p><strong>Summary</strong><br>     æ‰©æ•£æ¨¡å‹é€šè¿‡ä¼°è®¡æ•°æ®ç©ºé—´çš„æ¦‚ç‡å¯†åº¦æ¥ç ”ç©¶å…¶ç»“æ„ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åœ¨æ‰©æ•£æ½œåœ¨ç©ºé—´è®¡ç®—æµ‹åœ°çº¿ï¼Œå…¶ä¸­ç”±ç©ºé—´å˜åŒ–å†…ç§¯è¯±å¯¼çš„èŒƒæ•°ä¸æ¦‚ç‡å¯†åº¦æˆåæ¯”ã€‚åœ¨é«˜å¯†åº¦åŒºåŸŸï¼ˆå³å¯èƒ½çš„ï¼‰å›¾åƒæ½œåœ¨ç©ºé—´ä¸­çš„è·¯å¾„æ¯”ä½å¯†åº¦åŒºåŸŸçš„ç­‰æ•ˆè·¯å¾„æ›´çŸ­ã€‚æˆ‘ä»¬æå‡ºäº†è§£å†³ç›¸å…³åˆå§‹å’Œè¾¹ç•Œå€¼é—®é¢˜çš„ç®—æ³•ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•è®¡ç®—è·¯å¾„ä¸Šçš„æ¦‚ç‡å¯†åº¦å’Œä¸¤ç‚¹ä¹‹é—´çš„æµ‹åœ°è·ç¦»ã€‚åˆ©ç”¨è¿™äº›æŠ€æœ¯ï¼Œæˆ‘ä»¬åˆ†æäº†è§†é¢‘å‰ªè¾‘åœ¨é¢„è®­ç»ƒå›¾åƒæ‰©æ•£ç©ºé—´ä¸­çš„æµ‹åœ°çº¿è·¯è¿‘ä¼¼ç¨‹åº¦ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨ç»™å®šé¢„è®­ç»ƒå›¾åƒæ‰©æ•£æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå°†è¿™äº›æŠ€æœ¯åº”ç”¨äºæ— è®­ç»ƒå›¾åƒåºåˆ—çš„æ’å€¼å’Œé¢„æµ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿä¼°è®¡æ•°æ®ç©ºé—´çš„æ¦‚ç‡å¯†åº¦ï¼Œç”¨äºç ”ç©¶å…¶ç»“æ„ã€‚</li>
<li>åœ¨æ‰©æ•£æ½œåœ¨ç©ºé—´ä¸­å¯ä»¥è®¡ç®—æµ‹åœ°çº¿ï¼Œå…¶ä¸­èŒƒæ•°ä¸æ¦‚ç‡å¯†åº¦æˆåæ¯”ã€‚</li>
<li>é«˜å¯†åº¦åŒºåŸŸçš„å›¾åƒæ½œåœ¨ç©ºé—´è·¯å¾„æ¯”ä½å¯†åº¦åŒºåŸŸæ›´çŸ­ã€‚</li>
<li>æå‡ºäº†è§£å†³åˆå§‹å’Œè¾¹ç•Œå€¼é—®é¢˜çš„ç®—æ³•æ¥è®¡ç®—è·¯å¾„ä¸Šçš„æ¦‚ç‡å¯†åº¦å’Œä¸¤ç‚¹ä¹‹é—´çš„æµ‹åœ°è·ç¦»ã€‚</li>
<li>è§†é¢‘å‰ªè¾‘åœ¨é¢„è®­ç»ƒå›¾åƒæ‰©æ•£ç©ºé—´ä¸­çš„è·¯å¾„å¯è¿‘ä¼¼ä¸ºæµ‹åœ°çº¿ã€‚</li>
<li>æ‰€ææŠ€æœ¯å¯ç”¨äºæ— è®­ç»ƒå›¾åƒåºåˆ—çš„æ’å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06675">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4539551b6f0967aecb2b3f1cabaec763.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d06b122adb1825e79c3a16d4ba9b898.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b296e7c1379b1ae87ad2cd2a3b809087.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f34efe72965049724f3fa2baf72f5e30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-652fbb387a0eea35ddddc517bb64e55a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Meta-LoRA-Meta-Learning-LoRA-Components-for-Domain-Aware-ID-Personalization"><a href="#Meta-LoRA-Meta-Learning-LoRA-Components-for-Domain-Aware-ID-Personalization" class="headerlink" title="Meta-LoRA: Meta-Learning LoRA Components for Domain-Aware ID   Personalization"></a>Meta-LoRA: Meta-Learning LoRA Components for Domain-Aware ID   Personalization</h2><p><strong>Authors:BarÄ±ÅŸ Batuhan Topal, Umut Ã–zyurt, Zafer DoÄŸan Budak, Ramazan Gokberk Cinbis</strong></p>
<p>Recent advancements in text-to-image generative models, particularly latent diffusion models (LDMs), have demonstrated remarkable capabilities in synthesizing high-quality images from textual prompts. However, achieving identity personalization-ensuring that a model consistently generates subject-specific outputs from limited reference images-remains a fundamental challenge. To address this, we introduce Meta-Low-Rank Adaptation (Meta-LoRA), a novel framework that leverages meta-learning to encode domain-specific priors into LoRA-based identity personalization. Our method introduces a structured three-layer LoRA architecture that separates identity-agnostic knowledge from identity-specific adaptation. In the first stage, the LoRA Meta-Down layers are meta-trained across multiple subjects, learning a shared manifold that captures general identity-related features. In the second stage, only the LoRA-Mid and LoRA-Up layers are optimized to specialize on a given subject, significantly reducing adaptation time while improving identity fidelity. To evaluate our approach, we introduce Meta-PHD, a new benchmark dataset for identity personalization, and compare Meta-LoRA against state-of-the-art methods. Our results demonstrate that Meta-LoRA achieves superior identity retention, computational efficiency, and adaptability across diverse identity conditions. Our code, model weights, and dataset are released on barisbatuhan.github.io&#x2F;Meta-LoRA. </p>
<blockquote>
<p>è¿‘æœŸæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„è¿›å±•ï¼Œå°¤å…¶æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ï¼Œå·²ç»æ˜¾ç¤ºå‡ºä»æ–‡æœ¬æç¤ºåˆæˆé«˜è´¨é‡å›¾åƒæ–¹é¢çš„æ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ç°èº«ä»½ä¸ªæ€§åŒ–â€”â€”ç¡®ä¿æ¨¡å‹ä»æœ‰é™çš„å‚è€ƒå›¾åƒä¸­ä¸€è‡´åœ°ç”Ÿæˆç‰¹å®šä¸»é¢˜çš„è¾“å‡ºâ€”â€”ä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Meta-Low-Rank Adaptationï¼ˆMeta-LoRAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å…ƒå­¦ä¹ å°†é¢†åŸŸç‰¹å®šå…ˆéªŒç¼–ç åˆ°åŸºäºLoRAçš„èº«ä»½ä¸ªæ€§åŒ–çš„æ–°å‹æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªç»“æ„åŒ–çš„ä¸‰å±‚LoRAæ¶æ„ï¼Œå°†èº«ä»½æ— å…³çš„çŸ¥è¯†ä¸èº«ä»½ç‰¹å®šçš„é€‚åº”åˆ†ç¦»ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ŒLoRA Meta-Downå±‚åœ¨å¤šä¸ªä¸»é¢˜ä¹‹é—´è¿›è¡Œå…ƒè®­ç»ƒï¼Œå­¦ä¹ ä¸€ä¸ªå…±äº«æµå½¢ï¼Œä»¥æ•è·ä¸èº«ä»½ç›¸å…³çš„é€šç”¨ç‰¹å¾ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œä»…ä¼˜åŒ–LoRA-Midå’ŒLoRA-Upå±‚ä»¥é’ˆå¯¹ç»™å®šä¸»é¢˜è¿›è¡Œä¸“ä¸šåŒ–å¤„ç†ï¼Œè¿™æ˜¾è‘—å‡å°‘äº†é€‚åº”æ—¶é—´ï¼ŒåŒæ—¶æé«˜äº†èº«ä»½ä¿çœŸåº¦ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¼•å…¥äº†Meta-PHDï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºèº«ä»½ä¸ªæ€§åŒ–çš„æ–°åŸºå‡†æ•°æ®é›†ï¼Œå¹¶æ¯”è¾ƒäº†Meta-LoRAä¸æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒMeta-LoRAåœ¨èº«ä»½ä¿ç•™ã€è®¡ç®—æ•ˆç‡å’Œé€‚åº”å„ç§èº«ä»½æ¡ä»¶æ–¹é¢éƒ½å…·æœ‰ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ä»£ç ã€æ¨¡å‹æƒé‡å’Œæ•°æ®é›†å·²åœ¨barisbatuhan.github.io&#x2F;Meta-LoRAä¸Šå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22352v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ã€‚é’ˆå¯¹èº«ä»½ä¸ªæ€§åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶Meta-LoRAï¼Œåˆ©ç”¨å…ƒå­¦ä¹ å°†é¢†åŸŸç‰¹å®šå…ˆéªŒçŸ¥è¯†ç¼–ç åˆ°åŸºäºLoRAçš„èº«ä»½ä¸ªæ€§åŒ–ä¸­ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªç»“æ„åŒ–çš„ä¸‰å±‚LoRAæ¶æ„ï¼Œå°†èº«ä»½æ— å…³çš„çŸ¥è¯†ä¸èº«ä»½ç‰¹å®šçš„é€‚åº”åˆ†ç¦»ã€‚åœ¨å¤šä¸ªä¸»ä½“ä¹‹é—´è¿›è¡Œå…ƒè®­ç»ƒï¼Œå­¦ä¹ å…±äº«æµå½¢æ•æ‰ä¸€èˆ¬èº«ä»½ç›¸å…³ç‰¹å¾ã€‚ç„¶ååœ¨ç¬¬äºŒé˜¶æ®µï¼Œä»…ä¼˜åŒ–LoRA-Midå’ŒLoRA-Upå±‚ä»¥é€‚åº”ç»™å®šä¸»ä½“ï¼Œæé«˜äº†èº«ä»½ä¿çœŸåº¦å’Œè®¡ç®—æ•ˆç‡ã€‚ä¸ºè¯„ä¼°æ–¹æ³•ï¼Œå¼•å…¥äº†Meta-PHDæ–°åŸºå‡†æ•°æ®é›†ï¼Œå¹¶ä¸æœ€æ–°æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œç»“æœè¡¨æ˜Meta-LoRAåœ¨èº«ä»½ä¿ç•™ã€è®¡ç®—æ•ˆç‡å’Œé€‚åº”æ€§æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ï¼Œåœ¨åˆæˆé«˜è´¨é‡å›¾åƒæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚</li>
<li>èº«ä»½ä¸ªæ€§åŒ–æ˜¯ç¡®ä¿æ¨¡å‹ä»æœ‰é™å‚è€ƒå›¾åƒä¸­ä¸€è‡´ç”Ÿæˆç‰¹å®šä¸»ä½“è¾“å‡ºçš„é‡è¦æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶Meta-LoRAï¼Œåˆ©ç”¨å…ƒå­¦ä¹ å’ŒLoRAæ¶æ„è¿›è¡Œèº«ä»½ä¸ªæ€§åŒ–ã€‚</li>
<li>Meta-LoRAé€šè¿‡åˆ†ç¦»èº«ä»½æ— å…³çŸ¥è¯†å’Œèº«ä»½ç‰¹å®šé€‚åº”ï¼Œæé«˜äº†èº«ä»½ä¿çœŸåº¦å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>å¼•å…¥äº†Meta-PHDåŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°èº«ä»½ä¸ªæ€§åŒ–æ–¹æ³•çš„æ•ˆæœã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMeta-LoRAåœ¨èº«ä»½ä¿ç•™ã€è®¡ç®—æ•ˆç‡å’Œé€‚åº”æ€§æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>å…¬å¼€äº†ä»£ç ã€æ¨¡å‹æƒé‡å’Œæ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22352">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-067fa2d2ca8e71c2b0a309c4667e56bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11920b70becab08bdd624fada76a071c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24713df8339c1de4e054dc71bf6c9b3b.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Privacy-Attacks-on-Image-AutoRegressive-Models"><a href="#Privacy-Attacks-on-Image-AutoRegressive-Models" class="headerlink" title="Privacy Attacks on Image AutoRegressive Models"></a>Privacy Attacks on Image AutoRegressive Models</h2><p><strong>Authors:Antoni Kowalczuk, Jan DubiÅ„ski, Franziska Boenisch, Adam Dziedzic</strong></p>
<p>Image autoregressive generation has emerged as a powerful new paradigm, with image autoregressive models (IARs) matching state-of-the-art diffusion models (DMs) in image quality (FID: 1.48 vs. 1.58) while allowing for higher generation speed. However, the privacy risks associated with IARs remain unexplored, raising concerns about their responsible deployment. To address this gap, we conduct a comprehensive privacy analysis of IARs, comparing their privacy risks to those of DMs as a reference point. Specifically, we develop a novel membership inference attack (MIA) that achieves a remarkably high success rate in detecting training images, with a True Positive Rate at False Positive Rate &#x3D; 1% (TPR@FPR&#x3D;1%) of 86.38%, compared to just 6.38% for DMs using comparable attacks. We leverage our novel MIA to perform dataset inference (DI) for IARs and show that it requires as few as 6 samples to detect dataset membership, compared to 200 samples for DI in DMs. This confirms a higher level of information leakage in IARs. Finally, we are able to extract hundreds of training data points from an IAR (e.g., 698 from VAR-d30). Our results suggest a fundamental privacy-utility trade-off: while IARs excel in image generation quality and speed, they are empirically significantly more vulnerable to privacy attacks compared to DMs that achieve similar performance. This trend suggests that incorporating techniques from DMs into IARs, such as modeling the per-token probability distribution using a diffusion procedure, could help mitigate IARsâ€™ vulnerability to privacy attacks. We make our code available at: <a target="_blank" rel="noopener" href="https://github.com/sprintml/privacy_attacks_against_iars">https://github.com/sprintml/privacy_attacks_against_iars</a> </p>
<blockquote>
<p>å›¾åƒè‡ªå›å½’ç”Ÿæˆå·²ç»æˆä¸ºä¸€ç§å¼ºå¤§çš„æ–°èŒƒå¼ï¼Œå›¾åƒè‡ªå›å½’æ¨¡å‹ï¼ˆIARsï¼‰åœ¨å›¾åƒè´¨é‡æ–¹é¢ä¸æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ç›¸åŒ¹é…ï¼ˆFIDï¼š1.48 vs. 1.58ï¼‰ï¼ŒåŒæ—¶å…è®¸æ›´é«˜çš„ç”Ÿæˆé€Ÿåº¦ã€‚ç„¶è€Œï¼Œä¸IARsç›¸å…³çš„éšç§é£é™©å°šæœªå¾—åˆ°æ¢ç´¢ï¼Œè¿™å¼•å‘äº†å¯¹å…¶è´Ÿè´£ä»»éƒ¨ç½²çš„æ‹…å¿§ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¯¹IARsè¿›è¡Œäº†å…¨é¢çš„éšç§åˆ†æï¼Œå¹¶å°†å…¶éšç§é£é™©ä¸DMsä½œä¸ºå‚è€ƒç‚¹è¿›è¡Œæ¯”è¾ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼ˆMIAï¼‰ï¼Œè¯¥æ”»å‡»åœ¨æ£€æµ‹è®­ç»ƒå›¾åƒæ–¹é¢å–å¾—äº†éå¸¸é«˜çš„æˆåŠŸç‡ï¼Œåœ¨å‡é˜³æ€§ç‡ï¼ˆFPRï¼‰&#x3D; 1%çš„æƒ…å†µä¸‹ï¼ŒçœŸé˜³æ€§ç‡ï¼ˆTPRï¼‰è¾¾åˆ°86.38%ï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼Œä½¿ç”¨ç±»ä¼¼æ”»å‡»çš„DMsä»…ä¸º6.38%ã€‚æˆ‘ä»¬åˆ©ç”¨æ–°å‹MIAå¯¹IARsè¿›è¡Œæ•°æ®é›†æ¨ç†ï¼ˆDIï¼‰ï¼Œç»“æœè¡¨æ˜åªéœ€6ä¸ªæ ·æœ¬å³å¯æ£€æµ‹æ•°æ®é›†æˆå‘˜èº«ä»½ï¼Œè€ŒDMsè¿›è¡ŒDIåˆ™éœ€è¦200ä¸ªæ ·æœ¬ã€‚è¿™è¯å®äº†IARsä¸­å­˜åœ¨æ›´é«˜ç¨‹åº¦çš„ä¿¡æ¯æ³„éœ²ã€‚æœ€åï¼Œæˆ‘ä»¬èƒ½å¤Ÿä»IARä¸­æå–æ•°ç™¾ä¸ªè®­ç»ƒæ•°æ®ç‚¹ï¼ˆä¾‹å¦‚ï¼Œä»VAR-d30ä¸­æå–698ä¸ªï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜å­˜åœ¨åŸºæœ¬çš„éšç§æ•ˆç”¨æƒè¡¡ï¼šè™½ç„¶IARåœ¨å›¾åƒç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬å®é™…ä¸Šæ›´å®¹æ˜“å—åˆ°éšç§æ”»å‡»ï¼Œä¸è¡¨ç°ç›¸ä¼¼çš„DMsç›¸æ¯”ï¼Œè¿™è¡¨ç°å‡ºæ˜æ˜¾çš„è„†å¼±æ€§ã€‚è¿™ä¸€è¶‹åŠ¿è¡¨æ˜ï¼Œå°†DMsçš„æŠ€æœ¯èå…¥IARsä¸­ï¼Œä¾‹å¦‚ä½¿ç”¨æ‰©æ•£è¿‡ç¨‹å¯¹æ¯ä»¤ç‰Œæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œå¯èƒ½æœ‰åŠ©äºå‡è½»IARså¯¹éšç§æ”»å‡»çš„è„†å¼±æ€§ã€‚æˆ‘ä»¬å·²å°†ä»£ç æ”¾åœ¨<a target="_blank" rel="noopener" href="https://github.com/sprintml/privacy_attacks_against_iars%E4%BE%9B%E5%85%AC%E4%BC%97%E6%9F%A5%E9%98%85%E3%80%82">https://github.com/sprintml/privacy_attacks_against_iarsä¾›å…¬ä¼—æŸ¥é˜…ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.02514v3">PDF</a> Code: <a target="_blank" rel="noopener" href="https://github.com/sprintml/privacy_attacks_against_iars">https://github.com/sprintml/privacy_attacks_against_iars</a></p>
<p><strong>Summary</strong></p>
<p>å›¾åƒè‡ªå›å½’ç”Ÿæˆæ¨¡å‹ï¼ˆIARsï¼‰ä½œä¸ºä¸€ç§æ–°å…´çš„å¼ºå¤§èŒƒå¼ï¼Œåœ¨å›¾åƒè´¨é‡æ–¹é¢ä¸æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ç›¸åŒ¹é…ï¼ŒåŒæ—¶å…è®¸æ›´é«˜çš„ç”Ÿæˆé€Ÿåº¦ã€‚ç„¶è€Œï¼ŒIARsçš„éšç§é£é™©å°šæœªæ¢ç´¢ï¼Œå¼•å‘äº†å¯¹å…¶è´Ÿè´£ä»»éƒ¨ç½²çš„æ‹…å¿§ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¯¹IARsè¿›è¡Œäº†å…¨é¢çš„éšç§åˆ†æï¼Œå¹¶å°†å…¶ä¸DMsçš„éšç§é£é™©è¿›è¡Œæ¯”è¾ƒã€‚ç ”ç©¶å‘ç°ï¼ŒIARsåœ¨ä¿¡æ¯æ³„éœ²æ–¹é¢å­˜åœ¨æ›´é«˜çš„é£é™©ï¼Œæ›´æ˜“å—åˆ°éšç§æ”»å‡»ã€‚å°½ç®¡IARsåœ¨å›¾åƒç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ä¸DMsç›¸æ¯”ï¼Œå®ƒä»¬æ›´å®¹æ˜“å—åˆ°éšç§æ”»å‡»ã€‚å› æ­¤ï¼Œå»ºè®®å°†DMsçš„æŠ€æœ¯èå…¥IARsä¸­ï¼Œä»¥æé«˜å…¶æŠµå¾¡éšç§æ”»å‡»çš„èƒ½åŠ›ã€‚å®Œæ•´çš„ç ”ç©¶ç»“æœå·²å…¬å¼€äºGitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒè‡ªå›å½’ç”Ÿæˆæ¨¡å‹ï¼ˆIARsï¼‰åœ¨å›¾åƒè´¨é‡ä¸Šå¯ä¸æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ç›¸åŒ¹é…ï¼Œä½†ç”Ÿæˆé€Ÿåº¦æ›´å¿«ã€‚</li>
<li>IARsçš„éšç§é£é™©å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œå­˜åœ¨æ½œåœ¨çš„éšç§æ³„éœ²é—®é¢˜ã€‚</li>
<li>é€šè¿‡æ–°å‹çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼ˆMIAï¼‰ï¼Œå‘ç°IARsåœ¨æ£€æµ‹è®­ç»ƒå›¾åƒæ–¹é¢çš„æˆåŠŸç‡éå¸¸é«˜ï¼Œè¾¾åˆ°86.38%ã€‚</li>
<li>IARsçš„æ•°æ®é›†æ¨ç†ï¼ˆDIï¼‰ä»…éœ€6ä¸ªæ ·æœ¬å³å¯æ£€æµ‹æ•°æ®é›†æˆå‘˜ï¼Œç›¸æ¯”ä¹‹ä¸‹DMséœ€è¦200ä¸ªæ ·æœ¬ã€‚</li>
<li>IARsæ›´å®¹æ˜“å—åˆ°éšç§æ”»å‡»ï¼Œè¡¨ç°å‡ºè¾ƒé«˜çš„ä¿¡æ¯æ³„éœ²é£é™©ã€‚</li>
<li>å°½ç®¡IARsåœ¨å›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ä¸DMsç›¸æ¯”ï¼Œå®ƒä»¬å­˜åœ¨éšç§ä¸æ•ˆç”¨çš„æƒè¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.02514">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dbdc0e1440c5ebd749ee51a4528e123c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7b62fdde08f1ecb2ec199d326c14d19.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GenCAD-Image-Conditioned-Computer-Aided-Design-Generation-with-Transformer-Based-Contrastive-Representation-and-Diffusion-Priors"><a href="#GenCAD-Image-Conditioned-Computer-Aided-Design-Generation-with-Transformer-Based-Contrastive-Representation-and-Diffusion-Priors" class="headerlink" title="GenCAD: Image-Conditioned Computer-Aided Design Generation with   Transformer-Based Contrastive Representation and Diffusion Priors"></a>GenCAD: Image-Conditioned Computer-Aided Design Generation with   Transformer-Based Contrastive Representation and Diffusion Priors</h2><p><strong>Authors:Md Ferdous Alam, Faez Ahmed</strong></p>
<p>The creation of manufacturable and editable 3D shapes through Computer-Aided Design (CAD) remains a highly manual and time-consuming task, hampered by the complex topology of boundary representations of 3D solids and unintuitive design tools. While most work in the 3D shape generation literature focuses on representations like meshes, voxels, or point clouds, practical engineering applications demand the modifiability and manufacturability of CAD models and the ability for multi-modal conditional CAD model generation. This paper introduces GenCAD, a generative model that employs autoregressive transformers with a contrastive learning framework and latent diffusion models to transform image inputs into parametric CAD command sequences, resulting in editable 3D shape representations. Extensive evaluations demonstrate that GenCAD significantly outperforms existing state-of-the-art methods in terms of the unconditional and conditional generations of CAD models. Additionally, the contrastive learning framework of GenCAD facilitates the retrieval of CAD models using image queries from large CAD databases, which is a critical challenge within the CAD community. Our results provide a significant step forward in highlighting the potential of generative models to expedite the entire design-to-production pipeline and seamlessly integrate different design modalities. </p>
<blockquote>
<p>é€šè¿‡è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰åˆ›å»ºå¯åˆ¶é€ å’Œå¯ç¼–è¾‘çš„3Då½¢çŠ¶ä»ç„¶æ˜¯ä¸€é¡¹é«˜åº¦æ‰‹åŠ¨å’Œæ—¶é—´å¯†é›†çš„ä»»åŠ¡ï¼Œå—åˆ°3Då®ä½“è¾¹ç•Œè¡¨ç¤ºå¤æ‚æ‹“æ‰‘å’Œéç›´è§‚è®¾è®¡å·¥å…·çš„é™åˆ¶ã€‚å°½ç®¡3Då½¢çŠ¶ç”Ÿæˆæ–‡çŒ®ä¸­çš„å¤§å¤šæ•°å·¥ä½œéƒ½é›†ä¸­åœ¨ç½‘æ ¼ã€ä½“ç´ æˆ–ç‚¹äº‘ç­‰è¡¨ç¤ºæ–¹æ³•ä¸Šï¼Œä½†å®ç”¨å·¥ç¨‹åº”ç”¨è¦æ±‚CADæ¨¡å‹çš„å¯ä¿®æ”¹æ€§å’Œå¯åˆ¶é€ æ€§ï¼Œä»¥åŠå¤šæ¨¡å¼æ¡ä»¶CADæ¨¡å‹ç”Ÿæˆçš„èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†GenCADï¼Œå®ƒæ˜¯ä¸€ç§é‡‡ç”¨è‡ªå›å½’å˜å‹å™¨å’Œå¯¹æ¯”å­¦ä¹ æ¡†æ¶ä»¥åŠæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿå°†å›¾åƒè¾“å…¥è½¬æ¢ä¸ºå‚æ•°åŒ–CADå‘½ä»¤åºåˆ—ï¼Œä»è€Œäº§ç”Ÿå¯ç¼–è¾‘çš„3Då½¢çŠ¶è¡¨ç¤ºã€‚å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒGenCADåœ¨æ— æ¡ä»¶å’Œæœ‰æ¡ä»¶çš„CADæ¨¡å‹ç”Ÿæˆæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒGenCADçš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶æœ‰åŠ©äºä½¿ç”¨å›¾åƒæŸ¥è¯¢ä»å¤§å‹CADæ•°æ®åº“ä¸­æ£€ç´¢CADæ¨¡å‹ï¼Œè¿™æ˜¯CADç¤¾åŒºå†…çš„å…³é”®æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœçªæ˜¾äº†ç”Ÿæˆæ¨¡å‹åœ¨åŠ å¿«æ•´ä¸ªè®¾è®¡åˆ°ç”Ÿäº§æµç¨‹å¹¶æ— ç¼é›†æˆä¸åŒè®¾è®¡æ¨¡å¼æ–¹é¢çš„æ½œåŠ›ï¼Œè¿™æ ‡å¿—ç€å‘å‰è¿ˆè¿›äº†ä¸€å¤§æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.16294v2">PDF</a> 24 pages, 13 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡æå‡ºä¸€ç§åä¸ºGenCADçš„ç”Ÿæˆæ¨¡å‹ï¼Œåˆ©ç”¨è‡ªå›å½’å˜å‹å™¨ä¸å¯¹æ¯”å­¦ä¹ æ¡†æ¶åŠæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå°†å›¾åƒè¾“å…¥è½¬æ¢ä¸ºå‚æ•°åŒ–CADå‘½ä»¤åºåˆ—ï¼Œä»è€Œç”Ÿæˆå¯ç¼–è¾‘çš„3Då½¢çŠ¶è¡¨ç¤ºã€‚GenCADæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨CADæ¨¡å‹çš„æ— æ¡ä»¶ä¸æœ‰æ¡ä»¶ç”Ÿæˆæ–¹é¢ã€‚æ­¤å¤–ï¼ŒGenCADçš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶è¿˜èƒ½ä½¿ç”¨å›¾åƒæŸ¥è¯¢ä»å¤§å‹CADæ•°æ®åº“ä¸­æ£€ç´¢CADæ¨¡å‹ï¼Œè¿™æ˜¯CADç¤¾åŒºå†…çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ç ”ç©¶æˆæœå±•ç¤ºäº†ç”Ÿæˆæ¨¡å‹åœ¨åŠ å¿«æ•´ä¸ªè®¾è®¡åˆ°ç”Ÿäº§æµç¨‹å¹¶æ•´åˆä¸åŒè®¾è®¡æ¨¡æ€æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GenCADæ˜¯ä¸€ä¸ªåˆ©ç”¨è‡ªå›å½’å˜å‹å™¨å’Œå¯¹æ¯”å­¦ä¹ æ¡†æ¶çš„ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿå°†å›¾åƒè½¬åŒ–ä¸ºå‚æ•°åŒ–CADå‘½ä»¤åºåˆ—ã€‚</li>
<li>GenCADå¯ä»¥ç”Ÿæˆå¯ç¼–è¾‘çš„3Då½¢çŠ¶è¡¨ç¤ºï¼Œæ»¡è¶³å®é™…å·¥ç¨‹åº”ç”¨çš„éœ€æ±‚ã€‚</li>
<li>GenCADåœ¨æ— æ¡ä»¶ä¸æœ‰æ¡ä»¶ç”ŸæˆCADæ¨¡å‹æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>GenCADé‡‡ç”¨å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå¯ä»å¤§å‹CADæ•°æ®åº“ä¸­æ£€ç´¢CADæ¨¡å‹ã€‚</li>
<li>æ£€ç´¢åŠŸèƒ½è§£å†³äº†CADè®¾è®¡ä¸­çš„å…³é”®æŒ‘æˆ˜ä¹‹ä¸€ã€‚</li>
<li>ç”Ÿæˆæ¨¡å‹åœ¨åŠ å¿«è®¾è®¡åˆ°ç”Ÿäº§æµç¨‹æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.16294">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2fd5c4f46e20d78693e01cfd572879d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83daf0fdeb781e70dc3949dca2aa855f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3eb4079d2e452957a25221c05d749928.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-11/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-11/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-11/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0fb5f65a18ed0b7bb4c4d47bfac9a4b1.jpg" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-11  nnLandmark A Self-Configuring Method for 3D Medical Landmark Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-11/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-839e872a8ab25ca274bd8ab8bb869c51.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-11  Wheat3DGS In-field 3D Reconstruction, Instance Segmentation and   Phenotyping of Wheat Heads with Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">16470.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
