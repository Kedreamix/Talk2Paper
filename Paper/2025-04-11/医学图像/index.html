<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-11  Probable evidence for a transient mega-electron volt emission line in   the GRB 221023A">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f0ecc339981d64879190465ae20ee5dd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    66 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-11-æ›´æ–°"><a href="#2025-04-11-æ›´æ–°" class="headerlink" title="2025-04-11 æ›´æ–°"></a>2025-04-11 æ›´æ–°</h1><h2 id="Probable-evidence-for-a-transient-mega-electron-volt-emission-line-in-the-GRB-221023A"><a href="#Probable-evidence-for-a-transient-mega-electron-volt-emission-line-in-the-GRB-221023A" class="headerlink" title="Probable evidence for a transient mega-electron volt emission line in   the GRB 221023A"></a>Probable evidence for a transient mega-electron volt emission line in   the GRB 221023A</h2><p><strong>Authors:Lu-Yao Jiang, Yun Wang, Yu-Jia Wei, Da-Ming Wei, Xiang Li, Hao-Ning He, Jia Ren, Zhao-Qiang Shen, Zhi-Ping Jin</strong></p>
<p>Detection of spectral line in gamma-ray bursts (GRBs) is importance for studying GRB physics, as it provides insights into the composition and physical conditions of the GRB environment. However, progress in detecting X-ray or gamma-ray emission and absorption lines in GRB spectra has been relatively slow, only the narrow emission line feature of about 10 MeV found in GRB 221009A has exhibited a significance exceeding $5 \sigma$. Here, we report the probable evidence of a narrow emission feature at about 2.1 mega-electron volts (MeV) in the spectrum of GRB 221023A. The highest statistical significance of this feature is observed in the time interval between 8 and 30 seconds after Fermi Gamma-Ray Burst Monitor trigger, with the chance probability value $&lt;2.56 \times 10^{-5}$ (after accounting for the look-elsewhere effect), corresponding to a Gaussian-equivalent significance $&gt; 4.20 \sigma$. We interpret this feature as being generated through the de-excitation of excited electrons in the relativistic hydrogen-like high-atomic-number ions entrained in the GRB jet. </p>
<blockquote>
<p>åœ¨ä¼½é©¬å°„çº¿æš´ï¼ˆGRBsï¼‰ä¸­æ£€æµ‹å…‰è°±çº¿å¯¹äºç ”ç©¶GRBç‰©ç†éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒä¸ºGRBç¯å¢ƒçš„ç»„æˆå’Œç‰©ç†æ¡ä»¶æä¾›äº†è§è§£ã€‚ç„¶è€Œï¼Œåœ¨GRBå…‰è°±ä¸­æ£€æµ‹Xå°„çº¿æˆ–ä¼½é©¬å°„çº¿å‘å°„å’Œå¸æ”¶çº¿çš„è¿›å±•ç›¸å¯¹è¾ƒæ…¢ï¼Œä»…åœ¨GRB 221009Aä¸­å‘ç°çš„çº¦10MeVçš„çª„å‘å°„çº¿ç‰¹å¾æ‰å…·æœ‰è¶…è¿‡$5 \sigma$çš„æ˜¾è‘—æ€§ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æŠ¥å‘Šäº†GRB 221023Aå…‰è°±ä¸­å¤§çº¦2.1å…†ç”µå­ä¼ç‰¹ï¼ˆMeVï¼‰çš„çª„å‘å°„ç‰¹å¾çš„å¯èƒ½è¯æ®ã€‚æ­¤ç‰¹å¾åœ¨è´¹ç±³ä¼½é©¬å°„çº¿æš´ç›‘è§†å™¨è§¦å‘å8è‡³30ç§’çš„æ—¶é—´é—´éš”å†…å…·æœ‰æœ€é«˜çš„ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œæœºä¼šæ¦‚ç‡å€¼å°äº$2.56 \times 10^{-5}$ï¼ˆè€ƒè™‘äº†å…¶ä»–åœ°æ–¹æ•ˆåº”ï¼‰ï¼Œå¯¹åº”äºé«˜æ–¯ç­‰æ•ˆæ˜¾è‘—æ€§å¤§äº$ 4.20 \sigma$ã€‚æˆ‘ä»¬å°†æ­¤ç‰¹å¾è§£é‡Šä¸ºç”±GRBå–·æµä¸­æºå¸¦çš„é«˜ç›¸å¯¹è®ºæ€§æ°¢ç±»é«˜åŸå­åºæ•°ç¦»å­çš„æ¿€å‘æ€å»æ¿€å‘æ‰€äº§ç”Ÿã€‚</p>
</blockquote>
<p><strong>ç®€åŒ–ç‰ˆç¿»è¯‘</strong></p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06968v1">PDF</a> 20 pages, 5 figures, 3 tables. Publication in the Nature   Communications</p>
<p><strong>Summary</strong><br>     GRB 221023Aå…‰è°±ä¸­å¯èƒ½æ£€æµ‹åˆ°çª„å‘å°„ç‰¹å¾ï¼Œå…¶èƒ½é‡çº¦ä¸º2.1å…†ç”µå­ä¼ç‰¹ï¼ˆMeVï¼‰ã€‚è¯¥ç‰¹å¾åœ¨è§¦å‘å8è‡³30ç§’çš„æ—¶é—´é—´éš”å†…è§‚å¯Ÿåˆ°äº†æœ€é«˜ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œå¹¶ä¸”å‡ ç‡æä½ã€‚å¯¹å…¶äº§ç”Ÿçš„å¯èƒ½è§£é‡Šæ˜¯ç›¸å¯¹è®ºæ€§æ°¢ç±»é«˜åŸå­åºæ•°ç¦»å­åœ¨GRBå–·å°„ä¸­çš„æ¿€å‘ç”µå­çš„é€€æ¿€å‘æ‰€è‡´ã€‚è¿™ä¸€å‘ç°å¯¹äºç ”ç©¶GRBç‰©ç†å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GRB 221023Aå…‰è°±ä¸­å¯èƒ½å‘ç°äº†èƒ½é‡çº¦ä¸º2.1MeVçš„çª„å‘å°„ç‰¹å¾ã€‚</li>
<li>è¿™ä¸€ç‰¹å¾åœ¨è§¦å‘åçš„ç‰¹å®šæ—¶é—´é—´éš”ï¼ˆ8è‡³30ç§’ï¼‰å†…æ˜¾ç¤ºå‡ºæœ€é«˜ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚</li>
<li>ç‰¹å¾çš„å¯èƒ½æ€§è¯æ®è¶…è¿‡äº†$4.20 \sigma$çš„æ˜¾è‘—æ€§æ°´å¹³ã€‚</li>
<li>ç‰¹å¾çš„äº§ç”Ÿå¯èƒ½ä¸GRBå–·å°„ä¸­çš„ç›¸å¯¹è®ºæ€§æ°¢ç±»é«˜åŸå­åºæ•°ç¦»å­çš„æ¿€å‘ç”µå­é€€æ¿€å‘æœ‰å…³ã€‚</li>
<li>è¿™ä¸€å‘ç°ä¸ºç ”ç©¶GRBçš„ç‰©ç†ç¯å¢ƒæä¾›äº†æ–°çº¿ç´¢ï¼Œç‰¹åˆ«æ˜¯å…³äºGRBçš„ç»„æˆå’Œç‰©ç†æ¡ä»¶ã€‚</li>
<li>å°½ç®¡è¿›å±•ç¼“æ…¢ï¼Œä½†æ£€æµ‹GRBå…‰è°±ä¸­çš„Xå°„çº¿æˆ–ä¼½é©¬å°„çº¿å‘å°„å’Œå¸æ”¶çº¿ä»ç„¶è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06968">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-597ca00aaa368d74f4e223ea22a1ca11.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PathSegDiff-Pathology-Segmentation-using-Diffusion-model-representations"><a href="#PathSegDiff-Pathology-Segmentation-using-Diffusion-model-representations" class="headerlink" title="PathSegDiff: Pathology Segmentation using Diffusion model   representations"></a>PathSegDiff: Pathology Segmentation using Diffusion model   representations</h2><p><strong>Authors:Sachin Kumar Danisetty, Alexandros Graikos, Srikar Yellapragada, Dimitris Samaras</strong></p>
<p>Image segmentation is crucial in many computational pathology pipelines, including accurate disease diagnosis, subtyping, outcome, and survivability prediction. The common approach for training a segmentation model relies on a pre-trained feature extractor and a dataset of paired image and mask annotations. These are used to train a lightweight prediction model that translates features into per-pixel classes. The choice of the feature extractor is central to the performance of the final segmentation model, and recent literature has focused on finding tasks to pre-train the feature extractor. In this paper, we propose PathSegDiff, a novel approach for histopathology image segmentation that leverages Latent Diffusion Models (LDMs) as pre-trained featured extractors. Our method utilizes a pathology-specific LDM, guided by a self-supervised encoder, to extract rich semantic information from H&amp;E stained histopathology images. We employ a simple, fully convolutional network to process the features extracted from the LDM and generate segmentation masks. Our experiments demonstrate significant improvements over traditional methods on the BCSS and GlaS datasets, highlighting the effectiveness of domain-specific diffusion pre-training in capturing intricate tissue structures and enhancing segmentation accuracy in histopathology images. </p>
<blockquote>
<p>å›¾åƒåˆ†å‰²åœ¨è®¡ç®—ç—…ç†å­¦æµç¨‹ä¸­éå¸¸é‡è¦ï¼ŒåŒ…æ‹¬å‡†ç¡®çš„ç–¾ç—…è¯Šæ–­ã€äºšå‹åˆ†ç±»ã€ç»“æœé¢„æµ‹å’Œç”Ÿå­˜é¢„æµ‹ã€‚è®­ç»ƒåˆ†å‰²æ¨¡å‹çš„å¸¸è§æ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œé…å¯¹å›¾åƒå’Œæ©è†œæ³¨é‡Šçš„æ•°æ®é›†ã€‚è¿™äº›è¢«ç”¨æ¥è®­ç»ƒè½»é‡çº§çš„é¢„æµ‹æ¨¡å‹ï¼Œå°†ç‰¹å¾è½¬åŒ–ä¸ºåƒç´ çº§åˆ†ç±»ã€‚ç‰¹å¾æå–å™¨çš„é€‰æ‹©æ˜¯æœ€ç»ˆåˆ†å‰²æ¨¡å‹æ€§èƒ½çš„æ ¸å¿ƒï¼Œæœ€è¿‘çš„æ–‡çŒ®ä¸»è¦é›†ä¸­åœ¨å¯»æ‰¾é¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†PathSegDiffï¼Œä¸€ç§åˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ä½œä¸ºé¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„æ–°é¢–æ–¹æ³•æ¥è¿›è¡Œç»„ç»‡ç—…ç†å­¦å›¾åƒåˆ†å‰²ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ä¸€ä¸ªå—è‡ªæˆ‘ç›‘ç£ç¼–ç å™¨å¼•å¯¼çš„ç–¾ç—…ç‰¹å¼‚æ€§LDMï¼Œä»è‹æœ¨ç²¾ä¼Šçº¢æŸ“è‰²çš„ç»„ç»‡ç—…ç†å­¦å›¾åƒä¸­æå–ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚æˆ‘ä»¬é‡‡ç”¨ç®€å•çš„å…¨å·ç§¯ç½‘ç»œæ¥å¤„ç†ä»LDMä¸­æå–çš„ç‰¹å¾å¹¶ç”Ÿæˆåˆ†å‰²æ©è†œã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„æ–¹æ³•ç›¸æ¯”ï¼ŒBCSSå’ŒGlaSæ•°æ®é›†ä¸Šçš„ç»“æœæœ‰äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè¿™çªå‡ºäº†é¢†åŸŸç‰¹å®šçš„æ‰©æ•£é¢„è®­ç»ƒåœ¨æ•æ‰å¤æ‚çš„ç»„ç»‡ç»“æ„å’Œæé«˜ç»„ç»‡ç—…ç†å­¦å›¾åƒåˆ†å‰²ç²¾åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06950v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²åœ¨è®¡ç®—ç—…ç†å­¦æµç¨‹ä¸­è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬å‡†ç¡®ç–¾ç—…è¯Šæ–­ã€äºšå‹åˆ†ç±»ã€ç»“æœé¢„æµ‹å’Œç”Ÿå­˜é¢„æµ‹ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹åˆ†å‰²æ–¹æ³•PathSegDiffï¼Œé‡‡ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ä½œä¸ºé¢„è®­ç»ƒç‰¹å¾æå–å™¨ï¼Œé€šè¿‡è‡ªç›‘ç£ç¼–ç å™¨å¼•å¯¼ï¼Œä»H&amp;EæŸ“è‰²ç»„ç»‡ç—…ç†å›¾åƒä¸­æå–ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯ã€‚å®éªŒç»“æœåœ¨BCSSå’ŒGlaSæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå‡¸æ˜¾é¢†åŸŸç‰¹å®šæ‰©æ•£é¢„è®­ç»ƒåœ¨æ•æ‰å¤æ‚ç»„ç»‡ç»“æ„å’Œæé«˜ç»„ç»‡ç—…ç†å›¾åƒåˆ†å‰²å‡†ç¡®æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²åœ¨è®¡ç®—ç—…ç†å­¦ä¸­æœ‰é‡è¦åº”ç”¨ï¼Œæ¶‰åŠç–¾ç—…è¯Šæ–­ã€äºšå‹åˆ†ç±»ã€ç»“æœé¢„æµ‹å’Œç”Ÿå­˜é¢„æµ‹ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä¾èµ–é¢„è®­ç»ƒç‰¹å¾æå–å™¨å’Œé…å¯¹å›¾åƒä¸æ©è†œæ³¨é‡Šæ•°æ®é›†æ¥è®­ç»ƒé¢„æµ‹æ¨¡å‹ã€‚</li>
<li>ç‰¹å¾æå–å™¨çš„é€‰æ‹©å¯¹æœ€ç»ˆåˆ†å‰²æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>è¿‘æœŸç ”ç©¶å…³æ³¨äºå¯»æ‰¾é¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„ä»»åŠ¡ã€‚</li>
<li>PathSegDiffæ˜¯ä¸€ç§æ–°å‹ç»„ç»‡ç—…ç†å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ä½œä¸ºé¢„è®­ç»ƒç‰¹å¾æå–å™¨ã€‚</li>
<li>PathSegDiffé€šè¿‡è‡ªç›‘ç£ç¼–ç å™¨å¼•å¯¼ï¼Œæé«˜åˆ†å‰²å‡†ç¡®æ€§ï¼Œå¹¶åœ¨BCSSå’ŒGlaSæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06950">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-867f9a46e9b49b7bcc6527aebfd51d46.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b32336274937ff636bcc427d04c8f23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-538d150ba9201ced64414fe6e0d229a6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3e05e38811f2846699247f81eb4a90db.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ee00f85e8b288b5ab4a2206d3257def.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="UKBOB-One-Billion-MRI-Labeled-Masks-for-Generalizable-3D-Medical-Image-Segmentation"><a href="#UKBOB-One-Billion-MRI-Labeled-Masks-for-Generalizable-3D-Medical-Image-Segmentation" class="headerlink" title="UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image   Segmentation"></a>UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image   Segmentation</h2><p><strong>Authors:Emmanuelle Bourigault, Amir Jamaludin, Abdullah Hamdi</strong></p>
<p>In medical imaging, the primary challenge is collecting large-scale labeled data due to privacy concerns, logistics, and high labeling costs. In this work, we present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset of body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D images) and more than 1.37 billion 2D segmentation masks of 72 organs, all based on the UK Biobank MRI dataset. We utilize automatic labeling, introduce an automated label cleaning pipeline with organ-specific filters, and manually annotate a subset of 300 MRIs with 11 abdominal classes to validate the quality (referred to as UKBOB-manual). This approach allows for scaling up the dataset collection while maintaining confidence in the labels. We further confirm the validity of the labels by demonstrating zero-shot generalization of trained models on the filtered UKBOB to other small labeled datasets from similar domains (e.g., abdominal MRI). To further mitigate the effect of noisy labels, we propose a novel method called Entropy Test-time Adaptation (ETTA) to refine the segmentation output. We use UKBOB to train a foundation model, Swin-BOB, for 3D medical image segmentation based on the Swin-UNetr architecture, achieving state-of-the-art results in several benchmarks in 3D medical imaging, including the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the BTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained models and the code are available at <a target="_blank" rel="noopener" href="https://emmanuelleb985.github.io/ukbob">https://emmanuelleb985.github.io/ukbob</a> , and the filtered labels will be made available with the UK Biobank. </p>
<blockquote>
<p>åœ¨åŒ»å­¦æˆåƒé¢†åŸŸï¼Œä¸»è¦æŒ‘æˆ˜åœ¨äºç”±äºéšç§æ‹…å¿§ã€ç‰©æµå’Œé«˜æ ‡ç­¾æˆæœ¬è€Œéš¾ä»¥æ”¶é›†å¤§è§„æ¨¡æ ‡è®°æ•°æ®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†è‹±å›½ç”Ÿç‰©é“¶è¡Œå™¨å®˜ä¸éª¨éª¼ï¼ˆUKBOBï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯æœ€å¤§çš„å™¨å®˜æ ‡è®°æ•°æ®é›†ï¼ŒåŒ…å«åŸºäºè‹±å›½ç”Ÿç‰©é“¶è¡ŒMRIæ•°æ®é›†çš„51,761ä¸ªMRI 3Dæ ·æœ¬ï¼ˆç›¸å½“äº1790ä¸‡å¼ 2Då›¾åƒï¼‰å’Œè¶…è¿‡13.7äº¿å¼ åŒ…å«72ç§å™¨å®˜çš„äºŒç»´åˆ†å‰²è’™ç‰ˆã€‚æˆ‘ä»¬é‡‡ç”¨è‡ªåŠ¨æ ‡è®°çš„æ–¹æ³•ï¼Œå¼•å…¥äº†å…·æœ‰å™¨å®˜ç‰¹å¼‚æ€§è¿‡æ»¤å™¨çš„è‡ªåŠ¨æ ‡ç­¾æ¸…ç†ç®¡é“ï¼Œå¹¶æ‰‹åŠ¨å¯¹300å¼ è…¹éƒ¨MRIå›¾åƒä¸­çš„11ä¸ªç±»åˆ«è¿›è¡Œæ ‡æ³¨ä»¥éªŒè¯è´¨é‡ï¼ˆç§°ä¸ºUKBOBæ‰‹åŠ¨ï¼‰ã€‚è¿™ç§æ–¹æ³•å…è®¸åœ¨æ‰©å¤§æ•°æ®é›†æ”¶é›†çš„åŒæ—¶ä¿æŒå¯¹æ ‡ç­¾çš„ä¿¡å¿ƒã€‚æˆ‘ä»¬é€šè¿‡å±•ç¤ºç»è¿‡è®­ç»ƒçš„æ¨¡å‹åœ¨è¿‡æ»¤åçš„UKBOBä¸Šå¯¹å…¶ä»–ç±»ä¼¼é¢†åŸŸçš„å°è§„æ¨¡æ ‡è®°æ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›æ¥è¿›ä¸€æ­¥éªŒè¯æ ‡ç­¾çš„æœ‰æ•ˆæ€§ï¼ˆä¾‹å¦‚è…¹éƒ¨MRIï¼‰ã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡è½»å™ªå£°æ ‡ç­¾çš„å½±å“ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºç†µæµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆETTAï¼‰çš„æ–°æ–¹æ³•æ¥ä¼˜åŒ–åˆ†å‰²è¾“å‡ºã€‚æˆ‘ä»¬ä½¿ç”¨UKBOBè®­ç»ƒäº†ä¸€ä¸ªåŸºäºSwin-UNetræ¶æ„çš„ç”¨äºä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²çš„åŸºç¡€æ¨¡å‹Swin-BOBï¼Œåœ¨ä¸‰ç»´åŒ»å­¦å½±åƒçš„å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼ŒåŒ…æ‹¬BRATSè„‘éƒ¨MRIè‚¿ç˜¤æŒ‘æˆ˜èµ›ï¼ˆæé«˜äº†0.4%ï¼‰å’ŒBTCVè…¹éƒ¨CTæ‰«æåŸºå‡†æµ‹è¯•ï¼ˆæé«˜äº†1.3%ï¼‰ã€‚é¢„è®­ç»ƒæ¨¡å‹å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://emmanuelleb985.github.io/ukbob%E4%B8%8A%E6%89%BE%E5%88%B0%EF%BC%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E6%A0%87%E7%AD%BE%E4%BC%9A%E4%B8%8E%E%E8%8B%B1">https://emmanuelleb985.github.io/ukbobä¸Šæ‰¾åˆ°ï¼Œè¿‡æ»¤åçš„æ ‡ç­¾ä¹Ÿå°†ä¸è‹±å›½ç”Ÿç‰©é“¶è¡Œå…±äº«ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06908v1">PDF</a> preprint</p>
<p><strong>Summary</strong><br>     æœ¬åŒ»å­¦æˆåƒç ”ç©¶é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯éšç§ã€ç‰©æµå’Œæ ‡ç­¾æˆæœ¬é—®é¢˜ï¼Œå¯¼è‡´éš¾ä»¥æ”¶é›†å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†UKBiobank Organs and Bonesï¼ˆUKBOBï¼‰æ•°æ®é›†ï¼ŒåŒ…å«å¤§é‡äººä½“å™¨å®˜æ ‡ç­¾ï¼Œåˆ©ç”¨è‡ªåŠ¨æ ‡æ³¨å’Œæ¸…æ´—æµç¨‹ç¡®ä¿æ ‡ç­¾å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ç†µæµ‹è¯•æ—¶é€‚åº”ï¼ˆETTAï¼‰æ–¹æ³•ä»¥ä¼˜åŒ–åˆ†å‰²è¾“å‡ºï¼Œå¹¶åŸºäºSwin-UNetræ¶æ„è®­ç»ƒå‡ºå…ˆè¿›çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹Swin-BOBã€‚æ¨¡å‹åœ¨å¤šä¸ªåŒ»å­¦æˆåƒåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šã€‚æ•°æ®é›†å’Œä»£ç å·²åœ¨GitHubä¸Šå…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong><br>     1. åŒ»å­¦æˆåƒé¢†åŸŸé¢ä¸´å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®æ”¶é›†çš„æŒ‘æˆ˜ï¼Œæ¶‰åŠéšç§ã€ç‰©æµå’Œæˆæœ¬é—®é¢˜ã€‚<br>     2. æ¨å‡ºäº†UKBiobank Organs and Bonesï¼ˆUKBOBï¼‰æ•°æ®é›†ï¼ŒåŒ…å«å¤§é‡äººä½“å™¨å®˜æ ‡ç­¾æ•°æ®ã€‚<br>     3. ç»“åˆè‡ªåŠ¨æ ‡æ³¨å’Œæ¸…æ´—æµç¨‹ï¼Œç¡®ä¿æ ‡ç­¾å‡†ç¡®æ€§ã€‚<br>     4. æå‡ºäº†ä¸€ç§åä¸ºç†µæµ‹è¯•æ—¶é€‚åº”ï¼ˆETTAï¼‰çš„æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹åˆ†å‰²è¾“å‡ºã€‚<br>     5. åŸºäºSwin-UNetræ¶æ„è®­ç»ƒçš„Swin-BOBæ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸè¡¨ç°ä¼˜ç§€ã€‚<br>     6. æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼ŒåŒ…æ‹¬BRATSè„‘MRIè‚¿ç˜¤æŒ‘æˆ˜å’ŒBTCVè…¹éƒ¨CTæ‰«æåŸºå‡†æµ‹è¯•ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06908">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-52aa214eedbf028863f05a72c5666c19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c01baa922823fba9befe24fe55dd77f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-003f50d7974eb7083dcb4acc0bd44e6e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-094d7d06fac4a4cc89c56f18206b1cd8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a0861b7687d0243b7fe1cce03de8020.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MedSegFactory-Text-Guided-Generation-of-Medical-Image-Mask-Pairs"><a href="#MedSegFactory-Text-Guided-Generation-of-Medical-Image-Mask-Pairs" class="headerlink" title="MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs"></a>MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs</h2><p><strong>Authors:Jiawei Mao, Yuhan Wang, Yucheng Tang, Daguang Xu, Kang Wang, Yang Yang, Zongwei Zhou, Yuyin Zhou</strong></p>
<p>This paper presents MedSegFactory, a versatile medical synthesis framework that generates high-quality paired medical images and segmentation masks across modalities and tasks. It aims to serve as an unlimited data repository, supplying image-mask pairs to enhance existing segmentation tools. The core of MedSegFactory is a dual-stream diffusion model, where one stream synthesizes medical images and the other generates corresponding segmentation masks. To ensure precise alignment between image-mask pairs, we introduce Joint Cross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic cross-conditioning between streams. This bidirectional interaction allows both representations to guide each otherâ€™s generation, enhancing consistency between generated pairs. MedSegFactory unlocks on-demand generation of paired medical images and segmentation masks through user-defined prompts that specify the target labels, imaging modalities, anatomical regions, and pathological conditions, facilitating scalable and high-quality data generation. This new paradigm of medical image synthesis enables seamless integration into diverse medical imaging workflows, enhancing both efficiency and accuracy. Extensive experiments show that MedSegFactory generates data of superior quality and usability, achieving competitive or state-of-the-art performance in 2D and 3D segmentation tasks while addressing data scarcity and regulatory constraints. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†MedSegFactoryï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„åŒ»å­¦åˆæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆè·¨æ¨¡æ€å’Œä»»åŠ¡çš„é«˜è´¨é‡é…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚å®ƒçš„ç›®æ ‡æ˜¯ä½œä¸ºä¸€ä¸ªæ— é™çš„æ•°æ®ä»“åº“ï¼Œæä¾›å›¾åƒ-æ©è†œå¯¹ï¼Œä»¥å¢å¼ºç°æœ‰çš„åˆ†å‰²å·¥å…·ã€‚MedSegFactoryçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªåŒæµæ‰©æ•£æ¨¡å‹ï¼Œå…¶ä¸­ä¸€æµåˆæˆåŒ»å­¦å›¾åƒï¼Œå¦ä¸€æµç”Ÿæˆç›¸åº”çš„åˆ†å‰²æ©è†œã€‚ä¸ºäº†ç¡®ä¿å›¾åƒ-æ©è†œå¯¹ä¹‹é—´çš„ç²¾ç¡®å¯¹é½ï¼Œæˆ‘ä»¬å¼•å…¥äº†è”åˆäº¤å‰æ³¨æ„ï¼ˆJCAï¼‰ï¼Œé€šè¿‡æµä¹‹é—´çš„åŠ¨æ€äº¤å‰æ¡ä»¶ï¼Œå®ç°ååŒå»å™ªæ¨¡å¼ã€‚è¿™ç§åŒå‘äº¤äº’å…è®¸ä¸¤ç§è¡¨ç¤ºç›¸äº’å¼•å¯¼ç”Ÿæˆï¼Œå¢å¼ºç”Ÿæˆå¯¹ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚MedSegFactoryé€šè¿‡ç”¨æˆ·å®šä¹‰çš„æç¤ºè§£é”æŒ‰éœ€ç”Ÿæˆçš„é…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œï¼Œè¿™äº›æç¤ºæŒ‡å®šç›®æ ‡æ ‡ç­¾ã€æˆåƒæ¨¡æ€ã€è§£å‰–åŒºåŸŸå’Œç—…ç†çŠ¶å†µï¼Œä¿ƒè¿›å¯æ‰©å±•å’Œé«˜è´¨é‡çš„æ•°æ®ç”Ÿæˆã€‚è¿™ç§æ–°çš„åŒ»å­¦å›¾åƒåˆæˆæ¨¡å¼èƒ½å¤Ÿæ— ç¼é›†æˆåˆ°å¤šæ ·åŒ–çš„åŒ»å­¦æˆåƒå·¥ä½œæµç¨‹ä¸­ï¼Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMedSegFactoryç”Ÿæˆçš„æ•°æ®å…·æœ‰å“è¶Šçš„è´¨é‡å’Œå¯ç”¨æ€§ï¼Œåœ¨äºŒç»´å’Œä¸‰ç»´åˆ†å‰²ä»»åŠ¡ä¸­è¾¾åˆ°äº†ç«äº‰æˆ–æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶è§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œç›‘ç®¡çº¦æŸé—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06897v1">PDF</a> 12 pages, 8 figures, The project page can be accessed via   <a target="_blank" rel="noopener" href="https://jwmao1.github.io/MedSegFactory_web">https://jwmao1.github.io/MedSegFactory_web</a></p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆæˆæ¡†æ¶MedSegFactoryèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡é…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œï¼Œé€‚ç”¨äºå¤šç§æ¨¡æ€å’Œä»»åŠ¡ã€‚å…¶æ ¸å¿ƒæ˜¯åŒæµæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡è”åˆäº¤å‰æ³¨æ„åŠ›æœºåˆ¶å®ç°å›¾åƒå’Œæ©è†œä¹‹é—´çš„ç²¾ç¡®å¯¹é½ã€‚è¯¥æ¡†æ¶å¯å®ç°æŒ‰éœ€ç”Ÿæˆé…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œï¼Œå¹¶æ˜“äºé›†æˆåˆ°å„ç§åŒ»å­¦æˆåƒå·¥ä½œæµç¨‹ä¸­ï¼Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MedSegFactoryæ˜¯ä¸€ä¸ªé€šç”¨çš„åŒ»å­¦åˆæˆæ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡é…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚</li>
<li>å®ƒé‡‡ç”¨åŒæµæ‰©æ•£æ¨¡å‹ï¼Œå…¶ä¸­ä¸€æµç”ŸæˆåŒ»å­¦å›¾åƒï¼Œå¦ä¸€æµç”Ÿæˆç›¸åº”çš„åˆ†å‰²æ©è†œã€‚</li>
<li>é€šè¿‡å¼•å…¥è”åˆäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°å›¾åƒå’Œæ©è†œä¹‹é—´çš„ç²¾ç¡®å¯¹é½ã€‚</li>
<li>æ¡†æ¶æ”¯æŒæŒ‰éœ€ç”Ÿæˆé…å¯¹åŒ»å­¦å›¾åƒå’Œåˆ†å‰²æ©è†œï¼Œå¯æ ¹æ®ç”¨æˆ·å®šä¹‰çš„ç›®æ ‡æ ‡ç­¾ã€æˆåƒæ¨¡æ€ã€è§£å‰–åŒºåŸŸå’Œç—…ç†æ¡ä»¶è¿›è¡Œç”Ÿæˆã€‚</li>
<li>MedSegFactoryæ˜“äºé›†æˆåˆ°å„ç§åŒ»å­¦æˆåƒå·¥ä½œæµç¨‹ä¸­ï¼Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>æ¡†æ¶åœ¨2Då’Œ3Dåˆ†å‰²ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œè§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œç›‘ç®¡çº¦æŸçš„é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06897">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c11aeb509d8b84999d1bb0e9b5bd34b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5136966fc5c824d9fe3cd8414dda1962.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cee1c813ed6277fb8c6167a26c2e967.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a55c3c419f768f5fac8ccae852425662.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a7808eb0580cbb9679c48d802831938.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d78c323a4ded335c2985c17645871aac.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Hybrid-CNN-with-Chebyshev-Polynomial-Expansion-for-Medical-Image-Analysis"><a href="#Hybrid-CNN-with-Chebyshev-Polynomial-Expansion-for-Medical-Image-Analysis" class="headerlink" title="Hybrid CNN with Chebyshev Polynomial Expansion for Medical Image   Analysis"></a>Hybrid CNN with Chebyshev Polynomial Expansion for Medical Image   Analysis</h2><p><strong>Authors:Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza</strong></p>
<p>Lung cancer remains one of the leading causes of cancer-related mortality worldwide, with early and accurate diagnosis playing a pivotal role in improving patient outcomes. Automated detection of pulmonary nodules in computed tomography (CT) scans is a challenging task due to variability in nodule size, shape, texture, and location. Traditional Convolutional Neural Networks (CNNs) have shown considerable promise in medical image analysis; however, their limited ability to capture fine-grained spatial-spectral variations restricts their performance in complex diagnostic scenarios. In this study, we propose a novel hybrid deep learning architecture that incorporates Chebyshev polynomial expansions into CNN layers to enhance expressive power and improve the representation of underlying anatomical structures. The proposed Chebyshev-CNN leverages the orthogonality and recursive properties of Chebyshev polynomials to extract high-frequency features and approximate complex nonlinear functions with greater fidelity. The model is trained and evaluated on benchmark lung cancer imaging datasets, including LUNA16 and LIDC-IDRI, achieving superior performance in classifying pulmonary nodules as benign or malignant. Quantitative results demonstrate significant improvements in accuracy, sensitivity, and specificity compared to traditional CNN-based approaches. This integration of polynomial-based spectral approximation within deep learning provides a robust framework for enhancing automated medical diagnostics and holds potential for broader applications in clinical decision support systems. </p>
<blockquote>
<p>è‚ºç™Œä»ç„¶æ˜¯å…¨çƒç™Œç—‡ç›¸å…³æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œæ—©æœŸå’Œå‡†ç¡®çš„è¯Šæ–­åœ¨æ”¹å–„æ‚£è€…é¢„åä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚åœ¨è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­è‡ªåŠ¨æ£€æµ‹è‚ºç»“èŠ‚æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºç»“èŠ‚çš„å¤§å°ã€å½¢çŠ¶ã€çº¹ç†å’Œä½ç½®å­˜åœ¨å¾ˆå¤§çš„å˜åŒ–ã€‚ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨åŒ»å­¦å›¾åƒåˆ†ææ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼›ç„¶è€Œï¼Œå®ƒä»¬åœ¨æ•è·ç²¾ç»†çš„ç©ºé—´å…‰è°±å˜åŒ–æ–¹é¢çš„æœ‰é™èƒ½åŠ›é™åˆ¶äº†å®ƒä»¬åœ¨å¤æ‚çš„è¯Šæ–­åœºæ™¯ä¸­çš„è¡¨ç°ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„æ··åˆæ·±åº¦å­¦ä¹ æ¶æ„ï¼Œè¯¥æ¶æ„å°†åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼æ‰©å±•èå…¥CNNå±‚ï¼Œä»¥æé«˜è¡¨è¾¾èƒ½åŠ›å’Œæ”¹å–„æ½œåœ¨è§£å‰–ç»“æ„çš„è¡¨ç¤ºã€‚æ‰€æå‡ºçš„åˆ‡æ¯”é›ªå¤«-CNNåˆ©ç”¨åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„æ­£äº¤æ€§å’Œé€’å½’å±æ€§æ¥æå–é«˜é¢‘ç‰¹å¾ï¼Œå¹¶ä»¥æ›´é«˜çš„ä¿çœŸåº¦è¿‘ä¼¼å¤æ‚çš„éçº¿æ€§å‡½æ•°ã€‚è¯¥æ¨¡å‹åœ¨åŸºå‡†è‚ºç™Œæˆåƒæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼ŒåŒ…æ‹¬LUNA16å’ŒLIDC-IDRIæ•°æ®é›†ï¼Œåœ¨åˆ†ç±»è‚ºç»“èŠ‚ä¸ºè‰¯æ€§æˆ–æ¶æ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚å®šé‡ç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„åŸºäºCNNçš„æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å‡†ç¡®æ€§ã€æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚æ·±åº¦å­¦ä¹ ä¸­çš„å¤šé¡¹å¼åŸºäºå…‰è°±é€¼è¿‘çš„é›†æˆä¸ºæé«˜è‡ªåŠ¨åŒ–åŒ»å­¦è¯Šæ–­æä¾›äº†ä¸€ä¸ªç¨³å¥çš„æ¡†æ¶ï¼Œå¹¶æœ‰å¯èƒ½åœ¨ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿä¸­æœ‰æ›´å¹¿æ³›çš„åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06811v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è‚ºç™Œä»ç„¶æ˜¯å…¨çƒç™Œç—‡æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œæ—©æœŸå‡†ç¡®è¯Šæ–­å¯¹æ”¹å–„æ‚£è€…é¢„åè‡³å…³é‡è¦ã€‚ç ”ç©¶ä¸­ï¼Œæå‡ºä¸€ç§ç»“åˆåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼æ‰©å±•çš„æ–°å‹æ·±åº¦æ··åˆå­¦ä¹ æ¶æ„ï¼Œå°†å…¶èå…¥å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å±‚ä¸­ï¼Œä»¥æé«˜è¡¨è¾¾èƒ½åŠ›å’Œæ”¹å–„æ½œåœ¨è§£å‰–ç»“æ„çš„è¡¨ç¤ºã€‚è¯¥æ¨¡å‹åˆ©ç”¨åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„æ­£äº¤æ€§å’Œé€’å½’å±æ€§æå–é«˜é¢‘ç‰¹å¾ï¼Œå¹¶ä»¥æ›´é«˜çš„ä¿çœŸåº¦è¿‘ä¼¼å¤æ‚çš„éçº¿æ€§å‡½æ•°ã€‚åœ¨åŸºå‡†è‚ºç™Œæˆåƒæ•°æ®é›†ä¸Šè®­ç»ƒå’Œè¯„ä¼°è¯¥æ¨¡å‹ï¼ŒåŒ…æ‹¬LUNA16å’ŒLIDC-IDRIï¼Œåœ¨åˆ†ç±»è‚ºç»“èŠ‚è‰¯æ¶æ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚å®šé‡ç»“æœæ˜¾ç¤ºä¸ä¼ ç»ŸCNNæ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å‡†ç¡®æ€§ã€æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æé«˜ã€‚è¿™ç§å¤šé¡¹å¼åŸºäºè°±é€¼è¿‘çš„æ·±åº¦å­¦ä¹ ä¸åŒ»å­¦è¯Šæ–­çš„é›†æˆæä¾›äº†ä¸€ä¸ªç¨³å¥çš„æ¡†æ¶ï¼Œå…·æœ‰æ½œåœ¨çš„æ›´å¹¿æ³›åº”ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‚ºç™Œä»ç„¶æ˜¯å…¨çƒç™Œç—‡æ­»äº¡çš„ä¸»è¦åŸå› ä¹‹ä¸€ï¼Œæ—©æœŸå‡†ç¡®è¯Šæ–­è‡³å…³é‡è¦ã€‚</li>
<li>ä¼ ç»Ÿå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­å…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨å¤æ‚è¯Šæ–­åœºæ™¯ä¸­æ€§èƒ½å—é™ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹æ·±åº¦æ··åˆå­¦ä¹ æ¶æ„ï¼Œç»“åˆåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼æ‰©å±•ï¼Œä»¥æé«˜CNNçš„è¡¨è¾¾èƒ½åŠ›å’Œè§£å‰–ç»“æ„è¡¨ç¤ºã€‚</li>
<li>åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼ç”¨äºæå–é«˜é¢‘ç‰¹å¾å¹¶è¿‘ä¼¼å¤æ‚çš„éçº¿æ€§å‡½æ•°ã€‚</li>
<li>æ¨¡å‹åœ¨åŸºå‡†è‚ºç™Œæˆåƒæ•°æ®é›†ä¸Šè¡¨ç°å“è¶Šï¼ŒåŒ…æ‹¬LUNA16å’ŒLIDC-IDRIã€‚</li>
<li>ä¸ä¼ ç»ŸCNNæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹åœ¨å‡†ç¡®æ€§ã€æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§æ–¹é¢æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06811">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5f89d926aa910dca2ed55683ce86ccb0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-765000088056ba74f195b0e3aea01f03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7bd6e5652d964b9495c3381cf1ae7681.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63a9a945448031c0594fe7de3225e73b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75469cfca5a13786c1162755f7a13aa4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-366d90d87a8e36f3a56d86cdd1d12b4f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DIMA-DIffusing-Motion-Artifacts-for-unsupervised-correction-in-brain-MRI-images"><a href="#DIMA-DIffusing-Motion-Artifacts-for-unsupervised-correction-in-brain-MRI-images" class="headerlink" title="DIMA: DIffusing Motion Artifacts for unsupervised correction in brain   MRI images"></a>DIMA: DIffusing Motion Artifacts for unsupervised correction in brain   MRI images</h2><p><strong>Authors:Paolo Angella, Luca Balbi, Fabrizio Ferrando, Paolo Traverso, Rosario Varriale, Vito Paolo Pastore, Matteo Santacesaria</strong></p>
<p>Motion artifacts remain a significant challenge in Magnetic Resonance Imaging (MRI), compromising diagnostic quality and potentially leading to misdiagnosis or repeated scans. Existing deep learning approaches for motion artifact correction typically require paired motion-free and motion-affected images for training, which are rarely available in clinical settings. To overcome this requirement, we present DIMA (DIffusing Motion Artifacts), a novel framework that leverages diffusion models to enable unsupervised motion artifact correction in brain MRI. Our two-phase approach first trains a diffusion model on unpaired motion-affected images to learn the distribution of motion artifacts. This model then generates realistic motion artifacts on clean images, creating paired datasets suitable for supervised training of correction networks. Unlike existing methods, DIMA operates without requiring k-space manipulation or detailed knowledge of MRI sequence parameters, making it adaptable across different scanning protocols and hardware. Comprehensive evaluations across multiple datasets and anatomical planes demonstrate that our method achieves comparable performance to state-of-the-art supervised approaches while offering superior generalizability to real clinical data. DIMA represents a significant advancement in making motion artifact correction more accessible for routine clinical use, potentially reducing the need for repeat scans and improving diagnostic accuracy. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­çš„è¿åŠ¨ä¼ªå½±ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œå®ƒä¼šå½±å“è¯Šæ–­è´¨é‡ï¼Œå¹¶å¯èƒ½å¯¼è‡´è¯¯è¯Šæˆ–é‡å¤æ‰«æã€‚ç°æœ‰çš„ç”¨äºè¿åŠ¨ä¼ªå½±æ ¡æ­£çš„æ·±åº¦å­¦ä¹ æ–¹æ³•é€šå¸¸è¦æ±‚é…å¯¹æ— è¿åŠ¨å’Œå—è¿åŠ¨å½±å“çš„å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨ä¸´åºŠç¯å¢ƒä¸­å¾ˆå°‘å¯ç”¨ã€‚ä¸ºäº†å…‹æœè¿™ä¸€è¦æ±‚ï¼Œæˆ‘ä»¬æå‡ºäº†DIMAï¼ˆDIffusing Motion Artifactsï¼Œæ‰©æ•£è¿åŠ¨ä¼ªå½±ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨æ‰©æ•£æ¨¡å‹å®ç°å¤§è„‘MRIæ— ç›‘ç£è¿åŠ¨ä¼ªå½±æ ¡æ­£çš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µæ–¹æ³•é¦–å…ˆåœ¨ä¸€ä¸ªæœªé…å¯¹çš„å—è¿åŠ¨å½±å“çš„å›¾åƒä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥å­¦ä¹ è¿åŠ¨ä¼ªå½±çš„åˆ†å¸ƒã€‚ç„¶åï¼Œè¯¥æ¨¡å‹åœ¨æ¸…æ´å›¾åƒä¸Šç”Ÿæˆé€¼çœŸçš„è¿åŠ¨ä¼ªå½±ï¼Œåˆ›å»ºé€‚åˆæ ¡æ­£ç½‘ç»œç›‘ç£è®­ç»ƒçš„é…å¯¹æ•°æ®é›†ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒDIMAæ— éœ€è¿›è¡Œkç©ºé—´æ“ä½œæˆ–å¯¹MRIåºåˆ—å‚æ•°çš„è¯¦ç»†äº†è§£ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒçš„æ‰«æåè®®å’Œç¡¬ä»¶ã€‚åœ¨å¤šä¸ªæ•°æ®é›†å’Œè§£å‰–å¹³é¢ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†ä¸æœ€å…ˆè¿›çš„ç›‘ç£æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨çœŸå®ä¸´åºŠæ•°æ®ä¸Šæä¾›äº†æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚DIMAåœ¨ä½¿è¿åŠ¨ä¼ªå½±æ ¡æ­£æ›´æ˜“äºå¸¸è§„ä¸´åºŠä½¿ç”¨æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œæœ‰æœ›å‡å°‘é‡å¤æ‰«æçš„éœ€è¦ï¼Œæé«˜è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06767v1">PDF</a> 7 pages, 5 figures, 7 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— ç›‘ç£MRIè¿åŠ¨ä¼ªå½±æ ¡æ­£æ¡†æ¶â€”â€”DIMAã€‚è¯¥æ¡†æ¶èƒ½åœ¨ä¸éœ€è¦é…å¯¹è¿åŠ¨å›¾åƒçš„æƒ…å†µä¸‹å­¦ä¹ è¿åŠ¨ä¼ªå½±çš„åˆ†å¸ƒï¼Œç”Ÿæˆé€¼çœŸçš„è¿åŠ¨ä¼ªå½±ï¼Œä¸ºæ ¡æ­£ç½‘ç»œæä¾›é…å¯¹æ•°æ®é›†ã€‚DIMAå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ï¼Œæ— éœ€å¤æ‚çš„MRIåºåˆ—å‚æ•°çŸ¥è¯†ï¼Œé€‚ç”¨äºä¸åŒçš„æ‰«æåè®®å’Œç¡¬ä»¶ã€‚å…¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä»·è¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰è¾ƒé«˜çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DIMAæ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„MRIè¿åŠ¨ä¼ªå½±æ ¡æ­£æ¡†æ¶ã€‚</li>
<li>å®ƒä¸éœ€è¦é…å¯¹è¿åŠ¨å’Œæ— è¿åŠ¨çš„å›¾åƒè¿›è¡Œè®­ç»ƒã€‚</li>
<li>DIMAå­¦ä¹ è¿åŠ¨ä¼ªå½±çš„åˆ†å¸ƒå¹¶ç”Ÿæˆé€¼çœŸçš„è¿åŠ¨ä¼ªå½±ã€‚</li>
<li>è¯¥æ–¹æ³•é€‚ç”¨äºä¸åŒçš„æ‰«æåè®®å’Œç¡¬ä»¶ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä»·è¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6e74992e10f847d52dafdc2718c36f58.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34103cf7d6eb078caa10484a31f793b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53e80aedc03eb915acc701d99287982d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-929426030cfb00e3aeaa0779234f4262.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbcda19f84a0cf529a0398e9d2f0e9ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-77601f55a81ff09dde75f18347ee936e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-697ef6fbc73fe02717bc664852d36905.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b34ceb27d95f6ba8b10fab226786db34.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="nnLandmark-A-Self-Configuring-Method-for-3D-Medical-Landmark-Detection"><a href="#nnLandmark-A-Self-Configuring-Method-for-3D-Medical-Landmark-Detection" class="headerlink" title="nnLandmark: A Self-Configuring Method for 3D Medical Landmark Detection"></a>nnLandmark: A Self-Configuring Method for 3D Medical Landmark Detection</h2><p><strong>Authors:Alexandra Ertl, Shuhan Xiao, Stefan Denner, Robin Peretzke, David Zimmerer, Peter Neher, Fabian Isensee, Klaus Maier-Hein</strong></p>
<p>Landmark detection plays a crucial role in medical imaging tasks that rely on precise spatial localization, including specific applications in diagnosis, treatment planning, image registration, and surgical navigation. However, manual annotation is labor-intensive and requires expert knowledge. While deep learning shows promise in automating this task, progress is hindered by limited public datasets, inconsistent benchmarks, and non-standardized baselines, restricting reproducibility, fair comparisons, and model generalizability.This work introduces nnLandmark, a self-configuring deep learning framework for 3D medical landmark detection, adapting nnU-Net to perform heatmap-based regression. By leveraging nnU-Netâ€™s automated configuration, nnLandmark eliminates the need for manual parameter tuning, offering out-of-the-box usability. It achieves state-of-the-art accuracy across two public datasets, with a mean radial error (MRE) of 1.5 mm on the Mandibular Molar Landmark (MML) dental CT dataset and 1.2 mm for anatomical fiducials on a brain MRI dataset (AFIDs), where nnLandmark aligns with the inter-rater variability of 1.5 mm. With its strong generalization, reproducibility, and ease of deployment, nnLandmark establishes a reliable baseline for 3D landmark detection, supporting research in anatomical localization and clinical workflows that depend on precise landmark identification. The code will be available soon. </p>
<blockquote>
<p>åœ¨åŒ»å­¦æˆåƒä»»åŠ¡ä¸­ï¼Œåœ°æ ‡æ£€æµ‹å¯¹äºä¾èµ–ç²¾ç¡®ç©ºé—´å®šä½çš„ä»»åŠ¡èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼ŒåŒ…æ‹¬è¯Šæ–­ã€æ²»ç–—è®¡åˆ’ã€å›¾åƒæ³¨å†Œå’Œæ‰‹æœ¯å¯¼èˆªç­‰ç‰¹å®šåº”ç”¨ã€‚ç„¶è€Œï¼Œæ‰‹åŠ¨æ³¨é‡Šæ˜¯ä¸€é¡¹åŠ³åŠ¨å¯†é›†çš„å·¥ä½œï¼Œéœ€è¦ä¸“ä¸šçŸ¥è¯†ã€‚æ·±åº¦å­¦ä¹ è™½ç„¶åœ¨è‡ªåŠ¨åŒ–æ­¤ä»»åŠ¡æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç”±äºå…¬å…±æ•°æ®é›†æœ‰é™ã€åŸºå‡†æµ‹è¯•ä¸ä¸€è‡´å’Œéæ ‡å‡†åŒ–ç­‰å› ç´ ï¼Œé˜»ç¢äº†è¿›åº¦ï¼Œé™åˆ¶äº†å¯é‡å¤æ€§ã€å…¬å¹³æ¯”è¾ƒå’Œæ¨¡å‹çš„é€šç”¨æ€§ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†nnLandmarkï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº3DåŒ»å­¦åœ°æ ‡æ£€æµ‹çš„è‡ªåŠ¨é…ç½®æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒåŸºäºçƒ­å›¾å›å½’å¯¹nnU-Netè¿›è¡Œäº†æ”¹ç¼–ã€‚é€šè¿‡åˆ©ç”¨nnU-Netçš„è‡ªåŠ¨é…ç½®åŠŸèƒ½ï¼ŒnnLandmarkæ— éœ€æ‰‹åŠ¨å‚æ•°è°ƒæ•´ï¼Œå³å¯å¼€ç®±å³ç”¨ã€‚å®ƒåœ¨ä¸¤ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œåœ¨ä¸‹é¢Œç£¨ç‰™åœ°æ ‡ï¼ˆMMLï¼‰ç‰™ç§‘CTæ•°æ®é›†ä¸Šçš„å¹³å‡å¾„å‘è¯¯å·®ï¼ˆMREï¼‰ä¸º1.5æ¯«ç±³ï¼Œåœ¨è„‘éƒ¨MRIæ•°æ®é›†ï¼ˆAFIDsï¼‰ä¸Šçš„è§£å‰–æ ‡è®°ä¸º1.2æ¯«ç±³ï¼ŒnnLandmarkä¸1.5æ¯«ç±³çš„åŒ»å¸ˆé—´å˜å¼‚åº¦ä¸€è‡´ã€‚å‡­å€Ÿå…¶å¼ºå¤§çš„é€šç”¨æ€§ã€å¯é‡å¤æ€§å’Œæ˜“äºéƒ¨ç½²çš„ç‰¹ç‚¹ï¼ŒnnLandmarkä¸º3Dåœ°æ ‡æ£€æµ‹å»ºç«‹äº†å¯é çš„åŸºå‡†çº¿ï¼Œæ”¯æŒä¾èµ–ç²¾ç¡®åœ°æ ‡è¯†åˆ«çš„è§£å‰–å®šä½å’Œä¸´åºŠå·¥ä½œæµç¨‹ç ”ç©¶ã€‚ä»£ç å°†å¾ˆå¿«æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06742v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ·±åº¦å­¦ä¹ çš„nnLandmarkæ¡†æ¶ä¸ºä¸‰ç»´åŒ»å­¦åœ°æ ‡æ£€æµ‹æä¾›äº†ä¸€ç§è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡åˆ©ç”¨nnU-Netçš„è‡ªé…ç½®åŠŸèƒ½å®ç°äº†ç²¾ç¡®æ£€æµ‹ã€‚æ­¤æ¡†æ¶å…·æœ‰å‡ºè‰²çš„å‡†ç¡®æ€§ã€é€šç”¨æ€§ã€å¯é‡å¤æ€§å’Œæ˜“ç”¨æ€§ï¼Œä¸ºä¾èµ–äºç²¾ç¡®åœ°æ ‡è¯†åˆ«çš„ç ”ç©¶å’Œä¸´åºŠå·¥ä½œæµç¨‹æä¾›äº†å¯é çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>nnLandmarkæ˜¯ä¸€ä¸ªç”¨äºä¸‰ç»´åŒ»å­¦åœ°æ ‡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŸºäºnnU-Netè¿›è¡Œheatmap-basedå›å½’ã€‚</li>
<li>nnLandmarké€šè¿‡è‡ªåŠ¨é…ç½®æ¶ˆé™¤äº†æ‰‹åŠ¨å‚æ•°è°ƒæ•´çš„éœ€è¦ï¼Œæä¾›äº†å¼€ç®±å³ç”¨çš„åŠŸèƒ½ã€‚</li>
<li>nnLandmarkåœ¨å…¬å…±æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œå¦‚åœ¨Mandibular Molar Landmarkæ•°æ®é›†ä¸Šçš„å¹³å‡å¾„å‘è¯¯å·®ä¸º1.5æ¯«ç±³ã€‚</li>
<li>nnLandmarkåœ¨è„‘MRIæ•°æ®é›†ä¸Šçš„è§£å‰–æ ‡è®°ç‰©å¹³å‡å¾„å‘è¯¯å·®ä¸º1.2æ¯«ç±³ï¼Œä¸ä¸“å®¶ä¹‹é—´çš„è¯„åˆ†å˜å¼‚åº¦å¯¹é½ã€‚</li>
<li>nnLandmarkæ¡†æ¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯æ”¯æŒåœ¨è§£å‰–å®šä½å’Œä¸´åºŠå·¥ä½œæµç¨‹ä¸­çš„ç²¾ç¡®åœ°æ ‡è¯†åˆ«ç ”ç©¶ã€‚</li>
<li>nnLandmarkå…·æœ‰å¯é‡å¤æ€§ä¸”æ˜“äºéƒ¨ç½²ï¼Œä¸ºä¾èµ–äºç²¾ç¡®åœ°æ ‡è¯†åˆ«çš„åº”ç”¨æä¾›äº†å¯é åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06742">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0fb5f65a18ed0b7bb4c4d47bfac9a4b1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-56f31d8e17987f5df6e3c2a26e275812.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ae1e50ebedff6992dd74c47878d1260.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0ecc339981d64879190465ae20ee5dd.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Large-Scale-Supervised-Pretraining-For-Traumatic-Brain-Injury-Segmentation"><a href="#Large-Scale-Supervised-Pretraining-For-Traumatic-Brain-Injury-Segmentation" class="headerlink" title="Large Scale Supervised Pretraining For Traumatic Brain Injury   Segmentation"></a>Large Scale Supervised Pretraining For Traumatic Brain Injury   Segmentation</h2><p><strong>Authors:Constantin Ulrich, Tassilo Wald, Fabian Isensee, Klaus H. Maier-Hein</strong></p>
<p>The segmentation of lesions in Moderate to Severe Traumatic Brain Injury (msTBI) presents a significant challenge in neuroimaging due to the diverse characteristics of these lesions, which vary in size, shape, and distribution across brain regions and tissue types. This heterogeneity complicates traditional image processing techniques, resulting in critical errors in tasks such as image registration and brain parcellation. To address these challenges, the AIMS-TBI Segmentation Challenge 2024 aims to advance innovative segmentation algorithms specifically designed for T1-weighted MRI data, the most widely utilized imaging modality in clinical practice. Our proposed solution leverages a large-scale multi-dataset supervised pretraining approach inspired by the MultiTalent method. We train a Resenc L network on a comprehensive collection of datasets covering various anatomical and pathological structures, which equips the model with a robust understanding of brain anatomy and pathology. Following this, the model is fine-tuned on msTBI-specific data to optimize its performance for the unique characteristics of T1-weighted MRI scans and outperforms the baseline without pretraining up to 2 Dice points. </p>
<blockquote>
<p>åœ¨ä¸­åº¦è‡³é‡åº¦åˆ›ä¼¤æ€§è„‘æŸä¼¤ï¼ˆmsTBIï¼‰ä¸­ï¼Œç—…ç¶çš„åˆ†å‰²åœ¨ç¥ç»å½±åƒå­¦ä¸­å‘ˆç°å‡ºä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºè¿™äº›ç—…ç¶çš„ç‰¹æ€§å¤šç§å¤šæ ·ï¼Œå…¶å¤§å°ã€å½¢çŠ¶å’Œè„‘åŒºåŸŸåŠç»„ç»‡ç±»å‹çš„åˆ†å¸ƒåœ¨å„æœ‰ä¸åŒã€‚è¿™ç§å¼‚è´¨æ€§ä½¿ä¼ ç»Ÿçš„å›¾åƒå¤„ç†æŠ€æœ¯å¤æ‚åŒ–ï¼Œå¹¶åœ¨å›¾åƒé…å‡†å’Œè„‘åˆ†åŒºç­‰ä»»åŠ¡ä¸­å¯¼è‡´å…³é”®é”™è¯¯ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œ2024å¹´AIMS-TBIåˆ†å‰²æŒ‘æˆ˜èµ›æ—¨åœ¨æ¨è¿›ä¸“é—¨ç”¨äºT1åŠ æƒMRIæ•°æ®çš„åˆ›æ–°åˆ†å‰²ç®—æ³•ï¼Œè¿™æ˜¯ä¸´åºŠå®è·µä¸­åº”ç”¨æœ€å¹¿æ³›çš„æˆåƒæ–¹å¼ã€‚æˆ‘ä»¬æå‡ºçš„è§£å†³æ–¹æ¡ˆå€Ÿé‰´äº†MultiTalentæ–¹æ³•çš„å¤§è§„æ¨¡å¤šæ•°æ®é›†ç›‘ç£é¢„è®­ç»ƒæ–¹æ³•ã€‚æˆ‘ä»¬åœ¨æ¶µç›–å„ç§è§£å‰–å’Œç—…ç†ç»“æ„çš„æ•°æ®é›†ä¸Šè®­ç»ƒäº†ä¸€ä¸ªResenc Lç½‘ç»œï¼Œè¿™ä½¿æ¨¡å‹å…·å¤‡äº†å¯¹è„‘è§£å‰–å­¦å’Œç—…ç†å­¦çš„ç¨³å¥ç†è§£ã€‚ä¹‹åï¼Œè¯¥æ¨¡å‹åœ¨msTBIç‰¹å®šæ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥é’ˆå¯¹T1åŠ æƒMRIæ‰«æçš„ç‹¬ç‰¹ç‰¹æ€§ä¼˜åŒ–å…¶æ€§èƒ½ï¼Œä¸æœªç»é¢„è®­ç»ƒçš„åŸºçº¿ç›¸æ¯”ï¼Œè¡¨ç°æé«˜äº†2ä¸ªDiceç‚¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06741v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†åœ¨ç¥ç»å½±åƒä¸­é’ˆå¯¹ä¸­åº¦è‡³é‡åº¦åˆ›ä¼¤æ€§è„‘æŸä¼¤ï¼ˆmsTBIï¼‰çš„ç—…å˜åˆ†å‰²æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç”±äºè¿™äº›ç—…å˜åœ¨å¤§å°ã€å½¢çŠ¶å’Œè„‘åŒºåŠç»„ç»‡ç±»å‹åˆ†å¸ƒä¸Šçš„å¤šæ ·æ€§ï¼Œä¼ ç»Ÿå›¾åƒå¤„ç†æŠ€æœ¯é¢ä¸´å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†é‡‡ç”¨å¤§è§„æ¨¡å¤šæ•°æ®é›†ç›‘ç£é¢„è®­ç»ƒæ–¹æ³•çš„å¤§å‹æŒ‘æˆ˜èµ›â€”â€”AIMSTBIåˆ†å‰²æŒ‘æˆ˜èµ›çš„ç›®æ ‡æ˜¯é€šè¿‡ç‰¹å®šäºT1åŠ æƒMRIæ•°æ®çš„åˆ†å‰²ç®—æ³•æ¥æ¨è¿›æŠ€æœ¯è¿›æ­¥ã€‚è¯¥æ–¹æ³•åŸºäºMultiTalentæ–¹æ³•ï¼Œè®­ç»ƒäº†ä¸€ä¸ªResenc Lç½‘ç»œï¼Œè¯¥ç½‘ç»œåœ¨æ¶µç›–å„ç§è§£å‰–å’Œç—…ç†ç»“æ„çš„ç»¼åˆæ•°æ®é›†ä¸Šå…·æœ‰è‰¯å¥½çš„æ€§èƒ½å’Œé€‚åº”æ€§å¼ºå¤§çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡Œæ·±åº¦å­¦ä¹ å¹¶ç»è¿‡ä¼˜åŒ–åå¯æ»¡è¶³ç‰¹å®šçš„ä»»åŠ¡éœ€æ±‚ï¼Œå¹¶é€šè¿‡è®­ç»ƒå¯ä»¥æå‡è‡³ä¸€å®šçš„åˆ†å‰²æ•ˆæœæ”¹å–„è¡¨ç°è¶…è¿‡é¢„è®­ç»ƒæ—¶çš„åŸºçº¿å€¼è‡³2 Diceç‚¹ã€‚æ­¤å¤–æˆ‘ä»¬æ€»ç»“æå‡ºäº†åº”ç”¨å…·æœ‰è¶…å¼ºç»¼åˆç†è§£å’Œæ·±åº¦å­¦ä¹ èƒ½åŠ›çš„å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„ä¼˜ç§€æŠ€æœ¯å¯ä»¥åŠ å¼ºè¯¥é¢†åŸŸè¿›æ­¥åŒæ—¶ä½“ç°äº†å¯¹ç›¸å…³ç—…ä¾‹æ•°æ®åº“å’Œæ•°æ®é‡‡é›†æ ‡å‡†åŒ–å¤„ç†çš„å¿…è¦æ€§å’Œè¿«åˆ‡æ€§éœ€æ±‚ä»¥æ»¡è¶³ç ”ç©¶å’Œå¼€å‘éœ€æ±‚åŒæ—¶ä¹Ÿçªå‡ºäº†è®­ç»ƒæ›´å¤šç‰¹å®šæ¨¡å‹å¯¹æ”¹è¿›äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æ½œåœ¨ä½œç”¨ã€‚æ€»ä½“è€Œè¨€è¯¥æŒ‘æˆ˜å…·æœ‰é‡å¤§çš„ç°å®æ„ä¹‰å’Œå¯è¡Œæ€§ä»·å€¼å¹¶æœ‰æœ›ä¸ºåŒ»å­¦å½±åƒé¢†åŸŸçš„è¿›æ­¥æä¾›é‡è¦çš„æ¨åŠ¨åŠ›é‡ã€‚ç„¶è€Œæˆ‘ä»¬ä¹Ÿéœ€è¦æ³¨æ„åˆ°ç›¸å…³çš„æ•°æ®é‡‡é›†å¤„ç†å’Œæ•°æ®æ ‡å‡†åŒ–å·¥ä½œéœ€è¦å¾—åˆ°æ›´å¤šçš„å…³æ³¨å’ŒæŠ•å…¥ä»¥æ¨è¿›ç ”ç©¶å‘å±•å–å¾—æ›´å¤§çš„è¿›å±•æˆæœå°†å±•ç°å‡ºä¸€ç§æ½œåœ¨çš„éœ€æ±‚å’Œæå‡çš„å·¨å¤§ç©ºé—´å’ŒæŒ‘æˆ˜å¯èƒ½æ€§ä½“ç°ä¹Ÿæ˜ å°„äº†åŸºäºéœ€æ±‚éœ€è¦è¿›è¡Œçš„æœªæ¥å‘å±•ç›¸å…³æ€è€ƒå’Œç ”ç©¶æ¢ç´¢ã€‚æ€»çš„æ¥è¯´é€šè¿‡å…ˆè¿›ç®—æ³•çš„è¿ç”¨å’Œå¯¹å¤§æ•°æ®é›†çš„ç»¼åˆåº”ç”¨ä½¿å¾—åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„æŠ€æœ¯å‘å±•é¢ä¸´å·¨å¤§çš„æœºé‡å’ŒæŒ‘æˆ˜åŒæ—¶æ¨åŠ¨äº†åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œåˆ›æ–°ã€‚æ–‡ä¸­å¼ºè°ƒäº†ç®—æ³•çš„é‡è¦æ€§åŒæ—¶å¼ºè°ƒäº†æ•°æ®é›†åœ¨æ¨åŠ¨æŠ€æœ¯è¿›æ­¥ä¸­çš„å…³é”®ä½œç”¨ã€‚åŒæ—¶æ–‡ä¸­ä¹ŸæŒ‡å‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬æ”¹è¿›ç®—æ³•ä¼˜åŒ–æ¨¡å‹ä»¥åŠå»ºç«‹æ›´å¤§è§„æ¨¡çš„æ•°æ®é›†ç­‰ã€‚æ–‡ä¸­è¿˜æå‡ºäº†åˆ›æ–°çš„æ–¹æ³•æ¥æé«˜æ¨¡å‹å¯¹å¤æ‚å›¾åƒçš„ç†è§£èƒ½åŠ›å¹¶é€šè¿‡ç²¾ç»†çš„è®­ç»ƒå’Œé€‚åº”æ€§ä¼˜åŒ–æå‡æ¨¡å‹æ€§èƒ½æ˜¾ç¤ºå‡ºæœªæ¥çš„æŠ€æœ¯å‘å±•æ–¹å‘å’Œç ”ç©¶å‰æ™¯ã€‚æ€»ä½“æ¥è¯´è¯¥æ–‡æœ¬å±•ç¤ºäº†åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„æœ€æ–°è¿›å±•å’Œæœªæ¥çš„å‘å±•è¶‹åŠ¿å¹¶å¼ºè°ƒäº†äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸçš„åº”ç”¨å‰æ™¯å¹¿é˜”å¹¶å‘¼åæ›´å¤šçš„ç ”ç©¶è€…å’Œå·¥ç¨‹å¸ˆæŠ•å…¥åˆ°ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸­æ¨åŠ¨åŒ»å­¦å›¾åƒåˆ†å‰²æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥å’Œåˆ›æ–°å‘å±•ä»¥åŠæœªæ¥çš„æŠ€æœ¯æ”¹è¿›å’Œå‘å±•è¶‹åŠ¿æ¢ç´¢å…·æœ‰é‡å¤§ç°å®æ„ä¹‰å’Œæ½œåŠ›ä»·å€¼åŒæ—¶ä¹Ÿå±•ç°å‡ºæœªæ¥äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦é¢†åŸŸçš„å¹¿é˜”åº”ç”¨å‰æ™¯çš„å·¨å¤§å‘å±•æ½œèƒ½ä¸æŒ‘æˆ˜å‹åŠ›æ— ç–‘æ¿€å‘å¯¹æœªçš„äº†è§£å’Œåˆ†ææ€åº¦é€šè¿‡ä¸æ–­æ›´æ–°å‘å±•æŠ€æœ¯åŠç²¾è¿›ç ”ç©¶å’Œä¸æ–­å­¦ä¹ ä¸æ–­æ¢ç´¢å°†ä¸ºç§‘æŠ€è¿›æ­¥åšå‡ºè´¡çŒ®æœ‰ç€ä¸€å®šçš„å‚è€ƒæ„ä¹‰å’Œå‰ç»ä½œç”¨ä»è€Œæ›´å¥½åœ°æ¨è¿›ç§‘æŠ€å‘å±•æœåŠ¡ç¤¾ä¼šäººæ°‘ä¹Ÿæ¨åŠ¨äº†å…¨çƒå¥åº·æ°´å¹³åŠè¯Šç–—æ–¹å¼çš„å…¨é¢å‘å±•å’Œä¸æ–­è¿›æ­¥ç§¯æå¼€æ‹“æ›´å¤šæ™ºèƒ½åŒ–æ—¶ä»£çš„åŠŸèƒ½åŒ–å’Œæ•°å­—åŒ–çš„ä¾¿æ·æ™ºèƒ½æœªæ¥äººå·¥æ™ºèƒ½çš„åŒ»ç–—è¾…åŠ©æ­£åœ¨é€æ¸æˆä¸ºå¤§åŠ¿æ‰€è¶‹æŒç»­å¸¦åŠ¨æ›´å¤šçš„åº”ç”¨åœºæ™¯æ¢ç´¢å’Œæœªæ¥å¥åº·æŠ€æœ¯ç ”ç©¶çš„å‡çº§ä¸è¿›æ­¥ç­‰ç­‰åœ¨åŒ»ç–—æœåŠ¡ç­‰å¤šä¸ªæ–¹é¢æ‰®æ¼”æ—¥ç›Šé‡è¦çš„è§’è‰²å°†ä¼šå®ç°æ™ºèƒ½åŒ–æŠ€æœ¯åœ¨åŒ»ç–—å¥åº·é¢†åŸŸæ›´å¤šæ™ºèƒ½åŒ–äººæ€§åŒ–çš„æœªæ¥æ•°å­—åŒ–ç”Ÿæ´»å‘å±•æ–°å‰æ™¯è¿™ä¹Ÿæ˜¯å½“ä»£ç¤¾ä¼šå‘å±•æå‡ºçš„é‡è¦è¦æ±‚å’Œé¢ä¸´çš„æŒ‘æˆ˜å°†ä¼šå¸¦æ¥æ–°çš„è·¨è¶Šå‘å±•å…·æœ‰é‡è¦æ„ä¹‰æ˜¯æœªæ¥ä¸–ç•Œé‡è¦å‘å±•çš„ç»„æˆéƒ¨åˆ†å’Œç ”ç©¶ä¸»é¢˜é¡ºåº”ä¿¡æ¯åŒ–æ—¶ä»£å‘å±•çš„æµªæ½®æŒç»­æ¨è¿›ç§‘æŠ€ä¸åŒ»ç–—æœåŠ¡æ›´å¥½æ›´å¹¿æ³›çš„ç»“åˆå’Œæå‡åˆ©ç”¨å¯¹è¡Œä¸šå‘å±•å‘æŒ¥ç€å·¨å¤§ä¿ƒè¿›ä½œç”¨ä½“ç°ç€ç¤¾ä¼šçš„å‘å±•è¿›æ­¥çš„æ ‡å¿—è¶‹åŠ¿ä½“ç°å‡ºå‘å±•çš„é‡å¤§æ„ä¹‰ä¹Ÿåœ¨ä¸æ–­å®Œå–„å’Œè°ƒæ•´ç§‘æŠ€åˆ›æ–°å¸¦æ¥å¹¿é˜”ç©ºé—´ä»¥æ»¡è¶³æœªæ¥å‘å±•å‰æ™¯å‘æŒ¥è‡ªèº«çš„æ¨åŠ¨ç¤¾ä¼šç»æµå‘å±•çš„ä½œç”¨å’Œç§‘æŠ€è¿›æ­¥æ¨è¿›æ„ä¹‰ä»¥æœŸç»™ä¸–ç•Œç§‘æŠ€å¸¦æ¥æ›´å¤šçš„åŠ¨åŠ›åŠåˆ›æ–°ä»·å€¼å‘æŒ¥æ›´å¤§çš„ä½œç”¨ä¿ƒè¿›äººç±»ç¤¾ä¼šçš„æŒç»­å‘å±•å’Œè¿›æ­¥ä¸æ–­æ¨åŠ¨ç§‘æŠ€åˆ›æ–°çš„çªç ´å’Œå‘å±•æ€åŠ¿å±•ç°å‡ºæ— é™çš„å‘å±•æ½œåŠ›å’Œæœªæ¥å‰æ™¯ã€‚<br>    <strong>Key Takeaways</strong>ï¼šè¯¥æ–‡æœ¬åŒ…æ‹¬ä»¥ä¸‹ä¸ƒä¸ªå…³é”®è¦ç‚¹ï¼š</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06741">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-eb6ab517c61707bd2bb50af72a37a0ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c491b3c84b5ae53ef5ed74bd5e1fba4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4997e19439eb1f7c34dbed3eaf7cbfd0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-daec94f1bbf563c12f392575f8a867f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e07c14eb349c641477d005c34a98414d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Retuve-Automated-Multi-Modality-Analysis-of-Hip-Dysplasia-with-Open-Source-AI"><a href="#Retuve-Automated-Multi-Modality-Analysis-of-Hip-Dysplasia-with-Open-Source-AI" class="headerlink" title="Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open   Source AI"></a>Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open   Source AI</h2><p><strong>Authors:Adam McArthur, Stephanie Wichuk, Stephen Burnside, Andrew Kirby, Alexander Scammon, Damian Sol, Abhilash Hareendranathan, Jacob L. Jaremko</strong></p>
<p>Developmental dysplasia of the hip (DDH) poses significant diagnostic challenges, hindering timely intervention. Current screening methodologies lack standardization, and AI-driven studies suffer from reproducibility issues due to limited data and code availability. To address these limitations, we introduce Retuve, an open-source framework for multi-modality DDH analysis, encompassing both ultrasound (US) and X-ray imaging. Retuve provides a complete and reproducible workflow, offering open datasets comprising expert-annotated US and X-ray images, pre-trained models with training code and weights, and a user-friendly Python Application Programming Interface (API). The framework integrates segmentation and landmark detection models, enabling automated measurement of key diagnostic parameters such as the alpha angle and acetabular index. By adhering to open-source principles, Retuve promotes transparency, collaboration, and accessibility in DDH research. This initiative has the potential to democratize DDH screening, facilitate early diagnosis, and ultimately improve patient outcomes by enabling widespread screening and early intervention. The GitHub repository&#x2F;code can be found here: <a target="_blank" rel="noopener" href="https://github.com/radoss-org/retuve">https://github.com/radoss-org/retuve</a> </p>
<blockquote>
<p>å‘è‚²æ€§é«‹å…³èŠ‚å‘è‚²ä¸è‰¯ï¼ˆDDHï¼‰å­˜åœ¨é‡å¤§çš„è¯Šæ–­æŒ‘æˆ˜ï¼Œé˜»ç¢äº†åŠæ—¶çš„å¹²é¢„ã€‚å½“å‰ç­›æŸ¥æ–¹æ³•ç¼ºä¹æ ‡å‡†åŒ–ï¼Œè€Œäººå·¥æ™ºèƒ½é©±åŠ¨çš„ç ”ç©¶ç”±äºæ•°æ®æœ‰é™å’Œä»£ç å¯ç”¨æ€§é—®é¢˜è€Œé¢ä¸´å†ç°æ€§é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Retuveï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤šæ¨¡å¼DDHåˆ†æçš„å¼€æºæ¡†æ¶ï¼Œæ¶µç›–äº†è¶…å£°ï¼ˆUSï¼‰å’ŒXå°„çº¿æˆåƒã€‚Retuveæä¾›äº†ä¸€ä¸ªå®Œæ•´ä¸”å¯å¤åˆ¶çš„å·¥ä½œæµç¨‹ï¼Œæä¾›åŒ…å«ä¸“å®¶æ³¨é‡Šçš„USå’ŒXå°„çº¿å›¾åƒçš„å¼€æ”¾æ•°æ®é›†ã€å¸¦æœ‰è®­ç»ƒä»£ç çš„é¢„è®­ç»ƒæ¨¡å‹å’Œæƒé‡ï¼Œä»¥åŠç”¨æˆ·å‹å¥½çš„Pythonåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰ã€‚è¯¥æ¡†æ¶é›†æˆäº†åˆ†å‰²å’Œåœ°æ ‡æ£€æµ‹æ¨¡å‹ï¼Œèƒ½å¤Ÿå®ç°å…³é”®è¯Šæ–­å‚æ•°çš„è‡ªåŠ¨æµ‹é‡ï¼Œä¾‹å¦‚é˜¿å°”æ³•è§’å’Œé«‹è‡¼æŒ‡æ•°ã€‚é€šè¿‡åšæŒå¼€æºåŸåˆ™ï¼ŒRetuveä¿ƒè¿›äº†DDHç ”ç©¶çš„é€æ˜åº¦ã€åä½œå’Œå¯è®¿é—®æ€§ã€‚è¿™ä¸€ä¸¾æªæœ‰å¯èƒ½ä½¿DDHç­›æŸ¥æ™®åŠåŒ–ï¼Œä¿ƒè¿›æ—©æœŸè¯Šæ–­ï¼Œå¹¶é€šè¿‡å¹¿æ³›çš„ç­›æŸ¥å’Œæ—©æœŸå¹²é¢„æœ€ç»ˆæ”¹å–„æ‚£è€…ç»“æœã€‚GitHubä»“åº“&#x2F;ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/radoss-org/retuve">https://github.com/radoss-org/retuve</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06422v1">PDF</a> 12 pages, 8 figures, submitted to Software Impacts</p>
<p><strong>Summary</strong></p>
<p>åŸºäºDDHï¼ˆå‘è‚²æ€§é«‹å…³èŠ‚å‘è‚²ä¸è‰¯ï¼‰è¯Šæ–­çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºRetuveå¼€æºæ¡†æ¶ï¼Œç”¨äºè¶…å£°å’ŒXå°„çº¿å¤šæ¨¡æ€å½±åƒåˆ†æã€‚è¯¥æ¡†æ¶æä¾›å®Œæ•´çš„å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬å…¬å¼€æ•°æ®é›†ã€é¢„è®­ç»ƒæ¨¡å‹å’Œæƒé‡ã€ç”¨æˆ·å‹å¥½çš„Python APIç­‰ã€‚å®ƒèƒ½è‡ªåŠ¨åŒ–æµ‹é‡å…³é”®è¯Šæ–­å‚æ•°ï¼Œå¦‚Î±è§’å’Œé«‹è‡¼æŒ‡æ•°ã€‚Retuveéµå¾ªå¼€æºåŸåˆ™ï¼Œä¿ƒè¿›DDHç ”ç©¶çš„é€æ˜åº¦ã€åä½œæ€§å’Œå¯è®¿é—®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DDHè¯Šæ–­é¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦æ ‡å‡†åŒ–ç­›æŸ¥æ–¹æ³•å’Œå¯é çš„æ•°æ®æ”¯æŒã€‚</li>
<li>Retuveæ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºå¤šæ¨¡æ€ï¼ˆè¶…å£°å’ŒXå°„çº¿ï¼‰DDHåˆ†æã€‚</li>
<li>Retuveæä¾›å®Œæ•´çš„å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬å…¬å¼€æ•°æ®é›†ã€é¢„è®­ç»ƒæ¨¡å‹å’Œæƒé‡ã€‚</li>
<li>è¯¥æ¡†æ¶æä¾›ç”¨æˆ·å‹å¥½çš„Python APIï¼Œæ–¹ä¾¿ç”¨æˆ·æ“ä½œã€‚</li>
<li>Retuveèƒ½è‡ªåŠ¨åŒ–æµ‹é‡å…³é”®è¯Šæ–­å‚æ•°ï¼Œå¦‚Î±è§’å’Œé«‹è‡¼æŒ‡æ•°ã€‚</li>
<li>Retuveéµå¾ªå¼€æºåŸåˆ™ï¼Œä¿ƒè¿›DDHç ”ç©¶çš„é€æ˜åº¦ã€åä½œå’Œå¯è®¿é—®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06422">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8156ead1855082a3cde413d85df2828a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ba352ee5067f90a075e1b6e5dd8f80d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3aeeb3cf52f9911fdf61b746e58ee38a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e0423766bf0a9354779a140de2bb89d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Predicting-Survivability-of-Cancer-Patients-with-Metastatic-Patterns-Using-Explainable-AI"><a href="#Predicting-Survivability-of-Cancer-Patients-with-Metastatic-Patterns-Using-Explainable-AI" class="headerlink" title="Predicting Survivability of Cancer Patients with Metastatic Patterns   Using Explainable AI"></a>Predicting Survivability of Cancer Patients with Metastatic Patterns   Using Explainable AI</h2><p><strong>Authors:Polycarp Nalela, Deepthi Rao, Praveen Rao</strong></p>
<p>Cancer remains a leading global health challenge and a major cause of mortality. This study leverages machine learning (ML) to predict the survivability of cancer patients with metastatic patterns using the comprehensive MSK-MET dataset, which includes genomic and clinical data from 25,775 patients across 27 cancer types. We evaluated five ML models-XGBoost, Na&quot;ive Bayes, Decision Tree, Logistic Regression, and Random Fores using hyperparameter tuning and grid search. XGBoost emerged as the best performer with an area under the curve (AUC) of 0.82. To enhance model interpretability, SHapley Additive exPlanations (SHAP) were applied, revealing key predictors such as metastatic site count, tumor mutation burden, fraction of genome altered, and organ-specific metastases. Further survival analysis using Kaplan-Meier curves, Cox Proportional Hazards models, and XGBoost Survival Analysis identified significant predictors of patient outcomes, offering actionable insights for clinicians. These findings could aid in personalized prognosis and treatment planning, ultimately improving patient care. </p>
<blockquote>
<p>ç™Œç—‡ä»ç„¶æ˜¯å…¨çƒé¢ä¸´çš„ä¸»è¦å¥åº·æŒ‘æˆ˜å’Œä¸»è¦çš„æ­»äº¡åŸå› ã€‚æœ¬ç ”ç©¶åˆ©ç”¨æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æŠ€æœ¯ï¼Œä½¿ç”¨åŒ…å«27ç§ç™Œç—‡ç±»å‹ã€å…±æ¶‰åŠæ¥è‡ªä¸–ç•Œå„åœ°è¿‘äº”ä¸‡åæ‚£è€…çš„åŸºå› åŠä¸´åºŠæ•°æ®çš„MSK-METå¤§å‹æ•°æ®é›†ï¼Œé¢„æµ‹ç™Œç—‡æ‚£è€…çš„ç”Ÿå­˜æ¦‚ç‡ã€‚æˆ‘ä»¬å¯¹äº”ç§æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬XGBoostã€æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ã€å†³ç­–æ ‘ã€é€»è¾‘å›å½’å’Œéšæœºæ£®æ—æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨è¶…å‚æ•°è°ƒæ•´å’Œç½‘æ ¼æœç´¢è¿›è¡Œä¼˜åŒ–ã€‚å…¶ä¸­ï¼ŒXGBoostè¡¨ç°æœ€ä½³ï¼Œæ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰è¾¾åˆ°0.82ã€‚ä¸ºäº†å¢å¼ºæ¨¡å‹çš„è§£é‡Šæ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†SHapley Additive exPlanationsï¼ˆSHAPï¼‰ï¼Œæ­ç¤ºäº†å…³é”®é¢„æµ‹å› ç´ ï¼Œå¦‚è½¬ç§»éƒ¨ä½æ•°é‡ã€è‚¿ç˜¤çªå˜è´Ÿè·ã€åŸºå› æ”¹å˜çš„ç™¾åˆ†æ¯”ä»¥åŠå™¨å®˜ç‰¹å¼‚æ€§è½¬ç§»ç­‰ã€‚é€šè¿‡Kaplan-Meieræ›²çº¿ã€Coxæ¯”ä¾‹é£é™©æ¨¡å‹å’ŒXGBoostç”Ÿå­˜åˆ†æè¿›è¡Œçš„è¿›ä¸€æ­¥ç”Ÿå­˜åˆ†æç¡®å®šäº†æ‚£è€…é¢„åçš„é‡è¦é¢„æµ‹å› ç´ ï¼Œä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›äº†å¯æ“ä½œçš„è§è§£ã€‚è¿™äº›å‘ç°æœ‰åŠ©äºè¿›è¡Œä¸ªæ€§åŒ–çš„é¢„åé¢„æµ‹å’Œæ²»ç–—è®¡åˆ’åˆ¶å®šï¼Œæœ€ç»ˆæ”¹å–„æ‚£è€…çš„æŠ¤ç†å’Œæ²»ç–—ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06306v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹ç™Œç—‡æ‚£è€…çš„ç”Ÿå­˜èƒ½åŠ›ï¼ŒåŸºäºMSK-METæ•°æ®é›†ï¼ŒåŒ…å«27ç§ç™Œç—‡ç±»å‹ã€å…±æ¶‰åŠ25,775åæ‚£è€…çš„åŸºå› ç»„åŠä¸´åºŠæ•°æ®ã€‚ç»è¿‡å¯¹äº”ç§æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¯„ä¼°ï¼ŒXGBoostè¡¨ç°æœ€ä½³ï¼Œæ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰è¾¾0.82ã€‚é‡‡ç”¨SHAPæ–¹æ³•æé«˜æ¨¡å‹è§£é‡Šæ€§ï¼Œæ­ç¤ºå…³é”®é¢„æµ‹å› ç´ åŒ…æ‹¬è½¬ç§»éƒ¨ä½è®¡æ•°ã€è‚¿ç˜¤çªå˜è´Ÿæ‹…ã€åŸºå› ç»„æ”¹å˜æ¯”ä¾‹åŠå™¨å®˜ç‰¹å¼‚æ€§è½¬ç§»ç­‰ã€‚æ­¤å¤–ï¼Œé€šè¿‡Kaplan-Meieræ›²çº¿ã€Coxæ¯”ä¾‹é£é™©æ¨¡å‹åŠXGBoostç”Ÿå­˜åˆ†æç­‰æ–¹æ³•è¿›ä¸€æ­¥åˆ†ææ‚£è€…ç”Ÿå­˜æƒ…å†µï¼Œä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›é‡è¦å‚è€ƒï¼Œæœ‰åŠ©äºä¸ªæ€§åŒ–é¢„ååŠæ²»ç–—è®¡åˆ’åˆ¶å®šï¼Œæœ€ç»ˆæ”¹å–„æ‚£è€…æŠ¤ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹ç™Œç—‡æ‚£è€…ç”Ÿå­˜èƒ½åŠ›ã€‚</li>
<li>åŸºäºMSK-METæ•°æ®é›†ï¼Œæ¶µç›–å¤šç§ç™Œç—‡ç±»å‹å’Œå¤§é‡æ‚£è€…æ•°æ®ã€‚</li>
<li>äº”ç§æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼ŒXGBoostè¡¨ç°æœ€ä½³ã€‚</li>
<li>é‡‡ç”¨SHAPæ–¹æ³•æé«˜æ¨¡å‹è§£é‡Šæ€§ï¼Œæ­ç¤ºå…³é”®é¢„æµ‹å› ç´ ã€‚</li>
<li>è½¬ç§»éƒ¨ä½è®¡æ•°ã€è‚¿ç˜¤çªå˜è´Ÿæ‹…ç­‰æ˜¯é‡è¦é¢„æµ‹æŒ‡æ ‡ã€‚</li>
<li>é€šè¿‡å¤šç§æ–¹æ³•åˆ†ææ‚£è€…ç”Ÿå­˜æƒ…å†µï¼ŒåŒ…æ‹¬Kaplan-Meieræ›²çº¿å’ŒCoxæ¯”ä¾‹é£é™©æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b37f79a8e414cae3f281714ba135ae30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f560aa0f65ca063d43330f3bbe5e41d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-276f96bd5d86dabdc55d679bad4b0fd7.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Subjective-Visual-Quality-Assessment-for-High-Fidelity-Learning-Based-Image-Compression"><a href="#Subjective-Visual-Quality-Assessment-for-High-Fidelity-Learning-Based-Image-Compression" class="headerlink" title="Subjective Visual Quality Assessment for High-Fidelity Learning-Based   Image Compression"></a>Subjective Visual Quality Assessment for High-Fidelity Learning-Based   Image Compression</h2><p><strong>Authors:Mohsen Jenadeleh, Jon Sneyers, Panqi Jia, Shima Mohammadi, Joao Ascenso, Dietmar Saupe</strong></p>
<p>Learning-based image compression methods have recently emerged as promising alternatives to traditional codecs, offering improved rate-distortion performance and perceptual quality. JPEG AI represents the latest standardized framework in this domain, leveraging deep neural networks for high-fidelity image reconstruction. In this study, we present a comprehensive subjective visual quality assessment of JPEG AI-compressed images using the JPEG AIC-3 methodology, which quantifies perceptual differences in terms of Just Noticeable Difference (JND) units. We generated a dataset of 50 compressed images with fine-grained distortion levels from five diverse sources. A large-scale crowdsourced experiment collected 96,200 triplet responses from 459 participants. We reconstructed JND-based quality scales using a unified model based on boosted and plain triplet comparisons. Additionally, we evaluated the alignment of multiple objective image quality metrics with human perception in the high-fidelity range. The CVVDP metric achieved the overall highest performance; however, most metrics including CVVDP were overly optimistic in predicting the quality of JPEG AI-compressed images. These findings emphasize the necessity for rigorous subjective evaluations in the development and benchmarking of modern image codecs, particularly in the high-fidelity range. Another technical contribution is the introduction of the well-known Meng-Rosenthal-Rubin statistical test to the field of Quality of Experience research. This test can reliably assess the significance of difference in performance of quality metrics in terms of correlation between metrics and ground truth. The complete dataset, including all subjective scores, is publicly available at <a target="_blank" rel="noopener" href="https://github.com/jpeg-aic/dataset-JPEG-AI-SDR25">https://github.com/jpeg-aic/dataset-JPEG-AI-SDR25</a>. </p>
<blockquote>
<p>åŸºäºå­¦ä¹ çš„å›¾åƒå‹ç¼©æ–¹æ³•ä½œä¸ºå¯¹ä¼ ç»Ÿç¼–ç æŠ€æœ¯çš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆè€Œå‡ºç°ï¼Œæä¾›äº†æ”¹è¿›çš„é€Ÿç‡å¤±çœŸæ€§èƒ½å’Œæ„ŸçŸ¥è´¨é‡ã€‚JPEG AIä»£è¡¨æ­¤é¢†åŸŸçš„æœ€æ–°æ ‡å‡†åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè¿›è¡Œé«˜ä¿çœŸå›¾åƒé‡å»ºã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨JPEG AIC-3æ–¹æ³•å¯¹JPEG AIå‹ç¼©å›¾åƒè¿›è¡Œä¸»è§‚è§†è§‰è´¨é‡è¯„ä¼°ï¼Œè¯¥æ–¹æ³•ä»¥åˆšåˆšå¯å¯Ÿè§‰å·®å¼‚ï¼ˆJNDï¼‰å•ä½é‡åŒ–æ„ŸçŸ¥å·®å¼‚ã€‚æˆ‘ä»¬ä»äº”ä¸ªä¸åŒçš„æ¥æºç”Ÿæˆäº†åŒ…å«ç²¾ç»†å¤±çœŸçº§åˆ«çš„50ä¸ªå‹ç¼©å›¾åƒæ•°æ®é›†ã€‚ä¸€é¡¹å¤§è§„æ¨¡ä¼—åŒ…å®éªŒæ”¶é›†äº†æ¥è‡ª459åå‚ä¸è€…çš„96,200ä¸ªä¸‰å…ƒç»„å“åº”ã€‚æˆ‘ä»¬åŸºäºå¢å¼ºå’Œçº¯ä¸‰å…ƒæ¯”è¾ƒé‡å»ºäº†åŸºäºJNDçš„è´¨é‡é‡è¡¨ç»Ÿä¸€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å¤šä¸ªå®¢è§‚å›¾åƒè´¨é‡æŒ‡æ ‡ä¸é«˜ä¿çœŸèŒƒå›´å†…äººç±»æ„ŸçŸ¥çš„å¯¹é½ç¨‹åº¦ã€‚CVVDPæŒ‡æ ‡æ€»ä½“æ€§èƒ½æœ€é«˜ï¼›ç„¶è€Œï¼ŒåŒ…æ‹¬CVVDPåœ¨å†…çš„å¤§å¤šæ•°æŒ‡æ ‡åœ¨é¢„æµ‹JPEG AIå‹ç¼©å›¾åƒè´¨é‡æ—¶è¿‡äºä¹è§‚ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨ç°ä»£å›¾åƒç¼–ç æ ¼å¼çš„å¼€å‘å’ŒåŸºå‡†æµ‹è¯•ä¸­ä¸¥æ ¼è¿›è¡Œä¸»è§‚è¯„ä»·çš„å¿…è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜ä¿çœŸèŒƒå›´å†…ã€‚å¦ä¸€ä¸ªæŠ€æœ¯è´¡çŒ®æ˜¯å°†è‘—åçš„Meng-Rosenthal-Rubinç»Ÿè®¡æµ‹è¯•å¼•å…¥åˆ°ä½“éªŒè´¨é‡ç ”ç©¶é¢†åŸŸã€‚è¯¥æµ‹è¯•å¯ä»¥å¯é åœ°è¯„ä¼°è´¨é‡æŒ‡æ ‡åœ¨æŒ‡æ ‡ä¸åœ°é¢çœŸå®ä¹‹é—´çš„ç›¸å…³æ€§æ–¹é¢çš„æ€§èƒ½å·®å¼‚æ˜¯å¦æ˜¾è‘—ã€‚åŒ…æ‹¬æ‰€æœ‰ä¸»è§‚åˆ†æ•°åœ¨å†…çš„å®Œæ•´æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/jpeg-aic/dataset-JPEG-AI-SDR25%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/jpeg-aic/dataset-JPEG-AI-SDR25å…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06301v1">PDF</a> 7 pages, 5 figures, 3 tables, submitted to QoMEX 2025</p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬ç ”ç©¶å¯¹JPEG AIå‹ç¼©å›¾åƒè¿›è¡Œäº†å…¨é¢çš„ä¸»è§‚è§†è§‰è´¨é‡è¯„ä¼°ï¼Œé‡‡ç”¨JPEG AIC-3æ–¹æ³•è®ºé‡åŒ–æ„ŸçŸ¥å·®å¼‚ï¼Œç”Ÿæˆäº†åŒ…å«ç²¾ç»†å¤±çœŸçº§åˆ«çš„æ•°æ®é›†ã€‚é€šè¿‡å¤§è§„æ¨¡ç½‘ç»œå®éªŒæ”¶é›†å‚ä¸è€…å“åº”ï¼Œé‡å»ºåŸºäºJNDçš„è´¨é‡å°ºåº¦ã€‚è¯„ä¼°å¤šç§å®¢è§‚å›¾åƒè´¨é‡æŒ‡æ ‡ä¸äººç±»æ„ŸçŸ¥çš„ä¸€è‡´æ€§ï¼Œå‘ç°CVVDPæŒ‡æ ‡æ€§èƒ½æœ€ä½³ï¼Œä½†é¢„æµ‹JPEG AIå‹ç¼©å›¾åƒè´¨é‡æ—¶è¿‡äºä¹è§‚ã€‚ç ”ç©¶å¼ºè°ƒç°ä»£å›¾åƒç¼–ç æ ¼å¼å‘å±•ä¸­ä¸»è§‚è¯„ä¼°çš„é‡è¦æ€§ï¼Œå¹¶å°†Meng-Rosenthal-Rubinç»Ÿè®¡æµ‹è¯•å¼•å…¥QoEç ”ç©¶é¢†åŸŸï¼Œä»¥è¯„ä¼°è´¨é‡æŒ‡æ ‡æ€§èƒ½çš„æ˜¾è‘—æ€§ã€‚å®Œæ•´æ•°æ®é›†å…¬å¼€å¯ç”¨ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å­¦ä¹ å‹å›¾åƒå‹ç¼©æ–¹æ³•ä½œä¸ºä¼ ç»Ÿç¼–è§£ç å™¨çš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆå‡ºç°ï¼Œæä¾›äº†æ”¹è¿›çš„é€Ÿç‡å¤±çœŸæ€§èƒ½å’Œæ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>JPEG AIä»£è¡¨æ­¤é¢†åŸŸçš„æœ€æ–°æ ‡å‡†åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè¿›è¡Œé«˜ä¿çœŸå›¾åƒé‡å»ºã€‚</li>
<li>é‡‡ç”¨JPEG AIC-3æ–¹æ³•å¯¹JPEG AIå‹ç¼©å›¾åƒè¿›è¡Œäº†å…¨é¢çš„ä¸»è§‚è§†è§‰è´¨é‡è¯„ä¼°ï¼Œé€šè¿‡é‡åŒ–æ„ŸçŸ¥å·®å¼‚è¯„ä¼°å›¾åƒè´¨é‡ã€‚</li>
<li>ç”Ÿæˆäº†åŒ…å«äº”ç§ä¸åŒæ¥æºçš„50å¼ ç²¾ç»†å¤±çœŸçº§åˆ«å‹ç¼©å›¾åƒçš„æ•°æ®é›†ã€‚</li>
<li>å¤§è§„æ¨¡ç½‘ç»œå®éªŒæ”¶é›†äº†å¤§é‡å‚ä¸è€…å“åº”ï¼Œç”¨äºé‡å»ºåŸºäºJNDçš„è´¨é‡å°ºåº¦ã€‚</li>
<li>è¯„ä¼°äº†å¤šç§å®¢è§‚å›¾åƒè´¨é‡æŒ‡æ ‡åœ¨é«˜ä¿çœŸèŒƒå›´å†…ä¸äººç±»æ„ŸçŸ¥çš„ä¸€è‡´æ€§ï¼Œå‘ç°CVVDPæŒ‡æ ‡æ€§èƒ½æœ€ä½³ï¼Œä½†å­˜åœ¨é¢„æµ‹åå·®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06301">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c62cb1a9138fe33f94170e936fa29822.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51985f0939e88877aabe62b8bd3d75b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54445f47a8fefce6c0a69928f39b8bc5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6696ab71fc0970d034d8eabbb6251c85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45a0c29158a5e45bc05eea1a3c5844c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cbddc62196b060ab2fa726ac7d817554.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90e057c528def1f8d0b0d675f1495866.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77ccdcf9639a9439b76e1d36f5ceca67.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1b763085b9aa6e19cb69ebffa151663b.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Cross-correlation-between-soft-X-rays-and-galaxies-A-new-benchmark-for-galaxy-evolution-models"><a href="#Cross-correlation-between-soft-X-rays-and-galaxies-A-new-benchmark-for-galaxy-evolution-models" class="headerlink" title="Cross-correlation between soft X-rays and galaxies A new benchmark for   galaxy evolution models"></a>Cross-correlation between soft X-rays and galaxies A new benchmark for   galaxy evolution models</h2><p><strong>Authors:Johan Comparat, Andrea Merloni, Gabriele Ponti, Soumya Shreeram, Yi Zhang, Thomas H. Reiprich, Ang Liu, Riccardo Seppi, Xiaoyuan Zhang, Nicolas Clerc, Andrina Nicola, Kirpal Nandra, Mara Salvato, Nicola Malavasi</strong></p>
<p>This article presents the construction and validation of complete stellar mass-selected, volume-limited galaxy samples using the Legacy Survey (data release 10) galaxy catalogs, covering $\sim16,800$ deg$^2$ of extra-galactic sky, and extending to redshift $z&lt;0.35$. We measure the correlation function of these galaxies with tiny statistical uncertainties at the percent level and systematic uncertainties up to 5%. A 4-parameter halo occupation distribution (HOD) model is fitted to retrieve the population of host halos, yielding results on the stellar to halo mass relation consistent with the current models of galaxy formation and evolution. Using these complete galaxy samples, we measure and analyze the cross-correlation (X-corr) between galaxies and all soft X-ray photons observed by SRG&#x2F;eROSITA in the 0.5-2 keV band over $\sim13,000$ deg$^2$. The cross correlation measurements have unprecedented sub-percent statistical uncertainty and ~5-10% systematic uncertainty.   An extension to the halo model is introduced to interpret the X-corr, decomposing contributions from X-ray point sources, hot gas (CGM), satellites, and the 2-halo term. For low stellar mass thresholds ($\log M^*&#x2F;M_{\odot}&gt;$ 10, 10.25, 10.5), we find that the point source emission dominates the X-corr at small separation ($r&lt;80$kpc). Then, in the range ($80&lt;r&lt;2$Mpc), the emission from large halos hosting satellite galaxies dominates. Finally, on scales beyond that considered here ($r&gt;2$Mpc), the 2-halo term becomes dominant. Interestingly, there is no scale at which the CGM dominates. In the range ($20&lt;r&lt;200$kpc), the CGM contributes to more than 10% of the signal. Progressively, with the minimum stellar mass increasing, the CGM emission increases. We constrain the $M_{500c}-L_X$ scaling relation slope, $1.629^{+0.091}_{-0.089}$, at the 5% level using the samples with the lowest mass threshold. </p>
<blockquote>
<p>æœ¬æ–‡åˆ©ç”¨Legacy Surveyï¼ˆç¬¬10æ¬¡æ•°æ®å‘å¸ƒï¼‰æ˜Ÿç³»ç›®å½•ï¼Œæ„å»ºäº†å®Œæ•´çš„æ’æ˜Ÿè´¨é‡é€‰æ‹©ã€ä½“ç§¯é™åˆ¶çš„æ˜Ÿç³»æ ·æœ¬ï¼Œå¯¹çº¦16,800å¹³æ–¹åº¦å¤–çš„æ˜Ÿç³»è¿›è¡Œç ”ç©¶ï¼Œå»¶ä¼¸è‡³çº¢ç§»z &lt; 0.35ã€‚æˆ‘ä»¬å¯¹è¿™äº›æ˜Ÿç³»çš„å…³è”å‡½æ•°è¿›è¡Œäº†æµ‹é‡ï¼Œç»Ÿè®¡è¯¯å·®éå¸¸å°ï¼Œåªæœ‰ç™¾åˆ†ä¹‹ä¸€å·¦å³ï¼Œç³»ç»Ÿè¯¯å·®è¾¾ç™¾åˆ†ä¹‹äº”ã€‚é€šè¿‡æ‹Ÿåˆä¸€ä¸ªåŒ…å«å››ä¸ªå‚æ•°çš„æ™•å æ®åˆ†å¸ƒï¼ˆHODï¼‰æ¨¡å‹ï¼Œæˆ‘ä»¬å¾—åˆ°äº†å¯„ä¸»æ™•çš„äººå£æ•°æ®ï¼Œå¾—åˆ°çš„ç»“æœä¸å½“å‰çš„æ˜Ÿç³»å½¢æˆå’Œæ¼”åŒ–æ¨¡å‹ä¸€è‡´çš„æ’æ˜Ÿæ™•è´¨é‡å…³ç³»ã€‚ä½¿ç”¨è¿™äº›å®Œæ•´çš„æ˜Ÿç³»æ ·æœ¬ï¼Œæˆ‘ä»¬æµ‹é‡å¹¶åˆ†æäº†æ˜Ÿç³»ä¸SRG&#x2F;eROSITAåœ¨çº¦ä¸€ä¸‡ä¸‰åƒå¹³æ–¹åº¦å†…è§‚å¯Ÿåˆ°çš„æ‰€æœ‰è½¯Xå°„çº¿å…‰å­ä¹‹é—´çš„äº¤å‰å…³è”ï¼ˆX-corrï¼‰ã€‚äº¤å‰å…³è”çš„æµ‹é‡å…·æœ‰å‰æ‰€æœªæœ‰çš„äºšç™¾åˆ†ä¹‹ä¸€çš„ç»Ÿè®¡è¯¯å·®å’Œçº¦ç™¾åˆ†ä¹‹äº”åˆ°ç™¾åˆ†ä¹‹åçš„ç³»ç»Ÿè¯¯å·®ã€‚ä¸ºäº†è§£é‡ŠX-corrï¼Œå¯¹æ™•æ¨¡å‹è¿›è¡Œäº†æ‰©å±•ï¼Œåˆ†è§£äº†æ¥è‡ªXå°„çº¿ç‚¹æºã€çƒ­æ°”ä½“ï¼ˆæ™•æ°”ä½“ï¼‰ã€å«æ˜Ÿå’Œä¸¤æ™•æœ¯è¯­çš„è´¡çŒ®ã€‚å¯¹äºè¾ƒä½çš„æ’æ˜Ÿè´¨é‡é˜ˆå€¼ï¼ˆlog M * &#x2F; MâŠ™ &gt; 10ã€ 10.25ã€ 10.5ï¼‰ï¼Œæˆ‘ä»¬å‘ç°ç‚¹æºå‘å°„åœ¨å°åˆ†ç¦»è·ç¦»ï¼ˆr &lt; 80kpcï¼‰å†…ä¸»å¯¼äº†X-corrã€‚ç„¶åï¼Œåœ¨èŒƒå›´ï¼ˆ80 &lt; r &lt; 2Mpcï¼‰å†…ï¼Œç”±å®¿ä¸»å«æ˜Ÿæ˜Ÿç³»çš„å¤§å‹æ™•çš„å‘å°„å ä¸»å¯¼åœ°ä½ã€‚æœ€åï¼Œåœ¨æ­¤èŒƒå›´ä¹‹å¤–ï¼ˆr &gt; 2Mpcï¼‰ï¼Œä¸¤æ™•æœ¯è¯­å˜å¾—å ä¸»å¯¼åœ°ä½ã€‚æœ‰è¶£çš„æ˜¯ï¼Œæ²¡æœ‰å“ªä¸ªå°ºåº¦ä¸Šæ™•æ°”ä½“å ä¸»å¯¼åœ°ä½ã€‚åœ¨èŒƒå›´ï¼ˆ20 &lt; r &lt; 200kpcï¼‰å†…ï¼Œæ™•æ°”ä½“çš„è´¡çŒ®è¶…è¿‡äº†ä¿¡å·çš„ç™¾åˆ†ä¹‹åã€‚éšç€æœ€å°æ’æ˜Ÿè´¨é‡çš„å¢åŠ ï¼Œæ™•æ°”ä½“çš„å‘å°„ä¹Ÿéšä¹‹å¢åŠ ã€‚æˆ‘ä»¬çº¦æŸäº†æœ€å°æ’æ˜Ÿè´¨é‡ä¸Lxçš„ç¼©æ”¾å…³ç³»æ–œç‡ï¼ˆæœ€ä½è´¨é‡é˜ˆå€¼çš„æ ·æœ¬ï¼‰ä¸º 1.629 Â± 0.091ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19796v2">PDF</a> Accepted in A&amp;A</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡åˆ©ç”¨Legacy Surveyï¼ˆæ•°æ®å‘å¸ƒ10ç‰ˆï¼‰æ˜Ÿç³»ç›®å½•æ„å»ºäº†å®Œæ•´çš„æ’æ˜Ÿè´¨é‡é€‰å®šçš„ã€é™ä½“ç§¯çš„æ˜Ÿç³»æ ·æœ¬ï¼Œç ”ç©¶äº†æ˜Ÿç³»ä¸SRG&#x2F;eROSITAè§‚æµ‹çš„è½¯Xå°„çº¿å…‰å­ä¹‹é—´çš„äº¤å‰å…³è”ã€‚é‡‡ç”¨4å‚æ•°æ˜Ÿç³»å ç”¨æš—ç‰©è´¨æ™•æ¨¡å‹ï¼Œåˆ†æäº†æ˜Ÿç³»ä¸å„ç§Xå°„çº¿æºï¼ˆç‚¹æºã€çƒ­æ°”ä½“ï¼ˆå‘¨å›´ä»‹è´¨ï¼‰ã€å«æ˜Ÿæ˜Ÿç³»åŠå¤§å°ºåº¦ç»“æ„ï¼‰ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚å‘ç°ç‚¹æºåœ¨ä½æ’æ˜Ÿè´¨é‡é˜ˆå€¼ä¸‹å ä¸»å¯¼åœ°ä½ï¼Œéšç€å°ºåº¦çš„å¢å¤§ï¼Œå«æ˜Ÿæ˜Ÿç³»å’Œå¤§å°ºåº¦ç»“æ„çš„ä½œç”¨é€æ¸æ˜¾ç°ï¼Œè€Œå‘¨å›´ä»‹è´¨çš„å½±å“è¾ƒå°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨Legacy Surveyæ•°æ®æ„å»ºäº†å®Œæ•´çš„æ’æ˜Ÿè´¨é‡é€‰å®šã€é™ä½“ç§¯çš„æ˜Ÿç³»æ ·æœ¬ï¼Œè¦†ç›–çº¦16,800åº¦å¹³æ–¹çš„é“¶æ²³ç³»å¤–å¤©ç©ºï¼Œå¹¶æ‰©å±•åˆ°çº¢ç§»z&lt;0.35ã€‚</li>
<li>é€šè¿‡4å‚æ•°æš—ç‰©è´¨æ™•å ç”¨æ¨¡å‹ï¼Œå¯¹æ˜Ÿç³»çš„ä¸»å®¿æš—ç‰©è´¨æ™•è¿›è¡Œåˆ†æã€‚</li>
<li>æµ‹é‡å’Œåˆ†æäº†æ˜Ÿç³»ä¸SRG&#x2F;eROSITAè§‚æµ‹åˆ°çš„è½¯Xå°„çº¿å…‰å­ä¹‹é—´çš„äº¤å‰å…³è”ï¼ˆX-corrï¼‰ã€‚</li>
<li>X-corrçš„æµ‹é‡å…·æœ‰å‰æ‰€æœªæœ‰çš„ç™¾åˆ†ä¹‹ä¸€çº§çš„ç»Ÿè®¡ä¸ç¡®å®šæ€§å’Œçº¦5-10%çš„ç³»ç»Ÿä¸ç¡®å®šæ€§ã€‚</li>
<li>åœ¨ä¸åŒçš„å°ºåº¦ä¸Šï¼Œåˆ†æäº†Xå°„çº¿ç‚¹æºã€çƒ­æ°”ä½“ï¼ˆå‘¨å›´ä»‹è´¨ï¼‰ã€å«æ˜Ÿæ˜Ÿç³»ä»¥åŠä¸¤æš—ç‰©è´¨æ™•é—´çš„ç›¸äº’ä½œç”¨å¯¹X-corrçš„è´¡çŒ®ã€‚</li>
<li>å‘ç°ç‚¹æºåœ¨ä½æ’æ˜Ÿè´¨é‡é˜ˆå€¼ä¸‹å ä¸»å¯¼åœ°ä½ï¼Œè€Œå‘¨å›´ä»‹è´¨çš„å½±å“åœ¨ç‰¹å®šå°ºåº¦ä¸Šè¶…è¿‡10%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19796">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4d234c04709b52f7bb58f92ce18515a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-379fa79a12eed606ec5310933fb0c8e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-14920db024e0b22d52a641d745d35fb0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0a8d6d1e44626c8e839872b629c9dc1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c996e56421e5e8112a3e0d1d964bf20d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1be55f11c3489f839e17efd93f5704d3.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Learning-Generalizable-Features-for-Tibial-Plateau-Fracture-Segmentation-Using-Masked-Autoencoder-and-Limited-Annotations"><a href="#Learning-Generalizable-Features-for-Tibial-Plateau-Fracture-Segmentation-Using-Masked-Autoencoder-and-Limited-Annotations" class="headerlink" title="Learning Generalizable Features for Tibial Plateau Fracture Segmentation   Using Masked Autoencoder and Limited Annotations"></a>Learning Generalizable Features for Tibial Plateau Fracture Segmentation   Using Masked Autoencoder and Limited Annotations</h2><p><strong>Authors:Peiyan Yue, Die Cai, Chu Guo, Mengxing Liu, Jun Xia, Yi Wang</strong></p>
<p>Accurate automated segmentation of tibial plateau fractures (TPF) from computed tomography (CT) requires large amounts of annotated data to train deep learning models, but obtaining such annotations presents unique challenges. The process demands expert knowledge to identify diverse fracture patterns, assess severity, and account for individual anatomical variations, making the annotation process highly time-consuming and expensive. Although semi-supervised learning methods can utilize unlabeled data, existing approaches often struggle with the complexity and variability of fracture morphologies, as well as limited generalizability across datasets. To tackle these issues, we propose an effective training strategy based on masked autoencoder (MAE) for the accurate TPF segmentation in CT. Our method leverages MAE pretraining to capture global skeletal structures and fine-grained fracture details from unlabeled data, followed by fine-tuning with a small set of labeled data. This strategy reduces the dependence on extensive annotations while enhancing the modelâ€™s ability to learn generalizable and transferable features. The proposed method is evaluated on an in-house dataset containing 180 CT scans with TPF. Experimental results demonstrate that our method consistently outperforms semi-supervised methods, achieving an average Dice similarity coefficient (DSC) of 95.81%, average symmetric surface distance (ASSD) of 1.91mm, and Hausdorff distance (95HD) of 9.42mm with only 20 annotated cases. Moreover, our method exhibits strong transferability when applying to another public pelvic CT dataset with hip fractures, highlighting its potential for broader applications in fracture segmentation tasks. </p>
<blockquote>
<p>ç²¾ç¡®è‡ªåŠ¨åˆ†å‰²èƒ«éª¨å¹³å°éª¨æŠ˜ï¼ˆTPFï¼‰æ˜¯åŒ»å­¦å›¾åƒå¤„ç†é¢†åŸŸçš„æ ¸å¿ƒè¯¾é¢˜ã€‚åœ¨ä½¿ç”¨è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰çš„æƒ…å†µä¸‹ï¼Œè¦æƒ³å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œè®­ç»ƒéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ã€‚ç„¶è€Œï¼Œè·å–è¿™äº›æ ‡æ³¨æ•°æ®é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ã€‚è¿™ä¸€è¿‡ç¨‹éœ€è¦ä¸“ä¸šçŸ¥è¯†æ¥è¯†åˆ«å¤šç§éª¨æŠ˜æ¨¡å¼ã€è¯„ä¼°ä¸¥é‡ç¨‹åº¦ï¼Œå¹¶è€ƒè™‘ä¸ªä½“è§£å‰–ç»“æ„å·®å¼‚ï¼Œä½¿å¾—æ ‡æ³¨è¿‡ç¨‹æ—¢è€—æ—¶åˆæ˜‚è´µã€‚å°½ç®¡åŠç›‘ç£å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨æœªæ ‡è®°çš„æ•°æ®ï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥åº”å¯¹éª¨æŠ˜å½¢æ€çš„å¤æ‚æ€§å’Œå¯å˜æ€§ï¼Œä»¥åŠåœ¨æ•°æ®é›†ä¹‹é—´çš„é€šç”¨æ€§æœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ©ç è‡ªåŠ¨ç¼–ç å™¨ï¼ˆMAEï¼‰çš„æœ‰æ•ˆè®­ç»ƒç­–ç•¥ï¼Œç”¨äºCTä¸­å‡†ç¡®çš„TPFåˆ†å‰²ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨MAEçš„é¢„è®­ç»ƒåŠŸèƒ½ï¼Œä»éæ ‡è®°æ•°æ®ä¸­æ•è·å…¨å±€éª¨éª¼ç»“æ„å’Œç²¾ç»†çš„éª¨æŠ˜ç»†èŠ‚ï¼Œç„¶åä½¿ç”¨å°‘é‡æ ‡è®°æ•°æ®è¿›è¡Œå¾®è°ƒã€‚æ­¤ç­–ç•¥å‡å°‘äº†æˆ‘ä»¬å¯¹å¤§é‡æ³¨é‡Šçš„ä¾èµ–ï¼ŒåŒæ—¶æé«˜äº†æ¨¡å‹çš„é€šç”¨æ€§å’Œå¯è¿ç§»ç‰¹å¾çš„å­¦ä¹ èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åœ¨åŒ…å«180ä¾‹TPFçš„CTæ‰«æå†…éƒ¨æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸€ç›´ä¼˜äºåŠç›‘ç£æ–¹æ³•ï¼Œå¹³å‡Diceç›¸ä¼¼ç³»æ•°ï¼ˆDSCï¼‰è¾¾åˆ°95.81%ï¼Œå¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»ï¼ˆASSDï¼‰ä¸º1.91æ¯«ç±³ï¼ŒHausdorffè·ç¦»ï¼ˆ95HDï¼‰ä¸º9.42æ¯«ç±³ï¼Œä¸”ä»…ä½¿ç”¨20ä¸ªæ ‡æ³¨æ¡ˆä¾‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤„ç†å¦ä¸€å…¬å…±éª¨ç›†CTæ•°æ®é›†ï¼ˆåŒ…å«é«‹å…³èŠ‚éª¨æŠ˜ï¼‰æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„è¿ç§»æ€§ï¼Œçªæ˜¾å…¶åœ¨éª¨æŠ˜åˆ†å‰²ä»»åŠ¡ä¸­æ›´å¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.02862v2">PDF</a> 5 pages, 6 figures. Accepted to IEEE EMBC 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ©ç è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰çš„æœ‰æ•ˆè®­ç»ƒç­–ç•¥ï¼Œç”¨äºå‡†ç¡®åœ°å¯¹CTä¸­çš„èƒ«éª¨å¹³å°éª¨æŠ˜ï¼ˆTPFï¼‰è¿›è¡Œè‡ªåŠ¨åˆ†å‰²ã€‚è¯¥æ–¹æ³•åˆ©ç”¨MAEè¿›è¡Œé¢„è®­ç»ƒï¼Œä»éæ ‡è®°æ•°æ®ä¸­æ•è·å…¨å±€éª¨éª¼ç»“æ„å’Œç²¾ç»†éª¨æŠ˜ç»†èŠ‚ï¼Œç„¶åé€šè¿‡å°‘é‡æ ‡è®°æ•°æ®è¿›è¡Œå¾®è°ƒã€‚æ­¤ç­–ç•¥å‡å°‘äº†å¤§é‡æ ‡æ³¨çš„ä¾èµ–ï¼Œæé«˜äº†æ¨¡å‹å­¦ä¹ é€šç”¨å’Œå¯è¿ç§»ç‰¹å¾çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å†…éƒ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºåŠç›‘ç£æ–¹æ³•ï¼Œå¹¶åœ¨å¦ä¸€ä¸ªå…¬å…±éª¨ç›†CTæ•°æ®é›†ä¸Šå…·æœ‰è‰¯å¥½çš„å¯è¿ç§»æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‡†ç¡®è‡ªåŠ¨åˆ†å‰²èƒ«éª¨å¹³å°éª¨æŠ˜ï¼ˆTPFï¼‰éœ€è¦å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</li>
<li>æ ‡æ³¨è¿‡ç¨‹éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œä»¥è¯†åˆ«å¤šç§éª¨æŠ˜æ¨¡å¼ã€è¯„ä¼°ä¸¥é‡ç¨‹åº¦å¹¶è€ƒè™‘ä¸ªä½“è§£å‰–ç»“æ„å·®å¼‚ï¼Œå¯¼è‡´æ ‡æ³¨è¿‡ç¨‹æ—¢è€—æ—¶åˆæ˜‚è´µã€‚</li>
<li>åŠç›‘ç£å­¦ä¹ æ–¹æ³•å¯ä»¥åˆ©ç”¨æœªæ ‡è®°æ•°æ®ï¼Œä½†ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†éª¨æŠ˜å½¢æ€çš„å¤æ‚æ€§å’Œå¯å˜æ€§ï¼Œä»¥åŠæ•°æ®é›†ä¹‹é—´çš„æœ‰é™æ³›åŒ–æ€§ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºæ©ç è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰çš„æœ‰æ•ˆè®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨æ— æ ‡ç­¾æ•°æ®é¢„è®­ç»ƒæ¨¡å‹æ•æ‰å…¨å±€éª¨éª¼ç»“æ„å’Œç²¾ç»†éª¨æŠ˜ç»†èŠ‚ã€‚</li>
<li>é€šè¿‡å°‘é‡æ ‡è®°æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œå‡å°‘æ ‡æ³¨æ•°æ®çš„ä¾èµ–å¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å†…éƒ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–åŠç›‘ç£æ–¹æ³•ï¼Œå¹¶å®ç°äº†é«˜Diceç›¸ä¼¼ç³»æ•°ï¼ˆDSCï¼‰ã€ä½å¯¹ç§°è¡¨é¢è·ç¦»ï¼ˆASSDï¼‰å’Œä½Hausdorffè·ç¦»ï¼ˆ95HDï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.02862">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c16409ac0ded11bdc42af82821eb1135.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8988ae838d798cd22460152cf2e1163d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-456de70fc0725bae9ef6111c2ee2e6fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48f4a838f9509ab5fdc13babbe1303f7.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Medical-GAT-Cancer-Document-Classification-Leveraging-Graph-Based-Residual-Network-for-Scenarios-with-Limited-Data"><a href="#Medical-GAT-Cancer-Document-Classification-Leveraging-Graph-Based-Residual-Network-for-Scenarios-with-Limited-Data" class="headerlink" title="Medical-GAT: Cancer Document Classification Leveraging Graph-Based   Residual Network for Scenarios with Limited Data"></a>Medical-GAT: Cancer Document Classification Leveraging Graph-Based   Residual Network for Scenarios with Limited Data</h2><p><strong>Authors:Elias Hossain, Tasfia Nuzhat, Shamsul Masum, Shahram Rahimi, Noorbakhsh Amiri Golilarz</strong></p>
<p>Accurate classification of cancer-related medical abstracts is crucial for healthcare management and research. However, obtaining large, labeled datasets in the medical domain is challenging due to privacy concerns and the complexity of clinical data. This scarcity of annotated data impedes the development of effective machine learning models for cancer document classification. To address this challenge, we present a curated dataset of 1,874 biomedical abstracts, categorized into thyroid cancer, colon cancer, lung cancer, and generic topics. Our research focuses on leveraging this dataset to improve classification performance, particularly in data-scarce scenarios. We introduce a Residual Graph Attention Network (R-GAT) with multiple graph attention layers that capture the semantic information and structural relationships within cancer-related documents. Our R-GAT model is compared with various techniques, including transformer-based models such as Bidirectional Encoder Representations from Transformers (BERT), RoBERTa, and domain-specific models like BioBERT and Bio+ClinicalBERT. We also evaluated deep learning models (CNNs, LSTMs) and traditional machine learning models (Logistic Regression, SVM). Additionally, we explore ensemble approaches that combine deep learning models to enhance classification. Various feature extraction methods are assessed, including Term Frequency-Inverse Document Frequency (TF-IDF) with unigrams and bigrams, Word2Vec, and tokenizers from BERT and RoBERTa. The R-GAT model outperforms other techniques, achieving precision, recall, and F1 scores of 0.99, 0.97, and 0.98 for thyroid cancer; 0.96, 0.94, and 0.95 for colon cancer; 0.96, 0.99, and 0.97 for lung cancer; and 0.95, 0.96, and 0.95 for generic topics. </p>
<blockquote>
<p>ç™Œç—‡ç›¸å…³åŒ»å­¦æ‘˜è¦çš„ç²¾ç¡®åˆ†ç±»å¯¹åŒ»ç–—ç®¡ç†å’Œç ”ç©¶è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºéšç§é—®é¢˜å’Œä¸´åºŠæ•°æ®çš„å¤æ‚æ€§ï¼Œåœ¨åŒ»å­¦é¢†åŸŸè·å¾—å¤§é‡æœ‰æ ‡ç­¾çš„æ•°æ®é›†å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™ç§ç¼ºä¹æ ‡æ³¨æ•°æ®çš„æƒ…å†µé˜»ç¢äº†é’ˆå¯¹ç™Œç—‡æ–‡æ¡£åˆ†ç±»çš„æœ‰æ•ˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„å‘å±•ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç²¾é€‰çš„æ•°æ®é›†ï¼ŒåŒ…å«1874ç¯‡ç”Ÿç‰©åŒ»å­¦æ‘˜è¦ï¼Œåˆ†ä¸ºç”²çŠ¶è…ºç™Œã€ç»“è‚ ç™Œã€è‚ºç™Œå’Œé€šç”¨ä¸»é¢˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶é‡ç‚¹æ˜¯åˆ©ç”¨æ­¤æ•°æ®é›†æ¥æé«˜åˆ†ç±»æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¸¦æœ‰å¤šä¸ªå›¾æ³¨æ„åŠ›å±‚çš„æ®‹å·®å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆR-GATï¼‰ï¼Œèƒ½å¤Ÿæ•æ‰ç™Œç—‡ç›¸å…³æ–‡æ¡£ä¸­çš„è¯­ä¹‰ä¿¡æ¯å’Œç»“æ„å…³ç³»ã€‚æˆ‘ä»¬å°†R-GATæ¨¡å‹ä¸å„ç§æŠ€æœ¯è¿›è¡Œäº†æ¯”è¾ƒï¼ŒåŒ…æ‹¬åŸºäºå˜å‹å™¨çš„æ¨¡å‹ï¼Œå¦‚æ¥è‡ªå˜å‹å™¨çš„åŒå‘ç¼–ç å™¨è¡¨ç¤ºï¼ˆBERTï¼‰ã€RoBERTaï¼Œä»¥åŠç‰¹å®šäºé¢†åŸŸçš„æ¨¡å‹ï¼Œå¦‚BioBERTå’ŒBio+ClinicalBERTã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆCNNã€LSTMï¼‰å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆé€»è¾‘å›å½’ã€SVMï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢äº†ç»“åˆæ·±åº¦å­¦ä¹ æ¨¡å‹çš„é›†æˆæ–¹æ³•ï¼Œä»¥æé«˜åˆ†ç±»æ•ˆæœã€‚è¿˜è¯„ä¼°äº†å„ç§ç‰¹å¾æå–æ–¹æ³•ï¼ŒåŒ…æ‹¬ä½¿ç”¨ä¸€å…ƒè¯å’ŒäºŒå…ƒè¯çš„è¯é¢‘-é€†æ–‡æ¡£é¢‘ç‡ï¼ˆTF-IDFï¼‰ã€Word2Vecä»¥åŠæ¥è‡ªBERTå’ŒRoBERTaçš„æ ‡è®°å™¨ã€‚R-GATæ¨¡å‹çš„æ€§èƒ½ä¼˜äºå…¶ä»–æŠ€æœ¯ï¼Œåœ¨ç”²çŠ¶è…ºç™Œæ–¹é¢è¾¾åˆ°0.99çš„ç²¾ç¡®åº¦ã€0.97çš„å¬å›ç‡å’Œ0.98çš„F1åˆ†æ•°ï¼›ç»“è‚ ç™Œæ–¹é¢è¾¾åˆ°0.96ã€0.94å’Œ0.95ï¼›è‚ºç™Œæ–¹é¢è¾¾åˆ°0.96ã€0.99å’Œ0.97ï¼›é€šç”¨ä¸»é¢˜æ–¹é¢è¾¾åˆ°0.95ã€0.96å’Œ0.95ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.15198v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªé’ˆå¯¹ç™Œç—‡ç›¸å…³åŒ»å­¦æ‘˜è¦åˆ†ç±»çš„éš¾é¢˜ï¼Œå› ç¼ºä¹å¤§é‡æ ‡æ³¨æ•°æ®å¯¼è‡´å¼€å‘æœ‰æ•ˆçš„æœºå™¨å­¦ä¹ æ¨¡å‹å˜å¾—å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶è€…ä»¬æ¨å‡ºäº†ä¸€ä¸ªåŒ…å«ç”²çŠ¶è…ºç™Œã€ç»“è‚ ç™Œã€è‚ºç™Œä»¥åŠé€šç”¨ä¸»é¢˜çš„ç”Ÿç‰©åŒ»å­¦æ‘˜è¦æ•°æ®é›†ã€‚åŒæ—¶ï¼Œç ”ç©¶è¿˜èšç„¦äºä½¿ç”¨æ®‹å·®å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆR-GATï¼‰æ”¹å–„åˆ†ç±»æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ã€‚R-GATæ¨¡å‹é€šè¿‡å¤šå±‚å›¾æ³¨æ„åŠ›æœºåˆ¶æ•æ‰æ–‡æ¡£ä¸­çš„è¯­ä¹‰ä¿¡æ¯å’Œç»“æ„å…³ç³»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒR-GATæ¨¡å‹ç›¸è¾ƒäºå…¶ä»–æŠ€æœ¯è¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬BERTç­‰transformeræ¨¡å‹ã€æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆCNNå’ŒLSTMï¼‰ã€ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆé€»è¾‘å›å½’å’ŒSVMï¼‰ï¼Œä»¥åŠé›†æˆæ–¹æ³•å’Œç‰¹å¾æå–æ–¹æ³•ï¼ˆå¦‚TF-IDFã€Word2Vecç­‰ï¼‰ã€‚ç‰¹åˆ«æ˜¯åœ¨ç”²çŠ¶è…ºã€ç»“è‚ å’Œè‚ºç™Œçš„åˆ†ç±»ä¸Šï¼ŒR-GATæ¨¡å‹çš„ç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°å‡è¾¾åˆ°é«˜æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç™Œç—‡ç›¸å…³åŒ»å­¦æ‘˜è¦çš„å‡†ç¡®åˆ†ç±»å¯¹åŒ»ç–—ç®¡ç†å’Œç ”ç©¶è‡³å…³é‡è¦ã€‚</li>
<li>ç”±äºéšç§é—®é¢˜å’Œä¸´åºŠæ•°æ®çš„å¤æ‚æ€§ï¼Œè·å–å¤§è§„æ¨¡æ ‡æ³¨åŒ»å­¦æ•°æ®é›†å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>æ•°æ®ç¨€ç¼ºé™åˆ¶äº†æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨ç™Œç—‡æ–‡æ¡£åˆ†ç±»ä¸­çš„å‘å±•ã€‚</li>
<li>ç ”ç©¶äººå‘˜æ¨å‡ºåŒ…å«ç”²çŠ¶è…ºç™Œã€ç»“è‚ ç™Œå’Œè‚ºç™Œç­‰ä¸»é¢˜çš„ç”Ÿç‰©åŒ»å­¦æ‘˜è¦æ•°æ®é›†ã€‚</li>
<li>å¼•å…¥æ®‹å·®å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆR-GATï¼‰ä»¥æ”¹å–„åˆ†ç±»æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯æ•°æ®ç¨€ç¼ºçš„æƒ…å†µã€‚</li>
<li>R-GATæ¨¡å‹é€šè¿‡å¤šå±‚å›¾æ³¨æ„åŠ›æœºåˆ¶æ•æ‰æ–‡æ¡£ä¸­çš„è¯­ä¹‰ä¿¡æ¯å’Œç»“æ„å…³ç³»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.15198">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ba44946d3bcde06ab1e426a8cbcfaac6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1c8342d0ce23bf7ad2701d3429fd02f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1c71ebc35d947aa595878d43f1ffd10f.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Direct3Î³-A-Pipeline-for-Direct-Three-gamma-PET-Image-Reconstruction"><a href="#Direct3Î³-A-Pipeline-for-Direct-Three-gamma-PET-Image-Reconstruction" class="headerlink" title="Direct3Î³: A Pipeline for Direct Three-gamma PET Image   Reconstruction"></a>Direct3Î³: A Pipeline for Direct Three-gamma PET Image   Reconstruction</h2><p><strong>Authors:Youness Mellak, Alexandre Bousse, Thibaut Merlin, Debora Giovagnoli, Dimitris Visvikis</strong></p>
<p>This paper presents a novel image reconstruction pipeline for three-gamma (3-{\gamma}) positron emission tomography (PET) aimed at improving spatial resolution and reducing noise in nuclear medicine. The proposed Direct3{\gamma} pipeline addresses the inherent challenges in 3-{\gamma} PET systems, such as detector imperfections and uncertainty in photon interaction points. A key feature of the pipeline is its ability to determine the order of interactions through a model trained on Monte Carlo (MC) simulations using the Geant4 Application for Tomography Emission (GATE) toolkit, thus providing the necessary information to construct Compton cones which intersect with the line of response (LOR) to provide an estimate of the emission point. The pipeline processes 3-{\gamma} PET raw data, reconstructs histoimages by propagating energy and spatial uncertainties along the LOR, and applies a 3-D convolutional neural network (CNN) to refine these intermediate images into high-quality reconstructions. To further enhance image quality, the pipeline leverages both supervised learning and adversarial losses, with the latter preserving fine structural details. Experimental results demonstrate that Direct3{\gamma} consistently outperforms conventional 200-ps time-of-flight (TOF) PET in terms of SSIM and PSNR. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰å›¾åƒé‡å»ºçš„æ–°å‹æµç¨‹ï¼Œæ—¨åœ¨æé«˜æ ¸åŒ»å­¦ä¸­çš„ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½å™ªå£°ã€‚æ‰€æå‡ºçš„Direct3Î³æµç¨‹è§£å†³äº†å­˜åœ¨äºä¼ ç»ŸÎ³PETç³»ç»Ÿä¸­çš„å›ºæœ‰æŒ‘æˆ˜ï¼Œä¾‹å¦‚æ£€æµ‹å™¨çš„ä¸å®Œç¾å’Œå…‰å­ç›¸äº’ä½œç”¨ç‚¹çš„ä¸ç¡®å®šæ€§ã€‚è¯¥æµç¨‹çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§æ˜¯å…¶é€šè¿‡é‡‡ç”¨åŸºäºè’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿè®­ç»ƒçš„æ¨¡å‹ç¡®å®šç›¸äº’ä½œç”¨é¡ºåºçš„èƒ½åŠ›ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨GATEï¼ˆGeant4åº”ç”¨çš„å‘å°„æ–­å±‚æ‰«æï¼‰å·¥å…·åŒ…ã€‚å› æ­¤ï¼Œå®ƒèƒ½å¤Ÿæä¾›å¿…è¦ä¿¡æ¯æ¥æ„å»ºäº¤äºå“åº”çº¿ï¼ˆLORï¼‰çš„åº·æ™®é¡¿é”¥ï¼Œä»è€Œå¯¹å‘å°„ç‚¹è¿›è¡Œä¼°è®¡ã€‚è¯¥æµç¨‹å¤„ç†Î³PETåŸå§‹æ•°æ®ï¼Œé€šè¿‡æ²¿LORä¼ æ’­èƒ½é‡å’Œç©ºé—´ä¸ç¡®å®šæ€§é‡å»ºç›´æ–¹å›¾åƒï¼Œå¹¶ä½¿ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¯¹è¿™äº›ä¸­é—´å›¾åƒè¿›è¡Œç²¾ç»†åŒ–å¤„ç†ä»¥è·å¾—é«˜è´¨é‡é‡å»ºå›¾åƒã€‚ä¸ºäº†è¿›ä¸€æ­¥æ”¹å–„å›¾åƒè´¨é‡ï¼Œè¯¥æµç¨‹ç»“åˆäº†ç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—æ€§æŸå¤±ï¼Œåè€…ä¿ç•™äº†ç²¾ç»†ç»“æ„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„ä¼½ç›å…‰å­æˆåƒç³»ç»Ÿçš„æ•°ç™¾çš®ç§’é£è¡Œæ—¶é—´ï¼ˆTOFï¼‰PETç›¸æ¯”ï¼ŒDirectÎ³åœ¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ–¹é¢è¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.18337v4">PDF</a> 10 pages, 11 figures, 2 tables</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰å›¾åƒé‡å»ºçš„æ–°æµç¨‹ï¼Œæ—¨åœ¨æ”¹å–„æ ¸åŒ»å­¦ä¸­çš„ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½å™ªå£°ã€‚æ‰€æå‡ºDirect3Î³æµç¨‹è§£å†³äº†å¯¹ç”¨äºåŒ»å­¦å½±åƒçš„æ— è‰²è½½æœºåŒ–å­¦è¯„ä¼°å†…åœ¨æŒ‘æˆ˜é—®é¢˜ï¼Œæ¯”å¦‚æ£€æµ‹å™¨çš„ä¸å®Œå–„ä»¥åŠå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ã€‚è¯¥æµç¨‹çš„å…³é”®åŠŸèƒ½æ˜¯é€šè¿‡ä½¿ç”¨GATEå·¥å…·åŒ…è¿›è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å‹æ¥ç¡®å®šäº¤äº’çš„é¡ºåºï¼Œä»è€Œæ„å»ºäº¤äºçº¿æ€§å“åº”çº¿é”¥éƒ¨æ‰€éœ€çš„èµ„è®¯ç‚¹ä»¥å½¢æˆè®¡ç®—è·¯å¾„è¿›è¡Œå°„èƒ½æµ‹å®šå’Œé…åˆ†åƒå‘ˆç°é«˜å±‚æ¬¡çš„å‡†ç¡®æ€§ç»“æœå›¾åƒè´¨é‡è¾ƒé«˜é€šè¿‡å¯¹äºè¿™ç±»å½±å“æ¸…æ™°ç¨‹åº¦çš„å¤šç§çº¦æŸæ‰€åæ˜ çš„ç‰¹å¾è¿›è¡Œæ£€æµ‹æ¨¡æ‹Ÿæ ¸åˆ†æç›¸å…³ç‰¹æ®Šæ„ä¹‰çš„ç ”ç©¶æˆæœèƒ½å¤Ÿé€šè¿‡åŒæ—¶è§£å†³å†…éƒ¨å·®å¼‚å…³ç³»é€æ­¥åŒ–ä¸‰ç»´å¤æ‚è¿‡ç¨‹çš„ä¸ç¡®å®šæ€§é—®é¢˜ä¸ç©ºæ¨¡å‹ä¸è¿è´¯ä¹‹é—´çš„é—®é¢˜ï¼Œå®éªŒç»“æœè¡¨æ˜Direct3Î³åœ¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„åŸºäºé£è¡Œæ—¶é—´ï¼ˆTOFï¼‰çš„PETæˆåƒæŠ€æœ¯ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæœ¬æ–‡æä¾›äº†ä¸€ç§æ–°çš„å›¾åƒé‡å»ºæ–¹æ³•ï¼Œæœ‰åŠ©äºæé«˜PETæˆåƒçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰PETçš„æ–°å‹å›¾åƒé‡å»ºæµç¨‹ï¼Œæ—¨åœ¨æé«˜ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½å™ªå£°ã€‚</li>
<li>Direct3Î³æµç¨‹è§£å†³äº†æ£€æµ‹å™¨çš„ä¸å®Œå–„ä»¥åŠå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ç­‰å†…åœ¨æŒ‘æˆ˜é—®é¢˜ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå’ŒGATEå·¥å…·åŒ…ï¼Œèƒ½å¤Ÿç¡®å®šäº¤äº’çš„é¡ºåºï¼Œå¹¶æ„å»ºç”¨äºè®¡ç®—å‘å°„ç‚¹çš„è·¯å¾„ã€‚</li>
<li>é‡å»ºè¿‡ç¨‹æ¶‰åŠä»åŸå§‹çš„Triple Î³ PETæ•°æ®ä¸­è·å–æ•°æ®å¹¶è¿›è¡Œé‡å»ºå›¾åƒåŒ–è¡¨ç¤ºçš„è¿‡ç¨‹å¤„ç†æ“ä½œå¤„ç†å½±åƒç”Ÿæˆå½±åƒæ•ˆæœæ¨¡å‹æ¥å¾—åˆ°æœ€ç»ˆçš„æˆåƒç»“æœå›¾åƒé€šè¿‡å¯¹äºå½±å“æ¸…æ™°åº¦ç­‰å‚æ•°çš„è€ƒé‡è¯„ä¼°å…¶ä¼˜åŠ£ç¨‹åº¦ã€‚é€šè¿‡åˆ©ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¯¹ä¸­é—´å›¾åƒè¿›è¡Œç²¾ç»†åŒ–å¤„ç†ï¼Œæé«˜äº†å›¾åƒè´¨é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.18337">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cbdfe652485ee4a953892c5f872b36a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7791ae5b3ba79f5a50fe85192d64ebb2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ddb00c84237997a27f0f5af7359784ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8619f798cabe0e544740a0a5c636652b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d9a7730200c5e343e8e528e42110d3c.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-11/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-11/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-11/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-23ad0ad70d5d46832db0d11e5dfb6ea0.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-11  F5R-TTS Improving Flow-Matching based Text-to-Speech with Group   Relative Policy Optimization
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-11/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0fb5f65a18ed0b7bb4c4d47bfac9a4b1.jpg" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-11  nnLandmark A Self-Configuring Method for 3D Medical Landmark Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31086.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
