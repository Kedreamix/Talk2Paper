<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-05-08  Multi-Agent System for Comprehensive Soccer Understanding">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-245e2d5d70913e83da6eecd733b7086f.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    16.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    68 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-08-更新"><a href="#2025-05-08-更新" class="headerlink" title="2025-05-08 更新"></a>2025-05-08 更新</h1><h2 id="Multi-Agent-System-for-Comprehensive-Soccer-Understanding"><a href="#Multi-Agent-System-for-Comprehensive-Soccer-Understanding" class="headerlink" title="Multi-Agent System for Comprehensive Soccer Understanding"></a>Multi-Agent System for Comprehensive Soccer Understanding</h2><p><strong>Authors:Jiayuan Rao, Zifeng Li, Haoning Wu, Ya Zhang, Yanfeng Wang, Weidi Xie</strong></p>
<p>Recent advancements in AI-driven soccer understanding have demonstrated rapid progress, yet existing research predominantly focuses on isolated or narrow tasks. To bridge this gap, we propose a comprehensive framework for holistic soccer understanding. Specifically, we make the following contributions in this paper: (i) we construct SoccerWiki, the first large-scale multimodal soccer knowledge base, integrating rich domain knowledge about players, teams, referees, and venues to enable knowledge-driven reasoning; (ii) we present SoccerBench, the largest and most comprehensive soccer-specific benchmark, featuring around 10K standardized multimodal (text, image, video) multi-choice QA pairs across 13 distinct understanding tasks, curated through automated pipelines and manual verification; (iii) we introduce SoccerAgent, a novel multi-agent system that decomposes complex soccer questions via collaborative reasoning, leveraging domain expertise from SoccerWiki and achieving robust performance; (iv) extensive evaluations and ablations that benchmark state-of-the-art MLLMs on SoccerBench, highlighting the superiority of our proposed agentic system. All data and code are publicly available at: <a target="_blank" rel="noopener" href="https://jyrao.github.io/SoccerAgent/">https://jyrao.github.io/SoccerAgent/</a>. </p>
<blockquote>
<p>关于人工智能驱动的足球理解方面的最新进展已经显示出快速发展，但现有研究主要集中在孤立或狭窄的任务上。为了弥补这一差距，我们提出了一个全面的足球理解框架。具体来说，我们在本文中做出了以下贡献：（i）我们构建了SoccerWiki，这是一个首个大规模的多模式足球知识库，集成了关于球员、球队、裁判和场馆的丰富领域知识，以实现知识驱动推理；（ii）我们展示了SoccerBench，这是一个最大和最全面的足球专项基准测试平台，拥有约1万个标准化的多模式（文本、图像、视频）多选择题对，涵盖13个不同的理解任务，通过自动化管道和人工验证进行筛选；（iii）我们介绍了SoccerAgent，这是一个新型的多智能体系统，它通过协作推理分解复杂的足球问题，利用SoccerWiki的专业知识，实现了稳健的性能；（iv）我们在SoccerBench上进行了广泛评估和消除实验，以评估最先进的MLLMs的表现，凸显了我们提出的智能系统的优越性。所有数据代码均可公开访问：<a target="_blank" rel="noopener" href="https://jyrao.github.io/SoccerAgent/%E3%80%82">https://jyrao.github.io/SoccerAgent/。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03735v1">PDF</a> Technical Report; Project Page: <a target="_blank" rel="noopener" href="https://jyrao.github.io/SoccerAgent/">https://jyrao.github.io/SoccerAgent/</a></p>
<p><strong>Summary</strong><br>本文介绍了在足球理解方面的最新进展，并提出了一种全面的框架来实现在这个领域的整体理解。主要贡献包括构建了一个大型的多模式足球知识库SoccerWiki，推出了最大的足球专项基准测试SoccerBench，以及引入了一种新的多智能体系统SoccerAgent。该系统通过协作推理分解复杂问题，利用SoccerWiki中的领域专业知识实现稳健性能。所有数据和代码均已公开。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>构建了一个大型多模式足球知识库SoccerWiki，整合球员、球队、裁判和场馆等领域的丰富知识，实现知识驱动推理。</li>
<li>推出了最大的足球专项基准测试SoccerBench，包含约1万标准多模式（文本、图像、视频）多选问答对，涉及13个不同的理解任务。</li>
<li>通过自动化管道和人工验证来收集和组织这些数据。</li>
<li>引入了一种新的多智能体系统SoccerAgent，通过协作推理分解复杂问题，利用SoccerWiki的领域专业知识实现稳健性能。</li>
<li>提供了广泛评估和消融研究，评估了最前沿的MLLM在SoccerBench上的表现。</li>
<li>所有数据和代码均已公开可用。</li>
<li>强调了在足球理解方面需要更全面和整合的研究方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03735">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9c3c0b932a77e72862a69d6939c21393.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97d0e68f3dee37fd810e2abf649643c2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8c4a92e86acb5e0bc2f4301b97909533.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92993ddfab5d6f1945aa9847b968734b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="RoboOS-A-Hierarchical-Embodied-Framework-for-Cross-Embodiment-and-Multi-Agent-Collaboration"><a href="#RoboOS-A-Hierarchical-Embodied-Framework-for-Cross-Embodiment-and-Multi-Agent-Collaboration" class="headerlink" title="RoboOS: A Hierarchical Embodied Framework for Cross-Embodiment and   Multi-Agent Collaboration"></a>RoboOS: A Hierarchical Embodied Framework for Cross-Embodiment and   Multi-Agent Collaboration</h2><p><strong>Authors:Huajie Tan, Xiaoshuai Hao, Minglan Lin, Pengwei Wang, Yaoxu Lyu, Mingyu Cao, Zhongyuan Wang, Shanghang Zhang</strong></p>
<p>The dawn of embodied intelligence has ushered in an unprecedented imperative for resilient, cognition-enabled multi-agent collaboration across next-generation ecosystems, revolutionizing paradigms in autonomous manufacturing, adaptive service robotics, and cyber-physical production architectures. However, current robotic systems face significant limitations, such as limited cross-embodiment adaptability, inefficient task scheduling, and insufficient dynamic error correction. While End-to-end VLA models demonstrate inadequate long-horizon planning and task generalization, hierarchical VLA models suffer from a lack of cross-embodiment and multi-agent coordination capabilities. To address these challenges, we introduce RoboOS, the first open-source embodied system built on a Brain-Cerebellum hierarchical architecture, enabling a paradigm shift from single-agent to multi-agent intelligence. Specifically, RoboOS consists of three key components: (1) Embodied Brain Model (RoboBrain), a MLLM designed for global perception and high-level decision-making; (2) Cerebellum Skill Library, a modular, plug-and-play toolkit that facilitates seamless execution of multiple skills; and (3) Real-Time Shared Memory, a spatiotemporal synchronization mechanism for coordinating multi-agent states. By integrating hierarchical information flow, RoboOS bridges Embodied Brain and Cerebellum Skill Library, facilitating robust planning, scheduling, and error correction for long-horizon tasks, while ensuring efficient multi-agent collaboration through Real-Time Shared Memory. Furthermore, we enhance edge-cloud communication and cloud-based distributed inference to facilitate high-frequency interactions and enable scalable deployment. Extensive real-world experiments across various scenarios, demonstrate RoboOS’s versatility in supporting heterogeneous embodiments. Project website: <a target="_blank" rel="noopener" href="https://github.com/FlagOpen/RoboOS">https://github.com/FlagOpen/RoboOS</a> </p>
<blockquote>
<p>智能实体的黎明带来了在下一代生态系统中实现具有弹性的认知赋能多智能体协作的迫切需求，从而彻底改变了自主制造、自适应服务机器人和网实融合生产架构的范式。然而，当前机器人系统面临诸多局限性，如跨智能体的适应性有限、任务调度效率低下以及动态纠错不足等。端到端VLA模型显示出缺乏长远规划和任务泛化能力，而分层VLA模型则缺乏跨智能体和多智能体协作能力。为了解决这些挑战，我们推出了RoboOS，这是一个基于大脑-小脑分层架构的首个开源智能系统，能够实现从单智能体到多智能体范式的转变。具体来说，RoboOS包含三个关键组成部分：（1）智能体大脑模型（RoboBrain），这是一个用于全局感知和高级决策制定的MLLM；（2）小脑技能库，这是一个模块化、可插拔的工具包，可实现无缝执行多种技能；（3）实时共享内存，这是一种时空同步机制，用于协调多智能体的状态。通过整合分层信息流，RoboOS将智能体大脑和小脑技能库连接起来，促进了长期任务的稳健规划、调度和纠错，同时通过实时共享内存确保高效的多智能体协作。此外，我们增强了边缘云通信和基于云的分布式推理，以促进高频交互并实现可扩展部署。在多种场景下的真实世界实验广泛证明了RoboOS在支持异构智能体方面的通用性。项目网站：<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/RoboOS">https://github.com/FlagOpen/RoboOS</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03673v1">PDF</a> 22 pages, 10 figures</p>
<p><strong>Summary</strong><br>     体化智能的崛起为下一代生态系统中的认知赋能多智能体协作带来了前所未有的紧迫需求，革新了自主制造、自适应服务机器人和物理网络生产架构的模式。当前机器人系统面临跨体态适应性差等限制，RoboOS基于大脑小脑层次架构打造首个开源体系，实现单智能体向多智能体智能的转变。其核心组件包括体感大脑模型、小脑技能库和实时共享内存，可无缝执行多任务并确保多智能体协调。同时，增强边缘云计算和云端分布式推理可实现高频互动并支持可扩展部署。大量真实场景实验证明RoboOS在支持不同形态智能体的通用性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>体化智能对下一代生态系统中的多智能体协作提出新要求。</li>
<li>当前机器人系统存在跨体态适应性、任务调度和动态纠错不足的问题。</li>
<li>RoboOS体系基于大脑小脑层次架构，实现多智能体智能协同。</li>
<li>RoboOS包括体感大脑模型、小脑技能库和实时共享内存三大核心组件。</li>
<li>实时共享内存确保多智能体的时空同步协调。</li>
<li>增强边缘云计算和云端分布式推理支持高频互动和可扩展部署。</li>
<li>大量真实场景实验证明RoboOS的通用性和有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03673">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-b8284414a18786db7e0038faed37355f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4d1b85365b084e29a8fb07b999615b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e8546bc76251f44a87a6ea9e1578e29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-710d8e373f9189923d4597667e65900d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="LlamaFirewall-An-open-source-guardrail-system-for-building-secure-AI-agents"><a href="#LlamaFirewall-An-open-source-guardrail-system-for-building-secure-AI-agents" class="headerlink" title="LlamaFirewall: An open source guardrail system for building secure AI   agents"></a>LlamaFirewall: An open source guardrail system for building secure AI   agents</h2><p><strong>Authors:Sahana Chennabasappa, Cyrus Nikolaidis, Daniel Song, David Molnar, Stephanie Ding, Shengye Wan, Spencer Whitman, Lauren Deason, Nicholas Doucette, Abraham Montilla, Alekhya Gampa, Beto de Paola, Dominik Gabi, James Crnkovich, Jean-Christophe Testud, Kat He, Rashnil Chaturvedi, Wu Zhou, Joshua Saxe</strong></p>
<p>Large language models (LLMs) have evolved from simple chatbots into autonomous agents capable of performing complex tasks such as editing production code, orchestrating workflows, and taking higher-stakes actions based on untrusted inputs like webpages and emails. These capabilities introduce new security risks that existing security measures, such as model fine-tuning or chatbot-focused guardrails, do not fully address. Given the higher stakes and the absence of deterministic solutions to mitigate these risks, there is a critical need for a real-time guardrail monitor to serve as a final layer of defense, and support system level, use case specific safety policy definition and enforcement. We introduce LlamaFirewall, an open-source security focused guardrail framework designed to serve as a final layer of defense against security risks associated with AI Agents. Our framework mitigates risks such as prompt injection, agent misalignment, and insecure code risks through three powerful guardrails: PromptGuard 2, a universal jailbreak detector that demonstrates clear state of the art performance; Agent Alignment Checks, a chain-of-thought auditor that inspects agent reasoning for prompt injection and goal misalignment, which, while still experimental, shows stronger efficacy at preventing indirect injections in general scenarios than previously proposed approaches; and CodeShield, an online static analysis engine that is both fast and extensible, aimed at preventing the generation of insecure or dangerous code by coding agents. Additionally, we include easy-to-use customizable scanners that make it possible for any developer who can write a regular expression or an LLM prompt to quickly update an agent’s security guardrails. </p>
<blockquote>
<p>大型语言模型（LLM）已经从简单的聊天机器人进化成能够执行复杂任务的自主代理，例如编辑生产代码、协调工作流程和根据不可信的输入（如网页和电子邮件）采取更高风险的行动。这些功能引入了新的安全风险，而现有的安全措施（如模型微调或针对聊天机器人的护栏）并不能完全解决这些问题。考虑到风险较高且没有确定的解决方案来减轻这些风险，急需一种实时护栏监控器作为最后一层防御，并支持系统级别、针对用例的安全策略定义和强制执行。我们推出了LlamaFirewall，这是一个开源的安全护栏框架，旨在作为对抗与AI代理相关的安全风险的最后防线。我们的框架通过三个强大的护栏来减轻风险：PromptGuard 2，一种通用越狱探测器，展示了卓越的性能；Agent Alignment Checks，一种思维链审计员，检查代理推理是否存在提示注入和目标错位，虽然在实验阶段，但在一般场景中防止间接注入方面显示出比以前提出的方法更强的效果；以及CodeShield，一个快速且可扩展的在线静态分析引擎，旨在防止编码代理生成不安全或危险的代码。此外，我们还包含了易于使用可定制化的扫描器，使得任何能够编写正则表达式或LLM提示的开发者都能快速更新代理的安全护栏。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03574v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>大型语言模型（LLMs）已从简单的聊天机器人进化为能够执行复杂任务的自主代理，如编辑生产代码、协调工作流程和基于不可信的输入（如网页和电子邮件）采取高风险行动。这些能力带来了新的安全风险，现有的安全措施（如模型微调或针对聊天机器人的护栏）并不能完全解决这些问题。鉴于风险较高且没有确定的解决方案来减轻这些风险，急需一种实时护栏监控器作为最后一层防御，并支持系统级别的安全策略定义和执行。本文介绍了LlamaFirewall，这是一个专注于安全的护栏框架，旨在作为对抗与AI代理相关的安全风险的最后防线。我们的框架通过三大强力护栏来减轻风险，包括PromptGuard 2（一种具有先进性能的通用越权检测器）、Agent Alignment Checks（一种检查代理推理是否存在提示注入和目标偏离的链式思维审计员，虽然在预防间接注入方面仍属实验性，但在一般场景中的功效强于以前提出的方法），以及CodeShield（一种快速且可扩展的在线静态分析引擎，旨在防止编码代理生成不安全或危险的代码）。此外，我们还包括易于使用的可定制扫描器，使得任何能够编写正则表达式或LLM提示的开发者都能快速更新代理的安全护栏。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>大型语言模型（LLMs）已进化为具备复杂任务执行能力的自主代理，引入新的安全风险。</li>
<li>现有安全措施无法完全解决这些新风险，需要更强大的防御措施。</li>
<li>LlamaFirewall作为一种专注于安全的护栏框架被引入，作为对抗与AI代理相关的安全风险的最后防线。</li>
<li>LlamaFirewall包含三大强力护栏：PromptGuard 2、Agent Alignment Checks和CodeShield，分别用于检测越权行为、审计代理推理和防止生成危险代码。</li>
<li>LlamaFirewall提供易于使用的可定制扫描器，方便开发者快速更新代理的安全护栏。</li>
<li>该框架旨在支持系统级别的安全策略定义和执行。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03574">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e1dc39404c4e8a720c267f5458f44985.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-156c7718dce7387712e4f14c983cbbf0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a195dd7c7d2f6ddc6d07c7e9c1ce9550.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d67a66ce9ca5da3ff6a46d14bb38015c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="OSUniverse-Benchmark-for-Multimodal-GUI-navigation-AI-Agents"><a href="#OSUniverse-Benchmark-for-Multimodal-GUI-navigation-AI-Agents" class="headerlink" title="OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents"></a>OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents</h2><p><strong>Authors:Mariya Davydova, Daniel Jeffries, Patrick Barker, Arturo Márquez Flores, Sinéad Ryan</strong></p>
<p>In this paper, we introduce OSUniverse: a benchmark of complex, multimodal desktop-oriented tasks for advanced GUI-navigation AI agents that focuses on ease of use, extensibility, comprehensive coverage of test cases, and automated validation. We divide the tasks in increasing levels of complexity, from basic precision clicking to multistep, multiapplication tests requiring dexterity, precision, and clear thinking from the agent. In version one of the benchmark, presented here, we have calibrated the complexity of the benchmark test cases to ensure that the SOTA (State of the Art) agents (at the time of publication) do not achieve results higher than 50%, while the average white collar worker can perform all these tasks with perfect accuracy. The benchmark can be scored manually, but we also introduce an automated validation mechanism that has an average error rate less than 2%. Therefore, this benchmark presents solid ground for fully automated measuring of progress, capabilities and the effectiveness of GUI-navigation AI agents over the short and medium-term horizon. The source code of the benchmark is available at <a target="_blank" rel="noopener" href="https://github.com/agentsea/osuniverse">https://github.com/agentsea/osuniverse</a>. </p>
<blockquote>
<p>本文介绍了OSUniverse：这是一个面向高级GUI导航AI代理的复杂、多模式桌面任务基准测试，它侧重于易用性、可扩展性、测试用例的全面覆盖和自动化验证。我们将任务按复杂性递增进行划分，从基本精确点击到需要敏捷性、精确性和思维清晰的多步骤、多应用测试。在此处呈现的第一版基准测试中，我们已经校准了测试用例的复杂性，以确保当时的最先进代理的结果不会高于50%，而普通白领工人可以完全准确地完成所有任务。该基准测试可以手动评分，但我们也引入了一种自动化验证机制，其平均错误率低于2%。因此，这个基准测试为在短期内和中期内全自动衡量GUI导航AI代理的进步、能力和效果提供了坚实的基础。该基准测试的源代码可在<a target="_blank" rel="noopener" href="https://github.com/agentsea/osuniverse">https://github.com/agentsea/osuniverse</a>上找到。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03570v1">PDF</a> </p>
<p><strong>Summary</strong><br>OSUniverse是一个面向复杂、多模式桌面任务的基准测试，旨在评估先进GUI导航AI代理的性能。它强调易用性、可扩展性、全面覆盖测试用例和自动化验证。任务按难度递增设计，从基本精确点击到需要灵活性和精准思考的多步骤多应用测试。版本一确保现有技术前沿的人工智能无法达到很高的分数率。该基准测试既可手动评分，也提供平均误差率低于百分之二的自动化验证机制。这为短期内全面评估AI代理的进步提供了坚实基础。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OSUniverse是一个评估GUI导航AI性能的基准测试。</li>
<li>它包含从简单到复杂的多种桌面任务。</li>
<li>版本一的测试案例难度适中，现有顶尖AI代理无法取得高分数率。</li>
<li>基准测试强调易用性、可扩展性、全面覆盖测试用例和自动化验证。</li>
<li>提供手动和自动化评分机制，其中自动化验证机制误差率低。</li>
<li>该基准测试为短期内评估AI代理的进步提供了可靠依据。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03570">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ab87d1d96d728c677d011baf1083e2bc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-75794b20fd351664219b872dcf3ca329.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afb6a47b4163d690dfc1f5d7117e2eb6.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Reinforcement-Learning-Scheduling-to-Support-Low-Latency-in-Teleoperated-Driving"><a href="#Multi-Agent-Reinforcement-Learning-Scheduling-to-Support-Low-Latency-in-Teleoperated-Driving" class="headerlink" title="Multi-Agent Reinforcement Learning Scheduling to Support Low Latency in   Teleoperated Driving"></a>Multi-Agent Reinforcement Learning Scheduling to Support Low Latency in   Teleoperated Driving</h2><p><strong>Authors:Giacomo Avanzi, Marco Giordani, Michele Zorzi</strong></p>
<p>The teleoperated driving (TD) scenario comes with stringent Quality of Service (QoS) communication constraints, especially in terms of end-to-end (E2E) latency and reliability. In this context, Predictive Quality of Service (PQoS), possibly combined with Reinforcement Learning (RL) techniques, is a powerful tool to estimate QoS degradation and react accordingly. For example, an intelligent agent can be trained to select the optimal compression configuration for automotive data, and reduce the file size whenever QoS conditions deteriorate. However, compression may inevitably compromise data quality, with negative implications for the TD application. An alternative strategy involves operating at the Radio Access Network (RAN) level to optimize radio parameters based on current network conditions, while preserving data quality. In this paper, we propose Multi-Agent Reinforcement Learning (MARL) scheduling algorithms, based on Proximal Policy Optimization (PPO), to dynamically and intelligently allocate radio resources to minimize E2E latency in a TD scenario. We evaluate two training paradigms, i.e., decentralized learning with local observations (IPPO) vs. centralized aggregation (MAPPO), in conjunction with two resource allocation strategies, i.e., proportional allocation (PA) and greedy allocation (GA). We prove via ns-3 simulations that MAPPO, combined with GA, achieves the best results in terms of latency, especially as the number of vehicles increases. </p>
<blockquote>
<p>远程驾驶（TD）场景伴随着严格的Quality of Service（QoS）通信约束，特别是在端到端（E2E）延迟和可靠性方面。在这种情况下，预测性服务质量（PQoS）可能是结合强化学习（RL）技术的一个强大工具，可以估算QoS退化并作出相应的反应。例如，可以训练智能代理来选择汽车数据的最佳压缩配置，并在QoS条件恶化时减小文件大小。然而，压缩不可避免地可能损害数据质量，对TD应用程序产生负面影响。另一种策略涉及在无线电接入网络（RAN）级别操作，根据当前网络条件优化无线电参数，同时保留数据质量。在本文中，我们提出基于近端策略优化（PPO）的多智能体强化学习（MARL）调度算法，以动态智能地分配无线电资源，以最小化TD场景中的端到端延迟。我们评估了两种训练范式，即具有局部观察的分散学习（IPPO）与集中式聚合（MAPPO），以及与两种资源分配策略相结合，即比例分配（PA）和贪婪分配（GA）。我们通过ns-3模拟证明，MAPPO与GA相结合在延迟方面取得了最佳效果，尤其是车辆数量增加时。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03558v1">PDF</a> 8 pages, 6 figures, 1 table. This paper has been accepted for   publication in the 2025 IEEE Vehicular Networking Conference (VNC)</p>
<p><strong>Summary</strong></p>
<p>本文探讨了自动驾驶中的服务质量（QoS）问题，特别是在端到端（E2E）延迟和可靠性方面的挑战。为应对这些问题，提出了预测性服务质量（PQoS）结合强化学习（RL）技术的解决方案。通过多智能体强化学习（MARL）调度算法和基于近端策略优化（PPO）的方法，动态智能分配无线电资源以减少端到端延迟。通过ns-3模拟评估了两种训练模式和两种资源分配策略的效果，发现集中聚合（MAPPO）结合贪婪分配（GA）在车辆数量增加时延迟最低。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>在自动驾驶场景中，端到端延迟和服务质量可靠性是关键的通信约束。</li>
<li>预测性服务质量（PQoS）结合强化学习用于估计QoS 退化并相应调整。</li>
<li>通过智能代理进行训练，可以选择汽车数据的最佳压缩配置来减少文件大小，在QoS 条件恶化时尤为重要。</li>
<li>无线接入网络层面的优化可基于当前网络条件调整无线电参数并保持数据质量。</li>
<li>提出基于近端策略优化（PPO）的多智能体强化学习（MARL）调度算法，用于动态智能分配无线电资源。</li>
<li>通过模拟评估了两种训练模式和两种资源分配策略的效果，发现MAPPO与GA结合在减少延迟方面表现最佳。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03558">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-8a152fedf445533983868b7aa61ddd90.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-da745920655c8ca3070ed23446257cc6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c9379f0ed77b91c36e5a0353f3aca61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76910bcfb6c77c08b85f0a65c14f441c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Procedural-Memory-Is-Not-All-You-Need-Bridging-Cognitive-Gaps-in-LLM-Based-Agents"><a href="#Procedural-Memory-Is-Not-All-You-Need-Bridging-Cognitive-Gaps-in-LLM-Based-Agents" class="headerlink" title="Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in   LLM-Based Agents"></a>Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in   LLM-Based Agents</h2><p><strong>Authors:Schaun Wheeler, Olivier Jeunen</strong></p>
<p>Large Language Models (LLMs) represent a landmark achievement in Artificial Intelligence (AI), demonstrating unprecedented proficiency in procedural tasks such as text generation, code completion, and conversational coherence. These capabilities stem from their architecture, which mirrors human procedural memory – the brain’s ability to automate repetitive, pattern-driven tasks through practice. However, as LLMs are increasingly deployed in real-world applications, it becomes impossible to ignore their limitations operating in complex, unpredictable environments. This paper argues that LLMs, while transformative, are fundamentally constrained by their reliance on procedural memory. To create agents capable of navigating &#96;&#96;wicked’’ learning environments – where rules shift, feedback is ambiguous, and novelty is the norm – we must augment LLMs with semantic memory and associative learning systems. By adopting a modular architecture that decouples these cognitive functions, we can bridge the gap between narrow procedural expertise and the adaptive intelligence required for real-world problem-solving. </p>
<blockquote>
<p>大型语言模型（LLM）是人工智能（AI）领域的一项标志性成就，展现出前所未有的程序性任务熟练度，如文本生成、代码补全和对话连贯性。这些能力来源于其架构，该架构模仿人类的程序性记忆——大脑通过实践自动执行重复性、模式驱动任务的能力。然而，随着LLM在现实世界应用中的不断部署，它们面临在复杂、不可预测环境中运作的局限性，这使得我们难以忽视。本文认为，尽管LLM具有变革性，但它们从根本上受到对程序性记忆的依赖的限制。为了创建能够在“邪恶”学习环境中导航的代理——规则不断变化、反馈模糊、新颖性是常态——我们必须通过语义记忆和关联学习系统来增强LLM的功能。通过采用模块化架构，将这些认知功能解耦，我们可以缩小狭窄的程序专长与解决现实世界问题所需的适应性智能之间的差距。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03434v1">PDF</a> Accepted to the workshop on Hybrid AI for Human-Centric   Personalization (HyPer), co-located with ACM UMAP ‘25</p>
<p><strong>总结</strong></p>
<p>大型语言模型（LLM）在人工智能领域取得了里程碑式的成就，展现了前所未有的程序性任务熟练度，如文本生成、代码补全和对话连贯性。其能力源于其架构，该架构模仿人类的程序性记忆——大脑通过实践自动执行重复性、模式驱动任务的能力。然而，随着LLM在现实应用中的部署增加，它们在复杂、不可预测环境中运作的局限性不容忽视。本文认为，尽管LLM具有变革性，但它们从根本上受到程序性记忆的制约。为了创建能够在“邪恶”学习环境中导航的代理——规则变化、反馈模糊、新颖性常态——我们必须用语义记忆和关联性学习系统增强LLM。通过采用模块化架构，解耦这些认知功能，我们可以弥合狭窄的程序性专长与解决现实世界问题所需的适应性智力之间的差距。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>大型语言模型（LLM）在人工智能领域具有里程碑式的意义，擅长程序性任务，如文本生成和对话连贯性。</li>
<li>LLM的能力源于其模仿人类程序性记忆的架构。</li>
<li>LLM在现实应用中的部署凸显了其在复杂、不可预测环境中的局限性。</li>
<li>LLM受到程序性记忆的制约，无法完全适应变化的环境。</li>
<li>为了创建能在复杂环境中导航的代理，需要增强LLM的语义记忆和关联性学习系统。</li>
<li>通过模块化架构解耦认知功能，可以弥合狭窄的程序性专长与适应性智力之间的差距。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03434">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6393b53875b39101708902639c0c225a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Deep-Reinforcement-Learning-for-Zonal-Ancillary-Market-Coupling"><a href="#Multi-Agent-Deep-Reinforcement-Learning-for-Zonal-Ancillary-Market-Coupling" class="headerlink" title="Multi-Agent Deep Reinforcement Learning for Zonal Ancillary Market   Coupling"></a>Multi-Agent Deep Reinforcement Learning for Zonal Ancillary Market   Coupling</h2><p><strong>Authors:Francesco Morri, Hélène Le Cadre, Pierre Gruet, Luce Brotcorne</strong></p>
<p>We characterize zonal ancillary market coupling relying on noncooperative game theory. To that purpose, we formulate the ancillary market as a multi-leader single follower bilevel problem, that we subsequently cast as a generalized Nash game with side constraints and nonconvex feasibility sets. We determine conditions for equilibrium existence and show that the game has a generalized potential game structure. To compute market equilibrium, we rely on two exact approaches: an integrated optimization approach and Gauss-Seidel best-response, that we compare against multi-agent deep reinforcement learning. On real data from Germany and Austria, simulations indicate that multi-agent deep reinforcement learning achieves the smallest convergence rate but requires pretraining, while best-response is the slowest. On the economics side, multi-agent deep reinforcement learning results in smaller market costs compared to the exact methods, but at the cost of higher variability in the profit allocation among stakeholders. Further, stronger coupling between zones tends to reduce costs for larger zones. </p>
<blockquote>
<p>我们利用非合作博弈理论描述了区域辅助市场耦合的特性。为此，我们将辅助市场制定为一个多领导单一跟随者的双层问题，随后将其转化为带有侧约束和非凸可行集的广义纳什博弈。我们确定了均衡存在的条件，并证明该博弈具有广义势能博弈结构。为了计算市场均衡，我们依赖两种精确方法：一种整体优化方法和高斯-赛德尔最佳反应法，我们将这些方法与多智能体深度强化学习进行了比较。在来自德国和奥地利的真实数据进行的模拟表明，多智能体深度强化学习具有最小的收敛速率，但需要预先训练，而最佳反应法最慢。在经济方面，与精确方法相比，多智能体深度强化学习导致较小的市场成本，但代价是利益相关者之间的利润分配波动性更高。此外，区域之间的更强耦合往往有助于降低大区域的成本。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03288v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于非合作博弈理论，本文描述了区域辅助市场耦合的特点。为达到此目的，本文将辅助市场制定为多领导者单跟随者的双层问题，随后将其转化为带有侧约束和非凸可行集的广义纳什博弈。本文确定了均衡存在的条件，并展示了该游戏的广义势能游戏结构。在计算市场均衡时，本文依赖两种精确方法：集成优化方法和Gauss-Seidel最佳反应方法，并将其与多智能体深度强化学习进行比较。基于德国和奥地利实际数据的模拟表明，多智能体深度强化学习实现最小的收敛速率但需要预训练，而最佳反应方法最慢。在经济方面，多智能体深度强化学习相较于精确方法导致较小的市场成本，但利润在利益相关者之间的分配波动性更高。此外，区域间的更强耦合趋势在较大的区域中降低成本。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本文利用非合作博弈理论描述了区域辅助市场耦合的特性。</li>
<li>将辅助市场制定为多领导者单跟随者的双层问题，并进一步转化为广义纳什博弈。</li>
<li>确定了均衡存在的条件，并指出游戏具有广义势能游戏结构。</li>
<li>采用了集成优化方法和Gauss-Seidel最佳反应方法来计算市场均衡。</li>
<li>对比了多智能体深度强化学习与上述两种方法，发现多智能体深度强化学习收敛速率最快但需要预训练。</li>
<li>经济方面，多智能体深度强化学习导致较小的市场成本，但利润分配波动性较高。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03288">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3f5cd6a3f4048ad90c517b3faa38118a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c05e19b2387f6513943ac28203fa66a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c7ad5f5729f519459e735623b38d49a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bba91b0ac1b3400dc5cb14203340ca3c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Think-on-your-Feet-Adaptive-Thinking-via-Reinforcement-Learning-for-Social-Agents"><a href="#Think-on-your-Feet-Adaptive-Thinking-via-Reinforcement-Learning-for-Social-Agents" class="headerlink" title="Think on your Feet: Adaptive Thinking via Reinforcement Learning for   Social Agents"></a>Think on your Feet: Adaptive Thinking via Reinforcement Learning for   Social Agents</h2><p><strong>Authors:Minzheng Wang, Yongbin Li, Haobo Wang, Xinghua Zhang, Nan Xu, Bingli Wu, Fei Huang, Haiyang Yu, Wenji Mao</strong></p>
<p>Effective social intelligence simulation requires language agents to dynamically adjust reasoning depth, a capability notably absent in current approaches. While existing methods either lack this kind of reasoning capability or enforce uniform long chain-of-thought reasoning across all scenarios, resulting in excessive token usage and inappropriate social simulation. In this paper, we propose $\textbf{A}$daptive $\textbf{M}$ode $\textbf{L}$earning ($\textbf{AML}$) that strategically selects from four thinking modes (intuitive reaction $\rightarrow$ deep contemplation) based on real-time context. Our framework’s core innovation, the $\textbf{A}$daptive $\textbf{M}$ode $\textbf{P}$olicy $\textbf{O}$ptimization ($\textbf{AMPO}$) algorithm, introduces three key advancements over existing methods: (1) Multi-granular thinking mode design, (2) Context-aware mode switching across social interaction, and (3) Token-efficient reasoning via depth-adaptive processing. Extensive experiments on social intelligence tasks confirm that AML achieves 15.6% higher task performance than state-of-the-art methods. Notably, our method outperforms GRPO by 7.0% with 32.8% shorter reasoning chains. These results demonstrate that context-sensitive thinking mode selection, as implemented in AMPO, enables more human-like adaptive reasoning than GRPO’s fixed-depth approach. </p>
<blockquote>
<p>有效的社会智能模拟需要语言代理动态调整推理深度，而当前的方法明显缺乏这种能力。现有的方法要么缺乏这种推理能力，要么在所有场景中都强制使用统一的长链思维推理，导致令牌使用过多和不当的社会模拟。在本文中，我们提出了自适应模式学习（AML），它根据实时上下文从四种思维模式（直觉反应到深度思考）中进行战略选择。我们框架的核心创新点是自适应模式策略优化（AMPO）算法，相对于现有方法，它引入了三个关键进展：（1）多粒度思维模式设计，（2）社会交互中的上下文感知模式切换，以及（3）通过深度自适应处理的令牌高效推理。在社会智能任务上的大量实验证实，AML比最新技术方法实现了高出15.6%的任务性能。值得注意的是，我们的方法以更短（减少了32.8%）的推理链，比GRPO高出7.0%的性能。这些结果表明，如AMPO所实现的上下文敏感的思维模式选择，使得推理过程更加人性化，优于GRPO的固定深度方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02156v2">PDF</a> Work in Progress. The code and data are available, see   <a target="_blank" rel="noopener" href="https://github.com/MozerWang/AMPO">https://github.com/MozerWang/AMPO</a></p>
<p><strong>Summary</strong>：<br>现有社会智能模拟方法缺乏动态调整推理深度的能力，导致过度使用符号和不当的社会模拟。本文提出自适应模式学习（AML）方法，根据实时上下文从四种思维模式中做出战略选择。AML的核心创新是自适应模式优化算法（AMPO），它在现有方法的基础上引入了三个关键改进：多粒度思维模式设计、社交互动中的上下文感知模式切换以及通过深度自适应处理实现高效的符号推理。实验表明，AML在社交智能任务上的性能比现有方法高出15.6%，特别是相较于GRPO方法，AML在推理链缩短32.8%的同时，性能提升了7%。这表明AMPO实现的上下文敏感思维模式选择，实现了更类似于人类的自适应推理。</p>
<p><strong>Key Takeaways</strong>：</p>
<ul>
<li>当前社会智能模拟方法缺乏动态调整推理深度的能力。</li>
<li>AML方法能够根据实时上下文从多种思维模式中切换。</li>
<li>AMPO算法引入了多粒度思维模式设计、上下文感知模式切换以及符号高效推理。</li>
<li>AML在社交智能任务上的性能显著提高，相较于GRPO方法，推理链更短且性能更优。</li>
<li>AMPO实现了更类似于人类的自适应推理。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02156">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d0de66be52199adbd2e625a6a3b9b7ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c404ecfe71eefc58b729a6b7052a7e0f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77f2993ab3d5c3a7b3c300f867258d89.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Iterative-Tool-Usage-Exploration-for-Multimodal-Agents-via-Step-wise-Preference-Tuning"><a href="#Iterative-Tool-Usage-Exploration-for-Multimodal-Agents-via-Step-wise-Preference-Tuning" class="headerlink" title="Iterative Tool Usage Exploration for Multimodal Agents via Step-wise   Preference Tuning"></a>Iterative Tool Usage Exploration for Multimodal Agents via Step-wise   Preference Tuning</h2><p><strong>Authors:Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li</strong></p>
<p>Multimodal agents, which integrate a controller (e.g., a large language model) with external tools, have demonstrated remarkable capabilities in tackling complex tasks. However, existing agents need to collect a large number of expert data for fine-tuning to adapt to new environments. In this paper, we propose an online self-exploration method for multimodal agents, namely SPORT, via step-wise preference optimization to refine the trajectories of agents, which automatically generates tasks and learns from solving the generated tasks, without any expert annotation. SPORT operates through four iterative components: task synthesis, step sampling, step verification, and preference tuning. First, we synthesize multi-modal tasks using language models. Then, we introduce a novel search scheme, where step sampling and step verification are executed alternately to solve each generated task. We employ a verifier to provide AI feedback to construct step-wise preference data. The data is subsequently used to update the controller’s policy through preference tuning, producing a SPORT Agent. By interacting with real environments, the SPORT Agent evolves into a more refined and capable system. Evaluation in the GTA and GAIA benchmarks show that the SPORT Agent achieves 6.41% and 3.64% improvements, underscoring the generalization and effectiveness introduced by our method. The project page is <a target="_blank" rel="noopener" href="https://sport-agents.github.io/">https://SPORT-Agents.github.io</a>. </p>
<blockquote>
<p>多模态智能体通过整合控制器（如大型语言模型）与外部工具，在应对复杂任务方面展现出卓越的能力。然而，现有智能体需要收集大量专家数据来进行微调以适应新环境。在本文中，我们提出了一种在线自我探索的多模态智能体方法，名为SPORT，通过逐步偏好优化来优化智能体的轨迹，该方法可以自动生成任务并从解决生成的任务中学习，无需任何专家标注。SPORT通过四个迭代组件进行操作：任务合成、步骤采样、步骤验证和偏好调整。首先，我们使用语言模型合成多模态任务。然后，我们引入了一种新颖的搜索方案，其中步骤采样和步骤验证交替执行以解决每个生成的任务。我们采用验证器为人工智能提供反馈，以构建逐步偏好数据。随后使用该数据通过偏好调整更新控制器的策略，从而产生一个SPORT智能体。通过与真实环境进行交互，SPORT智能体逐渐进化为一个更加精细和强大的系统。在GTA和GAIA基准测试中的评估显示，SPORT智能体的性能实现了6.41%和3.64%的提升，凸显了我们的方法所带来的通用性和有效性。项目页面为<a target="_blank" rel="noopener" href="https://sport-agents.github.io./">https://SPORT-Agents.github.io。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21561v2">PDF</a> 16 pages, 8 figures</p>
<p><strong>Summary</strong><br>多媒体智能体通过集成控制器（如大型语言模型）和外部工具，展现出处理复杂任务的能力。然而，现有智能体需要大量专家数据进行微调以适应新环境。本文提出了一种在线自我探索方法——SPORT，通过逐步偏好优化来完善智能体的轨迹，该方法可自动生成任务并从解决生成的任务中学习，无需任何专家标注。SPORT通过四个迭代环节操作：任务合成、步骤采样、步骤验证和偏好调整。首先，利用语言模型合成多媒体任务；然后，采用一种新型搜索方案，交替执行步骤采样和步骤验证来解决每个生成的任务；利用验证器提供人工智能反馈来构建逐步偏好数据；最后，用这些数据通过偏好调整来更新控制器的策略，生成SPORT智能体。通过与真实环境的交互，SPORT智能体逐渐成为一个更加精细和强大的系统。在GTA和GAIA基准测试中的评估结果表明，SPORT智能体实现了6.41%和3.64%的改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多模态智能体具备处理复杂任务的能力，但需要大量专家数据进行微调以适应新环境。</li>
<li>SPORT是一种在线自我探索方法，用于多媒体智能体的轨迹优化，可自动生成任务并从解决这些任务中学习。</li>
<li>SPORT通过四个迭代环节操作：任务合成、步骤采样、步骤验证和偏好调整。</li>
<li>利用语言模型合成多媒体任务，并采用新型搜索方案解决生成的任务。</li>
<li>通过AI反馈构建逐步偏好数据，用于更新控制器的策略。</li>
<li>SPORT智能体在与真实环境的交互中逐渐进化，变得更加精细和强大。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21561">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-994a4c500af50280381adfb2fbe8c8a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ad1a3675777c7f5283cfc95695c66ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ba772608180e6bb3ad4b3393c5c6b1f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eacc2c9fab569ef5260632621d3b3d00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-245e2d5d70913e83da6eecd733b7086f.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="RepliBench-Evaluating-the-Autonomous-Replication-Capabilities-of-Language-Model-Agents"><a href="#RepliBench-Evaluating-the-Autonomous-Replication-Capabilities-of-Language-Model-Agents" class="headerlink" title="RepliBench: Evaluating the Autonomous Replication Capabilities of   Language Model Agents"></a>RepliBench: Evaluating the Autonomous Replication Capabilities of   Language Model Agents</h2><p><strong>Authors:Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney</strong></p>
<p>Uncontrollable autonomous replication of language model agents poses a critical safety risk. To better understand this risk, we introduce RepliBench, a suite of evaluations designed to measure autonomous replication capabilities. RepliBench is derived from a decomposition of these capabilities covering four core domains: obtaining resources, exfiltrating model weights, replicating onto compute, and persisting on this compute for long periods. We create 20 novel task families consisting of 86 individual tasks. We benchmark 5 frontier models, and find they do not currently pose a credible threat of self-replication, but succeed on many components and are improving rapidly. Models can deploy instances from cloud compute providers, write self-propagating programs, and exfiltrate model weights under simple security setups, but struggle to pass KYC checks or set up robust and persistent agent deployments. Overall the best model we evaluated (Claude 3.7 Sonnet) has a &gt;50% pass@10 score on 15&#x2F;20 task families, and a &gt;50% pass@10 score for 9&#x2F;20 families on the hardest variants. These findings suggest autonomous replication capability could soon emerge with improvements in these remaining areas or with human assistance. </p>
<blockquote>
<p>语言模型代理的不可控自主复制带来了关键的安全风险。为了更好地理解这一风险，我们引入了RepliBench，这是一套旨在测量自主复制能力的评估工具。RepliBench来源于对这些能力的分解，涵盖了四个核心领域：获取资源、模型权重外泄、复制到计算平台、以及长时间持续运行于此计算平台。我们创建了由86个单独任务组成的20个新型任务家族。我们对前沿的五个模型进行了基准测试，发现它们目前尚未构成可信的自我复制威胁，但在许多组件上取得了成功，并且正在迅速改进。这些模型能够从云计算提供商部署实例、编写自我传播程序，并在简单的安全设置下提取模型权重，但在通过KYC检查或设置稳健和持久的代理部署方面遇到了困难。总体而言，我们评估的最佳模型（Claude 3.7 Sonnet）在15个任务家族中的前十个任务中有超过一半的通过率，并且在最困难变体中有超过一半的通过率对于剩下的九个任务家族中的前十个任务也有类似的通过率。这些发现表明，随着这些领域的改进或在人类帮助下支持进步提升发展等情形可能很快会出现具备自主复制能力的语言模型代理的出现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18565v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>语言模型自主复制能力失控带来重大安全风险。为更好地了解风险，推出RepliBench评估套件，测量语言模型的自主复制能力。包括获取资源、提取模型权重、复制到计算平台和长期持续计算四个核心领域的评估。创建20个新任务家族，包含86个独立任务。对前沿模型进行基准测试发现，当前模型尚未构成可信的自我复制威胁，但在许多组件上表现良好且发展迅速。模型能够从云计算提供商部署实例、编写自我传播程序并在简单安全设置下提取模型权重，但在通过KYC检查或设置稳健持久代理部署方面遇到困难。总体而言，我们评估的最佳模型Claude 3.7 Sonnet在大部分任务上取得了良好的表现，并在某些方面表现出了很强的能力，暗示着随着剩余领域的改进或人类协助的发展，自主复制能力可能很快出现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语言模型自主复制能力失控带来安全风险。</li>
<li>RepliBench评估套件用于测量语言模型的自主复制能力，涵盖四个核心领域。</li>
<li>创建了20个任务家族，包含86个独立任务来基准测试前沿模型。</li>
<li>当前模型尚未构成自我复制威胁，但在许多方面表现良好且发展迅速。</li>
<li>模型能够部署实例、编写自我传播程序并提取模型权重。</li>
<li>模型在通过KYC检查或设置稳健持久代理部署方面遇到困难。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18565">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5de2fa7de8cd64df90896cbb016c3906.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53e1f1218f82dd74b9a5c4ac941038b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f09af0358f7cdf73b21b18885be3ae35.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-500b5860ca02cf295cdd9a4a8d66bd9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9cbcba699bf56ee8221ed6f3ace449a.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="“Trust-me-on-this”-Explaining-Agent-Behavior-to-a-Human-Terminator"><a href="#“Trust-me-on-this”-Explaining-Agent-Behavior-to-a-Human-Terminator" class="headerlink" title="“Trust me on this” Explaining Agent Behavior to a Human Terminator"></a>“Trust me on this” Explaining Agent Behavior to a Human Terminator</h2><p><strong>Authors:Uri Menkes, Assaf Hallak, Ofra Amir</strong></p>
<p>Consider a setting where a pre-trained agent is operating in an environment and a human operator can decide to temporarily terminate its operation and take-over for some duration of time. These kind of scenarios are common in human-machine interactions, for example in autonomous driving, factory automation and healthcare. In these settings, we typically observe a trade-off between two extreme cases – if no take-overs are allowed, then the agent might employ a sub-optimal, possibly dangerous policy. Alternatively, if there are too many take-overs, then the human has no confidence in the agent, greatly limiting its usefulness. In this paper, we formalize this setup and propose an explainability scheme to help optimize the number of human interventions. </p>
<blockquote>
<p>考虑一个预训练代理在环境中运行的场景，人类操作者可以决定暂时终止其操作并在一段时间内接管。在人类与机器交互中，这种场景非常普遍，例如在自动驾驶、工厂自动化和医疗保健中。在这些场景中，我们通常观察到两种极端情况之间的权衡——如果不允许接管，那么代理可能会采用一种次优的、可能是危险的策略。相反，如果接管次数过多，那么人类对代理缺乏信心，极大地限制了其有用性。在本文中，我们对这一设置进行了形式化，并提出了一种解释性方案，以帮助优化人类干预的次数。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04592v2">PDF</a> 6 pages, 3 figures, in proceedings of ICML 2024 Workshop on Models of   Human Feedback for AI Alignment</p>
<p><strong>Summary</strong></p>
<p>该文本探讨了在人机互动环境中预训练代理的运营情况，如自动驾驶、工厂自动化和医疗保健等领域。文章指出在没有人工接管和过度接管之间需要平衡，提出了一种解释方案来帮助优化人工干预的数量。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>在人机互动环境中，存在预训练代理运营时的平衡问题。</li>
<li>当不允许人工接管时，代理可能会采取次优甚至危险的策略。</li>
<li>过度的人工接管会使人类失去对代理的信任，限制其使用。</li>
<li>该论文提出了一种解释方案来优化人工干预的数量。</li>
<li>文章涉及的应用领域包括自动驾驶、工厂自动化和医疗保健等。</li>
<li>在实际应用中需要找到一种合适的平衡，以确保代理的有效性和安全性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04592">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-670e50672c14f3f7c3ddf0478013c3fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-129b709e6f3b435c61dd0cfa53dbb5b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d39f974fac6dddee68cfcfa082e28294.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51dd05b328a288a0d9c26b6d88123002.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LiteWebAgent-The-Open-Source-Suite-for-VLM-Based-Web-Agent-Applications"><a href="#LiteWebAgent-The-Open-Source-Suite-for-VLM-Based-Web-Agent-Applications" class="headerlink" title="LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications"></a>LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications</h2><p><strong>Authors:Danqing Zhang, Balaji Rama, Jingyi Ni, Shiying He, Fu Zhao, Kunyu Chen, Arnold Chen, Junyu Cao</strong></p>
<p>We introduce LiteWebAgent, an open-source suite for VLM-based web agent applications. Our framework addresses a critical gap in the web agent ecosystem with a production-ready solution that combines minimal serverless backend configuration, intuitive user and browser interfaces, and extensible research capabilities in agent planning, memory, and tree search. For the core LiteWebAgent agent framework, we implemented a simple yet effective baseline using recursive function calling, providing with decoupled action generation and action grounding. In addition, we integrate advanced research components such as agent planning, agent workflow memory, and tree search in a modular and extensible manner. We then integrate the LiteWebAgent agent framework with frontend and backend as deployed systems in two formats: (1) a production Vercel-based web application, which provides users with an agent-controlled remote browser, (2) a Chrome extension leveraging LiteWebAgent’s API to control an existing Chrome browser via CDP (Chrome DevTools Protocol). The LiteWebAgent framework is available at <a target="_blank" rel="noopener" href="https://github.com/PathOnAI/LiteWebAgent">https://github.com/PathOnAI/LiteWebAgent</a>, with deployed frontend at <a target="_blank" rel="noopener" href="https://lite-web-agent.vercel.app/">https://lite-web-agent.vercel.app/</a>. </p>
<blockquote>
<p>我们介绍了LiteWebAgent，这是一个用于基于VLM的Web代理应用程序的开源套件。我们的框架解决了Web代理生态系统中的一个关键空白，提供了一个可用于生产的解决方案，该解决方案结合了最小的无服务器后端配置、直观的用户和浏览器界面，以及可扩展的代理规划、内存和树搜索的研究能力。对于核心的LiteWebAgent代理框架，我们实现了一个简单而有效的基线，使用递归函数调用，提供了分离的动产生和动作接地。此外，我们以模块化和可扩展的方式集成了先进的组件，如代理规划、代理工作流程内存和树搜索。然后，我们将LiteWebAgent代理框架与前端和后端整合为两个格式的部署系统：（1）一个基于Vercel的生产Web应用程序，为用户提供代理控制的远程浏览器；（2）一个Chrome扩展程序，利用LiteWebAgent的API通过CDP（Chrome开发工具协议）控制现有的Chrome浏览器。LiteWebAgent框架可在<a target="_blank" rel="noopener" href="https://github.com/PathOnAI/LiteWebAgent%E4%B8%8A%E6%89%BE%E5%88%B0%EF%BC%8C%E5%B7%B2%E9%83%A8%E7%BD%B2%E7%9A%84%E5%89%8D%E7%AB%AF%E7%95%8C%E9%9D%A2%E4%B8%BAhttps://lite-web-agent.vercel.app/%E3%80%82">https://github.com/PathOnAI/LiteWebAgent上找到，已部署的前端界面为https://lite-web-agent.vercel.app/。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02950v2">PDF</a> </p>
<p><strong>Summary</strong><br>     推出开源的LiteWebAgent套件，为基于VLM的web代理应用程序提供支持。该框架解决了web代理生态系统中的关键空白，通过最小化的无服务器后端配置、直观的用户和浏览器界面以及可扩展的研究能力，实现代理规划、内存和树搜索。其核心框架采用递归函数调用实现简单有效的基线，并提供解耦的动作生成和动作接地。此外，还模块化集成了先进的组件如代理规划、代理工作流内存和树搜索。LiteWebAgent已部署为两种系统格式：生产Vercel Web应用程序（提供受控远程浏览器）和Chrome扩展程序（利用LiteWebAgent API控制现有Chrome浏览器）。框架位于[链接]，前端部署位于[链接]。</p>
<p><strong>Key Takeaways</strong></p>
<pre><code> * LiteWebAgent是一个针对web代理应用程序的开源框架，弥补了该领域的关键空白。
 
 * 该框架具有最小化的无服务器后端配置，并提供了直观的用户和浏览器界面。
 
 * LiteWebAgent框架具有可扩展的研究能力，包括代理规划、内存管理和树搜索等先进组件。
 
 * 框架采用递归函数调用的简单有效基线，实现动作生成与动作接地的解耦。
 
 * LiteWebAgent以两种系统格式部署：作为生产Vercel Web应用程序（提供代理控制的远程浏览器功能）。
 
 * 存在一个Chrome扩展程序，利用LiteWebAgent API控制现有Chrome浏览器。
</code></pre>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02950">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-607c56f6023ca9255eb0384b03f35f0f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7769c6a7a9b9ae636e7caf2dd735f79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-922ee18f9d46bfcadf31d4a196299779.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-52f9a8952ec1f965c6fb7bd59ace76e6.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="BRIDGE-Bootstrapping-Text-to-Control-Time-Series-Generation-via-Multi-Agent-Iterative-Optimization-and-Diffusion-Modelling"><a href="#BRIDGE-Bootstrapping-Text-to-Control-Time-Series-Generation-via-Multi-Agent-Iterative-Optimization-and-Diffusion-Modelling" class="headerlink" title="BRIDGE: Bootstrapping Text to Control Time-Series Generation via   Multi-Agent Iterative Optimization and Diffusion Modelling"></a>BRIDGE: Bootstrapping Text to Control Time-Series Generation via   Multi-Agent Iterative Optimization and Diffusion Modelling</h2><p><strong>Authors:Hao Li, Yuhao Huang, Chang Xu, Viktor Schlegel, Renhe Jiang, Riza Batista-Navarro, Goran Nenadic, Jiang Bian</strong></p>
<p>Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce &#96;&#96;Text-Controlled TSG’’, a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data. </p>
<blockquote>
<p>时间序列生成（TSG）是一个具有广泛应用前景的重要研究领域，在模拟、数据增强和反向事实分析等方面都有应用。虽然现有的方法在无条件单域TSG方面显示出了一定的潜力，但实际应用需要跨域的方法，能够适应特定域约束和实例级要求的有控制生成。在本文中，我们主张文本可以提供语义洞察、领域信息和实例特定的时间模式，以指导和改进TSG。我们引入了“文本控制TSG”，这是一项通过融入文本描述来生成真实时间序列的任务。为了解决此环境中的数据稀缺问题，我们提出了一个基于大型语言模型的多智能体框架，该框架可以综合多样化的、真实的文本到TS数据集。此外，我们还引入了BRIDGE，一个混合文本控制TSG框架，它将语义原型与文本描述相结合，以支持域级指导。该方法在12个数据集中有11个达到了最先进的生成保真度，并且在均方误差（MSE）上提高了12.52%，平均绝对误差（MAE）提高了6.34%，相较于无文本输入生成的方式提升了控制力，这突显了其在生成定制时间序列数据方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02445v3">PDF</a> ICML 2025</p>
<p><strong>Summary</strong><br>文本介绍了时间序数生成（TSG）的研究领域，并指出其在模拟、数据增强和反向事实分析中的广泛应用。现有方法主要关注无条件单域TSG，但实际应用需要跨域方法，以符合特定领域的约束和实例级要求。本文提出了“文本控制TSG”任务，旨在通过融入文本描述来生成真实的时间序列。为解决数据稀缺问题，我们提出了基于LLM的多代理框架，用于合成多样且真实的文本到TS数据集。此外，我们引入了BRIDGE这一混合文本控制TSG框架，结合语义原型和文本描述以支持领域级指导。该方法在12个数据集中有11个达到了最先进的生成保真度，并且在MSE上提高了12.52%，在MAE上提高了6.34%，相较于无文本输入生成的结果有所改善，凸显了其在生成定制时间序列数据方面的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>时间序数生成（TSG）在模拟、数据增强和反向事实分析中具有广泛应用。</li>
<li>现有方法主要关注无条件单域TSG，但实际应用需要跨域方法。</li>
<li>文本可以提供语义洞察、领域信息和实例级时间模式，用于指导和改进TSG。</li>
<li>提出“文本控制TSG”任务，旨在通过融入文本描述来生成真实的时间序列。</li>
<li>为解决数据稀缺问题，引入了基于LLM的多代理框架来合成真实文本到TS数据集。</li>
<li>引入BRIDGE框架结合语义原型和文本描述，以提高生成时间序列数据的保真度和可控性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02445">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a66c40c367a2fdfd375b678b526d792b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7896af185f4a2946206b762fa3e9df92.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Towards-Enterprise-Ready-Computer-Using-Generalist-Agent"><a href="#Towards-Enterprise-Ready-Computer-Using-Generalist-Agent" class="headerlink" title="Towards Enterprise-Ready Computer Using Generalist Agent"></a>Towards Enterprise-Ready Computer Using Generalist Agent</h2><p><strong>Authors:Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov, Ido Levy, Aviad Sela, Asaf Adi, Nir Mashkif</strong></p>
<p>This paper presents our ongoing work toward developing an enterprise-ready Computer Using Generalist Agent (CUGA) system. Our research highlights the evolutionary nature of building agentic systems suitable for enterprise environments. By integrating state-of-the-art agentic AI techniques with a systematic approach to iterative evaluation, analysis, and refinement, we have achieved rapid and cost-effective performance gains, notably reaching a new state-of-the-art performance on the WebArena benchmark. We detail our development roadmap, the methodology and tools that facilitated rapid learning from failures and continuous system refinement, and discuss key lessons learned and future challenges for enterprise adoption. </p>
<blockquote>
<p>本文介绍了我们正在开发的企业级通用代理（CUGA）系统的工作进展。我们的研究强调了构建适合企业环境的智能代理系统所具有的进化特性。通过将最新的人工智能技术和系统化方法进行迭代评估、分析和优化相结合，我们实现了快速且经济的性能提升，特别是在WebArena基准测试上达到了业界最佳水平。我们详细介绍了开发路线图、方法和工具，这些方法和工具有助于我们从失败中快速学习并不断进行系统优化，并讨论了从中学到的关键教训以及未来企业在采用方面的挑战。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.01861v2">PDF</a> </p>
<p><strong>Summary</strong>：<br>此论文展示了我们对开发面向企业的通用智能体系统（Computer Using Generalist Agent，简称CUGA）的进展。研究重点强调了构建适合企业环境的智能体系统的进化性质。通过集成先进的智能体AI技术和系统化的迭代评估、分析和改进方法，我们实现了快速且具有成本效益的性能提升，并在WebArena基准测试中达到了新的性能水平。论文详细阐述了开发路线图、方法和工具，这些方法和工具有助于从失败中学习并迅速进行系统改进，并讨论了企业采纳的关键经验教训和未来挑战。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>该研究旨在开发一种面向企业的通用智能体系统（CUGA）。</li>
<li>研究强调智能体系统的进化性质，通过整合先进AI技术以构建适合企业环境的应用。</li>
<li>通过系统方法和工具实现了快速和成本效益显著的性能提升。</li>
<li>在WebArena基准测试中取得了新的性能水平。</li>
<li>论文详细阐述了开发路线图和从失败中学习的方法，包括迭代评估、分析和改进过程。</li>
<li>研究讨论了企业采纳智能体系统的关键经验教训和未来挑战。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.01861">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-73c64f7e911871b04b2ba5e2659f0ab8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed6c9f26d55d2961f61e43d099f3e895.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32bea3c1583d52a23d6aad078c317929.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e1fef6f6eaa51a1fbaba55a8cfee797.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-544bef2c785f3d855de25951625beaa6.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Cooperative-Multi-Agent-Planning-with-Adaptive-Skill-Synthesis"><a href="#Cooperative-Multi-Agent-Planning-with-Adaptive-Skill-Synthesis" class="headerlink" title="Cooperative Multi-Agent Planning with Adaptive Skill Synthesis"></a>Cooperative Multi-Agent Planning with Adaptive Skill Synthesis</h2><p><strong>Authors:Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen</strong></p>
<p>Despite much progress in training distributed artificial intelligence (AI), building cooperative multi-agent systems with multi-agent reinforcement learning (MARL) faces challenges in sample efficiency, interpretability, and transferability. Unlike traditional learning-based methods that require extensive interaction with the environment, large language models (LLMs) demonstrate remarkable capabilities in zero-shot planning and complex reasoning. However, existing LLM-based approaches heavily rely on text-based observations and struggle with the non-Markovian nature of multi-agent interactions under partial observability. We present COMPASS, a novel multi-agent architecture that integrates vision-language models (VLMs) with a dynamic skill library and structured communication for decentralized closed-loop decision-making. The skill library, bootstrapped from demonstrations, evolves via planner-guided tasks to enable adaptive strategies. COMPASS propagates entity information through multi-hop communication under partial observability. Evaluations on the improved StarCraft Multi-Agent Challenge (SMACv2) demonstrate COMPASS’s strong performance against state-of-the-art MARL baselines across both symmetric and asymmetric scenarios. Notably, in the symmetric Protoss 5v5 task, COMPASS achieved a 57% win rate, representing a 30 percentage point advantage over QMIX (27%). Project page can be found at <a target="_blank" rel="noopener" href="https://stellar-entremet-1720bb.netlify.app/">https://stellar-entremet-1720bb.netlify.app/</a>. </p>
<blockquote>
<p>尽管在训练分布式人工智能（AI）方面取得了很大进展，但使用多智能体强化学习（MARL）构建合作多智能体系统仍面临样本效率、可解释性和可迁移性的挑战。不同于需要大量与环境交互的传统基于学习的方法，大型语言模型（LLM）在零射击计划和复杂推理方面表现出了卓越的能力。然而，现有的基于LLM的方法严重依赖于文本观察，并在部分可观察下挣扎于多智能体的非马尔可夫性质交互。我们提出了COMPASS，这是一种新型的多智能体架构，它结合了视觉语言模型（VLM）与动态技能库和结构化通信，用于分散式闭环决策。技能库从演示中启动，通过规划器指导的任务进行演变，以实现自适应策略。COMPASS在部分可观察的情况下通过多跳通信传播实体信息。在改进后的星际争霸多智能体挑战（SMACv2）上的评估表明，COMPASS在对称和不对称场景中的性能均优于最新的MARL基线。值得注意的是，在对称的Protoss 5v5任务中，COMPASS的胜率达到了57%，相比于QMIX有30个百分点的优势（QMIX的胜率为27%）。项目页面可以在<a target="_blank" rel="noopener" href="https://stellar-entremet-1720bb.netlify.app/%E6%89%BE%E5%88%B0%E3%80%82">https://stellar-entremet-1720bb.netlify.app/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.10148v2">PDF</a> </p>
<p><strong>Summary</strong>：<br>虽然分布式人工智能（AI）训练取得了很多进展，但在使用多智能体强化学习（MARL）构建合作多智能体系统时仍面临样本效率、可解释性和可迁移性的挑战。不同于传统的学习型方法需要大量与环境互动，大型语言模型（LLM）在零射击计划和复杂推理方面表现出卓越的能力。然而，现有的LLM方法主要依赖于文本观测，难以处理部分观测下的非马尔可夫多智能体交互。本文提出了COMPASS，一种新型的多智能体架构，融合了视觉语言模型（VLM）与动态技能库和结构化通讯，用于分布式闭环决策。技能库通过演示引导任务进行演化，使策略具有适应性。COMPASS在部分观测下通过多跳通信传播实体信息。在改进版星际争霸多智能体挑战（SMACv2）上的评估表明，COMPASS在多种场景中均表现出强劲性能，超越最新MARL基线。特别是在对称的Protoss 5v5任务中，COMPASS的胜率达到了57%，较QMIX高出30个百分点。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>分布式人工智能（AI）训练在样本效率、可解释性和可迁移性方面存在挑战。</li>
<li>大型语言模型（LLM）在零射击计划和复杂推理方面具有显著优势，但依赖文本观测。</li>
<li>COMPASS是一种新型多智能体架构，融合了视觉语言模型（VLM）、动态技能库和结构化通讯。</li>
<li>技能库通过演示引导任务演化，使策略具有适应性。</li>
<li>COMPASS在部分观测下通过多跳通信传播实体信息，以提高决策效率。</li>
<li>在改进版星际争霸多智能体挑战（SMACv2）上，COMPASS表现优异，超过现有MARL方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.10148">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a20691c4fcd1ec99c41f6b272c0c2df5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4914c085237c8c4a2db33b972a300bb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c3e734172f2bae1bf6f745882c05a04.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8cd7692b8bc39a07c4c9e69357130d10.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5855bd9e9a02fb64156949fb8324b385.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="AutoDroid-V2-Boosting-SLM-based-GUI-Agents-via-Code-Generation"><a href="#AutoDroid-V2-Boosting-SLM-based-GUI-Agents-via-Code-Generation" class="headerlink" title="AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation"></a>AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation</h2><p><strong>Authors:Hao Wen, Shizuo Tian, Borislav Pavlov, Wenjie Du, Yixuan Li, Ge Chang, Shanhui Zhao, Jiacheng Liu, Yunxin Liu, Ya-Qin Zhang, Yuanchun Li</strong></p>
<p>Large language models (LLMs) have brought exciting new advances to mobile UI agents, a long-standing research field that aims to complete arbitrary natural language tasks through mobile UI interactions. However, existing UI agents usually demand powerful large language models that are difficult to be deployed locally on end-users’ devices, raising huge concerns about user privacy and centralized serving cost. Inspired by the remarkable coding abilities of recent small language models (SLMs), we propose to convert the UI task automation problem to a code generation problem, which can be effectively solved by an on-device SLM and efficiently executed with an on-device code interpreter. Unlike normal coding tasks that can be extensively pre-trained with public datasets, generating UI automation code is challenging due to the diversity, complexity, and variability of target apps. Therefore, we adopt a document-centered approach that automatically builds fine-grained API documentation for each app and generates diverse task samples based on this documentation. By guiding the agent with the synthetic documents and task samples, it learns to generate precise and efficient scripts to complete unseen tasks. Based on detailed comparisons with state-of-the-art mobile UI agents, our approach effectively improves the mobile task automation with significantly higher success rates and lower latency&#x2F;token consumption. Code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/MobileLLM/AutoDroid-V2">https://github.com/MobileLLM/AutoDroid-V2</a>. </p>
<blockquote>
<p>大型语言模型（LLM）为移动用户界面代理（UI agents）带来了令人兴奋的新进展，这是一个长期的研究领域，旨在通过移动用户界面交互完成任意的自然语言任务。然而，现有的UI代理通常需要功能强大的大型语言模型，这些模型难以在最终用户的设备上本地部署，引发了关于用户隐私和集中服务成本的巨大担忧。受近期小型语言模型（SLM）显著编码能力的启发，我们提出将UI任务自动化问题转换为代码生成问题，该问题可以通过设备上的SLM有效解决并通过设备上的代码解释器高效执行。与可以使用公共数据集进行广泛预训练的常规编码任务不同，生成UI自动化代码具有挑战性，因为目标应用程序具有多样性、复杂性和可变性。因此，我们采用以文档为中心的方法，该方法会自动为每个应用程序建立精细的API文档，并基于此文档生成多样的任务样本。通过合成文档和任务样本引导代理，它学会了生成精确高效的脚本，以完成未见过的任务。与最新的移动UI代理相比，我们的方法有效地提高了移动任务自动化，成功率显著提高，延迟和令牌消耗大大降低。代码已开源至：<a target="_blank" rel="noopener" href="https://github.com/MobileLLM/AutoDroid-V2">https://github.com/MobileLLM/AutoDroid-V2</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18116v3">PDF</a> 13 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）为移动UI智能代理带来了新发展，但部署困难引发隐私和成本问题。受小型语言模型（SLM）启发，提出将UI任务自动化转为代码生成问题，通过设备上的SLM和代码解释器解决。采用文档为中心的方法，自动为应用构建精细API文档，生成任务样本，指导代理生成精确高效脚本完成任务。与现有移动UI智能代理相比，成功率更高、延迟更低。代码已开源。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型在移动UI智能代理领域有新发展，但部署难题引发隐私和成本担忧。</li>
<li>小型语言模型在编码能力方面表现出潜力，适用于移动UI任务自动化。</li>
<li>将UI任务自动化转为代码生成问题，通过设备上的SLM和代码解释器有效解决。</li>
<li>采用文档为中心的方法，自动构建API文档并生成任务样本，提高代理的任务完成能力。</li>
<li>与现有移动UI智能代理相比，新方法成功率更高、延迟更低。</li>
<li>代码已开源，便于进一步研究和应用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18116">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8b90c1a5a01c4f6172df9aa6642b1398.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7c5d5d6da679b3ce916b81cf8f3aa44.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8bcc8cb0e5521b52baed494a0fc11b52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c2841ebf3308a1a570b567061c06bb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b70f92a329f410f0bd0b0d4778f4570.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84bf2adbaed2081f2b261714f352b359.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Social-Opinions-Prediction-Utilizes-Fusing-Dynamics-Equation-with-LLM-based-Agents"><a href="#Social-Opinions-Prediction-Utilizes-Fusing-Dynamics-Equation-with-LLM-based-Agents" class="headerlink" title="Social Opinions Prediction Utilizes Fusing Dynamics Equation with   LLM-based Agents"></a>Social Opinions Prediction Utilizes Fusing Dynamics Equation with   LLM-based Agents</h2><p><strong>Authors:Junchi Yao, Hongjie Zhang, Jie Ou, Dingyi Zuo, Zheng Yang, Zhicheng Dong</strong></p>
<p>In the context where social media emerges as a pivotal platform for social movements and shaping public opinion, accurately simulating and predicting the dynamics of user opinions is of significant importance. Such insights are vital for understanding social phenomena, informing policy decisions, and guiding public opinion. Unfortunately, traditional algorithms based on idealized models and disregarding social data often fail to capture the complexity and nuance of real-world social interactions. This study proposes the Fusing Dynamics Equation-Large Language Model (FDE-LLM) algorithm. This innovative approach aligns the actions and evolution of opinions in Large Language Models (LLMs) with the real-world data on social networks. The FDE-LLM devides users into two roles: opinion leaders and followers. Opinion leaders use LLM for role-playing and employ Cellular Automata(CA) to constrain opinion changes. In contrast, opinion followers are integrated into a dynamic system that combines the CA model with the Susceptible-Infectious-Recovered (SIR) model. This innovative design significantly improves the accuracy of the simulation. Our experiments utilized four real-world datasets from Weibo. The result demonstrates that the FDE-LLM significantly outperforms traditional Agent-Based Modeling (ABM) algorithms and LLM-based algorithms. Additionally, our algorithm accurately simulates the decay and recovery of opinions over time, underscoring LLMs potential to revolutionize the understanding of social media dynamics. </p>
<blockquote>
<p>在社交媒体成为社会运动平台和塑造公众意见的关键背景下，准确模拟和预测用户意见的动态变得至关重要。这些见解对于理解社会现象、为政策决策提供信息以及引导公众意见都至关重要。然而，基于理想化模型并忽略社会数据的传统算法往往无法捕捉现实社会互动的复杂性和细微差别。本研究提出了融合动力学方程-大型语言模型（FDE-LLM）算法。这一创新方法将大型语言模型（LLM）中的行动和意见演变与社交网络上的真实世界数据相结合。FDE-LLM将用户分为两个角色：意见领袖和追随者。意见领袖使用LLM进行角色扮演，并使用元胞自动机（CA）来约束意见变化。相比之下，意见追随者被整合到一个结合CA模型和易感-感染-恢复（SIR）模型的动态系统中。这一创新设计显著提高了模拟的准确性。我们的实验使用了来自微博的四个真实数据集。结果表明，FDE-LLM显著优于传统的基于主体的建模（ABM）算法和基于LLM的算法。此外，我们的算法准确地模拟了意见随时间的变化和恢复过程，突出了LLM在理解社交媒体动态方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08717v4">PDF</a> </p>
<p><strong>Summary</strong><br>社交媒体作为社会运动和公众意见形成的重要平台，模拟和预测用户意见动态具有重大意义。本研究提出融合动力学方程-大型语言模型（FDE-LLM）算法，该算法将大型语言模型中的行动和意见演变与社交网络上的真实数据相结合。通过细分用户为意见领袖和追随者，并引入细胞自动机和SIR模型，该算法提高了模拟的准确性。研究结果表明，FDE-LLM在模拟微博真实世界数据集方面显著优于传统的基于主体的建模算法和基于大型语言模型的算法，并准确模拟了意见随时间的变化。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>社交媒体在模拟和预测用户意见动态方面至关重要，对于理解社会现象、制定政策决策和引导公众意见具有重要意义。</li>
<li>传统算法在捕捉现实社交互动的复杂性和细微差别方面存在缺陷。</li>
<li>FDE-LLM算法结合了大型语言模型与社交网络真实数据，提高了模拟的准确性。</li>
<li>FDE-LLM将用户分为意见领袖和追随者两个角色，并采用不同的模型进行模拟。</li>
<li>意见领袖采用角色扮演和细胞自动体来约束意见变化，而意见追随者则结合细胞自动体和SIR模型进行动态系统模拟。</li>
<li>FDE-LLM在模拟微博真实世界数据集方面的性能显著优于传统算法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08717">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-072a70506ca87213a2c9c8259da518d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffbf8d658cdced5e4b09b0d36dcb8eeb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b13e34063cdaac6b0397f7104ff2c710.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bc2288ed510db1d02f902a38d99c2be9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a737391a1fa68558abbae946c56dea0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5f191b718525d50d74679938812eb82.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-08/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-08/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-08/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-de7f6c38b37cbb82fa68cf62304b2b86.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-05-08  Towards Smart Point-and-Shoot Photography
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-08/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-07be0c23b7fac6f4ca15a78037644159.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-05-08  VITA-Audio Fast Interleaved Cross-Modal Token Generation for Efficient   Large Speech-Language Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19017.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
