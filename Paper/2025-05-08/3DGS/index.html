<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-08  GUAVA Generalizable Upper Body 3D Gaussian Avatar">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-017f70489e8edd59e6f27c2627b85e88.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    59 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-08-æ›´æ–°"><a href="#2025-05-08-æ›´æ–°" class="headerlink" title="2025-05-08 æ›´æ–°"></a>2025-05-08 æ›´æ–°</h1><h2 id="GUAVA-Generalizable-Upper-Body-3D-Gaussian-Avatar"><a href="#GUAVA-Generalizable-Upper-Body-3D-Gaussian-Avatar" class="headerlink" title="GUAVA: Generalizable Upper Body 3D Gaussian Avatar"></a>GUAVA: Generalizable Upper Body 3D Gaussian Avatar</h2><p><strong>Authors:Dongbin Zhang, Yunfei Liu, Lijian Lin, Ye Zhu, Yang Li, Minghan Qin, Yu Li, Haoqian Wang</strong></p>
<p>Reconstructing a high-quality, animatable 3D human avatar with expressive facial and hand motions from a single image has gained significant attention due to its broad application potential. 3D human avatar reconstruction typically requires multi-view or monocular videos and training on individual IDs, which is both complex and time-consuming. Furthermore, limited by SMPLXâ€™s expressiveness, these methods often focus on body motion but struggle with facial expressions. To address these challenges, we first introduce an expressive human model (EHM) to enhance facial expression capabilities and develop an accurate tracking method. Based on this template model, we propose GUAVA, the first framework for fast animatable upper-body 3D Gaussian avatar reconstruction. We leverage inverse texture mapping and projection sampling techniques to infer Ubody (upper-body) Gaussians from a single image. The rendered images are refined through a neural refiner. Experimental results demonstrate that GUAVA significantly outperforms previous methods in rendering quality and offers significant speed improvements, with reconstruction times in the sub-second range (0.1s), and supports real-time animation and rendering. </p>
<blockquote>
<p>é‡å»ºä¸€ä¸ªé«˜è´¨é‡ã€å¯åŠ¨ç”»åŒ–çš„3Däººç±»åŒ–èº«ï¼Œä»å•å¼ å›¾åƒä¸­è¡¨ç°å‡ºå…·æœ‰è¡¨æƒ…çš„é¢éƒ¨å’Œæ‰‹éƒ¨åŠ¨ä½œï¼Œç”±äºå…¶å¹¿æ³›çš„åº”ç”¨æ½œåŠ›è€Œå¤‡å—å…³æ³¨ã€‚3Däººç±»åŒ–èº«é‡å»ºé€šå¸¸éœ€è¦å¤šè§†è§’æˆ–å•ç›®è§†é¢‘ä»¥åŠå¯¹ä¸ªäººIDçš„è®­ç»ƒï¼Œè¿™æ—¢å¤æ‚åˆè€—æ—¶ã€‚æ­¤å¤–ï¼Œå—é™äºSMPLXçš„è¡¨ç°åŠ›ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¾§é‡äºèº«ä½“åŠ¨ä½œï¼Œä½†åœ¨é¢éƒ¨è¡¨æƒ…æ–¹é¢å´è¡¨ç°æŒ£æ‰ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥äº†ä¸€ä¸ªè¡¨æƒ…ä¸°å¯Œçš„äººç±»æ¨¡å‹ï¼ˆEHMï¼‰ä»¥å¢å¼ºé¢éƒ¨è¡¨æƒ…èƒ½åŠ›ï¼Œå¹¶å¼€å‘äº†ä¸€ç§ç²¾ç¡®çš„è·Ÿè¸ªæ–¹æ³•ã€‚åŸºäºè¿™ä¸ªæ¨¡æ¿æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†GUAVAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºå¿«é€Ÿå¯åŠ¨ç”»çš„3Dé«˜æ–¯åŒ–èº«é‡å»ºæ¡†æ¶ã€‚æˆ‘ä»¬åˆ©ç”¨é€†å‘çº¹ç†æ˜ å°„å’ŒæŠ•å½±é‡‡æ ·æŠ€æœ¯ä»å•å¼ å›¾åƒæ¨æ–­å‡ºä¸ŠåŠèº«çš„é«˜æ–¯åˆ†å¸ƒã€‚æ¸²æŸ“çš„å›¾åƒé€šè¿‡ç¥ç»ç½‘ç»œç²¾ç‚¼å™¨è¿›è¡Œç²¾ç‚¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGUAVAåœ¨æ¸²æŸ“è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œå¹¶åœ¨é€Ÿåº¦ä¸Šå®ç°äº†æ˜¾è‘—çš„æå‡ï¼Œé‡å»ºæ—¶é—´åœ¨äºšç§’èŒƒå›´å†…ï¼ˆ0.1ç§’ï¼‰ï¼Œæ”¯æŒå®æ—¶åŠ¨ç”»å’Œæ¸²æŸ“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03351v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://eastbeanzhang.github.io/GUAVA/">https://eastbeanzhang.github.io/GUAVA/</a></p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬ä»‹ç»äº†ä»å•å¼ å›¾åƒé‡å»ºé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„3Däººç±»è§’è‰²æ¨¡å‹çš„ç ”ç©¶è¿›å±•ã€‚è¯¥æ¨¡å‹å…·æœ‰è¡¨è¾¾æ€§é¢éƒ¨å’Œæ‰‹éƒ¨åŠ¨ä½œï¼Œå¹¶å¹¿æ³›åº”ç”¨äºå¤šä¸ªé¢†åŸŸã€‚ä¸ºè§£å†³ç°æœ‰æ–¹æ³•å¤æ‚åº¦é«˜ã€è€—æ—¶è¾ƒé•¿ä¸”é¢éƒ¨è¡¨æƒ…è¡¨è¾¾èƒ½åŠ›æœ‰é™çš„é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†è¡¨è¾¾æ€§äººç±»æ¨¡å‹ï¼ˆEHMï¼‰ä»¥æé«˜é¢éƒ¨è¡¨æƒ…èƒ½åŠ›ï¼Œå¹¶å¼€å‘äº†ç²¾å‡†è¿½è¸ªæ–¹æ³•ã€‚åŸºäºè¯¥æ¨¡æ¿æ¨¡å‹ï¼Œæå‡ºäº†é¦–ä¸ªå¿«é€Ÿå¯åŠ¨ç”»çš„ä¸ŠåŠèº«3Dé«˜æ–¯è§’è‰²é‡å»ºæ¡†æ¶GUAVAã€‚åˆ©ç”¨é€†å‘çº¹ç†æ˜ å°„å’ŒæŠ•å½±é‡‡æ ·æŠ€æœ¯ä»å•å¼ å›¾åƒæ¨æ–­ä¸ŠåŠèº«é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶é€šè¿‡ç¥ç»ç½‘ç»œè¿›è¡Œå›¾åƒæ¸²æŸ“ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGUAVAåœ¨æ¸²æŸ“è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºå…ˆå‰æ–¹æ³•ï¼Œå…·æœ‰äºšç§’çº§çš„é‡å»ºæ—¶é—´ï¼ˆ0.1ç§’ï¼‰ï¼Œå¹¶æ”¯æŒå®æ—¶åŠ¨ç”»å’Œæ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡å»ºé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„3Däººç±»è§’è‰²æ¨¡å‹æ˜¯ç ”ç©¶çš„çƒ­ç‚¹ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¤æ‚åº¦é«˜ã€è€—æ—¶è¾ƒé•¿ï¼Œä¸”é¢éƒ¨è¡¨æƒ…è¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚</li>
<li>ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†è¡¨è¾¾æ€§äººç±»æ¨¡å‹ï¼ˆEHMï¼‰ã€‚</li>
<li>åŸºäºEHMæ¨¡æ¿æ¨¡å‹ï¼Œæå‡ºäº†é¦–ä¸ªå¿«é€Ÿå¯åŠ¨ç”»çš„ä¸ŠåŠèº«3Dé«˜æ–¯è§’è‰²é‡å»ºæ¡†æ¶GUAVAã€‚</li>
<li>GUAVAåˆ©ç”¨é€†å‘çº¹ç†æ˜ å°„å’ŒæŠ•å½±é‡‡æ ·æŠ€æœ¯ä»å•å¼ å›¾åƒæ¨æ–­ä¸ŠåŠèº«é«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>GUAVAé€šè¿‡ç¥ç»ç½‘ç»œä¼˜åŒ–å›¾åƒæ¸²æŸ“è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03351">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b492c9c560198a974d0040ee385ce7f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cacc015185950b7a73906eff414d22d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8fa19a7ac5ea80320e38c6ea2b50231.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df44a82b04858e82c0ea72b0bdb1a9e5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Splatting-Data-Compression-with-Mixture-of-Priors"><a href="#3D-Gaussian-Splatting-Data-Compression-with-Mixture-of-Priors" class="headerlink" title="3D Gaussian Splatting Data Compression with Mixture of Priors"></a>3D Gaussian Splatting Data Compression with Mixture of Priors</h2><p><strong>Authors:Lei Liu, Zhenghao Chen, Dong Xu</strong></p>
<p>3D Gaussian Splatting (3DGS) data compression is crucial for enabling efficient storage and transmission in 3D scene modeling. However, its development remains limited due to inadequate entropy models and suboptimal quantization strategies for both lossless and lossy compression scenarios, where existing methods have yet to 1) fully leverage hyperprior information to construct robust conditional entropy models, and 2) apply fine-grained, element-wise quantization strategies for improved compression granularity. In this work, we propose a novel Mixture of Priors (MoP) strategy to simultaneously address these two challenges. Specifically, inspired by the Mixture-of-Experts (MoE) paradigm, our MoP approach processes hyperprior information through multiple lightweight MLPs to generate diverse prior features, which are subsequently integrated into the MoP feature via a gating mechanism. To enhance lossless compression, the resulting MoP feature is utilized as a hyperprior to improve conditional entropy modeling. Meanwhile, for lossy compression, we employ the MoP feature as guidance information in an element-wise quantization procedure, leveraging a prior-guided Coarse-to-Fine Quantization (C2FQ) strategy with a predefined quantization step value. Specifically, we expand the quantization step value into a matrix and adaptively refine it from coarse to fine granularity, guided by the MoP feature, thereby obtaining a quantization step matrix that facilitates element-wise quantization. Extensive experiments demonstrate that our proposed 3DGS data compression framework achieves state-of-the-art performance across multiple benchmarks, including Mip-NeRF360, BungeeNeRF, DeepBlending, and Tank&amp;Temples. </p>
<blockquote>
<p>3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰æ•°æ®å‹ç¼©å¯¹äºå®ç°ä¸‰ç»´åœºæ™¯å»ºæ¨¡ä¸­çš„é«˜æ•ˆå­˜å‚¨å’Œä¼ è¾“è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºå…¶ç†µæ¨¡å‹ä¸è¶³ä»¥åŠé’ˆå¯¹æ— æŸå’Œæœ‰æŸå‹ç¼©åœºæ™¯çš„é‡åŒ–ç­–ç•¥ä¸ä½³ï¼Œå…¶å¼€å‘ä»å—åˆ°é™åˆ¶ã€‚ç°æœ‰æ–¹æ³•å°šæœª1ï¼‰å……åˆ†åˆ©ç”¨è¶…å…ˆéªŒä¿¡æ¯æ¥æ„å»ºç¨³å¥çš„æ¡ä»¶ç†µæ¨¡å‹ï¼Œä»¥åŠ2ï¼‰åº”ç”¨ç²¾ç»†çš„ã€é€å…ƒç´ é‡åŒ–ç­–ç•¥æ¥æé«˜å‹ç¼©ç²’åº¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å…ˆéªŒæ··åˆï¼ˆMoPï¼‰ç­–ç•¥ï¼Œæ—¨åœ¨åŒæ—¶è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼Œå—åˆ°ä¸“å®¶æ··åˆï¼ˆMoEï¼‰èŒƒå¼çš„å¯å‘ï¼Œæˆ‘ä»¬çš„MoPæ–¹æ³•é€šè¿‡å¤šä¸ªè½»é‡çº§MLPå¤„ç†è¶…å…ˆéªŒä¿¡æ¯ï¼Œä»¥ç”Ÿæˆå¤šç§å…ˆéªŒç‰¹å¾ï¼Œç„¶åé€šè¿‡è¿™äº›ç‰¹å¾é€šè¿‡é—¨æ§æœºåˆ¶é›†æˆåˆ°MoPç‰¹å¾ä¸­ã€‚ä¸ºäº†å¢å¼ºæ— æŸå‹ç¼©ï¼Œä½¿ç”¨MoPç‰¹å¾ä½œä¸ºè¶…å…ˆéªŒä¿¡æ¯æ¥æ”¹å–„æ¡ä»¶ç†µå»ºæ¨¡ã€‚è€Œå¯¹äºæœ‰æŸå‹ç¼©ï¼Œæˆ‘ä»¬å°†MoPç‰¹å¾ä½œä¸ºé€å…ƒç´ é‡åŒ–è¿‡ç¨‹ä¸­çš„æŒ‡å¯¼ä¿¡æ¯ï¼Œé‡‡ç”¨å…ˆéªŒå¼•å¯¼çš„ç²—ç»†é‡åŒ–ï¼ˆC2FQï¼‰ç­–ç•¥ï¼Œå¹¶é¢„è®¾é‡åŒ–æ­¥é•¿å€¼ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†é‡åŒ–æ­¥é•¿å€¼æ‰©å±•ä¸ºçŸ©é˜µï¼Œå¹¶åœ¨MoPç‰¹å¾çš„å¼•å¯¼ä¸‹ä»ç²—åˆ°ç»†ç²’åº¦è¿›è¡Œè‡ªé€‚åº”ç»†åŒ–ï¼Œä»è€Œè·å¾—ä¿ƒè¿›é€å…ƒç´ é‡åŒ–çš„é‡åŒ–æ­¥é•¿çŸ©é˜µã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„3DGSæ•°æ®å‹ç¼©æ¡†æ¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬Mip-NeRF360ã€BungeeNeRFã€DeepBlendingå’ŒTank&amp;Templesã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03310v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºæ··åˆå…ˆéªŒï¼ˆMoPï¼‰ç­–ç•¥çš„æ”¹è¿›å‹ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹æ³•ï¼ˆ3DGSï¼‰æ•°æ®å‹ç¼©æ–¹æ³•ï¼Œä»¥è§£å†³ç°æœ‰çš„å‹ç¼©é—®é¢˜ã€‚æ­¤æ–¹æ³•èƒ½åŒæ—¶å¤„ç†ä¸¤ç±»é—®é¢˜ï¼šç¼ºä¹å…ˆéªŒä¿¡æ¯çš„å……åˆ†åˆ©ç”¨å’Œå¯¹æ— æŸå’ŒæŸå¤±å‹ç¼©åœºæ™¯ä¸­çš„æ¬¡ä¼˜é‡åŒ–ç­–ç•¥ã€‚é€šè¿‡å¼•å…¥æ··åˆä¸“å®¶ï¼ˆMoEï¼‰èŒƒå¼ï¼Œåˆ©ç”¨å¤šä¸ªè½»é‡çº§å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å¤„ç†å…ˆéªŒä¿¡æ¯ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„å…ˆéªŒç‰¹å¾ï¼Œå†é€šè¿‡é—¨æ§æœºåˆ¶é›†æˆåˆ°MoPç‰¹å¾ä¸­ã€‚å¯¹äºæ— æŸå‹ç¼©ï¼Œä½¿ç”¨MoPç‰¹å¾ä½œä¸ºè¶…å…ˆéªŒä¿¡æ¯æé«˜æ¡ä»¶ç†µå»ºæ¨¡ï¼›å¯¹äºæŸå¤±å‹ç¼©ï¼Œç»“åˆMoPç‰¹å¾è¿›è¡Œé€å…ƒç´ é‡åŒ–è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨å…ˆéªŒå¼•å¯¼çš„ç²—ç³™åˆ°ç²¾ç»†é‡åŒ–ï¼ˆC2FQï¼‰ç­–ç•¥ï¼Œæ ¹æ®é¢„è®¾çš„é‡åŒ–æ­¥é•¿å€¼è¿›è¡Œè°ƒæ•´ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šå–å¾—äº†å…ˆè¿›çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰åœ¨åˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹æ³•ï¼ˆ3DGSï¼‰è¿›è¡Œåœºæ™¯å»ºæ¨¡æ—¶é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šå¯¹è¶…å…ˆéªŒä¿¡æ¯çš„ä¸å……åˆ†ä½¿ç”¨å’Œé‡åŒ–ç­–ç•¥çš„ä¸è¶³ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ··åˆå…ˆéªŒï¼ˆMoPï¼‰ç­–ç•¥çš„æ”¹è¿›æ–¹æ³•ï¼Œæ—¨åœ¨åŒæ—¶è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äº†æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¡†æ¶çš„å¯å‘ï¼Œå¹¶ä½¿ç”¨å¤šä¸ªè½»é‡çº§å¤šå±‚æ„ŸçŸ¥å™¨å¤„ç†è¶…å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>MoPç‰¹å¾ç”¨äºæé«˜æ— æŸå‹ç¼©çš„æ¡ä»¶ç†µå»ºæ¨¡å’ŒæŸå¤±å‹ç¼©çš„é€å…ƒç´ é‡åŒ–è¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03310">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b91a2a0169426f654ef4576975bb07c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4138f53ae00de72fa3513b27a35d4977.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9cc17eebb26d852195fca1dbc0d35a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c220960af2c4d21747d215821a82b485.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Sparfels-Fast-Reconstruction-from-Sparse-Unposed-Imagery"><a href="#Sparfels-Fast-Reconstruction-from-Sparse-Unposed-Imagery" class="headerlink" title="Sparfels: Fast Reconstruction from Sparse Unposed Imagery"></a>Sparfels: Fast Reconstruction from Sparse Unposed Imagery</h2><p><strong>Authors:Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma</strong></p>
<p>We present a method for Sparse view reconstruction with surface element splatting that runs within 3 minutes on a consumer grade GPU. While few methods address sparse radiance field learning from noisy or unposed sparse cameras, shape recovery remains relatively underexplored in this setting. Several radiance and shape learning test-time optimization methods address the sparse posed setting by learning data priors or using combinations of external monocular geometry priors. Differently, we propose an efficient and simple pipeline harnessing a single recent 3D foundation model. We leverage its various task heads, notably point maps and camera initializations to instantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and image correspondences to guide camera optimization midst 2DGS training. Key to our contribution is a novel formulation of splatted color variance along rays, which can be computed efficiently. Reducing this moment in training leads to more accurate shape reconstructions. We demonstrate state-of-the-art performances in the sparse uncalibrated setting in reconstruction and novel view benchmarks based on established multi-view datasets. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢å…ƒç´ æ‹¼è´´æŠ€æœ¯çš„ç¨€ç–è§†å›¾é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œæ—¶é—´ä¸è¶…è¿‡3åˆ†é’Ÿã€‚å°½ç®¡å·²æœ‰å°‘æ•°æ–¹æ³•è§£å†³äº†ä»å™ªå£°æˆ–æœªæ ¡å‡†çš„ç¨€ç–ç›¸æœºä¸­å­¦ä¹ ç¨€ç–è¾å°„åœºçš„é—®é¢˜ï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½¢çŠ¶æ¢å¤çš„æ¢ç´¢ä»ç„¶ç›¸å¯¹è¾ƒå°‘ã€‚ä¸€äº›è¾å°„å’Œå½¢çŠ¶å­¦ä¹ æµ‹è¯•æ—¶é—´ä¼˜åŒ–æ–¹æ³•é€šè¿‡å­¦ä¹ æ•°æ®å…ˆéªŒæˆ–ä½¿ç”¨å¤–éƒ¨å•çœ¼å‡ ä½•å…ˆéªŒçš„ç»„åˆæ¥è§£å†³ç¨€ç–å®šä½è®¾ç½®é—®é¢˜ã€‚ä¸ä¹‹ä¸åŒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆä¸”ç®€å•çš„æµç¨‹ï¼Œåˆ©ç”¨äº†ä¸€ä¸ªæœ€æ–°çš„å•ä¸€3DåŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬åˆ©ç”¨è¯¥æ¨¡å‹çš„å„ç§ä»»åŠ¡å¤´ï¼Œç‰¹åˆ«æ˜¯ç‚¹å›¾å’Œç›¸æœºåˆå§‹åŒ–æ¥å®ä¾‹åŒ–ä¸€ä¸ªè°ƒæ•´æŸçš„äºŒç»´é«˜æ–¯æ‹¼è´´ï¼ˆ2DGSï¼‰æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å›¾åƒå¯¹åº”å…³ç³»æ¥æŒ‡å¯¼åœ¨2DGSè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›¸æœºä¼˜åŒ–ã€‚æˆ‘ä»¬è´¡çŒ®çš„å…³é”®åœ¨äºæ²¿å…‰çº¿æ‹¼è´´é¢œè‰²æ–¹å·®çš„æ–°å…¬å¼ï¼Œè¯¥å…¬å¼å¯ä»¥é«˜æ•ˆè®¡ç®—ã€‚åœ¨è®­ç»ƒä¸­å‡å°‘è¿™ä¸€æ—¶åˆ»ä¼šå¯¼è‡´æ›´å‡†ç¡®çš„å½¢çŠ¶é‡å»ºã€‚æˆ‘ä»¬åœ¨ç¨€ç–æœªæ ¡å‡†è®¾ç½®ä¸‹çš„é‡å»ºå’ŒåŸºäºå¤šè§†å›¾æ•°æ®é›†çš„æ–°è§†å›¾åŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02178v1">PDF</a> Project page : <a target="_blank" rel="noopener" href="https://shubhendu-jena.github.io/Sparfels/">https://shubhendu-jena.github.io/Sparfels/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢å…ƒç´ æ‹¼è´´æŠ€æœ¯çš„ç¨€ç–è§†è§’é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œæ—¶é—´ä¸è¶…è¿‡3åˆ†é’Ÿã€‚å°½ç®¡å·²æœ‰ä¸€äº›æ–¹æ³•è§£å†³äº†ç¨€ç–è¾å°„åœºå­¦ä¹ çš„é—®é¢˜ï¼Œä½†åœ¨å™ªå£°æˆ–æ— å§¿æ€ç¨€ç–ç›¸æœºçš„æƒ…å†µä¸‹ï¼Œå½¢çŠ¶æ¢å¤çš„æ¢ç´¢ç›¸å¯¹è¾ƒå°‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸åŒäºç°æœ‰çš„æµ‹è¯•æ—¶é—´ä¼˜åŒ–æ–¹æ³•ï¼Œå¦‚å­¦ä¹ æ•°æ®å…ˆéªŒæˆ–ç»“åˆå¤–éƒ¨å•çœ¼å‡ ä½•å…ˆéªŒæŠ€æœ¯æ¥å¤„ç†ç¨€ç–æœ‰å§¿æ€åœºæ™¯ï¼Œè€Œæ˜¯ä½¿ç”¨å•ä¸ªæœ€è¿‘çš„3DåŸºç¡€æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆä¸”ç®€å•çš„ç®¡é“ã€‚æˆ‘ä»¬åˆ©ç”¨è¯¥æ¨¡å‹çš„å„ç§ä»»åŠ¡å¤´ï¼Œç‰¹åˆ«æ˜¯ç‚¹å›¾å’Œç›¸æœºåˆå§‹åŒ–æ¥å»ºç«‹æŸè°ƒæ•´äºŒç»´é«˜æ–¯æ‹¼è´´æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å›¾åƒå¯¹åº”å…³ç³»æ¥æŒ‡å¯¼ç›¸æœºä¼˜åŒ–åœ¨äºŒç»´GSè®­ç»ƒä¸­çš„ä½ç½®ã€‚æœ¬æ–‡çš„å…³é”®è´¡çŒ®æ˜¯æ²¿å°„çº¿æ‹¼è´´é¢œè‰²æ–¹å·®çš„æ–°å…¬å¼ï¼Œå¯ä»¥é«˜æ•ˆè®¡ç®—ã€‚å‡å°‘è®­ç»ƒä¸­çš„è¿™ä¸ªçŸ©ä¼šæé«˜å½¢çŠ¶é‡å»ºçš„å‡†ç¡®æ€§ã€‚åœ¨ç¨€ç–æœªæ ¡å‡†æƒ…å†µä¸‹é‡å»ºå’Œæ–°è§†è§’è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸºäºå¤šè§†è§’æ•°æ®é›†çš„å®éªŒä¸­è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>è¦ç‚¹æ€»ç»“</strong></p>
<p>ä¸€ã€æå‡ºäº†ä¸€ä¸ªé«˜æ•ˆã€åŸºäºè¡¨é¢å…ƒç´ æ‹¼è´´çš„ç¨€ç–è§†è§’é‡å»ºæ–¹æ³•ï¼Œåœ¨æ¶ˆè´¹è€…çº§åˆ«çš„GPUä¸Šè¿è¡Œæ—¶é—´ä¸ºä¸‰åˆ†é’Ÿä»¥å†…ã€‚<br>äºŒã€è™½ç„¶å…¶ä»–æ–¹æ³•è§£å†³äº†ç¨€ç–è¾å°„åœºå­¦ä¹ çš„é—®é¢˜ï¼Œä½†åœ¨å™ªå£°æˆ–æ— å§¿æ€ç¨€ç–ç›¸æœºç¯å¢ƒä¸‹çš„å½¢çŠ¶æ¢å¤ä»ç„¶ç›¸å¯¹æœªè¢«å……åˆ†æ¢ç´¢ã€‚<br>ä¸‰ã€ä¸åŒäºç°æœ‰çš„æµ‹è¯•æ—¶é—´ä¼˜åŒ–æ–¹æ³•å¦‚å­¦ä¹ æ•°æ®å…ˆéªŒç­‰å¤„ç†ç¨€ç–æœ‰å§¿æ€åœºæ™¯ï¼Œé‡‡ç”¨å•ä¸ªè¿‘æœŸçš„ä¸‰ç»´åŸºç¡€æ¨¡å‹ã€‚æå‡ºäº†ç‚¹å›¾å’Œç›¸æœºåˆå§‹åŒ–ç­‰ä»»åŠ¡å¤´ç”¨äºå»ºç«‹äºŒç»´é«˜æ–¯æ‹¼è´´æ¨¡å‹ï¼ˆ2DGSï¼‰ã€‚åˆ©ç”¨å›¾åƒå¯¹åº”å…³ç³»æŒ‡å¯¼ç›¸æœºä¼˜åŒ–åœ¨äºŒç»´GSè®­ç»ƒä¸­çš„ä½ç½®ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-63f0fac03c79aab4628966372d5fbfab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff042d4b5e6d569f6eaed2de3f8b3c67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe35f6118a4c3163b8e371d12fa54c48.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SparSplat-Fast-Multi-View-Reconstruction-with-Generalizable-2D-Gaussian-Splatting"><a href="#SparSplat-Fast-Multi-View-Reconstruction-with-Generalizable-2D-Gaussian-Splatting" class="headerlink" title="SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian   Splatting"></a>SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian   Splatting</h2><p><strong>Authors:Shubhendu Jena, Shishir Reddy Vutukur, Adnane Boukhayma</strong></p>
<p>Recovering 3D information from scenes via multi-view stereo reconstruction (MVS) and novel view synthesis (NVS) is inherently challenging, particularly in scenarios involving sparse-view setups. The advent of 3D Gaussian Splatting (3DGS) enabled real-time, photorealistic NVS. Following this, 2D Gaussian Splatting (2DGS) leveraged perspective accurate 2D Gaussian primitive rasterization to achieve accurate geometry representation during rendering, improving 3D scene reconstruction while maintaining real-time performance. Recent approaches have tackled the problem of sparse real-time NVS using 3DGS within a generalizable, MVS-based learning framework to regress 3D Gaussian parameters. Our work extends this line of research by addressing the challenge of generalizable sparse 3D reconstruction and NVS jointly, and manages to perform successfully at both tasks. We propose an MVS-based learning pipeline that regresses 2DGS surface element parameters in a feed-forward fashion to perform 3D shape reconstruction and NVS from sparse-view images. We further show that our generalizable pipeline can benefit from preexisting foundational multi-view deep visual features. The resulting model attains the state-of-the-art results on the DTU sparse 3D reconstruction benchmark in terms of Chamfer distance to ground-truth, as-well as state-of-the-art NVS. It also demonstrates strong generalization on the BlendedMVS and Tanks and Temples datasets. We note that our model outperforms the prior state-of-the-art in feed-forward sparse view reconstruction based on volume rendering of implicit representations, while offering an almost 2 orders of magnitude higher inference speed. </p>
<blockquote>
<p>ä»åœºæ™¯æ¢å¤ä¸‰ç»´ä¿¡æ¯ï¼Œé€šè¿‡å¤šè§†å›¾ç«‹ä½“é‡å»ºï¼ˆMVSï¼‰å’Œæ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰æœ¬è´¨ä¸Šå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠç¨€ç–è§†å›¾è®¾ç½®çš„æƒ…å†µä¸‹ã€‚ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰çš„å‡ºç°ï¼Œå®ç°äº†å®æ—¶ã€é€¼çœŸçš„NVSã€‚ä¹‹åï¼ŒäºŒç»´é«˜æ–¯å¹³é“ºï¼ˆ2DGSï¼‰åˆ©ç”¨é€è§†å‡†ç¡®çš„äºŒç»´é«˜æ–¯åŸå§‹æ …æ ¼åŒ–ï¼Œåœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­å®ç°å‡†ç¡®çš„ä¸‰ç»´å‡ ä½•è¡¨ç¤ºï¼Œæé«˜äº†ä¸‰ç»´åœºæ™¯é‡å»ºçš„å®æ—¶æ€§èƒ½ã€‚æœ€è¿‘çš„æ–¹æ³•è§£å†³äº†ç¨€ç–å®æ—¶NVSçš„é—®é¢˜ï¼Œä½¿ç”¨é€šç”¨åŸºäºMVSçš„å­¦ä¹ æ¡†æ¶å†…çš„3DGSæ¥å›å½’ä¸‰ç»´é«˜æ–¯å‚æ•°ã€‚æˆ‘ä»¬çš„å·¥ä½œé€šè¿‡è§£å†³å¯æ³›åŒ–çš„ç¨€ç–ä¸‰ç»´é‡å»ºå’ŒNVSè”åˆæŒ‘æˆ˜æ¥æ‰©å±•è¿™ä¸€ç ”ç©¶é¢†åŸŸï¼Œå¹¶åœ¨ä¸¤é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†æˆåŠŸã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºMVSçš„å­¦ä¹ æµæ°´çº¿ï¼Œä»¥å‰é¦ˆæ–¹å¼å›å½’äºŒç»´GSè¡¨é¢å…ƒç´ å‚æ•°ï¼Œä»ç¨€ç–è§†å›¾å›¾åƒè¿›è¡Œä¸‰ç»´å½¢çŠ¶é‡å»ºå’ŒNVSã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¯æ³›åŒ–ç®¡é“å¯ä»¥ä»ç°æœ‰çš„å¤šè§†è§’æ·±åº¦è§†è§‰ç‰¹å¾ä¸­å—ç›Šã€‚æ‰€å¾—æ¨¡å‹åœ¨DTUç¨€ç–ä¸‰ç»´é‡å»ºåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œè¡¨ç°åœ¨ä¸çœŸå®å€¼çš„Chamferè·ç¦»ä»¥åŠå…ˆè¿›çš„NVSä¸Šã€‚å®ƒåœ¨BlendedMVSå’ŒTanks and Templesæ•°æ®é›†ä¸Šä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨åŸºäºéšå¼è¡¨ç¤ºçš„ä½“ç§¯æ¸²æŸ“çš„å‰é¦ˆç¨€ç–è§†å›¾é‡å»ºæ–¹é¢ä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼ŒåŒæ—¶æ¨ç†é€Ÿåº¦æé«˜äº†è¿‘ä¸¤ä¸ªæ•°é‡çº§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02175v1">PDF</a> Project page : <a target="_blank" rel="noopener" href="https://shubhendu-jena.github.io/SparSplat/">https://shubhendu-jena.github.io/SparSplat/</a></p>
<p><strong>æ‘˜è¦</strong><br>    åˆ©ç”¨åŸºäºå¤šè§†å›¾ç«‹ä½“é‡å»ºï¼ˆMVSï¼‰å’Œæ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰çš„3Dé«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œå®ç°ç¨€ç–è§†è§’ä¸‹çš„å®æ—¶ã€é€¼çœŸçš„NVSã€‚æå‡ºä¸€ç§MVSå­¦ä¹ ç®¡é“ï¼Œä»¥å›å½’2DGSè¡¨é¢å…ƒç´ å‚æ•°çš„æ–¹å¼è¿›è¡Œå‰é¦ˆï¼Œå®ç°ä»ç¨€ç–è§†è§’å›¾åƒè¿›è¡Œ3Då½¢çŠ¶é‡å»ºå’ŒNVSã€‚è¯¥ç®¡é“èƒ½å¤ŸæˆåŠŸåº”å¯¹é€šç”¨ç¨€ç–3Dé‡å»ºå’ŒNVSçš„æŒ‘æˆ˜ï¼Œå¹¶ä»ç°æœ‰çš„å¤šè§†è§’æ·±åº¦è§†è§‰ç‰¹å¾ä¸­å—ç›Šã€‚åœ¨DTUç¨€ç–3Dé‡å»ºåŸºå‡†æµ‹è¯•ã€æ–°é¢–è§†å›¾åˆæˆä»¥åŠBlendedMVSå’ŒTanks and Templesæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œæœ€å…ˆè¿›çš„ç»“æœã€‚ä¸åŸºäºä½“ç§¯æ¸²æŸ“çš„éšå¼è¡¨ç¤ºçš„å‰é¦ˆç¨€ç–è§†å›¾é‡å»ºçš„ç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹çš„æ¨ç†é€Ÿåº¦æé«˜äº†è¿‘ä¸¤ä¸ªæ•°é‡çº§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç¨€ç–è§†è§’ä¸‹çš„å¤šè§†å›¾ç«‹ä½“é‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>3Dé«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰æŠ€æœ¯å®ç°äº†å®æ—¶ã€é€¼çœŸçš„æ–°é¢–è§†å›¾åˆæˆã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºMVSçš„å­¦ä¹ ç®¡é“ï¼Œé€šè¿‡å›å½’2DGSè¡¨é¢å…ƒç´ å‚æ•°è¿›è¡Œå‰é¦ˆï¼Œå®ç°3Då½¢çŠ¶é‡å»ºå’ŒNVSã€‚</li>
<li>è¯¥ç®¡é“èƒ½å¤ŸæˆåŠŸåº”å¯¹é€šç”¨ç¨€ç–3Dé‡å»ºå’ŒNVSçš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰å¤šè§†è§’æ·±åº¦è§†è§‰ç‰¹å¾å¯ä»¥å—ç›Šäºè¯¥å­¦ä¹ ç®¡é“ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’Œæ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œæœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>ä¸å…¶ä»–æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹çš„æ¨ç†é€Ÿåº¦æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02175">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f465fe955bf4a9704e2cde9b704dd596.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5df00cfe95543b66820c8440882b65d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d986aa291a130df314e574a7b0cb055.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SignSplat-Rendering-Sign-Language-via-Gaussian-Splatting"><a href="#SignSplat-Rendering-Sign-Language-via-Gaussian-Splatting" class="headerlink" title="SignSplat: Rendering Sign Language via Gaussian Splatting"></a>SignSplat: Rendering Sign Language via Gaussian Splatting</h2><p><strong>Authors:Maksym Ivashechkin, Oscar Mendez, Richard Bowden</strong></p>
<p>State-of-the-art approaches for conditional human body rendering via Gaussian splatting typically focus on simple body motions captured from many views. This is often in the context of dancing or walking. However, for more complex use cases, such as sign language, we care less about large body motion and more about subtle and complex motions of the hands and face. The problems of building high fidelity models are compounded by the complexity of capturing multi-view data of sign. The solution is to make better use of sequence data, ensuring that we can overcome the limited information from only a few views by exploiting temporal variability. Nevertheless, learning from sequence-level data requires extremely accurate and consistent model fitting to ensure that appearance is consistent across complex motions. We focus on how to achieve this, constraining mesh parameters to build an accurate Gaussian splatting framework from few views capable of modelling subtle human motion. We leverage regularization techniques on the Gaussian parameters to mitigate overfitting and rendering artifacts. Additionally, we propose a new adaptive control method to densify Gaussians and prune splat points on the mesh surface. To demonstrate the accuracy of our approach, we render novel sequences of sign language video, building on neural machine translation approaches to sign stitching. On benchmark datasets, our approach achieves state-of-the-art performance; and on highly articulated and complex sign language motion, we significantly outperform competing approaches. </p>
<blockquote>
<p>ç›®å‰æœ€å‰æ²¿çš„é€šè¿‡é«˜æ–¯å¹³é“ºæŠ€æœ¯å®ç°æ¡ä»¶æ€§äººä½“æ¸²æŸ“çš„æ–¹æ³•ä¸»è¦å…³æ³¨ä»å¤šä¸ªè§†è§’æ•æ‰çš„ç®€å•èº«ä½“åŠ¨ä½œï¼Œè¿™å¸¸å¸¸åœ¨èˆè¹ˆæˆ–è¡Œèµ°çš„æƒ…å¢ƒä¸­ã€‚ç„¶è€Œï¼Œå¯¹äºæ›´å¤æ‚çš„ç”¨ä¾‹ï¼Œå¦‚æ‰‹è¯­ï¼Œæˆ‘ä»¬æ›´å…³æ³¨æ‰‹å’Œè„¸éƒ¨çš„ç»†å¾®å’Œå¤æ‚åŠ¨ä½œï¼Œè€Œéå¤§åŠ¨ä½œã€‚æ„å»ºé«˜ä¿çœŸæ¨¡å‹çš„é—®é¢˜åœ¨äºæ‰‹è¯­çš„å¤šè§†è§’æ•°æ®æ•æ‰çš„å¤æ‚æ€§ã€‚è§£å†³æ–¹æ¡ˆæ˜¯æ›´å¥½åœ°åˆ©ç”¨åºåˆ—æ•°æ®ï¼Œç¡®ä¿æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨æ—¶é—´å˜åŒ–æ€§æ¥å…‹æœä»…æ¥è‡ªå°‘æ•°è§†è§’çš„æœ‰é™ä¿¡æ¯ã€‚ç„¶è€Œï¼Œä»åºåˆ—çº§åˆ«çš„æ•°æ®ä¸­å­¦ä¹ éœ€è¦æå…¶ç²¾ç¡®å’Œä¸€è‡´çš„æ¨¡å‹æ‹Ÿåˆï¼Œä»¥ç¡®ä¿åœ¨å¤æ‚çš„åŠ¨ä½œä¸­å¤–è§‚çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬ä¸“æ³¨äºå¦‚ä½•å®ç°è¿™ä¸€ç‚¹ï¼Œé€šè¿‡çº¦æŸç½‘æ ¼å‚æ•°æ¥æ„å»ºä¸€ä¸ªå‡†ç¡®çš„é«˜æ–¯å¹³é“ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»æœ‰é™çš„è§†è§’å¯¹å¾®å¦™çš„äººä½“è¿åŠ¨è¿›è¡Œå»ºæ¨¡ã€‚æˆ‘ä»¬å¯¹é«˜æ–¯å‚æ•°é‡‡ç”¨æ­£åˆ™åŒ–æŠ€æœ¯æ¥ç¼“è§£è¿‡åº¦æ‹Ÿåˆå’Œæ¸²æŸ“ä¼ªå½±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”æ§åˆ¶æ–¹æ³•æ¥å¯†é›†åŒ–é«˜æ–¯å¹¶ç²¾ç®€ç½‘æ ¼è¡¨é¢çš„å¹³é“ºç‚¹ã€‚ä¸ºäº†è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬åœ¨ç¥ç»æœºå™¨ç¿»è¯‘æ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œæ¸²æŸ“äº†æ–°çš„æ‰‹è¯­è§†é¢‘åºåˆ—ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼›åœ¨é«˜åº¦ç²¾ç»†ä¸”å¤æ‚çš„æ‰‹è¯­åŠ¨ä½œä¸Šï¼Œæˆ‘ä»¬æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02108v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºåºåˆ—æ•°æ®çš„æ¡ä»¶äººä½“æ¸²æŸ“æ–¹æ³•ï¼Œé’ˆå¯¹å¤æ‚çš„æ‰‹åŠ¿å’Œé¢éƒ¨è¡¨æƒ…è¿›è¡Œç²¾ç»†å»ºæ¨¡ã€‚é€šè¿‡åˆ©ç”¨é«˜æ–¯æ˜ å°„æŠ€æœ¯ï¼Œä»æœ‰é™è§†è§’æ„å»ºå‡†ç¡®çš„æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨æ­£åˆ™åŒ–æŠ€æœ¯é¿å…è¿‡æ‹Ÿåˆå’Œæ¸²æŸ“ç‘•ç–µã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”æ§åˆ¶æ–¹æ³•ï¼Œç”¨äºåœ¨ç½‘æ ¼è¡¨é¢ç»†åŒ–é«˜æ–¯å¹¶åˆ é™¤æº…ç‚¹ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶åœ¨é«˜åº¦ç²¾ç»†å’Œå¤æ‚çš„æ ‡å¿—è¯­è¨€è¿åŠ¨ä¸­æ˜¾è‘—ä¼˜äºç«äº‰å¯¹æ‰‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡å…³æ³¨å¤æ‚æ‰‹åŠ¿å’Œé¢éƒ¨è¡¨æƒ…çš„ç²¾ç»†å»ºæ¨¡ï¼Œå¦‚æ ‡å¿—è¯­è¨€ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºåºåˆ—æ•°æ®çš„æ¡ä»¶äººä½“æ¸²æŸ“æ–¹æ³•ï¼Œå…‹æœæœ‰é™è§†è§’ä¿¡æ¯çš„ä¸è¶³ã€‚</li>
<li>åˆ©ç”¨é«˜æ–¯æ˜ å°„æŠ€æœ¯æ„å»ºå‡†ç¡®æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨æ­£åˆ™åŒ–æŠ€æœ¯é¿å…è¿‡æ‹Ÿåˆå’Œæ¸²æŸ“ç‘•ç–µã€‚</li>
<li>å¼•å…¥æ–°çš„è‡ªé€‚åº”æ§åˆ¶æ–¹æ³•ï¼Œç”¨äºç»†åŒ–é«˜æ–¯å¹¶åœ¨ç½‘æ ¼è¡¨é¢åˆ é™¤æº…ç‚¹ã€‚</li>
<li>æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>åœ¨é«˜åº¦ç²¾ç»†å’Œå¤æ‚çš„æ ‡å¿—è¯­è¨€è¿åŠ¨ä¸­æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02108">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-90f7f48c0eb67edf063202e80054ba9b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f62a8795f98305600bb2001d3dfb4410.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ea0111a7f7b185fa41141bce7b4d26ac.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="HybridGS-High-Efficiency-Gaussian-Splatting-Data-Compression-using-Dual-Channel-Sparse-Representation-and-Point-Cloud-Encoder"><a href="#HybridGS-High-Efficiency-Gaussian-Splatting-Data-Compression-using-Dual-Channel-Sparse-Representation-and-Point-Cloud-Encoder" class="headerlink" title="HybridGS: High-Efficiency Gaussian Splatting Data Compression using   Dual-Channel Sparse Representation and Point Cloud Encoder"></a>HybridGS: High-Efficiency Gaussian Splatting Data Compression using   Dual-Channel Sparse Representation and Point Cloud Encoder</h2><p><strong>Authors:Qi Yang, Le Yang, Geert Van Der Auwera, Zhu Li</strong></p>
<p>Most existing 3D Gaussian Splatting (3DGS) compression schemes focus on producing compact 3DGS representation via implicit data embedding. They have long coding times and highly customized data format, making it difficult for widespread deployment. This paper presents a new 3DGS compression framework called HybridGS, which takes advantage of both compact generation and standardized point cloud data encoding. HybridGS first generates compact and explicit 3DGS data. A dual-channel sparse representation is introduced to supervise the primitive position and feature bit depth. It then utilizes a canonical point cloud encoder to perform further data compression and form standard output bitstreams. A simple and effective rate control scheme is proposed to pivot the interpretable data compression scheme. At the current stage, HybridGS does not include any modules aimed at improving 3DGS quality during generation. But experiment results show that it still provides comparable reconstruction performance against state-of-the-art methods, with evidently higher encoding and decoding speed. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/Qi-Yangsjtu/HybridGS">https://github.com/Qi-Yangsjtu/HybridGS</a>. </p>
<blockquote>
<p>ç°æœ‰çš„å¤§å¤šæ•°3Dé«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰å‹ç¼©æ–¹æ¡ˆä¸»è¦ä¾§é‡äºé€šè¿‡éšå¼æ•°æ®åµŒå…¥ç”Ÿæˆç´§å‡‘çš„3DGSè¡¨ç¤ºã€‚å®ƒä»¬å…·æœ‰è¾ƒé•¿çš„ç¼–ç æ—¶é—´å’Œé«˜åº¦å®šåˆ¶çš„æ•°æ®æ ¼å¼ï¼Œä½¿å¾—éš¾ä»¥å¹¿æ³›éƒ¨ç½²ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„3DGSå‹ç¼©æ¡†æ¶ï¼Œç§°ä¸ºHybridGSï¼Œå®ƒç»“åˆäº†ç´§å‡‘ç”Ÿæˆå’Œæ ‡å‡†åŒ–ç‚¹äº‘æ•°æ®ç¼–ç ã€‚HybridGSé¦–å…ˆç”Ÿæˆç´§å‡‘ä¸”æ˜¾å¼çš„3DGSæ•°æ®ã€‚å¼•å…¥åŒé€šé“ç¨€ç–è¡¨ç¤ºæ¥ç›‘ç£åŸå§‹ä½ç½®å’Œç‰¹å¾ä½æ·±åº¦ã€‚ç„¶åï¼Œå®ƒåˆ©ç”¨æ ‡å‡†ç‚¹äº‘ç¼–ç å™¨æ‰§è¡Œè¿›ä¸€æ­¥çš„æ•°æ®å‹ç¼©å¹¶å½¢æˆæ ‡å‡†è¾“å‡ºæ¯”ç‰¹æµã€‚æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„é€Ÿç‡æ§åˆ¶æ–¹æ¡ˆï¼Œä»¥è°ƒæ•´å¯è§£é‡Šçš„æ•°æ®å‹ç¼©æ–¹æ¡ˆã€‚ç›®å‰é˜¶æ®µï¼ŒHybridGSä¸åŒ…æ‹¬ä»»ä½•æ—¨åœ¨æé«˜ç”Ÿæˆè¿‡ç¨‹ä¸­çš„3DGSè´¨é‡çš„æ¨¡å—ã€‚ä½†å®éªŒç»“æœè¡¨æ˜ï¼Œå®ƒä»ç„¶æä¾›äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„é‡æ„æ€§èƒ½ï¼Œå¹¶ä¸”ç¼–ç å’Œè§£ç é€Ÿåº¦æ˜æ˜¾æ›´é«˜ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Qi-Yangsjtu/HybridGS%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Qi-Yangsjtu/HybridGSè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01938v1">PDF</a> Accepted by ICML2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„3DGSå‹ç¼©æ¡†æ¶HybridGSï¼Œç»“åˆäº†ç´§å‡‘ç”Ÿæˆå’Œæ ‡å‡†åŒ–ç‚¹äº‘æ•°æ®ç¼–ç ã€‚è¯¥æ¡†æ¶æ—¨åœ¨è§£å†³ç°æœ‰å‹ç¼©æ–¹æ¡ˆç¼–ç æ—¶é—´é•¿ã€æ•°æ®æ ¼å¼é«˜åº¦å®šåˆ¶åŒ–çš„é—®é¢˜ï¼Œä½¿å¾—éƒ¨ç½²å›°éš¾ã€‚HybridGSé€šè¿‡å¼•å…¥åŒé€šé“ç¨€ç–è¡¨ç¤ºå’Œé€Ÿç‡æ§åˆ¶æ–¹æ¡ˆï¼Œå®ç°äº†å¿«é€Ÿä¸”æœ‰æ•ˆçš„æ•°æ®å‹ç¼©ï¼ŒåŒæ—¶åœ¨ç”Ÿæˆæ€§èƒ½ä¸Šä¸å…¶ä»–å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ä»å…·æœ‰ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HybridGSç»“åˆäº†ç´§å‡‘ç”Ÿæˆå’Œæ ‡å‡†åŒ–ç‚¹äº‘æ•°æ®ç¼–ç ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰3DGSå‹ç¼©æ–¹æ¡ˆçš„ç¼ºé™·ã€‚</li>
<li>å¼•å…¥åŒé€šé“ç¨€ç–è¡¨ç¤ºï¼Œç”¨äºç›‘ç£åŸå§‹æ•°æ®çš„ä½æ·±åº¦ã€‚</li>
<li>åˆ©ç”¨æ ‡å‡†ç‚¹äº‘ç¼–ç å™¨è¿›è¡Œè¿›ä¸€æ­¥çš„æ•°æ®å‹ç¼©ï¼Œå½¢æˆæ ‡å‡†è¾“å‡ºæ¯”ç‰¹æµã€‚</li>
<li>æå‡ºç®€å•æœ‰æ•ˆçš„é€Ÿç‡æ§åˆ¶æ–¹æ¡ˆï¼Œä»¥æ”¯æŒå¯è§£é‡Šçš„æ•°æ®å‹ç¼©ã€‚</li>
<li>HybridGSç›®å‰ä¸ä¸“æ³¨äºæé«˜ç”Ÿæˆé˜¶æ®µçš„3DGSè´¨é‡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒHybridGSåœ¨é‡å»ºæ€§èƒ½ä¸Šä¸å…¶ä»–å…ˆè¿›æŠ€æœ¯ç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01938">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3d11123b58d497120c74bf5f8c1ecf6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2132851d3405cec026b35e4035a9c328.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72f6a92e097d983f161d1e254745146c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GenSync-A-Generalized-Talking-Head-Framework-for-Audio-driven-Multi-Subject-Lip-Sync-using-3D-Gaussian-Splatting"><a href="#GenSync-A-Generalized-Talking-Head-Framework-for-Audio-driven-Multi-Subject-Lip-Sync-using-3D-Gaussian-Splatting" class="headerlink" title="GenSync: A Generalized Talking Head Framework for Audio-driven   Multi-Subject Lip-Sync using 3D Gaussian Splatting"></a>GenSync: A Generalized Talking Head Framework for Audio-driven   Multi-Subject Lip-Sync using 3D Gaussian Splatting</h2><p><strong>Authors:Anushka Agarwal, Muhammad Yusuf Hassan, Talha Chafekar</strong></p>
<p>We introduce GenSync, a novel framework for multi-identity lip-synced video synthesis using 3D Gaussian Splatting. Unlike most existing 3D methods that require training a new model for each identity , GenSync learns a unified network that synthesizes lip-synced videos for multiple speakers. By incorporating a Disentanglement Module, our approach separates identity-specific features from audio representations, enabling efficient multi-identity video synthesis. This design reduces computational overhead and achieves 6.8x faster training compared to state-of-the-art models, while maintaining high lip-sync accuracy and visual quality. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†GenSyncï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨3Dé«˜æ–¯å–·ç»˜æŠ€æœ¯å®ç°å¤šèº«ä»½å”‡åŒæ­¥è§†é¢‘åˆæˆçš„æ–°å‹æ¡†æ¶ã€‚ä¸å¤§å¤šæ•°ç°æœ‰3Dæ–¹æ³•éœ€è¦ä¸ºæ¯ä¸ªèº«ä»½è®­ç»ƒæ–°æ¨¡å‹ä¸åŒï¼ŒGenSyncå­¦ä¹ äº†ä¸€ä¸ªç»Ÿä¸€ç½‘ç»œï¼Œè¯¥ç½‘ç»œå¯ä»¥ä¸ºå¤šä¸ªè¯´è¯è€…åˆæˆå”‡åŒæ­¥è§†é¢‘ã€‚é€šè¿‡èå…¥åˆ†ç¦»æ¨¡å—ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå°†èº«ä»½ç‰¹å®šç‰¹å¾ä»éŸ³é¢‘è¡¨ç¤ºä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„å¤šèº«ä»½è§†é¢‘åˆæˆã€‚è¿™ç§è®¾è®¡å‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”å®ç°äº†6.8å€çš„å¿«é€Ÿè®­ç»ƒï¼ŒåŒæ—¶ä¿æŒäº†é«˜å”‡åŒæ­¥ç²¾åº¦å’Œè§†è§‰è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01928v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>GenSyncæ˜¯ä¸€ä¸ªåŸºäº3Dé«˜æ–¯è´´å›¾çš„å¤šèº«ä»½å”‡åŒæ­¥è§†é¢‘åˆæˆæ–°æ¡†æ¶ã€‚ä¸å…¶ä»–å¤§å¤šæ•°éœ€è¦ä¸ºæ¯ä¸ªèº«ä»½è®­ç»ƒæ–°æ¨¡å‹çš„3Dæ–¹æ³•ä¸åŒï¼ŒGenSyncå­¦ä¹ ä¸€ä¸ªç»Ÿä¸€ç½‘ç»œï¼Œä¸ºå¤šä¸ªè¯´è¯è€…åˆæˆå”‡åŒæ­¥è§†é¢‘ã€‚é€šè¿‡èå…¥åˆ†ç¦»æ¨¡å—ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»éŸ³é¢‘è¡¨ç¤ºä¸­åˆ†ç¦»å‡ºèº«ä»½ç‰¹å®šç‰¹å¾ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„å¤šèº«ä»½è§†é¢‘åˆæˆã€‚è¿™ç§è®¾è®¡å‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œå¹¶ä¸”ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”ï¼Œè®­ç»ƒé€Ÿåº¦æé«˜äº†6.8å€ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å”‡åŒæ­¥ç²¾åº¦å’Œè§†è§‰è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>GenSyncæ˜¯ä¸€ä¸ªç”¨äºå¤šèº«ä»½å”‡åŒæ­¥è§†é¢‘åˆæˆçš„æ–°æ¡†æ¶ã€‚</li>
<li>GenSyncé‡‡ç”¨3Dé«˜æ–¯è´´å›¾æŠ€æœ¯ã€‚</li>
<li>GenSyncå­¦ä¹ ä¸€ä¸ªç»Ÿä¸€ç½‘ç»œæ¥å¤„ç†å¤šä¸ªè¯´è¯è€…çš„è§†é¢‘åˆæˆã€‚</li>
<li>é€šè¿‡Disentanglement Moduleï¼ŒGenSyncèƒ½å¤Ÿä»éŸ³é¢‘è¡¨ç¤ºä¸­åˆ†ç¦»èº«ä»½ç‰¹å®šç‰¹å¾ã€‚</li>
<li>GenSyncå‡å°‘äº†è®¡ç®—å¼€é”€ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ¯”ç°æœ‰æŠ€æœ¯å¿«6.8å€ã€‚</li>
<li>GenSyncä¿æŒäº†é«˜å”‡åŒæ­¥ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01928">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-647018c3a094dbbdc0f5f95dd099c761.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c80d31535446e25f1fe4c00dcf96020b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2be47ba2c95a6ff5a0275ba616707753.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-017f70489e8edd59e6f27c2627b85e88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c9f3af86e5d39525ae4c4d5b9305703.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Visual-enhancement-and-3D-representation-for-underwater-scenes-a-review"><a href="#Visual-enhancement-and-3D-representation-for-underwater-scenes-a-review" class="headerlink" title="Visual enhancement and 3D representation for underwater scenes: a review"></a>Visual enhancement and 3D representation for underwater scenes: a review</h2><p><strong>Authors:Guoxi Huang, Haoran Wang, Brett Seymour, Evan Kovacs, John Ellerbrock, Dave Blackham, Nantheera Anantrasirichai</strong></p>
<p>Underwater visual enhancement (UVE) and underwater 3D reconstruction pose significant challenges in   computer vision and AI-based tasks due to complex imaging conditions in aquatic environments. Despite   the development of numerous enhancement algorithms, a comprehensive and systematic review covering both   UVE and underwater 3D reconstruction remains absent. To advance research in these areas, we present an   in-depth review from multiple perspectives. First, we introduce the fundamental physical models, highlighting the   peculiarities that challenge conventional techniques. We survey advanced methods for visual enhancement and   3D reconstruction specifically designed for underwater scenarios. The paper assesses various approaches from   non-learning methods to advanced data-driven techniques, including Neural Radiance Fields and 3D Gaussian   Splatting, discussing their effectiveness in handling underwater distortions. Finally, we conduct both quantitative   and qualitative evaluations of state-of-the-art UVE and underwater 3D reconstruction algorithms across multiple   benchmark datasets. Finally, we highlight key research directions for future advancements in underwater vision. </p>
<blockquote>
<p>æ°´ä¸‹è§†è§‰å¢å¼ºï¼ˆUVEï¼‰å’Œæ°´ä¸‹3Dé‡å»ºåœ¨è®¡ç®—æœºè§†è§‰å’ŒåŸºäºäººå·¥æ™ºèƒ½çš„ä»»åŠ¡ä¸­æ„æˆäº†é‡å¤§æŒ‘æˆ˜ï¼ŒåŸå› åœ¨äºæ°´ç”Ÿç¯å¢ƒçš„å¤æ‚æˆåƒæ¡ä»¶ã€‚å°½ç®¡å‡ºç°äº†è®¸å¤šå¢å¼ºç®—æ³•ï¼Œä½†æ¶µç›–UVEå’Œæ°´ä¸‹3Dé‡å»ºçš„å…¨é¢ç³»ç»Ÿç»¼è¿°ä»ç„¶ç¼ºå¤±ã€‚ä¸ºäº†æ¨åŠ¨è¿™äº›é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬ä»å¤šä¸ªè§’åº¦è¿›è¡Œäº†æ·±å…¥çš„å›é¡¾ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä»‹ç»äº†åŸºæœ¬çš„ç‰©ç†æ¨¡å‹ï¼Œå¹¶å¼ºè°ƒäº†æŒ‘æˆ˜ä¼ ç»ŸæŠ€æœ¯çš„ç‰¹æ€§ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†ä¸“é—¨ä¸ºæ°´ä¸‹åœºæ™¯è®¾è®¡çš„è§†è§‰å¢å¼ºå’Œ3Dé‡å»ºçš„å…ˆè¿›æ–¹æ³•ã€‚æœ¬æ–‡è¯„ä¼°äº†ä»éå­¦ä¹ æ–¹æ³•åˆ°å…ˆè¿›çš„æ•°æ®é©±åŠ¨æŠ€æœ¯ï¼ˆåŒ…æ‹¬ç¥ç»è¾å°„åœºå’Œ3Dé«˜æ–¯å–·å°„ï¼‰çš„å„ç§æ–¹æ³•ï¼Œå¹¶è®¨è®ºäº†å®ƒä»¬åœ¨å¤„ç†æ°´ä¸‹å¤±çœŸæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†æœ€æ–°UVEå’Œæ°´ä¸‹3Dé‡å»ºç®—æ³•çš„é‡åŒ–å’Œè´¨æ€§è¯„ä¼°ã€‚æœ€åï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æ°´ä¸‹è§†è§‰æœªæ¥è¿›æ­¥çš„å…³é”®ç ”ç©¶æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01869v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æ·±å…¥å›é¡¾äº†æ°´ä¸‹è§†è§‰å¢å¼ºå’Œ3Dé‡å»ºçš„ç ”ç©¶ï¼Œä»‹ç»äº†å…¶é¢ä¸´çš„åŸºç¡€ç‰©ç†æ¨¡å‹æŒ‘æˆ˜ã€å…ˆè¿›çš„è§†è§‰å¢å¼ºå’Œ3Dé‡å»ºæ–¹æ³•ï¼Œå¹¶è¯„ä¼°äº†éå­¦ä¹ æ–¹æ³•å’Œå…ˆè¿›çš„æ•°æ®é©±åŠ¨æŠ€æœ¯çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬ç¥ç»ç½‘ç»œè¾å°„åœºå’Œ3Dé«˜æ–¯å–·æ¶‚åœ¨å¤„ç†æ°´ä¸‹å¤±çœŸæ–¹é¢çš„è¡¨ç°ã€‚åŒæ—¶ï¼Œå¯¹æœ€æ–°çš„æ°´ä¸‹è§†è§‰å¢å¼ºå’Œ3Dé‡å»ºç®—æ³•è¿›è¡Œäº†å¤šåŸºå‡†æ•°æ®é›†çš„å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥æ°´ä¸‹è§†è§‰ç ”ç©¶çš„å…³é”®æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†æ°´ä¸‹è§†è§‰å¢å¼ºï¼ˆUVEï¼‰å’Œ3Dé‡å»ºåœ¨æ°´ä¸‹ç¯å¢ƒä¸­çš„å¤æ‚æˆåƒæ¡ä»¶æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚</li>
<li>å¼ºè°ƒäº†ç°æœ‰çš„å¢å¼ºç®—æ³•æ— æ³•å…¨é¢è¦†ç›–UVEå’Œ3Dé‡å»ºçš„é—®é¢˜ï¼Œéœ€è¦è¿›è¡Œæ·±å…¥ç ”ç©¶ã€‚</li>
<li>ä»å¤šä¸ªè§’åº¦è¿›è¡Œäº†å…¨é¢çš„æ–‡çŒ®ç»¼è¿°ï¼Œä»‹ç»äº†åŸºç¡€ç‰©ç†æ¨¡å‹ã€å…ˆè¿›çš„è§†è§‰å¢å¼ºå’Œ3Dé‡å»ºæ–¹æ³•ã€‚</li>
<li>è¯„ä¼°äº†å¤šç§æ–¹æ³•åœ¨å¤„ç†æ°´ä¸‹å¤±çœŸæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬éå­¦ä¹ æ–¹æ³•å’Œæ•°æ®é©±åŠ¨æŠ€æœ¯ã€‚</li>
<li>é€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œå¯¹æ¯”äº†å½“å‰å…ˆè¿›çš„æ°´ä¸‹è§†è§‰å¢å¼ºå’Œ3Dé‡å»ºç®—æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>æŒ‡å‡ºæœªæ¥æ°´ä¸‹è§†è§‰ç ”ç©¶çš„å…³é”®æ–¹å‘ï¼ŒåŒ…æ‹¬æ›´ç²¾ç¡®çš„æ¨¡å‹ã€æ›´é«˜çš„æ•ˆç‡ã€è·¨æ¨¡æ€èåˆç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01869">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bc7d5d6a23ee56fb7af6f6615bd173bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-db60bd846367f98bf88e26d518545a43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a841f349a37341f5b117c3e2b5320a90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9581f4c50888687a400d4c3a34b589ae.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AquaGS-Fast-Underwater-Scene-Reconstruction-with-SfM-Free-Gaussian-Splatting"><a href="#AquaGS-Fast-Underwater-Scene-Reconstruction-with-SfM-Free-Gaussian-Splatting" class="headerlink" title="AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian   Splatting"></a>AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian   Splatting</h2><p><strong>Authors:Junhao Shi, Jisheng Xu, Jianping He, Zhiliang Lin</strong></p>
<p>Underwater scene reconstruction is a critical tech-nology for underwater operations, enabling the generation of 3D models from images captured by underwater platforms. However, the quality of underwater images is often degraded due to medium interference, which limits the effectiveness of Structure-from-Motion (SfM) pose estimation, leading to subsequent reconstruction failures. Additionally, SfM methods typically operate at slower speeds, further hindering their applicability in real-time scenarios. In this paper, we introduce AquaGS, an SfM-free underwater scene reconstruction model based on the SeaThru algorithm, which facilitates rapid and accurate separation of scene details and medium features. Our approach initializes Gaussians by integrating state-of-the-art multi-view stereo (MVS) technology, employs implicit Neural Radiance Fields (NeRF) for rendering translucent media and utilizes the latest explicit 3D Gaussian Splatting (3DGS) technique to render object surfaces, which effectively addresses the limitations of traditional methods and accurately simulates underwater optical phenomena. Experimental results on the data set and the robot platform show that our model can complete high-precision reconstruction in 30 seconds with only 3 image inputs, significantly enhancing the practical application of the algorithm in robotic platforms. </p>
<blockquote>
<p>æ°´ä¸‹åœºæ™¯é‡å»ºæ˜¯æ°´ä¸‹æ“ä½œçš„å…³é”®æŠ€æœ¯ï¼Œèƒ½å¤Ÿä»æ°´ä¸‹å¹³å°æ•è·çš„å›¾åƒç”Ÿæˆ3Dæ¨¡å‹ã€‚ç„¶è€Œï¼Œç”±äºä»‹è´¨å¹²æ‰°ï¼Œæ°´ä¸‹å›¾åƒçš„è´¨é‡å¾€å¾€ä¸‹é™ï¼Œè¿™é™åˆ¶äº†ä»è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰å§¿æ€ä¼°è®¡çš„æœ‰æ•ˆæ€§ï¼Œå¯¼è‡´éšåçš„é‡å»ºå¤±è´¥ã€‚æ­¤å¤–ï¼ŒSfMæ–¹æ³•é€šå¸¸è¿è¡Œè¾ƒæ…¢ï¼Œè¿›ä¸€æ­¥é˜»ç¢äº†å®ƒä»¬åœ¨å®æ—¶åœºæ™¯ä¸­çš„åº”ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†AquaGSï¼Œä¸€ç§åŸºäºSeaThruç®—æ³•çš„éSfMæ°´ä¸‹åœºæ™¯é‡å»ºæ¨¡å‹ï¼Œå®ƒæœ‰åŠ©äºå¿«é€Ÿå‡†ç¡®åœ°åˆ†ç¦»åœºæ™¯ç»†èŠ‚å’Œä»‹è´¨ç‰¹å¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡é›†æˆæœ€æ–°çš„å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æŠ€æœ¯æ¥åˆå§‹åŒ–é«˜æ–¯åˆ†å¸ƒï¼Œä½¿ç”¨éšå¼ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å‘ˆç°åŠé€æ˜ä»‹è´¨ï¼Œå¹¶åˆ©ç”¨æœ€æ–°çš„æ˜¾å¼3Dé«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰æŠ€æœ¯å‘ˆç°ç‰©ä½“è¡¨é¢ï¼Œè¿™æœ‰æ•ˆåœ°è§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶èƒ½å‡†ç¡®åœ°æ¨¡æ‹Ÿæ°´ä¸‹å…‰å­¦ç°è±¡ã€‚åœ¨æ•°æ®é›†å’Œæœºå™¨äººå¹³å°ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»…ä½¿ç”¨3ä¸ªå›¾åƒè¾“å…¥å°±èƒ½åœ¨30ç§’å†…å®Œæˆé«˜ç²¾åº¦é‡å»ºï¼Œè¿™å¤§å¤§å¢å¼ºäº†ç®—æ³•åœ¨æœºå™¨äººå¹³å°ä¸Šçš„å®é™…åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01799v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æ°´ä¸‹åœºæ™¯é‡å»ºæ˜¯ä¸€é¡¹å¯¹æ°´ä¸‹æ“ä½œè‡³å…³é‡è¦çš„æŠ€æœ¯ï¼Œèƒ½é€šè¿‡æ°´ä¸‹å¹³å°æ•è·çš„å›¾åƒç”Ÿæˆ3Dæ¨¡å‹ã€‚ä½†ç”±äºä»‹è´¨å¹²æ‰°ï¼Œæ°´ä¸‹å›¾åƒè´¨é‡å¾€å¾€ä¸‹é™ï¼Œå½±å“ä»è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰å§¿æ€ä¼°è®¡çš„æ•ˆæœï¼Œå¯¼è‡´é‡å»ºå¤±è´¥ã€‚æ­¤å¤–ï¼ŒSfMæ–¹æ³•é€šå¸¸è¿è¡Œè¾ƒæ…¢ï¼Œè¿›ä¸€æ­¥é˜»ç¢å…¶åœ¨å®æ—¶åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æœ¬æ–‡ä»‹ç»äº†AquaGSï¼Œä¸€ç§åŸºäºSeaThruç®—æ³•çš„éSfMæ°´ä¸‹åœºæ™¯é‡å»ºæ¨¡å‹ï¼Œèƒ½å¤Ÿè¿…é€Ÿå‡†ç¡®åœ°åˆ†ç¦»åœºæ™¯ç»†èŠ‚å’Œä»‹è´¨ç‰¹å¾ã€‚è¯¥æ–¹æ³•é€šè¿‡é›†æˆæœ€æ–°å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æŠ€æœ¯åˆå§‹åŒ–é«˜æ–¯åˆ†å¸ƒï¼Œé‡‡ç”¨éšå¼ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å‘ˆç°åŠé€æ˜ä»‹è´¨ï¼Œå¹¶åˆ©ç”¨æœ€æ–°çš„æ˜¾å¼3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯å‘ˆç°ç‰©ä½“è¡¨é¢ï¼Œæœ‰æ•ˆè§£å†³ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ï¼Œå‡†ç¡®æ¨¡æ‹Ÿæ°´ä¸‹å…‰å­¦ç°è±¡ã€‚åœ¨æ•°æ®é›†å’Œæœºå™¨äººå¹³å°ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹ä»…éœ€3å¼ å›¾åƒè¾“å…¥ï¼Œå°±èƒ½åœ¨30ç§’å†…å®Œæˆé«˜ç²¾åº¦é‡å»ºï¼Œæ˜¾è‘—æé«˜äº†ç®—æ³•åœ¨æœºå™¨äººå¹³å°ä¸Šçš„å®é™…åº”ç”¨æ€§èƒ½ã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>æ°´ä¸‹åœºæ™¯é‡å»ºæ˜¯æ°´ä¸‹æ“ä½œçš„å…³é”®æŠ€æœ¯ï¼Œèƒ½å¤Ÿä»æ°´ä¸‹å¹³å°æ‹æ‘„çš„å›¾ç‰‡ç”Ÿæˆ3Dæ¨¡å‹ã€‚</li>
<li>ä»‹è´¨å¹²æ‰°å¯¼è‡´æ°´ä¸‹å›¾åƒè´¨é‡ä¸‹é™ï¼Œå½±å“SfMå§¿æ€ä¼°è®¡å’Œåç»­é‡å»ºã€‚</li>
<li>æå‡ºçš„AquaGSæ¨¡å‹åŸºäºSeaThruç®—æ³•ï¼Œæ— éœ€SfMæŠ€æœ¯ã€‚</li>
<li>AquaGSèƒ½è¿…é€Ÿåˆ†ç¦»åœºæ™¯ç»†èŠ‚å’Œä»‹è´¨ç‰¹å¾ã€‚</li>
<li>è¯¥æ–¹æ³•é›†æˆäº†å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æŠ€æœ¯ã€éšå¼ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯ã€‚</li>
<li>AquaGSèƒ½å‡†ç¡®æ¨¡æ‹Ÿæ°´ä¸‹å…‰å­¦ç°è±¡ï¼Œå¹¶æœ‰æ•ˆè§£å†³ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f960ec89cdb20f3837b2c0f2b7712a47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40465d119a9ba23416437730cb3e64e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c9d1eb2da85996f3b18d0de1159c1f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9591cca22f458043c17c600e7172f267.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5f8fe764b15282714ff3101a91986d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90ce9f482b943e57b87ab32b57c8dc2d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e2d07f47e41d8f6ac98aa22c56f0bdca.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="RGS-DR-Reflective-Gaussian-Surfels-with-Deferred-Rendering-for-Shiny-Objects"><a href="#RGS-DR-Reflective-Gaussian-Surfels-with-Deferred-Rendering-for-Shiny-Objects" class="headerlink" title="RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects"></a>RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects</h2><p><strong>Authors:Georgios Kouros, Minye Wu, Tinne Tuytelaars</strong></p>
<p>We introduce RGS-DR, a novel inverse rendering method for reconstructing and rendering glossy and reflective objects with support for flexible relighting and scene editing. Unlike existing methods (e.g., NeRF and 3D Gaussian Splatting), which struggle with view-dependent effects, RGS-DR utilizes a 2D Gaussian surfel representation to accurately estimate geometry and surface normals, an essential property for high-quality inverse rendering. Our approach explicitly models geometric and material properties through learnable primitives rasterized into a deferred shading pipeline, effectively reducing rendering artifacts and preserving sharp reflections. By employing a multi-level cube mipmap, RGS-DR accurately approximates environment lighting integrals, facilitating high-quality reconstruction and relighting. A residual pass with spherical-mipmap-based directional encoding further refines the appearance modeling. Experiments demonstrate that RGS-DR achieves high-quality reconstruction and rendering quality for shiny objects, often outperforming reconstruction-exclusive state-of-the-art methods incapable of relighting. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†RGS-DRï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹é€†å‘æ¸²æŸ“æ–¹æ³•ï¼Œç”¨äºé‡å»ºå’Œæ¸²æŸ“å…·æœ‰å…‰æ³½å’Œåå°„ç‰¹æ€§çš„ç‰©ä½“ï¼Œæ”¯æŒçµæ´»çš„é‡æ–°æ‰“å…‰å’Œåœºæ™¯ç¼–è¾‘ã€‚ä¸ç°æœ‰æ–¹æ³•ï¼ˆä¾‹å¦‚NeRFå’Œ3Dé«˜æ–¯æ‹¼è´´ï¼‰ç›¸æ¯”ï¼Œå®ƒä»¬åœ¨å¤„ç†ä¸è§†å›¾ç›¸å…³çš„æ•ˆæœæ—¶é‡åˆ°å›°éš¾ï¼Œè€ŒRGS-DRä½¿ç”¨2Dé«˜æ–¯surfelè¡¨ç¤ºæ³•æ¥å‡†ç¡®ä¼°è®¡å‡ ä½•å’Œè¡¨é¢æ³•çº¿ï¼Œè¿™æ˜¯é«˜è´¨é‡é€†å‘æ¸²æŸ“çš„åŸºæœ¬å±æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å¯å­¦ä¹ çš„åŸå§‹å…ƒç´ æ˜¾å¼å»ºæ¨¡å‡ ä½•å’Œææ–™å±æ€§ï¼Œå¹¶å°†å…¶æ¸²æŸ“åˆ°å»¶è¿Ÿç€è‰²ç®¡é“ä¸­ï¼Œè¿™æœ‰æ•ˆåœ°å‡å°‘äº†æ¸²æŸ“ä¼ªå½±å¹¶ä¿æŒäº†é”åˆ©çš„åå°„ã€‚é€šè¿‡é‡‡ç”¨å¤šå±‚æ¬¡ç«‹æ–¹ä½“mipmapï¼ŒRGS-DRèƒ½å¤Ÿå‡†ç¡®è¿‘ä¼¼ç¯å¢ƒå…‰ç…§ç§¯åˆ†ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„é‡å»ºå’Œé‡æ–°æ‰“å…‰ã€‚åŸºäºçƒå½¢mipmapçš„æ–¹å‘ç¼–ç çš„æ®‹å·®ä¼ é€’è¿›ä¸€æ­¥æ”¹è¿›äº†å¤–è§‚å»ºæ¨¡ã€‚å®éªŒè¡¨æ˜ï¼ŒRGS-DRåœ¨é‡å»ºå’Œæ¸²æŸ“å…‰æ³½ç‰©ä½“æ–¹é¢è¾¾åˆ°äº†é«˜è´¨é‡æ°´å¹³ï¼Œå¾€å¾€è¶…è¶Šäº†é‚£äº›ä¸èƒ½è¿›è¡Œé‡æ–°æ‰“å…‰çš„ä»…é‡å»ºçš„é¡¶å°–æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18468v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>RGS-DRæ˜¯ä¸€ç§æ–°å‹é€†å‘æ¸²æŸ“æ–¹æ³•ï¼Œèƒ½é‡å»ºå’Œæ¸²æŸ“å…·æœ‰å…‰æ³½å’Œåå°„ç‰¹æ€§çš„ç‰©ä½“ï¼Œæ”¯æŒçµæ´»çš„é‡æ–°ç…§æ˜å’Œåœºæ™¯ç¼–è¾‘ã€‚è¯¥æ–¹æ³•é‡‡ç”¨2Dé«˜æ–¯surfelè¡¨ç¤ºæ³•å‡†ç¡®ä¼°è®¡å‡ ä½•å’Œè¡¨é¢æ³•çº¿ï¼Œé€šè¿‡å¯å­¦ä¹ çš„åŸå§‹å…ƒç´ æ˜¾å¼å»ºæ¨¡å‡ ä½•å’Œæè´¨å±æ€§ï¼Œå¹¶æ¸²æŸ“åˆ°å»¶è¿Ÿç€è‰²ç®¡é“ä¸­ï¼Œæœ‰æ•ˆå‡å°‘æ¸²æŸ“ä¼ªå½±ï¼Œä¿ç•™é”åˆ©åå°„ã€‚é€šè¿‡é‡‡ç”¨å¤šçº§ç«‹æ–¹ä½“mipmapï¼ŒRGS-DRå‡†ç¡®è¿‘ä¼¼ç¯å¢ƒç…§æ˜ç§¯åˆ†ï¼Œå®ç°é«˜è´¨é‡é‡å»ºå’Œé‡æ–°ç…§æ˜ã€‚ä½¿ç”¨åŸºäºçƒé¢mipmapçš„æ–¹å‘ç¼–ç çš„æ®‹å·®ä¼ é€’è¿›ä¸€æ­¥æ”¹è¿›äº†å¤–è§‚å»ºæ¨¡ã€‚å®éªŒè¡¨æ˜ï¼ŒRGS-DRåœ¨é‡å»ºå’Œæ¸²æŸ“å…‰æ³½ç‰©ä½“æ–¹é¢å…·æœ‰é«˜è´¨é‡ï¼Œç»å¸¸è¶…è¶Šæ— æ³•é‡æ–°ç…§æ˜çš„é‡å»ºä¸“ç”¨æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RGS-DRæ˜¯ä¸€ç§ç”¨äºé‡å»ºå’Œæ¸²æŸ“å…·æœ‰å…‰æ³½å’Œåå°„ç‰¹æ€§çš„ç‰©ä½“çš„æ–°å‹é€†å‘æ¸²æŸ“æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨2Dé«˜æ–¯surfelè¡¨ç¤ºæ³•æ¥å‡†ç¡®ä¼°è®¡å‡ ä½•å’Œè¡¨é¢æ³•çº¿ï¼Œè¿™æ˜¯é«˜è´¨é‡é€†å‘æ¸²æŸ“çš„å…³é”®å±æ€§ã€‚</li>
<li>RGS-DRé€šè¿‡å¯å­¦ä¹ çš„åŸå§‹å…ƒç´ æ˜¾å¼å»ºæ¨¡å‡ ä½•å’Œæè´¨å±æ€§ï¼Œå¹¶å°†å…¶æ¸²æŸ“åˆ°å»¶è¿Ÿç€è‰²ç®¡é“ä¸­ï¼Œä»¥æé«˜æ¸²æŸ“è´¨é‡å¹¶å‡å°‘ä¼ªå½±ã€‚</li>
<li>é‡‡ç”¨å¤šçº§ç«‹æ–¹ä½“mipmapæŠ€æœ¯ï¼ŒRGS-DRèƒ½å‡†ç¡®è¿‘ä¼¼ç¯å¢ƒç…§æ˜ç§¯åˆ†ï¼Œå®ç°é«˜è´¨é‡çš„é‡å»ºå’Œé‡æ–°ç…§æ˜ã€‚</li>
<li>æ®‹å·®ä¼ é€’å’ŒåŸºäºçƒé¢mipmapçš„æ–¹å‘ç¼–ç è¿›ä¸€æ­¥æ”¹è¿›äº†RGS-DRçš„å¤–è§‚å»ºæ¨¡ã€‚</li>
<li>RGS-DRåœ¨é‡å»ºå’Œæ¸²æŸ“å…‰æ³½ç‰©ä½“æ–¹é¢çš„æ€§èƒ½è¶…è¶Šäº†æŸäº›æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18468">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4ebbed15ace63dcc9ff524cda794815d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cbe5993b0e82f86f21ec2593ea7f2ee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21a84f71db644f83249586af03728709.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="PIN-WM-Learning-Physics-INformed-World-Models-for-Non-Prehensile-Manipulation"><a href="#PIN-WM-Learning-Physics-INformed-World-Models-for-Non-Prehensile-Manipulation" class="headerlink" title="PIN-WM: Learning Physics-INformed World Models for Non-Prehensile   Manipulation"></a>PIN-WM: Learning Physics-INformed World Models for Non-Prehensile   Manipulation</h2><p><strong>Authors:Wenxuan Li, Hang Zhao, Zhiyuan Yu, Yu Du, Qin Zou, Ruizhen Hu, Kai Xu</strong></p>
<p>While non-prehensile manipulation (e.g., controlled pushing&#x2F;poking) constitutes a foundational robotic skill, its learning remains challenging due to the high sensitivity to complex physical interactions involving friction and restitution. To achieve robust policy learning and generalization, we opt to learn a world model of the 3D rigid body dynamics involved in non-prehensile manipulations and use it for model-based reinforcement learning. We propose PIN-WM, a Physics-INformed World Model that enables efficient end-to-end identification of a 3D rigid body dynamical system from visual observations. Adopting differentiable physics simulation, PIN-WM can be learned with only few-shot and task-agnostic physical interaction trajectories. Further, PIN-WM is learned with observational loss induced by Gaussian Splatting without needing state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM into a group of Digital Cousins via physics-aware randomizations which perturb physics and rendering parameters to generate diverse and meaningful variations of the PIN-WM. Extensive evaluations on both simulation and real-world tests demonstrate that PIN-WM, enhanced with physics-aware digital cousins, facilitates learning robust non-prehensile manipulation skills with Sim2Real transfer, surpassing the Real2Sim2Real state-of-the-arts. </p>
<blockquote>
<p>éé¢„æŠ“å–æ“ä½œï¼ˆä¾‹å¦‚ï¼Œå—æ§æ¨åŠ¨&#x2F;æˆ³åˆºï¼‰æ„æˆäº†ä¸€é¡¹åŸºç¡€æœºå™¨äººæŠ€èƒ½ï¼Œä½†ç”±äºå…¶å¯¹æ¶‰åŠæ‘©æ“¦å’Œæ¢å¤åŠ›çš„å¤æ‚ç‰©ç†äº¤äº’çš„é«˜åº¦æ•æ„Ÿæ€§ï¼Œå…¶å­¦ä¹ ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†å®ç°ç¨³å¥çš„ç­–ç•¥å­¦ä¹ å’Œæ³›åŒ–ï¼Œæˆ‘ä»¬é€‰æ‹©å­¦ä¹ æ¶‰åŠéé¢„æŠ“å–æ“ä½œçš„ä¸‰ç»´åˆšä½“åŠ¨åŠ›å­¦ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶å°†å…¶ç”¨äºåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬æå‡ºäº†PIN-WMï¼Œå³ç‰©ç†ä¿¡æ¯ä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿå®ç°ä»è§†è§‰è§‚å¯Ÿä¸­é«˜æ•ˆç«¯åˆ°ç«¯åœ°è¯†åˆ«ä¸‰ç»´åˆšä½“åŠ¨æ€ç³»ç»Ÿã€‚é€šè¿‡é‡‡ç”¨å¯å¾®åˆ†ç‰©ç†æ¨¡æ‹Ÿï¼ŒPIN-WMä»…é€šè¿‡å°‘é‡ä»»åŠ¡æ— å…³çš„ç‰©ç†è§£ç®—è½¨è¿¹å³å¯å­¦ä¹ ã€‚æ­¤å¤–ï¼ŒPIN-WMé€šè¿‡é«˜æ–¯Splattingè¯±å¯¼çš„è§‚å¯ŸæŸå¤±è¿›è¡Œå­¦ä¹ ï¼Œæ— éœ€è¿›è¡ŒçŠ¶æ€ä¼°è®¡ã€‚ä¸ºäº†å¼¥è™šæ‹Ÿä¸ç°å®ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬é€šè¿‡ç‰©ç†æ„ŸçŸ¥éšæœºåŒ–å°†å­¦ä¹ åˆ°çš„PIN-WMè½¬æ¢ä¸ºæ•°å­—å­ªç”Ÿç¾¤ä½“ï¼Œéšæœºæ‰°åŠ¨ç‰©ç†å’Œæ¸²æŸ“å‚æ•°æ¥ç”Ÿæˆå¤šæ ·è€Œæœ‰æ„ä¹‰çš„PIN-WMå˜åŒ–ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œé€šè¿‡å¢å¼ºç‰©ç†æ„ŸçŸ¥çš„æ•°å­—å­ªç”Ÿç¾¤ä½“ï¼ŒPIN-WMæœ‰åŠ©äºå­¦ä¹ å…·æœ‰ä»æ¨¡æ‹Ÿåˆ°ç°å®è¿ç§»èƒ½åŠ›çš„ç¨³å¥çš„éé¢„æŠ“å–æ“ä½œæŠ€èƒ½ï¼Œè¶…è¶Šäº†æœ€æ–°çš„Real2Sim2RealæŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16693v2">PDF</a> Robotics: Science and Systems 2025</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹éæŠ“å–æ“ä½œï¼ˆå¦‚æ§åˆ¶æ¨åŠ¨&#x2F;æˆ³åˆºï¼‰çš„æœºå™¨äººæŠ€èƒ½å­¦ä¹ ï¼Œå­˜åœ¨å¯¹å¤æ‚ç‰©ç†äº¤äº’çš„é«˜åº¦æ•æ„Ÿæ€§ï¼ŒåŒ…æ‹¬æ‘©æ“¦å’Œæ¢å¤ç³»æ•°ç­‰æŒ‘æˆ˜ã€‚ä¸ºå®ç°ç¨³å¥çš„ç­–ç•¥å­¦ä¹ å’Œæ³›åŒ–ï¼Œæˆ‘ä»¬é€‰æ‹©äº†å­¦ä¹ æ¶‰åŠéæŠ“å–æ“ä½œçš„ä¸‰ç»´åˆšä½“åŠ¨åŠ›å­¦çš„ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶ç”¨äºåŸºäºæ¨¡å‹å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬æå‡ºPIN-WMï¼Œä¸€ç§åŸºäºç‰©ç†ä¿¡æ¯çš„ä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿé«˜æ•ˆç«¯åˆ°ç«¯è¯†åˆ«ä¸‰ç»´åˆšä½“åŠ¨æ€ç³»ç»Ÿï¼Œä»è§†è§‰è§‚å¯Ÿä¸­å­¦ä¹ ã€‚é€šè¿‡é‡‡ç”¨å¯å¾®åˆ†ç‰©ç†ä»¿çœŸï¼ŒPIN-WMä»…é€šè¿‡å°‘é‡ã€ä»»åŠ¡æ— å…³çš„ç‰©ç†è§£ç®—è½¨è¿¹å³å¯å­¦ä¹ ã€‚æ­¤å¤–ï¼Œé€šè¿‡é«˜æ–¯æ‹¼è´´æŠ€æœ¯å¼•å…¥è§‚æµ‹æŸå¤±è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€çŠ¶æ€ä¼°è®¡ã€‚ä¸ºè§£å†³æ¨¡æ‹Ÿåˆ°ç°å®çš„å·®è·é—®é¢˜ï¼Œæˆ‘ä»¬å°†å­¦åˆ°çš„PIN-WMè½¬åŒ–ä¸ºæ•°å­—åˆ†èº«ç¾¤ä½“ï¼Œé€šè¿‡ç‰©ç†æ„ŸçŸ¥éšæœºåŒ–æŠ€æœ¯æ‰°åŠ¨ç‰©ç†å’Œæ¸²æŸ“å‚æ•°ï¼Œç”Ÿæˆå¤šæ ·ä¸”æ„ä¹‰æ·±è¿œçš„æ¨¡å‹å˜ä½“ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸­çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œè¾…ä»¥ç‰©ç†æ„ŸçŸ¥çš„æ•°å­—åˆ†èº«ç¾¤ä½“ï¼ŒPIN-WMèƒ½å­¦ä¹ ç¨³å¥çš„éæŠ“å–æ“ä½œæŠ€èƒ½å¹¶å®ç°æ¨¡æ‹Ÿåˆ°ç°å®çš„è¿ç§»å­¦ä¹ æ€§èƒ½è¶…è¶Šç°æœ‰çš„å…ˆè¿›æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>éæŠ“å–æ“ä½œçš„æœºå™¨äººæŠ€èƒ½å­¦ä¹ é¢ä¸´å¤æ‚ç‰©ç†äº¤äº’çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºPIN-WMæ¨¡å‹ï¼šåˆ©ç”¨åŸºäºç‰©ç†ä¿¡æ¯çš„ä¸–ç•Œæ¨¡å‹å­¦ä¹ ä¸‰ç»´åˆšä½“åŠ¨åŠ›å­¦ã€‚</li>
<li>é‡‡ç”¨å¯å¾®åˆ†ç‰©ç†ä»¿çœŸè¿›è¡Œé«˜æ•ˆç«¯åˆ°ç«¯å­¦ä¹ ã€‚</li>
<li>é€šè¿‡é«˜æ–¯æ‹¼è´´æŠ€æœ¯å¼•å…¥è§‚æµ‹æŸå¤±è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€çŠ¶æ€ä¼°è®¡ã€‚</li>
<li>åˆ©ç”¨ç‰©ç†æ„ŸçŸ¥éšæœºåŒ–æŠ€æœ¯å°†æ¨¡å‹è½¬åŒ–ä¸ºæ•°å­—åˆ†èº«ç¾¤ä½“ä»¥è§£å†³æ¨¡æ‹Ÿåˆ°ç°å®çš„å·®è·é—®é¢˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16693">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6edd20c06c48ef422b8968ef067637e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-650dc498b4b6715cc538deb1c022f2e5.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Mind2Matter-Creating-3D-Models-from-EEG-Signals"><a href="#Mind2Matter-Creating-3D-Models-from-EEG-Signals" class="headerlink" title="Mind2Matter: Creating 3D Models from EEG Signals"></a>Mind2Matter: Creating 3D Models from EEG Signals</h2><p><strong>Authors:Xia Deng, Shen Chen, Jiale Zhou, Lei Li</strong></p>
<p>The reconstruction of 3D objects from brain signals has gained significant attention in brain-computer interface (BCI) research. Current research predominantly utilizes functional magnetic resonance imaging (fMRI) for 3D reconstruction tasks due to its excellent spatial resolution. Nevertheless, the clinical utility of fMRI is limited by its prohibitive costs and inability to support real-time operations. In comparison, electroencephalography (EEG) presents distinct advantages as an affordable, non-invasive, and mobile solution for real-time brain-computer interaction systems. While recent advances in deep learning have enabled remarkable progress in image generation from neural data, decoding EEG signals into structured 3D representations remains largely unexplored. In this paper, we propose a novel framework that translates EEG recordings into 3D object reconstructions by leveraging neural decoding techniques and generative models. Our approach involves training an EEG encoder to extract spatiotemporal visual features, fine-tuning a large language model to interpret these features into descriptive multimodal outputs, and leveraging generative 3D Gaussians with layout-guided control to synthesize the final 3D structures. Experiments demonstrate that our model captures salient geometric and semantic features, paving the way for applications in brain-computer interfaces (BCIs), virtual reality, and neuroprosthetics. Our code is available in <a target="_blank" rel="noopener" href="https://github.com/sddwwww/Mind2Matter">https://github.com/sddwwww/Mind2Matter</a>. </p>
<blockquote>
<p>ä»è„‘ä¿¡å·é‡å»º3Dç‰©ä½“åœ¨è„‘æœºæ¥å£ï¼ˆBCIï¼‰ç ”ç©¶ä¸­å—åˆ°äº†å¹¿æ³›å…³æ³¨ã€‚ç›®å‰çš„ç ”ç©¶ä¸»è¦åˆ©ç”¨åŠŸèƒ½ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰è¿›è¡Œ3Dé‡å»ºä»»åŠ¡ï¼Œå› å…¶å…·æœ‰å‡ºè‰²çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚ç„¶è€Œï¼ŒfMRIçš„ä¸´åºŠåº”ç”¨å—é™äºå…¶é«˜æ˜‚çš„æˆæœ¬å’Œæ— æ³•æ”¯æŒå®æ—¶æ“ä½œã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè„‘ç”µå›¾ï¼ˆEEGï¼‰ä½œä¸ºç»æµå®æƒ ã€éä¾µå…¥å¼å’Œç§»åŠ¨å¼çš„å®æ—¶è„‘æœºäº¤äº’ç³»ç»Ÿè§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚è™½ç„¶æ·±åº¦å­¦ä¹ é¢†åŸŸçš„æœ€æ–°è¿›å±•åœ¨ç¥ç»æ•°æ®ç”Ÿæˆå›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä½†å°†EEGä¿¡å·è§£ç ä¸ºç»“æ„åŒ–çš„3Dè¡¨ç¤ºä»ç„¶å¾ˆå°‘è¢«æ¢ç´¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨ç¥ç»è§£ç æŠ€æœ¯å’Œç”Ÿæˆæ¨¡å‹å°†EEGè®°å½•è½¬åŒ–ä¸º3Då¯¹è±¡é‡å»ºçš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬è®­ç»ƒEEGç¼–ç å™¨ä»¥æå–æ—¶ç©ºè§†è§‰ç‰¹å¾ï¼Œå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ä»¥å°†è¿™äº›ç‰¹å¾è§£é‡Šä¸ºæè¿°æ€§çš„å¤šæ¨¡å¼è¾“å‡ºï¼Œå¹¶åˆ©ç”¨å¸¦æœ‰å¸ƒå±€æŒ‡å¯¼æ§åˆ¶çš„ç”Ÿæˆæ€§3Dé«˜æ–¯æ¥åˆæˆæœ€ç»ˆçš„3Dç»“æ„ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ•æ‰äº†æ˜¾è‘—çš„å‡ ä½•å’Œè¯­ä¹‰ç‰¹å¾ï¼Œä¸ºè„‘æœºæ¥å£ï¼ˆBCIï¼‰ã€è™šæ‹Ÿç°å®å’Œç¥ç»çŸ«å½¢å™¨åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sddwwww/Mind2Matter%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sddwwww/Mind2Matterä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11936v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨è„‘ç”µæ³¢ä¿¡å·è¿›è¡Œä¸‰ç»´ç‰©ä½“é‡å»ºçš„ç ”ç©¶ã€‚ç”±äºé«˜æ˜‚çš„æˆæœ¬å’Œæ— æ³•æ”¯æŒå®æ—¶æ“ä½œï¼ŒåŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰åœ¨ä¸‰ç»´é‡å»ºä»»åŠ¡ä¸­çš„ä½¿ç”¨å—åˆ°é™åˆ¶ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·è¿›è¡Œä¸‰ç»´ç‰©ä½“é‡å»ºçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡ç¥ç»è§£ç æŠ€æœ¯å’Œç”Ÿæˆæ¨¡å‹å°†EEGä¿¡å·è½¬æ¢ä¸ºä¸‰ç»´ç‰©ä½“ç»“æ„ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬è®­ç»ƒEEGç¼–ç å™¨æå–æ—¶ç©ºè§†è§‰ç‰¹å¾ã€å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ä»¥è§£é‡Šè¿™äº›ç‰¹å¾å¹¶ç”Ÿæˆå¤šæ¨¡å¼è¾“å‡ºï¼Œå¹¶åˆ©ç”¨å¸ƒå±€æ§åˆ¶çš„ç”Ÿæˆæ€§ä¸‰ç»´é«˜æ–¯æ¨¡å‹åˆæˆæœ€ç»ˆçš„ä¸‰ç»´ç»“æ„ã€‚å®éªŒè¯æ˜è¯¥æ¨¡å‹èƒ½å¤Ÿæ•æ‰å…³é”®çš„å‡ ä½•å’Œè¯­ä¹‰ç‰¹å¾ï¼Œä¸ºè„‘æœºæ¥å£ã€è™šæ‹Ÿç°å®å’Œç¥ç»ä»¿ç”Ÿç­‰é¢†åŸŸçš„åº”ç”¨å¼€è¾Ÿäº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨è„‘ç”µæ³¢ä¿¡å·è¿›è¡Œä¸‰ç»´ç‰©ä½“é‡å»ºæ˜¯è„‘æœºæ¥å£ç ”ç©¶é¢†åŸŸçš„çƒ­ç‚¹ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦ä½¿ç”¨åŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰è¿›è¡Œä¸‰ç»´é‡å»ºï¼Œä½†å…¶é«˜æ˜‚æˆæœ¬å’Œæ— æ³•å®æ—¶æ“ä½œé™åˆ¶äº†åº”ç”¨ã€‚</li>
<li>è„‘ç”µå›¾ï¼ˆEEGï¼‰ä½œä¸ºä¸€ç§ç»æµã€éä¾µå…¥å¼å’Œå¯ç§»åŠ¨çš„æŠ€æœ¯ï¼Œåœ¨å®æ—¶è„‘æœºäº¤äº’ç³»ç»Ÿä¸­å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨å›¾åƒç”Ÿæˆå’Œç¥ç»æ•°æ®è§£ç æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°†EEGä¿¡å·è§£ç ä¸ºç»“æ„åŒ–ä¸‰ç»´è¡¨ç¤ºä»å¾…æ¢ç´¢ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨ç¥ç»è§£ç æŠ€æœ¯å’Œç”Ÿæˆæ¨¡å‹å°†EEGä¿¡å·è½¬æ¢ä¸ºä¸‰ç»´ç‰©ä½“ç»“æ„ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…æ‹¬è®­ç»ƒEEGç¼–ç å™¨ã€å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹å’Œåˆ©ç”¨ç”Ÿæˆæ€§ä¸‰ç»´é«˜æ–¯æ¨¡å‹åˆæˆä¸‰ç»´ç»“æ„ç­‰æ­¥éª¤ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11936">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ac6bb56ca31d13cf649fafa84d818c7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca1f712f6ee96a259fc29c0453b3053f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-17ba79f5a837f15bdb2207ff4617883b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e223852dc3312651eaa87167b1aefe61.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="SonarSplat-Novel-View-Synthesis-of-Imaging-Sonar-via-Gaussian-Splatting"><a href="#SonarSplat-Novel-View-Synthesis-of-Imaging-Sonar-via-Gaussian-Splatting" class="headerlink" title="SonarSplat: Novel View Synthesis of Imaging Sonar via Gaussian Splatting"></a>SonarSplat: Novel View Synthesis of Imaging Sonar via Gaussian Splatting</h2><p><strong>Authors:Advaith V. Sethuraman, Max Rucker, Onur Bagoren, Pou-Chun Kung, Nibarkavi N. B. Amutha, Katherine A. Skinner</strong></p>
<p>In this paper, we present SonarSplat, a novel Gaussian splatting framework for imaging sonar that demonstrates realistic novel view synthesis and models acoustic streaking phenomena. Our method represents the scene as a set of 3D Gaussians with acoustic reflectance and saturation properties. We develop a novel method to efficiently rasterize Gaussians to produce a range&#x2F;azimuth image that is faithful to the acoustic image formation model of imaging sonar. In particular, we develop a novel approach to model azimuth streaking in a Gaussian splatting framework. We evaluate SonarSplat using real-world datasets of sonar images collected from an underwater robotic platform in a controlled test tank and in a real-world river environment. Compared to the state-of-the-art, SonarSplat offers improved image synthesis capabilities (+3.2 dB PSNR) and more accurate 3D reconstruction (52% lower Chamfer Distance). We also demonstrate that SonarSplat can be leveraged for azimuth streak removal. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SonarSplatï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ç”¨äºæˆåƒå£°å‘çš„é«˜æ–¯æ¨¡ç³Šæ¡†æ¶ï¼Œå®ƒå±•ç¤ºäº†çœŸå®çš„æ–°å‹è§†å›¾åˆæˆï¼Œå¹¶æ¨¡æ‹Ÿäº†å£°çº¿æ‹–å°¾ç°è±¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†åœºæ™¯è¡¨ç¤ºä¸ºå…·æœ‰å£°åå°„å’Œé¥±å’Œå±æ€§çš„3Dé«˜æ–¯é›†åˆã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†é«˜æ–¯é‡åŒ–ä¸ºèŒƒå›´&#x2F;æ–¹ä½å›¾åƒï¼Œè¯¥å›¾åƒå¿ å®äºæˆåƒå£°å‘çš„å£°æˆåƒå½¢æˆæ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬åœ¨é«˜æ–¯æ¨¡ç³Šæ¡†æ¶ä¸­å¼€å‘äº†ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œç”¨äºæ¨¡æ‹Ÿæ–¹ä½æ‹–å°¾ã€‚æˆ‘ä»¬ä½¿ç”¨çœŸå®ä¸–ç•Œçš„å£°å‘å›¾åƒæ•°æ®é›†å¯¹SonarSplatè¿›è¡Œäº†è¯„ä¼°ï¼Œè¿™äº›æ•°æ®é›†æ˜¯ä»å—æ§æµ‹è¯•æ°´ç®±å’ŒçœŸå®ä¸–ç•Œæ²³æµç¯å¢ƒä¸­æ°´ä¸‹æœºå™¨äººå¹³å°æ”¶é›†çš„ã€‚ä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒSonarSplatæä¾›äº†æ›´å¥½çš„å›¾åƒåˆæˆèƒ½åŠ›ï¼ˆ+ 3.2åˆ†è´å³°å€¼ä¿¡å™ªæ¯”ï¼‰ï¼Œå¹¶ä¸”ä¸‰ç»´é‡å»ºæ›´å‡†ç¡®ï¼ˆé™ä½äº†52%çš„Chamferè·ç¦»ï¼‰ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†SonarSplatå¯ä»¥ç”¨äºæ¶ˆé™¤æ–¹ä½æ‹–å°¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00159v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SonarSplatï¼Œä¸€ç§æ–°é¢–çš„åŸºäºé«˜æ–¯ç‚¹ç»˜æŠ€æœ¯çš„æˆåƒå£°çº³æ–¹æ³•ï¼Œå¯å®ç°çœŸå®çš„æ–°å‹è§†è§’åˆæˆï¼Œå¹¶æ¨¡æ‹Ÿå£°æ³¢æ‹–å°¾ç°è±¡ã€‚è¯¥æ–¹æ³•å°†åœºæ™¯è¡¨ç¤ºä¸ºå…·æœ‰å£°å­¦åå°„å’Œé¥±å’Œç‰¹æ€§çš„ä¸‰ç»´é«˜æ–¯é›†åˆã€‚é€šè¿‡é«˜æ•ˆçš„é«˜æ–¯æ …æ ¼åŒ–æŠ€æœ¯ï¼Œç”Ÿæˆå¿ äºå£°å­¦æˆåƒå£°çº³æ¨¡å‹çš„æ–¹ä½å›¾åƒã€‚ç‰¹åˆ«åœ°ï¼Œæœ¬æ–‡å¼€å‘äº†ä¸€ç§åœ¨é«˜æ–¯ç‚¹ç»˜æ¡†æ¶å†…æ¨¡æ‹Ÿæ–¹ä½æ‹–å°¾çš„æ–°æ–¹æ³•ã€‚é€šè¿‡å®é™…æ°´ä¸‹æœºå™¨äººå¹³å°é‡‡é›†çš„å£°çº³å›¾åƒæ•°æ®é›†è¿›è¡ŒéªŒè¯ï¼ŒSonarSplatç›¸è¾ƒäºç°æœ‰æŠ€æœ¯ï¼Œå›¾åƒåˆæˆèƒ½åŠ›æå‡ï¼ˆ+3.2 dB PSNRï¼‰ï¼Œä¸‰ç»´é‡å»ºæ›´ä¸ºç²¾å‡†ï¼ˆé™ä½äº†52%çš„Chamferè·ç¦»ï¼‰ã€‚æ­¤å¤–ï¼ŒSonarSplatè¿˜å¯ä»¥ç”¨äºå»é™¤æ–¹ä½æ‹–å½±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SonarSplatæ˜¯ä¸€ç§åŸºäºé«˜æ–¯ç‚¹ç»˜æŠ€æœ¯çš„æˆåƒå£°çº³æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†çœŸå®çš„æ–°å‹è§†è§’åˆæˆï¼Œå¹¶æ¨¡æ‹Ÿå£°æ³¢æ‹–å°¾ç°è±¡ã€‚</li>
<li>SonarSplatå°†åœºæ™¯è¡¨ç¤ºä¸ºå…·æœ‰å£°å­¦åå°„å’Œé¥±å’Œç‰¹æ€§çš„ä¸‰ç»´é«˜æ–¯é›†åˆã€‚</li>
<li>é€šè¿‡é«˜æ•ˆçš„é«˜æ–¯æ …æ ¼åŒ–æŠ€æœ¯ï¼Œç”Ÿæˆå¿ äºå£°å­¦æˆåƒå£°çº³æ¨¡å‹çš„æ–¹ä½å›¾åƒã€‚</li>
<li>SonarSplatåœ¨æ¨¡æ‹Ÿæ–¹ä½æ‹–å°¾æ–¹é¢æœ‰æ‰€åˆ›æ–°ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒSonarSplatåœ¨å›¾åƒåˆæˆå’Œä¸‰ç»´é‡å»ºæ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00159">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-86e126e7a0bd21cb2dc7935e7fca8b37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f42430ba086be735234973e6afc02a6b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-acc6dce8910dca3a2403639f45a28276.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d33d76d69a216893d2fc25446f5a426.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-af0caf0c7c4ec91f48809af55895fe6d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1de5aca1faf9b15a2c7e6845ad46350.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Deformable-Beta-Splatting"><a href="#Deformable-Beta-Splatting" class="headerlink" title="Deformable Beta Splatting"></a>Deformable Beta Splatting</h2><p><strong>Authors:Rong Liu, Dylan Sun, Meida Chen, Yue Wang, Andrew Feng</strong></p>
<p>3D Gaussian Splatting (3DGS) has advanced radiance field reconstruction by enabling real-time rendering. However, its reliance on Gaussian kernels for geometry and low-order Spherical Harmonics (SH) for color encoding limits its ability to capture complex geometries and diverse colors. We introduce Deformable Beta Splatting (DBS), a deformable and compact approach that enhances both geometry and color representation. DBS replaces Gaussian kernels with deformable Beta Kernels, which offer bounded support and adaptive frequency control to capture fine geometric details with higher fidelity while achieving better memory efficiency. In addition, we extended the Beta Kernel to color encoding, which facilitates improved representation of diffuse and specular components, yielding superior results compared to SH-based methods. Furthermore, Unlike prior densification techniques that depend on Gaussian properties, we mathematically prove that adjusting regularized opacity alone ensures distribution-preserved Markov chain Monte Carlo (MCMC), independent of the splatting kernel type. Experimental results demonstrate that DBS achieves state-of-the-art visual quality while utilizing only 45% of the parameters and rendering 1.5x faster than 3DGS-MCMC, highlighting the superior performance of DBS for real-time radiance field rendering. Interactive demonstrations and source code are available on our project website: <a target="_blank" rel="noopener" href="https://rongliu-leo.github.io/beta-splatting/">https://rongliu-leo.github.io/beta-splatting/</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰å·²ç»é€šè¿‡å®ç°å®æ—¶æ¸²æŸ“æ¨åŠ¨äº†è¾å°„åœºé‡å»ºçš„å‘å±•ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºé«˜æ–¯æ ¸è¿›è¡Œå‡ ä½•å¤„ç†ä»¥åŠä½é˜¶çƒé¢è°æ³¢ï¼ˆSHï¼‰è¿›è¡Œé¢œè‰²ç¼–ç ï¼Œè¿™é™åˆ¶äº†å…¶æ•æ‰å¤æ‚å‡ ä½•å’Œå¤šæ ·è‰²å½©çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†å¯å˜å½¢Betaè´´å›¾ï¼ˆDBSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¯å˜å½¢ä¸”ç´§å‡‘çš„æ–¹æ³•ï¼Œå¯å¢å¼ºå‡ ä½•å’Œé¢œè‰²çš„è¡¨ç¤ºã€‚DBSç”¨å¯å˜å½¢çš„Betaæ ¸æ›¿æ¢é«˜æ–¯æ ¸ï¼Œæä¾›æœ‰ç•Œæ”¯æŒå’Œè‡ªé€‚åº”é¢‘ç‡æ§åˆ¶ï¼Œä»¥æ›´é«˜çš„ä¿çœŸåº¦æ•æ‰ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ï¼ŒåŒæ—¶å®ç°æ›´å¥½çš„å†…å­˜æ•ˆç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†Betaæ ¸æ‰©å±•åˆ°é¢œè‰²ç¼–ç ï¼Œè¿™æœ‰åŠ©äºæ”¹è¿›æ¼«åå°„å’Œé•œé¢æˆåˆ†çš„è¡¨ç¤ºï¼Œä¸åŸºäºSHçš„æ–¹æ³•ç›¸æ¯”äº§ç”Ÿæ›´ä¼˜è¶Šçš„ç»“æœã€‚æ­¤å¤–ï¼Œä¸åŒäºä¾èµ–é«˜æ–¯å±æ€§çš„å…ˆå‰ç¨ å¯†åŒ–æŠ€æœ¯ï¼Œæˆ‘ä»¬ä»æ•°å­¦ä¸Šè¯æ˜ï¼Œä»…è°ƒæ•´æ­£åˆ™åŒ–ä¸é€æ˜åº¦å°±å¯ä»¥ç¡®ä¿ä¸è´´å›¾æ ¸ç±»å‹æ— å…³çš„åˆ†å¸ƒä¿ç•™é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ï¼ˆMCMCï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDBSå®ç°äº†æœ€å…ˆè¿›çš„è§†è§‰è´¨é‡ï¼ŒåŒæ—¶ä»…ä½¿ç”¨45%çš„å‚æ•°å¹¶ä»¥æ¯”3DGS-MCMCå¿«1.5å€çš„é€Ÿåº¦è¿›è¡Œæ¸²æŸ“ï¼Œçªæ˜¾äº†DBSåœ¨å®æ—¶è¾å°„åœºæ¸²æŸ“ä¸­çš„å“è¶Šæ€§èƒ½ã€‚äº¤äº’å¼æ¼”ç¤ºå’Œé¡¹ç›®æºä»£ç å¯åœ¨æˆ‘ä»¬çš„ç½‘ç«™ä¸Šæ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://rongliu-leo.github.io/beta-splatting/%E3%80%82">https://rongliu-leo.github.io/beta-splatting/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18630v2">PDF</a> SIGGRAPH 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºå¯å˜å½¢Beta Splattingï¼ˆDBSï¼‰æŠ€æœ¯çš„è¾å°„åœºé‡å»ºæ–¹æ³•ã€‚è¯¥æŠ€æœ¯æ”¹è¿›äº†3D Gaussian Splattingï¼ˆ3DGSï¼‰çš„å‡ ä½•å’Œè‰²å½©è¡¨ç°èƒ½åŠ›ï¼Œé€šè¿‡ä½¿ç”¨å¯å˜å½¢Betaæ ¸æ¥æé«˜å‡ ä½•ç»†èŠ‚è¡¨ç°ï¼ŒåŒæ—¶æ‰©å±•Betaæ ¸è‡³è‰²å½©ç¼–ç ä»¥æå‡è‰²å½©è¡¨ç°ã€‚æ­¤å¤–ï¼ŒDBSä¼˜åŒ–äº†å†…å­˜æ•ˆç‡å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œå®ç°äº†å®æ—¶è¾å°„åœºæ¸²æŸ“çš„ä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSå—é™äºé«˜æ–¯æ ¸å’Œä½é˜¶çƒé¢è°æ³¢ï¼ˆSHï¼‰çš„è‰²å½©ç¼–ç ï¼Œéš¾ä»¥æ•æ‰å¤æ‚å‡ ä½•å’Œå¤šæ ·è‰²å½©ã€‚</li>
<li>DBSé€šè¿‡å¼•å…¥å¯å˜å½¢Betaæ ¸ï¼Œå¢å¼ºäº†å‡ ä½•è¡¨ç°èƒ½åŠ›ï¼Œå¯å®ç°æ›´é«˜ç²¾åº¦çš„ç²¾ç»†å‡ ä½•ç»†èŠ‚æ•æ‰ã€‚</li>
<li>Betaæ ¸æ‰©å±•è‡³è‰²å½©ç¼–ç ï¼Œæå‡äº†æ¼«åå°„å’Œé•œé¢æˆåˆ†çš„è¡¨ç°ï¼Œä¼˜äºSHæ–¹æ³•ã€‚</li>
<li>è°ƒæ•´æ­£åˆ™åŒ–ä¸é€æ˜åº¦å¯ç¡®ä¿åˆ†å¸ƒä¿ç•™çš„Markové“¾è’™ç‰¹å¡æ´›ï¼ˆMCMCï¼‰æ–¹æ³•ï¼Œä¸splattingæ ¸ç±»å‹æ— å…³ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒDBSå®ç°äº†è¾ƒé«˜çš„è§†è§‰è´¨é‡ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ¯”3DGS-MCMCå°‘45%ï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº†1.5å€ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18630">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-94dfa34f66a21b7b5e6b60f40aafbc64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a96881ab5dec40956a2eac8bbf769e83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2beaedba4ca7ee7a41566a91640a0f49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ec2c6c2feb197d05515bc4e19ad8cab.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="3D-Vision-Language-Gaussian-Splatting"><a href="#3D-Vision-Language-Gaussian-Splatting" class="headerlink" title="3D Vision-Language Gaussian Splatting"></a>3D Vision-Language Gaussian Splatting</h2><p><strong>Authors:Qucheng Peng, Benjamin Planche, Zhongpai Gao, Meng Zheng, Anwesa Choudhuri, Terrence Chen, Chen Chen, Ziyan Wu</strong></p>
<p>Recent advancements in 3D reconstruction methods and vision-language models have propelled the development of multi-modal 3D scene understanding, which has vital applications in robotics, autonomous driving, and virtual&#x2F;augmented reality. However, current multi-modal scene understanding approaches have naively embedded semantic representations into 3D reconstruction methods without striking a balance between visual and language modalities, which leads to unsatisfying semantic rasterization of translucent or reflective objects, as well as over-fitting on color modality. To alleviate these limitations, we propose a solution that adequately handles the distinct visual and semantic modalities, i.e., a 3D vision-language Gaussian splatting model for scene understanding, to put emphasis on the representation learning of language modality. We propose a novel cross-modal rasterizer, using modality fusion along with a smoothed semantic indicator for enhancing semantic rasterization. We also employ a camera-view blending technique to improve semantic consistency between existing and synthesized views, thereby effectively mitigating over-fitting. Extensive experiments demonstrate that our method achieves state-of-the-art performance in open-vocabulary semantic segmentation, surpassing existing methods by a significant margin. </p>
<blockquote>
<p>è¿‘æœŸï¼Œä¸‰ç»´é‡å»ºæ–¹æ³•å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†å¤šæ¨¡æ€ä¸‰ç»´åœºæ™¯ç†è§£çš„å‘å±•ï¼Œè¿™åœ¨æœºå™¨äººæŠ€æœ¯ã€è‡ªåŠ¨é©¾é©¶å’Œè™šæ‹Ÿ&#x2F;å¢å¼ºç°å®ç­‰é¢†åŸŸæœ‰é‡è¦åº”ç”¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„å¤šæ¨¡æ€åœºæ™¯ç†è§£æ–¹æ³•è¿‡äºç®€å•åœ°å°†è¯­ä¹‰è¡¨ç¤ºåµŒå…¥åˆ°ä¸‰ç»´é‡å»ºæ–¹æ³•ä¸­ï¼Œè€Œæ²¡æœ‰åœ¨è§†è§‰å’Œè¯­è¨€æ¨¡æ€ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œè¿™å¯¼è‡´å¯¹åŠé€æ˜æˆ–åå°„ç‰©ä½“çš„è¯­ä¹‰æ …æ ¼åŒ–æ•ˆæœä¸ä½³ï¼Œä»¥åŠå¯¹é¢œè‰²æ¨¡æ€çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†ç¼“è§£è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆå¯ä»¥å……åˆ†å¤„ç†ä¸åŒçš„è§†è§‰å’Œè¯­ä¹‰æ¨¡æ€ï¼Œå³ä¸€ç§ç”¨äºåœºæ™¯ç†è§£çš„ä¸‰ç»´è§†è§‰è¯­è¨€é«˜æ–¯å¹³é“ºæ¨¡å‹ï¼Œé‡ç‚¹å­¦ä¹ è¯­è¨€æ¨¡æ€çš„è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è·¨æ¨¡æ€æ …æ ¼åŒ–å™¨ï¼Œä½¿ç”¨æ¨¡æ€èåˆä»¥åŠå¹³æ»‘çš„è¯­ä¹‰æŒ‡æ ‡æ¥å¢å¼ºè¯­ä¹‰æ …æ ¼åŒ–ã€‚æˆ‘ä»¬è¿˜é‡‡ç”¨ç›¸æœºè§†è§’æ··åˆæŠ€æœ¯ï¼Œä»¥æé«˜ç°æœ‰å’Œåˆæˆè§†è§’ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œä»è€Œæœ‰æ•ˆåœ°å‡è½»è¿‡æ‹Ÿåˆé—®é¢˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07577v2">PDF</a> Accepted at ICLR 2025. Main paper + supplementary material</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸï¼Œéšç€ä¸‰ç»´é‡å»ºæ–¹æ³•å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ï¼Œå¤šæ¨¡æ€ä¸‰ç»´åœºæ™¯ç†è§£å¾—åˆ°äº†æå¤§çš„å‘å±•ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿ&#x2F;å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œå½“å‰çš„å¤šæ¨¡æ€åœºæ™¯ç†è§£æ–¹æ³•åœ¨å¤„ç†åŠé€æ˜æˆ–åå°„ç‰©ä½“æ—¶å­˜åœ¨è¯­ä¹‰æ …æ ¼åŒ–ä¸ä½³çš„é—®é¢˜ï¼Œå¹¶å­˜åœ¨é¢œè‰²æ¨¡æ€çš„è¿‡æ‹Ÿåˆç°è±¡ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼šä¸€ä¸ªä¸“é—¨å¤„ç†è§†è§‰å’Œè¯­è¨€æ¨¡æ€çš„3Dè§†è§‰è¯­è¨€é«˜æ–¯æ‰©å±•æ¨¡å‹ã€‚é€šè¿‡è·¨æ¨¡æ€æ …æ ¼åŒ–æŠ€æœ¯å’Œå¹³æ»‘è¯­ä¹‰æŒ‡æ ‡çš„è¿ç”¨ï¼Œæé«˜è¯­ä¹‰æ …æ ¼åŒ–çš„è´¨é‡ã€‚åŒæ—¶é‡‡ç”¨ç›¸æœºè§†è§’èåˆæŠ€æœ¯ï¼Œæé«˜äº†ç°æœ‰å’Œåˆæˆè§†è§’ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œæœ‰æ•ˆç¼“è§£äº†è¿‡æ‹Ÿåˆç°è±¡ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿‘æœŸæŠ€æœ¯è¿›æ­¥æ¨åŠ¨äº†å¤šæ¨¡æ€ä¸‰ç»´åœºæ™¯ç†è§£çš„å‘å±•ï¼Œåº”ç”¨é¢†åŸŸå¹¿æ³›ã€‚</li>
<li>å½“å‰æ–¹æ³•åœ¨å¤„ç†åŠé€æ˜æˆ–åå°„ç‰©ä½“æ—¶å­˜åœ¨è¯­ä¹‰æ …æ ¼åŒ–é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„3Dè§†è§‰è¯­è¨€é«˜æ–¯æ‰©å±•æ¨¡å‹ï¼Œä¸“é—¨å¤„ç†è§†è§‰å’Œè¯­è¨€æ¨¡æ€ã€‚</li>
<li>é€šè¿‡è·¨æ¨¡æ€æ …æ ¼åŒ–æŠ€æœ¯å’Œå¹³æ»‘è¯­ä¹‰æŒ‡æ ‡æå‡è¯­ä¹‰æ …æ ¼åŒ–è´¨é‡ã€‚</li>
<li>é‡‡ç”¨ç›¸æœºè§†è§’èåˆæŠ€æœ¯æé«˜è§†è§’é—´è¯­ä¹‰ä¸€è‡´æ€§ï¼Œç¼“è§£è¿‡æ‹Ÿåˆç°è±¡ã€‚</li>
<li>å®éªŒè¯æ˜æ‰€ææ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07577">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bc36ff4aea235aec06da31ab4b4c495d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-12c2cf9801e27459bc8bbedfb7e5494d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e4d0e79112af4dfb69cdc8df399b121.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07081bd46775dce677a96262c544a08a.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="3D-HGS-3D-Half-Gaussian-Splatting"><a href="#3D-HGS-3D-Half-Gaussian-Splatting" class="headerlink" title="3D-HGS: 3D Half-Gaussian Splatting"></a>3D-HGS: 3D Half-Gaussian Splatting</h2><p><strong>Authors:Haolin Li, Jinyang Liu, Mario Sznaier, Octavia Camps</strong></p>
<p>Photo-realistic image rendering from 3D scene reconstruction has advanced significantly with neural rendering techniques. Among these, 3D Gaussian Splatting (3D-GS) outperforms Neural Radiance Fields (NeRFs) in quality and speed but struggles with shape and color discontinuities. We propose 3D Half-Gaussian (3D-HGS) kernels as a plug-and-play solution to address these limitations. Our experiments show that 3D-HGS enhances existing 3D-GS methods, achieving state-of-the-art rendering quality without compromising speed. </p>
<blockquote>
<p>åŸºäºç¥ç»æ¸²æŸ“æŠ€æœ¯çš„3Dåœºæ™¯é‡å»ºçš„å…‰ç…§ç°å®å›¾åƒæ¸²æŸ“æŠ€æœ¯å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚å…¶ä¸­ï¼Œ3Dé«˜æ–¯æ¶‚ç»˜ï¼ˆ3D-GSï¼‰åœ¨è´¨é‡å’Œé€Ÿåº¦æ–¹é¢ä¼˜äºç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰ï¼Œä½†åœ¨å¤„ç†å½¢çŠ¶å’Œé¢œè‰²ä¸è¿ç»­æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æˆ‘ä»¬æå‡ºäº†3DåŠé«˜æ–¯ï¼ˆ3D-HGSï¼‰æ ¸ä½œä¸ºä¸€ç§å³æ’å³ç”¨çš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³è¿™äº›å±€é™æ€§ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œ3D-HGSå¯ä»¥å¢å¼ºç°æœ‰çš„3D-GSæ–¹æ³•ï¼Œåœ¨ä¸ç‰ºç‰²é€Ÿåº¦çš„æƒ…å†µä¸‹å®ç°æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02720v4">PDF</a> 8 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¥ç»æ¸²æŸ“æŠ€æœ¯çš„ä¸‰ç»´åœºæ™¯é‡å»ºçš„å…‰ç…§ç°å®å›¾åƒæ¸²æŸ“å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•å¦‚Neural Radiance Fields (NeRFs)åœ¨æŸäº›æƒ…å†µä¸‹ä»é¢ä¸´è´¨é‡ä¸é«˜å’Œé€Ÿåº¦ç¼“æ…¢çš„é—®é¢˜ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è§£å†³æ–¹æ¡ˆâ€”â€”ä½¿ç”¨ä¸‰ç»´åŠé«˜æ–¯ï¼ˆHalf-Gaussianï¼‰æ ¸æŠ€æœ¯ï¼Œå®ƒèƒ½åœ¨ä¿è¯æ¸²æŸ“é€Ÿåº¦çš„åŒæ—¶æé«˜æ¸²æŸ“è´¨é‡ã€‚è¯¥æŠ€æœ¯ä½œä¸ºä¸€ä¸ªæ’æ‹¨å¼çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æ”¹å–„ç°æœ‰çš„æŠ€æœ¯ï¼Œå¹¶å®ç°ç›®å‰æœ€é«˜æ°´å¹³çš„æ¸²æŸ“è´¨é‡ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™ä¸€æŠ€æœ¯å°†åœ¨æœªæ¥çš„å›¾åƒæ¸²æŸ“é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¥ç»æ¸²æŸ“æŠ€æœ¯åœ¨ä¸‰ç»´åœºæ™¯é‡å»ºçš„å…‰ç…§ç°å®å›¾åƒæ¸²æŸ“æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>å½“å‰æ–¹æ³•å¦‚NeRFsåœ¨è´¨é‡å’Œé€Ÿåº¦æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>ä¸‰ç»´åŠé«˜æ–¯æ ¸æŠ€æœ¯ä½œä¸ºä¸€ç§æ’æ‹¨å¼è§£å†³æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•çš„å±€é™ã€‚</li>
<li>ä¸‰ç»´åŠé«˜æ–¯æ ¸æŠ€æœ¯èƒ½å¤Ÿæ”¹å–„ç°æœ‰æŠ€æœ¯å¹¶æå‡æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶ä¸ç‰ºç‰²é€Ÿåº¦ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.02720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9dbd21b86a7094db10f9b314c84e3263.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f44bbe830f53e3cc6444f38d72e9f52.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e9d66e77c466f1d355effdd364afb57a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-309644193ee175f318eda7cc06cdef21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc2bdec3b8a6a150c8f0c6f5d2b1349a.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-08/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-08/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-08/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-5cbe5993b0e82f86f21ec2593ea7f2ee.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-08  HandOcc NeRF-based Hand Rendering with Occupancy Networks
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-08/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cacc015185950b7a73906eff414d22d2.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-08  GUAVA Generalizable Upper Body 3D Gaussian Avatar
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32127.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
